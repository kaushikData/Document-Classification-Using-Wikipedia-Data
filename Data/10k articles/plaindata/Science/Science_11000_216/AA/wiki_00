{"id": "14754901", "url": "https://en.wikipedia.org/wiki?curid=14754901", "title": "3C 61.1", "text": "3C 61.1\n\n3C 61.1 is a Seyfert galaxy located in the constellation Cepheus.\n\n"}
{"id": "43325753", "url": "https://en.wikipedia.org/wiki?curid=43325753", "title": "Ammonium cyanate", "text": "Ammonium cyanate\n\nAmmonium cyanate is an inorganic compound with the formula NHOCN. It is a colorless solid.\n\nThe structure of this salt was verified by X-ray crystallography. The respective C−O and C−N distances are 1.174(8) and 1.192(7) Å, consistent with the O=C=N description. NH forms hydrogen bonds to N, not O.\n\nThe compound is notable as the precursor in the Wöhler synthesis of urea, an organic compound, from inorganic reactants.\n"}
{"id": "23580996", "url": "https://en.wikipedia.org/wiki?curid=23580996", "title": "Armilenium", "text": "Armilenium\n\nArmilenium is a CH carbocation and was originally proposed as the first entirely organic sandwich compound. Named for its resemblance to an armillary sphere, NMR evidence for the carbocation was first described by Melvin J. Goldstein and Stanley A. Klein at Cornell University in 1973. In subsequent C NMR experiments by Goldstein and Joseph P. Dinnocenzo in 1984, the CH carbocation was generated under stable ion conditions at lower temperature and at higher magnetic field than previously possible. These experiments revealed the carbocation to be fluxional. Fitting of the dynamic NMR process ruled out the sandwich species even as an intermediate in the 20-fold degenerate rearrangement of the carbocation.\n\n"}
{"id": "16696535", "url": "https://en.wikipedia.org/wiki?curid=16696535", "title": "Backstepping", "text": "Backstepping\n\nIn control theory, backstepping is a technique developed circa 1990 by Petar V. Kokotovic and others for designing stabilizing controls for a special class of nonlinear dynamical systems. These systems are built from subsystems that radiate out from an irreducible subsystem that can be stabilized using some other method. Because of this recursive structure, the designer can start the design process at the known-stable system and \"back out\" new controllers that progressively stabilize each outer subsystem. The process terminates when the final external control is reached. Hence, this process is known as \"backstepping.\"\n\nThe backstepping approach provides a recursive method for stabilizing the origin of a system in strict-feedback form. That is, consider a system of the form\n\nwhere\n\nAlso assume that the subsystem\nis stabilized to the origin (i.e., formula_11) by some known control formula_12 such that formula_13. It is also assumed that a Lyapunov function formula_14 for this stable subsystem is known. That is, this subsystem is stabilized by some other method and backstepping extends its stability to the formula_15 shell around it.\n\nIn systems of this \"strict-feedback form\" around a stable subsystem,\nThe backstepping approach determines how to stabilize the subsystem using formula_21, and then proceeds with determining how to make the next state formula_22 drive formula_21 to the control required to stabilize . Hence, the process \"steps backward\" from out of the strict-feedback form system until the ultimate control is designed.\n\n\nThis process is known as backstepping because it starts with the requirements on some internal subsystem for stability and progressively \"steps back\" out of the system, maintaining stability at each step. Because\nthen the resulting system has an equilibrium at the origin (i.e., where formula_64, formula_65, formula_66, ..., formula_67, and formula_68) that is globally asymptotically stable.\n\nBefore describing the backstepping procedure for general strict-feedback form dynamical systems, it is convenient to discuss the approach for a smaller class of strict-feedback form systems. These systems connect a series of integrators to the input of a\nsystem with a known feedback-stabilizing control law, and so the stabilizing approach is known as \"integrator backstepping.\" With a small modification, the integrator backstepping approach can be extended to handle all strict-feedback form systems.\n\nConsider the dynamical system\n\\dot{z}_1 = u_1\n\\end{cases}</math>\n\nwhere formula_2 and formula_21 is a scalar. This system is a cascade connection of an integrator with the subsystem (i.e., the input enters an integrator, and the integral formula_21 enters the subsystem).\n\nWe assume that formula_72, and so if formula_73, formula_11 and formula_75, then\nSo the origin formula_77 is an equilibrium (i.e., a stationary point) of the system. If the system ever reaches the origin, it will remain there forever after.\n\nIn this example, backstepping is used to stabilize the single-integrator system in Equation () around its equilibrium at the origin. To be less precise, we wish to design a control law formula_29 that ensures that the states formula_79 return to formula_80 after the system is started from some arbitrary initial condition.\n\n\n\n\n\n\n\ng_x(\\mathbf{x})-k_1(\\underbrace{z_1-u_x(\\mathbf{x})}_{e_1})}^{v_1} \\, + \\, \\overbrace{\\frac{\\partial u_x}{\\partial \\mathbf{x}}(\\underbrace{f_x(\\mathbf{x})+g_x(\\mathbf{x})z_1}_{\\dot{\\mathbf{x}} \\text{ (i.e., } \\frac{\\operatorname{d}\\mathbf{x}}{\\operatorname{d}t} \\text{)}})}^{\\dot{u}_x \\text{ (i.e., } \\frac{ \\operatorname{d}u_x }{\\operatorname{d}t} \\text{)}}</math>\n\nSo because this system is feedback stabilized by formula_144 and has Lyapunov function formula_145 with formula_146, it can be used as the upper subsystem in another single-integrator cascade system.\n\nBefore discussing the recursive procedure for the general multiple-integrator case, it is instructive to study the recursion present in the two-integrator case. That is, consider the dynamical system\n\\dot{z}_1 = z_2\\\\\n\\dot{z}_2 = u_2\n\\end{cases}</math>\n\nwhere formula_2 and formula_21 and formula_22 are scalars. This system is a cascade connection of the single-integrator system in Equation () with another integrator (i.e., the input formula_41 enters through an integrator, and the output of that integrator enters the system in Equation () by its formula_34 input).\n\nBy letting\nthen the two-integrator system in Equation () becomes the single-integrator system\n\\dot{z}_2 = u_2.\n\\end{cases}</math>\n\nBy the single-integrator procedure, the control law formula_155 stabilizes the upper formula_22-to- subsystem using the Lyapunov function formula_145, and so Equation () is a new single-integrator system that is structurally equivalent to the single-integrator system in Equation (). So a stabilizing control formula_41 can be found using the same single-integrator procedure that was used to find formula_34.\n\nIn the two-integrator case, the upper single-integrator subsystem was stabilized yielding a new single-integrator system that can be similarly stabilized. This recursive procedure can be extended to handle any finite number of integrators. This claim can be formally proved with mathematical induction. Here, a stabilized multiple-integrator system is built up from subsystems of already-stabilized multiple-integrator subsystems.\n\n\n\n\n\nHence, any system in this special many-integrator strict-feedback form can be feedback stabilized using a straightforward procedure that can even be automated (e.g., as part of an adaptive control algorithm).\n\nSystems in the special strict-feedback form have a recursive structure similar to the many-integrator system structure. Likewise, they are stabilized by stabilizing the smallest cascaded system and then \"backstepping\" to the next cascaded system and repeating the procedure. So it is critical to develop a single-step procedure; that procedure can be recursively applied to cover the many-step case. Fortunately, due to the requirements on the functions in the strict-feedback form, each single-step system can be rendered by feedback to a single-integrator system, and that single-integrator system can be stabilized using methods discussed above.\n\nConsider the simple strict-feedback system\n\\dot{z}_1 = f_1(\\mathbf{x}, z_1) + g_1(\\mathbf{x}, z_1) u_1\n\\end{cases}</math>\n\nwhere\nRather than designing feedback-stabilizing control formula_34 directly, introduce a new control formula_252 (to be designed \"later\") and use control law\nwhich is possible because formula_254. So the system in Equation () is\nwhich simplifies to\nThis new formula_252-to- system matches the \"single-integrator cascade system\" in Equation (). Assuming that a feedback-stabilizing control law formula_12 and Lyapunov function formula_87 for the upper subsystem is known, the feedback-stabilizing control law from Equation () is\nwith gain formula_123. So the final feedback-stabilizing control law is\ng_x(\\mathbf{x})-k_1(z_1-u_x(\\mathbf{x})) + \\frac{\\partial u_x}{\\partial \\mathbf{x}}(f_x(\\mathbf{x})+g_x(\\mathbf{x})z_1)}^{u_{a1}(\\mathbf{x},z_1)} \\, - \\, f_1(\\mathbf{x}, z_1) \\right)</math>\nwith gain formula_123. The corresponding Lyapunov function from Equation () is\n\\dot{z}_1 = f_1( \\mathbf{x}, z_1 ) + g_1( \\mathbf{x}, z_1 ) z_2\\\\\n\\dot{z}_2 = f_2( \\mathbf{x}, z_1, z_2 ) + g_2( \\mathbf{x}, z_1, z_2 ) z_3\\\\\n\\vdots\\\\\n\\dot{z}_i = f_i( \\mathbf{x}, z_1, z_2, \\ldots, z_i ) + g_i( \\mathbf{x}, z_1, z_2, \\ldots, z_i ) z_{i+1}\\\\\n\\vdots\\\\\n\\dot{z}_{k-2} = f_{k-2}( \\mathbf{x}, z_1, z_2, \\ldots z_{k-2} ) + g_{k-2}( \\mathbf{x}, z_1, z_2, \\ldots, z_{k-2} ) z_{k-1}\\\\\n\\dot{z}_{k-1} = f_{k-1}( \\mathbf{x}, z_1, z_2, \\ldots z_{k-2}, z_{k-1} ) + g_{k-1}( \\mathbf{x}, z_1, z_2, \\ldots, z_{k-2}, z_{k-1} ) z_k\\\\\n\\dot{z}_k = f_k( \\mathbf{x}, z_1, z_2, \\ldots z_{k-1}, z_k ) + g_k( \\mathbf{x}, z_1, z_2, \\ldots, z_{k-1}, z_k ) u\n\\end{cases}</math>\nhas the recursive structure\nand can be feedback stabilized by finding the feedback-stabilizing control and Lyapunov function for the single-integrator formula_98 subsystem (i.e., with input formula_22 and output ) and iterating out from that inner subsystem until the ultimate feedback-stabilizing control is known. At iteration , the equivalent system is\nBy Equation (), the corresponding feedback-stabilizing control law is\nwith gain formula_242. By Equation (), the corresponding Lyapunov function is\nBy this construction, the ultimate control formula_244 (i.e., ultimate control is found at final iteration formula_245).\nHence, any strict-feedback system can be feedback stabilized using a straightforward procedure that can even be automated (e.g., as part of an adaptive control algorithm).\n\n"}
{"id": "5469882", "url": "https://en.wikipedia.org/wiki?curid=5469882", "title": "Behavioral enrichment", "text": "Behavioral enrichment\n\nBehavioral enrichment (also referred to as environmental enrichment) is an animal husbandry principle that seeks to enhance the quality of captive animal care by identifying and providing the environmental stimuli necessary for optimal psychological and physiological well-being. Environmental enrichment can either be active or passive, depending on whether it requires direct contact between the animal and the enrichment. A variety of enrichment techniques are used to create desired outcomes similar to an animals individual and species' history. Each of the techniques used are intended to stimulate the animal's senses similarly to how they would be activated in the wild. Provided enrichment may be seen in the form of auditory, olfactory, habitat factors, food, research projects, training, and objects.\n\nEnvironmental enrichment improves the overall welfare of animals in captivity and creates a habitat similar to what they would experience in their wild environment. It can aims to maintain an animal's physical and psychological health by increasing the range or number of species-specific behaviors, increasing positive interaction with the captive environment, preventing or reducing the frequency of abnormal behaviors, such as stereotypies, and increasing the individual's ability to cope with the challenges of captivity.\n\nEnvironmental enrichment can be offered to any animal in captivity, including:\nEnvironmental enrichment can be beneficial to a wide range of vertebrates and invertebrates such as land mammals, marine mammals, and amphibians. In the United States, specific regulations (Animal Welfare Act of 1966) must be followed for enrichment plans in order to guarantee, regulate, and provide appropriate living environments and stimulation for animals in captivity. Moreover, the Association of Zoos and Aquariums (also known as the AZA), requires that animal husbandry and welfare be a main concern for those caring for animals in captivity.\n\nPassive enrichment provides sensory stimulation but no direct contact or control. This type of enrichment is commonly used for its potential to benefit several animals simultaneously as well as requiring limited direct animal contact.\n\nVisual enrichment is typically provided by changing the layout of an animal's holding area. The type of visual enrichment can vary, from something as simple as adding pictures on walls to videotapes and television. Visual enrichment such as television can especially benefit animals housed in single cages.\n\nMirrors are also a potential form of enrichment, specifically for animals that display an understanding of self-recognition, such as non-human primates. In addition to using mirrors to reflect the animal's own image, mirrors can also be angled so the animal is able to see normally out-of-sight areas of the holding area.\n\nEnclosures in modern zoos are often designed to facilitate environmental enrichment. For example, the Denver Zoo's exhibit Predator Ridge allows different African carnivores to be rotated among several enclosures, providing the animals with a differently sized environment.\n\nIn the wild, animals are exposed to a variety of sounds that they normally do not encounter in captivity. Auditory enrichment can be used to mimic the animal's natural habitat. Types of nature-based auditory enrichment include rainforest sounds and conspecific vocalizations.\n\nThe most common form of auditory enrichment is music, whose principal stems primarily from its benefit to humans. The benefits of classical music have been widely studied in animals, from sows to non-human primates. Studies have also looked at various other genres, such as pop and rock, but their ability to provide effective enrichment remains inconclusive. Most types of music that are selected for enrichment are based on human preferences, causing anthropomorphic biases that may not translate to animals. Therefore, music that is specifically attuned to the animal's auditory senses could be beneficial. Species-specific sounds require further research to find what pitch, frequency, and range is most suitable for the animal.\n\nActive enrichment often requires the animal to perform some sort of physical activity as well as direct interaction with the enrichment object. Active enrichment items can temporarily reduce stereotypic behaviors as their beneficial effects are usually limited to the short periods of active use.\n\nInanimate tactile enrichment encourages the animal to explore and manipulate various kinds of inanimate objects, behaviors that the animal would naturally display in the wild. Most inanimate tactile enrichment occurs in the context of searching for food, such as cracking open a nut or digging holes in tree trunks for worms. Other common manipulable tactile objects include rubber toys stuffed with treats. Instead of providing the food directly, foraging devices are useful in increasing the amount of searching and foraging of food, comparable to the amount of time they would spend in the wild. Elaborate systems of food presentation have also been developed (e.g. presenting dead rats for wildcats in a Swedish zoo) and computer programmed devices which allow the animals in the enclosure to search for prey as they would in their natural environment.\n\nInanimate tactile enrichment can also be beneficial without the association with food. For example, stones have been shown to encourage exploratory behavior in Japanese macaques. Interaction with the stones exhibited behaviors such as gathering, rolling in hands, rubbing, and carrying.\n\nOther common forms include cardboard, forage, and even the texture of the food (i.e. hard, smooth, cold, warm).\n\nOlfactory enrichment can stimulate naturalistic behavior, enhance exploration, and reduce inactivity. This type of enrichment is most commonly used for wild felines, both large and small. Exposure to different odors has been shown to influence behavior, resulting in increased activity and exploration. Odors can be smeared or sprayed on an object such as a ball or a tree branch. Types of odors can include catnip, odor of conspecific, or perfume.\n\nLack of cognitive stimulation could cause boredom and frustration which are manifested in behavioral disturbances. Because most cognitive enrichment is reinforced with food, it activates reward-related circuits in the brain that can directly affect emotional processes of appraisal. Puzzle feeders are a common method of providing cognitive enrichment, as it makes food harder to access than during routine feeding. Some consider training to be a form of cognitive enrichment, since it requires animals to use their cognitive skills to respond to cues.\n\nComputerized tasks are growing in popularity as it provides feedback as to whether an animal is cognitively enriched. These tasks are designed to test a specific cognitive skill and are standardized so that performance can be compared within and between subjects. It is important to ensure that the task provided is not too easy for the animal, nor too difficult that they get discouraged.\n\nSocial enrichment can either involve housing a group of conspecifics or animals of different species that would naturally encounter each other in the wild. Social animals in particular (i.e. most primates, lions, flamingos, etc.), benefit from social enrichment because it has the positive effect of creating confidence in the group. Social enrichment can encourage social behaviors that are seen in the wild, including feeding, foraging, defense, territoriality, reproduction, and courtship.\n\nThe most common form of human-interaction enrichment is training. The human and animal interaction during training builds trust, and increases the animal's cooperation during clinical and research procedures. In addition, training sessions have been shown to benefit the welfare of both individually housed animals and communally housed animals by providing cognitive stimulation, increasing social play, decreasing inactivity, and mitigating social aggression during feeding.\n\nA survey of over 200 staff working with mammals at 60 zoos in 13 countries found that all forms of enrichment were considered important for mammals, but several of them were rarely available, because of lack of staff or other priorities.\n\nA range of methods can be used to assess which environmental enrichments should be provided. These are based on the premises that captive animals should perform behaviours in a similar way to those in the ethogram of their ancestral species, animals should be allowed to perform the activities or interactions they prefer, i.e. preference test studies, and animals should be allowed to perform those activities for which they are highly motivated, i.e. motivation studies.\n\nEnvironmental enrichment is a way to ensure that an animals natural and instinctual behaviors are kept and able to be passed and taught from one generation to the next. Enrichment techniques that encourage species specific behaviors, like those that are discovered in the wild, have been studied and found to help the process of reintroduction of endangered species into their natural habitats, as well as helping to create offspring with natural traits and behaviors.\n\nThe main way the success of environmental enrichment can be measured is by recognizing the behavioral changes that occur from the techniques used to shape desired behaviors of the animal compared to the behaviors of those found in the wild. Other ways that the success of environmental enrichment can be assessed quantitatvely by a range of behavioral and physiological indicators of animal welfare. In addition to those listed above, behavioral indicators include the occurrence of abnormal behaviours (e.g. stereotypies, cognitive bias studies, and the effects of frustration. Physiological indicators include heart rate, corticosteroids, immune function, neuorobiology, eggshell quality and thermography.\n\nIt is very difficult for zookeepers to measure the effectiveness of enrichment in terms of the stress due to the fact that animals that are found in zoos are oftentimes on display and presented with very abnormal conditions that can cause uneasiness and stress. Measuring enrichment in terms of reproduction is easier because of our ability to record offspring numbers and fertility. By making necessary environment changes and providing mental stimulation, animals in captivity have been seen to reproduce at a more similar rate to their wild ancestors in comparison to those provided with less behavioral and environmental enrichment.\n\nAlthough environmental enrichments can provide sensory and social stimulations, it can also have limited efficacy if not changed frequently. Animals can become habituated to environmental enrichments, showing positive behaviors at onset of exposure and progressively declining with time. Environmental enrichments are effective primarily because it offers novelty stimuli, making the animal's daily routines less predictable, as would be in the wild. Therefore, maintaining novelty is important for the efficacy of the enrichment. Frequently changing the type of environmental enrichment will help prevent habituation.\n\nUsage of more highly advanced enrichment devices, such as computerized devices, requires training. This can lead to issues as training often consists of food as a reward. While food encourages the animal to participate with the device, the animal could associate the device with food. As a result, the interaction with the enrichment would bring about behaviors that are associated with training instead of the desired playful and voluntary behaviors.\n\nThe process of producing and providing environmental enrichment usually require a large allocation of time and resources. In a survey, \"time taken by animal care staff to complete other tasks\" was the most significant factor influencing environmental enrichment provisions and scheduling. Therefore it is important to develop appropriate environmental enrichment programs that can be effectively carried out with the size of staff and time available.\n\n"}
{"id": "14063216", "url": "https://en.wikipedia.org/wiki?curid=14063216", "title": "Biomechanical engineering", "text": "Biomechanical engineering\n\nBiomechanical engineering is a bioengineering subdiscipline, which applies principles of mechanical engineering to biological systems and stems from the scientific discipline of biomechanics. Topics of interest in the field include biomedical engineering and agricultural engineering. Biomechanics, specifically, is the study of biological systems such as the human body, combined with the study of mechanics, or mechanical applications. Using the skills learned from biology, engineering and physics to research and develop for health care, such as organs that have been made from artificial materials, or new advances with prosthetic limbs. The creation of biomaterial, which is a fake material that can be integrated into living tissue or can live in sync with biological material, is one of the biggest advances in medicine to this day. Those in this field might also hold the job of not only installing, but also adjusting, maintain, repairing, and providing technical help for all the biomaterial.\n\n"}
{"id": "25257593", "url": "https://en.wikipedia.org/wiki?curid=25257593", "title": "Brian Dunning (author)", "text": "Brian Dunning (author)\n\nBrian Andrew Dunning (born 1965) is an American writer and producer who focuses on science and skepticism. He has hosted a weekly podcast, \"Skeptoid\", since 2006, and he is an author of a series of books on the subject of scientific skepticism, some of which are based on the podcast. \"Skeptoid\" has been the recipient of several podcast awards such as the Parsec Award. Dunning has also created the \"Skeptoid.org\" spin-off video series, \"inFact\", and \"The Feeding Tube\" both available on YouTube.\n\nDunning has produced two educational films on the subject of critical thinking, \"Here be Dragons\" in 2008, and \"Principles of Curiosity\" in 2017.\n\nDunning co-founded Buylink, a business-to-business service provider, in 1996, and served at the company until 2002. He later became eBay's second biggest affiliate marketer; he has since been convicted of wire fraud through a cookie stuffing scheme. In August 2014, he was sentenced to 15 months in prison, to be followed by three years of supervised release for the company obtaining between $200,000 and $400,000 through wire fraud.\n\nIn 1996 Dunning co-founded and was chief technology officer for Buylink Corporation. Buylink received venture capital funding from Hummer Winblad Venture Partners. In 2000 he participated in a presentation on Buylink at The Berkeley Entrepreneurs Forum called \"Bricks to Clicks in the New Internet Reality\". He discussed the company on CNNfn's \"Market Call\", in Rhonda Schaffler's \"Maverick of the Morning\" segment. In 2002, Dunning left his position as CTO of BuyLink.\n\nBetween 1997 and 2005 he was technical editor for FileMaker Advisor Magazine, and contributing editor of ISO FileMaker Magazine, 1996–2002, winning one of the FileMaker Excellence Awards at the 2001 FileMaker Developers Conference.\n\nBeginning in 2006, Dunning hosted and produced \"Skeptoid\", a weekly audio podcast dedicated \"to furthering knowledge by blasting away the widespread pseudosciences that infect popular culture, and replacing them with way cooler reality.\" He is also the author of the book of the same title and a sequel.\n\nBeginning in 2007, Dunning periodically released video episodes of his \"InFact\" series. Each episode is under four minutes long and covers issues similar to those explored in more depth in the \"Skeptoid\" podcast, but is intended to reach a wider audience due to its brevity and availability on YouTube.\n\nIn 2008 Dunning produced \"Here Be Dragons\", a free 40 minute video introduction to critical thinking intended for general audiences, and received an award from the Portland Humanist Film Festival for this in November 2011.\n\nIn 2010 Dunning was awarded the Parsec Award for \"Best Fact Behind the Fiction Podcast\". In August 2010 he received an award recognizing his contributions in the skeptical field from the Independent Investigations Group (IIG) during its 10th Anniversary Gala.\n\nIn June 2017 Dunning's second film, \"Principles of Curiosity\", was released. According to Dunning, this \"presents a general introduction to the foundations of scientific skepticism and critical thinking... It is nonprofit, noncommercial, and licensed for free public and private screenings. It is provided with free educational materials for teachers, designed for high school through college. It is suitable for all audiences. Its 40-minute runtime should fit into most classes.\"\n\nDunning has written articles for Skepticblog.org, published by The Skeptics Society, and was an executive producer for the unreleased network television pilot \"The Skeptologists\".\nHe is a member of the National Association of Science Writers, and is the \"Chancellor\" of the non-accredited \"Thunderwood College\", a parody of unaccredited institutions of higher learning which offer \"degrees\" in a variety of subjects.\n\nIn August 2008, eBay filed suit against Dunning, accusing him of defrauding eBay and eBay affiliates in a cookie stuffing scheme for his company, Kessler's Flying Circus. In June 2010, based on the same allegations and following an investigation by the Federal Bureau of Investigation, a grand jury indicted Dunning on charges of wire fraud. On April 15, 2013, in the San Jose, California, U.S. District Court, as part of a plea agreement, Dunning pleaded guilty to wire fraud.\n\nFrom an agreement of the parties, the eBay civil suit was dismissed in May 2014 and Dunning was sentenced in August 2014 to fifteen months in prison for the company receiving between $200,000 and $400,000 in fraudulent commissions from eBay. Dunning admitted that he received payments to which he was not entitled, commenting \"I fully accept this determination, and fully accept and admit responsibility for every action I was involved in.\"\n\n\"Skeptoid\" is Dunning's weekly podcast. The show follows an audio essay format, and is dedicated to the critical examination of pseudoscience and the paranormal. In May 2012, \"Skeptoid\" became a California state non-profit corporation.\n\nAlong with similarly themed \"Point of Inquiry\", \"Skepticality: The Official Podcast of Skeptic Magazine\", and \"The Skeptics' Guide to the Universe\", it is listed on an iTunes (US) web page of popular science and medicine podcasts. In May 2014, \"Skeptoid\"’s website reported that the podcast had a weekly average of 161,000 downloads.\n\nEach roughly ten-minute \"Skeptoid\" episode focuses on a single issue that is generally pseudoscientific in nature. Transcriptions of the episodes are available on line, and usually fall into one of four categories:\n\nBeginning in 2007, Dunning authored a series of books based upon the \"Skeptoid\" podcast episodes.\n\nDespite his shift away from the technology industry, Dunning continues to do computer programming, and does web development for his Skeptoid website.\n\n\"Skeptoid\" was a 2009 Podcast Awards finalist in the Education category.\n\nIn 2010, \"Skeptoid\" won the Parsec Award for \"Best Fact Behind the Fiction\" podcast. Also in 2010, \"Skeptoid\" was recognized for \"Outstanding Contribution to Science and Skepticism\" by the Independent Investigations Group (IIG).\n\n\n"}
{"id": "12180808", "url": "https://en.wikipedia.org/wiki?curid=12180808", "title": "British Society for Social Responsibility in Science", "text": "British Society for Social Responsibility in Science\n\nThe British Society for Social Responsibility in Science (BSSRS) was a radical science movement most active in the 1970s. It was formed in 1968 in opposition to university research on chemical and biological weapons, and supported by 83 distinguished scientists, including William Bragg, Francis Crick, Julian Huxley and Bertrand Russell. Nobel laureate Maurice Wilkins was the founding President.\nThe main aims of the BSSRS was to raise awareness of the social responsibilities of scientists, the political aspect of science and technology, and to create an informed public.\nAmong groups that were particularly active in BSSRS were members of\n\nBSSRS's inaugural meeting, sponsored by 64 Fellows, was held at the Royal Society, and attended by more\nthan 300, mostly UK, scientists and engineers. Professor Maurice Wilkins\nwas the founding President (1969–91).\n\nOne of the groups first targets was the British Science Association. At a meeting of the BSA in Durham in 1970, they raised political issues under a banner of \"Science is not neutral\". They continued their stance against the BSA, claiming it served a \"propagandist function\".\n\nBSSRS published a newssheet (1969–72), continued by Science for People, (1972/3), and also had local societies and organized public meetings, as well as publishing longer research monographs. \n\nBurhop (1971); Dickson (1971). See also Hilary Rose and Steven Rose (1976); Pirani (1970); Werskey (1971); Fuller (ed.) (1971) and Rose (2003).\n\nThere is an archive group of BSSRS collecting materials, with a website www.bssrs.org. \nBSSRS (archive)\n\n"}
{"id": "24652286", "url": "https://en.wikipedia.org/wiki?curid=24652286", "title": "Bumper fracture", "text": "Bumper fracture\n\nA bumper fracture is a fracture of the lateral tibial plateau caused by the bumper of a car coming into contact with the outer side of the knee when a person is standing.\nSpecifically, it is caused by a forced valgus applied to the knee. This causes the lateral part of the distal femur and the lateral tibial plateau to come into contact, compressing the tibial plateau and causing the tibia to fracture. The name of the injury is because it was described as being caused by the impact of a car bumper on the lateral side of the knee while the foot is planted on the ground, although this mechanism is only seen in about 25% of tibial plateau fractures.\n\nFracture of the neck of the fibula may also be found, and associated injury to the medial collateral ligament or cruciate ligaments occurs in about 10% of cases. \n\nThe term \"bumper fracture\" was coined in 1929 by Cotton and Berg.\n"}
{"id": "4494160", "url": "https://en.wikipedia.org/wiki?curid=4494160", "title": "California Commission for Economic Development", "text": "California Commission for Economic Development\n\nThe California Commission for Economic Development (CED) was established by statute in 1971 to serve as a bipartisan advisory board on economic development issues to the executive and legislative leadership of the State of California. The CED is composed of six members of the State legislature and ten members of the public appointed by the current Governor and represent several industries within California. \n\nThe Commission served the state under the statutory Chairmanship of Lieutenant Governors from 1971 through 1994, but in the seven years that followed, funding for the Commission was not included in the annual state budgets. Recognizing the need for additional economic development efforts, Governor Gray Davis and the Legislature restored funding for the Commission in 2002. In mid-2003, the Governor appointed a sufficient number of members to establish a quorum. Under a previous Chair, Lt. Governor Cruz Bustamante, the Commission held its first official meeting in more than ten years on December 15, 2003. The most recent Chair, prior to Gavin Newsom, was Lieutenant Governor John Garamendi. Under Garamendi, quarterly meetings took place in July and November 2007 and February and May 2008. He ended his term as Lieutenant Governor of California when he was elected into office in 2009. The current Lieutenant Governor, Gavin Newsom, provided an agenda for economic growth and competitiveness for California in 2011. This agenda was the first statewide economic plan in over ten years. By 2016, over 75-percent of the recommendations presented in the plan had been at least partially implemented. \n\nPursuant to California Code §14999-14999.10, the Commission has the following powers and authority to carry out its statutory duties:\n\n· Evaluating specific economic development problems and providing recommendations for possible solutions.\n\n· Maintaining communication about economic dilemmas between the state government and the private sector.\n\n· Make recommendations to legislation regarding ongoing economic development projects and programs .\n\n· Evaluate development programs to ensure cost efficiency.\n\n· Preparing specialized reports, which can include key secondary outcomes on economic development of programs and/or regulations, to support and guide the Governor or Legislature.\n\nThe Commission for Economic Development assesses issues relating to developing the economy and workforce, trade and government efficiency. Its many goals include increasing effectiveness of the government and its partners in developing and augmenting the workforce of California. While maintaining the workforce, the commission seeks to assemble a strong connection between workforce development and a growing economy, all while encouraging education. The large-scale goal of the CED is to unite all major aspects of an economy (development, small businesses, trade, regulations, etc.) to transform California into a productive and continuously growing entity.\n"}
{"id": "4985628", "url": "https://en.wikipedia.org/wiki?curid=4985628", "title": "Cauchy–Born rule", "text": "Cauchy–Born rule\n\nThe Cauchy–Born rule or Cauchy-Born approximation is a basic hypothesis used in the mathematical formulation of solid mechanics which relates the movement of atoms in a crystal to the overall deformation of the bulk solid. It states that in a crystalline solid subject to a small strain, the positions of the atoms within the crystal lattice follow the overall strain of the medium. The currently accepted form is Max Born's refinement of Cauchy's original hypothesis which was used to derive the equations satisfied by the Cauchy stress tensor. The approximation generally holds for face-centered and body-centered cubic crystal systems. For complex lattices such as diamond, however, the rule has to be modified to allow for internal degrees of freedom between the sublattices. The approximation can then be used to obtain bulk properties of crystalline materials such as stress-strain relationship.\n\nFor crystalline bodies of finite size, the effect of surface stress is also significant. However, the standard Cauchy–Born rule cannot deduce the surface properties. To overcome this limitation, Park et al. (2006) proposed a surface Cauchy–Born rule. Several modified forms of the Cauchy–Born rule have also been proposed to cater to crystalline bodies having special shapes. Arroyo & Belytschko (2002) proposed an exponential Cauchy Born rule for modeling of mono-layered crystalline sheets as two-dimensional continuum shells. Kumar et al. (2015) proposed a helical Cauchy–Born rule for modeling slender bodies (such as nano and continuum rods) as special Cosserat continuum rods.\n\n"}
{"id": "20584561", "url": "https://en.wikipedia.org/wiki?curid=20584561", "title": "Death from the Skies!", "text": "Death from the Skies!\n\nDeath from the Skies!: These Are The Ways The World Will End is a book by the American astronomer Phil Plait, also known as \"the Bad Astronomer\". The book was published in 2008 and explores the various ways in which the human race could be rendered extinct by astronomical phenomena.\n\nThe author stated during an interview that one of the reasons for writing the book was that \"the Universe is incredibly inhospitable, yet we have this planet that’s doing OK by us. Another is that the Universe is incredibly cool and interesting. Black holes are really fun to think about. Actually, most of this is mind-stretching and fun. What happens to the Sun after 100 quadrillion years? One hundred octillion? A googol?\" He also said that the reason for using doomsday scenarios was to take a scientific viewpoint, make it like a roller coaster or horror movie to make it fun and exciting. The stories were not to scare people out of their pants but make it cool to read about it.\n\nThe book has had positive reviews from Todd Dailey of \"Wired\" Magazine, Nancy Atkinson of \"Universe Today\", \nand Rebecca Watson from Skepchick. It was also reviewed for \"Smithsonian\" magazine by Sarah Zielinski.\n\nIn 2010 the Discovery Channel had a documentary called \"Phil Plait’s Bad Universe\". This show was based on a few chapters of the book. George Hrab and Phil Plait recorded a song called \"Death from the Skies\" whose lyrics is based on some of the events covered in the book.\n\n\n"}
{"id": "17507367", "url": "https://en.wikipedia.org/wiki?curid=17507367", "title": "Differential game", "text": "Differential game\n\nIn game theory, differential games are a group of problems related to the modeling and analysis of conflict in the context of a dynamical system. More specifically, a state variable or variables evolve over time according to a differential equation. Early analyses reflected military interests, considering two actors - the pursuer and the evader - with diametrically opposed goals. More recent analyses have reflected engineering or economic considerations.\n\nDifferential games are related closely with optimal control problems. In an optimal control problem there is single control formula_1 and a single criterion to be optimized; differential game theory generalizes this to two controls formula_2 and two criteria, one for each player. Each player attempts to control the state of the system so as to achieve its goal; the system responds to the inputs of all players.\n\nThe first to study differential games was Rufus Isaacs (1951, published 1965) and one of the first games analyzed was the 'homicidal chauffeur game'.\n\nGames with a random time horizon are a particular case of differential games. In such games, the terminal time is a random variable with a given probability distribution function. Therefore, the players maximize the mathematical expectancy of the cost function. It was shown that the modified optimization problem can be reformulated as a discounted differential game over an infinite time interval\n\nDifferential games have been applied to economics. Recent developments include adding stochasticity to differential games and the derivation of the stochastic feedback Nash equilibrium (SFNE). A recent example is the stochastic differential game of capitalism by Leong and Huang (2010). In 2016 Yuliy Sannikov received the Clark Medal from the \"American Economic Association \" for his contributions to the analysis of continuous time dynamic games using stochastic calculus methods.\n\nFor a survey of pursuit-evasion differential games see Pachter.\n\n\n"}
{"id": "5886692", "url": "https://en.wikipedia.org/wiki?curid=5886692", "title": "Flyby anomaly", "text": "Flyby anomaly\n\nThe flyby anomaly is a discrepancy between current scientific models and the actual increase in speed (i.e. increase in \"kinetic energy\") observed during a planetary flyby by a spacecraft. In multiple cases, spacecraft have been observed to gain greater speed than scientists have predicted and as yet no convincing explanation has been found. This anomaly has been observed as shifts in the S-band and X-band Doppler and ranging telemetry. Taken together, it causes a significant unaccounted velocity increase of up to 13 mm/s during flybys.\n\nGravitational assists are valuable techniques for Solar System exploration. Because the success of these flyby maneuvers depends on the geometry of the trajectory, the position and velocity of a spacecraft is continually tracked during its encounter with a planet by the Deep Space Network (DSN).\n\nThe flyby anomaly was first noticed during a careful inspection of DSN Doppler data shortly after the Earth flyby of the Galileo spacecraft on 8 December 1990. While the Doppler residuals (observed minus computed data) were expected to remain flat, the analysis revealed an unexpected 66 mHz shift, which corresponds to a velocity increase of 3.92 mm/s at perigee. Investigations of this effect at the Jet Propulsion Laboratory (JPL), the Goddard Space Flight Center (GSFC) and the University of Texas have not yielded a satisfactory explanation. No anomaly was detected after the second Earth flyby of the Galileo spacecraft in December 1992, where the measured velocity decrease matched that expected from atmospheric drag at the lower altitude of 303 km. However, the drag estimates had large error bars, and so an anomalous acceleration could not be ruled out.\n\nOn 23 January 1998 the Near Earth Asteroid Rendezvous (NEAR) spacecraft experienced an anomalous velocity increase of 13.46 mm/s after its Earth encounter. Cassini–Huygens gained around 0.11 mm/s in August 1999, and Rosetta gained 1.82 mm/s after its Earth flyby in March 2005.\n\nAn analysis of the MESSENGER spacecraft (studying Mercury) did not reveal any significant unexpected velocity increase. This may be because MESSENGER both approached and departed Earth symmetrically about the equator (see data and proposed equation below). This suggests that the anomaly may be related to Earth's rotation.\n\nIn November 2009, ESA's Rosetta spacecraft was tracked closely during flyby in order to precisely measure its velocity, in an effort to gather further data about the anomaly, but no significant anomaly was found.\n\nThe 2013 flyby of Juno on the way to Jupiter yielded no anomalous acceleration.\n\nIn 2018, a careful analysis of the trajectory of the presumed interstellar asteroid ʻOumuamua revealed a small excess velocity as it receded from the Sun. Initial speculation suggested that the anomaly was due to outgassing, though none had been detected. Is the Interstellar Asteroid Really a Comet?\n\nSummary of some Earth-flyby spacecraft is provided in table below.\n\nUpcoming missions with Earth flybys include BepiColombo with its launch due in October 2018 and its Earth flyby due April 2020.\n\nSome missions designed to study gravity, such as STEP, will make extremely accurate gravity measurement and may shed some light on the anomaly.\n\nAn empirical equation for the anomalous flyby velocity change was proposed by J. D. Anderson et al.:\n\nwhere \"ω\" is the angular frequency of the Earth, \"R\" is the Earth radius, and \"φ\" and \"φ\" are the inbound and outbound equatorial angles of the spacecraft. This formula was derived later by Jean Paul Mbelek from special relativity, leading to one of the possible explanations of the effect. This does not, however, consider the SSN residuals – see \"Possible explanations\" below.\n\nThere have been a number of proposed explanations of the flyby anomaly, including:\n\n\n\n\n"}
{"id": "22000113", "url": "https://en.wikipedia.org/wiki?curid=22000113", "title": "Four-sides model", "text": "Four-sides model\n\nThe four-sides model (also known as communication square or four-ears model) is a communication model by Friedemann Schulz von Thun. According to this model every message has four facets though not the same emphasis might be put on each. The four sides of the message are fact, self-revealing, relationship, and appeal.\n\nThe communication square describes the multi-layered structure of human utterances. It combines the idea of a postulate (second axiom) from Paul Watzlawick, that every message contains content and relational facets, with the three sides of the Organon model by Karl Bühler, that every message might reveal something about the sender, the receiver, and the request at hand. Such models are familiar in the linguistic community as part of speech act theory.\n\n\nEvery layer can be misunderstood individually.\nThe classic example of Schulz von Thun is the front-seat passenger who tells the driver: \"Hey, the traffic lights are green\". The driver will understand something different, depending on the ear with which he will hear, and will react differently. (On the matter layer he will understand the \"fact\" \"\"the traffic lights are green\", he could also understand it as \"Come on, drive\"! .\"-\"command\", or on the \"relationship\" could hear a help like \"\"I want to help you\", or if he hears behind it: \"I am in a hurry\" the passenger reveals part of himself \"self-revelatory\".\") The emphasis on the four layers can be meant differently and also be understood differently. So the sender can stress the appeal of the statement and the receiver can mainly receive the relationship part of the message. This is one of the main reasons for misunderstandings.\n\nWhat I inform about:\n\nOn the factual level the sender of the news gives data, facts and statements. It is the task of the sender to send this information clearly and understandably.\n\nThe receiver proves with the Factual ear, whether the matter message fulfills the criteria of truth (true/untrue) or relevance (relevant/irrelevant) and the completeness (satisfying/something has to be added).\n\nIn a long-term team, the matter layer is clear and needs only a few words.\n\nWhat I reveal about myself:\n\nIn every news there is information about the sender.\nOn the layer of the self-revealing or self-disclosure the sender reveals himself. This message consists of conscious intended self-expression as well as unintended self-revealing, which is not conscious to the sender (see also Johari window). Thus, every news becomes information about the personality of the sender.\n\nThe self-revealing ear of the receiver perceives which information about the sender is hidden in the message.\n\nWhat I think about you (you-statement) and how we get along (we-statement):\n\nThe relationship layer expresses how the sender gets along with the receiver and what he thinks about him. Depending on how he talks to him (way of formulation, body language, intonation ...) he expresses esteem, respect, friendliness, disinterest, contempt or something else.\n\nDepending on which message the receiver hears with relationship ear, he feels either depressed, accepted or patronized. A good communication is distinguished by communication from mutual appreciation.\n\nWhat I want to make you do:\n\nWho states something, will also affect something. This appeal-message should make the receiver do something or leave something undone. The attempt to influence someone can be less or more open (advice) or hidden (manipulation).\n\nOn the Appeal ear the receiver asks himself: \"What should I do, think or feel now?\"\n\ncitation: \" Mothers are very appeal-influenced by children.\"\nMum! The shoes ... Yes! I'll be right there to put them on for you.\n\nTwo people are eating a home-cooked meal together.\n\nThe one who didn't cook says: \"There is something green in the soup.\"\n\n\nThe other answers: \"If you don't like the taste, you can cook it yourself.\"\n\n\n\n"}
{"id": "47243902", "url": "https://en.wikipedia.org/wiki?curid=47243902", "title": "Franklin's electrostatic machine", "text": "Franklin's electrostatic machine\n\nFranklin's electrostatic machine is a high-voltage static electricity-generating device used by Benjamin Franklin in the mid-18th century for research into electrical phenomena. Its key components are a glass globe which turned on an axis via a crank, a cloth pad in contact with the spinning globe, a set of metal needles to conduct away the charge developed on the globe by its friction with the pad, and a Leyden jara high-voltage capacitorto accumulate the charge. Franklin's experiments with the machine eventually led to new theories about electricity and inventing the lightning rod.\n\nFranklin was not the first to build an electrostatic generator. European scientists developed machines to generate static electricity decades earlier. In 1663, Otto von Guericke generated static electricity with a device that used a sphere of sulfur. Francis Hauksbee developed a more advanced electrostatic generator around 1704 using a glass bulb that had a vacuum. He later replaced the globe with a glass tube of about emptied of air. The glass tube was a less effective static generator than the globe, but it became more popular because it was easier to use.\n\nMachines that generated static electricity with a glass disc were popular and widespread in Europe by 1740. In 1745, German cleric Ewald Georg von Kleist and Dutch scientist Pieter van Musschenbroek discovered independently that the electric charge from these machines could be stored in a Leyden jar, named after the city of Leiden in the Netherlands.\n\nIn 1745, Peter Collinson, a businessman from London who corresponded with American and European scientists, donated a German \"glass tube\" along with instructions how to make static electricity, to Franklin's Library Company of Philadelphia. Collinson was the library's London agent and provided the latest technology news from Europe. Franklin wrote a letter to Collinson on March 28, 1747, thanking him, and saying the tube and instructions had motivated several colleagues and him to begin serious experiments with electricity.\n\nIn 1746, Franklin began working on electrical experiments with Ebenezer Kinnersley after he bought all of Archibald Spencer's electrical equipment that he used in his lectures. Later, he was also associated with Thomas Hopkinson and Philip Syng in experimentation with electricity. In the summer of 1747 they had received an electrical system from Thomas Penn. While no records exists to tell exactly what parts were included in the system, historian J. A. Leo LeMay believes it was a combination of an electricity generating machine, a Leyden jar, a glass tube, and a stool that was electrically insulated from the ground. This gave Franklin a complete system to experiment with generating and storing electricity.\n\nWhen amber, sulfur, or glass are rubbed with certain materials, they produce electrical effects. Franklin theorized this \"electrical fire\" was collected from this other material somehow, and not produced by the friction on the object. He decided to retire early from his printing business, still in his early forties, to spend more time studying electricity. In 1748, Franklin turned over his entire printing business to his partner David Hall. He moved into a new Philadelphia home with his wife, where he built a laboratory to conduct experiments and research new electrical theories. Franklin experimented not only with the electrostatic machine with the glass globe, but also with the Leyden jar. He kept a detailed journal of his research in a diary called \"Electrical Minutes\" that has since been lost. Franklin's machine was given to Library Company of Philadelphia by Franklin's grandson in 1792, and is currently on display at the Franklin Institute.\n\nFranklin's machine used a belt and pulley system that could be operated by one person turning a crank. A large pulley was attached to the crank handle, and a much smaller pulley was attached to a large glass globe. An iron axle passed through the globe. This allowed the globe to be rotated at high speed. When the crank was turned, the glass globe rubbed against a leather pad, which generated a large static charge, similar to the electrical charge that could be created by rubbing a glass tube with wool cloth by hand. The machine was unique improvement over others made in Europe at the time, as the glass globe could be spun faster with much less labor. A few revolutions of the handle were all that were needed to charge a Leyden jar.\n\nThe electricity produced by the machine, in the form of sparks, passed through a set of metal needles positioned close to the spinning globe. The electric charge continued passing through a beaded iron chain, which acted as a conductor, to a Leyden jar that received the electricity. Franklin called the sparks produced by the machine \"electrical fire\".\n\nFranklin had help building his machine. The basic mechanical design was developed by Philip Syng. The wood frame was probably made by Franklin's friend Benjamin Loxley, a Philadelphia carpenter who made similar machines for Lewis Evans in 1751. The glass globes, known as \"electerizing globes\", were made of glass that was scientifically designed to produce static electricity effectively. Franklin specified the materials to be used in the glass formula, and the globes were manufactured by Caspar Wistar, a close associate of Franklin. Wistarburgh Glass Works also made scientific glass for the Leyden jars Franklin used in the 1750s.\n\nFranklin's experiments with Leyden jars progressed to connecting several Leyden jars together in a series, with \"one hanging on the tail of the other\". All of the jars in the series could be charged simultaneously, which multiplied the electrical effect. A similar apparatus had been created earlier by Daniel Gralath. Franklin was the first to call the device an \"electrical battery\". At that time, the word \"battery\" was a military term for a group of cannons. Franklin was the first to use \"positive\" and \"negative\" as applied to electricity which is sometimes referred to as \"plus\" and \"minus\".\n\nThrough his research, Franklin was among first to prove the electrical principal of conservation of charge in 1747: a similar discovery was made independently in 1746 by William Watson. Franklin wrote detailed letters and documents about his experiments with the electrostatic machine and Leyden jars. In 1749, Franklin made a list of several ways in which lightning was similar to electricity. He concluded that lightning was essentially nothing more than giant electric sparks, similar to the sparks from the static charges produced by his electrostatic machine. He referred to static electricity as \"electric fire\", \"electric matter, or \"electric fluid.\" The term \"electric fluid\" was based on the idea that a jar could be filled and refilled when it became empty. That led to the revolutionary idea of \"electrical fire\" as a type of motion or current flow rather than a type of explosion.\n\nSeveral 18th-century electric terms were derived from his name. For example, static electricity was known as \"Franklin current\", and \"Franklinization\" is a form of electrotherapy where Franklin shocked patients with strong static charges, to treat patients with various illnesses.\n\nFranklin invented the lightning rod based on what he learned from experiments with his electrostatic machine. Franklin and his associates observed that pointed objects were more effective than blunt objects at \"drawing off\" and \"throwing off\" sparks from static electricity. This discovery was first reported by Hopkinson. Franklin wondered if this discovery could be used in a practical invention. He thought something could be made to attract the electricity out of storm clouds, but first he had to verify that lightning bolts really are giant electric sparks. He wrote Collinson and Cadwallader Colden letters about this theory. The 1752, Franklin letter to Collinson of October 19 of the kite experiment is noted by historian LeMay as a basis how it proved that lightning was electricity. Tom Tucker of the Isothermal Community College doubts the account, however, because of ambiguities in the account and points that out in his book \"Bolt of Fate: Benjamin Franklin and his Electric Kite Hoax.\" Others disagree with this view, arguing that Franklin would not make up such a fake story because he valued the integrity of the scientific community.\nTo test his theory, Franklin proposed a potentially deadly experiment, to be performed during an electrical storm, where a person would stand on an insulated stool inside a sentry box, and hold out a long, pointed iron rod to attract a lightning bolt. A similar but less dangerous version of this experiment was first performed successfully in France On May 10, 1752, and later repeated several more times throughout Europe, though after a fatality in 1753 it was less frequently tried. Franklin declared that this \"sentry-box experiment\" showed that lightning and electricity were one and the same.\n\nFranklin realized that wooden buildings could be protected from lightning strikes, and the deadly fires that often resulted, by placing a pointed iron on a rooftop, with the other end of the rod placed deep into the ground. The sharp point of the lightning rod would attract the electrical discharge from the cloud, and the lightning bolt would hit the iron rod instead of the wooden building. The electric charge from the lightning would flow through the rod directly into the earth, bypassing the structure, and preventing a fire.\n\nFranklin's friend Kinnersley traveled throughout the eastern United States in the 1750s demonstrating man-made \"lightning\" on model thunder houses to show a how an iron rod placed into the ground would protect a wooden structure. He explained that lightning followed the same principles as the sparks from Franklin's electrostatic machine. These lectures by Kinnersley were widely advertised, and were one of the ways Franklin's lightning rod was demonstrated to the general public.\nFranklin distributed copies of the electrostatic machine to many of his close associates to encourage them to study electricity. Between 1747 and 1750, Franklin sent many letters to his friend Collinson in London about his experiments with the electrostatic machine and the Leyden jar, including his observations and theories on the principles of electricity. These letters were collected and published in 1751 in a book entitled \"Experiments and Observations on Electricity.\"\n\nWhile Joseph Priestley was writing about the history of electricity, Franklin encouraged him to use an electrostatic machine to perform the experiments he was writing about. Priestly designed and used his own variations of Franklin's machine. While replicating the electrical experiments, some unanswered questions prompted Priestly to design additional experiments, leading to additional discoveries. In 1767, he published a 700-page book on his findings called \"The History and Present State of Electricity.\"\n\nEighteenth-century scientific laboratories usually contained some form of hand-operated electrostatic machine. Italian scientist Luigi Galvani had an electrostatic generator in his laboratory, where experiments with frog legs led to the discovery of animal electricity. Another Italian scientist, Alessandro Volta, disagreed with some of Galvani's ideas, and this scientific argument motivated Volta to develop the first frog-free galvanic cell, and led directly to the invention of the first practical electric battery, the voltaic pile.\n\nAfter Franklin's death, two iconic artifacts from his research, the original \"battery\" of Leyden jars, and the \"glass tube\" that was a gift from Collinson in 1747, were given to the Royal Society in 1836 by Thomas Hopkinson's grandson Joseph Hopkinson, in accordance with Franklin's will.\n\n\n\n"}
{"id": "12515309", "url": "https://en.wikipedia.org/wiki?curid=12515309", "title": "Handley's slender opossum", "text": "Handley's slender opossum\n\nHandley's slender opossum (\"Marmosops handleyi\") is a species of opossum in the family Didelphidae. It is endemic to Colombia.\n"}
{"id": "13884766", "url": "https://en.wikipedia.org/wiki?curid=13884766", "title": "Integrated master plan", "text": "Integrated master plan\n\nIn the United States Department of Defense, the Integrated Master Plan (IMP) and the Integrated Master Schedule (IMS) are important program management tools that provide significant assistance in the planning and scheduling of work efforts in large and complex materiel acquisitions. The IMP is an event-driven plan that documents the significant accomplishments necessary to complete the work and ties each accomplishment to a key program event. The IMP is expanded to a time-based IMS to produce a networked and multi-layered schedule showing all detailed tasks required to accomplish the work effort contained in the IMP. The IMS flows directly from the IMP and supplements it with additional levels of detail——both then form the foundations to implement an Earned Value Management System.\n\n\nIn civic planning or urban planning, \"Integrated Master Plan\" is used at the levels of city development, county, and state or province to refer to a document integrating diverse aspects of a public works project.\n\nThe primary purpose of the IMP—and the supporting detailed schedules of the IMS—is their use by the U.S. Government and Contractor acquisition team as the day-to-day tools for the planning, executing, and tracking program technical, schedule, and cost status, including risk mitigation efforts. The IMP provides a better structure than either the Work Breakdown Structure (WBS) or Organizational Breakdown Structure (OBS) for measuring actual integrated master schedule (IMS) progress.\n\nThe primary objective of the IMP is a single plan that establishes the program or project fundamentals. It provides a hierarchical, event-based plan that contains: Events; Significant accomplishments; Entry and exit criteria; however it does not include any dates or durations. Using the IMP provides sufficient definition for explain program process and completion tracking, as well as providing effective communication of the program/project content and the \"What and How\" of the program.\n\nThe IMP is a collection of milestones (called \"events\") that form the process architecture of the program. This means the sequence of events must always result in a deliverable product or service. While delivering products or services is relatively straight forward in some instances (i.e., list the tasks to be done, arrange them in the proper sequence, and execute to this “plan”), in other cases, problems often arise: (i) the description of \"complete\" is often missing for intermediate activities; (ii) program partners, integration activities, and subcontractors all have unknown or possibly unknowable impacts on the program; and (iii) as products or services are delivered the maturity of the program changes (e.g., quality and functionality expectations, as well as other attributes)——this maturity provided by defining \"complete\"\nserves as an insurance policy against future problems encountered later in the program.\n\nOften, it's easier to define the IMP by stating what it is not. The IMP is NOT BASED on calendar dates, and therefore it is not\nschedule oriented; each event is completed when its supporting accomplishments are completed, and this completion is evidenced by the satisfaction of the criteria supporting each of the accomplishments. Furthermore, many of the IMP events are fixed by customer-defined milestones\n(e.g., Preliminary or Critical Design Review, Production Deliver, etc.) while intermediate events are defined by the Supplier (e.g., integration and test, software build releases, Test Readiness Review, etc.).\n\nThe critical IMP attribute is its focus on events, when compared to effort or task focused planning.\nThe event focus asks and answers the question \"what does done look like?\" rather than what work has been done. Certainly work must be done to complete a task, but a focus solely on the work hides the more important metric of \"are we meeting our commitments?\" While meeting commitments is critical, it's important to first define the criteria used for judging if the commitments are being met. This is where Significant Accomplishments (SA) and their Accomplishment Criteria (AC) become important. It is important to meet commitments, but recognizing when the commitment has been met is even more important.\n\nThe IMP provides Program Traceability by expanding and complying with the program's Statement of Objectives (SOO), Technical Performance Requirements (TPRs), the Contract Work Breakdown Structure (CWBS), and the Contract Statement of Work (CSOW)—all of which are based on the Customer's WBS to form the basis of the IMS and all cost reporting. The IMP implements a measurable and trackable program structure to accomplish integrated product development, integrate the functional program activities, and incorporates functional, lower-level and subcontractor IMPs. The IMP provides a framework for independent evaluation of Program Maturity by allowing insight into the overall effort with a level-of-detail that is consistent with levied risk and complexity metrics. It uses the methodology of decomposing events into a logical series of accomplishments having measurable criteria to demonstrate the completion and/or quality of accomplishments.\n\nA Government customer tasks a Supplier to prepare and implement an IMP that linked with the IMS and integrated with the EVMS. The IMP list the contract requirements documents (e.g., Systems Requirements Document and Technical Requirements Document (i.e., the system specification or similar document)) as well as the IMP events corresponding to development and/or production activities required by the contract. The IMP should include significant accomplishments encompassing all steps necessary to satisfy all contract objectives and requirements, manage all significant risks, and facilitate Government insight for each event. Significant accomplishments shall be networked to show their logical relationships and that they flow logically from one to another. The IMP, IMS, and EVMS products will usually include the prime contractor, subcontractor, and major vendor activities and products.\n\nWhen evaluating a proposed IMS, the user should focus on realistic task durations, predecessor/successor relationships, and identification of critical path tasks with viable risk mitigation and contingency plans. An IMS summarized at too high a level may result in obscuring critical execution elements, and contributing to failure of the EVMS to report progress. A high-level IMS may fail to show related risk management approaches being used, which can result in long duration tasks and artificial linkages masking the true critical path. In general, the IMP is a top-down planning tool and the IMS as the bottom-up execution tool. It should be noted, however, the IMS is a scheduling tool for management control of program progression, not for cost collection purposes.\n\nAn IMS would seek general consistency and a standardized approach to project planning, scheduling and analysis. It may use guides such as the PASEG Generally Accepted Schedule Principles (GASP) as guidance to improve execution and enable EVMS.\n\nThe IMP/IMS are related to the product-based Work Breakdown Structure (WBS) as defined in MIL-STD-881, by giving a second type of view on the effort, for different audiences or to provide a combination which gives better overall understanding. Linkage between the IMP/IMS and WBS is done by referencing the WBS numbering whenever the PE (Program Event), SA (Significant Accomplishment), or AC (Accomplishment Criteria) involves a deliverable product.\n\nThe IMP is often called out as a contract data deliverable on United States Department of Defense materiel acquisitions, as well as other U.S. Government procurements. Formats for these deliverables are covered in Data Item Descriptions (DIDs) that define the data content, format, and data usages. Recently, the DoD cancelled the DID (DI-MISC-81183A) that jointly addressed both the IMP and the IMS. The replacement documents include DI-MGMT-81650 (Integrated Master Schedule), DI-MGMT-81334A (Contract Work Breakdown Structure) and DI-MGMT-81466 (Contract Performance Report). In addition DFARS 252.242–7001 and 252.242–7002 provide guidance for integrating IMP/IMS with Earned Value Management.\n"}
{"id": "2694936", "url": "https://en.wikipedia.org/wiki?curid=2694936", "title": "International Association for Plant Taxonomy", "text": "International Association for Plant Taxonomy\n\nThe International Association for Plant Taxonomy (IAPT) promotes an understanding of plant biodiversity, facilitates international communication of research between botanists, and oversees matters of uniformity and stability in plant names. The IAPT was founded on July 18, 1950 at the Seventh International Botanical Congress in Stockholm, Sweden. Currently, the IAPT headquarters is located in Bratislava, Slovakia. Its current president, since 2017, is Patrick S. Herendeen of the Chicago Botanic Garden; vice-president is Gonzalo Nieto Feliner of the Real Jardín Botánico, Madrid; and secretary-general is Karol Marhold of the Plant Science and Biodiversity Centre, Slovak Academy of Sciences, Bratislava.\n\nBoth the taxonomic journal Taxon and the series Regnum Vegetabile are published by the IAPT. The latter series includes the \"International Code of Nomenclature for algae, fungi, and plants\", the \"Index Nominum Genericorum\", and \"Index Herbariorum\".\n\nThe IAPT's primary purpose is the promotion and understanding of biodiversity—the discovery, naming, classification, and systematics of plants—for both living and fossil plants. Additionally, it promotes the study and conservation of plant biodiversity, and works to raise awareness of the general public to this issue. The organization also facilitates international cooperation among botanists working in the fields of plant systematics, taxonomy, and nomenclature. This is accomplished in part through sponsorship of meetings and publication of resources, such as reference publications and journals.\n\nThe IAPT also seeks to achieve uniformity and stability in plant names. It accomplishes this through the \"International Code of Nomenclature for algae, fungi, and plants\", previously known as the \"International Code of Botanical Nomenclature\", and through the oversight of the International Bureau for Plant Taxonomy and Nomenclature.\n\n\"Taxon\" is the bi-monthly journal of the IAPT. The journal, which was initiated in 1951, publishes original papers and reviews dealing with systematic botany in the broadest sense. Preference is given to integrative papers combining the results of modern analysis with their consequences for classification. \"Taxon\" also contains matters related to botanical nomenclature, and is the medium for the publication of both proposals to conserve or reject names and proposals to amend the \"International Code of Nomenclature for algae, fungi, and plants\" (ICN). Publication of such matters in \"Taxon\" satisfies the required submission to the General Committee. The journal also contains sections devoted to the International Organisation of Plant Biosystematics, reviews and notices of books and other publications, and news in the world of plant systematics. Although the journal is \"devoted to systematic and evolutionary biology with emphasis on botany\", it has been in the past criticized for focusing overly on nomenclature and less on the principles and advancements made in the field of plant systematics.\n\n\"Regnum Vegetabile\" is a published series of books on topics of interest to plant taxonomists. Many of the volumes are literature surveys or monographs in the area of plant systematics. There are several volumes of general use:\n\nThe series includes many additional volumes of interest to specialists in specific subdisciplines of botany, in addition to the ones listed above.\n\nIn addition to electronic versions of its print publications, the IAPT maintains the following:\n\nThe IAPT established two Engler Medals in honour of Adolf Engler in 1986: the Engler Medal in Gold awarded every six years for outstanding lifetime contributions to plant taxonomy and presented since 1987 at each International Botanical Congress (IBC), and the Engler Medal in Silver (medal sensu lato) awarded from 1987 to 2001 for a monograph or other work in systematic botany and presented from 1990 to 2002 at various meetings, congresses, symposia, etc. In 2002 the latter medal was divided into three awards for outstanding publications in these areas: the Engler Medal in Silver (medal sensu stricto) awarded for monographic or floristic plant systematics; the Stafleu Medal awarded for historical, bibliographic, and/or nomenclatural aspects of plant systematics; and the Stebbins Medal awarded for phylogenetic plant systematics and/or plant evolution. The medals honor Adolf Engler (24 Mar. 1844-10 Oct. 1930), Frans Antonie Stafleu (8 Sep. 1921-16 Dec. 1997), and George Ledyard Stebbins, Jr. (6 Jan. 1906-19 Jan. 2000).\n\n\n"}
{"id": "10187733", "url": "https://en.wikipedia.org/wiki?curid=10187733", "title": "International Carnivorous Plant Society", "text": "International Carnivorous Plant Society\n\nThe International Carnivorous Plant Society (ICPS) is a non-profit organization founded in 1972. It is the International Cultivar Registration Authority for carnivorous plants. As of June 2011, the society had around 1400 members.\n\nThe ICPS is probably best known for its quarterly publication, the \"Carnivorous Plant Newsletter\".\nThe ICPS has set up the \"Nepenthes clipeata\" Survival Project (NcSP) to facilitate \"ex situ\" conservation of this species. With only an estimated 15 plants remaining in the wild as of 1995, \"Nepenthes clipeata\" is the most endangered of all known tropical pitcher plants. It is estimated that there are only three or four genetically-distinct lines of \"white market\" (legally collected) plants in cultivation.\n\nThe ICPS partially funded the establishment of The Rare \"Nepenthes\" Collection, which aims to conserve four of the rarest \"Nepenthes\" species: \"N. aristolochioides\", \"N. clipeata\", \"N. khasiana\", and \"N. rigidifolia\".\n\n\n"}
{"id": "34048151", "url": "https://en.wikipedia.org/wiki?curid=34048151", "title": "International Society for Biological and Environmental Repositories", "text": "International Society for Biological and Environmental Repositories\n\nThe International Society for Biological and Environmental Repositories (ISBER) is the largest international forum that addresses the technical, legal, ethical, and managerial issues relevant to repositories of biological and environmental specimens. ISBER is a professional society of individuals and organizations who share an interest in promoting consistent, high quality standards, ethical principles and innovation in biospecimen banking by uniting the global biobanking community. ISBER invites all sub-components of government, academia, the private sector, and manufacturers to become active participants of the society.\n\nISBER is a global organization which creates opportunities for sharing ideas and innovations in biobanking and harmonizes approaches to evolving challenges for biological and environmental repositories.\n\nISBER fosters collaboration, creates education and training opportunities, provides an international showcase for state-of-the-art policies, processes, and research findings, and innovative technologies, products, and services. Together, these activities promote best practices that cut across the broad range of repositories that ISBER serves.\n\nISBER will be the leading global forum for promoting harmonized high quality standards, ethical principles, and innovation in the science and management of biorepositories.\n\nMembership includes organizations and individuals from over 30 countries involved in long-term preservation and storage of animal, environmental, human, microorganism culture, museum, and plant/seed collections.\n\nISBER has members from all around the world. Here are some of them:\n\nAbbott Informatics\nUnited States\nGeographic Region: Americas\n\nAccelerated Cure Project for MS\nUnited States\nGeographic Region: Americas\n\nAdministrator, Health Sciences Core Research Facilities\nUnited States\nGeographic Region: Americas\n\nAlbert Einstein College of Medicine\nUnited States\nGeographic Region: Americas\n\nAlberta Cancer Research Biobank\nCanada\nGeographic Region: Americas\n\nAnalytical Biological Services, Inc (ABS)\nUnited States\nGeographic Region: Americas\n\nArtel\nUnited States\nGeographic Region: Americas\n\nArtificial Intelligence in Medicine\nCanada\nGeographic Region: Americas\n\nAsterand Bioscience\nUnited States\nGeographic Region: Americas\n\nAurora Research Institute\nUnited States\nGeographic Region: Americas\n\nAutoGen, Inc.\nUnited States\nGeographic Region: Americas\n\nBC Cancer Agency Tumour Tissue Repository\nCanada\nGeographic Region: Americas\n\nBC Children's Hospital \nCanada\nGeographic Region: Americas\n\nBeaumont Health System\nUnited States\nGeographic Region: Americas\n\nBiobank of the Repository Health Network of FRQS\nCanada\nGeographic Region: Americas\n\nBioCision, LLC\nUnited States\nGeographic Region: Americas\n\nBioFortis, Inc. \nUnited States\nGeographic Region: Americas\n\nBioLife Solutions, Inc.\nUnited States\nGeographic Region: Americas\n\nBiomatrica\nUnited States\nGeographic Region: Americas\n\nBioRepository Resources, LLC\nUnited States\nGeographic Region: Americas\n\nBioSero\nUnited States\nGeographic Region: Americas\n\nBioStorage Technologies, Inc\nUnited States\nGeographic Region: Americas\n\nBioTillion\nUnited States\nGeographic Region: Americas\n\nBlood Systems Research Inst\nUnited States\nGeographic Region: Americas\n\nBoston Children's Hospital\nUnited States\nGeographic Region: Americas\n\nBrigham & Womens Hospital\nUnited States\nGeographic Region: Americas\n\nBrooks Automation\nUnited States\nGeographic Region: Americas\n\nCanadian Tissue Repository Network \nCanada\nGeographic Region: Americas\n\nCGI\nUnited States\nGeographic Region: Americas\n\nCHTN Eastern Division\nUnited States\nGeographic Region: Americas\n\nCloudLIMS\nUnited States\nGeographic Region: Americas\n\nComprehensive Cancer Center-Univ. of Puerto Rico\nGeographic Region: Americas\n\nConversant Bio\nUnited States\nGeographic Region: Americas\n\nCore Cryolab Inc\nCanada\nGeographic Region: Americas\n\nCoriell Inst for Med Research\nUnited States\nGeographic Region: Americas\n\nCryogenic Control \nUnited States\nGeographic Region: Americas\n\nCryoport, Inc\nUnited States\nGeographic Region: Americas\n\nCryoXtract Instruments\nUnited States\nGeographic Region: Americas\n\nCureline, Inc\nUnited States\nGeographic Region: Americas\n\nDataworks Development, Inc. (Freezerworks) \nUnited States\nGeographic Region: Americas\n\nDepartment of Veterans Affairs\nUnited States\nGeographic Region: Americas\n\nDiversified Laboratory Repair, Inc.\nUnited States\nGeographic Region: Americas\n\nDuke University\nUnited States\nGeographic Region: Americas\n\nEastern Virginia Medical School\nUnited States\nGeographic Region: Americas\n\nEli Lilly and Company\nUnited States\nGeographic Region: Americas\n\nElpro Services Inc.\nUnited States\nGeographic Region: Americas\n\nEMMC Cancer Care Biorepository\nUnited States\nGeographic Region: Americas\n\nEPL Archives, Inc \nUnited States\nGeographic Region: Americas\n\nEversight\nUnited States\nGeographic Region: Americas\n\nFarrar Scientific Corporation\nUnited States\nGeographic Region: Americas\n\nThe complete list is available over official website.\n\nISBER holds one international meeting each year. Lectures, workshops, poster presentations, and working group discussions focus on technical issues and challenges such as quality assurance and control, regulations, human subject privacy and confidentiality issues, and provide information about sources of equipment and expertise.\n\n\nThe availability of high quality biological and environmental specimens for research purposes requires the development of standardized methods for collection, long-term storage, retrieval and distribution of specimens that will enable their future use. Sharing successful strategies for accomplishing this goal is one of the driving forces for the International Society for Biological and Environmental Repositories (ISBER).\n\nISBER's Best Practices for Repositories (Best Practices) reflects the collective experience of its members and has received broad input from other repository professionals. Throughout this document effective practices are presented for the management of specimen collections and repositories. The term \"Best Practice\" is used in cases where a level of operation is indicated that is above the basic recommended practice or, more specifically, designates the most effective practice. It is understood that repositories in certain locations or with particular financial constraints may not be able to adhere to each of the items designated as \"Best Practices\". Repositories fitting into either of these categories will need to decide how they might best adhere to these recommendations within their particular circumstances. While adherence to ISBER Best Practices is strictly on a voluntary basis, it is important to note that some aspects of specimen management are governed by national/federal, regional and local regulations. The reader should refer directly to regulations for their national/federal, regional and local requirements, as appropriate.\n\nThe ISBER Best Practices are periodically reviewed and revised to reflect advances in research and technology. The third edition of the Best Practices builds on the foundation established in the first and second editions which were published in 2005 and 2008, respectively.\n\n\"ISBER Best Practices For Repositories: Collection, Storage, Retrieval and Distribution of Biological Materials for Research\" provides repository professionals with standardized guidelines for the management of biobank specimen collections and repositories. The most current version of the ISBER Best Practices was published in \"Biopreservation and Biobanking\" (BIO), April 2012 issue.\n\nISBER has created this Self-Assessment Tool(SAT) to assist repository operators in determining how well their repository follows the ISBER Best Practices for Repositories.The assessment is confidential and aimed at helping specimen collection centers strengthen their practices through the identification of areas in need of improvement.\n\nISBER provides a yearly anonymized SAT result summary, found on the ISBER website here .\n\nThe tool contains 158 questions which may be answered in a single or multiple sessions. Each page of the survey corresponds to a section of the ISBER Best Practices. Results from pilot tests indicated that the SAT takes a little over an hour to complete if all required information is available at the time of completing the survey. The tool is free to ISBER members, and non-members may participate for a fee.\n\nAfter completion of the SAT, a personalized e-mail is sent to the participant which includes a \"risk-balanced assessment score\" and notification of top deviation areas to help the participant evaluate how their current practices conform to the ISBER Best Practices. The score is based on possible risk to the specimens, frequency of implementation of each practice, and the ease with which deviations can be detected.\n\nDeveloped in collaboration with the Integrated Biobank of Luxembourg (IBBL), the Biorepository Proficiency Testing Program is designed to allow biorepositories to assess the accuracy of their quality control assays and characterization of biospecimens. Participants can compare their results with those obtained in other laboratories and can identify testing issues that may be related to individual staff performance or calibration of instrumentation used in biospecimen quality control. The program provides guidance to biorepositories so they can take appropriate remedial action to be in compliance with ISO/IEC 17043:2010, providing a necessary External Quality Assessment tool for biorepositories who wish to seek accreditation (ISO 17025, CLIA or equivalent).\n"}
{"id": "18226044", "url": "https://en.wikipedia.org/wiki?curid=18226044", "title": "International Society for Biosemiotic Studies", "text": "International Society for Biosemiotic Studies\n\nThe International Society for Biosemiotic Studies (ISBS) is an academic society for the researchers in semiotic biology. The Society was established in 2005. Its official journal is Biosemiotics, published by Springer and launched in 2008. \n\nThe purpose of the ISBS is to constitute an organizational framework for the collaboration among scholars dedicated to biosemiotic studies, including the interdisciplinary research of sign processes in living systems, organic codes, and biocommunication. The ISBS attempts to develop the qualitative research methods in biology. Among the central focuses is also theoretical semiotics as a basis for theoretical biology.\n\nThe ISBS assures the organization of regular meetings on research into the semiotics of nature, as well as promotes publication of scholarly work on the semiotics of life processes. The ISBS organizes the annual international conferences (\"Gatherings in Biosemiotics\") that were started by Copenhagen and Tartu biosemioticians and have taken place regularly already since 2001.\n\nThe first President of the ISBS was Jesper Hoffmeyer (Copenhagen University), the second President (since 2015) is Kalevi Kull. \n"}
{"id": "505307", "url": "https://en.wikipedia.org/wiki?curid=505307", "title": "Island of California", "text": "Island of California\n\nThe Island of California refers to a long-held Spanish misconception, dating from the 16th century, that the Baja California Peninsula was not part of mainland North America but rather a large island (spelled on early maps as Cali Fornia) separated from the continent by a strait now known as the Gulf of California.\n\nOne of the most famous cartographic errors in history, it was propagated on many maps during the 17th and 18th centuries, despite contradictory evidence from various explorers. The legend was initially infused with the idea that California was a terrestrial paradise, like the Garden of Eden or Atlantis.\n\nThe first known mention of the legend of the \"Island of California\" was in the 1510 romance novel \"Las sergas de Esplandián\" by Garci Rodríguez de Montalvo—the sequel to Montalvo's more famous tales of Amadis de Gaula, father of Esplandian. He described the island in this passage:\n\nKnow, that on the right hand of the Indies there is an island called California very close to the side of the Terrestrial Paradise; and it is peopled by black women, without any man among them, for they live in the manner of Amazons.\n\nIt is probable that this description prompted early explorers to misidentify the Baja California Peninsula as the island in these legends.\n\nIn 1533, Fortún Ximénez, a mutineer on an exploring expedition sent by Hernán Cortés, discovered the southern portion of Baja California, around present-day La Paz. He was killed by natives but his men returned to New Spain and gave report of their find. In 1535 Cortés arrived in the bay there and named the area Santa Cruz; he attempted to start a colony but abandoned his efforts after several years due to logistical problems. Cortés' limited information on southern Baja California apparently led to the naming of the region after the legendary California and to an initial but short-lived assumption that it was a large island.\n\nIn 1539, Cortés sent the navigator Francisco de Ulloa northward along the Gulf and Pacific coasts of Baja California. Ulloa reached the mouth of the Colorado River at the head of the Gulf, which seemed to prove that the region was a peninsula rather than an island. An expedition under Hernando de Alarcón ascended the lower Colorado River and confirmed Ulloa's finding. Maps published subsequently in Europe during the 16th century, including those by Gerardus Mercator and Abraham Ortelius, correctly showed Baja California as a peninsula.\n\nDespite this evidence, however, the depiction of California as an island revived in the early 17th century. One contributing factor may have been the second voyage of Juan de Fuca in 1592. De Fuca claimed to have explored the western coast of North America and to have found a large opening that possibly connected to the Atlantic Ocean — the legendary Northwest Passage. De Fuca's claim remains controversial because there is only one surviving written account of it found, his account as related to an Englishman, Michael Locke. Nonetheless, this account claims de Fuca found a large strait, with a large island at its mouth, at around 47° north latitude. The Strait of Juan de Fuca is in fact at around 48° N, as is the southern tip of the large island now called Vancouver Island, while the northern reach of the Gulf of California terminates much farther south, at about 31° N. It is possible that explorers and mapmakers in the 17th century could have confused the two (if in fact they were aware of de Fuca's voyage), and in any case further exploration was inevitable. Indeed, the famed British explorer James Cook narrowly missed the Strait of Juan de Fuca in March 1778, almost 200 years later. Cook even named Cape Flattery (at the northwest tip of modern Washington state) which is at the mouth of the strait, and instead stopped in Nootka Sound just off the west coast of Vancouver Island at about 49° N. His account states \"we saw nothing like [the Strait of Juan de Fuca]; nor is there the least probability that ever any such thing existed.\" However, Cook describes some bad weather in his account around this time, and did continue on to map most of the outer Pacific coastline of North America from modern-day northern California to the Bering Strait in Alaska on the same voyage.\n\nA key role in changing ideas about California seems to have been played by an overland expedition led by the founding governor of Santa Fe de Nuevo México, Juan de Oñate. The expedition descended the Colorado River in 1604 and 1605, and its participants believed that they saw the Gulf of California continuing off to the northwest (presumably behind in the Sierra Cucapá into the Laguna Macuata Basin).\n\nReports from Oñate's expedition reached Antonio de la Ascención, a Carmelite friar who had participated in Sebastián Vizcaíno's explorations of the west coast of California in 1602 and 1603. Ascención was a tireless propagandist in favor of Spanish settlement in California, and his later writings referred to the region as an island. As older maps confirm, Spanish authorities and local residents were well aware where the actual northern terminus of the Gulf of California lay, but by extending the coastline north past Cape Mendocino and eventually even into Puget Sound, Sir Francis Drake's claim of Nova Albion for England (1579) could be invalidated by the priority of Cortes' claim (1533).\n\nThe first known reappearance of the Island of California on a map dates to 1622 in a map by Michiel Colijn of Amsterdam. The image became the standard for many later maps throughout the 17th century and intermittently into the 18th century. Previous maps show the Gulf terminating in its correct location. On the stretch of the Gulf between its actual terminus and Juan de Fuca's strait was written \"Mare Vermexo\" (\"Red Sea\") on later maps drawn from Spanish sources.\n\nThe Jesuit missionary and cartographer Eusebio Francisco Kino revived the fact that Baja California was a peninsula. While studying in Europe, Kino had accepted the insularity of California, but when he reached Mexico he began to have doubts. He made a series of overland expeditions from northern Sonora to areas within or near the Colorado River's delta in 1698–1706, in part to provide a practical route between the Jesuits' missions in Sonoran and Baja California but also to resolve the geographical question. Kino satisfied himself that a land connection must exist, and the 18th century Jesuits generally followed his example. The first report of Kino's discovery and his map from 1701 showing California as a peninsula were sent to Europe by Marcus Antonius Kappus, a Jesuit missionary from Kamna Gorica (Duchy of Carniola, now Slovenia). In a June 1701 letter, he wrote about that to his friend Philippus Alberth in Vienna and thus acted as an important intermediary in the dissemination of this knowledge. However, Juan Mateo Manje, a military companion on several of Kino's treks, expressed scepticism; European cartographers remained divided on the question.\n\nJesuit missionary-explorers in Baja California who attempted to lay the issue finally to rest included Juan de Ugarte (1721), Ferdinand Konščak (1746), and Wenceslaus Linck (1766). The matter was settled beyond all dispute when the expeditions of Juan Bautista de Anza traveled between Sonora and the west coast of California in the period 1774–1776.\n\n\n\n"}
{"id": "34678258", "url": "https://en.wikipedia.org/wiki?curid=34678258", "title": "James Gow Black", "text": "James Gow Black\n\nJames Gow Black (10 May 1835 – 25 December 1914) was a New Zealand chemist, mineralogist, lecturer and university professor . He was born in Tomgarrow, Perthshire, Scotland on 10 May 1835.\n"}
{"id": "12742523", "url": "https://en.wikipedia.org/wiki?curid=12742523", "title": "Jane Francis", "text": "Jane Francis\n\nDame Jane Elizabeth Francis is the Director of the British Antarctic Survey. She previously worked as Professor of Palaeoclimatology at the University of Leeds where she also was Dean of the Faculty of Environment. In 2002 she was the fourth woman to receive the Polar Medal for outstanding contribution to British polar research. She is currently the Chancellor of the University of Leeds.\n\nFrancis was educated at Simon Langton Girls' Grammar School in Canterbury, and received both her undergraduate degree in Geology and her PhD from the University of Southampton.\n\nFrancis was a NERC research student in geology/biology at Southampton University from 1979 until 1982. She continued on as a NERC Postdoctoral Research Fellow at Bedford College, London, until 1984. She was appointed to a position as Palaeobotanist at the British Antarctic Survey (BAS), from 1984–1986.\n\nFor five years Francis was a Postdoctoral Research Associate with Professor Larry Frakes at the University of Adelaide. In 1991 she accepted a position as a lecturer in the Department of Earth Sciences at the University of Leeds UK; she was promoted to Senior Lecturer in 1996. In 2002, she was awarded the Polar Medal, becoming only the fourth woman in history to receive the award. \n\nShe was promoted to Professor of Palaeoclimatology in the School of Earth and Environment and was the Director for the Centre for Polar Science at the University of Leeds, before becoming Dean of the Faculty of Environment in 2008. She is an Honorary Professor at the University of Leeds. On 1 October 2013 Professor Francis took up her post as Director of the British Antarctic Survey, becoming the first woman Director of the institution.\n\nFrancis's principal interests are in palaeoclimatology and palaeobotany. She specialises in the study of fossil plants, and their use as tools for climate interpretation and information about past biodiversity: for example, understanding past climate change during greenhouse and icehouse periods. Her research has emphasised the \"Antarctic paradox,\" that although the Antarctic is largely inhospitable now, its abundant plant fossils indicate a drastically warmer past climate. She has undertaken more than 16 expeditions to the Arctic and Antarctic.\n\nFrancis was described by the Geological Society of London during the awarding of her Coke Medal as playing a \"pivotal role in shaping and directing the Earth science carried out in polar regions, through her extensive service on a staggeringly wide range of national and international policy committees.\" She is also the first woman to chair the Operations Working Group of Antarctic Treaty Consultative Meetings, the international forum of nations concerned with legal and operational issues in Antarctica.\n\nFrancis holds a number of memberships of national and international scientific bodies. She is a member of the UK Natural Environment Research Council (NERC) Executive Board; member of the Scientific Advisory Group of the Swedish Polar Research Secretariat; Executive committee member of the European Polar Board; and UK Delegate to the international Scientific Committee on Antarctic Research.\n\nFrancis's contributions have been recognised with numerous awards. Most notably, she was awarded the Polar Medal in 2002 for outstanding contribution to British polar research, presented by H.M. Elizabeth II, and was the fourth woman ever to receive the award. \n\nShe received an Honorary Doctorate of Science from the University of Leeds in 2014, as well as an Honorary Doctorate of Environmental Science from the University Of Plymouth, also in 2014. In that same year she was named \"Explorer Scientist\" among 100 leading UK scientists by The Science Council. She also has been awarded the Coke Medal from the Geological Society of London (2014); the President's Award of the Paleontological Society; the Antarctic Service Medal from the US National Science Foundation; and the Workplace Achievement Award from the BBC's 'eve' magazine, sponsored by Nivea.\n\nIn the 2017 New Year Honours, Francis was appointed Dame Commander of the Order of St Michael and St George (DCMG) for services to polar science and diplomacy.\n\nIn 2017, Francis became the seventh Chancellor of the University of Leeds, succeeding Melvyn Bragg. \n\n"}
{"id": "27979791", "url": "https://en.wikipedia.org/wiki?curid=27979791", "title": "Jonas Acus-Acukas", "text": "Jonas Acus-Acukas\n\nJonas Asevicius-Acus-Acukas (July 29, 1885 in Jieznas – July 11, 1976 in Kaunas) was a Lithuanian army officer and chemist. From 1909 to 1918, he served in the Imperial Russian Army at Kaunas Fortress. He fought in the First World War and the Russian Civil War. In 1921 he returned to Lithuania and was mobilized into the Lithuanian Armed Forces, where he attained the rank of colonel (1927) and served until 1940. Acus graduated from Vytautas Magnus University in 1930. He lectured on chemistry and commodity science at Vytautas Magnus University (1934–1940), Vilnius University (1940–1950), and Lithuanian University of Agriculture (1951–1957). He wrote textbooks on foundations of commodity science (1949) and a short course in physical chemistry (1957). Acus was awarded the Commander's Crosses of the Order of Vytautas the Great (1938) and the Order of the Lithuanian Grand Duke Gediminas (1928).\n"}
{"id": "10508033", "url": "https://en.wikipedia.org/wiki?curid=10508033", "title": "Khôra", "text": "Khôra\n\nKhôra (also chora; ) was the territory of the Ancient Greek \"polis\" outside the city proper. The term has been used in philosophy by Plato to designate a receptacle (as a “third kind” [\"triton genos\"]; \"Timaeus\" 48e4), a space, a material substratum, or an interval. In Plato's account, \"khôra\" is neither being nor nonbeing but an interval between in which the \"forms\" were originally held; it \"gives space\" and has maternal overtones (a womb, matrix). Jacques Derrida has written a short text with the title \"Khôra\", using his deconstructionist approach to investigate Plato's word usage. It is the origin for the recent interest in this rather obscure Greek term.\n\nKey authors addressing \"khôra\" include Martin Heidegger, who refers to a \"clearing\" in which being happens or takes place. Julia Kristeva deploys the term as part of her analysis of the difference between the semiotic and symbolic realms, in that Plato's concept of \"khora\" is said to anticipate the emancipatory employment of semiotic activity as a way of evading the allegedly phallocentric character of symbolic activity (signification through language), which, following Jacques Lacan, is regarded as an inherently limiting and oppressive form of \"praxis\".\n\nJulia Kristeva articulates the \"khôra\" in terms of a presignifying state: \"Although the \"khôra\" can be designated and regulated, it can never be definively posited: as a result, one can situate the \"khôra\" and, if necessary, lend it a topology, but one can never give it axiomatic form.\"\n\nJacques Derrida uses \"khôra\" to name a radical otherness that \"gives place\" for being. Nader El-Bizri builds on this by more narrowly taking \"khôra\" to name the radical happening of an ontological difference between being and beings. El-Bizri's reflections on \"khôra\" are taken as a basis for tackling the meditations on \"dwelling\" and on \"being and space\" in Heidegger's thought and the critical conceptions of space and place as they evolved in architectural theory and in history of philosophy and science, with a focus on geometry and optics. Derrida argues that the subjectile is like Plato’s \"khôra\", Greek for space, receptacle or site. Plato proposes that the \"khôra\" rests between the sensible and the intelligible, through which everything passes but in which nothing is retained. For example, an image needs to be held by something, just as a mirror will hold a reflection. For Derrida, \"khôra\" defies attempts at naming or either/or logic, which he \"deconstructs\". See also Derrida's collaborative project with architect Peter Eisenmann, in \"Chora L Works: Jacques Derrida and Peter Eisenman\". The project proposed the construction of a garden in the Parc de la Villette in Paris, which included a sieve, or harp-like structure that Derrida envisaged as a physical metaphor for the receptacle-like properties of the \"khôra\". The concept of the \"khôra\", distinguished by its elusive properties, would have become a physical reality had the project been realised.\n\nFollowing Derrida, John Caputo describes \"khôra\" as:\n\nneither present nor absent, active or passive, the good nor evil, living nor nonliving - but rather atheological and nonhuman - \"khôra\" is not even a receptacle. \"Khôra\" has no meaning or essence, no identity to fall back upon. She/it receives all without becoming anything, which is why she/it can become the subject of neither a philosopheme nor mytheme. In short, the \"khôra\" is tout autre [fully other], very.\n\n\n"}
{"id": "28870190", "url": "https://en.wikipedia.org/wiki?curid=28870190", "title": "List of Chinese scientists", "text": "List of Chinese scientists\n\nThis is a list of notable Chinese scientists.\n\n\n"}
{"id": "37572955", "url": "https://en.wikipedia.org/wiki?curid=37572955", "title": "List of MorphOS bundled applications", "text": "List of MorphOS bundled applications\n\nA number of bundled applications are delivered with the operating system.\n"}
{"id": "11206972", "url": "https://en.wikipedia.org/wiki?curid=11206972", "title": "List of stratovolcanoes", "text": "List of stratovolcanoes\n\nA list of stratovolcanoes active in geologically recent (Holocene) times follows below. The Smithsonian Institution's Global Volcanism Program database lists more than 700 such stratovolcanoes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "39478776", "url": "https://en.wikipedia.org/wiki?curid=39478776", "title": "List of things named after Jean-Pierre Serre", "text": "List of things named after Jean-Pierre Serre\n\nThese are the things named after Jean-Pierre Serre, a French mathematician.\n\n"}
{"id": "43402273", "url": "https://en.wikipedia.org/wiki?curid=43402273", "title": "List of things named after Jean d'Alembert", "text": "List of things named after Jean d'Alembert\n\nThis article is a list of things named after Jean d'Alembert:\n\n\n\n"}
{"id": "11015838", "url": "https://en.wikipedia.org/wiki?curid=11015838", "title": "Malagasy giant rat", "text": "Malagasy giant rat\n\nThe Malagasy giant rat (\"Hypogeomys antimena\"), also known as the votsotsa or votsovotsa, is a nesomyid rodent found only in the Menabe region of Madagascar. It is an endangered species due to habitat loss, slow reproduction, and limited range (200 square kilometres north of Morondava, between the rivers Tomitsy and Tsiribihina) Pairs are monogamous and females bear only one or two young per year. It is the only extant species in the genus \"Hypogeomys\"; another species, \"Hypogeomys australis\", is known from subfossil remains a few thousand years old.\n\nMalagasy giant rats have an appearance somewhat similar to rabbits, though maintaining many rat-like features especially in the face. Males and females both grow to roughly rabbit-size, around and , though with an additional of dark tail. They have a coarse coat which varies from gray to brown to reddish, darkening around the head and fading to white on the belly. They also have prominent, pointed ears and long, muscular back legs, used for jumping to avoid predators. They can leap almost in the air, for which reason they are sometimes called giant jumping rats.\n\nThe male Malagasy giant rat reaches sexual maturity within one year, but will not mate until they reach 1.5 to two years. The female Malagasy giant rat reaches sexual maturity in two years. These rats are one of the few rodent species to practice sexual monogamy. Once mated, a pair will stay together until one of them dies. On the death of a mate, females tend to remain in the burrow until a new male is found. While males usually wait for a new mate as well, they do occasionally move to live with a widowed female. Females give birth to a single offspring after a gestation of 102–138 days (number observed in captivity) once or twice during the mating season, which coincides with the Madagascar rainy season from December to April. The young are raised by both parents, remaining in the family burrow for the first 4–6 weeks, then increasingly exploring and foraging outside. Young males stay with the family unit for one year before achieving sexual maturity and leaving to find their own burrow. Females do not mature for 2 years and remain with their parents for the extra year. Males are extremely protective of their young. They are known to increase their own predation risk to follow or defend their offspring.\n\nCompletely nocturnal, the giant rats live in burrows up to across with as many as 6 entrances. Entrances, even those in regular use, are kept blocked by dirt and leaves to discourage predation by the Malagasy ground boa. The other main traditional predatory threat is the puma-like fossa but increasingly feral dogs and cats introduced to the island are hunting them as well. When foraging, the rats move on all fours, searching the forest floor for fallen fruit, nuts, seeds, and leaves. They have also been known to strip bark from trees and dig for roots and invertebrates. Pairs are highly territorial and both members will defend their territory from other rats. They mark their territory with urine, feces, and scent gland secretions.\n\nThe Malagasy giant rat is listed as endangered. Limited range, habitat destruction, increased predation by non-native feral dogs and cats, and disease have all led to the decline. Many feral cats also carry a parasite called toxoplasmosis. The parasite causes rodents to lose their fear of cats, to the point of almost being attracted to cats, which allows them to be caught and killed more easily. Hantavirus is another rodent disease that is ravaging the population that causes kidney failure.\n\nThe Madagascan Government has enacted laws to protect the rat. Much of their territory is now the Kirindy Forest Reserve where sustainable forestry is practiced. They have also introduced policies that help the inhabitants of the island coexist with the animals that live there. Gerald Durrell was the first scientist to breed the rats in captivity. In 1990, he brought five specimens to Jersey. Since then, 16 breeding programs have been set up and 12 have been successful.\n"}
{"id": "35368123", "url": "https://en.wikipedia.org/wiki?curid=35368123", "title": "Masao Kitagawa", "text": "Masao Kitagawa\n"}
{"id": "33739475", "url": "https://en.wikipedia.org/wiki?curid=33739475", "title": "Mobilities", "text": "Mobilities\n\nMobilities is a contemporary paradigm in the social sciences that explores the movement of people (Human migration, travel, transport), ideas (see e.g. meme) and things (transport), as well as the broader social implications of those movements.\n\nA mobility \"turn\" (or transformation) in the social sciences began in the 1990s in response to the increasing realization of the historic and contemporary importance of movement on individuals and society. This turn has been driven by generally increased levels of mobility and new forms of mobility where bodies combine with information and different patterns of mobility. The mobilities paradigm incorporates new ways of theorizing about how these mobilities lie \"at the center of constellations of power, the creation of identities and the microgeographies of everyday life.\" (Cresswell, 2011, 551)\n\nThe mobility turn arose as a response to the way in which the social sciences had traditionally been static, seeing movement as a black box and ignoring or trivializing \"the importance of the systematic movements of people for work and family life, for leisure and pleasure, and for politics and protest\" (Sheller and Urry, 2006, 208). Mobilities emerged as a critique of contradictory orientations toward both sedentarism and deterritorialisation in social science. People had often been seen as static entities tied to specific places, or as nomadic and placeless in a frenetic and globalized existence. Mobilities looks at movements and the forces that drive, constrain and are produced by those movements.\n\nSeveral typologies have been formulated to clarify the wide variety of mobilities. Most notably, John Urry divides mobilities into five types: mobility of objects, corporeal mobility, imaginative mobility, virtual mobility and communicative mobility. Later, Leopoldina Fortunati and Sakari Taipale proposed an alternative typology taking the individual and the human body as a point of reference. They differentiate between ‘macro-mobilities’ (consistent physical displacements), ‘micro-mobilities’ (small-scale displacements), ‘media mobility’ (mobility added to the traditionally fixed forms of media) and ‘disembodied mobility’ (the transformation in the social order). The categories are typically considered interrelated, and therefore they are not exclusive.\n\nWhile mobilities is commonly associated with sociology, contributions to the mobilities literature have come from scholars in anthropology, cultural studies, economics, geography, migration studies, science and technology studies, and tourism and transport studies. (Sheller and Urry, 2006, 207)\n\nMobilities as a specific body of research remains associated with a small group of largely British researchers, notably John Urry, Mimi Sheller, Peter Adey, Tim Edensor, David Bissell, and Tim Cresswell. However, Cresswell (2011, 555) notes that \"many people involved in research on mobility topics do not see themselves as part of a new paradigm or turn\" (e.g. Noel B. Salazar). The community of mobilities researchers, as well as the areas they research, have expanded across the globe.\n\nThe eponymous journal \"Mobilities\" provides a list of typical subjects which have been explored in the mobilities paradigm (Taylor and Francis, 2011):\n\nSheller and Urry (2006, 215) place mobilities in the sociological tradition by defining the primordial theorist of mobilities as Georg Simmel (1858–1918). Simmel's essays, \"Bridge and Door\" (Simmel, 1909 / 1994) and \"The Metropolis and Mental Life\" (Simmel, 1903 / 2001) identify a uniquely human will to connection, as well as the urban demands of tempo and precision that are satisfied with mobility.\n\nThe more immediate precursors of contemporary mobilities research emerged in the 1990s (Cresswell 2011, 551). Historian James Clifford (1997) advocated for a shift from deep analysis of particular places to the routes connecting them. Marc Augé (1995) considered the philosophical potential of an anthropology of \"non-places\" like airports and motorways that are characterized by constant transition and temporality. Sociologist Manuel Castells outlined a \"network society\" and suggested that the \"space of places\" is being surpassed by a \"space of flows.\" Feminist scholar Caren Kaplan (1996) explored questions about the gendering of metaphors of travel in social and cultural theory.\n\nThe contemporary paradigm under the moniker \"mobilities\" appears to originate with the work of sociologist John Urry. In his book, \"Sociology Beyond Societies: Mobilities for the Twenty-First Century\", Urry (2000, 1) presents a \"manifesto for a sociology that examines the diverse mobilities of peoples, objects, images, information and wastes; and of the complex interdependencies between, and social consequences of, these diverse mobilities.\"\n\nThis is consistent with the aims and scope of the eponymous journal \"Mobilities\", which \"examines both the large-scale movements of people, objects, capital, and information across the world, as well as more local processes of daily transportation, movement through public and private spaces, and the travel of material things in everyday life\" (Taylor and Francis, 2011).\n\nIn 2006, Mimi Sheller and John Urry published an oft-cited paper that examined the mobilities paradigm as it was just emerging, exploring its motivations, theoretical underpinnings, and methodologies. Sheller and Urry specifically focused on automobility as a powerful socio-technical system that \"impacts not only on local public spaces and opportunities for coming together, but also on the formation of gendered subjectivities, familial and social networks, spatially segregated urban neighborhoods, national images and aspirations to modernity, and global relations ranging from transnational migration to terrorism and oil wars\" (Sheller and Urry, 2006, 209).\n\nMobilities can be viewed as an extension of the \"spatial turn\" in the arts and sciences in the 1980s, in which scholars began \"to interpret space and the spatiality of human life with the same critical insight and interpretive power as have traditionally been given to time and history (the historicality of human life) on one hand, and to social relations and society (the sociality of human life) on the other\" (Sheller and Urry, 2006, 216; Engel and Nugent, 2010, 1; Soja, 1999 / 2005, 261).\n\nEngel and Nugent (2010) trace the conceptual roots of the spatial turn to Ernst Cassirer and Henri Lefebvre (1974), although Fredric Jameson appears to have coined the epochal usage of the term for the 1980s paradigm shift. Jameson (1988 / 2003, 154) notes that the concept of the spatial turn \"has often seemed to offer one of the more productive ways of distinguishing postmodernism from modernism proper, whose experience of temporality -- existential time, along with deep memory -- it is henceforth conventional to see as dominant of the high modern.\"\n\nFor Oswin & Yeoh (2010) mobility seems to be inextricably intertwined with late-modernity and the end of the nation-state. The sense of mobility makes us to think in migratory and tourist fluxes as well as the necessary infrastructure for that displacement takes place. R. Tzanelli (2014) explains that modernity has recycled the human emotions, particularly trauma, whatever their cause may be, to generate a logic of spectacle. Any mediated and consumed event not only destroys the previous states of conflicts and cleavages, but provides a one-sided ideological message to visitors. Tourism is for Tzanelli more than a mechanism to control, it is an instrument of ideology. The efficacy for state to reduce the discrepancy and discontent of citizenry consists in commoditizing the human suffering into affordable products.\n\nP. Vannini (2012) opted to see mobility as a projection of existent cultural values, expectances and structures that denotes styles of life. Mobility after all would not only generate effects on people's behaviour but also specific styles of life. Vannini explains convincingly that on Canada's coast, the values of islanders defy the hierarchal order in populated cities from many perspectives. Islanders prioritize the social cohesion and trust of their communities before the alienation of mega-cities. There is a clear physical isolation that marks the boundaries between urbanity and rurality. From another view, nonetheless, this ideological dichotomy between authenticity and alienation leads residents to commercialize their spaces to outsiders. Although the tourism industry is adopted in these communities as a form of activity, many locals have historically migrated from urban populated cities.\n\nThe intellectual roots of mobilities in sociology distinguish it from traditional transportation studies and transportation geography, which have firmer roots in mid 20th century positivist spatial science.\n\nCresswell (2011, 551) presents six characteristics distinguishing mobilities from prior approaches to the study of migration or transport:\n\n\nMobilities can be seen as a postmodern descendant of modernist transportation studies, with the influence of the spatial turn corresponding to a \"post-structuralist agnosticism about both naturalistic and universal explanations and about single-voiced historical narratives, and to the concomitant recognition that position and context are centrally and inescapably implicated in all constructions of knowledge\" (Cosgrove, 1999, 7; Warf and Arias, 2009).\n\nDespite these ontological and epistemological differences, Shaw and Hesse (2010, 207) have argued that mobilities and transport geography represent points on a continuum rather than incompatible extremes. Indeed, traditional transport geography has not been wholly quantitative any more than mobilities is wholly qualitative. Sociological explorations of mobility can incorporate empirical techniques, while model-based inquiries can be tempered with richer understandings of the meanings, representations and assumptions inherently embedded in models.\n\nShaw and Sidaway (2010, 505) argue that even as research in the mobilities paradigm has attempted to reengage transportation and the social sciences, mobilities shares a fate similar to traditional transportation geography in still remaining outside the mainstream of the broader academic geographic community.\n\nSheller and Urry (2006, 215-217) presented six bodies of theory underpinning the mobilities paradigm:\n\nThe prime theoretical foundation of mobilities is the work of early 20th-century sociologist Georg Simmel, who identified a uniquely human \"will to connection,\" and provided a theoretical connection between mobility and materiality. Simmel focused on the increased tempo of urban life, that \"drives not only its social, economic, and infrastructural formations, but also the psychic forms of the urban dweller.\" Along with this tempo comes a need for precision in timing and location in order to prevent chaos, which results in complex and novel systems of relationships.\n\nA second body of theory comes from the science and technology studies which look at mobile sociotechnical systems that incorporate hybrid geographies of human and nonhuman components. Automobile, rail or air transport systems involve complex transport networks that affect society and are affected by society. These networks can have dynamic and enduring parts. Non-transport information networks can also have unpredictable effects on encouraging or suppressing physical mobility (Pellegrino 2012).\n\nA third body of theory comes from the postmodern conception of spatiality, with the substance of places being constantly in motion and subject to constant reassembly and reconfiguration (Thrift 1996).\n\nA fourth body of theory is a \"recentring of the corporeal body as an affective vehicle through which we sense place and movement, and construct emotional geographies\". For example, the car is \"experienced through a combination of senses and sensed through multiple registers of motion and emotion″ (Sheller and Urry 2006, 216).\n\nA fifth body of theory incorporates how topologies of social networks relate to how complex patterns form and change. Contemporary information technologies and ways of life often create broad but weak social ties across time and space, with social life incorporating fewer chance meetings and more networked connections.\n\nFinally, the last body of theory is the analysis of complex transportation systems that are \"neither perfectly ordered nor anarchic.\" For example, the rigid spatial coupling, operational timings, and historical bindings of rail contrast with unpredictable environmental conditions and ever-shifting political winds. And, yet, \"change through the accumulation of small repetitions...could conceivably tip the car system into the postcar system.\"\n\nMimi Sheller and John Urry (2006, 217-219) presented seven methodological areas often covered in mobilities research:\n\n\n"}
{"id": "37579789", "url": "https://en.wikipedia.org/wiki?curid=37579789", "title": "Nuummite", "text": "Nuummite\n\nNuummite is a rare metamorphic rock that consists of the amphibole minerals gedrite and anthophyllite. It is named after the area of Nuuk in Greenland, where it was found.\n\nNuummite is usually black in colour and opaque. It consists of two amphiboles, gedrite and anthophyllite, which form exsolution lamellae that give the rock its typical iridescence. Other common minerals in the rock are pyrite, pyrrhotite and chalcopyrite, which form shimmering yellow bands in polished specimens.\n\nIn Greenland the rock was formed by two consecutive metamorphic overprints of an originally igneous rock. The intrusion took place in the Archean around 2800 million years ago and the metamorphic overprint was dated at 2700 and 2500 million years ago.\n\nThe rock was first discovered in 1810 in Greenland by the mineralogist K. L. Giesecke. It was defined scientifically by O. B. Bøggild between 1905 and 1924. True Nuummite is only found in Greenland. \nDue to its iridescent nature, this rare stone is sought after by gemstone dealers, collectors and those interested in the esoteric. It is often sold with tumble finishing.\n\n"}
{"id": "35683128", "url": "https://en.wikipedia.org/wiki?curid=35683128", "title": "Oglethorpe Plan", "text": "Oglethorpe Plan\n\nJames Edward Oglethorpe founded the Georgia Colony, and the town of Savannah, on February 12, 1733 (February 1, 1732 by the Julian calendar used in the British colonies until September 2, 1752). The new Georgia colony was authorized under a grant from George II to a group constituted by Oglethorpe as the Trustees for the Establishment of the Colony of Georgia in America, or simply the Georgia Trustees. The new colony was bounded by the Savannah River on the north and the Altamaha River to the south, while the western boundary reached almost to the Mississippi River and lands claimed by France as part of Louisiana. Not until 1763 did the French formally cede this territory east of the Mississippi to Great Britain, but Spain still claimed a considerable portion of it. Much of the territory ultimately became American in 1795, when the United States resolved its West Florida boundary dispute with Spain. \nOglethorpe's plan for settlement of the new colony had been in the works since 1730, three years before the founding of Savannah. The multifaceted plan sought to achieve several goals through interrelated policy and design elements, including the spacing of towns, the layout of towns and eventually their surrounding counties, equitable allocation of land, and limits to growth to preserve a sustainable agrarian economy.\n\nThe Oglethorpe Plan was an embodiment of all of the major themes of the Enlightenment, including science, humanism, and secular government. Georgia became the only American colony infused at its creation with Enlightenment ideals: the last of the Thirteen Colonies, it would become the first to embody the principles later embraced by the Founders. Remnants of the Oglethorpe Plan exist today in Savannah, showcasing a town plan that retains the vibrancy of ideas behind its conception.\n\nAt the heart of Oglethorpe’s comprehensive and multi-faceted plan there was a vision of social equity and civic virtue. The mechanisms supporting that vision, including yeoman governance, equitable land allocation, stable land tenure, prohibition of slavery, and secular administration, were among the ideas debated during the British Enlightenment. Many of those ideals have been carried forward, and are found today in Savannah’s Tricentennial Plan and other policy documents.\n\nThe Grand Model for the Province of Carolina was cited by the Georgia Trustees as a source of their plan for Georgia, although with the major difference that it would have neither aristocracy nor slavery. Oglethorpe wrote that the plan was conceived with \"toleration\" and \"wholesome regulations.\" Benjamin Martyn, the Trustees secretary, wrote, \"We are indebted to the Lord Shaftsbury, and that truly wise man Mr. Locke, for the excellent laws which they drew up for the first settlement of Carolina.\" Other sources are speculative, since they were not cited by Oglethorpe of the Trustees. Such possible inspirations include classical planning concepts dating to Vitruvius and Roman colonial planning (e.g., Timgad), Renaissance concepts of the ideal city, and later plans such as the Vauban plan of Neuf-Brisach.\n\nMany prominent planners and urban theorists have commented on various attributes of the Oglethorpe Plan, particularly the layout of Savannah. The quotes cited below are only a few of many laudatory comments.\n\n\"The famous Oglethorpe plan for Savannah … made a unique use of the square in the design, nothing like it having appeared in a town plan before or since. Here, in Savannah, the square by frequent repetition becomes an integral part of the street pattern and creates a series of rhythmically placed openings which give a wonderful sense of space in a solidly built townscape.\" –Paul Zucker\n\n\"… a plan so exalted that it remains as one of the finest diagrams for city organization and growth in existence.\" –Edmund Bacon\n\n\"[T]he grid pattern of Savannah . . . is like no other we know in its fineness and its distinguishable squares. . . . [O]nce seen it is unforgettable, and it carries over into real life experience.\" --Allan Jacobs\n\n\"Savannah occupies a unique position in the history of city planning. No complete precedents exist for its pattern of multiple open spaces….\"—John W. Reps\n\nSuch comments nearly always apply to the ward layout found in the Savannah historic district, where the city preserved and elaborated on the original town plan laid out by Oglethorpe. Though seldom mentioned, notable vestiges of the Oglethorpe Plan can be found in the land use pattern surrounding Savannah; in the cities of Darien, Georgia; Brunswick, Georgia; and at Fort Frederica National Monument on St. Simons Island, Georgia.\n\nOglethorpe developed a town plan in which the basic design unit was the ward. Wards were composed of four tything (residential) blocks and four trust (civic) blocks, arrayed around a central square. The tything blocks contained ten houses, which was the basic organizational unit for administration, farming, and defense. Each tything was assigned a square mile tract outside town for farming, with each family farming a forty-five acre plot within that tract. The tything trained together for militia duty, a necessity on the frontier. Families were also assigned five-acre kitchen gardens near town.\n\nOglethorpe’s town plan was initially developed for Savannah, which grew largely in accordance with the original design. The same basic plan was intended for replication in towns throughout the colony; however, the original design survives in few towns. Recently, Brunswick, Georgia, adopted a version of the design modeled after the Trustee period\n\nThe City of Savannah has preserved the ward design within its National Historic Landmark District. Oglethorpe originally laid out six wards in Savannah. The design proved remarkably adaptable as the city grew, and city officials perpetuated the same basic model for more than a century. Ultimately, twenty-four wards were laid out in general accordance with the original design, filling most of the original square-mile town common.\n\nThe city’s modern street grid outside of the historic district follows much of the original system of rights-of-way established under the Oglethorpe Plan for the gardens, farms, and villages that made up the Savannah region.\n\nMany of the principles found in the Oglethorpe Plan are as relevant today as the democratic principles articulated at the dawn of the American Revolution. Urban theorists have duly acknowledged Oglethorpe’s remarkable design legacy in Savannah, but most have said little about the plan’s larger purpose of fostering social equity. Urban planners and designers in Savannah have rediscovered Oglethorpe’s principles of integrated town planning, incorporating them in the city’s comprehensive plan and various implementing ordinances. The city’s success in doing so now stands as a model inviting wider application.\n\nThe plan is fundamentally different from modern town or community plans by allowing for growth in small, interlocking units, or wards, of approximately 10 acres (4 hectares). The exact size of a ward will vary depending on the width of streets that bound it. In Savannah, streets between wards vary from 45 feet to 120 feet, including sidewalks and landscaped medians. While the size of a ward may vary, it is important to keep it within about 15 percent of Oglethorpe’s original layout. In following this standard automobile traffic is naturally limited to speeds of about 20 mph (30 kph), the threshold for pedestrian comfort in a mixed-modal, shared space environment.\n\nAnother way in which the plan is fundamentally different from most designs today is in maximizing lot coverage on buildable lots while minimizing the open space requirement on those lots. Minimizing or eliminating these standards can be done because open space is provided in the public realm. A ward contains approximately 50% developable area and 50% public area (depending on the width of bounding streets), and because the public area is shared space streets contribute to open space both aesthetically and functionally.\n\nThe Savannah town plan has been praised profusely, as mentioned earlier, but no recent or contemporary replicas of it exist either in infill or suburban developments, even in Savannah's own districts that lie beyond the original square mile commons. Its cellular ward system has been cited as a unique example of fractal, or \"organic\", city growth in which each ward cell is a microcosm of the entire city.\n\nIts recognized and praised advantages have recently been incorporated in a planning model, which is also cellular, that shows the influence of the Oglethorpe plan – the Fused Grid. Diagrammatic and approved plans, based on this model reflect the Savannah plan principle of organizing buildable space around open space. In this reformulated expression of it, which accommodates contemporary planning, technological and cultural priorities, Oglethorpe’s Town Plan could find a renewed appreciation and wider replication.\n\n"}
{"id": "10162537", "url": "https://en.wikipedia.org/wiki?curid=10162537", "title": "Oleosin", "text": "Oleosin\n\nOleosins are structural proteins found in vascular plant oil bodies and in plant cells. Oil bodies are not considered organelles because they have a single layer membrane and lack the pre-requisite double layer membrane in order to be considered an organelle. They are found in plant parts with high oil content that undergo extreme desiccation as part of their maturation process, and help stabilize the bodies.\n\nOleosins are proteins of 16 kDa to 24 kDa and are composed of three domains: an N-terminal hydrophilic region of variable length (from 30 to 60 residues); a central hydrophobic domain of about 70 residues and a C-terminal amphipathic region of variable length (from 60 to 100 residues). The central hydrophobic domain is proposed to be made up of beta-strand structure and to interact with the lipids. It is the only domain whose sequence is conserved. Models show oleosins having a hairpin-like hydrophobic shape that is inserted inside the triacylglyceride (TAG), while the hydrophilic parts are left outside oil bodies.\n\nOleosins have been found on oil bodies of seeds, tapetum cells, and pollen but not fruits. Instead of a stabilizer of oil bodies, oleosins are believed to be involved in water-uptaking of pollen on stigma.\n\nOleosins provide an easy way of purifying proteins which have been produced recombinantly in plants. If the protein is made as a fusion protein with oleosin and a protease recognition site is incorporated between them, the fusion protein will sit in the membrane of the oil body, which can be easily isolated by centrifugation. The oil droplets can then be mixed with aqueous medium again, and oleosin cleaved from the protein of interest. Centrifugation will cause two phases to separate again, and the aqueous medium now contains the purified protein.\n"}
{"id": "1923795", "url": "https://en.wikipedia.org/wiki?curid=1923795", "title": "Population geography", "text": "Population geography\n\nPopulation geography is a division of human geography. It is the study of the ways in which spatial variations in the distribution, composition, migration, and growth of populations are related to the nature of places. Population geography involves demography in a geographical perspective. It focuses on the characteristics of population distributions that change in a spatial context. This often involves factors such as where populations are found and how the size and composition of these populations is regulated by the demographic processes of fertility, mortality, and migration. Contributions to population geography are cross-disciplinary because geographical epistemologies related to environment, place and space have been developed at various times. Related disciplines include geography, demography, sociology, and economics.\n\nSince its inception, population geography has taken at least three distinct but related forms, the most recent of which appears increasingly integrated with human geography in general. The earliest and most enduring form of population geography emerged in the 1950s, as part of spatial science. Pioneered by Glenn Trewartha, Wilbur Zelinsky, William A. V. Clark, and others in the United States, as well as Jacqueline Beujeau-Garnier and Pierre George in France, it focused on the systematic study of the distribution of population as a whole and the spatial variation in population characteristics such as fertility and mortality.\nPopulation geography defined itself as the systematic study of:\n\n\n\n\nAccordingly, it categorized populations as groups synonymous with political jurisdictions representing gender, religion, age, disability, generation, sexuality, and race, variables which go beyond the vital statistics of births, deaths, and marriages. Given the rapidly growing global population as well as the baby boom in affluent countries such as the United States, these geographers studied the relation between demographic growth, displacement, and access to resources at an international scale.\n\nExamples can be shown through population density maps. A few types of maps that show the spatial layout of population are choropleth, isoline, and dot maps.\n\nSuburbanization in the developed part of North America has roots in the migration decisions of many families who leave central cities and relocate on the urban fringe. This type of metropolitan decentralization matters because it contributes to the pressures on rural and \"green-field\" land, the under-funding of inner-city schools, the continuing segregation of groups in society, and the difficulties some suburban housewives encounter in finding jobs.\n\nWhen the political creation of Israel was brokered in 1948, the act of drawing boundaries created new populations and divided others. Specifically, the displacement of thousands of residents of the former Palestine and the wholesale destruction of over 500 Arab villages created a refugee population that is, today, the world’s largest (over 4 million) and longest-lasting, including over two generations. Palestinian refugee communities lack access to human rights, protection, territorially rooted homelands and land that can support reasonable livelihoods. Refugee populations are some of the world’s poorest, most insecure, most fragile, and most dependent communities. While poverty and endemic insecurity characterize Palestinian refugees, the state of Israel is both threatened by the co-presence of this refugee community and complicit/active in its maintenance, through acts purported as securing the state.\n\nTuberculosis (TB) was a leading cause of death among young men and women in many North American cities at the turn of the 20th century. Medical discoveries about the spread of the disease and childhood vaccinations helped to decrease TB infections and case mortality rates declined steadily during the century. However, by the early 1990s, figures by place of birth suggested that foreign-born persons were eight times more likely to die from TB than native-born Americans. By studying the geographic context of disease, it becomes apparent that TB is less a marker of immigration than it is of poverty. Increasing TB levels in parts of the former Soviet Union territories and Haiti suggest that unemployment, poor access to underfunded healthcare systems, and stress all elevate risk. Immigrants also do not seem to be bringing TB to the United States but instead developing TB once inside the country. Concentrations of TB among immigrants in non-traditional destination states may suggest poor agricultural working conditions, barriers to accessing healthcare, and concentrations of refugee groups in unhealthy areas.\n\nAfrica has now become the fastest-growing and fastest-urbanizing continent. Africa's population is estimated to reach two billion by 2050. As countries get richer, they experience a demographic transition. Africa's people are its biggest asset; one day, its workforce could be as robust and dynamic as Asia's. But there is nothing inevitable about the ability to cash in the demographic dividend. For that to happen, Africa will have to choose the right policies and overcome its many problems.\n\nThe traditional United Nations definition of retirees is defined as age 65. The population aging that is presently occurring is unprecedented. Over the next decade, the number of people aged 60 years and over is expected to rise substantially, and most of the increase will occur in developing countries. Globally, the number of older persons is expected to exceed the number of children in 2045 for the first time.\n\nThe rapidly aging population is likely to have far-reaching effects. Economically, population aging affects growth, savings, investments, consumption, labor markets, social security systems, taxation, and inter-generational transfers. Socially, it influences family structures, housing demands, migration trends, and the epidemiology of diseases and the need for healthcare service. Politically, it shapes voting patterns and representation. Population aging has received considerable attention in developed countries, but only in the past few decades has awareness of the ramifications of a rapidly aging population grown in the rest of the world.\n\n\nResearch topics of other geographic sub-disciplines, such as settlement geography, also have a population geography dimension:\n\n\nAll of the above are looked at over space and time. Population geography also studies the relationships between man and his environment, including problems from those relationships, such as overpopulation, pollution, and others.\n\n\n"}
{"id": "39079246", "url": "https://en.wikipedia.org/wiki?curid=39079246", "title": "Regulatory mode theory", "text": "Regulatory mode theory\n\nRegulatory mode theory, along with regulatory focus theory was developed by E. Tory Higgins and Arie Kruglanski who are interested in the development of goal-pursuit as well as motivation. The theory depicts two main approaches to situations using locomotion and assessment.\n\nThe regulatory mode theory depicts how people approach situations to achieve the goal. This theory is part of E. Tory Higgins research in motivation theories and goal pursuit theories. People can either use the locomotion or the assessment method for goal-pursuit. E. Tory Higgins states, \"When people self-regulate they decide what they want that they don’t currently have. They then figure out what they need to do to get what they want, and then they do it.\" People who are geared towards the locomotion mode are focused on moving and getting things done. In contrast, those that are strong in assessment will compare different goals and analyze different options.\n\nA study done by Pierro, Giacomantonio, Pica, Kruglanski, and Higgins (2011) examined the ways locomotion and assessment affects procrastination and how people manage time. The study found that assessment is positively related to procrastination and locomotion is negatively related to procrastination. To reach a certain goal, assessors have to analyze and compare a large amount of work. However, the locomotors were generally quicker to make decisions and act on them. The study emphasized that assessment orientation evaluates and analyzes in such detail that they delay making the decision quickly. Yet for the assessment-oriented individuals, they were more accurate in their decisions even though they took a longer time. These two regulatory modes reflect motivational styles for goal-pursuit. The motivation behind the assessment mode is accuracy and for locomotion mode it is action.\n\nA person's regulatory mode is correlated with regulatory fitness. They display their optimal level of performance in addition to valuing the end goals. In Avnet and Higgin's study (2004), the participants paid more for the book-light when their decisions were based on their regulatory orientation—either locomotion or assessment. They demonstrated that the value of the book-light is dependent on their approach systems.\n\nConsequently, locomotion can be very efficient in maintaining attitude, creating intention, and facilitating behavior. Mannetti, Pierro, Higgins, and Kruglanski (2012) investigated peoples' commitment to exercising at the gym and how regularly they went. They evaluated the participants' regulatory mode using a questionnaire and then their attendance was recorded in a 6-month period. Results show that when the people had high locomotion concerns and they had positive attitudes about physical exercise, their intentions to engage in physical exercise were high. They would proceed to actually engage in physical exercise within the 6-month period. Since locomotion runs on the motivation to do and to act, the positive effects of making a behavior happen can be expanded to other areas.\n"}
{"id": "37521998", "url": "https://en.wikipedia.org/wiki?curid=37521998", "title": "Scalindua brodae", "text": "Scalindua brodae\n\n\"Candidatus Scalindua brodae\" is a bacterial member of the order Planctomycetes and therefore lacks peptidoglycan in its cell wall, has a compartmentalized cytoplasm. It is an ammonium oxidising bacteria.\n\n"}
{"id": "27440977", "url": "https://en.wikipedia.org/wiki?curid=27440977", "title": "Society for Philosophy and Technology", "text": "Society for Philosophy and Technology\n\nThe Society for Philosophy and Technology (SPT) is an independent international organization founded in 1976 whose purpose is to promote philosophical consideration of technology. SPT publishes \"\", a tri-annual scientific journal.\n\n\n\n\n\n"}
{"id": "30121570", "url": "https://en.wikipedia.org/wiki?curid=30121570", "title": "Thermo galvanometer", "text": "Thermo galvanometer\n\nThe thermo-galvanometer is an instrument for measuring small electric currents. It was invented by William Duddell about 1900. The following is a description of the instrument taken from a trade catalog of Cambridge Scientific Instrument Company dated 1905: \n\nFor a long time the need of an instrument capable of accurately measuring small alternating currents has been keenly felt. The high resistance and self-induction of the coils of instruments of the electro-magnetic type frequently prevent their use. Electro-static instruments as at present constructed are not altogether suitable for measuring very small currents, unless a sufficient potential difference is available.\n\nThe thermo-galvanometer designed by Mr W. Duddell can be used for the measurement of extremely small currents to a high degree of accuracy. It has practically no self-induction or capacity and can therefore be used on a circuit of any frequency (even up to 120,000~ per sec.) and currents as small as twenty micro-amperes can be readily measured by it . It is equally correct on continuous and alternating currents. It can therefore be accurately standardized by continuous current and used without error on circuits of any frequency or wave-form.\n\nThe principle of the thermo-galvanometer is simple. The instrument consists of a resistance which is heated by the current to be measured, the heat from the resistance falling on the thermo-junction of a Boys radio-micrometer. The rise in temperature of the lower junction of the thermo-couple produces a current in the loop which is deflected by the magnetic field against the torsion of the quartz fibre.\n"}
{"id": "7141379", "url": "https://en.wikipedia.org/wiki?curid=7141379", "title": "Touchet River", "text": "Touchet River\n\nThe Touchet River is a tributary of the Walla Walla River in southeastern Washington in the United States.\n\nThe upper Touchet was a traditional summer meeting place for trade and games for the Palus, Nez Perce and Walla Walla tribes. The name Touchet derives from the similarly pronounced Sahaptin term for the river, \"Tu-se\" meaning roasting. Nez Perce legend tells that coyote roasted salmon at this river after breaking a fish dam guarded by the seven swallow sisters at Celilo.\n\nThe USGS cited two variant names, Pouchet River and Toosha River.\n\nThe Touchet River drains an area of about . The main stem is long. The average annual flow of the Touchet is 6.23 m³/s (220 ft³/s), not including diversions.\n\nIts headwaters lie in the Umatilla National Forest which is located in the Blue Mountains in Columbia County, southern Washington. It originates above the town of Dayton, Washington. It then passes through Waitsburg and Prescott before joining the Walla Walla at the town of Touchet, Washington.\n\nThe main Touchet River is formed by the confluence of the North Fork of the Touchet which originates in the vicinity of the Bluewood Ski Area, and the South Fork of the Touchet which originates at Deadman Peak. The forks join about south of (upstream of) Dayton. The North Fork is about long and the South Fork about long. Other tributaries include Patit Creek, which joins the Touchet at Dayton; Coppei Creek, which enters at Waitsburg, and Whetstone Creek, which joins the Touchet at Prescott.\n\nThe Touchet is known for its trout fishing, especially in the upper reaches.\n\nAlthough summer steelhead, which like salmon are anadromous, and Chinook salmon spawned throughout a large portion of the middle and upper reaches of the Touchet River drainage, the population is virtually nonexistent in the 21st century. The Nine Mile Dam, constructed in 1905 on the Walla Walla River below the confluence with the Touchet River, ended anadromous fish migration into the Touchet.\n\nThe Touchet River lay in the traditional range of the Palus American Indian tribe, marking their southern border with the range of the Walla Walla tribe. These peoples were of the Sahaptin-speaking group which traditionally inhabited the Columbia Plateau region of the northwestern United States.\n\nRoots provided plentiful food along the Touchet Rivers. These included quamash, camas, kouse, bitterroots, serviceberry (currant), chokecherry, huckleberry, gooseberries, rose berries and whortleberries, elderberries, wild strawberries, wild onions and balsamroot. Once Euroamerican immigrants began settling the area after 1858, Indian root grounds were displaced by agriculture.\n\nPrior to the white man coming into the valley of the Touchet River, there was an established American Indian trail through the valley, the \"Nez Perce Trail to Celilo Falls\" or \"Old Celilo Falls Trail\", by which the Nez Perce (also part of the Sahaptin-speaking group) passed west to fish for salmon at Celilo Falls on the Columbia River. As with other Sahaptin-speaking peoples, the Nez Perce were migratory, returning to the same locations year after year; Celilo Falls lay at the western end of their annual range.\n\nOn their return journey in 1806, the Lewis and Clark Expedition followed the \"Old Celilo Falls Trail\", up the Walla Walla and Touchet River Valleys; they camped on the Touchet about north of today's town of Touchet on April 30, 1806. The Lewis and Clark Trail State Park commemorates their May 1, 1806 campsite on the Touchet River. The expedition left the Touchet River to follow a tributary, Patit Creek, at what is now Dayton. They camped about above modern-day Dayton on Patit Creek on May 2, 1806, before following the trail across country to the Tucannon River.\n\nThe Whitman Mission catalyzed white settlement of the region, beginning in 1843 when 1,000 people, 120 wagons, and approximately 5,000 horses and cattle came to the Walla Walla valley. The initial settlers remained near the current city of Walla Walla and into the Touchet River valley.\n\nThe Lamar Cabin, built in 1863 of hand-hewn cottonwood logs from the Touchet River valley by George Dudley Goodwin, became the home of the bachelor brothers James and Joseph Lamar in 1872 (women were rare in the valley and many men remained unmarried). The brothers initially raised sheep and horses; in later years they, mirroring the transitions of many others in the region, cultivated dryland winter wheat. This area developed into the town of Lamar when the Hunt Railroad was built along the Touchet River valley in 1888. The railway left the Touchet River and continued west at Lamar at the point where the Touchet River turns south to meet the Walla Walla. Although the town site is now virtually abandoned, the historic Lamar cabin is preserved to this day (see photo).\n\nNear the head of the Touchet valley, Dayton was officially incorporated on November 10, 1881.\n\n\n"}
{"id": "5615980", "url": "https://en.wikipedia.org/wiki?curid=5615980", "title": "Tree of knowledge system", "text": "Tree of knowledge system\n\nThe tree of knowledge (ToK) system is a theoretical approach to the unification of psychology developed by Gregg Henriques, associate professor and director of the Combined-Integrated Doctoral Program in Clinical and School Psychology at James Madison University.\n\nThe outline of the system was published in 2003 in \"Review of General Psychology\". Two special issues of the \"Journal of Clinical Psychology\" in December 2004 and January 2005 were devoted to the elaboration and evaluation of the model. The latest evaluation of this model appeared in a December 2008 special issue of \"Theory & Psychology''.\n\nThe official website on the tree of knowledge system claims that the ToK is\n\nHenriques argues that the most difficult problem in psychology as a discipline is that while there is incredible diversity offered by different approaches to psychology, there is no consensus model of what \"psychology\" actually is.\nAccording to the ToK system, the \"problem of psychology\", (as Henriques puts it), is that a clear definition, an agreed upon subject matter, and a coherent conceptual framework have eluded its students for its entire history. He further argues that the patent tendency of psychology has been toward theoretical and substantial fragmentation and increasing insularity among the \"specialties.\" In other words, the discipline has fragmented into different schools of thought and methodology, with no overall framework to interpret and integrate the research of different areas. At its best, the different approaches are a strength of psychology; different approaches lead to novel ideas, and prevent psychologists from clinging to a paradigm that fails to explain a phenomenon. At its worst, adherents of one particular school cling to their beliefs concerning the relative importance of their research and disregard or are ignorant of different approaches. In most cases, individual psychologists have to determine for themselves which elements of which perspective to apply, and how to integrate them into their overall understanding.\nThe reason for psychology's fragmentation, according to the ToK, is that there has been no meta-theoretical frame that allows scholars to agree on the basic questions that need to be addressed. As such, the different schools of thought in psychology are like the blind men who each grab a part of the elephant and proclaim they have discovered its true nature. With its novel depiction of evolving dimensions of complexity, the ToK allows scholars finally to see the elephant. In his 2003 \"Review of General Psychology\" paper, Henriques used the ToK System with the attempt to clarify and align the views of B.F. Skinner and Sigmund Freud. These luminaries were chosen because when one considers their influence and historical opposition, it can readily be argued that they represent two schools of thought that are the most difficult to integrate. Henriques used the meta-perspective offered by the ToK to argue how one can retain the key insights from each school of thought, identify errors and points of confusion, and integrate the insights into a coherent whole.\n\nCultural and personality psychologist, Michael Katzko, however critiques Henriques' position on \"the problem of psychology\":\n\nIn one way, the tree of knowledge system reflects a fairly common hierarchy of nature and of the sciences that has been represented in one way or another since the time of Auguste Comte, who in the 19th century used a hierarchical conception of nature to argue for the existence of sociology. Despite its surface agreement with a standard conception, the ToK System offers a set of ideas that have added implications for both ontology and epistemology. The ontological claim made by the ToK, (and depicted pictorially above), is that cosmic evolution consists of four separable dimensions of complexity, namely matter, life, mind, and culture. The dimension of complexity argument is arguably one of the most complicated aspects of the system. Many have argued nature is hierarchically leveled; for example, a list of such levels might be subatomic particles, atoms, molecules, cells, organ structures, multi-celled organisms, consciousness, and society is common. The ToK System embraces a view of nature as levels, but adds the notion that there are also \"dimensions of complexity\". The difference can be seen pictorially. A view of nature as solely consisting of levels would have a single \"cone\" of complexity, whereas the ToK depicts four \"cones\". The ToK posits that a separate dimension of complexity emerges when a process of selection operates on a unit of information. Thus, according to the ToK, natural selection operating on genetic combinations gives rise to the dimension of Life; behavioral selection operating on neuronal combinations gives rise to the dimension of Mind; and justification operating on symbolic combinations gives rise to Culture.\n\nThe ToK system also offers a new epistemology that Henriques believes will move toward what E.O. Wilson termed \"consilience\". Consilience is the interlocking of fact and theory into a coherent, holistic view of knowledge. The ToK offers alternative perspectives on how knowledge is obtained because it depicts science itself as both emerging out of culture and as a unique type of \"justification system\" that is based on the values of accuracy and objectivity. A \"justification system\", according to Henriques, refers to any belief system that emerges that coordinates the behaviors of individual humans to human populations. The four dimensions of complexity correspond to four broad classes of science: the physical, biological, psychological and social sciences.\n\nThe dimension of matter refers to the set of material objects and their behaviors through time. In accordance with modern cosmology, matter is theorized to have emerged from a pure energy singularity at the Big Bang. Space and time were also born at such a point. Nonliving material objects range in complexity from subatomic particles to large organic molecules. The physical sciences (i.e., physics, chemistry, geology, astronomy) describe the behavior of material objects.\n\nThe dimension of life refers to organisms and their behaviors through time. Living objects are considered a unique subset of material objects. Just as quantum particles form the fundamental units of material complexity, genes are the fundamental units of living information. Although many questions about the emergence of life remain unanswered, in accordance with modern biology, the ToK posits that natural selection operating on genetic combinations through time is the unified theory of biology and forms the foundational understanding for the emergence of organic complexity.\n\nMind/cognition in the ToK system refers to the set of mental behaviors. \"Mental behaviors\" are behaviors of animals mediated by the nervous system that produce a functional effect on the animal-environment relationship. As such, Mind/cognition is essentially synonymous with what behavioral psychologists have meant when they use the term behavior. Thus, a fly avoiding a fly swatter, a rat pushing a bar or a human getting a drink of water are all mental behaviors. Mind is not synonymous with sentience or the capacity for mental experience, although such processes are presumed to emerge in the mental/cognitive dimension. Cognition, in the broad sense of the term is meaning bodily-neuro-social information processing, as in EEEE Cognition: Embodied, Embedded, Enactive, Extended. While cognitive science stands for naturalist study of mind, psychology is an approach grounded in the tradition of humanities, especially philosophy. Thus, by defining mind as mental behavior, Henriques argues that the ToK System provides a way to bridge the epistemological differences between cognitive and behavioral science.\n\nCulture in the ToK system refers to the set of sociolinguistic behaviors, which range from large scale nation states to individual human justifications for particular actions. Just as genetic information processing is associated with the Life dimension and neuronal information processing associated with the Mind dimension, symbolic information processing emerges with the Cultural dimension.\n\nQuantum gravity refers to the imagined merger between the twin pillars of physical science which are quantum mechanics, the study of the microscopic (e.g., electrons), and general relativity, the science of the macroscopic (e.g., galaxies). Currently, these two great domains of science cannot be effectively interwoven into a single, physical Theory of Everything. Yet progress is being made, most notably through string theory, loop quantum gravity, black hole thermodynamics and the study of the early universe. Some of the difficulties combining these two pillars of physical science are philosophical in nature and it is possible that the macro view of knowledge offered by the ToK may eventually aid in the construction of a coherent theory of quantum gravity. The reason the ToK might help is that it locates scientific knowledge in relationship to the physical universe.\n\nThe modern synthesis refers to the merger of genetics with natural selection which occurred in the 1930s and 1940s and offers a reasonably complete framework for understanding the emergence of biological complexity. Although there remain significant gaps in biological knowledge surrounding questions such as the origin of life and the emergence of sexual reproduction, the modern synthesis represents the most complete and well-substantiated joint point.\n\nBehavioral investment theory (BIT) is proposed as a merger of the selection science of behaviorism with the information science of cognitive neuroscience (notice the parallel with the modern synthesis). BIT posits that the nervous system evolved as an increasingly flexible computational control system that coordinates the behavioral expenditure of energy of the animal as a whole. Expenditure of behavioral energy is theorized to be computed on an investment value system built evolutionarily through natural selection operating on genetic combinations and ontogenetically through behavioral selection operating on neural combinations. As such, the current behavioral investments of the animal are conceptualized as the joint product of the two vectors of phylogeny and ontogeny. A unique element of BIT is that it finds a core of agreement and builds bridges between five brain-behavior paradigms: (1) cognitive science; (2) behavioral science; (3) evolutionary theory and genetics; (4) neuroscience; and (5) cybernetics/systems theory.\n\nDavid C. Geary noted the similarities between his \"motive-to-control\" hypothesis and Henriques' Behavioral Investment Theory, which were developed independently of each other. Furthermore, Geary suggested that his model \"seem[ed] to fill in many of the proximate mechanisms and evolutionary pressures that define the life-mind joint point, and provided a framework for further development of the mind-culture joint point.\"\n\nThe justification hypothesis (JH) is a novel proposal that allows for both the understanding of the evolution of culture and for identifying what makes humans distinct animals. A basic initial claim of the JH is that the process of justification is a crucial component of human mental behavior at both the individual and societal level. Unlike all other animals, humans everywhere ask for and give explanations for their actions. Arguments, debates, moral dictates, rationalizations, and excuses all involve the process of explaining why one's claims, thoughts or actions are warranted. In virtually every form of social exchange, from warfare to politics to family struggles to science, humans are constantly justifying their behavioral investments to themselves and others.\n\nThe JH can be stated succinctly as follows: The evolution of language gave rise to the problem of justification, and this evolutionary pressure ultimately resulted in the human self-consciousness system and human culture. The JH carries with it three fundamental postulates. \n\nThe problem of psychology, according to the ToK, is its conceptual incoherence, which Henriques identifies by the following: \n\nWhen the various conceptions of psychology (e.g., behavioral, humanistic, cognitive) are viewed through the lens of the ToK System, psychology spans two different dimensions of complexity: the mental and the cultural. In other words, the discipline has historically spanned two fundamentally separate problems: \nIf, as previously thought, nature simply consisted of levels of complexity, psychology would not be crisply defined in relationship to biology or the social sciences. And, indeed, it is frequently suggested that psychology exists in an amorphous space between biology and the social sciences. However, with its dimension of complexity depiction, the ToK System suggests that psychology can be crisply defined as the science of mind, which is the third dimension of complexity. Furthermore, because human behavior exists in the fourth dimension, psychology must be divided into two broad scientific domains of \n\n\"Psychological formalism\" is defined as the science of mind and corresponds to the behavior of animal objects. \"Human psychology\" is considered to be a unique subset of psychological formalism that deals with human behavior at the level of the individual. Because human behavior is immersed in the larger socio-cultural context (level four in the ToK System), human psychology is considered a hybrid discipline that merges the pure science of psychology with the social sciences. It is important to point out that there are other disciplines the ToK System would classify as “hybrids.” Molecular genetics, for example, is a hybrid between chemistry and biology and neuroscience is a hybrid between biology and psychology. As with Henriques' proposed conception of human psychology, both of these disciplines adopt an object level perspective (molecular and cellular, respectively) on phenomena that simultaneously exist as part of meta-level system processes (life and mind, respectively).\n\nThough David A. F. Haaga \"congratulate[d] Dr. Henriques' ambitious, scholarly, provocative paper\", and \"found the Tree of Knowledge taxonomy, the theoretical joint points, the evolutionary history, and the levels of emergent properties highly illuminating\", he asks the rhetorical questions, \n\nIn a similar vein, Scott O. Lilienfeld, who described Henriques' effort as \"thoughtful\", contended that psychology is \"an inherently fuzzy concept that resists precise definition\" and that \"attempts to define psychology [would be] likely to hamper rather than foster consilience across disciplines\". Lilienfield went on further to suggest that the scientist-practitioner gap in psychology lies not in definitional issues, but in different \"epistemic attitudes\" between these two groups. He stated that scientists have an epistemic attitude of empiricism, (where questions regarding human nature are settled by scientific evidence), and that practitioners have an epistemic attitude of romanticism, (where questions of human nature are settled by intuition). Lilienfeld suggested that the solution to the scientist-practitioner gulf isn't definitional, but in \"train[ing] future clinical scientists to appreciate the proper places of romanticism and empiricism within science\".\n\nA frequent question and point of confusion in the ToK System is the definition and meaning of consciousness. As mentioned above, mind is not synonymous with consciousness. And, to understand consciousness from a ToK vantage point, it is crucial to recognize that the term is often ambiguous in its meaning. Two primary meanings are sentience, which is the capacity for mental experience and self-awareness, which is the capacity to be aware of one's awareness. Sentience is conceptualized as a \"level 3\" phenomena, possessed by many animals other than humans and is defined as a \"perceived\" electro-neuro-chemical representation of animal-environment relations. The ingredient of neurological behavior that allows for the emergence of mental experience is considered the \"hard\" problem of conscious and the ToK System does not address this question explicitly. In contrast, through the Justification Hypothesis (see below), the ToK System involves a very direct analysis of the other issue of consciousness, that of self-awareness. \nAnother frequent question that is raised is \"Where does individual human behavior fall on the ToK?\" To analyze human behavior from the context of the ToK, one uses the ToK like a prism to separate the dimensions of behavior into physiochemical, biogenetic, neuropsychological and sociolinguistic. Thus if we imagine a conversation between a husband and wife as follows:\n\nThe words represent the sociolinguistic dimension and are understood as a function of justification. Justification systems are seen both at the level of individual, micro-social and societal (i.e., the context of justification in which men work and women stay at home). The actions of the husband and wife in terms of facial expression, body movement, etc. are seen as the mental dimension and are understood as a function of behavioral investment. The physiological make up of the organ systems and cells of each body is seen as the biogenetic dimension. Finally, the position, temperature, molecular make up is seen as the physiochemical dimension. Each of the more basic dimensions represent conditions of possibility that allow for the emergence of the higher dimension of process. Thus, insufficient oxygen disrupts organic processes which in turn renders neuropsychological and sociolinguistic processes impossible.\n\nAs stated above, the ToK System proposes a new epistemology with the goal of moving academic knowledge toward what E.O. Wilson termed consilience. Consilience is the interlocking of fact and theory into a coherent, holistic view of knowledge. Henriques argues that the ToK affords new perspectives on how knowledge is obtained because it depicts how science emerges from culture and that the four dimensions of complexity correspond to four broad classes of science: the physical, biological, psychological and social sciences.\n\nHenriques further argues that developing such a system for integrating knowledge is not just an academic enterprise. He suggests that in an increasingly complex world, the fragmented state of knowledge can be seen as one of the most pressing social problems of our time. Henriques also believes that history seems to attest that the absence of a collective worldview ostensibly condemns humanity to an endless series of conflicts that inevitably stem from incompatible, partially correct, locally situated justification systems. Thus, from Henriques' perspective, there are good reasons for believing that if there was a shared, general background of explanation, humanity might be able to achieve much greater levels of harmonious relations.\nIn a 2008 article on the ToK, Henriques cites Oliver Reiser's 1958 call for unifying scientific knowledge that Henriques implies is similar in theme to the ToK:\n\nWith its depiction of the dimensions of complexity and interlocking theoretical joint points, Henriques' believes that his ToK System offers new avenues that might allow scholars to meet Reiser’s call for academic synthesis. Henriques, like Reiser, believes that with a shared sense of purpose and a common background of explanation, people might yet be able to integrate bodies of knowledge into a unified interpretation of humanity, with humanity's place in nature and its potentialities for creating the good society.\n\n\n"}
{"id": "34500414", "url": "https://en.wikipedia.org/wiki?curid=34500414", "title": "Udacity", "text": "Udacity\n\nUdacity, Inc. is a for-profit educational organization founded by Sebastian Thrun, David Stavens, and Mike Sokolsky offering massive open online courses (MOOCs). \n\nAccording to Thrun, the origin of the name Udacity comes from the company's desire to be \"audacious for you, the student\". While it originally focused on offering university-style courses, it now focuses more on vocational courses for professionals.\n\nUdacity is the outgrowth of free computer science classes offered in 2011 through Stanford University. Thrun has stated he hopes half a million students will enroll, after an enrollment of 160,000 students in the predecessor course at Stanford, Introduction to Artificial Intelligence, and 90,000 students had enrolled in the initial two classes . Udacity was announced at the 2012 Digital Life Design conference. Udacity is funded by venture capital firm, Charles River Ventures, and $200,000 of Thrun's personal money. In October 2012, the venture capital firm Andreessen Horowitz led the investment of another $15 million in Udacity. In November 2013, Thrun announced in a Fast Company article that Udacity had a \"lousy product\" and that the service was pivoting to focus more on vocational courses for professionals and \"nanodegrees.\" , Udacity has 1.6 million users in 12 full courses and 26 free courseware.\n\nIn 2014, the Georgia Institute of Technology launched the first \"massive online open degree\" in computer science by partnering with Udacity and AT&T; a complete master's degree through that program costs students $7,000.\n\nIn October 2017, Udacity along with Unity, launched ‘Learn ARKit’ program which could help the developers improve their AR application building skills. In the same month, Google partners with Udacity to launch a new scholarship initiative for aspiring Web and Android application developers.\nWhile not yet profitable as of February 2018, Udacity is valued at over $1B USD having raised $163M USD from noted investors included Andreessen Horowitz, Drive Capital, and Alphabet’s venture capital arm, GV.\n\nThe first two courses on Udacity started on 20 February 2012, entitled \"CS 101: Building a Search Engine\", taught by David Evans from the University of Virginia, and \"CS 373: Programming a Robotic Car\" taught by Thrun. Both courses use Python.\n\nFour more courses began on 16 April 2012, encompassing a range of ability and subject matter, with teachers including Steve Huffman and Peter Norvig. Five new courses were announced on 31 May 2012, and marked the first time Udacity offered courses outside the domain of computer science. Four of these courses launched at the start of the third \"hexamester\", on 25 June 2012. One course, Logic & Discrete Mathematics: Foundations of Computing, was delayed for several weeks before an email announcement was sent out on 14 August stating that the course would not be launched, although no further explanation was provided.\n\nOn 23 August 2012, a new course in entrepreneurship, EP245 taught by retired serial entrepreneur Steve Blank, was announced. Four new specialized CS courses were announced as part of collaboration with Google, Nvidia, Microsoft, Autodesk, Cadence Design Systems, and Wolfram Research on 18 October 2012, to be launched in early 2013. On 28 November 2012, Thrun's original AI-class from 2011 was relaunched as a course at Udacity, CS271.\n\n<div class=\"NavContent\" style=\"text-align:left\">\n"}
{"id": "55740418", "url": "https://en.wikipedia.org/wiki?curid=55740418", "title": "W.E.B. Du Bois Career of Distinguished Scholarship Award", "text": "W.E.B. Du Bois Career of Distinguished Scholarship Award\n\nThe W.E.B. Du Bois Career of Distinguished Scholarship Award is given annually by the American Sociological Association to a scholar among its members whose cumulative body of work constitutes a significant contribution to the advancement of sociology. Formerly called simply the Career of Distinguished Scholarship Award, the award was renamed in 2006 to honor pioneering American sociologist W. E. B. Du Bois.\n\n\n \n"}
{"id": "57898182", "url": "https://en.wikipedia.org/wiki?curid=57898182", "title": "Wing (company)", "text": "Wing (company)\n\nWing is a subsidiary of Alphabet Inc. that aims to rapidly deliver products across a city by using flying vehicles, similar to the Amazon Prime Air concept. At the time of the announcement on August 28, 2014, it had already been in development secretly at Google X for about two years, with full-scale testing being carried out in Australia. The flying vehicles take off vertically, then rotate to a horizontal position for flying around. For delivery, it hovers and winches packages down to the ground. At the end of the tether is a small bundle of electronics which detects that the package has hit the ground, detaches from the delivery, and is pulled back up into the body of the vehicle. Dropping the cargo or landing were found to be unfeasible, as users compromised the safety. In July 2018, Project Wing was spun out of X into an Alphabet owned company.\n"}
