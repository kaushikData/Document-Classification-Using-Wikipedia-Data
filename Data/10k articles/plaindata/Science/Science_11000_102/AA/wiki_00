{"id": "7628451", "url": "https://en.wikipedia.org/wiki?curid=7628451", "title": "A370 road", "text": "A370 road\n\nThe A370 is a primary road in England running from Bath Road, near Temple Meads railway station in the city of Bristol to Weston-super-Mare before continuing to the village of East Brent in Somerset. A more direct route from Bristol to East Brent is the A38.\n\nWithin Bristol urban area, the road begins at Bath Road roundabout, at the busy junction with A4 near Temple Meads. It then follows the new cut of River Avon west to Cumberland basin, via Bedminster.\n\nFrom here on, it begins to head south-westwards out of the City. It first bypasses Long Ashton, then passes through Flax Bourton, Backwell, Brockley, Cleeve, Congresbury and Hewish, beyond which it crosses the M5 motorway at Junction 21.\n\nThe road then enters Weston-super-Mare: a dual carriageway extends most of the way, by passing the built-up area, including Junction 21 Enterprise Area to the east of the town. On reaching the waterfront, the road turns south to run partly along the beach, then leaves Weston at Uphill. It passes Bleadon and Lympsham before meeting the A38 road at East Brent.\n\nThe A370 can get extremely busy during rush hour. Congestion points include the approaches to the M5 motorway, the traffic lights in Congresbury and the Long Ashton bypass—which now has a high-occupancy vehicle lane solely for use by buses, taxis, motorcycles, and cars with two or more occupants.\n\nAs part of the \"Greater Bristol Strategic Transport Study\", a link road is under consideration to the south of Bristol. This is in part due to the congestion at Winterstoke Road and Barrow Gurney, both of which are very busy, especially the latter where the road can only accommodate travelling at one direction at a given time); and the incomplete Bristol Ring Road (A4174).\n\nBy 2017, A370 Long Ashton By Pass will be connected to the South Bristol Link (SBL) road, currently under construction as part of the MetroBus rapid transit scheme, providing a new road linking Hengrove to Long Ashton By Pass and the Long Ashton Park & Ride.\n\n"}
{"id": "2950924", "url": "https://en.wikipedia.org/wiki?curid=2950924", "title": "Accession number (bioinformatics)", "text": "Accession number (bioinformatics)\n\nAn accession number in bioinformatics is a unique identifier given to a DNA or protein sequence record to allow for tracking of different versions of that sequence record and the associated sequence over time in a single data repository. Because of its relative stability, accession numbers can be utilized as foreign keys for referring to a sequence object, but not necessarily to a unique sequence. All sequence information repositories implement the concept of \"accession number\" but might do so with subtle variations.\n\nLocus Reference Genomic (LRG) records have unique accession numbers starting with LRG_ followed by a number. They are recommended in the Human Genome Variation Society Nomenclature guidelines as stable genomic reference sequences to report sequence variants in LSDBs and the literature.\n\n"}
{"id": "1608605", "url": "https://en.wikipedia.org/wiki?curid=1608605", "title": "Alex Grossmann", "text": "Alex Grossmann\n\nAlexander Grossmann (Croatian: \"Aleksander Grossmann\"; born 5 August 1930) is a Croatian-French physicist at the Université de la Méditerranée Aix-Marseille II in Luminy campus who did pioneering work on wavelet analysis with Jean Morlet.\n"}
{"id": "34656582", "url": "https://en.wikipedia.org/wiki?curid=34656582", "title": "Annual BCI Research Award", "text": "Annual BCI Research Award\n\nThe Annual BCI Research Award is an annual accolade to recognize excellence in the field of brain-computer interface (BCI) research. The award is open to any person or group in any country. Each year, a different institute known for BCI research is chosen to host the award.\n\nThis institute selects a jury from established researchers within the BCI community, which selects ten nominees and then a winner. All ten nominees are invited and expected to submit chapters that summarize their submission to the Award, subsequent progress, and future directions. These chapters are then collected in a book with a major publisher, which also includes an introduction and conclusion with summary information.\n\nThe winner of the Annual BCI Research Award also receives $3,000 (1st), $2,000 (2nd), $1,000 (3rd) and a statue at a gala awards ceremony attached to a major conference. g.tec medical engineering GmbH and Guger Technologies OG, companies headquartered in Austria that manufactures BCI products, organize the Award together with international institutions.\n\nThe jury is instructed to score all projects based on the following criteria:\n\nEach year, the Annual BCI Research Award follows a rigorous, structured schedule to encourage the best submissions, ensure the most effective decisionmaking processes, and maximize the impact. This section describes the general timeline for each annual. Since the Award is presented at a major conference, the exact dates change each year, but the general procedure will not change.\n\nThe jury for the BCI Award was:\nStanford University, USA<br>\nAalborg University, Denmark<br>\n\nUniversity of Wisconsin at Madison, USA<br>\n\nChinese Academy of Sciences, China<br>\n\nFlorida Hospital for Children<br>\n\nStanford University<br>\n\nThe jury was responsible for selecting twelve nominees, and then three winners, using the same award criteria as earlier years. The Award Ceremony occurred on May 23, 2018 as part of the 7th International BCI Meeting, which occurred from May 21 to 25, 2018 at the Asilomar Conference Center in Pacific Grove, CA. For the first time, the awards ceremony occurred outside. The emcee (Brendan Allison) announced the nominees and the jury chair (Dr. Miller) presented the awards. Most of the attendees at the BCI meeting were in the audience during the ceremony. The first place winner received $3000 and the prestigious trophy, and the second and third place winners received $2000 and $1000, respectively. All nominees also received a certificate and other awards, and were invited to write a chapter for a book series with Springer Publishing that reviews the nominated projects each year. Twelve projects were nominated in 2018, which are presented below along with their authors and affiliation(s). \n\n<br>Generating Handwriting from Multichannel EMG\n\nAlexei E. Ossadtchi, Elizaveta Okorokova, Joseph S. Erlichman, Valery I. Rupasov, Mikhail A. Lebedev, and Michael Linderman\n\n<br>Real-time EEG Control of a Dexterous Hand Exoskeleton embedded with Synergies\n\nMartin Burns, Dingyi Pei, Ramana Vinjamuri\n\nDepartment of Biomedical Engineering, Stevens Institute of Technology, NJ, USA.\n\n<br>Neural decoding of attentional selection in multi-speaker environments without access to clean sources\n\nJames O’Sullivan, Zhuo Chen, Jose Herrero, Guy M McKhann, Sameer A Sheth, Ashesh D Mehta, Nima Mesgarani\n\n<br>BCI-based regulation of arousal improves human performance in a demanding sensory-motor task\n\nJ. Faller, J. Cummings, S. Saproo, P. Sajda\n\n<br>Brain-To-Speech: Direct Synthesis of Speech from Intracranial Brain Activity Associated with Speech Production\n\nChristian Herff, Lorenz Diener, Emily Mugler, Marc Slutzky, Dean Krusienski, Tanja Schultz\n\n<br>Restoring Functional Reach-to-Grasp in a Person with Chronic Tetraplegia using Implanted Functional Electrical Stimulation and Intracortical Brain-Computer Interfaces\n\nAbidemi Bolu Ajiboye, Francis R. Willett, Daniel R. Young, William D. Memberg, Brian A. Murphy, Jonathan P. Miller, Benjamin L. Walter, Jennifer A. Sweet, Harry A. Hoyen, Michael W. Keith, Paul Hunter Peckham, John D. Simeral, John P. Donoghue, Leigh R. Hochberg, Robert F. Kirsch\n\n<br>A BCI-Based Language Training for Patients with Chronic Aphasia\n\nMichael Tangermann, David Hübner, Simone Denzer, Atieh Bamdadian, Sarah Schwarzkopf, Mariacristina Musso\n\n<br>Neuromotor Recovery based on BCI, FES, Virtual Reality and Augmented Feedback for upper limbs\n\nRobert Gabriel Lupu, Florina Ungureanu, Oana Ferche, Alin Moldoveanu\n\n<br>A Dynamic Window SSVEP-Based Brain-Computer Interface System using a Spatio-Temporal Equalizer\n\nChen Yang, Xiang Li, Shangkai Gao, Xiaorong Gao\n\nDepartment of Biomedical Engineering, Tsinghua University Beijing, P.R. China.\n\n<br>Successful mutual learning with two tetraplegic users: The Cybathlon BCI race experience\n\nS. Perdikis, L. Tonin, S. Saeedi, C. Schneider, J. del R. Millán\n\nDefitech Chair in Brain-Machine Interface (CNBI), École Polytechnique Fédérale de Lausanne (EPFL), Geneva, Switzerland.\n\n<br>A Wireless Sensory Interface to Inform Goal-Directed Actions\n\nAndrew G. Richardson, Yohannes Ghenbot, Xilin Liu, Han Hao, Sam DeLuccia, Gregory Boyek, Solymar Torres-Maldonado, Firooz Aflatouni, Jan Van der Spiegel, Timothy H. Lucas\n\nUniversity of Pennsylvania, Philadelphia, PA, USA.\n\n<br>Longitudinal training and use of non-invasive motor imagery BCI by an incomplete locked-in user\n\nS. Perdikis, S. Saeedi, J. del R. Millán\n\nDefitech Chair in Brain-Machine Interface (CNBI), École Polytechnique Fédérale de Lausanne (EPFL), Geneva, Switzerland\n\n\"First place:\"\n\n<br>Restoring Functional Reach-to-Grasp in a Person with Chronic Tetraplegia using Implanted Functional Electrical Stimulation and Intracortical Brain-Computer Interfaces\n\nAbidemi Bolu Ajiboye, Francis R. Willett, Daniel R. Young, William D. Memberg, Brian A. Murphy, Jonathan P. Miller, Benjamin L. Walter, Jennifer A. Sweet, Harry A. Hoyen, Michael W. Keith, Paul Hunter Peckham, John D. Simeral, John P. Donoghue, Leigh R. Hochberg, Robert F. Kirsch\n\n\"Second place:\"\n\n<br>A BCI-Based Language Training for Patients with Chronic Aphasia\n\nMichael Tangermann, David Hübner, Simone Denzer, Atieh Bamdadian, Sarah Schwarzkopf, Mariacristina Musso\n\n\"Third place:\"\n\n<br>Brain-To-Speech: Direct Synthesis of Speech from Intracranial Brain Activity Associated with Speech Production\n\nChristian Herff, Lorenz Diener, Emily Mugler, Marc Slutzky, Dean Krusienski, Tanja Schultz\n\n<br>2019 BCI Research Awards\n\nThe 2019 BCI Research Awards Ceremony will occur on Sep 17, 2019. The ceremony will be part of the Eighth International BCI Conference, which is scheduled for Sep 16-20 in Graz, Austria. The deadline to submit projects is June 1, 2019. The 2019 jury is:\n\nMichael Tangermann, PhD (Chair)\nFreiburg University, Germany\n\nAbidemi Bolu Ajiboye, PhD\nCase Western Reserve University, USA\n\nRossella Spataro, MD, PhD\nUniversity of Palermo, Italy\n\nMichael Smith, PhD\nUniversity of California at Berkeley, USA\n\nKeiichi Kitajo, PhD\nRiken Institute of Brain Sciences, Japan\n\nSelina Wreissnegger, PhD\nGraz University of Technology, Austria\nSubmissions for the 2017 BCI Award were due May 15, 2017. The jury was:\n\nAs with previous years, the jury managed the selection of nominees and winners, and any jury members who also contributed a submission did not vote on that submission. The selection of nominees and winners was based on the same award criteria as previous years, described above. The Award Ceremony took place on September 20, 2017 as part of the 7th International BCI Conference 2017, which occurred from September 18 to 22, 2017. Prof. Gernot Muller-Putz introduced Dr. Guger, who briefly introduced the award to the attendees. The jury chair, Natalie Mrachacz-Kersting, announced the nominees, and Brendan Allison announced the winners.\n\n<br>BCI prosthetic hand to control phantom limb pain \nTakufumi Yanagisawa, Ryohei Fukuma, Ben Seymour, Koichi Hosomi, Haruhiko Kishima, Takeshi Shimizu1, Hiroshi Yokoi, Masayuki Hirata, Toshiki Yoshimine, Yukiyasu Kamitani, Youichi Saitoh\n\n<br>Implantable Communication Brain-Computer Interface for Home-Use in Locked-In Syndrome\nMariska J Vansteensel, Elmar GM Pels, Martin G. Bleichner, Mariana P. Branco, Timothy Denison, Zachary V. Freudenburg, Peter Gosselaar, Sacha Leinders, Thomas H. Ottens, Max A Van Den Boom, Peter C. Van Rijen, Erik J. Aarnoutse, Nick F Ramsey\n\n<br>A brain-spine interface to alleviate gait deficits after spinal cord injury\nTomislav Milekovic, Marco Capogrosso, David Borton, Fabien Wagner, Eduardo Martin Moraud, Jean-Baptiste Mignardot, Nicolas Buse, Jerome Gandar, Quentin Barraud, David Xing, Elodie Rey, Simone Duis, Yang Jianzhong, Wai Kin D. Ko, Qin Li, Peter Detemple, Tim Denison, Silvestro Micera, Erwan Bezard, Jocelyne Bloch, Grégoire Courtine\n\n<br>Brain Computer Interface for Communication with Patients in Completely Locked-in State\nUjwal Chaudhary, Aygul Rana, Azim Malekshahi, Stefano Silvoni, Niels Birbaumer\n\n<br>Individual word classification during imagined speech\nStephanie Martin, Peter Brunner, Iñaki Iturrate, José del R. Millán, Gerwin Schalk, Robert T. Knight & Brian N. Pasley\n\n<br>Restoration of finger movements in everyday life environments using a hybrid brain/neural hand exoskeleton\nSurjo R. Soekadar, Matthias Witkowski, Cristina Gómez, Eloy Opisso, Josep Medina, Mario Cortese, Marco Cempini, Maria Chiara Carrozza, Leonardo G. Cohen, Niels Birbaumer, Nicola Vitiello\nUniversity Hospital of Tübingen, Germany.\n\n<br>Rethinking BCI Paradigm and Machine Learning Algorithm as a Symbiosis: Zero Calibration, Guaranteed Convergence and High Decoding Performance\nDavid Hübner, Pieter-Jan Kindermans, Thibault Verhoeven, Klaus-Robert Müller, Michael Tangermann\n\n<br>Targeted up-conditioning of contralesional corticospinal pathways promotes motor recovery in poststroke patients with severe chronic hemiplegia\nTakasaki K, Liu F, Hiramato M, Okuyama K, Kawakami M, Mizuno K, Kasuga S, Noda T, Morimoto J, Fujiwara T, Ushiba J, Liu M\n\n<br>Gold Standard for epilepsy/tumor surgery coupled with deep learning offers independence to a promising functional mapping modality\nKorostenskaja, M., RaviPrakash, H., Bagci, U., Lee, K.H., Chen, P.C., Salinas, C., Baumgartner, J., Castillo, E.\n\n<br>High Performance BCI in Controlling an Avatar Using the Missing Hand Representation in Long Term Amputees\nOri Cohen, Dana Doron, Moshe Koppel, Rafael Malach, Doron Friedman\n\n<br>Online adaptive brain-computer interface with attention variations\nS. Aliakbaryhosseinabadi, E. N. Kamavuako, N. Jiang, D. Farina, N. Mrachacz-Kersting\n\n<br>Which BCI paradigm is better to induce agency or sense of control over movements?\nBirgit Nierula, Maria V. Sanchez-Vives\n\n\"First place:\"<br>\n\n\"Online adaptive brain-computer interface with attention variations\"<br>\n\nS. Aliakbaryhosseinabadi et al.<br>\n\"Second place:\"<br>\n\n\"Individual word classification during imagined speech\"<br>\n\nMartin et al.<br>\n\"Third place:\"<br>\n\n\"BCI prosthetic hand to control phantom limb pain\"<br>\n\nYanagisawa et al.<br>\n\n2018 Award<br>\n\nOne of the announcements during the 2017 Awards Ceremony stated that the next BCI Research Award ceremony would occur at the Seventh International BCI Meeting, which is scheduled for May 2018 in Pacific Grove, CA. The jury will again select twelve nominees from the submissions and then choose the three winners.\n\nSubmissions for the 2016 BCI Award were due Mar 1, 2016. The jury was:\n\n\nAs with previous Awards, the jury was responsible for reviewing submissions that presented new BCI research, nominating the best projects, and choosing the winners. For the first time in the history of the Award, the jury selected twelve nominees instead of ten. \n\n<br>A P300-based brain-computer interface for social attention rehabilitation in autism\n\nCarlos Amaral, João Andrade, Marco Simões, Susana Mouga, Bruno Direito, Miguel Castelo-Branco\n\n<br>Sixteen Commands and 40 Hz Carrier Frequency Code-modulated Visual Evoked Potential BCI\n\nDaiki Aminaka, Tomasz M. Rutkowski\n\nUniversity of Tsukuba, Japan.\n\n<br>Natural movement with concurrent brain-computer interface control induces persistent dissociation of neural activity\n\nLuke Bashford, JingWu3, Devapratim Sarma, Kelly Collins, Jeff Ojemann, Carsten Mehring\n\n<br>Intracortical Microstimulation as a Feedback Source for Brain-Computer Interface Users\n\nSharlene Flesher, John Downey, Jennifer Collinger, Stephen Foldes, Jeffrey Weiss, Elizabeth Tyler-Kabara, Sliman Bensmaia, Andrew Schwartz, Michael Boninger, Robert Gaunt\n\n<br>Minimally invasive endovascular stent-electrode array for high-fidelity, chronic recordings of cortical neural activity\n\nThomas J. Oxley, Nicholas L. Opie, Sam E. John, Gil S. Rind, Stephen M. Ronayne, Clive N. May, Terence J. O’Brien\n\nVascular Bionics Laboratory, Melbourne Brain Centre, Departments of Medicine and Neurology, The Royal Melbourne Hospital, The University of Melbourne, Parkville, Victoria, Australia.\n\n<br>Brain-Computer Interfaces based on fMRI for Volitional Control of Amygdala and Fusiform Face Area: Applications in Autism\n\nJaime A. Pereira, Ranganatha Sitaram, Pradyumna Sepulveda, Mohit Rana, Cristián Montalba, Cristián Tejos, Sergio Ruiz\n\n<br>Reclaiming the Free Will: A Real-Time Duel between a Human and a Brain-Computer Interface\n\nMatthias Schultze-Kraft, Daniel Birman, Marco Rusconi, Carsten Allefeld, Kai Görgen, Sven Dähne, Benjamin Blankertz, John-Dylan Haynes\n\nNeurotechnology Group, Technische Universität Berlin, Berlin, Germany.\n\n<br>An Implanted BCI for Real-Time Cortical Control of Functional Wrist and Finger Movements in a Human with Quadriplegia\n\nGaurav Sharma, Nick Annetta1, Dave Friedenberg, Marcie Bockbrader, Ammar Shaikhouni, W. Mysiw, Chad Bouton, Ali Rezai\n\n<br>Broad-band BCI: finding structure in noisy data\n\nJordy Thielen, Pieter Marsman, Colleen Monaghan, Jason Farquhar and Peter Desain\n\nDonders Center for Cognition, Radboud University Nijmegen\n\n<br>Vision-Augmented Rat Cyborg\n\nYueming Wang, Minlong Lu, Zhaohui Wu, Liwen Tian, Kedi Xu, Xiaoxiang Zheng, Gang Pan\n\n<br>Precise and reliable activation of cortex with micro-coils\n\nSeung Woo Lee and Shelley I. Fried\n\nBoston VA Healthcare System, Boston, Massachusetts, USA, Department of Neurosurgery, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA.\n\n<br>Towards Online Functional Brain Mapping and Monitoring during Awake Craniotomy Surgery using ECoG-based Brain-Surgeon Interface (BSI)\n\nL. Yao, T. Xie, Z. Wu, X. Sheng, D. Zhang, C. Lin, F. Negro, L. Chen, N. Mrachacz-Kersting, X. Zhu, D. Farina\n\nThe Gala Awards Ceremony occurred on June 2, 2016 in Merrill Hall at the Asilomar Conference Center as part of the Sixth International BCI Meeting, which was from May 30 - June 3, 2016 in Pacific Grove, CA. Dr. Kyosuke Kamada represented the jury, while Dr. Christoph Guger presented the awards and Dr. Brendan Allison emceed the ceremony. Most of the conference attendees were present to see the twelve nominees receive a certificate and stand onstage while the first, second, and third place winners were announced. The winners were:\n\n\"First place:\"\n\n<br>An Implanted BCI for Real-Time Cortical Control of Functional Wrist and Finger Movements in a Human with Quadriplegia\n\nGaurav Sharma, Nick Annetta1, Dave Friedenberg, Marcie Bockbrader, Ammar Shaikhouni, W. Mysiw, Chad Bouton, Ali Rezai\n\nThe following image shows one person representing most of the twelve nomimated projects on stage during the Award Ceremony. (The picture shows ten nominees, not twelve, because two were not available at the Ceremony.) On the far right of the image is Dr. Christoph Guger, and to his right is Dr. Kyosuke Kamada.\n\n\"Second place:\"\n\n<br>Intracortical Microstimulation as a Feedback Source for Brain-Computer Interface Users\n\nSharlene Flesher, John Downey, Jennifer Collinger, Stephen Foldes, Jeffrey Weiss, Elizabeth Tyler-Kabara, Sliman Bensmaia, Andrew Schwartz, Michael Boninger, Robert Gaunt\n\n\"Third place:\"\n\n<br>Minimally invasive endovascular stent-electrode array for high-fidelity, chronic recordings of cortical neural activity\n\nThomas J. Oxley, Nicholas L. Opie, Sam E. John, Gil S. Rind, Stephen M. Ronayne, Clive N. May, Terence J. O’Brien\n\nVascular Bionics Laboratory, Melbourne Brain Centre, Departments of Medicine and Neurology, The Royal Melbourne Hospital, The University of Melbourne, Parkville, Victoria, Australia.\n\nThe first, second, and third place winners received cash awards of $3000, $2000, and $1000, respectively. These three winners also received a special bread knife, and all nominees won other prizes. The 2017 BCI Research Award will accept submissions later, and this information will be posted on the BCI Research Award website. The 2017 BCI Research Award Ceremony will be part of the Seventh International BCI conference.\n\nThe deadline for the 2015 Award is 1 July 2015. The Annual BCI Research Award 2015 will be awarded by the Department of Biosciences and Informatics - Faculty of Science and Technology, Keio University, Japan at the Society for Neuroscience annual meeting, NEUROSCIENCE 2015, Oct 17-21, 2015 in Chicago, Illinois, United States.\n\nIn 2015, 60 top-level research projects were submitted from all over the world!\nThe jury, chaired by Junichi Ushiba, carefully scores 10 nominated projects, and then selects the winner for the Annual BCI Research Award 2014. \n\n<br>An ECoG-Based BCI on Auditory Attention to Natural Speech\n\n\n<br>Easy riders: Brain-Computer interfaces for enhancing driving experience\n\n\n<br>Sensorimotor Modulation Assessment and Brain-Computer Interface Training with Auditory feedback in Disorders of Consciousness\n\n\n<br>Brain-to-Text: Towards continuous speech as a paradigm for BCI\n\n\n<br>De-novo experience-based learning in rats interfaced with a \"cerebellar chip\"\n\n\n<br>Individual Finger Control of the Modular Prosthetic Limb using High-Density Electrocorticography in a Human Subject\n\n\n<br>Restoration for the volitional motor function via an artificial neural connection\n\n\n<br>Brain-Computer Interface Controlling Cyborg: A Functional Brain-to-Brain Interface between Human and Cockroach\n\n\n<br>A Brain-Computer-Interface to combat musculoskeletal pain\n\n\n<br>Increasing the useful lifespan of intracortical BCIs by decoding local field potentials as an alternative or compliment to spikes\n\n\n\"First place:\"\n<br>Individual Finger Control of the Modular Prosthetic Limb using High-Density Electrocorticography in a Human Subject\n\nGuy Hotson, David P McMullen, Matthew S. Fifer, Matthew S. Johannes, Kapil D. Katyal, Matthew P. Para, Robert Armiger, William S. Anderson, Nitish V. Thakor, Brock A. Wester, Nathan E. Crone (Department of Electrical and Computer Engineering, Johns Hopkins University, US,Department of Neurosurgery, Johns Hopkins University, US, Department of Biomedical Engineering, Johns Hopkins University, US, Applied Neuroscience, JHU Applied Physics Laboratory, US, Department of Neurology, Johns Hopkins University, US)\n\n\"Second place:\"\n\n<br>De-novo experience-based learning in rats interfaced with a \"cerebellar chip\"\n\nRoni Hogri, Simeon A. Bamford, Aryeh H. Taub (Psychobiology Research Unit, Tel Aviv University, IL,Complex Systems Modeling Group, Istituto Superiore di Sanità, IT, Department of Neurophysiology, Medical University of Vienna, AT,Inilabs Gmbh, CH,Department of Neurobiology, Wiezmann Institute of Science, IL)\n\n\"Third place:\"\n\n<br>Restoration for the volitional motor function via an artificial neural connection\n\nKenji Kato, Masahiro Sawada, Tadashi Isa, Yukio Nishimura (National Institute for Physiological Sciences, Aichi, JP)\n\nThe 2015 jury was:\n\nJunichi Ushiba (chair of the jury 2015)\n\nMasayuki Hirata\n\nNuri Firat Ince\n\nZachary Freudenburg\n\nJosé del R. Millán\n\nSydney Cash\n\nTomasz M. Rutkowski\n\nThe deadline for the 2014 Award was 1 July 2014, but was extended to 10 July 2014. The Annual BCI Research Award 2014 will be awarded by the Institute of Knowledge Discovery, Graz University of Technology, Austria at the 6th International Brain-Computer Interface Conference 2014, September 16–19, 2014 in Graz, Austria. In 2014, 68 top-level research projects were submitted from all over the world! The jury, chaired by Gernot R. Müller-Putz, carefully scores 10 nominated projects, and then selects the winner for the Annual BCI Research Award 2014. \n\n<br>Towards an Auditory Attention BCI\n\n\n<br>Neurofeedback training by motor imagery based-BCI improves neurocognitive areas in elderly people\n\n\n<br>Airborne Ultrasonic Tactile Display BCI\n\n\n<br>Heterogeneous BCI-triggered functional electrical stimulation intervention for the upper-limb rehabilitation of stroke patients\n\n<br>Demonstration of a Semi-Autonomous Hybrid Brain-Machine Interface using Human Intracranial EEG, Eye Tracking, and Computer Vision to Control a Robotic Upper Limb Prosthetic\n\n\n<br>Unsupervised decoding the onset and type of visual stimuli using electrocorticographic (ECoG) signals in humans\n\n\n<br>The changing Brain: Bidirectional learning between algorithm and user\n\n<br>Rapid control and feedback rates in the sensorimotor pathway enhance neuroprosthetic control\n\n\n<br>Retraining the Brain to Directly Control Muscle Stimulators in an Upper-Limb Neuroprosthesis\n\n\n<br>Real-Time Bedside Cortical Language Mapping during Spontaneous Conversation with Children\n\n\n\"First place:\"\n\n<br>Airborne Ultrasonic Tactile Display BCI\n\nK. Hamada, H. Mori, H. Shinoda, T.M. Rutkowski (The University of Tokyo, JP, Life Science Center of TARA, University of Tsukuba, JP, RIKEN Brain Science Institute, JP)\n\n\"Second place:\"\n\n<br>Heterogeneous BCI-triggered functional electrical stimulation intervention for the upper-limb rehabilitation of stroke patients\n\nJ. Ibáñez, J. I. Serrano, M. D. del Castillo, E. Monge, F. Molina, F.M. Rivas, J.L. Pons (Bioengineering Group of the Spanish National Research Council (CSIC), LAMBECOM group, Health Sciences Faculty, Universidad Rey Juan Carlos, Alcorcón, ES)\n\n\"Third place:\"\n\n<br>The changing Brain: Bidirectional learning between algorithm and user\n\nN. Mrachacz-Kersting, N. Jiang, S. Aliakbaryhosseinabadi, R. Xu, L. Petrini, R. Lontis, M. Jochumsen, K. Dremstrup, D. Farina (Sensory-Motor Interaction, Department of Health Science and Technology, DK, Dept. Neurorehabilitation Engineering Bernstein Center for Computational Neuroscience University Medical Center, DE)\n\nThe 2014 jury consisted of:\n\nGernot R. Müller-Putz,\n\nDeniz Erdogmus,\nPeter Brunner,\nTomasz M. Rutkowski,\nMikhail A. Lebedev,\n\nThe original deadline for the 2013 Award was 30 March 2013, but was extended to 14 April 2013. The Annual BCI Research Award 2013 will be awarded by the Wadsworth Center, Albany, United States at the BCI Meeting 2013 in June 3–7, 2013 in Asilomar, California, USA.\n\n169 projects were submitted for the 2013 Award. Like the preceding years, the submissions came from groups all over the world, and reflected a wide range of different types of BCIs. The jury, chaired by Theresa Vaughan, carefully scores 10 nominated projects, and then selects the winner for the Annual BCI Research Award 2013. \n\n<br>Give me a sign: The possibilities of using hand gestures as control signal for implanted brain computer interfaces.\n\n\n<br>An Ipsilateral, Contralesional BCI in Chronic Stroke Patients.\n\n\n<br>A learning-based approach to artificial sensory feedback: intracortical microstimulation replaces and augments vision.\n\n\n<br>Motor recovery of chronic writer’s cramp by brain-computer interface rehabilitation: A pilot study.\n\n\n<br>Cognitive signals for brain-machine interfaces: an alternative paradigm to neuroprosthetics control.\n\n\n<br>An Accurate, Versatile, and Robust Brain Switch for Neurorehabilitation.\n\n\n<br>:Ear-EEG: Continuous Brain Monitoring.\n\n\n<br>A hybrid brain computer interface for adaptive workload estimation in rehabilitation robotics.\n\n\n<br>A concurrent brain-machine interface for sequential motor function.\n\n\n<br>Exploring an fMRI-guided minimally invasive subdural N200 speller.\n\n\n<br>A learning-based approach to artificial sensory feedback: intracortical microstimulation replaces and augments vision.\n\nM. C. Dadarlat, J. E. O’Doherty, P. N. Sabes (Department of Physiology, Center for Integrative Neuroscience, San Francisco, CA, US, UC Berkeley-UCSF Bioengineering Graduate Program, University of California, San Francisco, CA, US)\nThe 2013 jury consists of:\n\nTheresa Vaughan, Dr.,\n\nDouglas Weber, Dr.,\n\nAdam Hebb, Dr.,\n\nDonatella Mattia, Dr.,\n\nAndrzej Cichocki, Dr.,\n\nAdam Wilson, Dr.,\n\nThe original deadline for the 2012 Award was 15 July 2012, but was extended to 30 July 2012. The 2012 award was presented at a dinner ceremony at the 2012 conference of the Society for Neuroscience, which was 13-17 Oct in New Orleans, Louisiana. The annual SfN conference is a well-established venue for presenting BCI research.\n\n68 projects were submitted for the 2012 Award. Like the two preceding years, the submissions came from groups all over the world, and reflected a wide range of different types of BCIs. Relative to previous years, there was a stronger emphasis on BCIs with direct medical applications (as opposed to pure research, healthy user applications, etc.) Most of the nominated projects were aimed at helping groups with specific medical needs, such as persons with stroke, tetraplegia, epilepsy, paralysis or visual deficits. \n\nA.B. Ajiboye, D. Bacher, L. Barefoot, E. Berhanu, M.J. Black, D. Blana, S.S. Cash, K. Centrella, E.K. Chadwick, A. Cornwell, J. P. Donoghue, E. Eskandar, J. M. Feldman, G. M. Friehs, E. Gallivan, B. Jarosiewicz, L. R. Hochberg, M. Homer, P.-S. Kim, B. King, R. F. Kirsch, J. Liu, W. Q. Malik, N. Y. Masse, J. A. Perge, D. M. Rosler, A. Sarma, N. Schmansky, J. D. Simeral, S. Stavisky, B. Travers, K. Tringale, W. Truccolo and S. Haddadin, J. Vogel and P. van der Smagt \n\nSchool of Engineering, Brown University\n\nInstitute of Robotics and Mechatronics, German Aerospace Center / DLR\n\nInstitute of Informatics, Technische Universität München\n\n<br>Intracortical control of assistive devices by individuals with tetraplegia.\n\n\nUniversidade de Coimbra, Portugal\n\n<br>Brainatic: A system for real-time epileptic seizure prediction.\n\n\nINRIA, Rennes, France\n\n<br>Combining Brain-Computer Interfaces and Haptics: Detecting Mental Workload to Adapt Haptic Assistance.\n\n\nSecond Sight Medical Products, Sylmar, CA, USA\n\n<br>Reading visual Braille with a retinal prosthesis.\n\n\nImperial College London, United Kingdom\n\n<br>Ear-EEG: User-Centered, Wearable & 24/7 BCI.\n\n\nAalborg University, Denmark\n\n<br>A novel brain-computer interface for chronic stroke patients.\n\n\nEberhard Karls University, Tübingen, Germany\n\n<br>Brain connectivity and semantic priming enhancement using Brain Computer Interfaces based on real-time fMRI Neurofeedback.\n\n\nEberhard Karls University, Tübingen, Germany\n\n<br>Improving Efficacy of Ipsilesional Brain-Computer Interface Training in Neurorehabilitation of Chronic Stroke.\n\n\nKeio University, Japan\n\n<br>Online estimate of event-related desynchronization by hand motor imagery is associated with corticospinal excitability-physiological evidence for brain-computer interface based neurorehabilitation.\n\n\nOsaka University Medical School, Japan\n\n<br>Electrocorticographic control of prosthetic hands in paralyzed patients.\n\nSurjo R. Soekadar, Niels Birbaumer \n\nApplied Neurotechnology Lab, University Hospital Tübingen and \n\nInstitute of Medical Psychology and Behavioral Neurobiology, Eberhard Karls University, Tübingen, Germany\n\n<br>Improving Efficacy of Ipsilesional Brain-Computer Inteface Training in Neurorehabilitation of Chronic Stroke\n\nDr. Eric Leuthardt said that \"It is a great pleasure to congratulate the Soekadar and Birbaumer team on their project entitled \"Improving Efficacy of Ipsilesional Brain-Computer Interface Training in Neurorehabilitation of Chronic Stroke.\" Their work is highlighting the important movement of neuroprosthetics towards stroke. There is a fundamental need to use BCI approaches to address this clinical area of motor disability that numbers in the hundreds of thousands per year and stands to increase substantially as the world population ages. BCI for stroke will likely be the next chapter for engineered restorative strategies that could be paradigm shifting in this widespread form of motor impairment.\"\n\nThe 2012 jury again included some of the top figures in BCI research, with a stronger emphasis on medical doctors than previous years. The 2012 jury also included the winner of the 2011 BCI Award, just as the 2012 jury included the winnerof the 2010 BCI Award. For the first time, the jury also included scientists who had been jurors in previous years. Specifically, the jury included Profs. Gerwin Schalk and Gert Pfurtscheller, who were the chairmen of the jury in 2010 and 2011, respectively. The 2012 was chaired by Eric Leuthardt, M.D., and also consisted of:\n\nGert Pfurtscheller, Ph.D.,\n\nLeigh Hochberg, M.D, Ph.D.,\n\nGerwin Schalk, Ph.D.,\n\nMoritz Grosse-Wentrup, Ph.D.,\n\nJunichi Ushiba, Ph.D.\n\nSpringer Publishing will publish a book about the 2012 BCI Award. Like the prior books about awards in earlier years, the book will include an introduction, discussion, and ten chapters from the ten nominees. These ten chapters will each describe the work submitted and updated information about more recent progress. The book will be edited by Drs. Guger, Allison, and Edlinger.\n\nThe 2011 award was presented at a dinner ceremony at the Hotel Weitzer in Graz, Austria. The ceremony was scheduled around 5th International Brain-Computer Interface Conference, which was held in Graz from 22-24 Sept. 2011. The awarding institute was the Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, which also hosted the conference. Prof. Gert Pfurtscheller, the Chairman of the Jury, presented the award, and the ceremony was emceed by Dr. Brendan Allison. In addition to Prof. Pfurtscheller, the 2011 jury consisted of:\n\nRobert Leeb, Ph.D.,\n\nCuntai Guan, Ph.D.,\n\nTheresa Vaughan,\n\nMichael Tangermann, Ph.D.,\n\nJane Huggins, Ph.D.\n\nThe ceremony featured over 100 attendees from the BCI community, and featured a Distinguished Special Guest, Prof. Jacques Vidal. Prof. Vidal is the inventor of BCIs (Vidal, 1973, 1977), as widely noted in review articles and book chapters (Wolpaw et al., 2002; Allison et al., 2007, 2012; Wolpaw and Wolpaw, 2012). \n64 projects were submitted for the 2011 award. The ten projects that were nominated showed the breadth of BCI research. The projects reflected a range of different sensor types, including BCIs based on single cell recordings, invasive recordings with implanted electrodes on the cortex, and non-invasive scalp recordings. A range of BCI applications were also nominated, including BCIs for speech recognition, stroke rehabilitation, and robotic device control. The projects that were nominated are presented below, in alphabetical order by first author, along with the author affiliation(s); \n\n<br>Exploring the cortical dynamics of learning by leveraging BCI paradigms.\n\nUniversity of Washington, USA\n\n<br>An auditory output brain-computer interface for speech communication.\n\nBoston University, USA\n\n<br>Seven degree of freedom cortical control of a robotic arm.\n\nCarnegie Mellon University, University of Pittsburgh, USA\n\n<br>Utilizing high gamma (HG) band power changes as control signal for non-invasive BCI.\n\nUniversity of Washington, USA\n\n<br>User-appropriate and robust control strategies to enhance brain computer interface performance and usability.\n\nUniversity of Graz, Austria\n\n<br>What are the neuro-physiological causes of performance variations in brain-computer interfacing?\n\nMax Planck Institute for Intelligent Systems, Germany\n\n<br>Using the electrocorticographic speech network to control a brain-computer interface in humans\n\nWashington University in St. Louis, USA\n\n<br>Towards communication in the completely locked-in state: neuroelectric semantic conditioning BCI.\n\nUniversity of Tübingen, IRCCS, International Max Planck Research School, Germany\n\n<br>An affective BCI using multiple ERP components associated to facial emotion processing.\n\n\nRIKEN, Japan\n\n<br>What's your next move? Detecting movement intention for stroke rehabilitation.\n\n\nETH Zürich, Switzerland\n\n<br>What are the Neuro-Physiological Causes of Performance Variations in Brain-Computer Interfacing?\n\nMoritz Grosse-Wentrup, Bernhard Schölkopf \n\nMax Planck Institute for Intelligent Systems, Tübingen, Germany\n\ng.tec has announced that it is developing a book through Springer Publishing based on the 2011 BCI Research Award competition. This book will be similar to the book based on the 2010 Award, which is described below. All ten of the nominees have written chapters that summarize the work they submitted for the 2011 Award and their follow-up efforts. Two other chapters, an introduction and conclusion, include analyses and summaries of the ten projects that were nominated as well as all submitted projects. The chapters have been peer-reviewed, then revised by the authors, and are soon going to press. The book's editors are Drs. Christoph Guger, Brendan Allison, and Günter Edlinger.\n\nThe 2010 award was presented at a dinner ceremony with over 100 attendees from the BCI community on the Asilomar Conference grounds near Monterey, California. The ceremony was scheduled around the BCI Meeting 2010, which was held on the same grounds from 31 May until 4 June 2010. The awarding institute was the Wadsworth Center, represented by Prof. Gerwin Schalk. The 2010 jury also consisted of:\n\nEric Sellers, Ph.D., \n\nDean Krusienski, Ph.D.,\n\nKlaus-Robert Müller, Ph.D.,\n\nBo Hong, Ph.D.,\n\nBenjamin Blankertz, Ph.D.\n\n60 projects were submitted for the 2010 Award. These projects are presented in alphabetical order by the first author, along with the affiliation(s) of the authors.\n\n<br>A high speed word spelling BCI system based on code modulated visual evoked potentials\n\n\nTsinghua University, China\n\n<br>Operant conditioning to identify independent, volitionally-controllable patterns of neural activity\n\n\nCarnegie Mellon University, USA\n\n<br>Motor imagery-based Brain-Computer Interface robotic rehabilitation for stroke\n\n\nA*STAR, Singapore\n\n<br>An active auditory BCI for intention expression in locked-in\n\n\nTsinghua University, China\n\n<br>Neurorehabilitation for Chronic-Phase Stroke using a Brain-Machine Interface\n\n\nKeio University, Japan\n\n<br>Brain-actuated Google search by using motion onset VEP\n\n\nTsinghua University, China\n\n<br>Brain Painting - \"Paint your way out\"\n\n\nUniversität Tübingen, Germany\n\n<br>Thought Recognition with Semantic Output Codes\n\n\nCarnegie Mellon University, USA\n\n<br>Predictive Spelling with a P300-based BCI: Increasing Communication Rate\n\n\nEast Tennessee State University, USA\n\n<br>Innovations in P300-based BCI Stimulus Presentation Methods\n\n\nUniversity BCI Lab, Canada\n\nThe ten nominated projects have been published in a 2011 book, edited by Reza Fazel.\n\n<br>Motor imagery-based Brain-Computer Interface robotic rehabilitation for stroke\n\nCuntai Guan, Kai Keng Ang, Karen Sui Geok Chua, Beng Ti Ang \n\nA*STAR, Singapore\n\nIn addition to the usual awards, the winner also received an autographed copy of the book “A Practical guide to Brain-Computer Interfacing with BCI2000”.\n\nThere are a few other awards for BCI research. For example, the Berlin BCI group has hosted several Data Analysis Competitions. These competitions provide data from different types of BCIs (such as P300, ERD, or SSVEP), and competitors attempt to develop data analysis algorithms that can most accurately classify new data. The recently announced HCI Challenge instead focuses on improving the human-computer interaction within BCIs, such as through more natural and friendly interfaces. The X-Prize Foundation lists X-Prizes for BCI and Enduring Brain Computer Communication as “Concepts Under Consideration\". The Gao group at Tsinghua University in Beijing coordinated an online BCI competition at a conference that they hosted in 2010, and hosted a second competition in 2012. The Annual BCI Research Award is the only general award open to any facet of BCI research.\n"}
{"id": "1531329", "url": "https://en.wikipedia.org/wiki?curid=1531329", "title": "Aphorismus", "text": "Aphorismus\n\nAphorismus (from the , \"aphorismós\", \"a marking off\", also \"rejection, banishment\") is a figure of speech that calls into question if a word is properly used (\"How can you call yourself a man?\"). It often appears in the form of a rhetorical question which is meant to imply a difference between the present thing being discussed and the general notion of the subject.\n\n"}
{"id": "33353300", "url": "https://en.wikipedia.org/wiki?curid=33353300", "title": "Arseniosiderite", "text": "Arseniosiderite\n\nArseniosiderite is a rare arsenate mineral formed by the oxidation of other arsenic-containing minerals, such as scorodite or arsenopyrite. It occurs in association with beudantite, carminite, dussertite, pharmacolite, pitticite, adamite and erythrite. The name arseniosiderite reflects two major elements of the mineral, arsenic and iron (Greek \"sideros\" means iron).\n"}
{"id": "8390635", "url": "https://en.wikipedia.org/wiki?curid=8390635", "title": "Association for Women in Science", "text": "Association for Women in Science\n\nThe Association for Women in Science was founded in 1971 at the annual Federation of American Societies for Experimental Biology (FASEB) meeting. The organization aims to combat job discrimination, lower pay, and professional isolation. The main issue areas that the modern Association addresses are fair compensation, work-life integration, attrition, and professional development. \n\nAWIS was founded in 1971 at the annual meeting of the Federation of American Societies for Experimental Biology (FASEB), after a series of champagne brunches organized by an informal women's caucus. After establishing an executive director and an office in Washington, DC, chapters were organized across the country for individual members. Its founding co-presidents were Neena Schwartz and Judith Pool. Along with other women in science associations, an early AWIS action involved initiating a class action lawsuit against the National Institutes of Health in response to poor representation on NIH grant review committees. The lawsuit was dropped after representatives of the groups, including Schwartz, met with Robert Marsten, then head of the NIH, who solicited recommendations and committed to appointing more women. Early projects include the creation of the AWIS Educational Foundation (now known as the Educational Awards) to receive donations and award fellowships. In 1997, AWIS won the Presidents Mentoring Award. \n\nAs of 2015, the AWIS executive director was Janet Bandows Koster and the president of the board was Ann Lee-Karlon. \n\nAWIS activities include public advocacy, news and media distribution, and educational programs such as mentorship programs and scholarship awards. AWIS publishes a variety of materials to inform women about science programs and women's issues, including the quarterly AWIS Magazine and the AWIS in Action! Advocacy and Public Policy Newsletter. \n\nRepresenting the 7.4 million women working in STEM fields, AWIS members are professionals and students in a variety of STEM fields. Over 50% of AWIS members have doctorates in their respective fields.\n\nAWIS has 49 chapters in the United States, which support local networking and mentorship, as well as outreach to young women considering careers in STEM.\n\n\n\n\n"}
{"id": "36422581", "url": "https://en.wikipedia.org/wiki?curid=36422581", "title": "Bend Glacier", "text": "Bend Glacier\n\nBend Glacier is in the U.S. state of Oregon. The glacier is situated in the Cascade Range at an elevation around . Bend Glacier is just to the north of Broken Top, an extinct stratovolcano.\n\n"}
{"id": "7723926", "url": "https://en.wikipedia.org/wiki?curid=7723926", "title": "Biseriate", "text": "Biseriate\n\nBiseriate is a botanical term applied to both plantae and fungi, meaning 'arranged in two rows'. \n\nThe term can refer to any number of structures found within these kingdoms, from arrangement of leaves to the placement of spores.\n\nIt becomes useful in taxonomy for placing a species within a certain genus, family, or even order, based upon morphology, when making an initial choice or when DNA evidence is inconclusive.\n\n"}
{"id": "24038372", "url": "https://en.wikipedia.org/wiki?curid=24038372", "title": "Bismuth phosphate process", "text": "Bismuth phosphate process\n\nThe bismuth-phosphate process was used to extract plutonium from irradiated uranium taken from nuclear reactors. It was developed during World War II by Stanley G. Thompson, a chemist working for the Manhattan Project at the University of California, Berkeley. This process was used to produce plutonium at the Hanford Site. Plutonium was used in the atomic bomb that was used in the atomic bombing of Nagasaki in August 1945. The process was superseded in the 1950s by the REDOX and PUREX processes.\n\nDuring World War II, the Allied Manhattan Project attempted to develop the first atomic bombs. One method was to make a bomb using plutonium, which was first produced by deuteron bombardment of uranium in the cyclotron at the Berkeley Radiation Laboratory at the University of California, Berkeley. It was isolated on 14 December 1940 and chemically identified on 23 February 1941, by Glenn T. Seaborg, Edwin McMillan, Joseph W. Kennedy and Arthur Wahl. It was thought that plutonium-239 would be fissile like uranium-235 and suitable for use in an atomic bomb.\n\nPlutonium could be produced through the irradiation of uranium-238 in a nuclear reactor, although no one had yet built one. This was not the Manhattan Project's chemists' problem; theirs was to develop a large-scale process for separating fission products, some of which were dangerously radioactive; uranium, the chemistry of which little was known; and plutonium, the chemistry of which almost nothing at all was known and which at first was only available in microscopic quantities.\n\nFour methods of separation were pursued. Seaborg performed the first successful separation of a weighable quantity of plutonium in August 1942, using a process involving lanthanum fluoride. Isadore Perlman and William J. Knox, Jr., looked into peroxide separation because most elements form soluble peroxides in neutral or acid solution. They soon discovered that plutonium was an exception. After a good deal of experimentation, they found that they could precipitate it by adding hydrogen peroxide to a dilute uranyl nitrate solution. They were then able to get the process to work but it produced tons of precipitate, where the lanthanum fluoride process would produce kilograms.\n\nJohn E. Willard tried an alternative approach, based on the fact that some silicates absorbed plutonium more readily than other elements; this was found to work but with low efficiency. Theodore T. Magel and Daniel K. Koshland, Jr., researched a solvent-extraction processes and Harrison Brown and Orville F. Hill experimented with separation using volatility reactions, based on how uranium could be readily volatilized by fluorine. They and other chemists at the Manhattan Project's Radiation Laboratory at the University of California, Metallurgical Laboratory at the University of Chicago and Ames Laboratory at Iowa State College, explored plutonium chemistry. A crucial discovery was that plutonium had two oxidation states, a tetravalent (+4) state and hexavalent (+6) state. with different chemical properties.\n\nThe lanthanum fluoride process became the preferred method for use in the Manhattan Project's plutonium separation semiworks at the Clinton Engineer Works and the production facilities at the Hanford Site but further work with the process revealed difficulties. It required large amounts of hydrogen fluoride, which corroded the equipment and Charles M. Cooper from DuPont, who would be responsible for the design and construction of the facilities, began experiencing problems with stabilizing the plutonium in its hexavalent state in the fluoride solution. There were also difficulties with recovering the precipitate through filtration or centrifugation.\n\nWhile the chemical engineers worked on these problems, Seaborg asked Stanley G. Thompson, a colleague at Berkeley, to have a look at the possibility of a phosphate process. It was known that the phosphates of many heavy metals were insoluble in an acid solutions. Thompson tried phosphates of thorium, uranium, cerium, niobium and zirconium without success. He did not expect bismuth phosphate () to work any better but when he tried it on 19 December 1942, he was surprised to find that it carried 98 percent of the plutonium in solution. Bismuth phosphate was similar in its crystalline structure to plutonium phosphate and this became known as the bismuth phosphate process. Cooper and Burris B. Cunningham were able to replicate Thompson's results and the bismuth phosphate process was adopted as a fallback in case lanthanum fluoride could not be made to work. The processes were similar and the equipment used for lanthanum fluoride could be adapted for use with Thompson's bismuth phosphate process. In May 1943, the DuPont engineers decided to adopt the bismuth phosphate process for use in the Clinton semiworks and the Hanford production site.\n\nThe bismuth phosphate process involved taking the irradiated uranium fuel slugs and removing their aluminium cladding. Because there were highly radioactive fission products inside, this had to be done remotely behind a thick concrete barrier. This was done in the \"Canyons\" (B and T buildings) at Hanford. The slugs were dumped into boiling sodium hydroxide to which sodium nitrate was added. With the aluminium jackets removed, a dissolver was charged with about three tons of unclad slugs. Nitric acid was added to dissolve about one ton at a time.\n\nThe second step was to separate the plutonium from the uranium and the fission products. Bismuth nitrate and phosphoric acid were added, producing bismuth phosphate, which was precipitated carrying the plutonium with it. This was very similar to the lanthanum fluoride process, in which lanthanum fluoride was used as the carrier. The precipitate was removed from the solution with a centrifuge and the liquid discharged as waste. Getting rid of the fission products reduced the gamma radiation by 90 percent. The precipitate was a plutonium-containing cake which was placed in another tank and dissolved in nitric acid. Sodium bismuthate or potassium permanganate was added to oxidize the plutonium. Plutonium would be carried by the bismuth phosphate in the tetravalent state but not in the hexavalent state. The bismuth phosphate would then be precipitated as a by product, leaving the plutonium behind in solution.\n\nThis step was then repeated in the third step. The plutonium was reduced again by adding ferrous ammonium sulfate. Bismuth nitrate and phosphoric acid were added and bismuth phosphate precipitated. It was dissolved in nitric acid and the bismuth phosphate was precipitated. This step resulted in reducing the gamma radiation by four more orders of magnitude, so the plutonium-bearing solution now had 100,000-th of the original gamma radiation. The plutonium solution was transferred from the 224 buildings to the 221 buildings, through underground pipes. In the fourth step, phosphoric acid was added and the bismuth phosphate precipitated and removed; potassium permanganate was added to oxidize the plutonium.\n\nIn the \"crossover\" step, the lanthanum fluoride process was used. Lanthanum salts and hydrogen fluoride were added again and lanthanum fluoride was precipitated, while hexavalent plutonium was left in solution. This removed lanthanides like cerium, strontium and lanthanum, that bismuth phosphate could not. The plutonium was again reduced with oxalic acid and the lanthanum fluoride process was repeated. This time potassium hydroxide was added to metathesize the solution. Liquid was removed with a centrifuge and the solid dissolved in nitric acid to form plutonium nitrate. At this point, a batch sent would have been concentrated to .\n\nThe final step was carried out at the 231-Z building, where hydrogen peroxide, sulfates and ammonium nitrate were added to the solution and the hexavalent plutonium was precipitated as plutonium peroxide. This was dissolved in nitric acid and put into shipping cans, which were boiled in hot air to produce a plutonium nitrate paste. Each can weighed about 1 kg and was shipped to the Los Alamos Laboratory. Shipments were made in a truck carrying twenty cans and the first arrived at Los Alamos on 2 February 1945. The plutonium was used in the Fat Man bomb design tested in the Trinity nuclear test on 16 July 1945, and in the bombing of Nagasaki on 9 August 1945.\n\nIn 1947, experiments began at Hanford on a new REDOX process, which was more efficient. Construction of a new REDOX plant commenced in 1949 and operations began in January 1952, the B plant closing that year. Improvements to the T plant resulted in a 30 percent increase in productivity and improvements were made to the B plant. There were plans to reactivate the B plant but the new PUREX plant that opened in January 1956 was so efficient that the T plant was closed in March 1956 and plans to reactivate the B plant were abandoned. By 1960, the PUREX plant's output had surpassed the combined output of the B and T plants and the REDOX plant.\n\n"}
{"id": "29323347", "url": "https://en.wikipedia.org/wiki?curid=29323347", "title": "Bledisloe Glacier", "text": "Bledisloe Glacier\n\nBledisloe Glacier () is a glacier flowing north west between All-Blacks Nunataks and Wallabies Nunataks, west of the Churchill Mountains. It was named in association with the adjacent All-Blacks and Wallabies Nunataks, and specifically named after the Bledisloe Cup, which is contested between the New Zealand and Australian rugby union teams, the All-Blacks and the Wallabies.\n"}
{"id": "1157821", "url": "https://en.wikipedia.org/wiki?curid=1157821", "title": "Burkhard Heim", "text": "Burkhard Heim\n\nBurkhard Heim (; February 9, 1925 – January 14, 2001) was a German theoretical physicist. He devoted a large portion of his life to the pursuit of his unified field theory, Heim theory. One of his childhood ambitions was to develop a method of space travel, which contributed to his motivation to find such a theory.\n\nDuring World War II, Heim was conscripted into the air force. However, a previous essay about explosives led to his working briefly in a chemical laboratory as an explosives technician, instead. An explosion in the laboratory caused by the mishandling of unstable compounds left him with debilitating handicaps. The accident left him without hands and mostly deaf and blind when he was 19, forcing him to use Krukenberg hands. Illobrand von Ludwiger claims this to be a terrorist assassination attempt, for which Heim saved the assassins life by \"forgiving him\". Neither name nor motivation of the claimed assassin nor details of the \"forgiving\" and how this saved his life are given.\n\nHis behavior subsequently became progressively eccentric and reclusive. Eventually, he retreated into almost total seclusion, concentrating on developing and refining his theory of everything.\n\nA large proportion of the 76 years of Heim's life was spent on theoretical physics and the formulation of his Heim theory.\n\nIn 1943 Heim met Heisenberg, who was involved in German atom bomb research at that time, and told him of his plan to use chemical implosion to facilitate an atomic explosion. This design was based on his idea he developed for a 'clean' hydrogen bomb when he was 18. Heisenberg was impressed by Heim's knowledge, but thought the approach would be impractical.\n\nAt that point Heim had to do military service in the German air force. He sent a paper on explosives to the Chemical-Technical 'Reichsanstalt' in Berlin, whereupon he was summoned to work there on the development of the proposed new explosives. It was here that he met with the accident that handicapped him for life.\n\nIn 1946, Heim registered at the University of Göttingen to study physics. He fulfilled his academic degree requirements with the help of companions. Afterwards, he continued to study a variety of topics including medicine, psychology, electronics, history and theology.\n\nIn 1952, during the third congressional session of the International Astronautical Federation (IAF) in Stuttgart, Germany, Burkhard Heim presented his theory for interplanetary propulsion under the title of “Die dynamische Kontrabarie als Lösung des astronautischen Problems” (The Dynamic Kontrabarie as solution of the Astronautical Problem). It was the first time the idea of gravitational, electromagnetic, weak, and strong forces were treated as distortions of their proper Euclidean metrics in a higher-dimensional space. A brief description of Heim’s lecture was recorded in the proceedings of the Society for Space Research.\n\nIn 1954 he began to study under Carl Friedrich von Weizsäcker in Göttingen. He wrote his diploma thesis on physical processes in the Crab Nebula Supernova. After this, he began to work at the Max Planck Institute for Astrophysics in Göttingen. However, he soon found it extremely difficult to work in a team due to his handicaps. Von Weizsäcker also did not want to burden Heim with the development of a unified field theory. However, this was essentially his primary interest.\n\nAlso, his second IAF presentation was given in 1954, Innsbruck, Austria, during its fifth congress. News about his presentations may have been relayed to the United States by the American representatives, Frederick C. Durant III and Andrew G. Haley, who were serving as President and Vice President, respectively, of the IAF during its fifth congress.\n\nDuring the 1955 holiday week of Thanksgiving Day, the \"New York Herald Tribune\", and \"The Miami Herald\" carried announcements about the completion of contractual arrangements between Burkhard Heim and Glenn L. Martin Company. Heim was to assist them with their gravity control propulsion project. The news about Heim's contract was among several revelations that had been published during the period of intensified United States gravity control propulsion research (1955 - 1974).\n\nIn 1956, Heim completed a twenty-seven paged progress report. Copies of it and its English translation were archived at the Gravity Research Foundation. It had summarized his philosophy (syntrometry) and his theory (Principle of Dynamic Contrabarie) for coupling general relativity with quantum dynamics for propulsion applications. Sample calculations for an expedition from the surface of the Earth to the surface of the planet Mars appeared at the end of Heim’s progress report. His six-dimensional meso-field-equations required only 285 kg of fuel to be expended to propel a manned vehicle, with the empty weight of fifty tons, on a round trip lasting only 336 hours. Those calculations allowed 111 hours for interplanetary travel, 100 hours to explore Mars, and fourteen hours to perform engine overhaul and launch preparations. His endothermic process required a maximum cooling rate of 1.2 GW.\n\nIn November 1957, Heim delivered a lecture about his propulsion theory to the Deutschen Gesellschaft für Raketentechnik und Raumfahrt (German Society for Rocket Technology and Space Travel), Frankfurt. Subsequently, Wernher von Braun sought his comments on various aerospace projects. According to von Ludwiger, an audiotape of Heim’s presentation had been prepared for shipment to America.\n\nIn 1959, Heim completed his first publication in the obscure German journal \"Zeitschrift für Flugkörper\" (\"Magazine for Missiles\"). It carried a series of four articles about his theory. The series of papers carried claims and sample calculations that were similar to his 1956 progress report at the Gravity Research Foundation. Heim discussed \"the principle of the dynamic Kontrabarie\" in which he examined how a field drive would be more effective than the best chemical drive for rockets. These papers remained ambiguous on the fundamental concepts underlying his theory of the field drive, likely due to the necessity to complete the calculations on the extra fields of his field theory. These calculations were not performed until a few years later.\n\nHeim was very mindful of keeping his work from others and worried about plagiarism. In particular, he saw some colleagues as possible plagiarists. One other reason for his distrust of others was due to a colleague who embezzled donations from a society he founded in 1959. (The \"Institut für Kraftfeldphysik e.V.\" was intended to develop test models of his propulsion concepts.)\n\nHeim stopped work on the propulsion aspect of his theory in 1959. Neither failures nor flaws had made Heim discontinue his propulsion research – it was the unbridled interest of unsavory firms. The preface by Helmut Goeckel to Heim’s first paper in the series of four articles published by \"Magazine for Missiles\" indicated various aerospace and ordnance companies had made several attempts to kidnap him. Subsequently, the remainder of his life was devoted to refining the unified field attributes of his theory.\n\nIn the late 1950s and early 1960s there were a number of reports on Heim in magazines and tabloids such as \"Le Figaro\", \"Bunte Illustrierte\", \"Quick\" and \"Stern\". The magazine \"le Figaro\" remarked (January 15, 1969) that he was an \"inhuman robot\". Also, the main German TV station, ARD, ran reports and interviews with Heim. It was speculated that Heim was likely to make a breakthrough, either in fundamental physics or propulsion theory.\n\nOn November 17, 1969, Heim, reported the progress he had made towards developing his unified field theory to Messerschmitt-Bölkow-Blohm (MBB). Pascual Jordan and Gebhard Lyra were among the small body of scientists who attended that colloquium. Jordan wrote Heim a letter on December 22, 1969 encouraging him to publish his theory.\n\nLudwig Bölkow encouraged Heim to enhance his theory. On November 25, 1976, Heim publicly introduced, for the first time, his completed unified field theory in a presentation to MBB engineers. It included the methodology for calculating the mass spectrum of elementary particles. Pursuant to recommendations by Werner Heisenberg’s successor, Hans-Peter Dürr, Heim published his unified field theory summary, the following year, in an article entitled Recommendations of a Way to a Unified Description of Elementary Particles in the Max Planck Institute journal \"Zeitschrift für Naturforschung\". This was the first publication of his theory in a peer reviewed scientific journal.\n\nIn 1982 Heim's mass formula was programmed on a computer at the German Electron Synchrotron DESY in Hamburg with the assistance of some resident scientists. Up to that point, Heim had not yet confided in other theoretical physicists on the details of the mass formula derivation. Hence, the DESY results were not widely published and disseminated for academic scrutiny. That year Walter Dröscher, a theorist at the Vienna Patent Office, began to work with Heim. The first result of their collaboration cumulated into the second volume of Heim's major work, appearing in 1984.\n\nIn 1992, Hans Theodor Auerbach and Illobrand von Ludwiger presented a summary of Heim’s unified field theory of elementary particles and their internal structures. It contained Heim’s derivation of Sommerfeld’s fine structure constant (α = 1/137.0360085) – it was a close approximation of the 1987 measured value (α = 1/137.035989).\n\nHeim died in Northeim in 2001 at age 75.\n\nIn 2004, the American Institute of Aeronautics and Astronautics (AIAA) awarded the winning paper in the nuclear and future flight field to a retired Austrian patent officer named Walter Dröscher and Jochem Häuser, a physicist and professor of computer science at the University of Applied Sciences in Salzgitter, Germany. They turned the theoretical framework of Burkhard Heim into a proposal for an experimental test for a propulsion device that is thought to theoretically be able to travel at rates faster than the speed of light. Hans Theodor Auerbach, a theoretical physicist and someone who has worked alongside Heim has stated that, \"As far as I understand it, Heim theory is ingenious,\" and, \"I think that physics will take this direction in the future\".\n\nIn 2008, the AIAA Nuclear and Future Flight Propulsion Technical Committee published the following statement:\n\nHeim had to undergo a series of at least 50 operations after a laboratory explosion resulted in the loss of his arms. He found that intense concentration on the study of Einstein's relativity theory helped him control the pain in his arms mentally and physically.\n\nThe loss of his hands and serious diminution of his eyesight apparently resulted in Heim acquiring an eidetic, acoustic memory. He was claimed to rarely forget a formula if he heard it recited, and was said to be able to learn a language in a matter of days. He married a former concert singer from Prague in 1950 named Gerda.\n\nHeim achieved some media renown in the 1950s and 1960s, but his ideas have never been well-accepted in the physics community. A significant portion of Heim's work has not been published in rigorously peer reviewed journals. Heim's theory also predicts the existence of two hypothetical neutrinos, which have been shown not to exist by experiments at the Large Electron–Positron Collider.\n\nJean Cocteau created a drawing with Einstein, Newton and Copernicus under the mystic \"Eye of Heim\".\n\n\n"}
{"id": "9784315", "url": "https://en.wikipedia.org/wiki?curid=9784315", "title": "Christian Samuel Weiss", "text": "Christian Samuel Weiss\n\nChristian Samuel Weiss (26 February 1780 – 1 October 1856) was a German mineralogist born in Leipzig.\n\nFollowing graduation, he worked as a physics instructor in Leipzig from 1803 until 1808. and in the meantime, conducted geological studies of mountain formations in Tyrol, Switzerland and France (1806–08). In 1810 he became a professor of mineralogy at the University of Berlin, where in 1818/19 and 1832/33, he served as university rector. He died near Eger in Bohemia.\n\nWeiss is credited for creating parameters of modern crystallography, and was instrumental in making it a branch of mathematical science. He stressed the significance of direction in crystals, considering crystallographic axes to be a possible basis for classification of crystals. He is credited for introducing the categorization schema of crystal systems, and has a basic law of crystallography named after him called the \"Weiss zone law\".\n\n"}
{"id": "42922698", "url": "https://en.wikipedia.org/wiki?curid=42922698", "title": "Cirque du Bout du Monde", "text": "Cirque du Bout du Monde\n\nA fluvial cirque is a steephead valley formed in a Karst landscape \n\n"}
{"id": "42845342", "url": "https://en.wikipedia.org/wiki?curid=42845342", "title": "Crop simulation model", "text": "Crop simulation model\n\nA Crop Simulation Model (CSM) is a simulation model that describes processes of crop growth and development as a function of weather conditions, soil conditions, and crop management. Typically, such models estimate times that specific growth stages are attained, biomass of crop components (e.g., leaves, stems, roots and harvestable products) as they change over time, and similarly, changes in soil moisture and nutrient status.\n\nCrop simulation models have been classified into three broad categories:\n\n\n\n"}
{"id": "53037756", "url": "https://en.wikipedia.org/wiki?curid=53037756", "title": "Dipole repeller", "text": "Dipole repeller\n\nThe dipole repeller is a center of effective repulsion in the large-scale flow of galaxies in the neighborhood of the Milky Way, first detected in 2017.\n\nIt is thought to be represented as a large supervoid, the \"Dipole Repeller Void\".\n\nThe Local Group of galaxies is moving relative to the cosmic microwave background (CMB) at .\n\nThere is also a pattern of bulk flow in the motion of neighboring galaxies extending to distances of over 250 megaparsecs (Mpc). There is a known overdensity – the Shapley Supercluster – creating an attraction in the flow of galaxies. \n\nFundamentally gravitation is always attractive, but if there is an underdense region it apparently acts as a gravitational repeller. That's because there is less attraction in the direction of the underdensity, and the greater attraction due to the higher density in other directions acts to pull objects away from the underdensity.\n\nThe repeller appears to be located at a distance of about 220 Mpc and is anticipated to coincide with a void in galaxy density.\n\nThat single center of attraction along with a roughly equal single repeller appear to be the most significant contributors to the CMB dipole.\n\n\n"}
{"id": "53844269", "url": "https://en.wikipedia.org/wiki?curid=53844269", "title": "Elliott R. Brown", "text": "Elliott R. Brown\n\nElliott R. Brown from the University of California, Los Angeles, was awarded the status of Fellow in the American Physical Society, after they were nominated by their Forum on Industrial and Applied Physics in 2007, for \"breakthroughs in THz science and technology including new solid-state coherent sources: (1) resonant-tunneling oscillators, and (2) photomixers; new detectors based on single-crystal, semimetal-semiconductor junctions; and high-resolution spectroscopy of solids.\"\n"}
{"id": "2705177", "url": "https://en.wikipedia.org/wiki?curid=2705177", "title": "Emil Godlewski (junior)", "text": "Emil Godlewski (junior)\n\nEmil Godlewski (1875–1944) was a Polish embryologist, professor of the Jagiellonian University in Kraków. After early research on the development and histogenesis of muscles, professor Godlewski's scientific interests focused on regeneration and mechanisms regulating the process of fertilization, as well as early embryo development, blastulation and gastrulation. He was also interested in the origin of the primary differentiating cells in regenerates. He postulated the importance of epithelial tissue in this process and was the first to point out the change in the function, organization and role of the cells under the influence of external stimuli. Investigating fertilization and early development, he focused on the cooperation between the nucleus and the cytoplasm in the regulation of the early stages of development. Godlewski was also the author of the theory of migration of the inherited substances from the nucleus to the cytoplasm and, after their processing, from the cytoplasm to the nucleus. His works were never fragmentary, but always synthetic attempts at explaining important issues relating to the mechanisms of development. In 1936 Professor Godlewski was awarded the title of Member of the Pontifical Academy of Sciences. Apart from doing research and teaching, Emil Godlewski devoted a lot of time to social issues, especially those connected to medicine. When Poland regained independence after World War I, he actively participated in the reopening of the Jagiellonian University.\n\n\n"}
{"id": "2290205", "url": "https://en.wikipedia.org/wiki?curid=2290205", "title": "Fei Junlong", "text": "Fei Junlong\n\nMajor general Fei Junlong (; born 1965) is a Chinese military pilot and an astronaut. He flew on the second manned spaceflight of the Shenzhou program.\n\nHe was born in Suzhou, Jiangsu province of China and was recruited from high school by the People's Liberation Army Air Force (PLAAF) in 1982 at the age of 17. He graduated with excellent marks from the PLAAF's No. 9 Aviation School, the Changchun No.1 Flight College of the PLA Air Force and Flight Training School of the Air Force. In the PLAAF, he was a pilot, flight trainer and flight technology inspector.\n\nFèi was selected for the CNSA astronaut program in 1998. He was in the final five selected for the \"Shenzhou 5\" flight. He was the commander on the \"Shenzhou 6\" flight that launched October 12, 2005, with Niè Hǎishèng serving as flight engineer). They landed on October 17, 2005.\n\nHe was married in 1991 and has one son. During his personal time he dabbles in fine arts.\n\nThe asteroid 9512 Feijunlong was named after him.\n\n\n\n"}
{"id": "20883309", "url": "https://en.wikipedia.org/wiki?curid=20883309", "title": "Fossilization (linguistics)", "text": "Fossilization (linguistics)\n\nIn linguistic morphology, fossilization refers to two close notions. One is preserving of ancient linguistic features which have lost their grammatical functions in language. Another is loss of productivity of a grammatical paradigm (\"e.g.\" of an affix), which still remains in use in some words. \n\nExamples of fossilization include fossilized morphemes and fossil words.\n"}
{"id": "78928", "url": "https://en.wikipedia.org/wiki?curid=78928", "title": "Fruit tree forms", "text": "Fruit tree forms\n\nFruit trees are grown in a variety of shapes, sometimes to please the eye but mainly to encourage fruit production. The form or shape of fruit trees can be manipulated by pruning and training. Shaping and promoting a particular tree form is done to establish the plant in a particular situation under certain environmental conditions, to increase fruit yield, and to enhance fruit quality. For example, pruning a tree to a pyramid shape enables trees to be planted closer together. An open bowl or cup form helps sunlight penetrate the canopy, thus encouraging a high fruit yield whilst keeping the tree short and accessible for harvesting. Other shapes such as cordons, espaliers and fans offer opportunities for growing trees two dimensionally against walls or fences, or they can be trained to function as barriers.\n\nSome of the following fruit tree forms require training by tying the branches to the required form. Most require pruning to retain the desired structure. However, not all types of fruit tree are suitable for all forms; apples and pears do well as cordons and espaliers, for example, whereas cherries are more suited to the fan form.\n\nAn open-centred crown on a short trunk of less than . This is a traditional and popular form for apple trees. Bush trees are easy to maintain and bear fruit at a young age. Final height is between and , depending on which rootstock is used.\n\nLarger than the bush form, with trunks of or more. Standard trees can reach a total height of . They eventually produce high yields but, being large trees, are not easy to maintain.\n\nSimilar to the bush form, although the main leader shoot is allowed to maintain its dominance, resulting in a pyramidal shape.\n\nA variant of the pyramid form in which the lateral branches are tied down to a horizontal position. \nDesigned for dense orchards by Otto Schmitz-Hübsch and Heinrichs in Germany in 1936, this is currently the most popular training system for dwarf apple and pear trees.\n\nSingle-stemmed trees planted at an angle (usually 45°), with fruiting spurs encouraged to form along the stem. Any side branches are removed by pruning. Cordons take less space and crop earlier than most other forms, so more varieties can be grown in a given space, but yields are smaller per tree. A special cordon set-up is the Bouché-Thomas system.\n\nA central vertical trunk with three or four horizontal branches on each side. A special espalier in this group is the LePage-system.\n\nA short central trunk with several radiating branches growing from the crown.\n\nEspaliers with just one tier of horizontal branches 30 cm from the ground. These make a novel and productive border for a vegetable plot.\n\nA study on orchard mango trees in Nelspruit, South Africa, compared open vase, closed vase, central leader, palmette and standard pruning systems and recommended a modified pyramid, somewhere between a central leader and a closed vase system, for high-density mango orchards. The study also evaluated both post-fruit-set and post-harvest pruning, indicating that late mango cultivars benefit from pruning while bearing in late fall, while early cultivars may be best pruned immediately after harvest.\n\n\n"}
{"id": "18744801", "url": "https://en.wikipedia.org/wiki?curid=18744801", "title": "Johan Lundström", "text": "Johan Lundström\n\nDr. Johan N. Lundström (born 1973) is a Swedish biologist and psychologist.\n\nHe was awarded his Ph.D. in 2005 from Uppsala University and is most notable for his chemosensory work, and currently works at the Monell Chemical Senses Center. His experiments involve the use of neuroimaging and testing of human behavior.\n\n"}
{"id": "45099113", "url": "https://en.wikipedia.org/wiki?curid=45099113", "title": "John Castagnini", "text": "John Castagnini\n\nJohn Castagnini (born December 3, 1970) is an ontologist, public speaker on consciousness, and publisher of the best-selling \"Thank God I\" series of self-help books. He was an awesome network marketer with Global Prosperity.\n\nCastagnini has appeared in several movies, including the spiritual documentary \"Discover the Gift\", co-starring with spiritual leaders The Dalai Lama and Sri Sri Ravi Shankar, as well as international relationship author Barbara De Angelis.\n\nBorn in Canarsie, Brooklyn, New York as the eldest of three sons, Castagnini obtained a B.A degree in Biology from Cal-State Fullerton. Prompted by the death of his mother in 2005, Castagnini went on to found the \"ThankGodi\" publication, which focuses on methods of \"equilibration\" as a means to come to terms with traumatic personal events, and features well known authors John Demartini, Dr. Wayne Dyer and Dr. Bernie Seigel. The experiences that contributed to this approach of counselling were detailed in the documentary \"Discover the Gift\", and on ABC's show \"A View from the Bay\" with Spencer Christian.\n\n\n\n"}
{"id": "39572092", "url": "https://en.wikipedia.org/wiki?curid=39572092", "title": "Ke Kā o Makali‘i", "text": "Ke Kā o Makali‘i\n\nKe Kā o Makali‘i is a Polynesian constellation consisting of five stars in a curving formation in the shape of a bailer surrounding the western constellation Orion, although not including any stars from it. The constellation is seen to rise in the east like a cup and set in the west pouring onto the western horizon.\n\nKe Kā o Makali‘i comprises the stars:\n"}
{"id": "502832", "url": "https://en.wikipedia.org/wiki?curid=502832", "title": "Kitti's hog-nosed bat", "text": "Kitti's hog-nosed bat\n\nKitti's hog-nosed bat (\"Craseonycteris thonglongyai\"), also known as the bumblebee bat, is a vulnerable species of bat and the only extant member of the family Craseonycteridae. It occurs in western Thailand and southeast Myanmar, where it occupies limestone caves along rivers.\n\nKitti's hog-nosed bat is the smallest species of bat and arguably the world's smallest mammal. It has a reddish-brown or grey coat, with a distinctive pig-like snout. Colonies range greatly in size, with an average of 100 individuals per cave. The bat feeds during short activity periods in the evening and dawn, foraging around nearby forest areas for insects. Females give birth annually to a single offspring.\n\nAlthough the bat's status in Myanmar is not well known, the Thai population is restricted to a single province and may be at risk for extinction. Its potential threats are primarily anthropogenic, and include habitat degradation and the disturbance of roosting sites.\n\nKitti's hog-nosed bat is about in length and in mass. hence the common name of \"bumblebee bat\". It is the smallest species of bat and may be the world's smallest mammal, depending on how size is defined. The main competitors for the title are small shrews; in particular, the Etruscan shrew may be lighter at but is longer, measuring from its head to the base of the tail.\n\nThe bat has a distinctive swollen, pig-like snout with thin, vertical nostrils. Its ears are relatively large, while its eyes are small and mostly concealed by fur. Its teeth are typical of an insectivorous bat. The dental formula is 1:1:1:3 in the upper jaw and 2:1:2:3 in the lower jaw, with large upper incisors.\n\nThe bat's upperparts are reddish-brown or grey, while the underside is generally paler. The wings are relatively large and darker in colour, with long tips that allow the bat to hover. Despite having two caudal vertebrae, Kitti's Hog-nosed Bat has no visible tail. There is a large web of skin between the hind legs (the uropatagium) which may assist in flying and catching insects, although there are no tail bones or calcars to help control it in flight.\n\nKitti's hog-nosed bat occupies limestone caves along rivers within dry evergreen or deciduous forests. In Thailand, Kitti's hog-nosed bat is restricted to a small region of the Tenasserim Hills in Sai Yok District, Kanchanaburi Province, within the drainage basin of the Khwae Noi River. While Sai Yok National Park in the Dawna Hills contains much of the bat's range, some Thai populations occur outside the park and are therefore unprotected.\n\nSince the 2001 discovery of a single individual in Myanmar, at least nine separate sites have been identified in the limestone outcrops of the Dawna and Karen Hills outside the Thanlwin, Ataran, and Gyaing Rivers of Kayin and Mon States. The Thai and Myanmar populations are morphologically identical, but their echolocation calls are distinct. It is not known whether the two populations are reproductively isolated.\n\nKitti's hog-nosed bat roosts in caves in limestone hills, far from the entrance. While many caves contain only 10 to 15 individuals, the average group size is 100, with a maximum of about 500. Individuals roost high on walls or roof domes, far apart from each other. Bats also undertake seasonal migration between caves.\n\nKitti's hog-nosed bat has a brief activity period, leaving its roost for only 30 minutes in the evening and 20 minutes at dawn. These short flights are easily interrupted by heavy rain or cold temperatures. During this period, the bat forages within fields of cassava and kapok or around the tops of bamboo clumps and teak trees, within one kilometre of the roosting site. The wings seem to be shaped for hovering flight, and the gut contents of specimens include spiders and insects that are presumably gleaned off foliage. Nevertheless, most prey is probably caught in flight. Main staples of the bat's diet include small flies (Chloropidae, Agromyzidae, and Anthomyiidae), hymenopterans, and psocopterans.\n\nLate in the dry season (around April) of each year, females give birth to a single offspring. During feeding periods, the young either stays in the roost or remains attached to the mother at one of her two vestigial pubic nipples.\n\nKitti's hog-nosed bat is the only extant species in the family Craseonycteridae, which is grouped in the superfamily Rhinolophoidea as a result of molecular testing. Based on this determination, the bat's closest relatives are members of the families Hipposideridae and Rhinopomatidae.\n\nKitti's hog-nosed bat was unknown to the world at large prior to 1974. Its common name refers to its discoverer, Thai zoologist Kitti Thonglongya. Thonglongya worked with a British partner, John E. Hill, in classifying bats of Thailand; after Thonglongya died suddenly in February 1974, Hill formally described the species, giving it the binomial name \"Craseonycteris thonglongyai\" in honour of his colleague.\n\nAs of the species' most recent review in 2008, Kitti's hog-nosed bat is listed by the IUCN as vulnerable, with a downward population trend.\n\nSoon after the bat's discovery in the 1970s, some roosting sites became disturbed as a result of tourism, scientific collection, and even the collection and sale of individuals as souvenirs. However, these pressures may not have had a significant effect on the species as a whole, since many small colonies exist in hard-to-access locations, and only a few major caves were disturbed. Another potential risk is the activity of local monks, who have occupied roost caves during periods of meditation.\n\nCurrently, the most significant and long-term threat to the Thai population could be the annual burning of forest areas, which is most prevalent during the bat's breeding season. In addition, the proposed construction of a pipeline from Myanmar to Thailand may have a negative impact. Threats to the Myanmar population are not well known.\n\nIn 2007, Kitti's hog-nosed bat was identified by the Evolutionarily Distinct and Globally Endangered project as one of its Top 10 \"focal species\".\n\n"}
{"id": "17818125", "url": "https://en.wikipedia.org/wiki?curid=17818125", "title": "Kota Kinabalu Wetland Centre", "text": "Kota Kinabalu Wetland Centre\n\nKota Kinabalu Wetland Centre is of the only remains of mangrove forest that once existed extensively along the coastal region of Kota Kinabalu, Malaysia. Previously known as Likas Swamp or Likas Mangrove and later Kota Kinabalu City Bird Sanctuary, the Centre came foremost out of 20 wetlands selected by the Sabah Wetlands Inventory Committee in 1986.\n\nThe Centre is an important refuge and feeding ground for many species of resident birds, as well as several migratory bird species from Northern Asia. In addition, it is a breeding ground for marine life protected by the Fishery Department of Sabah.\n\nApart from providing shelter and food for both resident and migratory species of wildlife, wetlands also prevent salt build-up in surrounding freshwater supplies, stabilising sedimentation, storing nutrients and removing toxins.\n\nBirds from around the globe, including non-breeding winter visitors, are commonly sighted at the sanctuary, especially during migratory season of Asian birds (i.e. Sept-April).\n\n\n\n\nOther mangrove wildlife includes monitor lizards, fiddler crabs, mudskippers, weaver ants, butterflies and other insects, jellyfish, water snakes and mud lobsters.\n\n"}
{"id": "26422984", "url": "https://en.wikipedia.org/wiki?curid=26422984", "title": "Learning about Forests", "text": "Learning about Forests\n\nLearning about Forests (LEAF) is one of the five programs run by the Foundation for Environmental Education (FEE), a non-governmental organization located in Copenhagen, Denmark. LEAF aims to encourage school classes and teachers to use forests for educational activities. The \"vision\" is to see an increased level of awareness and knowledge the key role the forest plays on our planet. The program's \"mission\" is to spread environmental education concerning forests and all their values among school children all around the world.\n\nIn August 2013, LEAF was composed of twenty-one organizations: \n"}
{"id": "37895120", "url": "https://en.wikipedia.org/wiki?curid=37895120", "title": "List of Anseriformes by population", "text": "List of Anseriformes by population\n\nThis is a list of Anseriformes species by global population. While numbers are estimates, they have been made by the experts in their fields.\n\nAnseriformes (Anser being Latin for \"goose\") is the taxonomic order to which the ducks, geese, swans, and screamers belong. BirdLife International has assessed 166 species; 89 (54% of total species) have had their population estimated. A variety of methods are used for counting waterfowl. For example, in North America, national and sub-national agencies use planes and helicopters to make aerial transects of breeding populations, and extrapolate these counts over the species' known ranges. Methodologies are continuously being refined; thus estimates can be expected to become more accurate over time. Forecasts can be made by studying habitat condition trends and by interviewing local experts. For more information on how these estimates were ascertained, see Wikipedia's articles on population biology and population ecology.\n\nThe first bird in this list, the crested shelduck, retains a status of Critically Endangered on the IUCN Red List but may in fact be extinct. The last confirmed reporting was in 1964 near Vladivostok. North Korea claimed a sighting in March 1971, but this record is highly suspect. Unconfirmed reports do, however, periodically roll in from Northeast China, giving scientists hope that the last individual has not yet died.\nTo be assessed as Critically Endangered a species must have experienced a decline of at least 80% in the past ten years or three generations, or be projected to decline that much in the future ten years or three generations. As some species below are rapidly approaching their minimum viable population (MVP), the future may see their removal from the list and addition to the preceding paragraph.\n\nExtinct species:\n"}
{"id": "10576501", "url": "https://en.wikipedia.org/wiki?curid=10576501", "title": "List of Michigan state symbols", "text": "List of Michigan state symbols\n\nThe following is a list of symbols of the U.S. state of Michigan.\n\n\nAlthough Michigan has not adopted a state beverage, most Michigan natives claim that Vernors, a ginger flavored soda, is the state's unofficial beverage due to its wide use to ease common illnesses such as an upset stomach and sore throat other than for normal consumption.\n\n\n\n</noinclude>\n"}
{"id": "35318208", "url": "https://en.wikipedia.org/wiki?curid=35318208", "title": "List of isomers of undecane", "text": "List of isomers of undecane\n\nThis is the list of 159 isomers of undecane.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "14485936", "url": "https://en.wikipedia.org/wiki?curid=14485936", "title": "List of members of the National Academy of Sciences (Microbial biology)", "text": "List of members of the National Academy of Sciences (Microbial biology)\n"}
{"id": "15873020", "url": "https://en.wikipedia.org/wiki?curid=15873020", "title": "List of people with chronic fatigue syndrome", "text": "List of people with chronic fatigue syndrome\n\nThis is a list of notable people diagnosed with Myalgic Encephalomyelitis (ME). ME is sometimes referred to as chronic fatigue syndrome. Myalgic Encephalomyelitis is the standard global name as stated by the World Health Organization (WHO) ICD-10 G93.3.\n\n33. \"Henrik Berggren drabbad av kroniskt trötthetssyndrom\" (Article in Swedish) http://www.aftonbladet.se/nojesbladet/musik/a/dKwyA/henrik-berggren-drabbad-av-kroniskt-trotthetssyndrom\n"}
{"id": "46426116", "url": "https://en.wikipedia.org/wiki?curid=46426116", "title": "List of q-analogs", "text": "List of q-analogs\n\nThis is a list of \"q\"-analogs in mathematics and related fields. \n\n\n\n\n\n\n\n"}
{"id": "40483917", "url": "https://en.wikipedia.org/wiki?curid=40483917", "title": "List of small shelly fossil taxa", "text": "List of small shelly fossil taxa\n\nThis is a list of small shelly fossils of prehistoric marine animals, ordered by their type.\n\n\n\nElements of a scleritome, \n\nProbable palaeoscolecid worm sclerites:\n\nTomotiid-like sclerites:\n\nProblematic cones: \n\nProbable Lobopodian sclerites: \n\n\n\n\n\n"}
{"id": "11782853", "url": "https://en.wikipedia.org/wiki?curid=11782853", "title": "Mario Pino Quivira", "text": "Mario Pino Quivira\n\nMario Pino Quivira is a Chilean geologist specialized in geoarchaeology and sedimentology that has been involved in several studies of early human settlements in Southern Chile. After Tom Dillehay's excavation of Monte Verde near Puerto Montt, where human remains estimated to be about 12,800 years old have been found, challenging the Clovis theory of the first human arrival in the Americas, Pino controversially claimed the site was 33,000 years old. Other studied sites includes the Chan-Chan settlement near Mehuín and the Gomphotherium of Osorno.\n"}
{"id": "6657114", "url": "https://en.wikipedia.org/wiki?curid=6657114", "title": "Mirror Fusion Test Facility", "text": "Mirror Fusion Test Facility\n\nThe Mirror Fusion Test Facility, or MFTF, was an experimental magnetic confinement fusion device built using the tandem magnetic mirror design. It was, by far, the largest, most powerful and most expensive mirror machine ever constructed. Due to budget cuts, it was mothballed the day after its construction was complete, and sat unused for a year before being formally cancelled. $372 million dollars were spent on the system during its lifetime.\n\nMFTF was the ultimate development of a series of machines at Lawrence Livermore National Laboratory (LLNL) that trace their history back to the early 1950s. Over the years one problem after another had been addressed, leading to designs using \"baseball\" and \"yin-yang\" mirrors. By the late 1960s, it appeared possible to build stable mirrors. However, these changes had also lowered their economic performance, to the point where they appeared unattractive as power generators. A new concept introduced in the early 1970s, the tandem mirror, appeared to offer a way forward.\n\nIn 1968 the Soviets demonstrated their tokamak systems were outperforming all others by a factor of at least ten times. The path to practical fusion appeared open, and in the US, Robert Hirsch began plans to produce a prototype power plant using the tokamak design. Having secured a massive budget increase, and desiring a second design in case the tokamak didn't pan out, a study of the alternative concepts suggested the best developed was the tandem mirror, and the MFTF concept was born. A smaller version, the Tandem Mirror Experiment (TMX), was also funded to test the basic layout.\n\nConstruction of MFTF and TMX began in 1977. TMX was much smaller and easier to build than MFTF, and began operations in 1979. By the early 1980s, TMX was beginning to demonstrate serious problems that suggested MFTF would not work as predicted. This was occurring around the same time that Ronald Reagan declared that the energy crisis was over. In a series of sweeping budget cuts across the entire energy research field, MFTF had its operational budget cancelled, although its construction budget survived. Construction completed in 1986, and the facility sat unused for a year being scavenged for parts by other researchers until it was formally cancelled in 1987 and disassembled.\n\nIt was designed and built at Lawrence Livermore National Laboratory (LLNL), one of the primary research centers for mirror fusion devices. It cost 372 million dollars to construct, making it at the time the most expensive project in the lab's history. It opened on February 21, 1986 and was promptly shut down. The reason given was to balance the United States federal budget.\n\nFollowing on from the earlier Baseball II device, the facility was originally a similar system in which the confinement area was located between two horseshoe-shaped \"mirrors\". \n\nDuring construction the success of the Tandem Mirror Experiment (\"TMX\") led to a redesign to insert a solenoid area between two such magnets, dramatically improving confinement time from a few milliseconds to over one second. Most of the fusion power would be produced in the long solenoid. The yin-yang magnets would then serve only to dam up the ends in order to maintain good plasma confinement in the solenoid. Limited to break-even energy balance, the magnetic mirror endcaps consumed power, but much less than that produced in a solenoid of sufficient length. \n\nA new version, officially MFTF-B, started construction in 1977 and was completed in 1986 on the very day the project was canceled. No experiments were performed. Rollbacks in fusion research funding dramatically reduced funding levels across the entire field.\n\nParts of the MFTF have since been re-used on newer fusion experiments, one of which won a recycling award.\n"}
{"id": "36953335", "url": "https://en.wikipedia.org/wiki?curid=36953335", "title": "Moredun Research Institute", "text": "Moredun Research Institute\n\nThe Moredun Research Institute is a scientific research institution based at the Pentlands Science Park, in the Bush Estate area of Midlothian, Scotland. It conducts research into diseases of farm livestock and the promotion of animal health and welfare.\n\nMoredun employs over 200 vets, scientists and support staff, that are funded primarily by the Agriculture, Food and Rural Communities Directorate of the Scottish Government. The Institute received £7.1 million from the government in 2010-11.\n\nThe Animal Diseases Research Association, now the registered charity the Moredun Foundation, was founded in 1920 by a group of Scottish farmers, with the aim of improving the health of livestock, especially sheep. The association founded a research institute employing vets and scientists, and over the decades the scope of animal health work expanded to cover goats, cows, horses and wildlife.\n\nThe Institute was originally based at Moredun, in Edinburgh.\n\nThe origins of Moredun go back to the years following World War I which saw an increased demand for home grown food and a significant rise in the market value of livestock. This emphasised the seriousness of the losses associated with disease and concerned farmers voiced their strong support for an organised body to conduct research into livestock diseases. In the 1920s Louping Ill and Braxy claimed almost a third of the lambs born in Scotland and Grass Sickness was having a devastating effect on horses, which were used for heavy labour on farms at that time. In March 1920 a group of enlightened Scottish farmers held a public meeting at the Highland and Agricultural Society’s chambers in Edinburgh and the Animal Diseases Research Association (now known as The Moredun Foundation) was formed. Within six years the founder members had raised enough funds to buy a plot of land and build the Moredun Research Institute. Within ten years of the Research Institute opening, Moredun scientists had discovered the cause and developed vaccines and treatment strategies for Braxy and lamb dysentery. Scientists then went on to solve the mystery of Louping Ill which was found to be caused by a virus transmitted by ticks and a vaccine was soon developed.\n\nBy the 1940s over half a million doses of vaccine and treatment products were produced and distributed by Moredun. Research gained momentum and further funding was secured to find out the causes of many different diseases such as: scrapie, pine, milk fever, Johne’s disease and a range of respiratory and reproductive disorders. Vaccines, diagnostics and treatment strategies followed. Today, many of the veterinary medicines and vaccines that are routinely used on farms have been researched, developed or tested at Moredun. This research is vital – 17% of the value of the UK sheep industry is lost each year due to infectious diseases. Subclinical infections of gut parasites are estimated to cost the UK sheep industry over £84 million a year in lost production. Enzootic abortion in ewes is thought to cost the UK sheep industry £15 million a year and Johne’s disease costs the UK cattle industry £13 million a year. Ninety years on, and still governed by farmers, Moredun’s mission to improve animal health and welfare remains strong and Moredun continues to apply cutting edge science and technology to help protect both livestock and people, today and tomorrow.\n\nThe Pentlands Science Park opened in 1995. It is part of the Moredun Group, under the control of the Moredun Foundation. It is a public-private partnership. The Pentlands Science Park and Moredun are participants in the Edinburgh Science Triangle project.\n\nIn addition to being the home of the Moredun Research Institute, the science park has attracted 20 companies to the site. The focus of Pentlands Science Park is animal bioscience but the tenants include research companies involved in pharmaceuticals, software, and environmental science. The area occupied by non-Moredun organisations is approximately 55,000 sq ft, and these tenants employ over 200 people.\n\n\n\n\n\n\n"}
{"id": "43134310", "url": "https://en.wikipedia.org/wiki?curid=43134310", "title": "Not Censorship, But Selection", "text": "Not Censorship, But Selection\n\n\"Not Censorship But Selection\" is a 1953 article written by Lester Asheim. It was initially published in the \"Wilson Library Bulletin,\" and has been influential in library professional standards relating to censorship and collection development. The full text of the article currently resides on the website of the American Library Association.\n\nThis seminal 1953 article on the difference between censorship and selection in libraries influenced later thought and formed the cornerstone of many intellectual freedom documents.\n\nIn the first section of the article Asheim goes over the difference of censorship of a book by the law or by a town, versus the choice of a librarian not to select something for her library. He states that the librarian is not censoring because she is making a choice that only affects her specific institution, whereas the choice the censors are making affect an entire town or nation. The librarian is not saying that the book cannot be circulated, only that she is not going to circulate it. Patrons are still able to get it elsewhere.\n\nAsheim then brings up the question of limited control. He wonders if limited control, which the librarian has when choosing not to select a book, is any different from the limited control of the local pressure group. He then concludes that it is different because the reasons and motives behind the choice are different. He also believes that the patron who is being denied the book is affected differently depending on the intent of the person who is choosing to limit the book. Asheim makes the analogy of the difference between someone’s leg being amputated by a doctor who is doing it because it is necessary, versus a leg being amputated by someone who is psychotic and is doing it because of a sick compulsion. The man who has had his leg amputated by the psychotic knows the difference and is affected differently than if a doctor had done it out of a need to help his patient.\n\nBecause it is a physical impossibility to make all books equally accessible, selection by librarians is necessary. Asheim writes that some of the standards that librarians use for selecting books are the same standards that censors use to ban books. For example, it is valid to use the intent of the author as a selection standard, however it can also be used to ban a book in which it is decided that the author's intent is pornographic or treasonable. The standards are subjective. Therefore, the difference between selection and censorship is found in the way the standards are applied.\n\nAsheim argues that the main difference between a selector and a censor is in their approach: the selector's is positive, the censor's is negative. The selector, seeking to preserve, looks to find reasons to keep a book. The censor, seeking to ban, looks for reasons to reject a book. Asheim says that the negative approach makes it inevitable that a book will be judged not in its wholeness but by isolated parts. He writes that the selector's positive approach is demonstrated by the diversity of a library's collection that makes as much as possible accessible to patrons. Further, he believes that the frequency of challenges to library holdings is in itself a testament to the difference between selection and censorship.\n\nHe writes that the censor uses external criteria to judge a book; for instance, the author's life may be examined and used as a way to reject a work. The selector, on the other hand, uses internal values and judges a book by its own merit. He calls selection democratic and censorship authoritarian. Finally, Asheim reminds that the confidence the public has in librarians is an earned confidence that can only be kept by staying true to the profession's ideals. And one of these ideals is maintaining the essential difference between selection and censorship.\n\nAsheim's article has influenced many in the library profession and authors continue to cite it when responding to the changing censorship landscape. In 2002, Tony Doyle drew upon Asheim's article to talk about censorship in the aftermath of the September 11 attacks and June Pinnell-Stephens argued that Asheim's censorship/selection distinction is useful for understanding collection development and censorship in the digital age. It has been argued that the dichotomy of \"censorship\" and \"selection\" has the effect of othering the censor. In 2010, Rickey Best cited Asheim in an article portraying academic libraries as bastions of intellectual freedom for maintaining access to materials that were frequently challenged in public libraries.\n\nIn 1983, Asheim wrote a reappraisal of his own article to address the changing tactics of censors and to challenge the persistent assumption that librarians select materials based primarily on their personal tastes. Asheim characterizes groups such as the Moral Majority as having recently (at the time of his writing) switched from attempting to have objectionable books removed to attempting to have books they approved of included to such an extent that the library's collection would be skewed to their perspective. In response, Asheim further emphasizes that segments of the library's patron base should not be allowed to impede each other's rights, and that the job of the librarian is to make selection choices with the library's entire community in mind. He also upholds his prior assertion that the best response to the problem of access is to add ideas rather than to remove them.\n\n\n"}
{"id": "174386", "url": "https://en.wikipedia.org/wiki?curid=174386", "title": "Planck time", "text": "Planck time\n\nIn quantum mechanics, the Planck time () is the unit of time in the system of natural units known as Planck units. A Planck unit is the time required for light to travel in a vacuum a distance of 1 Planck length, which is approximately 5.39 × 10 s. The unit is named after Max Planck, who was the first to propose it.\n\nThe Planck time is defined as:\n\nwhere:\n\nUsing the known values of the constants, the approximate equivalent value in terms of the SI unit, the second, is\nwhere the two digits between parentheses denote the standard error of the approximated value.\n\nThe Planck time (also known as Planck second) was first suggested by Max Planck in 1899. He suggested that there existed some fundamental natural units for length, mass, time and energy. Planck derived these using dimensional analysis only using what he considered the most fundamental universal constants: the speed of light, the Newton gravitational constant and the Planck constant. The Planck time is by many physicists considered to be the shortest possible measurable time interval; however, this is still a matter of debate.\n\nThe Planck time is the unique combination of the gravitational constant , the special-relativistic constant , and the quantum constant , to produce a constant with dimension of time. Because the Planck time comes from dimensional analysis, which ignores constant factors, there is no reason to believe that exactly one unit of Planck time has any special physical significance. Rather, the Planck time represents a rough time scale at which quantum gravitational effects are likely to become important. This essentially means that whilst smaller units of time can exist, they are so small their effect on our existence is negligible. The nature of those effects, and the exact time scale at which they would occur, would need to be derived from an actual theory of quantum gravity.\n\nThe reciprocal of the Planck time, which is Planck frequency, can be interpreted as an upper bound on the frequency of a wave. This follows from the interpretation of the Planck length as a minimal length, and hence a lower bound on the wavelength.\n\nAll scientific experiments and human experiences occur over time scales that are dozens of orders of magnitude longer than the Planck time, making any events happening at the Planck scale undetectable with current scientific knowledge. , the smallest time interval uncertainty in direct measurements is on the order of 850 zeptoseconds (8.50 × 10 seconds)\n\n"}
{"id": "26418907", "url": "https://en.wikipedia.org/wiki?curid=26418907", "title": "Plastic Fantastic", "text": "Plastic Fantastic\n\nPlastic Fantastic: How the Biggest Fraud in Physics Shook the Scientific World is a 2009 book by American-based science reporter Eugenie Samuel Reich.\n\nIn \"Plastic Fantastic\", Reich investigates how Jan Hendrik Schön, a young physicist working in the field of advanced microelectronics at Bell Labs, was able to repeatedly fabricate scientific results to mislead his collaborators, journal editors, and the scientific community. The book is based on interviews with 126 scientists.\n\nThe book carries , and was initially published by Palgrave MacMillan.\n\n"}
{"id": "54022970", "url": "https://en.wikipedia.org/wiki?curid=54022970", "title": "PyTorch", "text": "PyTorch\n\nPyTorch is an open-source machine learning library for Python, based on Torch, used for applications such as natural language processing. It is primarily developed by Facebook's artificial-intelligence research group, and Uber's \"Pyro\" software for probabilistic programming is built on it.\n\nPyTorch provides two high-level features:\n\nIn terms of programming, Tensors can simply be considered multidimensional arrays. Tensors in PyTorch are similar to NumPy arrays, with the addition being that Tensors can also be used on a GPU that supports CUDA. PyTorch supports various types of Tensors.\n\nPyTorch uses a technique called automatic differentiation. A recorder records what operations have performed, and then it replays it backward to compute our gradients. This technique is especially powerful when building neural networks in order to save time on one epoch by calculating differentiation of the parameters at the forward pass itself.\n\ntorch.optim is a module that implements various optimization algorithms used for building neural networks. Most of the commonly used methods are already supported, so there is no need to build them from scratch\n\nPyTorch autograd makes it easy to define computational graphs and take gradients, but raw autograd can be a bit too low-level for defining complex neural networks. This is where the nn module can help.\n\n"}
{"id": "27352253", "url": "https://en.wikipedia.org/wiki?curid=27352253", "title": "Retort pouch", "text": "Retort pouch\n\nA retort pouch or retortable pouch is a type of food packaging made from a laminate of flexible plastic and metal foils. It allows the sterile packaging of a wide variety of food and drink handled by aseptic processing, and is used as an alternative to traditional industrial canning methods. Packaged foods range from water to fully cooked, thermo-stabilized (heat-treated) high-caloric (1,300 kcal on average) meals such as Meals, Ready-to-Eat (MREs) which can be eaten cold, warmed by submersing in hot water, or through the use of a flameless ration heater, a meal component introduced by the military in 1992. Retort pouches are used in field rations, space food, fish products \ncamping food, instant noodles, and brands such as Capri Sun and Tasty Bite.\n\nSome varieties have a bottom gusset and are known as Stand-Up Pouches.\n\nThe retort pouch was invented by the United States Army Natick R&D Command, Reynolds Metals Company, and Continental Flexible Packaging, who jointly received the Food Technology Industrial Achievement Award for its invention in 1978. Retortable pouches are extensively used by the U.S. military for field rations (called \"Meals, Ready-to-Eat\", or \"MREs\").\n\nA retort pouch is constructed from a flexible metal-plastic laminate that is able to withstand the thermal processing used for sterilization. The food is first prepared, either raw or cooked, and then sealed into the retort pouch. The pouch is then heated to 240-250°F (116-121°C) for several minutes under high pressure inside a retort or autoclave machine. The food inside is cooked in a similar way to pressure cooking. This process reliably kills all commonly occurring microorganisms (particularly \"Clostridium botulinum\"), preventing it from spoiling. The packaging process is very similar to canning, except that the package itself is flexible. The lamination structure does not allow permeation of gases from outside into the pouch. The retort pouch construction varies from one application to another, as a liquid product needs different barrier properties than a dry product, and similarly an acidic product needs different chemical resistance than a basic product. Some different plastic layers used in retort pouches include:\n\n\nThis multi-layer structure prevents the retort pouch from being recycled into other retort pouches or food packaging. However, the material can be recycled into an aluminized resin or up-cycled into textile materials. The weight of a pouch is less than regular cans or bottles, and the energy required to produce each pouch is less than competing packaging from metals, paper, and glass.\n\nIn the consumer market, retort pouches have gained great popularity outside of the United States, particularly in the Pacific Rim region. However, American consumers have evidently demonstrated reluctance regarding the packaging technology, and its adoption has been slow. As a result, many retort packages sold in the United States are packaged in cartons to give them an appearance more familiar to consumers. Tasty Bite products are an example of a retort pouch product packaged in a carton. Several American food distributors have begun manufacturing foods in retort pouches without cartons, notably tuna canning companies Chicken of the Sea, and Bumble Bee. In 2012, the Campbell Soup Company introduced its \"Go\" line of ready-to-eat soups in stand-up retort pouches to American consumers. The product launch came with a marketing campaign targeted toward Millennials, who have shown reluctance to purchasing other Campbell Soup products in the past.\n\n\n"}
{"id": "917126", "url": "https://en.wikipedia.org/wiki?curid=917126", "title": "Smart glass", "text": "Smart glass\n\nSmart glass or switchable glass (also smart windows or switchable windows in those applications) is a glass or glazing whose light transmission properties are altered when voltage, light or heat is applied. Generally, the glass changes from translucent to transparent, changing from blocking some (or all) wavelengths of light to letting light pass through.\n\nSmart glass technologies include electrochromic, photochromic, thermochromic, suspended-particle, micro-blind and polymer-dispersed liquid-crystal devices.\n\nWhen installed in the envelope of buildings, smart glass creates climate adaptive building shells, with the ability to save costs for heating, air-conditioning and lighting and avoid the cost of installing and maintaining motorized light screens or blinds or curtains. Blackout smart glass blocks 99.4% of ultraviolet light, reducing fabric fading. For suspended particle device (SPD)-type smart glass, this is achieved in conjunction with low emissivity coatings.\n\nCritical aspects of smart glass include material costs, installation costs, electricity costs and durability, as well as functional features such as the speed of control, possibilities for dimming, and the degree of transparency.\n\nIn suspended-particle devices (SPDs), a thin film laminate of rod-like nano-scale particles is suspended in a liquid and placed between two pieces of glass or plastic, or attached to one layer. When no voltage is applied, the suspended particles are randomly organized, thus blocking and absorbing light. When voltage is applied, the suspended particles align and let light pass. Varying the voltage of the film varies the orientation of the suspended particles, thereby regulating the tint of the glazing and the amount of light transmitted.\n\nSPDs can be manually or automatically \"tuned\" to precisely control the amount of light, glare and heat passing through, reducing the need for air conditioning during the summer months and heating during winter. Smart glass can be controlled through a variety of mediums, such as automatic photosensors and motion detectors, smartphone applications, integration with intelligent building and vehicle systems, knobs or light switches.\n\nElectrochromic devices change light transmission properties in response to voltage and thus allow control over the amount of light and heat passing through. In electrochromic windows, the electrochromic material changes its opacity: it changes between a transparent and a tinted state. A burst of electricity is required for changing its opacity, but once the change has been effected, no electricity is needed for maintaining the particular shade which has been reached. \n\nFirst generation electrochromic technologies tend to have a yellow cast in their clear states and blue hues in their tinted states. Darkening occurs from the edges, moving inward, and is a slow process, ranging from many seconds to several minutes (20-30 minutes) depending on window size. Newer electrochromic technologies, also known as \"smart-tinting glass,\" tackled the drawbacks of earlier versions by eliminating the yellow cast in the clear state and tinting to more neutral shades of gray, tinting evenly rather than from the outside in, and accelerating the tinting speeds to less than three minutes, regardless of the size of the glass. However, these newer electrochromic technologies have yet to pass ASTM-2141 for long term reliability and durability testing. This lack of third party independent ASTM certification is one of the limiting aspects of market acceptance in comparison to first generation electrochomric technologies that have successfully passed ASTM-2141 certification.\n\nElectrochromic glass provides visibility even in the darkened state and thus preserves visible contact with the outside environment. It has been used in small-scale applications such as rearview mirrors. Electrochromic technology also finds use in indoor applications, for example, for protection of objects under the glass of museum display cases and picture frame glass from the damaging effects of the UV and visible wavelengths of artificial light.\nElectrochromic glass can be programmed to automatically tint according to the weather or the sun's position or user preferences. It can also be controlled via mobile applications and even via popular voice assistants. \n\nRecent advances in electrochromic materials pertaining to transition-metal hydride electrochromics have led to the development of reflective hydrides, which become reflective rather than absorbing, and thus switch states between transparent and mirror-like.\n\nRecent advancements in modified porous nano-crystalline films have enabled the creation of electrochromic display. The single substrate display structure consists of several stacked porous layers printed on top of each other on a substrate modified with a transparent conductor (such as ITO or ). Each printed layer has a specific set of functions. A working electrode consists of a positive porous semiconductor (say Titanium Dioxide, ) with adsorbed chromogens (different chromogens for different colors). These chromogens change color by reduction or oxidation. A passivator is used as the negative of the image to improve electrical performance. The insulator layer serves the purpose of increasing the contrast ratio and separating the working electrode electrically from the counter electrode. The counter electrode provides a high capacitance to counterbalances the charge inserted/extracted on the SEG electrode (and maintain overall device charge neutrality). Carbon is an example of charge reservoir film. A conducting carbon layer is typically used as the conductive back contact for the counter electrode. In the last printing step, the porous monolith structure is overprinted with a liquid or polymer-gel electrolyte, dried, and then may be incorporated into various encapsulation or enclosures, depending on the application requirements. Displays are very thin, typically 30 micrometer, or about 1/3 of a human hair. The device can be switched on by applying an electrical potential to the transparent conducting substrate relative to the conductive carbon layer. This causes a reduction of viologen molecules (coloration) to occur inside the working electrode. By reversing the applied potential or providing a discharge path, the device bleaches. A unique feature of the electrochromic monolith is the relatively low voltage (around 1 Volt) needed to color or bleach the viologens. This can be explained by the small over- potentials needed to drive the electrochemical reduction of the surface adsorbed viologens/chromogens.\n\nIn polymer-dispersed liquid-crystal devices (PDLCs), liquid crystals are dissolved or dispersed into a liquid polymer followed by solidification or curing of the polymer. During the change of the polymer from a liquid to solid, the liquid crystals become incompatible with the solid polymer and form droplets throughout the solid polymer. The curing conditions affect the size of the droplets that in turn affect the final operating properties of the \"smart window\". Typically, the liquid mix of polymer and liquid crystals is placed between two layers of glass or plastic that include a thin layer of a transparent, conductive material followed by curing of the polymer, thereby forming the basic sandwich structure of the smart window. This structure is in effect a capacitor.\n\nElectrodes from a power supply are attached to the transparent electrodes. With no applied voltage, the liquid crystals are randomly arranged in the droplets, resulting in scattering of light as it passes through the smart window assembly. This results in the translucent, \"milky white\" appearance. When a voltage is applied to the electrodes, the electric field formed between the two transparent electrodes on the glass causes the liquid crystals to align, allowing light to pass through the droplets with very little scattering and resulting in a transparent state. The degree of transparency can be controlled by the applied voltage. This is possible because at lower voltages, only a few of the liquid crystals align completely in the electric field, so only a small portion of the light passes through while most of the light is scattered. As the voltage is increased, fewer liquid crystals remain out of alignment, resulting in less light being scattered. It is also possible to control the amount of light and heat passing through, when tints and special inner layers are used. It is also possible to create fire-rated and anti X-Ray versions for use in special applications. Most of the devices offered today operate in on or off states only, even though the technology to provide for variable levels of transparency is easily applied. This technology has been used in interior and exterior settings for privacy control (for example conference rooms, intensive-care areas, bathroom/shower doors) and as a temporary projection screen. It is commercially available in rolls as adhesive-backed smart film that can be applied to existing windows and trimmed to size in the field.\n\nThe expression smart glass can be interpreted in a wider sense to include also glazings that change light transmission properties in response to an environmental signal such as light or temperature.\n\nThese types of glazings cannot be controlled manually. In contrast, all electrically switched smart windows can be made to automatically adapt their light transmission properties in response to temperature or brightness by integration with a thermometer or photosensor, respectively\n\nEureka Tower in Melbourne has a glass cube which projects out from the building with visitors inside, suspended almost above the ground. When one enters, the glass is opaque as the cube moves out over the edge of the building. Once fully extended over the edge, the glass becomes clear.\n\nThe Boeing 787 Dreamliner features electrochromic windows which replace the pull down window shades on existing aircraft. \n\nNASA is looking into using electrochromics to manage the thermal environment experienced by the newly developed Orion and Altair space vehicles.\n\nSmart glass has been used in some small-production cars including the Ferrari 575 M Superamerica.\n\nICE 3 high speed trains use electrochromatic glass panels between the passenger compartment and the driver's cabin.\n\nThe elevators in the Washington Monument use smart glass in order for passengers to view the commemorative stones inside the monument.\n\nThe city's restroom in Amsterdam's Museumplein square features smart glass for ease of determining the occupancy status of an empty stall when the door is shut, and then for privacy when occupied.\n\nBombardier Transportation has intelligent on-blur windows in the Bombardier Innovia APM 100 operating on Singapore's Bukit Panjang LRT Line, to prevent passengers from peering into apartments as the trains pass by and is planning to offer windows using smart glass technology in its Flexity 2 light rail vehicles.\n\n\n\n"}
{"id": "40833540", "url": "https://en.wikipedia.org/wiki?curid=40833540", "title": "Social network (sociolinguistics)", "text": "Social network (sociolinguistics)\n\nIn the field of sociolinguistics, social network describes the structure of a particular speech community. Social networks are composed of a \"web of ties\" (Lesley Milroy) between individuals, and the structure of a network will vary depending on the types of connections it is composed of. Social network theory (as used by sociolinguists) posits that social networks, and the interactions between members within the networks, are a driving force behind language change.\n\nThe key participant in a social network is the \"anchor\", or center individual. From this anchor, ties of varying strengths radiate outwards to other people with whom the anchor is directly linked. These people are represented by \"points\". Participants in a network, regardless of their position, can also be referred to as \"actors \"or \"members\".\n\nThere are multiple ways to describe the structure of a social network. Among them are \"density, member closeness centrality, multiplexity, \"and\" orders\". These metrics measure the different ways of connecting within of a network, and when used together they provide a complete picture of the structure of a particular network.\n\nA social network is defined as either \"loose\" or \"tight\" depending on how connected its members are with each other, as measured by factors like density and multiplexity. This measure of tightness is essential to the study of socially motivated language change because the tightness of a social network correlates with lack of innovation in the population's speech habits. Conversely, a loose network is more likely to innovate linguistically.\n\nThe density of a given social network is found by dividing the number of all existing links between the actors by the number of potential links within the same set of actors. The higher the resulting number, the more dense a network is. Dense networks are most likely to be found in small, stable communities with few external contacts and a high degree of social cohesion. Loose social networks, by contrast, are more liable to develop in larger, unstable communities that have many external contacts and exhibit a relative lack of social cohesion.\n\nMember closeness centrality is the measurement of how close an individual actor is to all the other actors in the community. An actor with high closeness centrality is a central member, and thus has frequent interaction with other members of the network. A central member of a network tends to be under pressure to maintain the norms of that network, while a peripheral member of the network (one with a low closeness centrality score) does not face such pressure. Therefore, central members of a given network are typically not the first members to adopt a linguistic innovation because they are socially motivated to speak according to pre-existing norms within the network.\n\nMultiplexity is the number of separate social connections between any two actors. It has been defined as the \"interaction of exchanges within and across relationships\". A single tie between individuals, such as a shared workplace, is a uniplex relationship. A tie between individuals is multiplex\" \"when those individuals interact in multiple social contexts. For instance, A is B's boss, and they have no relationship outside of work, so their relationship is uniplex. However, C is both B's coworker and neighbor, so the relationship between B and C is multiplex, since they interact with each other in a variety of social roles.\n\nOrders are a way of defining the place of a speaker within a social network. Actors are classified into three different zones\nA \"first order zone\" is composed of all individuals that are directly linked to any given individual. The first order zone can also be referred to as the \"interpersonal environment\" or \"neighborhood\". A first order member of a network is an actor who has a large number of direct connections to the center of the network.\nA \"second order zone\" is a grouping of any individuals who are connected to at least one actor within the first order zone. However, actors in the second order zone are not directly connected to the central member of the network. A second order member has a loose or indirect connection to the network, and may only be connected to a certain network member.\nA \"third order zone\" is made up of newly observed individuals not directly connected to the first order zone. Third order members may be connected to actors in the second order zone, but not the first. They are peripheral members of the network, and are often the actors with the lowest member closeness centrality, since they may not have frequent contact with other members of the network.\n\nSocial networks are used in sociolinguistics to explain linguistic variation in terms of community norms, rather than broad categories like gender or race. Instead of focusing on the social characteristics of speakers, social network analysis concentrates on the relationships between speakers, then considers linguistic change in the light of those relationships. In an effort to depart from variationist sociolinguistics, the concept of the social network has been used to examine the links between the strength of network ties and the use of a linguistic variant. This allows researchers to create an accurate picture of a community's language use without resorting to stereotypical classification.\n\nThe concept of social networks is applicable at both the macro and micro levels. Social networks are at work in communities as large as nation-states or as small as an online dating service. They can also be applied to intimate social groups such as a friendship, family unit, or neighborhood. Because even the smallest of networks contains an enormous number of potential connections between actors, sociolinguists usually only study small networks so that the fieldwork is manageable. In fact, even when studying small networks, sociolinguists rely on the metrics outlined in the previous section, rather than mapping the network out, one connection at a time. One way of mapping the general structure of a network is to assign a \"strength scale\" to each speaker. For example, in Lesley Milroy's study of social networks in Belfast, Northern Ireland, the researchers measured five social variables, which together generated a strength scale for each member of the network: \nThe allocation of a network strength score allows the network patterns of individuals to be measured and possible links with linguistic patterns to be tested.\n\nIn recent years, computer simulation and modeling have been used to study social networks from a broader perspective. Because previous social network studies were focused on individual connections, the size of the networks were limited so that the researcher could work personally with subjects. With the rise of advanced computer modeling techniques, sociolinguists have been able to study the linguistic behavior of large networks of individuals over long periods of time without the inconvenience of individually working with thousands of subjects.\n\nAdvances in computer simulation and modeling technology have been used to study social networks on a larger scale, both with more participants and over a greater span of time. Previous social network studies had to examine individual connections in great detail, and so had to limit the size of the networks involved. Linguists working in the field were also unable to accurately pinpoint the causes of linguistic change because it tends to occur slowly over a long period of time, on a scale beyond the scope of a single research project. With the rise of computer modeling, sociolinguists have been able to study the linguistic behavior of large networks without the huge expenditure of time required to individually work with thousands of subjects long-term. The pioneering study in this field was Fagyal et al. in 2011.\n\nBecause social networks investigate the forces that impact individual behavior, rather than simply attributing linguistic difference to social class, a theory of language change based on social networks is able to explain linguistic behavior more deeply than variationist sociolinguistics. The two major findings of social network theory are that dense (highly interconnected) networks are resistant to change, and that most linguistic change is initiated by weak links—people who are not centrally connected to the network in question. Though most sociolinguistics working on social networks agree on these findings, there has been extended debate about which actors in the network are the primary drivers of linguistic change. The results of this debate are two theories, the strong-tie theory, and the weak-tie theory.\n\nThis study demonstrated that actors chose to imitate other (more prestigious) actors who embodied desirable social attributes, especially \"toughness\" as exemplified by urban students. This imitation of desirable qualities indicates that strongly connected agents lead change by spreading norms through network members. In Eckert's study of speech norms in Detroit high schools, she notes that suburban youth adopted the speech traits of urban youth (including a diphthongized and lowered [i]).\n\nLabov's 1986 study of Philadelphia speech communities (a term used before \"social networks\" became widespread) demonstrated that the agents of linguistic change were the leaders of the speech communities. Actors with high levels of prestige in the linguistic led the use of these forms, and enforced them as norms within the community. Members of this network then used the forms normalized within the network outside of the network, and continuous usage led to wide adoption of these speech norms.\n\nTakeshi Sibata's 1960 study of elementary school children provides strong support for the view that insiders, or leaders, in a social network facilitate language change. He interviewed several elementary school children, and taught them some invented words he created for the purpose of this study. After teaching the students these words, and telling them to teach the other students these words, he came back a week later to observe the results. A few children, those who were popular, friendly, cheerful, active in class activities, were the main people who spread those words. As the centers of their respective networks, these children functioned as strong-tie leaders of linguistic change.\n\nLabov's 1966 study of African American Vernacular English in South Harlem, revealed that second-order actors in African American social networks were the initiators of linguistic change in their communities. Though these second-order actors, or \"lames\" were not held in high regard by the leaders of the speech network, they had connections to other networks, and were sources of new linguistic variables. This study served as the basis of the \"Weak Tie Theory\" proposed by Milroy and Milroy.\n\nThis Milroy and Milroy study examined vernacular English as it was spoken in inner-city Belfast in the 1970s, in three working class communities in Belfast: those in the Ballymacarrett area, the Hammer area, and the Clonard area. Milroy took part in the life of each community as an acquaintance, or 'friend of a friend', investigating the correlation between the integration of individuals in the community and the way those individuals speak.\n\nEach individual studied was given a network strength score based on the person's knowledge of other people in the community, the workplace and at leisure activities to give a score of 1 to 5, with 5 being the highest network 'strength score'. Out of the five variables, one measured density, while the other four measured multiplexity.\n\nEach person's use of phonological variables, (ai), (a), (l), (th), (ʌ), (e), which were clearly indexical of the Belfast urban speech community, were then measured. The independent variables for this study were age, sex and location. These linguistic variables made up the dependent variable of the study, and were analyzed in relation to the network structure and background of each individual speaker. Deviation from the regional standard was determined by density and multiplicity of the social networks into which speakers are integrated.\n\nThe researchers found that a high network strength score was correlated with the use of vernacular forms, and therefore that the use of vernacular variants was strongly influenced by the level of integration into a network. The conclusion of the study was that close-knit networks are important for dialect maintenance.\n\nThis 1987 study, also conducted by Milroy, examined the variable [u], and its relationship to working class identity. The researchers found that actors with the weakest tie to this community identity were most likely to use the variable [u], possibly as a way to strengthen their ties to the network.\n\nIn Ballymacarrett, one of the villages the researchers surveyed, unrounded [u] was most often used by young males and females, who had weak ties to the working class networks, but use the variables frequently to project an image of working-class toughness. These young people often interacted with members of other social networks, and thus spread the [u] realization through their own social networks, which resulted in the adoption of unrounded [u] in most of Belfast. These results provide support for the weak tie theory of language change, because it was the actors on the peripheries of social networks who were responsible for spreading linguistic change. \n\nOne key study that employed computer simulations was Fagyal, Swarup, Escobar, Gasser, and Lakkarajud's work on the roles of group insiders (leaders) and outsiders (loners) in language change. The researchers found that both first-order and second-order network members (also known as \"leaders\" and \"loners\") were both needed in order for changes to spread predictably within the network.\n\nIn this study, the researchers simulated a social network of 900 participants, called nodes, which were connected into a network using a matrix algorithm. They then randomly assigned a linguistic variant to each node. On each cycle of the algorithm, every node interacted with another node, and the variant assigned to each node changed randomly depending on which variant the other node had. This cycle was repeated 40,000 times, and at the end of each cycle, the variant connected to each node was recorded.\n\nThe results of the Fagyal et al. study indicated that \"in a large, socially heterogenous population\", one linguistic variant eventually became the community norm, though other variants were not entirely eliminated. However, when the researchers manipulated the network to remove either loners or leaders, the results changed: without loners, one variant rapidly caused the loss of all other variants; and without leaders, no single variant became the norm for a majority of speakers.\n\nThese findings allowed the researchers to address the major debate in social network theory: whether it is leaders (or centers) or loners who are responsible for language change. In their findings, the presence of both leaders and loners was essential, though the two types of agents played different roles in the process of change.\n\nRather than introducing entirely new forms, leaders accelerate the adoption of forms that already exist within the network. Conversely, the researchers describe the loners' role this way: \"when loners are a part of a population structure that allows their influence to reach centrally-connected hubs, they can have a decisive impact on the linguistic system over time.\"\n\nPreviously, researchers had posited that loners preserved old forms that had been neglected by the larger community. Fagyal et al. complicate this claim by suggesting that the role of loners in a network is to safeguard old features, then reintroduce them to the community.\n\nThe researchers in Berg's 2006 study of digital social networks as linguistic social networks note the value of social networks as both linguistic corpuses and linguistic networks.\n\nIn Carmen Perez-Sabater's 2012 study of Facebook users, she discusses the use of English by native and non-native speakers on university Facebook pages. The researchers categorize these posts as a model of \"computer-mediated communication\", a new communication style that combines features of writing and speech. Facebook posts generally have a degree of informality, whether the users are native or nonnative English speakers, but native English speakers often have a higher degree of informality. For example, non-native speakers cited in the study use separated letter-style greetings and salutations, indicating linguistic insecurity. The conclusions of the study were that \"computer-mediated communication\" do not always tend toward informality, and that online social networks pattern similarly to non-virtual social networks.\n\n\n"}
{"id": "46803322", "url": "https://en.wikipedia.org/wiki?curid=46803322", "title": "Sociology of scientific ignorance", "text": "Sociology of scientific ignorance\n\nThe sociology of scientific ignorance (SSI) is the study of ignorance in and of science. The most common way is to see ignorance as something relevant, rather than simply lack of knowledge. There are two distinct areas in which SSI is being studied: some focus on ignorance in scientific research, whereas other focus on public ignorance of science. Sociology of scientific ignorance is a complementary field to the sociology of scientific knowledge (SSK).\n\nWhen studying ignorance in scientific research, the common standpoint is that ignorance can be used as a tool in science. An example of this is blackboxing, which is the notion that it can be beneficial to hide the internal parts of a system, and only make the input and output visible to the user.\n\nStudies of public ignorance of science focuses on how scientific ignorance can affect society, the public view of science, and what can give rise to public ignorance of science. This area is related to public understanding of science.\n\nGenerally, the word 'ignorance' has a negative tone to it, and for a long time scientific ignorance was viewed as a purely negative thing. Recently, however, people have started to abandon this idea, and instead try to find uses of deliberate ignorance.\nThis has generally been called useful ignorance. A first step in finding uses of ignorance is realizing that ignorance is inevitable. As Matthias Gross says: \"new knowledge also means more ignorance\".\nGross also talks about the connection between ignorance and surprise. Surprise can reveal what scientists are ignorant of, which help them focus their research in order to gain knowledge. On the other hand, ignorance is what gives rise to surprise, making the two very connected.\n\nIn correspondence with knowledge mobilization, which refers to moving available knowledge into use, a concept of 'ignorance mobilization' has been introduced. \"Ignorance mobilization can be understood as the use of\nignorance towards the achievement of goals.\"\nThis concept also makes a distinction between two types of ignorance: \"active\" non-knowledge is ignorance that is intentionally or unintentionally taken into account within science; \"latent\" non-knowledge is ignorance that is not taken into account. The latter more resembles the old view of ignorance, as lack of knowledge. Ignorance mobilization can be said to aim to change latent non-knowledge into active non-knowledge, thereby making it useful for further research.\n\nSpecified ignorance is the notion of non-knowledge that the scientists are aware of, and must change into knowledge in order to gain knowledge of something else. \"The express recognition of what is not yet known but needs to be known in order to lay the foundation for still more knowledge\".\nThis can help scientist direct their research, in that it shows what pre-studies needs to be done, before doing the main research.\n\nThis division of SSI is generally looking at the causes of public ignorance of science, as well as the impact it can have on scientific research and society. One way of categorizing the causes of ignorance uses the following three categories:\nStudies have also been done that focus heavily on the role journalists - and media in general - play when it comes to public ignorance of science and common scientific misconceptions. The reason behind journalists spreading false or misleading information can be either because the journalists believe the information to be true, or because of some personal gain for the journalist. A common way to put weight to the journalists claims is to point to a controversy within the scientific world, or to ignorance within scientific research. Although the latter is unavoidable, by the common view in SSI, this has made scientists more hesitant to discuss their ignorance, since this could be used by media to diminish their work.\nOne area where media is said to have played a prominent role in the public opinion of the matter is that of global warming.\n\n\n"}
{"id": "2173797", "url": "https://en.wikipedia.org/wiki?curid=2173797", "title": "Starfish Prime", "text": "Starfish Prime\n\nStarfish Prime was a July 9, 1962 high-altitude nuclear test conducted by the United States, a joint effort of the Atomic Energy Commission (AEC) and the Defense Atomic Support Agency. It was launched from Johnston Island, and was the largest nuclear test conducted in outer space and one of five conducted by the US in space.\n\nA Thor rocket carrying a W49 thermonuclear warhead (manufactured by Los Alamos Scientific Laboratory) and a Mk. 2 reentry vehicle was launched from Johnston Island in the Pacific Ocean, about west-southwest of Hawaii. The explosion took place at an altitude of , above a point southwest of Johnston Island. It produced a yield equivalent to 1.4 megatonnes of TNT. The explosion was about 10° above the horizon as seen from Hawaii, at 11 PM Hawaii time.\n\nThe Starfish test was one of five high-altitude tests grouped together as Operation Fishbowl within the larger Operation Dominic, a series of tests in 1962 begun in response to the Soviet announcement on August 30, 1961 that they would end a three-year moratorium on testing.\n\nIn 1958 the United States had completed six high-altitude nuclear tests, but the high-altitude tests of that year produced many unexpected results and raised many new questions. According to the U.S. Government Project Officer's Interim Report on the Starfish Prime project:\n\nPrevious high-altitude nuclear tests: YUCCA, TEAK, and ORANGE, plus the three ARGUS shots were poorly instrumented and hastily executed. Despite thorough studies of the meager data, present models of these bursts are sketchy and tentative. These models are too uncertain to permit extrapolation to other altitudes and yields with any confidence. Thus there is a strong need, not only for better instrumentation, but for further tests covering a range of altitudes and yields.\nThe Starfish test was originally planned as the second in the Fishbowl series, but the first launch (Bluegill) was lost by the radar tracking equipment and had to be destroyed in flight.\n\nThe initial Starfish launch attempt on June 20 was aborted in flight due to failure of the Thor launch vehicle. The Thor missile flew a normal trajectory for 59 seconds; then the rocket engine stopped, and the missile began to break apart. The range safety officer ordered the destruction of the missile and warhead. The missile was between 30,000 and 35,000 feet (9.1 and 10.7 km) in altitude when it was destroyed. Parts of the missile and some radioactive contamination fell upon Johnston Island and nearby Sand Island and the surrounding ocean. \n\nOn July 9, 1962, at 09:00:09 Coordinated Universal Time (11:00:09 p.m. on July 8, Honolulu time), the Starfish Prime test was detonated at an altitude of . The coordinates of the detonation were .\nThe actual weapon yield came very close to the design yield, which various sources have set at different values in the range of 1.4 to 1.45 megatons (6.0 PJ). The nuclear warhead detonated 13 minutes 41 seconds after liftoff of the Thor missile from Johnston Island.\n\nStarfish Prime caused an electromagnetic pulse (EMP), which was far larger than expected, so much larger that it drove much of the instrumentation off scale, causing great difficulty in getting accurate measurements. The Starfish Prime electromagnetic pulse also made those effects known to the public by causing electrical damage in Hawaii, about away from the detonation point, knocking out about 300 streetlights, setting off numerous burglar alarms and damaging a telephone company microwave link. The EMP damage to the microwave link shut down telephone calls from Kauai to the other Hawaiian islands.\n\nA total of 27 small rockets were launched from Johnston Island to obtain experimental data from the Starfish Prime detonation. In addition, a large number of rocket-borne instruments were launched from Barking Sands, Kauai, in the Hawaiian Islands.\n\nA large number of United States military ships and aircraft were operating in support of Starfish Prime in the Johnston Island area and across the nearby North Pacific region.\n\nA few military ships and aircraft were also positioned in the region of the South Pacific Ocean near the Samoan Islands. This location was at the southern end of the magnetic field line of the Earth's magnetic field from the position of the nuclear detonation, an area known as the \"southern conjugate region\" for the test. An uninvited scientific expeditionary ship from the Soviet Union was stationed near Johnston Island for the test, and another Soviet scientific expeditionary ship was located in the southern conjugate region near the Samoan Islands.\n\nAfter the Starfish Prime detonation, bright auroras were observed in the detonation area, as well as in the southern conjugate region on the other side of the equator from the detonation. According to one of the first technical reports:\nThese auroral effects were partially anticipated by Nicholas Christofilos, a scientist who had earlier worked on the Operation Argus high-altitude nuclear shots.\n\nAccording to U.S. atomic veteran Cecil R. Coale, some hotels in Hawaii offered \"rainbow bomb\" parties on their roofs for Starfish Prime, contradicting some reports that the artificial aurora was unexpected.\n\nPages 19–21 of \"A 'Quick Look' at the Technical Results of Starfish Prime\" (August 1962) state:\nA 2006 report described the particle and field measurements of the Starfish diamagnetic cavity and the injected beta flux into the artificial radiation belt.\nThese measurements describe the explosion from 0.1 milliseconds to 16 minutes after the detonation.\n\nWhile some of the energetic beta particles followed the Earth's magnetic field and illuminated the sky, other high-energy electrons became trapped and formed radiation belts around the Earth. There was much uncertainty and debate about the composition, magnitude and potential adverse effects from this trapped radiation after the detonation. The weaponeers became quite worried when three satellites in low Earth orbit were disabled. The half-life of the energetic electrons was only a few days. At the time it was not known that solar and cosmic particle fluxes varied by a factor 10, and energies could exceed 1 MeV. In the months that followed these man-made radiation belts eventually caused six or more satellites to fail, as radiation damaged their solar arrays or electronics, including the first commercial relay communication satellite, Telstar, as well as the United Kingdom's first satellite, Ariel 1. Detectors on Telstar, TRAAC, Injun, and Ariel 1 were used to measure distribution of the radiation produced by the tests.\n\nIn 1963, it was reported that Starfish Prime had created a belt of MeV electrons. In 1968, it was reported that some Starfish electrons had remained for 5 years.\n\n\n\n\n"}
{"id": "13467643", "url": "https://en.wikipedia.org/wiki?curid=13467643", "title": "Symbolic Interaction (journal)", "text": "Symbolic Interaction (journal)\n\nSymbolic Interaction is a quarterly peer-reviewed academic journal published by Wiley-Blackwell. It was established in 1978, originally published by the University of California Press, and covers research and theoretical developments concerned with symbolic interactionism. It is the official publication of the Society for the Study of Symbolic Interaction. The editor-in-chief is Robert Dingwall (Nottingham Trent University).\n\nThe journal is abstracted and indexed in:\nAccording to the \"Journal Citation Reports\", the journal has a 2013 impact factor of 0.519.\n\n"}
{"id": "56226654", "url": "https://en.wikipedia.org/wiki?curid=56226654", "title": "Timeline of the gunpowder age in Southeast Asia", "text": "Timeline of the gunpowder age in Southeast Asia\n\nThis is a timeline of the history of gunpowder and related topics such as weapons, warfare, and industrial applications in Southeast Asia.\n\n\n"}
{"id": "14686527", "url": "https://en.wikipedia.org/wiki?curid=14686527", "title": "Triad of Violence", "text": "Triad of Violence\n\nThe triad of violence is a sociological theory that originates from political scientist Michael Kaufman and elaborated on by sociologist Michael Messner. The triad of violence consists of violence against women, violence against other men, and violence against themselves.\n\nThis refers to instances of rape conducted by male athletes. Messner emphasizes that the majority of male athletes do not participate in violence against women. An example of this would be the 2006 Duke University lacrosse team scandal. Messner argues that situations like this are an expression of masculinity through sexual aggression. However, all allegations have been dropped on the athletes.\n\nThis refers to the idea that sports encourages athletes to be act rough against opponents. Rituals such as hazing are also example of such violence against other men. These rituals focus on suppressing empathy as a form of masculinity.\n\nThis refers to the idea of athletes being tough and being able to play through pain. Corporations such as Nike perpetuate this notion that the body is a machine. This is best exemplified by instances where athletes injure themselves but still continue playing despite severe injuries. The high injury rate of athletes are both indicators of male athletes violence against themselves and other men.\n\nMichael Kaufman originally came up with the phrase \"Triad of Violence\". He further breaks down the analysis of men's violence in sports as the 6 P's.\n\nThese are\n\n\"patriarchal power\": which states that violence has been related with male power. Violence then becomes about maintaining power\n\n\"sense of privilege\": is the feeling that one is entitled to commit violence.\n\n\"paradox of men's power\": is that violence has become a source of power and a source of fear for men.\n\n\"psychic armor\": which argues that violence is men's way of achieving emotional distance.\n\n\"psychic pressure cooker\": masculinity has been directly tied to bottling up of emotions. Only anger has been considered a \"valid\" male emotion\n\n\"past experience\": the past experiences of men affect their attitudes towards violence. i.e. growing up in a violent household will teach a young boy that violence is an accepted part of life.\n"}
{"id": "44328", "url": "https://en.wikipedia.org/wiki?curid=44328", "title": "Ulugh Beg", "text": "Ulugh Beg\n\nMīrzā Muhammad Tāraghay bin Shāhrukh (, ), better known as Ulugh Beg () (March 22, 1394 in Sultaniyeh, Persia – October 27, 1449, Samarkand)Uzbekistan), was a Timurid ruler as well as an astronomer, mathematician and sultan. His commonly known name is not truly a personal name, but rather a moniker, which can be loosely translated as \"Great Ruler\" (compare modern Turkish \"ulu\", \"great\", and \"bey\", \"chief\") and is the Turkic equivalent of Timur's Perso-Arabic title \"Amīr-e Kabīr\". His real name was \"Mīrzā Mohammad Tāraghay bin Shāhrukh\". Ulugh Beg was also notable for his work in astronomy-related mathematics, such as trigonometry and spherical geometry. He built the great Ulugh Beg Observatory in Samarkand between 1424 and 1429. It was considered by scholars to have been one of the finest observatories in the Islamic world at the time and the largest in Central Asia. He built the Ulugh Beg Madrasah (1417–1420) in Samarkand and Bukhara, transforming the cities into cultural centers of learning in Central Asia. He was also a mathematician of the 15th century. His observatory is situated in Samarkand which is in Uzbekistan. He ruled Uzbekistan, Tajikistan, Turkmenistan, Kyrgyzstan, southern Kazakhstan and most of Afghanistan from 1411 to 1449. Ulugh Beg is recognized as the most important observational astronomer from the 15th century by many scholars.\n\nHe was a grandson of the great conqueror, Timur (Tamerlane) (1336–1405), and the oldest son of Shah Rukh, both of whom came from the Turkicized Barlas tribe of Transoxiana (now Uzbekistan). His mother was a noblewoman named Goharshad, daughter of the representative Turkic of tribal aristocracy Giyasitdin Tarhan. Ulugh Beg was born in Sultaniyeh in Persia during Timur's invasion. As a child he wandered through a substantial part of the Middle East and India as his grandfather expanded his conquests in those areas. After Timur's death, however, and the accession of Ulugh Beg's father to much of the Timurid Empire, he settled in Samarkand, which had been Timur's capital. After Shāhrukh moved the capital to Herat (in modern Afghanistan), sixteen-year-old Ulugh Beg became his governor in Samarkand in 1409. In 1411, he became the sovereign ruler of the whole Mavarannahr khanate.\n\nFrom an early age, astronomy piqued his interest after he paid a visit to what was still present of the Maragheh Observatory located in Maragheh, which is located in East Azerbaijan Province, Iran. This is the observatory where the well-known astronomer Nasir al-Din al-Tusi practiced.\n\nThe teenaged ruler set out to turn the city into an intellectual center for the empire. Between 1417 and 1420, he built a \"madrasa\" (\"university\" or \"institute\") on Registan Square in Samarkand (currently in Uzbekistan), and he invited numerous Islamic astronomers and mathematicians to study there. The \"madrasa\" building still survives. Ulugh Beg's most famous pupil in astronomy was Ali Qushchi (died in 1474).\nHe was also famous in the fields of medicine and poetry. He used to debate with other poets about contemporary social issues. He liked to debate in a poetic style, called \"Bahribayt\" among local poets. According to the medical book \"Mashkovskiy\" which is in the Russian language, Ulugh Beg discovered a mixture of alcohol with garlic, apparently preserving it to help treat conditions like diarrhea, headache, stomach ache and intestine illnesses. He also offered advice for newly married couples, which indicate recipes containing nuts, dried apricot, dried grape etc. He claimed these to be useful to increase men's virility. This recipe has been given in Ibn Sina's books also.\n\nHis own particular interests concentrated on astronomy, and, in 1428, he built an enormous observatory, called the \"Gurkhani Zij\", similar to Tycho Brahe's later Uraniborg as well as Taqi al-Din's observatory in Constantinople. Lacking telescopes to work with, he increased his accuracy by increasing the length of his sextant; the so-called \"Fakhri\" sextant had a radius of about and the optical separability of 180\" (seconds of arc).\n\nUsing it, he compiled the 1437 \"Zij-i-Sultani\" of 994 stars, generally considered the greatest star catalogue between those of Ptolemy and Brahe, a work that stands alongside Abd al-Rahman al-Sufi's \"Book of Fixed Stars\". The serious errors which he found in previous Arabian star catalogues (many of which had simply updated Ptolemy's work, adding the effect of precession to the longitudes) induced him to redetermine the positions of 992 fixed stars, to which he added 27 stars from Abd al-Rahman al-Sufi's catalogue \"Book of Fixed Stars\" from the year 964, which were too far south for observation from Samarkand. This catalogue, one of the most original of the Middle Ages, was first edited by Thomas Hyde at Oxford in 1665 under the title \"Tabulae longitudinis et latitudinis stellarum fixarum ex observatione Ulugbeighi\" and reprinted in 1767 by G. Sharpe. More recent editions are those by Francis Baily in 1843 in \"vol. xiii\" of the \"Memoirs of the Royal Astronomical Society\" and by Edward Ball Knobel in \"Ulugh Beg's Catalogue of Stars, Revised from all Persian Manuscripts Existing in Great Britain, with a Vocabulary of Persian and Arabic Words\" (1917).\n\nIn 1437, Ulugh Beg determined the length of the sidereal year as 365.2570370... = 365 6 10 8 (an error of +58 seconds). In his measurements over the course of many years he used a 50 m high gnomon. This value was improved by 28 seconds in 1525 by Nicolaus Copernicus, who appealed to the estimation of Thabit ibn Qurra (826–901), which had an error of +2 seconds. However, Ulugh Beg later measured another more precise value of tropical year as 365 5 49 15, which has an error of +25 seconds, making it more accurate than Copernicus's estimate which had an error of +30 seconds. Ulugh Beg also determined the Earth's axial tilt as 23°30'17\" in the sexagesimal system of degrees, minutes and seconds of arc, which in decimal notation converts to 23.5047 degrees.\n\nIn mathematics, Ulugh Beg wrote accurate trigonometric tables of sine and tangent values correct to at least eight decimal places.\n\nUlugh Beg's scientific expertise was not matched by his skills in governance. When he heard of the death of his father Shahrukh Mirza, Ulugh Beg went to Balkh, where he heard that his nephew Ala-ud-Daulah Mirza bin Baysonqor, son of Ulugh Beg's brother Baysonqor, had claimed the emirship of the Timurid Empire in Herat. Consequently, Ulugh Beg marched against Ala-ud-Daulah and met him in battle at Murghab. Having won this battle, Ulugh Beg advanced toward Herat and massacred its people in 1448, but Ala-ud-Daulah's brother Mirza Abul-Qasim Babur bin Baysonqor came to his aid, defeating Ulugh Beg. Ulugh Beg retreated to Balkh, where he found that its governor, his oldest son Abdal-Latif Mirza, had rebelled against him. Another civil war ensued. Within two years, he was beheaded by the order of his own eldest son while on his way to Mecca. Eventually, his reputation was rehabilitated by his nephew, Abdallah Mirza (1450–1451), who placed Ulugh Beg's remains in the mausoleum of Timur in Samarkand, where they were found by archeologists in 1941.\n\nUlugh Beg had thirteen wives:\n\n\nSoviet anthropologist Mikhail M. Gerasimov reconstructed the face of Ulugh Beg. Like his grandfather Timurlane, Ulugh Beg is close to the Mongoloid type with slightly Europoid features. His father Shah Rukh, had predominantly Caucasoid features, with no obvious Mongoloid feature.\n\n\n\n"}
