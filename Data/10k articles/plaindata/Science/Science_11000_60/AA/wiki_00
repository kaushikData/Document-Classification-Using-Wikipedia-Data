{"id": "2479544", "url": "https://en.wikipedia.org/wiki?curid=2479544", "title": "Adelite", "text": "Adelite\n\nThe rare mineral adelite, is a calcium, magnesium, arsenate with chemical formula CaMgAsOOH. It forms a solid solution series with the vanadium bearing mineral gottlobite. Various transition metals substitute for magnesium and lead replaces calcium leading to a variety of similar minerals in the \"adelite - duftite group\".\n\nAdelite forms variably colored (blue, green, yellow and grey) crystals in the orthorhombic crystal system. The form is typically massive. It has a Mohs hardness rating of 5 and a specific gravity of 3.73 to 3.79.\n\nIt was first described in 1891 from Värmland, Sweden. Its name comes from the Greek word for \"indistinct\".\n\n"}
{"id": "764614", "url": "https://en.wikipedia.org/wiki?curid=764614", "title": "Alexander F. I. Forbes", "text": "Alexander F. I. Forbes\n\nAlexander Forbes Irvine Forbes (April 13, 1871 – May 15, 1959) was a South African astronomer.\n\nHe was born in Scotland in Kinellar, Aberdeenshire and came to South Africa in 1896. He returned to Scotland to study but emigrated permanently to South Africa in 1909. He worked as an architect until 1932.\n\nHe was president of the Astronomical Society of South Africa from 1942 to 1943.\n\nHe discovered the periodic comet 37P/Forbes. He was also one of several co-discoverers of \"Comet Pons-Coggia-Winnecke-Forbes\", which is today known as 27P/Crommelin in honor of the astronomer who computed its orbit.\n\n"}
{"id": "9621847", "url": "https://en.wikipedia.org/wiki?curid=9621847", "title": "Anatoly Konstantinovich Rozhdestvensky", "text": "Anatoly Konstantinovich Rozhdestvensky\n\nAnatoly Konstantinovich Rozhdestvensky (, 1920–1983) was a Russian paleontologist responsible for naming many dinosaurs, including \"Aralosaurus\" and \"Probactrosaurus\".\n"}
{"id": "12557133", "url": "https://en.wikipedia.org/wiki?curid=12557133", "title": "Anouschka Izmirlian", "text": "Anouschka Izmirlian\n\nAnouschka Izmirlian is a gemologist who evaluates and appraises gemstones for clients in New York City. From 1999 to 2004, she was a counselor at the Armenian Mission to the United Nations.\n\nShe is the daughter of Helena and Dikran S. Izmirlian of Geneva. Her father is the chairman and chief executive of Alimenta, a Geneva commodities trading company.\n\nShe was formerly married to John Demsey.\n"}
{"id": "17971033", "url": "https://en.wikipedia.org/wiki?curid=17971033", "title": "Ballpark model", "text": "Ballpark model\n\nThe ballpark model is a system under which users of a facility do so at their own risk. The name arises from the fact that visitors to a ballpark bear the risk of getting hit by bats, balls and other objects flying into the stands at high velocities. An example of this type of system is New Hampshire's lack of a requirement that motorists carry liability insurance. The risk of getting hit by a driver who has neither insurance nor the means to pay for damages is borne by other motorists.\n\nIt is in contrast to the Disneyland model.\n"}
{"id": "34946913", "url": "https://en.wikipedia.org/wiki?curid=34946913", "title": "Bombing of the Bezuidenhout", "text": "Bombing of the Bezuidenhout\n\nThe bombing of the Bezuidenhout took place on 3 March 1945, when the Royal Air Force accidentally bombed the Bezuidenhout neighbourhood in the Dutch city of The Hague. At the time, the neighbourhood was more densely populated than usual with evacuees from The Hague and Wassenaar; tens of thousands were left homeless and had to be quartered in the Eastern and Central Netherlands.\n\nThe British bomber crews had intended to bomb the Haagse Bos (\"Forest of the Hague\") district where the Germans had installed V-2 launching facilities that had been used to attack English cities. However the pilots were issued with the wrong coordinates so the navigational instruments of the bombers had been set incorrectly, and combined with fog and clouds obscured their vision, the bombs were instead dropped on the Bezuidenhout residential neighbourhood.\n\nOn the morning of March 3, 1945 medium and light bombers of the North American B-25 Mitchell and Douglas Boston types from No. 137 and No. 139 wings of the Second Tactical Air Force took off from Melsbroek near Brussels and Vitry in Northern France. Between 8 and 9 o'clock in the morning the bombers dropped 67 tonnes of high explosive bombs on the Bezuidenhout, wreaking widespread destruction.\n\nDue to insufficient fire engines and firemen (as many of them had been either called up for forced labour in German industry or had gone into hiding to prevent being signed up) the resulting fire was largely unchecked, killing 511 people, including eight firemen.\n\nAs soon as the British realized the extent of the damage, they dropped fliers over the neighbourhood apologizing for the error. \"Trouw\", the Dutch resistance newspaper, reported:\n\nThe horrors of the war are increasing. We have seen the fires in The Hague after the terrible bombings due to the V2-launching sites. We have seen the column of smoke, drifting to the south and the ordeal of the war has descended upon us in its extended impact. We heard the screaming bombs falling on (the) Bezuidenhout, and the missiles which brought death and misery fell only a hundred metres from us. At the same time we saw the launching and the roaring, flaming V2, holding our breath to see if the launch was successful, if not falling back on the homes of innocent people. It is horrible to see the monsters take off in the middle of the night between the houses, lighting up the skies. One can imagine the terrors that came upon us now that The Hague is a frontline town, bombed continuously for more than ten days. Buildings, burning and smouldering furiously, a town choking from smoke, women and children fleeing, men hauling furniture which they tried to rescue from the chaos. What misery, what distress.\n\nThe bombing is commemorated every year on the first Sunday after 3 March. In 2011 Mayor Jozias van Aartsen of The Hague as well as the Mayors of Wassenaar and Leidschendam-Voorburg (residents of both towns helped with firefighting and caring for the survivors) were present at the remembrance ceremony, which consisted of a church service, the laying of a wreath at the \"Monument of the human mistake\" () and a remembrance concert in the Royal Conservatory of The Hague. A similar church service and concert were held in 2012.\n\nAs a result of the bombing, there were:\n\n"}
{"id": "57300099", "url": "https://en.wikipedia.org/wiki?curid=57300099", "title": "Carlsberg Fault zone", "text": "Carlsberg Fault zone\n\nThe Carlsberg Fault zone is a concealed tectonic formation that runs across Copenhagen city centre. It is one of the most significant faults in the Copenhagen area and can be followed for about 30 km.\n\nThe Carlsberg Fault is located in a NNW-SSE striking fault system in the border zone between the Danish Basin and the Baltic Shield. Recent earthquakes indicate that this area is tectonically active.\n\nIt was described for the first time in 1925 at the Carlsberg Breweries.\n"}
{"id": "2377453", "url": "https://en.wikipedia.org/wiki?curid=2377453", "title": "Cauliflory", "text": "Cauliflory\n\nCauliflory is a botanical term referring to plants that flower and fruit from their main stems or woody trunks rather than from new growth and shoots. This can allow trees to be pollinated or have their seeds dispersed by animals which cannot climb or fly. With fruit, plants may instead have fruit which drop from the canopy and ripen only after they reach the ground, an alternative \"strategy\" to cauliflory. (Note that the concept of cauliflory includes that of ramiflory.)\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "8870886", "url": "https://en.wikipedia.org/wiki?curid=8870886", "title": "Challenging the Chip", "text": "Challenging the Chip\n\nChallenging the Chip is a 2006 book on \"labor rights and environmental justice in the global electronics industry\" edited by Ted Smith, David A. Sonnenfeld, and David Naguib Pellow . It is published by Temple University Press. In three parts, the book looks at global electronics, environmental justice and labor rights, and electronic waste and extended producer responsibility. In four appendices, the book also deals with the principles of environmental justice, the computer take-back campaign, sample shareholder resolutions, and the electronics recycler's pledge of true stewardship.\n\nThis 357-page book was put together by \"scores of people around the world (who) have been involved over the course of several years in the conceptualization, development, editing and production (of it)\".\n\nIn his Foreword to the text, former Texas Agriculture Commissioner Jim Hightower makes out a case to explain how \"technology happens\". He writes: \"Take cars. After Henry Ford began mass production, it took only a flash in time for these four-wheeled chunks of technology to wholly transform our landscape, environment, economy, culture, psychology, and ... well, pretty much our whole world. For better or worse, cars created freeways, shopping malls, McDonald's, drive-in banking -- even the Beach Boys!\" Hightower argues: \"A new wave of technology is sweeping the land. It is embodied in the tiny chips (and the computers they power) that are radically and rapidly transforming our world -- and, like the automobile, not always for the better.\"\n\nHe also contends that the story of the \"dark side of the chip\" needs to be \"told and retold\" across the \"global village\" before it is too late to do anything about it.\n\nThe book narrates the story of how the high-tech industry grew in the \"Valley of Heart's Delight\" (before the place got renamed to Silicon Valley) and how Santa Clara Valley fruit-processing workers such as Alida Hernandez got reinvented into \"clean room\" workers. This \"deplorable pattern is still being replicated around the world\".\n\nThe book contains stories about electronic workers suffering toxic exposures and fighting over it. From the Southwestern US and the Maquiladora region on the Mexico–United States border, to Malaysia, Taiwan, Thailand, China, and India.\n\nThe book argues that \"far too (words) have been addressed to the downside of the (electronics industry's) revolution\". Its co-editors, in a signed article titled \"The Quest for Sustainability and Justice in a High-Tech World\", say: \"Although most consumers are eager to enjoy their latest electronic games, few relate the declining prices of these and other electronic technologies to the labor of Third World women, who are paid pennies a day.\"\n\nOther issues focused on by the co-editors include environmental degradation, occupational health hazards, and the \"widespread ignorance\" of the \"health and ecological footprints of the global electronics industry\".\n\nThere are problems of contamination by hi-tech manufacturing (of workers, air, land and water) from all around -- Silicon Valley in the United States, Silicon Glen in Scotland, Silicon Island in Thailand, and Silicon Paddy in China. It contrasts the reality between the \"CEOs and upper management\" drawing \"multimillion dollar salaries and 'golden parachutes'\" as against the reality of the production workers living in packed dormitories and often facing sweatshop conditions.\n\nWhile acknowledging the work of the hi-tech revolution pioneers, the book's editors also points to the \"accomplishments of the unsung heroines and heroes of this revolution's other side\". Including Santa Clara Center for Occupational Safety and Health founder Amanda Hawes; San Jose, California housewife Lorraine Ross, who battled against Fairchild Semiconductor Corporation's polluting practices in Silicon Valley; Thai occupational health physician Orapan Metadilogkul who confronted Seagate Corporation; and Scottish semiconductor worker Helen Clark \"who gave her life fighting to provide a voice for poisoned workers of National Semiconductor's plant in Silicon Glen\".\n\nIts editors say the book has \"two geographical frames of reference\"—the vicinity of San Jose, California (or, Silicon Valley), and \"parts of the world increasingly integrated into global networks of electronics production, consumption, and disposal\". The volume looks at three \"broad, integrative themes\": the globalization of electronics manufacturing; labor rights and environmental justice; and the product end-of-life cycle issues (e-waste, and extended producer responsibility).\n\nIn terms of global electronics, the book focuses on Silicon Valley (where the United States electronics industry's roots lie, and which has a three-decade history of community and worker dialog and struggle). It also looks at electronics manufacturing in China, India, Thailand, and Central and Eastern Europe.\n\nIn terms of labor rights and \"environmental justice\", the book looks at the stories of workers and environmentalists taking up such issues -- \"work hazards, antiunion hostility, and environmental health perils\"—in countries that range from the United States, to Mexico, Scotland, and Thailand, among others.\n\nE-waste issues get looked at in the context of trading or dumping from the North to South. \"But as nations like India and China increasingly modernize, their own industries and consumers are contributing to the problems as well,\" says the editors.\n\nThey argue that while the electronics industry leaders have produced \"enormous technical innovation over the years\", they have failed to keep \"sufficient pace with the socially and environmentally oriented advances that are available to them.\" In their chapter titled \"The Quest for Sustainability\", the co-editors suggest that sustainability, environmental justice and labor rights \"cannot lie solely in the hands of either the social movements or the captains of industry or the representatives of the state\". Instead, it suggests, all citizens and stakeholders must play a role in shaping the industry, its workers, and the environment wherever communities get affected.\n\nSays an introduction to its contents: \"Of the millions of words written over the past several decades about the electronics industry's incredible transformation of our world, far too few have been addressed (to) the downside of this revolution. Many are surprised to learn that environmental degradation and occupational health hazards are as much a part of high-tech manufacturing as miniaturization and other such marvels\".\n\nThe editors also comment: \"Although most consumers are eager to enjoy their latest computers, televisions, cellular phones, iPods, and electronic games, few relate the declining prices of these and other electronic technologies to the labor of Third World women, who are paid pennies a day. Fewer still realize that the amazingly powerful microprocessors and superminiaturized, high-capacity memory devices harm the workers who produce them and pollute the surrounding communities' air and water\".\n\nSandra Steingraber calls this book \"essential reading for anyone who owns a cell phone or a computer\" and says \"our digital possessions connect us not only to global information but also to global contamination and injustice\". Nicholas Ashford calls the work \"an impressive, comprehensive critique and hopeful, but realistic, blueprint for transforming the global electronics industry into a sustainable one encompassing technological advance, environmental improvement, and equitable, safe, and secure employment\". Jan Mazurek says that \"contrary to high tech's clean image, this pioneering work illustrates the industry's environmental and economic downsides from the birthplace of Silicon Valley to the four corners of the globe to which the industry recently has spread\". Mazurek comments that this book is \"told from the compelling and passionate perspective of workers and activists involved in these struggles\".\n\nChapters of the book cover \"Made in China\" electronics workers, Thailand's electronic sector's corporate social responsibility, electronic workers in India, workers in and around Central and Eastern Europe's semiconductor plants (Russia, Belarus, Slovakia, Czech Republic, Poland and Romania), Silicon Valley's Toxics' Coalition and workers' struggles, Mexico, Taiwan's Hsinchu Science Park, other issues from Taiwan, high-tech pollution in Japan, the electronic waste trade, e-waste in Delhi, producer responsibility laws in Sweden and Japan, among other themes.\n\n\nhttp://www.temple.edu/tempress/titles/1788_reg.html\nhttp://www.temple.edu/tempress/titles/1788_reg.html \n"}
{"id": "16659275", "url": "https://en.wikipedia.org/wiki?curid=16659275", "title": "Cosmo Oro", "text": "Cosmo Oro\n\nCosmo Oro (subtitle: \"Classici della Fantascienza\", \"science fiction classics\") was a series of science fiction books published in Italy by Editrice Nord starting from October 1970, usually consisting of re-prints. Authors translated (often with greater care for translation than in previous editions) included science fiction writers such as Philip K. Dick, Jack Vance, Robert A. Heinlein, Frank Herbert, Isaac Asimov, John Brunner, Alfred E. van Vogt and many others. \n\n\"Cosmo Oro\" was paired by \"Cosmo Argento\", which normally published works previously unpublished in Italy. The series reduced substantially in quality and frequency of publication in the 2000s, and ceased publication with issue #203 in April 2002 (\"The Andromeda Strain\" by Michael Crichton).\n"}
{"id": "43857677", "url": "https://en.wikipedia.org/wiki?curid=43857677", "title": "Critical military studies", "text": "Critical military studies\n\nCritical Military Studies is a new academic sub-discipline which brings critical theory to the study of military institutions and practices. It intersects with many academic disciplines, such as international relations, political science, gender studies, human geography and anthropology. Academic conferences in 2013 and 2014 have included panels on Critical Military Studies. The sub-discipline also has a new academic journal published by Taylor and Francis. Scholarship on Critical Military Studies includes issues such as military recruitment and military landscapes. Critical Military Studies is particularly concerned with how understandings of gender and sexuality shape military practices and research on the military.\n"}
{"id": "15448406", "url": "https://en.wikipedia.org/wiki?curid=15448406", "title": "Deadline (science fiction story)", "text": "Deadline (science fiction story)\n\n\"Deadline\" is a 1944 science fiction short story by American writer Cleve Cartmill, first published in \"Astounding Science Fiction\". The story described the then-secret atomic bomb in some detail. At that time the bomb was still under development and top secret, which prompted a visit by the FBI.\n\nIn 1943, Cartmill suggested to John W. Campbell, the then-editor of \"Astounding\", that he could write a story about a futuristic super-bomb. Campbell liked the idea and supplied Cartmill with considerable background information gleaned from unclassified scientific journals, on the use of Uranium-235 to make a nuclear fission device. The resulting story appeared in the issue of \"Astounding\" dated March 1944, which actually appeared early in February of that year.\n\nBy March 8 it had come to the attention of the Counterintelligence Corps, who saw many similarities between the technical details in the story and the research currently being undertaken in great secrecy at Los Alamos. Gregory Benford describes the incident as told to him by Edward Teller in his autobiographical essay \"Old Legends\":\n\nComing three years later in the same magazine, Cleve Cartmill's \"Deadline\" provoked astonishment in the lunch table discussions at Los Alamos. It really did describe isotope separation and the bomb itself in detail, and raised as its principal plot pivot the issue the physicists were then debating among themselves: should the Allies use it? To the physicists from many countries clustered in the high mountain strangeness of New Mexico, cut off from their familiar sources of humanist learning, it must have seemed particularly striking that Cartmill described an allied effort, a joint responsibility laid upon many nations. <br>\nDiscussion of Cartmill's \"Deadline\" was significant. The story's detail was remarkable, its sentiments even more so. Did this rather obscure story hint at what the American public really thought about such a superweapon, or would think if they only knew? <br>\nTalk attracts attention, Teller recalled a security officer who took a decided interest, making notes, saying little. In retrospect, it was easy to see what a wartime intelligence monitor would make of the physicists' conversations. Who was this guy Cartmill, anyway? Where did he get these details? Who tipped him to the isotope separation problem? \"and that is why Mr. Campbell received his visitors.\"\n\nFearing a security breach, the FBI began an investigation into Cartmill, Campbell, and some of their acquaintances (including Isaac Asimov and Robert A. Heinlein). It appears that the authorities eventually accepted the explanation that the story's material had been gleaned from unclassified sources, but as a precautionary measure they requested that Campbell should not publish any further stories about nuclear technology for the remainder of the war.\n\nCampbell, in the meantime, had guessed from the number of \"Astounding\" subscribers who had suddenly moved to the Los Alamos area, that the US government probably had some sort of technical or scientific project ongoing there. He declined to volunteer this information to the FBI.\n\n\"Deadline\" was described by Robert Silverberg as \"a klutzy clunker\" and by Cartmill himself as \"that stinker\". According to Silverberg, Cartmill also used the phrase \"it stinks\" when describing the story to a postman who was acting as an informer for military intelligence.\n\nHowever, the story was included in the anthologies \"The Best of Science Fiction\" (1946; ed. Groff Conklin), \"Science Fiction of the Forties\" (1978; ed. Joseph Olander, Martin Harry Greenberg, and Frederik Pohl), \"The Golden Age of Science Fiction\" (1980; ed. Groff Conklin), and \"The Great Science Fiction Stories: Volume 6, 1944\" (1981; ed. Isaac Asimov and Martin H. Greenberg), which suggests that these noted editors considered it as having some merit.\n\n"}
{"id": "23720950", "url": "https://en.wikipedia.org/wiki?curid=23720950", "title": "Delimitative aspect", "text": "Delimitative aspect\n\nThe delimitative aspect is a grammatical construct that indicates that a situation lasts only a certain amount of time. It is sometimes called \"durative aspect\". Polish: \"stałem i gadałem\" - \"I stood and chatted\" compared with \"postałem i pogadałem\" = \"I stood and chatted for a while\" (the prefix \"po-\" marking the delimitative aspect in this example).\n\nDelimitative aspect in Chinese is often marked by reduplication of the verb. For details see Chinese grammar → Aspects.\n"}
{"id": "33891046", "url": "https://en.wikipedia.org/wiki?curid=33891046", "title": "Disease gene identification", "text": "Disease gene identification\n\nDisease gene identification is a process by which scientists identify the mutant genotypes responsible for an inherited genetic disorder. Mutations in these genes can include single nucleotide substitutions, single nucleotide additions/deletions, deletion of the entire gene, and other genetic abnormalities.\n\nKnowledge of which genes (when non-functional) cause which disorders will simplify diagnosis of patients and provide insights into the functional characteristics of the mutation. The advent of modern-day high-throughput sequencing technologies combined with insights provided from the growing field of genomics is resulting in more rapid disease gene identification, thus allowing scientists to identify more complex mutations.\n\nDisease gene identification techniques often follow the same overall procedure. DNA is first collected from several patients who are believed to have the same genetic disease. Then, their DNA samples are analyzed and screened to determine probable regions where the mutation could potentially reside. These techniques are mentioned below. These probable regions are then lined-up with one another and the overlapping region should contain the mutant gene. If enough of the genome sequence is known, that region is searched for candidate genes. Coding regions of these genes are then sequenced until a mutation is discovered or another patient is discovered, in which case the analysis can be repeated, potentially narrowing down the region of interest. \nThe differences between most disease gene identification procedures are in the second step (where DNA samples are analyzed and screened to determine regions in which the mutation could reside).\n\nWithout the aid of the whole-genome sequences, pre-genomics investigations looked at select regions of the genome, often with only minimal knowledge of the gene sequences they were looking at. Genetic techniques capable of providing this sort of information include Restriction Fragment Length Polymorphism (RFLP) analysis and microsatellite analysis.\n\nLoss of heterozygosity (LOH) is a technique that can only be used to compare two samples from the same individual. LOH analysis is often used when identifying cancer-causing oncogenes in that one sample consists of (mutant) tumor DNA and the other (control) sample consists of genomic DNA from non-cancerous cells from the same individual. RFLPs and microsatellite markers provide patterns of DNA polymorphisms, which can be interpreted as residing in a heterozygous region or a homozygous region of the genome. Provided that all individuals are affected with the same disease resulting from a manifestation of a deletion of a single copy of the same gene, all individuals will contain one region where their control sample is heterozygous but the mutant sample is homozygous - this region will contain the disease gene.\n\nWith the advent of modern laboratory techniques such as High-throughput sequencing and software capable of genome-wide analysis, sequence acquisition has become increasingly less expensive and time-consuming, thus providing significant benefits to science in the form of more efficient disease gene identification techniques.\n\nIdentity by descent (IBD) mapping generally uses single nucleotide polymorphism (SNP) arrays to survey known polymorphic sites throughout the genome of affected individuals and their parents and/or siblings, both affected and unaffected. While these SNPs probably do not cause the disease, they provide valuable insight into the makeup of the genomes in question. A region of the genome is considered identical by descent if contiguous SNPs share the same genotype. When comparing an affected individual to his/her affected sibling, all identical regions are recorded (ex. Shaded in red in above figure). Given that an affected sibling and an unaffected sibling do not have the same disease phenotype, their DNA must by definition be different (barring the presence of a genetic or environmental modifier). Thus, the IBD mapping results can be further supplemented by removing any regions that are identical in both affected individuals and unaffected siblings. This is then repeated for multiple families, thus generating a small, overlapping fragment, which theoretically contains the disease gene.\n\nHomozygosity/Autozygosity mapping is a powerful technique, but is only valid when searching for a mutation segregating within a small, closed population. Such a small population, possibly created by the founder effect, will have a limited gene pool, and thus any inherited disease will probably be a result of two copies of the same mutation segregating on the same haplotype. Since affected individuals will probably be homozygous in the regions, looking at SNPs in a region is an adequate marker of regions of homozygosity and heterozygosity. Modern day SNP arrays are used to survey the genome and identify large regions of homozygosity. Homozygous blocks in the genomes of affected individuals can then be laid on top of each other, and the overlapping region should contain the disease gene.\n\nThis analysis is often extended by analyzing autozygosity, an extension of homozygosity, in the genomes of affected individuals. This can be accomplished by plotting a cumulative LOD score alongside the overlaid blocks of homozygosity. By taking into consideration the population allele frequencies for all SNPs via autozygosity mapping, the results of homozygosity can be confirmed. Furthermore, if two suspicious regions appear as a result of homozygosity mapping, autozygosity mapping may be able to distinguish between the two (ex. If one block of homozygosity is a result of a very non-diverse region of the genome, the LOD score will be very low).\n\nTools for Homozygosity Mapping\n\nGenome-wide knockdown studies are an example of the reverse genetics made possible by the acquisition of whole genome sequences, and the advent of genomics and gene-silencing technologies, mainly siRNA and deletion mapping. Genome-wide knockdown studies involve systematic knockdown or deletion of genes or segments of the genome. This is generally done in prokaryotes or in a tissue culture environment due to the massive number of knockdowns that must be performed. After the systematic knockout is completed (and possibly confirmed by mRNA expression analysis), the phenotypic results of the knockdown/knockout can be observed. Observation parameters can be selected to target a highly specific phenotype. The resulting dataset is then be queried for samples which exhibit phenotypes matching the disease in question – the gene(s) knocked down/out in said samples can then be considered candidate disease genes for the individual in question.\n\nWhole exome sequencing is a brute-force approach that involves using modern day sequencing technology and DNA sequence assembly tools to piece together all coding portions of the genome. The sequence is then compared to a reference genome and any differences are noted. After filtering out all known benign polymorphisms, synonymous changes, and intronic changes (that do not affect splice sites), only potentially pathogenic variants will be left. This technique can be combined with other techniques to further exclude potentially pathogenic variants should more than one be identified.\n\n"}
{"id": "47203681", "url": "https://en.wikipedia.org/wiki?curid=47203681", "title": "EUROfusion", "text": "EUROfusion\n\nEUROfusion is a consortium of national fusion research institutes located in the European Union, Switzerland and the Ukraine. It was established in 2014 to succeed the European Fusion Development Agreement (EFDA) as the umbrella organisation of Europe's fusion research laboratories. The consortium is currently funded by the Euratom Horizon 2020 programme.\n\nThe EUROfusion consortium agreement has been signed by 30 research organisations and universities from 26 European Union countries plus Switzerland and Ukraine.\nThe EUROfusion's Programme Management Unit offices located in Garching, near Munich (Germany), are hosted by the Max Planck Institute of Plasma Physics (IPP). The IPP is also the seat for the co-ordinator of EUROfusion.\n\nEUROfusion funds fusion research activities in accordance with the Roadmap to the realisation of fusion energy. The Roadmap outlines the most efficient way to realise fusion electricity by 2050. Research carried out under the EUROfusion umbrella aims to prepare for ITER experiments and develop concepts for the fusion power demonstration plant DEMO. EUROfusion is in charge of the fusion-related research carried out at JET, the Joint European Torus, which is housed in the Culham Centre for Fusion Energy, UK. Other fusion devices in Europe that devote some amount of time towards research under the EUROfusion framework include the following: \n"}
{"id": "1300903", "url": "https://en.wikipedia.org/wiki?curid=1300903", "title": "Ecosystem valuation", "text": "Ecosystem valuation\n\nEcosystem valuation is an economic process which assigns a value (either monetary, biophysical, or other) to an ecosystem and/or its ecosystem services. By quantifying, for example, the human welfare benefits of a forest to reduce flooding and erosion while sequestering carbon, providing habitat for endangered species, and absorbing harmful chemicals, such monetization ideally provides a tool for policy-makers and conservationists to evaluate management impacts and compare a cost-benefit analysis of potential policies. However, such valuations are estimates, and involve the inherent quantitative uncertainty and philosophical debate of evaluating a range non-market costs and benefits.\n\nCost-benefit analyses and the generation of market value have existed within the economic literature for centuries. However, in 1997, Robert Costanza, Distinguished University Professor of sustainability at Portland State University, Oregon, was the first to estimate the worldwide worth of ecosystem services—bringing new attention to the field of ecosystem valuation. He and his colleagues calculated that such services were worth $33 trillion annually ($44 trillion present dollars).\n\nDespite Costanza's fanfare, the World Bank, three decades later, that \"the benefits provided by natural ecosystems are both widely recognized and poorly understood.”\n\nCiting the importance of such knowledge to informed policy-making, in 2007, Environmental Ministers from the G8 + 5 nations agreed to both publicly call for and begin to undertake the calculation of global ecosystem benefits, conservation costs, and the opportunity costs of developing such ecosystems. The resulting watershed initiative and ongoing project is The Economics of Ecosystems and Biodiversity (TEEB).\n\nIn the United States, the President's Council on Science and Technology suggested in 2011 that the “U.S. government should institute and fund a Quadrennial Ecosystems Services Trends (QuEST) Assessment” that studying trends in ecosystem performance, quality, and value.\n\nEcosystem valuation attempts to capture the range of benefits and costs contained within a complicated natural web with a range of economic methodologies.\n\nEcological systems provide four general categories of services: provisioning (e.g. fish to eat, timber to sell), regulatory, supporting, and cultural (e.g. ecosystems supporting indigenous gathering techniques, or supplies for traditional clothing). See Figure 1. for a mangrove-specific example of this complex subject.\nThese four types of services can then provide two basic categories of value: the use and use and non-use categories. Environmental economists have further separated categorizes for which individuals are willing to pay:\nGiven these types of potential ecological values, economists utilize a variety of methods to calculate those market values and measure non-market values. Standard environmental economic methods are used to place a monetary value on ecosystem services where there are no market prices. These include \"stated preference\" methods and \"revealed preference\" methods. Stated preference methods, such as the contingent valuation method ask people for their willingness to pay for a certain ecosystem (service). Revealed preference methods, such as hedonic pricing and the travel cost method, use a relation with a market good or service to estimate the willingness-to-pay for the service. Applying such preference based approaches has been criticized as a means of deriving the value of ecosystems and biodiversity and for avoiding deliberation, justification and judgment in making choices.\n\nWhile the literature is still emerging, many important studies have resulting in striking valuations.\n\nOne academic paper by de Groot et. al., which synthesized more than 300 scholarly works collectively evaluating the 10 main biomes, \"shows that the total value of ecosystem services is considerable and ranges between 490 int$/year for the total bundle of ecosystem services that can potentially be provided by an ‘average’ hectare of open oceans to almost 350,000 int$/year for the potential services of an ‘average’ hectare of coral reefs.\" This potential benefit can take many forms depending on the degree of exploitation and such exploitation's sustainability, but can result, for example, in large ecotourist revenues for local communities, protection from storm destruction, or profit for an international lumber company.\n\nFurthermore, de Groot et. al. find that most of their paper's calculated value is \"outside the market and best considered as non-tradable public benefits. The continued over-exploitation of ecosystems thus comes at the expense of the livelihood of the poor and future generations.\"\n\nThe Economics of Ecosystems and Biodiversity (TEEB), in one of its first large, cumulative reports, also found that ecosystem services start at roughly $100/hectare/year for open ocean, and top off to more than $1,000,000/hectare/year for the most lucrative coral reefs.\n\nBeyond biome \"price tags,\" these environmental valuations can explore quite complex policy questions. For example, the Copenhagen Consensus think tank calculated that stemming the loss of coral reefs by 50 percent by 2030 would return more than $24 for every dollar spent. The Consensus' founder, Bjorn Lomborg, explains that \"coral reefs, which both act as fishery hatcheries and fishing resources while storing abundant numbers of species. At the same time, coral reefs possess an amazing beauty, which both shows up in large tourism revenues but also in most individuals saying they are willing to pay a certain amount to make sure they continue to exist for our grand children. … [Programs to preserve 50% more coral reef by 2030] cost about $3 billion per year but the total benefits likely run to at least $72, or about $24 dollars back for every dollar invested.\"\n\nAs another example, the National Oceanic and Atmospheric Administration (NOAA) manages the Integrated Valuation Environmental Services and Tradeoffs (InVEST) Natural Capital Project. This open-source tool—although geared towards policy-makers, advocates, and scientists—allows anyone to interact with a map quantifying \"trade offs between alternative management choices\" and identifying \"areas where investment in natural capital can enhance human development and conservation.”\n\nAfter (and, sometimes, before) evaluating the ecosystem costs and benefits, some programs have attempted to internalize those values with specific programs providing payments for environmental services. Costa Rica paid about $42/hectare for landowners to preserve forests; in 2010 Norway began paying Indonesia a total of $1 billion to mitigate deforestation; China responded to 1998 floods with payments targeting deforestation and soil erosion; and many other programs large and small.\n\nFrom an academic perspective, although scholarly research is quite rapidly adding to this field of understanding, many knowledge gaps still remain. For example, there is an inherent uncertainty in attempting to quantify non-market goods. As pointed to by de Groot et. al., many environmental goods (such as clean air and biodiversity) are simply not traded in established markets. In addition, many environmental goods may be non-rival, non-excludable, and even inseparable goods with multiple value options further complicating any valuation.\n\nFrom an ethical and philosophical perspective, too, ecosystem valuation is far from uncontroversial. Arguments about the non-market valuation of ecosystem can be found by referring to environmental ethics and deep ecology.\n\nSince animals do not put explicit prices on ecosystems they use, but do behave as if they are valuable, e.g. by selecting one territory vs. another, defending their territories, etc., it is mostly a matter of definition whether ecology should include valuation as an issue. It may be anthropocentric to do so, since \"valuation\" more clearly refers to a human perception rather than being an \"objective\" attribute of the system perceived. Ecology itself is also human perception, and such related concepts as a food chain are constructed by humans to help them understand ecosystems. In many cases by those who hold that markets and pricing exist independently of any individual human observers and \"users\", and especially those who deem markets to be \"out of control\", ecosystem valuation is considered a (marginal, ignored) part of economics. Others argue that natural capital is an economic concept that is at least as viable as financial capital, which itself is determined on subjective valuation. Some even suggest that valuation of ecosystem services is more cogent than financial valuation, as the ecosystem would continue after the collapse of the economy, while the inverse is not valid.\n\nIn addition, many fascinating questions about where ecosystem benefits go, and who should pay for those benefits, is an ongoing political debate. In one Washington city, residents now pay a water bill in order for the town to buy and restore land adjacent to the municipal water source; and international examples of evaluating and paying for services is no less a fascinating field of ongoing development.\n\n\n\n"}
{"id": "20368427", "url": "https://en.wikipedia.org/wiki?curid=20368427", "title": "Edge Foundation, Inc.", "text": "Edge Foundation, Inc.\n\nThe Edge Foundation, Inc. is an association of science and technology intellectuals created in 1988 as an outgrowth of The Reality Club. Its main activities are reflected on the edge.org website, edited by publisher and businessman John Brockman. The site is a critically noted online magazine exploring scientific and intellectual ideas.\n\nA long-running feature on Edge is the Annual Question, which gathers many short essays on topical questions from Brockman's broad network of thought leaders in philosophy and science; these essays are usually published collectively as a book shortly thereafter.\n\nMany of the feature articles on Edge are structured as video interviews with a prominent figure in some scientific field (such as Daniel Kahneman or Steven Pinker) discussing his or her recent research or mental preoccupations, in a free-flowing spiel from which the interviewer—often Brockman himself—is largely absent. This is usually accompanied by a full transcript which includes more material than the video portion (which is typically edited for brevity, down to less than an hour in length).\n\nBecause Brockman functions primarily as a literary agent, subjects featured on Edge are in most cases lucid communicators, even when relating new developments in highly specialized research areas. The lucid exposition of challenging and novel science is Edge's primary calling card.\n\nA less common format is video conference proceedings or Master Class round-table seminars on a set subject matter, such as Philip E. Tetlock's seminar on superforecasting from 2015, or Richard Thaler's seminar on behavioural psychology from 2008.\n\nEdge adds new content relatively infrequently, with no set schedule, apart from the Annual Question.\n\n\"The Third Culture\" is the growing movement towards (re)integration of literary and scientific thinking and is a nod toward British scientist C. P. Snow's concept of the two cultures of science and the humanities. John Brockman published a book of the same name whose themes are continued at the Edge website. Here, scientists and others are invited to contribute their thoughts in a manner readily accessible to non-specialist readers. In doing so, leading thinkers are able to communicate directly with each other and the public without the intervention of middlemen such as journalists and journal editors.\n\nMany areas of academic work are incorporated, including genetics, physics, mathematics, psychology, evolutionary biology, philosophy and computing technology.\n\nEdge poses its members an annual question:\n\n\n, contributors included Anthony Aguirre, Stephon Alexander, John Allen Paulos, Adam Alter, Alun Anderson, Ross Anderson, Samuel Arbesman, Scott Atran, Mahzarin Banaji, Samuel Barondes, Thomas Bass, Sue Blackmore, Paul Bloom, Giulio Boccaletti, Stefano Boeri, Nick Bostrom, Stewart Brand, David Buss, William Calvin, Nicholas Carr, Sean M. Carroll, Joan Chiao, Nicholas Christakis, George M. Church, Andy Clark, Gregory Cochran, Alana Conner, James Croak, Fiery Cushman, Scott D. Sampson, W. Daniel Hillis, Satyajit Das, Richard Dawkins, Aubrey De Grey, Daniel Dennett, Emanuel Derman, Keith Devlin, Rolf Dobelli, George Dyson, David Eagleman, Brian Eno, Juan Enriquez, Dylan Evans, Christine Finn, Stuart Firestein, Helen Fisher, Susan Fiske, Tecumseh Fitch, Richard Foreman, Howard Gardner, Amanda Gefter, David Gelernter, Neil Gershenfeld, Gerd Gigerenzer, Marcelo Gleiser, Joel Gold, Nigel Goldenfeld, Rebecca Goldstein, Daniel Goleman, Beatrice Golomb, Alison Gopnik, Joshua Greene, Jonathan Haidt, Diane Halpern, Kevin Hand, Haim Harari, Sam Harris, Marti Hearst, Roger Highfield, Donald D. Hoffman, Gerald Holton, Bruce Hood, Nicholas Humphrey, Marco Iacoboni, Jennifer Jacquet, Xeni Jardin, Daniel Kahneman, Paul Kedrosky, Kevin Kelly, Douglas Kenrick, Christian Keysers, Vinod Khosla, Marcel Kinsbourne, Jon Kleinberg, Brian Knutson, Bart Kosko, Kai Krause, Lawrence Krauss, Andrian Kreye, Rob Kurzban, George Lakoff, Jaron Lanier, Jonah Lehrer, Garrett Lisi, Seth Lloyd, Tania Lombrozo, Stephen M. Kosslyn, Gary Marcus, Hazel Rose Markus, John McWhorter, Thomas Metzinger, Geoffrey Miller, Evgeny Morozov, P.Z. Myers, David Myers, Richard Nisbett, Tor Norretranders, Gloria Origgi, Neri Oxman, Carl Page, Mark Pagel, Greg Paul, Irene Pepperberg, Clifford Pickover, Steven Pinker, David Pizarro, Ernst Pöppel, Robert Provine, V.S. Ramachandran, Lisa Randall, Martin Rees, Andrew Revkin, Matt Ridley, Matthew Ritchie, Jay Rosen, Carlo Rovelli, David Rowan, Rudy Rucker, Douglas Rushkoff, Paul Saffo, Eduardo Salcedo-Albaran, Robert Sapolsky, Dimitar Sasselov, Richard Saul Wurman, Roger Schank, Kathryn Schulz, Gino Segre, Charles Seife, Terrence Sejnowski, Martin Seligman, Michael Shermer, Clay Shirky, Gerald Smallberg, Laurence C. Smith, Lee Smolin, Dan Sperber, Tom Standage, Victoria Stodden, Linda Stone, Nassim Taleb, Don Tapscott, Max Tegmark, Richard Thaler, John Tooby, Eric Topol, Hans-Ulrich Obrist, J. Craig Venter, Eric Weinstein, Frank Wilczek, Dave Winer, Milford Wolpoff, Carl Zimmer, and Jason Zweig.\n\n"}
{"id": "1666249", "url": "https://en.wikipedia.org/wiki?curid=1666249", "title": "Euclid number", "text": "Euclid number\n\nIn mathematics, Euclid numbers are integers of the form , where \"p\"# is the \"n\"th primorial, i.e. the product of the first \"n\" prime numbers. They are named after the ancient Greek mathematician Euclid, in connection with Euclid's theorem that there are infinitely many prime numbers.\n\nFor example, the first three primes are 2, 3, 5; their product is 30, and the corresponding Euclid number is 31.\n\nThe first few Euclid numbers are 3, 7, 31, 211, 2311, 30031, 510511, 9699691, 223092871, 6469693231, 200560490131, ... .\n\nIt is sometimes falsely stated that Euclid's celebrated proof of the infinitude of prime numbers relied on these numbers. Euclid did not begin with the assumption that the set of all primes is finite. Rather, he said: consider any finite set of primes (he did not assume that it contained only the first \"n\" primes, e.g. it could have been ) and reasoned from there to the conclusion that at least one prime exists that is not in that set.\nNevertheless, Euclid's argument, applied to the set of the first \"n\" primes, shows that the \"n\"th Euclid number has a prime factor that is not in this set.\n\nNot all Euclid numbers are prime.\n\"E\" = 13# + 1 = 30031 = 59 × 509 is the first composite Euclid number.\n\nEvery Euclid number is congruent to 3 mod 4 since the primorial of which it is composed is twice the product of only odd primes and thus congruent to 2 modulo 4. This property implies that no Euclid number can be a square.\n\nFor all the last digit of \"E\" is 1, since is divisible by 2 and 5. In other words, since all primorial numbers greater than \"E\" have 2 and 5 as prime factors, they are divisible by 10, thus all \"E\"+1 have a final digit of 1.\n\nIt is not known whether there is an infinite number of prime Euclid numbers (primorial primes).\nIt is also unknown whether every Euclid number is a squarefree number.\n\nA Euclid number of the second kind (also called Kummer number) is an integer of the form \"E\" = \"p\"# − 1, where \"p#\" is the nth primorial. The first few such numbers are:\n\nAs with the Euclid numbers, it is not known whether there are infinitely many prime Kummer numbers. The first of these numbers to be composite is 209.\n\n"}
{"id": "1242793", "url": "https://en.wikipedia.org/wiki?curid=1242793", "title": "Flat Eric", "text": "Flat Eric\n\nFlat Eric is a fictional puppet character created by Quentin Dupieux from Levi's commercials for Sta-Prest One Crease Denim Clothing, built by Jim Henson's Creature Shop. His name comes from an idea for a commercial that included having a car run over his head and flattening it. The idea was not used, but the name stuck. In the commercials, Flat Eric would ride with his friend Angel (played by Philippe Petit) around California, evading the police as a wanted criminal.\n\nFlat Eric was based on a puppet called Stéphane that was similar, but with ears and the hands were fixed. Stéphane appeared in some short films by Mr. Oizo (including a video for the track M-Seq), and had a small cult following in the United Kingdom and France. In 1999, Levi's decided to build a television commercial campaign around the puppet, to be directed by Oizo. The character was renamed Eric, a more \"international name\", in contrast to the original French name Stéphane.\n\nHe was made by Janet Knechtel for Jim Henson's Creature Shop, in the United Kingdom, and was performed by Drew Massey for all the Levi's commercials. The Levi's adverts took three days to shoot. The original short films made with Stéphane cost around 15,000 francs to produce. The two Levi's ads cost around two or three million francs each. The rights to the character were retained by Oizo and production company Partizan.\n\nHe was featured in the music video for \"Flat Beat\" by French musician Mr. Oizo and he also appeared as a prop in Series 1 of the 2001 to 2003 BBC comedy \"The Office\". In August 2004, he co starred with David Soul, in a five million pound television advert for \"Auto Trader\". He has also appeared on \"The Big Breakfast\". The puppet also featured heavily as a prop for more than ten years on SIC Radical interactive chat show \"Curto Circuito\", being usually named as \"Boneco Amarelo\" (Portuguese for \"Yellow Puppet\").\n\nFlat Eric has also been featured in many magazines, including \"Arena\", \"Cosmopolitan\", \"Heat\", \"Melody Maker\", \"Ministry\", \"Mixmag\", \"Muzik\", \"NME\" and \"The Face\".\n\nFlat Eric appears as an unlockable character in the game \"Crossy Road\".\n\n"}
{"id": "1091018", "url": "https://en.wikipedia.org/wiki?curid=1091018", "title": "Gas electron diffraction", "text": "Gas electron diffraction\n\nGas electron diffraction (GED) is one of the applications of electron diffraction techniques. The target of this method is the determination of the structure of gaseous molecules i.e. the geometrical arrangement of the atoms from which a molecule is built up.\n\nDiffraction occurs because the wavelength of electrons accelerated by a potential of a few thousand volts is of the same order of magnitude as internuclear distances in molecules. The principle is the same as that of other electron diffraction methods such as LEED and RHEED, but the obtainable diffraction pattern is considerably weaker than those of LEED and RHEED because the density of the target is about one thousand times smaller. Since the orientation of the target molecules relative to the electron beams is random, the internuclear distance information obtained is one-dimensional. Thus only relatively simple molecules can be completely structurally characterized by electron diffraction in the gas phase. It is possible to combine information obtained from other sources, such as rotational spectra, NMR spectroscopy or high-quality quantum-mechanical calculations with electron diffraction data, if the latter are not sufficient to determine the molecule's structure completely. \n\nThe total scattering intensity in GED is given as a function of the momentum transfer, which is defined as the difference between the wave vector of the incident electron beam and that of the scattered electron beam and has the reciprocal dimension of length. The total scattering intensity is composed of two parts: the atomic scattering intensity and the molecular scattering intensity. The former decreases monotonically and contains no information about the molecular structure. The latter has sinusoidal modulations as a result of the interference of the scattering spherical waves generated by the scattering from the atoms included in the target molecule. The interferences reflect the distributions of the atoms composing the molecules, so the molecular structure is determined from this part.\n"}
{"id": "36168414", "url": "https://en.wikipedia.org/wiki?curid=36168414", "title": "Gemini Docking Mechanism", "text": "Gemini Docking Mechanism\n\nThe Gemini spacecraft was the first American craft that could dock to another in space.\n\nIt used a non-androgynous docking mechanism.\n\nThe docking system was not hollow, so there was no ability to transfer people or material between the craft; the docking system merely locked two craft together.\n\n"}
{"id": "30403380", "url": "https://en.wikipedia.org/wiki?curid=30403380", "title": "Gesellschaft für Didaktik der Mathematik", "text": "Gesellschaft für Didaktik der Mathematik\n\nThe Gesellschaft für Didaktik der Mathematik (GDM) (Society for Didactics of Mathematics) is a scientific society pursuing the goal to foster mathematics education, particularly in German-speaking countries. It seeks cooperation with the respective institutions in other countries.\n\nThe society primarily concerns itself with:\n\nThe GDM consists of the executive board, the general assembly and the advisory board.\n\nCurrently, the executive board consists of:\n\nWithin the GDM there are numerous special interest groups concerned with different topics within mathematics education.\n\nThese special interest groups include: \n\nAll links to the website of each group can be found on the GDM wiki.\n\nMembers generally work at universities or other scientific research groups, or are located in schools, though membership of the GDM is open to anyone interested in mathematics education. In 2011, one year's membership cost 60€ which includes multiple issues of members journals, plus the proceedings of the annual meeting.\n\nThe society holds an annual meeting in Germany — the Tagung für Didaktik der Mathematik.\n\nThe members' journal \"Mitteilungen der GDM\" (Proceedings of the GDM) is published twice a year. The editor is Andreas Vohns, Klagenfurt, on behalf of the executive board.\n\nThe \"Journal für Mathematik-Didaktik\" (\"Journal for Didactics of Mathematics\") is the official organ of the GDM. Published quarterly, it contains original articles from all areas of mathematics education research and development. All articles are peer-reviewed by three anonymous referees. Decisions about the publication and modifications are made by the editorial board. Submissions are open to related sciences (pedagogy, psychology, sociology or philosophy) and neighbour sciences (didactics of science or languages). All articles, however, are related to the teaching and learning of mathematics.\n\nThe GDM is responsible for the annual meeting of the society, the Tagung für Didaktik der Mathematik. The presentations of the conference are published in the series \"Beiträge zum Mathematikunterricht\".\nThe German proceedings were published until 2007 at Verlag Franzbecker and can be ordered online. Starting 2008, they are published by WTM-Verlag, Münster and are available online.\nStarting with the 2005 proceedings an electronic version can be found here.\n\n"}
{"id": "8712474", "url": "https://en.wikipedia.org/wiki?curid=8712474", "title": "Hastings Rarities", "text": "Hastings Rarities\n\nThe Hastings Rarities affair is a case of statistically demonstrated ornithological fraud that misled the bird world for decades in the twentieth century. The discovery of the long-running hoax shocked ornithologists.\n\nThe Hastings Rarities were a series of records of rare birds added to the British list on the basis of hundreds of reports, supported by preserved specimens, from George Bristow (1863–1947), a taxidermist and gunsmith of St Leonards-on-Sea, a town on the south coast of England. His reports were made between 1892 and 1930.\n\nIn August 1962, the statistician John Nelder published an analysis in the journal \"British Birds\", demonstrating that the records were unlikely to be genuine. This was supported by an editorial in the same issue. 29 bird species or subspecies were dropped from the British List. On the basis of later records from elsewhere in Britain, most have subsequently been readmitted.\n\nTwo articles in the August 1962 issue of the journal \"British Birds\", one a statistical examination by John Nelder, the other an editorial by Max Nicholson and James Ferguson-Lees, made a case using several statistical measures that a series of records of birds collected within a radius of Hastings, in Kent and Sussex, south-east England, between 1892 and 1930, should be treated with suspicion. As a result, 29 bird species or subspecies were dropped from the British List (though most of these have subsequent acceptable records from elsewhere in Britain) and 550 records, relating to 80–90 species, were rejected. Although some of these rejected records were undoubtedly good ones, there was no easy way of distinguishing them.\n\nAlthough doubts had been expressed privately for many years about the provenance of many specimens from the Hastings area, until the articles appeared there had been no systematic investigation of the records. The case made in \"British Birds\" was essentially statistical, concerning the unlikelihood of so many records of rare or new species being made within a limited area and limited time period when compared with a similar area and with earlier and later time periods. However, most records recommended for rejection were of specimens that had passed through the hands of George Bristow (1863–1947), a taxidermist and gunsmith of St Leonards-on-Sea in the borough of Hastings.\n\nIt was clear that Bristow was suspected of having been the perpetrator of a series of frauds, carried out from the 1890s over at least the first two, and possibly three, decades of the 20th century, through importing bird specimens from outside the British Isles, and selling them to wealthy ornithologists, such as Walter Rothschild, as having been procured from the Hastings area. John Nelder later estimated that Bristow had made about £7000, a considerable amount of money at the time, from this scheme.\n\nThe deletion of several taxa from the list had considerable repercussions. As the suspect records covered nearly four decades, many had been incorporated into books about birds in Britain, including major ornithological reference works, and there was resistance from some ornithologists to accepting the deletions. David Bannerman, in the late stages of completing his monumental \"The Birds of the British Isles\" (12 vols, 1933–63), decided to maintain his faith in the validity of the controversial Hastings records and ignore the decision to delete them from the list. Since then, most of the species dropped have been readmitted to the list on the basis of reliable subsequent records.\n\nFifty of the rarities are held in the Birmingham Museums Trust natural history collection.\n\n\n"}
{"id": "41409124", "url": "https://en.wikipedia.org/wiki?curid=41409124", "title": "Illusion optics", "text": "Illusion optics\n\nIllusion optics is an electromagnetic theory that can change the optical appearance of an object to be exactly like that of another virtual object, i.e. an illusion, such as turning the look of an apple into that of a banana. Invisibility is a special case of illusion optics, which turns objects into illusions of free space. The concept and numerical proof of illusion optics was proposed in 2009 based on transformation optics in the field of metamaterials. \nIt is a scientific disproof of the idiom 'Seeing is Believing'.\n\nIllusion optics proves that the optical responses or properties of a space containing any objects can be changed to be exactly those of a virtual space but containing arbitrary virtual objects (illusions) by using a passive \"illusion optics device\" composed of materials or metamaterials with specific parameters and shape. For example, a dielectric spoon was numerically shown to exhibit the scattering properties of a metallic cup by using an illusion optics device in the seminal paper.\n\nSuch illusion effects do not rely on the direction and form of incident waves. However, due to dispersion limitation of specific material parameters, the functionality of illusion optics device only works in a narrow band of frequency.\n\nUnlike optical illusions that utilize the misinterpretation of human brain to create illusionary perception different from the physical measurement, illusion optics changes the optical response or properties of objects, i.e. the physical measurements.\n"}
{"id": "1735527", "url": "https://en.wikipedia.org/wiki?curid=1735527", "title": "Kymograph", "text": "Kymograph\n\nA kymograph (from Greek κῦμα, swell or wave + γραφή, writing; also called a kymographion) is a device that draws a graphical representation of spatial position over time in which a spatial axis represents time. It basically consists of a revolving drum wrapped with a sheet of paper on which a stylus moves back and forth recording perceived changes of phenomena such as motion or pressure.\n\nThe kymograph was initially a mechanical and hydraulic device, invented by German physiologist Carl Ludwig in the 1840s, and found its first use as a means to monitor blood pressure. The blood pressure was conveyed by hydraulics and levers to move a stylus that scratched a white trace into soot-covered paper on the revolving drum. Time is represented by the drum's rotation rate, and was recorded by a further stylus driven by a clock or tuning fork. The kymograph almost immediately became the central instrument in physiology and physiology education. Throughout the nineteenth and twentieth centuries, researchers and technicians devised many improvements to the device, plus numerous new sensory components to measure a wide range of physiological phenomena such as breathing, muscle movement, speech. New detection and registration systems included electrical and electronic methods, and plotted in ink.\n\nKymographs were also used outside medical science to measure atmospheric pressure, tuning fork vibrations, the functioning of steam engines, animal habits and the movement of molecules in cells.\n\nKymograph is generally used to study the effects of xenobiotics on tissue preparations. It is a standalone recording apparatus used alongside other apparatus such as organ bath. Writing levers are used to trace the recording from muscle contractions. Some of the commonly used writing levers are simple lever, frontal writing lever and starling heart lever to name a few. These writing levers are connected to a fulcrum which are found on secondary apparatus.\n\n"}
{"id": "20205548", "url": "https://en.wikipedia.org/wiki?curid=20205548", "title": "Leo the Mathematician", "text": "Leo the Mathematician\n\nLeo the Mathematician or the Philosopher ( or ὁ Φιλόσοφος, \"Léōn ho Mathēmatikós\" or \"ho Philósophos\"; c. 790 – after 869) was a Byzantine philosopher and logician associated with the Macedonian Renaissance and the end of the Second Byzantine Iconoclasm. His only preserved writings are some notes contained in manuscripts of Plato's dialogues. He has been called a \"true Renaissance man\" and \"the cleverest man in Byzantium in the 9th century\". He was archbishop of Thessalonica and later became the head of the Magnaura School of philosophy in Constantinople, where he taught Aristotelian logic.\n\nLeo was born in Thessaly, a cousin of the Patriarch of Constantinople, John the Grammarian. He was probably at least in part of Armenian descent. In his youth he was educated at Constantinople, but he travelled to the monasteries of Andros, where he could obtain rare manuscripts and was taught mathematics by an old monk. He originally taught privately in obscurity in Constantinople. The story goes that when one of his students was captured during the Byzantine–Arab Wars, the Caliph al-Mamun was so impressed by his knowledge of mathematics that he offered Leo great riches to come to Baghdad. Leo took the letter from the caliph to the Byzantine emperor Theophilos, who, impressed by his international repute, conferred on him a school (\"ekpaideutērion\") in either the Magnaura or the church of the Forty Martyrs.\n\nIn the version of the story recorded by Theophanes Continuatus, the caliph, upon receiving Leo's letter of refusal, sent a letter requesting answers to some difficult questions of geometry and astrology, which Leo obliged. Al-Mamun then offered two thousands pounds of gold and a perpetual peace to Theophilos, if only he could borrow Leo's services briefly; the request was declined. The emperor then honoured Leo by having John the Grammarian consecrate him metropolitan of Thessalonica, which post he held from the spring of 840 to 843. There is a discrepancy in this account, however, in that the caliph died in 833. It has been suggested that either the connection between the caliph's final letter and Leo's appointment as metropolitan is in error, or the caliph in question was actually al-Mutasim. This latter option squares with the account of Symeon the Logothete, who makes Leo teach at the Magnaura from late 838 to early 840 and was paid handsomely.\n\nLeo, an iconoclast sometimes accused of paganism, lost his metropolitancy with the end of the Iconoclasm in 843. Despite this, he delivered a sermon favourable of icons within months of Theophilos' death. Around 855, Leo was appointed at the head of a newly established Magnaura School by Bardas. He was renowned for his philosophical, mathematical, medical, scientific, literary, philological, astronomic, and astrological learning, and was patronised by Theoktistos and befriended by Photios I of Constantinople. Cyril was his student. Leo has been credited with a system of beacons (an optical telegraph) stretching across Asia Minor from Cilicia to Constantinople, which gave advance warning of Arab raids, as well as diplomatic communication. Leo also invented several automata, such as trees with moving birds, roaring lions, and a levitating imperial throne. The throne was in operation a century later, when Liutprand of Cremona witnessed it during his visit to Constantinople.\n\nMost of Leo's writings have been lost. He wrote book-length works, poems, and many epigrams, and was also a compiler, who brought together a wide range of philosophical, medical, and astronomic texts. His library can at least partially be reconstructed: Archimedes, Euclid, Plato, Paul of Alexandria, Theon of Alexandria, Proclus, Porphyry, Apollonius of Perga, the lost \"Mechanics\" of Quirinus and Marcellus, and possibly Thucydides. He composed his own medical encyclopaedia. Later Byzantine scholars sometimes confused Leo with the scholar Leo Choirosphaktes and the emperor Leo VI the Wise, and ascribe to him oracles.\n\n"}
{"id": "2083594", "url": "https://en.wikipedia.org/wiki?curid=2083594", "title": "Lions Eye Institute", "text": "Lions Eye Institute\n\nThe Lions Eye Institute (LEI) is an Australian medical research institute affiliated with the University of Western Australia. It was established in 1983 with support of the Lions Club of Australia and headquartered in the suburb of , Western Australia. The LEI is a not-for-profit centre of excellence that combines an ophthalmic clinic with scientific discovery developing techniques for the prevention of blindness and the reduction of pain from blinding eye conditions.\n\nAt a 1970 convention in Albany, Western Australia, the Western Australian Lions Clubs created the Lions Save Sight Foundation (WA) Inc. with the aim of leading the development of ophthalmic care. In 1975 the Lions Save-Sight Foundation (LSSF) established the Lions Chair in Ophthalmology at the University of Western Australia. Since its establishment, clinical facilities, new equipment, and research laboratories have been strategically commissioned to support the LEI’s core activities. In 1983, under Ian Constable's guidance, the LEI, a not-for-profit organisation was established. With Constable, the LEI became an international centre for scientific research into blindness. Following its development, it relocated to the grounds of Sir Charles Gairdner Hospital. Its current Managing director David Mackey leads a team of clinicians, medical professionals, researchers and support staff. In 1994, the Institute created in partnership with the University of Western Australia, the Centre for Ophthalmology and Visual Science (COVS). This centre has an independent University status within the Faculty of Medicine and Dentistry. In 2003, the LEI revised its basis of incorporation from a public benevolent charitable institution to a not-for profit limited liability company. \n\nThe LEI employs scientists, clinicians, and support staff to conduct scientific research into blindness with known ophthalmic practices in Australia. The Institute also includes a Laser Vision Centre, Western Australia’s refractive surgery centre; the Lions Eye Bank, Lions Optics and the LSSF. The LEI actively participates in numerous clinical trials for the development of new treatments for eye diseases, in collaboration with scientists, ophthalmologists, and pharmaceutical companies. The Institute receives funds from clinic operations and its grants from organisations such as the National Health and Medical Research Council, individual benefactors and the LSSF.\n\nThe LEI provides a range of services including standard clinical services, LASIK surgery at the Lions Laser Vision Center, cataract micro-surgery and lens implantation, plastic surgery of the eyelids and full optometric service at Lions Optics. The Lions Eye Bank collects and distributes corneal tissue, scleral tissue and supplies thousands of corneal transplants throughout Western Australia. The Institute initiated the Pilbara Aboriginal Eye Health Program, a strategy targeting indigenous people who suffer from diabetes and associated blinding eye diseases prevalent within the Aboriginal population. As part of the Australian Government aid to the Indonesian Government, In July 2007, the LEI was instrumental in setting up the Bali Mandara Eye Hospital which was handed over to the Indonesian Government on 13 October 2015. The LEI provides open consultations and health education seminars in cooperation with several organisations including Glaucoma Australia, Retinitis Pigmentosa Society of Western Australia, Macular Degeneration Foundation and the Australian Foundation for the Prevention of Blindness. Its ophthalmologists also consult at Perth’s main teaching public hospitals including Sir Charles Gairdner Hospital, Royal Perth Hospital and Fremantle Hospital.\n\nThe LEI teams investigate all major causes of blindness including cataracts, diabetes related eye disease, glaucoma, retinal degenerations, corneal, and immune-based diseases. More than 70 scientists at the LEI use a range of technologies to develop treatments for blinding diseases, including gene therapy and telemedicine. The LEI has national and international institutional partnerships including American Juvenile Diabetes Foundation, Shanghai University, Swedish University of Agricultural Science, University of Missouri and the National Eye Institute (USA). For example, the LEI participates in joint research and development projects with the American Juvenile Diabetes Foundation, Swedish University of Agricultural Sciences, University of Missouri and the National Eye Institute (USA). Research carried out by the Institute teams led to the first retinal vein bypass treatment of blockages, and the development of the first transgenic mouse model for Age-Related Macular Degeneration, the leading cause of blindness for people over 55. This model is expected to accelerate the development of ARMD leading to an effective treatment. At the LEI, the first artificial cornea, the AlphaCor was developed and implanted into a human eye. The LEI is acknowledged as a core academic centre involved in clinical trials of new pharmaceutical therapies and surgical procedures before government approval. For example, the Xen Gel Stent, an implantable transcleral microsurgical device developed at the LEI was approved for use in the USA by the FDA in 2016.\n\n\n \n"}
{"id": "10369986", "url": "https://en.wikipedia.org/wiki?curid=10369986", "title": "List of JavaScript libraries", "text": "List of JavaScript libraries\n\nThis is a list of notable JavaScript libraries.\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3239735", "url": "https://en.wikipedia.org/wiki?curid=3239735", "title": "List of Lepidoptera that feed on poplars", "text": "List of Lepidoptera that feed on poplars\n\nPoplars, \"Populus\" species, are used as food plants by the larvae of a large number of Lepidoptera species:\n\nSpecies which feed exclusively on \"Populus\"\n\n\nSpecies which feed on \"Populus\" and other plants\n\n\n"}
{"id": "3555631", "url": "https://en.wikipedia.org/wiki?curid=3555631", "title": "List of breast cancer patients by survival status", "text": "List of breast cancer patients by survival status\n\nThis list of notable breast cancer patients includes people who made significant contributions to their respective fields and who were diagnosed with breast cancer at some point in their lives, as confirmed by public information.\n\nAccording to the United States National Cancer Institute, an estimated 252,710 new cases and 40,610 deaths (women only; no estimates for male victims due to size of sampling pool) would occur in the United States in 2017.\n\n\n\n\n\n"}
{"id": "16661256", "url": "https://en.wikipedia.org/wiki?curid=16661256", "title": "List of computer standards", "text": "List of computer standards\n\nComputer hardware and software standards are technical standards instituted for compatibility and interoperability between software, systems, platforms and devices.\n\n"}
{"id": "5450474", "url": "https://en.wikipedia.org/wiki?curid=5450474", "title": "List of diseases (0–9)", "text": "List of diseases (0–9)\n\nThis is a list of diseases starting with a digit.\n\n\n"}
{"id": "391591", "url": "https://en.wikipedia.org/wiki?curid=391591", "title": "List of refractive indices", "text": "List of refractive indices\n\nMany materials have a well-characterized refractive index, but these indexes depend strongly upon the frequency of light. Standard refractive index measurements are taken at the \"yellow doublet\" sodium D line, with a wavelength of 589 nanometers.\n\nThere are also weaker dependencies on temperature, pressure/stress, etc., as well on precise material compositions (presence of dopants, etc.); for many materials and typical conditions, however, these variations are at the percent level or less. Thus, it is especially important to cite the source for an index measurement if precision is required.\n\nIn general, an index of refraction is a complex number with both a real and imaginary part, where the latter indicates the strength of absorption loss at a particular wavelength—thus, the imaginary part is sometimes called the extinction coefficient formula_1. Such losses become particularly significant, for example, in metals at short (e.g. visible) wavelengths, and must be included in any description of the refractive index.\n\n\n"}
{"id": "2645494", "url": "https://en.wikipedia.org/wiki?curid=2645494", "title": "Manna (novel)", "text": "Manna (novel)\n\nManna is a 2003 science fiction essay by Marshall Brain that explores several issues in modern information technology and user interfaces, including some around transhumanism.\n\nThe fictional story is set in 2050 and takes place in Cary, North Carolina before the narrator flies to Australia. The narrator starts at a minimum wage job at Burger-G before being laid-off, primarily due to the Manna, a computer management system, replacing people in the service industry. He then takes a bus to a small government provided welfare dormitory where he meets a friend. Soon after, he is visited by two girls who tell him that he's invited to live in Australia because his father bought stock in the Australia Project years prior. The narrator then goes on to discover the many aspects of the Australia Project.\n\nIn the US, which has a libertarian economic system, most Americans are unemployable and live in cramped housing projects, where they are fed and kept safe like farm animals. Birth control medicine in the water prevents them from having children. In contrast, in Australia, everyone has access to the goods provided by automation.\n\n\"Manna\" is meant to be a thought-provoking read or conceptual prototype rather than an entertaining novel (\"see exploratory engineering for more on such writing\"). The novel shows two possible outcomes of the 'robotic revolution' in the near future: one outcome is a dystopia based around US capitalism and the other is a utopia based upon a communal and technological society in Australia. Essentially, the two differ in that lower-class humans in the dystopic society have been left unmodified and are controlled by AI \"managers\" to the point of slavery, while humans in the utopian society more directly and efficiently participate in the management of the society as a whole and most or all willingly accept implanted AI aids.\n\nSome technological and social themes explored :\n\nPositions and assumptions presented in the novel include:\n\nThe book can be read online for free (see link below).\n\n\n"}
{"id": "4361884", "url": "https://en.wikipedia.org/wiki?curid=4361884", "title": "Mary R. Dawson", "text": "Mary R. Dawson\n\nMary R. Dawson (born 1930) is a vertebrate paleontologist and curator emeritus at the Carnegie Museum of Natural History in Pittsburgh, Pennsylvania.\n\nDawson was raised in Michigan, received her undergraduate degree from Michigan State University, and received her Ph.D. from the University of Kansas. She was Curator of Vertebrate Paleontology at the Carnegie Museum of Natural History in Pittsburgh from 1972 until she retired in 2003, including serving as chair of the Earth Sciences Division from 1973 to 1997.\n\nDawson's research has focused on the evolution of mammals, especially of Cenozoic rodents and lagomorphs. She has also maintained an active research program at Ellesmere Island and other sites in the high arctic which showed that tropical and subtropical animals lived inside the Arctic Circle during the exceptionally warm climates of the Paleogene geological period. Through this work, she and her collaborators discovered the first fossils of Tertiary land animals that documented a migration route between North America and Europe. This migration route provided early support for the theory of plate tectonics, which was only gaining wide acceptance in the 1960s and 1970s. In 2006 she disputed the classification of the Laotian rock rat, arguing that it is a member of the family Diatomyidae, which had previously been believed to have gone extinct 11 million years ago .\n\nIn 1992 Dr. Dawson became the first American woman to receive the Romer-Simpson medal, which is awarded for lifetime achievement in the field of vertebrate paleontology and considered the highest honor bestowed by the Society of Vertebrate Paleontology. Likewise she was only the second woman to serve as the Society's president in 1973-1974. The Society of Vertebrate Paleontology's Mary R. Dawson Predoctoral Fellowship Grant, which recognizes and supports graduate student research excellence, is named after her.\n\n\n"}
{"id": "8304842", "url": "https://en.wikipedia.org/wiki?curid=8304842", "title": "Mathematica: A World of Numbers... and Beyond", "text": "Mathematica: A World of Numbers... and Beyond\n\nMathematica: A World of Numbers… and Beyond is a kinetic and static exhibition of mathematical concepts designed by Charles and Ray Eames, originally debuted at the California Museum of Science and Industry in 1961. Duplicates have since been made, and they (as well as the original) have been moved to other institutions.\n\nIn March, 1961 a new science wing at the California Museum of Science and Industry in Los Angeles opened. The IBM Corporation had been asked by the Museum to make a contribution; IBM in turn asked the famous California designer team of Charles Eames and his wife Ray Eames to come up with a good proposal. The result was that the Eames Office was commissioned by IBM to design an interactive exhibition called \"Mathematica: A World of Numbers... and Beyond\". This was the first of many exhibitions designed by the Eames Office.\n\nThe exhibition stayed at the Museum until January 1998, making it the longest running of any corporate sponsored museum exhibition. Furthermore, it is the only one of the dozens of exhibitions designed by the Office of Charles and Ray Eames that is still extant. This original \"Mathematica\" exhibition was reassembled for display at the Alyce de Roulet Williamson Gallery at Art Center College of Design in Pasadena, California, July 30 through October 1, 2000. It is now owned by and on display at the New York Hall of Science, though it now lacks the overhead plaques with quotations from mathematicians that were part of the original installation.\n\nIn November, 1961 an exact duplicate was made for Chicago's Museum of Science and Industry, where it was shown until late 1980. From there it was sold and relocated to the Museum of Science in Boston, Massachusetts, where it is permanently on display. In January 2014, the exhibit temporarily closed to undergo a much-needed year-long refurbishment, and reopened in a new location at the Museum of Science in April 2015. The Boston installation bears the closest resemblance to the original Eames design, including numerous overhead plaques featuring historic quotations from famous mathematicians. As part of the refurbishment, a graphic panel was added to supplement the History Wall timeline to recognize the contributions of both men and women mathematicians of the late 20th and early 21st centuries. \n\nAnother copy was made for the IBM Pavilion at the 1964/1965 New York World's Fair. Subsequently, it was briefly on display in Manhattan, and was then installed in the Pacific Science Center in Seattle where it stayed until 1980. It was briefly re-installed in New York City at the 590 Madison Ave IBM Headquarters Building, before being moved to SciTrek in Atlanta, but that organization was shut down in 2004 due to funding cuts. The exhibit was then shipped to Petaluma, California to Lucia Eames, the daughter of the original designers. , the exhibit has been acquired by the Henry Ford Museum in Dearborn, Michigan.\n\nSome of the displays are minimally interactive, in that they start to operate at the push of a button. Other displays are motorized and run continuously, or operate automatically on a fixed cycle as long as power is supplied. The moving display elements combine with noise made by balls falling through the probability machine, to fill the exhibit space with an atmosphere of continuous activity.\n\n\nIn addition, large placards hang from the ceiling, carrying interesting quotations from famous mathematicians. Some installations have omitted this feature, although it was an integral part of the original exhibition.\n\nIn 1966, five years after the opening of the Mathematica Exhibit, IBM published a timeline poster, titled \"Men of Modern Mathematics\". It was based on the items displayed on the exhibit's History Wall, and free copies were distributed to schools. The timeline covered the period from 1000 AD to approximately 1950 AD, and the poster featured biographical and historical items, along with numerous pictures showing progress in various areas of science, including architecture. The mathematical items in this chart were prepared by Professor Raymond Redheffer of UCLA. Long after the chart was distributed, mathematics departments around the world have proudly displayed this chart on their walls.\n\nIn 2012, IBM Corporation released a free iPad application, \"Minds of Modern Mathematics\", based on the poster but updated to the present, including expanded coverage of women mathematicians. The app was developed by IBM with the assistance of the Eames Office. , the app has not been updated to run on current versions of iOS, which only support 64-bit code.\n\n\n"}
{"id": "14573061", "url": "https://en.wikipedia.org/wiki?curid=14573061", "title": "Megaprime", "text": "Megaprime\n\nA megaprime is a prime number with at least one million decimal digits (whereas titanic prime is a prime number with at least 1,000 digits, and gigantic prime has at least 10,000 digits).\n\n, 325 (probable) megaprimes are known, including 309 definite primes and 16 probable primes. The first to be found was the Mersenne prime 2−1 with 2,098,960 digits, discovered in 1999 by Nayan Hajratwala, a participant in the distributed computing project GIMPS.\n\nThe term bevaprime has been proposed as a term for a prime with at least 1,000,000,000 digits.\n\nIn fact, \"almost all\" primes are megaprimes, as the number of primes with less than a million digits is finite. However, the vast majority of known primes are not megaprimes.\n\nEntries labelled \"Prime\" have been proved prime; those labelled \"PRP\" have not. See the article Probable prime. There are currently 412 proven mega primes.\n\nAll numbers from 10 through 10 + 593498 are known to be composite, and there is a very high probability 10 + 593499, a strong PRP, is actually the smallest megaprime.\n\nformula_1 = gcd(formula_2,the aurifeuillean \"L\" part of formula_3), formula_4 = gcd(formula_2,the aurifeuillean \"M\" part of formula_3).\n\n\n"}
{"id": "19216990", "url": "https://en.wikipedia.org/wiki?curid=19216990", "title": "Metapsychology", "text": "Metapsychology\n\nMetapsychology (Greek: \"meta\" 'beyond, transcending', and \"ψυχολογία\" 'psychology') is that aspect of any psychological theory which refers to the structure of the theory itself (hence the prefix \"meta\") rather than to the entity it describes. The psychology is about the psyche; the metapsychology is about the psychology. The term is used mostly in discourse about psychoanalysis, the psychology developed by Sigmund Freud, which today is regarded as a branch of science (with roots in the work of Freud's scientific mentors and predecessors, especially Helmholtz, Brucke, Charcot, and Janet) and/or a hermeneutics of understanding (with roots in Freud's literary sources, especially Sophocles and, to a lesser extent, Goethe and Shakespeare). Emphasis on the scientific status of psychoanalysis has been renewed in the emerging discipline of neuropsychoanalysis, whose major exemplar is Mark Solms. The hermeneutic vision of psychoanalysis is the focus of influential works by Donna Orange.\n\nPsychoanalytic metapsychology is concerned with the fundamental structure and concepts Freudian theory. Sigmund Freud first used the term on 13 February 1896 in a letter to Wilhelm Fliess, to refer to his addition of unconscious processes to the conscious ones of traditional psychology. On March 10, 1898, he wrote to Fiess: \"It seems to me that () the theory of wish fulfillment has brought only the psychological solution and not the biological - or, rather, metapsychical - one. (I am going to ask you seriously, by the way, whether I may use the name metapsychology for my psychology that leads behind consciousness).\" Three years after completing his unpublished \"Project for a Scientific Psychology\", Freud's optimism had completely vanished. In a letter dated March 10 of that year he told Fliess: \"I am not at all in disagreement with you, not at all inclined to leave psychology hanging in the air without an organic basis. But apart from this conviction, I do not know how to go on, neither theoretically nor therapeutically, and therefore must behave as if [\"als läge\"] only the psychological were under consideration. Why I cannot fit it together [the organic and the psychological] I have not even begun to fathom\". \"When, in his 'Autobiographical Study' of 1925, Freud called his metapsychology a 'speculative superstructure'...the elements of which could be abandoned or changed once proven inadequate, he was, in the terminology of Kant's \"Critique of Judgment\", proposing a psychology \"als ob\" or \"as if\" – a heuristic model of mental functioning that did not necessarily correspond with external reality.\"\n\nA salient example of Freud's own metapsychology is his chracterization of psychoanalysis as a \"simultaneously closed system, fundamentally unrelated and impervious to the external world and as an open system inherently connected and responsive to environmental influence\".\n\nIn the 1910s, Freud wrote a series of twelve essays, to be collected as \"Preliminaries to a Metapsychology\". Five of these were published independently under the titles: \"Instincts and Their Vicissitudes,\" \"Repression,\" \"The Unconscious,\" \"A Metapsychological Supplement to the Theory of Dreams,\" and \"Mourning and Melancholia.\" The remaining seven remained unpublished, an expression of Freud's ambivalence about his own attempts to articulate the whole of his vision of psychoanalysis. In 1919 he wrote to Lou Andreas-Salome, \"Where is my Metapsychology? In the first place it remains unwritten\". In 1920 he published \"Beyond the Pleasure Principle\", a text with metaphysical ambitions. \n\nMidcentury psychoanalyst David Rapaport defined the term thus: \"Books on psychoanalysis usually deal with its clinical theory... there exists, however, a fragmentary—yet consistent—general theory of psychoanalysis, which comprises the premises of the special (clinical) theory, the concepts built on it, and the generalizations derived from it... named \"metapsychology\".\"\n\n\n"}
{"id": "3282446", "url": "https://en.wikipedia.org/wiki?curid=3282446", "title": "Militarized interstate dispute", "text": "Militarized interstate dispute\n\nMilitarized interstate disputes (MIDs) are conflicts between states that do not involve a full-scale war. A conflict is described as an MID if it causes fewer than 1,000 deaths, and some military force is used. This can be as little as a military display of force with no deaths. Under this definition, over 2,000 MIDs have been identified since 1816 in the Correlates of War project.\n\nFor example, although the 2003 invasion of Iraq by the United States-led coalition would be considered a full-scale war, the bombings and disputes related to American, British, and (until 1996) French control of the Iraqi no-fly zone in the 1990s are described by Frank Wayman as an \"MID\".\n\nSome of the findings from research on MIDs:\n\n\nThe Correlates of War (CoW) Militarized Interstate Dispute (MID) dataset is the most extensive dataset on MIDs, and has been the basis of much of the published research on MIDs. However, a 2017 study found that the coding in the dataset was deeply flawed with significant effects on the findings of studies that relied on the dataset: \"After strictly applying MID coding rules, we recommend dropping 251 cases (or over 10% of the dataset), as either we were unable to find a militarized incident in the historical record or the dispute appeared elsewhere in the data. We found evidence linking 75 disputes to other cases, and we could not identify 19 cases in the historical record. Among the remaining disputes, we recommend major changes (changes in dispute year, fatality level, and participants) in 234 disputes and minor changes in 1,009 disputes... estimates in our replications of three recent studies of dispute escalation, dispute duration, and dispute reciprocation all witness substantial changes when using corrected data—to the point of reversing previous conclusions in some cases.\"\n\n\n"}
{"id": "42247367", "url": "https://en.wikipedia.org/wiki?curid=42247367", "title": "Moore Center for Theoretical Cosmology and Physics", "text": "Moore Center for Theoretical Cosmology and Physics\n\nThe Moore Center for Theoretical Cosmology and Physics (CTCP) is a think tank for research into the nature of the universe on cosmological and nanoscales. Their research involves studies \"from the beginning of time to the ongoing dynamics of dark matter, galaxies, and stars.\"\n\nMarc Kamionkowski was one of the founding Directors in 2006. Current director is Mark B. Wise\n\nThe Center is physically located inside the Lauritsen and Cahill buildings on the Caltech campus in Pasadena, California.\n"}
{"id": "27397711", "url": "https://en.wikipedia.org/wiki?curid=27397711", "title": "Parten's stages of play", "text": "Parten's stages of play\n\nStages of play is a theory and classification of children's participation in play developed by Mildred Parten Newhall in her 1929 dissertation. Parten observed American preschool age (ages 2 to 5) children at free play (defined as anything unrelated to survival, production or profit).\n\nParten recognized six different types of play:\n\nAccording to Parten, as children became older, improving their communication skills, and as opportunities for peer interaction become more common, the nonsocial (solitary and parallel) types of play become less common, and the social (associative and cooperative) types of play become more common.\n\nModern scholars agree that Parten's theory has contributed substantially to our understanding of play, and while alternative classification schemes have been proposed, Parten's stages of play are still widely used. However, there is disagreement on whether there is indeed a sequence of play stages that children go through – for example, whether toddlers are really unable to play cooperatively, and whether solitary play in older children is less common or a sign of immaturity. Alternative explanations suggest that types of play may be influenced by other circumstances (such as how well the children know one another).\n\n\n\n"}
{"id": "2786731", "url": "https://en.wikipedia.org/wiki?curid=2786731", "title": "Pseudoword", "text": "Pseudoword\n\nA pseudoword or non-word is a unit of speech or text that appears to be an actual word in a certain language, while in fact it has no meaning in the lexicon. It is a kind of non-lexical vocable.\n\nSuch words without a meaning in a certain language or no occurrence in any text corpus or dictionary can be the result of (the interpretation of) a truly random signal, there will usually be an underlying deterministic source as is the case for:\n\n\nWhen nonsensical words are strung together, gibberish may arise. Word salad in contrast may contain legible and intelligible words but without semantic or syntactic correlation or coherence.\n\nWithin linguistics, a pseudoword is defined specifically as respecting the phonotactic restrictions of a language. That is, it does not include sounds or series of sounds that do not exist in that language: it is easily pronounceable for speakers of the language. Also, when written down, a pseudoword does not include strings of characters that are not permissible in the spelling of the target language. \"Vonk\" is a pseudoword in English, while \"dfhnxd\" is not. The latter is an example of a nonword. Nonwords are contrasted with pseudowords in that they are not pronounceable and by that their spelling could not be the spelling of a real word.\n\nPseudowords are also sometimes called wug words in the context of linguistic experiments. This is because \"wug\" [wʌg] was one such pseudoword used by Jean Berko Gleason in her wug test 1958 experiments. Words like \"wug\", which could have been a perfectly acceptable word in English but isn't due to an accidental gap, were presented to children. The experimenter would then prompt the children to create a plural for \"wug\", which was almost invariably \"wugs\" [wʌgz]. The experiments were designed to see if English morphophonemics would be applied by children to novel words. They revealed that even at a very young age, children have already internalized many of the complex features of their language.\n\nA logatome is a short pseudoword or just a syllable which is used in acoustic experiments to examine speech recognition.\n\nA logatome or nonsense syllable is a short pseudoword consisting most of the time of just one syllable which has no meaning of its own. Examples of English logatomes are the nonsense words \"snarp\" or \"bluck\".\n\nLike other pseudowords, logatomes obey all the phonotactic rules of a specific language.\n\nLogatomes are used in particular in acoustic experiments. They are also used in experiments in the psychology of learning as a way to examine speech recognition. and in experimental psychology, especially the psychology of learning and memory.\n\nNonsense syllables were first introduced by Hermann Ebbinghaus in his experiments on the learning of lists. His intention was that they would form a standard stimulus so that experiments would be reproducible. However, with increasing use it became apparent that different nonsense syllables were learned at very different rates, even when they had the same superficial structure. Glaze introduced the concept of association value to describe these differences, which turned out to be reliable between people and situations. Since Glaze's time, experiments using nonsense syllables typically control association value in order to reduce variability in results between stimuli.\n\nNonsense syllables can vary in structure. The most used are the so-called CVC syllables, composed of a consonant, a vowel, and a consonant. These have the advantage that nearly all are pronounceable, that is, they fit the phonotactics of any language that uses closed syllables, such as English and German. They are often described as \"CVC trigrams\", reflecting their three-letter structure. Obviously many other structures are possible, and can be described on the same principles, e.g. VC, VCV, CVCV. But the CVC trigrams have been studied most intensively; for example, Glaze determined association values for 2019 of them.\n\nThe term nonsense syllable is widely used to describe non-lexical vocables used in music, most notably in scat singing but also in many other forms of vocal music. Although such usages do not invoke the technical issues about structure and associability that are of concern in psychology, the essential meaning of the term is the same.\n\n"}
{"id": "1796242", "url": "https://en.wikipedia.org/wiki?curid=1796242", "title": "Rationalization (sociology)", "text": "Rationalization (sociology)\n\nIn sociology, rationalization (or rationalisation) is the replacement of traditions, values, and emotions as motivators for behavior in society with concepts based on rationality and reason. For example, the implementation of bureaucracies in government is a kind of rationalization, as is the construction of high-efficiency living spaces in architecture and urban planning. A potential reason as to why rationalization of a culture may take place in the modern era is the process of globalization. Countries are becoming increasingly interlinked, and with the rise of technology, it is easier for countries to influence each other through social networking, the media and politics. An example of rationalization in place would be the case of witch doctors in certain parts of Africa. Whilst many locals view them as an important part of their culture and traditions, development initiatives and aid workers have tried to rationalize the practice in order to educate the local people in modern medicine and practice (Giddens, 2013).\n\nMany sociologists, critical theorists and contemporary philosophers have argued that rationalization, falsely assumed as progress, has had a negative and dehumanizing effect on society, moving modernity away from the central tenets of Enlightenment. The founders of sociology had critical reaction to rationalization:\n\nRationalization formed a central concept in the foundation of classical sociology, particularly with respect to the emphasis the discipline placed – by contrast with anthropology – on the nature of modern Western societies. The term was presented by the profoundly influential German antipositivist Max Weber, though its themes bear parallel with the critiques of modernity set forth by a number of scholars. A rejection of dialectism and sociocultural evolution informs the concept.\n\nWeber demonstrated rationalization in \"The Protestant Ethic and the Spirit of Capitalism\", in which the aims of certain Protestant Theologies, particularly Calvinism, are shown to have shifted towards rational means of economic gain as a way of dealing with their 'salvation anxiety'. The rational consequences of this doctrine, he argued, soon grew incompatible with its religious roots, and so the latter were eventually discarded. Weber continues his investigation into this matter in later works, notably in his studies on bureaucracy and on the classifications of authority. In these works he alludes to an inevitable move towards rationalization.\n\nWeber believed that a move towards rational-legal authority was inevitable. In charismatic authority, the death of a leader effectively ends the power of that authority, and only through a rationalized and bureaucratic base can this authority be passed on. Traditional authorities in rationalized societies also tend to develop a rational-legal base to better ensure a stable accession. (See also: Tripartite classification of authority)\n\nWhereas in traditional societies such as feudalism governing is managed under the traditional leadership of, for example, a queen or tribal chief, modern societies operate under rational-legal systems. For example, democratic systems attempt to remedy qualitative concerns (such as racial discrimination) with rationalized, quantitative means (for example, civil rights legislation). Weber described the eventual effects of rationalization in his \"Economy and Society\" as leading to a \"polar night of icy darkness\", in which increasing rationalization of human life traps individuals in an \"iron cage\" (or \"steel-hard casing\") of rule-based, rational control.\n\nJürgen Habermas has argued that understanding rationalization properly requires going beyond Weber's notion of rationalization. It requires distinguishing between \"instrumental rationality\", which involves calculation and efficiency (in other words, reducing all relationships to those of means and ends), and \"communicative rationality\", which involves expanding the scope of mutual understanding in communication, the ability to expand this understanding through reflective discourse about communication, and making social and political life subject to this expanded understanding.\n\nFor Zygmunt Bauman, rationalization as a manifestation of modernity may be closely associated with the events of the Holocaust. In \"Modernity and Ambivalence\", Bauman attempted to give an account of the different approaches modern society adopts toward the stranger. He argued that, on the one hand, in a consumer-oriented economy the strange and the unfamiliar is always enticing; in different styles of food, different fashions and in tourism it is possible to experience the allure of what is unfamiliar.\n\nYet this strange-ness also has a more negative side. The stranger, because he cannot be controlled and ordered, is always the object of fear; he is the potential mugger, the person outside of society's borders who is constantly threatening. Bauman's most famous book, \"Modernity and the Holocaust\", is an attempt to give a full account of the dangers of these kinds of fears. Drawing upon Hannah Arendt and Theodor Adorno's books on totalitarianism and the Enlightenment, Bauman argues that the Holocaust should not simply be considered to be an event in Jewish history, nor a regression to pre-modern barbarism. Rather, he says, the Holocaust should be seen as deeply connected to modernity and its order-making efforts. Procedural rationality, the division of labour into smaller and smaller tasks, the taxonomic categorization of different species, and the tendency to view rule-following as morally good all played their role in the Holocaust coming to pass.\n\nFor this reason, Bauman argues that modern societies have not fully taken on board the lessons of the Holocaust; it is generally viewed – to use Bauman's metaphor – like a picture hanging on a wall, offering few lessons. In Bauman's analysis, the Jews became 'strangers' \"par excellence\" in Europe; the Final Solution was pictured by him as an extreme example of the attempts made by societies to excise the uncomfortable and indeterminate elements existing within them. Bauman, like the philosopher Giorgio Agamben, contended that the same processes of exclusion that were at work in the Holocaust could, and to an extent do, still come into play today.\n\nIn their analysis of contemporary western society, \"Dialectic of Enlightenment\" (1944, revised 1947), Theodor Adorno and Max Horkheimer developed a wide and pessimistic concept of enlightenment. In their analysis, enlightenment had its dark side: while trying to abolish superstition and myths by 'foundationalist' philosophy, it ignored its own 'mythical' basis. Its strivings towards totality and certainty led to an increasing instrumentalization of reason. In their view, the enlightenment itself should be enlightened and not posed as a 'myth-free' view of the world. For Marxist philosophy in general, rationalization is closely associated with the concept of \"commodity fetishism\", for the reason that not only are products designed to fulfill certain tasks, but employees are hired to fulfill specific tasks as well.\n\nModern food consumption typifies the process of rationalization. Where food preparation in traditional societies is more laborious and technically inefficient, modern society has strived towards speed and precision in its delivery. Fast-food restaurants, designed to maximise profit, have strived toward total efficiency since their conception, and continue to do so. A strict level of efficiency has been accomplished in several ways, including stricter control of its workers' actions, the replacement of more complicated systems with simpler, less time-consuming ones, simple numbered systems of value meals and the addition of drive-through windows.\n\nRationalization is also observable in the replacement of more traditional stores, which may offer subjective advantages to consumers, such as what sociologists consider a less regulated, more natural environment, with modern stores offering the objective advantage of lower prices to consumers. The case of Wal-Mart is one strong example demonstrating this transition. While Wal-Marts have attracted considerable criticism for effectively displacing more traditional stores, these subjective social-value concerns have held minimal effectiveness in limiting expansion of the enterprise, particularly in more rationalized nations, due to the preferences of the public for lower prices over the advantages sociologists claim for more traditional stores.\n\nThe sociologist George Ritzer has used the term McDonaldization to refer, not just to the actions of the fast food restaurant, but to the general process of rationalization. Ritzer distinguishes four primary components of McDonaldization:\n\n\nAs capitalism itself is a rationalized economic policy, so is the process of commercialization it utilizes in order to increase sales. Most holidays, for instance, were created out of a religious context or in celebration of some past event. However, in rationalized societies these traditional values are increasingly diminished and the aim shifts from the qualitative aim of a meaningful celebration to the more quantitative aim of increasing sales.\n\nIn the United States, for example, most major holidays now are represented by rationalized, secularized figures which serve as a corporate totem. In more traditional environments, gifts are more often hand-crafted works which hold some symbolic meaning. This qualitative value of gifts diminishes in rationalized societies, where individuals often offer hints or speak directly about what present they are interested in receiving. In these societies, the value of a gift is more likely to be weighed by objective measures (i.e. monetary value) than subjective (i.e. symbolism).\n\nOne rational tendency is towards increasing the efficiency and output of the human body. Several means can be employed in reaching this end, including trends towards regular exercise, dieting, increased hygiene, drugs, and an emphasis on optimal nutrition. As well as increasing lifespans, these allow for stronger, leaner, more optimized bodies for quickly performing tasks. Another aspect of this is maintaining a certain level of physical attraction. Processes such as the combing of hair, use of a fragrance, having an appropriate haircut, and wearing certain clothes receive calculated use, that of giving off a certain impression to other individuals. In these cases, we see how rationalization does produce meaning and is not just simply a way to speed things up, i.e., a fat person is said to have poor self-control and discipline and thus you can now make personal judgments about them.\n\nAnother trend is in the bureaucratization of processes that formerly might have been done through the home. This includes the use of hospitals for childbirth and the use of doctors to identify symptoms of an illness and to prescribe treatment.\n\nRationalized education tends to focus less on subjects based around the use of critical discourse (for instance, religion) and more on matters of a calculated importance (such as business administration). This is reflected also in the move towards standardized and multiple choice testing, which measures students on the basis of numbered answers and against a uniform standard.\n\n\n"}
{"id": "386978", "url": "https://en.wikipedia.org/wiki?curid=386978", "title": "Saturn I SA-2", "text": "Saturn I SA-2\n\nSaturn-Apollo 2 (SA-2) was the second flight of the Saturn I launch vehicle, the first flight of Project Highwater, and was part of the American Apollo program. The rocket was launched on April 25, 1962, from Cape Canaveral, Florida.\n\nLaunch preparation for the mission began at Cape Canaveral on February 27, 1962, with the arrival of the second Saturn I launch vehicle. The only significant change made to the vehicle from the previous SA-1 flight was the addition of extra baffles in the propellant tanks to prevent fuel sloshing. While no serious delays were encountered, there were several minor problems reported.\n\nA leak was detected between the liquid oxygen dome and injector for the #4 H-1 rocket engine; while attempts were made to fix the problem, it was eventually decided to launch without replacing the engine. Minor problems were found in the guidance subsystem and service structure operations, damaged strain gauges were found in a liquid oxygen stud and truss member, and a manhole cover on the dummy Centaur (S-V-D) third stage had to be replaced. Problems arose with two of the fueling computers, but each was repaired. Three hydraulic systems were also listed as potential problems.\n\nDespite the issues encountered during flight preparation, none required the target launch date of April 25 to be pushed back.\n\nSaturn-Apollo 2 was launched at 14:00:34 UTC on April 25, 1962, from Launch Complex 34. The only hold in the countdown sequence was for 30 minutes due to a vessel which entered the flight safety zone down range. The rocket carried of propellant, about 83% of its maximum capacity.\n\nThe H-1 engines shut down at an altitude of after firing for 1 minute 55 seconds and reaching a maximum velocity of . The vehicle continued to coast to an altitude of , at which point, 2 minutes 40 seconds after launch, officials sent a terminate command to the rocket, setting off several charges which caused the vehicle to destruct.\n\nThe objectives of SA-2 were much the same as those of SA-1 in that it was primarily a test of the Saturn I rocket and the new H-1 engines. Specifically, its goals were to prove propulsion performance and mission adequacy, vehicle structural design and aerodynamic characteristics, guidance and control systems, and launch facility and ground support equipment. NASA declared all objectives as successful. Additionally, the fuel sloshing issue from SA-1 was minimized.\n\nA second objective of both this mission and SA-3 was Project Highwater, the intentional release of ballast water from the second and third stages which allowed scientists to investigate the nature of Earth's ionosphere, as well as noctilucent clouds and the behavior of ice in space.\n\nSA-2's dummy upper stages contained approximately of water, or , used to simulate the mass of future payloads. Stage two contained of water, and stage three contained . When the terminate command was sent to the rocket, dynamite charges split the second stage longitudinally, instantly releasing its water load. Primacord charges created several holes in the third stage, releasing its water over a period of several seconds.\n\nCameras on the ground immediately recorded the water cloud, and personnel at a ground station began to observe it about four to five seconds after release. Those personnel reported that the cloud dispersed from vision within an average of five seconds, while more sensitive instruments tracked the cloud to a maximum altitude of . The cloud produced lightning-like effects, which Dr. Wernher von Braun described as \"probably the first synthetic thunderstorm ever generated in space.\" Project Highwater on this flight was also declared a success.\n"}
{"id": "2715469", "url": "https://en.wikipedia.org/wiki?curid=2715469", "title": "Symmetry (physics)", "text": "Symmetry (physics)\n\nIn physics, a symmetry of a physical system is a physical or mathematical feature of the system (observed or intrinsic) that is preserved or remains unchanged under some transformation.\n\nA family of particular transformations may be \"continuous\" (such as rotation of a circle) or \"discrete\" (e.g., reflection of a bilaterally symmetric figure, or rotation of a regular polygon). Continuous and discrete transformations give rise to corresponding types of symmetries. Continuous symmetries can be described by Lie groups while discrete symmetries are described by finite groups (see Symmetry group).\n\nThese two concepts, Lie and finite groups, are the foundation for the fundamental theories of modern physics. Symmetries are frequently amenable to mathematical formulations such as group representations and can, in addition, be exploited to simplify many problems.\n\nArguably the most important example of a symmetry in physics is that the speed of light has the same value in all frames of reference, which is known in mathematical terms as Poincaré group, the symmetry group of special relativity. Another important example is the invariance of the form of physical laws under arbitrary differentiable coordinate transformations, which is an important idea in general relativity.\n\nInvariance is specified mathematically by transformations that leave some property (e.g. quantity) unchanged. This idea can apply to basic real-world observations. For example, temperature may be homogeneous throughout a room. Since the temperature does not depend on the position of an observer within the room, we say that the temperature is \"invariant\" under a shift in an observer's position within the room.\n\nSimilarly, a uniform sphere rotated about its center will appear exactly as it did before the rotation. The sphere is said to exhibit spherical symmetry. A rotation about any axis of the sphere will preserve how the sphere \"looks\".\n\nThe above ideas lead to the useful idea of \"invariance\" when discussing observed physical symmetry; this can be applied to symmetries in forces as well.\n\nFor example, an electric field due to an electrically charged wire of infinite length is said to exhibit cylindrical symmetry, because the electric field strength at a given distance \"r\" from the wire will have the same magnitude at each point on the surface of a cylinder (whose axis is the wire) with radius \"r\". Rotating the wire about its own axis does not change its position or charge density, hence it will preserve the field. The field strength at a rotated position is the same. This is not true in general for an arbitrary system of charges. \n\nIn Newton's theory of mechanics, given two bodies, each with mass \"m\", starting at the origin and moving along the \"x\"-axis in opposite directions, one with speed \"v\" and the other with speed \"v\" the total kinetic energy of the system (as calculated from an observer at the origin) is and remains the same if the velocities are interchanged. The total kinetic energy is preserved under a reflection in the \"y\"-axis.\n\nThe last example above illustrates another way of expressing symmetries, namely through the equations that describe some aspect of the physical system. The above example shows that the total kinetic energy will be the same if \"v\" and \"v\" are interchanged.\n\nSymmetries may be broadly classified as \"global\" or \"local\". A \"global symmetry\" is one that holds at all points of spacetime, whereas a \"local symmetry\" is one that has a different symmetry transformation at different points of spacetime; specifically a local symmetry transformation is parameterised by the spacetime co-ordinates. Local symmetries play an important role in physics as they form the basis for gauge theories.\n\nThe two examples of rotational symmetry described above - spherical and cylindrical - are each instances of continuous symmetry. These are characterised by invariance following a continuous change in the geometry of the system. For example, the wire may be rotated through any angle about its axis and the field strength will be the same on a given cylinder. Mathematically, continuous symmetries are described by continuous or smooth functions. An important subclass of continuous symmetries in physics are spacetime symmetries.\n\nContinuous \"spacetime symmetries\" are symmetries involving transformations of space and time. These may be further classified as \"spatial symmetries\", involving only the spatial geometry associated with a physical system; \"temporal symmetries\", involving only changes in time; or \"spatio-temporal symmetries\", involving changes in both space and time.\n\n\nMathematically, spacetime symmetries are usually described by smooth vector fields on a smooth manifold. The underlying local diffeomorphisms associated with the vector fields correspond more directly to the physical symmetries, but the vector fields themselves are more often used when classifying the symmetries of the physical system.\n\nSome of the most important vector fields are Killing vector fields which are those spacetime symmetries that preserve the underlying metric structure of a manifold. In rough terms, Killing vector fields preserve the distance between any two points of the manifold and often go by the name of isometries.\n\nA discrete symmetry is a symmetry that describes non-continuous changes in a system. For example, a square possesses discrete rotational symmetry, as only rotations by multiples of right angles will preserve the square's original appearance. Discrete symmetries sometimes involve some type of 'swapping', these swaps usually being called \"reflections\" or \"interchanges\".\n\n\nThe Standard model of particle physics has three related natural near-symmetries. These state that the universe in which we live should be indistinguishable from one where a certain type of change is introduced.\n\n\nThese symmetries are near-symmetries because each is broken in the present-day universe. However, the Standard Model predicts that the combination of the three (that is, the simultaneous application of all three transformations) must be a symmetry, called CPT symmetry. CP violation, the violation of the combination of C- and P-symmetry, is necessary for the presence of significant amounts of baryonic matter in the universe. CP violation is a fruitful area of current research in particle physics.\n\nA type of symmetry known as supersymmetry has been used to try to make theoretical advances in the standard model. Supersymmetry is based on the idea that there is another physical symmetry beyond those already developed in the standard model, specifically a symmetry between bosons and fermions. Supersymmetry asserts that each type of boson has, as a supersymmetric partner, a fermion, called a superpartner, and vice versa. Supersymmetry has not yet been experimentally verified: no known particle has the correct properties to be a superpartner of any other known particle. Currently LHC is preparing for a run which tests supersymmetry.\n\nThe transformations describing physical symmetries typically form a mathematical group. Group theory is an important area of mathematics for physicists.\n\nContinuous symmetries are specified mathematically by \"continuous groups\" (called Lie groups). Many physical symmetries are isometries and are specified by symmetry groups. Sometimes this term is used for more general types of symmetries. The set of all proper rotations (about any angle) through any axis of a sphere form a Lie group called the special orthogonal group formula_13. (The \"3\" refers to the three-dimensional space of an ordinary sphere.) Thus, the symmetry group of the sphere with proper rotations is formula_13. Any rotation preserves distances on the surface of the ball. The set of all Lorentz transformations form a group called the Lorentz group (this may be generalised to the Poincaré group).\n\nDiscrete groups describe discrete symmetries. For example, the symmetries of an equilateral triangle are characterized by the symmetric group formula_15.\n\nAn important type of physical theory based on \"local\" symmetries is called a \"gauge\" theory and the symmetries natural to such a theory are called gauge symmetries. Gauge symmetries in the Standard model, used to describe three of the fundamental interactions, are based on the SU(3) × SU(2) × U(1) group. (Roughly speaking, the symmetries of the SU(3) group describe the strong force, the SU(2) group describes the weak interaction and the U(1) group describes the electromagnetic force.)\n\nAlso, the reduction by symmetry of the energy functional under the action by a group and spontaneous symmetry breaking of transformations of symmetric groups appear to elucidate topics in particle physics (for example, the unification of electromagnetism and the weak force in physical cosmology).\n\nThe symmetry properties of a physical system are intimately related to the conservation laws characterizing that system. Noether's theorem gives a precise description of this relation. The theorem states that each continuous symmetry of a physical system implies that some physical property of that system is conserved. Conversely, each conserved quantity has a corresponding symmetry. For example, the isometry of space gives rise to conservation of (linear) momentum, and isometry of time gives rise to conservation of energy.\n\nThe following table summarizes some fundamental symmetries and the associated conserved quantity.\n\nContinuous symmetries in physics preserve transformations. One can specify a symmetry by showing how a very small transformation affects various particle fields. The commutator of two of these infinitesimal transformations are equivalent to a third infinitesimal transformation of the same kind hence they form a Lie algebra.\n\nA general coordinate transformation (also known as a diffeomorphism) has the infinitesimal effect on a scalar, spinor and vector field for example:\n\nformula_16\n\nformula_17\n\nformula_18\n\nfor a general field, formula_19. Without gravity only the Poincaré symmetries are preserved which restricts formula_19 to be of the form:\n\nformula_21\n\nwhere M is an antisymmetric matrix (giving the Lorentz and rotational symmetries) and P is a general vector (giving the translational symmetries). Other symmetries affect multiple fields simultaneously. For example, local gauge transformations apply to both a vector and spinor field:\n\nformula_22\n\nformula_23\n\nwhere formula_24 are generators of a particular Lie group. So far the transformations on the right have only included fields of the same type. Supersymmetries are defined according to how the mix fields of \"different\" types.\n\nAnother symmetry which is part of some theories of physics and not in others is scale invariance which involve Weyl transformations of the following kind:\n\nformula_25\n\nIf the fields have this symmetry then it can be shown that the field theory is almost certainly conformally invariant also. This means that in the absence of gravity h(x) would restricted to the form:\n\nformula_26\n\nwith D generating scale transformations and K generating special conformal transformations. For example, N=4 super-Yang-Mills theory has this symmetry while General Relativity doesn't although other theories of gravity such as conformal gravity do. The 'action' of a field theory is an invariant under all the symmetries of the theory. Much of modern theoretical physics is to do with speculating on the various symmetries the Universe may have and finding the invariants to construct field theories as models.\n\nIn string theories, since a string can be decomposed into an infinite number of particle fields, the symmetries on the string world sheet is equivalent to special transformations which mix an infinite number of fields.\n\n\n\n\n"}
{"id": "18542343", "url": "https://en.wikipedia.org/wiki?curid=18542343", "title": "Takasi Tokioka", "text": "Takasi Tokioka\n\nAt least a dozen species are named in his honor, including these below.\n\n\n \n"}
{"id": "17761044", "url": "https://en.wikipedia.org/wiki?curid=17761044", "title": "Timeline of the Apple II family", "text": "Timeline of the Apple II family\n\nThis timeline of Apple II Family models lists all major types of Apple II computers produced by Apple Computer in order of introduction date. The Apple I, Apple III and Apple Lisa are included, even though they are not classed as part of the Apple II series (or a Macintosh), because of their unique role in Apple's product lineup of the era.\n\n\n"}
{"id": "34605878", "url": "https://en.wikipedia.org/wiki?curid=34605878", "title": "Trevor Hatherton", "text": "Trevor Hatherton\n\nTrevor Hatherton (30 September 1924 – 2 May 1992) was a New Zealand geophysicist, scientific administrator and Antarctic scientist. He was born in Sharlston, Yorkshire, England on 30 September 1924.\n\nIn the 1958 Queen's Birthday Honours Hatherton was appointed an Officer of the Order of the British Empire.\n"}
{"id": "50175480", "url": "https://en.wikipedia.org/wiki?curid=50175480", "title": "WeatherBrains", "text": "WeatherBrains\n\nWeatherBrains is a weekly podcast hosted by a panel of meteorologists. It is available as an audio podcast from iTunes, a video podcast from the official website and broadcast live over the cable systems in central Alabama. The podcast was nominated for the 9th Annual Podcast Awards in the Science category.\n\nPanelists include broadcast meteorologists James Spann , Brian Peters, Nate Johnson, Aubrey Urbanowicz, Kevin Selle, along with National Weather Service Warning Coordination Meteorologist Rick Smith, National Weather Association vice president Bill Murray and former NASA researcher Dr. John Scala.\n\nIn addition to panel discussion of weather events from the past week, each episode features a guest from the weather enterprise ranging from government agencies such as the National Hurricane Center, NOAA and NASA, atmospheric science researchers, and broadcast meteorologists from around the country.\n"}
{"id": "18118796", "url": "https://en.wikipedia.org/wiki?curid=18118796", "title": "Xiaobo Yu", "text": "Xiaobo Yu\n\nDr. Xiaobo Yu is a Chinese palaeontologist and professor on biological sciences. Yu is credited with first describing the lobe-finned fish \"Psarolepis\" romeri, a transitional species between fish and amphibians. Yu is currently a professor at Kean University in Union, New Jersey.\n\n\n"}
