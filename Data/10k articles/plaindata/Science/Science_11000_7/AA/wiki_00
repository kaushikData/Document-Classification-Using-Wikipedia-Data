{"id": "58584065", "url": "https://en.wikipedia.org/wiki?curid=58584065", "title": "AI Superpowers", "text": "AI Superpowers\n\nAI Superpowers: China, Silicon Valley, and the New World Order is a 2018 non-fiction book by Beijing, China-based Kai-Fu Lee, an Artificial Intelligence (AI) pioneer, expert on China and a venture capitalist, and he previously held executive positions at Apple, then SGI, Microsoft, and Google before creating his own company, Sinovation Ventures.\n\nIn his September 2018 \"The New York Times\" Opinion piece, Thomas L. Friedman cited \"AI Superpowers\" in his summary of the emerging global dominance of China in AI. According to Kai-Fu Lee, \"If data is the new oil, then China is the new Saudi Arabia.\"\n\nSenator Mark Warner named \"AI Superpowers\" as his recommended book for The 2018 POLITICO 50 Reading List. \n"}
{"id": "16525976", "url": "https://en.wikipedia.org/wiki?curid=16525976", "title": "Ahern Glacier (Antarctica)", "text": "Ahern Glacier (Antarctica)\n\nAhern Glacier is a small tributary glacier flowing east from the Churchill Mountains between Mount Lindley and Mount Hoskins to enter Starshot Glacier. It was named by the Holyoake, Cobham, and Queen Elizabeth Ranges Party of the New Zealand Geological Survey Antarctic Expedition (1964–65) for B. Ahern, a member of the party.\n\n"}
{"id": "1267492", "url": "https://en.wikipedia.org/wiki?curid=1267492", "title": "Anders Gustaf Ekeberg", "text": "Anders Gustaf Ekeberg\n\nAnders Gustaf Ekeberg (Stockholm, Sweden, 16 January 1767 – Uppsala, Sweden, 11 February 1813) was a Swedish chemist who discovered tantalum in 1802. He was notably deaf.\n\nAnders Gustav Ekeberg was a Swedish scientist, mathematician and expert in Greek literature. He was a gifted student and enrolled at Uppsala University 1784, graduating in 1788. He was made docent in chemistry 1794 and experimentator (\"laborator\") 1799. In 1799, he was elected a member of the Royal Swedish Academy of Sciences. Carl Gustaf Ekeberg was his uncle.\n\nEkeberg is credited with finding the element tantalum in two different minerals, specifically, tantalite from Kimito, Finland and yttrotantalite from Ytterby, Sweden. Ekeberg named the new element after the mythical Ancient Greek demigod Tantalus who, according to legend, was condemned to eternal frustration when he had to stand in water up to his neck, but the water receded as he attempted to drink.\n\nEkeberg suffered from poor health throughout his life. During his childhood a severe cold had impaired his hearing, which was further weakened over the years, so that it hindered his teaching activities. Subsequently, a gas explosion blinded him in one eye. Ekeberg was portrayed by his friends and students as a kind and gentle man. He died, unmarried, at the age of 46.\n\nThe Anders Gustaf Ekeberg Tantalum Prize\n\nIn 2018 the Tantalum-Niobium International Study Center established The Anders Gustaf Ekeberg Tantalum Prize (\"Ekeberg Prize\"), an annual award to recognize excellence in tantalum research. The Prize will increase awareness of the many unique properties of tantalum products and the applications in which they excel. \nThe inaugural winner of the Ekeberg Prize was Dr Yuri Freeman for his book “Tantalum and Niobium-Based Capacitors” (Springer, 2018).\n\n"}
{"id": "5814962", "url": "https://en.wikipedia.org/wiki?curid=5814962", "title": "Angle condition", "text": "Angle condition\n\nIn mathematics, the angle condition is a constraint that is satisfied by the locus of points in the s-plane on which closed-loop poles of a system reside. In combination with the magnitude condition, these two mathematical expressions fully determine the root locus.\n\nLet the characteristic equation of a system be formula_1, where formula_2. Rewriting the equation in polar form is useful.\n\nwhere formula_5 are the only solutions to this equation. Rewriting formula_6 in factored form,\n\nand representing each factor formula_8 and formula_9 by their vector equivalents, formula_10 and formula_11, respectively, formula_6 may be rewritten.\n\nSimplifying the characteristic equation, \n\nfrom which we derive the angle condition:\n\nfor formula_5, \n\nare the angles of zeros 1 to \"n\", and\n\nare the angles of poles 1 to \"m\".\n\nThe magnitude condition is derived similarly.\n"}
{"id": "51598704", "url": "https://en.wikipedia.org/wiki?curid=51598704", "title": "Auguste Aymard", "text": "Auguste Aymard\n\nAuguste Aymard (1808–1889) was a French prehistorian and palaeontologist who lived and died in Puy-en-Velay (Haute-Loire). He described the fossil \"Entelodon magnus\" and the fossil genera \"Anancus\" and \"Amphechinus\".\nAuguste Aymard was the archivist for the Departement Haute-Loire and Conservateur of Musée du Puy-en-Velay. He made archaeological discoveries in Puy-en-Velay, Polignac, Haute-Loire and Espaly-Saint-Marcel.\n\n\n"}
{"id": "6547859", "url": "https://en.wikipedia.org/wiki?curid=6547859", "title": "Axiom of Maria", "text": "Axiom of Maria\n\nAxiom of Maria is a precept in alchemy: \"One becomes two, two becomes three, and out of the third comes the one as the fourth.\" It is attributed to 3rd century alchemist Maria Prophetissa, also called the Jewess, sister of Moses, or the Copt. Marie-Louise von Franz gives an alternative version this: \"Out of the One comes Two, out of Two comes Three, and from the Third comes the One as the Fourth.\"\n\nSwiss psychiatrist Carl Jung (1875–1961) used the axiom as a metaphor for the process of individuation. \"One\" is unconscious wholeness; \"two\" is the conflict of opposites; \"three\" points to a potential resolution; \"the third\" is the transcendent function, described as a \"psychic function that arises from the tension between consciousness and the unconscious and supports their union\"; and \"the one as the fourth\" is a transformed state of consciousness, relatively whole and at peace.\n\nJung speaks of the axiom of Maria as running in various forms through the whole of alchemy like a \"leitmotiv.\" In \"The Psychology of the Transference\" he writes of the fourfold nature of the transforming process using the language of Greek alchemy:\n\nThe Axiom of Maria may be interpreted as an alchemical analogy of the process of individuation from the many to the one, from undifferentiated unconsciousness to individual consciousness.\n\n\n\n"}
{"id": "2988398", "url": "https://en.wikipedia.org/wiki?curid=2988398", "title": "Capital improvement plan", "text": "Capital improvement plan\n\nA capital improvement plan (CIP), or capital improvement program, is a short-range plan, usually four to ten years, which identifies capital projects and equipment purchases, provides a planning schedule and identifies options for financing the plan. Essentially, the plan provides a link between a\nmunicipality, school district, parks and recreation department and/or other local government entity and a comprehensive and strategic plan and the entity's annual budget.\n\nA CIP provides many benefits including: \n\nThe CIP typically includes the following information:\n\n\nPrior to undertaking the development of the CIP, the government entity will want to define the criteria for what kind of projects or equipment are to be included and organize a process for developing the plan. What is defined as a capital project or capital purchase may vary from city to county to district to state depending on the size of the local government provisioning the plan. Generally, they will be tangible items that have a life expectancy greater than one year.\n\nA local government will also need to forecast where it believes it will face future demands and growth, which will involve an inventory of existing facilities, infrastructure and equipment. In addition, a local government will want to develop basic policies for implementing the plan. Because the CIP includes financing issues, the municipality may want to seek advice from their financial advisor and/or bond counsel. A review of the municipality's current finances is also vital.\n\nOnce the CIP is finalized, the local government may be required to hold a public hearing before the plan is adopted by a city council, a board of regents and/or a bond review commission.\n\n\nDeveloping a Capital Improvements Plan - Massachusetts 1997.pdf\n\n"}
{"id": "33355192", "url": "https://en.wikipedia.org/wiki?curid=33355192", "title": "City Mayors Foundation", "text": "City Mayors Foundation\n\nThe City Mayors Foundation, also known as City Mayors, is an international think tank dedicated to urban affairs. It has been active since 2003 and runs the biennial World Mayor award, as well as providing pro bono consultancy services. Unlike Eurocities and United Cities and Local Governments it is wholly independent of any city.\n\nCity Mayors has instituted a Code of Ethics for city leaders who wish to perform their duties beyond all reproach. Preamble from the Code: \"Good and honest local government is the foundation of any nation that strives to provide its citizens with happiness, security and prosperity. Incompetence, corruption and misconduct in local government threaten fundamental decency in a society.\" The foundation also publishes books as an imprint on urban affairs.\n\nThe City Mayors Foundation commissions the trophy presented as the World Mayor Award. The trophy was designed by artist Manuel Ferrari and is handmade out of steel by the metalworker Kaspar Swankey.\n\nThe City Mayors Foundation was set up in 2003 by Tann vom Hove (UK/Germany), Ruth Maguire (UK), Guy Kervella (UK/France), Nick Swift (Canada) and Josh Fecht (USA). In 2004 Andrew Stevens (UK), Mayraj Fahim (USA), Tony Favro (USA) and Adriana Maciel (Mexico) joined City Mayors.\n\n"}
{"id": "8160882", "url": "https://en.wikipedia.org/wiki?curid=8160882", "title": "Co-Extra", "text": "Co-Extra\n\nCo-Extra was an EU-funded research programme on \"co-ex\"istence and \"tra\"ceability of genetically modified crops and their edible derivatives that ran from 2005-2009. It was granted €13.5 million under the Sixth Framework Programme of the European Union, and is conducted by more than 200 scientists in 52 organisations in 18 countries.\n\nThe research programme studied and validated biological containment methods, forged supply chain organisations, and provided practical tools and methods for implementing co-existence between GMO-based (i.e., based on the use of genetically modified organisms) and non-GMO-based supply chains.\n\nWith regard to supporting cost-effective documentary traceability, Co-Extra was aimed at devising reliable, analytical detection methods, and at establishing the most appropriate methods of collecting, organising and distributing information. A core programme objective was the provision, to all stakeholders of food and feed chains, of a central decision-support system incorporating all necessary institutional tools, methods, models and guidelines.\n\nThe programme was structured in eight work packages (WP):\n\nThe editorial team of WP 8 presented all findings on the programme's website (no longer in existence as of 2014), which had been written and designed for an audience of stakeholders and interested lay persons. The website also supplied background information on the public debate on co-existence and traceability in many EU countries, as well as on the current status of implementation of co-existence and traceability legislation and measures.\n\n"}
{"id": "862058", "url": "https://en.wikipedia.org/wiki?curid=862058", "title": "Creativity and mental illness", "text": "Creativity and mental illness\n\nThe concept of a link between creativity and mental illness has been extensively discussed and studied by psychologists and other researchers for centuries. Parallels can be drawn to connect creativity to major mental disorders including: bipolar disorder, schizophrenia, major depressive disorder, anxiety disorder, and ADHD. For example, studies have demonstrated correlations between creative occupations and people living with mental illness. There are cases that support the idea that mental illness can aid in creativity, but it is also generally agreed that mental illness does not have to be present for creativity to exist.\n\nIt has been proposed that there is a particular link between creativity and mental illness (e.g. bipolar disorder, whereas major depressive disorder appears to be significantly more common among playwrights, novelists, biographers, and artists). Association between mental illness and creativity first appeared in literature in the 1970s, but the idea of a link between \"madness\" and \"genius\" is much older, dating back at least to the time of Aristotle. In order to comprehend how the connection between “madness” and “genius” correlate, first understand that there are different types of geniuses: literary geniuses, creative geniuses, scholarly geniuses, and “all around” geniuses. Since there are many different categories, this means that individuals can completely excel in one subject and know an average, or below average, amount of information about others. The Ancient Greeks believed that creativity came from the gods, in particular the Muses (the mythical personifications of the arts and sciences, the nine daughters of Zeus). In the Aristotelian tradition, conversely, genius was viewed from a physiological standpoint, and it was believed that the same human quality was perhaps responsible for both extraordinary achievement and melancholy. Romantic writers had similar ideals, with Lord Byron having pleasantly expressed, \"We of the craft are all crazy. Some are affected by gaiety, others by melancholy, but all are more or less touched\".\n\nIndividuals with mental illness are said to display a capacity to see the world in a novel and original way; literally, to see things that others cannot.\n\nFor many years, the creative arts have been used in therapy for those recovering from mental illness or addiction.\n\nAnother study found creativity to be greater in schizotypal than in either normal or schizophrenic individuals. While divergent thinking was associated with bilateral activation of the prefrontal cortex, schizotypal individuals were found to have much greater activation of their \"right\" prefrontal cortex. This study hypothesizes that such individuals are better at accessing both hemispheres, allowing them to make novel associations at a faster rate. In agreement with this hypothesis, ambidexterity is also associated with schizotypal and schizophrenic individuals.\n\nThree recent studies by Mark Batey and Adrian Furnham have demonstrated the relationships between schizotypal and hypomanic personality and several different measures of creativity.\n\nParticularly strong links have been identified between creativity and mood disorders, particularly manic-depressive disorder (a.k.a. bipolar disorder) and depressive disorder (a.k.a. unipolar disorder). In \"Touched with Fire: Manic-Depressive Illness and the Artistic Temperament\", Kay Redfield Jamison summarizes studies of mood-disorder rates in writers, poets and artists. She also explores research that identifies mood disorders in such famous writers and artists as Ernest Hemingway (who shot himself after electroconvulsive treatment), Virginia Woolf (who drowned herself when she felt a depressive episode coming on), composer Robert Schumann (who died in a mental institution), and even the famed visual artist Michelangelo.\n\nA study looking at 300,000 persons with schizophrenia, bipolar disorder or unipolar depression, and their relatives, found overrepresentation in creative professions for those with bipolar disorder as well as for undiagnosed siblings of those with schizophrenia or bipolar disorder. There was no overall overrepresentation, but overrepresentation for artistic occupations, among those diagnosed with schizophrenia. There was no association for those with unipolar depression or their relatives.\n\nA study involving more than one million people, conducted by Swedish researchers at the Karolinska Institute, reported a number of correlations between creative occupations and mental illnesses. Writers had a higher risk of anxiety and bipolar disorders, schizophrenia, unipolar depression, and substance abuse, and were almost twice as likely as the general population to kill themselves. Dancers and photographers were also more likely to have bipolar disorder.\n\nHowever, as a group, those in the creative professions were no more likely to experience psychiatric disorders than other people, although they were more likely to have a close relative with a disorder, including anorexia and, to some extent, autism, the Journal of Psychiatric Research reports.\n\nResearch in this area is usually constrained to cross-section data-sets. One of the few exceptions is an economic study of the well-being and creative output of three famous music composers over their entire lifetime. The emotional indicators are obtained from letters written by Wolfgang Amadeus Mozart, Ludwig van Beethoven and Franz Liszt, and the results indicate that negative emotions had a causal impact on the creative production of the artists studied.\n\nPsychological stress has also been found to impede spontaneous creativity.\n\nA 2005 study at the Stanford University School of Medicine measured creativity by showing children figures of varying complexity and symmetry and asking whether they like or dislike them. The study showed for the first time that a sample of children who either have or are at high risk for bipolar disorder tend to dislike simple or symmetric symbols more. Children with bipolar parents who were not bipolar themselves also scored higher dislike scores.\n\nMood-creativity research reveals that people are most creative when they are in a positive mood and that mental illnesses such as depression or schizophrenia actually decrease creativity. People who have worked in the field of arts throughout the history have had problems with poverty, persecution, social alienation, psychological trauma, substance abuse, high stress and other such environmental factors which are associated with developing and perhaps causing mental illness. It is thus likely that when creativity itself is associated with positive moods, happiness, and mental health, pursuing a career in the arts may bring problems with stressful environment and income. Other factors such as the centuries-old stereotype of the suffering of a \"mad artist\" help to fuel the link by putting expectations on how an artist should act, or possibly making the field more attractive to those with mental illness. Additionally, where specific areas of the brain are less developed than others by nature or external influence, the spacial capacity to expand another increases beyond \"the norm\" allowing enhanced growth and development.\n\nSimulations by Stephen Thaler of limbo-thalamo-cortical loops engaged in invention, discovery, and artistic endeavors reveal a critical link between various psychopathologies and creativity. These contemplative artificial neural systems exploit the computational equivalent of volume-released neurotransmitters, namely random, hopping disturbances applied to connection weights in a process tantamount to neuromodulation, the diffusive molecular infiltration of the brain's synapses. These disturbances seed the formation of the novel neural activation patterns necessary for creativity. Close observation of such artificial neural systems as they engage in creative problem solving tasks reveals a cyclic or ‘tidal’ variation in synaptic chaos. At higher disturbance levels, ideas form as the memories and confabulations absorbed within multiple neural modules weakly couple into transient, subliminal notions that go unnoticed by critic neural modules incapacitated by the synaptic chaos. As disturbance levels subside, certain neural modules may lucidly perceive novelty, utility, or value to these oftentimes half-baked notions that then perfect themselves, consolidating into full-blown ideas coupled with accompanying affective responses. Extending these computational findings to human cognition, creativity cannot be attributed to any given brain state or mood. Instead, it is a hysteretic effect brought about by multiple transits through chaotic and quiescent phases. The more intense these swings, the more novel the creative product, but at the expense of increasingly severe cognitive pathologies, including hallucinations, confusion, inattention to the external environment, and inability to differentiate imagination from reality. In addition to providing a transparent artificial neural system by which to study creative cognition, such brain simulations provide evaluation metrics for originality and utility that are quantitative rather than subjective.\n\nBipolar disorder is one of the main mental disorders said to inspire creativity, as the manic episodes are typically characterised by prolonged and elevated periods of energy. In her book, \"Touched With Fire\", American clinical psychologist Kay Redfield Jamison wrote that 38% of writers and poets had been treated for a type of mood disorder, and virtually all creative writers and artists (89%) had experienced \"intense, highly productive, and creative episodes\". These were characterised by \"pronounced increases in enthusiasm, energy, self-confidence, speed of mental association, fluency of thought and elevated mood\". There is a range of types of bipolar disorder. Individuals with Bipolar I Disorder experience severe episodes of mania and depression with periods of wellness between episodes. The severity of the manic episodes can mean that the person is seriously disabled and unable to express the heightened perceptions and flight of thoughts and ideas in a practical way. Individuals with Bipolar II Disorder experience milder periods of hypomania during which the flight of ideas, faster thought processes and ability to take in more information can be converted to art, poetry or design. Dutch artist Vincent Van Gogh is widely theorised to have suffered from bipolar disorder. Other notable creative people with bipolar disorder include Carrie Fisher, Demi Lovato, Stephen Fry (who suffers from cyclothimia, a milder and more chronic form of bipolar), Mariah Carey, Catherine Zeta-Jones, Jean-Claude Van Damme, and Patty Duke.\n\nPeople with schizophrenia live with positive, negative, and cognitive symptoms. Positive symptoms (psychotic behaviors that are not present in healthy people): hallucinations, delusions, thought & movement disorders. Negative symptoms (abnormal functioning of emotions and behavior): \"flat affect\", Anhedonia, reserved. Cognitive symptoms: problems with \"executive functioning\", attention, and memory. One artist known for his schizophrenia was the Frenchman Antonin Artaud, founder of the Theatre of Cruelty movement. In \"Madness and Modernism\" (1992), clinical psychologist Louis A. Sass noted that many common traits of schizophrenia – especially fragmentation, defiance of authority, and multiple viewpoints – happen to also be defining features of modern art.\n\nIn a 2002 conversation with Christopher Langan, educational psychologist Arthur Jensen stated that the relationship between creativity and mental disorder \"has been well researched and is proven to be a fact\", writing that schizothymic characteristics are somewhat more frequent in philosophers, mathematicians, and scientists than in the general population. In a 2015 study, Iceland scientists found that people in creative professions are 25% more likely to have gene variants that increase the risk of bipolar disorder and schizophrenia, with deCODE Genetics co-founder Kári Stefánsson saying, \"Often, when people are creating something new, they end up straddling between sanity and insanity. I think these results support the concept of the mad genius.\"\n\nMany famous historical figures gifted with creative talents may have been affected by bipolar disorder. Ludwig van Beethoven, Virginia Woolf, Ernest Hemingway, Isaac Newton, Judy Garland and Robert Schumann are some people whose lives have been researched to discover signs of mood disorder. In many instances, creativity and psychosis share some common traits, such as a tendency for \"thinking outside the box,\" flights of ideas, speeding up of thoughts and heightened perception of visual, auditory and somatic stimuli.\n\nIt has been found that the brains of creative people are more open to environmental stimuli due to smaller amounts of latent inhibition, an individual's unconscious capacity to ignore unimportant stimuli. While the absence of this ability is associated with psychosis, it has also been found to contribute to original thinking.\n\nMany people with bipolar disorder may feel powerful emotions during both depressive and manic phases, potentially aiding in creativity. Because (hypo)mania decreases social inhibition, performers are often daring and bold. As a consequence, creators commonly exhibit characteristics often associated with mental illness. The frequency and intensity of these symptoms appear to vary according to the magnitude and domain of creative achievement. At the same time, these symptoms are not equivalent to the full-blown psychopathology of a clinical manic episode which, by definition, entails significant impairment.\n\nSome creative people have been posthumously diagnosed as experiencing bipolar or unipolar disorder based on biographies, letters, correspondence, contemporaneous accounts, or other anecdotal material, most notably in Kay Redfield Jamison's book \"Touched with Fire: Manic-Depressive Illness and the Artistic Temperament\". \"Touched With Fire\" presents the argument that bipolar disorder, and affective disorders more generally, may be found in a disproportionate number of people in creative professions such as actors, artists, comedians, musicians, authors, performers and poets.\n\nSeveral recent clinical studies have also suggested that there is a positive correlation between creativity and bipolar disorder, although the relationship between the two is unclear. Temperament may be an intervening variable. Ambition has also been identified as being linked to creative output in people across the bipolar spectrum.\n\nBrain simulations built from artificial neural nets manifest the classic psychopathologies as they push themselves toward higher levels of creativity.\n\nIn 2017, associate professor of psychiatry Gail Saltz stated that the increased production of divergent thoughts in people with mild-to-moderate mental illnesses leads to greater creative capacities. Saltz argued that the \"wavering attention and day-dreamy state\" of ADHD, for example, \"is also a source of highly original thinking. [...] CEOs of companies such as Ikea and Jetblue have ADHD. Their creativity, out-of-the-box thinking, high energy levels, and disinhibited manner could all be a positive result of their negative affliction.\" Mania has also been credited with aiding in creativity because \"when speed of thinking increases, word associations form more freely, as do flight of ideas, because the manic mind is less inclined to filtering details that, in a normal state, would be dismissed as irrelevant.\"\n\nAlbert Rothenberg of \"Psychology Today\" noted that the \"list of mentally ill creators who were successful [...] is dwarfed by the very large number of highly creative people both in modern times and throughout history without evidence of disorder\", which includes figures such as William Shakespeare, Johann Sebastian Bach, and Jane Austen. Rothenberg reported that when interviewing 45 science Nobel laureates for the book \"Flight from Wonder\" he had found no evidence of mental illness in any of them, and also stated, \"The problem is that the criteria for being creative is never anything very creative. Belonging to an artistic society, or working in art or literature, does not prove a person is creative. But the fact is that many people who have mental illness do try to work in jobs that have to do with art and literature, not because they are good at it, but because they're attracted to it. And that can skew the data.\"\n\nThe 2012 book \"Tortured Artists\", by the American arts journalist Christopher Zara, shows the universal nature of the tortured artist stereotype and how it applies to all of the creative disciplines, including film, theater, literature, music, and visual art. The artists profiled in the book have made major contributions to their respective mediums (Charles Schulz, Charlie Parker, Lenny Bruce, Michelangelo, Madonna, Andy Warhol, Amy Winehouse, and dozens of others). In each case, the author attempts to make a connection between the art and the artist's personal suffering.\n\n\n\n\n\n\n\n"}
{"id": "3928108", "url": "https://en.wikipedia.org/wiki?curid=3928108", "title": "DARPA Falcon Project", "text": "DARPA Falcon Project\n\nThe DARPA Falcon Project (Force Application and Launch from CONtinental United States) is a two-part joint project between the Defense Advanced Research Projects Agency (DARPA) and the United States Air Force (USAF) and is part of Prompt Global Strike. One part of the program aims to develop a reusable, rapid-strike \"Hypersonic Weapon System\" (HWS), now retitled the \"Hypersonic Cruise Vehicle\" (HCV), and the other is for the development of a launch system capable of accelerating an HCV to cruise speeds, as well as launching small satellites into Earth orbit. This two-part program was announced in 2003 and continued into 2006.\n\n\"Blackswift\" was a project announced under the Falcon banner using a fighter-sized unmanned aircraft which would take off from a runway and accelerate to before completing its mission and landing again. The memo of understanding between DARPA and the USAF on Blackswift—also known as the HTV-3X—was signed in September 2007. The Blackswift HTV-3X did not receive needed funding and was canceled in October 2008.\n\nCurrent research under FALCON program is centered on X-41 Common Aero Vehicle (CAV), a common aerial platform for hypersonic ICBMs and cruise missiles, as well as civilian RLVs and ELVs. The prototype Hypersonic Technology Vehicle 2 (HTV-2) first flew on 22 April 2010; the second test flew 11 August 2011. Both flights ended prematurely.\n\nThe aim was always to be able to deploy a craft from the continental United States, which could reach anywhere on the planet within one to two hours. The X-20 Dyna-Soar in 1957 was the first publicly acknowledged program—although this would have been launched vertically on a rocket and then glided back to Earth, as the Space Shuttle did, rather than taking off from a runway. Originally, the Shuttle was envisaged as a part-USAF operation, and separate military launch facilities were built at Vandenberg AFB at great cost, though never used. After the open DynaSoar USAF program from 1957–1963, spaceplanes went black (became highly classified). In the mid-1960s, the CIA began work on a high-Mach spyplane called Project Isinglass. This developed into Rheinberry, a design for a Mach-17 air-launched reconnaissance aircraft, which was later canceled.\n\nAccording to Henry F. Cooper, who was the Director of the Strategic Defense Initiative (\"Star Wars\") under President Reagan, spaceplane projects consumed $4 billion of funding in the 1970s, 1980s and 1990s (excluding the Space Shuttle). This does not include the 1950 and 1960s budgets for the Dynasoar, ISINGLASS, Rheinberry, and any 21st-century spaceplane project which might emerge under Falcon. He told the United States Congress in 2001 that all the United States had in return for those billions of dollars was \"one crashed vehicle, a hangar queen, some drop-test articles and static displays\". Falcon was allocated US$170 million for budget year 2008.\n\nThe HyperSoar was an American hypersonic aircraft project developed at Lawrence Livermore National Laboratory (LLNL). It was to be capable of flying at around Mach 12 (9,200 mph, 14,700 km/h), allowing it to transit between any two points on the globe in under two hours. The HyperSoar was predicted to be a passenger plane capable of skipping outside the atmosphere to prevent it from burning up in the atmosphere. A trip from Chicago to Tokyo (10,123 kilometers) would take 18 skips, or 72 minutes. It was planned to use hydrocarbon-based engines outside the atmosphere and experimental jet engine technology with testing to begin by 2010. Later, the Hypersoar concept was acquired from LLNL by DARPA, and in 2002 it was combined with the USAF X-41 Common Aero Vehicle to form the FALCON program.\n\nThe overall FALCON (\"F\"orce \"A\"pplication and \"L\"aunch from \"CON\"tinental United States) program announced in 2003 had two major components: a small launch vehicle for carrying payloads to orbit or launching the hypersonic weapons platform payload, and the hypersonic vehicle itself.\n\nThe DARPA FALCON solicitation in 2003 asked for bidders to do development work on proposed vehicles in a first phase of work, then one or more vendors would be selected to build and fly an actual launch vehicle. Companies which won first phase development contracts of $350,000 to $540,000 in November 2003 included:\n\nThe first phase of the hypersonic weapon system development was won by three bidders in 2003, each receiving a $1.2 to $1.5 million contract for hypersonic vehicle development:\n\nLockheed Martin received the only Phase 2 HWS contract in 2004, to develop technologies further and reduce technology risk on the program.\n\nFollowing the Phase 2 contract, DARPA and the US Air Force continued to develop the hypersonic vehicle platform.\n\nThe program was to follow a set of flight tests with a series of hypersonic technology vehicles.\n\nThe FALCON project includes:\n\nThe Hypersonic Cruise Vehicle (HCV) would be able to fly 9,000 nautical miles (17,000 km) in 2 hours with a payload of 12,000 lb (5,500 kg). It would fly at a high altitude and achieve speeds of up to Mach 20.\n\nThe Blackswift was a proposed aircraft capable of hypersonic flight designed by the Lockheed Martin Skunk Works, Boeing, and ATK.\n\nThe USAF states that the \"Blackswift flight demonstration vehicle will be powered by a combination turbine engine and ramjet, an all-in-one power plant. The turbine engine accelerates the vehicle to around Mach 3 before the ramjet takes over and boosts the vehicle up to Mach 6.\" Dr. Steven Walker, the Deputy Director of DARPA's Tactical Technology Office (acting Director as of January, 2017), will be coordinating the project. He told the USAF website,\n\nThe Falcon program has announced the hypersonic horizontal take-off Blackswift/HTV-3X. It is also launching the HTV-2 off the top of a rocket booster. Falcon seems to be converging from two directions, on the ultimate goal of producing a hypersonic aircraft which can take off and land from a runway in the USA, and be anywhere in the world in an hour or two. Falcon is methodically proceeding toward a Hypersonic Cruise Vehicle. Dr. Walker stated,\n\nIn October 2008 it was announced that HTV-3X or Blackswift did not receive needed funding in the fiscal year 2009 defense budget and had been canceled. The Hypersonic Cruise Vehicle program will continue with reduced funding.\n\nDARPA had two HTV-2s built for two flight tests in 2010 and 2011. The Minotaur IV light rocket is the booster for the HTV-2 with Vandenberg Air Force Base serving as the launch site. DARPA planned the flights to demonstrate thermal protection systems and aerodynamic control features. Test flights were supported by NASA, the Space and Missile Systems Center, Lockheed Martin, Sandia National Laboratories and the Air Force Research Laboratory's (AFRL) Air Vehicles and Space Vehicles Directorates.\n\nThe first HTV-2 flight was launched on 22 April 2010. The HTV-2 glider was to fly across the Pacific to Kwajalein at Mach 20. The launch was successful, but the first mission was not completed as planned. Reports stated that contact had been lost with the vehicle nine minutes into the mission. In mid-November, DARPA revealed that the test flight had ended when the computer autopilot had \"commanded flight termination\". According to a DARPA spokesman, \"When the onboard system detects [undesirable or unsafe flight] behavior, it forces itself into a controlled roll and pitchover to descend directly into the ocean.\" Reviews found that the craft had begun to roll violently.\n\nA second flight was launched on 11 August 2011. The unmanned Falcon HTV-2 successfully separated from the booster and entered the mission's glide phase, but again lost contact with control about nine minutes into its planned 30-minute Mach 20 glide flight. Initial reports indicated it purposely impacted the Pacific Ocean along its planned flight path as a safety precaution. Some analysts thought that the second failure would result in an overhaul of the Falcon program.\n\nIn July 2013, DARPA decided it would not conduct a third flight test of the HTV-2 because enough data had been collected from the first two flights, and another test was not thought to provide any more usable data for the cost. The tests provided data on flight aerodynamics and high-temperature effects on the aeroshell. Work on the HTV-2 would continue to summer 2014 to provide more study on hypersonic flight. The HTV-2 was the last active part of the Falcon program. DARPA has now changed its focus for the program from global/strategic strike to high-speed tactical deployment to penetrate air defenses and hit targets quickly from a safe distance.\n\n\n"}
{"id": "48212870", "url": "https://en.wikipedia.org/wiki?curid=48212870", "title": "Edvard Jünger", "text": "Edvard Jünger\n\nFrederik Gottlieb Edvard Jünger (19 April 1823 – 21 October 1899) was a Danish precision mechanic and instrument maker. His company was taken over by Christopher Peter Jürgensen in 1869. In the 1870s and early 1880s, he was the manager of Holmegaard Glass Factory near Næstved.\n\nJünger was born in Holbæk. He initially worked as a clerk at various offices, most lately at the Bregentved estate. He was, however, interested in the technical sciences and his talent for mechanics caught the attention of Hans Christian Ørsted. Ørsted helped him obtain a grant from count F. M. Knuth which enabled him to enroll at the College of Advanced Technology. His education also brought him to Munich and Vienna.\n\nBack in Denmark, he settled as an instrument maker in Copenhagen in 1852. He produced technical instruments for the College of Advanced Technology and Sorø Academy as well as distance measurement devices for the Danish army and navy and had also many customers abroad. Júrger lived on Sortedam Dossering No. 37 and worked out of his basement. He was involved in the development of the Hansen Writing Ball in 1865. He spent several years working on an equatorial mount for Østervold Observatory and later a similar instrument for Lund Observatory in Sweden. In 1867, he was appointed to university mechanic (\"universitetsmekanikus\") at University of Copenhagen and the following year he received the title of professor.\n\nJünger's work compromised his vision and in 1869 he ceded his company to his employee Christopher Peter Jürgensen. He went abroad in 1869 and settled on a country estate in Steiermark. In 1873, he received an offer to take over the management of the Holmegaard Glass Factory and returned to Denmark where he ran the company for 11 years. He spent his last years in Copenhagen and is buried at Solbjerg Cemetery.\n"}
{"id": "37067463", "url": "https://en.wikipedia.org/wiki?curid=37067463", "title": "Ethnosport", "text": "Ethnosport\n\nEthnosport (from the — Ethnos meaning \"people\" + \"sport\") is a set of traditional styles of physical activity, methods of their preservation, and their development, as described in the ethnosport theory of Russian cultural anthropologist Alexey Kylasov. \n\nEthnosport is an institutional form of united social and cultural space for all traditional styles of physical activity. The purpose of ethnosport theory is to provide a methodological basis for the design and prediction of the formation and functioning of social and cultural systems in conditions of rising representations of ethnocultural sport processes sport.\n\nSport became emancipated as traditional games and sport transformed in an advertised product. Sports became more independent from ethnocultural gaming traditions that in the past belonged to the entertainment of society.\n\nSport emancipation led to its emergence and consolidation, which was followed by a new social function. Currently, \"sport for all\" is often a symbol of the values of a liberal society, which are easily accepted worldwide as \"universal\" because of its popularity. This new function allows sport to impose \"standard values\" and \"ideal models\" on all nations, requiring automatic copying to the prejudice of age-old traditions and identity. This is how public mind \"reads\" sport ideals, such as the Olympics and international sport.\n\nThe international nature of sports facilitates consolidation of this new ideological function, accessible to all nations without belonging to any of them. Sport also has the ability to mask the deepening polarization between countries in the global division of labor as well as their political differences. Sport provides a targeted ideological influence (spread of liberal ideology) for the imaginary de-ideology. These differences do not seem as important if athletes from communist, capitalist, developed, or developing countries have an equal chances of succeed.\n\nEthnosport identifies traditional styles of physical activity that have undergone a sportization, such as the introduction of sports-type institutes of sports, as expressed in the formation of federations, explicit refereeing, standard equipment, standard scoring systems, and regular, predictable outcomes.\n\nExamples of ethnosports include martial arts, bellydance, yoga, and massage.\n\nToday, cultural diversity of sport brings an institutional standard of promotion and development to traditional physical activities. Many countries are beginning to move traditional sports in certain direction, offering these traditional activities protection and preservation. Traditional games are proclaimed as a part of UNESCO World Heritage Sites. The Social and Human Science department of UNESCO coordinates efforts of various organizations and academic institutions with regards to traditional sport.\n\nGlobalization has led to the need for consideration of local cultural heritage, where local cultural resources (in particular, traditional styles of physical activity) are under threat of complete or partial destruction if they are not included in global sport projects, such as the Olympics, the World Games, the Commonwealth Games, the Mediterranean Games, and the Asian Games. International sports organizations such as the IOC, SportAccord, IWGA, IMSA, and FILA recognize this treat and try to combat it.\n\nFILA has moved further than others in this direction. FILA launched a broad program of cooperation in the field of ethnosport. Now, along with Olympic freestyle wrestling, Greco-Roman wrestling, and Women's freestyle wrestling FILA develops Grappling, Pankration, Beach wrestling, and many other traditional wrestling styles. FILA works with the World Committee of Grappling and the Pankration and World Traditional Wrestling Committeeto put on the FILA World Wrestling Games. Because of FILA's efforts, tatarcha koresh and Kazakh kores were included in program of the 2013 Summer Universiade in Kazan as a new discipline: belt-wrestling. Recognition of Yakut wrestling (\"khapsagai\") and mas-wrestling have allowed those disciplines to establish federations and hold their first continental championships using FILA's infrastructure.\n\nAlthough there is overall positive impact to recognition of ethnocultural sports as subjects of international sport, such progress does not satisfy enthusiasts of ethnosport who want full autonomy. Their distrust is expressed thusly: can sportization help spread at least some traditional physical activities? Immanuel Wallerstein who claims that countries cannot jump from the previous stage of development to another, if the previous stage is not included in the capitalist system of relations. By analogy, ethnocultural styles of competitions cannot become sports if their origin country is not included in the global world of sport.\n\nIn 2012 the Ethnosport World Society was created in order to promote ethnosport as an alternative to Anglo-Saxon sports.\n\nTAFISA, a world organization that promotes ethnosport.\n"}
{"id": "2271813", "url": "https://en.wikipedia.org/wiki?curid=2271813", "title": "European Research Council", "text": "European Research Council\n\nThe European Research Council (ERC) is a public body for funding of scientific and technological research conducted within the European Union (EU). Established by the European Commission in 2007, the ERC is composed of an independent Scientific Council, its governing body consisting of distinguished researchers, and an Executive Agency, in charge of the implementation. It forms part of the framework programme of the union dedicated to research and innovation, Horizon 2020, preceded by the Seventh Research Framework Programme (FP7). The ERC budget is over €13 billion from 2014 – 2020 and comes from the Horizon 2020 programme, a part of the European Union's budget. Under Horizon 2020 it is estimated that around 7,000 ERC grantees will be funded and 42,000 team members supported, including 11,000 doctoral students and almost 16,000 post-doctoral researchers.\n\nResearchers from any field can compete for the grants that support pioneering projects. The ERC competitions are open to top researchers also from outside the union. The average success rate is about 12%. Five ERC grantees have won Nobel Prizes. Grant applications are assessed by qualified experts. Excellence is the sole criterion for selection; there are neither thematic priorities, nor geographical quotas for funding. The aim is to recognise the best ideas, and confer status and visibility to the best research in Europe, while also attracting talent from abroad.\n\nAlong with national funding bodies, the ERC aims to improve the climate for European frontier research. The Scientific Council has been keen to learn from the ERC’s peers in national research councils (European and overseas) and to engage in dialogue and appropriate collaboration. Also, some countries – such as Poland – have used the ERC model to establish national basic research funding bodies.\n\nThe idea of having a pan-European funding mechanism for basic research has been discussed and supported for a long time. However, its realisation was held back at the political level because the founding treaties of the European Union was interpreted as allowing union funding only to strengthen the scientific and technological base of European industry – that is, only funding for applied research rather than basic research. In conjunction with the Lisbon declaration in 2000, leaders of the EU, in particular the European Commissioner for Research at the time, Philippe Busquin, realised that the European Treaty had to be reinterpreted; a transformation of European economy from traditional manufacturing to a knowledge-based economy has to involve the enhanced support at the European level for science of all kinds, including both fundamental and applied research.\n\nIn 2003, a report from the ERC Expert Group (ERCEG), chaired by Professor Federico Mayor, described how the ERC could take shape. In 2004, a high-level expert group was commissioned to further explore the possibilities of creating a European Research Council. This group concluded that the EU should establish an institution to support frontier research. A number of other expert groups, such as one commissioned by the European Science Foundation, another charged with the task of analysing the economic implications of the Lisbon declaration and a high level group commissioned by the European Commission, also arrived at a similar conclusion and boosted the idea. With the ice broken, scientists and politicians have since strongly supported the establishment of an ERC. In 2006, the European Parliament and EU Council of Ministers accepted the Seventh Framework Programme (FP7) for the European Union's support for research, of which the ERC was a flagship component. In the ERC kick-off conference in Berlin, various speakers talked of 'an idea whose time has come', 'a European factory of ideas', 'a champions' league’, 'a great day for Europe and a great day for science', and the beginning of a 'snowball effect'.\n\nThe ERC is governed by the Scientific Council (ScC), consisting of 22 eminent European scientists and scholars (including Nobel prize laureates), and supported operationally by the European Research Council Executive Agency (ERCEA), based in Brussels. The ScC acts on behalf of the scientific community in Europe to promote creativity and innovative research. It is responsible for setting the ERC's scientific strategy, including establishing the annual Work Programmes, designing the peer review systems, identifying the peer review experts, and communicating with the scientific community. The first Scientific Council members were nominated by Commissioner Potočnik in July 2005 and worked intensively to define the key principles and scientific operating practices of the ERC in preparation for the start-up.\n\nThe members of the Scientific Council are selected by an Identification Committee, consisting of highly respected personalities in European research, and appointed by the European Commission. The ScC members term of office lasts four years.\n\nFollowing its formal establishment, the Scientific Council reaffirmed the election of its Chair and ERC president, Professor Fotis Kafatos, and the two Vice-Chairs and ERC Vice-Presidents, Professor Helga Nowotny and Dr. Daniel Estève. After the highly successful Presidency of Fotis Kafatos, Helga Nowotny took over as President in March 2010 with Prof. Carl-Henrik Heldin and Prof. Pavel Exner as Vice-Presidents. In January 2014, after the end of Helga Nowotny's term of office, Professor Jean-Pierre Bourguignon became ERC President. Since then, the ERC also has a third Vice-President, Professor Nuria Sebastian Galles, alongside the two vice-presidents already in office (each of them in charge of one of the ERC scientific domains).\n\nThe ERC Scientific Council has established two Standing Committees: one deals with conflict of interest issues, the other oversees the selection of reviewers and panel lists.\n\nThe Scientific Council is supported operationally by the European Research Council Executive Agency (ERCEA), based in Brussels. The implementing pillar of the ERC, the ERC Executive Agency (ERCEA), is responsible for supporting the peer review process, implementing the ERC strategy as set by the ScC, executing all financial operations and communicating about the ERC. The ERCEA is currently headed by the Director, Pablo Amor. It employs some 400 staff of which more than 50 hold PhDs.\n\nThe fact that most Scientific staff hold a PhD, have done post-docs and/or have been academics reinforces the feeling among panellists and the Scientific Community as a whole that ERC Schemes are implemented by scientists understanding the pitfalls and hurdles of Research and who are constantly working to better their procedures in order to simplify the application as well as the granting processes, hand in hand with their colleagues from financial units.\n\nThere is also a five-member ERCEA Steering Committee, chaired by the European Commission's Director-General for Research and Innovation, two ScC members, and two Commission officials.\n\nTo create an integrated institution consisting of the ScC and the ERCEA, two integrative mechanisms were initially put in place:\n\n\nUnder the EU's Framework Programme for Research and Innovation Horizon 2020 the ERC has a budget of €13.1 billion for the period 2014 - 2020. That is a substantial increase from its initial seven-year budget under the EU's seventh Research Framework Programme (2007-2013), when the total allocated to the ERC was €7.5 billion. The ERC budget is supported by the European Commission and is supplemented by contributions from the EU associated countries. Together, the 28 EU member states and the associated countries comprise the European Research Area (ERA).\n\nThe ERC's peer-review evaluation process must command the confidence of the research community and is central to the achievement of the ERC's objectives. The ERC Scientific Council divided the full range of scientific disciplines into three major domains, with budgets allotted as follows. The peer review in the three domains is carried out by a total of 25 panels led by Panel Chairs whose scientific status gives credibility to the selection process. The peer review experts come from all over the world, which makes the ERC peer review process one of the most international of its kind on this scale. There are currently about 900 ERC panel members; together with the 2000 external reviewers, they constitute the backbone of the ERC evaluation structure.\nThe ScC encourages interdisciplinary proposals.\n\nThe two founding principles of the ERC regarding grants are:\n\nThe ERC asks researchers to think big, and provides generous support for ambitious projects. It does not want its carefully selected grantees to waste their time by taking on numerous peripheral projects, or constantly having to seek additional money to fund their research. The grants are flexible, so that all costs for a specific project can be covered, and portable, meaning that if grant holders move to another university or institute, the grant moves with them.\n\nThe applicant can be of any nationality and age, and needs to demonstrate an excellent track record and present a ground-breaking research proposal. The research must be conducted in a Host Institution located within the European Union or an associated country.\n\nThe council offers the following grant schemes, with funding for up to five years:\nThe following charts present annual success rates.\n\nThe Scientific Council has adopted an ‘open access’ policy with regard to the access and availability of publications and research results. This requires all peer-reviewed publications from ERC-funded research projects to be deposited in the appropriate Internet-accessible libraries within six months of publication.\n\n\n\n"}
{"id": "9670", "url": "https://en.wikipedia.org/wiki?curid=9670", "title": "Evolutionism", "text": "Evolutionism\n\nEvolutionism describes the belief in the evolution of organisms. Its exact meaning has changed over time as the study of evolution has progressed. In the 19th-century, it was used to describe the belief that organisms deliberately improved themselves through progressive inherited change (orthogenesis). The teleological belief went on to include cultural evolution and social evolution. In the 1970s the term Neo-Evolutionism was used to describe the idea \"that human beings sought to preserve a familiar style of life unless change was forced on them by factors that were beyond their control\".\n\nThe term is also sometimes used by the creationist movement to describe adherence to the scientific consensus on evolution as equivalent to a secular religion. The term is very seldom used within the scientific community, since the scientific position on evolution is accepted by the overwhelming majority of scientists. Because evolutionary biology is the default scientific position, it is assumed that \"scientists\" or \"biologists\" are \"evolutionists\" unless specifically noted otherwise. In the creationevolution controversy, creationists often call those who accept the validity of the modern evolutionary synthesis \"evolutionists\" and the theory itself \"evolutionism\".\n\nBefore its use to describe biological evolution, the term \"evolution\" was originally used to refer to any orderly sequence of events with the outcome somehow contained at the start. The first five editions of Darwin's in \"Origin of Species\" used the word \"evolved\", but the word \"evolution\" was only used in its sixth edition in 1872. By then, Herbert Spencer had developed the concept theory that organisms strive to evolve due to an internal \"driving force\" (orthogenesis) in 1862. Edward B. Tylor and Lewis H Morgan brought the term \"evolution\" to anthropology though they tended toward the older pre-Spencerian definition helping to form the concept of unilineal (social) evolution used during the later part of what Trigger calls the Antiquarianism-Imperial Synthesis period (c1770-c1900). The term evolutionism subsequently came to be used for the now discredited theory that evolution contained a deliberate component, rather than the selection of beneficial traits from random variation by differential survival.\n\nIn modern times, the term \"evolution\" is widely used, but the terms \"evolutionism\" and \"evolutionist\" are seldom used in the scientific community to refer to evolutionary biology, since the term is considered both redundant and anachronistic. \n\nHowever, the term has been used by creationists in discussing the creation-evolution controversy. For example, the Institute for Creation Research, in order to imply placement of evolution in the category of 'religions', including atheism, fascism, humanism and occultism, commonly uses the words \"evolutionism\" and \"evolutionist\" to describe the consensus of mainstream science and the scientists subscribing to it, thus implying through language that the issue is a matter of religious belief. The BioLogos Foundation, an organization that promotes the idea of theistic evolution, uses the term \"evolutionism\" to describe \"the atheistic worldview that so often accompanies the acceptance of biological evolution in public discourse.\" It views this as a subset of scientism.\n\n\n"}
{"id": "45064406", "url": "https://en.wikipedia.org/wiki?curid=45064406", "title": "Expected satiety", "text": "Expected satiety\n\nThe term expected satiety refers to the satiety (relief from hunger) that is expected from a particular food. It is closely associated with 'expected satiation' which refers to the immediate fullness (post meal) that a food is expected to generate.\n\nScientists have discovered that foods differ considerably in their expected satiety. One estimate suggests that there may be a six-fold difference in commonly consumed foods (in the UK), when they are compared calorie for calorie. This range of variation is important because expected satiety is thought to be a good predictor of food choice and an excellent predictor of self-selected portion sizes. Specifically, foods that have high expected satiety and high expected satiation tend to be selected in smaller portions (fewer calories). Therefore, they may be especially suited to diets that are designed to reduce energy intake.\n\nSome researchers also suggest that expected satiety is an important mediator of energy intake. They argue that within-meal events (immediate post-ingestive feedback, e.g., gastric stretch) play a relatively minor role and that meal size is largely determined by decisions about portion size, before a meal begins. Consistent with this proposition, observational studies show that 'plate cleaning' is extremely common, that humans tend to plan their meal size in advance, and that \"ad libitum\" eating is relatively rare.\n\nEarly approaches relied on rating scales. More recently, techniques have been developed that quantify expectations very precisely by comparing foods directly on a calorie-for-calorie basis. The first of these used a classical psychophysical approach based on a 'method of constant stimuli'. Participants are shown a fixed 'standard' portion of food and this is compared against a different 'comparison' food. Over a series of trials the size of the comparison food is manipulated and participants are asked to pick the food that is expected to deliver greater satiety. At the end of the task a measure of 'expected satiety' is calculated. This relates to the number of calories of the comparison food that would be expected to deliver the same satiety as the fixed standard. A conceptually similar alternative is to use a 'method of adjustment'. Participants are shown a picture of a standard food next to a picture of a comparison food. Using specialist software, participants change the size of the comparison portion using keyboard responses. Pictures are loaded with sufficient speed that the change in the comparison becomes 'animated.' Participants are told to match the comparison food until both are expected to deliver the same satiety. If the same standard is used then the expected satiety of different foods can be quantified and compared directly.\n\nExpectations about the post-ingestive effects of a food are learned over time. In particular, it would appear that the expected satiety and expected satiation of foods increases as they become familiar.\n\nExpectations are also thought to be governed by the orosensory characteristics of food. Even subtle changes to the flavor or texture of food can have a marked effect. Expected satiation may be higher in foods that have a higher protein content, and in those that require more chewing and that are eaten slowly. Remarkably, it also appears that the expected satiety and expected satiation of foods is influenced by their perceived weight.\n\nThe effects of expected satiety and expected satiation appear to extend beyond meal planning. Several studies show that these expectations also influence the hunger and fullness that is experienced after a meal has been consumed. Product labelling and branding is likely to modify expected satiety. Therefore, this kind of information has the potential to influence appetite directly. Together, these observations are consistent with emerging evidence that implicates hippocampal-dependent memory mechanisms in behavioural responses to food.\n\nSometimes expected satiety is otherwise referred to as 'satiety expectations'.\n"}
{"id": "1022525", "url": "https://en.wikipedia.org/wiki?curid=1022525", "title": "Explorer 6", "text": "Explorer 6\n\nExplorer 6, or S-2, was an American satellite launched on August 7, 1959. It was a small, spheroidal satellite designed to study trapped radiation of various energies, galactic cosmic rays, geomagnetism, radio propagation in the upper atmosphere, and the flux of micrometeorites. It also tested a scanning device designed for photographing the Earth's cloud cover, and transmitted the first pictures of Earth from orbit.\n\nThe satellite was launched into a highly elliptical orbit with an initial local time of apogee of 2100 h. The satellite was spin-stabilized at 2.8 rps, with the direction of the spin axis having a right ascension of 217 degrees and a declination of 23 degrees. Four solar cell paddles mounted near its equator recharged the storage batteries while in orbit. Each experiment except the television scanner had two outputs, digital and analog. A UHF transmitter was used for the digital telemetry and the TV signal. Two VHF transmitters were used to transmit the analog signal. The VHF transmitters were operated continuously. The UHF transmitter was operated for only a few hours each day. Only three of the solar cell paddles fully erected, and this occurred during spin up rather than prior to spin up as planned. Consequently, initial operation of the payload power supply was 63% nominal, and this decreased with time. The decreased power caused a lower signal-to-noise ratio affecting most of the data, especially near apogee. One VHF transmitter failed on September 11, 1959, and the last contact with the payload was made on October 6, 1959, at which time the solar cell charging current had fallen below that required to maintain the satellite equipment.\n\nIn 1959 an anti-satellite missile test of the Bold Orion rocket used Explorer 6 as a target. The missile successfully passed within of the satellite.\n\nBold Orion’s ASAT mission occurred on Tuesday, 13 October 1959. Launch took place within the Atlantic Missile Range Drop Zone (AMR DZ). The altitude, latitude and longitude of the drop point were , 29° North and 79° West, respectively. Bold Orion successfully intercepted the Explorer 6 satellite, passing its target at a range of less than and an altitude of .\n\nThe satellite's orbit decayed on July 1, 1961.\nA total of 827 hours of analog and 23 hours of digital data were obtained.\n\n\n"}
{"id": "33255301", "url": "https://en.wikipedia.org/wiki?curid=33255301", "title": "Fast Infrared Exoplanet Spectroscopy Survey Explorer", "text": "Fast Infrared Exoplanet Spectroscopy Survey Explorer\n\nFast Infrared Exoplanet Spectroscopy Survey Explorer (FINESSE) is a NASA mission proposal for a space observatory operating in the Near-infrared spectrum for the Medium-Class Explorers program. The Principal Investigator is Mark Swain of the Jet Propulsion Laboratory in Pasadena, California.\n\nFINESSE was one of three Medium-Class Explorers (MIDEX) mission concepts that received $2 million to conduct a nine-month mission concept study in August 2017. The other two competing concepts are Arcus (an X-ray space observatory) and SPHEREx (a near-infrared space observatory). If selected, the mission would launch no earlier than 2022 and would last at least two years.\n\nFINESSE would consist of a space observatory tasked to study exoplanet atmospheres by spectroscopically surveying over 500 planets outside the Solar System with the goal of gaining understanding of the processes responsible for their composition, and how the Solar System fits into the larger family of planets.\n\nFINESSE is a candidate for NASA's next Explorers program MIDEX mission, and is currently in a nine-months-long Phase A study starting from August 2017 to refine its mission concept. NASA is expected to announce the selection result of the next MIDEX mission in 2019.\n\nWhile FINESSE was selected as finalist for the MIDEX mission, NASA also conditionally selected the CASE proposal as an Explorers Program Partner Mission of Opportunity (PMO). FINESSE and CASE shares the same Primary Investigator and science team. CASE, or Contribution To ARIEL Spectroscopy of Exoplanets, is a proposal for US participation in the European ARIEL space telescope. An exoplanet atmosphere survey mission, ARIEL is similar to FINESSE both in spacecraft capability and scientific objectives. CASE was selected on the condition that it will only be constructed if the European Space Agency selects ARIEL. At the time this was announced, it was still uncertain whether ARIEL will be ultimately selected or not. NASA has stated that if ARIEL and CASE are selected, they will not select FINESSE as the next MIDEX mission. On March 2018, ARIEL was selected by ESA for the fourth Cosmic Vision Medium class mission (M4).\n\n\nFINESSE would measure the atmospheric light spectra of exoplanets transiting or eclipsing their parent star. The proposed spectrometer functions on the 0.5-5.0 μm range, on the far infrared wavelegths of λ/Δλ = 80 at 1.2μm, 300 at 3 μm, and it would use a 75 cm diameter primary mirror.\n\n"}
{"id": "30784948", "url": "https://en.wikipedia.org/wiki?curid=30784948", "title": "Feedforward, Behavioral and Cognitive Science", "text": "Feedforward, Behavioral and Cognitive Science\n\nFeedforward, Behavior and Cognitive Science is a method of teaching and learning that illustrates or indicates a desired future behavior or path to a goal. Feedforward provides information, images, etc. exclusively about what one could do right in the future, often in contrast to what one has done in the past. The feedforward method of teaching and learning is in contrast to its opposite, feedback, concerning human behavior because it focuses on learning in the future, whereas feedback uses information from a past event to provide reflection and the basis for behaving and thinking differently. In isolation, feedback is the least effective form of instruction, according to US Department of Defense studies in the 1980s. Feedforward was coined in 1976 by Peter W. Dowrick in his dissertation.\n\nFeedforward in behavioral and cognitive science may be defined as \"images of adaptive future behavior, hitherto not mastered\"; images capable of triggering that behavior in a challenging context. Feedforward is created by restructuring current component behaviors into what appears to be a new skill or level of performance.\n\nOne concept of feedforward originated in behavioral science. Related concepts have emerged in biology, cybernetics, and management sciences. The understanding of feedforward help the understanding of brain function and rapid learning. The concept contributed to research and development of video self modeling (VSM). The most productive advances in feedforward came from its association with videos that showed adaptive behavior (see Dowrick, 1983, pp. 111, 121; 1991, pp. 110–3, 120-2, 240-1; 1999, esp. pp. 25–26). For example, a boy with autism role-plays squeezing a ball (stress management technique) instead of having a tantrum when his work is found imperfect by the teacher – or a selectively mute child is seen on video talking at school, by editing in footage of her talking at home (location disguised by use of a classroom backdrop). By selectively editing a video, a clip was made that demonstrated the desired behavior and allowed the children to learn from their future successes.\n\nBy reference to its historical context of VSM, it became recognized that feedforward comprised component behaviors already in the repertoire, and that it could exist in forms other than videos. In fact, feedforward exists as images in the brain, and VSM is just one of many ways to create these simulations. The videos are very short – the best are 1 or 2 minutes long, and achieve changes in behavior very rapidly. Under the right conditions, a very few viewings of these videos can produce skill acquisitions or changes in performance that typically take months and have been resistant to change by other methods. The boy with autism and the girl with selective mutism, mentioned above, are good examples. Further examples can be found in journal articles, and on the web (e.g., in sport).\n\nThe evidence for ultra-rapid learning, built from component behaviors that are reconfigured to appear as new skills, indicates the feedforward self model mechanism existing in the brain to control our future behavior. That is, if the conditions of learning are right, the brain takes pieces of existing skills, puts them together in new ways or in a different context, to produce a future image and a future response. Thus we learn from the future – more rapidly than we learn from the past. Further evidence comes from cognitive processes dubbed \"mental time travel\" and for parts of the hippocampus etc. where they occur. However, the links between these hot spots in the brain and feedforward learning have yet to be confirmed.\n\nFeedforward concepts have become established in at least four areas of science, and they continue to spread. Feedforward often works in concert with feedback loops for guidance systems in cybernetics or self-control in biology .\n\nFeedforward in management theory enables the prediction and control of organizational behavior. These concepts have developed during and since the 1990s.\n"}
{"id": "25666690", "url": "https://en.wikipedia.org/wiki?curid=25666690", "title": "Fried Egg structure", "text": "Fried Egg structure\n\nThe Fried Egg is an informal name for an underwater geomorphic structure in the North Atlantic that is a suspected impact crater. This structure is at a depth of and is about south of the Azores archipelago. It consists of a dome high and in diameter that lies within a larger and roughly circular depression deep and in diameter. It is this morphology on which its informal name is based. Images that accompany media reports show the presence of a well-defined rim that surrounds the depression. These images also show a second but smaller circular depression, which also has a central peak, lying adjacent to the Fried Egg structure.\n\nThis structure is less than 17 million years old as constrained by the age of the ocean floor of which it is a part. Based on its morphology and the absence of any obvious lava flows that can be seen in the multibeam echosounder bathymetric data, it is hypothesized that this structure is a possible oceanic impact crater.\n\nIt was reported that the Fried Egg structure was first identified using data acquired during a 2008 multibeam echosounder hydrographic survey. Its presence was confirmed during a research cruise from September to November 2009. In addition, gravity and magnetic data were also acquired during the September 2009 research cruise and that a third expedition using remotely operated underwater vehicles to gather samples from this structure was planned.\n\n"}
{"id": "1841012", "url": "https://en.wikipedia.org/wiki?curid=1841012", "title": "Gamma counter", "text": "Gamma counter\n\nA gamma counter is a machine to measure gamma radiation emitted by a radionuclide. Unlike survey meters, gamma counters are designed to measure small samples of radioactive material, typically with automated measurement and movement of multiple samples.\n\nGamma counters are usually scintillation counters. In a typical system, a number of samples are placed in sealed vials or test tubes, and moved along a track. One at a time, they move down inside a shielded detector, set to measure specific energy windows characteristic of the particular isotope. Within this shielded detector there is a scintillation crystal that surrounds the radioactive sample. Gamma rays emitted from the radioactive sample interact with the crystal, are absorbed, and light is emitted. A detector, such as a photomultiplier tube converts the visible light to an electrical signal. Depending on the half-life and concentration of the sample, measurement times may vary from 0.02 minutes to several hours.\n\nIf the photon has too low of an energy level it will be absorbed into the scintillation crystal and never be detected. If the photon has too high of an energy level the photons may just pass right through the crystal without any interaction. Thus the thickness of the crystal is very important when sampling radioactive materials using the Gamma Counter.\n\nGamma counters are standard tools used in the research and development of new radioactive compounds used for diagnosing and treating disease, (as in PET scanning). Gamma counters are used in radiobinding assays, radioimmunoassays (RIA) and Nuclear Medicine measurements such as GFR and hematocrit.\n\nSome gamma counters can be used for gamma spectroscopy to identify radioactive materials based on their output energy spectrum, e.g. as a wipe test counter.\n"}
{"id": "38642855", "url": "https://en.wikipedia.org/wiki?curid=38642855", "title": "Gladys Lounsbury Hobby", "text": "Gladys Lounsbury Hobby\n\nGladys Lounsbury Hobby (November 19, 1910 – July 4, 1993), born in New York City, was an American microbiologist whose research played a key role in the development and understanding of antibiotics. Her work took penicillin from a laboratory experiment to a mass-produced drug during World War II.\n\nHobby was born in the Washington Heights neighbourhood in New York City, one of two daughters of Theodore Y. Hobby and Flora R. Lounsbury. Hobby graduated from Vassar College in 1931. She earned her and Ph.D. in bacteriology from Columbia University in 1935. She wrote her doctoral thesis on the medical uses of nonpathogenic organisms.\n\nHobby worked for Presbyterian Hospital and the Columbia Medical School from 1934 to 1943, during which time she collaborated with Dr. Karl Meyer, a biochemist, and Dr. Martin Henry Dawson, a clinician and associate professor of medicine, on determining diseases caused by hemolytic streptococci and later on refining penicillin. During this time, Hobby also worked for Prespyterian Hospital in New York City. Hobby left Columbia University in 1944 to work for Pfizer Pharmaceuticals in New York where she researched streptomycin and other antibiotics.\n\nIn 1959, Hobby left Pfizer to specialize in chronic infectious diseases as chief of research at the Veterans Administration Hospital in East Orange, New Jersey. She also served as an assistant clinical research professor in public health at Cornell University Medical College. In 1972 she founded the monthly publication, \"Antimicrobial Agents and Chemotherapy\", and continued to edit it for eight years. She retired from her main career in 1977. In retirement Hobby wrote over 200 articles, working as a consultant and freelance science writer. She also published a book, \"Penicillin: Meeting the Challenge\", in 1985, in which she chronicled penicillin's journey and compared it to the Manhattan project in its importance to the war effort.\n\nHobby died of a heart attack in 1993 at her home in a Pennsylvania retirement community.\n\nHobby is recognized for her work in creating a form of penicillin that was effective on human hosts. In 1940, Hobby and her colleagues, Dr. Karl Meyer and Dr. Martin Henry Dawson, wrote to Howard Florey and Ernst Chain to procure a sample of penicillin. They naively decided to make some penicillin and soon became experts in the fermentation process, and began refining it into a drug. Hobby, Meyer, and Dawson performed the first tests of penicillin on humans in 1940 and 1941, before presenting at the American Society for Clinical Investigation. They discovered that penicillin was a powerful germ-killer that reduced the severity of infectious diseases and made procedures such as organ transplantation and open-heart surgery possible. Their findings received media coverage, which helped attract funding from the United States Government to mass-produce penicillin during World War II, saving the lives of many soldiers.\n\nAt Pfizer, Hobby did extensive early work on Terramycin and Viomycin, used for the treatment of tuberculosis.\n\n"}
{"id": "17943278", "url": "https://en.wikipedia.org/wiki?curid=17943278", "title": "Glossary of experimental design", "text": "Glossary of experimental design\n\nThe following is a glossary of terms. It is not intended to be all-inclusive.\n\n\n\n"}
{"id": "35993661", "url": "https://en.wikipedia.org/wiki?curid=35993661", "title": "Glossary of scientific naming", "text": "Glossary of scientific naming\n\nThis is a list of terms and symbols used in scientific names for organisms, and in describing the names. For proper parts of the names themselves, see glossary of scientific names. Note that many of the abbreviations are used with or without a stop.\n\n\n\n\nThe main ranks are kingdom (\"regnum\"), phylum or division (\"divisio\"), class (\"classis\"), order (\"ordo\"), family (\"familia\"), genus and species. The ranks of section and series are also used in botany for groups within genera, while section is used in zoology for a division of an order. Further levels in the hierarchy can be made by the addition of prefixes such as sub-, super-, infra-, and so on.\n\nDivisions such as \"form\", \"variety\", \"strain\", \"breed\", \"cultivar\", hybrid (nothospecies) and \"landrace\" are used to describe various sub-specific groups in different fields.\n\nIt is possible for a clade to be unranked, for example Psoroptidia (Yunker, 1955) and the SAR supergroup.\n\nNote that in zoology the English descriptions, such as \"conserved name\", for example, are acceptable and generally used. This descriptions can be classified between accepted names (\"nom. cons., nom. nov., nom. prot.\") and unaccepted combinations for different reasons (\"nom. err., nom. illeg., nom. nud., nom. rej., nom. supp., nom. van.\"), with some cases in between regarding the use (\"nom. dub.\": used but not fully accepted; \"nom. obl.\": accepted but not fully used, so it yields precedence to a \"nom. prot\").\n\n\n\n\n"}
{"id": "24370169", "url": "https://en.wikipedia.org/wiki?curid=24370169", "title": "Guyland", "text": "Guyland\n\nGuyland: The Perilous World Where Boys Become Men () is a book by Michael Kimmel, published in 2008. The book covers the culture for young men transitioning from adolescence to adulthood.\n\nKimmel interviewed 400 men aged 16 to 26 and identified a trend whereby young men increasingly delay adulthood. Kimmel notes that, in 1960, almost 70% of American men had by the age of 30 left home, completed their educations, found a partner and started work. By comparison, today less than a third of men reach these milestones before their thirties. Kimmel writes that young men are reluctant to grow up because they \"see grown-up life as such a loss\". In order to avoid the responsibilities of adulthood, young men retreat into a homosocial world Kimmel terms \"Guyland\", a social space and a stage of life where \"guys gather to be guys with each other, unhassled by the demands of parents, girlfriends, jobs, kids, and the other nuisances of adult life\". Young white men, in particular, feel a sense of \"thwarted entitlement\", believing that women and minorities have taken away traditionally white male jobs and positions.\n\n"}
{"id": "17784468", "url": "https://en.wikipedia.org/wiki?curid=17784468", "title": "Halogen Foundation", "text": "Halogen Foundation\n\nHalogen Foundation (Singapore) is an Institute of Public Character and not-for-profit organization in Singapore whose mission is to inspire and influence a generation of young people to lead themselves and others well.\n\nHalogen Foundation was started in 1997 in Australia originally called the Young Leaders Foundation. Its hallmark program is the National Young Leaders Days, an annual event initiated in 1997 to develop student leadership in schools. The Foundation exists in five major cities in Australia - Sydney, Melbourne, Brisbane, Adelaide, and Perth. It can also be found in New Zealand, incorporated under the Charitable Trusts Act 1957] and covering Auckland, Wellington, Christchurch, and Dunedin. It also has operations in Singapore where it is considered an Institute of Public Character.\n\nNational Young Leaders Day consists of a range of presenters, who aim to motivate young leaders in taking action in their schools and passing on the lessons they have learned on the day. \n\nHalogen Foundation is endorsed by national leaders of the respective countries. Mr John Howard (Prime Minister of Australia), Mrs Helen Clark (Prime Minister of New Zealand), and Mr Teo Chee Hean (Minister of Defense of Singapore).\n\n• Halogen Foundation (Singapore)\n• Halogen Foundation International\n"}
{"id": "11167164", "url": "https://en.wikipedia.org/wiki?curid=11167164", "title": "Integrated Biosphere Simulator", "text": "Integrated Biosphere Simulator\n\nIBIS-2 is the version 2 of the land-surface model Integrated Biosphere Simulator (IBIS), which includes several major improvements and additions to the prototype model developed by Foley et al. [1996]. IBIS was designed to explicitly link land surface and hydrological processes, terrestrial biogeochemical cycles, and vegetation dynamics within a single physically consistent framework \n\nThe model considers transient changes in vegetation composition and structure in response to environmental change and is, therefore, classified as a Dynamic Global Vegetation Model (DGVM) This new version of IBIS has improved representations of land surface physics, plant physiology, canopy phenology, plant functional type (PFT) differences, and carbon allocation. Furthermore, IBIS-2 includes a new belowground biogeochemistry submodel, which is coupled to detritus production (litterfall and fine root turnover). All process are organized in a hierarchical framework and operate at different time steps, ranging from 60 min to 1 year. Such an approach allows for explicit coupling among ecological, biophysical, and physiological processes occurring on different timescales.\n\nThe land surface module is based on the land surface transfer model (LSX) package of Thompson and Pollard, and simulates the energy, water, carbon, and momentum balance of the soil-vegetation-atmosphere system. The model represents two vegetation canopies (e.g., trees versus shrubs and grasses), eight soil layers, and three layers of snow (when required). The solar radiative transfer scheme of IBIS-2 has been simplified in comparison with LSX and IBIS-1; sunlit and shaded fractions of the canopies are no longer treated separately. The model now follows the approach of Sellers et al. [1986] and Bonan [1995]. Infrared radiation is simulated as if each vegetation layer is a semitransparent plane; canopy emissivity depends on foliage density. Another difference between IBIS-2 and IBIS-1 and LSX, is that IBIS-2 uses an empirical linear function of wind speed to estimate turbulent transfer between the soil surface and the lower vegetation canopy, and IBIS-1 and LSX use a logarithmic wind profile. The total evapotranspiration from the land surface is treated as the sum of three water vapor fluxes: evaporation from the soil surface, evaporation of water intercepted by vegetation canopies, and canopy transpiration.\n\nIBIS simulates the variations of heat and moisture in the soil. The eight layers are described in terms of soil temperature, volumetric water content and ice content. All the process occurring in the soil are influenced by the soil texture and amount of organic matter within the soil. One difference from the physiological processes in previous version of the model is that IBIS-1 calculates the maximum Rubisco carboxylation capacity (Vm) by optimizing the net assimilation of carbon by the leaf. IBIS-2 prescribes constant values of Vm for the plant functional typed (PFT). To scale photosynthesis and transpiration from the leaf level to canopy level, IBIS-2 assumes that the net photosynthesis within the canopy is proportional to the APAR within it.\n\nIn the original version of IBIS there was no explicit below ground biogeochemistry model to complete flow of carbon between the vegetation, detritus, and soil organic matter pools. IBIS-2 includes a new soil biogeochemistry module.\n\n"}
{"id": "4919310", "url": "https://en.wikipedia.org/wiki?curid=4919310", "title": "Interpretation of Schizophrenia", "text": "Interpretation of Schizophrenia\n\nInterpretation of Schizophrenia (first edition, 1955) is a book by Italy-born American psychiatrist Silvano Arieti in which the author sets forth demonstrative evidence of a psychological etiology for schizophrenia.\n\nArieti expanded the book vastly in 1974 () and that edition won the U.S. National Book Award in the Science category.\n\n\"Interpretation of schizophrenia\" is a 756-page book divided in 45 chapters. Arieti begins his book stating that it is difficult to define schizophrenia. He asks if schizophrenia is an illness and answers in the negative, since the disorder is not understood in classic Virchowian criterion of cellular pathology. Though those searching for a biological basis of schizophrenia far outnumber those undertaking psychological approaches, Arieti supports the minority view. He believes schizophrenia is an unrealistic way to represent both the self and the world and praises psychiatrist Adolf Meyer for stressing the importance of psychological factors in the etiology of schizophrenia. Arieti also mentions that Freud felt that in schizophrenia the patient's relationship with people is handicapped (an observation that resembles what presently is called \"autism\").\n\nArieti then describes the psychogenic factors that lead to the disorder. The family environment and psychodynamics in the etiology of psychosis comes under scrutiny. Arieti describes the building of neurotic and psychotic defense mechanisms; the emerging schizoid personality, and fully developed schizophrenia understood as an injury to the inner self. Arieti believes that a state of extreme anxiety originating in early childhood produces vulnerability for the whole life of the individual.\n\nA characteristic of \"Homo sapiens\" is a prolonged childhood with a consequently extended dependency on adults. This, according to Arieti, \"is the basis of the psychodynamics of schizophrenia\", a claim that also appears in later writers on child abuse such as Alice Miller and Colin Ross. Arieti reviews the paper by Frieda Fromm-Reichmann about the \"schizophrenogenic\" mother and reaches the tentative conclusion that only 25 percent of the mothers of people with schizophrenia in his clinical experience fit that image. However, he adds that only in a minority of schizophrenia cases \"the child is able to retain the good maternal image\". Arieti also mentions the work of Theodore Lidz, another trauma model author of schizophrenia. Like Lidz, Arieti emphasizes the weakness of the father of the patient with schizophrenia in the paternal role. In Arieti's own words:\n\nThe roles can be reversed when the domineering spouse is the father. Arieti is convinced that each schizophrenia case is representative of those human situations in which something went extremely wrong. \"If we ignore it, we become deaf to a profound message that the patient may try to convey\". For example, Arieti states about one of his patients that \"his adolescence was a crescendo of frustration, anxiety and injury to self-esteem\". Arieti also mentions a catatonic patient who, after introjecting the mother's engulfing behavior, believed that by moving he could produce havoc. The patient's feelings, according to Arieti, became reminiscent of cosmic powers that may cause the destruction of the universe, so the patient chose immobility. For Arieti, the selectivity of certain motor actions is proof that catatonia is not a biological disease or illness, but rather a disorder of the will.\n\nIn Part three of \"Interpretation of schizophrenia\" Arieti describes how in spite of its efforts to stay in reality, the patient's defenses finally succumb. When the patient \"cannot change the unbearable situation of himself any longer, he has to change reality\". Arieti examines the inner world of the person with schizophrenia.\n\nWhen a patient states he is Jesus he is compensating a feeling of extreme humiliation at home. The paranoid schizophrenic, Arieti explains, resorts to \"teleologic causality\" or animism to understand the world. He writes that whatever occurs to the patient is interpreted as willed by the parental alters of the patient. In deterministic or teleologic causality, if Nature's happenings were not willed they simply would not occur. In paranoid projection the schizophrenic takes out from him/herself a disagreeable part of the self onto the world. In \"Interpretation of schizophrenia\" Arieti illustrates all of the above theoretical constructions with concrete cases of his clinical experience as a psychiatrist.\n\nArieti maintains that in every case of schizophrenia that he studied serious family disturbance was found. When the patient idealizes the parent the idealized image of the parent is maintained in the patient's mind at the expense of an unbearable self-image. He speculates that psychosis starts only when the malevolent image of the parent is transformed \"into a distressing other\". The parent or parents alters enter the mind accusing the patient of \"bad child\" or other equivalent accusations in voices that the adult patient hears.\n\nSince the 1980s, and into the beginnings of 21st century, biological psychiatric models of schizophrenia almost completely took over the psychiatric profession. Current research into the disorder focuses on neurobiology. Psychological approaches to schizophrenia like Arieti's are a rarity in the profession, although this structurally created circumstance neglects the obvious connection between psychological phenomena and neurotransmitter levels, which can be changed through certain practices, like Yoga, meditation, hyperventilation, sensory deprivation, sleep deprivation, among others.\n\n\n"}
{"id": "288557", "url": "https://en.wikipedia.org/wiki?curid=288557", "title": "Javan rhinoceros", "text": "Javan rhinoceros\n\nThe Javan rhinoceros (\"Rhinoceros sondaicus\"), also known as the Sunda rhinoceros or lesser one-horned rhinoceros, is a very rare member of the family Rhinocerotidae and one of five extant rhinoceroses. It belongs to the same genus as the Indian rhinoceros, and has similar mosaic, armour-like skin, but at in length and in height, it is smaller (closer in size to the black rhinoceros of the genus \"Diceros\"). Its horn is usually shorter than , and is smaller than those of the other rhino species. Only adult males have horns; females lack them altogether.\n\nOnce the most widespread of Asian rhinoceroses, the Javan rhinoceros ranged from the islands of Java and Sumatra, throughout Southeast Asia, and into India and China. The species is critically endangered, with only one known population in the wild, and no individuals in captivity. It is possibly the rarest large mammal on Earth, with a population of as few as 58 to 61 in Ujung Kulon National Park at the western tip of Java in Indonesia. A second population in Cat Tien National Park in Vietnam was declared by some conservation groups to be extinct in 2011. The decline of the Javan rhinoceros is attributed to poaching, primarily for their horns, which are highly valued in traditional Chinese medicine, fetching as much as US$30,000 per kg on the black market. As European presence in their range increased, trophy hunting also became a serious threat. Loss of habitat, especially as the result of wars, such as the Vietnam War, in Southeast Asia, has also contributed to the species' decline and hindered recovery. The remaining range is within one nationally protected area, but the rhinos are still at risk from poachers, disease, and loss of genetic diversity leading to inbreeding depression.\n\nThe Javan rhino can live around 30–45 years in the wild. It historically inhabited lowland rain forest, wet grasslands, and large floodplains. It is mostly solitary, except for courtship and offspring-rearing, though groups may occasionally congregate near wallows and salt licks. Aside from humans, adults have no predators in their range. The Javan rhino usually avoids humans. Scientists and conservationists rarely study the animals directly due to their extreme rarity and the danger of interfering with such an endangered species. Researchers rely on camera traps and fecal samples to gauge health and behavior. Consequently, the Javan rhino is the least studied of all rhino species. Two adult rhinos with their calves were filmed in a motion-triggered video released on February 28, 2011, by WWF and Indonesia's National Park Authority, which proved it is still breeding in the wild. In April 2012, the National Parks Authority released video showing 35 individual Javan rhinos, including mother/offspring pairs and courting adults. There are a 58 to 68 individuals left in the wild, and none in captivity, after the death of a male rhinoceros named Samson. Samson died in April 2018 at 30 years of age, far younger than the species' usual lifespan of 50 to 60 years, so DNA test is being conducted to explore the cause of death, including the possibility of inbreeding degeneration.\n\nThe first studies of the Javan rhinoceros by naturalists from outside of its region took place in 1787, when two animals were shot in Java. The skulls were sent to the renowned Dutch naturalist Petrus Camper, who died in 1789 before he was able to publish his discovery that the rhinos of Java were a distinct species. Another Javan rhinoceros was shot on the island of Sumatra by Alfred Duvaucel, who sent the specimen to his stepfather Georges Cuvier, the famous French scientist. Cuvier recognized the animal as a distinct species in 1822, and in the same year it was identified by Anselme Gaëtan Desmarest as \"Rhinoceros sondaicus\". It was the last species of rhinoceros to be identified. Desmarest initially identified the rhino as being from Sumatra, but later amended this to say his specimen was from Java.\n\nThe genus name \"Rhinoceros\", which also includes the Indian rhinoceros, is derived from the ancient Greek words ῥίς (\"rhis\"), which means \"nose\", and κέρας (\"ceras\"), which means \"horn\"; \"sondaicus\" is derived from \"sunda\", the biogeographical region that comprises the islands of Sumatra, Java, Borneo, and surrounding smaller islands. The Javan rhino is also known as the lesser one-horned rhinoceros (in contrast with the greater one-horned rhinoceros, another name for the Indian rhino).\n\nOf the three distinct subspecies, only one still is known to exist:\n\n\nAncestral rhinoceroses are held to have first diverged from other perissodactyls in the Early Eocene. Mitochondrial DNA comparison suggests the ancestors of modern rhinos split from the ancestors of Equidae around 50 million years ago. The extant family, the Rhinocerotidae, first appeared in the Late Eocene in Eurasia, and the ancestors of the extant rhino species dispersed from Asia beginning in the Miocene.\n\nThe Indian and Javan rhinoceros, the only members of the genus \"Rhinoceros\", first appear in the fossil record in Asia around 1.6 million–3.3 million years ago. Molecular estimates, however, suggest the two species diverged from each other much earlier, around 11.7 million years ago. Although belonging to the type genus, the Indian and Javan rhinoceroses are not believed to be closely related to other rhino species. Different studies have hypothesized that they may be closely related to the extinct \"Gaindatherium\" or \"Punjabitherium\". A detailed cladistic analysis of the Rhinocerotidae placed \"Rhinoceros\" and the extinct \"Punjabitherium\" in a clade with \"Dicerorhinus\", the Sumatran rhino. Other studies have suggested the Sumatran rhinoceros is more closely related to the two African species. The Sumatran rhino may have diverged from the other Asian rhinos 15 million years ago, or as far back as 25.9 million years ago based on mitochondrial data.\n\nThe Javan rhino is smaller than the Indian rhinoceros, and is close in size to the black rhinoceros. It is the largest animal in Java and the second-largest animal in Indonesia after the Asian elephant. The length of the Javan rhino including its head is 2 to 4 metres (6.5 to 13 feet), and it can reach a height of . Adults are variously reported to weigh between , although a study to collect accurate measurements of the animals has never been conducted and is not a priority because of their extreme conservation status. No substantial size difference is seen between genders, but females may be slightly bigger. The rhinos in Vietnam appeared to be significantly smaller than those in Java, based on studies of photographic evidence and measurements of their footprints.\n\nLike the Indian rhino, the Javan rhinoceros has a single horn (the other extant species have two horns). Its horn is the smallest of all extant rhinos, usually less than with the longest recorded only . Only males have horns. Female Javan rhinos are the only extant rhinos that remain hornless into adulthood, though they may develop a tiny bump of an inch or two in height. The Javan rhinoceros does not appear to often use its horn for fighting, but instead uses it to scrape mud away in wallows, to pull down plants for eating, and to open paths through thick vegetation. Similar to the other browsing species of rhino (Black, Sumatran, and Indian), the Javan rhino has a long, pointed, upper lip which helps in grabbing food. Its lower incisors are long and sharp; when the Javan rhino fights, it uses these teeth. Behind the incisors, two rows of six low-crowned molars are used for chewing coarse plants. Like all rhinos, the Javan rhino smells and hears well, but has very poor vision. They are estimated to live for 30 to 45 years.\n\nIts hairless, splotchy gray or gray-brown skin falls in folds to the shoulder, back and rump. The skin has a natural mosaic pattern, which lends the rhino an armored appearance. The neck folds of the Javan rhinoceros are smaller than those of the Indian rhinoceros, but still form a saddle shape over the shoulder. Because of the risks of interfering with such an endangered species, however, the Javan rhinoceros is primarily studied through fecal sampling and camera traps. They are rarely encountered, observed or measured directly.\n\nEven the most optimistic estimate suggests fewer than 100 Javan rhinos remain in the wild. They are considered one of the most endangered species in the world. The Javan rhinoceros is known to survive in only one place, the Ujung Kulon National Park on the western tip of Java.\n\nThe animal was once widespread from Assam and Bengal (where their range would have overlapped with both the Sumatran and Indian rhinos) eastward to Myanmar, Thailand, Cambodia, Laos, Vietnam, and southwards to the Malay Peninsula and the islands of Sumatra, Java, and possibly Borneo. The Javan rhino primarily inhabits dense, lowland rain forests, grasslands, and reed beds with abundant rivers, large floodplains, or wet areas with many mud wallows. Although it historically preferred low-lying areas, the subspecies in Vietnam was pushed onto much higher ground (up to 2,000 m or 6,561 ft), probably because of human encroachment and poaching.\n\nThe range of the Javan rhinoceros has been shrinking for at least 3,000 years. Starting around 1000 BC, the northern range of the rhinoceros extended into China, but began moving southward at roughly per year, as human settlements increased in the region. It likely became locally extinct in India in the first decade of the 20th century. The Javan rhino was hunted to extinction on the Malay Peninsula by 1932. The last ones on Sumatra died out during World War II. They were extinct from Chittagong and the Sunderbans by the middle of the 20th century. By the end of the Vietnam War, the Vietnamese rhinoceros was believed extinct across all of mainland Asia. Local hunters and woodcutters in Cambodia claim to have seen Javan rhinos in the Cardamom Mountains, but surveys of the area have failed to find any evidence of them. In the late 1980s, a small population was found in the Cat Tien area of Vietnam. However, the last individual of that population was shot in 2010. A population may have existed on the island of Borneo, as well, though these specimens could have been the Sumatran rhinoceros, a small population of which still lives there.\n\nThe Javan rhinoceros is a solitary animal with the exception of breeding pairs and mothers with calves. They sometimes congregate in small groups at salt licks and mud wallows. Wallowing in mud is a common behavior for all rhinos; the activity allows them to maintain cool body temperatures and helps prevent disease and parasite infestation. The Javan rhinoceros does not generally dig its own mud wallows, preferring to use other animals' wallows or naturally occurring pits, which it will use its horn to enlarge. Salt licks are also very important because of the essential nutrients the rhino receives from the salt. Male home ranges are larger at ²) compared to the female, which are around ²). Male territories overlap each other less than those of the female. It is not known if there are territorial fights.\n\nMales mark their territories with dung piles and by urine spraying. Scrapes made by the feet in the ground and twisted saplings also seem to be used for communication. Members of other rhino species have a peculiar habit of defecating in massive rhino dung piles and then scraping their back feet in the dung. The Sumatran and Javan rhinos, while defecating in piles, do not engage in the scraping. This adaptation in behavior is thought to be ecological; in the wet forests of Java and Sumatra, the method may not be useful for spreading odors.\nThe Javan rhino is much less vocal than the Sumatran; very few Javan rhino vocalizations have ever been recorded. Adults have no known predators other than humans. The species, particularly in Vietnam, is skittish and retreats into dense forests whenever humans are near. Though a valuable trait from a survival standpoint, it has made the rhinos difficult to study. Nevertheless, when humans approach too closely, the Javan rhino becomes aggressive and will attack, stabbing with the incisors of its lower jaw while thrusting upward with its head. Its comparatively antisocial behavior may be a recent adaptation to population stresses; historical evidence suggests they, like other rhinos, were once more gregarious.\n\nThe Javan rhinoceros is herbivorous, eating diverse plant species, especially their shoots, twigs, young foliage and fallen fruit. Most of the plants favored by the species grow in sunny areas in forest clearings, shrubland and other vegetation types with no large trees. The rhino knocks down saplings to reach its food and grabs it with its prehensile upper lip. It is the most adaptable feeder of all the rhino species. Currently, it is a pure browser, but probably once both browsed and grazed in its historical range. The rhino eats an estimated of food daily. Like the Sumatran rhino, it needs salt in its diet. The salt licks common in its historical range do not exist in Ujung Kulon but the rhinos there have been observed drinking seawater, likely for the same nutritional need. \n\nThe main factor in the continued decline of the Javan rhinoceros population has been poaching for horns, a problem that affects all rhino species. The horns have been a traded commodity for more than 2,000 years in China, where they are believed to have healing properties. Historically, the rhinoceros' hide was used to make armor for Chinese soldiers, and some local tribes in Vietnam believed the hide could be used to make an antidote for snake venom. Because the rhinoceros' range encompasses many areas of poverty, it has been difficult to convince local people not to kill a seemingly (otherwise) useless animal which could be sold for a large sum of money. When the Convention on International Trade in Endangered Species of Wild Fauna and Flora first went into effect in 1975, the Javan rhinoceros was placed under complete Appendix 1 protection; all international trade in the Javan rhinoceros and products derived from it is illegal. Surveys of the rhinoceros horn black market have determined that Asian rhinoceros horn fetches a price as high as $30,000 per kg, three times the value of African rhinoceros horn.\n\nAs with many types Asian and African megafauna, the Javan rhino was relentlessly hunted by trophy and big-game hunters for decades following the arrival of Europeans in its range. The rhinos being easy targets, this was as severe a contributor to its decline as was poaching for its horns. Such was the toll of big-game hunting that by the time the rhino's plight was made known to the world, only the Javan and the (then unknown) Vietnamese populations remained.\n\nLoss of habitat because of agriculture has also contributed to its decline, though this is no longer as significant a factor because the rhinoceros only lives in one nationally protected park. Deteriorating habitats have hindered the recovery of rhino populations that fell victim to poaching. Even with all the conservation efforts, the prospects for their survival are grim. Because the population is restricted to one small area, they are very susceptible to disease and inbreeding depression. Conservation geneticists estimate a population of 100 rhinos would be needed to preserve the genetic diversity of this conservation-reliant species.\n\nThe Ujung Kulon peninsula of Java was devastated by the eruption of Krakatoa in 1883. The Javan rhinoceros recolonized the peninsula after the event, but humans never returned in large numbers, thus creating a haven for wildlife. In 1931, as the Javan rhinoceros was on the brink of extinction in Sumatra, the government of the Dutch East Indies declared the rhino a legally protected species, which it has remained ever since. A census of the rhinos in Ujung Kulon was first conducted in 1967; only 25 animals were recorded. By 1980, that population had doubled, and has remained steady, at about 50, ever since. Although the rhinos in Ujung Kulon have no natural predators, they have to compete for scarce resources with wild cattle, which may keep their numbers below the peninsula's carrying capacity. Ujung Kulon is managed by the Indonesian Ministry of Forestry. Evidence of at least four baby rhinos was discovered in 2006, the most ever documented for the species.\n\nIn March 2011, hidden-camera video was published showing adults and juveniles, indicating recent matings and breeding. During the period from January to October 2011, the cameras had captured images of 35 rhinos. As of December 2011, a rhino breeding sanctuary in an area of 38,000 hectares is being finalized to help reach the target of 70 to 80 Javan rhinos by 2015.\n\nIn April 2012, the WWF and International Rhino Foundation added 120 video cameras to the existing 40 to better monitor rhino movements and judge the size of the animals' population. A recent survey has found far fewer females than males. Only four females among 17 rhinos were recorded in the eastern half of Ujung Kulon, which is a potential setback in efforts to save the species.\n\nWith Ujung Kulon as the last resort of this species, all the Javan rhinos are in one location, an advantage over the Sumatran rhino which is dispersed in different, unconnected areas. However, this may also be disadvantageous to the Javan rhino population, because any catastrophic diseases or tsunamis could wipe them all out at once. Poaching for their horns is no longer as serious a threat as in the past, due to stricter international regulations on rhino horn, active protection efforts by local authorities, the rhinos' elusiveness and Ujung Kulon's remoteness. However, there are still obstacles to the species recovery. In 2012, the Asian Rhino Project was working out the best eradication programme for the arenga palm, which was blanketing the park and crowding out the rhinos' food sources. Following the trails of Javan rhinoceros allowed in-depth observation of their feeding habits in their natural habitat. Comparing the acid insoluble ash (MA) content of faeces and in the dry weight of food provided reliable estimates of digestibility, and this method has potential for wider application in situations where total collection of faecal matter is not feasible. There was a strong positive correlation between the size of home range and diversity of food intake, and between the size of home range with the numbers of wallow holes used. The quantity and quality of food intake were variable among rhinoceroses and over time. Overall energy consumption was related to the size of the animal, while the digestibility of plants consumed appeared to be influenced by individual age and habitat conditions.\n\nIn May 2017, Director of the Biodiversity Conservation at the Ministry of Environment and Forestry, Bambang Dahono Adji announced plans to transfer the rhinos to the Cikepuh Wildlife Sanctuary located in West Java. The animals will first undergo DNA tests to determine lineage and risk to disease so as to avoid issues such as \"inbreeding\" or marriage kinship.\n\nOnce widespread in Southeast Asia, the Javan rhinoceros was presumed extinct in Vietnam in the mid-1970s, at the end of the Vietnam War. The combat wrought havoc on the ecosystems of the region through the use of napalm, extensive defoliation from Agent Orange, aerial bombing, use of landmines, and overhunting by local poachers.\n\nIn 1988, the assumption of the subspecies' extinction was challenged when a hunter shot an adult female, proving the species had somehow survived the war. In 1989, scientists surveyed Vietnam's southern forests to search for evidence of other survivors. Fresh tracks belonging to up to 15 rhinos were found along the Dong Nai River. Largely because of the rhinoceros, the region they inhabited became part of the Cat Tien National Park in 1992.\n\nBy the early 2000s, their population was feared to have declined past the point of recovery in Vietnam, with some conservationists estimating as few as three to eight rhinos, and possibly no males, survived. Conservationists debated whether or not the Vietnamese rhinoceros had any chance of survival, with some arguing that rhinos from Indonesia should be introduced in an attempt to save the population, with others arguing that the population could recover.\n\nGenetic analysis of dung samples collected in Cat Tien National Park in a survey from October 2009 to March 2010 showed only a single individual Javan rhinoceros remained in the park. In early May 2010, the body of a Javan rhino was found in the park. The animal had been shot and its horn removed by poachers. In October 2011, the International Rhino Foundation confirmed the Javan rhinoceros was extinct in Vietnam, leaving only the rhinos in Ujung Kulon.\n\nA Javan rhinoceros has not been exhibited in a zoo for over a century. In the 19th century, at least four rhinos were exhibited in Adelaide, Calcutta, and London. At least 22 Javan rhinos have been documented as having been kept in captivity; the true number is possibly greater, as the species was sometimes confused with the Indian rhinoceros.\n\nThe Javan rhinoceros never fared well in captivity. The oldest lived to be 20, about half the age that the rhinos can reach in the wild. No records are known of a captive rhino giving birth. The last captive Javan rhino died at the Adelaide Zoo in Australia in 1907, where the species was so little known that it had been exhibited as an Indian rhinoceros.\n\nThe Javan rhinoceros occurred in Cambodia in the past and there are at least three depictions of rhinos in the bas reliefs of the temple at Angkor Wat. The west wing of the North Gallery has a relief that shows a rhino mounted by a god thought to be the fire god Agni. The rhinos are thought to be Javan rhinoceros rather than the somewhat similar looking one-horned Indian rhino on the basis of the skinfold on the shoulder which continues along the back in the Javan to give a saddle-like appearance. A depiction of the rhino in the east wing of the South Gallery shows a rhino attacking the damned in the panel depicting heaven and hell. An architect of the temple is thought to have been an Indian Brahmin priest named Divakarapandita (1040-1120 AD) who served king Jayavarman VI, Dharanindravarman I as well as Suryavarman II who constructed the temple. It is thought that the Indian priest who died before the construction of the temple might have influenced the use of tubercles on the skin which are based on the Indian rhino while the local Khmer artisans carved the other details of the rhinos based on the more familiar local Javan rhino. The association of the rhinoceros as the vahana of the god Agni is unique to Khmer culture. Another rhinoceros carving in the centre of a circular arrangement in a column with other circles containing elephants and water buffalo is known from the temple of Ta Prohm. It has been at the centre of anachronistic speculation that it might represent a Stegosaur due to the leaves behind it that give the impression of plates.\n\nAccording to the World Wide Fund for Nature (WWF) the Javan rhino is the most threatened rhino species with only 58-68 remaining in Ujung Kulan National Park in Java, Indonesia.\n\nAccording to the WWF, there are many threats faced by the Javan rhino for survival for its species that result in its designation as \"critically endangered\". One of those threats is its \"reduced genetic diversity\", because the low number of existing Javan rhinos results in a low amount of genetic diversity and increased inbreeding, making it difficult for the Javan rhino to survive. The WWF also identifies \"natural disasters\" as another threat faced by Javan rhinos, because Ujung National Park can be affected by tsunamis or the explosion of the nearby volcano Anak Krakatau, which potentially could wipe out the entire Javan rhino species. A third threat identified by the WWF is \"disease\", given that four Javan rhinos are believed to have died from a disease transmitted to them by wild cattle. Another threat is \"habitat degradation\", since the WWF reports that people are encroaching and developing areas near the Ujung National Park and thus destroying the last known habitat of the Javan rhino.\n\n"}
{"id": "44360481", "url": "https://en.wikipedia.org/wiki?curid=44360481", "title": "Juan Tavera", "text": "Juan Tavera\n\nJuan Tavera (1917–1991) was a Chilean geologist and paleontologist. His most important work was on the marine invertebrate fossils of the formations of Algarrobo, Arauco and Navidad. Tavera's work contributed to an increased understanding of the stratigraphy of Chile, for example by defining Ranquil Formation in 1942.\n\nAlong with Charles Darwin, Juan Brüggen and Gustav Steinmann he is one of the prominent geologists to have studied Navidad Formation in Central Chile.\n\nThe species \"Paulckella taverai\" is named after him.\n"}
{"id": "27008781", "url": "https://en.wikipedia.org/wiki?curid=27008781", "title": "Kinetic exchange models of markets", "text": "Kinetic exchange models of markets\n\nKinetic exchange models are multi-agent dynamic models inspired by the statistical physics of energy distribution, which try to explain the robust and universal features of income/wealth distributions.\n\nUnderstanding the distributions of income and wealth in an economy has been a classic problem in economics for more than a hundred years. Today it is one of the main branches of econophysics.\n\nIn 1897, Vilfredo Pareto first found a universal feature in the distribution of wealth. After that, with some notable exceptions, this field had been dormant for many decades, although accurate data had been accumulated over this period.\nConsiderable investigations with the real data during the last fifteen years (1995–2010) revealed that the tail (typically 5 to 10 percent of agents in any country) of the income/wealth distribution indeed follows a power law. However, the majority of the population (i.e., the low-income population) follows a different distribution which is debated to be either Gibbs\nor log-normal.\n\nBasic tools used in this type of modelling are probabilistic and statistical methods mostly taken from the kinetic theory of statistical physics. Monte Carlo simulations often come handy in solving these models.\n\nSince the distributions of income/wealth are the results of the interaction among many heterogeneous agents, there is an analogy with statistical mechanics, where many particles interact. This similarity was noted by Meghnad Saha and B. N. Srivastava in 1931 and thirty years later by Benoit Mandelbrot. In 1986, an elementary version of the stochastic exchange model was first proposed by J. Angle.\n\nIn the context of kinetic theory of gases, such an exchange model was first investigated by A. Dragulescu and V. Yakovenko. The main modelling effort has been put to introduce the concepts of savings, and taxation in the setting of an ideal gas-like system. Basically, it assumes that in the short-run, an economy remains conserved in terms of income/wealth; therefore \"law of conservation\" for income/wealth can be applied. Millions of such conservative transactions lead to a steady state distribution of money (gamma function-like in the \"Chakraborti-Chakrabarti\" model with uniform savings, and a gamma-like bulk distribution ending with a Pareto tail in the \"Chatterjee-Chakrabarti-Manna\" model with distributed savings) and the distribution converges to it. The distributions derived thus have close resemblance with those found in empirical cases of income/wealth distributions.\n\nThough this theory has been originally derived from the entropy maximization principle of statistical mechanics, it has recently been shown that the same could be derived from the utility maximization principle as well, following a standard exchange-model with Cobb-Douglas utility function. The exact distributions produced by this class of kinetic models are known only in certain limits and extensive investigations have been made on the mathematical structures of this class of models. The general forms have not been derived so far.\n\nThis class of models has attracted criticisms from many dimensions. It has been debated for long whether the distributions derived from these models are representing the income distributions or wealth distributions. The \"law of conservation\" for income/wealth has also been a subject of criticism.\n\n\n"}
{"id": "10882956", "url": "https://en.wikipedia.org/wiki?curid=10882956", "title": "La Recherche", "text": "La Recherche\n\nLa Recherche is a monthly French language popular science magazine covering recent scientific news. It is published by the Société d'éditions scientifiques (the \"Scientific Publishing Group\"), a subsidiary of Financière Tallandier. Tallandier is owned by Artémis, an investment company of François-Henri Pinault. The headquarters is in Paris.\n\nCreated in 1946 Under the name \"Atomes\" (\"Atoms\"), it changed its name to the current \"La Recherche\" in 1970. The first issue with the title was published in May 1970. It absorbed the French journal \"Nucleus\", formerly \"La Revue Scientifique de France et de l'étranger\" (the \"Scientific Journal of France and Abroad\") in 1971, followed by \"Science Progrès, Découverte\", formerly \"La Nature\" in 1973. \"La Recherche\" is published monthly. The website of the magazine was started in 1995.\n\n\n\"This article incorporates text from the French language Wikipedia article\" .\n"}
{"id": "7719976", "url": "https://en.wikipedia.org/wiki?curid=7719976", "title": "Lactobacillus brevis", "text": "Lactobacillus brevis\n\nLactobacillus brevis is a gram-positive, rod shaped species of lactic acid bacteria which is heterofermentive, creating CO2 and lactic acid during fermentation. There are approximately 16 different strains. It can be found in many different environments, such as fermented foods, and as normal microbiota. \"L.brevis\" is found in food such as sauerkraut and pickles. It is also one of the most common causes of beer spoilage. Ingestion has been shown to improve human immune function, and it has been patented several times. Normal gut \"microbiota\" \"L.brevis\" is found in human intestines, vagina and feces.\n\n\"L. brevis\" is one of the major \"Lactobacillus\" species found in tibicos grains, used to make kefir, and has been identified as the species responsible for the production of the polysaccharide (dextran) that forms the grains. Major metabolites of \"L. brevis\" include lactic acid and ethanol. Strains of \"L. brevis\" and \"L. hilgardii\" have been found to produce the biogenic amines tyramine and phenylethylamine.\n\nE.B.Fred, W.H. Peterson, and J.A. Anderson initially discovered the entire Lactobacillus species in 1921 and the species was categorized based on the ability to metabolize certain carbon and sugars. This early study showed that this can produce acetic acid, carbon dioxide and large amounts of mannitol. Mannitol which is another carbon source that can be used to produce lactic acid.\n\n\"L. brevis\" has been shown to actively transport glucose and galactose. When fructose was used as a carbon source there was only some growth and \"L. brevis\" was able to partially metabolize the fructose to mannitol. Normal growth follows the lactic acid pathway that is commonly used by most lactic acid bacterium. There are some strains that poorly metabolize glucose, whereas other strain are able to easily metabolize the sugar. As stated, this is considered a lactic acid pathway.By using the fermentation pathway the end result is lactic acid. It appears that under high temperature conditions, 50 degrees Celsius and in acidic environments the survival of this bacteria is longer than most bacteria under acidic conditions, the bacteria can live about 45 minutes.\n\nAntibiotic resistance is acquired through conjugation, a method of bacterial reproduction. Conjugation permits a sharing of DNA allowing the bacterium to learn about various antibiotics through exposure and this information is passed down through replication between bacteria. \n\"L. brevis\" produces more organic acids, specifically acetic acid and ethanol. This means that this bacterium produces an increased acidic environment and alcohol. Growth conditions all depend on the location of the bacterium within the intestines. It does seem that they are unable to significantly replicate in anaerobic environments.\n\nMetabolic pathways are defined to mean the chemical process that occurs within an organism. \"L. brevis\" uses the glycolysis process to metabolize carbon sources by active transport, which moves material against the concentration gradient, normally this occurs is a movement from a high to low concentration. This pathway is used in probiotics and food preservation. \n\"L. brevis\" is found in food such as sauerkraut and pickles. It is also one of the most common causes of beer spoilage. The hop, which is an antimicrobial bitter flavoring agent in beer, fails to suppress some strains of L. brevis because they produce a transporter that pumps the active agents of hops out of the bacterial cell. \"L. brevis\" is one of the major \"Lactobacillus\" species found in tibicos grains (aka water kefir grains), and has been identified as the species responsible for the production of the polysaccharide (dextran) that forms the grains. Major metabolites of \"L. brevis\" include lactic acid and ethanol. Strains of \"L. brevis\" and \"L. hilgardii\" have been found to produce the biogenic amines tyramine, which is found by the fermentation metabolic pathway and is commonly found in spoiled or fermented foods and phenylethylamine, which is found in chocolates but can also produce a fishy odor in other foods.\nAs a bacterium there are some physical attributes that are common for all bacteria. Gram-positive bacteria consists of an external plasma membrane, followed by periplasmic space and finally a peptidoglycan layer, which faces the interior of the bacteria. The external plasma membrane is very important for bacteria because this is how cells recognize the possible pathogenesis of the bacteria. Peptidoglycan is also called murein and is made up of a series of sugars. Within gram-positive bacteria the peptidoglycan layer is much thicker than gram-negative bacteria. The actual lattice that comprises peptidoglycan is referred to as the S-layer; this lattice is linked to the peptidoglycan layer. Unfortunately, the S-layer is normally lost when processing the bacteria under laboratory conditions, which can affect measuring adhesion. When the S-layer is dissolved with high concentration levels of substances that break down hydrogen bonds the S-layers have a survival time of about 20 minutes with each generation. \"L.brevis\" contains approximately two promotors within this area, meaning that there is significant transcription of the S-layer by high levels of transcribing of the sIpA gene. SipA is a gene that has been found to aid in the coding for the production of murin (peptidoglycan) within the bacteria. The purpose of transcription is to copy DNA into a mRNA, which is used to create proteins. The promoter is used during transcription to identify the appropriate location to begin transcribing. Within probiotics it is actually the S-layer that attaches to the cellular wall of the gastrointestinal tract \nIngestion of probiotics has been shown to improve human immune function, and \"L. brevis\" has been patented several times. \"L. brevis\" has been shown to survive in the gastrointestinal tract in humans and can therefore be used as a probiotic. Currently the bacterium does not have the ability to convert milk to yogurt however, they are appropriate to be used as an alternative to other probiotics in yogurts. Within the geriatric population use of the bacteria in milk has been shown to increase cellular immunity. Dietary probiotic supplementation enhances natural killer cell activity in the elderly (an investigation of age-related immunological changes). \"L. brevis\" is considered appropriate for probiotic use because there is significant growth at pH’s 4-5, pH 5 is normally the appropriate range for milk and yogurts.\n\nThere are significant vaginal bacteria that are found within the vagina and \"L. brevis\" is included in this microbiome, which is a collection of various bacteria. The bacteria collaborate on protecting the vagina and vaginal maintenance. Women of childbearing ages have a significant amount of \"L.brevis\" and this is normally found in a healthy vagina. For some illnesses or disruptions of the vagina this bacteria can be used in aiding to restore the microbiome. Most of the Lactobacillus species of bacteria have been found useful in preventing urinary tract infections. The efficiency in which a bacterium can defend the body is:\n(1) Their symbiosis with potential pathogens.\n(2) Their capability of producing antibacterial materials, such as hydrogen peroxide, to limit pathogen growth.\n(3) Their production of biosurfactants that inhibit pathogen adherence.\n(4) Their ability to prime macrophages, leukocytes, cytokines, and other host defenses.\n\nDuring normal childbirth, it appears that newborns after a period of days receive transmission of \"L. brevis\" from the mother. It appears that the transmission occurs through breast feeding or through natural child birth. In infants, this resistance is also helpful with protecting the gut against various bile and acids. \"Helicobacter pylori,\" which is a common gut pathogen in humans, studies have shown that certain strains of \"L.brevis\" are successful at combating this pathogen.\n\nVaginosis is the most common form of bacterial infection this is commonly diagnosed as a yeast infection or trichomoniasis, which is a sexually transmitted parasite commonly acquired during intercourse. \"L.brevis\" along with \"Lactobacillus jensenii\" has been shown to produce high levels of hydrogen peroxide which may be able remediate the bacterial vaginosis pathogenesis.\"L. Brevis\" is a commonly used ingredient in pharmaceutical materials used to treat vaginosis. An evaluation of clue cells is one method of assessing vaginosis; this assessment is performed by mounting clue cells and vaginal discharge onto a slide then adding sodium chloride followed by a microscopic assessment which involves bacteria identification.\n\nIn addition to surviving within the gut of an organism, \"L.Brevis\" can also act to inhibit the pathogenic effects of certain gut pathogens and can also proliferate in the presence of additional bacteria. Some strains are resistant to certain antibiotics, specifically erythromycin and clindamycin. This antibiotic resistance may be helpful in maintaining a healthy gut microbiome when taking prescribed antibiotics.\n\n"}
{"id": "6635218", "url": "https://en.wikipedia.org/wiki?curid=6635218", "title": "Line source", "text": "Line source\n\nA line source, as opposed to a point source, area source, or volume source, is a source of air, noise, water contamination or electromagnetic radiation that emanates from a linear (one-dimensional) geometry. The most prominent linear sources are roadway air pollution, aircraft air emissions, roadway noise, certain types of water pollution sources that emanate over a range of river extent rather than from a discrete point, elongated light tubes, certain dose models in medical physics and electromagnetic antennas. While point sources of pollution were studied since the late nineteenth century, linear sources did not receive much attention from scientists until the late 1960s, when environmental regulations for highways and airports began to emerge. At the same time, computers with the processing power to accommodate the data processing needs of the computer models required to tackle these one-dimensional sources became more available.\n\nIn addition, this era of the 1960s saw the first emergence of environmental scientists who spanned the disciplines required to accomplish these studies. For example, meteorologists, chemists, and computer scientists in the air pollution field were required to build complex models to address roadway air dispersion modeling. Prior to the 1960s, these specialities tended to work within their own disciplines, but with the advent of NEPA, the Clean Air Act, the Noise Control Act in the United States, and other seminal legislation, the era of multidisciplinary environmental science had begun.\n\nFor electromagnetic linear sources, the principal early advances in computer modeling arose in the Soviet Union and USA when the end of World War II and the Cold War were fought partially by progress in electronic warfare, including the technologies of active antenna arrays.\n\nAir pollution levels near major highways and urban arterials are in violation of U.S. National Ambient Air Quality Standards where millions of Americans live or work. Even the interior of a building does not really protect inhabitants from adverse exterior air quality, since the exterior air is the intake supply, and it is well known that indoor air quality is typically worse than exterior air.\n\nA roadway travelled by motor vehicles can be idealized by a line source emitting air pollutants. This mathematical problem was first solved in 1970 by a collaboration of physics, mathematics and computer science. The original theory assumed steady-state traffic conditions and meteorology on a perfectly straight roadway. Currently the models have evolved to treat variable meteorology, time-variant traffic operations and complex roadbed geometries. Current technology allows highway designers and city planners to analyze alternative roadway development plans and assess air quality impacts. The same basic model theory can be applied to airport operations, since the linear source is merely an inclined line. In the early 1970s these ESL models were refined into area source models to account for the finite width of the roadway.\n\nRoadway noise is the most important example of a linear noise source, since it comprises about 80 percent of the environmental noise exposure for humans worldwide. In the 1960s, when computer modeling of this phenomenon was perfected, the first applications of linear source noise modeling became systematic. After passage of the National Environmental Policy Act and Noise Control Act, the demand for detailed analysis soared, and decision makers began to look to acoustical scientists for answers regarding the planning of new roadways and the design of noise mitigation. The intensity of roadway noise is governed by the following variables: traffic operations (speed, truck mix, age of vehicle fleet), roadway surface type, tire types, roadway geometrics, terrain, micrometeorology and the geometry of area structures.\n\nDue to the complexity of the variables, a line source acoustic model must be a computer model that can analyze sound levels in the vicinity of roadways. The first meaningful models arose in the late 1960s and early 1970s. Two of the leading research teams were BBN in Boston and ESL Inc. of Sunnyvale, California. Both of these groups developed complex mathematical models to allow the study of alternate roadway designs, traffic operations and noise mitigation strategies in an arbitrary setting. Later model alterations have come into widespread use among state Departments of Transportation and city planners, but the accuracy of early models has had little change in 40 years.\n\nGenerally line source acoustic models trace sound ray bundles and calculate spreading loss along with ray bundle divergence (or convergence} from refractive phenomena. Diffraction is usually addressed by establishing secondary emitters at any points of topographic or anthropomorphic “sharpness” (such as noise barriers or building surfaces. Meteorology can be addressed in a statistical manner allowing for actual wind rose and wind speed statistics (along with thermocline data).\n\nLess common are line source applications in the field of water pollutant dispersal. This phenomenon generally arises when surface runoff scours soil contaminants from upper soil layers and transports these pollutants to a linear receiving water, such as a river. The underlying land management practices which lead to such sources of water pollution are logging, pesticide application, construction grading, slash-and-burn activity and urban stormwater runoff.\n\nAgain computer models are needed to address the complexity of such an extended linear discharge into a dynamic medium such as flowing water. The resulting surface runoff water carrying pollutants may be considered a line source discharging into a river or stream. The chemical composition of this surface runoff may be characterized by a surface runoff model such as the USGS runoff precipitation algorithm, while the instream transport may be analyzed by a dynamic river pollutant model such as DSSAM.\n\nIn the study of illumination, a variety of sources are linear in nature, most commonly the fluorescent tube, During the process of interior lighting design it is important to calculate the light intensity at work stations or other user areas, not only to ensure sufficient light is present, but more importantly to avoid over-illumination and its attendant energy wastage as well as adverse health effects. Thus the scientists involved in light transmission calculations employ computer models that recognize linear sources when fluorescent fixtures are used. In a typical setting there may be hundreds of finite length light sources that comprise the light output in an office environment. A related concept are the ultraviolet tubes used in phototherapy, where output radiation from the tube can be accurately modeled by treating the tube as a line source. On a larger scale, an illuminated roadway may act as a line source of light pollution.\n\n\n"}
{"id": "17539", "url": "https://en.wikipedia.org/wiki?curid=17539", "title": "Linnaean taxonomy", "text": "Linnaean taxonomy\n\nLinnaean taxonomy can mean either of two related concepts: \n\nLinnaean name also has two meanings: depending on the context, it may either refer to a formal name given by Linnaeus (personally), such as \"Giraffa camelopardalis\" Linnaeus, 1758, or a formal name in the accepted nomenclature (as opposed to a modernistic clade name).\n\nIn his \"Imperium Naturae\", Linnaeus established three kingdoms, namely \"Regnum Animale\", \"Regnum Vegetabile\" and \"Regnum Lapideum\". This approach, the Animal, Vegetable and Mineral Kingdoms, survives today in the popular mind, notably in the form of the parlour game question: \"Is it animal, vegetable or mineral?\". The work of Linnaeus had a huge impact on science; it was indispensable as a foundation for biological nomenclature, now regulated by the nomenclature codes. Two of his works, the first edition of the \"Species Plantarum\" (1753) for plants and the tenth edition of the \"Systema Naturae\" (1758), are accepted as part of the starting points of nomenclature; his binomials (names for species) and generic names take priority over those of others. However, the impact he had on science was not because of the value of his taxonomy.\n\nHis classes and orders of plants, according to his \"Systema Sexuale\", were never intended to represent natural groups (as opposed to his \"ordines naturales\" in his \"Philosophia Botanica\") but only for use in identification. They were used for that purpose well into the nineteenth century. Within each class were several orders.\n\nThe Linnaean classes for plants, in the Sexual System, were: \n\nThe classes based on the number of stamens were then subdivided by the number of pistils, e.g. \"Hexandria monogynia\" with six stamens and one pistil.\n\nIndex to genera p. 1201\n\nOnly in the Animal Kingdom is the higher taxonomy of Linnaeus still more or less recognizable and some of these names are still in use, but usually not quite for the same groups. He divided the Animal Kingdom into six classes, in the tenth edition, of 1758, these were:\n\nHis taxonomy of minerals has long since dropped from use. In the tenth edition, 1758, of the \"Systema Naturae\", the Linnaean classes were:\n\n\nThis rank-based method of classifying living organisms was originally popularized by (and much later named for) Linnaeus, although it has changed considerably since his time. The greatest innovation of Linnaeus, and still the most important aspect of this system, is the general use of binomial nomenclature, the combination of a genus name and a second term, which together uniquely identify each species of organism within a kingdom. For example, the human species is uniquely identified within the animal kingdom by the name \"Homo sapiens\". No other species of animal can have this same binomen (the technical term for a binomial in the case of animals). Prior to Linnaean taxonomy, animals were classified according to their mode of movement.\n\nLinnaeus's use of binomial nomenclature was anticipated by the theory of definition used in Scholasticism. Scholastic logicians and philosophers of nature defined the species man, for example, as \"Animal rationalis\", where \"animal\" was considered a genus and \"rationalis\" (Latin for \"rational\") the characteristic distinguishing man from all other animals. Treating \"animal\" as the immediate genus of the species man, horse, etc. is of little practical use to the biological taxonomist, however. Accordingly, Linnaeus's classification treats \"animal\" as a class including many genera (subordinated to the animal \"kingdom\" via intermediary classes such as \"orders\"), and treats \"homo\" as the genus of a species \"Homo sapiens\", with \"sapiens\" (Latin for \"knowing\" or \"understanding\") playing a differentiating role analogous to that played, in the Scholastic system, by \"rationalis\" (the word \"homo\", Latin for \"human being\", was used by the Scholastics to denote a species, not a genus).\n\nA strength of Linnaean taxonomy is that it can be used to organize the different kinds of living organisms, simply and practically. Every species can be given a unique (and, one hopes, stable) name, as compared with common names that are often neither unique nor consistent from place to place and language to language. This uniqueness and stability are, of course, a result of the acceptance by working systematists (biologists specializing in taxonomy), not merely of the binomial names themselves, but of the rules governing the use of these names, which are laid down in formal nomenclature codes.\n\nSpecies can be placed in a ranked hierarchy, starting with either \"domains\" or \"kingdoms\". Domains are divided into kingdoms. Kingdoms are divided into \"phyla\" (singular: \"phylum\") — for animals; the term \"division\", used for plants and fungi, is equivalent to the rank of phylum (and the current International Code of Botanical Nomenclature allows the use of either term). Phyla (or divisions) are divided into \"classes\", and they, in turn, into \"orders\", \"families\", \"genera\" (singular: \"genus\"), and \"species\" (singular: \"species\"). There are ranks below species: in zoology, \"subspecies\" (but see \"form\" or \"morph\"); in botany, \"variety\" (varietas) and \"form\" (forma), etc.\n\nGroups of organisms at any of these ranks are called \"taxa\" (singular: \"taxon\") or \"taxonomic groups\".\n\nThe Linnaean system has proven robust and it remains the only extant working classification system at present that enjoys universal scientific acceptance. However, although the number of ranks is unlimited, in practice any classification becomes more cumbersome the more ranks are added. Among the later subdivisions that have arisen are such entities as phyla, families, and tribes, as well as any number of ranks with prefixes (superfamilies, subfamilies, etc.). The use of newer taxonomic tools such as cladistics and phylogenetic nomenclature has led to a different way of looking at evolution (expressed in many nested clades) and this sometimes leads to a desire for more ranks. An example of such complexity is the scheme for mammals proposed by McKenna and Bell.\n\nOver time, the understanding of the relationships between living things has changed. Linnaeus could only base his scheme on the structural similarities of the different organisms. The greatest change was the widespread acceptance of evolution as the mechanism of biological diversity and species formation, following the 1859 publication of Charles Darwin's \"On the Origin of Species\". It then became generally understood that classifications ought to reflect the phylogeny of organisms, their descent by evolution. This led to evolutionary taxonomy, where the various extant and extinct are linked together to construct a phylogeny. This is largely what is meant by the term 'Linnaean taxonomy' when used in a modern context.\n\nIn cladistics, originating in the work of Willi Hennig, 1950 onwards, each taxon is grouped so as to include the common ancestor of the group's members (and thus to avoid polyphyly). Such taxa may be either monophyletic (including all descendants) such as genus \"Homo\", or paraphyletic (excluding some descendants), such as genus \"Australopithecus\".\n\nOriginally, Linnaeus established three kingdoms in his scheme, namely for Plants, Animals and an additional group for minerals, which has long since been abandoned. Since then, various life forms have been moved into three new kingdoms: Monera, for prokaryotes (i.e., bacteria); Protista, for protozoans and most algae; and Fungi. This five kingdom scheme is still far from the phylogenetic ideal and has largely been supplanted in modern taxonomic work by a division into three domains: Bacteria and Archaea, which contain the prokaryotes, and Eukaryota, comprising the remaining forms. These arrangements should not be seen as definitive. They are based on the genomes of the organisms; as knowledge on this increases, classifications will change.\n\nRepresenting presumptive evolutionary relationships, especially given the wide acceptance of cladistic methodology and numerous molecular phylogenies that have challenged long-accepted classifications, within the framework of Linnaean taxonomy, is sometimes seen as problematic. Therefore, some systematists have proposed a PhyloCode to replace it.\n\n\n"}
{"id": "620709", "url": "https://en.wikipedia.org/wiki?curid=620709", "title": "List of Linux distributions", "text": "List of Linux distributions\n\nThis page provides general information about notable Linux distributions in the form of a categorized list. Distributions are organized into sections by the major distribution they are based on, or the package management system they are based around.\n\nRed Hat Linux and SUSE Linux were the original major distributions that used the .rpm file format, which is today used in several package management systems. Both of these were later divided into commercial and community-supported distributions. Red Hat Linux was divided into a community-supported but Red Hat-sponsored distribution named Fedora, and a commercially supported distribution called Red Hat Enterprise Linux, whereas SUSE was divided into openSUSE and SUSE Linux Enterprise\n\nFedora is a community supported distribution. It aims to provide the latest software while maintaining a completely Free Software system.\n\nThis list is about the distributions using the .rpm packages, excluding derivatives over zypp or Fedora or urpmi or apt-rpm.\nDebian is a distribution that emphasizes free software. It supports many hardware platforms. Debian and distributions based on it use the .deb package format and the dpkg package manager and its frontends (such as apt-get or synaptic).\n\nUbuntu is a distribution based on Debian, designed to have regular releases, a consistent user experience and commercial support on both desktops and servers.\n\nThese Ubuntu variants simply install a set of packages different from the original Ubuntu, but since they draw additional packages and updates from the same repositories as Ubuntu, all of the same software is available for each of them.\n\nUnofficial variants and derivatives are not controlled or guided by Canonical Ltd. and generally have different goals in mind.\n\nKnoppix, itself, is based on Debian. It is a live distribution, with automated hardware configuration and a wide choice of software, which is decompressed as it loads from the drive.\n\npacman is a package manager that is capable of resolving dependencies and automatically downloading and installing all necessary packages. In theory, a user need only run a single command to completely update the system.\nGentoo is a distribution designed to have highly optimized and frequently updated software. Distributions based on Gentoo use the Portage package management system with emerge or one of the alternative package managers.\n\nAlso, the Gentoo project maintains its own list of distributions based on Gentoo.\n\nSlackware is known as a highly customizable distribution that stresses ease of maintenance and reliability over cutting-edge software and automated tools. Generally considered a distribution for advanced users, it is often suggested to those who want to learn the inner workings of a Linux operating system.\n\nSlax's modularity and reputation of quality have made it a popular base for other live CD projects.\n\nThe following distributions can not be categorized under the preceding sections.\n\n\n"}
{"id": "32845880", "url": "https://en.wikipedia.org/wiki?curid=32845880", "title": "List of gene prediction software", "text": "List of gene prediction software\n\nThis is a list of software tools and web portals used for gene prediction.\n\n"}
{"id": "4411034", "url": "https://en.wikipedia.org/wiki?curid=4411034", "title": "M82 X-1", "text": "M82 X-1\n\nM82 X-1 is an ultra-luminous X-ray source located in the galaxy M82. It is a candidate intermediate-mass black hole.\n\n"}
{"id": "23575855", "url": "https://en.wikipedia.org/wiki?curid=23575855", "title": "Manuel Ballester", "text": "Manuel Ballester\n\nManuel Ballester Boix (born in Barcelona on June 27, 1919; died April 5, 2005) was a Spanish chemist.\n\nHe received his degree at the University of Barcelona in 1944, his doctorate in Madrid, and finished his training at Harvard University in 1951. In 1944 he formed a team at the Spanish National Research Council. His work has largely been in kinetics and organic chemistry.\n\n"}
{"id": "7420632", "url": "https://en.wikipedia.org/wiki?curid=7420632", "title": "Minimum information required in the annotation of models", "text": "Minimum information required in the annotation of models\n\nMIRIAM (Minimum Information Required In The Annotation of Models) is a community-level effort to standardize the annotation and curation processes of quantitative models of biological systems. It consists of a set of guidelines suitable for use with any structured format, allowing different groups to collaborate and share resulting models. Adherence to these guidelines also facilitates the sharing of software and service infrastructures built upon modeling activities.\n\nThe idea of \"a set of good practices\" including \"some obligatory metadata\" was first proposed by Nicolas Le Novère in October 2004 as part of a discussion to develop a common database of models in systems biology (which led to the creation of BioModels Database). These initial ideas were further refined at a meeting in Heidelberg, during ICSB 2004, with representatives from many other interested groups.\n\nMIRIAM is a registered project of the MIBBI (minimum information for biological and biomedical investigations).\n\nThe MIRIAM Guidelines are composed of three parts, \"reference correspondence\", \"attribution annotation\", and \"external resource annotation\", each of which deals with a different aspect of information that should be included within a model.\n\n'Reference correspondence' deals with the basic reference information needed to make use of the model, detailing on a gross level the format of the model file, and its instantiability for simulation purposes.\n\n\n'Attribution annotation' deals with the attribution information that must be embedded within the model file.\n\n\n'External resource annotation' defines the manner in which annotations should be constructed. Those annotations contain references to entities in databases, classifications, ontologies, etc. One of the purposes of annotation is to allow unambiguous identification of the various model components.\n\n\nMore information about the existing qualifiers is available from BioModels.net.\n\nSo far, annotation is mainly a manual work, so to ensure their longevity the usage of perennial URIs is necessary. It was recognised that the generation of valid and unique URIs for annotation required the creation of a catalogue of shared namespaces for use by the community. This function is provided by the MIRIAM Registry. The Registry also provides a variety of supporting auxiliary features to enable automated procedures based upon these URIs. The ability to generate resolvable identifiers is provided through the use of the resolving layer, Identifiers.org.\n\n"}
{"id": "20429570", "url": "https://en.wikipedia.org/wiki?curid=20429570", "title": "Motor imagery", "text": "Motor imagery\n\nMotor imagery is a mental process by which an individual rehearses or simulates a given action. It is widely used in sport training as mental practice of action, neurological rehabilitation, and has also been employed as a research paradigm in cognitive neuroscience and cognitive psychology to investigate the content and the structure of covert processes (i.e., unconscious) that precede the execution of action. In some medical, musical, and athletic contexts, when paired with physical rehearsal, mental rehearsal can be as effective as pure physical rehearsal (practice) of an action.\n\nMotor imagery can be defined as a dynamic state during which an individual mentally simulates a given action. This type of phenomenal experience implies that the subject feels themselves performing the action. It corresponds to the so-called internal imagery (or first person perspective) of sport psychologists.\n\nMental practice refers to use of visuo-motor imagery with the purpose of improving motor behavior. Visuo-motor imagery requires the use of one's imagination to simulate an action, without physical movement. It has come to the fore due to the relevance of imagery in enhancing sports and surgical performance.\n\nMental practice, when combined with physical practice, can be beneficial to beginners learning a sport, but even more helpful to professionals looking to enhance their skills. Physical practice generates the physical feedback necessary to improve, while mental practice creates a cognitive process physical practice cannot easily replicate.\n\nWhen surgeons and other medical practitioners mentally rehearse procedures along with their physical practice, it produces the same results as physical rehearsal, but costs much less. But unlike its use in sports, to improve a skill, mental practice is used in medicine as a form of stress reduction before operations.\n\nMental practice is a technique used in music as well. Professional musicians may use mental practice when they are away from their instrument or unable to physically practice due to an injury. Studies show that a combination of physical and mental practice can provide improvement in mastering a piece equal to physical practice alone. This is because mental practice causes neuron growth that mirrors growth caused by physical practice. And there is precedent: Vladimir Horowitz and Arthur Rubinstein, among others, supplemented their physical practice with mental rehearsal.\n\nMental practice has been used to rehabilitate motor deficits in a variety of neurological disorders. Mental practice of action seems to improve balance in individuals with multiple sclerosis and in elderly women. For instance, mental practice has been used with success in combination with actual practice to rehabilitate motor deficits in a patient with sub-acute stroke. Several studies have also shown improvement in strength, function, and use of both upper and lower extremities in chronic stroke.\n\nMotor imagery has been studied using the classical methods of introspection and mental chronometry. These methods have revealed that motor images retain many of the properties, in terms of temporal regularities, programming rules and biomechanical constraints, which are observed in the corresponding real action when it comes to execution. For instance, in an experiment participants were instructed to walk mentally through gates of a given apparent width positioned at different apparent distances. The gates were presented to the participants with a 3-D visual display (a virtual reality helmet) which involved no calibration with external cues and no possibility for the subject to refer to a known environment. Participants were asked to indicate the time they started walking and the time they passed through the gate. Mental walking time was found to increase with increasing gate distance and decreasing gate width. Thus, it took the participant longer to walk mentally through a narrow gate than to walk through a larger gate placed at the same distance. This finding led neurophysiologists Marc Jeannerod and Jean Decety to propose that there is a similarity in mental states between action simulation and execution.\n\nThe functional equivalence between action and imagination goes beyond motor movements. For instance similar cortical networks mediate music performance and music imagery in pianists.\n\n A large number of functional neuroimaging studies have demonstrated that motor imagery is associated with the specific activation of the neural circuits involved in the early stage of motor control (i.e., motor programming). This circuits includes the supplementary motor area, the primary motor cortex, the inferior parietal cortex, the basal ganglia, and the cerebellum. Such physiological data gives strong support about common neural mechanisms of imagery and motor preparation.\n\nMeasurements of cardiac and respiratory activity during motor imagery and during actual motor performance revealed a covariation of heart rate and pulmonary ventilation with the degree of imagined effort.\nMotor imagery activates motor pathways. Muscular activity often increases with respect to rest, during motor imagery. When this is the case, EMG activity is limited to those muscles that participate in the simulated action and tends to be proportional to the amount of imagined effort.\n\nMotor imagery is now widely used as a technique to enhance motor learning and to improve neurological rehabilitation in patients after stroke. Its effectiveness has been demonstrated in musicians.\n\n\nMotor imagery is close to the notion of simulation used in cognitive and social neuroscience to account for different processes. An individual who is engaging in simulation may replay his own past experience in order to extract from it pleasurable, motivational or strictly informational properties. Such a view was clearly described by the Swedish physiologist Hesslow. For this author, the simulation hypothesis states that thinking consists of simulated interaction with the environment, and rests on the following three core assumptions: (1) Simulation of actions: we can activate motor structures of the brain in a way that resembles activity during a normal action but does not cause any overt movement; (2) Simulation of perception: imagining perceiving something is essentially the same as actually perceiving it, only the perceptual activity is generated by the brain itself rather than by external stimuli; (3) Anticipation: there exist associative mechanisms that enable both behavioral and perceptual activity to elicit other perceptual activity in the sensory areas of the brain. Most importantly, a simulated action can elicit perceptual activity that resembles the activity that would have occurred if the action had actually been performed.\n\nMental simulation may also be a representational tool to understand the self and others. Philosophy of mind and developmental psychology also draw on simulation to explain our capacity to mentalize, i.e., to understand mental states (intentions, desires, feelings, and beliefs) of others (aka theory of mind). In this context, the basic idea of simulation is that the attributor attempts to mimic the mental activity of the target by using his own psychological resources. In order to understand the mental state of another when observing the other acting, the individual imagines herself/himself performing the same action, a covert simulation that does not lead to an overt behavior. One critical aspect of the simulation theory of mind is the idea that in trying to impute mental states to others, an attributor has to set aside her own current mental states, and substitutes those of the target.\n\n\n"}
{"id": "44290263", "url": "https://en.wikipedia.org/wiki?curid=44290263", "title": "Mutual shaping", "text": "Mutual shaping\n\nThe term mutual shaping was developed through Science and Technology Studies (STS) in an attempt to explain the detailed process of technological design. Mutual shaping is a combination of social determinism and technological determinism, suggesting that society and technology are not mutually exclusive to one another and, instead, influence and shape each other.\n\nTechnological determinism (TD), coined by Thorstein Veblen, suggests that technology is the primary catalyst for change in society. Following this theory, the development and implementation of technology is beyond the control of society as it is pervasive in all elements of our lives. Once a technology has been created its influence on society is an inevitable, predetermined path. An example that supports technological determinism is the development of the printing press that accelerated the Protestant Reformation.\n\nIn contrast, social determinism (SD), popularized by social theorists Karl Marx and Emile Durkheim, purports that social structure is the driving factor towards change in society. Following this view, society is the governing force that determines social behaviour, and technology is created and adapted based on society’s wants and needs.\n\nBoth TD and SD are cause-and-effect theories suggesting that technology and society are mutually exclusive. The theory of mutual shaping suggests that technology design is a result of a synthesis of TD and SD. It sees technology and society working together to facilitate change. Society changes as a direct result of the implementation of technology that has been created based on society’s wants and needs. They function collectively to shape one another.\n\nMutual shaping is exemplified through the integration of online social networking platforms into daily life. They are a communications technology designed to complement pre-existing methods of communication, such as the phone or in-person conversations, that have become more convenient and/or affordable than their predecessors. TD would argue that these communication technologies have directly influenced our networking capabilities due to their accessibility. Without them we would not be able to conduct business or maintain friendships over long distances. SD would argue that these platforms were created as a result of a need to facilitate communication over long distances. Mutual shaping supports both of these arguments, believing that the two cannot be separated. Social networking platforms display how technology and society are inextricably linked as they work together towards the advancement of one another, exemplifying the theory of mutual shaping.\n"}
{"id": "51301299", "url": "https://en.wikipedia.org/wiki?curid=51301299", "title": "NGC 155", "text": "NGC 155\n\nNGC 155 is a lenticular galaxy in the Cetus constellation. It was discovered on September 1, 1886, by Lewis A. Swift.\n\n"}
{"id": "30891039", "url": "https://en.wikipedia.org/wiki?curid=30891039", "title": "Oxford Department of International Development", "text": "Oxford Department of International Development\n\nThe Oxford Department of International Development (ODID), or Queen Elizabeth House (QEH), is a department of the University of Oxford in England, and a unit of the University’s Social Sciences Division. It is the focal point at Oxford for multidisciplinary research and postgraduate teaching on the developing world.\n\nThe current Head of Department is Professor Christopher Adam. Former Heads of Department include Dr Nandini Gooptu, Professor Valpy FitzGerald, Professor Barbara Harriss-White, Rosemary Thorp and Professor Frances Stewart.\n\nQEH was founded as a result of a gift of £100,000 given by Sir Ernest Oppenheimer to the University of Oxford. The donation was for the development of colonial studies and the establishment of an associated colonial centre. A further gift of £50,000 was given by the Colonial Development and Welfare Fund of the British government.\n\nQEH was constituted by Royal Charter in 1954 to provide a residential centre which people concerned with the study of Commonwealth affairs could visit to make contacts and exchange ideas.\n\nIn the 1980s there was a drive to reshape QEH as a centre for international studies, rather than purely for study concerning the Commonwealth. In 1986 it was merged with the Institute of Commonwealth Studies, Oxford and the Oxford University Institute of Agricultural Economics to create the International Development Centre, a department of the University within the Social Studies Faculty.\n\nFrom 1958 to 2005 QEH was located at 20-21 St Giles. In 2005, the department moved to the former School of Geography building in Mansfield Road and became known as the Oxford Department of International Development. In 2011 the Palace authorised the use of the name Queen Elizabeth House for the buildings at 3 Mansfield Road.\n\nThe Department provides postgraduate research training (DPhil and MPhil) and four MSc taught courses to some 200 students. These programmes involve advanced research methods, personal supervision, subject specialisation and fieldwork. International demand for these programmes is high and entrance standards are exacting. The Department forms part of the ESRC-funded Doctoral Training Centre for the Social Sciences at the University of Oxford.\n\nODID currently offers the following degree courses:\n\nThe Department hosts some 80 active researchers working on four broad themes: Economic Development and International Institutions; Migration and Refugees in a Global Context; Human Development, Poverty and Children; and Political Change, Conflict and the Environment.\n\nResearch at ODID is conducted by individual scholars as well as by six externally funded research groups:\n\n"}
{"id": "39395613", "url": "https://en.wikipedia.org/wiki?curid=39395613", "title": "PolarTREC", "text": "PolarTREC\n\nPolarTREC (Teachers and Researchers Exploring and Collaborating) is a program for K-12 teachers to participate in field research in the polar regions in order to improve their knowledge of polar science and expand the reach of current scientific research beyond the scientific community. Teachers involved in PolarTREC spend about two to six weeks at their polar sites, collaborating with scientific research teams and connecting with students and the public via online media. PolarTREC is funded by the National Science Foundation and managed by the Arctic Research Consortium.\n\nThe purpose of PolarTREC is to stimulate polar science education and awareness.\n\nNotable past PolarTREC expeditions include:\n\n•Carbon Balance in Warming and Drying Tundra (2013), which studied the effects of warming and drying on tundra carbon balance \n\n•Airborne Survey of Polar Ice (2013), a six-year NASA mission, which is the largest airborne survey of Earth's polar ice ever conducted \n\n•Tectonic History of the Transantartic Mountains (2012), which deciphered the tectonic history of the Transantarctic Mountains and the Wilkes Subglacial Basin \n\n•Greenland Education Tour (2012), part of an initiative to foster enhanced international scientific cooperation between Greenland and the US \n\n•In 2011, PolarTREC teacher John Wood lived in a tent at the top of Mt. Erebus, an active volcano in Antarctica. The average temperative was -20 F.\n\nTeachers must apply to the program and only the top 100 applications make it to the PolarTREC selection committee. Researcher also must apply and be selected as a PolarTREC research team. After researchers are selected, a selection of the top 30-40 teacher applications are sent to the various research teams. Researchers select which of the teachers to interview, after which they invite a teacher to join the team. There are usually 12 research teams—6 in the Arctic and 6 in the Antarctic—so out of the over 200 applicants each year only 12 get chosen.\n\nOnce accepted PolarTREC covers the costs of the expedition. The teachers are given special training through webinars and a week long orientation in Fairbanks, Alaska. While on the trip teachers are expected to communicate through the Virtual Home Base and give updates using message boards, photo albums, podcasts, \"PolarConnect\" events and presentations from the field. Using the message boards and journals, teachers can document what the students get excited about and how they learn. This data can be used to shape science curriculum. Teachers are encouraged to share their experiences with a wider audience by writing articles and speaking at conferences. Teachers also encouraged to develop lessons based on their expedition for the Learning Resources section of the website.\n\n\nArctic exploration\n\nResearch Experiences for Teachers\n"}
{"id": "23815340", "url": "https://en.wikipedia.org/wiki?curid=23815340", "title": "Relational-cultural therapy", "text": "Relational-cultural therapy\n\nRelational-cultural theory, and by extension, relational-cultural therapy (RCT) stems from the work of Jean Baker Miller, M.D.. Often, relational-cultural theory is aligned with the feminist and or multicultural movements in psychology. In fact, RCT embraces many social justice aspects from these movements.\n\nRCT was developed in Boston, Massachusetts in the 1970s through the work of psychiatrist, Jean Baker Miller (Toward a New Psychology of Women), psychologists, Judith V. Jordan, Janet Surrey, and Irene Stiver at the Stone Center at Wellesley College in reaction to psychodynamic theory. The Stone Center at Wellesley College and the Jean Baker Miller Training Institute are the hubs of RCT research and training and are perhaps best known for their \"Working Papers\" series, collective works that are continuously considered for review and reconsideration. As RCT was founded in strong feminist principles, and was started at Wellesley College, the movement's traditional focus was on women and their relational experiences.\n\nMany mental health professionals employ RCT in their practice. A nonexhaustive list of these include: counselors, social workers, psychologists, and psychiatrists. Some current major relational-cultural theorists, writers, and practitioners include: Judith V. Jordan, Ph D, Amy Banks, MD, Maureen Walker, Ph D, Linda Hartling, Ph D, Thelma Duffey, Ph D, and Dana Comstock, Ph D.\n\nThe consistent, primary focus of RCT is the primacy of relationships. That is, relationships are both the indicators for, and the healing mechanism in psychotherapy toward, mental health and wellness.\n\nOne of the core tenets of RCT is the Central Relational Paradox (CRP). The CRP assumes that we all have a natural drive toward relationships, and in these relationships we long for acceptance. However, we come to believe that there are things about us that are unacceptable or unlovable. Thus, we choose to hide these things; we keep them out of our relationships. In the end, the connections we make with others are not as fulfilling and validating as they otherwise might have been.\n\nA primary goal of RCT is to create and maintain Mutually-Growth-Fostering Relationships, relationships in which both parties feel that they matter. In these healthy relationships, all of the involved parties experience what is known as the Five Good Things. These include: 1) a desire to move into more relationships, because of how a good relational experience feels; 2) a sense of zest, or energy; 3) increased knowledge of oneself and the other person in the relationship; 4) a desire to take action both in the growth-fostering relationship and outside of it; 5) an overall increased sense of worth.\n\nRCT involves working with clients to identify, and strive in, relationships that present opportunities for her/him to experience Mutually-Growth-Fostering Relationships. In fact, a strong, connected therapeutic relationship should be a model for these kinds of relationships. While there a number of specific challenges presented in the therapeutic relationship, RCT practitioners believe that their relationships with their clients can have a reasonably high degree of mutuality. Clinical experiences of mutuality include: the client's movement toward the awareness that she/he matters to the therapist, the therapist that she/he, too, matters to the client, an integrative awareness both have of what it means to feel like one matters, and the worth involved in offering this to another person through the process of connection.\n"}
{"id": "4697454", "url": "https://en.wikipedia.org/wiki?curid=4697454", "title": "Robert Emden", "text": "Robert Emden\n\nJacob Robert Emden (March 4, 1862 – October 8, 1940) was a Swiss astrophysicist and meteorologist. \n\nEmden was born in St. Gallen, Switzerland. In 1907 he became associate professor of physics and meteorology at the Technical University of Munich. The same year he published the classic work, \"Gaskugeln: Anwendungen der mechanischen Wärmetheorie auf kosmologische und meteorologische Probleme\" (Gas balls: Applications of the mechanical heat theory to cosmological and meteorological problems), which provided a mathematical model as a basis of stellar structure. By 1920 he was a member of the Bayerische Akademie der Wissenschaften.\n\nEmden served as the editor of \"Zeitschrift fur Astrophysik\", founded in 1930. In 1933 he fled from Germany to escape the rise of the National Socialist party, returning to his native Switzerland. \n\nHe was the uncle of the German American astrophysicist Martin Schwarzschild by marriage to Karl Schwarzschild's sister. Jacob Robert Emden died in Zürich in 1940.\n\nThe crater Emden on the Moon is named after him. The Lane-Emden equation and Emden–Chandrasekhar equation are named for him and Jonathan Homer Lane.\n\n"}
{"id": "10105237", "url": "https://en.wikipedia.org/wiki?curid=10105237", "title": "Sylvester equation", "text": "Sylvester equation\n\nIn mathematics, in the field of control theory, a Sylvester equation is a matrix equation of the form:\nThen given matrices \"A\",\"B\", and \"C\", the problem is to find the possible matrices \"X\" that obey this equation. All matrices are assumed to have coefficients in the complex numbers. For the equation to make sense, the matrices must have appropriate sizes, for example they could all be square matrices of the same size. But more generally, \"A\" and \"B\" must be square matrices of sizes \"n\" and \"m\" respectively, and then \"X\" and \"C\" both have \"n\" rows and \"m\" columns.\n\nA Sylvester equation has a unique solution for \"X\" exactly when there are no common eigenvalues of \"A\" and −\"B\".\nMore generally, the equation \"AX\" + \"XB\" = \"C\" has been considered as an equation of bounded operators on a (possibly infinite-dimensional) Banach space. In this case, the condition for the uniqueness of a solution \"X\" is almost the same: There exists a unique solution \"X\" exactly when the spectra of \"A\" and −\"B\" are disjoint.\n\nUsing the Kronecker product notation and the vectorization operator formula_2, we can rewrite Sylvester's equation in the form\nwhere formula_4 is of dimension formula_5, formula_6 is of dimension formula_7, formula_8 of dimension formula_9 and formula_10 is the formula_11 identity matrix. In this form, the equation can be seen as a linear system of dimension formula_12.\n\nProposition. \n\"Given complex formula_13 matrices formula_4 and formula_6, Sylvester's equation has a unique solution formula_8 for all formula_17 if and only if formula_4 and formula_19 have no common eigenvalues.\"\n\nProof. Consider the linear transformation formula_20 given by formula_21.\n\n(i) Suppose that formula_4 and formula_19 have no common eigenvalues. Then their characteristic polynomials formula_24 and formula_25 have highest common factor formula_26. Hence there exist complex polynomials formula_27 and formula_28 such that formula_29. By the Cayley–Hamilton theorem, formula_30; hence formula_31. Let formula_8 be any solution of formula_33; so formula_34 and repeating this one sees that formula_35. Hence by the rank plus nullity theorem formula_36 is invertible, so for all formula_17 there exists a unique solution formula_8.\n\n(ii) Conversely, suppose that formula_39 is a common eigenvalue of formula_4 and formula_19. Note that \nformula_39 is also an eigenvalue of the transpose formula_43. Then there exist non-zero vectors formula_44 and formula_45 such that formula_46 and formula_47. Choose formula_17 such that formula_49, the vector whose entries are the complex conjugates of formula_45. Then formula_51 has no solution formula_8, as is clear from the complex bilinear pairing formula_53; the right-hand side is positive whereas the left is zero.\n\nGiven two square complex matrices \"A\" and \"B\", of size \"n\" and \"m\", and a matrix \"C\" of size \"n\" by \"m\", then one can ask when the following two square matrices of size \"n\" + \"m\" are similar to each other: formula_54 and formula_55. The answer is that these two matrices are similar exactly when there exists a matrix \"X\" such that \"AX\" − \"XB\" = \"C\". In other words, \"X\" is a solution to a Sylvester equation. This is known as Roth's removal rule.\n\nOne easily checks one direction: If \"AX\" − \"XB\" = \"C\" then \nRoth's removal rule does not generalize to infinite-dimensional bounded operators on a Banach space.\n\nA classical algorithm for the numerical solution of the Sylvester equation is the Bartels–Stewart algorithm, which consists of transforming formula_4 and formula_6 into Schur form by a QR algorithm, and then solving the resulting triangular system via back-substitution. This algorithm, whose computational cost is formula_59 arithmetical operations, is used, among others, by LAPACK and the codice_1 function in GNU Octave. See also the codice_2 function in that language. In some specific image processing application, the derived Sylvester equation has a closed form solution.\n\n\n\n"}
{"id": "38982662", "url": "https://en.wikipedia.org/wiki?curid=38982662", "title": "Through Distant Worlds and Times", "text": "Through Distant Worlds and Times\n\nThrough Distant Worlds and Times or Through Distant Worlds and Times: Letters from a Wayfarer in the Universe is a romantic scientific story written by Milutin Milanković, the Serbian mathematician, astronomer, geophysicist and climatologist, in the form of letters to an anonymous young woman.\n\nBetween 1925 and 1928, Milanković tried his hand at popular writing with a series of magazine articles on astronomy, astronomers, and climatology. Each month for three years he wrote a letter to an imaginary friend about visiting something in the universe or journeying to the past to visit an astronomer. The letters contained a large amount of autobiographical detail. They were published in a Serbian magazine and later collected in a book, \"Through Distant Worlds and Times\", published in Serbian and later in German. It was the best selling book of his career.\n\nThe book consists of 37 letters to the unnamed woman. They serve as vehicles for discussion of the history of astronomy, climatology and science. In writing the letters, Milanković remembers his early life, from birth in Dalj, through his education, to successes and failures at a professional level. The work takes inspiration from his travels through Germany, Hungary, Istanbul and Europe, and his return to his birthplace, which seems to him desolate and dilapidated in contrast.\n\nThe writer uses a personal approach to science, traveling with a friend through time and space. In the appropriate attire, they roam the ancient world. Unseen by the natives, they spy Babylonian priests, Aristotle, Eratosthenes and other great scholars and figures of antiquity and modern history.\n\nThe letters describe experiments, development of scientific instruments, ancient architecture and new cities, and an epic voyage on the seas. The history of scientific ideas is explored, including basic knowledge about our sun, planets and their orbits. In the central part of the book, the writer discusses climate change and cyclical ice ages throughout the history and future of the Earth.\n\nIn the final letters, Milanković describes the formation of the Earth and the stages through which it passed until it became the cradle of life, then presents its future, following the dying stages of the Sun and planets. Finally, the book deals with travel to the Moon, Mars and Venus, and a pilgrimage to the universe.\n"}
{"id": "39849418", "url": "https://en.wikipedia.org/wiki?curid=39849418", "title": "Çöpler mine", "text": "Çöpler mine\n\nThe Çöpler mine is one of the largest gold mines in Turkey and in the world, operated by the American Alacer Gold Corporation. The mine is located in Erzincan Province. The mine has estimated reserves of 6 million oz of gold.\n\nÇöpler is an epithermal porphyry copper-gold deposit which forms part of the Middle Eocene Çöpler–Kabataş magmatic complex in central-eastern Turkey which formed on the north-eastern margin of the Tauride-Anatolide microcontinent. The intrusive rocks at Çöpler were emplaced into Late Paleozoic-Mesozoic metamorphosed sedimentary rocks. Dating of igneous rocks indicate a brief magmatic and hydrothermal history at Çöpler less than a million year long about 43.8–44.6 Ma. The composition of magma indicate it was generated in a convergent margin. Çöpler is, however, located to far away from the Maden–Helete arc and therefore must have formed in a back-arc setting, similar to that in the Bingham Canyon Mine, Utah.\n"}
