{"id": "46728242", "url": "https://en.wikipedia.org/wiki?curid=46728242", "title": "AERES", "text": "AERES\n\nAERES, the Agence d'évaluation de la recherche et de l'enseignement supérieur, is a French academic research evaluation agency. AERES was set up as a result of a 2006 law relating to research, and has the task of \"evaluating research and higher education institutions, research organisations, research units, higher education programmes and degrees and with approving their staff evaluation procedures\". \n\nThe Italian ANVUR agency was partly modelled on AERES.\n\n"}
{"id": "5292427", "url": "https://en.wikipedia.org/wiki?curid=5292427", "title": "Ace Science Fiction Specials", "text": "Ace Science Fiction Specials\n\nAce Science Fiction Specials are three series of science fiction and fantasy books published by Ace Books between 1968 and 1990. Terry Carr edited the first and third series, taking the \"TV special\" concept and adapting it to paperback marketing. The first series was one of the most influential in the history of science fiction publishing; four of the six novels nominated for 1970 Nebula Awards were from the series.\n\nThe date given is the year of publication by Ace; some are first editions and some are reprints. Also given is the Ace serial number. The serial number given is that of the first printing in the Ace Special series (except for the reissue of Rite of Passage). Books with a previous first edition are noted as \"reissue\" below. The order listed for series one is the original order of publication; the price is given. Ace reissued many of these books outside of the Ace Special line with different covers and prices, and sometimes different paginations. Award winners are noted; many were nominated for awards. \n\n\nCarr had purchased eight more books for the line, which Ace later published after the series was terminated. The Aldiss volume had been delayed due to issues over Canadian publishing rights, and eventually appeared with the Carr-commissioned Dillon cover.\n\n\nThis series was not edited by Terry Carr.\n\nTerry Carr returned on a freelance basis to edit this series, all of them first novels.\n\n"}
{"id": "8380737", "url": "https://en.wikipedia.org/wiki?curid=8380737", "title": "Acoustic radiation pressure", "text": "Acoustic radiation pressure\n\nAcoustic radiation pressure is the apparent pressure difference between the average pressure at a surface moving with the displacement of the wave propagation (the Lagrangian pressure) and the pressure that would have existed in the fluid of the same mean density when at rest. Numerous authors make a distinction between the phenomena of Rayleigh radiation pressure and Langevin radiation pressure.\n\n\n\n"}
{"id": "416820", "url": "https://en.wikipedia.org/wiki?curid=416820", "title": "Albert Einstein World Award of Science", "text": "Albert Einstein World Award of Science\n\nThe Albert Einstein World Award for Science is an annual award given by the World Cultural Council \"as a means of recognition and encouragement for scientific and technological research and development\", with special consideration for researches which \"have brought true benefit and well being to mankind\". Named for physicist and theoretician Albert Einstein (1879–1955); the award includes a diploma, a commemorative medal, and $10,000.\n\nThe recipient of the award is evaluated and elected by an Interdisciplinary Committee, which is composed of world-renowned scientists, among them 25 Nobel laureates.\n\n"}
{"id": "873844", "url": "https://en.wikipedia.org/wiki?curid=873844", "title": "Anatoli Levchenko", "text": "Anatoli Levchenko\n\nAnatoli Semyonovich Levchenko (; May 5, 1941 – August 6, 1988) was a Soviet cosmonaut.\n\nLevchenko was planned to be the back-up commander of the first Buran space shuttle flight, and in March 1987 he began extensive training for a Soyuz spaceflight, intended to give him some experience in space. In December 1987, he occupied the third seat aboard the spacecraft Soyuz TM-4 to the space station Mir, and returned to Earth about a week later on Soyuz TM-3. His mission is sometimes called Mir LII-1, after the Gromov Flight Research Institute shorthand. In the year following his spaceflight, Levchenko died of a brain tumor, in the Nikolay Burdenko Neurosurgical Institute in Moscow.\n\nSelected as a cosmonaut on July 12, 1980. He was married with one child.\n\nHe was awarded the titles of Hero of the Soviet Union and Pilot-Cosmonaut of the USSR and the Order of Lenin.\n\n"}
{"id": "11760149", "url": "https://en.wikipedia.org/wiki?curid=11760149", "title": "Angle of climb", "text": "Angle of climb\n\nIn aerodynamics, climb gradient is the ratio between distance travelled over the ground and altitude gained, and is expressed as a percentage. The angle of climb can be defined as the angle between a horizontal plane representing the Earth's surface and the actual flight path followed by the aircraft during its ascent.\n\nThe speed of an aircraft type at which the angle of climb is largest is called V. It is always slower than V, the speed for the best rate of climb.\nAs the latter gives the quickest way for gaining altitude levels, regardless of the distance covered during such a maneuver, it is more relevant to cruising. The maximum angle of climb on the other hand is where the aircraft gains the most altitude in a given distance, regardless of the time needed for the maneuver. This is important for clearing an obstacle, and therefore is the speed a pilot uses when executing a \"short field\" takeoff.\nV increases with altitude and V decreases with altitude until they converge at the airplane's absolute ceiling.\n\n"}
{"id": "2235169", "url": "https://en.wikipedia.org/wiki?curid=2235169", "title": "Austin Model 1", "text": "Austin Model 1\n\nAustin Model 1, or AM1, is a semi-empirical method for the quantum calculation of molecular electronic structure in computational chemistry. It is based on the Neglect of Differential Diatomic Overlap integral approximation. Specifically, it is a generalization of the modified neglect of differential diatomic overlap approximation. Related methods are PM3 and the older MINDO.\n\nAM1 was developed by Michael Dewar and co-workers and published in 1985. AM1 is an attempt to improve the MNDO model by reducing the repulsion of atoms at close separation distances. The atomic core-atomic core terms in the MNDO equations were modified through the addition of off-center attractive and repulsive Gaussian functions. \n\nThe complexity of the parameterization problem increased in AM1 as the number of parameters per atom increased from 7 in MNDO to 13-16 per atom in AM1. \n\nThe results of AM1 calculations are sometimes used as the starting points for parameterizations of forcefields in molecular modelling.\n\nAM1 is implemented in the MOPAC, AMPAC, Gaussian, CP2K, GAMESS (US), PC GAMESS, GAMESS (UK), and SPARTAN programs.\n\nAn extension of AM1 is SemiChem Austin Model 1 (SAM1), which is implemented in the AMPAC program and which explicitly treats d-orbitals.\n\nA model for the AM1 calculation of lanthanide complexes, called Sparkle/AM1, was also introduced and is implemented in MOPAC2007.\n\nAM1 has been recently reparameterized, leading to the new RM1, or Recife Model 1, available in MOPAC2007, SPARTAN software, Hyperchem 8, etc.\n\nAn extension of AM1 is AM1* that is available in VAMP software.\n\n\n"}
{"id": "5434910", "url": "https://en.wikipedia.org/wiki?curid=5434910", "title": "Bonner sphere", "text": "Bonner sphere\n\nA Bonner sphere is a device used to determine the energy spectrum of a neutron beam. The method was first described in 1960 by Rice University's Bramblett, Ewing and Tom W. Bonner and employs thermal neutron detectors embedded in moderating spheres of different sizes. Comparison of the neutrons detected by each sphere allows accurate determination of the neutron energy. This detector system utilizes a few channel unfolding techniques to determine the coarse, few group neutron spectrum. The original detector system was capable of measuring neutrons between thermal energies up to ~20 MeV. These detectors have been modified to provide additional resolution above 20 MeV to energies up to 1 GeV.\n\nBecause of the complexity with which neutrons interact with the environment, precise determination of the neutron energy is quite difficult. Bonner sphere spectroscopy (BSS) is one of the few methods that provide an accurate measure of the neutron spectrum.\n\nA single Bonner sphere of an appropriate size can be used for dosimetry, as the sensitivity of the detector will approximate the radiation weighting factor across a range of neutron energies. Such Bonner spheres are sometimes known as a remball.\n\n"}
{"id": "25277659", "url": "https://en.wikipedia.org/wiki?curid=25277659", "title": "Carlo Bassi", "text": "Carlo Bassi\n\nCarlo Bassi (1807, in Amsterdam – 1856, in Milano) \nwas an Italian entomologist.\n\nHe was honorary curator of entomology in the Museo Civico di Storia Naturale di Milan from 1841 to his death in 1856. He was a specialist in Coleoptera.\n\nBassi wrote Description du genre \"Malacogaster\" in Guérin-Méneville's \"Magasin de Zoologie, d'Anatomie com- parée et de Paleontologie\" 1833 and in the 1834 issue of \"Annales de la Société Entomologique de France\") he erected the carabid genus \"Cardiomera\".\nHis collection and extensive library of works on Coleoptera is conserved in the Museo Civico di Storia Naturale di Milan.\n\n"}
{"id": "16872890", "url": "https://en.wikipedia.org/wiki?curid=16872890", "title": "Demographic and Health Surveys", "text": "Demographic and Health Surveys\n\nThe Demographic and Health Surveys (DHS) Program is responsible for collecting and disseminating accurate, nationally representative data on health and population in developing countries. The project is implemented by ICF International and is funded by the United States Agency for International Development (USAID) with contributions from other donors such as UNICEF, UNFPA, WHO, and UNAIDS.\n\nThe DHS is highly comparable to the Multiple Indicator Cluster Surveys and the technical teams developing and supporting the surveys are in close collaboration. \n\nSince September 2013, ICF International has been partnering with seven internationally experienced organizations to expand access to and use of the DHS data: Johns Hopkins Bloomberg School of Public Health Center for Communication Programs; Program for Appropriate Technology in Health (PATH); Avenir Health; Vysnova; Blue Raster; Kimetrica; and EnCompass.\n\nSince 1984, The Demographic and Health Surveys (DHS) Program has provided technical assistance to more than 300 demographic and health surveys in over 90 countries. DHS surveys collect information on fertility and total fertility rate (TFR), reproductive health, maternal health, child health, immunization and survival, HIV/AIDS; maternal mortality, child mortality, malaria, and nutrition among women and children stunted. The strategic objective of The DHS Program is to improve and institutionalize the collection and use of data by host countries for program monitoring and evaluation and for policy development decisions.\n\nThe DHS Program supports the following data collection options:\n\nThe DHS Program works to provide survey data for program managers, health care providers, policymakers, country leaders, researchers, members of the media, and others who can act to improve public health. The DHS Program distributes unrestricted survey data files for legitimate academic research at no cost.\n\nOnline databases include: STATcompiler, STATmapper, HIV/AIDS Survey Indicators Database, HIV Spatial Data Repository, HIVmapper, and Country QuickStats.\n\nThe DHS Program produces publications that provide country specific and comparative data on population, health, and nutrition in developing countries. Most publications are available online for download, but if an electronic version of the publication is not available, a hard copy may be available.\n\nThe DHS Program has been active in over 90 countries in Africa, Asia, Central Asia; West Asia; and Southeast Asia, Latin America and the Caribbean. A list of the publications for each country is available online at The DHS Program web site.\n\nSince 2001, The DHS Program has worked in over 15 countries in Africa, Asia and Latin America and Caribbean conducting population-based HIV testing. By collecting blood for HIV testing from representative samples of the population of men and women in a country, the DHS Program provides nationally representative estimates of HIV rates. The testing protocol provides for anonymous, informed, and voluntary testing of women and men.\n\nThe program also collects data on internationally recognized AIDS indicators. Currently, the main sources of HIV/AIDS indicators in the database are the Demographic and Health Surveys (DHS), the Multiple Indicator Cluster Surveys (MICS), the Reproductive Health Surveys (RHS), the Sexual Behavior Surveys (SBS), and Behavioral Surveillance Surveys (BSS). Eventually it will cover all countries for which indicators are available. The project also collects data on the capacity of health care facilities to deliver HIV prevention and treatment services.\n\nSince 2000, DHS (and some AIS) surveys have collected data on ownership and use of mosquito nets, treatment of fever in children, and intermittent preventive treatment of pregnant women. In recent years, additional questions on indoor residual spraying, and biomarker testing for anemia and malaria have been conducted.This has however not changed the trend in malaria infections thereby calling for more interventions by researchers and scientists.\n\nThe DHS Program researches and trains for integrating gender into population, health and nutrition programs and HIV/AIDS-related activities in the developing world.\n\nQuestions on gender roles and empowerment are integrated into most DHS questionnaires. For countries interested in more in-depth data on gender, modules of questions are available on specific topics such as status of women, domestic violence, and female genital mutilation.\n\nThe DHS Program has interviewed thousands of young people and gathered information about their education, employment, media exposure, nutrition, sexual activity, fertility, unions, and general reproductive health, including HIV prevalence. \nThe Youth Corner on the DHS website presents findings about youth and features profiles of young adults ages 15–24 from more than 30 countries worldwide. The Youth Corner is part of the broader effort by the Interagency Youth Working Group (IYWG) to help program managers, donors, national and local governments, teachers, religious leaders, and nongovernmental organizations (NGOs) plan and implement programs to improve the reproductive health of young adults.\n\nThe DHS Program now analyzes the impact of geographic location using DHS data and geographic information systems (GIS). The DHS Program routinely collects geographic information in all surveyed countries. Using GIS, researchers can link DHS data with routine health data, health facility locations, local infrastructure such as roads and rivers, and environmental conditions.\n\nUsing field-friendly technologies, the DHS Program is able to collect biomarker data relating to conditions and infections. DHS surveys have tested for anemia (by measuring hemoglobin), HIV infection, sexually transmitted diseases such as syphilis and the herpes simplex virus, serum retinol (Vitamin A), lead exposure, high blood pressure, and immunity from vaccine-preventable diseases like measles and tetanus. Traditionally, much of the data gathered in DHS surveys is self-reported. Biomarkers complement this information by providing an objective profile of a specific disease or health condition in a population. Biomarker data contributes to the understanding of behavioral risk factors and determinants of different illnesses.\n\n\n"}
{"id": "2312372", "url": "https://en.wikipedia.org/wiki?curid=2312372", "title": "Electropherogram", "text": "Electropherogram\n\nAn electropherogram (or electrophorogram) is a record or chart produced when electrophoresis is used in an analytical technique, primarily in the fields of molecular biology or biochemistry.\n\nIn the field of genetics, an electropherogram is a plot of DNA sequencing results generated by Sanger sequencing. Such plots are often achieved using an instrument such as an automated DNA sequencer. Such electropherograms may be used to determine DNA sequence genotypes, or genotypes that are based on the length of specific DNA fragments. These genotypes can be used for:\n\n\n\n"}
{"id": "13929163", "url": "https://en.wikipedia.org/wiki?curid=13929163", "title": "Forensic software engineering", "text": "Forensic software engineering\n\nForensic software engineering refers to the discipline of analyzing (and sometimes reconstructing) the functionality of software applications or services that have become defunct; are no longer accompanied by, or previously lacked, documentation; or for which the original engineers are no longer available.\n\nUsually, forensic software engineering is performed with an interest in understanding the functionality - and sometimes intent - of software that has been abandoned by its creators, with an eye to correcting unexpected outcomes or determining whether to port, rebuild, replace, or retire a functional software instance.\n\nIs often required as a result of a corporate mergers or acquisitions, or during the migration/transition from an old datacenter to a newer one.\n\n"}
{"id": "16269782", "url": "https://en.wikipedia.org/wiki?curid=16269782", "title": "Gnaural", "text": "Gnaural\n\nGnaural is brainwave entrainment software for Microsoft Windows, Mac OS X, and Linux licensed under the GNU General Public License. Gnaural is free software for creating binaural beats intended to be used as personal brainwave synchronization software, for scientific research, or by professionals. Gnaural allows for the creation of binaural beat tracks specifying different frequencies and exporting tracks into different audio formats. Gnaural runnings can also be linked over the internet, allowing synchronous sessions between many users.\n\n\n"}
{"id": "20761697", "url": "https://en.wikipedia.org/wiki?curid=20761697", "title": "Hydrocholeretic", "text": "Hydrocholeretic\n\nHydrocholeretics are substances that increase the volume of secretion of bile from the liver without increasing the amount of solids secreted. Some substances can result in decreased solid production, possibly due to circulatory effects.\n\n"}
{"id": "20634704", "url": "https://en.wikipedia.org/wiki?curid=20634704", "title": "IC 1517", "text": "IC 1517\n\nIC 1517 is an elliptical galaxy, of apparent magnitude +13.8, in the constellation Pisces. The galaxy is south and west of Gamma Piscium, just south of the ecliptic, and north of the constellation Aquarius. It has a redshift of 0.02449.\n\n"}
{"id": "38448296", "url": "https://en.wikipedia.org/wiki?curid=38448296", "title": "Index of physics articles (F)", "text": "Index of physics articles (F)\n\nThe index of physics articles is split into multiple pages due to its size.\n\nTo navigate by individual letter use the table of contents below.\n\n"}
{"id": "41139856", "url": "https://en.wikipedia.org/wiki?curid=41139856", "title": "Johann Michael Ekling", "text": "Johann Michael Ekling\n\nJohann Michael Ekling (also spelt Eckling) (8 August 1795, – 30 March 1876, Landstraße) was an Austrian mechanic and inventor of scientific apparatuses and instruments.\nJohann Michael Ekling was the posthumous son of the army surgeon Joseph Ekling. His mother was Anna Maria Eurosina Ekling née Stitzbarth. He was born in the suburb of (today a part of Margareten) in Vienna. At the age of 33 he married Theresia Schwarz with whom he had five sons and a daughter. In the years to follow he cooperated closely with mathematics and physics professors and Andreas von Ettingshausen of the University of Vienna. He produced artificial magnets on behalf of Baumgartner and one of the first photographic apparatuses in Austria (1839) following instructions by Ettingshausen, who had worked with Daguerre. By 1844 he is referred to as a \"university mechanic\". An announcement in a paper describes his range of products as follows: \"[Ekling] makes all sorts mathematical and physical instruments and apparatuses, air pumps with glass barrel chambers, travel barometers, goniometers, chemical and mineralogical apparatuses\". His multiplicator was used for the analysis of mineral waters among other things and praised for its sensitivity. Ekling was granted patents for induction machines, cameras and improvements to the Bain telegraph, which were taken over by the Austrian railway. Ekling’s last invention was a \"Galvanic Induction Machine for Medical Purposes\".\n\nHis reputation as a mechanic is documented in the Austrian Law Gazette for 1850: \"The most recommendable mechanic in Vienna, and as regards more sophisticated optical equipment, the only one to be recommended, is Eckling.\" Among these instruments we find the heliostat in the picture alongside. Young mechanics from Germany like Rudolph Carl Adolph Dolberg (1817-1863) and Adolph Hermann Friedrich Petri (1819-1895) were apprenticed to Ekling. Johann Leopolder, who later ran his own large Telegraph and Telephone Company was also one of his apprentices and later his foreman, until he started his own establishment in 1850.\nIn 1860 Ekling sold his premises at 25 Erdbergstrasse to his neighbour Rudolf Ditmar who owned a rapidly expanding kerosine lamp factory. He died a gentleman of independent means at Landstrasse/Vienna in 1876.\n\n\nInstruments and apparatuses made by Ekling are in various physics collections in Austria (Innsbruck, Kremsmünster Observatory For a list of acquisitions see: Linz and \nVienna, Czech Republic (Prague), Germany (Augsburg and Munich), Italy (Venice) and the USA (Kenyon College, OH).\n"}
{"id": "4901481", "url": "https://en.wikipedia.org/wiki?curid=4901481", "title": "Johannes Herman Frederik Umbgrove", "text": "Johannes Herman Frederik Umbgrove\n\nJohannes Herman Frederik Umbgrove (February 5, 1899 Hulsberg (Limburg) – June 14, 1954 Wassenaar), called in short Jan Umbgrove, was a Dutch geologist and Earth scientist.\n\nUmbgrove studied geology at Leiden University, he finished his studies in 1926. He then became employed as a paleontologist for the \"Dienst van de Mijnbouw in Nederlands Indië\" (Geological Survey of the Dutch East Indies), where he studied Tertiary foraminifera and corals. He also studied volcanoes, tectonics, coastal morphology and the bathymetry of the seas surrounding the Sunda Islands.\n\nFrom 1929 he went back to Leiden to become the assistant of his former teacher B.G. Escher. In 1930 he became professor in stratigraphy and paleontology at Delft University. His research was again multidiciplinary. He studied the paleogeography of the Dutch East Indies from the data acquired by the gravitational surveys of F.A. Vening Meinesz, the paleontology of corals and coral reefs, tectonics, the geology of the Netherlands and volcanology. Because of his broad field of interest he was one of the first to think of the Earth as one dynamic system, an idea on which he wrote his book \"the Pulse of the Earth\" in 1942. Another book on paleontology was published in 1943.\n\nWhen he turned seriously ill in 1952 he kept writing in his bed, until his death in 1954.\n\n"}
{"id": "29593689", "url": "https://en.wikipedia.org/wiki?curid=29593689", "title": "Kanesuke Hara", "text": "Kanesuke Hara\n\n"}
{"id": "1669387", "url": "https://en.wikipedia.org/wiki?curid=1669387", "title": "Laboratory experimentation in psychology", "text": "Laboratory experimentation in psychology\n\nPsychology has adapted the principles of positivist research to develop a wide range of laboratory-based approaches to research. Typically, such research seeks to test a hypothesis in controlled circumstances. In other words, all independent variables (causes) are controlled apart from a test variable to investigate the effect on a dependent variable (effect).\n\nIn the simplest model, two 'treatments' (independent variables) are compared: for example, subjects are exposed to two different sound stimuli such as tones of different frequencies, to compare the effects on heart rate (dependent variable). The heart rates observed are then analysed using inferential statistics such as the 't-test' which can evaluate whether the differences are due to chance or to the two treatments.\n\nPsychologists have explored many aspects of human and animal behaviour using this kind of approach. Advantages are that the effects of confounding variables are controlled, including the influence of observation on behaviour; disadvantages are associated with the lack of relationship to the 'real world'.\n"}
{"id": "49227605", "url": "https://en.wikipedia.org/wiki?curid=49227605", "title": "Laboratory for the Conservation of Endangered Species", "text": "Laboratory for the Conservation of Endangered Species\n\nLaCONES or Laboratory for the Conservation of Endangered Species, is a Council of Scientific and Industrial Research lab located in Hyderabad. It was conceptualised by Lalji Singh. It is India's only research facility engaged in conservation and preservation of wildlife and its resources. It was established in 1998 with the help of Central Zoo Authority of India, CSIR and the government of Andhra Pradesh. It was dedicated to the nation in 2007 by then President of India APJ Abdul Kalam.It is a part of ccmb (centre for cellular and molecular biology).India's 1st genetic bank for wilflife conservation nwgrb (national wildlife genetic resource bank) stablished by government in lacones\n"}
{"id": "22861963", "url": "https://en.wikipedia.org/wiki?curid=22861963", "title": "List of 20th-century earthquakes", "text": "List of 20th-century earthquakes\n\nThis list of 20th-century earthquakes is a global list of notable earthquakes that occurred in the 20th century. After 1900 most earthquakes have some degree of instrumental records and this means that the locations and magnitudes are more reliable than for earlier events. To prevent this list becoming unmanageable, only those of magnitude 6 and above are included unless they are notable for some other reason.\n\n"}
{"id": "1752944", "url": "https://en.wikipedia.org/wiki?curid=1752944", "title": "List of EN standards", "text": "List of EN standards\n\nStandards (abbreviated ENs owing to the more literal translation from French/German as European Norms) maintained by CEN (European Committee for Standardization), CENELEC (European Committee for Electrotechnical Standardization) and ETSI (European Telecommunications Standards Institute).\n\n\n\n\nThis range includes almost exclusively CEN Standards related to iron and steel.\n\n\n\n\n\n"}
{"id": "3270224", "url": "https://en.wikipedia.org/wiki?curid=3270224", "title": "List of SIP software", "text": "List of SIP software\n\nThis list of SIP software documents notable software applications which use Session Initiation Protocol (SIP) as a voice over IP (VoIP) protocol.\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "40812533", "url": "https://en.wikipedia.org/wiki?curid=40812533", "title": "List of failed and overbudget custom software projects", "text": "List of failed and overbudget custom software projects\n\nThis is a list of notable custom software projects which have significantly failed to achieve some or all of their objectives, either temporarily or permanently, and/or have suffered from significant cost overruns. For a list of \"successful\" major custom software projects, see Custom software#Major project successes.\n\nNote that failed projects, and projects running over budget, are not necessarily the sole fault of the employees or businesses creating the software. In some cases, problems may be due partly to problems with the purchasing organisation, including poor requirements, over-ambitious requirements, unnecessary requirements, poor contract drafting, poor contract management, poor end-user training, or poor operational management.\n\nBecause software, unlike a major civil engineering construction project, is often easy and cheap to change after it has been constructed, a piece of custom software that fails to deliver on its objectives may sometimes be modified over time in such a way that it later succeeds - and/or business processes or end-user mindsets may change to accommodate the software. However, sometimes, for various reasons, neither approach succeeds (or is even tried), and this may be considered as another level of failure - a \"permanent\" failure.\n\nUntil the significant problems with these projects are resolved, or the projects cancelled, it is not yet possible to classify them into one of the above categories.\n\n\n"}
{"id": "5971821", "url": "https://en.wikipedia.org/wiki?curid=5971821", "title": "List of mathematicians (O)", "text": "List of mathematicians (O)\n\n\n\n\n"}
{"id": "177652", "url": "https://en.wikipedia.org/wiki?curid=177652", "title": "List of psychological research methods", "text": "List of psychological research methods\n\nA wide range of research methods are used in psychology. These methods vary by the sources from which information is obtained, how that information is sampled, and the types of instruments that are used in data collection. Methods also vary by whether they collect qualitative data, quantitative data or both.\n\nQualitative psychological research is where the research findings are not arrived at by statistical or other quantitative procedures. Quantitative psychological research is where the research findings result from mathematical modeling and statistical estimation or statistical inference. Since qualitative information can be handled as such statistically, the distinction relates to method, rather than the topic studied.\n\nThere are three main types of psychological research:\n\n\nThe following are common research designs and data collection methods:\n\n\nResearch designs vary according to the period(s) of time over which data are collected:\n\n\nResearch in psychology has been conducted with both animals and human subjects:\n\n\n\n[[Category:Research]\nMKJGKM,]"}
{"id": "39502637", "url": "https://en.wikipedia.org/wiki?curid=39502637", "title": "List of things named after Siméon Denis Poisson", "text": "List of things named after Siméon Denis Poisson\n\nThese are things named after Siméon Denis Poisson (1781 – 1840), a French mathematician.\n\n\n\n\n\n\n\n\n\n"}
{"id": "34507261", "url": "https://en.wikipedia.org/wiki?curid=34507261", "title": "Lists of network protocols", "text": "Lists of network protocols\n\nThis is a list of articles that list different types or classifications of communication protocols used in computer networks.\n\n"}
{"id": "2416793", "url": "https://en.wikipedia.org/wiki?curid=2416793", "title": "M621 motorway", "text": "M621 motorway\n\nThe M621 is a short loop of motorway in England that takes traffic into central Leeds between the M1 and M62 motorways.\n\nThe first section of the M621 to open, known at the time as the 'South West Urban Motorway', extends from the M62 to Junction 3 in central Leeds where it used to terminate at a roundabout which was also the terminus of the M1 motorway. This section opened in stages, from the M62 to Junction 1 in 1971, and from Junction 1 to Junction 3 in 1973.\n\nWhen the M1 was diverted away from Leeds when the 'M1 – A1 Lofthouse to Bramham' extension opened in 1999 adjustments were made to Junction 3 and the Leeds section of the M1 was re-designated as M621 (Junctions 3–7).\n\n"}
{"id": "40440471", "url": "https://en.wikipedia.org/wiki?curid=40440471", "title": "Mouse Genetics Project", "text": "Mouse Genetics Project\n\nThe Mouse Genetics Project (MGP) is a large-scale mutant mouse production and phenotyping programme aimed at identifying new model organisms of disease.\n\nBased at the Wellcome Trust Sanger Institute, the project uses knockout mice most of which were generated by the International Knockout Mouse Consortium. For each mutant line, groups of seven male and seven female mice move through a standard analysis pipeline aimed at detecting traits that differ from healthy C57BL/6 mice. The pipeline collects many measurements of viability, fertility, body weight, infection, hearing, morphology, haematology, behaviour, blood chemistry and immunity and compares them to wild type controls using a statistical mixed model. These data are immediately shared among the scientific and medical research community through a bespoke open access database, and summaries are displayed in other online resources, including the Mouse Genome Informatics database and the Wikipedia-based Gene Wiki.\n\nAs of July 2013, the MGP reports having over 900 mutant lines openly available to the international research community, and have \"substantively complete\" analysis for over 650 mutant lines, of which over 75 per cent have at least one abnormal phenotype. Among these are new discoveries of genes implicated in disease, including finding: \n\n\n"}
{"id": "57816741", "url": "https://en.wikipedia.org/wiki?curid=57816741", "title": "Nina Papavasiliou", "text": "Nina Papavasiliou\n\nNina Papavasiliou is an immunologist and Helmholtz Professor in the Division of Immune Diversity at the German Cancer Research Center in Heidelberg, Germany. She is also an Adjunct Professor at the Rockefeller University, where she was previously Associate Professor and head of the Laboratory of Lymphocyte Biology. She is best known for her work in the fields of DNA and RNA editing.\n\nPapavasiliou received her Bachelors of Science from Oberlin College in biology in 1992. She then completed her PhD at the Rockefeller University in Michel C. Nussenzweig's Laboratory of Molecular Immunology. There, she began studying how B cell antigen receptors—or antibodies anchored to the cell membrane—undergo mutation so they can specifically recognize a particular antigen and elicit an immune response. She followed that interest to the Yale School of Medicine, where she worked as a postdoctoral fellow in the lab of David G. Schatz.\n\nPapavasiliou's research centers on demystifying how cells and organisms diversify and expand the information encoded in their genomes, both at the DNA and RNA level. She opened her Laboratory of Lymphocyte Biology at Rockefeller University in 2001 as an Assistant Professor. Much of her group's early work was done in the context of the adaptive immune response, which is able to combat a wide array of pathogens seeking to invade the host by rapidly generating novel antibodies that are able to specifically recognize a given invader. Her group has worked to characterize the activity of an enzyme known as activation-induced cytidine deaminase (AID). AID changes cytidine (C) residues to uracil (U) in DNA, which is recognized as DNA damage and repaired in such a way that introduces thymidine (T), effectively mutating Cs to Ts in DNA. The process is known as somatic hypermutation and is how B cells can rapidly introduce DNA mutations into receptors that recognize the invaders, known as antigens. Papavasiliou's lab has worked to understand how AID expression is regulated in the immune system and how AID targets certain genes for mutation.\n\nPapavasiliou also studies RNA editing in the context of the innate immune response using next-generation sequencing and bioinformatics approaches to identify and characterize RNA editing targets. Her group first identified novel RNA editing targets of APOBEC1, which mutates a cytosine to a uracil in an RNA transcript, and was previously thought to only edit Apolipoprotein B (apoB) in the small intestine. Her group has since moved on to attempt to characterize the potential role APOBEC1-editing may be playing outside of its function with apoB.\n\nPapavasiliou most recently branched out to studying mechanisms of antigenic variation—or how pathogens vary their surface proteins to escape the immune response—using Trypanosoma brucei, the parasite that causes African sleeping sickness, as a model organism. Her group has developed new tools to better understand the dynamics of protein coat switching in trypanosomes, and is working to better understand the mechanisms by which trypanosomes are able to diversify their coat proteins over the course of an infection.\n\nIn 2016, Papavasiliou moved to the German Cancer Research Center to begin her lab in the Division of Immune Diversity with additional support from a European Research Council Consolidator Grant.\n\n"}
{"id": "21612033", "url": "https://en.wikipedia.org/wiki?curid=21612033", "title": "Ola Hunderi", "text": "Ola Hunderi\n\nOla David Raa Hunderi (born 4 February 1939) is a Norwegian physicist.\n\nHe took the dr.philos. degree in 1970, and was appointed as professor at the Norwegian Institute of Technology in 1981. From 1987 to 1993 he was the research director at SINTEF.\n"}
{"id": "2260901", "url": "https://en.wikipedia.org/wiki?curid=2260901", "title": "Otto Hönigschmid", "text": "Otto Hönigschmid\n\nOtto Hönigschmid (13 March 1878 in Hořovice – 14 October 1945 in Munich) was a Czech/Austrian chemist. He won the Haitinger Prize of the Austrian Academy of Sciences in 1913.\n\nHönigschmid studied at the gymnasium in Olomouc, then at the Charles University in Prague under the guidance of Guido Goldschmiedt (the discoverer of the structure of papaverine).\n\nHönigschmid worked in Paris under Henri Moissan (1904–06) and at Harvard University under Theodore Richards. He was habilitated in 1908. After 1911 he was professor of inorganic and analytical chemistry at the Prague Polytechnic University, and after World War I at the University of Munich. He specialised in research on carbides, silicates and measurement of atomic mass.\n\nHe committed suicide shortly after his friend and colleague at the Munich University Hans Fischer.\n\n\n"}
{"id": "58440560", "url": "https://en.wikipedia.org/wiki?curid=58440560", "title": "Oukaïmeden Observatory", "text": "Oukaïmeden Observatory\n\nOukaïmeden Observatory is an astronomical observatory located in the Moroccan commune of Oukaïmden.\n\nLocated in the Atlas Mountains, 2750 meters above sea level, the TRAPPIST-North telescope is a twin telescope of TRAPPIST–South located at the La Silla Observatory in Chile.\n\nIn May 2016, data from the telescopes helped identify TRAPPIST-1.\n\n"}
{"id": "9953081", "url": "https://en.wikipedia.org/wiki?curid=9953081", "title": "Pizza Principle", "text": "Pizza Principle\n\nThe Pizza Principle, or the Pizza-Subway Connection, in New York City, is a humorous but generally historically accurate \"economic law\" proposed by native New Yorker Eric M. Bram. He noted, as reported by \"The New York Times\" in 1980, that from the early 1960s \"the price of a slice of pizza has matched, with uncanny precision, the cost of a New York subway ride.\"\n\nIn 1985, the late writer, historian, and film critic George Fasel learned of the correlation and wrote about it in an op-ed for \"The New York Times.\" The term \"Pizza Connection\" referring to this phenomenon was coined in 2002 by \"New York Times\" columnist Clyde Haberman, who commented on the two earlier publications of the theory in the \"Times,\" and predicted a rise in subway fare.\n\nIn May 2003, \"The New Yorker\" magazine proclaimed the validity of the Pizza Connection (now called the \"pizza principle\") in accurately predicting the rise of the subway (and bus) fare to $2.00 the week before. They also quoted Mr. Bram (by then a patent attorney) as warning that since the New York City Transit Authority had announced the discontinuation of the subway token itself in favor of the variable-fare cost MetroCard (also used on the buses at that point), the direct correlation between the cost of an off-the-street slice of cheese pizza and the cost of a subway token might not continue to hold.\n\nIn 2005, and again in 2007, Haberman noted the price of a slice was again rising, and, citing the Pizza Connection, worried that the subway/bus fare might soon rise again. The fare did indeed rise to $2.25 in June 2009, and again in 2013 to $2.50. In 2014 Jared Lander, a professional statistician and Adjunct Professor at Columbia University, conducted a study of pizza slice prices within New York City and concluded that the Pizza Principle still holds true. Other New York City news organizations occasionally confirm the ability of the Pizza Principle to predict increases in the cost of a single-ride subway/bus fare in the city.\n\n"}
{"id": "46655391", "url": "https://en.wikipedia.org/wiki?curid=46655391", "title": "Prism spectrometer", "text": "Prism spectrometer\n\nA prism spectrometer is an optical spectrometer which uses a dispersive prism as its dispersive element. The prism refracts light into its different colors (wavelengths). The dispersion occurs because the angle of refraction is dependent on the refractive index of the prism's material, which in turn is slightly dependent on the wavelength of light that is traveling through it.\n\nLight is emitted from a source such as a vapor lamp. A slit selects a thin strip of light which passes through the collimator where it gets parallelized. The aligned light then passes through the prism in which it is refracted twice (once when entering and once when leaving). Due to the nature of a dispersive element the angle with which light is refracted depends on its wavelength. This leads to a spectrum of thin lines of light, each being observable at a different angle.\n\nReplacing the prism with a diffraction grating would result in a grating spectrometer. Optical gratings are less expensive, provide much higher resolution, and are easier to calibrate, due to their linear diffraction dependency. A prism's refraction angle varies nonlinearly with wavelength. On the other hand, gratings have significant intensity losses.\n\nA prism spectrometer may be used to determine the composition of a material from its emitted spectral lines.\n\nA prism spectrometer may be used to measure the refractive index of a material if the wavelengths of the light used are known. The calibration of a prism spectrometer is carried out with known spectral lines from vapor lamps or laser light.\n\n"}
{"id": "6895400", "url": "https://en.wikipedia.org/wiki?curid=6895400", "title": "Raw data", "text": "Raw data\n\nRaw data, also known as primary data, is data (e.g., numbers, instrument readings, figures, etc.) collected from a source. If a scientist sets up a computerized thermometer which records the temperature of a chemical mixture in a test tube every minute, the list of temperature readings for every minute, as printed out on a spreadsheet or viewed on a computer screen is \"raw data\". Raw data has not been subjected to processing, \"cleaning\" by researchers to remove outliers, obvious instrument reading errors or data entry errors, or any analysis (e.g., determining central tendency aspects such as the average or median result). As well, raw data has not been subject to any other manipulation by a software program or a human researcher, analyst or technician. It is also referred to as \"primary\" data. Raw data is a relative term (see data), because even once raw data has been \"cleaned\" and processed by one team of researchers, another team may consider this processed data to be \"raw data\" for another stage of research. Raw data can be inputted to a computer program or used in manual procedures such as analyzing statistics from a survey. The term \"raw data\" can refer to the binary data on electronic storage devices, such as hard disk drives (also referred to as \"low-level data\").\n\nData has two ways of being created or generated. The first is what is called 'captured data', and is found through purposeful investigation or analysis. The second is called 'exhaust data', and is gathered usually by machines or terminals as a secondary function. For example, cash registers, smartphones, and speedometers serve a main function but may collect data as a secondary task. Exhaustive data is usually too large or of little use to process and becomes 'transient' or thrown away.\n\nIn computing, raw data may have the following attributes: it may possibly contain human, machine, or instrument errors, it may not be validated; it might be in different areen (colloquial) formats; uncoded or unformatted; or some entries might be \"suspect\" (e.g., outliers), requiring confirmation or citation. For example, a data input sheet might contain dates as raw data in many forms: \"31st January 1999\", \"31/01/1999\", \"31/1/99\", \"31 Jan\", or \"today\". Once captured, this raw data may be processed stored as a normalized format, perhaps a Julian date, to make it easier for computers and humans to interpret during later processing. Raw data (sometimes colloquially called \"sourcey\" data or \"eggy\" data, the latter a reference to the data being \"uncooked\", that is, \"unprocessed\", like a raw egg) are the data input to processing. A distinction is made between \"data\" and \"information\", to the effect that information is the \"end\" product of \"data\" processing. Raw data that has undergone processing are sometimes referred to as \"cooked\" data in a colloquial sense. Although raw data has the potential to be transformed into \"information,\" extraction, organization, analysis and formatting for presentation are required before raw data can be transformed into usable information.\n\nFor example, a point-of-sale terminal (POS terminal, a computerized cash register) in a busy supermarket collects huge volumes of raw data each day about customers' purchases. However, this list of grocery items and their prices and the time and date of purchase does not yield much information until it is processed. Once processed and analyzed by a software program or even by a researcher using a pen and paper and a calculator, this raw data may indicate the particular items that each customer buys, when they buy them, and at what price; as well, an analyst or manager could calculate the average total sales per customer or the average expenditure per day of the week by hour. This processed and analyzed data provides information for the manager, that the manager could then use to help her determine, for example, how many cashiers to hire and at what times. Such \"information\" could then become \"data\" for further processing, for example as part of a predictive marketing campaign. As a result of processing, raw data sometimes ends up being put in a database, which enables the raw data to become accessible for further processing and analysis in any number of different ways.\n\nTim Berners-Lee (inventor of the World Wide Web) argues that sharing raw data is important for society. Inspired by a post by Rufus Pollock of the Open Knowledge Foundation his call to action is \"Raw Data Now\", meaning that everyone should demand that governments and businesses share the data they collect as raw data. He points out that \"data drives a huge amount of what happens in our lives… because somebody takes the data and does something with it.\" To Berners-Lee, it is essentially from this sharing of raw data, that advances in science will emerge. Advocates of open data argue that once citizens and civil society organizations have access to data from businesses and governments, it will enable citizens and NGOs to do their \"own\" analysis of the data, which can empower people and civil society. For example, a government may claim that its policies are reducing the unemployment rate, but a poverty advocacy group may be able to have its staff econometricians do their own analysis of the raw data, which may lead this group to draw different conclusions about the data set.\n\n"}
{"id": "57696483", "url": "https://en.wikipedia.org/wiki?curid=57696483", "title": "Raychelle Burks", "text": "Raychelle Burks\n\nRaychelle Burks is an analytical chemist and Assistant Professor of Chemistry at St. Edward's University in Austin, Texas.\n\nBurks current research centers on developing low-cost colorimetric sensors for detecting chemicals of forensic interest including explosives and illicit drugs. To maximize portability in the field, her group focuses on transforming smart phones into detection devices. Her research interests lie in the applied science domain, which she believes is well-suited to capturing and holding students' attention because they are working to solve real world problems. She has spoken about her intersectional research approach to equipping students with the technical knowledge they need to work on these real world challenges with the United States Department of Defense Science, Technology, and Innovation Exchange.\n\nBurks is a popular science communicator, using pop culture as an anchor to explore chemistry. She appeared on the Science Channel's \"Outrageous Acts of Science\" and \"Reactions\", the video series for the American Chemical Society. She has appeared on \"Mother Jones\"' \"Inquiring Minds\" podcast to share how chemistry can save you from a zombie apocalypse and on \"The Story Collider\" podcast with a story from her time working in a crime lab. Her writing has been featured in \"Slate\", \"The Washington Post\", \"UNDARK\", and \"Chemistry World\".\n\nBurks is also an advocate for women and underrepresented groups in science, speaking from her experiences as a black woman in STEM. She founded the DIYSciZone at GeekGirlCon, bringing scientists and science educators together to give convention attendees hands-on experiences with science experiments.\n\nBurks earned her BS in Chemistry at Northern Iowa University, her MSc in Forensic Science at Nebraska Wesleyan University, and her PhD in Chemistry from the University of Nebraska - Lincoln, and was a Postdoctoral Research Associate at the Doane College.\n"}
{"id": "57231605", "url": "https://en.wikipedia.org/wiki?curid=57231605", "title": "ScotCen Social Research", "text": "ScotCen Social Research\n\nScotCen Social Research is the Scottish branch of the United Kingdom’s largest centre for independent social research, NatCen Social Research. \n\nBased in Edinburgh, ScotCen Social Research is a not-for-profit organisation. Employees include survey methodologists, data analysts and expert quantitative and qualitative researchers. It is commissioned by governments and charities to investigate public opinion about social issues. \n\nThe Centre is known for conducting fieldwork and reporting on studies including the annual Scottish Health Survey, the Scottish Social Attitudes survey, and the Growing Up in Scotland longitudinal study. \n\nThe research conducted covers:\n\n"}
{"id": "11026307", "url": "https://en.wikipedia.org/wiki?curid=11026307", "title": "Simulation theory of empathy", "text": "Simulation theory of empathy\n\nSimulation theory of empathy is a theory that holds that humans anticipate and make sense of the behavior of others by activating mental processes that, if carried into action, would produce similar behavior. This includes intentional behavior as well as the expression of emotions. The theory states that children use their own emotions to predict what others will do. Therefore, we project our own mental states onto others.\nSimulation theory is not primarily a theory \"of\" empathy, but rather a theory of how people understand others—that they do so \"by way of\" a kind of empathetic response. This theory uses more biological evidence than other theories of mind, such as the theory-theory.\n\nSimulation theory is based in philosophy of mind, a branch of philosophy that studies the nature of the mind and its relationship to the brain, especially the work of Alvin Goldman and Robert Gordon. The discovery of mirror neurons in macaque monkeys has provided a physiological mechanism for the common coding between perception and action (see Wolfgang Prinz) and the hypothesis of a similar mirror neuron system in the human brain.\nSince the discovery of the mirror neuron system, many studies have been carried out to examine the role of this system in action understanding, emotion and other social functions.\n\nMirror neurons are activated both when actions are executed and the actions are observed. This unique function of mirror neurons may explain how people recognize and understand the states of others; mirroring observed action in the brain as if they conducted the observed action.\n\nTwo sets of evidence suggest that mirror neurons in the monkey have a role in action understanding. First, the activation of mirror neurons requires biological effectors such as hand or mouth. Mirror neurons do not respond to the action with tools like pliers. Mirror neurons respond to neither the sight of an object alone nor an action without an object (intransitive action). Umilta and colleagues demonstrated that a subset of mirror neurons fired when final critical part of the action was not visible to the observer. The experimenter showed his hand moving toward a cube and grasping it, and later showed the same action without showing later part grasping the cube (placing the cube behind the occluder). Mirror neurons fired on both visible and invisible conditions. On the other hand, mirror neurons did not discharge when the observer knew that there was not a cube behind the occluder.\n\nSecond, responses of mirror neurons to same actions are different depending on context of the action. A single cell recording experiment with monkeys demonstrated the different level of activation of mouth mirror neurons when monkey observed mouth movement depending on context (ingestive actions such as sucking juice vs. communicative actions such as lip-smacking or tongue protrusions). An fMRI study also showed that mirror neurons respond to the action of grasping a cup differently depending on context (to drink a cup of coffee vs. to clean a table on which a cup was placed).\n\nOne criticism of mirror neurons is that since they show that same muscle groups is used for someone watching an action as someone completing an action, they only predict actions, not beliefs or desires. While someone acts a certain way, they may not believe that what they are doing is the right thing.\n\nShared neural representation for a motor behavior and its observation has been extended into the domains of feelings and emotions. Not only movements but also facial expressions activate the same brain regions that are activated by direct experiences. In an fMRI study, same brain regions on action representation found to be activated when people both imitated and observed emotional facial expressions such as happy, sad, angry, surprise, disgust, and afraid.\n\nObserving video clips that displayed facial expression of feeling disgust activated the neural networks typical of direct experience of disgust. Similar results have been found in the case of touch. Watching movies that someone touched legs or faces activated the somatosensory cortex for direct feeling of the touch. A similar mirror system exists in perceiving pain. When people see other people feel pain, people feel pain not only affectively, but also sensorially.\n\nThese results suggest that understanding other's feelings and emotions is driven not by cognitive deduction of what the stimuli means but by automatic activation of somatosensory neurons. A recent study on pupil size directly demonstrated emotion perception was automatic process modulated by mirror systems. When people saw sad faces, pupil sizes influenced viewers in perceiving and judging emotional states without explicit awareness of differences of pupil size. When pupil size was 180% of original size, people perceived a sad face as less negative and less intense than when pupil was smaller than or equal to original pupil size. This mechanism was correlated with brain regions that implicated in emotion process, the amygdala. Furthermore, viewers mimic the size of their own pupils to those of sad faces they watched. Considering that pupil size is beyond voluntary control, the change of pupil size upon emotion judgment is a good indication that understanding emotions is automatic process. However, the study could not find other emotional faces such as happiness and anger influence pupil size as sadness did.\n\nUnderstanding other's actions and emotions is believed to facilitate efficient human communication. Based on findings from neuroimaging studies, de Vignemont and Singer proposed empathy as a crucial factor in human communication arguing its epistemological role; \"Empathy might enable us to make faster and more accurate predictions of other people's needs and actions and discover salient aspects of our environment.\" Mental mirroring of actions and emotions may enable humans to understand other's actions and their related environment quickly, and thus help humans communicate efficiently.\n\nIn an fMRI study, a mirror system has been proposed as common neural substrates to mediate the experiences of basic emotions. Participants watched video clips of happy, sad, angry and disgust facial expressions, and measured their empathy quotient (EQ). Specific brain regions relevant to the four emotions were found to be correlated with the EQ while the mirror system (i.e., the left dorsal inferior frontal gyrus/premotor cortex) was correlated to the EQ across all emotions. The authors interpreted this result as an evidence that action perception mediates face perception to emotion perception.\n\nA paper published in Science (Singer et al., 2005) challenges the idea that pain sensations and mirror neurons play a role in empathy for pain. Specifically, the authors found that activity in the anterior insula and the anterior cingulate cortex was present both when one's self and another person were presented with a painful stimulus, two regions known to be responsible for the affective experience of pain, but the rest of the pain matrix, responsible for sensation, was not active. Furthermore, participants merely saw the hand of another person with the electrode on it, making it unlikely that 'mirroring' could have caused the empathic response. However, a number of other studies, using magnetoencephalography and functional MRI have since demonstrated that empathy for pain does involve the somatosensory cortex, which supports the simulation theory.\n\nSupport for anterior insula and anterior cingulate cortex being the neural substrates of empathy include Wicker et al., 2003 who report that their \"core finding is that the anterior insula is activated both during observation of disgusted facial expressions and during the emotion of disgust evoked by unpleasant odorants\" (p. 655).\n\nFurthermore, one study demonstrated that \"for actions, emotions, and sensations both animate and inanimate touch activates our inner representation of touch.\" They note, however that \"it is important at this point to clarify the fact that we do not believe that the activation we observe evolved in order to empathize with other objects or human beings\" (p. 343).\n\nThis model states that empathy activates only one interpersonal motivation: altruism. Theoretically, this model makes sense, because empathy is an other-focused emotion. There is an impressive history of research suggesting that empathy, when activated, causes people to act in ways to benefit the other, such as receiving electric shocks for the other. These findings have often been interpreted in terms of empathy causing increased altruistic motivation, which in turn causes helping behavior.\n"}
{"id": "11129423", "url": "https://en.wikipedia.org/wiki?curid=11129423", "title": "Social impact theory", "text": "Social impact theory\n\nSocial impact theory was created by Bibb Latané in 1981 and consists of four basic rules which consider how individuals can be \"sources or targets of social influence\". Social impact is the result of social forces including the strength of the source of impact, the immediacy of the event, and the number of sources exerting the impact. The more targets of impact that exist, the less impact each individual target has.\n\nAccording to psychologist Bibb Latané, social impact is defined as any influence on individual feelings, thoughts or behavior that is created from the real, implied or imagined presence or actions of others. The application of social impact varies from diffusion of responsibility to social loafing, stage fright or persuasive communication. In 1981, Latané developed the social impact theory using three key variables:\nWith these variables, Latané developed three laws through formulas — social forces, psychosocial, and multiplication/division of impact.\n\nThe social forces law states that i = f(S * I * N). Impact (i) is a function of the three variables multiplied and grows as each variable is increased. However, if a variable were to be 0 or significantly low, the overall impact would be affected.\n\nThe Psychosocial law states that the most significant difference in social impact will occur in the transition from 0 to 1 source and as the number of sources increases, this difference will become even eventually. The equation Latané uses for this law is\nformula_1 \nThat is, some power (t) of the number of people (N) multiplied by the scaling constant (s) determines social impact. Latané applied this theory to previous studies done on imitation and conformity as well as on embarrassment. Asch's study of conformity in college students contradicts the psychosocial law, showing that one or two sources of social impact make little difference. However, Gerard, Wilhelmy, and Conolley conducted a similar study on conformity sampling from high school students. High school students were deemed less likely to be resistant to conformity than college students, and thus may be more generalizable, in this regard, than Asch's study. Gerard, Wilhelmy, and Conolley's study supported the psychosocial law, showing that the first few confederates had the greatest impact on conformity. Latané applied his law to imitation as well, using Milgram's gawking experiment. In this experiment various numbers of confederates stood on a street corner in New York craning and gawking at the sky. The results showed that more confederates meant more gawkers, and the change became increasingly insignificant as more confederates were present. In a study Latané and Harkins conducted on stage fright and embarrassment, the results also followed the psychosocial law showing that more audience members meant greater anxiety and that the greatest difference existed between 0 and 1 audience members.\n\nThe third law of social impact states that the strength, immediacy, and number of targets play a role in social impact. That is, the more strength and immediacy and the greater number of targets in a social situation causes the social impact to be divided amongst all of the targets. The equation that represents this division is\nformula_2\nThis law relates to diffusion of responsibility, in which individuals feel less accountable as the number of people present increases. In emergency situations, the impact of the emergency is reduced when more people are present.\n\nThe social impact theory is both a generalizable and a specific theory. It uses one set of equations, which are applicable to many social situations. For example, the psychosocial law can be used to predict instances of conformity, imitation and embarrassment. Yet, it is also specific because the predictions that it makes are specific and can be applied to and observed in the world. The theory is falsifiable as well. It makes predictions through the use of equations; however, the equations may not be able to accurately predict the outcome of social situations. Social impact theory is also useful. It can be used to understand which social situations result in the greatest impact and which situations present exceptions to the rules.\nWhile Social Impact theory explores social situations and can help predict the outcomes of social situations, it also has some shortcomings and questions that are left unresolved. The rules guiding the theory depict people as recipients that passively accept social impact and do not take into account the social impact that people may actively seek out. The model is also static, and does not fully compensate for the dynamics involved in social interactions. The theory is relatively new and fails to address some pertinent issues. These issues include finding more accurate ways to measure social outcomes, understanding the \"t\" exponent in psychosocial law, taking susceptibility into account, understanding how short-term consequences can develop into chronic consequences, application to group interactions, understanding the model's nature (descriptive vs. explanatory, generalization vs. theory).\n\nThe social impact theory specifies the effects of social variables — strength, immediacy, and number of sources — but does not explain the nature of these influencing processes. There are various factors not considered by experimenters while implementing the theory. Concepts such as peripheral persuasion affect how communicators may be more credible to some individuals and untrustworthy to others. The variables are inconsistent from individual to individual, possibly associating strength with source credibility and attractiveness or immediacy with physical closeness. Therefore, in the application of the social impact theory, the idea of persuasiveness, the ability to induce someone with an opposing position to change, and supportiveness, the ability to help those who agree with someone's point of view to resist the influence of others, is introduced. Ultimately, an individual's likelihood of change and being influenced is a direct function of strength (persuasiveness), immediacy and the number of advocates and is a direct inverse function of strength (supportiveness), immediacy and number of target individuals.\n\nThe Dynamic Social Impact Theory was developed by Latané and his colleagues in 1996. This theory is considered an extension of the Social Impact Theory as it uses its basic principles, mainly that social influence is determined by the strength, immediacy, and number of sources present, to describe how majority and minority group members influence one another. As its name suggests, the Dynamic Social Impact Theory proposes that groups are complex systems that are constantly changing and are never static. Groups that are spatially distributed and interact repeatedly organize and reorganize themselves in four basic patterns: \"consolidation, clustering, correlation,\" and \"continuing diversity\". These patterns allow for group dynamics to operate and ideas to be diffused throughout the group.\n\n1. Consolidation – as individuals interact with each other, over time, their actions, attitudes, and opinions become uniform. In this manner, opinions held by the majority of the group spread to the minority, which then decreases in size.\n\n2. Clustering – individuals tend to interact with clusters of group members with similar opinions. Clusters are common when group members communicate more frequently with members in close proximity, and less frequently with members who are more distant. Minority group members are often shielded from majority influence due to clustering. Therefore, subgroups can emerge which may possess similar ideas to one another, but hold different beliefs than the majority population.\n\n3. Correlation – over time, individual group members` opinions on a variety of issues converge and correlate with each other; this is true even of issues that are not discussed by the group.\n\n4. Continuing Diversity – a degree of diversity can exist within a group if minority group members cluster together or minority members who communicate with majority members resist majority influence. However, if the majority is large or minority members are physically isolated from one another, this diversity drops.\n\nIn 1985 Mullen analyzed two of the factors that Latané associated with Social Impact theory. Mullen conducted a meta-analysis that examined the validity of the source strength and the source immediacy. The studies that were analyzed were sorted by the method of measurement used with the self-reported in one category and the behavior measurements in the other category. Mullen's results showed that the source strength and immediacy were only supported in cases in which tension was self-reported, and not when behavior was measured. He thus concluded that Latané's source strength and immediacy were weak and lacked consistency. Critics of Mullen's study, however, argue that perhaps not enough studies were available or included, which may have skewed his results and given him an inaccurate conclusion.\n\nA study conducted by Constantine Sedikides and Jeffrey M. Jackson took another look at the role of strength and within social impact theory. This study was conducted in a bird house at a zoo. In one scenario, an experimenter dressed as a bird keeper walked into the bird house and told visitors that leaning on the railing was prohibited. This was considered the high-strength scenario because of the authority that a zookeeper possesses within a zoo. The other scenario involved an experimenter dressed in ordinary clothes addressing the visitors with the same message. The results of the study showed that visitors responded better to the high-strength scenario, with fewer individuals leaning on the railing after the zookeeper had told them not to. The study also tested the effect that immediacy had on social impact. This was done by measuring the incidences of leaning on the rail both immediately after the message was delivered and at a later point in time. The results showed that immediacy played a role in determining social impact since there were fewer people leaning on the rails immediately after the message. The visitors in the bird house were studied as members of the group they came with to determine how number of targets would influence the targets' behavior. The group size ranged from 1 to 6 and the results showed that those in larger groups were less likely to comply with the experimenter's message than those in smaller groups. All of these findings support the parameters of Latané's Social Impact Theory.\n\nKipling D. Williams, and Karen B. Williams theorized that social impact would vary depending on the underlying motive of compliance. When compliance is simply a mechanism to induce the formation of a positive impression, stronger sources should produce a greater social impact. When it is an internal motive that induces compliance, the strength of the source shouldn't matter. Williams and Williams designed a study in which two persuasion methods were utilized, one that would evoke external motivation and one that would evoke internal motivation. Using these techniques, experimenters went from door to door using one of the techniques to attempt to collect money for a zoo. The foot-in-the-door technique was utilized to evoke the internal motive. In this technique, the experimenter would make an initial request that was relatively small, and gradually request larger and larger amounts. This is internally motivated because the target's self-perception is altered to feel more helpful after the original contribution. The door-in-the-face technique, on the other hand, involves the experimenter asking for a large amount first; and when the target declines, they ask for a much smaller amount as a concession. This technique draws on external motivation because the request for a concession makes one feel obliged to comply. The experiment was conducted with low-strength and high-strength experimenters. Those who were approached by higher-strength experimenters were more likely to contribute money. Using the different persuasion approaches did not produce statistically significant results; however, it did support Williams and Williams hypothesis that the strength of the experimenter would heighten the effects of the door-in-the-face technique, but have minimal effect on the foot-in-the-door technique\n\nThere have also been studies done to examine Latané's dynamic social impact theory. One study was conducted within three classrooms. Two of these classes were small and one of them was large. The experimenter would develop 10 moderate multiple choice questions, which were read aloud to the class one at a time. The students were then instructed to discuss each question as it was read aloud with their neighbors and come to a final answer at the end of the given time period. The results of this simple study were able to illustrate and support the effects of dynamic social impact theory. The answers were consolidated because many of those with a minority answer within their group would comply with the majority opinion, which reduced the diversity of the answers. There was also considerable clustering: those sitting near each other tended to have the same answers. Correlation was visible because answers that weren't originally apparently related, became connected for students within some of the groups. However, none of the answers were entirely eliminated, allowing for continuing diversity. Many of the groups had members that changed their answers from the wrong answer to the right answer; however, there were also students that changed their answer to the wrong one after the discussion.\n\nDue to social media's influence, there has been movement towards e-commerce. Researchers have since looked into the relationship between social media influence and visit and purchase intentions within individuals.\n\nMost recently, Rodrigo Perez-Vega, Kathryn Waite, and Kevin O'Gorman suggest that the theory is also relevant in the context of social media. Empirical research on this context has found support for the effects of numbers of sources (i.e. likes) in performance outcomes such as box office sales. Furthermore, Babajide Osatuyi and Katia Passerini operationalized strength, immediacy, and number using Social Network Analysis centrality measures, i.e., betweeness, closeness, and degree centralities to test two of the rules stipulated in Social Impact Theory. They compared the influence of using Twitter and discussion board in a learning management system (e.g., Moodle and Blackboard) on student performance, measured as final grade in a course. The results provide support for the first law, i.e., impact (grade) as a multiplicative resultant of strength, immediacy, and number of interactions among students. Additional interesting insights were observed in this study that educators ought to consider to maximize the integration of new social technologies into pedagogy.\n\n\n"}
{"id": "39647470", "url": "https://en.wikipedia.org/wiki?curid=39647470", "title": "The Edge of the Unknown", "text": "The Edge of the Unknown\n\nThe Edge of the Unknown: 101 Things You Don't Know about Science and No One Else Does Either is a popular science book written by American physicist James Trefil. Published in 1996, the 355-page work is Trefil's 10th publication.\n\nAccording to a review on the \"Publishers Weekly\" website, \"if readers overlook the fatuous subtitle; (the book provides) a competent and sometimes fascinating tour of the frontiers of scientific inquiry, such that the readers will appreciate being able to satisfy their curiosity about the likelihood of time travel, the causes of cancer and the future of computers with this user-friendly resource ...(readers) will come away sharing the author's respect and awe for achievements of those who scan the geometric surfaces of viruses and construct molecular remedies for deadly diseases, probe chaotic system of the earth's atmosphere and even try to save us from our genetically encoded craving for fat.\"\n\nAccording to Bruce Slutsky, \"the book's major shortcoming is that treatment of each issue is very cursory (only three-page summations) with no historical context or extended discussion on the philosophical consequences of scientific discoveries. Trefil also makes his readers feel disappointed by failing to provide bibliographies of references that consider these issues in more detail of questionable value to public libraries.\"\n"}
{"id": "23701752", "url": "https://en.wikipedia.org/wiki?curid=23701752", "title": "The Tragedy of the Moon", "text": "The Tragedy of the Moon\n\nThe Tragedy of the Moon is a collection of seventeen nonfiction science essays written by Isaac Asimov. It was the tenth of a series of books collecting essays from \"The Magazine of Fantasy and Science Fiction\", these being first published between March 1972 and July 1973. It was first published by Doubleday & Company in 1973.\n\n\n"}
{"id": "20446176", "url": "https://en.wikipedia.org/wiki?curid=20446176", "title": "Thomas Bourgeron", "text": "Thomas Bourgeron\n\nThomas Bourgeron is a French scientist working at the Institut Pasteur. The group he leads has discovered the first monogenic mutations involved in autism.\n"}
{"id": "42475956", "url": "https://en.wikipedia.org/wiki?curid=42475956", "title": "Vancouver classification", "text": "Vancouver classification\n\nThe Vancouver classification is a grading system used in orthopaedics to determine management of post-operative periprosthetic femoral fractures following a hip arthroplasty. It is named for the city Vancouver, home province of the University of British Columbia where the authors of the 1995 paper worked.\n\n"}
{"id": "50858083", "url": "https://en.wikipedia.org/wiki?curid=50858083", "title": "William M. Furnish", "text": "William M. Furnish\n\nWilliam Madison Furnish (born August 17, 1912, in Tipton, Iowa, died November 9, 2007) was an American paleontologist. He taught at the University of Iowa. \nIn 1938, he described the conodont genus \"Acanthodus\" from the Prairie du Chien (Lower Ordovician) beds of the upper Mississippi valley.\n\nIn 1964, with Carl B. Rexroad, he described the conodont genus \"Hindeodus\" from the Pella Formation (Mississippian) of South-Central Iowa.\n\nHe received the Pander Medal, awarded by the Pander Society, an informal organisation founded in 1967 for the promotion of the study of conodont palaeontology.\n\nThe conodont genus name \"Furnishina\" Müller 1959 is a tribute to WM Furnish.\n\n"}
{"id": "44472774", "url": "https://en.wikipedia.org/wiki?curid=44472774", "title": "Women Who Code", "text": "Women Who Code\n\nWomen Who Code is an international non-profit organization that provides services for women pursuing technology careers and a job board for companies seeking coding professionals. The company aims to provide an avenue into the technology world by evaluating and assisting women developing technical skills. In addition to training, professional evaluations, meetings, and scholarships, Women Who Code offers networking and mentorship. As of 2018, the organization has executed more than 8,000 free events around the world, built a membership of over 167,000, and has locations in 60 cities in over 20 countries.\n\nWomen Who Code was created in 2011. The non-profit was founded in November 2013 and is best known for its weekly publication the CODE Review, free technical study groups, hack nights, career development and leadership development, and speaking events featuring influential technology industry experts and investors. Since inception, WWCode has produced thousands of events worldwide and garnered sponsorship from organizations like Google, Zendesk, VMware, KPCB, Capital One, Nike, Yelp, and many others.\n\nWomen Who Code takes action in:\n\n• Providing free technical study groups (Ruby, Javascript, iOS, Android, Python, Algorithms)\n\n• Connecting our community with influential tech experts and investors\n\n• Offering career and leadership development\n\n• Increasing female speakers and judges at conferences and hackathons\n\n• Increasing participation in the tech community\n\n\n"}
{"id": "34043", "url": "https://en.wikipedia.org/wiki?curid=34043", "title": "Wormhole", "text": "Wormhole\n\nA wormhole (or Einstein–Rosen bridge) is a speculative structure linking disparate points in spacetime, and is based on a special solution of the Einstein field equations solved using a Jacobian matrix and determinant. A wormhole can be visualized as a tunnel with two ends, each at separate points in spacetime (i.e., different locations or different points of time). More precisely it is a transcendental bijection of the spacetime continuum, an asymptotic projection of the Calabi–Yau manifold manifesting itself in Anti-de Sitter space. \n\nWormholes are consistent with the general theory of relativity, but whether wormholes actually exist remains to be seen.\n\nA wormhole could connect extremely long distances such as a billion light years or more, short distances such as a few meters, different universes, or different points in time.\n\nFor a simplified notion of a wormhole, space can be visualized as a two-dimensional (2D) surface. In this case, a wormhole would appear as a hole in that surface, lead into a 3D tube (the inside surface of a cylinder), then re-emerge at another location on the 2D surface with a hole similar to the entrance. An actual wormhole would be analogous to this, but with the spatial dimensions raised by one. For example, instead of circular holes on a 2D plane, the entry and exit points could be visualized as spheres in 3D space.\n\nAnother way to imagine wormholes is to take a sheet of paper and draw two somewhat distant points on one side of the paper. The sheet of paper represents a plane in the spacetime continuum, and the two points represent a distance to be traveled, however theoretically a wormhole could connect these two points by folding that plane so the points are touching. In this way it would be much easier to traverse the distance since the two points are now touching.\nIn 1928, Hermann Weyl proposed a wormhole hypothesis of matter in connection with mass analysis of electromagnetic field energy; however, he did not use the term \"wormhole\" (he spoke of \"one-dimensional tubes\" instead).\n\nAmerican theoretical physicist John Archibald Wheeler (inspired by Weyl's work) coined the term \"wormhole\" in a 1957 paper co-authored by Charles Misner:\n\nWormholes have been defined both \"geometrically\" and \"topologically\". From a topological point of view, an intra-universe wormhole (a wormhole between two points in the same universe) is a compact region of spacetime whose boundary is topologically trivial, but whose interior is not simply connected. Formalizing this idea leads to definitions such as the following, taken from Matt Visser's \"Lorentzian Wormholes\" (1996).\n\nGeometrically, wormholes can be described as regions of spacetime that constrain the incremental deformation of closed surfaces. For example, in Enrico Rodrigo's \"The Physics of Stargates, \"a wormhole is defined informally as: \n\nThe equations of the theory of general relativity have valid solutions that contain wormholes. The first type of wormhole solution discovered was the \"Schwarzschild wormhole\", which would be present in the Schwarzschild metric describing an \"eternal black hole\", but it was found that it would collapse too quickly for anything to cross from one end to the other. Wormholes that could be crossed in both directions, known as traversable wormholes, would only be possible if exotic matter with negative energy density could be used to stabilize them.\n\nSchwarzschild wormholes, also known as \"Einstein–Rosen bridges\" (named after Albert Einstein and Nathan Rosen), are connections between areas of space that can be modeled as vacuum solutions to the Einstein field equations, and that are now understood to be intrinsic parts of the maximally extended version of the Schwarzschild metric describing an eternal black hole with no charge and no rotation. Here, \"maximally extended\" refers to the idea that the spacetime should not have any \"edges\": it should be possible to continue this path arbitrarily far into the particle's future or past for any possible trajectory of a free-falling particle (following a geodesic in the spacetime).\n\nIn order to satisfy this requirement, it turns out that in addition to the black hole interior region that particles enter when they fall through the event horizon from the outside, there must be a separate white hole interior region that allows us to extrapolate the trajectories of particles that an outside observer sees rising up \"away\" from the event horizon. And just as there are two separate interior regions of the maximally extended spacetime, there are also two separate exterior regions, sometimes called two different \"universes\", with the second universe allowing us to extrapolate some possible particle trajectories in the two interior regions. This means that the interior black hole region can contain a mix of particles that fell in from either universe (and thus an observer who fell in from one universe might be able to see light that fell in from the other one), and likewise particles from the interior white hole region can escape into either universe. All four regions can be seen in a spacetime diagram that uses Kruskal–Szekeres coordinates.\n\nIn this spacetime, it is possible to come up with coordinate systems such that if a hypersurface of constant time (a set of points that all have the same time coordinate, such that every point on the surface has a space-like separation, giving what is called a 'space-like surface') is picked and an \"embedding diagram\" drawn depicting the curvature of space at that time, the embedding diagram will look like a tube connecting the two exterior regions, known as an \"Einstein–Rosen bridge\". Note that the Schwarzschild metric describes an idealized black hole that exists eternally from the perspective of external observers; a more realistic black hole that forms at some particular time from a collapsing star would require a different metric. When the infalling stellar matter is added to a diagram of a black hole's history, it removes the part of the diagram corresponding to the white hole interior region, along with the part of the diagram corresponding to the other universe.\n\nThe Einstein–Rosen bridge was discovered by Ludwig Flamm in 1916, a few months after Schwarzschild published his solution, and was rediscovered by Albert Einstein and his colleague Nathan Rosen, who published their result in 1935. However, in 1962, John Archibald Wheeler and Robert W. Fuller published a paper showing that this type of wormhole is unstable if it connects two parts of the same universe, and that it will pinch off too quickly for light (or any particle moving slower than light) that falls in from one exterior region to make it to the other exterior region.\n\nAccording to general relativity, the gravitational collapse of a sufficiently compact mass forms a singular Schwarzschild black hole. In the Einstein–Cartan–Sciama–Kibble theory of gravity, however, it forms a regular Einstein–Rosen bridge. This theory extends general relativity by removing a constraint of the symmetry of the affine connection and regarding its antisymmetric part, the torsion tensor, as a dynamical variable. Torsion naturally accounts for the quantum-mechanical, intrinsic angular momentum (spin) of matter. The minimal coupling between torsion and Dirac spinors generates a repulsive spin–spin interaction that is significant in fermionic matter at extremely high densities. Such an interaction prevents the formation of a gravitational singularity. Instead, the collapsing matter reaches an enormous but finite density and rebounds, forming the other side of the bridge.\n\nAlthough Schwarzschild wormholes are not traversable in both directions, their existence inspired Kip Thorne to imagine traversable wormholes created by holding the \"throat\" of a Schwarzschild wormhole open with exotic matter (material that has negative mass/energy).\n\nOther non-traversable wormholes include \"Lorentzian wormholes\" (first proposed by John Archibald Wheeler in 1957), wormholes creating a spacetime foam in a general relativistic spacetime manifold depicted by a Lorentzian manifold, and \"Euclidean wormholes\" (named after Euclidean manifold, a structure of Riemannian manifold).\n\nThis Casimir effect shows that quantum field theory allows the energy density in certain regions of space to be negative relative to the ordinary matter vacuum energy, and it has been shown theoretically that quantum field theory allows states where energy can be \"arbitrarily\" negative at a given point. Many physicists, such as Stephen Hawking, Kip Thorne, and others, argue that such effects might make it possible to stabilize a traversable wormhole. Physicists have not found any natural process that would be predicted to form a wormhole naturally in the context of general relativity, although the quantum foam hypothesis is sometimes used to suggest that tiny wormholes might appear and disappear spontaneously at the Planck scale, and stable versions of such wormholes have been suggested as dark matter candidates. It has also been proposed that, if a tiny wormhole held open by a negative mass cosmic string had appeared around the time of the Big Bang, it could have been inflated to macroscopic size by cosmic inflation.\n\nLorentzian traversable wormholes would allow travel in both directions from one part of the universe to another part of that same universe very quickly or would allow travel from one universe to another. The possibility of traversable wormholes in general relativity was first demonstrated in a 1973 paper by Homer Ellis\nand independently in a 1973 paper by K. A. Bronnikov.\nEllis analyzed the topology and the geodesics of the Ellis drainhole, showing it to be geodesically complete, horizonless, singularity-free, and fully traversable in both directions. The drainhole is a solution manifold of Einstein's field equations for a vacuum space-time, modified by inclusion of a scalar field minimally coupled to the Ricci tensor with antiorthodox polarity (negative instead of positive). (Ellis specifically rejected referring to the scalar field as 'exotic' because of the antiorthodox coupling, finding arguments for doing so unpersuasive.) The solution depends on two parameters: formula_1, which fixes the strength of its gravitational field, and formula_2, which determines the curvature of its spatial cross sections. When formula_1 is set equal to 0, the drainhole's gravitational field vanishes. What is left is the Ellis wormhole, a nongravitating, purely geometric, traversable wormhole.\nKip Thorne and his graduate student Mike Morris, unaware of the 1973 papers by Ellis and Bronnikov, manufactured, and in 1988 published, a duplicate of the Ellis wormhole for use as a tool for teaching general relativity. For this reason, the type of traversable wormhole they proposed, held open by a spherical shell of exotic matter, was from 1988 to 2015 referred to in the literature as a \"Morris–Thorne wormhole\". Later, other types of traversable wormholes were discovered as allowable solutions to the equations of general relativity, including a variety analyzed in a 1989 paper by Matt Visser, in which a path through the wormhole can be made where the traversing path does not pass through a region of exotic matter. However, in the pure Gauss–Bonnet gravity (a modification to general relativity involving extra spatial dimensions which is sometimes studied in the context of brane cosmology) exotic matter is not needed in order for wormholes to exist—they can exist even with no matter. A type held open by negative mass cosmic strings was put forth by Visser in collaboration with Cramer \"et al.\", in which it was proposed that such wormholes could have been naturally created in the early universe.\n\nWormholes connect two points in spacetime, which means that they would in principle allow travel in time, as well as in space. In 1988, Morris, Thorne and Yurtsever worked out how to convert a wormhole traversing space into one traversing time by accelerating one of its two mouths. However, according to general relativity, it would not be possible to use a wormhole to travel back to a time earlier than when the wormhole was first converted into a time 'machine'. Until this time it could not have been noticed or have been used.\n\nTo see why exotic matter is required, consider an incoming light front traveling along geodesics, which then crosses the wormhole and re-expands on the other side. The expansion goes from negative to positive. As the wormhole neck is of finite size, we would not expect caustics to develop, at least within the vicinity of the neck. According to the optical Raychaudhuri's theorem, this requires a violation of the averaged null energy condition. Quantum effects such as the Casimir effect cannot violate the averaged null energy condition in any neighborhood of space with zero curvature, but calculations in semiclassical gravity suggest that quantum effects may be able to violate this condition in curved spacetime. Although it was hoped recently that quantum effects could not violate an achronal version of the averaged null energy condition, violations have nevertheless been found, so it remains an open possibility that quantum effects might be used to support a wormhole.\n\nIn some hypotheses where general relativity is modified, it is possible to have a wormhole that does not collapse without having to resort to exotic matter. For example, this is possible with R^2 gravity, a form of f(R) gravity.\n\nThe impossibility of faster-than-light relative speed only applies locally. Wormholes might allow effective superluminal (faster-than-light) travel by ensuring that the speed of light is not exceeded locally at any time. While traveling through a wormhole, subluminal (slower-than-light) speeds are used. If two points are connected by a wormhole whose length is shorter than the distance between them \"outside\" the wormhole, the time taken to traverse it could be less than the time it would take a light beam to make the journey if it took a path through the space \"outside\" the wormhole. However, a light beam traveling through the same wormhole would of course beat the traveler.\n\nIf traversable wormholes exist, they could allow time travel. A proposed time-travel machine using a traversable wormhole would hypothetically work in the following way: One end of the wormhole is accelerated to some significant fraction of the speed of light, perhaps with some advanced propulsion system, and then brought back to the point of origin. Alternatively, another way is to take one entrance of the wormhole and move it to within the gravitational field of an object that has higher gravity than the other entrance, and then return it to a position near the other entrance. For both of these methods, time dilation causes the end of the wormhole that has been moved to have aged less, or become \"younger\", than the stationary end as seen by an external observer; however, time connects differently \"through\" the wormhole than \"outside\" it, so that synchronized clocks at either end of the wormhole will always remain synchronized as seen by an observer passing through the wormhole, no matter how the two ends move around. This means that an observer entering the \"younger\" end would exit the \"older\" end at a time when it was the same age as the \"younger\" end, effectively going back in time as seen by an observer from the outside. One significant limitation of such a time machine is that it is only possible to go as far back in time as the initial creation of the machine; It is more of a path through time rather than it is a device that itself moves through time, and it would not allow the technology itself to be moved backward in time.\n\nAccording to current theories on the nature of wormholes, construction of a traversable wormhole would require the existence of a substance with negative energy, often referred to as \"exotic matter\". More technically, the wormhole spacetime requires a distribution of energy that violates various energy conditions, such as the null energy condition along with the weak, strong, and dominant energy conditions. However, it is known that quantum effects can lead to small measurable violations of the null energy condition, and many physicists believe that the required negative energy may actually be possible due to the Casimir effect in quantum physics. Although early calculations suggested a very large amount of negative energy would be required, later calculations showed that the amount of negative energy can be made arbitrarily small.\n\nIn 1993, Matt Visser argued that the two mouths of a wormhole with such an induced clock difference could not be brought together without inducing quantum field and gravitational effects that would either make the wormhole collapse or the two mouths repel each other, or otherwise prevent information from passing through the wormhole. Because of this, the two mouths could not be brought close enough for causality violation to take place. However, in a 1997 paper, Visser hypothesized that a complex \"Roman ring\" (named after Tom Roman) configuration of an N number of wormholes arranged in a symmetric polygon could still act as a time machine, although he concludes that this is more likely a flaw in classical quantum gravity theory rather than proof that causality violation is possible.\n\nA possible resolution to the paradoxes resulting from wormhole-enabled time travel rests on the many-worlds interpretation of quantum mechanics.\n\nIn 1991 David Deutsch showed that quantum theory is fully consistent (in the sense that the so-called density matrix can be made free of discontinuities) in spacetimes with closed timelike curves. However, later it was shown that such model of closed timelike curve can have internal inconsistencies as it will lead to strange phenomena like distinguishing non-orthogonal quantum states and distinguishing proper and improper mixture. Accordingly, the destructive positive feedback loop of virtual particles circulating through a wormhole time machine, a result indicated by semi-classical calculations, is averted. A particle returning from the future does not return to its universe of origination but to a parallel universe. This suggests that a wormhole time machine with an exceedingly short time jump is a theoretical bridge between contemporaneous parallel universes.\n\nBecause a wormhole time-machine introduces a type of nonlinearity into quantum theory, this sort of communication between parallel universes is consistent with Joseph Polchinski's proposal of an Everett phone (named after Hugh Everett) in Steven Weinberg's formulation of nonlinear quantum mechanics.\n\nThe possibility of communication between parallel universes has been dubbed interuniversal travel.\n\nTheories of \"wormhole metrics\" describe the spacetime geometry of a wormhole and serve as theoretical models for time travel. An example of a (traversable) wormhole metric is the following:\n\nfirst presented by Ellis (see Ellis wormhole) as a special case of the Ellis drainhole.\n\nOne type of non-traversable wormhole metric is the Schwarzschild solution (see the first diagram):\n\nThe original Einstein–Rosen bridge was described in an article published in July 1935.\n\nFor the Schwarzschild spherically symmetric static solution \n\nIf one replaces formula_9 with formula_10 according to\nformula_11\n\nFor the combined field, gravity and electricity, Einstein and Rosen derived the following Schwarzschild static spherically symmetric solution\n\nThe field equations without denominators in the case when formula_1 = 0 can be written\n\nIn order to eliminate singularities, if one replaces formula_9 by formula_10 according to the equation:\n\nand with formula_1 = 0 one obtains\n\nWormholes are a common element in science fiction because they allow interstellar, intergalactic, and sometimes even interuniversal travel within human lifetime scales. In fiction, wormholes have also served as a method for time travel.\n\n\n"}
