{"id": "18047542", "url": "https://en.wikipedia.org/wiki?curid=18047542", "title": "Alexander Salomonovich", "text": "Alexander Salomonovich\n\nAlexander Yefimovich Salomonovich (; 1916-1989) was a Russian radio astronomer. He graduated from the Physical Faculty of Moscow State University in 1939.\n\nDuring 1953-1959, he was chief scientist responsible for creation of the Lebedev \"RT-22\" 22 meter precision radio telescope and until 1964 he was the chief scientist for operations with this instrument.\n\n\n"}
{"id": "21743687", "url": "https://en.wikipedia.org/wiki?curid=21743687", "title": "Back-reaction", "text": "Back-reaction\n\nIn theoretical physics, back-reaction (or backreaction) is often necessary to calculate the self-consistent behaviour of a particle or an object in an external field.\n\nWhen a particle is considered to have no mass or to have an infinitesimal charge, this can be described as saying that we deal with a probe and that back-reaction is neglected. However, a real object also carries (in general) a mass and a charge itself. These properties imply that the model of the original environment needs to be modified to reach self-consistency. For example, a particle can be described as helping to curve the space in general relativity. Taking into account the constraints implied on the model by the particle's properties – the back-reaction – is one way of reaching a more accurate model than if those constraints are ignored.\n\nIn inhomogeneous cosmology, in which structure formation is taken into account in a general-relativistic model of the Universe, the term \"backreaction\" is used for a measure of the non-commutativity of the averaging procedure\n(which comes from the non-linearity of Einstein field equations) and the dynamical evolution of spatial slices of space-time.\n, the role of backreaction in possibly leading to an alternative to dark energy is an open question of debate among cosmologists. The existence of a homogeneity length scale can be considered to be that at which the calculations with and without backreaction give the same results. , the existence of such a scale needs experimental confirmation.\n"}
{"id": "657224", "url": "https://en.wikipedia.org/wiki?curid=657224", "title": "Bedrock", "text": "Bedrock\n\nIn geology, bedrock is the lithified rock that lies under a loose softer material called regolith at the surface of the Earth or other terrestrial planets. The broken and weathered regolith includes soil and subsoil. The surface of the bedrock beneath the soil cover is known as rockhead in engineering geology, and its identification by digging, drilling or geophysical methods is an important task in most civil engineering projects. Superficial deposits (also known as drift) can be extremely thick, such that the bedrock lies hundreds of meters below the surface.\n\nBedrock may also experience subsurface weathering at its upper boundary, forming saprolite.\n\nA solid geologic map of an area will usually show the distribution of differing bedrock types, rock that would be exposed at the surface if all soil or other superficial deposits were removed.\n\nSoil scientists use the capital letters O, A, B, C, and E to identify the master soil horizons. Hard bedrock, which is not soil, uses the letter R.\n"}
{"id": "65891", "url": "https://en.wikipedia.org/wiki?curid=65891", "title": "Boyle's law", "text": "Boyle's law\n\nBoyle's law (sometimes referred to as the Boyle–Mariotte law, or Mariotte's law) is an experimental gas law that describes how the pressure of a gas tends to increase as the volume of the container decreases. A modern statement of Boyle's law is\n\nThe absolute pressure exerted by a given mass of an ideal gas is inversely proportional to the volume it occupies if the temperature and amount of gas remain unchanged within a closed system.\n\nMathematically, Boyle's law can be stated as\n\nor\nwhere \"P\" is the pressure of the gas, \"V\" is the volume of the gas, and \"k\" is a constant.\n\nThe equation states that the product of pressure and volume is a constant for a given mass of confined gas and this holds as long as the temperature is constant. For comparing the same substance under two different sets of conditions, the law can be usefully expressed as\n\nThe equation shows that, as volume increases, the pressure of the gas decreases in proportion. Similarly, as volume decreases, the pressure of the gas increases. The law was named after chemist and physicist Robert Boyle, who published the original law in 1662.\n\nThis relationship between pressure and volume was first noted by Richard Towneley and Henry Power in the seventeenth century. Robert Boyle confirmed their discovery through experiments and published the results. According to Robert Gunther and other authorities, it was Boyle's assistant, Robert Hooke, who built the experimental apparatus. Boyle's law is based on experiments with air, which he considered to be a fluid of particles at rest in between small invisible springs. At that time, air was still seen as one of the four elements, but Boyle disagreed. Boyle's interest was probably to understand air as an essential element of life; for example, he published works on the growth of plants without air. Boyle used a closed J-shaped tube and after pouring mercury from one side he forced the air on the other side to contract under the pressure of mercury. After repeating the experiment several times and using different amounts of mercury he found that under controlled conditions, the pressure of a gas is inversely proportional to the volume occupied by it. The French physicist Edme Mariotte (1620–1684) discovered the same law independent of Boyle in 1679, but Boyle had already published it in 1662. Mariotte did, however, discover that air volume changes with temperature. Thus this law is sometimes referred to as Mariotte's law or the Boyle–Mariotte law. Later, in 1687 in the \"Philosophiæ Naturalis Principia Mathematica\", Newton showed mathematically that if an elastic fluid consisting of particles at rest, between which are repulsive forces inversely proportional to their distance, the density would be directly proportional to the pressure, but this mathematical treatise is not the physical explanation for the observed relationship. Instead of a static theory a kinetic theory is needed, which was provided two centuries later by Maxwell and Boltzmann.\n\nThis law was the first physical law to be expressed in the form of an equation describing the dependence of two variable quantities.\n\nThe law itself can be stated as follows:\nOr Boyle's law is a gas law, stating that the pressure and volume of a gas have an inverse relationship, when temperature is held constant. If volume increases, then pressure decreases and vice versa, when temperature is held constant.\n\nTherefore, when the volume is halved, the pressure is doubled; and if the volume is doubled, the pressure is halved.\n\nBoyle's law states that \"at constant temperature\" the volume of a given mass of a dry gas is inversely proportional to its pressure.\n\nMost gases behave like ideal gases at moderate pressures and temperatures. The technology of the 17th century could not produce high pressures or low temperatures. Hence, the law was not likely to have deviations at the time of publication. As improvements in technology permitted higher pressures and lower temperatures, deviations from the ideal gas behavior became noticeable, and the relationship between pressure and volume can only be accurately described employing real gas theory. The deviation is expressed as the compressibility factor.\n\nBoyle (and Mariotte) derived the law solely on experimental grounds. The law can also be derived theoretically based on the presumed existence of atoms and molecules and assumptions about motion and perfectly elastic collisions (see kinetic theory of gases). These assumptions were met with enormous resistance in the positivist scientific community at the time however, as they were seen as purely theoretical constructs for which there was not the slightest observational evidence.\n\nDaniel Bernoulli in 1737-1738 derived Boyle's law using Newton's laws of motion with application on a molecular level. It remained ignored until around 1845, when John Waterston published a paper building the main precepts of kinetic theory; this was rejected by the Royal Society of England. Later works of James Prescott Joule, Rudolf Clausius and in particular Ludwig Boltzmann firmly established the kinetic theory of gases and brought attention to both the theories of Bernoulli and Waterston.\n\nThe debate between proponents of Energetics and Atomism led Boltzmann to write a book in 1898, which endured criticism up to his suicide in 1906. Albert Einstein in 1905 showed how kinetic theory applies to the Brownian motion of a fluid-suspended particle, which was confirmed in 1908 by Jean Perrin.\n\nThe mathematical equation for Boyle's law is:\n\nwhere:\n\nSo long as temperature remains constant the same amount of energy given to the system persists throughout its operation and therefore, theoretically, the value of \"k\" will remain constant. However, due to the derivation of pressure as perpendicular applied force and the probabilistic likelihood of collisions with other particles through collision theory, the application of force to a surface may not be infinitely constant for such values of \"v\", but will have a limit when differentiating such values over a given time. Forcing the volume \"V\" of the fixed quantity of gas to increase, keeping the gas at the initially measured temperature, the pressure \"p\" must decrease proportionally. Conversely, reducing the volume of the gas increases the pressure. Boyle's law is used to predict the result of introducing a change, in volume and pressure only, to the initial state of a fixed quantity of gas.\n\nThe initial and final volumes and pressures of the fixed amount of gas, where the initial and final temperatures are the same (heating or cooling will be required to meet this condition), are related by the equation:\n\nHere \"P\" and \"V\" represent the original pressure and volume, respectively, and \"P\" and \"V\" represent the second pressure and volume.\n\nBoyle's law, Charles's law, and Gay-Lussac's law form the combined gas law. The three gas laws in combination with Avogadro's law can be generalized by the ideal gas law.\n\nBoyle's law is often used as part of an explanation on how the breathing system works in the human body. This commonly involves explaining how the lung volume may be increased or decreased and thereby cause a relatively lower or higher air pressure within them (in keeping with Boyle's law). This forms a pressure difference between the air inside the lungs and the environmental air pressure, which in turn precipitates either inhalation or exhalation as air moves from high to low pressure.\n\nRelated phenomena:\n\nOther gas laws:\n\n"}
{"id": "2963313", "url": "https://en.wikipedia.org/wiki?curid=2963313", "title": "Chartered Chemist", "text": "Chartered Chemist\n\nChartered Chemist (CChem) is a chartered status awarded by the Royal Society of Chemistry (RSC) in the United Kingdom, the Royal Australian Chemical Institute (RACI) in Australia, by the Ministry of Education in Italy, and the Institute of Chemistry Ceylon (IChemC), Sri Lanka.\n\nAchieving chartered status in any profession denotes to the wider community a high level of specialised subject knowledge and professional competence. The award of the Chartered Chemist (CChem) designation recognises the experienced practising chemist who has demonstrated an in-depth knowledge of chemistry, significant personal achievements based upon chemistry, professionalism in the workplace and a commitment to maintaining technical expertise through continuing professional development.\n\nIn the United Kingdom, CChem candidates must meet the following requirements:\n\n\nThe 12 professional attributes for Chartered Chemist in the UK are divided into five sections. The full list of attributes is: \nA. Demonstrate and develop your knowledge and experience of chemistry as well as analytical and scientific skills.\nB. Exercise autonomy and professionalism in the workplace.\nC. Communicate effectively and demonstrate influence in your role.\nD. Demonstrate an involvement in Environmental, Health and Safety matters and adhere to the relevant requirements relating to your role.\n\nE. Demonstrate an interest in broader developments in chemical science\nand make a contribution to the profession outside your usual job remit.\n\nIn Australia, Chartered Membership (MRACI CChem) is for:\n\nIn Sri Lanka, every candidate for the award of the status of Chartered Chemist (C.Chem.) shall \nAND \nOR \n(b) have obtained a Special Degree with Chemistry as the principal subject from a recognized university. \nOR \n(c) have obtained a bachelor's degree from a recognized university with an adequate coverage of Chemistry, acceptable to the Council and at least a master's degree in a branch of Chemistry from a recognized university. \nOR\n(d) have obtained a bachelor's degree from a recognized university, with an adequate coverage of Chemistry and has had sufficient experience and/or attainments in the Chemical Sciences for the period of at least 10 years acceptable to the Council. \nOR\n(f) have obtained any other equivalent qualifications acceptable to the Council,\n\nAND\nOR (b) have an equivalent attainment acceptable to the Council.\n\nAND\nAND\n(a) has specialist chemical skills relevant to their practice \n(b) has in– depth knowledge of the specialist areas of chemistry\n(c) has responsibilities based upon chemistry and has made a significant personal contribution.\n(d) demonstrates professionalism in the workplace\n(e) has maintained chemical expertise through continuing professional development.\n\n\n"}
{"id": "18400581", "url": "https://en.wikipedia.org/wiki?curid=18400581", "title": "Chelating resin", "text": "Chelating resin\n\nChelating resins are a class of ion exchange resins. They are almost always used to bind cations. They utilize chelating agents covalently attached to a polymer matrix. Chelating resins have the same bead form and polymer matrix as usual ion exchangers. Their main use is for preconcentration of metal ions in a dilute solution.\n\nChelating resins operate similarly to ordinary ion exchange resins.\nMost chelating resins are polymers (copolymers to be precise) with reactive functional groups that chelate to metal ions. The variation in chelating resins arises from the nature of the chelating agents pendant from the polymer backbone. Dowex chelating resin A-1, also known as Chelex 100, is based on iminodiacetic acid in a styrene-divinylbenzene matrix. Dowex A-1 is available commercially and is widely used to determine general properties of chelating resins such as rate determining step and pH dependence, etc. Dowex A-1 is produced from chloromethylated styrene-divinylbenzene copolymer via amination with aminodiacetic acid.\n\nPoly metal chelating resin has almost negligible affinity to both alkali and alkaline earth metals; small quantities of resin can be utilized to concentrate trace metals in natural water systems or biological fluids, in which there are three or four orders of magnitude greater alkali and alkaline earth metal concentration than the trace metal concentrations.\n\nOther functional groups bound to chelating resins are aminophosphonic acids, thiourea, and 2-picolylamine.\n\nSoil contaminated with heavy metals including radionuclides is mitigated primarily using chelating resins.\n\n"}
{"id": "6422341", "url": "https://en.wikipedia.org/wiki?curid=6422341", "title": "Chief creative officer", "text": "Chief creative officer\n\nA chief creative officer (CCO) is the highest ranking position of the creative team within a company. Depending on the type of company, this position may be responsible for the overall look and feel of marketing, media, and branding associated with the organization. The CCO may also be charged with managing, developing, and leading the team of creative directors, art directors, designers, and copywriters.\n\nThe CCO directs a company's creative output, developing the artistic design strategy that defines the company's brand. The CCO creates the unique image of the firm and deliver this distinctive design to consumers and to create a clear brand image which is a fundamental and essential work throughout the company. Advertisements present a certain memorable artistic design while also structured to accomplish functional goals. The CCO ensures that the design and functionality combine harmoniously so the firm can present a product that successfully represents its creative brand.\n\nCCOs, in some cases are called creative directors, are demanded in firms which involve creative thinking and artistic design. The position of generic head of marketing is usually replaced by chief creative officer in advertising firms. The power of chief creative officer can even be compared to CEO and at the early stages of a small company, usually at the start of partnerships, the CCO and the CEO manage jointly.\n\n"}
{"id": "8061879", "url": "https://en.wikipedia.org/wiki?curid=8061879", "title": "Colleter (botany)", "text": "Colleter (botany)\n\nColleters are plant structures, multicellular secretory hairs, found in groups near the base of petioles, on stipules, and on sepals. They are found in members of the Loganiaceae and Rubiaceae families.\n"}
{"id": "29824007", "url": "https://en.wikipedia.org/wiki?curid=29824007", "title": "Darwin Core Archive", "text": "Darwin Core Archive\n\nDarwin Core Archive (DwC-A) is a biodiversity informatics data standard that makes use of the Darwin Core terms to produce a single, self-contained dataset for species occurrence, checklist, sampling event or material sample data. Essentially it is a set of text (CSV) files with a simple descriptor (meta.xml) to inform others how your files are organized. The format is defined in the Darwin Core Text Guidelines. It is the preferred format for publishing data to the GBIF network. \n\nThe Darwin Core standard has been used to mobilize the vast majority of specimen occurrence and observational records within the GBIF network. The Darwin Core standard was originally conceived to facilitate the discovery, retrieval, and integration of information about modern biological specimens, their spatio-temporal occurrence, and their supporting evidence housed in collections (physical or digital).\n\nThe Darwin Core today is broader in scope. It aims to provide a stable, standard reference for sharing information on biological diversity. As a glossary of terms, the Darwin Core provides stable semantic definitions with the goal of being maximally reusable in a variety of contexts. This means that Darwin Core may still be used in the same way it has historically been used, but may also serve as the basis for building more complex exchange formats, while still ensuring interoperability through a common set of terms.\n\nThe central idea of an archive is that its data files are logically arranged in a star-like manner, with one core data file surrounded by any number of ’extensions’. Each extension record (or ‘extension file row’) points to a record in the core file; in this way, many extension records can exist for each single core record.\n\nDetails about recommended extensions can be found in their respective subsections and will be extensively documented in the GBIF registry, which will catalogue all available extensions.\n\nSharing entire datasets instead of using pageable web services like DiGIR and TAPIR allows much simpler and more efficient data transfer. For example, retrieving 260,000 records via TAPIR takes about nine hours, issuing 1,300 http requests to transfer 500 MB of XML-formatted data. The exact same dataset, encoded as DwC-A and zipped, becomes a 3 MB file. Therefore, GBIF highly recommends compressing an archive using ZIP or GZIP when generating a DwC-A. \n\nAn archive requires stable identifiers for core records, but not for extensions. For any kind of shared data it is therefore necessary to have some sort of local record identifiers. It’s good practice to maintain – with the original data – identifiers that are stable over time and are not being reused after the record is deleted. If you can, please provide globally unique identifiers instead of local ones.\n\nTo be completed.\n\nA Darwin Core Archive should contain a file containing metadata describing the whole dataset. The Ecological Metadata Language (EML) is the most common format for this, but simple Dublin Core files are being used too.\n\n"}
{"id": "50527507", "url": "https://en.wikipedia.org/wiki?curid=50527507", "title": "Dynamic syntax", "text": "Dynamic syntax\n\nDynamic Syntax is a grammar formalism that aims to represent the real-time nature of the parsing/production process. Under the Dynamic Syntax approach, linguistic knowledge is considered to be the ability to parse spoken language in context, whilst syntax is the constraint-based way in which representations of context can be built up from words encountered in a string. While it has similarities to Combinatory categorial grammar in terms of the representations it generates, it is unique amongst grammar formalisms in that it puts word-by-word left-to-right incremental build-up of representations at the heart of the formalism, rather than incrementality only being used in external parsing algorithms.\n\nDynamic Syntax constitutes several core components: semantic formulae and composition calculus (epsilon calculus within typed lambda calculus), trees (lambda application ordering), and tree building actions (lexical and computational actions).\n\nThe semantic formulae which classical Dynamic Syntax generates are a combination of Epsilon calculus formulae and Lambda calculus terms (in recent years DS-TTR has been developed alongside DS where Record Types from the formalism Type Theory with Records (TTR)) are used - see Purver et al. (2011)).\n\nThe formulae are either simple first order logic constants such as formula_1, predicate terms such as formula_2 or functions such as formula_3. Normal lambda calculus substitution (formula_4-reduction) means a function can be applied to a simple term to return a predicate such that formula_5. The Epsilon calculus extension to first order logic is implemented in quantifiers, where formula_6, e.g. the string \"a boy\" may result in the formula formula_7 being generated.\n\nOne of the basic assumptions behind DS is that natural language syntax can be seen as the progressive accumulation of transparent semantic representations with the upper goal being the construction of a logical propositional formula (a formula of type \"t\"). This process is driven by means of monotonic tree growth, representing the attempt to model the way information is processed in a time-linear, incremental, word-to-word manner. Tree growth is driven by means of requirements (indicated by the question mark (?)).\n\nTree growth can take place in three ways: through computational rules, lexical input and pragmatic enrichment.\n\nThe language of representation in Dynamic Syntax consists of binary trees. These trees are underpinned by the Logic Of Finite Trees (LOFT, Blackburn & Meyer-Viol 1994). LOFT is an expressive modal language that allows statements to be made about any treenode from the perspective of any treenode. LOFT uses two basic tree modalities, the up and down arrow relations. These correspond to the daughter and mother relations. Left nodes are addressed as 0 nodes and right nodes are 1 nodes. By convention, nodes on the left correspond to argument nodes, i.e. nodes in which arguments are represented, whereas right nodes correspond to the functor nodes, i.e. nodes in which all the various types of predicates are represented. The rootnode is given the treenode address 0 and it is defined as the sole node that does not have a mother node.\n\n"}
{"id": "2927081", "url": "https://en.wikipedia.org/wiki?curid=2927081", "title": "Elaterite", "text": "Elaterite\n\nElaterite (also known as Aeonite, 'elastic bitumen' , 'mineral caoutchouc' or Wurtzilite) is a brown hydrocarbon varying somewhat in consistency, being sometimes soft, elastic and sticky, like India rubber, and occasionally hard and brittle. It is usually dark brown in color and slightly translucent. A substance of similar physical character is found at sites around the Coorong lagoon in South Australia, and is hence termed coorongite. \n\n\"Strawberry, Utah, USA: Occurs in the Indian Canyon, Sams Canyon, Dry Fork, and Lake canyon, tributaries of the Strawberry river in Duchesne County. It occurs in vertical veins from one to twenty-two inches wide, twenty to two hundred feet high, and a maximum length of three and one quarter miles\" Also flows from the ground in a soft elastic form at various locations along the Strawberry River \n\n\"Castleton in Derbyshire:\" Windy Knoll Cave. The lead mines of Odin.\n\n"}
{"id": "33744145", "url": "https://en.wikipedia.org/wiki?curid=33744145", "title": "Food moisture analysis", "text": "Food moisture analysis\n\nFood moisture analysis involves the whole coverage of the food items in the world because foods are comprising a considerable amount of water rather than other ingredients. Foods are vital components which are consumed by the people at each and every moment for the surviving in the world. Basically there are several kinds of foods are available for the consumption as raw foods, processed foods and modified foods in the market. Moisture content of the food material is important to consider the food is suitable before the consumption, because moisture content affects the physical, chemical aspects of food which relates with the freshness and stability for the storage of the food for a long period of time and the moisture content determine the actual quality of the food before consumption and to the subsequent processing in the food sector by the food producers.\n\nFood moisture analysis involves the amount of moisture content and the concentration of moisture by measuring qualitatively and quantitatively. The food processing companies and the \"Research and Development\" (R&D) people of the food producing company, food related peoples, graduates, undergraduates and the high school students must be well aware of the moisture analysis of the food which do a lot in the food safety and storage conditions and the shelf life of the food. Moisture content analysis is important in determining the shelf life of foods and products\n\nLegal limitations regarding the amount of water present in the food is necessary for producing some of the specific products. For example, there should be less than 40% of moisture should be controlled during the production of cheddar cheese.\n\nMoisture present in the food material is related with some type of food is dealing with economical values and the big business among industries therefore, food moisture analysis plays a significant role in the modern world.\n\nFurther, microbial activity of the food materials favor with the moisture availability in the food. Moisture rich foods are easily susceptible to the microbial attack and got rotted and damaged. Thus the shelf life of the food material is determined by the moisture content in the food.Low moisture foods usually slow down growth of microorganisms hence the need for analysis and control of food moisture.\n\nQuality of the food is determined in terms of the food texture, taste, and appearance but moisture content of the food is a determination factor of the quality and the stability of the processed food products.\n\nFood processing operations are involved with the amount of moisture content present in the food item which is going to be processed for a specific purpose.\n\nMoisture analysis\nFood analysis\nAnalytical chemistry\nFood Science\nFood Chemistry\n\n\n\n"}
{"id": "900698", "url": "https://en.wikipedia.org/wiki?curid=900698", "title": "Geyserite", "text": "Geyserite\n\nGeyserite is a form of opaline silica that is often found around hot springs and geysers. It is sometimes referred to as sinter. Botryoidal geyserite is known as fiorite.\n\nIn May 2017, evidence of the earliest known life on land may have been found in 3.48-billion-year-old geyserite uncovered in the Pilbara Craton of Western Australia.\n\n\n"}
{"id": "17356921", "url": "https://en.wikipedia.org/wiki?curid=17356921", "title": "Helmut Volz", "text": "Helmut Volz\n\nHelmut Volz (; 1 August 1911 in Göppingen – 23 October 1978) was a German experimental nuclear physicist who worked on the German nuclear energy project during World War II. In the latter years of World War II, he became a professor at Erlangen University. He declined to take a position offered to him in the United States after the war, and he continued his teaching and research at Erlangen.\n\nFrom 1929 to 1933, Volz studied at the \"Eberhard-Karls-Universität Tübingen\" and the \"Ludwig-Maximilians-Universität München\". He received his doctorate in 1935 under Hans Geiger at the University of Tübingen.\n\nFrom 1935 to 1937, Volz worked at and studied physics at the \"Institut für theoretische Physik\" of the \"Universität Leipzig\". From 1937 to 1944, Volz was a teaching assistant to Hans Geiger at the \"Technische Hochschule Berlin\" (today, the Technische Universität Berlin, in Berlin-Charlottenburg. During this period, Volz worked on the German nuclear energy project, also called the \"Uranverein\" (Uranium Club). He specialized in experimental studies of neutron absorption in uranium, conducted with another former student of Geiger, Otto Haxel. From 1943 to 1944, he was also a lecturer at the \"Technische Hochschule Berlin\".\n\nFrom 1944, Volz was an extraordinarius professor (professor without a chair) at the Friedrich-Alexander-Universität Erlangen-Nürnberg.\n\nNear the close and after the end of World War II in Europe, the Russians and the Western powers had programs to foster technology transfer and exploit German technical specialists. For example, the U.S. had Operation Paperclip and the Russians had trophy brigades advancing with their military forces. In the area of atomic technology, the U.S. had Operation Alsos and the Russians had their version. While operational aspects of the Russian operation were modelled after the trophy brigades, a more refined approach was warranted for the exploitation of German atomic related facilities, intellectual materials, and scientific personnel. This was rectified with a decree in late 1944 and the formation of specialised exploitation teams in early 1945 under the Russian Alsos, which had broader objectives, including wholesale relocation of scientific facilities to the Soviet Union. \n\nVolz was offered a position in the United States through Operation Paperclip. Volz had received a letter from the Munich Branch of the American War Department indicating that he had been suggested for a position in the United States and that he should henceforth report any change of address to the United States occupation authorities. The letter was not clear if this offer was voluntary or compulsory. Under further investigation, Volz found that the offer had a number of stipulations. On the positive side, his family in Germany would receive better quality care and rations than the average citizen of Germany under the occupation. On the other hand, he would not be allowed to correspond with anyone other than his relatives, he was to obey all orders, he would be restricted to a 50-mile radius around his duty station, and the minimum obligation had to be for at least six months. Furthermore, after his contractual period, he would not be allowed to return to Germany without permission of his employer. That was the last straw; Volz declined the offer. However, even with these conditions, the United States was able to attract considerable scientific talent to the United States under Operation Paperclip, as the living conditions in Germany were harsh and there were limited opportunities for meaningful scientific work there.\n\nFrom 1958, Volz was an ordinarius professor at the Friedrich-Alexander-Universität Erlangen-Nürnberg.\n\nThe following reports were published in \"Kernphysikalische Forschungsberichte\" (\"Research Reports in Nuclear Physics\"), an internal publication of the German \"Uranverein\". The reports were classified Top Secret, they had very limited distribution, and the authors were not allowed to keep copies. The reports were confiscated under the Allied Operation Alsos and sent to the United States Atomic Energy Commission for evaluation. In 1971, the reports were declassified and returned to Germany. The reports are available at the Karlsruhe Nuclear Research Center and the American Institute of Physics. \n\n\n\n"}
{"id": "27919953", "url": "https://en.wikipedia.org/wiki?curid=27919953", "title": "International Society for Ecological Economics", "text": "International Society for Ecological Economics\n\nThe International Society for Ecological Economics (ISEE) was founded in 1989, based heavily on the work of Herman Daly to promote ecological economics and assist ecological economists and related societies. The society publishes a monthly journal \"Ecological Economics\", books and other materials, and holds periodic meetings and conferences to facilitate a voice for ecological economists.\n\nThe ISEE was initially presided over by Robert Costanza who was also the first editor of the journal. Subsequent presidents have been Richard B. Norgaard, John Proops, Charles Perrings, Joan Martinez Alier, Peter May, John Gowdy, Bina Agarwal, and Marina Fischer-Kowalski, an Austrian sociologist. The current president is Sabine O'Hara, Dean of the College of Agriculture, Urban Sustainability & Environmental Sciences at the University of the District of Columbia. Clóvis Cavalcanti is the President Elect of the ISEE, his term as president commencing in January 2018. The journal is currently edited by Richard B. Howarth.\n\nIn 1996, the Right Livelihood Award was awarded to steady-state theorist Herman Daly \"for defining a path of ecological economics that integrates the key elements of ethics, quality of life, environment and community.\" He was honored as one of the key figures in the foundation of ISEE, that was considered to be \"the major forum that links economists and ecologists, and academics and environmental activists.\" Dr. Daly was also awarded the 2014 Japanese Blue Planet Award.\n\nThe ISEE is divided into regional societies. There are currently ten regional societies:\n\nThere is also a Chinese Ecological Economics Society which is not affiliated to the ISEE and an Iberoamerican Network, REDIBEC.\n\nISEE holds biennial conferences in different locations:\n\n"}
{"id": "32788867", "url": "https://en.wikipedia.org/wiki?curid=32788867", "title": "International Society on Thrombosis and Haemostasis", "text": "International Society on Thrombosis and Haemostasis\n\nThe International Society on Thrombosis and Haemostasis (ISTH) is a not-for-profit global membership organization of specialists in the field of blood coagulation and its disorders, such as thrombosis and hemophilia. It was founded in 1954 as the International Committee on Thrombosis and Haemostasis (ICTH). The society was reorganized in 1969 as the ISTH. It currently represents about 4000 members from 93 different countries. The society initiates and promotes education and outreach initiatives, research activities, scientific meetings, peer-reviewed publications, expert committees and the development of standards allowing a common language and approach to basic and clinical science all over the world. It also publishes a medical journal, the \"Journal of Thrombosis and Haemostasis\".\n\nThe mission of the International Society on Thrombosis and Haemostasis is to advance the understanding, prevention, diagnosis and treatment of thrombotic and bleeding disorders.\n\nThe Scientific and Standardization Committee (SSC) began in 1954 as the International Committee for the Standardization of the Nomenclature of the Blood Clotting Factors. The SSC is a permanent committee of the ISTH and is its scientific working arm. Conducted through 20 subcommittees and working groups, its activities promote cooperation among leading international scientists and direct their energies to projects that generate reliable and standardized clinical and basic science tools.\n\nThe ISTH hosts a biennial congress as well as annual meetings of the SSC. In odd-numbered years, SSC Meetings are held jointly with the congress.\n\nThe ISTH Academy is the online education platform for the society. The ISTH Academy features webinars, webcasts, online courses and access to abstracts and posters from past ISTH meetings.\n\n\n"}
{"id": "38175597", "url": "https://en.wikipedia.org/wiki?curid=38175597", "title": "Jacques Dauphin", "text": "Jacques Dauphin\n\nJacques Dauphin (July 4, 1923 – April 1, 1994) was a French advertising pioneer founder and CEO of Dauphin OTA. He is best known as the father of modern billboard advertising.\n\nIn 1999 Dauphin OTA was sold to the American company Clear Channel and became an emblematic part of its outdoor communication division.\n\nAfter graduating with a law degree from Faculte de droit de Paris and from HEC Paris, Jacques Dauphin re-opened the Parisian-based office created by his father Eugene Dauphin in 1921 who closed it during WWII to prevent any collaboration with the Nazis. He then developed the company to a broader scale after the French Liberation expanding its activities (mainly billboard advertising and radio) to other European countries including the UK, Belgium, Italy or Spain. Jacques Dauphin has notably created and developed the 4x3 format that remains today the international standard format used in billboard advertising worldwide.\n\nHis professional achievements have been honoured in several occasions and he has successively occupied the following positions: president (1958 - 1966) of the national outdoor advertising federations of France, Germany, Belgium, Finland, Italy and the Netherlands best known as FEPE that he created and the International Advertising Association. He was then vice-president (1969), president (1972 - 1974), and honorary president of the French Chambers of advertising. He presided the 3rd World Congress of Outdoor Advertising in London in 1972. He was a member of the International Commission « Publicité distribution » of the International Chamber of Commerce, and co-president of Grand prix international de l´affichage. He has been made Knight of the Legion of Honour and Knight of the Ordre des Arts et des Lettres by the French authorities.\nThrough Dauphin OTA Jacques Dauphin was also particularly active in the promotion of the arts and image. \n\nHe notably promoted the Cannes Film Festival and the French International Contemporary Art Fair best known as FIAC.\n\nThrough Dauphin, Jacques Dauphin has commissioned and inspired various artists, such as Daniel Buren or François Morellet among others.\n\nJacques Dauphin has turned billboard advertising into a popular art form, a witness of the contemporary society, and one of the leading media of the XXth century in Europe.\n\nAfter his only son died in a tragic car accident in 1988 Jacques Dauphin had no heir to take up the business that has led to the sale of the company in 1999.\n\nHis only heiress is his only granddaughter Charlotte de La Rochefoucauld (born Charlotte Dauphin in 1987) who has married Comte Charles-Henri de La Rochefoucauld in 2012 in Saint-Louis des Invalides cathedral in Paris, France.\n\nJacques Dauphin's life and career, his personality, leadership, and his passion for sailing have inspired French film director Claude Lelouch for his film Itinerary of a Spoiled Child and its lead character Sam Lion.\n\n“Billboard advertising is a visual rape.”\n\n“Our billboards are our stage, our trestles: we are an entertainment business, a performing art company.”\n\n“Billboards are the infantry of advertising.”\n\n\n\n\n"}
{"id": "31816507", "url": "https://en.wikipedia.org/wiki?curid=31816507", "title": "Langat virus", "text": "Langat virus\n\nLangat virus (LGTV) is a virus of the genus Flavivirus. The virus was first isolated in Malaysia in 1956 from a hard tick of the Ixodes genus. This virus is antigenically related to Omsk hemorrhagic fever virus, Kyasanur forest disease virus, Alkhurma virus, Louping ill virus and other viruses of the tick-borne encephalitis virus (TBEV) complex. The Langat virus does not pose a significant epidemiological threat in comparison with TBEV. There are no known cases of human diseases associated with LGTV. The Malaysian strain (LGT strain TP21, also known as the Yelantsev virus) is naturally attenuated and induces neutralizing antibodies to tick-borne encephalitis virus (TBEV) and protection against other TBEV complex viruses in animals.\n\nIn the 1970s a live attenuate LGTV-based vaccine against tick-borne encephalitis was made. At the same time, another vaccine was tested, but the group vaccinated with the LGTV-based vaccine had the lowest level of developing infection decease. However, there were two big problems: the high level incidents of encephalitis (1:10 000) and lack of absolute protection from infection in endemic regions.\n"}
{"id": "22176006", "url": "https://en.wikipedia.org/wiki?curid=22176006", "title": "List of European countries by number of Internet users", "text": "List of European countries by number of Internet users\n\nThis article presents a map and a list of European countries by number of Internet users. \n\n\n"}
{"id": "33332159", "url": "https://en.wikipedia.org/wiki?curid=33332159", "title": "List of Muslim Nobel laureates", "text": "List of Muslim Nobel laureates\n\nAs of 2018, twelve Nobel Prize laureates have been Muslims, more than half in the 21st century. Seven of the twelve laureates have been awarded the Nobel Peace Prize, while three have been for the sciences. The recipient of the 1979 Nobel Prize in Physics, Abdus Salam, was a member of the Ahmadiyya Muslim community of Pakistan. Aziz Sancar is the second Turkish Nobel laureate and was awarded Nobel prize in the field of molecular biology in 2015.\n\n\n\n\n\n\nThe year of receiving Nobel Prize is given after each Nobel Laureate in this article. For verification of candidacy of above listed Nobel Laureates, please go to nobelprize.org, and search the corresponding year of reception of Nobel Prize in the respective field.\n\n\n"}
{"id": "9024530", "url": "https://en.wikipedia.org/wiki?curid=9024530", "title": "List of UN numbers 1401 to 1500", "text": "List of UN numbers 1401 to 1500\n\nThe UN numbers from UN1401 to UN1500 as assigned by the United Nations Committee of Experts on the Transport of Dangerous Goods.\n\n"}
{"id": "38596702", "url": "https://en.wikipedia.org/wiki?curid=38596702", "title": "List of discoveries influenced by chance circumstances", "text": "List of discoveries influenced by chance circumstances\n\nBelow are discoveries in science that involve chance circumstances in a particularly salient way. This page should not list all chance involved in all discoveries (i.e. it should focus on discoveries reported for their notable circumstances).\n\nRoyston Roberts says that various discoveries required a degree of genius, but also some lucky element for that genius to act on. Richard Gaughan writes that accidental discoveries result from the convergence of preparation, opportunity, and desire.\n\nMajor everyday discoveries that were helped by luck in some way include products like vulcanized rubber, teflon, nylon, penicillin, cyanoacrylate (Super Glue), the implantable pacemaker, the microwave oven, Scotchgard, Saran wrap, Silly Putty, Slinky, safety glass, propeller, snowmaking, stainless steel, Perkin's mauve, and popsicles. Most artificial sweeteners have been discovered when accidentally tasted, including aspartame and saccharin.\n\nIdeas include the theory of the big bang, tissue culture, radio astronomy, and the discovery of DNA.\n\nSuch archeological discoveries as the Rosetta stone, the Dead Sea Scrolls and the ruins of Pompeii also emerged partly out of serendipity.\n\nMany relevant and well known scientific theories were developed by chance at some degree along history. According to a legend, Archimedes realized his principle on hydrostatics when he entered in a bath full of water, which overflows (he then shouted out his famous \"Eureka!\"). And the unexpected, negative results of the Michelson-Morley experiment in their search of the luminiferous aether ultimately led to the Theory of Special Relativity by Albert Einstein.\n\nThe optical illusion called the \"flashed face distortion effect\" suggests a new area of research in the neurology of face perception.\n\nIn his book, Roberts recounts Sir Isaac Newton's discovery of gravity (using Newton's own descriptions and notes). Newton was sitting in his yard when he noticed an apple fall from a tree. The apple fell straight down, perpendicular to the ground, and Newton found himself wondering why the apple never falls upward or off to a side. Newton soon realized that it was a property of all matter to have an attractive force, including the apple, and even the moon – which moves as one would expect if it was passing the earth but nevertheless being attracted. It was another 20 years before Newton published his detailed theory of gravity, but he later visited the tree that helped him provoke the idea. Gaughan elaborates that Newton only had the opportunity to reflect on his orchard because of other chance circumstances: Newton was home because his university was shut down due to an outbreak of plague.\n\nAccording to Roberts, the common story that Alfred Nobel's discovery of dynamite was an accident may not be true. On the other hand, Roberts says, Nobel did make a discovery with the help of luck soon after that. Nobel cut his finger on a piece of glass one day at work and subsequently applied collodion in order to form a protective layer over the wound (similar in principle to liquid bandage). Nobel was kept up at night by the pain in his finger, so he started to think about a problem he was having back at work: Nobel was trying to create a powerful explosive using nitrocellulose and nitroglycerine, but the two would not combine. Roberts reports that Nobel then realized that collodion (which he was using to dress his wound) could allow the two substances to combine, which led to the invention of blasting gelatin (as powerful as dynamite but much safer to handle).\n\nThe French scientist Louis Pasteur is responsible for various discoveries, some of which involved serendipity in some way. This seems to be the case with both his discovery that chemically identical molecules can have chirality (the way a right handed baseball glove will not work with the left hand), as well as his discovery of the chicken cholera vaccine.\n\nRoberts writes \"Pasteur was puzzled: the salts of tartaric acid and racemic acid were said to be identical in chemical composition and crystalline shape, but they had different effects on polarized light.\" Pasteur later prepared a solution of only racemic acid and found that it itself contained salt crystals with chirality and which affected light differently. This was somewhat lucky because the type of salt crystals that Pasteur was studying (sodium ammonium salt of racemic acid) is one of few salts that would be visibly different in Pasteur's time. Moreover, the salts only differentiate if the solution reaches a temperature below ; Pasteur did not know about this temperature requirement, but he did happen to store the solution on a window sill over night and the cold Paris air activated it.\n\nPasteur and his assistants had succeeded in isolating a microbe from chickens sick or dead from cholera. Chickens injected with the isolated microbe invariably died — a key element in Pasteur's reasoning that the microbe was responsible for the disease, rather than a result of the disease, as many thought. Pasteur was searching for a method of preventing the disease, but no matter what he did to the \"broth\" of microbes or to the chickens, all injected chickens died. Gaughan writes \"Finally Pasteur had had enough, he needed a vacation. He told [his assistant] to take care of injecting more chickens with the next batch of bacteria.\" His assistant neglected the task, electing to go on vacation as well. When the men returned and injected chickens with the batch of bacteria that had sat around for a few weeks, none died, indicating to Pasteur that the batch of bacteria had been ruined. But when those same chickens were injected with a new batch of bacteria, none of them died, while chickens that hadn't previously been injected with the \"spoiled\" batch all died. Pasteur reasoned that the \"attenuated\" microbes in the spoiled batch \"'used up' something within the body; something that wasn't there for the fully functional bacteria to eat.\" His explanation was wrong, but his chance creation of attenuated bacteria resulted in the first intentionally created vaccine.\n"}
{"id": "47533608", "url": "https://en.wikipedia.org/wiki?curid=47533608", "title": "List of female Fellows of the Royal Academy of Engineering", "text": "List of female Fellows of the Royal Academy of Engineering\n\nThe page lists female Fellows of the Royal Academy of Engineering (FREng), elected by the Royal Academy of Engineering in the UK.\n\nThe Royal Academy of Engineering (RAEng), founded in 1976, is the youngest of the five national academies in the UK. It represents the nation's best practising engineers, innovators and entrepreneurs, who are very often in leading roles in industry, business and academia. Fellowship of the RAEng is a national honour, bringing prestige to both the individual and any organisation the Fellow is associated with. In recent years between 50 and 60 new Fellows have been chosen each year by peer review from nominations made by the current Fellowship;. Those proposed for Fellowship must come “from among eminent engineers regarded by virtue of their personal achievements in the field of engineering as being of exceptional merit and distinction”.\n\nAll 130 of the Founding Fellows in 1976 were men. Four women were elected in the first 20 years, the first in 1982. In all, 13 female Fellows pre-date 2000, with a further 23 elected before 2010. In 2010 the Council determined a policy that over time 10-20% of newly elected Fellows should be women.\nThe Academy currently has a diversity policy and staff appointed to pursue it, both within the institution and across the engineering profession.\n\nAs of 2018, 85 women have been elected to Fellowship, plus six International Fellows, two Honorary Fellows and one Royal Fellow. Female engineers make up 4% of the total current Fellowship.\n\nInternational Fellows are engineers of international distinction who are not of British nationality and who are not resident and working in Britain. The number of International Fellows cannot exceed one-tenth of the number of Fellows, and no more than ten may be elected in any year.\n\nPersons not being Fellows who have made or are making a distinguished contribution to the practice of engineering are eligible for election as Honorary Fellows. Their number cannot exceed fifty and no more than five may be elected in any year.\n\nRoyal Fellows are such members of the Royal Family as on the invitation of the Board shall agree to become Royal Fellows.\n\n\n"}
{"id": "48779009", "url": "https://en.wikipedia.org/wiki?curid=48779009", "title": "List of science centers", "text": "List of science centers\n\nThis page will be the list of science centers all over the word.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "38309040", "url": "https://en.wikipedia.org/wiki?curid=38309040", "title": "List of things named after David Hilbert", "text": "List of things named after David Hilbert\n\nDavid Hilbert (1862–1943), a mathematician, is the eponym of all of the things (and topics) listed below.\n\n"}
{"id": "11038723", "url": "https://en.wikipedia.org/wiki?curid=11038723", "title": "List of volcanoes in Cambodia", "text": "List of volcanoes in Cambodia\n\nThis is a list of active, dormant and extinct volcanoes in Cambodia. \n"}
{"id": "58002201", "url": "https://en.wikipedia.org/wiki?curid=58002201", "title": "List of women in leadership positions on astronomical instrumentation projects", "text": "List of women in leadership positions on astronomical instrumentation projects\n\nThe following is a list of women who are the Principal Investigators (PIs), Project Scientists (PSs) or Directors (Dirs) of astronomical instruments, missions or observatories.\n"}
{"id": "39718245", "url": "https://en.wikipedia.org/wiki?curid=39718245", "title": "Lone Signal", "text": "Lone Signal\n\nLone Signal was a crowdfunded active SETI project designed to send messages from Earth to a possible extraterrestrial civilization. Founded by businessman Pierre Fabre and supported by several entrepreneurs, Lone Signal was based at the Jamesburg Earth Station in Carmel, California. The project's beacon, which commenced continuous operations on June 17, 2013, transmitted short, 144-character messages by citizens of Earth to the red dwarf star Gliese 526, located 17.6 light-years away from Earth in the constellation Boötes. The Lone Signal team hoped to earn  million to construct a network of dishes across the Earth's surface, beaming messages to many regions of the Milky Way galaxy. The project ceased transmission shortly after it began, due to lack of funding.\n\nLone Signal's message consists of two key components, a background hailing component and a more complex message component. The hailing component, designed by planetary scientist Michael W. Busch, uses a universal binary encoding system, which goes through an octal intermediary, representing numbers, mathematical operators, or other symbols. Each value corresponds to a single unique frequency. The offsets between those frequencies are set to be much larger than the bit rate (i.e. if transmitting at 100 Hz, the offsets between adjacent frequencies will be ~300 Hz). Using these code blocks, coherent mathematical statements about the laws of physics and Earth's location in the galaxy are produced. The hailing message repeats on average three times in order to allow the recipient to decode it at any time when observation begins, with some parts repeating more often than others. The hailing component was designed to be easily decoded by an extraterrestrial civilization, which was confirmed by a double-blind experiment.\n\nThe hailing component is not an end in itself, but is designed to be a \"Rosetta Stone\" toward understanding the more complex message component, consisting of brief, 144-character statements by the general public. These messages, with widely varying languages and contents, were posted from the Lone Signal website. Individuals who have signed up to send messages with Lone Signal, collectively known as the \"beaming community\", were permitted to send one message for free, and thereafter required to purchase \"message credits\" of $0.25 per message sent in order to fund the operation of the project. The content of messages sent via Lone Signal could be syndicated to the Twitter and Facebook accounts of beaming community members as desired. It was in this beaming community user space that an attempt was being made to extend the syntax used in the hailing message to communicate in a way that, while neither mathematical nor strictly logical, was nonetheless designed to be understandable given the prior definition of terms and concepts in the hailing message.\n\nVarious commentators have identified several dangers with messaging extraterrestrial intelligence, which chief scientific officer Jacob Haqq-Misra covered in a 2013 paper before joining Lone Signal. In his paper, Haqq-Misra stated that while ordinary communication which might involve inadvertent leakage into space would not pose a threat, the dangers of actively beaming messages to extraterrestrial intelligences, and hence a determination of whether or not such beaming activities should be carried out, are uncertain.\n\nUpon becoming an executive of Lone Signal, Haqq-Misra stated his belief that extraterrestrial civilizations probably already know of humanity's existence, and reaffirmed his position that the cultural impact of extraterrestrial contact is unknowable. He based this belief on the fact that various other radio sources have been broadcasting into space for decades, and would be detectable to any civilization with sufficiently large radio telescopes. For example, the hailing message sent by Lone Signal would be detectable with an array area of , and the message portion would be detectable by a telescope with of collecting area; by contrast, humanity's most powerful signals, from military radars and the Arecibo Observatory, could be detected with a small, antenna. At the same time, though, the previous messages from the most powerful beaming sources were intermittent, while Lone Signal aimed to establish the first continuous beam to space.\n\n"}
{"id": "16938645", "url": "https://en.wikipedia.org/wiki?curid=16938645", "title": "Louis Visentin", "text": "Louis Visentin\n\nLouis Peter Visentin is a Canadian scientist and former President and Vice-Chancellor of Brandon University. Visentin held this position from May 2000 until his retirement in 2009.\n\nVisentin received his doctorate in molecular biology from the University of Michigan in 1969. Prior to assuming the role of President at Brandon University, he served as Vice President (Academic) with the University of New Brunswick. He is a former member of the National Research Council Governing Council and the Premier of Manitoba's Economic Advisory Council Image Strategy Development Task Group. Visentin was awarded the Queen's Golden Jubilee Medal for service to Canada in 2002 and the Venerable Order of Saint John in 2003.\n\n"}
{"id": "49590909", "url": "https://en.wikipedia.org/wiki?curid=49590909", "title": "Miguel Herrero Uceda", "text": "Miguel Herrero Uceda\n\nMiguel Herrero Uceda (born January 24, 1964 in Ceclavín, Cáceres, Spain) is a writer, lecturer and natural scientist committed to the defence of the environment and the conservation of popular traditional culture. He has a PhD in artificial intelligence and was a professor at Universidad Complutense of Madrid. He is a promoter of the natural philosophy \"arbotherapy\", a therapy to combat the stress and the anxiety generated by modern world. \n\nUceda is a collaborator of the Más Árboles Foundation for the regeneration and creation of new forests and a contributor to magazines and newspapers including \"El Mundo\", \"El Periódico de Extremadura\", \"Foresta\", \"Tecnociencia\", \"The ecologist\", \"Revista Natural\", and \"Guardabosque\" (environmental agents magazine).\n\nHe is the brother of painter Antonio José Herrero Uceda and of writer Elisa Herrero Uceda.\nOn May 31, 2014, he organised, along with poet José Iglesias Benítez, \"Beturia Cultural association\" president, the meeting of Extremaduran writers from inside and outside of Extremadura, \"Extremaduran Writers Day\", in Ceclavín (Cáceres).\n\nOn May 30, 2015, he organised, along with the community \"The Bohème\", the Poets and Artists International Meeting in favour of the nature \"Men, forests and jungles\" at the Palace of the Infantado in Guadalajara.\n\n\n\nExhibitions about nature and popular culture.\n\nBoth documentaries participated in the Cycle of Scientific Cinema – visual Space organised in 2011 by ASECIC (Spanish Association of Cinema and Scientific Image) and by the National Museum of Natural Sciences.\n\n"}
{"id": "35184684", "url": "https://en.wikipedia.org/wiki?curid=35184684", "title": "Mycoplasma haemomuris", "text": "Mycoplasma haemomuris\n\nMycoplasma haemomuris, formerly known as \"Haemobartonella muris\" and \"Bartonella muris\", is a Gram-negative bacillus. It is known to cause anemia in rats and mice.\n"}
{"id": "39039164", "url": "https://en.wikipedia.org/wiki?curid=39039164", "title": "Nerode Prize", "text": "Nerode Prize\n\nThe EATCS--IPEC Nerode Prize is a theoretical computer science prize awarded for outstanding research in the area of multivariate algorithmics. It is awarded by the European Association for Theoretical Computer Science and the International Symposium on Parameterized and Exact Computation. The prize was offered for the first time in 2013.\n\nThe prize winners so far have been:\n"}
{"id": "1006496", "url": "https://en.wikipedia.org/wiki?curid=1006496", "title": "Open Polar Sea", "text": "Open Polar Sea\n\nThe Open Polar Sea was a hypothesized ice-free ocean surrounding the North Pole. This unproven (and eventually disproved) theory was once so widely believed that many exploring expeditions used it as justification for attempts to reach the North Pole by sea, or to find a navigable sea route between Europe and the Pacific across the North Pole.\n\nThe theory that the north polar region might be a practical sea route goes back to at least the 16th century when it was suggested by Robert Thorne. Explorers William Barents and Henry Hudson also believed in the Open Polar Sea. For a time, the theory was put aside due to the practical experience of navigators who encountered impenetrable ice as they went north. But the idea was revived again in the mid-19th century by theoretical geographers such as Matthew F. Maury and August Petermann. At this time, interest in polar exploration was high due to the search for John Franklin's missing expedition, and many would-be polar explorers took up the theory, including Elisha Kent Kane, Dr. Isaac Israel Hayes, and George Washington De Long. It was believed that once a ship broke through the regions of thick ice that had stopped previous explorers, a temperate sea would be found beyond it.\n\nAlthough today we know that the North Pole was covered with thick ice for much of the period, the theory of the Open Polar Sea was popular in the 16th–19th centuries and many arguments were made to justify its existence:\n\n\nThe Open Polar Sea theory was debunked gradually by the failure of the expeditions in the 1810s through the 1880s to navigate the polar sea. Reports of open water by earlier explorers, such as Elisha Kent Kane and Isaac Israel Hayes, fueled optimism in the theory in the 1850s and 1860s. Support faded when George W. De Long sailed into the Bering Strait hoping to find an open 'gateway' to the North Pole and was met by a sea of ice. After a long drift, pack ice crushed the \"Jeannette\" and her survivors returned home with first hand accounts of an ice-covered polar sea. Other explorers such as British explorer George Nares confirmed this. By the time Fridtjof Nansen and Otto Sverdrup drifted through the polar ice pack in \"Fram\" in 1893–1895, the Open Polar Sea theory was defunct.\n\nNevertheless, scientific studies of climate change in the 2000s project that by the end of the 21st century, the annual summer withdrawal of the polar ice cap could expose large areas of the Arctic Ocean as open water, and an ice-free Arctic is possible in the future due to Arctic shrinkage. Although the North Pole itself could potentially remain ice-covered in winter, a navigable seasonal sea passage from Europe to the Pacific could develop along the north coast of Asia.\n\n\nRussell Potter, \"The Open Polar Sea,\" \"Encyclopedia of the Arctic\" (Routledge, 2004)\n\nMichael Robinson, \"The Coldest Crucible: Arctic Exploration and American Culture\" (Chicago, 2006).\n\nMichael Robinson, \"Reconsidering the Theory of the Open Polar Sea,\" in Extremes: Oceanography's Adventures at the Poles (Sagamore Beach MA, 2006)\n\nHampton Sides, \"In the Kingdom of Ice: The Grand and Terrible Polar Voyage of the U.S.S. Jeannette.\" (New York: Doubleday, 2014.)\n\nJ. K. Wright, \"The Open Polar Sea, Human Nature in Geography\" (Cambridge MA, 1966)\n"}
{"id": "6473570", "url": "https://en.wikipedia.org/wiki?curid=6473570", "title": "Outline of algebra", "text": "Outline of algebra\n\nAlgebra is one of the main branches of mathematics, covering the study of structure, relation and quantity. Algebra studies the effects of adding and multiplying numbers, variables, and polynomials, along with their factorization and determining their roots. In addition to working directly with numbers, algebra also covers symbols, variables, and set elements. Addition and multiplication are general operations, but their precise definitions lead to structures such as groups, rings, and fields.\n\n\nAn algebraic equation is an equation involving only algebraic expressions in the unknowns. These are further classified by degree.\n\n\nHistory of algebra\n\n\n"}
{"id": "29621505", "url": "https://en.wikipedia.org/wiki?curid=29621505", "title": "People accounting hypothesis", "text": "People accounting hypothesis\n\nWithin the fields of equality, diversity, and inclusion, the people accounting hypothesis is a social psychological theory based on social categorization. It is defined as “a hypothesis that describes how a simple numerical imbalance in representation along nominal social category lines can affect people’s choice of candidates in highly competitive situations (e.g., awards, jobs, etc.)”.\n\nThe people accounting hypothesis can be derived from connecting social categorization, fairness, and choice literatures. When a numerical imbalance between social categories is recognized by individuals, the “social categorization and fairness literature clearly suggests that the concern for fairness shifts from the interpersonal to the intergroup level, prompting individuals to correct an imbalance by promoting equality between groups”.\n\nAnother characteristic of the people accounting hypothesis is that while it can be caused by many different nominal social category lines, in the end it is “more likely to be triggered on a meaningful social category dimension versus a less meaningful one”. It should also be stressed that the significance of a social category line is “context specific”.\nFurthermore, there are implications of the people accounting hypothesis toward the affirmative action policy discussion. Observers note that “people accounting explains a much broader aversion to imbalance across social category lines” than affirmative action programs that try to promote diversity and overcome past inequalities By examining the people accounting hypothesis, they want to address a far broader phenomenon than the “narrow policy of affirmative action” and examine its tendency towards equality that goes beyond race and gender.\n\nFurther, the people accounting hypothesis only works under two conditions: It requires an objective perspective of third parties and the acknowledgment of an imbalance along gender lines. If third parties do not recognize a numerical imbalance between social categories – be it on purpose or not – or “are partial to one category in the dispute, people accounting will not take place”, whilst cautioning that “there are undoubtedly individual differences in what people perceive as an imbalance”.\n\nAlso, the assumption of an impartial, objective assessment of third-party observers should be questioned. It is difficult to find third-party observers with a totally impartial perspective. Since every person acts in a certain context and has his own background and interconnections with other people, there is no such thing as an impartial third-party observer.\n\nGarcia and Ybarra conducted a series of empirical studies where they tested the people accounting hypothesis. Based on these findings, the focus of their analysis was that if there is an alleged imbalance along social category lines, then not everybody will have equal opportunities in the workplace. Garcia and his colleagues conclude that “to the extent that a social category is overrepresented, the winning chances for a member from an over-represented category will drop at the discretion of impartial third parties”. This process is explained by the fact that impartial third-party observers are reluctant to create inequalities along social category lines, and therefore feel pressure to categorically deny the overrepresented social category equal opportunity.\n\nGarcia et al. also critically observe that “people accounting does not always result in the final selection of members of underrepresented social category groups”. There are many other possible reasons why not everyone will have the same opportunity in the workplace (e.g., ingroup favoritism). Garcia and his colleagues focus on the perspective of impartial third-party observers and the psychological aspects of social categorization.\n\nGarcia, S.M., Meyle, M.J. & Provins, E.A. (2009) \"Headcounts and equal opportunity: people \naccounting in the workplace.\" In: Özbilgin, M. (Hrsg). Equality, diversity and inclusion at work. Cheltenham, UK: Edward Elgar.\n\nGarcia, S.M. & Ybarra, O. (2007). \"People accounting: Social category-based choice.\" Journal \nof Experimental Social Psychology, 48, p. 802-809.\n"}
{"id": "1986238", "url": "https://en.wikipedia.org/wiki?curid=1986238", "title": "Polarity item", "text": "Polarity item\n\nIn linguistics, a polarity item is a lexical item that can appear only in environments associated with a particular grammatical polarity – affirmative or negative. A polarity item that appears in affirmative (positive) contexts is called a positive polarity item (PPI), and one that appears in negative contexts is a negative polarity item (NPI).\n\nThe environment in which a polarity item is permitted to appear is called a \"licensing context\". In the simplest case, an affirmative statement provides a licensing context for a PPI, while negation provides a licensing context for an NPI. However, there are many complications, and not all polarity items of a given type need necessarily have exactly the same set of licensing contexts.\n\nAs examples of polarity items, consider the English lexical items \"somewhat\" and \"at all\", as used in the following sentences:\n\nAs can be seen, \"somewhat\" is licensed by the affirmative environment of sentence (1), but it is forbidden (anti-licensed) by the negative environment of sentence (4). It can therefore be considered to be a positive polarity item (PPI). On the other hand, \"at all\" is licensed by the negative environment of sentence (2), but anti-licensed by the positive environment of sentence (3), and is therefore considered a negative polarity item (NPI). \n\nBecause standard English does not have negative concord, that is, double negatives are not used to intensify each other, the language makes frequent use of certain NPIs that correspond in meaning to negative items, and can be used in the environment of another negative. For example, \"anywhere\" is an NPI corresponding to the negative \"nowhere\", as used in the following sentences:\nNote that the alternative form with the double negative, *\"I was not going nowhere\", is ungrammatical in the standard language, although such forms are used in some colloquial English, and parallel the constructions used in certain other languages which have negative concord. (Note also that \"anywhere\", like most of the other NPIs listed below, is also used in other senses where it is not an NPI, as in \"I would go anywhere with you\".) Similar pairs of negatives and corresponding NPI are listed below.\n\nSee also , and .\n\nThe actual set of contexts that license particular polarity items is not as easily defined as a simple distinction between affirmative and negative sentences. Baker noted that double negation may provide an acceptable context for positive polarity items:\n\nHowever, licensing contexts can take many forms besides simple negation/affirmation. To complicate matters, polarity items appear to be highly idiosyncratic, each with its own set of licensing contexts.\n\nEarly discussion of polarity items can be found in the work of Otto Jespersen and Edward Klima. Much of the research on polarity items has centered around the question of what creates a negative context. In the late 1970s, William Ladusaw (building on work by Gilles Fauconnier) discovered that most English NPIs are licensed in downward entailing environments. This is known as the Fauconnier–Ladusaw hypothesis. A downward entailing environment, however, is not a necessary condition for an NPI to be licensed—they may be licensed by some non-monotone (and thus not downward entailing) contexts, like \"exactly N\", as well. \nNor is a downward entailing environment a sufficient condition for all negative polarity items, as first pointed out by Zwarts (1981) for Dutch \"ook maar\".\n\nLicensing contexts across languages include the scope of n-words (negative particles, negative quantifiers), the antecedent of conditionals, questions, the restrictor of universal quantifiers, non-affirmative verbs (doubt), adversative predicates (be surprised), negative conjunctions (without), comparatives and superlatives, \"too\"-phrases, negative predicates (unlikely), some subjunctive complements, some disjunctions, imperatives, and others (finally, only). Given this wide range of mostly non-downward entailing environments, the Fauconnier-Ladusaw Hypothesis has gradually been replaced in favor of theories based on the notion of nonveridicality (proposed by Zwarts and Giannakidou).\n\nDifferent NPIs may be licensed by different expressions. Thus, while the NPI \"anything\" is licensed by the downward entailing expression \"at most two of the visitors\", the idiomatic NPI \"lift a finger\" (known as a \"minimizer\") is not licensed by the same expression.\n\nWhile NPIs have been discovered in many languages, their distribution is subject to substantial cross-linguistic variation; this aspect of NPIs is currently the subject of ongoing research in cross-linguistic semantics.\n\n\n\n"}
{"id": "527877", "url": "https://en.wikipedia.org/wiki?curid=527877", "title": "Political Parties", "text": "Political Parties\n\nPolitical Parties: A Sociological Study of the Oligarchical Tendencies of Modern Democracy () is a book by the sociologist Robert Michels, published in 1911 and first introducing the concept of iron law of oligarchy. It is considered one of the classics of social sciences, in particular sociology and political science. It was translated to Italian as \"Sociologia del partito politico nella democrazia moderna: studi sulle tendenze oligarchiche degli aggregati politici\" by Alfredo Polledro in 1912, and then translated from the Italian to English by Eden Paul and Cedar Paul for Hearst's International Library Co. in 1915.\n\nThis work analyses the power structures of organizations such as political parties and trade unions. Michels's main argument is that all organizations, even those in theory most egalitarian and most committed to democracy – like socialist political parties – are in fact oligarchical, and dominated by a small group of leadership. The book also provides a first systematic analysis of how a radical political party loses its radical goals under the dynamics of electoral participation. The origins of moderation theory can be found in this analysis.\n\nMichels put forward a thesis about incompatibility of democracy and large-scale social organizations. He observed that contrary to democratic and egalitarian principles, both society in general, and specific organizations in particular are dominated by the leadership – the oligarchy. This, according to Michels, was not because of any particular weakness of a particular society or organization in question, but a characteristic of any and all complex social systems. Such social systems have to be organized along the bureaucratic principles, and bureaucracies inevitably develop oligarchies. Michels concluded that in any complex organization, and such dominate the modern world, it is impossible to escape domination of oligarchy - a conclusion which became known as the iron law of oligarchy.\n\nThe iron law of oligarchy is based on the following logic. First, any large scale organization will necessitate the development of bureaucracy for efficient administration. Such leaders will amass resources (superior knowledge control over the formal means of communication with the membership, and the skill in the art of politics) given them power at the expense of rank and file members.\n\nSecond, Michels expressed doubts about whether the rank and file possess the skills necessary to compete with the leaders, a concept he phrased as the \"incompetence of the masses\". In order to prevent the development of an oligarchy, the regular members must be involved in various activities of the organizations; however, reality of time constrains due to work, family and leisure will reduce the amount of time that most such members are willing to dedicate to active involvement in organizational activities and politics. This is compounded by the rank and file lack of education, and corresponding sophistication of the leadership.\n\nIn his case study of his contemporary socialist parties, primarily the German Social Democratic Party. It was radical organization in his time, fighting for novel concepts such as adult suffrage, free speech, and popular participation in the government. Michels described how their political program was overshadowed by the expansion of the organization favoured by the administrative bureaucracy. This, Michels observed, can be explained thus: \"it is far from obvious that the interests of the masses which have combined to form the party will coincide with the interests of the bureaucracy in which the party becomes personified.\" Michels noted that if an organization dedicated to such principles failed to realize its democratic ideals in its own governance, it is unlikely that other organizations, even less concerned with such lofty goals, would be able to function as democracies.\n\nMichels book quickly became a classic of social sciences. His theory was quickly vindicated on a large scale during First World War, when most socialist parties of that time endorsed the war policies of their respective governments, thus showing that their corresponding party leaders put the short-term goals of organizational survival (allying with the state) over doctrinal points of \"proletariat against bourgeoisie\".\n\nSigmund Neumann said that \"the study of sociology of political parties have been completely dominated by Robert Michels' iron law of [oligarchy].\" Michels work significantly influenced the views on political party theory by his friend and one of the founding fathers of sociology, Max Weber. A number of other theorists of political parties acknowledged that this work was a major influence on theirs, including James Bryce, 1st Viscount Bryce, Maurice Duverger, and Robert McKenzie, among others.\n\nBeyond political parties, Michels work was used to explain the functioning of numerous other voluntary organizations from trade unions to medical associations. His theories are also seen as being applicable and influential to the study of all organizations in general, as well as theories of bureaucracy.\n\nMichel's argument has been criticized for being over-deterministic and overly critical of bureaucracy.\n\n\n\n"}
{"id": "1624638", "url": "https://en.wikipedia.org/wiki?curid=1624638", "title": "RasMol", "text": "RasMol\n\nRasMol is a computer program written for molecular graphics visualization intended and used mainly to depict and explore biological macromolecule structures, such as those found in the Protein Data Bank. It was originally developed by Roger Sayle in the early 1990s.\n\nHistorically, it was an important tool for molecular biologists since the extremely optimized program allowed the software to run on (then) modestly powerful personal computers. Before RasMol, visualization software ran on graphics workstations that, due to their cost, were less accessible to scholars. RasMol continues to be important for research in structural biology, and has become important in education.\n\nRasMol has a complex licensing version history. Starting with the version 2.7 series, RasMol source code is dual-licensed under a GNU General Public License (GPL), or custom license \"RASLIC\". Starting with version 2.7.5, a GPL is the only license valid for binary distributions.\n\nRasMol includes a scripting language, to perform many functions such as selecting certain protein chains, changing colors, etc. Jmol and Sirius software have incorporated this language into their commands.\n\nProtein Data Bank (PDB) files can be downloaded for visualization from members of the Worldwide Protein Data Bank (wwPDB). These have been uploaded by researchers who have characterized the structure of molecules usually by X-ray crystallography, protein NMR spectroscopy, or cryo-electron microscopy.\n\nRasmol can communicate with other programs via Tcl/Tk on Unix platforms, and via Dynamic Data Exchange (DDE) on Microsoft Windows.\n\nWith a multiple sequence alignment program, the responsible Java class can be freely used in other applications.\n\n\n"}
{"id": "11142047", "url": "https://en.wikipedia.org/wiki?curid=11142047", "title": "Researchers Alliance for Development", "text": "Researchers Alliance for Development\n\nResearchers Alliance for Development (RAD) is a World Bank supported action-oriented and multidisciplinary network of researchers. Recognizing the engagement of academia in the global intellectual debate on development cooperation, the RAD aims to strengthen the interaction between the World Bank and the research community worldwide. It is headed by a steering committee of academics and many major universities over the world are its members.\n\nRAD objectives include:\n1. Facilitating interaction between the academic community and the World Bank; \n2. Mobilizing the academic and student community on development issues and curricula, facilitating mutual flow of knowledge. \n\nTowards these ends, it runs a number of activities including a student essay prize, a post/doctoral workshop on international organisations and development as well as working groups on an ad hoc basis. \n\n\n1. Diane Stone and Christopher Wright (eds) \"The World Bank and Governance: A Decade of Reform and Reaction\", Routledge, 2006\n"}
{"id": "53722281", "url": "https://en.wikipedia.org/wiki?curid=53722281", "title": "Risk score", "text": "Risk score\n\nRisk score (or risk scoring) is the name given to a general practice in applied statistics, bio-statistics, econometrics and other related disciplines, of creating an easily calculated number (the score) that reflects the level of risk in the presence of some risk factors (e.g. risk of mortality or disease in the presence of symptoms or genetic profile, risk financial loss considering credit and financial history, etc.). \n\nRisk scores are designed to be: \n\nA typical scoring method is composed of 3 components:\n\nItems 1 & 2 can be achieved by using some form of regression, that will provide both the risk estimation and the formula to calculate the score. Item 3 requires setting an arbitrary set of thresholds and will usually involve expert opinion. \n\nRisk score are designed to represent an underlying probability of an adverse event denoted formula_1 given a vector of formula_2 explaining variables formula_3 containing measurements of the relevant risk factors. In order to establish the connection between the risk factors and the probability we estimate a set of weights formula_4 is estimated using a generalized linear model:\n\nWhere formula_6 is a real-valued, monotonically increasing function that maps the values of the linear predictor formula_7 to the interval formula_8. GLM methods typically uses the logit or probit as the link function.\n\nWhile it's possible to estimate formula_9 using other statistical or machine learning methods, the requirements of simplicity and easy interpretation (and monotonicity per risk factor) make most of these methods difficult to use for scoring in this context:\n\nWhen using GLM, the set of estimated weights formula_4 can be used to assign different values (or \"points\") to different values of the risk factors in formula_3 (continuous or nominal as indicators). The score can then be expressed as a weighted sum:\n\n\nLet formula_16 denote a set of formula_17 \"escalating\" actions available for the decision maker (e.g. for credit risk decisions: formula_18 = \"approve automatically\", formula_19 = \"require more documentation and check manually\", formula_20 = \"decline automatically\"). In order to define a decision rule, we want to define a map between different values of the score and the possible decisions in formula_21. Let formula_22 be a partition of formula_23 into formula_24 consecutive, non-overlapping intervals, such that formula_25. \n\nThe map is defined as follows: \n\n\nSome notable examples, taken from the category page :\n\nThe primary use of scores in the financial sector is for Credit scorecards, or credit scores: \n\n"}
{"id": "56293715", "url": "https://en.wikipedia.org/wiki?curid=56293715", "title": "Ross-on-Wye weather station", "text": "Ross-on-Wye weather station\n\nThe Ross-on-Wye weather station is now a fully automated weather station, situated off the Walford Road in Ross-on-Wye, Herefordshire, England.\nThroughout the Second World War, it was the only volunteer run weather station to be accepted by the Met office. Every night throughout the conflict, it was the only land-locked station to be included in the shipping forecast on the World Service. The anecdotes goes that- even when in the Pacific- the soldiers from Ross would know exactly what the weather was like around at their mothers. Clement Grant Dixon, Physics teacher, Ross Grammar School, 1970.\n\nHenry Southall (1836-1916), set up a station at 'The Craig, Ross' in 1859. It was in 1860, after the loss of the Royal Charter in 1859, that Fitzroy (1805–1865) used the electric telegraph to transmit weather data so he might issue storm warnings and in 1861 issue weather forecasts. Importantly Ross was already operating. \n\nFrederick James Parsons arrived in Ross in 1912 having previously had his own amateur station when a child. He met up with Southall, and established his own station at Chase Dale in the Chase, Ross. In 1914 he was made a Fellow of Royal Meteorological Society but due to the outbreak of war he joined the Herefordshire Territorials and was transferred to the Royal Engineers as one of the first five meteorologists to be in the service. The station was maintained in his absence by the landowner, Mrs Purchase. On return he continued to take daily readings until 1964 when he was 72. \n\nFrom 1975 until 1985 the town was without a weather station, but on the initiative of the mayor, Arthur Clarke, it was reopened in May 1985. \n\nMore recently readings were taken by Howard Ellis, a retired chemist assisted by the husband and wife team, June and Rex Swallow. June Swallow took over the monitoring station in 1995 and continued to take readings until the Summer 2008 when she retired after 23 years.\nThe station was semi-automated but still needed volunteers to take some readings. \n\nIn October 2017 the station was fully automated.\n\nHenry Southall was a distinguished meteorologist, a Fellow of Royal Meteorological Society who served as its president. In December 1895, he read his paper on the \"Floods in the West Midlands\" in which he considered the great floods that had occurred on the rivers Severn, Wye, Usk andAvon. He took data from the River Wye at Ross. He used a rise of as measure of a 'primary flood'. He wrote that all the great floods occurred in November and February, and their frequency was decreasing. This he attributed to better drainage in the lower reaches and railway embankments and bridges holding back the surge from the upper reaches. He noted that rainfall had not decreased and he had taken the readings.\n\nThe floods at Ross were in \n\nThe station has these instruments:\n\n"}
{"id": "2219220", "url": "https://en.wikipedia.org/wiki?curid=2219220", "title": "Royal Society Bakerian Medal", "text": "Royal Society Bakerian Medal\n\nThe Bakerian Medal is one of the premier medals of the Royal Society that recognizes exceptional and outstanding science. It comes with a medal award and a prize lecture. The medalist is required to give a lecture on any topic related to physical sciences. It is awarded annually to individuals in the field of physical sciences, including computer science. \n\nThe prize was started in 1775, when Henry Baker left £100 to establish a spoken lecture given by a Fellow of the Royal Society \"on such part of natural history or experimental philosophy\" as the Society shall determine. Clearly, this is to deliver a lecture of scientific interests and importance, and encourage sharing of knowledge with others.\n\nSource: Royal Society\n\n\n\n\n\n"}
{"id": "860693", "url": "https://en.wikipedia.org/wiki?curid=860693", "title": "Spatial planning", "text": "Spatial planning\n\nSpatial planning systems refer to the methods and approaches used by the public and private sector to influence the distribution of people and activities in spaces of various scales. Spatial planning can be defined as the coordination of practices and policies affecting spatial organization. Spatial planning is synonymous with the practices of urban planning in the United States but at larger scales and the term is often used in reference to planning efforts in European countries. Discrete professional disciplines which involve spatial planning include land use, urban, regional, transport and environmental planning. Other related areas are also important, including economic and community planning. Spatial planning takes place on local, regional, national and inter-national levels and often results in the creation of a spatial plan.\n\nAn early definition of spatial planning comes from the European Regional/Spatial Planning Charter (often called the 'Torremolinos Charter'), adopted in 1983 by the European Conference of Ministers responsible for Regional Planning (CEMAT): \"\"Regional/spatial planning gives geographical expression to the economic, social, cultural and ecological policies of society. It is at the same time a scientific discipline, an administrative technique and a policy developed as an interdisciplinary and comprehensive approach directed towards a balanced regional development and the physical organisation of space according to an overall strategy\".\"\n\nNumerous planning systems exist around the world. The form of planning largely diverges and co-evolves with societies and their governance systems. Every country, and states within those countries, have a unique planning systems that is made up by different actors, different planning perspectives and a particular institutional framework. Perspectives, actors and institutions change over time, influencing both the form and the impact of spatial planning. Especially in Northwestern Europe spatial planning has evolved greatly since the late 1950s.\n\nVarious compendia of spatial planning systems can be found. Below is a table showing some of the main sources, the countries covered and the date of publication.\n\nIn 1999, a document called the European Spatial Development Perspective (ESDP) was signed by the ministers responsible for regional planning in the EU member states. Although the ESDP has no binding status, and the European Union has no formal authority for spatial planning, the ESDP has influenced spatial planning policy in European regions and member states, and placed the coordination of EU sectoral policies on the political agenda.\n\nAt the European level, the term territorial cohesion is becoming more widely used and is for example mentioned in the draft EU Treaty (Constitution) as a shared competency of the European Union; it is also included in the Treaty of Lisbon. The term was defined in a \"scoping document\" in Rotterdam in late 2004 and is being elaborated further using empirical data from the ESPON programme in a document entitled \"The Territorial State and Perspectives of the European Union\". At the minister's conference in May 2007 in Leipzig, a political document called the \"Territorial Agenda\" was signed to continue the process begun in Rotterdam, revised in May 2011 in Godollo.\n\n\n"}
{"id": "50597374", "url": "https://en.wikipedia.org/wiki?curid=50597374", "title": "Statistical alchemy", "text": "Statistical alchemy\n\nStatistical alchemy was a term originated by John Maynard Keynes to describe econometrics in 1939. The phrase has subsequently been used by Alvan Feinstein to describe meta-analysis. It is generally regarded as a deprecatory term which undermines attempts to present such activities as meeting the rigorous standards of science.\n\nKeynes (1939) wrote a review of Jan Tinbergen's \"Statistical Testing of Business-Cycle Theories\". Although he praised Tinbergen for his objectivity, he however depicted his methodology as \"black magic\" which he regarded as essentially untrustworthy. He was unpersuaded that \"this brand of \"statistical alchemy\" is ripe to become a branch of science\" (emphasis in the original).\n\nOften this metaphor is seen as a way of suggesting that econometricians were following a foolhardy pursuit comparable to the alchemical quest of turning base metal into gold. However G. M. P. Swann points out that Keynes was well aware that such eminent early scientists as Isaac Newton. He rather proposes a more nuanced interpretation of the metaphor as referring to the Alkahest, a universal solvent, which, it was claimed could turn stone into water. He claimed that by restricting econometrics to theory, mathematics and statistics, econometricians had discarded other important applied techniques. Although Ragnar Frisch had made warnings about this, these had been subsequently ignored by other econometricians who had ended up claiming that econometrics constituted a universal solvent.\n\nFeinstein (1995) published \"Meta-analysis: statistical alchemy for the 21st century\" where he claimed that in meta-analysis scientific requirements had been removed or destroyed, eliminating the scientific requirements of reproducibility and precision. This was equivalent to a \"free lunch\", comparable to the alchemical transmutation of base metals to gold. Detourning the adage concerning the combination of apples and oranges, Feinstein suggested that meta-analytic mixtures were so heterogeneous that they might be better described as \"combining rotten fruits\". He argues that meta-analysis violates the Bradford Hill criteria of consistency as inconsistencies are ignored or buried through the process of agglomerating the data.\n\n"}
{"id": "57328148", "url": "https://en.wikipedia.org/wiki?curid=57328148", "title": "Staying with the Trouble", "text": "Staying with the Trouble\n\nStaying with the Trouble: Making Kin in the Chthulucene is a 2016 book by Donna Haraway, published by Duke University Press. In it, Haraway offers \"making kin\" as a way to consider multiple species and interact in a multiple species world. \n\nBy emphasizing connectedness, \"Staying with the Trouble\" can be thought of as a continuation of major themes from \"A Cyborg Manifesto\" and \"The Companion Species Manifesto\". Haraway's book can also be thought of as a critique of the Anthropocene as a way of making sense of the present, de-emphasizing human exceptionalism in favor of multispecism.\n"}
{"id": "40773353", "url": "https://en.wikipedia.org/wiki?curid=40773353", "title": "Studia Socjologiczne", "text": "Studia Socjologiczne\n\nThe Studia Socjologiczne (Sociological Studies) is a quarterly peer-reviewed academic journal co-published by the Polish Academy of Sciences (PAN Institute of Philosophy and Sociology and the PAN Committee on Sociology) and the University of Warsaw. It covers various areas of sociology. The journal publishes articles in Polish and since 2012, English.\n\nThe journal was abstracted and indexed in the Social Sciences Citation Index up to 2012. According to the \"Journal Citation Reports\", the journal has a 2012 impact factor of 0.024, ranking it 138th out of 139 journals in the category \"Sociology\".\n"}
{"id": "27813", "url": "https://en.wikipedia.org/wiki?curid=27813", "title": "Systematics", "text": "Systematics\n\nBiological systematics is the study of the diversification of living forms, both past and present, and the relationships among living things through time. Relationships are visualized as evolutionary trees (synonyms: cladograms, phylogenetic trees, phylogenies). Phylogenies have two components: branching order (showing group relationships) and branch length (showing amount of evolution). Phylogenetic trees of species and higher taxa are used to study the evolution of traits (e.g., anatomical or molecular characteristics) and the distribution of organisms (biogeography). Systematics, in other words, is used to understand the evolutionary history of life on Earth.\n\nIn the study of biological systematics, researchers use the different branches to further understand the relationships between differing organisms. These branches are used to determine the applications and uses for modern day systematics.\n\nBiological systematics classifies species by using three specific branches. \"Numerical systematics\", or \"biometry\", uses biological statistics to identify and classify animals. \"Biochemical systematics\" classifies and identifies animals based on the analysis of the material that makes up the living part of a cell—such as the nucleus, organelles, and cytoplasm. \"Experimental systematics\" identifies and classifies animals based on the evolutionary units that comprise a species, as well as their importance in evolution itself. Factors such as mutations, genetic divergence, and hybridization all are considered evolutionary units.\n\nWith the specific branches, researchers are able to determine the applications and uses for modern-day systematics. These applications include: \n\nJohn Lindley provided an early definition of systematics in 1830, although he wrote of \"systematic botany\" rather than using the term \"systematics\".\n\nIn 1970 Michener \"et al.\" defined \"systematic biology\" and \"taxonomy\" (terms that are often confused and used interchangeably) in relationship to one another as follows:\nSystematic biology (hereafter called simply systematics) is the field that (a) provides scientific names for organisms, (b) describes them, (c) preserves collections of them, (d) provides classifications for the organisms, keys for their identification, and data on their distributions, (e) investigates their evolutionary histories, and (f) considers their environmental adaptations. This is a field with a long history that in recent years has experienced a notable renaissance, principally with respect to theoretical content. Part of the theoretical material has to do with evolutionary areas (topics e and f above), the rest relates especially to the problem of classification. Taxonomy is that part of Systematics concerned with topics (a) to (d) above.\nTaxonomy, systematic biology, systematics, biosystematics, scientific classification, biological classification, phylogenetics: At various times in history, all these words have had overlapping, related meanings. However, in modern usage, they can all be considered synonyms of each other.\n\nFor example, Webster's 9th New Collegiate Dictionary of 1987 treats \"classification\", \"taxonomy\", and \"systematics\" as synonyms. According to this work, the terms originated in 1790, c. 1828, and in 1888 respectively. Some claim systematics alone deals specifically with relationships through time, and that it can be synonymous with phylogenetics, broadly dealing with the inferred hierarchy of organisms. This means it would be a subset of taxonomy as it is sometimes regarded, but the inverse is claimed by others.\n\nEuropeans tend to use the terms \"systematics\" and \"biosystematics\" for the study of biodiversity as a whole, whereas North Americans tend to use \"taxonomy\" more frequently. However, taxonomy, and in particular alpha taxonomy, is more specifically the identification, description, and naming (i.e. nomenclature) of organisms,\nwhile \"classification\" focuses on placing organisms within hierarchical groups that show their relationships to other organisms. All of these biological disciplines can deal with both extinct and extant organisms.\n\nSystematics uses taxonomy as a primary tool in understanding, as nothing about an organism's relationships with other living things can be understood without it first being properly studied and described in sufficient detail to identify and classify it correctly. Scientific classifications are aids in recording and reporting information to other scientists and to laymen. The systematist, a scientist who specializes in systematics, must, therefore, be able to use existing classification systems, or at least know them well enough to skilfully justify not using them.\n\nPhenetics was an attempt to determine the relationships of organisms through a measure of overall similarity, making no distinction between plesiomorphies (shared ancestral traits) and apomorphies (derived traits). From the late-20th century onwards, it was superseded by cladistics, which rejects plesiomorphies in attempting to resolve the phylogeny of Earth's various organisms through time. systematists generally make extensive use of molecular biology and of computer programs to study organisms.\n\ntaxonomy is the study of classification and nomenclature but phylogenetic and evolutionary relations are studied in systematics.\n\nTaxonomic characters are the taxonomic attributes that can be used to provide the evidence from which relationships (the phylogeny) between taxa are inferred. Kinds of taxonomic characters:\n\n\nplant_systematics-iii/biosystematics/et/5905_et_21-biosystematics-et.pdf ..///^^Qprine/;'\n\n"}
{"id": "13483532", "url": "https://en.wikipedia.org/wiki?curid=13483532", "title": "Table of historic and prehistoric climate indicators", "text": "Table of historic and prehistoric climate indicators\n\nThis table is a reference tool for rapidly locating Wikipedia articles on Historic and Prehistoric climate indicators of all types.\n\nTo Add:\n"}
{"id": "35835795", "url": "https://en.wikipedia.org/wiki?curid=35835795", "title": "WISE J004945.61+215120.0", "text": "WISE J004945.61+215120.0\n\nWISE J004945.61+215120.0 is a brown dwarf of spectral class T8.5, located in constellation Andromeda at approximately 24 light-years from Earth.\n\nWISE J004945.61+215120.0 was discovered in 2012 by Mace et al. from data, collected by Wide-field Infrared Survey Explorer (WISE) Earth-orbiting satellite — NASA infrared-wavelength 40 cm (16 in) space telescope, which mission lasted from December 2009 to February 2011. In 2013, the discovery paper was published.\n\nTrigonometric parallax of WISE J004945.61+215120.0 is not yet measured. Therefore, there are only distance estimates of this object, obtained by indirect — spectrofotometric — means (see table).\n\nWISE J004945.61+215120.0 distance estimates\n"}
{"id": "2156689", "url": "https://en.wikipedia.org/wiki?curid=2156689", "title": "World Medical Association", "text": "World Medical Association\n\nThe World Medical Association (WMA) is an international and independent confederation of free professional medical associations, therefore representing physicians worldwide. WMA was formally established on September 18, 1947 and has grown in 2018 to 113 national medical associations and more than 10 million physicians.\n\nThe WMA provides a forum for its member associations to communicate freely, to co-operate actively, to achieve consensus on high standards of medical ethics and professional competence and to promote the professional freedom of physicians worldwide. With this unique partnership, WMA aims to facilitate high-caliber, humane care to patients in a healthy environment, enhancing the quality of life for all people in the world.\n\nThe purpose of the WMA is to serve humanity by endeavoring to achieve the highest international standards in Medical Education, Medical Science, Medical Art and Medical Ethics, and Health Care for all people in the world.\n\nThe WMA was founded on 18 September 1947, when physicians from 27 different countries met at the First General Assembly of the WMA in Paris. This organization was built from an idea born in the House of the British Medical Association in 1945, within a meeting organized in London to initiate plans for an international medical organization to replace l'Association Professionnelle Internationale des Médecins\", which had suspended its activities because of World War II.\n\nIn order to facilitate financial support from its member associations, in 1948, the executive board, known as the Council, established the Secretariat of the WMA in New York City in order to provide close liaison with the United Nations and its various agencies. The WMA Secretariat remained in New York City until 1974 when for reasons of economy, and in order to operate within the vicinity of Geneva-based international organizations (WHO, ILO, ICN, ISSA, etc.) it was transferred to its present location in Ferney-Voltaire, France.\nThe WMA members gathered in an annual meeting, which from 1962 was named \"World Medical Assembly.\"\n\nSince its beginning WMA has shown concern over the state of medical ethics in general and over the world, taking the responsibility for setting ethical guidelines for the world physicians. A modernized wording of the ancient oath of Hippocrates was sent for consideration at the II General Assembly in Geneva in 1948. The medical vow was adopted and the Assembly agreed to name it the \"Declaration of Geneva.\"\n\nAlso in the same II General Assembly a report on \"War Crimes and Medicine\" was received. This prompted the Council to appoint another Study Committee to prepare an International Code of Medical Ethics, which after an extensive discussion, was adopted in 1949 by the III General Assembly.\n\nEven after the adoption of these two documents, WMA was constantly being informed about violations of medical ethics, crimes committed by doctors in time of war, unethical human experimentation, among several other problems in the field of medical ethics and medical law. This information caused the Council to establish a permanent Committee on Medical Ethics in 1952, which has been working actively ever since, as one can see from the declarations or statements of the WMA and their continuous updates.\n\nDuring the World Medical Association General Assembly in Reykjavik in early October, members of the Canadian Medical Association stated that parts of the speech by WMA's incoming president Leonid Eidelman had been plagiarized from a speech made in 2014 by Chris Simpson (cardiologist) who was then the president of CMA. Current president Dr. Gigi Osler told the group that part of the address was \"copied word for word\" from Simpson's speech. \"Multiple other parts of the speech were also copied from various websites, blogs and news articles, without proper appropriate attribution to the authors\", she latter added in a statement. A motion by Canada at the Assembly to call on Eidelman to resign was not successful. On 6 October, the CMA resigned; their press release stated that the decision was made because WMA was not upholding ethical standards. \n\nIn an email to The Canadian Press, WMA spokesman Nigel Duncan said that Eidelman's speech had been written by others and that he did not know that it might contain plagiarism. A WMA source also told The Canadian Press that Eidelman apologized at the general assembly, after the Canadian delegates had departed; he \"acknowledge[d] that part of his speech was taken from Simpson\", and most delegates \"accepted his apology\" for the mistake.\n\nThe main decision-making body of the WMA is the General Assembly, which meets annually and is formed by delegations from the National Member Associations, officers and members of the Council of the WMA, and representatives of the Associate Members (Associate Members are individual physicians who wish to join the WMA).\n\nThe Assembly elects the WMA Council every two years with representatives drawn from each of the six WMA regions, namely Africa, Asia, Europe, Latin America, North America and the Pacific. It also elects the WMA president annually, who is the Ceremonial Head of the WMA. The President, President Elect and Immediate Past President form the Presidium that is available to speak for the WMA and represent it officially.\n\nEvery two years, the WMA Council, excluding the Presidium, elects a Chairperson who is the political head of the organization.\nAs Chief Executive of the operational units of the WMA, the Secretary-General is in full-time employment at the Secretariat, appointed by the WMA Council.\n\nThe WMA Secretariat is situated in Ferney-Voltaire, France, adjacent to the City of Geneva.\n\nEnglish, French, and Spanish are the official languages of the association since its creation.\n\nThe WMA have the following status of membership:\n\nSee more information on Membership by clicking on the following link (WMA Membership):\n\nThe WMA is active in several areas of action, but mainly in:\n\nIn what concerns Ethics, the WMA has various Declarations, Resolutions and Statements with which tries to help to guide National Medical Associations, governments and international organizations throughout the world. A wide range of subjects are covered like the rights of patients, research on human subjects, care of the sick and wounded in times of armed conflict, torture of prisoners, the use and abuse of drugs, family planning and pollution.\n\nWMA also works on:\n\nThe WMA also works on Education Programs such as the prison-medicine course, the MDR-TB and the TB refresher course, the ethics course and the course on microbial resistance (together with the George Mason University and the International Society for Microbial Resistance).\n\nAll WMA policy documents and publications (some in various languages) are available for free download on their website. These include:\n\nThe World Medical Association is embedded in a network of organizations ranging from medical societies and associations to organizations of commercial entities. While not all inclusive, this page provides an overview of the WMA's most important partnerships.\n\n\n\n\n\n\n\n\nThe WMA also has official relations with the World Health Organization (WHO), the United Nations as well as other UN bodies and specialized programs dealing directly with health problems.\n\nOther examples of relationships are the Joint United Nations Program on HIV / AIDS (UNAIDS), the International Labor Organization (ILO), the International Organization for Migration (IMO), the United Nations Children's Fund (UNICEF) The Food and Agriculture Organization of the United Nations (FAO), the United Nations High Commissioner for Refugees (UNHCR) and the United Nations Environment Program (UNEP).\n\n\n\n\n"}
