{"id": "8099272", "url": "https://en.wikipedia.org/wiki?curid=8099272", "title": "Acoustic contrast factor", "text": "Acoustic contrast factor\n\nThe acoustic contrast factor is a number used to describe the relationship between the densities and the sound velocities (or, equivalently because of the form of the expression, the densities and compressibilities) of two media. It is most often used in the context of biomedical ultrasonic imaging techniques using acoustic contrast agents and in the field of ultrasonic manipulation of particles much smaller than the wavelength using ultrasonic standing waves. In the latter context, the acoustic contrast factor is the number which, depending on its sign, tells whether a given type of particle in a given medium will be attracted to the pressure nodes or anti-nodes.\n\nGiven the compressibilities formula_1 and formula_2 and densities formula_3 and formula_4 of the medium and particle, respectively, the acoustic contrast factor formula_5 can be expressed as\n\nFor a positive value of formula_7, the particles will be attracted to the pressure nodes, and vice versa.\n\n"}
{"id": "1537", "url": "https://en.wikipedia.org/wiki?curid=1537", "title": "Acupuncture", "text": "Acupuncture\n\nAcupuncture is a form of alternative medicine in which thin needles are inserted into the body. It is a key component of traditional Chinese medicine (TCM). TCM theory and practice are not based upon scientific knowledge, and acupuncture is a pseudoscience. There is a diverse range of acupuncture theories based on different philosophies, and techniques vary depending on the country. The method used in TCM is probably the most widespread in the United States. It is most often used for pain relief, though it is also used for a wide range of other conditions. Acupuncture is generally used only in combination with other forms of treatment.\nThe conclusions of many trials and numerous systematic reviews of acupuncture are largely inconsistent, which suggests that it is not effective. An overview of Cochrane reviews found that acupuncture is not effective for a wide range of conditions. A systematic review found little evidence of acupuncture's effectiveness in treating pain. The evidence suggests that short-term treatment with acupuncture does not produce long-term benefits. Some research results suggest acupuncture can alleviate pain, though the majority of research suggests that acupuncture's effects are mainly due to the placebo effect. A systematic review concluded that the analgesic effect of acupuncture seemed to lack clinical relevance and could not be clearly distinguished from bias. A meta-analysis found that acupuncture for chronic low back pain was cost-effective as an adjunct to standard care, while a systematic review found insufficient evidence for the cost-effectiveness of acupuncture in the treatment of chronic low back pain.\n\nAcupuncture is generally safe when done by an appropriately trained practitioner using clean needle technique and single-use needles. When properly delivered, it has a low rate of mostly minor adverse effects. Accidents and infections are associated with infractions of sterile technique or neglect of the practitioner. A review stated that the reports of infection transmission increased significantly in the previous decade. The most frequently reported adverse events were pneumothorax and infections. Since serious adverse events continue to be reported, it is recommended that acupuncturists be trained sufficiently to reduce the risk.\nScientific investigation has not found any histological or physiological evidence for traditional Chinese concepts such as \"qi\", meridians, and acupuncture points, and many modern practitioners no longer support the existence of life force energy (\"qi\") flowing through meridians, which was a major part of early belief systems. Acupuncture is believed to have originated around 100 BC in China, around the time \"The Yellow Emperor's Classic of Internal Medicine\" (Huangdi Neijing) was published, though some experts suggest it could have been practiced earlier. Over time, conflicting claims and belief systems emerged about the effect of lunar, celestial and earthly cycles, yin and yang energies, and a body's \"rhythm\" on the effectiveness of treatment. Acupuncture grew and diminished in popularity in China repeatedly, depending on the country's political leadership and the favor of rationalism or Western medicine. Acupuncture spread first to Korea in the 6th century AD, then to Japan through medical missionaries, and then to Europe, starting with France. In the 20th century, as it spread to the United States and Western countries, the spiritual elements of acupuncture that conflict with Western beliefs were sometimes abandoned in favor of simply tapping needles into acupuncture points.\n\nAcupuncture is a form of alternative medicine. It is used most commonly for pain relief, though it is also used to treat a wide range of conditions. The majority of people who seek out acupuncture do so for musculoskeletal problems, including low back pain, shoulder stiffness, and knee pain. Acupuncture is generally only used in combination with other forms of treatment. For example, American Society of Anesthesiologists states it may be considered in the treatment for nonspecific, noninflammatory low back pain only in conjunction with conventional therapy.\n\nAcupuncture is the insertion of thin needles into the skin. According to the Mayo Foundation for Medical Education and Research (Mayo Clinic), a typical session entails lying still while approximately five to twenty needles are inserted; for the majority of cases, the needles will be left in place for ten to twenty minutes. It can be associated with the application of heat, pressure, or laser light. Classically, acupuncture is individualized and based on philosophy and intuition, and not on scientific research. There is also a non-invasive therapy developed in early 20th century Japan using an elaborate set of \"needles\" for the treatment of children (\"shōnishin\" or \"shōnihari\").\n\nClinical practice varies depending on the country. A comparison of the average number of patients treated per hour found significant differences between China (10) and the United States (1.2). Chinese herbs are often used. There is a diverse range of acupuncture approaches, involving different philosophies. Although various different techniques of acupuncture practice have emerged, the method used in traditional Chinese medicine (TCM) seems to be the most widely adopted in the US. Traditional acupuncture involves needle insertion, moxibustion, and cupping therapy, and may be accompanied by other procedures such as feeling the pulse and other parts of the body and examining the tongue. Traditional acupuncture involves the belief that a \"life force\" (\"qi\") circulates within the body in lines called meridians. The main methods practiced in the UK are TCM and Western medical acupuncture. The term Western medical acupuncture is used to indicate an adaptation of TCM-based acupuncture which focuses less on TCM. The Western medical acupuncture approach involves using acupuncture after a medical diagnosis. Limited research has compared the contrasting acupuncture systems used in various countries for determining different acupuncture points and thus there is no defined standard for acupuncture points.\n\nIn traditional acupuncture, the acupuncturist decides which points to treat by observing and questioning the patient to make a diagnosis according to the tradition used. In TCM, the four diagnostic methods are: inspection, auscultation and olfaction, inquiring, and palpation. Inspection focuses on the face and particularly on the tongue, including analysis of the tongue size, shape, tension, color and coating, and the absence or presence of teeth marks around the edge. Auscultation and olfaction involve listening for particular sounds such as wheezing, and observing body odor. Inquiring involves focusing on the \"seven inquiries\": chills and fever; perspiration; appetite, thirst and taste; defecation and urination; pain; sleep; and menses and leukorrhea. Palpation is focusing on feeling the body for tender \"A-shi\" points and feeling the pulse.\n\nThe most common mechanism of stimulation of acupuncture points employs penetration of the skin by thin metal needles, which are manipulated manually or the needle may be further stimulated by electrical stimulation (electroacupuncture). Acupuncture needles are typically made of stainless steel, making them flexible and preventing them from rusting or breaking. Needles are usually disposed of after each use to prevent contamination. Reusable needles when used should be sterilized between applications. Needles vary in length between , with shorter needles used near the face and eyes, and longer needles in areas with thicker tissues; needle diameters vary from 0 to 0, with thicker needles used on more robust patients. Thinner needles may be flexible and require tubes for insertion. The tip of the needle should not be made too sharp to prevent breakage, although blunt needles cause more pain.\n\nApart from the usual filiform needle, other needle types include three-edged needles and the Nine Ancient Needles. Japanese acupuncturists use extremely thin needles that are used superficially, sometimes without penetrating the skin, and surrounded by a guide tube (a 17th-century invention adopted in China and the West). Korean acupuncture uses copper needles and has a greater focus on the hand.\n\nThe skin is sterilized and needles are inserted, frequently with a plastic guide tube. Needles may be manipulated in various ways, including spinning, flicking, or moving up and down relative to the skin. Since most pain is felt in the superficial layers of the skin, a quick insertion of the needle is recommended. Often the needles are stimulated by hand in order to cause a dull, localized, aching sensation that is called \"de qi\", as well as \"needle grasp,\" a tugging feeling felt by the acupuncturist and generated by a mechanical interaction between the needle and skin. Acupuncture can be painful. The skill level of the acupuncturist may influence how painful the needle insertion is, and a sufficiently skilled practitioner may be able to insert the needles without causing any pain.\n\n\"De-qi\" (; \"arrival of qi\") refers to a sensation of numbness, distension, or electrical tingling at the needling site which might radiate along the corresponding meridian. If \"de-qi\" can not be generated, then inaccurate location of the acupoint, improper depth of needle insertion, inadequate manual manipulation, or a very weak constitution of the patient can be considered, all of which are thought to decrease the likelihood of successful treatment. If the \"de-qi\" sensation does not immediately occur upon needle insertion, various manual manipulation techniques can be applied to promote it (such as \"plucking\", \"shaking\" or \"trembling\").\n\nOnce \"de-qi\" is achieved, further techniques might be utilized which aim to \"influence\" the \"de-qi\"; for example, by certain manipulation the \"de-qi\" sensation allegedly can be conducted from the needling site towards more distant sites of the body. Other techniques aim at \"tonifying\" () or \"sedating\" () \"qi\". The former techniques are used in deficiency patterns, the latter in excess patterns. \"De qi\" is more important in Chinese acupuncture, while Western and Japanese patients may not consider it a necessary part of the treatment.\n\nAcupuncture has been researched extensively; as of 2013, there were almost 1,500 randomized controlled trials on PubMed with \"acupuncture\" in the title. The results of reviews of reviews of acupuncture's effectiveness, however, have been inconclusive.\n\nIt is difficult but not impossible to design rigorous research trials for acupuncture. Due to acupuncture's invasive nature, one of the major challenges in efficacy research is in the design of an appropriate placebo control group. For efficacy studies to determine whether acupuncture has specific effects, \"sham\" forms of acupuncture where the patient, practitioner, and analyst are blinded seem the most acceptable approach. Sham acupuncture uses non-penetrating needles or needling at non-acupuncture points, e.g. inserting needles on meridians not related to the specific condition being studied, or in places not associated with meridians. The under-performance of acupuncture in such trials may indicate that therapeutic effects are due entirely to non-specific effects, or that the sham treatments are not inert, or that systematic protocols yield less than optimal treatment.\n\nA 2014 review in \"Nature Reviews Cancer\" found that \"contrary to the claimed mechanism of redirecting the flow of \"qi\" through meridians, researchers usually find that it generally does not matter where the needles are inserted, how often (that is, no dose-response effect is observed), or even if needles are actually inserted. In other words, 'sham' or 'placebo' acupuncture generally produces the same effects as 'real' acupuncture and, in some cases, does better.\" A 2013 meta-analysis found little evidence that the effectiveness of acupuncture on pain (compared to sham) was modified by the location of the needles, the number of needles used, the experience or technique of the practitioner, or by the circumstances of the sessions. The same analysis also suggested that the number of needles and sessions is important, as greater numbers improved the outcomes of acupuncture compared to non-acupuncture controls. There has been little systematic investigation of which components of an acupuncture session may be important for any therapeutic effect, including needle placement and depth, type and intensity of stimulation, and number of needles used. The research seems to suggest that needles do not need to stimulate the traditionally specified acupuncture points or penetrate the skin to attain an anticipated effect (e.g. psychosocial factors).\n\nA response to \"sham\" acupuncture in osteoarthritis may be used in the elderly, but placebos have usually been regarded as deception and thus unethical. However, some physicians and ethicists have suggested circumstances for applicable uses for placebos such as it might present a theoretical advantage of an inexpensive treatment without adverse reactions or interactions with drugs or other medications. As the evidence for most types of alternative medicine such as acupuncture is far from strong, the use of alternative medicine in regular healthcare can present an ethical question.\n\nUsing the principles of evidence-based medicine to research acupuncture is controversial, and has produced different results. Some research suggests acupuncture can alleviate pain but the majority of research suggests that acupuncture's effects are mainly due to placebo. Evidence suggests that any benefits of acupuncture are short-lasting. There is insufficient evidence to support use of acupuncture compared to mainstream medical treatments. Acupuncture is not better than mainstream treatment in the long term.\n\nPublication bias is cited as a concern in the reviews of randomized controlled trials (RCTs) of acupuncture. A 1998 review of studies on acupuncture found that trials originating in China, Japan, Hong Kong, and Taiwan were uniformly favourable to acupuncture, as were ten out of eleven studies conducted in Russia. A 2011 assessment of the quality of RCTs on TCM, including acupuncture, concluded that the methodological quality of most such trials (including randomization, experimental control, and blinding) was generally poor, particularly for trials published in Chinese journals (though the quality of acupuncture trials was better than the trials testing TCM remedies). The study also found that trials published in non-Chinese journals tended to be of higher quality. Chinese authors use more Chinese studies, which have been demonstrated to be uniformly positive. A 2012 review of 88 systematic reviews of acupuncture published in Chinese journals found that less than half of these reviews reported testing for publication bias, and that the majority of these reviews were published in journals with impact factors of zero. A 2015 study comparing pre-registered records of acupuncture trials with their published results found that it was uncommon for such trials to be registered before the trial began. This study also found that selective reporting of results and changing outcome measures to obtain statistically significant results was common in this literature.\n\nScientist and journalist Steven Salzberg identifies acupuncture and Chinese medicine generally as a focus for \"fake medical journals\" such as the \"Journal of Acupuncture and Meridian Studies\" and \"Acupuncture in Medicine\".\n\nThe conclusions of many trials and numerous systematic reviews of acupuncture are largely inconsistent with each other. A 2011 systematic review of systematic reviews found that for reducing pain, real acupuncture was no better than sham acupuncture, and concluded that numerous reviews have shown little convincing evidence that acupuncture is an effective treatment for reducing pain. The same review found that neck pain was one of only four types of pain for which a positive effect was suggested, but cautioned that the primary studies used carried a considerable risk of bias. A 2009 overview of Cochrane reviews found acupuncture is not effective for a wide range of conditions.\n\nA 2014 systematic review suggests that the nocebo effect of acupuncture is clinically relevant and that the rate of adverse events may be a gauge of the nocebo effect. According to the 2014 \"Miller's Anesthesia\" book, \"when compared with placebo, acupuncture treatment has proven efficacy for relieving pain\". A 2012 meta-analysis conducted by the Acupuncture Trialists' Collaboration found \"relatively modest\" efficiency of acupuncture (in comparison to sham) for the treatment of four different types of chronic pain (back and neck pain, knee osteoarthritis, chronic headache, and shoulder pain) and on that basis concluded that it \"is more than a placebo\" and a reasonable referral option. Commenting on this meta-analysis, both Edzard Ernst and David Colquhoun said the results were of negligible clinical significance. Edzard Ernst later stated that \"I fear that, once we manage to eliminate this bias [that operators are not blind] … we might find that the effects of acupuncture exclusively are a placebo response.\" In 2017, the same research group updated their previous meta-analysis and again found acupuncture to be superior to sham acupuncture for non-specific musculoskeletal pain, osteoarthritis, chronic headache, and shoulder pain. They also found that the effects of acupuncture decreased by about 15% after one year.\n\nA 2010 systematic review suggested that acupuncture is more than a placebo for commonly occurring chronic pain conditions, but the authors acknowledged that it is still unknown if the overall benefit is clinically meaningful or cost-effective. A 2010 review found real acupuncture and sham acupuncture produce similar improvements, which can only be accepted as evidence against the efficacy of acupuncture. The same review found limited evidence that real acupuncture and sham acupuncture appear to produce biological differences despite similar effects. A 2009 systematic review and meta-analysis found that acupuncture had a small analgesic effect, which appeared to lack any clinical importance and could not be discerned from bias. The same review found that it remains unclear whether acupuncture reduces pain independent of a psychological impact of the needling ritual. A 2017 systematic review and meta-analysis found that ear acupuncture may be effective at reducing pain within 48 hours of its use, but the mean difference between the acupuncture and control groups was small.\n\nA 2013 systematic review found that acupuncture may be effective for nonspecific lower back pain, but the authors noted there were limitations in the studies examined, such as heterogeneity in study characteristics and low methodological quality in many studies. A 2012 systematic review found some supporting evidence that acupuncture was more effective than no treatment for chronic non-specific low back pain; the evidence was conflicting comparing the effectiveness over other treatment approaches. A 2011 systematic review of systematic reviews found that \"for chronic low back pain, individualized acupuncture is not better in reducing symptoms than formula acupuncture or sham acupuncture with a toothpick that does not penetrate the skin.\" A 2010 review found that sham acupuncture was as effective as real acupuncture for chronic low back pain. The specific therapeutic effects of acupuncture were small, whereas its clinically relevant benefits were mostly due to contextual and psychosocial circumstances. Brain imaging studies have shown that traditional acupuncture and sham acupuncture differ in their effect on limbic structures, while at the same time showed equivalent analgesic effects. A 2005 Cochrane review found insufficient evidence to recommend for or against either acupuncture or dry needling for acute low back pain. The same review found low quality evidence for pain relief and improvement compared to no treatment or sham therapy for chronic low back pain only in the short term immediately after treatment. The same review also found that acupuncture is not more effective than conventional therapy and other alternative medicine treatments. A 2017 systematic review and meta-analysis concluded that, for neck pain, acupuncture was comparable in effectiveness to conventional treatment, while electroacupuncture was even more effective in reducing pain than was conventional acupuncture. The same review noted that \"It is difficult to draw conclusion [sic] because the included studies have a high risk of bias and imprecision.\" A 2015 overview of systematic reviews of variable quality showed that acupuncture can provide short-term improvements to people with chronic Low Back Pain. The overview said this was true when acupuncture was used either in isolation or in addition to conventional therapy. A 2017 systematic review for an American College of Physicians clinical practice guideline found low to moderate evidence that acupuncture was effective for chronic low back pain, and limited evidence that it was effective for acute low back pain. The same review found that the strength of the evidence for both conditions was low to moderate. Another 2017 clinical practice guideline, this one produced by the Danish Health Authority, recommended against acupuncture for both recent-onset low back pain and lumbar radiculopathy.\n\nTwo separate 2016 Cochrane reviews found that acupuncture could be useful in the prophylaxis of tension-type headaches and episodic migraines. The 2016 Cochrane review evaluating acupuncture for episodic migraine prevention concluded that true acupuncture had a small effect beyond sham acupuncture and found moderate-quality evidence to suggest that acupuncture is at least similarly effective to prophylactic medications for this purpose. A 2012 review found that acupuncture has demonstrated benefit for the treatment of headaches, but that safety needed to be more fully documented in order to make any strong recommendations in support of its use.\n\nA 2014 review concluded that \"current evidence supports the use of acupuncture as an alternative to traditional analgesics in osteoarthritis patients.\" , a meta-analysis showed that acupuncture may help osteoarthritis pain but it was noted that the effects were insignificant in comparison to sham needles. A 2013 systematic review and network meta-analysis found that the evidence suggests that acupuncture may be considered one of the more effective physical treatments for alleviating pain due to knee osteoarthritis in the short-term compared to other relevant physical treatments, though much of the evidence in the topic is of poor quality and there is uncertainty about the efficacy of many of the treatments. A 2012 review found \"the potential beneficial action of acupuncture on osteoarthritis pain does not appear to be clinically relevant.\" A 2010 Cochrane review found that acupuncture shows statistically significant benefit over sham acupuncture in the treatment of peripheral joint osteoarthritis; however, these benefits were found to be so small that their clinical significance was doubtful, and \"probably due at least partially to placebo effects from incomplete blinding\".\n\nA 2013 Cochrane review found low to moderate evidence that acupuncture improves pain and stiffness in treating people with fibromyalgia compared with no treatment and standard care. A 2012 review found \"there is insufficient evidence to recommend acupuncture for the treatment of fibromyalgia.\" A 2010 systematic review found a small pain relief effect that was not apparently discernible from bias; acupuncture is not a recommendable treatment for the management of fibromyalgia on the basis of this review.\n\nA 2012 review found that the effectiveness of acupuncture to treat rheumatoid arthritis is \"sparse and inconclusive.\" A 2005 Cochrane review concluded that acupuncture use to treat rheumatoid arthritis \"has no effect on ESR, CRP, pain, patient's global assessment, number of swollen joints, number of tender joints, general health, disease activity and reduction of analgesics.\" A 2010 overview of systematic reviews found insufficient evidence to recommend acupuncture in the treatment of most rheumatic conditions, with the exceptions of osteoarthritis, low back pain, and lateral elbow pain.\n\nA 2014 systematic review found that although manual acupuncture was effective at relieving short-term pain when used to treat tennis elbow, its long-term effect in relieving pain was \"unremarkable\". A 2007 review found that acupuncture was significantly better than sham acupuncture at treating chronic knee pain; the evidence was not conclusive due to the lack of large, high-quality trials. A 2005 Cochrane Review concluded that there is not enough evidence to determine if acupuncture is effective as a method to treat shoulder pain.\n\nA 2014 overview of systematic reviews found insufficient evidence to suggest that acupuncture is an effective treatment for postoperative nausea and vomiting (PONV) in a clinical setting. A 2013 systematic review concluded that acupuncture might be beneficial in prevention and treatment of PONV. A 2015 Cochrane review found moderate-quality evidence of no difference between stimulation of the P6 acupoint on the wrist and antiemetic drugs for preventing PONV. A new finding of the review was that further comparative trials are futile, based on the conclusions of a trial sequential analysis. Whether combining PC6 acupoint stimulation with antiemetics is effective was inconclusive.\n\nA 2014 overview of systematic reviews found insufficient evidence to suggest that acupuncture is effective for surgical or post-operative pain. For the use of acupuncture for post-operative pain, there was contradictory evidence. A 2014 systematic review found supportive but limited evidence for use of acupuncture for acute post-operative pain after back surgery. A 2014 systematic review found that while the evidence suggested acupuncture could be an effective treatment for postoperative gastroparesis, a firm conclusion could not be reached because the trials examined were of low quality.\n\nA 2015 Cochrane review found that there is insufficient evidence to determine whether acupuncture is an effective treatment for cancer pain in adults. A 2014 systematic review published in the Chinese Journal of Integrative Medicine found that acupuncture may be effective as an adjunctive treatment to palliative care for cancer patients. A 2013 overview of reviews published in the Journal of Multinational Association for Supportive Care in Cancer found evidence that acupuncture could be beneficial for people with cancer-related symptoms, but also identified few rigorous trials and high heterogeneity between trials. A 2012 systematic review of randomised clinical trials published in the same journal found that the number and quality of RCTs for using acupuncture in the treatment of cancer pain was too low to draw definite conclusions.\n\nA 2014 systematic review reached inconclusive results with regard to the effectiveness of acupuncture for treating cancer-related fatigue. A 2013 systematic review found that acupuncture is an acceptable adjunctive treatment for chemotherapy-induced nausea and vomiting, but that further research with a low risk of bias is needed. A 2013 systematic review found that the quantity and quality of available RCTs for analysis were too low to draw valid conclusions for the effectiveness of acupuncture for cancer-related fatigue.\n\nA 2016 systematic review and meta-analysis found that acupuncture was \"associated with a significant reduction in sleep disturbances in women experiencing menopause-related sleep disturbances.\"\n\nFor the following conditions, the Cochrane Collaboration or other reviews have concluded there is no strong evidence of benefit:\n\nA 2010 overview of systematic reviews found that moxibustion was effective for several conditions but the primary studies were of poor quality, so there persists ample uncertainty, which limits the conclusiveness of their findings.\n\nAcupuncture is generally safe when administered by an experienced, appropriately trained practitioner using clean-needle technique and sterile single-use needles. When improperly delivered it can cause adverse effects. Accidents and infections are associated with infractions of sterile technique or neglect on the part of the practitioner. To reduce the risk of serious adverse events after acupuncture, acupuncturists should be trained sufficiently. People with serious spinal disease, such as cancer or infection, are not good candidates for acupuncture. Contraindications to acupuncture (conditions that should not be treated with acupuncture) include coagulopathy disorders (e.g. hemophilia and advanced liver disease), warfarin use, severe psychiatric disorders (e.g. psychosis), and skin infections or skin trauma (e.g. burns). Further, electroacupuncture should be avoided at the spot of implanted electrical devices (such as pacemakers).\n\nA 2011 systematic review of systematic reviews (internationally and without language restrictions) found that serious complications following acupuncture continue to be reported. Between 2000 and 2009, ninety-five cases of serious adverse events, including five deaths, were reported. Many such events are not inherent to acupuncture but are due to malpractice of acupuncturists. This might be why such complications have not been reported in surveys of adequately-trained acupuncturists. Most such reports originate from Asia, which may reflect the large number of treatments performed there or a relatively higher number of poorly trained Asian acupuncturists. Many serious adverse events were reported from developed countries. These included Australia, Austria, Canada, Croatia, France, Germany, Ireland, the Netherlands, New Zealand, Spain, Sweden, Switzerland, the UK, and the US. The number of adverse effects reported from the UK appears particularly unusual, which may indicate less under-reporting in the UK than other countries. Reports included 38 cases of infections and 42 cases of organ trauma. The most frequent adverse events included pneumothorax, and bacterial and viral infections.\n\nA 2013 review found (without restrictions regarding publication date, study type or language) 295 cases of infections; mycobacterium was the pathogen in at least 96%. Likely sources of infection include towels, hot packs or boiling tank water, and reusing reprocessed needles. Possible sources of infection include contaminated needles, reusing personal needles, a person's skin containing mycobacterium, and reusing needles at various sites in the same person. Although acupuncture is generally considered a safe procedure, a 2013 review stated that the reports of infection transmission increased significantly in the prior decade, including those of mycobacterium. Although it is recommended that practitioners of acupuncture use disposable needles, the reuse of sterilized needles is still permitted. It is also recommended that thorough control practices for preventing infection be implemented and adapted.\n\nA 2013 systematic review of the English-language case reports found that serious adverse events associated with acupuncture are rare, but that acupuncture is not without risk. Between 2000 and 2011 the English-language literature from 25 countries and regions reported 294 adverse events. The majority of the reported adverse events were relatively minor, and the incidences were low. For example, a prospective survey of 34,000 acupuncture treatments found no serious adverse events and 43 minor ones, a rate of 1.3 per 1000 interventions. Another survey found there were 7.1% minor adverse events, of which 5 were serious, amid 97,733 acupuncture patients. The most common adverse effect observed was infection (e.g. mycobacterium), and the majority of infections were bacterial in nature, caused by skin contact at the needling site. Infection has also resulted from skin contact with unsterilized equipment or with dirty towels in an unhygienic clinical setting. Other adverse complications included five reported cases of spinal cord injuries (e.g. migrating broken needles or needling too deeply), four brain injuries, four peripheral nerve injuries, five heart injuries, seven other organ and tissue injuries, bilateral hand edema, epithelioid granuloma, pseudolymphoma, argyria, pustules, pancytopenia, and scarring due to hot-needle technique. Adverse reactions from acupuncture, which are unusual and uncommon in typical acupuncture practice, included syncope, galactorrhoea, bilateral nystagmus, pyoderma gangrenosum, hepatotoxicity, eruptive lichen planus, and spontaneous needle migration.\n\nA 2013 systematic review found 31 cases of vascular injuries caused by acupuncture, three resulting in death. Two died from pericardial tamponade and one was from an aortoduodenal fistula. The same review found vascular injuries were rare, bleeding and pseudoaneurysm were most prevalent. A 2011 systematic review (without restriction in time or language), aiming to summarize all reported case of cardiac tamponade after acupuncture, found 26 cases resulting in 14 deaths, with little doubt about causality in most fatal instances. The same review concluded cardiac tamponade was a serious, usually fatal, though theoretically avoidable complication following acupuncture, and urged training to minimize risk.\n\nA 2012 review found a number of adverse events were reported after acupuncture in the UK's National Health Service (NHS) but most (95%) were not severe, though miscategorization and under-reporting may alter the total figures. From January 2009 to December 2011, 468 safety incidents were recognized within the NHS organizations. The adverse events recorded included retained needles (31%), dizziness (30%), loss of consciousness/unresponsive (19%), falls (4%), bruising or soreness at needle site (2%), pneumothorax (1%) and other adverse side effects (12%). Acupuncture practitioners should know, and be prepared to be responsible for, any substantial harm from treatments. Some acupuncture proponents argue that the long history of acupuncture suggests it is safe. However, there is an increasing literature on adverse events (e.g. spinal-cord injury).\n\nAcupuncture seems to be safe in people getting anticoagulants, assuming needles are used at the correct location and depth. Studies are required to verify these findings. The evidence suggests that acupuncture might be a safe option for people with allergic rhinitis.\n\nA 2010 systematic review of the Chinese-language literature found numerous acupuncture-related adverse events, including pneumothorax, fainting, subarachnoid hemorrhage, and infection as the most frequent, and cardiovascular injuries, subarachnoid hemorrhage, pneumothorax, and recurrent cerebral hemorrhage as the most serious, most of which were due to improper technique. Between 1980 and 2009, the Chinese-language literature reported 479 adverse events. Prospective surveys show that mild, transient acupuncture-associated adverse events ranged from 6.71% to 15%. In a study with 190,924 patients, the prevalence of serious adverse events was roughly 0.024%. Another study showed a rate of adverse events requiring specific treatment of 2.2%, 4,963 incidences among 229,230 patients. Infections, mainly hepatitis, after acupuncture are reported often in English-language research, though are rarely reported in Chinese-language research, making it plausible that acupuncture-associated infections have been underreported in China. Infections were mostly caused by poor sterilization of acupuncture needles. Other adverse events included spinal epidural hematoma (in the cervical, thoracic and lumbar spine), chylothorax, injuries of abdominal organs and tissues, injuries in the neck region, injuries to the eyes, including orbital hemorrhage, traumatic cataract, injury of the oculomotor nerve and retinal puncture, hemorrhage to the cheeks and the hypoglottis, peripheral motor-nerve injuries and subsequent motor dysfunction, local allergic reactions to metal needles, stroke, and cerebral hemorrhage after acupuncture.\n\nA causal link between acupuncture and the adverse events cardiac arrest, pyknolepsy, shock, fever, cough, thirst, aphonia, leg numbness, and sexual dysfunction remains uncertain. The same review concluded that acupuncture can be considered inherently safe when practiced by properly trained practitioners, but the review also stated there is a need to find effective strategies to minimize the health risks. Between 1999 and 2010, the Republic of Korean-literature contained reports of 1104 adverse events. Between the 1980s and 2002, the Japanese-language literature contained reports of 150 adverse events.\n\nAlthough acupuncture has been practiced for thousands of years in China, its use in pediatrics in the United States did not become common until the early 2000s. In 2007, the National Health Interview Survey (NHIS) conducted by the National Center For Health Statistics (NCHS) estimated that approximately 150,000 children had received acupuncture treatment for a variety of conditions.\n\nIn 2008 a study determined that the use of acupuncture-needle treatment on children was \"questionable\" due to the possibility of adverse side-effects and the pain manifestation differences in children versus adults. The study also includes warnings against practicing acupuncture on infants, as well as on children who are over-fatigued, very weak, or have over-eaten.\n\nWhen used on children, acupuncture is considered safe when administered by well-trained, licensed practitioners using sterile needles; however, a 2011 review found there was limited research to draw definite conclusions about the overall safety of pediatric acupuncture. The same review found 279 adverse events, 25 of them serious. The adverse events were mostly mild in nature (e.g. bruising or bleeding). The prevalence of mild adverse events ranged from 10.1% to 13.5%, an estimated 168 incidences among 1,422 patients. On rare occasions adverse events were serious (e.g. cardiac rupture or hemoptysis); many might have been a result of substandard practice. The incidence of serious adverse events was 5 per one million, which included children and adults.\n\nWhen used during pregnancy, the majority of adverse events caused by acupuncture were mild and transient, with few serious adverse events. The most frequent mild adverse event was needling or unspecified pain, followed by bleeding. Although two deaths (one stillbirth and one neonatal death) were reported, there was a lack of acupuncture-associated maternal mortality. Limiting the evidence as certain, probable or possible in the causality evaluation, the estimated incidence of adverse events following acupuncture in pregnant women was 131 per 10,000.\nAlthough acupuncture is not contraindicated in pregnant women, some specific acupuncture points are particularly sensitive to needle insertion; these spots, as well as the abdominal region, should be avoided during pregnancy.\n\nFour adverse events associated with moxibustion were bruising, burns and cellulitis, spinal epidural abscess, and large superficial basal cell carcinoma. Ten adverse events were associated with cupping. The minor ones were keloid scarring, burns, and bullae; the serious ones were acquired hemophilia A, stroke following cupping on the back and neck, factitious panniculitis, reversible cardiac hypertrophy, and iron deficiency anemia.\n\nA 2013 meta-analysis found that acupuncture for chronic low back pain was cost-effective as a complement to standard care, but not as a substitute for standard care except in cases where comorbid depression presented. The same meta-analysis found there was no difference between sham and non-sham acupuncture. A 2011 systematic review found insufficient evidence for the cost-effectiveness of acupuncture in the treatment of chronic low back pain. A 2010 systematic review found that the cost-effectiveness of acupuncture could not be concluded. A 2012 review found that acupuncture seems to be cost-effective for some pain conditions.\n\nAs with other alternative medicines, unethical or naïve practitioners may induce patients to exhaust financial resources by pursuing ineffective treatment. Professional ethics codes set by accrediting organizations such as the National Certification Commission for Acupuncture and Oriental Medicine require practitioners to make \"timely referrals to other health care professionals as may be appropriate.\" Stephen Barrett states that there is a \"risk that an acupuncturist whose approach to diagnosis is not based on scientific concepts will fail to diagnose a dangerous condition\".\n\nAcupuncture is a substantial part of traditional Chinese medicine (TCM). Early acupuncture beliefs relied on concepts that are common in TCM, such as a life force energy called \"qi\". \"Qi\" was believed to flow from the body's primary organs (zang-fu organs) to the \"superficial\" body tissues of the skin, muscles, tendons, bones, and joints, through channels called meridians. Acupuncture points where needles are inserted are mainly (but not always) found at locations along the meridians. Acupuncture points not found along a meridian are called extraordinary points and those with no designated site are called \"A-shi\" points.\n\nIn TCM, disease is generally perceived as a disharmony or imbalance in energies such as yin, yang, \"qi\", xuĕ, zàng-fǔ, meridians, and of the interaction between the body and the environment. Therapy is based on which \"pattern of disharmony\" can be identified. For example, some diseases are believed to be caused by meridians being invaded with an excess of wind, cold, and damp. In order to determine which pattern is at hand, practitioners examine things like the color and shape of the tongue, the relative strength of pulse-points, the smell of the breath, the quality of breathing, or the sound of the voice. TCM and its concept of disease does not strongly differentiate between the cause and effect of symptoms.\n\nScientific research has not supported the existence of \"qi\", meridians, or yin and yang. A \"Nature\" editorial described TCM as \"fraught with pseudoscience\", with the majority of its treatments having no logical mechanism of action. Quackwatch states that \"TCM theory and practice are not based upon the body of knowledge related to health, disease, and health care that has been widely accepted by the scientific community. TCM practitioners disagree among themselves about how to diagnose patients and which treatments should go with which diagnoses. Even if they could agree, the TCM theories are so nebulous that no amount of scientific study will enable TCM to offer rational care.\"\n\nSome modern practitioners support the use of acupuncture to treat pain, but have abandoned the use of \"qi\", meridians, \"yin\", \"yang\" and other energies based in mysticism as explanatory frameworks. The use of \"qi\" as an explanatory framework has been decreasing in China, even as it becomes more prominent during discussions of acupuncture in the US. Academic discussions of acupuncture still make reference to pseudoscientific concepts such as \"qi\" and meridians despite the lack of scientific evidence. Many within the scientific community consider attempts to rationalize acupuncture in science to be quackery, pseudoscience and \"theatrical placebo\". Academics Massimo Pigliucci and Maarten Boudry describe it as a \"borderlands science\" lying between science and pseudoscience.\n\nMany acupuncturists attribute pain relief to the release of endorphins when needles penetrate, but no longer support the idea that acupuncture can affect a disease. It is a generally held belief within the acupuncture community that acupuncture points and meridians structures are special conduits for electrical signals, but no research has established any consistent anatomical structure or function for either acupuncture points or meridians. Human tests to determine whether electrical continuity was significantly different near meridians than other places in the body have been inconclusive.\n\nSome studies suggest acupuncture causes a series of events within the central nervous system, and that it is possible to inhibit acupuncture's analgesic effects with the opioid antagonist naloxone. Mechanical deformation of the skin by acupuncture needles appears to result in the release of adenosine. The anti-nociceptive effect of acupuncture may be mediated by the adenosine A1 receptor. A 2014 review in \"Nature Reviews Cancer\" found that since the key mouse studies that suggested acupuncture relieves pain via the local release of adenosine, which then triggered nearby A1 receptors \"caused more tissue damage and inflammation relative to the size of the animal in mice than in humans, such studies unnecessarily muddled a finding that local inflammation can result in the local release of adenosine with analgesic effect.\"\n\nIt has been proposed that acupuncture's effects in gastrointestinal disorders may relate to its effects on the parasympathetic and sympathetic nervous system, which have been said to be the \"Western medicine\" equivalent of \"yin and yang\". Another mechanism whereby acupuncture may be effective for gastrointestinal dysfunction involves the promotion of gastric peristalsis in subjects with low initial gastric motility, and suppressing peristalsis in subjects with active initial motility. Acupuncture has also been found to exert anti-inflammatory effects, which may be mediated by the activation of the vagus nerve and deactivation of inflammatory macrophages. Neuroimaging studies suggest that acupuncture stimulation results in deactivation of the limbic brain areas and the default mode network.\n\nAcupuncture, along with moxibustion, is one of the oldest practices of traditional Chinese medicine. Most historians believe the practice began in China, though there are some conflicting narratives on when it originated. Academics David Ramey and Paul Buell said the exact date acupuncture was founded depends on the extent dating of ancient texts can be trusted and the interpretation of what constitutes acupuncture.\n\nAccording to an article in \"Rheumatology\", the first documentation of an \"organized system of diagnosis and treatment\" for acupuncture was in \"The Yellow Emperor's Classic of Internal Medicine\" (Huangdi Neijing) from about 100 BC. Gold and silver needles found in the tomb of Liu Sheng from around 100 BC are believed to be the earliest archeological evidence of acupuncture, though it is unclear if that was their purpose. According to Plinio Prioreschi, the earliest known historical record of acupuncture is the Shih-Chi (\"Record of History\"), written by a historian around 100 BC. It is believed that this text was documenting what was established practice at that time.\n\nThe 5,000-year-old mummified body of Ötzi the Iceman was found with 15 groups of tattoos, many of which were located at points on the body where acupuncture needles are used for abdominal or lower back problems. Evidence from the body suggests Otzi suffered from these conditions. This has been cited as evidence that practices similar to acupuncture may have been practiced elsewhere in Eurasia during the early Bronze Age; however, \"The Oxford Handbook of the History of Medicine\" calls this theory \"speculative\". It is considered unlikely that acupuncture was practiced before 2000 BC. The Ötzi the Iceman's tattoo marks suggest to some experts that an acupuncture-like treatment was previously used in Europe 5 millennia ago.\n\nAcupuncture may have been practiced during the Neolithic era, near the end of the stone age, using sharpened stones called Bian shi. Many Chinese texts from later eras refer to sharp stones called \"plen\", which means \"stone probe\", that may have been used for acupuncture purposes. The ancient Chinese medical text, Huangdi Neijing, indicates that sharp stones were believed at-the-time to cure illnesses at or near the body's surface, perhaps because of the short depth a stone could penetrate. However, it is more likely that stones were used for other medical purposes, such as puncturing a growth to drain its pus. The \"Mawangdui\" texts, which are believed to be from the 2nd century BC, mention the use of pointed stones to open abscesses, and moxibustion, but not for acupuncture. It is also speculated that these stones may have been used for bloodletting, due to the ancient Chinese belief that illnesses were caused by demons within the body that could be killed or released. It is likely bloodletting was an antecedent to acupuncture.\n\nAccording to historians Lu Gwei-djen and Joseph Needham, there is substantial evidence that acupuncture may have begun around 600 BC. Some hieroglyphs and pictographs from that era suggests acupuncture and moxibustion were practiced. However, historians Gwei-djen and Needham said it was unlikely a needle could be made out of the materials available in China during this time period. It is possible that bronze was used for early acupuncture needles. Tin, copper, gold and silver are also possibilities, though they are considered less likely, or to have been used in fewer cases. If acupuncture was practiced during the Shang dynasty (1766 to 1122 BC), organic materials like thorns, sharpened bones, or bamboo may have been used. Once methods for producing steel were discovered, it would replace all other materials, since it could be used to create a very fine, but sturdy needles. Gwei-djen and Needham noted that all the ancient materials that could have been used for acupuncture and which often produce archeological evidence, such as sharpened bones, bamboo or stones, were also used for other purposes. An article in \"Rheumatology\" said that the absence of any mention of acupuncture in documents found in the tomb of Ma-Wang-Dui from 198 BC suggest that acupuncture was not practiced by that time.\n\nSeveral different and sometimes conflicting belief systems emerged regarding acupuncture. This may have been the result of competing schools of thought. Some ancient texts referred to using acupuncture to cause bleeding, while others mixed the ideas of blood-letting and spiritual ch'i energy. Over time, the focus shifted from blood to the concept of puncturing specific points on the body, and eventually to balancing Yin and Yang energies as well. According to David Ramey, no single \"method or theory\" was ever predominantly adopted as the standard. At the time, scientific knowledge of medicine was not yet developed, especially because in China dissection of the deceased was forbidden, preventing the development of basic anatomical knowledge.\n\nIt is not certain when specific acupuncture points were introduced, but the autobiography of Pien Chhio from around 400–500 BC references inserting needles at designated areas. Bian Que believed there was a single acupuncture point at the top of one's skull that he called the point \"of the hundred meetings.\" Texts dated to be from 156–186 BC document early beliefs in channels of life force energy called meridians that would later be an element in early acupuncture beliefs.\n\nRamey and Buell said the \"practice and theoretical underpinnings\" of modern acupuncture were introduced in \"The Yellow Emperor's Classic\" (Huangdi Neijing) around 100 BC. It introduced the concept of using acupuncture to manipulate the flow of life energy (\"qi\") in a network of meridian (channels) in the body. The network concept was made up of acu-tracts, such as a line down the arms, where it said acupoints were located. Some of the sites acupuncturists use needles at today still have the same names as those given to them by the \"Yellow Emperor's Classic\". Numerous additional documents were published over the centuries introducing new acupoints. By the 4th century AD, most of the acupuncture sites in use today had been named and identified.\n\nIn the first half of the 1st century AD, acupuncturists began promoting the belief that acupuncture's effectiveness was influenced by the time of day or night, the lunar cycle, and the season. The Science of the Yin-Yang Cycles (\"Yün Chhi Hsüeh\") was a set of beliefs that curing diseases relied on the alignment of both heavenly (thien) and earthly (ti) forces that were attuned to cycles like that of the sun and moon. There were several different belief systems that relied on a number of celestial and earthly bodies or elements that rotated and only became aligned at certain times. According to Needham and Gwei-djen, these \"arbitrary predictions\" were depicted by acupuncturists in complex charts and through a set of special terminology.\n\nAcupuncture needles during this period were much thicker than most modern ones and often resulted in infection. Infection is caused by a lack of sterilization, but at that time it was believed to be caused by use of the wrong needle, or needling in the wrong place, or at the wrong time. Later, many needles were heated in boiling water, or in a flame. Sometimes needles were used while they were still hot, creating a cauterizing effect at the injection site. Nine needles were recommended in the \"Chen Chiu Ta Chheng\" from 1601, which may have been because of an ancient Chinese belief that nine was a magic number.\n\nOther belief systems were based on the idea that the human body operated on a rhythm and acupuncture had to be applied at the right point in the rhythm to be effective. In some cases a lack of balance between Yin and Yang were believed to be the cause of disease.\n\nIn the 1st century AD, many of the first books about acupuncture were published and recognized acupuncturist experts began to emerge. The \"Zhen Jiu Jia Yi Jing\", which was published in the mid-3rd century, became the oldest acupuncture book that is still in existence in the modern era. Other books like the \"Yu Kuei Chen Ching\", written by the Director of Medical Services for China, were also influential during this period, but were not preserved. In the mid 7th century, Sun Simiao published acupuncture-related diagrams and charts that established standardized methods for finding acupuncture sites on people of different sizes and categorized acupuncture sites in a set of modules.\n\nAcupuncture became more established in China as improvements in paper led to the publication of more acupuncture books. The Imperial Medical Service and the Imperial Medical College, which both supported acupuncture, became more established and created medical colleges in every province. The public was also exposed to stories about royal figures being cured of their diseases by prominent acupuncturists. By time \"The Great Compendium of Acupuncture and Moxibustion\" was published during the Ming dynasty (1368–1644 AD), most of the acupuncture practices used in the modern era had been established.\n\nBy the end of the Song dynasty (1279 AD), acupuncture had lost much of its status in China. It became rarer in the following centuries, and was associated with less prestigious professions like alchemy, shamanism, midwifery and moxibustion. Additionally, by the 18th century, scientific rationality was becoming more popular than traditional superstitious beliefs. By 1757 a book documenting the history of Chinese medicine called acupuncture a \"lost art\". Its decline was attributed in part to the popularity of prescriptions and medications, as well as its association with the lower classes.\n\nIn 1822, the Chinese Emperor signed a decree excluding the practice of acupuncture from the Imperial Medical Institute. He said it was unfit for practice by gentlemen-scholars. In China acupuncture was increasingly associated with lower-class, illiterate practitioners. It was restored for a time, but banned again in 1929 in favor of science-based Western medicine. Although acupuncture declined in China during this time period, it was also growing in popularity in other countries.\n\nKorea is believed to be the first country in Asia that acupuncture spread to outside of China. Within Korea there is a legend that acupuncture was developed by emperor Dangun, though it is more likely to have been brought into Korea from a Chinese colonial prefecture in 514 AD. Acupuncture use was commonplace in Korea by the 6th century. It spread to Vietnam in the 8th and 9th centuries. As Vietnam began trading with Japan and China around the 9th century, it was influenced by their acupuncture practices as well. China and Korea sent \"medical missionaries\" that spread traditional Chinese medicine to Japan, starting around 219 AD. In 553, several Korean and Chinese citizens were appointed to re-organize medical education in Japan and they incorporated acupuncture as part of that system. Japan later sent students back to China and established acupuncture as one of five divisions of the Chinese State Medical Administration System.\n\nAcupuncture began to spread to Europe in the second half of the 17th century. Around this time the surgeon-general of the Dutch East India Company met Japanese and Chinese acupuncture practitioners and later encouraged Europeans to further investigate it. He published the first in-depth description of acupuncture for the European audience and created the term \"acupuncture\" in his 1683 work \"De Acupunctura\". France was an early adopter among the West due to the influence of Jesuit missionaries, who brought the practice to French clinics in the 16th century. The French doctor Louis Berlioz (the father of the composer Hector Berlioz) is usually credited with being the first to experiment with the procedure in Europe in 1810, before publishing his findings in 1816.\n\nBy the 19th century, acupuncture had become commonplace in many areas of the world. Americans and Britons began showing interest in acupuncture in the early 19th century but interest waned by mid century. Western practitioners abandoned acupuncture's traditional beliefs in spiritual energy, pulse diagnosis, and the cycles of the moon, sun or the body's rhythm. Diagrams of the flow of spiritual energy, for example, conflicted with the West's own anatomical diagrams. It adopted a new set of ideas for acupuncture based on tapping needles into nerves. In Europe it was speculated that acupuncture may allow or prevent the flow of electricity in the body, as electrical pulses were found to make a frog's leg twitch after death.\n\nThe West eventually created a belief system based on Travell trigger points that were believed to inhibit pain. They were in the same locations as China's spiritually identified acupuncture points, but under a different nomenclature. The first elaborate Western treatise on acupuncture was published in 1683 by Willem ten Rhijne.\n\nIn China, the popularity of acupuncture rebounded in 1949 when Mao Zedong took power and sought to unite China behind traditional cultural values. It was also during this time that many Eastern medical practices were consolidated under the name traditional Chinese medicine (TCM).\n\nNew practices were adopted in the 20th century, such as using a cluster of needles, electrified needles, or leaving needles inserted for up to a week. A lot of emphasis developed on using acupuncture on the ear. Acupuncture research organizations were founded in the 1950s and acupuncture services became available in modern hospitals. China, where acupuncture was believed to have originated, was increasingly influenced by Western medicine. Meanwhile, acupuncture grew in popularity in the US. The US Congress created the Office of Alternative Medicine in 1992 and the National Institutes of Health (NIH) declared support for acupuncture for some conditions in November 1997. In 1999, the National Center for Complementary and Alternative Medicine was created within the NIH. Acupuncture became the most popular alternative medicine in the US.\n\nPoliticians from the Chinese Communist Party said acupuncture was superstitious and conflicted with the party's commitment to science. Communist Party Chairman Mao Zedong later reversed this position, arguing that the practice was based on scientific principles.\n\nIn 1971, a \"New York Times\" reporter published an article on his acupuncture experiences in China, which led to more investigation of and support for acupuncture. The US President Richard Nixon visited China in 1972. During one part of the visit, the delegation was shown a patient undergoing major surgery while fully awake, ostensibly receiving acupuncture rather than anesthesia. Later it was found that the patients selected for the surgery had both a high pain tolerance and received heavy indoctrination before the operation; these demonstration cases were also frequently receiving morphine surreptitiously through an intravenous drip that observers were told contained only fluids and nutrients. One patient receiving open heart surgery while awake was ultimately found to have received a combination of three powerful sedatives as well as large injections of a local anesthetic into the wound. After the National Institute of Health expressed support for acupuncture for a limited number of conditions, adoption in the US grew further. In 1972 the first legal acupuncture center in the US was established in Washington DC and in 1973 the American Internal Revenue Service allowed acupuncture to be deducted as a medical expense.\n\nIn 2006, a BBC documentary \"Alternative Medicine\" filmed a patient undergoing open heart surgery allegedly under acupuncture-induced anesthesia. It was later revealed that the patient had been given a cocktail of anesthetics.\n\nIn 2010, UNESCO inscribed \"acupuncture and moxibustion of traditional Chinese medicine\" on the UNESCO Intangible Cultural Heritage List following China's nomination.\n\nAcupuncture is popular in China, the US, Australia, and Europe including all five Nordic countries, though less so in Finland. It is most heavily practiced in China and is one of the most common alternative medicine practices in Europe. In Switzerland, acupuncture has become the most frequently used alternative medicine since 2004. In the United Kingdom, a total of 4 million acupuncture treatments were administered in 2009. Acupuncture is used in most pain clinics and hospices in the UK. An estimated 1 in 10 adults in Australia used acupuncture in 2004. In Japan, it is estimated that 25 percent of the population will try acupuncture at some point, though in most cases it is not covered by public health insurance. Users of acupuncture in Japan are more likely to be elderly and to have a limited education. Approximately half of users surveyed indicated a likelihood to seek such remedies in the future, while 37% did not. Less than one percent of the US population reported having used acupuncture in the early 1990s. By the early 2010s, more than 14 million Americans reported having used acupuncture as part of their health care.\n\nIn the US, acupuncture is increasingly () used at academic medical centers, and is usually offered through CAM centers or anesthesia and pain management services. Examples include those at Harvard University, Stanford University, Johns Hopkins University, and UCLA. This usage has been criticized owing to there being little scientific evidence for explicit effects, or the mechanisms for its supposed effectiveness, for any condition that is discernible from placebo. Acupuncture has been called 'theatrical placebo', and David Gorski argues that when acupuncture proponents advocate 'harnessing of placebo effects' or work on developing 'meaningful placebos', they essentially concede it is little more than that.\n\nThe use of acupuncture in Germany increased by 20% in 2007, after the German acupuncture trials supported its efficacy for certain uses. In 2011, there were more than one million users, and insurance companies have estimated that two-thirds of German users are women. As a result of the trials, German public health insurers began to cover acupuncture for chronic low back pain and osteoarthritis of the knee, but not tension headache or migraine. This decision was based in part on socio-political reasons. Some insurers in Germany chose to stop reimbursement of acupuncture because of the trials. For other conditions, insurers in Germany were not convinced that acupuncture had adequate benefits over usual care or sham treatments. Highlighting the results of the placebo group, researchers refused to accept a placebo therapy as efficient.\n\nThere are various government and trade association regulatory bodies for acupuncture in the United Kingdom, the United States, Saudi Arabia, Australia, Japan, Canada, and in European countries and elsewhere. The World Health Organization recommends that before being licensed or certified, an acupuncturist receive 200 hours of specialized training if they are a physician and 2,500 hours for non-physicians; many governments have adopted similar standards.\n\nIn China, the practice of acupuncture is regulated by the Chinese Medicine Council that was formed in 1999 by the Legislative Council. It includes a licensing exam and registration, as well as degree courses approved by the board. Canada has acupuncture licensing programs in the provinces of British Columbia, Ontario, Alberta and Quebec; standards set by the Chinese Medicine and Acupuncture Association of Canada are used in provinces without government regulation. Regulation in the US began in the 1970s in California, which was eventually followed by every state but Wyoming and Idaho. Licensing requirements vary greatly from state to state. The needles used in acupuncture are regulated in the US by the Food and Drug Administration. In some states acupuncture is regulated by a board of medical examiners, while in others by the board of licensing, health or education.\n\nIn Japan, acupuncturists are licensed by the Minister of Health, Labour and Welfare after passing an examination and graduating from a technical school or university. Australia regulates Chinese medical traditions through the Chinese Medicine Board of Australia and the Public Health (Skin Penetration) Regulation of 2000. It restricts the use of words like \"Acupuncture\" and \"Registered Acupuncturist\". At least 28 countries in Europe have professional associations for acupuncturists. In France, the Académie Nationale de Médecine (National Academy of Medicine) has regulated acupuncture since 1955.\n\n\n\n"}
{"id": "50123722", "url": "https://en.wikipedia.org/wiki?curid=50123722", "title": "Adriaan Metius", "text": "Adriaan Metius\n\nAdriaan Adriaanszoon, called Metius, (9 December 1571 – 6 September 1635), was a Dutch geometer and astronomer born in Alkmaar. The name \"Metius\" comes from the Dutch word \"meten\" (\"measuring\"), and therefore means something like \"measurer\" or \"surveyor.\"\n\nAdriaan Metius was born in Alkmaar, North Holland. His father, Adriaan Anthonisz, was a mathematician, land-surveyor, cartographer, and military engineer who from 1582 served also as burgomaster of Alkmaar.\n\nMetius' brother, Jacob Metius, worked as an instrument-maker and a specialist in grinding lenses. Also born in Alkmaar, Jacob died between 1624 and 1631. Little is known of him besides the fact that, in October 1608, the States General discussed his patent application for an optical telescope of his own invention described as a device for \"seeing faraway things as though nearby\", consisting of a convex and concave lens in a tube, and the combination magnified three or four times.\n\nAdriaan Metius attended a Latin school in Alkmaar and studied philosophy in 1589 at the recently founded University of Franeker. He continued his studies at Leiden in 1594, where he studied under Rudolph Snellius. He worked for a brief time under Tycho Brahe on the island of Hven, where Brahe had built two observatories, and subsequently worked at Rostock and Jena, where he gave lectures in 1595. Subsequently, he returned to Alkmaar and assisted his father for a time as a military engineer inspecting fortifications, and also worked as a teacher of mathematics at Franeker in Frisia, his teaching especially geared towards the training of surveyors.\n\nAt the University of Franeker, he was appointed \"professor extraordinarius\" in 1598, and served from 1600 to 1635 as \"professor ordinarius\" of mathematics, navigation, surveying, military engineering, and astronomy. He was permitted to teach in the vernacular instead of Latin. He served as rector of the university in 1603 and 1632.\n\nWith his father and brother he established an instrument making business which specialised in optical instruments. The family business seems to have manufactured the precision Jacob's staffs used by Tycho Brahe for his star sightings.\n\nHe died in Franeker.\n\nThough he scoffed at astrology, Metius is said to have spent a lot of time pursuing alchemy, especially the philosophers' stone.\n\nMetius published treatises on the astrolabe and on surveying. His works include \"Arithmeticæ et geometriæ practica\" (1611), \"Institutiones Astronomicae Geographicae\", and \"Arithmeticæ libri duo: et geometriæ libri VI\" (1640). Metius also manufactured astronomical instruments and developed a special form of Jacob's staff.\n\nIn 1585, his father had estimated the ratio of a circle's circumference to its diameter, later called pi, to be approximately . Metius later published his father's results, and the value is traditionally referred to as Metius' number.\n\nThe lunar crater Metius is named after him.\n\nIn Vermeer's painting \"The Astronomer\" (1668), the book lying on the table has been identified as a 1621 second edition of Metius's \"Institutiones Astronomicae Geographicae\". It is opened to Book III, where \"inspiration from God\" is recommended for astronomical research along with knowledge of geometry and the aid of mechanical instruments.\n\n"}
{"id": "9664551", "url": "https://en.wikipedia.org/wiki?curid=9664551", "title": "Amorphism", "text": "Amorphism\n\nAn Amorphism, in chemistry, crystallography and, by extension, to other areas of the natural sciences is a substance or feature that lacks an ordered form. In the specific case of crystallography, an amorphic material is one that lacks long range (significant) crystalline order at the molecular level. In the history of chemistry, \"amorphism\" was recognised even before the discovery of the nature of the exact atomic crystalline lattice structure. The concept of amorphism can also be found in the fields of art, biology, archaeology and philosophy as a characterisation of objects without form, or with random or unstructured form.\n\n\n"}
{"id": "2567928", "url": "https://en.wikipedia.org/wiki?curid=2567928", "title": "Aperture (botany)", "text": "Aperture (botany)\n\nApertures are areas on the walls of a pollen grain, where the wall is thinner and/or softer. For germination it is necessary that the pollen tube can reach out from the inside of the pollen grain and transport the sperm to the egg deep down in the pistil. The apertures are the places where the pollen tube is able to break through the (elsewhere very tough) pollen wall.\n\nThe number and configuration of apertures are often very exactly characteristic of different groups of plants. The biggest class of plant species, the Eudicots, usually have three apertures in each pollen grain.\n\n"}
{"id": "11632441", "url": "https://en.wikipedia.org/wiki?curid=11632441", "title": "Archive of European Integration", "text": "Archive of European Integration\n\nThe Archive of European Integration (AEI) is an electronic repository and archive for research materials on the topic of European integration and unification. The AEI contains two types of documents:\n\nIn January, 2016 the AEI contained over 41,800 EC/EU documents and more than 7,300 privately produced documents, making it the largest online repository of EU documents in the world except for EU websites.\n\nSince the creation of the AEI in February 2003, the University Library System (ULS), University of Pittsburgh, Pennsylvania, United States has provided the technical and material support for the AEI. The ULS department of Information Technology - under the directorship of Tim Deliyannides - hosts and maintains the AEI as part of its D-Scribe Digital Publishing program. The AEI system is powered by EPrints 3, free Open Source software developed by the School of Electronics and Computer Science, University of Southampton, UK.\n\nThe Archive of European Integration (AEI) was initiated in early 2003 by Dr. Phil Wilkin, then Social Sciences Bibliographer - and current Editor of the AEI - at the ULS, in collaboration with Dr. Michael Nentwich, Austrian Academy of Sciences, Institute of Technology Assessment, Vienna, Austria. Mr. Nentwich was then managing editor of the European Research Papers Archive (ERPA). ERPA was an Internet-based platform providing access to the papers of several research institutions focusing on European integration. ERPA featured only referred high quality series, featuring some form of refereeing, and the AEI was designed to complement ERPA by collecting research materials on European integration which did not necessarily meet ERPA's high quality standards. ERPA was archived on March 1, 2015.\n\nIn fall 2004, Barbara Sloan, then Head of Public Inquiries, Delegation of the European Union to the United States, Washington, DC, (then the Delegation of the European Commission to the United States) began working with the AEI on digitizing and uploading EC/EU documents onto the AEI. The Delegation's EU library collection, founded in the mid-1950s, is by far the largest collection of EC/EU documentation in North America. A comprehensive guide to this collection can be found at European Union Archival Collection at the University of Pittsburgh, pp. 31-41. The Delegation donated this collection - spanning years early 1950s to 2004 - to the ULS in 2007. The collection contains both a shelf section and a \"research files\" section. The latter consists of 650 linear shelf feet of mostly small working and staff documents arranged in folders by subject, and will provide thousands of hard to locate materials for digitization. There is a \"finding aid\" for the \"research files\" collection at Barbara Sloan European Union Document Collection. \n\nThe AEI immediately began using this collection as a source of documents to digitize and place onto the AEI. The goal was to complement the existing electronic collections on EU websites. The AEI Delegation collection contains two primary types of document formats: series and individual bound items in monographic form which most libraries would classify and place on shelves, and \"internal working documents\" which most libraries would not classify, making them more difficult to locate. At first the AEI, cognizant of the possibility that the EU itself might digitize large numbers of its older documents, took a conservative approach, digitizing mostly the internal working documents (COM docs) and staff working documents (SEC docs) and other select documents. Indeed, in 2009-2010 the EU did digitize and place on EU Bookshop over 2,000,000 pages of its bound documents. \n\nIn 2011-2012 the AEI adopted a new, long-range policy regarding digitization, for several reasons. First, the AEI learned that it was unlikely that the EU would perform more large-scale digitization. Consequently, the AEI could develop a true \"archive\" where the goal would be to digitize as many documents as resources allowed. \n\nSecond, the two EU websites containing the bulk of EC/EU documentation - EU Bookshop and Eur-Lex: Access to European Union Law - contained only a portion of these documents. In EU Bookshop, many of the annuals and series there are not complete runs. Either they do not contain earlier documents from the 1950-60s, and/or volumes are missing throughout the run. Eur-Lex contains a considerable number of full text COM documents published 1990-2000 and nearly all 2001-present, but very few which were published before 1990. Despite their importance for research purposes, there is no comprehensive list of COM documents for the early years. Two indexes published 1976-1986 listed all COM docs, but there is no available written record which contains the titles of previous COM docs. The AEI Delegation collection contains nearly all of these documents which are missing from the EU Bookshop and Eur-Lex, which it will digitize. \n\nThird, navigating the EU Bookshop during large parts of the day is very slow, and much slower on older computers. In order to make documents easily available, the AEI decided to download annual and serial documents from the EU Bookshop and place them on the AEI, thereby furnishing full runs of all in one place. In most cases these runs will go from earliest volume up through 2000. It is likely all these runs will be completed sometime in 2017. Here are some examples (NOTE: some annuals and serials have been only partially uploaded):\n\nAnnual reports - located on Browse by EU Annual Reports - about 900 have been located. Examples:\nSeries and periodicals - located on Browse by EU Series and Periodicals - about 180 have been located: Examples:\nInstitutional newsletters and information bulletins - such as institutional and DG newsletters, etc. (scattered throughout Browse by EU Series and Periodicals) - over 100 have been located.\n\nNumerous documents not part of any series. Mostly one-off documents Commission working documents and reports.\n\n\n\n\n"}
{"id": "36571110", "url": "https://en.wikipedia.org/wiki?curid=36571110", "title": "August Alphonse Derbès", "text": "August Alphonse Derbès\n\nAugust Alphonse Derbès (8 May 1818, Marseille – 27 January 1894, Marseille) was a French professor of naturalist, zoologist and botanist at the University of Marseille who studied reproduction of sea urchins and of algae. Derbès was the first scientist to observe the fertilization of an egg in an animal when he detailed the process of an envelope forming around the gamete during sea urchin reproduction, a process now known to be associated with Ca release.\n"}
{"id": "16139022", "url": "https://en.wikipedia.org/wiki?curid=16139022", "title": "Baboon lymphocryptovirus", "text": "Baboon lymphocryptovirus\n\nThe baboon lymphocryptovirus (baboon herpes virus, HVP) was the first lymphocryptovirus isolated from a non-human primate to be described.\n"}
{"id": "21002817", "url": "https://en.wikipedia.org/wiki?curid=21002817", "title": "Bachelor in Information Management", "text": "Bachelor in Information Management\n\nA Bachelor in Information Management (BIM) degree is an academic degree in Information technology requiring four years of study to acquire. This degree is a hybrid program with a mix of management and information technology courses with a focus on analytical, problem solving, decision-making and critical thinking skills.\n\nProvide professional training to students by combining information technology with managerial skills.\n\nGraduating with a bachelors in Information Management highly beneficial as it opens up a plethora of career options and routes for students. This is manly due to the fact that employers now-a-days show a growing interest for applicants with both a business management education as well as an IT background. Paul Matthews from the Institute of IT Professionals stated that \"Employers tell me the key thing holding them back is the ability to get skilled people\". This degree would be beneficial as it is employable all over world. Every company has an IT department, which even in non-tech firms, play an essential role in the company's daily functions.\n\nThe fine combination of IT and management that this degree offers, has shown career prospects in fields such as:\n\nGraduates from these types of degrees have also found themselves working for some of the world's top organisations including Ernst and Young, Deloitte, Goldman Sachs, and Bruder Mannesmann \n\nKeep in mind that although you can start a career straight after your bachelors, you may also be interested in furthering your study by enrolling in a masters program. Employers seem to be finding that business management undergraduates are too keen on starting work immediately, without actually having attained the essential skills need for a professional workplace. This may be in terms of general maturity and also the students ability to 'hit the ground running'. This is where masters students have the greater advantage.\n\nThere are many different masters programs available to graduates from an Information Management degree. However at this point, the studies tend to narrow down to more specific areas. As you have a solid background in both Business Management and IT, you have a large range to choose from.\n\nIf after studying you seem to be more keen in IT then perhaps you should consider doing a masters in either computer science or information systems.These two programs are some of the best for finding postgraduate jobs with high earning salaries.\n\nInformation Management students enrolled in a full-time degree generally have 8–13 hours a week in class, whether its lectures, tutorials, or seminars. However time must be spend outside of class working on coursework and assignments as well as doing prerequisite readings for certain modules.\n\nOne of the hardest parts about being a student is learning how to survive on a budget. To compensate for this, many students choose to get a part-time job while studying. In the United States, about 50% of students have a part-time job whilst enrolled in a full-time degree. However it becomes increasing difficult to balance a part-time job along with course work, classes, good grades, self study time, and social life. Often self study time suffers the most from part-time jobs. Therefore it would be recommended to work no more than 10 hours a week.\n\n"}
{"id": "2529967", "url": "https://en.wikipedia.org/wiki?curid=2529967", "title": "Back scattering alignment", "text": "Back scattering alignment\n\nThe Back Scattering Alignment (BSA) is a coordinate system used in coherent electromagnetic scattering. The coordinate system is defined from the viewpoint of the wave source, before and after scattering. The BSA is most commonly used in radar, specifically when working with a Sinclair Matrix because the monostatic radar detector and source are physically coaligned. BSA gives rise to conjugate eigenvalue equations. The alternative coordinate system in electromagnetic scattering is the Forward Scattering Alignment (FSA) which is primarily used in optics. Both coordinate systems contain essentially the same information and meaning, and thus a scattering matrix can be transformed from one to the other by use of the matrix,\n\nformula_1\n\n"}
{"id": "8989793", "url": "https://en.wikipedia.org/wiki?curid=8989793", "title": "Coding (social sciences)", "text": "Coding (social sciences)\n\nIn the social sciences, coding is an analytical process in which data, in both quantitative form (such as questionnaires results) or qualitative form (such as interview transcripts) are categorized to facilitate analysis.\n\nOne purpose of coding is to transform the data into a form suitable for computer-aided analysis. This categorization of information is an important step, for example, in preparing data for computer processing with statistical software.\n\nSome studies will employ multiple coders working independently on the same data. This minimizes the chance of errors from coding and is believed to increase the reliability of data.\n\nOne code should apply to only one category and categories should be comprehensive. There should be clear guidelines for \"coders\" (individual who do the coding) so that code is consistent.\n\nFor quantitative analysis, data is coded usually into measured and recorded as nominal or ordinal variables.\n\nQuestionnaire data can be \"pre-coded\" (process of assigning codes to expected answers on designed questionnaire), \"field-coded\" (process of assigning codes as soon as data is available, usually during fieldwork), \"post-coded\" (coding of open questions on completed questionnaires) or \"office-coded\" (done after fieldwork). Note that some of the above are not mutually exclusive.\n\nIn social sciences, spreadsheets such as Excel and more advanced software packages such as R, Matlab, PSPP/SPSS, DAP/SAS, MiniTab and Stata are often used.\n\nFor disciplines in which a qualitative format is preferential, including ethnography, humanistic geography or phenomenological psychology a varied approach to coding can be applied. Iain Hay (2005) outlines a two-step process beginning with basic coding in order to distinguish overall themes, followed by a more in depth, interpretive code in which more specific trends and patterns can be interpreted.\n\nMuch of qualitative coding can be attributed to either grounded or \"a priori\" coding. Grounded coding refers to allowing notable themes and patterns emerge from the document themselves, where as \"a priori\" coding requires the researcher to apply pre-existing theoretical frameworks to analyze the documents. As coding methods are applied across various texts, the researcher is able to apply axial coding, which is the process of selecting core thematic categories present in several documents to discover common patterns and relations.\n\nPrior to constructing categories, a researcher must apply a first cycle coding method. There are a multitude of methods available, and a researcher will want to pick one that is suited for the format and nature of their documents. Not all methods can be applied to every type of document. Some examples of first cycle coding methods include:\n\n\nThe process can be done manually, which can be as simple as highlighting different concepts with different colours, or fed into a software package. Some examples of qualitative software packages include Atlas.ti, MAXQDA, NVivo, and QDA Miner.\n\nAfter assembling codes it is time to organize them into broader themes and categories. The process generally involves identifying themes from the existing codes, reducing the themes to a manageable number, creating hierarchies within the themes and then linking themes together through theoretical modeling.\n\nCreating memos during the coding process is integral to both grounded and a priori coding approaches. Qualitative research is inherently reflexive; as the researcher delves deeper into their subject, it is important to chronicle their own thought processes through reflective or methodological memos, as doing so may highlight their own subjective interpretations of data It is crucial to begin memoing at the onset of research. Regardless of the type of memo produced, what is important is that the process initiates critical thinking and productivity in the research. Doing so will facilitate easier and more coherent analyses as the project draws on \nMemos can be used to map research activities, uncover meaning from data, maintaining research momentum and engagement and opening communication.\n\n\nHay, I. (2005). \"Qualitative research methods in human geography\" (2nd ed.). Oxford: Oxford University Press.\n\nGrbich, Carol. (2013). \"Qualitative Data Analysis\" (2nd ed.). The Flinders University of South Australia: SAGE Publications Ltd.\n\nSaldaña, Johnny. (2015). \"The Coding Manual for Qualitative Researchers\" (3rd ed.). SAGE Publications Ltd.\n"}
{"id": "45457517", "url": "https://en.wikipedia.org/wiki?curid=45457517", "title": "Constant Bar", "text": "Constant Bar\n\nConstant Bar (14 October 1817, Nantes – June 1884, Paramaribo) was a French entomologist.\n\nConstant Bar lived in French Guiana at L'île Portal in the commune of Saint-Laurent-du-Maroni and with his three brothers made extensive entomological explorations of that region, collecting specimens for his own studies and for Charles Oberthür and others. He wrote Note critique sur les différent systèmes de classification des lépidoptères rhopalocères établis depuis l'époque de Latreille et essai d'une nouvelle classification jusqu'aux genres exclusivement. \"Annales de la Societé entomologique de France\", Paris, (5) 8 (1): 5–30. (1878). In 1854 he became a Member of the Société entomologique de France.\n\nHe is honoured in the names \"Hypercompe bari\", \"Heliconia bari\" and \"Parides lysander bari\".\n\n"}
{"id": "57860502", "url": "https://en.wikipedia.org/wiki?curid=57860502", "title": "Cooperative Observer Program", "text": "Cooperative Observer Program\n\nThe NOAA Cooperative Observer Program (COOP) is a citizen weather observer network run by the U.S. National Weather Service (NWS) and National Centers for Environmental Information (NCEI). Over 8,700 volunteers from the fifty states and all territories report at least daily a variety of weather conditions such as daily maximum and minimum temperatures, 24-hour precipitation totals, including snowfall, and significant weather occurrences throughout a day that are recorded via remarks in observer logs. Some stations also report stream stage or tidal levels. \nDaily observations are reported electronically or over the phone, and monthly logs are submitted electronically or via the mail. Many stations are located in rural areas but the network also includes long-term stations in most urban centers. Observation locations include farms, in urban and suburban areas, National Parks, seashores, and mountaintops. Volunteers are trained by local NWS offices who provide rain gauges, snowsticks, thermometers, or other instruments. Data is initially received and analyzed by local NWS offices then ultimately stored and analyzed by NCEI, which also does final data quality checks. The program began with act of Congress in 1890 and grew out a network of observers developed by the Smithsonian Institution. It was a backbone of the U.S. climatological observation network and remains an important network in providing long-term observations of particular locations.\n\nThe Cooperative Weather Observer network consists of manual observations of only a few variables and consists of daily summaries rather than being continuous (i.e. real-time). Because of these limitations and other sensor limitations, there has been a move to supplement the coop program using automated weather stations since the 1990s. NWS sponsored programs include the Citizen Weather Observer Program (CWOP) and Community Collaborative Rain, Hail and Snow Network (CoCoRaHS). The coop network predates but grew to supplement significant surface weather observation sites typically located around major airports. Mesonets also supplement these major weather stations and may be official or unofficial, possess varying degrees of rigor, may be temporary or used for specific research project goals, and may even be mobile.\n\n\n"}
{"id": "21560040", "url": "https://en.wikipedia.org/wiki?curid=21560040", "title": "Creeper (program)", "text": "Creeper (program)\n\nCreeper was an experimental computer program written by Bob Thomas at BBN in 1971. Its original iteration was designed to move between DEC PDP-10 mainframe computers running the TENEX operating system using the ARPANET, with a later version by Ray Tomlinson designed to copy itself between computers rather than simply move. This self-replicating version of Creeper is generally accepted to be the first computer worm. \n\nThe program was not actively malicious software as it caused no damage to data, the only effect being a message it output to the teletype reading \"I'm the creeper: catch me if you can\". \n\nReaper was a similar program created by Ray Tomlinson to move across the ARPANET and delete the self-replicating Creeper.\n\nThe conflict between Creeper and Reaper served as inspiration for the programming game \"Core War\", while fictionalized versions of Reaper have been used as antagonists in the anime \"Digimon Tamers\" and the visual novel \"\".\n"}
{"id": "48838467", "url": "https://en.wikipedia.org/wiki?curid=48838467", "title": "Czech Science Foundation", "text": "Czech Science Foundation\n\nThe Czech Science Foundation (GACR) was established in 1993 as an independent public organisation supporting basic research in the Czech Republic. On the basis of calls for proposals and a public competition, the Czech Science Foundation provides financial support for both experienced and young and early-stage researchers. It also funds international projects on a bilateral basis in cooperation with several partner agencies as well as projects carried out within international research programmes. It is one of two major government-supported research funding agencies in the Czech Republic, the other being the Technological Agency of the Czech Republic (TAČR).\n\n\nThe GACR authorities are the President, Presidium, Scientific Advisory Board and Supervisory Board. The Presidium is assisted by Discipline Committees. Evaluation Panels are the expert bodies of Discipline Committee. Organizational and administrative work is in the competency of the GACR Office.\n\nThe Presidium of the Czech Science Foundation is appointed by the Government of the Czech Republic. The Presidium is authorized to organize the Calls for Proposals for scientific and research projects and to award grants. It consists of five members. The GACR Presidium is headed by the President. He/she represents GACR and acts in its name in all relevant matters. Members of the Presidium are elected for four years with a maximum of two consecutive terms. Each member is responsible for one of the scientific areas (Physical Sciences, Social Sciences and Humanities, Technical Sciences, Medical and Biological Sciences, Agricultural and Biological-Environmental Sciences).\n\nThe Scientific Advisory Board consists of 12 experts representing different scientific fields. Membership in the Scientific Advisory Board lasts for four years with a maximum of two consecutive terms. The Scientific Advisory Board provides expert scientific advice to the GACR Presidium with regards to promoted projects and the structure and operation of GACR Discipline Committees and Panels. It also evaluates overall scientific level of the Czech Science Foundation and creates the strategy for its future development and direction.\n\nThe Supervisory Board has 10 members, who are appointed by the Parliament of the Czech Republic. Membership in the Supervisory Board lasts for four years a maximum of two consecutive terms. The Supervisory Board controls the transparency of the evaluation process, oversees the distribution of funds and overall functioning of the Czech Science Foundation.\n\nDiscipline Committees are permanent advisory bodies, which assist the Presidium during the evaluation process. Panels are the expert bodies of Discipline Committees. Each of the committees consists of Chairmen and Vice-Chairmen from individual Panels and has between 10 and 20 members who are nominated by the GACR Presidium. The total numer of Panels is 39. Members are appointed for a two-year term with a possibility of two consecutive terms maximum.\n\nThe GACR Office is the organisational and administrative body of the Czech Science Foundation. It is managed by the Director, who is appointed and recalled by the GACR President. The GACR Office carries out the organisation of evaluation process of submitted project proposals and the agenda for ongoing and completed projects. International activities and administration of international projects are also handled by the Office. The office transfers funds to the recipients of the grants, offers consultations to recipients and grant project researchers in financial matters, administers the budget of the GACR Office, provides for all related agenda as well as monitors compliance with procedures and rules prescribed by the generally valid economic and legal regulations or by the GACR Guidelines.\n\nGACR provides financial support for the following types of projects:\n\nThe topic of all types of project is determined by the applicant (bottom-up principle). The duration of projects is 2–3 years and proposals are invited in all disciplines of basic research.\n\nDevelopment and strengthening of international relations is one of the GACR’s long-term priorities. Worldwide international cooperation is implemented within the GACR’s membership in the Global Research Council (GRC), at the pan-European level especially within the GACR’s membership in the European Science Foundation (ESF) (until reorganization of the latter) and in Science Europe (SE). Based on bilateral agreements GACR closely cooperates with Germany, Austria, Taiwan and South Korea.\n\n"}
{"id": "53578123", "url": "https://en.wikipedia.org/wiki?curid=53578123", "title": "David Schiel", "text": "David Schiel\n\nDavid Schiel is a New Zealand marine ecologist and biologist, currently a Distinguished Professor of University of Canterbury.\n"}
{"id": "197207", "url": "https://en.wikipedia.org/wiki?curid=197207", "title": "Georgy Shonin", "text": "Georgy Shonin\n\nGeorgy Stepanovich Shonin () (August 3, 1935 – April 7, 1997; born in Rovenky, Luhansk Oblast, (now Ukraine) but grew up in Balta of Ukrainian SSR) was a Soviet cosmonaut, who flew on the Soyuz 6 space mission.\n\nShonin was part of the original group of cosmonauts selected in 1960. He left the space programme in 1979 for medical reasons.\n\nShonin's family hid a Jewish family from the Nazis during WWII.\n\nShonin later worked as the director of the 30th Central Scientific Research Institute, Ministry of Defence (Russia).\n\nHe died of a heart attack in 1997.\n\nHe was awarded:\n"}
{"id": "13302381", "url": "https://en.wikipedia.org/wiki?curid=13302381", "title": "Jacob H. Eckert", "text": "Jacob H. Eckert\n\nJacob H. Eckert (1888–1934) invented the type of cash register that has a cash drawer and a bell.\n\n"}
{"id": "31601539", "url": "https://en.wikipedia.org/wiki?curid=31601539", "title": "Johanneberg Science Park", "text": "Johanneberg Science Park\n\nJohanneberg Science Park was established in December 2009 by the Chalmers University of Technology Foundation and the City of Gothenburg to create better conditions for regional sustainable growth, based on the activities currently conducted within Chalmers University of Technology at Campus Johanneberg in Gothenburg, Sweden.\n\nThe Science Park primarily support development of activities within the disciplines of Urban Development, Environment, Energy, Materials and Nanoscience. \n\nwww.johannebergsciencepark.com\n"}
{"id": "28938099", "url": "https://en.wikipedia.org/wiki?curid=28938099", "title": "L183", "text": "L183\n\nL183 or L134N is a much-studied pre-stellar core in the constellation Serpens Cauda 360 light-years away. This massive accumulation of gas and dust was the interstellar object in which the phenomenon of coreshine was first investigated by astronomers and produced a new means of probing its previously opaque core.\n\n"}
{"id": "31629330", "url": "https://en.wikipedia.org/wiki?curid=31629330", "title": "Language, Proof and Logic", "text": "Language, Proof and Logic\n\nLanguage, Proof and Logic is an educational software package, devised and written by Jon Barwise and John Etchemendy, geared to teaching formal logic through the use of a tight integration between a textbook (same name as the package) and four software programs, where three of them are logic related (Boole, Fitch and Tarski's World) and the other (Submit) is an internet-based grading service. The name is a pun derived from \"Language, Truth, and Logic\", the philosophy book by A. J. Ayer.\nOn September 2, 2014, there was launched a massive open online course (MOOC) with the same name, which utilizes this educational software package.\n\nA short description of the programs:\n\n\n"}
{"id": "21564286", "url": "https://en.wikipedia.org/wiki?curid=21564286", "title": "Leadership Institute at Harvard College", "text": "Leadership Institute at Harvard College\n\nThe Leadership Institute at Harvard College (LIHC) is the largest student-run leadership training and development organization at Harvard College, located in Cambridge, Massachusetts. Founded in 2005, the Leadership Institute hosts high-profile speakers, organizes skill development workshops and forums, and publishes the annual \"Harvard Undergraduate Leadership Magazine\". LIHC is the umbrella organization for four integrated programs: the Leadership Development Initiative (LDI), the Presidents' Forum (TPF), the \"Harvard Undergraduate Leadership Magazine\" (\"HULM\"), and the LIHC-Citizen Schools Youth Outreach Initiative.\n\nFounded in 2005 by four Harvard undergraduates, LIHC was established in response to the lack of leadership development resources available to Harvard College students. More recently, in September 2008, LIHC announced its definition of leadership: \"the skill of motivating, guiding and empowering a team towards a socially responsible vision.\" The Leadership Institute is guided by an Executive Board of eight undergraduates and a Board of Advisors drawn from Harvard Business School, Harvard Law School, Harvard Medical School, the Kennedy School of Government, and as well as government and corporate institutions.\n\nMembers of the 2011 Executive Board are:\n\nMembers of the Board of Advisors (as of September 2011) are:\n\nThe current members of the Executive Board as of (May 2015):\n\nJames Ho\n, \"President\"\n\nJames is a junior in Dunster House concentrating in Statistics with a secondary in Economics. Growing up in the Bay Area, he is interested in business and technology. Before serving as the President of LIHC, he served as the Strategic Development Chair in 2014 and the Finance and Communications Chair in 2013, and has taught for YLC Boston and Myanmar. James is also involved as an Investment Research Director for the Harvard Financial Analysts Club, and dances with the Asian American Dance Troupe. In his free time, he enjoys watching stand up comedy, playing squash, and traveling. He looks forward to having another great year with LIHC and furthering the organization and its mission.\n\nJim Chan\n, \"Vice President\"\n\nJim Chan is a junior living in Dunster House, studying Biomedical Engineering, with interests in the business of health and healthcare. Before serving as Vice President, Jim spearheaded outreach (2013) and revamped programming (2014) for the Strategic Development Committee’s flagship conference, as well as revitalized LIHC’s social media platforms (2013). As a native New Yorker, it is no surprise that Jim is enthusiastic about exploring new places, listening to alternative pop-rock music, international traveling, breakfast foods and spending time with friends. Outside of LIHC, Jim serves as President of the Biotechnology Association, dances with Asian American Dance Troupe, works at Harvard’s student-run clinic and dabbles in non-profit work with the East Coast Asian American Student Union. This year, he is most excited about planning valuable full club trainings for members, as it pertains to personal awareness, development and success in leadership.\n\nSerguei Balanovich\n, \"Chair, Harvard Leads\"\n\nSerguei is a junior who was born and raised in Siberia, but currently lives in Cabot House. He is concentrating in Applied Mathematics with a secondary in Computer Science. Being very interested in both developing his skills as a programmer and in becoming more involved in the business and entrepreneurial world of start-ups, he hopes to someday try his hand at starting a business in the tech world and hopes that the Leadership Institute will help him develop the skills necessary for this. Outside of LIHC, he is a member of the Harvard International Review, the Hack Harvard club, and in his free time he likes playing chess and solving Rubik’s cubes.\n\nAlex Heyde\n, \"Co-Editor in Chief, Harvard Leadership Magazine\"\n\nAlex Heyde is a junior in Eliot House, concentrating in Applied Math and Integrative Biology. Born in Chicago, Alex is an editor-in-chief of Rise, the Harvard College Leadership Magazine. At Harvard, Alex conducts biomathematical and biostatistical research in the field of evolutionary developmental biology. He also works as a mathematics course assistant and a health educator for Peer Health Exchange. In his free time, he enjoys watching movies and discussing philosophy.\n\nDylan Clark\n,\"Co-Editor in Chief, Harvard Leadership Magazine\"\n\nDylan is a freshman from Dallas, Texas who is planning on studying Economics. His crowning achievement is being awarded “Hardest Working Player” on his High School basketball team senior year, a season in which he averaged roughly 1/3 of a point per game. He was also the editor of his high school’s newspaper, which won a Pacemaker and is a Gold Crown finalist.\n\nWes Friedman\n, \"Chair, Leadership Development Initiative\"\n\nWesley Friedman is currently a Junior in Winthrop House, concentrating in History and Science. Wesley is also the head student coordinator for the 25th Reunion Committee of the Harvard Alumni Association. Last summer, he worked at the XPRIZE Foundation, designing competitions to incentivize innovation in such areas as aerospace technology and medicine. A graduate of the Harvard-Westlake School in Los Angeles, Wesley was the co-director of the Zoobiquity Research Initiative, a pathbreaking research organization focusing on the intersection of human and veterinary medicine. He also served as the Co-chair of the Student Ambassador program and the Student Director of the Harvard-Westlake Alumni Organization. He has also spent summers working at UCLA’s Ronald Reagan Medical Center and the Los Angeles Zoo, where he worked on medical procedures on black bears, chimpanzees, and other zoo animals.\n\nJesse Jiang\n, \"Chair, Strategic Development\"\n\nJesse Jiang is a sophomore in Adams who was raised in New York/New Jersey and currently lives in Beijing, China. He is interested in the intersection of business and science and its cross cultural significance. Having attended boarding school in Connecticut, where he served as the Chairman of the Judicial Committee, he is passionate about leadership in the context of integrity and strongly believes that leadership is a skill that can be taught and developed.\n\nKate Hoffman\n, \"Chair, Social Outreach\"\n\nKate Hoffman is currently a Sophomore living in Pforzheimer House. She is originally from Dallas, Texas and attended both The Hockaday School and the School for Ethics and Global Leadership. At Harvard she hopes to concentrate in Social Studies, as well as explore her interests of Environmental Science and Psychology. She is very excited to continue with LIHC this year and teach high schoolers leadership skills. Outside of LIHC, she volunteers as a coordinator for the Mission Hill After School Program through the Phillips Brooks House Association. She loves to work with kids, to travel, and to spend time with family and friends.\n\nChris Willis\n, \"Chair, Youth Lead the Change\"\n\nChris is a sophomore in Cabot House. Growing up in Atlanta, he participated in many leadership development clubs and activities where he planned Leadership Summits and led training sessions. Chris enjoys playing tennis on the Harvard Club Team. He is a brother in the Sigma Chi fraternity, where he loves socializing and learning from his brothers. Chris looks forward to all the work in YLC and LIHC!\n\nChristina Gao\n, \"Co-Chair, Finance and Communications\"\n\nChristina is a sophomore living in Leverett House who is from Cincinnati, OH. She has figure skated for 12 years and is returning from a gap year she took to train. She studies Economics with a secondary in Neurobiology and is interested in leadership across many different fields. She hopes to bring her knowledge of leadership and share it with the college population and beyond by being actively involved with LIHC.\n\nVictoria Machado\n, \"Co-Chair, Finance and Communications\"\n\nVictoria is a junior in Leverett House concentrating in Statistics with a focus in Biology. In her second semester as a member of LIHC’s Strategic Development Committee, she has taken on the role of co-manager of Finance and Communications for LIHC. In this position, she hopes to expand alumni outreach initiatives to increase advising and support for LIHC’s various committees and leadership initiatives. Victoria is from Braintree, MA and attended Braintree High School. Outside of LIHC, She is also involved with the Harvard Alumni Association as a Student Coordinator for Commencement and Reunions. In her spare time, she enjoys traveling, running, and breakfast sandwiches.\n\nThe current Board of Advisors as of (May 2015):\n\nJared Katseff\nJared Katseff is currently a candidate for an MBA at Harvard Business School as well as a Master in Urban Planning at Harvard Graduate School of Design. He is pursuing both degrees because he is interested in realizing transit oriented development by making the financial case for walkable urbanism. Originally from Manalapan, New Jersey, he graduated Magna Cum Laude from the Wharton School of Business at the University of Pennsylvania with a major in Finance and Real Estate. After college, Jared worked for three years at McKinsey & Company, where he focused his time charting economic development strategies for cities in North America, the Middle East and Southeast Asia.\nRita Chung\nOriginally from Hong Kong, but growing up between Vancouver, Hong Kong, Duino (Italy) and London, I am now pursuing her Master in Public Policy at Harvard Kennedy School (HKS). My interest is in energy and water policy. Prior to HKS, I worked for Earthwatch Institute in their Hong Kong office, developing and managing employee engagement projects on climate change and freshwater scarcity research across the Asia Pacific region for large corporations. My work at Earthwatch led to my interest in energy and water resource distribution conflicts, and I am passionate about finding more equitable and sustainable ways of distributing energy and water resources around the world. In my other lives, I have worked in investment banking in London, campaigned for human rights issues in Canada and Israel, and launched a magazine in Shanghai.\nTuba Rashid Khan\nTuba is currently in the child advocacy track at Harvard. She is a strong advocate for increasing opportunities, access and early identification for special needs children. A doctor with also a public health degree from Harvard, she has worked on numerous projects on child development in Pakistan, UAE, Kenya, US and Nigeria in association with MIT and Boston Children’s Hospital. Having completed the leadership concentration from HSPH, her other leadership experiences include being a teaching fellow, instructor and leading special needs projects in Bangladesh. She also happens to be a scrabble fanatic and loves to jet ski.\nTessa Hamilton\nI am a recent graduate of the University of Arizona, where I completed my degree in Psychology. As an undergraduate I was actively engaged in research projects as well as community projects related to youth empowerment, mental health, and educational equity. I am currently studying Prevention Science/School Social Work at the Ed school and I am especially interested in promoting leadership and participatory improvement efforts amongst low-income Latino populations. Outside of school, I am passionate about nutrition and fitness. I am an avid socializer. Currently, I serve as a Senator on the Student Council Association at the Ed school and as a member of the Association’s Diversity Committee.\nYasser Jeelani\nI am a physician from London, England, training in Neurological Surgery and currently here at Harvard doing a postdoctoral research fellowship in Minimally Invasive Pediatric neurosurgery at HMS. Being orphaned at a young age of 8, and being left to tend to myself and to my siblings, challenges demanded not only solving challenges for myself, but also to lead my siblings to survival. Since then, I have been capitulating on those instincts by utilizing them in all walks of life, academics included. At my current position, I have been instrumental in establishing the first Neurosurgery cadaver laboratory for minimally invasive and skull base neurosurgery at Harvard, where we will be training neurosurgeons and fellows besides conducting some ground breaking research in attempting novel approaches to relatively inaccessible areas of the brain.\nBenjamin Summers\nI’m an active duty Army officer, current MBA candidate at Harvard Business School and will return to West Point in 2015 for a 2-year teaching fellowship in the Department of Social Sciences. I live with my wife, Chrissy, in Cambridge (and we’re expecting a new member to our family in September). After graduating from West Point in 2006, I attended the Army’s flight school and was qualified in the Blackhawk helicopter. After flight school, I deployed twice with the 101st Airborne Division. Whether leading a company of Soldiers during a deployment to Afghanistan or leading an aircrew during a Blackhawk helicopter combat mission, I’ve found that successful leadership often means trusting, empowering and developing the people around me. That realization is what brought me to HBS and what makes the idea of teaching and mentoring cadets at West Point so fulfilling. Serving on the Board of Advisors with the LIHC would match with these passions towards leadership development.I currently serve as a VP for Admission for the Armed Forces Alumni Association at HBS, as a planning officer for the Harvard Veterans Alumni Organization and as a member of the Social Enterprise Club.\n\nAmal Elbakhar\nI grew up in an immigrant culture in which educational achievement was difficult to obtain, and this has always served as a source of motivation for me. Thus, as an eager New Yorker, I spent my college years immersing myself in every aspect of my community, attending events as well as leading them. Experience after experience, I realized that – academically – women’s issues are the most important to me. I am intrigued by the concept of using the law and policy to affect social change in a way that serves a greater societal purpose. In fact, I am driven by any topic that is innovative, fun and challenging – and yet, moves an important societal discourse forward.\nDesmond Lim\nDesmond Lim previously worked for Bank of America Merrill Lynch and UBS in a wide variety of sectors including financial institutions, energy and power, and retail. He ran an education non-profit, Choson Exchange, teaching business skills to over 200 North Koreans in Pyongyang, Beijing, and Singapore. He also previously co-founded a Thai-cuisine restaurant, started up a clothes trading company, and was an infantry officer with the Singapore Armed Forces for 2.5 years. He played competitive basketball for over 15 years and represented the Singapore National Team in the Southeast Asian Games. As a Research Affiliate at MIT, and a university fellow at Harvard University, Desmond pursued research in entrepreneurship, development, and innovation. Desmond is a current graduate student at Harvard University, and completed two bachelor's degrees in 4 years in Business Management and Accounting (Magna Cum Laude). Desmond has lived in Singapore, China, United Kingdom, Korea, and the US, is fluent in Mandarin, and proficient in Korean.\n\nThe Leadership Development Initiative (LDI) hosts skill-building workshops (the Skills Development Series) and speaker events with veteran leaders (Biography Speaker Series) to connect undergraduates with exemplary role models. Speakers are drawn from all sectors, including business, civil service, healthcare, non-profits, and social entrepreneurship. LIHC conducts surveys to determine the specific leadership training needs at Harvard College and tailors its workshops to satisfy these needs, such as ethical decision-making in difficult situations, public speaking, negotiation and persuasion, leadership in entrepreneurship, dealing with organizational change, and facing competition with integrity.\n\nIn the past, LDI has hosted:\n\n• Ray Mabus, United States Secretary of the Navy and former Mississippi Governor\n• John Clarkeson, former CEO and Chairman of Boston Consulting Group\n• Tom Monahan, CEO and Chairman of The Corporate Executive Board Company\n• David Gergen, Director of the Center for Public Leadership and adviser to presidents for over 30 years\n• Bill Drayton, CEO and Founder of Ashoka\n• Lewis B. Kaden, Vice Chairman of Citigroup<br>\n• Seth Moulton, Marine Corps veteran in Iraq, Special Assistant to General Petraeus<br>\n• Rye Barcott, Founder and President of international NGO Carolina for Kibera<br>\n• Tad Hutcheson, Vice President of Marketing of AirTran Airways<br>\n• Fred Swaniker, Co-Founder and CEO of the African Leadership Academy<br>\n• Alan Khazei, Co-Founder and former CEO of City Year<br>\n• Jim Mongan, President and CEO of Partners HealthCare, former President of the Massachusetts General Hospital\n\nLDI has also hosted workshops on Building an Effective Team Culture, Effective Delegation, Elevator Pitches, Managing Organizational Transitions, Negotiations, Organizational Sustainability and Growth, Public Speaking, Sales, and Using Your Emotions as you Negotiate.\n\nThe Presidents' Forum (TPF), founded by Jessica Zofnass ('08), brings together the Presidents, Managing Editors, and Captains of Harvard's student organizations and Varsity sports teams in bi-monthly discussion forums and an annual banquet (the Presidents' Banquet). The Presidents' Banquet began in 2006 and is the largest gathering of student leaders at Harvard College. TPF enables student leaders to learn from each other's experiences and establish lifelong friendships and correspondences. Past keynote speakers of the Banquet include:\n\n• Bill George, HBS Professor of Management Practice, author of True North, and former CEO of Medtronic, Inc. \n• Carl Hobert, Founder and Executive Director of Axis of Hope Center for Conflict Resolution and Prevention \n• Abigail Levy, McKinsey & Company innovations expert\n\nThe annual \"Harvard Undergraduate Leadership Magazine\" (\"HULM\") was inaugurated in 2008 with the intention of empowering students to examine leadership through multiple perspectives and to construct their own conceptions of what it means to be a true leader. The full-color publication features articles on leadership skills as well as interviews and biographies. The magazine has a circulation of 1000. Featured leaders have included:\n\n\nIn 2009, LIHC began an experimental youth outreach program, targeting at-risk middle school students in the Boston area. This program, a partnership with the nationally renowned Citizen Schools program, aims to provide pertinent leadership skills for youth. The program has now expanded to three schools and hopes to expand in the future.\n\nLIHC spearheads a number of special initiatives to expand its impact at and beyond Harvard.\n\n\nThe Leadership Institute works with the Ivy Council to facilitate a coordinated response to the leadership challenges faced by all eight Ivy League schools.\n\nIn the 2011-2012 school year, LIHC and the Ivy Council hosted the Ivy Leadership Summit, which brought together student leaders from all eight Ivy League schools.\n\n"}
{"id": "322337", "url": "https://en.wikipedia.org/wiki?curid=322337", "title": "Learning curve", "text": "Learning curve\n\nA learning curve is a graphical representation of how an increase in learning (measured on the vertical axis) comes from greater experience (the horizontal axis); or how the more someone (or thing) does something, the better they get at it.\n\nThe term \"learning curve\" is used in two main ways: where the same task is repeated in a series of trials, or where a body of knowledge is learned over time. The first person to describe the learning curve was Hermann Ebbinghaus in 1885, in the field of the psychology of learning, although the name wasn't used until 1903. In 1936, Theodore Paul Wright described the effect of learning on production costs in the aircraft industry. This form, in which \"unit cost\" is plotted against \"total production\", is sometimes called an experience curve.\n\nThe familiar expression \"a steep learning curve\" is intended to mean that the activity is difficult to learn, although a learning curve with a steep start actually represents rapid progress.\n\nThe first person to describe the learning curve was Hermann Ebbinghaus in 1885. His tests involved memorizing series of nonsense syllables, and recording the success over a number of trials. The translation does not use the term \"learning curve\"—but he presents diagrams of learning against trial number. He also notes that the score can decrease, or even oscillate.\n\nThe first known use of the term \"learning curve\" is from 1903: \"Bryan and Harter (6) found in their study of the acquisition of the telegraphic language a learning curve which had the rapid rise at the beginning followed by a period of retardation, and was thus convex to the vertical axis.\"\n\nPsychologist Arthur Bills gave a more detailed description of learning curves in 1934. He also discussed the properties of different types of learning curves, such as negative acceleration, positive acceleration, plateaus, and ogive curves. (Fig 1)\n\nIn 1936, Theodore Paul Wright described the effect of learning on production costs in the aircraft industry and proposed a mathematical model of the learning curve.\n\nIn 1968 Bruce Henderson of the Boston Consulting Group (BCG) generalized the Unit Cost model pioneered by Wright, and specifically used a Power Law, which is sometimes called \"Henderson's Law\". He named this particular version the experience curve.\nResearch by BCG in the 1970s observed experience curve effects for various industries that ranged from 10 to 25 percent.\n\nThe economic learning of productivity and efficiency generally follows the same kinds of experience curves and have interesting secondary effects. Efficiency and productivity improvement can be considered as whole organization or industry or economy learning processes, as well as for individuals. The general pattern is of first speeding up and then slowing down, as the practically achievable level of methodology improvement is reached. The effect of reducing local effort and resource use by learning improved methods paradoxically often has the opposite latent effect on the next larger scale system, by facilitating its expansion, or economic growth, as discussed in the Jevons paradox in the 1880s and updated in the Khazzoom-Brookes Postulate in the 1980s.\n\nA learning curve is a plot of proxy measures for implied learning (proficiency or progression toward a limit) with experience.\n\n\nFor the performance of one person in a series of trials the curve can be erratic, with proficiency increasing, decreasing or leveling out in a plateau. (Fig 1)\n\nWhen the results of a large number of individual trials are averaged then a smooth curve results, which can often be described with a mathematical function. (Fig 2)\n\nSeveral main functions have been used:\n\n\n\n\n\nThe page on \"Experience curve effects\" offers more discussion of the mathematical theory of representing them as deterministic processes, and provides a good group of empirical examples of how that technique has been applied.\n\nPlots relating performance to experience are widely used in machine learning. Performance is the error rate or accuracy of the learning system, while experience may be the number of training examples used for learning or the number of iterations used in optimizing the system model parameters. The machine learning curve is useful for many purposes including comparing different algorithms, choosing model parameters during design, adjusting optimization to improve convergence, and determining the amount of data used for training.\n\nInitially introduced in educational and behavioral psychology, the term has acquired a broader interpretation over time, and expressions such as \"experience curve\", \"improvement curve\", \"cost improvement curve\", \"progress curve\", \"progress function\", \"startup curve\", and \"efficiency curve\" are often used interchangeably. In economics the subject is rates of \"development\", as development refers to a whole system learning process with varying rates of progression. Generally speaking all learning displays incremental change over time, but describes an \"S\" curve which has different appearances depending on the time scale of observation. It has now also become associated with the evolutionary theory of punctuated equilibrium and other kinds of revolutionary change in complex systems generally, relating to innovation, organizational behavior and the management of group learning, among other fields. These processes of rapidly emerging new form appear to take place by complex learning within the systems themselves, which when observable, display curves of changing rates that accelerate and decelerate.\n\n\"Learning curves\", also called \"experience curves\", relate to the much broader subject of natural limits for resources and technologies in general. Such limits generally present themselves as increasing complications that slow the learning of how to do things more efficiently, like the well-known limits of perfecting any process or product or to perfecting measurements. These practical experiences match the predictions of the second law of thermodynamics for the limits of waste reduction generally. Approaching limits of perfecting things to eliminate waste meets geometrically increasing effort to make progress, and provides an environmental measure of all factors seen and unseen changing the learning experience. Perfecting things becomes ever more difficult despite increasing effort despite continuing positive, if ever diminishing, results. The same kind of slowing progress due to complications in learning also appears in the limits of useful technologies and of profitable markets applying to product life cycle management and software development cycles). Remaining market segments or remaining potential efficiencies or efficiencies are found in successively less convenient forms.\n\nEfficiency and development curves typically follow a two-phase process of first bigger steps corresponding to finding things easier, followed by smaller steps of finding things more difficult. It reflects bursts of learning following breakthroughs that make learning easier followed by meeting constraints that make learning ever harder, perhaps toward a point of cessation.\n\n\nThe expression steep learning curve is used with opposite meanings. Most sources, including the \"Oxford English Dictionary\", the \"American Heritage Dictionary of the English Language\", and \"Merriam-Webster’s Collegiate Dictionary\", define a learning curve as the rate at which skill is acquired, so a steep increase would mean a quick increment of skill.\nHowever, the term is often used in common English with the meaning of a difficult initial learning process.\n\nArguably, the common English use is due to metaphorical interpretation of the curve as a hill to climb. (A steeper hill is initially hard, while a gentle slope is less strainful, though sometimes rather tedious. Accordingly, the shape of the curve (hill) may not indicate the total amount of work required. Instead, it can be understood as a matter of preference related to ambition, personality and learning style.)\nThe term \"learning curve\" with meanings of \"easy\" and \"difficult\" can be described with adjectives like \"short\" and \"long\" rather than \"steep\" and \"shallow\". If two products have similar functionality then the one with a \"steep\" curve is probably better, because it can be learned in a shorter time. (Fig 9) On the other hand, if two products have different functionality, then one with a \"short\" curve (a short time to learn) and limited functionality may not be as good as one with a \"long\" curve (a long time to learn) and greater functionality. (Fig 10)\n\nFor example, the Windows program Notepad is extremely simple to learn, but offers little after this. At the other extreme is the UNIX terminal editor vi or Vim, which is difficult to learn, but offers a wide array of features after the user has learned how to use it.\n\nBen Zimmer discusses the use of the term \"ON a steep learning curve\" in an article \"A Steep Learning Curve\" for \"Downton Abbey\", concentrating mainly on whether it is an anachronism. \"Matthew Crawley, the presumptive heir of Downton Abbey and now the co-owner of the estate, says, 'I've been on a steep learning curve since arriving at Downton.' By this he means that he's had a difficult time learning the ways of Downton. Unfortunately, people didn't start talking that way until the 1970s.\"\n\nZimmer also comments that the popular use of \"steep\" as \"difficult\" is a reversal of the technical meaning. He identifies the first use of \"steep learning curve\" as 1973, and the \"arduous\" interpretation as 1978.\n\n\n"}
{"id": "47154642", "url": "https://en.wikipedia.org/wiki?curid=47154642", "title": "Lincoln and Darwin", "text": "Lincoln and Darwin\n\nLincoln and Darwin: Shared Visions of Race, Science, and Religion is a 2010 book by James Lander about the lives and views of Abraham Lincoln and Charles Darwin.\n\nAbraham Lincoln and Charles Darwin were born on the same day, February 12, 1809. Both lost their mother at a young age and, despite their differences in upbringing, both men saw themselves as autodidacts. Lander argues that they also shared an interest in science and a skeptical approach to religion. Darwin closely followed the events of the American Civil War and wanted Lincoln and the Union to prevail, but it is unlikely that Lincoln read Darwin's work.\n\n\"Lincoln and Darwin\" is structured as a series of alternating narratives concerning each man's interactions with the events and discoveries of the mid-19th century. Lander explores similarities in the intellectual development, concerns, and impacts of Abraham Lincoln and Charles Darwin, focusing in particular on the issue of slavery in the United States, which both men influentially opposed. Lander's broader argument is that Lincoln and Darwin shared the same outlook on the central issues of race, science, and religion. He also looks at the relationship between science and race in the 19th century United States and the emergence and influence of scientific racism. Lander situates Lincoln and Darwin against their respective opponents: Stephen A. Douglas, Lincoln's rival in Illinois politics, and Louis Agassiz, an advocate of polygenism.\n\nTom Allen, in \"The Journal of the Civil War Era\", wrote that \"Lincoln and Darwin\" \"is not always completely convincing\" with regard to the \"shared vision\" Lander identifies, but concluded that the book \"is well worth reading. The prose is delightfully lucid, and the parallel account of two lives so apparently different provides a fresh perspective on the intellectual culture of the nineteenth century.\"\n\nJean H. Baker, writing in \"Civil War History\", described \"Lincoln and Darwin\" as \"a profound comparison of the two men's perspectives and ... a worthy addition to the numerous individual studies of either man\", and praised Lander for providing a new means of understanding and appreciating each man.\n\nSteven Conn, in the \"Reports of the National Center for Science Education\", noted that Lander's comparisons occasionally appear \"a little strained\", but that \"more often than not these comparisons and juxtapositions persuade\"; and praised in particular Lander's analysis of the interactions between race and science.\n\nStephen L. Hansen, in the \"Journal of the Illinois State Historical Society\", criticized Lander's \"optimistic and sentimental view\" of Lincoln's attitudes on race, but praised the book's \"readable style\" and concluded \"This is a book that should be read, discussed, and enjoyed.\"\n\nMark Largent, writing in \"Isis\" described \"Lincoln and Darwin\" as \"a strange project\", but nonetheless \"quite engaging because it allows Lander to bring into focus broad questions about the relationship between individuals and their contexts as well as some specific questions about mid-nineteenth-century Western thought.\"\n\nDavid Turley, writing in \"American Nineteenth Century History\", observed that the book contains little original research and questioned the coherence of its themes \"applied to Lincoln and Darwin \"together\"\", but praised \"Lander's lucid, succinct, and up-to-date accounts of the topics that he deploys to illustrate his protagonists' involvement with his three main themes.\"\n\n\n"}
{"id": "1172401", "url": "https://en.wikipedia.org/wiki?curid=1172401", "title": "List of ZX Spectrum clones", "text": "List of ZX Spectrum clones\n\nThe following is a list of clones of Sinclair Research's ZX Spectrum home computer:\n\nThe only official clones of the Spectrum were made by Timex. There were three models developed, only two of which were released:\n\nA significantly more sophisticated machine than the original Spectrum. The most significant changes were the addition of a cartridge port, an AY-3-8912 sound chip and an improved ULA giving access to better graphics modes. The TS2068 was marketed in the United States, while very similar machines were marketed in Portugal and Poland as the Timex Computer 2068 (TC2068) and Unipolbrit Komputer 2086 (UK2086) respectively. A small amount of TC2068 were also sold in Poland.\n\nA machine similar to the Spectrum 48K, but with the improved ULA from the TC2068 allowing access to the improved graphics modes. Marketed only in Portugal and Poland.\n\nA never released variant of the TS2068 with 16 KB of RAM.\n\nATM (ATM Turbo) was developed in Moscow, in 1991, by two firms, MicroArt and ATM. It has Z80 at 7 MHz, 1024 KB RAM, 128 KB ROM, AY-8910 (two ones in upgraded models), 8-bit DAC, 8-bit 8-channel ADC, RS-232, Centronics, Beta Disk Interface, IDE interface, AT/XT keyboard, text mode (80×25, 16 possible colours, 8×8 pattern), and three graphics modes.\n\nAn open project to build a ZX Spectrum compatible computer. The CPU is Zilog Z380 (a 32-bit version of the Z80, capable of running at 40 MHz), it has its own graphic adapter, AT-keyboard, own BIOS and extended BASIC-ROM, and RAM expandable up to 4GB linear. The computer is supposed to be almost 100% compatible. Standard devices of are HDD-controller, DMA vs IRQ controller, ROM-Task Switching and more. So far only the HDD-controller is produced but the rest exists as drawings. All the plans are freely available.\n\nA Russian clone of the 48K ZX Spectrum. ULA replacement made with K556PT4 and K155PE3. CPU running at a higher frequency (4 MHz) which made it less compatible.\n\nA ZX Spectrum clone made in St. Petersburg, Russia in 1993. The size of the system unit is 16.8 × 10 × 2½ inches. It even uses a Russian Z80 clone as CPU.\n\nA Russian clone of the ZX Spectrum. The name of the Bi Am ZX-Spectrum 48/64 suggests that it comes with 64 KB RAM. The size of the system unit is 10 × 8.4 × 2 inches. Made of metal. Has the sign Made in RF (Russian Federation) at the back. It was produced in 1992–1994.\n\nThe Bi Am ZX-Spectrum 128 was a 128 KB version of the same computer.\n\nA ZX Spectrum clone built in Braşov, Romania.\n\nA Romanian ZX Spectrum clone made by Intreprinderea Electronica. It is called 'Calculator pentru Instruire Personală' which means 'computer for personal teaching'. The keyboard looks nice, but the key switches are very simple and therefore so is the 'feeling'. A nicely built PCB with 45 chips (most 74-family) inside. The ROM is original Sinclair, although instead of the Sinclair copyright message, it states 'BASIC S'. Only one set of 8× 1-bit 64 KB RAMs present. The power supply is the size and weight of a couple of bricks including a huge transformer unlike the now-standard switching power supply.\n\nA Russian clone of the ZX Spectrum with 48 KB RAM.. It is a modified version of Leningrad 2, produced by co-op Composite.\n\nThe Czerweny CZ 2000, Czerweny CZ Spectrum and Czerweny CZ Spectrum Plus were Argentinian produced clones.\n\nA Russian clone of ZX Spectrum+ manufactured in 1991, at a former military plant, near the city of Zelenograd. Fully compatible with the Spectrum+, the Delta came equipped with 48 KB of RAM, video output, cassette in/out, two joysticks ports (both Kempston and Sinclair), RGB adjustment controls, and its own expansion port for Russian hardware.\n\nThe Delta originally sold for about 620DM, and sold very well: for a few months it was on the bestseller list in the region.\n\nAt least in Czechoslovakia the machines sold under the name Delta around 1986, were re-badged unsold ZX Spectrum+ from the UK. As they were actually ZX Spectrum+ they resemble no further similarities with the Russian clone. Various stickers cover up hints of made in the UK and official Sinclair badging. It was coming with an original English user guide along with very good translation and the original cassette of the game Chequered Flag. more\n\nPossibly related to Delta S-128.\n\nA Russian clone of ZX Spectrum built in Voronezh, Kazan and other cities since 1990 that can run at up to 7 MHz. Comes with kempston and sinclair joystick ports and ports both for TV and RGB monitor. It has a printer interface and sound processor. As it is a modular design you can add disk controller.\n\nThese were derivatives from the \"Delta\" series. Changes included more relaxed hardware planning, bigger case and partially non compatible ROM. The machine had built-in Russification feature, which was toggling charset to Russian when pressing the dedicated key (Sending BASIC code #209), and back to English charset (Sending BASIC code#210). These changes dissallow any floppy drive usage with these clones, and also, a lot of hacked titles, using famous \"Hacked by Bill Gilbert\" loader, will not launch. Later, corrected rom was released, which while still not able to work with floppy, was more compatible with game titles, but still not was fully compatible, games like \"Pole Position\" or \"Starfox\" will crash after loading. Additional changes were introduced in \"Delta SB\", it has extended ROM, and came with 4 game titles pre-built in. These titles were selected by additional hardware switches, located at top left side of computer. Pressing any of them will cause immediate reset and load of the corresponding title. Included titles generally vary, but most popular were: \"Commando\", \"Astro Marine Corps\", \"Dan Dare 3\", \"Star Invaders 2\".\n\nSome of these clones were manufactured in Tbilisi, Republic of Georgia, at currently abandoned Military Scientific Plant \"Skhivi\". No references to real manufacturer was given, and all data refer like this was an original product from Zelenograd. The difference may be noted by the correction table of user manual. In original manual, it was hand written and rotoscoped, the Georgian release included computer typed correction list.\n\nThe Didaktik was a series of home computers produced in Skalica, former Czechoslovakia, now Slovakia. Later models compatible with ZX Spectrum were based on the U880 and Zilog Z80 processors.\nThere were three main models of Didaktik ZX clones: First was Didaktik Gama (released in three variants 87, 88 and 89). Didaktik Gama has 80KB RAM comparing to original ZX spectrum. Gama-series was soon followed by the Didaktik M (first variant released at 1990 second variant release at 1991), M contain much better keyboard and Sinclair and Kempston Joystick ports. Last ZX spectrum compatible model was Didaktik Kompakt (1991) which has integrated 3,5 Floppy disk mechanic and sound chipAY-3–8920 and still 48KB of RAM.\n\nA Soviet clone of the ZX Spectrum home computer. It was based on an analogue of the Zilog Z80 microprocessor. Its name comes from Dubna, a town near Moscow where it was produced, and \"48K\" stands for 48 KBs of RAM.\n\nAlso known as the Elara-Disk 128 was a Russian clone of the 128K ZX Spectrum with 58-key keyboard, disk drive, kempston and sinclair joystick. It is possible to expand it but it's slightly incompatible due to some ports are changed.\n\nPolish clones of the ZX Spectrum. It had a full size keyboard and even a paper holder. The reason it has a paper holder is that the case was originally designed for a small electric organ. A disk drive was available and there also was a version of CP/M called CP\\J for this machine. The updated 804 Junior PC had an internal 3.5\" diskdrive.\n\nIn Poland the computer that won a contest for being the school computer - \"Elwro 800 Junior\" used DIN connectors for monitor output, cassette adapter, and Junet. Junet had two inputs - in and out(like MIDI). Student computers connected by DIN cables to the teacher's computer, which had the costly floppy drive and printer. Other uses of Junet were for sending messages, or to allow the teacher to see what students are doing on their screens, at the teacher's computer. The computer had also optional Spectrum net, but it was simple jack input/output. To send data the user had to do SAVE on cassette in Spectrum mode, and input had to be connected to Timex/Spectrum. Other ports used D-subminiature connectors, for RGB video, joystick, printer, and floppy drive. \n\nA series of ZX Spectrum clones was manufactured in Romania from 1985 to 1994, by ICE Felix. The designation HC means Home Computer, and for the first three models in the series, the number is the year of first manufacture. Models in the series were: HC 85, HC 88, HC 90, HC 91, HC91+ (HC128), , HC386.\n\nThe earliest version, HC 85, closely resembled the Spectrum, with a built-in BASIC interpreter, Z80A processor, 48 KB RAM, tape, and TV interfaces. It was used in schools/universities and as a personal computer.\n\nAn optional Interface 1 extension was available for the HC 85, HC 90, and HC 91. It was functionally similar to the ZX Interface 1, but instead of Microdrives it supported single-density or double-density floppy disks.\n\nThe HC 90 had a redesigned circuit board supporting fewer, larger memory chips; it was functionally equivalent with the HC 85.\n\nThe HC 91 had a modified keyboard with 50 keys instead of 40. It had 64 KB RAM and extra circuitry which provided CP/M support, if the Interface 1 extension was also present.\n\nThe HC 2000 (manufactured from 1992–94) had a built-in 3.5-inch 720 KB disk, and 64 KB RAM, it could be used both as a Spectrum clone with added disk functionality (only 48 KB RAM available) or in CP/M mode, giving access to the full 64 KB memory. Essentially, it brought the HC 91, Interface 1, and floppy disk in a single case.\n\nThe last model to be made in the Z80 line was the HC91+. It was a ZX Spectrum 128K clone in a HC91 case and keyboard and had some compatibility problems. For the first time, the AY-8910 sound chip was offered as an add-on service and was soldered on the board by factory technicians. Demoscene demos had problems running multi-colour effects and displaying sound VU-meter like effects lacking some data from the AY chip probably.\n\nA Russian clone of the ZX Spectrum made in 1993 in Moscow. It is very similar to the Pentagon but INT is re-made to be like the original. There exists four or five models of it but there are only minor differences between them, for instance one has wrong released turbo Beta Disk interface so when you read/write disks on your own GRM everything is normal, but when you want to save something to this disk on any another machine then all information on disk will be destroyed. They are not easy to expand because of some PLM (small ones) chips inside which does not allow you take some signals you may need to attach modem, etc.\n\nThe GRM2+ board was used to create the GrandBoard2+\n\nA Russian clone of ZX Spectrum. The size is 350×280×35 mm (13.2 × 8.4 × 2 inches). Developed and manufactured from 1994, by Independent Science-Manufacturing Laboratory of Computer Techniques in city Frajzino. Based on board GRM2+\n\n\nA UK clone of the 48K ZX Spectrum, designed and developed by Chris Smith to aid the reverse engineering of the ZX Spectrum custom ULA chip, and its research documentation. Complete in 2008, it is the first 100% timing compatible clone. Until 2012/13 the Harlequin existed only as a breadboard prototype, but recently, José Leandro Martínez, Ingo Truppel and others produced a limited number of PCB versions (documented here) as an exact board replacement for an actual ZX Spectrum.\n\nA Hungarian ZX Spectrum clone made by Híradástechnikai Szövetkezet, released in 1986. It was the third computer from the company. The two first computers HT 1080Z and HT 2080Z were clones of TRS-80 and were unsuccessful because of the poor graphics features and high price. They were both school computers. In 1986, in Hungary the school computers have to fulfill new requirements: they have to produce high resolution graphics and support the special Hungarian characters. That's why the HT 3080C came out and it was both compatible with the previous HT machines as well as the ZX Spectrum. You could switch between TRS-80 and ZX Spectrum mode. It had a graphics resolution of 256x192 (standard Speccy) and an AY-chip for sound (to be compatible with the previous HT machines, not with the 128K Spectrum). ROM: 32 KB (Speccy+HT ROMs), RAM: 64 KB (possibly also a requirement for Hungarian school computers, because all school computers in Hungary had 64 KB). It had a Commodore serial port so you could also connect peripherals made for the C64 to it, for instance the 1541 disk drive.\n\nA Soviet/Russian 8-bit home computer, based on the Sinclair Research ZX Spectrum hardware architecture. It also featured a CP/M mode and Forth mode or LOGO mode, with the Forth or LOGO operating environment residing in an on-board ROM chip.\n\nA clone of the ZX Spectrum+ from Investronica in Spain. Released after Amstrad bought Sinclair Research Ltd. Looked much like a normal 48+. It has compatibility problems with some games (Bombjack, Commando, \"Top Gun\", etc.). On the rear there was a Kempston joystick connector.\n\nA Romanian clone. The casing was adapted from a telephone.\n\nA Russian clone of the ZX Spectrum that came in 1998. It was made by NEMO company and has 1024 KB of RAM and was a rival of Scorpion ZS 256 and has a slightly lower price. It has controller for PC keyboard and HDD but not for floppy although it was available as an extension card. It's very easy to connect General Sound. Has turbo mode at 10 MHz.\n\nA Russian clone of the ZX Spectrum which used PZY K573PF2(5) to produce the TV signal. It was developed and manufactured from 1991 but was never made in as many copies as the Leningrad 1.\n\nA Czechoslovakian clone of ZX Spectrum, developed by František Kubiš at 1984, student of EF SVŠT (Electrotechnical Faculty of Slovak Technical University) Bratislava. ULA designed from discrete 74xx ICs, screen part or RAM was synchronized perfectly, without CPU blocking. \n\nA series of Russian ZX Spectrum clones.\n\nKvorum had 48K KB memory. Probably a clone of the standard 48K Spectrum\n\nKvorum 64 had 64 KB memory.\n\nKvorum 128 was a clone with built in tests, memory monitor and copying in ROM. Possibility to run CP/M and TR-DOS (betadisk).\n\nKvorum 128+ was as the Kvorum 128 but comes with built-in 3.5\" drive.\n\nA series of two Russian clones of the ZX Spectrum.\n\nIn 1989, came Leningrad 1 a clone of the 48K which came to be the cheapest of the mass-made clones. They attempted to make the design as simple as possible and more compact. The only addition was a joystick port. It was designed by Sergey Zonov who later went on and created the Scorpion.\n\nLeningrad 2 came in 1991. The joystick was changed to Kempston compatible and the keyboard was much improved. It sold in great numbers.\n\nA clone of the ZX Spectrum made in Russia in 1990. It runs at 2.5 MHz with 48 KB RAM. It has ports for Sinclair and Kempston joysticks. The name suggests it's related to Master K11\n\nA Russian clone of the ZX Spectrum made in Ivanovo in 1991. 48 KB RAM, 16 KB ROM and built in(?) kempston joystick interface. The size of the system unit is 14 × 8 × 2½ inches, the weight is 1.5 kg approx.\n\nThe TK90X was the first Brazilian ZX Spectrum clone made in 1985, by Microdigital Eletronica, a company located at São Paulo, Brazil, that manufactured some ZX81 clones before (TK82, TK82C, TK83 and TK85) and a ZX80 clone (TK80). The ROM were hacked to allow an UDG editor and accented characters (incompatibility issues are very rare or none). The keyboard membrane is more resistant than the original from ZX-Spectrum 48K (very similar to the actual PS2/USB keyboard we use now), and there is also a Sinclair-compatible joystick connector between expansion and mic/ear connectors.\n\nThe TK95 microcomputer was the evolution of TK90X made in the 1980s, by Microdigital Eletronica, a company located at São Paulo, Brazil that manufactured some ZX81 clones before (TK82, TK82C, TK83 and TK85) and a ZX80 clone (TK80). The first version was launched in November 1986. This \"evolution\" was mostly \"cosmetic\" at the keyboard and whole ABS plastic case. The board is exactly the same as the TK90X and its 16 KB ROM has only minor differences.\n\nA Czech clone of the 48K ZX Spectrum. The ROM include Roman chars and Roman chars with Czech diacritic marks. As the Mistum was a is a hardware design they may look very different as each builder made his own case and keyboard. An article on how to build a Mistrum was published in the Czechoslovak amateur radio magazine \"Amatérské Radio\" nr 1/89.\n\nMoskva was the name of two ZX Spectrum clones.\n\nMoskva 48K (Москва/Moscow) was the first mass-produced clone of the 48K Spectrum in Russia. It was first made in 1988.\n\nMoskva 128K was a faithful clone of ZX Spectrum 128K with built-in printer interface, joystick, TV/RGB port but without sound processor and disk drive. It was first made in 1989.\n\nA Russian ZX Spectrum clone from 1990, designed for transport in a case. It was made for diplomatic offices and children. It is compatible with Dubna 48K and has a joystick port. At the time of launch time the price was 650 roubles.\n\nпа́рус ВИ201 (\"Sail VI-201\")\n\nA Russian ZX Spectrum clone from around 1993. Size is 14 × 7.2 × 2 inches. The name suggest that it has 64 KB of RAM and was made by Peters Plus, Ltd. that went on to make the Sprinter.\n\nPeters MC64S1 has Service monitor (additional ROM), fast loading in the RAM frequently used software. Assembler & monitor, test of a video and copyist for tape are included in first version Service monitor.\n\nPeters MC64S2 has Service monitor 2, which included of Tetris, test of a video, copyist for tape and text editor. It has a printer slot.\n\nA Russian clone of the ZX Spectrum.\n\nPeters MD-256S3 has Service monitor 3, including an alternate (for TR-DOS) disk operational system IS-DOS.\n\nA ZX Spectrum clone produced between 1989 and 1994, by Selto-Rotor (Scientifically technical industrial creative association) a former military factory.\n\nA Soviet ZX Spectrum clone developed in 1991, in Moscow by Kondor and Kramis.\n\nIt has Z80 at 7 MHz, up to 1024 KB RAM, 64 KB ROM, Centronics, AY8910 sound chip, Beta 128 disc interface, IDE interface, and 512x240 multi-colour (i.e. two possible colours per 8×1 block) graphics mode for CP/M.\n\nUsers liked to plug in two 8-bit DACs to play 4-channel modules of Scream Tracker.\n\nIt was possible to run CP/M and a graphics mode with 512x240 pixels was added to be able to run 80 characters per row. It has both parallel and serial ports, sound processor and the possibility to use an IBM keyboard. In later issues it also had a hard disk interface and turbo mode.\n\nA East-German private clone of the ZX Spectrum. \n\nA clone of ZX Spectrum Plus produced in 1990 in Lithuania. It has Russian symbols instead of lower case English and is reported to be a good and reliable machine because it was produced by ex-military plants as a part of conversion program.\n\nScorpion (), was a very widespread ZX Spectrum clone produced in St. Petersburg, Russia by Sergey Zonov. It had a Z80 processor and from 256 to 1024 KB memory, the Shadow Service Monitor (debugger) in the basic ROM activated by pressing the Magic Button (NMI), a ProfROM with additional included ZX-Word editor, a clock, HDD utilities and more. Various extensions were produced, including SMUC — adapter of IDE and ISA slots, which allowed the use of IBM PC compatible hard drives and extension cards.\n\nA Russian clone of the ZX Spectrum. It was made in 1990 and comes with 64 KB RAM and 16 KB ROM. The size of the system unit is 12x8x2½ inches, the weight is 1.5 kg.\n\nA Soviet clone of the ZX Spectrum developed in the \"Signal\" factory within the Moldovan SSR in 1989.\n\nThe original Sintez resembled the \"Spectrum +\" model, while the -Sintez- was an improved version with a more common mechanical keyboard, an added serial port, as well as the ability for an 8080 or related processor (for example 8255) to be added and used together with the UA 880. \n\nWhile it was software compatible with ZX Spectrum 48K and has two Interface 2 joystick ports, its hardware was quite different, utilizing different memory chip set-up, lacking slowdown when accessing certain areas of memory, as in original ZX Spectrum, so, certain applications and games may not behave correctly or crash.\n\nAn East-German clone of the ZX Spectrum. It came with built in joystick interface and either 48 or 128 KB RAM. It was sold in kit form by Hübner Elektronik.\n\nA Russian clone of the 48K ZX Spectrum. It used a membrane keyboard and has both Latin and Cyrillic letters. It was made in 1991, by Oryol PC manufacturer, a former military factory. The ROM includes a monitor program.\n\nRussian clone of ZX Spectrum, produced on JSC \"Radiozavod\" in Penza from 1990 to 1995.\n\nTimS was developed around the university of Timişoara in Romania and the name TimS comes from TIMişoara and Spectrum. The models were extended in various ways and production continued into the early 1990s. The computer is fully compatible with ZX Spectrum, but comes with 64 KB RAM. At the back it has Source (ALIM), parallel and serial connectors, cassette player, monitor and TV connector, reset button. Later models have a joystick connection, 192 KB RAM and AY-3-8912 sound chip.\n\nAlso known as ZX-Forum 2 or XX Frium2. A relatively unsuccessful Russian clone of the ZX Spectrum. It was designed with two Z80 processors, one serving as the video processor, and had an RS-232 port, turbo mode, IBM keyboard, 10 Mbit/s local network and a CGA graphics mode with 640x200 pixel resolution. The memory is expandable to 512 KB.\n\nSeveral emulators are also available to enable Spectrum software to be run on other hardware.\n\n"}
{"id": "26099638", "url": "https://en.wikipedia.org/wiki?curid=26099638", "title": "Messestadt Riem", "text": "Messestadt Riem\n\nMessestadt Riem (literally: Convention City Riem) is an urban district in the east of Munich. It is part of the municipality 15 Trudering-Riem, and located entirely on the grounds of the 1992 abandoned Munich-Riem airport and includes today, along with a residential area, the Neue Messe München trade fair center and the Riem Arcaden shopping mall.\n\nMessestadt Riem is, after Freiham, the second youngest district of Munich. After the flight operation was moved in 1992 to the new Munich Airport, the old airport building in Riem could be emptied and the construction of the new exhibition center started from the mid-1990s, with the corresponding rapid transit connections in the following years. In 1998, the fair could finally move out of their exhibition halls on the Theresienhöhe to the spacious new building in the fair city. Many other companies also moved and established themselves on the former airport site.\nImmediately west of the west entrance, the \"Messesee\" (Fair lake) was created, 390 m long (north-south) and 46 to 94 m wide (east-west), with a water area of 2.6 hectare.\n\nIn the southern part of the former airport a development area with rental apartments and condominiums was created. With the Riem Arcaden, shopping for daily items is easily accomplished, and because of the numerous pedestrian zones, many kindergartens and three primary schools the fair site is a suitable location for young families to live. The first projects for car-free living in Munich have been established here since 1998.\nThe first multi-family passive house and the first multifamily zero-energy house in Munich were created here.\n\nSouth of the residential area is the Riemer Park. In 2005, the Bundesgartenschau was held here after Munich won the corresponding competition in 2000. For this purpose Riemer Park, a large landscaped park, was built in 2002. After the Bundesgartenschau Riemer Park, the third largest park in the city of Munich, was opened to the public as a recreation area. With enormous effort, a lake was created in its center, known under the name Buga Lake (officially Riemer lake). The lake is east to west 800 m long, 150 m wide, 10 ha in size, up to 18 m deep and contains 100,000 m of water. It is an upscale ground water reserve, which can also be used for bathing. Because the water table is too low in the area and also varies greatly seasonally, a concrete trough was applied and the three pumps, each pumping a constant 40 liters of water per second into the lake, stopping the water from accumulating and causing flooding in the basements of surrounding residential buildings, among other things a drain pipe was laid under the sea. On the east bank there is a beach, while on the west bank, where a pedestrian bridge leads over the lake, a sedimentation zone was created with aquatic plants. Located near the west bank is two more, shallow sedimentation basins with water plants that are only 1100 and 800 m in size.\n\nIn 2005, in the West of Messestadt Riem, an ecumenical church center where the Protestant St. Sophia and the Catholic St. Florian churches were dedicated and opened. \n\nMessestadt Riem is connected to two rapid transport stations of Munich U-Bahn, as well as, the bus lines 139, 186, 189, 190 and N74. The Autobahn 94 passes to the north of the fair city. Discussions are ongoing about a railway connection to Messestadt Riem as part of the Erding Ring Closure to the airport.\n"}
{"id": "1674626", "url": "https://en.wikipedia.org/wiki?curid=1674626", "title": "Metamodeling", "text": "Metamodeling\n\nA metamodel or surrogate model is a model of a model, and metamodeling is the process of generating such metamodels. Thus metamodeling or meta-modeling is the analysis, construction and development of the frames, rules, constraints, models and theories applicable and useful for modeling a predefined class of problems. As its name implies, this concept applies the notions of meta- and modeling in software engineering and systems engineering. Metamodels are of many types and have diverse applications.\n\nA metamodel or surrogate model is a model of the model, i.e. a simplified model of an actual model of a circuit, system, or software like entity. Metamodel can be a mathematical relation or algorithm representing input and output relations. A model is an abstraction of phenomena in the real world; a metamodel is yet another abstraction, highlighting properties of the model itself. A model conforms to its metamodel in the way that a computer program conforms to the grammar of the programming language in which it is written. Various types of metamodels include polynomial equations, neural network, Kriging, etc. \"Metamodeling\" is the construction of a collection of \"concepts\" (things, terms, etc.) within a certain domain. Metamodeling typically involves studying the output and input relationships and then fitting right metamodels to represent that behavior. \n\nCommon uses for metamodels are:\n\nBecause of the \"meta\" character of metamodeling, both the praxis and theory of metamodels are of relevance to metascience, metaphilosophy, metatheories and systemics, and meta-consciousness. The concept can be useful in mathematics, and has practical applications in computer science and computer engineering/software engineering. The latter are the main focus of this article.\n\nIn software engineering, the use of models is an alternative to more common code-based development techniques. A model always conforms to a unique metamodel. One of the currently most active branch of Model Driven Engineering is the approach named model-driven architecture proposed by OMG. This approach is based on the utilization of a language to write metamodels called the Meta Object Facility or MOF. Typical metamodels proposed by OMG are UML, SysML, SPEM or CWM. ISO has also published the standard metamodel ISO/IEC 24744. All the languages presented below could be defined as MOF metamodels.\n\nMetadata modeling is a type of metamodeling used in software engineering and systems engineering for the analysis and construction of models applicable and useful to some predefined class of problems. (see also: data modeling).\n\nOne important move in Model Driven Engineering is the systematic use of Model Transformation Languages. The OMG has proposed a standard for this called QVT for Queries/Views/Transformations. QVT is based on the Meta-Object Facility or MOF. Among many other Model Transformation Languages (MTLs), some examples of implementations of this standard are AndroMDA, VIATRA, Tefkat, MT, ManyDesigns Portofino.\n\nMeta-models are closely related to ontologies. Both are often used to describe and analyze the relations between concepts\n\nFor software engineering, several \"types\" of models (and their corresponding modeling activities) can be distinguished:\n\nA library of similar metamodels has been called a Zoo of metamodels.\nThere are several types of meta-model zoos. Some are expressed in ECore. Others are written in MOF 1.4 - XMI 1.2. The metamodels expressed in UML-XMI1.2 may be uploaded in Poseidon for UML, a UML CASE tool.\n\n"}
{"id": "24474414", "url": "https://en.wikipedia.org/wiki?curid=24474414", "title": "Minimum Fisher information", "text": "Minimum Fisher information\n\nIn information theory, the principle of minimum Fisher information (MFI) is a variational principle which, when applied with the proper constraints needed to reproduce empirically known expectation values, determines the best probability distribution that characterizes the system. (See also Fisher information.)\n\nInformation measures (IM) are the most important tools of information theory. They measure either the amount of positive information or of \"missing\" information an observer possesses with regards to any system of interest. The most famous IM is the so-called Shannon-entropy (1948), which determines how much additional information the observer still requires in order to have all the available knowledge regarding a given system S, when all he/she has is a probability density function (PD) defined on appropriate elements of such system. This is then a \"missing\" information measure. The IM is a function of the PD only. If the observer does not have such\na PD, but only a finite set of empirically determined mean values of the system, then a fundamental scientific principle called the Maximum Entropy one (MaxEnt) asserts that the \"best\" PD is the one that, reproducing the known expectation values, maximizes otherwise Shannon's IM.\n\nFisher's information (FIM), named after Ronald Fisher, (1925) is another kind of measure, in two respects, namely,\n\n1) it reflects the amount of (positive) information of the observer,\n2) it depends not only on the PD but also on its first derivatives, a property that makes it a local quantity (Shannon's is instead a global one).\n\nThe corresponding counterpart of MaxEnt is now the FIM-minimization, since Fisher's measure grows when Shannon's diminishes, and vice versa. The minimization here referred to (MFI) is an important theoretical tool in a manifold of disciplines, beginning with physics. In a sense it is clearly superior to MaxEnt because the later procedure yields always as the solution an exponential PD, while the MFI solution is a differential equation for the PD, which allows for greater flexibility and versatility.\n\nMuch effort has been devoted to Fisher's information measure, shedding much light upon the manifold physical applications. As a small sample, it can be shown that the whole field of thermodynamics (both equilibrium and non-equilibrium) can be derived from the MFI approach. Here FIM is specialized to the particular but important case of translation families, i.e., distribution functions whose form does not change under translational transformations. In this case, Fisher measure becomes shift-invariant. Such minimizing of Fisher's measure leads to a Schrödinger-like equation for the probability amplitude, where the ground state describes equilibrium physics and the excited states account for non-equilibrium situations.\n\nMore recently, Zipf's law has been shown to arise as the variational solution of the MFI when scale invariance is introduced in the measure, leading for the first time an explanation of this regularity from first principles. It has been also shown that MFI can be used to formulate a thermodynamics based on scale invariance instead of translational invariance, allowing the definition of the Scale-Free Ideal Gas, the scale invariant equivalent of the Ideal Gas.\n"}
{"id": "40239247", "url": "https://en.wikipedia.org/wiki?curid=40239247", "title": "Mycobiota", "text": "Mycobiota\n\nMycobiota (plural noun, no singular) are a group of all the fungi present in a particular geographic region (e.g. \"the mycobiota of Ireland\") or habitat type (e.g. \"the mycobiota of cocoa\").\n\nMycobiota exist on the surface and in the gastrointestinal system of humans. There are as many as sixty-six genera and 184 species in the gastrointestinal tract of healthy people. Most of these are in the \"Candida\" genera.\n\nThough found to be present on the skin and in the gi tract in healthy individuals, the normal resident mycobiota can become pathogenic in those who are immunocompromized. Such multispecies infections lead to higher mortalities. In addition hospital-acquired infections by \"C. albicans\" have become a cause of major health concerns. A high mortality rate of 40-60% is associated with systemtic infection. The best-studied of these are \"Candida\" species due to their ability to become pathogenic in immunocompromised and even in healthy hosts. Yeasts are also present on the skin, such as \"Malassezia\" species, where they consume oils secreted from the sebaceous glands. \"Pityrosporum (Malassezia) ovale\", which is lipid-dependent and found only on humans. \"P. ovale\" was later divided into two species, \"P. ovale\" and \"P. orbiculare\", but current sources consider these terms to refer to a single species of fungus, with \"M. furfur\" the preferred name.\n\nThere is a peer reviewed mycological journal titled \"Mycobiota\".\n"}
{"id": "22000", "url": "https://en.wikipedia.org/wiki?curid=22000", "title": "Neural Darwinism", "text": "Neural Darwinism\n\nNeural Darwinism, a large scale theory of brain function by Gerald Edelman, was initially published in 1978, in a book called \"The Mindful Brain\" (MIT Press). It was extended and published in the 1987 book \"Neural Darwinism – The Theory of Neuronal Group Selection\".\n\nIn 1972, Edelman was awarded the Nobel Prize in Medicine or Physiology (shared with Rodney Porter of Great Britain) for his work in immunology showing how the population of lymphocytes capable of binding to a foreign antigen is increased by differential clonal multiplication following antigen discovery. Essentially, this proved that the human body is capable of creating complex adaptive systems as a result of local events with feedback. Edelman's interest in selective systems expanded into the fields of neurobiology and neurophysiology, and in \"Neural Darwinism\", Edelman puts forth a theory called \"neuronal group selection\". It contains three major parts:\n\nWith neuronal heterogeneity (by Edelman called \"degeneracy\"), it is possible to test the many circuits (on the order of 30 billion neurons with an estimated one quadrillion connections between them in the human brain) with a diverse set of inputs, to see which neuronal groups respond \"appropriately\" statistically. Functional \"distributed\" (widespread) brain circuits thus emerge as a result.\n\nEdelman goes into some detail about how brain development depends on a variety of cell adhesion molecules (CAMs) and substrate adhesion molecules (SAMs) on cell surfaces which allow cells to dynamically control their intercellular binding properties. This surface modulation allows cell collectives to effectively \"signal\" as the group aggregates, which helps govern morphogenesis. So morphology depends on CAM and SAM function. And CAM and SAM function also depend on developing morphology.\n\nEdelman theorized that cell proliferation, cell migration, cell death, neuron arbor distribution, and neurite branching are also governed by similar selective processes.\n\nOnce the basic variegated anatomical structure of the brain is laid down during early development, it is more or less fixed. But given the numerous and diverse collection of available circuitry, there are bound to be functionally equivalent albeit anatomically non-isomorphic neuronal groups capable of responding to certain sensory input. This creates a competitive environment where circuit groups proficient in their responses to certain inputs are \"chosen\" through the enhancement of the synaptic efficacies of the selected network. This leads to an increased probability that the same network will respond to similar or identical signals at a future time. This occurs through the strengthening of neuron-to-neuron synapses. And these adjustments allow for neural plasticity along a fairly quick timetable.\n\nThe last part of the theory attempts to explain how we experience spatiotemporal consistency in our interaction with environmental stimuli. Edelman called it \"reentry\" and proposes a model of reentrant signaling whereby a disjunctive, multimodal sampling of the same stimulus event correlated in time leads to self-organizing intelligence. Put another way, multiple neuronal groups can be used to sample a given stimulus set in parallel and communicate between these disjunctive groups with incurred latency.\n\nIt has been suggested that Friedrich Hayek had earlier proposed a similar idea in his book \"The Sensory Order: An Inquiry into the Foundations of Theoretical Psychology\", published in 1952 (Herrmann-Pillath, 1992). Other leading proponents include Jean-Pierre Changeux, Daniel Dennett and Linda B. Smith. William Calvin proposes true replication in the brain, whereas Edelman opposes the idea that there are true replicators in the brain.\n\nCriticism of Neural \"Darwinism\" was made by Francis Crick on the basis that neuronal groups are instructed by the environment rather than undergoing blind variation. A recent review by Fernando, Szathmary and Husbands explains why Edelman's Neural Darwinism is not Darwinian because it does not contain units of evolution as defined by John Maynard Smith. It is selectionist in that it satisfies the Price equation, but there is no mechanism in Edelman's theory that explains how information can be transferred between neuronal groups. A recent theory called Evolutionary Neurodynamics being developed by Eors Szathmary and Chrisantha Fernando has proposed several means by which true replication may take place in the brain. These neuronal models have been extended by Fernando in a later paper . In the most recent model, three plasticity mechanisms i) multiplicative STDP, ii) LTD, and iii) Heterosynaptic competition, are responsible for copying of connectivity patterns from one part of the brain to another. Exactly the same plasticity rules can explain experimental data for how infants do causal learning in the experiments conducted by Alison Gopnik. It has also been shown that by adding Hebbian learning to neuronal replicators the power of neuronal evolutionary computation may actually be greater than natural selection in organisms.\n\nJean Piaget (1896–1980) often used the concept of the \"schème\" (a supposed unit of action-coding), which he left as an abstraction. However, later theorizing led to the hypothesis that such \"schèmes\" were probably RNA-like molecules, at least in their simplest cases. Such molecular sites would need to intercommunicate mainly via infra-red signals: messages which would be able to travel through fatty tissue such as myelin, but would be blocked by water barriers (of >20 microns). This \"new\" \"[R]-system\" was proposed as a cooperative alternative arrangement, more concerned with digital signals and data required \"for advanced thinking\"—(whereas the traditional \"[A]-system\" of action-potentials and synapses would perhaps cope more with activities such as logistics, muscle-control, and pattern-recognition which can probably manage using \"analogue\" devices—a division of labour).\n\nWhether or not one accepts those actual details, such a \"molecule-based\" system offers (i) an obvious scope for clear-cut encoding, (ii) an obvious explanation for any inherited behaviour-traits, (iii) a vastly greater number of candidate-codes from which to select-or-waste in a Darwinian contest; etc. Hence, this might be seen as overcoming Crick's objections, at least partially.\n\n\n\n"}
{"id": "38780056", "url": "https://en.wikipedia.org/wiki?curid=38780056", "title": "New Family Structures Study", "text": "New Family Structures Study\n\nThe New Family Structures Study (abbreviated NFSS) is an epidemiological study of LGB parenting conducted by sociologist Mark Regnerus of the University of Texas at Austin. The study surveyed over 15,000 adults between the ages of 18 and 39. The first research article based on data from the study was published in July 2012 in \"Social Science Research\", and concluded that children raised by parents in same-gender relationships were at a greater risk of several adverse outcomes, including \"being on public assistance, being unemployed, and having poorer educational attainment.\"\n\nRegnerus claimed his study was methodologically superior to previous research on the topic because it used a larger and more random sample. Nevertheless, the study was met with considerable criticism from many academics and scholarly organizations.\n\nThe NFSS surveyed over 15,000 adults between the ages of 18 and 39 and was conducted by Knowledge Networks on behalf of the University of Texas at Austin. Its stated purpose was to determine differences in outcomes among young adults raised by same-sex parents compared to young adults raised by \"their married biological parents, those raised with a step-parent, and those raised in homes with two adoptive parents.\" The survey collected data from young adults who had grown up in one of five unconventional families, namely, those where their parents are of the same sex, biologically unrelated parents adopted the respondent, parents were unmarried but co-habiting, biological mother had a romantic relationship with another man, and biological mother did not have a romantic relationship with another man. The survey also collected data from young adults from conventional families as a control group.\n\nThe study was funded by the Witherspoon Institute, which spent about $700,000 on it, and by the Bradley Foundation, which invested $90,000 in it. The Witherspoon Institute's president expected results that would be unfavorable to those supporting gay marriage. In the initial report, Regnerus stated that the Witherspoon Institute and the Bradley Foundation played no role in the design of the study, and dismissed accusations that these organizations had improperly influenced him. In 2013, however, in response to requests by the American Independent News Network, emails sent between Regnerus and Witherspoon Institute employee Brad Wilcox were released which cast doubt on these statements. In one email, Wilcox approved several items relating to the study on behalf of the Witherspoon Institute. Critics have also noted that Wilcox was on the editorial board of \"Social Science Research\", the journal in which the study was later published.\n\nCynthia Osborne, who is on the UT-Austin faculty along with Regnerus, argued the study was unable to show \"whether same-sex parenting causes the observed differences.\" She also said that \"Children of lesbian mothers might have lived in many different family structures, and it is impossible to isolate the effects of living with a lesbian mother from experiencing divorce, remarriage or living with a single parent.\" Similarly, Gary Gates of the Williams Institute argued that the study's comparison of children of lesbian mothers was a less fair comparison than, for instance, comparing \"children of heterosexual or same-sex couples who were raised in similar homes\".\n\nSeveral writers criticized Regnerus' study for classifying children as being raised by gay parents merely if one of their parents \"ever\" had a same-sex relationship until the child turned 18. Additionally, Regnerus himself acknowledged that other factors might explain the differences observed in his study, including \"...a lack of social support for parents, stress exposure resulting from persistent stigma, and modest or absent legal security for their parental and romantic relationship statuses.\" In the July 2015 issue of \"Social Science Research\", Cheng and Powell reanalyzed the data from Regnerus' study and found numerous potential measurement errors, and concluded that Regnerus' conclusions were due to these errors \"and other methodological choices\".\n\nSoon after the paper was published, blogger Scott Rose accused Regnerus of scientific misconduct for two reasons: deviating from ethical standards and possible falsification of his research. An inquiry was later conducted by the University of Texas-Austin which found that no investigation into these charges was warranted. In 2014, the Dean of the College of Liberal Arts at the University of Texas-Austin, Randy Diehl asked University of Texas sociologist and associate dean Marc Musick to review the controversy around the NFSS article as part of Regnerus' seventh-year post-tenure evaluation. Musick sympathetically summarized many of the prior criticisms, going on to allege that the survey itself was designed to ensure the conflation of family structure and the parents' same-sex orientation, practically guaranteeing negative results. Musick claimed that non-disclosure of this design flaw in the original article possibly violated University research ethics standards. Regnerus claimed the opposite, that the observed instability was due to social realities, not study design.\n\nIn July 2012, over 150 scientists wrote a letter to the editor of \"Social Science Research\" criticizing the study and raising concerns about the journal's peer review process. In the November 2012 issue of the journal, an audit was published by Darren Sherkat of Southern Illinois University regarding the peer-review process with respect to the Regnerus study (as well as another study from the same issue). The audit concluded that the peer-review process failed in these instances because of “both ideology and inattention” by the reviewers; he added that of the six reviewers, three of them were on record as opposing same-sex marriage. Sherkat also dismissed the study as \"bullshit\" in an interview and argued that its definition of gay fathers and lesbian mothers should have “disqualified it immediately” from being considered for publication.\n\nIn April 2013, journalist John Becker sued the University of Central Florida, where James D. Wright, editor-in-chief of \"Social Science Research\", worked. The suit alleged that the school has violated state law by failing to provide documents pertaining to the study's publication. Becker and others expressed suspicion on the fact that Regnerus' study had taken only six weeks to be published after it was first submitted, while other papers in the same issue took an entire year. \nIn August 2013, sociologist Philip N. Cohen wrote on his blog that Wright relied on paid consultants to review the paper and failed to disclose this when the study was first published. He also called for the paper to be retracted and for Wright to step down.\n\nIn the 2012 California case \"Golinski v. Office of Personnel Management\", several major medical organizations, including the American Psychological Association, filed an amicus brief in which they harshly criticized Regnerus' research. The brief argued that \"the Regnerus study sheds no light on the parenting of stable, committed same-sex couples – as Regnerus himself acknowledges...\"\n\nIn the study Simon Cheng and Brian Powell published on the July 2015 issue of \"Social Science Research\" a large number of potential measurement errors and other methodological choices were identified, which led to erroneous results. According to the authors, which discuss in details how even small differences in coding can profoundly shape empirical patterns, after repeating the analysis with sound methods, the \"[d]ifferences in being raised by gay/lesbian and heterosexual parents are minimal.\"\n\nRegnerus' study was defended by 18 social scientists in a letter written on the website of the Institute for Studies of Religion at Baylor University.\n\nRegnerus' former mentor Christian Smith has described the public and academic reaction to the \"New Family Structures Study\" as a \"witch hunt\" and said that the \"push-back\" to Regnerus' article \"is coming simply because some people don’t like where the data led.\" This backlash, Smith argues in his book \"The Sacred Project of American Sociology\", is a result of the content of sociology's \"sacred project\" (of mitigating oppression, inequality, etc.); Smith holds that the critical reaction, e.g. on methodological issues, displays a set of double standards insofar as work by other scholars could be (but is generally not) subjected to similar criticism.\n\nThe New Family Structures Study was cited in amicus briefs the United States Supreme Court cases of \"United States v. Windsor\" and \"Hollingsworth v. Perry\". It was also cited by a Hawaiian judge in \"Jackson v. Abercrombie\".\n"}
{"id": "28786781", "url": "https://en.wikipedia.org/wiki?curid=28786781", "title": "Ny Teknik", "text": "Ny Teknik\n\nNy Teknik (meaning \"New Technology\" in English) is a weekly Swedish magazine with news, debates and ads in the field of technology and engineering. It is published in Stockholm, Sweden.\n\n\"Ny Teknik\" was launched on 18 October 1967. Its former publisher was Ekonomi och Teknik Förlag AB. The magazine is headquartered in Stockholm and is published by Talentum Sweden.\n\nIt is distributed to all members of The Swedish Association of Graduate Engineers. The magazine mostly covered news about inventions until 1997 when a new section, Frontlinjen (meaning Front Line), was started to feature news on technological research. The magazine also includes news on the effects of technology on society, IT and telecom.\n\nAs of 2006 the editor-in-chief was Lars Nilsson. Susanna Baltscheffsky also served as the editor-in-chief. Jan Huss is the editor-in-chief of the magazine. Corresponding publications are \"Ingeniøren\" in Denmark, \"Teknisk Ukeblad\" in Norway and \"Technisch Weekblad\" in the Netherlands.\n\nIn 2006 \"Ny Teknik\" had a circulation of 146,500 copies. In 2008 the magazine sold 153,900 copies. Its circulation was 156,400 copies in 2010.\n"}
{"id": "28283580", "url": "https://en.wikipedia.org/wiki?curid=28283580", "title": "Outline of alchemy", "text": "Outline of alchemy\n\nThe following outline is provided as an overview of and topical guide to alchemy:\n\nAlchemy – A philosophical tradition recognized as protoscience, that includes the application of Hermetic principles, and practices related to mythology, religion, and spirituality.\n\n\nInfluences upon alchemy – alchemy developed dependent on a number of influences and experienced regional and period-specific variations:\n\n\n\nMagnum opus – great work of alchemy consisting of:\n\nAlchemists also engaged in practical and symbolic processes including:\n\nAlchemical symbol – \n1. Glyphs\n2. Imagery\n3. Visual Symbolism\n\n\nmore...\n\nStills\n\nVessels\n\nHeating devices\n\n\n\n\nThe most influential names in the history of alchemy include:\n\n\n"}
{"id": "9076272", "url": "https://en.wikipedia.org/wiki?curid=9076272", "title": "Peter John Wyllie", "text": "Peter John Wyllie\n\nPeter John Wyllie (b. 8 February 1930, London, England) is a British petrologist and academic. He was Professor of Geology at the California Institute of Technology from 1983 until his retirement in 1999. Prior to this, he held positions at the University of St Andrews (1955–56), Pennsylvania State University (1958–59 and 1961–66), the University of Leeds (1959–61), and the University of Chicago (1965–83). He is well known for his many contributions to the understanding of magmatism, particularly through his work on the experimental petrology of magmas and volatiles. In the early 1970s, Wyllie wrote two widely used textbooks; \"The Dynamic Earth\" (1971) and \"The Way the Earth Works\" (1976) which integrated the new understanding of magmatism and plate tectonics. He is also famous for his contributions to the coverage of earth sciences in the \"Encyclopædia Britannica\", particularly his outline of the field in Part Two of the \"Propædia\". Wylie was President of the International Union of Geodesy and Geophysics (IUGG) from 1995 to 1999.\n"}
{"id": "10003704", "url": "https://en.wikipedia.org/wiki?curid=10003704", "title": "Postgraduate research", "text": "Postgraduate research\n\nPostgraduate research represents a formal area of study that is recognized by a university or institute of higher learning. By definition, the notion of “postgraduate” (United States) carries the implication that the candidate undertaking such research has already completed a formal Master's degree and at some instances the PhD, at an accredited university or tertiary institution. The resulting qualifications arising from postgraduate research leads to Post (Doctorates).\nThe structure of postgraduate research programs can vary significantly from one country to another. To enter into a PhD program in the United States, students generally must have some form of prerequisite study beyond their basic graduate qualification. This may be a Master’s coursework program, which acts as a qualifier for entry. In other countries, entry to Doctoral or Master’s research programs is based on the academic track record of the candidates in their undergraduate degrees.\n\nMany students confuse the notion of postgraduate research with “invention” and “discovery”. Postgraduate research ultimately represents an apprenticeship in the field of research. In his textbook, \"Key Factors in Postgraduate Research – A Guide for Students\". Dario Toncich explains that the objective of postgraduate research is not necessarily to make a breakthrough invention or, indeed, a major scientific discovery. \n\nIt is, rather, a mechanism by which graduate students learn how to undertake a systematic investigation, founded upon the work built by peers in the field, and then to extend the current state of knowledge. In the context of assessing a postgraduate research program, it is generally the systematic process of research and investigation that is given more attention than the level to which knowledge is extended. The title \"doctor\" emanates from the Latin word \"docera\"—to teach. Hence there is an expectation that the recipient of a doctorate would go on to become some form of \"teacher\" in the broad sense of the word.\n\nIn the 19th century, postgraduate research was a rarity, with countries such as the United States only having a small number of candidates across their university spectrum. However, by the start of the 21st century, postgraduate research, and postgraduate qualifications, had become commonplace. In any one year, at a global level, there are hundreds of thousands of candidates undertaking postgraduate research programs. For this reason the nature of postgraduate research has also changed. \n\nAt Doctoral level, there is some recognition that it is no longer reasonable to expect major research breakthroughs as part of a postgraduate research program. To this end, Doctoral research more commonly now represents an extension of knowledge, rather than some form of breakthrough. There is also some recognition that modern postgraduate research programs now have to be conducted in the light of massive amounts of previously published work, and hence the literature review process has become significantly more complex.\n\nThe nomenclature associated with titles arising from postgraduate research vary from one institution to another and one country to another. Postgraduate research programs generally result in a thesis/dissertation, which is assessed by independent experts in the field. The specific nature of the thesis varies from one discipline to another and from one country to another. In addition, some universities insist that students also undertake a \"viva-voce\" oral examination in which they can defend their research and processes before an expert panel.\n\nIn India, generally, the higher the level of the research degree the less association it has with a specific discipline. For example, at Bachelor's level, it would be common to receive a BSc(Chemistry). At Master's level, the corresponding degree would be an MSc (without the specific subdiscipline). At Doctoral level, the degree would be simply PhD with no discipline stated. This is intended to show that the recipient of the award has mastered techniques that are more generic than those encapsulated in a specific discipline or subdiscipline. There are some exceptions to this. In a professional Doctorate, where the objective is to demonstrate an in-depth research knowledge of a particular area, the discipline is usually included (e.g., Doctor of Business).\n\nIn some universities, it is also possible for candidates to achieve what is referred to as a \"higher doctorate\". This is generally an award bestowed upon people who have made a substantial contribution to their discipline through their research. Higher doctorates would normally be awarded after a significant research career and therefore those who receive such awards generally already have a basic PhD to begin with. Like professional doctorates, higher doctorates generally carry the title of the discipline to which the research contributions have been made—for example, Doctor of Engineering.\n\n"}
{"id": "21119583", "url": "https://en.wikipedia.org/wiki?curid=21119583", "title": "Qadan culture", "text": "Qadan culture\n\nThe Qadan culture (13,000-9,000 BC) was an ancient culture that, archaeological evidence suggests, originated in Upper Egypt (present day south Egypt) approximately 15,000 years ago . This way of life is estimated to have persisted for approximately 4,000 years, and was characterized by hunting, as well as a unique approach to food gathering that incorporated the preparation and consumption of wild grasses and grains. Systematic efforts were made by the Qadan people to water, care for, and harvest local plant life, but grains were not planted in ordered rows. \n\nSites from this period span from the Second Cataract of the Nile to Tushka, situated approximately 250 kilometers upriver from Aswan.\n\nIn archaeological terms, the Qadan culture is generally viewed as a cluster of Mesolithic Stage communities living in Nubia in the upper Nile Valley prior to 9000 BC. At a time of relatively high water levels in the Nile, it is characterized by a diverse stone tool industry that is taken to represent increasing degrees of specialization and locally differentiated regional groupings. Large numbers of grinding stones and blades have been found with glossy films of silica on them, which could possibly be the result of cutting grass stems on their surfaces. There is some evidence of conflict between the groups, suggesting periods of invasion or intense inter-tribal war. In fact, about 40 percent of individuals buried in the Jebel Sahaba cemetery near the border of Sudan on the Nile river show signs of fatal wounds caused by projectiles, from weapons such as spears, darts, or arrows. The remains found in the cemeteries suggest that ritual burials were practiced. \n\nThe Qadan economy was based on fishing, hunting, and, as mentioned, the extensive use of wild grain.\n"}
{"id": "40861730", "url": "https://en.wikipedia.org/wiki?curid=40861730", "title": "Replicate (biology)", "text": "Replicate (biology)\n\nIn the biological sciences, a replicate is an exact copy of a sample that is being analyzed, such as a cell, organism or molecule, on which exactly the same procedure is done. This is often done in order to check for experimental or procedural error. In the absence of error replicates should yield the same result. However, replicates are not independent tests of the hypothesis because they are still the same sample, and so do not test for variation between samples.\n\nReplicates are often created to test the quality and repeatability of a procedure, or for a destructive procedure where preserving the original sample is desirable. They are also sometimes inappropriately used to inflate the apparent number of observations in a sample, creating an illusion of statistical significance.\n\n"}
{"id": "59068081", "url": "https://en.wikipedia.org/wiki?curid=59068081", "title": "Rhodopirellula bahusiensis", "text": "Rhodopirellula bahusiensis\n\nRhodopirellula bahusiensis is a bacterium from the genus of \"Rhodopirellula\".\n"}
{"id": "4857685", "url": "https://en.wikipedia.org/wiki?curid=4857685", "title": "Seasonal Attribution Project", "text": "Seasonal Attribution Project\n\nThe Seasonal Attribution Project is a Climateprediction.net sub-project, with support from the WWF. It runs a high resolution model in order to try to determine the extent to which extreme weather events are attributable to human-induced global warming.\n\nThe project did cease giving out more work, however there has been a project extension to try a fourth sea surface temperature pattern. Current work will still be accepted and used for collaborations and possibly revisions of papers during the review process.\n\nA further extension will start soon.\n\n\nThe latter two will use the same models. Information has been uploaded but analysis of information generated has not yet started.\n\n\n"}
{"id": "6398170", "url": "https://en.wikipedia.org/wiki?curid=6398170", "title": "Seeding (fluid dynamics)", "text": "Seeding (fluid dynamics)\n\nSeeding a material is a concept used in fluid dynamics to describe the act of introducing specific particulates or other foreign substances into a stream of fluid being evaluated. An altered fluid will be described as having a seeded flow.\n\nThese particulates are generally small enough to be carried by the fluid but large enough to be picked up using a flow visualization technique, such as particle image velocimetry (PIV). In reference to aerodynamic testing, such as wind tunnel testing, water tunnel testing, or any other test investigating the flow of a fluid which may be invisible to the naked eye, seeding a flow is often the only way to take visual measurements. Simple examples of a seeded flow include the introduction of smoke into a low speed wind tunnel to see the general path of the air, or injecting colored dye into a water tunnel to see secondary flow structures such as hairpin vortices.\n\nAs stated in \"The Handbook of Fluid Dynamics\", an ideal seeding particle should have uniform properties such that its density is the same as the fluid that it's added to.\n\n"}
{"id": "51354085", "url": "https://en.wikipedia.org/wiki?curid=51354085", "title": "Shanghai Project", "text": "Shanghai Project\n\nThe Shanghai Project is a multidisciplinary ideas platform bringing together practitioners from a variety of disciplines, including art, architecture, design, film, performance, sound, as well as the humanities, social and natural sciences.\n\nThe inaugural edition of the Shanghai Project, under the co-artistic directorship of Yongwoo Lee, Executive Director of Shanghai Himalayas Museum, and Hans Ulrich Obrist, Artistic Director of Serpentine Galleries London, is organized by the Shanghai Himalayas Museum, and co-organized by the Shanghai International Culture Association, and supported by Envision Energy and Zendai Group.\n\nThe Shanghai Project was founded in 2015 by Yongwoo Lee in partnership with Dai Zhikang. The first phase of Shanghai Project took place in 2016 at the Himalaya Center and Shanghai Himalayas Museum, its satellite venue at Zendai Zhujiajiao Art Museum, and various venues across Shanghai including Century Park (Shanghai)|Century Park in Pudong New District.\n\n\nThe inaugural edition of the Shanghai Project will launch on September 4, 2016 and take place over the duration of eleven months, ending in July 2017.\n\nTaking “Envision 2116” as its theme, the festival gathering—from China and abroad—\"artists, filmmakers, performers, musicians, designers, architects, writers (including journalists, bloggers, science fiction novelists, and poets), philosophers, historians, scientists, economists, geographers, sociologists, anthropologists, doctors, lawyers, engineers, hackers, and activists, all of whom will be dubbed 'researchers'\", and the people of Shanghai to think, discuss, relate, and act on the sustainability of the humankind's futures in the 22nd century\".\n\nPhase one of the first edition includes exhibitions, gatherings, screenings, talks, workshops, an open call, a commissioned architectural pavilion, and public art installations across sites in Shanghai, as well as the annual International Biennial Association Conference in collaboration with the Power Station of Art from September 3–4, 2016.\n\nResearchers of this phase included: Xu Bing, Jenova Chen, Otobong Nkanga, Douglas Coupland, Liam Gillick, Liu Yi, Sou Fujimoto, and Cildo Meireles, etc.\n\nThe Shanghai Project invited Japanese architect Sou Fujimoto to design and construct a pavilion, titled \"Envision Pavilion\" and situated besides the Arata Isozaki-designed Shanghai Himalayas Center, to house various cultural activities and amenities.\n\nThe Shanghai Project's exhibitions program creates multiple narratives in response to the theme of \"Envision 2116\", through an open and flexible configuration of multi-media installations, taking place at different venues across Shanghai.\n\nThe Shanghai Project’s public program includes a wide range of public activities, including performances, film and video screenings, discursive programs and participatory events. Notable ones include “Community Participation Program,” a series of neighborhood events intended to open a dialogue between the city of Shanghai and its residents that launched on July 15, 2016, joint programs with Jifeng Bookstore and Shanghai Flaneur, as well as a children’s program located in Century Park.\n\n“Qidian,” which loosely translates into “starting point”, is an nationwide open call designed to tap into the talent and interests of China’s new generation, which is based on the long-term international project “89plus” (co-curated by Simon Castets and Hans Ulrich Obrist in collaboration with Katherine Dionysius).\n\n"}
{"id": "15642232", "url": "https://en.wikipedia.org/wiki?curid=15642232", "title": "Society for Science &amp; the Public", "text": "Society for Science &amp; the Public\n\nSociety for Science & the Public (SSP), formerly known as Science Service, is a 501(c)3 non-profit organization dedicated to the promotion of science, through its science education programs and publications, including the bi-weekly \"Science News\" magazine and the free-accessible online \"Science News for Students\".\n\nThe organization has headquarters in Washington, D.C. It promotes the understanding and appreciation of science and the role it plays in human advancement. In pursuit of this goal, it publishes \"Science News\" and \"Science News for Students\", and sponsors events including the Intel International Science and Engineering Fair, the Regeneron Science Talent Search, and the Broadcom MASTERS (Math, Applied Science, Technology and Engineering for Rising Stars) competition.\n\nSSP was founded in 1921 by journalist Edward W. Scripps and zoologist William Emerson Ritter, under the name \"Science Service\", with the goal of informing the public of the latest scientific discoveries and achievements. The Science Service emerged from a reorganization of a group that Scripps and Ritter had originally founded in 1919 as the American Society for the Dissemination of Science.\n\nScripps and Ritter accomplished their goal by distributing the latest science research to the public through a news service for reporters. In 1922, due to interest from non-journalists, Science Service started distributing \"Science News-Letter\", which became a magazine in 1926. It quickly grew into a prime source of science news for libraries, schools, and individuals. In 1942, Science Service launched the first of its prestigious education competitions, the Westinghouse Science Talent Search.\n\nIn 2008, Science Service became Society for Science & the Public (SSP) in order to better reflect the mission of the organization to advocate for science in the public interest.\n\nBetween the World Wars, Science Service sponsored Science Clubs of America, founded by Watson Davis, a national organization to popularize science among amateur scientists. High school science clubs were encouraged to join.\n\nFrom 1940 through 1989, Science Service sponsored the Things of Science Club. Subscribers received a monthly box containing some kind or material or artifact along with an pamphlet describing experiments that could be done with it. Sometimes the kits contained parts which could be assembled into a scientific instrument.\n\nBeginning in 2003, it published \"Science News for Kids\", an online magazine aimed at students, and also at teachers and parents\n\n"}
{"id": "43838573", "url": "https://en.wikipedia.org/wiki?curid=43838573", "title": "The Mathematics of Life", "text": "The Mathematics of Life\n\nThe Mathematics of Life is a 2011 popular science book by mathematician Ian Stewart, on the increasing role of mathematics in biology.\n\nStewart discusses the mathematics behind such topics as population growth, speciation, brain function, chaos theory, game theory, networking, symmetry, and animal coloration, with little recourse to equations. He identifies six revolutions which modernized biology:\n\n\nWriter Alex Bellos described \"The Mathematics of Life\" as \"a testament to the versatility of maths and how it is shaping our understanding of the world.\" \"Kirkus Reviews\" called the book \"an ingenious overview of biology with emphasis on mathematical ideas—stimulating but requiring careful reading despite the lack of equations.\" A review in \"Notices of the American Mathematical Society\" noted that the book \"does an admirable job of unfolding the mathematics undergirding so much of the research being carried out today in the many fields that comprise the subject of biology.\"\n\nMathematician and science writer Keith Devlin criticized the book, writing that \"readers of the author's many general-audience books on mathematics may be surprised to find themselves at times frustrated by his latest outing, which is marred by overlapping and often repetitious passages.\"\n"}
{"id": "5996838", "url": "https://en.wikipedia.org/wiki?curid=5996838", "title": "The Story of Science in America", "text": "The Story of Science in America\n\nThe Story of Science in America is a 1967 science book by L. Sprague de Camp and Catherine Crook de Camp, illustrated by Leonard Everett Fisher, published by Charles Scribner's Sons. It has been translated into Spanish, Portuguese, Burmese and French.\n\nThe book traces the work of inventors and naturalists in the United States from the Colonial era through the mid-19th century, and relates scientific developments in the century following.\n\n\nCritical response to the book was positive. Jane E. Brody, writing for \"The New York Times\", called it \"a fast-moving, informative and thoroughly enjoyable chronicle, with amusing anecdotes, legends and interesting sidelights that reflect the personalities, lives and times of the men who shaped our nation scientifically.\" She noted that \"the authors have kept their writing free of chauvinism,\" and that \"[m]ost of the scientific concepts are well enough explained so that even the newcomer to science should be able to grasp at least the essence of them.\" In the same issue the book was included among seventy-five recommended titles selected by the Children's Editor of the newspaper's Book Review, described as an \"[i]nformative, thoroughly enjoyable chronicle of the development of science in our country.\"\n\n\"Publishers' Weekly\" stated that \"[t]o read the index ... is to read the names of the men and of their discoveries in science in America, from the earliest days ... to the space age. To read the book is to become familiar with the men and their contributions to science.\"\n\nGeorge Basalia, writing for \"Library Journal\", called the book \"a first-rate history of American science and technology for high-school students ... cover[ing] major American technical discoveries as well as our contributions to the purely theoretical aspects of science.\" He found \"much to be praised ... the book is intelligently conceived, carefully organized, clearly written, and handsomely designed. Unfortunately, the illustrations do not do justice to [the] excellent text.\"\n\nH. D. Allen in the \"Montreal Gazette\" wrote that the book's story \"makes fascinating reading,\" and that \"[w]hile the treatment of any one discipline may at first seem superficial and chatty, the total impact is most impressive, for the reader is left with an acquaintance with the leading figures of the age of science and some appreciation of how the contribution of each influenced a way of life.\" He concluded \"The breadth of scientific knowledge which this book represents is remarkable, as is the skill with which it has been set down and the effortlessness with which it reads.\"\n\n\"The Booklist\" called it \"[a] wide-ranging survey [that] reflects the authors' humanistic interests as well as their familiarity with several branches of science and their extensive background reading.\"\n\nHarry C. Stubbs in \"The Horn Book Magazine\" included it among \"half a dozen books dealing ... with the history of science [that] I can recommend [both] to nonscientists as guides toward the Light [and] to scientists and science teachers as reminders that what we know was long, slow, and hard in coming.\" He noted that it \"give[s] us a series of fascinating biographical and anecdotal items strung loosely on the thread of developing scientific knowledge.\"\n\nPhilip and Phylis Morrison in \"Scientific American\" felt it \"manages to convey a sense of coherence, even though it deals at staccato length with so many men, trends and ideas ... The reason is partly in the expert writing--smooth, unusually candid, cheerful and sometimes a bit condescending (as in the two or three pages about Veblen).\" They add that \"[n]ot all the dicta of the authors seem reasonable, but to find any personal judgment at work is so rare in this kind of pedagogy that one is pleased by the De Camps even when one disagrees with them.\"\n"}
{"id": "36294056", "url": "https://en.wikipedia.org/wiki?curid=36294056", "title": "Theory of the Earth", "text": "Theory of the Earth\n\nTheory of the Earth was a publication by James Hutton which laid the foundations for geology. In it he showed that the Earth is the product of natural forces. What could be seen happening today, over long periods of time, could produce what we see in the rocks. This idea, uniformitarianism, was used by Charles Lyell in his work, and Lyell's textbook was an important influence on Charles Darwin. The work was first published in 1788 by the Royal Society of Edinburgh, and later in 1795 as two book volumes.\n\nHutton recognized that rocks record the evidence of the past action of processes which still operate today. He also anticipated natural selection, as follows:\n\nHutton's prose hindered his theories. John Playfair in 1802 restated of Huttton's geological ideas in clearer English. However, he left out Hutton's thoughts on evolution. Charles Lyell in the 1830s popularised the idea of an infinitely repeating cycle (of the erosion of rocks and the building up of sediment). Lyell believed in gradual change, and thought even Hutton gave too much credit to catastrophic changes. \n\nHutton's work was published in different forms and stages:\n\n"}
{"id": "1331806", "url": "https://en.wikipedia.org/wiki?curid=1331806", "title": "Toy problem", "text": "Toy problem\n\nIn scientific disciplines, a toy problem or a puzzlelike problem is a problem that is not of immediate scientific interest, yet is used as an expository device to illustrate a trait that may be shared by other, more complicated, instances of the problem, or as a way to explain a particular, more general, problem solving technique.\n\nFor instance, while engineering a large system, the large problem is often broken down into many smaller toy problems which have been well understood in detail. Often these problems distill a few important aspects of complicated problems so that they can be studied in isolation. Toy problems are thus often very useful in providing intuition about specific phenomena in more complicated problems.\n\nAs an example, in the field of artificial intelligence, classical puzzles, games and problems are often used as toy problems. These include sliding-block puzzles, N-Queens problem, missionaries and cannibals problem, tick-tack-toe, chess, Hanoi tower and others.\n\n"}
{"id": "18727507", "url": "https://en.wikipedia.org/wiki?curid=18727507", "title": "USA-212", "text": "USA-212\n\nUSA-212 was the first flight of the Boeing X-37B Orbital Test Vehicle 1 (X-37B OTV-1), an American unmanned robotic vertical-takeoff, horizontal-landing (VTHL) spaceplane.\nIt was launched aboard an Atlas V rocket from Cape Canaveral on 22 April 2010, and operated in low Earth orbit. Its designation is part of the USA series.\n\nThe spaceplane is operated by the United States Air Force, which has not revealed the specific identity of the spaceship's payload for the mission. The Air Force has stated only that the spacecraft would \"demonstrate various experiments and allow satellite sensors, subsystems, components, and associated technology to be transported into space and back.\"\n\nUSA-212 was launched on an Atlas V 501 rocket, tail number AV-012, from Space Launch Complex 41 at the Cape Canaveral Air Force Station in Florida. The launch, which was conducted by United Launch Alliance, occurred at 23:52 UTC on 22 April 2010, placing the spacecraft into low Earth orbit for testing.\n\nThe X-37B spacecraft was originally intended to be deployed from the payload bay of a NASA Space Shuttle, but following the \"Columbia\" accident, it was transferred to a Delta II 7920. It was subsequently transferred to the Atlas V following concerns over the X-37B's aerodynamic properties during launch.\n\nThe launch was the first flight of the Atlas V 501 configuration, and the first in four years to use a payload fairing. Prior to the installation of the spacecraft, the Atlas rocket was moved to the launch pad and performed a wet dress rehearsal on 2 April 2010. It was returned to the Vertical Integration Facility the next day for final assembly. The X-37 arrived at the VIF on 8 April. On 9 April, a 24-hour delay was announced. It subsequently slipped a further 24 hours after the landing of on Mission STS-131 was delayed, as the Eastern Range could not have been reconfigured quickly enough to accommodate both events on the same day. After a series of delays, it was set for 19 April 2010. On 21 April, the Atlas was rolled back out to the launch pad for launch. The launch window on 22 April opened at 23:52 UTC, and closed at 00:01 on 23 April.\n\nMost of the mission parameters for the USA-212 flight have not been disclosed. The vehicle is capable of being on-orbit for up to 270 days. The Air Force stated the mission time would depend on progress of the craft's experiments during orbit. Mission control was handled by the 3d Space Experimentation Squadron, 21st Space Wing, of the Air Force Space Command in Colorado Springs.\n\nIn May 2010, an amateur astronomer claimed to spot the spacecraft from his home in Toronto, Ontario, Canada. Shortly after the initial observation, several more detailed observations were made by amateur skywatchers from around the world, who reported the spacecraft to have an almost circular low Earth orbit with an inclination of 40°. The group believed in their calculations and observations with a high degree of confidence. The spacecraft's ground track was observed to repeat every four days, which was considered indicative for a possible imaging reconnaissance mission profile.\n\nFor two weeks, starting on 29 July, the amateur skywatchers were unable to find the spacecraft in the locations they had predicted, leading them to believe it had suddenly changed its course. During the mission, the vehicle was observed to change its orbit multiple times, with a total delta-v of the first four orbit changes amounting to . A common characteristic of all the orbits was that the ground track nearly repeated every few days. By 12 November 2010, the orbit had been lowered to with the ground track now repeating every three days (47 orbits).\n\nBased on data collected by amateur observers, the following orbital characteristics were calculated by amateur skywatcher Ted Molczan.\n\nAfter completing its mission, the X-37B was deorbited, entered the atmosphere, and landed at Vandenberg Air Force Base on 3 December 2010.\n\nThe X-37B is the second reusable spacecraft to perform an automated landing after returning from orbit, the first being the Soviet Buran spacecraft in 1988.\n\nAs the mission of USA-212 and the X-37B program are classified, public commentary on the program is speculation. James Oberg speculated that the concurrent launch of Air Force's Hypersonic Technology Vehicle HTV-2 was related to the mission. Part of an X-37B's mission profile might involve a simulated enemy attack, which the X-37B should be able to detect and autonomously counteract. HTV-2 was launched at 23:00 UTC on 22 April 2010, i.e., 52 minutes ahead of X-37B, from Vandenberg Air Force Base in California, on a suborbital trajectory supposed to last less than 25 min. The mission failed and was aborted nine minutes after launch.\n\nWilliam Scott, coauthor of the techno-novel \"Counterspace: The Next Hours of World War III\" and former Rocky Mountain Bureau Chief for \"Aviation Week & Space Technology\" magazine believes that with X-37B, the Air Force might test weapon delivery from a space plane in low Earth orbit. He mentions Rods from God as a possible scenario. This hypothesis aligns with speculation that the launch of USA-212 marks the beginning of military operations in space.\n\n"}
{"id": "37456405", "url": "https://en.wikipedia.org/wiki?curid=37456405", "title": "Variance-based sensitivity analysis", "text": "Variance-based sensitivity analysis\n\nVariance-based sensitivity analysis (often referred to as the Sobol method or Sobol indices, after Ilya M. Sobol) is a form of global sensitivity analysis. Working within a probabilistic framework, it decomposes the variance of the output of the model or system into fractions which can be attributed to inputs or sets of inputs. For example, given a model with two inputs and one output, one might find that 70% of the output variance is caused by the variance in the first input, 20% by the variance in the second, and 10% due to interactions between the two. These percentages are directly interpreted as measures of sensitivity. Variance-based measures of sensitivity are attractive because they measure sensitivity across the whole input space (i.e. it is a global method), they can deal with nonlinear responses, and they can measure the effect of interactions in non-additive systems.\n\nFrom a black box perspective, any model may be viewed as a function \"Y\"=\"f\"(X), where X is a vector of \"d\" uncertain model inputs {\"X\", \"X\", ... \"X\"}, and \"Y\" is a chosen univariate model output (note that this approach examines scalar model outputs, but multiple outputs can be analysed by multiple independent sensitivity analyses). Furthermore, it will be assumed that the inputs are independently and uniformly distributed within the unit hypercube, i.e. formula_1 for formula_2. This incurs no loss of generality because any input space can be transformed onto this unit hypercube. \"f\"(X) may be decomposed in the following way,\n\nwhere \"f\" is a constant and \"f\" is a function of \"X\", \"f\" a function of \"X\" and \"X\", etc. A condition of this decomposition is that,\n\ni.e. all the terms in the functional decomposition are orthogonal. This leads to definitions of the terms of the functional decomposition in terms of conditional expected values,\n\nFrom which it can be seen that \"f\" is the effect of varying \"X\" alone (known as the main effect of \"X\"), and \"f\" is the effect of varying \"X\" and \"X\" simultaneously, \"additional to the effect of their individual variations\". This is known as a second-order interaction. Higher-order terms have analogous definitions.\n\nNow, further assuming that the \"f\"(X) is square-integrable, the functional decomposition may be squared and integrated to give,\n\nNotice that the left hand side is equal to the variance of \"Y\", and the terms of the right hand side are variance terms, now decomposed with respect to sets of the \"X\". This finally leads to the decomposition of variance expression,\n\nwhere\n\nand so on. The \"X\" notation indicates the set of all variables \"except\" \"X\". The above variance decomposition shows how the variance of the model output can be decomposed into terms attributable to each input, as well as the interaction effects between them. Together, all terms sum to the total variance of the model output.\n\nA direct variance-based measure of sensitivity \"S\", called the \"first-order sensitivity index\", or \"main effect index\" is stated as follows,\n\nThis is the contribution to the output variance of the main effect of \"X\", therefore it measures the effect of varying \"X\" \"alone\", but averaged over variations in other input parameters. It is standardised by the total variance to provide a fractional contribution. Higher-order interaction indices \"S\", \"S\" and so on can be formed by dividing other terms in the variance decomposition by Var(\"Y\"). Note that this has the implication that,\n\nUsing the \"S\", \"S\" and higher-order indices given above, one can build a picture of the importance of each variable in determining the output variance. However, when the number of variables is large, this requires the evaluation of 2-1 indices, which can be too computationally demanding. For this reason, a measure known as the \"Total-effect index\" or \"Total-order index\", \"S\", is used. This measures the contribution to the output variance of \"X\", \"including\" all variance caused by its interactions, of any order, with any other input variables. It is given as,\n\nNote that unlike the \"S\",\n\ndue to the fact that the interaction effect between e.g. \"X\" and \"X\" is counted in both \"S\" \"and\" \"S\" In fact, the sum of the \"S\" will only be equal to 1 when the model is purely additive.\n\nFor analytically tractable functions, the indices above may be calculated analytically by evaluating the integrals in the decomposition. However, in the vast majority of cases they are estimated – this is usually done by the Monte Carlo method.\n\nThe Monte Carlo approach involves generating a sequence of randomly distributed points inside the unit hypercube (strictly speaking these will be pseudorandom). In practice, it is common to substitute random sequences with low-discrepancy sequences to improve the efficiency of the estimators. This is then known as the quasi-Monte Carlo method. Some low-discrepancy sequences commonly used in sensitivity analysis include the Sobol sequence and the Latin hypercube design.\n\nTo calculate the indices using the (quasi) Monte Carlo method, the following steps are used:\n\n\nThe accuracy of the estimators is of course dependent on \"N\". The value of \"N\" can be chosen by sequentially adding points and calculating the indices until the estimated values reach some acceptable convergence. For this reason, when using low-discrepancy sequences, it can be advantageous to use those that allow sequential addition of points (such as the Sobol sequence), as compared to those that do not (such as Latin hypercube sequences).\n\nThere are a number of possible Monte Carlo estimators available for both indices. Two that are currently in general use are,\n\nand\n\nfor the estimation of the \"S\" and the \"S\" respectively.\n\nFor the estimation of the \"S\" and the \"S\" for all input variables, \"N\"(\"d\"+2) model runs are required. Since \"N\" is often of the order of hundreds or thousands of runs, computational expense can quickly become a problem when the model takes a significant amount of time for a single run. In such cases, there are a number of techniques available to reduce the computational cost of estimating sensitivity indices, such as emulators, HDMR and FAST.\n\n"}
{"id": "13322391", "url": "https://en.wikipedia.org/wiki?curid=13322391", "title": "World Commission on Protected Areas", "text": "World Commission on Protected Areas\n\nThe World Commission on Protected Areas (WCPA) is one of six commissions of the International Union for Conservation of Nature (IUCN). WCPA is the world's premier network of protected area expertise. It is administered by IUCN's Global Protected Areas Programme and has over 2,400 members, spanning 140 countries.\n\n"}
