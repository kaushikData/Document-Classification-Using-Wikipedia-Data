{"id": "1469552", "url": "https://en.wikipedia.org/wiki?curid=1469552", "title": "Affine pricing", "text": "Affine pricing\n\nIn economics, affine pricing is a situation where buying more than zero of a good gains a fixed benefit or cost, and each purchase after that gains a per-unit benefit or cost.\n\nDenoting\n\"T\" is the total price paid,\n\"q\" is the quantity in units purchased, \n\"p\" is a constant price per unit, \n\"k\" is the fixed cost,\n\nthe affine price is then calculated by formula_1\n\nIn mathematical language, the price is an affine function (sometimes also linear function) of the quantity bought.\n\nAn example would be a cell phone contract where a base price is paid each month with a per-minute price for calls. \n\nSliding-scale price contracts achieve a similar effect, although the terms are stated differently. The price decreases with volume produced, achieving the same financial transfer over time, but the transaction is always based on units sold, with the fixed cost amortized into the price of each unit.\n"}
{"id": "26174362", "url": "https://en.wikipedia.org/wiki?curid=26174362", "title": "Afocal system", "text": "Afocal system\n\nIn optics an afocal system (a system without focus) is an optical system that produces no net convergence or divergence of the beam, i.e. has an infinite effective focal length. This type of system can be created with a pair of optical elements where the distance between the elements is equal to the sum of each element's focal length (\"d\" = \"f\"+\"f\"). A simple example of an afocal optical system is an optical telescope imaging a star, the light entering the system is at infinity and the image it forms is at infinity (the light is collimated). Although the system does not alter the divergence of a collimated beam, it does alter the width of the beam, increasing magnification. The magnification of such a telescope is given by\n\nAfocal systems are used in laser optics, for instance as beam expanders, Infrared and forward looking infrared systems, camera zoom lenses and telescopic lens attachments such as teleside converters, and photography setups combining cameras and telescopes (Afocal photography).\n\n"}
{"id": "30185887", "url": "https://en.wikipedia.org/wiki?curid=30185887", "title": "Atlantic Watershed of North America", "text": "Atlantic Watershed of North America\n\nThe Atlantic Watershed of North America is the portion of the continent which drains from the Continental Divide of the Americas and the Laurentian Divide to the Atlantic Ocean. The watershed includes a portion of Greenland, the Atlantic Seaboard Watershed, and the North American portion of the American Mediterranean Sea Watershed. \n"}
{"id": "44497180", "url": "https://en.wikipedia.org/wiki?curid=44497180", "title": "BBVA Foundation Frontiers of Knowledge Award", "text": "BBVA Foundation Frontiers of Knowledge Award\n\nThe BBVA Foundation Frontiers of Knowledge Awards, \"Premios Fundación BBVA Fronteras del Conocimiento\", in Spanish, are an international award programme recognizing significant contributions in the areas of scientific research and cultural creation. The categories that make up the Frontiers of Knowledge Awards respond to the knowledge map of the present age. As well as the fundamental knowledge that is at their core, they address developments in information and communication technologies, and interactions between biology and medicine, ecology and conservation biology, climate change, economics, development cooperation and, finally, contemporary musical creation and performance. Specific categories are reserved for developing knowledge fields of critical relevance, as in the case of the two environmental awards. Accolades in the environment area and development cooperation, two central challenges of the 21st century, may go to either research or practical actions and programs founded on the best available knowledge.\n\nThe awards were established in 2008, with the first set of winners receiving their prizes in 2009. The BBVA Foundation – belonging to financial group BBVA – is partnered in the scheme by the Spanish National Research Council (CSIC), the country’s premier public research organization.\n\nIn their eight editions, as many as four winners of BBVA Foundation Frontiers of Knowledge Awards have gone on to win the Nobel Prize. They are: Robert J. Lefkowitz, 2009 BBVA Foundation Frontiers of Knowledge Laureate in Biomedicine and winner of the Nobel Prize in Chemistry in 2012; Shinya Yamanaka, 2010 BBVA Foundation Frontiers of Knowledge Laureate in Biomedicine and Nobel Laureate in Physiology or Medicine 2012; Lars Peter Hansen, 2010 BBVA Foundation Frontiers of Knowledge Laureate in Economics, Finance and Management, and 2013 Nobel Laureate in Economics; Jean Tirole, 2008 BBVA Foundation Frontiers of Knowledge Laureate in Economics, Finance and Management and winner of the Nobel Prize in Economics 2014, and Angus Deaton, 2011 BBVA Foundation Frontiers of Knowledge Laureate in Economics, Finance and Management and winner of the Nobel Prize in Economics 2015.\n\nThere are 8 award categories: Basic science, Biomedicine, Ecology and Conservation Biology, Information and Communication Technologies, Economics, Finance and Management, Contemporary Music, Climate Change, and Development cooperation. Specific categories are reserved for developing knowledge fields of critical relevance, as in the case of the two environmental awards. Accolades in the environment area and development cooperation, two central challenges of the 21st century, may go to either research or practical actions and programs founded on the best available knowledge.\n\nEight juries, one for each category, analyze the nominations put forward by eminent international academic and research institutions. Jury chairs in the latest 9th(2016) award edition were:\n\nIn Basic Sciences, Theodor W. Hänsch, Director of the Division of Laser Spectroscopy at the Max Planck Institute of Quantum Optics, and holder of a Nobel Prize in Physics.\n\nIn Biomedicine, Angelika Schnieke, Chair of Livestock Technology in the Technische Universität München (TUM).\nIn Ecology and Conservation Biology, Emily Bernhardt, Professor of the Department of Biology at Duke University.\n\nIn Information and Communication Technologies, George Gottlob, Professor in the Department of Computer Science at the University of Oxford.\n\nIn Economics, Finance and Management, Eric S. Maskin, Adams University Professor at Harvard University and Nobel Prize in Economics.\n\nIn Contemporary Music, Nicholas Cook, Professor of Music at the University of Cambridge.\n\nIn Climate Change, Bjorn Stevens, Director of the Max Planck Institute for Meteorology.\n\nIn Development Cooperation, Joachim Von Braun, Director of the Center for Development Research (ZEF) at the University of Bonn.\n\nAward decision\n\nTo reach their decision, the juries meet during January and February in the Marqués de Salamanca Palace, Madrid headquarters of the BBVA Foundation. \nThe day after the jury’s decision, the name of the winners(s) and the achievements that earned them the award are revealed at an announcement event in the same location.\n\nCeremony\n\nThe awards are presented in June each year at a ceremony held in the Marqués de Salamanca Palace, Madrid headquarters of the BBVA Foundation, and attended by representatives of Spain’s scientific and cultural communities.\n\nThe BBVA Foundation engages in the promotion of research, advanced training and the transmission of knowledge to society, focusing on the emerging issues of the 21st century in five areas: Environment, Biomedicine and Health, Economy and Society, Basic Sciences and Technology, and Arts and Humanities. The BBVA Foundation designs, develops and finances research projects in these areas; facilitates advanced specialist training through grants, courses, seminars and workshops; organizes award schemes for researchers and professionals whose work has contributed significantly to the advancement of knowledge; and communicates and disseminates such new knowledge through publications, databases, lecture series, debates, exhibitions and audiovisual and electronic media.\n\nEach BBVA Foundation Frontiers of Knowledge laureate receives a commemorative artwork, a diploma and a cash prize of 400,000 euros per category. Awards may not be granted posthumously, and when an award is shared, its monetary amount is divided equally among the recipients.\n\nThe commemorative artwork is created by Madrid sculptor Blanca Muñoz, B.A. in Fine Arts from the Universidad Complutense de Madrid. Holder of scholarships at Calcografia Nazionale (1989), awarded by the Italian Government, at the Spanish Royal Academy in Rome (1990), and in Mexico City (1992), awarded by the Mexican Department of Foreign Affairs, her numerous distinctions include the 1999 National Print Prize.\n\n"}
{"id": "2368032", "url": "https://en.wikipedia.org/wiki?curid=2368032", "title": "COSI Columbus", "text": "COSI Columbus\n\nCOSI (an acronym for Center of Science and Industry) is a science museum and research center located in Columbus, Ohio in the United States. Originally opened in 1964, COSI was relocated to a 320,000 square foot state-of-the-art facility designed by Japanese architect Arata Isozaki along a bend in the Scioto River in the Franklinton neighborhood in 1999. COSI features more than 300 interactive exhibits throughout themed exhibition areas.\n\nAs a “center of science and industry” (rather than a standalone “science center”), COSI established embedded partnerships with local organizations. WOSU@COSI (Central Ohio’s NPR member station and Public Broadcasting Service public media station) maintains a digital media center and offices; OSU maintains a center of research as well as health & medicine laboratories staffed by medical residents; and Columbus Historical Society maintains offices and exhibit space.\n\nCOSI also operates the largest outreach education program of any science museum in the United States through COSI in the Classroom, 21st Century Lab field trip experiences, international distance education Interactive Video Conferencing programs, and COSI On Wheels traveling outreach program. As well, COSI originated the Camp-In overnight program for Girl Scouts and Boy Scouts in 1972 – a concept that is now commonplace in museums nationwide. Since 1964, COSI has engaged with nearly 30 million unique visitors through on-site and outreach programs.\n\nAs a not-for-profit organization, COSI is supported by ticket sales, a network of community and statewide partnerships (including relationships with a variety of donors and sponsors), a volunteer program supported by 10,000 volunteers annually, and nearly 20,000 member households. In 2008, COSI was the named the #1 science center in the United States for families by Parent Magazine.\n\n\"As adopted in 1964...\" \"COSI provides an exciting and informative atmosphere for those of all ages to discover more about our environment, our accomplishments, our heritage, and ourselves. We motivate a desire toward a better understanding of science, industry, health, and history through involvement in exhibits, demonstrations, and a variety of educational activities and experiences. COSI is for the enrichment of the individual and for a more rewarding life on our planet, Earth.\"\n\nUpon relocating to its new home in 1999, COSI was developed with large, self-contained, themed atria, each dedicated to a single topic (similar to the style of world’s fair pavilions) and designed as immersive theatrical “learning worlds.” As of 2018, COSI contains seven main exhibit areas: Ocean, Energy Explorers, Space, Progress, Gadgets, Life, and the American Museum of National History Dinosaur Gallery. Hallways between each learning world are filled with hands-on exhibits and displays.\n\nThe Ocean exhibit is divided into two realms. Accessed via an “underwater cave” through a crashed shipwreck, the cavern path splits as guests pass to the right or left. The pathway to the right leads to a docked submarine laboratory where hands-on exhibits explore the realities of ocean research, submersibles, SCUBA, water pressure, and remote-operated vehicles. Lilypad Lab focuses on drainage basin and Central Ohio wildlife. The path forking left from the shipwreck leads to the Temple of Poseidon, an “ancient” stone chamber built around a 30-foot tall statue of Poseidon with waterfalls, fountains, and water jets. This second realm focuses not on the study of water, but on the properties of water and the stories it inspires – laminar flow, whirlpools, erosion, water bells, and mythology.\n\nEnergy Explorers, which opened in 2013, allows visitors to choose an avatar (computing) character that follows the guest to the Home Zone, Transportation Zone, and Product Zone of a town, making decisions via computer kiosks to balance energy efficiency and cost.\n\nThe Space exhibit area features a replica space station pod to tour, a recreation of John Glenn's Friendship 7 spacecraft from the Mercury-Atlas 6, remote-operated vehicles, balance tests, and other hands-on experiments that deal with space flight trajectory, gravitational pull, and simulated rover landings. Space was originally located on Level 2 in its own enclosed atrium exhibit area, entered via a \"black hole\" spinning funhouse hallway meant to disorient guests. The exhibit itself - like Ocean or Adventure - was in a dark, immersive, themed area, stylized after the 1969 moon landing of Apollo 11. Under starry skies, guests interacted with \"retro\" stylized monitors and exhibits with a matching wood-panel / brushed metal motif that was reminiscent of the era and united in style. The exhibit even included a 1960s living room (including shag carpeting) where guests could watch the recorded landing.\n\nWhen the south end of COSI's building was closed due to lost levies in 2004, the Space exhibit was cut off. As such, it was relocated from Level 2 to an empty gallery on Level 1. In 2012, that area underwent construction to become Energy Explorers, necessitating yet another location switch. Some of the Space exhibit's displays moved to the Mezzanine Level while much remained in storage. With the re-opening of COSI's Planetarium in November 2014, the location of Space on the Mezzanine leading toward the Planetarium's lobby was reinforced by the return and refurbishment of the rest of Space's exhibits. However, Space still remains the only one of COSI's seven learning worlds to not have its own dedicated, theatrical, immersive atrium, instead being located on the bright Mezzanine bridge, open to the Atrium and entryway. The original home of Space is now Gallery 3, available for traveling exhibits and special event rentals. Gallery 3 still contains the \"Galaxy Theater,\" fittingly still painted with murals of planets and stars left over from its time as a live theater for Space.\n\nThe Progress exhibit (modeled after the “Streets of Yesteryear” exhibit at COSI’s original location) traces the hopes and fears of a small town called Progress in 1898, just as electricity, horseless carriages, and canned food become available. The recreated town (specifically, the shops, homes, and restaurants at the corner of Hope Street and Fear Street) includes a telegraph office, livery, stable, grocer, apothecary, and clothiers. After visitors walk through Progress in 1898, they turn the corner enter the same intersection of the same town 64 years later in 1962, where a new set of hopes and fears have arisen.\n\nIn 1962, the town of Progress includes an appliance store, working TV studio, radio station (where the telegraph office was), department store, diner, and gas station (replacing the livery). At the exit, the exhibit challenges guests to consider how the streets of the village of Progress might look today, and to question why the concept of progress deserves as much weight in scientific study as that of oceans, space, or energy.\n\nThe Gadgets exhibit area contains many classic science museum hands-on experiments, such as pulleys, wind tunnels, plasmaglobes, magnets, light bulbs, engines, and counterweights. As well, Gadgets contains the ‘Gadgets Café’, where families are seated and given a “menu” with quick science experiments to choose from. A “take-apart” menu allows visitors to disassemble donated phones, computers, clocks, and other electronic devices, which are recycled afterward.\n\nLife explores humanity through three separate areas dedicated to mind, body, and spirit. The \"Mind\" area contains optical illusions, physical illusions, an anechoic chamber, and a posable zoetrope. \"Spirit\" discusses the concept of birth and death and how human cultures understand them. \"Body\" features interactive health stations where visitors can record their weight, flexibility, and heart rate, then compare their statistics to that of COSI visitors and national averages. Life also contains the \"Labs in Life\", three working medical research pods staffed by OSU Health & Medicine students and staff.\n\nOn November 19 of 2017, COSI, in partnership with the American Museum of Natural History, opened a permanent Dinosaur Gallery. In addition, a traveling special exhibition gallery opened in Spring of 2018. Together, they will occupy 22,000 square feet on the first floor.\n\nThe building also contains an interactive “little kidspace” area designed for children up through first grade, the National Geographic Giant Screen Theater (the largest digital screen in Ohio), and an outdoor Big Science Park. On November 22, 2014, COSI reopened its 60-foot diameter, 220-seat Planetarium (Ohio’s largest) with all new digital projection. In addition, there is a History of COSI exhibit.\n\nThe building also includes three large Galleries for traveling exhibits and special event hosting, a Dive Theater in Ocean, the Galaxy Theater in Gallery 3 (its name a remnant of when Gallery 3 was once the Space exhibit), the Gadgets Stage, the Atomic Cafe, the Science2Go! retail store, and five meeting rooms utilizing refurbished areas within the former Central High School, which the new COSI location was built around.\n\nCOSI opened on March 29, 1964, as a venture of the Franklin County Historical Society. COSI is a founding member of the Science Museum Exhibit Collaborative (SMEC) and a long-standing member of the Association of Science-Technology Centers (ASTC).\n\nFrom its 1964 opening, COSI was housed in Memorial Hall, a Columbus landmark constructed in 1906. COSI closed at the Memorial Hall location on East Broad Street on September 6, 1999, and re-opened two months later on November 6, 1999, at its new location on the Scioto riverfront in downtown Columbus. The new, 320,000 square foot facility is one of the largest modern-built science centers in the world. The building was designed by internationally renowned Japanese architect Arata Isozaki, who designed an elliptical, geometric, \"blimp\" shaped structure composed of 159 curved concrete panels. COSI is designed to appear progressively futuristic from the neighborhood of Franklinton, while from downtown Columbus it uses the exterior of the original Central High School to blend into the city.\nShortly after the move to the riverfront, the museum experienced a shortfall of funds. With an initial construction budget of over $210 million, high maintenance costs of the new facility, \"six figure\" utility bills, and \"lower-than-expected\" ticket sales, COSI's reliance on admission revenue proved to be an unsuitable long term plan. In 2004, the museum spearheaded an effort to assess a property tax levy, chaired by former NASA astronaut John Glenn. The levy would have imposed a property tax on residents of Franklin County, who would receive free admission in return. The levy failed. As a result, the south wing of COSI's \"blimp\" structure was closed.\n\nAs part of the reconfiguration of the museum following the loss of the levy in 2004, COSI opened only five days per week instead of seven. Many of the museum's exhibits were announced to close permanently (though many have re-opened in stages in the years since). Two of the original exhibit areas were closed permanently (called i|o and SimZone, the spaces they formerly occupied are now Gallery 1 and Energy Explorers, respectively).\n\nClosures from 2004 that have since been reversed include Space (relocated to Level 1 in 2005, then to the Mezzanine in 2012), the original Gallery 1 (space reused as WOSU@COSI in September 2006), Adventure (re-opened as an additional-charge experience in September 2010), CityView (still off limits to the public; now available for special events), and the Planetarium (re-opened in November 2014 as the final piece of the building to come back online).\n\nDuring the spring and summer of 2005, COSI hosted the blockbuster traveling exhibition \"Titanic: The Artifact Exhibition\" and saw record attendance (prompting the return of the exhibit in 2010). In the summer 2006, COSI hosted another large exhibit: \"\", produced by the Museum of Science, Boston.\n\nIn April 2006 Dr. David Chesebrough, former president and CEO of the Buffalo Museum of Science, became COSI's new president and CEO. He replaced former NASA astronaut Kathryn D. Sullivan, who transitioned to a new role as COSI science advisor on a volunteer basis while serving in her new role as the Director of Ohio State University's Battelle Center for Mathematics and Science Education Policy.\n\nSince then, COSI has integrated additional-cost traveling exhibits as part of its funding model. The museum has hosted \"EINSTEIN, An Exhibition on the Man and his Science\" (2007), \"Animation featuring Cartoon Network\" (2007), \"Gregor Mendel: Planting the Seeds of Genetics \" (2007), \"Bob the Builder: Project Build It\" (2007), \"Goosebumps! The Science of Fear\" (2008), \"CSI: The Experience\" (2008), \"Adventures with Clifford the Big Red Dog\" (2010), \"Geckos: From Tail to Toepads\" (2011), \"Dinosaurs: Explore. Escape. Survive.\" (2011), Dora and Diego - Let's Explore! (2011), RACE: Are We So Different? (2012), WATER (2012), LEGO Castle Adventure (2012), BODYWORLDS and The Brain (2012), MindBender Mansion and Amazing Mazes (2013), MythBusters: The Explosive Exhibition (2013), Curious George: Let's Get Curious! (2013), and Sherlock: The Exhibition (2014). As well, COSI developed its own traveling exhibit, \"Lost Egypt: Ancient Secrets, Modern Science\" (2009) in cooperation with the Science Museum Exhibit Collaborative, built by the Science Museum of Minnesota. \"Lost Egypt\" now travels the nation to other museums.\n\nIn January 2016, Dr. Chesebrough announced that he planned to retire at the end of 2016. A executive search firm was contracted, and an advisory committee formed, to identify candidates to succeed him as president and CEO.\n\nOn August 23, 2016, the Capitol South Community Redevelopment Corp. announced the approval of a $37 million plan to replace the 600-spot parking lots on COSI's west side with an underground parking garage topped with an 8-acre green space and programmatic park as a compliment to the larger Scioto Peninsula green space along the Scioto River. The construction project is expected to be completed in spring 2018.\n\nOn September 16, 2016, COSI announced a partnership between the city of Columbus and the American Museum of Natural History (AMNH) in New York City to build a $5 million permanent Dinosaur Exhibition Gallery and a dedicated AMNH Traveling Exhibition Gallery replacing the WOSU and Adventure exhibits. The WOSU exhibit has since relocated; however, the Adventure exhibition closed permanently on January 1, 2017.\n\nOn November 10, 2016, the COSI board of trustees announced the selection of Dr. Frederic Bertley as COSI Columbus' new president and CEO, effective January 1, 2017. Dr. Bertley was previously senior vice president for science and education at the Franklin Institute in Philadelphia.\n\nOn January 1, 2017, the Adventure exhibit permanently closed to make room for COSI's Dinosaur Gallery.\n\n\n"}
{"id": "344828", "url": "https://en.wikipedia.org/wiki?curid=344828", "title": "Canada's athletes of the 20th century", "text": "Canada's athletes of the 20th century\n\nCanada's Athletes of the 20th century as voted on in a 1999 survey of newspaper editors and broadcasters conducted by the Canadian Press and Broadcast News:\n\n\n\n"}
{"id": "33290205", "url": "https://en.wikipedia.org/wiki?curid=33290205", "title": "Cand.scient.pol.", "text": "Cand.scient.pol.\n\nCand.scient.pol. (i.e. Latin \"candidatus/candidata scientiarum politicarum\", also translated into Danish as \"kandidat i statskundskab\", \"candidate of political science\") is a candidate's degree, viz. an advanced degree, in political science, awarded by several Danish universities. The degree currently requires 5 years of studies, historically 6 years. The current 5-year degree is, since 2009, translated into English as \"Master of Science in Political Science\".\n\nThe equivalent degree used in Norway (until 2008) was called cand.polit. In Denmark, cand.polit. is a degree in economics.\n\n20% of all members of parliament hold a cand.scient.pol. degree.\n"}
{"id": "59022538", "url": "https://en.wikipedia.org/wiki?curid=59022538", "title": "Cathy Tie", "text": "Cathy Tie\n\nCathy Tie is a Canadian bioinformatician and entrepreneur known best as a founder of Ranomics, a genetic screening company based in San Francisco.\n\nTie's family moved from China to Canada when she was four years old. Her father has a masters degree in chemical engineering, but she describes both parents as \"entrepreneurs.\" Growing up in Mississagua, Ontario, she attended the Glenforest Secondary School (International Baccalaureate Diploma Program). \n\nAt 15, she worked on an immunology project with researchers at the University of Toronto, work that was published the next year in the \"Canadian Young Scientist Journal\" as a single-author manuscript. Further research using yeast as a gene variant model was published by a larger team in 2018. \n\nDuring her first year as an undergraduate at the University of Toronto, Tie worked at Mount Sinai Hospital, in the genetic research laboratory of Dr. Frederick Roth. After hearing about a competition for a biotech startup, she teamed up with Leo Wan, a graduate student in Roth's lab, to create a business plan for a genomics start-up. They later presented their business plan to IndieBio, an accelerator run by SOSV, who gave them $100,000 of funding. Tie took a leave of absence in 2014 after less than a year of college to work on the project in San Francisco with IndieBio.\n\nIn 2015, Tie was one of only four Canadians to win a Thiel Fellowship, which encourages college undergraduates to leave college and instead further their education by building a startup company.\n\nTie founded Ranomics as its CEO in 2015. In a JLabs profile, Tie explained that the company's focus was to investigate variants of unknown significance (VUS) that caused genetic tests to fail or misdiagnose patients. Ranomics worked for external genetic testing firms in a business-to-business arrangement to analyze oncogene mutations. Tie and her partner eventually partnered lead product VariantFind with Science Exchange to provide variant analysis on their online platform.\n\nTie was a 2015 Thiel Fellow and a 2018 Forbes Healthcare \"30 under 30\". She and co-founder Leo Wan won a $100K USD incubator mentorship through SOSV's incubator IndieBio. Her company was chosen as a Kairos Society 50 in 2017.\n\nShe was named a partner in SF-based Cervin Ventures in 2018.\n"}
{"id": "33073181", "url": "https://en.wikipedia.org/wiki?curid=33073181", "title": "Clay dog", "text": "Clay dog\n\nClay dogs are naturally occurring clay formations that are sculpted by river currents from glacially deposited blue-gray clay and then dried by the sun. They exhibit tremendous variety in shape and size, with some being simple and others having highly complex forms. They only occur in a few places in the world. Until recently, Croton Point along the Hudson River produced them, but the clay slope that produced the dogs was subsequently demolished to extend a park lawn. Clay dogs were described in detail in an article by L. P. Gratacap, \"Opinions on Clay Stones and Concretions\".\n"}
{"id": "397271", "url": "https://en.wikipedia.org/wiki?curid=397271", "title": "Cohort study", "text": "Cohort study\n\nA cohort study is a particular form of longitudinal study that sample a cohort (a group of people who share a defining characteristic, typically those who experienced a common event in a selected period, such as birth or graduation), performing a cross-section at intervals through time. While a cohort study is a panel study, a panel study is not always a cohort study as individuals in a panel study do not always share a common characteristic.\n\nCohort studies represent one of the fundamental designs of epidemiology which are used in research in the fields of medicine, nursing, psychology, social science, and in any field reliant on 'difficult to reach' answers that are based on evidence (statistics). In medicine for instance, while clinical trials are used primarily for assessing the safety of newly developed pharmaceuticals before they are approved for sale, epidemiological analysis on how risk factors affect the incidence of diseases is often used to identify the causes of diseases in the first place, and to help provide pre-clinical justification for the plausibility of protective factors (treatments). Cohort studies differ from clinical trials in that no intervention, treatment, or exposure is administered to participants in a cohort design; and no control group is defined. Rather, cohort studies are largely about the life histories of segments of populations, and the individual people who constitute these segments. Exposures or protective factors are identified as preexisting characteristics of participants. The study is controlled by including other common characteristics of the cohort in the statistical analysis. Both exposure/treatment and control variables are measured at baseline. Participants are then followed over time to observe the incidence rate of the disease or outcome in question. Regression analysis can then be used to evaluate the extent to which the exposure or treatment variable contributes to the incidence of the disease, while accounting for other variables that may be at play.\n\nDouble-blind randomized controlled trials (RCTs) are generally considered superior methodology in the hierarchy of evidence in treatment, because they allow for the most control over other variables that could affect the outcome, and the randomization and blinding processes reduce bias in the study design. This minimizes the chance that results will be influenced by confounding variables, particularly ones that are unknown. However, educated hypotheses based on prior research and background knowledge are used to select variables to be included in the regression model for cohort studies, and statistical methods can be used to identify and account potential confounders from these variables. Bias can also be mitigated in a cohort study when selecting participants for the cohort. It is also important to note that RCTs may not be suitable in all cases; such as when the outcome is a negative health effect and the exposure is hypothesized to be a risk factor for the outcome. Ethical standards, and morality, would prevent the use of risk factors in RCTs. The natural or incidental exposure to these risk factors (e.g. time spent in the sun), or self-administered exposure (e.g. smoking), can be measured without subjecting participants to risk factors outside of their individual lifestyles, habits, and choices.\n\nCohort studies can be retrospective (looking back in time, thus using existing data such as medical records or claims database) or prospective (requiring the collection of new data). Retrospectives cohort studies restrict the investigators ability to reduce confounding and bias because collected information is restricted to data that already exists. There are advantages to this design however, as retrospective studies are much cheaper and faster because the data has already been collected and stored.\n\nA cohort is a group of people who share a common characteristic or experience within a defined period (e.g., are currently living, are exposed to a drug or vaccine or pollutant, or undergo a certain medical procedure). Thus a group of people who were born on a day or in a particular period, say 1948, form a birth cohort. The comparison group may be the general population from which the cohort is drawn, or it may be another cohort of persons thought to have had little or no exposure to the substance under investigation, but otherwise similar. Alternatively, subgroups within the cohort may be compared with each other.\n\nIndicators of cohort study: \n\nIn medicine, a cohort study is often undertaken to obtain evidence to try to refute the existence of a suspected association between cause and effect; failure to refute a hypothesis often strengthens confidence in it. Crucially, the cohort is identified before the appearance of the disease under investigation. The study groups follow a group of people who do not have the disease for a period of time and see who develops the disease (new incidence). The cohort cannot therefore be defined as a group of people who already have the disease. Prospective (longitudinal) cohort studies between exposure and disease strongly aid in studying causal associations, though distinguishing true causality usually requires further corroboration from further experimental trials.\n\nThe advantage of prospective cohort study data is that it can help determine risk factors for contracting a new disease because it is a longitudinal observation of the individual through time, and the collection of data at regular intervals, so recall error is reduced. However, cohort studies are expensive to conduct, are sensitive to attrition and take a long follow-up time to generate useful data. Nevertheless, the results that are obtained from long-term cohort studies are of substantially superior quality to those obtained from retrospective/cross-sectional studies. Prospective cohort studies are considered to yield the most reliable results in observational epidemiology. They enable a wide range of exposure-disease associations to be studied.\n\nSome cohort studies track groups of children from their birth, and record a wide range of information (exposures) about them. The value of a cohort study depends on the researchers' capacity to stay in touch with all members of the cohort. Some studies have continued for decades.\n\nIn a cohort study, the population under investigation consists of individuals who are at risk of developing a specific disease or health outcome.\n\nAn example of an epidemiological question that can be answered using a cohort study is whether exposure to X (say, smoking) associates with outcome Y (say, lung cancer). In 1951, commenced the British Doctors Study, a cohort that included both smokers (the exposed group) and non-smokers (the unexposed group). The study continued through 2001. By 1956, the study provided convincing proof of the association of smoking with the incidence of lung cancer. In a cohort study, the groups are \"matched\" in terms of many other variables such as economic status and other health status so that the variable being assessed, the independent variable (in this case, smoking) can be isolated as the cause of the dependent variable (in this case, lung cancer). In this example, a statistically significant increase in the incidence of lung cancer in the smoking group as compared to the non-smoking group is evidence in favor of the hypothesis. However, rare outcomes, such as lung cancer, are generally not studied with the use of a cohort study, but are rather studied with the use of a case-control study.\n\nShorter term studies are commonly used in medical research as a form of clinical trial, or means to test a particular hypothesis of clinical importance. Such studies typically follow two groups of patients for a period of time and compare an endpoint or outcome measure between the two groups.\n\nRandomized controlled trials, or RCTs are a superior methodology in the hierarchy of evidence, because they limit the potential for bias by randomly assigning one patient pool to an intervention and another patient pool to non-intervention (or placebo). This minimizes the chance that the incidence of confounding variables will differ between the two groups.\n\nNevertheless, it is sometimes not practical or ethical to perform RCTs to answer a clinical question. To take our example, if we already had reasonable evidence that smoking causes lung cancer then persuading a pool of non-smokers to take up smoking in order to test this hypothesis would generally be considered quite unethical.\n\nTwo examples of cohort studies that have been going on for more than 50 years are the Framingham Heart Study and the National Child Development Study (NCDS), the most widely researched of the British birth cohort studies. Key findings of NCDS and a detailed profile of the study appear in the \"International Journal of Epidemiology\".\n\nThe Dunedin Longitudinal Study, started in 1975, has been studying the thousand people born in Dunedin, New Zealand in 1972-73. The subjects are interviewed regularly, with Phase 45 starting in 2017. \n\nThe largest cohort study in women is the Nurses' Health Study. Started in 1976, it is tracking over 120,000 nurses and has been analyzed for many different conditions and outcomes.\n\nThe largest cohort study in Africa is the Birth to Twenty Study, which began in 1990 and tracks a cohort of over 3,000 children born in the weeks following Nelson Mandela's release from prison.\n\nOther famous examples are the Grant Study tracking a number of Harvard graduates from ca. 1950.77, the Whitehall Study tracking 10,308 British civil servants, and the Caerphilly Heart Disease Study, which since 1979 has studied a representative sample of 2,512 men, drawn from the Welsh town of Caerphilly.\n\nThe diagram indicates the starting point and direction of cohort and case-control studies.\nIn Case-control studies the analysis proceeds from documented disease and investigations are made to arrive at the possible causes of the disease. In cohort studies the assessments starts with the putative cause of disease, and observations are made of the occurrence of disease relative to the hypothesized causal agent.\n\nA current cohort study represents a true prospective study where the data concerning exposure are assembled prior to the occurrence of the fact to be studied, for instance a disease. An example of a current cohort study is the Oxford Family Planning Association Study in the United Kingdom, which aimed to provide a balanced view of the beneficial and harmful effects of different methods of contraception. This study has provided a large amount of information on the efficacy and safety of contraceptive methods, and in particular oral contraceptives (OCs), diaphragms and intrauterine device (IUDs).\n\nIn a historical cohort study the data concerning exposure and occurrence of a disease, births, a political attitude or any other categorical variable are collected after the events have taken place, and the subjects (those exposed and unexposed to the agent under study) are assembled from existing records or health care registers.\n\nA \"prospective cohort\" defines the groups before the study is done, while historical studies, which are sometimes referred to as \"retrospective cohort\", defines the grouping after the data is collected. Examples of a retrospective cohort are \"Long-Term Mortality after Gastric Bypass Surgery\" and \"The Lothian Birth Cohort Studies\".\n\nAlthough historical studies are sometimes referred to as retrospective study, it a misnomer as the methodological principles of historical cohort studies and prospective studies are the same.\n\nAn example of a nested case-control study is \"Inflammatory markers and the risk of coronary heart disease in men and women\", which was a case control analyses extracted from the Framingham Heart Study cohort.\n\nHousehold panel surveys are an important sub-type of cohort study. These draw representative samples of households and survey them, following all individuals through time on a usually annual basis. Examples include the US Panel Study of Income Dynamics (since 1968), the \"German\" Socio-Economic Panel (since 1984), the British Household Panel Survey (since 1991), the Household, Income and Labour Dynamics in Australia Survey (since 2001) and the European Community Household Panel (1994–2001).\n\nFor an example in business analysis, see cohort analysis.\n\n\n"}
{"id": "8638682", "url": "https://en.wikipedia.org/wiki?curid=8638682", "title": "Comparison of wireless data standards", "text": "Comparison of wireless data standards\n\nA wide variety of different wireless data technologies exist, some in direct competition with one another, others designed for specific applications. Wireless technologies can be evaluated by a variety of different metrics of which some are described in this entry.\n\nStandards can be grouped as follows in increasing range order:\n\nPersonal Area Network (PAN) systems are intended for short range communication between devices typically controlled by a single person. Some examples include wireless headsets for mobile phones or wireless heart rate sensors communicating with a wrist watch. Some of these technologies include standards such as ANT UWB, Bluetooth, ZigBee, and Wireless USB.\n\nWireless Sensor Networks (WSN / WSAN) are, generically, networks of low-power, low-cost devices that interconnect wirelessly to collect, exchange, and sometimes act-on data collected from their physical environments - \"sensor networks\". Nodes typically connect in a star or mesh topology. While most individual nodes in a WSAN are expected to have limited range (Bluetooth, ZigBee, 6LoWPAN, etc.), particular nodes may be capable of more expansive communications (Wi-Fi, Cellular networks, etc.) and any individual WSAN can span a wide geographical range. An example of a WSAN would be a collection of sensors arranged throughout an agricultural facility to monitor soil moisture levels, report the data back to a computer in the main office for analysis and trend modeling, and maybe turn on automatic watering spigots if the level is too low.\n\nFor wider area communications, Wireless Local Area Network (WLAN) is used. WLANs are often known by their commercial product name Wi-Fi. These systems are used to provide wireless access to other systems on the local network such as other computers, shared printers, and other such devices or even the internet. Typically a WLAN offers much better speeds and delays within the local network than an average consumer's Internet access. Older systems that provide WLAN functionality include DECT and HIPERLAN. These however are no longer in widespread use. One typical characteristic of WLANs is that they are mostly very local, without the capability of seamless movement from one network to another.\n\nCellular networks or WAN are designed for citywide/national/global coverage areas and seamless mobility from one access point (often defined as a Base Station) to another allowing seamless coverage for very wide areas. Cellular network technologies are often split into 2nd generation 2G, 3G and 4G networks. Originally 2G networks were voice centric or even voice only digital cellular systems (as opposed to the analog 1G networks). Typical 2G standards include GSM and IS-95 with extensions via GPRS, EDGE and 1xRTT, providing Internet access to users of originally voice centric 2G networks. Both EDGE and 1xRTT are 3G standards, as defined by the ITU, but are usually marketed as 2.9G due to their comparatively low speeds and high delays when compared to true 3G technologies.\n\nTrue 3G systems such as EV-DO, W-CDMA (including HSPA) provide combined circuit switched and packet switched data and voice services from the outset, usually at far better data rates than 2G networks with their extensions. All of these services can be used to provide combined mobile voice access and Internet access at remote locations.\n\n4G networks provide even higher bitrates and many architectural improvements, which are not necessarily visible to the consumer. The current 4G systems that are deployed widely are HSPA+, WIMAX and LTE. The latter two are pure packet based networks without traditional voice circuit capabilities. These networks provide voice services via VoIP.\n\nSome systems are designed for point-to-point line-of-sight communications, once two such nodes get too far apart they can no longer communicate. Other systems are designed to form a wireless mesh network using one of a variety of routing protocols. In a mesh network, when nodes get too far apart to communicate directly, they can still communicate indirectly through intermediate nodes.\n\nThe following standards are included in this comparison.\n\n\n\n\nWhen discussing throughput, there is often a distinction between the peak data rate of the physical layer, the theoretical maximum data throughput and typical throughput.\n\nThe peak bit rate of the standard is the net bit rate provided by the physical layer in the fastest transmission mode (using the fastest modulation scheme and error code), excluding forward error correction coding and other physical layer overhead.\n\nThe theoretical maximum throughput for end user is clearly lower than the peak data rate due to higher layer overheads. Even this is never possible to achieve unless the test is done under perfect laboratory conditions.\n\nThe typical throughput is what users have experienced most of the time when well within the usable range to the base station. The typical throughput is hard to measure, and depends on many protocol issues such as transmission schemes (slower schemes are used at longer distance from the access point due to better redundancy), packet retransmissions and packet size. The typical throughput is often even lower because of other traffic sharing the same network or cell, interference or even the fixed line capacity from the base station onwards being limited.\n\nNote that these figures cannot be used to predict the performance of any given standard in any given environment, but rather as benchmarks against which actual experience might be compared.\n\n\n\n"}
{"id": "1773453", "url": "https://en.wikipedia.org/wiki?curid=1773453", "title": "Drapetomania", "text": "Drapetomania\n\nDrapetomania was a conjectural mental illness that, in 1851, American physician Samuel A. Cartwright hypothesized as the cause of enslaved Africans fleeing captivity. It has since been debunked as pseudoscience and part of the edifice of scientific racism.\n\nThe term derives from the Greek δραπέτης (\"drapetes\", \"a runaway [slave]\") and μανία (\"mania\", \"madness, frenzy\").\n\nIn \"Diseases and Peculiarities of the Negro Race\", Cartwright points out that the Bible calls for a slave to be submissive to his master, and by doing so, the slave will have no desire to run away.\n\nCartwright described the disorder – which, he said, was \"unknown to our medical authorities, although its diagnostic symptom, the absconding from service, is well known to our planters and overseers\" – in a paper delivered before the Medical Association of Louisiana that was widely reprinted.\n\nHe stated that the malady was a consequence of masters who \"made themselves too familiar with [slaves], treating them as equals\".\n\nIn addition to identifying drapetomania, Cartwright prescribed a remedy. His feeling was that with \"proper medical advice, strictly followed, this troublesome practice that many Negroes have of running away can be almost entirely prevented\".\n\nIn the case of slaves \"sulky and dissatisfied without cause\" – a warning sign of imminent flight – Cartwright prescribed \"whipping the devil out of them\" as a \"preventative measure\". As a remedy for this \"disease\", doctors also made running a physical impossibility by prescribing the removal of both big toes.\n\nWhile Cartwright's article was reprinted in the South, in the northern United States it was widely mocked. A satirical analysis of the article appeared in a \"Buffalo Medical Journal\" editorial in 1855. Renowned landscape architect Frederick Law Olmsted, in \"A Journey in the Seaboard Slave States\" (1856), observed that white indentured servants had often been known to flee as well, so he satirically hypothesized that the supposed disease was actually of white European origin, and had been introduced to Africa by traders.\n\nAs late as 1914, the third edition of Thomas Lathrop Stedman's \"Practical Medical Dictionary\" included an entry for \"drapetomania\", defined as \"Vagabondage, dromomania; an uncontrollable or insane impulsion to wander.\"\n\n\n\n"}
{"id": "46185525", "url": "https://en.wikipedia.org/wiki?curid=46185525", "title": "Ethnoscape", "text": "Ethnoscape\n\n\"Ethnoscape\" is one of five elementary frameworks (ethnoscapes, \"mediascapes\", \"technoscapes\", \"financescapes\", and \"ideoscapes\") used by Arjun Appadurai, in purpose of exploring fundamental discrepancies of global cultural flows. The suffix \"-scape\" indicates that these terms are perspectival constructs inflected by the historical, linguistic, and political situatedness of different kinds of actors: nation-states, multinationals, diasporic communities, and subnational groupings and movements, whether religious, political, or economic, etc..\n\nBy using the ethnoscape, Appadurai extends the landscape of persons who form the shifting world where we live, that is, tourists, immigrants, refugees, or any moving groups and individuals of fundamental feature of the world and appear to affect the politics of (and between) nations to a hitherto unprecedented degree. Appadurai claims that this is not to say there are no relatively stable communities and networks of kinship, friendship, work, and leisure, as well as of birth, residence, and other filial forms. But it is to say that the warp of these stabilities is everywhere shot through with the weft of human motion, as more persons and groups deal with the realities of having to move of the fantasies of wanting to move. Ethnoscapes allow us to recognize that our notions of space, place and community have become much more complex, indeed a ‘single community’ may now be dispersed across a variety of sites.\n"}
{"id": "2969078", "url": "https://en.wikipedia.org/wiki?curid=2969078", "title": "Feminism and Nationalism in the Third World", "text": "Feminism and Nationalism in the Third World\n\nFeminism and Nationalism in the Third World written by Kumari Jayawardena is widely used in women's studies programs around the world and is considered a key text of third-world feminism.\n\nJayawardena reconstructs the history of women's rights movements in Asia and the Middle East from the 19th century to the 1980s, focusing on Egypt, Turkey, Iran, India, Sri Lanka, China, Indonesia, Vietnam, Japan, Korea, and the Philippines. Her research shows that feminism was \"not\" a foreign ideology 'imposed' on 'Third World' countries, but instead, was indigenous to Asia and the Middle East as women struggled for equal rights and against the subordination of women in the home and in society in general.\n\nJayawardena is the author of several other books, including \"The Rise of the Labor Movement in Ceylon\" and \"Embodied Violence: Communalising Women's Sexuality in South Asia\". (Co-edited with Malathi de Alwis). However \"Feminism and Nationalism in the Third World\" is one of Jayawarden's oft-cited works and has gained international recognition. The book was chosen for the Feminist Fortnight award in Britain in 1986 and was cited by \"Ms.\" magazine in 1992 as one of the 20 most important books of 'the feminist decades' (i.e. 1970-1990).\n\n"}
{"id": "1983473", "url": "https://en.wikipedia.org/wiki?curid=1983473", "title": "Flat-field correction", "text": "Flat-field correction\n\nFlat-field correction is a technique used to improve quality in digital imaging. The goal is to remove artifacts from 2-D images that are caused by variations in the pixel-to-pixel sensitivity of the detector and/or by distortions in the optical path. It is a standard calibration procedure in everything from pocket digital cameras to giant telescopes.\n\nFlat fielding refers to the process of compensating for different gains and dark currents in a detector. Once a detector has been appropriately flat-fielded, a uniform signal will create a uniform output (hence flat-field). This then means any further signal is due to the phenomenon being detected and not a systematic error.\n\nA flat-field consists of two numbers for each pixel, the pixel's gain and its dark current (or dark frame). The pixel's gain is how the amount of signal given by the detector varies as a function of the amount of light (or equivalent). The gain is almost always a linear variable, as such the gain is given simply as the ratio of the input and output signals. The dark-current is the amount of signal given out by the detector when there is no incident light (hence dark frame). In many detectors this can also be a function of time, for example in astronomical telescopes it is common to take a dark-frame of the same time as the planned light exposure. The gain and dark-frame for optical systems can also be established by using a series of neutral density filters to give input/output signal information and applying a least squares fit to obtain the values for the dark current and gain.\nformula_1\n\nwhere:\n\n\nIn this equation, capital letters are 2D matrices, and lowercase letters are scalars. All matrix operations are performed element-by-element.\n\nIn order for an astrophotographer to capture a light frame, he or she must place a light source over the imaging instrument's objective lens such that the light source emanates evenly through the users optics. The photographer must then adjust the exposure of their imaging device (CCD or DSLR camera) so that when the histogram of the image is viewed, a peak reaching about 40–70% of the dynamic range (maximum range of pixel values) of the imaging device is seen. The photographer typically takes 15–20 light frames and performs median stacking. Once the desired light frames are acquired, the objective lens is covered so that no light is allowed in, then 15–20 dark frames are taken, each of equal exposure time as a light frame. These are called Dark-Flat frames.\n\nIn X-ray imaging, the acquired projection images generally suffer from fixed-pattern noise, which is one of the limiting factors of image quality. It may stem from beam inhomogeneity, gain variations of the detector response due to inhomogeneities in the photon conversion yield, losses in charge transport, charge trapping, or variations in the performance of the readout. Also, the scintillator screen may accumulate dust and/or scratches on its surface, resulting in systematic patterns in every acquired X-ray projection image. In X-ray Computed Tomography (CT), fixed-pattern noise is known to significantly degrade the achievable spatial resolution and generally leads to ring or band artifacts in the reconstructed images. Fixed pattern noise can be easily removed using flat field correction. In conventional flat field correction, projection images without sample are acquired with and without the X-ray beam turned on, which are referred to as flat fields (F) and dark fields (D). Based on the acquired flat and dark fields, the measured projection images (P) with sample are then normalized to new images (N) according to \n\nformula_3\n\nWhile conventional flat field correction is an elegant and easy procedure that largely reduces fixed-pattern noise, it heavily relies on the stationarity of the X-ray beam, scintillator response and CCD sensitivity. In practice, however, this assumption is only approximately met. Indeed, detector elements are characterized by intensity dependent, nonlinear response functions and the incident beam often shows time dependent non-uniformities, which render conventional FFC inadequate. In synchrotron X-ray tomography, many factors may cause flat field variations: instability of the bending magnets of the synchrotron, temperature variations due to the water cooling in mirrors and the monochromator, or vibrations of the scintillator and other beamline components. The latter is responsible for the biggest variations in the flat fields. To deal with such variations, a dynamic flat field correction procedure can be employed that estimates a flat field for each individual projection. Through principal component analysis of a set of flat fields, which are acquired prior and/or posterior to the actual scan, eigen flat fields can be computed. A linear combination of the most important eigen flat fields can then used to individually normalize each X-ray projection:\n\nformula_4\n\n\n\n\n"}
{"id": "13843189", "url": "https://en.wikipedia.org/wiki?curid=13843189", "title": "Free molecular flow", "text": "Free molecular flow\n\nFree molecular flow describes the fluid dynamics of gas where the mean free path of the molecules is larger than the size of the chamber or of the object under test. For tubes/objects of the size of several cm, this means pressures well below 10 mbar. This is also called the regime of high vacuum, or even ultra-high vacuum. This is opposed to viscous flow encountered at higher pressures. The presence of free molecular flow can be calculated, at least in estimation, with the Knudsen number (Kn). If Kn > 1, the system is in free molecular flow.\n\nIn free molecular flow, the pressure of the remaining gas can be considered as effectively zero. Thus, boiling points do not depend on the residual pressure. The flow can be considered to be individual particles moving in straight lines. Practically, the \"vapor\" cannot move around bends or into other spaces behind obstacles, as they simply hit the tube wall. This implies conventional pumps cannot be used, as they rely on viscous flow and fluid pressure. Instead, special sorption pumps and ion pumps must be used.\n\nFree molecular flow occurs in various processes such as molecular distillation, ultra-high vacuum equipment such as particle accelerators, and naturally in outer space.\n\nThe definition of a free molecular flow depends on the distance scale under consideration. For example, in the interplanetary medium, the plasma is in a free molecular flow regime in scales less than 1 AU; thus, planets and moons are effectively under particle bombardment. However, on larger scales, fluid-like behavior is observed, because the probability of collisions between particles becomes significant.\n\n"}
{"id": "33876751", "url": "https://en.wikipedia.org/wiki?curid=33876751", "title": "Fuzzy architectural spatial analysis", "text": "Fuzzy architectural spatial analysis\n\nFuzzy architectural spatial analysis (FASA) (also fuzzy inference system (FIS) based architectural space analysis or fuzzy spatial analysis) is a spatial analysis method of analysing the spatial formation and architectural space intensity within any architectural organization.\n\nFuzzy architectural spatial analysis is used in architecture, interior design, urban planning and similar spatial design fields.\n\nFuzzy architectural spatial analysis was developed by Burcin Cem Arabacioglu (2010) from the architectural theories of space syntax and visibility graph analysis, and is applied with the help of a fuzzy system with a Mamdami inference system based on fuzzy logic within any architectural space. Fuzzy architectural spatial analysis model analyses the space by considering the perceivable architectural element by their boundary and stress characteristics and intensity properties. The method is capable of taking all sensorial factors into account during analyses in conformably with the perception process of architectural space which is a multi-sensorial act.\n\n\n"}
{"id": "1056866", "url": "https://en.wikipedia.org/wiki?curid=1056866", "title": "GC-content", "text": "GC-content\n\nIn molecular biology and genetics, GC-content (or guanine-cytosine content) is the percentage of nitrogenous bases on a DNA or RNA molecule that are either guanine or cytosine (from a possibility of four different ones, also including adenine and thymine in DNA and adenine and uracil in RNA). This may refer to a certain fragment of DNA or RNA, or that of the whole genome. When it refers to a fragment of the genetic material, it may denote the GC-content of section of a gene (domain), single gene, group of genes (or gene clusters), or even a non-coding region.\n\nQualitativelty, G (guanine) and C (cytosine) undergo a specific hydrogen bonding, whereas A (adenine) bonds specifically with T (thymine, in DNA) or U (uracil, in RNA). Quantitativelty, the GC pair is bound by three hydrogen bonds, while AT and AU pairs are bound by two hydrogen bonds. To emphasize this difference in the number of hydrogen bonds, the base pairings can be represented as respectively G≡C versus A=T and A=U. DNA with low GC-content is less stable than DNA with high GC-content; however, the hydrogen bonds themselves do not have a particularly significant impact on stabilization, the stabilization is due mainly to interactions of base stacking.\nIn spite of the higher thermostability conferred to the genetic material, it has been observed that at least some bacteria species with DNA of high GC-content undergo autolysis more readily, thereby reducing the longevity of the cell \"per se\". Due to the thermostability given to the genetic materials in high GC organisms, it was commonly believed that the GC content played a necessary role in adaptation temperatures, a hypothesis that was refuted in 2001.\nHowever, it has been shown that there is a strong correlation between the prokaryotic optimal growth at higher temperatures and the GC content of structured RNAs (such as ribosomal RNA, transfer RNA, and many other non-coding RNAs). The AU base pairs are less stable than the GC base pairs previously attributed to GC bonds containing 3 hydrogen bonds and AU having only 2 hydrogen bonds, making high-GC-content RNA structures more resistant to the effects of high temperatures.\nMore recently, it has been proved that the most stabilizing factor of thermal stability of double stranded nucleic acids is actually due to the base stackings of adjacent bases, rather than the number of hydrogen bonds between the bases.There is more favorable stacking energy for G:C pairs because of the relative positions of exocyclic groups than in the A:U pairs. Additionally, there is a correlation between the order in which the bases stack and thermal stability.\n\nGC content is usually expressed as a percentage value, but sometimes as a ratio (called G+C ratio or GC-ratio). GC-content percentage is calculated as\n\nwhereas the AT/GC ratio is calculated as \n\nThe GC-content percentages as well as GC-ratio can be measured by several means, but one of the simplest methods is to measure what is called the melting temperature of the DNA double helix using spectrophotometry. The absorbance of DNA at a wavelength of 260 nm increases fairly sharply when the double-stranded DNA separates into two single strands when sufficiently heated. The most commonly used protocol for determining GC ratios uses flow cytometry for large number of samples.\n\nIn alternative manner, if the DNA or RNA molecule under investigation has been sequenced then the GC-content can be accurately calculated by simple arithmetic or by using the free online GC calculator.\n\nThe GC ratio within a genome is found to be markedly variable. These variations in GC ratio within the genomes of more complex organisms result in a mosaic-like formation with islet regions called isochores. This results in the variations in staining intensity in the chromosomes. GC-rich isochores include in them many protein coding genes, and thus determination of ratio of these specific regions contributes in mapping gene-rich regions of the genome.\n\nWithin a long region of genomic sequence, genes are often characterised by having a higher GC-content in contrast to the background GC-content for the entire genome. Evidence of GC ratio with that of length of the coding region of a gene has shown that the length of the coding sequence is directly proportional to higher G+C content. This has been pointed to the fact that the stop codon has a bias towards A and T nucleotides, and, thus, the shorter the sequence the higher the AT bias.\n\nComparison of more than 1,000 orthologous genes in mammals showed marked within-genome variations of the third-codon position GC content, with a range from less than 30% to more than 80%.\n\nGC content is found to be variable with different organisms, the process of which is envisaged to be contributed to by variation in selection, mutational bias, and biased recombination-associated DNA repair. \n\nThe average GC-content in human genomes ranges from 35% to 60% across 100-Kb fragments, with a mean of 46.1%. The GC-content of Yeast (\"Saccharomyces cerevisiae\") is 38%, and that of another common model organism, thale cress (\"Arabidopsis thaliana\"), is 36%. Because of the nature of the genetic code, it is virtually impossible for an organism to have a genome with a GC-content approaching either 0% or 100%. However, a species with an extremely low GC-content is \"Plasmodium falciparum\" (GC% = ~20%), and it is usually common to refer to such examples as being AT-rich instead of GC-poor.\n\nSeveral mammalian species (e.g., shrew, microbat, tenrec, rabbit) have independently undergone a marked increase in the GC-content of their genes. These GC-content changes are correlated with species life-history traits (e.g., body mass or longevity) and genome size, and might be linked to a molecular phenomenon called the GC-biased gene conversion.\n\nIn polymerase chain reaction (PCR) experiments, the GC-content of primers are used to predict their annealing temperature to the template DNA. A higher GC-content level indicates a relatively higher melting temperature.\n\nThe species problem in prokaryotic taxonomy has led to various suggestions in classifying bacteria, and the \"ad hoc committee on reconciliation of approaches to bacterial systematics\" has recommended use of GC ratios in higher level hierarchical classification. For example, the Actinobacteria are characterised as \"high GC-content bacteria\". In \"Streptomyces coelicolor\" A3(2), GC content is 72%.\n\nGCSpeciesSorter and TopSort are software tools for classifying species based on their GC contents.\n\n\n"}
{"id": "40696546", "url": "https://en.wikipedia.org/wiki?curid=40696546", "title": "Glossary of sound laws in the Indo-European languages", "text": "Glossary of sound laws in the Indo-European languages\n\nThis glossary gives a general overview of the various sound laws that have been formulated by linguists for the various Indo-European languages. A concise description is given for each rule; more details are given on their articles.\n\nIn all words or word-groups of four or more syllables bearing the chief accent on a long syllable, a short unaccented medial vowel was necessarily syncopated, but might be restored by analogy\n"}
{"id": "3012984", "url": "https://en.wikipedia.org/wiki?curid=3012984", "title": "Hans Hollmann", "text": "Hans Hollmann\n\nHans Erich (Eric) Hollmann (4 November 1899 – 19 November 1960) was a German electronic specialist who made several breakthroughs in the development of radar.\n\nHollmann was born in Solingen, Germany. He became interested in radio and even as a teenager subscribed to the technical magazines of the day. Late in World War I he became a prisoner of war of the French and did not return to Germany until 1920. He then studied at the Technical University at Darmstadt until he received his doctorate in 1928.\n\nHollmann's doctoral research included the development of an ultra-short-wave transmitter and receiver for centimetre and decimetre waves. This gained the attention of \"Telefunken\", and ultimately led to their development of the first microwave telecommunication system.\n\nIn 1930 Hollmann moved to the Heinrich-Hertz Institute for Oscillatory Research in Berlin. There he continued studies in microwaves and cathode ray tubes and also worked on the ionosphere research and radio astronomy. In 1933 Hollmann became a lecturer at the Technical University in Berlin.\n\nIn January 1934, Hans-Karl von Willisen and Paul-Günther Erbslöh started a company called Gesellschaft für elektroakustische und mechanische Apparate (GEMA). With Hollmann as a consultant, GEMA built a system using interference detection in the autumn of 1934. It operated at 50 cm wavelength and could detect ships up to 10 km distance. By 1935, they used pulse-modulation, allowing measurement of range (distance to the target), and developed the technology into two applications. For naval use, the \"Seetakt\" system used a wavelength of 80 cm. A land based version at 120 cm wavelength was also developed as \"Freya\".\n\nTelefunken set up a radar business in 1933 based on Hollmann's work and developed a much shorter-range gun-laying system called \"Würzburg\". During World War II, \"Freya\" and \"Würzburg\" worked in pairs. \"Freya\" would spot the incoming aircraft while the \"Würzburg\" calculated the distance and height.\n\nIn 1935, Hollmann wrote two books on microwaves, \"Physics and Technique of Ultra-short Waves\" and \"Seeing with Electromagnetic Waves\", which were the inspiration for the development of centimetre radar in other countries despite some censorship of their contents.\n\nDuring the war he supervised many research institutes in occupied countries and saved many scientists from being deported to Germany. His home and his laboratory in Berlin were destroyed during the war. After the war he was not allowed to work on microwaves but he turned his attention to a wide range of other fields in electronics. He eventually accepted an offer from the US Government to work in California.\n\nHe was married to Gisela Schimmelbusch and had three children. He died in Los Angeles in 1960.\n\n"}
{"id": "29746234", "url": "https://en.wikipedia.org/wiki?curid=29746234", "title": "Hector (cloud)", "text": "Hector (cloud)\n\nHector is the name given to a cumulonimbus, or thundercloud, that forms regularly nearly every afternoon on the Tiwi Islands, Northern Territory, Australia, from approximately September to March each year. Hector, or sometimes \"Hector the Convector\", is known as one of the world's most consistently large thunderstorms, reaching heights of approximately .\n\nNamed by pilots during the Second World War, the recurring position of the thunderstorm made it a navigational beacon for pilots and mariners in the region. Hector is caused primarily by a collision of several sea breeze boundaries across the Tiwi Islands and is known for its consistency and intensity. Lightning rates and updraft speeds are notable aspects of this thunderstorm and during the 1990s National Geographic Magazine published a comprehensive study of the storm with pictures of damaged trees and details of updraft speeds and references to tornadic events.\n\nSince the late 1980s the thunderstorm has been the subject of many meteorological studies, many centered on Hector itself but also utilising the consistency of the storm cell to study other aspects of thunderstorms and lightning.\n\n"}
{"id": "32945511", "url": "https://en.wikipedia.org/wiki?curid=32945511", "title": "Hercules Superclusters", "text": "Hercules Superclusters\n\nThe Hercules Superclusters (SCl 160) refers to a set of two nearby superclusters of galaxies.\n\nRelative to other local superclusters, Hercules is considered particularly large, being approximately 330 Mly in diameter. The Northern Local Supervoid lies in front of the superclusters, and is as big as the superclusters themselves. The redshifts of the member galaxies lie between 0.0304 and 0.0414.\n\nThe region includes Abell 2147, Abell 2151 (Hercules Cluster), and Abell 2152 galaxy clusters. An extremely long filament of galaxies has been found, that connects this group of clusters to the Abell 2197 and Abell 2199 pair.\nAbell 2162 in the nearby constellation Corona Borealis is also a member.\n\nThe Hercules Superclusters are near the Coma Supercluster, helping make up part of the CfA2 Great Wall.\n\n"}
{"id": "10293481", "url": "https://en.wikipedia.org/wiki?curid=10293481", "title": "Ice III", "text": "Ice III\n\nIce III is a form of solid matter which consists of tetragonal crystalline ice, formed by cooling water down to at . It is the least dense of the high-pressure water phases, with a density of (at 350 MPa). The proton-ordered form of is ice IX.\n\nOrdinary water ice is known as , (in the Bridgman nomenclature). Different types of ice, from ice II to ice XVI, have been created in the laboratory at different temperatures and pressures.\n\n"}
{"id": "221797", "url": "https://en.wikipedia.org/wiki?curid=221797", "title": "Index of psychology articles", "text": "Index of psychology articles\n\nPsychology (from psykhē \"breath, spirit, soul\"; and , \"-logia\" \"study of\") is an academic and applied discipline involving the scientific study of human mental functions and behavior. Occasionally, in addition or opposition to employing the scientific method, it also relies on symbolic interpretation and critical analysis, although these traditions have tended to be less pronounced than in other social sciences, such as sociology. Psychologists study phenomena such as perception, cognition, emotion, personality, behavior, and interpersonal relationships. Some, especially depth psychologists, also study the unconscious mind.\n\nArticles related to psychology (excluding psychologists – see list of psychologists) include:\n\n\nA-not-B error -\nAbnormal psychology -\nAbreaction -\nAbsexual -\nAbuse -\nAcceptance and commitment therapy -\nAcrophobia -\nActing out -\nAction research -\nActive intellect -\nActive learning -\nActivity theory -\nActor-observer bias -\nAdaptation -\nAdaptive behavior -\nAdjustment disorder -\nAdolescence -\nAdolescent psychology -\nAdvanced Placement Psychology -\nAffect (psychology) -\nAffect display -\nAffectional bond -\nAffectional orientation -\nAffective forecasting -\nAffective science -\nAffirming the consequent -\nAfterburn (psychotherapy) -\nAge regression -\nAgeing -\nAggression -\nAgoraphobia -\nAgraphia  -\nAIDS dementia complex -\nAkinesia -\nAlexithymia -\nAlgophobia -\nAllophilia -\nAlogia -\nAlter ego -\nAltered state of consciousness -\nAltruism -\nAlzheimer's disease -\nAmbivalence -\nAmerican Psychological Association -\n\"The American Psychologist\" -\nAmnesia -\nAnal retentive -\nAnal stage -\nAnalytical psychology -\nAnamnesis (philosophy) -\nAnchoring -\nAnger -\nAnhedonia -\nAnima and animus -\nAnimal hoarding -\nAnomic aphasia -\nAnomie -\nAnorexia nervosa -\nAnorgasmia -\nAnterograde amnesia -\nAnticathexis -\nAnticipation (emotion) -\nAntidepressant -\nAntilocution -\nAntipathy -\nAntipsychotic -\nAnti-social behaviour -\nAnxiety -\nAnxiety disorder -\nAnxiogenic -\nApathy -\nAphanisis -\nAphasia -\nApoplexy -\nApperception -\nApplied behavior analysis -\nApplied psychology -\nApproach-avoidance conflict -\nAquaphobia -\nArchetypal psychology -\nArchetype -\nArousal -\nArtificial demand -\nArtisan temperament -\nAsian psychology -\nAsperger syndrome -\nAssertiveness -\nAssociation (psychology) -\nAstraphobia -\nAttachment theory -\nAttachment disorder -\nAttention -\nAttention-deficit hyperactivity disorder -\nAttention seeking -\nAttention span -\nAttitude (psychology) -\nAttribution (psychology) -\nAttribution theory -\nAttributional bias -\nAtypical depression -\nAuditory processing disorder -\nAudience effect -\nAura -\nAustralasian Society for Experimental Psychology -\nAustralian Psychological Society -\nAutassassinophilia -\nAuthoritarian personality -\nAuthority -\nAutism -\nAutism Diagnostic Observation Schedule -\nAutism spectrum -\nAutoassociative memory -\nAutodidacticism -\nAutomatic behavior -\nAvailability heuristic -\nAversion therapy -\nAversives -\nAvoidant personality disorder -\nAvolition -\nAwareness\n\nBackward inhibition -\nBaragnosis -\nBarnes Akathisia Scale -\nBarnes maze -\nBeck's cognitive triad -\nBehavior -\nBehavior modification -\nBehavior modification facility -\nBehavioral communication -\nBehavioral economics -\nBehavioral engineering -\nBehavioral medicine -\nBehavioral neurology -\nBehavioral neuroscience -\nBehavioral theories of depression -\nBehaviorism -\nBehaviour therapy -\nBehavioural despair test -\nBehavioural genetics -\nBehavioural sciences -\nBelief -\nBelongingness -\nBeyond the Pleasure Principle -\nBias disorder -\nBibliomania -\nBicameralism (psychology) -\nBidirectional associative memory -\nBinge drinking -\nBinge eating -\nBiodata -\nBioenergetic analysis -\nBiofeedback -\nBiological psychology -\nBipolar disorder -\nBipolar I disorder -\nBipolar II disorder -\nBlame -\nBlock design test -\nBlood-injection-injury type phobia -\nBlunted affect -\nBoanthropy -\nBody dysmorphic disorder -\nBody image -\nBody language -\nBody psychotherapy -\nBoldness -\nBorderline intellectual functioning -\nBorderline personality disorder -\nBorromean clinic -\nBouma -\nBradykinesia -\nBrainstorming -\nBreathwork -\nBrief psychotherapy -\nBrief reactive psychosis -\nBritish Journal of Social Psychology -\nBritish Psychological Society -\nBulimia nervosa -\nBullying -\nBurn Syndrome -\nBurnout (psychology) -\nBystander effect\n\nCalifornia Psychological Inventory -\nCalifornia School of Professional Psychology -\nCanadian Psychological Association -\nCannon-Bard theory -\nCare perspective -\nCassandra (metaphor) -\nCastration anxiety -\nCatalepsy -\nCatastrophization -\nCatatonia -\nCatatonic schizophrenia -\nCatharsis -\nCathexis -\nCenter for Evolutionary Psychology -\nCentration -\nChaining -\nCharacter orientation -\nCharacter structure -\nCharisma -\nCheating -\nChemical imbalance -\nChild (archetype) -\nChild abuse -\nChild and Adolescent Mental Health Services -\nChild development -\nChild directed speech -\nChild sexual abuse -\nChildhood disintegrative disorder -\nChinese Classification of Mental Disorders -\nChronophilia -\nChunking (psychology) -\nCibophobia -\nCinderella complex -\nCinderella effect -\nCircadian rhythm -\nCircadian rhythm sleep disorder -\nCircumstantiality -\nClanging -\nClassical Adlerian psychology -\nClassical Adlerian psychotherapy -\nClassical conditioning -\nClaustrophobia -\nClinical psychology -\nClique -\nClosure (psychology) -\nCodependency -\nCognition -\nCognitive behavioral therapy -\nCognitive bias -\nCognitive development -\nCognitive dimensions of notations -\nCognitive disorder -\nCognitive dissonance -\nCognitive distortion -\nCognitive elite -\nCognitive interventions -\nCognitive load -\nCognitive map -\nCognitive neuropsychology -\nCognitive psychology -\nCognitive restructuring -\nCognitive revolution -\nCognitive science -\nCognitive shift -\nCognitive slippage -\nCognitive space -\nCognitive specialization -\nCognitive style -\nCognitive test -\nCognitive therapy -\nCognitivism (psychology) -\nCohort effect -\nCollective consciousness -\nCollective identity -\nCollective intelligence -\nCollective unconscious -\nColor agnosia -\nColor psychology -\nCombat stress reaction -\nCommunication disorder -\nCommunication sciences -\nCommunity mental health service -\nCommunity psychology -\nComorbidity -\nComparative psychology -\nCompensation (psychology) -\nCompersion -\nComplex (psychology) -\nComplex post-traumatic stress disorder -\nCompliance (psychology) -\nCompulsive behavior -\nComputational theory of mind -\nConation -\nConceptual blending -\nConcrete operational stage -\nConcurrent validity -\nConditioning, operant -\nConduct disorder -\nConfabulation -\nConfidence -\nConfirmation bias -\nConformity -\nCongenital disorder -\nConscientiousness -\nConsciousness -\nConservation (psychology) -\nContact hypothesis -\nContent validity -\nContinuous reinforcement -\nControl freak -\nControl theory -\nConvergent and divergent production -\nConvergent thinking -\nConversion disorder -\nCoordination disorder, developmental -\nCoping (psychology) -\nCoping skill -\nCoprophilia -\nCotard delusion -\nCoulrophobia -\nCounseling psychology -\nCountersignaling -\nCreative problem solving -\nCreativity -\nCriminal psychology -\nCritical period -\nCritical psychology -\nCritical thinking -\nCriticism -\nCross-sectional study -\nCrowd manipulation -\nCrowd psychology -\nCryptomnesia -\nCue-dependent forgetting -\nCultivation theory -\nCultural dimensions -\nCultural identity -\nCultural psychology -\nCulture shock -\nCuriosity -\nCyberpsychology -\nCyclopean image -\nCyclothymia\n\nDa Costa's syndrome -\nDaydream -\nDead inside (concept) -\nDeath drive -\nDecay theory -\nDeception -\nDecision theory -\nDeclarative learning -\nDeclarative memory -\nDeconstruction therapy -\nDeep trance identification -\nDefence mechanism -\nDeindividuation -\nDeinstitutionalisation -\nDéjà vu -\nDelay reduction hypothesis -\nDelayed sleep phase syndrome -\nDelirium -\nDelusion -\nDelusion and Dream in Jensen's Gradiva -\nDelusional disorder -\nDemand (psychoanalysis) -\nDemand characteristics -\nDementia -\nDementia praecox -\nDenial -\nDental fear -\nDependency need -\nDependent personality disorder -\nDepersonalization -\nDepersonalization disorder -\nDepressive Disorder Not Otherwise Specified -\nDepressive personality disorder -\nDepressive position -\nDepressive realism -\nDepth psychology -\nDerealization -\nDereistic thinking -\nDermatillomania -\nDesensitization (psychology) -\nDesign thinking -\nDesignated patient -\nDesire (psychoanalysis) -\nDestrudo -\ndetachment (philosophy) -\nDetection theory -\nDeterrence (psychology) -\nDevaluation -\nDevelopmental coordination disorder -\nDevelopmental disorder -\nDevelopmental lines -\nDevelopmental profile -\nDevelopmental psychology -\nDevelopmental stage theories -\nDiagnostic and Statistical Manual of Mental Disorders -\nDialectical behavior therapy -\nDialogical self -\nDiathesis–stress model -\nDichotic listening -\nDifferential psychology -\nDiogenes syndrome -\nDipsomania -\nDisappointment -\nDiscrimination -\nDiscursive psychology -\nDisinhibited attachment disorder -\nDisinhibition -\nDisintegrative disorder -\nDisorder of written expression -\nDisorganized schizophrenia -\nDisplacement (psychology) -\nDispositionist -\nDissocial personality disorder  -\nDissociation -\nDissociative amnesia -\nDissociative disorder -\nDissociative fugue -\nDissociative identity disorder -\nDistancing language -\nDistressed personality type -\nDistributed cognition -\nDistrust -\nDivergent thinking -\nDoctor of Psychology -\nDominance and submission -\nDoor-in-the-face technique -\nDouble bind -\nDouble depression -\nDream -\nDream dictionary -\nDream interpretation -\nDream journal -\nDream transference -\nDrive Theory -\nDSM-5 -\nDual-coding theory -\nDual diagnosis -\nDump job -\nDynamicism -\nDysarthria -\nDyscalculia -\nDysfunctional family -\nDysgraphia -\nDyskinesia -\nDyslexia -\nDyspareunia -\nDysphonia -\nDysphoria -\nDyssomnia -\nDysthymia\n\nEarly childhood education -\nEarly intervention in psychosis -\nEating disorder -\nEcholalia -\nEchopraxia -\nEcological psychology -\nEcopsychology -\nEducational organization -\nEducational psychology -\nEdwards Personal Preference Schedule -\nEgo -\nEgo ideal -\nEgo psychology -\nEgo reduction -\nEgocentric predicament -\nEgocentrism -\nEgodystonic -\nEgo-dystonic sexual orientation -\nEgomania -\nEgosyntonic -\nElective mutism -\nElectra complex -\nElectroencephalography -\nEMDR Institute -\nEmetophobia -\nEmotion -\nEmotion and memory -\nEmotional age -\nEmotional blackmail -\nEmotional conflict -\nEmotional contagion -\nEmotional dysregulation -\nEmotional expression -\nEmotional insecurity -\nEmotional intelligence -\nEmotional isolation -\nEmotional labor -\nEmotional reasoning -\nEmpathic distress -\nEmpathy -\nEmpathy gap -\nEmptiness -\nEmpty-chair technique -\nEncoding (memory) -\nEncopresis -\nEncounter group -\nEndogenous depression -\nEndogeny -\nEnergy psychology -\nENFJ -\nENFP -\nEngram -\nEntitlement -\nENTJ -\nEntomophobia -\nENTP -\nEnuresis -\nEnvironmental psychology -\nEnvy -\nEpiphany (feeling) -\nEquity theory -\nErgophobia -\nErikson's stages of psychosocial development -\nErotomania -\nErotophobia -\nErythrophobia -\nESFJ -\nESFP -\nESTJ -\nESTP -\nEthics and evolutionary psychology -\nEuphoria -\nEuropean Association for Psychotherapy -\nEvaluation -\nEvolutionary developmental psychology -\nEvolutionary educational psychology -\nEvolutionary Principle -\nEvolutionary psychology -\nExaggeration -\nExclusivism -\nExecutive functions -\nExhibitionism -\nExistential therapy -\nExogeny -\nExorcism -\nExperimental group -\nExperimental method -\nExperimental neurosis -\nExperimental psychology -\nExperimental Psychology Society -\nExperimenter's bias -\nExplanation -\nExplicit memory -\nExposure and response prevention -\nExpressed emotion -\nExpressive language disorder -\nExternal validity -\nExtraversion and introversion -\nEysenck Personality Questionnaire\n\nF-scale -\nFace-ism -\nFace perception -\nFace validity -\nFacial expression -\nFactitious disorder -\nFactorial ANOVA -\nFaculty psychology -\nFalse awakening -\nFamily therapy -\nFantasy (psychology) -\nFast mapping -\nFear -\nFear of flying -\nFeature integration theory -\nFeeble-minded -\nFeedback loop -\nFeelings -\nFemale sexual arousal disorder -\nFemininity -\nFeral child -\nFetal alcohol syndrome -\n\"The Fifth Discipline\" -\nFight-or-flight response -\nFixation (psychology) -\nFlashback (psychology) -\nFlashbulb memory -\nFlattery -\nFlooding (psychology) -\nFlow (psychology) -\nFlowerpot technique -\nFluid and crystallized intelligence -\nFolie à deux -\nFolk psychology -\nFooled by Randomness -\nFoolishness -\nFoot-in-the-door technique -\nForensic psychology -\nForgiveness -\nFormal operational stage -\nFormication -\nFormicophilia -\nFoundations of Cyclopean Perception -\nFour discourses -\nFour stages of competence -\nFragile X syndrome -\nFree association (psychology) -\nFree-floating anxiety -\nFree-running sleep -\nFrigidity -\nFrustration -\nFugue -\nFunctional autonomy -\nFunctional disorder -\nFunctional psychology -\nFunctional symptom -\nFundamental attribution error -\nFundamental Interpersonal Relations Orientation\n\nGanser syndrome -\nGaze -\nGender identity -\nGender identity disorder -\nGender narcissism -\nGender role -\nGeneral adaptation syndrome -\nGeneral intelligence factor -\nGeneralized anxiety disorder -\nGenetic predisposition -\nGenie (feral child) -\nGenital stage -\nGenophobia -\nGeon (psychology) -\nGermaphobia -\nGeschwind–Galaburda hypothesis -\nGestalt psychology -\nGestalt theoretical psychotherapy -\nGestalt therapy -\nGlobal aphasia -\nGlossophobia -\nGnosology -\nGod helmet -\nGrand mal epilepsy -\nGrandiose delusions -\nGrandiosity -\nGratification -\nGratitude -\nGraz School -\nGreed -\nGregariousness -\nGrief -\nGrounding (punishment) -\nGroup attribution error -\nGroup Dynamics (Myers-Briggs) -\nGroup dynamics -\nGroup intelligence -\nGroup polarization -\nGroup psychotherapy -\nGroup-serving bias -\nGroup synergy -\nGroupthink -\nGuilt -\nGuilty but mentally ill -\nGustation -\nGymnophobia -\nGyrus\n\nHabit (psychology) -\nHabituation -\nHair pulling -\nHakomi -\nHallucination -\nHallucinosis -\nHalo effect -\nHamilton Depression Rating Scale -\nHawthorne effect -\nHealing temple -\nHealth and Human Services -\nHealth psychology -\nHedonism -\nHeffter Research Institute -\nHeliophobia -\nHemophobia -\nHerpetophobia -\nHidden observer -\nHierarchy of needs -\nHigh IQ society -\nHighway hypnosis -\nHistory of psychology -\nHistrionic personality disorder -\nHolland Codes -\nHomophobia -\nHomosexual panic -\nHomosexuality -\nHopfield net -\nHost (psychology) -\nHostility -\nHow the Mind Works -\nHubris -\nHuman behavior -\nHuman bonding -\nHuman computer interaction -\nHuman Givens -\nHumanistic psychology -\nHumiliation -\nHwa-Byung -\nHydrophobia -\nHydrotherapy -\nHyperactivity -\nHyperactivity disorder -\nHypergraphia -\nHypergyny -\nHyperkinetic disorder -\nHypermasculinity -\nHyperprosexia -\nHyperreflexia -\nHypersomnia -\nHypertension -\nHypertensive crisis -\nHyperthymesia -\nHyperventilation -\nHypesthesia -\nHypnopompic -\nHypnotherapy -\nHypnotic -\nHypoactive sexual desire disorder -\nHypochondriasis -\nHypomania -\nHypomanic episode -\nHysterical neurosis -\nHysteria\n\nIatrogenic illness -\nICD-10 -\nICD-9 -\nId, ego, and super-ego -\nIdea -\nIdealization and devaluation -\nIdeas bank -\nIdeas of reference -\nIdeasthesia -\nIdeation -\nIdentification (information) -\nIdentity crisis (psychology) -\nIdeomotor effect -\nIdiot savant -\nIdiothetic -\nImage schema -\nImagination -\nImitation -\nImmediate memory -\nImplementation intention -\nImpotence -\nImpregnation fetish -\nImprinting (psychology) -\nImpulse (psychology) -\nImpulse control disorder -\nIncentive salience -\nIncest -\nIncest taboo -\nIncompetent to stand trial -\nIndirect realism -\nIndividual differences psychology -\nIndividual psychology -\nIndividuation -\nInductive reasoning -\nIndustrial and organizational psychology -\nparaphilic infantilism -\nInfantophilia -\nInference -\nInferiority complex -\nINFJ -\nInformed consent -\nINFP -\nInfradian rhythm -\nInheritance of intelligence -\nInhibited male orgasm -\nInhibited orgasm -\nSocial inhibition -\nInnate -\nInnate ideas -\nInner child -\nInnocence -\nInquiry -\nInsanity -\nInsanity defense -\nInsight -\nInsomnia -\nInstinct -\nInstitute for Collaborative Engagement -\nInstitute of Transpersonal Psychology -\nInstitutionalization -\nInstrumental conditioning -\nInsult -\nIntellectual disability -\nIntegral psychology -\nIntegral theory -\nIntegrative complexity -\nIntellectualization -\nIntelligence (trait) -\nIntelligence amplification -\nIntelligence quotient -\nIntelligence test -\nInteraction effects -\nInterference theory -\nIntergender -\nIntermittent explosive disorder -\nInternal capsule -\nInternal consistency -\nInternal locus of control -\nInternalized oppression -\nInternational Association of Analytical Psychologists -\nInternational Classification of Diseases -\nInternational Society for Comparative Psychology -\nInterpersonal and social rhythm therapy -\nInterpersonal psychoanalysis -\nInterpersonal psychotherapy -\nInterpersonal skills -\nInter-rater reliability -\nInterstimulus interval -\nIntertwingularity -\nIntervention (counseling) -\nInterview -\nIntimacy -\nIntimate relationship -\nINTJ -\nINTP -\nIntrapsychic -\nIntravenous -\nIntrinsic motivation -\nIntrojection -\nIntromission -\nIntrospection -\nIntroversion -\nIntuition (knowledge) -\nInvoluntary commitment -\nInvolutional melancholia -\nIQ -\nIronic process theory -\nIrrational anger -\nIrresistible impulse -\nISFJ -\nISFP -\nIsolation -\nISTJ -\nISTP (personality type)\n\nJealousy -\nJenkins activity survey -\nJohari window -\nJoint Commission on Accreditation of Healthcare Organizations -\nJournal of Applied Developmental Psychology -\nJournal of Health Psychology -\nJournal of Psychohistory -\nJudgement -\nJungian psychology -\nJust-world phenomenon\n\nKeirsey Temperament Sorter -\nKharkov School of Psychology -\nKinesics -\nKinesthesis -\nKlein-Levin syndrome -\nKleptomania -\nKlinefelter syndrome -\nKlismaphilia -\nKlüver-Bucy syndrome -\nKübler-Ross model -\nKnowledge management -\nKohlberg's stages of moral development\n\nL-dopa -\nLabeling theory -\nLabile -\nLability -\nLaboratory for Automation Psychology -\nLaceration -\nLacrimation -\nLacunar amnesia -\nLandolt ring -\nLanguage acquisition device -\nLanguage disorder -\nLapsus -\nLapsus linguae -\nLarge Group Awareness Training -\nLarge-group communication -\nLatah -\nChild sexuality#Middle childhood -\nLatency period -\nLatency stage -\nLatent learning -\nLateral thinking -\nLaw of effect -\nLeadership -\nLearned helplessness -\nLearning -\nLearning curve -\nLearning disabilities -\nLearning disability -\nLearning disorders -\nLearning organization -\nLearning theory (education) -\nLegal psychology -\nLethologica -\nLevels-of-processing effect -\nLiberation psychology -\nLibido -\nLie -\nLifespring -\nLifetime prevalence -\nLight therapy -\nLigyrophobia -\nList of cognitive biases -\nList of credentials in psychology -\nList of emotions -\nList of psychologists -\nList of psychology disciplines -\nList of psychology journals -\nList of psychology organizations -\nList of psychological research methods -\nList of important publications in psychology -\nList of scientific journals in psychology -\nLüscher color test -\nLocus of control -\nLoevinger's stages of ego development -\nLogorrhea (psychology) -\nLogotherapy -\nLogovisual technology -\nLoner -\nLongitudinal study -\nLooking glass self -\nLoose associations -\nLoss aversion -\nLovaas technique -\nLove styles -\nLovemap -\nLow frustration tolerance -\nLucid dream -\n\nMacDonald triad -\nMachiavellianism -\nMadonna-whore complex -\nMagical thinking -\nMain effect -\nMajor depression -\nMajor depressive disorder -\nMaking excuses -\nMaladaptive daydreaming -\nMalignant narcissism -\nMalingering -\nMan and His Symbols -\nMania -\nManic-depressive illness -\nManic episode -\nManipulation -\nMarital therapy -\nMarriage guidance -\nMartyr complex -\nMasculine psychology -\nMasking (personality) -\nMaslow's hierarchy of needs -\nMasochistic personality disorder -\nMass hysteria -\nMaternal deprivation -\nMathematical psychology -\nMathematics disorder -\nMaturation and environmentalism -\nMcLean Hospital -\nMean World Syndrome -\nMeasure of central tendency -\nMedical model -\nMedical psychology -\nMegalomania -\nMelancholia -\nMemory-prediction framework -\nMemory and aging -\nMemory augmentation -\nMemory consolidation -\nMemory effect -\nMemory inhibition -\nMemory suppression -\nMental age -\nMental block -\nMental calculation -\nMental confusion -\nMental disorder -\nMental function -\nMental health -\nMental health consumer -\nMental health disorders -\nMental illness -\nMental management -\nMental model -\nMental status -\nMental status examination -\nMentalism (psychology) -\nMentally ill -\nMentoring -\nMesmerism -\nMesomorphic -\nMessiah complex -\nMetabolism -\nMetabolite -\nMetacognition (thinking about thinking) -\nMetaknowledge (knowledge about knowledge) -\nMetapsychology -\nMicroexpression -\nMid-life crisis -\nMiddle age -\nMilgram experiment -\nMilieu therapy -\nMind's eye -\nMind-body dualism -\nMind-body problem -\nMind control -\nMind Dynamics -\nMind map -\nMindfulness (psychology) -\nMindset -\nMinimisation (psychology) -\nMinnesota Multiphasic Personality Inventory -\nMirror stage -\nMixed anxiety-depressive disorder -\nMixed state (psychiatry) -\nMMPI-2 -\nMnemonics -\nMnemonic link system -\nMnemonist -\nMob psychology -\nModel (abstract) -\nModel of hierarchical complexity -\nConceptual model -\nModelling (psychology) -\nMonomania -\nMood (psychology) -\nMood disorder -\nMood swing -\nMoral psychology -\nMoral reasoning -\nMoral treatment -\nMorbid jealousy -\nMoron (psychology) -\nMortido -\nMotion illusion -\nMotivation -\nMotor coordination -\nMotor skills disorder -\nMozart Effect -\nMovement context in handwriting -\nMultidisciplinary Association for Psychedelic Studies -\nMulti-infarct dementia -\nMultilevel model -\nMultilevel models\nMultisensory integration -\nMultimodal Therapy -\nMultimodal therapy -\nMultiple-complex Developmental Disorder -\nMultiple personality disorder -\nHuman multitasking -\nMultnomah Community Ability Scale -\nMünchausen syndrome -\nMünchausen syndrome by proxy -\nMusic psychology -\nMutism -\nMyers-Briggs Type Indicator -\nMysophilia -\nMysophobia -\nMythomania\n\nN-Affil -\nN-Pow -\nNapoleon complex -\nNarcissism -\nNarcissism of small differences -\nNarcissistic parent -\nNarcissistic personality disorder -\nNarcissistic rage -\nNarcosynthesis -\nNarrative therapy  -\nNaturalistic observation -\nNecrophobia -\nNeed -\nNegative reinforcement -\nNegative symptoms -\nNegativistic personality disorder -\nNeglect -\nNeo-Freudian -\nNeo-Piagetian theories of cognitive development -\nNeophobia -\nNeuro-linguistic programming -\nNeurocognition -\nNeurofeedback -\nNeurological disorder -\nNeuropsychological test -\nNeuropsychology -\nNeuroscience -\nNeurosis -\nNeurosyphilis -\nNeuroticism Extraversion Openness Personality Inventory -\nNight owl (person) -\nNightmare -\nNightmare disorder -\nNoetic Psychology -\nNonparametric test -\nNonverbal communication\nNonviolent self defense -\nNorm (sociology) -\nNT (temperament) -\nNurturant parent model -\nNurture -\nNyctophobia -\nNymphophilia -\n\nObject permanence -\nObjective test -\nObservational learning -\nObsessive-compulsive disorder -\nObsessive-compulsive personality disorder -\nObsessive Relational Intrusion (ORI) -\nOccupational health psychology -\nOccupational psychology -\nOccupational psychosis -\nOccupational therapy -\nOctave illusion -\nOedipus complex -\nOne-upmanship -\nOpen relationship -\nOperant behavior -\nOperant conditioning -\nOperations research -\nOpponent-process theory -\nOpportunism -\nOppositional defiant disorder -\nOptimal distinctiveness theory -\nOral stage -\nOrdinal numerical competence -\nOrganizational citizenship behavior -\nOrganizational communication -\nOrganizational psychology -\nOrgone -\nOrientation (mental) -\nOrnithophobia -\nOsmophobia -\nOverjustification effect -\nOverlearning\n\nPain and pleasure -\nPain disorder -\nPair by association -\nPairwise comparison -\nPalilalia -\nPanic attack -\nPanic disorder -\nPapert's principle -\nParadoxical intention -\nParallel play -\nParanoia -\nParanoid-schizoid position -\nParanoid disorder -\nParanoid personality disorder -\nParanoid schizophrenia -\nParaphilia -\nParaphrenia -\nParapsychology -\nParaskevidekatriaphobia -\nParasuicide -\nParenting (Myers-Briggs) -\nParesthesia -\nParosmia -\nPassion (emotion) -\nPassive–aggressive behavior -\nPassword psychology -\nPastoral counseling -\nPathogenic theory of schizophrenia -\nPathognomy -\nPathological gambling -\nPathological lying -\nPatience -\nPDD not otherwise specified -\nPedophile -\nPedophilia -\nPenis envy -\nPeople skills -\nPerception -\nPerceptual psychology -\nPerfectionism (psychology) -\nPerformance anxiety -\nPerformance psychology -\nPersecution complex -\nPersecutory delusions -\nPerson centered planning -\nPerson-centered therapy -\nPersonal boundaries -\nPersonal commitment -\nPersonal construct psychology -\nPersonal construct theory -\nPersonality alteration -\nPersonality Assessment Inventory -\nPersonality disorder -\nPersonality psychology -\nPersonality tests -\nPersonality trait -\nPerspective (cognitive) -\nPersuasion -\nPervasive developmental disorders -\nPhagophobia -\nPhallic stage -\nPhantom rings -\nPhenomenology (psychology) -\nPhenotype -\nPhenotypic trait -\nPhilippine psychology -\nPhilomath -\nPhilosophy of mind -\nPhilosophy of psychology -\nPhobia -\nPhonological disorder -\nPhonology -\nPhotopic vision -\nPhrenology -\nPhysiological psychology -\nPiaget's theory of cognitive development -\nPick's disease -\nPicture thinking -\nPillow talk -\nPituitary gland -\nPiquerism -\nPlacebo effect -\nPlanning -\nPlateau phase -\nPlatykurtic -\nPlay therapy -\nPleasure principle (psychology) -\nPoker psychology -\nPolarization (psychology) -\nPolitical psychology -\nPopular psychology -\nPositive Mental Attitude -\nPositive psychology -\nPositive reinforcement -\nPost-cognitivist psychology -\nPost-purchase rationalization -\nPost-traumatic embitterment disorder -\nPost-traumatic stress disorder -\nPostcognitivism -\nPostvention -\nPotential development level -\nPoverty of speech -\nPower (sociology) -\nPower Law of Practice -\nPractical equine psychology -\nPrairie madness -\nPraise -\nPre- and perinatal psychology -\nPreconscious -\nPrediction -\nPredictive validity -\nPrejudice -\nPremature ejaculation -\nPremenstrual dysphoric disorder -\nPreoperational stage -\nPrescriptions regarding gender roles -\nPresenile dementia -\nPrimacy effect -\nPrimal therapy -\nThe Principles of Psychology -\nPrivileged communication -\nProactive inhibition -\nProactivity\nProactive interference -\nProbability of error -\nProbands -\nProblem-based learning -\nProblem finding -\nProblem shaping -\nProblem solving -\nProcess Oriented Psychology -\nProcess Psychology -\nProcrastination -\nProdrome -\nProfessional practice of behavior analysis -\nProgram evaluation -\nProgrammed learning -\nPsychiatrist -\nPsychological projection -\nPsychological trauma -\nProjective identification -\nProjective test -\nPronoia (psychology) -\nPronoun reversal -\nProperception -\nPropinquity -\nProposition -\nPropositional attitude -\nProsopagnosia -\nProspect theory  -\nProspection -\nProtoself -\nProxemics -\nPrudence -\nPseudocertainty effect -\nPseudologia -\nPsychiatric hospital -\nPsychopathy -\nPunitive psychiatry in the Soviet Union -\nPsyche (psychology) -\nPsychedelic -\nPsychic driving -\nPsychoacoustics -\nPsychoactive -\nPsychoactive drug -\nPsychoanalysis -\nPsychoanalyst -\nPsychoanalytic feminism -\nPsychoanalytic theory -\nPsychoanalytic film theory -\nPsychobiography -\nPsychodrama -\nPsychodynamic theory -\nPsychodynamic therapy -\nPsychodynamics -\nPsychogenesis -\nPsychogenic amnesia -\nPsychogenic pain -\nPsychogenic polydipsia -\nPsychogram -\nPsychohistory -\nPsycholinguist -\nPsycholinguistics -\nPsychological abuse -\nPsychological adaptation -\nPsychological assessment -\nPsychological dependency -\nPsychological identity -\nPsychological manipulation -\nPsychological pain -\nPsychological repression -\nPsychological research methods -\nResearch methods -\nPsychological resilience -\nPsychological Review -\nPsychological statistics -\nPsychological testing -\nPsychological tests -\nPsychological types -\nPsychology of combat -\nPsychology of learning -\nPsychology of Monogamy -\nPsychology of previous investment -\nPsychology of programming -\nPsychology of religion -\nPsychology of reasoning -\nPsychology Today -\nPsychology, Philosophy and Physiology -\nPsychometrics -\nPsychomotor agitation -\nPsychomotor retardation -\nPsychonomics -\nPsychoneuroimmunology -\nPsychoorganic syndrome -\nPsychopathology -\nPsychopharmacology -\nPsychophysics -\nPsychophysiology -\nPsychosexual stages -\nPsychosis -\nPsychosomatic disorders -\nPsychotherapeutic Postural Integration -\nPsychotherapy -\nPsychotic depression -\nPsychotropic medication -\nPsycINFO -\nPuer Aeternus -\nPunishment\n\nQuantitative psychological research -\nQuantitative psychology -\nQuantitative trait locus -\nQuantum Psychology\n\nRadical behaviorism -\nRadical Psychology Network -\nRadiophobia -\nRage (emotion) -\nRandom assignment -\nRape trauma syndrome -\nRapport -\nRapport congruency -\nRashomon effect -\nRational-emotive therapy -\nRational choice theory -\nRational emotive therapy -\nRationality -\nRationalization (psychology) -\nRaynaud's disease -\nRe-evaluation Counseling -\nReachback -\nReactance (psychology) -\nReaction formation -\nReactive attachment disorder -\nReactivity (psychology) -\nReading (activity) -\nRelational aggression -\nRelational disorder -\nReality distortion field -\nReality principle -\nReasoning -\nReciprocal liking -\nReciprocity (social psychology) -\nRecklessness (psychology) -\nRecluse -\nRecollection -\nRecovery International -\nRecurring dream -\nReferent power -\nReframing -\nRegression -\nRegression analysis -\nRegulatory Focus Theory -\nRehabilitation (neuropsychology) -\nRehabilitation counseling -\nReinforcement -\nReinforcer -\nRejection (emotion) -\nRelational frame theory -\nRelationship counseling -\nRelationships (Myers-Briggs) -\nReligious instinct -\nReligious trauma syndrome -\nReminiscence -\nRemorse -\nRenfield's syndrome -\nRepetition compulsion -\nRepresentations -\nRepresentativeness heuristic -\nRepression -\nRescorla-Wagner model -\nResentment -\nResidual schizophrenia -\nResistance (psychology) -\nRespondent conditioning -\nRetroactive inhibition -\nRetroactive interference -\nRetrograde amnesia -\nRetrospective memory -\nReuptake -\nReverse learning -\nReverse psychology -\nRhetoric -\nRighteous indignation -\nRisky shift -\nRitualization -\nRole-playing -\nRole reversal -\nRole theory -\nRorschach inkblot test -\nRosenthal effect -\nRotter Incomplete Sentence Blank -\nRousseau Institute -\n\nSadistic personality disorder -\nSadomasochism -\nSafety in numbers -\nSander illusion -\nSapience -\nScale (social sciences) -\nSchadenfreude -\nSchedules of reinforcement -\nSchema (psychology) -\nSchizoaffective disorder -\nSchizoid personality disorder -\nSchizophrenia -\nSchizophrenics Anonymous -\nSchizophreniform disorder -\nSchizotypal personality disorder -\nScholastic Aptitude Test -\nSchool phobia -\nSchool refusal -\nScience and Consciousness Review -\nScientific control -\nSeasonal affective disorder -\nSecondary gain -\nSecurity blanket -\nSelective abstraction -\nSelective distortion -\nSelf-actualization -\nSelf-awareness -\nSelf-concept -\nSelf-consciousness -\nSelf-criticism -\nSelf-deception -\nSelf-defeating personality disorder -\nSelf-determination theory -\nSelf-disclosure -\nSelf-efficacy -\nSelf-esteem -\nSelf-esteem functions -\nSelf-help -\nSelf-injury -\nSelf-knowledge -\nSelf-loathing -\nSelf-monitoring -\nSelf-parenting -\nSelf-perception theory -\nSelf-pity -\nSelf-punishment -\nSelf-realization -\nSelf-regulated learning -\nSelf (Jung) -\nSelf (psychology) -\nSelf actualization -\nSelf control -\nSelf efficacy -\nSelf-esteem -\nSelf handicapping -\nSelf propaganda -\nSelf psychology -\nSelf serving bias -\nSelfishness -\nSemantic dementia -\nSemantic dyslexia -\nSemantic memory -\nSemantics -\nSenile dementia -\nSenile plaques -\nSensation (psychology) -\nSense of time -\nSensitivity (human) -\nSensory adaptation -\nSensory gating -\nSensory memory -\nSensory neuroscience -\nSensory preconditioning -\nSensory threshold -\nSentience -\nSeparation anxiety disorder -\nSerial position effect -\nSerial sevens -\nSex-reassignment surgery -\nSexual arousal disorders -\nSexual arousal -\nSexual aversion disorder -\nSexual desire -\nSexual deviation -\nSexual disorders -\nSexual dysfunction -\nSexual fetishism -\nSexual masochism -\nSexual orientation -\nSexual response cycle -\nSexual sadism -\nhuman sexuality -\nShadow (psychology) -\nShame -\nShaping (psychology) -\nShell shock -\nShock value -\nShort term memory -\nShyness -\nSibling -\nSiege mentality -\nSigmund Freud Archives -\nSilva Method -\nSimilarity (psychology) -\nSimon effect -\nSimplicity theory -\nSimulated consciousness -\nSimulated pregnancy -\nSimulation heuristic -\nSitophobia -\nSituational awareness -\nSix Thinking Hats -\nSize-weight illusion -\nSkinner box -\nSleep-learning -\nSluggish cognitive tempo -\nSluggishly progressing schizophrenia -\nSmart mob -\nSocial anxiety -\nSocial anxiety disorder -\nSocial cognition -\nSocial desirability -\nSocial disruption -\nSocial distance -\nSocial distance scale -\nSocial facilitation -\nSocial group -\nSocial influence -\nSocial inhibition -\nSocial interaction -\nSocial learning theory -\nSocial loafing -\nSocial neuroscience -\nSocial norm -\nSocial proof -\nSocial psychology (psychology) -\nSocial psychology (sociology) -\nSocial rejection -\nSocial rhythm therapy -\nSocial role -\nSocial skills -\nSocial statistics -\nSocial status -\nSocial stigma -\nSocial support -\nSocialization -\nSociety of Mind theory -\nSocioeconomic status -\nSociometry -\nSocionics -\nSociosexual orientation -\nSodomy -\nSolitary confinement -\nSoma -\nSomatization disorder -\nSomatoform disorder -\nSomatotherapy -\nSomatotype and constitutional psychology -\nSpatial empathy -\nSpatial memory -\nSpatial-temporal reasoning -\nSpeaker recognition -\nSpecific phobia -\nSpecific social phobia -\nSpeech act -\nSpeech perception -\nSpeed reading -\nSpiral dynamics -\nsplitting (psychology) -\nSpontaneous recovery -\nSport psychology -\nStage fright -\nStage theory -\nStages of faith development -\nStanford-Binet -\nState-dependent learning -\nState-dependent memory -\nSteppingstone theory -\nStereotypes -\nStereotypic movement disorder -\nStigmatic/eligibilic paraphilia -\nStimming -\nStimulus generalization -\nStir crazy (condition) -\nStockholm syndrome -\nStorage (memory) -\nStrategic planning -\nStream of consciousness (psychology) -\nStress (medicine) -\nStress management -\nStressor -\nStructural communication -\nStructural ritualization theory -\nStructuralism -\nStructure-agency debate -\nStructured interview -\nStudy Skills -\nSubjective reality -\nSublimation (psychology) -\nSubliminal advertising -\nSubliminal perception -\nSubmission -\nSubstance-related disorder -\nSubstance abuse -\nSubstance Abuse and Mental Health Services Administration -\nSubstance dependence -\nSubstance intoxication -\nSubstance-related disorder -\nSubvocalization -\nSuffering -\nSuicidal ideation -\nSuicide -\nSuicide treatment -\nSuicide watch -\nSuicidology -\nSuperego -\nSuperficial charm -\nSuperiority complex -\nSuperman complex -\nSuperordinate goals -\nSurprise (emotion) -\nSwept-plane display -\nSycophancy -\nSyllogism -\nSylvia Plath effect -\nSymbolic violence -\nSympathy -\nSympathetic nervous system -\nSynesthesia -\nSynectics -\nSystematic desensitization -\nSystems psychology -\nSystems intelligence -\nSystems thinking\n\nT-groups -\nT test -\nT.O.T.E. -\nTaboo -\nTactile -\nTaijin kyofusho -\nTalking cure -\nTaphophobia -\nTarget fixation -\nTaunting -\nThematic Apperception Test -\nTechnophobia -\nTelepathy -\nTemperament -\nTerdekaphobia -\nTernus illusion -\nTest (assessment) -\nTest-retest reliability -\nTexas State Board of Examiners of Psychologists -\nThalamus -\nThe Blank Slate -\n -\nThe Imaginary -\nThe Mean Reds -\nThe Real -\nThe Retreat -\nThe Social Animal -\nThe Symbolic -\nThe Third Wave -\nThe Wisdom of Crowds -\nWisdom of crowds -\nThematic Apperception Test -\nTheophylline -\nTheoretical psychology -\nTheory of Cognitive development -\nTheory of Constraints -\nTheory of Deadly Initials -\nTheory of mind -\nTheory of multiple intelligences -\nTherapeutic community -\nThinking -\nThinking Processes (Theory of Constraints) -\nThought-terminating cliché -\nThought -\nThought broadcasting -\nThought disorder -\nThought experiment -\nThought Field Therapy -\nThought insertion -\nThought withdrawal -\nThousand-yard stare -\nThree Essays on the Theory of Sexuality -\nTimeline of psychology -\nToilet training -\nToken economy -\nTonic–clonic seizure -\nTouch illusion -\nTourette syndrome -\nTraffic psychology -\nTrait theory -\nTransactional analysis -\nTransderivational search -\nTransduction (psychology) -\nTransfer (propaganda) -\nTransfer of learning -\nTransfer of training -\nTransference -\nTransference neurosis -\nTranspersonal -\nTranspersonal psychology -\nTranssexual -\nTranssexualism -\nTransvestic fetishism -\nPsychological trauma -\nTree of Knowledge System -\nTriarchic theory of intelligence -\nTriskaidekaphobia -\nTrisomy -\nTrollope ploy -\nTrue experiment -\nTrust (sociology) -\nTrust metric -\nTrypanophobia -\nTumescence -\nTwin study -\nType A and Type B personality theory\n\nUltradian -\nUnconditional positive regard -\nUnconditioned response -\nUnconditioned stimulus -\nUnconscious mind -\nUnderstanding -\nUndifferentiated schizophrenia -\nUnipolar depression -\nUnited Kingdom Council for Psychotherapy -\nUniversal law of generalization -\nUniversalization -\n\nValence (psychology) -\nValue (personal and cultural) -\nValue theory -\nVascular dementia -\nVegetotherapy -\nVertical thinking -\nVictim blaming -\nVictim playing -\nVictimisation -\nVictimology -\nVienna Psychoanalytic Society -\nVigilance (psychology) -\nVision-logic -\nVisual learning -\nVisual thinking -\nVolition (psychology) -\nVoodoo death -\nVoyeurism -\nVulnerability -\n\nWAIS-III -\nWakefulness -\nWaking states -\nWaxy flexibility -\nWeapon focus -\nWeb Experimental Psychology Lab -\nWechsler adult intelligence scale -\nWechsler Intelligence Scale for Children -\nWechsler Preschool and Primary Scale of Intelligence -\nWilliam Alanson White Institute -\nWise old man -\nWithdrawal symptoms -\nWitzelsucht -\nWomb envy -\nWord salad -\nWorking memory -\nWorking through -\nWorld Federation for Mental Health -\n\nXenophobia -\n\nYerkes-Dodson law -\nYoung adult (psychology) -\n\nZeitgeist -\nZener cards -\nZero-defects mentality\n\n"}
{"id": "4457515", "url": "https://en.wikipedia.org/wiki?curid=4457515", "title": "Kappa Epsilon", "text": "Kappa Epsilon\n\nKappa Epsilon (ΚΕ) is a professional pharmacy fraternity founded by Zada M. Cooper on May 13, 1921. It was founded with the purpose of uniting female pharmacy students in an era when women were a minority in the profession. Today, KE has 43 collegiate chapters and 10 alumni chapters. Over 20,000 women and men have been initiated into ΚΕ since its founding.\n\nKappa Epsilon's National Project is the promotion of breast cancer awareness. Many ΚΕ chapters participate in the Race for the Cure or Relay For Life. KE chapters are also encouraged to promote awareness of other women's health issues such as osteoporosis. KE's recently added the Pharmacy Career Opportunity Recruitment Project (Pharm-CORP) to their National Project. Pharm-CORP works to introduce pharmacy careers to middle and high school aged students and encourages them to excel in math and the sciences.\n\nKappa Epsilon sponsors one scholarship and one fellowship. The Zada Cooper Scholarship, named for the fraternity's founder, is given to five students every year. The Nellie Wakeman Fellowship is given to a member in his/her last year of pharmacy school who wishes to pursue graduate study. For both awards, the recipient must be a fraternity member in good standing.\n\nEvery two years, the fraternity holds a convention where national officers are elected and collegiate and alumni members can network.\n\nThe official colors of Kappa Epsilon are only Red and White.\n\n"}
{"id": "57744538", "url": "https://en.wikipedia.org/wiki?curid=57744538", "title": "Keystone virus", "text": "Keystone virus\n\nThe Keystone virus is a mosquito-borne virus which can infect mammals. It was first discovered in animals in the Florida area, where it is spread in part by local species of \"Aedes\" mosquitoes. In 1964, a case of human infection, producing minor symptoms of a rash and fever, was circumstantially diagnosed. Conclusive laboratory demonstration of the virus in humans was first obtained and reported in 2018.\n\nThe Keystone virus was first discovered in mosquitoes in the Keystone area of Tampa, Florida in 1964, based on antigenic evidence from specimens caught in 1963. The virus has been subsequently observed along the eastern and southern coastline of the United States, from Boston through Texas. In small mammals it can produce symptoms of encephalitis. Infection in humans is believed to be widespread, based on a 1972 report detecting Keystone virus antibodies in 19–21 percent of the people tested in the Tampa Bay region.\n\nThe first laboratory isolation of the virus from a human case occurred in Florida in 2016, and was reported in 2018. Identification took almost two years after the case actually occurred, when blood samples taken from the subject in 2016 were analyzed retrospectively by researchers studying the incidence of Zika virus in the Florida population.\n\nThe \"Aedes atlanticus\" mosquito is a demonstrated vector. The virus transmits transstadially through the different stages of the insect's life: A female mosquito may lay eggs carrying the virus, which hatch into infected larvae, eventually maturing into adults that can infect mammals while injecting their anti-coagulant saliva during a bite.\n"}
{"id": "2022488", "url": "https://en.wikipedia.org/wiki?curid=2022488", "title": "Krennerite", "text": "Krennerite\n\nKrennerite is an orthorhombic gold telluride mineral which can contain variable amounts of silver in the structure. The formula is AuTe varying to (Au,Ag)Te. Both of the chemically similar gold-silver tellurides, calaverite and sylvanite, are in the monoclinic crystal system, whereas krennerite is orthorhombic.\n\nThe color varies from silver-white to brass-yellow. It has a specific gravity of 8.62 and a hardness of 2.5. It occurs in high temperature, hydrothermal environments. \n\nKrennerite was discovered in 1878 near the village of Săcărâmb, Romania, and first described by the Hungarian mineralogist Joseph Krenner (1839–1920).\n\n\n"}
{"id": "39227870", "url": "https://en.wikipedia.org/wiki?curid=39227870", "title": "List of Bioacoustics Software", "text": "List of Bioacoustics Software\n\nHere is a listing of the most referenced bioacoustics software.\n\n\n"}
{"id": "37572635", "url": "https://en.wikipedia.org/wiki?curid=37572635", "title": "List of LIMS software packages", "text": "List of LIMS software packages\n\nThis is a list of proprietary laboratory information management systems (LIMS) from businesses and organizations \"listed in Wikipedia\".\n\n"}
{"id": "6973036", "url": "https://en.wikipedia.org/wiki?curid=6973036", "title": "List of Sun Microsystems employees", "text": "List of Sun Microsystems employees\n\nThese notable people worked at Sun Microsystems at some point prior to its acquisition by Oracle Corporation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "35516244", "url": "https://en.wikipedia.org/wiki?curid=35516244", "title": "List of flash memory controller manufacturers", "text": "List of flash memory controller manufacturers\n\nThis is a list of manufacturers of flash memory controllers for various flash memory devices like SSDs, USB flash drives, SD cards, and CompactFlash cards.\nNote: \"Independent\"=sells to any 3rd party; \"Captive\"=only used for their own products\n\n"}
{"id": "39957824", "url": "https://en.wikipedia.org/wiki?curid=39957824", "title": "List of international databases on individual student achievement tests", "text": "List of international databases on individual student achievement tests\n\nThis page contains a list of international databases on individual student achievement tests that can be used for psychometric research. In other words, this table only includes datasets containing items measuring ability and directly answered by students.\n\n"}
{"id": "20986106", "url": "https://en.wikipedia.org/wiki?curid=20986106", "title": "List of medical and health informatics journals", "text": "List of medical and health informatics journals\n\nThis is a list of journals related to medical and health informatics.\n\n\n"}
{"id": "7120122", "url": "https://en.wikipedia.org/wiki?curid=7120122", "title": "List of volcanoes in Mexico", "text": "List of volcanoes in Mexico\n\nThis is a list of active and extinct volcanoes in Mexico. \n\n"}
{"id": "47805321", "url": "https://en.wikipedia.org/wiki?curid=47805321", "title": "Loren E. Babcock", "text": "Loren E. Babcock\n\nLoren E. Babcock is an American geologist. He is professor of Earth Science at Ohio State University. Babcock has written over 125 scientific articles and the textbook, \"Visualizing Earth History\". He researches topics in processes of fossilization and the evolutionary history of trilobites and other Cambrian fossils. A fellow from the Geological Society of America, Babcock was the recipient of the Charles Schuchert Award for Excellence and Promise in Paleontology and the Erasmus Haworth Award for Distinguished Alumni Honors in Geology. He received a Ph.D. from the University of Kansas in 1990.\n\nIn 2008, he was one of a team of researches who discovered the oldest footprints ever found, over 570 million years old, in Nevada. Although he was uncertain, Babcock believed that they came from an arthropod species.\n"}
{"id": "53848867", "url": "https://en.wikipedia.org/wiki?curid=53848867", "title": "László Baksay", "text": "László Baksay\n\nLászló András Baksay (born 22 July 1945) is a Hungarian physicist and academic. He is a professor and had of the Physics and Space Sciences at the Department of Physics and Space Sciences at the Florida Institute of Technology.\n\nBaksay was born in Budapest in 1945, but his family moved to Germany in 1956, where he went to high school in Düsseldorf. He received his doctorate from RWTH Aachen University, in Aachen, West Germany, in 1978.\n\nHe was awarded the status of Fellow in the American Physical Society, after they were nominated by their Forum on International Physics in 2008, for \"his contributions to high energy physics, leadership of international collaborations especially in bringing the Hungarian physics community into the international enterprise, innovations and activities in science education and many efforts for the APS international program and the Forum on International Physics.\"\n"}
{"id": "33797591", "url": "https://en.wikipedia.org/wiki?curid=33797591", "title": "MIT150", "text": "MIT150\n\nThe MIT150 is a list published by the Boston Globe, in honor of the 150th anniversary of the Massachusetts Institute of Technology (MIT) in 2011, listing 150 of the most significant innovators, inventions or ideas from MIT, its alumni, faculty, and related people and organizations in the 150 year history of the institute.\n\nThe top 30 innovators and inventions on the list are:\n\n\n\n"}
{"id": "18683438", "url": "https://en.wikipedia.org/wiki?curid=18683438", "title": "Martín Cárdenas (botanist)", "text": "Martín Cárdenas (botanist)\n\nMartín Cárdenas Hermosa (November 12, 1899 – February 14, 1973) was a Bolivian botanist. Cárdenas is considered one of the most important botanists in Bolivia's history.\nHe is responsible for recording some 6,500 species of plants in his native country.\n\nIn 1918, he graduated as a Bachelor in Biological Sciences and Letters and secured a scholarship to continue his studies at the Instituto Normal Superior in La Paz, where he specialized in Biology and Chemistry. He graduated in 1922. On his vacations in Cochabamba he went for long walks by gathering plants, of which he soon recorded their characteristics in books and journals at the Municipal Library of La Paz. At that time, Cardenas had met Swedish botanist Erik Asplund, who had also shown a keen interest in studying the plants in Bolivia. Asplund played an important role in enhancing his knowledge of botany and was an early mentor for him.\n\nBy May 1922, Cárdenas was already professor in the Special Natural Sciences and Chemistry, being an auxiliary senior instructor and later obtained a title at the \"Instituto Normal Superior de La Paz\".\n\nIn his career, over a 40 or 50-year period, Cárdenas classified 6,500 species of the flora of Bolivia, and described 180 new species of cactus, with 16 varieties. He also registered 26 types of \"Solanum tuberosum\" with six varieties.\n\nIn 1951, he was awarded the Mary Soper Pope Memorial Award in botany.\n\n"}
{"id": "57696352", "url": "https://en.wikipedia.org/wiki?curid=57696352", "title": "Navigation surface", "text": "Navigation surface\n\nIn hydrography, the Navigation Surface paradigm represents an alternative to traditional approaches to manage bathymetric data by creating bathymetric databases that can be used to generate high-resolution navigation aids and other applications. \n\nThe paradigm also provides methods to manipulate the data to create products for various applications (e.g., thematic maps for marine geology,acoustic seabed classification and marine biology).\n\nRecent technological developments in hydrography (e.g., large adoption of multibeam echosounder and electronic navigational charts) have pushed hydrographic organizations to adopt a new production paradigm centered on gridded surfaces rather than sounding-based workflow and products.\n\nBased on such a shift, the concept of navigation surface was introduced in 2003 to provide a seafloor model at the best resolution that the data support. Depth values for nautical charting are then derived by generalization of the available gridded surfaces. In addition, a quality assessment for each grid node of the navigation surface is created through an uncertainty layer.\n\nThe Open Navigation Surface (ONS) project designed a free, open-source code library to manage (read/write) the information required to create a Navigation Surface. The implementation of these requirements is represented by the Bathymetric Attributed Grid data format.\n\nThe US Navy has implemented a global navigation surface database using an infrastructure called DBDB-NV.\n"}
{"id": "2883565", "url": "https://en.wikipedia.org/wiki?curid=2883565", "title": "Notational analysis", "text": "Notational analysis\n\nIn professional sports, notational analysis is the study of movement patterns, strategy and tactics in team sports. Successful patterns of play can be identified and used in subsequent matches. Notational analysis has a history in dance and music notation. Notational analysis is a way that critical events in a performance can be quantified in a consistent and reliable manner.\n\nIn notational analysis, no change in performance of any kind will take place without feedback. The role of feedback is central in the performance improvement process, and by inference, so is the need for accuracy and precision of such feedback. The provision of this accurate and precise feedback can only be facilitated if performance and practice is subjected to a vigorous process of analysis.\n\nAugmented feedback has traditionally been provided by subjective observations, made during performance by the coaches, in the belief that they can accurately report on the critical elements of performance without any observation aids. Several studies not only contradict this belief, but also suggest that the recall abilities of experienced coaches are little better than those of novices, and that even with observational training, coaches' recall abilities improved only slightly. Furthermore, research in applied psychology has suggested that these recall abilities are also influenced by factors that include the observer's motives and beliefs. The coach is not a passive perceiver of information, and as such his or her perception of events is selective and constructive, not simply a copying process. This importance of feedback to performance improvement, and the limitations of coaches' recall abilities alluded to above, implies a requirement for objective data upon which to base augmented feedback, and the main methods of \"objectifying\" this data involve the use of video / notational analysis (Hughes and Franks, 1997 p. 11).\n\nCoaches have been aware, consciously or unconsciously, of these needs for accuracy of feedback and have been using simple data gathering systems for decades. More recently, sports scientists have been using notational analysis systems to answer fundamental questions about game play and performance in sport. An early work, over some decades, on analysis of soccer was picked up by the then Director of Coaching at the Football Association, and this had a profound effect on the patterns of play in British football – the adoption of the 'long ball' game. Generally, the first publications in Britain of the research process by notational analysis of sport were in the mid-1970s, so as a discipline it is one of the more recent to be embraced by sports science. The publication of a number of notation systems in racket sports provided a fund of ideas used by other analysts. Because of the growth and development of sports science as an academic discipline, a number of scientists began using and extending the simple hand notation techniques that had served for decades. This also coincided with the introduction of personal computers, which transformed all aspects of data gathering in sports science. Currently hand and computerised notation systems are both used to equal extents by working analysts, although the use of computer databases to collate hand notated data post-event makes the analyses much more powerful.\n\nThe applications of notation have been defined as:\n\nMost pieces of research using notation, or indeed any practical applications working directly with coaches and athletes, will span more than one of these purposes.\n\nThe definition of tactical patterns of play in sports has been a profitable source of work for a number of researchers. The maturation of tactics can be analysed at different levels of development of a specific sport, usually by means of a cross-sectional design. The different tactics used at each level of development within a sport will inevitably depend upon technical development, physical maturation and other variables. The 'maturation models' have very important implications for coaching methods and directions at the different stages of development in each of the racket sports. These tactical 'norms' or 'models', based both upon technique and tactics, demonstrate how the different applications, defined above, can overlap.\n\nSanderson and Way (1977) used symbols to notate seventeen different strokes, as well as incorporating court plans for recording accurate positional information. The system took an estimated 5–8 hours of use and practise before an operator was sufficiently skilful to record a full match actually during the game. In an average squash match there are about 1000 shots, an analyst using this system will gather over 30 pages of data per match. Not only were the patterns of rally-ending shots (the Nth shot of the rally) examined in detail, but also those shots that preceded the end shot, (N-1) to a winner or error, and the shots that preceded those, (N-2) to a winner or error. In this way the rally ending patterns of play were analysed. Not surprisingly, processing the data for just one match could take as long as 40 hours of further work. The major emphasis of this system was on the gathering of information concerning `play patterns' as well as the comprehensive collection of descriptive match data. Sanderson felt that `suggestive' symbols were better than codes, being easier for the operator to learn and remember. The main disadvantages of this system, as with all longhand systems, was the time taken to learn the system and the large amounts of data generated, which in turn needed so much time to process it.\n\nThe 1980s and 1990s saw researchers struggling to harness the developing technology to ease the problems inherent in gathering and interpreting large amounts of complex data. Hughes (1987) modified the method of Sanderson and Way so that the hand-notated data could be processed on a mainframe computer. Eventually, the manual method was modified so that a match could be notated in-match at courtside directly into a microcomputer. This work was then extended to examine the patterns of play of male squash players at recreational, county and elite levels, thus creating empirical models of performance, although the principles of data stabilisation were not thoroughly understood at the time. This form of empirical modelling of tactical profiles is fundamental to a large amount of the published work in notational analysis. By comparing the patterns of play of successful and unsuccessful teams or players in elite competitions, world cup competitions, for example, enables the definition of those performance indicators that differentiate between the two groups. This research template has been used in a number of sports to highlight the tactical parameters that determine success, and it has been extended in tennis to compare the patterns of play that are successful on the different surfaces on which the major tournaments are played.\n\nMost of the examples for tactical applications of notation could appear in the other sections of direct applications of notational analysis, but their initial aims were linked with analysis of tactics. The interesting theme that is emerging, from some of the recent research, is that the tactical models that are defined are changing with time, as players become fitter, stronger, faster, bigger (think of the changes in rugby union since professionalisation in 1996), and the equipment changes – for example, the rackets in all the sports have become lighter and more powerful. Over a period of less than 15 years the length of rallies in squash, for elite players, has decreased from about 20 shots, to about 12 shots per rally. An excellent review (Croucher, 1996) of the application of strategies using notational analysis of different sports outlines the problems, advantages and disadvantages associated with this function.\n\nTo define quantitatively where technique fails or excels has very practical uses for coaches, in particular, and also for sports scientists aiming to analyse performance at different levels of development of athletes.\n\nWinners and errors are powerful indicators of technical competence in racket sports and have often been used in research in notational analysis of net-wall games. It has been found that, for all standards of play in squash, if the winner: error ratio for a particular player in a match was greater than one, then that player usually won. (This was achieved with English scoring and a 19-inch tin). Although this ratio is a good index of technique, it would be better used with data for both players, and the ratios should not be simplified nor decimalised. Rally end distributions, winners and errors in the different position cells across the court, have often been used to define technical strengths and weaknesses. This use of these distributions as indicators is valid as long as the overall distribution of shots across the court is evenly balanced. This even distribution of shots rarely occurs in any net or wall game. Dispersions of winners and errors should be normalised with respect to the totals of shots from those cells. It would be more accurate to represent the winner, or error, frequency, from particular position cells, as a ratio to the total number of shots from those cells.\n\nSimilarly, performance indicators such as shots are insufficient and need to be expressed with more detail, for example shot to goal ratios (soccer). Even these, powerful as they are, need to be viewed with caution and perhaps integrated with some measure of shooting opportunities? In rugby union, simple numbers of rucks and mauls won by teams may not give a clear impression of the match, the ratio of 'rucks won' to 'rucks initiated' is a more powerful measure of performance. This too could be improved by some measure of how quickly the ball was won in critical areas of the pitch?\n\nMany coaches seek the template of tactical play at the highest level for preparation and training of both elite players and/or teams, and also for those developing players who aspire to reach the highest position. Particular databases, aimed at specific individuals or teams, can also be used to prepare in anticipation of potential opponents for match play. This modelling of technical attainment has been replicated in many sports and form the basis of preparation at the highest levels by the sports science support teams.\n\nReilly and Thomas (1976) recorded and analysed the intensity and extent of discrete activities during match play in field soccer. With a combination of hand notation and the use of an audio tape recorder, they analysed in detail the movements of English first division soccer players. They were able to specify work-rates of the different positions, distances covered in a game and the percentage time of each position in each of the different ambulatory classifications. Reilly has continually added to this base of data enabling him to clearly define the specific physiological demands in not just soccer, but all the football codes. This piece of work by Reilly and Thomas has become a standard against which other similar research projects can compare their results and procedures, and it has been replicated by many other researchers in many different sports.\n\nModern tracking systems have taken the chore out of gathering movement data, which was the most time-consuming application of notational analysis, and advanced computer graphics make the data presentation very simple to understand. Modelling movement has created a better understanding of the respective sports and has enabled specific training programmes to be developed to improve the movement patterns, and fitness, of the respective athletes.\n\nTeams and performers often demonstrate a stereotypical way of playing and these are idiosyncratic models, which include positive and negative aspects of performance. Patterns of play will begin to establish over a period of time but the greater the database then the more accurate the model. An established model provides for the opportunity to compare single performance against it. The modelling of competitive sport is an informative analytic technique because it directs the attention of the modeller to the critical aspects of data that delineate successful performance. The modeller searches for an underlying signature of sport performance, which is a reliable predictor of future sport behaviour. Stochastic models have not yet, to our knowledge, been used further to investigate sport at the behavioural level of analysis. However, the modelling procedure is readily applicable to other sports and could lead to useful and interesting results.\n\nOnce notational analysis systems are used to collect amounts of data that are sufficiently large enough to define 'norms' of behaviour, then all the ensuing outcomes of the work are based upon the principles of modelling. It is an implicit assumption in notational analysis that in presenting a performance profile of a team or an individual that a 'normative profile' has been achieved. Inherently this implies that all the variables that are to be analysed and compared have all stabilised. Most researchers assume that this will have happened if they analyse enough performances. But how many is enough? In the literature there are large differences in sample sizes.\n\nThese problems have very serious direct outcomes for the analyst working with coaches and athletes, both in practical and theoretical applications. It is vital that when analysts are presenting profiles of performance that they are definitely stable otherwise any statement about that performance is spurious. The whole process of analysis and feedback of performance has many practical difficulties. The performance analyst working in this applied environment will experience strict deadlines and acute time pressures defined by the date of the next tournament, the schedule and the draw. The need then is to provide coaches with accurate information on as many of the likely opposition players, or teams, in the amount of time available. This may be achieved by the instigation of a library of team and/or player analysis files, which can be extended over time and receive frequent updating. Player files must be regularly updated by adding analyses from recent matches to the database held on each player.\n\nFinally, some scientists have considered the use of a number of sophisticated techniques, such as neural networks, chaos theory, fuzzy logic and catastrophe theory, for recognizing structures, or processes, within sports contests. Each of these system descriptions, while incomplete, may assist in our understanding of the behaviours that form sports contests. Furthermore, these descriptions for sports contests need not be exclusive of each other, and a hybrid type of description (or model) may be appropriate in the future, a suggestion that remains only a point of conjecture at this time.\n\nIt is accepted that feedback, if presented at the correct time and in the correct quantity, plays a great part in the learning of new skills and the enhancement of performance. Recent research, however, has shown that the more objective or quantitative the feedback, the greater effect it has on performance. However, in order to gauge the exact effect of feedback alone, complete control conditions would be needed in order to minimise the effect of other external variables, which is by definition impossible in real competitive environments. This experimental design is also made more difficult because working with elite athletes precludes large numbers of subjects.\n\nHughes and Robertson (1997) were using notation systems as an adjunct to a spectrum of tactical models that they have created for squash. The hand notation systems are used by the Welsh national youth squads, the actual notation being completed by the players, for the players. It is believed that in this way the tactical awareness of the players, doing the notation, are heightened by their administration of these systems. This type of practical educational use of notation systems has been used in a number of teams sports, soccer, rugby union, rugby league, basketball, cricket, and so on, by players in the squads, substitutes, injured players, as a way of enhancing their understanding of their sport, as well as providing statistics on their team.\n\n"}
{"id": "5193812", "url": "https://en.wikipedia.org/wiki?curid=5193812", "title": "Orbital Express", "text": "Orbital Express\n\nOrbital Express was a space mission managed by the United States Defense Advanced Research Projects Agency (DARPA) and a team led by engineers at NASA's Marshall Space Flight Center (MSFC). The Orbital Express program was aimed at developing \"a safe and cost-effective approach to autonomously service satellites in orbit.\"\nThe system consisted of two spacecraft: the ASTRO servicing satellite, and a prototype modular next-generation serviceable satellite; NEXTSat. \nThe mission launched from Cape Canaveral Air Force Station on March 8, 2007, aboard an Atlas V expendable launch vehicle. The launch was part of the United States Air Force Space Test Program STP-1 mission.\n\nThe Orbital Express program was managed by the Tactical Technology Office (TTO), one of the six technical offices in DARPA.\nTTO programs included both \"Aerospace Systems\" such as Orbital Express, and \"Tactical Multipliers\" such as the \"Magneto Hydrodynamic Explosive Munition (MAHEM) program\".\nASTRO was developed by Boeing Integrated Defense Systems, which included the Orbital Express Demonstration Manipulator System (OEDMS) developed by MacDonald, Dettwiler and Associates, and NEXTSat was developed by Ball Aerospace & Technologies Corp.\nNASA's involvement was through the Automated Systems and Automated Rendezvous and Docking Division of the Engineering Directorate at MSFC. The MSFC Engineering Directorate also managed the Advanced Video Guidance System (AVGS) for Orbital Express project.\nThe refueling mechanism was designed, developed and produced by VACCO Industries. The docking mechanism, as well as the launch adapter, were designed, developed and produced by Sierra Nevada Corporation (SNC) Space Systems.\n\nThe project hoped to demonstrate several satellite servicing operations and technologies including rendezvous, proximity operations and station keeping, capture, docking, fluid transfer (specifically, hydrazine on this mission), and ORU (Orbit Replaceable Unit) transfer. A prime military mission would be to refuel reconnaissance satellites so they can improve coverage, increase surprise and be more survivable.\n\nThe fluid (fuel) and ORU (battery) transfers were completed successfully at the lowest levels of spacecraft autonomy. Subsequent transfers over a three-month period were intended to demonstrate greater autonomy.\nThe Orbital Express Demonstration Manipulator System (OEDMS), provided by MDA Corp., was the mission’s integrated robotics solution. It consisted primarily of a 6-DOF rotary joint robotic arm, its flight avionics (the Manipulator Control Unit or MCU) and arm vision system, two On-Orbit Replaceable Units (ORUs) and their spacecraft attachment interfaces, a visual target and grapple fixture installed on NEXTSat, and the Manipulator Ground Segment.\n\nThe OEDMS was mounted on the ASTRO. It was used to capture and service the NEXTSat, the client satellite provided by Ball Aerospace. Using a robotic arm on-orbit, the Orbital Express mission demonstrated autonomous capture of a fully unconstrained free-flying client satellite, autonomous transfer of a functional battery ORU between two spacecraft, and autonomous transfer of a functional computer ORU. These operations were executed as part of mission scenarios that demonstrated complete sequences of autonomous rendezvous, capture, berthing and ORU transfer.\n\nAll robotic operations were scripted prior to execution and performed autonomously as part of increasingly complex mission scenarios. The arm was commanded to perform its operations by either direct command from the ground, or autonomously by the ASTRO Mission Manager software. Scenarios in the early phases of flight operations incorporated a number of Authority to Proceed (ATP) pause points, which required a signal to be sent from the ground to authorize the ASTRO Mission Manager to continue the sequence. This allowed the ground operations team to verify that the scenario was proceeding as planned before continuing to the next step. Later scenarios incorporated fewer ATPs. The final scenarios were compound autonomous sequences, performing rendezvous, capture, ORU transfer and fluid transfer without any ATPs.\n\nThe final rendezvous and docking between the two spacecraft occurred on 29 June 2007. This was followed by the final demonstration, the changeout of a flight computer aboard ASTRO. NASA's plans for an extended mission were abandoned. The two craft demated for a final time, with ASTRO backing out to greater than in a test of sensor performance. Following this the craft performed a rendezvous to a standoff, where decommissioning took place. The NEXTSat spacecraft was deactivated on 21 July, when its computers were turned off, and solar panels pointed away from the Sun. Subsequently, ASTRO vented its Hydrazine propellant, and was deactivated on 22 July 2007. The satellites were left to decay naturally.\n\nNextSat was expected to take three to five years to decay, while the heavier ASTRO satellite was expected to take fifteen years.\nHowever, ASTRO reentered the atmosphere on 25 October 2013.\n\n\n1. https://web.archive.org/web/20100203220541/http://www.boeing.com/bds/phantom_works/orbital.html\n\n"}
{"id": "23741950", "url": "https://en.wikipedia.org/wiki?curid=23741950", "title": "POEM@Home", "text": "POEM@Home\n\nPOEM@Home was a distributed computing project hosted by the Karlsruhe Institute of Technology and running on the Berkeley Open Infrastructure for Network Computing (BOINC) software platform. It modeled protein folding using Anfinsen's dogma. POEM@Home was started in 2007 and, due to advances using GPUs that rendered the BOINC program redundant, concluded in October 2016. The POEM@home applications were proprietary.\n\nThe project studied how protein structure determined protein function, predict a protein's structure from its amino acid sequence, investigated how proteins interact with each other, and understand how malfunctioning proteins can cause functional disorders. The resulting knowledge could then be used in the development of medical treatments.\n\n\n"}
{"id": "6788445", "url": "https://en.wikipedia.org/wiki?curid=6788445", "title": "Planetary Fourier Spectrometer", "text": "Planetary Fourier Spectrometer\n\nThe Planetary Fourier Spectrometer (PFS) is an infrared spectrometer built by the Istituto Nazionale di Astrofisica (Italian National Institute for Astrophysics) along with the Istituto di Fisica dello spazio Interplanetario and the Consiglio Nazionale delle Ricerche (Italian National Research Council). The instrument is currently used by the European Space Agency on both the Mars Express Mission and the Venus Express Mission. It consists of four units which together weigh around 31.4 kg, including a pointing device, a power supply, a control unit, and an interferometer with electronics. \n\nThe main objective of the instrument is to provide temperature profiles of Mars's carbon dioxide atmosphere, and to the study composition of the planet's atmosphere through the infrared radiation that is reflected and emitted by the planet.\n\nOn March 2004, Professor Vittorio Formisano, the researcher in charge of the Mars Express Planetary Fourier Spectrometer, announced the discovery of methane in the Martian atmosphere. However, methane cannot persist in the Martian atmosphere for more than a few hundred years since it can be broken down by sunlight. Thus, this discovery suggests that the methane is being continually replenished by some unidentified volcanic or geologic process, or that some kind of extremophile life form similar to some existing on Earth is metabolising carbon dioxide and hydrogen and producing methane. In July 2004, rumours began to circulate that Formisano would announce the discovery of ammonia at an upcoming conference. It later came to light that none had been found; in fact some noted that the PFS was not precise enough to distinguish ammonia from carbon dioxide anyway.\n\n\n"}
{"id": "41616956", "url": "https://en.wikipedia.org/wiki?curid=41616956", "title": "Qui-Lim Choo", "text": "Qui-Lim Choo\n\nQui-Lim Choo is a Singapore-born scientist, who along with Michael Houghton, George Kuo and Daniel W. Bradley, co-discovered and cloned Hepatitis C in 1989. He also co-discovered the Hepatitis D genome in 1986. The discovery of Hepatitis C led to the rapid development of diagnostic reagents to detect HCV in blood supplies which has reduced the risk of acquiring HCV through blood transfusion from one in three to about one in two million. It is estimated that antibody testing has prevented at least 40,000 new infections per year in the US alone and many more worldwide.\n\nHe received his undergraduate training at Queen Elizabeth College in 1973 and completed his PhD in biochemistry at King's College London in 1980. He trained under William J. Rutter at the University of California, San Francisco before joining Chiron Corporation.\n\nHe was awarded the Karl Landsteiner Memorial Award (1992) and Dale A. Smith Memorial Award (2005) of the American Association of Blood Banks, and the William Beaumont Prize of the American Gastroenterological Association in 1994.\n"}
{"id": "1906854", "url": "https://en.wikipedia.org/wiki?curid=1906854", "title": "R/K selection theory", "text": "R/K selection theory\n\nIn ecology, \"r\"/\"K\" selection theory relates to the selection of combinations of traits in an organism that trade off between quantity and quality of offspring. The focus upon either increased quantity of offspring at the expense of individual parental investment of r-strategists, or reduced quantity of offspring with a corresponding increased parental investment of K-strategists, varies widely, seemingly to promote success in particular environments.\n\nThe terminology of \"r\"/\"K\"-selection was coined by the ecologists Robert MacArthur and E. O. Wilson in 1970 based on their work on island biogeography; although the concept of the evolution of life history strategies has a longer history (see e.g. plant strategies).\n\nThe theory was popular in the 1970s and 1980s, when it was used as a heuristic device, but lost importance in the early 1990s, when it was criticized by several empirical studies. A life-history paradigm has replaced the \"r\"/\"K\" selection paradigm but continues to incorporate many of its important themes.\n\nIn \"r\"/\"K\" selection theory, selective pressures are hypothesised to drive evolution in one of two generalized directions: \"r\"- or \"K\"-selection. These terms, \"r\" and \"K\", are drawn from standard ecological algebra as illustrated in the simplified of population dynamics:\n\nwhere \"N\" is the population, \"r\" is the maximum growth rate, \"K\" is the carrying capacity of the local environment, and \"dN/dt\", the derivative of \"N\" with respect to time \"t\", is the rate of change in population with time. Thus, the equation relates the growth rate of the population \"N\" to the current population size, incorporating the effect of the two constant parameters \"r\" and \"K\".\n(Note that decrease is negative growth.) The choice of the letter \"K\" came from the German \"Kapazitätsgrenze\" (capacity limit), while \"r\" came from \"rate\".\n\n\"r\"-selected species are those that emphasize high growth rates, typically exploit less-crowded ecological niches, and produce many offspring, each of which has a relatively low probability of surviving to adulthood (i.e., high \"r\", low \"K\"). A typical \"r\" species is the dandelion (genus \"Taraxacum\").\n\nIn unstable or unpredictable environments, \"r\"-selection predominates due to the ability to reproduce quickly. There is little advantage in adaptations that permit successful competition with other organisms, because the environment is likely to change again. Among the traits that are thought to characterize \"r\"-selection are high fecundity, small body size, early maturity onset, short generation time, and the ability to disperse offspring widely.\n\nOrganisms whose life history is subject to \"r\"-selection are often referred to as \"r\"-strategists or \"r\"-selected. Organisms that exhibit \"r\"-selected traits can range from bacteria and diatoms, to insects and grasses, to various semelparous cephalopods and small mammals, particularly rodents.\n\nBy contrast, \"K\"-selected species display traits associated with living at densities close to carrying capacity and typically are strong competitors in such crowded niches that invest more heavily in fewer offspring, each of which has a relatively high probability of surviving to adulthood (i.e., low \"r\", high \"K\"). In scientific literature, \"r\"-selected species are occasionally referred to as \"opportunistic\" whereas \"K\"-selected species are described as \"equilibrium\".\n\nIn stable or predictable environments, \"K\"-selection predominates as the ability to compete successfully for limited resources is crucial and populations of \"K\"-selected organisms typically are very constant in number and close to the maximum that the environment can bear (unlike \"r\"-selected populations, where population sizes can change much more rapidly).\n\nTraits that are thought to be characteristic of \"K\"-selection include large body size, long life expectancy, and the production of fewer offspring, which often require extensive parental care until they mature. Organisms whose life history is subject to \"K\"-selection are often referred to as \"K\"-strategists or \"K\"-selected. Organisms with \"K\"-selected traits include large organisms such as elephants, humans, and whales, but also smaller, long-lived organisms such as Arctic terns, parrots and eagles.\n\nAlthough some organisms are identified as primarily \"r\"- or \"K\"-strategists, the majority of organisms do not follow this pattern. For instance, trees have traits such as longevity and strong competitiveness that characterise them as \"K\"-strategists. In reproduction, however, trees typically produce thousands of offspring and disperse them widely, traits characteristic of \"r\"-strategists.\n\nSimilarly, reptiles such as sea turtles display both \"r\"- and \"K\"-traits: although sea turtles are large organisms with long lifespans (provided they reach adulthood), they produce large numbers of unnurtured offspring.\n\nThe \"r\"/\"K\" dichotomy can be re-expressed as a continuous spectrum using the economic concept of discounted future returns, with \"r\"-selection corresponding to large discount rates and \"K\"-selection corresponding to small discount rates.\n\nIn areas of major ecological disruption or sterilisation (such as after a major volcanic eruption, as at Krakatoa or Mount Saint Helens), \"r\"- and \"K\"-strategists play distinct roles in the ecological succession that regenerates the ecosystem. Because of their higher reproductive rates and ecological opportunism, primary colonisers typically are \"r\"-strategists and they are followed by a succession of increasingly competitive flora and fauna. The ability of an environment to increase energetic content, through photosynthetic capture of solar energy, increases with the increase in complex biodiversity as \"r\" species proliferate to reach a peak possible with \"K\" strategies.\n\nEventually a new equilibrium is approached (sometimes referred to as a climax community), with \"r\"-strategists gradually being replaced by \"K\"-strategists which are more competitive and better adapted to the emerging micro-environmental characteristics of the landscape. Traditionally, biodiversity was considered maximized at this stage, with introductions of new species resulting in the replacement and local extinction of endemic species. However, the Intermediate Disturbance Hypothesis posits that intermediate levels of disturbance in a landscape create patches at different levels of succession, promoting coexistence of colonizers and competitors at the regional scale.\n\nWhile usually applied at the level of species, \"r\"/\"K\" selection theory is also useful in studying the evolution of ecological and life history differences between subspecies, for instance the African honey bee, \"A. m. scutellata\", and the Italian bee, \"A. m. ligustica\". At the other end of the scale, it has also been used to study the evolutionary ecology of whole groups of organisms, such as bacteriophages.\n\nSome researchers, such as Lee Ellis, J. Philippe Rushton, and Aurelio José Figueredo, have applied \"r\"/\"K\" selection theory to various human behaviors, including crime, sexual promiscuity, fertility, IQ, and other traits related to life history theory. Rushton's work resulted in him developing \"differential \"K\" theory\" to attempt to explain many variations in human behavior across geographic areas, a theory which has been criticized by many other researchers. Other researchers have proposed that the evolution of human inflammatory responses is related to \"r\"/\"K\" selection.\n\nAlthough \"r\"/\"K\" selection theory became widely used during the 1970s, it also began to attract more critical attention. In particular, a review by the ecologist Stephen C. Stearns drew attention to gaps in the theory, and to ambiguities in the interpretation of empirical data for testing it.\n\nIn 1981, a review of the \"r\"/\"K\" selection literature by Parry demonstrated that there was no agreement among researchers using the theory about the definition of \"r\"- and \"K\"-selection, which led him to question whether the assumption of a relation between reproductive expenditure and packaging of offspring was justified. A 1982 study by Templeton and Johnson, showed that in a population of \"Drosophila mercatorum\" under \"K\"-selection the population actually produced a higher frequency of traits typically associated with \"r\"-selection. Several other studies contradicting the predictions of \"r\"/\"K\" selection theory were also published between 1977 and 1994.\n\nWhen Stearns reviewed the status of the theory in 1992, he noted that from 1977 to 1982 there was an average of 42 references to the theory per year in the BIOSIS literature search service, but from 1984 to 1989 the average dropped to 16 per year and continued to decline. He concluded that \"r\"/\"K\" theory was a once useful heuristic that no longer serves a purpose in life history theory.\n\nMore recently, the panarchy theories of adaptive capacity and resilience promoted by C. S. Holling and Lance Gunderson have revived interest in the theory, and use it as a way of integrating social systems, economics and ecology.\n\nWriting in 2002, Reznick and colleagues reviewed the controversy regarding \"r\"/\"K\" selection theory and concluded that: \n"}
{"id": "1111581", "url": "https://en.wikipedia.org/wiki?curid=1111581", "title": "Reaction (physics)", "text": "Reaction (physics)\n\nAs described by the third of Newton's laws of motion of classical mechanics, all forces occur in pairs such that if one object exerts a force on another object, then the second object exerts an equal and opposite reaction force on the first. The third law is also more generally stated as: \"To every action there is always opposed an equal reaction: or the mutual actions of two bodies upon each other are always equal, and directed to contrary parts.\" The attribution of which of the two forces is the action and which is the reaction is arbitrary. Either of the two can be considered the action, while the other is its associated reaction.\n\nWhen something is exerting force on the ground, the ground will push back with equal force in the opposite direction. In certain fields of applied physics, such as biomechanics, this force by the ground is called 'ground reaction force'; the force by the object on the ground is viewed as the 'action'.\n\nWhen someone wants to jump, he or she exerts additional downward force on the ground ('action'). Simultaneously, the ground exerts upward force on the person ('reaction'). If this upward force is greater than the person's weight, this will result in upward acceleration. When these forces are perpendicular to the ground, they are also called a normal force.\n\nLikewise, the spinning wheels of a vehicle attempt to slide backward across the ground. If the ground is not too slippery, this results in a pair of friction forces: the 'action' by the wheel on the ground in backward direction, and the 'reaction' by the ground on the wheel in forward direction. This forward force propels the vehicle.\n\nThe Earth, among other planets, orbits the Sun because the Sun exerts a gravitational pull that acts as a centripetal force, holding the Earth to it, which would otherwise go shooting off into space. If the Sun's pull is considered an action, then Earth simultaneously exerts a reaction as a gravitational pull on the Sun. Earth's pull has the same amplitude as the Sun but in the opposite direction. Since the Sun's mass is so much larger than Earth's, the Sun does not generally appear to react to the pull of Earth, but in fact it does, as demonstrated in the animation (not to precise scale). A correct way of describing the combined motion of both objects (ignoring all other celestial bodies for the moment) is to say that they both orbit around the center of mass, referred to in astronomy as the barycenter, of the combined system.\n\nAny mass on earth is pulled down by the gravitational force of the earth; this force is also called its weight. The corresponding 'reaction' is the gravitational force that mass exerts on the planet.\n\nIf the object is supported so that it remains at rest, for instance by a cable from which it is hanging, or by a surface underneath, or by a liquid on which it is floating, there is also a support force in upward direction (tension force, normal force, buoyant force, respectively). This support force is an 'equal and opposite' force; we know this not because of Newton's Third Law, but because the object remains at rest, so that the forces must be balanced.\n\nTo this support force there is also a 'reaction': the object pulls down on the supporting cable, or pushes down on the supporting surface or liquid. In this case, there are therefore four forces of equal magnitude:\n\n\nForces F and F are equal due of Newton's Third Law; the same is true for forces F and F.\nForces F and F are equal if and only if the object is in equilibrium, and no other forces are applied. (This has nothing to do with Newton's Third Law.)\n\nIf a mass is hanging from a spring, the same considerations apply as before. However, if this system is then perturbed (e.g., the mass is given a slight kick upwards or downwards, say), the mass starts to oscillate up and down. Because of these accelerations (and subsequent decelerations), we conclude from Newton's second law that a net force is responsible for the observed change in velocity. The gravitational force pulling down on the mass is no longer equal to the upward elastic force of the spring. In the terminology of the previous section, F and F are no longer equal.\n\nHowever, it is still true that F = F and F = F, as this is required by Newton's Third Law.\n\nThe terms 'action' and 'reaction' have the misleading suggestion of causality, as if the 'action' is the cause and 'reaction' is the effect. It is therefore easy to think of the second force as being there because of the first, and even happening some time after the first. This is incorrect; the forces are perfectly simultaneous, and are there for the same reason.\n\nWhen the forces are caused by a person's volition (e.g. a soccer player kicks a ball), this volitional cause often leads to an asymmetric interpretation, where the force by the player on the ball is considered the 'action' and the force by the ball on the player, the 'reaction'. But physically, the situation is symmetric. The forces on ball and player are both explained by their nearness, which results in a pair of contact forces (ultimately due to electric repulsion). That this nearness is caused by a decision of the player has no bearing on the physical analysis. As far as the physics is concerned, the labels 'action' and 'reaction' can be flipped.\n\nOne problem frequently observed by physics educators is that students tend to apply Newton's Third Law to pairs of 'equal and opposite' forces acting on the same object. \nThis is incorrect; the Third Law refers to forces on two different objects. For example, a book lying on a table is subject to a downward gravitational force (exerted by the earth) and to an upward normal force by the table. Since the book is not accelerating, these forces must be exactly balanced, according to Newton's First or Second law. They are therefore 'equal and opposite'. However, these forces are not always equally strong; they will be different if the book is pushed down by a third force, or if the table is slanted, or if the table-and-book system is in an accelerating elevator. The case of three or more forces\nis covered by considering the sum of all forces.\n\nA possible cause of this problem is that the Third Law is often stated in an abbreviated form: \"For every action there is an equal and opposite reaction,\" without the details, namely that these forces act on two different objects. Moreover, there is a causal connection between the weight of something and the normal force: if an object had no weight, it would not experience support force from the table, and the weight dictates how strong the support force will be. This causal relationship is not due to the Third Law but to other physical relations in the system.\n\nAnother common mistake is to state that\n\n\"The centrifugal force that an object experiences is the reaction to the centripetal force on that object.\"\n\nIf an object were simultaneously subject to both a centripetal force and an equal and opposite centrifugal force, the resultant force would vanish and the object could not experience a circular motion. The centrifugal force is sometimes called a fictitious force or pseudo force, to underscore the fact that such a force only appears when calculations or measurements are conducted in non-inertial reference frames.\n\n\n"}
{"id": "37550127", "url": "https://en.wikipedia.org/wiki?curid=37550127", "title": "Robin Williams (academic)", "text": "Robin Williams (academic)\n\nRobin A Williams (born 13 November 1952 in London) is a Professor of Social Research on Technology at the University of Edinburgh, Scotland, and director of the Institute for the Study of Science, Technology and Innovation. He is an interdisciplinary researcher in the field of Science and Technology Studies and contributed much to the social shaping of technology by studying the interplay between 'social' and 'technical' factors in the design and implementation of a range of technologies.\n\nAfter studying Natural Sciences and Social and Political Science at the University of Cambridge, Robin Williams took an MSc and PhD at Aston University and worked as research fellow in the Technology Policy Unit until 1986. He then joined the Research Centre for Social Sciences (RCSS) at the University of Edinburgh and coordinated the Edinburgh PICT Centre, one of the six university research centres established under the ESRC Programme on Information and Communications Technologies (1986 - 1995). During this time Robin Williams and other researchers in Edinburgh PICT Centre published on issues regarding social, economic and political aspects of the design and implementation of technology. Concluding the findings of a decade's research Robin Williams and David Edge published a notable paper on the ‘broad church’ of social shaping of technology. He became director of RCSS in 1997.\n\nIn 2000 Robin Williams established the Institute for the Study of Science, Technology and Innovation (ISSTI) to bring together groups of academics and individual researchers across the University of Edinburgh who are involved in research, teaching and knowledge transfer on social and policy aspects of science, technology and innovation. He was co-director of ESRC Innogen Centre from 2002-2012. In 2008 he arranged the merger of RCSS and the Science Studies Unit to form the Science, Technology and Innovation Studies subject group in the University of Edinburgh School of Social and Political Science.\nProfessor Williams established institutional links to and between research centres and institutions throughout the UK, Europe and Asia. His various involvements included co-chairing the UK Association for Studies in Innovation Science and Technology (AsSIST), being representative of Britain on the COST A4 European Research Collaboration initiative on the Social Shaping of Technology and coordinator of the China-EU Information Technology Standards Research Project (2008-2010).\n\n"}
{"id": "6612470", "url": "https://en.wikipedia.org/wiki?curid=6612470", "title": "Sandberg, California", "text": "Sandberg, California\n\nSandberg is the name of a post office and small surrounding community that was attached to The Sandberg Lodge (originally Sandberg's Summit Hotel), located on the Ridge Route highway in the Sierra Pelona Mountains of Southern California. The Ridge Route linked the Greater Los Angeles area to the San Joaquin Valley and Central California from 1919 through 1933.\n\nThe lodge was destroyed by a fire in 1961, but the site lives on as a dot on northwestern Los Angeles County maps. Sandberg was later the site of a U.S. weather station.\n\nSandberg is southwest of the small town of Neenach in the Antelope Valley. It is via Interstate 5 to Downtown Los Angeles. Sandberg is classed as a populated place by the United States Geological Survey, which means it is \"a place or area with clustered or scattered buildings and a permanent human population.\" Its elevation above sea level is .\n\nIt is northwest of the summit of Burnt Peak.\n\nHarald Sandberg, a native of Norway, settled in the Antelope Valley with his brother, Albert, in 1882, and they developed large areas there. On April 2, 1897, Harald filed homestead papers on ranch property just north of the parcel that later housed his hotel and inn.\n\nIn December 1900 the brothers made news when they \" \"captured a very large specimen of the California condor on their mountain ranch at Neenach, near Newhall, last Saturday\".\"\n\nHarald built his lodge in 1914, just one year before the opening of the Ridge Route resulted in a parade of cars by his front door, seven days a week. \"Sandberg's lodge at the top of the grade was a welcome sight to weary [Los Angeles] motorists still only halfway to Bakersfield,\" the \"Los Angeles Times\" reported. A hotel, restaurant, and cabins were constructed on leased Forest Service land immediately to the south of the homesteaded property.\n\nWhen first opened in a one-story building, the business was named Sandberg's Summit Hotel. Some time after 1921 the owner turned it into a three-story log hostelry set amid a grove of California live oaks. A crank telephone provided access to the outside world via the long-distance phone circuits that connected Los Angeles with Bakersfield. Cabins also provided lodging behind the hotel.\n\nIn 1918, Harald Sandberg was appointed postmaster of the settlement, which was thenceforth named Sandberg, with the post office inside the hotel itself.\n\n\"It was a small tourist community,\" Bakersfield resident Frank Kaufman told Interviewer Harrison Irving Scott (author of a history of the Ridge Route); it had a repair garage that advertised \"Labor $2, after 6 p.m. $3; never closed.\" Motor Stages would stop at Sandberg's for meals, and motorists would hunger for Mrs. (Marion) Sandberg's apple pie.\n\nIn September 1929, attorney and real estate developer Ulysses S. Grant Jr., the son of the 18th American president, checked into Sandberg's with his wife and nephew for a visit. He died of a heart attack in his room.\n\nIn spring 1934, the lodge was put up for sale. A newspaper classified advertisement described it:\n\n\" \"RESORT SANITARIUM DUDE RANCH SANDBERG'S INN. RIDGE ROUTE. 75 mi. from L.A. by highway. Ideal climate: natural beauty. 100 A. of tree covered level & rolling land. Secluded & quiet. 3-story bldg. with lobby, dining rm., hotel rms., etc. 7 other bldgs. Accommodate 35 guests. Own elec. & water plants. Fully equipt. & furn. to operate now. Sell or TRADE. Phone CRestview 7644 or Box M-285, Times\".\"\n\nSandberg died on July 9, 1939, and his wife on April 1, 1954.\n\nBy the time of Harald Sandberg's death, there were new operators for the place, a newspaper advertisement having proclaimed:\n\" \"Grand Opening and Free Barbecue Sunday, May 28, 1939. Sandberg Lodge and Dude Ranch, Larry Brock proprietor, Harry Moss Manager\".\"\n\nBut the hotel never regained its former popularity: An alternate to the Ridge Route was opened, an event that virtually stopped traffic through Sandberg. Nevertheless, J.H. Cox purchased both the lodge and the ranch and, according to Walter W. (Lucky) Stevens, a later owner, Cox tainted the hotel's reputation by allegedly \"bringing in booze, slot machines and 'ladies of the night.' \" Cox sold the operation to Lillian Grojean, who turned the hotel garage into a ceramics factory; her lease from the Forest Service amounted to $90 a year.\n\nLucky Stevens, a sometime film actor, was running a ceramics business in Burbank when he met Grojean. In 1950 or 1951 he paid her $15,000 for the dilapidated hotel, outbuildings, and lease.\nAt first he had plans to install a swimming pool and a fishing pond and to reopen the property as a guest ranch. By that time, the lodge was in disrepair, with pigeons roosting among the rafters. Eight years later, he said he wanted to open the spread of as a children's ranch, and he did succeed in acquiring money, furniture, and used clothing.\n\nOn April 29, 1961, fire destroyed the main lodge. Stevens was alone in the building. A district forest ranger said the blaze was apparently started by sparks from the chimney, and Stevens told an interviewer later that he had been burning trash when the flames began.\n\nThe Forest Service canceled Stevens' lease in 1963, and nothing remains on the site today but a historic marker, some stone steps, a bit of foundation, trees, and shrubbery.\n\nA four-man weather station was established in 1933 at the windy peak of nearby Bald Mountain, which straddles the boundary between the maritime climate to the south and a drier climate to the north. In 1953, the weather observers had to visually check the instruments and manually transmit the information via Teletype.\n\nIn 1978, the Weather Service switched to an automated station, explaining, in the words of \"Los Angeles Times\" staff writer Marika Gerrard, that \"It was just too hard to find someone to live up in that remote region with nothing to do but record weather statistics every hour on the hour.\" Nevertheless, in May 1981 reporter Gerrard found two people living at the station — a college student-caretaker and a man experimenting with the prototype of a modular wind turbine.\n\nThe other two people living in Sandberg in that month were Willard Sparks, captain of the Quail Lake Fire Station, and his wife, Shirley. Sparks was responsible for covering of forested land that included Sandberg, Gorman, Pyramid Lake, part of the Angeles Forest, and a stretch of Interstate 5 known as \"Blood Alley\" because of the frequent accidents there.\n\n"}
{"id": "8985161", "url": "https://en.wikipedia.org/wiki?curid=8985161", "title": "Star 48", "text": "Star 48\n\nStar 48 is a type of solid rocket motor used by many space propulsion and launch vehicle stages. It is used almost exclusively as an upper stage. It was developed primarily by Thiokol Propulsion, and is now manufactured by Orbital ATK, which purchased Thiokol in 2001. A Star 48B stage is also one of the few man-made items sent on escape trajectories out of the Solar System, although it is derelict since its use. The Star 48B variant is the PAM-D upper stage used on the Delta II rocket.\n\nThe Star 48 has been used as a third stage in a three stage launch systems.\n\nThe \"48\" designation refers to the approximate diameter of the fuel casing in inches; Thiokol had also manufactured other motors such as the Star 37 and Star 30. Internally, Thiokol's designation was TE-M-711 for early versions, and TE-M-799 for later ones. Subtypes are given one or more letter suffixes after the diameter number, or a trailing number (i.e., \"-2\") after the internal designation. Not surprisingly, the \"T\" prefix stands for Thiokol, and the following letter refers to the company division that developed the rocket motor. In this case, \"E\" refers to the Elkton, MD division and the \"M\" stands for motor.\n\nThe most common use of the Star 48 was as the final stage of the Delta II launch vehicles. Other launchers have also incorporated the motor, but with lower frequency. In such usage, the complete stage (motor plus accessories) is referred to as the Payload Assist Module (PAM), as the Shuttle could only take satellites to low Earth orbit. Because geostationary orbit is much more lucrative, the additional stage was needed for the final leg of the journey. On such missions, the stage is spin-stabilized. A turntable, mounted in the shuttle payload bay or atop the previous Delta stage, spun the PAM and payload to approximately 60 rpm prior to release.\n\nUsually after motor burnout and just prior to satellite release the PAM is de-spun using a yo-yo de-spin technique.\n\nA non-spinning, thrust-vectoring version of the Star 48 is available (\"Star 48BV\"), but much less common. A thrust-vectoring Star 48 is the final stage of the Minotaur IV+ launch vehicle.\n\nA Star 48BV was used in conjunction with a Delta IV Heavy for the Parker Solar Probe launch.\n\nA Star 48 motor used in the 3rd stage of the New Horizons probe was the first part of the New Horizons mission to reach Jupiter, arriving before the probe. It also crossed Pluto's orbit in 2015 at a distance of 200 million kilometers.\nA Star 48 Payload Assist Module that had been used to launch a GPS satellite in 1993 crashed in the Saudi Arabian desert in January 2001, after its orbit decayed. The unit did not burn up on reentry and was positively identified on the ground.\n\nIn 2013 a Star 48GXV was tested for the Solar Probe Plus mission.\n\nThe Star 48B version has an extra 11 kilograms of propellant more than the regular Star 48, for a total of 2011 kg. There is a version of the Star 48B that is lengthened and also heavier, called the Star 48B L.\n\nIn operation as a third stage, the Star 48B sits on top of spin table, and before it is separated it is spun up to stabilize it during the separation from the previous stage. (see also Spin-stabilisation) The Star 48B can produce 15,000 pounds of thrust (66.723 kilonewtons), with a burn time of 1 minute 27 seconds.\n\nA Star 48B was used on the third stage of the New Horizons spacecraft launch. New Horizons was launched by its stack in January 2006, and the Star 48B booster was launched along with the New Horizons's spacecraft on an escape trajectory out of the Solar System. The Star 48B ignited and burned for 48-seconds, taking both on a trajectory past Pluto; however because the Star 48B became derelict and did not have course corrections like the NH spacecraft, it would be projected to miss Pluto by hundreds of millions of miles.\n\n\"New Horizons\" Star 48B was calculated to arrive at planet Jupiter 6 hours before \"New Horizons\", and on Oct 15, 2015 would pass through Pluto's orbit at a distance of 213 million kilometers (over 1 AU) distant from Pluto. This was nearly four months after the \"New Horizons\" probe did.\n\nThe Star 48B is basis for the McDonnell Douglas PAM-D upper stage used on the Delta rocket.\n\n"}
