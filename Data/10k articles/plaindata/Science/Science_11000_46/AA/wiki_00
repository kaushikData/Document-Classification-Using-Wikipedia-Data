{"id": "8223032", "url": "https://en.wikipedia.org/wiki?curid=8223032", "title": "A507 road", "text": "A507 road\n\nThe A507 is an A-class road in England, linking the M1 motorway near Milton Keynes to the A10 at Buntingford. Beginning at junction 13 of the M1, the road heads east past Ridgmont to Ampthill. Here it passes between Ampthill and its close neighbour Flitwick, essentially separating the two. After this it passes Flitton before encountering the A6 at a roundabout. Passing Shefford the road briefly multiplexes with the A600 before crossing the A6001 and bypassing Stotfold. Crossing the A1 at junction 10 of the A1(M), where the motorway becomes a normal A-road, the A507 then heads south east through Baldock. After bridging over the A505 (here being the recently opened Baldock north-south bypass) it terminates at a roundabout with the A10 at Buntingford.\n\nIn 2008, a bypass opened alongside the M1 at Ridgmont. Prior to this the A507 formerly passed through Husborne Crawley and Ridgmont, where it met the A4012 road. The bypass includes three roundabouts and a bridge over the Marston Vale Line.\n\n"}
{"id": "39219551", "url": "https://en.wikipedia.org/wiki?curid=39219551", "title": "A calorie is a calorie", "text": "A calorie is a calorie\n\n\"A calorie is a calorie\" is a tautology used to convey the speaker's conviction that the concept of the \"calorie\" is in fact a sufficient way to describe energy content of food.\n\nThe tautological phrase means that regardless of the form of food calorie a person consumes (whether a carbohydrate, protein or fat calorie) the energetic value of such a calorie, is identical to any other. One dietary calorie contains 4,184 joules of energy. With this knowledge, it is easy to assume that all calories have equal value.\n\nHowever, good human nutrition measures foods for other values than just energy in calories.\n"}
{"id": "30830288", "url": "https://en.wikipedia.org/wiki?curid=30830288", "title": "Alejo Avello", "text": "Alejo Avello\n\nAlejo Avello is a main researcher at CEIT-IK4 Technological Center (since 1992) and a Professor at Tecnun-School of Engineering, University of Navarra (since 1992) where he lectures Mechanical Engineering.\n\nHe has been Ceit-Ik4’ Director from 2000 to 2017 and Dean of Tecnun from 2008 to 2012.\n\nMr. Avello’s expertise is mainly focused on Advanced Powder Metallurgy and Laser Manufacturing. He is currently involved on Research projects for local and global companies.\n\n"}
{"id": "32373441", "url": "https://en.wikipedia.org/wiki?curid=32373441", "title": "Anthony Moffat", "text": "Anthony Moffat\n\nAnthony (Tony)Lee Moffatt is an emeritus professor of astronomy at the Université de Montréal in Montreal, Quebec, Canada. Dr. Moffatt was appointed as a fellow of the Royal Society of Canada in 2001. Dr. Moffatt's interests focus on massive stars (Wolf-Rayet stars in particular), stellar winds, binary stars, as well as the structure and dynamics of star formation regions and galaxies.\n\nProf. Moffatt completed his Master of Science at the University of Toronto in 1966. His doctorate was granted in 1970 from Universität Bonn (Dr. rer. nat.). Following postdoctoral studies at Ruhr-Universität Bochum from 1970 to 1976, and the awarding of his second Dr. Habil. in 1976, Moffat was hired to the faculty of Université de Montréal in 1976.\n\nProf. Moffatt has supervised 8 postdoctoral scientists and 14 doctoral students at Université de Montréal. This includes Alexandre David-Uraz's research into dust formation around Wolf-Rayet stars.\n\nIn a series of papers beginning with a study of the open star cluster NGC 7380 \nand eleven other clusters, Moffatt used photographic UBV photometry to identify the massive star population.\n"}
{"id": "45222643", "url": "https://en.wikipedia.org/wiki?curid=45222643", "title": "Aragoscope", "text": "Aragoscope\n\nAn Aragoscope is a theoretical design for a telescope, based on diffraction around the edge of an occluding disc, named after French scientist Francois Arago.\n\nThe light diffracted around the edge of a perfectly circular occluder interferes constructively at the central axis, and the resolution at that point would be equal to the resolution of conventional lens with the same size of the occluder. Only light intensity would be lower. On this basis it would be possible to create a telescope by placing a suitable disc in space accompanied by a separate telescope some distance away along its axis. This concept has been explored by NASA and received Phase One funding in June 2014 by the NASA Innovative Advanced Concepts (NIAC) program. \n\nIt is important to note that this is a very different approach from that taken by another NASA project, the New Worlds Mission, which aims to use an occluder with \"petals\", otherwise known as a starshade, specifically designed to \"avoid\" diffraction onto the central axis.\n\n"}
{"id": "28131241", "url": "https://en.wikipedia.org/wiki?curid=28131241", "title": "Arkansas River Valley", "text": "Arkansas River Valley\n\nThe Arkansas River Valley (usually shortened to River Valley) is a region in Arkansas defined by the Arkansas River in the western part of the state. Generally defined as the area between the Ozark and Ouachita Mountains, the River Valley is characterized by flat lowlands covered in fertile farmland and lakes periodically interrupted by high peaks. Mount Magazine, Mount Nebo, and Petit Jean Mountain compose the Tri-Peaks Region, a further subdivision of the River Valley popular with hikers and outdoors enthusiasts. In addition to the outdoor recreational activities available to residents and visitors of the region, the River Valley contains Arkansas's wine country as well as hundreds of historical sites throughout the area.It is one of six natural divisions of Arkansas.\n\nThe Arkansas River Valley is not formally defined along county boundaries, including all of Logan and Sebastian counties and portions of Conway, Franklin, Johnson, Perry, Pope, and Yell counties.\n\n\nIn the Pre-Colonial era, the River Valley was inhabited by Native American tribes, including Caddo, Cherokee, Choctaw, Osage, Tunica, and Quapaw tribes. Most first encounters describe scattered villages and individual farmsteads in the River Valley, unlike the organized \"towns\" and groves and orchards encountered in eastern Arkansas. Much of what is known about these early societies has been uncovered by the Arkansas Archaeological Survey and the Arkansas Archaeological Society at Carden Bottoms in Yell County near the Arkansas and Petit Jean Rivers. Research at the site has linked artifacts to cave art (pictured at right) in a cave on Petit Jean Mountain, as well as establishing links to the Caddo, Osage, and Quapaw tribes.\n\nHernando de Soto became the first European explorer to enter Arkansas in 1541. His expedition of 600 Spanish explorers searching for gold and riches crossed into Arkansas across the Mississippi River, and explored the state for the next two years. The expedition traveled to Tanico, an important city somewhere in the River Valley, in September 1542. The following month, the expedition fought with a tribe referred to as the Tula somewhere near Fort Smith. This fighting apparently caused de Soto to turn the expedition back east, leaving the River Valley.\n\nFollowing the war, the Southern economy was in shambles, including Arkansas. The cost of the war effort, loss of human capital, and Confederate currency losing value were serious issues for the South in addition to the destruction of property, infrastructure, and crops. Many parts of Arkansas had descended into lawlessness and violence between whitecapping groups (including the Ku Klux Klan), freedmen, Republicans, and unaffiliated bandits taking advantage of the chaos. Indicative of the disarray, Radical Republican Governor Powell Clayton declared martial law in ten counties following reelection in 1868. Although no River Valley counties were initially subject to the proclamation, Claytdded four more counties, including one partial-River Valley county, Conway County. Since settlement, the River Valley had been a largely cashless society with significantly less reliance on slave labor compared to plantation agriculture areas like the Arkansas Delta and elsewhere in the Deep South. The Klan had limited support, and much of the area was viewed steadily Re\nDue to its relatively strong position following the Civil War, the River Valley attracted new settlement throughout Reconstruction. Populations of Austrian Catholics, German Catholics, and German Catholics and Lutherans were relocating to the River Valley. Some immigrated directly from Europe, but most came from early settlements in the Ohio River Valley. The Lutherans generally immigrated in organized companies, where the Catholics came independently, although some Catholic settlements like Clarksville and Subiaco were founded by organized groups. These settlements received support from existing immigrant populations in Little Rock and Fort Smith, and groups of Protestant settlers also establishing settlements in the area. Several of the River Valley's small towns were founded by these groups, beginning as small clusters of immigrants and evolving into cohesive communities.\n\nMany immigrants came to the River Valley searching for agricultural prosperity, particularly by farming cotton, which could fetch high prices at market and quickly turn a farm into a profitable enterprise. Upon arriving in the region, many found only densely forested upland to be the only property they could afford. River Valley soil and climate are much less conducive to cotton cultivation than the Arkansas Delta, and many settlers struggled. Eventually, a preference for mixed farming emerged, including potatoes and other garden vegetables, to protect against a poor cotton crop sending a farm into economic ruin.\n\nCoal mining was an important industry in the River Valley's early history. Dangerous and demanding, the industry attracted Swiss and German immigrants who were unable to establish productive farms. Mining became prominent by 1873, especially around the Altus area. The Swiss and German immigrants found the rolling hills similar to the topography of their homeland. Due to the climate, fertile soil and immigrants accustomed to wine with their meals, several wineries were established in the River Valley. The German community thrived with coal mining and railroad work driving the local economy. The Central Collegiate Institute was established in Altus in 1876 (now known as Hendrix College in Conway) and Hiram and Lydia College in 1890 (which went defunct in 1906). However, the railroad's prominence declined during the Great Depression, shrinking Altus's economy and population. Today, the Altus Area Coal Miner's Memorial is a series of five sculptures paying homage to area coal miners, with the names of over 2,500 local miners engraved at the site. Greenwood also has a Coal Miner's Memorial near the town square, with a restored coal railroad car and names of Sebastian County coal workers engraved on site.\n\nElsewhere in the county, cotton and timber had given way to strawberry, hay, and cattle. However, competition introduced into the market by the railroads allowed farmers in Texas and other states to undercut the prices offered by River Valley farmers. An exploration period for a new regional crop tested beans, legumes, and tomatoes before settling on mustard greens and spinach. The spinach and greens products allowed Alma to leverage its existing fruit canning facility owned by the Alma Canning and Evaporating Company, which had been in the area since 1888. In 1987, Alma claimed the title of \"Spinach Capital of the World\" and erected a Popeye statue in front of the Chamber of Commerce building.\n\nThe most populous city within the River Valley is Fort Smith, the principal city of the Fort Smith metropolitan area that also includes Van Buren and Alma. Fort Smith is the second-largest city in Arkansas, and serves as a regional hub for culture, health care and transportation. Approximately east, Russellville was the 16th largest city in Arkansas at the 2010 Census. The city is an important economic, education and population center in the state. Other cities in the River Valley are mostly of county-level significance, gateways to nearby recreational sites or small rural settlements. Cities such as Booneville, Clarksville, Morrilton, Paris, and Perryville serve as cultural and economic centers within the rural counties of the River Valley.\n\nThe River Valley has generally mild winters and hot, humid summers. Temperatures are generally warmer than in the Ozarks and cooler than Central Arkansas, although the wide variance in elevation in the River Valley can create locally different climactic conditions. The western portion of the River Valley (i.e., around Fort Smith) is situated near an area known as Tornado Alley in the central United States.\n\nVineyards and wineries around Altus have been in the same family for generations. The River Valley's first wineries date to the postbellum era, when they were founded to produce wine for the Swiss and German immigrants relocating to the area to work in coal mines. This culture lives on today in the five vineyards still in operation. The Chateau Aux Arc Vineyards and Winery is the largest US Chardonnay producer outside of California, and the largest Zinfandel producer in Arkansas. Mount Bethel Winery has been in operation for over 100 years, and offers a tasting, tour and gift shop for visitors. The Post Winery has been in the Post family for five generations. Visitors can buy wines, tour the winery and watch the production process.\n\nThe Alma Performing Arts Center is the largest and most popular performing arts venue in the River Valley. In Russellville, the Arkansas River Valley Arts Center offers visual arts as well as art classes and infrequent performances. The Greenwood Performing Arts Center has over 1,000 seats and is used for various performances in the city. In Clarksville, the Walton Fine Arts Center on the campus of the University of the Ozarks offers university theater, performers, and speakers to patrons. The Stephens Gallery hosts exhibits of glass and ivory carvings. In Van Buren, the King Opera House is a restored 1880s opera house, now holding various events throughout the year.\n\nThe River Valley is home to several annual cultural events, including art, history, music, and traditional heritage festivals. Many events are held at the state parks and on town squares throughout the River Valley.\n\nPetit Jean State Park hosts an annual Wildflower Weekend in April and a Rendezvous the weekend after Thanksgiving. The Museum of Automobiles atop Petit Jean Mountain hosts annual Antique Auto Show and Swap Meet events in June and September. Mount Magazine hosts an annual International Butterfly Festival in June, Frontier Days in October, and is the final destination on the Peak to Peak Poker Run, which begins at Queen Wilhelmina State Park in May.\n\n\nThe Alma Spinach Festival held on the third weekend in April pays homage to Alma's reputation as \"Spinach Capital of the World\".\n\nIn Clarksville, the Johnson County Peach Festival is the longest-running festival in Arkansas. Held annually in July, the festival offers peach pit spitting contest and a terrapin derby in addition to a parade and traditional food and craft vendors.\n\nThe Wiederkehr Weinfest in Wiederkehr Village is a free harvest festival held annually in October, including wine tasting, vineyard tours, music, polka dancing, traditional German cuisine and other festival entertainment. First held in 1963, Weinfest is one of the most popular festivals in the region.\n\nTwo major yard-sale events, Bargains Galore on Highway 64 and Big To Do on Highway 22, happen annually in the River Valley. Residents and businesses along the highways offer items for sale to visitors and residents traveling two of the main east-west highways in the River Valley.\n\n\nA host of regional and local history museums preserve and interpret the history and culture of the River Valley's early settlers, small towns, historic events, and rural residents.\n\n\nThe River Valley contains a large quantity of protected areas, with broad diversity across the region and several different managing agencies.\n\nNear Booneville, Blue Mountain Lake offers a variety of recreational opportunities. The Blue Mountain Wildlife Demonstration Area is a bird-dog field training center of international renown. The Jack Creek Recreation Area and Knopper's Ford Recreation Area offer well-known Arkansas swimming holes as well as hiking, camping and fishing.\n\nNear Clarksville, the Spadra Waterfront Marina offers RV camping, boat rentals, and guided trips along Spadra Creek. North of Clarksville, Lake Ludwig offers swimming, boating and fishing to visitors.\n\nSouth of Dardanelle, the Holla Bend National Wildlife Refuge protects over of bottomland and wetland surrounded by a cutoff meander of the Arkansas River. Wintering waterfowl and other migrating species use the area as a safe haven during their journey. The NWR offers a driving tour with interpretative signs.\n\nOn the Fourche LaFave River near Ola, the Nimrod Lake is managed by the USACE as a crappie fishing destination and camping area.\n\nNear Ozark, the Aux Arc Park offers boating access to the Arkansas River and RV sites.\n\nOzark Lake, formed on the Arkansas River southwest of Mulberry, is surrounded by a WMA\n\n\nThe United States Forest Service operates both the Ouachita National Forest and the Ozark National Forest within the region, offering trails, camping, and fishing over thousands of acres of public land. The state operates four parks within the region: Lake Dardanelle State Park, Mount Magazine State Park, Mount Nebo State Park, and Petit Jean State Park.\n\n\n"}
{"id": "57478939", "url": "https://en.wikipedia.org/wiki?curid=57478939", "title": "Bibsam Consortium", "text": "Bibsam Consortium\n\nBibsam Consortium is a consortium where 85 higher education and research institutions in Sweden participate to negotiate license agreements for electronic\ninformation resources . The consortium is head by the National Library of Sweden which negotiate and administrate license agreements for e-resource packages. The participating institutions sign a power of attorney which allows the National Librarian to sign contracts with the e-resource providers.\n\nBibsam Consortium was formed in 1996 in order to negotiate license agreements for electronic resources on behalf of Swedish Universities, research institutes and government agencies in Sweden. The total turnover of the agreements in 2015 was € 33 million and was € 35 million in 2017 . Out of this, 73% of the turnover is from the ten large universities of Sweden. There are six members in National Library of Sweden to negotiate and administrate the 100 license agreements for approximately 40 e-resource packages .\n\nIn 2018, Bibsam Consortium terminated its agreement with Elsevier publishers in order to stop rising prices of publishing and to support open access publishing . If the termination takes into effect by 1 July 2018, Swedish Universities and colleges will not have access to 2100 e-journals published by Elsevier. However, all articles published between 1 January 1995 and 30 June 2018 will still be available . Astrid Söderbergh Widding, President of Stockholm University, Chairman of the Bibsam consortium steering committee and Head of the negotiation team, said:\n\nThe requirements that Bibsam Consortium asks for are:\n"}
{"id": "33939070", "url": "https://en.wikipedia.org/wiki?curid=33939070", "title": "Biobank ethics", "text": "Biobank ethics\n\nBiobank ethics refers to the ethics pertaining to all aspects of biobanks. The issues examined in the field of biobank ethics are special cases of clinical research ethics.\n\nThe following table shows many of the leading controversial issues related to biobanking. The table names an issue, then describes a point on which there is consensus and an aspect of that same point for which there is no consensus.\n\nThere is broad consensus that when a person donates a specimen for research then that person has a right to privacy thereafter. To this end, researchers balance the need for specimens to be anonymous or de-identified from protected health information with the need to have access to data about the specimen so that researchers can use the sample without knowing the identity of the donor. In the United States, for example, the Office for Human Research Protections often promotes a traditional system wherein data which could identify a participant is coded, and then elsewhere stored away from the data is key which could decipher the identities in special circumstances when required outside of usual research.\n\nComplications arise in many situations, such as when the identity of the donor is released anyway or when the researchers want to contact the donor of the sample. Donor identities could become known if the data and decipher key are unsecure, but more likely, with rich datasets the identities of donors could be determined only from a few pieces of information which were thought unrelated to disturbing anonymity before the advent of computer communication.\n\nAmong the concerns which participants in biobanks have expressed are giving personal information to researchers and having data used against them somehow.\n\nScientists have demonstrated that in many cases where participants' names were removed from data, the data still contained enough information to make identification of the participants possible. This is because the historical methods of protecting confidentiality and anonymity have become obsolete when radically more detailed databases became available. Another problem is that even small amounts of genetic data, such as a record of 100 single nucleotide polymorphisms, can uniquely identify anyone.\n\nThere have been problems deciding what safeguards should be in place for storing medical research data. In response, some researchers have made efforts to describe what constitutes sufficient security and to recognize what seemingly anonymized information can be used to identify donors.\n\nWhen a person donates a specimen to a researcher, it is not easy to describe what the participant is donating because ownership of the specimen represents more rights than physical control over the specimen.\n\nThe specimens themselves have commercial value, and research products made from specimens can also. Fundamental research benefits all sectors, including government, non-profit, and commercial, and these sectors will not benefit equally. Specimens may be subject to biological patenting or research results from specimen experimentation may lead to the development of products which some entity will own. The extent to which a specimen donor should be able to restrict the way their specimen is used is a matter of debate.\n\nSome researchers make the argument that the specimens and data should be publicly owned. Other researchers say that by calling for donations and branding the process as altruistic the entities organizing biobank research are circumventing difficult ethical questions which participants and researchers ought to address.\n\nThere is broad consensus that participants in clinical research have a right to know the results of a study in which they participated so that they can check the extent to which their participation delivered beneficial results to their community. The right to justice in the Belmont Report is a part of this idea. Despite the consensus that researchers should return some information to communities, there is no universally recognized authoritative policy on how researchers should return results to communities, and the views and practices of researchers in the field vary widely.\n\nReturning results can be problematic for many reasons, such as increased difficulty of tracking participants who donated a sample as time passes, the conflict with the participant's right to privacy, the inability of researchers to meaningfully explain scientific results to participants, general disinterest of participants to study results, and deciding what constitutes a return of results.\n\nIf genetic testing is done, then researches may get health information about participants, but in many cases there is no plan in place for giving participants information derived from their samples.\n\nBecause donating a specimen involves consideration of many issues, different people will have different levels of understanding of what they are doing when they donate a specimen. Since it is difficult to explain every issue to everyone, problems of giving informed consent arise when researchers take samples.\n\nA special informed consent problem happened historically with biobanks. Previous to the advent of biobanks, researchers would ask specimen donors for consent to participate in a single study, and give participants information about that study. In a biobank system, a researcher may have many specimens collected over many years and then long after the donors gave the sample, that researcher may want to conduct a new study using those samples but have no good way to give donors information about that study and collect their consent. This problem was first identified in widespread publication in 1995 when an article on this topic was published.\n\nMany people have the opportunity to donate samples to medical research in the course of their regular medical care, but there are ethical problems in having one's own doctor request specimens.\n\nResearchers support biobanking despite risk to participants because the benefit is high, it pays respect to people's wishes to involve themselves in research, current practices and culture support this kind of research, and consensus is that the risk of participation is low.\n\nDonors to biobanks frequently do not have a good understanding of the concept of a biobank or the implications of donating a specimen to one.\n"}
{"id": "21311067", "url": "https://en.wikipedia.org/wiki?curid=21311067", "title": "CRISES", "text": "CRISES\n\nLaboratoire CRISES (or \"Centre de recherches interdisciplinaires en sciences humaines et sociales\") is a French research centre in humanities and social sciences, founded in Montpellier, France, in January 2009.\n\nIt brings together about 100 scholars and 200 PhD students working in the field of Humanities and Social Sciences : History, History of Art, Archaeology, Classics, Fine Arts, Law, Political Sciences, Economy, Spanish and French Literature, Educational Sciences, Ethnology, Psychanalysis, Philosophy, Theology. The director of Crises is, for the time being, Frédéric Rousseau (elected in 2008, December), Professor of Contemporary History, University of Montpellier.\n\n"}
{"id": "50899867", "url": "https://en.wikipedia.org/wiki?curid=50899867", "title": "Cipriano Targioni", "text": "Cipriano Targioni\n\nCipriano Targioni (1672–1748) was an Italian scientific instrument maker.\n\nBorn in Florence, Targioni studied medicine at the University of Pisa. On returning to his native town, he was named supervisor of the observations and physical experiments carried out in the Galleria Medicea by order of the Grand Duke of Tuscany, Cosimo III de' Medici. He developed methods for preserving animal corpses for anatomical dissection. Targioni also conducted meteorological observations on a systematic basis beginning in 1728.\n"}
{"id": "44162435", "url": "https://en.wikipedia.org/wiki?curid=44162435", "title": "Context-based model of minimal counterintuitiveness", "text": "Context-based model of minimal counterintuitiveness\n\nThe context-based model of the counterintuitiveness effect is a cognitive model of The Minimal Counterintuitiveness Effect (or MCI-effect for short) i.e., the finding by many cognitive scientists of religion that minimally counterintuitive concepts are more memorable for people than intuitive and maximally counterintuitive concepts The context-based model emphasizes the role played by the context in which a concept appears in making it counterintuitive. This is in contrast to the traditional (also called \"content-based\") accounts of the MCI-effect which underscore the role played by context. Barrett & Nyhoff (2001) claim that this is necessary in order to explain cross-cultural success of religious concepts.\n\nAlthough research on schemas and scripts suggests the possibility that incongruent concepts may be better remembered thus contributing to their transmission, these conceptual structures are culturally variable to a large extent and will not provide an explanation for cross-culturally prevalent classes of concepts.\n\nThe context-based model was first proposed by cognitive scientist Afzal Upal in 2005 and has been subsequently elaborated in a number of publications. According to the context-based model, counterintuitiveness of a concept depends on the mental knowledge activated in the mind of a reader at the time at which the reader processes the concept in question. Since this mental knowledge clearly varies from person to person, a concept that is counterintuitive to one person may not be so for another person. Furthermore, a concept may be counterintuitive to a person at one time but not at another time. In fact the context-based model predicts that since people learn, their conceptual representations change over time. When people encounter a minimally counterintuitive concept for the first time, they are forced to make sense out of it (Upal (2005) labelled it as the \"postdiction\" process). The postdiction process results in the formation of new knowledge structures and in strengthening of existing knowledge structures. Because of these new knowledge structures, when the same concept is encountered again, it does not seem as counterintuitive as it did in the past. The context-based model predicts that over time the counterintuitive concepts come to lose their very counterintuitiveness (and the memory advantages it confers upon the concept).\n"}
{"id": "8477500", "url": "https://en.wikipedia.org/wiki?curid=8477500", "title": "Davorin Dolar", "text": "Davorin Dolar\n\nDavorin Dolar (January 1, 1921 – November 12, 2005) was a Slovenian chemist at the University of Ljubljana. He was a physical chemist who studied polyelectrolyte solutions. He is regarded as a founder of modern physical chemistry teaching in Slovenia. He was a member of the Slovenian Academy of Sciences and Arts.\n\nIn 1939 Dolar began studying chemistry at the University of Ljubljana and then graduated in 1944. In 1947 he enrolled at the University of Leningrad and continued studying physical chemistry. In 1952 he became an assistant professor of physical chemistry in Ljubljana. In 1954 he moved to Brooklyn to work under Professor Greogr at the Polytechnic Institute. In 1957, after returning to Ljubljana, he obtained his PhD. He was appointed an associate professor in 1960, and a professor in 1965. In 1960, while working at the Chair in Physical Chemistry, he started doing research in thermodynamic and transport properties of polyelectrolytic solutions, eventually gaining notability in the field. In 1978 he became a full member of the Slovenian Academy of Sciences and Arts. He received the Boris Kidrič Award in 1979 and the Order of Slovenia in 1988. After retiring from Ljubljana in 1989, he was named a professor emeritus and received a golden plaque from the university in 1993. In 2004, he received the Zois Award for Lifetime Achievement.\n\nWhen deciding what to study at the university, Dolar was torn between mathematics, physics, and chemistry. He ended up choosing chemistry because he wanted to stay near the mountains and there was a factory nearby in need of chemical engineers. Known in his prime as a master mountain climber and mountain rescuer, he continued to hike his entire life.\n\nHis father was Simon Dolar, a popular mathematics professor, who was responsible for inspiring Davorin's love of the sciences.\nFrom his retirement in 1989 to his death in 2005, Dolar remained highly active in the academic community, continuing to advise aspiring chemists until the end of his life.\n"}
{"id": "57999053", "url": "https://en.wikipedia.org/wiki?curid=57999053", "title": "Disease in fiction", "text": "Disease in fiction\n\nDiseases, both real and fictional, play a significant role in fiction, with certain diseases like Huntington's disease and tuberculosis appearing in many books and films. Pandemic plagues threatening all human life, such as \"The Andromeda Strain\", are among the many fictional diseases described in literature and film.\n\nGenuine plagues have formed the central elements of books from Giovanni Boccaccio's c. 1353 \"The Decameron\" onwards. Bocaccio tells the tales of ten people of Florence who escape from the Black Death in their city. The book inspired Geoffrey Chaucer's 14th century \"Canterbury Tales\", which similarly tells the stories of people on pilgrimage in a time of plague. Ingmar Bergman's 1957 film \"The Seventh Seal\" () is set in Denmark during the Black Death, and features a game of chess with Death personified as a monk-like figure.\n\nTuberculosis was a common disease in the 19th century, and it appeared in several major works of Russian literature. Fyodor Dostoevsky used the theme of the consumptive nihilist repeatedly, with Katerina Ivanovna in \"Crime and Punishment\"; Kirillov in \"The Possessed\", and both Ippolit and Marie in \"The Idiot.\" Turgenev did the same with Bazarov in \"Father and Sons\". In English literature of the Victorian era, major tuberculosis novels include Charles Dickens's 1848 \"Dombey and Son\", Elizabeth Gaskell's 1855 \"North and South\", and Mrs. Humphry Ward's 1900 \"Eleanor\".\n\nAlbert Camus's 1947 \"The Plague\", probably based on cholera in 19th century France, was seen both as fable about the need for people to help each other in the meaningless world seen by existentialism, and as alluding to the German invasion of France, fresh in Camus's mind.\n\nHuntington's disease appears in many novels, such as Ian McEwan's 2005 \"Saturday\". It was criticised as prejudiced in the medical journal \"The Lancet\" for its negative portrayal of the protagonist with the disease.\n\nDiseases, especially if infectious, have long been popular themes and plot devices in fiction. Daniel Defoe's pioneering 1722 \"A Journal of the Plague Year\" is a fictional diary of a man's life during the plague year of 1665 in England. Mary Shelley's 1826 \"The Last Man\" created the genre of \"post-apocalyptic pandemic thriller\" with her story of a plague that is spreading across Europe towards her protagonists in Britain. Edgar Allan Poe's 1842 \"The Masque of the Red Death\" is a gothic tale of a plague, perhaps symbolising the hubris of the wealthy, and their nemesis. More recently, Michael Crichton's 1969 \"The Andromeda Strain\" is a science fiction thriller about a world-threatening microbe that a military satellite brings down to Earth and wipes out a town in Arizona. White-coated scientists do their best to contain the outbreak.\n\n\n"}
{"id": "50899369", "url": "https://en.wikipedia.org/wiki?curid=50899369", "title": "Edward Marmaduke Clarke", "text": "Edward Marmaduke Clarke\n\nEdward Marmaduke Clarke (fl. 1830-1850) was an Irish maker of scientific instruments.\n\nHe worked in Dublin and London, 1830-1850, and was important in the forming and running of the London Electrical Society. He was buried in All Souls' Cemetery (Kensall Green), London on 31 January 1859.\n\n"}
{"id": "7698471", "url": "https://en.wikipedia.org/wiki?curid=7698471", "title": "Electronic watch", "text": "Electronic watch\n\nElectronic watch may refer to:\n\n\n"}
{"id": "37427679", "url": "https://en.wikipedia.org/wiki?curid=37427679", "title": "Environmental velocity", "text": "Environmental velocity\n\nIn strategic management and organizational theory, environmental velocity is the rate and direction of change of the notional space in which organizations exist. This \"space\" consists of the political, technological, economic and competitive environment that influences an organization Organizations that can adjust and entrain their activities to suit their environmental velocity will have a competitive advantage over those organizations that can’t.\n\nEisenhardt & Bourgeois (1988) proposed the concept of environmental velocity when studying strategic decision making in the micro-computer industry. They argued that this particular industry could be characterized as having a high-velocity environment, because it exhibited rapid and discontinuous change in demand, competition, technology and regulations. In a number of subsequent studies, it has been determined that success in high-velocity environments is related to fast, formal strategic decision-making processes and the use of heuristic reasoning processes.\n\nIn line with contingency theory, an organization’s environmental velocity dictates the rate at which high performing organizations should adapt. In a study that examined the link between product innovation and organizational change, Eisenhardt and Tabrizi (1995) show that rapid product development facilitates fast organizational change and thus gives firms the capability to keep pace with fast changing environments. Similarly, it has been found that the management of multiple-product innovation projects by firms induces improvisation and experimentation behaviors within these firms. These behaviors help firms to consistently succeed in high-velocity environments.\n\nIn the context of environmental velocity, research has examined the link between firm collective cognition and perceived environmental velocity. That is, how do the collective beliefs and associated practices of a firm shape how members of the firm perceive the velocity conditions of the environment? In a study of firms in the aircraft and semiconductor industries, it was found that environmental velocity is not simply an external and objective condition to which firms react; rather, firms collectively construct their environmental velocity through their social networks, collective assumptions, and environmental scanning approaches (Nadkarni and Narayanan, 2007). Furthermore, firms should employ adaptive scanning and sensemaking approaches to effectively understand and deal with the dynamism in high-velocity environments.\n\nIn a key review of some of the major studies in this area, McCarthy et al. (2010) found that researchers and managers often focus on the rate or speed of change only, treating velocity as a single, latent aspect of the environment, characterized simply as being “high” or “low”. However, the original definition of environmental velocity (Eisenhardt and Bourgeois 1988) defines and describes it as a vector quality, composed of both rate and direction of change across multiple dimensions (e.g., regulations, demand, product, technology, and competition).\n\nMcCarthy et al. (2010) developed a framework that describes the relationships between these multiple velocity dimensions, noting that they may each have a distinct and often different velocity. They define “velocity homology” as the degree to which velocity dimensions have similar rates and directions of change and “velocity coupling” as the degree to which the velocities of different dimensions affect one another. This multidimensional treatment of environmental velocity results in four “velocity regimes” - simple, divergent, conflicted and integrated - based on the patterns of velocity homology and velocity coupling. A key implication of the framework is that firms should not necessarily focus on being uniformly fast (or slow) to suit industry conditions. Each of the four velocity regimes requires firms to maintain different forms of temporal fit (i.e., the entrainment of multiple organizational paces) and temporal coordination (i.e., managing the interdependences between organizational paces).\n\nMcCarthy et al. (2010) explain that each of the velocity regimes they propose is suited to a different temporal orientation, which they define as “how individuals and teams conceive of time\". Specially, they argue that when velocity dimensions are tightly coupled to each (i.e., “the relationship between the velocities of different dimensions involve significant immediate, direct causal effects”), an organization’s capabilities would benefit from a polychronic orientation. In contrast, when velocity regimes are loosely coupled (i.e., “changes in the velocity of one dimension have relatively little immediate, direct impact on the velocities of other dimensions”) an organization’s capabilities would benefit from a monochronic orientation.\n\n"}
{"id": "1055334", "url": "https://en.wikipedia.org/wiki?curid=1055334", "title": "Equatorial mount", "text": "Equatorial mount\n\nAn equatorial mount is a mount for instruments that compensates for Earth's rotation by having one rotational axis parallel to the Earth's axis of rotation. This type of mount is used for astronomical telescopes and cameras. The advantage of an equatorial mount lies in its ability to allow the instrument attached to it to stay fixed on any celestial object with diurnal motion by driving one axis at a constant speed. Such an arrangement is called a sidereal or clock drive.\n\nIn astronomical telescope mounts, the equatorial axis (the \"right ascension\") is paired with a second perpendicular axis of motion (known as the \"declination\"). The equatorial axis of the mount is often equipped with a motorized \"clock drive\", that rotates that axis one revolution every 23 hours and 56 minutes in exact sync with the apparent diurnal motion of the sky. They may also be equipped with setting circles to allow for the location of objects by their celestial coordinates. Equatorial mounts differ from mechanically simpler altazimuth mounts, which require variable speed motion around both axes to track a fixed object in the sky. Also, for astrophotography, the image does not rotate in the focal plane, as occurs with altazimuth mounts when they are guided to track the target's motion, unless a rotating erector prism or other field-derotator is installed.\n\nEquatorial telescope mounts come in many designs. In the last twenty years motorized tracking has increasingly been supplemented with computerized object location. There are two main types. Digital setting circles take a small computer with an object database that is attached to encoders. The computer monitors the telescope's position in the sky. The operator must push the telescope. Go-to systems use (in most cases) servo motors and the operator need not touch the instrument at all to change its position in the sky. The computers in these systems are typically either hand-held in a control \"paddle\" or supplied through an adjacent laptop computer which is also used to capture images from an electronic camera. The electronics of modern telescope systems often include a port for autoguiding. A special instrument tracks a star and makes adjustment in the telescope's position while photographing the sky. To do so the autoguider must be able to issue commands through the telescope's control system. These commands can compensate for very slight errors in the tracking performance, such as periodic error caused by the worm drive that makes the telescope move.\n\nIn new observatory designs, equatorial mounts have been out of favor for decades in large-scale professional applications. Massive new instruments are most stable when mounted in an alt-azimuth (up down, side-to-side) configuration. Computerized tracking and field-derotation are not difficult to implement at the professional level. At the amateur level, however, equatorial mounts remain popular, particularly for astrophotography.\n\nIn the German equatorial mount, (sometimes called a \"GEM\" for short) the primary structure is a T-shape, where the lower bar is the \"right ascension\" axis (lower diagonal axis in image), and the upper bar is the \"declination\" axis (upper diagonal axis in image). The mount was developed by Joseph von Fraunhofer for the Great Dorpat Refractor that was finished in 1824. The telescope is placed on one end of the declination axis (top left in image), and a suitable counterweight on other end of it (bottom right). The right ascension axis has bearings below the T-joint, that is, it is not supported above the declination axis.\n\nThe Open Fork mount has a \"Fork\" attached to a right ascension axis at its base. The telescope is attached to two pivot points at the other end of the fork so it can swing in declination. Most modern mass-produced catadioptric reflecting telescopes (200 mm or larger diameter) tend to be of this type. The mount resembles an Altazimuth mount, but with the azimuth axis tilted and lined up to match earth rotation axis with a piece of hardware usually called a \"wedge\".\n\nMany mid-size professional telescopes also have \"equatorial forks\", these are usually in range of 0.5-2.0 meter diameter.\n\nThe English mount or Yoke mount has a frame or \"yoke\" with \"right ascension\" axis bearings at the top and the bottom ends, and a telescope attached inside the midpoint of the yoke allowing it to swing on the \"declination\" axis. The telescope is usually fitted entirely inside the fork, although there are exceptions such as the Mt. Wilson 2.5 m reflector, and there are no counterweights as with the \"German mount\".\n\nThe original \"English fork\" design is disadvantaged in that it does not allow the telescope to point too near the north or south celestial pole.\n\nThe Horseshoe mount overcomes the design disadvantage of English or Yoke mounts by replacing the polar bearing with an open \"horseshoe\" structure to allow the telescope to access Polaris and stars near it. The Hale telescope is the most prominent example of a Horseshoe mount in use.\n\nThe Cross-axis or English cross axis mount is like a big \"plus\" sign (+). The \"right ascension\" axis is supported at both ends, and the \"declination\" axis is attached to it at approximately midpoint with the telescope on one end of the declination axis and a counter weight on the other.\n\nAn equatorial platform is a specially designed platform that allows any device sitting on it to track on an equatorial axis. It achieves this by having a surface that pivots about a \"virtual polar axis\". This gives equatorial tracking to anything sitting on the platform, from small cameras up to entire observatory buildings. These platforms are often used with altazimuth mounted amateur astronomical telescopes, such as the common Dobsonian telescope type, to overcome that type of mount's inability to track the night sky.\n\n"}
{"id": "2794562", "url": "https://en.wikipedia.org/wiki?curid=2794562", "title": "Functional zoning", "text": "Functional zoning\n\nFunctional zoning or functional city zoning is a method used for dividing land use by its function. Typically, land use is divided in two ways, by its function and by its physical characteristics. An example of functional zoning would be an area that has designated zones based on a function such as an industrial zone, a recreational zone and a residential zone. An example of an area zoned by its physical characteristics is defined in terms of characteristics like development density, minimum lot size, and building coverage, placement and height.\n\nFunctional zoning tends to create or increase car dependency, while mixed-use zoning tends to enable walking, making it more sustainable. It has been criticized for causing the squandering of land, energy, and time.\n"}
{"id": "54225599", "url": "https://en.wikipedia.org/wiki?curid=54225599", "title": "Gemini spacecraft No. 2", "text": "Gemini spacecraft No. 2\n\nGemini spacecraft No. 2 (officially known as \"Gemini SC-2\", for \"space capsule 2\") was the second NASA Project Gemini full-up space capsule built. This McDonnell Gemini capsule was the first ever spacecraft to be reused, flying twice into suborbital space. No.2 flew on missions Gemini-Titan 2 and Manned Orbiting Laboratory Gemini-B flight. The capsule is currently on display at the Smithsonian Institution, in Washington, D.C..\n\nThe capsule is part of the collection of the National Air and Space Museum of the Smithsonian Institution.\n\nOn 19 January 1965, the Gemini-Titan 2 suborbital test mission was launched, with the second prototype Gemini capsule.\n\nIn March 1965, NASA approved the transfer of the Gemini 2 capsule to the USAF for modification into the first prototype of the Gemini B capsule.\n\nOn 3 November 1965, the first Manned Orbiting Laboratory (MOL) and Gemini B suborbital test mission was launched. Thus, it became the only Mercury, Gemini, or Apollo, capsule to be reflown, and the first capsule to ever be space-reflown.\n\nThe capsule was transferred to the Smithsonian Institution, as part of the National Air and Space Museum collection.\n\nThe capsule was put on display in the Allan and Malcolm Lockheed and Glenn Martin Space Gallery at the National Museum of the USAF in 2016.\n\nThe capsule was put on display in the exhibit hall of the Air Force Space and Missile Museum of the USAF in 2017.\n\n\n"}
{"id": "12459101", "url": "https://en.wikipedia.org/wiki?curid=12459101", "title": "Gemmotherapy", "text": "Gemmotherapy\n\nGemmotherapy [from Lat. \"gemma\", bud, and New Lat. \"therapīa\", Grk. \"therapeia\", medical treatment] is a form of herbal medicine that uses remedies made principally from the embryonic tissue of various trees and shrubs (the buds and emerging shoots), but also from the reproductive parts (the seeds and catkins) and from newly grown tissue (the rootlets and the cortex of rootlets). In two instances, remedies are also made from the sap.\n\nThis raw material is taken at the peak time of the tree or shrub’s annual germination, in the spring for buds or the autumn for seeds. Certain plant hormones and enzymes are released during this process, and in some cases are only present in the plant at this time.\n\nThe therapeutic effects of remedies made from the embryonic material of plants were first investigated in the late 1950s by a Belgian homeopath, Pol Henry (1918–88), working with a group of French homeopaths and biotherapists including Max Tétau (1927-2012) and O.A. Julian (1910–84). They conducted the first experiments as well as human and animal clinical trials that elucidated the effects of gemmotherapy and summarized their clinical findings.\n\nHenry initially called the new type of medicine, phytoembryotherapy, but it was Tetau that later coined the phrase gemmotherapy.\n\nGemmotherapy was included in herbal therapies in France in the \"Pharmacopée Francaise\" in 1965.\n"}
{"id": "14164045", "url": "https://en.wikipedia.org/wiki?curid=14164045", "title": "Herpes simplex virus protein vmw65", "text": "Herpes simplex virus protein vmw65\n\nVmw65, also known as VP16 or α-TIF (Trans Inducing Factor) is a trans-acting protein that forms a complex with the host transcription factors Oct-1 and HCF to induce immediate early gene transcription in the herpes simplex viruses.\n"}
{"id": "36953004", "url": "https://en.wikipedia.org/wiki?curid=36953004", "title": "Hiroshige Koyama", "text": "Hiroshige Koyama\n\nHiroshige Koyama (1937–2016) is a Japanese botanist specialist of Asteraceae.\n\n"}
{"id": "37113838", "url": "https://en.wikipedia.org/wiki?curid=37113838", "title": "Index of biodiversity articles", "text": "Index of biodiversity articles\n\nThis is a list of topics in biodiversity.\n\nAbiotic stress —\nAdaptation —\nAgricultural biodiversity —\nAgroecological restoration —\nAll-taxa biodiversity inventory —\nAlpha diversity —\nApplied ecology —\nArca-Net —\nASEAN Center for Biodiversity —\nASEAN Heritage Parks —\nAquatic biomonitoring —\nAxe Lake Swamp State Nature Preserve —\nBank of Natural Capital —\nBeta diversity —\nBioBlitz —\nBiocomplexity —\nBiocultural diversity —\nBiodiversity action plan —\nBiodiversity and drugs —\nBiodiversity and food —\nBiodiversity banking —\nBiodiversity hotspot —\nBiodiversity in Israel, the West Bank, and the Gaza Strip —\nBiodiversity Indicators Partnership —\nBiodiversity informatics —\nBiodiversity of Borneo —\nBiodiversity of Cape Town —\nBiogeography —\nBioindicator —\nBioinformatics —\nBIOPAT - Patrons for Biodiversity —\nBiorisk —\nBiosafety Clearing-House —\nBioSearch —\nBiosurvey —\nBioWeb —\nBody size and species richness —\nBox corer —\nBray–Curtis dissimilarity — \nCaribbean Initiative —\nCarta di Siracusa on Biodiversity —\nCartagena Protocol on Biosafety —\nCenter for Biological Diversity —\nCentres of Plant Diversity —\nChresonym —\nComisión Nacional para el Conocimiento y Uso de la Biodiversidad —\nConservation Biology —\nConservation Commons —\nConservation ethic —\nConservation in Papua New Guinea —\nConservation reliant species —\nConservation status —\nConvention on Biological Diversity —\nCritically Endangered —\nCrop diversity —\n\nData Deficient —\nDeforestation —\nDiversitas —\nDiversity-function debate —\nDiversity index —\n\nECNC-European Centre for Nature Conservation —\nEcological economics —\nEcological effects of biodiversity —\nEcological goods and services —\nEcological restoration —\nEcology —\nEconomics of biodiversity —\nEcosystem diversity —\nEffect of climate change on plant biodiversity —\nEichler's rule —\nEndemic Species in Slovakia —\nEndemism —\nEnzootic —\nEthnic diversity —\nEwens sampling formula —\nExtinct in the Wild —\nExtinction —\n\nFelidae Conservation Fund —\nFlora and vegetation of Turkey —\nForest farming —\nFunctional agrobiodiversity —\n\nGamma diversity —\nGene pool —\nGenetic diversity —\nGenetic erosion —\nGenetic pollution —\nGlobal 200 —\nGlobal Biodiversity Information Facility —\nGlobal biodiversity —\nGlobal Crop Diversity Trust —\nGlobal warming —\nGreen Revolution —\n\nHabitat conservation —\nHabitat fragmentation —\nHeirloom plant —\nHeirloom tomato —\nHolocene extinction event —\n\nIndicator species —\nIndicator value —\nIntact forest landscape —\nInter-American Biodiversity Information Network —\nIntergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services —\nIntermediate Disturbance Hypothesis —\nInternational Cooperative Biodiversity Group —\nInternational Council for Game and Wildlife Conservation —\nInternational Day for Biological Diversity —\nInternational Institute of Tropical Agriculture —\nInternational Mechanism of Scientific Expertise on Biodiversity —\nInternational Treaty on Plant Genetic Resources for Food and Agriculture —\nInternational Union for Conservation of Nature —\nInternational Year of Biodiversity —\nInsect biodiversity —\nIUCN Red List —\nIUCN Red List vulnerable species (list) —\n\nKey Biodiversity Areas -\n\nLand use, land-use change and forestry —\nLangtang National Park —\nLatitudinal gradients in species diversity —\nLeast Concern —\nList of biodiversity databases —\nList of environmental issues —\nList of environmental topics —\nLivestock Keepers' Rights —\nLiving Planet Index —\nLocal Biodiversity Action Plan —\n\nMan and the Biosphere Programme —\nMeasurement of biodiversity —\nMegadiverse countries —\nMillennium Ecosystem Assessment —\nMillennium Seed Bank Project —\nMonoculture —\nMonodominance —\nMutation —\n\nNaGISA —\nNational Biodiversity Centre (Singapore) —\nNational Biodiversity Network —\nNational Biological Information Infrastructure —\nNative Vegetation Management Framework —\nNatural environment —\nNatural heritage —\nNatural landscape —\nNature —\nNature Conservation Act vulnerable flora of Queensland (list) —\nNatureServe —\nNatureServe conservation status —\nNear Threatened —\nNiche apportionment models —\nNot Evaluated —\nNutritional biodiversity —\n\nOccupancy–abundance relationship \nOrganic farming and biodiversity —\n\nPark Grass Experiment —\nParsa National Park —\nPhylogenetic diversity —\nPlant Resources of Tropical Africa —\n\nRange condition scoring —\nRank abundance curve —\nRare species —\nRarefaction (ecology) —\nReconciliation ecology —\nRECOrd (Local Biological Records Centre) —\nRegional Red List —\nRelative species abundance —\nRenkonen similarity index —\n\nSatoyama —\nSAVE Foundation —\nSeedbank —\nSeedy Sunday —\nShivapuri Nagarjun National Park —\nSoil biodiversity —\nSpecies evenness —\nSpecies richness —\nSubsurface Lithoautotrophic Microbial Ecosystem —\nSustainability —\nSustainable development —\nSustainable forest management —\n\nThe Economics of Ecosystems and Biodiversity —\nThreatened species —\n\nUnified neutral theory of biodiversity —\nUnited Nations Decade on Biodiversity —\nUniversity of California, Riverside Herbarium —\n\n —\nVulnerable flora of Queensland, Nature Conservation Act list —\nVulnerable species —\nVulnerable species, IUCN Red List —\n\nWild Solutions —\nWildlife preserve —\nWooded meadow —\nWorld Conservation Monitoring Centre —\nWorld Conservation Union —\nWorld Forestry Congress —\nWorld Network of Biosphere Reserves —\n\nYasuni National Park\n\n"}
{"id": "37760976", "url": "https://en.wikipedia.org/wiki?curid=37760976", "title": "Infologs", "text": "Infologs\n\nInfologs are independently designed synthetic genes derived from one or a few genes where substitutions are systematically incorporated to maximize information. Infologs are designed for perfect diversity distribution to maximize search efficiency.\n\nTypical protein engineering methods rely on screening a high number (10-10 or more) of gene variants to identify individuals with improved activity using a surrogate high throughput screen (HTP) to identify initial hits. Unfortunately, results are defined by what is screened for, thus the “hit” from the HTP screen often has very little real activity in a lower throughput assay more indicative of the improved functionality for which the protein is being developed. By adapting the standard algorithms for engineering complex systems to work with biological systems, the resulting process enables researchers to deconvolute how substitutions within a protein sequence modify its function. Combining these algorithms with an integrated query and ranking mechanism allows the identification of appropriate sequence substitutions. Infologs refers to the set of designed genes, singular use Infolog describes an individual variant.\n\nHomology between protein or DNA sequences is defined in terms of shared ancestry. Two segments of DNA can have shared ancestry because of either a speciation event (orthologs) or a duplication event (paralogs).\n\nHomologs are similar genes and/or proteins which are related by ancestry.\n\nOrthologs are the 'same' gene, but from different organisms. Homologous sequences are orthologous if they were separated by a speciation event: when a species diverges into two separate species, the copies of a single gene in the two resulting species are said to be orthologous. Orthologs, or orthologous genes, are genes in different species that originated by vertical descent from a single gene of the last common ancestor. The term \"ortholog\" was coined in 1970 by Walter Fitch.\nParalogs are related genes originating from one gene that through duplication ended up as two genes that over time has evolved for two separate functions (or, according to a recent Science paper, a promiscuous starting gene that duplicated and each copy evolved towards different functions). Paralogs typically have the same or similar function, but sometimes do not: due to lack of the original selective pressure upon one copy of the duplicated gene, this copy is free to mutate and acquire new functions. Paralogs usually occur from within the same species.\nXenologs are homologs resulting from horizontal gene transfer between two organisms. Xenologs can have different functions, if the new environment is vastly different for the horizontally moving gene. In general, though, xenologs typically have similar function in both organisms.\n\nInfologs are similar genes and/or proteins which are related by synthetic ancestry to approach perfect diversity distribution.\n\n\nTransforming Protein engineering with Infologs:\n\nUsing independently designed synthetic genes where substitutions are systematically incorporated (Infologs) leads to uniform sampling, systematic variance and unrestricted information rich results. Wheat Glutathione S-transferases (GST) with the ability to detoxify a panel of common herbicides was designed using this patented bioengineering method. The relative functional contribution of 60 amino acid substitutions against 14 herbicides was quantified using only 96 Infologs and dramatically improved by a small set (16) of 2nd generation Infologs. In addition, highly predictable GST sequence-function models against two commercially relevant herbicides were created with quantification of relative functional contribution of 60 amino acid substitutions in two dimensions.\n\nIn rational protein design, the scientist uses detailed knowledge of the structure and function of the protein to make desired changes. This generally has the advantage of being technically easy and inexspensive, since site-directed mutagenesis techniques are well-developed. However, its major drawback is that detailed structural knowledge of a protein is often unavailable, and even when it is available, it can be extremely difficult to predict the effects of various mutations.\n\nComputational protein design algorithms seek to identify novel amino acid sequences that are low in energy when folded to the pre-specified target structure. While the sequence-conformation space that needs to be searched is large, the most challenging requirement for computational protein design is a fast, yet accurate, energy function that can distinguish optimal sequences from similar suboptimal ones.\n\n\n\n"}
{"id": "18424449", "url": "https://en.wikipedia.org/wiki?curid=18424449", "title": "International Committee on Intellectual Cooperation", "text": "International Committee on Intellectual Cooperation\n\nThe International Committee on Intellectual Cooperation (sometimes League of Nations Committee on Intellectual Cooperation) was an advisory organization for the League of Nations which aimed to promote international exchange between scientists, researchers, teachers, artists and intellectuals. Established in 1922, it counted such figures as Henri Bergson, Albert Einstein, Marie Curie, Gonzague de Reynold and Robert A. Millikan among its members. The Committee was the predecessor to UNESCO, and all of its properties were transferred to that organisation in 1946.\n\nThe International Committee on Intellectual Cooperation (CICI) was formally established in August 1922. Having started out with 12 members, its membership later grew to 19 individuals. The first session was held on August 1st 1922, under the chairmanship of Henri Bergson. During its lifetime, the committee attracted a variety of prominent members, for instance Albert Einstein, Marie Curie, Kristine Bonnevie, Jules Destrée, Robert Andrews Millikan, Alfredo Rocco, Paul Painlevé, Gonzague de Reynold, Jagadish Chandra Bose and Sarvepalli Radhakrishnan. Einstein resigned in 1923, protesting publicly the committee's inefficacy; he rejoined in 1924 to mitigate the use German chauvinists made of his resignation. The body was successively chaired by:\nThe CICI maintained a number of sub-committees (e.g. Museums, Arts and Letters, Intellectual Rights or Bibliography) which also worked with figures such as Béla Bartók, Thomas Mann, Salvador de Madariaga and Paul Valéry.\n\nThe CICI worked closely with the International Educational Cinematographic Institute created in Rome in 1928 by the Italian government under Mussolini.\n\nThe last session took place in 1939, but the CICI was only formally dissolved in 1946, like the League of Nations.\n\nIn order to support the work of the commission in Geneva, the organization was offered assistance from France to establish an executive branch, the International Institute of Intellectual Cooperation (IIIC), in Paris in 1926. However, the IIIC had an autonomous status and was almost only financed by the French Government. It maintained relations with the League's member states, which established national commissions for intellectual cooperation and appointed delegates to represent their interests at the Institute in Paris. While being an international organisation, each of the IIIC's three successive directors was French:\nFrom 1926 to 1930, Alfred Zimmern – the well-known British classicist and a pioneering figure in the discipline of international relations – served as the IIIC's Deputy Director. \n\nAs a result of the Second World War, the Institute was closed from 1940 to 1944. It re-opened briefly from 1945 to 1946. When it closed for good in 1946, UNESCO inherited its archives and some parts of its mission.\n\n\n\n"}
{"id": "28813979", "url": "https://en.wikipedia.org/wiki?curid=28813979", "title": "Israeli Children", "text": "Israeli Children\n\nIsraeli Children is a political organization aimed at stopping the deportation of non-Jewish Israel-born children from Israel. About 1200 children of migrant workers to Israel are scheduled to be deported.\n"}
{"id": "15563071", "url": "https://en.wikipedia.org/wiki?curid=15563071", "title": "Kaitai Shinsho", "text": "Kaitai Shinsho\n\nOn 4 March 1771, the eighth year of Meiwa, the students of Rangaku medicine Sugita Genpaku, Maeno Ryōtaku, Nakagawa Jun'an, \"et al.\", by studying performing autopsies on criminals executed at the Kozukappara execution grounds (now, there is a possibility that Katsuragawa Hoshū was at this facility as well, but from the description in , it seems more likely that he was not). Both Sugita and Maeno had the book \"Ontleedkundige Tafelen\", imported from Holland. Sugita, marveling at the accuracy of the work while comparing it by eye with his autopsies, proposed to Maeno that it be translated. For some time, Sugita had a desire to translate something from Dutch; now he would get approval for this. He met with Maeno the very next day (5 March) and began translation. The one who recommended \"Kaitai Shinsho\" to the \"shōgun\" was Katsuragawa Hosan.\n\nAt first, Sugita and Nakagawa could not actually read Dutch; even with Maeno who could, their Dutch vocabulary was inadequate. It would have been difficult for them to consult with the Dutch translations and translators (Tsūji) in Nagasaki, and naturally there were no dictionaries at the time. A translation from any other Western language would have been out of the question, as the government of the time did not allow contact with any other Western nation. Therefore, in a process comparable to cryptanalysis, they progressed with translation work. In his later years, Sugita would detail the process in \"Rangaku Koto Hajime\".\n\nIn the second year of An'ei (1773), as they arrived at a translation goal, in order to ascertain society’s response, they released the , a five-page flyer.\n\nIn 1774, \"Kaitai Shinsho\" was published.\n\nMaeno Ryōtaku was at the center of the translation work, but there is not a name as to the author of the \"Kaitai Shinsho\". By one account, Maeno was on the way to study at Nagasaki; when he prayed at a Tenman-gū for the fulfillment of his studies, he vowed not to study in order to raise his own name, so he abstained from submitting it. By another account, since he knew that the completed works were not completely perfect, the academic Maeno could not submit his name in good conscience. Sugita Genpaku said, \"I am sickly and numbered in years as well. I do not know when I will die.\" While he knew the translation was imperfect in places, he rushed to publish. The publication of \"Anatomic Illustrations\" was also Sugita’s design; in regard to this, Maeno is said to have had shown dislike for it. However, the man would actually go on to live an extremely long life for the time (he lived to the age of eighty-five). Unsure of when he would die and unsure of whether the government would approve the distribution of the Western ideas, it could be said this was a risky but important move.\n\nNakagawa Jun'an, after \"Kaitai Shinsho\"’s publication, also continued his study of Dutch, along with Katsuragawa Hoshū, and took on the natural history of Sweden according to Thunberg. Katsuragawa Hosan was a same-generation friend of Sugita's. With his status as a hōgen, he served as a court physician to the \"shōgun\". He was not a direct influence on the translation work itself, though his son Hoshū did participate. Also, he provided for the supplementary materials that amounted to three volumes of Dutch medical texts. Upon the publishing of \"Kaitai Shinsho\", since there was a possibility that it encroached on the Bakufu’s taboos, Katsuragawa was the one who ran it by the Ōoku. Katsuragawa Hoshū was the son of the hōgen Katsuragawa Hosan, and would become a hōgen himself later on. He is said to have been involved with the translation work from early on. Afterwards, he would serve to develop rangaku along with Ōtsuki Gentaku.\n\nThere are others that had to do with the translation work, like Ishikawa Genjō, whose name appears in the opening pages, Toriyama Shōen, Kiriyama Shōtetsu, and Mine Shuntai (among others) whose names appear in \"Rangaku Koto Hajime\". Yoshio Kōgyū (posthumously Yoshio Nagaaki) was a Dutch tsūji. He wrote the preface to \"Kaitai Shinsho\", and admired what he felt to be Sugita and Maeno’s masterpiece. Hiraga Gennai, on Shōgatsu of the third year of An'ei, visited the home of Sugita Genpaku. The translation of \"Kaitai Shinsho\"’s text was nearly complete, and he was informed that they were looking for an artist for the dissection figures. Odano Naotake was a \"bushi\" from Kakunodate in the Akita Domain, and the artist. By Hiraga Gennai's referral, he got to drawing \"Kaitai Shinsho\"s figures off the original pictures. Until \"Kaitai Shinsho\"s first edition, it took the short time of half a year. It was his first time working in Edo, and yet it was historical record-setting work for Japanese science.\n\n\"Kaitai Shinsho\" is generally said to be a translation of \"Ontleedkundige Tafelen\". However, other than the work itself, Bartholini's, Blankaart's, Schamberger’s, Koyter’s, Veslingius', Palfijn's, and others' works were also consulted; the cover is based on Valuerda's. Of course, Asian sources and opinions also had an influence.\n\nThe book is not a mere translation; the translation was done mostly by doctors like Sugita, who had to decipher and reconstruct the contents. There are notes in various places left by Sugita, as leftovers from the work.\n\nThe contents are split into four volumes:\n\n\nThe illustrations only comprise one volume.\n\nAfter the publication of the \"Kaitai Shinsho\", there was besides the development in medical science, the progress of the comprehension of the Dutch language. Also, it is important to note that Japan, even under its extreme isolationist policies, still had some foundation to understand the products of Western culture. It also helped to give a chance for promotion for such talents as those of Ōtsuki Gentaku.\n\nIn translation, some words had to be coined (that is, there were no Japanese words that existed for them prior to the work). Some of them, such as the terms for , , and are still used to this day as a result.\n\nThe fact that this was a first translation means that minor misunderstandings were practically unavoidable. There are many mistranslations in the \"Kaitai Shinsho\"; later on, Ōtsuki Gentaku retranslated it and released the in the ninth year of Bunsei (1826).\n\nIn his last years, Sugita Genpaku would write about the work on \"Kaitai Shinsho\" in .\n\n\n\n"}
{"id": "1635", "url": "https://en.wikipedia.org/wiki?curid=1635", "title": "Kolmogorov complexity", "text": "Kolmogorov complexity\n\nIn algorithmic information theory (a subfield of computer science and mathematics), the Kolmogorov complexity of an object, such as a piece of text, is the length of the shortest computer program (in a predetermined programming language) that produces the object as output. It is a measure of the computational resources needed to specify the object, and is also known as descriptive complexity, Kolmogorov–Chaitin complexity, algorithmic complexity, algorithmic entropy, or program-size complexity. It is named after Andrey Kolmogorov, who first published on the subject in 1963.\n\nThe notion of Kolmogorov complexity can be used to state and prove impossibility results akin to Cantor's diagonal argument, Gödel's incompleteness theorem, and Turing's halting problem.\nIn particular, for almost all objects, it is not possible to compute even a lower bound for its Kolmogorov complexity (Chaitin 1964), let alone its exact value.\n\nConsider the following two strings of 32 lowercase letters and digits.\n\nThe first string has a short English-language description, namely \"ab 16 times\", which consists of 11 characters. The second one has no obvious simple description (using the same character set) other than writing down the string itself, which has 32 characters.\n\nMore formally, the complexity of a string is the length of the shortest possible description of the string in some fixed universal description language (the sensitivity of complexity relative to the choice of description language is discussed below). It can be shown that the Kolmogorov complexity of any string cannot be more than a few bytes larger than the length of the string itself. Strings like the \"abab\" example above, whose Kolmogorov complexity is small relative to the string's size, are not considered to be complex.\n\nThe Kolmogorov complexity can be defined for any mathematical object, but for simplicity the scope of this article is restricted to strings. We must first specify a description language for strings. Such a description language can be based on any computer programming language, such as Lisp, Pascal, or Java virtual machine bytecode. If P is a program which outputs a string \"x\", then P is a description of \"x\". The length of the description is just the length of P as a character string, multiplied by the number of bits in a character (e.g. 7 for ASCII).\n\nWe could, alternatively, choose an encoding for Turing machines, where an \"encoding\" is a function which associates to each Turing Machine M a bitstring <M>. If M is a Turing Machine which, on input \"w\", outputs string \"x\", then the concatenated string <M> \"w\" is a description of \"x\". For theoretical analysis, this approach is more suited for constructing detailed formal proofs and is generally preferred in the research literature. In this article, an informal approach is discussed.\n\nAny string \"s\" has at least one description. For example, the second string above is output by the program:\n\nwhere the first string is output by the (much shorter) pseudo-code:\n\nIf a description \"d\"(\"s\") of a string \"s\" is of minimal length (i.e. it uses the fewest bits), it is called a minimal description of \"s\". Thus, the length of \"d\"(\"s\") (i.e. the number of bits in the description) is the Kolmogorov complexity of \"s\", written \"K\"(\"s\"). Symbolically,\n\nThe length of the shortest description will depend on the choice of description language; but the effect of changing languages is bounded (a result called the \"invariance theorem\"). The standard textbook is authored by Ming Li and Paul Vitanyi \nin the references.\n\nThere are some description languages which are optimal, in the following sense: given any description of an object in a description language, said description may be used in the optimal description language with a constant overhead. The constant depends only on the languages involved, not on the description of the object, nor the object being described.\n\nHere is an example of an optimal description language. A description will have two parts:\n\n\nIn more technical terms, the first part of a description is a computer program, with the second part being the input to that computer program which produces the object as output.\n\nThe invariance theorem follows: Given any description language \"L\", the optimal description language is at least as efficient as \"L\", with some constant overhead.\n\nProof: Any description \"D\" in \"L\" can be converted into a description in the optimal language by first describing \"L\" as a computer program \"P\" (part 1), and then using the original description \"D\" as input to that program (part 2). The\ntotal length of this new description \"D′\" is (approximately):\n\nThe length of \"P\" is a constant that doesn't depend on \"D\". So, there is at most a constant overhead, regardless of the object described. Therefore, the optimal language is universal up to this additive constant.\n\nTheorem: If \"K\" and \"K\" are the complexity functions relative to Turing complete description languages \"L\" and \"L\", then there is a constant \"c\" – which depends only on the languages \"L\" and \"L\" chosen – such that\n\nProof: By symmetry, it suffices to prove that there is some constant \"c\" such that for all strings \"s\"\n\nNow, suppose there is a program in the language \"L\" which acts as an interpreter for \"L\":\n\nwhere \"p\" is a program in \"L\". The interpreter is characterized by the following property:\n\nThus, if P is a program in \"L\" which is a minimal description of \"s\", then codice_3(P) returns the string \"s\". The length of this description of \"s\" is the sum of\n\n\nThis proves the desired upper bound.\n\nAlgorithmic information theory is the area of computer science that studies Kolmogorov complexity and other complexity measures on strings (or other data structures).\n\nThe concept and theory of Kolmogorov Complexity is based on a crucial theorem first discovered by Ray Solomonoff, who published it in 1960, describing it in \"A Preliminary Report on a General Theory of Inductive Inference\" as part of his invention of algorithmic probability. He gave a more complete description in his 1964 publications, \"A Formal Theory of Inductive Inference,\" Part 1 and Part 2 in \"Information and Control\".\n\nAndrey Kolmogorov later independently published this theorem in \"Problems Inform. Transmission\" in 1965. Gregory Chaitin also presents this theorem in \"J. ACM\" – Chaitin's paper was submitted October 1966 and revised in December 1968, and cites both Solomonoff's and Kolmogorov's papers.\n\nThe theorem says that, among algorithms that decode strings from their descriptions (codes), there exists an optimal one. This algorithm, for all strings, allows codes as short as allowed by any other algorithm up to an additive constant that depends on the algorithms, but not on the strings themselves. Solomonoff used this algorithm, and the code lengths it allows, to define a \"universal probability\" of a string on which inductive inference of the subsequent digits of the string can be based. Kolmogorov used this theorem to define several functions of strings, including complexity, randomness, and information.\n\nWhen Kolmogorov became aware of Solomonoff's work, he acknowledged Solomonoff's priority. For several years, Solomonoff's work was better known in the Soviet Union than in the Western World. The general consensus in the scientific community, however, was to associate this type of complexity with Kolmogorov, who was concerned with randomness of a sequence, while Algorithmic Probability became associated with Solomonoff, who focused on prediction using his invention of the universal prior probability distribution. The broader area encompassing descriptional complexity and probability is often called Kolmogorov complexity. The computer scientist Ming Li considers this an example of the Matthew effect: \"…to everyone who has more will be given…\"\n\nThere are several other variants of Kolmogorov complexity or algorithmic information. The most widely used one is based on self-delimiting programs, and is mainly due to Leonid Levin (1974).\n\nAn axiomatic approach to Kolmogorov complexity based on Blum axioms (Blum 1967) was introduced by Mark Burgin in the paper presented for publication by Andrey Kolmogorov.\n\nIn the following discussion, let \"K\"(\"s\") be the complexity of the string \"s\".\n\nIt is not hard to see that the minimal description of a string cannot be too much larger than the string itself — the program codice_6 above that outputs \"s\" is a fixed amount larger than \"s\".\n\nTheorem: There is a constant \"c\" such that\n\nTheorem: There exist strings of arbitrarily large Kolmogorov complexity. Formally: for each \"n\" ∈ ℕ, there is a string \"s\" with \"K\"(\"s\") ≥ \"n\".\n\nProof: Otherwise all of the infinitely many possible finite strings could be generated by the finitely many programs with a complexity below \"n\" bits.\n\nTheorem: \"K\" is not a computable function. In other words, there is no program which takes a string \"s\" as input and produces the integer \"K\"(\"s\") as output.\n\nThe following indirect proof uses a simple Pascal-like language to denote programs; for sake of proof simplicity assume its description (i.e. an interpreter) to have a length of bits.\nAssume for contradiction there is a program\n\nwhich takes as input a string \"s\" and returns \"K\"(\"s\"); for sake of proof simplicity, assume the program's length to be bits.\nNow, consider the following program of length bits:\n\nUsing codice_7 as a subroutine, the program tries every string, starting with the shortest, until it returns a string with Kolmogorov complexity at least bits, i.e. a string that cannot be produced by any program shorter than bits. However, the overall length of the above program that produced \"s\" is only bits, which is a contradiction. (If the code of codice_7 is shorter, the contradiction remains. If it is longer, the constant used in codice_9 can always be changed appropriately.)\n\nThe above proof uses a contradiction similar to that of the Berry paradox: \"The smallest positive integer that cannot be defined in fewer than twenty English words\". It is also possible to show the non-computability of \"K\" by reduction from the non-computability of the halting problem \"H\", since \"K\" and \"H\" are Turing-equivalent.\n\nThere is a corollary, humorously called the \"full employment theorem\" in the programming language community, stating that there is no perfect size-optimizing compiler.\n\nAt first glance it might seem trivial to write a program which can compute \"K\"(\"s\") for any \"s\" (thus disproving the above theorem), such as the following:\n\nThis program iterates through all possible programs (by iterating through all possible strings and only considering those which are valid programs), starting with the shortest. Each program is executed to find the result produced by that program, comparing it to the input \"s\". If the result matches the length of the program is returned.\n\nHowever this will not work because some of the programs \"p\" tested will not terminate, e.g. if they contain infinite loops. There is no way to avoid all of these programs by testing them in some way before executing them due to the non-computability of the halting problem.\n\nThe chain rule for Kolmogorov complexity states that\n\nIt states that the shortest program that reproduces \"X\" and \"Y\" is no more than a logarithmic term larger than a program to reproduce \"X\" and a program to reproduce \"Y\" given \"X\". Using this statement, one can define an analogue of mutual information for Kolmogorov complexity.\n\nIt is straightforward to compute upper bounds for \"K\"(\"s\") – simply compress the string \"s\" with some method, implement the corresponding decompressor in the chosen language, concatenate the decompressor to the compressed string, and measure the length of the resulting string – concretely, the size of a self-extracting archive in the given language.\n\nA string \"s\" is compressible by a number \"c\" if it has a description whose length does not exceed |\"s\"| − \"c\" bits. This is equivalent to saying that \"K\"(\"s\") ≤ |\"s\"| − \"c\". Otherwise, \"s\" is incompressible by \"c\". A string incompressible by 1 is said to be simply \"incompressible\" – by the pigeonhole principle, which applies because every compressed string maps to only one uncompressed string, incompressible strings must exist, since there are 2 bit strings of length \"n\", but only 2 − 1 shorter strings, that is, strings of length less than \"n\", (i.e. with length 0, 1, …, \"n − 1).\n\nFor the same reason, most strings are complex in the sense that they cannot be significantly compressed – their \"K\"(\"s\") is not much smaller than |\"s\"|, the length of \"s\" in bits. To make this precise, fix a value of \"n\". There are 2 bitstrings of length \"n\". The uniform probability distribution on the space of these bitstrings assigns exactly equal weight 2 to each string of length \"n\".\n\nTheorem: With the uniform probability distribution on the space of bitstrings of length \"n\", the probability that a string is incompressible by \"c\" is at least 1 − 2 + 2.\n\nTo prove the theorem, note that the number of descriptions of length not exceeding \"n\" − \"c\" is given by the geometric series:\n\nThere remain at least\n\nbitstrings of length \"n\" that are incompressible by \"c\". To determine the probability, divide by 2.\n\nWe know that, in the set of all possible strings, most strings are complex in the sense that they cannot be described in any significantly \"compressed\" way. However, it turns out that the fact that a specific string is complex cannot be formally proven, if the complexity of the string is above a certain threshold. The precise formalization is as follows. First, fix a particular axiomatic system S for the natural numbers. The axiomatic system has to be powerful enough so that, to certain assertions A about complexity of strings, one can associate a formula F in S. This association must have the following property:\n\nIf F is provable from the axioms of S, then the corresponding assertion A must be true. This \"formalization\" can be achieved, either by an artificial encoding such as a Gödel numbering, or by a formalization which more clearly respects the intended interpretation of S.\n\nTheorem: There exists a constant \"L\" (which only depends on the particular axiomatic system and the choice of description language) such that there does not exist a string \"s\" for which the statement\n\ncan be proven within the axiomatic system S.\n\nNote that, by the abundance of nearly incompressible strings, the vast majority of those statements must be true.\n\nThe proof of this result is modeled on a self-referential construction used in Berry's paradox. The proof is by contradiction. If the theorem were false, then\n\nWe can find an effective enumeration of all the formal proofs in S by some procedure\n\nwhich takes as input \"n\" and outputs some proof. This function enumerates all proofs. Some of these are proofs for formulas we do not care about here, since every possible proof in the language of S is produced for some \"n\". Some of these are complexity formulas of the form \"K\"(\"s\") ≥ \"n\" where \"s\" and \"n\" are constants in the language of S. There is a program\n\nwhich determines whether the \"n\"th proof actually proves a complexity formula \"K\"(\"s\") ≥ \"L\". The strings \"s\", and the integer \"L\" in turn, are computable by programs:\n\nConsider the following program\n\nGiven an \"n\", this program tries every proof until it finds a string and a proof in the formal system S of the formula \"K\"(\"s\") ≥ \"L\" for some \"L\" ≥ \"n\". The program terminates by our Assumption (X). Now, this program has a length \"U\". There is an integer \"n\" such that \"U\" + log(\"n\") + \"C\" < \"n\", where \"C\" is the overhead cost of\n\n(note that \"n\" is hard-coded into the above function, and the summand log(\"n\") already allows for its encoding). The program GenerateProvablyParadoxicalString outputs a string \"s\" for which there exists an \"L\" such that \"K\"(\"s\") ≥ \"L\" can be formally proved in S with \"L\" ≥ \"n\". In particular, \"K\"(\"s\") ≥ \"n\" is true. However, \"s\" is also described by a program of length \"U\" + log(\"n\") + \"C\", so its complexity is less than \"n\". This contradiction proves Assumption (X) cannot hold.\n\nSimilar ideas are used to prove the properties of Chaitin's constant.\n\nThe minimum message length principle of statistical and inductive inference and machine learning was developed by C.S. Wallace and D.M. Boulton in 1968. MML is Bayesian (i.e. it incorporates prior beliefs) and information-theoretic. It has the desirable properties of statistical invariance (i.e. the inference transforms with a re-parametrisation, such as from polar coordinates to Cartesian coordinates), statistical consistency (i.e. even for very hard problems, MML will converge to any underlying model) and efficiency (i.e. the MML model will converge to any true underlying model about as quickly as is possible). C.S. Wallace and D.L. Dowe (1999) showed a formal connection between MML and algorithmic information theory (or Kolmogorov complexity).\n\n\"Kolmogorov randomness\" defines a string (usually of bits) as being random if and only if it is shorter than any computer program that can produce that string. To make this precise, a universal computer (or universal Turing machine) must be specified, so that \"program\" means a program for this universal machine. A random string in this sense is \"incompressible\" in that it is impossible to \"compress\" the string into a program whose length is shorter than the length of the string itself. A counting argument is used to show that, for any universal computer, there is at least one algorithmically random string of each length. Whether any particular string is random, however, depends on the specific universal computer that is chosen.\n\nThis definition can be extended to define a notion of randomness for \"infinite\" sequences from a finite alphabet. These algorithmically random sequences can be defined in three equivalent ways. One way uses an effective analogue of measure theory; another uses effective martingales. The third way defines an infinite sequence to be random if the prefix-free Kolmogorov complexity of its initial segments grows quickly enough — there must be a constant \"c\" such that the complexity of an initial segment of length \"n\" is always at least \"n\"−\"c\". This definition, unlike the definition of randomness for a finite string, is not affected by which universal machine is used to define prefix-free Kolmogorov complexity.\n\nFor dynamical systems, entropy rate and algorithmic complexity of the trajectories are related by a theorem of Brudno, that the equality K(x;T) = h(T) holds for almost all x.\n\nIt can be shown that for the output of Markov information sources, Kolmogorov complexity is related to the entropy of the information source. More precisely, the Kolmogorov complexity of the output of a Markov information source, normalized by the length of the output, converges almost surely (as the length of the output goes to infinity) to the entropy of the source.\n\nThe notion of Kolmogorov complexity has been used to evaluate the complexity of geographical areas from maps or from field observations.\n\nThe conditional Kolmogorov complexity of two strings formula_1 is, roughly speaking, defined as the Kolmogorov complexity of \"x\" given \"y\" as an auxiliary input to the procedure.\n\nThere is also a length-conditional complexity formula_2, which is the complexity of \"x\" given the length of \"x\" as known/input.\n\n\n\n"}
{"id": "31736382", "url": "https://en.wikipedia.org/wiki?curid=31736382", "title": "Life (David E. Sadava book)", "text": "Life (David E. Sadava book)\n\nLife, by David E. Sadava et al, is a 1983 biological science textbook, under continual revision, used at many colleges and universities around the United States of America. As of 2016, it is in its eleventh edition. It is published by W.H. Freeman through MacMillan Learning.\n"}
{"id": "55591948", "url": "https://en.wikipedia.org/wiki?curid=55591948", "title": "List of Serbian inventors and discoverers", "text": "List of Serbian inventors and discoverers\n\nThis is a List of Serbian inventors and discoverers, working locally or overseas. The list comprises people from Serbia and ethnic Serb people.\n\n\n\n\n\n\n"}
{"id": "555747", "url": "https://en.wikipedia.org/wiki?curid=555747", "title": "List of chemical compounds with unusual names", "text": "List of chemical compounds with unusual names\n\nChemical nomenclature, replete as it is with compounds with complex names, is a repository for some very peculiar and sometimes startling names. A browse through the \"Physical Constants of Organic Compounds\" in the \"CRC Handbook of Chemistry and Physics\" (a fundamental resource) will reveal not just the whimsical work of chemists, but the sometimes peculiar compound names that occur as the consequence of simple juxtaposition. Some names derive legitimately from their chemical makeup, from the geographic region where they may be found, the plant or animal species from which they are isolated or the name of the discoverer.\n\nSome are given intentionally unusual trivial names based on their structure, a notable property or at the whim of those who first isolate them. However, many trivial names predate formal naming conventions. Trivial names can also be ambiguous or carry different meanings in different industries, geographic regions and languages.\n\nGodly noted that \"Trivial names having the status of INN or ISO are carefully tailor-made for their field of use and are internationally accepted\". In his preface to \"Chemical Nomenclature\", Thurlow wrote that \"Chemical names do not have to be deadly serious\". A website in existence since 1997 and maintained at the University of Bristol lists a selection of \"molecules with silly or unusual names\" strictly for entertainment. These so-called silly or funny trivial names (of course depending on culture) can also serve an educational purpose. In an article in the \"Journal of Chemical Education\", Dennis Ryan argues that students of organic nomenclature (considered a \"dry and boring\" subject) may actually take an interest in it when tasked with the job of converting funny-sounding chemical trivial names to their proper systematic names.\n\nThe collection listed below presents a sample of trivial names and gives an idea how chemists are inspired when they coin a brand new name for a chemical compound outside of systematic naming. It also includes some examples of systematic names and acronyms that accidentally resemble English words.\n\nGlenn Seaborg told his students that he proposed the chemical symbol Pu (from P U) instead of the conventional \"Pl\" for plutonium as a joke, only to find it officially adopted.\nUnununium (Uuu) was the former temporary name of the chemical element number 111, a synthetic transuranium element. This element was named roentgenium (Rg) in November 2004.\n\n\n"}
{"id": "31637173", "url": "https://en.wikipedia.org/wiki?curid=31637173", "title": "Magyar Tudomány", "text": "Magyar Tudomány\n\nMagyar Tudomány () is the official monthly science magazine of the Hungarian Academy of Sciences. It publishes short articles on various new scientific developments as well as on problems of scientific life. Most articles are written by members of the academy. It has appeared continuously since 1840, under various names: \"Académiai Értesítő\" (1840—1859), \"Magyar Akadémiai Értesítő\" (1860—1867), \"A Magyar Tudományos Akadémia értesítője\" (1867—1889), \"Akadémiai Értesítő\" (1890—1955), \"Magyar Tudomány\" (since 1956). The editor-in-chief is Vilmos Csányi.\n"}
{"id": "5820809", "url": "https://en.wikipedia.org/wiki?curid=5820809", "title": "Mahābhūta", "text": "Mahābhūta\n\nMahābhūta is Sanskrit and Pāli for \"great element.\"\n\nIn Hinduism's sacred literature, the \"great\" or \"gross\" elements (\"mahābhūta\") are fivefold: space (or \"ether\"), air, fire, water and earth.\n\nFor instance, the describes the five \"sheaths\" of a person (Sanskrit: \"purua\"), starting with the grossest level of the five evolving great elements:\n\nIn the , God is identified as the source of the great elements:\n\nThe same Upanishad also mentions, \"When earth, water fire, air and akasa arise, when the five attributes of the elements, mentioned in the books on yoga, become manifest then the yogi's body becomes purified by the fire of yoga and he is free from illness, old age and death.\" (Verse 2.12).\n\nIn Buddhism, the four Great Elements (Pali: \"cattāro mahābhūtāni\") are earth, water, fire and air. Mahābhūta is generally synonymous with catudhātu, which is Pāli for the \"Four Elements.\" In early Buddhism, the Four Elements are a basis for understanding that leads one through unbinding of 'Rupa' or materiality to the supreme state of pure 'Emptiness' or Nirvana.\n\nIn the Pali canon, the most basic elements are usually identified as four in number but, on occasion, a fifth and, to an even lesser extent, a sixth element may be also be identified.\n\nIn canonical texts, the four Great Elements refer to elements that are both \"external\" (that is, outside the body, such as a river) and \"internal\" (that is, of the body, such as blood). These elements are described as follows:\n\n\nAny entity that carry one or more of these qualities (attractive forces, repulsive forces, energy and relative motion) are called matter (\"rupa\"). The material world is considered to be nothing but a combination of these qualities arranged in space (\"akasa\"). The result of these qualities are the inputs to our five senses, color (\"warna\"), smell (\"ghandda\"), taste (\"rasa\") and sensation of body (\"ojha\"). The matter that we perceive in our mind are just a mental interpretation of these qualities.\n\nIn addition to the above four elements of underived matter, two other elements are occasionally found in the Pali Canon:\n\n\nAccording to the Abhidhamma Pitaka, the \"space element\" is identified as \"secondary\" or \"derived\" (\"upādā\").\n\nRūpa (matter) means both materiality and sensibility—it signifies, for example, a tactile object both insofar as that object is tactile and that it can be sensed. Rūpa is never a materiality which can be separated or isolated from cognizance; such a non-empirical category is incongruous in the context of early Buddhism. Rūpa is not a substratum or substance which has sensibility as a property. It functions in early Buddhist thought as perceivable physicality. Matter, or rūpa, is defined in its function; what it does, not what it is. As such, the four great elements are conceptual abstractions drawn from the sensorium. They are sensorial typologies, and are not metaphysically materialistic. They are not meant to give an account of matter as constitutive of external, mind-independent reality.\n\nThe Four Elements are used in Buddhist texts to both elucidate the concept of suffering (\"dukkha\") and as an object of meditation. The earliest Buddhist texts explain that the four primary material elements are the sensory qualities solidity, fluidity, temperature, and mobility; their characterisation as earth, water, fire, and air, respectively, is declared an abstraction – instead of concentrating on the fact of material existence, one observes how a physical thing is sensed, felt, perceived.\n\nThe Four Elements pertinence to the Buddhist notion of suffering comes about due to:\n\nSchematically, this can be represented in reverse order as:\n\nThus, to deeply understand the Buddha's Four Noble Truths, it is beneficial to have an understanding of the Great Elements.\n\nIn the Mahasatipatthana Sutta (\"The Greater Discourse on the Foundations of Mindfulness,\" DN 22), in listing various bodily meditation techniques, the Buddha instructs:\n\nIn the Visuddhimagga's well-known list of forty meditation objects (\"kammahāna\"), the great elements are listed as the first four objects.\n\nB. Alan Wallace compares the Theravada meditative practice of \"attending to the emblem of consciousness\" to the practice in Mahamudra and Dzogchen of \"maintaining the mind upon non-conceptuality\", which is also aimed at focusing on the nature of consciousness.\n\nIn the Pali canon, the Four Elements are described in detail in the following discourses (\"sutta\"):\n\nThe Four Elements are also referenced in:\n\n\nIn addition, the Visuddhimagga XI.27\"ff\" has an extensive discussion of the Four Elements.\n\n"}
{"id": "27255866", "url": "https://en.wikipedia.org/wiki?curid=27255866", "title": "MoEDAL experiment", "text": "MoEDAL experiment\n\nMoEDAL (Monopole and Exotics Detector at the LHC) is a particle physics experiment at the Large Hadron Collider (LHC).\n\nMoEDAL shares the cavern at Point 8 with LHCb, and its prime goal is to directly search for the magnetic monopole (MM) or dyon and other highly ionizing stable massive particles (SMPs) and pseudo-stable massive particles. To detect these particles, the project uses nuclear track detectors (NTDs), which suffer characteristic damage due to highly ionizing particles. As MMs and SMPs are highly ionizing, NTDs are perfectly suited for the purpose of detection.\n\nIt is an international research collaboration whose spokesperson is the University of Alberta's James Pinfold. It is the seventh experiment at the LHC, was approved and sanctioned by the CERN research board on May 2010, and started its first test deployment in January 2011.\n\nIn 2012 MoEDAL accuracy surpassed accuracy of similar experiments. A new detector was installed in 2015, but as of 2017 it also did not find any magnetic monopoles, setting new limits on their production cross section.\n\n"}
{"id": "39153890", "url": "https://en.wikipedia.org/wiki?curid=39153890", "title": "Mycobacterium phage L5", "text": "Mycobacterium phage L5\n\nMycobacterium phage L5 is a bacteriophage known to infect bacterial species of the genus \"Mycobacterium\".\n"}
{"id": "2347885", "url": "https://en.wikipedia.org/wiki?curid=2347885", "title": "Myles Allen", "text": "Myles Allen\n\nMyles R. Allen is head of the Climate Dynamics group at the University of Oxford's Atmospheric, Oceanic and Planetary Physics Department. He is the Principal Investigator of the distributed computing project Climateprediction.net (which makes use of computing resources provided voluntarily by the general public), and was principally responsible for starting this project. He is Professor of Geosystem Science in the School of Geography and the Environment, and a Fellow of Linacre College, Oxford.\n\nHe has worked at the Energy Unit of the United Nations Environment Programme, the Rutherford Appleton Laboratory in Oxfordshire, and the Massachusetts Institute of Technology.\nHe contributed to the Third Assessment Report of the Intergovernmental Panel on Climate Change as a Lead Author of the Chapter on detection of change and attribution of causes, and was a Review Editor for the chapter on predictions of global climate change for the IPCC Fourth Assessment Report and a co-author of the IPCC October 8, 2018 Special Report on Global Warming of 1.5ºC. His research focuses on the attribution of recent climate change and assessing what these changes mean for global climate simulations of the future.\n\nIn 2010, Allen was awarded the Appleton Medal and Prize by the Institute of Physics for \"his important contributions to the detection and attribution of human influence on climate and quantifying uncertainty in climate predictions\".\n\nAllen also provided the technical expertise for the game Fate of the World, which is \"a PC strategy game that simulates the real social and environmental impact of global climate change over the next 200 years\".\n\n"}
{"id": "7701863", "url": "https://en.wikipedia.org/wiki?curid=7701863", "title": "Orion abort modes", "text": "Orion abort modes\n\nNASA's newest spacecraft, the Orion Multi-Purpose Crew Vehicle (MPCV), will be the first American spacecraft since Project Apollo to use an escape system in the event of a launch abort, something its predecessor, the Space Shuttle, had for only its first four orbital test flights in 1981-1982. Like the Apollo Command-Service Module (CSM), the Orion CEV will use the Launch escape system (LES), a solid-fueled tractor rocket that will be able to pull the Orion crew module away from a malfunctioning Space Launch System (SLS) rocket during the initial launch phase. Based on the launch escape system found on the Soviet/Russian Soyuz spacecraft, the LAS, designed and manufactured by ATK for the Orion CEV, will be larger than the Soyuz version and will have more thrust than the Atlas 109-D booster that carried astronaut John Glenn into orbit in 1962.\n\nThe earlier Apollo system had various abort modes depending on altitude, velocity, and other circumstances. Likewise the Orion will have similar modes of operation for its launch performance aborts. Some of these may not use the LAS itself, but would use the second stage of the Ares I, or even the Orion vehicle's own propulsion system (the Aerojet AJ-10 engine) instead.\n\nInitially designed to land on solid ground, like that of the early and current Soviet and Russian manned spacecraft (Vostok, Voskhod, and Soyuz), with a water landing as a backup, in August 2007, NASA tentatively redesigned the Orion for water landings (splashdowns) as the primary mode of landing, with ground landings as the emergency backup . Under the advice of the Exploration Systems Architecture Study (ESAS) report, NASA will most likely develop abort procedures that resemble the abort procedures used on Apollo, but with some procedures carried over from the Shuttle.\n\nThe method of abort, either using the LAS or the second stage of the Space Launch System booster, will depend on how far into the flight the spacecraft and crew are traveling.\n\nNASA has acquired several MRAPs to station near the launch pad, should there be time for the crew to evacuate the vehicle. One will be occupied by emergency rescue personnel, while the other will stand empty behind a blast shelter. Pad emergency egress enables astronauts and engineers to quickly escape the perimeter of the rocket. Both zip-lines and roller coasters were at one time studied for this purpose.\n\nDuring the first 120 seconds of flight, up to the jettisoning of the solid-fueled boosters at , the Orion Crew Module (CM) will separate from the rest of the rocket propelled by the LAS. Unlike the Apollo Launch Escape System, which used a pair of canards and the weight of the spacecraft to flip the vehicle over for landing, the Orion LAS has a set of steering rockets that will steer the spacecraft away from the malfunctioning SLS, as well as prepare the spacecraft for both separation and splashdown. The tower will then be jettisoned 14 seconds later and the hypergolic fuel on the Orion CM would be automatically released at a pre-determined altitude.\n\nAfter the LAS is jettisoned, the Orion Crew and Service Modules (CSM) will separate as a whole from the SLS and either use its large AJ-10 engine or smaller control engines to maneuver from the rocket. Similar to a Space Shuttle trans-Atlantic (TAL) abort profile, the Orion will use the AJ-10 engine to propel the spacecraft to a desired separation point, in which then the Orion CM would land in either western Spain or Morocco on \"due east\" (i.e., lunar) flights, or in Ireland or the United Kingdom on ISS-bound flights. A splashdown in the eastern Atlantic Ocean would only be a contingency.\n\nThe SLS would propel the Orion CSM into an initial orbit, upon which the spacecraft will immediately separate, and then perform a retrofire that will allow the Orion CM to splashdown in the Pacific Ocean off the U.S. West Coast, or make a ground landing at either Edwards Air Force Base in California or White Sands Space Harbor in New Mexico. This is similar in profile to the Shuttle's \"Abort Once Around\" (AOA) profile.\n\nIf the SLS suffers less-than-ideal performance during the initial orbit insertion, it can be restarted 45 minutes later to place the Orion CSM into a less than ideal orbit that can be corrected with the on-board propellant reserves later in the flight. This is similar to the Shuttle's \"Abort To Orbit\" (ATO) profile, but depending upon the stable orbit reached, it may require NASA to end the mission with a landing at either Edwards or White Sands within a 24-hour period.\n\nThe four abort modes would also be used if the Max Launch Abort System (MLAS), a proposed alternative to the LAS, is flown in place of the LAS. The MLAS, which resembles the LAS, but without the Soyuz-like rocket tower, uses a strengthened boost protective cover, but with the main rockets placed inside of the BPC itself.\n\n\n"}
{"id": "49641461", "url": "https://en.wikipedia.org/wiki?curid=49641461", "title": "Peterandresenite", "text": "Peterandresenite\n\nPeterandresenite is a very rare mineral, the first known natural hexaniobate. Its chemical formula is MnNbO•14HO. Its structure contains a special type of octahedron: Lindqvist ion. Peterandresenite was found in a pegmatite of the Larvik complex in Norway. It is somewhat similar to other unique niobium minerals, aspedamite and menezesite.\n\nPeterandresenite was discovered in AS Granit quarry, Tvedalen, Larvik, Vestfold, Norway.\n"}
{"id": "9974435", "url": "https://en.wikipedia.org/wiki?curid=9974435", "title": "Planctobacteria", "text": "Planctobacteria\n\nPlanctobacteria is a taxon created by Cavalier-Smith, specifically a division (phylum). However, it is not followed by the larger scientific community. Cavalier-Smith postulated that the Planctobacteria probably lost or reduced their peptidoglycan cell wall twice.\n\nIn the Cavalier-Smith bacterial megaclassification, it is within the bacterial Gracilicutes infrakingdom and comprises the phyla Chlamydiae, Lentisphaerae, Planctomycetes, Verrucomicrobia. It has been hypothesised that a member of the PVC clade might have been the host cell in the endosymbiotic event that gave rise to the first proto-eukaryotic cell.\n\nThese three groups in the traditional molecular phylogeny view are considered as phyla and also cluster together in what is referred to as the PVC superphylum, along with the candidate phyla OP3 and the Poribacteria. An important molecular marker in the form of a conserved signature protein has been found to be consistently shared by PVC members, with the exception of Poribacteria. The conserved signature protein may be a marker that represents a synapomorphic quality and a means to distinguish this bacterial group. Recent studies have characterized this protein and it has been attributed to play an important housekeeping function in DNA/RNA binding. This observation not only provides a means to demarcate the PVC superphylum, but it supports strongly supports an evolutionary relationship shared by this clade that is distinct from other bacteria.\n\nConserved signature indels (CSIs)have also been found specific for the Planctomycetes, Verrucomicrobia, and Chlamydiae that distinguish each respective phylum from one another, and from other bacteria. A three-amino-acid insert in the RNA polymerase protein RpoB has been found that is shared by all sequenced Verrucomicrobia, Chlamydiae, and Lentisphaerae species. The CSI is absent from neighbouring Planctomycetes' and Poribacteria, suggesting common ancestry among the groups for which the CSI is specific.\n\nAdditional lines of evidence for the existence of this clade have been found. These include the presence of membrane coat-like proteins, tubulin, sterol synthesis, and the presence of condensed DNA.\n"}
{"id": "3839716", "url": "https://en.wikipedia.org/wiki?curid=3839716", "title": "Principles of Neural Science", "text": "Principles of Neural Science\n\nFirst published in 1981 by Elsevier, Principles of Neural Science is an influential neuroscience textbook edited by Eric R. Kandel, James H. Schwartz, and Thomas M. Jessell. The original edition was 468 pages; now on the fifth edition, the book has grown to 1747 pages. The second edition was published in 1985, third in 1991, fourth in 2000. The fifth and latest edition was published on October 26th, 2012 and includes Steven A. Siegelbaum and A.J. Hudspeth as editors. It has been hailed as the \"Bible of Neuroscience\" having been co-written by the \"Father of Neuroscience\", Eric Kandel. \n\n\nIncluding the editors—all of whom also contributed to individual chapters in the book—there are a total of 45 authors of this text. Included among them are several notable researchers and physicians. Several authors are also highly decorated scientists, including Nobel laureate Linda B. Buck and renowned neurophysiologist Roger M. Enoka.\n\n\"Principles of Neural Science\" is often assigned as a textbook for many undergraduate and graduate/medical neuroscience and neurobiology courses. The book attempts to at least introduce every aspect of our most modern understanding of the brain. The fifth edition is divided into sixty-seven chapters, organized into nine parts:\n\n"}
{"id": "9880182", "url": "https://en.wikipedia.org/wiki?curid=9880182", "title": "Putrefying bacteria", "text": "Putrefying bacteria\n\nPutrefying bacteria are bacteria involved in putrefaction of living matter. Along with other decomposers, they play a critical role in recycling nitrogen from dead organisms.\n\nPutrefying bacteria use amino acids or urea as an energy source to decompose dead organisms. In the process, they produce ammonium ions. Nitrifying bacteria then convert this ammonium into nitrate, which can then be used by plants to create more proteins thus completing the nitrogen cycle.\n\n"}
{"id": "4510308", "url": "https://en.wikipedia.org/wiki?curid=4510308", "title": "Research Papers in Economics", "text": "Research Papers in Economics\n\nResearch Papers in Economics (RePEc) is a collaborative effort of hundreds of volunteers in many countries to enhance the dissemination of research in economics. The heart of the project is a decentralized database of working papers, preprints, journal articles, and software components. The project started in 1997. Its precursor NetEc dates back to 1993.\n\nSponsored by the Research Division of the Federal Reserve Bank of St. Louis and using its IDEAS database, RePEc provides links to over 1,200,000 full text articles. Most contributions are freely downloadable, but copyright remains with the author or copyright holder. It is among the largest internet repositories of academic material in the world.\n\nMaterials to RePEc can be added through a department or institutional archive or, if no institutional archive is available, through the Munich Personal RePEc Archive. Institutions are welcome to join and contribute their materials by establishing and maintaining their own RePEc archive.\n\nLeading publishers, such as Elsevier and Springer, have their economics material listed in RePEc. RePEc collaborates with the American Economic Association's EconLit database to provide content from leading universities' working paper or preprint series to EconLit. Over 1500 journals and over 3300 working paper series have registered, for a total of over 1.2 million articles, the majority of which are online.\n\nThe information in the database is used to rank the more than 50,000 registered economists. Andrei Shleifer is currently the highest ranked economist, followed by Joseph Stiglitz and James Heckman. The economics department of Harvard University is ranked first, followed by the World Bank and the University of Chicago. Massachusetts is the top region, followed by the United Kingdom and California. There are also rankings by country and sub-discipline.\n\nRePEc also indexes worldwide economics institutions through its Economic Departments, Institutes and Research Centers in the World (EDIRC) database.\n\nRePEc promotes Open Access journals and also benefits from Open Access for its own citation analysis efforts.\n\n\n"}
{"id": "18862994", "url": "https://en.wikipedia.org/wiki?curid=18862994", "title": "Science Communication Observatory", "text": "Science Communication Observatory\n\nThe Science Communication Observatory (, , OCC) is a Special Research Centre attached to the Department of Communication of the Pompeu Fabra University in Barcelona, Spain, set up in 1994. This centre is specialized in the study and analysis of the transmission of scientific, medical, environmental and technological knowledge to society. The journalist Vladimir de Semir, associated professor of Science Journalism at the Pompeu Fabra University, was the funder and is the current director of the centre. A multidisciplinary team of researchers coming from different backgrounds (i.e. journalists, biologists, physicians, linguists, historians, etc.) is working on various lines of research: science communication; popularization of sciences, risk and crisis communication; science communication and knowledge representation; journalism specialized in science and technology; scientific discourse analysis; health and medicine in the daily press; relationships between science journals and mass media; history of science communication; public understanding of science; gender and science in the mass media, promotion of scientific vocations, science museology, etc.\n\nThe Science Communication Observatory is linked to the international network on Public Communication of Science & Technology (PCST), which includes individuals from around the world who are active in producing and studying PCST through science journalism, science museums and science centers, academic researchers in social and experimental sciences, scientists who deal with the public, public information officers for scientific institutions and others related to science in society issues. The PCST Network sponsors international conferences, electronic discussions, and other activities to foster dialogue among the different groups of people interested in PCST, leading to cross-fertilization across professional, cultural, international, and disciplinary boundaries. The PCST Network seeks to promote new ideas, methods, intellectual and practical questions and perspectives.\n\nThe first conference held by the PCST Network was at Poitiers, France in 1989. Since then biennial conferences have been held in Madrid (1991), Montreal (1994), Melbourne (1996), Berlin (1998), Geneva (2000), Cape Town (2002), Barcelona (2004), Seoul (2006), Malmo/Copenhagen (2008) and New Delhi (2010). The 2012 conference is scheduled for Florence in 2012.\n\nWith events in Melbourne, Beijing, Seoul and Cape Town, the Network expanded from its European origins to become a truly international network. The Scientific Committee managing the organisation is drawn from 19 different countries ranging across the globe. The Committee is chaired by Mr Toss Gascoigne (Australia).\n\nThe Science Communication Observatory hosts the PCST Academy. The PCST Academy is responsible for the creation of the documentary basis of the Public Communication of Science and Technology network (PCST) and its main task is the selection and organized collection of articles, reports and resources on particular topics in the field of communication and social understanding of sciences. As stated by the Chair of the Network from 2004 to 2006, Vladimir de Semir, the Academy looks for the necessary resources at international level to guarantee the access to the network of representatives from those countries that currently have to face more difficulties: “The main aim is to represent and include the multiplicity of identities existing in the world, because the study and practice of science communication should respect the different cultural contexts and integrate the knowledge coming from all continents.”\n\nThe Science Communication Observatory runs a Master in Science, Medical and Environmental Communication in Barcelona (Spain) since 1995 and a Diploma in Science Communication in Buenos Aires (Argentina) since 2008 and other courses and workshops about science communication and the popularization of science. The Science Communication Observatory also publishes Quark, a journal about “Science, Medicine, Communication and Culture”, and also carries on researches and analysis in the Science in Society field, working with other European institutions and academic groups on several European projects such as:\n\n• PLACES - Platform of Local Authorities and Communicators Engaged in Science, a four-year European project establishing and developing the concept of the European City of Scientific Culture. The project focuses on developing and strengthening City Partnerships, bringing together 67 science centres, museums, festivals and events, each partnering with local authorities, and 10 European regional networks. The project facilitates cooperation among these alliances to structure their science communication activities, sharing tools, resources and results.\n\n• KiiCS - Knowledge Incubation in Innovation and Creation for Science, the project aims to build bridges between arts, science and technology by giving evidence of the positive impacts of their interaction for creativity as well as for triggering interest in science. The project will stimulate co-creation processes involving creators and scientists, and nurture youth interest in science in a creative way. (KiiCS starts 15 February 2012)\n\n• MASIS - Monitoring Policy and Research Activities on Science in Society in Europe, project to develop structural links and interaction between scientists, policy-makers and society at large, therefore an instrumental tool in relation to stimulating further cooperation in Europe and reducing fragmentation through the identification of common resources, common trends, common interests, and common challenges.\n\n• ESCITY - Europe, Science and the City: promoting scientific culture at local level, an initiative to create the core of a network for the exchange of information and best practices in the area of promoting scientific culture, with two particular characteristics; focusing on local and regional action and emplacing strategies that situate the promotion of scientific culture under the umbrella of cultural policies.\n\n• ESConet - European Science Communication Network, which brings together experienced science communication lecturers, researchers and practitioners from across Europe to train natural scientists and technologists to communicate effectively with the media, policy-makers and the general public. As well as delivering these core communication skills, ESConet workshops encourage scientists to reflect critically on the social, cultural, and ethical dimensions of their scientific work.\n\n• E-KNOWNET - Network for ICT-enabled non-formal science learning, a project supported by the Lifelong Learning Programme of the European Commission to develop an innovative and viable ICT-enabled mechanism for fast and efficient sharing of new knowledge among larger non-expert segments of society, in forms suitable for non-formal learning.\n\n• STEPE - Sensitive Technologies and European Public Ethics project is innovative in contributing to the early identification of potentially controversial technological developments and related public ethics, by systematically considering both the view of key stakeholders in technological, political and societal life and the perceptions of European citizens in 25 European member states, thereby contextualising the findings by a systematic analysis of policy developments both on national and European levels. The interdisciplinary and multi-method approach will aim at establishing an integrated European Map of Public Ethics. It is the aim to stimulate new, empirically grounded, thinking on public ethics as a contribution to wider debates and policy making on responsible technological innovation. As a key data source, the proposal is based on the triennial Eurobarometer survey on the Biotechnology and the Life Sciences.\n\n• Benchmarking the Promotion of RTD culture and Public Understanding of Science to establish the current state of RTD culture in Member States, to provide a survey of the ongoing activities, and to recommend measures to be followed to improve the present situation. In order to clarify the meaning behind the vocabulary used in different Member States, our introduction also contains an analysis of the concepts behind\n“Public Understanding of Science”, “Public Understanding of Science and the Humanities (Wissenschaft)” and “Culture Scientifique”.\n\nThe Science Communication Observatory was responsible of the organization of the 8th International Conference of the PCST Network in Barcelona (Spain), June 2004. The main theme of the conference was \"Scientific Knowledge and Cultural Diversity\" which opened up a field to debate on the global discourse of science in a range of local culture and knowledge environments. When talking about various cultures we are referring to the different groups sharing the same language, same traditions, ideology or religion, inhabiting in a specific geographical environment, having the same job, or being a man or a woman, a young, a child, an elder… All this rich cultural diversity also reflects its stamp on scientific knowledge, in its creation and application as well as in the whole process of public communication of science and technology.\nThe main theme of \"Scientific Knowledge and Cultural Diversity\", included 3 subthemes or discussion subjects.\n\nNative Knowledge & Modern Science\nCultural diversity. Traditional knowledge. Local wisdom. Regional identity and globalization. Indigenous knowledge system. Citizenship participation on scientific decisions. Popular culture and scientific culture. Possibilities of native knowledge facing with new technologies. Science ethics and believes. Religion or morality influence in knowledge construction. Cohabitation between medicines with different evaluation systems. Knowledge, religion and beliefs. Parasciences. Science as a universal knowledge Intellectual property. Gender and cultural approach. New models, trends and concepts in PCST.\n\nScience Communication: Historical Perspectives And New Trends\nInfluences of historical processes on science communication. The greatest science communicators. The role of the mass media. The role of science centres and museums. Main initiatives in the promotion of scientific culture. Results analysis methodology. International networks. New models, trends and concepts in PCST.\n\nScience Communication & Social Participation\nPeripheral science and science in the outskirts. Science culture and cooperation with illiterate population and marginal groups. Social inclusion. Public engagement with science policy (consensus conferences, citizen juries, deliberative polling). Science vocations in the changing world. Media impact on science opinion. Science festivals. Ethics of science communication. Public policies in scientific culture. Citizen participation on scientific decisions. Informal science education. Science centers and museums. Science communication training. New models, trends and concepts in PCST.\n\nIn December 2007, the Science Communication Observatory organized with the European Commission the European Forum on Science Journalism (EFSJ) where leading science journalists and editors of national newspapers and specialised science publications from across Europe and the world met in Barcelona to discuss the challenges in reporting on science, the impact of new technologies on the profession and importance of linking science to society and everyday life together with leading scientists and top science communication professionals from across Europe, the US, Canada, China and Australia. A Special Eurobarometer on scientific research in the media and a European Guide to Science Journalism Training were presented in this forum.\nHow to strengthen science coverage in the European press? How to convince editors to run science stories? How to assess the trustworthiness of scientific research? How to explain science in an understandable fashion? How to stimulate public interest in science news?... These were among the key questions addressed at the first European Forum on Science Journalism.\n\nIn May 2010, the Science Communication Observatory was member of the scientific committee of the Media for Science Forum organised by the Spanish Foundation for Science and Technology with the collaboration of the European Commission in the context of the Spanish Presidency of Europe 2010.\n\n"}
{"id": "52630840", "url": "https://en.wikipedia.org/wiki?curid=52630840", "title": "SpaCy", "text": "SpaCy\n\nspaCy ( ) is an open-source software library for advanced Natural Language Processing, written in the programming languages Python and Cython. The library is published under the MIT license and currently offers statistical neural network models for English, German, Spanish, Portuguese, French, Italian, Dutch and multi-language NER, as well as tokenization for various other languages.\n\nUnlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage. As of version 1.0, spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning libraries like TensorFlow, Keras, Scikit-learn or PyTorch. spaCy's machine learning library, Thinc, is also available as a separate open-source Python library. On November 7, 2017, version 2.0 was released. It features convolutional neural network models for part-of-speech tagging, dependency parsing and named entity recognition, as well as API improvements around training and updating models, and constructing custom processing pipelines.\n\n\nspaCy comes with several extensions and visualizations that are available as free, open-source libraries: \n\n\n"}
{"id": "52152136", "url": "https://en.wikipedia.org/wiki?curid=52152136", "title": "Tasia Maximova Stadnichenko", "text": "Tasia Maximova Stadnichenko\n\nTaisia Maximova Stadnichenko (9 October 1894 – 26 November 1958) was a Russian born geologist and chemist whose fieldwork was focused on the distribution of germanium and the minor-element content in coal. She was born in Taganash, Crimea on October 9, 1894 and died on November 26,1958 at the age of sixty-four due to a heart ailment. She attended Petrograd University and joined the Russian Geological Survey before moving to the United States in 1918 to act as an interpreter for the Russian mission throughout World War I. After the war she continued her professional life as a researcher at the University of Illinois and as a professor at Vassar College from 1922 to 1935. In 1935, Stadnichenko led the first U.S Geological Survey exploring the minor-element distribution within coal by collecting samples of coal ash for element content analysis, which found germanium and other elements within the coal ash. Stadnichenko is widely considered instrumental in the discovery and understanding of coal's structure and origin.\n"}
{"id": "4396809", "url": "https://en.wikipedia.org/wiki?curid=4396809", "title": "The Ground of Arts", "text": "The Ground of Arts\n\nRobert Recorde's Arithmetic: or, The Ground of Arts was one of the first printed English textbooks on arithmetic and the most popular of its time. It introduced the equals sign (\"=\"). It was preceded only by two anonymous texts in 1537 and 1539; \"The Ground of Arts\" appeared in London in 1543, and it was reprinted around 45 more editions until 1700. Editors and contributors of new sections included John Dee, John Mellis, Robert Hartwell, Thomas Willsford, and finally Edward Hatton.\n\n"}
{"id": "4603794", "url": "https://en.wikipedia.org/wiki?curid=4603794", "title": "USNS Mission San Fernando", "text": "USNS Mission San Fernando\n\nSS \"Mission San Fernando\" was a Type T2-SE-A2 tanker built for the United States Maritime Commission during World War II. After the war she was acquired by the United States Navy as USS \"Mission San Fernando\" (AO-122). Later the tanker transferred to the Military Sea Transportation Service as USNS \"Mission San Fernando\" (T-AO-122). She was a member of the and was named for Mission San Fernando Rey de España in Los Angeles. She was later renamed USNS \"Muscle Shoals\" (T-AGM-19) (after Muscle Shoals, Alabama), and, later, USNS \"Vanguard\" (T-AG-194).\n\n\"Mission San Fernando\" was laid down on 26 August 1943 under a Maritime Commission contract by Marine Ship Corporation, Sausalito, California; launched on 25 November 1943; sponsored by Mrs. Ruth B. Krohn; and delivered on 29 February 1944. Chartered to Pacific Tankers Inc., for operations, she served the remainder of the War carrying fuel to Allied forces in the western Pacific (during which time she was twice awarded the Battle Efficiency Award as well as the National Defense Service Medal). She remained in service until 10 May 1946 when she was returned to the Maritime Commission and laid up in the Reserve Fleet at Olympia, Washington. \n\nAcquired by the Navy on 21 October 1947 she was chartered to the Union Oil Company for operations and placed in service under the operational control of the Naval Transportation Service as \"Mission San Fernando\" (AO-122). Transferred to the operational control of the newly created Military Sea Transportation Service on 1 October 1949 she was redesignated USNS \"Mission San Fernando\" (T-AO-l22). She served in MSTS until 24 May 1955 when she was returned to the Maritime Administration and laid up in the Maritime Reserve Fleet at Olympia. She was struck from the Naval Vessel Register on 22 June 1955. \n\nReacquired by the Navy on 21 June 1956 she was placed in service with MSTS and operated, under charter, by Marine Transportation Lines. She served with MSTS until she was returned to the Maritime Administration on 4 September 1957 and laid up in the Maritime Reserve Fleet at James River, Virginia.\n\nReacquired by the Navy on 28 September 1964 she was taken in hand by General Dynamics Quincy Shipbuilding Division for extensive modernization and rebuilding at its Quincy, Massachusetts yard. This included adding 80 feet to her length. While under conversion to a missile-range instrumentation ship, she was renamed for Muscle Shoals, Alabama and reclassified, becoming \"Muscle Shoals\" (AGM-19). Renamed \"Vanguard\" on 1 September 1965, she was placed in service with MSTS on 28 February 1966 as USNS \"Vanguard\" (T-AGM-19). Designed to be a seagoing missile tracking station, she participated in the Apollo Project test series and into 1969 had continued in these duties. She then participated in the Skylab program and the joint US/Soviet Apollo–Soyuz Test Project.\n\nIn September 1980, she was reconfigured and the large missile tracking antennas were removed. She replaced the and reclassified as T-AG-194. Her role became that of a Navigational Test Ship and she was used to check submarine navigation systems. She steamed over 250,000 miles in support of Poseidon and Trident I navigation subsystems and in development of the Trident II navigation subsystem. She was stricken again on 12 December 1999 after being replaced by USNS \"Waters\" (T-AGS-45).\n\nOn 29 November 2001 she was transferred to the United States Maritime Administration (MARAD). On 16 March 2005 MARAD issued a \"Request for Comments\" for public input on the historical significance of the \"Vanguard\".\n\nFollowing historical review, the vessel was cleared for disposal by the Virginia State Historic Preservation Office on 15 November 2006.\n\nAs of January, 2014 she is being recycled at Marine Metal Inc. recycle slip in Brownsville, Texas.\n\n"}
{"id": "30951006", "url": "https://en.wikipedia.org/wiki?curid=30951006", "title": "University spin-off", "text": "University spin-off\n\nUniversity spin-offs transform technological inventions developed from university research that are likely to remain unexploited otherwise. As such, university/academic spin-offs are a subcategory of research spin-offs. Prominent examples of university spin-offs are Genentech, Crucell, Lycos and Plastic Logic. In most countries, universities can claim the intellectual property (IP) rights on technologies developed in their laboratories. In the United States, the Bayh–Dole Act permits universities to pursue ownership of inventions made by researchers at their institutions using funding from the federal government, where previously federal research funding contracts and grants obligated inventors (wherever they worked) to assign the resulting IP to the government. This IP typically draws on patents or, in exceptional cases, copyrights. Therefore, the process of establishing the spin-off as a new corporation involves transferring the IP to the new corporation or giving the latter a license on this IP. Most research universities now have Technology Licensing Offices (TLOs) to facilitate and pursue such opportunities.\n\nUniversity spin-offs typically go through a number of critical steps to develop the initial invention into a successful business venture. The following steps are critical in creating a successful spin-off (not necessarily in this order). \n\nSome universities generate substantially higher numbers of spin-offs than others. Universities with high numbers of successful spin-offs …\n\nUniversity spin-off activity may give rise to potential conflict of interest between commercial and academic work. In addition, the university’s reputation may be at risk if founders of spin-offs act inappropriately. Moreover, the antagonism between academic research and technology commercialization by way of spin-offs is likely to create fairness issues, for example regarding the distribution of royalties or equity. This antagonism can be managed by installing transparent procedures for the spin-off formation process that enhance fair treatment of all participants.\n\n\n\n\n"}
{"id": "5562687", "url": "https://en.wikipedia.org/wiki?curid=5562687", "title": "Vasili Pronchishchev", "text": "Vasili Pronchishchev\n\nVasili Vasilyevich Pronchishchev () (1702–) was a Russian explorer.\n\nIn 1718, Vasili Pronchishchev graduated from Moscow School of Mathematics and Navigation and was promoted to naval cadet. In 1733, he was promoted to the rank of lieutenant and appointed head of one of the units of the Second Kamchatka Expedition, the purpose of which was to map the shores of the Arctic Ocean from the mouth of the Lena to the mouth of the Yenisey. \n\nIn 1735, Vasili Pronchishchev went down the Lena River (from Yakutsk) on his sloop \"Yakutsk\", doubled its delta, and stopped for wintering at the mouth of the Olenek River. Many members of the crew fell ill and died, mainly owing to scurvy. Despite the difficulties, in 1736, he reached the eastern shore of the Taymyr Peninsula and went north along its coastline. Finally Pronchishchev and his wife Maria (also referred to as Tatyana Feodorovna) succumbed to scurvy and died on the way back. \n\nDespite the death toll, the expedition was successful regarding the fulfillment of its goals. During his journey, Vasili Pronchishchev discovered a number of islands off the northeastern coast of the Taymyr Peninsula (Faddey Islands, Komsomolskoy Pravdy Islands, Saint Peter Islands). His expedition was the first to accurately map the Lena River from Yakutsk to its estuary and the Laptev seacoast from the Lena's mouth to the Gulf of Faddey. Pronchishchev's wife Maria Pronchishcheva (died September 12(23), 1736), who took part in his expedition, is considered the first female polar explorer. After their deaths, both of them were interred at the mouth of the Olenek River. \n\nA part of the eastern coastline of the Taymyr Peninsula and a ridge between the mouths of the Olenek and Anabar Rivers bear Vasili Pronchishchev's name. Icebreaker \"Vasili Pronchishchev\", built in 1961 in Leningrad, was also named after this pioneering Arctic explorer. \n\nMaria Pronchishcheva Bay in the Laptev Sea is named after his wife Maria. \n\n"}
{"id": "53206138", "url": "https://en.wikipedia.org/wiki?curid=53206138", "title": "Women's Technology Empowerment Centre", "text": "Women's Technology Empowerment Centre\n\nThe Women's Technology Empowerment Centre, often referred to as W.TEC, is a non-profit organization that focuses on empowering Nigerian women and girls through the use of technology. It was founded in 2008 by Oreoluwa Lesi after noticing a gender gap in understanding of Information and Communications Technology (ICT) throughout Nigeria and other African countries. Services and programs offered by W.TEC include mentoring, training in technology, technology camp, awareness campaigns, collaborative projects, and research and publication. In 2017, Facebook partnered with W.TEC to take efforts toward improved Internet safety.\n"}
