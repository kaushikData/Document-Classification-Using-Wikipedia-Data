{"id": "14226822", "url": "https://en.wikipedia.org/wiki?curid=14226822", "title": "Alveolo-palatal fricative", "text": "Alveolo-palatal fricative\n\nAlveolo-palatal fricative is a class of consonants in some oral languages. The consonants are sibilants, a variety of fricative. Their place of articulation is postalveolar. They differ in voicing.\n\nThe voiceless alveolo-palatal fricative is written in the International Phonetic Alphabet.\n\nThe voiced alveolo-palatal fricative, written , is similar to the voiced postalveolar fricative in English words such as \"Asia\".\n\nFeatures of alveolo-palatal fricatives:\n\n"}
{"id": "5204518", "url": "https://en.wikipedia.org/wiki?curid=5204518", "title": "Archetype (information science)", "text": "Archetype (information science)\n\nIn the field of informatics, an archetype is a formal re-usable model of a domain concept. Traditionally, the term \"archetype\" is used in psychology to mean an idealized model of a person, personality or behaviour (see \"Archetype\"). The usage of the term in informatics is derived from this traditional meaning, but applied to domain modelling instead.\n\nAn archetype is defined by the OpenEHR Foundation (for health informatics) as follows:\n\nThe modern Archetype formalism is specified and maintained by the openEHR Foundation, and although originally developed for the health IT domain, is completely domain-independent, and has been used in geospatial modelling, telecommunications, and defence.\n\nThe Archetype Formalism consists of a number of specifications including:\n\n\nThe Archetype Technology Overview provides a short technical overview of the archetype formalism useful for new users.\n\nThe ADL/AOM 1.4 specifications were provided to ISO TC 215 in 2008 and became the ISO 13606-2 standard, extant until 2017. ISO TC 215 has accepted the AOM 2 specification as the basis for a revision of this standard, to be issued in 2017.\n\nIn late 2015, the Object Management Group (OMG) accepted an RfP entitled 'Archetype Modeling Language (AML)' as a new candidate standard. This specification is a form of ADL re-engineered as a UML profile so as to enable archetype modelling to be supported within UML tools.\n\nA number of tools area available for working with archetypes. Most are listed on the openEHR modelling tools page. They include:\n\n\n"}
{"id": "2065886", "url": "https://en.wikipedia.org/wiki?curid=2065886", "title": "BET theory", "text": "BET theory\n\nBrunauer–Emmett–Teller (BET) theory aims to explain the physical adsorption of gas molecules on a solid surface and serves as the basis for an important analysis technique for the measurement of the specific surface area of materials. In 1938, Stephen Brunauer, Paul Hugh Emmett, and Edward Teller published the first article about the BET theory in the Journal of the American Chemical Society. The BET theory applies to systems of multilayer adsorption and usually utilizes probing gases that do not chemically react with material surfaces as adsorbates to quantify specific surface area. Nitrogen is the most commonly employed gaseous adsorbate used for surface probing by BET methods. For this reason, standard BET analysis is most often conducted at the boiling temperature of N (77 K). Further probing adsorbates are also utilized, albeit with lower frequency, allowing the measurement of surface area at different temperatures and measurement scales. These have included argon, carbon dioxide, and water. Specific surface area is a scale-dependent property, with no single true value of specific surface area definable, and thus quantities of specific surface area determined through BET theory may depend on the adsorbate molecule utilized and its adsorption cross section.\n\nThe concept of the theory is an extension of the Langmuir theory, which is a theory for monolayer molecular adsorption, to multilayer adsorption with the following hypotheses:\nThe resulting BET equation is\n\nwhere formula_2 and formula_3 are the equilibrium and the saturation pressure of adsorbates at the temperature of adsorption, formula_4 is the adsorbed gas quantity (for example, in volume units), and formula_5 is the monolayer adsorbed gas quantity. formula_6 is the \"BET constant\",\n\nwhere formula_8 is the heat of adsorption for the first layer, and formula_9 is that for the second and higher layers and is equal to the heat of liquefaction.\n\nEquation (1) is an adsorption isotherm and can be plotted as a straight line with formula_10 on the y-axis and formula_11 on the x-axis according to experimental results. This plot is called a \"BET plot\". The linear relationship of this equation is maintained only in the range of formula_12. The value of the slope formula_13 and the y-intercept formula_14 of the line are used to calculate the monolayer adsorbed gas quantity formula_5 and the BET constant formula_6. The following equations can be used:\n\nThe BET method is widely used in surface science for the calculation of surface areas of solids by physical adsorption of gas molecules. The total surface area formula_19 and the specific surface area formula_20 are given by\nwhere formula_5 is in units of volume which are also the units of the monolayer volume of the adsorbate gas,\nformula_24 is Avogadro's number, formula_25 the adsorption cross section of the adsorbing species, formula_26 the molar volume of the adsorbate gas, and formula_27 the mass of the solid sample or adsorbent.\n\nThe BET theory can be derived similarly to the Langmuir theory, but by considering multilayered gas molecule adsorption, where it is not required for a layer to be completed before an upper layer formation starts. Furthermore, the authors made five assumptions:\n\nLet us consider a given amount of solid sample in a controlled atmosphere. Let \"θ\" be the fractional coverage of the sample surface covered by a number \"i\" of successive molecule layers. Let us assume that the adsorption rate \"R\" for molecules on a layer (\"i\"-1) (i.e. formation of a layer \"i\") is proportional to both its fractional surface \"θ\" and to the pressure \"P\", and that the desorption rate \"R\" on a layer \"i\" is also proportional to its fractional surface \"θ\":\nwhere \"k\" and \"k\" are the kinetic constants (depending on the temperature) for the adsorption on the layer (\"i\"−1) and desorption on layer \"i\", respectively. For the adsorptions, these constant are assumed similar whatever the surface.\nAssuming an Arrhenius law for desorption, the related constants can be expressed as\nwhere \"E\" is the heat of adsorption, equal to \"E\" at the sample surface and to \"E\" otherwise.\n\nIt is still not clear on how to find the linear range of the BET plot for microporous materials in a way that reduces any subjectivity in the assessment of the monolayer capacity. Rouquerol et al. suggested a procedure that is based on two criteria:\n\nBy application of the BET theory it is possible to determine the inner surface of hardened cement paste. If the quantity of adsorbed water vapor is measured at different levels of relative humidity a BET plot is obtained.\nFrom the slope formula_13 and y-intersection formula_14 on the plot it is possible to calculate formula_5 and the BET constant formula_6. In case of cement paste hardened in water (\"T\" = 97 °C), the slope of the line is formula_35 and the y-intersection formula_36; from this follows\nFrom this the specific BET surface area formula_20 can be calculated by use of the above-mentioned equation (one water molecule covers formula_40). It follows thus formula_41 which means that hardened cement paste has an inner surface of 156 square meters per g of cement.\n\nFor example, activated carbon strongly adsorbs many gases and has an adsorption cross section formula_25 of 0.162 nm for nitrogen adsorption at liquid-nitrogen temperature (77 K). BET theory can be applied to estimate the specific surface area of activated carbon from experimental data, demonstrating a large specific surface area, even around 3000 m/g. However, this surface area is largely overestimated due to enhanced adsorption in micropores, and more realistic methods should be used for its estimation, such as the subtracting pore effect (SPE) method.\n\nIn the field of solid catalysis, the surface area of catalysts is an important factor in catalytic activity. inorganic materials such as mesoporous silica and layered clay minerals have high surface areas of several hundred m/g calculated by the BET method, indicating the possibility of application for efficient catalytic materials.\n\nThe ISO 9277 standard for calculating the specific surface area of solids is based on the BET method.\n\n"}
{"id": "28914305", "url": "https://en.wikipedia.org/wiki?curid=28914305", "title": "Bartók Glacier", "text": "Bartók Glacier\n\nBartók Glacier () is a glacier, long and wide, flowing southwest from the southern end of the Elgar Uplands in the northern part of Alexander Island. It was first photographed from the air and roughly mapped by the British Graham Land Expedition in 1937, and more accurately mapped from air photos taken by the Ronne Antarctic Research Expedition, 1947–48, by D. Searle of the Falkland Islands Dependencies Survey in 1960. It was named by the UK Antarctic Place-Names Committee after the Hungarian composer Béla Bartók.\n\n"}
{"id": "243467", "url": "https://en.wikipedia.org/wiki?curid=243467", "title": "Beardmore Glacier", "text": "Beardmore Glacier\n\nThe Beardmore Glacier in Antarctica is one of the largest valley glaciers in the world, being long and having a width of . It descends about from the Antarctic Plateau to the Ross Ice Shelf and is bordered by the Commonwealth Range of the Queen Maud Mountains on the eastern side and the Queen Alexandra Range of the Central Transantarctic Mountains on the western.\n\nThe glacier is one of the main passages through the Transantarctic Mountains to the great polar plateau beyond, and was one of the early routes to the South Pole despite its steep upward incline.\n\nThe glacier was discovered and climbed by Ernest Shackleton during his Nimrod Expedition of 1908. Although Shackleton turned back before reaching the South Pole, he established the first proven route towards the pole and, in doing so, became the first person to set foot upon the polar plateau. In 1911–1912, Captain Scott and his Terra Nova Expedition team reached the South Pole by similarly climbing the Beardmore. However, they reached the pole a month after Roald Amundsen and his team, who had chosen a route up the previously unknown Axel Heiberg Glacier. It was on the way back to the Nova expedition's base camp after they left the South Pole that Edgar Evans, one of the members of Scott's chosen team to go to on the final trek to the South Pole, died around the foot of Beardmore Glacier on February 17, 1912.\n\nBeardmore Glacier was named by Shackleton after Sir William Beardmore, a Scottish industrialist and expedition sponsor born in 1856.\n\nIn 2016 the first beetle fossils, in the form of wing-cases (elytra) of Ball's Antarctic tundra beetle, 14 to 20 million years old, were found on the glacier.\n\n"}
{"id": "29071166", "url": "https://en.wikipedia.org/wiki?curid=29071166", "title": "Blaiklock Glacier", "text": "Blaiklock Glacier\n\nBlaiklock Glacier () is a glacier long, flowing north from Turnpike Bluff, then northwest to Mount Provender and Mount Lowe in the western part of the Shackleton Range. It was first mapped in 1957 by the Commonwealth Trans-Antarctic Expedition (CTAE), and named for Kenneth V. Blaiklock, the leader of the advance party of the CTAE in 1955–56 and a surveyor with the transpolar party in 1956–58.\n\n"}
{"id": "34227237", "url": "https://en.wikipedia.org/wiki?curid=34227237", "title": "Carlos Ameghino", "text": "Carlos Ameghino\n\nCarlos Ciriaco Ameghino (16 June 1865 – 12 April 1936) was an Argentine paleontologist and explorer who accompanied his brother Florentino Ameghino throughout Argentina searching for fossils. \n\nCarlos Ameghino was educated as a naturalist with his brother Florentino Ameghino on his journeys to Buenos Aires and the Chaco Province in Argentina. The goal of this expedition was to collect fossils.\n\nIn 1887, he decided to explore South Argentina, and the watersheds of the Santa Cruz River, the Chubut River, the Chico River, the Deseado River, the Gallegos River, and the Straits of Megellan. He discovered many fossils and created several geological and paleontological reports in his research the he gave to his brother. He also demonstrated the exact superposition of two great tertiary formations.\n"}
{"id": "58944573", "url": "https://en.wikipedia.org/wiki?curid=58944573", "title": "Centro Nacional de Aceleradores", "text": "Centro Nacional de Aceleradores\n\nThe Centro Nacional de Aceleradores (CNA) is the centre for particle accelerators in Spain and is based in Seville. It was created in 1997.\n\nIt combines the efforts of the University of Seville, the Regional Government of Andalusia and the Spanish Higher Council for Scientific Research. It is located in the Cartuja 93 Science and Technology Park.\n\nIt has three different types of ion accelerators (3MV Van de Graaf Tandem, Cyclotron which provides 18 MeV protons and 9 MeV deuters and a 1 MV Cockcroft-Walton Tandem as a mass spectrometer) for studies in various fields. In addition, they feature a PET/CT scanner for people, new Carbon 14 dating systems (the MiCaDaS) and a 60CO.2 irradiator.\n"}
{"id": "34591865", "url": "https://en.wikipedia.org/wiki?curid=34591865", "title": "Charles Knight (doctor)", "text": "Charles Knight (doctor)\n\nCharles Knight ( 1808 – 3 September 1891) was a New Zealand doctor, public servant and botanist. He was born in Rye, Sussex, England in 1808. Knight was the country's inaugural auditor-general. In New Zealand, he first lived in Auckland and when the government moved to Wellington, he also relocated to the new capital. He died at his home in Wellington and is buried at Bolton Street Memorial Park.\n"}
{"id": "290634", "url": "https://en.wikipedia.org/wiki?curid=290634", "title": "Chess as mental training", "text": "Chess as mental training\n\nThere are efforts to use the game of chess as a tool to aid the intellectual development of young people. Chess is significant in cognitive psychology and artificial intelligence (AI) studies, because it represents the domain in which expert performance has been most intensively studied and measured.\n\nAlthough the results of research studies have failed to produce unambiguous support for the intellectual benefits of playing chess, several local government, schools, and student organizations all over the world are implementing chess programs. \n\nNew York based Chess-In-The-Schools, Inc. has been active in the public school system in the city since 1986. It currently reaches more than 30,000 students annually. America's Foundation for Chess has initiated programs in partnership with local school districts in several U.S. cities, including Seattle, San Diego, Philadelphia, and Tampa. The Chess'n Math Association promotes chess at the scholastic level in Canada. Chess for Success is a program for at-risk schools in Oregon. Since 1991, the U.S. Chess Center in Washington, D.C. teaches chess to children, especially those in the inner city, \"as a means of improving their academic and social skills.\"\n\nThere are a number of experiments that suggest that learning and playing chess aids the mind. The Grandmaster Eugene Torre Chess Institute in the Philippines, the United States Chess Federation's chess research bibliography, and English educational consultant Tony Buzan's Brain Foundation, among others, continuously collect such experimental results. The advent of chess software that automatically record and analyze the moves of each player in each game and can tirelessly play with human players of various levels, further helped in giving new directions to experimental designs on chess as mental training.\n\nAs early as 1779 Benjamin Franklin, in his article \"The morals of chess\", has advocated such a view:\n\"The Game of Chess is not merely an idle amusement; several very valuable qualities of the mind, useful in the course of human life, are to be acquired and strengthened by it, so as to become habits ready on all occasions; for life is a kind of Chess, in which we have often points to gain, and competitors or adversaries to contend with, and in which there is a vast variety of good and ill events, that are, in some degree, the effect of prudence, or the want of it. By playing at Chess then, we may learn:\n\n1st, Foresight, which looks a little into futurity, and considers the consequences that may attend an action ...\n\n2nd, Circumspection, which surveys the whole Chess-board, or scene of action: - the relation of the several Pieces, and their situations; ...\n\n3rd, Caution, not to make our moves too hastily...\"\nAlfred Binet demonstrated in the late 19th century that good chess players have superior memory and imagination. Adriaan de Groot concurred with Alfred Binet that visual memory and visual perception are important attributors and that problem-solving ability is of paramount importance. Thus, since 1972, at the collegiate level, the University of Texas at Dallas and the University of Maryland, Baltimore County both recruit chessplayer-scholars and run scholastic outreach programs in their respective communities.\n\n"}
{"id": "3116066", "url": "https://en.wikipedia.org/wiki?curid=3116066", "title": "Colure", "text": "Colure\n\nColure, in astronomy, is either of the two principal meridians of the celestial sphere.\n\nThe \"equinoctial colure\" is the meridian or great circle of the celestial sphere which passes through the celestial poles and the two equinoxes: the first point of Aries and the first point of Libra.\n\nThe \"solstitial colure\" is the meridian or great circle of the celestial sphere which passes through the poles and the two solstices: the first point of Cancer and the first point of Capricorn. There are several stars closely aligned with the solstitial colure: Pi Herculis, Delta Aurigae, and Theta Scorpii. This makes the solstitial colure point towards the North Celestial Pole and Polaris.\n\n\n"}
{"id": "5808518", "url": "https://en.wikipedia.org/wiki?curid=5808518", "title": "Communication physics", "text": "Communication physics\n\nCommunication physics is one of the applied branches of physics. It deals with various kinds of communication systems\n"}
{"id": "56452747", "url": "https://en.wikipedia.org/wiki?curid=56452747", "title": "Cryogenic electron microscopy", "text": "Cryogenic electron microscopy\n\nCryo-Electron Microscopy (Cryo-EM) is an electron microscopy (EM) technique applied on samples cooled to cryogenic temperatures and embedded in an environment of vitreous water. An aqueous sample solution is applied to a grid-mesh and plunge-frozen in liquid ethane. While development of the technique began in the 1970s, recent advances in detector technology and software algorithms have allowed for the determination of biomolecular structures at near-atomic resolution. This has attracted wide attention to the approach as an alternative to X-ray crystallography or NMR spectroscopy for macromolecular structure determination without the need for crystallization.\n\nIn 2017, the Nobel Prize in Chemistry was awarded to Jacques Dubochet, Joachim Frank, and Richard Henderson \"for developing cryo-electron microscopy for the high-resolution structure determination of biomolecules in solution.\"\n\nTransmission electron cryomicroscopy (CryoTEM) is a transmission electron microscopy technique that is used in structural biology.\n\nIn the 1960s, scientist were faced with the issue of structure determination methods using electron microscopy damaging the specimen due to high energy electron beams, so cryogenic electron microscopy was considered to overcome this issue as it was expected that low temperatures would reduce beam damage. In 1980, Erwin Knapek and Jacques Dubochet published commenting on beam damage at cryogenic temperatures sharing observations that:Thin crystals mounted on carbon film were found to be from 30 to 300 times more beam-resistant at 4 K than at room temperature... Most of our results can be explained by assuming that cryoprotection in the region of 4 K is strongly dependent on the temperature.However, these results were not reproducible and amendments were published in the Nature international journal of science just 2 years later informing that the beam resistance was less significant than initially anticipated. The protection gained at 4 K was closer to “tenfold for standard samples of L-valine,” than what was previously stated.\n\nIn 2017, three scientists, Jacques Dubochet, Joachim Frank and Richard Henderson were awarded the Nobel Prize in Chemistry for developing a technique that would image biomolecules.\n\nIn 2018, Chemists realized that electron diffraction can be used to readily determine the structures of small molecules that form needle-like crystals, structures that would otherwise need to be determined from X-ray crystallography, by growing larger crystals of the compound.\n\nScanning electron cryomicroscopy (CryoSEM), is scanning electron microscopy technique with a scanning electron microscope's cold stage in a cryogenic chamber.\n\n"}
{"id": "1439607", "url": "https://en.wikipedia.org/wiki?curid=1439607", "title": "Currency band", "text": "Currency band\n\nA currency band is a range of values for the exchange rate for a country’s currency which the country’s central bank acts to keep the exchange rate within.\n\nThe central bank selects a range, or \"band\", of values at which to set their currency, and will intervene in the market or return to a fixed exchange rate if the value of their currency shifts outside this band. This allows for some revaluation, but tends to stabilize the currency's value within the band. In this sense, it is a compromise between a fixed (or \"pegged\") exchange rate and a floating exchange rate.\n\nFor example, the exchange rate of the \"renminbi\" of the mainland of the People's Republic of China has recently been based upon a currency band; the European Economic Community's \"snake in the tunnel\" was a similar concept that failed, but ultimately led to the establishment of the European Exchange Rate Mechanism (ERM) and ultimately the Euro.\n"}
{"id": "27222803", "url": "https://en.wikipedia.org/wiki?curid=27222803", "title": "Data storage tag", "text": "Data storage tag\n\nA data storage tag (DST), also sometimes known as an archival tag, is a data logger that uses sensors to record data at predetermined intervals. Data storage tags usually have a large memory size and a long lifetime. Most archival tags are supported by batteries that allow the tag to record positions for several years. Alternatively some tags are solar powered and allow the scientist to set their own interval; this then allows data to be recorded for significantly longer than battery-only powered tags.\n\nData storage tags can have a variety of sensors; temperature, depth, light, salinity, pressure, pitch and roll, GPS, magnetic and compass. They can be used internally or externally in fish, marine animals or research animals. They are also used in other industries such as the food and beverage industry. \n\nAt the end of the monitoring period, the loggers can be connected to a computer and the data uploaded for analysis. Data collected by data storage tags can be used to infer locations of the animal when it is at large.\n\nArchival tags archive data to internal memory. Once they are recovered the data is then extracted by the researcher. The tag is generally mounted to the animal either by cutting a slit into the animal, inserting the tag, and sewing the opening closed. Alternatively researchers externally attach tags to animals by running anchor lines through the tag and into the dorsal fin for most \"fish\" species. For turtles the tag is epoxied to the shell of the turtle. \n"}
{"id": "6170575", "url": "https://en.wikipedia.org/wiki?curid=6170575", "title": "Dynamic light scattering", "text": "Dynamic light scattering\n\nDynamic light scattering (DLS) is a technique in physics that can be used to determine the size distribution profile of small particles in suspension or polymers in solution. In the scope of DLS, temporal fluctuations are usually analyzed by means of the intensity or photon auto-correlation function (also known as photon correlation spectroscopy or quasi-elastic light scattering). In the time domain analysis, the autocorrelation function (ACF) usually decays starting from zero delay time, and faster dynamics due to smaller particles lead to faster decorrelation of scattered intensity trace. It has been shown that the intensity ACF is the Fourier transformation of the power spectrum, and therefore the DLS measurements can be equally well performed in the spectral domain. DLS can also be used to probe the behavior of complex fluids such as concentrated polymer solutions.\n\nA monochromatic light source, usually a laser, is shot through a polarizer and into a sample. The scattered light then goes through a second polarizer where it is collected by a photomultiplier and the resulting image is projected onto a screen. This is known as a speckle pattern (Figure 1).\n\nAll of the molecules in the solution are being hit with the light and all of the molecules diffract the light in all directions. The diffracted light from all of the molecules can either interfere constructively (light regions) or destructively (dark regions). This process is repeated at short time intervals and the resulting set of speckle patterns are analyzed by an autocorrelator that compares the intensity of light at each spot over time. \nThe polarizers can be set up in two geometrical configurations. One is a vertical/vertical (VV) geometry, where the second polarizer allows light through that is in the same direction as the primary polarizer. In vertical/horizontal (VH) geometry the second polarizer allows light not in same direction as the incident light.\n\nWhen light hits small particles, the light scatters in all directions (Rayleigh scattering) as long as the particles are small compared to the wavelength (below 250 nm). Even if the light source is a laser, and thus is monochromatic and coherent, the scattering intensity fluctuates over time. This fluctuation is due to small molecules in solutions undergoing Brownian motion, and so the distance between the scatterers in the solution is constantly changing with time. This scattered light then undergoes either constructive or destructive interference by the surrounding particles, and within this intensity fluctuation, information is contained about the time scale of movement of the scatterers. Sample preparation either by filtration or centrifugation is critical to remove dust and artifacts from the solution.\n\nThe dynamic information of the particles is derived from an autocorrelation of the intensity trace recorded during the experiment. The second order autocorrelation curve is generated from the intensity trace as follows:\n\nwhere is the autocorrelation function at a particular wave vector, , and delay time, , and is the intensity. The angular brackets <> denote the expected value operator, which in some texts is denoted by a capital .\n\nAt short time delays, the correlation is high because the particles do not have a chance to move to a great extent from the initial state that they were in. The two signals are thus essentially unchanged when compared after only a very short time interval. As the time delays become longer, the correlation decays exponentially, meaning that, after a long time period has elapsed, there is no correlation between the scattered intensity of the initial and final states. This exponential decay is related to the motion of the particles, specifically to the diffusion coefficient. To fit the decay (i.e., the autocorrelation function), numerical methods are used, based on calculations of assumed distributions. If the sample is monodisperse then the decay is simply a single exponential. The Siegert equation relates the second-order autocorrelation function with the first-order autocorrelation function as follows:\n\nwhere the parameter is a correction factor that depends on the geometry and alignment of the laser beam in the light scattering setup. It is roughly equal to the inverse of the number of speckle (see Speckle pattern) from which light is collected. A smaller focus of the laser beam yields a coarser speckle pattern, a lower number of speckle on the detector, and thus a larger second order autocorrelation.\n\nThe most important use of the autocorrelation function is its use for size determination.\n\nDynamic light scattering provides insight into the dynamic properties of soft materials by measuring single scattering events, meaning that each detected photon has been scattered by the sample exactly once. However, the application to many systems of scientific and industrial relevance has been limited due to often-encountered multiple scattering, wherein photons are scattered multiple times by the sample before being detected. Accurate interpretation becomes exceedingly difficult for systems with nonnegligible contributions from multiple scattering. Especially for larger particles and those with high refractive index contrast, this limits the technique to very low particle concentrations, and a large variety of systems are, therefore, excluded from investigations with dynamic light scattering. However, as shown by Schaetzel, it is possible to suppress multiple scattering in dynamic light scattering experiments via a cross-correlation approach. The general idea is to isolate singly scattered light and suppress undesired contributions from multiple scattering in a dynamic light scattering experiment. Different implementations of cross-correlation light scattering have been developed and applied. Currently, the most widely used scheme is the so-called 3D-dynamic light scattering method. The same method can also be used to correct static light scattering data for multiple scattering contributions. Alternatively, in the limit of strong multiple scattering, a variant of dynamic light scattering called diffusing-wave spectroscopy can be applied.\n\nOnce the autocorrelation data have been generated, different mathematical approaches can be employed to determine 'information' from it. Analysis of the scattering is facilitated when particles do not interact through collisions or electrostatic forces between ions. Particle-particle collisions can be suppressed by dilution, and charge effects are reduced by the use of salts to collapse the electrical double layer.\n\nThe simplest approach is to treat the first order autocorrelation function as a single exponential decay. This is appropriate for a monodisperse population.\n\nwhere is the decay rate. The translational diffusion coefficient may be derived at a single angle or at a range of angles depending on the wave vector .\n\nwith\n\nwhere is the incident laser wavelength, is the refractive index of the sample and is angle at which the detector is located with respect to the sample cell.\n\nDepending on the anisotropy and polydispersity of the system, a resulting plot of vs. may or may not show an angular dependence. Small spherical particles will show no angular dependence, hence no anisotropy. A plot of vs. will result in a horizontal line. Particles with a shape other than a sphere will show anisotropy and thus an angular dependence when plotting of vs. . The intercept will be in any case the D. Thus there is an optimum angle of detection for each particle size. A high quality analysis should always be performed at several scattering angles (multiangle DLS). This becomes even more important in a polydisperse sample with an unknown particle size distribution. At certain angles the scattering intensity of some particles will completely overwhelm the weak scattering signal of other particles, thus making them invisible to the data analysis at this angle. DLS instruments which only work at a fixed angle can only deliver good results for some particles. Thus the indicated precision of a DLS instrument with only one detection angle is only ever true for certain particles.\n\nIn most cases, samples are polydisperse. Thus, the autocorrelation function is a sum of the exponential decays corresponding to each of the species in the population.\n\nIt is tempting to obtain data for and attempt to invert the above to extract . Since is proportional to the relative scattering from each species, it contains information on the distribution of sizes. However, this is known as an ill-posed problem. The methods described below (and others) have been developed to extract as much useful information as possible from an autocorrelation function.\n\nOne of the most common methods is the cumulant method, from which in addition to the sum of the exponentials above, more information can be derived about the variance of the system as follows:\n\nwhere is the average decay rate and is the second order polydispersity index (or an indication of the variance). A third-order polydispersity index may also be derived but this is necessary only if the particles of the system are highly polydisperse. The z-averaged translational diffusion coefficient may be derived at a single angle or at a range of angles depending on the wave vector .\n\nOne must note that the cumulant method is valid for small and sufficiently narrow . One should seldom use parameters beyond µ, because overfitting data with many parameters in a power-series expansion will render all the parameters including formula_9 and µ, less precise.\nThe cumulant method is far less affected by experimental noise than the methods below.\n\nAn alternative method for analyzing the autocorrelation function can be achieved through an inverse Laplace transform known as CONTIN developed by Steven Provencher. The CONTIN analysis is ideal for heterodisperse, polydisperse, and multimodal systems that cannot be resolved with the cumulant method. The resolution for separating two different particle populations is approximately a factor of five or higher and the difference in relative intensities between two different populations should be less than 1:10.\n\nThe Maximum entropy method is an analysis method that has great developmental potential. The method is also used for the quantification of sedimentation velocity data from analytical ultracentrifugation. The maximum entropy method involves a number of iterative steps to minimize the deviation of the fitted data from the experimental data and subsequently reduce the χ of the fitted data.\n\nIf the particle in question is not spherical, rotational motion must be considered as well because the scattering of the light will be different depending on orientation. According to Pecora, rotational Brownian motion will affect the scattering when a particle fulfills two conditions; they must be both optically and geometrically anisotropic. Rod shaped molecules fulfill these requirements, so a rotational diffusion coefficient must be considered in addition to a translational diffusion coefficient. In its most succinct form the equation appears as\n\nWhere is the ratio of the two relaxation modes (translational and rotational), contains information about the axis perpendicular to the central axis of the particle, and contains information about the axis parallel to the central axis.\n\nIn 2007, Peter R. Lang and his team decided to use dynamic light scattering to determine the particle length and aspect ratio of short gold nanorods. They chose this method due to the fact that it does not destroy the sample and it has a relatively easy setup. Both relaxation states were observed in VV geometry and the diffusion coefficients of both motions were used to calculate the aspect ratios of the gold nanoparticles.\n\nDLS is used to characterize size of various particles including proteins, polymers, micelles, vesicles, carbohydrates, nanoparticles, biological cells and gels. If the system is not disperse in size, the mean effective diameter of the particles can be determined. This measurement depends on the size of the particle core, the size of surface structures, particle concentration, and the type of ions in the medium.\n\nSince DLS essentially measures fluctuations in scattered light intensity due to diffusing particles, the diffusion coefficient of the particles can be determined. DLS software of commercial instruments typically displays the particle population at different diameters. If the system is monodisperse, there should only be one population, whereas a polydisperse system would show multiple particle populations. If there is more than one size population present in a sample then either the CONTIN analysis should be applied for photon correlation spectroscopy instruments, or the power spectrum method should be applied for Doppler shift instruments.\n\nStability studies can be done conveniently using DLS. Periodical DLS measurements of a sample can show whether the particles aggregate over time by seeing whether the hydrodynamic radius of the particle increases. If particles aggregate, there will be a larger population of particles with a larger radius. In some DLS machines, stability depending on temperature can be analyzed by controlling the temperature \"in situ\".\n\n"}
{"id": "12872534", "url": "https://en.wikipedia.org/wiki?curid=12872534", "title": "Edmund February", "text": "Edmund February\n\nEdmund C February is an Associate Professor in the Department of Biological Sciences at the University of Cape Town, South Africa. His main research interest are in obtaining a better understanding of where plants get their resources and how this affects vegetation structure. He explores the processes that define the boundaries between different vegetation types, as well as the anthropogenic effect on the environment.\n\nHe is also well known internationally as a rock climber, being perhaps the most prominent black climber in South Africa. Named after one of the two climbers first confirmed to reach the summit of Everest, Edmund Hillary, and living in the shadow of Table Mountain, Edmund was destined to be a climber. He had to overcome immense challenges to become one: during Apartheid he wasn’t welcome in the Mountain Club of South Africa and had to outwit authorities to climb on restricted land.\n\nProf. February has opened more than 500 new climbing routes throughout Africa and has been on climbing expeditions to Australia, America, Britain, Cameroon, France, Germany, India, Italy, Kenya, Lesotho, Malaysia, Malawi, Mali, Morocco, Namibia, Nepal, Thailand, and Zimbabwe.\n\nExcerpts from an interview with Ed February where recently added to the BBC Scotland, Great Climb video archive.\n\n"}
{"id": "50753594", "url": "https://en.wikipedia.org/wiki?curid=50753594", "title": "Estufa Fria", "text": "Estufa Fria\n\nThe Estufa Fria is a greenhouse with three gardens located in Eduardo VII Park, between Alameda Engenheiro Edgar Cardoso and Alameda Cardeal Cerejeira in Lisbon, Portugal.\n\nWith an area of about 1.5 hectares, it consists of three parts, the Cold Greenhouse proper, Glasshouse Hot and Sweet Greenhouse. The cold area, the largest of the three with about 8100 square meters, is covered with a lath of wood that naturally control the temperature and light inside. Alberga species such as azalea (\"rhododendron\" spp.) and camellias (\"Camellia japonica\") from various parts of the world.\n\nThe area of the Estufa Quente occupies about 3000 square meters and is home to such tropical climate species as coffee (\" coffea\" sp.) and mangifera.\n\nThe Estufa Doce has species of cacti, and other succulent plants, such as aloe (\"Aloe vera\").\n\nThe whole greenhouse features small lakes, waterfalls and statues.\n\nThe Estufa Fria opened in 1933, being the result of a project conceived by architect Raul Carapinha. It was built on an area of old basalt mining , which stopped after the discovery of a source of water in the place.\n\nThe greenhouse underwent a remodeling that accompanied the remodeling of Parque Eduardo VII, with the construction of the lake at the entrance and a huge living room, the ship call, which hosts several types of events.\n\nIn 1975 two new sections opened, the Estufa Quente and Estufa Doce, expanding the botanical collection to include plants from the tropics and equatorial species.\n\nThe term \"cold greenhouse\" comes from not using any heating system. Wooden slats protect the plants from excessively hot or cold temperatures.\n\nThere are white Soares statues, Leopoldo de Almeida and Teixeira Angels (son). As to the porch of the entrance, it is a project of Keil do Amaral.\n\nOn 29 April 2009, the cold greenhouse closed due to the risk of collapse of its steel structure covering. After two years of work, it reopened in April 2011.\n\n"}
{"id": "50900082", "url": "https://en.wikipedia.org/wiki?curid=50900082", "title": "François de Baillou", "text": "François de Baillou\n\nFrançois de Baillou (ca. 1700-1774) was a French scientific instrument makers.\n\nBorn into a French family settled in Milan, François de Baillou conducted research on a wide range of scientific topics. A distinguished optician, he produced numerous microscopes and telescopes in a period of thirty years (1734-1764). In 1750, he received the title of \"Regio Cesareo Ottico\" [Imperial Optician] from Empress Maria Theresa of Austria (1717-1780) via Count Harnach, Governor of Milan. From his published booklets on his optical instruments, we learn that he made mono- and binocular telescopes of various sizes and in different versions (theater, pocket, astronomical, terrestrial), simple and compound microscopes, camera obscuras and magic lanterns, and lenses and cylinders for anamorphoses. Many of Baillou's instruments are now preserved in public and private collections.\n\n"}
{"id": "21633243", "url": "https://en.wikipedia.org/wiki?curid=21633243", "title": "Gustav Budde-Lund", "text": "Gustav Budde-Lund\n\nGustav Henrik Andreas Budde-Lund (11 January 1846 – 19 September 1911) was a Danish invertebrate zoologist. In 1868, he co-founded the \"Entomologisk Forening\", alongside Rasmus William Traugott Schlick, Carl August Møller, Andreas Haas and Ivar Frederik Christian Ammitzbøll. He was a student of entomologist J. C. Schiødte, and became a leading authority on terrestrial isopods (woodlice, pill bugs and relatives), describing over 70 genera and around 500 species. He married in 1875 and in 1885 produced his seminal work \"Crustacea Isopoda terrestria\". The woodlouse genus \"Buddelundiella\" was named in Budde-Lund's honour by Filippo Silvestri in 1897.\n"}
{"id": "8633642", "url": "https://en.wikipedia.org/wiki?curid=8633642", "title": "Heinlein (crater)", "text": "Heinlein (crater)\n\nHeinlein is a crater in Promethei Terra, Mars. Centered at 64.6 degrees south, 243.8 degrees west, it is 83 km in diameter and is in the southeast end of the Hellas quadrangle. It forms a crater pair with Weinbaum as the southern rim touches that crater, that crater is in the Southern Polar Region.\n\nOther nearby named prominent craters are Huxley to the west, Wells to the east-northeast and Byrd to the east, the latter two are not of the Hellas quadrangle.\n\nIt is named after Robert A. Heinlein, a leading science fiction author.\n\nHeinlein helped to narrate the Moon landing with Walter Cronkite on CBS in 1969. He was involved in the planning of the Star Wars Defense program in the 1980s. Several of his novels involve Mars, especially \"Stranger in a Strange Land\", \"Red Planet\", and \"Podkayne of Mars\". Many NASA officials say that his works inspired them to enter the space industry.\n"}
{"id": "789458", "url": "https://en.wikipedia.org/wiki?curid=789458", "title": "L'Année Sociologique", "text": "L'Année Sociologique\n\nL'Année Sociologique is an academic journal of sociology established in 1898 by Émile Durkheim, who also served as its editor. It was published annually until 1925, changing its name to \"Annales Sociologiques\" between 1934 and 1942. After World War II it returned to its original name. Durkheim established the journal as a way of publicizing his own research and the research of his students and other scholars working within his new sociological paradigm.\n\nUntil 1969 a part of the journal was classified into three groups: (1) anthropology and sociology, (2) empirical qualitative sociology, and (3) empirical quantitative sociology. The rest was dedicated to book reviews. Durkheim wanted to use the journal to describe contents of the books reviewed.\n\nMany well-known sociologists were initial contributors to the journal, including Célestin Bouglé, Henri Hubert, Marcel Mauss, Francois Simiand and Georg Simmel. During Durkheim's directorship of the journal,the editorial board comprised a team of approximately fifty authors, a group which became known as the 'French school of sociology'.\n\nThe journal was relaunched following a break in publication due to World War I and the death of Durkheim in 1917. Mauss' \"The\" \"Essay on the Gift\" was the only article included in the relaunched edition, preceded by his eulogy to colleagues who had died since the previous edition in 1912.\n\nAlthough originally influenced by Émile Durkheim, the modern journal is based on accurate actual research in the history of the social sciences. Originally publishing in French only, the journal now also publishes translations from French and articles written in English.\n\n\n"}
{"id": "37122169", "url": "https://en.wikipedia.org/wiki?curid=37122169", "title": "Labor geography", "text": "Labor geography\n\nLabor geography is a sub-discipline of human geography and economic geography that deals with the spatial relationships and geographic trends within labor and political systems.\n\n\n"}
{"id": "4972809", "url": "https://en.wikipedia.org/wiki?curid=4972809", "title": "List of Ace SF letter-series single titles", "text": "List of Ace SF letter-series single titles\n\nAce Books have published hundreds of science fiction titles, starting in 1953. Many of these were Ace Doubles (dos-a-dos format), but they also published many single volumes. Between 1953 and 1968, the books had a letter-series identifier; after that date they were given five digit numeric serial numbers. There were a total of 378 letter-series sf titles(62 S&D, 174 F, 19 M, 78 G, 29 H, 1 N, 1 K, and 14 A series books).\n\nThe list given here gives a date of publication; in all cases this refers to the date of publication by Ace, and not the date of original publication of the novels. For more information about the history of these titles, see Ace Books, which includes a discussion of the serial numbering conventions used and an explanation of the letter-code system.\n\n\n\n\n\n\n\nAce Books published its A series of books from about 1966 to 1968, priced at 75 cents.\n\n\n\n\nThe following references have not been seen:\n\n"}
{"id": "34358008", "url": "https://en.wikipedia.org/wiki?curid=34358008", "title": "List of European tornadoes in 2010", "text": "List of European tornadoes in 2010\n\nThis is a list of all tornadoes that were confirmed throughout Europe by the European Severe Storms Laboratory and local meteorological agencies during 2010. Unlike the United States, the original Fujita Scale and the TORRO scale are used to rank tornadoes across the continent.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "57247430", "url": "https://en.wikipedia.org/wiki?curid=57247430", "title": "List of German chemists", "text": "List of German chemists\n\nThis is a list of German chemists.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "17527247", "url": "https://en.wikipedia.org/wiki?curid=17527247", "title": "List of cutaneous conditions", "text": "List of cutaneous conditions\n\nMany conditions affect the human integumentary system—the organ system covering the entire surface of the body and composed of skin, hair, nails, and related muscle and glands. The major function of this system is as a barrier against the external environment. The skin weighs an average of four kilograms, covers an area of two square meters, and is made of three distinct layers: the epidermis, dermis, and subcutaneous tissue. The two main types of human skin are: glabrous skin, the hairless skin on the palms and soles (also referred to as the \"palmoplantar\" surfaces), and hair-bearing skin. Within the latter type, the hairs occur in structures called pilosebaceous units, each with hair follicle, sebaceous gland, and associated arrector pili muscle. In the embryo, the epidermis, hair, and glands form from the ectoderm, which is chemically influenced by the underlying mesoderm that forms the dermis and subcutaneous tissues.\n\nThe epidermis is the most superficial layer of skin, a squamous epithelium with several strata: the stratum corneum, stratum lucidum, stratum granulosum, stratum spinosum, and stratum basale. Nourishment is provided to these layers by diffusion from the dermis, since the epidermis is without direct blood supply. The epidermis contains four cell types: keratinocytes, melanocytes, Langerhans cells, and Merkel cells. Of these, keratinocytes are the major component, constituting roughly 95 percent of the epidermis. This stratified squamous epithelium is maintained by cell division within the stratum basale, in which differentiating cells slowly displace outwards through the stratum spinosum to the stratum corneum, where cells are continually shed from the surface. In normal skin, the rate of production equals the rate of loss; about two weeks are needed for a cell to migrate from the basal cell layer to the top of the granular cell layer, and an additional two weeks to cross the stratum corneum.\n\nThe dermis is the layer of skin between the epidermis and subcutaneous tissue, and comprises two sections, the papillary dermis and the reticular dermis. The superficial papillary dermis interdigitates with the overlying rete ridges of the epidermis, between which the two layers interact through the basement membrane zone. Structural components of the dermis are collagen, elastic fibers, and ground substance. Within these components are the pilosebaceous units, arrector pili muscles, and the eccrine and apocrine glands. The dermis contains two vascular networks that run parallel to the skin surface—one superficial and one deep plexus—which are connected by vertical communicating vessels. The function of blood vessels within the dermis is fourfold: to supply nutrition, to regulate temperature, to modulate inflammation, and to participate in wound healing.\n\nThe subcutaneous tissue is a layer of fat between the dermis and underlying fascia. This tissue may be further divided into two components, the actual fatty layer, or panniculus adiposus, and a deeper vestigial layer of muscle, the panniculus carnosus. The main cellular component of this tissue is the adipocyte, or fat cell. The structure of this tissue is composed of septal (i.e. linear strands) and lobular compartments, which differ in microscopic appearance. Functionally, the subcutaneous fat insulates the body, absorbs trauma, and serves as a reserve energy source.\n\nConditions of the human integumentary system constitute a broad spectrum of diseases, also known as dermatoses, as well as many nonpathologic states (like, in certain circumstances, melanonychia and racquet nails). While only a small number of skin diseases account for most visits to the physician, thousands of skin conditions have been described. Classification of these conditions often presents many nosological challenges, since underlying etiologies and pathogenetics are often not known. Therefore, most current textbooks present a classification based on location (for example, conditions of the mucous membrane), morphology (chronic blistering conditions), etiology (skin conditions resulting from physical factors), and so on. Clinically, the diagnosis of any particular skin condition is made by gathering pertinent information regarding the presenting skin lesion(s), including the location (such as arms, head, legs), symptoms (pruritus, pain), duration (acute or chronic), arrangement (solitary, generalized, annular, linear), morphology (macules, papules, vesicles), and color (red, blue, brown, black, white, yellow). Diagnosis of many conditions often also requires a skin biopsy which yields histologic information that can be correlated with the clinical presentation and any laboratory data.\n\nAcneiform eruptions are caused by changes in the pilosebaceous unit.\n\n\nAutoinflammatory syndromes are a group of inherited disorders characterized by bouts of inflammatory skin lesions and periodic fevers.\n\n\nChronic blistering cutaneous conditions have a prolonged course and present with vesicles and bullae.\n\n\nConditions of the mucous membranes involve the moist linings of the eyes, nose, mouth, genitals, and anus.\n\n\nConditions of the skin appendages are those affecting the glands of the skin, hair, nails, and arrector pili muscles.\n\n\nConditions of the subcutaneous fat are those affecting the layer of adipose tissue that lies between the dermis and underlying fascia.\n\n\nCutaneous congenital anomalies are a diverse group of disorders that result from faulty morphogenesis, the biological process that forms the shape of a human body.\n\n\nConnective tissue diseases are caused by a complex array of autoimmune responses that target or affect collagen or ground substance.\n\n\nAbnormalities of dermal fibrous and elastic tissue are caused by problems in the regulation of collagen synthesis or degradation.\n\nDermal and subcutaneous growths result from (1) reactive or neoplastic proliferation of cellular components of the dermis or subcutaneous tissue, or (2) neoplasms invading or aberrantly present in the dermis.\n\n\nDermatitis is a general term for \"inflammation of the skin\".\n\n\nAtopic dermatitis is a chronic dermatitis associated with a hereditary tendency to develop allergies to food and inhalant substances.\n\n\nContact dermatitis is caused by certain substances coming in contact with the skin.\n\n\nEczema refers to a broad range of conditions that begin as spongiotic dermatitis and may progress to a lichenified stage.\n\nPustular dermatitis is an inflammation of the skin that presents with pustular lesions.\n\n\nSeborrheic dermatitis is a chronic, superficial, inflammatory disease characterized by scaling on an erythematous base.\n\n\nDisturbances of human pigmentation, either loss or reduction, may be related to loss of melanocytes or the inability of melanocytes to produce melanin or transport melanosomes correctly.\n\n\nDrug eruptions are adverse drug reactions that present with cutaneous manifestations.\n\n\nEndocrine conditions often present with cutaneous findings as the skin interacts with the endocrine system in many ways.\n\n\nEosinophilic cutaneous conditions encompass a wide variety of diseases that are characterized histologically by the presence of eosinophils in the inflammatory infiltrate, or evidence of eosinophil degranulation.\n\n\nEpidermal nevi, neoplasms, and cysts are skin lesions that develop from the epidermal layer of the skin.\n\n\nErythemas are reactive skin conditions in which there is blanchable redness.\n\n\nGenodermatoses are inherited genetic skin conditions often grouped into three categories: chromosomal, single gene, and polygenetic.\n\n\nInfection-related cutaneous conditions may be caused by bacteria, fungi, yeast, viruses, or parasites.\n\nBacterium-related cutaneous conditions often have distinct morphologic characteristics that may be an indication of a generalized systemic process or simply an isolated superficial infection.\n\n\n\"Mycobacterium\"-related cutaneous conditions are caused by \"Mycobacterium\" infections.\n\n\nMycosis-related cutaneous conditions are caused by fungi or yeasts, and may present as either a superficial or deep infection of the skin, hair, or nails.\n\n\nParasitic infestations, stings, and bites in humans are caused by several groups of organisms belonging to the following phyla: Annelida, Arthropoda, Bryozoa, Chordata, Cnidaria, Cyanobacteria, Echinodermata, Nemathelminthes, Platyhelminthes, and Protozoa.\n\n\nVirus-related cutaneous conditions are caused by two main groups of viruses–DNA and RNA types–both of which are obligatory intracellular parasites.\n\n\nLichenoid eruptions are dermatoses related to the unique, common inflammatory disorder lichen planus, which affects the skin, mucous membranes, nails, and hair.\n\n\nLymphoid-related cutaneous conditions are a group of disorders characterized by collections of lymphocyte cells within the skin.\n\n\nMelanocytic nevi and neoplasms are caused by either a proliferation of (1) melanocytes, or (2) nevus cells, a form of melanocyte that lack dendritic processes.\n\n\nMelanoma is a malignant proliferation of melanocytes and the most aggressive type of skin cancer.\n\n\nMonocyte- and macrophage-related cutaneous conditions are characterized histologically by infiltration of the skin by monocyte or macrophage cells, often divided into several categories, including granulomatous disease, histiocytoses, and sarcoidosis.\n\n\nMucinoses are a group of conditions caused by dermal fibroblasts producing abnormally large amounts of mucopolysaccharides.\n\n\nNeurocutaneous conditions are due organic nervous system disease or are psychiatric in etiology.\n\n\nNoninfectious immunodeficiency-related cutaneous conditions are caused by T-cell or B-cell dysfunction.\n\n\nNutrition-related cutaneous conditions are caused by malnutrition due to an improper or inadequate diet.\n\n\nPapulosquamous hyperkeratotic cutaneous conditions are those that present with papules and scales caused by a thickening of the stratum corneum.\n\nPalmoplantar keratodermas are a diverse group of hereditary and acquired keratodermas in which there is hyperkeratosis of the skin of the palms and soles.\n\nPregnancy-related cutaneous conditions are a group of skin changes observed during pregnancy.\n\n\nPruritus, commonly known as itchiness, is a sensation exclusive to the skin, and characteristic of many skin conditions.\n\n\nPsoriasis is a common, chronic, and recurrent inflammatory disease of the skin characterized by circumscribed, erythematous, dry, scaling plaques.\n\nReactive neutrophilic cutaneous conditions constitute a spectrum of disease mediated by neutrophils, and typically associated with underlying diseases, such as inflammatory bowel disease and hematologic malignancy.\n\nRecalcitrant palmoplantar eruptions are skin conditions of the palms and soles which are resistant to treatment.\n\n\nSkin conditions resulting from errors in metabolism are caused by enzymatic defects that lead to an accumulation or deficiency of various cellular components, including, but not limited to, amino acids, carbohydrates, and lipids.\n\n\nSkin conditions resulting from physical factors occur from a number of causes, including, but not limited to, hot and cold temperatures, friction, and moisture.\n\n\nIonizing radiation-induced cutaneous conditions result from exposure to ionizing radiation.\n\n\nUrticaria is a vascular reaction of the skin characterized by the appearance of wheals, which are firm, elevated swelling of the skin. Angioedema, which can occur alone or with\nurticaria, is characterized by a well-defined, edematous swelling that involves subcutaneous tissues, abdominal organs, or upper airway.\n\nVascular-related cutaneous conditions result from dysfunction of the blood or blood vessels in the dermis, or lymphatics in the subcutaneous tissues.\n\n\n\n"}
{"id": "29574416", "url": "https://en.wikipedia.org/wiki?curid=29574416", "title": "List of psychotherapy journals", "text": "List of psychotherapy journals\n\nThis is a list of academic journals pertaining to the field of psychotherapy.\n\n\n"}
{"id": "24936706", "url": "https://en.wikipedia.org/wiki?curid=24936706", "title": "List of rock formations that resemble human beings", "text": "List of rock formations that resemble human beings\n\nA list of rock formations worldwide that resemble human beings.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "11485569", "url": "https://en.wikipedia.org/wiki?curid=11485569", "title": "List of towns and cities with 100,000 or more inhabitants/country: L-M-N-O", "text": "List of towns and cities with 100,000 or more inhabitants/country: L-M-N-O\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "43457615", "url": "https://en.wikipedia.org/wiki?curid=43457615", "title": "Membrane theory of shells", "text": "Membrane theory of shells\n\nThe membrane theory of shells, or membrane theory for short, describes the mechanical properties of shells when twisting and bending moments are small enough to be negligible.\n\nThe spectacular simplification of membrane theory makes possible the examination of a wide variety of shapes and supports, in particular, tanks and shell roofs. There are heavy penalties paid for this simplification, and such inadequacies are apparent through critical inspection, remaining within the theory, of solutions. However, this theory is more than a first approximation. If a shell is shaped and supported so as to carry the load within a membrane stress system it may be a desirable solution to the design problem, i.e., thin, light and stiff.\n\n\n"}
{"id": "8178277", "url": "https://en.wikipedia.org/wiki?curid=8178277", "title": "Microstructured optical arrays", "text": "Microstructured optical arrays\n\nMicrostructured optical arrays (MOAs) are instruments for focusing x-rays. MOAs use total external reflection at grazing incidence from an array of small channels to bring x-rays to a common focus. This method of focusing means that MOAs exhibit low absorption. MOAs are used in applications which require x-ray focal spots in the order of few micrometers or below, such as radiobiology of individual cells. Current MOA-based focusing optics designs have two consecutive array components in order to reduce comatic aberration.\n\nMOAs are achromatic (which means the focal properties do not change for radiation of different wavelengths) as they utilize grazing incidence reflection. This means that they are able to focus chromatic radiation to a common point unlike zone plates. MOAs are also adjustable as the optic can be compressed to alter the focal properties such as focal length. Focal length can be calculated for the system in fig. 1 using the geometry shown in fig. 2 where it can be seen that changing the gap between the components (\"d\"+\"D\" in the figure) or the radius of curvature (\"R\") will have a large effect on the focal length.\n\nMOAs have been used in configurations shown in figs. 1 & 3 whereby one or both components can be adjusted. This has varying effects on the focal properties, in general it has been found that smaller focal spot sizes are apparent when MOAs are used as shown in fig. 1 with only the second component adjusted.\n\nThe focal length of this system can be calculated using the geometry shown below:\n\nCurrent microstructured optical arrays are composed of silicon and created via the Bosch process, an example of Deep reactive ion etching and not to be confused with the Haber-Bosch process. In the Bosch process the channels are etched into the silicon using a plasma (plasma (physics)) in increments of a few micrometres. In between each etching the silicon is coated with a polymer in order to preserve the integrity of the channel walls.\n\nThe focal spot size is important in x-ray microprobe instrumentation where x-rays are focused onto a biological sample to investigate phenomena such as the bystander effect.\n\nTo target a specific cell the focal spot size of the system must be around 10 micrometers, whereas to target specific areas of a cell such as the cytoplasm or the cell nucleus it should be no more than a few micrometers. Currently, only MOAs in the configuration shown in fig. 1 are thought to be able to achieve this.\n\nMOAs provide a good alternative to zone plates in microprobe use due to the adjustable focal properties (making cell alignment easier) and ability to provide focusing of chromatic radiation to a single point. This is particularly useful when considering the finding that different effects can be observed using radiation of different wavelengths.\n\n5. \n"}
{"id": "944875", "url": "https://en.wikipedia.org/wiki?curid=944875", "title": "Moritz Balthasar Borkhausen", "text": "Moritz Balthasar Borkhausen\n\nMoritz Balthasar Borkhausen (3 December 1760, Giessen – 30 November 1806, Darmstadt) was a German naturalist and forester. He took part in the production of \"\" by Johann Conrad Susemihl.\n\nHe received his education in Giessen, and in 1796 started work as an assessor at the forestry office in Darmstadt. In 1800 he attained the title of \"Kammerrat\", followed by a role as counselor at the Oberforsthaus Collegium in 1804.\n\nAs a botanist, he was the taxonomic author of Alliaceae and Asclepiadaceae as well as the circumscriber of numerous plant genera and species.\n\n\n\n"}
{"id": "43444201", "url": "https://en.wikipedia.org/wiki?curid=43444201", "title": "NCSA Brown Dog", "text": "NCSA Brown Dog\n\nNCSA Brown Dog is a research project to develop a method for easily accessing historic research data stored in order to maintain the long-term viability of large bodies of scientific research. It is supported by the National Center for Supercomputing Applications (NCSA) that is funded by the National Science Foundation (NSF).\n\nBrown Dog is part of the DataNet partners program funded by NSF in 2008. DataNet was conceived to address the increasingly digital and data-intensive nature of science, engineering and education. Brown Dog is part of a follow-on effort called Data Infrastructure Building Blocks (DIBBs), focused on building software to support DataNet. The project was proposed by researchers at NCSA and the University of Illinois Urbana-Champaign as well as researchers from Boston University and the University of North Carolina at Chapel Hill.\n\nMuch scientific data is smaller, unstructured and uncurated and thus not easily shared. Such data is sometimes referred to as \"long tail\" data. This borrows a term from statistics and refers to the tail of the distribution of project sizes. The majority of smaller projects lack the resources to properly steward the data they produce. This so-called \"long tail\" data, both past and present, has the potential to inform future research in many study areas. Much of this data has become inaccessible due to obsolete software and file formats. The resulting impossibility of reviewing data from older research disrupts the overall scientific research project.\n\nBrown Dog describes itself as the \"super mutt\" of software (thus the name \"Brown Dog\"), serving as a low-level data infrastructure to interface digital data content across the internet. Its approach is to use every possible source of automated help (i.e., software) in existence in a robust and provenance-preserving manner to create a service that can deal with as much of this data as possible. The project sees the broader impact of its work in its potential to serve the general public as a sort of \"DNS for data\", with the goal of making all data and all file formats as accessible as webpages are today.\n\nBrown Dog seeks to address problems involving the use of uncurated and unstructured data collections through the development of two services: the Data Access Proxy (DAP) to aid in the conversion of file formats and the Data Tilling Services (DTS) for the automatic extraction of metadata from file contents. Once developed, researchers and general public users will be able to download browser plugins and other tools from the Brown Dog tool catalog.\n\nData Tilling Service (DTS) will allow users to search data collections using an existing file to discover other similar files in a collection. A DTS search field will be appended to configured browsers where example files can be dropped. This tells DTS to search all the files under a given URL for files similar to the dropped file. For example, while browsing an online image collection, a user could drop an image of three people into the search field, and the DTS would return all images in the collection that also contain three people. If DTS encounters a foreign file format, it will utilize DAP to make the file accessible. DTS also indexes the data and extract and appends metadata to files and collections enabling users to gain some sense of the type of data they are encountering.\n\nThis service runs on port 9443.\n\nData Access Proxy (DAP) allows users to access data files that would otherwise be unreadable. Similar to an internet gateway or Domain Name Service, the DAP configuration would be entered into a user's machine and browser settings. Data requests over HTTP would first be examined by DAP to determine if the native file format is readable on the client device. If not, DAP converts the file into the best available format readable by the client machine. Alternatively, the user could specify the desired format themselves.\n\nThis service runs on port 8184.\n\nBrown Dog targets three use cases proposed by groups within the EarthCube research communities. Developers and researchers from these communities will work together on use cases that span geoscience, engineering, biology and social science.\n\nThis use case is led by Michael Dietze, Boston University\n\nData on the abundance, species composition, and size structure of vegetation is critically important for a wide array of sub-disciplines in ecology, conservation, natural resource management, and global change biology. However, addressing many of the pressing questions in these disciplines will require that terrestrial biosphere and hydrologic models are able to assimilate the large amount of long-tail data that exists but is largely inaccessible. The Brown Dog team in cooperation with researches from Dietze's lab will facilitate the capture of a huge body of smaller research-oriented vegetation data sets collected over many decades and historical vegetation data embedded in Public Land Survey data dating back to 1785. This data will be used as initial conditions for models, to make sense of other large data sets and for model calibration and validation.\n\nThis use case is led by Barbara Minsker, University of Illinois at Urbana-Champaign; William Sullivan, University of Illinois at Urbana-Champaign; Arthur Schmidt, University of Illinois at Urbana-Champaign\n\nThis case study involves developing novel green infrastructure design criteria and models that integrate requirements for storm water management and ecosystem and human health and well being. To address the scientific and social problems associated with the design of green spaces, data accessibility and availability is a major challenge. This study will focus on identified areas of the Green Healthy Neighborhood Planning region within the City of Chicago where existing local sewer performance is most deficient and where changes in impervious area through green infrastructure would be beneficial to under served neighborhoods. Brown Dog will be used to extract long-tail experimental data on human landscape preferences and health impacts. This data will be used to develop a human health impacts model that will then be linked together with a terrestrial biosphere model and a storm water model using Brown Dog technology.\n\nThis use case is led by Praveen Kumar, University of Illinois at Urbana-Champaign\n\nCIF21 DIBBs: Brown Dog was awarded in the winter of 2013 with a start date of October 1, 2013. Estimated expiration date is September 30, 2018.\n\nThe award amount was $10,519,716.00, the largest DIBB award. The principal investigator is Kenton McHenry of NCSA at the University of Illinois at Urbana-Champaign. Coleaders are Jong Lee NCSA/UIUC; Barbara Minsker, Civil and Environmental Engineering, University of Illinois at Urbana-Champaign; Praveen Kumar, Civil and Environmental Engineering, University of Illinois at Urbana-Champaign; Michael Dietze, Department of Earth and Environment, Boston University.\n"}
{"id": "22713586", "url": "https://en.wikipedia.org/wiki?curid=22713586", "title": "Necrophoresis", "text": "Necrophoresis\n\nNecrophoresis is a behavior found in social insects – such as ants, bees, wasps, and termites – in which they carry the dead bodies of members of their colony from the nest or hive area. This acts as a sanitary measure to prevent disease or infection from spreading throughout the colony. Although any member of a colony can carry the bodies, it is usually done by designated 'undertakers'. Ant undertakers have a slightly altered development cycle, and are much more likely than other ants to handle corpse removal. They are not restricted to performing only this task, but they do exhibit different behavioral and movement patterns than other members of the colony, which assist them in this task. Non-undertaker ants may also remove dead bodies, but do so with much less consistency. Differentiating between dead and living insects is accomplished by detecting their chemical signature. Depending on the species, this can be communicated by either the absence of chemicals that are present when they are alive, or by those released in decaying corpses. Corpses will either be taken to a random point a certain distance away from the nest, or placed in a refuse pile closer to the nest, along with other waste. \n\nThe removal of corpses carrying infectious disease is crucial to the health of a colony. Efforts to eliminate colonies of fire ants, for instance, include introducing pathogens into the population, but this has limited efficacy where the infected insects are quickly separated from the population. However, certain infections have been shown to delay the removal of dead bodies or alter where they are placed. Although placing corpses farther away reduces the risk of infection, it also requires more energy. Burial and cannibalism are other recorded methods of corpse disposal among social insects. Termites have been shown to use burial when they cannot afford to devote workers to necrophoresis, especially when forming a new colony.\n\nAlthough in mature ant colonies only workers feature undertaking behaviours, the queen ants from the \"Lasius niger\" species undertake deceased co-founders.\n"}
{"id": "42257649", "url": "https://en.wikipedia.org/wiki?curid=42257649", "title": "Neelima Gupte", "text": "Neelima Gupte\n\nNeelima M. Gupte is an Indian physicist. She obtained her B.Sc from Bombay University in 1976, M.Sc from IIT Bombay in 1978 and Ph.D from SUNY at Stony Brook in 1983. She has subsequently worked at the University of Hyderabad, and was on the faculty of Pune University from 1985 to 1993. She now works as a Professor in the Department of Physics, IIt Madras. Her research interests lie in the field of nonlinear dynamics, and chaos. Some important results obtained by her and her collaborators include the phase transition analogs of the thermodynamics of multifractals, the method of impulsive synchronisation and the enhancement of the eciency of load-bearing and communication networks. Her current research interests include the analysis of spatio-temporal intermittency in extended systems, chaotic advection and the study of networks. In addition to her academic interests, she has also participated in the activities of the 'Women in Physics' group of the International Union of Pure and Applied Physics.\n"}
{"id": "51363292", "url": "https://en.wikipedia.org/wiki?curid=51363292", "title": "Nélida María Bacigalupo", "text": "Nélida María Bacigalupo\n\nNélida María Bacigalupo (born 1924) is an Argentine botanist, curator, and professor. She studied at the National University of La Plata, and in 1953, she received her doctorate in Natural Sciences at the same university. She served as an investigator at the Instituto de Botánica Darwinion, San Isidro, Buenos Aires. Bacigalupo did her botanical research in Paraguay and Argentina. She is a world authority on the Rubiaceae family. She is a member of the Argentine Botanical Society, and was the honorary vice-president of the 33rd Argentine Botany Conference in 2011.\n\n\n"}
{"id": "1550515", "url": "https://en.wikipedia.org/wiki?curid=1550515", "title": "Open-label trial", "text": "Open-label trial\n\nAn open-label trial, or open trial, is a type of clinical trial in which both the researchers and participants know which treatment is being administered.\nThis contrasts with single blind and double blind experimental designs, where participants are not aware of what treatment they are receiving (researchers are also unaware in a double blind trial). \n\nOpen-label trials may be appropriate for comparing two very similar treatments to determine which is most effective. An open-label trial may be unavoidable under some circumstances, such as comparing the effectiveness of a medication to intensive physical therapy sessions.\nAn open-label trial may still be randomized. Open-label trials may also be uncontrolled (i.e. without a placebo group), with all participants receiving the same treatment. \n"}
{"id": "51550758", "url": "https://en.wikipedia.org/wiki?curid=51550758", "title": "Science is a Sacred Cow", "text": "Science is a Sacred Cow\n\nScience is a Sacred Cow is a book written by the chemist Anthony Standen. It was first published in 1950 by E. P. Dutton. It was in print for 40 years. The book argues that some scientists and many teachers of science have \"inflated egos\" or, in the words of Standen, \"a fabulous collective ego, as inflated as a skillfully blown piece of bubble gum\". The book was widely reviewed.\n\nPart of the book's thesis is that the general public and students of science hold the words of scientists in awe even when these are merely \"latinized nonsense\". According to a March 1950 issue of \"Time\", Standen's concerns are that scientists can be and have been \"overbearing,\" \"overpraised,\" and \"overindulged\". The book was once praised by one of the great scientists: Albert Einstein. An editorial note in the March 27, 1950, issue of \"Life\" magazine introducing several pages of excerpts and a half dozen editorial cartoons from \"Sacred Cow\" states \"With tongue-in-cheek hyperbole, [Standen] suggests that a group that takes itself so seriously deserves some serious skepticism. \"Life\"—without taking all Mr. Standen's funmaking too seriously—thinks he deserves a happy hearing\".\n\nThe book is 221 pages and has eight chapters: \n\n"}
{"id": "23964491", "url": "https://en.wikipedia.org/wiki?curid=23964491", "title": "Shanghai University of Political Science and Law", "text": "Shanghai University of Political Science and Law\n\nThe Shanghai University of Political Science and Law is a public university in Shanghai, China, founded in 1984. \n\n"}
{"id": "39657380", "url": "https://en.wikipedia.org/wiki?curid=39657380", "title": "Space Atlas: Mapping the Universe and Beyond", "text": "Space Atlas: Mapping the Universe and Beyond\n\nSpace Atlas: Mapping the Universe and Beyond is a 2012 book by American physicist James Trefil. It is Trefil's 17th book.\n\nThe book contains three parts: \"The Solar System\", \"The Galaxy\", and \"The Universe\"\n\n\"The Space Atlas\" includes star charts, photography, and other information. Trefil, the Robinson Professor of Physics at George Mason University also highlights scientists whose discoveries helped inform this book and human knowledge of the universe, such as Nicolaus Copernicus, who produced the first serious model of the solar system in which the sun was at the center and Earth moved in orbit, and Jocelyn Bell Burnell, who discovered the signals of pulsars.\n"}
{"id": "29163384", "url": "https://en.wikipedia.org/wiki?curid=29163384", "title": "Spanish Flu: The Forgotten Fallen", "text": "Spanish Flu: The Forgotten Fallen\n\nSpanish Flu: The Forgotten Fallen is a 2009 television drama. It deals with Dr James Niven's attempts to deal with the 1918 flu pandemic in Manchester. Its screenplay was written by Peter Harness and it starred Bill Paterson as Niven, along with Mark Gatiss, Kenneth Cranham and Charlotte Riley. It was first broadcast on BBC Four on 5 August 2009.\n\n"}
{"id": "17887977", "url": "https://en.wikipedia.org/wiki?curid=17887977", "title": "Sternal fracture", "text": "Sternal fracture\n\nA sternal fracture is a fracture of the sternum (the breastbone), located in the center of the chest. The injury, which occurs in 5–8% of people who experience significant blunt chest trauma, may occur in vehicle accidents, when the still-moving chest strikes a steering wheel or dashboard or is injured by a seatbelt. Cardiopulmonary resuscitation (CPR), has also been known to cause thoracic injury, including sternum and rib fractures. Sternal fractures may also occur as a pathological fracture, in people who have weakened bone in their sternum, due to another disease process. Sternal fracture can interfere with breathing by making it more painful; however, its primary significance is that it can indicate the presence of serious associated internal injuries, especially to the heart and lungs.\n\nSigns and symptoms include crepitus (a crunching sound made when broken bone ends rub together), pain, tenderness, bruising, and swelling over the fracture site. The fracture may visibly move when the person breathes, and it may be bent or deformed, potentially forming a \"step\" at the junction of the broken bone ends that is detectable by palpation. Associated injuries such as those to the heart may cause symptoms such as abnormalities seen on electrocardiograms.\n\nThe upper and middle parts of the sternum are those most likely to fracture, but most sternal fractures occur below the sternal angle.\n\nBecause of the high frequency of associated injuries, clinicians are taught to suspect that a patient has multiple severe injuries if a sternal fracture is present. Sternal fracture is commonly associated with injuries to the heart and lungs; if a person is injured with enough force to fracture the sternum, injuries such as myocardial and pulmonary contusions are likely. Other associated injuries that may occur include damage to blood vessels in the chest, myocardial rupture, head and abdominal injuries, flail chest, and vertebral fracture. Sternal fractures may also accompany rib fractures and are high-energy enough injuries to cause bronchial tears (ruptures of the bronchioles). They may hinder breathing. Due to the associated injuries, the mortality rate for people with sternal fracture is high, at an estimated 25–45%. However, when sternal fractures occur in isolation, their outcome is very good.\n\nThere is controversy over the question of whether the presence of sternal fracture is an indication of cardiac injuries.\n\nVehicle collisions are the usual cause of sternal fracture; the injury is estimated to occur in about 3% of auto accidents. The chest of a driver who is not wearing a seat belt may strike the steering wheel, and the shoulder component of a seatbelt may injure the chest if it is worn without the lap component. It was common enough for the sternum to be injured by the seatbelt that it was included in the 'safety belt syndrome', a pattern of injuries caused by seat belts in vehicle accidents.\n\nThe injury can also occur when the chest suddenly flexes, in the absence of an impact. In the case of an injury sustained during CPR, the most common injuries sustained are rib fractures, with literature suggesting an incidence between 13% and 97%, and sternal fractures, with an incidence between 1% to 43%. Additionally, injury to the sternum may be made more likely if there are other disease processes in place that have weakened the bone - in this case, the fracture that occurs is termed a pathologic fracture.\n\nX-rays of the chest are taken in people with chest trauma and symptoms of sternal fractures, and these may be followed by CT scanning. Since X-rays taken from the front may miss the injury, they are taken from the side as well.\n\nManagement involves treating associated injuries; people with sternal fractures but no other injuries do not need to be hospitalized. However, because it is common for cardiac injuries to accompany sternal fracture, heart function is monitored with electrocardiogram. Fractures that are very painful or extremely out of place can be operated on to fix the bone fragments into place, but in most cases treatment consists mainly of reducing pain and limiting movement. The fracture may interfere with breathing, requiring tracheal intubation and mechanical ventilation.\n\nPeople who experience a pathologic fracture will be investigated for the cause of the underlying disease, if it is unknown. Treatment of any underlying disease, such as chemotherapy if indicated for bone cancer, may help to improve the pain of a sternal fracture. \nIn 1864, E. Guilt published a handbook recording sternal fractures as a rare injury found in severe trauma. The injury became more common with the introduction and wide use of automobiles and the subsequent rise in traffic accidents. A rise in sternal fractures has also been seen with an increase in the frequency of laws requiring that seat belts be worn.\n\n"}
{"id": "54420371", "url": "https://en.wikipedia.org/wiki?curid=54420371", "title": "The Role of Culture in Early Expansions of Humans", "text": "The Role of Culture in Early Expansions of Humans\n\nThe Role of Culture in Early Expansions of Humans (ROCEEH) is an interdisciplinary project of the Heidelberg Academy of Sciences and Humanities. Within the framework of this Research Center social scientists and natural scientists study the effect that culture had on the successive expansions of humans out of Africa and across the Old World. The Research Center is located at the Eberhard Karls University of Tübingen and the Senckenberg Research Institute in Frankfurt am Main.\n\nThe project was initiated in 2008 by the Heidelberg Academy of Sciences and Humanities and is scheduled to continue for 20 years until 2027.\n\nOver the course of the last 2 million years at least two species of the genus \"Homo\" (\"Homo erectus\" and \"Homo sapiens\") have expanded out of Africa in successive waves into Asia and Europe. Modern humans (\"Homo sapiens\") were probably the only species of hominins capable of settling new territories such as Australia, the sub-arctic region and the Americas. While Australopithecines and early species of humans were limited by their natural environments—as most species are—our ancestors were able to take advantage of their newly developed cultural capacities on their way to becoming human, as well as adaptating to their environment.\n\nThese thoughts helped to establish one of the working hypotheses in the ROCEEH project: We assume that the influence of the environment on the expansions of hominin species decreased through time, while the significance of culture increased through new technologies.\n\nThe ROCEEH project has many goals:\n\nThe project pays special attention to the development of human capabilities that deal with problem-solving through culture.\n\nTo achieve these aims, the project selected six senior researchers with experience in the disciplines of paleoanthropology, paleoecology, paleobotany, geography and archaeology.\n\nA central part of the project is represented by the interdisciplinary and web-based database called the ROCEEH Out-of-Africa Database (ROAD) with geographic information system functions. Geographic data about a locality are added to information about the geological layers, the divisions of archaeological layers, and cultural remains. To complete the picture we gather information about important human and animal fossils, vegetation and climate in order to reconstruct early habitats. Using a geographic information system, we compile the results in a digital atlas to show the important developments in human-environment interactions.\n\nThe ROCEEH is located at the University of Tübingen and the Senckenberg Research Institute in Frankfurt am Main, Germany. The leaders of the Research Center in Tübingen include Nicholas Conard and Volker Hochschild, as well as Volker Mosbrugger and Friedemann Schrenk in Frankfurt am Main. The current chairman of the Scientific Advisory Board is Hermann H. Hahn.\n\nOn occasions, the ROCEEH organizes international workshops, symposiums and conferences, inviting guests to propose new methods and introduce and discuss the latest developments and research results.\n\n"}
{"id": "48385296", "url": "https://en.wikipedia.org/wiki?curid=48385296", "title": "The Sixteen Principles of Urban Design", "text": "The Sixteen Principles of Urban Design\n\n\"Die Sechzehn Grundsätze des Städtebaus\", or \"The Sixteen Principles of Urban Design\", were from 1950 until 1955 the primary model for urban planning in the GDR.\n\n\"Decided by the Government of the German Democratic Republic on 27 July 1950:\n\n\"The urban planning and architectural design of our cities, which shall influence the construction of all of Germany, must express the social order of the German Democratic Republic, as well as the progressive traditions and great goals of our German people. They shall adhere to the following principles:\n\n\nBy September 7, 1950, one day after the adoption of a national building law, the demolition of the heavily damaged Berlin City Palace began. The plan was to build a 90-meter wide stretch of road from the Frankfurter Straße via Alexanderplatz, Königstraße (now Rathausstraße) and the street Unter den Linden to the Brandenburg Gate. The \"central axis\" was to create a new representation Magistrale arise between the Brandenburg Gate and Alexanderplatz, the center of the monumental height dominant - should be in place of the castle, the central government building - as a \"city crown\" the Marx-Engels-Platz. In 1951, Stalinallee emerged as the first Socialist avenue in the GDR. The first stages of construction was from 1952 to 1958, designed by Hermann Henselmann, architect of Hochhaus an der Weberwiese. When the work at Frankfurter Tor was completed in 1960, the historicist style of the avenue was already outdated and perceived almost bashfully. Other major projects were in Dresden at the Altmarkt, in Leipzig on Roßplatz and at the Long Street realized in Rostock. \nFrom 1955 a new phase of urban development in the GDR took place after the Soviet Union adopted new directives for 1954 architecture, which called for greater standardization and the waiving of expensive ornamentation. The second phase of Stalinallee-between Strausberger Platz and Alexander Platz-was therefore built in an industrial aesthetic.\n\n\n"}
{"id": "30719", "url": "https://en.wikipedia.org/wiki?curid=30719", "title": "Tidal force", "text": "Tidal force\n\nThe tidal force is an apparent force that stretches a body towards and away from the center of mass of another body due to a gradient (difference in strength) in gravitational field from the other body; it is responsible for diverse phenomena, including tides, tidal locking, breaking apart of celestial bodies and formation of ring systems within Roche limit, and in extreme cases, spaghettification of objects. It arises because the gravitational field exerted on one body by another is not constant across its parts: the nearest side is attracted more strongly than the farthest side. It is this difference that causes a body to get stretched. Thus, the tidal force is also known as the differential force, as well as a secondary effect of the gravitational field.\n\nIn celestial mechanics, the expression \"tidal force\" can refer to a situation in which a body or material (for example, tidal water) is mainly under the gravitational influence of a second body (for example, the Earth), but is also perturbed by the gravitational effects of a third body (for example, the Moon). The perturbing force is sometimes in such cases called a tidal force (for example, the perturbing force on the Moon): it is the difference between the force exerted by the third body on the second and the force exerted by the third body on the first.\n\nA gravitational force is not the same as a gravitational field. \n\nA \"gravitational field\" extends into the space around a massive body, and results in a \"gravitational force\" on other massive bodies, depending on the distance and mass of those bodies. The strength of the gravitational field decreases as the inverse square of distance from the massive body.\n\n\"Tidal force\" is not a force, but rather a difference in gravitational field strength.\n\nThe relationship of an astronomical body's size, to its distance from another body, strongly influences the magnitude of tidal force. The tidal force acting on an astronomical body, such as the Earth, is directly proportional to the diameter of that astronomical body and inversely proportional to the cube of the distance from another body producing a gravitational attraction, such as the Moon or the Sun. Tidal action on bath tubs, swimming pools, lakes, and other small bodies of water is negligible.\nFigure 3 is a graph showing how gravitational force declines with distance. In this graph, the attractive force decreases in proportion to the square of the distance, while the gradient (slope) decreases in direct proportion to the distance. This is why the gradient at any point is inversely proportional to the cube of the distance.\n\nThe tidal force corresponds to the difference in Y between two points on the graph, with one point on the near side of the body, and the other point on the far side. The tidal force becomes larger, when the two points are either farther apart, or when they are more to the left on the graph, meaning closer to the attracting body.\n\nFor example, the Moon produces a greater tidal force on the Earth than the Sun, even though the Sun exerts a greater gravitational attraction on the Earth than the Moon, because the gradient is less. The Moon produces a greater tidal force on the Earth, than the tidal force of the Earth on the Moon. The distance is the same, but the diameter of the Earth is greater than the diameter of the Moon, resulting in a greater tidal force.\n\nWhat matters is not the total gravitational attraction on a body, but the difference from one side to the other. The greater the diameter of the body, the more difference there will be from one side to the other.\n\nGravitational attraction is inversely proportional to the square of the distance from the source. The attraction will be stronger on the side of a body facing the source, and weaker on the side away from the source. The tidal forced is proportional to the difference.\n\nAs expected, the table below shows that the distance from the Moon to the Earth, is the same as the distance from the Earth to the Moon. The Earth is 81 times more massive than the Moon but has roughly 4 times its radius. As a result, at the same distance, the tidal force per unit mass of the Earth on the Moon is about 20 times stronger than that of the Moon on the Earth.\n\nThus the Earth was able to lock the Moon's rotation to its orbit around the Earth but not vice versa.\n\nWhen a body (body 1) is acted on by the gravity of another body (body 2), the field can vary significantly on body 1 between the side of the body facing body 2 and the side facing away from body 2. Figure 4 shows the differential force of gravity on a spherical body (body 1) exerted by another body (body 2). These so-called \"tidal forces\" cause strains on both bodies and may distort them or even, in extreme cases, break one or the other apart. The Roche limit is the distance from a planet at which tidal effects would cause an object to disintegrate because the differential force of gravity from the planet overcomes the attraction of the parts of the object for one another. These strains would not occur if the gravitational field were uniform, because a uniform field only causes the entire body to accelerate together in the same direction and at the same rate.\n\nIn the case of an infinitesimally small elastic sphere, the effect of a tidal force is to distort the shape of the body without any change in volume. The sphere becomes an ellipsoid with two bulges, pointing towards and away from the other body. Larger objects distort into an ovoid, and are slightly compressed, which is what happens to the Earth's oceans under the action of the Moon. The Earth and Moon rotate about their common center of mass or barycenter, and their gravitational attraction provides the centripetal force necessary to maintain this motion. To an observer on the Earth, very close to this barycenter, the situation is one of the Earth as body 1 acted upon by the gravity of the Moon as body 2. All parts of the Earth are subject to the Moon's gravitational forces, causing the water in the oceans to redistribute, forming bulges on the sides near the Moon and far from the Moon.\n\nWhen a body rotates while subject to tidal forces, internal friction results in the gradual dissipation of its rotational kinetic energy as heat. In the case for the Earth, and Earth's Moon, the loss of rotational kinetic energy results in a gain of about 2 milliseconds per century. If the body is close enough to its primary, this can result in a rotation which is tidally locked to the orbital motion, as in the case of the Earth's moon. Tidal heating produces dramatic volcanic effects on Jupiter's moon Io. Stresses caused by tidal forces also cause a regular monthly pattern of moonquakes on Earth's Moon.\n\nTidal forces contribute to ocean currents, which moderate global temperatures by transporting heat energy toward the poles. It has been suggested that in addition to other factors, harmonic beat variations in tidal forcing may contribute to climate changes. However, no strong link has been found to date.\n\nTidal effects become particularly pronounced near small bodies of high mass, such as neutron stars or black holes, where they are responsible for the \"spaghettification\" of infalling matter. Tidal forces create the oceanic tide of Earth's oceans, where the attracting bodies are the Moon and, to a lesser extent, the Sun. Tidal forces are also responsible for tidal locking, tidal acceleration, and tidal heating. Tides may also induce seismicity.\n\nBy generating conducting fluids within the interior of the Earth, tidal forces also affect the Earth's magnetic field.\n\nFor a given (externally generated) gravitational field, the tidal acceleration at a point with respect to a body is obtained by vector subtraction of the gravitational acceleration at the center of the body (due to the given externally generated field) from the gravitational acceleration (due to the same field) at the given point. Correspondingly, the term tidal force is used to describe the forces due to tidal acceleration. Note that for these purposes the only gravitational field considered is the external one; the gravitational field of the body (as shown in the graphic) is not relevant. (In other words, the comparison is with the conditions at the given point as they would be if there were no externally generated field acting unequally at the given point and at the center of the reference body. The externally generated field is usually that produced by a perturbing third body, often the Sun or the Moon in the frequent example-cases of points on or above the Earth's surface in a geocentric reference frame.)\n\nTidal acceleration does not require rotation or orbiting bodies; for example, the body may be freefalling in a straight line under the influence of a gravitational field while still being influenced by (changing) tidal acceleration.\n\nBy Newton's law of universal gravitation and laws of motion, a body of mass \"m\" at distance \"R\" from the center of a sphere of mass \"M\" feels a force formula_1,\n\nequivalent to an acceleration formula_3,\n\nwhere formula_5 is a unit vector pointing from the body \"M\" to the body \"m\" (here, acceleration from \"m\" towards \"M\" has negative sign).\n\nConsider now the acceleration due to the sphere of mass \"M\" experienced by a particle in the vicinity of the body of mass \"m\". With \"R\" as the distance from the center of \"M\" to the center of \"m\", let ∆\"r\" be the (relatively small) distance of the particle from the center of the body of mass \"m\". For simplicity, distances are first considered only in the direction pointing towards or away from the sphere of mass \"M\". If the body of mass \"m\" is itself a sphere of radius ∆\"r\", then the new particle considered may be located on its surface, at a distance (\"R\" ± \"∆r\") from the centre of the sphere of mass \"M\", and \"∆r\" may be taken as positive where the particle's distance from \"M\" is greater than \"R\". Leaving aside whatever gravitational acceleration may be experienced by the particle towards \"m\" on account of \"m\"s own mass, we have the acceleration on the particle due to gravitational force towards \"M\" as:\n\nPulling out the \"R\" term from the denominator gives:\n\nThe Maclaurin series of formula_8 is formula_9 which gives a series expansion of:\n\nThe first term is the gravitational acceleration due to \"M\" at the center of the reference body formula_11, i.e., at the point where formula_12 is zero. This term does not affect the observed acceleration of particles on the surface of \"m\" because with respect to \"M\", \"m\" (and everything on its surface) is in free fall. When the force on the far particle is subtracted from the force on the near particle, this first term cancels, as do all other even-order terms. The remaining (residual) terms represent the difference mentioned above and are tidal force (acceleration) terms. When ∆\"r\" is small compared to \"R\", the terms after the first residual term are very small and can be neglected, giving the approximate tidal acceleration formula_13 for the distances ∆\"r\" considered, along the axis joining the centers of \"m\" and \"M\":\n\nWhen calculated in this way for the case where ∆\"r\" is a distance along the axis joining the centers of \"m\" and \"M\", formula_15 is directed outwards from to the center of \"m\" (where ∆\"r\" is zero).\n\nTidal accelerations can also be calculated away from the axis connecting the bodies \"m\" and \"M\", requiring a vector calculation. In the plane perpendicular to that axis, the tidal acceleration is directed inwards (towards the center where ∆\"r\" is zero), and its magnitude is formula_16 in linear approximation as in Figure 4.\n\nThe tidal accelerations at the surfaces of planets in the Solar System are generally very small. For example, the lunar tidal acceleration at the Earth's surface along the Moon-Earth axis is about 1.1 × 10 g, while the solar tidal acceleration at the Earth's surface along the Sun-Earth axis is about 0.52 × 10 g, where g is the gravitational acceleration at the Earth's surface. Hence the tide-raising force (acceleration) due to the Sun is about 45% of that due to the Moon. The solar tidal acceleration at the Earth's surface was first given by Newton in the \"Principia\".\n\n\n"}
{"id": "10815131", "url": "https://en.wikipedia.org/wiki?curid=10815131", "title": "Trace theory", "text": "Trace theory\n\nIn mathematics and computer science, trace theory aims to provide a concrete mathematical underpinning for the study of concurrent computation and process calculi. The underpinning is provided by an algebraic definition of the free partially commutative monoid or trace monoid, or equivalently, the history monoid, which provides a concrete algebraic foundation, analogous to the way that the free monoid provides the underpinning for formal languages. \n\nThe power of trace theory stems from the fact that the algebra of dependency graphs (such as Petri nets) is isomorphic to that of trace monoids, and thus, one can apply both algebraic formal language tools, as well as tools from graph theory. \n\nWhile the trace monoid had been studied by Pierre Cartier and Dominique Foata for its combinatorics in the 1960s, trace theory was first formulated by Antoni Mazurkiewicz in the 1970s, in an attempt to evade some of the problems in the theory of concurrent computation, including the problems of interleaving and non-deterministic choice with regards to refinement in process calculi.\n\n"}
{"id": "158826", "url": "https://en.wikipedia.org/wiki?curid=158826", "title": "Transect", "text": "Transect\n\nA transect is a path along which one counts and records occurrences of the species of study (e.g. plants).\n\nIt requires an observer to move along a fixed path and to count occurrences along the path and, at the same time (in some procedures), obtain the distance of the object from the path. This results in an estimate of the area covered and an estimate of the way in which detectability increases from probability 0 (far from the path) towards 1 (near the path). Using the raw count and this probability function, one can arrive at an estimate of the actual density of objects.\n\nThe estimation of the abundance of populations (such as terrestrial mammal species) can be achieved using a number of different types of transect methods, such as strip transects, line transects, belt transects, point transects and curved line transects.\n\n"}
{"id": "1232743", "url": "https://en.wikipedia.org/wiki?curid=1232743", "title": "Universal science", "text": "Universal science\n\nUniversal science (; ) is a branch of metaphysics. In the work of Gottfried Wilhelm Leibniz, the universal science is the true logic. Plato's system of idealism, formulated using the teachings of Socrates, is a predecessor to the concept of universal science.\nIt emphasizes on the first principles which appear to be the reasoning behind everything, emerging and being in state with everything.\n\n\n"}
{"id": "873965", "url": "https://en.wikipedia.org/wiki?curid=873965", "title": "Vladimir Aksyonov", "text": "Vladimir Aksyonov\n\nVladimir Viktorovich Aksyonov (Влади́мир Ви́кторович Аксёнов) (born in Giblitsy, Kasimovsky District, Ryazan Oblast, Russian SFSR, on 1 February 1935) is a former Soviet cosmonaut, married with two children.\nHe graduated from institute of Engineering with diploma and graduated from Air Force Institute and graduated from polytechnical Institute. He was a candidate technical science.\n\nAksyonov was selected as cosmonaut on 3 March 1973. He was awarded the title of the Hero of the Soviet Union on two occasions. He retired on 17 October 1988.\n\nFlew as Flight Engineer on Soyuz 22 and Soyuz T-2.\n\nHe is currently director of the institute for research of Russian mineral resources.\n\n"}
