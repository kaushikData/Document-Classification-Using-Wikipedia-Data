{"id": "57813272", "url": "https://en.wikipedia.org/wiki?curid=57813272", "title": "2012 organic greens E coli outbreak O157:H7", "text": "2012 organic greens E coli outbreak O157:H7\n\nIn 2012, an unusual strain of E coli bacteria caused the reported illness of 33 people across several states in the US, carried on organically grown greens like spinach and spring mix. This strain produces shiga toxin, which is thought to have been transferred to the species from the shigella bacterium, by a bacteriophage, a kind of virus that (as the name implies) \"eats\" bacteria.\n\nOn October 18, 2012, cases of food poisoning began to be reported in the New York State area. The CDC eventually concluded this was an example of O157:H7, its code for a strain of E coli that is noteworthy for seeming to have genes from a different species, shigella, producing an unusual toxin, though not one especially lethal to human beings.\n\nOverall, 33 people in 5 states are known to have been infected. There were no deaths reported. This outbreak seems to have originated with food from State Garden, an organic produce company in Chelsea, MA.\n\nList of foodborne illness outbreaks in the United States\n"}
{"id": "42786025", "url": "https://en.wikipedia.org/wiki?curid=42786025", "title": "3739 virus", "text": "3739 virus\n\nThe 3739 virus is a strain of Pichinde virus in the genus Arenavirus.\n"}
{"id": "2645852", "url": "https://en.wikipedia.org/wiki?curid=2645852", "title": "Agricultural experiment station", "text": "Agricultural experiment station\n\nAn agricultural experiment station (AES) or agricultural research station (ARS) is a scientific research center that investigates difficulties and potential improvements to food production and agribusiness. Experiment station scientists work with farmers, ranchers, suppliers, processors, and others involved in food production and agriculture.\n\nStation scientists study biological, economic, and social problems of food and agriculture and related industries in each state. They investigate such areas as crop variations, soil testing, livestock, processing and animal technology, and other advanced technology in food and agriculture. They also work with specialists called extension agents. These specialists help inform famers about developments in agriculture. Most agricultural experiment station scientists are faculty members of the land-grant universities.\n\nIn Canada, about 50 per cent (1988) of the experiment stations are controlled by the Canadian government. The Central Experimental Farm in Ottawa is the headquarters of the federal system. Private industries, universities, and agricultural colleges control the remainder of the stations. Each province has a number of provincial stations. The University of Saskatchewan has extensive agricultural experimental land.\n\nThe Benaki Phytopathological Institute conducts experiments pertaining to plant health in many locations throughout the mainland, as well as in Crete and on other Greek islands.\n\nThe Agricultural University of Iceland maintains several experiment stations throughout the country.\n\nThe Regional Agricultural Research Station at Lam of Guntur.\n\nJapan has five agricultural experiment stations of Independent Administrative Institution of National Agriculture and Food Research Organization, former national stations, and many other prefectural stations all over the country.\n\nNew Zealand has agricultural research stations at Ruakura, Winchmore and Invermay.\n\nSutton Bridge Crop Storage Research in Sutton Bridge, Lincolnshire, is a leading UK agricultural experiment station owned by the Agriculture and Horticulture Development Board and operated by its Potato Council division, it engages in a wide range of research disciplines impacting upon crop storage for the British potato industry, including confidential contract research and development.\n\nSyngenta's largest R&D center is at Jealott's Hill in Berkshire. Before its current incarnation it belonged to Imperial Chemical Industries.\n\nThe Hatch Act of 1887 authorized the establishment of an agricultural experiment station, to be affiliated with the land grant college of agriculture, in each state (7 U.S.C. 361a et seq.). Research done at these stations underpins the curriculum of the colleges, as well as the programs of the Cooperative Extension System.\n\nThe United States of America has more than 50 stations (1988), run by about 13,000 scientists (1988). Each state has at least one main station, usually located at and associated with a land-grant university. Many states have branch stations to meet the special needs of different climate and geographical zones in those states.\n\nThe United States Department of Agriculture also directly maintains several experiment stations, including the Henry A. Wallace Beltsville Agricultural Research Center in Maryland and the U.S. Sheep Experiment Station near Dubois, Idaho. The Beltsville station contains the main building of the National Agricultural Library. The United States National Arboretum in Washington, DC is a division of the Beltsville Agricultural Research Center.\n\nThe U.S. experiment stations are state institutions. However, the federal and state governments cooperate in funding the research done at the stations. The states provide about 60 percent (1988) of the government money. Additional income comes from grants, contracts, and the sale of products. The stations receive a total income of more than $1 billion a year.\n\nThe University of the Virgin Islands maintains an experiment station on the island of St. Croix, working on agroforestry, aquaponics, biotechnology, forage agronomy, and tilapia farming, among other areas of research.\n\nIn 1786, Comte d'Angiviller, acting for Louis XVI of France, acquired 366 merino sheep from Spain and began an experimental program of adapting the species to France at the farm attached to Château de Rambouillet. As a result there is the branch of merinos called Rambouillet sheep.\n\nIn 1836 Jean-Baptiste Boussingault established the first agricultural experiment station at Pechelbronn in Alsace.\n\nA precursor to the agricultural experiment station was the botanical garden. For example, Christian Gottfried Daniel Nees von Esenbeck founded the Botanische Gärten der Friedrich-Wilhelms-Universität Bonn in 1818. With need for animal nutrition, scientists such as Karl Heinrich Ritthausen turned to biochemistry to investigate the comparative nutrition from grains and pulses.\n\nFollowing the footsteps of the Enlightenment rationalism and experimentalism, Germany began to see the rise of agricultural experiment stations, indicating the beginnings of an attempt to merge traditional agronomy with analytical chemistry. In 1840, Justus von Liebig, an influential German chemist and professor at the University of Giessen, published his book \"Organic Chemistry in its Application to Agriculture and Physiology\". Liebig theorized that nitrogen and trace minerals from soil erosion were essential to plant nutrition, and, from this analytical chemistry perspective, simplified agriculture to a series of chemical reactions. While Liebig’s work inspired a generation of analytical agricultural chemists interested in fundamental questions of plant nutrition, founders of early German agricultural experiment stations did not solely seek to pursue questions of soil chemistry, but rather sought to bridge the gap between the two fields of agriculture and chemistry.\n\nThe most well-known and earliest German experimental station, or \"Landwirtschaftliche\" \"Versuchsstationen\", established was the Mockern Experiment Station, located near the city of Leipzig. Created on September 28, 1850, the Mockern project was spearheaded by three Saxon men: Julius Adolf Stockhardt, a professor of agricultural chemistry; Wilhelm Crusius, German estate owner interested in scientific agriculture; and Theodor Reuning, the German agricultural minister at the time. Though all three men took interest in Liebig’s scientific approach to soil chemistry, they maintained distinct agricultural and economic focus at Mockern, and rejected a purely laboratory approach to agriculture. Unlike Liebig, Stockhardt sought the integration of chemistry with agriculturists, rather than a specialization of chemists to come in and do the work. As a landowner who employed chemists, Crusius saw the value of chemical agriculture in economic terms to increase profit, while Reuning’s support for Mockern Station represented the beginnings of governmental interest and funding of agricultural experimental stations.\n\nUnder Crusius, the Mockern Station submitted a Letter of Purpose in a government application. It specified that the Mockern Station belonging to the Leipzig Economic Society would devote itself to the advancement of agriculture via scientific investigation, through cooperation between practical farmers and scientific professionals. They listed six main research objectives, summarized below: \n\nHokkaido Development Commission founded the very first agricultural experiment station of the country in Sapporo in 1871, under the advice of O-yatoi gaikokujin(hired foreign experts).\n\nThe first national agricultural experiment station was founded in 1893 in Tokyo, Sendai, Kanazawa, Osaka, Hiroshima, Tokushima, and Kumamoto under the Edict No.18.\n\nAnd, 1899 act for prefectural agricultural experiment stations supported prefectural movement to establish agricultural experiment stations all over Japan.\n\nJohn Bennet Lawes, with the help of Joseph Henry Gilbert, established one of the oldest agricultural experiment stations in the world: Rothamsted Experimental Station, located at Harpenden in Hertfordshire, England, was founded in 1843. This establishment was where Ronald Fisher was inspired to important advances in the theory of statistical inference and genetics.\n\nThe movement to establish agricultural experiment stations in the USA can be credited to Samuel William Johnson who taught the first course in biochemistry. The development was recounted by William Cumming Rose:\nThe Bussey Institution at Harvard University (since 1871) and the Houghton Farm at Cornwall, New York (1876–88), were privately endowed stations. By 1887 fourteen states had definite organizations and in thirteen others the colleges conducted equivalent work.\n\nFederal aid for state experiment stations began with the Hatch Act of 1887. The Hatch Act authorized direct payment of federal grant funds to each state to establish an agricultural experiment station \"under direction of\" its land-grant college. Land-grant colleges had been established under the Morrill Act of 1862. The aid was increased by the Adams Act (1906) and the Purnell Act (1925). The provisions of the original Hatch Act and of later legislation providing increasing funds were combined in the Hatch Act of 1955. \n\nThe McIntire–Stennis Act of 1962 authorized forestry research studies at experiment stations.\n\n\n\n"}
{"id": "24147004", "url": "https://en.wikipedia.org/wiki?curid=24147004", "title": "Airone", "text": "Airone\n\nAirone () is an Italian science magazine devoted to science and technology issues. It is published in Milan, Italy, by Editoriale Giorgio Mondadori (former company, now a division of Cairo Editore, a subsidiary of Cairo Communication).\n\n\"Airone\" was founded in 1981 as an ecologist magazine primarily containing articles about animal world, nature, ethnology and geography. The founder and first director was Egidio Gavazzi. It was for years the most widely circulated scientific magazine in Italy, with a peak of average circulation of about 250,000 copies per month. Between 1985 and 1986 it co-produced with RAI the nature documentary series \"Pan\". In 1989 it was launched a spin-off for the younger readers, \"Airone Junior\", renamed \"Dodo\" in April 1995. \n\n\"Airone\" was described as a \"magazine similar to \"National Geographic\", but perhaps more conservation-minded\", and it was referred to as \"a stunning natural history magazine, the best of several European magazines\". In an article about the first ten years of the magazine, the \"L'Unità\" journalist Antonio Del Giudice pointed how the magazine was \"not just an editorial phenomenon, but also a cultural, political e social phenomenon\". \n\nThe circulation of \"Airone\" was 94,000 copies in 2007. In December 2013 the magazine had a circulation of 83,000 copies per month.\n\n\n"}
{"id": "51028770", "url": "https://en.wikipedia.org/wiki?curid=51028770", "title": "Amandus Heinrich Christian Zietz", "text": "Amandus Heinrich Christian Zietz\n\nAmandus Heinrich Christian Zietz (1839–1921) was a zoologist born in Hamburg, Schleswig-Holstein, and best known for his work at the South Australian Museum. His son Frederick Robert Zietz was also a zoologist.\n\nHis publications include:\n"}
{"id": "37982024", "url": "https://en.wikipedia.org/wiki?curid=37982024", "title": "Anupam Garg", "text": "Anupam Garg\n\nAnupam Garg is a professor in the department of Physics & Astronomy at Northwestern University, Illinois. He received his Ph.D. in 1983 from Cornell University.\nIn 2012 he became a Fellow of the American Physical Society (APS) thanks to his work on molecular magnetism and macroscopic quantum phenomena.\n\nGarg is best known for formulating the Leggett–Garg inequality, named for Anthony James Leggett and himself, which is a mathematical inequality fulfilled by all macrorealistic physical theories. He is also known for the Garg-Onuchic-Ambegaokar model of charge transfer.\nHis current research interests center around quantum and semi-classical phenomena associated with the orientation of quantum mechanical spin.\n\nGarg is the author of a graduate physics textbook, \"Classical Electromagnetism in a Nutshell\".\n"}
{"id": "23859493", "url": "https://en.wikipedia.org/wiki?curid=23859493", "title": "Articulo – Journal of Urban Research", "text": "Articulo – Journal of Urban Research\n\nArticulo – Journal of Urban Research is a peer-reviewed academic journal covering urban issues and publishes both theoretical and empirical articles. It is abstracted and indexed in several online directories, including Scopus, the French Evaluation Agency for Research and Higher Education (AERES), and Intute.\n\"Articulo\" is hosted by Revues.org, a platform for journals in the humanities and social sciences run by the Centre for Open Electronic Publishing and several academic institutions in France. \"Articulo\" publishes thematic issues, book reviews and conference proceedings. Papers are published in English or French.\n"}
{"id": "66414", "url": "https://en.wikipedia.org/wiki?curid=66414", "title": "Baconian method", "text": "Baconian method\n\nThe Baconian method is the investigative method developed by Sir Francis Bacon. The method was put forward in Bacon's book \"Novum Organum\" (1620), or 'New Method', and was supposed to replace the methods put forward in Aristotle's \"Organon\". This method was influential upon the development of the scientific method in modern science; but also more generally in the early modern rejection of medieval Aristotelianism.\n\nBacon's method is an example of the application of inductive reasoning. However, Bacon's method of induction is much more complex than the essential inductive process of making generalizations from observations. Bacon's method begins with description of the requirements for making the careful, systematic observations necessary to produce quality facts. He then proceeds to use induction, the ability to generalize from a set of facts to one or more axioms. However, he stresses the necessity of not generalizing beyond what the facts truly demonstrate. The next step may be to gather additional data, or the researcher may use existing data and the new axioms to establish additional axioms. Specific types of facts can be particularly useful, such as negative instances, exceptional instances and data from experiments. The whole process is repeated in a stepwise fashion to build an increasingly complex base of knowledge, but one which is always supported by observed facts, or more generally speaking, empirical data.\n\nHe argues in the \"Novum Organum\" that our only hope for building true knowledge is through this careful method. Old knowledge-building methods were often not based in facts, but on broad, ill-proven deductions and metaphysical conjecture. Even when theories were based in fact, they were often broad generalizations and/or abstractions from few instances of casually gathered observations. Using Bacon's process, man could start fresh, setting aside old superstitions, over-generalizations, and traditional (often unproven) \"facts\". Researchers could slowly but accurately build an essential base of knowledge from the ground up. Describing then-existing knowledge, Bacon claims:\n\nThere is the same degree of licentiousness and error in forming axioms as [there is] in abstracting notions, and [also] in the first principles, which depend in common induction [versus Bacon's induction]; still more is this the case in axioms and inferior propositions derived from syllogisms.\n\nWhile he advocated a very empirical, observational, reasoned method that did away with metaphysical conjecture, Bacon was a religious man, believed in God, and believed his work had a religious role. He contended, like other researchers at the time, that by doing this careful work man could begin to understand God's wonderful creation, to reclaim the knowledge that had been lost in Adam and Eve's \"fall\", and to make the most of his God-given talents.\n\nThere is a wider array of seminal works about the interaction of Puritanism and early science. Among others, Dorothy Stimson, Richard Foster Jones, and Robert Merton saw Puritanism as a major driver of the reforms initiated by Bacon and the development of science overall. Steven Matthews is cautious about the interaction with a single confession, as the English Reformation allowed a higher doctrinal diversity compared to the continent. However Matthews is quite outspoken, that \"Bacon's entire understanding of what we call “science,” and what he called “natural philosophy,” was fashioned around the basic tenets of his belief system.\" \n\nThe method consists of procedures for isolating and further investigating the \"form nature\", or cause, of a phenomenon, including the method of agreement, method of difference, and method of concomitant variation.\n\nBacon suggests that you draw up a list of all things in which the phenomenon you are trying to explain occurs, as well as a list of things in which it does not occur. Then you rank your lists according to the degree in which the phenomenon occurs in each one. Then you should be able to deduce what factors match the occurrence of the phenomenon in one list and don't occur in the other list, and also what factors change in accordance with the way the data had been ranked.\n\nThus, if an army is successful when commanded by Essex, and not successful when not commanded by Essex: and when it is more or less successful according to the degree of involvement of Essex as its commander, then it is scientifically reasonable to say that being commanded by Essex is causally related to the army's success.\n\nFrom this Bacon suggests that the underlying cause of the phenomenon, what he calls the \"form,\" can be approximated by interpreting the results of one's observations. This approximation Bacon calls the \"First Vintage.\" It is not a final conclusion about the formal cause of the phenomenon but merely a hypothesis. It is only the first stage in the attempt to find the form and it must be scrutinized and compared to other hypotheses. In this manner, the truth of natural philosophy is approached \"by gradual degrees,\" as stated in his \"Novum Organum\".\n\nThe \"Baconian method\" does not end at the First Vintage. Bacon described numerous classes of \"Instances with Special Powers,\" cases in which the phenomenon one is attempting to explain is particularly relevant. These instances, of which Bacon describes 27 in the \"Novum Organum\", aid and accelerate the process of induction.\n\nAside from the First Vintage and the Instances with Special Powers, Bacon enumerates additional \"aids to the intellect\" which presumably are the next steps in his method. These additional aids, however, were never explained beyond their initial limited appearance in \"Novum Organum\".\n\nThe \"Natural History\" of Pliny the Elder was a classical Roman encyclopedia work. Induction, for Bacon's followers, meant a type of rigour applied to factual matters. Reasoning should not be applied in plain fashion to just any collection of examples, an approach identified as \"Plinian\". In considering natural facts, a fuller survey was required to form a basis for going further. Bacon made it clear he was looking for more than \"a botany\" with discursive accretions.\n\nIn concrete terms, the cabinet of curiosities, exemplifying the Plinian approach, was to be upgraded from a source of wonderment to a challenge to science. The main source in Bacon's works for the approach was his \"Sylva Sylvarum\", and it suggested a more systematic collection of data in the search for causal explanations.\n\nUnderlying the method, as applied in this context, are therefore the \"tables of natural history\" and the ways in which they are to be constructed. Bacon's background in the common law has been proposed as a source for this concept of investigation.\n\nAs a general intellectual programme, Bacon's ideas on \"natural history\" have been seen as a broad influence on British writers later in the 17th century, in particular in economic thought and within the Royal Society.\n\nBacon also listed what he called the idols (false images) of the mind. He described these as things which obstructed the path of correct scientific reasoning.\n\nThe physician Thomas Browne (1605–82) was one of the first scientists to adhere to the empiricism of the Baconian method. His encyclopaedia \"Pseudodoxia Epidemica\" (1st edition 1646 – 5th edition 1672) includes numerous examples of Baconian investigative methodology, while its preface echoes lines from Bacon's \"On Truth\" from \"The Advancement of Learning\" (1605). Isaac Newton's saying \"hypotheses non fingo\" (I don't frame hypotheses) occurs in later editions of the \"Principia\". It represents his preference for rules that could be demonstrated, as opposed to unevidenced hypotheses.\n\nThe Baconian method was further developed and promoted by John Stuart Mill. His 1843 book, \"A System of Logic\", was an effort to shed further light on issues of causation. In this work, he formulated the five principles of inductive reasoning now known as Mill's methods.\n\nMax Horkheimer and Theodor Adorno observe that Bacon shuns \"knowledge that tendeth but to satisfaction\" in favor of effective procedures. While the Baconian method disparages idols of the mind, its requirement for effective procedures compels it to adopt a credulous, submissive stance toward worldly power. \n\nHorkheimer and Adorno offer a plea to recover the virtues of the \"metaphysical apologia,\" which is able to reveal the injustice of effective procedures rather than merely employing them.\n\n"}
{"id": "188976", "url": "https://en.wikipedia.org/wiki?curid=188976", "title": "Compilers: Principles, Techniques, and Tools", "text": "Compilers: Principles, Techniques, and Tools\n\nCompilers: Principles, Techniques, and Tools is a computer science textbook by Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman about compiler construction. First published in 1986, it is widely regarded as the classic definitive compiler technology text.\n\nIt is affectionately known as the Dragon Book to generations of computer scientists as its cover depicts a knight and a dragon in battle, a metaphor for conquering complexity. This name can also refer to Aho and Ullman's older \"Principles of Compiler Design\".\n\nThe first edition (1986) is informally called the \"red dragon book\" to distinguish it from the second edition and from Aho & Ullman’s 1977 \"Principles of Compiler Design\" sometimes known as the \"green dragon book\" \nTopics covered in the first edition include:\n\nFollowing in the tradition of its two predecessors, the second edition (2006) features a dragon and a knight on its cover, and is informally known as the purple dragon. Monica S. Lam of Stanford University became a co-author with this edition.\n\nThe second edition includes several additional topics, including:\n\n\n"}
{"id": "474931", "url": "https://en.wikipedia.org/wiki?curid=474931", "title": "Diving physics", "text": "Diving physics\n\nDiving physics are the aspects of physics which directly affect the underwater diver and which explain the effects that divers and their equipment are subject to underwater which differ from the normal human experience out of water.\n\nThese effects are mostly consequences of immersion in water, the hydrostatic pressure of depth and the effects of the pressure on breathing gases. An understanding of the physics is useful when considering the physiological effects of diving and the hazards and risks of diving.\n\nThe main laws of physics that describe the influence of the underwater diving environment on the diver and diving equipment are:\n\nThe physical effects of water or the underwater environment are:\n\nThe physical phenomena found in large bodies of water that may have a practical influence on divers include:\n\n"}
{"id": "33094679", "url": "https://en.wikipedia.org/wiki?curid=33094679", "title": "Edwin Brown (naturalist)", "text": "Edwin Brown (naturalist)\n\nEdwin Brown (died 1 September 1876, Tenby) was an English naturalist and entomologist.\n\nEdwin Brown was manager of the Burton, Uttoxeter and Ashbourne Union Bank in Burton on Trent. He had a private museum of geological, zoological and botanical specimens and a library of taxonomic works.\n\nBrown was a Member of the Entomological Society of London from 1849. He specialised in Carabidae and Cicindelidae.\n\nParts of his collection were purchased by Oxford University Museum of Natural History when it was sold at auction in March 1877. The purchase included insects collected by Alfred Russel Wallace.\n\nEdwin Brown was Henry Walter Bates's first naturalist friend.\n\nPartial list\n"}
{"id": "42046259", "url": "https://en.wikipedia.org/wiki?curid=42046259", "title": "Enterovirus D", "text": "Enterovirus D\n\nEnterovirus D is a species of enterovirus which causes disease in humans. Five subtypes have been identified to date:\n\n"}
{"id": "11371983", "url": "https://en.wikipedia.org/wiki?curid=11371983", "title": "Everglades virus", "text": "Everglades virus\n\nEverglades virus (EVEV) is an alphavirus included in the Venezuelan equine encephalitis virus complex. The virus circulates among rodents and vector mosquitoes and sometimes infects humans, causing a febrile illness with occasional neurological manifestations. The virus is named after the Everglades, a region of subtropical wetlands in southern Florida. The virus is endemic to the U.S. state of Florida, where its geographic range mirrors that of the mosquito species \"Culex cedecei\". Most clinical cases of infection occur in and around the city of Miami.\n\nSymptoms of infection include:\n\nThe virus is transmitted by the bite of infected mosquitoes of the genus \"Culex\", specifically \"Culex cedecei\".\n"}
{"id": "3989813", "url": "https://en.wikipedia.org/wiki?curid=3989813", "title": "Flags depicting the Southern Cross", "text": "Flags depicting the Southern Cross\n\nThe Southern Cross or Crux, a constellation visible in the Southern Hemisphere, is depicted on flags and coats of arms of various countries and sub-national entities. This star constellation is visible mostly in the southern hemisphere and it therefore symbolises the southern location of its users.\n\nThe term \"Southern Cross\" can also refer to the blue saltire as used in various flags of the Confederate States of America in the American Civil War.\n\nThis list is an incomplete list and some of the flags in this list might not have official status. Also, note that flag proportions may vary between the different flags, and sometimes even vary between different versions of the same flag.\n\n"}
{"id": "12142270", "url": "https://en.wikipedia.org/wiki?curid=12142270", "title": "GENESIS (software)", "text": "GENESIS (software)\n\nGENESIS (The \"GEneral NEural SImulation System\") is a simulation environment for constructing realistic models of neurobiological systems at many levels of scale including: sub-cellular processes, individual neurons, networks of neurons, and neuronal systems. These simulations are “computer-based implementations of models whose primary objective is to capture what is known of the anatomical structure and physiological characteristics of the neural system of interest”. GENESIS is intended to quantify the physical framework of the nervous system in a way that allows for easy understanding of the physical structure of the nerves in question. “At present only GENESIS allows parallelized modeling of single neurons and networks on multiple-instruction-multiple-data parallel computers.” Development of GENESIS software spread from its home at Caltech to labs at the University of Texas at San Antonio, the University of Antwerp, the National Centre for Biological Sciences in Bangalore, the University of Colorado, the Pittsburgh Supercomputing Center, the San Diego Supercomputer Center, and Emory University.\n\nGENESIS works by creating simulation environments for constructing models of neurons or neural systems. \"Nerve cells are capable of communicating with each other in such a highly structured manner as to form neuronal networks. To understand neural networks, it is necessary to understand the ways in which one neuron communicates with another through synaptic connections and the process called synaptic transmission\". Neurons have a specialized structure for their function, they \"are different from most other cells in the body in that they are polarized and have distinct morphological regions, each with specific functions\". The two important regions of a neuron are the dendrite and the axon. \"Dendrites are the region where one neuron receives connections from other neurons. The cell body or soma contains the nucleus and the other organelles necessary for cellular function. The axon is a key component of nerve cells over which information is transmitted from one part of the neuron (e.g., the cell body) to the terminal regions of the neuron\". The third important piece of a neuron is the synapse. \"The synapse is the terminal region of the axon this is where one neuron forms a connection with another and conveys information through the process of synaptic transmission\".\n\nNeural networks like the ones simulated with GENESIS software can quickly become highly complex and difficult to understand. \"Just a few interconnected neurons (a microcircuit) can perform sophisticated tasks such as mediate reflexes, process sensory information, generate locomotion and mediate learning and memory. Even more complex networks, macrocircuits, consist of multiple embedded microcircuits. Macrocircuits mediate higher brain functions such as object recognition and cognition\". GENESIS endeavors to simulate neural systems as they are found in nature. Often, \"a neuron can receive contacts from up to 10,000 presynaptic neurons, and, in turn, any one neuron can contact up to 10,000 postsynaptic neurons. The combinatorial possibility could give rise to enormously complex neuronal circuits or network topologies, which might be very difficult to understand\".\n\nGENESIS was developed by Dr. James M. Bower, in the Caltech laboratory, and first released to the public in 1988 in association with the first Methods in Computational Neuroscience Course at the Marine Biological Laboratory in Woods Hole, MA. Full source code for the software was released in the same year under an open software model for development. It's now supported by the Computational Biology Initiative at the University of Texas at San Antonio and is available free along with tutorial guides on its use.\nP-GENESIS, a parallel version of GENESIS, was first run in 1990 on the Intel Delta, which was the prototype for the Intel Paragon family of massively parallel supercomputers.\n\nGENESIS is useful in creating a simulation environment for constructing models of neurobiological systems such as:\n\nThe GENESIS system is complicated, but relatively easy to use.\nAn individual can input commands through one of three ways: script files, graphical user interface, or the GENESIS command shell. These commands are then processed by the script language interpreter. \"The Script Language Interpreter processes commands entered through the keyboard, script files, or the graphical user interface, and passes them to the GENESIS simulation engine. The simulation engine also loads compiled object libraries, reads and writes data files, and interacts with the graphical user interface\". Below is a graphical representation of the user input process and a sample GENESIS output.\n\nMost current applications for GENESIS involve realistic simulations of biological systems. It is usually used to simulate the behavior of larger brain structures, for example the cerebral cortex. These studies most often occur in lab courses in neural simulation at Caltech and the Marine Biological Laboratory at Woods Hole, Massachusetts.\n\nGENESIS can be used in combination with Yale University’s software called NEURON as a means for scientists to collaborate to construct a physical description of the nervous system. The GENESIS software can also be used with Kinetikit in the modeling of signal transduction pathways.\n\nGENESIS has been used in many studies. Some of these studies involve research that focuses on the development of software that would be useful across many disciplines. Others are studies of neurons, such as Purkinje cells. These studies used GENESIS to simulate Purkinje cells and could be useful for the planning and development of later experiments using the GENESIS software.\n\nThere may also be biomedical applications of the software. For example, St. Jude Medical in Europe has developed an implanted GENESIS device.\n\n\n\n"}
{"id": "3808493", "url": "https://en.wikipedia.org/wiki?curid=3808493", "title": "GFP-cDNA", "text": "GFP-cDNA\n\nThe GFP-cDNA project documents the localisation of proteins to subcellular compartments of the eukaryotic cell applying fluorescence microscopy. Experimental data are complemented with bioinformatic analyses and published online in a database. A search function allows the finding of proteins containing features or motifs of particular interest. The project is a collaboration of the research groups of Rainer Pepperkok at the European Molecular Biology Laboratory (EMBL) and Stefan Wiemann at the German Cancer Research Centre (DKFZ).\n\nThe cDNAs of novel identified Open Reading Frames(ORF) are tagged with Green Fluorescent Protein (GFP) and expressed in eukaryotic cells. Subsequently, the subcellular localisation of the fusion proteins is recorded by fluorescence microscopy.\n\nSteps:\n\nAny large-scale manipulation of ORFs requires cloning technologies which are free of restriction enzymes. In this respect those that utilise recombination cloning (Gateway of Invitrogen or Creator of BD Biosciences) have proved to be the most suitable. This cloning technology is based on recombination mechanisms used by phages to integrate their DNA into the host genome. It allows the ORFs to be rapidly and conveniently shuttled between functionally useful vectors without the need for conventional restriction cloning. In the cDNA-GFP project the ORFs are transferred into CFP/YFP expression vectors. For the localisation analysis both N- and C-terminal fusions are generated. This maximises the possibility of correctly ascertaining the localisation, since the presence of GFP may mask targeting signals that may be present at one end of the native protein.\n\nInsert your gene of interest into the MCS upstream of the fluorescent protein gene, and express your gene as a fusion to the N-terminus of the fluorescent protein.\n\nInsert your gene of interest into the MCS downstream of the fluorescent protein gene, and express your gene as a fusion to the C-terminus of the fluorescent protein.\n\nThe fusion vectors are transfected in Vero cells (monkey kidney fibroblasts). Particularly interesting ORFs are also screened for localisation in PC12 cells and hippocampal neurons.\n\nAt different time points, the subcellular localisation of the fusion proteins is recorded via fluorescence microscopy. At the end of the live cell imaging, the cells can still be fixed and colocalisation experiments made.\nAs the sequence of the cDNAs is known, bioinformatics can make predictions regarding the localisation and function of the encoded protein. The bioinformatics analysis is facilitated by the bioinformatic search engine Harvester.\n\nResults from the N- and C-terminal fusions are assessed and in turn these data are compared to the bioinformatic predictions. A final subcellular localisation (from approximately 20 categories) is then assigned for each ORF. Similar localisations with both N- and C-terminal constructs provide a higher degree of reliability of the result. For those ORFs where the two fusions do not give a similar localisation pattern, a series of other criteria, including bioinformatic predictions, are considered. Occasionally a clear cut localization cannot be assigned.\nEvery data sheet contains the fluorescence images of both N- and C-terminal fusions, the assigned localization, other localizations, comments and the Swissprot ID. For every protein entry, a link is provided to the corresponding Harvester bioinformatics page.\n\nImages of all localised proteins and their bioinformatic analysis can be viewed via the ‘Results Table’ or ‘Results Images’ buttons. In addition, use the search window on the entry site to find proteins containing features or motifs of particular interest to you that have been localised in this project.\n\n\n"}
{"id": "21323317", "url": "https://en.wikipedia.org/wiki?curid=21323317", "title": "Genome Reference Consortium", "text": "Genome Reference Consortium\n\nThe Genome Reference Consortium (GRC) is an international collective of academic and research institutes with expertise in genome mapping, sequencing, and informatics, formed to improve the representation of reference genomes. At the time the human reference was initially described, it was clear that some regions were recalcitrant to closure with existing technology. The main reason for improving the reference assemblies are that they are the cornerstones upon which all whole genome studies are based (e.g. the 1000 Genomes Project).\n\nThe GRC is a collaborative effort which interacts with various groups in the scientific community, however the primary member institutes are:\n\nInitially the focus lies with the Human and the Mouse reference genomes, but in mid-late 2010 full maintenance and improvement of the Zebrafish genome sequence was also added to the GRC. The goal of the Consortium is to correct the small number of regions in the reference that are currently misrepresented, to close as many remaining gaps as possible and to produce alternative assemblies of structurally variant loci when necessary.\n\nAs of June 2015, the major assembly release for human, mouse and zebrafish are GRCh38, GRCm38 and GRCz10 respectively. Major assembly releases do not follow a fixed cycle, however there are \"minor\" assembly updates in the form of genome patches which either correct errors in the assembly or add additional alternate loci. These assemblies are represented in various genome browsers and databases including Ensembl, those in NCBI and UCSC Genome Browser.\n\n\n\nInstitute Homepages\n"}
{"id": "1328337", "url": "https://en.wikipedia.org/wiki?curid=1328337", "title": "Golden-rumped elephant shrew", "text": "Golden-rumped elephant shrew\n\nThe golden-rumped elephant shrew (\"Rhynchocyon chrysopygus\") is a small African mammal. It is the largest species of the elephant shrew family. It is classified as endangered.\n\nThe golden-rumped elephant shrew is found in the northern coastal areas in and around Arabuko Sokoke National Park Mombasa in Kenya. Its name derives from the conspicuous golden fur on its hindquarters, distinctive golden coloration on its rump, and grizzled gold forehead contrasting with its dark reddish-brown color. The golden-rumped elephant shrew has long muscular rear legs and shorter, less developed forelegs. Like other elephant shrews, this species has a long and flexible snout, which is where its genus gets its name. Its tail is largely black except for the last third, which is white with a black tip. On juveniles, the fur shows vestigial traces of a checkerboard pattern seen on giant elephant shrews like the checkered elephant shrew.\n\nThe golden-rumped elephant shrews are monogamous and territorial behavior is seen in both males and females defending overlapping territories. They mate year round. Females give birth to one young in an approximate 42-days cycle. The newborn offspring are usually ready to leave the mother's den after 2 weeks, and it takes approximately 5 days after leaving the nest for them to become fully independent in the wild. The male does not take part in any parental care of the newborns.\n\nThe golden-rumped elephant shrew is a diurnal animal, which lives in densely vegetated forests, avoiding clear and open areas to help protect themselves from predators. Golden-rumped elephant shrews build up to 6 nests at a time, alternating nests every night to leave no pattern for hunting predators to follow. It inhabits coastal regions and is found in moist, dense-brush forests and lowland semi-deciduous forests. Males have slightly larger home areas than females, and are more likely to trespass into neighboring territories, which makes them more vulnerable to predators.\n\nTheir diet consist of invertebrates such as earthworms, millipedes, insects and spiders. These animals root through the leaf litter for 80% of their day looking for grasshoppers, beetles, spiders and other small invertebrates. The golden-rumped elephant shrew evolved various strategies to avoid predators, particularly snakes (such as black mambas and cobras) and the southern banded snake-eagle. This animal is fast, capable of running up to 25 km/h. When it detects a predator within its escape distance, it will adopt a defensive position and will try to escape taking advantage of its agility and speed. If, however, the predator is outside its escape distance, the elephant shrew will advertise its presence by slapping the leaf litter, letting the predator know it has been spotted. In the event of a chase or an ambush, the golden-rumped's flash of fur will often deflect the predator's attention away from the head and onto the rump, which has thicker skin and could give them an opportunity to survive and attack. The protected rump is more pronounced in males than female, and this dermal shield is roughly three times thicker than the skin in the middle of its back. Each shrew maintains several nests so they cannot be easily found by leaving a trace or establishing a pattern.\n\nThe golden-rumped elephant shrew is classified as endangered largely due to a fragmented forest environment and anthropogenic factors. Their most notable population is in the Arabuko-Sokoke Forest in Kenya. They are subject to being caught in traps, but are not targeted for a source of food because of its poor taste. In the early 1990s, it was estimated that roughly 3,000 were caught yearly by trappers. Forest patrols have reduced trapping since then, but there are areas that are not patrolled, where trappers are able to trap freely. The Arabuko-Sokoke forest and other Kenyan forests where the shrews live, have the status of National Monuments, which prevents any further development, but does not particularly provide specific protection for them or for biodiversity. Due to their small populations, even though many are protected, their numbers are expected to continue to decline due to stochastic events and further anthropogenic disturbances.\n\n\n"}
{"id": "15432121", "url": "https://en.wikipedia.org/wiki?curid=15432121", "title": "Heinrich Christian Burckhardt", "text": "Heinrich Christian Burckhardt\n\nHeinrich Christian Burckhardt (26 February 1811, Adelebsen – 14 December 1879, Hannover) was a German forester and entomologist.\n\nIn 1853 Burckhardt became the first civil director of forest administration in the Kingdom of Hanover (after 1866 a province of Prussia. He wrote \"Säen und Pflanzen nach forstlicher Praxis: ein Beitrag zur Holzerziehung\" (Sowing and planting in forestry practice: a contribution to forest education) published in Hannover by Rümpler in 1855. This work contains sections on pest insects.\n\n"}
{"id": "25390580", "url": "https://en.wikipedia.org/wiki?curid=25390580", "title": "Hotspot Ecosystems Research on the Margins of European Seas", "text": "Hotspot Ecosystems Research on the Margins of European Seas\n\nHotspot Ecosystems Research on the Margins of European Seas, or HERMES, was an international multidisciplinary project, from April 2005 to March 2009, that studied deep-sea ecosystems along Europe's deep-ocean margin.\n\nThe HERMES project was funded by the European Commission's Sixth Framework Programme, and was the predecessor to the HERMIONE project, which started in April 2009.\n"}
{"id": "30721431", "url": "https://en.wikipedia.org/wiki?curid=30721431", "title": "Hubble bubble (astronomy)", "text": "Hubble bubble (astronomy)\n\nIn astronomy, a Hubble bubble would be \"a departure of the local value of the Hubble constant from its globally averaged value,\" or, more technically, \"a local monopole in the peculiar velocity field, perhaps caused by a local void in the mass density.\"\n\nThe Hubble constant, named for astronomer Edwin Hubble, whose work made clear the expansion of the universe, measures the rate at which expansion occurs. In accordance with the Copernican principle that the Earth is not in a central, specially favored position, one would expect that measuring this constant at any point in the universe would yield the same value. If, on the other hand, Earth were at or near the center of a very low-density region of interstellar space (a relative void), denser material in a shell around it would strongly attract material away from the centerpoint. Thus, stars inside such a \"Hubble bubble\" would accelerate away from Earth much faster than the general expansion of the universe. This situation would provide an alternative to dark energy in explaining the apparent accelerating universe.\n\nIn 1998, Zehavi et al. reported evidence in support of a Hubble bubble. The initial suggestion that local redshift velocities differ from those seen elsewhere in the universe was based on observations of Type 1a supernovae, often abbreviated \"SNe Ia.\" Such stars have been used as standard candle distance markers for 20 years, and were key to the first observations of dark energy.\n\nZehavi \"et al.\" studied the peculiar velocites of 44 SNe Ia to test for a local void, and reported that Earth seemed to be inside a relative void of roughly 20% underdensity, surrounded by a dense shell, a \"bubble\".\n\nIn 2007, Conley et al. examined the SNe Ia color data comparisons while taking into account the effect of cosmic dust in external galaxies. They concluded that the data did not support the existence of a local Hubble bubble.\n\nIn 2010, Moss et al. analyzed the Hubble Bubble model although without using that name, saying \"The suggestion that we occupy a privileged position near the center of a large, nonlinear, and nearly spherical void has recently attracted much attention as an alternative to dark energy.\" Looking not only at supernova data but also at the cosmic microwave background spectrum, Big Bang nucleosynthesis and other factors, they concluded that \"voids are in severe tension with the data. In particular, void models predict a very low local Hubble rate, suffer from an \"old age problem\", and predict much less local structure than is observed.\"\n\n"}
{"id": "13990345", "url": "https://en.wikipedia.org/wiki?curid=13990345", "title": "Impact gardening", "text": "Impact gardening\n\nImpact gardening is the process by which impact events stir the outermost crusts of moons and other celestial objects with no atmospheres. In the particular case of the Moon, this is more often known as lunar gardening. Planetary bodies lacking an atmosphere will generally also lack any erosional processes, with the possible exception of volcanism, and as a result impact debris accumulates at the object's surface as a rough \"soil,\" commonly referred to as regolith. Subsequent impacts, especially by micrometeorites, stir and mix this soil. It had long been estimated that the top centimeter of the lunar surface is overturned every 10 million years. However more recent analysis by the LRO satellite, of impact ejecta coverage, puts the figure closer to 80,000 years.\n\n"}
{"id": "53083326", "url": "https://en.wikipedia.org/wiki?curid=53083326", "title": "Institute of Political Studies in Belgrade", "text": "Institute of Political Studies in Belgrade\n\nInstitute of Political Studies in Belgrade is an academic institution in Belgrade, Serbia. It is for research of political science.\n\nThe institute was started in 1968. It developed out of the research unit of the High School of Political Science. It developed into an independent scientific institution. After separating from the Faculty of Political Science in Belgrade, the Institute for Political Studies was given the status of independent scientific institution.\n\nThe current periodical editions of the Institute are: \n"}
{"id": "12220917", "url": "https://en.wikipedia.org/wiki?curid=12220917", "title": "Irlen filters", "text": "Irlen filters\n\nIrlen Spectral Filters or Irlen Lenses, are coloured overlay filters or tinted lenses crafted specifically for the wearer and worn as glasses or contact lenses. They are intended to help people with the supposed perceptual processing difficulty known as Irlen Syndrome, also known as Scotopic Sensitivity Syndrome or visual stress. For individuals who suffer from Irlen Syndrome, the brain is sensitive to specific wavelengths of light, resulting in difficulties with print clarity and stability and discomfort when performing visually intensive activities such as reading. Irlen Syndrome affects approximately 50 percent of individuals with reading difficulties and dyslexia, 33 percent of those with attention difficulties such as attention-deficit hyperactivity disorder, 33 percent with autism, up to 50 percent of those who have suffered a traumatic brain injury, whiplash or concussion, and approximately 12-14 percent of the general population. Standardised diagnostic procedures have been developed to individualise the colour selection. Experts call the syndrome and the treatment controversial, because it is based on insufficient research. However, current research on the topic includes placebo controls, longitudinal studies, and cutting-edge brain mapping technology, all of which support the use of colour to alleviate the symptoms associated with Irlen Syndrome.\n\nScotopic sensitivity syndrome, also known as Irlen Syndrome, is said to be a visual-perceptual defect related to difficulties with light source, glare, luminance, wavelength and black/white contrast. According to Irlen, these difficulties lead to reading problems, eye-strain, headaches, migraines, and other physical difficulties that can be alleviated by the use of person specific tinted lenses, known as Irlen Spectral Filters, worn as glasses or contact lenses.\n\nThe syndrome has six characteristics:\n\n\nScotopic sensitivity syndrome is diagnosed by interviewing the client and by observing responses to certain visual tasks such as interpreting geometric figures and reading.\n\nThe idea of page based distortion was initially suggested in 1980 by Olive Meares, to improve the reading ability of people with a learning disability, specifically a certain type of dyslexia. Later this was taken further by psychologist Helen Irlen. The proposition by Irlen was made at the Annual Meeting of the American Psychological Association in 1983. At that time, there was little research made on the effect of tinted lenses. Irlen gained notable publicity demonstrating the efficacy of her method on television. Tinted lenses became a commercial success, and testing and prescribing centers were opened throughout USA.\n\nDiagnosis of Irlen Syndrome and treatment with Irlen Spectral Filters has been reviewed by the USA Medical Board, and has been determined as not the practice of medicine; it has also been reviewed by various USA Boards of Optometry and has been found not to be the practice of optometry. Binocular and accommodative anomalies may occur in conjunction with the syndrome, but are not considered to be the underlying physiological basis of the condition.\n\nAccording to Irlen, the lenses can be used to treat a wide variety of problems that are associated with light sensitivity, discomfort and distortions, including head injury, concussion, whiplash, perceptual problems, neurologic impairment, memory loss, language deficits, headaches and migraine, autoimmune disease, fibromyalgia, macular degeneration, cataracts, retinitis pigmentosa, complications from an eye operation, depression, chronic anxiety and others. She has also claimed that a treatment for scotopic sensitivity syndrome could help a number of incarcerated individuals and delinquent children.\n\nThe Irlen method has been criticised for being put to the market prior to serious research. According to Helveston, the scotopic sensitivity syndrome and its treatment has, as a phenomenon, resulted in classic group behaviour and has the characteristics of a fad with a charismatic personality as a leader and the supporting evidence being mostly anecdotal. A 2004 study by Professor Arnold Wilkins at Essex University, though, shows that this may not be the case. It is suspicious that the treatment quickly came to be applied to a wide variety of maladies, suggesting that this treatment is an example of classic group behavior. The syndrome is, however, associated with a growing array of possibly diverse conditions, as well as worldwide franchise according to critics.\n\n\n"}
{"id": "57389616", "url": "https://en.wikipedia.org/wiki?curid=57389616", "title": "Irène Joliot-Curie Prize", "text": "Irène Joliot-Curie Prize\n\nThe Irène Joliot-Curie Prize is a French prize for women in science and technology, founded in 2001 by the Ministry of Higher Education, Research and Innovation. It is named after French scientist Irène Joliot-Curie. It should be distinguished from a different prize with the same name, offered since 1956 by the Société Française de Physique.\n\nEach year three awards are given: one for the female scientist of the year, a second to a young female scientist, and a third to a woman in business and technology. In addition, in early years of the award a fourth category of awards was given, to an individual or group in recognition of their mentorship of women in science.\nSince 2011, the award winners have been chosen by the French Academy of Sciences and the French Academy of Technologies.\n\nThe winners have included:\n"}
{"id": "86820", "url": "https://en.wikipedia.org/wiki?curid=86820", "title": "Khālid ibn ʿAbd al‐Malik al‐Marwarrūdhī", "text": "Khālid ibn ʿAbd al‐Malik al‐Marwarrūdhī\n\nKhālid ibn ʿAbd al‐Malik al‐Marwarrūdhī () was a Zanji slave who was taken to Persia in the 9th century.\n\nTogether with ʿAlī ibn ʿĪsā al-Asṭurlābī in 827, he measured at 35 degrees north latitude, in the valley of the Tigris, the length of a meridian arc and thus the Earth's circumference, getting a result of 40,248 km (or, according to other sources, 41,436 km). The two researchers measured in Arabian ell, and determined the geographical latitudes of the end points they used from the star altitudes in a celestial horizontal coordinate system. We believe that 1 Arabian ell was 49 1/3 cm. Thus, they found the length of 1° of meridian to be 111.8 km (115.1 km), which differs from the actual value by 850 metres.\n\n"}
{"id": "1651967", "url": "https://en.wikipedia.org/wiki?curid=1651967", "title": "Kosterlitz–Thouless transition", "text": "Kosterlitz–Thouless transition\n\nThe Berezinskii–Kosterlitz–Thouless transition (BKT transition) is a phase transition in the two-dimensional (2-D) XY model. It is a transition from bound vortex-antivortex pairs at low temperatures to unpaired vortices and anti-vortices at some critical temperature. The transition is named for condensed matter physicists Vadim Berezinskii, John M. Kosterlitz and David J. Thouless. BKT transitions can be found in several 2-D systems in condensed matter physics that are approximated by the XY model, including Josephson junction arrays and thin disordered superconducting granular films. More recently, the term has been applied by the 2-D superconductor insulator transition community to the pinning of Cooper pairs in the insulating regime, due to similarities with the original vortex BKT transition.\n\nWork on the transition led to the 2016 Nobel Prize in Physics being awarded to Thouless, Kosterlitz and Duncan Haldane.\n\nThe XY model is a two-dimensional vector spin model that possesses U(1) or circular symmetry. This system is not expected to possess a normal second-order phase transition. This is because the expected ordered phase of the system is destroyed by transverse fluctuations, i.e. the Nambu-Goldstone modes (see Goldstone boson) associated with this broken continuous symmetry, which logarithmically diverge with system size.\nThis is a specific case of what is called the Mermin–Wagner theorem in spin systems.\n\nRigorously the transition is not completely understood, but the existence of two phases was proved by and .\n\nIn the XY model in two dimensions, a second-order phase transition is not seen. However, one finds a low-temperature quasi-ordered phase with a correlation function (see statistical mechanics) that decreases with the distance like a power, which depends on the temperature. The transition from the high-temperature disordered phase with the exponential correlation to this low-temperature quasi-ordered phase is a Kosterlitz–Thouless transition.\nIt is a phase transition of infinite order.\n\nIn the 2-D XY model, vortices are topologically stable configurations. It is found that the high-temperature disordered phase with exponential correlation decay is a result of the formation of vortices. Vortex generation becomes thermodynamically favorable at the critical temperature formula_1 of the KT transition. At temperatures below this, vortex generation has a power law correlation.\n\nMany systems with KT transitions involve the dissociation of bound anti-parallel vortex pairs, called vortex–antivortex pairs, into unbound vortices rather than vortex generation. In these systems, thermal generation of vortices produces an even number of vortices of opposite sign. Bound vortex–antivortex pairs have lower energies than free vortices, but have lower entropy as well. In order to minimize free energy, formula_2, the system undergoes a transition at a critical temperature, formula_1. Below formula_1, there are only bound vortex–antivortex pairs. Above formula_1, there are free vortices.\n\nThere is an elegant thermodynamic argument for the KT transition. The energy of a single vortex is formula_6, where formula_7 is a parameter that depends upon the system in which the vortex is located, formula_8 is the system size, and formula_9 is the radius of the vortex core. One assumes formula_10. In the 2D system, the number of possible positions of a vortex is approximately formula_11. From Boltzmann's entropy formula, formula_12 (with W is the number of states), the entropy is formula_13, where formula_14 is Boltzmann's constant. Thus, the Helmholtz free energy is\n\nWhen formula_16, the system will not have a vortex. On the other hand, when formula_17, entropic considerations favor the formation of a vortex. The critical temperature above which vortices may form can be found by setting formula_18 and is given by\n\nThe KT transition can be observed experimentally in systems like 2D Josephson junction arrays by taking current and voltage (I-V) measurements. Above formula_20, the relation will be linear formula_21. Just below formula_20, the relation will be formula_23, as the number of free vortices will go as formula_24. This jump from linear dependence is indicative of a KT transition and may be used to determine formula_20. This approach was used in Resnick et al. to confirm the KT transition in proximity-coupled Josephson junction arrays.\n\nThe following discussion uses field theoretic methods. Assume a field φ(x) defined in the plane which takes on values in formula_26. For convenience, we work with the universal cover R of formula_26 instead, but identify any two values of φ(x) that differ by an integer multiple of 2π.\n\nThe energy is given by\n\nand the Boltzmann factor is formula_29.\n\nTaking a contour integral formula_30 over any contractible closed path formula_31, we would expect it to be zero. However, this is not the case due to the singular nature of vortices. We can imagine that the theory is defined up to some energetic cut-off scale formula_32, so that we can puncture the plane at the points where the vortices are located, by removing regions of linear size of order formula_33. If formula_31 winds counter-clockwise once around a puncture, the contour integral formula_30 is an integer multiple of formula_36. The value of this integer is the index of the vector field formula_37. Suppose that a given field configuration has formula_38 punctures located at formula_39 each with index formula_40. Then, formula_41 decomposes into the sum of a field configuration with no punctures, formula_42 and formula_43, where we have switched to the complex plane coordinates for convenience. The complex argument function has a branch cut, but, because formula_41 is defined modulo formula_45, it has no physical consequences.\n\nNow,\n\nIf formula_47, the second term is positive and diverges in the limit formula_48: configurations with unbalanced numbers of vortices of each orientation are never energetically favoured.\nWhen however formula_49, the second term is equal to formula_50, which is the total potential energy of a two-dimensional Coulomb gas. The scale \"L\" is an arbitrary scale that renders the argument of the logarithm dimensionless.\n\nAssume the case with only vortices of multiplicity formula_51. At low temperatures and large formula_52 the distance between a vortex and antivortex pair tends to be extremely small, essentially of the order formula_33. At large temperatures and small formula_52 this distance increases, and the favoured configuration becomes effectively the one of a gas of free vortices and antivortices. The transition between the two different configurations is the Kosterlitz–Thouless phase transition.\n\n\n\n"}
{"id": "3469779", "url": "https://en.wikipedia.org/wiki?curid=3469779", "title": "List of Lepidoptera that feed on Senecio", "text": "List of Lepidoptera that feed on Senecio\n\nSenecio species are used as food plants by the caterpillars of a number of Lepidoptera species including:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "59179983", "url": "https://en.wikipedia.org/wiki?curid=59179983", "title": "List of U.S. state and territory plants and botanical gardens", "text": "List of U.S. state and territory plants and botanical gardens\n\nThis is a list of U.S. state and territory plants and botanical gardens — plants and botanical gardens which have been designated as an official symbol(s) by a state or territory's legislature. 5 U.S. states and 1 U.S. territory have an official state/territory plant. 7 U.S. states have an official state botanical garden or arboretum. This list excludes state flowers, state trees, and state grasses.\n\nIn addition to Hawaii's state plant, Hawaii has official state lei-making material and flowers for the individual islands of Hawaii:\n"}
{"id": "585883", "url": "https://en.wikipedia.org/wiki?curid=585883", "title": "List of UTC time offsets", "text": "List of UTC time offsets\n\nThis is a list of the UTC time offsets, showing the difference in hours and minutes from Coordinated Universal Time (UTC), from the westernmost (−12:00) to the easternmost (+14:00). It includes countries and regions that observe them during standard time or year-round.\n\nThe main purpose of this page is to list the standard time offsets of different countries, territories and regions. Information on daylight saving time or historical changes in offsets can be found in the individual offset articles (e.g. ), or the country-specific time articles (e.g. Time in Russia).\n\nPlaces that observe daylight saving time (DST) during their respective summer periods are listed only once, at the offset for their winter (usually known as \"standard\") period; see their individual articles for more information. A source for detailed DST and historical information is the tz database. Note that there are many instances of unofficial observation of a different offset (and/or DST) than expected by areas close to borders, usually for economic reasons.\n\nIn the section names, the letter after the offset is that used in nautical time. If present, a dagger (†) indicates the usage of a nautical time zone letter outside of the standard geographic definition of that time zone.\n\nSome locations use the term GMT (Greenwich Mean Time) instead of UTC in their definition of local time. (For most purposes, including this article, this distinction is not significant; see the UTC article for details.)\n\nSome zones that are north/south of each other in the mid Pacific differ by 24 hours in time – they have the same time of day but dates that are one day apart. The two extreme time zones on Earth (both in the mid Pacific) differ by 26 hours.\n\nNOTE: The purpose of the \"principal cities\" list at the top of some of the time zone entries is to give a brief list of major cities. These should be limited to a maximum of one city per country (within each zone), and not all countries in a zone need to have a city listed. Similarly, time zones need not have any cities listed if there are no major cities in that offset.\n\nPrincipal cities: Alofi, Pago Pago \n\n\"Principal cities: Papeete, Honolulu\"\n\nPrincipal cities: Taiohae\n\n\"Principal cities: Juneau, Anchorage\n\n\"Principal cities: Los Angeles, Vancouver, Tijuana\"\n\n\n\"Principal cities: Phoenix, Denver, Edmonton, Ojinaga\n\n\n\"Principal cities: Guatemala City, San José, San Salvador, Mexico City, Chicago, Winnipeg\"\n\n\"Principal cities: Lima, Bogotá, Kingston, Havana, New York, Toronto\n\n\"Principal cities: Santo Domingo, Caracas, La Paz, Manaus, Asunción, Santiago, Halifax\n\n\"Principal cities: St. John's\"\n\n\n\"Principal cities: Buenos Aires, Montevideo, São Paulo\"\n\nPrincipal cities: Fernando de Noronha, King Edward Point\n\nPrincipal cities: Praia, Ponta Delgada, Ittoqqortoormiit\n\n\"Principal cities: Accra, Dakar, London, Dublin, Lisbon\n\n\"Principal cities: Tunis, Casablanca, Lagos, Berlin, Vienna, Rome, Oslo\n\n\"Principal cities: Cairo, Johannesburg, Khartoum, Athens, Bucharest, Helsinki, Kiev, Jerusalem, Beirut\n\n\"Principal cities: Moscow, Riyadh, Baghdad, Doha, Minsk, Nairobi, Istanbul\n\n\"Principal cities: Tehran\"\n\n\"Principal cities: Muscat, Baku, Dubai, Samara\n\n\"Principal cities: Kabul\"\n\n\"Principal cities: Malé, Tashkent, Karachi, Yekaterinburg\n\n\"Principal cities: Mumbai, Chennai, Kolkata, Colombo\"\n\n\"Principal cities: Kathmandu\"\n\"Principal cities: Dhaka, Thimphu, Bishkek, Almaty, Omsk\"\n\n\"Principal cities: Yangon\"\n\n\"Principal cities: Jakarta, Bangkok, Ho Chi Minh City, Krasnoyarsk\n\n\"Principal cities: Shanghai, Beijing, Hong Kong, Taipei, Manila, Kuala Lumpur, Singapore, Makassar, Irkutsk, Perth\n\n\n\"Principal cities: Tokyo, Seoul, Pyongyang, Jayapura, Yakutsk\"\n\n\"Principal cities: Darwin, Adelaide\n\n\"Principal cities: Port Moresby, Vladivostok, Sydney, Melbourne\n\n\n\"Principal cities: Noumea, Port Vila, Honiara, Magadan\n\n\"Principal cities: Funafuti, Anadyr, Auckland, Suva,\n\n\nPrincipal cities: Nuku’alofa, Apia\n\n\n\n"}
{"id": "37894892", "url": "https://en.wikipedia.org/wiki?curid=37894892", "title": "List of carnivorans by population", "text": "List of carnivorans by population\n\nThis is a list of estimated global populations of Carnivora species. This list is not comprehensive, as not all carnivorans have had their numbers quantified.\n"}
{"id": "48757814", "url": "https://en.wikipedia.org/wiki?curid=48757814", "title": "List of causes of genital pain", "text": "List of causes of genital pain\n\nGenital pain and pelvic pain can arise from a variety of conditions, crimes, trauma, medical treatments, physical diseases, mental illness and infections. In some instances the pain is consensual and self-induced. Self-induced pain can be a cause for concern and may require a psychiatric evaluation. In other instances the infliction of pain is consensual but caused by another person (such as in surgery or tattooing). In other instances, the pain is vague\" and difficult to localize. Abdominal pain can be related to conditions related to reproductive and urinary tissues and organs.\n\nThose with pain in the genital and pelvic regions can have dysfunctional voiding or defecation. Pain in this region of the body can be associated with anxiety, depression and other psycho-social factors. In addition, this pain can have effects on activities of daily living or quality of life. Treatment can be symptomatic if the pathology is unknown and managed by physical therapy, counseling and medication.\n\n\n\n\n\n"}
{"id": "1560823", "url": "https://en.wikipedia.org/wiki?curid=1560823", "title": "List of homeopaths", "text": "List of homeopaths\n\nThe following people are recognized as notable homeopaths, either historically or currently:\n\n"}
{"id": "4711917", "url": "https://en.wikipedia.org/wiki?curid=4711917", "title": "List of volcanoes in Pakistan", "text": "List of volcanoes in Pakistan\n\nThis is a list of active and extinct volcanoes in Pakistan. Most of these are mud volcanoes, rather than the conventional magmatic type.\n\n"}
{"id": "32444480", "url": "https://en.wikipedia.org/wiki?curid=32444480", "title": "Lucien Hardy", "text": "Lucien Hardy\n\nLucien Hardy (born 1973) is a theoretical physicist, known for his work on the foundation of quantum physics including Hardy's paradox, a thought experiment he devised in 1992, and his widely cited 2001 axiomatic reconstruction of quantum theory that led to a surge of papers in this area.\n\nIn the course of his career he has performed research and lecturing in various universities in Europe. In 1992, he became lecturer in mathematical physics at Maynooth College, The National University of Ireland, subsequently he was a Royal Society postdoctoral fellow at the University of Innsbruck, Austria, lecturer in Mathematical Sciences Department at the University of Durham, UK, and a postdoctoral fellow at La Sapienza University in Rome, Italy.\n\nStarting in 1997, he was a Royal Society university research fellow for five years at the University of Oxford.\n\nHardy is currently affiliated with the University of Waterloo and is among the faculty of the Perimeter Institute for Theoretical Physics.\n\n"}
{"id": "533789", "url": "https://en.wikipedia.org/wiki?curid=533789", "title": "Magnetorheological fluid", "text": "Magnetorheological fluid\n\nA magnetorheological fluid (MR fluid, or MRF) is a type of smart fluid in a carrier fluid, usually a type of oil. When subjected to a magnetic field, the fluid greatly increases its apparent viscosity, to the point of becoming a viscoelastic solid. Importantly, the yield stress of the fluid when in its active (\"on\") state can be controlled very accurately by varying the magnetic field intensity. The upshot is that the fluid's ability to transmit force can be controlled with an electromagnet, which gives rise to its many possible control-based applications. Extensive discussions of the physics and applications of MR fluids can be found in a recent book.\n\nMR fluid is different from a ferrofluid which has smaller particles. MR fluid particles are primarily on the micrometre-scale and are too dense for Brownian motion to keep them suspended (in the lower density carrier fluid). Ferrofluid particles are primarily nanoparticles that are suspended by Brownian motion and generally will not settle under normal conditions. As a result, these two fluids have very different applications.\n\nThe magnetic particles, which are typically micrometer or nanometer scale spheres or ellipsoids, are suspended within the carrier oil and distributed randomly in suspension under normal circumstances, as below.\n\nWhen a magnetic field is applied, however, the microscopic particles (usually in the 0.1–10 µm range) align themselves along the lines of magnetic flux, see below.\n\nTo understand and predict the behavior of the MR fluid it is necessary to model the fluid mathematically, a task slightly complicated by the varying material properties (such as yield stress). \nAs mentioned above, smart fluids are such that they have a low viscosity in the absence of an applied magnetic field, but become quasi-solid with the application of such a field. In the case of MR fluids (and ER), the fluid actually assumes properties comparable to a solid when in the activated (\"on\") state, up until a point of yield (the shear stress above which shearing occurs). This yield stress (commonly referred to as apparent yield stress) is dependent on the magnetic field applied to the fluid, but will reach a maximum point after which increases in magnetic flux density have no further effect, as the fluid is then magnetically saturated. The behavior of a MR fluid can thus be considered similar to a Bingham plastic, a material model which has been well-investigated.\n\nHowever, a MR fluid does not exactly follow the characteristics of a Bingham plastic. For example, below the yield stress (in the activated or \"on\" state), the fluid behaves as a viscoelastic material, with a complex modulus that is also known to be dependent on the magnetic field intensity. MR fluids are also known to be subject to shear thinning, whereby the viscosity above yield decreases with increased shear rate. Furthermore, the behavior of MR fluids when in the \"off\" state is also non-Newtonian and temperature dependent, however it deviates little enough for the fluid to be ultimately considered as a Bingham plastic for a simple analysis.\n\nThus our model of MR fluid behavior in the shear mode becomes:\n\nWhere formula_2 = shear stress; formula_3 = yield stress; formula_4 = Magnetic field intensity formula_5 = Newtonian viscosity; formula_6 is the velocity gradient in the z-direction.\n\nLow shear strength has been the primary reason for limited range of applications. In the absence of external pressure the maximum shear strength is about 100 kPa. If the fluid is compressed in the magnetic field direction and the compressive stress is 2 MPa, the shear strength is raised to 1100 kPa. If the standard magnetic particles are replaced with elongated magnetic particles, the shear strength is also improved.\n\nFerroparticles settle out of the suspension over time due to the inherent density difference between the particles and their carrier fluid. The rate and degree to which this occurs is one of the primary attributes considered in industry when implementing or designing an MR device. Surfactants are typically used to offset this effect, but at a cost of the fluid's magnetic saturation, and thus the maximum yield stress exhibited in its activated state.\n\nMR fluids often contain surfactants including, but not limited to:\n\n\nThese surfactants serve to decrease the rate of ferroparticle settling, of which a high rate is an unfavorable characteristic of MR fluids. The ideal MR fluid would never settle, but developing this ideal fluid is as highly improbable as developing a perpetual motion machine according to our current understanding of the laws of physics. Surfactant-aided prolonged settling is typically achieved in one of two ways: by addition of surfactants, and by addition of spherical ferromagnetic nanoparticles. Addition of the nanoparticles results in the larger particles staying suspended longer since the non-settling nanoparticles interfere with the settling of the larger micrometre-scale particles due to Brownian motion. Addition of a surfactant allows micelles to form around the ferroparticles. A surfactant has a polar head and non-polar tail (or vice versa), one of which adsorbs to a ferroparticle, while the non-polar tail (or polar head) sticks out into the carrier medium, forming an inverse or regular micelle,respectively, around the particle. This increases the effective particle diameter. Steric repulsion then prevents heavy agglomeration of the particles in their settled state, which makes fluid remixing (particle redispersion) occur far faster and with less effort. For example, magnetorheological dampers will remix within one cycle with a surfactant additive, but are nearly impossible to remix without them.\n\nWhile surfactants are useful in prolonging the settling rate in MR fluids, they also prove detrimental to the fluid's magnetic properties (specifically, the magnetic saturation), which is commonly a parameter which users wish to maximize in order to increase the maximum apparent yield stress. Whether the anti-settling additive is nanosphere-based or surfactant-based, their addition decreases the packing density of the ferroparticles while in its activated state, thus decreasing the fluids on-state/activated viscosity, resulting in a \"softer\" activated fluid with a lower maximum apparent yield stress. While the on-state viscosity (the \"hardness\" of the activated fluid) is also a primary concern for many MR fluid applications, it is a primary fluid property for the majority of their commercial and industrial applications and therefore a compromise must be met when considering on-state viscosity, maximum apparent yields stress, and settling rate of an MR fluid.\n\nAn MR fluid is used in one of three main modes of operation, these being flow mode, shear mode and squeeze-flow mode. These modes involve, respectively, fluid flowing as a result of pressure gradient between two stationary plates; fluid between two plates moving relative to one another; and fluid between two plates moving in the direction perpendicular to their planes. In all cases the magnetic field is perpendicular to the planes of the plates, so as to restrict fluid in the direction parallel to the plates.\n\nThe applications of these various modes are numerous. Flow mode can be used in dampers and shock absorbers, by using the movement to be controlled to force the fluid through channels, across which a magnetic field is applied. Shear mode is particularly useful in clutches and brakes - in places where rotational motion must be controlled. Squeeze-flow mode, on the other hand, is most suitable for applications controlling small, millimeter-order movements but involving large forces. This particular flow mode has seen the least investigation so far.\nOverall, between these three modes of operation, MR fluids can be applied successfully to a wide range of applications. However, some limitations exist which are necessary to mention here.\n\nAlthough smart fluids are rightly seen as having many potential applications, they are limited in commercial feasibility for the following reasons:\n\n\nCommercial applications do exist, as mentioned, but will continue to be few until these problems (particularly cost) are overcome.\n\nStudies published beginning in the late 2000s which explore the effect of varying the aspect ratio of the ferromagnetic particles have shown several improvements over conventional MR fluids. Nanowire-based fluids show no sedimentation after qualitative observation over a period of three months. This observation has been attributed to a lower close-packing density due to decreased symmetry of the wires compared to spheres, as well as the structurally supportive nature of a nanowire lattice held together by remnant magnetization. Further, they show a different range of loading of particles (typically measured in either volume or weight fraction) than conventional sphere- or ellipsoid-based fluids. Conventional commercial fluids exhibit a typical loading of 30 to 90 wt%, while nanowire-based fluids show a percolation threshold of ~0.5 wt% (depending on the aspect ratio). They also show a maximum loading of ~35 wt%, since high aspect ratio particles exhibit a larger per particle excluded volume as well as inter-particle tangling as they attempt to rotate end-over-end, resulting in a limit imposed by high off-state apparent viscosity of the fluids. This range of loadings suggest a new set of applications are possible which may have not been possible with conventional sphere-based fluids.\n\nNewer studies have focused on dimorphic magnetorheological fluids, which are conventional sphere-based fluids in which a fraction of the spheres, typically 2 to 8 wt%, are replaced with nanowires. These fluids exhibit a much lower sedimentation rate than conventional fluids, yet exhibit a similar range of loading as conventional commercial fluids, making them also useful in existing high-force applications such as damping. Moreover, they also exhibit an improvement in apparent yield stress of 10% across those amounts of particle substitution.\n\nAnother way to increase the performance of magnetorheological fluids is to apply a pressure to them. In particular the properties in term of yield strength can be increased up to ten times in shear mode and up five times in flow mode. The motivation of this behaviour is the increase in the ferromagnetic particles friction, as described by the semiempirical magneto-tribological model by Zhang et al. Even though applying a pressure strongly improves the magnetorheological fluids behaviour, particular attention must be paid in terms of mechanical resistance and chemical compatibility of the sealing system used.\n\nThe application set for MR fluids is vast, and it expands with each advance in the dynamics of the fluid.\n\nMagnetorheological dampers of various applications have been and continue to be developed. These dampers are mainly used in heavy industry with applications such as heavy motor damping, operator seat/cab damping in construction vehicles, and more.\n\nAs of 2006, materials scientists and mechanical engineers are collaborating to develop stand-alone seismic dampers which, when positioned anywhere within a building, will operate within the building's resonance frequency, absorbing detrimental shock waves and oscillations within the structure, giving these dampers the ability to make any building earthquake-proof, or at least earthquake-resistant.\n\nThe U.S. Army Research Office is currently funding research into using MR fluid to enhance body armor. In 2003, researchers stated they were five to ten years away from making the fluid bullet resistant. In addition, HMMWVs, and various other all-terrain vehicles employ dynamic MR shock absorbers and/or dampers.\n\nMagnetorheological finishing, a magnetorheological fluid-based optical polishing method, has proven to be highly precise. It was used in the construction of the Hubble Space Telescope's corrective lens. \nIf the shock absorbers of a vehicle's suspension are filled with magnetorheological fluid instead of a plain oil or gas, and the channels which allow the damping fluid to flow between the two chambers is surrounded with electromagnets, the viscosity of the fluid, and hence the critical frequency of the damper, can be varied depending on driver preference or the weight being carried by the vehicle - or it may be dynamically varied in order to provide stability control across vastly different road conditions. This is in effect a magnetorheological damper. For example, the MagneRide active suspension system permits the damping factor to be adjusted once every millisecond in response to conditions. General Motors (in a partnership with Delphi Corporation) has developed this technology for automotive applications. It made its debut in both Cadillac (Seville STS build date on or after 1/15/2002 with RPO F55) as \"Magneride\" (or \"MR\") and Chevrolet passenger vehicles (All Corvettes made since 2003 with the F55 option code) as part of the driver selectable \"Magnetic Selective Ride Control (MSRC)\" system in model year 2003. Other manufacturers have paid for the use of it in their own vehicles, for example Audi and Ferrari offer the MagneRide on various models.\n\nGeneral Motors and other automotive companies are seeking to develop a magnetorheological fluid based clutch system for push-button four wheel drive systems. This clutch system would use electromagnets to solidify the fluid which would lock the driveshaft into the drive train.\n\nPorsche has introduced magnetorheological engine mounts in the 2010 Porsche GT3 and GT2. At high engine revolutions, the magnetorheological engine mounts get stiffer to provide a more precise gearbox shifter feel by reducing the relative motion between the power train and chassis/body.\n\nAs of September 2007, Acura (Honda) has begun an advertising campaign highlighting its use of MR technology in passenger vehicles manufactured for the 2007 MDX model year.\n\nMagnetorheological dampers are under development for use in military and commercial helicopter cockpit seats, as safety devices in the event of a crash. They would be used to decrease the shock delivered to a passenger's spinal column, thereby decreasing the rate of permanent injury during a crash.\n\nMagnetorheological dampers are utilized in semi-active human prosthetic legs. Much like those used in military and commercial helicopters, a damper in the prosthetic leg decreases the shock delivered to the patients leg when jumping, for example. This results in an increased mobility and agility for the patient.\n\n\n\n"}
{"id": "235195", "url": "https://en.wikipedia.org/wiki?curid=235195", "title": "Mineral (nutrient)", "text": "Mineral (nutrient)\n\nIn the context of nutrition, a mineral is a chemical element required as an essential nutrient by organisms to perform functions necessary for life. Minerals originate in the earth and cannot be made by living organisms. Plants get minerals from soil. Most of the minerals in a human diet come from eating plants and animals or from drinking water. As a group, \"minerals\" are one of the four groups of essential nutrients, the others of which are vitamins, essential fatty acids, and essential amino acids. The five major minerals in the human body are calcium, phosphorus, potassium, sodium, and magnesium. All of the remaining elements in a human body are called \"trace elements\". The trace elements that have a specific biochemical function in the human body are sulfur, iron, chlorine, cobalt, copper, zinc, manganese, molybdenum, iodine and selenium.\n\nMost chemical elements that are ingested by organisms are in the form of simple compounds. Plants absorb dissolved elements in soils, which are subsequently ingested by the herbivores and omnivores that eat them, and the elements move up the food chain. Larger organisms may also consume soil (geophagia) or use mineral resources, such as salt licks, to obtain limited minerals unavailable through other dietary sources.\n\nBacteria and fungi play an essential role in the weathering of primary elements that results in the release of nutrients for their own nutrition and for the nutrition of other species in the ecological food chain. One element, cobalt, is available for use by animals only after having been processed into complex molecules (e.g., vitamin B) by bacteria. Minerals are used by animals and microorganisms for the process of mineralizing structures, called \"biomineralization\", used to construct bones, seashells, eggshells, exoskeletons and mollusc shells.\n\nAt least twenty chemical elements are known to be \"required\" to support human biochemical processes by serving structural and functional roles as well as electrolytes. However, as many as twenty-nine elements in total (including hydrogen, carbon, nitrogen and oxygen) are suggested to be used by mammals, as inferred by biochemical and uptake studies. Calcium makes up 920 to 1200 grams of adult body weight, with 99% of it contained in bones and teeth. Phosphorus makes up about 1% of a person's body weight. The other major minerals (potassium, sodium, chlorine, sulfur and magnesium) make up only about 0.85% of the weight of the body. Together these eleven chemical elements (H, C, N, O, Ca, P, K, Na, Cl, S, Mg) make up 99.85% of the body. There is not scientific consensus on whether chromium is an essential trace element. The United States and Japan designate chromium as an essential nutrient, but the European Food Safety Authority (EFSA), representing the European Union, reviewed the question in 2014 and does not agree. \n\nMost of the known and suggested mineral nutrients are of relatively low atomic weight, and are reasonably common on land, or for sodium and iodine, in the ocean:\n\nRDA = Recommended Dietary Allowance; UL = Tolerable upper intake level; Figures shown are for adults age 31-50, male or female neither pregnant nor lactating\n\n<nowiki>*</nowiki> One serving of seaweed exceeds the US UL of 1100 μg but not the 3000 μg UL set by Japan.\n\nMinerals are present in a healthy human being's blood at certain mass and molar concentrations. The figure below presents the concentrations of each of the chemical elements discussed in this article, from center-right to the right. Depending on the concentrations, some are in upper part of the picture, while others are in the lower part. The figure includes the relative values of other constituents of blood such as hormones. In the figure, minerals are color highlighted in purple.\n\nDietitians may recommend that minerals are best supplied by ingesting specific foods rich with the chemical element(s) of interest. The elements may be naturally present in the food (e.g., calcium in dairy milk) or added to the food (e.g., orange juice fortified with calcium; iodized salt fortified with iodine). Dietary supplements can be formulated to contain several different chemical elements (as compounds), a combination of vitamins and/or other chemical compounds, or a single element (as a compound or mixture of compounds), such as calcium (calcium carbonate, calcium citrate) or magnesium (magnesium oxide), or iron (ferrous sulfate, iron bis-glycinate).\n\nThe dietary focus on chemical elements derives from an interest in supporting the biochemical reactions of metabolism with the required elemental components. Appropriate intake levels of certain chemical elements have been demonstrated to be required to maintain optimal health. Diet can meet all the body's chemical element requirements, although supplements can be used when some recommendations are not adequately met by the diet. An example would be a diet low in dairy products, and hence not meeting the recommendation for calcium.\n\nMany ultratrace elements have been suggested as essential, but such claims have usually not been confirmed. Definitive evidence for efficacy comes from the characterization of a biomolecule containing the element with an identifiable and testable function. One problem with identifying efficacy is that some elements are innocuous at low concentrations and are pervasive (examples: silicon and nickel in solid and dust), so proof of efficacy is lacking because deficiencies are difficult to reproduce. Ultratrace elements of some minerals such as silicon and boron are known to have a role but the exact biochemical nature is unknown, and others such as arsenic are suspected to have a role in health, but with weaker evidence.\n\nMinerals can be bioengineered by bacteria which act on metals to catalyze mineral dissolution and precipitation. Mineral nutrients are recycled by bacteria distributed throughout soils, oceans, freshwater, groundwater, and glacier meltwater systems worldwide. Bacteria absorb dissolved organic matter containing minerals as they scavenge phytoplankton blooms. Mineral nutrients cycle through this marine food chain, from bacteria and phytoplankton to flagellates and zooplankton, which are then eaten by other marine life. In terrestrial ecosystems, fungi have similar roles as bacteria, mobilizing minerals from matter inaccessible by other organisms, then transporting the acquired nutrients to local ecosystems.\n\n\n\n"}
{"id": "43796674", "url": "https://en.wikipedia.org/wiki?curid=43796674", "title": "Natural deep eutectic solvents", "text": "Natural deep eutectic solvents\n\nNatural deep eutectic solvents (NADES) are bio-based ionic liquids and deep eutectic solvents which are composed of two or more compounds that are generally plant based primary metabolites, i.e. organic acids, sugars, alcohols, amines and amino acids. Ionic liquids are salts, liquid at room temperature, characterized by ionic bonds which have at least one large organic ion and a cation with a low degree of symmetry. The positive and negatively charged ions in the liquid are thus kept far apart so that they reduce the attractive forces between them and hinder crystallization, lowering the melting point and resulting in a completely ionic liquid at room temperature. Deep eutectic solvents (DES) are mixtures of solid compounds that form liquids due to a large depression of the melting point; the charge delocalization in the case of DES is caused by hydrogen bonding forming a non-aqueous liquid at room temperature. Work done by Choi, Spronsen \"et al\". showed that water can be present as part of the solvent, being strongly retained in the liquid and which cannot be evaporated.\n"}
{"id": "31462289", "url": "https://en.wikipedia.org/wiki?curid=31462289", "title": "Old Baldy (Lynch, Nebraska)", "text": "Old Baldy (Lynch, Nebraska)\n\nOld Baldy, also known as the Tower, is a hill located near the village of Lynch, in Boyd County, in the northern part of the state of Nebraska in the Midwestern United States. It was visited by the Lewis and Clark Expedition on their way up the Missouri River in 1804; nearby, they discovered a colony of prairie dogs, an animal previously unknown to scientists.\n\nFor its connection with Lewis and Clark, and because it has little changed since their passage in 1804, the site was listed in the National Register of Historic Places in 2004.\n\nOld Baldy is located about north of Lynch, Nebraska, and about half a mile (about a kilometer) south of the Missouri River. It is part of a line of bluffs at the southern edge of the Missouri valley; it rises an additional above the surrounding highlands, reaching an elevation of above sea level.\n\nThe formation making up the hill is part of the Pierre Shale, deposited in the deep marine waters of the Western Interior Seaway during the Campanian and Maastrichtian ages of the late Cretaceous period, 70–80 million years ago. The Pierre consists chiefly of dark shale, but also contains chalky strata, one of which is exposed at the top of the hill. The chalk does not readily support plant growth, giving the hill its conspicuous bald appearance.\n\nFor many years before the 1803 Louisiana Purchase, Thomas Jefferson had contemplated seeking a water route from the United States to the Pacific Ocean. With the acquisition of the Louisiana Territory from France, this could be done legally. Jefferson, now President of the United States, accordingly dispatched the Lewis and Clark Expedition up the Missouri River. The party was charged with following the main stem of the river to its headwaters and then finding rivers running westward from the Rocky Mountains to the Pacific. They were also directed to establish peaceable relations with the indigenous peoples of the region; to note mineral and other resources; to map the major physiographic features; and to describe and collect specimens of the flora and fauna of the territory.\n\nOn May 14, 1804, the party left its winter quarters at Camp Dubois, near the confluence of the Missouri and the Mississippi River. On July 21, it reached the mouth of the Platte River; on September 4, the mouth of the Niobrara River.\n\nOn September 7, 1804, the two captains left the boats to explore the conspicuous bald hill, which they had seen from the river the day before. They climbed to the summit and measured its height as , and its base as .\n\nIn descending the hill, the explorers discovered a colony of prairie dogs, an animal then unknown to science, though known to French explorers. To secure specimens, Lewis and Clark summoned other members of the party from the boat. They were able to shoot one, \"which was cooked for the Capts dinner\", but wanted a live animal. An attempt to dig one out of its burrow proved unsuccessful: after digging through hard clay, the men thrust a pole down the hole and discovered that they were less than halfway to the bottom. The party then attempted to flood an animal out, which also proved no small task: \"we por'd into one of the holes 5 barrels of water without filling it.\" Although they worked until nightfall, they only succeeded in flushing out and capturing a single prairie dog.\n\nThe prairie dog survived the trip up the river to the expedition's winter camp at Fort Mandan, near the mouth of the Knife River in present-day North Dakota. On April 7, 1805, the expedition's keelboat was dispatched back down the Missouri to St. Louis, carrying a collection of specimens including six living animals: a sharp-tailed grouse, four magpies, and the prairie dog. The grouse apparently died between St. Louis and New Orleans, and three of the magpies did not survive the trip from New Orleans to Baltimore. On October 4, the prairie dog and the surviving magpie were inspected by President Jefferson in Washington, D.C. They were then sent to Charles Willson Peale for his museum in Philadelphia. The prairie dog is known to have survived at least until April 1806.\n\nAs a conspicuous and recognizable landmark, Old Baldy was used by surveyors operating in this region of Nebraska and South Dakota. In particular, it was used by Lieutenant J. C. Clark (apparently unrelated to William Clark of the Lewis and Clark Expedition) in an 1860 survey to lay out the boundary of the Fort Randall Military Reservation. In 1948, the U.S. Coast and Geodetic Survey established a triangulation station named \"Lynch\" atop a hill located just north of Old Baldy; the northern hill is of about the same height, but is not devoid of vegetation.\n\nFor communities along the Missouri River in eastern Nebraska, the 2004 bicentennial of the Lewis and Clark Expedition was an opportunity to promote tourism. It was estimated that as many as 40 million people might travel to parts of the Corps of Discovery's route in that year.\n\nThe residents of Lynch used the prairie-dog episode as a focus for tourism promotion. Although the animals are generally regarded as pests by farmers and ranchers, it was thought that the story of their discovery might draw visitors specifically to the area. To fund Lewis and Clark-related projects, the city sold stuffed fabric prairie dogs made by local volunteers and dubbed \"Lynch Dawgs\". A Lynch restaurateur also installed a chainsaw sculpture of a prairie dog outside of his establishment. Tourist promotion of Old Baldy continued after the Lewis and Clark bicentennial.\n\nIn 2004, an area of about including Old Baldy was placed on the National Register of Historic Places under the name \"the Tower\". The site was nominated for its connection to Lewis and Clark; it was noted that the surrounding prairie and burr oak woodlands were little altered since 1804. In 2005, a conservation easement was purchased covering including the hill.\n\nThe site is on private land, but can be viewed from an overlook with an interpretive sign off a nearby county road.\n\n"}
{"id": "51002757", "url": "https://en.wikipedia.org/wiki?curid=51002757", "title": "Paolo Lioy", "text": "Paolo Lioy\n\nPaolo Lioy (31 July 1834, Vicenza – 27 January 1911, Vancimuglio di Grumolo delle Abbadesse) was an Italian naturalist, redshirt patriot and politician.\n\nAfter graduating from high school, Lioy studied law in Padua. In 1853 he demonstrated his childhood interest in the natural sciences, by taking part in the reorganization of collections of the natural history section of Museo naturalistico archeologico in Vicenza \nAt this time he was also engaged in writing articles and political activism in favor of the unification of Italy.\n\nIn 1857, he married the daughter of an officer of Bourbon, Giulia de Beaumont.\n\nIn 1859 he published La vita nell'universo (Life in the universe), the first of his several popular science books and translated into French.\n\nFrom 1862 to 1869 he served as Secretary of the Accademia Olimpica di Vicenza.\n\nIn 1864 he began excavations in the valleys around Arcugnano, looking for remains of prehistoric settlements, thus giving rise to a series of archaeological finds that continued in the next century, well after his death. Based on data collected in 1876 he published the book \"Le abitazioni lacustri di Fimon\" ( Fimon Lake dwellings), which had once again international resonance.\n\nFrom 1865 he also studied fossils from Monte Bolca.\n\nIn 1866 because his involvement with Garibaldi the Austrian authorities forced him to leave.He moved to Milan along with other political refugees. His exile lasted a few months, after which he returned to Vicenza where he was appointed Provveditorato agli studi and became a Deputy, although again only for a few months.\n\nHe served as councillor from 1866 to 1902 and from 1867 to 1905 provincial Councillor. From 1870 he was elected to 6 consecutive legislatures, until 1888.\n\nIn 1905 he was appointed senatore del Regno (Senator of the Kingdom).\n\nHis scientific and literary activity continued despite political commitments, throughout his life, which ended in 1911.\n\nFor his calling for a general audience and literary abilities, Paolo Lioy was nicknamed by his contemporaries \"il poeta della natura\" (the poet of nature). \n\n\n\n"}
{"id": "57669296", "url": "https://en.wikipedia.org/wiki?curid=57669296", "title": "Peter Milner", "text": "Peter Milner\n\nPeter Milner (13 June 1919 – 2 June 2018) was a Canadian neuroscientist. He was the husband of Dr. Brenda Milner.\nBorn in Yorkshire, England, Milner worked at the British Air Defence Research and Development Establishment before moving to Canada in 1944. He was an electrical engineer, but became interested in neuroscience while Brenda was studying the subject at McGill University; he became a graduate student under the same supervisor as she, and later taught at McGill himself. In collaboration with James Olds, he is credited with the discovery of the brain's pleasure centre in 1954.\n\nMilner received the Gold Medal for Distinguished Lifetime Contributions to Canadian Psychology from the Canadian Psychological Association in 2005.\n"}
{"id": "23970994", "url": "https://en.wikipedia.org/wiki?curid=23970994", "title": "Prehistoric Journey: A History of Life on Earth", "text": "Prehistoric Journey: A History of Life on Earth\n\nPrehistoric Journey: A History of Life on Earth is a book by Kirk R Johnson and Richard Stucky. It was published by Fulcrum Publishing.\n"}
{"id": "221536", "url": "https://en.wikipedia.org/wiki?curid=221536", "title": "Right-hand rule", "text": "Right-hand rule\n\nIn mathematics and physics, the right-hand rule is a common mnemonic for understanding orientation of axes in 3-dimensional space.\n\nMost of the various left- and right-hand rules arise from the fact that the three axes of three-dimensional space have two possible orientations. This can be seen by holding your hands outward and together, palms up, with the fingers curled. If the curl of your fingers represents a movement from the first or \"x\"-axis to the second or \"y\"-axis, then the third or \"z\"-axis can point along either thumb. Left- and right-hand rules arise when dealing with coordinate axes, rotation, spirals, electromagnetic fields, mirror images, and enantiomers in mathematics and chemistry.\n\nCoordinates are usually right-handed.\n\nFor right-handed coordinates your right thumb points along the Z axis in the positive direction and the curl of your fingers represents a motion from the first or X axis to the second or Y axis. When viewed from the top or Z axis the system is counter-clockwise.\n\nFor left-handed coordinates your left thumb points along the Z axis in the positive direction and the curled fingers of your left hand represent a motion from the first or X axis to the second or Y axis. When viewed from the top or Z axis the system is clockwise.\n\nInterchanging the labels of any two axes reverses the handedness. Reversing the direction of one axis (or of all three axes) also reverses the handedness. (If the axes do not have a positive or negative direction then handedness has no meaning.) Reversing two axes amounts to a 180° rotation around the remaining axis.\nIn mathematics, a rotating body is commonly represented by a vector along the axis of rotation. The length of the vector gives the speed of rotation and the direction of the axis gives the direction of rotation according to the right-hand rule: right fingers curled in the direction of rotation and the right thumb pointing in the positive direction of the axis. This allows some easy calculations using the vector cross product. Note that no part of the body is moving in the direction of the axis arrow, which takes some getting used to. By coincidence, if your thumb points north, Earth rotates in a prograde direction according to the right-hand rule. This causes the Sun, Moon, and stars to appear to revolve westward according to the left-hand rule.\n\n \nA helix is a curved line formed by a point rotating around a center while the center moves up or down the Z-axis. Helices are either right- or left-handed, curled fingers giving the direction of rotation and thumb giving the direction of advance along the Z-axis. \nThe threads of a screw are a helix and therefore screws can be right- or left-handed. The rule is this: if a screw is right-handed (most screws are) point your right thumb in the direction you want the screw to go and turn the screw in the direction of your curled right fingers.\n\nAmpère's right-hand grip rule (also called \"right-hand screw rule\", \"coffee-mug rule\" or the \"corkscrew-rule\") is used either when a vector (such as the Euler vector) must be defined to represent the rotation of a body, a magnetic field, or a fluid, or vice versa, when it is necessary to define a rotation vector to understand how rotation occurs. It reveals a connection between the current and the magnetic field lines in the magnetic field that the current created.\n\nAndré-Marie Ampère, a French physicist and mathematician, for whom the rule was named, was inspired by Hans Christian Ørsted, another physicist who experimented with magnet needles. Ørsted observed that the needles swirled when in the proximity of an electric current-carrying wire, and concluded that electricity could create magnetic fields.\n\nThis version of the rule is used in two complementary applications of Ampère's circuital law:\n\nThe rule is also used to determine the direction .\n\nThe cross product of two vectors is often taken in physics and engineering. For example, in statics and dynamics, torque is the cross product of lever length and force, while angular momentum is the cross product of linear momentum and distance. In electricity and magnetism, the force exerted on a moving charged particle when moving in a magnetic field B is given by:\n\nThe direction of the cross product may be found by application of the right hand rule as follows: \n\nFor example, for a positively charged particle moving to the North, in a region where the magnetic field points West, the resultant force points up.\n\nThe right hand rule is in widespread use in physics. A list of physical quantities whose directions are related by the right-hand rule is given below. (Some of these are related only indirectly to cross products, and use the second form.)\n\n\n\n"}
{"id": "272021", "url": "https://en.wikipedia.org/wiki?curid=272021", "title": "S-IVB", "text": "S-IVB\n\nThe S-IVB (sometimes S-4B, always pronounced \"ess four bee\") was built by the Douglas Aircraft Company and served as the third stage on the Saturn V and second stage on the Saturn IB. It had one J-2 engine. For lunar missions it was fired twice: first for the orbit insertion after second stage cutoff, and then for translunar injection (TLI).\n\nThe S-IVB evolved from the upper stage of the Saturn I rocket, the S-IV, and was the first stage of the Saturn V to be designed. The S-IV used a cluster of six engines but used the same fuels as the S-IVB — liquid hydrogen and liquid oxygen. It was also originally meant to be the fourth stage of a planned rocket called the C-4, hence the name S-IV.\n\nEleven companies submitted proposals for being the lead contractor on the stage by the deadline of 29 February 1960. NASA administrator T. Keith Glennan decided on 19 April that Douglas Aircraft Company would be awarded the contract. Convair had come a close second but Glennan did not want to monopolize the liquid hydrogen-fueled rocket market as Convair was already building the Centaur rocket stage.\n\nIn the end the Marshall Space Flight Center decided to use the C-5 rocket (later called the Saturn V), which had three stages and would be topped with an uprated S-IV called the S-IVB which instead of using a cluster of engines would have a single J-2 engine. Douglas was awarded the contract for the S-IVB because of the similarities between it and the S-IV. At the same time it was decided to create the C-IB rocket (Saturn IB) that would also use the S-IVB as its second stage and could be used for testing the Apollo spacecraft in Earth orbit.\n\nDouglas built two distinct versions of the S-IVB, the 200 series and the 500 series. The 200 series was used by the Saturn IB and differed from the 500 in that it did not have a flared interstage and it had less helium pressurization on board since it did not have to be restarted. In the 500 series, the interstage needed to flare out to match the larger diameter of the S-IC and S-II stages of the Saturn V. The 200 series also had three solid rockets for separating the S-IVB stage from the S-IB stage during launch. On the 500 series this was reduced to two, and two small APS (auxiliary propulsion system) thruster modules were added as ullage motors for restarting the J-2 engine and to provide attitude control during coast phases of flight.\n\nThe S-IVB carried 73,280 liters (19,359 U.S. gallons) of LOX, massing 87,200 kg (192,243 lbs). It carried 252,750 liters (66,770 U.S. gallons) of LH2, massing 18,000 kg (39,683 lbs). Empty mass was 10,000 kg (23,000 lb)\n\nAttitude control was provided by J-2 engine gimbaling during powered flight and by the two APS modules during coast. The APS modules each contained four thrusters providing 150 pounds of thrust (three for roll, pitch, and yaw, and one for ullage), and these were fueled by a hypergolic mixture of dinitrogen tetroxide and monomethyl hydrazine. They were used for three-axis control during coast phases, roll control during J-2 firings, and ullage for the second ignition of the J-2 engine.\n\nA surplus S-IVB tank, serial number 212, was converted into the hull for the Skylab, the first American space station. Skylab was launched on a Saturn V on May 14, 1973, but it eventually reentered the atmosphere on July 11, 1979. A second S-IVB, serial number 515, was also converted into a backup Skylab, but this one never flew.\n\nDuring the missions of Apollo 13, Apollo 14, Apollo 15, Apollo 16, and Apollo 17, the S-IVB stages were crashed into the Moon to perform seismic measurements used for characterizing the lunar interior.\n\nThe second stage of the Ares I rocket and the proposed Earth Departure Stage (EDS) would have had some of the characteristics of the S-IVB stage, as both would have had an uprated J-2 engine, called the J-2X, with the latter performing the same functions as that of the Series 500 version of the stage (placing the payload into orbit, and later firing the spacecraft into trans-lunar space).\n\n\n"}
{"id": "295148", "url": "https://en.wikipedia.org/wiki?curid=295148", "title": "Shoal", "text": "Shoal\n\nIn oceanography, geomorphology, and earth sciences, a shoal is a natural submerged ridge, bank, or bar that consists of, or is covered by, sand or other unconsolidated material, and rises from the bed of a body of water to near the surface. Often it refers to those submerged ridges, banks, or bars that rise near enough to the surface of a body of water as to constitute a danger to navigation. Shoals are also known as sandbanks, sandbars, or gravelbars. Two or more shoals that are either separated by shared troughs or interconnected by past and/or present sedimentary and hydrographic processes are referred to as a shoal complex.\n\nThe term \"shoal\" is also used in a number of ways that can be either similar or quite different from how it is used in the geologic, geomorphic, and oceanographic literature. Sometimes, this terms refers to either (1) any relatively shallow place in a stream, lake, sea, or other body of water; (2) a rocky area on the sea floor within an area mapped for navigation purposes; (3) a growth of vegetation on the bottom of a deep lake that occurs at any depth; (4) and as a verb for the process of proceeding from a greater to a lesser depth of water. \n\nShoals are characteristically long and narrow (linear) ridges. They can develop where a stream, river, or ocean current promotes deposition of sediment and granular material, resulting in localized shallowing (shoaling) of the water. Marine shoals also develop either by the in place drowning of barrier islands as the result of episodic sea level rise or by the erosion and submergence of inactive delta lobes.\n\nShoals can appear as a coastal landform in the sea, where they are classified as a type of ocean bank, or as fluvial landforms in rivers, streams, and lakes.\n\nA shoal–sandbar may seasonally separate a smaller body of water from the sea, such as:\n\n\nThe term \"bar\" can apply to landform features spanning a considerable range in size, from a length of a few metres in a small stream to marine depositions stretching for hundreds of kilometers along a coastline, often called barrier islands.\n\nThey are typically composed of sand, although they could be of any granular matter that the moving water has access to and is capable of shifting around (for example, soil, silt, gravel, cobble, shingle, or even boulders). The grain size of the material comprising a bar is related to the size of the waves or the strength of the currents moving the material, but the availability of material to be worked by waves and currents is also important.\n\nWave shoaling is the process when surface waves move towards shallow water, such as a beach, they slow down, their wave height increases and the distance between waves decreases. This behavior is called \"shoaling\", and the waves are said to shoal. The waves may or may not build to the point where they break, depending on how large they were to begin with, and how steep the slope of the beach is. In particular, waves shoal as they pass over submerged sandbanks or reefs. This can be treacherous for boats and ships.\n\nShoaling can also diffract waves, so the waves change direction. For example, if waves pass over a sloping bank which is shallower at one end than the other, then the shoaling effect will result in the waves slowing more at the shallow end. Thus the wave fronts will refract, changing direction like light passing through a prism. Refraction also occurs as waves move towards a beach if the waves come in at an angle to the beach, or if the beach slopes more gradually at one end than the other.\n\nSandbars, also known as a trough bars, form where the waves are breaking, because the breaking waves set up a shoreward current with a compensating counter-current along the bottom. Sometimes this occurs seaward of a trough (marine landform).\n\nSand carried by the offshore moving bottom current is deposited where the current reaches the wave break. Other longshore bars may lie further offshore, representing the break point of even larger waves, or the break point at low tide.\n\nA harbor or river bar is a sedimentary deposit formed at a harbor entrance or river mouth by: the deposition of freshwater sediment, or the action of waves on the sea floor or up—current beaches.\n\nWhere beaches are suitably mobile, or the river’s suspended and/or bed loads are large enough, deposition can build up a sandbar that completely blocks a river mouth and damming the river. It can be a seasonally natural process of aquatic ecology, causing the formation of estuaries and wetlands in the lower course of the river. This situation will persist until the bar is eroded by the sea, or the dammed river develops sufficient head to break through the bar.\n\nThe formation of harbor bars can prevent access for boats and shipping, can be the result of: \n\nIn a nautical sense, a \"bar\" is a shoal, similar to a reef: a shallow formation of (usually) sand that is a navigation or grounding hazard, with a depth of water of or less. It therefore applies to a silt accumulation that shallows the entrance to or course of a river, or creek. A bar can form a dangerous obstacle to shipping, preventing access to the river or harbour in unfavourable weather conditions or at some states of the tide.\n\nIn addition to longshore bars discussed above that are relatively small features of a beach, the term \"shoal\" can be applied to larger geological units that form off a coastline as part of the process of coastal erosion. These include spits and baymouth bars that form across the front of embayments and rias. A tombolo is a bar that forms an isthmus between an island or offshore rock and a mainland shore.\n\nIn places of re-entrance along a coastline (such as inlets, coves, rias, and bays), sediments carried by a longshore current will fall out where the current dissipates, forming a spit. An area of water isolated behind a large bar is called a lagoon. Over time, lagoons may silt up, becoming salt marshes.\n\nIn some cases, shoals may be precursors to beach expansion and dunes formation, providing a source of windblown sediment to augment such beach or dunes landforms.\n\nSince prehistoric times humans have chosen some shoals as a site of habitation. In some early cases the locations provided easy access to exploit marine resources. In modern times these sites are sometimes chosen for the water amenity or view, but many such locations are prone to storm damage.\n\n\n"}
{"id": "848763", "url": "https://en.wikipedia.org/wiki?curid=848763", "title": "Soyuz 20", "text": "Soyuz 20\n\nSoyuz 20 (, Union 20) was an unmanned spacecraft launched by the Soviet Union. It was a long-duration test of the Soyuz spacecraft that docked with the Salyut 4 space station. Soyuz 20 performed comprehensive checking of improved on-board systems of the spacecraft under various flight conditions. It also carried a biological payload. Living organisms were exposed to three months in space.\n\nIt was reentered on 16 February 1976.\n\nNone.\n\n"}
{"id": "6746813", "url": "https://en.wikipedia.org/wiki?curid=6746813", "title": "Spinhenge@Home", "text": "Spinhenge@Home\n\nSpinhenge@home is a distributed computing project for the BOINC client, which performs extensive numerical simulations concerning the physical characteristics of magnetic molecules. It is a project of the Bielefeld University of Applied Sciences, Department of Electrical Engineering and Computer Science, in cooperation with the University of Osnabrück and Ames Laboratory.\n\nThe project began beta testing on September 1, 2006. The project uses the Metropolis Monte Carlo algorithm to calculate and simulate spin dynamics in nanoscale molecular magnets.\n\nOn September 28, 2011, a hiatus was announced while the project team reviewed results and upgraded hardware. As of July 10, 2015 the hiatus continues and it is possible that the project has been closed down permanently.\n\n\n"}
{"id": "23065547", "url": "https://en.wikipedia.org/wiki?curid=23065547", "title": "Standard sea level", "text": "Standard sea level\n\nStandard sea level (SSL) (also known as \"sea level standard\" (SLS)) defines a set of conditions for physical calculations.\nThe term \"standard sea level\" is used to indicate that values of properties are to be taken to be the same as those standard at sea level, and is done to define values for use in general calculations.\n\nAt SSL some atmospheric properties are:\n\n"}
{"id": "49976857", "url": "https://en.wikipedia.org/wiki?curid=49976857", "title": "Tardiness (scheduling)", "text": "Tardiness (scheduling)\n\nIn scheduling, tardiness is a measure of a delay in executing certain operations and earliness is a measure of finishing operations before due time. The operations may depend on each other and on the availability of equipment to perform them.\n\nTypical examples include job scheduling in manufacturing and data delivery scheduling in data processing networks.\n\nIn manufacturing environment, inventory management considers both tardiness and earliness undesirable. Tardiness involves backlog issues such as customer compensation for delays and loss of goodwill. Earliness incurs expenses for storage of the manufactured items.\n\nIn an environment with multiple jobs, let the deadline be formula_1 and the completion time be formula_2 of job formula_3. Then for job formula_3 lateness is formula_5, earliness is formula_6, tardiness is formula_7. The common objective functions are formula_8 or weighted version of these sums, formula_9, where every job comes with a weight formula_10. The weight is a representation of job cost, priority, etc.\n\nIn a large number of cases the problems of optimizing these functions are NP-hard.\n"}
{"id": "29426653", "url": "https://en.wikipedia.org/wiki?curid=29426653", "title": "Wolstenholme prime", "text": "Wolstenholme prime\n\nIn number theory, a Wolstenholme prime is a special type of prime number satisfying a stronger version of Wolstenholme's theorem. Wolstenholme's theorem is a congruence relation satisfied by all prime numbers greater than 3. Wolstenholme primes are named after mathematician Joseph Wolstenholme, who first described this theorem in the 19th century.\n\nInterest in these primes first arose due to their connection with Fermat's last theorem, another theorem with significant importance in mathematics. Wolstenholme primes are also related to other special classes of numbers, studied in the hope to be able to generalize a proof for the truth of the theorem to all positive integers greater than two.\n\nThe only two known Wolstenholme primes are 16843 and 2124679 . There are no other Wolstenholme primes less than 10.\n\nWolstenholme prime can be defined in a number of equivalent ways.\n\nA Wolstenholme prime is a prime number \"p\" > 7 that satisfies the congruence\nwhere the expression in left-hand side denotes a binomial coefficient.\nCompare this with Wolstenholme's theorem, which states that for every prime \"p\" > 3 the following congruence holds:\n\nA Wolstenholme prime is a prime \"p\" that divides the numerator of the Bernoulli number \"B\". The Wolstenholme primes therefore form a subset of the irregular primes.\n\nA Wolstenholme prime is a prime \"p\" such that (\"p\", \"p\"–3) is an irregular pair.\n\nA Wolstenholme prime is a prime \"p\" such that\n\ni.e. the numerator of the harmonic number formula_4 expressed in lowest terms is divisible by \"p\".\n\nThe search for Wolstenholme primes began in the 1960s and continued over the following decades, with the latest results published in 2007. The first Wolstenholme prime 16843 was found in 1964, although it was not explicitly reported at that time. The 1964 discovery was later independently confirmed in the 1970s. This remained the only known example of such a prime for almost 20 years, until the discovery announcement of the second Wolstenholme prime 2124679 in 1993. Up to 1.2, no further Wolstenholme primes were found. This was later extended to 2 by McIntosh in 1995 and Trevisan & Weber were able to reach 2.5. The latest result as of 2007 is that there are only those two Wolstenholme primes up to .\n\nIt is conjectured that infinitely many Wolstenholme primes exist. It is conjectured that the number of Wolstenholme primes ≤ \"x\" is about \"ln ln x\", where \"ln\" denotes the natural logarithm. For each prime \"p\" ≥ 5, the Wolstenholme quotient is defined as\n"}
