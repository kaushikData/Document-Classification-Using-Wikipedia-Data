{"id": "8224985", "url": "https://en.wikipedia.org/wiki?curid=8224985", "title": "A4260 road", "text": "A4260 road\n\nThe A4260 is a road that leads from the A422 Henneff Way, Banbury to Frieze Way near Oxford. It is single carriageway for a majority of the route, except for a section near Steeple Aston for and on Frieze Way where the A4260 meets the A34 at Peartree Interchange, Oxford, where it becomes a dual carriageway. The road passes through Bodicote, Adderbury, Deddington and Kidlington, Oxfordshire. The road terminates at the A44 road roundabout at Frieze Way which is just north of Oxford. Until 1990 it was part of the A423 and the major route from Banbury to Oxford. It was renumbered to encourage the traffic that formerly used this route to use the M40.\n"}
{"id": "873868", "url": "https://en.wikipedia.org/wiki?curid=873868", "title": "Aleksandr Laveykin", "text": "Aleksandr Laveykin\n\nAleksandr Ivanovich Laveykin (; born April 21, 1951) is a retired Soviet cosmonaut.\n\nBorn in Moscow, Laveykin was selected as a cosmonaut on December 1, 1978. He flew on one spaceflight, for the first part of the long duration expedition Mir EO-2. He flew as a flight engineer, and was both launched and landed with the spacecraft Soyuz TM-2. He spent 174 days 3 hours 25 minutes in space. Married with one child, Laveykin retired on March 28, 1994.\n\nLaunched in February 1987, his spaceflight was intended to last until December 1987, but doctors on the ground determined that he was having minor heart irregularities. For this reason, in July he was replaced by Soviet cosmonaut Aleksandr Pavlovich Aleksandrov, who stayed on Mir to the end of the expedition in December.\n\nHe was awarded the titles of Hero of the Soviet Union and Pilot-Cosmonaut of the USSR, Order of Lenin and the Russian Federation Medal \"For Merit in Space Exploration\".\n"}
{"id": "230428", "url": "https://en.wikipedia.org/wiki?curid=230428", "title": "Angular resolution", "text": "Angular resolution\n\nAngular resolution or spatial resolution describes the ability of any image-forming device such as an optical or radio telescope, a microscope, a camera, or an eye, to distinguish small details of an object, thereby making it a major determinant of image resolution. In physics and geosciences, the term \"spatial resolution\" refers to the precision of a measurement with respect to space.\n\n\"Resolving power\" is the ability of an imaging device to separate (i.e., to see as distinct) points of an object that are located at a small angular distance or it is the power of an optical instrument to separate far away objects, that are close together, into individual images. The term \"resolution\" or \"minimum resolvable distance\" is the minimum distance between distinguishable objects in an image, although the term is loosely used by many users of microscopes and telescopes to describe resolving power. In scientific analysis, in general, the term \"resolution\" is used to describe the precision with which any instrument measures and records (in an image or spectrum) any variable in the specimen or sample under study.\n\nThe imaging system's resolution can be limited either by aberration or by diffraction causing blurring of the image. These two phenomena have different origins and are unrelated. Aberrations can be explained by geometrical optics and can in principle be solved by increasing the optical quality — and consequently the cost — of the system. On the other hand, diffraction comes from the wave nature of light and is determined by the finite aperture of the optical elements. The lens' circular aperture is analogous to a two-dimensional version of the single-slit experiment. Light passing through the lens interferes with itself creating a ring-shape diffraction pattern, known as the Airy pattern, if the wavefront of the transmitted light is taken to be spherical or plane over the exit aperture.\n\nThe interplay between diffraction and aberration can be characterised by the point spread function (PSF). The narrower the aperture of a lens the more likely the PSF is dominated by diffraction. In that case, the angular resolution of an optical system can be estimated (from the diameter of the aperture and the wavelength of the light) by the Rayleigh criterion defined by Lord Rayleigh: two point sources are regarded as just resolved when the principal diffraction maximum of one image coincides with the first minimum of the other. If the distance is greater, the two points are well resolved and if it is smaller, they are regarded as not resolved. Rayleigh defended this criteria on sources of equal strength.\n\nConsidering diffraction through a circular aperture, this translates into:\nwhere \"θ\" is the \"angular resolution\" (radians), \"λ\" is the wavelength of light, and \"D\" is the diameter of the lens' aperture. The factor 1.220 is derived from a calculation of the position of the first dark circular ring surrounding the central Airy disc of the diffraction pattern. This number is more precisely 1.21966989... (), the first zero of the order-one Bessel function of the first kind formula_2 divided by π.\n\nThe formal Rayleigh criterion is close to the empirical resolution limit found earlier by the English astronomer W. R. Dawes who tested human observers on close binary stars of equal brightness. The result, \"θ\" = 4.56/\"D\", with \"D\" in inches and \"θ\" in arcseconds is slightly narrower than calculated with the Rayleigh criterion: A calculation using Airy discs as point spread function shows that at Dawes' limit there is a 5% dip between the two maxima, whereas at Rayleigh's criterion there is a 26.3% dip. Modern image processing techniques including deconvolution of the point spread function allow resolution of binaries with even less angular separation.\n\nThe angular resolution may be converted into a \"spatial resolution\", Δ\"ℓ\", by multiplication of the angle (in radians) with the distance to the object. For a microscope, that distance is close to the focal length \"f\" of the objective. For this case, the Rayleigh criterion reads:\n\nThis is the size, in the imaging plane, of smallest object that the lens can resolve, and also the radius of the smallest spot to which a collimated beam of light can be focused. The size is proportional to wavelength, \"λ\", and thus, for example, blue light can be focused to a smaller spot than red light. If the lens is focusing a beam of light with a finite extent (e.g., a laser beam), the value of \"D\" corresponds to the diameter of the light beam, not the lens. Since the spatial resolution is inversely proportional to \"D\", this leads to the slightly surprising result that a wide beam of light may be focused to a smaller spot than a narrow one. This result is related to the Fourier properties of a lens.\n\nA similar result holds for a small sensor imaging a subject at infinity: The angular resolution can be converted to a spatial resolution on the sensor by using \"f\" as the distance to the image sensor; this relates the spatial resolution of the image to the f-number, #:\nSince this is the radius of the Airy disk, the resolution is better estimated by the diameter, formula_5\n\nPoint-like sources separated by an angle smaller than the angular resolution cannot be resolved. A single optical telescope may have an angular resolution less than one arcsecond, but astronomical seeing and other atmospheric effects make attaining this very hard.\n\nThe angular resolution \"R\" of a telescope can usually be approximated by\nwhere \"λ\" is the wavelength of the observed radiation, and \"D\" is the diameter of the telescope's objective. The Resulting \"R\" is in radians. For example, in the case of yellow light with a wavelength of 580 nm, for a resolution of 0.1 arc second, we need D=1.2 m. Sources larger than the angular resolution are called extended sources or diffuse sources, and smaller sources are called point sources.\n\nThis formula, for light with a wavelength of about 562 nm, is also called the Dawes' limit.\n\nThe highest angular resolutions can be achieved by arrays of telescopes called astronomical interferometers: These instruments can achieve angular resolutions of 0.001 arcsecond at optical wavelengths, and much higher resolutions at x-ray wavelengths. In order to perform aperture synthesis imaging, a large number of telescopes are required laid out in a 2-dimensional arrangement with a dimensional precision better than a fraction (0.25x) of the required image resolution.\n\nThe angular resolution \"R\" of an interferometer array can usually be approximated by\nwhere \"λ\" is the wavelength of the observed radiation, and \"B\" is the length of the maximum physical separation of the telescopes in the array, called the baseline. The resulting \"R\" is in radians. Sources larger than the angular resolution are called extended sources or diffuse sources, and smaller sources are called point sources.\n\nFor example, in order to form an image in yellow light with a wavelength of 580 nm, for a resolution of 1 milli-arcsecond, we need telescopes laid out in an array that is 120 m × 120 m with a dimensional precision better than 145 nm.\n\nThe resolution \"R\" (here measured as a distance, not to be confused with the angular resolution of a previous subsection) depends on the angular aperture formula_8:\n\nHere NA is the numerical aperture, formula_11 is half the included angle formula_8 of the lens, which depends on the diameter of the lens and its focal length, formula_13 is the refractive index of the medium between the lens and the specimen, and formula_14 is the wavelength of light illuminating or emanating from (in the case of fluorescence microscopy) the sample.\n\nIt follows that the NAs of both the objective and the condenser should be as high as possible for maximum resolution. In the case that both NAs are the same, the equation may be reduced to:\n\nThe practical limit for formula_11 is about 70°. In a dry objective or condenser, this gives a maximum NA of 0.95. In a high-resolution oil immersion lens, the maximum NA is typically 1.45, when using immersion oil with a refractive index of 1.52. Due to these limitations, the resolution limit of a light microscope using visible light is about 200 nm. Given that the shortest wavelength of visible light is violet (formula_14 ≈ 400 nm),\n\nwhich is near 200 nm.\n\nOil immersion objectives can have practical difficulties due to their shallow depth of field and extremely short working distance, which calls for the use of very thin (0.17 mm) cover slips, or, in an inverted microscope, thin glass-bottomed Petri dishes.\n\nHowever, resolution below this theoretical limit can be achieved using super-resolution microscopy. These include optical near-fields (Near-field scanning optical microscope) or a diffraction technique called 4Pi STED microscopy. Objects as small as 30 nm have been resolved with both techniques. In addition to this Photoactivated localization microscopy can resolve structures of that size, but is also able to give information in z-direction (3D).\n\nIn the case of laser beams, a Gaussian Optics analysis is more appropriate than the Rayleigh criterion, and may reveal a smaller diffraction-limited spot size than that indicated by the formula above.\n\n\n"}
{"id": "328602", "url": "https://en.wikipedia.org/wiki?curid=328602", "title": "Ansari X Prize", "text": "Ansari X Prize\n\nThe Ansari X Prize was a space competition in which the X Prize Foundation offered a US$10,000,000 prize for the first non-government organization to launch a reusable manned spacecraft into space twice within two weeks. It was modeled after early 20th-century aviation prizes, and aimed to spur development of low-cost spaceflight.\n\nCreated in May 1996 and initially called just the \"X Prize\", it was renamed the \"Ansari X Prize\" on May 6, 2004 following a multimillion-dollar donation from entrepreneurs Anousheh Ansari and Amir Ansari.\n\nThe prize was won on October 4, 2004, the 47th anniversary of the Sputnik 1 launch, by the Tier One project designed by Burt Rutan and financed by Microsoft co-founder Paul Allen, using the experimental spaceplane SpaceShipOne. $10 million was awarded to the winner, and more than $100 million was invested in new technologies in pursuit of the prize.\n\nSeveral other X Prizes have since been announced by the X Prize Foundation, promoting further development in space exploration and other technological fields.\n\nThe X Prize was inspired by the Orteig Prize—the 1919 prize worth 25,000 dollars offered by New York hotel owner Raymond Orteig that encouraged a number of intrepid aviators in the mid-1920s to fly across the Atlantic Ocean—which was ultimately won in 1927 by Charles Lindbergh in his aircraft \"Spirit of St. Louis\". In reading the book, \"The Spirit of St. Louis\" during 1994, Peter Diamandis realized that \"such a prize, updated and offered ... as a \"space\" prize, might be just what was needed to bring space travel to the general public, to jump-start a commercial space industry.\"\n\nDiamandis developed a fully formed idea for a \"suborbital space barnstorming prize\", and set an initial goal of finding backers to support a prize. He named it the X Prize, in part because \"X\" could serve as a variable for the name of the person who might later back the prize; any craft built to win the prize would be experimental, and a long line of experimental aircraft built for the US Air Force had been so designated, including the X-15 that was, in 1963, the first government-built craft to carry a human into space; and because \"Ten is the Roman numeral X\".\n\nThe X Prize was first publicly proposed by Diamandis in an address to the NSS International Space Development Conference in 1995. The competition goal was adopted from the SpaceCub project, demonstration of a private vehicle capable of flying a pilot to the edge of space, defined as 100 km altitude. This goal was selected to help encourage the space industry in the private sector, which is why the entries were not allowed to have any government funding. It aimed to demonstrate that spaceflight can be affordable and accessible to corporations and civilians, opening the door to commercial spaceflight and space tourism. It is also hoped that competition will breed innovation, introducing new low-cost methods of reaching Earth orbit, and ultimately pioneering low-cost space travel and unfettered human expansion into the solar system.\n\nNASA is developing a similar prize program called Centennial Challenges to generate innovative solutions to space technology problems.\n\nTwenty-six teams from around the world participated, ranging from volunteer hobbyists to large corporate-backed operations:\n\nSome sources mention two other companies:\nbut do not mention Whalen Aeronautics Inc.\n\nThe Tier One project made two successful competitive flights: X1 on September 29, 2004, piloted by Mike Melvill to 102.9 km; and X2 on October 4, 2004, piloted by Brian Binnie to 112 km. They thus won the prize, which was awarded on November 6, 2004. In press coverage, the winning team has been variously referred to as Mojave Aerospace Ventures, the corporation that funded the attempt; Tier One, the project name of Mojave's contest entry; and Scaled Composites, the manufacturer of the craft.\n\nAs of 2011, the trophy is on display in the Saint Louis Science Center in St. Louis, Missouri.\n\nAlthough only the Tier One team actually launched a spacecraft into suborbital space, several other teams have conducted low-altitude tests or announced future plans to launch into space:\n\n\nWith the Ansari X Prize, the X Prize Foundation (based in Santa Monica, CA) established a philanthropic model in which offering a prize for achieving a specific goal stimulates entrepreneurial investment that produces a tenfold or greater return on the prize purse and at least one hundredfold in follow-on investment and social benefit. The Foundation has developed into a non-profit prize institute that conceives, designs and manages public competitions for the benefit of humanity.\n\nThe funding for the US $10,000,000 prize was unconventional in being \"backed by an insurance policy to guarantee that the $10 million is in place on the day that the prize is won.\" Diamandis referred to this as a \"hole-in-one insurance policy\".\n\nThe success of the X Prize competition has spurred spin-offs that are set up in the same way. There have been two major spin-offs at this point, the first of which is the M Prize (short for Methuselah Mouse Prize), which is a prize set up by University of Cambridge biogerontologist Aubrey de Grey which will go to the scientific team that successfully extends the life or reverses the aging of mice, which would then eventually be available to humans. The second is the NASA Centennial Challenges, which consist of (among others) the Tether Challenge in which teams compete to develop superstrong tethers as a component to space elevators, and the Beam Power Challenge which encourages ideas for transmitting power wirelessly. An independent spin-off called the N-Prize was started by Cambridge Microbiologist Paul H. Dear in 2007, designed to foster research into low-cost orbital launchers.\n\nThe X Prize foundation itself is developing additional prizes: the Archon X Prize, to advance research in the field of genomics; the Automotive X Prize, an engineering competition to create a fuel efficient clean car; the Wirefly X Prize Cup, an annually held air & space exposition featuring space-related competitions and rocketry, and the Google Lunar X Prize, a competition for privately funded lunar exploration. Of several awards on offer, the largest—$20 million—will be awarded to the first privately funded team to produce a robot that lands on the Moon and travels 500m (1,640 ft) across its surface. \n\nThere is also a possible \"H-Prize\", focused on hydrogen vehicle research, although this goal has been addressed by H.R. 5143, an X-Prize-inspired bill passed by the United States House of Representatives, which was later folded into the Energy Independence and Security Act of 2007.\n\nAnsari X Prize:\n\nSimilar topics:\n\nRelated technical topics:\n\n\n"}
{"id": "28913444", "url": "https://en.wikipedia.org/wiki?curid=28913444", "title": "Apfel Glacier", "text": "Apfel Glacier\n\nApfel Glacier () is a glacier about wide and long, flowing west-northwest along the south flank of the Bunger Hills and terminating in Edisto Ice Tongue. It was mapped from air photos taken by U.S. Navy Operation Highjump, 1946–47, and named by the Advisory Committee on Antarctic Names for Earl T. Apfel, professor of geology at Syracuse University, who served as geologist with the U.S. Navy Operation Windmill parties, 1947–48, which established astronomical control stations along Queen Mary, Knox and Budd Coasts.\n\n"}
{"id": "331959", "url": "https://en.wikipedia.org/wiki?curid=331959", "title": "Apollo–Soyuz Test Project", "text": "Apollo–Soyuz Test Project\n\nThe Apollo–Soyuz Test Project (ASTP) (, \"Eksperimentalniy polyot Apollon-Soyuz\", lit. \"Experimental flight Apollo-Soyuz\", commonly referred to by the Soviets as \"Soyuz-Apollo\"), conducted in July 1975, was the first joint U.S.–Soviet space flight, as a symbol of the policy of détente that the two superpowers were pursuing at the time. It involved the docking of an Apollo Command/Service Module with the Soviet Soyuz 19. The unnumbered Apollo vehicle was a surplus from the terminated Apollo program and the last one to fly. This mission ceremoniously marked the end of the Space Race that had begun in 1957 with the Sputnik launch.\n\nThe mission included both joint and separate scientific experiments (including an engineered eclipse of the Sun by Apollo to allow Soyuz to take photographs of the solar corona), and provided useful engineering experience for future joint US–Russian space flights, such as the Shuttle–Mir Program and the International Space Station.\n\nASTP was the last manned US space mission until the first Space Shuttle flight in April 1981. It was also U.S. astronaut Donald \"Deke\" Slayton's only space flight. He was chosen as one of the original Mercury Seven astronauts in April 1959, but had been grounded until 1972 for medical reasons.\n\nThe purpose and catalyst of the Apollo–Soyuz Test Project was the policy of détente between the two Cold War superpowers, the United States and the Soviet Union. Prior to this mission, tensions remained high between the two world superpowers while the United States was engaged in the Vietnam War. Meanwhile, the Soviet press was highly critical of the Apollo space missions, printing \"the armed intrusion of the United States and Saigon puppets into Laos is a shameless trampling underfoot of international law\" over a photograph of the Apollo 14 launch in 1971. Although Soviet leader Nikita Khrushchev made the Soviet Union's policy of détente official in his 1956 doctrine of peaceful coexistence at the 20th Congress of the Communist Party of the Soviet Union, the two nations seemed to be in perpetual conflict.\n\nDue to tense relations, space cooperation between the United States and the Soviet Union was unlikely in the early 1970s. On June 7, 1971, the USSR had launched the first piloted orbital space station, Salyut 1. Meanwhile, the United States had launched the Apollo 14 mission several months prior, the third spacecraft to land humans on the moon. Each side gave the other little coverage whatsoever of their achievements.\n\nBoth sides had severe criticisms of the other side's engineering. Soviet spacecraft were designed with automation in mind; the Lunokhod 1 and Luna 16 were both unmanned probes, and each Soyuz spacecraft had been designed to minimize risk due to human error by having fewer manual controls with which human operators would have to contend during flight. By contrast, the Apollo spacecraft was designed to be operated by humans and required highly trained astronauts in order to operate. The Soviet Union criticised the Apollo spacecraft as being \"extremely complex and dangerous\".\n\nThe Americans also had their own concerns about Soviet spacecraft. Christopher C. Kraft, director of the Manned Spacecraft Center, criticized the design of the Soyuz: \"We in NASA rely on redundant components--if an instrument fails during flight, our crews switch to another in an attempt to continue the mission. Each Soyuz component, however, is designed for a specific function; if one fails, the cosmonauts land as soon as possible. The Apollo vehicle also relied on astronaut piloting to a much greater extent than did the Soyuz machine\". American and Soviet engineers already settled their differences for a possible docking of American and Soviet spacecraft in meetings between June and December 1971 in Houston and Moscow, including Bill Creasy's design of the Androgynous Peripheral Attach System between the two ships that would allow either to be active or passive during docking.\n\nWith the close of the Vietnam War, relations between the United States and the USSR began to improve, as did the prognosis for a potential cooperative space mission. The Apollo–Soyuz Test Project was made possible by the thaw in these relations, and the project itself endeavored to amplify and solidify the improving relations between the United States and the Soviet Union. According to Soviet leader Leonid Brezhnev, \"The Soviet and American spacemen will go up into outer space for the first major joint scientific experiment in the history of mankind. They know that from outer space our planet looks even more beautiful. It is big enough for us to live peacefully on it, but it is too small to be threatened by nuclear war\". Thus, both sides recognized ASTP as a political act of peace.\n\nIn October 1970, Soviet Academy of Sciences president Mstislav Keldysh responded to NASA Administrator Thomas O. Paine's letter proposing a cooperative space mission, and there was subsequently a meeting to discuss technical details. By January 12, U.S. President Richard Nixon's Foreign Policy Adviser Henry Kissinger enthusiastically espoused plans for the mission, and expressed these views to NASA administrator George M. Low: \"As long as you stick to space, do anything you want to do. You are free to commit--in fact, I want you to tell your counterparts in Moscow that the President has sent you on this mission.\" By April 1972, both the United States and the USSR signed an Agreement Concerning Cooperation in the Exploration and Use of Outer Space for Peaceful Purposes, committing both the USSR and the United States to the launch of the Apollo–Soyuz Test Project in 1975.\n\nASTP was particularly significant for the USSR's policy of keeping the details of their space program secret from the Soviet people and the world at large, especially Americans. The ASTP was the first Soviet space mission to be televised in a live fashion during the launch, while in space, and during the landing. Soyuz 19 was also the first Soviet spacecraft to which a foreign flight crew had access before flight; the Apollo crew were permitted to inspect it and the launch and crew training site, which was an unprecedented sharing of information with Americans about any Soviet space program.\n\nNot all reactions to ASTP were positive. Many Americans feared that ASTP was giving the USSR too much credit in their space program, putting them on equal footing with the sophisticated space exploration efforts of NASA. More feared that the apparent peaceful cooperation between the USSR and the United States would lull people into believing there was no conflict at all between the two superpowers. Soliciting appropriations from the United States Congress proved to be quite difficult, which was not a problem in the Soviet Union, and the dedication to space exploration demonstrated by the Soviet Union rejected these criticisms. Some Soviet publicists called American critics of the mission \"demagogues who stand against scientific cooperation with the U.S.S.R.\" In general, tensions between the United States and the USSR had softened, and the project set a precedent for future cooperative projects in space.\n\nJack Swigert had originally been assigned as the command module pilot for the ASTP prime crew, but prior to the official announcement he was removed as punishment for his involvement in the Apollo 15 postage stamp incident.\n\n\n\nThe ASTP entailed the docking of an American Apollo Command/Service Module (CSM) with a Soviet Soyuz 7K-TM spacecraft. Although the Soyuz was given a mission designation number (Soyuz 19) as part of the ongoing Soyuz program, its radio call sign was simply \"Soyuz\" for the duration of the joint mission. The Apollo mission was not a numbered mission of the Apollo program, and similarly bore the call sign \"Apollo\". Despite this, some of the press and a few NASA web pages have referred to the mission as \"Apollo 18\", but this should not be confused with the canceled lunar mission.\n\nThe Apollo spacecraft was launched with a docking module specially designed to enable the two spacecraft to dock with each other, used only once for this mission. The Saturn IB launch vehicle and CSM were surplus material. Like the Apollo Lunar Module, the docking module had to be retrieved from the S-IVB upper-stage of the Saturn rocket after launch. The docking module was designed as both an airlock — as the Apollo was pressurized at about using pure oxygen, while the Soyuz used a nitrogen/oxygen atmosphere at sea level pressure (about 15 psi / 1000 mbar) — and an adapter, since the surplus Apollo hardware used for the ASTP mission was not equipped with the APAS docking collar jointly developed by NASA and the Soviet Academy of Sciences for the mission. One end of the docking module was attached to the Apollo using the same \"probe-and-drogue\" docking mechanism used on the Lunar Module and the Skylab space station, while its other end had the APAS docking collar, which Soyuz 19 carried in place of the standard Soyuz/Salyut system of the time. The APAS collar fitted onto Soyuz 19 was releasable, allowing the two spacecraft to separate in case of malfunction.\n\nThe Apollo flew with a three-man crew on board: Tom Stafford, Vance Brand, and Deke Slayton. Stafford had already flown into space three times, including within eight miles of the lunar surface as Commander of Apollo 10, and was the first general officer to fly into space. Slayton was one of the original Mercury Seven astronauts selected in 1959, but an irregular heartbeat grounded him until 1972. He became head of NASA's astronaut office and, after a lengthy medical program, selected himself for this mission. At the time, Slayton was the oldest person to fly in space and the one with the longest gap between selection as an astronaut and first flight into space. Brand, meanwhile, had trained with the Apollo spacecraft during his time as a backup Apollo 15 command module pilot, and had served two stints as a backup Skylab commander. The closest he had come to flying prior to ASTP was as commander for the Skylab Rescue mission mustered to potentially retrieve the crew of Skylab 3 due to a fuel leak on that mission's Apollo CSM.\n\nThe Soyuz flew with two men: Alexey Leonov and Valeri Kubasov. Leonov became the first man to walk in space on Voskhod 2 in 1965. Kubasov, who flew on Soyuz 6 in 1969, ran some of the earliest space manufacturing experiments. Both were to have flown on the ill-fated Soyuz 11 in 1971 (Leonov as commander, Kubasov as the flight engineer), but were grounded because Kubasov was suspected to have tuberculosis. The two-man crew on the Soyuz was a result of the modifications needed to allow the cosmonauts to wear the Sokol pressure suit during launch, docking, and reentry.\n\nThe ASTP-class Soyuz 7K-TM spacecraft used was a variation of the post-Soyuz 11 two-man design, with the batteries replaced by solar panels enabling \"solo\" flights (missions not docking to one of the Salyut space stations). It was designed to operate, during the docking phase, at a reduced nitrogen/oxygen pressure of 10.2 psi, allowing easier transfers between the Apollo and Soyuz. Six ASTP-class Soyuz spacecraft were built in total, including the one used. Before the actual mission, two craft were launched unmanned as Kosmos satellites. The third was launched as the manned Soyuz 16 flight as a rehearsal in order to test the APAS docking mechanism. Another craft was used fully fueled as a \"hot backup\" at the launch site – later it was disassembled. And the sixth craft was available as a \"cold\" backup; it was later used on the last \"solo\" Soyuz flight in 1976, but with the APAS docking adapter replaced by the MKF-6 multispectral camera.\n\nThe Soyuz and Apollo flights launched within seven-and-a-half hours of each other on July 15, and docked on July 17. Three hours later, the two mission commanders, Stafford and Leonov, exchanged the first international handshake in space through the open hatch of the Soyuz. NASA had calculated that the historic handshake would have taken place over the British seaside resort of Bognor Regis, but a delay resulted in its occurrence being over the city of Metz in France. During the first crew exchange, the crews were read a statement from Soviet Premier Leonid Brezhnev, and received a phone call from U.S. President Gerald Ford.\n\nWhile the two ships were docked, the three Americans and two Soviets conducted joint scientific experiments, exchanged flags and gifts (including tree seeds which were later planted in the two countries), signed certificates, visited each other's ships, ate together, and conversed in each other's languages. (Because of Stafford's pronounced drawl when speaking Russian, Leonov later joked that there were three languages spoken on the mission: Russian, English, and \"Oklahomski.\") There were also docking and redocking maneuvers, during which the two spacecraft reversed roles and the Soyuz became the \"active\" ship.\n\nAmerican scientists developed four of the experiments performed during the mission. Embryologist Jane Oppenheimer analyzed the effects of weightlessness on fish eggs at various stages of development.\n\nAfter 44 hours together, the two ships separated, and maneuvered to use the Apollo to create an artificial solar eclipse to allow the crew of the Soyuz to take photographs of the solar corona. Another brief docking was made before the ships went their separate ways. The Soviets remained in space for two more days, and the Americans for five, during which the Apollo crew also conducted Earth observation experiments.\n\nThe mission was considered a great success, both technically and as a public-relations exercise for both nations. The only serious problem was during reentry and splashdown of the Apollo craft, during which the crew were accidentally exposed to toxic hydrazine and nitrogen tetroxide fumes, caused by unignited reaction control system (RCS) hypergolic propellants venting from the spacecraft and reentering a cabin air intake. The RCS was inadvertently left on during descent, and the toxic fumes were sucked into the spacecraft as it drew in outside air. Brand briefly lost consciousness, while Stafford retrieved emergency oxygen masks, put one on Brand, and gave one to Slayton. The three astronauts were hospitalized for two weeks in Honolulu. Brand took responsibility for the mishap; because of high noise levels in the cabin during reentry, he believes he was unable to hear Stafford call off one item of the reentry checklist, the closure of two switches which would have automatically shut off the RCS and initiated drogue parachute deployment. These procedures were manually performed later than usual, allowing the ingestion of the propellant fumes through the ventilation system.\n\nThe ASTP was the final flight of an Apollo spacecraft. Immediately after the launch of the Apollo spacecraft, preparations began to convert Launch Pad 39B and the Vehicle Assembly Building at Kennedy Space Center for use by the Space Shuttle, the United States' next manned spacecraft program. Launch Pad 39A had already been closed after the launch of Skylab.\n\nA derivative (but mechanically incompatible) docking collar, APAS-89 was launched as part of the Kristall module of the Soviet Mir space station. Originally intended as the docking port for the (defunct) Buran Soviet space shuttle, the APAS-89 unit was used for the next Russian-American docking mission, STS-71, twenty years later as part of the Shuttle–Mir Program (though not before the docking port was tested by the last APAS-equipped Soyuz, TM-16, in 1993).\n\nThe American Space Shuttle continued to use the same APAS-89 docking hardware through the end of the Space Shuttle program to dock to Mir and then the International Space Station, the latter through the Pressurized Mating Adapters (PMAs).\n\nThe PMAs are equipped with the later APAS-95 adapters, which differ from the APAS-89 adapters in that they are no longer androgynous; while compatible with the APAS-89 docking collars, they are not capable of acting as the \"active\" partner in docking.\n\nThe first PMA, PMA-1, remains in use as the interface connecting the Russian-built, NASA-owned Zarya module to the US segment of the ISS, and so the APAS continues in use to this day.\n\nThe Apollo–Soyuz Test Project was the first joint US-Soviet space mission. At the time it was thought that space would become either more international or competitive as a result, however instead it became both. The mission became symbolic of each countries goals of scientific cooperation, while their individual news reports downplayed the technical prowess of the other. Soviet press implied that it was leading the US in space flight, tying it to Marxist ideology, while the US reported that the Soyuz was technically primitive. High-profile space cooperation declined after the successful mission and became entangled in linkage politics, however it set a precedent of cooperation that continued in the Shuttle–Mir Program.\n\nThe US and Soviet commanders, Stafford and Leonov became lasting friends. Leonov is the godfather of Stafford's younger children.\n\nA minor planet, 2228 Soyuz-Apollo, discovered in 1977 by Soviet astronomer Nikolai Stepanovich Chernykh, is named after the mission.\n\nThe Apollo Command Module from the mission is on display at the California Science Center in Los Angeles. The descent module of Soyuz 19 is on display at the RKK Energiya museum in Korolyov, Moscow Oblast, Russia.\n\nA display at the National Air and Space Museum in Washington, D.C. shows the docked Apollo/Soyuz configuration with the restored Apollo Command and Service Module used for testing prior to the mission, the back-up Docking Module, and a model of the Soyuz spacecraft. An identical Soyuz model is exhibited at the Kennedy Space Center Visitor Complex. A full-size mockup of the two docked spacecraft is located at the Cosmosphere in Hutchinson, Kansas.\n\nThe US Postal Service issued the Apollo–Soyuz commemorative stamps, honoring the United States–Soviet link up in space, on July 15, 1975, the day of the launch.\nThe remaining crew's most recent reunion was on July 16, 2010, when Leonov, Kubasov, Stafford, and Brand met at an Omega timepiece store in New York City. All except Leonov participated in a public roundtable that evening. Omega had produced several watches to be used on the mission.\n\nIn the wake of the mission, a large Apollo–Soyuz monument was constructed outside TsUP (the Soviet, later Russian space control center) in Moscow. It consisted of a metal Earth overarched by an arc terminating in a scale model of the joined Apollo–Soyuz spacecraft. It was damaged when a vehicle collided with it in the late 1990s, and was removed for repairs.\n\nThe mission control room that hosted the Americans in Korolyov, Russia was preserved in memorial of Apollo-Soyuz.\n\nThe United States spent $245 million on Apollo–Soyuz, or $1 billion in 2010 inflation-adjusted dollars.\n\n\n"}
{"id": "12469074", "url": "https://en.wikipedia.org/wiki?curid=12469074", "title": "Association of Los Alamos Scientists", "text": "Association of Los Alamos Scientists\n\nThe Association of Los Alamos Scientists (ALAS) was founded on 30 August 1945, by a group of scientists, who had worked on the development of the atomic bomb at the Los Alamos Laboratory, a division of the Manhattan Project. \n\nThe purpose of the organization was \"to promote the attainment and use of scientific and technological advances in the best interests of humanity\", according to the manifesto, available in the archives of the University of Chicago.\n\nThe scientists believed that they, \"by virtue of their special knowledge, have, in certain spheres, special political and social responsibilities beyond their obligations as individual citizens\". The association sought to carry out these responsibilities by keeping its members informed, \"and by providing a forum through which their views can be publicly and authoritatively expressed\".\n\nThe ALAS concentrated its activities principally in promoting international control of nuclear power and directing it to peaceful uses. Its members also attempted to promote responsible uses of science, and the freedom and integrity of scientists and scientific research. \n\nThe group sponsored public education on the nature and control of atomic energy through lectures, films, and exhibits, and the distribution of literature. It also attempted to influence public policy by means of informed statements to the press and correspondence with high government officials and congressmen.\n\n"}
{"id": "6448233", "url": "https://en.wikipedia.org/wiki?curid=6448233", "title": "Canes II Group", "text": "Canes II Group\n\nThe Canes II Group or Canes Venatici II Group (CVn II Group) is a group of galaxies about 26.1 million light-years away from Earth. The group resides in the Local Supercluster. The largest galaxy within the cluster is M106 (NGC 4258), which is a barred spiral galaxy.\n\nCanes II is directly behind Canes I, which makes it difficult to show which galaxy belongs in which cluster. It is generally accepted that the following galaxies belong in Canes II;\n"}
{"id": "23395169", "url": "https://en.wikipedia.org/wiki?curid=23395169", "title": "Canopy seed bank", "text": "Canopy seed bank\n\nA canopy seed bank or aerial seed bank is the aggregate of viable seed stored by a plant in its canopy. Canopy seed banks occur in plants that postpone seed release for some reason.\n\nIt is often associated with serotiny, the tendency of some plants to store seed in a cone (e.g. in the genus \"Pinus\") or woody fruits (e.g. in the genus \"Banksia\"), until seed release is triggered by the passage of a wildfire.\n\nIt also occurs in plants that colonise areas of shifting sands such as sand dunes. In such cases, the seed is held in the canopy even if the canopy becomes buried; thus the seed is anchored in place until good germination conditions occur.\n"}
{"id": "11131397", "url": "https://en.wikipedia.org/wiki?curid=11131397", "title": "Cascading discontinuity set", "text": "Cascading discontinuity set\n\nA cascading discontinuity set is a term related to Wild Cards and applied in foresight and risk management areas. It attempts to define a series of smaller, seemingly disconnected events that merge over time leading to a Wild Card-like result.\n\n"}
{"id": "46884197", "url": "https://en.wikipedia.org/wiki?curid=46884197", "title": "Chaotic rotation", "text": "Chaotic rotation\n\nChaotic rotation involves the irregular and unpredictable rotation of an astronomical body. Unlike Earth's rotation, a chaotic rotation may not have a fixed axis or period. Because of the conservation of angular momentum, chaotic rotation is not seen in objects that are spherically symmetric or well isolated from gravitational interaction, but is the result of the interactions within a system of orbiting bodies, similar to those associated with orbital resonance.\n\nExamples of chaotic rotation include Hyperion, a moon of Saturn, which rotates so unpredictably that the Cassini probe could not be reliably scheduled to pass by unexplored regions, and Pluto's Nix, Hydra, and possibly Styx and Kerberos, and also Neptune's Nereid. According to Mark R. Showalter, author of a recent study, \"Nix can flip its entire pole. It could actually be possible to spend a day on Nix in which the sun rises in the east and sets in the north. It is almost random-looking in the way it rotates.\" Another example is that of galaxies; from careful observation by the Keck and Hubble telescopes of hundreds of galaxies, a trend was discovered that suggests galaxies such as our own Milky Way used to have a very chaotic rotation, with planetary bodies and stars rotating randomly. New evidence suggests that our galaxy and other have settled into an orderly, disk-like rotation over the past 8 billion years and that other galaxies are slowly following suit over time.\n"}
{"id": "908081", "url": "https://en.wikipedia.org/wiki?curid=908081", "title": "Coherent information", "text": "Coherent information\n\nCoherent information is an entropy measure used in quantum information theory. It is a property of a quantum state ρ and a quantum channel formula_1; intuitively, it attempts to describe how much of the quantum information in the state will remain after the state goes through the channel. In this sense, it is intuitively similar to the mutual information of classical information theory. The coherent information is written formula_2.\n\nThe coherent information is defined as formula_3 where formula_4 is the von Neumann entropy of the output and formula_5 is the entropy exchange between the state and the channel.\n\nThe coherent information was introduced by Benjamin Schumacher and Michael A. Nielsen in a 1996 paper \"Quantum data processing and error correction\", which appeared in Physical Review A.\n\n"}
{"id": "23443825", "url": "https://en.wikipedia.org/wiki?curid=23443825", "title": "Council for Scientific and Industrial Research", "text": "Council for Scientific and Industrial Research\n\nThe Council for Scientific and Industrial Research (CSIR) is South Africa's central and premier scientific research and development organisation. It was established by an act of parliament in 1945 and is situated on its own campus in the city of Pretoria. It is the largest research and development (R&D) organisation in Africa and accounts for about 10% of the entire African R&D budget. It has a staff of approximately 3,000 technical and scientific researchers, often working in multi-disciplinary teams.\n\nThe CSIR contract R&D portfolio aims to enable clear understanding of national imperatives and the needs of industry to optimise the impact of the CSIR's R&D outputs. It leverages public, private and international partnerships in support of cutting-edge science, engineering and technology (SET).The organisation has clients in both the private sector (micro, small, medium and large enterprises; formal and informal), as well as in the public sector (national, provincial and local government). The organisation also deals with public enterprises and institutions, national safety and security establishments, and development structures. Regionally and abroad, the CSIR fosters partnerships and a network of clients and partner organisations as part of a global sphere of influence on matters of technology. The CSIR liaises closely with tertiary education institutions. With a strong emphasis on relevant and developmental work, it also has strong roots in various communities, and collaborates with a wide range of donors and funding agencies.The CSIR aims to contribute to the national programme of development, perform relevant knowledge generating research and transferring technology and skilled human capital, and strengthen the science and technology base. The Frascati Manual defines R&D as creative work undertaken systematically to increase the stock of knowledge, including knowledge of humanity, culture and society, and the use of this knowledge to devise new applications. At the CSIR, the research, development and innovation (RDI) chain encompasses, what we term, types A, B and C research: \nThe CSIR operates with two kinds of R&D income, each with its own purpose. The Parliamentary Grant is used for strengthening the CSIR’s S&T base - knowledge, people and infrastructure. Secondly, Contract R&D income is derived from performing contract research for clients in the public and private sectors, locally and abroad, on specific programmes, initiatives and projects. All R&D work contributes to the National System of Innovation (NSI).\n\n• Built Environment\n\n• Biosciences\n\n• Defence, Peace, Safety and Security\n\n• Information and Communications\n\n• Laser Technology\n\n• Materials Science and Manufacturing\n\n• Natural Resources and the Environment\n\n• Mining Innovation\n\n• Modelling and Digital Science\n\n• Mobile Intelligence Autonomous Systems\n\n• Nanotechnology\n\n• Synthetic Biology\n\n• Remote Sensing\n\nIn 1999 a strategic alliance was formed between the University of Pretoria and the Council for Scientific and Industrial Research. This alliance, which is known as the Southern Education and Research Alliance (SERA), collaborates locally and internationally with universities, NGO’s, companies and multinational bodies in various research areas.\n\n\nIn July 2016 the amaBhungane Centre for Investigative Journalism published an article that alleges that South Africa's Science and Technology Minister Naledi Pandor and Director-General Phil Mjwara were attempting to put undue pressure the CSIR, at the behest of ANC treasurer-general Zweli Mkhize, to favour the Chinese multinational Huawei Technologies in the purchase of a new R116-million (equivalent to around US$8 million) super computer for the institute. This followed the publication of the Council's long time CEO, Sibusiso Sibisi's, open letter of resignation stating that irregularities and political pressure on the awarding of contracts to suppliers was of great concern.\n\nIn a well-known case of biopiracy, bioprospectors from South Africa’s Council for Scientific and Industrial Research realized that Hoodia was marketable (after a marketing campaign falsely claiming that it was an appetite suppressant for weight loss) and patented its use as an appetite suppressant without recognizing the San people's traditional claims to the knowledge of the plant and its uses. The patent was later sold to Unilever, which marketed hoodia products as diet supplements. In 2003, the South African San Council made an agreement with CSIR in which they would receive from 6 to 8% of the revenue from the sale of \"Ho. gordonii\" products, money which would be deposited in a fund to purchase land for the San people who had been dispossessed from their lands by white settlers.\n\n"}
{"id": "4129530", "url": "https://en.wikipedia.org/wiki?curid=4129530", "title": "Dasymeter", "text": "Dasymeter\n\nA dasymeter was meant initially as a device to demonstrate the buoyant effect of gases like air; as shown in the adjacent pictures. A dasymeter which allows weighing acts as a densimeter used to measure the density of gases.\n\nThe Principle of Archimedes permits to derive a formula which does not rely on any information of volume:\nA sample, the big sphere in the adjacent images, of known mass-density is weighed in vacuum and then immersed into the gas and weighed again. \nFrom the known mass density of the sample (sphere) and its two weight-values can be calculated the mass-density of the gas:\n\nIt consists of a thin sphere made of glass, ideally with an average density close to that of the gas to be investigated. This sphere is immersed in the gas and weighed.\n\nThe dasymeter was invented in 1650 by Otto von Guericke. Archimedes used a pair of scales which he immersed into water to demonstrate the buoyant effect of water. A dasymeter can be seen as a variant of that pair of scales, only immersed into gas.\n\n"}
{"id": "43816664", "url": "https://en.wikipedia.org/wiki?curid=43816664", "title": "Doug Allan", "text": "Doug Allan\n\nDouglas \"Doug\" Allan, FRSGS, (born 1951) is a Scottish wildlife cameraman and photographer best known for his work in polar regions and underwater.\n\nAllan is one of twin brothers born in Dunfermline in Scotland, the son of a photographer and photojournalist who ran his own photography shop in the town. As a child Allan became a keen snorkeller and underwater diver, which inspired him to study marine biology at the University of Stirling. His first job was as a pearl diver with Bill Abernathy, the last pearl hunter in Scotland. Allan then worked for eight years for the British Antarctic Survey in Antarctica as a research diver, scientist and photographer.\n\nBecoming a full time cinematographer in 1985, Allan has been a principal cameraman on many BBC wildlife programmes, particularly concerning extreme environments, including Life in the Freezer, Wildlife Special: Polar Bear, The Blue Planet, Planet Earth, and Frozen Planet.\n\nAllan has won eight Emmys including \"Outstanding Cinematography for Nonfiction Programming in 2002, for Blue Planet, and in 2007, for Planet Earth. He has won four BAFTAs and in 2017 he won an outstanding contribution award at the British Academy Scotland Awards. He frequently gives illustrated lectures and talks, including at the 2016 Cambridge University Expedition Society annual dinner.\n"}
{"id": "24085833", "url": "https://en.wikipedia.org/wiki?curid=24085833", "title": "Dude, What Would Happen", "text": "Dude, What Would Happen\n\nDude, What Would Happen is an American live-action reality series that aired on Cartoon Network originally as part of its CN Real block which aired a line of live-action reality shows promoted in the summer season of 2009. The show premiered on August 19, 2009, preceded by another CN Real series \"Bobb'e Says\". The show is hosted by three male teenagers (C.J. Manigo, Jackson Rogow, and Ali Sepasyar) who wondered what would happen if some wild event, scheme or experiment were to occur. The three teens attempt to create the event themselves and consult experts (\"The Lab Dudes\") when needed.\n\nThe series went on to have four seasons aired throughout a span of two years, in which the series eventually ended in September 2011, as the series was not announced for a renewal by Cartoon Network.\n\n\"Dude, What Would Happen\" was one of only two CN Real shows (the other being \"Destroy Build Destroy\") to have been renewed for additional seasons, as the other CN Real shows had already been cancelled earlier most likely due to low ratings.\n\nIn the \"Dudes Make It Happen\" weekend special, it was revealed that new episodes were coming. These episodes ranked #1 in their timeslot among boys 6-11 on all television.\n\nThe show was listed as returning for Cartoon Network's 2010–2011 season. The next season began airing on October 6, 2010.\n\nIn February 2011, Vincent Cariati renewed his contract to serve an additional four seasons as the series' showrunner, co-creator and co-executive producer. The show had four seasons aired, but was not announced as a returning series, automatically cancelling the series altogether.\n\n\n\n"}
{"id": "2416419", "url": "https://en.wikipedia.org/wiki?curid=2416419", "title": "ESO 510-G13", "text": "ESO 510-G13\n\nESO 510-G13 is a spiral galaxy approximately 150 million light-years away in the constellation Hydra. The equatorial dust cloud is heavily warped; this may indicate that ESO 510-G13 has interacted with another galaxy. If this is the case, it would provide an excellent illustration of the distortion caused by interacting galaxies, discussed in the article Galaxy formation and evolution under the \"Spiral galaxy\" heading.\n\nThis galaxy was examined by the Hubble Space Telescope in 2001.\n\n\n"}
{"id": "45004055", "url": "https://en.wikipedia.org/wiki?curid=45004055", "title": "Empirical valence bond", "text": "Empirical valence bond\n\nThe Empirical Valence Bond (EVB) approach (Warshel and Weiss 1980, 1981) is an approximation developed by Arieh Warshel to determine reaction free energies of enzymatic reactions by making the assumption that Rudy Marcus precise electron transfer theory of metals can be applied to electron transfers responsible for chemical catalysis in solution via a calibrated Hamiltonian.\n\n\n\n"}
{"id": "1036932", "url": "https://en.wikipedia.org/wiki?curid=1036932", "title": "Faculty of 1000", "text": "Faculty of 1000\n\nFaculty of 1000 (abbreviated F1000) is a publisher of services for life scientists and clinical researchers.\n\nF1000Prime publishes recommendations of articles in biology and medicine from a \"faculty\" of around 6,000 scientists and clinical researchers and 5,000 more junior \"associate\" faculty. The service covers 32 disciplines and around 3,700 journals. It previously existed as two sister sites, \"F1000 Biology\", launched in 2002, and \"F1000 Medicine\", launched in 2006. In 2010, these services were combined as \"F1000.com\". The service obtained its current name in 2012. When Faculty Members recommend an article for F1000Prime, they rate it as 'Good'. F1000Prime uses the individual scores to calculate the total scores for each article, which are used to rank the articles in each discipline. The F1000Prime score is an article-level metric, or altmetric, and is a potential indicator of the scientific impact of individual papers.\n\nF1000Research is an open access, open peer-review scientific publishing platform covering the life sciences. Articles are published first and peer reviewed after publication by invited referees. The peer reviewer's names and comments are visible on the site. As part of its open science model, the data behind each article are also published and are downloadable. \"F1000Research\" publishes multiple article types including traditional research articles, single findings, case reports, protocols, replications and null or negative results. The journal has been criticized for unclear peer-review standards in relation to its inclusion in PubMed, but has since clarified how articles are indexed in the PubMed and PubMed Central databases. F1000Research also publishes posters and slide presentations in biology and medicine.\nIn October 2014, F1000Research's Managing Director Rebecca Lawrence took part in a Reddit Science AMA (Ask Me Anything) as part of Open Access Week, to answer questions about the F1000Research publication format and about open science in general.\n\nF1000Workspace is a suite of tools to help scientists with writing, collaborating, reference management and preparation for publishing scientific papers. The service was launched in May 2015. It includes a Word plug-in, from which you're able to directly search PubMed, as well as save references or articles with just one click. F1000Workspace also allows you to directly annotate articles online, as well as share these notes - and whole projects - with co-authors.\n\nF1000 Specialists – An affiliate program aimed at experienced users and advocates of F1000 services. F1000 Specialists receive in-kind rewards from F1000 in exchange for being a local representative and contact for one or more F1000 services at their organization.\n\nFaculty of 1000 was founded in 2000 by publishing entrepreneur Vitek Tracz, a scientific publishing pioneer and founder of the BioMed Central and Current Opinions journals. The company is part of the Science Navigation Group, which also owns Web of Stories.\n\nIn March 2015, Tracz was featured in an article in Library Journal, titled \"F1000’s Vitek Tracz: Redefining Scientific Communication\", discussing the problems with peer review and why he thinks it is \"mortally sick\".\n\nTracz also published an editorial piece in \"F1000Research\" in May 2015 about the \"five deadly sins of science publishing\", detailing the problems with the process of preparing and publishing research findings, and judging their veracity and significance. He explains how F1000 is starting to tackle these ‘deadly sins’.\n\nIn July 2017, F1000 launched Open Research Central, a \"central portal for open research publishing\". The model has been running on F1000Research since 2013 and current partners include Wellcome Trust's Wellcome Open Research, Gates Foundation's Gates Open Research, University College London's, UCL Child Health Open Research with more to come in the future. The MNI Open Research platform was launched in August 2017.\n\n"}
{"id": "10050972", "url": "https://en.wikipedia.org/wiki?curid=10050972", "title": "Ginsberg's theorem", "text": "Ginsberg's theorem\n\nGinsberg's theorem is a parody of the laws of thermodynamics in terms of a person playing a game. The quote was first attributed to the poet Allen Ginsberg in a 1975 issue of the \"Coevolution Quarterly\"\n\nIt is possible that the quote originates as a slight misstatement of the opening lines of \"You Can't Win,\" by Charlie Smalls, as the copyright date for Small's song is 1974, earlier than the first attribution to Ginsberg. While the song was cut from 1975 Broadway debut of the Wiz, it was performed at the original, 1974, Baltimore run of the musical.\n\nThe \"theorem\" is given as a restatement of the consequences of the zeroth, first, second, and third laws of thermodynamics, with regard to the usable energy of a closed system:\n\n0. There is a game (consequence of zeroth law of thermodynamics)<br>\n1. You can't win. (consequence of first law of thermodynamics)<br>\n2. You can't break even. (consequence of second law of thermodynamics)<br>\n3. You can't even get out of the game. (consequence of third law of thermodynamics)<br>\n\nIt is sometimes stated as a general adage without specific reference to the laws of thermodynamics.\n"}
{"id": "41975063", "url": "https://en.wikipedia.org/wiki?curid=41975063", "title": "Gravitational instability", "text": "Gravitational instability\n\nThe key idea in explaining the way in which structures evolve in the universe is gravitational instability. If material is to be brought together to form structures, then a long-range force is required, and gravity is the only known possibility. (Although electromagnetism is a long-range force, charge neutrality demands that its influence is unimportant on large scales.) The basic picture is as follows.\n\nSuppose that at some initial time, say decoupling, there are small irregularities in the distribution of matter. Those regions with more matter will exert a greater gravitational force on their neighboring regions, and hence tend to draw in the surrounding material. This extra material makes them even more dense than before, increasing their gravitational attraction and further enhancing their pull on their neighbors. An irregular distribution of matter is therefore unstable under the influence of gravity, becoming more and more irregular as time goes by.\n\nThis instability is exactly what is needed to explain the observation that the Universe is much more irregular now than at decoupling, and gravitational instability is almost universally accepted to be the primary influence leading to the formation of structures in the Universe. It is an appealingly simple picture, rather spoiled in real life by the fact that while gravity may have the lead role, numerous other processes also have a part to play and things become quite complicated. For example, we know that radiation has pressure proportional to its density, and during structure formation the irregularities create pressure gradients which lead to forces opposing the gravitational collapse. We know that neutrinos move relativistically and do not interact with other material, and so they are able to escape from structures as they form. And once structure formation begins, the complex astrophysics of stars, especially supernovae, can inject energy back into the intergalactic regions and influence regions yet to complete their gravitational collapse.\n"}
{"id": "36901201", "url": "https://en.wikipedia.org/wiki?curid=36901201", "title": "Heightened Senses", "text": "Heightened Senses\n\nHeightened Senses is an online story written by Sharat Chinnapa. It was started on May 6, 2012. It is a dystopian and borderline science fiction story set approximately 30 years into the future. The story is updated every Tuesday and Saturday.\n\nIn this alternate future, genetic experimentation has caused an infectious genetic mutation known as \"Gene-X\" to run rampant.\n\nA Gene-X mutation, caused by the virus \"Hithalmia Azitas\", is a highly infectious condition that causes the afflicted to react to a single certain \"trigger\".\nThe reaction to this trigger often results in a heightening of the senses of the afflicted - a condition known as a \"Heightening\".\nMost of the main characters in Heightened Senses are infected, and have Heightenings.\n\nGene-X went viral thirty years ago and the world went out of control. There were massacres of infected people and those who wanted to escape the infection built settlements called \"Stations\" that were completely cut off from the outside world.\nThe population of the world dropped drastically and people regressed to a life with very limited resources. Outside the Stations, people grouped together under powerful leaders in order to survive. And an organisation called the Country was formed. The origins of the Country are uncertain, but they are the primary organisation that battles the Stations in the vicinity of the story.\n\nThe plot begins in a city now called Haven. The old name of the city is forgotten. The primarily follows two characters, Lance and Reide. They are fighters for hire in the city of Haven, where they accept jobs for payment in cash or kind to keep themselves supplied. An informant, Terrai Hanswitch, approaches them with a case regarding a missing child - and they accept.\nThe case leads them to the doorstep of the one who is effectively rules the city, Shadow.\nShadow has, in fact, constructed this case to bring Lance and Reide to him - and make them an offer. A third party, Erin Iyelsviel - the Ace of Diamonds (see rankings in the Country) - joins their meeting, and things turn hostile. Eventually, Shadow makes his proposition, after Erin leaves. He wants the pair to infiltrate the Country and bring back information regarding research the Country is doing on multiple Heightenings. He reveals that this boy he has kidnapped, Jared - the one Lance and Reide are supposed to recover - is an example of a person with two Heightenings.\n\nLance and Reide decide to accept the offer - despite the danger involved in dealing with the Country. They return to their base of operations and are met by the Jack of Clubs, Jay, who identifies herself as a double agent who is reporting to Shadow from the Country. They leave with her to the Country's base and are welcomed into the House of Clubs. Inside, Reide is taken to meet the King of Clubs, Cloud - while Lance is dismissed to a room upstairs. Inside, he is met by the Queen of Clubs, Eleanor. Cloud offers to teach Reide to \"transcend\" on the condition that he joins the Country, and Reide accepts. Meanwhile Eleanor makes a similar proposition to Lance - she suggests that since they have very similar abilities, they might be able to learn each other's - proving that Heightenings are not as limited as they are believed to be, he accepts as well and they begin \"practice\" immediately.\n\nTerrai Hanswitch attempts to sneak into the Spire - Shadow's stronghold - and spy on a meeting between the top executives in Shadows organisation. She manages to get in, but is caught. However, Jared pleads for her life and Shadow decides not to kill her. Instead, both Jared and Terrai are sent on a mission to a Station identified as Station \"Aris\".\n\nThe next day, Lance is accosted by some members of the House of Clubs and is forced to defend himself. The fight is interrupted by Jay, the Jack, who declares that Lance be put in solitary confinement (for a week) for his actions. She escorts him out, and explains that this is a ruse to give him greater freedom of movement in the Country. His task is now to infiltrate the other Houses (of Spades, Diamonds, and Hearts) in turn and fulfill Shadow's assignment. Meanwhile, Reide begins his training with Cloud - and is kept apart from Lance. He believes his friend to be in solitary confinement.\n\nJay leaves Lance at the house of Spades where over a few days he befriends the Three of Spades, Flair, and steals one of her access cards. With these he is granted access to the computers and he finds information he believes Shadow might be interested in - and transfers it onto a drive that Jay gave him. He then leaves the House of Spades and goes to the House of Diamonds. \n\nSix days into his week of solitary confinement, Lance incapacitates the Four of Diamonds and takes his access card - attempting to use the same trick he used at Spades. But while attempting to steal data from the House of Diamonds, he sets of an alarm. Before he can escape, he is confronted again by Erin Iylesviel and captured - but during the battle, he catches a glimpse of Jay leaving the facility.\n\nWithin Station Aris, an order is given for people to be sent out of the Station to capture \"specimens\" from the outside to test the effectiveness of a drug that the Stations have developed to Counter Gene-X.\n\nIn the Country, a meeting of the royalty is called - and Cloud finds that Eleanor has disappeared. He takes Reide along instead. At the meeting, the possibility of the Stations mobilizing again is discussed. And at the end, Erin Iyelsviel announces that an intruder was caught in Diamonds - Lance. The punishment decided for him is death.\nMeanwhile, Eleanor breaks into the House of Diamonds and rescues Lance and they attempt to escape the facility.\n\nThe Country is an organisation formed approximately 30 years prior to the start of the story. Their primary objective is to combat the Stations - and prevent them from massacring people from the Outside as was done 30 years ago. The Country is divided into four Houses - the House of Spades, Hearts, Diamonds and Clubs. The Country is composed of \"members\" and \"card holders\" - the former are mostly soldiers or scientists.\n\nThe Country's equivalent of an \"officer\" is a card holder. They rank Two through Ace and increase in seniority and power from Two through Jack. The King and Queen seem to have an approximately equal relationship as decisions are taken by both parties. (Note: There is no indication that the King and Queen are married - it's just a rank) Very little is known, at this point, about the Aces. The Ace of Diamonds seems to be a somewhat autonomous entity but has never taken a decision that affected the entire House.\n\nCommonly, there are three distinct types of Heightenings, Transformative, Amplificatory, and Hypnotic. There is also mention of a fourth type, the Transcendental Heightening.\n\nAlso known as: The Ignitor\nAge: 19\nHeight: 172 cm\nTrigger: Proximity to fire.\nHeightening: (Hypnotic) The ability to transfer select thoughts with a person for as long as he is near the fire.\n\nBackground: Lance grew up in a small town many miles from the city of Haven. He was an only child. The town was closely knit - as such places are - but supplies are scarce. The only have what they can produce themselves. Lance (and Reide) both left to seek their futures elsewhere - three years before the start of the story. They still occasionally return and leave some of their profits behind.\n\nLance has a very high tolerance of pain. He sometimes practices his heightening on himself. However, despite his famous reputation as the demonic Ignitor, he only kills when he is forced to.\n\nLast name is currently unknown. \nAlso known as: The Viper\nAge: 23\nHeight: 180 cm\nTrigger: Repetition of a sequence of notes. (exact notes will be added)\nHeightening: (Amplificatory) Dramatically heightened brain assimilation. Results in faster judgement and reaction time. Average (heightened) reaction time: 0.06 seconds.\n\nBackground: Reide and Lance come from the same town, and have known each other almost all their lives. Reide is practical and situation oriented. It was his idea to leave the village and work for hire in Haven, in order to be less of a burden to the town that was his home. He proposed the idea to Lance, who agreed.\n\nAge: 22\nHeight: 167 cm\nTrigger: Skin contact with iron. (exact notes will be added)\nHeightening: (Amplificatory) The ability to repel attention. Implies that people are highly likely to not notice her presence.\n\nAge: 15\nHeight: 172 cm\nTrigger: Unknown\nHeightening: Unknown\nBackground: Very little is actually known about the one called Shadow. He rose to prominence in haven four years before the start of the story, when he was merely an eleven-year-old boy. He was quickly surrounded by strong people, who often acted on his behalf. Slowly, his power began to consolidate in the unnamed gang, that is known only as 'Shadow's folk'. He has a reputation for not being seen - or leaving dead those he has encountered, perhaps this is the reason for his name. The truth of his heightening and trigger is obscure, because most who have seen it are dead.\n\nAlso known as: The Ace of Diamonds \nAge: 22\nHeight: 167 cm\nTrigger: Unknown\nHeightening: It is likely to be the production of electricity in his body. \nBackground: Erin is a powerful member of the Country. In the organisation, he is something of a lone wolf, with his own agenda. He seems to have a good intelligence network, as he often comes to know of things quickly, but this network has never been discovered.\n\nAlso known as: The Jack of Clubs \nAge: 25\nHeight: 156 cm\nTrigger: Unknown\nHeightening: Unknown\nBackground: Jay is the Jack of Clubs - she plays the dangerous role of Shadow's contact in the Country and she cannot afford to be found out. She brings Lance and Reide to the Country as Shadow's agents - but there are other reasons too...\n\nAlso known as: The King of Clubs\nAge: 27\nHeight: 183 cm\nTrigger: Unknown\nHeightening: Telekinesis\nBackground: The awe inspiring and charismatic King of Clubs is the youngest of the four Kings. It is said that he has never even been touched in a battle. He joined the Country as a Jack - the first and only person to ever be made a senior member upon joining. When the previous King was killed in the raids by Stations eight years ago Cloud took his place not only by the old king's command, but along with a unanimous vote in his favour. All of the Clubs are fervently loyal and will do anything he says - except, perhaps, one person?\n\nAlso known as: The Queen of Clubs\nAge: 26\nHeight: 170 cm\nTrigger: Absence of sunlight\nHeightening: The ability to transfer thoughts from another person to herself. \nBackground: Eleanor was the Country's youngest member - both her parents were of the Country so she was born and raised within it. With both of them among the dead in the Station's raids eight years ago she was left alone and rose quickly up the ranks. While her ability is not an offensive one, she is able to use it to predict a person's movements making exceedingly difficult to match in combat.\n\nAge: 41\nHeight: 179 cm\nTrigger: none \nHeightening: none \nBackground: Ray Steele was eleven years old when he became part of Station Aris - just as the conflict was beginning. His father was a rich businessman who died when Steele was in his late twenties. That year, Steele joined the Aris defence force. He was a late entrant, but rose up the ranks quickly. In his early thirties he played a vital role in the most crippling strike the Stations ever made on the Country. Acclaimed for his strategic improvisations in that battle, eight years prior to today, he became a candidate for the post of the Captain of the Aris Defence Force. He finally rose to this position when he was 35 and has led the Force competently since then. He is also an excellent shot with a variety of weapons.\n\n"}
{"id": "49035974", "url": "https://en.wikipedia.org/wiki?curid=49035974", "title": "Idea Man", "text": "Idea Man\n\nIdea Man: A Memoir by the Cofounder of Microsoft (2011) is the \"New York Times\" bestselling memoir by Microsoft cofounder Paul Allen. Published in 2011 by Portfolio, a Penguin Group imprint, the book recounts how Allen became enamored with computers at an early age, conceived the idea for Microsoft, recruited his friend Bill Gates to join him, and launched what would become the world’s most successful software company.\n\nThe book, reveals the often conflicted partnership between Allen and Gates, and how — when Allen was recovering from cancer — Gates unsuccessfully conspired to dilute Allen’s 36 percent share of Microsoft. \"Idea Man\" also explores Allen's business and creative ventures following his 1983 departure from Microsoft, including his involvement in SpaceShipOne, his purchase of the Portland Trailblazers and Seattle Seahawks, his passion for music, and his ongoing support for scientific research.\n\nDescribed by critics as candid, profound and incendiary, \"Idea Man\" is a true story of ambition and ideas made real.\n\n\"The Guardian\": “There's an important lesson here that has subsequently been airbrushed out of the Microsoft legend: Allen's contributions to the partnership were as critical as Gates's. Without the tools that he developed, and his insight into the infrastructure that software development requires, Microsoft's subsequent growth would have been impossible.”\n\n\"Kirkus Reviews\": ...\"surprisingly profound and refreshingly frank.\"\n\n\"USA Today\": “…complete and candid…”\n\n\"The New York Times\": “The book reads well.”\n\n"}
{"id": "30839887", "url": "https://en.wikipedia.org/wiki?curid=30839887", "title": "Indium arsenide antimonide phosphide", "text": "Indium arsenide antimonide phosphide\n\nIndium arsenide antimonide phosphide () is a semiconductor material.\n\nInAsSbP has been widely used as blocking layers for semiconductor laser structures, as well as for the mid-infrared light-emitting diodes, photodetectors and thermophotovoltaic cells.\n\nInAsSbP layers can be grown by heteroepitaxy on indium arsenide, gallium antimonide and other materials. The vibrational properties of the alloy have been investigated by Raman spectroscopy.\n\n"}
{"id": "2450788", "url": "https://en.wikipedia.org/wiki?curid=2450788", "title": "Leiotrichi", "text": "Leiotrichi\n\nIn early anthropology, Leiotrichi described the races of people distinguished by their smooth hair. Races with hair that is not smooth were termed \"Ulotrichi\".\n"}
{"id": "5065043", "url": "https://en.wikipedia.org/wiki?curid=5065043", "title": "List of lakes in New Hampshire", "text": "List of lakes in New Hampshire\n\nThis is a list of lakes in the U.S. state of New Hampshire. The New Hampshire Department of Environmental Services lists 944 lakes and impoundments in their \"Official List of Public Waters\". The water bodies that are listed include natural lakes and reservoirs, including areas on rivers impounded behind dams. Wikipedia articles have been written about the following New Hampshire lakes:\n"}
{"id": "1569872", "url": "https://en.wikipedia.org/wiki?curid=1569872", "title": "List of sovereign states and dependencies by total fertility rate", "text": "List of sovereign states and dependencies by total fertility rate\n\nThis is a list of all sovereign states and dependencies by total fertility rate (TFR): the expected number of children born per woman in her child-bearing years.\n\nThe World Bank ranking list is based on the data for the year 2016 published online. The World Bank is a United Nations international financial institution, a component of the World Bank Group, and a member of the United Nations Development Group, but it also collects and analyses information on demography issues based on international and national sources: (1) United Nations Population Division. World Population Prospects, (2) United Nations Statistical Division. Population and Vital Statistics Report (various years), (3) Census reports and other statistical publications from national statistical offices, (4) Eurostat: Demographic Statistics, (5) Secretariat of the Pacific Community: Statistics and Demography Programme, and (6) U.S. Census Bureau: International Database.\n\nThe Population Reference Bureau (PRB) ranking list is based on the data of the \"2018 World Population Data Sheet\" published online.\nThe Population Reference Bureau (PRB) is a private, nonprofit organization which informs people around the world about population, health and the environment for research or academic purposes. It was founded in 1929. World Population Data Sheets are double-sided wallcharts (now published online) that present detailed information on demographic, health and environment indicators for more than 200 countries.\n\nThe CIA ranking list is sourced from the CIA World Factbook unless otherwise specified. Sovereign states and countries are ranked. Some countries might not be listed because they are not fully recognized as countries at the time of this census.\n\nThe Our World In Data (OWID) \"Country ranking and comparison by TFR: 1950 and 2015\" list is sourced and based on the OWID website (on the clickable map and quoted sources). Our World In Data (OWID) is an online publication that presents empirical research and data that show how living conditions around the world are changing. The aim is to show how the world is changing and why. The publication is developed at the University of Oxford and authored by social historian and development economist Max Roser.\n\nThe World Bank \"Country ranking and comparison by TFR: 1960 and 2015\" list is sourced and based on the online published demographic data of the World Bank web site (on the clickable map and quoted sources).\n\nThe Population Reference Bureau (PRB) \"Country ranking and comparison by TFR: 1970 and 2013\" list is sourced and based on the data of the \"2014 World Population Data Sheet\" published online.\n\nThe UN ranking list is sourced from the United Nations World Population Prospects. Figures are from the 2015 revision of the United Nations World Population Prospects report, for the period 2015-2020, using the medium assumption.\nOnly countries/territories with a population of 100,000 or more in 2015 are included. Rank is based on the 2015–2020 figure.\n\nNote:\n\n(-) Data unavailable, inapplicable, not collected or country or dependent territory not included. Sovereign states and dependent territories listed by alphabetical order, not ranked.\n\nNotes:\n\n(→) Country that changed name and flag, dependent territory that is now an independent country (sovereign state) from another current or extinct (dissolved) state or empire, former dependent territory from a sovereign state or empire that was included in another sovereign state.\n\n(-) Data unavailable, inapplicable, not collected or country or dependent territory not included. Sovereign states and dependent territories listed by alphabetical order, not ranked.\n\nNotes:\n\n(→) Country that changed name and flag, dependent territory that is now an independent country (sovereign state) from another current or extinct (dissolved) state or empire, former dependent territory from a sovereign state or empire that was included in another sovereign state.\n\n(-) Data unavailable, inapplicable, not collected or country or dependent territory not included. Sovereign states and dependent territories listed by alphabetical order, not ranked.\n\nNotes:\n\n(→) Country that changed name and flag, dependent territory that is now an independent country (sovereign state) from another current or extinct (dissolved) state or empire, former dependent territory from a sovereign state or empire that was included in another sovereign state.\n\n(-) Data unavailable, inapplicable, not collected or country or dependent territory not included. Sovereign states and dependent territories listed by alphabetical order, not ranked.\n\nNote:\n\n(-) Data unavailable, inapplicable, not collected or country or dependent territory not included. Sovereign states and dependent territories listed by alphabetical order, not ranked.\n\nCase studies:\n"}
{"id": "7120034", "url": "https://en.wikipedia.org/wiki?curid=7120034", "title": "List of volcanoes in India", "text": "List of volcanoes in India\n\nThis is a list of Quaternary active, dormant/extinct volcanoes in India.\n\n\nR, Bhutani, K. Pande, J.S. Ray, R.S. Smitha, N. Awasthi & A. Kumar, Paper No. 268-9, 2014 GSA Annual Meeting in Vancouver, British Columbia (19–22 October 2014)\n"}
{"id": "37663214", "url": "https://en.wikipedia.org/wiki?curid=37663214", "title": "Lists of mammals by population", "text": "Lists of mammals by population\n\nThis is a collection of lists of mammal species by the estimated global population, divided by orders. (Lists only exist for some orders; e.g. the most diverse order - rodents - is missing.) Much of the data in these lists were created by the IUCN's Global Mammal Assessment Team, which consists of 1700 mammalogists from over 130 countries. They recognize 5488 species in the class.\n\nThese lists are not comprehensive, as not all mammals have had their numbers estimated. For example, a live specimen of the spade-toothed whale was first observed in December 2010, and the event only recognized as such in November 2012; no estimate yet exists for the global population. The accuracy of the quote numbers may only be an order of magnitude.\n\nIt is estimated that the total number of wild mammals in the world is about 130 billion.\n\n"}
{"id": "13114237", "url": "https://en.wikipedia.org/wiki?curid=13114237", "title": "Mahmoud Behzad", "text": "Mahmoud Behzad\n\nProfessor Mahmoud Behzad (, b. 1913 - d. 2007), born in Rasht, the capital city of Gilan province, is known as the father of new Biology science in Iran. He has written more than 100 books in Persian and participated in the authorship of more than 200 books in Iran.\n\nHe is the founder of Iran Scholarly Books Editing Organization and also fluent in English, French and German. Professor Behzad is famous because of the books he has translated of French science writer Jean Rostand and English naturalist Charles Darwin.\n\nHe worked for more than 5 years in Alborz High School as the vice president and the teacher of Biology.\nHe died due to stomach cancer in his personal home in Rasht.\n\nIn the last years of his life, Professor Behzad worked in Shargh pharmacy in Rasht where he was ready to answer his fans and former students.\n\nHis senior son, Prof. Faramarz Behzad previous Lecturer of Persian at the German Otto-Friedrich University in Bamberg, and renowerd lexiographer in Bamberg his only daughter Prof. Parichehr Behzad works in the research department of Ludwig Maximilians University of Munich and his junior son, Eng. Hooshang Behzad, lives and works in Shiraz as an architect.\n\n\n"}
{"id": "24550396", "url": "https://en.wikipedia.org/wiki?curid=24550396", "title": "Mario Hamuy", "text": "Mario Hamuy\n\nMario Hamuy is a Chilean Astronomer and Professor of Astronomy at the University of Chile and Cerro Calan Observatory. He is well known for his observational work on all classes of supernovae, especially the use of Type Ia and Type II supernovae as measures of cosmic distance. He was a student in astronomy and physics at the University of Chile working with Jorge Melnick. In February 1987, he came to the Cerro Tololo Inter-American Observatory and within a few days of his arrival when the Type II supernova SN1987A exploded in the Large Magellanic Cloud, he began a major campaign at CTIO to monitor this important supernova.\n\nIn 1989, in collaboration with Jose Maza, Mark M. Phillips, and Nicholas Suntzeff, he began the Calán/Tololo Supernova Survey which led to the pioneering work on the standard candle luminosities of Type Ia supernovae. This work led to the precise measurements of the Hubble Constant H and the deceleration parameter q, the latter indicating the presence of a dark energy or cosmological constant dominating the mass/energy of the Universe.\n\nIn graduate school at the University of Arizona at the Steward Observatory working with Professor Phil Pinto, he changed his focus to the study of core collapse supernovae, in particular using Type II supernovae to measure geometric distances using the Baade-Wesselink method, also called the expanding-photosphere method (EPM). \nWith Pinto, he invented a semi-empirical method to measure distances to Type II events, called the Standard Candle method, which improved the distance accuracies over EPM.\n\nIn 2011, asteroid 109097 was named after him. In 2015 he won the National Prize for Exact Sciences. He is also the president of CONICYT, the Chilean government's scientific research agency and a recipient of the 2016 TWAS Prize.\n\n"}
{"id": "6598198", "url": "https://en.wikipedia.org/wiki?curid=6598198", "title": "Martin Marietta Spacemaster", "text": "Martin Marietta Spacemaster\n\nThe Martin Marietta Spacemaster was a proposed configuration for what became the Space Shuttle, which featured an X-24-derived orbiter, and an unusual \"catamaran style\" booster stage. During launch and ascent, the orbiter would be located in a recess in the booster. The booster's 14 engines would be located in clusters of seven, at the bottom of both halves of the booster. Unlike the final design for the Space Shuttle, the Spacemaster would lack an external tank, and the boosters would be joined, by means of connecting struts which would also serve as the mounting for the orbiter.\n\nThe concept was evaluated in 1967, but was rejected. Martin Marietta went on to produce the Space Shuttle external tank (ET) for the final STS Space Shuttle design (by Lockheed Martin after a merger with Lockheed).\n\nA model of the Martin Marietta Spacemaster is in the collection of the Smithsonian National Air and Space Museum.\n\n\n"}
{"id": "22579694", "url": "https://en.wikipedia.org/wiki?curid=22579694", "title": "Mass media impact on spatial perception", "text": "Mass media impact on spatial perception\n\nMass media influences spatial perception through journalistic cartography and spatial bias in news coverage.\n\n\"Journalism is one of the few industries that provide the general public the most of its information about places and geography,\", mass media is one of the significant factors in shaping perception of places. Moreover, mass media has been criticized for \"limited iconography that constructs the newscape-generic locations that are interchangeable from story to story, and which have come to give a restrictive and distorted worldview\". Lack of geographical balance in news coverage may lead to limitations of spatial knowledge, i.e., US media focuses on a limited number of nations and regions for international news coverage.\n\nWhen some news has an important geographic component, journalism concerns with a location of journalistic information. Use of maps becomes appropriate as \"a map is an efficient means for showing location and describing geographic relationships\". Mass media may use maps to show an event that have spatially distributed data like election results, the distribution of acid rain, radon contamination, weather forecast, traffic, or traveling routes; also describe a story of a battle, a geopolitical strategy, or an environmental threat. Geographers criticize journalistic cartography for deficiencies and constraints of map production. Maps in journalism are produced by graphic artists, who lack in cartographic training. \n\nGeographers have explored the spatial bias in news reporting. Spatial pattern of news is created by journalistic norms, which concern is national coverage, national interest, geographic stereotypes and accessibility to news events. As mass media provides live reporting from the scenes of the news events, journalism requires spatial proximity, event proximity, and broadcast proximity. Capitals, major financial centers and politically unstable places are highly geographically stereotyped and considered as newsworthy locations where important events happen often Economic ties and social distance play also significant role in news coverage.\n"}
{"id": "20588935", "url": "https://en.wikipedia.org/wiki?curid=20588935", "title": "Myelopoiesis", "text": "Myelopoiesis\n\nIn hematology, myelopoiesis in the broadest sense of the term is the production of bone marrow and of all cells that arise from it, namely, all blood cells. But in a narrower sense that is also commonly used, myelopoiesis is the regulated formation specifically of myeloid leukocytes (myelocytes), including eosinophilic granulocytes, basophilic granulocytes, neutrophilic granulocytes, and monocytes.\n\nThe common myeloid progenitor can differentiate in the bone marrow into red blood cells and megakaryocytes (leading to platelets) as well as mast cells and myeloblasts, the latter leading to the myelocytic line (granulocytes) and to monocytes, macrophages, and dendritic cells of the innate immune system. The granulocytes, also called polymorphonuclear leukocytes because of their multilobed nuclei, are three short lived cell types including eosinophils, basophils, and neutrophils. A granulocyte differentiates into a distinct cell type by a process called granulopoiesis. In this process it first transforms from a common myeloblast (myeloid progenitor) to a common promyelocyte. This promyelocyte gives rise to a unique myelocyte that for the first time can be classified as an eosinophil, basophil, or neutrophil progenitor based on the histological staining affinity (eosinophilic, basophilic, or neutral granules). The unique myelocyte next differentiates into a metamyelocyte and then a band cell, with a \"C\" shaped nucleus, before becoming a mature eosinophil, basophil, or neutrophil. Macrophages come from monoblast progenitors that differentriate into promonocytes, which mature into monocytes. Monocytes eventually enter the tissues and become macrophages.\n"}
{"id": "15165446", "url": "https://en.wikipedia.org/wiki?curid=15165446", "title": "Nullor", "text": "Nullor\n\nA nullor is a theoretical two-port network consisting of a nullator at its input and a norator at its output. Nullors represent an ideal amplifier, having infinite current, voltage, transconductance and transimpedance gain. Its transmission parameters are all zero, that is, its input–output behavior is summarized with the matrix equation\nIn negative-feedback circuits, the circuit surrounding the nullor determines the nullor output in such a way as to force the nullor input to zero.\n\nInserting a nullor in a circuit schematic imposes mathematical constraints on how that circuit must behave, forcing the circuit itself to adopt whatever arrangements are needed to meet the conditions. For example, an ideal operational amplifier can be modeled using a nullor, and the textbook analysis of a feedback circuit using an ideal op-amp uses the mathematical conditions imposed by the nullor to analyze the circuit surrounding the op-amp.\n\nFigure 1 shows a voltage-controlled current sink. The sink is intended to draw the same current \"i\" regardless of the applied voltage \"V\" at the output. The value of current drawn is to be set by the input voltage \"v\". Here the sink is to be analyzed by idealizing the op amp as a nullor.\n\nUsing properties of the input nullator portion of the nullor, the input voltage across the op amp input terminals is zero. Consequently, the voltage across reference resistor \"R\" is the applied voltage \"v\", making the current in \"R\" simply \"v\"/\"R\". Again using the nullator properties, the input current to the nullor is zero. Consequently, Kirchhoff's current law at the emitter provides an emitter current of \"v\"/\"R\". Using properties of the norator output portion of the nullor, the nullor provides whatever current is demanded of it, regardless of the voltage at its output. In this case, it provides the transistor base current \"i\". Thus, Kirchhoff's current law applied to the transistor as a whole provides the output current drawn through resistor \"R\" as\n\nwhere the base current of the bipolar transistor \"i\" is normally negligible provided the transistor remains in active mode. That is, based upon the idealization of a nullor, the output current is controlled by the user-applied input voltage \"v\" and the designer's choice for the reference resistor \"R\".\n\nThe purpose of the transistor in the circuit is to reduce the portion of the current in \"R\" supplied by the op-amp. Without the transistor, the current through \"R\" would be \"i\" = (\"V\" − \"v\")/\"R\", which interferes with the design goal of independence of \"i\" from \"V\". Another practical advantage of the transistor is that the op amp must deliver only the small transistor base current, which is unlikely to tax the op amp's current delivery capability. Of course, only real op amps are current-limited, not nullors.\n\nThe remaining variation of the current with the voltage \"V\" is due to the Early effect, which causes the β of the transistor to change with its collector-to-base voltage \"V\" according to the relation β = β(1 + \"V\"/\"V\"), where \"V\" is the so-called Early voltage. Analysis based upon a nullor leads to the output resistance of this current sink as \"R\" = \"r\"(β + 1) + \"R\", where \"r\" is the small-signal transistor output resistance given by \"r\" = (\"V\" + \"V\")/\"i\". See current mirror for the analysis.\n\nUse of the nullor idealization allows design of the circuitry around the op-amp. The practical problem remains of designing an op-amp that behaves like a nullor.\n"}
{"id": "8704200", "url": "https://en.wikipedia.org/wiki?curid=8704200", "title": "Outline of forestry", "text": "Outline of forestry\n\nThe following outline is provided as an overview of and guide to forestry:\n\nForestry – science and craft of creating, managing, using, conserving, and repairing forests and associated resources to meet desired goals, needs, and values for human and environment benefits. Forestry is practiced in plantations and natural stands. Forestry accommodates a broad range of concerns, through what is known as multiple-use management, striving for sustainability in the provision of timber, fuel wood, wildlife habitat, natural water quality management, recreation, landscape and community protection, employment, aesthetically appealing landscapes, biodiversity management, watershed management, erosion control, and preserving forests as 'sinks' for atmospheric carbon dioxide.\n\n\nForest management – comprises the overall administrative, economic, legal, and social aspects of forest regulation\n\n\n\n<br>\n\n\nSilviculture – practice of controlling the establishment, growth, composition, health, and quality of forests to meet diverse needs and values. Silviculture also focuses on making sure that the treatment(s) of forest stands are used to preserve and to better their productivity.\n\nSite preparation\nPlanting\nIntermediate treatments\nHarvest rotations\n\n\nForest inventory – systematic collection of data and forest information for assessment or analysis. An estimate of the value and possible uses of timber is an important part of the broader information required to sustain ecosystems.\n\n\nLogging – cutting, skidding, on-site processing, and loading of trees or logs onto trucks or skeleton cars. The term is sometimes used in a narrow sense to mean moving wood from the stump to somewhere outside the forest, usually a sawmill or a lumber yard. However, in common usage, the term may be used to indicate a range of forestry or silviculture activities...\n\n\n\n\nForest product – any material derived from a forest for direct consumption or commercial use, such as lumber, paper, or forage for livestock. Wood is by far the dominant forest product, used for fuel (as firewood or charcoal), structural materials in the construction of buildings, or as a raw material, such as wood pulp used in the production of paper. All non-wood products derived from forest resources are called non-timber forest products.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistory of forestry organizations\n\nList of historic schools of forestry\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "15202596", "url": "https://en.wikipedia.org/wiki?curid=15202596", "title": "Paracrine regulator", "text": "Paracrine regulator\n\nA Paracrine regulator is a molecule or hormone produced by a tissue to regulate activity in that same tissue. Paracrine regulators are distinct from endocrine regulators, which secrete substances directly into the blood stream, thus accessing other tissues as well. Some paracrine regulators can also be autocrine regulators, which are produced by cells to induce changes within themselves.\n\n"}
{"id": "466599", "url": "https://en.wikipedia.org/wiki?curid=466599", "title": "Pedro Duque", "text": "Pedro Duque\n\nPedro Francisco Duque Duque, OF, OMSE (Madrid, 14 March 1963) is a Spanish astronaut and aeronautics engineer, currently serving as Spain's Minister of Science, Innovation and Universities. He was the first Spanish astronaut.\n\nBorn in Madrid in 1963. The son of an agricultural engineer who worked as an air traffic controller and a housewife from Badajoz. In 1986 Duque earned a degree in Aeronautical Engineering from the Universidad Politécnica de Madrid. In 1986 he worked for GMV and for the European Space Agency (ESA) for six years before being selected as an astronaut candidate in 1992.\n\nDuque underwent training in both Russia and the United States. His first spaceflight was as a mission specialist aboard space shuttle mission STS-95, during which Duque supervised ESA experimental modules. In October 2003, Duque visited the International Space Station on board of a Soyuz TMA Ship for several days during a crew changeover. The scientific program of this visit was called by ESA/Spain Misión Cervantes.\n\nIn 2003 he started working at UPM School of Aeronautical Engineers as head of operations of the Spanish USOC, also lecturing students on space science and operations. \n\nIn 2006 Duque was named managing director of Deimos Imaging, a private company, that in 2009 put in orbit the first Spanish earth observation satellite (Deimos 1) with uses in agriculture, forestry wildfire detection and control. In 2011 he was named CEO of the Company.\n\nIn October 2011 Duque returned to his position in the European Space Agency, retaking his position as an atronaut. Until 2015 he was the leader of the Flight Operations Office, with responsibility for ESA operations in the ISS. After that he assumed the responsibility of the review of future ESA manned flights, within the ESA's astronaut corps.\n\nAfter the success of the motion of no confidence against the Spanish government in June 2018, Prime Minister Pedro Sanchez named Pedro Duque Minister of Science, Innovation and Universities.\n\n\n\n"}
{"id": "5563106", "url": "https://en.wikipedia.org/wiki?curid=5563106", "title": "Programming the Universe", "text": "Programming the Universe\n\nProgramming the Universe: A Quantum Computer Scientist Takes On the Cosmos is a 2006 popular science book by Seth Lloyd, professor of mechanical engineering at the Massachusetts Institute of Technology. The book proposes that the universe is a quantum computer, and advances in the understanding of physics may come from viewing entropy as a phenomenon of information, rather than simply thermodynamics. Lloyd also postulates that the universe can be fully simulated using a quantum computer; however, in the absence of a theory of quantum gravity, such a simulation is not yet possible.\n\nReviewer Corey S. Powell of \"The New York Times\" writes:\n\nIn the space of 221 dense, frequently thrilling and occasionally exasperating pages, … tackles computer logic, thermodynamics, chaos theory, complexity, quantum mechanics, cosmology, consciousness, sex and the origin of life — throwing in, for good measure, a heartbreaking afterword that repaints the significance of all that has come before. The source of all this intellectual mayhem is the kind of Big Idea so prevalent in popular science books these days. Lloyd, a professor of mechanical engineering at M.I.T., takes as his topic the fundamental workings of the universe…, which he thinks has been horribly misunderstood. Scientists have looked at it as a ragtag collection of particles and fields while failing to see what it is as a majestic whole: an enormous computer.\nIn an interview with \"Wired\" magazine, Lloyd writes:\n\neverything in the universe is made of bits. Not chunks of stuff, but chunks of information — ones and zeros. … Atoms and electrons are bits. Atomic collisions are \"ops.\" Machine language is the laws of physics. The universe is a quantum computer.\n\nGilbert Taylor, writing in \"Booklist\" of the American Library Association, said that the book:\n\noffers brilliantly clarifying explanations of the \"bit,\" the smallest unit of information; how bits change their state; and how changes-of-state can be registered on atoms via quantum-mechanical qualities such as \"spin\" and \"superposition.\" Putting readers in the know about quantum computation, Lloyd then informs them that it may well be the answer to physicists' search for a unified theory of everything. Exploring big questions in accessible, comprehensive fashion, Lloyd's work is of vital importance to the general-science audience.\n\n\n"}
{"id": "36313540", "url": "https://en.wikipedia.org/wiki?curid=36313540", "title": "Proton spin crisis", "text": "Proton spin crisis\n\nThe proton spin crisis (sometimes called the \"proton spin puzzle\") is a theoretical crisis precipitated by an experiment in 1987 which tried to determine the spin configuration of the proton. The experiment was carried out by the European Muon Collaboration (EMC).\n\nPhysicists expected that the quarks carry all the proton spin. However, not only was the total proton spin carried by quarks far smaller than 100%, these results were consistent with almost zero (4–24%) proton spin being carried by quarks. This surprising and puzzling result was termed the \"proton spin crisis\". The problem is considered one of the important unsolved problems in physics.\n\nA key question is how the nucleon's spin is distributed amongst its constituent partons (quarks and gluons). Physicists originally expected that quarks carry all of the nucleon spin.\n\nA proton is built from three valence quarks (two up quarks and one down quark), gluons, and virtual (or \"sea\") quarks and antiquarks (which do not influence the proton's quantum numbers). The ruling assumption was that since the proton is stable, then it exists in the lowest possible energy level. Therefore, it was expected that the quark's wave function is the spherically symmetric s-wave with no spatial contribution to angular momentum. The proton is, like each of its quarks, a spin 1/2 particle. Therefore, it was assumed that two of the quarks have their spins parallel to the proton's and the spin of the third quark is opposite.\n\nIn this EMC experiment, a quark of a polarized proton target was hit by a polarized muon beam, and the quark's instantaneous spin was measured. In a polarized proton target, all the protons' spin take the same direction, and therefore it was expected that the spin of two out of the three quarks cancels out and the spin of the third quark is polarized in the direction of the proton's spin. Thus, the sum of the quarks' spin was expected to be equal to the proton's spin.\n\nHowever, it was found in this EMC experiment that the number of quarks with spin in the proton's spin direction was almost the same as the number of quarks whose spin was in the opposite direction. This is the proton spin crisis. Similar results have been obtained in later experiments.\n\nA 2008 work shows that more than half of the spin of the proton comes from the spin of its quarks, and that the missing spin is produced by the quarks' orbital angular momentum. This work uses relativistic effects together with other quantum chromodynamic properties and explains how they boil down to an overall spatial angular momentum that is consistent with the experimental data. A 2013 work shows how to calculate the gluon helicity contribution using lattice QCD. Recent Monte Carlo calculation shows that 50% of the proton spin come from gluon polarization. 2016 results from the RHIC indicate that gluons may carry even more of protons' spin than quarks do.\n\n"}
{"id": "12515412", "url": "https://en.wikipedia.org/wiki?curid=12515412", "title": "Rolando fracture", "text": "Rolando fracture\n\nThe Rolando fracture is a comminuted intra-articular fracture through the base of the first metacarpal bone (the first bone forming the thumb). It was first described in 1910 by Silvio Rolando. This is a fracture consisting of 3 distinct fragments; it is typically T- or Y-shaped.\n\nThere are several proposed methods of treatment. The quality of reduction does not correlate with late symptoms and osteoarthritic changes. Despite this fact, the joint surface should be restored as close to its anatomical position as possible.\nSome advocate fixation with Kirschner wires, or plate and screw constructions.\nAnother accepted treatment is an external fixator accompanied by the tension band wiring technique.\n\nTension band wiring is a technique in which the bone fragments are transfixed by Kirschner wires, which are then also used as an anchor for a loop of flexible wire. As the loop is tightened the bone fragments are compressed together.\n\nThe Rolando fracture is less common than the Bennett's fracture, and is associated with a worse prognosis.\n\n\n"}
{"id": "332823", "url": "https://en.wikipedia.org/wiki?curid=332823", "title": "Royal Institution", "text": "Royal Institution\n\nThe Royal Institution of Great Britain (often abbreviated as the Royal Institution or Ri) is an organisation devoted to scientific education and research, based in London.\nIt was founded in 1799 by the leading British scientists of the age including Henry Cavendish and its first president, George Finch, the 9th Earl of Winchilsea, for diffusing the knowledge, and facilitating the general introduction, of useful mechanical inventions and improvements; and for teaching, by courses of philosophical lectures and experiments, the application of science to the common purposes of life. \nMuch of the Institution's initial funding and the initial proposal for its founding were given by the Society for Bettering the Conditions and Improving the Comforts of the Poor, under the guidance of philanthropist Sir Thomas Bernard and American-born British scientist Sir Benjamin Thompson, Count Rumford. Since its founding it has been based at 21 Albemarle Street in Mayfair. Its Royal Charter was granted in 1800.\n\nThroughout its history, the Institution has supported public engagement with science through a programme of lectures, many of which continue today. The most famous of these are the annual Royal Institution Christmas Lectures, founded by Michael Faraday.\nThe Royal Institution was founded as the result of a proposal by the American-born Bavarian Count Rumford for the \"formation by Subscription, in the Metropolis of the British Empire, of a Public Institution for diffusing the Knowledge and facilitating the general Introduction of useful Mechanical Inventions and Improvements, and for the teaching by courses of Philosophical Lectures and Experiments, the application of Science to the Common Purposes of Life\".\n\nThe first Professor and Public Lecturer in Experimental Philosophy, Mechanics and Chemistry was Dr Thomas Garnett, whom Rumford poached from the newly founded Andersonian Instute in Glasgow. Despite Garnett's first lectures being a great success, his salary was frozen, he was not allowed to practise as a doctor, and Humphry Davy was appointed as his assistant, so he resigned. Humphry Davy was an even greater success, as was his assistant and successor Michael Faraday. Davy's immediate successor was William Thomas Brande.\n\nThus the Institution has had an instrumental role in the advancement of science since its founding. Notable scientists who have worked there include Sir Humphry Davy (who discovered sodium and potassium), Michael Faraday, James Dewar, Sir William Henry Bragg and Sir William Lawrence Bragg (who jointly won the Nobel prize for their work on x-ray diffraction), Max Perutz, John Kendrew, Antony Hewish, and George Porter. \n\nIn the 19th century, Faraday carried out much of the research which laid the groundwork for the practical exploitation of electricity at the Royal Institution. In total fifteen scientists attached to the Royal Institution have won Nobel Prizes. Ten chemical elements including sodium were discovered there; the electric generator was devised at the Institution, and much of the early work on the atomic structure of crystals was carried out within it.\n\n\n\nSince 1799, the Royal Institution has had fifteen presidents and one acting president.\nThe leadership of the Royal Institution has had various titles:\n\nThe position was abolished in 2010. The Institution's last director was Susan Greenfield.\n\nSarah Harper, Professor of Gerontology at the University of Oxford, was announced as the new Director of the Ri in April 2017 and resigned in September 2017.\nIn 1952, Edward Andrade was forced to resign following a complicated controversy over the management of the Royal Institution and his powers as director, involving a power struggle with Alexander Rankine who was secretary. Following various resignations and general meetings of members, Andrade was awarded £7,000 by arbitration: the arbitrators blamed the problems on \"a lack of clear definition of roles ... an outdated constitution, and the inability of the protagonists to compromise\". Andrade launched a lawsuit to set the arbitration aside, which he lost.\n\nFrom 1998 to 8 January 2010, the director of the Royal Institution was Baroness Susan Greenfield, but following a review, the position was abolished for being \"no longer affordable\". The Royal Institution had found itself in a financial crisis following a £22 million development programme led by Greenfield, which included refurbishment of the institution's main Albemarle Street building, and the addition of a restaurant and bar with an aim to turn the venue into a \"Groucho club for science\". The project ended £3 million in debt.\n\nGreenfield subsequently announced that she would be suing for discrimination.\nThe RI's official statement stated it would \"continue to deliver its main charitable objectives under the direction of chief executive officer, Chris Rofe and a talented senior team including Professor Quentin Pankhurst, the Director of the Davy Faraday Research Laboratory, Dr Gail Cardew, the Head of Programmes and Professor Frank James, Head of Collections and Heritage.\" Baroness Greenfield later dropped the discrimination case.\n\nToday the Royal Institution is committed to \"diffusing science for the common purposes of life\". Membership is open to all, with no nomination procedure or academic requirements, on payment of an annual subscription.\n\nThe Institution's patrons and trustees include:\n\nIn February 2018, the institution appointed Dr Shaun Fitzgerald FREng as director. Fitzgerald took up the post in April 2018. In July 2018, the institution announced a new five-year strategy running from October 2018 to September 2023. The strategy, which sets out to double the charity's size, involves \"plans for new research, development of a new national science club and open forum public policy debates\". One new venture will be a Research Centre for Science and Culture, working with other academic groups, this \"will investigate historical and contemporary examples of the relationship between science and culture\".\n\nThe institution's palatial home has been greatly enlarged and redeveloped since 1799, and is a Grade I listed building. The structure's last refurbishment was a £22 million project completed in 2008, intended to create a \"science salon\" for the public. As well as the famous Lecture Theatre, the building contains several function rooms, modern research facilities and a public café. The trustees were considering selling the building in an effort to recoup the organisation's debts, which amounted to £7 million. In 2013 The Ri received an anonymous donation of £4.4m and as of January 2016, the Ri is now debt-free.\n\nThe Institution (today abbreviated as the Ri) has a substantial public science programme and science for schools programme, holding over one hundred events per year on a wide variety of topics. The Christmas Lectures continue today as a series of three televised lectures aimed at children. The Friday Evening Discourses are monthly lectures given by eminent scientists, each limited to exactly one hour, a tradition started by Faraday. There is an annual members' ballot for tickets to the Christmas Lectures but all other events are open to the public. Discounts or free tickets are available to Ri Patrons and Members. Many other events and lectures are held both at Albemarle Street and at other venues around the country.\n\nScientific research headed by Professor Quentin Pankhurst continues to be done under the auspices of the Davy-Faraday Research Laboratory (DFRL), and indeed this is considered to be one of the UK's most notable labs in nano-science.\n\nIn May 2015, The Royal Institution was host to the historic unveiling of the Santara Computer, created by Dr Andrew Deonarine.\n\nIn November 2015 a new membership scheme was launched and Fellows of the Ri were abolished. The new scheme includes the categories Member, Under 26 and Ri Young Member. A Patrons scheme has also been introduced for the first time.\n\nIn December 2011 the Royal Institution launched the Ri Channel, a new website displaying science videos and archive content from the Royal Institution, including past Christmas Lectures. The Ri Channel was archived in late 2017 with all Ri videos except past Christmas Lectures being hosted on YouTube. Past Christmas Lectures are hosted on the Ri's website and in early 2018 the Ri began a to upload all past Christmas Lectures that were not already available on its website.\n\nDespite its noble history, the Royal Institution has now become a mixed tenancy office building that hosts conferences, weddings and events in order to pay its bills. In 2015 it sold part of its historic collection of manuscripts to raise funds.\n\nIn 2015, a room in the Institution was used in an experiment on moral ethics for the US TV scientific show \"Braingames\".\n\nIn 1973 the Royal Institution opened the Faraday Museum, a museum dedicated to Michael Faraday. It is in the main building in Albemarle Street and is open to the public during weekday office hours. The highlight of the exhibition is Faraday's original 1850s laboratory (not a reconstruction as often cited). Opposite this lab is the current state-of-the-art nanotechnology lab. Other exhibits include the discoveries, people and activities of the Royal Institution.\n\n"}
{"id": "31183690", "url": "https://en.wikipedia.org/wiki?curid=31183690", "title": "SLinCA@Home", "text": "SLinCA@Home\n\nSLinCA@Home (Scaling Laws in Cluster Aggregation) was a research project that uses Internet-connected computers to do research in fields such as physics and materials science.\n\nSLinCA@Home is based at the G. V. Kurdyumov Institute for Metal Physics (IMP) of the National Academy of Sciences of Ukraine (NASU) in Kiev, Ukraine's capital city. It runs on the Berkeley Open Infrastructure for Network Computing (BOINC) software platform, the SZTAKI Desktop Grid platform, and the Distributed Computing API (DC-API) by SZTAKI. SLinCA@Home hosts several scientific applications dedicated to research into scale-invariant dependencies in experimental data and computer simulation results.\n\nThe SLinCA@Home project was previously launched in January 2009 as part of the EGEE project in the European Union's Seventh Framework Programme (FP7) for the funding of research and technological development in Europe. During 2009–2010 it used the power of a local IMP Desktop Grid (DG), but from December 2010 it has been using the power of volunteer-driven distributed computing in solving the computationally intensive problems involved in research into scale-invariant dependencies in experimentally obtained and simulated scientific data. It is now operated by a group of scientists from IMP NASU in close cooperation with partners from IDGF and the 'Ukraine' Distributed Computing team. From June 2010 SLinCA@Home has been under the framework of the DEGISCO FP7 EU project.\n\nCurrently, SLinCA@Home is considered to be in alpha-test, due to gradual upgrades of the server and client parts.\n\nBy informal statistics at the BOINCstats site (as of 16 March 2011), over 2,000 volunteers in 39 countries have participated in the project; it is the second most popular BOINC project in Ukraine (after the Magnetism@Home project, which is now inactive). About 700 active users contribute about 0.5–1.5 teraFLOPS of computational power, which would rank SLinCA@Home among the top 20 on the TOP500 list of supercomputers – if this were June 2005.\n\nCurrently, one application (SLinCA) is running publicly using IMP Desktop Grid (DG) infrastructure (SLinCA@Home); three others (MultiScaleIVideoP, CPDynSG, and LAMMPS over DCI) are being tested internally at IMP.\nThe SLinCA@Home project was created to perform searches for and research into previously unknown scale-invariant dependencies using data from experiments and simulations.\nThe SLinCA (Scaling Laws in Cluster Aggregation) application was the first one ported to the DG infrastructure by the Physics of Deformation Processes Lab at IMP NASU. Its goal is to find scale-invariant laws in kinetic scenarios of monomer aggregation in clusters of different kinds in multiple scientific domains.\n\nThe processes of agent aggregation into clusters are investigated in many branches of science: defect aggregation in materials science, population dynamics in biology, city growth and evolution in sociology, etc. Experimental data exist confirming evolving structures, which tends to be hierarchical on many scales. The available theories give rise to many scenarios of cluster aggregation and the formation of hierarchical structures, and predict various scaling properties. However, there are huge databases of experimental data, which require powerful computational resources for hierarchical processing. A typical simulation of one cluster aggregation process with 10 monomers takes approximately 1–7 days on a single modern CPU, depending on the number of Monte Carlo steps (MCS).\n\nDeploying SLinCA on a Grid computing infrastructure, utilising hundreds of machines at the same time, allows harnessing sufficient computational power to undertake simulations on a larger scale and in a much shorter timeframe. Running the simulations and analysing the results on the Grid provides the required significant computational power.\n\nThe technical characteristics of running the Desktop Grid-enabled version of the SLinCA application based on the IMP Desktop Grid infrastructure (SLinCA@Home) are:\n\nThe previous scientific results of the SLinCA application were obtained on EGEE computing resources at CETA-CIEMAT and XtremWeb-HEP Laboratoire de l'accélérateur linéaire test infrastructures were reported in March 29–30, 2009 during the poster session at the 4th EGEE training event and 3rd AlmereGrid Workshop, in Almere, Netherlands.\n\nCurrent plans for the SLinCA application are for stable checkpointing, some new functionality, and supporting NVIDIA GPU computing for faster computation; the last is predicted to make SLinCA from 50% to 200% faster.\n\nOptical microscopy is usually used for structural characterization of materials in a narrow range of magnification, a small region of interest (ROI), and without changes during microscopy. But many crucial processes of damage initiation and propagation take place dynamically in a timescale ranging from 10 s to 10 s and distance scales from micrometers (solitary defects places) to centimeters (for correlated linked networks of defects). Multiscale Image and Video Processing (MultiscaleIVideoP) is designed to process the recorded changes in materials under mechanical deformation in a loading machine (e.g., a diamond anvil cell). The calculations include many parameters of the physical process (e.g., rate, magnification, illumination conditions, and hardware filters) and image processing parameters (e.g., size distribution, anisotropy, localization, and scaling parameters); thus, the calculations are very slow, requiring more powerful computational resources. Deploying this application on a grid computing infrastructure, utilising hundreds of machines at the same time, allows harnessing sufficient computational power to perform image and video processing on a larger scale and in a much shorter timeframe.\n\nThe technical characteristics when running the Desktop Grid-enabled version of the MultiScaleIVideoP application at the IMP are:\n\nThe scientific results of the MultiScaleIVideoP application were obtained on EGEE computing resources at CETA-CIEMAT and XtremWeb-HEP Laboratoire de l'accélérateur linéaire test infrastructures were reported in March 29–30, 2009 during the poster session at the 4th EGEE training event and 3rd AlmereGrid Workshop, in Almere, Netherlands.\n\nIn January 2011, further scientific results for experiments on cyclic constrained tension of aluminum foils under video monitoring were reported.\n\nCurrent plans for the MultiScaleIVideoP application are for stable checkpointing, some new functionality, and supporting NVIDIA GPU computing for faster computation; the last is predicted to make MultiScaleIVideoP from 300% to 600% faster.\n\nIn the social sciences, it has been found that the growth of cities (or municipalities, lands, counties, etc.) can be explained by migration, merges, population growth, and similar phenomena. For example, from the literature one can found that the city population distribution in many countries is consistent with a power law form in which the exponent t is close to 2. This finding is confirmed qualitatively by data on the populations of various cities during their early histories. The population of essentially every major city grows much faster than each of their countries as a whole over a considerable timespan. However, as cities reach maturity, their growth may slow or their population may even decline for reasons unrelated to preferential migration to still-larger cities. Different theories give varying growth rates, asymptotics, and distributions of such populations. It is important to compare the various theories with each other, compare the theories with observations, and make predictions of possible population dynamics and sustainable growth for various subnational, national, and multinational regions. The City Population Dynamics and Sustainable Growth (CPDynSG) application allows investigating the correspondences between model predictions and the vast volume of available long-term historical data.\n\nThe technical characteristics when running the Desktop Grid-enabled version of the CPDynSG application at the IMP are:\n\nIn June–September 2010 some results from porting CPDynSG to the Distributed Computing Infrastructure (DCI) using BOINC and the SZTAKI Desktop Grid were obtained, specifically analyses of city size distributions in several Central and Eastern European countries. The distinctive isolation of the city size distribution in Hungary was noted. A very high similarity in the evolution of city size distributions in Ukraine and Poland was discovered. These results were reported during the Cracow Grid Workshop'10 (October 11–13, 2010) in oral and poster presentations. The poster presentation was awarded the \"Best Poster of the Cracow Grid Workshop'10\" prize.\n\nCurrent plans for the CPDynSG application are for stable checkpointing, some new functionality, and supporting NVIDIA GPU computing for faster computation; the last is predicted to make CPDynSG from 50% to 200% faster.\n\nOne important topic in materials science currently is the development of new nanoscale functional devices. However, controlled fabrication of such requires careful selection and tuning of the critical parameters (e.g., elements, interaction potentials, and external influences such as temperature) of atomic self-organization in designed patterns and structures for nanoscale functional devices. Thus, molecular dynamics simulations of nanofabrication processes with brute-force searches through different combinations of parameters are of interest. For this, the very popular open-source package \"Large-scale Atomic/Molecular Massively Parallel Simulator\" (LAMMPS) by the Sandia National Laboratories was selected as a candidate for porting to DCI using the Desktop Grid. In other words, LAMMPS with \"parameter sweeping\" parallelism can be ported to DCI on DG. Usually, it requires powerful computational resources to simulate nano-objects with many parameters. The typical simulation of an investigated nanostructure under one set of physical parameters — for instance, a single crystal of metal (such as aluminium, copper, or molybdenum) with 10 atoms using embedded atom potentials for as little as 1–10 picoseconds of simulated physical process — takes approximately 1–7 days on a single modern CPU. Deploying LAMMPS on a grid computing infrastructure, utilising hundreds of machines at the same time, allows harnessing sufficient computational power to undertake the simulations in a wider range of physical parameter configurations and a much shorter timeframe.\n\nThe technical characteristics when running the Desktop Grid-enabled version of LAMMPS at the IMP are:\n\nIn September–October 2010 results were obtained and reported in an oral presentation during the International Conference on “Nanostructured materials-2010”, in Kiev, Ukraine.\n\nCurrent plans for the LAMMPS over DCI application are for stable checkpointing, some new functionality, and supporting NVIDIA GPU computing for faster computation; the last is predicted to make LAMMPS over DCI from 300% to 500% faster.\n\nAn additional goal is migration to the OurGrid platform for testing and demonstrating potential mechanisms of interoperation between worldwide communities with different DCI paradigms. The OurGrid platform is targeted at the support of peer-to-peer desktop grids; these are in nature very different from volunteer computing desktop grids such as the SZTAKI Desktop Grid.\n\nSLinCA@Home collaborates with:\n\n\n\n"}
{"id": "58058360", "url": "https://en.wikipedia.org/wiki?curid=58058360", "title": "Sawbones (podcast)", "text": "Sawbones (podcast)\n\nSawbones is a weekly, comedic medical podcast hosted by Dr. Sydnee McElroy and her husband, podcaster Justin McElroy. The show is distributed online by Maximum Fun.\n\nIn each episode, Sydnee discusses an element of historical medical practice, while Justin provides a comedic foil. The show normally focusses on practices that have long since fallen out of use, and are unusual to modern listeners.\n\nSydnee and Justin McElroy had previously worked together on a short podcast series entitled \"Losing the Sheen\", focused on watching \"Two and a Half Men\". The show only lasted nine episodes before the two became tired of it, instead starting a medical podcast based on Sydnee's expertise. While developing the idea for the show, the McElroys decided that it would be irresponsible for them to give medical advice to listeners, even with Sydnee's background. They opted instead to focus on the historical aspects, which had been an interest of Sydnee's. Like other shows by the family, such as \"My Brother, My Brother and Me\", \"Sawbones\" is distributed via the Maximum Fun network.\n\n\"Sawbones\" has on occasion been performed live, such as the November 2nd, 2017 performance at the Keith-Albee Performing Arts Center in Huntington, WV.\n\nIn June 2018, a book adaptation of the podcast was announced, under the title \"The Sawbones Book: The Horrifying, Hilarious Road To Modern Medicine\". Published by Weldon Owen, the book became available in October 2018.\n"}
{"id": "40342730", "url": "https://en.wikipedia.org/wiki?curid=40342730", "title": "The Illustrated Guide to the Elements", "text": "The Illustrated Guide to the Elements\n\nThe Illustrated Guide to the Elements is a book by Jenna Whyte. Published in 2012, the book features factual information about all the chemical elements with drawings to illustrate the information. There was mention of a sequel.\n"}
{"id": "2151282", "url": "https://en.wikipedia.org/wiki?curid=2151282", "title": "The Shamba Raiders", "text": "The Shamba Raiders\n\nThe Shamba Raiders: Memories of a Game Warden was written by Bruce Kinloch. It is a non-fiction account of his experiences in Africa and was first published in 1972. It proved so successful that a revised edition came out in 1988, and then again in 2004.\n\nThe title refers to the marauding elephants destroying peasant crops, driven by heavy poaching pressure in wilderness areas, which formed the most urgent task for Kinloch.\n\nThat his book is still in demand is a source of pride to him and his wife, Elizabeth, who accompanied him frequently and typed up the notes of his original book. \"It is a book that never dies, its contents are as relevant now as ever,\" she said.\n\n\"The Shamba Raiders\" is an account of the struggle to preserve herds of game threatened by modern civilisation, poaching, war and the political and economic changes which have swept Africa in the middle of the last century. As the Chief Game Warden in Uganda, Tanzania and Malawi, Kinloch walked the tight rope of retaining Africa's wildlife heritage while safeguarding crops and livelihood of the population, featuring ivory poachers and middlemen as well as uncaring and bigoted officials. \n\nIn particular, the book describes Kinloch's management of the Uganda Game and Fisheries Department during the introduction of the Protectorate's first National Parks, the introduction of Nile Perch to the upper Victoria Nile, and the creation of the College of African Wildlife Management.\n\n\"Eyeball to eyeball with bull elephant,\" \"This is Herefordshire.\" Online Article\n"}
{"id": "32965228", "url": "https://en.wikipedia.org/wiki?curid=32965228", "title": "Traces of Catastrophe", "text": "Traces of Catastrophe\n\nTraces of Catastrophe: A Handbook of Shock-Metamorphic Effects in Terrestrial Meteorite Impact Structures is a book written by Bevan M. French of the Smithsonian Institution. It is a comprehensive technical reference on the science of impact craters. It was published in 1998 by the Lunar and Planetary Institute (LPI), which is part of the Universities Space Research Association (USRA). It was originally available in hard copy from LPI, but is now only available as a portable document format (PDF) e-book free download.\n\nThe book has become very influential in the field of impact crater research, appearing as a common reference for papers and web sites on the topic. The Earth Impact Database lists it among the suggested reading on its introductory page about impact craters. The Impact Field Studies Group Impact Database says it is required reading before submitting an observation of a proposed impact site. NASA's Goddard Space Flight Center (GSFC) lists it among general references relevant to Planetary Science across the solar system. NASA GSFC also has a Remote Sensing Tutorial site which calls \"Traces of Catastrophe\" an \"exceptional summary of impact cratering.\"\n\nThe book is divided into chapters listed below.\n\nChapter 1 introduces impact craters, now recognized on Earth due to the study of other planetary bodies, most significantly the Moon. On Earth, impact craters differ from other processes in geology in being rare, from a release of extremely large amounts of energy, and happening in an instant. It contrasts with other geological forces that mostly take very long periods of time.\n\nChapter 2 covers the astronomical aspect with asteroids and comets. Historical impacts are discussed, including the Tunguska event of 1908. There is a table comparing effects from tiny to enormous meteor impacts.\n\nChapter 3 is about the process of formation of a crater during an impact event. The propagation of the shock wave leads to progressive stages of contact/compression, excavation and modification. It differentiates simple and complex craters, and multi-ring basins. Then it covers the erosion processes that continue after the crater has been made.\n\nChapter 4 is about shock metamorphism, the unique changes made to rocks by the extreme but brief shock forces of an impact. The effects include shatter cones, planar deformation features (PDFs), selective melting and many others. The amount of shock metamorphism in the rocks progresses in stages with the amount of pressure that they were exposed to, ranging from fracturing and brecciation to vaporization of the rocks and later condensation into glass.\n\nChapter 5 surveys various impactites, meaning shock-metamorphosed rocks, and where they are found in an impact structure based on the pressures in various parts of the cratering process. The topics include crater-fill breccias, ejecta blanket, pseudotachylite and impact melt breccias.\n\nChapter 6 covers impact melts, their volume relative to crater size, melt rocks in the crater, impact melt breccias, dikes & sills, and tektites.\n\nChapter 7 is about finding new impact structures. It includes search methods and verification using unique features of craters covered earlier.\n\nChapter 8 looks to the future, considers current problems and subjects for further study.\n\nAn appendix \"Criteria for recognizing terrestrial impact structures\" provides a checklist for use in verification of potential impact sites.\n\n"}
{"id": "659136", "url": "https://en.wikipedia.org/wiki?curid=659136", "title": "United States House Committee on Science, Space, and Technology", "text": "United States House Committee on Science, Space, and Technology\n\nThe Committee on Science, Space and Technology is a committee of the United States House of Representatives. It has jurisdiction over non-defense federal scientific research and development. Specifically, the committee has partial or complete jurisdiction over the following federal agencies: NASA, the Department of Energy, EPA, ATSDR, NSF, FAA, NOAA, NIST, FEMA, the U.S. Fire Administration, and USGS.\n\nIn the wake of the Soviet Sputnik program in the late 1950s, Congress created the Select Committee on Astronautics and Space Exploration in 1958, chaired by majority leader John William McCormack. This select committee drafted the National Aeronautics and Space Act that created the National Aeronautics and Space Administration (NASA). A staff report of the committee, the \"Space Handbook: Astronautics and its Applications\", provided non-technical information about spaceflight to U.S. policy makers.\n\nThe committee also chartered the permanent House Committee on Science and Astronautics, which officially began on January 3, 1959, and was the first new standing committee established in the House since 1946. The name was changed in 1974 to the House Committee on Science and Technology. The name was changed again in 1987 to the House Committee on Science, Space and Technology. After the Republican Party gained a majority in Congress in 1994, the name of the committee was changed to the House Committee on Science. With the return of control to the Democrats in 2007, the committee's name was changed back to the House Committee on Science and Technology.\n\nIn the 112th Congress, Committee Chairman Ralph Hall added \"Space\" back into the committee's name: \"The Committee on Science, Space, and Technology\" – a nod to the committee's history, broad jurisdiction, and the importance of space exploration in maintaining American innovation and competitiveness.\n\nOn December 1, 2016, the committee's Twitter account posted a link to an article on Breitbart which argued that climate change was the result of natural weather processes. The tweet was criticized by members of the scientific community on Twitter for promoting an unscientific and misleading article. The Committee's Ranking Member Eddie Bernice Johnson also criticized the tweet, writing, \"False news & false facts put us all in danger.\"\n\nThere are five subcommittees in the 115th Congress.\n\nChairmen since 1959.\n\n\n"}
{"id": "1424913", "url": "https://en.wikipedia.org/wiki?curid=1424913", "title": "Vis viva", "text": "Vis viva\n\n1\nVis viva (from the Latin for \"living force\") is a historical term used for the first (known) description of what we now call kinetic energy in an early formulation of the principle of conservation of energy.\n\nProposed by Gottfried Leibniz over the period 1676–1689, the theory was controversial as it seemed to oppose the theory of conservation of momentum advocated by Sir Isaac Newton and René Descartes. The two theories are now understood to be complementary.\n\nThe theory was eventually absorbed into the modern theory of energy though the term still survives in the context of celestial mechanics through the \"vis viva\" equation.\n\nThe term is due to German Gottfried Wilhelm Leibniz, who during 1676–1689 first attempted a mathematical formulation. Leibniz noticed that in many mechanical systems (of several masses, \"m\" each with velocity \"v\") the quantity:\n\nwas conserved. He called this quantity the \"vis viva\" or \"living force\" of the system. The principle, it is now realised, represents an accurate statement of the conservation of kinetic energy in elastic collisions, and is independent of the conservation of momentum. However, many physicists at the time were unaware of this fact and, instead, were influenced by the prestige of Sir Isaac Newton in England and of René Descartes in France, both of whom advanced the conservation of momentum as a guiding principle. Thus the momentum:\n\nwas held by the rival camp to be the conserved \"vis viva\". It was largely engineers such as John Smeaton, Peter Ewart, Karl Holtzmann, Gustave-Adolphe Hirn and Marc Seguin who objected that conservation of momentum alone was not adequate for practical calculation and who made use of Leibniz's principle. The principle was also championed by some chemists such as William Hyde Wollaston.\n\nThe French mathematician Émilie du Châtelet, who had a sound grasp of Newtonian mechanics, developed Leibniz's concept and, combining it with the observations of Willem 's Gravesande, showed that \"vis viva\" was dependent on the square of the velocities.\n\nMembers of the academic establishment such as John Playfair were quick to point out that kinetic energy is clearly not conserved. This is obvious to a modern analysis based on the second law of thermodynamics but in the 18th and 19th centuries, the fate of the lost energy was still unknown. Gradually it came to be suspected that the heat inevitably generated by motion was another form of \"vis viva\". In 1783, Antoine Lavoisier and Pierre-Simon Laplace reviewed the two competing theories of \"vis viva\" and caloric theory. Count Rumford's 1798 observations of heat generation during the boring of cannons added more weight to the view that mechanical motion could be converted into heat. \"Vis viva\" now started to be known as \"energy\", after the term was first used in that sense by Thomas Young in 1807.\nThe recalibration of \"vis viva\" to include the coefficient of a half, namely:\n\nwas largely the result of the work of Gaspard-Gustave Coriolis and Jean-Victor Poncelet over the period 1819–1839, although the present-day definition can occasionally be found earlier (e.g., in Daniel Bernoulli texts).\n\nThe former called it the \"quantité de travail\" (quantity of work) and the latter, \"travail mécanique\" (mechanical work) and both championed its use in engineering calculation.\n\n\n"}
{"id": "542652", "url": "https://en.wikipedia.org/wiki?curid=542652", "title": "Visconte Maggiolo", "text": "Visconte Maggiolo\n\nVisconte Maggiolo (1478 – 1530), also spelled \"Maiollo\" and \"Maiolo\", was an Italian cartographer and sailor.\n\nHe was born in Genoa and maybe he was a fellow sailor of explorer Giovanni da Verrazzano. Some historians say that he died of malaria in 1530; but archival documents show that he was still alive, in Genoa, at least in 1549, although he certainly was already dead in 1561 (Astengo, 2007, p. 72).\n\nIn 1527, he created a map depicting Verrazzano's travels. This map had a major error (so-called \"Verrazzano Sea\" with his \"Verrazzano Isthmus\", as Giovanni did not accurately describe the North American continent. This error was not to be fixed for over a century.\n\nA copy of his map was destroyed during World War II. “Sixteenth Century Maps Destroyed in War. It has been learned with much regret that the manuscript world chart of Vesconte de Maiollo, 1527, in the Ambrosiana Library and Art Gallery in Milan, Italy, (the Biblioteca Ambrosiana)was lost through war damage. A number of libraries, including the American Geographical Society Library at UW Milwaukee, have a full size reproduction of the famous map that was issued in 1905 by the Hispanic Society of America.\"\n\nThere are other world maps made by Vesconte Maggiolo: one, by a private collector, is known to scholars for years (Astengo, 2007, p. 73: 14: “Vesconte de maiollo [SIC] composuit hanc cartam In Janua anno dominy 1531 die VIII novembri: planisfero nautico, proprietà privata”) is dated Genoa, 1531; another kept at a public library in Treviso (in Italian), is dated Genoa, 1549.\n\n\n"}
