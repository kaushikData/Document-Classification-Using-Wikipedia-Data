{"id": "15993881", "url": "https://en.wikipedia.org/wiki?curid=15993881", "title": "1000 Genomes Project", "text": "1000 Genomes Project\n\nThe 1000 Genomes Project (abbreviated as 1KGP), launched in January 2008, was an international research effort to establish by far the most detailed catalogue of human genetic variation. Scientists planned to sequence the genomes of at least one thousand anonymous participants from a number of different ethnic groups within the following three years, using newly developed technologies which were faster and less expensive. In 2010, the project finished its pilot phase, which was described in detail in a publication in the journal \"Nature\". In 2012, the sequencing of 1092 genomes was announced in a \"Nature\" publication. In 2015, two papers in \"Nature\" reported results and the completion of the project and opportunities for future research. Many rare variations, restricted to closely related groups, were identified, and eight structural-variation classes were analyzed.\n\nThe project unites multidisciplinary research teams from institutes around the world, including China, Italy, Japan, Kenya, Nigeria, Peru, the United Kingdom, and the United States. Each will contribute to the enormous sequence dataset and to a refined human genome map, which will be freely accessible through public databases to the scientific community and the general public alike.\nBy providing an overview of all human genetic variation, the consortium will generate a valuable tool for all fields of biological science, especially in the disciplines of genetics, medicine, pharmacology, biochemistry, and bioinformatics.\n\nSince the completion of the Human Genome Project, advances in human population genetics and comparative genomics have made it possible to gain increasing insight into the nature of genetic diversity. However, we are just beginning to understand how processes like the random sampling of gametes, structural variations (insertions/deletions (indels), copy number variations (CNV), and retroelements), single-nucleotide polymorphisms (SNPs), and natural selection have shaped the level and pattern of variation within species and also between species.\n\nThe random sampling of gametes during sexual reproduction leads to genetic drift — a random fluctuation in the population frequency of a trait — in subsequent generations and would result in the loss of all variation in the absence of external influence. It is postulated that the rate of genetic drift is inversely proportional to population size, and that it may be accelerated in specific situations such as bottlenecks, where the population size is reduced for a certain period of time, and by the founder effect (individuals in a population tracing back to a small number of founding individuals).\n\nAnzai et al. demonstrated that indels account for 90.4% of all observed variations in the sequence of the major histocompatibility locus (MHC) between humans and chimpanzees. After taking multiple indels into consideration, the high degree of genomic similarity between the two species (98.6% nucleotide sequence identity) drops to only 86.7%. For example, a large deletion of 95 kilobases (kb) between the loci of the human \"MICA\" and \"MICB\" genes, results in a single hybrid chimpanzee \"MIC\" gene, linking this region to a species-specific handling of several retroviral infections and the resultant susceptibility to various autoimmune diseases. The authors conclude that instead of more subtle SNPs, indels were the driving mechanism in primate speciation.\n\nBesides mutations, SNPs and other structural variants such as copy-number variants (CNVs) are contributing to the genetic diversity in human populations. Using microarrays, almost 1,500 copy number variable regions, covering around 12% of the genome and containing hundreds of genes, disease loci, functional elements and segmental duplications, have been identified in the HapMap sample collection. Although the specific function of CNVs remains elusive, the fact that CNVs span more nucleotide content per genome than SNPs emphasizes the importance of CNVs in genetic diversity and evolution.\n\nInvestigating human genomic variations holds great potential for identifying genes that might underlie differences in disease resistance (e.g. MHC region) or drug metabolism.\n\nNatural selection in the evolution of a trait can be divided into three classes. Directional or positive selection refers to a situation where a certain allele has a greater fitness than other alleles, consequently increasing its population frequency (e.g. antibiotic resistance of bacteria). In contrast, stabilizing or negative selection (also known as purifying selection) lowers the frequency or even removes alleles from a population due to disadvantages associated with it with respect to other alleles. Finally, a number of forms of balancing selection exist; those increase genetic variation within a species by being overdominant (heterozygous individuals are fitter than homozygous individuals, e.g. \"G6PD\", a gene that is involved in both Hemolytic anaemia and malaria resistance) or can vary spatially within a species that inhabits different niches, thus favouring different alleles. Some genomic differences may not affect fitness. Neutral variation, previously thought to be “junk” DNA, is unaffected by natural selection resulting in higher genetic variation at such sites when compared to sites where variation does influence fitness.\n\nIt is not fully clear how natural selection has shaped population differences; however, genetic candidate regions under selection have been identified recently. Patterns of DNA polymorphisms can be used to reliably detect signatures of selection and may help to identify genes that might underlie variation in disease resistance or drug metabolism. Barreiro et al. found evidence that negative selection has reduced population differentiation at the amino acid–altering level (particularly in disease-related genes), whereas, positive selection has ensured regional adaptation of human populations by increasing population differentiation in gene regions (mainly nonsynonymous and 5'-untranslated region variants).\n\nIt is thought that most complex and Mendelian diseases (except diseases with late onset, assuming that older individuals no longer contribute to the fitness of their offspring) will have an effect on survival and/or reproduction, thus, genetic factors underlying those diseases should be influenced by natural selection. Although, diseases that have late onset today could have been childhood diseases in the past as genes delaying disease progression could have undergone selection. Gaucher disease (mutations in the \"GBA\" gene), Crohn's disease (mutation of \"NOD2\") and familial hypertrophic cardiomyopathy (mutations in \"MYH7\", \"TNNT2\", \"TPM1\" and \"MYBPC3\") are all examples of negative selection. These disease mutations are primarily recessive and segregate as expected at a low frequency, supporting the hypothesized negative selection. There is evidence that the genetic-basis of Type 1 Diabetes may have undergone positive selection. Few cases have been reported, where disease-causing mutations appear at the high frequencies supported by balanced selection. The most prominent example is mutations of the \"G6PD\" locus where, if homozygous G6PD enzyme deficiency and consequently Hemolytic anaemia results, but in the heterozygous state are partially protective against malaria. Other possible explanations for segregation of disease alleles at moderate or high frequencies include genetic drift and recent alterations towards positive selection due to environmental changes such as diet or genetic hitch-hiking.\n\nGenome-wide comparative analyses of different human populations, as well as between species (e.g. human versus chimpanzee) are helping us to understand the relationship between diseases and selection and provide evidence of mutations in constrained genes being disproportionally associated with heritable disease phenotypes. Genes implicated in complex disorders tend to be under less negative selection than Mendelian disease genes or non-disease genes.\n\nThere are two kinds of genetic variants related to disease. The first are rare genetic variants that have a severe effect predominantly on simple traits (e.g. Cystic fibrosis, Huntington disease). The second, more common, genetic variants have a mild effect and are thought to be implicated in complex traits (e.g. cognition, diabetes, heart disease). Between these two types of genetic variants lies a significant gap of knowledge, which the 1000 Genomes Project is designed to address.\n\nThe primary goal of this project is to create a complete and detailed catalogue of human genetic variations, which in turn can be used for association studies relating genetic variation to disease. By doing so the consortium aims to discover >95 % of the variants (e.g. SNPs, CNVs, indels) with minor allele frequencies as low as 1% across the genome and 0.1-0.5% in gene regions, as well as to estimate the population frequencies, haplotype backgrounds and linkage disequilibrium patterns of variant alleles.\n\nSecondary goals will include the support of better SNP and probe selection for genotyping platforms in future studies and the improvement of the human reference sequence. Furthermore, the completed database will be a useful tool for studying regions under selection, variation in multiple populations and understanding the underlying processes of mutation and recombination.\n\nThe human genome consists of approximately 3 billion DNA base pairs and is estimated to carry around 20,000 protein coding genes. In designing the study the consortium needed to address several critical issues regarding the project metrics such as technology challenges, data quality standards and sequence coverage.\n\nOver the course of the next three years, scientists at the Sanger Institute, BGI Shenzhen and the National Human Genome Research Institute’s Large-Scale Sequencing Network are planning to sequence a minimum of 1,000 human genomes. Due to the large amount of sequence data that need to be generated and analyzed it is possible that other participants may be recruited over time.\n\nAlmost 10 billion bases will be sequenced per day over a period of the two year production phase. This equates to more than two human genomes every 24 hours; a groundbreaking capacity. Challenging the leading experts of bioinformatics and statistical genetics, the sequence dataset will comprise 6 trillion DNA bases, 60-fold more sequence data than what has been published in DNA databases over the past 25 years.\n\nTo determine the final design of the full project three pilot studies were designed and will be carried out within the first year of the project. The first pilot intends to genotype 180 people of 3 major geographic groups at low coverage (2x). For the second pilot study, \nthe genomes of two nuclear families (both parents and an adult child) are going to be sequenced with deep coverage (20x per genome). The third pilot study involves sequencing the coding regions (exons) of 1,000 genes in 1,000 people with deep coverage (20x).\n\nIt has been estimated that the project would likely cost more than $500 million if standard DNA sequencing technologies were used. Therefore, several new technologies (e.g. Solexa, 454, SOLiD) will be applied, lowering the expected costs to between $30 million and $50 million. The major support will be provided by the Wellcome Trust Sanger Institute in Hinxton, England; the Beijing Genomics Institute, Shenzhen (BGI Shenzhen), China; and the NHGRI, part of the National Institutes of Health (NIH).\n\nIn keeping with Fort Lauderdale principles, all genome sequence data (including variant calls) is freely available as the project progresses and can be downloaded via ftp from the 1000 genomes project webpage.\n\nBased on the overall goals for the project, the samples will be chosen to provide power in populations where association studies for common diseases are being carried out. Furthermore, the samples do not need to have medical or phenotype information since the proposed catalogue will be a basic resource on human variation.\n\nFor the pilot studies human genome samples from the HapMap collection will be sequenced. It will be useful to focus on samples that have additional data available (such as ENCODE sequence, genome-wide genotypes, fosmid-end sequence, structural variation assays, and gene expression) to be able to compare the results with those from other projects.\n\nComplying with extensive ethical procedures, the 1000 Genomes Project will then use samples from volunteer donors. The following populations will be included in the study: Yoruba in Ibadan (YRI), Nigeria; Japanese in Tokyo (JPT); Chinese in Beijing (CHB); Utah residents with ancestry from northern and western Europe (CEU); Luhya in Webuye, Kenya (LWK); Maasai in Kinyawa, Kenya (MKK); Toscani in Italy (TSI); Peruvians in Lima, Peru (PEL); Gujarati Indians in Houston (GIH); Chinese in metropolitan Denver (CHD); people of Mexican ancestry in Los Angeles (MXL); and people of ancestry in the southwestern United States (ASW).\n<nowiki>*</nowiki> Population that was collected in diaspora\n\nData generated by the 1000 Genomes Project is widely used by the genetics community, making the first 1000 Genomes Project one of the most cited papers in biology. To support this user community, the project held a community analysis meeting in July 2012 that included talks highlighting key project discoveries, their impact on population genetics and human disease studies, and summaries of other large scale sequencing studies.\n\nThe pilot phase consisted of three projects:\nIt was found that on average, each person carries around 250-300 loss-of-function variants in annotated genes and 50-100 variants previously implicated in inherited disorders. Based on the two trios, it is estimated that the rate of de novo germline mutation is approximately 10 per base per generation.\n\n\n"}
{"id": "55794161", "url": "https://en.wikipedia.org/wiki?curid=55794161", "title": "Andrea Weiss (filmmaker)", "text": "Andrea Weiss (filmmaker)\n\nAndrea Weiss is an independent documentary filmmaker, author, and professor of film/video at the City College of New York where she co-directs the MFA Program in Film. She was the archival research director for the documentary \"Before Stonewall: The Making of a Gay and Lesbian Community\", for which she won an News & Documentary Emmy Award. She is also a historian, with a Ph.D. in History from Rutgers University. She co-founded a non-profit film company, Jezebel Productions, with partner Greta Schiller, in 1984. She is the author of: \"In The Shadow of the Magic Mountain: The Erika and Klaus Mann Story\" which won a Publishing Triangle Award, \"Paris Was a Woman\" (reprinted by Counterpoint Press, 2013) which won a Lambda Literary Award, and \"Vampires & Violets: Lesbians in Film\" (Penguin, 1993). Her books have been translated into French, Spanish, German, Korean, Swedish, Japanese, Slovenian, and Croatian. She has been awarded fellowships from the National Endowment for the Humanities, National Endowment for the Arts, New York State Council on the Arts, and New York Foundation for the Arts as well as a U.S./Spain Fulbright Fellowship. Her 2017 feature documentary, \"Bones of Contention\", premiered in the 2017 Berlin Film Festival, won Best Documentary at the Side by Side Film Festival in Russia, and was featured at the Houston QFest, at the Outfest Los Angeles LGBT Film Festival in July 2017, and at New York's NewFest in October 2017. Additional film credits include \"International Sweethearts of Rhythm\", \"Tiny & Ruby: Hell Divin' Women\", \"Paris Was a Woman\", \"Escape to Life: The Erika and Klaus Mann Story\" (co-directed with Wieland Speck), and \"A Bit of Scarlet\", among others. She has lived in London, Berlin, and Barcelona, and currently resides in New York City.\n\n"}
{"id": "53623399", "url": "https://en.wikipedia.org/wiki?curid=53623399", "title": "Association for Research on Nonprofit Organizations and Voluntary Action", "text": "Association for Research on Nonprofit Organizations and Voluntary Action\n\nThe Association for Research on Nonprofit Organizations and Voluntary Action (ARNOVA) was founded and incorporated in 1971 by David Horton Smith, with the help of Burt R. Baldwin, Richard D. Reddy, and Eugene D. White, Jr. as the Association for Voluntary Action Scholars (AVAS).\n\nThe vision of the founders was to create an independent and impartial forum for researchers in the fledgling field of voluntary action and citizen participation. For a long time, AVAS’ annual conferences and quarterly journal were the only outlets available to scholars interested in this area of research.\n\nAVAS originally held parallel conferences with the Association for Volunteer Administration and the Association of Volunteer Bureaus. The first conference was held in Denver, Colorado in 1974. The first solo conference was held in 1982 in Lansing, Michigan. These annual conventions allowed the organization to fulfill its purpose, as stated in the by-laws, to \"stimulate, coordinate, and otherwise aid the efforts of those engaged in research, other scholarship and professional activity related to the understanding and improvement of nonprofit organizations and voluntary action\" by creating a face-to-face forum for idea exchange.\n\nAVAS’ publications were a major part of its contribution to the research community. The newsletter begun in 1973 and contained information about events and individuals in the research community as well as information specific to the organization. Citizen Participation and Voluntary Action Abstracts appeared originally as a supplement to the first newsletter, bringing together a variety of resources for researchers working in this interdisciplinary field. Volunteer Administration was published by AVAS until 1982, and is now published by the Association of Volunteer Administrators as the \"Journal of Volunteer Administration\". The \"Journal of Voluntary Action Research (JVAR)\" begun in 1972 and was, for a long time, the only scholarly journal focusing on all aspects of voluntary action research. In 1986 JVAR attempted to broaden its focus to include the rapidly growing field of nonprofit study by adding a subtitle: Studies of Voluntarism, Citizen Participation, Philanthropy, and Nonprofit Organizations. 1988 heralded a new publisher for the journal, and an entirely new name- Nonprofit and Voluntary Sector Quarterly (NVSQ). More recently, the organization has collaborated with the Indiana University Center on Philanthropy on Research in Progress.\n\nARNOVA’s executive office moved from its original home at Boston College to Pennsylvania State University, and then again to the Lincoln Filene Center at Tufts University in 1986. In 1990 the office moved again to become loosely affiliated with the Department of Adult and Youth Education at Washington State University. Continuing financial problems and low membership throughout the 1980s caused Delwyn A. Dyer to convene a Strategic Planning Committee in 1988. Following the committee’s recommendation, the Board of Directors voted to change the organization’s name from the narrowly focused Association for Voluntary Action Scholars to the more inclusive Association of Researchers on Nonprofit Organizations and Voluntary Action (ARNOVA).\n\nThe planning process continued at a retreat on February 8–10, 1991, in Corpus Christi, Texas. Board members focused on the need to upgrade the association’s services, enhance its reputation, and reach out to include a diverse, interdisciplinary group of researchers and practitioners interested in voluntary action and nonprofit study. Following the retreat, Kirsten Gronbjerg (co-president 1993-1994) prepared a document stating ARNOVA’s goals to present to possible funders.\n\nA second retreat was held at lifetime member David Mason’s ranch on March 19–21, 1993. Decisions made at the Mason Ranch Retreat resulted in the formalization of ARNOVA’s relationships with Independent Sector and the academic centers, and the affiliation of NVSQ with the Program on Non-Profit Organizations (PONPO) at Yale University and the executive office with the Indiana University Center on Philanthropy in 1994. These affiliations strengthened ARNOVA’s position as a research organization. Consequent funding from the Ford Foundation and the Kellogg Foundation gave the organization the wherewithal to become the \"interdisciplinary fellowship of scholars\" its founders had envisioned.\n\n"}
{"id": "16490030", "url": "https://en.wikipedia.org/wiki?curid=16490030", "title": "Astudillo Glacier", "text": "Astudillo Glacier\n\nAstudillo Glacier () is a small glacier flowing into Paradise Harbor between Leith Cove and Skontorp Cove on the Danco Coast of Graham Land. The glacier was surveyed by the Chilean Antarctic Expedition of 1950–51, which applied the name, probably after an expedition member.\n\n"}
{"id": "30335048", "url": "https://en.wikipedia.org/wiki?curid=30335048", "title": "Bunch–Davies vacuum", "text": "Bunch–Davies vacuum\n\nIn quantum field theory in curved spacetime, there is a whole class of quantum states over a background de Sitter space which are invariant under all the isometries: the alpha-vacua. Among them there is a particular one whose associated Green functions verify a condition (Hadamard condition) consisting to behave on the light-cone as in flat space. This state is usually called the Bunch–Davies vacuum or Euclidean vacuum,\nactually was first obtained by N.A. Chernikov and E. A. Tagirov, in 1968 and later by C. Schomblond and P. Spindel, in 1976, in the framework of a general discussion about invariant Green functions on de Sitter space.\nThe Bunch–Davies vacuum can also be described as being generated by an infinite time trace from the condition that the scale of quantum fluctuations is much smaller than the Hubble scale. The state possesses no quanta at the asymptotic past infinity.\n\nThe Bunch-Davies state is the zero-particle state as seen by a geodesic observer, that is, an observer who is in free fall in the expanding state. The state explains the origin of cosmological perturbation fluctuations in inflationary models.\n\n"}
{"id": "293128", "url": "https://en.wikipedia.org/wiki?curid=293128", "title": "Burke and Wills expedition", "text": "Burke and Wills expedition\n\nThe Burke and Wills expedition was organised by the Royal Society of Victoria in Australia in 1860–61 of 19 men, led by Robert O'Hara Burke and William John Wills, with the objective of crossing Australia from Melbourne in the south, to the Gulf of Carpentaria in the north, a distance of around 3,250 kilometres (approximately 2,000 miles). At that time most of the inland of Australia had not been explored by non-Indigenous people and was largely unknown to the European settlers.\n\nThe expedition left Melbourne in winter. Bad weather, poor roads and broken-down wagons meant they made slow progress at first. After dividing the party at Menindee on the Darling River Burke made good progress, reaching Cooper Creek at the beginning of summer. The expedition established a depot camp at the Cooper, and Burke, Wills and two other men pushed on to the north coast (although swampland stopped them from reaching the northern coastline).\n\nThe return journey was plagued by delays and monsoon rains, and when they reached the depot at Cooper Creek, they found it had been abandoned just hours earlier. Burke and Wills died on or about 30 June 1861. Several relief expeditions were sent out, all contributing new geographical findings. All together, seven men lost their lives, and only one man, the Irish soldier John King crossed the continent with the expedition and returned alive to Melbourne.\n\nGold was discovered in Victoria in 1851 and the subsequent gold rush led to a huge influx of migrants, with the local population increasing from 29,000 in 1851 to 139,916 in 1861 (Sydney had 93,686 at the time). The colony became very wealthy and Melbourne grew rapidly to become Australia's largest city and the second largest city of the British Empire. The boom lasted forty years and ushered in the era known as \"marvellous Melbourne\". The influx of educated gold seekers from England, Ireland and Germany led to rapid growth of schools, churches, learned societies, libraries and art galleries. The University of Melbourne was founded in 1855 and the State Library of Victoria in 1856. The Philosophical Institute of Victoria was founded in 1854 and became the Royal Society of Victoria after receiving a Royal Charter in 1859.\n\nBy 1855 there was speculation about possible routes for the Australian Overland Telegraph Line to connect Australia to the new telegraph cable in Java and then Europe. There was fierce competition between the colonies over the route with governments recognising the economic benefits that would result from becoming the centre of the telegraph network. A number of routes were considered including Ceylon to Albany in Western Australia, or Java to the north coast of Australia and then either onto east coast, or south through the centre of the continent to Adelaide. The Victorian government organised the Burke and Wills expedition to cross the continent in 1860. The South Australian government offered a reward of £2000 to encourage an expedition to find a route between South Australia and the north coast.\n\nIn 1857 the Philosophical Institute formed an \"Exploration Committee\" with the aim of investigating the practicability of fitting out an exploring expedition. While interest in inland exploration was strong in the neighbouring colonies of New South Wales and South Australia, in Victoria enthusiasm was limited. Even the anonymous donation of £1,000 (later discovered to be from Ambrose Kyte) to the \"Fund Raising Committee\" of the Royal Society failed to generate much interest and it was 1860 before sufficient money was raised and the expedition was assembled.\n\nThe Exploration Committee called for offers of interest for a leader for the \"Victorian Exploring Expedition\". Only two members of the Committee, Ferdinand von Mueller and Wilhelm Blandowski, had any experience in exploration but due to factionalism both were consistently outvoted. Several people were considered for the post of leader and the Society held a range of meetings in early 1860. Robert O'Hara Burke was selected by committee ballot as the leader, and William John Wills was recommended as surveyor, navigator and third-in-command. Burke had no experience in exploration and it is strange that he was chosen to lead the expedition. Burke was an Irish-born ex-officer with the Austrian army, and later became police superintendent with virtually no skills in bushcraft. Wills was more adept than Burke at living in the wilderness, but it was Burke's leadership that was especially detrimental to the mission.\n\nRather than take cattle to be slaughtered during the trip the Committee decided to experiment with dried meat. The weight required three extra wagons and was to slow the expedition down appreciably.\n\nThe Exploration Committee of the Royal Society of Victoria included:\n\n\nCamels had been used successfully in desert exploration in other parts of the world, but by 1859 only seven camels had been imported into Australia.\nThe Victorian Government appointed George James Landells to purchase 24 camels in India for use in desert exploration. The animals arrived in Melbourne in June 1860 and the Exploration Committee purchased an additional six from George Coppin's Cremorne Gardens. The camels were initially housed in the stables at Parliament House and later moved to Royal Park. Twenty-six camels were taken on the expedition, with six (two females with their two young calves and two males) being left in Royal Park.\n\nThe expedition set off from Royal Park, Melbourne at about 4 pm on 20 August 1860 watched by around 15,000 spectators. The 19 men of the expedition included six Irishmen, five Englishmen, three Afghan and one Indian camel drivers, three Germans and an American. They took 23 horses, 6 wagons and 26 camels.\n\nThe expedition took a large amount of equipment, including enough food to last two years, a cedar-topped oak camp table with two chairs, rockets, flags and a Chinese gong; the equipment all together weighed as much as 20 tonnes. As committee member Captain Francis Cadell had opposed his appointment as leader of the expedition, Burke refused his offer to transport the supplies to Adelaide by ship and then up the Murray and Darling Rivers to be collected on the way; everything was instead loaded onto six wagons. One wagon broke down before it had even left Royal Park and by midnight of the first day the expedition had reached only Essendon on the edge of Melbourne. At Essendon two more wagons broke down. Heavy rains and bad roads made travelling through Victoria difficult and time-consuming. The party arrived at Lancefield on 23 August and set up their fourth camp. The first day off was taken on Sunday, 26 August at Camp VI in Mia Mia.\n\nThe expedition reached Swan Hill on 6 September and arrived in Balranald on 15 September. There, to lighten the load, they left behind their sugar, lime juice and some of their guns and ammunition. At Gambala on 24 September, Burke decided to load some of the provisions onto the camels for the first time, and to lessen the burden on the horses he ordered the men to walk. He also ordered that personal luggage be restricted to . At Bilbarka on the Darling, Burke and his second-in-command, Landells, argued after Burke decided to dump the 60 gallons (≈270 litres) of rum that Landells had brought to feed to the camels in the belief that it prevented scurvy. At Kinchega on the Darling, Landells resigned from the expedition, followed by the expedition's surgeon, Dr Hermann Beckler. Third-in-command Wills was promoted to second-in-command. They reached Menindee on 12 October having taken two months to travel from Melbourne—the regular mail coach did the journey in little more than a week. Two of the expedition's five officers had resigned, thirteen members of the expedition had been fired and eight new men had been hired.\n\nIn July 1859 the South Australian government offered a reward of £2,000 (about A$289,000 in 2011 dollars) for the first successful south-north crossing of the continent west of the 143rd line of longitude. The experienced explorer John McDouall Stuart had taken up the challenge. Burke was concerned Stuart might beat him to the north coast and he soon grew impatient with their slow progress often averaging only an hour. Burke split the group, taking the strongest horses, seven of the fittest men and a small amount of equipment, with plans to push on quickly to Cooper Creek (then known as Cooper's Creek) and then wait for the others to catch up. They left Menindee on 19 October, guided by William Wright who was appointed third-in-command. Travel was relatively easy because recent rain made water abundant, while in unusually mild weather temperatures exceeded only twice before the party reached Cooper Creek. At Torowotto Swamp Wright was sent back to Menindee alone to bring up the remainder of the men and supplies and Burke continued on to Cooper Creek.\n\nIn 1860 Cooper Creek was the outer limit of the land that had been explored by Europeans, the river having been visited by Captain Charles Sturt in 1845 and Augustus Charles Gregory in 1858. Burke arrived at the Cooper on 11 November and they formed a depot at Camp LXIII (Camp 63) while they conducted reconnaissance to the north. A plague of rats forced the men to move camp and they formed a second depot further downstream at Bullah Bullah Waterhole. This was Camp LXV (Camp 65) and they erected a stockade and named the place Fort Wills.\n\nIt was thought that Burke would wait at Cooper Creek until autumn (March the next year) so that they would avoid having to travel during the hot Australian summer. However, Burke waited only until Sunday, 16 December before deciding to make a dash for the Gulf of Carpentaria. He split the group again, leaving William Brahe in charge of the depot, with Dost Mahomet, William Patton and Thomas McDonough. Burke, Wills, John King and Charles Gray set off for the Gulf with six camels, one horse and enough food for just three months. By now it was mid-summer and the daily temperature often reached in the shade, and in the Strzelecki and Sturt Stony Deserts there was very little shade to be found. Brahe was ordered by Burke to wait for three months; however, the more conservative Wills had reviewed the maps and developed a more realistic view of the task ahead, and secretly instructed Brahe to wait for four months.\n\nExcept for the heat, travel was easy. As a result of recent rains water was still easy to find and the Aborigines, contrary to expectations, were peaceful. On 9 February 1861 they reached the Little Bynoe River, an arm of the Flinders River delta, where they found they could not reach the ocean because of the mangrove swamps in their way. Burke and Wills left the camels behind with King and Gray at Camp CXIX (Camp 119), and set off through the swamps, although after they decided to turn back. By this stage, they were desperately short of supplies. They had food left for 27 days, but it had already taken them 59 days to travel from Cooper Creek.\nOn their way north, the weather had been hot and dry, but on the way back the wet season broke and the tropical monsoonal rains began. A camel named \"Golah Sing\" was abandoned on 4 March when it was unable to continue. Three other camels were shot and eaten along the way and they shot their only horse, \"Billy\", on 10 April on the Diamantina River, south of what is today the town of Birdsville. Equipment was abandoned at a number of locations as the number of pack animals was reduced. One of these locations, \"Return Camp 32\", was relocated in 1994 and The Burke and Wills Historical Society mounted an expedition to verify the discovery of camel bones in 2005.\n\nTo extend their food supply, they ate portulaca. Gray also caught an Python (probably \"Aspidites melanocephalus\", a black-headed python), which they ate. Both Burke and Gray immediately came down with dysentery. Gray was ill, but Burke thought he was \"gammoning\" (pretending). On 25 March on the Burke River (just south of what is now the town of Boulia), Gray was caught stealing skilligolee (a type of watery porridge) and Burke beat him. By 8 April, Gray could not walk; he died on 17 April of dysentery at a place they called Polygonum Swamp. The location of Gray's death is unknown, although it is generally believed to be Lake Massacre in South Australia. While the possibility that Burke killed Gray has been discounted, the severity of the beating Burke gave has been widely debated. The three surviving men stopped for a day to bury Gray, and to recover their strength—they were by this stage very weak from hunger and exhaustion. They finally reached Cooper Creek on 21 April, only to find that the camp had been abandoned several hours earlier.\n\nBurke had asked Brahe and the depot party to remain at the camp on the Cooper for 13 weeks. The party had actually waited for 18 weeks and was running low on supplies and starting to feel the effects of scurvy; they had come to believe that Burke would never return from the Gulf. After one of his men had injured his leg, Brahe decided to return to Menindee, but before leaving buried some provisions in case Burke did return, and blazed (cut or carved) a message on a tree to mark the spot.\n\nBrahe left the depot on Cooper Creek on the morning of Sunday, 21 April 1861. Burke, Wills and King returned that evening. Finding the camp deserted, they dug up the cache of supplies, and a letter explaining that the party had given up waiting and had left. Burke's team had missed them by only nine hours. The three men and two remaining camels were exhausted; they had no hope of catching up to the main party.\nThey decided to rest and recuperate, living off the supplies left in the cache. Wills and King wanted to follow their outward track back to Menindee, but Burke overruled them and decided to attempt to reach the furthest outpost of pastoral settlement in South Australia, a cattle station near Mount Hopeless. This would mean travelling southwest through the desert for . They wrote a letter explaining their intentions and reburied it in the cache under the marked tree in case a rescue party visited the area. Unfortunately, they did not change the mark on the tree or alter the date. On 23 April they set off, following the Cooper downstream and then heading out into the Strzelecki Desert towards Mount Hopeless.\n\nMeanwhile, while returning to Menindee, Brahe had met with Wright trying to reach the Cooper with the supplies. The two men decided to go back to Cooper Creek to see if Burke had returned. When they arrived on Sunday, 8 May, Burke had already left for Mount Hopeless, and the camp was again deserted. Burke and Wills were away by this point. As the mark and date on the tree were unaltered, Brahe and Wright assumed that Burke had not returned, and did not think to check whether the supplies were still buried. They left to rejoin the main party and return to Menindee.\n\nBrahe might have stayed at Cooper Creek longer, but one of his men, the blacksmith Patton, had injured his leg after being thrown from his horse, so they decided to leave for Menindee that morning. Patton was to die from complications six weeks later. Burke and Wills discussed catching up with them, but they were too exhausted and decided to wait.\n\nMeanwhile, the other mission led by William Wright was having terrible problems of its own. Wright was supposed to bring supplies up from Menindee to Cooper Creek, but it was the end of January 1861 before he managed to set out from Menindee. Wright's delay subsequently resulted in his being blamed for the deaths of Burke and Wills. Alan Moorehead wrote of the 'mystery' surrounding Wright's delay;\n\nAn in-depth study of Wright's action formed a part of Tom Bergin's 1982 MA thesis at the University of New England. Bergin showed that a lack of money and too few pack animals to carry the supplies meant Wright was placed in an unenviable position. His requests to the Exploration Committee were not acted on until early January, by which time the hot weather and lack of water meant that the party moved extremely slowly. They were harassed by the Bandjigali and Karenggapa Murris, and three of the men, Dr Ludwig Becker, Charles Stone and William Purcell, died from malnutrition on the trip. On his way north, Wright camped at Koorliatto Waterhole on the Bulloo River while he tried to find Burke's tracks to Cooper Creek. While he was there he met Brahe, who was on his way back from the Cooper to Menindee.\n\nThe tree () at the depot camp that Brahe blazed to mark the location of the buried supplies on the banks of Bullah Bullah Waterhole on Cooper Creek is a coolibah (\"Eucalyptus coolabah\" formerly \"Eucalyptus microtheca\") estimated to be around 250 years old. Initially the tree was known as \"Brahe's Tree\" or the \"Depot Tree\" and the tree under which Burke died attracted most attention and interest. This tree has been known as the \"Dig Tree\" from at least 1912 . As a result of the blaze on the tree and the subsequent popularity of the book \"Dig\" written in 1935 by Frank Clune, the name \"Dig Tree\" became popular. There are three separate blazes on the tree; the camp number, a date blaze and the instruction to dig. Two of the blazes have grown closed and only the camp number blaze remains visible today.\n\nThe date blaze indicated the date of arrival and the date of departure \"DEC-6-60\" carved over \"APR-21-61\". The camp number blaze shows the initial \"B\" (for Burke) carved over the Roman numerals for (camp) 65; \"B\" over \"LXV\". The exact \"DIG\" inscription that Brahe carved is not known. It is variously recalled to be \"DIG under\" or \"DIG 3 FT N.W.\" or \"DIG 40 FT N.E.\" or \"DIG 21 APR 61\" or a combination of these.\n\nIn 1899 John Dick carved a likeness of Burke's face in a nearby tree along with his initials, his wife's initials and the date.\n\nAfter leaving the \"Dig Tree\" they rarely travelled more than a day. One of the two remaining camels, \"Landa\", became bogged in Minkie Waterhole and the other, \"Rajah\" was shot when he could travel no further. Without pack animals, Burke, Wills and King were unable to carry enough water to leave Cooper Creek and cross the Strzelecki Desert to Mount Hopeless, and so the three men were unable to leave the creek. Their supplies were running low and they were malnourished and exhausted. The Cooper Creek Aborigines, the Yandruwandha people, gave them fish, beans called \"padlu\" and a type of damper made from the ground sporocarps of the \"ngardu\" (nardoo) plant (\"Marsilea drummondii\") in exchange for sugar.\n\nAt the end of May 1861, Wills returned to the \"Dig Tree\" to put his diary, notebook and journals in the cache for safekeeping. Burke bitterly criticised Brahe in his journal for not leaving behind any supplies or animals. While Wills was away from camp, Burke foolishly shot his pistol at one of the Aborigines, causing the whole group to flee. Within a month of the Aborigines' departure, Burke and Wills both perished.\n\nTowards the end of June 1861 as the three men were following the Cooper upstream to find the Yandruwandha campsite, Wills became too weak to continue. He was left behind at his own insistence at Breerily Waterhole with some food, water and shelter. Burke and King continued upstream for another two days until Burke became too weak to continue. The next morning Burke died. King stayed with his body for two days and then returned downstream to Breerily Waterhole, where he found that Wills had died as well.\n\nThe exact dates on which Burke and Wills died are unknown and different dates are given on various memorials in Victoria. The Exploration Committee fixed 28 June 1861 as the date both explorers died. King found a group of Yandruwandha willing to give him food and shelter and in return he shot birds to contribute to their supplies.\n\nIn all, six expeditions were sent to search for Burke and Wills, two commissioned by the Exploration Committee, three by the Royal Society of Victoria and one by the Government of South Australia. Two went by sea in order to search the Gulf of Carpentaria for the missing expedition while the others began their search from different directions.\n\nAfter six months without receiving word from the Burke expedition, the media began questioning its whereabouts. Public pressure for answers increased and on 13 June 1861, the Exploration Committee agreed to send a search party to find the Burke and Wills expedition and, if necessary, offer them support. The Victorian Relief Expedition left Melbourne on 26 June 1861 under the leadership of Alfred William Howitt. At the Loddon River Howitt met Brahe, who was returning from Cooper Creek. As Brahe did not have knowledge of Burke's whereabouts, Howitt decided a much larger expedition would be required to find the missing party. Leaving three of his men at the river, Howitt returned to Melbourne with Brahe to update the Exploration Committee. On 30 June the expanded expedition left to follow Burke’s trail. On 3 September the party reached Cooper Creek, on 11 September the \"Dig Tree\", and four days later Edwin Welch found King living with the Yandruwandha. Over the next nine days Howitt found the remains of Burke and Wills and buried them. In pitiful condition, King survived the two-month trip back to Melbourne, and died eleven years later, aged 33, never having recovered his health. He is buried in the Melbourne General Cemetery.\n\nOn 4 August 1861, the HMCSS \"Victoria\" under the Command of William Henry Norman sailed from Hobson's Bay in Victoria with orders to search the Gulf of Carpentaria. Arriving in Brisbane on 24 August, the Queensland Relief Expedition boarded. The \"Victoria\" arrived at the Albert River in the Gulf at the end of September 1861. After finding traces of the explorers, the Queensland Relief Expedition disembarked and the vessel returned to Melbourne.\n\nAfter disembarking from the \"Victoria\" in November, the Queensland Relief Expedition under the leadership of William Landsborough searched the gulf coast for the missing expedition. Later it turned south and continued until it arrived in Melbourne in October 1862. Having crossed Australia from north to south, the expedition was awarded the £2000 prize for the first successful crossing of the continent.\n\nFrederick Walker led the Victorian Relief Expedition. The party, consisting of twelve mounted men, seven of them ex-troopers from the Native Police Corps, started from Rockhampton on 7 September 1861 with the goal of reaching the Gulf of Carpentaria. They found traces of Burke and followed them to Burke’s northernmost Camp, but lost the trail from there. On 4 December, they came across a group of Aborigines, killing 12 in the fight that ensued. On 7 December, Walker met up with the HMVS \"Victoria\" in the Gulf. Walker’s party went on to explore much of the Gulf region.\n\nThe South Australian House of Assembly chose John McKinlay to lead the South Australian relief expedition that left Adelaide on 16 August 1861. On 20 October the grave of a European, thought to be Charles Gray, was found at Polygonum Swamp near Cooper Creek. Finding another grave nearby, McKinlay assumed that the Burke expedition had been killed there and named the site Massacre Lake. Learning that Howitt had found the remains of Burke and Wills, McKinlay decided to search in the direction of Central Mount Stuart but was driven back by heavy rains and floods. McKinlay then made for the Gulf of Carpentaria, hoping to find the HMVS \"Victoria\" still there. By 20 May 1862, McKinlay was around five miles (8 km) from the shore of the Gulf, but the intervening country was found to be impassable and he decided to turn east and make for Port Denison on the north Queensland coast. On 2 August 1862, McKinlay reached a station on the Bowen River near Port Denison and after resting a few days the expedition reached Port Denison. The party then returned by sea to Adelaide. McKinlay received a grant of £1000 from the government and a gold watch from the Royal Geographical Society of England.\n\nThe Victorian Exploration Party was the second expedition under the guidance of Alfred Howitt and was tasked with returning Burke and Wills' remains to Melbourne. On 9 December 1861 Howitt left Melbourne for Cooper Creek. After a long stay in Menindee and again at Mount Murchison the party arrived at Cooper Creek on 25 February 1862, camping at Cullyamurra waterhole. From there Howitt undertook numerous exploratory trips into the surrounding area. On 13 April 1862, Burke's and Wills' remains were exhumed.\n\nFor the next six months Howitt explored the Australian interior before deciding in November to return to the settled areas. On 8 December the party arrived in Clare, South Australia. Howitt and the expedition's doctor continued on to Adelaide while the rest of the expedition members followed three days later by train. Burke's and Wills' remains were then taken to Melbourne, arriving on 29 December 1862.\n\nBreastplates were issued to Aboriginal people between 1815 and 1946 for faithful service, for saving the lives of non-Indigenous people and to recognise stockmen and trackers. On this trip to exhume Burke and Wills' remains, Howitt presented three breastplates commissioned by the Victorian Exploration Committee to the Yandruwandha people in appreciation of the assistance they had given to Burke, Wills and King. One of these plates is in the collection of the National Museum of Australia. The inscription on the plate states that it was presented \"for the Humanity shewn to the Explorers Burke, Wills and King 1861\".\nThese ten watercolours by S. T. Gill form a narrative story of Burke and Wills 1860-1861 expedition. The originals are held in the State Library of New South Wales DGA 15\n\nUnknown to the explorers, \"ngardu\" sporocarps contain the enzyme thiaminase, which depletes the body of vitamin B (thiamin). It is probable that they were not preparing the seedcakes in accordance with Aboriginal food preparation methods, as the food was a staple among the local people. It has been argued that they did not first process the food into a paste, which might have prevented the ill effects they suffered. Despite eating, the men got weaker and weaker. Wills wrote in his diary:My pulse is at 48 and very weak and my legs and arms are nearly skin and bone. I can only look out like Mr Micawber for something to turn up, but starvation on nardoo is by no means unpleasant, but for the weakness one feels, and the utter inability to move oneself, for as the appetite is concerned, it gives me the greatest satisfaction.\n\nAs a result, it is likely that the deaths of Burke and Wills resulted in part from a vitamin deficiency disease called beriberi. Evidence to this effect is further provided by King's account, which revealed that Burke complained of leg and back pain shortly before his death. However, other research suggests that scurvy (vitamin C deficiency) and environmental factors also contributed to their deaths.\n\n\n\nThe Victorian Government held a Commission of Enquiry into the deaths of Burke and Wills. Howitt was sent back to Cooper Creek to recover their bodies and the explorers were given a state funeral in Melbourne on Wednesday, 21 January 1863. The funeral car was modelled on the design used for the Duke of Wellington ten years earlier. There were reported to have been 40,000 spectators. Burke and Wills were buried at the Melbourne General Cemetery.\n\nIn some ways the tragic expedition was not a waste. It completed the picture of inland Australia, and proved that there was no inland sea. More importantly, each of the rescue parties sent from different parts of the continent added in some way to the understanding of the land it crossed.\n\nIn 1862 monuments were erected in Back Creek Cemetery, Bendigo, and also on the hill overlooking Castlemaine where Burke had been stationed before leading the expedition. The Victorian towns of Beechworth and Fryerstown also unveiled memorials. In 1867 Ballarat erected the Explorer's Fountain on Sturt and Lydiard Streets. Wills, his brother Tom and their father, Dr William Wills, had all lived in Ballarat.\n\nIn 1890 a monument was erected at Royal Park, the expedition's departure point in Melbourne. The plaque on the monument states:\n\nIn 1983 they were honoured on a postage stamp depicting their portraits issued by Australia Post. In August 2010 Australia Post issued four stamps to commemorate the 150th anniversary.\n\nIn 1918 a silent movie, \"A Romance of Burke and Wills Expedition of 1860\", was released. The plot is fictional and only loosely connected to the Burke and Wills expedition.\n\nIn 1985 the film, \"Burke & Wills\", was made with Jack Thompson as Burke, and Nigel Havers as Wills. Also in 1985, the spoof \"Wills & Burke\" was released with Garry McDonald as Burke and Kym Gyngell as Wills.\n\nIn November 2009 the Royal Australian Mint issued two coins, $1 and a 20 cent, to commemorate the 150th anniversary of the expedition.\n\nHeritage listings associated with the Burke and Wills expedition include:\n\n\n"}
{"id": "2323711", "url": "https://en.wikipedia.org/wiki?curid=2323711", "title": "California Science Center", "text": "California Science Center\n\nThe California Science Center (sometimes spelled California ScienCenter) is a state agency and museum located in Exposition Park, Los Angeles, next to the Natural History Museum of Los Angeles County and the University of Southern California. Billed as the West Coast's largest hands-on science center, the California Science Center is a public-private partnership between the State of California and the California Science Center Foundation. The California Natural Resources Agency oversees the California Science Center and the California African American Museum.\nFounded in 1951 as the \"California Museum of Science and Industry\", the Museum was remodeled and renamed in 1998 as the \"California Science Center\". The California Science Center hosts the California State Science Fair annually.\n\nAdmission includes access to the permanent exhibits, such as the Space Shuttle \"Endeavour\" and other prominent aircraft and spacecraft, and to various demonstrations. A separate ticket is required for the IMAX movies, most special traveling exhibitions, and special activities that include a climbing wall, motion simulator, and a high-wire bicycle.\n\nThe Center has been accredited by the American Alliance of Museums and the Association of Zoos and Aquariums, and is a member of the Association of Science and Technology Centers. The museum is also an affiliate in the Smithsonian Affiliations program.\n\nThe two-story, 45,000-square-foot exhibit features display zones with live animals and aquariums about wildlife and adaptation in different ecosystems, including a river, desert, polar region, deep sea, ocean, island and urban areas, as well as the entire planet Earth.\n\nAn area with hands-on activities and exhibits that explore innovation and invention, with themes involving construction, energy and transportation.\n\nExamines the processes of life and similarities among organisms, including food, body organs like the heart and brain, senses, defenses against threats, how living things reproduce which includes a hatching chick display, DNA, and microscopic organisms.\n\n\n\n\n\nThe museum's history dates back to the first California State Exhibition building, which opened in Exposition Park in Los Angeles in 1912, the site of an agricultural fairground from 1872 to 1910. The brick and terra cotta building, designed by William D. Coates, Jr., state architect, and N. Ellery, state engineer, displayed agriculturally-based natural resources and industrial products from across the state, including ranching, fish and game, coal mining, gold mining, oil production, and lumbering, as well as some of the state's recreational attractions. After World War II, the building also featured exhibits about state science and technology industries.\n\nIn 1951, the exhibition became the \"California Museum of Science and Industry\". The State Exhibition building was renamed in honor of major donor and trustee Howard F. Ahmanson as the Howard F. Ahmanson Building. The hands-on interactive exhibits included themes on agriculture, transportation, electricity, energy, industries, and minerals.\n\nIn 1961, the museum opened a new science wing that featured \"\", an exhibit sponsored by IBM and designed by Charles and Ray Eames to visually demonstrate fundamental mathematical concepts. Interaction stations demonstrated different concepts including celestial mechanics, the Möbius strip, multiplication, symmetry, and projective geometry. The original exhibit closed in 1998, and is now on display at the New York Hall of Science.\n\nThe Hall of Health was added in 1968.\n\nIn preparation for the 1984 Summer Olympics, the museum added new exhibits on earthquakes and economics, and a IMAX theatre. The opening and closing ceremonies for the games were held in the Los Angeles Memorial Coliseum, which is adjacent to the museum.\n\nThe California African American Museum was founded in 1981 and housed in the California Museum of Science and Industry building until 1984, when its own facility was opened adjacent to the California Aerospace Museum.\n\nIn 1994, the museum's building was damaged by the Northridge earthquake. The California Museum of Science and Industry closed in 1996 to prepare for a new facility.\n\nThe \"California Aerospace Museum\" was also opened in 1984 adjacent to and operated by the California Museum of Science and Industry to coincide with the Summer Olympics. It was also known as Aerospace Hall but also commonly known as the California Air and Space Museum/Gallery and the SKETCH Foundation Gallery, and was the first major public work of architect Frank Gehry. The museum focused on the State's history as a leader in the aviation and aerospace industries and featured a giant, hangar-like space with aircraft and space vehicles and artifacts.\n\nThe building, now known as the Air and Space Gallery, was closed in 2011. In 2012 the building was listed on the California Register of Historical Resources, but its future is unknown.\n\nIn 1988 the museum's leadership began a to develop a three-phase, 25-year master plan to transform the institution from a science museum to a science education facility. This new facility would be known as the \"California Science Center\". The original museum building closed its doors in 1996 to prepare for the new construction.\n\nThe new construction was designed by Portland, Oregon-based Zimmer Gunsul Frasca Partnership. Changes included:\n\n\nPhase I was completed and opened in 1998, when the museum was opened and officially renamed the California Science Center.\n\n\n\n\n"}
{"id": "3007465", "url": "https://en.wikipedia.org/wiki?curid=3007465", "title": "Children's literature criticism", "text": "Children's literature criticism\n\nThe term children's literature criticism includes both generalist discussions of the relationship between children's literature and literary theory and literary analyses of a specific works of children's literature. Some academics consider young adult literature to be included under the rubric of 'children's literature.'\n\nNearly every school of theoretical thought has been applied to children's literature, most commonly reader response (Chambers 1980) and new criticism. However, other schools have been applied in controversial and influential ways, including Orientalism (Nodelman 1992), feminist theory (Paul 1987), postmodernism (Stevenson 1994), structuralism (Neumeyer 1977), post-structuralism (Rose, 1984, Lesnik-Oberstein, 1994) and many others.\n\nEarly children's literature critics aimed to learn how children read literature specifically (rather than the mechanics of reading itself) so that they could recommend \"good books\" for children. These early critics were often teachers, librarians and other educationalists. The critics often disagreed about what books they think children would like, and why, and about which books will be \"good\" for children and why. Though many critics are still child-centric, the discipline has expanded to include other modes of analysis. As children's literature criticism started developing as an academic discipline (roughly in the past thirty years or so, see historical overviews by Hunt (1991) and McGillis (1997)), children's literature criticism became involved with wider work in literary theory and cultural studies.\n\nMany children's literature critics now point out that children are not one group, but differ according to gender, ethnicity, religious background, and so on. Feminist children's literature critics such as Lissa Paul (1987) therefore try to work out how boys and girls read differently, for instance. Other critics (for instance, Peter Hunt (1991), Perry Nodelman (1992), John Stephens (1992), and Roderick McGillis (1996)) take this idea a step further and argue that children are often \"colonized\" by adults, including children's literature critics, because adults speak on behalf of children instead of letting children express themselves. However, these critics too can not agree on what then are \"true\" children expressing themselves, and which books are therefore \"good\" for them. Finally, a few critics, notably Jacqueline Rose (1984) and Karin Lesnik-Oberstein (1994 and 2004) take this discussion even further, arguing that identities are created and not \"inherent\", and that in the case of an identity such as \"childhood\" it is created by \"adults\" in the light of their own perceptions of themselves. That is, \"adulthood\" defines \"childhood\" in relation to differences and similarities it perceives to itself. This post-structuralist approach is similar to that argued by critics in gender studies such as Judith Butler and is widely accepted and used in sociological and anthropological studies of childhood (Jenks 1996; Jenks, James and Prout 1997).\n\nMany scholars approach children's literature from the perspective of literary studies, examining the text \"as text\" without focus on audience. Stephens and McCallum (1998) discuss the intertextuality of children's literature, while Rose explores the identifying characteristics of the genre. Nodelman (1990) looks at the synthesis of text and illustration in picturebooks.\n\nCulture studies scholars investigate children's literature as an aspect of culture. Children's literature, in this light, is a product consumed like other aspects of children's culture: video games, television, and the like. For more analysis of children's culture in general, see Jenkins. For literature in particular as cultural artifact, see Mackey.\n\n\n\n"}
{"id": "17648921", "url": "https://en.wikipedia.org/wiki?curid=17648921", "title": "China Circle", "text": "China Circle\n\nThe China Circle refers to the economic relationship between the PRC, Hong Kong, and Taiwan. Professor Barry Naughton coined the term in his book, “The China Circle.”\n\nDuring the 1960s and 1970s, Hong Kong and Taiwan specialized in labor-intensive manufactured exports that mainly went to the United States market. By the mid-1980s, however, rising land and labor costs, coupled with current realignments, created pressures for manufacturers to move to lower-cost locations. Additionally, national capabilities moved up as scientific education increased and commercial and financial experience accumulated. This created a “pull” for Hong Kong and Taiwan to move to high-skilled sectors.\n\nAt the same time, China was opening up for foreign investment, and modeled parts of its economic reform after the successes of Taiwan and Hong Kong. This created an opportunity for Taiwan and Hong Kong firms to move their labor-intensive operations to their lower-cost neighbor, China. In the end, this created a regional production chain whereby Hong Kong and Taiwan specialized in high-value services and technology-intensive production and while the PRC took on the more labor-intensive manufacturing. This economic network is now known as “The China Circle.”\n\nNaughton attributes this move to three main factors. First, there was a global trend in increased intra-industry trade. Second, labor and land costs in China were low and access was made relatively open. Third, the common language and customs made cultural entry costs cheap.\n\n"}
{"id": "42985608", "url": "https://en.wikipedia.org/wiki?curid=42985608", "title": "Cognitive biology", "text": "Cognitive biology\n\nCognitive biology is an emerging science that regards natural cognition as a biological function. It is based on the theoretical assumption that every organism—whether a single cell or multicellular—is continually engaged in systematic acts of cognition coupled with intentional behaviors, i.e., a sensory-motor coupling. That is to say, if an organism can sense stimuli in its environment and respond accordingly, it is cognitive. Any explanation of how natural cognition may manifest in an organism is constrained by the biological conditions in which its genes survives from one generation to the next. And since by Darwinian theory the species of every organism is evolving from a common root, three further elements of cognitive biology are required: (i) the study of cognition in one species of organism is useful, through contrast and comparison, to the study of another species’ cognitive abilities; (ii) it is useful to proceed from organisms with simpler to those with more complex cognitive systems, and (iii) the greater the number and variety of species studied in this regard, the more we understand the nature of cognition.\n\nWhile cognitive science endeavors to explain human thought and the conscious mind, the work of cognitive biology is focused on the most fundamental process of cognition for any organism. In the past several decades, biologists have investigated cognition in organisms large and small, both plant and animal. “Mounting evidence suggests that even bacteria grapple with problems long familiar to cognitive scientists, including: integrating information from multiple sensory channels to marshal an effective response to fluctuating conditions; making decisions under conditions of uncertainty; communicating with conspecifics and others (honestly and deceptively); and coordinating collective behaviour to increase the chances of survival.” Without thinking or perceiving as humans would have it, an act of basic cognition is arguably a simple step-by-step process through which an organism senses a stimulus, then finds an appropriate response in its repertoire and enacts the response. However, the biological details of such basic cognition have neither been delineated for a great many species nor sufficiently generalized to stimulate further investigation. This lack of detail is due to the lack of a science dedicated to the task of elucidating the cognitive ability common to all biological organisms. That is to say, a \"science\" of cognitive biology has yet to be established. A prolegomena for such science was presented in 2007 and several authors have published their thoughts on the subject since the late 1970s. Yet as the examples in the next section suggest, there is neither consensus on the theory nor widespread application in practice.\n\nAlthough the two terms are sometimes used synonymously, cognitive biology should not be confused with the biology of cognition in the sense that it is used by adherents to the Chilean School of Biology of Cognition. Also known as the Santiago School, the biology of cognition is based on the work of Francisco Varela and Humberto Maturana, who crafted the doctrine of autopoiesis. Their work began in 1970 while the first mention of cognitive biology by Brian Goodwin (discussed below) was in 1977 from a different perspective.\n\n'Cognitive biology' first appeared in the literature as a paper with that title by Brian C. Goodwin in 1977. There and in several related publications Goodwin explained the advantage of cognitive biology in the context of his work on morphogenesis. He subsequently moved on to other issues of structure, form, and complexity with little further mention of cognitive biology. Without an advocate, Goodwin’s concept of cognitive biology has yet to gain widespread acceptance. \nAside from an essay regarding Goodwin’s conception by Margaret Boden in 1980, the next appearance of ‘cognitive biology’ as a phrase in the literature came in 1986 from a professor of biochemistry, Ladislav Kováč. His conception, based on natural principles grounded in bioenergetics and molecular biology, is briefly discussed below. Kováč’s continued advocacy has had a greater influence in his homeland, Slovakia, than elsewhere partly because several of his most important papers were written and published only in Slovakian.\n\nBy the 1990s, breakthroughs in molecular, cell, evolutionary, and developmental biology generated a cornucopia of data-based theory relevant to cognition. Yet aside from the theorists already mentioned, no one was addressing cognitive biology except for Kováč.\n\nLadislav Kováč's “Introduction to cognitive biology” (Kováč, 1986a) lists ten ‘Principles of Cognitive Biology.’ A closely related thirty page paper was published the following year: “Overview: Bioenergetics between chemistry, genetics and physics.” (Kováč, 1987). Over the following decades, Kováč elaborated, updated, and expanded these themes in frequent publications, including \"Fundamental principles of cognitive biology\" (Kováč, 2000), “Life, chemistry, and cognition” (Kováč, 2006a), \"Information and Knowledge in Biology: Time for Reappraisal” (Kováč, 2007) and \"Bioenergetics: A key to brain and mind\" (Kováč, 2008).\n\nThe concept of cognitive biology is exemplified by this seminar description:\n\nThe University of Adelaide has established a \"Cognitive Biology\" workgroup using this operating concept:\nMembers of the group study the biological literature on simple organisms (e.g., nematode) in regard to cognitive process and look for homologues in more complex organisms (e.g., crow) already well studied. This comparative approach is expected to yield simple cognitive concepts common to all organisms. “It is hoped a theoretically well-grounded toolkit of basic cognitive concepts will facilitate the use and discussion of research carried out in different fields to increase understanding of two foundational issues: what cognition is and what cognition does in the biological context.” (Bold letters from original text.)\nThe group’s choice of name, as they explain on a separate webpage, might have been ‘embodied cognition’ or ‘biological cognitive science.’ But the group chose ‘cognitive biology’ for the sake of (i) emphasis and (ii) method. For the sake of emphasis, (i) “We want to keep the focus on biology because for too long cognition was considered a function that could be almost entirely divorced from its physical instantiation, to the extent that whatever could be said of cognition almost by definition had to be applicable to both organisms and machines.” (ii) The method is to “assume (if only for the sake of enquiry) that cognition is a biological function similar to other biological functions—such as respiration, nutrient circulation, waste elimination, and so on.”\nThe method supposes that the genesis of cognition is biological, i.e., the method is \"biogenic\". The host of the group’s website has said elsewhere that cognitive biology requires a biogenic approach, having identified ten principles of biogenesis in an earlier work. The first four biogenic principles are quoted here to illustrate the depth at which the foundations have been set at the Adelaide school of cognitive biology:\n\n\n\nThe words ‘cognitive’ and ‘biology’ are also used together as the name of a category. The category of \"cognitive biology\" has no fixed content but, rather, the content varies with the user. If the content can only be recruited from \"cognitive science\", then cognitive biology would seem limited to a selection of items in the main set of sciences included by the interdisciplinary concept—cognitive psychology, artificial intelligence, linguistics, philosophy, neuroscience, and cognitive anthropology. These six separate sciences were allied “to bridge the gap between brain and mind” with an interdisciplinary approach in the mid-1970s. Participating scientists were concerned only with human cognition. As it gained momentum, the growth of cognitive science in subsequent decades seemed to offer a big tent to a variety of researchers. Some, for example, considered evolutionary epistemology a fellow-traveler. Others appropriated the keyword, as for example Donald Griffin in 1978, when he advocated the establishment of cognitive ethology.\nMeanwhile, breakthroughs in molecular, cell, evolutionary, and developmental biology generated a cornucopia of data-based theory relevant to cognition. Categorical assignments were problematic. For example, the decision to append \"cognitive\" to a body of biological research on neurons, e.g. the cognitive biology of neuroscience, is separate from the decision to put such body of research in a category named cognitive sciences. No less difficult a decision needs be made—between the computational and constructivist approach to cognition, and the concomitant issue of simulated v. embodied cognitive models—before appending biology to a body of cognitive research, e.g. the cognitive science of artificial life.\nOne solution is to consider \"cognitive biology\" only as a subset of \"cognitive science\". For example, a major publisher’s website displays links to material in a dozen domains of major scientific endeavor. One of which is described thus: “Cognitive science is the study of how the mind works, addressing cognitive functions such as perception and action, memory and learning, reasoning and problem solving, decision-making and consciousness.” Upon its selection from the display, the \"Cognitive Science\" page offers in nearly alphabetical order these topics: \"Cognitive Biology\", Computer Science, Economics, Linguistics, Psychology, Philosophy, and Neuroscience. Linked through that list of topics, upon its selection the \"Cognitive Biology\" page offers a selection of reviews and articles with biological content ranging from cognitive ethology through evolutionary epistemology; cognition and art; evo-devo and cognitive science; animal learning; genes and cognition; cognition and animal welfare; etc.\n\nA different application of the \"cognitive biology\" category is manifest in the 2009 publication of papers presented at a three-day interdisciplinary workshop on “The New Cognitive Sciences” held at the Konrad Lorenz Institute for Evolution and Cognition Research in 2006. The papers were listed under four headings, each representing a different domain of requisite cognitive ability: (i) space, (ii) qualities and objects, (iii) numbers and probabilities, and (iv) social entities. The workshop papers examined topics ranging from “Animals as Natural Geometers” and “Color Generalization by Birds” through “Evolutionary Biology of Limited Attention” and “A comparative Perspective on the Origin of Numerical Thinking” as well as “Neuroethology of Attention in Primates” and ten more with less colorful titles. “[O]n the last day of the workshop the participants agreed [that] the title ‘Cognitive Biology’ sounded like a potential candidate to capture the merging of the cognitive and the life sciences that the workshop aimed at representing.” Thus the publication of Tommasi, et al. (2009), \"Cognitive Biology: Evolutionary and Developmental Perspectives on Mind, Brain and Behavior.\"\nA final example of categorical use comes from an author’s introduction to his 2011 publication on the subject, \"Cognitive Biology: Dealing with Information from Bacteria to Minds\". After discussing the differences between the cognitive and biological sciences, as well as the value of one to the other, the author concludes: “Thus, the object of this book should be considered as an attempt at building a new discipline, that of \"cognitive biology\", which endeavors to bridge these two domains.” There follows a detailed methodology illustrated by examples in biology anchored by concepts from cybernetics (e.g., self-regulatory systems) and quantum information theory (regarding probabilistic changes of state) with an invitation \"to consider system theory together with information theory as the formal tools that may ground biology and cognition as traditional mathematics grounds physics.”\n\n\n\n"}
{"id": "2931717", "url": "https://en.wikipedia.org/wiki?curid=2931717", "title": "Conditioner (chemistry)", "text": "Conditioner (chemistry)\n\nA conditioner is a substance or process that improves the quality of another material. Conditioning agents are also called moisturizers in some cases and usually are composed of various oils and lubricants. One method of their use is coating of the substrate to alter their feel and appearance.\n\nSome materials used as conditioners include:\n\n"}
{"id": "47862666", "url": "https://en.wikipedia.org/wiki?curid=47862666", "title": "Cooking oil", "text": "Cooking oil\n\nCooking oil is plant, animal, or synthetic fat used in frying, baking, and other types of cooking. It is also used in food preparation and flavouring not involving heat, such as salad dressings and bread dips, and in this sense might be more accurately termed edible oil.\n\nCooking oil is typically a liquid at room temperature, although some oils that contain saturated fat, such as coconut oil, palm oil and palm kernel oil are solid.\n\nThere is a wide variety of cooking oils from plant sources such as olive oil, palm oil, soybean oil, canola oil (rapeseed oil), corn oil, peanut oil and other vegetable oils, as well as animal-based oils like butter and lard.\n\nOil can be flavoured with aromatic foodstuffs such as herbs, chillies or garlic.\n\nA guideline for the appropriate amount of fat—a component of daily food consumption—is established by regulatory agencies like the Food and Drug Administration. The recommendation is that 10% or fewer of daily calories should be from saturated fat, and 20-35% of total daily calories should come from polyunsaturated and monounsaturated fats.\n\nWhile consumption of small amounts of saturated fats is common in diets, meta-analyses found a significant correlation between \"high consumption\" of saturated fats and blood LDL concentration, a risk factor for cardiovascular diseases. Other meta-analyses based on cohort studies and on controlled, randomized trials found a positive, or neutral, effect from consuming polyunsaturated fats instead of saturated fats (a 10% lower risk for 5% replacement).\n\nMayo Clinic has highlighted certain oils that are high in saturated fats, including coconut, palm oil and palm kernel oil. Those having lower amounts of saturated fats and higher levels of unsaturated (preferably monounsaturated) fats like olive oil, peanut oil, canola oil, soy and cottonseed oils are generally healthier. The US National Heart, Lung and Blood Institute urged saturated fats be replaced with polyunsaturated and monounsaturated fats, listing olive and canola oils as sources of healthier monounsaturated oils while soybean and sunflower oils as good sources of polyunsaturated fats. One study showed that consumption of non-hydrogenated unsaturated oils like soybean and sunflower are preferable to the consumption of palm oil for lowering the risk of heart disease.\n\nPeanut oil, cashew oil and other nut-based oils may present a hazard to persons with a nut allergy.\n\nUnlike other dietary fats, trans fats are not essential, and they do not promote good health. The consumption of trans fats increases one's risk of coronary heart disease by raising levels of \"bad\" LDL cholesterol and lowering levels of \"good\" HDL cholesterol. Trans fats from partially hydrogenated oils are more harmful than naturally occurring oils.\n\nSeveral large studies indicate a link between the consumption of high amounts of trans fat and coronary heart disease, and possibly some other diseases. The United States Food and Drug Administration (FDA), the National Heart, Lung and Blood Institute and the American Heart Association (AHA) all have recommended limiting the intake of trans fats.\n\nHeating an oil changes its characteristics. Oils that are healthy at room temperature can become unhealthy when heated above certain temperatures, so when choosing a cooking oil, it is important to match the oil's \"heat tolerance\" with the temperature which will be used. \nDeep-fat frying temperatures are commonly in the range of , less commonly, lower temperatures ≥  are used.\n\nPalm oil contains more saturated fats than canola oil, corn oil, linseed oil, soybean oil, safflower oil, and sunflower oil. Therefore, palm oil can withstand deep frying at higher temperatures and is resistant to oxidation compared to high-polyunsaturated vegetable oils. Since about 1900, palm oil has been increasingly incorporated into food by the global commercial food industry because it remains stable in deep frying, or in baking at very high temperatures, and for its high levels of natural antioxidants, though the refined palm oil used in industrial food has lost most of its carotenoid content (and its orange-red color).\n\nThe following oils are suitable for high-temperature frying due to their high smoke point above :\n\nLess aggressive frying temperatures are frequently used. A quality frying oil has a bland flavor, at least smoke and flash points, with maximums of 0.1% free fatty acids and 3% linolenic acid. Those oils with higher linolenic fractions are avoided due to polymerization or gumming marked by increases in viscosity with age. Olive oil resists thermal degradation and has been used as a frying oil for thousands of years.\n\n\nAll oils degrade in response to heat, light, and oxygen. To delay the onset of rancidity, a blanket of an inert gas, usually nitrogen, is applied to the vapor space in the storage container immediately after production – a process called tank blanketing.\n\nIn a cool, dry place, oils have greater stability, but may thicken, although they will soon return to liquid form if they are left at room temperature. To minimize the degrading effects of heat and light, oils should be removed from cold storage just long enough for use.\n\nRefined oils high in monounsaturated fats, such as macadamia oil, keep \"up to a year\", while those high in polyunsaturated fats, such as soybean oil, keep about six months. Rancidity tests have shown that the shelf life of walnut oil is about 3 months, a period considerably shorter than the \"best before\" date shown on labels.\n\nBy contrast, oils high in saturated fats, such as avocado oil, have relatively long shelf lives and can be safely stored at room temperature, as the low polyunsaturated fat content facilitates stability.\n\nCooking oils are composed of various fractions of fatty acids. For the purpose of frying food, oils high in monounsaturated or saturated fats are generally popular, while oils high in polyunsaturated fats are less desirable. High oleic acid oils include almond, macadamia, olive, pecan, pistachio, and high-oleic cultivars of safflower and sunflower.\n\nThe smoke point is marked by \"a continuous wisp of smoke.\" It is the temperature at which an oil starts to burn, leading to a burnt flavor in the foods being prepared and degradation of nutrients and phytochemicals characteristic of the oil.\n\nAbove the smoke point are flash and fire points. The flash point is the temperature at which oil vapors will ignite but aren't produced in sufficient quantities to stay lit. The flash point generally occurs at about . The fire point is the temperature at which hot oil produces sufficient vapors they will catch on fire and burn. As frying hours increase, all these temperature points decrease. They depend more on an oil's acidity than fatty-acid profile.\n\nThe smoke point of cooking oils varies generally in association with how an oil is refined: a higher smoke point results from removal of impurities and free fatty acids. Residual solvent remaining from the refining process may decrease the smoke point. It has been reported to increase with the inclusion of antioxidants (BHA, BHT, and TBHQ). For these reasons, the published smoke points of oils may vary.\n\nOils are extracted from nuts, seeds, olives, grains or legumes by extraction using industrial chemicals or by mechanical processes. Expeller pressing is a chemical-free process that collects oils from a source using a mechanical press with minimal heat. Cold-pressed oils are extracted under a controlled temperature setting usually below intended to preserve naturally occurring phytochemicals, such as polyphenols, plant sterols and vitamin E which collectively affect color, flavor, aroma and nutrient value.\n\nCooking oil extraction and refinement are separate processes. Extraction first removes the oil, typically from a seed, nut or fruit. Refinement then alters the appearance, texture, taste, smell, or stability of the oil to meet buyer expectations.\n\nThere are three broad types of oil extraction:\n\nIn large-scale industrial oil extraction you will often see some combination of pressing, chemical extraction and/or centrifuging in order to extract the maximum amount of oil possible.\n\nCooking oil can either be unrefined, or refined using one or more of the following refinement processes (in any combination):\n\n\nFiltering, a non-chemical process which screens out larger particles, could be considered a step in refinement, although it doesn't alter the state of the oil.\nMost large-scale commercial cooking oil refinement will involve all of these steps in order to achieve a product that's uniform in taste, smell and appearance, and has a longer shelf life. Cooking oil intended for the health food market will often be unrefined, which can result in a less stable product but minimizes exposure to high temperatures and chemical processing.\n\nProper disposal of used cooking oil is an important waste-management concern. Oil can congeal on pipes provoking blockages.\n\nBecause of this, cooking oil should never be dumped in the kitchen sink or in the toilet bowl. The proper way to dispose of oil is to put it in a sealed non-recyclable container and discard it with regular garbage. Placing the container of oil in the refrigerator to harden also makes disposal easier and less messy.\n\nCooking oil can be recycled. It can be used as animal feed, directly as fuel, and to produce biodiesel, soap, and other industrial products.\n\nIn the recycling industry, used cooking oil recovered from restaurants and food-processing industries (typically from deep fryers or griddles) is called recycled vegetable oil (RVO), used vegetable oil (UVO), waste vegetable oil (WVO), or yellow grease.\n\nYellow grease is used to feed livestock, and to make soap, make-up, clothes, rubber, detergents, and biodiesel fuel.\n\nUsed cooking oil, besides being converted to biodiesel, can be used directly in modified diesel engines and for heating.\n\nGrease traps or interceptors collect fats and oils from kitchen sinks and floor drains which would otherwise clog sewer lines and interfere with septic systems and sewage treatment. The collected product is called brown grease in the recycling industry. Brown grease is contaminated with rotted food solids and considered unsuitable for re-use in most applications.\n\nGutter oil and trench oil are terms used in China to describe recycled oil processed to resemble virgin oil, but containing toxic contaminants and sold illegally for cooking; its origin is frequently brown grease from garbage.\n\nIn Kenya, thieves sell transformer oil stolen from electric transformers to operators of roadside food stalls for use in deep frying, suitable for prolonged use longer than regular cooking oil, but a threat to consumer health due to the presence of PCBs.\n\n"}
{"id": "2137836", "url": "https://en.wikipedia.org/wiki?curid=2137836", "title": "Cornering force", "text": "Cornering force\n\nCornering force or \"side force\" is the lateral (i.e., parallel to the road surface) force produced by a vehicle tire during cornering. \n\nCornering force is generated by tire slip and is proportional to slip angle at low slip angles. The rate at which cornering force builds up is described by relaxation length. Slip angle describes the deformation of the tire contact patch, and this deflection of the contact patch deforms the tire in a fashion akin to a spring.\n\nAs with deformation of a spring, deformation of the tire contact patch generates a reaction force in the tire; the cornering force. Integrating the force generated by every tread element along the contact patch length gives the total cornering force. Although the term, \"tread element\" is used, the compliance in the tire that leads to this effect is actually a combination of sidewall deflection and deflection of the rubber within the contact patch. The exact ratio of sidewall compliance to tread compliance is a factor in tire construction and inflation pressure.\n\nBecause the tire deformation tends to reach a maximum behind the center of the contact patch, by a distance known as pneumatic trail, it tends to generate a torque about a vertical axis known as self aligning torque.\n\nThe diagram is misleading because the reaction force would appear to be acting in the wrong direction. It is simply a matter of convention to quote positive cornering force as acting in the opposite direction to positive tire slip so that calculations are simplified, since a vehicle cornering under the influence of a cornering force to the left will generate a tire slip to the right.\n\nThe same principles can be applied to a tire being deformed longitudinally, or in a combination of both longitudinal and lateral directions. The behaviour of a tire under combined longitudinal and lateral deformation can be described by a traction circle.\n\n"}
{"id": "39617127", "url": "https://en.wikipedia.org/wiki?curid=39617127", "title": "Faculty of Political Science, Thammasat University", "text": "Faculty of Political Science, Thammasat University\n\nThe Faculty of Political Science, Thammasat University () is an academic faculty of Thammasat University, Ministry of Education of Thailand. The Faculty of Political Science is one of the four founding faculties of the university. It was founded in 1949 after the Faculty of Law and the Thammasat Business School, respectively, and is thereby given the code \"03\". It is also the second oldest school of political science in Thailand after the Faculty of Political Science, Chulalongkorn University.\n\nThe teaching in political science in Thailand, basically before 1932 was focused on training the people to enter the government system of Thailand. According to the course of political science is against the political system in Thailand, the field of the study in that era was limited.\nAfter the Siamese Revolution of 1932 and the continuous incidents cause the establishment of University of Moral and Political Science (former name of Thammasat University) in 1934 is the beginning of the study in field of political science in Thailand. The study of political science in the past of bachelor's degree was in the curriculum of Thammasat Bundit or 'The Science of Moral' (Thai: ธรรมศาสตร์บัณฑิต) and the master's degree was separated in 3 departments; Laws, Political Science and Economics. For doctoral degree was separated in 4 departments; Laws, Political Science, Economics and Diplomatic. \n\nIn 1948-1949, the affection of the conflict of politic from the coup on 8 November 1947 and the atmosphere of international politics that changed during that time, United States and Soviet Union had become the major powers and suspicious on each other, caused Cold War and these 2 factors cause the effects.\n\nBy that effect, the committees of University of Moral and Political Science during that era such as Professor Direk Jayanama, Professor Duen Bunnag by the leading of General Mangkorn Phromyothi as director and Professor Vijitr Lutitanon as the secretariat had agreed to establish the \"Additional Regulation of the separation of studying into 4 faculties and the specification of the academic session and exam 1949\" and that affected to the establishment of Faculty of Law, Accounting and Commerce (former name of Thammasat Business School), Political Science and Economics on 14 June 1949.\nIn the first period of the establishment of Faculty of Political Science, the first dean of faculty is Professor Direk Jayanama and another curriculum drafting committees; Professor Serm Vinijchaijul, Professor Thawee Reangkam, H.H. Princess Prem Burachat, H.S.H Luksanalert Chayangkul, Professor Dr. Puey Ungpakorn and Dr. Yuad Lertrit had comparative study over the various foreign universities curriculum such as London School of Economics or Harvard University, etc. By the academic supporting of the expert of Fulbright Foundation that coming to Thailand in that period. After that the studying of political science have been change time by time.\n\n1953, established the \"boarding department\". Student will live in the university and will be trained about the academic and disciplines.\n1955, Thammasat University had the academic supporting from United States directly and establish the department of Public Administration in master's degree, as bilingual program (Thai and English).\n1959, faculty agree to establish the department of Diplomatic in the bachelor program after opened in master's degree for a while.\n1967 (B.E. 2510); founded the department of Public Administration and Political Science study in bachelor's degree.\nIn the beginning of 1977 era (B.E. 2520), faculty had opened the courses in bachelor's and master's degrees for 4 departments; governance, public administration, international relations (former 'diplomatic') and political philosophy (former 'political science study') and terminated political philosophy departments, so it have 3 departments until nowadays.\nSince the beginning of 1987 era (B.E. 2530), after the end of Cold War and the beginning of globalization affect the political atmosphere as well as socio-economics in domestic and international cause the rapidly development of faculty. Led to the establishment of special program offered in master's degree.\nIn 1999 on the occasion of celebrating the 50 years anniversary of faculty of political science, faculty had recreated the curriculum in doctoral degree and open at Tha Prachan Campus in 2002.\nIn 2009 on the occasion of celebrating the 60 years anniversary of faculty of political science, faculty had established the new program in international program as the first combined bachelor's and master's degrees in Thailand. 'The Combined Bachelor and master's degree in Politics and International Relations (English Program)' or briefly called BMIR at Tha Prachan Campus.\n\nFaculty of Political Science of Thammasat University offers two departments in Thai and English program study at Tha Prachan Campus, center of Bangkok. This campus have been focus to be the international campus that offer to Thai student who wish to study in international standard as English program and the international student who wish to study at Thammasat University. Faculty offer 3 programs in this campus.\n\nFaculty of Political Science of Thammasat University offers three departments in Thai program study at Rangsit Campus, Pathum Thani suburban of Bangkok metropolitan area.\nFaculty of Political Science have various partners universities around the world in faculty level and also the students in the faculty can apply for the international exchange program in university level.\n\nThammasat University offer various exchange program to students for outgoing and for incoming students. For outgoing, Thammasat have various partner universities in different parts of the world. Responsible by Office of International Affairs (OIA)\n\n"}
{"id": "12684302", "url": "https://en.wikipedia.org/wiki?curid=12684302", "title": "Fauna Europaea", "text": "Fauna Europaea\n\nFauna Europaea is a database of the scientific names and distribution of all living multicellular European land and fresh-water animals. It serves as a standard taxonomic source for animal taxonomy within the Pan-European Species directories Infrastructure (PESI).\n\nIts construction was initially funded by the European Council (2000–2004). The project was co-ordinated by the University of Amsterdam which launched the first version in 2004, after which the database was transferred to the Natural History Museum Berlin in 2015.\n\n"}
{"id": "52998362", "url": "https://en.wikipedia.org/wiki?curid=52998362", "title": "Franz Firbas", "text": "Franz Firbas\n\nFranz Firbas (* June 4, 1902 in Prague; † February 19, 1964 in Göttingen) was a German botanist who taught at the University of Gottingen. From 1952-1964, he was director of their Systematisch-Geobotanisches Institut. Former students include Gerhard Lang and Heinz Ellenberg.\n\nFirbas studied at the German branch of Charles University (German Charles-Ferdinand University) under Prof. K. Rudolph. He was an assistant professor for a short time, before leaving to go to Germany.\n"}
{"id": "42748548", "url": "https://en.wikipedia.org/wiki?curid=42748548", "title": "Hellenophilia", "text": "Hellenophilia\n\nHellenophila is the idea that all western science began in Greek tradition. This is in length discussed by David Pingree in his address to colleagues. Hellenophilia is a way of thought that allows those who look into the history of science to be blinded to science that was born in other cultures. Pingree states, in explanation of the term that \"a Hellenophile suffers from a form of madness that blinds him or her to historical truth\" (Pingree, 1992, p. 554) He continues by explaining the main symptoms of Hellenophilia \"the first of these is that the Greeks invented science; the second is that they discovered a way to truth, the scientific method, that we are now successfully following; the third is that the only real sciences are those that began in Greece; and the fourth (and last?) is that the true definition of science is just that which scientists happen to be doing now, following a method or methods adumbrated by the Greeks, but never fully understood or utilized by them\" (Pingree, 1992, p. 555).\n\nAlthough Hellenophilia relates directly to the history of science it is important to look at it through aspects of history that lend to the habit, other than the symptoms listed by Pingree. One of these habits, as described by David C. Lindberg is looking at the history of science as starting with writing in fully syllabic systems. According to Lindberg the beginning of syllabic writing was around 1500 B.C., although fully alphabetic writing was apparent in Greece in 800 B.C. (Linberg, 2007, p. 10).\n"}
{"id": "1495629", "url": "https://en.wikipedia.org/wiki?curid=1495629", "title": "International Commission for Optics", "text": "International Commission for Optics\n\nThe International Commission for Optics (ICO) was created in 1947 with the objective to contribute, on an international basis, to the progress and dissemination of the science of optics and photonics and their applications. It emphasises the unity of the crossdisciplinary field of optics.\n\nOptics and photonics are defined as the fields of science and engineering encompassing the physical phenomena and technologies associated with the generation, transmission, manipulation, detection, and utilisation of light. It extends on both sides of the visible part of the electromagnetic spectrum as far as the same concepts apply.\n\nIn particular, the ICO promotes international cooperation and facilitates the rapid exchange of information, by encouraging and furthering the organisation, on an international basis, of scientific meetings and summer schools. It emphasises actions for the education and training in optics and photonics internationally. It undertakes special actions for the development of optics and photonics in regions where particular support is needed. It strives to improve the recognition of optics and photonics as fields of science with a significant impact on economy. It works also for the promotion of international agreements on nomenclature, units, symbols and standards.\n\nIt is a Scientific Associate of the International Council for Science (ICSU) and Affiliated Commission of the International Union of Pure and Applied Physics (IUPAP).\n\nAmong the activities of ICO are the organization and sponsorship of congresses, meetings and schools, and the awarding of prizes to distinguished scientists in optics and photonics. It has a Traveling Lecturer Program, and publishes quarterly the ICO Newsletter, the triennial book series International trends in optics and a Triennial Report.\n\nThe mission of the International Commission for Optics is to contribute, on an international basis, to the progress and diffusion of knowledge in the fields of optics and photonics.\n\nIn 1946 Europe was at last beginning to recover from the ordeal of World War II. The oldest and largest optics group in Europe was the Institut d'Optique in Paris, which had been founded in 1921 by the distinguished optical physicist Charles Fabry\n(1867-1945), and the director of the Institut d'Optique, Prof. Pierre Fleury, who had succeeded Fabry in 1945, was eager to resume an active role in European optics. He wrote to his optics colleagues and former students throughout Europe and invited them to participate in a Reunions d'Opticiens in Paris 14–19 October 1946. Scientists from 16 different countries participated in this first post-war European optics conference. The invited papers were by Frank Twyman (of Hilger and Watts) on the production of aspherical surfaces; Louis de Broglie on image formation, Jean Cabannes on the development of optics in France, and Pierre Fleury reviewed the history of the Institut d'Optique and research pursued since 1940. Then followed several days of contributed papers from most of the European optics groups. Many of the participants urged Fleury to seek some mechanism for continued cooperation in the optics community.\n\nPierre Fleury was already a French representative to IUPAP (the International Union of Pure and Applied Physics), with headquarters in Paris, and he was aware that the statutes of IUPAP provided for the creation of commissions in specific areas of physics; why not a commission for optics? He also determined that UNESCO (the United Nations Educational, Scientific, and Cultural Organization, with headquarters in Paris) would also be able to provide -through IUPAP- some funds for travel to a Preparatory Meeting in Prague to discuss the formation of an International Commission for Optics.\n\nIn January 1947 the General Assembly of IUPAP approved the appointment of a Preparatory Committee, with Prof. Pierre Fleury as Secretary, to consider forming an International Commission for Optics. The preparatory committee met in Prague, Czechoslovakia, 2–7 June 1947, with Prof Josef Hrdlicka as host. Fifteen delegates attended, representing eight countries, (Belgium, Czechoslovakia, France, Great Britain, Italy, the Netherlands, Poland, and Sweden). Replies were received from five other countries (Denmark, Finland, Norway, Switzerland, and the USA) that their representatives would be unable to attend, and Argentina and the USSR did not respond.\n\nThe attendees agreed that an International Commission for Optics should be formed as a self-governing affiliated commission of IUPAP. Each member country would form a national committee for ICO, which would select that country's representative to the ICO Bureau meetings. A set of provisional Statutes was adopted (patterned after the Statutes of IUPAP), and a provisional bureau was elected, (subject to approval by IUPAP and re-confirmation by the national committees at the first official meeting.) Thomas Smith of London was elected president; Pierre Fleury of Paris, secretary; Albert Arnulf of Paris, treasurer; and Josef Hrdlicka of Prague a vice-president, with two other vice-presidents to be selected at the first official meeting. The delegates decided to hold their first plenary session of ICO in conjunction with the next General Assembly of IUPAP in July 1948 in Amsterdam. (The Dutch delegate, Prof van Heel, invited the ICO to meet at his laboratory in Delft.)\n\nThe organizers also formulated the objectives of ICO: the study of optical theory, the theoretical study and construction of optical instruments, and the physiological optics of the eye. The organizers were grateful to both UNESCO and IUPAP for travel, secretarial and publication support during the initial organizational stage, but in order to ensure smooth functioning of ICO in 1948 and beyond it was decided to assess each member country for an annual contribution based on the same population scale used by IUPAP: countries with less than 5 million inhabitants, 1 unit; 5 to 10 million, 2 units; 10 to 15 million, 3 units; 15 to 20 million, 5 units; and greater than 20 million, 8 units.\n\nAs tasks to be accomplished in the near term by ICO, each national committee was asked to establish if possible a list of the names and addresses of its optics researchers and also a list of the manufacturers of optical instruments. Each country was also asked to supply a list of their optics publications for the war years 1939-1945.\n\nAs a further challenge to the new organization the delegates compiled a list of about 20 technical problem areas in optics. These subjects were assigned to various ICO national committees, with a request that each committee report on its problem at the 1948 meeting in the Netherlands. Most of the problem areas represented the special interests of the delegates present at the preparatory session, and this would provide a quick mechanism to ensure some technical content at the first formal meeting of ICO. Italy () would survey diffraction theory; Great Britain (T. Smith) would survey aberration studies (without diffraction); and France (André Maréchal) and the Netherlands would report on the combined effect of aberrations and diffraction. Sweden () would survey gratings; Great Britain, photographic objectives; and other groups were assigned other tasks. Finally, there would be reports on sign conventions, notation, tolerances and the specification of optical drawings.\n\nIn drawing up these assigned tasks the preparatory commission was following the usual format of a commission of a scientific union: stating specific problems to be reported on by the commission. In Prague the founding group had recognized the need for improved international cooperation in optics, had sketched a charter for ICO, and had planned a comprehensive program for the ICO initial meeting in 1948.\n\nThe first official meeting of ICO took place 12–17 July 1948 at the Physics Laboratory of the Technische Hogeschool, Delft, Netherlands. Forty-four delegates from eleven countries attended the meetings. At the first session Prof Fleury announced that IUPAP had cordially accepted the affiliation of ICO and had approved the Statutes provisionally adopted at Prague. The appointment of officers elected in 1947 was confirmed, and two additional vice-presidents were elected: S.S. Ballard (USA) and A.C.S. van Heel (Netherlands). Thus the eleven countries represented at Delft became the founding member countries of the ICO; Belgium, Czechoslovakia, France, Great Britain, Italy, Netherlands, Poland, Spain, Sweden, Switzerland, and the United States.\n\nIn addition to the sessions devoted to reports on the problem areas that had been assigned at Prague, the participants heard four invited lectures: by M. Françon (France); T. Smith (Great Britain); D.B. Judd (USA); and A.C.S. van Heel (Netherlands). On the first day of the meeting Prof van Heel hosted a reception at his home, and on the last evening the group held a formal dinner. During the week there were several local visits to research laboratories: de Oude Delft; the Kammerlingh-Onnes Laboratory in Leiden; the Philips Research Labs at Eindhoven; van Cittert's collection of historical optical instruments at Utrecht; and the optics and electron optics laboratories of the Technische Hogeschool, Delft. This sort of mixing of technical reports and social activities is important in building a sense of community among the attendees.\n\nThe principal work at the meeting was the presentation of detailed reports on the topics that had been assigned at Prague. These reports occupied most of the six technical sessions. The delegates also agreed that ICO should not act as a vehicle for publishing original research papers. Full use should be made of existing scientific journals..The delegates agreed that one of the roles of ICO should be to sponsor conferences at which sets of invited papers are given on some specialized field or fields of optics.\n\nAt the final session President Thomas Smith announced that he had been authorized to invite the ICO to hold the next meeting in 1950 in London. This announcement was accepted by acclamation.\n\nThe ICO Congresses are held every three years; they include a General Business Meeting as requested by the statutes and a Scientific Meeting that covers most of research topics in optics and photonics. Dates and locations of ICO Congresses:\n\n(preliminary meetings had been held in Czechoslovakia and France).\n\n\nThe provenience of ICO financial resources are the contributions from its members.\n\n(A) Associate member\n\n\n\nThe ICO Prize was established in 1982 and is presented annually to a person who has made a noteworthy contribution to Optics before reaching the age of 40.\n\n\n"}
{"id": "5941352", "url": "https://en.wikipedia.org/wiki?curid=5941352", "title": "International Union of Microbiological Societies", "text": "International Union of Microbiological Societies\n\nThe International Union of Microbiological Societies (IUMS), founded in 1927 as the International Society of Microbiology, is one of 31 Scientific Unions of the International Council for Science (ICSU).\n\nThe objectives of the Union are to promote the study of microbiological sciences internationally: initiate, facilitate and coordinate research and other scientific activities which involve international cooperation; ensure the discussion and dissemination of the results of international conferences, symposia and meetings and assist in the publication of their reports; represent microbiological sciences in ICSU and maintain contact with other international organizations.\n\nIUMS activities include the classification and nomenclature of bacteria, fungi and viruses, food microbiology, medical microbiology and diagnostics, culture collections, education, and biological standardization.\n\nThe IUMS has three divisions:\n\nThese divisions each have their own set of officers and objectives. Each division is responsible for the organization of their own International Congresses. They work together toward the goal of furthering microbiology research and communication globally. \nIn addition to the three divisions, the IUMS also conducts scientific activities through the following:\n\nThe president-elect of IUMS is Professor Eliora Ron of Tel Aviv University.\n\n"}
{"id": "45006576", "url": "https://en.wikipedia.org/wiki?curid=45006576", "title": "Janssen (Martian crater)", "text": "Janssen (Martian crater)\n\nJanssen Crater is an impact crater in the Arabia quadrangle on Mars at 2.7° N and 322.5° W. and is 158.0 km in diameter, it is also in the north of Terra Sabaea. Its name was approved in 1973, and it was named after Pierre Janssen. Some close up images of the crater reveal layers in a floor deposit. A picture below show these layers, as well as dark slope streaks. The darker the streak, the younger it is. The layers on the floor of Janssen may have been formed on the bottom of lakes.\n\nNearby prominent and named craters include Teisserenc de Bort crater in the east, Tuscaloosa to the west and the large Tikhonravov for the north. Some tens of kilometers to the west is a valley known as Naktong Vallis.\n\n"}
{"id": "41132820", "url": "https://en.wikipedia.org/wiki?curid=41132820", "title": "Kanagram", "text": "Kanagram\n\nKanagram is an educational game that creates anagrams, re-assortment of letters in a word, and the user needs to guess what the original word is. It is licensed under the GNU Public License v2, and it is part of the kdeedu package, and the user interface is designed to be approachable even by very young children. There is no time limit or limitations at attempts, and a hint system is built in.\n\nThe world list for Kanagram is user editable, with several default word lists included. A vocabulary editor is included, and the user can download other word lists or distribute their created word lists via the KNewStuff service.\n\nKanagram first appeared in the release of KDE 3.5, and replaced the previous program, KMessedWords. The user interface has been reworked to be more user friendly, and uses skeuomorphism appearing as a chalkboard.\n\n\n"}
{"id": "19701580", "url": "https://en.wikipedia.org/wiki?curid=19701580", "title": "Lexicon Mediae et Infimae Latinitatis Polonorum", "text": "Lexicon Mediae et Infimae Latinitatis Polonorum\n\nLexicon Mediae et Infimae Latinitatis Polonorum (Polish \"Słownik łaciny średniowiecznej w Polsce\") is the most comprehensive dictionary of the Latin language as was used in Poland from the 10th to the middle of the 16th century. Administratively, the dictionary belongs to the Institute of the Polish Language, Cracow, which is incorporated in the Polish Academy of Sciences.\n\nAs with similar dictionaries in other European countries, the origins of the \"Lexicon Mediae et Infimae Latinitatis Polonorum\" date from a project launched through the Union Académique Internationale in 1920, which aimed to compile a great common dictionary of Medieval Latin based on excerpts from the different national sources. Since the initiative at that time was not fully possible to be accomplished and caused many technical problems, it eventually resulted in the establishment of a number of separate, national dictionaries after suggestions given by Dr Plezia. In Poland, preparatory work started immediately (under the auspices of the Polish Academy of Learning), and the majority of the excerpts were collected in the years 1924–1939. Subsequently, due to the outbreak of the Second World War, progress on the dictionary was impeded for some years.\n\nThe first fascicle was published only in 1953, under the direction of the late Prof. Marian Plezia (1917–1996), longstanding editor of the \"Lexicon\" until his retirement in 1988. Prof. Krystyna Weyssenhoff–Brozkowa (1934–2007) was appointed as his successor, and performed the function until 2005, when Michał Rzepiela was appointed editor. The editorial team numbers six persons.\n\nSince 1953, seventy fasciscles have been published, making it seven volumes completed to date (A–Q) plus most of the eighth volume (as of 2011, R–Sto).\n\n\n\n\n"}
{"id": "10344162", "url": "https://en.wikipedia.org/wiki?curid=10344162", "title": "Li-kuo Fu", "text": "Li-kuo Fu\n\nProfessor Li-kuo Fu (or Li Kuo Fu) (born 1934) worked for the Institute of Botany at the Chinese Academy of Sciences, Beijing. The author of numerous treatises on Chinese plants, notably the \"China Red Data Book\" of rare and endangered species in the 1990s. In 1973, he took part in the Qinghai - Tibet Expedition, during which he discovered and named the Tibetan elm, \"Ulmus microcarpa\". \n"}
{"id": "49860998", "url": "https://en.wikipedia.org/wiki?curid=49860998", "title": "List of ACM-W chapters", "text": "List of ACM-W chapters\n\nThis is a list of chapters of the Association of Computing Machinery Council on Women in Computing (ACM-W). Chapters are listed by country and if applicable, by state.\n\n"}
{"id": "27581261", "url": "https://en.wikipedia.org/wiki?curid=27581261", "title": "List of New Jersey state symbols", "text": "List of New Jersey state symbols\n\nThis is a list of official symbols of the U.S. state of New Jersey. Official symbols of New Jersey are codified in the laws of New Jersey.\n\nA decade-long campaign by a Haddon Township teacher led to the selection of Hadrosaurus foulkii as the official state fossil in June 1991. This example of the dinosaur was excavated in 1858 from a marl pit near Haddonfield as one of the most complete dinosaur skeletons to be reconstructed. It remains on display at the New Jersey State Museum, where it has been on display since 1931.\n\nIn what \"The New York Times\" described as a \"food fight\", Assemblymember Clare Farragher argued in 2003 that the tomato has a strong historical association with the Garden State and that \"the Jersey tomato does have a unique taste\" that derives from the characteristics of the soil on the Atlantic coast. Legislation ultimately passed in 2003 establishing the blueberry as New Jersey's official state fruit.\n\nIn online balloting, \"New Jersey: Come See For Yourself\" was selected by the 11,000 participants in 2006 as the winner, from a slogan originally submitted by a resident of Passaic, New Jersey. The Governor of New Jersey announced the new slogan in January 2006, after having previously rejected the slogan \"We'll Win You Over\", which had been developed by an advertising agency at the cost of $250,000 and was deemed to be \"too negative and prone to ridicule\". \"Come See For Yourself\" edged out second-place finisher \"New Jersey: The Best Kept Secret\" by approximately 100 votes.\n\n\n"}
{"id": "586316", "url": "https://en.wikipedia.org/wiki?curid=586316", "title": "List of Soviet computer systems", "text": "List of Soviet computer systems\n\nThis is the list of Soviet computer systems. The Russian abbreviation EVM (ЭВМ), present in some of the names below, means “electronic computing machine” ().\n\nThe Russian abbreviation EVM (ЭВМ), present in some of the names below, means “electronic computing machine” ().\n\nComputer systems from the Ministry of Radio Technology:\n\nComputer systems from the Ministry of Instrument Making:\n\nComputer systems from the Ministry of Electronics Industry:\n\n\n\n\n\n"}
{"id": "38446032", "url": "https://en.wikipedia.org/wiki?curid=38446032", "title": "List of forests in Serbia", "text": "List of forests in Serbia\n\nThis is a list of forests in Serbia. \n\n"}
{"id": "35987270", "url": "https://en.wikipedia.org/wiki?curid=35987270", "title": "List of heliophysics missions", "text": "List of heliophysics missions\n\nThis is a list of missions supporting heliophysics, including solar observatory missions, solar orbiters, and spacecraft studying the solar wind.\n"}
{"id": "733446", "url": "https://en.wikipedia.org/wiki?curid=733446", "title": "List of lakes in Arizona", "text": "List of lakes in Arizona\n\nThis is a list of lakes and reservoirs located in the U.S. state of Arizona. Many of the lakes listed here contain game fish and are managed by the Arizona Game and Fish Department. Some lakes may dry out or freeze out fish and will require seasonal restocking. Most lakes will not allow large motorboats.\n\nDue to Arizona's dry climate, many of the lakes listed here are intermittent lakes and do not contain water throughout the entire year.\n\n\nThere are 18 lakes in the Urban lake system. Urban Lakes are stocked with sports fish seasonally.\n\n\n\n\n"}
{"id": "28968894", "url": "https://en.wikipedia.org/wiki?curid=28968894", "title": "List of medical schools in South Korea", "text": "List of medical schools in South Korea\n\nThis is a list of medical schools located in South Korea.\n\n\n"}
{"id": "29296203", "url": "https://en.wikipedia.org/wiki?curid=29296203", "title": "List of national parks of Nigeria", "text": "List of national parks of Nigeria\n\nThere are several national parks of Nigeria. The Nigeria National Park Service (NNPS) is responsible for preserving, enhancing, protecting and managing vegetation and wild animals in the national parks of Nigeria.\nThe NNPS is a parastatal under the Federal Ministry of the Environment, and is headed by a Conservator General.\nIt works closely with the Nigerian Tourism Development Corporation.\n\nThe first national park was Kainji Lake, established by the military ruler General Olusegun Obasanjo in 1979. The National Parks Governing Board and five new National Parks were set up in 1991. \n\nYankari Game Reserve was upgraded to a national park in 1992, although it was later handed over to the Bauchi State government in June 2006. \n\nThe parks cover a total land area of approximately 20,156 km, or about 3% of Nigeria's total land area.\n"}
{"id": "57326415", "url": "https://en.wikipedia.org/wiki?curid=57326415", "title": "List of unsolved problems in astronomy", "text": "List of unsolved problems in astronomy\n\nSome of the unsolved problems in astronomy are theoretical, meaning that existing theories seem incapable of explaining a certain observed phenomenon or experimental result. The others are experimental, meaning that there is a difficulty in creating an experiment to test a proposed theory or investigate a phenomenon in greater detail. Some unresolved questions in astronomy pertain to one-off events, unusual occurrences that have not repeated and whose causes therefore remain unclear.\n\n\n\n\n\n"}
{"id": "7852383", "url": "https://en.wikipedia.org/wiki?curid=7852383", "title": "M-ratio", "text": "M-ratio\n\nIn no-limit or pot-limit poker, a player's M-ratio (also called \"M number\", \"M factor\" or just \"M\") is a measure of the health of a player's chip stack as a function of the cost to play each round. In simple terms, a player can sit passively in the game, making only compulsory bets, for \"M\" laps of the dealer button before running out of chips. A high \"M\" means the player can afford to wait a high number of rounds before making a move. The concept applies primarily in tournament poker; in a cash game, a player can in principle manipulate his M at will, simply by purchasing more chips.\n\nA player with a low \"M\" must act soon or be weakened by the inability to force other players to fold with aggressive raises.\n\nThe term was named after Paul Magriel.\nThe M-ratio is calculated by the formula: \n\nFor example, a player in an eight-player game with blinds of $50/$100, an ante of $10, and a stack of $2,300 has an M-ratio of 10:\n\nThat is, if the player only makes the compulsory bets, he will be \"blinded out\" of the game in 10 rounds, or 80 hands.\n\nDan Harrington studied the concept in great detail in \"Harrington on Holdem: Volume II The Endgame\", defining several \"zones\" in which the M-ratio may fall:\n\nHarrington further develops the concept to account for shortening tables, as is seen at the closing stages of multi-table tournaments. The M-ratio is simply multiplied by the percentage of players remaining at the table, assuming a ten-player table to be \"full\".\n\nTherefore, for a player with a \"simple M ratio\" of 9 at a five player table, the effective M is 4.5:\n\nThis means that although the player's simple M value places him in the orange zone, his effective M dictates a shift in playing style appropriate for the red zone. In essence, ten times the effective M denotes the expected number of hands a player can let pass before running out of chips.\n\n"}
{"id": "29798108", "url": "https://en.wikipedia.org/wiki?curid=29798108", "title": "Malleability of intelligence", "text": "Malleability of intelligence\n\nMalleability of intelligence describes the processes by which intelligence can increase or decrease over time and is not static. These changes may come as a result of genetics, pharmacological factors, psychological factors, behavior, or environmental conditions. Malleable intelligence may refer to changes in cognitive skills, memory, reasoning, or muscle memory related motor skills. \nIn general, the majority changes in human intelligence occurs at either the onset of development, during the critical period, or during old age (see Neuroplasticity).\n\nCharles Spearman, who coined the general intelligence factor \"g\", described intelligence as one's ability to adapt to his environment with a set of useful skills including reasoning and understanding patterns and relationships. He believed individuals highly developed in one intellectual ability tended to be highly developed at other intellectual abilities. A more intelligent individual was thought to be able to more easily \"accommodate\" experiences into existing cognitive structures to develop structures more compatible with environmental stimuli.\n\nIn general, intelligence is thought to be attributed to both genetic and environmental factors, but the extent to which each plays a key role is highly disputed. Studies of identical and non-identical twins raised separately and together show a strong correlation between child IQ and socio-economic level of the parents. Children raised in lower-class families tend to score lower on intelligence tests when compared to children raised in both middle and upper-class families. However, there is no difference in intelligence scores between children raised in middle versus upper-class families.\n\n\nThe biological basis of intelligence is founded in the degree of connectivity of neurons in the brain and the varying amounts of white and grey matter. Studies show that intelligence is positively correlated with total cerebral volume. While it is true that the number of neurons in the brain actually decreases throughout development, as neural connections grow and the pathways become more efficient, the supporting structures in the brain increase. This increase in supporting tissues, which include myelination, blood vessels, and glial cells, leads to an increase in overall brain size. When brain circumference and IQ were compared in 9 year olds, a positive correlation was found between the two. An increase of 2.87 IQ points occurred for each standard deviation increase in brain circumference.\n\nThe brain grows rapidly for the first five years of human development. At age five, the human brain is 90% of its total size. Then the brain finishes growing gradually until age twenty. From start to finish, the brain increases in size by over 300% from birth. The critical period, defined as the beginning years of brain development, is essential to intellectual development, as the brain optimizes the overproduction of synapses present at birth. During the critical period, the neuronal pathways are refined based on which synapses are active and receiving transmission. It is a \"use it or lose it\" phenomenon.\n\nNeural plasticity refers to any change in the structure of the neural network that forms the central nervous system. Neural plasticity is the neuronal basis for changes in how the mind works, including learning, the formation of memory, and changes in intelligence. One well-studied form of plasticity is Long-Term Potentiation (LTP). It refers to a change in neural connectivity as a result of high activation on both sides of a synaptic cleft. This change in neural connectivity allows information to be more easily processed, as the neural connection associated with that information becomes stronger through LTP. Other forms of plasticity involve the growth of new neurons, the growth of new connections between neurons, and the selective elimination of such connection, called \"dendritic pruning\".\n\nHumans have varying degrees of neuroplasticity due to their genetic makeups, which affects their ability to adapt to conditions in their environments and effectively learn from experiences. The degree to which intelligence test scores can be linked to genetic heritability \"increases\" with age. There is presently no explanation for this puzzling result, but flaws in the testing methods are suspected. A study of Dutch twins concludes that intelligence of 5 year olds is 26% heritable, while the test scores of 12-year-olds is 64% heritable. Structurally, genetic influences explain 77–88% of the variance in the thickness of the mid-sagittal area of the corpus callosum, the volume of the caudate nucleus, and the volumes of the parietal and temporal lobes.\n\nNumerous pharmacological developments have been made to help organize neural circuitry for patients with learning disorders. The cholinergic and glutamatergic systems in the brain serve an important role in learning, memory, and the developmental organization of neuronal circuitry. These systems help to capitalize on the critical period and organize synaptic transmission. Autism and other learning disabilities have been targeted with drugs focusing on cholinergic and glutamatergic transmission. These drugs increase the amount of acetylcholine present in the brain by increasing the production of acetylcholine precursors, as well as inhibiting acetylcholine degradation by cholinesterases. By focusing on heightening the activity of this system, the brain's responsiveness to activity-dependent plasticity is improved. Specifically, glutamatergic drugs may reduce the threshold for LTP, promote more normal dendritic spine morphology, and retain a greater number of useful synaptic connections. Cholinergic drugs may reconnect the basal forebrain with the cortex and hippocampus, connections that are often disrupted in patients with learning disorders.\n\nPsychological factors and preconceived notions about intelligence can be as influential on intelligence as genetic makeup. Children with early chronic stress show impaired corticolimbic connectivity in development. Early chronic stress is defined as inconsistent or inadequate care-giving and disruption to early rearing environment. These children showed decreased cognitive function, especially in fluid cognition, or the ability to effectively utilize working memory. The lack of connectivity between the limbic system and the prefrontal cortex can be blamed for this deficiency.\n\nIn the study of malleable intelligence, behavioral factors are often the most intriguing because these are factors humans can seek to control. There are numerous behavioral factors that affect intellectual development and neural plasticity. The key is plasticity, which is caused by experience-driven electrical activation of neurons. This experience-driven activation causes axons to sprout new branches and develop new presynaptic terminals. These new branches often lead to greater mental processing in different areas.\n\nAs previously discussed, the critical period is a time of neural pruning and great intellectual development.\n\n\n"}
{"id": "26252591", "url": "https://en.wikipedia.org/wiki?curid=26252591", "title": "Mohamed H.A. Hassan", "text": "Mohamed H.A. Hassan\n\nMohamed H. A. Hassan (محمد حاج علي حاج الحسن ) is co-chair of IAP, the Global Network of Science Academies, and chairman of the Council of the United Nations University (UNU). He also serves on a number of Boards of international organizations worldwide, including the Board of Trustees of Bibliotheca Alexandrina, Egypt; the Council of Science and Technology in Society (STS ) Forum, Japan; the Board of the International Science Programme, Sweden; the Board of the Science Initiative Group (SIG), USA; and the International Advisory Board of the Centre for International Development (ZEF), Germany.\n\nAfter obtaining his PhD in Mathematics from the University of Oxford, he returned to Sudan and later became Professor and Dean of the School of Mathematical Sciences, University of Khartoum. He has a long list of publications in theoretical plasma physics and fusion energy, wind erosion, and dust and sand transport in dry lands. He has also published several articles on science and technology in the developing world.\n\nDr. Hassan was the founding Executive Director of the Academy of Science for the Developing World (TWAS), President of the African Academy of Sciences, President of the Network of Academies of Science in Africa (NASAC) and Chairman, Honorary Presidential Advisory Council for Science and Technology, Nigeria.\n\nAmong his honours: Comendator, Grand Cross, and National Order of Scientific Merit, Brazil; and Officer, Order of Merit of the Italian Republic.\n\nHe is a member of several merit-based academies of science, including TWAS; the African Academy of Sciences; Islamic World Academy of Sciences; Academia Colombiana de Ciencias Exactas, Físicas y Naturales; Académie Royale des Sciences d’Outre-Mer, Belgium; Pakistan Academy of Sciences;\nAcademy of Sciences of Lebanon; Cuban Academy of Sciences; and Academy of Sciences of South Africa.\n\n"}
{"id": "6447575", "url": "https://en.wikipedia.org/wiki?curid=6447575", "title": "NGC 2997 Group", "text": "NGC 2997 Group\n\nThe NGC 2997 group is a group of galaxies about 24.8 million light-years from Earth containing NGC 2997 as a member. It is a group in the Local Supercluster along with the Local Group.\n\nG. De Vaucouleurs, 1975. Nearby Groups of Galaxies, ch. 5. the nearer groups within 10 megaparsecs. Published in \"Galaxies and the Universe,\" ed. by A. Sandage, M. Sandage and J. Kristian.\n"}
{"id": "5152951", "url": "https://en.wikipedia.org/wiki?curid=5152951", "title": "Nominal (linguistics)", "text": "Nominal (linguistics)\n\nIn linguistics, the term nominal refers to a category used to group together nouns and adjectives based on shared properties. The motivation for nominal grouping is that in many languages nouns and adjectives share a number of morphological and syntactic properties. The systems used in such languages to show agreement can be classified broadly as gender systems, noun class systems or case marking, classifier systems, and mixed systems. Typically an affix related to the noun appears attached to the other parts of speech within a sentence to create agreement. Such morphological agreement usually occurs in parts within the noun phrase, such as determiners and adjectives. Languages with overt nominal agreement vary in how and to what extent agreement is required.\n\nThe history of research on \"nominals\" dates back to European studies on Latin and Bantu in which agreement between \"nouns\" and \"adjectives\" according to the class of the \"noun\" can be seen overtly.\n\nWithin the study of European languages, recognition of the \"nominal\" grouping is reflected in traditional grammar studies based on Latin, which has a highly productive marking system. \"Nominals\" can be seen in the shared morphemes that attach to the ends of \"nouns\" and \"adjectives\" and agree in case and gender. In the example below, 'son' and 'good' agree in \"nominative\" case because they are the subject of the sentence and at the same time they agree in gender because the ending is masculine. Likewise, 'the dog' and 'wild' share the same morphemes that show they agree in accusative case and masculine gender. In Latin agreement goes beyond \"nouns\" and \"adjectives\".\n\nThe earliest study of \"noun\" classes was conducted in 1659 on Bantu languages, and this study has to this day undergone only very minor modifications. These alterations began with Wilhelm Bleek's \"Ancient Bantu\" which led to Proto-Bantu . The following example is from the Bantu Language Ganda. For \"nominal\" classes in Bantu, \"see below.\n\nAlthough much of the research on nominals focuses on their morphological and semantic properties, syntactically \"nominals\" can be considered a \"super category\" which subsumes \"noun\" heads and \"adjective\" heads. This explains why languages that take overt agreement features have agreement in \"adjectives\" and \"nouns\".\n\nIn Chomsky's 1970 [±V, ±N] analysis, words with the feature \"plus \"noun\"\" that are not verbs \"minus \"verb\"\", are predicted to be \"nouns\", while words with the feature \"plus \"verb\"\" and \"minus \"noun\"\" would be \"verbs\". Following from this, when a word has both characteristics of \"nouns\" and \"verbs\" we get \"adjectives.\" When a word lacks either feature, one logically gets \"prepositions.\"\n\nThe following tree demonstrates that the category [+N] groups together \"nouns\" and \"adjectives.\"\n\nThis suggests English illustrates characteristics of \"nominals\" at a syntactic level because \"nouns\" and \"adjectives\" take the same complements at the head level. Likewise, \"verbs\" and \"prepositions\" take the same kinds of complements at the head level. This parallel distribution is predicted by the feature distribution of lexical items.\n\nIn Russian, the nominal category contains nouns, pronouns, adjectives and numerals. These categories share features of case, gender, and number each of which are inflected with different suffixes. Nominals are seen as secondary inflection of agreement. Understanding the different noun classes and how they relate to gender and number is important because the agreement of adjectives will change depending on the type of noun. \n\nExample of nominal predicate:\n\n'The girl is very beautiful' Девушка очень красив-а\n\nAlthough there is not complete agreement about the categorization of noun classes in Russian, a common view breaks the noun classes up into five categories or classes, each of which gets different affixes depending on gender, case and number.\n\nNoun class 1 refers to mass nouns, collective nouns, and abstract nouns.\n\nexamples: вода 'water', любовь 'love'\n\nNoun class 2 refers to items with which the eye can focus on and must be non-active\n\nexamples: дом 'house', школа 'school'\n\nNoun class 3 refers to non-humans that are active.\n\nexamples: рыба 'fish', чайка 'seagull'\n\nNoun Class 4 refers to human beings that are not female.\n\nexamples: отец 'father, 'один' man\n\nNoun Class 5 refers to human beings that are female.\n\nexamples: женщина \"woman\", мать 'mother'\n\nDeclensional class refers to the form rather than semantics.\n\nNouns and adjectives inflect for case and gender.\n\nIn Russian, nominals occur when:\n\nCases\n\nGender and class\n\nRussian has three grammatical genders: masculine, feminine and neuter. Gender and class are closely related in that the noun class will reflect the gender marking a nominal will get. Reflecting gender in Russian is usually restricted to the singular with a few exceptions in the plural. Gender is reflected on both the noun and the adjective or pronoun. Gendered nominals are clearly reflected in anaphors and relative pronouns because even if there is no explicit inflection upon the nouns they inherit animacy, gender and number from their antecedent.\n\nAffixes identifying one gender\n\nAffixes linked with two genders\n\nRussian has two numbers: singular and plural. Number is inherent to the noun so it is reflected by inflection on the noun and the agreeing nominals such as attributive adjectives, predicates and relative pronouns. There is only alteration of singular and plural between semantic classes 2–5 because class 1 does not distinguish between one or more than one.\n\nAdjectives\n\nAdjectives agree with gender, case and number markings and consequently agree with the noun class.\n\nShort form basic inflectional pattern\n\n\"Nominals\" are a common feature of Indigenous Australian languages, many of which do not categorically differentiate nouns from adjectives.\n\nSome features of nominals in some Australian languages include:\n\nAn example paradigm is given below, adapted from . One can see that each of the nominal morphemes in each class attaches to both the nouns and the adjectives.\nNominal structures are also found in Bantu languages. These languages constitute a sub-set of the Niger-Congo languages in Africa. There are approximately 250 different varieties of Bantu. Within these languages, nouns have historically been classified into certain groups based on shared characteristics. For example, noun class 1 and 2 represent humans and other animate objects, while noun class 11 represents long thing objects, and abstract nouns.\n\nBantu languages use different combinations of the approximately 24 different Proto-Bantu noun classes. The language with the highest number of documented \"noun\" classes is Ganda, which utilizes 21 of the 24 noun classes. This ranges all the way to zero, which is the case in Komo D23, whose \"noun\" class system has faded out over time. Languages that have approximately six classes paired for singular and plural and about six other classes that are not paired (e.g. infinitive and locative classes) are classified as canonical noun class systems, systems that have many \"noun\" classes. These systems are far more typical of Bantu languages than the alternative, reduced noun class systems, such as Komo D23 and other languages that have limited \"noun\" classes.\n\nA common feature of Bantu languages is nominal gender class agreement. This agreement can also be described as an extensive system of concord. For every noun class, there is a corresponding gender class prefix. The nominal gender prefixes are shown below, with the \"Proto-Bantu\" (i.e. historical) prefixes on the left-hand side, and modern day Sesotho prefixes on the right-hand side. Note that modern day Sesotho has lost many \"noun\" classes. This is typical of many other Bantu languages, as well.\n\nAs can be seen in the table above, in the Sesotho variety of Bantu (spoken mainly in South Africa) there are approximately 15 nominal gender class prefixes.\nIn this language, nouns and adjectives share the same gender class prefix. Adjectives take a 'pre'-prefix in addition to the main prefix. The main prefix (the one closest to the adjective, which is in bold in the example below) agrees with the prefix attached to the noun, whereas the 'pre'-prefix does not always agree with the noun.\n\nThe following examples from Swahili demonstrate class agreement with the noun, adjective and verb. The different classes of the nouns in Swahili dictate which prefix will also agree with the adjective and verb. It is not always the case in Bantu languages that the verb has noun agreement in the form of nominals, or in any form, but in Swahili it is a good representation of how these prefixes travel across the associated words. In the first Swahili example, the noun has the prefix \"m-\" because it is part of class 1 for human beings. The prefix \"m-\" then agrees with the adjective \"m-dogo\". The verb agreement is different simply because the verb agreement for class 1 is \"a-\" rather than \"m-\". The second example has the prefix \"ki-\" because the noun \"basket\" is part of class 7. Class 7 has the same prefix form for nouns, adjectives and verbs.\n\n\n"}
{"id": "3219634", "url": "https://en.wikipedia.org/wiki?curid=3219634", "title": "North America: Growth of a Continent", "text": "North America: Growth of a Continent\n\nNorth America: Growth of a Continent was an educational television show which was produced and broadcast by TVOntario in 1980-81. The series was narrated by Gordon Pinsent.\n\n"}
{"id": "9809673", "url": "https://en.wikipedia.org/wiki?curid=9809673", "title": "Person-centered ethnography", "text": "Person-centered ethnography\n\nPerson-centered ethnography is an approach within psychological anthropology that draws on techniques and theories from psychiatry and psychoanalysis to understand how individuals relate to and interact with their sociocultural context. The term was first used by Robert I. Levy, a psychoanalytically trained psychiatrist, to describe his psychodynamically informed approach to interviewing during his anthropological fieldwork in Tahiti and Nepal.\n\nA key distinction in person-centered interviewing is that between interviewees as \"informants\" and as \"respondents\". As Levy and Hollan describe it,\n\nThere is a significant difference between asking a Tahitian interviewee something like \"Please describe for me exactly how and why supercision (a penis-mutilating rite of passage) is done by Tahitians,\" and asking him \"Can you tell me about \"your\" supercision?\"...\"Did it change your life in any way?\" \"How?\" \"What did you think and feel about it then?\" \"What do you think and feel about it now?\"\n\nThe first question engages interviewees as typical ethnographic informants, asking them to describe features of their culture or social system; the latter questions ask much more directly about their own experiences, feelings, hopes, and desires, as well as changes in these over time. Not surprisingly, asking about these more intimate topics generally requires much longer acquaintance with an interviewee than do questions about more publicly available knowledge.\n\nLevy and Hollan note that person-centered interviewing makes use of both modes and tacks back and forth between them; its difference from most methods of ethnographic interviewing lies in its emphasis on the latter and its concern with understanding how individuals relate to, experience, and understand their larger sociocultural context. Within these, major topics of interest typically include: the experience of the self, morality, the body, illness and healing, emotions, and family relationships.\n\nMethodologically, person-centered interviewing also depends on a fair degree of experience in self-monitoring for transference and countertransference phenomena, as well as attention to elisions, avoidances, and gaps in an interviewees' answers and attention to interviewees' emotional reactions during and outside the formal interview setting.\n\nPerson-centered interviewing comes out of a psychodynamically informed tradition within Culture and Personality studies and American psychological anthropology and shares a number of methodological and thematic concerns with clinical ethnography.\n\n\n"}
{"id": "4870845", "url": "https://en.wikipedia.org/wiki?curid=4870845", "title": "Professor of Natural Philosophy (Glasgow)", "text": "Professor of Natural Philosophy (Glasgow)\n\nThe Chair of Natural Philosophy is a professorship at the University of Glasgow, in Scotland, which was established in 1727\n\nThe Nova Erectio of King James VI of Scotland shared the teaching of moral philosophy, logic and natural philosophy among the regents.\n\nIn 1727 separate chairs were instituted.\n\n\n"}
{"id": "623243", "url": "https://en.wikipedia.org/wiki?curid=623243", "title": "Science and Engineering Research Council", "text": "Science and Engineering Research Council\n\nThe Science and Engineering Research Council (SERC) was the UK agency in charge of publicly funded scientific and engineering research activities, including astronomy, biotechnology and biological sciences, space research and particle physics, between 1965 and 1994. The SERC also had oversight of the Royal Greenwich Observatory, Royal Observatory Edinburgh, the Rutherford Appleton Laboratory and the Daresbury Laboratory.\n\nFrom its formation in 1965 until 1981 it was known as the Science Research Council (SRC). The SRC had been formed in 1965 as a result of the Trend Committee enquiry into the organisation of civil science in the UK. Previously the Minister for Science had been responsible for various research activities in the Department of Scientific and Industrial Research (DSIR) and more loosely with a variety of agencies concerned with the formulation of civil scientific policy. One of the main problems addressed by the enquiry was how to decide the priorities for government funding across all areas of scientific research. Previously this task had been the responsibility of the Treasury without direct scientific advice. The other Research Councils formed in 1965 were the Natural Environment Research Council, and the Social Science Research Council which joined the Medical Research Council which had existed since 1920, and the Agricultural Research Council.\n\nIn 1981, to reflect the increased emphasis on engineering research, the SRC was renamed the Science and Engineering Research Council.\n\nIn 1994, the new Director General of Research Councils was charged with reorganization of the four existing research councils, and this resulted in the SERC being split into the Particle Physics and Astronomy Research Council (PPARC), the Engineering and Physical Sciences Research Council (EPSRC) and the Biotechnology and Biological Sciences Research Council (BBSRC). The two Observatories were moved under the aegis of PPARC, and the Laboratories initially into EPSRC and later into their own organization, the Council for the Central Laboratory of the Research Councils (CCLRC).\n\nIn 2007 CCLRC and PPARC were merged to form the Science and Technology Facilities Council (STFC), with responsibility for nuclear physics being transferred from EPSRC to STFC.\n\n"}
{"id": "26903", "url": "https://en.wikipedia.org/wiki?curid=26903", "title": "Solar System", "text": "Solar System\n\nThe Solar System is the gravitationally bound system of the Sun and the objects that orbit it, either directly or indirectly. Of the objects that orbit the Sun directly, the largest are the eight planets, with the remainder being smaller objects, such as the five dwarf planets and small Solar System bodies. Of the objects that orbit the Sun indirectly—the moons—two are larger than the smallest planet, Mercury.\n\nThe Solar System formed 4.6 billion years ago from the gravitational collapse of a giant interstellar molecular cloud. The vast majority of the system's mass is in the Sun, with the majority of the remaining mass contained in Jupiter. The four smaller inner planets, Mercury, Venus, Earth and Mars, are terrestrial planets, being primarily composed of rock and metal. The four outer planets are giant planets, being substantially more massive than the terrestrials. The two largest, Jupiter and Saturn, are gas giants, being composed mainly of hydrogen and helium; the two outermost planets, Uranus and Neptune, are ice giants, being composed mostly of substances with relatively high melting points compared with hydrogen and helium, called volatiles, such as water, ammonia and methane. All eight planets have almost circular orbits that lie within a nearly flat disc called the ecliptic.\n\nThe Solar System also contains smaller objects. The asteroid belt, which lies between the orbits of Mars and Jupiter, mostly contains objects composed, like the terrestrial planets, of rock and metal. Beyond Neptune's orbit lie the Kuiper belt and scattered disc, which are populations of trans-Neptunian objects composed mostly of ices, and beyond them a newly discovered population of sednoids. Within these populations are several dozen to possibly tens of thousands of objects large enough that they have been rounded by their own gravity. Such objects are categorized as dwarf planets. Identified dwarf planets include the asteroid Ceres and the trans-Neptunian objects Pluto and Eris. In addition to these two regions, various other small-body populations, including comets, centaurs and interplanetary dust clouds, freely travel between regions. Six of the planets, at least four of the dwarf planets, and many of the smaller bodies are orbited by natural satellites, usually termed \"moons\" after the Moon. Each of the outer planets is encircled by planetary rings of dust and other small objects.\n\nThe solar wind, a stream of charged particles flowing outwards from the Sun, creates a bubble-like region in the interstellar medium known as the heliosphere. The heliopause is the point at which pressure from the solar wind is equal to the opposing pressure of the interstellar medium; it extends out to the edge of the scattered disc. The Oort cloud, which is thought to be the source for long-period comets, may also exist at a distance roughly a thousand times further than the heliosphere. The Solar System is located in the Orion Arm, 26,000 light-years from the center of the Milky Way galaxy.\nFor most of history, humanity did not recognize or understand the concept of the Solar System. Most people up to the Late Middle Ages–Renaissance believed Earth to be stationary at the centre of the universe and categorically different from the divine or ethereal objects that moved through the sky. Although the Greek philosopher Aristarchus of Samos had speculated on a heliocentric reordering of the cosmos, Nicolaus Copernicus was the first to develop a mathematically predictive heliocentric system.\n\nIn the 17th century, Galileo discovered that the Sun was marked with sunspots, and that Jupiter had four satellites in orbit around it. Christiaan Huygens followed on from Galileo's discoveries by discovering Saturn's moon Titan and the shape of the rings of Saturn. Edmond Halley realised in 1705 that repeated sightings of a comet were recording the same object, returning regularly once every 75–76 years. This was the first evidence that anything other than the planets orbited the Sun. Around this time (1704), the term \"Solar System\" first appeared in English. In 1838, Friedrich Bessel successfully measured a stellar parallax, an apparent shift in the position of a star created by Earth's motion around the Sun, providing the first direct, experimental proof of heliocentrism. Improvements in observational astronomy and the use of unmanned spacecraft have since enabled the detailed investigation of other bodies orbiting the Sun.\n\nThe principal component of the Solar System is the Sun, a G2 main-sequence star that contains 99.86% of the system's known mass and dominates it gravitationally. The Sun's four largest orbiting bodies, the giant planets, account for 99% of the remaining mass, with Jupiter and Saturn together comprising more than 90%. The remaining objects of the Solar System (including the four terrestrial planets, the dwarf planets, moons, asteroids, and comets) together comprise less than 0.002% of the Solar System's total mass.\n\nMost large objects in orbit around the Sun lie near the plane of Earth's orbit, known as the ecliptic. The planets are very close to the ecliptic, whereas comets and Kuiper belt objects are frequently at significantly greater angles to it. All the planets, and most other objects, orbit the Sun in the same direction that the Sun is rotating (counter-clockwise, as viewed from above Earth's north pole). There are exceptions, such as Halley's Comet.\n\nThe overall structure of the charted regions of the Solar System consists of the Sun, four relatively small inner planets surrounded by a belt of mostly rocky asteroids, and four giant planets surrounded by the Kuiper belt of mostly icy objects. Astronomers sometimes informally divide this structure into separate regions. The inner Solar System includes the four terrestrial planets and the asteroid belt. The outer Solar System is beyond the asteroids, including the four giant planets. Since the discovery of the Kuiper belt, the outermost parts of the Solar System are considered a distinct region consisting of the objects beyond Neptune.\n\nMost of the planets in the Solar System have secondary systems of their own, being orbited by planetary objects called natural satellites, or moons (two of which, Titan and Ganymede, are larger than the planet Mercury), and, in the case of the four giant planets, by planetary rings, thin bands of tiny particles that orbit them in unison. Most of the largest natural satellites are in synchronous rotation, with one face permanently turned toward their parent.\n\nKepler's laws of planetary motion describe the orbits of objects about the Sun. Following Kepler's laws, each object travels along an ellipse with the Sun at one focus. Objects closer to the Sun (with smaller semi-major axes) travel more quickly because they are more affected by the Sun's gravity. On an elliptical orbit, a body's distance from the Sun varies over the course of its year. A body's closest approach to the Sun is called its \"perihelion\", whereas its most distant point from the Sun is called its \"aphelion\". The orbits of the planets are nearly circular, but many comets, asteroids, and Kuiper belt objects follow highly elliptical orbits. The positions of the bodies in the Solar System can be predicted using numerical models.\n\nAlthough the Sun dominates the system by mass, it accounts for only about 2% of the angular momentum. The planets, dominated by Jupiter, account for most of the rest of the angular momentum due to the combination of their mass, orbit, and distance from the Sun, with a possibly significant contribution from comets.\n\nThe Sun, which comprises nearly all the matter in the Solar System, is composed of roughly 98% hydrogen and helium. Jupiter and Saturn, which comprise nearly all the remaining matter, are also primarily composed of hydrogen and helium. A composition gradient exists in the Solar System, created by heat and light pressure from the Sun; those objects closer to the Sun, which are more affected by heat and light pressure, are composed of elements with high melting points. Objects farther from the Sun are composed largely of materials with lower melting points. The boundary in the Solar System beyond which those volatile substances could condense is known as the frost line, and it lies at roughly 5 AU from the Sun.\n\nThe objects of the inner Solar System are composed mostly of rock, the collective name for compounds with high melting points, such as silicates, iron or nickel, that remained solid under almost all conditions in the protoplanetary nebula. Jupiter and Saturn are composed mainly of gases, the astronomical term for materials with extremely low melting points and high vapour pressure, such as hydrogen, helium, and neon, which were always in the gaseous phase in the nebula. Ices, like water, methane, ammonia, hydrogen sulfide, and carbon dioxide, have melting points up to a few hundred kelvins. They can be found as ices, liquids, or gases in various places in the Solar System, whereas in the nebula they were either in the solid or gaseous phase. Icy substances comprise the majority of the satellites of the giant planets, as well as most of Uranus and Neptune (the so-called \"ice giants\") and the numerous small objects that lie beyond Neptune's orbit. Together, gases and ices are referred to as \"volatiles\".\n\nThe distance from Earth to the Sun is . For comparison, the radius of the Sun is . Thus, the Sun occupies 0.00001% (10 %) of the volume of a sphere with a radius the size of Earth's orbit, whereas Earth's volume is roughly one millionth (10) that of the Sun. Jupiter, the largest planet, is from the Sun and has a radius of , whereas the most distant planet, Neptune, is from the Sun.\n\nWith a few exceptions, the farther a planet or belt is from the Sun, the larger the distance between its orbit and the orbit of the next nearer object to the Sun. For example, Venus is approximately 0.33 AU farther out from the Sun than Mercury, whereas Saturn is 4.3 AU out from Jupiter, and Neptune lies 10.5 AU out from Uranus. Attempts have been made to determine a relationship between these orbital distances (for example, the Titius–Bode law), but no such theory has been accepted. The images at the beginning of this section show the orbits of the various constituents of the Solar System on different scales.\n\nSome Solar System models attempt to convey the relative scales involved in the Solar System on human terms. Some are small in scale (and may be mechanical—called orreries)—whereas others extend across cities or regional areas. The largest such scale model, the Sweden Solar System, uses the 110-metre (361 ft) Ericsson Globe in Stockholm as its substitute Sun, and, following the scale, Jupiter is a 7.5-metre (25-foot) sphere at Arlanda International Airport, 40 km (25 mi) away, whereas the farthest current object, Sedna, is a 10 cm (4 in) sphere in Luleå, 912 km (567 mi) away.\n\nIf the Sun–Neptune distance is scaled to 100 metres, then the Sun would be about 3 cm in diameter (roughly two-thirds the diameter of a golf ball), the giant planets would be all smaller than about 3 mm, and Earth's diameter along with that of the other terrestrial planets would be smaller than a flea (0.3 mm) at this scale.\n\nThe Solar System formed 4.568 billion years ago from the gravitational collapse of a region within a large molecular cloud. This initial cloud was likely several light-years across and probably birthed several stars. As is typical of molecular clouds, this one consisted mostly of hydrogen, with some helium, and small amounts of heavier elements fused by previous generations of stars. As the region that would become the Solar System, known as the pre-solar nebula, collapsed, conservation of angular momentum caused it to rotate faster. The centre, where most of the mass collected, became increasingly hotter than the surrounding disc. As the contracting nebula rotated faster, it began to flatten into a protoplanetary disc with a diameter of roughly 200 AU and a hot, dense protostar at the centre. The planets formed by accretion from this disc, in which dust and gas gravitationally attracted each other, coalescing to form ever larger bodies. Hundreds of protoplanets may have existed in the early Solar System, but they either merged or were destroyed, leaving the planets, dwarf planets, and leftover minor bodies.\n\nDue to their higher boiling points, only metals and silicates could exist in solid form in the warm inner Solar System close to the Sun, and these would eventually form the rocky planets of Mercury, Venus, Earth, and Mars. Because metallic elements only comprised a very small fraction of the solar nebula, the terrestrial planets could not grow very large. The giant planets (Jupiter, Saturn, Uranus, and Neptune) formed further out, beyond the frost line, the point between the orbits of Mars and Jupiter where material is cool enough for volatile icy compounds to remain solid. The ices that formed these planets were more plentiful than the metals and silicates that formed the terrestrial inner planets, allowing them to grow massive enough to capture large atmospheres of hydrogen and helium, the lightest and most abundant elements. Leftover debris that never became planets congregated in regions such as the asteroid belt, Kuiper belt, and Oort cloud. The Nice model is an explanation for the creation of these regions and how the outer planets could have formed in different positions and migrated to their current orbits through various gravitational interactions.\n\nWithin 50 million years, the pressure and density of hydrogen in the centre of the protostar became great enough for it to begin thermonuclear fusion. The temperature, reaction rate, pressure, and density increased until hydrostatic equilibrium was achieved: the thermal pressure equalled the force of gravity. At this point, the Sun became a main-sequence star. The main-sequence phase, from beginning to end, will last about 10 billion years for the Sun compared to around two billion years for all other phases of the Sun's pre-remnant life combined. Solar wind from the Sun created the heliosphere and swept away the remaining gas and dust from the protoplanetary disc into interstellar space, ending the planetary formation process. The Sun is growing brighter; early in its main-sequence life its brightness was 70% that of what it is today.\n\nThe Solar System will remain roughly as we know it today until the hydrogen in the core of the Sun has been entirely converted to helium, which will occur roughly 5 billion years from now. This will mark the end of the Sun's main-sequence life. At this time, the core of the Sun will contract with hydrogen fusion occurring along a shell surrounding the inert helium, and the energy output will be much greater than at present. The outer layers of the Sun will expand to roughly 260 times its current diameter, and the Sun will become a red giant. Because of its vastly increased surface area, the surface of the Sun will be considerably cooler (2,600 K at its coolest) than it is on the main sequence. The expanding Sun is expected to vaporize Mercury and render Earth uninhabitable. Eventually, the core will be hot enough for helium fusion; the Sun will burn helium for a fraction of the time it burned hydrogen in the core. The Sun is not massive enough to commence the fusion of heavier elements, and nuclear reactions in the core will dwindle. Its outer layers will move away into space, leaving a white dwarf, an extraordinarily dense object, half the original mass of the Sun but only the size of Earth. The ejected outer layers will form what is known as a planetary nebula, returning some of the material that formed the Sun—but now enriched with heavier elements like carbon—to the interstellar medium.\n\nThe Sun is the Solar System's star and by far its most massive component. Its large mass (332,900 Earth masses), which comprises 99.86% of all the mass in the Solar System, produces temperatures and densities in its core high enough to sustain nuclear fusion of hydrogen into helium, making it a main-sequence star. This releases an enormous amount of energy, mostly radiated into space as electromagnetic radiation peaking in visible light.\n\nThe Sun is a G2-type main-sequence star. Hotter main-sequence stars are more luminous. The Sun's temperature is intermediate between that of the hottest stars and that of the coolest stars. Stars brighter and hotter than the Sun are rare, whereas substantially dimmer and cooler stars, known as red dwarfs, make up 85% of the stars in the Milky Way.\n\nThe Sun is a population I star; it has a higher abundance of elements heavier than hydrogen and helium (\"metals\" in astronomical parlance) than the older population II stars. Elements heavier than hydrogen and helium were formed in the cores of ancient and exploding stars, so the first generation of stars had to die before the Universe could be enriched with these atoms. The oldest stars contain few metals, whereas stars born later have more. This high metallicity is thought to have been crucial to the Sun's development of a planetary system because the planets form from the accretion of \"metals\".\n\nThe vast majority of the Solar System consists of a near-vacuum known as the interplanetary medium. Along with light, the Sun radiates a continuous stream of charged particles (a plasma) known as the solar wind. This stream of particles spreads outwards at roughly 1.5 million kilometres per hour, creating a tenuous atmosphere that permeates the interplanetary medium out to at least 100 AU \"(see )\". Activity on the Sun's surface, such as solar flares and coronal mass ejections, disturb the heliosphere, creating space weather and causing geomagnetic storms. The largest structure within the heliosphere is the heliospheric current sheet, a spiral form created by the actions of the Sun's rotating magnetic field on the interplanetary medium.\n\nEarth's magnetic field stops its atmosphere from being stripped away by the solar wind. Venus and Mars do not have magnetic fields, and as a result the solar wind is causing their atmospheres to gradually bleed away into space. Coronal mass ejections and similar events blow a magnetic field and huge quantities of material from the surface of the Sun. The interaction of this magnetic field and material with Earth's magnetic field funnels charged particles into Earth's upper atmosphere, where its interactions create aurorae seen near the magnetic poles.\n\nThe heliosphere and planetary magnetic fields (for those planets that have them) partially shield the Solar System from high-energy interstellar particles called cosmic rays. The density of cosmic rays in the interstellar medium and the strength of the Sun's magnetic field change on very long timescales, so the level of cosmic-ray penetration in the Solar System varies, though by how much is unknown.\n\nThe interplanetary medium is home to at least two disc-like regions of cosmic dust. The first, the zodiacal dust cloud, lies in the inner Solar System and causes the zodiacal light. It was likely formed by collisions within the asteroid belt brought on by gravitational interactions with the planets. The second dust cloud extends from about 10 AU to about 40 AU, and was probably created by similar collisions within the Kuiper belt.\n\nThe inner Solar System is the region comprising the terrestrial planets and the asteroid belt. Composed mainly of silicates and metals, the objects of the inner Solar System are relatively close to the Sun; the radius of this entire region is less than the distance between the orbits of Jupiter and Saturn. This region is also within the frost line, which is a little less than 5 AU (about 700 million km) from the Sun.\n\nThe four terrestrial or inner planets have dense, rocky compositions, few or no moons, and no ring systems. They are composed largely of refractory minerals, such as the silicateswhich form their crusts and mantlesand metals, such as iron and nickel, which form their cores. Three of the four inner planets (Venus, Earth and Mars) have atmospheres substantial enough to generate weather; all have impact craters and tectonic surface features, such as rift valleys and volcanoes. The term \"inner planet\" should not be confused with \"inferior planet\", which designates those planets that are closer to the Sun than Earth is (i.e. Mercury and Venus).\n\nAsteroids except for the largest, Ceres, are classified as small Solar System bodies and are composed mainly of refractory rocky and metallic minerals, with some ice. They range from a few metres to hundreds of kilometres in size. Asteroids smaller than one meter are usually called meteoroids and micrometeoroids (grain-sized), depending on different, somewhat arbitrary definitions.\n\nThe asteroid belt occupies the orbit between Mars and Jupiter, between from the Sun. It is thought to be remnants from the Solar System's formation that failed to coalesce because of the gravitational interference of Jupiter. The asteroid belt contains tens of thousands, possibly millions, of objects over one kilometre in diameter. Despite this, the total mass of the asteroid belt is unlikely to be more than a thousandth of that of Earth. The asteroid belt is very sparsely populated; spacecraft routinely pass through without incident.\n\nThe outer region of the Solar System is home to the giant planets and their large moons. The centaurs and many short-period comets also orbit in this region. Due to their greater distance from the Sun, the solid objects in the outer Solar System contain a higher proportion of volatiles, such as water, ammonia, and methane than those of the inner Solar System because the lower temperatures allow these compounds to remain solid.\n\nThe four outer planets, or giant planets (sometimes called Jovian planets), collectively make up 99% of the mass known to orbit the Sun. Jupiter and Saturn are together more than 400 times the mass of Earth and consist overwhelmingly of hydrogen and helium. Uranus and Neptune are far less massiveless than 20 Earth masses () eachand are composed primarily of ices. For these reasons, some astronomers suggest they belong in their own category, ice giants. All four giant planets have rings, although only Saturn's ring system is easily observed from Earth. The term \"superior planet\" designates planets outside Earth's orbit and thus includes both the outer planets and Mars.\n\nThe centaurs are icy comet-like bodies whose orbits have semi-major axes greater than Jupiter's (5.5 AU) and less than Neptune's (30 AU). The largest known centaur, 10199 Chariklo, has a diameter of about 250 km. The first centaur discovered, 2060 Chiron, has also been classified as comet (95P) because it develops a coma just as comets do when they approach the Sun.\n\nComets are small Solar System bodies, typically only a few kilometres across, composed largely of volatile ices. They have highly eccentric orbits, generally a perihelion within the orbits of the inner planets and an aphelion far beyond Pluto. When a comet enters the inner Solar System, its proximity to the Sun causes its icy surface to sublimate and ionise, creating a coma: a long tail of gas and dust often visible to the naked eye.\n\nShort-period comets have orbits lasting less than two hundred years. Long-period comets have orbits lasting thousands of years. Short-period comets are thought to originate in the Kuiper belt, whereas long-period comets, such as Hale–Bopp, are thought to originate in the Oort cloud. Many comet groups, such as the Kreutz Sungrazers, formed from the breakup of a single parent. Some comets with hyperbolic orbits may originate outside the Solar System, but determining their precise orbits is difficult. Old comets that have had most of their volatiles driven out by solar warming are often categorised as asteroids.\n\nBeyond the orbit of Neptune lies the area of the \"trans-Neptunian region\", with the doughnut-shaped Kuiper belt, home of Pluto and several other dwarf planets, and an overlapping disc of scattered objects, which is tilted toward the plane of the Solar System and reaches much further out than the Kuiper belt. The entire region is still largely unexplored. It appears to consist overwhelmingly of many thousands of small worlds—the largest having a diameter only a fifth that of Earth and a mass far smaller than that of the Moon—composed mainly of rock and ice. This region is sometimes described as the \"third zone of the Solar System\", enclosing the inner and the outer Solar System.\n\nThe Kuiper belt is a great ring of debris similar to the asteroid belt, but consisting mainly of objects composed primarily of ice. It extends between 30 and 50 AU from the Sun. Though it is estimated to contain anything from dozens to thousands of dwarf planets, it is composed mainly of small Solar System bodies. Many of the larger Kuiper belt objects, such as Quaoar, Varuna, and Orcus, may prove to be dwarf planets with further data. There are estimated to be over 100,000 Kuiper belt objects with a diameter greater than 50 km, but the total mass of the Kuiper belt is thought to be only a tenth or even a hundredth the mass of Earth. Many Kuiper belt objects have multiple satellites, and most have orbits that take them outside the plane of the ecliptic.\n\nThe Kuiper belt can be roughly divided into the \"classical\" belt and the resonances. Resonances are orbits linked to that of Neptune (e.g. twice for every three Neptune orbits, or once for every two). The first resonance begins within the orbit of Neptune itself. The classical belt consists of objects having no resonance with Neptune, and extends from roughly 39.4 AU to 47.7 AU. Members of the classical Kuiper belt are classified as cubewanos, after the first of their kind to be discovered, 15760 Albion (which previously had the provisional designation 1992 QB), and are still in near primordial, low-eccentricity orbits.\n\nThe scattered disc, which overlaps the Kuiper belt but extends much further outwards, is thought to be the source of short-period comets. Scattered-disc objects are thought to have been ejected into erratic orbits by the gravitational influence of Neptune's early outward migration. Most scattered disc objects (SDOs) have perihelia within the Kuiper belt but aphelia far beyond it (some more than 150 AU from the Sun). SDOs' orbits are also highly inclined to the ecliptic plane and are often almost perpendicular to it. Some astronomers consider the scattered disc to be merely another region of the Kuiper belt and describe scattered disc objects as \"scattered Kuiper belt objects\". Some astronomers also classify centaurs as inward-scattered Kuiper belt objects along with the outward-scattered residents of the scattered disc.\n\nThe point at which the Solar System ends and interstellar space begins is not precisely defined because its outer boundaries are shaped by two separate forces: the solar wind and the Sun's gravity. The limit of the solar wind's influence is roughly four times Pluto's distance from the Sun; this \"heliopause\", the outer boundary of the heliosphere, is considered the beginning of the interstellar medium. The Sun's Hill sphere, the effective range of its gravitational dominance, is thought to extend up to a thousand times farther and encompasses the theorized Oort cloud.\n\nThe heliosphere is a stellar-wind bubble, a region of space dominated by the Sun, which radiates at roughly 400 km/s its solar wind, a stream of charged particles, until it collides with the wind of the interstellar medium.\n\nThe collision occurs at the \"termination shock\", which is roughly 80–100 AU from the Sun upwind of the interstellar medium and roughly 200 AU from the Sun downwind. Here the wind slows dramatically, condenses and becomes more turbulent, forming a great oval structure known as the \"heliosheath\". This structure is thought to look and behave very much like a comet's tail, extending outward for a further 40 AU on the upwind side but tailing many times that distance downwind; evidence from \"Cassini\" and Interstellar Boundary Explorer spacecraft has suggested that it is forced into a bubble shape by the constraining action of the interstellar magnetic field.\n\nThe outer boundary of the heliosphere, the \"heliopause\", is the point at which the solar wind finally terminates and is the beginning of interstellar space. Voyager 1 and Voyager 2 are reported to have passed the termination shock and entered the heliosheath, at 94 and 84 AU from the Sun, respectively. Voyager 1 is reported to have crossed the heliopause in August 2012.\n\nThe shape and form of the outer edge of the heliosphere is likely affected by the fluid dynamics of interactions with the interstellar medium as well as solar magnetic fields prevailing to the south, e.g. it is bluntly shaped with the northern hemisphere extending 9 AU farther than the southern hemisphere. Beyond the heliopause, at around 230 AU, lies the bow shock, a plasma \"wake\" left by the Sun as it travels through the Milky Way.\nDue to a lack of data, conditions in local interstellar space are not known for certain. It is expected that NASA's Voyager spacecraft, as they pass the heliopause, will transmit valuable data on radiation levels and solar wind to Earth. How well the heliosphere shields the Solar System from cosmic rays is poorly understood. A NASA-funded team has developed a concept of a \"Vision Mission\" dedicated to sending a probe to the heliosphere.\n\n90377 Sedna (520 AU average) is a large, reddish object with a gigantic, highly elliptical orbit that takes it from about 76 AU at perihelion to 940 AU at aphelion and takes 11,400 years to complete. Mike Brown, who discovered the object in 2003, asserts that it cannot be part of the scattered disc or the Kuiper belt because its perihelion is too distant to have been affected by Neptune's migration. He and other astronomers consider it to be the first in an entirely new population, sometimes termed \"distant detached objects\" (DDOs), which also may include the object , which has a perihelion of 45 AU, an aphelion of 415 AU, and an orbital period of 3,420 years. Brown terms this population the \"inner Oort cloud\" because it may have formed through a similar process, although it is far closer to the Sun. Sedna is very likely a dwarf planet, though its shape has yet to be determined. The second unequivocally detached object, with a perihelion farther than Sedna's at roughly 81 AU, is , discovered in 2012. Its aphelion is only half that of Sedna's, at 400–500 AU.\n\nThe Oort cloud is a hypothetical spherical cloud of up to a trillion icy objects that is thought to be the source for all long-period comets and to surround the Solar System at roughly 50,000 AU (around 1 light-year (ly)), and possibly to as far as 100,000 AU (1.87 ly). It is thought to be composed of comets that were ejected from the inner Solar System by gravitational interactions with the outer planets. Oort cloud objects move very slowly, and can be perturbed by infrequent events, such as collisions, the gravitational effects of a passing star, or the galactic tide, the tidal force exerted by the Milky Way.\n\nMuch of the Solar System is still unknown. The Sun's gravitational field is estimated to dominate the gravitational forces of surrounding stars out to about two light years (125,000 AU). Lower estimates for the radius of the Oort cloud, by contrast, do not place it farther than 50,000 AU. Despite discoveries such as Sedna, the region between the Kuiper belt and the Oort cloud, an area tens of thousands of AU in radius, is still virtually unmapped. There are also ongoing studies of the region between Mercury and the Sun. Objects may yet be discovered in the Solar System's uncharted regions.\n\nCurrently, the furthest known objects, such as Comet West, have aphelia around 70,000 AU from the Sun, but as the Oort cloud becomes better known, this may change.\n\nThe Solar System is located in the Milky Way, a barred spiral galaxy with a diameter of about 100,000 light-years containing about 100 billion stars. The Sun resides in one of the Milky Way's outer spiral arms, known as the Orion–Cygnus Arm or Local Spur. The Sun lies between 25,000 and 28,000 light-years from the Galactic Centre, and its speed within the Milky Way is about 220 km/s, so that it completes one revolution every 225–250 million years. This revolution is known as the Solar System's galactic year. The solar apex, the direction of the Sun's path through interstellar space, is near the constellation Hercules in the direction of the current location of the bright star Vega. The plane of the ecliptic lies at an angle of about 60° to the galactic plane.\n\nThe Solar System's location in the Milky Way is a factor in the evolutionary history of life on Earth. Its orbit is close to circular, and orbits near the Sun are at roughly the same speed as that of the spiral arms. Therefore, the Sun passes through arms only rarely. Because spiral arms are home to a far larger concentration of supernovae, gravitational instabilities, and radiation that could disrupt the Solar System, this has given Earth long periods of stability for life to evolve. The Solar System also lies well outside the star-crowded environs of the galactic centre. Near the centre, gravitational tugs from nearby stars could perturb bodies in the Oort cloud and send many comets into the inner Solar System, producing collisions with potentially catastrophic implications for life on Earth. The intense radiation of the galactic centre could also interfere with the development of complex life. Even at the Solar System's current location, some scientists have speculated that recent supernovae may have adversely affected life in the last 35,000 years, by flinging pieces of expelled stellar core towards the Sun, as radioactive dust grains and larger, comet-like bodies.\n\nThe Solar System is in the Local Interstellar Cloud or Local Fluff. It is thought to be near the neighbouring G-Cloud but it is not known if the Solar System is embedded in the Local Interstellar Cloud, or if it is in the region where the Local Interstellar Cloud and G-Cloud are interacting. The Local Interstellar Cloud is an area of denser cloud in an otherwise sparse region known as the Local Bubble, an hourglass-shaped cavity in the interstellar medium roughly 300 light-years (ly) across. The bubble is suffused with high-temperature plasma, that suggests it is the product of several recent supernovae.\n\nThere are relatively few stars within ten light-years of the Sun. The closest is the triple star system Alpha Centauri, which is about 4.4 light-years away. Alpha Centauri A and B are a closely tied pair of Sun-like stars, whereas the small red dwarf, Proxima Centauri, orbits the pair at a distance of 0.2 light-year. In 2016, a potentially habitable exoplanet was confirmed to be orbiting Proxima Centauri, called Proxima Centauri b, the closest confirmed exoplanet to the Sun. The stars next closest to the Sun are the red dwarfs Barnard's Star (at 5.9 ly), Wolf 359 (7.8 ly), and Lalande 21185 (8.3 ly).\n\nThe largest nearby star is Sirius, a bright main-sequence star roughly 8.6 light-years away and roughly twice the Sun's mass and that is orbited by a white dwarf, Sirius B. The nearest brown dwarfs are the binary Luhman 16 system at 6.6 light-years. Other systems within ten light-years are the binary red-dwarf system Luyten 726-8 (8.7 ly) and the solitary red dwarf Ross 154 (9.7 ly). The closest solitary Sun-like star to the Solar System is Tau Ceti at 11.9 light-years. It has roughly 80% of the Sun's mass but only 60% of its luminosity. The closest known free-floating planetary-mass object to the Sun is WISE 0855−0714, an object with a mass less than 10 Jupiter masses roughly 7 light-years away.\nCompared to many other planetary systems, the Solar System stands out in lacking planets interior to the orbit of Mercury. The known Solar System also lacks super-Earths (Planet Nine could be a super-Earth beyond the known Solar System). Uncommonly, it has only small rocky planets and large gas giants; elsewhere planets of intermediate size are typical—both rocky and gas—so there is no \"gap\" as seen between the size of Earth and of Neptune (with a radius 3.8 times as large). Also, these super-Earths have closer orbits than Mercury. This led to hypothesis that all planetary systems start with many close-in planets, and that typically a sequence of their collisions causes consolidation of mass into few larger planets, but in case of the Solar System the collisions caused their destruction and ejection.\n\nThe orbits of Solar System planets are nearly circular. Compared to other systems, they have smaller orbital eccentricity. Although there are attempts to explain it partly with a bias in the radial-velocity detection method and partly with long interactions of a quite high number of planets, the exact causes remain undetermined.\n\nThis section is a sampling of Solar System bodies, selected for size and quality of imagery, and sorted by volume. Some omitted objects are larger than the ones included here, notably Eris, because these have not been imaged in high quality.\n\n"}
{"id": "5962524", "url": "https://en.wikipedia.org/wiki?curid=5962524", "title": "Trace fossil classification", "text": "Trace fossil classification\n\nTrace fossils are classified in various ways for different purposes. Traces can be classified taxonomically (by morphology), ethologically (by behavior), and toponomically, that is, according to their relationship to the surrounding sedimentary layers. Except in the rare cases where the original maker of a trace fossil can be identified with confidence, phylogenetic classification of trace fossils is an unreasonable proposition.\n\nThe taxonomic classification of trace fossils parallels the taxonomic classification of organisms under the International Code of Zoological Nomenclature. In trace fossil nomenclature a Latin binomial name is used, just as in animal and plant taxonomy, with a genus and specific epithet. However, the binomial names are not linked to an organism, but rather just a trace fossil. This is due to the rarity of association between a trace fossil and a specific organism or group of organisms. Trace fossils are therefore included in an \"ichnotaxon\" separate from Linnaean taxonomy. When referring to trace fossils, the terms \"ichnogenus\" and \"ichnospecies\" parallel genus and species respectively.\n\nThe most promising cases of phylogenetic classification are those in which similar trace fossils show details complex enough to deduce the makers, such as bryozoan borings, large trilobite trace fossils such as \"Cruziana\", and vertebrate footprints. However, most trace fossils lack sufficiently complex details to allow such classification.\n\nAdolf Seilacher was the first to propose a broadly accepted ethological basis for trace fossil classification. He recognized that most trace fossils are created by animals in one of five main behavioural activities, and named them accordingly:\n\n\nSince the inception of behavioural categorization, several other ethological classes have been suggested and accepted, as follows:\n\n\nOver the years several other behavioural groups have been proposed, but in general they have been quickly discarded by the ichnological community. Some of the failed proposals are listed below, with a brief description.\n\n\nFixichnia is perhaps the group with the most weight as a candidate for the next accepted ethological class, being not fully described by any of the eleven currently accepted categories. There is also potential for the three plant traces (cecidoichnia, corrosichnia and sphenoichnia) to gain recognition in coming years, with little attention having been paid to them since their proposal.\n\nAnother way to classify trace fossils is to look at their relation to the sediment of origin. Martinsson has provided the most widely accepted of such systems, identifying four distinct classes for traces to be separated in this regard:\n\n\nOther classifications have been proposed, but none stray far from the above.\n\nEarly paleontologists originally classified many burrow fossils as the remains of marine algae, as is apparent in ichnogenera named with the \"-phycus\" suffix. Alfred Gabriel Nathorst and Joseph F. James both controversially challenged this incorrect classification, suggesting the reinterpretation of many \"algae\" as marine invertebrate trace fossils.\n\nSeveral attempts to classify trace fossils have been made throughout the history of paleontology. In 1844, Edward Hitchcock proposed two orders: \"Apodichnites\", including footless trails, and \"Polypodichnites\", including trails of organisms with more than four feet.\n\n\n"}
{"id": "48305383", "url": "https://en.wikipedia.org/wiki?curid=48305383", "title": "Tri-Agency Open Access Policy on Publications", "text": "Tri-Agency Open Access Policy on Publications\n\nCanada introduced the Tri-Agency Open Access Policy on Publications in May 2015 to mandate open access to research articles funded by Canada's three major research agencies: the Natural Sciences and Engineering Research Council (NSERC), the Social Sciences and Humanities Research Council (SSHRC) and the Canadian Institutes of Health Research (CIHR). CIHR has had an open access policy since 2008 and the new Tri-Agency policy is largely based on CIHR's pre-existing policy.\n\nThe policy stipulates that peer-reviewed journal articles produced from funded research must be made open access within 12 months of publication by either:\n\nThe policy affects Tri-Agency grants awarded on or after May 1, 2015. All funded researchers are affected except graduate students and postdoctoral fellows. Only peer-reviewed journal articles are covered by the policy: other research outputs such as books or media, are not affected. Only postprints or final published articles may be archived in a subject or institutional repository; other article versions, e.g. preprints, are not acceptable.\n\nEnforcement of the Tri-Agency policy has not been explicitly described. Compliance with the CIHR open access policy has been managed in conjunction with the Research Reporting Service.\n"}
{"id": "41756904", "url": "https://en.wikipedia.org/wiki?curid=41756904", "title": "U-bit", "text": "U-bit\n\nIn quantum mechanics, the u-bit or ubit is a proposed theoretical entity which arises in attempts to reformulate wave functions using only real numbers instead of the complex numbers conventionally used.\n\nIn order to discover the real probability of a given quantum event occurring, the conventional calculation carries out an operation, analogous to squaring, on an associated set of complex numbers. A complex number involves the use of the square root of minus one, a number which is described as \"imaginary\" in contrast to the familiar \"real\" numbers used for counting and describing real physical objects. Because the computed result is required to be a real number, information is lost in the computation.\n\nThis situation is regarded as unsatisfactory by some researchers, who seek an alternative formulation which does not involve the square root of minus one. Bill Wootters, of Williams College, Williamstown, Massachusetts, and colleagues have derived such a model. This model requires the presence of a universal entity which is quantum-entangled with every quantum wave and which he calls the u-bit.\n\nMathematically the u-bit may be represented as a vector rotating in a real two-dimensional plane. It has no known physical representation in the real world.\n"}
{"id": "30965219", "url": "https://en.wikipedia.org/wiki?curid=30965219", "title": "Vicentino Prestes de Almeida", "text": "Vicentino Prestes de Almeida\n\nVicentino Prestes de Almeida, (Born 1900 in Chiniquá, Rio Grande do Sul, Brazil) was a Brazilian paleontologist. He died on October 28, 1954, in São Pedro do Sul.\n\nPrestes was a self-taught paleontologist. Beginning in 1925, he worked with many visiting paleontologists in both Santa Maria and São Pedro do Sul in the Brazilian state of Rio Grande do Sul.\n\nMany of the fossils collected by Prestes are in museums in Porto Alegre, such as the Júlio de Castilhos Museum, the Zoobotanical Natural History Museum of Rio Grande do Sul, the Museum of Science and Technology (PUCRS) and the Museum of Paleontology Irajá Damiani Pinto.\n\nFriedrich von Huene named the carnivorous Triassic reptile Prestosuchus chiniquensis in Prestes's honor (from Prestes and Chiniquá, his birthplace).\n\nPrestes organized and arranged the fossils for the Instituto de Educação General Flores da Cunha and contributed considerably to the Paleorrota Geopark.\n\n"}
{"id": "44426201", "url": "https://en.wikipedia.org/wiki?curid=44426201", "title": "Virtual metrology", "text": "Virtual metrology\n\nIn semiconductor manufacturing, virtual metrology refers to methods to predict the properties of a wafer based on machine parameters and sensor data in the production equipment, without performing the (costly) physical measurement of the wafer properties. Statistical methods such as classification and regression are used to perform such a task.\n\nExamples of virtual metrology include:\n"}
{"id": "30313551", "url": "https://en.wikipedia.org/wiki?curid=30313551", "title": "Warkworth Radio Telescope", "text": "Warkworth Radio Telescope\n\nThe Warkworth 12m Radio Telescope at the Warkworth Radio Astronomical Observatory is operated by the Institute of Radio Astronomy and Space Research of Auckland University of Technology. It was constructed in 2008 and is located just south of Warkworth off SH1 about 50 km north of Auckland, New Zealand.\n\n12m diameter antenna designed and constructed by COBHAM Satcom, Patriot Products division.\n\nDual polarization S and X-band feeds from COBHAM with room temperature receivers, the receiver systems cover 2.2 to 2.4 GHz at S-band and 8.1 to 9.1 GHz at X-band.\n\nIn 2010 this dish was used for several Very Long Baseline Interferometry observations as part of the Australian Long Baseline Array.\n\nIt will also from 2011 be part of the International VLBI Service for Geodesy and Astrometry. As such, it is also co-located with a LINZ/GeoNet 'PositioNZ' GNSS station to help future inclusion in the definition of the International Terrestrial Reference Frame (ITRF).\n\n\n"}
{"id": "55333944", "url": "https://en.wikipedia.org/wiki?curid=55333944", "title": "Why We Sleep", "text": "Why We Sleep\n\nWhy We Sleep: The New Science of Sleep and Dreams is a science book about sleep by the neuroscientist and \"sleep scientist\" Matthew Walker. Walker is a Professor of Neuroscience and Psychology and the director of the Center for Human Sleep Science at the University of California, Berkeley.\n\nWalker spent four years writing the book, in which he argues that sleep deprivation is linked to numerous fatal diseases, including dementia.\n"}
{"id": "6102836", "url": "https://en.wikipedia.org/wiki?curid=6102836", "title": "Zhao Xijin", "text": "Zhao Xijin\n\nZhao Xijin (赵喜进; died July 21, 2012) was a Chinese paleontologist notable for having named numerous dinosaurs. He is currently a professor at Beijing's Institute of Vertebrate Paleontology and Paleoanthropology.\n\nPaul Sereno and Zhao went on a dinosaur fossil hunt in 2005 to Tibet to look for a site that Zhao had found 27 years prior. Before this hunt, in 2001, they had been engaged in a dig in the Gobi Desert. This involved a rock quarry that led them to finding 25 skeletons of the species \"Sinornithomimus dongi\".\n\nIn 2008, Zhao was involved in and in charge of a dig in Zhucheng that consisted of digging out a \"980 ft-long pit\". The site has unearthed more than 7,600 fossils through Xijin's work. It is believed to be the largest such site in the world. The majority of the fossils found appeared to be from the Late Cretaceous period.\n\nHe died in 2012 at the age of 77.\n\n\nBesides the above, Zhao Xijin also named the family Mamenchisauridae (with Young Chung Chien, 1972).\n\n"}
