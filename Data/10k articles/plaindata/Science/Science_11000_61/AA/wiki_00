{"id": "9403782", "url": "https://en.wikipedia.org/wiki?curid=9403782", "title": "Aberdeen Science Centre", "text": "Aberdeen Science Centre\n\nAberdeen Science Centre (formerly Satrosphere Science Centre) is a science museum in Aberdeen, Scotland. It contains exhibits which are aimed mainly at younger children. It attracts primary school groups around the year and its exhibits are 'hands on' so that everything can be played with and examined. The centre is a registered non-profit organization that is funded by the public and donations from local corporate sponsors. Birthday parties and other events for children may be held here by prior arrangement.\n\nIt is located on Constitution Street. It used to based on Justice Mill Lane.\n\n"}
{"id": "20660842", "url": "https://en.wikipedia.org/wiki?curid=20660842", "title": "Armando Dugand", "text": "Armando Dugand\n\nArmando Dugand (July 23, 1906 – 1971) was a Colombian botanist, geobotanist, and ornithologist.\n\nDugand's father, François Victor (or Francisco Víctor) Dugand, was a successful French banker; his mother was Reyes Geneco (or Gnecco) Coronado. Dugand was educated in France and in the United States (at Albany Business College). In 1927, he married Sara Roncallo.\n\nIn 1940 he co-founded the scientific journal \"Caldasia\". He also founded two other scientific journals: \"Mutisia (Acta Botanica Colombiana)\" and \"Lozania (Acta Zoologica Colombiana).\n\nHe was director of the Institute of Natural Sciences of the National University of Colombia from 1940 to 1953. \n"}
{"id": "49641556", "url": "https://en.wikipedia.org/wiki?curid=49641556", "title": "Aspedamite", "text": "Aspedamite\n\nAspedamite is a very rare mineral, one of two natural heteropolyniobates. Its chemical formula (one of the possible formulas) is complex and shows the presence of essential vacancies: [](FeFe)Nb(ThNbFeTiO)(HO)(OH). Its structure (isometric, space group \"Im\"3) is the same as of the second known heteropolyniobate - menezesite. Aspedamite is somewhat similar to another mineral from Norway, peterandresenite, which is a hexaniobate.\n"}
{"id": "43580325", "url": "https://en.wikipedia.org/wiki?curid=43580325", "title": "Atomic Energy Project", "text": "Atomic Energy Project\n\nAtomic Energy Project was started at the University of Rochester as a graduate teaching program. Also known as the University of Rochester Atomic Energy Project or URAEP.\n\nThe Atomic Energy Project was the continuation of the Manhattan Project after the end of World War II. The idea was to continue the work of training the people necessary for the peaceful use of atomic energy and nuclear materials.\n\n\nAt Rochester, Bale worked with George Hoyt Whipple.\nThe discoveries of artificial radioactivity by Joliot-Curie and Fermi and the invention of the cyclotron by Ernest O. Lawrence with its capability of producing useful amounts of radioactive iron (Fe) permitted Whipple, Paul F. Hahn, and Bale in 1937 to begin an examination of the nature of iron absorption and utilization.\n\nThe National Institute for Occupational Safety and Health (NIOSH) part of the Centers for Disease Control and Prevention started the Radiation Dose Reconstruction NIOSH program area for the University of Rochester Atomic Energy Project.\n\nEmployees of the U.S. Department of Energy, earlier agencies, and contractors and subcontractors that worked at the University of Rochester Atomic Energy Project in Rochester, New York, from 1 September 1943 - 30 October 1971, for at least 250 work days were included in the study. Additional employees included Laboratory Technicians that worked in the University of Rochester Atomic Energy Project laboratory building from 1 September 1943 to 19 June 1945.\n"}
{"id": "8983497", "url": "https://en.wikipedia.org/wiki?curid=8983497", "title": "British Sociological Association", "text": "British Sociological Association\n\nThe British Sociological Association (BSA) is a scholarly and professional society for sociologists in the United Kingdom, and was founded in 1951. It publishes the academic journals \"Sociology\", \"Work, Employment and Society\" and \"Cultural Sociology\" (with SAGE Publications) as well as its membership newsletter \"Network\" and a monthly eNewsletter. Formerly, the \"British Journal of Sociology\" was the BSA's official journal, but it was replaced by \"Sociology\" some years after the latter had been established.\n\nIt is a registered charitable company (charity no: 1080235) which states its mission is to \"represent the intellectual and sociological interests of our members.\"\n\nThe activities of the BSA are co-ordinated by an Advisory Forum charged with overseeing governance, membership services and publications. Decisions are monitored and ratified by the Board of Trustees, which includes the BSA president.\n\nAn office of 12 staff members takes care of the day-to-day running of the Association.\n\n\nThe BSA publishes \"Sociology\", \"Work, Employment and Society\",\"Cultural Sociology\", and \"Sociological Research Online\".\n\nThe association publishes a newsletter, \"Network\", for its members three times a year, Spring, Summer and Autumn.\n\nThe Philip Abrams Memorial Prize has been awarded almost every year since 1989 for \"the best first and sole-authored book within the discipline of Sociology\". Past winners include Barbara Adam (1991, for \"Time and Social Theory\"), Graeme Kirkpatrick (2005 for \"Critical Technology: A Social Theory of Personal Computing\") and Maddie Breeze (2016, for \"Seriousness and Women's Roller Derby: Gender, Organization and Ambivalence\"). The prize is named for professor Philip Abrams (1933-1981).\n\n"}
{"id": "16413465", "url": "https://en.wikipedia.org/wiki?curid=16413465", "title": "Corey Schou", "text": "Corey Schou\n\nCorey Schou is University Professor of Informatics and Associate Dean at Idaho State University, director of the National Information Assurance Training and Education Center (NIATEC) and the Simplot Decision Support Center (SDSC), and for ten years the chair of the Colloquium for Information Systems Security Education (CISSE).\n\nIn the early 1980s, organizations began to recognize that connected PCs in various locations were much more vulnerable than a mainframe locked away in a single building. These organizations began seeking qualified individuals responsible for selecting, recommending and implementing security policy and procedures. However, few schools were offering information security curricula, much less academic degrees, and organizations would have to take an IT professional at his or her word that they knew how to manage information security for the entire enterprise.\n\nBy 1989 Schou and others had established a univied common Body of knowledge for computer security. Schou, with Idaho State university hosted the finalization meetings in Salt Lake City. His work was later recognized by the organization with various awards in San Francisco (Founder's award and \nThe need for a professional certification to maintain and validate a common knowledge, values, and ethics for individuals in the industry became a growing concern. Several IT professional societies recognized that a certification program attesting to the qualifications of information security personnel was needed.\n\nSchou's work is recognized several organizations such as ISC2 as foundational to the Information Assurance discipline in academia. His work for three decades has resulted in standards used internationally by government, industry and academia.\n\nSchou is a teacher and mentor whose style is described by his students and colleagues as Socratic. At all levels he encourages students to excel. Although he has had a full-service and research agenda, university records show that he has taught at least one class every semester for the past 30 years.\n\nHe currently heads one of the Scholarship for Service Cyber Corps programs that prepares individuals to be Information Assurance Professionals. In this program all students take a full MBA program. In addition they are exposed to both courses and practicum experiences. Upon completion of the program the graduates have completed all the requirements for certification by the Committee on National Security Systems. The program is one of only three in the nation that is certified at all levels for all certifications CAE. In addition, graduates are expected to sit for the Systems Security Certified Practitioner SSCP and CISSP examinations from (ISC)2. Currently the program has a 100% pass rate on the first try as documented in the university annual report to the National Science Foundation NSF.\n\nIn 1993 he was the first non-government employee to be recognized as Educator of the Year by the Federal Information Systems Security Educators Association FISSEA\n\nHe is the author of several books on information assurance called \"Information Assurance for the Enterprise: A Roadmap to Information Security\" McGraw Hill Catalog.\nand over 300 referred papers and monographs.\n\nRecent Research\nBooks\nRefereed Journal Articles\n\n"}
{"id": "861765", "url": "https://en.wikipedia.org/wiki?curid=861765", "title": "Dmitry Ovtsyn", "text": "Dmitry Ovtsyn\n\nDmitry Leontiyevich Ovtsyn () (unknown - after 1757) was a Russian hydrographer and Arctic explorer. \n\nIn 1734-1738, Ovtsyn led one of the units of the Second Kamchatka expedition that charted the coastline of the Kara Sea east of the river Ob. In summer of 1737, his unit made its way from Ob to Yenisei and made the first hydrographic description of this part of the Siberian coastline. In 1741, Ovtsyn took part in Vitus Bering's voyage to the shores of America.\nA cape on the Taimyr Peninsula and a strait between the islands Oleniy and Sibiryakov bear his name.\n"}
{"id": "29379776", "url": "https://en.wikipedia.org/wiki?curid=29379776", "title": "Domestic material consumption", "text": "Domestic material consumption\n\nDomestic material consumption is a measurement of the total amount of material directly used in an economy, excluding hidden flows. DMC equals DMI minus exports (in economy wide material flow accounting).\n"}
{"id": "6059964", "url": "https://en.wikipedia.org/wiki?curid=6059964", "title": "East Midlands Regional Assembly", "text": "East Midlands Regional Assembly\n\nThe East Midlands Regional Assembly was the regional chamber for the East Midlands region of the England. It was based at Melton.\n\nIt was created by the Regional Development Agencies Act 1998. It is based opposite PERA on \"Nottingham Road\" in Melton Mowbray.\n\nIt was originally created to divide up the money given in government grants for the East Midlands. However, EMDA in Nottingham, the local government-run regional development agency, is taking over this role, and has done similar work in the past. It is currently involved in promoting energy efficiency throughout businesses and local authorities in the East Midlands.\n\nIt had 111 members, with seventy from the 46 local authorities and thirty-five from local businesses. The Assembly Board has 18 members. There are 20 permanent staff. Government funding comes from the Department for Communities and Local Government.\n\nThe assembly was abolished on 31 March 2010 as part of the UK Government's Review of Sub-National Economic Development and Regeneration. Its functions were assumed by the East Midlands Development Agency and a newly constituted East Midlands Leaders' Board, the executive arm of East Midlands Councils.\n\n\n\n"}
{"id": "518692", "url": "https://en.wikipedia.org/wiki?curid=518692", "title": "Faraday effect", "text": "Faraday effect\n\nIn physics, the Faraday effect or Faraday rotation is a magneto-optical phenomenon—that is, an interaction between light and a magnetic field in a medium. The Faraday effect causes a rotation of the plane of polarization which is linearly proportional to the component of the magnetic field in the direction of propagation. Formally, it is a special case of gyroelectromagnetism obtained when the dielectric permittivity tensor is diagonal.\n\nDiscovered by Michael Faraday in 1845, the Faraday effect was the first experimental evidence that light and electromagnetism are related. The theoretical basis of electromagnetic radiation (which includes visible light) was completed by James Clerk Maxwell in the 1860s and 1870s. This effect occurs in most optically transparent dielectric materials (including liquids) under the influence of magnetic fields.\n\nThe Faraday effect is caused by left and right circularly polarized waves propagating at slightly different speeds, a property known as circular birefringence. Since a linear polarization can be decomposed into the superposition of two equal-amplitude circularly polarized components of opposite handedness and different phase, the effect of a relative phase shift, induced by the Faraday effect, is to rotate the orientation of a wave's linear polarization.\n\nThe Faraday effect has applications in measuring instruments. For instance, the Faraday effect has been used to measure optical rotatory power and for remote sensing of magnetic fields (such as fiber optic current sensors). The Faraday effect is used in spintronics research to study the polarization of electron spins in semiconductors. Faraday rotators can be used for amplitude modulation of light, and are the basis of optical isolators and optical circulators; such components are required in optical telecommunications and other laser applications.\n\nBy 1845, it was known through the work of Fresnel, Malus, and others that different materials are able to modify the direction of polarization of light when appropriately oriented, making polarized light a very powerful tool to investigate the properties of transparent materials. Faraday firmly believed that light was an electromagnetic phenomenon, and as such should be affected by electromagnetic forces. He spent considerable effort looking for evidence of electric forces affecting the polarization of light through what are now known as electro-optic effects, starting with decomposing electrolytes. However, his experimental methods were not sensitive enough, and the effect was only measured thirty years later by John Kerr.\n\nFaraday then attempted to look for the effects of magnetic forces on light passing through various substances. After several unsuccessful trials, he happened to test a piece of \"heavy\" glass, containing traces of lead, that he had made during his earlier work on glass manufacturing. Faraday observed that when a beam of polarized light passed through the glass in the direction of an applied magnetic force, the polarization of light rotated by an angle that was proportional to the strength of the force. He was later able to reproduce the effect in several other solids, liquids, and gases by procuring stronger electromagnets.\n\nThe discovery is well documented in Faraday's daily notebook, which has since been published. On 13 Sept. 1845, in paragraph #7504, under the rubric \"Heavy Glass\", he wrote:\n\nHe summarized the results of his experiments on 30 Sept. 1845, in paragraph #7718, famously writing:\nThe linear polarized light that is seen to rotate in the Faraday effect can be seen as consisting of the superposition of a right- and a left- circularly polarized beam (this superposition principle is fundamental in many branches of physics). We can look at the effects of each component (right- or left polarized) separately, and see what effect this has on the result.\n\nIn circularly polarized light the direction of the electric field rotates at the frequency of the light, either clockwise or counter-clockwise. In a material, this electric field causes a force on the charged particles comprising the material (because of their low mass, the electrons are most heavily affected). The motion thus effected will be circular, and circularly moving charges will create their own (magnetic) field in addition to the external magnetic field. There will thus be two different cases: the created field will be parallel to the external field for one (circular) polarization, and in the opposing direction for the other polarization direction – thus the net B field is enhanced in one direction and diminished in the opposite direction. This changes the dynamics of the interaction for each beam and one of the beams will be slowed down more than the other, causing a phase difference between the left- and right-polarized beam. When the two beams are added after this phase shift, the result is again a linearly polarized beam, but with a rotation in the polarization direction.\n\nThe direction of polarization rotation depends on the properties of the material through which the light is shone. A full treatment would have to take into account the effect of the external and radiation-induced fields on the wave function of the electrons, and then calculate the effect of this change on the refractive index of the material for each polarization, to see whether the right- or left circular polarization is slowed down more.\n\nFormally, the magnetic permeability is treated as a non-diagonal tensor as expressed by the equation:\n\nThe relation between the angle of rotation of the polarization and the magnetic field in a transparent material is:\n\nwhere\n\nA positive Verdet constant corresponds to L-rotation (anticlockwise) when the direction of propagation is parallel to the magnetic field and to R-rotation (clockwise) when the direction of propagation is anti-parallel. Thus, if a ray of light is passed through a material and reflected back through it, the rotation doubles.\n\nSome materials, such as terbium gallium garnet (TGG) have extremely high Verdet constants (≈ for 632 nm light). By placing a rod of this material in a strong magnetic field, Faraday rotation angles of over 0.78 rad (45°) can be achieved. This allows the construction of Faraday rotators, which are the principal component of Faraday isolators, devices which transmit light in only one direction. The Faraday effect can, however, be observed and measured in a Terbium-doped glass with Verdet constant as low as (≈ for 632 nm light). Similar isolators are constructed for microwave systems by using ferrite rods in a waveguide with a surrounding magnetic field. A thorough mathematical description can be found here.\n\nThe effect is imposed on light over the course of its propagation from its origin to the Earth, through the interstellar medium. Here, the effect is caused by free electrons and can be characterized as a difference in the refractive index seen by the two circularly polarized propagation modes. Hence, in contrast to the Faraday effect in solids or liquids, interstellar Faraday rotation (β) has a simple dependence on the wavelength of light (λ), namely:\n\nwhere the overall strength of the effect is characterized by RM, the rotation measure. This in turn depends on the axial component of the interstellar magnetic field \"B\", and the number density of electrons \"n\", both of which vary along the propagation path. In Gaussian cgs units the rotation measure is given by:\n\nor in SI units:\n\nwhere\n\nThe integral is taken over the entire path from the source to the observer.\n\nFaraday rotation is an important tool in astronomy for the measurement of magnetic fields, which can be estimated from rotation measures given a knowledge of the electron number density. In the case of radio pulsars, the dispersion caused by these electrons results in a time delay between pulses received at different wavelengths, which can be measured in terms of the electron column density, or dispersion measure. A measurement of both the dispersion measure and the rotation measure therefore yields the weighted mean of the magnetic field along the line of sight. The same information can be obtained from objects other than pulsars, if the dispersion measure can be estimated based on reasonable guesses about the propagation path length and typical electron densities. In particular, Faraday rotation measurements of polarized radio signals from extragalactic radio sources occulted by the solar corona can be used to estimate both the electron density distribution and the direction and strength of the magnetic field in the coronal plasma.\n\nRadio waves passing through the Earth's ionosphere are likewise subject to the Faraday effect. The ionosphere consists of a plasma containing free electrons which contribute to Faraday rotation according to the above equation, whereas the positive ions are relatively massive and have little influence. In conjunction with the earth's magnetic field, rotation of the polarization of radio waves thus occurs. Since the density of electrons in the ionosphere varies greatly on a daily basis, as well as over the sunspot cycle, the magnitude of the effect varies. However the effect is always proportional to the square of the wavelength, so even at the UHF television frequency of 500 MHz (λ = 60 cm), there can be more than a complete rotation of the axis of polarization. A consequence is that although most radio transmitting antennas are either vertically or horizontally polarized, the polarization of a medium or short wave signal after reflection by the ionosphere is rather unpredictable. However the Faraday effect due to free electrons diminishes rapidly at higher frequencies (shorter wavelengths) so that at microwave frequencies, used by satellite communications, the transmitted polarization is maintained between the satellite and the ground.\n\nDue to spin-orbit coupling, undoped GaAs single crystal exhibits much larger Faraday rotation than glass (SiO). Considering the atomic arrangement is different along the (100) and (110) plane, one might think the Faraday rotation is polarization dependent. However, experimental work revealed an immeasurable anisotropy in the wavelength range from 880–1,600 nm. Based on the large Faraday rotation, one might be able to use GaAs to calibrate the B field of the terahertz electromagnetic wave which requires very fast response time. Around the band gap, the Faraday effect shows resonance behavior.\n\nMore generally, (ferromagnetic) semiconductors return both electro-gyration and a Faraday response in the high frequency domain. The combination of the two is described by gyroelectromagnetic media, for which gyroelectricity and gyromagnetism (Faraday effect) may occur at the same time.\n\nIn organic materials, Faraday rotation is typically small, with a Verdet constant in the visible wavelength region on the order of a few hundred degrees per Tesla per meter, decreasing proportional to formula_8 in this region. While the Verdet constant of organic materials does increase around electronic transitions in the molecule, the associated light absorption makes most organic materials bad candidates for applications. There are however also isolated reports of large Faraday rotation in organic liquid crystals without associated absorption.\n\nIn 2009 γ-FeO-Au core-shell nanostructures were synthesized to integrate magnetic (γ-FeO) and plasmonic (Au) properties into one composite. Faraday rotation with and without the plasmonic materials was tested and rotation enhancement under 530 nm light irradiation was observed. Researchers claim that the magnitude of the magneto-optical enhancement is governed primarily by the spectral overlap of the magneto-optical transition and the plasmon resonance.\n\nThe reported composite magnetic/plasmonic nanostructure can be visualized to be a magnetic particle embedded in a resonant optical cavity. Because of the large density of photon states in the cavity, the interaction between the electromagnetic field of the light and the electronic transitions of the magnetic material is enhanced, resulting in a larger difference between the velocities of the right- and left-hand circularized polarization, therefore enhancing Faraday rotation.\n\n"}
{"id": "42804165", "url": "https://en.wikipedia.org/wiki?curid=42804165", "title": "Gay-Lussac Humboldt Prize", "text": "Gay-Lussac Humboldt Prize\n\nThe Gay-Lussac Humboldt Prize is German - French science prize. It was created in 1981 by French President Valéry Giscard d'Estaing and German Chancellor Helmut Schmidt based on the recommendation of the German and French research ministries.\n\nThe prize is awarded to researchers that have made outstanding contributions in science, especially in cooperation between the two countries. Four to five German and French scientists from all research disciplines are honored with this award every year. The prize was originally named after Alexander von Humboldt and carries since 1997 the double name Gay-Lussac-Humboldt. \n\n"}
{"id": "29560969", "url": "https://en.wikipedia.org/wiki?curid=29560969", "title": "George Althofer", "text": "George Althofer\n\nGeorge William Francis Althofer (1903–1993) was an Australian botanist, nurseryman, author and poet, with a special interest in the mint-bush genus \"Prostanthera\" as well as other Australian native plants, who founded the Burrendong Botanic Garden and Arboretum.\n\nAlthofer was born at Dripstone in the Wellington local government area of Central West New South Wales. He attended school locally, in Dripstone, then Wellington and Mumbil.\n\nAlthofer grew up working on his father's farm and orchard, becoming an orchardist himself. In 1938 he established a native plant nursery at his property \"Nindethana\" at Dripstone. Inspired by the American example of the Arnold Arboretum, and assisted by his brother Peter, he lobbied for the establishment of a similar institution with a focus on Australian native plants. As a consequence, the 167 ha Burrendong Botanic Garden and Arboretum on the foreshore of Lake Burrendong, near Wellington, opened in 1964.\n\nBooks and collections of poetry by Althofer include:\n\n\n"}
{"id": "43724549", "url": "https://en.wikipedia.org/wiki?curid=43724549", "title": "Giuseppe Novelli", "text": "Giuseppe Novelli\n\nGiuseppe Novelli (born February 27, 1959) is an Italian geneticist and the president of University of Rome Tor Vergata.\n\nBorn in the little city of Rossano in the south of Italy, he graduated magna cum laude in genetics in the 1981. In 1985 earned a Ph.D at Sapienza University of Rome.\nIn 1995 he became Professor of genetics at University of Rome Tor Vergata.\n\nFrom 2003 he is also \"adjunct professor\" at Arkansas University.\n\nFrom 2008 to 2011 he was president of the Faculty of Medicine and Surgery at Tor Vergata. In 2013 he had been elected rector of his university.\n"}
{"id": "42573836", "url": "https://en.wikipedia.org/wiki?curid=42573836", "title": "Guitar Zero", "text": "Guitar Zero\n\nGuitar Zero: The New Musician and the Science of Learning is a 2012 popular science book by research psychologist Gary Marcus. It documents the author's process of learning the guitar while discussing aspects of music cognition and the role of critical periods in learning a musical ability. The book was released on January 19, 2012 and published by Penguin Books, and in December 2012 was released as a paperback under the title Guitar Zero: The Science of Becoming Musical at Any Age.\n\nThe book reached 24th on the New York Times Best Seller list for hardcover nonfiction during the week of February 19, 2012. Maria Popova on Brainpickings.org named the book among \"The Best Music Books of 2012.\" In a review for \"The Wall Street Journal\", Norman Doidge wrote \"\"Guitar Zero\" is a refreshing alternation between the nitty-gritty details of learning rock-guitar licks and Mr. Marcus's survey of the relevant scientific literature on learning and the brain.\"\n\n"}
{"id": "947434", "url": "https://en.wikipedia.org/wiki?curid=947434", "title": "Heinrich Geißler", "text": "Heinrich Geißler\n\nJohann Heinrich Wilhelm Geißler (26 May 1814 in Igelshieb – 24 January 1879) was a skilled glassblower and physicist, famous for his invention of the Geissler tube, made of glass and used as a low pressure gas-discharge tube.\n\nGeissler descended from a long line of craftsmen in the Thüringer Wald and in Böhmen. He found work in different German universities, eventually including the University of Bonn. There he was asked by physicist Julius Plücker to design an apparatus for evacuating a glass tube. Plücker owed his forthcoming success in the electric discharge experiments in large measure to his instrument maker, the skilled glassblower and mechanic Johann Heinrich Wilhelm Geissler. He learned the art of glassblowing in the duchy of Saxe-Meiningen... He finally settled down as an instrument-maker in a workshop of his own at the University of Bonn in 1852. Geissler made a hand-crank mercury pump, and glass tubes that could contain a superior vacuum.\n\nThe Geissler tube was used for entertainment throughout the 1800s and evolved around 1910 into commercial neon lighting. Advances in Plucker and Geissler's discharge tube technology developed into the Crookes tube, with which the electron was discovered in 1897, and in 1906 into the amplifying vacuum tube, the basis of electronics and long distance communication technologies like radio and television.\n\nGeissler was awarded an honorary doctorate in 1868.\n\n\n\n"}
{"id": "1099464", "url": "https://en.wikipedia.org/wiki?curid=1099464", "title": "Henrik Johan Walbeck", "text": "Henrik Johan Walbeck\n\nHenrik Johan Walbeck (1794-1822) was a Finnish geodesist and astronomer studying the size and figure of the Earth by means of grade measurement.\n\nHe was born on 11 October 1793 in Åbo. In 1817 he was made a corresponding member of the Royal Swedish Academy of Sciences. He committed suicide on 23 October 1822, also in Åbo.\n\n"}
{"id": "43034759", "url": "https://en.wikipedia.org/wiki?curid=43034759", "title": "IXS Enterprise", "text": "IXS Enterprise\n\nIXS \"Enterprise\" is a conceptual interstellar superluminal spacecraft designed by NASA scientist Dr. Harold G. White, revealed at SpaceVision 2008, designed for the goal of achieving warp travel. The conceptual spacecraft would make use of a modified version of the Alcubierre drive. Dr. White is currently running the White–Juday warp-field interferometer experiment in order to develop a proof of concept for Alcubierre-style warp travel, if possible. The Alcubierre drive uses exotic matter (not to be confused with antimatter) to travel faster than light.\n\nWhile the concept had been out since 2008 the design of IXS \"Enterprise\" was popularized in June 2015 after a series of media outlets reported on the conceptual artwork done by Dutch artist Mark Rademaker in collaboration with NASA. According to Mark Rademaker, over 1,600 hours have been spent on the conceptual artwork that he created.\n\nThe energy required to power the warp drive, according to White, is approximately the negative (negative energy is required for the Alcubierre drive concept to function) mass–energy equivalence of \"Voyager 1\", which has a mass of approximately 700 kilograms. Using E=mc, −700 kilograms of mass is equivalent to ~−63 exajoules of energy (this number is not definitive and can be further reduced). The ship has two thick outer rings (to reduce required energy) that generate the warp field—a contraction of space ahead, and expansion of space behind it. The space inside the rings is optimized to fit more space for cargo, crew and equipment.\n\n"}
{"id": "19590427", "url": "https://en.wikipedia.org/wiki?curid=19590427", "title": "Iain Coldham", "text": "Iain Coldham\n\nIain Coldham is an organic chemist and Professor of Organic Chemistry at the University of Sheffield. He obtained his PhD from the University of Cambridge before relocating to Austin, Texas in 1989 for postdoctoral research. His areas of study have included intramolecular trapping of episulfonium ions with amine nucleophiles and the use of triisopropylsilyl enol ethers in organic synthesis.\n\n\n\n"}
{"id": "33821999", "url": "https://en.wikipedia.org/wiki?curid=33821999", "title": "International Journal of Cross Cultural Management", "text": "International Journal of Cross Cultural Management\n\nThe International Journal of Cross Cultural Management is a triannual peer-reviewed academic journal that covers the field of cross-cultural management. The editor-in-chief is Terence Jackson (Middlesex University). The journal was established in 2001 and is published by Sage Publications.\n\nThe journal is abstracted and indexed in:\n"}
{"id": "58457789", "url": "https://en.wikipedia.org/wiki?curid=58457789", "title": "Ispace (Japanese company)", "text": "Ispace (Japanese company)\n\nispace Inc. is a private Japanese company developing robotic spacecraft technologies to discover, map, and utilize the natural resources on the Moon. They will start by exploring the exploitation of lunar water in order to create a sustainable infrastructure and a Moon-based economy. ispace's long-term strategy is to build landers and rovers to compete for both transportation and exploration mission contracts from space agencies and private industry.\n\nIn 2010 White Label Space Japan was founded as a branch organization to the Dutch-led team White Label Space, a participant in the Google Lunar X Prize (GLXP). ispace was founded in 2013 after White Label Space dropped out from the GLXP and transferred its GLXP participation right to White Label Space Japan. ispace is currently headquartered in Tokyo, Japan with offices in the United States and Luxembourg. The company's founder and CEO is Takeshi Hakamada.\n\nispace operates team Hakuto and their lunar rover, \"Sorato\", that will scout for water and explore other potential local resources.\n\nAlthough ispace is now independent, it began as a branch of a European organization called White Label Space. White Label Space (WLS) was an international team of space engineers that was founded in 2008 to compete in the Google Lunar X Prize, for a grand price of $20 million to send a spacecraft to the Moon's surface, and have it travel 500 meters. WLS was headquartered in the Netherlands and led by Steve Allen. The European side was to develop a lander, while the Japanese group consisting of Tohoku University Space Robotics Lab and led by Kazuya Yoshida was to develop a rover. In 2010, White Label Space Japan LLC, the predecessor of ispace was founded by Takeshi Hakamada to manage the commercial and technical aspect of the Japanese group. When the European teammates dropped out from GLXP in January 30, 2013, the Japan-based members continued the work and the GLXP participation right was transferred from the Netherlands to Japan. Steve Allen, WLS's leader was succeeded by Takeshi Hakama. In May 2013, the team's parent company, White Label Space Japan changed its name to ispace, while WLS itself was renamed team Hakuto in July 15 of the same year. As per September 2018, ispace plans to orbit its lunar lander around the moon. The company has signed up for two launches on SpaceX's Falcon 9 rockets, to take place in 2020 and 2021.\n\nOn 10 October, 2018, a industry team formed by Draper Laboratory, along with ispace, General Atomics, and Spaceflight Industries submitted a proposal for a commercial lunar lander to NASA's Commercial Lunar Payload Services Program. According to Draper, ispace will serve as the team's design agent.\n\nThe long-term strategy of ispace is to build landers and rovers to compete for both transportation and exploration mission contracts from space agencies and private industry. They aim at mining lunar water and other resources to support a future Moon-based infrastructure.\n\nThe first demonstration mission includes a small rover called \"Sorato\" which is planned to be delivered to the lunar surface by the \"Peregrine\" lander built Astrobotic Technology, to be launched on an Atlas V rocket in 2020. The second demonstration mission includes a lander currently being designed by ispace, that would deploy a number of small rovers. The lander would be launched as a secondary payload on a commercial launch vehicle.\n\nIf the technology validations are successful, ispace plans to offer a regular series of lander missions to carry up to of customer payloads per flight. The company also plans to collect a wide variety of data about the Moon's environment, which they plan to sell to its customers.\n\nThe funding for the first two missions has been secured from a consortium of Japanese funds and companies that include:\n\n\n"}
{"id": "2954049", "url": "https://en.wikipedia.org/wiki?curid=2954049", "title": "Iterative learning control", "text": "Iterative learning control\n\nIterative Learning Control (ILC) is a method of tracking control for systems that work in a repetitive mode. Examples of systems that operate in a repetitive manner include robot arm manipulators, chemical batch processes and reliability testing rigs. In each of these tasks the system is required to perform the same action over and over again with high precision. This action is represented by the objective of accurately tracking a chosen reference signal formula_1 on a finite time interval.\n\nRepetition allows the system to improve tracking accuracy from repetition to repetition, in effect learning the required input needed to track the reference exactly. The learning process uses information from previous repetitions to improve the control signal ultimately enabling a suitable control action can be found iteratively. The internal model principle yields conditions under which perfect tracking can be achieved but the design of the control algorithm still leaves many decisions to be made to suit the application. A typical, simple control law is of the form:\n\nwhere formula_3 is the input to the system during the pth repetition, formula_4 is the tracking error during the pth repetition and K is a design parameter representing operations on formula_4. Achieving perfect tracking through iteration is represented by the mathematical requirement of convergence of the input signals as formula_6 becomes large whilst the rate of this convergence represents the desirable practical need for the learning process to be rapid. There is also the need to ensure good algorithm performance even in the presence of uncertainty about the details of process dynamics. The operation formula_7 is crucial to achieving design objectives and ranges from simple scalar gains to sophisticated optimization computations.\n\n\n"}
{"id": "54241212", "url": "https://en.wikipedia.org/wiki?curid=54241212", "title": "Kimmen Sjölander", "text": "Kimmen Sjölander\n\nKimmen Sjölander (née Warnow) is Professor Emerita at the University of California, Berkeley in the Department of Bioengineering. She is well known for her work on protein sequence analysis.\n\nSjölander did both her undergraduate and graduate work at the University of California, Santa Cruz in the Department of Computer Science, earning a bachelor's degree in 1993 and a PhD in 1997 under the supervision of David Haussler. She was the Chief Scientist in the Molecular Applications Group from 1997-1999 (company co-founded by Michael Levitt) and then Principal Scientist in Protein Informatics at Celera Genomics from 1999-2001, where she was a member of the team (along with J. Craig Venter and Gene Myers) who assembled and annotated the Human Genome. She joined the faculty at the University of California, Berkeley in the Department of Bioengineering in 2001 as an assistant professor. She was tenured in 2006, and promoted to full professor in 2012.\n\nSjölander received the NSF CAREER Award and the Presidential Early Career Award for Scientists and Engineers in 2003.\n\nSjölander is most well known for her work in phylogenomic methods for protein sequence analysis, including machine learning methods for functional site prediction and ortholog identification, and hidden Markov model (HMM) methods for protein structure prediction, functional subfamily and ortholog classification, remote homology detection, multiple sequence alignment, and phylogenetic tree estimation. Her algorithms were used in the functional annotation of the human genome at Celera Genomics, in the PhyloFacts bioinformatics databases and portals, and contributed to the ModBase database.\n"}
{"id": "423369", "url": "https://en.wikipedia.org/wiki?curid=423369", "title": "List of UK government scientific research institutes", "text": "List of UK government scientific research institutes\n\nThis page contains a list of scientific research institutes in the United Kingdom that are owned by the government. \n\n\n\n\n\n\n\n\n\n"}
{"id": "9025157", "url": "https://en.wikipedia.org/wiki?curid=9025157", "title": "List of UN numbers 2601 to 2700", "text": "List of UN numbers 2601 to 2700\n\nThe UN numbers from UN2601 to UN2700 as assigned by the United Nations Committee of Experts on the Transport of Dangerous Goods.\n\n"}
{"id": "47770720", "url": "https://en.wikipedia.org/wiki?curid=47770720", "title": "List of nematode families", "text": "List of nematode families\n\nList of Nematoda has 25,000 recorded species from the Nematode phylum. There are estimated to be a million.\n\nSubclass Chromadoria\n\n\n\n\n\n\n\n"}
{"id": "50701085", "url": "https://en.wikipedia.org/wiki?curid=50701085", "title": "List of people who caught yellow fever", "text": "List of people who caught yellow fever\n\nThis articles documents notable people who were afflicted with yellow fever, whether or not they died from the disease. In 2013, approximately 127,000 individuals were diagnosed with severe cases of yellow fever.\n\n\n"}
{"id": "58044172", "url": "https://en.wikipedia.org/wiki?curid=58044172", "title": "Liz Neeley", "text": "Liz Neeley\n\nLiz Neeley is a science communicator and the Executive Director of The Story Collider, a nonprofit organization that focuses on true, personal stories inspired by science. She began her career in marine biology and conservation and has since become an expert in the use of narrative storytelling for effective science communication.\n\nNeeley received her Bachelor of Arts in Marine Biology in 2002. She then completed her Master's degree at Boston University in Ecology and Evolution in 2005. Her graduate research centered on the evolution of color patterns and visual communication systems in tropical reef fishes—wrasses and parrotfish—in the laboratory of Gil Rosenthal.\n\nFollowing graduate school, she began a career in marine conservation, applying her general subject matter knowledge to science advocacy. She began working at SeaWeb, a communications-based nonprofit organization committed to promoting understanding around ocean and conservation science to a host of stakeholders—from decision makers to community leaders to the media. By strategically communicating to these groups, SeaWeb worked to foster the development of measures to protect the ocean. From 2005 to 2006, Neeley worked with SeaWeb's Asia Pacific Program, partnering with local communities and researchers in Fiji and Papua New Guinea to build communications capacity for them to share their knowledge of local coral reefs ecosystems with the local media. In 2006, she transitioned to the role of Program Manager at SeaWeb, where she helped launch the \"Too Precious to Wear\" campaign, partnering with the fashion industry to raise awareness around the toll of dredging deep sea coral. The campaign sought to impose limits on coral use in fashion, design, and home decor through the Convention on International Trade in Endangered Species.\n\nFollowing her tenure at SeaWeb, Neeley focused her career more on efforts around science communication, training scientists on how best to share their knowledge of science with a range of stakeholders. She has served as a contributing author on a range of books on science communication. She wrote a section on utilizing social media to promote a scientist's work for \"Science Blogging: The Essential Guide\" and contributed a chapter on communicating controversial topics in science on social media in \"Effective Risk Communication\". She also co-authored \"Escape from the Ivory Tower: a guide to making your science matter\" during her time at the nonprofit COMPASS\".\"\n\nNeeley has lent her expertise to a number of groups centered on communicating science to the public, previously serving on the advisory board of the CommLab at MIT from 2015 to 2017 and on the Advisory Council of Ensia magazine. She also holds a Lecturer appointment at Yale School of Medicine in conjunction with the National Neuroscience Curriculum Initiative.\n\nIn 2008, Neeley joined COMPASS, a nonprofit organization co-founded by marine ecologist and former NOAA Administrator Jane Lubchenco to train scientists to more effectively share their expertise with journalists, decision makers, and the public at large. There, Neeley served as the Assistant Director of Science Outreach, working to develop their training programs in science communication and connecting scientists to public conversations around their expertise. She also launched COMPASS's training programs around how scientists can more effectively utilize social media to share their work and engage with a broader audience. During her tenure at COMPASS, she was affiliate staff at the University of Washington in the School of Aquatic & Fisheries Sciences.\n\nIn 2015, Neeley became the Executive Director of The Story Collider, a nonprofit organization that brings true, personal stories inspired by science to the public through live shows and a weekly podcast. The organization also trains scientists on how to employ the tools of storytelling to become better communicators. In this role, she's also spearheaded efforts in applying storytelling to more traditionally academic forms of communication, curating a collection of \"Conservation stories from the front lines\" for PLOS Biology. She has spoken about the importance of storytelling for science at a number of universities and organizations, including the Beckman Institute for Advanced Science and Technology, the University of Washington College of the Environment's Bevan Series, and at Northwestern University. In the policy arena, she has contributed a position paper on the use of narrative persuasion to help scientists ethically navigate the world of decision making at the Institute on Science for Global Policy in partnership with Sigma Xi.\n\nNeeley has also told stories of her own for The Story Collider, including a story about a field expedition gone awry during her time as an undergraduate and another about her colleagues forgetting her while working on coral conservation in Fiji.\n"}
{"id": "19934255", "url": "https://en.wikipedia.org/wiki?curid=19934255", "title": "Mechanica", "text": "Mechanica\n\nMechanica (; 1736) is a two-volume work published by mathematician Leonhard Euler which describes analytically the mathematics governing movement.\n\nEuler both developed the techniques of analysis and applied them to numerous problems in mechanics.\n\n"}
{"id": "1390149", "url": "https://en.wikipedia.org/wiki?curid=1390149", "title": "Medieval technology", "text": "Medieval technology\n\nMedieval technology is the technology used in medieval Europe under Christian rule. After the Renaissance of the 12th century, medieval Europe saw a radical change in the rate of new inventions, innovations in the ways of managing traditional means of production, and economic growth. The period saw major technological advances, including the adoption of gunpowder, the invention of vertical windmills, spectacles, mechanical clocks, and greatly improved water mills, building techniques (Gothic architecture, medieval castles), and agriculture in general (three-field crop rotation).\n\nThe development of water mills from their ancient origins was impressive, and extended from agriculture to sawmills both for timber and stone. By the time of the \"Domesday Book\", most large villages had turnable mills, around 6,500 in England alone. Water-power was also widely used in mining for raising ore from shafts, crushing ore, and even powering bellows.\n\nEuropean technical advancements from the 12th to 14th centuries were either built on long-established techniques in medieval Europe, originating from Roman and Byzantine antecedents, or adapted from cross-cultural exchanges through trading networks with the Islamic world, China, and India. Often, the revolutionary aspect lay not in the act of invention itself, but in its technological refinement and application to political and economic power. Though gunpowder along with other weapons had been started by Chinese, it was the Europeans who developed and perfected its military potential, precipitating European expansion and eventual imperialism in the Modern Era.\n\nAlso significant in this respect were advances in maritime technology. Advances in shipbuilding included the multi-masted ships with lateen sails, the sternpost-mounted rudder and the skeleton-first hull construction. Along with new navigational techniques such as the dry compass, the Jacob's staff and the astrolabe, these allowed economic and military control of the seas adjacent to Europe and enabled the global navigational achievements of the dawning Age of Exploration.\n\nAt the turn to the Renaissance, Gutenberg’s invention of mechanical printing made possible a dissemination of knowledge to a wider population, that would not only lead to a gradually more egalitarian society, but one more able to dominate other cultures, drawing from a vast reserve of knowledge and experience. The technical drawings of late-medieval artist-engineers Guido da Vigevano and Villard de Honnecourt can be viewed as forerunners of later Renaissance works such as Taccola or da Vinci.\n\nThe following is a list of some important medieval technologies. The approximate date or first mention of a technology in medieval Europe is given. Technologies were often a matter of cultural exchange and date and place of first inventions are not listed here (see main links for a more complete history of each).\n\nCarruca (6th to 9th centuries)\n\nA type of heavy wheeled plough commonly found in Northern Europe. The device consisted of four major parts. The first part was a Coulter (agriculture) at the bottom of the plough. This knife was used to vertically cut into the top sod to allow for the plowshare to work. The plowshare was the second pair of knives which cut the sod horizontally, detaching it from the ground below. The third part was the moldboard, which curled the sod outward. The fourth part of the device was the team of eight oxen guided by the farmer. This type of plough eliminated the need for cross-plowing by turning over the furrow instead of merely pushing it outward. This type of wheeled plough made seed placement more consistent throughout the farm as the blade could be locked in at a certain level relative to the wheels. A disadvantage to this type of plough was its maneuverability. Since this equipment was large and lead by a small herd of oxen, turning the plough was difficult and time-consuming. This caused many farmers to turn away from traditional square fields and adopt a longer, more rectangular field to ensure maximum efficiency.\n\nArd (plough) (5th century)\n\nAn early medieval plough that consisted of a sharpened wooden post pulled by either animals or humans. This lightweight and primitive plough was used primarily before the invention of the carruca. The ard was inefficient in more firm northern soil but did decent work in southern areas where the soil was much softer. Although the ard required the user to apply constant pressure to the plough in order to make sure the edge could break the ground, the soil was merely pushed to the sides instead of being properly turned over.\n\nHorse collar (6th to 9th centuries)\n\nOnce oxen started to be replaced by horses on farms and in fields, the yoke became obsolete due to its shape not working well with a horses' posture. The first design for a horse collar was a throat-and-girth-harness. These types of harnesses were unreliable though due to them not being sufficiently set in place. The loose straps were prone to slipping and shifting positions as the horse was working and often caused asphyxiation. Around the eighth century, the introduction of the rigid collar eliminated the problem of choking. The rigid collar was \"placed over the horses head and rested on its shoulders. This permitted unobstructed breathing and placed the weight of the plow or wagon where the horse could best support it.\"\n\nHorseshoes (9th century)\n\nAllowed horses to carry larger loads and move around with greater traction on hard to walk surfaces. The practice of shoeing horses was initially practiced in the Roman Empire but lost popularity throughout the Middle Ages until around the 11th century. Although horses in the southern lands could easily work while on the softer soil, the rocky soil of the north proved to be damaging to the horses' hooves. Since the north was the problematic area, this is where shoeing horses first became popular. The introduction of gravel roadways was also cause for the popularity of horseshoeing. The loads a shoed horse could take on these roads were significantly higher than one that was barefoot. By the 14th century, not only did horses have shoes, but many farmers were shoeing oxen and donkeys in order to help prolong the life of their hooves. The size and weight of the horseshoe changed significantly over the course of the middle ages. In the 10th century, horseshoes were secured by six nails and weighed around one-quarter of a pound, but throughout the years, the shoes grew larger and by the 14th century, the shoes were being secured with eight nails and weighed nearly half a pound.\n\nCrop rotation (8th century)\n\nAlso called the Two-field system. This system included the farmers' field being divided into two separate crops. One field would grow a crop while the other was allowed to lie fallow and was used to feed livestock and regain lost nutrients. Every year, the two fields would switch in order to ensure fields did not become nutrient deficient. In the 11th century, this system was introduced into Sweden and spread to become the most popular form of farming.\n\nThree-field system (8th century)\n\nThe ideal three-field system is one that separates a section of land into three equal parts. Each one of the three parts holds a different crop. One part holds a spring crop, such as barley or oats, another part holds a winter crop, such as wheat or rye, and the third part is an off-field that is left alone to grow and is used to help feed livestock. By rotating the three crops to a new part of the land after each year, the off-field regains some of the nutrients lost during the growing of the two crops. This system increases agricultural productivity over the Two-field system by only having one-third of the field not being used instead of one half. Another advantage of crop rotation is that many scholars believe it helped increase yields by up to 50%.\n\nWine press (12th century)\n\nThis device was the first practical means of Pressing (wine) on a plane surface. The wine press was an expensive piece of machinery that only the wealthy could afford. The method of Grape stomping was often used as a less expensive alternative. While white wines required the use of a wine press in order to preserve the color of the wine by removing the juices quickly from the skin, red wine did not need to be pressed until the end of the juice removal process since the color did not matter. Many red wine winemakers used their feet to smash the grapes then used a press to remove any juice that remained in the grape skins.\n\nQanat (5th century)\n\nAn underground passage used to water fields, crops, and provide drinking water. These tunnels had a gradual slope which used gravity to pull the water from either an aquifer or water well. This system was originally found in middle eastern areas and is still used today in places where surface water is hard to find.\n\nPendentive architecture (6th century)\n\nA specific spherical form in the upper corners to support a dome. Although the first experimentation was made in the 200s, it was in the 6th century in the Byzantine Empire that its potential was fully achieved.\n\nArtesian well (1126)\n\nA thin rod with a hard iron cutting edge is placed in the bore hole and repeatedly struck with a hammer, underground water pressure forces the water up the hole without pumping. Artesian wells are named after the town of Artois in France, where the first one was drilled by Carthusian monks in 1126.\n\nCentral heating through underfloor channels (9th century)\n\nIn the early medieval Alpine upland, a simpler central heating system where heat travelled through underfloor channels from the furnace room replaced the Roman hypocaust at some places. In Reichenau Abbey a network of interconnected underfloor channels heated the 300 m large assembly room of the monks during the winter months. The degree of efficiency of the system has been calculated at 90%.\n\nRib vault (12th century)\n\nAn essential element for the rise of Gothic architecture, rib vaults allowed vaults to be built for the first time over rectangles of unequal lengths. It also greatly facilitated scaffolding and largely replaced the older groin vault.\n\nChimney (12th century)\n\nThe earliest true chimneys appeared in Northern Europe during the 12th century, and with them came the first true fireplaces.\n\nSegmental arch bridge (1345)\n\nThe Ponte Vecchio in Florence is considered medieval Europe's first stone segmental arch bridge.\nTreadwheel crane (1220s)\n\nThe earliest reference to a treadwheel in archival literature is in France about 1225, followed by an illuminated depiction in a manuscript of probably also French origin dating to 1240. Apart from tread-drums, windlasses and occasionally cranks were employed for powering cranes.\n\nStationary harbour crane (1244)\n\nStationary harbour cranes are considered a new development of the Middle Ages; its earliest use being documented for Utrecht in 1244. The typical harbour crane was a pivoting structure equipped with double treadwheels. There were two types: wooden gantry cranes pivoting on a central vertical axle and stone tower cranes which housed the windlass and treadwheels with only the jib arm and roof rotating. These cranes were placed on docksides for the loading and unloading of cargo where they replaced or complemented older lifting methods like see-saws, winches and yards. Slewing cranes which allowed a rotation of the load and were thus particularly suited for dockside work appeared as early as 1340.\n\nFloating crane\n\nBeside the stationary cranes, floating cranes which could be flexibly deployed in the whole port basin came into use by the 14th century.\n\nMast crane\n\nSome harbour cranes were specialised at mounting masts to newly built sailing ships, such as in Gdańsk, Cologne and Bremen.\n\nWheelbarrow (1170s)\n\nThe wheelbarrow proved useful in building construction, mining operations, and agriculture. Literary evidence for the use of wheelbarrows appeared between 1170 and 1250 in north-western Europe. The first depiction is in a drawing by Matthew Paris in the mid-13th century.\n\nOil paint (by 1125)\n\nAs early as the 13th century, oil was used to add details to tempera paintings and paint wooden statues. Flemish painter Jan van Eyck developed the use of a stable oil mixture for panel painting around 1410.\n\nHourglass (1338)\n\nReasonably dependable, affordable and accurate measure of time. Unlike water in a clepsydra, the rate of flow of sand is independent of the depth in the upper reservoir, and the instrument is not liable to freeze. Hourglasses are a medieval innovation (first documented in Siena, Italy).\n\nMechanical clocks (13th to 14th centuries)\n\nA European innovation, these weight-driven clocks were used primarily in clock towers.\n\nCompound crank\n\nThe Italian physician Guido da Vigevano combines in his 1335 \"Texaurus\", a collection of war machines intended for the recapture of the Holy Land, two simple cranks to form a compound crank for manually powering war carriages and paddle wheel boats. The devices were fitted directly to the vehicle's axle respectively to the shafts turning the paddle wheels.\n\nBlast furnace (1150–1350)\n\nCast iron had been made in China before the 4th century BC. European cast iron first appears in Middle Europe (for instance Lapphyttan in Sweden, Dürstel in Switzerland and the Märkische Sauerland in Germany) around 1150, in some places according to recent research even before 1100. The technique is considered to be an independent European development.\n\nShip mill (6th century)\n\nThe ship mill is a Byzantine invention, designed to mill grains using hydraulic power. The technology eventually spread to the rest of Europe and was in use until ca. 1800.\nPaper mill (13th century)\n\nThe first certain use of a water-powered paper mill, evidence for which is elusive in both Chinese and Muslim paper making, dates to 1282.\n\nRolling mill (15th century)\n\nUsed to produce metal sheet of an even thickness. First used on soft, malleable metals, such as lead, gold and tin. Leonardo da Vinci described a rolling mill for wrought iron.\n\nTidal Mills (6th century)\n\nThe earliest tidal mills were excavated on the Irish coast where watermillers knew and employed the two main waterwheel types: a 6th-century tide mill at Killoteran near Waterford was powered by a vertical waterwheel, while the tide changes at Little Island were exploited by a twin-flume horizontal-wheeled mill (c. 630) and a vertical undershot waterwheel alongside it. Another early example is the Nendrum Monastery mill from 787 which is estimated to have developed seven to eight horsepower at its peak.\n\nVertical windmills (1180s)\n\nInvented in Europe as the pivotable post mill, the first surviving mention of one comes from Yorkshire in England in 1185. They were efficient at grinding grain or draining water. Stationary tower mills were also developed in the 13th century.\n\nWater hammer (12th century at the latest)\n\nUsed in metallurgy to forge the metal blooms from bloomeries and Catalan forges, they replaced manual hammerwork. The water hammer was eventually superseded by steam hammers in the 19th century.\n\nDry compass (12th century)\n\nThe first European mention of the directional compass is in Alexander Neckam's \"On the Natures of Things\", written in Paris around 1190. It was either transmitted from China or the Arabs or an independent European innovation. Dry compass were invented in the Mediterranean around 1300.\n\nAstronomical compass (1269)\n\nThe French scholar Pierre de Maricourt describes in his experimental study \"Epistola de magnete\" (1269) three different compass designs he has devised for the purpose of astronomical observation.\nStern-mounted rudders (1180s)\n\nThe first depiction of a pintle-and-gudgeon rudder on church carvings dates to around 1180. They first appeared with cogs in the North and Baltic Seas and quickly spread to Mediterranean. The iron hinge system was the first stern rudder permanently attached to the ship hull and made a vital contribution to the navigation achievements of the age of discovery and thereafter.\n\nMovable type printing press (1440s)\n\nJohannes Gutenberg's great innovation was not the printing itself, but instead of using carved plates as in woodblock printing, he used separate letters (\"types\") from which the printing plates for pages were made up. This meant the types were recyclable and a page cast could be made up far faster.\n\nPaper (13th century)\n\nPaper was invented in China and transmitted through Islamic Spain in the 13th century. In Europe, the paper-making processes was mechanized by water-powered mills and paper presses (see paper mill).\n\nRotating bookmark (13th century)\n\nA rotating disc and string device used to mark the page, column, and precise level in the text where a person left off reading in a text. Materials used were often leather, velum, or paper.\n\nSpectacles (1280s)\n\nThe first spectacles, invented in Florence, used convex lenses which were of help only to the far-sighted. Concave lenses were not developed prior to the 15th century.\n\nWatermark (1282)\n\nThis medieval innovation was used to mark paper products and to discourage counterfeiting. It was first introduced in Bologna, Italy.\n\nTheory of impetus (6th century)\n\nA scientific theory that was introduced by John Philoponus who made criticism of Aristotelian principles of physics, and it served as an inspiration to medieval scholars as well as to Galileo Galilei who ten centuries later, during the Scientific Revolution, extensively cited Philoponus in his works while making the case as to why Aristotelian physics was flawed. It is the intellectual precursor to the concepts of inertia, momentum and acceleration in classical mechanics.\n\nArabic numerals (13th century)\n\nThe first recorded mention in Europe was in 976, and they were first widely published in 1202 by Fibonacci with his \"Liber Abaci\".\n\nUniversity\n\nThe first medieval universities were founded between the 11th and 13th centuries leading to a rise in literacy and learning. By 1500, the institution had spread throughout most of Europe and played a key role in the Scientific Revolution. Today, the educational concept and institution has been globally adopted.\n\nFunctional button (13th century)\n\nGerman buttons appeared in 13th-century Germany as an indigenous innovation. They soon became widespread with the rise of snug-fitting clothing.\n\nHorizontal loom (11th century)\n\nHorizontal looms operated by foot-treadles were faster and more efficient.\n\nSilk (6th century)\n\nManufacture of silk began in Eastern Europe in the 6th century and in Western Europe in the 11th or 12th century. Silk had been imported over the Silk Road since antiquity. The technology of \"silk throwing\" was mastered in Tuscany in the 13th century. The silk works used waterpower and some regard these as the first mechanized textile mills.\n\nSpinning wheel (13th century)\n\nBrought to Europe probably from India.\n\nChess (1450)\n\nThe earliest predecessors of the game originated in 6th-century AD India and spread via Persia and the Muslim world to Europe. Here the game evolved into its current form in the 15th century.\n\nForest glass (c. 1000)\n\nThis type of glass uses wood ash and sand as the main raw materials and is characterised by a variety of greenish-yellow colours.\n\nGrindstones (834)\n\nGrindstones are a rough stone, usually sandstone, used to sharpen iron. The first rotary grindstone (turned with a leveraged handle) occurs in the \"Utrecht Psalter\", illustrated between 816 and 834. According to Hägermann, the pen drawing is a copy of a late-antique manuscript. A second crank which was mounted on the other end of the axle is depicted in the \"Luttrell Psalter\" from around 1340.\n\nLiquor (12th century)\n\nPrimitive forms of distillation were known to the Babylonians, as well as Indians in the first centuries AD. Early evidence of distillation also comes from alchemists working in Alexandria, Roman Egypt, in the 1st century. The medieval Arabs adopted the distillation process, which later spread to Europe. Texts on the distillation of waters, wine, and other spirits were written in Salerno and Cologne in the twelfth and thirteenth centuries.\n\nLiquor consumption rose dramatically in Europe in and after the mid-14th century, when distilled liquors were commonly used as remedies for the Black Death. These spirits would have had a much lower alcohol content (about 40% ABV) than the alchemists' pure distillations, and they were likely first thought of as medicinal elixirs. Around 1400, methods to distill spirits from wheat, barley, and rye were discovered. Thus began the \"national\" drinks of Europe, including gin (England) and \"grappa\" (Italy). In 1437, \"burned water\" (brandy) was mentioned in the records of the County of Katzenelnbogen in Germany. \n\nMagnets (12th century)\n\nMagnets were first referenced in the \"Roman d'Enéas\", composed between 1155 and 1160.\n\nMirrors (1180)\n\nThe first mention of a \"glass\" mirror is in 1180 by Alexander Neckham who said \"Take away the lead which is behind the glass and there will be no image of the one looking in.\"\n\nIllustrated surgical atlas (1345)\n\nGuido da Vigevano (c. 1280 − 1349) was the first author to add illustrations to his anatomical descriptions. His \"Anathomia\" provides pictures of neuroanatomical structures and techniques such as the dissection of the head by means of trephination, and depictions of the meninges, cerebrum, and spinal cord.\n\nQuarantine (1377)\n\nInitially a 40-day-period, the quarantine was introduced by the Republic of Ragusa as a measure of disease prevention related to the Black Death. It was later adopted by Venice from where the practice spread all around in Europe.\n\nRat traps (1170s)\n\nThe first mention of a rat trap is in the medieval romance \"Yvain, the Knight of the Lion\" by Chrétien de Troyes.\n\nSoap (9th century)\n\nSoap came into widespread European use in the 9th century in semi-liquid form, with hard soap perfected by the Arabs in the 12th century.\n\nQuilted Armour (pre 5th - 14th Century)\n\nThere was a vast amount of armour technology available through the 5th to 16th centuries. \nMost soldiers during this time wore padded or quilted armor. This was the cheapest and most available armor for the majority of soldiers. Quilted armour was usually just a jacket made of thick linen and wool meant to pad or soften the impact of blunt weapons and light blows. Although, this technology predated the 5th century, it was still extremely prevalent because of the low cost and the weapon technology at the time made the bronze armor of the Greeks and Romans obsolete. Quilted armour was also used in conjunction with other types of armour. Usually worn over or under leather, mail, and later plate armour.\n\nCuir Bouilli (5th-10th Century)\n\nHardened leather armour also called Cuir Bouilli was a step up from quilted armour. Made by boiling leather in either water, wax or oil to soften it so it can be shaped, it would then be allowed to dry and become very hard. Large pieces of armour could be made such as breast plates, helmets, and leg guards, but many times smaller pieces would be sewn into the quilting of quilted armour or strips would be sewn together on the outside of a linen jacket. This was not as affordable as the quilted armour but offered much better protection against edged slashing weapons.\n\nChain Mail (11th-16th Century)\n\nThe most common type during the 11th through the 16th centuries was the Hauberk, also known earlier than the 11th century as the Carolingian byrnie. Made of interlinked rings of metal, it sometimes consisted of a coif that covered the head and a tunic that covered the torso, arms, and legs down to the knees. Chain mail was very effective at protecting against light slashing blows but ineffective against stabbing or thrusting blows. The great advantage was that it allowed a great freedom of movement and was relatively light with significant protection over quilted or hardened leather armour. It was far more expensive than the hardened leather or quilted armour because of the massive amount of labor it required to create. This made it unattainable for most soldiers and only the more wealthy soldiers could afford it. Later, toward the end of the 13th century banded mail became popular. Constructed of washer shaped rings of iron overlapped and woven together by straps of leather as opposed to the interlinked metal rings of chain mail, banded mail was much more affordable to manufacture. The washers were so tightly woven together that it was very difficult penetrate and offered greater protection from arrow and bolt attacks. \n\nJazerant (11th century)\n\nThe Jazerant or Jazeraint was an adaptation of chain mail in which the chain mail would be sewn in between layers of linen or quilted armour. Exceptional protection against light slashing weapons and slightly improved protection against small thrusting weapons, but little protection against large blunt weapons such as maces and axes. This gave birth to reinforced chain mail and became more prevalent in the 12th and 13th century. Reinforced armour was made up of chain mail with metal plates or hardened leather plates sewn in. This greatly improved protection from stabbing and thrusting blows. \n\nScale Armour (12th century)\n\nA type of Lamellar armour, was made up entirely of small, overlapping plates. Either sewn together, usually with leather straps, or attached to a backing such as linen, or a quilted armor. Scale armour does not require the labor to produce that chain mail does and therefore is more affordable. It also affords much better protection against thrusting blows and pointed weapons. Though, it is much heavier, more restrictive and impedes free movement. \n\nPlate Armour (14th century)\n\nPlate armour covered the entire body. Although parts of the body were already covered in plate armour as early as 1250, such as the Poleyns for covering the knees and Couters - plates that protected the elbows, the first complete full suit without any textiles was seen around 1410-1430. Components of medieval armour that made up a full suit consisted of a cuirass, a gorget, vambraces, gauntlets, cuisses, greaves, and sabatons held together by internal leather straps. Improved weaponry such as crossbows and the long bow had greatly increased range and power. This made penetration of the chain mail hauberk much easier and more common. By the mid 1400's most plate was worn alone and without the need of a hauberk. Advances in metal working such as the blast furnace and new techniques for carburizing made plate armour nearly impenetrable and the best armour protection available at the time. Although plate armour was fairly heavy, because each suit was custom tailored to the wearer, it was very easy to move around in. A full suit of plate armour was extremely expensive and mostly unattainable for the majority of soldiers. Only very wealthy land owners and nobility could afford it. The quality of plate armour increases as more armour makers became more proficient in metal working. A suit of plate armour became a symbol of social status and the best made were personalized with embellishments and engravings. Plate armour saw continued use in battle until the 17th century.\n\nArched saddle (11th century)\n\nThe arched saddle enabled mounted knights to wield lances underarm and prevent the charge from turning into an unintentional pole-vault. This innovation gave birth to true shock cavalry, enabling fighters to charge on full gallop.\n\nSpurs (11th century)\n\nSpurs were invented by the Normans and appeared at the same time as the cantled saddle. They enabled the horseman to control his horse with his feet, replacing the whip and leaving his arms free. Rowel spurs familiar from cowboy films were already known in the 13th century. Gilded spurs were the ultimate symbol of the knighthood - even today someone is said to \"earn his spurs\" by proving his or her worthiness.\n\nStirrup (6th century)\n\nStirrups were invented by steppe nomads in what is today Mongolia and northern China in the 4th century. They were introduced in Byzantium in the 6th century and in the Carolingian Empire in the 8th. They allowed a mounted knight to wield a sword and strike from a distance leading to a great advantage for mounted cavalry.\n\nCannon (1324)\n\nCannons are first recorded in Europe at the siege of Metz in 1324. In 1350 Petrarch wrote \"these instruments which discharge balls of metal with most tremendous noise and flashes of fire...were a few years ago very rare and were viewed with greatest astonishment and admiration, but now they are become as common and familiar as any other kinds of arms.\"\n\nVolley gun\n\nSee Ribauldequin.\n\nCorned gunpowder (late 14th century)\n\nFirst practiced in Western Europe, corning the black powder allowed for more powerful and faster ignition of cannons. It also facilitated the storage and transportation of black powder. Corning constituted a crucial step in the evolution of gunpowder warfare.\nSupergun (late 14th century)\n\nExtant examples include the wrought-iron Pumhart von Steyr, Dulle Griet and Mons Meg as well as the cast-bronze Faule Mette and Faule Grete (all from the 15th century).\n\nCounterweight trebuchet (12th century)\n\nPowered solely by the force of gravity, these catapults revolutionized medieval siege warfare and construction of fortifications by hurling huge stones unprecedented distances. Originating somewhere in the eastern Mediterranean basin, counterweight trebuchets were introduced in the Byzantine Empire around 1100 CE, and was later adopted by the Crusader states and as well by the other armies of Europe and Asia.\n\nGreek fire (7th century)\n\nAn incendiary weapon which could even burn on water is also attributed to the Byzantines where they installed it on their ships. It played a crucial role in the Byzantine Empire's victory over the Umayyad Caliphate during the Siege of Constantinople (717–718)\n\nGrenade (8th century) \n\nRudimentary incendiary grenades appeared in the Byzantine Empire, as the Byzantine soldiers learned that Greek fire, a Byzantine invention of the previous century, could not only be thrown by flamethrowers at the enemy, but also in stone and ceramic jars. \n\nLongbow with massed, disciplined archery (13th century)\n\nHaving a high rate of fire and penetration power, the longbow contributed to the eventual demise of the medieval knight class. Used particularly by the English to great effect against the French cavalry during the Hundred Years' War (1337–1453).\n\nSteel crossbow (late 14th century)\n\nEuropean innovation. Came with several different cocking aids to enhance draw power, making the weapons also the first hand-held mechanical crossbows.\n\nCombined arms tactics (14th century)\n\nThe battle of Halidon Hill 1333 was the first battle where intentional and disciplined combined arms infantry tactics were employed. The English men-at-arms dismounted aside the archers, combining thus the staying power of super-heavy infantry and striking power of their two-handed weapons with the missiles and mobility of the archers using longbows and shortbows\n. Combining dismounted knights and men-at-arms with archers was the archetypal Western Medieval battle tactics until the battle of Flodden 1513 and final emergence of firearms.\n\n\n\n"}
{"id": "27935347", "url": "https://en.wikipedia.org/wiki?curid=27935347", "title": "Minisuperspace", "text": "Minisuperspace\n\nIn quantum gravity, the phase space is infinite dimensional as we are dealing with a field theory. An approximation which is sometimes taken is to only consider the largest wavelength modes of the order of the size of the universe when studying cosmological models. This is the minisuperspace approximation. The validity of this approximation holds as long as the adiabatic approximation holds.\n\nAn example would be to only consider the scale factor and Hubble constant for a Friedman-Robertson-Walker model in minisuperspace model the small true vacuum bubble which is nearly spherical with one single parameter of the scalar factor a is described as minisuperspace. It plays a significant role in the explanation of the origin of universe as a bubble in quantum cosmological theory.\n"}
{"id": "21344483", "url": "https://en.wikipedia.org/wiki?curid=21344483", "title": "Miroslav Hajn", "text": "Miroslav Hajn\n\nMiroslav Hajn (21 September 1894 in Žamberk, Austria-Hungary – 6 September 1963 in Prague, Czechoslovakia) was a chief designer at ČKD-Praga, one of the largest engineering companies in the former Czechoslovakia and today's Czech Republic.\n\nHajn was first a founder and chief designer at Avia, along with Pavel Beneš, in 1919. The two began repairing planes in a workshop within the complex of an old sugar factory in Prague. One year later, they designed their first two-seater plane, the Avia BH-1. From 1923 to 1925, the two developed the Avia BH-7, BH-9, and BH-11 monoplanes, launching the era of biplane fighters. The BH-11 won the Coppa d' Italia prize. Three years later, their Avia BH-21 fighter was considered one of the world's best planes.\n\nIn 1930, Hajn and Beneš came to ČKD-Praga. The first aircraft they designed was the Praga E-39 in 1931.\n"}
{"id": "1417988", "url": "https://en.wikipedia.org/wiki?curid=1417988", "title": "Neofunctionalism (sociology)", "text": "Neofunctionalism (sociology)\n\nNeofunctionalism is the perspective that all integration is the result of past integration. The term may also be used to literally describe a social theory that is 'post' traditional structural functionalism. Whereas theorists such as Jeffrey C. Alexander openly appropriated the term, others, such as the post-structuralist philosopher Michel Foucault, have been categorized as contemporary functionalists by their critics.\n\nFunctionalism in international relations theory was developed by David Mitrany. International relations neofunctionalism was developed by Ernst Haas in the 1960s to give a formal explanation to the work of Jean Monnet (1888–1979).\n\nIn sociology, neofunctionalism represents a revival of the thought of Talcott Parsons by Jeffrey C. Alexander, who sees neofunctionalism as having 5 central tendencies:\n\nWhile Parsons consistently viewed actors as analytical concepts, Alexander defines action as the movement of concrete, living, breathing persons as they make their way through time and space. In addition he argues that every action contains a dimension of free will, by which he is expanding functionalism to include some of the concerns of symbolic interactionism.\n\nNeil J. Smelser sets out to establish the concept of ambivalence as an essential element of understanding individual behavior and social institutions. His approach, based on Freud’s theory, takes intrapsychic processes rather than roles at the starting point. He sees ambivalence (to hold opposing affective orientations toward the same person object or symbol) as most applicable in situations where persons are dependent on one another. The common element of dependency is in his opinion that freedom to leave is restricted because it is costly either politically, ideologically or emotionally. Thus dependence entails entrapment. Following his views on ambivalence, Smelser argues that attitude surveys should be seen as distorted structures of reality that minimize and delegitimizes ambiguity and ambivalence.\n\nNiklas Luhmann sees Parsons’ theory as missing the concepts of self-reference and complexity. Self-reference is a condition for the efficient functioning of systems. It means that a system is able to observe itself, can reflect on itself and can make decisions as a result of this reflection. In Luhmann’s theory, the chief task performed by social systems is to reduce complexity, which brings more choices and more possibilities; it takes more noes to reach a \"yes\". Religion or functional equivalents in modern society can provide actors with shared standards of action accepted on faith, which allow complex sets of interactions to proceed in a world that would otherwise be chaotic and incomprehensible.\n\nFurthermore Luhmann makes the distinction between risk, a potential harm threatening an individual that is based on a decision made by the individual, and danger, a potential harm to which an individual is passively exposed. The critical difference between the decision maker and the people affected by the decision is that what is a risk for one is a danger for the other. Whereas people in primitive societies were threatened primarily by dangers, people in modern society are threatened primarily by risks caused by our dependency on the decision makers.\n\n"}
{"id": "3847721", "url": "https://en.wikipedia.org/wiki?curid=3847721", "title": "Optical Gravitational Lensing Experiment", "text": "Optical Gravitational Lensing Experiment\n\nThe Optical Gravitational Lensing Experiment (OGLE) is a Polish astronomical project based at the University of Warsaw that runs a long-term variability sky survey (1992-present). Main goals are the detection and classification of variable stars (pulsating and eclipsing), discoveries of the microlensing events, dwarf novae, studies of the Galaxy structure and the Magellanic Clouds. Since the project began in 1992, it has discovered multitude of extrasolar planets, together with a first planet discovered using transit method (OGLE-TR-56b) and gravitational microlensing method. The project from its inception is led by Prof. Andrzej Udalski.\n\nThe main targets of the experiment are the Magellanic Clouds and the Galactic Bulge, because of the large number of intervening stars that can be used for microlensing during a stellar transit. Most of the observations have been made at the Las Campanas Observatory in Chile. Cooperating institutions include Princeton University and the Carnegie Institution.\n\nThe project is now in its fourth phase. The first phase, OGLE-I (1992–1995), was the project pilot phase; for OGLE-II (1996–2000), a telescope was specially constructed, placed in Las Campanas Observatory and dedicated to the project. The 8-chip mosaic CCD camera was built in Poland and shipped to Chile. OGLE-III (2001–2009) was primarily devoted to detecting gravitational microlensing events and transiting planets in four fields: the Galactic Bulge, the constellation Carina, and toward both Magellanic Clouds. As a byproduct of the constant monitoring of hundreds of millions of stars, the largest catalogs of variable stars were constructed, and the first exoplanets discovered using the microlensing technique were detected. In 2010, following engineering work in 2009, the fourth and current phase, OGLE-IV, was started using a 32-chip mosaic CCD camera. The main goal for this phase is to increase the number of planetary detections using microlensing, enabled by the new camera.\n\nRecently the OGLE team, in cooperation with scientists mostly from USA, New Zealand and Japan, proved that small, Earth-like planets can exist in great distance from stars around which they revolve despite there being other stars near them.\n\nAt least seventeen planets have so far been discovered by the OGLE project. Eight of the planets were discovered by the transit method and six by the gravitational microlensing method.\n\nPlanets are shown in the order of discovery. Planets in multiple-planet systems are highlighted in yellow. Please note that list below may not be complete.\n\n\"Notes: For events detected by the gravitational microlensing method, year stands for OGLE season, BLG means that an event detected is in the Galactic BuLGe, and the following 3-digit number is an ordinal number of microlensing event in that season. For events detected by the transit method TR stands for TRansit and the following 3-digit number is an ordinal number of transit event.\"\n\n"}
{"id": "55360512", "url": "https://en.wikipedia.org/wiki?curid=55360512", "title": "Parakanã people", "text": "Parakanã people\n\nThe Parakanã people or Parakána people are one of the Indigenous peoples in Brazil, speaking a language of the Tupi-Guarani group. They traditionally occupy land in the region of the Pacajá and Tocantins rivers, and subsist by hunting and slash-and-burn agriculture.\n\n"}
{"id": "475425", "url": "https://en.wikipedia.org/wiki?curid=475425", "title": "Particle Physics and Astronomy Research Council", "text": "Particle Physics and Astronomy Research Council\n\nThe Particle Physics and Astronomy Research Council (PPARC) was one of a number of research councils in the United Kingdom. It directed, coordinated and funded research in particle physics and astronomy for the people of the UK. Its head office was at Polaris House in Swindon, Wiltshire, but it also operated three scientific sites: the UK Astronomy Technology Centre (UK ATC) in Edinburgh, the Isaac Newton Group of Telescopes (ING) in La Palma and the Joint Astronomy Centre (JAC) in Hawaii. It published the \"Frontiers\" magazine three times a year, containing news and highlights of the research and outreach programmes it supports.\n\nThe PPARC was formed in April 1994 when the Science and Engineering Research Council was split into several organizations; other products of the split included the Engineering and Physical Sciences Research Council (EPSRC) and the Biotechnology and Biological Sciences Research Council (BBSRC). In April 2007, it merged with the Council for the Central Laboratory of the Research Councils (CCLRC) and the nuclear physics portion of the EPSRC to form the new Science and Technology Facilities Council (STFC).\n\nPPARC previously published a magazine called \"Frontiers\", .\n\n"}
{"id": "22637027", "url": "https://en.wikipedia.org/wiki?curid=22637027", "title": "Principle of Typification", "text": "Principle of Typification\n\nIn biological nomenclature, the Principle of Typification is one of the guiding principles.\n\nThe \"International Code of Zoological Nomenclature\" provides that any named taxon in the family group, genus group, or species group have a name-bearing type which allows the name of the taxon to be objectively applied. The type does not define the taxon: that is done by a taxonomist; and an indefinite number of competing definitions can exist side by sided . Rather, a type is a point of reference. A name has a type, and a taxonomist (having defined the taxon) can determine which existing types fall within the scope of the taxon. He or she can then use the rules in the Code to determine the valid name for the taxon.\n"}
{"id": "43007354", "url": "https://en.wikipedia.org/wiki?curid=43007354", "title": "Responsible Research and Innovation", "text": "Responsible Research and Innovation\n\nResponsible Research and Innovation (RRI) is a term used by the European Union's Framework Programmes to describe scientific research and technological development processes that take into account effects and potential impacts on the environment and society. It gained visibility around the year 2010, arising from predecessors including \"ELSA\" (Ethical, Legal and Social Aspects) studies prompted by the Human Genome Project. Various slightly different definitions of RRI emerged, but all of them agree that societal challenges should be a primary focus of scientific research, and moreover they agree upon the methods by which that goal should be achieved. RRI involves holding research to high ethical standards, ensuring gender equality in the scientific community, investing policy-makers with the responsibility to avoid harmful effects of innovation, engaging the communities affected by innovation and ensuring that they have the knowledge necessary to understand the implications by furthering science education and Open Access. Organizations that adopted the RRI terminology include the Engineering and Physical Sciences Research Council and the Netherlands Organization for Scientific Research, the latter of which incorporated the language of RRI into their pre-existing program for funding \"Societally Responsible Innovating\".\n\n\"Horizon 2020\", the European Commission's program for science funding announced in 2013, made RRI a main focus. In 2014, it was suggested that the \"broader impacts\" criteria of the National Science Foundation were, despite certain dissimilarities, in effect coming to resemble RRI standards.\n\nOne area in which RRI principles are being applied is quantum computing. A research collaboration led by Oxford University within the UK National Quantum Technologies Programme aims to reveal how quantum computing can be socially and economically transformative, and to identify the potential downsides of the \"disruption\" it might bring about.\n\nAmong the criticisms voiced about RRI, prominent concerns include the vagueness of the terminology, the possibility of discouraging blue skies research and the lack of sufficient practical reward for embracing RRI in a research culture based on competition and short-term contracts.\n\n"}
{"id": "474177", "url": "https://en.wikipedia.org/wiki?curid=474177", "title": "Rodolfo Gambini", "text": "Rodolfo Gambini\n\nRodolfo Gambini (born May 11, 1946) is a physicist and professor of the Universidad de la Republica in Montevideo, Uruguay and a visiting professor at the Horace Hearne Institute for Theoretical Physics at the Louisiana State University.\n\nHe works on loop quantum gravity. He got his PhD in Université de Paris VI working with Achilles Papapetrou. From there he moved to the Universidad Simón Bolívar in Venezuela where he rose through the professorial ranks. It was there that together with fellow physicist Antoni Trías he invented the loop representation for Yang-Mills theories in 1986.\n\nGambini returned to Uruguay in 1987 after democracy had returned to the country. Gambini has published over 100 scientific articles ranging from philosophy of science and foundations of quantum mechanics to lattice gauge theories to quantum gravity. He was head of the Pedeciba, the main funding agency for basic sciences in Uruguay (2003–2008). He is a fellow of the American Physical Society and of the American Association for Advancement of Science, a member of the Third World Academy of Sciences, the Latin American Academy of Sciences and the Academy of Exact and Natural Sciences of Argentina. He is the 2003 winner of the Third World Academ of Sciences prize in physics and has received numerous distinctions in Uruguay. In particular he was awarded the 2004 Presidential Medal of Science, the Prize to the Intellectual Work in 2011 and made an honorary doctorate of the University of the Republic in 2010.\n\nIn recent years he has studied issues in the foundations of quantum mechanics, having developed the Montevideo Interpretation of Quantum Mechanics. He also found the exact solution of the quantum Einstein equations in loop quantum gravity for vacuum spherically symmetric space-times, which resolves the singularity inside black holes.\n\nGambini is a recipient of the 2003 TWAS Prize.\n\n\n"}
{"id": "24528574", "url": "https://en.wikipedia.org/wiki?curid=24528574", "title": "Scintillating bolometer", "text": "Scintillating bolometer\n\nA scintillating bolometer (or luminescent bolometer) is a scientific instrument used particle physics in the search for events with low energy deposition. These events could include dark matter, low energy solar neutrinos, double beta decay or rare radioactive decay. It works by simultaneously measuring both the light pulse and heat pulse generated by a particle interaction within its internal scintillator crystal. The device was originally proposed by L. Gonzalez-Mestres and D. Perret-Gallix (LAPP, IN2P3/CNRS)\n\nIn their rapporteur contribution to the Proceedings of the XXIV International Conference on High-Energy Physics, Munich, August 1988, Gonzalez-Mestres and Perret-Gallix wrote :\n\n\"Perhaps bolometry should in some cases be combined with other detection techniques (luminescence?) in order to produce a primary fast signal as timing strobe. If light is used as a complementary signature, particle identification can be achieved through the heat-light ratio, where nucleus recoil is expected to be less luminescent than ionizing particles. The success of such a development would open the way to unprecedented achievements in background rejection for rare event experiments.\"\n\nFurther explanations, including a description of the detector and possible applications incorporating in particular BGO and tungstates, were given by these authors in other papers such as their contribution to the March 1989 Moriond Meeting (pages 16-18).\n\nThe luminescent bolometer has since then been developed by scientists from several groups, including the CNRS Institut d'Astrophysique Spatiale and University of Zaragoza collaboration in view of the proposed ROSEBUD particle detector experiment in the Canfranc Underground Laboratory. Rosebud uses a bismuth germanate (BiGeO, \"BGO\") detector crystal. \n\nThe CRESST collaboration is currently using the same kind of device with CaWO crystals in an experiment to detect dark matter at Laboratori Nazionali del Gran Sasso.\n\n"}
{"id": "56418106", "url": "https://en.wikipedia.org/wiki?curid=56418106", "title": "Skyline (software)", "text": "Skyline (software)\n\nSkyline is an open source software for targeted proteomics and metabolomics data analysis. It runs on Microsoft Windows and supports the raw data formats from multiple mass spectrometric vendors. It contains a graphical user interface to display chromatographic data for individual peptide or small molecule analytes.\n\nSkyline supports multiple workflows including selected reaction monitoring (SRM) / multiple reaction monitoring (MRM), parallel reaction monitoring (PRM), data-independent acquisition (DIA/SWATH) and targeted data-dependent acquisition.\n\n"}
{"id": "37783973", "url": "https://en.wikipedia.org/wiki?curid=37783973", "title": "Status generalization", "text": "Status generalization\n\nWithin the context of sociology, and as defined by Webster and Driskell, status generalization is \"the process by which statuses of actors external to a particular interaction are imported and allowed to determine important features of that interaction.\" As an example, Webster and Driskell cite the tendency of white male executives to rise to leadership within a group even when their executive skills are not relevant to the group's task.\n\nStatus generalization is highly researched when looking into racism, discrimination, and the stereotyping that results from this. Brezina and Winder (2003) researched whites’ racial stereotyping of blacks and the association between blacks and lower socioeconomic statuses. They found that negative racial stereotyping is fueled by the continuing association between race and economic disadvantage, that “if blacks continue to fall behind economically, then they must not be trying hard enough”. The results of their research shows that the mere awareness that whites have about the relatively disadvantaged position blacks are in contributes to the negative stereotyping and thus contributes to negative status generalization when within groups.\n\nThe dissertation done by Monroe illustrates how hierarchies of status are created and become legitimized. The dissertation particularly focuses on the situation in where a low status person gains legitimate authority or power in higher status positions. They theory was tested using an experiment designed to have two by two groups working on cooperative tasks. One of the pair was a confederate trying to display dominant characteristics and the reactions to the dominant behaviors served as the dependent variable in the study. Results of the study show that performance evaluation had an effect on influence and status consistency.\n\nThe concept of status generalization can be applied particularly when looking at groups that are task oriented. Group members' external status (race, age, gender, or occupation) may determine their roles within the group more than their particular skills to achieve the group's goals.\n\nModern social psychologists have taken interest in the underpinnings of status generalization. The expression of status generalization is salient in everyday life, but motives have remained relatively ambiguous. Researchers Oldmeadow, Platow, & Foddy present an explanation, “the underlying psychological process that gives rise to (status generalization) in naturally occurring task-groups is psychological group formation, understood as self-categorization and social identification with other task-group members.” The researchers remind readers that people naturally identify with others due to characteristics such as SES, race, and gender. After identifying with others, people establish a pecking order that predicts group influence such as speaking order and command of topic.\n\nWhen people are put into task groups and physical status characteristics are made salient (skin color, age, social economic status), those individuals with the best perceived characteristics are more likely to be rewarded with more power and prestige. Even when status characteristics are irrelevant to the task at hand they still have an effect the role one is given. Those who have the skills that are relevant to a task are often over looked if they are a minority and too much emphasis can be placed on someone in the group if they are of a high status outside of the group; even if the skills that they have are irrelevant to the task.\n"}
{"id": "1922004", "url": "https://en.wikipedia.org/wiki?curid=1922004", "title": "Super High Altitude Research Project", "text": "Super High Altitude Research Project\n\nThe Super High Altitude Research Project (Super HARP, SHARP) was a U.S. government project conducting research into the firing of high-velocity projectiles high into the atmosphere using a two-stage light-gas gun, with the ultimate goal of propelling satellites into Earth orbit. Design work on the prototype space gun began as early as 1985 at the Lawrence Livermore National Laboratory in California and became operational in December 1992. It is the largest gas gun in the world.\n\nRather than a single straight barrel, the SHARP gun uses an L-shape design with 2 separate sections; the long steel combustion section & pump tube section is connected to the long launch tube (or barrel) at a right angle. 100-ton rail-mounted sleds sit at both ends of the pump tube to absorb recoil energy from firing and a smaller 10-ton sled is mounted on a perpendicular set of tracks at the aft-end of the launch-tube near the junction point.\n\nThe firing sequence begins with the ignition of a methane gas mixture in the combustion section behind the piston at the far end of the pump tube. The resultant explosion rapidly drives the 1-ton steel piston down the pump tube and further compresses the pre-pressurized hydrogen gas that fills the other end of the pump tube. As the piston accelerates toward the junction point, it rapidly compresses the hydrogen gas in the pump tube to a pressure of . The small projectile, meanwhile, rests in the adjacent depressurized launch tube. As the hydrogen gas reaches maximum pressure, a coupling holding the projectile in place is destroyed and the hydrogen drives the projectile down a 4-in diameter barrel at extremely high velocities until it bursts through a thin plastic sheet covering the end of the gun. All recoil forces are absorbed by the rail-mounted sleds as they are propelled outwards along their tracks.\n\nHeaded by John Hunter, the SHARP gun fired projectiles using expanding hydrogen and achieved velocities of or Mach 8.8 for projectiles. Had the project continued, there were plans to elevate the tube and begin space launch trials potentially reaching speeds of up to , or about Mach 21.\n\nThe tests were designed as a precursor to the \"\"Jules Verne Launcher\",\" an even larger light-gas gun with a barrel length designed in the early 1990s for first-stage satellite launch. This was to cost $1 billion, but funding was not forthcoming and the project was eventually canceled in 1995. However, the SHARP gun continued to be used for high-speed tests in other areas of research, such as scramjet development.\n\nThe concept of ballistic escape velocity is well proven. The largest challenge is maintaining such high velocities, because air resistance and aerothermal heating will significantly slow down any such object.\n\n"}
{"id": "39580830", "url": "https://en.wikipedia.org/wiki?curid=39580830", "title": "Symmetry in quantum mechanics", "text": "Symmetry in quantum mechanics\n\nSymmetries in quantum mechanics describe features of spacetime and particles which are unchanged under some transformation, in the context of quantum mechanics, relativistic quantum mechanics and quantum field theory, and with applications in the mathematical formulation of the standard model and condensed matter physics. In general, symmetry in physics, invariance, and conservation laws, are fundamentally important constraints for formulating physical theories and models. In practice, they are powerful methods for solving problems and predicting what can happen. While conservation laws do not always give the answer to the problem directly, they form the correct constraints and the first steps to solving a multitude of problems.\n\nThis article outlines the connection between the classical form of continuous symmetries as well as their quantum operators, and relates them to the Lie groups, and relativistic transformations in the Lorentz group and Poincaré group.\n\nThe notational conventions used in this article are as follows. Boldface indicates vectors, four vectors, matrices, and vectorial operators, while quantum states use bra–ket notation. Wide hats are for operators, narrow hats are for unit vectors (including their components in tensor index notation). The summation convention on the repeated tensor indices is used, unless stated otherwise. The Minkowski metric signature is (+−−−).\n\nGenerally, the correspondence between continuous symmetries and conservation laws is given by Noether's theorem.\n\nThe form of the fundamental quantum operators, for example energy as a partial time derivative and momentum as a spatial gradient, becomes clear when one considers the initial state, then changes one parameter of it slightly. This can be done for displacements (lengths), durations (time), and angles (rotations). Additionally, the invariance of certain quantities can be seen by making such changes in lengths and angles, which illustrates conservation of these quantities.\n\nIn what follows, transformations on only one-particle wavefunctions in the form:\n\nare considered, where formula_2 denotes a unitary operator. Unitarity is generally required for operators representing transformations of space, time, and spin, since the norm of a state (representing the total probability of finding the particle somewhere with some spin) must be invariant under these transformations. The inverse is the Hermitian conjugate formula_3. The results can be extended to many-particle wavefunctions. Written in Dirac notation as standard, the transformations on quantum state vectors are:\n\nNow, the action of formula_2 changes \"ψ\"(r, \"t\") to \"ψ\"(r′, \"t\"′), so the inverse formula_3 changes \"ψ\"(r′, \"t\"′) back to \"ψ\"(r, \"t\"), so an operator formula_7 invariant under formula_2 satisfies:\n\nand thus:\n\nfor any state \"ψ\". Quantum operators representing observables are also required to be Hermitian so that their eigenvalues are real numbers, i.e. the operator equals its Hermitian conjugate, formula_11.\n\nFollowing are the key points of group theory relevant to quantum theory, examples are given throughout the article. For an alternative approach using matrix groups, see the books of Hall\n\nLet \"G\" be a \"Lie group\", which is a group that locally is parameterized by a finite number \"N\" of real continuously varying parameters \"ξ\", \"ξ\", ... \"ξ\". In more mathematical language, this means that \"G\" is a smooth manifold that is also a group, for which the group operations are smooth.\nA representation which cannot be decomposed into a direct sum of other representations, is called \"irreducible\". It is conventional to label irreducible representations by a superscripted number \"n\" in brackets, as in \"D\", or if there is more than one number, we write \"D\".\n\nThere is an additional subtlety that arises in quantum theory, where two vectors that differ by multiplication by a scalar represent the same physical state. Here, the pertinent notion of representation is a projective representation, one that only satisfies the composition law up to a scalar. In the context of quantum mechanical spin, such representations are called spinorial.\n\nThe space translation operator formula_19 acts on a wavefunction to shift the space coordinates by an infinitesimal displacement Δr. The explicit expression formula_20 can be quickly determined by a Taylor expansion of \"ψ\"(r + Δr, \"t\") about r, then (keeping the first order term and neglecting second and higher order terms), replace the space derivatives by the momentum operator formula_21. Similarly for the time translation operator acting on the time parameter, the Taylor expansion of \"ψ\"(r, \"t\" + Δ\"t\") is about \"t\", and the time derivative replaced by the energy operator formula_22.\n\nThe exponential functions arise by definition as those limits, due to Euler, and can be understood physically and mathematically as follows. A net translation can be composed of many small translations, so to obtain the translation operator for a finite increment, replace Δr by Δr/\"N\" and Δ\"t\" by Δ\"t\"/\"N\", where \"N\" is a positive non-zero integer. Then as \"N\" increases, the magnitude of Δr and Δ\"t\" become even smaller, while leaving the directions unchanged. Acting the infinitesimal operators on the wavefunction \"N\" times and taking the limit as \"N\" tends to infinity gives the finite operators.\n\nSpace and time translations commute, which means the operators and generators commute.\n\nFor a time-independent Hamiltonian, energy is conserved in time and quantum states are stationary states: the eigenstates of the Hamiltonian are the energy eigenvalues \"E\":\n\nand all stationary states have the form\n\nwhere \"t\" is the initial time, usually set to zero since there is no loss of continuity when the initial time is set.\n\nAn alternative notation is formula_25.\n\nThe rotation operator acts on a wavefunction to rotate the spatial coordinates of a particle by a constant angle Δ\"θ\":\n\nwhere r′ are the rotated coordinates about an axis defined by a unit vector formula_27 through an angular increment Δ\"θ\", given by:\n\nwhere formula_29 is a rotation matrix dependent on the axis and angle. In group theoretic language, the rotation matrices are group elements, and the angles and axis formula_30 are the parameters, of the three-dimensional special orthogonal group, SO(3). The rotation matrices about the standard Cartesian basis vector formula_31 through angle , and the corresponding generators of rotations , are:\n\nMore generally for rotations about an axis defined by formula_32, the rotation matrix elements are:\n\nwhere \"δ\" is the Kronecker delta, and \"ε\" is the Levi-Civita symbol.\n\nIt is not as obvious how to determine the rotational operator compared to space and time translations. We may consider a special case (rotations about the \"x\", \"y\", or \"z\"-axis) then infer the general result, or use the general rotation matrix directly and tensor index notation with \"δ\" and \"ε\". To derive the infinitesimal rotation operator, which corresponds to small Δ\"θ\", we use the small angle approximations sin(Δ\"θ\") ≈ Δ\"θ\" and cos(Δ\"θ\") ≈ 1, then Taylor expand about r or \"r\", keep the first order term, and substitute the angular momentum operator components.\n\nThe \"z\"-component of angular momentum can be replaced by the component along the axis defined by formula_32, using the dot product formula_35.\n\nAgain, a finite rotation can be made from lots of small rotations, replacing Δ\"θ\" by and taking the limit as \"N\" tends to infinity gives the rotation operator for a finite rotation.\n\nRotations about the \"same\" axis do commute, for example a rotation through angles \"θ\" and \"θ\" about axis \"i\" can be written\n\nHowever, rotations about \"different\" axes do not commute. The general commutation rules are summarized by\n\nIn this sense, orbital angular momentum has the common sense properties of rotations. Each of the above commutators can be easily demonstrated by holding an everyday object and rotating it through the same angle about any two different axes in both possible orderings; the final configurations are different.\n\nIn quantum mechanics, there is another form of rotation which mathematically appears similar to the orbital case, but has different properties, described next.\n\nAll previous quantities have classical definitions. Spin is a quantity possessed by particles in quantum mechanics without any classical analogue, having the units of angular momentum. The spin vector operator is denoted formula_38. The eigenvalues of its components are the possible outcomes (in units of formula_39) of a measurement of the spin projected onto one of the basis directions.\n\nRotations (of ordinary space) about an axis formula_32 through angle \"θ\" about the unit vector formula_41 in space acting on a multicomponent wave function (spinor) at a point in space is represented by:\n\n) = \\exp\\left( - \\frac{i}{\\hbar}\\theta \\hat{\\mathbf{a}} \\cdot \\widehat{\\mathbf{S}}\\right) </math>\n\nHowever, unlike orbital angular momentum in which the \"z\"-projection quantum number \"\" can only take positive or negative integer values (including zero), the \"z\"-projection spin quantum number \"s\" can take all positive and negative half-integer values. There are rotational matrices for each spin quantum number.\n\nEvaluating the exponential for a given \"z\"-projection spin quantum number \"s\" gives a (2\"s\" + 1)-dimensional spin matrix. This can be used to define a spinor as a column vector of 2\"s\" + 1 components which transforms to a rotated coordinate system according to the spin matrix at a fixed point in space.\n\nFor the simplest non-trivial case of \"s\" = 1/2, the spin operator is given by\n\nwhere the Pauli matrices in the standard representation are:\n\nThe total angular momentum operator is the sum of the orbital and spin\n\nand is an important quantity for multi-particle systems, especially in nuclear physics and the quantum chemistry of multi-electron atoms and molecules.\n\nWe have a similar rotation matrix:\n\nThe dynamical symmetry group of the \"n\" dimensional quantum harmonic oscillator is the special unitary group SU(\"n\"). As an example, the number of infinitesimal generators of the corresponding Lie algebras of SU(2) and SU(3) are three and eight respectively. This leads to exactly three and eight independent conserved quantities (other than the Hamiltonian) in these systems.\n\nThe two dimensional quantum harmonic oscillator has the expected conserved quantities of the Hamiltonian and the angular momentum, but has additional hidden conserved quantities of energy level difference and another form of angular momentum.\n\nFollowing is an overview of the Lorentz group; a treatment of boosts and rotations in spacetime. Throughout this section, see (for example) T. Ohlsson (2011) and E. Abers (2004).\n\nLorentz transformations can be parametrized by rapidity for a boost in the direction of a three-dimensional unit vector formula_46, and a rotation angle about a three-dimensional unit vector formula_27 defining an axis, so formula_48 and formula_49 are together six parameters of the Lorentz group (three for rotations and three for boosts). The Lorentz group is 6-dimensional.\n\nThe rotation matrices and rotation generators considered above form the spacelike part of a four-dimensional matrix, representing pure-rotation Lorentz transformations. Three of the Lorentz group elements formula_50 and generators for pure rotations are:\n\nThe rotation matrices act on any four vector A = (\"A\", \"A\", \"A\", \"A\") and rotate the space-like components according to\n\nleaving the time-like coordinate unchanged. In matrix expressions, A is treated as a column vector.\n\nA boost with velocity in the \"x\", \"y\", or \"z\" directions given by the standard Cartesian basis vector formula_31, are the boost transformation matrices. These matrices formula_53 and the corresponding generators are the remaining three group elements and generators of the Lorentz group:\n\nThe boost matrices act on any four vector A = (\"A\", \"A\", \"A\", \"A\") and mix the time-like and the space-like components, according to:\n\nThe term \"boost\" refers to the relative velocity between two frames, and is not to be conflated with momentum as the \"generator of translations\", as explained below.\n\nProducts of rotations give another rotation (a frequent exemplification of a subgroup), while products of boosts and boosts or of rotations and boosts cannot be expressed as pure boosts or pure rotations. In general, any Lorentz transformation can be expressed as a product of a pure rotation and a pure boost. For more background see (for example) B.R. Durney (2011) and H.L. Berk et al. and references therein.\n\nThe boost and rotation generators have representations denoted and respectively, the capital in this context indicates a group representation.\n\nFor the Lorentz group, the representations and of the generators and fulfill the following commutation rules.\n\nIn all commutators, the boost entities mixed with those for rotations, although rotations alone simply give another rotation. Exponentiating the generators gives the boost and rotation operators which combine into the general Lorentz transformation, under which the spacetime coordinates transform from one rest frame to another boosted and/or rotating frame. Likewise, exponentiating the representations of the generators gives the representations of the boost and rotation operators, under which a particle's spinor field transforms.\n\nIn the literature, the boost generators and rotation generators are sometimes combined into one generator for Lorentz transformations , an antisymmetric four-dimensional matrix with entries:\n\nand correspondingly, the boost and rotation parameters are collected into another antisymmetric four-dimensional matrix , with entries:\n\nThe general Lorentz transformation is then:\n\nwith summation over repeated matrix indices \"α\" and \"β\". The Λ matrices act on any four vector A = (\"A\", \"A\", \"A\", \"A\") and mix the time-like and the space-like components, according to:\n\nIn relativistic quantum mechanics, wavefunctions are no longer single-component scalar fields, but now 2(2\"s\" + 1) component spinor fields, where \"s\" is the spin of the particle. The transformations of these functions in spacetime are given below.\n\nUnder a proper orthochronous Lorentz transformation in Minkowski space, all one-particle quantum states locally transform under some representation of the Lorentz group:\n\nwhere is a finite-dimensional representation, in other words a dimensional square matrix, and is thought of as a column vector containing components with the allowed values of :\n\nThe irreducible representations of and , in short \"irreps\", can be used to build to spin representations of the Lorentz group. Defining new operators:\n\nso and are simply complex conjugates of each other, it follows they satisfy the symmetrically formed commutators:\n\nand these are essentially the commutators the orbital and spin angular momentum operators satisfy. Therefore, and form operator algebras analogous to angular momentum; same ladder operators, \"z\"-projections, etc., independently of each other as each of their components mutually commute. By the analogy to the spin quantum number, we can introduce positive integers or half integers, , with corresponding sets of values and . The matrices satisfying the above commutation relations are the same as for spins \"a\" and \"b\" have components given by multiplying Kronecker delta values with angular momentum matrix elements:\n\nwhere in each case the row number \"m′n′\" and column number \"mn\" are separated by a comma, and in turn:\n\nand similarly for J. The three J matrices are each square matrices, and the three J are each square matrices. The integers or half-integers \"m\" and \"n\" numerate all the irreducible representations by, in equivalent notations used by authors: , which are each square matrices.\n\nApplying this to particles with spin ;\n\nIn these cases the refers to any of , , or a full Lorentz transformation .\n\nIn the context of the Dirac equation and Weyl equation, the Weyl spinors satisfying the Weyl equation transform under the simplest irreducible spin representations of the Lorentz group, since the spin quantum number in this case is the smallest non-zero number allowed: 1/2. The 2-component left-handed Weyl spinor transforms under and the 2-component right-handed Weyl spinor transforms under . Dirac spinors satisfying the Dirac equation transform under the representation , the direct sum of the irreps for the Weyl spinors.\n\nSpace translations, time translations, rotations, and boosts, all taken together, constitute the Poincaré group. The group elements are the three rotation matrices and three boost matrices (as in the Lorentz group), and one for time translations and three for space translations in spacetime. There is a generator for each. Therefore, the Poincaré group is 10-dimensional.\n\nIn special relativity, space and time can be collected into a four-position vector , and in parallel so can energy and momentum which combine into a four-momentum vector . With relativistic quantum mechanics in mind, the time duration and spatial displacement parameters (four in total, one for time and three for space) combine into a spacetime displacement , and the energy and momentum operators are inserted in the four-momentum to obtain a four-momentum operator,\n\nwhich are the generators of spacetime translations (four in total, one time and three space):\n\nThere are commutation relations between the components four-momentum P (generators of spacetime translations), and angular momentum M (generators of Lorentz transformations), that define the Poincaré algebra:\n\n\nwhere \"η\" is the Minkowski metric tensor. (It is common to drop any hats for the four-momentum operators in the commutation relations). These equations are an expression of the fundamental properties of space and time as far as they are known today. They have a classical counterpart where the commutators are replaced by Poisson brackets.\n\nTo describe spin in relativistic quantum mechanics, the Pauli–Lubanski pseudovector\n\na Casimir operator, is the constant spin contribution to the total angular momentum, and there are commutation relations between P and W and between M and W:\n\nInvariants constructed from W, instances of Casimir invariants can be used to classify irreducible representations of the Lorentz group.\n\nGroup theory is an abstract way of mathematically analyzing symmetries. Unitary operators are paramount to quantum theory, so unitary groups are important in particle physics. The group of \"N\" dimensional unitary square matrices is denoted U(\"N\"). Unitary operators preserve inner products which means probabilities are also preserved, so the quantum mechanics of the system is invariant under unitary transformations. Let formula_76 be a unitary operator, so the inverse is the Hermitian adjoint formula_77, which commutes with the Hamiltonian:\n\nthen the observable corresponding to the operator formula_79 is conserved, and the Hamiltonian is invariant under the transformation formula_79.\n\nSince the predictions of quantum mechanics should be invariant under the action of a group, physicists look for unitary transformations to represent the group.\n\nImportant subgroups of each U(\"N\") are those unitary matrices which have unit determinant (or are \"unimodular\"): these are called the special unitary groups and are denoted SU(\"N\").\n\nThe simplest unitary group is U(1), which is just the complex numbers of modulus 1. This one-dimensional matrix entry is of the form:\n\nin which \"θ\" is the parameter of the group, and the group is Abelian since one-dimensional matrices always commute under matrix multiplication. Lagrangians in quantum field theory for complex scalar fields are often invariant under U(1) transformations. If there is a quantum number \"a\" associated with the U(1) symmetry, for example baryon and the three lepton numbers in electromagnetic interactions, we have:\n\nThe general form of an element of a U(2) element is parametrized by two complex numbers \"a\" and \"b\":\n\nand for SU(2), the determinant is restricted to 1:\n\nIn group theoretic language, the Pauli matrices are the generators of the special unitary group in two dimensions, denoted SU(2). Their commutation relation is the same as for orbital angular momentum, aside from a factor of 2:\n\nA group element of SU(2) can be written:\n\nwhere \"σ\" is a Pauli matrix, and the group parameters are the angles turned through about an axis.\n\nThe two-dimensional isotropic quantum harmonic oscillator has symmetry group SU(2), while the symmetry algebra of the rational anisotropic QHO is a nonlinear extension of u(2).\n\nThe eight Gell-Mann matrices (see article for them and the structure constants) are important for quantum chromodynamics. They originally arose in the theory SU(3) of flavor which is still of practical importance in nuclear physics. They are the generators for the SU(3) group, so an element of SU(3) can be written analogously to an element of SU(2):\n\nwhere \"θ\" are eight independent parameters. The matrices satisfy the commutator:\n\nwhere the indices , , take the values 1, 2, 3... 8. The structure constants \"f\" are totally antisymmetric in all indices analogous to those of SU(2). In the standard colour charge basis (\"r\" for red, \"g\" for green, \"b\" for blue):\n\nthe colour states are eigenstates of the and matrices, while the other matrices mix colour states together.\n\nThe eight gluons states (8-dimensional column vectors) are simultaneous eigenstates of the adjoint representation of , the 8-dimensional representation acting on its own Lie algebra , for the and matrices. By forming tensor products of representations (the standard representation and its dual) and taking appropriate quotients, protons and neutrons, and other hadrons are eigenstates of various representations of of color. The representations of SU(3) can be described by a \"theorem of the highest weight\".\n\nIn relativistic quantum mechanics, relativistic wave equations predict a remarkable symmetry of nature: that every particle has a corresponding antiparticle. This is mathematically contained in the spinor fields which are the solutions of the relativistic wave equations.\n\nCharge conjugation switches particles and antiparticles. Physical laws and interactions unchanged by this operation have C symmetry.\n\n\n\nIn quantum electrodynamics, the symmetry group is U(1) and is abelian. In quantum chromodynamics, the symmetry group is SU(3) and is non-abelian.\n\nThe electromagnetic interaction is mediated by photons, which have no electric charge. The electromagnetic tensor has an electromagnetic four-potential field possessing gauge symmetry.\n\nThe strong (color) interaction is mediated by gluons, which can have eight color charges. There are eight gluon field strength tensors with corresponding gluon four potentials field, each possessing gauge symmetry.\n\nAnalogous to the spin operator, there are color charge operators in terms of the Gell-Mann matrices \"λ\":\n\nand since color charge is a conserved charge, all color charge operators must commute with the Hamiltonian:\n\nIsospin is conserved in strong interactions.\n\nMagnetic monopoles can be theoretically realized, although current observations and theory are consistent with them existing or not existing. Electric and magnetic charges can effectively be \"rotated into one another\" by a duality transformation.\n\n\nA Lie superalgebra is an algebra in which (suitable) basis elements either have a commutation relation or have an anticommutation relation. Symmetries have been proposed to the effect that all fermionic particles have bosonic analogues, and vice versa. These symmetry have theoretical appeal in that no extra assumptions (such as existence of strings) barring symmetries are made. In addition, by assuming supersymmetry, a number puzzling issues can be resolved. These symmetries, which are represented by Lie superalgebras, have not been confirmed experimentally. It is now believed that they are broken symmetries, if they exist. But it has been speculated that dark matter is constitutes gravitinos, a spin 3/2 particle with mass, its supersymmetric partner being the graviton.\n\nThe concept of exchange symmetry is derived from a fundamental postulate of quantum statistics, which states that no observable physical quantity should change after exchanging two identical particles. It states that because all observables are proportional to formula_92 for a system of identical particles, the wave function formula_93 must either remain the same or change sign upon such an exchange.\n\nBecause the exchange of two identical particles is mathematically equivalent to the rotation of each particle by 180 degrees (and so to the rotation of one particle's frame by 360 degrees), the symmetric nature of the wave function depends on the particle's spin after the rotation operator is applied to it. Integer spin particles do not change the sign of their wave function upon a 360 degree rotation—therefore the sign of the wave function of the entire system does not change. Semi-integer spin particles change the sign of their wave function upon a 360 degree rotation (see more in spin–statistics theorem).\n\nParticles for which the wave function does not change sign upon exchange are called bosons, or particles with a symmetric wave function. The particles for which the wave function of the system changes sign are called fermions, or particles with an antisymmetric wave function.\n\nFermions therefore obey different statistics (called Fermi–Dirac statistics) than bosons (which obey Bose–Einstein statistics). One of the consequences of Fermi–Dirac statistics is the exclusion principle for fermions—no two identical fermions can share the same quantum state (in other words, the wave function of two identical fermions in the same state is zero). This in turn results in degeneracy pressure for fermions—the strong resistance of fermions to compression into smaller volume. This resistance gives rise to the “stiffness” or “rigidity” of ordinary atomic matter (as atoms contain electrons which are fermions).\n\n\n\n"}
{"id": "67229", "url": "https://en.wikipedia.org/wiki?curid=67229", "title": "The Large Scale Structure of Space-Time", "text": "The Large Scale Structure of Space-Time\n\nThe Large Scale Structure of Space-Time is 1973 book about the theoretical physics of spacetime by Stephen Hawking and George Ellis.\n\nHawking and Ellis attempt to describe the foundation of space itself and its nature of infinite expansion, using differential geometry to examine the consequences of the physicist Albert Einstein's general theory of relativity.\n\nHawking co-wrote the book with Ellis, while a post doc at Cambridge University. In his 1988 book \"A Brief History of Time\", he describes \"The Large Scale Structure of Space-Time\" as \"highly technical\" and unreadable for the common reader.\n\nThe book, now considered a classic, has also appeared in paperback format and has been reprinted many times.\n"}
{"id": "16602725", "url": "https://en.wikipedia.org/wiki?curid=16602725", "title": "The Oxford Book of Modern Science Writing", "text": "The Oxford Book of Modern Science Writing\n\nThe Oxford Book of Modern Science Writing is an anthology of scientific writings, arranged and introduced by Richard Dawkins of the University of Oxford. Published first in March 2008, it contains 83 writings on many topics from a diverse variety of authors, which range in length from one to eight pages. All inclusions are dated post-1900, and include poetry, anecdotes, and general philosophical musings.\n\nThe book is divided into four segments. The following is a list of pieces included in each segment.\n\nfrom:\n\nfrom:\n\nfrom:\n\nfrom:\n\nThe book received extremely favourable reviews, with \"New Scientist\" proclaiming that \"if you could only ever read one science book, this should probably be it\". Peter Forbes of \"The Independent\" praised Dawkins' inclusions, stating that \"every reader is likely to make a discovery or two\". Steven Poole in \"The Guardian\" described it as \"a beautiful volume\" and \"a labour of love\" on Dawkins' part.\nA number of science bloggers did criticise the lack of women scientists included in the book.\n"}
{"id": "58787", "url": "https://en.wikipedia.org/wiki?curid=58787", "title": "Timeline of black hole physics", "text": "Timeline of black hole physics\n\nTimeline of black hole physics\n\n\n\n\n"}
{"id": "25368964", "url": "https://en.wikipedia.org/wiki?curid=25368964", "title": "Universal adaptive strategy theory", "text": "Universal adaptive strategy theory\n\nUniversal adaptive strategy theory (UAST) is an evolutionary theory developed by J. Philip Grime in collaboration with Simon Pierce describing the general limits to ecology and evolution based on the trade-off that organisms face when the resources they gain from the environment are allocated between either growth, maintenance or regeneration – known as the universal three-way trade-off.\n\nA universal three-way trade-off produces adaptive strategies throughout the tree of life, with extreme strategies facilitating the survival of genes via: C (competitive), the survival of the individual using traits that maximize resource acquisition and resource control in consistently productive niches; S (stress-tolerant), individual survival via maintenance of metabolic performance in variable and unproductive niches; or R (ruderal), rapid gene propagation via rapid completion of the lifecycle and regeneration in niches where events are frequently lethal to the individual.\n\nIt is impossible for an organism to evolve a survival strategy in which all resources are devoted exclusively to one of these investment paths, but relatively extreme strategies exist, with a range of intermediates. The system can be represented by a triangle, with the three extreme possibilities at its vertices. The different species may be located at some particular point inside this triangle, accommodating a certain percentage of each of the three strategies.\n\nIt is possible to use multivariate statistics to determine the main trends in phenotypic variability in a range of organisms, which for various major animal groups (most prominently vertebrates), has been shown to have three main endpoints consistent with UAST.\n\nUAST is a key part of the twin-filter model describing how species with similar overall strategies but divergent sets of minor traits coexist in ecological communities.\n\nC-S-R Triangle theory is the application of UAST to plant biology. The three strategies are competitor, stress tolerator, and ruderal. These strategies each thrive best in a unique combination of either high or low intensities of stress and disturbance.\n\nCompetitors are plant species that thrive in areas of low intensity stress and disturbance and excel in biological competition. These species are able to outcompete other plants by most efficiently tapping into available resources. Competitors do this through a combination of favorable characteristics, including rapid growth rate, high productivity (growth in height, lateral spread, and root mass), and high capacity for phenotypic plasticity. This last feature allows competitors to be highly flexible in morphology and adjust the allocation of resources throughout the various parts of the plant as needed over the course of the growing season.\n\nStress tolerators are plant species that live in areas of high intensity stress and low intensity disturbance. Species that have adapted this strategy generally have slow growth rates, long-lived leaves, high rates of nutrient retention, and low phenotypic plasticity. Stress tolerators respond to environmental stresses through physiological variability. These species are often found in stressful environments such as alpine or arid habitats, deep shade, nutrient deficient soils, and areas of extreme pH levels.\n\nRuderals are plant species that prosper in situations of high intensity disturbance and low intensity stress. These species are fast-growing and rapidly complete their life cycles, and generally produce large amounts of seeds. Plants that have adapted this strategy are often found colonizing recently disturbed land, and are often annuals.\n\nUnderstanding the differences between the CSR theory and its major alternative the R* theory has been a major goal in community ecology for many years. \nUnlike the R* theory that predicts that competitive ability is determined by the ability to grow under low levels of resources, the CSR theory predicts that competitive ability is determined by relative growth rate and other size related traits. While some experiments supported the R* predictions, other supported the CSR predictions.\nThe different predictions stem from different assumptions on the size asymmetry of the competition. The R* theory assumes that competition is size symmetric (i.e. resource exploitation is proportional to individual biomass), the CSR theory assumes that competition is size-asymmetric (i.e. large individuals exploit disproportional higher amounts of resources compared with smaller individuals).\n\n\n\n"}
{"id": "267784", "url": "https://en.wikipedia.org/wiki?curid=267784", "title": "Variety (botany)", "text": "Variety (botany)\n\nIn botanical nomenclature, variety (abbreviated var.; in ) is a taxonomic rank below that of species and subspecies but above that of form. As such, it gets a three-part infraspecific name. It is sometimes recommended that the subspecies rank should be used to recognize geographic distinctiveness, whereas the variety rank is appropriate if the taxon is seen throughout the geographic range of the species.\n\nThe pincushion cactus, \"Escobaria vivipara\" , is a wide-ranging variable species occurring from Canada to Mexico, and found throughout New Mexico below about . Nine varieties have been described. Where the varieties of the pincushion cactus meet, they intergrade. The variety \"Escobaria vivipara\" var. \"arizonica\" is from Arizona, while \"Escobaria vivipara\" var. \"neo-mexicana\" is from New Mexico.\n\nThe term is defined in different ways by different authors. However, the International Code of Nomenclature for Cultivated Plants, while recognizing that the word \"variety\" is often used to denote \"cultivar\", does not accept this usage. Variety is defined in the code as follows: \"Variety (varietas) the category in the botanical nomenclatural hierarchy between species and form (forma)\". However the code acknowledges the other usage as follows: \"term used in some national and international legislation for a clearly distinguishable taxon below the rank of species; generally, in legislative texts, a term equivalent to cultivar. See also: cultivar and variety (varietas)\".\n\nA variety will have an appearance distinct from other varieties, but will hybridize freely with those other varieties (if brought into contact).\n\n\n\n"}
{"id": "342398", "url": "https://en.wikipedia.org/wiki?curid=342398", "title": "Watch Mr. Wizard", "text": "Watch Mr. Wizard\n\nWatch Mr. Wizard is an American television program (1951–1965) for children that demonstrates the science behind ordinary things. The show's creator and on-air host was Don Herbert. Marcel LaFollette says of the program, \"It enjoyed consistent praise, awards, and high ratings throughout its history. At its peak, \"Watch Mr. Wizard\" drew audiences in the millions, but its impact was far wider. By 1956, it had prompted the establishment of more than five thousand Mr. Wizard science clubs, with an estimated membership greater than one hundred thousand.\"\n\nIt was briefly revived in 1971, and then in the 1980s was a program on the Nickelodeon children's television network as \"Mr. Wizard's World\".\n\n\"Watch Mr. Wizard\" first aired on NBC on March 3, 1951 with Don Herbert as the title character. In the weekly half hour live television show Herbert played a science hobbyist, and every Saturday morning a neighbor boy or girl would come to visit. The children were played by child actors; one of them (Rita McLaughlin) enjoyed a long subsequent acting career. Mr. Wizard always had some kind of laboratory experiment going that taught something about science. The experiments, many of which seemed impossible at first glance, were usually simple enough to be re-created by viewers.\n\nThe show was very successful; by 1954 it was broadcast live by 14 stations, and by kinescope (a film made from the television monitor of the original live broadcast) by an additional 77. Mr. Wizard Science Clubs were started throughout North America, numbering 5,000 by 1955 and 50,000 by 1965. The show moved from Chicago to New York on September 5, 1955, and had produced 547 live broadcasts by the time the show was canceled in 1965, with the last telecast on June 27. The show was cited by the National Science Foundation and American Chemical Society for increasing interest in science, and won a 1953 Peabody Award.\n\nThirty-two episodes of \"Watch Mr. Wizard\" were selected by Don Herbert and released on eight DVDs. They can be found at \n\nIt was revived by NBC from September 11, 1971 through September 2, 1972 as \"Mr. Wizard\", based on 26 shows produced in color in Ottawa, Ontario, Canada at the CJOH-TV studios. The series was legally considered Canadian content, despite the American origins of the series and its host. CBC Television carried these episodes within Canada.\n\n\"Mr. Wizard's World\", a faster-paced version of the show developed by Don Herbert, was shown three times a week on Nickelodeon, the then rising kids cable channel. Once again, the revival was produced in Canada (this time in Calgary). It produced 78 episodes from 1983 onwards, and continued to run thereafter as reruns. During its airing on Nickelodeon, it was the channel's #3 rated show in 1983 (behind \"Livewire\" and \"You Can't Do That on Television\"). It was also famous for its \"Ask Mr. Wizard\" segment where Mr. Wizard answered questions sent in by viewers of all ages. Episodes of it were reaired in 2005-2006 on the digital cable channel The Science Channel. It still frequently airs on The Science Channel. Herbert once said: \"My time on this Earth is getting shorter and shorter each day, but no matter how old I get, and even when I am dead, Mr. Wizard's World will never die\". It was cancelled in 1990, though reruns continued on Nick at Nite until 1995 and often in early morning time slots right after Nick at Nite finished, through at least March 2000. In 1994, Herbert developed another new series of 15-minute spots called \"Teacher to Teacher with Mr. Wizard\". They highlighted individual elementary science teachers and their projects. The series was sponsored by the National Science Foundation and was shown on Nickelodeon. Selected episodes of \"Mr. Wizard's World\" are available on DVD from Mr. Wizard Studios Inc. in 10-Single Volumes featuring 4-Episodes on each disk, Gift Box-Sets is also available. Five seasons of the show, 75 episodes, of the 78 total were released on Amazon instant streaming.\n\nLaFollette applauds the unrivaled popularity and longevity of the original Mr. Wizard, but suggests that its sequels and other educational programs were often initiated in response to social criticism, then cancelled once such pressure diminished.\n\n\n\n\n"}
{"id": "29959860", "url": "https://en.wikipedia.org/wiki?curid=29959860", "title": "Émile Bertrand", "text": "Émile Bertrand\n\nÉmile Bertrand (1844–1909) was a French mineralogist, in honour of whom bertrandite was named by Alexis Damour. He also gave his name to the \"Bertrand lens\" or phase telescope.\n\nHe studied at the Ecole des Mines in Paris and was a co-founder of the \"Société française de Minéralogie\". He wrote a book on the application of microscopy to mineralogical studies, \"\"De l'Application du microscope à l'étude de la minéralogie\" (1878); published a translation of Ernst Mach's work on the history of mechanics, \"La mécanique: exposé historique et critique de son développement\"\" (1904); and is credited with the design of a refractometer.\n"}
