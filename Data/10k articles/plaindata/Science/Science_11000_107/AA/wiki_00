{"id": "5665528", "url": "https://en.wikipedia.org/wiki?curid=5665528", "title": "A369 road", "text": "A369 road\n\nThe A369 is an A road running from Ashton Gate junction with the A370 and the A3029 to Portishead in South West England. The first part is relatively flat and the route passes through several villages which are Leigh Woods, Abbots Leigh, Easton in Gordano to Portishead. The road crosses the M5 motorway at Junction 19 which is where the single complex Gordano services are located. \n\nDuring the rush hour period the road gets extremely busy since it is the main commuter route from Portishead to Bristol. There is lots of congestion on the A369 which is why one of the primary reasons for reopening the Portishead Branch Line.\n\nIn 1922, the A369 was originally connected from Ashcott to Marksbury. By 1935 however, the road and became part of the A39, eventually the roads number became unused for many decades.\n\nBy the 1950s, it was thought that Portishead was a connection to the A-road but it was connected to the B3124 and eventually it became part of the A369. The road crossed over the Clifton Suspension Bridge where soon after however, it was re-routed over the B3126 and connected to the A370.\n\nIn the early 1970s, the M5 was completed from the Avonmouth Bridge and went southwards, the western half of the route became part of the Gordano Interchange. Eventually a new route was completed from the village of Portbury into Portishead, and the old road through Sheepway was separated by the M5 motorway so a new road called Wyndham Way was constructed to allow faster access to the Town Centre, Bristol Docks and Power Station. \n\n"}
{"id": "7771134", "url": "https://en.wikipedia.org/wiki?curid=7771134", "title": "About Time (book)", "text": "About Time (book)\n\nAbout Time (), published in 1995, is the second book written by Paul Davies, regarding the subject of time. The intended audience is the general public, rather than science academics.\n\n\"About Time\" explores selected mysteries of spacetime, following on from Albert Einstein's theory of relativity, which Davies believes does not fully explain time as humans experience it. The author explains \nImportant though Einstein's time turned out to be, it still did not solve \"the riddle of time\".\nThe book delves into the nature of metaphysics, time, motion and gravity, covering a wide range of aspects surrounding the current cosmological debate, across 283 pages in great detail. It includes an index, a bibliography, and numerous diagrams.\n\n"}
{"id": "47925891", "url": "https://en.wikipedia.org/wiki?curid=47925891", "title": "Additive utility", "text": "Additive utility\n\nIn economics, additive utility is a cardinal utility function with the sigma additivity property.\nAdditivity (also called \"linearity\" or \"modularity\") means that \"the whole is equal to the sum of its parts.\" That is, the utility of a set of items is the sum of the utilities of each item separately. Let formula_1 be a finite set of items. A cardinal utility function formula_2, where formula_3 is the power set of formula_1, is additive if for any formula_5,\nIt follows that for any formula_7,\nAn additive utility function is characteristic of independent goods. For example, an apple and a hat are considered independent: the utility a person receives from having an apple is the same whether or not he has a hat, and vice versa. A typical utility function for this case is given at the right.\n\n\n"}
{"id": "842514", "url": "https://en.wikipedia.org/wiki?curid=842514", "title": "Bahuvrihi", "text": "Bahuvrihi\n\nA bahuvrihi compound (from , literally meaning \"much rice\" but denoting a rich man) is a type of compound that denotes a referent by specifying a certain characteristic or quality the referent possesses. A bahuvrihi is exocentric, so that the compound is not a hyponym of its head. For instance, a sabretooth (\"smil-odon\") is neither a sabre nor a tooth, but a feline with sabre-like teeth. \n\nIn Sanskrit bahuvrihis, the last constituent is a noun—more strictly, a nominal stem—while the whole compound is an adjective. In Vedic Sanskrit the accent is regularly on the first member ( ' \"a king's son\", but bahuvrihi ' \"having kings as sons\", viz. ', m., \"father of kings\", ', f., \"mother of kings\"), with the exception of a number of non-nominal prefixes such as the privative a; the word \"\" is itself likewise an exception to this rule.\n\nIn English bahuvrihis can be identified and the last constituent is usually a noun, while the whole compound is a noun or an adjective. The accent is on the first constituent. English bahuvrihis often describe people using synecdoche: \"flatfoot\", \"half-wit\", \"highbrow\", \"lowlife\", \"redhead\", \"tenderfoot\", \"long-legs\", and \"white-collar\".\n\n\n\n"}
{"id": "28847536", "url": "https://en.wikipedia.org/wiki?curid=28847536", "title": "Bayldonite", "text": "Bayldonite\n\nBayldonite (BAIL-done-ite) is a rare secondary mineral with the chemical formula PbCu(AsO)(OH). It was first discovered in Penberthy Croft Mine, Cornwall, England, United Kingdom. It is named after its discoverer, John Bayldon (1837(8) – 1872). Specimens are also found in Tsumeb, Namibia, and Arizona, United States. It is sometimes used as a gemstone. \n"}
{"id": "15717827", "url": "https://en.wikipedia.org/wiki?curid=15717827", "title": "COCIR", "text": "COCIR\n\nCOCIR is the European Coordination Committee of the Radiological, Electromedical and Healthcare IT Industry. It is a non-profit trade association, which was founded in 1959, and represents the medical technology industry in Europe. Since 2006 COCIR headquarters are located in Brussels. In 2007, Heinrich von Wulfen became its chairman and succeeded Frank Anton. COCIR is a member of the European Medical Devices Industry Group (EMIG).\n\n\n\n"}
{"id": "36279899", "url": "https://en.wikipedia.org/wiki?curid=36279899", "title": "CRC Concise Encyclopedia of Mathematics", "text": "CRC Concise Encyclopedia of Mathematics\n\nCRC Concise Encyclopedia of Mathematics is a bestselling book by American author Eric W. Weisstein.\n\nThe book is presented in a dictionary format. The book is divided into headwords. The book also provides relevant diagrams and illustrations.\n\nThe book, quite notably became the subject of a lawsuit between CRC Press and Eric W. Weisstein.\n\nThe book has consistently received good reviews.\n\n\n"}
{"id": "2926724", "url": "https://en.wikipedia.org/wiki?curid=2926724", "title": "Chartered Scientist", "text": "Chartered Scientist\n\nChartered Scientist (CSci) is a professional qualification in the United Kingdom that is awarded by the Science Council through its Licensed member organisations. Holders of this qualification can use the post-nominal letters CSci.\n\nChartered scientists are professional scientists who are practising and/or advancing science at the full professional level and are individuals for whom scientific knowledge or practice at that level form an essential element of their role.\nThe required standard for Chartered Scientist registration is a Masters-level science qualification (or equivalent) with four years of postgraduate work experience.\n\nThe standards of the Chartered Scientist designation are upheld by the Science Council’s Registration Authority, whose members are elected representatives from the Licensed Bodies and appointed experts from other areas.\nThere is a specialist section of the register for scientists whose primary profession is teaching. Those registered are entitled to use the post-nominal CSciTeach. It was developed in 2007 by the Science Council in partnership with the Association for Science Education, and is also awarded by the Royal Society of Biology and the Royal Society of Chemistry.\n\n\n"}
{"id": "33942981", "url": "https://en.wikipedia.org/wiki?curid=33942981", "title": "Chimpanzee stool associated circular virus", "text": "Chimpanzee stool associated circular virus\n\nChimpanzee stool associated circular virus is a single stranded DNA virus isolated from chimpanzee stool.\n\nThe genome is ~2.6 kilobases in length and encodes two open reading frames (ORFs). The larger of the ORFs encodes the replicase gene and the other the putative capsid protein. A stem-loop and TATA boxes are present in the non coding parts of the sequence.\n\nThis virus appears to be related to the bovine stool associated circular virus but to no other known group of viruses.\n"}
{"id": "58698928", "url": "https://en.wikipedia.org/wiki?curid=58698928", "title": "Colin Hayter Crick", "text": "Colin Hayter Crick\n\nColin Hayter Crick (1899–1988) was Canadian geomorphologist known fors his contributions to river and hillslope erosion. Influenced by the observations of the geologist Eleanora Knopf he coined the concept of unequal activity to describe the great disparities that can between stream erosion near stream channels and apparently unchanged uplands, and between headwaters with limited erosion and the more active middle and lower courses of streams. Crick did also coin the term panplanation to describe a planation surfaces thought to be formed by lateral stream migration.\n"}
{"id": "26267244", "url": "https://en.wikipedia.org/wiki?curid=26267244", "title": "Comet (book)", "text": "Comet (book)\n\nComet is a 1985 popular-science book by Carl Sagan and Ann Druyan. The authors describe the scientific nature of comets, as well as their varying roles and perceptions throughout history. The evolution of human understanding of comets is also detailed, and thinkers and astronomers such as Edmond Halley, Immanuel Kant, and William Huggins are discussed.\n\nThe publication of the book was months ahead of the 1986 appearance of Halley's Comet.\n"}
{"id": "194618", "url": "https://en.wikipedia.org/wiki?curid=194618", "title": "Completeness (statistics)", "text": "Completeness (statistics)\n\nIn statistics, completeness is a property of a statistic in relation to a model for a set of observed data. In essence, it ensures that the distributions corresponding to different values of the parameters are distinct.\n\nIt is closely related to the idea of identifiability, but in statistical theory it is often found as a condition imposed on a sufficient statistic from which certain optimality results are derived.\n\nConsider a random variable \"X\" whose probability distribution belongs to a parametric model P parametrized by \"θ\".\n\nSay \"T\" is statistic; that is, the composition of a measurable function with a random sample \"X\"...,\"X\".\n\nThe statistic \"T\" is said to be complete for the distribution of \"X\" if, for every measurable function \"g,\": \n\nformula_1\n\nThe statistic \"T\" is said to be boundedly complete for the distribution of \"X\" if this implication holds for every measurable function \"g\" that is also bounded.\n\nThe Bernoulli model admits a complete statistic. Let \"X\" be a random sample of size \"n\" such that each \"X\" has the same Bernoulli distribution with parameter \"p\". Let \"T\" be the number of 1s observed in the sample. \"T\" is a statistic of \"X\" which has a binomial distribution with parameters (\"n\",\"p\"). If the parameter space for \"p\" is (0,1), then \"T\" is a complete statistic. To see this, note that\n\nObserve also that neither \"p\" nor 1 − \"p\" can be 0. Hence formula_3 if and only if:\n\nOn denoting \"p\"/(1 − \"p\") by \"r\", one gets:\n\nFirst, observe that the range of \"r\" is the positive reals. Also, E(\"g\"(\"T\")) is a polynomial in \"r\" and, therefore, can only be identical to 0 if all coefficients are 0, that is, \"g\"(\"t\") = 0 for all \"t\".\n\nIt is important to notice that the result that all coefficients must be 0 was obtained because of the range of \"r\". Had the parameter space been finite and with a number of elements less than or equal to \"n\", it might be possible to solve the linear equations in \"g\"(\"t\") obtained by substituting the values of \"r\" and get solutions different from 0. For example, if \"n\" = 1 and the parameter space is {0.5}, a single observation and a single parameter value, \"T\" is not complete. Observe that, with the definition:\n\nthen, E(\"g\"(\"T\")) = 0 although \"g\"(\"t\") is not 0 for \"t\" = 0 nor for \"t\" = 1.\n\nThis example will show that, in a sample \"X\", \"X\" of size 2 from a normal distribution with known variance, the statistic \"X\" + \"X\" is complete and sufficient. Suppose (\"X\", \"X\") are independent, identically distributed random variables, normally distributed with expectation \"θ\" and variance 1.\nThe sum\n\nis a complete statistic for \"θ\".\n\nTo show this, it is sufficient to demonstrate that there is no non-zero function formula_8 such that the expectation of\n\nremains zero regardless of the value of \"θ\".\n\nThat fact may be seen as follows. The probability distribution of \"X\" + \"X\" is normal with expectation 2\"θ\" and variance 2. Its probability density function in formula_10 is therefore proportional to\n\nThe expectation of \"g\" above would therefore be a constant times\n\nA bit of algebra reduces this to\n\nwhere \"k\"(\"θ\") is nowhere zero and\n\nAs a function of \"θ\" this is a two-sided Laplace transform of \"h\"(\"X\"), and cannot be identically zero unless \"h\"(\"x\") is zero almost everywhere. The exponential is not zero, so this can only happen if \"g\"(\"x\") is zero almost everywhere.\n\nFor some parametric families, a complete sufficient statistic does not exist (for example, see Galili and Meilijson 2016 ). Also, a minimal sufficient statistic need not exist. (A case in which there is no minimal sufficient statistic was shown by Bahadur in 1957. ) Under mild conditions, a minimal sufficient statistic does always exist. In particular, these conditions always hold if the random variables (associated with P ) are all discrete or are all continuous.\n\nThe notion of completeness has many applications in statistics, particularly in the following two theorems of mathematical statistics.\n\nCompleteness occurs in the Lehmann–Scheffé theorem,\nwhich states that if a statistic that is unbiased, complete and sufficient for some parameter \"θ\", then it is the best mean-unbiased estimator for \"θ\". In other words, this statistic has a smaller expected loss for any convex loss function; in many practical applications with the squared loss-function, it has a smaller mean squared error among any estimators with the same expected value.\n\nExamples exists that when the minimal sufficient statistic is not complete then several alternative statistics exist for unbiased estimation of \"θ\", while some of them have lower variance than others.\n\nSee also minimum-variance unbiased estimator.\n\nBounded completeness occurs in Basu's theorem, which states that a statistic that is both boundedly complete and sufficient is independent of any ancillary statistic.\n\nBounded completeness also occurs in Bahadur's theorem. In the case where there exists at least one minimal sufficient statistic, a statistic which is sufficient and boundedly complete, is necessarily minimal sufficient.\n\n"}
{"id": "5456985", "url": "https://en.wikipedia.org/wiki?curid=5456985", "title": "Craig Heller (physiologist)", "text": "Craig Heller (physiologist)\n\nHorace Craig Heller is a physiologist and biologist, currently a professor at Stanford University. He has worked primarily on circadian rhythms and homeostasis. He is also credited with inventing \"the glove,\" a vacuum cooling device used to cool core body temperature and increase muscle performance, which has been used by athletes at Stanford, by the University of Miami Hurricanes, and by boxer Sugar Shane Mosley. As of December 2012, Professor Heller continues teaches undergraduate classes at Stanford, including Bio 42 and courses in the Department of Human Biology.\n\n"}
{"id": "2226213", "url": "https://en.wikipedia.org/wiki?curid=2226213", "title": "Dendroarchaeology", "text": "Dendroarchaeology\n\nDendroarchaeology is a term used for the study of vegetation remains, old buildings, artifacts, furniture, art and musical instruments using the techniques of dendrochronology (tree-ring dating). It refers to dendrochronological research of wood from the past regardless of its current physical context (in or above the soil). This form of dating is the most accurate and precise absolute dating method available to archaeologists, as the last ring that grew is the first year the tree could have been incorporated into an archaeological structure.\n\nTree-ring dating is useful in that it can contribute to \"chronometric\", \"environmental\", and \"behavioral\" archaeological research.\n\nThe utility of tree-ring dating in an environmental sense is the most applicable of the three in today's world. Tree rings can be used to \"reconstruct numerous environmental variables\" such as \"temperature\", \"precipitation\", \"stream flow\", \"drought society\", \"fire frequency and intensity\", \"insect infestation\", \"atmospheric circulation patterns\", among others.\n\nTree ring laboratory scientists from Columbia University were some of the first to apply tree-ring dating to the colonial period, specifically architectural timbers in the eastern United States. For agencies like the National Park Service and other historical societies, Dr. Jacoby and Cook began dating historic structures in the lower Hudson River Valley, New Jersey and Eastern Pennsylvania. This was difficult at the time due to a lack of sufficiently long master dating chronology and access to suitable structures. Not until 1998 was a Boston area master dating chronology developed.\nToday, the effectiveness of tree ring laboratory archaeological dating chronologies covers most of the area that was settled by the first European colonists. The numbers of these are in the hundreds and include historically significant structures such as Independence Hall and the Tuckahoe estate.\n\nThere are two types of dates that can be assigned to tree specimens: \"cutting\" dates, and \"noncutting\" dates. Which date is assigned to a specimen is dependent on whether or not there is evidence that the last ring present on the specimen was the last ring the tree grew before it died.\n\n\"Cutting dates\" can be used for crossdated tree specimens that \"possess evidence that the last ring present on the specimen was the last ring grown by the tree before it died.\" \n\n\"Noncutting dates\" are used for crossdated tree specimens \"if there is no evidence indicating that the last ring present on the specimen is the last one grown before the tree died.\" \nPatterns of tree growth will be similar between trees of the same species, growing in the same climate. These matching patterns align growth rings in different trees formed in the same year. Once aligned, knowing the precise calendar year of any individual tree-ring is the same as knowing the calendar year of all the rings. The goal of a dendroarchaeologist is to determine the year when the last ring was formed. \nCrossdating, the skill of finding matching ring-width patterns between tree-ring samples, is used to assign the precise calendar year to every ring. This is affected by the climate that the timber was in. It is also important to have enough rings to actually confirm a date. Once the rings are dates, the chronology is measured. The last step is to compare the rings with that of ring-width patterns in sampled timbers and a master dating chronology.\n\nFor trees to be useful in archaeological analysis, they must \"produce annual growth rings that are uniform around the tree stem\", they must \"live for decades and, preferably, centuries\" and they \"must have been used extensively by humans either for habitation or fuel.\" One of the problems with this evaluation is that it is possible under certain conditions for a tree to miss a growth-ring or produce two growth rings in a season. During extreme drought there can be insufficient growth of xylem to form a noticeable ring. Alternatively, if a defoliating agent (e.g. drought, late frost, or insect damage) can arrest the growth of a tree early in a year, after which there is a secondary growth period of new foliage causing two rings to form. Another difficulty in the use of tree-ring dating as applied to archaeology is the variety and condition of wood used in construction of archaeological sites. Many such samples are encountered wet. Heartwood can normally retain much of its substance and can be dried out and polished for analysis. On the other hand, ancient wet sapwood samples seldom survive drying out. As a result, the sapwood should either be measured wet and then allowed to dry, or it should be frozen or kept wet.\n\nIn North America, \"millennial-length chronologies have been developed for two species of bristlecone pine (\"Pinus longaeva\" in the Great Basin and \"Pinus aristata\" in the Rocky Mountains), bald cypress (\"Taxodium distichum\"), coast redwood (\"Sequoia sempervirens\"), Douglas-fir (\"Pseudotsuga menziesii\"), eastern cedar (\"Juniperus virginiana\"), juniper (\"Juniperus sp.\"), Larch (\"Larix sp.\"), lodgepole pine (\"Pinus contorta\"), limber pine (\"Pinus flexilis\"), mountain hemlock (\"Tsuga mertensiana\"), ponderosa pine (\"Pinus ponderosa\"), and giant sequoia (\"Sequoiadendron giganteum\") (Jacoby, 2000a).” \n\n“In the southern hemisphere, successful crossdating has been achieved on alerce (\"Fitroya cupressoides\") and pehuen (\"Araucaria araucana\"), also known as 'Chilean pine' or the 'monkey puzzle tree,' specimens in South America, kauri (\"Agathis australis\") specimens in New Zealand, clanwilliam cedar (\"Widdringtonia cedarbergensis\") specimens in Australia and Tasmania, and huon pine (\"Lagarostrobus franklinii\") in Tasmania (Jacoby, 2000al; Norton, 1990).” \n\nThe main application of tree research laboratory science or dendroarchaeology is to produce records of past climates that might be unavailable otherwise. Timber remains give insight into what little remains of our national forests prior to colonial settlement. This also benefits the sciences of paleoclimatology.\n\nDendrochronological dating is potentially applicable wherever trees were growing, except in tropical regions. For use in absolute dating of archaeological sites, it is partially limited by the availability of a master reference chronology for the region concerned. If there is a gap in the chronology (e.g. the inability to use a chronology constructed from pine samples in the British Isle prior to the 17th century due to the lack of use of pine in architecture then) then absolute dating cannot be applied. Additionally, non-climatic influences can also affect the tree-ring pattern of timber samples. Even if a reference chronology is available, care must be taken to identify aberrations in the ring pattern to determine if the sample is usable for dating.\n\nDendroarchaeology has been used extensively in the dating of historical buildings. After cross-matching the chronology from the building with the chronology of living trees, it is immediately possible to figure out the dates at which the historic timbers used in construction were felled. Similarly, if an extended chronology is available, then dating of samples from buildings of known or unknown date is possible. However, a limiting aspect of this application becomes apparent when dating medieval buildings. In such buildings, many timber samples lack completeness out to the underbark surface which can make the task of determining the felling year much more difficult.\n\nThe application of dendroarchaeology in uncovering past trade patterns also becomes possible as chronology records for timber around the world become more complete and accessible. Patterns from individual samples will match much more closely with their native chronologies than with their regional chronology. For example, strong cross dating is found between Irish and English chronologies, but individual ring patterns tend to match better against their local chronologies. Hence, this strong geographical component of tree ring chronologies can be used to source timber samples at archaeological sites to uncover trade routes required for the site construction.\n\nDendrochronology can also be used in concert with radiocarbon dating to allow for more accurate date measurements using radiocarbon dating on archaeological sites. It is known that the concentration of carbon-14 in the atmosphere is not constant. By performing radiocarbon dating on timber samples in a known chronology, radiocarbon dates can be plotted against real time generating a calibration curve that can be used for future radiocarbon samples.\n\nWhile dendrochronology is often considered as an absolute dating method, it can also be used as a powerful tool in the relative dating of an archaeological site. Timber samples may be able to be compared with others on the site to help construct a timeline of events for that particular site. Such samples can also be used to settle issues in constructing a chronological typology for artifacts found on site. The important point is that such within-site analysis can be done whether or not a chronology is available to date the whole assemblage.\n\n"}
{"id": "20937523", "url": "https://en.wikipedia.org/wiki?curid=20937523", "title": "E2 (HCV)", "text": "E2 (HCV)\n\nE2 is a viral structural protein found in the hepatitis C virus. It is present on the viral membrane and functions as a host receptor binding protein, mediating entry into host cells. It is a key target for the design of entry inhibitors and vaccine immunogens.\n"}
{"id": "58721433", "url": "https://en.wikipedia.org/wiki?curid=58721433", "title": "Emma Yhnell", "text": "Emma Yhnell\n\nEmma Yhnell is a research scientist at Cardiff University, in the Medical Research Council Centre for Neuropsychiatric Genetics and Genomics. She conducts research on computerised cognitive training and Huntington's disease. In 2018, Yhnell won the British Science Association's Charles Darwin Award Lecture for Agricultural, Biological and Medical Sciences.\n\nYhnell attended Chosen Hill School in Gloucestershire (2001-2009). Yhnell then went to Cardiff University for undergraduate study and graduated with a First Class BSc Hons in Biochemistry in 2012. She completed her PhD in 2015, which was funded by an MRC studentship, on Behavioural Neuroscience and Huntington’s disease.\n\nYhnell currently works as a post-doctoral research fellow in the Neuroscience and Mental Health Research Institute, within the MRC Centre for Neuropsychiatric Genetics and Genomics at Cardiff University. Her research is on Huntington's disease, a rare genetic brain disorder which causes cognitive, motor, and psychiatric problems. She currently has a Health and Care Research Wales Fellowship to investigate the potential of computerised cognitive training for people with Huntington's disease, translating her findings from her PhD into the clinical setting with patients.\n\nYhnell's public engagement work has included speaking at the Hay Festival of Literature & Arts, Soapbox Science, a series of events promoting women working in science, and Pint of Science, a festival communicating scientific developments to the general public. In March 2016, Yhnell attended the Westiminster Parliament of the United Kingdom to present on the potential of using games to train the brain, to improve cognition and movement, as part of the national competition \"SET for Britain\". \n\nShe is a Fellow of the Higher Education Academy and a British Neuroscience Association Local Group Representative. \n\nYhnell won the Biochemical Society's Science Communication Competition in the Written category in 2015. In 2017 she won the Young Investigator Award from the Cardiff Institute of Tissue Engineering and Repair. In the same year she was a finalist for the Womenspire Chwarae Teg Rising Star award.\n\nIn 2018, Yhnell was awarded the British Science Association's Charles Darwin Award Lecture for Agricultural, Biological and Medical Sciences. Yhnell gave her award lecture at the British Science Festival in Hull in September 2018, in which she discussed her cutting edge research in Huntington's disease and it's challenges, and public and patient involvement in research in using brain-training.\n\n"}
{"id": "25231240", "url": "https://en.wikipedia.org/wiki?curid=25231240", "title": "Etatorquevirus", "text": "Etatorquevirus\n\nEtatorquevirus is a recently discovered genus in the new family of Anelloviridae, in group . It encompasses the single type species of the Torque Teno Felis Virus.\n\n"}
{"id": "53848834", "url": "https://en.wikipedia.org/wiki?curid=53848834", "title": "Gabor Forgacs", "text": "Gabor Forgacs\n\nGabor Forgacs is a hungarian theoretical physicist turned bioengineer turned innovator and entrepreneur. He was awarded the status of Fellow in the American Physical Society, after they were nominated by their Division of Biological Physics in 2008, for \"his original contributions to the elucidation of physical mechanisms in early morphogenesis, intracellular signaling, establishment of the technology of organ printing, as well as for his synergistic and educational activity to bridge the gap between the physical and life sciences.\"\n"}
{"id": "16914868", "url": "https://en.wikipedia.org/wiki?curid=16914868", "title": "Gaonburha", "text": "Gaonburha\n\nA gaonburha or gaoburha is the leader of an Assamese gaon or village. The role of gaonburhas in Assamese gaons that are under mouzas are limited, since mouzadars take the responsibility of the gaonburha. For gaons that are far from district heads or major cities, gaonburhas still play difinitive roles.\n"}
{"id": "49725679", "url": "https://en.wikipedia.org/wiki?curid=49725679", "title": "Helia Bravo Hollis", "text": "Helia Bravo Hollis\n\nHelia Bravo Hollis (30 September 1901 – 26 September 2001) was a Mexican botanist, distinguished with the titles of Emeritus Researcher and honoris causa doctorate by the UNAM. For many years she developed her scientific research at the Faculty of Sciences of the same university.\n\nShe was born and raised in the neighborhood of Mixcoac, in Mexico City. Her interest in the study of living beings came from Sunday walks with her parents.\n\nThough the Mexican Revolution conflicts affected her family, she made progress with her studies and entered high school in 1919.\n\nSaint Ildefonso (National Preparatory High School), in Mexico City, was a very interesting institution for her, with professors like Vicente Lombardo Toledano, Sotero Prieto, Erasmo Castellano, Antonio Caso, and , who influenced Bravo's interest in the biological sciences.\n\nSuccessfully finishing high school, she continued her studies in medicine, as there was pressure from her family to become a doctor and biology was not available as a major at the UNAM. However, an opportunity to study biology arose a year afterwards, and she transferred to study at the College of Sciences of the same university.\n\nIn 1931, she obtained the degree of Master of Science in Biological Sciences from the College of Philosophy and Letters of the UNAM, with the thesis \"Contribution to the knowledge of the cactus of Tehuacán, Puebla\"\".\" She received an honorary doctorate from UNAM in 1985. \n\nBravo worked in the field of zoology in the area of parasitic and free-living protozoa, publishing nine studies between 1921 and 1927 while still a student alongside Professor Isaac Ochoterena. She joined the teaching faculty at the National Preparatory School as a teaching assistant, and later as a professor. \n\nShe is invited to head the Biology Department of the UNAM, which has changed its name to \"Instituto de Biología de la UNAM\" after the University became autonomous in 1929.\n\nIn the 1950s, she returned to academic life and was a professor of Botany at the National School of Biological Sciences of the Instituto Politécnico Nacional. Two years later she returned to the Instituto de Biología at UNAM. It is during this period that she shared the leadership of the National Herbarium with Débora Ramírez Cantú.\n\nShe made contributions to the area of floriculture, although in the arid regions of eastern Mexico, she focused on the taxonomy of cactaceae. She organized a collection of live cactaceae and other succulent plants in order to observe their development and evaluate morphological characteristics.\n\nShe co-founded the Mexican Cactus Society (Sociedad Mexicana de Cactología) in 1951, and later helped to found the Botanical Gardens at UNAM in 1959, serving as its director in the 1960s. She specialized in the taxonomy of cactacea in Mexico, authoring an entire monograph on the Mesoamerican region. She conducted fieldwork and worked in herbariums, disseminating her findings in publications, conferences, and in the classroom. \n\nHer scientific writings span over 160 publications, 60 taxonomy descriptions, and 59 reclassifications. Bravo published her first book in 1937.\n\nBravo obtained several distinctions as well as national and international recognitions. She received the Cactus d'Or Award from the International Organization for Succulent Plant Study (IOS) in 1980. The last award she received was for her work regarding the flora of Metztitlán, Hidalgo, during the creation of the Reservation of the Biosphere in 2000.\n\nThe Helia Bravo Hollis Botanical Garden in Puebla, Mexico was named after her and is home to many endangered cactus species.\n\nNine taxa of the flora and fauna of Mexico have been appointed in her honor, including:\n\nOn 30 September 2018, search engine Google commemorate Helia Bravo Hollis with a Doodle.\n\n"}
{"id": "6478242", "url": "https://en.wikipedia.org/wiki?curid=6478242", "title": "Helper virus", "text": "Helper virus\n\nA helper virus is a virus used when producing copies of a helper dependent viral vector which does not have the ability to replicate on its own. The helper virus is used to co-infect cells alongside the viral vector and provides the necessary enzymes for replication of the genome of the viral vector.\n\nHepatitis B virus (HBV) is an example of a helper virus that helps Hepatitis D virus (HDV) (a replication defective, helper dependent ssRNA virus) to replicate -- as HDV requires the surface antigen of HBV (HBsAg) for the encapsidation of its own genome. The envelope proteins on the outer surface of HDV are entirely provided by HBV.\n\nHelper Dependent Virus\n"}
{"id": "9575078", "url": "https://en.wikipedia.org/wiki?curid=9575078", "title": "Hollow Moon", "text": "Hollow Moon\n\nThe Hollow Moon hypothesis, or Spaceship Moon hypothesis, proposes that Earth's Moon is either wholly hollow or otherwise contains a substantial interior space. No scientific evidence exists to support the idea; seismic observations and other data collected since spacecraft began to orbit or land on the Moon indicate that it has a thin crust, extensive mantle and small, dense core, although overall it is much less dense than Earth.\n\nThe Hollow Moon concept is similar to the better-known Hollow Earth hypothesis, which was a recurring plot device in pre-spaceflight science fiction. The first discussion of a hollow Earth was by scientist Edmond Halley in 1692, with the first mention of a hollow Moon being in H. G. Wells' 1901 novel \"The First Men in the Moon\".\n\nThe Hollow Moon hypothesis is the suggestion that the Moon is hollow, usually as a product of an alien civilization. It is often called the Spaceship Moon hypothesis, and often corresponds with beliefs in UFOs or ancient astronauts.\n\nThe suggestion of a hollow moon first appeared in science fiction, when H. G. Wells wrote about a hollow moon in his 1901 book \"The First Men in the Moon\". The concept of hollow planets was not new; Wells borrowed from earlier fictional works that described a hollow Earth, such as the 1741 novel \"Niels Klim's Underground Travels\" by Ludvig Holberg. Academic proposals for a hollow Earth pre-dated that. Edmond Halley's hypotheses, advanced in 1692, was the first one to specify an actual void in the Earth.\n\nGreek mythology, with its Hades, and early religious concepts of an underworld, such as the Christian Hell, contributed to ideas of the Earth being hollow.\n\nIt is now considered to be a fringe theory. It is often described in the media as a conspiracy theory, and the concept of the Moon as a spaceship is often mentioned as one of David Icke's beliefs.\n\nIn 1970, Michael Vasin and Alexander Shcherbakov, of what was then the Soviet Academy of Sciences, advanced a hypothesis that the Moon is a spaceship created by unknown beings. The article was entitled \"Is the Moon the Creation of Alien Intelligence?\", and was published in \"Sputnik\", the Soviet equivalent of \"Reader's Digest\".\n\nTheir hypothesis relies heavily on the suggestion that large lunar craters, generally assumed to be formed from meteor impact, are generally too shallow and have flat or even convex bottoms. They hypothesized that small meteors are making a cup-shaped depression in the rocky surface of the moon while the larger meteors are drilling through a rocky layer and hitting an armoured hull underneath.\n\nThe authors reference earlier speculation by astrophysicist Iosif Shklovsky, who suggested that the Martian moon Phobos was an artificial satellite and hollow; this has since been shown to not be the case. Sceptical author Jason Colavito points out that all of their evidence is circumstantial, and that in the 1960s the atheistic Soviet Union promoted the ancient astronaut concept in an attempt to undermine the West's faith in religion.\n\nBetween 1972 and 1977, seismometers installed on the Moon by the Apollo missions recorded moonquakes. The Moon was described as \"ringing like a bell\" during some of those quakes, specifically the shallow ones. This phrase was brought to popular attention in March 1970, in an article in \"Popular Science\". When Apollo 12 deliberately crashed the Ascent Stage of its Lunar Module onto the Moon's surface, it was claimed that the Moon rang like a bell for an hour, leading to arguments that it must be hollow like a bell. Lunar seismology experiments since then have shown that the lunar body has shallow moonquakes that act differently from quakes on Earth, due to differences in texture, type and density of the planetary strata, but there is no evidence of any large empty space inside the body.\n\nThe fact that the Moon is less dense than the Earth is advanced as support for it to be hollow. The moon's mean density is 3.3 g/cm whereas the Earth's is 5.5 g/cm. One explanation of this discrepancy is that the moon may have been formed by a giant impact which ejected some of the early Earth's upper crust into its orbit. The Earth's upper mantle and crust are less dense than its core.\n\nCornell University's \"Ask an Astronomer\", run by volunteers in the Astronomy Department, answered the question \"Can we prove that the Moon isn't hollow?\". There, physicist Suniti Karunatillake suggests that there are at least two ways to determine the distribution of mass within a body. One involves moment of inertia parameters, the other involves seismic observations. In the case of the former, Karunatillake points out that the moment of inertia parameters indicate that the core of the moon is both dense and small, with the rest of the moon consisting of material with nearly-constant density. As for the latter, he notes that the moon is the only planetary body besides Earth on which extensive seismic observations have been made. These observations have constrained the thickness of the moon's crust, mantle and core, suggesting it could not be hollow.\n\nMainstream scientific opinion on the internal structure of the Moon overwhelmingly supports a solid internal structure with a thin crust, an extensive mantle and a small denser core. This is based on:\n\n\n"}
{"id": "1547778", "url": "https://en.wikipedia.org/wiki?curid=1547778", "title": "Identity by descent", "text": "Identity by descent\n\nA DNA segment is identical by state (IBS) in two or more individuals if they have identical nucleotide sequences in this segment. An IBS segment is identical by descent (IBD) (note: the acronym IBD is also used for another concept in population genetics, isolation by distance) in two or more individuals if they have inherited it from a common ancestor without recombination, that is, the segment has the same ancestral origin in these individuals. DNA segments that are IBD are IBS per definition, but segments that are not IBD can still be IBS due to the same mutations in different individuals or recombinations that do not alter the segment.\n\nAll individuals in a finite population are related if traced back long enough and will, therefore, share segments of their genomes IBD. During meiosis segments of IBD are broken up by recombination. Therefore, the expected length of an IBD segment depends on the number of generations since the most recent common ancestor at the locus of the segment. The length of IBD segments that result from a common ancestor \"n\" generations in the past (therefore involving 2\"n\" meiosis) is exponentially distributed with mean 1/(2\"n\") Morgans (M). The expected number of IBD segments decreases with the number of generations since the common ancestor at this locus. For a specific DNA segment, the probability of being IBD decreases as 2 since in each meiosis the probability of transmitting this segment is 1/2.\n\nIdentified IBD segments can be used for a wide range of purposes. As noted above the amount (length and number) of IBD sharing depends on the familial relationships between the tested individuals. Therefore, one application of IBD segment detection is to quantify relatedness. Measurement of relatedness can be used in forensic genetics, but can also increase information in genetic linkage mapping and help to decrease bias by undocumented relationships in standard association studies.\nAnother application of IBD is genotype imputation and haplotype phase inference. Long shared segments of IBD, which are broken up by short regions may be indicative for phasing errors.\n\nIBD mapping is similar to linkage analysis, but can be performed without a known pedigree on a cohort of unrelated individuals. IBD mapping can be seen as a new form of association analysis that increases the power to map genes or genomic regions containing multiple rare disease susceptibility variants.\n\nUsing simulated data, Browning and Thompson showed that IBD mapping has higher power than association testing when multiple rare variants within a gene contribute to disease susceptibility. Via IBD mapping, genome-wide significant regions in isolated populations as well as outbred populations were found while standard association tests failed. Houwen et al. used IBD sharing to identify the chromosomal location of a gene responsible for benign recurrent intrahepatic cholestasis in an isolated fishing population. Kenny et al. also used an isolated population to fine-map a signal found by a genome-wide association study (GWAS) of plasma plant sterol (PPS) levels, a surrogate measure of cholesterol absorption from the intestine. Francks et al. was able to identify a potential susceptibility locus for schizophrenia and bipolar disorder with genotype data of case-control samples. Lin et al. found a genome-wide significant linkage signal in a dataset of multiple sclerosis patients. Letouzé et al. used IBD mapping to look for founder mutations in cancer samples.\n\nDetection of natural selection in the human genome is also possible via detected IBD segments. Selection will usually tend to increase the number of IBD segments among individuals in a population. By scanning for regions with excess IBD sharing, regions in the human genome that have been under strong, very recent selection can be identified.\n\nIn addition to that, IBD segments can be useful for measuring and identifying other influences on population structure. Gusev et al. showed that IBD segments can be used with additional modeling to estimate demographic history including bottlenecks and admixture. Using similar models Palamara et al. and Carmi et al. reconstructed the demographic history of Ashkenazi Jewish and Kenyan Maasai individuals. Botigué et al. investigated differences in African ancestry among European populations. Ralph and Coop used IBD detection to quantify the common ancestry of different European populations and Gravel et al. similarly tried to draw conclusions of the genetic history of populations in the Americas. Ringbauer et al. utilized geographic structure of IBD segments to estimate dispersal within Eastern Europe during the last centuries. Using the 1000 Genomes data Hochreiter found differences in IBD sharing between African, Asian and European populations as well as IBD segments that are shared with ancient genomes like the Neanderthal or Denisova.\n\nPrograms for the detection of IBD segments in unrelated individuals:\n\n"}
{"id": "10518059", "url": "https://en.wikipedia.org/wiki?curid=10518059", "title": "Jim T. Enright", "text": "Jim T. Enright\n\nJ. T. Enright was a skeptic and professor of behavioral physiology at the Scripps Institution of Oceanography, University of California, San Diego. As a teacher, he emphasized data analysis in the critical evaluation of scientific literature. He has conducted research on biological clocks and sensory physiology of both crustaceans and humans. \n\n"}
{"id": "7301821", "url": "https://en.wikipedia.org/wiki?curid=7301821", "title": "Journal of Parapsychology", "text": "Journal of Parapsychology\n\nThe Journal of Parapsychology is a biannual peer-reviewed academic journal covering research on psi phenomena, including telepathy, clairvoyance, precognition, and psychokinesis, as well as human consciousness in general and anomalous experiences.\n\nIt was established in April 1937 by Joseph Banks Rhine (Duke University). It is published by the Rhine Research Center and the current editor-in-chief is Etzel Cardeña (Lund University). The journal is abstracted and indexed in PsychINFO. It publishes research reports, theoretical discussions, book reviews, and correspondence, as well as the abstracts of papers presented at the Parapsychological Association's annual meeting.\n\n\n"}
{"id": "14357505", "url": "https://en.wikipedia.org/wiki?curid=14357505", "title": "Laysan honeycreeper", "text": "Laysan honeycreeper\n\nThe Laysan honeycreeper or Laysan apapane (\"Himatione fraithii\") is an extinct bird species that was endemic to the island of Laysan in the Northwestern Hawaiian Islands.\n\nThe species was described by the British ornithologist Walter Rothschild in 1892 under its current binomial name. In a review published in 1950, the American ornithologist Dean Amadon treated the Laysan honeycreeper as a subspecies of the ʻApapane and adopted the trinomial name \"Himatione sanguinea freethii\". Subsequent publications followed this lead. In 2015 the North American Classification Committee (NACC) of the American Ornithologists' Union decided to promote the extinct honeycreeper to the species level and to adopt the original binomial name. This change was adopted by the International Ornithological Committee in their world list of birds.\n\n \nAn adult male Laysan honeycreeper had vermilion upperparts, an ashy-brown lower abdomen and underwing-coverts, and brownish-white undertail-coverts. Adult females were similar to the male, but had paler red feathers. After molting, the feathers were brighter but faded with sunlight exposure.\n\nLaysan honeycreepers fed on nectar from the native flowers on the island, especially \"maiapilo\" (Capparis sandwichiana). When populations of that species declined, it was forced to feed on nectar from \"ākulikuli\" (\"Sesuvium portulacastrum\") and \"ihi\" (\"Portulaca lutea\"). It was observed visiting \"koali awa\" (\"Ipomoea indica\"), \"pōhuehue\" (\"I. pes-caprae brasiliensis\"), and \"nohu\" (\"Tribulus cistoides\"), and would also feed on caterpillars and moths. Unlike the ʻapapane, the Laysan honeycreeper foraged on the ground.\n\nLaysan honeycreeper primarily nested in the center of tall grass bunches, but sometimes built nests in dense \"āheahea\" (\"Chenopodium sandwichensis\") shrubs. Nests were made of rootlets interwoven with grass blades. The clutch size was four to five eggs.\n\nDomestic rabbits were introduced to the island in the late 19th century, and quickly consumed nearly all vegetation on the island, including nectar sources for the Laysan honeycreeper. The bird was filmed in 1923 during the Tanager Expedition. Shortly after, Laysan was battered by a strong storm, and later attempts at finding any remaining Laysan honeycreeper failed. Other birds also inhabited the island, including the Laysan millerbird, the Laysan rail, the Laysan duck, and the Laysan finch. Of these, only the finch and the duck remain extant.\n"}
{"id": "30126483", "url": "https://en.wikipedia.org/wiki?curid=30126483", "title": "List of animals of Malaysia", "text": "List of animals of Malaysia\n\nThis is a list of animals found in Malaysia. Malaysia is a megadiverse country, with its rainforest hosting a huge \nanimal species. There are around 361 mammals species, 250 reptile species, and 150 frog species found in Malaysia. 677 bird species are found on Peninsular Malaysia alone (and 694 for Malaysia). Malaysia's large marine territory also holds a great diversity of life, with the country's waters being part of the Coral Triangle.\n\n\n\n\n"}
{"id": "25414243", "url": "https://en.wikipedia.org/wiki?curid=25414243", "title": "List of archosaurs of the Chinle Formation", "text": "List of archosaurs of the Chinle Formation\n\nThe Chinle Formation is an Upper Triassic continental geologic formation in the western United States which has yielded fossils of many archosaurs: a group of vertebrates that includes crocodiles, pterosaurs, dinosaurs (including birds), and other extinct relatives.\n\nProsauropod tracks are present in the Redonda, Sloan Canyon, and Sheep Pen Sandstone formations. Possibly the Rock Point Formation as well. Geographically, the tracks are present in New Mexico.\n\nIndeterminate ceratosaurian remains have been recovered from the Bull Canyon Formation in New Mexico. Theropod tracks have been found in Utah and New Mexico recovered from the Redonda, Sloan Canyon, and Sheep Pen Sandstone formations. Indeterminate theropod remains are stratigraphically present in the Santa Rosa, Petrified Forest, Bluewater Creek, Rock Point, and Garita Creek formations. They are geographically present in New Mexico. Indeterminate herrerasaurid remains stratigraphically present in the Bull Canyon Formation and geographically present in New Mexico.\n\n"}
{"id": "25804896", "url": "https://en.wikipedia.org/wiki?curid=25804896", "title": "List of jumping activities", "text": "List of jumping activities\n\n\n\n"}
{"id": "23633", "url": "https://en.wikipedia.org/wiki?curid=23633", "title": "List of physicists", "text": "List of physicists\n\nFollowing is a list of physicists who are notable for their achievements.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "42686458", "url": "https://en.wikipedia.org/wiki?curid=42686458", "title": "List of solar storms", "text": "List of solar storms\n\nSolar storms of different types are caused by disturbances on the Sun, most often coronal clouds associated with coronal mass ejections (CMEs) produced by solar flares emanating from active sunspot regions, or, less often, from coronal holes.\n\nActive stars produce disturbances in space weather with the field of heliophysics the science that studies such phenomena; itself primarily an interdisciplinary combination of solar physics and planetary science. In the Solar System, the Sun can produce intense geomagnetic and proton storms capable of causing severe damage to technology including but not limited to large scale power outages, disruption or blackouts of radio communications (including GPS), and temporary to permanent disabling of satellites and other spaceborne technology. Intense solar storms may also be hazardous to high-latitude, high-altitude aviation and to human spaceflight. Geomagnetic storms are the cause of auroras. The most significant known solar storm occurred in September 1859 and is known as the \"Carrington event\". The damage from the most potent solar storms is capable of existentially threatening the stability of modern human civilization, although proper preparedness and mitigation can substantially reduce the hazards. Proxy data from Earth, as well as analysis of stars similar to the Sun suggest that it may be capable of producing so called superflares, those which are much larger than any flares in the historical record (as much as 1000x stronger every 5000 years).\n\n\nAlthough there is proxy evidence, interpretation of such proxy data remains unresolved..\n\nThe above events affected Earth (and its vicinity, known as the magnetosphere), whereas the following events occurred elsewhere in the solar system and were detected by monitoring spacecraft or other means.\n\n"}
{"id": "41720812", "url": "https://en.wikipedia.org/wiki?curid=41720812", "title": "List of symbols of Indian states and territories", "text": "List of symbols of Indian states and territories\n\nThis is a list of the symbols of the States and union territories of India. Each State and Union territory has a unique set of official symbols.\n\n\n\n"}
{"id": "46479115", "url": "https://en.wikipedia.org/wiki?curid=46479115", "title": "Ludwig Staiger", "text": "Ludwig Staiger\n\nLudwig Staiger is a German mathematician and computer scientist at the Martin-Luther-Universität Halle-Wittenberg, Germany. Previously he had positions at the Academy of Sciences in Berlin (East),\nthe Central Institute of Cybernetics and Information Processes, the Karl Weierstrass Institute for Mathematics and the Technical University Otto-von-Guericke Magdeburg. He was a visiting professor at the RWTH Aachen, the universities Dortmund, Siegen, Cottbus in Germany and the Technical University Vienna, Austria. He is a member of the Managing Committee of the Georg Cantor Association and an external researcher of the Center for Discrete Mathematics and Theoretical Computer Science at the University of Auckland, New Zealand.\n\nHe co-invented with Klaus Wagner the Staiger-Wagner Automaton. Staiger is an expert in ω-languages, an area in which he wrote more than 19 papers including the paper on this topic in the monograph. He found surprising applications of ω-languages in the study of Liouville numbers.\n\nStaiger is an active researcher in combinatorics on words, automata theory, effective dimension theory and algorithmic information theory.\n\n\n"}
{"id": "15366768", "url": "https://en.wikipedia.org/wiki?curid=15366768", "title": "Mononuclidic element", "text": "Mononuclidic element\n\nA mononuclidic element or monotopic element is one of the 22 chemical elements that is found naturally on Earth essentially as a single nuclide (which may, or may not, be a stable nuclide). This single nuclide will have a characteristic atomic mass. Thus, the element's natural isotopic abundance is dominated either by one stable isotope or by one very long-lived isotope. There are 19 elements in the first category (which are both monoisotopic and mononuclidic), and 3 (bismuth, thorium and protactinium) in the second category (mononuclidic but not monoisotopic, since they have zero, not one, stable nuclides). A list of the 22 mononuclidic elements is given at the end of this article.\n\nOf the 26 \"monoisotopic elements\" that, by definition, have only one stable isotope, there exist 7 (26 minus 19 = 7) which are nevertheless \"not\" considered mononuclidic, due to the presence of a significant fraction of a very long-lived (primordial) radioisotope occurring in their natural abundance. These elements are vanadium, rubidium, indium, lanthanum, europium, rhenium, and lutetium.\n\nMononuclidic elements are of scientific importance because their atomic weights can be measured to high accuracy, since there is minimal uncertainty associated with the isotopic abundances present in a given sample. Another way of stating this, is that, for these elements, the standard atomic weight and atomic mass are the same. \n\nIn practice, only 11 of the mononuclidic elements are used in standard atomic weight metrology. These are aluminium, bismuth, caesium, cobalt, gold, manganese, phosphorus, scandium, sodium, terbium, and thorium.\n\nIn nuclear magnetic resonance spectroscopy (NMR), the three most sensitive stable nuclei are hydrogen-1 (H), fluorine-19 (F) and phosphorus-31 (P). Fluorine and phosphorus are monoisotopic, with hydrogen nearly so. H NMR, F NMR and P NMR allow for identification and study of compounds containing these elements.\n\nTrace concentrations of unstable isotopes of some mononuclidic elements are found in natural samples. For example, beryllium-10 (Be), with a half-life of 1.4 million years, is produced by cosmic rays in the Earth's upper atmosphere; iodine-129 (I), with a half-life of 15.7 million years, is produced by various cosmogenic and nuclear mechanisms; caesium-137 (Cs), with a half-life of 30 years, is generated by nuclear fission. Such isotopes are used in a variety of analytical and forensic applications.\n\nData from Atomic Weights and Isotopic Compositions ed. J. S. Coursey, D. J. Schwab and R. A. Dragoset, National Institute of Standards and Technology (2005).\n"}
{"id": "44115838", "url": "https://en.wikipedia.org/wiki?curid=44115838", "title": "Nieves López Martínez", "text": "Nieves López Martínez\n\nNieves López Martínez (Burgos, 5 February 1949 - Madrid, 15 December 2010) was a Spanish paleontologist specializing in research on the vertebrate fossil record and part of a group of paleontologists who were responsible for the modernization of paleontological studies in Spain.\n\nLopez Martinez studied at Complutense University of Madrid, graduating in Biological Sciences in 1970. She received a scholarship to do her PhD work, under the supervision of Dr. Louis Thaler at the University of Montpellier.\n\nLópez Martínez was recognized worldwide as a leading figure in the study of the evolution of Cenozoic lagomorphs, as well as the Cretaceous–Paleogene extinction event in the area of the Pyrenees. She was also very involved with university teaching programs, both officially at the Complutense University of Madrid and through various projects, such as the Somosaguas Paleontology Project, which was associated with the Somosaguas paleontological site.\n"}
{"id": "4583557", "url": "https://en.wikipedia.org/wiki?curid=4583557", "title": "OELib", "text": "OELib\n\nOELib was an Open Source Cheminformatics library. Its actual GPLed C++ and Java successors are OpenBabel and JOELib. Its commercial successor is called OEChem.\n\n\n"}
{"id": "38699400", "url": "https://en.wikipedia.org/wiki?curid=38699400", "title": "Outline of brain mapping", "text": "Outline of brain mapping\n\nThe following outline is provided as an overview of and topical guide to brain mapping:\n\nBrain mapping – set of neuroscience techniques predicated on the mapping of (biological) quantities or properties onto spatial representations of the (human or non-human) brain resulting in maps. Brain mapping is further defined as the study of the anatomy and function of the brain and spinal cord through the use of imaging (including intra-operative, microscopic, endoscopic and multi-modality imaging), immunohistochemistry, molecular & optogenetics, stem cell and cellular biology, engineering (material, electrical and biomedical), neurophysiology and nanotechnology.\n\n\n\n\nThis section covers imaging and recording systems. The general section covers history, neuroimaging, and techniques for mapping specific neural connections. The specific systems section covers the various specific technologies, including experimental and widely deployed imaging and recording systems.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "11235593", "url": "https://en.wikipedia.org/wiki?curid=11235593", "title": "Pedicel (botany)", "text": "Pedicel (botany)\n\nA pedicel is a stem that attaches a single flower to the inflorescence. In the absence of a pedicel, the flowers are described as sessile. Pedicel is also applied to the stem of the infructescence. The word \"pedicel\" is derived from the latin \"pediculus\", meaning \"little foot\". \n\nThe stem or branch from the main stem of the inflorescence that holds a group of pedicels is called a peduncle.\n\nIn Halloween types of pumpkin or squash plants, the shape of the pedicel has received particular attention because plant breeders are trying to optimize the size and shape of the pedicel for the best \"lid\" for a \"jack-o'-lantern\".\n\n"}
{"id": "1191117", "url": "https://en.wikipedia.org/wiki?curid=1191117", "title": "Peierls bracket", "text": "Peierls bracket\n\nIn theoretical physics, the Peierls bracket is an equivalent description of the Poisson bracket. It can be defined directly from the action and does not require the canonical coordinates and their canonical momenta to be defined in advance. \n\nThe bracket \n\nis defined as \n\nas the difference between some kind of action of one quantity on the other, minus the flipped term. \n\nIn quantum mechanics, the Peierls bracket becomes a commutator i.e. a Lie bracket.\n\nPeierls, R. \"The Commutation Laws of Relativistic Field Theory,\"\nProc. R. Soc. Lond. A August 21, 1952 214 1117 143-157.\n"}
{"id": "25437026", "url": "https://en.wikipedia.org/wiki?curid=25437026", "title": "Polar exploration", "text": "Polar exploration\n\nPolar exploration is the process of exploration of the polar regions of the Earth - the Arctic region and Antarctica - particularly with the goal of reaching the North Pole and South Pole, respectively. Historically, this was accomplished by explorers making often arduous travels on foot or by sled in these regions, known as a polar expedition. More recently, exploration has been accomplished with technology, particularly with satellite imagery.\n\nFrom 600 BC to 300 BC Greek Philosophers theorized that the planet was a Spherical Earth with North and South Polar regions. By 150 AD Ptolemy published Geographia, which notes a hypothetical Terra Australis Incognita. However, due to harsh weather conditions, the poles themselves would not be reached for centuries after that. When they finally were reached, the achievement was realized only a few years apart.\n\nThere are two claims, both disputed, about who was the first person to reach the geographic North Pole. Frederick Cook, accompanied by two Inuit men, Ahwelah and Etukishook claimed to have reached the Pole on April 21, 1908, although this claim is generally doubted. On April 6, 1909, Robert Peary claimed to be the first person in recorded history to reach the North Pole, accompanied by his employee Matthew Henson and four Inuit men Ootah, Seegloo, Egingway, and Ooqueah (although whether he actually reached the Pole is doubted by some).\n\nNorwegian explorer Roald Amundsen had planned to reach the North Pole by means of an extended drift in an icebound ship. He obtained the use of Fridtjof Nansen's polar exploration ship \"Fram\", and undertook extensive fundraising. Preparations for this expedition were disrupted when Cook and Peary each claimed to have reached the North Pole. Amundsen then changed his plan and began to prepare for a conquest of the geographic South Pole; uncertain of the extent to which the public and his backers would support him, he kept this revised objective secret. When he set out in June 1910, he led even his crew to believe they were embarking on an Arctic drift, and revealed their true Antarctic destination only when \"Fram\" was leaving their last port of call, Madeira.\n\nAmundsen's South Pole expedition, with Amundsen and four others, arrived at the pole on 14 December 1911, five weeks ahead of a British party led by Robert Falcon Scott as part of the Terra Nova Expedition. Amundsen and his team returned safely to their base, and later learned that Scott and his four companions had died on their return journey.\n\n"}
{"id": "39770643", "url": "https://en.wikipedia.org/wiki?curid=39770643", "title": "Remote Associates Test", "text": "Remote Associates Test\n\nThe Remote Associates Test (RAT) is a creativity test used to determine a human's creative potential. The test typically lasts forty minutes and consists of thirty to forty questions each of which consists of three common stimulus words that appear to be unrelated. The person being tested must think of a fourth word that is somehow related to each of the first three words. Scores are calculated based on the number of correct questions.\n\nThe Remote Associates Test (RAT), adult form was originally published in 1959, and then again in 1962, by Professor Sarnoff Mednick and Martha T. Mednick. In 1971, Mednick and Mednick published the high school form of the RAT. Mednick and Mednick defined the creative thinking process in the test manual as \"the forming of associative elements into new combinations which either meet specified requirements or are in someway useful. The more mutually remote the elements of the new combination, the more creative the process or solution.\" Mednick reported a Spearman-Brown reliability of RAT=0.92 in one sample of students at an Eastern women’s college, and 0.91 in a sample of men tested at the University of Michigan.\n\nThe two adult forms of the RAT consist of 30 items each. The respondent is allowed 40 minutes to complete the test. Each item provides three stimulus words that are remote from one another; the respondent is then required to find (via the creative process) another word that is a criteria-meeting mediating link, which can be associated with them all in a meaningful way. The test-taker's score is the number correct.\n\nIn Mednick’s two college-level versions of the test, each consisting of 30 items, each item can be associated with the solution word in a number of ways. For example, the three words same/tennis/head are associated with the solution match by means of synonymy (same = match), formation of a compound (matchhead), and semantics association (tennis match). In 2003, Edward M. Bowden and Mark Jung-Beeman developed 144 compound remote associate problems, a subset of RAT problems, for their studies of insight problem solving. They wanted a greater number of problems than were available in the original RAT, and to present participants with a more consistent task – that the solution word would always be related to the stimulus words in the same way. They designed a set of problems to which the solution word was associated with all three words of the triad through formation of a compound word (or phrase) (e.g., age/mile/sand for the compounds stone age, milestone, and sandstone with the solution word stone). Solution words were never repeated or used as problem words; problem words were sometimes repeated. The problems can be divided into two types: homogeneous, for which the solution word is a prefix (or suffix) to all three words of the problem triad, and heterogeneous, for which the solution word is a prefix (or suffix) to at least one of the words of the triad and a suffix (prefix) to the other word(s) of the triad. The 144 problems were scored according to the time required to solve them and to the difficulty ratio. This compound RAT gives researchers a cohesive and operational definition normative list, where subjects are able to solve tasks in less time. The increase in the task solving ratios also provides the test with stronger reliability, but at the price of losing complexity and ending up with a less challenging test, in terms of creativity.\n\nAccording to Mednick, the RAT could be used to test \"all fields of creative endeavor\" and suggest that those who excel on the RAT will be gifted creatively as well as in the sciences. Mednick also suggested that this test be used to select students from lower-income families to be admitted to special educational programs. However there is no data that shows that students who have done well on the RAT excel in any particular subject leading to criticism of the validity of the RAT. Worthen and Clark (1971) concluded that the RAT measured sensitivity to language rather than creative potential. The correct response is often the most common response and does not link the other three words in any conceptual way. Worthen and Clark improved upon the RAT to create the Functionally Remote Associates Test (FRAT) that depends on functional relationships.\n\nDespite the original intent for the RAT to be used as a measure of individual differences in associative ability, the RAT has fallen out of use as a self-standing test of creativity. This test has been used to assess a wider range of cognitive abilities thought to underline creative thinking.\n\nOver the years, the RAT has been used to assess various cognitive abilities linked to creativity including insight, memory and problem solving. It has been used to study the relation between creativity and rapid eye movement sleep (REM), peripheral attention, attention deficit, memory, synesthesia, and mental illness. In a meta analysis, surveying 45 studies concerning creativity and neuroimaging, the RAT is shown as the second most used standardized test, following the Alternate Uses Test and placing the Torrance Test of Creativity in third place.\n\nWhether the RAT should be used and interpreted as a measure of associative processing, convergent thinking and/or creative thinking remains an open question on both theoretical and empirical grounds. Currently, the debate surrounding the proper use of the RAT is difficult to determine in the absence of additional empirical studies examining the internal and external structure of the RAT. Findings from one study provide evidence for the RAT as a convergent thinking test, but much still remains to be understood regarding potential subprocesses of convergent thinking theorized to be assessed by the RAT and how these processes are linked to actual creative behaviors.\n\nThe RAT has been adapted into several versions. Researchers have developed a Jamaican adaptation as well as Hebrew, Dutch, Italian, Chinese and Japanese versions.\n"}
{"id": "18346908", "url": "https://en.wikipedia.org/wiki?curid=18346908", "title": "Social map", "text": "Social map\n\nThe first social maps date from the early 20th century. A recent example is the mapping of the residences of U.S. Facebook users and their social links .\n\nIn \"marketing\" a social map is a visualized analysis of a digital identity of a person, brand or company. A social map shows exactly where a digital identity is created, formed or discussed and sets each element in context and proportions.\n\nThese social map created an intense discussion about digital reputation and digital identities. For companies a so-called Corporate Social Map is still very new and an unusual methodology, but also very effective and meaningful.\n\n\n"}
{"id": "39369653", "url": "https://en.wikipedia.org/wiki?curid=39369653", "title": "Society for the History of Astronomy", "text": "Society for the History of Astronomy\n\nThe Society for the History of Astronomy is an organisation based in the United Kingdom that promotes research into the history of astronomy. It publishes a research journal called \"The Antiquarian Astronomer\" and a regular \"Bulletin\".\n\nThe Society for the History of Astronomy was founded in 2002 to promote the study of the history of astronomy by hosting talks by members and publishing new research into the field. One main objective was to encourage research into past astronomers who have previously been neglected within the history of science. Some of its members are professional historians of science but most are amateur historians.\n\nThe Honorary President is Dr Allan Chapman of Wadham College, Oxford. The honorary vice-presidents are Dr Michael Hoskin of Churchill College, Cambridge, and \nSir Arnold Wolfendale, FRS.\nSir Patrick Moore was an honorary vice-president until his death in 2012.\n\nThe Society hosts several one-day conferences at venues across the United Kingdom each year. A \"Bulletin\" is published twice yearly containing articles and news items about astronomical history. The Bulletin includes short reports of original research by members.\n\nThe society maintains a library of publications of importance to the history of science. It is known as the Sir Robert Ball Library and is located at the Birmingham and Midland Institute in central Birmingham. The archives of the Society are preserved at the Library of the Institute of Astronomy, Cambridge.\n\nOne of the Society's major activities is organising a Survey of Astronomical History in the form of lists of historical astronomers and observatories in each of the old counties of Britain and Ireland. This has been motivated by a desire to promote research into local astronomical activities that have previously been neglected.\n\nThe Society publishes annually a refereed journal called \"The Antiquarian Astronomer\" containing new research into the history of astronomy, particularly articles written by members. Published papers have discussed activities in major observatories, scientific research by individuals of particular note, scientific instrument makers, and the activities of prominent amateur astronomers.\n\nThe first issue appeared in 2004, and issue 9 was published in 2015. Back issues are indexed in the SAO/NASA Astrophysics Data System (ADS), and the ADS contains scans of all articles published during the period\n2004–2015.\nIts current editor is Ian Ridpath.\n\nThe Society publishes an bi-annual \"Bulletin\" containing news relating to the study of the history of astronomy and the organisation's activities. The \"Bulletin\" also includes short research articles and notes by members. It was previously called \"News\" (editions 1–4, 2002–2004) and \"Newsletter\" (editions 5–17, 2004–2008).\nArticles are indexed in the SAO/NASA Astrophysics Data System \nbut scans are not currently available.\nDigital versions are available online for some editions. The current editors are Carolyn Kennett and Len Adam.\n\nOne feature of this society is an annual summer picnic. Past picnics have been held at:-\n\n5 July 2003 Wadham College, Oxford\n\n3 July 2004 Woolsthorpe Manor\n\n6 August 2005 Wadham College, Oxford\n\n8 July 2006 ‘Farthings’, Selsey\n\n16 June 2007 Pendrell Hall, Staffordshire\n\n2 August 2008 Marlborough College, Wiltshire\n\n4 July 2009 Hanwell Community Observatory\n\n17 July 2010 Stonyhurst College\n\n16 July 2011 Orwell Park, Suffolk\n\n9 June 2012 Carr House, Much Hoole\n\n29 June 2013 Mill Hill Observatory\n\n12 July 2014 National Maritime Museum, Greenwich\n\n4 July 2015 Woolsthorpe Manor\n\n2 July 2016 Hanwell Community Observatory\n\n1 July 2017 Liverpool City Centre\n\n30 June 2018 Seething Observatory\n\n"}
{"id": "47781757", "url": "https://en.wikipedia.org/wiki?curid=47781757", "title": "Strong in the Rain", "text": "Strong in the Rain\n\nStrong In The Rain: Surviving Japan's Earthquake, Tsunami, and Fukushima Nuclear Disaster is a book by Lucy Birmingham and David McNeill published in 2012. The title is taken from the Japanese poem by Kenji Miyazawa about endurance.\n"}
{"id": "5598795", "url": "https://en.wikipedia.org/wiki?curid=5598795", "title": "Tekin Dereli", "text": "Tekin Dereli\n\nTekin Dereli (November 30, 1949) is a Turkish theoretical physicist.\n\nHe studied at Ankara Science High School and the Middle East Technical University.\n\nHe was an associate professor and a Professor of Physics at Middle East Technical University (1984–1987, 1993–2001); professor at Faculty of Science at Ankara University (1987–1993), Leverhulme Visiting Professor at Lancaster University UK (2000–2001) and since 2001, he is a professor at the department of physics at Koc University.\n\nTUBITAK honored him with TUBITAK Junior Science Price in 1982 and TUBITAK Science Price in 1996. He also was awarded prestigious Turkish prizes for science by \"Sedat Simavi Trust\" in 1989 and \"Prof. Mustafa Parlar Foundation\" in (1993).\n\nHe is a member of Turkish Academy of Sciences (TAS) since 1993.\n\nHe is married with two children.\n\nHis research interests are Yang-Mills gauge theories, supersymmetry, supergravity, quaternion and octonion algebras, spin structures, generalised theories of gravity, cosmological solutions, integrable systems and phase space quantisation.\n\n\n"}
{"id": "52769308", "url": "https://en.wikipedia.org/wiki?curid=52769308", "title": "Trial registration", "text": "Trial registration\n\nTrial registration is the practice of publishing the methodology of clinical trials before they begin. This reduces problems from publication bias and selective reporting (such as choosing the methodology after the results are known). Clinical trial registrations are now common and required by many funders and governments, and are increasingly being standardized. Trial registration is less common in other disciplines, but is part of the open science movement.\n\n"}
{"id": "40064315", "url": "https://en.wikipedia.org/wiki?curid=40064315", "title": "Vanishing Hand", "text": "Vanishing Hand\n\nThe Vanishing Hand theory is a concept first conceived of by economist Richard Normand Langlois. The term is an intentional play on both Adam Smith's invisible hand and Alfred Chandler's .\n\nIn Smith's work, his invisible hand describes the self-regulating behavior of the market. In essence, this theory states that individual personal motivations lead to the most efficient allocation of resources and greatest overall benefit, even if those motivations were not in any way benevolent. This is exemplified by relatively small firms operating with no market control. Competition between buyers and sellers channels the profit motive causing competition to lead to socially desirable outcomes. During Smith's time and much after, this was a justification for a laissez-faire economy. However, in Smith's day there were not several market forces that currently exist, such as large-scale industry, finance, and advertising.\n\nThe Visible hand, however, was believed by Chandler to have replaced the Invisible hand with middle management in the mid 19th century, which became “the most powerful institution in the American economy”. In short, he states that the multi-unit business structure arose because administrative coordination could yield greater profits than market coordination, giving rise to managerial hierarchy and led to furthered growth and profit. The rise of this new system yielded major sectors of the economy being dominated and altered the structure of markets, steering away from a competitive state and to an economy controlled by corporate managers. In other words, the large scale industries arising began to provide larger social benefits due to managerial presence and long-term scope rather than perfectly competitive markets.\n\nLanglois intended to show that Chandler's theory was partially correct but needed some reevaluation.\n\nThe Vanishing Hand theory, as argued by Dick Langlois:\n\n\"One of my longest-running interests has been the relationship between economic change, including technological change, and the boundaries of the firm. In broad strokes, my story is this: when markets are thin and market-supporting institutions weak, technological change, especially systemic change, leads to increased vertical integration, since in such an environment centralized ownership and control may reduce “dynamic” transaction costs; but when markets are thick and market-supporting institutions well developed, technological change leads to vertical disintegration, since in that environment the benefits of specialization and the division of labor outweigh the (now relatively smaller) transaction costs of contracting. This latter scenario is what I called the Vanishing Hand. I recently ran across a new working paper by Ann Bartel, Saul Lach, and Nachum Sicherman, called “Technological Change and the Make-or-Buy Decision,” that supports the Vanishing Hand idea empirically.\"\n\nIn other words, the Vanishing hand theory states that initially the Visible hand is present as industries require managerial cooperation and vertical integration for long term growth, but eventually fades away to a more Invisible hand in which specialization allows for market forces to coordinate more effectively leading to a quasi-Smithian division of labor. Temporary clusters of firms arose acting under Chandler's Visible hand process that would eventually be replaced by Smith's division of labor and thus Invisible hand. Many of the large, vertically-integrated corporations of the past have broken up in recent years into more specialized firms due to the removal of barriers to trade, such as outsourcing. Specifically it has once more become economically optimal to seek a division of labor, or seek vertical disintegration, rather than integrate.\n\nAs minimum efficient scale falls firms size should fall as well. When firm size is viewed as firm activity undertaken, this holds true. It is likely, therefore, that as integration becomes costlier in comparison to alternatives, large firms are more likely disintegrate to varying degrees and have a loosened managerial presence, although complete return to a Smithian market is unlikely.\n"}
{"id": "5059329", "url": "https://en.wikipedia.org/wiki?curid=5059329", "title": "War in the Age of Intelligent Machines", "text": "War in the Age of Intelligent Machines\n\nWar in the Age of Intelligent Machines (1991) is a book by Manuel DeLanda, in which he traces the history of warfare and the history of technology.\n\nIt is influenced in part by Michel Foucault's \"Discipline and Punish\" (1978) and also reinterprets the concepts of war machines and the machinic phylum, introduced in Gilles Deleuze and Félix Guattari's \"A Thousand Plateaus\" (1980). Deleuze and Guattari appreciated Foucault's definition of philosophy as a \"tool box\" that was to encourage thinking about new ideas. They prepared the field for a re-appropriation of their concepts, for use in another context of the \"same\" concept, which they called \"actualization\". DeLanda drew on the concepts these authors put forth, to investigate the history of warfare and technology.\n\nDeLanda describes how social and economic formations influence war machines, i.e. the form of armies, in each historical period. He draws on chaos theory to show how the biosphere reaches singularities (or bifurcations) which mark self-organization thresholds where emergent properties are displayed and claims that the \"mecanosphere\", constituted by the machinic phylum, possesses similar qualities. He argues for example how a certain level of population growth may induce invasions and others may provoke wars.\n\nAs a historian, DeLanda is indebted to the \"Annales School\" and the study of long-time historical phenomena, as opposed to human-scale phenomena. The next threshold point, or singularity, to be reached, according to DeLanda, is the point where man and machine cease to oppose themselves, becoming a war machine and when that war machine is crossed by the machinic phylum. It may result in erratic war machines that become nomads, because of a lack of political control. DeLanda writes:\n\nAccording to DeLanda, centralization and decentralization are two trends in the \"war machine\": either military commanders try to centralize command and control of each event on the battlefield and get \"human will out of the decision-making loop\" or they delegate responsibility to individual soldiers (e.g., platoons or the German mission-type tactics) to avoid \"friction\". \"Friction\", according to DeLanda, is like \"noise\" — too much friction blocks the war machine, which destroys itself. Thus, rather than waiting for friction to accumulate at the head of the control, command and communication center (C), which is the case in centralized armies, decentralized war machines allow it to disperse at each level of the machine.\n\nThe 1805 Jacquard loom, used holes punched in pasteboard punched cards to control the weaving of patterns in fabric and is the first example of a \"migration\" of human control to machine control and marks the invention of software according to DeLanda. Command and control techniques adapted by the Germans were then introduced in army arsenals by Frederick Taylor and extended to civilian society: \"the imposition of military production methods into the civilian society was accompanied by the transfer of a whole command and control grid.\" (p. 153) The system of Numerical control — and then the CNC — which was developed by funds from the US Air Force, \"withdraws all control from workers in the area of weapons production and centralizes it at the top. But if the NC (and related methods) effectively shortened the chain of command be getting humans out of the decision-making loop, it also weakened the civilian sector of the economy by its adverse effects on workers' productivity,\" (p. 154) argues Manuel DeLanda. He thus underlines that the US has become a net importer of machine tools for the first time since the 19th century, and points out that while in 1975 all major manufacturers of integrated chips were American, in 1986 only two were not Japanese. In 1982, the Japanese MITI had launched the Fifth Generation Computer Systems project (FGCS) initiative to create computers supposed to perform much calculation utilizing massive parallelism.\n\nAccording to DeLanda, the Prussian Army was thus Jominian, that it favored centralized command of the battlefield and the conduct of military affairs over diplomacy and politics. He opposes Clausewitz's classic theory exposed in \"On War\" (1832) of the primacy of politics over warfare (if strategy is the art of assembling battles, politics is the art of making sense of victories). Although DeLanda did not quote Sun Tzu, his use of Clausewitz recalls the Sun's counsels on the way to avoid wars as being the most effective warfare: one may be sure he won the war when the war didn't happen. DeLanda claims that this Jominian theory influenced Prussian militarism, the RAND Corporation and current Pentagon policies concerning research and development. This centralization always aims at taking out humans from the decision-making loop and is therefore closely linked to the evolution of technology — although a major thesis of DeLanda's book is that evolution of technology is neither good or bad, as technophiles and technophobes hope or fear. It may be used to keep the human will out of the loop or prioritize cooperative behavior and decentralization: the classic example used is the hackers' re-appropriation of the military ARPANET in the early ages of the Internet.\n\nThus, the Schlieffen Plan, formulated by the German general staff after the 1870–71 Franco-Prussian war, is a good example of centralized war planning and of Jominian theory: everything was so rigidly planned that there was almost zero ability to adapt for sudden changes. When World War I started in August 1914, the military told the emperor that they could do nothing but invade France, although the emperor changed his mind, hoping that if he didn't invade France, Great Britain wouldn't enter the war (in virtue of the 1904 \"Entente cordiale\" agreement). But the plan was too rigid and didn't allow for modification, thus potentially becoming one of the indirect causes of the war (although it surely wasn't the only one: DeLanda, who begins his book quoting Fernand Braudel, doesn't believe in unicausality or determinism).\n\nDeLanda also shows how wargaming, invented in the early 19th century by Prussians under the name of \"Kriegsspiel\", has been used since that time for simulation of battles, in particular by the general staff, which may be considered the \"institutionalized brain\" of the armed forces — until their substitution by think tanks, the first one being the RAND Corporation, charged with the elaboration of science policy in the frame of the military-industrial complex. Frederick the Great was fascinated with automatons, as Foucault has shown and with miniature wargames. 19th century wargaming models, which benefited from progress in cartography, was dependent on dice at the beginning to represent the effects of chaos. Eventually, these irrational conditions were taken out of the loop, as well as human will: current military wargames oppose computers, not human beings. It was shown during the nuclear arms race that human beings refused in game models to cross the threshold and press the red button, which convinced military programmers to take out human players.\n\nDeLanda distinguishes various \"ages\" of war machines (although they probably don't succeed each other in a simple way; Foucault and Deleuze likewise cast in doubt such historical linear succession); he also defines various \"levels\" of war machines (tactics, strategy and logistics, which necessarily involve politics).\n\nHenceforth, describing the passage from the \"clockwork paradigm\" to the \"motor paradigm\", he quotes Michel Serres's studies to demonstrate how this new paradigm led to the creation of an \"abstract motor\" composed of three components: a reservoir (steam in the case of the steam engine), a form of exploitable difference (heat/cold) and a \"diagram\" or \"program\" for the exploitation of (thermal) differences. Michel Serres thus mentioned Darwin, Marx and Freud as examples in the area of scientific discourse,\n\n\"reservoirs of population, of capital or of unconscious desires, put to work by the use of differences of fitness, class or sex, each following a procedure directing the circulation of naturally selected species, or commodities and labor, or symptoms and fantasies...\"|Serres (p.141)\n\nThus, Napoleon's armies, born from the 1789 French Revolution, marked a new threshold of the machinic phylum or singularities or bifurcation: emergent properties are displayed in this \"evolution\" from the \"clockwork paradigm\" to the \"motor paradigm\". This evolution is not merely technological; it is not so much the invention of the steam engine — the first type of motor — that determines this \"evolution\". The first steam engine was invented through tinkering and can thus not be said to be the consequences of a \"paradigm shift\" as Thomas Kuhn would conceive it. There is no necessary pre-eminence of science over technology (nor the reverse). De Landa thus explains that the \"abstract motor\" is more important than the \"concrete motor\", taking as his example the dazzling victories during the Napoleonic Wars,\n\nNapoleon's true innovation was not in the implementation of the motor invention — he rejected the use of steamboats — but his use of the pool of energy formed by patriotism, itself fuelled by the French Revolution. This high morale made conscription possible; it also allowed more local initiative by and decentralization of the army, since French commanders didn't dread, as did their counterparts, endless cases of desertions if they allowed small groups of soldiers to take over specific missions.\n\nDeLanda also notes how John von Neumann was hired by the RAND Corporation to improve war exercises, which he did by devising game theory, which helped The Pentagon think about nuclear strategy. In particular, game theory was used to represent the Cold War dualism conflict as an instantiation of the Prisoner's dilemma. Since the zero-sum fallacy wasn't yet thought, this led to systemic bias in favor of conflict against cooperative games, according to de Landa. Thus, the massive retaliation nuclear strategy was chosen, although nuclear disarmament would have been, in a more realistic win-win game, the best solution. The Turing machines were also perfect \"abstract machines\" which would be implemented in concrete machines only later.\n\n\n"}
{"id": "39790406", "url": "https://en.wikipedia.org/wiki?curid=39790406", "title": "Warwick Anderson", "text": "Warwick Anderson\n\nWarwick Hugh Anderson (born 10 December 1958), medical doctor, poet, and historian, is Janet Dora Hine Professor of Politics, Governance and Ethics in the Department of History and the Charles Perkins Centre, University of Sydney, where he was previously an Australian Research Council Laureate Fellow (2012-17). He is also honorary professor in the School of Population and Global Health, University of Melbourne. He is a fellow of the Australian Academy of the Humanities, the Academy of Social Sciences in Australia, the Australian Academy of Health and Medical Sciences and the Royal Society of New South Wales from which he received the History and Philosophy of Science Medal in 2015. For the 2018-19 academic year, Anderson will be the Gough Whitlam and Malcolm Fraser chair of Australian Studies at Harvard University. As a historian of science and medicine, Anderson focuses on the biomedical dimensions of racial thought, especially in colonial settings, and the globalisation of medicine and science. He has introduced anthropological insights and themes to the history of medicine and science; developed innovative frameworks for the analysis of science and globalisation; and conducted historical research into the material cultures of scientific exchange. His influential formulation of the postcolonial studies of science and medicine has generated a new style of inquiry within science and technology studies.\n\nAnderson was born and educated in Melbourne, Australia, where he attended the University High School. His father, Hugh McDonald Anderson (1927-2017), was a leading folklorist and historian of Australian popular and literary culture, with more than forty books to his credit; his mother, Dawn Anderson, has written books on drama education and creativity.\n\nHe graduated from the University of Melbourne Medical School (M.B., B.S. [equivalent to the US M.D.]) in 1983. During the medical course he conducted neurophysiology research, supervised by Ian Darian-Smith, which earned him the B.Med.Sc. (1980). He was an intern at the Royal Melbourne Hospital, and had paediatric training at the Royal Children's Hospital, Melbourne, and the John Radcliffe Hospital, Oxford. In the 1986 season he was the assistant doctor for the Footscray Football Club (now the AFL Bulldogs). From 1987, he worked in general practice in the inner west of Melbourne, which he continued intermittently until 1999. \nAnderson (\"Dr. Androgen\") was a co-presenter on the award-winning radio program \"Spoonful of Medicine\" (3RRR) from 1987–88.\n\nAs a medical student, Anderson began writing and publishing poetry. More than forty poems have appeared in a range of leading journals in Australia and the US. His poetry collection, \"Hard Cases, Brief Lives\" (Adelaide: Ginninderra, 2011) was short-listed in 2012 for the Mary Gilmore Award of the Association for the Study of Australian Literature (ASAL).\n\nAnderson completed a PhD in the Department of the History and Sociology of Science at the University of Pennsylvania in 1992. His dissertation was on US colonial medicine and public health in the Philippines, and his advisor was Charles E. Rosenberg. Before moving to Sydney, Anderson held appointments at Harvard University (1992–95); the University of Melbourne (1995–2000); UCSF and Berkeley (2000–2003); and the University of Wisconsin-Madison (2003–08). At Melbourne, he founded the Centre for Health and Society (1997) and helped to establish the Onemda VicHealth Koori Health Unit (1998). At Madison, he was chair of the Department of Medical History and Bioethics.\n\nHe was the founding editor of \"Health and History\" (1998), and served as associate editor for the \"East Asian STS Journal\" and \"Postcolonial Studies\". He served on the councils of the American Association of the History of Medicine (AAHM), the Australian and New Zealand Society for the History of Medicine, the Australian Society of Health, Law and Ethics, History of Medicine in Southeast Asia (HOMSEA), the Institute of Postcolonial Studies (Melbourne), and the Pacific Circle.\n\nAnderson was awarded a fellowship from the John Simon Guggenheim Foundation (2007–08), and he was a Frederick Burkhardt Fellow of the American Council of Learned Societies (2005–06), which he held at the Institute for Advanced Study, Princeton. In 2013 he was a Whitney J. Oates Fellow at the Humanities Council, Princeton University and a John Hope Franklin Fellow at Duke University.\n\nAmong Anderson's key publications are:\nAdditionally he is the author of more than 60 articles and book chapters.\n\nAnderson has published a number of manifestos for postcolonial approaches to explaining the globalisation of science and medicine, including: \n\nIn 2011, the Australian Research Council (ARC) awarded Anderson a Laureate Fellowship, making him the first historian to receive this award and the only applicant from the humanities to receive a fellowship in the initial round. The fellowship supported comparative, transnational research in the history of ideas of race and human difference in the Global South. These studies involved collaborators from Brazil, New Zealand, and South Africa, and over the course of the fellowship supported six post-doctoral fellows.\n"}
{"id": "2113849", "url": "https://en.wikipedia.org/wiki?curid=2113849", "title": "Wilson cycle", "text": "Wilson cycle\n\nThe Wilson cycle is a model where a continent rifts, forms an ocean basin in-between, and then begins a process of convergence that leads to the collision of the two plates and closure of the ocean. The model is named after its originator John Tuzo Wilson. It has been suggested that Wilson cycles on Earth started about 3 Ga (3 billion years) ago in the Archean Eon of Earth's history.\n\nA Wilson cycle is not the same as a supercontinent cycle, which is the break-up of one supercontinent and the development of another and takes place on a global scale. The Wilson cycle rarely synchronizes with the timing of a supercontinent cycle. However, supercontinent cycles and Wilson cycles were both involved in the creation of Pangaea and Rodinia.\n"}
