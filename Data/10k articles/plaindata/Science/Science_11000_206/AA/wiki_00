{"id": "4698226", "url": "https://en.wikipedia.org/wiki?curid=4698226", "title": "Abell 400", "text": "Abell 400\n\nAbell 400 is a galaxy cluster which contains the galaxy NGC 1128 with two supermassive black holes (3C 75) spiraling towards merger.\n\nThese two supermassive black holes are contained in NGC 1128. The galaxy, microwave radio jets, multi-million degree X-ray producing gas and resultant radio source is known as 3C 75. X-ray source 2A 0252+060 (1H 0253+058, XRS 02522+060) may be some additional or other portion of Abell 400.\n\nThe black holes are an estimated 25,000 light years apart, and thus will take millions of years to collide. Should the two supermassive black holes merge, they will form a single super-supermassive black hole.\n\n\n"}
{"id": "1134", "url": "https://en.wikipedia.org/wiki?curid=1134", "title": "Analysis", "text": "Analysis\n\nAnalysis is the process of breaking a complex topic or substance into smaller parts in order to gain a better understanding of it. The technique has been applied in the study of mathematics and logic since before Aristotle (384–322 B.C.), though \"analysis\" as a formal concept is a relatively recent development.\n\nThe word comes from the Ancient Greek ἀνάλυσις (\"analysis\", \"a breaking up\", from \"ana-\" \"up, throughout\" and \"lysis\" \"a loosening\").\n\nAs a formal concept, the method has variously been ascribed to Alhazen, René Descartes (\"Discourse on the Method\"), and Galileo Galilei. It has also been ascribed to Isaac Newton, in the form of a practical method of physical discovery (which he did not name).\n\nThe field of chemistry uses analysis in at least three ways: to identify the components of a particular chemical compound (qualitative analysis), to identify the proportions of components in a mixture (quantitative analysis), and to break down chemical processes and examine chemical reactions between elements of matter. For an example of its use, analysis of the concentration of elements is important in managing a nuclear reactor, so nuclear scientists will analyse neutron activation to develop discrete measurements within vast samples. A matrix can have a considerable effect on the way a chemical analysis is conducted and the quality of its results. Analysis can be done manually or with a device. Chemical analysis is an important element of national security among the major world powers with materials\n\nChemists can use isotope analysis to assist analysts with issues in anthropology, archeology, food chemistry, forensics, geology, and a host of other questions of physical science. Analysts can discern the origins of natural and man-made isotopes in the study of environmental radioactivity.\n\n\n\n\nAnalysts in the field of engineering look at requirements, structures, mechanisms, systems and dimensions. Electrical engineers analyse systems in electronics. Life cycles and system failures are broken down and studied by engineers. It is also looking at different factors incorporated within the design.\n\nThe field of intelligence employs analysts to break down and understand a wide array of questions. Intelligence agencies may use heuristics, inductive and deductive reasoning, social network analysis, dynamic network analysis, link analysis, and brainstorming to sort through problems they face. Military intelligence may explore issues through the use of game theory, Red Teaming, and wargaming. Signals intelligence applies cryptanalysis and frequency analysis to break codes and ciphers. Business intelligence applies theories of competitive intelligence analysis and competitor analysis to resolve questions in the marketplace. Law enforcement intelligence applies a number of theories in crime analysis.\n\nLinguistics look at individual languages and language in general. It breaks language down and analyses its component parts: theory, sounds and their meaning, utterance usage, word origins, the history of words, the meaning of words and word combinations, sentence construction, basic construction beyond the sentence level, stylistics, and conversation. It examines the above using statistics and modeling, and semantics. It analyses language in context of anthropology, biology, evolution, geography, history, neurology, psychology, and sociology. It also takes the applied approach, looking at individual language development and clinical issues.\n\nLiterary criticism is the analysis of literature. The focus can be as diverse as the analysis of Homer or Freud. While not all literary-critical methods are primarily analytical in nature, the main approach to the teaching of literature in the west since the mid-twentieth century, literary formal analysis or close reading, is. This method, rooted in the academic movement labelled The New Criticism, approaches texts – chiefly short poems such as sonnets, which by virtue of their small size and significant complexity lend themselves well to this type of analysis – as units of discourse that can be understood in themselves, without reference to biographical or historical frameworks. This method of analysis breaks up the text linguistically in a study of prosody (the formal analysis of meter) and phonic effects such as alliteration and rhyme, and cognitively in examination of the interplay of syntactic structures, figurative language, and other elements of the poem that work to produce its larger effects.\n\nModern mathematical analysis is the study of infinite processes. It is the branch of mathematics that includes calculus. It can be applied in the study of classical concepts of mathematics, such as real numbers, complex variables, trigonometric functions, and algorithms, or of non-classical concepts like constructivism, harmonics, infinity, and vectors.\n\nFlorian Cajori explains in (1893) the difference between modern and ancient mathematical analysis, as distinct from logical analysis, as follows:\n\nThe terms \"synthesis\" and \"analysis\" are used in mathematics in a more special sense than in logic. In ancient mathematics they had a different meaning from what they now have. The oldest definition of mathematical analysis as opposed to synthesis is that given in [appended to] Euclid, XIII. 5, which in all probability was framed by Eudoxus: \"Analysis is the obtaining of the thing sought by assuming it and so reasoning up to an admitted truth; synthesis is the obtaining of the thing sought by reasoning up to the inference and proof of it.\" \n\nThe analytic method is not conclusive, unless all operations involved in it are known to be reversible. To remove all doubt, the Greeks, as a rule, added to the analytic process a synthetic one, consisting of a reversion of all operations occurring in the analysis. Thus the aim of analysis was to aid in the discovery of synthetic proofs or solutions.\nJames Gow uses a similar argument as Cajori, with the following clarification, in his \"A Short History of Greek Mathematics\" (1884):\nThe synthetic proof proceeds by shewing that the proposed new truth involves certain admitted truths. An analytic proof begins by an assumption, upon which a synthetic reasoning is founded. The Greeks distinguished \"theoretic\" from \"problematic\" analysis. A theoretic analysis is of the following kind. To \"prove\" that A is B, \"assume\" first that A is B. If so, then, since B is C and C is D and D is E, therefore A is E. If this be known a falsity, A is not B. But if this be a known truth and all the intermediate propositions be convertible, then the reverse process, A is E, E is D, D is C, C is B, therefore A is B, constitutes a synthetic proof of the original theorem. Problematic analysis is applied in all cases where it is proposed to construct a figure which is assumed to satisfy a given condition. The problem is then converted into some theorem which is involved in the condition and which is proved synthetically, and the steps of this synthetic proof taken backwards are a synthetic solution of the problem.\n\n\n\n\n\nIn statistics, the term \"analysis\" may refer to any method used\nfor data analysis. Among the many such methods, some are:\n\n\n\n"}
{"id": "18015419", "url": "https://en.wikipedia.org/wiki?curid=18015419", "title": "Antonio Krapovickas", "text": "Antonio Krapovickas\n\nAntonio Krapovickas (8 October 1921 – 17 August 2015) was an Argentine agronomist.\n\nKrapovickas received a degree in 1948 in agronomic engineering from the University of Buenos Aires and began teaching in 1949 as Professor of Genetics and Systems Botany at the University of Córdoba. He later became Professor of Plant Anatomy at the National University of Tucumán.\n\nIn 1964, he moved to Corrientes to accept a position at the National University of the Northeast (UNNE), becoming Chair of its Department of Botany and Ecology in 1977. He also founded the university's botanical gardens, or \"Ibone\", with his wife, Dr. Carmen L. Cristóbal.\n\nKrapovickas' research centered on taxonomy of the Malvaceae family and biology of species in the genus \"Arachis\" (Fabaceae). His publications in these fields, including over 110 papers, 8 book chapters, and a monograph on \"Arachis\" - the genus of the groundnut - that he coauthored with Walton C. Gregory, are very influential and widely cited.\n\n\n"}
{"id": "36758008", "url": "https://en.wikipedia.org/wiki?curid=36758008", "title": "British Bryological Society", "text": "British Bryological Society\n\nThe British Bryological Society is an academic society dedicated to bryology, which encourages the study of bryophytes – mosses and liverworts. It publishes the peer-reviewed \"Journal of Bryology\".\n"}
{"id": "5816780", "url": "https://en.wikipedia.org/wiki?curid=5816780", "title": "Buran (spacecraft)", "text": "Buran (spacecraft)\n\nBuran (, , meaning \"Snowstorm\" or \"Blizzard\"; GRAU index serial number: \"11F35 K1\") was the first spaceplane to be produced as part of the Soviet/Russian Buran programme. It is, depending on the source, also known as \"OK-1K1\", \"Orbiter K1\", \"OK 1.01\" or \"Shuttle 1.01\". Besides describing the first operational Soviet/Russian shuttle orbiter, \"Buran\" was also the designation for the whole Soviet/Russian spaceplane project and its orbiters, which were known as \"\"Buran\"-class spaceplanes\".\n\nOK-1K1 completed one unmanned spaceflight in 1988, and was destroyed in 2002 when the hangar it was stored in collapsed. It remains the only Soviet reusable spacecraft to be launched into space. The \"Buran\"-class orbiters used the expendable Energia rocket, a class of super heavy-lift launch vehicle.\n\nThe construction of the \"Buran\"-class space shuttle orbiters began in 1980, and by 1984 the first full-scale orbiter was rolled out. Construction of a second orbiter (OK-1K2, informally known as \"Ptichka\") started in 1988. The \"Buran\" programme ended in 1993.\n\nThe only orbital launch of a \"Buran\"-class orbiter occurred at 03:00:02 UTC on 15 November 1988 from Baikonur Cosmodrome launch pad 110/37. \"Buran\" was lifted into space, on an unmanned mission, by the specially designed Energia rocket. The automated launch sequence performed as specified, and the Energia rocket lifted the vehicle into a temporary orbit before the orbiter separated as programmed. After boosting itself to a higher orbit and completing two orbits around the Earth, the ODU (, сombined propulsion system) engines fired automatically to begin the descent into the atmosphere, return to the launch site, and horizontal landing on a runway.\n\nAfter making an automated approach to Site 251 (known as Yubileyniy Airfield), \"Buran\" touched down under its own control at 06:24:42 UTC and came to a stop at 06:25:24, 206 minutes after launch. Despite a lateral wind speed of , \"Buran\" landed only laterally and longitudinally from the target mark. It was the first space shuttle to perform an unmanned flight, including landing in fully automatic mode. It was later found that \"Buran\" had lost only eight of its 38,000 thermal tiles over the course of its flight.\n\nIn 1989, it was projected that OK-1K1 would have an unmanned second flight by 1993, with a duration of 15–20 days. Although the Buran programme was never officially cancelled, the dissolution of the Soviet Union led to funding drying up and this never took place.\n\nIn June 1989, \"Buran\" was carried on the back of the Antonov An-225 and took part in the 1989 Paris Air Show.\nIn 1990, it appeared at the Farnborough Airshow. Another flight of the spacecraft did not occur as together with the Energia carrier it was later put in a hangar at the Baikonur Cosmodrome, Kazakhstan.\n\nOn 12 May 2002, during a severe storm at the Baikonur Cosmodrome in Kazakhstan, the MIK 112 hangar housing OK-1K1 collapsed as a result of poor maintenance. The collapse killed eight workers and destroyed the craft as well as an Energia carrier rocket.\n\n\n\n"}
{"id": "11268399", "url": "https://en.wikipedia.org/wiki?curid=11268399", "title": "Centre de données astronomiques de Strasbourg", "text": "Centre de données astronomiques de Strasbourg\n\nThe Centre de Données astronomiques de Strasbourg (CDS; English translation: \"Strasbourg Astronomical Data Center\") is a data hub which collects and distributes astronomical information. It was established in 1972 under the name \"Centre de Données Stellaires\". The on-line services currently provided by the CDS include:\n\n"}
{"id": "54111445", "url": "https://en.wikipedia.org/wiki?curid=54111445", "title": "Charles Clifton Brittlebank", "text": "Charles Clifton Brittlebank\n\nCharles Clifton Brittlebank (1 Jan 1863 - 3 Nov 1945) was an Australian plant pathologist, mycologist (fungi specialist), scientific illustrator, university lecturer and farmer (near Bacchus Marsh, Victoria). In all of his endeavours he became outstanding in his field, gaining international acclaim for his discoveries and publications. In February 1992 he was officially commemorated by the naming of the road Brittlebank Circuit, in the suburb of Banks, in Canberra, Australian Capital Territory.\n\nFrom 17th to 19th centuries the Brittlebank family was well-established in Wirksworth, in the Peak District of Derbyshire in England. The family prospered as (amongst other things) members of the legal profession and owners of lead mines. In 1700 Hugh Brittlebank (1675-1764) moved from Wirksworth to the village at the centre of lead mining, Winster, becoming the owner of the substantial manor house and grounds, Oddo House.\n\nHugh Brittlebank's family came to own most of the village of Winster. They were at the centre of dramatic events in 1821 when they seem to have overstepped the mark, as the \"Times (London, England)\" reported on 2 June 1821: three of Hugh's great-great-grandsons forced a local doctor, William Cuddie, into a duel at which he was mortally wounded. The shooter, William Brittlebank, then disappeared completely. The other two brothers involved, Andrew and Francis, were tried for murder but were acquitted, in August 1821.\n\nA fourth brother, not involved in the duel, was Thomas Brittlebank (1797-1838) whose son, Andrew William Thomas Brittlebank (1838-1877), was recorded in the 1871 England Census as having moved away from the traditional family village of Winster to a small seaside village, Hornsea, in the neighbouring county of Yorkshire. He was accompanied by his wife Ellen Sarah Leese (1837-1906), his mother-in-law Mary Leese (1805-1877), and three sons: Lewis Oswald (1861-1877), Charles Clifton (1863-1945) and Thomas Andrew (1865-1948). The head of the house was not employed - he enjoyed a private income derived from his investments.\n\nAndrew WT Brittlebank took his wife and children overseas, spending two years in Vanuatu (known then as the Spanish East Indies, and later as the New Hebrides), before going to Brisbane, Queensland, Australia, where the passenger list of the ship \"Sam Mendel\" records their arrival on 28 July 1875 \n\nIn 1876 and 1877 \"The Brisbane Courier\" frequently reported local waves of epidemics such as smallpox, malaria and influenza. In March and April 1877 Andrew WT Brittlebank and his eldest son, Lewis Oswald, both died and were buried in the South Brisbane Cemetery in Plot 11a, graves 268 and 269. Administrative procedures appear to have taken two years, for the \"Brisbane Telegraph\" reported, on Friday 14 March 1879, page 3, that \"his widow Ellen S. Brittlebank was appointed guardian of the persons and the estates of Charles Clifton Brittlebank and Thomas Andrew Brittlebank\".\n\nThe family then went south to the island of Tasmania. However, they did not remain in Tasmania, but returned to the mainland and finally put down roots in Myrniong, near Bacchus Marsh, in the state of Victoria. The \"Bacchus Marsh Express\", 28 November 1885, page 2, announced that a mixed farm of 363 acres (approximately 150 hectares) was up for lease, after the death of the owner, William Dunbar in July 1884. It appears that the Brittlebanks took the lease, because the \"Bacchus Marsh Express\" reported in 1888 that the two brothers were the owners: The Messrs. Brittlebank, the present owners of Dunbar's farm, have done excellent work, and have almost entirely eradicated the rabbits from their property. They have also erected a quantity of wire net fence. - \"Bacchus Marsh Express\", 17 Nov 1888, p.3.\n\nThroughout their lives, the work of the brothers Charles and Thomas, whether joint or individual, contributed significantly to the dissemination of new knowledge of Australian plants, animals and geology. The \"Victorian Naturalist\" summarized their contribution as follows:\n\nThe brothers remained at Myrniong until 1910 after which the Australian Electoral Rolls show that Charles and family moved to Caulfield near Melbourne, whilst Thomas took up a position as the manager of the Agricultural High School Farm, in Sale, Gippsland and, later, the Agricultural High School Farm in Warnambool.\n\nCharles Clifton Brittlebank and Sarah Jane Palmer (1861-1935) were married on 1 August 1894, in St Matthew's Church in Kensington, Victoria.\n\nThey had only one child, Cyril Clifton, born in Myrniong in 1895. When World War I occurred he enlisted in Australian 13th Light Horse Regiment in May 1915. After fighting at Gallipoli and on many of the battlefields on the Western Front, and having survived typhoid and various wounds, he died of influenza on 25 May 1918. He was buried in Etretat Cemetery, Le Havre, Haute-Normandie, France. His grave is listed on the Etretat Churchyard Extension web site .\n\nA couple of months before the wedding of Charles and Sarah, Brittlebank's brother Thomas Andrew had married Marion Margaret Myers (1869-1932), on 10 June 1894. They had three children.\n\nTheir eldest son, Andrew Buxton Brittlebank was born 10 February 1895. Like his cousin Cyril, he enlisted in 1915, as reported in the \"Melton Express\" on 19 June 1915, page 3. He became a corporal in Australian 59th Battalion, was repeatedly wounded, and died of pneumonia on 15 Oct 1917. He was buried in Aeroplane Cemetery, Ypres, Flanders, Belgium, and is listed on the cemetery's web site .\n\nAs described on the history page of the Shrine's web site the Shrine of Remembrance in Melbourne, Victoria was originally erected to commemorate the 19,000 Victorian victims of World War I who, like the Brittlebank cousins, were buried overseas leaving their Australian families without graves at which to mourn.\n\nThe name Buxton was the maiden name of Andrew William Thomas Brittlebank's maternal grandmother, Margaret Buxton (1779-1820) who lived in Thorpe, Derbyshire, England. Furthermore, Buxton was also the name of one of the most important towns in the Peak District of Derbyshire. Thus the name may have held sentimental value for the expatriate Thomas Andrew Brittlebank who had been brought to Australia as a child. He and his wife Marion gave each of their children the middle name of Buxton: Andrew (1895-1917), Olive (1897-1984) and Tom (1899-1966).\n\nThe value of Charles Clifton Brittlebank's work can be appreciated from the excitement generated by the announcement of a discovery reported on 29 September 2013, on \"The Age\" web site : Researchers have found \"the holy grail of entomology\" - a long-lost guide to Victoria's insects written by pioneer researcher Charles French.\n\nThe handwritten manuscript, beautifully illustrated with artwork by Charles Brittlebank and LC Vald Anderson, describes the state's bug life before insecticides were used. - Bridie Smith, \"The Age\", 29 September 2013.\n\nRecognition for his many and varied accomplishments in the field of natural history came to Brittlebank long before his official appointment as Government Plant Pathologist. Some of the significant milestones of his scientific life include the following:\n\n\nCharles Brittlebank's brother Thomas lost his wife, Marion, in July 1932, and Charles himself became widowed in 1935 when Sarah died. After that time the brothers both lived at No. 48 York Street, Caulfield, near Melbourne.\n\nCharles pre-deceased his younger brother by three years, dying in 1945, aged 83. He is buried in the family grave in the Maddingley Central Cemetery, in Bacchus Marsh, Victoria. The cemetery has been in use since the 1860s. The Brittlebank grave also holds four other relatives of Charles, as follows:\n\n\nAn insight into his character is found in the tribute to him from his colleague and successor Stanislaus Fish: I worked with him for 3 years before he retired as a plant pathologist, [he was also an] artist, naturalist, successful farmer, professional boxer, and no mean golfer - an unforgettable character. - S. Fish, \"Annual Revue of Phytopathology\", 1970.\n\nRegret at the loss of a good friend, and appreciation for his contribution to science are also evident in other obituaries, such as that in \"Wild Life\" and in the \"Victorian Naturalist\":\n\nA sample of the scholarly works by CC Brittlebank (solo and in collaboration) includes the following, listed chronologically by date of publication:\n\n\n\n"}
{"id": "48868043", "url": "https://en.wikipedia.org/wiki?curid=48868043", "title": "Colored coin", "text": "Colored coin\n\nColored coins are a class of methods for associating real world assets with addresses on the bitcoin network. Examples could be a deed for a house, stocks, bonds or futures. The technology could also be used to track and register intellectual property assets.\n\nThrough 2014/15 it was suggested that various coloured coin protocols could be of interest to banks and major financial institutions. This prediction came true in June 2015 when NASDAQ announced they were developing a system in partnership with blockchain startup Chain using the Open Assets protocol developed and utilised by CoinPrism and built on by Get Hashing. In late 2015 NASDAQ announced that the first ever trade had occurred using its new platform, Linq.\n\nThere are several competing implementations of the coloured coins idea, using differing methods, including those developed by CoinSpark, Colu and several built on the EPBOC protocol.\n\nColored Coins was invented by Yoni Assia.\n\n\n"}
{"id": "50901137", "url": "https://en.wikipedia.org/wiki?curid=50901137", "title": "Daniel Delander", "text": "Daniel Delander\n\nDaniel Delander (died 1733), also known as De Lander or Delaunder, was a notable London clock and watch maker coming from a dynasty of clockmakers.\n\nSuccessor to Nathaniel Delander, Daniel Delander was apprenticed in 1692 to Charles Halstead and, later, to Thomas Tompion; he became a member of the Clockmakers' Company in 1699. He opened his own shop at the Dial in Devereux Court in 1706 and worked there until 1712. Then he relocated to Two Temple Gates where he stayed until 1717, and finally he moved to Fleet Street, where he toiled until his death in 1733. Delander invented the lock spring for securing watch cases and was the first to produce an independent centre seconds stopwatch. Delander also built many mantel clocks and longcase clocks. His son Nathaniel Delander II continued the family tradition.\n\nThere are clocks by Delander at the Science Museum and Guildhall Museum in London and at the Metropolitan Museum of Art in New York City. The British Museum (Ilbert Collection) has the oldest independent-seconds watch, built by Delander in 1720.\n\n"}
{"id": "19805948", "url": "https://en.wikipedia.org/wiki?curid=19805948", "title": "Dark current (chemistry)", "text": "Dark current (chemistry)\n\nIn analytical chemistry, dark current refers to the constant response produced by a spectrochemical receptor, even in the absence of radiation. This response adds to the signal produced when the receptor is used to measure light and so must be dealt with to determine how much of the detector response is actually due to the radiation. To compensate for this extra signal, the dark current may be measured in the absence of radiation and then subtracted from the final signal or reduced to zero by a compensating circuit. Dealing with dark current is a form of blank correction.\n"}
{"id": "2103729", "url": "https://en.wikipedia.org/wiki?curid=2103729", "title": "Duban (crater)", "text": "Duban (crater)\n\nDuban is a crater in the northern hemisphere of Saturn's moon Enceladus. Duban was first seen in \"Voyager 2\" images, though the crater has also been seen in much higher resolution \"Cassini\" images. It is located at and is 19 kilometers across. In the \"Cassini\" image, evidence for significant tectonic deformation can be seen along the northwest rim of the crater. \n\nDuban is named after a sage who cured King Yunan of leprosy in \"Arabian Nights\".\n"}
{"id": "8526759", "url": "https://en.wikipedia.org/wiki?curid=8526759", "title": "Eco-innovation", "text": "Eco-innovation\n\nEco-innovation is the development of products and processes that contribute to sustainable development, applying the commercial application of knowledge to elicit direct or indirect ecological improvements. This includes a range of related ideas, from environmentally friendly technological advances to socially acceptable innovative paths towards sustainability. The field of research that seeks to explain how, why, and at what rate new \"ecological\" ideas and technology spread is called eco-innovation diffusion.\n\nThe idea of eco-innovation is fairly recent. One of the first appearances of the concept of eco-innovation in the literature is in the book by Claude Fussler and Peter James. In a subsequent article, Peter James defines eco-innovation as \"new products and processes which provide customer and business value but significantly decrease environmental impacts\". Klaus Rennings introduces the term eco-innovation addressing explicitly three kinds of changes towards sustainable development: technological, social and institutional innovation.\n\nEco-innovation is closely linked to a variety of related concepts. It is often used interchangeably with \"environmental innovation\", and is also often linked with environmental technology, eco-efficiency, eco-design, environmental design, sustainable design, or sustainable innovation. While the term \"environmental innovation\" is used in similar contexts to \"eco-innovation\", the other terms are mostly used when referring to product or process design, and therefore focus more on the technological aspects of eco-innovation rather than the societal or political aspects. Ecovation is the process by which responsible capitalism aligns with ecological innovation to construct products which have a generative nature and are recyclable back into the environment for usage in other industries.\n\nThe most common usage of the term \"eco-innovation\" is to refer to innovative products and processes that reduce environmental impacts. This is often used in conjunction with eco-efficiency and eco-design. Leaders in many industries have been developing innovative technologies in order to work towards sustainability. However, these are not always practical, or enforced by policy and legislation.\n\nAnother position held (for example, by the organisation Eco Innovation) is that this definition should be complemented: eco-innovations should also bring greater social and cultural acceptance. In this view, this \"social pillar\" added to James's definition is necessary because it determines learning and the effectiveness of eco-innovations. This approach gives eco-innovations a social component, a status that is more than a new type of commodity, or a new sector, even though environmental technology and eco-innovation are associated with the emergence of new economic activities or even branches (e.g., waste treatment, recycling, etc.). This approach considers eco-innovation in terms of usage rather than merely in terms of product. The social pillar associated with eco-innovation introduces a governance component that makes eco-innovation a more integrated tool for sustainable development.\n\nLiterature in the field of eco-innovations often focuses on policy, regulations, technology, market and firm specific factors rather than diffusion. However, understanding of diffusion of eco-innovations recently has gained more importance given the fact that some eco-innovations are already at a mature stage. Survey research shows that most customers hold positive attitudes towards various types of eco-innovations. At the same time, adoption rates of solutions such as dynamic electricity tariffs remain unsatisfactorily low. The \"Not In My Back Yard\" (NIMBY) concept is often used to describe what at first seems to be a confusing intention-behavior gap between high levels of public support for eco-innovations and frequent non-engagement or even local hostility towards specific project proposals. Social psychology and economic behavior models could and should be used to overcome these challenges.\n\n\n"}
{"id": "43021100", "url": "https://en.wikipedia.org/wiki?curid=43021100", "title": "Electrostatic–pneumatic activation", "text": "Electrostatic–pneumatic activation\n\nElectrostatic–pneumatic activation is an actuation method for shaping thin membranes for MEMS and MOEMS devices. This method benefits from operation at high speed and low power consumption. It can also cause large deflection on thin membranes. Electrostatic-pneumatic MEMS devices usually consist of two membranes with a sealed cavity in between. One membrane calling actuator deflects into cavity by electrostatic pressure to compress air and increase air pressure. Elevated pressure pushes the other membrane and cause dome shape. With direct electrostatic actuation on membrane, a concave shape is achieved.\n\nThis method is used in MEMS deformable mirrors\n\nMoreover, mechanical advantage is possible by use of electrostatic-pneumatic actuation. Since the cavity is filled with air, mechanical amplification is lower than hydraulic machinery with a non-compressible fluid.\n"}
{"id": "26774614", "url": "https://en.wikipedia.org/wiki?curid=26774614", "title": "European Pulsar Timing Array", "text": "European Pulsar Timing Array\n\nThe European Pulsar Timing Array (EPTA) is a European collaboration to combine five 100-m class radio-telescopes to observe an array of pulsars with the specific goal of detecting gravitational waves. It is one of three pulsar timing array projects in operation, the others being the Parkes Pulsar Timing Array and the North American Nanohertz Observatory for Gravitational Waves.\n\nPulsars are rapidly rotating, highly magnetised neutron stars that emit radio waves from their magnetic poles that are, due to the star's rotation, observed on Earth as a string of pulses. Due to the extremely high density of neutron stars, their rotation periods are very stable, hence the observed arrival time of the pulses are highly regular. These arrival times are called TOAs (time of arrival) and can be used to perform high-precision timing experiments.\n\nThe stability of the TOAs from most pulsars is limited due to the presence of red noise, also called \"timing noise\". However, there is a special class of pulsars, called millisecond pulsars (MSP), that are shown to suffer from little or no timing noise. Keeping track of the TOAs of different MSPs over the sky allows for a high-precision timing experiment to detect gravitational waves.\n\nGravitational waves (GW) are small disturbances in space-time, caused by the motion of masses, if the third time derivative of the mass quadrupole moment is non-zero. These waves are very weak, such that only the strongest waves, caused by the rapid motion of dense stars or black-holes, have a chance of being detected. A pulsar timing array (PTA) uses an array of MSPs as the endpoints of a Galaxy-scale GW detector. It is sensitive to GWs with a frequency in the nanohertz regime, which corresponds to the regime where the stochastic GW background, caused by the coalescence of super-massive black holes in the early Universe, is predicted to exist. This makes PTAs complementary to other GW detectors such as LIGO, VIRGO and LISA.\n\nThe EPTA uses five European telescopes. These are the Westerbork Synthesis Radio Telescope, the Effelsberg Radio Telescope, the Lovell Telescope, the Nançay Radio Telescope and the Sardinia Radio Telescope.\n\nSince 2009, the EPTA has made some progress thanks to a project European Research Council funded project known as the Large European Array for Pulsars (LEAP). The aim of this project is to coherently combine the five EPTA telescopes to synthesise the equivalent of a fully steerable 194-m dish. This will improve the accuracy with which the pulsar TOAs can be measured by an order of magnitude, essential for the first detection of gravitational waves within the next decade.\n\n"}
{"id": "778246", "url": "https://en.wikipedia.org/wiki?curid=778246", "title": "Flora", "text": "Flora\n\nFlora is the plant life occurring in a particular region or time, generally the naturally occurring or indigenous—native plant life. The corresponding term for animal life is fauna. \"Flora\", \"fauna\" and other forms of life such as fungi are collectively referred to as biota. Sometimes bacteria and fungi are also referred to as flora, as in the terms gut flora or skin flora.\n\nThe word \"flora\" comes from the Latin name of Flora, the goddess of plants, flowers, and fertility in Roman mythology.\n\nThe distinction between vegetation (the general appearance of a community) and flora (the taxonomic composition of a community) was first made by Jules Thurmann (1849). Prior to this, the two terms were used indiscriminately.\n\nPlants are grouped into floras based on region (floristic regions), period, special environment, or climate. Regions can be distinct habitats like mountain vs. flatland. Floras can mean plant life of a historic era as in \"fossil flora\". Lastly, floras may be subdivided by special environments:\n\n\nThe flora of a particular area or time period can be documented in a publication also known as a \"flora\" (often capitalized as \"Flora\" to distinguish the two meanings when they might be confused). Floras may require specialist botanical knowledge to use with any effectiveness. Traditionally they are books, but some are now published on CD-ROM or websites.\n\nIt is said that the \"Flora Sinensis\" by the Polish Jesuit Michał Boym was the first book that used the name \"Flora\" in this meaning, a book covering the plant world of a region. However, despite its title it covered not only plants, but also some animals of the region.\n\nA published flora often contains diagnostic keys. Often these are \"dichotomous\" keys, which require the user to repeatedly examine a plant, and decide which one of two alternatives given best applies to the plant.\n\n\n\n"}
{"id": "14854332", "url": "https://en.wikipedia.org/wiki?curid=14854332", "title": "From Black Power to Hip Hop", "text": "From Black Power to Hip Hop\n\nFrom Black Power to Hip-Hop: Racism, Nationalism, and Feminism is the title of a non-fiction book written by Patricia Hill Collins. Published in 2006 by Temple University Press, the book analyzes issues as diverse as family planning, Afrocentrism, and the role of African-American women in the hip-hop movement.\n\nThe book is divided into three parts:\n\nEach section has two long essays with the fifth essay totalling thirty-eight pages.\n\n\n"}
{"id": "57061920", "url": "https://en.wikipedia.org/wiki?curid=57061920", "title": "George Alexander Ehrman", "text": "George Alexander Ehrman\n\nGeorge Alexander Ehrman (2 February 1862,Pittsburgh- 30 January, 1926,Pittsburgh) was an American entomologist who specialised in Lepidoptera notably Papilionidae.\n\nEhrman invented equipment which came into general use in the manufacture of blown and pressed glass for the Macbeth-Evans Glass Company and the United States Glass Company. In later years he was employed in the Research Laboratory of the Mesta Machine Company.\n\nFinancially secure Ehrman was able during his later life to devote himself to natural history including ornithology. He made extensive collections of the Lepidoptera and Coleoptera of western Pennsylvania then extended his \ncollections worldwide. He specialised in Papilionidae, the genus \"Catocala\", and the butterflies and moths of \nLiberia, and the beetle genus \"Cychrus\" and its allies.\n\nHis collection of American und exotic Rhopalocera and Coleoptera was bequeathed to the Carnegie Museum of Natural History.The species described by him are listed by Holland (1927) \n\npartial list\n\n\n"}
{"id": "17712747", "url": "https://en.wikipedia.org/wiki?curid=17712747", "title": "Geuda", "text": "Geuda\n\nGeuda (, pronounced gay-yoo-dah) is a form of the mineral corundum, or sapphire, found primarily in Sri Lanka. Around 70%-80% of gems mined in Sri Lanka belong to geuda varieties. Because of its semitransparent and milky appearance due to rutile inclusions, these stones have little value as gemstones in their natural state.\n\nGeuda was frequently stored in large drums or used to gravel home gardens prior to the 1970s discovery that heat treatment can drastically alter the stone's color. \n\nSome geuda varieties turn to a blue color after heat treatments. Others turn to red after oxidizing. Kowangu pushparaga turns to yellow sapphire after oxidizing. After heating geuda to roughly 1800 °C, the aluminium oxide lattice-work of the gem is disrupted and cooling greatly improves both color and clarity. Though many stones are destroyed by the heating and cooling process, those that survive are significantly altered and rival naturally blue sapphires in both appearance and price.\n"}
{"id": "21500178", "url": "https://en.wikipedia.org/wiki?curid=21500178", "title": "Herbert A. Wagner", "text": "Herbert A. Wagner\n\nHerbert Alois Wagner (22 May 1900, Graz, Austria - 28 May 1982 in Newport Beach, California, USA) was an Austrian scientist who developed numerous innovations in the fields of aerodynamics, aircraft structures and guided weapons. He is most famous for Wagner's function describing unsteady lift on wings and developing the Henschel Hs 293 glide bomb.\n\nWagner attended the Austrian Naval Academy from 1914 to 1917 and served as an Ensign in the Austrian Navy during World War I. He survived the sinking of his ship after it was struck by an enemy torpedo. After the war he returned to his studies, earning a doctorate from the Technical University of Berlin when he was only 23. His doctoral thesis entitled \"Origin of the dynamic lift of wings\" contained the solution of one of fundamental unsteady aerodynamics problems concerned with lift force on wings that are suddenly set into motion. The result later became known as \"Wagner's function\".\n\nIn the mid-1920s he worked for Rohrbach Metall-Flugzeugbau on new designs for flying boats. During that time he also invented the so-called \"Wagner beam\", a method of constructing aircraft structural components from sheet metal. Following a short stint as a professor at the Technical University of Berlin, he returned to industry at Junkers Flugzeugwerke, helping to design aircraft and aircraft engines working together with Hans von Ohain. There he played an instrumental role in the development of the first jet engines. He left Junkers following a disagreement with the management, and settled at Henschel Flugzeugwerke in Berlin.\n\nWagner helped the computer pioneer Konrad Zuse as an intermediary concerning orders that Zuse got from the Reich Ministry of Aviation.\n\nWhile at Henschel, Wagner began to study remotely controlled aircraft. In July 1940 he began work on a prototype glide bomb that could be used to attack thinly armored warships and merchant ships. This ultimately evolved into the Hs 293 guided missile, used with considerable effectiveness in late 1943 and early 1944. Several notable successes were achieved, including the first sinking of a ship by a remotely controlled weapon, the destruction of HMS Egret on 27 August 1943. Another notable success for the Hs 293 was the sinking of the transport HMT Rohna with the loss of over 1000 soldiers, sailors and crewmen.\n\nHowever, the Allies developed several electronic countermeasures against the Hs 293 and other radio guides weapons, such as electronic jammers. Those and the increasing Allied air superiority prevented the Hs 293 from having any significant impact in the later war years.\n\nHe also designed the Henschel Hs 117 \"Schmetterling\" surface-to-air guided missile.\n\nAfter the war, Wagner was the first of many German scientists brought to America as part of Operation Paperclip, arriving at Frederick, Maryland on 18 May 1945 with seven large cases of blueprints and other technical data. Wagner and his team were moved to the Special Devices Center, a U.S.-Navy run research unit housed at the Castle Gould and Hempstead House, the former estate of Daniel and Florence Guggenheim at Sands Point, Long Island. There he supported U.S. efforts to deploy glide bombs against Japan.\n\nWagner then moved to the new Naval Air Missile Test Center in Point Mugu, California, the centerpiece of the U.S. Navy's research into guided missiles. There he helped develop the control mechanisms for advanced missiles, several of which remain (in upgraded forms) in service today. A formerly classified FBI counterintelligence report describes his approach to his work:\nAn excellent German scientist of good character and who is not interested in politics... He has given no evidence of being either pro-Nazi or pro-Communist and is disinterested politically... Once belonged to the German SS for a four week’s instruction course but dropped out of same on his own volition... Is an opportunist who is interested only in science and does not subscribe to any political ideology... Since the death of his wife, Wagner has been drinking considerably but is not a drunkard.\nWagner left US government service and formed his own technical consulting firm, HA Wagner Company. He sold this company to Curtiss-Wright in 1957 and returned to Germany to take up a position as professor of Technical Mechanics and Space Technology at the RWTH Aachen. He continued to serve as technical advisor to several U.S. defense companies during this period. Wagner was awarded the Ludwig-Prandtl-Ring from the Deutsche Gesellschaft für Luft- und Raumfahrt (German Society for Aeronautics and Astronautics) for \"outstanding contribution in the field of aerospace engineering\" in 1980. He died aged 82 on 28 May 1982.\n\n"}
{"id": "36920393", "url": "https://en.wikipedia.org/wiki?curid=36920393", "title": "History of experiments", "text": "History of experiments\n\nThe history of experimental research is long and varied. Indeed, the definition of an experiment itself has changed in responses to changing norms and practices within particular fields of study. This article documents the history and development of experimental research from its origins in Galileo's study of gravity into the diversely applied method in use today.\n\nThe Arab physicist Ibn al-Haytham (Alhazen) used experimentation to obtain the results in his \"Book of Optics\" (1021). He combined observations, experiments and rational arguments to support his intromission theory of vision, in which rays of light are emitted from objects rather than from the eyes. He used similar arguments to show that the ancient emission theory of vision supported by Ptolemy and Euclid (in which the eyes emit the rays of light used for seeing), and the ancient intromission theory supported by Aristotle (where objects emit physical particles to the eyes), were both wrong.\n\nExperimental evidence supported most of the propositions in his \"Book of Optics\" and grounded his theories of vision, light and colour, as well as his research in catoptrics and dioptrics. His legacy was elaborated through the 'reforming' of his \"Optics\" by Kamal al-Din al-Farisi (d. c. 1320) in the latter's \"Kitab Tanqih al-Manazir\" (\"The Revision of\" [Ibn al-Haytham's] \"Optics\").\n\nAlhazen viewed his scientific studies as a search for truth: \"Truth is sought for its own sake. And those who are engaged upon the quest for anything for its own sake are not interested in other things. Finding the truth is difficult, and the road to it is rough. ...\n\nAlhazen's work included the conjecture that \"Light travels through transparent bodies in straight lines only\", which he was able to corroborate only after years of effort. He stated, \"[This] is clearly observed in the lights which enter into dark rooms through holes. ... the entering light will be clearly observable in the dust which fills the air.\" He also demonstrated the conjecture by placing a straight stick or a taut thread next to the light beam.\n\nIbn al-Haytham also employed scientific skepticism and emphasized the role of empiricism. He also explained the role of induction in syllogism, and criticized Aristotle for his lack of contribution to the method of induction, which Ibn al-Haytham regarded as superior to syllogism, and he considered induction to be the basic requirement for true scientific research.\n\nSomething like Occam's razor is also present in the \"Book of Optics\". For example, after demonstrating that light is generated by luminous objects and emitted or reflected into the eyes, he states that therefore \"the extramission of [visual] rays is superfluous and useless.\" He may also have been the first scientist to adopt a form of positivism in his approach. He wrote that \"we do not go beyond experience, and we cannot be content to use pure concepts in investigating natural phenomena\", and that the understanding of these cannot be acquired without mathematics. After assuming that light is a material substance, he does not further discuss its nature but confines his investigations to the diffusion and propagation of light. The only properties of light he takes into account are those treatable by geometry and verifiable by experiment.\n\nGalileo Galilei was a scientist who performed many quantitative experiments by addressing many topics. Using several different methods, Galileo was able to accurately measure time. Previously, most scientists had used distance to describe falling bodies using geometry, which had been used and trusted since Euclid. Galileo himself used geometrical methods to express his results. Galileo's successes were aided by the development of a new mathematics as well as cleverly designed experiments and equipment. At that time, another kind of mathematics was being developed—algebra. Algebra allowed arithmetical calculations to become as sophisticated as geometric ones. Algebra also allowed the discoveries of scientists such as Galileo—as well as later scientists like Newton, Maxwell and Einstein—to be later summarized by mathematical equations. These equations described physical relationships in a precise, self-consistent manner.\n\nOne prominent example is the \"ball and ramp experiment.\" In this experiment Galileo used an inclined plane and several steel balls of different weights. With this design, Galileo was able to slow down the falling motion and record, with reasonable accuracy, the times at which a steel ball passed certain markings on a beam. Galileo disproved Aristotle's assertion that weight affects the speed of an object's fall. According to Aristotle's Theory of Falling Bodies, the heavier steel ball would reach the ground before the lighter steel ball. Galileo's hypothesis was that the two balls would reach the ground at the same time.\n\nOther than Galileo, not many people of his day were able to accurately measure short time periods, such as the fall time of an object. Galileo accurately measured these short periods of time by creating a pulsilogon. This was a machine created to measure time using a pendulum. The pendulum was synchronized to the human pulse. He used this to measure the time at which the weighted balls passed marks that he had made on the inclined plane. He measured to find that balls of different weights reached the bottom of the inclined plane at the same time and that the distance traveled was proportional to the square of the elapsed time. Later scientists summarized Galileo's results as The Equation of Falling Bodies.\n\nThese results supported Galileo's hypothesis that objects of different weights, when measured at the same point in their fall, are falling at the same speed because they experience the same gravitational acceleration.\n\nAntoine Lavoisier (1743–1794) was a French chemist regarded as the founder of modern chemistry. Lavoisier's experiments were among the first truly quantitative chemical experiments. He showed that, although matter changes its state in a chemical reaction, the quantity of matter is the same at the end as at the beginning of every chemical reaction. In one experiment, he burned phosphorus and sulfur in air to see whether the results further supported his previous conclusion (Law of Conservation of Mass). In this experiment, however, he determined that the products weighed more than the original phosphorus and sulfur. He decided to do the experiment again. This time he measured the mass of the air surrounding the experiment as well. He discovered that the mass gained in the product was lost from the air. These experiments provided further support for his Law of Conservation of Mass.\n\nOne of Lavoisier's experiments connected the worlds of respiration and combustion. Lavoisier's hypothesis was that combustion and respiration were one and the same, and combustion occurs with every instance of respiration. Lavoisier, working with Pierre-Simon Laplace, designed an ice calorimeter apparatus for measuring the amount of heat given off during combustion or respiration. This machine consisted of three concentric compartments. The center compartment held the source of heat, in this case, the guinea pig or piece of burning charcoal. The middle compartment held a specific amount of ice for the heat source to melt. The outside compartment contained packed snow for insulation. Lavoisier then measured the quantity of carbon dioxide and the quantity of heat produced by confining a live guinea pig in this apparatus. Lavoisier also measured the heat and carbon dioxide produced when burning a piece of charcoal in the calorimeter. Using this data, he concluded that respiration was in fact a slow combustion process. He also discovered through precise measurements that these processes produced carbon dioxide and heat with the same constant of proportionality. He found that for 224 grains of \"fixed air\" (CO) produced, . of ice was melted in the calorimeter. Converting grains to grams and using the energy required to melt . of ice, one can compute that for each gram of CO produced, about 2.02 kcal of energy was produced by the combustion of carbon or by respiration in Lavoisier's calorimeter experiments. This compares well with the modern published heat of combustion for carbon of 2.13 kcal/g. This continuous slow combustion, which Lavoisier and Laplace supposed took place in the lungs, enabled the living animal to maintain its body temperature above that of its surroundings, thus accounting for the puzzling phenomenon of animal heat. Lavoisier concluded, \"Lla respiration est donc une combustion,\" That is, respiratory gas exchange is combustion, like that of burning a candle.\n\nLavoisier was the first to conclude by experiment that the Law of Conservation of Mass applied to chemical change. His hypothesis was that the mass of the reactants would be the same as the mass of the products in a chemical reaction. He experimented on vinous fermentation. He determined the amounts of hydrogen, oxygen, and carbon in sugar. He weighed a quantity of sugar, added yeast and water in measured amounts, and allowed the mixture to ferment. Lavoisier measured the mass of the carbonic acid gas and water that were given off during fermentation and weighed the residual liquor, the components of which were then separated and analyzed to determine their elementary composition. In this way he controlled a couple of potential confounding factors. He was able to capture the carbonic acid gas and water vapor that were given off during fermentation so that his final measurements would be as accurate as possible. Lavoisier then concluded that the total mass of the reactants was equal to the mass of the final product and residue. Moreover, he showed that the total mass of each constituent element before and after the chemical change remained the same. Similarly, he demonstrated via experimentation that the mass of products of combustion is equal to the mass of the reacting ingredients.\n\nThe French biologist Louis Pasteur (1822-1895), regarded as the \"Father of microbiological sciences and immunology\", worked during the 19th century. He postulated - and supported with experimental results - the idea that disease-causing agents do not spontaneously appear but are alive and need the right environment to prosper and multiply. Stemming from this discovery, he used experimentation to develop vaccines for chicken cholera, anthrax and rabies, and to develop methods for reducing bacteria in some food products by heating them (pasteurization). His work also led him to advocate (along with the English physician Dr. Joseph Lister) for antiseptic surgical techniques. Most scientists of that day believed that microscopic life sprang into existence from nonliving matter. This idea was called spontaneous generation.\n\nPasteur's observations of tiny organisms under the microscope caused him to doubt spontaneous generation. He designed an experiment to test it. His hypothesis was that life could not arise from where there is no life. He took care to control possible confounding factors. For example, he needed to make sure there was no life, even microscopic, in the flasks of broth he used as a test medium. He decided to kill any microscopic organisms already present by boiling the broth until he was confident that any microorganisms present were killed. Pasteur also needed to make sure that no microscopic organisms entered the broth after boiling, yet the broth needed exposure to air to properly test the theory. A colleague suggested a flask with a neck the shape of an \"S\" turned sideways. Dust (which Pasteur thought contained microorganisms) would be trapped at the bottom of the first curve, but the air would flow freely through.\n\nThus, if bacteria should really be spontaneously generated, then they should be growing in the flask after a few days. If spontaneous generation did not occur, then the contents of the flasks would remain lifeless. The experiment appeared conclusive: not a single microorganism appeared in the broth. Then Pasteur allowed the dust containing the microorganisms to mix with the broth. In just a few days the broth became cloudy from millions of organisms growing in it. For two more years, he repeated the experiment in various conditions and locales to assure himself that the results were correct. In this way Pasteur supported his hypothesis that spontaneous generation does not occur. Despite the experimental results supporting his hypotheses and his success curing or preventing various diseases, correcting the public misconception of spontaneous generation proved a slow, difficult process.\n\nAs he worked to solve specific problems, Pasteur sometimes revised his ideas in the light of the results of his experiments, as when faced with the task of finding the cause of disease devastating the French silkworm industry in 1865. After a year of diligent work he correctly identified a culprit organism and gave practical advice for developing a healthy population of moths. However, when he tested his own advice, he found disease still present. It turned out he had been correct but incomplete – there were two organisms at work. It took two more years of experimenting to find the complete solution.\n\n\n"}
{"id": "10425807", "url": "https://en.wikipedia.org/wiki?curid=10425807", "title": "Indiana Archives of Cognitive Science", "text": "Indiana Archives of Cognitive Science\n\nThe Indiana Archives of Cognitive Science (IACS) is an online information portal providing information about the field of cognitive science. The purpose of IACS is to promote the study of cognitive science at the undergraduate level. The site provides information about history, current research trends, and career opportunities associated in cognitive science.\n\nThis site is also home to the Indiana Undergraduate Journal of Cognitive Science, an online journal of writing by undergraduate cognitive science students nationwide. Another feature of this website is an extensive listing of cognitive science programs across the nation, research and internship opportunities, a monthly reading list, and other links of interest to cognitive science students.\n\nThe Indiana Archives of Cognitive Science was developed and is maintained by undergraduate students in the Cognitive Science Program at Indiana University.\n\n"}
{"id": "42834", "url": "https://en.wikipedia.org/wiki?curid=42834", "title": "Inessive case", "text": "Inessive case\n\nInessive case (abbreviated ; from Latin \"inesse\" \"to be in or at\") is a locative grammatical case. This case carries the basic meaning of \"in\": for example, \"in the house\" is \"talo·ssa\" in Finnish, \"maja·s\" in Estonian, \"куд·са\" (kud·sa) in Moksha, \"etxea·n\" in Basque, \"nam·e\" in Lithuanian, \"sāt·ā\" in Latgalian and \"ház·ban\" in Hungarian.\n\nIn Finnish the inessive case is typically formed by adding \"ssa/ssä\". Estonian adds \"s\" to the genitive stem. In Moksha, \"са\" (sa) is added. In Hungarian, the suffix \"ban/ben\" is most commonly used for inessive case, although many others, such as \"on/en/ön\" and others are also used, especially with cities.\n\nIn the Finnish language, the inessive case is considered the first (in Estonian the second) of the six locative cases, which correspond to locational prepositions in English. The remaining five cases are:\n\nThe Finnish inessive uses the suffix -ssa or -ssä (depending on vowel harmony). It is usually added to nouns and associated adjectives.\n\nIt is used in the following ways:\n\n\n\n\n\n"}
{"id": "53753101", "url": "https://en.wikipedia.org/wiki?curid=53753101", "title": "John Tilton Hack", "text": "John Tilton Hack\n\nJohn Tilton Hack (1913–1991) was an American geologist and geomorphologist known for his contributions to establish the dynamic equilibrium concept in landscapes. He was a student of Kirk Bryan. He retired from the United States Geological Survey in 1981.\n\nHack graduated from Harvard University, where he received his bachelors and master's degrees and doctorate in geomorphology.\n"}
{"id": "24693669", "url": "https://en.wikipedia.org/wiki?curid=24693669", "title": "Lanthanum barium copper oxide", "text": "Lanthanum barium copper oxide\n\nLanthanum barium copper oxide, or LBCO, was discovered in 1986 and was the first high temperature superconductor. Johannes Georg Bednorz and K. Alex Müller shared the 1987 Nobel Prize in physics for its discovery.\n"}
{"id": "737164", "url": "https://en.wikipedia.org/wiki?curid=737164", "title": "Large diffeomorphism", "text": "Large diffeomorphism\n\nIn mathematics and theoretical physics, a large diffeomorphism is an equivalence class of diffeomorphisms under the equivalence relation where diffeomorphisms that can be continuously connected to each other are in the same equivalence class.\n\nFor example, a two-dimensional real torus has a SL(2,Z) group of large diffeomorphisms by which the one-cycles formula_1 of the torus are transformed into their integer linear combinations. This group of large diffeomorphisms is called the modular group.\n\nMore generally, for a surface \"S\", the structure of self-homeomorphisms up to homotopy is known as the mapping class group. It is known (for compact, orientable \"S\") that this is isomorphic with the automorphism group of the fundamental group of \"S\". This is consistent with the genus 1 case, stated above, if one takes into account that then the fundamental group is \"Z\", on which the modular group acts as automorphisms (as a subgroup of index 2 in all automorphisms, since the orientation may also be reverse, by a transformation with determinant −1).\n\n"}
{"id": "6191199", "url": "https://en.wikipedia.org/wiki?curid=6191199", "title": "List of Chinese gardens", "text": "List of Chinese gardens\n\nThis is a list of Chinese-style gardens both within China and elsewhere in the world.\n\nThis list is organized by region within the Greater China region, roughly following the structure laid out by Maggie Keswick in \"The Chinese Garden\". The names of Chinese gardens are very problematic in English; this list aims to capture all the major variants, both in Chinese and in English.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "52208569", "url": "https://en.wikipedia.org/wiki?curid=52208569", "title": "List of NA numbers", "text": "List of NA numbers\n\nThe NA numbers as assigned by the United States Department of Transportation.\n\n\n"}
{"id": "16823402", "url": "https://en.wikipedia.org/wiki?curid=16823402", "title": "List of Slovenian biologists", "text": "List of Slovenian biologists\n\nList of notable biologists from Slovenia\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "28256710", "url": "https://en.wikipedia.org/wiki?curid=28256710", "title": "List of allergens", "text": "List of allergens\n\nThis is a list of allergies, which includes the allergen, potential reactions, and a brief description of the cause where applicable.\n\nMany substances can cause an allergic reaction when in contact with the human integumentary system.\n\n\n"}
{"id": "5089856", "url": "https://en.wikipedia.org/wiki?curid=5089856", "title": "List of clinical psychologists", "text": "List of clinical psychologists\n\nThis list includes notable clinical psychologists and contributors to clinical psychology, some of whom may not have thought of themselves primarily as clinical psychologists but are included here because of their important contributions to the discipline.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3935867", "url": "https://en.wikipedia.org/wiki?curid=3935867", "title": "List of filename extensions", "text": "List of filename extensions\n\nThis alphabetical list of filename extensions contains standard extensions associated with computer files.\n\n"}
{"id": "4643212", "url": "https://en.wikipedia.org/wiki?curid=4643212", "title": "List of soil scientists", "text": "List of soil scientists\n\nA soil scientist is a contributor to soil science. Soil scientists include agrologists, pedologists and soil classifiers.\n\nThe following is a list of notable soil scientists.\n"}
{"id": "56597987", "url": "https://en.wikipedia.org/wiki?curid=56597987", "title": "Liz MacDonald", "text": "Liz MacDonald\n\nElizabeth MacDonald is a space weather scientist who works at NASA Goddard Space Flight Center. She is a co-investigator on the Helium, Oxygen, Proton, and Electron Spectrometer on the NASA Radiation Belts Storm Probe mission.\n\nElizabeth MacDonald was born to Walla Wallans Bill and Alice MacDonald. MacDonald received a BSc in Physics from the University of Washington, funded by a NASA Space Grant scholarship, in 1999. Her mentor, Ruth Skoug, encouraged her to remain in research. MacDonald completed her postgraduate studies at the University of New Hampshire, earning her PhD in Physics in 2004.\n\nMacDonald specializes in plasma mass spectrometry, and has 23 years of expertise in instrument development and data analysis/interpretation.\n\nAfter completing her PhD, MacDonald joined Los Alamos National Laboratory. At LANL she was the Principal Investigator for the Z-Plasma Spectrometer on the Department of Energy Space and Atmospheric Burst Reporting System geosynchronous payload. She also led the \"Innovative Research and Integrated Sensing\" team. She was principal investigator for the Advanced Miniaturized Plasma Spectrometer. She received the Los Alamos Awards Program recognition three times.\n\nBetween 2009 and 2011 she led the Department of Energy funded \"Modular Advanced Space Environment Instrumentation\". In 2012 she became a New Mexico Consortium-affiliated researcher, working on the prototype for the Aurorasaurus citizen science project. She has served on scientific review panels for the National Science Foundation and Los Alamos National Laboratory grants. Today MacDonald works in the Goddard Space Flight Center.\n\nIn 2018 MacDonald and her team announced the discovery of a new aurora called Strong Thermal Emission Velocity Enhancement (STEVE). STEVE is farther from the poles than the aurora is typically seen. The European Space Agency Swam A satellite was used to identify that the charged particles in STEVE were around 6000 °C. It was observed by Canadian aurora enthusiasts in 2015. MacDonald attributes the faint purple glow to a subauroral ion drift. MacDonald published the finding in Science. She is working with NASA to crowd source sightings of STEVE.\n\nIn 2018, MacDonald was named as a Walla Walla Public Schools Graduate of Distinction as a \"pioneer in citizen science initiatives and mentor for aspiring scientists of all ages.\"\n\nIn 2016 in the journal Space Weather, MacDonald and co-workers reported that \"citizen scientists are regularly able to spot auroras farther south of an area where prediction models indicated\". MacDonald leads an interdisciplinary citizen science project called Aurorasaurus, which uses social media to predict the Northern Lights during the current solar maximum. To fund the program, she won a $1 million INSPIRE grant from the National Science Foundation together with Prof. Andrea Tapia of Pennsylvania State University and Michelle Hall of Science Education Solutions. \n\nAfter noticing a spike in Tweets about an aurora borealis in October 2011, she established Aurorasaurus to track such geolocation information in order to improve forecasting, such as that done by NOAA’s Space Weather Prediction Center.\n\nIn 2017 she described the aurora as a \"glitter bomb\" on the radio program Science Friday. In August 2017, she spoke at the Carl Sandburg Home National Historic Site about the 2017 solar eclipse. MacDonald regularly speaks to high school students and community groups.\n"}
{"id": "587277", "url": "https://en.wikipedia.org/wiki?curid=587277", "title": "Mesotherapy", "text": "Mesotherapy\n\nMesotherapy (from Greek \"mesos\", \"middle\", and therapy from Greek \"therapeia\", \"to treat medically\") is a non-surgical cosmetic medicine treatment. Mesotherapy employs multiple injections of pharmaceutical and homeopathic medications, plant extracts, vitamins, and other ingredients into subcutaneous fat. Mesotherapy injections allegedly target adipose fat cells, apparently by inducing lipolysis, rupture and cell death among adipocytes.\n\nThere are published studies on the clinical treatments and effects of these medications and numerous cocktails of combined chemical compounds on the body have been reported in Europe and South America for several years. There is no conclusive research proof that these chemical compounds work to target adipose (fat cells) specifically. Cell lysis, resulting from the detergent action of deoxycholic, may account for any clinical effect.\n\nIn 2012, a French laboratory invented a way to insert a treatment of Mesotherapy into a liquid podlet. This podlet is then plugged into a facial steamer which applies the treatment to the user's facial pores via steam. This was the first invention of its kind to enable Mesotherapy treatments directly to consumers within their own home.\n\nSubstances used include these:\n\nMichel Pistor (1924–2003) performed clinical research and founded the field of mesotherapy. Multi-national research in intradermal therapy culminated with Pistor's work from 1948 to 1952 in human mesotherapy treatments. The French press coined the term Mesotherapy in 1958. The French Académie Nationale de Médecine recognized Mesotherapy as a Specialty of Medicine in 1987. The French society of Mesotherapy recognizes its use as treatment for various conditions but makes no mention of its use in plastic surgery. Popular throughout European countries and South America, mesotherapy is practiced by approximately 18,000 physicians worldwide.\n\nMesotherapy treatments have been performed throughout Europe, South America, and more recently the United States for over fifty years. However physicians have expressed concern over the efficacy of mesotherapy, arguing that the treatment hasn't been studied enough to make a determination. The primary issue is that mesotherapy for the treatment of cosmetic conditions hasn't been the subject of gold standard clinical trials; however the procedure has been studied for the pain relief of other ailments, such as tendonitis, tendon calcification, dental procedures, cancer, cervicobrachialgia, arthritis, lymphedema, and venous stasis. Further, there have been case series and numerous medical papers on the mesotherapy as a cosmetic treatment, as well as studies that employ the ingredients used in mesotherapy.\n\nThe other side of the debate is expressed by Rod Rohrich, M.D., Chairman, Dept. of Plastic Surgery, University of Texas Southwestern Medical Center, Dallas: \"There is simply no data, no science and no information, to my knowledge, that mesotherapy works.\" The American Society of Plastic Surgeons issued a position statement not endorsing mesotherapy, but this non-endorsement is the subject of some controversy. Since mesotherapy isn't a surgical treatment but, rather, a non-invasive alternative to plastic surgery, the treatment competes with plastic surgery for the same patients.\n\nThe FDA cannot control the use of practitioners injecting various mixtures into patient's bodies because this practice falls under the jurisdiction of state medical boards. This is the case because the mesotherapy is considered a \"procedure\" by state medical boards. The FDA, on the other hand, is mandated to approve foods, dietary supplements, drugs, vaccines, biological medical products, blood products, medical devices, radiation-emitting devices, veterinary products and cosmetics.\n\nRobin Ashinoff, speaking for the American Academy of Dermatology, says \"A simple injection is giving people false hope. Everybody's looking for a quick fix. But there is no quick fix for fat or fat deposits or for cellulite.\" The American Society for Dermatologic Surgery informed its members in February 2005 that \"further study is warranted before this technique can be endorsed.\"\n\nMany dermatologists and plastic surgeons are alarmed about the growing profile of mesotherapy. \"No one says exactly what they put into the (syringe),\" says Naomi Lawrence, a derma-surgeon at the University of Medicine and Dentistry of New Jersey. \"One drug they often use, phosphatidylcholine, is unpredictable and causes extreme inflammation and swelling where injected. It is not a benign drug.\"\n\nIt is currently banned in a number of South American countries. Even Brazil, which is less strict than the USA in drug approvals, has banned the drug for these purposes.\n\nIn Australia, an alternative therapy salon is being investigated by the Health Department after several clients developed skin abscesses on the calves, buttocks, thighs, abdomen, shoulders, face and neck from the treatment, with one patient also developing a mycobacterial infection.\n\nFollowing undesirable effects observed on several patients of a French practitioner, an official ratification was published in France in April 2011 to ban Mesotherapy as a method for removing fat deposits.\nThis ban has been canceled in June 2011 by the French Council of State because the investigation proved that these undesirable effects weren’t due to the Mesotherapy itself, but to the fact it had been practiced in bad conditions and without respecting the hygiene principles.\n\nIn a prospective study, 10 patients underwent four sessions of facial mesotherapy using multivitamins at monthly intervals. This study found that there was no clinically relevant benefit.\n\nDeoxycholic acid received FDA approval as an injectable to dissolve submental fat June 2015. This was based on a Phase III randomized trial of 2600 patients. 68.2% showed a response by measurement of the fat deposit. 81% had mild adverse reactions of bruising, swelling, pain, numbness, erythema, and firmness around the treated area.\n\n"}
{"id": "8305325", "url": "https://en.wikipedia.org/wiki?curid=8305325", "title": "Nickel titanium", "text": "Nickel titanium\n\nNickel titanium, also known as Nitinol (part of shape memory alloy), is a metal alloy of nickel and titanium, where the two elements are present in roughly equal atomic percentages e.g. Nitinol 55, Nitinol 60.\n\nNitinol alloys exhibit two closely related and unique properties: shape memory effect (SME) and superelasticity (SE; also called pseudoelasticity, PE). Shape memory is the ability of nitinol to undergo deformation at one temperature, then recover its original, undeformed shape upon heating above its \"transformation temperature\". Superelasticity occurs at a narrow temperature range just above its transformation temperature; in this case, no heating is necessary to cause the undeformed shape to recover, and the material exhibits enormous elasticity, some 10-30 times that of ordinary metal.\n\nThe word Nitinol is derived from its composition and its place of discovery: (\"Ni\"ckel \"Ti\"tanium-\"N\"aval \"O\"rdnance \"L\"aboratory). William J. Buehler along with Frederick Wang, discovered its properties during research at the Naval Ordnance Laboratory in 1959. Buehler was attempting to make a better missile nose cone, which could resist fatigue, heat and the force of impact. Having found that a 1:1 alloy of nickel and titanium could do the job, in 1961 he presented a sample at a laboratory management meeting. The sample, folded up like an accordion, was passed around and flexed by the participants. One of them applied heat from his pipe lighter to the sample and, to everyone's surprise, the accordion-shaped strip stretched and took its previous shape.\n\nWhile the potential applications for nitinol were realized immediately, practical efforts to commercialize the alloy did not take place until a decade later. This delay was largely because of the extraordinary difficulty of melting, processing and machining the alloy. Even these efforts encountered financial challenges that were not readily overcome until the 1980s, when these practical difficulties finally began to be resolved.\n\nThe discovery of the shape-memory effect in general dates back to 1932, when Swedish chemist Arne Ölander first observed the property in gold-cadmium alloys. The same effect was observed in Cu-Zn (brass) in the early 1950s.\n\nNitinol's unusual properties are derived from a reversible solid-state phase transformation known as a martensitic transformation, between two different martensite crystal phases, requiring of mechanical stress.\n\nAt high temperatures, nitinol assumes an interpenetrating simple cubic structure referred to as austenite (also known as the parent phase). At low temperatures, nitinol spontaneously transforms to a more complicated monoclinic crystal structure known as martensite (daughter phase). There are four transition temperatures associated to the austenite-to-martensite and martensite-to-austenite transformations. Starting from full austenite, martensite begins to form as the alloy is cooled to the so-called \"martensite start temperature\", or M, and the temperature at which the transformation is complete is called the \"martensite finish temperature\", or M. When the alloy is fully martensite and is subjected to heating, austenite starts to form at the \"austenite start temperature\", A, and finishes at the \"austenite finish temperature\", A.\nThe cooling/heating cycle shows thermal hysteresis. The hysteresis width depends on the precise nitinol composition and processing. Its typical value is a temperature range spanning about 20-50 K (20-50 °C; 36-90 °F) but it can be reduced or amplified by alloying and processing.\n\nCrucial to nitinol properties are two key aspects of this phase transformation. First is that the transformation is \"reversible\", meaning that heating above the transformation temperature will revert the crystal structure to the simpler austenite phase. The second key point is that the transformation in both directions is instantaneous.\n\nMartensite's crystal structure (known as a monoclinic, or B19' structure) has the unique ability to undergo limited deformation in some ways without breaking atomic bonds. This type of deformation is known as twinning, which consists of the rearrangement of atomic planes without causing slip, or permanent deformation. It is able to undergo about 6–8% strain in this manner. When martensite is reverted to austenite by heating, the original austenitic structure is restored, regardless of whether the martensite phase was deformed. Thus the name \"shape memory\" refers to the fact that the shape of the high temperature austenite phase is \"remembered,\" even though the alloy is severely deformed at a lower temperature. \n\nA great deal of pressure can be produced by preventing the reversion of deformed martensite to austenite — from 35,000 psi to, in many cases, more than 100,000 psi (689 MPa). One of the reasons that nitinol works so hard to return to its original shape is that it is not just an ordinary metal alloy, but what is known as an intermetallic compound. In an ordinary alloy, the constituents are randomly positioned in the crystal lattice; in an ordered intermetallic compound, the atoms (in this case, nickel and titanium) have very specific locations in the lattice. The fact that nitinol is an intermetallic is largely responsible for the complexity in fabricating devices made from the alloy.\nThe scenario described above (cooling austenite to form martensite, deforming the martensite, then heating to revert to austenite, thus returning the original, undeformed shape) is known as the thermal shape memory effect. To fix the original \"parent shape,\" the alloy must be held in position and heated to about . This process is usually called \"shape setting\". A second effect, called superelasticity or pseudoelasticity, is also observed in nitinol. This effect is the direct result of the fact that martensite can be formed by applying a stress as well as by cooling. Thus in a certain temperature range, one can apply a stress to austenite, causing martensite to form while at the same time changing shape. In this case, as soon as the stress is removed, the nitinol will spontaneously return to its original shape. In this mode of use, nitinol behaves like a super spring, possessing an elastic range 10–30 times greater than that of a normal spring material. There are, however, constraints: the effect is only observed about 0-40 K (0-40 °C; 0-72 °F) above the A temperature. This upper limit is referred to as M, which corresponds to the highest temperature in which it is still possible to stress-induce the formation of martensite. Below M, martensite formation under load allows superelasticity due to twinning. Above M, since martensite is no longer formed, the only response to stress is slip of the austenitic microstructure, and thus permanent deformation.\n\nNitinol is typically composed of approximately 50 to 51% nickel by atomic percent (55 to 56% weight percent). Making small changes in the composition can change the transition temperature of the alloy significantly. Transformation temperatures in nitinol can be controlled to some extent, where A temperature ranges from about −20 °C to +110 °C. Thus, it is common practice to refer to a nitinol formulation as \"superelastic\" or \"austenitic\" if A is lower than a reference temperature, while as \"shape memory\" or \"martensitic\" if higher. The reference temperature is usually defined as the room temperature or the human body temperature (37 °C; 98 °F).\n\nOne often-encountered effect regarding nitinol is the so-called R-phase. The R-phase is another martensitic phase that competes with the martensite phase mentioned above. Because it does not offer the large memory effects of the martensite phase, it is usually of non practical use.\n\nNitinol is exceedingly difficult to make, due to the exceptionally tight compositional control required, and the tremendous reactivity of titanium. Every atom of titanium that combines with oxygen or carbon is an atom that is robbed from the NiTi lattice, thus shifting the composition and making the transformation temperature that much lower. There are two primary melting methods used today:\n\n\nWhile both methods have advantages, it has been demonstrated that an industrial state-of-the-art VIM melted material has smaller inclusions than an industrial state-of-the-art VAR one, leading to a higher fatigue resistance. Other research report that VAR employing extreme high-purity raw materials may lead to a reduced number of inclusions and thus to an improved fatigue behavior. Other methods are also used on a boutique scale, including plasma arc melting, induction skull melting, and e-beam melting. Physical vapour deposition is also used on a laboratory scale.\n\nHot working of nitinol is relatively easy, but cold working is difficult because the enormous elasticity of the alloy increases die or roll contact, leading to tremendous frictional resistance and tool wear. For similar reasons, machining is extremely difficult—to make things worse, the thermal conductivity of nitinol is poor, so heat is difficult to remove. Grinding (abrasive cutting), Electrical discharge machining (EDM) and laser cutting are all relatively easy.\n\nHeat treating nitinol is delicate and critical. It is a knowledge intensive process to fine-tune the transformation temperatures. Aging time and temperature controls the precipitation of various Ni-rich phases, and thus controls how much nickel resides in the NiTi lattice; by depleting the matrix of nickel, aging increases the transformation temperature. The combination of heat treatment and cold working is essential in controlling the properties of nitinol products.\n\nFatigue failures of nitinol devices are a constant subject of discussion. Because it is the material of choice for applications requiring enormous flexibility and motion (e.g., peripheral stents, heart valves, smart thermomechanical actuators and electromechanical microactuators), it is necessarily exposed to much greater fatigue strains compared to other metals. While the strain-controlled fatigue performance of nitinol is superior to all other known metals, fatigue failures have been observed in the most demanding applications. There is a great deal of effort underway trying to better understand and define the durability limits of nitinol.\n\nNitinol is half nickel, and thus there has been a great deal of concern in the medical industry regarding the release of nickel, a known allergen and possible carcinogen. (Nickel is also present in substantial amounts in stainless steel and cobalt-chrome alloys.) When properly treated (via electropolishing and/or passivation), nitinol forms a very stable protective TiO layer that acts as a very effective and self-healing barrier against ion exchange. It has been repeatedly shown that nitinol releases nickel at a slower pace than stainless steel, for example. With that said, very early medical devices were made without electropolishing, and corrosion was observed. Today's nitinol vascular self-expandable metallic stents, for example, show no evidence of corrosion or nickel release, and the outcomes in patients with and without nickel allergies are indistinguishable.\n\nThere are constant and long-running discussions regarding inclusions in nitinol, both TiC and TiNiO. As in all other metals and alloys, inclusions can be found in Nitinol. The size, distribution and type of inclusions can be controlled to some extent. Theoretically, smaller, rounder and few inclusions should lead to increased fatigue durability. In literature, some early works report to have failed to show measurable differences, while novel studies demonstrate a dependence of fatigue resistance on the typical inclusion size in an alloy.\n\nNitinol is difficult to weld, both to itself and other materials. Laser welding nitinol to itself is a relatively routine process. More recently, strong joints between NiTi wires and stainless steel wires have been made using nickel filler. Laser and Tungsten Inert Gas (TIG) welds have been made between NiTi tubes and stainless steel tubes . More research is ongoing into other processes and other metals to which nitinol can be welded.\n\nActuation frequency of nitinol is dependent on the heat management, especially during the cooling phase. Numerous methods are used to increase the cooling performance, such as forced air, flowing liquids, thermoelectric modules (i.e. Peltier or semiconductor heat pumps), heat sinks, conductive materials and higher surface-to-volume ratio (improvements up to 3.3 Hz with very thin wires and up to 100 Hz with thinfilm nitinol). The fastest nitinol actuation recorded was carried by a high voltage capacitor discharge which heated an SMA wire in a manner of microseconds, and resulted in a complete phase transformation (and high velocities) in a few milliseconds.\n\nRecent advances have shown that processing of nitinol can expand thermomechanical capabilities, allowing for multiple shape memories to be embedded within a monolithic structure. Research on multi-memory technology is on-going and promises to deliver enhanced shape memory devices in the near future\n, and the application of new materials and material structures, such hybrid shape memory materials (SMMs) and shape memory composites (SMCs).\n\nThere are four commonly used types of applications for nitinol:\n\nFree recovery\nConstrained recovery\nWork production\nSuperelasticity\nIn 1989 a survey was conducted in the United States and Canada that involved seven organizations. The survey focused on predicting the future technology, market, and applications of SMAs. The companies predicted the following uses of nitinol in a decreasing order of importance: (1) Couplings, (2) Biomedical and medical, (3) Toys, demonstration, novelty items, (4) Actuators, (5) Heat Engines, (6) Sensors, (7) Cryogenically activated die and bubble memory sockets, and finally (8) lifting devices.\n\nToday, nitinol finds application in the listed industrial applications:\n\n\n\n\n\nA process of making parts and forms of Type 60 Nitinol having a shape memory effect, comprising: selecting a Type 60 Nitinol. Inventor G, Julien CEO of Nitinol Technologies, Inc. (Washington State)\n\n\nScience Digest articles - Miracle Metal 1982 - PDF\n"}
{"id": "56570847", "url": "https://en.wikipedia.org/wiki?curid=56570847", "title": "Nuclear shaped charge", "text": "Nuclear shaped charge\n\nNuclear shaped charges refers to nuclear weapons that focus the energy of their explosion into certain directions, as opposed to a spherical explosion. Edward Teller referred to such concepts as third-generation weapons, the first generation being the atom bomb and the second the H-bomb.\n\nThe basic concept has been raised on several occasions, with the first known references being part of the Project Orion nuclear-powered spacecraft project in the 1960s. This used beryllium oxide to convert the X-rays released by a small bomb into infrared light, which explosively vaporized a tamper material, normally tungsten, causing it to carry away much of the bomb's energy as kinetic energy in the form of tungsten plasma. The same concept was explored as a weapon in the Casaba Howitzer proposals.\n\nThe ideas were explored by Los Alamos National Laboratory as part of the Strategic Defense Initiative.\n"}
{"id": "17295260", "url": "https://en.wikipedia.org/wiki?curid=17295260", "title": "Optimal projection equations", "text": "Optimal projection equations\n\nIn control theory, optimal projection equations constitute necessary and sufficient conditions for a locally optimal reduced-order LQG controller.\n\nThe Linear-Quadratic-Gaussian (LQG) control problem is one of the most fundamental optimal control problems. It concerns uncertain linear systems disturbed by additive white Gaussian noise, incomplete state information (i.e. not all the state variables are measured and available for feedback) also disturbed by additive white Gaussian noise and quadratic costs. Moreover, the solution is unique and constitutes a linear dynamic feedback control law that is easily computed and implemented. Finally the LQG controller is also fundamental to the optimal perturbation control of non-linear systems.\n\nThe LQG controller itself is a dynamic system like the system it controls. Both systems have the same state dimension. Therefore, implementing the LQG controller may be problematic if the dimension of the system state is large. The reduced-order LQG problem (fixed-order LQG problem) overcomes this by fixing a-priori the number of states of the LQG controller. This problem is more difficult to solve because it is no longer separable. Also the solution is no longer unique. Despite these facts numerical algorithms are available to solve the associated optimal projection equations.\n\nThe reduced-order LQG control problem is almost identical to the conventional full-order LQG control problem. Let formula_1 represent the state of the reduced-order LQG controller. Then the only difference is that the state dimension formula_2 of the LQG controller is a-priori fixed to be smaller than formula_3, the state dimension of the controlled system.\n\nThe reduced-order LQG controller is represented by the following equations:\n\nThese equations are deliberately stated in a format that equals that of the conventional full-order LQG controller. For the reduced-order LQG control problem it is convenient to rewrite them as\n\nwhere\n\nThe matrices formula_9 and formula_10 of the reduced-order LQG controller are determined by the so-called optimal projection equations (OPE).\n\nThe square optimal projection matrix formula_11 with dimension formula_12 is central to the OPE. The rank of this matrix is almost everywhere equal to formula_13 The associated projection is an oblique projection: formula_14 The OPE constitute four matrix differential equations. The first two equations listed below are generalizations of the matrix Riccati differential equations associated to the conventional full-order LQG controller. In these equations formula_15 denotes formula_16 where formula_17 is the identity matrix of dimension formula_12.\n\nIf the dimension of the LQG controller is not reduced, that is if formula_25, then formula_26 and the two equations above become the uncoupled matrix Riccati differential equations associated to the conventional full-order LQG controller. If formula_27 the two equations are coupled by the oblique projection formula_28 This reveals why the reduced-order LQG problem is not separable. The oblique projection formula_11 is determined from two additional matrix differential equations which involve rank conditions. Together with the previous two matrix differential equations these are the OPE. To state the additional two matrix differential equations it is convenient to introduce the following two matrices:\n\nThen the two additional matrix differential equations that complete the OPE are as follows:\n\nwith\n\nHere * denotes the group generalized inverse or Drazin inverse that is unique and given by\n\nwhere + denotes the Moore-Penrose pseudoinverse.\n\nThe matrices formula_38 must all be nonnegative symmetric. Then they constitute a solution of the OPE that determines the reduced-order LQG controller matrices formula_9 and formula_10:\n\nIn the equations above the matrices formula_45 are two matrices with the following properties:\n\nThey can be obtained from a projective factorization of formula_47.\n\nThe OPE can be stated in many different ways that are all equivalent. To identify the equivalent representations the following identities are especially useful:\n\nUsing these identities one may for instance rewrite the first two of the optimal projection equations as follows:\n\nThis representation is both relatively simple and suitable for numerical computations.\n\nIf all the matrices in the reduced-order LQG problem formulation are time-invariant and if the horizon formula_53 tends to infinity, the optimal reduced-order LQG controller becomes time-invariant and so do the OPE. In that case the derivatives on the left hand side of the OPE are zero.\n\nSimilar to the continuous-time case, in the discrete-time case the difference with the conventional discrete-time full-order LQG problem is the a-priori fixed reduced-order formula_27 of the LQG controller state dimension. As in continuous-time, to state the discrete-time OPE it is convenient to introduce the following two matrices:\n\nThen the discrete-time OPE is\n\nThe oblique projection matrix is given by\n\nThe nonnegative symmetric matrices formula_64 that solve the discrete-time OPE determine the reduced-order LQG controller matrices formula_65 and formula_66:\n\nIn the equations above the matrices formula_71 are two matrices with the following properties:\n\nThey can be obtained from a projective factorization of formula_73. To identify equivalent representations of the discrete-time OPE the following identities are especially useful:\n\nAs in the continuous-time case if all the matrices in the problem formulation are time-invariant and if the horizon formula_75 tends to infinity the reduced-order LQG controller becomes time-invariant. Then the discrete-time OPE converge to a steady state solution that determines the time-invariant reduced-order LQG controller.\n\nThe discrete-time OPE apply also to discrete-time systems with variable state, input and output dimensions (discrete-time systems with time-varying dimensions). Such systems arise in the case of digital controller design if the sampling occurs asynchronously.\n"}
{"id": "7843015", "url": "https://en.wikipedia.org/wiki?curid=7843015", "title": "Peace enforcement", "text": "Peace enforcement\n\nPeace enforcement is the use of military force to compel peace in a conflict, generally against the will of those combatants. To do this, it generally requires more military force than peacekeeping operations. The United Nations, through its Security Council per Chapter VII of its charter, has the ability to authorize force to enforce its resolutions and ceasefires already created.\n\nPeace enforcement differs from peacekeeping as peace enforcement activities are generally used to create a peace from a broken ceasefire or to enforce a peace demanded by the United Nations. Compared to peacekeeping, peace enforcement requires more military force and is thereby best done by heavily armed forces. However, it is generally unable to create lasting peace, as it does nothing to deal with the underlying problems which caused the conflict itself.\n\nOne of the most famous examples of peace enforcement was the UN intervention during the Gulf War to force Saddam Hussein's Iraqi army from Kuwait. The United Nations was thereby able to compel Iraq's compliance with the UN Resolutions which demanded its withdrawal from the region.\n\nA report on peacekeeping and peace enforcement in the 1990s for the United States Army established this difference between peace enforcement and peacekeeping: Peacekeeping, a role the U.N. has played over the years, is relatively straightforward and, despite its difficulties, comparatively easy. Peacekeeping involves monitoring and enforcing a cease-fire agreed to by two or more former combatants. It proceeds in an atmosphere where peace exists and where the former combatants minimally prefer peace to continued war. Peace-enforcement, as it is used by the United States Joint Chiefs of Staff, entails the physical interposition of armed forces to separate ongoing combatants to create a cease-fire that does not exist. Boutros-Ghali, on the other hand, uses the term to refer to actions to keep a cease-fire from being violated or to reinstate a failed cease-fire. It is a subtle difference, but it does imply the existence of some will for peace. The American version more realistically portrays another, far more difficult matter. By definition, in a situation for which peace-enforcement is a potentially appropriate response, war and not peace describes the situation, and one or more of the combatants prefer it that way. This means that, unlike peacekeepers, peace enforcers are often not welcomed by one or either side(s). Rather, they are active fighters who must impose a cease-fire that is opposed by one or both combatants; in the process, the neutrality that distinguishes peacekeepers will most likely be lost.\n\n\nMohamed Awad Osman, \"The United Nations and Peace Enforcement, wars, Terrorism and Democracy\", Aldershot, Ashgate 2002.\n\n"}
{"id": "4297192", "url": "https://en.wikipedia.org/wiki?curid=4297192", "title": "Peter Crüger", "text": "Peter Crüger\n\nPeter Crüger or Peter Krüger (20 October 1580 – 6 June 1639) was a mathematician, astronomer, polymath, and teacher of Johannes Hevelius.\n\nCrüger was born in Königsberg, Duchy of Prussia, a fief of the Kingdom of Poland.\n\nIn scientific documents published in Latin, his common name \"Krüger\" (German for \"potter\" or \"innkeeper\") was Latinized and spelled \"Crüger\". (Compared to the frequency of the family name \"Krüger\", the name \"\" is relatively uncommon.)\n\nCrüger studied at the universities in Königsberg, Leipzig and Wittenberg, graduating from Wittenberg in 1606. Among his teachers were Tycho Brahe and Johannes Kepler. He then moved to the city of Danzig (Gdańsk) in the Kingdom of Poland, where he worked for the rest of his life as a professor of poetry and mathematics at the \"Danziger Akademikum\" (Danzig Academy). \n\nAs a philosopher and poet, Crüger was associated with the poet Johannes Plavius, who in his \"Institutio Poetica\" mentions Crüger in the opening letter. Crüger dedicated an extremely laudatory poem to Plavius, which appears in the preface to Plavius' \"Praecepta logicalia\".\n\nAt the time of the Thirty Years' War a number of Silesians took refuge in Danzig from the ravages of war in their towns, among them Andreas Gryphius, who, when he studied at the Danzig academy from 1634 to 1636, had Crüger as a teacher and was very much influenced by the famous mathematician and astronomer. Professors Crüger and Mochingert made Gryphius aware of the new style of German-language poetry. Gryphius wrote memorial verses, when in 1638 Crüger's child died. Years earlier Crüger had already developed a great friendship with Martin Opitz, \"father of German poetry\", who also lived in Danzig.\n\nCrüger published treatises on many scientific subjects and contributed to the progress of trigonometry, geography and astronomy, and to the development of astronomical instruments. In the years 1627 to 1630, Crüger was the teacher of a teenager of the Hewelke family who would become known later as Johannes Hevelius, the astronomer. After Hevelius had returned to Danzig in 1634, the dying Crüger appealed to him to pursue astronomy. Hevelius gratefully mentions Crüger in his \"Machina coelestis\".\n\nHe died in Danzig.\n\nThe crater Crüger on the Moon is named after him.\n\n\n"}
{"id": "5777298", "url": "https://en.wikipedia.org/wiki?curid=5777298", "title": "Port-aux-Français", "text": "Port-aux-Français\n\nPort-aux-Français is the capital settlement of the Kerguelen Islands, French Southern and Antarctic Lands, in the south Indian Ocean. The port station is located on the Gulf of Morbihan, at .\n\nThe station was selected in 1949 by the chief of mission Pierre Sicaud because of its sheltered position which was suitable for a runway that was never built. From 1955 to 1957, and using Australian equipment, a French slaughterhouse company called Sidap constructed a sealing factory. The factory opened following the first marriage on the islands, that of Marc Pechenart and Martine Raulin on 16 December 1957. The factory closed in 1960, and the equipment was sent to Réunion in 2005. It has about 45 inhabitants in winter; the population can rise to more than 120 in summer.\n\nPort-aux-Français has a shallow seaport and a quay for unloading supply ships, including the \"Marion Dufresne\". The station, in addition to logistics necessary to its operation, consists of scientific laboratories (biology, geophysics), technical installations (meteorology, telecommunications, satellite tracking, et cetera), a cinema and a small medical centre.\n\nThe base of Port-aux-Français is equipped with a recently installed marigraphic station, having 3 measuring devices:\nThe two marigraphs and the radar send data to a local server, which relays them hourly to the Internet via the Argos satellite system.\n\nPort-aux-Français has an ocean moderated (Köppen climate classification \"ET\"). Temperatures (without windchill) tend to remain fairly stable throughout the year, rarely reaching over or falling below . The average temperature in February, the warmest month, is with a maximum of during the day and during the night. In winter, August and July are the coldest months, averaging during the day and at night. \n\nSnowfall is possible in all months, even in summer though it is more common during the winter months than during the summer months. The climate is windier than in most places, with a recorded gust of .\nThe lowest recorded temperature was on 11 August 2014, which beats the old record of set in June 1953.\nThe highest temperature was on 30 January 1959.\n"}
{"id": "18021242", "url": "https://en.wikipedia.org/wiki?curid=18021242", "title": "Public Culture", "text": "Public Culture\n\nPublic Culture is a peer-reviewed, interdisciplinary academic journal of cultural studies, published three times a year—in January, May, and September—by Duke University Press. It is sponsored by the Institute for Public Knowledge at New York University.\n\nA four-time CELJ award winner, \"Public Culture\" has been publishing field-defining ethnographies and analyses of the cultural politics of globalization for more than twenty-five years. The journal provides a forum for the discussion of the places and occasions where cultural, social, and political differences emerge as public phenomena, manifested in everything from highly particular and localized events in popular or folk culture to global advertising, consumption, and information networks. Artists, activists, and both well-established and younger scholars, from across the humanities and social sciences and around the world, present some of their most innovative and exciting work in the pages of \"Public Culture\".\n\nThe journal was established in 1988 by anthropologists Carol Breckenridge and Arjun Appadurai. Professor of Sociology and Director of the Institute for Public Knowledge at New York University Eric Klinenberg served as Public Culture's editor-in-chief from 2010 to 2015, during which time he initiated the online book review offshoot \"Public Books\". Since 2015, \"Public Culture\" has been edited by Shamus Khan, Professor of Sociology at Columbia University. \n\n\"Public Culture\" received awards for Best New Journal in 1992 and Best Special Issue in 2000 from The Council of Editors of Learned Journals. In 2013, the same body named \"Public Culture\" co-winner of the Phoenix Award for Significant Editorial Achievement, recognizing the journal's revitalization and transformation with a \"marked emphasis on accessibility and broader relevance.\" The journal has also been reviewed in the \"Times Literary Supplement\".\nFounded in 2012 by editors-in-chief Sharon Marcus and Caitlin Zaloom, \"Public Books\" supports an international community of emerging and established intellectuals and artists committed to vigorous debate about works and ideas that deserve timely, intensive discussion. The online journal is independently edited but affiliated with \"Public Culture\". \"Public Books\" welcomes proposals for review essays about books (fiction or nonfiction), films, exhibitions, or plays, as well as profiles of intellectuals or literary scenes, visual essays, and multimedia work. \n\n"}
{"id": "460235", "url": "https://en.wikipedia.org/wiki?curid=460235", "title": "Resultant force", "text": "Resultant force\n\nA resultant force is the single force and associated torque obtained by combining a system of forces and torques acting on a rigid body. The defining feature of a resultant force, or resultant force-torque, is that it has the same effect on the rigid body as the original system of forces.\n\nThe point of application of the resultant force determines its associated torque. The term \"resultant force\" should be understood to refer to both the forces and torques acting on a rigid body, which is why some use the term resultant force-torque. \n\nThe diagram illustrates simple graphical methods for finding the line of application of the resultant force of simple planar systems.\n\nA force applied to a body has a point of application. The effect of the force is different for different points of application. For this reason a force is called a \"bound vector\", which means that it is bound to its point of application.\n\nForces applied at the same point can be added together to obtain the same effect on the body. However, forces with different points of application cannot be added together and maintain the same effect on the body.\n\nIt is a simple matter to change the point of application of a force by introducing equal and opposite forces at two different points of application that produce a pure torque on the body. In this way, all of the forces acting on a body can be moved to the same point of application with associated torques. \n\nA system of forces on a rigid body are combined by moving the forces to the same point of application and computing the associated torques. The sum of these forces and torques yields the resultant force-torque.\n\nIf a point R is selected as the point of application of the resultant force F of a system of \"n\" forces F then the associated torque T is determined from the formulas\nand\n\nIt is useful to note that the point of application R of the resultant force may be anywhere along the line of action of F without changing the value of the associated torque. To see this add the vector kF to the point of application R in the calculation of the associated torque,\nThe right side of this equation can be separated into the original;formula for T plus the additional term including kF,\nbecause the second term is zero. To see this notice that F is the sum of the vectors F which yields\nthus the value of the associated torque is unchanged.\n\nIt is useful to consider whether there is a point of application R such that the associated torque is zero. This point is defined by the property\nwhere F is resultant force and F form the system of forces.\n\nNotice that this equation for R has a solution only if the sum of the individual torques on the right side yield a vector that is perpendicular to F. Thus, the condition that a system of forces has a torque-free resultant can be written as\nIf this condition is satisfied then there is a point of application for the resultant which results in a pure force. If this condition is not satisfied, then the system of forces includes a pure torque for every point of application.\n\nThe forces and torques acting on a rigid body can be assembled into the pair of vectors called a \"wrench\".If a system of forces and torques has a net resultant force F and a net resultant torque T, then the entire system can be replaced by a force F and an arbitrarily located couple that yields a torque of T. In general, if F and T are orthogonal, it is possible to derive a radial vector R such that formula_16, meaning that the single force F, acting at displacement R, can replace the system. If the system is zero-force (torque only), it is termed a \"screw\" and is mathematically formulated as screw theory.\nThe resultant force and torque on a rigid body obtained from a system of forces F i=1...,n, is simply the sum of the individual wrenches W, that is\n\nNotice that the case of two equal but opposite forces F and -F acting at points A and B respectively, yields the resultant W=(F-F, A×F - B× F) = (0, (A-B)×F). This shows that wrenches of the form W=(0, T) can be interpreted as pure torques.\n"}
{"id": "7890833", "url": "https://en.wikipedia.org/wiki?curid=7890833", "title": "Rimantas Stankevičius", "text": "Rimantas Stankevičius\n\nRimantas Antanas Stankevičius (26 July 1944 in Marijampolė, Lithuania – 9 September 1990 in Salgareda, Italy) was a Lithuanian cosmonaut who test flew Soviet space shuttle Buran and its test vehicles. He was killed in a crash of his Su-27 fighter plane during an airshow in Salgareda.\n\nIn 1966 he has graduated from Chernigov Higher Aviation School. After that he served as an USSR pilot in Germany, Egypt, Turkmenia. In 1975 Stankevičius has graduated from the Fedotov Test Pilot School and became a test pilot. He has accomplished spin testing of MiG-29. He flew 57 types of aircraft and had over 4000 hours of flying experience. In 1982 he was graded as a 1st class test-pilot.\n\nIn 1979 he was assigned to prepare for 11F35 (Buran, USSR space shuttle). In February 1982 he passed all the required exams and became the first Lithuanian cosmonaut. After September 1984 he trained to fly the space shuttle Buran. Stankevičius accomplished 14 test-flights with Buran's counterpart BTS-02 aircraft and 6 taxi tests with Buran. He was both the pilot and the commander of the space shuttle.\n\nIn 1990 Rimantas Stankevičius participated the Everett Air Show with a Su-27 fighter jet. Soon after his return home, he went to Italy to replace another USSR pilot in Salgareda Air Show. On 9 September, during a flight in the show in a Su-27, he started a loop in a lower altitude than he estimated and made an unintentional touchdown. He died in the crash. The crash resulted in only one fatality aside from the pilot.\n\nStankevičius, along with Soviet Cosmonauts Igor Volk and Sergei Tresvyatskiy, worked closely with Americans in the late 1980s to improve relations during the Cold War. The three were involved in what is believed to be the first formation flight with Soviet SU-27 fighter planes and American F-16s in history in July 1990 (before the breakup of the USSR) at the Opening Ceremonies of the Goodwill Games in Seattle. The three also flew the first Americans, (8 members of the Organizing Committee of the 1990 Goodwill Games) since World War II in an Ilyushin Il-62 from Seattle to Petropavlovsk-Kamchatsky, USSR in 1989. Petropavlovsk-Kamchatsky was one of the most important and secretive air and submarine bases in the USSR. ref \"Who the Hell is Bob?\" pages 255-260; 278-280\n\nStankevičius was killed in the crash of a Sukhoi Su-27 fighter, '14 Red', at the Salgareda Air Show at Treviso, Italy on 9 September 1990. Footage: https://www.youtube.com/watch?v=4wlnnZZsx2k\nStankevičius is buried in Kaunas, Lithuania.\n"}
{"id": "1242904", "url": "https://en.wikipedia.org/wiki?curid=1242904", "title": "SIT Graduate Institute", "text": "SIT Graduate Institute\n\nSIT Graduate Institute (formally, the School for International Training) is an accredited institution of higher education administered by World Learning, a non-profit international development and education organization. The Graduate Institute offers master's degrees and graduate certificates in a variety of fields related to international education and sustainable development. Located in Brattleboro, Vermont, the school also maintains a branch campus in downtown Washington, D.C.\n\nThe School for International Training (SIT) was established in 1964. SIT filled a need of returned Peace Corps volunteers by offering a graduate degree in international development. The Vermont campus originally consisted of a small collection of dorms around a Carriage House on a scenic farm on the north end of Brattleboro. These early Peace Corps volunteers took lessons in foreign languages with materials and teachers from the language training from their service, and The School for International Training began to expand its offerings. By 1968, the small but increasing number of returned Peace Corps volunteers were requesting a degree in Teaching English as a Second Language, a new specialty. In 1969, two graduate programs were developed, International Career Training (ICT), and Masters in Teaching Languages (MAT) (French, Spanish and ESL). An undergraduate program, the World Issues Program (WIP), was developed in 1973 and resulted in 26 graduating classes. The WIP program was based on an experiential learning model. Students received their BA in International or Community Development, and International Studies. The last WIP class graduated in 1999.\n\nThe first MAT class consisted of three students, the second of 28 students, and the third of 38; in the fourth year the class size reached 50 students and stayed there for many years. ICTs spent part of their program on campus and part in internships around the world. MATs originally went to Mexico or Quebec for student teaching but by 1972, students began to develop other sites around the world. Eventually, the ICT program changed to PIM: Programs in Intercultural Management and developed specializations in NGS's and Civil Society, Peace and Conflict Transformation, Social Justice, Socially Responsible Management, Sustainable Development, International Education, Language and Culture, Teacher Preparation. Jody Williams, an MAT graduate, won the Nobel Prize for her work on banning land mines. Wangari Maathai, former Trustee Emerita, won the Nobel Peace Prize for her work on sustainable development and democracy in Kenya.\n\nIn the late 1990s the MAT department created the Teacher Knowledge Project as a way for teachers to work together using the reflective cycle (to inquire into their practice) and principles of Experiential Learning. This project resulted in research in schools in New England focusing on reflective teaching, mentoring and structured language immersion. Other offshoots of the MAT program include a four-week TESOL Certificate program that offers basic preparation for teaching English as a second or foreign language and the ACCESS program that helps content teachers develop skills for working with English language learners in their classes.\n\nOver the years, the School for International Training hosted and worked with Nord-Amerika Somera Kursaro (NASK), BRAC, OTEP, USAID and other international groups through the World Learning network.\n\nSIT Graduate Institute offers Master of Arts degrees in the following fields:\n\nThree graduate certificate programs also are offered.\n\nThe school head is Dean Kenneth Williams, a specialist in \"organization and leadership\". The school's website currently lists 19 core faculty members, including six department chairs and one program director; as well as senior practitioners and adjunct faculty.\n\nThe SIT Graduate Institute is accredited by the Commission on Institutions of Higher Education of the New England Association of Schools and Colleges. Initially accredited in 1974, the institute's most recent accreditation was issued in 2014 and its next review for accreditation will take place in 2022.\n\nUS Federal education statistics reporting continues under the name, School for International Training, but may include data in some respects (perhaps financial, but apparently not enrollment) for SIT Study Abroad, as well.\n\n\n\n"}
{"id": "1240502", "url": "https://en.wikipedia.org/wiki?curid=1240502", "title": "Scotochromogenic", "text": "Scotochromogenic\n\nScotochromogenic bacteria develop pigment in the dark. Runyon Group II nontuberculous mycobacteria are examples but the term could apply to many other organisms.\n"}
{"id": "52231152", "url": "https://en.wikipedia.org/wiki?curid=52231152", "title": "Sheila Tinney", "text": "Sheila Tinney\n\nSheila Christina Tinney (\"née\" Power, 15 January 1918 – 27 March 2010) was an Irish mathematical physicist. Her 1941 PhD from the University of Edinburgh, completed under the supervision of Max Born in just two years, is believed to make her the first Irish-born and -raised woman to receive a doctorate in the mathematical sciences.\n\nSheila Christina Power was the fourth of six children born in Galway city to Michael Power (aka Mícheál de Paor, originally from rural Kilkenny, Chair of Mathematics at University College Galway from 1912–1955) and Christina Cunniffe (who died in childbirth when Sheila was 12). She was educated by the Dominican nuns, both in Galway and in Dublin, and was awarded Honours in Mathematics in the Leaving Certificate Examination (the nation's secondary school exit exam), one of only 8 girls to do so in the whole country. After one year attending UCG, she switched to University College Dublin, from which she graduated with a BSc in 1938, with First Class Honours in Mathematics, and ranked at the top of her class. She did her Master's at UCD in 1939, and was subsequently awarded a National University of Ireland travelling studentship, which enabled her to undertake research at the University of Edinburgh in Scotland. Two years later, in 1941, she earned her doctorate under the supervision of the celebrated physicist Max Born on the stability of crystal lattices.\n\nReturning to Dublin, she became an assistant lecturer at University College Dublin, and was also one of the first three scholars appointed to the brand new Dublin Institute for Advanced Studies (DIAS), in October 1941. While at the DIAS she worked with Paul Dirac, Arthur Eddington and Erwin Schrödinger. She developed a great interest in quantum physics, and wrote papers with Schrödinger, Hideki Yukawa, and Walter Heitler. From September 1948 to June 1949 she took a leave of absence from UCD and was a visiting scholar at the Institute for Advanced Study in Princeton where worked in an environment that included Freeman Dyson, Hermann Weyl, Harish-Chandra, and Albert Einstein.\n\nShe developed the first mathematical courses on quantum mechanics at UCD and taught the subject to generations of students there, until her early retirement in 1979.\n\nIn 1952, she married Seán Tinney, a former engineering student she had lectured, and the couple's three children include classical pianist Hugh Tinney.\n\nBy 1900 the campaign for the acceptance of women in academia was largely successful, and even Trinity College Dublin began admitting women in 1904. But the Royal Irish Academy (RIA) threw up legal obstacles and did not bow to the inevitable until 1949 when it finally admitted four women–one of them Sheila Tinney. In 2016 the RIA honoured Tinney by hanging her portrait along with 11 other female academic leaders on its walls.\n\nEven at University College Dublin, Tinney faced the entrenched prejudice against women. One professor emeritus recalls the sympathy she received when, early in her career, she was passed over for promotion in favour of a younger, and demonstrably less academically qualified, male colleague. During her time at UCD she gained a reputation for helping younger female colleagues who were trying to develop their careers.\n\nThe special medal cast for the 25 Global Winners of The Undergraduate Awards in 2016 (presented 10 November in Dublin) honoured Sheila Tinney, \"trail-blazing and brilliant academic, who achieved astounding success through self-belief and determination.\" In August 2018, a plaque was unveiled in UCD in honour of Tinney.\n\n"}
{"id": "49150216", "url": "https://en.wikipedia.org/wiki?curid=49150216", "title": "Social and Behavioral Sciences Team", "text": "Social and Behavioral Sciences Team\n\nThe Social and Behavioral Sciences Team (SBST) was established in the US by Executive Order #13707 on September 15, 2015.\n\nThe Social and Behavioral Sciences Team is a group of experts in applied behavioral science that translates findings and methods from the social and behavioral sciences into improvements in Federal policies and programs for the benefit of the American people. The SBST is chaired by the White House Office of Science and Technology Policy (OSTP) and represents a dozen member agencies across the Federal Government, as well as offices within the Executive Office of the President. SBST also receives critical support from the General Services Administration. The Executive Order charges SBST with providing advice and policy guidance to Federal agencies in support of the order.\n\nThe team was chaired by Maya Shankar Ph.D. \"The goal is to help people who want to take a given step but may face some barriers,\" commented Maya. The team is no longer active as of January 21, 2017, with employees having left to other agencies or organizations. \n\nThe SBST aimed to apply insights from social and behavioral science to policy It has helped connect veterans with employment and educational counseling benefits and helped struggling student borrowers understand their loan repayment options.\n"}
{"id": "743576", "url": "https://en.wikipedia.org/wiki?curid=743576", "title": "SpaceShipOne flight 14P", "text": "SpaceShipOne flight 14P\n\nFlight 14P of SpaceShipOne was its third powered flight, which occurred on May 13, 2004. The pilot was Mike Melvill.\n\nSpaceShipOne was released from White Knight at an altitude of 46,000 feet (14.0 km) and a speed of 120 knots (62 m/s). After ten seconds the rocket was lit, for a 55 second burn.\n\nAt burn-out the altitude was 150,000 feet (45.7 km) and the Mach number was 2.5. The craft then coasted to an apogee altitude of 211,400 feet (64.3 km).\n\nAt one point during the flight, the avionics computer froze up and had to be rebooted. Melvill flew the aircraft manually until the computer became operable again.\n\nDuring reentry, the craft attained Mach 1.9 and deceleration of 3.5 \"g\" (34 m/s²). The craft switched to glider configuration at 55,000 feet (17.4 km). The craft returned to the spaceport and landed safely.\n\n"}
{"id": "30423282", "url": "https://en.wikipedia.org/wiki?curid=30423282", "title": "Variable and attribute (research)", "text": "Variable and attribute (research)\n\nIn science and research, an attribute is a characteristic of an object (person, thing, etc.). Attributes are closely related to variables. A variable is a logical set of attributes. Variables can \"vary\" - for example, be high or low. How high, or how low, is determined by the value of the attribute (and in fact, an attribute could be just the word \"low\" or \"high\"). \"(For example see: Binary option)\"\n\nWhile an attribute is often intuitive, the variable is the operationalized way in which the attribute is represented for further data processing. In data processing data are often represented by a combination of \"items\" (objects organized in rows), and multiple variables (organized in columns).\n\nValues of each variable statistically \"vary\" (or are distributed) across the variable's domain. A domain is a set of all possible values that a variable is allowed to have. The values are ordered in a logical way and must be defined for each variable. Domains can be bigger or smaller. The smallest possible domains have those variables that can only have two values, also called \"binary\" (or dichotomous) variables. Bigger domains have \"non-dichotomous\" variables and the ones with a higher level of measurement. (See also domain of discourse.)\n\nSemantically, greater precision can be obtained when considering an object's characteristics by distinguishing 'attributes' (characteristics that are attributed to an object) from 'traits' (characteristics that are inherent to the object).\n\nAge is an attribute that can be operationalized in many ways. It can be dichotomized so that only two values - \"old\" and \"young\" - are allowed for further data processing. In this case the attribute \"age\" is operationalized as a binary variable. If more than two values are possible and they can be ordered, the attribute is represented by ordinal variable, such as \"young\", \"middle age\", and \"old\". Next it can be made of rational values, such as 1, 2, 3... 99\n\nThe \"social class\" attribute can be operationalized in similar ways as age, including \"lower\", \"middle\" and \"upper class\" and each class could be differentiated between upper and lower, transforming thus changing the three attributes into six (see the model proposed by William Lloyd Warner) or it could use different terminology (such as the working class as in the model by Gilbert and Kahl).\n\n"}
{"id": "43218", "url": "https://en.wikipedia.org/wiki?curid=43218", "title": "Zipf's law", "text": "Zipf's law\n\n</math> where \"H\" is the \"N\"th generalized harmonic number|\nZipf's law () is an empirical law formulated using mathematical statistics that refers to the fact that many types of data studied in the physical and social sciences can be approximated with a Zipfian distribution, one of a family of related discrete power law probability distributions. \"Zipf distribution\" is related to the zeta distribution, but is not identical.\n\nFor example, Zipf's law states that given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.: the rank-frequency distribution is an inverse relation. For example, in the Brown Corpus of American English text, the word \"the\" is the most frequently occurring word, and by itself accounts for nearly 7% of all word occurrences (69,971 out of slightly over 1 million). True to Zipf's Law, the second-place word \"of\" accounts for slightly over 3.5% of words (36,411 occurrences), followed by \"and\" (28,852). Only 135 vocabulary items are needed to account for half the Brown Corpus.\n\nThe law is named after the American linguist George Kingsley Zipf (1902–1950), who popularized it and sought to explain it (Zipf 1935, 1949), though he did not claim to have originated it. The French stenographer Jean-Baptiste Estoup (1868–1950) appears to have noticed the regularity before Zipf. It was also noted in 1913 by German physicist Felix Auerbach (1856–1933).\n\nThe same relationship occurs in many other rankings unrelated to language, such as the population ranks of cities in various countries, corporation sizes, income rankings, ranks of number of people watching the same TV channel, and so on. The appearance of the distribution in rankings of cities by population was first noticed by Felix Auerbach in 1913. Empirically, a data set can be tested to see whether Zipf's law applies by checking the goodness of fit of an empirical distribution to the hypothesized power law distribution with a Kolmogorov–Smirnov test, and then comparing the (log) likelihood ratio of the power law distribution to alternative distributions like an exponential distribution or lognormal distribution. When Zipf's law is checked for cities, a better fit has been found with exponent \"s\" = 1.07; i.e. the formula_8 largest settlement is formula_9 the size of the largest settlement.\n\nZipf's law is most easily observed by plotting the data on a log-log graph, with the axes being log (rank order) and log (frequency). For example, the word \"the\" (as described above) would appear at \"x\" = log(1), \"y\" = log(69971). It is also possible to plot reciprocal rank against frequency or reciprocal frequency or interword interval against rank. The data conform to Zipf's law to the extent that the plot is linear.\n\nFormally, let:\nZipf's law then predicts that out of a population of \"N\" elements, the normalized frequency of elements of rank \"k\", \"f\"(\"k\";\"s\",\"N\"), is:\n\nZipf's law holds if the number of elements with a given frequency is a random variable with power law distribution formula_11\n\nIt has been claimed that this representation of Zipf's law is more suitable for statistical testing, and in this way it has been analyzed in more than 30,000 English texts. The goodness-of-fit tests yield that only about 15% of the texts are statistically compatible with this form of Zipf's law. Slight variations in the definition of Zipf's law can increase this percentage up to close to 50%.\n\nIn the example of the frequency of words in the English language, \"N\" is the number of words in the English language and, if we use the classic version of Zipf's law, the exponent \"s\" is 1. \"f\"(\"k\"; \"s\",\"N\") will then be the fraction of the time the \"k\"th most common word occurs.\n\nThe law may also be written:\n\nwhere \"H\" is the \"N\"th generalized harmonic number.\n\nThe simplest case of Zipf's law is a \"⁄ function.\" Given a set of Zipfian distributed frequencies, sorted from most common to least common, the second most common frequency will occur ½ as often as the first. The third most common frequency will occur ⅓ as often as the first. The fourth most common frequency will occur ¼ as often as the first. The \"n\" most common frequency will occur ⁄ as often as the first. However, this cannot hold exactly, because items must occur an integer number of times; there cannot be 2.5 occurrences of a word. Nevertheless, over fairly wide ranges, and to a fairly good approximation, many natural phenomena obey Zipf's law.\n\nIn human languages, word frequencies have a very heavy-tailed distribution, and can therefore be modeled reasonably well by a Zipf distribution with an \"s\" close to 1.\n\nAs long as the exponent \"s\" exceeds 1, it is possible for such a law to hold with infinitely many words, since if \"s\" > 1 then\nwhere \"ζ\" is Riemann's zeta function.\n\nAlthough Zipf’s Law holds for all languages, even non-natural ones like Esperanto, the reason is still not well understood. However, it may be partially explained by the statistical analysis of randomly generated texts. Wentian Li has shown that in a document in which each character has been chosen randomly from a uniform distribution of all letters (plus a space character), the \"words\" follow the general trend of Zipf's law (appearing approximately linear on log-log plot). Vitold Belevitch in a paper, \"On the Statistical Laws of Linguistic Distribution\" offered a mathematical derivation. He took a large class of well-behaved statistical distributions (not only the normal distribution) and expressed them in terms of rank. He then expanded each expression into a Taylor series. In every case Belevitch obtained the remarkable result that a first-order truncation of the series resulted in Zipf's law. Further, a second-order truncation of the Taylor series resulted in Mandelbrot's law.\n\nThe principle of least effort is another possible explanation:\nZipf himself proposed that neither speakers nor hearers using a given language want to work any harder than necessary to reach understanding, and the process that results in approximately equal distribution of effort leads to the observed Zipf distribution. \n\nSimilarly, preferential attachment (intuitively, \"the rich get richer\" or \"success breeds success\") that results in the Yule–Simon distribution has been shown to fit word frequency versus rank in language and population versus city rank better than Zipf's law. It was originally derived to explain population versus rank in species by Yule, and applied to cities by Simon.\n\n\"Zipf's law\" in fact refers more generally to frequency distributions of \"rank data,\" in which the relative frequency of the \"n\"th-ranked item is given by the Zeta distribution, 1/(\"n\"\"ζ\"(\"s\")), where the parameter \"s\" > 1 indexes the members of this family of probability distributions. Indeed, \"Zipf's law\" is sometimes synonymous with \"zeta distribution,\" since probability distributions are sometimes called \"laws\". This distribution is sometimes called the Zipfian distribution.\n\nA generalization of Zipf's law is the Zipf–Mandelbrot law, proposed by Benoît Mandelbrot, whose frequencies are:\n\nThe \"constant\" is the reciprocal of the Hurwitz zeta function evaluated at \"s\". In practice, as easily observable in distribution plots for large corpora, the observed distribution can be modelled more accurately as a sum of separate distributions for different subsets or subtypes of words that follow different parameterizations of the Zipf–Mandelbrot distribution, in particular the closed class of functional words exhibit \"s\" lower than 1, while open-ended vocabulary growth with document size and corpus size require \"s\" greater than 1 for convergence of the Generalized Harmonic Series.\n\nZipfian distributions can be obtained from Pareto distributions by an exchange of variables.\n\nThe Zipf distribution is sometimes called the discrete Pareto distribution because it is analogous to the continuous Pareto distribution in the same way that the discrete uniform distribution is analogous to the continuous uniform distribution.\n\nThe tail frequencies of the Yule–Simon distribution are approximately\n\nfor any choice of \"ρ\" > 0.\n\nIn the parabolic fractal distribution, the logarithm of the frequency is a quadratic polynomial of the logarithm of the rank. This can markedly improve the fit over a simple power-law relationship. Like fractal dimension, it is possible to calculate Zipf dimension, which is a useful parameter in the analysis of texts.\n\nIt has been argued that Benford's law is a special bounded case of Zipf's law, with the connection between these two laws being explained by their both originating from scale invariant functional relations from statistical physics and critical phenomena. The ratios of probabilities in Benford's law are not constant. The leading digits of data satisfying Zipf's law with s = 1 satisfy Benford's law.\nIn information theory, a symbol (event, signal) of probability formula_16 contains formula_17 bits of information. Hence, Zipf law for natural numbers: formula_18 is equivalent with number formula_19 containing formula_20 bits of information. To add information from a symbol of probability formula_16 into information already stored in a natural number formula_19, we should go to formula_23 such that formula_24, or equivalently formula_25. For instance, in standard binary system we would have formula_26, what is optimal for formula_27 probability distribution. Using formula_25 rule for a general probability distribution is the base of Asymmetric Numeral Systems family of entropy coding methods used in data compression, which state distribution is also governed by Zipf law.\n\nZipf's law also has been used for extraction of parallel fragments of texts out of comparable corpora.\n\nPrimary:\nSecondary:\nInternational Conference on Bioinformatics Computational Biology: 2011.\n\n"}
