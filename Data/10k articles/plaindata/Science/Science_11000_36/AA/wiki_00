{"id": "2590921", "url": "https://en.wikipedia.org/wiki?curid=2590921", "title": "Animal engine", "text": "Animal engine\n\nAn animal engine is a machine powered by an animal. Horses, donkeys, oxen, dogs, and humans have all been used in this way.\n\n"}
{"id": "59188554", "url": "https://en.wikipedia.org/wiki?curid=59188554", "title": "Aridibacter famidurans", "text": "Aridibacter famidurans\n\nAridibacter famidurans is a non-motile bacterium from the genus of \"Aridibacter\" which has been isolated from clayey sand from Erichsfelde in Namibia.\n"}
{"id": "10037743", "url": "https://en.wikipedia.org/wiki?curid=10037743", "title": "Association theory", "text": "Association theory\n\nAssociation theory (also aggregate theory) is a discredited theory first advanced by chemist Thomas Graham in 1861 to describe the molecular structure of substances such as cellulose and starch, now understood to be polymers. Association theory postulates that such materials are composed of a collection of smaller molecules bound together by an unknown force. Graham termed these materials colloids. Prior to the development of macromolecular theory by Hermann Staudinger in the 1920s, association theory remained the most prevalent model of polymer structure in the scientific community.\n\n"}
{"id": "53179838", "url": "https://en.wikipedia.org/wiki?curid=53179838", "title": "Atanas Skatov", "text": "Atanas Skatov\n\nAtanas Georgiev Skatov (Dimitrov until 2009) is a Bulgarian alpinist, vegan, agronomist in plant protection, entomologist and ecologist. He is the first known vegan climber to have climbed Everest, on 24 May 2014. Currently, he is attempting to scale the 14 highest summits on Earth as a vegan, and has climbed five of the fourteen eight–thousanders: Mount Everest north and south, Manaslu, Annapurna, Makalu, and Lhotse.\n\nOn 20 June 2017 Atanas Skatov climbed solo in alpine style Denali peak in Alaska and became the world's first vegan who climbed the Seven Summits. \n\nOn 13 May 2018 Atanas Skatov climbed solo with out supplemental oxygen Cho Oyu, 8201m. \n\nAtanas Skatov was born on 11 March, 1978 in Sliven, Bulgaria. In 2001, he graduated with distinction from the Agricultural University in Plovdiv, Bulgaria and holds a master's degree in plant protection. During his study he gained two scholarships, allowing him to study for two semesters at Humboldt University, Berlin, Germany. From 2001–2004, he was a full-time PhD student, in the departments of both horticulture and phytomedicine (plant protection). In February 2005, he was awarded a Doctorate degree in Agricultural Science after successfully presenting his dissertation on “Integrated Tomato Production (\"Lycopersicon esculentum\") in a glasshouse with an emphasis on integrated and biological pest control against the greenhouse whitefly (\"Trialeurodes vaporariorum westwood\")”.\n\nIn 2015, he published his first book \"The Mother Goddess of the Universe\". At the same time his first documentary movie: \"Skatov, The Experiment, Episode 1: The First Vegan on Everest\" was released. Skatov has published many scientific articles in Bulgaria and abroad, including instructions for the National Service for Plant Protection. He conducts presentations and motivational meetings. He has been interviewed more than 100 times regarding his latest project: Climbing the 14 highest summits on the planet without consumption of food of animal origin.\n\nSkatov has one son, born in 2009.\n\nSkatov says he had never been on a mountain until 2010, and before 2012 had never been an active sports person. Without passing even a basic mountaineering or climbing training program, he became the first known person of the world on a vegan diet who climbed the highest summits on six of the continents in less than two years, climbing four eight – thousanders in a week apiece. He is the first Bulgarian mountaineer taking part in four expeditions to climb eight-thousanders in a single season.\n\nSkatov became a vegan January 2012, and decided to put on test this kind of diet by climbing the highest summits of each continent in the world, testing his physical and mental endurance. He has chosen the high-altitude mountaineering as it allows a human being to put his physical and mental health under intense pressure.\n\nIn 2015, Skatov was awarded a “Honorary Citizen” of Sliven, Bulgaria.\n\nDr. Skatov has conducted scientific researches in areas such as: \n\nAt 14 years of age, as a school boy at the Gymnasium of Electronics and Electrical Engineering in Sliven, he dreamed of completing Bulgaria’s longest high-mountain hiking trail from Kom to Emine (650 km). This dream came true 18 years later, in the summer of 2010. In his childhood, until he the age of 18, he had been part of the prominent folklore dance ensemble “Trakiyche”. Until 2012, he had never participated in any sports competitions. He started in the summer of 2010, when for the first time he hiked the Kom-Emine trail. Later in 2011 and 2012 repeated the hike, captivated by the magic of the mountain. In the mountains, he considered what could be done for the safety of the planet. Since 2000, he was concerned that the world's population is constantly growing and that agricultural areas are limited. \n\nAt the end of 2011, he had the idea to become a vegan and to climb the highest peaks on all continents as well as all eight–thousanders as a vegan. In that way, he combined veganism and alpinism in his first Project: Climbing the highest peaks on all seven continents as a vegan. In less than two years he reached the highest summits of all seven continents. \n\nSkatov is self-educated in the subject of climbing and alpinism. He does not conduct preliminary research on a given peak prior to the expedition, in order to feel the spirit of the pioneers who hadn’t known what to expect while climbing.\n\nIn 2015, he launched his second project: climbing the 14 highest summits on the planet, the \"Crown of the Himalaya” without consumption of food of animal origin (including an expedition to the eighth highest peak on the planet – Manaslu, 8163 m., which had not been climbed by a Bulgarian before). Only Skatov, from all the alpinists present in the autumn of 2015, made three consecutive attempts to attack the peak and on 1 October 2015 at 5:50 am he reached the peak. Only a few hours prior, another Bulgarian alpinist had climbed the summit in his first attempt. Skatov then became the second Bulgarian and possibly the second vegan in the world to have climbed Manaslu.\n\nIn 2016, Skatov took part in three expeditions for climbing eight-thousanders in Himalayas before monsoons in spring, which no other Bulgarian had done before and there are just a few similar cases in the world. On 16 April he reached 7700 m. of Annapurna I, 8091 m. with another five alpinists, but due to the bad weather is forced to went down to the Base Camp. However, on 1 May 2016 he climbed successfully the tenth highest summit on the planet – Annapurna I, which is the deadliest one, possibly being the first vegan to step on the peak of Annapurna. Immediately after Annapurna, he tried to climb Dhaulagiri, 8172 m., reaching 7900 m. in alpine style on 15 May 2016. He didn’t have time for second attempt because he had a bigger target in mind, the fifth highest peak in the world – Makalu, 8485 m. \n\nHaving only one day to rest, after Dhaulagiri he aimed at Makalu and for only one night at Base Camp, started his climb at Makalu, in alpine style. On 23 May, at 12:00 pm, Skatov became the first known vegan to climb Makalu and, according to the data provided by his fellow mountaineers, he accomplished the fastest expedition to Makalu, for just 96 hours with only one night at the Base Camp before the attack. Thus, for 23 days he participated in three expeditions on eight-thousenders, as two of them in alpine style in less than a week, for the first time in the world from a Bulgarian and a known vegan.\n\nTwo weeks after his return from 80-days triple expedition in Nepal, on 15 June 2016 Skatov flew to Pakistan, where he joined in an expedition to Gasherbrum I and Gasherbrum II. For Skatov, it is important to constantly pursue the limits of his physical and mental strength while on a vegan diet. After almost a month on Base Camp Gasherbrum, time spent for acclimatization, on 21 July, he headed towards Camp I at Gasherbrum II. On 22 July, a snow started to fall for 26 hours nonstop, so on 23 July, Skatov went down to Base Camp and suspended the expedition.\n\nIn conclusion, for 2016, Atanas Skatov participated in four expeditions above 8 000 meters, which hasn’t been done by any other known vegan or a Bulgarian. Atanas Skatov considers that examining the vegan diet is the most prominent scientific research, he has ever done. In January 2017, he marked six years of the beginning of his vegan lifestyle which he says he has no intention to change. He is regularly subject to blood tests, checking the important for a human being indices. Additionally, he maintains a diary regarding sport activities and his mental health.\n\nIn 2017, Skatov took part in two expeditions for climbing eight-thousanders in Himalayas before monsoons. On 16 May 2017 he climbed successfully the fourth highest summit on the planet -Lhotse, 8516m. Only 5 days later Skatov climbed successfully on 22 May Everest, 8848 for second time, but now from south side. So Atanas Skatov is the first Bulgarian, who climbed Mount Everest from north and from south ridges. \n\nAfter Lhotse and Everest, Skatov climbed solo in alpine style on 20 June 2017his last one of Seven summits-Denali, 6197m. \n"}
{"id": "47362225", "url": "https://en.wikipedia.org/wiki?curid=47362225", "title": "Beyond Star Trek", "text": "Beyond Star Trek\n\nBeyond Star Trek: Physics from Alien Invasions to the End of Time is the fourth non-fiction book by the American theoretical physicist Lawrence M. Krauss. The book was initially published on November 7, 1997 by Basic Books and since then has appeared in five foreign editions.In his previous work, \"The Physics of Star Trek\", Lawrence Krauss explained a number of ideas and concepts featured in the series; they may or may not exist in our universe. In this book, Krauss goes farther to discuss the realities of physics when it is applied to components from other sci-fi story lines.\n\nA reviewer of \"Kirkus Reviews\" wrote \"The author...scored a bestseller with his previous book, \"The Physics of Star Trek\" (1995). Now he expands his scope to address other sci-fi hits, ranging from the film \"\" to TV's \"The X-Files\". He also scrutinizes such newsworthy events as the chess match between world champion Garry Kasparov and an IBM computer. Krauss begins by examining the alien attack on Earth that was portrayed in the movie \"Independence Day\". He uses basic Newtonian physics to show that the gravitational effects of the huge arriving alien ships would have caused floods and earthquakes sufficient to destroy our civilization before the invaders had even fired a shot. Next, the author assesses the supposed flight characteristics of UFOs, depicted as stopping on a dime and making sudden sharp turns at utterly unbelievable speeds. Krauss calculates that these maneuvers would create inertial G-forces greater than a close-range nuclear explosion; neither the pilots nor any conceivable construction material could withstand them. Another chapter examines the cost of mounting an interstellar expedition, a journey that would require many decades to complete and cost more than the moon. Later chapters apply the principle of general relativity to star travel, explore computer consciousness, and forecast the end of the world. The book concludes by affirming the author's belief that the universe is a place of boundless potential--and that we must fathom it.\"\n\n\n"}
{"id": "3889124", "url": "https://en.wikipedia.org/wiki?curid=3889124", "title": "Boyana Glacier", "text": "Boyana Glacier\n\nBoyana Glacier (Lednik Boyana \\'led-nik bo-'ya-na\\) in Levski Ridge, Tangra Mountains on Livingston Island, South Shetland Islands in Antarctica is situated southeast of Macy Glacier and west-southwest of Srebarna Glacier. It is bounded by Vazov Rock on the west, St. Naum Peak, Starosel Gate, Silistra Knoll and Kotel Gap on the north, and Christoff Cliff on the east. The glacier extends 3 km in east-west direction and 1.6 km in north-south direction, and flows southeastward into the Bransfield Strait between Vazov Point and Aytos Point.\n\nThe feature is named after the Bulgarian settlement of Boyana, now part of Sofia.\n\nThe glacier is centred at . Bulgarian mapping in 2005 and 2009.\n\n\n\n"}
{"id": "9668147", "url": "https://en.wikipedia.org/wiki?curid=9668147", "title": "Campbell's law", "text": "Campbell's law\n\nCampbell's law is an adage developed by Donald T. Campbell, a psychologist and social scientist who often wrote about research methodology, which states \"The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor.\" (p. 85) On a similar note, Campbell also wrote:Achievement tests may well be valuable indicators of general school achievement \"under conditions of normal teaching aimed at general competence.\" But when test scores become the goal of the teaching process, they both lose their value as indicators of educational status and distort the educational process in undesirable ways. (Similar biases of course surround the use of objective tests in courses or as entrance examinations.)Campbell's law can be seen as an example of the cobra effect. The social science principle of Campbell's law is sometimes used to point out the negative consequences of high-stakes testing in U.S. classrooms. This may take the form of teaching to the test or outright cheating. An example is \"The High-Stakes Education Rule\" as described in the \"Learning-Disadvantage Gap\".\n\nThere are closely related ideas known by different names, such as Goodhart's law and the Lucas critique. Another concept related to Campbell's law emerged in 2006 when UK researchers Rebecca Boden and Debbie Epstein published an analysis of evidence-based policy, a practice espoused by Prime Minister Tony Blair. In the paper, Boden and Epstein described how a government that tries to base its policy on evidence can actually end up producing corrupted data because it \"seeks to capture and control the knowledge producing processes to the point where this type of 'research' might best be described as 'policy-based evidence'.\"\n\nWhen someone distorts decisions in order to improve the performance measure, they often surrogate, coming to believe that the measure is a better measure of true performance than it really is.\n\nCampbell’s Law imparts a more positive but complicated message. It is important to measure progress making use of quantitative and qualitative indicators. However, utilizing quantitative data for evaluation can distort and manipulate these indicators. Concrete measures must be adopted to reduce alteration and manipulation of information. In his article, “Assessing the Impact of Planned Social Change”, Campbell emphasized that “\"the more quantitative social indicator used for social decision-making is subjected to corruption pressure and liable to distort and damage social processes it meant to monitor\".” Campbell’s Law helps people discern that the No Child Left Behind and Race to the Top statutes can impair education.\n\n\n"}
{"id": "58467542", "url": "https://en.wikipedia.org/wiki?curid=58467542", "title": "Capped trigonal prismatic molecular geometry", "text": "Capped trigonal prismatic molecular geometry\n\nIn chemistry, the capped trigonal prismatic molecular geometry describes the shape of compounds where seven atoms or groups of atoms or ligands are arranged around a central atom defining the vertices of an augmented triangular prism. This shape has C symmetry and is one of the three common shapes for heptacoordinate transition metal complexes, along with the pentagonal bipyramid and the capped octahedron.\n\nExamples of the capped trigonal prismatic molecular geometry are the heptafluorotantalate (TaF) and the heptafluoroniobate (NbF) ions.\n"}
{"id": "32954910", "url": "https://en.wikipedia.org/wiki?curid=32954910", "title": "Chaos de Montpellier-le-Vieux", "text": "Chaos de Montpellier-le-Vieux\n\nThe Chaos de Montpellier-le-Vieux is a blockfield at the southern edge of the Causse Noir, above the Gorges de la Dourbie, north-east of Millau and its famous viaduct, in the commune of La Roque-Sainte-Marguerite, Aveyron, France.\n\nThe rocks formed from dolomite.\n\n"}
{"id": "50036569", "url": "https://en.wikipedia.org/wiki?curid=50036569", "title": "Circuit Value Problem", "text": "Circuit Value Problem\n\nThe Circuit Value Problem (or Circuit Evaluation Problem) is the computational problem of computing the output of a given Boolean circuit on a given input.\n\nThe problem is complete for P under uniform AC reductions. The Boolean Formula Value Problem (or Boolean Formula Evaluation Problem) is the special case of the problem when the circuit is a tree. The Boolean Formula Value Problem is complete for NC.\n\nThe problem is closely related to the Boolean Satisfiability Problem which is complete for NP and its complement Propositional Tautologihood Problem which is complete for co-NP.\n"}
{"id": "12763440", "url": "https://en.wikipedia.org/wiki?curid=12763440", "title": "Compaction (geology)", "text": "Compaction (geology)\n\nIn sedimentology, compaction is the process by which a sediment progressively loses its porosity due to the effects of loading. This forms part of the process of lithification. When a layer of sediment is originally deposited, it contains an open framework of particles with the pore space being usually filled with water. As more sediment is deposited above the layer, the effect of the increased loading is to increase the particle-to-particle stresses resulting in porosity reduction primarily through a more efficient packing of the particles and to a lesser extent through elastic compression and pressure solution. The initial porosity of a sediment depends on its lithology. Mudstones start with porosities of >60%, sandstones typically ~40% and carbonates sometimes as high as 70%. Results from hydrocarbon exploration wells show clear porosity reduction trends with depth.\n\nIn sediments compacted under self-weight, especially in sedimentary basins,the porosity profiles often show an exponential decrease, called Athy's law as first shown by Athy in 1930. A mathematical analytical solution was obtained by Fowler and Yang to show the theoretical basis for Athy's law. This process can be easily observed in experiments and used as a good approximation to many real data.\n\nIf there is a variation in thickness and compactability of a sequence, loading by later deposits will give rise to spatially varying amounts of compaction. This form of compactation is a function of the lithology of the base sediment. Both the thickness and structure of the later sequence will be controlled by the underlying geology in the absence of any active tectonics. Buried tilted fault blocks in a rift basin often produce large anticlinal closures in the post-rift section that may form traps for hydrocarbons e.g. the Daqing Field, the largest oil field in the People's Republic of China (PRC), in the Songliao Basin.\n"}
{"id": "39059578", "url": "https://en.wikipedia.org/wiki?curid=39059578", "title": "Computer Atlas of Surface Topology of Proteins", "text": "Computer Atlas of Surface Topology of Proteins\n\nComputer Atlas of Surface Topology of Proteins (CASTp) aims to provide comprehensive and detailed quantitative characterization of topographic features of protein, is now updated to version 3.0. Since its release in 2006, the CASTp server has ∼ 45 000 visits and fulfills ∼ 33 000 calculation requests annually. CASTp has been proven as a confident tool for a wide range of researches, including investigations of signaling receptors, discoveries of cancer therapeutics, understanding of mechanism of drug actions, studies of immune disorder diseases, analysis of protein–nanoparticle interactions, inference of protein functions and development of high-throughput computational tools. This server is maintained by Jie Liang's lab in University of Illinois at Chicago.\n\nFor the calculation strategy of CASTp, alpha-shape and discrete-flow methods are applied to the protein binding site, also the measurement of pocket size by the program of CAST by Liang et al in 1998, then updated by Tian et al in 2018. Firstly, CAST identifies atoms which form the protein pocket, then calculates the volume and area, identifies the atoms forming the rims of pocket mouth, computes how many mouth openings for each pocket, predict the area and circumference of mouth openings, finally locates cavities and calculate their size. The secondary structures were calculated by DSSP. The single amino acid annotations were fetched from UniProt database, then mapped to PDB structures following residue-level information from SIFTS database.\n\n3.1 Input\n\nProtein structures in PDB format, and a probe radius.\n\n3.2 Searching\n\nUsers can either search for pre-computed result by 4-letter PDB ID, or upload their own PDB file for customized computation. The core algorithm helps in finding the pocket or cavity with capability of housing a solvent, with a default or adjusted diameter.  \n\n3.3 Output\n\nCASTp identifies all surface pockets, interior cavities and cross channels, provides detailed delineation of all atoms participating in their formation, including the area and volume of pocket or void as well as measurement of numbers of mouth opening of a particular pocket ID by solvent accessible surface model (Richards' surface) and by molecular surface model (Connolly surface), all calculated analytically. The core algorithm helps in finding the pocket or cavity with capability of housing a solvent with a diameter of 1.4 Å. This online tool also supports PyMOL and UCSF Chimera plugin for molecular visualization.\n\n4.1 Protein science, from an amino acid to sequences and structures\n\nProteins are large, complex molecules that playing critical roles to maintain the normal functioning of the human body. They are essential not just for the structure and function, but also the regulation among the body’s tissues and organs. Proteins are made up of hundreds of smaller units called amino acids that are attached to one another by peptide bonds, forming a long chain.\n\n4.2 Protein active sites\n\nUsually, the active site of a protein locates on its center of action and, the key to its function. The first step is the detection of active sites on the protein surface and an exact description of their features and boundaries. These specifications are vital inputs for subsequent target druggability prediction or target comparison. Most of the algorithms for active site detection are based on geometric modeling or energetic features based calculation.\n\n4.3 The role of protein pockets\n\nThe shape and properties of the protein surface determine what interactions are possible with ligands and other macromolecules. Pockets are an important yet ambiguous feature of this surface. During drug discovery process, the first step in screening for lead compounds and potential molecules as drugs is usually a selection of the shape of the binding pocket. Shape plays a role in many computational pharmacological methods. Based on existing results, most features important to predicting drug-binding were depended on size and shape of the binding pocket, with the chemical properties of secondary importance. The surface shape is also important for interactions between protein and water. However, defining discrete pockets or possible interaction sites still remains unclear, due to the shape and location of nearby pockets affected promiscuity and diversity of binding sites. Since most pockets are open to solvent, to define the border of a pocket is the primary difficulty. Those closed to solvent we refer to as buried cavities. With the benefit of well-defined extent, area and volume, buried cavities are more straightforward to locate. In contrast, the border of an open pocket defines its mouth and it provides the cut-off for determination of the surface area and volume. Even defining the pocket as a set of residues does not define the volume or the mouth of the pocket.\n\n4.4 Druggability role prediction\n\nIn pharmaceutical industry, the current priority strategy for target assessment is high-throughput screening (HTS). NMR screenings are applied against large compound datasets. Chemical characteristics of compounds binding against specific targets are measured, so how well the compound sets bind to the chemical space will decide the binding efficiency. Success rates of virtually docking of the drug-like ligands into the active sites of the target proteins would be detected for prioritization, while the most of the active sites located at the pockets.\n\nWith the benefits of large amount of structural data, computational methods from different perspectives for druggability prediction have been introduced during the last 30 years with positive results, as a vital instrument to accelerate the prediction accessibility.  Many candidates have been integrated into drug discovery pipeline already since then.\n\n5.1 Pre-computed results for biological assemblies\n\nFor a lot of proteins deposited in Protein Data Bank, the asymmetric unit might be different from biological unit, which would make the computational result biologically irrelevant. So the new CASTp 3.0 computed the topological features for biological assemblies, overcome the barriers between asymmetric unit and biological assemblies.\n\n5.2 Imprints of negative volumes of topological features\n\nIn the 1st release of CASTp server in 2006, only geometric and topological features of those surface atoms participated in the formation of protein pockets, cavities, and channels. The new CASTp added the “negative volume” of the space, referred to the space encompassed by the atoms formed these geometric and topological features.\n\n5.3 Comprehensive annotation on single amino-acid polymorphism\n\nThe latest CASTp integrated protein annotations aligned with the sequence, including the brief feature, positions, description, and reference of the domains, motifs, and single amino-acid polymorphisms.\n\n5.4 Improved user interface & convenient visualization\n\nThe new CASTp now incorporated 3Dmol.js for structural visualization, made users able to browse, to interact the protein 3D model, and to examine the computational results in latest web-browsers including Chrome, Firefox, Safari, et al. Users can pick their own representation style of the atoms which form each topographic feature, and to edit the colors by their own preferences.\n"}
{"id": "29392122", "url": "https://en.wikipedia.org/wiki?curid=29392122", "title": "Computer Graphics: Principles and Practice", "text": "Computer Graphics: Principles and Practice\n\nComputer Graphics: Principles and Practice is a textbook written by John F. Hughes, Andries van Dam, Morgan McGuire, David F. Sklar, James D. Foley, Steven K. Feiner, and Kurt Akeley and published by Addison–Wesley. First published in 1982 as \"Fundamentals of Interactive Computer Graphics\", it is widely considered a classic standard reference book on the topic of computer graphics. It is sometimes known as \"the bible of computer graphics\" (due to its size).\n\nThe first edition, published in 1982 and titled \"Fundamentals of Interactive Computer Graphics\", discussed the SGP library, which was based on ACM's \"SIGGRAPH CORE\" 1979 graphics standard, and focused on 2D vector graphics.\n\nThe second edition, published 1990, was completely rewritten and covered 2D and 3D raster and vector graphics, user interfaces, geometric modeling, anti-aliasing, advanced rendering algorithms and an introduction to animation. The SGP library was replaced by SRGP (\"Simple Raster Graphics Package\"), a library for 2D raster primitives and interaction handling, and SPHIGS (\"Simple PHIGS\"), a library for 3D primitives, which were specifically written for the book.\n\nIn the second edition in C all examples were converted from Pascal to C. New implementations for the SRGP and SPHIGS graphics packages in C were also provided.\n\nA third edition covering modern GPU architecture was released in July 2013. Examples in the third edition are written in C++, C#, WPF, GLSL, OpenGL, G3D, or pseudocode.\n\nThe book has won a Front Line Award (Hall of Fame) in 1998.\n"}
{"id": "1579034", "url": "https://en.wikipedia.org/wiki?curid=1579034", "title": "Coupled model intercomparison project", "text": "Coupled model intercomparison project\n\nIn climatology, the Coupled Model Intercomparison Project (CMIP) is a collaborative framework designed to improve knowledge of climate change, being the analog of Atmospheric Model Intercomparison Project (AMIP) for global coupled ocean-atmosphere general circulation models (GCMs). It was organized in 1995 by the Working Group on Coupled Modelling (WGCM) of the World Climate Research Programme’s (WCRP). It is developed in phases to foster the climate model improvements but also to support national and international assessments of climate change. \n\nThe Program for Climate Model Diagnosis and Intercomparison at Lawrence Livermore National Laboratory has been supporting the several CMIP phases by helping WGCM to determine the scope of the project, by maintaining the project's data base and by participating in data analysis. CMIP has received model output from the pre-industrial climate simulations (\"control runs\") and 1% per year increasing-CO simulations of about 30 coupled GCMs. More recent phases of the project (20C3M, ...) include more realistic scenarios of climate forcing for both historical, paleoclimate and future scenarios.\n\nAccording to Lawrence Livermore National Laboratory PCMDI, the response to the CMIP1 announcement was very successful and up to 18 global coupled models participated in the data collection representing most of the international groups with global coupled GCMs. In consequence, at the September 1996 meeting of CLIVAR NEG2 in Victoria, Canada, it was decided that CMIP2 will be an inter-comparison of 1% per year compound CO2 increase integrations (80 years in length) where CO2 doubles at around year 70. \n\nDuring 2005 and 2006, a collection of climate model outputs was coordinated and stored by PCMDI . The climate model outputs included simulations of past, present and future climate scenarios This activity enabled those climate models, outside the major modeling centers to perform research of relevance to climate scientists preparing the IPCC Fourth Assessment Report (IPCC-AR4). For the CMIP3 a list of 20 different experiments were proposed , and the PCMDI kept the documentation of all the global climate model involved . Additional information and data-sets are in . \n\nThe most recently completed phase of the project (2010-2014) is CMIP5. CMIP5 included more metadata describing model simulations than previous phases. The METAFOR project created an exhaustive schema describing the scientific, technical, and numerical aspects of CMIP runs which was archived along with the output data.\n\nA main objective of the CMIP5 experiments is to address outstanding scientific questions that arose as part of the IPCC AR4 process, improve understanding of climate, and to provide estimates of future climate change that will be useful to those considering its possible consequences. The IPCC Fifth Assessment Report summarizes information of CMIP5 experiments, while the CMIP5 experimental protocol was endorsed by the 12th Session of the WCRP Working Group on Coupled Modelling (WGCM) . Additional information and data-sets are in .\n\nPlanning meetings for Phase 6 began in 2013, and an overview of the design and organization was published in 2016. By 2018 CMIP6 had endorsed 23 Model Intercomparison Projects (MIPs) involving 33 modeling groups in 16 countries. A small number of common experiments were also planned. The deadline for submission of papers to contribute to the IPCC 6th Assessment Report Working Group I is early 2020.\n\nThe structure of the CMIP6 has been extended with respect to CMIP5 by providing an equivalent framework named CMIP Diagnostic, Evaluation and Characterization of Klima (DECK), together with a set of Endorsed MIPs to improve the description of aspects of climate models beyond the core set of common experiments included in DECK. However, CMIP-Endorsed Model Intercomparison Projects (MIPs) are still built on the DECK and CMIP historical simulations, therefore their main goal is just to address a wider range of specific questions . This structure will be kept in future CMIP experiments.\n\nCMIP6 also aims to be consistent regarding common standards and documentation. To achieve that it includes methods to facilitate a wider distribution and characterization of model outputs, and common standard tools for their analyses. A number of guides has been created for data managers, modelers and users. \n\nA set of official/common forcings datasets are available for the studies under DECK, as well as several MIPS. That allows for more sensible comparisons on the model ensemble created under the CMIP6 umbrella. \n\nThese common dataset forcings are stored and coordinated by input4MIPS (input datasets for Model Intercomparison Projects). Most of them are freely available at . \n\n\nBeyond these historical forcings, CMIP6 also has a common set of future scenarios comprising land use and emissions as required for the future Shared Socio-economic Pathway (SSP) and Representative Concentration Pathways (RCPs) .\n\n\n"}
{"id": "12102147", "url": "https://en.wikipedia.org/wiki?curid=12102147", "title": "Criticism of evolutionary psychology", "text": "Criticism of evolutionary psychology\n\nEvolutionary psychology has generated substantial controversy and criticism. The criticism includes but is not limited to: disputes about the testability of evolutionary hypotheses, alternatives to some of the cognitive assumptions (such as massive modularity) frequently employed in evolutionary psychology, alleged vagueness stemming from evolutionary assumptions (such as uncertainty about the environment of evolutionary adaptation), differing stress on the importance of non-genetic and non-adaptive explanations, and political and ethical issues.\n\nWhile evolutionary psychology has been accused of straw man evidence, ideologically rather than scientifically motivated, evolutionary psychologists respond by arguing that these criticisms are also straw men, are based on an incorrect nature versus nurture dichotomy, or are based on misunderstandings of the discipline.\n\nThe history of the debate from the critics' perspective is detailed by Gannon (2002). Critics of evolutionary psychology include the philosophers of science David Buller author of \"Adapting Minds\", Robert C. Richardson author of \"Evolutionary Psychology as Maladapted Psychology\", and Brendan Wallace, author of \"Getting Darwin Wrong: Why Evolutionary Psychology Won't Work.\" Other critics include neurobiologists like Steven Rose who edited \"Alas, Poor Darwin: Arguments against Evolutionary Psychology\", and biological anthropologists like Jonathan Marks and social anthropologists like Tim Ingold and Marshall Sahlins.\n\nThe evolutionary psychology response to critics has been covered in books by Segerstråle (2000), \"Defenders of the Truth: The Battle for Science in the Sociobiology Debate and Beyond,\" Barkow (2005), \"Missing the Revolution: Darwinism for Social Scientists,\" and Alcock (2001), \"The Triumph of Sociobiology\". See also: rebuttals to critics in Confer, et al. (2010), Tooby and Cosmides (2005), and Hagen (2005).\n\nEvolutionary psychologists have postulated that the mind is composed of cognitive modules specialized to perform specific tasks. Evolutionary psychologists have theorized that these specialized modules enabled our ancestors to react quickly and effectively to environmental challenges. As a result, domain-specific modules would have been selected for, whereas broad general-purpose cognitive mechanisms that worked more slowly would have been eliminated in the course of evolution.\n\nA number of cognitive scientists have criticized the modularity hypothesis, citing neurological evidence of brain plasticity and changes in neural networks in response to environmental stimuli and personal experiences. Steven Quartz and Terry Sejnowski, for example, have argued that the view of the brain as a collection of specialized circuits, each chosen by natural selection and built according to a \"genetic blueprint\", is contradicted by evidence that cortical development is flexible and that areas of the brain can take on different functions. Neurobiological research does not support the assumption by evolutionary psychologists that higher-level systems in the neocortex responsible for complex functions are massively modular. Peters (2013) cites neurological research showing that higher-order neocortical areas can become functionally specialized by way of synaptic plasticity and the experience-dependent changes that take place at the synapse during learning and memory. As a result of experience and learning processes the developed brain can look modular although it is not necessarily innately modular. However, Klasios (2014) responds to Peters' critique.\n\nAnother criticism is that there is little empirical support in favor of the domain-specific theory. Leading evolutionary psychologists Leda Cosmides and John Tooby have found that performance on the selection task is content-dependent: People find it easier to detect violations of \"if-then” rules when the rules can be interpreted as cheating on a social contract. From this Cosmides and Tooby and other evolutionary psychologists concluded that the mind consisted of domain-specific, context-sensitive modules (including a cheater-detection module). Critics have suggested that Cosmides and Tooby use untested evolutionary assumptions to eliminate rival reasoning theories and that their conclusions contain inferential errors. Davies et al., for example, have argued that Cosmides and Tooby did not succeed in eliminating the general-purpose theory because the adapted Wason selection task they used tested only one specific aspect of deductive reasoning and failed to examine other general-purpose reasoning mechanisms (e.g., reasoning based on syllogistic logic, predicate logic, modal logic, and inductive logic etc.). Furthermore, Cosmides and Tooby use rules that incorrectly represent genuine social exchange situations. Specifically, they posit that someone who received a benefit and does not pay the cost is cheating. However, in real-life social exchange situations people can benefit and not pay without cheating (as in the case of receiving gifts or benefiting from charity).\n\nSome critics have suggested that our genes cannot hold the information to encode the brain and all its assumed modules. Humans share a significant portion of their genome with other species and have corresponding DNA sequences so that the remaining genes must contain instructions for building specialized circuits that are absent in other mammals.\n\nOne controversy concerns the particular modularity of mind theory used in evolutionary psychology (massive modularity). Critics argue in favor of other theories.\n\nCritics have questioned the proposed innateness of certain phobias, such as fear of snakes. Recent evidence, however, suggests that Japanese macaques, and presumably other primates, have a snake-detection brain module—neurons in the preferential medial and dorsolateral pulvinar—that respond very rapidly to images of snakes, even without any prior exposure to snakes.\n\nOne method employed by evolutionary psychologists is using knowledge of the environment of evolutionary adaptedness to generate hypotheses regarding possible psychological adaptations.\n\nPart of the critique of the scientific basis of evolutionary psychology is of the concept of the environment of evolutionary adaptation. Evolutionary psychology often assumes that human evolution occurred in a uniform environment, and critics suggest that we know so little about the environment (or probably multiple environments) in which homo sapiens evolved, that explaining specific traits as an adaption to that environment becomes highly speculative.\n\nThe evolutionary psychologists John Tooby and Leda Cosmides state that research is confined to certainties about the past, such as pregnancies only occurring in women, and that humans lived in groups. They argue that there are many environmental features that are known regarding our species' evolutionary history. They argue that our hunter-gatherer ancestors dealt with predators and prey, food acquisition and sharing, mate choice, child rearing, interpersonal aggression, interpersonal assistance, diseases and a host of other fairly predictable challenges that constituted significant selection pressures. Knowledge also include things such as nomadic, kin-based lifestyle in small groups, long life for mammals, low fertility for mammals, long female pregnancy and lactation, cooperative hunting and aggression, tool use, and sexual division of labor.\n\nSome hypotheses that certain psychological traits are evolved adaptations have not been empirically corroborated.\n\nSmith et al. (2001) criticized Thornhill and Palmer's hypothesis that a predisposition to rape in certain circumstances might be an evolved sexually dismorphic psychological adaptation. They developed a fitness cost/benefit mathematical model and populated it with estimates of certain parameters (some parameter estimates were based on studies of the Aché in Paraguay). Their model suggested that, on average, the costs of rape for a typical 25-year-old male outweigh benefits by a factor of ten to one. On the basis of their model and parameter estimates, they suggested that this would make it unlikely that rape generally would have net fitness benefits for most men. They also find that rape from raiding other tribes has lower costs but does not offer net fitness benefits, making it also unlikely that was an adaptation.\n\nBeckerman et al. (2009) disputed explanations of male aggression as a reproductive strategy. In a study of the Waorani tribes, the most aggressive warriors had the fewest descendants.\n\nOthers have criticized the assertion that men universally preferred women with a waist-to-hip ratio of 0.7 or the \"hourglass\" figure. Studies of peoples in Peru and Tanzania found that men preferred ratios of 0.9. Cashdan (2008) found that in male preferences for waist-to-hip ratios varied and were correlated to economic dependence for women; societies with less economic equality such as Greece, Japan and Portugal favored lower ratios while more egalitarian societies favored higher hip ratios.\n\nRecent studies utilizing realistic stimuli, by contrast, show that men display a cross-cultural consensus in preferring a low waist-to-hip ratio (i.e., hourglass-like figure), with some fluctuation depending on whether the local ecology is nutritionally-stressed. Congenitally-blind men also display a preference for hourglass figures in women.\n\nA number of theories in evolutionary psychology that are hinged on the assumption that sheer number of calories constitute the only important bottleneck in nutrition are challenged by research on hidden hunger, types of malnutrition in which deficits of specific essential micronutrients cause diseases or even death despite a suitable number of calories. Comparisons between species show that although human brains consume more nutrients than the brains of other species, human brains consuming roughly 20% of the body's total calory requirements in adult humans and 60% in young children, there are other organs in many other species that consume more calories than their human counterparts. This means that humans do not stand out in requirements for calories at any stage of life, though human brains stand out in requiring higher amounts of many different essential nutrients while other organs in other species may require higher amounts of two or three specific micronutrients. While studies of blood flow in the brain's dura mater in fossil humans show a negligible difference in oxygen and with it caloric requirements between Neanderthals and modern humans, the fact that some Neanderthal groups in Belgium lived exclusively of large land animal meat while other Neanderthal groups in Spain lived exclusively of plants that were present there at the time with a much narrower range of nutrients than the diets vegans eat today shows that although Neanderthals were capable of varying their diets, they could also survive off non-varied diets that would cause lethal deficits in modern humans. Since many micronutrient deficits in modern humans cause neurological symptoms, this is explainable as a result of less flexible synapses in Neanderthal brains requiring lower levels of many specific mincronutrients than the highly flexible synapses of modern humans. This contradicts the claim that human females were under unique selection pressure to evolve curvy shapes for fat storage for fetal brain development, as fat would only store calories and not micronutrients which could be stored without affecting body shape and nonhuman animals with other high fetal calory requirements do not have curvy females. The claim that human females evolved large breasts to feed infants needing many calories is also challenged, empirically citing the human example that while most asian women have small breasts, asian people do not have smaller brains than other people and that explaining it away as a \"trade-off\" would be a misuse of the term as the observation is one trait (brain size) being unaffected by a dramatic reduction of another trait (breast size) as opposed to the correct definition of \"trade-off\" which is an otherwise adaptive trait being reduced by a change of something else. The distribution of essential nutrients between different types of food varied dramatically between regions in the paleolithic before the exchange of breeding stock of domestic and feral plants and animal species over long distances at the dawn of agriculture and the many micronuitrients required in higher levels by sapiens than by archaics meant that in every region, one or more types of food became narrower bottlenecks for sapiens group size than for archaic group size though the specific bottleneck food varied from region to region. This contradicts evolutionary psychology's claim that sapiens evolved in larger group sizes and since many essential nutreients are in types of food that cannot be prevented from going rancid in short times while other essential nutrients degrade fast even if the food in which they are contained does not become rancid, trade over long distances could not address the problem. The discovery of stone tools further from the origin of the stone at sapiens sites than at archaic sites is therefore not explainable by trade between tribes, but can be explained by people moving further to eat the essential nutrients and that the same movement patterns in other sapiens groups making them less capable of consistent territorial defense than archaics were, allowing sapiens to move longer and take their tools with them. It also challenges evolutionary psychology's claim of an universal exchange value of animal versus vegetable food that would have maintained an universal division of labour between hunting men and gathering women and/or a need for stable pair bonds in a context of paying for guard services with food within the tribe, as the most valuable essential micronutrient food would have been animal in some regions yet vegetable in other regions and such differences were commonly found between different localities within the relatively large part of Africa in which Homo sapiens evolved as a number of interbreeding groups.\n\nA frequent criticism of evolutionary psychology is that its hypotheses are difficult or impossible to test, challenging its status as an empirical science. As an example, critics point out that many current traits likely evolved to serve different functions from those they do now, confounding attempts to make backward inferences into history. Evolutionary psychologists acknowledge the difficulty of testing their hypotheses but assert it is nevertheless possible.\n\nCritics argue that many hypotheses put forward to explain the adaptive nature of human behavioural traits are \"just-so stories\"; neat adaptive explanations for the evolution of given traits that do not rest on any evidence beyond their own internal logic. They allege that evolutionary psychology can predict many, or even all, behaviours for a given situation, including contradictory ones. Therefore, many human behaviours will always fit some hypotheses. Noam Chomsky argued:\n\nLeda Cosmides argued in an interview:\n\nA 2010 review article by evolutionary psychologists describes how an evolutionary theory may be empirically tested. A hypothesis is made about the evolutionary cause of a psychological phenomenon or phenomena. Then the researcher makes predictions that can be tested. This involves predicting that the evolutionary cause will have caused other effects than the ones already discovered and known. Then these predictions are tested. The authors argue numerous evolutionary theories have been tested in this way and confirmed or falsified. Buller (2005) makes the point that the entire field of evolutionary psychology is never confirmed or falsified; only specific hypotheses, motivated by the general assumptions of evolutionary psychology, are testable. Accordingly, he views evolutionary psychology as a paradigm rather than a theory, and attributes this view to prominent evolutionary psychologists including Cosmides, Tooby, Buss, and Pinker.\n\nIn his review article \"Discovery and Confirmation in Evolutionary Psychology\" (in The Oxford Handbook of Philosophy of Psychology) Edouard Machery concludes:\n\nOne aspect of evolutionary psychology is finding traits that have been shown to be universal in humans. Many critics have pointed out that many traits considered universal at some stage or another by evolutionary psychologists often turn out to be dependent on cultural and particular historical circumstances. Critics allege that evolutionary psychologists tend to assume that their own current cultural context represents a universal human nature. For example, anthropologist Susan McKinnon argues that evolutionary theories of kinship rest on ethnocentric presuppositions. Evolutionary psychologists assert that the degree of genetic relatedness determines the extent of kinship (e.g., solidarity, nurturance, and altruism) because in order to maximize their own reproductive success, people \"invest\" only in their own genetic children or closely related kin. Steven Pinker, for instance, stated \"You're either someone's mother or you aren't\". McKinnon argues that such biologically centered constructions of relatedness result from a specific cultural context: the kinship category \"mother\" is relatively self-evident in Anglo-American cultures where biology is privileged but not in other societies where rank and marital status, not biology, determine who counts as a mother or where mother's sisters are also considered mothers and one's mother's brother is understood as the \"male mother\".\n\nIn a review of Pinker's book on evolutionary psychology (\"The Blank Slate\"), Louis Menand wrote: \"In general, the views that Pinker derives from 'the new sciences of human nature' are mainstream Clinton-era views: incarceration is regrettable but necessary; sexism is unacceptable, but men and women will always have different attitudes toward sex; dialogue is preferable to threats of force in defusing ethnic and nationalist conflicts; most group stereotypes are roughly correct, but we should never judge an individual by group stereotypes; rectitude is all very well, but 'noble guys tend to finish last'; and so on.\"\n\nHowever, evolutionary psychologists point out that their research actually focuses on commonalities between people of different cultures to help to identify \"human psychological nature\" and cultural universals. It is not a focus on local behavioral variation (which may sometimes be considered ethnocentric) that interests evolutionary psychologists; rather their focus is to find underlying psychological commonalities between people from various cultures.\n\nSome critics view evolutionary psychology as influenced by genetic determinism and reductionism.\n\nEvolutionary psychology is based on the theory that human physiology and psychology are influenced by genes. Evolutionary psychologists assume that genes contain instructions for building and operating an organism and that these instructions are passed from one generation to the next via genes.\n\nLickliter and Honeycutt (2003) have argued that evolutionary psychology is a predeterministic and preformationistic approach that assumes that physical and psychological traits are predetermined and programmed while virtually ignoring non-genetic factors involved in human development. Even when evolutionary psychologists acknowledge the influence of the environment, they reduce its role to that of an activator or trigger of the predetermined developmental instructions presumed to be encoded in a person's genes. Lickliter and Honeycutt have stated that the assumption of genetic determinism is most evident in the theory that learning and reasoning are governed by innate, domain-specific modules. Evolutionary psychologists assume that modules preexist individual development and lie dormant in the structure of the organism, awaiting activation by some (usually unspecified) experiential events. Lickliter and Honeycutt have opposed this view and suggested that it is the entire developmental system, including the specific features of the environment a person actually encounters and interacts with (and not the environments of distant ancestors) that brings about any modularity of cognitive function.\n\nCritics argue that a reductionist analysis of the relationship between genes and behavior results in a flawed research program and a restricted interpretation of the evidence, creating problems for the creation of models attempting to explain behavior. Lewontin, Rose & Kamin instead advocate a dialectical interpretation of behavior in which \"it is not just that wholes are more than the sum of their parts, it is that parts become qualitatively new by being parts of the whole\". They argue that reductionist explanations such as the hierarchical reductionism proposed by Richard Dawkins will cause the researcher to miss dialectical ones. Similarly, Hilary Rose criticizes evolutionary psychologists' explanations of child abuse as excessively reductionist. As an example she cites Martin Daly and Margot Wilson's theory that stepfathers are more abusive because they lack the nurturing instinct of natural parents and can increase their reproductive success in this way. According to Rose this does not explain why most stepfathers do not abuse their children and why some biological fathers do. She also argues that cultural pressures can override the genetic predisposition to nurture as in the case of sex-selective infanticide prevalent in some cultures where male offspring are favored over female offspring.\n\nEvolutionary psychologists Workman and Reader reply that while reductionism may be a \"dirty word\" to some it is actually an important scientific principle. They argue it is at the root of discoveries such as the world being made up of atoms and complex life being the result of evolution. At the same time they emphasize that it is important to look at all \"levels\" of explanations, e.g. both psychologists looking at environmental causes of depression and neuroscientists looking the brain contribute to different aspects of our knowledge of depression. Workman and Reader also deny the accusation of genetic determinism, asserting that genes usually do not cause behaviors absolutely but predispose to certain behaviors that are affected by factors such as culture and an individual's life history.\n\nA common critique is that evolutionary psychology does not address the complexity of individual development and experience and fails to explain the influence of genes on behavior in individual cases.\n\nCritics assert that evolutionary psychology has trouble developing research that can distinguish between environmental and cultural explanation and adaptive evolutionary explanations. Some studies have been criticized for their tendency to attribute to evolutionary processes elements of human cognition that may be attributable to social processes (e.g. preference for particular physical features in mates), cultural artifacts (e.g. patriarchy and the roles of women in society), or dialectical considerations (e.g. behaviours in which biology interacts with society, as when a biologically determined skin colour determines how one is treated). Evolutionary psychologists are frequently criticized for ignoring the vast bodies of literature in psychology, philosophy, politics and social studies. Both sides of the debate stress that statements such as \"biology vs. environment\" and \"genes vs. culture\" amount to false dichotomies, and outspoken critics of sociobiology such as Richard Lewontin, Steven Rose and Leon Kamin helped to popularise a \"dialectical\" approach to questions of human behaviour, where biology and environment interact in complex ways to produce what we see.\n\nEvolutionary psychologists respond that their discipline is not primarily concerned with explaining the behavior of specific individuals, but rather broad categories of human behaviors across societies and cultures. It is the search for species-wide psychological adaptations (or \"human nature\") that distinguishes evolutionary psychology from purely cultural or social explanations. These psychological adaptations include cognitive decision rules that respond to different environmental, cultural, and social circumstances in ways that are (on average) adaptive.\n\nEvolutionary psychologists Confer et al. argue that evolutionary psychology fully accepts nature-nurture interactionism, and that it is possible to test the theories in order to distinguish between different explanations.\n\nCritics point out that within evolutionary biology there are many other non-adaptive pathways along which evolution can move to produce the behaviors seen in humans today. Natural selection is not the only evolutionary process that can change gene frequencies and produce novel traits. Genetic drift is caused by chance variation in the genes, environment, or development. Evolutionary by-products are traits that were not specially designed for an adaptive function, although they may also be species-typical and may also confer benefits on the organism. A \"spandrel\" is a term coined by Gould and Lewontin (1979a) for traits which confer no adaptive advantage to an organism, but are 'carried along' by an adaptive trait. Gould advocates the hypothesis that cognition in humans came about as a spandrel: \"Natural selection made the human brain big, but most of our mental properties and potentials may be spandrels – that is, nonadaptive side consequences of building a device with such structural complexity\". Once a trait acquired by some other mechanism confers an adaptive advantage, it may be open to further selection as an \"exaptation\". Evolutionary psychologists suggest that critics misrepresent their field, and that their empirical research is designed to help identify which psychological traits are prone to adaptations, and which are not.\n\nSome have argued that even if the theoretical assumptions of evolutionary psychology turned out to be true, it would nonetheless lead to methodological problems that would compromise its practice. The disjunction and grain problems are argued to create methodological challenges related to the indeterminacy of evolutionary psychology’s adaptive functions. That is, the inability to correctly choose, from a number of possible answers to the question: \"what is the function of a given mechanism?\"\n\nThe \"disjunction problem\" occurs when a mechanism appears to respond to one thing (\"F\"), but is also correlated with another (\"G\"). Whenever \"F\" is present, \"G\" is also present, and the mechanism seems to respond to both \"F\" and \"G\". The difficulty thus involves deciding whether to characterize the mechanism's adaptive function as being related to \"F\", \"G\", or \"both\". \"For example, a frogs pre-catching mechanism responds to flies, bees, food pellets, etc.; so is its adaptation attuned to flies, bees, fleebees, pellets, all of these, or just some?\"\n\nThe \"grain problem\" refers to the challenge in knowing what kind of environmental 'problem' an adaptive mental mechanism might have solved. As summarized by Sterenly & Griffiths (1999): \"What are the problems 'out there' in the environment? Is the problem of mate choice a single problem or a mosaic of many distinct problems? These problems might include: When should I be unfaithful to my usual partner? When should I desert my old partner? When should I help my sibs find a partner? When and how should I punish infidelity?\" The grain problem therefore refers to the possibility that an adaptive problem may actually involve a set of nested 'sub-problems' \"which may themselves relate to different input domains or situations. Franks states that \"if both adaptive problems and adaptive solutions are indeterminate, what chance is there for evolutionary psychology?\"\n\nFranks also states that \"The arguments in no sense count against a general evolutionary explanation of psychology.\" and that by relaxing assumptions the problems may be avoided, although this may reduce the ability to make detailed models.\n\n\"Maladaptive\" behaviors such as homosexuality and suicide seem to reduce reproductive success and pose a challenge for evolutionary psychology. Evolutionary psychologists have proposed explanations, such that there may be higher fertility rates for the female relatives of homosexual men, thus progressing a potential homosexual gene, or that they may be byproducts of adaptive behaviors that usually increase reproductive success. However, a review by Confer et al. states that they \"remain at least somewhat inexplicable on the basis of current evolutionary psychological accounts\". If seen to be of a maladaptive nature, and therefore disregarding the evolutionary psychological evidence for things such as homosexuality, these behaviours can simply be seen in a no different manner than other maladaptations such as poor eyesight.\n\nMany critics have argued that evolutionary psychology and sociobiology justify existing social hierarchies and reactionary policies. Evolutionary psychologists have been accused of conflating \"is\" and \"ought\", and evolutionary psychology has been used to argue against social change (because the way things are now has been evolved and adapted) and against social justice (e.g. the argument that the rich are only rich because they've inherited greater abilities, so programs to raise the standards of the poor are doomed to fail).\n\nIt has also been suggested by critics that evolutionary psychologists' theories and interpretations of empirical data rely heavily on ideological assumptions about race and gender. Halford Fairchild, for example, argues that J. Philippe Rushton's work on race and intelligence was influenced by preconceived notions about race and was \"cloaked in the nomenclature, language and 'objectivity'\" of evolutionary psychology, sociobiology and population genetics.\n\nMoreover, evolutionary psychology has been criticized for its ethical implications. Richardon (2007) and Wilson et al. (2003) have cited the theories in \"A Natural History of Rape\" where rape is described as a form of mate choice that enhances male fitness as examples. Critics have expressed concern over the moral consequences of such evolutionary theories and some critics have understood them to justify rape. However, empirical research has found that, compared to a control group, exposure to evolutionary psychology theories had no observable impact on male judgments of men’s criminal sexual behavior.\n\nEvolutionary psychologists caution against committing the naturalistic fallacy – the idea that \"ought can be derived from is\" and that \"what is natural\" is necessarily a moral good. In the book \"The Blank Slate\", Steven Pinker contends that critics have committed two logical fallacies: The naturalistic fallacy is the idea that what is found in nature is good. It was the basis for Social Darwinism, the belief that helping the poor and sick would get in the way of evolution, which depends on the survival of the fittest. Today, biologists denounce the Naturalistic Fallacy because they want to describe the natural world honestly, without people deriving morals about how we ought to behave -- as in: If birds and beasts engage in adultery, infanticide, cannibalism, it must be OK. The moralistic fallacy is that what is good is found in nature. It lies behind the bad science in nature-documentary voiceovers: lions are mercy-killers of the weak and sick, mice feel no pain when cats eat them, dung beetles recycle dung to benefit the ecosystem and so on. It also lies behind the romantic belief that humans cannot harbor desires to kill, rape, lie, or steal because that would be too depressing or reactionary.\n\nSimilarly, the authors of \"A Natural History of Rape\", Thornhill and Palmer, as well as McKibbin et al. respond to allegations that evolutionary psychologists legitimizes rape by arguing that their critics' reasoning is a naturalistic fallacy in the same way it would be a fallacy to accuse the scientists doing research on the causes of cancer of justifying cancer. Instead, they argue that understanding the causes of rape may help create preventive measures.\n\nWilson et al. (2003) have stated that evolutionary psychologists are themselves confused about the naturalistic fallacy and misuse it to forestall legitimate ethical discussions. The authors have argued that a factual statement must be combined with an ethical statement to derive an ethical conclusion. Thus, \"ought\" cannot be described \"exclusively\" from \"is\". They have suggested that if one combines Thornhill and Palmer's theory that rape increases the fitness of a woman's offspring with the ethical premise that it is right to increase fitness of offspring, the resulting deductively valid conclusion is that rape has also positive effects and that its ethical status is ambiguous. Wilson et al. have stated: \"Any critic who objects to Thornhill and Palmer's evolutionary interpretation of rape on ethical grounds is dismissed with the phrase 'naturalistic fallacy' like a child stupid enough to write 2+2=5, stifling any meaningful discussion of the ethical issues surrounding the subject of rape. Yet, it is Thornhill and Palmer who are thinking fallaciously by using the naturalistic fallacy in this way.\" However, in the same article these authors also note that \"...we want to stress that we are sympathetic with the goals of evolutionary psychology and think that research should proceed on all fronts, including the possibility that unethical behaviors such as rape evolved by natural selection\".\n\nPart of the controversy has consisted in each side accusing the other of holding or supporting extreme political viewpoints: evolutionary psychology has often been accused of supporting right-wing politics, whereas critics have been accused of being motivated by Marxist view points.\n\nLinguist and activist Noam Chomsky has said that evolutionary psychologists often ignore evidence that might harm the political status quo:\n\nChomsky has also said that not enough is known about human nature to point to any political conclusions.\n\nEvolutionary psychologist Glenn Wilson argues that \"promoting recognition of the true power and role of instincts is not the same as advocating the total abandonment of social restraint\". Left-wing philosopher Peter Singer in his book \"A Darwinian Left\" has argued that the view of human nature provided by evolution is compatible with and should be incorporated into the ideological framework of the Left.\n\nEvolutionary psychology critics have argued that researchers use their research to promote a right-wing agenda. Evolutionary psychologists conducted a 2007 study investigating the views of a sample of 168 United States PhD psychology students. The authors concluded that those who self-identified as adaptationists were much less conservative than the general population average. They also found no differences compared to non-adaptationist students and found non-adaptationists to express a preference for less strict and quantitative scientific methodology than adaptationists.\n\n\n\n\n\n"}
{"id": "42621632", "url": "https://en.wikipedia.org/wiki?curid=42621632", "title": "Dual process theory (moral psychology)", "text": "Dual process theory (moral psychology)\n\nDual process theory is an influential theory of human moral judgment that alleges that human beings possess emotion-based and rationally-based cognitive subsystems that compete in moral reasoning processes. Initially proposed by Joshua Greene along with Brian Sommerville, Leigh Nystrom, John Darley, Jonathan Cohen and others, the theory can be seen as a domain specific example of more general dual process accounts in psychology.\n\nThe dual process account asserts that human beings have two separate methods for moral reasoning. The first refers to intuitive or instinctual responses to moral violations. These responses are implicit and the factors affecting them may be consciously inaccessible. Greene asserts that these responses are supported by emotional activation. The second method refers to conscious, controlled reasoning processes. These processes ignore the emotional aspects of decision making, instead focusing on maximizing gain or obtaining the most desirable overall outcome. In everyday decision making, most decisions use one or other system, but in moral dilemmas in which an individual must compromise between violating moral rules and maximizing overall good, the systems come into conflict.\n\nGreene ties the two processes to theories of ethics existing in moral philosophy, specifically consequentialism and deontological ethics. He argues that the existing tension between systems of ethics that focus on \"right action\" and those that focus on \"best results\" can be explained by the existence of the proposed dueling systems in individual human minds.\n\nThis theory of moral judgment has had influence on research in moral psychology. The original fMRI investigation proposing the dual process account has been cited in excess of 2000 scholarly articles, generating extensive use of similar methodology as well as criticism. An alternative formulation of dual process theory in moral psychology may be found in.\n\nThe dual process account first grew out of fMRI experiments showing that moral dilemmas such as the trolley problem engaged areas of the brain corresponding to emotional processing when the context involved \"personal\" moral violations (such as direct bodily force). When the context of the dilemma was more \"impersonal\" (the decision maker pulls a switch rather than use bodily force) areas corresponding to working memory and controlled reasoning were engaged instead. Neuropsychological evidence from lesion studies focusing on patients with damage to the ventromedial prefrontal cortex also points to a possible dissociation between emotional and rational decision processes. Damage to this area is typically associated with antisocial personality traits and impairments of moral decision making. Patients with these lesions tend to show more frequent endorsement of the \"utilitarian\" path in trolley problem dilemmas. Greene et al. claim that this shows that when emotional information is removed through context or damage to brain regions necessary to render such information, the process associated with rational, controlled reasoning dominates decision making.\n\nAnother critical piece of evidence supporting the dual process account comes from reaction time data associated with moral dilemma experiments. Subjects who choose the \"utilitarian\" path in moral dilemmas showed increased reaction times under high cognitive load in \"personal\" dilemmas, while those choosing the \"deontological\" path remained unaffected. Cognitive load in general is also found to increase the likelihood \"deontological\" judgment. These laboratory findings are supplemented by work that looks at the decision-making processes of real world altruists in life-or-death situations. These heroes overwhelming described their actions as fast and intuitive, and virtually never as carefully reasoned.\n\nSeveral criticisms have been leveled against the dual process account. The most common criticism asserts that the dual emotional/rational model ignores the motivational aspect of decision making in human social contexts A more specific example of this criticism focuses on the ventromedial prefrontal cortex lesion data. Although patients with this damage display characteristically \"cold-blooded\" behavior in the trolley problem, they show more likelihood of endorsement of emotionally laden choices in the Ultimatum Game. It is argued that moral decisions are better understood as integrating emotional, rational, and motivational information, the last of which has been shown to involve areas of the brain in the limbic system and brain stem.\n\nOther criticisms focus on the methodology of using moral dilemmas such as the trolley problem. These criticisms note the lack of affective realism in contrived moral dilemmas and their tendency to use the actions of strangers to offer a view of human moral sentiments. Paul Bloom in particular, argues that a multitude of attitudes towards the agents involved are important in evaluating an individual's moral stance, as well as evaluating the motivations that may inform those decisions.\n\nThomas Nagel critiques it by suggesting that Joshua Greene, in his book \"Moral Tribes,\" is too quick to conclude utilitarianism specifically from the general goal of constructing an impartial morality; for example, he says, Kant and Rawls offer other impartial approaches to ethical questions.\n\nRobert Wright calls Joshua Greene's proposal for global harmony ambitious and adds, \"I like ambition!\" But he also claims that people have a tendency to see facts in a way that serves their ingroup, even if there's no disagreement about the underlying moral principles that govern the disputes. \"If indeed we’re wired for tribalism,\" Wright explains, \"then maybe much of the problem has less to do with differing moral visions than with the simple fact that my tribe is my tribe and your tribe is your tribe. Both Greene and Paul Bloom cite studies in which people were randomly divided into two groups and immediately favored members of their own group in allocating resources -- even when they knew the assignment was random.\" Instead, Wright proposes that \"nourishing the seeds of enlightenment indigenous to the world’s tribes is a better bet than trying to convert all the tribes to utilitarianism -- both more likely to succeed, and more effective if it does.\"\n"}
{"id": "9348093", "url": "https://en.wikipedia.org/wiki?curid=9348093", "title": "Energy engineering", "text": "Energy engineering\n\nEnergy engineering or energy systems engineering is a broad field of engineering dealing with energy efficiency, energy services, facility management, plant engineering, environmental compliance and alternative energy technologies. Energy engineering is one of the more recent engineering disciplines to emerge. Energy engineering combines knowledge from the fields of physics, math, and chemistry with economic and environmental engineering practices. Energy engineers apply their skills to increase efficiency and further develop renewable sources of energy.\nThe main job of energy engineers is to find the most efficient and sustainable ways to operate buildings and manufacturing processes. Energy engineers audit the use of energy in those processes and suggest ways to improve the systems. This means suggesting advanced lighting, better insulation, more efficient heating and cooling properties of buildings. Although an energy engineer is concerned about obtaining and using energy in the most environmentally friendly ways, their field is not limited to strictly renewable energy like hydro, solar, biomass, or geothermal. Energy engineers are also employed by the fields of oil and natural gas extraction.\n\nEnergy minimization is the purpose of this growing discipline. Often applied to building design, heavy consideration is given to HVAC, lighting, refrigeration, to both reduce energy loads and increase efficiency of current systems. Energy engineering is increasingly seen as a major step forward in meeting carbon reduction targets. Since buildings and houses consume over 40% of the United States energy, the services an energy engineer performs are in demand.\n\nHuman beings have been transferring energy from one form to another since their use of fire. The efficiency of the transfer of energy is a new field. The oil crisis of 1973 and energy crisis of 1979 brought to light the need to get more work out of less energy. The United States government passed several laws in the seventies to promote increased energy efficiency, such as United States public law 94-413, the Federal Clean Car Incentive Program.\n\nConsidered a subdivision of energy engineering, power engineering applies math and physics to the movement and transfer of energy to work in a system.\n\nLeadership in Energy and Environmental Design (LEED) is a program created by the United States Green Building Council (USGBC) in March 2000. LEED is a program that encourages green building and promotes sustainability in the construction of buildings and the efficiency of the utilities in the buildings.\n\nIn 2012 the United States Green Building Council asked the independent firm Booz Allen Hamilton to conduct a study on the effectiveness of LEED program. \"This study confirmed that green buildings generate substantial energy savings. From 2000–2008, green construction and renovation generated $1.3 billion in energy savings. Of that $1.3 billion, LEED-certified buildings accounted for $281 million.\" The study also found the summation of all green construction supported 2.4 million jobs.\n\nEnergy efficiency is seen two ways. The first view is that more work is done from the same amount of energy used. The other perception is that the same amount of work is accomplished with less energy used in the system. Some ways to get more work out of less energy is to \"Reduce, Reuse, and Recycle\" the materials used in daily life. The advancement of technology has led to other uses of waste. Technology such as waste-to-energy facilities which convert solid wastes through the process of gasification or pyrolysis to liquid fuels to be burned. The Environmental Protection Agency stated that the United States produced 250 million tons of municipal waste in 2010. Of that 250 million tons roughly 54% gets thrown in land fills, 33% is recycled, and 13% goes to energy recovery plants. In European countries who pay more for fuel, such as Denmark where the price for a gallon of gas neared $10 in 2010, have more fully developed waste-to energy facilities. In 2010 Denmark sent 7% of waste to landfills, 69% was recycled, and 24% was sent to waste-to-energy facilities. There are several other developed Western European countries that also have taken energy engineering into consideration. Germany's \"Energiewende\", a policy which set the goal by 2050 to meet 80% of electrical needs from renewable energy sources.\n\nThe median yearly salary for an energy engineer is $64,587 U.S. dollars. 83% of energy engineers are male while the remaining 17% are female. 65% of energy engineers have less than five years of experience in their profession.\n\nEnergy engineers have one main professional organization. The Association of Energy Engineers (AEE) founded in 1977. It now has 16,000 members in 89 countries. The organizations main responsibility is to lead energy certification programs to teach individuals across the world and certify as qualified to perform the job of an energy engineer.\n\nA bachelor’s degree is a primary requirement of becoming an energy engineer. Some energy engineers are registered Professional Engineers (P.E.); although the completion of that program is not a necessity. Of the 16,000 energy engineers that are in the Association of Energy Engineers (AEE), 58.4% have post-graduate degrees from accredited colleges. If the engineer is not a P.E. he or she would need a Certified Energy Manager (CEM) or Certified Energy Auditor (CEA) certificate from a group like the Association of Energy Engineers (AEE). Both CEM and CEA Certifications are recognized by the United States Department of Energy\n\nWhile a student who wants to become an energy engineer does not directly need to get a degree in energy engineering, several universities across the world have established departments or centers offering energy engineering degrees, to better prepare future engineers for their career. One of those programs is the IEP PEM Certification which is offered at Virginia Tech University. The Certified Professional Energy Manager (PEM) was created in conjunction by the Institute of Energy Professionals (IEP) and Energy University. Since 2009, Energy University has provided energy efficiency education to more than 130,000 professionals worldwide. The program offers more than 150 courses.\n\n\n"}
{"id": "36320643", "url": "https://en.wikipedia.org/wiki?curid=36320643", "title": "Engineering Legends", "text": "Engineering Legends\n\nEngineering Legends: Great American Civil Engineers is a 2005 book by engineer Richard Weingardt. The book features a list of 32 engineering legends from the 1700s to the present, including Fazlur Khan, Hal Iyengar, Tung-Yen Lin, Benjamin Wright, and Fred Severud.\n\nWeingardt describes how the ingenuity of these engineers, many of whom were immigrants to the United States, revolutionized the world, and how people take so many things for granted which were made possible because of the genius of these engineers. The book discusses the fact that while the engineering achievements are regularly recognized, the engineers themselves are rarely discussed. These engineers should become common household names.\n\nThe book explores the personal lives and professional accomplishments of its subjects, providing an in-depth look at the people behind these achievements. The book also illustrates the diversity surrounding these engineers, such as their differing backgrounds, their reasons for becoming engineers, the obstacles they faced, and their work in different disciplines of civil engineering. In the foreword, Henry Petroski describes the book as a work that \"cannot help but inspire engineers, future engineers, and all who benefit (and will continue to benefit) from their work\".\n\n\n\n\n\n\n\n\n\n"}
{"id": "39630233", "url": "https://en.wikipedia.org/wiki?curid=39630233", "title": "Heliophysics NASA science", "text": "Heliophysics NASA science\n\nHeliophysics is an aspect of NASA science that enables understanding the sun, heliosphere, and planetary environments as a single connected system. In addition to solar processes, this domain of study includes the interaction of solar plasma and solar radiation with Earth, the other planets, and the galaxy. By analyzing the connections between the sun, solar wind, planetary space environments, and human's place in the milky way galaxy, the fundamental physical processes that occur throughout the universe are uncovered. Understanding the connections between the Sun and its planets will allow for predicting the impacts of solar interaction on humans, technological systems, and even the presence of life itself. This is also the stated goal of Science Mission Directorate's Heliophysics Research.\n\nFurthermore, \"heliophysics\" of \"NASA science\" views the sun as an active star, and that the earth is physically located within its atmosphere. This view also encompasses the interaction of the earth's geophysical properties with this active star. For example, the sun' light influences all life and processes on Earth. It is an energy provider that allows and sustains life on earth. However, the sun also produces streams of high energy particles known as the solar wind, and radiation that can harm life or alter its evolution. Additionally, under the protective shield of earth's magnetic field and its atmosphere, NASA science sees the Earth as an island in the universe where life has developed and flourished. The origins and fate of life on Earth are intimately connected to the sun's behavior. Hence, NASA science studies Heliophysics from this perspective.\n\nMethods have been developed to see into the internal workings of the sun and understand how the earth's magnetosphere responds to solar activity. Further studies are concerned with exploring the full system of complex interactions that characterize the relationship of the Sun with the solar system. According to NASA, understanding these connections is especially critical as we contemplate our destiny in the third millennium. Heliophysics is needed to facilitate the accelerated expansion of human experience beyond the confines of our earthly home. Recent advances in technology allow us, for the first time, to realistically contemplate voyages beyond the solar system.\n\nThere are three primary objectives that define the multi-decadal studies needed: \n\n\nEarth is located within the extended atmosphere of a magnetic variable star that drives the local solar system and sustains life on Earth. The Sun is observed to vary from multiple perspectives. The Sun emits light in the infrared, visible, ultraviolet, and at x-ray energies, and it emits a magnetic field, bulk plasma (the solar wind) and energetic particles moving up to nearly the speed of light, and all of these emissions vary.\n\nThe intertwined response of the earth and heliosphere are studied because this planet is immersed in this unseen yet exotic and inherently dangerous environment. Above the protective cocoon of Earth’s lower atmosphere is a plasma soup composed of electrified and magnetized matter entwined with penetrating radiation and energetic particles. The sun has an impact because modern society depends heavily on a variety of technologies that are susceptible to the extremes of space weather — severe disturbances of the upper atmosphere and of the near-Earth space environment that are driven by the magnetic activity of the Sun. Strong electrical currents driven in the Earth’s surface during auroral events can disrupt and damage modern electric power grids and may contribute to the corrosion of oil and gas pipelines. \n\nBuilding on NASA’s rich history of exploration of Earth’s neighborhood and distant planetary systems, we are poised to provide a predictive understanding of our place in the solar system. We do not live in isolation; we are intimately coupled with the Sun and the space environment through Earth’s climate system, our technological systems, the habitability of planets and solar system bodies we plan to explore, and ultimately the fate of Earth itself. Variability in this environment affects the daily activities that constitute the underpinning of modern society, including communication, navigation, and weather monitoring and prediction. Because the space environment matters to humans and their technological systems both on Earth and in space, it is essential as a space-faring Nation that we develop an understanding of these space plasma processes. \n\nPlasmas and their embedded magnetic fields affect the formation, evolution and destiny of planets and planetary systems. The heliosphere shields the solar system from galactic cosmic radiation. Our habitable planet is shielded by its magnetic field, protecting it from solar and cosmic particle radiation and from erosion of the atmosphere by the solar wind. Planets without a shielding magnetic field, such as Mars and Venus, are exposed to those processes and evolve differently. And on Earth, the magnetic field changes strength and configuration during its occasional polarity reversals, altering the shielding of the planet from external radiation sources. \n\nDetermine changes in the Earth's magnetosphere, ionosphere, and upper atmosphere in order to enable specification, prediction, and mitigation of their effects. Heliophysics seeks to develop an understanding of the response of the near-Earth plasma regions to space weather. This complex, highly coupled system protects Earth from the worst solar disturbances while redistributing energy and mass throughout. \n\nUnderstand the causes and subsequent evolution of solar activity that affects Earth's space climate and environment. The climate and space environment of Earth are significantly determined by the impact of plasma, particle, and radiative outputs from the Sun. Therefore, it is essential to understand the Sun, determine how predictable solar activity truly is, and develop the capability to forecast solar activity and the evolution of disturbances as they propagate to Earth. \n\n\n"}
{"id": "47012091", "url": "https://en.wikipedia.org/wiki?curid=47012091", "title": "Hiding in the Mirror", "text": "Hiding in the Mirror\n\nHiding in the Mirror is a popular science book by the theoretical physicist Lawrence M. Krauss. The text was initially published on October 20, 2005 by Viking Press. This is his seventh non-fiction book.\n\nThe work draws on the works of scientists, mathematicians, artists, and writers to consider the cultural and scientific aspects of extra dimensions. The book explores popular theories about such topics as black holes, life in other dimensions, and string theory.\n\nA reviewer of \"Publishers Weekly\" mentioned \"Physicist Krauss offers an erudite and well-crafted overview of the role multiple dimensions have played in the history of physics. This isn't an easy book, even with a writer as talented as Krauss (whom some will recognize as the author of \"The Physics of Star Trek\" and \"Beyond Star Trek\") serving as one's Virgil. Long on science and short on its connections with culture, the book is essentially an introduction to the physics and mathematics of extra dimensions with a few more or less disconnected chapters that touch on how these ideas show up in art and popular culture; there's more on brane-world and the ekpyrotic universe than on Plato's cave, whose inhabitants could not perceive reality in all its dimensions, or Buckaroo Banzai.\"\n\n\n\n"}
{"id": "44042166", "url": "https://en.wikipedia.org/wiki?curid=44042166", "title": "INTEROP-VLab", "text": "INTEROP-VLab\n\nThe INTEROP V-Lab (\"International Virtual Laboratory for Enterprise Interoperability\") is a network of organizations, which links scientists, research centers, representatives of industry, and small and medium-sized enterprises. The members come from several European countries as well as China and represent 250 scientists and 70 organizations.\n\nINTEROP-VLab was founded in 2007 and is the continuation of the INTEROP Network of Excellence (Interoperability research for networked enterprise applications and software), a research initiative of the European Union founded early 2000s, which developed the Model Driven Interoperability (MDI) Framework.\n\nIn 2012 Guy Doumeingts was appointed general manager of INTEROP-VLab.\n\nINTEROP-VLab is an initiative that is working within the context of interoperability, in particular the so-called Enterprise Interoperability (EI). It aims to link together in a network researchers and research institutions and industry representatives, engaged in developing approaches and integrative solutions to connect heterogeneous industrial systems, public administrations or organizations.\n\nThe basic objective of INTEROP-VLab is the defragmentation of the European research and scientific landscape and support the cooperation of other regions of the world:\n\nThe activities of INTEROP-VLab consist of research, teaching and training services and standardization consultancy.\n\nThe independent research within INTEROP-VLabs is based on the following three key components:\n\nWithin INTEROP-VLab developed solutions include:\n\nThe members of the INTEROP-VLab are organize in poles of geographic regions within a State or group of States. Activities of each organization are coordinated at European level. The members of the INTEROP-VLab are:\n\n"}
{"id": "53738484", "url": "https://en.wikipedia.org/wiki?curid=53738484", "title": "Intellectual curiosity", "text": "Intellectual curiosity\n\nIntellectual curiosity (also called epistemic curiosity) is curiosity that leads to an acquisition of general knowledge. It can include curiosity about such things as: what objects are composed of, the underlying mechanisms of systems, mathematical relationships, languages, social norms, and history. It can be differentiated from another type of curiosity that does not lead to acquisition of general knowledge, such as curiosity about the intimate secrets of other people. It is a facet of openness to experience in the Five Factor Model used to describe human personalities. It is similar to need for cognition and typical intellectual engagement.\n\nIn antiquity, the Roman philosopher Cicero wrote about our innate love of learning:\n\nIn 1738, the Scottish philosopher David Hume differentiated intellectual curiosity from a more primitive form of curiosity: \nLater, in 1954, Berlyne differentiated it into perceptual curiosity and epistemic curiosity, and in 2004 a psychometric scale to assess epistemic and perceptual curiosity was developed.\n\nHumans seem to be born with intellectual curiosity, but depending on how parents react to questions from their children, intellectual curiosity might be increased or decreased. Parents that always react negatively to questions asked by their children, are discouraging them from asking questions, and that is likely to make them less curious. On the other hand, parents that always react positively to questions asked by their children, are encouraging them to ask questions, and that is likely to make them more curious. There is a book about how to foster intellectual curiosity and a love for knowledge in children.\n\nIt has been positively correlated with academic performance (0.20), together with general intelligence (0.35) and conscientiousness (0.20).\n\nToby E. Huff has argued that the European civilization had a high level of intellectual curiosity during the scientific revolution. He also argues that other civilizations have had a high level of intellectual curiosity in their most progressive stages.\n\nThe temporal lobe is involved in understanding. Intellectual curiosity might be regarded as the trait that motivates growth of understanding in the temporal lobe. Motivation is effectuated by the neurotransmitter dopamine\n\nDue to a high level of correlation (.78), it has been argued that need for cognition and typical intellectual engagement basically are measuring the same trait. Intellectual curiosity might be regarded as an umbrella term for these two traits.\n"}
{"id": "14485040", "url": "https://en.wikipedia.org/wiki?curid=14485040", "title": "Jefferson fracture", "text": "Jefferson fracture\n\nA Jefferson fracture is a bone fracture of the anterior and posterior arches of the C1 vertebra, though it may also appear as a three- or two-part fracture. The fracture may result from an axial load on the back of the head or hyperextension of the neck (e.g. caused by diving), causing a posterior break, and may be accompanied by a break in other parts of the cervical spine.\n\nIt is named after the British neurologist and neurosurgeon Sir Geoffrey Jefferson, who reported four cases of the fracture in 1920 in addition to reviewing cases that had been reported previously.\n\nIndividuals with Jefferson fractures usually experience pain in the upper neck but no neurological signs. The fracture may also cause damage to the arteries in the neck, resulting in lateral medullary syndrome, Horner's syndrome, ataxia, and the inability to sense pain or temperature.\n\nIn rare cases, congenital abnormality may cause the same symptoms as a Jefferson fracture.\n\nJefferson fracture is often caused by an impact or load on the back of the head, and are frequently associated with diving into shallow water, impact against the roof of a vehicle and falls, and in children may occur due to falls from playground equipment. Less frequently, strong rotation of the head may also result in Jefferson fractures.\n\nJefferson fractures are extremely rare in children, but recovery is usually complete without surgery.\n\nThe use of surgery to treat a Jefferson fracture is somewhat controversial. Non-surgical treatment varies depending on if the fracture is stable or unstable, defined by an intact or broken transverse ligament and degree of fracture of the anterior arch. An intact ligament requires the use of a soft or hard collar, while a ruptured ligament may require traction, a halo or surgery. The use of rigid halos can lead to intracranial infections and are often uncomfortable for individuals wearing them, and may be replaced with a more flexible alternative depending on the stability of the injured bones, but treatment of a stable injury with a halo collar can result in a full recovery. Surgical treatment of a Jefferson fracture involves fusion or fixation of the first three cervical vertebrae; fusion may occur immediately, or later during treatment in cases where non-surgical interventions are unsuccessful. A primary factor in deciding between surgical and non-surgical intervention is the degree of stability as well as the presence of damage to other cervical vertebrae.\n\nThough a serious injury, the long-term consequences of a Jefferson's fracture are uncertain and may not impact longevity or abilities, even if untreated. Conservative treatment with an immobilization device can produce excellent long-term recovery.\n"}
{"id": "59050674", "url": "https://en.wikipedia.org/wiki?curid=59050674", "title": "Kimberly Arcand", "text": "Kimberly Arcand\n\nKimberly 'Kim' Kowal Arcand is a science communicator and the *Visualization Lead for NASA's Flagship Chandra X-ray Observatory.* As visualization lead, Arcand is responsible for using the raw binary data received from the space telescope to create astronomical images and animations of Chandra's new discoveries. She then incorporates these visualizations into various multimedia platforms to use in her presentations, customized to her specific audience. Arcand is also responsible for the design and creation of science exhibits which are displayed at government agencies, educational institutions, local schools and other venues for the general public. She is the principal investigator for the Aesthetics and Astronomy image response project at the Harvard-Smithsonian Center for Astrophysics located in Cambridge, Massachusetts. \n\nArcand wanted to be an astronaut as a child. She studied molecular biology at the University of Rhode Island and also became a developer for the University of Rhode Island Center for Vector-Borne Disease Public Health project. She was awarded a fellowship with the Rhode Island Public Health Partnership to work on lyme disease. Her efforts were recognised; she won an intellectual property invention award. She worked in the University of Rhode Island Department of Computer Science as an instructor between 1997 and 1999. She joined the Smithsonian Astrophysical Observatory and Chandra X-ray Observatory as Visualisation Lead in 1998. She studied at the Harvard University Department of Computer Science between 2000 and 2002.\n\nIn 2009 Arcand launched \"From Earth to the Universe\" with UNESCO, a series of large exhibitions that occurred in 1,000 locations around the world. She is Principal Investigator of the Aesthetics and Astronomy image response project at the Harvard–Smithsonian Center for Astrophysics. The project launched in 2010 and looks at variations in the presentation of colour and scale in astronomical images. They look at how people respond to images, and the misconceptions that non-experts have when they view them. The project began when Randall and Lisa Smith realised that there was a lot astrophysicists could learn from art about how to present results. The group explored the public perception of astronomical pictures using a survey linked to the NASA Astronomical Picture of the Day site, gaining almost 10,000 responses. In 2013 Arcand earned a Master's degree in Public Humanities from Brown University.\n\nShe worked closely with UNESCO to celebrate the International Year of Light. It was an open-source exhibition that showcased science based on light. The celebration was supported by SPIE. Using NASA data, Arcand developed a way to 3D print a supernova remnant and virtual reality application.\n\nIn 2016 the White House selected her as a \"changemaker\" at the United State of Women Summit. She wrote about the event for the HuffPost and the United State of Women blog. In 2017 she was profiled on Vinita Marwaha Madill's website \"Rocket Women\". She is completing her doctorate at the University of Otago, where she is a member of the Art and Science group. As a science advisor, Kim was welcomed as a board member for the Rhode Island Museum of Science and Art (RIMOSA). This non-profit organization takes learning to the next level by stimulating one's creativity through highly interactive exhibits instead of using conventional educational methods. As a technologist, Kim was also selected to serve on the Rhode Island's Tech Collective executive board. As a federal employee, she serves as vice president for the Federally Employed Women, Greater Boston chapter. \n\nArcand has won several awards for her work from NASA and the Smithsonian Institution.\n\n\n\n\n\nArcand has written several popular science books. Her book \"Colouring the Universe\" was selected by Cosmos as one of the Top Illustrated Science Books of 2016. She collaborates with Megan Watzke and Travis Rector, Ph.D.. Her book \"Light: The Visible Spectrum and Beyond\" was selected by forbes as one of the Top 10 Gifts of 2016.\n\n\n\n"}
{"id": "33936876", "url": "https://en.wikipedia.org/wiki?curid=33936876", "title": "Library Literature and Information Science", "text": "Library Literature and Information Science\n\nLibrary Literature and Information Science is a bibliographic database that indexes over 410 library and information science periodicals published internationally. It also covers books, chapters within books, library school theses, and pamphlets. In 2011, the H. W. Wilson Company, the firm that created the index, sold it to EBSCO Publishing along with other H.W. Wilson indexes and databases. \n\nBibliographical indexing from 1984 to present. Full-text coverage from 1997, but start date varies for each publication.\n\n\n"}
{"id": "30557939", "url": "https://en.wikipedia.org/wiki?curid=30557939", "title": "Linda Rising", "text": "Linda Rising\n\nLinda Rising is an American author, lecturer, independent consultant and chief operating officer (COO) of The Hillside Group. Rising is credited as having played a major role in having \"moved the pattern approach from design into corporate change.\" She also contributed to the book \"97 Things Every Software Architect Should Know\", edited by Kevlin Henney and published by O´Reilly in 2009 ().\n\nIn 1964, Rising obtained a bachelor's degree in chemistry at the University of Kansas, in 1984 a Master of Science degree in computer science at Southern Illinois University and in 1987 a M. A. in mathematics at the Southwest Missouri State University. In 1992, Rising obtained her PhD degree in computer science from the Arizona State University, with her thesis entitled \"Information hiding metrics for modular programming languages\" relating to object-based design metrics.\n\nRising taught as instructor in mathematics and computer science at various universities throughout the midwest from 1977 to 1984 and worked as assistant professor from 1984 to 1987 at Indiana University – Purdue University Fort Wayne.\n\nIn industry, she worked in the areas of telecommunications, avionics, and tactical weapons systems.\n\nRising has extended the use of \"patterns\", building upon the work of Christopher Alexander on a pattern language for architecture and the work of the \"Gang of Four\" on patterns for software development. She extended the use of patterns to the support of organisational change. Her work and lectures cover patterns, retrospectives, agile development approaches and the change process, topics on which she is an internationally known lecturer.\n\nSince 2010, she is editor of the \"Insights\" series of the IEEE Software magazine.\n\nHer book \"The Pattern Almanac 2000\" provides a comprehensive inventory of patterns compiled from publications in patterns conferences and books prior to the year 2000. The patterns are listed by name and divided into categories, and for each pattern a rudimentary description as well as a reference to a book, journal or URL where the actual published pattern can be found is provided. \"The Pattern Almanac 2000\" has been cited as reference on existing patterns and used as starting-point of further research. Rising's indexing of existing patterns is seen as \"a significant start toward achieving the ultimate goal of a pattern database.\"\n\nThe study \"The scrum software development process for small teams\" by Rising and Norman S. Janoff is cited as first published study in which the scrum, a development process for small teams which includes a series of \"sprints\" which each last typically between one and four weeks, was tested in real-life projects. The study has been cited for showing \"that nonhierarchical teams work more effectively through the complex iterations and time-consuming gestation of a software program\" and that \"they gain strength through shared successes and failures\".\n\nShe is editor of the book \"Design Patterns in Communication Software\", a compendium of patterns, which appeared 2001. Contributors to her book include experts from the patterns community such as James O. Coplien and Douglas C. Schmidt. She is author of \"Fearless Change: Patterns for Introducing New Ideas\", co-authored with Mary Lynn Manns and published 2004.\n\nRising has been keynote speaker at the \"agile 2007\" conference (topic: \"Are agilists the bonobos of software development?\"), the \"OOP 2009\" conference (topic: \"Who Do You Trust?\"), the \"Agile testing days Berlin 2010\" (topic: \"Deception and Estimation: How we fool ourselves\"), at the \"GOTO Amsterdam 2014\" conference (topic: \"Science or Stories?\"), and at the \"European Testing Conference 2016\" in Bukarest (topic: \"The Agile Mindset\") \n\nHer work has inspired many in the agile community, for instance Steve Adolph and Paul Bramble, who, together with Alistair Cockburn and Andy Pols, expanded further on Rising's use patterns.\n\nRising lives in Phoenix, Arizona.\n\n \n"}
{"id": "50631201", "url": "https://en.wikipedia.org/wiki?curid=50631201", "title": "List of CP cannabinoids", "text": "List of CP cannabinoids\n\nMany synthetic cannabinoids were designed by Pfizer in the 1970s and 1980s, and feature an alphanumeric code beginning with the prefix \"CP\". Recently, several members of this class of cannabinoids have been discovered in recreational drug products.\n"}
{"id": "1172392", "url": "https://en.wikipedia.org/wiki?curid=1172392", "title": "List of ZX80 and ZX81 clones", "text": "List of ZX80 and ZX81 clones\n\nThe following is a list of clones of Sinclair Research's ZX80 and ZX81 home computers:\n\n\n\n\n"}
{"id": "45314091", "url": "https://en.wikipedia.org/wiki?curid=45314091", "title": "List of diseases eliminated from the United States", "text": "List of diseases eliminated from the United States\n\nThis is a list of diseases known (or declared) to have been eliminated from the United States, either permanently or at one time. Most of the diseases listed were eliminated after coordinated public health campaigns. (Since some diseases can be eliminated and then reintroduced at a later time, such diseases are still eligible for the list, but with the fact of reintroduction noted.) Some entries are based on formal public health declarations, others are based on reliable information in the medical or public health literature. Since some diseases can be eliminated, but subsequently reimported without transmitting additional endemic cases, these are noted in a dedicated column. Although no fixed rule always applies, many infectious diseases (e.g., measles) are considered eliminated when no cases have been reported to public health authorities for at least 12 months.\n\n \n\nVarious public health projects are going on, with a goal of eliminating diseases from the country. Several infectious diseases in the United States, not on the above list, are considered close to elimination (98-99% reductions): e.g., \"Hemophilus influenzae\", mumps, rubella, congenital rubella, and tetanus. Other disease pathogens (e.g., those of anthrax and rabies) have been almost entirely eliminated from humans in the US, but remain as hazards in the environment, so cannot accurately be described as eliminated. The stated goal of \"eradication\" of hookworm from the southeast US (1915-20) was not achieved, although the hookworm-infection rate of that region did drop by more than half.\n\n"}
{"id": "41689952", "url": "https://en.wikipedia.org/wiki?curid=41689952", "title": "List of medical schools in Karachi", "text": "List of medical schools in Karachi\n\nIn Pakistan, a medical school is more often referred to as a medical college. A medical college is affiliated with a university as a department which usually has a separate campus. The medical schools in Karachi are both private and public.\n\nUniversity of Karachi announced in September 2014 that it will establish its own medical college and a 100-bed hospital. The admission in the college for 100 students will be started in November 2014.\n\n"}
{"id": "55286737", "url": "https://en.wikipedia.org/wiki?curid=55286737", "title": "List of the Paleozoic life of Arizona", "text": "List of the Paleozoic life of Arizona\n\nThis list of the Paleozoic life of Arizona contains the various prehistoric life-forms whose fossilized remains have been reported from within the US state of Arizona and are between 541 and 252.17 million years of age.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "5976704", "url": "https://en.wikipedia.org/wiki?curid=5976704", "title": "Peenemünde Airfield", "text": "Peenemünde Airfield\n\nPeenemünde Airfield is an airfield along the Baltic Sea north of Peenemünde, Germany. Today round trips in light aircraft take place from Peenemünde Airfield. Bus tours are also available, on which one can visit the former shelters of the NVA and the remnants of the V-1 flying bomb facilities. Because of its long runway the airfield Peenemünde is also a location for flight schools.\n\nOn April 2, 1936, the Reich Air Ministry paid 750,000 German Reichsmarks to the town of Wolgast for the whole Northern peninsula of Usedom. The airfield began service on 1 April 1938, and on the same date, the Air Ministry officially separated Peenemünde-West from the joint command that included the adjacent Army Research Center Peenemünde.\n\nAs \"Werk West\", the Luftwaffe Test Site () and under control from the central \"Erprobungsstelle Rechlin\" facility inland, the Peenemünde-West coastal facility was used for testing experimental aircraft (\"Erprobungsflugzeug\") such as the Heinkel He 176 (flown at Peenemünde on June 20, 1939) and the Messerschmitt Me 163 rocket-powered fighter (code named 'Peenemünde 30' by British intelligence - the '30' referring to the object's measured wingspan in feet). At the northeast edge of the concrete airfield was a launch ramp for testing the V-1 flying bomb and on which, in 1943, RAF officer Constance Babington Smith, working at RAF Medmenham, detected a small winged aircraft ('Peenemünde 20') while viewing an Allied reconnaissance photograph. The airfield was also used for take-off of Heinkel He 111 for initial air-launch testing of V-1s. V-1 launch crew training was at the nearby resort of Zempin, and after the August 1943 Operation \"Hydra\" bombing of the area, V-1 flight testing was moved to Brüsterort. Peenemünde West also developed World War II night-navigation and radar systems (Dr. Johannes Plendl). After the 2nd Belorussian Front under General Konstantin Rokossovsky captured the Swinemünde port and Usedom island on May 5, 1945, the airfield became part of the Soviet Zone of Occupation.\n\nIn 1956, the airfield received a new 2,465 metre-long concrete runway, which is oriented in a northwesterly direction and allows the operation of modern military jet planes. A further landmark is the collection of radio beacons at the northwest end, which were built on artificial islands in the sea. In 1961, the airfield was transferred to the National People's Army (NVA), which used it until 1989. After 1989, the airfield was used among other things as parking area of former military vehicles of the NVA. From Summer 2010, a high-performance jet trainer aircraft Aero L-39 Albatros of the former National People's Army (NVA) is back on Peenemünde Airfield.\n\n"}
{"id": "59068250", "url": "https://en.wikipedia.org/wiki?curid=59068250", "title": "Planctopirus hydrillae", "text": "Planctopirus hydrillae\n\nPlanctopirus hydrillae is a Gram-negative bacterium from the genus of \"Planctopirus\" which has been isolated from the plant \"Hydrilla verticillata\" from Hyderabad in India.\n"}
{"id": "5132659", "url": "https://en.wikipedia.org/wiki?curid=5132659", "title": "Port Lockroy", "text": "Port Lockroy\n\nPort Lockroy is a natural harbour on the north-western shore of Wiencke Island in the Palmer Archipelago in front of the Antarctic Peninsula. The Antarctic base includes the most southerly operational post office in the world.\n\nThe bay was discovered during 1904 and named after Edouard Lockroy, a French politician and Vice President of the Chamber of Deputies, who assisted Jean-Baptiste Charcot in obtaining government funding for his French Antarctic Expedition. The harbour was used for whaling between 1911 and 1931. During World War II, the British military Operation Tabarin established the Port Lockroy Station A on tiny Goudier Island in the bay, which continued to operate as a British research station until January 16, 1962.\n\nDuring 1996, the Port Lockroy base was renovated and is now a museum and post office operated by the United Kingdom Antarctic Heritage Trust.\n\nIt is one of the most popular tourist destinations for cruise-ship passengers in Antarctica. Proceeds from the small souvenir shop fund the maintenance of the site and other historic sites and monuments in Antarctica. The Trust collects data for the British Antarctic Survey to observe the effect of tourism on penguins. Half the island is open to tourists, while the other half is reserved for penguins. A staff of four typically process 70,000 pieces of mail sent by 18,000 visitors that arrive during the five month Antarctic cruise season. A souvenir passport stamp is also offered to visitors.\n\nThe historic importance of the site relates to both its establishment as an Operation Tabarin base during 1944, and for the scientific work performed there, including the first measurements of the ionosphere, and the first recording of an atmospheric whistler, from Antarctica. It was also a key monitoring site during the International Geophysical Year (1957). The site has been designated a Historic Site or Monument (HSM 61), following a proposal by the United Kingdom to the Antarctic Treaty Consultative Meeting.\n\n\n"}
{"id": "54407328", "url": "https://en.wikipedia.org/wiki?curid=54407328", "title": "Project Troy", "text": "Project Troy\n\nProject Troy was a research study of psychological warfare undertaken for the Department of State by a group of scholars including physicists, historians and psychologists from Harvard University, the Massachusetts Institute of Technology and RAND Corporation in the fall of 1950. The \"Project Troy Report to the Secretary of State\", presented to Secretary of State Archeson on 1 February 1951, made various proposals for political warfare, including possible methods of minimizing the effects of Soviet jamming on the Voice of America broadcasts.\n\nDuring World War II the United States Office of War Information (OWI) launched a large-scale information and propaganda campaign both at home and abroad through radio broadcasts, newspapers, posters, photographs, films and other forms of media, but \"psychological warfare\" operations had been run by special military units.\n\nAfter the end of the war President Truman transferred the operations of the OWI as well as control over Voice of America overseas radio network to the Interim International Information Service (IIS) within the State Department. The State Department, eager to assert leadership in this area, organized a civilian-sponsored project on new methods and approaches to Cold War propaganda, code-named Project Troy. Convened in October 1950 at the State Department's request, it brought together for a period of almost three months a group of twenty-one distinguished scientists, social scientists, and historians, most of whom were academics.\n\nIt can be assumed that the Truman administration tried to implement plans established by the Project Troy in the project \"Overload and Delay\". The purpose of the latter was to break the Stalinist system by increasing the number of input points in the system and by creating complex and unpredictable situations requiring action.\n\nOn 26 March 1951 Robert J. Hooker delivered a memorandum on the Troy Report to the Director of the Policy Planning Staff Paul Nitze, asserting that the report \"deserves the most serious consideration. It lays down principles and techniques for the conduct of political warfare which, with few exceptions, seem worthy of adoption.\"\n"}
{"id": "24190958", "url": "https://en.wikipedia.org/wiki?curid=24190958", "title": "San Francisco Women on the Web", "text": "San Francisco Women on the Web\n\nSan Francisco Women on the Web (SFWOW) is a nonprofit organization based in San Francisco, California. It works to serve, educate and empower women in technology through professional development, support, and networking opportunities. In 1998, the organization created a nationally recognized awards program called the Top 25 Women on the Web, a program that continued through 2007.\n\nSan Francisco Women on the Web began as a chapter of Webgrrls. The volunteers of that chapter broke away in 1998 and formed an independent organization and began discussions and paperwork to achieve nonprofit status, which they did in 2000. In 1998, while still a part of Webgrrls, the San Francisco volunteers created an awards program called the Top 25 Women on the Web, which was held up to 2001 and garnered regular press attention, including national coverage. Membership (non-dues) totaled 1807 in 2007. Volunteer-run, it organized workshops, from HTML to Java, events, monthly meetings, study groups, coffee klatches, and \"scrappies\" a kind of happy hour networking gathering.\n\n\n\n"}
{"id": "32089236", "url": "https://en.wikipedia.org/wiki?curid=32089236", "title": "Sighard F. Hoerner", "text": "Sighard F. Hoerner\n\nDr. Sighard F. Hoerner (born 18 April 1906, Münster, Germany — d. 22 June 1971, Brick Town, USA) was an important figure in the aerodynamics field and is known worldwide for his two compendiums of aerodynamic knowledge, \"Fluid-Dynamic Drag\" and \"Fluid-Dynamic Lift\". He is also notable for his design work on the pioneering STOL aircraft, the Fieseler Fi 156 \"Storch\".\n\nDr. Hoerner studied mechanical engineering at the Technical University of Munich, earning a Dipl.Ing. and he earned a degree as Dr.-Ing. in aerodynamics at the Institute of Technology at Braunschweig. Finally, he obtained a degree as Dr.-Ing.-habil. from the TH Berlin.\n\nInitially, he served as research assistant at the Deutsche Versuchsanstalt fur Luftfahrt (DVL, near Berlin). After this, he worked as an aerodynamicist at the Fieseler Corporation, where he worked on the aerodynamic design of the Fieseler Fi 156 Storch STOL aircraft. From there, he went to Junkers, where he worked as the head of design aerodynamics, before going to Messerschmitt, where he worked as a research aerodynamicist during World War II. After the war, he was \"invited\" (Operation Paperclip) to emigrate to the United States, where he worked in aerodynamics at Wright Field in Ohio. Eventually, he ended up working as a specialist in aerodynamics and hydrodynamics in the field of naval architecture at Gibbs & Cox, Inc. in New York City.\n\nIn 1945 and 1946, Dr. Hoerner prepared a manuscript for the book \"Aerodynamic Drag\". The technical publishing houses in New York City were not confident enough to bring a book as specialized as this to the market. As a result, he published the book himself in 1951, using a photo-offset process and sold copies of the book by mail order from his home. The book got very good reviews and demand was steady. In 1958 it was reissued as \"Fluid-Dynamic Drag\". With the rapid progress in aerodynamics over the years, he prepared an update to the book, which was published in 1965. As before, the book was self-published by Hoerner Fluid Dynamics. This book contains documentation of the worldwide knowledge (at the time) of the sources of aerodynamic drag and the means to quantify aerodynamic drag. While substantial knowledge on this subject has been learned since 1965, this book is often the starting point in work where aerodynamic drag must be calculated.\n\nThe US Navy Office of Naval Research gave Dr. Hoerner a contract in the mid-1960s to write a companion volume \"Fluid-Dynamic Lift\". Co-authored with Henry V. \"Hank\" Borst, this book was published by Hoerner Fluid Dynamics in 1975. Unfortunately, Dr. Hoerner died before publication. This book, like its companion, contains documentation of the worldwide knowledge on the generation of aerodynamic lift and is still used heavily.\n\nDr. Hoerner was married to Liselotte A. Hoerner. After his death, she continued the mail order business, selling copies of both books to engineers around the world.\n\n\n"}
{"id": "6817421", "url": "https://en.wikipedia.org/wiki?curid=6817421", "title": "Space Shuttle orbiter", "text": "Space Shuttle orbiter\n\nThe Space Shuttle orbiter was the spaceplane component of the Space Shuttle, a partially reusable orbital spacecraft system that was part of the Space Shuttle program. Operated by NASA, the U.S. space agency, this vehicle could carry astronauts and payloads into low Earth orbit, perform in-space operations, then re-enter the atmosphere and land as a glider, returning its crew and any on-board payload to the Earth.\n\nSix orbiters were built for flight: \"Enterprise\", \"Columbia\", \"Challenger\", \"Discovery\", \"Atlantis\", and \"Endeavour\". All were built in Palmdale, California, by the Pittsburgh, Pennsylvania-based Rockwell International company. The first orbiter, \"Enterprise\", made its maiden flight in 1977. An unpowered glider, it was carried by a modified Boeing 747 airliner called the Shuttle Carrier Aircraft and released for a series of atmospheric test flights and landings. \"Enterprise\" was partially disassembled and retired after completion of critical testing. The remaining orbiters were fully operational spacecraft, and were launched vertically as part of the Space Shuttle stack.\n\n\"Columbia\" was the first space-worthy orbiter, and made its inaugural flight in 1981. \"Challenger\", \"Discovery\", and \"Atlantis\" followed in 1983, 1984 and 1985 respectively. In 1986, \"Challenger\" was destroyed in an accident shortly after launch. \"Endeavour\" was built as \"Challenger\"s replacement, and was first launched in 1992. In 2003, \"Columbia\" was destroyed during re-entry, leaving just three remaining orbiters. \"Discovery\" completed its final flight on March 9, 2011, and \"Endeavour\" completed its final flight on June 1, 2011. \"Atlantis\" completed the last ever Shuttle flight, STS-135, on July 21, 2011.\n\nIn addition to their crews and payloads, the reusable orbiter carried most of the Space Shuttle System's liquid-fueled rocket propulsion system, but both the liquid hydrogen fuel and the liquid oxygen oxidizer for its three main rocket engines were fed from an external cryogenic propellant tank. Additionally, two reusable solid rocket boosters provided additional thrust for approximately the first two minutes of launch. The orbiters themselves did carry hypergolic propellants for their RCS thrusters and Orbital Maneuvering System engines.\n\nThe Space Shuttle orbiter resembled an airplane in its design, with a standard-looking fuselage and two double delta wings, both swept wings at an angle of 81 degrees at their inner leading edges and 45 degrees at their outer leading edges. The vertical stabilizer of the orbiter had a leading edge that was swept back at a 45-degree angle. There were four elevons mounted at the trailing edges of the delta wings, and the combination rudder and speed brake was attached at the trailing edge of the vertical stabilizer. These, along with a movable body flap located underneath the main engines, controlled the orbiter during later stages of descent through the atmosphere and landing.\n\nOverall, the Space Shuttle orbiter was roughly the same size as a McDonnell Douglas DC-9 airliner.\n\nThe Reaction Control System (RCS) was composed of 44 small liquid-fueled rocket thrusters and their very sophisticated fly-by-wire flight control system, which utilized computationally intensive digital Kalman filtering. This control system carried out the usual attitude control along the pitch, roll, and yaw axes during all of the flight phases of launching, orbiting, and re-entry. This system also executed any needed orbital maneuvers, including all changes in the orbit's altitude, orbital plane, and eccentricity. These were all operations that required a lot more power and energy than mere attitude control.\n\nThe forward rockets of the Reaction Control System, located near the nose of the Space Shuttle orbiter, included 14 primary and two vernier RCS rockets. The aft RCS engines were located in the two Orbital Maneuvering System (OMS) pods at the rear of the orbiter, and these included 12 primary (PRCS) and two vernier (VRCS) engines in each pod. The PRCS system provided the pointing control of the Orbiter, and the VRCS was used for fine maneuvering during the rendezvous, docking, and undocking maneuvers with the International Space Station, or formerly with the Russian Mir space station. The RCS also controlled the attitude of the orbiter during most of its re-entry into the Earth's atmosphere – until the air became dense enough that the rudder, elevons and body flap became effective.\n\nDuring the early design process of the orbiter, the forward RCS thrusters were to be hidden underneath retractable doors, which would open once the orbiter reached space. These were omitted in favor of flush-mounted thrusters for fear that the RCS doors would remain stuck open and endanger the crew and orbiter during re-entry.\n\nThe orbiter crew cabin consisted of three levels: the flight deck, the mid-deck, and the utility area. The uppermost of these was the flight deck, in which sat the Space Shuttle's commander and pilot, with up to two mission specialists seated behind them. The mid-deck, which was below the flight deck, had three more seats for the rest of the crew members.\n\nThe galley, toilet, sleep locations, storage lockers, and the side hatch for entering and exiting the orbiter were also located on the mid-deck, as well as the airlock. The airlock had an additional hatch into the payload bay. This airlock allowed two or three astronauts, wearing their Extravehicular Mobility Unit (EMU) space suits, to depressurize before a walk in space (EVA), and also to repressurize and re-enter the orbiter at the conclusion of the EVA.\n\nThe utility area was located under the floor of the mid-deck and contained air and water tanks in addition to the carbon dioxide scrubbing system.\n\nThree Space Shuttle Main Engines (SSMEs) were mounted on the orbiter's aft fuselage in the pattern of an equilateral triangle. These three liquid-fueled engines could be swiveled 10.5 degrees vertically and 8.5 degrees horizontally during the rocket-powered ascent of the orbiter in order to change the direction of their thrust. Hence, they steered the entire Space Shuttle, as well as providing rocket thrust towards orbit. The aft fuselage also housed three auxiliary power units (APU). The APUs chemically converted hydrazine fuel from a liquid state to a gas state, powering a hydraulic pump which supplied pressure for all of the hydraulic system, including the hydraulic sub-system that pointed the three main liquid-fueled rocket engines, under computerized flight control. The hydraulic pressure generated was also used to control all of the orbiter's \"flight control surfaces\" (the elevons, rudder, speed brake, etc.), to deploy the landing gear of the orbiter, and to retract the umbilical hose connection doors located near the rear landing gear, which supplied the orbiter's SSMEs with liquid hydrogen and oxygen from the external tank.\n\nTwo Orbital Maneuvering System (OMS) thrusters were mounted in two separate removable pods on the orbiter's aft fuselage, located between the SSMEs and the vertical stabilizer. The OMS engines provided significant thrust for coarse orbital maneuvers, including insertion, circularization, transfer, rendezvous, deorbit, abort to orbit, and to abort once around. At lift-off, two solid rocket boosters (SRBs) were used to take the vehicle to an altitude of roughly 140,000 feet.\n\nElectric power for the orbiter's subsystems was provided by a set of three hydrogen-oxygen fuel cells which produced 28 volt DC power and was also converted into 115 volt 400 Hz AC three-phase electric power (for systems that used AC power). These provided power to the entire Shuttle stack (including the SRBs and ET) from T-minus 3m30s up through the end of the mission. The hydrogen and oxygen for the fuel cells was kept in pairs of cryogenic storage tanks in the mid-fuselage underneath the payload bay liner, and a variable number of such tanks could be installed (up to five) depending on the requirements of the mission. The three fuel cells were capable of generating 21 kilowatts of power continuously (or a 15-minute peak of 36 kilowatts) with the orbiter consuming an average of about 14 kilowatts of that power (leaving 7 kilowatts for the payload).\n\nAdditionally, the fuel cells provided potable water for the crew during the mission.\n\nThe orbiter's computer system consisted of five identical IBM AP-101 avionics computers, which redundantly controlled the vehicle's on-board systems. The specialized HAL/S programming language was used for orbiter systems.\n\nThe orbiters were protected by Thermal Protection System (TPS) materials (developed by Rockwell Space Systems) inside and out, from the Orbiter's outer surface to the payload bay. The TPS protected it from the cold soak of in space to the heat of re-entry.\n\nThe orbiter's structure was made primarily from aluminium alloy, although the engine thrust structure was made from titanium alloy. The later orbiters (\"Discovery\", \"Atlantis\" and \"Endeavour\") substituted graphite epoxy for aluminum in some structural elements in order to reduce weight. The windows were made of aluminum silicate glass and fused silica glass, and comprised an internal pressure pane, a optical pane, and an external thermal pane. The windows were tinted with the same ink used to make American banknotes.\n\nThe Space Shuttle orbiter had three sets of landing gear which emerged downwards through doors in the heat shield. As a weight-saving measure, the gear could not be retracted once deployed. Since any premature extension of the landing gear would very likely have been catastrophic (because it opened through the heat shield layers), the landing gear could only be lowered by manual controls, and not by any automatic system.\n\nSimilarly, since the Shuttle landed at high speed and could not abort its landing attempt, the gear had to deploy reliably on the first try every time. The gear were unlocked and deployed by triple redundant hydraulics, with the gear doors actuated by mechanical linkages to the gear strut. If all three hydraulic systems failed to release the landing gear uplocks within one second of the release command, pyrotechnic charges automatically cut the lock hooks and a set of springs deployed the gear.\n\nDuring landing, the Shuttle nose wheel could be steered with the rudder pedals in the cockpit. During the construction of , an improved nose wheel steering system was developed which allowed easier and better nose wheel steering. After \"Endeavour\" roll-out, the system was installed on the other shuttles except \"Challenger\", during their overhauls in the early 1990s.\n\nThe Space Shuttle orbiter did not carry anti-collision lights, navigational lights, or landing lights, because the orbiter always landed in areas that had been specially cleared by both the Federal Aviation Administration and the Air Force. The Orbiter nearly always landed at either Edwards Air Force Base (California) or at the Kennedy Space Center Shuttle Landing Facility (Florida), although one mission – STS-3 – landed at the White Sands Space Harbor in New Mexico. Similar special clearances (no-fly zones) were also in effect at potential emergency landing sites, such as in Spain and in West Africa during all launches.\n\nWhen an orbiter landing was carried out at night, the runway was always strongly illuminated with light from floodlights and spotlights on the ground, making landing lights on the orbiter unnecessary and also an unneeded spaceflight weight load. A total of 26 landings took place at night, the first being STS-8 in September 1983.\n\nThe typeface used on the Space Shuttle Orbiter was Helvetica.\n\nThe prototype orbiter \"Enterprise\" originally had a flag of the United States on the upper surface of the left wing and the letters \"USA\" in black on the right wing. The name \"Enterprise\" in black was painted on the payload bay doors just above the forwardmost hinge and behind the crew module; on the aft end of the payload bay doors was the NASA \"worm\" logotype in gray. Underneath the rear of the payload bay doors on the side of the fuselage just above the wing was the text \"United States\" in black with a flag of the United States ahead of it.\n\nThe first operational orbiter, \"Columbia\", originally had the same markings as \"Enterprise\", although the letters \"USA\" on the right wing were slightly larger and spaced farther apart. \"Columbia\" also had black tiles which \"Enterprise\" lacked on its forward RCS module, around the cockpit windows, and on its vertical stabilizer. \"Columbia\" also had distinctive black \"chines\" on the forward part of its upper wing surfaces, which none of the other orbiters had.\n\n\"Challenger\" established a modified marking scheme for the shuttle fleet that would be matched by \"Discovery\", \"Atlantis\" and \"Endeavour\". The letters \"USA\" in black above an American flag were displayed on the left wing, with the NASA \"worm\" logotype in gray centered above the name of the orbiter in black on the right wing. Also, the name of the orbiter was inscribed not on the payload bay doors, but on the forward fuselage just below and behind the cockpit windows. This would make the name visible when the orbiter was photographed in orbit with the doors open. \"Challenger\" also had black tiles on the tip of its vertical stabilizer much like \"Columbia\", which the other orbiters lacked.\n\nIn 1983, \"Enterprise\" had its wing markings changed to match \"Challenger\", and the NASA \"worm\" logotype on the aft end of the payload bay doors was changed from gray to black. Some black markings were added to the nose, cockpit windows and vertical tail to more closely resemble the flight vehicles, but the name \"Enterprise\" remained on the payload bay doors as there was never any need to open them. \"Columbia\" had its name moved to the forward fuselage to match the other flight vehicles after STS-61-C, during the 1986–88 hiatus when the shuttle fleet was grounded following the loss of \"Challenger\", but retained its original wing markings until its last overhaul (after STS-93), and its unique black wing \"chines\" for the remainder of its operational life.\n\nBeginning in 1998, the flight vehicles' markings were modified to incorporate the NASA \"meatball\" insignia. The \"worm\" logotype, which the agency had phased out, was removed from the payload bay doors and the \"meatball\" insignia was added aft of the \"United States\" text on the lower aft fuselage. The \"meatball\" insignia was also displayed on the left wing, with the American flag above the orbiter's name, left-justified rather than centered, on the right wing. The three surviving flight vehicles, \"Discovery\", \"Atlantis\" and \"Endeavour\", still bear these markings as museum displays. \"Enterprise\" became the property of the Smithsonian Institution in 1985 and was no longer under NASA's control when these changes were made, hence the prototype orbiter still has its 1983 markings and still has its name on the payload bay doors.\n\nWith the end of the shuttle program, plans were made to place the three remaining shuttle orbiters on permanent display. NASA Administrator Charles Bolden announced the disposition location of the orbiters on April 12, 2011, the 50th anniversary of the first human space flight and the 30th anniversary of the first flight of \"Columbia\". \"Discovery\" went to the Smithsonian's Steven F. Udvar-Hazy Center, replacing \"Enterprise\" which was moved to the Intrepid Sea, Air & Space Museum in New York City. \"Endeavour\" went to the California Science Center in Los Angeles arriving on October 14, 2012. \"Atlantis\" went to the Kennedy Space Center Visitor Complex on November 2, 2012. Hundreds of other shuttle artifacts will be put on display at various other museums and educational institutions around the US.\n\nThe Cargo bay is 18.3 m long and 4.6 m wide (60 ft by 15 ft), with a payload rating of 16,050 kg (35,380 lb) to ISS, and return-to-Earth payload of 14,400 kg (31,700 lb\n\nThe orbiter's maximum glide ratio/lift-to-drag ratio varied considerably with speed, ranging from 1:1 at hypersonic speeds, 2:1 at supersonic speeds, and reaching 4.5:1 at subsonic speeds during approach and landing.\n\nIndividual Space Shuttle orbiters were named in honor of antique sailing ships of the navies of the world, and they were also numbered using the NASA Orbiter Vehicle Designation system. Three of the names had also been borne by Apollo spacecraft between 1969 and 1972: Apollo 11 Command Module \"Columbia\", Apollo 15 Command Module \"Endeavour\", and Apollo 17 Lunar Module \"Challenger\".\n\nWhile all of the orbiters were externally practically identical, they had minor differences in their interiors. New equipment for the Orbiters was installed in the same order that they underwent maintenance work, and the newer orbiters were constructed by Rockwell International, under NASA supervision, with some more advanced, lighter in weight, structural elements. Thus, the newer orbiters (\"Discovery\", \"Atlantis\" and \"Endeavour\") had slightly more cargo capacity than \"Columbia\" or \"Challenger\".\n\nThe Space Shuttle orbiters were assembled at Rockwell's assembly facility in Palmdale, California, at the federally owned Plant 42 complex.\n\nIn addition to the test articles and orbiters produced for use in the Shuttle program, there are also various mock-up replicas on display throughout the United States:\n\n\n"}
{"id": "56111973", "url": "https://en.wikipedia.org/wiki?curid=56111973", "title": "Stalin and the Scientists", "text": "Stalin and the Scientists\n\nStalin and the Scientists: A History of Triumph and Tragedy 1905–1953 is a 2016 popular science non-fiction book on the history of science in the Soviet Union under Joseph Stalin by English novelist and science writer, Simon Ings. It is Ings' second non-fiction book, the first being \"The Eye: A Natural History\" (2007). He had previously published eight novels.\n\n\"Stalin and the Scientists\" was longlisted for the 2016 Baillie Gifford Prize for Non-Fiction.\n\nIngs' inspiration for \"Stalin and the Scientists\" came from Soviet psychologist, Alexander Luria's book \"Mind of a Mnemonist\", about the life of Russian journalist and mnemonist, Solomon Shereshevsky. Ings said in 2016 interviews that Luria is often referred to as the founder of modern neuroanatomy and \"the godfather of the literary genre we call popular science\". \"Luria's account more or less set the template for modern popular science and ... pretty much set me on the path I'm on now.\" Ings had considered writing a biography about Luria, but felt that while Luria's achievements were \"extraordinary\", considering the climate of political repression he worked in, Ings was concerned that Western readers would consider his career too ordinary, and would miss the context in which it unfolded. Ings' passion for popular science and the need to explain the context within which Luria and other Soviet scientists worked, changed what would have been a one-year \"modest biography\" into a \"five-year behemoth\" that \"burned through three editors\" and, Ings added, \"nearly killed me\".\n\nIngs said, as a novelist, he was \"absurdly under-qualified\" to tackle a book like \"Stalin and the Scientists\", but added that only a novelist could be so \"ridiculously ambitious\" and \"naive enough to stick his or her neck out so far\". Ings felt that given the kind of science prevalent in Russia at the time, perhaps this \"really has to be the job of a novelist rather than a historian\". Responding to statements that this is \"the first history\" of Soviet science, Ings said, \"Certainly no-one's been foolish enough to attempt to tell the whole story of science under Stalin in a single volume, but be assured I didn't dig this entire thing single-handed from virgin ground.\"\n\n\nIn a review in \"The Guardian\", David Holloway described \"Stalin and the Scientists\" as a \"fascinating story\" that reveals \"the tragedy and the triumph\" of Soviet science. He called it a \"lively book\" and complimented Ings on his \"clear and simple\" scientific explanations, and the way he highlighted the personalities of those involved: the \"brilliant scientists\", the \"charlatans\", the \"visionaries\" and the \"careerists\". A reviewer of the book in \"Publishers Weekly\" complimented Ings on the sensitive way in which he exposed the lives of the scientists and their experiences, and how he \"ably documents the challenges, failures, and achievements of Soviet science\". The reviewer commented that while Ings \"can be long-winded\", he \"engagingly fuses history, science, and storytelling\".\n\nBritish historian and author Simon Sebag Montefiore wrote in \"The New York Times\" that Ings \"skillfully\" portrays the lives of the scientists of this period. He called Ings \"an entertaining storyteller who often captures the essence of things\", and described the book as \"lively and interesting\" and full of \"priceless nuggets and a cast of frauds, crackpots and tyrants\". Montefiore added, however, that while Ings highlights the failures of Soviet science, he omits its successes, for example the Tupolev and MiG airplanes, and the T-34 tank. Montefiore was also critical of errors in the book, for example Stalin's birthday and Felix Dzerzhinsky's tenure as head of Cheka, the Soviet secret police.\n\nWriting in \"Socialist Review\", John Parrington was also critical of flaws and omissions. While he described the book as \"ambitious in scope\", and called it \"fascinating\" and \"important\", Parrington said it is not without \"elementary errors\", like Ings' statement that \"the Bolsheviks ... and the Mensheviks ... missed the 1905 revolution\". Parrington also complained that Ings does not explain what it was that \"destroyed the hopes and dreams\" of Russian scientists in the 1920s when Stalin came to power.\n\nAmerican science historian Loren Graham also criticised errors and omissions in the book. In a review in \"The Wall Street Journal\", he said Ings is \"a gifted writer\", and called \"Stalin and the Scientists\" \"a good single source\" for readers new to Soviet science. But Graham felt that one of the book's shortcomings was that Ings only focuses on topics that interest him, like biology, physiology and psychology, while giving little attention to mathematics and theoretical physics. Graham also noted several \"incorrect or exaggerated\" statements in the book, for example: Alexei Gastev was a \"leading architect of Russia's industrialisation programme\"; Nikolai Bernstein \"invented cybernetics\"; and Stalin was \"the last in a long line of European philosopher kings\". Graham concluded that the book is the result of \"an impressive amount of study\" and \"deserves attention\", but \"a very critical form of attention\".\n"}
{"id": "8159070", "url": "https://en.wikipedia.org/wiki?curid=8159070", "title": "Stefan Marinov", "text": "Stefan Marinov\n\nStefan Marinov () (1 February 1931 – 15 July 1997) was a Bulgarian physicist, researcher, writer and lecturer who promoted anti-relativistic theoretical viewpoints, and later in his life defended the ideas of perpetual motion and free energy. In 1997 he self-published experimental results that confirmed classical electromagnetism and disproved that a machine constructed by Marinov himself could be a source of perpetual motion. Devastated by the negative results, he committed suicide in Graz, Austria on 15 July 1997.\n\nMarinov was born on 1 February 1931 in Sofia to a family of intellectual communists. \nIn 1948 he finished Soviet College in Prague, then studied physics at the Czech Technical University in Prague and Sofia University. He was an Assistant Professor of Physics from 1960 to 1974 at Sofia University. In 1966-67, 1974, and 1977 he was subject to compulsory psychiatric treatment in Sofia because of his political dissent. In September 1977 Marinov received a passport and he successfully emigrated out of the country, moving to Brussels. In 1978, Marinov moved to Washington, D.C.. Later he lived in Italy and Austria. In his later years, Marinov earned a living as a groom for horses.\n\nOn 15 July 1997, Marinov jumped to his death from a staircase at a library at the University of Graz, after leaving suicide notes. He was 66 years old and was survived by his son Marin Marinov, who at the time was a vice-Minister of Industry of Bulgaria.\n\nOne of Marinov's interests was the quest for free energy sources via construction of toy theories (new axiomatic systems that putatively describe our physical reality) and their experimental testing against mainstream physical theories. In 1992 Marinov wrote a letter to German Federal Chancellor Helmut Kohl in support of a German company, Becocraft, that was doing research into \"free energy\" technologies and had recently been the target of lawsuits. In the letter, Marinov threatened to set himself on fire at the steps of the German parliament if Kohl was not willing to intervene in favour of Marinov's associates.\n\nMarinov attempted to find experimental disproof of the theory of relativity by testing the speed of light in different directions using an arrangement of \"coupled mirrors\" and \"coupled shutters\". Marinov reported in 1974 that he had measured an anisotropy of the velocity of light. However, Marinov's claims have not found acceptance within the scientific community, despite his energetic efforts to promote his claims. Marinov planned to develop an updating of the relativistic mechanics and electrodynamics, as described in his self-published book \"Eppur si Muove\". Marinov succeeded in having his claims presented in numerous publications including peer-reviewed journals.\n\nMarinov was involved publicly with many quarrels with John Maddox, the editor of \"Nature\", who refused to print either his papers or his letters to the editor. He retaliated by securing the funds to place a full-page advertisement in \"Nature\" expressing his frustration with what he regarded as the dogmatic attitude of the establishment. Marinov himself published a journal, \"Deutsche Physik\", of which he was editor-in-chief and which discussed mainly his ideas on physics.\n\nStefan Marinov was interested in bizarre experiments alleged to violate known physical laws. Marinov claimed to have seen in operation and learned the secret of the so-called \"Swiss ML converter\" or Testatika electrical generator, another alleged perpetual motion machine, at a religious commune in Switzerland called Methernitha. According to Marinov's account, this 500-member commune, led by religious leader Paul Baumann, met all its energy needs using this device.\n\nMarinov has been editor of a five-volume encyclopaedic series called \"Classical Physics\". In 1993 Marinov also authored a book on electromagnetism which discoursed on his belief that mainstream scientific thought was mired in dogma and had discarded still-valid knowledge from scientific thought of previous eras. In 1997 in the last issue 21 of \"Deutsche Physik\", Marinov self-published experimental results that disprove that the \"Siberian Coliu\", constructed by Marinov himself, is a perpetual motion machine, and where Marinov concluded that Ampere's law in electromagnetism is correct. Most of Marinov's friends think these negative results on constructing a source of free energy (in order to solve the global energy needs of humanity) might have pushed him to commit a suicide.\n"}
{"id": "53089168", "url": "https://en.wikipedia.org/wiki?curid=53089168", "title": "Technica Curiosa", "text": "Technica Curiosa\n\nTechnica Curiosa was an early compendium of scientific and medical technologies. It was published in 1664 by Gaspar Schott near the beginning of the scientific revolution. It contained some of the first accounts of Otto von Guericke's experiments with a vacuum. One of the first \"popular science\" publications, the book did much to inspire interest in the sciences.\n\nDuring 2017, the title 'Technica Curiosa' is being reused for an online publication with content of a similar nature for a modern audience. It will incorporate the titles of \"Popular Astronomy\", \"Popular Electronics\", and \"Mechanix Illustrated\".\n"}
{"id": "30872886", "url": "https://en.wikipedia.org/wiki?curid=30872886", "title": "The Feynman Lectures on Physics", "text": "The Feynman Lectures on Physics\n\nThe Feynman Lectures on Physics is a physics textbook based on some lectures by Richard P. Feynman, a Nobel laureate who has sometimes been called \"The Great Explainer\". The lectures were presented before undergraduate students at the California Institute of Technology (Caltech), during 1961–1963. The book's co-authors are Feynman, Robert B. Leighton, and Matthew Sands.\n\n\"The Feynman Lectures on Physics\" is perhaps the most popular physics book ever written. More than 1.5 million English-language copies have been sold; probably even more copies have been sold in a dozen foreign-language editions. A 2013 review in \"Nature\" described the book as having \"simplicity, beauty, unity ... presented with enthusiasm and insight\".\n\nThe textbook comprises three volumes. The first volume focuses on mechanics, radiation, and heat, including relativistic effects. The second volume covers mainly electromagnetism and matter. The third volume covers quantum mechanics; for example, it shows how the double-slit experiment demonstrates the essential features of quantum mechanics. The book also includes chapters on the relationship between mathematics and physics, and the relationship of physics to other sciences.\n\nIn 2013, Caltech in cooperation with The Feynman Lectures Website made the book freely available, on the web site.\n\nBy 1960, Richard Feynman’s research and discoveries in physics had resolved a number of troubling inconsistencies in several fundamental theories. In particular, it was his work in quantum electrodynamics for which he was awarded the 1965 Nobel Prize in physics. At the same time that Feynman was at the pinnacle of his fame, the faculty of the California Institute of Technology was concerned about the quality of the introductory courses for undergraduate students. It was thought the courses were burdened by an old-fashioned syllabus and the exciting discoveries of recent years, many of which had occurred at Caltech, were not being taught to the students.\n\nThus, it was decided to reconfigure the first physics course offered to students at Caltech, with the goal being to generate more excitement in the students. Feynman readily agreed to give the course, though only once. Aware of the fact that this would be a historic event, Caltech recorded each lecture and took photographs of each drawing made on the blackboard by Feynman.\n\nBased on the lectures and the tape recordings, a team of physicists and graduate students put together a manuscript that would become \"The Feynman Lectures on Physics\". Although Feynman's most valuable technical contribution to the field of physics may have been in the field of quantum electrodynamics, the Feynman Lectures were destined to become his most widely-read work.\n\n\"The Feynman Lectures\" are considered to be one of the most sophisticated and comprehensive college-level introductions to physics. Feynman himself stated in his original preface that he was “pessimistic” with regard to his success in reaching all of his students. The Feynman lectures were written “to maintain the interest of very enthusiastic and rather smart students coming out of high schools and into Caltech”. Feynman was targeting the lectures to students who, “at the end of two years of our previous course, [were] very discouraged because there were really very few grand, new, modern ideas presented to them”. As a result, some physics students find the lectures more valuable after they have obtained a good grasp of physics by studying more-traditional texts, and the books are sometimes seen as more helpful for teachers than for students.\n\nWhile the two-year course (1961–1963) was still underway, rumors of it spread throughout the physics research and teaching community. In a special preface to the 1989 edition, David Goodstein and Gerry Neugebauer claimed that as time went on, the attendance of registered undergraduate students dropped sharply but was matched by a compensating increase in the number of faculty and graduate students. Co-author Matthew Sands, in his memoir accompanying the 2005 edition, contested this claim. Goodstein and Neugebauer also stated that, “it was [Feynman’s] peers — scientists, physicists, and professors — who would be the main beneficiaries of his magnificent achievement, which was nothing less than to see physics through the fresh and dynamic perspective of Richard Feynman”, and that his \"gift was that he was an extraordinary teacher of teachers\".\n\nAddison-Wesley published a collection of exercises and problems to accompany \"The Feynman Lectures on Physics\". The problem sets were first used in the 1962-1963 academic year, and were organized by Robert B. Leighton. Some of the problems are sophisticated and difficult enough to require an understanding of advanced topics, such as Kolmogorov's zero–one law. The original set of books and supplements contained a number of errors, some of which rendered problems insoluble. Various errata were issued, which are now available online.\n\nAddison–Wesley also released in CD format all the audio tapes of the lectures, over 103 hours with Richard Feynman, after remastering the sound and clearing the recordings. For the CD release, the order of the lectures was rearranged from that of the original texts. The publisher has released a table showing the correspondence between the books and the CDs.\n\nIn March 1964, Feynman appeared once again before the freshman physics class as a lecturer, but the notes for this particular guest lecture were lost for a number of years. They were finally located, restored, and made available as \"\".\n\nIn 2005, Michael A. Gottlieb and Ralph Leighton co-authored \"Feynman's Tips on Physics\", which includes four of Feynman's freshman lectures which had not been included in the main text (three on problem solving, one on inertial guidance), a memoir by Matthew Sands about the origins of the \"Feynman Lectures on Physics\", and exercises (with answers) that were assigned to students by Robert B. Leighton and Rochus Vogt in recitation sections of the Feynman Lectures course at Caltech. Also released in 2005, was a \"Definitive Edition\" of the lectures which included corrections to the original text.\n\nAn account of the history of these famous volumes is given by Sands in his memoir article “Capturing the Wisdom of Feynman\", and another article \"Memories of Feynman\" by the physicist T. A. Welton.\n\nIn a September 13, 2013 email to members of the Feynman Lectures online forum, Gottlieb announced the launch of a new website by Caltech and The Feynman Lectures Website which offers \"[A] free high-quality online edition\" of the lecture text. To provide a device-independent reading experience, the website takes advantage of modern web technologies like HTML5, SVG, and MathJax to present text, figures, and equations in any sizes while maintaining the display quality.\n\n\n\n\nSix readily-accessible chapters were later compiled into a book entitled \"Six Easy Pieces: Essentials of Physics Explained by Its Most Brilliant Teacher\". Six more chapters are in the book \"Six Not So Easy Pieces: Einstein's Relativity, Symmetry and Space-Time\".\n\n“\"Six Easy Pieces\" grew out of the need to bring to as wide an audience as possible, a substantial yet nontechnical physics primer based on the science of Richard Feynman... General readers are fortunate that Feynman chose to present certain key topics in largely qualitative terms without formal mathematics…”\n\nChapters:\n\nChapters:\n\nChapters:\n\n\n\n\n\nAtomic Discourse in the Feynman Lectures on Physics\n"}
{"id": "6702611", "url": "https://en.wikipedia.org/wiki?curid=6702611", "title": "The Naturalists' Handbooks", "text": "The Naturalists' Handbooks\n\nThe Naturalists' Handbooks is a series of natural history books aimed at students, naturalists and ecologists. Most volumes cover topics relating to insects, but some cover other groups of invertebrates, and some are botanical or mycological in scope, and other cover study techniques.\n\nA list of the volumes published to date is:\n"}
{"id": "1131755", "url": "https://en.wikipedia.org/wiki?curid=1131755", "title": "The Origins of Virtue", "text": "The Origins of Virtue\n\nThe Origins of Virtue is a 1996 popular science book by Matt Ridley, which has been recognised as a classic in its field. In the book, Ridley explores the issues surrounding the development of human morality. The book, written from a sociobiological viewpoint, explores how genetics can be used to explain certain traits of human behaviour, in particular morality and altruism.\n\nStarting from the premise that society can on a simplistic level be represented as a variant of the prisoner's dilemma, Ridley examines how it has been possible for a society to arise in which people choose to co-operate rather than defect.\n\nRidley examines the history of different attempts which have been made to explain the fact that humans in society do not defect, looking at various computer generated models which have been used to explain how such behaviour could arise. In particular he looks at systems based on the idea of tit for tat, where members of the group only cooperate with those who also cooperate and exclude those who do not. This allows altruistic behaviour to develop, and causes the optimum solution to the dilemma, to no longer be to defect but instead to cooperate. He applies this to humans and suggests that genes which generated altruistic-tit for tat behaviour would be likely to be passed on and therefore give rise to the kind of behaviour we see today.\n\nFrom this argument Ridley argues that society operates best in groups of around 150 individuals, which he suggests is the level at which humans are capable of being sure about which members to cooperate with and which to exclude. Although he avoids drawing any specific political points, Ridley ends his book by arguing for a smaller state operating on a more local level.\n\n\n"}
{"id": "32495538", "url": "https://en.wikipedia.org/wiki?curid=32495538", "title": "Thermodynamic efficiency limit", "text": "Thermodynamic efficiency limit\n\nThermodynamic efficiency limit is the absolute maximum theoretically possible conversion efficiency of sunlight to electricity. Its value is about 86%, which is the Chambadal-Novikov efficiency, an approximation related to the Carnot limit, based on the temperature of the photons emitted by the Sun's surface.\n\nSolar cells operate as quantum energy conversion devices, and are therefore subject to the thermodynamic efficiency limit. Photons with an energy below the band gap of the absorber material cannot generate an electron-hole pair, and so their energy is not converted to useful output and only generates heat if absorbed. For photons with an energy above the band gap energy, only a fraction of the energy above the band gap can be converted to useful output. When a photon of greater energy is absorbed, the excess energy above the band gap is converted to kinetic energy of the carrier recombination. The excess kinetic energy is converted to heat through phonon interactions as the kinetic energy of the carriers slows to equilibrium velocity. Hence, the solar energy cannot be converted to electricity beyond a certain limit.\n\nSolar cells with multiple band gap absorber materials improve efficiency by dividing the solar spectrum into smaller bins where the thermodynamic efficiency limit is higher for each bin. The thermodynamic limits of such cells (also called multi-junction cells, or tandem cells) can be analyzed using and online simulator in nanoHUB.\n\nThermodynamic efficiency limits for different solar cell technologies are as follows: \n\nExcitonic solar cells generates free charge by bound and intermediate exciton states unlike inorganic and crystalline solar cells. The efficiency of the excitonic solar cells and inorganic solar cells (with less exciton-binding energy) cannot go beyond 31% as explained by Shockley and Queisser.\n\nCarrier multiplication facilitates multiple electron-hole pair generation for each photon absorbed. Efficiency limits for photovoltaic cells can be theoretically higher considering thermodynamic effects. For a solar cell powered by the Sun's unconcentrated black body radiation, the theoretical maximum efficiency is 43% whereas for a solar cell powered by the Sun's full concentrated radiation, the efficiency limit is up to 85%. These high values of efficiencies are possible only when the solar cells use radiative recombination and carrier multiplication.\n\n"}
{"id": "1617461", "url": "https://en.wikipedia.org/wiki?curid=1617461", "title": "Tvashtar Paterae", "text": "Tvashtar Paterae\n\nTvashtar Paterae compose an active volcanic region of Jupiter's moon Io located near its north pole. It is a series of paterae, or volcanic craters. It is named after Tvashtar, the Hindu god of blacksmiths.\nTvashtar was studied by the Galileo spacecraft over several years. During this time, a long, high curtain of lava was seen to erupt from one patera, a lake of superheated silicate lava erupted in the largest patera, and finally a plume of gas burst out, rising above Io and blanketing areas as far away as .\n\nAn eruption on Tvashtar on February 26, 2007 was photographed by the New Horizons probe as it went past Jupiter \"en route\" to Pluto. The probe observed an enormous high plume from the volcano, with an as-yet unexplained filamentary structure made clearly visible by the background light from the sun.\n\n\n"}
{"id": "5307952", "url": "https://en.wikipedia.org/wiki?curid=5307952", "title": "Two in the Far North", "text": "Two in the Far North\n\nTwo in the Far North is a biographical novel written by Margaret Murie. Raised in Fairbanks, in the U.S. state of Alaska, and wife and companion of the biologist Olaus Murie, she tells the tale of their lives spent first living, then exploring and finally fighting for the preservation of the final wilderness frontiers of Alaska.\n\nThe book is divided into sections covering her childhood in the northernmost state (including the beginning of rail travel), her honeymoon in the unexplored wilds, later biological survey expeditions (with members including her husband and small baby) and finally her whirlwind trips back to Alaska from her home in Wyoming.\n\n"}
{"id": "22680086", "url": "https://en.wikipedia.org/wiki?curid=22680086", "title": "Tähdet ja avaruus", "text": "Tähdet ja avaruus\n\nTähdet ja avaruus is a Finnish science magazine which publishes recent developments, news and interviews in astronomy, space technology, cosmology and amateur astronomy. It is the largest circulation astronomy magazine in Scandinavia. \n\n\"Tähdet ja avaruus\" is a member magazine of the Ursa Astronomical Association and it can also be subscribed without a membership. Ursa Astronomical Association is a non profit organization which promotes astronomy and related sciences and astronomy school education. \n\nThe editor in chief of the magazine is Marko Pekkola, editor is Laura Koponen, staff science writers are Sakari Nummila and Anne Liljeström. Layout is by Heikki Laurila. A group of free science journalists assist the magazine. Many Finnish astronomers answer the readers questions in the questions and answers column.\n\n"}
{"id": "29004985", "url": "https://en.wikipedia.org/wiki?curid=29004985", "title": "Whorl (biology)", "text": "Whorl (biology)\n\nIn biology, a whorl is a cluster of cells or tissue that surrounds another and wraps around another in an expanding circular pattern. Whorls occur at the ends of different structures or in the middle of structures. Structures of some organs are often described as whorls and used in the aid of identification.\n\nThe Hassall's corpuscle, formed from type VI epithelial reticular cells in the thymus, is an example of a whorl-shaped structure.\n"}
{"id": "13984801", "url": "https://en.wikipedia.org/wiki?curid=13984801", "title": "Wildlife observation", "text": "Wildlife observation\n\nWildlife observation is the practice of noting the occurrence or abundance of a dead or living animal species at a specific location and time. The process of scientific wildlife observation includes the reporting of what (diagnosis of the species), where (geographical location), when (date and time), who (details about observer), and why (reason for observation, or explanations for occurrence). Wildlife observation can be performed if the animals are alive, with the most notable example being face-to-face observation and live cameras, or are dead, with the primary example being the notifying of where roadkill has occurred. This outlines the basic information needed to collect data for a wildlife observation; which can also contribute to scientific investigations of distribution, habitat relations, trends, and movement of wildlife species. One example of this type of activity is bird watching. Wildlife observation allows for the study of organisms with minimal disturbance to their ecosystem depending on the type of method or equipment used. The use of equipment such as unmanned aerial vehicles (UAVs), more commonly known as drones, may disturb and cause negative impacts on wildlife. Specialized equipment can be used to collect more accurate data.\n\nThrough wildlife observation, there are many important details that can be discovered about the environment. For instance, if a fisher in Taiwan discovers that a certain species of fish he/she frequently catches is becoming rarer and rarer, there might be a substantial issue in the water that fisher is fishing in. It could be that there is a new predator in the water that has changed the animal food chain, a source of pollution, or perhaps even a larger problem. Regardless of the reason, this process of observing animals can help identify potential issues before they become severe problems in the world.\n\nAdditionally, through animal observation, those who participate are also actively participating in the conservation of animal life. Oftentimes, the two subjects go hand-in-hand with one another because through the observation of animals, individuals are also discovering what issues animals around the world are currently facing and if there are any ways to put up a fight against them. With more observation, fewer species of animals will become extinct.\n\nBefore one can get started observing wildlife and helping the environment, it is important to research the animal they are choosing to observe. If one simply went into the observation process and skipped the crucial process of obtaining knowledge about the animals, it would be difficult for them to determine if anything was out of the ordinary. Before observing, it would be wise to find out simple information about the animal such as:\n\nThere are a variety of projects and websites devoted to wildlife observations. One of the most common projects are for bird observations (for example: e-bird). For those who enjoy bird watching, there are a variety of ways one can contribute to this type of wildlife observation. The National Wildlife Refuge System has volunteer opportunities, citizen science projects, and if one is limiting in time; could purchase a Federal Duck Stamp that donates money to the wildlife refuge lands. In the past few years, websites dedicated to reporting wildlife across broad taxonomic ranges have become available. For example, the California Roadkill Observation System provides a mechanism for citizen-scientists in California to report wildlife species killed by vehicles. The Maine Audubon Wildlife Road Watch allows reporting of observations of both dead and live animals along roads. A more recent addition to wildlife observation tools are the web sites that facilitate uploading and management of images from remote wildlife cameras. For example, the Smithsonian Institution supports the eMammal and Smithsonian Wild programs, which provide a mechanism for volunteer deployment of wildlife cameras around the world. Similarly, the Wildlife Observer Network hosts over a dozen wildlife-camera projects from around the world, providing tools and a database to manage photographs and camera networks.\n\nMonitoring programs for wildlife utilize new and easier ways to monitor animal species for citizen scientists and research scientists alike. One such monitoring device is the automated recorder. Automated recorders are a reliable way to monitor species such as bird, bats, and amphibians as they provide ability to save and independently identify a specific animal call. The automated recorder analyzes the sounds of the species to identify the species and how many there are. It was found that using the automated recorders produced larger quantity and even more quality data when compared with traditional, point-count data recording. While providing better quality, it also provides a permanent record of the census which can be continually reviewed for any potential bias. This monitoring device can improve wildlife observation and potentially save more animals. Using this device can allow for continued tracking of populations, continued censusing of individuals within a species, and allow for faster population size estimates.\n\nOne of the most popular forms of wildlife observation, birdwatching, is typically performed as a recreational pleasure. Those looking to birdwatch typically travel into a forest or other wooded area with a pair of binoculars in hand to aid the process. Birdwatching has become all the more important with the amount of deforestation that has been occurring in the world. Birds are arguably the most important factor in the balance of environmental systems: \"They pollinate plants, disperse seeds, scavenge carcasses and recycle nutrients back into the earth.\" A decrease in the total number of birds would cause destruction to much of the environmental system. The plants and trees around the world would die at an alarming rate which would, in turn, set off a chain reaction that would cause many other animals to die due to the environment change and habitat loss. \nOne of the ways that birdwatching has an effect on the environment as a whole is that through consistent birdwatching, an observer would be able to identify whether they are seeing less of a certain species of bird. If this happens, there typically is a reasons for the occurrence, whether it be because of an increase in pollution in the area or possibly an increase in the population of predators. If a watcher were to take notice of a change in what they typically see, they could notify the city or park and allow them to investigate into the cause a bit further. Through this action, birdwatchers are preserving the future for both animal and human life.\n\nSubsequently, by taking children birdwatching it is allowing the future generation to understand the importance of animal observation. If children learn at a young age how the environmental system works and that all life is intertwined, the world will be in much better hands. These children will be the ones pioneer conservation movements and attempt to protect the habit for all animals.\n\nLive streams of animal exhibits at various zoos and aquariums across the United States have also become extremely popular. The Tennessee Aquarium has a webcam that allows online viewers to take a look into the happening so their Secret Reef exhibit which consists of reef fish, sharks, and a rescued green sea turtle.\n\nPerhaps the most popular animals cams in the United States though come from, naturally, the largest zoo in the United States: The San Diego Zoo. The San Diego Zoo features eight live cams on their website – A panda, elephant, ape, penguin, polar bear, tiger, condor, and koala. The purpose of the live streams is to help educate the public about the behaviors of several different animals and to entertain those who might not be able to travel to a zoo.\n\nThe other notable zoos that have webcams are the National Zoo, Woodland Park Zoo, Houston Zoo, and Atlanta Zoo.\n\nAdditionally, the Smithsonian National Museum of Natural History has opened a butterfly and plant observation pavilion. Visitors walk into a large tent and experience a one-of-a-kind situation in which hundreds of rare butterflies from all across the world are inches from their faces.\n\nAs is the case with a majority of subjects, one of the best and most effective ways to observe live animals is through data collection. This process can be done through a livestream or in the wild but it is more useful if the data is collected on animals that are in currently in the wild. The ways the data can be collected are endless and it really just depends on what purpose an individual has as to what data would be the most useful.\n\nFor example, if someone is interested in how deer interact with other animals in a certain location, it would be beneficial for them to take notes and record all of the animals that are native to the area where the deer are located. From there, they can describe any scenarios in which the deer had a positive or negative interaction with the other species of animals. In this instance, it would not really be helpful for the observer to collect data pertaining to the types of food the deer eat because the study is only focusing on the interaction amongst animals.\n\nAnother example of how collecting data on wildlife would be useful is keeping track of the total number of a certain species exists within a forest. Naturally, it will be impossible to get a definitive number but if an accurate approximation can be made, it could be beneficial in determining if there has been a random increase or decrease in the population. If there is an increase, it could be due to a change in the species migration habits and if there is a decrease, it could be due to an external factor such as pollution or introduction of a new predator.\n\nMany states have already begun to set up websites and systems for the public. The main purpose behind the movement is so that they can notify other individuals about road-killed wildlife. If enough people fill out the forms located on the websites, the government will become notified that there have been occurrences of a loss of animal life and will take the steps required to prevent it. Typically, the step that is taken is the posting of a wildlife crossing sign that, in turn, allows the public to know where there are common animal crossings. Maine and California are the states that have been the pioneers of this movement and this process has become particularly important on heavily traveled roads as no one would like endanger the animals or themselves.\n\nCurrently, there is an app (available on both iPhone and Android devices) made specifically for the purpose of identifying road-kill called “Mobile Mapper.” The app is a partner of the HerpMapper website. The purpose of the website is to use the user recorded observations for research and conservation purposes.\n\nOn average, the cost of repairing a car that has been damaged by a deer or other medium to large-sized animal is $2,000. Even though there is no way that accidents involving animals can completely be prevented, placing more signs about possible animal crossings zones would cause drivers to drive more carefully and therefore have fewer accidents. Economically, this means that more families will be saving money and it could be used in a different way to help contributed to society as a whole.\n\nClimate change is one of the most heavily discussed topics around the world today, both politically and scientifically. The climate that Earth is currently experiencing has been steadily changing over time due to both natural causes and human exploitation. Climate change has the potential to be detrimental to wildlife across the world, whether that be through rising sea levels, changes in temperatures through the years, or deforestation. These are just a few of the examples of the contributing factors to climate change.\n\nClimate change is not something that citizens can entirely prevent from happening even if they wanted to. There are many natural causes such as volcanic activity and the Earth's orbit around the sun that are strong contributing factors to the phenomena. There are, however, prevention measures that can be taken to prevent climate change from happening as quickly. The primary way to prevent climate change is for society to reduce the amount of greenhouse gases that are present in the atmosphere. This can be done through the improving of energy efficiency in many buildings, the stoppage of deforestation so more carbon dioxide can be removed from the atmosphere, and mode switching.\n\nOne of the more notable effects climate change has on the environment is the rising of sea levels around the world. Over the past 100 years, the sea level has risen approximately 1.8 millimeters each year. The steady rise in sea levels can be attributed to the steadily increasing temperatures the Earth faces each year which causes the ice caps and glaciers to melt. This increase in sea level is detrimental to the coastal ecosystems that exist around the world.\n\nThe increase in sea level causes flooding on coastal wetlands, where certain animals will be unable to survive due to saltwater inundation. The increase in the total amount of saltwater present in these wetlands could prove to be problematic for many species. While some may simply have to migrate to other areas, smaller ecosystems within the wetlands could be destroyed which, once again, influences the animal food chain.\n\nPolar bears are animals that are specifically affected through the process of rising sea levels. Living near the Arctic region, polar bears find their food on ice caps and sheets of ice. As these sheets continue to become fewer in quantity, it is predicted that the polar bears will have a difficult time sustaining life and that by the year 2050, there could be less than 20,000 on Earth.\n\nCoral reefs are the primary ecosystem that would be affected through a continuing increase in the sea level:\"The coral reef ecosystem is adapted to thrive within certain temperature and sea level range. Corals live in a symbiotic relationship with photosynthetic zooxanthellae. Zooxanthellae need the sunlight in order to produce the nutrients necessary for the coral. Sea level rise may cause a decrease in solar radiation at the sea surface level, affecting the ability of photosynthetic zooxanthellae to produce nutrients for the coral, whereas, a sudden exposure of the coral reef to the atmosphere due to a low tide event may induce coral bleaching.\"\n\nThe loss of coral would have a subsequent effect on the total number of fish that exist within these ecosystems. In the Indo-Pacific coral reefs alone, there are in-between 4000 and 5000 different species of fish that have a relationship with the species of coral. Specifically, the numerous different species of butterfly fish that feed on coral within these reefs would be affected if the coral was unable to live due to an increase in sea level. Referring back to the food chain topic, this would then subsequently but directly affect species of snappers, eels, and sharks that use butterfly fish as a primary source of food. If the snappers cannot find any butterfly fish to eat because the butterfly fish are dying due to the lack of coral, it means that the snapper population will decrease as well.\n\nThe rising of sea level has the possibility to be catastrophic to the coastal ecosystems.\n\nPollution is another crucial threat to animal life, and human life, across the world. Every form of pollution has an effect on wildlife, whether it be through the air, water, or ground. While sometimes the origin and form of pollution is visible and easy to determine, other times it can be a mystery as to what exactly is causing the death of animals. Through constant and consistent observation of habitat analysis, humans can help prevent the loss of animal life by recognizing the early signs of pollution before the problem becomes too large.\n\nPollution can enter bodies of water in many different ways - Through toxic runoff from pesticides and fertilizers, containers of oil and other hazardous materials falling off of ships, or just from debris from humans that has not been picked up. No matter what the form of pollution is, the effects water pollution has on animal life can be drastic. For example, the BP oil spill which occurred in 2010 impacted over 82,000 birds, 6,000 sea turtles, approximately 26,000 marine animals, and hundreds of thousands of fish.\n\nWhile the observation of how animal life was and has been affected by this spill is unique and definitely on the larger scale, it still represents an accurate depiction of how observation can be crucial to animal lives. For example, by observing that a certain species of sea turtle was affected by the oil spill, zoologists and their teams would be able to determine the effects the loss of that sea turtle would have.\n\nAnother prominent example is how if one day a fisherman goes to a lake that he/she frequently visits and notices two or three dead fish on the surface. Knowing that that frequently does not happen, the fisherman tells his local city officials and park rangers about the occurrence and they find out that a farmer has been using a new pesticide that runs off into the lake. By simply observing what is common and what is not, the effects of some water pollution can be stopped before becoming too severe.\n\nAir pollution is commonly associated with the image of billowing clouds of smoke rising into the sky from a large factory. While the fumes and smoke previously stated definitely is a prominent form of air pollution, it is not the only one. Air pollution can come from the emission of cars, smoking, and other sources. Air pollution does not just affect birds though, like one may have thought. Air pollution affects mammals, birds, reptiles, and any other organism that requires oxygen to live. Frequently, if there is any highly dangerous air pollution, the animal observation process will be rather simple: There will be an abundance of dead animals located near the vicinity of the pollution.\n\nThe primary concern of air pollution is how widespread the pollution can become in a short period of time. Acid rain is one of the largest forms of pollution today. The issue with acid rain is that it affects literally every living organism it comes in contact with, whether that be trees in a forest, water in an ocean or lake, or the skin of humans and animals. Typically, acid rain is a combination of sulfur dioxide and nitrogen oxides that are emitted from factories. If it is not controlled in a timely manner, it could lead to loss of life due to the dangerous nature of the composition of the rain.\n\nDeforestation has become one of the most prevalent issues environmentally. With an continuously growing population and not having the space to contain all the humans on Earth, forests are frequently the first areas that are cleared to make more room. According to National Geographic, forests still cover approximately 30 percent of the land on Earth but each year large portions are cleared.\n\nWith deforestation, there are numerous subsequent side effects. Most notably, the clearing of entire forests (in some instances) destroys the habitat for hundreds of species of animals and 70 percent of the animals that reside in the forest will die as a result. Additionally, deforestation causes a reduction in the total canopy cover which leads to more extreme temperature swings on the ground level because there are no branches and leaves to catch the sun's rays.\n\nThe way to combat the severe effects on the loss of animal life would be to stop cutting trees and forests down. While this is unlikely and almost impossible to happen, there is another solution: the partial removal of forests. By only removing portions of the forest, it keeps the environment of the entire forest in tact which allows the animals to adapt to their surroundings. Additionally, it is recommended that for every tree that is cut down that another one be planted elsewhere in the forest.\n\nTypically, the costs of animal observation are minuscule. As previously stated, animal observation can be done on a small or large scale; it just depends what goal an individual has in mind. For example, animal observation can be performed in the backyard of a house or at a local state park at no charge. All one would have to do is take a notepad, phone, or other device to write down their data and observations. On a larger scale, animal observation could be performed at an animal reserve, where the associated costs would be those associated with keeping the animals happy inside the reserve.\n\nWhile it is impossible to pinpoint exactly how much the zoos across the world spend on live streaming, it is estimated to be in the $1,000 range for every camera that is set up.\n\nReferring back to the example from the \"Deceased Wildlife Observation\" section, it becomes apparent how animal observation can save families and the government money. With the average cost of repairing a car that has damage from a large sized animal being $2,000, families and the government could save money by making the public aware that they should proceed with caution in areas where animals have been hit.\n\nAdditionally, approximately $44 million of the $4.3 billion spent on water purity is spent each year on protecting aquatic species from nutrient pollution. It is encouraging that the government is willing to spend the money to help save animals' lives, sometimes the effects of the pollution take effect before they are able to stop them entirely. One million seabirds and hundred thousand aquatic mammals and fish that are killed as a result of water pollution each year and that has its economic effects, both directly and indirectly.\n\nDirectly, the loss of aquatic mammals and fish has a direct impact on the sales of food. The EPA estimated recently that the effects of pollution cost the fishing industry tens of millions of dollars in sales. Indirectly, the loss of birds causes humans to spend more money on pest control because the food chain is out of order. The small rodents and insects that some birds prey upon are no longer being killed if the birds die. This means more of these pests find their ways into homes which causes more people to call exterminators, therefore setting off a chain reaction. The exterminators then must use insecticides to kill the animals which can have harmful runoff into the ground and local water systems, instead of allowing it to be done naturally by the animal food chain.\n\n"}
