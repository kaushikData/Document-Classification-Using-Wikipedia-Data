{"id": "8208965", "url": "https://en.wikipedia.org/wiki?curid=8208965", "title": "A258 road", "text": "A258 road\n\nThe A258 road is an A road in England, running through East Kent from Dover to Sandwich. It is in Zone 2 of the Great Britain numbering scheme.\n\nIt begins at the A256 within Dover, running up Castle Hill and passing Dover Castle on its eastern side and the Duke of York's Royal Military School on its western side. It then crosses the A2 at a four-way roundabout (called Guston Roundabout) at the top of Jubilee Way before running behind the East Kent coast, with turn-offs to Westcliffe, Martin Mill and St Margaret's at Cliffe. \nIt then runs through Ringwould (passing Ripple Mill), Walmer and Deal. \nWhilst in Deal it is named 'the Strand' and it passes Deal Castle, then becomes part of a one-way traffic system in Deal, it heads up 'Victoria Road', then right onto 'Ranelagh Road' then left onto 'Prince of Wales Terrace' (beside the coastline). 'Deal Castle Road' leads back to the Ringwould/Dover route.\nThe route heads away from the coast on 'Broad Street', where it crosses over the pedestrianised high street and becoming 'Queen Street'. It passes over the railway close to Deal Railway station . Then it becomes 'London Road' heading to Upper Deal. Then it heads north-west, passing Sholden and later Betteshanger Park. It is once again called the A258, passing through the hamlet of Hacklinge and past the junction to Finglesham and then the junction to Worth. When it reaches the southern part of Sandwich, near Woodnesborough, it terminates at another junction with the A256 (Sandwich By-pass) at Stone Cross.\nIn 2006, improvement works were carried out to the A2(T)/A258 Guston Roundabout Junction, Dover. This meant the road from Deal was widened at the junction to allow for more queuing on the road.\n\n"}
{"id": "8219492", "url": "https://en.wikipedia.org/wiki?curid=8219492", "title": "A4123 road", "text": "A4123 road\n\nThe A4123, also known as the Birmingham New Road or Wolverhampton New Road, is a major road in the West Midlands linking Wolverhampton with Birmingham. It was one of the first major new roads constructed for use by motor traffic, and was designed as an unemployment relief project. It runs roughly northwest to southeast from the Wolverhampton Ring Road to Harborne, west Birmingham.\n\nConstruction of the road began on 4 February 1924, and was built in individual sections., and provided jobs for at least 470 unemployed workers in surrounding areas including Birmingham, Wolverhampton, Dudley, West Bromwich, Smethwick and Oldbury. It was opened by the then Prince Of Wales (later Edward VIII of the United Kingdom) on 2 November 1927.\n\nThe road has previously been a Trunk Road (looked after by the Highways Agency), but was detrunked on 13 November 2008.\n\nNational Express West Midlands service 126 serves the majority of the A4123 from Birmingham to Wolverhampton. Buses are supposed to run every 10 minutes during peak times.\n\n"}
{"id": "39301183", "url": "https://en.wikipedia.org/wiki?curid=39301183", "title": "Angelo Vermeulen", "text": "Angelo Vermeulen\n\nAngelo Vermeulen (born 1971) is a Belgian visual artist. His multidisciplinary oeuvre crosses over the boundaries of biology, technology and community. Vermeulen won the Witteveen+Bos Art+Technology Award in 2012. He is crew commander of HI-SEAS, a Mars simulation study on improving the nutritional value of space food, funded by NASA. As a TED Senior Fellow he travels the world to share information about his art and scientific projects.\n\nAngelo Vermeulen is a space systems researcher, biologist, artist and community organizer. In his work, he ties technological, ecological and social systems together through group engagement and collaboration.\n\nBiomodd is one of his most well-known art projects and consists of a worldwide series of interactive art installations in which computers and ecosystems coexist. In 2009 he launched SEAD (Space Ecologies Art and Design), a platform for research on architecture and ethics of space colonization. Seeker is one of the resulting projects involving co-created starship sculptures that evolve over time. From 2011 to 2012 he was a member of the European Space Agency Tropical Team Arts & Science (ETTAS) and in 2013 he was a crew a commander for the NASA-funded HI-SEAS Mars mission simulation in Hawai'i.\n\nHis space-related work led him to start a new PhD at Delft University of Technology, developing paradigm-shifting concepts for evolvable starships. He co-authored the book 'Baudelaire in Cyberspace: Dialogues on Art, Science and Digital Culture' with philosopher Antoon Van den Braembussche, and gives talks about his work around the world. IN 2012 he was a Michael Kalil Endowment for Smart Design Fellow at Parsons in New York.\n\nCurrently, Vermeulen is a TED Senior Fellow and holds positions at LUCA School of Visual Arts in Ghent (Belgium) and Die Angewandte in Vienna (Austria).Vermeulen is also a member of the Arts & Science Topical Team of the European Space Agency (ESA).\n\nVermeulen grew up in the Belgian city Sint-Niklaas. In 1998 Vermeulen completed his PhD on the deformation of the teeth of non-biting midges at the biology department of the Catholic University of Leuven in Belgium. He also graduated from the Academy of Fine Arts in Leuven, where he studied photography. Vermeulen left Belgium to work in London as a photographer together with Nick Waplington. After his return to Belgium in 2001, he attended a two-year post-academic course at the Higher Institute for Fine Arts (HISK) in Belgium. This became the starting point of an exploration trying to find out how biology and ecological processes could interact in art and materialize them as art installations.\n\n2011-2015: PhD in space habitat design and participatory systems engineering, Delft University of Technology\n\n2009-2011: Adjunct Professor, Faculty of Information and Communication Studies, University of the Philippines, Open University, Los Banos, Philippines\n\n2005-2007: Film and Video Art studies at the Royal Academy of Fine Arts DKO, Antwerp, Belgium\n\n2004-2011: Lecturer, Sint-Lucas Visual Arts, Ghent, Belgium\n\n2001-2003: Postgraduate studies at the Higher Institute for Fine Arts, Leuven, Belgium\n\n1994-1998: Photography studies at the Academy of Fine Arts, Leuven, Belgium\n\n1993-1998: PhD in Biology, University of Leuven, Belgium\n\nSeeker is a DIY spaceship model which experiments with the integration of the technological, ecological and social systems that enable long-term survival in a spaceship. Vermeulen started the first edition of Seeker (DV1) in response to the Witteveen+Bos Art+Technology award he won in 2012. The designing and making of Seeker was a collaboration between Witteveen+Bos engineers, local artists, independent volunteers and the artist as inspirer/connector. The spaceship was exhibited in autumn 2012 in the Bergkerk church in Deventer, the Netherlands.\n\nBy the end of the exhibition, Seeker became partly demolished and re-used for a second edition during the Space Odyssey 2.0-exhibition in Z33 in Hasselt (Belgium). Several months before the opening of the exhibition, Vermeulen launched an open call for ideas and participation on Seeker (HS2). The outward construction was unaltered, but the interior changed depending on the needs and priorities of the new crew. Although Vermeulen and Matilda Krzykowski share their leadership over the crew, there is no hierarchy in the process of realizing the work.\n\nSeeker is primarily a community project in which a tiny, isolating room is created to provide the best possible conditions for a particular group of inhabitants. Seeker developed itself as a traveling project with always new groups of participants.\n\nStarted in Athens Ohio during a four-month residency at the ‘Aesthetic Technologies Lab’ in 2007.\n\nBiomodd is a socially engaged art installation that finds meaningful relationships between biology, computers and people. On its most basic level, Biomodd creates symbiotic relationships between plants and computers, and ignites conversations among the community around it. For example, algae are used to cool computer processors so they can run faster, while the heat that is generated by the computer electronics is used to create ideal growing conditions for a plant-based ecosystem. This dynamic is the catalyst for a collaboration between the team members - which include artists, biologists, computer scientists, game designers, gardeners, community organizers - and members of the local community in which the project takes place.\n\nThis open source project was conceived by Belgian biologist turned artist Angelo Vermeulen. Fellow collaborators and himself have brought Biomodd to different countries throughout the world. The first version started in Athens (Ohio, USA) in 2007 and has since traveled to the Philippines, Slovenia, New Zealand, Belgium, New York (USA), Chile, the Netherlands and London (Great Britain). Biomodds all over the world are still ongoing and every single project has new groups of participants. This leading to very different results for every culture.\n\nBiomodd [ATH1] became a self-generating eco-system that gets stimulated by playing a computer game. By playing the computer game, the computer's components heat up and nurse the plants that surround them. Microscopic algae are used to simultaneously cool some of the hot components. Filmmaker Morgan Riles directed a documentary on the Biomodd [ATH1] which has been screened at the 27th International Festival of Films on Art, and the Houston Cinema Arts Festival in 2009.\n\nBiomodd [LBA2] was conceived in Los Baños in the Philippines. The installation contained local recycled materials, however, certain parts of previous versions were integrated into the new structure as well. Vermeulen and Diego Maranan co-lead a team of 22 members with different backgrounds. The travelling, social and evolving nature of the project is essential to it even though all versions are conceptually and physically connected.\n\nBiomodd [TUDelft3]: In October 2011 Vermeulen was invited by Professor Frances Brazier of the Systems Engineering section at TU Delft (the Netherlands) for the Biomodd project at the university.\n\nBiomodd [NYC4] was developed as part of the art exhibition “ReGeneration” at the New York Hall of Science in New York. ReGeneration included seventeen artists. In collaboration with the Immigrant Movement International, the Biomodd [NYC4] was part of Springmavera. In April 2012 Katherine Moriwaki and Vermeulen worked with the students of Parsons The New School for Design on the building of your own Bioreactor.\n\nVermeulen's artistic engagement consists of actively bringing art's radical freedom and focus on sensory, aesthetic and emotional directness to other domains, such as science, cultural communities, game culture and science fiction.\n\n\nAngelo Vermeulen became a TED Fellow in 2010 for a TED talk on Biomodd in Long Beach. In 2013, Vermeulen became a TED Senior Fellow.\n\nHI-SEAS (Hawaii Space Exploration Analog and Simulation) is an analog habitat for human spaceflight to Mars. HI-SEAS is located in an isolated position on the slopes of the Mauna Loavolcano on the island of Hawaii. The area has Mars-like features and an elevation of approximately 8,200 feet above sea level. HI-SEAS is funded by the NASA Human Research Program for four research missions. The missions are of extended duration from four months to a year.\n\nThe purpose of the detailed research studies is to determine what is required to keep a space flight crew happy and healthy during an extended mission to Mars and while living on Mars.Research into food, crew dynamics, behaviors, roles and performance, and other aspects of space flight and a mission on Mars itself is the primary focus. The HI-SEAS researchers also carry out studies on a variety of other topics as part of their daily activities.\n\nVermeulen was crew commander of a four-month Mars simulation mission. HI-SEAS (Hawaii Space Exploration Analogand Simulation) takes place on the flanks of the Mauna Loa Volcano which is the closest approximation of the actual surface of Mars. The mission intends to study improving the taste and nutritional quality of the meals consumed during a spaceflight. Previous spaceflight simulations such as MARS-500 proved the importance of the quality of the food during long periods of isolation of this nature. During the mission, Vermeulen is in charge of a six-man crew consisting of researchers from different backgrounds. Among the other researchers OlegAbramov, Simon Engler, Kate Greene, Sian Proctor, and Yajaira Sierra Sastre, Vermeulen is the only European member of the crew. Due to his experience in community building in complex conditions, such as Biomodd and other projects, he is commissioned as the leader of the crew. Aside from the food study, Vermeulen investigates the possibilities of remote-operated robotic agriculture in order to create semi-autonomous farms for Mars settlement. The mission is initiated by NASA in collaboration with Cornell University of New York and the University of Manoa in Hawaii.\n\nIn September - October 2015, Vermeulen exhibited a selection of art photos he made when he was commander on a HI-SEAS mission at the Dome of Visions in Stockholm (Sweden).\n\nThe Micro-Ecological Life Support System Alternative (MELiSSA) is a European Space Agency initiative (ESA) with the aim to develop the technology for a future regenerative life support systemfor long term human space missions. Initiated in 1989, the design is inspired by a terrestrial ecosystem. Today MELiSSA is a consortium made up of 30 organisations across Europe.\n\nVermeulen founded Space Ecologies Art and Design (SEAD), an artistic research platform on the architectures and biopolitics of space colonization in 2009. Two years after the platform was launched, Vermeulen started a doctoral research in Space habitat design and participatory systems engineering at the Delft University of Technology in the Netherlands. Vermeulen is a member of the Arts & Science Topical Team of the European Space Agency (ESA).\n\n\n\n"}
{"id": "55980248", "url": "https://en.wikipedia.org/wiki?curid=55980248", "title": "Anita Cochran (astronomer)", "text": "Anita Cochran (astronomer)\n\nAnita L. Cochran is an American astronomer, planetary scientist, and senior research scientist at the University of Texas at Austin. She is also the assistant director for research support at the McDonald Observatory. She focuses on the study of primitive bodies in the solar system and the composition of comets.\n\nCochran was born in New York City and raised on Long Island. She earned a bachelor's degree in Physics from Cornell University in 1976. She then went on to the University of Texas at Austin, where she completed a master's degree in Astronomy in 1979 and her PhD in Astronomy in 1982.\n\nIn her astronomy career, Cochran has taken on numerous high-level leadership roles. She served, for instance, as the chair of the Division for Planetary Sciences of the American Astronomical Society from 1995 to 1996 and a committee member from 1989-1992. She has also served on several committees for the National Research Council, including the Committee on Planetary and Lunar Exploration (COMPLEX). She was a co-investigator on the Comet Nucleus Tour, or CONTOUR, mission and on the imaging team for NASA's Comet Rendezvous Asteroid Flyby Mission.\n\nShe is currently a member of the International Astronomical Union and the National Optical Astronomy Observatory's Observatory Council.\n\nAnita Cochran is married to fellow astronomer Bill Cochran.\n"}
{"id": "50899559", "url": "https://en.wikipedia.org/wiki?curid=50899559", "title": "Aomawa Shields", "text": "Aomawa Shields\n\nAomawa L. Shields is an Assistant Professor of Physics and Astronomy at UC Irvine. Her research is focused on exploring the climate and habitability of small exoplanets, using data from observatories including NASA's Kepler spacecraft. Shields was previously an NSF astronomy and astrophysics postdoctoral fellow and a UC President's Postdoctoral Fellow in the UCLA Department of Physics and Astronomy and the Harvard-Smithsonian Center for Astrophysics. She received her PhD in Astronomy and Astrobiology in 2014 from the University of Washington, and conducts research in the emerging field of exoplanet climates and habitability. She is one of only two astrophysicists to be recognized as a 2015 TED Fellow. Shields founded the Rising Stargirls program in 2015 to encourage middle school girls of all colours and backgrounds to explore the universe.\n\nShe attended Phillips Exeter Academy.\n\n\n"}
{"id": "10395600", "url": "https://en.wikipedia.org/wiki?curid=10395600", "title": "Atmospheric radiative transfer codes", "text": "Atmospheric radiative transfer codes\n\nAn Atmospheric radiative transfer model, code, or simulator calculates radiative transfer of electromagnetic radiation through a planetary atmosphere, such as the Earth's.\n\nAt the core of a radiative transfer model lies the radiative transfer equation that is numerically solved using a solver such as a discrete ordinate method or a Monte Carlo method. The radiative transfer equation is a monochromatic equation to calculate radiance in a single layer of the Earth's atmosphere. To calculate the radiance for a spectral region with a finite width (e.g., to estimate the Earth's energy budget or simulate an instrument response), one has to integrate this over a band of frequencies (or wavelengths). The most exact way to do this is to loop through the frequencies of interest, and for each frequency, calculate the radiance at this frequency. For this, one needs to calculate the contribution of each spectral line for all molecules in the atmospheric layer; this is called a \"line-by-line\" calculation.\nFor an instrument response, this is then convolved with the spectral response of the instrument. A faster but more approximate method is a \"band transmission\". Here, the transmission in a region in a band is characterised by a set of pre-calculated coefficients (depending on temperature and other parameters). In addition, models may consider scattering from molecules or particles, as well as polarisation; however, not all models do so.\n\nRadiative transfer codes are used in broad range of applications. They are commonly used as forward models for the retrieval of geophysical parameters (such as temperature or humidity). Radiative transfer models are also used to optimize solar photovoltaic systems for renewable energy generation. Another common field of application is in a weather or climate model, where the radiative forcing is calculated for greenhouse gases, aerosols, or clouds. In such applications, radiative transfer codes are often called radiation parameterization. In these applications, the radiative transfer codes are used in forward sense, i.e. on the basis of known properties of the atmosphere, one calculates heating rates, radiative fluxes, and radiances.\n\nThere are efforts for intercomparison of radiation codes. One such project was ICRCCM (Intercomparison of Radiation Codes in Climate Models) effort that spanned the late 1980s - early 2000s. The more current (2011) project, Continual Intercomparison of Radiation Codes, emphasises also using observations to define intercomparison cases.\n\nFor a line-by-line calculation, one needs characteristics of the spectral lines, such as the line centre, the intensity, the lower-state energy, the line width and the shape.\n\n\n\n"}
{"id": "25388296", "url": "https://en.wikipedia.org/wiki?curid=25388296", "title": "Australian Square Kilometre Array Pathfinder", "text": "Australian Square Kilometre Array Pathfinder\n\nThe Australian Square Kilometre Array Pathfinder (ASKAP) is a radio telescope array located at Murchison Radio-astronomy Observatory (MRO) in the Australian Mid West. ASKAP consists of 36 identical parabolic antennas, each 12 metres in diameter, working together as a single instrument with a total collecting area of approximately 4,000 square metres.\n\nIt is operated by the governmental research agency CSIRO and forms part of the Australia Telescope National Facility.\n\nASKAP's combination of fast survey speed and high sensitivity will allow activities such as researching the creation and early evolution of the Universe, analysing cosmic magnetism, testing predictions of the general theory of relativity, mapping black holes, and exploring the origins of galaxies.\n\nASKAP is also a technology demonstrator for the international Square Kilometre Array (SKA), a planned radio telescope that is planned to be the world's largest and most sensitive. The ASKAP's home, the MRO, has also been selected as one of the SKA's two central location.\n\nConstruction on ASKAP began in late 2009 and it was opened in October 2012, ready to become the world's fastest survey radio telescope.\n\nDevelopment and construction of ASKAP was led by CSIRO Astronomy and Space Science (CASS), in collaboration with scientists and engineers in The Netherlands, Canada and the USA, as well as colleagues from Australian universities and industry partners in China.\n\nThe Wajarri Yamatji people are the traditional owners of the land on which the observatory lies.\n\nThe construction and assembly of the dishes was completed in June 2012.\n\nThe features that will make ASKAP an unprecedented synoptic telescope include a wide field-of-view, large spectral bandwidth, extremely fast survey speed, and excellent u-v coverage.\n\nASKAP is located in the Murchison district in Western Australia, a region that is extremely \"radio-quiet\" due to the low population density and resultant lack of radio interference (generated by human activity) that would otherwise interfere with weak astronomical signals.\n\nThe unique radio quiet nature is being recognised as a natural resource and is being protected by the Australian Commonwealth and Western Australia State Government through a range of protective regulatory measures.\n\nData from ASKAP will be transmitted from the MRO to a supercomputer at the Pawsey Supercomputing Centre in Perth. The data will be converted to images of the sky in near-real-time by a pipeline processor running the purpose-built ASKAPsoft package. All data will be placed in the public domain after being checked for quality by the ten ASKAP Survey Science Teams. Post processing will be supported by supercomputers operated by iVEC at the Pawsey Centre in Perth, and may also be complemented by 'theSkyNet', a \"community computing initiative\" similar to Seti@home.\n\nDuring ASKAP's first five years of operation, at least 75% of its time will be used for large Survey Science Projects. ASKAP is expected to make substantial advances in key areas, including the following:\n\nIn 2009, after an open call for proposals, CSIRO announced that ten major science projects had been selected to use ASKAP. Of the ten projects' authors, 33% were from Australia and New Zealand, 30% from North America, 28% from Europe, and 9% from elsewhere in the world.\n\nThe ten ASKAP Survey Science Projects are:\n\n\n\n\n"}
{"id": "3931657", "url": "https://en.wikipedia.org/wiki?curid=3931657", "title": "Balkan Snowfield", "text": "Balkan Snowfield\n\nBalkan Snowfield (Plato Balkan \\'pla-to bal-'kan\\) is an ice-covered plateau of elevation ranging from 150 to 280 m in eastern Livingston Island in the South Shetland Islands, Antarctica, situated south of lower Perunika Glacier, northwest of Huntress Glacier and north of Contell Glacier. It is 3 km long in southwest-northeast direction and 2 km wide, and bounded by Burdick Ridge to the east, Willan Nunatak and Castillo Nunatak to the southeast, and Krum Rock to the southwest. The feature slopes gently northwestwards with its foot bounded by the hills along Bulgarian Beach. It is named after the Balkans.\n\nThe midpoint of the snowfield is located at . Detailed mapping by the Spanish Servicio Geográfico del Ejército in 1991, and Bulgarian mapping in 1996, 2004 and 2009.\n\n\n\n"}
{"id": "58297431", "url": "https://en.wikipedia.org/wiki?curid=58297431", "title": "Basic aluminium salt", "text": "Basic aluminium salt\n\nBasic aluminium (or basic aluminum) is the name of more than one functional group consisting of aluminium with one or two hydroxy groups attached.\n\nDihydroxyaluminium, Al(OH), also known as dibasic aluminium, is monovalent, and known in these compounds:\n\nHydroxyaluminium, Al(OH), also known as monobasic aluminium or basic aluminium, is divalent, and known in these compounds:\n\nAluminium, Al, is trivalent. Aluminium triacetate, Al(CHCO), is a complete molecule without any hydroxy groups, so it is not a \"basic aluminum\" compound.\n\nAluminium hydroxide, Al(OH), aluminium with three hydroxy groups attached, is a complete molecule, so it is not a \"basic aluminum\" compound.\n\nAluminium acetate is a name for three salts in the solid state: dihydroxyaluminium aluminium acetate, hydroxyaluminium diacetate, and aluminium triacetate, Al(CHCO). In aqueous solution, aluminium triacetate hydrolyses to form a mixture of the other two, so all solutions of all three can be referred to simply as \"aluminium acetate\", as the species co-exist and inter-convert in chemical equilibrium.\n"}
{"id": "33945372", "url": "https://en.wikipedia.org/wiki?curid=33945372", "title": "Bimoment", "text": "Bimoment\n\nBimoment (aka warping moment) is a term used in the analysis of beams (continuum mechanics), which relates to torsion and warping. Its symbol is Mω. Bimoment show the distributions at a cross-section of (longitudinal) warping stress, for the cases of torsional warping and distortional warping respectively. Generally, a bimoment can be represented by a pair of equal and opposite bending moments.\n\n"}
{"id": "29332992", "url": "https://en.wikipedia.org/wiki?curid=29332992", "title": "Borns Glacier", "text": "Borns Glacier\n\nBorns Glacier () is a glacier immediately west of Mount Coates, flowing north from the Kukri Hills of Victoria Land. It was charted by the British Antarctic Expedition under R. F. Scott, 1910–13, and named by the Advisory Committee on Antarctic Names for Harold W. Borns, Jr., United States Antarctic Research Program geologist who made investigations in the area during 1960–61.\n"}
{"id": "31329785", "url": "https://en.wikipedia.org/wiki?curid=31329785", "title": "Chang Yi Wang", "text": "Chang Yi Wang\n\nChang Yi Wang ()\n\nDr. Wang is the founder of United Biomedical, Inc. (UBI) , headquartered in Hauppauge, New York, and its group of companies in Asia. She has served as chief scientific officer of UBI since its inception in December 1985, and as chairperson and chief executive officer of the UBI Group of companies since 1998. Dr. Wang is the author of more than 120 peer-reviewed scientific publications and she is the inventor of more than 100 patents to date. She has given various keynote and plenary lectures both nationally and internationally in the areas of Immunology, vaccination, immunotherapeutics and Infectious disease. She has also served on the scientific review committee for the Cooperative Research Partnerships for BioDefense and Allergy and Immunobiology programs funded and administered by the U.S. National Institutes of Health ( NIH) . In 2007, the New York Intellectual Property Law Association ( NYIPLA) presented Dr. Wang with the Inventor of the Year Award. In 2018, the Brain Mapping Foundation presented Dr. Wang with the Pioneer in Technology Award for her contribution in the development of therapeutic vaccines for the treatment of Neurodegenerative Diseases.\n\nDr. Wang was born in Taipei, Taiwan. She attended the prestigious Taipei First Girls' High School, where she first became aware of the double helix structure of DNA, which served as one of the primary motivators for her lifetime pursuit of biomedical sciences.\nShe graduated with honor from National Taiwan University in 1973, majoring in chemistry. Dr. Wang was the first Asian woman accepted into the graduate program at Rockefeller University in the United States, where in 1979 she received a Ph.D. degree with dual specialization in Biochemistry and Immunology. She joined the Memorial Sloan Kettering Cancer Center from 1979 to 1985, becoming its youngest faculty member, principal investigator and head of the molecular immunology laboratory, endowed by the Arthur J. and Leslie Levine Fund.\n\nDr. Wang has been a pioneer in advocating “immunology as a secret weapon in medicine,” combined with personal motivation for developing medical interventions via application of basic biomedical sciences. Her first such achievements in terms of immunological applications of synthetic peptides were antibody screening immunoassays employing highly optimized synthetic viral peptide antigens. The first involved developing a synthetic peptide-based HIV 1, and later an HIV 1,2 diagnostic test for blood screening, both of which received U.S. Food and Drug Administration approval, in 1989 and 1996, respectively. These tests were subsequently recognized by the WHO as being suitable for worldwide use. Her other contributions in this area include synthetic peptide-based blood screening diagnostics for HTLV I/II and the Hepatitis C virus (HCV), which received CE certification and was sold in the global market through Organon Teknika /Biomerieux since 1991, as well as screening diagnostics for the SARS coronavirus, and diagnostic tests for the differentiation of infected vs. vaccinated animals for foot and mouth disease.\n\nSince 1992, she has received support and guidance from Dr. James D. Watson, the co-discoverer of the double-helix DNA structure and a board member of United Biomedical, Inc at the time, in the courageous pursuit of many challenging vaccine and immunotherapy programs employing designer synthetic peptides.\n\nAt the invitation of the Taiwanese government (Ministry of Economic Affairs and National Development Fund), Dr. Wang, representing UBI US, established UBI-Asia as a joint venture with Taiwanese government Agencies. Upon establishing UBI Asia in Taiwan in 1999, Dr. Wang’s mission was to position UBI Asia as the center of excellence in the protein and monoclonal antibody drug-development area. In line with her mission, she assembled and led a team of scientists and industrial experts to ensure the establishment of an integrated platform technology and a rich pipeline of high-impact products. The UBI-421 monoclonal antibody, first in this pipeline and also a brainchild of hers with a series of issued and pending patents, is in phase III trials for HIV treatment as a HAART substitution, as well as other applications including functional cure. Many other products are currently in various preclinical and clinical stages of development. In order to fully develop and commercialize these products, two companies, United BioPharma and UBI Pharma, were spun off from UBI Asia to allow dedicated resources for commercialization of the respective pipelines of monoclonal antibodies and long-acting protein drugs. The two companies have also established respective state-of-the-art manufacturing facilities at both Hsin Chu, Taiwan and Yangzhou, China to prepare for commercialization of these innovative protein drugs worldwide.\n\nDr. Wang’s patent for diagnostic Hepatitis C virus (HCV) peptide epitopes was the first such patent issued in the United States which was also subsequently licensed to Roche Diagnostics. Partnering with distributor Organon Teknika/Biomerieux, UBI’s peptide\nantigen-based HCV blood-screening test was a success in Europe in the early 1990s. However, patent litigation ensued between\nChiron et al. and UBI et al. regarding Chiron’s broadly claimed HCV epitope patent. Six Nobel laureates served as expert witnesses and judicial advisors in the UK court to dispute the validity of the broadly claimed Chiron HCV epitope/peptide patent. Following years of litigation and Dr. Wang’s valiant efforts in putting forth technical arguments challenging the validity of Chiron’s overly broad HCV epitope claims, UBI prevailed. In the year of 2000, the Technical Board of the European Patent Office invalidated all overly broad HCV epitope claims. Meanwhile, the UK’s Section 44 patent law was also repealed at the advice of a team of experts including patent barristers and judges setting a case for “lack of support can be used to attack the breadth of patent claims even after the patent is issued”. This result freed up valuable information derived from detailed RNA or DNA sequences for public research and follow-up inventions, finally allowing for worldwide use of the vast amount of Genomic sequence generated by the biomedical community.\n\nFor the past 25 years, Dr. Wang has dedicated herself to the discovery, design and development of a new class of biologicals comprising Immunotherapeutics and vaccines for the therapy and prevention of chronic and infectious diseases, and companion diagnostics for monitoring treatment and control of these diseases. The resultant peptide-based biologicals act by directing the immune system to specific functional target sites and have great potential in a wide range of therapeutic areas.\n\nUnder her direction, “UBITh”, a new platform technology in high precision peptide immunogen design for the development of innovative vaccines and immunotherapeutics, was established. Some examples include a site-specific UBITh amyloid-β vaccine and Tau vaccine for Alzheimer’s disease, a site-specific Alpha Synuclein vaccine for Parkinson’s disease, an IgE vaccine for allergic diseases, and others for multiple human and animal health applications, including an LHRH vaccine for boar taint removal via immunocastration, and vaccines against infections caused by Porcine circovirus, Porcine Reproductive and Respiratory Syndrome Virus, and Foot and mouth disease viruses. Validation for the UBITh vaccine\ntechnology has been demonstrated by achieving the long-sought goal of producing a Synthetic peptide vaccine for Foot and mouth disease, selling over 3 billion doses since introduction in 2007 in China, the largest swine market.\n\nThe New York Intellectual Property Law Association’s Inventor of the Year award recognizes an individual or group who, through inventive talents, has made worthwhile contributions to society by promoting “the progress of science and useful arts”. Dr. Chang Yi Wang was the 2007 recipient for her work on “UBITh peptide immunogens”. Dr. Wang’s work on synthetic peptide-based immunotherapeutics, vaccines, and diagnostics made her the first Asian female recipient of the prestigious award.\n\nThe Brain Mapping Foundation (BMF) is established for the purpose of facilitating multidisciplinary brain and spinal cord research, and expediting integration of cutting-edge technologies into the field of Neuroscience. Dr. Wang was the 2018 recipient for Pioneer in Technology Award given by the foundation for her cumulative work on the development of high precision endobody vaccines for the treatment of Neurodegenerative Diseases.\n\nDr. Wang divides her time between the United States and Taiwan, actively engaged in R&D and business development activities in biomedical applications. Her husband, Nean Hu , devotes his time to UBI’s subsidiaries in Shanghai, China. She has one daughter, Mei Mei Hu, JD, who serves as co-CEO of United Biomedical Inc. (UBI) and CEO of United NeuroScience(UNS).\n\n1. C. Y. Wang, W.-W. Wong, H.-C. Tsai, Y.-H. Chen, B.-S. Kuo, S. Lynn, J. Blazkova, K. E. Clarridge, H.-W. Su, C.-Y. Lin, F.-C. Tseng, A. Lai, F.-H. Yang, C.-H. Lin, W. Tseng, H.-Y. Lin, C. L. Finstad, F. Wong-Staal, C. V. Hanson, T.-W. Chun, and M.-J. Liao. Impact of anti-CD4 antibody UB-421 on plasma viral rebound in HIV-infected individuals following discontinuation of antiretroviral therapy. New Engl. J. Med 2018, submitted. \n\n2. Wang CY, Wang PN, Chiu MJ, Finstad CL, Lin F, Lynn S, et al. UB-311, a novel UBITh® amyloid β peptide vaccine for mild Alzheimer's Disease. Alzheimer’s & Dementia: Translational Research & Clinical Interventions 3 (2017) 262-272.\n\n3. Chen HC, Wang PN, Chiu MJ, Huang CC, Chang CC, Yen TC, Lin KJ, Seibyl J, Hesterman J, Wang CY, Verma A. (2017, November). Low PET screen failure rate in the UB-311 phase 2A study enriched for ApoE4 carriers with mild cognitive deficit. Poster session presented at Clinical Trials of Alzheimer's Disease, Boston, MA.\n\n4. Verma A, Maruff P, Schembri A, Wang PN, Chiu MJ, Huang CC, Chang CC, Chen HC, Chang P, Wang CY. (2017, November). UB-311 active vaccine generates titers specific for Aβ oligomers and fibrils without evidence of ARIA-E or encephalopathy in a completed Phase 1 and an ongoing Phase 2a study in Alzheimer's Disease. Poster session presented at Clinical Trials of Alzheimer's Disease, Boston, MA.\n\n5. Wang, C.Y., Wang, PN, Chiu,J, Finstad, CL, Lin, F, Lynn, S, Tai, YH, Fang, XD, Zhao, K, Hung, CH, Tseng, Y, Pen, WJ, Wang, J, Yu, CC, Kuo, BS, Frohna, P. UB-311 a novel UBITh® amyloid-β immunotherapeutic vaccine for immunotherapy of mild Alzheimer's Disease. Alzheimer’s & Dementia Translational Research & Clinical Interventions 2017, 3:262-272.Supplementary data related to this article can be can be found at:https://dx.doi.org/10.1016/j.trci.2017.03.005.\n\n6. Wang CY, Wong WW, Tsai HC, Chen YH, Liao MJ, Lynn S. Poster Abstract 450LB: A Phase 2 Open-Label Trial of Antibody UB-421 Monotherapy as a Substitute for HAART. Presented at the Annual Conference on Retroviruses and Opportunistic Infections (CROI), February 13-16, 2017, Seattle, WA.\n\n7. Wang, C.Y. “Peptide Immunogens from the C-Terminal End of Alpha Synuclein Protein and Formulations Thereof for treatment of Synucleinopathies.” US Provision Patent Application No. 62/521,287 (2017)\n\n8. Wang, C.Y. “TAU peptide immunogen constructs. US Patent Application” US Provisional Application 62/578,124 (2017)\n\n9. Wang, C.Y. “Treatment and Sustained Virologic Remission of HIV Infection by Antibodies to CD4 in HAART Stabilized Patients” TW Patent Application 106127443 (2017) and WO Application No. PCT/US2017/046668. (2017)\n\n10. Wang C. Y. et al., “Immunoglobulin fusion proteins and use thereof” US Patent Application 15/002,396 (2016), TW Patent Application 105117815 (2016) and WO Patent Application PCT/US16/039615 (2016).\n\n11. Wang C. Y., “Treatment and functional cure of HIV infection by monoclonal antibodies to CD4 mediating competitive HIV entry inhibition” US Patent Application 15/512,043 (2017)\n\n12. Wang C. Y., and Peng W. J., “Immunogenic LHRH composition and use thereof in pigs” US Patent Application 15/329,154 (2017).\n\n13. Wang C. Y., “Peptide vaccine for prevention and immunotherapy of dementia of the Alzheimer’s type” US Patent 9,102,752 (2015), US Patent Application 14/824,075 (2015), and WO Patent Application PCT/US13/37865 (2013).\n\n14. Wang C. Y., “Synthetic peptide-based emergency vaccine against foot and mouth disease (FMD)” US Patent Application 14/443,363 (2015), and WO Patent Application PCT/US2012/065386 (2012).\n\n15. Wang C. Y., “Synthetic Peptide-Based Marker Vaccine and Diagnostic System for Effective Control of Porcine Reproductive and Respiratory Syndrome (PRRS)” US Patent Application 14/380,010 (2014), and WO Patent Application PCT/US/2011/068133 (2011).\n\n16. Wang C. Y. and Peng W. J., “Designer Peptide-based PCV2 Vaccine” WO Patent Application PCT/US/2010/041406 (2010).\n\n17. Wang, Chang Yi, Finstad, Connie L., Walfield, Alan M., Sia Charles, Sokoll, Kenneth K., et al. Site Specific UBITh Amyloid-β Vaccine for Immunotherapy of Alzheimer's Disease. Vaccine, 2007: 25: 3041-3052.\n\n18. Wang, Chang Yi, Walfield, Alan M. Site-specific peptide vaccines for immunotherapy and immunization against chronic diseases, cancer, infectious diseases, and for veterinary applications. [Review Article] Vaccine 2005: 23:2049-2056.\n19. Hsueh PR, Kao CL, Lee CN, Chen LK, Ho MS, Sia C, Fang XD, Lynn S, et al. and Wang, CY. Highly Specific Severe Acute Respiratory Syndrome Antibody Test for Serosurveillance. Emerg. Infect. Diseases 2004, 10:1558-1562\n\n20. Wang, C.Y., Lynn, S., Jong, M-H., Lin, Y-L., et al. Appendix 58, Full protection in pigs against FMDV challenge following single dose of synthetic emergency vaccine. In Report of the Session of the Research Group of the Standing Technical Committee of the European Commission for the Control of Foot-and-Mouth Disease. Food and Agricultural Organization, Rome, pp. 365–375, 2004.\n\n21. Finstad, CL, Wang, CY, Kowalski J, Zhang M, Li ML, Li XM, Xi WG, Bosland MC, Murthy KK, Walfield AM, and Zamb TJ. Synthetic Luteinizing Hormone Releasing Hormone (LHRH) vaccine for effective androgen deprivation and its application to Prostate Cancer immunotheray. Vaccine 2004: 22:1300 1313\n\n22. Wang, CY, Walfield AM, Fang X, Hammerberg B, Ye J, Li ML, Shen F, Shen M, Alexander V and MacGlashan DW. Synthetic IgE peptide vaccine for immunotherapy for Allergy. Vaccine 2003, 21:1580-1590.\n\n23. Wang, CY, Shen M, Tam G, Fang XD, Ye J, Shen F, Walfield AM, Wang JJG, et al. Synthetic AIDS vaccine by targeting HIV receptor. Vaccine 2002, 21: 89-97.\n\n24. Wang, CY, Chang TY, Walfield AM, Ye J, Shen M, Chen SP, Li MC, Lin YL, et al. Effective Synthetic peptide vaccine for Foot and mouth disease in swine. Vaccine. 2002, 20:2603-2610.\n\n25. Wang, CY, Chang TY, Walfield AM, Ye J, Shen M, Zhang ML, Lubroth J, et al. Synthetic Peptide-based Vaccine and Diagnostic System for Effective Control of Foot and mouth disease. Biologicals 2001, 29: 221-228.\n\n26. Wang, CY, Sawyer LSW, Murthy KK, Fang XD, Walfield AM, et al. Postexposure immunoprophylaxis of HIV primary isolates by an antibody to HIV receptor complex. Proc. Natl. Acad. Sci. United States 1999; 96:10367-10372\n\n27. Shen F, Chen PD, Walfield AM, Ye J, House J, Brown F, Wang CY. Differentiation of convalescent animals from those vaccinated against Foot and mouth disease by a peptide ELISA. Vaccine, 1999; 17:3039-3049.\n\n28. Singh M, Li XM, Wang H, McGee JP, Zamb T, Koff W, Wang CY, et al. Controlled release microparticles as a single dose diphtheria toxoid vaccine; immunogenicity in small animal models. Vaccine 1998; 16:346-352.\n\n29. Singh M. Hiou C, Qiu H, Li XM, Wang CY, et al. CTL induction using synthetic peptides delivered in emulsions – critical role of the formulation procedure. Vaccine 1997; 15:1773-1778.\n\n30. Li D, Forrest BD, Li Z, Xue P, Hanson CV, Duan S, Cheng H, Li M, Wang CY, et al. International clinical trials of HIV vaccines: II. Phase I trial of an HIV-1 synthetic peptide vaccine evaluating an accelerated immunization schedule in Yunnan, China. Asian Pac J Allergy Immunol 1997; 15: 105-113.\n\n31. Phanuphak P. Teeratakulpixarn S, Sarangbin S, Nookhai S, Ubolyam S, Sirivichayakul S, Leesavan A, Forrest BD, Hanson CV, Li ML, Wang, CY, et al. International clinical trials of HIV vaccines: I. Phase I trial of an HIV-1 synthetic peptide vaccine in Bangkok, Thailand. Asian Pac J Allerg Immunol 1997; 15:41-48.\n\n32. Singh M, McGee JP, Li XM, Koff W, Zamb T, Wang CY and O’Hagan DT. Biodegradable microparticles with an entrapped branched octameric peptide as a controlled-release HIV-1 vaccine. J Pharmaceut Sci 1997; 86:1229.\n\n33. Singh M, Li XM, McGee JP, Zamb T, Koff W, Wang CY and O’Hagan DT. Controlled release microparticles as a single dose hepatitis B vaccine; evaluation of immunogenicity in mice. Vaccine 1997; 15:475.\n\n34. Singh M, Li XM, Wang HY, McGee JP, Zamb T, Koff W, Wang CY and O’Hagan DT. Immunogenicity and protection in small-animal models with controlled-release tetanus toxois microparticles as a single-dose vaccine. Infect and Immunity 1997; 65:1716.\n\n35. Nixon DF, Hioe C, Chen PD, Bian Z, Kuebler P, Li ML, Qiu H, Li XM, Singh M, Richardson J, McGee P, Zamb T, Koff W, Wang CY and O’Hagan D. Syntehtic peptides entrapped in microparticles can elicit cytotoxic T cell activity. Vaccine 1996; 14:1523.\n\n36. Hioe CE, Qiu H, Chen PD, Bian Z, Li ML, Li J, Singh M, Kuebler P, McGee P, O’Hagan D, Zamb T, Koff W, Allsopp C, Wang CY, et al. Comparison of adjuvant formulations for cytotoxic T cell induction using synthetic peptides. Vaccine 1996: 14:412-418.\n\n37. Quiroga JA, van Binsbergen J, Wang CY, Pardo M, Navas S, Trines C, Herrero M and Carreno V. Immunoglobulin M antibody to hepatitis C virus core antigen: Correlations with viral replication, histological activity, and Liver disease outcome. Hepatol 1995; 11:1635.\n\n38. Prince AM, Brotman B, Inchauspe G, Pascual D. Nasoff M. Hosein B and Wang CY. Patterns and prevalence of hepatitis type C infection in post-transfusion non-A, non-B hepatitis. J Inf Dis 1993; 167: 1296-1301.\n\n39. Sheu JC, Wang JT, Wang TH, Wang CY, et al. Prevalence of hepatitis C viral infection in a community in Taiwan. Detection by synthetic peptide-based assay and polymerase chain reaction. J Hepatol 1993; 17:192.\n\n40. Wang, CY, Looney, P.J., Li, M.L., Walfield, A.M., Ye, J., Hosein, B., Tam, J.P., and Wong-Staal, F. Long-term high-titer neutralizing activity induced by octameric synthetic HIV-1 antigen. Science 1991; 254:285-288.\n\n41. Hosein B, Fang X and Wang CY. Anti-HCV, anti-GOR, and autoimmunity. Lancet 1992, 339:871.\n\n42. Hosein B, Fang CT, Popvsky MA, Ye J, Zhang M and Wang, CY. Improved serodiagnosis of Hepatitis C virus infection with synthetic peptide antigen from capsid protein. Proc Natl Acad Sci USA. 1991; 88:3647\n\n43. Hosein B, Present W, Wang CY, and Fang CT. synthetic peptide-based EIAs to distinguish HTLV-I from HTLV-II infection. Transfusion 1990; 30S: 513\n\n44. Kao HT, Gregerson PK, Tang JC, Takahashi T, Wang CY and Silver J, Molecular analysis of HLA class genes in two DR6w-related haplotypes, DRw13 DQw1 and DRw14 DQw3. J Immunol 1989; 142: 1743.\n\n45. Sung SSJ, Bjorndahl JM, Wang CY, Kao HT and Fu SM. Production of tumor necrosis factor/cachectin by human T cell lines and peripheral blood T lymphocytes stimulated by PMA and Anti-CD3 monoclonal antibody. J Exp Med 1988; 167: 937.\n\n46. Sung SSJ, Jung LKL, Walters JA, Chen W, Wang CY, and Fu SM, Production of tumor necrosis factor/cachectin by human B cell lines and tonsillar B cells. J Exp Med 1988; 168: 1539.\n\n47. Wang CY. Synthetic-peptide-based immunodiagnosis of retrovirus infection: current status and future prospects. In “Synthetic Peptides in Biotechnology.”, Edited by A. Mizrahi, Adv. In Biotechnological Processes. 1988; 10:131\n\n48. Shimazaki C, Wisniewolski D, Scheinberg D, Atzpodien J, Strife A, Gulati S, Fried J,Wisniewolski R, Wang CY and Clarkson B. Elimination of myeloma cells from bone marrow by using Monoclonal antibodies and magnetic immunobeads. Blood 1988: 72:1248.\n\n49. Gottlieb AB, Lifshitz B, Fu SM, Staiano-Coico L, Wang CY and Carter DM. Expression of HLA-DR molecules by Keratinocyte and presence of Langerhans cells in the dermal infiltrate of active psoriatic plaques. J Exp Med 1986; 164: 1013.\n\n50. Gregerson P, Shen M, Song Q, Wang CY, et al. Molecular diversity of HLA-DR4 haplotypes. Proc Natl. Acad Sci USA 1986; 83: 2642. 35.\n\n51. Rinnooy-Kan EA, Wright SD, Welte K and Wang CY. Fc receptors on monocytes cause OKT-3 treated lymphocytes to internalize T3 and secrete IL-2. Cell Immunol 1986; 98: 181\n\n52. Buskin Y, Posnett DN, Pernis B and Wang CY. A new HLA-linked T cell membrane molecule, related to the beta chain of the clonotypic receptor, is associated with T3. J Exp Med 1986; 164: 458\n\n53. Posnett D, Wang CY and Friedman SM. Inherited polymorphism of the human T cell antigen receptor detected by a monoclonal antibody. Proc Natl. Acad Sci USA 1986; 83:7888.\n\n54. Tse DB, Al-Haiden M, Pernis B, Cantor CR and Wang CY. Intracellular accumulation of T cell receptor complex molecules in a human T leukemia cell line. Science 1986; 234:748.\n\n55. Wang JG, Steel S, Wisniewolski R and Wang CY. Detection of antibodies to HTLV-III using a synthetic peptide of 21 amino acid residues corresponding to a highly antigenic segment of gp41 envelope protein. Proc Natl Acad Sci USA 1986; 83:6159.\n\n56. Wang CY, Bushin Y, Lane CL, McGrath H and Posnett DN. Stimulation and expansion of a human T cell subpopulation by a monoclonal antibody to T cell receptor molecule. Hybridoma 1986; 5:179.\n\n57. Schwarting R, Stein H and Wang CY. monoclonal antibody S-HCL1 and S-HCL3 [also known as Leu 13 and Leu 14] allow the diagnosis of hairy cell leukemia. Blood 1985; 65:974.\n\n58. Bushkin Y, Chorney MJ, Diamante E, Lane CL, Fu SM and Wang, CY. Biochemical characteriazation of a p43,12 complex: comparison to human and murine class I molecules. Mol Immunol 1985; 22:695.\n\n59. Schwarting R, Welte K, Chiorazzi N, Ralph P, Lane CL, Long CW, and Wang, CY. Biochemical characterization and purification of human B cell stimulatory factory (BSF). Eur J Immunol 1985; 15:632.\n\n60. Wang, CY, Bushkin Y, Chen BPD, Platsoucas C and Long CW. Preparation and characterization of monoclonal antibodies directed against epitopes of Human IFN-. Hybridoma 1984; 4:321.\n\n61. Bushkin Y, Chorney MJ, Diamante E, Fu SM and Wang, CY. Biochemical characterization of the human T6 antigen; a comparison between T6 and murine TL. Mol. Immunol 1984; 21:821.\n\n62. Posnett DN, Biegler RD, Bushkin Y, Fisher DE, Wang, CY, Mayer LF, Chiorazzi N and Kunkel HG. T cell anti-idiotypic antibodies reveal differences between two human leukemias. J Exp Med 1984; 160:499\n\n63. Posnett DN, Wang, CY, Chiorazzi N, Crow MK and Kunkel HG. An antigen characteristic of hairy cell leukemia cells is expressed on certain activated B cells. J immunol 1984; 133:1635.\n\n64. Peng RL, Al-Katib A, Knowles DM, Lu L, Broxmeyer H, Telidjian B, C Hiao JW and Wang, CY. Preparation and characterization of monoclonal antibodies recognizing two distinct differentiation antigens Pro-Im1, Pro-Im2 on early hematopoeitic cells. Blood 1984; 64:1169.\n\n65. Rinnooy Kan EA, Platzer E, Welte K, and Wang, CY. Modulation induction of the T3 antigen by OKT3 is monocyte dependent. J Immunol 1984; 133:2979\n\n66. Wang, CY, Azzo W, Al-Katib A, Chiorazzi N and Knowles DM. Preparation and characterization of monoclonal antibodies recognizing three distinct differentiation antigens (BL1, BL2, and BL3) on human B lymphocytes. J Immunol 1984; 1133:684.\n\n67. Wang, CY, Al-Katib A, Lane CL, Koziner B and Fu, SM. Induction of Leu 10 (HLA-DC/DS) antigen expression by human precursor B cell lines. J Exp Med 1983; 158:1757.\n\n68. Rinnooy Kan EA, Wang, CY, Wang LC and Evans RL. Non-covalently bonded subunits of 22KD and 28KD are rapidly internalized by T cells reacted with anti-Leu4 [now termed CD3] antibody. J Immunol 1983; 131:536.\n\n69. Biegler RD, Fisher DE, Wang, CY, Rinnooy Kan EA and Kunkel HG. Idiotype-like molecules on cells of a human T-cell leukemia. J Exp Med 1983; 158:1000.\n\n70. Welte K, Platzer EW, Wang, CY, Rinnooy Kan EA, Moore MAS and Mertelsmann R. OKT8 [now termed CD8] antibody inhibits OKT3 [now termed CD3]-induced IL-2 production and proliferation of CD8+ cells. J Immunol 1983; 131:2356.\n\n71. Knowles DM, Tolidgian B, Maiboe CC, Halper J, Azzo W and Wang, CY. A new human B lymphocyte surface antigen (BL2) detected by a monoclonal antibodies: Distribution of benign and malignant lymphoid cells. Blood 1983; 62:191.\n\n72. Venuta S, Mertelsmann R, Welte K, Feldman S, Wang, CY and Moore MAS. Production and regulation of Interleukin-2 in human lymphoblastic leukemias studied with T cell monoclonal antibodies. Blood 1983; 61:781.\n\n73. Venuta S, Mertelsmann R, Welte K, Feldman S, Wang, CY and Moore MAS. Production and regulation of Interleukin-2 in human lymphoblastic leukemias studied with T cell monoclonal antibodies. Blood 1983; 61:781.\n\n74. Welte K, Wang, CY, Mertelsmann R, Venuta S, Feldman S and Moore MAS. Purification of human Interleukin-2 to apparent homogeneity and its molecular heterogeneity. J Exp Med 1982; 156:454.\n\n75. Shin HS, Wang, CY and Choi YS. Activation of autologous reactive helper T lymphocytes for differentiation of human B lymphocytes. J Immunol 1981: 126:2483.\n\n76. Wang, CY, Good RA, Ammirati P, Dymbort G and Evans RL. Identification of a p69/71 complex [now termed Leu 1 or CD5] expressed on human T cells sharing determinants with B type chronic lymphatic leukemia. J Exp Med 1980; 151: 1539.\n\n77. Halper J, Knowles DM and Wang, CY. Ia antigen [now termed HLA-DR or class II MHC antigen] expression by human malignant lymphomas: correlation with conventional lymphoid markers. Blood 1980; 55:373\n\n78. Gottlieb AB, Fu SM, Yu DTY, Wang, CY, Halper JP and Kunkel HG. The nature of the stimulation cell in human allogeneic and autologous MLC reaction: Role of isolated IgM-bearing B cells. J Immunol 1979; 123: 1497.\n\n79. Wang, CY, Structural and functional characterization of surface antigens on human B lymphocytes. Ph.D. Thesis, The Rockefeller University, 1979.\n\n80. Wang, CY, Fu SM and Kunkel HG. Isolation and immunological characterization of a major surface glycoprotein gp54 [now known as IL6 receptor] preferentially expressed on certain human B cells. J Exp Med 1979; 149:1434.\n\n81. Fu SM, Chiorazzi N, Wang, CY, Montazeri CM and Kunkel HG Ia bearing T cells in man. Their identification and role in the generation of allogeneic helper activity. J Exp Med 1978; 148:1423.\n\n82. Winchester RJ, Wang, CY, Gibofsky A, Kunkel HG, Lloyd K and Old, LJ. Expression of Ia-like antigens [now termed HLA-DR or class II MHC antigen] on cultured human malignant melanoma cell lines. Proc Natl. Acad Sci. 1978; 75:6235.\n\n83. Winchester RJ, Meyers PA, Broxmeyer HE, Wang, CY, Moore MAS and Kunkel HG. Inhibition of human erythropoietic colony formation in culture by treatment with Ia antisera. J Exp Med 1978; 148:613.\n\n84. Halper JP, Fu SM, Wang, CY, Winchester RJ and Kunkel HG. Patterns of expression of human Ia-like antigens [now termed HLA-DR or class II MHC antigen] during the terminal stages of B cell development. J Immunol 1978; 119:1520.\n\n85. Hoffman T, Wang, CY, Winchester RJ, Ferarrini M and Kunkel HG. Human lymphocyte bearing Ia-like antigens [now termed HLA-DR or class II MHC antigen]: Absence in patients with infantile Hypogammaglobulinemia . J immunol 1977; 119:1250.\n\n86. Winchester RJ, Ross, GD, Jarowski CI, Wang, CY, Halper J and Broxmeyer HE. Expression of a Ia-like antigen on human granulocytes during early stages of differentiation. Proc Natl Acad Sci USA 1977; 74:4012.\n\n\nDr. Chang Yi Wang has been invited to numerous Presentations and Plenary Lectures including:\n\n• Hsinchu, Taiwan National Tsing Hua University Lecture Series: “From Double Helix to Efficacious Vaccines Through Rational Design” April 10, 2010\n\n• Taipei, Taiwan Forum on Vaccine Industry Development in Taiwan, Taiwan Biotech Association: “A Reflection and New Determination: Site Directed Vaccines and Immunotherapeutics” [Plenary Lecture] July 24, 2008\n\n• Vienna, Austria International Atomic Energy Agency (IAEA)/Food and Agriculture Organization (FAO) and Office of International des Epizooties (OIE) World Organization for Animal Health: Use Of Standards and References for Serological And Molecular Tests for Transboundary Diseases In Livestock. November 21–24, 2006\n\n• Montreal, Quebec, Canada 5th World Congress on Vaccines, Immunization & Immunotherapy [Plenary Lecture] November 6–9, 2006\n\n• Dubai, UAE 7th Global Vaccinology Forum on Disease Immunization and Immunotherapy: Site-Specific Peptide Vaccines for Immunotherapy and Immunization and for Veterinary Applications [Plenary Lecture] March 5–7, 2005\n\n• Tokyo, Japan 4th World Congress on Vaccines & Immunization: Site-Specific Peptide Vaccines for Immunotherapy and Immunization Against Chronic Diseases, Cancer, Infectious Disease, and for Veterinary Applications [Plenary Lecture], September 30-October 3, 2004\n\n• Washington, D.C., US-Taiwan Business Council, The Brookings Institution, and the Center for Strategic and International Studies Symposium on The Taiwan Presidential Elections: “Political, Economic, & Security Implications”: Reasons to Choose Taiwan May 6, 2004\n\n• Singapore. Biomedical Asia, Partnering Seminar: UBI as a Rising Star of the Biopharmaceutical Industry November 4, 2003\n\n• San Diego, California Days of Molecular Medicine Symposium: Immunotherapy of Infectious, Chronic Diseases and Cancer by Site-Specific Peptide Vaccines. March 13–15, 2003\n\n• Cambridge, Massachusetts Knowledge Foundation’s International Conference on HIV Vaccines: Synthetic AIDS Vaccine by Targeting HIV Receptor June 22–23, 2003\n\n• Tainan, Taiwan International Symposium on Agricultural Biotechnology, National Cheng Kung University: Site Specific Synthetic Peptide Antigens and Functional Antigenics: Applications to Animal Health. December 13–14, 2002\n\n• Lyon, France Foundation Merieux of International Association of Biologicals Standardization: Immunological Application of Synthetic Peptides. May 9–11, 2001\n\n• Amsterdam, Netherlands IAVI Neutralization Task Force: Immunoprophylaxis, Immunotherapy, and a Synthetic AIDS Vaccine Targeting HIV Receptors. April 25, 2001\n\n• London, England HIV Therapeutics:Searching for the Next Generation: Immunoprophylaxis, Immunotherapy, and a Synthetic AIDS Vaccine Targeting HIV Receptors February. 28-March 1, 2001\n\n• Baltimore, Maryland Maryland Meeting of the Institute of Human Virology: Postexposure Immunoprophylaxis of Primary Isolate by an Antibody to HIV Receptor Complex. September 15, 2000\n\nRobert B. Merrifield\n\nIn 1974, Chang Yi, already an astute organic chemist as a result of her undergraduate training at National Taiwan University, joined Dr. Merrifield’s laboratory at Rockefeller University as a\nfirst-year Ph.D. student, learning the many facets of solid-phase peptide chemistry. Dr. Merrifield won the Nobel Prize in Chemistry in 1984 for his pioneering work in solid-phase peptide synthesis.\nChang Yi’s use of this synthetic tool for some of her inventions in immunological applications in diagnostics, vaccines and immunotherapeutics began in the mid ‘80s.\n\nHenry G. Kunkel\n\nDr. Kunkel, often referred to as “the father of immunopathology” was Chang Yi’s Ph.D. dissertation advisor from 1975 to 1979 at Rockefeller University. He trained Chang Yi as an investigator, teaching her how to master a few simple technologies and apply them to the most important subjects, and how an inquisitive mind can discover intriguing findings in an ignored corner that few can fathom.\n\nGerald M. Edelman\n\nDr. Edelman, an American biologist who received his Ph.D. training at Dr. Kunkel’s laboratory, shared the 1972 Nobel Prize in Physiology or Medicine for work with Rodney R. Porter on the immune system. Specifically, the Nobel Prize was given for his discovery of the structure of antibody molecules. Dr. Edelman and his laboratory colleagues taught immunology and biochemistry classes at Rockefeller University and were instrumental in leading Chang Yi to the most exciting, yet then still primitive, field of immunology.\n\nRalph M. Steinman\n\nDr. Steinman, a Canadian Immunologist and cell biologist, was one of the recipients of the 2011 Nobel Prize in Physiology or Medicine for his discovery of the dendritic cell and its role in adaptive immunity. He was the first teacher at the Rockefeller University to bring Chang Yi to the intriguing field of cellular immunology at a time when he was describing his EM finding of dendrite-like immune cells later known as the dendritic cells, critical for initiating the immune responses.\n\nRobert A. Good\n\nDr. Good, regarded as a founder of modern immunology, was an American physician who performed the first successful human bone marrow transplant between persons who were not identical twins. Chang Yi was recruited immediately after receiving her Ph.D. degree as an independent Principal Investigator and Head of Laboratory of Molecular Immunology by Dr. Good, then president of the Sloan Kettering Institute of the Memorial Sloan Kettering Cancer Center (MSKCC) in Manhattan, the world’s largest cancer center.\nHer work in the early ‘80s used specific monoclonal antibodies to define several critical lymphocyte surface markers (LEU1, LEU3, LEU4, LEU10, LEU13, LEU14 and the idiotypic leukemic T cell marker, also known as the T cell receptor).\n\nLloyd J. Old\n\nDr. Old was one of the founders and standard bearers of the field of cancer immunology. Chang Yi’s entry into the tumor immunology and cytokine fields originated from a collaboration with Dr. Old while at the MSKCC by characterizing a tumor necrosis factor defined by Dr. Old’s laboratory in the ‘70s found in mice serum. The cytokine was purified to homogeneity as a 17KD molecule before it was cloned by Cetus in 1983.\nMonoclonal antibodies to cytokines including TNF-alpha, funding through a NCI contract, and other tumor-specific antigens—mostly heat-stable glycolipids—were developed in the mid-‘80s by Chang Yi’s laboratory for further clinical applications.\n\n"}
{"id": "5499416", "url": "https://en.wikipedia.org/wiki?curid=5499416", "title": "Clorpt", "text": "Clorpt\n\nClorpt (or Corpt) is a mnemonic for Hans Jenny's state equation for the factors influencing soil formation:\n\nThere are two principal methods that the state equation may be solved: first in a theoretical or conceptual manner by logical deductions from certain premises, and second empirically by experimentation or field observation. \nThe empirical method is still mostly employed today, and soil formation can be defined by varying a single factor and keeping the other factors constant. This led to the development of empirical models to describe pedogenesis, such as climofunctions, biofunctions, topofunctions, lithofunctions, and chronofunctions. Since Hans Jenny published his formulation in 1941, it has been used by innumerable soil surveyors all over the world as a qualitative list for understanding the factors that may be important for producing the soil pattern within a region.\n\nThe term \"clorpt\" is mainly used for empirical quantitative prediction with the purposes of making digital soil maps. In this approach, the state-factor equation was put explicitly into a spatial framework and the factors were also observed in the same spatial domain. Some people have termed the approach \"environmental correlation\", associated with using stratigraphy, digital terrain models and gamma radiometric surveys, to predict and map soil properties.\n\n\n"}
{"id": "245966", "url": "https://en.wikipedia.org/wiki?curid=245966", "title": "Compact Muon Solenoid", "text": "Compact Muon Solenoid\n\nThe Compact Muon Solenoid (CMS) experiment is one of two large general-purpose particle physics detectors built on the Large Hadron Collider (LHC) at CERN in Switzerland and France. The goal of CMS experiment is to investigate a wide range of physics, including the search for the Higgs boson, extra dimensions, and particles that could make up dark matter.\n\nCMS is 21.6 metres long, 15 m in diameter, and weighs about 14,000 tonnes. Approximately 3,800 people, representing 199 scientific institutes and 43 countries, form the CMS collaboration who built and now operate the detector. It is located in an underground cavern at Cessy in France, just across the border from Geneva. In July 2012, along with ATLAS, CMS tentatively discovered the Higgs boson.. \nBy March 2013 its existence was confirmed.\n\nRecent collider experiments such as the now-dismantled Large Electron-Positron Collider and the newly renovated Large Hadron Collider (LHC) at CERN, as well as the () recently closed Tevatron at Fermilab have provided remarkable insights into, and precision tests of, the Standard Model of Particle Physics. A principle achievement of these experiments (specifically of the LHC) is the discovery of a particle consistent with the Standard Model Higgs boson, the particle resulting from the Higgs mechanism, which provides an explanation for the masses of elementary particles.\n\nHowever, there are still many questions that future collider experiments hope to answer. These include uncertainties in the mathematical behaviour of the Standard Model at high energies, tests of proposed theories of dark matter (including supersymmetry), and the reasons for the imbalance of matter and antimatter observed in the Universe.\n\nThe main goals of the experiment are:\n\nThe ATLAS experiment, at the other side of the LHC ring is designed with similar goals in mind, and the two experiments are designed to complement each other both to extend reach and to provide corroboration of findings. CMS and ATLAS uses different technical solutions and design of its detector magnet system to achieve the goals.\n\nCMS is designed as a general-purpose detector, capable of studying many aspects of proton collisions at 0.9-13 TeV, the center-of-mass energy of the LHC particle accelerator.\n\nThe CMS detector is built around a huge solenoid magnet. This takes the form of a cylindrical coil of superconducting cable that generates a magnetic field of 4 teslas, about 100 000 times that of the Earth. The magnetic field is confined by a steel 'yoke' that forms the bulk of the detector's weight of 12 500 tonnes. An unusual feature of the CMS detector is that instead of being built in-situ underground, like the other giant detectors of the LHC experiments, it was constructed on the surface, before being lowered underground in 15 sections and reassembled.\n\nIt contains subsystems which are designed to measure the energy and momentum of photons, electrons, muons, and other products of the collisions. The innermost layer is a silicon-based tracker. Surrounding it is a scintillating crystal electromagnetic calorimeter, which is itself surrounded with a sampling calorimeter for hadrons. The tracker and the calorimetry are compact enough to fit inside the CMS Solenoid which generates a powerful magnetic field of 3.8 T. Outside the magnet are the large muon detectors, which are inside the return yoke of the magnet.\nFor full technical details about the CMS detector, please see the Technical Design Report.\n\nThis is the point in the centre of the detector at which proton-proton collisions occur between the two counter-rotating beams of the LHC. At each end of the detector magnets focus the beams into the interaction point. At collision each beam has a radius of 17 μm and the crossing angle between the beams is 285 μrad.\n\nAt full design luminosity each of the two LHC beams will contain 2,808 bunches of protons. The interval between crossings is 25 ns, although the number of collisions per second is only 31.6 million due to gaps in the beam as injector magnets are activated and deactivated.\n\nAt full luminosity each collision will produce an average of 20 proton-proton interactions. The collisions occur at a centre of mass energy of 8 TeV. But, it is worth noting that for studies of physics at the electroweak scale, the scattering events are initiated by a single quark or gluon from each proton, and so the actual energy involved in each collision will be lower as the total centre of mass energy is shared by these quarks and gluons (determined by the parton distribution functions).\n\nThe first test which ran in September 2008 was expected to operate at a lower collision energy of 10 TeV but this was prevented by the 19 September 2008 shutdown. When at this target level, the LHC will have a significantly reduced luminosity, due to both fewer proton bunches in each beam and fewer protons per bunch. The reduced bunch frequency does allow the crossing angle to be reduced to zero however, as bunches are far enough spaced to prevent secondary collisions in the experimental beampipe.\n\nMomentum of particles is crucial in helping us to build up a picture of events at the heart of the collision. One method to calculate the momentum of a particle is to track its path through a magnetic field; the more curved the path, the less momentum the particle had. The CMS tracker records the paths taken by charged particles by finding their positions at a number of key points.\n\nThe tracker can reconstruct the paths of high-energy muons, electrons and hadrons (particles made up of quarks) as well as see tracks coming from the decay of very short-lived particles such as beauty or “b quarks” that will be used to study the differences between matter and antimatter.\n\nThe tracker needs to record particle paths accurately yet be lightweight so as to disturb the particle as little as possible. It does this by taking position measurements so accurate that tracks can be reliably reconstructed using just a few measurement points. Each measurement is accurate to 10 µm, a fraction of the width of a human hair. It is also the inner most layer of the detector and so receives the highest volume of particles: the construction materials were therefore carefully chosen to resist radiation.\n\nThe CMS tracker is made entirely of silicon: the pixels, at the very core of the detector and dealing with the highest intensity of particles, and the silicon microstrip detectors that surround it. As particles travel through the tracker the pixels and microstrips produce tiny electric signals that are amplified and detected. The tracker employs sensors covering an area the size of a tennis court, with 75 million separate electronic read-out channels: in the pixel detector there are some 6000 connections per square centimetre.\n\nThe CMS silicon tracker consists of 13 layers in the central region and 14 layers in the endcaps. The innermost three layers (up to 11 cm radius) consist of 100×150 μm pixels, 66 million in total.\n\nThe next four layers (up to 55 cm radius) consist of silicon strips, followed by the remaining six layers of strips, out to a radius of 1.1 m. There are 9.6 million strip channels in total.\n\nDuring full luminosity collisions the occupancy of the pixel layers per event is expected to be 0.1%, and 1–2% in the strip layers. The expected HL-LHC upgrade will increase the number of interactions to the point where over-occupancy would significantly reduce trackfinding effectiveness. An upgrade is planned to increase the performance and the radiation tolerance of the tracker.\n\nThis part of the detector is the world's largest silicon detector. It has 205 m of silicon sensors (approximately the area of a tennis court) comprising 76 million channels.\n\nThe Electromagnetic Calorimeter (ECAL) is designed to measure with high accuracy the energies of electrons and photons.\n\nThe ECAL is constructed from crystals of lead tungstate, PbWO. This is an extremely dense but optically clear material, ideal for stopping high energy particles. Lead tungstate crystal is made primarily of metal and is heavier than stainless steel, but with a touch of oxygen in this crystalline form it is highly transparent and scintillates when electrons and photons pass through it. This means it produces light in proportion to the particle’s energy. These high-density crystals produce light in fast, short, well-defined photon bursts that allow for a precise, fast and fairly compact detector. It has a radiation length of χ = 0.89 cm, and has a rapid light yield, with 80% of light yield within one crossing time (25 ns). This is balanced however by a relatively low light yield of 30 photons per MeV of incident energy. The crystals used have a front size of 22 mm × 22 mm and a depth of 230 mm. They are set in a matrix of carbon fibre to keep them optically isolated, and backed by silicon avalanche photodiodes for readout.\n\nThe ECAL, made up of a barrel section and two ”endcaps”, forms a layer between the tracker and the HCAL. The cylindrical “barrel” consists of 61,200 crystals formed into 36 “supermodules”, each weighing around three tonnes and containing 1700 crystals. The flat ECAL endcaps seal off the barrel at either end and are made up of almost 15,000 further crystals.\n\nFor extra spatial precision, the ECAL also contains preshower detectors that sit in front of the endcaps. These allow CMS to distinguish between single high-energy photons (often signs of exciting physics) and the less interesting close pairs of low-energy photons.\n\nAt the endcaps the ECAL inner surface is covered by the preshower subdetector, consisting of two layers of lead interleaved with two layers of silicon strip detectors. Its purpose is to aid in pion-photon discrimination.\n\nThe Hadron Calorimeter (HCAL) measures the energy of hadrons, particles made of quarks and gluons (for example protons, neutrons, pions and kaons). Additionally it provides indirect measurement of the presence of non-interacting, uncharged particles such as neutrinos.\n\nThe HCAL consists of layers of dense material (brass or steel) interleaved with tiles of plastic scintillators, read out via wavelength-shifting fibres by hybrid photodiodes. This combination was determined to allow the maximum amount of absorbing material inside of the magnet coil.\n\nThe high pseudorapidity region formula_1 is instrumented by the Hadronic Forward (HF) detector. Located 11 m either side of the interaction point, this uses a slightly different technology of steel absorbers and quartz fibres for readout, designed to allow better separation of particles in the congested forward region.\nThe HF is also used to measure the relative online luminosity system in CMS.\n\nAbout half of the brass used in the endcaps of the HCAL used to be Russian artillery shells.\n\nThe CMS magnet is the central device around which the experiment is built, with a 4 Tesla magnetic field that is 100,000 times stronger than the Earth’s. CMS has a large solenoid magnet. This allows the charge/mass ratio of particles to be determined from the curved track that they follow in the magnetic field. It is 13 m long and 6 m in diameter, and its refrigerated superconducting niobium-titanium coils were originally intended to produce a 4 T magnetic field. The operating field was scaled down to 3.8 T instead of the full design strength in order to maximize longevity.\n\nThe inductance of the magnet is 14 Η and the nominal current for 4 T is 19,500 A, giving a total stored energy of 2.66 GJ, equivalent to about half-a-tonne of TNT. There are dump circuits to safely dissipate this energy should the magnet quench. The circuit resistance (essentially just the cables from the power converter to the cryostat) has a value of 0.1 mΩ which leads to a circuit time constant of nearly 39 hours. This is the longest time constant of any circuit at CERN. The operating current for 3.8 T is 18,160 A, giving a stored energy of 2.3 GJ.\n\nThe job of the big magnet is to bend the paths of particles emerging from high-energy collisions in the LHC. The more momentum a particle has the less its path is curved by the magnetic field, so tracing its path gives a measure of momentum. CMS began with the aim of having the strongest magnet possible because a higher strength field bends paths more and, combined with high-precision position measurements in the tracker and muon detectors, this allows accurate measurement of the momentum of even high-energy particles.\n\nThe tracker and calorimeter detectors (ECAL and HCAL) fit snugly inside the magnet coil whilst the muon detectors are interleaved with a 12-sided iron structure that surrounds the magnet coils and contains and guides the field. Made up of three layers this “return yoke” reaches out 14 metres in diameter and also acts as a filter, allowing through only muons and weakly interacting particles such as neutrinos. The enormous magnet also provides most of the experiment’s structural support, and must be very strong itself to withstand the forces of its own magnetic field.\n\nAs the name “Compact Muon Solenoid” suggests, detecting muons is one of CMS’s most important tasks. Muons are charged particles that are just like electrons and positrons, but are 200 times more massive. We expect them to be produced in the decay of a number of potential new particles; for instance, one of the clearest \"signatures\" of the Higgs Boson is its decay into four muons.\n\nBecause muons can penetrate several metres of iron without interacting, unlike most particles they are not stopped by any of CMS's calorimeters. Therefore, chambers to detect muons are placed at the very edge of the experiment where they are the only particles likely to register a signal.\n\nTo identify muons and measure their momenta, CMS uses three types of detector: drift tubes (DT), cathode strip chambers (CSC) and resistive plate chambers (RPC). The DTs are used for precise trajectory measurements in the central \"barrel\" region, while the CSCs are used in the \"end caps\". The RPCs provide a fast signal when a muon passes through the muon detector, and are installed in both the barrel and the end caps.\n\nThe drift tube (DT) system measures muon positions in the barrel part of the detector. Each 4-cm-wide tube contains a stretched wire within a gas volume. When a muon or any charged particle passes through the volume it knocks electrons off the atoms of the gas. These follow the electric field ending up at the positively charged wire. By registering where along the wire electrons hit (in the diagram, the wires are going into the page) as well as by calculating the muon's original distance away from the wire (shown here as horizontal distance and calculated by multiplying the speed of an electron in the tube by the time taken) DTs give two coordinates for the muon’s position. Each DT chamber, on average 2m x 2.5m in size, consists of 12 aluminium layers, arranged in three groups of four, each with up to 60 tubes: the middle group measures the coordinate along the direction parallel to the beam and the two outside groups measure the perpendicular coordinate.\n\nCathode strip chambers (CSC) are used in the endcap disks where the magnetic field is uneven and particle rates are high. CSCs consist of arrays of positively charged “anode” wires crossed with negatively charged copper “cathode” strips within a gas volume. When muons pass through, they knock electrons off the gas atoms, which flock to the anode wires creating an avalanche of electrons. Positive ions move away from the wire and towards the copper cathode, also inducing a charge pulse in the strips, at right angles to the wire direction. Because the strips and the wires are perpendicular, we get two position coordinates for each passing particle. In addition to providing precise space and time information, the closely spaced wires make the CSCs fast detectors suitable for triggering. Each CSC module contains six layers making it able to accurately identify muons and match their tracks to those in the tracker.\n\nResistive plate chambers (RPC) are fast gaseous detectors that provide a muon trigger system parallel with those of the DTs and CSCs. RPCs consist of two parallel plates, a positively charged anode and a negatively charged cathode, both made of a very high resistivity plastic material and separated by a gas volume. When a muon passes through the chamber, electrons are knocked out of gas atoms. These electrons in turn hit other atoms causing an avalanche of electrons. The electrodes are transparent to the signal (the electrons), which are instead picked up by external metallic strips after a small but precise time delay. The pattern of hit strips gives a quick measure of the muon momentum, which is then used by the trigger to make immediate decisions about whether the data are worth keeping. RPCs combine a good spatial resolution with a time resolution of just one nanosecond (one billionth of a second).\n\nNew particles discovered in CMS will be typically unstable and rapidly transform into a cascade of lighter, more stable and better understood particles. Particles travelling through CMS leave behind characteristic patterns, or ‘signatures’, in the different layers, allowing them to be identified. The presence (or not) of any new particles can then be inferred.\n\nTo have a good chance of producing a rare particle, such as a Higgs boson, a very large number of collisions is required. Most collision events in the detector are \"soft\" and do not produce interesting effects. The amount of raw data from each crossing is approximately 1 megabyte, which at the 40 MHz crossing rate would result in 40 terabytes of data a second, an amount that the experiment cannot hope to store, let alone process properly. The full trigger system reduces the rate of interesting events down to a manageable 1000 per second.\n\nTo accomplish this, a series of \"trigger\" stages are employed. All the data from each crossing is held in buffers within the detector while a small amount of key information is used to perform a fast, approximate calculation to identify features of interest such as high energy jets, muons or missing energy. This \"Level 1\" calculation is completed in around 1 µs, and event rate is reduced by a factor of about thousand down to 50 kHz. All these calculations are done on fast, custom hardware using reprogrammable field-programmable gate arrays (FPGA).\n\nIf an event is passed by the Level 1 trigger all the data still buffered in the detector is sent over fibre-optic links to the \"High Level\" trigger, which is software (mainly written in C++) running on ordinary computer servers. The lower event rate in the High Level trigger allows time for much more detailed analysis of the event to be done than in the Level 1 trigger. The High Level trigger reduces the event rate by a further factor of hundred down to 1000 events per second. These are then stored on tape for future analysis.\n\nData that has passed the triggering stages and been stored on tape is duplicated using the Grid to additional sites around the world for easier access and redundancy. Physicists are then able to use the Grid to access and run their analyses on the data.\n\nThere are a huge range of analyses performed at CMS, including:\n\nThe term Compact Muon Solenoid comes from the relatively compact size of the detector, the fact that it detects muons, and the use of solenoids in the detector. \"CMS\" is also a reference to the center-of-mass system, an important concept in particle physics.\n\n\n\n"}
{"id": "1209416", "url": "https://en.wikipedia.org/wiki?curid=1209416", "title": "DIDO (nuclear reactor)", "text": "DIDO (nuclear reactor)\n\nDIDO was a materials testing nuclear reactor at the Atomic Energy Research Establishment at Harwell, Oxfordshire in the United Kingdom. It used enriched uranium metal fuel, and heavy water as both neutron moderator and primary coolant. There was also a graphite neutron reflector surrounding the core. In the design phase, DIDO was known as AE334 after its engineering design number.\n\nDIDO was designed to have a high neutron flux, largely to reduce the time required for testing of materials intended for use in nuclear power reactors. This also allowed for the production of intense beams of neutrons for use in neutron diffraction.\n\nDIDO was shut down in 1990. The primary facilities decommissioning is expected to be complete in 2023 with the reactor decommissioning completed in 2031 and final site clearance achieved in 2064 \n\nIn all, six DIDO class reactors were constructed based on this design:\n\n\nHIFAR was the last to shut down, in 2007.\n\n"}
{"id": "3273853", "url": "https://en.wikipedia.org/wiki?curid=3273853", "title": "Dimension (metadata)", "text": "Dimension (metadata)\n\nIn metadata, dimension is a set of equivalent units of measure, where equivalence between two units of measure is determined by the existence of a quantity preserving one-to-one correspondence between values measured in one unit of measure and values measured in the other unit of measure, independent of context, and where characterizing operations are the same.\n\nThe equivalence defined here forms an equivalence relation on the set of all units of measure. Each equivalence class corresponds to a dimensionality. The units of measure \"temperature in degrees Fahrenheit\" and \"temperature in degrees Celsius\" have the same dimensionality, because given a value measured in degrees Fahrenheit there is a value measured in degrees Celsius with the same quantity, and vice versa. Quantity preserving one-to-one correspondences are the well-known equations Cº = (5/9)*(Fº − 32) and Fº = (9/5)*(Cº) + 32.\n\nUnits of measure are not limited to physical categories. Examples of physical categories are: linear measure, area, volume, mass, velocity, time duration.Examples of non-physical categories are: currency, quality indicator, colour intensity.\n\nQuantities may be grouped together into categories of quantities which are mutually comparable. Lengths, diameters, distances, heights, wavelengths and so on would constitute such a category. Mutually comparable quantities have the same dimensionality. ISO 31-0 calls these \"quantities of the same kind\".\n\n"}
{"id": "57151052", "url": "https://en.wikipedia.org/wiki?curid=57151052", "title": "Discursive deracialization", "text": "Discursive deracialization\n\nDiscursive deracialization is a term used for the rhetorical removal of 'race' from potentially racially motivated arguments. Earlier known as \"deracialization of discourse\", discursive deracialization is where the opposition to, or negative representations of, minority out-groups is attributed to reasons other than race.\nDiscourse does not have to be explicitly racist to have discriminatory, exclusionary and oppressive effects. Downplaying race as an explanatory construct may allow for the continued institutionalisation of racial exclusion. \nGoodman and Burke point out that economic, religious and incompatibility arguments are used in the discursive deracialization of opposition to asylum-seeking (in the UK). These explanatory arguments may be viewed in light of an increasing emphasis on national belonging and discourses of nation in the discursive deracialization of racist discourses.\n"}
{"id": "45164926", "url": "https://en.wikipedia.org/wiki?curid=45164926", "title": "Douglass (Martian crater)", "text": "Douglass (Martian crater)\n\nDouglass is a crater in the east of Thaumasia quadrangle of Mars and in the east of Aonia Terra, located at 51.8°S latitude and 70.6°W longitude. It is 94.0 km in diameter and was named after Andrew E. Douglass, and the name was approved in 1973.\n\nThe crater is located nearly WNW of Halley and east of the ringed crater of Lowell. A third of the way to Halley is Ogygis Undae which s the only named dune field in the southern hemisphere. Further east is Argyre Planitia, southwest is Aonia Planum and north is Phrixi Rupes.\n\n"}
{"id": "8969039", "url": "https://en.wikipedia.org/wiki?curid=8969039", "title": "Electrochromic devices", "text": "Electrochromic devices\n\nAn electrochromic device (ECD) controls optical properties such as optical transmission, absorption, reflectance and/or emittance in a continual but reversible manner on application of voltage (electrochromism). This property enables an ECD to be used for applications like smart glass, electrochromic mirrors, and electrochromic display devices.\n\nThe history of coloration goes back to 1704 when Diesbach discovered Prussian blue (hexacyanoferrate), which changes the color from transparent to blue under oxidation of iron. In the 1930s, Kobosew and Nekrassow first noted electrochemical coloration in bulk tungsten oxide. While working at Balzers in Lichtenstein, T. Kraus provided a detailed description of electrochemical coloration in thin film of tungsten trioxide (WO) on 30 July 1953. In 1969, S. K. Deb demonstrated electrochromic coloration in WO thin films. Deb observed electrochromic color by applying electric field of the order of 10 Vcm across WO thin film. In fact, the real birth of the EC technology is usually attributed to S. K. Deb’s seminal paper of 1973, wherein he described the coloration mechanism in WO. The electrochromism occurs due to the electrochemical redox reactions that take place in electrochromic materials. Various types of materials and structures can be used to construct electrochromic devices, depending on the specific applications.\n\nElectrochromic (sometimes called electrochromatic) devices are one kind of electrochromic cells. The basic structure of ECD consists of two EC layers separated by an electrolytic layer. The ECD works on an external voltage, for which the conducting electrodes are used on the either side of both EC layers. Electrochromic devices can be categorized in two types depending upon the kind of electrolyte used viz. Laminated ECD are the one in which liquid gel is used while in solid electrolyte EC devices solid inorganic or organic material is used. The basic structure of electrochromic device embodies five superimposed layers on one substrate or positioned between two substrates in a laminated configuration. In this structure there are three principally different kinds of layered materials in the ECD: The EC layer and ion-storage layer conduct ions and electrons and belong to the class of mixed conductors. The electrolyte is a pure ion conductor and separates the two EC layers. The transparent conductors are pure electron conductors. Optical absorption occurs when electrons move into the EC layers from the transparent conductors along with charge balancing ions entering from the electrolyte.\n\nIn solid-state electrochromic devices, solid inorganic or organic material is used as the electrolyte. TaO and ZrO are the most extensively studied inorganic solid electrolytes.\n\nLaminated electrochromic devices are the ones in which a liquid gel is used as the electrolyte.\n\nTypically, ECD are of two types depending on the modes of device operation, namely the transmission mode and reflectance mode. In the transmission mode, the conducting electrodes are transparent and control the light intensity passing through them; this mode is used in smart-window applications. In the reflectance mode, one of the transparent conducting electrodes (TCE) is replaced with a reflective surface like aluminum, gold or silver, which controls the reflective light intensity; this mode is useful in rear-view mirrors of cars and EC display devices.\n\nElectrochromic windows, also known as smart windows, are a new technological arrangement for achieving energy efficiency in buildings, with variable transmittance of light and solar energy. These ‘‘smart windows’’ can automatically control the amount of light and solar energy passing through the windows which subsequently improves indoor comfort; for example, electrochromic glass provides better glare resistance than fritted glass in most direct sunlight applications. The efficiency of these windows will vary depending on their placement, size, and local climate conditions since these factors influence the amount of sunlight that comes in contact with these windows. Electrochromic windows generally achieve their control over light and heat through their layered design. These layers within the window allow for tinting of the glass in response to increases in incoming sunlight as well as protection against UV radiation. An example of this layered design is the electrochromic glass developed by Gesimat, where multiple layers of material (i.e. tungsten oxide, polyvinyl butyral, and Prussian Blue) are sandwiched by two dual layers of glass and fluorine-doped tin oxide-coated glass. Together, the tungsten oxide and Prussian Blue layers form complementary electrochromic layers; essentially, this means they form the positive and negative ends of a battery using the incoming solar energy. The polyvinyl butyral (PVB) forms the central layer in this configuration, and it serves as a polymer electrolyte (this allows for the flow of ions which, in turn, generates a current).\n\nElectrochromic reflecting surfaces are employed as self darkening mirrors that regulate reflections of flashing light from following vehicles at night so that a driver can see them without discomfort.\nElectrochromic display operating in either reflecting or transmitting mode. Advantages of EC display is Low power consumption and cheap.\n\nHowever, there are various other display applications where ECD can be used viz. electrochromic paper, electrochromic goggles, motorcycle helmet-visors. Electrochromic paper, which on touching it with a stylus electrode can create an image, has been prepared by incorporating ECs in paper. Furthermore, visors of helmets and goggles can be colored to a chosen degree at day times and bleached during the night.\n"}
{"id": "21192785", "url": "https://en.wikipedia.org/wiki?curid=21192785", "title": "Ernő Csíki", "text": "Ernő Csíki\n\nErnst Csiki, or Ernő Csiki (Csíki) (, 1875 in Vulkan – 1954 in Budapest) was a Hungarian entomologist who specialised in Coleoptera.\n\nHe was, between 1897 and 1932, Keeper of the Collections of the Hungarian Natural History Museum where his collection is conserved.\n\nAt the time of Ernő Csiki's retirement (1932) the beetle collection contained over 1 million specimens largely due to his purchases and his obtaining funding for expeditions.\nCsiki wrote several parts of \"Coleopterorum Catalogus\" and many papers on Carpathian Coleoptera.\n\n\n"}
{"id": "50460577", "url": "https://en.wikipedia.org/wiki?curid=50460577", "title": "Evolutionary theory of the self", "text": "Evolutionary theory of the self\n\nWhen trying to understand the self in terms of the brain, neuroscientists have found contradictory results and paradoxes. Nevertheless, Gonzalo Munevar has argued that neuroscience in an evolutionary context can give a proper explanation of the self. His Evolutionary Theory of the Self depends on, “the ability by the brain to coordinate new sensory information in light of the organism’s internal states and in the context of its personal history and genetic inheritance.\" His theory is an alternative conception for the explanation of the self, which takes into account the evolutionary biology of the brain.\n\nOrganisms that are highly complex execute the function of telling self from other with the brain and the immune system. To fulfill the function of recognizing self from other, the brain uses past experiences and genetic inheritance (e.g. survival, reproduction). The self is defined by these functions that distinguish an organisms from other organisms, which allow them to act as one whole entity in social and physical environments. Simply put, the theory revolves around the idea that the brain constitutes the self, which represents itself in a variety of internal states.\n\nThe brain/self evolves for action to be able to interact with social and physical environments. It is suggested that the brain performs a complex list of tasks to complete these interactions to distinguish self from other. This defines the brain to be characteristically distributive to complete complex tasks, and thus suggests that the self is also distributive. Therefore, the Evolutionary Theory of the Self detours from the traditional conceptions that include the self being a centralized, unitary mechanism that is both conscious (sense of self) and compiled of a collection of episodic memories. Alternatively, it suggests that the conception of self is mostly unconscious, and the brain evolves from past experiences and genetic inheritance to create the evolutionary self.\n\nIn Munevar’s study, “fMRI Study of Self vs. Others’ Attributions of Traits Consistent with Evolutionary Understanding of the Self,” he aimed to demonstrate the experimental feasibility of this conception of the self as a distributive system, and discovered results complimenting the Evolutionary Theory of the Self while resolving the contradictions and paradoxes of traditional conceptions of self.\n\nOne of the problems is that the results of brain-imaging studies of self-knowledge vary depending on the behavioral tasks chosen. Some studies use positron emission tomography (PET) to do self-attribution of personality traits, while others use functional magnetic resonance imaging (fMRI). Other studies prefer to do tasks involving self-recognition (recognizing a photograph or yourself and others). Studies that use self-attribution studies, “find neural activation of the medial prefrontal cortex (MPFC) as evidence for the self”, while studies consisting of self-recognition tasks find, “correlated activation of the right prefrontal lobe and regions of the medial and left hemisphere as evidence self-awareness and self-knowledge.\"\n\nThis variety of results of the studies have provided evidence for Gillihan and Farah to conclude that there is not a unitary and common neural system concerning the self, which leads into the next two problems of the traditional conception of self. These problems are that the traditional conceptions of the self argue that the self is a unified mechanism that exists in a centralized area in the brain, and that the self is something we can consciously sense. The problems with these accounts are that there is scientific research contradicting the claims of traditional conceptions. Llinas suggests that the self is a form of perception and thus that the self is an invention of the brain just as secondary sensory qualities are. He argues that there is no one brain area that could account for the self, and he concludes that the self doesn’t exist. Although Llinas is confusing the conscious and unconscious self, because when he suggests the self as a form of perception he should be referring to the conscious self being a form of perception. Munevar suggests that Llinas is incorrect in assuming the self does not exist, because just as an elephant and the perception of an elephant are different things, so are the self and our perception of the self.\n\nTraditional conceptions also assume that the self is a collection of episodic memories, since they are memories of the actions that sculpt our personalities, and therefore closely link personality and the self. According to Klein, in a study of patients who had lost their hippocampi (the part of the brain responsible for memories), patients were able to recollect their knowledge of personality even in the absence of episodic memories. This points to show that the trait summaries of their personality must have come around subconsciously, inferring that the self can exist even in the absence of episodic memories. Thus, the self cannot be a collection of episodic memories.\n\nThe Evolutionary Theory points out that distributive systems are characteristic of the brain. Organisms need to identify itself from others in many complex ways, thus many areas of the brain are used when distinguishes self from other. We need to understand that the brain is full of distributed mechanisms, thus creating an expectation that the self will be too. With this understanding, the Evolutionary Theory of the Self avoids all the difficulties about the unified and central mechanisms that traditional conceptions hold. In addition, the brain-based model of the evolutionary theory recognizes that the majority of the mental tasks highly complex organisms do are unconscious. Simply put, we may be aware of a decision we have made, but not the calculations that went into the decision as they are not capable to be understood by the conscious self. By attempting to take an evolutionary approach to understanding the self, the confrontation of self with the sense of self is avoided, in addition to, “all the problems that arise from an undue emphasis on consciousness.”\n\nAs suggested by Munevar, research on the evolutionary theory of self needs to firstly examine the existence of distributed activation in the brain when doing a self-attribution task. Secondly, they need to examine distinctions in brain activity when identifying self and close others in a manner of objective vs subjective to see if there are activation variances between the two. Thirdly, research needs to use non-personality traits as well as personality traits to take into account the importance of non-personality traits to the evolutionary needs of an organism. Fourthly, the research should aim to prove that humans, “should identify with those close to us, although not as strongly as with ourselves.\" These four aims were the four that structured the hypotheses in his study, and provide blueprint for further research to test.\n\nIn Munevar’s study, they compared self vs other conditions in which personality trait adjectives were rated in terms of Self vs Best Friend, Self vs Bill Gates, and Best Friend vs Bill Gates. He used a blocked-design fMRI paradigm, where non-personality and personality trait adjectives were rated as to whether they applied to themselves or other. The four hypotheses were as follows:(1) Self conditions would show a different pattern of brain activation from those shown by Best Friend (i.e., close other) and Bill Gates (i.e., far other) conditions; (2) our data should exhibit a fair degree of distributive performance by the brain in responding to these attribution tasks; and (3) the resulting patterns of activation should show some overlap with structures normally involved in preparedness to action (motion). In addition, (4) the Best Friend condition would also differ from the Bill Gates condition.The study found that several areas of the brain were active when doing the tasks related to ‘Self’ and Best Friend. In support of the first hypothesis (1), there was very significant differential activation in BA 31 (covering part of posterior cingulate gyrus and the medial parietal), and the substantia nigra. There was significant activity in the right and left portions of BA 23, and the caudate tail. In a lesser degree, there was some activity in the BA 10 and the thalamus. There was also greater activation in BA 24, particularly the anterior cingulate cortex, in Self-Bill Gates condition compared to the Best Friend-Bill Gates condition. With these results, there is different brain patterns shown by Best Friend and Bill Gate conditions. The contrasting results found also support the second hypothesis (2), and indicate that a large number of distributive structures throughout the brain are used when doing a self-attribution task.\n\nIn support of the third hypothesis (3), he found a large amount of activation of the substantia nigra (key stricture of basal ganglia for action), in addition to the activation of the caudate nucleus of the basal ganglia. These areas in the brain are known to be crucial to the process of movement, and thus an overlap with these structures supports their hypothesis.\n\nIn support of the fourth hypothesis (4), the greater activation of BA 24 in comparison of Best Friend vs Bill Gates condition and the Self-Bill Gates condition points to show that humans strongly identify with those you are close to us, and less strongly with ourselves.\n\nThe results displayed that the brain areas that we use for thinking about ourselves may also be used for thinking about those who are important to us. The fact that there is this relationship with multiple parts of the brain being active during both goes to show that there is an association between the two, furthering to suggest that one area in the brain nor one unified mechanism is not responsible for the self. The results also support the evolutionary expectation of a connection between self and the preparedness for action. The activation of key areas in the basal ganglia and the differential activation of BA 31 by the self-conditions in contrast with the Best Friend conditions in this study, elude to further support the idea of personality being a product of the unconscious self.\n\nFrom the results seen in Munevar’s study, there are several implications for the future progress of this theory. Since the study had a limitation of gender impacting the results of the conditions of Self vs Best Friend and Best Friend vs Bill Gates, further research should be done that classify results of fMRI by each gender. Another positive direction this study points to is by studying brains with deficits in activation of the anterior cingulate that bring problems when identifying self from non-self. This problem is prevalent in mental disorders such as schizophrenia, autism, and late-stage Alzheimer’s, where the ability to differentiate self vs other is compromised. Further research should use the results of Munevar's study and continue on to dissect the paradoxes and problems of traditional conceptions, while focusing on the evolutionary biology of the brain. Overall, the research done on the Evolutionary Theory of Self is promising and provides fruitful insight to the possibility of discovering new conclusions on what we know about the self.\n"}
{"id": "56630159", "url": "https://en.wikipedia.org/wiki?curid=56630159", "title": "Fahlore", "text": "Fahlore\n\nFahlore, or Fahlerz, refers to an ore consisting of complex sulfosalts, mostly the series between tennantite (Cu[Cu(Fe,Zn)]AsS) and tetrahedrite (Cu[Cu(Fe,Zn)]SbS). It comes from the German word for pale: Fahl. This refers to the characteristic pale grey to dark black colour.\n"}
{"id": "34355820", "url": "https://en.wikipedia.org/wiki?curid=34355820", "title": "Gwacheon National Science Museum", "text": "Gwacheon National Science Museum\n\nGwacheon National Science Museum is a national museum in Gwacheon, South Korea. It opened in 2008.\n\n\n"}
{"id": "1996424", "url": "https://en.wikipedia.org/wiki?curid=1996424", "title": "Hyalite", "text": "Hyalite\n\nHyalite is a form of opal with a glassy and clear appearance which may exhibit an internal play of colors if natural inclusions are present. It is also called \"Muller's glass\", \"water opal\" and \"jalite\". The name Müller's glass derived from the name of its discoverer, Franz-Joseph Müller von Reichenstein. \n\nHyalite's Mohs hardness is 5.5 to 6 and has a specific gravity of 1.9 - 2.1. It has no planes of cleavage but fractures conchoidally, is clear or translucent and has a globular structure. Its luster is vitreous and its streak is white. Hyalite is an amorphous form of silica (SiO) formed as a volcanic sublimate in volcanic or pegmatic rock and is therefore considered a mineraloid. It contains 3 - 8% water, either as a silanol group or in molecular form. \n\nOpalescent hyalite is used in jewellery, and well-formed samples are of interest to collectors due to their unusual appearance, mode of formation and relative rarity. It is sometimes mistaken for resin opal or silica glass since they both may appear clear and globular, but it can be identified under ultraviolet light due to its bright green fluorescence.\n\n"}
{"id": "18595591", "url": "https://en.wikipedia.org/wiki?curid=18595591", "title": "International Association of Geodesy", "text": "International Association of Geodesy\n\nThe International Association of Geodesy is a constituent Association of the International Union of Geodesy and Geophysics. It was founded in 1862 as the \"Mitteleuropäische Gradmessung\" became the \"Europäische Gradmessung\" in 1867, the \"Internationale Erdmessung\" (\"Association Geodésique Internationale\" in French and \"International Geodetic Association\" in English) in 1886 and took its present name in 1946. At present there are 4 commissions and one inter-commission committee:\n\n\nThe Global Geodetic Observing System (GGOS) is the observing arm of the IAG that focuses on proving the geodetic infrastructure to measure changes in the earth's shape, rotation and mass distribution.\n\n\n"}
{"id": "35314773", "url": "https://en.wikipedia.org/wiki?curid=35314773", "title": "Kai-Ming Ho", "text": "Kai-Ming Ho\n\nKai-Ming Ho is a Senior Physicist at Ames Laboratory and distinguished Professor in Department of Physics and Astronomy at Iowa State University.\n\n\n"}
{"id": "33870431", "url": "https://en.wikipedia.org/wiki?curid=33870431", "title": "Laser detuning", "text": "Laser detuning\n\nIn optical physics, laser detuning is the tuning of a laser to a frequency that is slightly off from a quantum system's resonant frequency. When used as a noun, the laser detuning is the difference between the resonance frequency of the system and the laser's optical frequency (or wavelength). Lasers tuned to a frequency below the resonant frequency are called \"red-detuned\", and lasers tuned above resonance are called \"blue-detuned\".\n\nLet us consider a system with a resonance frequency formula_1 in the optical frequency range of the electromagnetic spectrum, i.e. with frequency of a few THz to a few PHz, or equivalently with a wavelength in the range of 10 nm to 100 μm. If this system is excited by a laser with a frequency formula_2 close to this value, the laser detuning is then defined as:formula_3The most common examples of such resonant systems in the optical frequency range are optical cavities (free-space, fiber or microcavities), atoms, and dielectrics or semiconductors. \n\nThe laser detuning is important for a resonant system such as a cavity because it determines the phase (modulo 2π) acquired by the laser field per roundtrip. This is important for linear optical processes such as interference and scattering, and extremely important for nonlinear optical processes because it affects the phase-matching condition.\n\nLasers can be detuned in the lab frame so that they are Doppler shifted to the resonant frequency in a moving system, which allows lasers to affect only atoms moving at a specific speed or in a specific direction and makes laser detuning a central tool of laser cooling and magneto-optical traps. \n\nSimilar to the laser cooling of atoms, the sign of the detuning plays an important part in Optomechanical applications. In the red detuned regime, the optomechanical system undergoes cooling and coherent energy transfer between the light and the mechanical mode (a \"beam splitter\"). In the blue-detuned regime, it undergoes heating, mechanical amplification and possibly squeezing and entanglement. The on-resonance case when the laser detuning is zero, can be used for very sensitive detection of mechanical motion, such as used in LIGO.\n"}
{"id": "17568225", "url": "https://en.wikipedia.org/wiki?curid=17568225", "title": "List of Montana state symbols", "text": "List of Montana state symbols\n\nThe following is a list of symbols of the U.S. state of Montana.\n\n\n\n"}
{"id": "16677038", "url": "https://en.wikipedia.org/wiki?curid=16677038", "title": "List of Slovenian astronomers", "text": "List of Slovenian astronomers\n\nA list of notable astronomers from Slovenia:\n\n\n\n\n\n\n\n\n\n"}
{"id": "1313985", "url": "https://en.wikipedia.org/wiki?curid=1313985", "title": "List of Washington state symbols", "text": "List of Washington state symbols\n\nThe U.S. state of Washington has 21 official emblems, as designated by the Washington State Legislature. These symbols, which reflect the history and culture of the state, are often opportunities for politicians to \"tie themselves to popular symbols\", for teachers to highlight the legislative process to their students, and for lobbyists to \"have their products given official designation\".\n\nWhile some of the symbols are unique to Washington, others are used by multiple states. For example, the willow goldfinch (also known as the American goldfinch), Washington's state bird, is also an official symbol for Iowa and New Jersey. Washington's state grass, bluebunch wheatgrass, is also a symbol for the state of Montana. The square dance and apple are commonly used state dances and state foods, respectively. While most states have an official motto and nickname, Washington's motto (\"Al-ki\", meaning \"by and by\" in Chinook Jargon) and nickname (\"The Evergreen State\") have never been officially adopted by the Legislature.\n\nWashington's first official symbol was its flag, adopted in 1923. While some symbols, including the state flower and state seal, were selected before then, they were not adopted by the Legislature until later. Washington's second symbol was western hemlock, selected as the state tree in 1947. Fourteen symbols were added between 1950 and 2000. Five symbols have been adopted in the 21st century. The newest symbol of Washington is the Olympic marmot, declared the state endemic mammal in 2009.\n\nWhile most states have an official motto and nickname, the Washington Legislature never officially adopted either. \"Al-ki\", meaning \"by and by\" in Chinook Jargon, is the state's unofficial motto, first appearing on the territorial seal designed by Lt. J.K. Duncan. Washington was unofficially nicknamed \"The Evergreen State\" by pioneer and historian C.T. Conover for its abundant evergreen forests.\n\nSeveral symbols have been proposed for addition to the list of official state symbols but were never adopted. Proposed symbols have included Richard Berry's \"Louie Louie\" as the state song and Aplets and Cotlets (a confection made from apples and apricots by Liberty Orchards) as the state candy. The designation of sasquatch as the state's official cryptid or monster has been proposed since the 1970s, going as far as a joke proclamation issued by Governor Daniel J. Evans in 1970.\n\n\n"}
{"id": "663359", "url": "https://en.wikipedia.org/wiki?curid=663359", "title": "List of complexity classes", "text": "List of complexity classes\n\nThis is a list of complexity classes in computational complexity theory. For other computational and complexity subjects, see list of computability and complexity topics.\n\nMany of these classes have a 'co' partner which consists of the complements of all languages in the original class. For example if a language L is in NP then the complement of L is in co-NP. (This does not mean that the complement of NP is co-NP—there are languages which are known to be in both, and other languages which are known to be in neither.)\n\n\"The hardest problems\" of a class refer to problems which belong to the class such that every other problem of that class can be reduced to it. Furthermore, the reduction is also a problem of the given class, or its subset.\n\n"}
{"id": "16173852", "url": "https://en.wikipedia.org/wiki?curid=16173852", "title": "List of installation software", "text": "List of installation software\n\nThe following is a list of applications for building installation programs, organized by platform support.\n\n"}
{"id": "15385907", "url": "https://en.wikipedia.org/wiki?curid=15385907", "title": "List of lakes in the San Francisco Bay Area", "text": "List of lakes in the San Francisco Bay Area\n\nThis list of lakes in the San Francisco Bay Area groups lakes, ponds, and reservoirs by county. Numbers in parentheses are Geographic Names Information System feature ids.\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "608858", "url": "https://en.wikipedia.org/wiki?curid=608858", "title": "Looking Backward", "text": "Looking Backward\n\nLooking Backward: 2000–1887 is a utopian science fiction novel by Edward Bellamy, a journalist and writer from Chicopee Falls, Massachusetts; it was first published in 1888.\n\nIt was the third-largest bestseller of its time, after \"Uncle Tom's Cabin\" and \"Ben-Hur: A Tale of the Christ\". It influenced a large number of intellectuals, and appears by title in many socialist writings of the day. \"It is one of the few books ever published that created almost immediately on its appearance a political mass movement\".\n\nIn the United States alone, over 162 \"Bellamy Clubs\" sprang up to discuss and propagate the book's ideas. Owing to its commitment to the nationalization of private property and the desire to avoid use of the term \"socialism\", this political movement came to be known as Nationalism — not to be confused with the political concept of nationalism. The novel also inspired several utopian communities.\n\nThe decades of the 1870s and the 1880s were marked by economic and social turmoil, including the Long Depression of 1873–1879, a series of recessions during the 1880s, the rise of organized labor and strikes, and the 1886 Haymarket affair and its controversial aftermath. Moreover, American capitalism's tendency towards concentration into ever larger and less competitive forms—monopolies, oligopolies, and trusts—began to make itself evident, while emigration from Europe expanded the labor pool and caused wages to stagnate. The time was ripe for new ideas about economic development which might ameliorate the current social disorder.\n\nEdward Bellamy (1850–1898), a relatively unknown New England-born novelist with a history of concern with social issues, began to conceive of writing an impactful work of visionary fiction shaping the outlines of a utopian future, in which production and society were ordered for the smooth production and distribution of commodities to a regimented labor force. In this he was not alone — between 1860 and 1887, no fewer than 11 such works of fiction were produced in the United States by various authors dealing fundamentally with the questions of economic and social organization.\n\nBellamy's book, gradually planned throughout the 1880s, was completed in 1887 and taken to Boston publisher Benjamin Ticknor, who published a first edition of the novel in January 1888. Initial sales of the book were modest and uninspiring, but the book did find a readership in the Boston area, including enthusiastic reviews by future Bellamyites Cyrus Field Willard of the \"Boston Globe\" and Sylvester Baxter of the \"Boston Herald.\"\n\nShortly after publication, Ticknor's publishing enterprise, Ticknor and Company, was purchased by the larger Boston publisher, Houghton, Mifflin & Co., and new publishing plates were created for the book. Certain \"slight emendations\" were made to the text by Bellamy for this second edition, released by Houghton Mifflin in September 1889.\n\nIn its second release, Bellamy's futuristic novel met with enormous popular success, with more than 400,000 copies sold in the United States alone by the time Bellamy's follow-up novel, \"Equality,\" was published in 1897. Sales topped 532,000 in the USA by the middle of 1939. The book gained an extensive readership in Great Britain, as well, with more than 235,000 copies sold there between its first release in 1890 and 1935.\nThe first version of the novel published in China, heavily edited for the tastes of Chinese readers, was titled \"Huitou kan jilüe\" (回頭看記略). This text was later retitled \"Bainian Yi Jiao\" (百年一覺 ), or \"A Sleep of 100 Years\" and in 1891–1892 this version was serialized in \"Wanguo gongbao\"; the organization Guangxuehui (廣學會; Society for Promoting Education) published these pieces in a book format. This first translation, the first piece of science fiction from a Western country published in Qing dynasty China, was done in an abridged format by Timothy Richard. The novel was again serialized in China in 1898, in \"Zhongguo guanyin baihua bao\" (中國官音白話報); and in 1904, under the title \"Huitou kan\" (Looking Backward), within \"Xiuxiang xiaoshuo\" (繡像小說; Illustrated Fiction).\n\nThe book remains in print in multiple editions, with one publisher alone having reissued the title in a printing of 100,000 copies in 1945.\n\nBellamy's novel tells the story of a hero figure named Julian West, a young American, who towards the end of the 19th century, falls into a deep, hypnosis-induced sleep and wakes up 113 years later. He finds himself in the same location (Boston, Massachusetts), but in a totally changed world: It is the year 2000, and while he was sleeping, the United States has been transformed into a socialist utopia. The remainder of the book outlines Bellamy's thoughts about improving the future. The major themes include problems associated with capitalism, a proposed socialist solution of a nationalization of all industry, and the use of an \"industrial army\" to organize production and distribution, as well as how to ensure free cultural production under such conditions.\n\nThe young man readily finds a guide, Doctor Leete, who shows him around and explains all the advances of this new age, including drastically reduced working hours for people performing menial jobs and almost instantaneous, Internet-like delivery of goods. Everyone retires with full benefits at age 45, and may eat in any of the public kitchens. The productive capacity of the United States is nationally owned, and the goods of society are equally distributed to its citizens. A considerable portion of the book is dialogue between Leete and West wherein West expresses his confusion about how the future society works and Leete explains the answers using various methods, such as metaphors or direct comparisons with 19th-century society.\n\nAlthough Bellamy's novel did not discuss technology or the economy in detail, commentators frequently compare \"Looking Backward\" with actual economic and technological developments. For example, Julian West is taken to a store which (with its descriptions of cutting out the middleman to cut down on waste in a similar way to the consumers' cooperatives of his own day based on the \"Rochdale Principles\" of 1844) somewhat resembles a modern warehouse club like BJ's, Costco, or Sam's Club. He additionally introduces a concept of \"credit\" cards in chapters 9, 10, 11, 13, 25, and 26, but these actually function like modern debit cards. All citizens receive an equal amount of \"credit\". Those with more difficult, specialized, dangerous, or unpleasant jobs work fewer hours (in contrast to the real-world practice of paying them more for their efforts of, presumably, the same hours). Bellamy also predicts both sermons and music being available in the home through cable \"telephone\" (already demonstrated but commercialized only in 1890 as Théâtrophone in France).\n\nDespite the \"ethical\" character of his socialism (though he was initially reluctant to use the term \"socialism\"), Bellamy's ideas somewhat reflect classical Marxism. In chapter 19, for example, he has the new legal system explained. Most civil suits have ended in socialism, while crime has become a medical issue. The idea of atavism, then current, is employed to explain crimes not related to inequality (which Bellamy thinks will vanish with socialism). Remaining criminals are medically treated. One professional judge presides, appointing two colleagues to state the prosecution and defense cases. If all do not agree on the verdict, then it must be tried over. Chapters 15 and 16 have an explanation of how free, independent public art and news outlets could be provided in a more libertarian socialist system. In one case, Bellamy even writes, \"the nation is the sole employer and capitalist\".\n\nThough Bellamy tended to stress the independence of his work, \"Looking Backward\" shares relationships and resemblances with several earlier works—most notably the anonymous \"The Great Romance\" (1881), John Macnie's \"The Diothas\" (1883), Laurence Gronlund's \"The Co-operative Commonwealth\" (1884), and August Bebel's \"Woman in the Past, Present, and Future\" (1886). For example, in \"The True Author of Looking Backward\" (1890) J. B. Shipley argued that Bellamy's novel was a repeat of Bebel's arguments, while literary critic R. L. Shurter went so far as to argue that \"\"Looking Backward\" is actually a fictionalized version of \"The Co-operative Commonwealth\" and little more\". However, Bellamy's book also bears resemblances to the early socialist theorists or 'utopian socialists' Etienne Cabet, Charles Fourier, Robert Owen, and Henri Saint-Simon, as well as to the 'Associationism' of Albert Brisbane whom Bellamy had met in the 1870s.\n\nOn publication, \"Looking Backward\" was praised by both the American Federation of Labor and the Knights of Labor. Many members of the Knights read \"Looking Backward\" and also joined Bellamy's Nationalist clubs. \"Looking Backward\" was also praised by Daniel De Leon, Elizabeth Gurley Flynn and Upton Sinclair.\n\nIn 1897, Bellamy wrote a sequel, \"Equality\", dealing with women's rights, education, and many other issues. Bellamy wrote the sequel to elaborate and clarify many of the ideas merely touched upon in \"Looking Backward\".\n\nThe success of \"Looking Backward\" provoked a spate of sequels, parodies, satires, dystopian, and 'anti-utopian' responses. A partial list of these follows.\n\nDirectly 'anti-Bellamy' responses:\n\n\nDirect and positive utopian responses / unofficial sequels:\n\n\nThe result was a \"battle of the books\" that lasted through the rest of the 19th century and into the 20th. The back-and-forth nature of the debate is illustrated by the subtitle of Geissler's 1891 \"Looking Beyond\", which is \"A Sequel to 'Looking Backward' by Edward Bellamy and an Answer to 'Looking Forward' by Richard Michaelis\".\n\nThe book was translated into Bulgarian in 1892. In 1900 Bellamy personally approved a request by Bulgarian author Iliya Yovchev to make an \"adapted translation\" based on the realities of Bulgarian social order. The resulting work, titled \"The Present as Seen by Our Descendants And a Glimpse at the Progress of the Future\" (\"Настоящето, разгледано от потомството ни и надничане в напредъка на бъдещето\"), generally followed the same plot. The events in Yovchev's version take place in an environmentally friendly Sofia and describe the country's unique path of adapting to the new social order. It is considered by local critics to be the first Bulgarian utopian work.\n\nWilliam Morris's 1890 utopia \"News from Nowhere\" was partly written in reaction to Bellamy's utopia, which Morris did not find congenial.\n\nBeyond the purely literary sphere, Bellamy's descriptions of utopian urban planning had a practical influence on Ebenezer Howard's founding of the garden city movement in England, and on the design of the Bradbury Building in Los Angeles.\n\nDuring the Great Strikes of 1877, Eugene V. Debs opposed the strikes and argued that there was no essential necessity for the conflict between capital and labor. Debs was influenced by Bellamy's book to turn to a more socialist direction. He soon helped to form the American Railway Union. With supporters from the Knights of Labor and from the immediate vicinity of Chicago, workers at the Pullman Palace Car Company went on strike in June 1894. This came to be known as the Pullman Strike.\n\nThe book had a specific and intense reception in Wilhelminian Germany including various parodies and sequels, from Eduard Loewenthal, Ernst Müller and Philipp Wasserburg, Konrad Wilbrandt and Richard Michaelis.\n\nIn the 1930s, there was a revival of interest in \"Looking Backward\". Several groups were formed to promote the book's ideas. The largest was Edward Bellamy Association of New York; its honorary members included John Dewey, Heywood Broun and Roger N. Baldwin. Arthur Ernest Morgan, chairman of the Tennessee Valley Authority, also admired the book and wrote the first biography of Bellamy. \n\n\"Looking Backward\" influenced the novel \"Future of a New China\" by Liang Qichao.\n\n\"Looking Backward\" was rewritten in 1974 by American science fiction writer Mack Reynolds as \"Looking Backward from the Year 2000\". Matthew Kapell, a historian and anthropologist, examined this re-writing in his essay, \"Mack Reynolds' Avoidance of his own Eighteenth Brumaire: A Note of Caution for Would-Be Utopians\".\n\nIn 1984, Herbert Knapp and Mary Knapp's \"Red, White and Blue Paradise: The American Canal Zone in Panama\" appeared. The book was in part a memoir of their careers teaching at fabled Balboa High School, but also a re-interpretation of the Canal Zone as a creature of turn-of-the-century Progressivism, a workers' paradise. The Knapps used Bellamy's \"Looking Backward\" as their heuristic model for understanding Progressive ideology as it shaped the Canal Zone.\n\nA one-act play, \"Bellamy's Musical Telephone,\" was written by Roger Lee Hall and premiered at Emerson College in Boston in 1988 on the centennial year of the novel's publication. It was released as a DVD titled, \"The Musical Telephone.\"\n\n\n\n"}
{"id": "22868263", "url": "https://en.wikipedia.org/wiki?curid=22868263", "title": "Mandyam Veerambudi Srinivasan", "text": "Mandyam Veerambudi Srinivasan\n\nMandyam Veerambudi Srinivasan AM FRS is an Indian-born Australian biologist who studies visual systems particularly those of bees and birds.\n\nA faculty member at the University of Queensland, he is a recipient of the Prime Minister's Prize for Science and a fellow of the Australian Academy of Science and the Royal Society (elected 2001).\n\n\nFocusing his attention on bees, Srinivasan has explored how simple animal systems display complex behaviours. This broad field has applications in robotics, especially unmanned aerial vehicles because of the competing needs for autonomy and a lightweight control system.\n\nBees are highly competent fliers. Srinivasan has shown that many ostensibly complex flight behaviours can be attributed to the tendency of the bee to keep optic flow constant. Some examples:\n"}
{"id": "213233", "url": "https://en.wikipedia.org/wiki?curid=213233", "title": "Mercury-Redstone 3", "text": "Mercury-Redstone 3\n\nMercury-Redstone 3, or Freedom 7, was the first United States human spaceflight, on May 5, 1961, piloted by astronaut Alan Shepard. It was the first manned flight of Project Mercury, the objective of which was to put an astronaut into orbit around the Earth and return him safely. Shepard's mission was a 15-minute suborbital flight with the primary objective of demonstrating his ability to withstand the high g-forces of launch and atmospheric re-entry.\n\nShepard named his space capsule \"Freedom 7\", setting a precedent for the remaining six Mercury astronauts naming their spacecraft. The number 7 was included in all the manned Mercury spacecraft names to honor NASA's first group of seven astronauts. His spacecraft reached an altitude of 116.5 statute miles (101.2 nautical miles, 187.5 km) and traveled a downrange distance of 302.8 statute miles (263.1 nautical miles, 487.3 km). It was the fourth Mercury flight launched with the Mercury-Redstone Launch Vehicle, from Cape Canaveral, Florida, close to the Atlantic Ocean.\n\nDuring the flight, Shepard observed the Earth and tested the capsule's attitude control system, turning the capsule around to face its blunt heat shield forward for atmospheric re-entry. He also tested the retrorockets which would return later missions from orbit, though the capsule did not have enough energy to remain in orbit. After re-entry, the capsule landed by parachute on the North Atlantic Ocean off the Bahamas. Shepard and the capsule were picked up by helicopter and brought to U.S. Navy aircraft carrier USS \"Lake Champlain\"\".\n\nThe mission was a technical success, though American pride in the accomplishment was dampened by the fact that just three weeks before, the Soviet Union had launched the first man in space, Yuri Gagarin, who completed one orbit on Vostok 1. In 2017 the first National Astronaut Day was held on May 5 to pay tribute to this first flight.\n\nThe \"Freedom 7\" spacecraft, Mercury capsule #7, was delivered to Cape Canaveral on December 9, 1960. It had originally been expected that a mission could be launched soon after the spacecraft was available, but Capsule #7 turned out to require extensive development and testing work before it was deemed safe for flight. However, as it had been earmarked since the summer as the first manned spacecraft, the decision was taken to delay the mission until this particular capsule was ready, with a tentative launch date of March 6, rather than use an alternative capsule. The booster originally intended for the flight, Redstone #3, had been delivered to the Cape in early December; however, it was then used on the MR-1A test flight on December 19. The replacement, Redstone #7, did not arrive at the Cape until late March; by this time, however, the mission had already been postponed to await the results of another test flight.\n\nIn late 1960, there had been a growing number of concerns about the standards of the Redstone launch vehicle; the MR-2 test flight, \"manned\" by a chimpanzee, had had technical problems during the launch leading to the spacecraft flying too high, too far and too fast. As a result, the mission was two minutes longer than planned, and the re-entry subjected the passenger to 14.7g rather than the planned figure of approximately 12g. The splashdown point was sixty miles from the nearest recovery ship, and it was over two and a half hours before a helicopter could recover the capsule and its passenger – by which time it had almost sunk. As a result, NASA was unwilling to launch the MR-3 mission without further development work; by late February, there were still seven major alterations they had made to the booster which required testing. An additional testing flight was accordingly added to the schedule, MR-BD (for \"Booster Development\"; it was originally known as MR-2A). This would launch on March 28, pushing the MR-3 flight back a month to April 25. The MR-BD flight was almost completely successful, ensuring that the manned MR-3 flight could proceed without further significant delay.\n\nThe pilot for MR-3 had been chosen several months in advance, in early January, by the head of the program, Robert R. Gilruth. He had selected Alan Shepard as the primary pilot, with John Glenn and Gus Grissom as his backups; the other members of the Mercury Seven continued to train for later missions. The three names were announced to the press on February 22 without any indication as to which of the three was expected to fly the mission. Shepard's name was only announced publicly after the initial launch attempt had been canceled, as Gilruth wished to keep his options open in the event that last-minute personnel changes were required. Glenn served as Shepard's backup on launch day, with Grissom focusing on training for MR-4, the next suborbital mission.\n\nThe initial launch attempt, on May 2, was canceled due to weather problems two hours and 20 minutes before the launch time, with Shepard waiting in a hangar already suited and prepared. The flight was rescheduled for two days later, when it was delayed one more day due to inclement weather conditions, until 5 May, with an expected launch time of 7:20 am. EST.\n\nThe countdown began at 8:30 p.m. the previous night, with Shepard waking up and eating a breakfast of steak and eggs with toast, coffee, and orange juice (the steak and eggs breakfast would soon become a tradition for astronauts the morning of a launch). He entered the spacecraft at 5:15 am. ET, just over two hours before the planned 7:20 launch time. At 7:05 am, the launch was held for an hour to let cloud cover clear – good visibility would be essential for photographs of the Earth – and fix a power supply unit; shortly after the count restarted, another hold was called in order to reboot a computer at Goddard Space Flight Center. The count was eventually resumed, after slightly over two and a half hours of unplanned holds, and continued with no further faults. All of the delays resulted in Shepard lying on his back in the capsule for almost three hours, by which point he complained to the blockhouse crew that he had a severe need to urinate (because the mission would last under 20 minutes, nobody had thought to equip the Mercury with a urine collection device). The crew told him that this was impossible as they'd have to set the White Room back up and waste considerable amounts of time removing the Mercury's heavily bolted hatch. An irate Shepard then announced that if he couldn't get out for a bathroom trip, he'd simply urinate in his suit. When the blockhouse protested that that would short out the medical electrodes on his body, he told them to simply turn the power off. They complied, and Shepard emptied his bladder. Because of the position he was sitting in, the urine pooled somewhat underneath his back and with oxygen flowing through the spacesuit, he was soon dried out, and the countdown resumed.\n\nMercury-Redstone 3 finally lifted off at 9:34 am. ET, watched by an estimated 45 million television viewers in the United States. Shepard was subjected to a maximum acceleration of 6.3g just before the Redstone engine shut down, two minutes and 22 seconds after launch. \"Freedom 7's\" space-fixed velocity was , close to the planned value. Ten seconds later, the escape tower was jettisoned. At the three-minute mark, the automated attitude control system rotated \"Freedom 7\" so the heat shield faced forward ready for re-entry.\n\nShepard was now able to take manual control of the spacecraft, and began testing whether he was able to adjust its orientation. The first thing he did was position the spacecraft to its retrofire attitude of 34 degrees pitch (nose of spacecraft pitched down 34 degrees). He then tested manual control of yaw, motion from left to right, and roll. When he took control of all three axes, he found that the spacecraft response was about the same as that of the Mercury simulator; however, he could not hear the jets firing, as he could on the ground, due to the levels of background noise.\n\nThe secondary objective was to make observations of the ground from the spacecraft; returning the spacecraft to automatic control, Shepard found that he was able to distinguish major land masses from clouds easily, and could make out coastlines, islands and major lakes, but had difficulty identifying cities. He had problems working with the spacecraft periscope – early Mercury capsules had a small periscope rather than a viewing window – and had to abandon an attempt to change optical filters on it after noticing that a pressure gauge on his wrist kept bumping the lever that would have activated the Launch Escape System. Although the escape tower was long gone and pressing on the lever probably wouldn't do anything, Shepard still didn't want to risk it in case something unexpected happened.\n\nUnder automatic control, the spacecraft had developed a slight movement as it passed through peak altitude; Shepard now switched into the \"fly-by-wire\" mode, where the pilot used a controller to order the automatic system to fire the rockets for the desired positioning, rather than manually controlling the individual jets. Adjusting roll and yaw, he found the pitch position was around ten degrees too shallow – 25 degrees rather than the desired 35 for reentry – and as he began to correct it, the timed retrorockets fired to send him into reentry. The retrorocket pack – strapped atop the heatshield and so requiring release before reentry – was successfully jettisoned, but the confirmation light failed, requiring Shepard to activate the manual override for the jettison system before it confirmed that the rockets were fully released.\n\nShepard resumed fly-by-wire control after retrofire, reporting that it felt smooth and gave the sensation of being fully in command of the craft, before letting the automatic systems briefly take over to reorient the capsule for reentry. He then kept control until the g-forces peaked at 11.6g during re-entry; he held the capsule until it had stabilized and then relinquished control to the automated system. The descent was faster than anticipated, but the parachutes deployed as planned, a drogue at and a main parachute at .\n\nSplashdown occurred with an impact comparable to landing a jet aircraft on an aircraft carrier. \"Freedom 7\" tilted over on its right side about 60 degrees from an upright position, but did not show any signs of leaking; it gently righted itself after a minute, and Shepard was able to report to the circling aircraft that he had landed safely and was ready to be recovered. A recovery helicopter arrived after a few minutes, and after a brief problem with the spacecraft antenna, the capsule was lifted partly out of the water in order to allow Shepard to leave by the main hatch. He squeezed out of the door and into a sling hoist, and was pulled into the helicopter, which flew both the astronaut and his spacecraft to a waiting aircraft carrier, . The whole recovery process had taken only eleven minutes, from splashdown to arriving aboard.\n\nThe flight lasted 15 minutes, 22 seconds and the spacecraft traveled from its launch point, ascending to . \"Freedom 7\" landed at these coordinates: . It reached a speed of .\n\nFollowing the flight the spacecraft was examined by engineers and found to be in excellent shape, so much so that they decided it could have been safely used again in another launch. Given to the Smithsonian Institution by NASA, \"Freedom 7\" was previously displayed at the U.S. Naval Academy in Annapolis, Maryland until 2012. Since 2012, it has been on display at the John F. Kennedy Library in Boston, Massachusetts.\n\nIn June 1961, Laurie Records issued a 45 rpm single featuring William Allen and Orchestra entitled \"Space Flight Freedom 7.\" It consisted of recreations of the tower to astronaut communications spoken over an instrumental backing.\nThe Mercury-Redstone 3 mission was dramatized in the HBO miniseries \"From the Earth to the Moon\" episode \"Can We Do This?\" (starring Ted Levine as Alan Shepard), as well as in Tom Wolfe's book \"The Right Stuff\", and Philip Kaufman's movie \"The Right Stuff\" based on the book. (In Kaufman's film, Scott Glenn plays Shepard.)\n\n\n\n"}
{"id": "163242", "url": "https://en.wikipedia.org/wiki?curid=163242", "title": "Mirror galvanometer", "text": "Mirror galvanometer\n\nA mirror galvanometer is an electromechanical instrument that indicates that it has sensed an electric current by deflecting a light beam with a mirror. The beam of light projected on a scale acts as a long massless pointer. In 1826, Johann Christian Poggendorff developed the mirror galvanometer for detecting electric currents. The apparatus is also known as a \"spot galvanometer\" after the spot of light produced in some models.\n\nMirror galvanometers were used extensively in scientific instruments before reliable, stable electronic amplifiers were available. The most common uses were as recording equipment for seismometers and submarine cables used for telegraphy.\n\nIn modern times, the term \"mirror galvanometer\" is also used for devices that move laser beams by rotating a mirror through a galvanometer set-up. The name is often abbreviated as \"galvo\".\n\nThe mirror galvanometer was later improved by William Thomson, later to become Lord Kelvin. He would patent the device in 1858.\n\nThomson reacted to the need for an instrument that could indicate with sensibility all the variations of the current in a long cable. This instrument was far more sensitive than any which preceded it, enabling the detection of the slightest defect in the core of a cable during its manufacture and submersion. Moreover, it proved the best apparatus for receiving messages through a long cable.\n\nThe following is adapted from a contemporary account of Thomson's instrument:\n\nMoving coil galvanometer was developed independently by Marcel Deprez and Jacques-Arsène d'Arsonval about 1880. Deprez's galvanometer was developed for high currents, while D'Arsonval designed his to measure weak currents. Unlike in the Kelvin's galvanometer, in this type of galvanometer the magnet is stationary and the coil is suspended in the magnet gap. The mirror attached to the coil frame rotates together with it. This form of instrument can be more sensitive and accurate and it replaced the Kelvin's galvanometer in most applications. The moving coil galvanometer is practically immune to ambient magnetic fields. Another important feature is self-damping generated by the electro-magnetic forces due to the currents induced in the coil by its movements the magnetic field. These are proportional to the angular velocity of the coil.\n\nIn modern times, high-speed mirror galvanometers are employed in laser light shows to move the laser beams and produce colorful geometric patterns in fog around the audience. Such high speed mirror galvanometers have proved to be indispensable in industry for laser marking systems for everything from laser etching hand tools, containers, and parts to batch-coding semiconductor wafers in semiconductor device fabrication. They typically control X and Y directions on and CO laser markers to control the position of the infrared power laser spot. Laser ablation, laser beam machining and wafer dicing are all industrial areas where high-speed mirror galvanometers can be found.\n\nThis moving coil galvanometer is mainly used to measure very feeble or low currents of order 10 A.\n\nTo linearise the magnetic field across the coil throughout the galvanometer's range of movement, the d'Arsonval design of a soft iron cylinder is placed inside the coil without touching it. This gives a consistent radial field, rather than a parallel linear field.\n\n\n"}
{"id": "32095347", "url": "https://en.wikipedia.org/wiki?curid=32095347", "title": "Reststrahlen effect", "text": "Reststrahlen effect\n\nThe reststrahlen effect (German: “residual rays”) is a reflectance phenomenon in which electromagnetic radiation within a narrow energy band cannot propagate within a given medium due to a change in refractive index concurrent with the specific absorbance band of the medium in question; this narrow energy band is termed the \"reststrahlen band\".\n\nAs a result of this inability to propagate, normally incident reststrahlen band radiation experiences strong-reflection or total-reflection from that medium.\n\nThe energies at which reststrahlen bands occur vary and are particular to the individual compound.\n\nNumerous physical attributes of a compound will have an effect on the appearance of the reststrahlen band. These include phonon band-gap, particle/grain size, strongly absorbing compounds, compounds with optically opaque bands in the infrared.\n\nReststrahlen bands manifest in diffuse reflectance infrared absorption spectra as complete band reversal, or in infrared emission spectra as a minimum in emissivity.\n\nThe reststrahlen effect is used to investigate the properties of semiconductors, it is also used in geophysics and meteorology. \n\n\n"}
{"id": "10681803", "url": "https://en.wikipedia.org/wiki?curid=10681803", "title": "Royal Society Wolfson Research Merit Award", "text": "Royal Society Wolfson Research Merit Award\n\nThe Royal Society Wolfson Research Merit Grant Award was a grant award originally announced in 2000. which has now been superseded by the Royal Society Wolfson Fellowships. \n\nIt was administered by the Royal Society and jointly funded by the Wolfson Foundation and the UK Office of Science and Technology, to give universities additional financial support to attract key researchers to this country or to retain those who might seek to gain higher salaries elsewhere.\" to tackle the brain drain. They were given in four annual rounds, with up to seven awards per round.\n\nWinners of this grant (see ) award included:\n"}
{"id": "196372", "url": "https://en.wikipedia.org/wiki?curid=196372", "title": "SimPy", "text": "SimPy\n\nSimPy is a process-based discrete-event simulation framework based on standard\nPython. Its event dispatcher is based on Python’s generators and can also\nbe used for asynchronous networking or to implement multi-agent systems (with\nboth, simulated and real communication).\n\nProcesses in SimPy are simple Python generator functions and are used to model\nactive components like customers, vehicles or agents. SimPy also provides\nvarious types of shared \"resources\" to model limited capacity congestion points\n(like servers, checkout counters and tunnels). From version 3.1, it will also\nprovide monitoring capabilities to aid in gathering statistics about resources\nand processes.\n\nSimulations can be performed “as fast as possible”, in real time (wall clock\ntime) or by manually stepping through the events.\n\nThough it is theoretically possible to do continuous simulations with SimPy, it\nhas no features to carry out that. However, SimPy is overkill\nfor simulations with a fixed step size where your processes don’t interact with\neach other or with shared resources — use a simple codice_1 loop in this case.\n\nThe SimPy distribution contains tutorials, in-depth documentation, and a large\nnumber of examples.\n\nSimPy is released as open source software under the MIT License. The first version was released in December 2002.\n\nOne of SimPy's main goals is to be easy to use. Here is an example for a simple SimPy simulation: a clock process that prints the current simulation time at each step:\n"}
{"id": "8774050", "url": "https://en.wikipedia.org/wiki?curid=8774050", "title": "Telecommunications engineering", "text": "Telecommunications engineering\n\nTelecommunications engineering is an engineering discipline centered on electrical and computer engineering which seeks to support and enhance telecommunication systems. The work ranges from basic circuit design to strategic mass developments. A telecommunication engineer is responsible for designing and overseeing the installation of telecommunications equipment and facilities, such as complex electronic switching systems, and other plain old telephone service facilities, optical fiber cabling, IP networks, and microwave transmission systems. Telecommunication engineering also overlaps with broadcast engineering.\n\nTelecommunication is a diverse field of engineering connected to electronic, civil and systems engineering. Ultimately, telecom engineers are responsible for providing high-speed data transmission services. They use a variety of equipment and transport media to design the telecom network infrastructure; the most common media used by wired telecommunications today are twisted pair, coaxial cables, and optical fibers. Telecommunications engineers also provide solutions revolving around wireless modes of communication and information transfer, such as wireless telephony services, radio and satellite communications, and internet and broadband technologies.\n\nTelecommunication systems are generally designed by telecommunication engineers which sprang from technological improvements in the telegraph industry in the late 19th century and the radio and the telephone industries in the early 20th century. Today, telecommunication is widespread and devices that assist the process, such as the television, radio and telephone, are common in many parts of the world. There are also many networks that connect these devices, including computer networks, public switched telephone network (PSTN), radio networks, and television networks. Computer communication across the Internet is one of many examples of telecommunication. Telecommunication plays a vital role in the world economy, and the telecommunication industry's revenue has been placed at just under 3% of the gross world product.\n\nSamuel Morse independently developed a version of the electrical telegraph that he unsuccessfully demonstrated on 2 September 1837. Soon after he was joined by Alfred Vail who developed the register — a telegraph terminal that integrated a logging device for recording messages to paper tape. This was demonstrated successfully over three miles (five kilometres) on 6 January 1838 and eventually over forty miles (sixty-four kilometres) between Washington, D.C. and Baltimore on 24 May 1844. The patented invention proved lucrative and by 1851 telegraph lines in the United States spanned over 20,000 miles (32,000 kilometres).\n\nThe first successful transatlantic telegraph cable was completed on 27 July 1866, allowing transatlantic telecommunication for the first time. Earlier transatlantic cables installed in 1857 and 1858 only operated for a few days or weeks before they failed. The international use of the telegraph has sometimes been dubbed the \"Victorian Internet\".\n\nThe first commercial telephone services were set up in 1878 and 1879 on both sides of the Atlantic in the cities of New Haven and London. Alexander Graham Bell held the master patent for the telephone that was needed for such services in both countries. The technology grew quickly from this point, with inter-city lines being built and telephone exchanges in every major city of the United States by the mid-1880s. Despite this, transatlantic voice communication remained impossible for customers until January 7, 1927 when a connection was established using radio. However no cable connection existed until TAT-1 was inaugurated on September 25, 1956 providing 36 telephone circuits.\n\nIn 1880, Bell and co-inventor Charles Sumner Tainter conducted the world's first wireless telephone call via modulated lightbeams projected by photophones. The scientific principles of their invention would not be utilized for several decades, when they were first deployed in military and fiber-optic communications.\n\nOver several years starting in 1894 the Italian inventor Guglielmo Marconi built the first complete, commercially successful wireless telegraphy system based on airborne electromagnetic waves (radio transmission). In December 1901, he would go on to established wireless communication between Britain and Newfoundland, earning him the Nobel Prize in physics in 1909 (which he shared with Karl Braun). In 1900 Reginald Fessenden was able to wirelessly transmit a human voice. On March 25, 1925, Scottish inventor John Logie Baird publicly demonstrated the transmission of moving silhouette pictures at the London department store Selfridges. In October 1925, Baird was successful in obtaining moving pictures with halftone shades, which were by most accounts the first true television pictures. This led to a public demonstration of the improved device on 26 January 1926 again at Selfridges. Baird's first devices relied upon the Nipkow disk and thus became known as the mechanical television. It formed the basis of semi-experimental broadcasts done by the British Broadcasting Corporation beginning September 30, 1929.\n\nThe first U.S. satellite to relay communications was Project SCORE in 1958, which used a tape recorder to store and forward voice messages. It was used to send a Christmas greeting to the world from U.S. President Dwight D. Eisenhower. In 1960 NASA launched an Echo satellite; the aluminized PET film balloon served as a passive reflector for radio communications. Courier 1B, built by Philco, also launched in 1960, was the world's first active repeater satellite. Satellites these days are used for many applications such as uses in GPS, television, internet and telephone uses.\n\nTelstar was the first active, direct relay commercial communications satellite. Belonging to AT&T as part of a multi-national agreement between AT&T, Bell Telephone Laboratories, NASA, the British General Post Office, and the French National PTT (Post Office) to develop satellite communications, it was launched by NASA from Cape Canaveral on July 10, 1962, the first privately sponsored space launch. Relay 1 was launched on December 13, 1962, and became the first satellite to broadcast across the Pacific on November 22, 1963.\n\nThe first and historically most important application for communication satellites was in intercontinental long distance telephony. The fixed Public Switched Telephone Network relays telephone calls from land line telephones to an earth station, where they are then transmitted a receiving satellite dish via a geostationary satellite in Earth orbit. Improvements in submarine communications cables, through the use of fiber-optics, caused some decline in the use of satellites for fixed telephony in the late 20th century, but they still exclusively service remote islands such as Ascension Island, Saint Helena, Diego Garcia, and Easter Island, where no submarine cables are in service. There are also some continents and some regions of countries where landline telecommunications are rare to nonexistent, for example Antarctica, plus large regions of Australia, South America, Africa, Northern Canada, China, Russia and Greenland.\n\nAfter commercial long distance telephone service was established via communication satellites, a host of other commercial telecommunications were also adapted to similar satellites starting in 1979, including mobile satellite phones, satellite radio, satellite television and satellite Internet access. The earliest adaption for most such services occurred in the 1990s as the pricing for commercial satellite transponder channels continued to drop significantly.\n\nOn 11 September 1940, George Stibitz was able to transmit problems using teleprinter to his Complex Number Calculator in New York and receive the computed results back at Dartmouth College in New Hampshire. This configuration of a centralized computer or mainframe computer with remote \"dumb terminals\" remained popular throughout the 1950s and into the 1960s. However, it was not until the 1960s that researchers started to investigate packet switching — a technology that allows chunks of data to be sent between different computers without first passing through a centralized mainframe. A four-node network emerged on 5 December 1969. This network soon became the ARPANET, which by 1981 would consist of 213 nodes.\n\nARPANET's development centered around the Request for Comment process and on 7 April 1969, RFC 1 was published. This process is important because ARPANET would eventually merge with other networks to form the Internet, and many of the communication protocols that the Internet relies upon today were specified through the Request for Comment process. In September 1981, RFC 791 introduced the Internet Protocol version 4 (IPv4) and RFC 793 introduced the Transmission Control Protocol (TCP) — thus creating the TCP/IP protocol that much of the Internet relies upon today.\n\nOptical fiber can be used as a medium for telecommunication and computer networking because it is flexible and can be bundled into cables. It is especially advantageous for long-distance communications, because light propagates through the fiber with little attenuation compared to electrical cables. This allows long distances to be spanned with few repeaters.\n\nIn 1966 Charles K. Kao and George Hockham proposed optical fibers at STC Laboratories (STL) at Harlow, England, when they showed that the losses of 1000 dB/km in existing glass (compared to 5-10 dB/km in coaxial cable) was due to contaminants, which could potentially be removed.\n\nOptical fiber was successfully developed in 1970 by Corning Glass Works, with attenuation low enough for communication purposes (about 20dB/km), and at the same time GaAs (Gallium arsenide) semiconductor lasers were developed that were compact and therefore suitable for transmitting light through fiber optic cables for long distances.\n\nAfter a period of research starting from 1975, the first commercial fiber-optic communications system was developed, which operated at a wavelength around 0.8 µm and used GaAs semiconductor lasers. This first-generation system operated at a bit rate of 45 Mbps with repeater spacing of up to 10 km. Soon on 22 April 1977, General Telephone and Electronics sent the first live telephone traffic through fiber optics at a 6 Mbit/s throughput in Long Beach, California.\n\nThe first wide area network fibre optic cable system in the world seems to have been installed by Rediffusion in Hastings, East Sussex, UK in 1978. The cables were placed in ducting throughout the town, and had over 1000 subscribers. They were used at that time for the transmission of television channels,not available because of local reception problems.\n\nThe first transatlantic telephone cable to use optical fiber was TAT-8, based on Desurvire optimized laser amplification technology. It went into operation in 1988.\n\nIn the late 1990s through 2000, industry promoters, and research companies such as KMI, and RHK predicted massive increases in demand for communications bandwidth due to increased use of the Internet, and commercialization of various bandwidth-intensive consumer services, such as video on demand. Internet protocol data traffic was increasing exponentially, at a faster rate than integrated circuit complexity had increased under Moore's Law.\n\nTransmitter (information source) that takes information and converts it to a signal for transmission. In electronics and telecommunications a transmitter or radio transmitter is an electronic device which, with the aid of an antenna, produces radio waves. In addition to their use in broadcasting, transmitters are necessary component parts of many electronic devices that communicate by radio, such as cell phones, \n\nTransmission medium over which the signal is transmitted. For example, the transmission medium for sounds is usually air, but solids and liquids may also act as transmission media for sound. Many transmission media are used as communications channel. One of the most common physical medias used in networking is copper wire. Copper wire to carry signals to long distances using relatively low amounts of power.Another example of a physical medium is optical fiber, which has emerged as the most commonly used transmission medium for long-distance communications. Optical fiber is a thin strand of glass that guides light along its length.\n\nThe absence of a material medium in vacuum may also constitute a transmission medium for electromagnetic waves such as light and radio waves.\n\nReceiver (information sink) that receives and converts the signal back into required information. In radio communications, a radio receiver is an electronic device that receives radio waves and converts the information carried by them to a usable form. It is used with an antenna. The information produced by the receiver may be in the form of sound (an audio signal), images (a video signal) or digital data.\n\nWired communications make use of underground communications cables (less often, overhead lines), electronic signal amplifiers (repeaters) inserted into connecting cables at specified points, and terminal apparatus of various types, depending on the type of wired communications used.\n\nWireless communication involves the transmission of information over a distance without help of wires, cables or any other forms of electrical conductors. Wireless operations permit services, such as long-range communications, that are impossible or impractical to implement with the use of wires. The term is commonly used in the telecommunications industry to refer to telecommunications systems (e.g. radio transmitters and receivers, remote controls etc.) which use some form of energy (e.g. radio waves, acoustic energy, etc.) to transfer information without the use of wires. Information is transferred in this manner over both short and long distances.\n\nA telecom equipment engineer is an electronics engineer that designs equipment such as routers, switches, multiplexers, and other specialized computer/electronics equipment designed to be used in the telecommunication network infrastructure.\n\nA network engineer is a computer engineer who is in charge of designing, deploying and maintaining computer networks. In addition, they oversee network operations from a network operations center, designs backbone infrastructure, or supervises interconnections in a data center.\n\nA central-office engineer is responsible for designing and overseeing the implementation of telecommunications equipment in a central office (CO for short), also referred to as a wire center or telephone exchange A CO engineer is responsible for integrating new technology into the existing network, assigning the equipment's location in the wire center, and providing power, clocking (for digital equipment), and alarm monitoring facilities for the new equipment. The CO engineer is also responsible for providing more power, clocking, and alarm monitoring facilities if there are currently not enough available to support the new equipment being installed. Finally, the CO engineer is responsible for designing how the massive amounts of cable will be distributed to various equipment and wiring frames throughout the wire center and overseeing the installation and turn up of all new equipment.\n\nAs structural engineers, CO engineers are responsible for the structural design and placement of racking and bays for the equipment to be installed in as well as for the plant to be placed on.\n\nAs electrical engineers, CO engineers are responsible for the resistance, capacitance, and inductance (RCL) design of all new plant to ensure telephone service is clear and crisp and data service is clean as well as reliable. Attenuation or gradual loss in intensity and loop loss calculations are required to determine cable length and size required to provide the service called for. In addition, power requirements have to be calculated and provided to power any electronic equipment being placed in the wire center.\n\nOverall, CO engineers have seen new challenges emerging in the CO environment. With the advent of Data Centers, Internet Protocol (IP) facilities, cellular radio sites, and other emerging-technology equipment environments within telecommunication networks, it is important that a consistent set of established practices or requirements be implemented.\n\nInstallation suppliers or their sub-contractors are expected to provide requirements with their products, features, or services. These services might be associated with the installation of new or expanded equipment, as well as the removal of existing equipment.\n\nSeveral other factors must be considered such as:\n\nOutside plant (OSP) engineers are also often called field engineers because they frequently spend much time in the field taking notes about the civil environment, aerial, above ground, and below ground. OSP engineers are responsible for taking plant (copper, fiber, etc.) from a wire center to a distribution point or destination point directly. If a distribution point design is used, then a cross-connect box is placed in a strategic location to feed a determined distribution area.\n\nThe cross-connect box, also known as a serving area interface, is then installed to allow connections to be made more easily from the wire center to the destination point and ties up fewer facilities by not having dedication facilities from the wire center to every destination point. The plant is then taken directly to its destination point or to another small closure called a terminal, where access can also be gained to the plant if necessary. These access points are preferred as they allow faster repair times for customers and save telephone operating companies large amounts of money.\n\nThe plant facilities can be delivered via underground facilities, either direct buried or through conduit or in some cases laid under water, via aerial facilities such as telephone or power poles, or via microwave radio signals for long distances where either of the other two methods is too costly.\n\nAs structural engineers, OSP engineers are responsible for the structural design and placement of cellular towers and telephone poles as well as calculating pole capabilities of existing telephone or power poles onto which new plant is being added. Structural calculations are required when boring under heavy traffic areas such as highways or when attaching to other structures such as bridges. Shoring also has to be taken into consideration for larger trenches or pits. Conduit structures often include encasements of slurry that needs to be designed to support the structure and withstand the environment around it (soil type, high traffic areas, etc.).\n\nAs electrical engineers, OSP engineers are responsible for the resistance, capacitance, and inductance (RCL) design of all new plant to ensure telephone service is clear and crisp and data service is clean as well as reliable. Attenuation or gradual loss in intensity and loop loss calculations are required to determine cable length and size required to provide the service called for. In addition power requirements have to be calculated and provided to power any electronic equipment being placed in the field. Ground potential has to be taken into consideration when placing equipment, facilities, and plant in the field to account for lightning strikes, high voltage intercept from improperly grounded or broken power company facilities, and from various sources of electromagnetic interference.\n\nAs civil engineers, OSP engineers are responsible for drafting plans, either by hand or using Computer-aided design (CAD) software, for how telecom plant facilities will be placed. Often when working with municipalities trenching or boring permits are required and drawings must be made for these. Often these drawings include about 70% or so of the detailed information required to pave a road or add a turn lane to an existing street. Structural calculations are required when boring under heavy traffic areas such as highways or when attaching to other structures such as bridges. As civil engineers, telecom engineers provide the modern communications backbone for all technological communications distributed throughout civilizations today.\n\nUnique to telecom engineering is the use of air-core cable which requires an extensive network of air handling equipment such as compressors, manifolds, regulators and hundreds of miles of air pipe per system that connects to pressurized splice cases all designed to pressurize this special form of copper cable to keep moisture out and provide a clean signal to the customer.\n\nAs political and social ambassador, the OSP engineer is a telephone operating company's face and voice to the local authorities and other utilities. OSP engineers often meet with municipalities, construction companies and other utility companies to address their concerns and educate them about how the telephone utility works and operates. Additionally, the OSP engineer has to secure real estate to place outside facilities on, such as an easement to place a cross-connect box on.\n"}
{"id": "24697292", "url": "https://en.wikipedia.org/wiki?curid=24697292", "title": "Tesla valve", "text": "Tesla valve\n\nA Tesla valve, called by Tesla a valvular conduit, is a fixed-geometry passive check valve. It allows a fluid to flow preferentially in one direction, without moving parts. The device is named after Nikola Tesla, who was awarded a patent in 1920 for its invention. The patent application describes the invention as follows:\n\nThe interior of the conduit is provided with enlargements, recesses, projections, baffles, or buckets which, while offering virtually no resistance to the passage of the fluid in one direction, other than surface friction, constitute an almost impassable barrier to its flow in the opposite [direction].\n\nTesla illustrates this with the drawing, showing one possible construction with a series of eleven flow-control segments, although any other number of such segments could be used as desired to increase or decrease the flow regulation effect.\n\nOne computational fluid dynamics simulation of Tesla valves with 2 and 4 segments showed that the flow resistance in the blocking (or reverse) direction was respectively about 15 and 40 times greater than the unimpeded (or forward) direction. This lends support to Tesla's patent assertion that in the valvular conduit in his diagram, a pressure ratio \"approximating 200 can be obtained so that the device acts as a slightly leaking valve\".\n\nThe Tesla valve is used in microfluidic applications and offers advantages such as scalability, durability, and ease of fabrication in a variety of materials.\n\nThe valves are structures that have a higher pressure drop for the flow in one direction (reverse) than the other (forward). This difference in flow resistance causes a net directional flow rate in the forward direction in oscillating flows. The efficiency is often expressed in diodicity formula_1, being the ratio of pressure drops for identical flow rates:\nwhere formula_3 is the reverse flow pressure drop, and formula_4 the forward flow pressure drop for flow rate formula_5.\n\n"}
{"id": "58013819", "url": "https://en.wikipedia.org/wiki?curid=58013819", "title": "The Oxford Textbook of Clinical Research Ethics", "text": "The Oxford Textbook of Clinical Research Ethics\n\nThe Oxford Textbook of Clinical Research Ethics is a textbook on clinical research ethics edited by Ezekiel Emanuel, Christine Grady, Robert A. Crouch, Reidar Lie, Franklin G. Miller and David Wendler.\n"}
{"id": "11108915", "url": "https://en.wikipedia.org/wiki?curid=11108915", "title": "Three-sector model", "text": "Three-sector model\n\nThe three-sector model in economics divides economies into three sectors of activity: extraction of raw materials (primary), manufacturing (secondary), and services (tertiary). It was developed by Allan Fisher, Colin Clark and Jean Fourastié.\n\nAccording to the model, the main focus of an economy's activity shifts from the primary, through the secondary and finally to the tertiary sector. Fourastié saw the process as essentially positive, and in \"The Great Hope of the Twentieth Century\" he wrote of the increase in quality of life, social security, blossoming of education and culture, higher level of qualifications, humanisation of work, and avoidance of unemployment.\n\nCountries with a low per capita income are in an early state of development; the main part of their national income is achieved through production in the primary sector. Countries in a more advanced state of development, with a medium national income, generate their income mostly in the secondary sector. In highly developed countries with a high income, the tertiary sector dominates the total output of the economy.\n\nThe distribution of the workforce among the three sectors progresses through different stages as follows, according to Fourastié:\n\nWorkforce quotas:\nThis phase represents a society which is scientifically not yet very developed, with a negligible use of machinery. The state of development corresponds to that of European countries in the early Middle Ages, or that of a modern-day developing country.\n\nWorkforce quotas:\n\nMore machinery is deployed in the primary sector, which reduces the number of workers needed. As a result, the demand for machinery production in the secondary sector increases. The transitional way or phase begins with an event which can be identified with the industrialisation: far-reaching mechanisation (and therefore automation) of manufacture, such as the use of conveyor belts.\n\nThe tertiary sector begins to develop, as do the financial sector and the power of the state.\n\nWorkforce quotas:\n\nThe primary and secondary sectors are increasingly dominated by automation, and the demand for workforce numbers falls in these sectors. It is replaced by the growing demands of the tertiary sector. The situation now corresponds to modern-day industrial societies and the society of the future, the service or post-industrial society. Today the tertiary sector has grown to such an enormous size that it is sometimes further divided into an information-based quaternary sector, and even a quinary sector based on human services.\n\n\n"}
{"id": "8278672", "url": "https://en.wikipedia.org/wiki?curid=8278672", "title": "Three Roads to Quantum Gravity", "text": "Three Roads to Quantum Gravity\n\nThree Roads to Quantum Gravity: A New Understanding of Space, Time and the Universe is the second non-fiction book by American theoretical physicist Lee Smolin. The book was initially published on May 30, 2001 by Basic Books as a part of \"Science Masters\" series.\n\nSmolin discusses three potential approaches by which a unified theory of quantum gravity, arguably the foremost issue in theoretical physics, may be realized. Approaches discussed include string theory, M-theory, and Smolin's preferred approach, loop quantum gravity. Smolin suggests that these approaches may be approximations of a single, underlying theory.\n\n—\"The Guardian\"\n\n"}
{"id": "23874740", "url": "https://en.wikipedia.org/wiki?curid=23874740", "title": "Tobii Technology", "text": "Tobii Technology\n\nTobii (formerly known as Tobii Technology AB) is a Swedish high-technology company that develops and sells products for eye control and eye tracking.\n\nJohn Elvesjo, Mårten Skogö and Henrik Eskilsson founded the company in 2001. All three founders play an active role in the company: Henrik Eskilsson is the CEO, John Elvesjö is vice president and CTO, and Mårten Skogö is Chief Science Officer. The Tobii Group consists of three business units: Tobii Dynavox from an acquisition of US based DynaVox, Tobii Pro, and Tobii Tech. Tobii is based in Stockholm, Sweden, with offices in the US, Japan, China, Germany, Norway and Ukraine. Tobii became publicly traded on April 22, 2015, trading on the Stockholm Stock Exchange.\n\nIn 2007, the company got $14 million in venture capital from Investor Growth Capital. In May 2009, Investor, Amadeus Capital Partners and Northzone Ventures invested an additional $16 million, and at the start of 2012, Intel Capital invested $21 million.\n\nIn 2008, Tobii won the Swedish Grand Award of Design together with the design company Myra Industriell Design, for the technology and design in their eye controlled screens. In 2010, Tobii won the SIME Grand Prize for having the most innovative technology concept. In 2011, Tobii Glasses won the red dot design award, an international product design competition and later the same year, Tobii won the Bully Award. In 2012, Tobii took home the award for best prototype at the consumer technology tradeshow 2012 CES and Laptop Magazine named Tobii the winner in its best new technology category.\n\nTobii's products are sold directly and through resellers and partners worldwide. People with communication disabilities use Tobii Dynavox’s technical devices and language tools (AAC devices) to communicate. Due to their high cost, they are often the goal of charity drives.\n\nTobii Pro has products that are widely used for research in the academic community, and to conduct usability studies and market surveys of commercial products. \nTobii Tech is the business unit that partners with others to integrate eye tracking and eye control in different industry applications and fields such as advanced driver assistance, consumer computing and gaming.\n\nAt the Consumer Electronics Show 2012, they demonstrated the Tobii Gaze, an infrared light based eye tracking device that makes it possible for users to use their eyes to point and interact with a standard computer.\n\nIn 2014, Tobii partnered with Danish SteelSeries and launched their first eye tracking system for consumers: the Tobii EyeX and the SteelSeries Sentry Eye Tracker. Several video games from major publishers were released in 2015-16 with support for Tobii's consumer devices, with varying levels of success.\n"}
{"id": "2250971", "url": "https://en.wikipedia.org/wiki?curid=2250971", "title": "Toussaint de Charpentier", "text": "Toussaint de Charpentier\n\nToussaint de Charpentier (22 November 1779 – 4 March 1847) was a German geologist and entomologist.\n\nHe was the author of \"Libellulinae europaeae descriptae e depictae\" (1840).\n\nToussaint de Charpentier was born in Freiberg, Saxony ( 22 November 1779 and died in Brieg 4 March 1847. \nCharpentier was the son of the Saxony geologist and \"Berghauptmann\" (head of the mining inspectorate), Johann Friedrich William von Charpentier and the brother of Johann von Charpentier. He studied geology and mining engineering at the Bergakademie Freiberg and continued his studies at the University of Leipzig.\n\nIn the year 1802 Charpentier went to Prussia, where he accepted a place with the Silesia Oberbergamt (upper mining authority) in Breslau. Charpentier took over the management of Schweidnitz local mining authority in Schweidnitz until returning, in 1811, to the upper mining authority in Breslau.\n\nIn 1828 his transfer to Dortmund as \"Vizeberghauptmann\" took place. 1830 he was appointed to a post in \"Oberbergamtes\" Dortmund. In the year 1836 he transferred to the Silesian mining authority in the same capacity. After 1819 he was transferred to Brieg and remained there up to his death in the same office.\n\nCharpentier published numerous writings on mountain structure and geology, in addition, to writing on his hobby, entomology. He published between 1829 and 1830 a new edition of the publications \"Die europäischen Schmetterlinge\" and \"Die ausländischen Schmetterlinge\" with Eugenius Johann Christoph Esper.\n\n"}
{"id": "44891350", "url": "https://en.wikipedia.org/wiki?curid=44891350", "title": "Ulbo de Sitter (sociologist)", "text": "Ulbo de Sitter (sociologist)\n\nLamoraal Ulbo de Sitter (April 2, 1930 – December 18, 2010) was a Dutch sociologist and Professor of business administration at the Radboud University Nijmegen, known for his seminal work in the field of sociotechnical system in the Netherlands.\n\nBorn in Jönköping, Sweden, Ulbo de Sitter was named after his father Ulbo de Sitter (1902–1980), a geologist working at the Leiden University. He studied sociology at the University of Amsterdam, and obtained his PhD in 1970 at the University of Leiden with the thesis, entitled \"Leiderschapsvorming en leiderschapsgedrag in een organisatie\" (Leadership formation and leadership behavior in an organization).\n\nDe Sitter had started working as engineer in the merchant navy for four years before he started his studies in Amsterdam. After graduation in Amsterdam he worked as sociologist at the head office of the Koninklijke PTT Nederland, nowadays KPN. Sequentially he was research assistant at the Sociografische Werkgemeenschap (Socio Graphic Work Association) of the University of Amsterdam. In 1971 he was appointed professor at Eindhoven University of Technology. From 1986 to 1988 he was also director of the Koers consulting group in 's-Hertogenbosch. In 1990 he was appointed Professor of Sociotechnical System at the University of Nijmegen, where he retired March 31, 1995.\n\nDe Sitter is best known for introducing the sociotechnical system approach in the Netherlands. This approach involves redesign of organization and change management theory, which was initially developed at the British Tavistock Institute in the late 1950s. De Sitter combined in his work the systems theory fundamentals of the Delft Systems Approach, developed by Jan in 't Veld and Pierre Malotaux. With scientists as Björn Gustavsen, Fred Emery, Eric Trist, De Sitter is considered among the foremost social systems scientists in their field.\n\nBenders et al. (2010) recalled the development of socio-technical systems design since its initiation at the British coal mines in the late 1940s, and the development of Modern Socio-technology (MST) by De Sitter and others:\n\nAnd furthermore specifically about Modern Socio-technology (MST):\n\n\nArticles, a selection:\n"}
{"id": "53974986", "url": "https://en.wikipedia.org/wiki?curid=53974986", "title": "Vader (crater)", "text": "Vader (crater)\n\nVader is the unofficial name given to a dark crater on Pluto's largest moon Charon. The crater was discovered by NASA's \"New Horizons\" space probe on its way by Pluto. It was named after Darth Vader from the \"Star Wars\" media franchise.\n\n"}
{"id": "1415813", "url": "https://en.wikipedia.org/wiki?curid=1415813", "title": "Wider than the Sky", "text": "Wider than the Sky\n\nWider than the Sky: The Phenomenal Gift of Consciousness is an English-language book on neuroscience by the neuroscientist Gerald M. Edelman. Yale University Press published the book in 2004 . The book includes a glossary, a bibliographic note, and an index. The title alludes to an English-language poem written by Emily Dickinson in about 1862 . In that poem, Dickinson describes the brain as \"wider than the Sky\", \"deeper than the sea\", and \"just the weight of God\".\n\nIn the preface (page xiii), Edelman describes, as follows, the purpose of the book.\n\nThe book's content is similar to another one Edelman co-authored: \"A Universe of Consciousness: How Matter Becomes Imagination\". Both books put forward the theory of neuronal group selection, also known as Neural Darwinism. Both books make a distinction between primary consciousness and higher-order consciousness.\n\n"}
