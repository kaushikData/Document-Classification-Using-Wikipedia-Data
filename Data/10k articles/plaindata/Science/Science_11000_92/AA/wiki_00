{"id": "28836805", "url": "https://en.wikipedia.org/wiki?curid=28836805", "title": "Bronnant Fault", "text": "Bronnant Fault\n\nBronnant Fault is a geological fault in Wales.\n\n"}
{"id": "18162840", "url": "https://en.wikipedia.org/wiki?curid=18162840", "title": "CLAS detector", "text": "CLAS detector\n\nCEBAF Large Acceptance Spectrometer (CLAS) is a nuclear and particle physics detector located in the experimental Hall B at Jefferson Laboratory in Newport News, Virginia, United States. It is used to study the properties of the nuclear matter by the collaboration of over 200 physicists (CLAS Collaboration) from many countries all around the world.\n\nThe 0.5 to 12.0 GeV electron beam from the accelerator of Jefferson Laboratory is brought into \"Hall B\", the experimental hall that houses the CLAS system. Electrons or photons in the incoming beam collide with the nuclei of atoms in the physics \"target\" located at the center of CLAS. These collisions generally produce new particles, often after the target nucleons (protons and neutrons) are briefly excited to heavier-mass versions of the familiar protons and neutrons. A whole variety of intermediate-mass short-lived particles called \"mesons\" can be created. Scattered electron as well as the longer-lived produced particles travel through the CLAS detector, where they are measured. Particle physicists use these measurements to deduce the underlying structure of protons and neutrons and to better understand the interactions that create these new particles.\n\nThe CLAS detector system was operational from 1998 until May 2012. From that time onward, analysis of archived data continued for some years, as can be traced in the publications. Since 2012, a similar but new system called CLAS12 was constructed, which began operations with particle beams in 2017.\n\nThe CLAS detector was notable among devices in the area of hadronic particle physics in that it had a very large acceptance; in other words, it measured the momentum and angles of almost all of the particles produced in the electron-proton collisions. Roughly spherical, the detector measured 30 feet across. It surrounded the physics target, which was typically a small cylinder of liquid hydrogen (hydrogen's nucleus is composed of a single proton) or deuterium (with a nucleus consisting of a neutron and a proton).\n\nEach particle-target collision is called an \"event\". An elaborate data acquisition system records each event measured by the particle detectors, up to several thousand events per second on average. This data is then transferred to a \"farm\" of computing processors. Teams of physicists analyze the events, looking for new kinds of particles or information related to the underlying structure of the proton.\n\nA diagram of the CLAS detector is shown in the Figure, as well as a photograph of the detector when it was partially pulled open for maintenance. The physics target is at the center. Charged particles are detected in almost all directions, excluding the very forward (beam) and backward (beam) directions, and also excluding azimuthal directions occupied by six toroidal magnetic field coils.\nThe detector was designed in a nested form, with successive layers of particle detectors to either track particle paths or record particle flight-times. The toroidal magnet field causes charged particle from the target to bend in arcs either toward or away from the beam line. Particles leaving the target first pass through a timing counter to register the beginning of their trajectories. The particles then traverse three packages of drift chambers which are used to track their paths though the magnetic field, and thereby allow determination of their momentum.\n\nOutside the magnetic field, a layer of timing detectors measure the time of passage of the particles at a distance of about four meters from the target. Dividing the path length of a particle track by the time of travel gives the speed. Knowing the momentum and speed of a particle leads to its identification via its mass. The CLAS detector also contains additional detectors in the forward direction (Cherenkov counters and Electromagnetic Calorimeters) whose purpose is to distinguish electrons from other types of particles such as pions.\n\nTwo categories of experiments were carried out with CLAS: using electrons in the beam and using so-called real photons created using the electron beam. Experiments using electron scattering primarily probe the structure of protons and their excitations at various sub-nuclear \"length scales\". Experiments using real photon beams primarily probe the production and decay of mesons and excited baryons.\n\nA list of the scientific and technical papers resulting from the CLAS program is linked at the bottom of this article. The range of questions addressed is broad, as seen in the following list of topics given in no particular order:\n\n\n\n\n"}
{"id": "49669587", "url": "https://en.wikipedia.org/wiki?curid=49669587", "title": "Capitalism Nature Socialism", "text": "Capitalism Nature Socialism\n\nCapitalism Nature Socialism is an academic journal founded by James O'Connor and Barbara Laurence. It is published by Taylor and Francis. It publishes articles on political ecology, with an ecosocialist perspective.\n"}
{"id": "1373051", "url": "https://en.wikipedia.org/wiki?curid=1373051", "title": "Catkin", "text": "Catkin\n\nA catkin or ament is a slim, cylindrical flower cluster (a spike), with inconspicuous or no petals, usually wind-pollinated (anemophilous) but sometimes insect-pollinated (as in \"Salix\"). They contain many, usually unisexual flowers, arranged closely along a central stem which is often drooping. They are found in many plant families, including Betulaceae, Fagaceae, Moraceae, and Salicaceae. For some time, they were believed to be a key synapomorphy among the proposed Hamamelididae, also known as Amentiferae (\"i.e.\", literally plants \"bearing aments\"). Based on molecular phylogeny work, it is now believed that Hamamelididae is a polyphyletic group. This suggests that the catkin flower arrangement has arisen at least twice independently by convergent evolution, in Fagales and in Salicaceae. Such a convergent evolution raises questions about what the ancestral inflorescence characters might be and how catkins did evolve in these two lineages.\n\nIn many of these plants, only the male flowers form catkins, and the female flowers are single (hazel, oak), a cone (alder) or other types (mulberry). In other plants (such as poplar) both male and female flowers are borne in catkins.\n\nCatkin-bearing plants include many other trees or shrubs such as birch, willow, hickory, sweet chestnut and sweetfern (\"Comptonia\").\n\nThe word \"catkin\" is a loanword from the old Dutch \"katteken\", meaning \"kitten\", on account of the resemblance to a kitten's tail. \"Ament\" is from the Latin \"amentum\", meaning \"thong\" or \"strap\".\n\nIn Britain, they can be seen in January or February, when many trees are bare for winter. They can even occur in December. \n"}
{"id": "16145231", "url": "https://en.wikipedia.org/wiki?curid=16145231", "title": "Christopher Henn-Collins", "text": "Christopher Henn-Collins\n\nLieutenant-Colonel C A Henn-Collins, CEng, FIEE, FIERE served in the Second World War, notably, in the Polish Campaign under General Carton de Wiart. After the war Henn-Collins was a prolific inventor, including the first transistorised quartz clock.\n\nBorn in 1915, Christopher Henn-Collins was the third son of Lieutenant-Colonel the Hon. Richard Henn Collins, CMG, DSO, and grandson of Lord Collins, Master of the Rolls from 1901 to 1907. He was educated at Shrewsbury, and destined for a military career in his father's regiment, but pleaded to be allowed to pursue his boyhood ambition to be a telecommunications engineer. In 1934 he enlisted as a Gentleman Cadet at the Royal Military Academy at Woolwich for signals training and was commissioned in 1935.\n\n\"Main article Invasion of Poland (1939)\"\nAfter service in Palestine he earned the dubious distinction of being possibly the first serving officer to come under enemy fire in the first few hours of the second World War. In August 1939, when he was Brigade Signals Officer to the 1st Brigade of Guards, he had been ordered to lead a detachment of signallers and their equipment into Poland, as part of a British Military Mission under the command of the battle-scarred veteran General Carton de Wiart, VC, blinded in one eye and with an artificial hand. Their objective was to set up radio communications between Mission HQ in Warsaw, the UK and units of the Polish army. They were to travel in plain clothes, but with battle-dress in their kit, and six tons of equipment, through France to Marseilles, where HMS Shropshire would take them to Alexandria. There they were issued with passports and fictitious occupations, before trans-shipping to a ferry en route to Turkey, by which time Britain and France were at war with Germany. From there they travelled by rail through Romania, setting up radio communications along the way.\n\nBy the time they crossed the Polish frontier southeast of Warsaw, German armoured divisions were driving east towards the capital, and their reconnaissance planes were taking an interest in this strange convoy, which was now in a war zone. The detachment was ordered to change into uniform. In Lvov they were under heavy fire from low-flying aircraft: they could not move forward, nor could they stay put, risking further attentions from the Luftwaffe. For several nights they shuttled to and fro a few miles west to east and back again, awaiting instructions, and it was not until 8 September when they rendezvoused with General de Wiart, who had moved his headquarters from Warsaw to Tarnopol, that their mission was abandoned. They were ordered to destroy their equipment, and make their way home in twos and threes as best they could. Back in Alexandria Henn-Collins's instructions were to return to London where he was posted to Staff College at Camberley, and wrote a critical report on the lessons to be learned from this expedition.\n\nAlthough the mission was aborted, the outcome would have been quite different if the Russians had not invaded. The Poles had plans to conduct a guerrilla war in the east, and a British Signals unit behind the lines would have been of considerable use to the Allies.\n\nFor Henn-Collins various postings during the next three years included a period in the Directorate of Military Training, and promotion to Major. And then, with the rank of Lieutenant-Colonel, to Allied Forces Headquarters in Algiers as Officer in Charge of Radio Section, to set up links throughout the North African Theatre.\n\nHe was a resourceful, inventive and practical engineer. He patented an enciphering and deciphering machine, assigned to the Ministry of Supply with no financial benefit to himself; and he had so many ideas for civilian projects which could not be exploited within the service that he resigned his commission in 1947 in order to set up as a consulting engineer.\n\nPartly as a result of his wartime contacts, his company, Henn-Collins Associates, undertook a wide range of projects for government agencies and commercial organisations worldwide, mostly in the field of telecommunications, but he had other interests as well, and in the 1950s and 60s he patented a number of devices of an electro-mechanical nature. In his workshop he developed his idea for a quartz crystal clock which by using transistors in place of thermionic valves, made possible a much smaller quartz clock than was previously feasible. He described his \"mantelpiece\" clock in the \"British Horological Journal\" in 1957 and showed it at an exhibition in Goldsmiths' Hall in 1958, \"The Pendulum to the Atom\", which was opened by the Duke of Edinburgh. Christopher Henn-Collins and Dr Louis Essen, inventor of the caesium clock were presented to him.\n\nBefore he retired to Guernsey in 1970 he represented the Institution of Electrical Engineers and the Institution of Electrical and Radio Engineers on a British Standards Institution committee which produced a Code of Practice for the reception of sound and television broadcasting. He returned to England three years before his death.\n\nHe married first Patricia Hooper, who died in 1974, and in 1976 he married Andora de Quehen who survives him.\n\n\n"}
{"id": "1418331", "url": "https://en.wikipedia.org/wiki?curid=1418331", "title": "Deferribacteraceae", "text": "Deferribacteraceae\n\nThe Deferribacteraceae are a family of gram-negative bacteria which make energy by anaerobic respiration.\n\n\"Deferribacteraceae\" are rod-shaped, although the rods may be straight or bent. They are gram-negative. \"Deferribacteraceae\" all perform anaerobic respiration using iron, manganese, or nitrate. They can also produce energy by fermentation. The type genus of the family is \"Deferribacter\".\n\nThe currently accepted taxonomy is based on the List of Prokaryotic names with Standing in Nomenclature (LSPN) \n\nThe family was first described in 2001 in order to hold the genera \"Deferribacter\", \"Flexistipes\", and \"Geovibrio\".\n"}
{"id": "46529795", "url": "https://en.wikipedia.org/wiki?curid=46529795", "title": "Denise L. Herzing", "text": "Denise L. Herzing\n\nDenise L. Herzing is the founder and Research Director of the Wild Dolphin Project, a non-profit which funds the study of the natural behaviors and communication of Atlantic spotted dolphins in the wild.\n\nHerzing has earned her Ph. D. in Behavioral Biology/Environmental Studies, her M. A. in Behavioral Biology, and her B. S. in Marine Zoology\n\nHer ultimate aim is to achieve two-way communication with dolphins. She hopes to use a wearable underwater computer to record and make dolphin sounds. The computer aims to create synthesized dolphin sounds that can be established between sound and object, so the hope is for dolphins to imitate the sound in order to make requests from people.\n\nHerzing has contributed extensively to the field of dolphin intelligence and communication. Among these contributions, she has recorded observations of dolphins expressing teaching behaviors. She also worked as part of a team that developed a new camera/hydrophone system which allows researchers to identify which dolphin on a recording made which sound. This device pairs a video camera with three hydrophones, recordings from the device can be used to assess the directionality of a sound moving through water. Due to her expertise in studying dolphin intelligence, Herzing has described a method for unbiased quantification of nonhuman intelligence which can be applied to other animals as well as dolphins.\n\n"}
{"id": "12673103", "url": "https://en.wikipedia.org/wiki?curid=12673103", "title": "Diploma in Engineering", "text": "Diploma in Engineering\n\nThe Diploma in Engineering or Diploma in Technical Education are programs focused on practical and skills-oriented training. It is a technical degree that only covers the essentials when ranked with an undergraduate engineering degree. It aims to provide students with industry or job related engineering knowledge, scientific skills, computing & analysis, mathematical techniques, a sound knowledge of English to communicate in the field and ability to apply problem solving techniques.\n\nIts duration is 2–3 years. Many countries in the world recognize it as equivalent to Pre-Engineering or Bridging course when considered for continuing studies in engineering related bachelors or associate degree programs. After successful completion of Diploma in Engineering course, students can either continue further Engineering studies in undergraduate level or get employment as technicians, technologists, supervisors, superintendents, foremen, machinist, workshop technicians, draughtsman, station technicians (energy, thermal, aeronautical), automobile technicians, maintenance & service technicians, equipment mechanics and technicians, CAD/CAM programmer, agricultural overseers, instrument technicians, junior instructors, manufacturing, tool and die designers, electricians...etc.\n\nIn most of the countries one can apply for studying diploma in engineering degree after completion of 10th grade (Secondary School Certificate).\n\nDiploma in Engineering degree can be obtained in many disciplines such as:\n\nIn Bangladesh, Engineering Diploma is an academic certificate awarded by a technical board. It is a 4 years program offered by public and private sector polytechnic institutions.\n\n\"See also : Industrial training institute, one year inter science equivalent vocational training.\"\n\nIn India a Diploma in Engineering is a 3 year Course awarded in Engineering Studies with specific branch of Engineering . Studies of Diploma in Engineering is usually held in Polytechnic institutes recognized by respective State Boards of Technical Education/Examination (e.g. Uttar Pradesh Board of Technical Education) and/or State Departments/Directorates of Technical Educations and All India Council for Technical Education.\nDiploma Holders can sit for the exam of Associate Member of the Institution of Engineers (A.M.I.E) membership, Member of Indian Institution of Industrial Engineering, Navi Mumbai which is equivalent to the Associate engineering bachelor's degree. Diploma holders can enroll for advanced diploma programmes in concentrated job sectors within their area of study. Diploma holders are also eligible for lateral entry to the third semester Engineering Courses in various Technical Universities like UPTU, VTU, etc., i.e. direct entry to second year. Diploma holders are eligible for part-time entry to Bachelor of Engineering Courses in various Technical Universities like Sri Sai Group of Institutes, Manipal Institute of Technology, Jaipur National University, Sunrise University, Jamia Millia Islamia and Delhi Technological University, NTTF Technical training center, Uttarakhand board of technical education (Dehradun)...etc. In Tamil Nadu the government is revolutionizing its technical education by upgrading its diploma courses with newer schemes (L Scheme and forward) to make it equivalent with UK's HND programs that enables students for direct entry into the fifth semester of a Bachelor of Technology program. Those who have a twelfth grade (Higher Secondary School Certificate) in Physics, Chemistry and Mathematics (PCM) combination, require only to complete two years excluding first year physics, chemistry, mathematics inter science level subjects. Diploma holders can enroll for advanced diploma programmes in concentrated job sectors within their area of study.In India a Diploma in Engineering is a specific academic award usually awarded in technical courses e.g. Chemical Engineering , Mechanical Engineering,Civil Engineering , Electrical Engineering , etc.\n\nIn Pakistan, Engineering Diploma is an academic certificate awarded by a technical board. It is a 3 years program offered by public and private sector polytechnic institutions, namely Diploma of Associate Engineering (DAE) which is equivalent to HSSC/FSc (Pre-Engineering) by IBCC. A candidate having SSC or TSC can enroll in this program. This program is offered in various engineering disciplines such as Electrical, Electronics, Computer, Telecommunication, Mechanical, Civil, Chemical etc.\n\nDiploma holders are often called Associate Engineers. They can enroll in Bachelor of Technology and Bachelor of Engineering degree programs for higher study.\n\n\n"}
{"id": "45374373", "url": "https://en.wikipedia.org/wiki?curid=45374373", "title": "Director of the Royal Greenwich Observatory", "text": "Director of the Royal Greenwich Observatory\n\nThe Director of the Royal Greenwich Observatory was the senior scientist responsible for the administration of the Royal Greenwich Observatory from 1972 until the institution's closure in 1998.\n\nExecutive responsibility for the Royal Observatory, Greenwich, London, \nhad rested with the Astronomer Royal from the institution's foundation \nin 1675. This practice continued when the observatory moved to \nHerstmonceux Castle in 1948 and was renamed the Royal Greenwich \nObservatory.\n\nHowever, the title Astronomer Royal was separated from directorship of \nthe observatory after the retirement of Richard Woolley in 1971.\nFollowing this, Margaret Burbidge was appointed Director, and Sir Martin Ryle \n(1918–1984) was appointed Astronomer Royal in an honorary \ncapacity. The Astronomer Royal no longer had any association with the \nobservatory after this time.\n\nDirectors took action to modernise the institution and to establish a \nnew observatory on the island of La Palma \nin the Canary Islands. \nThe Director oversaw the move of the Royal Greenwich Observatory from Herstmonceux \nto Cambridge in 1990, and continued in charge until the observatory was closed by the \nParticle Physics and Astronomy Research Council in 1998. The post expired with \nthe institution.\n\nThe Directors of the Royal Greenwich Observatory as a post distinct from \nAstronomer Royal were:\n"}
{"id": "8594100", "url": "https://en.wikipedia.org/wiki?curid=8594100", "title": "EXIT chart", "text": "EXIT chart\n\nAn extrinsic information transfer chart, commonly called an EXIT chart, is a technique to aid the construction of good iteratively-decoded error-correcting codes (in particular low-density parity-check (LDPC) codes and Turbo codes).\n\nEXIT charts were developed by Stephan ten Brink, building on the concept of extrinsic information developed in the Turbo coding community. An EXIT chart includes the response of elements of decoder (for example a convolutional decoder of a Turbo code, the LDPC parity-check nodes or the LDPC variable nodes). The response can either be seen as extrinsic information or a representation of the messages in belief propagation. \n\nIf there are two components which exchange messages, the behaviour of the decoder can be plotted on a two-dimensional chart. One component is plotted with its input on the horizontal axis and its output on the vertical axis. The other component is plotted with its input on the vertical axis and its output on the horizontal axis. The decoding path followed is found by stepping between the two curves. For a successful decoding, there must be a clear swath between the curves so that iterative decoding can proceed from 0 bits of extrinsic information to 1 bit of extrinsic information.\n\nA key assumption is that the messages to and from an element of the decoder can be described by a single number, the extrinsic information. This is true when decoding codes from a binary erasure channel but otherwise the messages are often samples from a Gaussian distribution with the correct extrinsic information. The other key assumption is that the messages are independent (equivalent to an infinite block-size code without local structure between the components)\n\nTo make an optimal code, the two transfer curves need to lie close to each other. This observation is supported by the theoretical result that for capacity to be reached for a code over a binary-erasure channel there must be no area between the curves and also by the insight that a large number of iterations are required for information to be spread throughout all bits of a code.\n\n\n"}
{"id": "2726034", "url": "https://en.wikipedia.org/wiki?curid=2726034", "title": "Einstein force", "text": "Einstein force\n\nThe Einstein force is an apparent force which acts in an accelerated reference system.\n\nSuppose that there are two reference frames \"S\" and \"S\"<nowiki> '</nowiki>, where \"S\"<nowiki> '</nowiki> is moving relative to \"S\". The origin of \"S\"<nowiki> '</nowiki> moves along some curve in \"S\", which can be traced out by some vector C which is a function of \"t\". The Einstein force is the apparent force acting on a particle of mass \"m\" in the \"S\"<nowiki> '</nowiki> frame, and is defined by\n"}
{"id": "1928465", "url": "https://en.wikipedia.org/wiki?curid=1928465", "title": "Flavour (particle physics)", "text": "Flavour (particle physics)\n\nIn particle physics, flavour or flavor refers to the \"species\" of an elementary particle. The Standard Model counts six flavours of quarks and six flavours of leptons. They are conventionally parameterized with \"flavour quantum numbers\" that are assigned to all subatomic particles. They can also be described by some of the family symmetries proposed for the quark-lepton generations.\n\nIn classical mechanics, a force acting on a point-like particle can only alter the particle's dynamical state, i.e., its momentum, angular momentum, etc. Quantum field theory, however, allows interactions that can alter other facets of a particle's nature described by non dynamical, discrete quantum numbers. In particular, the action of the weak force is such that it allows the conversion of quantum numbers describing mass and electric charge of both quarks and leptons from one discrete type to another. This is known as a flavour change, or flavour transmutation. Due to their quantum description, flavour states may also undergo quantum superposition.\n\nIn atomic physics the principal quantum number of an electron specifies the electron shell in which it resides, which determines the energy level of the whole atom. Analogously, the five flavour quantum numbers (isospin, strangeness, charm, bottomness or topness) can characterize the quantum state of quarks, by the degree to which it exhibits six distinct flavours (u, d, s, c, b, t).\n\nComposite particles can be created from multiple quarks, forming hadrons, such as mesons and baryons, each possessing unique aggregate characteristics, such as different masses, electric charges, and decay modes. A hadron's overall flavour quantum numbers depend on the numbers of constituent quarks of each particular flavour.\n\nAll of the various charges discussed above are conserved by the fact that the corresponding charge operators can be understood as \"generators of symmetries\" that commute with the Hamiltonian. Thus, the eigenvalues of the various charge operators are conserved.\n\nAbsolutely conserved flavour quantum numbers are:\n\nIn some theories, the individual baryon and lepton number conservation can be violated, if the difference between them () is conserved (see chiral anomaly). All other flavour quantum numbers are violated by the electroweak interactions. Strong interactions conserve all flavours.\n\nIf there are two or more particles which have identical interactions, then they may be interchanged without affecting the physics. Any (complex) linear combination of these two particles give the same physics, as long as the combinations are orthogonal, or perpendicular, to each other.\n\nIn other words, the theory possesses symmetry transformations such as formula_1, where and are the two fields (representing the various \"generations\" of leptons and quarks, see below), and is any unitary matrix with a unit determinant. Such matrices form a Lie group called SU(2) (see special unitary group). This is an example of flavour symmetry.\n\nIn quantum chromodynamics, flavour is a conserved global symmetry. In the electroweak theory, on the other hand, this symmetry is broken, and flavour changing processes exist, such as quark decay or neutrino oscillations.\n\nAll leptons carry a lepton number . In addition, leptons carry weak isospin, , which is − for the three charged leptons (i.e. electron, muon and tau) and + for the three associated neutrinos. Each doublet of a charged lepton and a neutrino consisting of opposite are said to constitute one generation of leptons. In addition, one defines a quantum number called weak hypercharge, , which is −1 for all left-handed leptons. Weak isospin and weak hypercharge are gauged in the Standard Model.\n\nLeptons may be assigned the six flavour quantum numbers: electron number, muon number, tau number, and corresponding numbers for the neutrinos. These are conserved in strong and electromagnetic interactions, but violated by weak interactions. Therefore, such flavour quantum numbers are not of great use. A separate quantum number for each generation is more useful: electronic lepton number (+1 for electrons and electron neutrinos), muonic lepton number (+1 for muons and muon neutrinos), and tauonic lepton number (+1 for tau leptons and tau neutrinos). However, even these numbers are not absolutely conserved, as neutrinos of different generations can mix; that is, a neutrino of one flavour can transform into another flavour. The strength of such mixings is specified by a matrix called the Pontecorvo–Maki–Nakagawa–Sakata matrix (PMNS matrix).\n\nAll quarks carry a baryon number . They also all carry weak isospin, . The positive- quarks (up, charm, and top quarks) are called \"up-type quarks\" and negative- quarks (down, strange, and bottom quarks) are called \"down-type quarks\". Each doublet of up and down type quarks constitutes one generation of quarks.\n\nFor all the quark flavour quantum numbers listed below, the convention is that the flavour charge and the electric charge of a quark have the same sign. Thus any flavour carried by a charged meson has the same sign as its charge. Quarks have the following flavour quantum numbers:\n\nThese five quantum numbers, together with baryon number (which is not a flavour quantum number), completely specify numbers of all 6 quark flavours separately (as , i.e. an antiquark is counted with the minus sign). They are conserved by both the electromagnetic and strong interactions (but not the weak interaction). From them can be built the derived quantum numbers:\n\nThe terms \"strange\" and \"strangeness\" predate the discovery of the quark, but continued to be used after its discovery for the sake of continuity (i.e. the strangeness of each type of hadron remained the same); strangeness of anti-particles being referred to as +1, and particles as −1 as per the original definition. Strangeness was introduced to explain the rate of decay of newly discovered particles, such as the kaon, and was used in the Eightfold Way classification of hadrons and in subsequent quark models. These quantum numbers are preserved under strong and electromagnetic interactions, but not under weak interactions.\n\nFor first-order weak decays, that is processes involving only one quark decay, these quantum numbers (e.g. charm) can only vary by 1, that is, for a decay involving a charmed quark or antiquark either as the incident particle or as a decay byproduct, ; likewise, for a decay involving a bottom quark or antiquark . Since first-order processes are more common than second-order processes (involving two quark decays), this can be used as an approximate \"selection rule\" for weak decays.\n\nA special mixture of quark flavours is an eigenstate of the weak interaction part of the Hamiltonian, so will interact in a particularly simple way with the W bosons. (Charged weak interactions violate flavor). On the other hand, a fermion of a fixed mass (an eigenstate of the kinetic and strong interaction parts of the Hamiltonian) is an eigenstate of flavour. The transformation from the former basis to the flavor-eigenstate/mass-eigenstate basis for quarks underlies the Cabibbo–Kobayashi–Maskawa matrix (CKM matrix). This matrix is analogous to the PMNS matrix for neutrinos, and quantifies flavour changes under charged weak interactions of quarks.\n\nThe CKM matrix allows for CP violation if there are at least three generations.\n\nFlavour quantum numbers are additive. Hence antiparticles have flavour equal in magnitude to the particle but opposite in sign. Hadrons inherit their flavour quantum number from their valence quarks: this is the basis of the classification in the quark model. The relations between the hypercharge, electric charge and other flavour quantum numbers hold for hadrons as well as quarks.\n\nQuantum chromodynamics (QCD) contains six flavours of quarks. However, their masses differ and as a result they are not strictly interchangeable with each other. The up and down flavours are close to having equal masses, and the theory of these two quarks possesses an approximate SU(2) symmetry (isospin symmetry).\n\nUnder some circumstances, the masses of quarks do not meaningfully contribute to the system's behavior, and can be ignored. The simplified behavior of flavour transformations can then be successfully modeled as acting independently on the left- and right-handed parts of each quark field. This approximate description of the flavour symmetry is described by a chiral group .\n\nIf all quarks had non-zero but equal masses, then this chiral symmetry is broken to the \"vector symmetry\" of the \"diagonal flavour group\" , which applies the same transformation to both helicities of the quarks. This reduction of symmetry is a form of \"explicit symmetry breaking\". The amount of explicit symmetry breaking is controlled by the current quark masses in QCD.\n\nEven if quarks are massless, chiral flavour symmetry can be spontaneously broken if the vacuum of the theory contains a chiral condensate (as it does in low-energy QCD). This gives rise to an effective mass for the quarks, often identified with the valence quark mass in QCD.\n\nAnalysis of experiments indicate that the current quark masses of the lighter flavours of quarks are much smaller than the QCD scale, Λ, hence chiral flavour symmetry is a good approximation to QCD for the up, down and strange quarks. The success of chiral perturbation theory and the even more naive chiral models spring from this fact. The valence quark masses extracted from the quark model are much larger than the current quark mass. This indicates that QCD has spontaneous chiral symmetry breaking with the formation of a chiral condensate. Other phases of QCD may break the chiral flavour symmetries in other ways.\n\nSome of the historical events that led to the development of flavour symmetry are discussed in the article on isospin.\n\n\n\n"}
{"id": "2636319", "url": "https://en.wikipedia.org/wiki?curid=2636319", "title": "Fluxon", "text": "Fluxon\n\nIn physics, a fluxon is a quantum of electromagnetic flux. The term may have any of several related meanings.\n\nIn the context of superconductivity, in type II superconductors fluxons (also known as Abrikosov vortices) can form when the applied field lies between formula_1 and formula_2. The fluxon is a small whisker of normal phase surrounded by superconducting phase, and Supercurrents circulate around the normal core. The magnetic field through such a whisker and its neighborhood, which has size of the order of London penetration depth formula_3 (~100 nm), is quantized because of the phase properties of the magnetic vector potential in quantum electrodynamics, see magnetic flux quantum for details.\n\nIn the context of long Superconductor-Insulator-Superconductor Josephson tunnel junctions, a fluxon (aka Josephson vortex) is made of circulating supercurrents and has \"no\" normal core in the tunneling barrier. Supercurrents circulate just around the mathematical center of a fluxon, which is situated with the (insulating) Josephson barrier. Again, the magnetic flux created by circulating supercurrents is equal to a magnetic flux quantum formula_4 (or less, if the superconducting electrodes of the Josephson junction are thinner than formula_3).\n\nIn the context of numerical MHD modeling, a fluxon is a discretized magnetic field line, representing a finite amount of magnetic flux in a localized bundle in the model. Fluxon models are explicitly designed to preserve the topology of the magnetic field, overcoming numerical resistivity effects in Eulerian models.\n\n"}
{"id": "79888", "url": "https://en.wikipedia.org/wiki?curid=79888", "title": "Fruit tree pruning", "text": "Fruit tree pruning\n\nFruit tree pruning is the cutting and removing of selected parts of a fruit tree. It spans a number of horticultural techniques. Pruning often means cutting branches back, sometimes removing smaller limbs entirely. It may also mean removal of young shoots, buds, and leaves. \n\nEstablished orchard practice of both organic and nonorganic types typically includes pruning. Pruning can control growth, remove dead or diseased wood, and stimulate the formation of flowers and fruit buds. It is widely stated that careful attention to pruning and training young trees improves their later productivity and longevity, and that good pruning and training can also prevent later injury from weak crotches or forks (where a tree trunk splits into two or more branches) that break from the weight of fruit, snow, or ice on the branches.\n\nSome sustainable agriculture or permaculture personalities, such as Sepp Holzer and Masanobu Fukuoka, advocate and practice no-pruning methods, which runs counter to the widespread confidence in the idea that pruning produces superior results compared with not pruning. Many books about fruit-growing assert advantages and disadvantages of pruning or not pruning, although without randomized controlled trials, it is hard to separate theorizing and traditional knowledge from evidence-based recommendations.\n\nPlants form new tissue in an area called the meristem, located near the tips of roots and shoots, where active cell division takes place. Meristem growth is aimed at ensuring that leaves are quickly elevated into sunlight, and that roots are able to penetrate deeply into the soil. Once adequate height and length is achieved by the stems and roots, they begin to thicken to support the plant. On the shoots, these growing tips of the plant are called \"apical\" buds. The \"apical meristem\" (or tip) produces the growth hormone auxin, which not only promotes cell division, but also diffuses downwards and inhibits the development of lateral bud growth that otherwise competes with the apical tip for light and nutrients. Removing the apical tip and its suppressive hormone lets lower, dormant lateral buds develop, and the buds between the leaf stalk and stem produce new shoots that compete to become lead growth.\n\nManipulating this natural response to damage (known as the principle of apical dominance) by processes such as pruning (as well as coppicing and pollarding) allows the arborist to determine the shape, size, and productivity of many fruiting trees and bushes. The main aim when pruning fruit trees is usually to maximize fruit yield. Unpruned trees tend to produce large numbers of small fruits that may be difficult to reach when harvesting by hand. Branches can become broken by the weight of the crop, and the cropping may become biennial (that is, bearing fruit only every other year). Overpruned trees on the other hand tend to produce light crops of large, flavourless fruit that does not store well. Careful pruning balances shoot growth and fruit production.\n\nOne of the simplest instructions given in nearly every article or book chapter on the subject is that no branches should cross each other, that is, rub against each other, and that one of them should be selected and removed.\n\nIn the early years of the tree's life, it is important to develop a framework sufficiently strong to bear the weight of crops. This requires formative pruning to reinforce the tree. Formative pruning of apple (\"Malus pumila\") and pear (\"Pyrus communis\") trees should be carried out in the dormant winter months. For the Northern hemisphere, this should occur between November and March; For the Southern hemisphere, June and September. Stone fruits—such as cherries, plums, and gages—have different requirements, and should not be pruned in dormant months.\n\nA maiden whip (a one-year-old tree with no side shoots) should be pruned to a bud with two buds below it at about 80 cm from the ground immediately after planting to produce primary branches during the first growing season. A feathered maiden (that is, a one-year-old tree with several side branches) should have its main stem pruned back to three or four strong shoots at 80 cm from the ground. Side shoots should be shortened by two thirds of their length to an upward or outward facing bud. Lower shoots should be removed flush with the stem.\n\nRemove lower shoots and prune between three and five of the best-placed shoots by half to an upwards or outwards facing bud to form what becomes the tree's main structural branches. Remove any inward-facing shoots.\n\nPrune leading shoots of branches selected to extend the framework by half, to a bud facing in the desired direction. Select four good laterals to fill the framework and shorten these by a half. Prune any remaining laterals to four buds to form fruiting spurs.\n\nThe tree has begun to fruit and requires only limited formative pruning. Shorten leaders by one third and prune laterals not required to extend the framework to four buds.\n\nThe tree is established, and should be pruned annually as described in the following section.\n\nBefore pruning, distinguish between spur-bearing varieties, tip-bearing varieties, and an intermediate between the two that bears both on spurs and at the tips. Spur-bearing trees occur more frequently than tip-bearing trees, and they bear most of their fruit yearly at the end of short lateral pieces of wood (spurs) up to about 4 inches long.\n\nSpur-bearing types include apples of the varieties 'Cox's Orange Pippin', 'James Grieve' and 'Sunset', and pears such as 'Conference', 'Doyenne du Commice', and 'Williams Bon Chretien'. Tip-bearers on the other hand produce most of their fruit buds at the tips of slender shoots grown the previous summer, and include the apples 'Worcester Pearmain' and 'Irish Peach', and the pears such as 'Jargonelle' and 'Josephine de Malines'. There are basically three types of pruning that are applied once the main shape of the tree has been established. These are:\n\nTip-bearers should be pruned lightly in winter using the regulatory system (see above). Any maiden shoots less than 25 cm in length should be left untouched as they have fruit buds at their tips. Longer shoots are spur pruned to prevent overcrowding and to stimulate the production of more short-tip-bearing shoots the following year. Branch leaders are 'tipped', removing the top three or four buds to a bud facing in the desired direction to make them branch out and so produce more tip-bearing shoots.\n\n\n"}
{"id": "22547944", "url": "https://en.wikipedia.org/wiki?curid=22547944", "title": "Fusain", "text": "Fusain\n\nFusain is a fossilised carbon deposit which, after some controversy, has been identified as fossilised charcoal. \nIt is fibrous, black and opaque, and often preserves details of cell wall architecture. Wood-derived fusain usually takes the form of cubic blocks, whereas fusain from other plant material may take the form of thin films which are only visible under a microscope where the surrounding rock is dissolved by acid maceration. The material is silky and crumbles on the touch.\nThe loss of volatile elements during combustion means that fusain fossils are usually smaller than the original organism, but this same factor makes them unlikely to be eaten by any animals (for they have no nutritional value), enhancing their preservation potential.\n\nFusain shows characteristics diagnostic of pyrolysis in modern material: the cell walls of xylem are homogenized, and subsequently crack along their middles.\n\nhttp://www.palaeocast.com/episode-22-fire-and-charcoal/#.U446-i-KWKO\n"}
{"id": "33487881", "url": "https://en.wikipedia.org/wiki?curid=33487881", "title": "Gen-ichi Koidzumi", "text": "Gen-ichi Koidzumi\n\n\n"}
{"id": "52193743", "url": "https://en.wikipedia.org/wiki?curid=52193743", "title": "HE 1256-2738", "text": "HE 1256-2738\n\nHE 1256-2738 is a subdwarf located approximately 1,000 light years away in the constellation Hydra, with a surface temperature of approximately . Along with stars HE 2359-2844 and LS IV-14 116, HE 1256-2738 forms a new group of star called heavy metal subdwarfs.\n"}
{"id": "14773", "url": "https://en.wikipedia.org/wiki?curid=14773", "title": "Information theory", "text": "Information theory\n\nInformation theory studies the quantification, storage, and communication of information. It was originally proposed by Claude E. Shannon in 1948 to find fundamental limits on signal processing and communication operations such as data compression, in a landmark paper entitled \"A Mathematical Theory of Communication\". Applications of fundamental topics of information theory include lossless data compression (e.g. ZIP files), lossy data compression (e.g. MP3s and JPEGs), and channel coding (e.g. for digital subscriber line (DSL)). Its impact has been crucial to the success of the Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones, the development of the Internet, the study of linguistics and of human perception, the understanding of black holes, and numerous other fields.\n\nA key measure in information theory is \"entropy\". Entropy quantifies the amount of uncertainty involved in the value of a random variable or the outcome of a random process. For example, identifying the outcome of a fair coin flip (with two equally likely outcomes) provides less information (lower entropy) than specifying the outcome from a roll of a (with six equally likely outcomes). Some other important measures in information theory are mutual information, channel capacity, error exponents, and relative entropy.\n\nThe field is at the intersection of mathematics, statistics, computer science, physics, neurobiology, information engineering, and electrical engineering. The theory has also found applications in other areas, including statistical inference, natural language processing, cryptography, neurobiology, human vision, the evolution and function of molecular codes (bioinformatics), model selection in statistics, thermal physics, quantum computing, linguistics, plagiarism detection, pattern recognition, and anomaly detection. Important sub-fields of information theory include source coding, channel coding, algorithmic complexity theory, algorithmic information theory, information-theoretic security, and measures of information.\n\nInformation theory studies the transmission, processing, extraction, and utilization of information. Abstractly, information can be thought of as the resolution of uncertainty. In the case of communication of information over a noisy channel, this abstract concept was made concrete in 1948 by Claude Shannon in his paper \"A Mathematical Theory of Communication\", in which \"information\" is thought of as a set of possible messages, where the goal is to send these messages over a noisy channel, and then to have the receiver reconstruct the message with low probability of error, in spite of the channel noise. Shannon's main result, the noisy-channel coding theorem showed that, in the limit of many channel uses, the rate of information that is asymptotically achievable is equal to the channel capacity, a quantity dependent merely on the statistics of the channel over which the messages are sent.\n\nInformation theory is closely associated with a collection of pure and applied disciplines that have been investigated and reduced to engineering practice under a variety of rubrics throughout the world over the past half century or more: adaptive systems, anticipatory systems, artificial intelligence, complex systems, complexity science, cybernetics, informatics, machine learning, along with systems sciences of many descriptions. Information theory is a broad and deep mathematical theory, with equally broad and deep applications, amongst which is the vital field of coding theory.\n\nCoding theory is concerned with finding explicit methods, called \"codes\", for increasing the efficiency and reducing the error rate of data communication over noisy channels to near the channel capacity. These codes can be roughly subdivided into data compression (source coding) and error-correction (channel coding) techniques. In the latter case, it took many years to find the methods Shannon's work proved were possible. A third class of information theory codes are cryptographic algorithms (both codes and ciphers). Concepts, methods and results from coding theory and information theory are widely used in cryptography and cryptanalysis. \"See the article ban (unit) for a historical application.\"\n\nInformation theory is also used in information retrieval, intelligence gathering, gambling, statistics, and even in musical composition.\n\nThe landmark event that \"established\" the discipline of information theory and brought it to immediate worldwide attention was the publication of Claude E. Shannon's classic paper \"A Mathematical Theory of Communication\" in the \"Bell System Technical Journal\" in July and October 1948.\n\nPrior to this paper, limited information-theoretic ideas had been developed at Bell Labs, all implicitly assuming events of equal probability. Harry Nyquist's 1924 paper, \"Certain Factors Affecting Telegraph Speed\", contains a theoretical section quantifying \"intelligence\" and the \"line speed\" at which it can be transmitted by a communication system, giving the relation (recalling Boltzmann's constant), where \"W\" is the speed of transmission of intelligence, \"m\" is the number of different voltage levels to choose from at each time step, and \"K\" is a constant. Ralph Hartley's 1928 paper, \"Transmission of Information\", uses the word \"information\" as a measurable quantity, reflecting the receiver's ability to distinguish one sequence of symbols from any other, thus quantifying information as , where \"S\" was the number of possible symbols, and \"n\" the number of symbols in a transmission. The unit of information was therefore the decimal digit, which has since sometimes been called the hartley in his honor as a unit or scale or measure of information. Alan Turing in 1940 used similar ideas as part of the statistical analysis of the breaking of the German second world war Enigma ciphers.\n\nMuch of the mathematics behind information theory with events of different probabilities were developed for the field of thermodynamics by Ludwig Boltzmann and J. Willard Gibbs. Connections between information-theoretic entropy and thermodynamic entropy, including the important contributions by Rolf Landauer in the 1960s, are explored in \"Entropy in thermodynamics and information theory\".\n\nIn Shannon's revolutionary and groundbreaking paper, the work for which had been substantially completed at Bell Labs by the end of 1944, Shannon for the first time introduced the qualitative and quantitative model of communication as a statistical process underlying information theory, opening with the assertion that\n\nWith it came the ideas of\n\nInformation theory is based on probability theory and statistics. Information theory often concerns itself with measures of information of the distributions associated with random variables. Important quantities of information are entropy, a measure of information in a single random variable, and mutual information, a measure of information in common between two random variables. The former quantity is a property of the probability distribution of a random variable and gives a limit on the rate at which data generated by independent samples with the given distribution can be reliably compressed. The latter is a property of the joint distribution of two random variables, and is the maximum rate of reliable communication across a noisy channel in the limit of long block lengths, when the channel statistics are determined by the joint distribution.\n\nThe choice of logarithmic base in the following formulae determines the unit of information entropy that is used. A common unit of information is the bit, based on the binary logarithm. Other units include the nat, which is based on the natural logarithm, and the decimal digit, which is based on the common logarithm.\n\nIn what follows, an expression of the form is considered by convention to be equal to zero whenever . This is justified because formula_1 for any logarithmic base.\n\nBased on the probability mass function of each source symbol to be communicated, the Shannon entropy , in units of bits (per symbol), is given by\nwhere is the probability of occurrence of the -th possible value of the source symbol. This equation gives the entropy in the units of \"bits\" (per symbol) because it uses a logarithm of base 2, and this base-2 measure of entropy has sometimes been called the \"shannon\" in his honor. Entropy is also commonly computed using the natural logarithm (base , where is Euler's number), which produces a measurement of entropy in \"nats\" per symbol and sometimes simplifies the analysis by avoiding the need to include extra constants in the formulas. Other bases are also possible, but less commonly used. For example, a logarithm of base will produce a measurement in bytes per symbol, and a logarithm of base 10 will produce a measurement in decimal digits (or hartleys) per symbol.\n\nIntuitively, the entropy of a discrete random variable is a measure of the amount of \"uncertainty\" associated with the value of when only its distribution is known.\n\nThe entropy of a source that emits a sequence of symbols that are independent and identically distributed (iid) is bits (per message of symbols). If the source data symbols are identically distributed but not independent, the entropy of a message of length will be less than .\n\nIf one transmits 1000 bits (0s and 1s), and the value of each of these bits is known to the receiver (has a specific value with certainty) ahead of transmission, it is clear that no information is transmitted. If, however, each bit is independently equally likely to be 0 or 1, 1000 shannons of information (more often called bits) have been transmitted. Between these two extremes, information can be quantified as follows. If 𝕏 is the set of all messages that could be, and is the probability of some formula_3, then the entropy, , of is defined:\n\n(Here, is the self-information, which is the entropy contribution of an individual message, and is the expected value.) A property of entropy is that it is maximized when all the messages in the message space are equiprobable ; i.e., most unpredictable, in which case .\n\nThe special case of information entropy for a random variable with two outcomes is the \"binary entropy function\", usually taken to the logarithmic base 2, thus having the shannon (Sh) as unit:\n\nThe \"joint entropy\" of two discrete random variables and is merely the entropy of their pairing: . This implies that if and are independent, then their joint entropy is the sum of their individual entropies.\n\nFor example, if represents the position of a chess piece — the row and the column, then the joint entropy of the row of the piece and the column of the piece will be the entropy of the position of the piece.\n\nDespite similar notation, joint entropy should not be confused with \"cross entropy\".\n\nThe \"conditional entropy\" or \"conditional uncertainty\" of given random variable (also called the \"equivocation\" of about ) is the average conditional entropy over :\n\nBecause entropy can be conditioned on a random variable or on that random variable being a certain value, care should be taken not to confuse these two definitions of conditional entropy, the former of which is in more common use. A basic property of this form of conditional entropy is that:\n\n\"Mutual information\" measures the amount of information that can be obtained about one random variable by observing another. It is important in communication where it can be used to maximize the amount of information shared between sent and received signals. The mutual information of relative to is given by:\n\nwhere (\"S\"pecific mutual \"I\"nformation) is the pointwise mutual information.\n\nA basic property of the mutual information is that\nThat is, knowing \"Y\", we can save an average of bits in encoding \"X\" compared to not knowing \"Y\".\n\nMutual information is symmetric:\n\nMutual information can be expressed as the average Kullback–Leibler divergence (information gain) between the posterior probability distribution of \"X\" given the value of \"Y\" and the prior distribution on \"X\":\nIn other words, this is a measure of how much, on the average, the probability distribution on \"X\" will change if we are given the value of \"Y\". This is often recalculated as the divergence from the product of the marginal distributions to the actual joint distribution:\n\nMutual information is closely related to the log-likelihood ratio test in the context of contingency tables and the multinomial distribution and to Pearson's χ test: mutual information can be considered a statistic for assessing independence between a pair of variables, and has a well-specified asymptotic distribution.\n\nThe \"Kullback–Leibler divergence\" (or \"information divergence\", \"information gain\", or \"relative entropy\") is a way of comparing two distributions: a \"true\" probability distribution \"p(X)\", and an arbitrary probability distribution \"q(X)\". If we compress data in a manner that assumes \"q(X)\" is the distribution underlying some data, when, in reality, \"p(X)\" is the correct distribution, the Kullback–Leibler divergence is the number of average additional bits per datum necessary for compression. It is thus defined\n\nAlthough it is sometimes used as a 'distance metric', KL divergence is not a true metric since it is not symmetric and does not satisfy the triangle inequality (making it a semi-quasimetric).\n\nAnother interpretation of the KL divergence is the \"unnecessary surprise\" introduced by a prior from the truth: suppose a number \"X\" is about to be drawn randomly from a discrete set with probability distribution \"p(x)\". If Alice knows the true distribution \"p(x)\", while Bob believes (has a prior) that the distribution is \"q(x)\", then Bob will be more surprised than Alice, on average, upon seeing the value of \"X\". The KL divergence is the (objective) expected value of Bob's (subjective) surprisal minus Alice's surprisal, measured in bits if the \"log\" is in base 2. In this way, the extent to which Bob's prior is \"wrong\" can be quantified in terms of how \"unnecessarily surprised\" it is expected to make him.\n\nOther important information theoretic quantities include Rényi entropy (a generalization of entropy), differential entropy (a generalization of quantities of information to continuous distributions), and the conditional mutual information.\n\nCoding theory is one of the most important and direct applications of information theory. It can be subdivided into source coding theory and channel coding theory. Using a statistical description for data, information theory quantifies the number of bits needed to describe the data, which is the information entropy of the source.\n\n\nThis division of coding theory into compression and transmission is justified by the information transmission theorems, or source–channel separation theorems that justify the use of bits as the universal currency for information in many contexts. However, these theorems only hold in the situation where one transmitting user wishes to communicate to one receiving user. In scenarios with more than one transmitter (the multiple-access channel), more than one receiver (the broadcast channel) or intermediary \"helpers\" (the relay channel), or more general networks, compression followed by transmission may no longer be optimal. Network information theory refers to these multi-agent communication models.\n\nAny process that generates successive messages can be considered a \"source\" of information. A memoryless source is one in which each message is an independent identically distributed random variable, whereas the properties of ergodicity and stationarity impose less restrictive constraints. All such sources are stochastic. These terms are well studied in their own right outside information theory.\n\nInformation \"rate\" is the average entropy per symbol. For memoryless sources, this is merely the entropy of each symbol, while, in the case of a stationary stochastic process, it is\n\nthat is, the conditional entropy of a symbol given all the previous symbols generated. For the more general case of a process that is not necessarily stationary, the \"average rate\" is\n\nthat is, the limit of the joint entropy per symbol. For stationary sources, these two expressions give the same result.\n\nIt is common in information theory to speak of the \"rate\" or \"entropy\" of a language. This is appropriate, for example, when the source of information is English prose. The rate of a source of information is related to its redundancy and how well it can be compressed, the subject of \"source coding\".\n\nCommunications over a channel—such as an ethernet cable—is the primary motivation of information theory. As anyone who's ever used a telephone (mobile or landline) knows, however, such channels often fail to produce exact reconstruction of a signal; noise, periods of silence, and other forms of signal corruption often degrade quality.\n\nConsider the communications process over a discrete channel. A simple model of the process is shown below:\n\nHere \"X\" represents the space of messages transmitted, and \"Y\" the space of messages received during a unit time over our channel. Let be the conditional probability distribution function of \"Y\" given \"X\". We will consider to be an inherent fixed property of our communications channel (representing the nature of the \"noise\" of our channel). Then the joint distribution of \"X\" and \"Y\" is completely determined by our channel and by our choice of , the marginal distribution of messages we choose to send over the channel. Under these constraints, we would like to maximize the rate of information, or the \"signal\", we can communicate over the channel. The appropriate measure for this is the mutual information, and this maximum mutual information is called the \"channel capacity\" and is given by:\nThis capacity has the following property related to communicating at information rate \"R\" (where \"R\" is usually bits per symbol). For any information rate \"R < C\" and coding error ε > 0, for large enough \"N\", there exists a code of length \"N\" and rate ≥ R and a decoding algorithm, such that the maximal probability of block error is ≤ ε; that is, it is always possible to transmit with arbitrarily small block error. In addition, for any rate \"R > C\", it is impossible to transmit with arbitrarily small block error.\n\n\"Channel coding\" is concerned with finding such nearly optimal codes that can be used to transmit data over a noisy channel with a small coding error at a rate near the channel capacity.\n\n\n\nInformation theoretic concepts apply to cryptography and cryptanalysis. Turing's information unit, the ban, was used in the Ultra project, breaking the German Enigma machine code and hastening the end of World War II in Europe. Shannon himself defined an important concept now called the unicity distance. Based on the redundancy of the plaintext, it attempts to give a minimum amount of ciphertext necessary to ensure unique decipherability.\n\nInformation theory leads us to believe it is much more difficult to keep secrets than it might first appear. A brute force attack can break systems based on asymmetric key algorithms or on most commonly used methods of symmetric key algorithms (sometimes called secret key algorithms), such as block ciphers. The security of all such methods currently comes from the assumption that no known attack can break them in a practical amount of time.\n\nInformation theoretic security refers to methods such as the one-time pad that are not vulnerable to such brute force attacks. In such cases, the positive conditional mutual information between the plaintext and ciphertext (conditioned on the key) can ensure proper transmission, while the unconditional mutual information between the plaintext and ciphertext remains zero, resulting in absolutely secure communications. In other words, an eavesdropper would not be able to improve his or her guess of the plaintext by gaining knowledge of the ciphertext but not of the key. However, as in any other cryptographic system, care must be used to correctly apply even information-theoretically secure methods; the Venona project was able to crack the one-time pads of the Soviet Union due to their improper reuse of key material.\n\nPseudorandom number generators are widely available in computer language libraries and application programs. They are, almost universally, unsuited to cryptographic use as they do not evade the deterministic nature of modern computer equipment and software. A class of improved random number generators is termed cryptographically secure pseudorandom number generators, but even they require random seeds external to the software to work as intended. These can be obtained via extractors, if done carefully. The measure of sufficient randomness in extractors is min-entropy, a value related to Shannon entropy through Rényi entropy; Rényi entropy is also used in evaluating randomness in cryptographic systems. Although related, the distinctions among these measures mean that a random variable with high Shannon entropy is not necessarily satisfactory for use in an extractor and so for cryptography uses.\n\nOne early commercial application of information theory was in the field of seismic oil exploration. Work in this field made it possible to strip off and separate the unwanted noise from the desired seismic signal. Information theory and digital signal processing offer a major improvement of resolution and image clarity over previous analog methods.\n\nSemioticians and Winfried Nöth both considered Charles Sanders Pierce as having created a theory of information in his works on semiotics. Nauta defined semiotic information theory as the study of \"the internal processes of coding, filtering, and information processing.\"\n\nConcepts from information theory such as redundancy and code control have been used by semioticians such as Umberto Eco and to explain ideology as a form of message transmission whereby a dominant social class emits its message by using signs that exhibit a high degree of redundancy such that only one message is decoded among a selection of competing ones.\n\nInformation theory also has applications in gambling and investing, black holes, and bioinformatics.\n\n\n\n\n"}
{"id": "48762980", "url": "https://en.wikipedia.org/wiki?curid=48762980", "title": "John Carrick (botanist)", "text": "John Carrick (botanist)\n\nJohn Carrick (14 June 1914 – 4 January 1978) was a botanist and the author of a number of plant names. He was born in Glasgow and died in Australia. He worked at the University of Malaya from 1952 to 1967 and then became a botanist at the South Australian State Herbarium.\n"}
{"id": "54441937", "url": "https://en.wikipedia.org/wiki?curid=54441937", "title": "Langgan", "text": "Langgan\n\nLanggan 琅玕 is the ancient Chinese name of a gemstone which remains an enigma in the history of mineralogy; it has been identified, variously, as blue-green malachite, blue coral, white coral, whitish chalcedony, red spinel, and red jade. It is also the name of a mythological \"langgan\" tree of immortality found in the western paradise of Kunlun Mountain, and the name of the classic \"waidan\" alchemical elixir of immortality \"langgan huadan\" 琅玕華丹 \"Elixir Efflorescence of Langgan\".\n\nThe Chinese characters 琅 and 玕 used to write the gemstone name \"lánggān\" are classified as radical-phonetic characters that combine the semantically significant \"jade radical\" 玉 or 王 (commonly used to write names of jades or gemstones) and phonetic elements hinting at pronunciation. \"Láng\" 琅 combines the \"jade radical\" with \"liáng\" 良 \"good; fine\" (interpreted to denote \"fine jade\") and \"gān\" 玕 combines it with the phonetic \"gān\" 干 \"stem; trunk\". The Chinese word \"yù\" 玉 is usually translated as \"jade\" but in some contexts translates as \"fine ornamental stone; gemstone; precious stone\", and can refer to a variety of rocks that carve and polish well, including jadeite, nephrite, agalmatolite, bowenite, and serpentine (Desautels 1977: 81).\n\nModern written Chinese \"láng\" 琅 and \"gān\" 玕 have variant Chinese characters. \"Láng\" 琅 is occasionally transcribed as \"láng\" 瑯 (with \"láng\" 郞 \"gentleman\") or \"lán\" 瓓 (\"lán\" 闌 \"railing\"); and \"gān\" 玕 is rarely written as \"gān\" 玵 (with a \"gān\" 甘 \"sweet\" phonetic). \"Guwen\" \"ancient script\" variants were \"láng\" 𤨜 or 𤦴 and \"gān\" 𤥚.\n\nBerthold Laufer proposed that \"langgan\" was an onomatopoetic word \"descriptive of the sound yielded by the sonorous stone when struck\" (1915: 206). \"Lang\" occurs in several imitative words meaning \"tinkling of jade pendants/ornaments\": \"lángláng\" 琅琅 \"tinkling/jingling sound\", \"língláng\" 玲琅 \"tinkling/jangling of jade\", \"línláng\" 琳琅 \"beautiful jade; sound of jade\", and \"lángdāng\" 琅璫 \"tinkling sound\". Laufer further suggests this etymology would explain the transference of the name \"langgan\" from a stone to a coral; Du Wan's 杜綰 c. 1125 \"Yunlin shipu\" 雲林石譜 \"Stone Catalogue of the Cloudy Forest\" (below) expressly states that the coral \"langgan\" \"when struck develops resonant properties\".\n\nThe name \"langgan\" has undergone remarkable semantic change. The first references to \"langgan\" are found in Chinese classics from the Warring States period (475-221 BCE) and Han dynasty (206 BCE-220 CE), which describe it as a valuable gemstone and mineral drug, as well as the mythological fruit of the \"langgan\" tree of immortality on Kunlun Mountain. Texts from the turbulent Six Dynasties period (220-589) and Sui dynasty (581-618) used \"langgan\" gemstone as a literary metaphor, and an ingredient in alchemical elixirs of immortality, many of which were poisonous. During the Tang dynasty (618-907), \"langgan\" was reinterpreted as a type of coral.\n\nSeveral early texts (including the \"Shujing\", \"Guanzi\", and \"Erya\" below) recorded \"langgan\" in context with the obscure gemstone(s) \"qiúlín\" 璆琳. In Classical Chinese syntax, 璆琳 can be parsed as two \"qiu\" and \"lin\" types of jade or as one \"qiulin\" type. A recent dictionary of Classical Chinese says \"qiú\" 璆 \"fine jade, jade lithophone\" is cognate with \"qiú\" 球 \"precious gem, fine jade; jade chime or lithophone\" (which later came to mean \"ball; sphere\"), and \"lín\" 琳 \"blue-gem; sapphire\" (Kroll 2017: 374, 272).\n\nIn what may be the earliest record (Schafer 1978: 29), the c. 5th-3rd centuries BCE \"Yu Gong\" \"Tribute of Yu the Great\" chapter of the \"Shujing\" \"Classic of Documents\" says the tributary products from Yong Province (located in the Wei River plain, one of the ancient Nine Provinces) included \"qiulin\" and \"langgan\" jade-like gemstones: \"Its articles of tribute were the k'ew and lin \"gem-stones\", and the lang-kan \"precious stones\"\" (tr. Legge 1865 3: 127). Legge quotes Kong Anguo's commentary that \"langgan\" is \"a stone, but like a pearl\", and suggests it was possibly lazulite or lapis lazuli, which Laufer calls \"purely conjectural\" (1915: 205).\n\nThe c. 4th-3rd centuries BCE \"Guanzi\" encyclopedic text, named for and attributed to the 7th century BCE philosopher Guan Zhong, who served as Prime Minister to Duke Huan of Qi (r. 685-643 BCE), uses \"bi\" 璧 \"a flat jade disc with a hole in the center\", \"qiulin\" 璆琳 \"lapis lazuli\", and \"langgan\" 琅玕 as examples of how establishing diverse local commodities as fiat currencies will encourage foreign economic cooperation. When Duke Huan asks Guanzi about how to politically control the \"Four \"Yi\"\" (meaning \"all foreigners\" on China's borders), he replies: \nSince the Yuzhi [i.e., Yuezhi/Kushans in Central Asia] have not paid court, I request our use of white jade discs [白璧] as money. Since those in the Kunlun desert (modern-day Xinjiang and Tibet) have not paid court, I request our use of lapis lazuli and \"langgan\" gems as money. … Since a white jade held tight unseen against one's chest or under one's armpit will be used as a thousand pieces of gold, we can obtain the Yuezhi eight thousand \"li\" away and make them pay court. Since a lapis lazuli and \"langgan\" gem (fashioned in) a hair clasp and earring will be used as a thousand gold pieces, we can obtain [i.e., defeat] [the inhabitants] of the Kunlun deserts eight thousand \"li\" away and make them pay court. Therefore if resources are not commandeered, economies will not connect, those distant from each other will have nothing to use for their common interest and the four \"yi\" will not be obtained and come to court. (tr. (Lavan et al. 2016: 149; one \"li\" was approximately one-third mile) \n\nXun Kuang's 3rd century BCE Confucian classic \"Xunzi\" has a context criticizing elaborate burials that uses \"dan'gan\" 丹矸 (with \"dān\" 丹 \"cinnabar\" and \"gān\" 矸 \"waste rock\", with the \"stone radical\" and same \"gān\" 干 phonetic) and \"langgan\" 琅玕. \nIn these ancient times, the body was covered with pearls and jades, the inner coffin was filled with beautifully ornamented embroideries, and he outer coffin was filled with yellow gold and decorated with cinnabar [丹矸] with added layers of laminar verdite. [In the outer tomb chamber were] rhinoceros and elephant ivory fashioned into trees, with precious rubies [琅玕], magnetite lodestones, and flowering aconite for their fruit.\" (18.7, tr. Knoblock 1994: 44) \nJohn Knoblock translates \"langgan\" as \"rubies\", noting perhaps the genuine ruby or balas spinel, were connected with the cult of immortality, and cites the \"Shanhaijing\" saying they grow on Mount Kunlun's Fuchang trees, and the \"Zhen'gao\" saying that adepts swallow \"ruby blossoms\" to feign death and become transcendents (1994: 30).\n\nEarly Chinese dictionaries define \"langgan\". The c. 4th-3rd century BCE \"Erya\" geography section (9 \"Shidi\" 釋地) lists valuable products from the various regions of ancient China: \"The beautiful things of the northwest are the \"qiulin\" [璆琳] and \"langgan\" gemstones from the wastelands [虛] of Kunlun Mountain\". The 121 CE \"Shuowen jiezi\" (Jade Radical section 玉部) has two consecutive definitions for \"lang\" 琅 and \"gan\" 玕. \"Lang\" is [used in] \"langgan\", which \"resembles a pearl [似珠者]\", \"Gan\" is [used in] \"langgan\", paraphrasing the \"Yu Gong\", \"Yong Province [using the ancient \"yōng\" 雝 character for \"yōng\" 雍] [produces] \"qiulin\" and \"langgan\" [gems] [球琳琅玕]\". \n\nThree sections about western Chinese mountains in the c. 4th-2nd centuries BCE \"Shanhaijing\" \"Classic of Mountains and Seas\" record early geographic legends associating \"langgan\" with Xi Wang Mu \"Queen Mother of the West\" who lives on Jade Mountain in the mythological axis mundi Kunlun Mountain paradise. Two mention \"langgan\" gems and one mentions \"langganshu\" 琅玕樹 trees. The \"Shanhaijing\" translator Anne Birrell exemplifies the difficulties of translating the word \"langgan\" in three ways: \"pearl-like gems\", \"red jade\", and \"precious gem [tree]\".\n\nFirst, the \"Classic of the Mountains: West\" section says Huaijiang 槐江 (lit. \"pagoda-tree river\") Mountain, located 400 \"li\" northeast of Kunlun Mountain, has abundant \"langgan\" and other valuable minerals. \"On the summit of Mount Carobriver are quantities of green male-yellow [多青雄黃]], precious pearl-like gems [藏琅玕], and yellow gold and jade. Granular cinnabar is abundant on its south face and there are quantities of speckled yellow gold and silver on its north face.\" (2, tr. Birrell 2000: 22). \"Male-yellow\" overliterally translates \"xiónghuáng\" 雄黃 \"realgar; red orpiment\"—Compare Richard Strassberg's translation, \"On the mountain’s heights is much green realgar, the finest quality of Langgan-Stone, yellow gold, and jade. On its southern slope are many grains of cinnabar, while on its northern slope are much glittering yellow gold and silver.\" (2002: 106). Guo Pu's 4th century CE \"Shanhaijing\" commentary says \"langgan\" \"shi\" 石 \"stone/gem\" (cf. \"zi\" 子 \"seeds\" in the third section) resembles a pearl, and \"cáng\" 藏 \"store; conceal, hide\" means \"yǐn\" 隱 \"conceal; hide\". However, Hao Yixing's 郝懿行 1822 commentary says \"cáng\" 藏 was originally written \"zāng\" 臧 \"good\", that is, Huaijiang Mountain has the \"best\" quality \"langgan\".\n\nSecond, the \"Classic of the Great Wilderness: West\" section records that on [Xi] Wang Mu 王母 \"Queen Mother [of the West]\" Mountain: \"Here are the sweet-bloom tree, sweet quince, white weeping willow, the look-flesh creature, the triply-grey horse, precious jade [琁瑰], dark green jade gemstone [瑤碧], the white tree, red jade [琅玕], white cinnabar, green cinnabar, and quantities of silver and iron.\" (16, tr. Birrell 2000: 174)\n\nThird, the \"Classic of Regions Within the Seas: West\" section refers to a mythical tricephalic creature dwelling in a \"fuchangshu\" 服常樹 (lit. \"serve constant tree\") who guards a \"langganshu\" tree south of Kunlun: \"The wears-ever fruit tree—on its crown there is a three-headed person who is in charge of the precious gem tree [琅玕樹].\" (11, tr. Birrell 2000: 141). Interpreters disagree whether the \"langgan\" tree grows alongside the \"fuchang\" tree or grows on it (Knoblock 1994: 30). Guo Pu's commentary admits unfamiliarity with the \"fuchang\" 服常 tree; Wu Renchen's 17th-century commentary notes the similarity with the \"shachang\" 沙棠 \"sand-plum tree\" that the \"Huainanzi\" lists with \"langgan\", but doubts they are the same. Guo's commentary says \"langgan\" \"zi\" 子 \"seeds\" (Birrell 2000: 249) or \"fruits\" (Knoblock 1994: 30) resemble pearls (cf. the \"Shuowen\" definition) and quotes the \"Erya\" that it is found on Kunlun Mountain.\n\nThe c. 120 BCE \"Huainanzi\" \"Terrestrial Forms\" chapter (4 墬形) describes \"langgan\" trees and \"langgan\" jade both found on Mt. Kunlun. The first context describes how Yu the Great controlled the Great Flood and \"excavated the wastelands of Kunlun [昆侖之球] to make level ground\". \"Atop the heights of Kunlun are treelike cereal plants [木禾] thirty-five feet tall. Growing to the west of these are pearl trees [珠樹], jade trees [玉樹], carnelian trees [琁樹], and no-death trees [不死樹]. To the east are found sand-plum trees [沙棠] and malachite trees [琅玕]. To the south are crimson trees [絳樹]. To the north are \"bi\" jade trees [碧樹] and \"yao\" jade trees [瑤樹].\" (4.3, tr. Major et al. 2010: 159; translating with Schafer's \"malachite\" instead of \"coral\"). The second context paraphrases the \"Erya\" definition (above) of \"langgan\": \"The beautiful things of the northwest are the \"qiu\", \"lin\", and \"langgan\" jades [球琳琅玕] of the Kunlun Mountains [昆侖]\" (4.7, tr. Major et al. 2010: 159; noting that \"qiu\", \"lin\", and \"langgan\" are \"types of jade, mostly not identifiable with certainty\").\n\nSeveral early classics of traditional Chinese medicine mention \"langgan\".\n\nThe c. 1st century BCE \"Huangdi Neijing\"'s \"Suwen\" 素問 \"Basic Questions\" section uses \"langgan\" beads to describe a healthy pulse. \"When man is serene and healthy the pulse of the heart flows and connects, just as pearls are joined together or like a string of red jade [如循琅玕]—then one can speak of a healthy heart\" (tr. Veith 1949: 173).\n\nThe c. 2nd century CE \"Nan Jing\" explains this \"langgan\" bead simile: \"[If the \"qi\" in] the vessels comes tied together like rings, or as if they were following [in their movement a chain of] \"lang gan\" stones [如循琅玕], that implies a normal state.\" Commentaries elaborate that \"langgan\" stones \"resemble pearls\" and their movement is like a \"string of jade- or pearl-like beads\" (tr. Unschuld 2016: 179). \n\nThe c. 3rd century CE \"Shennong Bencaojing\" lists \"qīng lánggān\" 青琅玕 \"blue-green \"langgan\"\" or \"shízhū\" 石珠 (lit. \"rock pearl\") as a mineral drug used to treat ailments such as itchy skin, carbuncle, and ALS. This is one of the rare early references to \"langgan\" that treats it as a real substance, while many others make it a feature of the divine world (Schafer 1978: 27).\n\nThe \"langgan huadan\" 琅玕華丹 \"Elixir Efflorescence of Langgan\" name of the \"waidan\" \"external alchemy\" elixir of immortality is the best-known usage of the word \"langgan\" (Pregadio 2008: 605). Some other translations are \"Elixir of Langgan Efflorescence\" (Strickmann 1979: 135, Bokenkamp 1997: 190),\"Lang-Kan (Gem) Radiant Elixir\" (Needham et al. 1980: 217), and \"Elixir Flower of Langgan\" (Pregadio 2006: 7). \n\nThe earliest method of compounding the elixir is found in the \"Taiwei lingshu ziwen langgan huadan shenzhen shangjing\" 太微靈書紫文琅玕華丹神真上經 \"Supreme Scripture on the Elixir of Langgan Efflorescence, from the Purple Texts Inscribed by the Spirits of Grand Tenuity\" (translated by Bokenkamp 1997: 331-339). This text was originally part of the Daoist Shangqing School scriptural corpus supposedly revealed to Yang Xi (330-c. 386 CE) between 364 and 370 (Komjathy 2004: 23-24).\n\nThe Purple Texts alchemical recipe for preparing Elixir of \"Langgan\" Efflorescence involves nine steps in four stages carried out over thirteen years. The first stage produces the \"Langgan\" Efflorescence proper, which when ingested is said to make \"one's complexion similar to gold and jade and enables one to summon divine beings\". The next three stages further refine and transform the \"Langgan\" Elixir, repeatedly plant it in the earth, and eventually generate a tree whose fruits confer immortality when eaten, just like those of the legendary \"langgan\" tree on Mount Kunlun (Pregadio 2008: 605). Upon completing any of the nine successive steps in producing the elixir, the alchemist (or adept in the \"neidan\" interpretation) can choose to either ingest the products and obtain immortality by ascending into the realm of Shangqing heavens or may continue on to the next step with the promise of ever-increasing rewards (Bokenkamp 1997: 290).\n\nThe first stage has one complex \"waidan\" step of compounding the primary \"Langgan\" Efflorescence. After performing ritual \"zhāi\" 齋 \"purification practices\" for 40 days, the adept spends 60 days to acquire and prepared the elixir's fourteen ingredients, place them in a crucible, add mercury on top of them, lute the crucible with several layers of mud, and after sacrificing wine to the divinities, heating the crucible for 100 days. The elixir's fourteen reagents, given in exalted code names such as \"White-Silk Flying Dragon\" for quartz, are: cinnabar, realgar, milky quartz, azurite, amethyst, graphite, saltpeter, sulfur, asbestos, mica, iron pyrite, lead carbonate, Turkestan salt (desert lake precipitates containing gypsum, anhydrite, and halite), and orpiment (Bokenkamp 1997: 334). Based upon these ingredients, Schafer says the end product was probably bluish flint glass with a high lead content (1978: 37). The alchemist can either leave the crucible closed and proceed to the next stage or break it open and consume the \"langan\" elixir that is said to yield marvelous results. \nThe efflorescence should have thirty-seven hues. It is a volatile liquid both brilliant and mottled, a purple aurora darkly flashing. This is called the Elixir of \"Langgan\" Efflorescence. If, just at dawn on the first day of the eleventh, fourth, or eighth month, you bow repeatedly and ingest one ounce of this elixir with the water from an east-flowing stream, seven-colored pneumas will rise from your head and your face will have the jadelike glow of metallic efflorescence. If you hold your breath, immediately a chariot from the eight shrouded extents of the universe will arrive. When you spit on the ground, your saliva will transform into a flying dragon. When you whistle to your left, divine Transcendents will pay court to you; when you point to the right, the vapors of Three Elementals will join with the wind. Then, in thousands of conveyances, with myriad outriders, you will fly up to Upper Clarity. (tr. Bokenkamp 1997: 336) \n\nThe second stage comprises two iterative 100-day \"waidan\" alchemical steps transforming the elixir. Firing the unopened stage one crucible of \"Langgan\" Efflorescence for another 100 days will produce the Lunar Efflorescence of the Yellow Solution [黄水月華], which when consumed will make you \"change forms ten thousand times, your eyes will become luminous moons, and you will float above in the Grand Void to fly off to the Palace of Purple Tenuity\". The next step of firing the closed crucible for an additional one 100 days will produce three giant pearls called the Jade Essence of the Swirling Solution [徊水玉精]. Ingesting one alchemical pearl supposedly causes you to immediately give off liquid and fire, form gems with your breath, and your body \"will become a sun, and the Thearchs of Heaven will descend to greet you. You will rise as a glowing orb to Upper Clarity.\" (tr. Bokenkamp 1997: 336-337).\n\nThe third stage involves four 3-year steps utilizing the elixirs produced in the first two stages to create fantastic seeds that are replanted and grow into increasingly perfected \"spirit trees\" with fruits of immortality. This stage falls between conventional \"waidan\" alchemy and the horticultural art of growing marvelous \"zhi\" 芝 \"plants of longevity; fungi\" such as the lingzhi mushroom (Needham et al. 1980: 217). Initially, the adept mixes the Elixir of \"Langgan\" Efflorescence with Jade Essence of the Swirling Solution, transforming the \"jīng\" 精 \"essence; sperm; seed\" in the latter name into an actual seed that is planted in an irrigated field. After three years it grows into the Tree of Ringed Adamant [環剛樹子] or Hidden Polypore of the Grand Bourne [太極隱芝], which has a ring-shaped fruit like a red jujube. Next, the adept plants one of the ringed fruits and waters it with the Yellow Solution, and after three years a plant called the called the Phoenix-Brain Polypore [\"fengnao zhi\" 鳳腦芝] will grow like a calabash, with pits like five-colored peaches. Then, a phoenix-brain fruit is planted and watered with Yellow Solution, which after three years will grow into a red tree, like a pine, five or six feet in height, with a jade-white fruit like a pear [赤樹白子]. Lastly, the adept plants the seed of the red tree, waters it with Swirling Solution, waits another three years for the growth of a vermilion tree like a plum, six or seven feet in height, with a halycon-blue fruit like the jujube [絳樹青實]. Upon eating this fruit, the adept will ascend to the heaven of Purple Tenuity. (tr. Bokenkamp 1997: 337-338).\n\nThe fourth stage involves two comparatively quicker \"waidan\" steps. The adept repeatedly boils equal parts of the Yellow Solution and the Swirling Solution, and transforms them into the Blue Florets of Aqueous Yang [水陽青映]. If you drink this at dawn, your body will issue a blue and gemmy light, your mouth will spew forth purple vapors, and you will rise above to Upper Clarity [\"Shangqing\"]. But before departing earth, the adept's last step is to mix the remaining Elixir of Langan Efflorescence with liquified lead and mercury to produce 50-pound ingots of alchemical silver and purple gold, make incantations to the water spirits, and throw both oblatory ingots into a stream (tr. Bokenkamp 1997: 338-339).\n\nDespite the carefully detailed Purple Texts' \"waidan\" recipe for preparing \"langgan\" elixirs, scholars have doubted that the authors actually meant for it to be produced and consumed. Some interpret the impractical 13-year elixir recipe as symbolic instructions for what later came to be known as \"neidan\" meditative visualization, and is more a \"product of religious imagination\", drawing on the respected metaphors of alchemical language, than a laboratory manual drawing on the metaphors of meditation (Bokenkamp 1997: 295). Others believe this \"extravagantly impractical recipe\" is an attempt to assimilate into conventional \"waidan\" alchemy the ancient legends about \"langgan\" gems that grow on trees in the paradise of KunIun (Needham et al. 1980: 217).\n\nThe Shangqing Daoist patriarch Tao Hongjing compiled and edited both the c. 370 \"Taiwei lingshu ziwen langgan huadan shenzhen shangjing\" and the c. 499 \"Zhen'gao\" 真誥 \"Declarations of the Perfected\" that also mentions \"langan\" elixirs in some of the same terminology. One context records that the early Daoist masters Yan Menzi 衍門子, Gao Qiuzi 高丘子, and Master Hongyai 洪涯先生 swallowed \"langgan hua\" 琅玕華 \"langgan blossoms\" to feign death and become \"xian\" transcendents and enter the \"dark region\" beyond the world. Needham and Lu proposed this \"langgan hua\" probably refers to a red or green poisonous mushroom (1974: 296), and Knoblock surmised that these \"ruby blossoms\" were a species of hallucinogenic mushroom connected with the elixir of immortality (1994: 30). Another \"Zhen'gao\" context describes how in the Shangqing latter days before the apocalypse (predicted to be in 507) people will practice alchemy to create immortality drugs, including the \"Langgan\" Elixir that \"will flow and flower in thick billows\" and Cloud \"Langgan\". If the adept takes one spatula full of elixir, \"their spiritual feathers will spread forth like pinions. Then will they (be able to) peruse the pattern figured on the Vault of Space, and glow forth in the Chamber of Primal Commencement\" (tr. Needham et al. 1980: 216).\n\nSeveral ingredients in the Elixir of \"Langgan\" Efflorescence are toxic heavy metals including mercury, lead, and arsenic, and alchemical elixir poisoning was common knowledge in China. Academics have puzzled over why Daoist adepts would knowingly consume a compound of mineral poisons, and Michel Strickmann, a scholar of Daoist and Buddhist studies, proposes that \"langgan\" elixir was believed to be an agent of self-liberation that guaranteed immortality to the faithful through a kind of ritual suicide. Since early Daoist literature thoroughly, \"even rapturously\", described the deadly toxic qualities of many elixirs, Strickmann concluded that scholars need to reexamine the Western stereotype of \"accidental elixir poisoning\" that supposedly applied to \"misguided alchemists and their unwitting imperial patrons\" (1979:191).\n\nChinese authors extended the classical descriptions of \"langgan\" meaning \"a highly valued gem from western China; a mythical tree of immortality on Kunlun Mountain\" into a literary and poetic metaphor for the exotic beauties of an idealized natural world. \nSeveral early writers described \"langgan\" jewelry, both real and fictional. The 2nd-century scholar and scientist Zhang Heng described a party for the Han nobility at which guests were delighted with the presentation of bowls overflowing with \"zhēnxiū\" 珍羞 \"delicacies; exotic foods\" including \"langgan\" fruits of paradise. The 3rd-century poet Cao Zhi described hanging \"halcyon blue\" (\"cuì\" 翠) \"langgan\" from the waist of his \"beautiful person\", and the 5th-century poet Jiang Yan adorned a goddess with gems of \"langgan\". Some other authors reinforced use of its name to refer to divine fruits on heavenly trees. Ruan Ji, one of the Seven Sages of the Bamboo Grove, wrote a 3rd-century poem titled \"Dining at Sunrise on Langgan Fruit\". The 8th-century poet Li Bai wrote about a famished but proud \"fenghuang\" that would not deign to peck at bird food, but like a Daoist adept, would scorn all but a diet of \"langgan\". This represents a literary transition from glittering fruit of distant Kunlun, to aristocratic fare in golden bowls, eventually to an elixir of immortality (Schafer 1978: 30).\n\nA further extension of the \"langgan\" metaphor was to describe natural images of beautiful crystals and lush vegetation. For example, Ban Zhao's poem on \"The Arrival of Winter\" says, \"The long [Yellow River] forms (crystalline) \"langgan\" [written \"langan\" 瓓玕] / Layered ice is like banked-up jade\". Two of Du Fu's poems figuratively used the word \"langgan\" in reference to the vegetation around the forest home of a Daoist recluse, and to the splendid grass that provided seating for guests at a royal picnic near a mysterious grotto (Schafer 1978: 31). Bamboo was the most typical representative of blue-green \"langgan\" in the plant world, compare \"láng\" 筤 (\"bamboo radical\" and the \"liáng\" phonetic in \"láng\" 琅) \"young bamboo; blue'\" (Schafer 1978: 32). Liu Yuxi wrote that the famous spotted bamboo of South China was \"\"langgan\" colored\" (Schafer 1965: 545).\n\nChinese texts list many diverse locations from where \"langgan\" occurred. \n\nSeveral classical works associate mythical \"langan\" trees with Kunlun Mountain (far west or northwest China), and two gives sources of actual \"langgan\" gemstones, the \"Shujing\" says it was tribute from Yong Province (present day Gansu and Shaanxi) and the \"Guanzi\" says the Kunlun desert (Xinjiang and Tibet).\n\nOfficial Chinese histories record \"langgan\" coming from different sources. The 3rd-century \"Weilüe\", 5th-century \"Hou Hanshu\", 6th-century \"Wei shu\", and 7th-century \"Liang shu\" list \"langgan\" among the products of Daqin, which depending on context meant the Near East or the Eastern Roman Empire, especially Syria. The \"Liang shu\" also says it was found in Kucha (modern Aksu Prefecture, Xinjiang), the 7th-century \"Jinshu\" says in Shaanxi, and the 10th-century \"Tangshu\" says in India. The \"Jiangnan Bielu\" history of the Southern Tang (937–976) says \"langgan\" was mined at Pingze 平澤 in Shu (Sichuan Province) (Laufer 1915: 205). \n\nThe Daoist scholar and alchemist Tao Hongjing (456-536) notes \"langgan\" gemstone was traditionally associated with Sichuan. The Tang pharmacologist Su Jing 蘇敬 (d. 674) reports that it came from the distant Man tribes of the Yunnan–Guizhou Plateau and Hotan/Khotan (Schafer 1978: 29-30). Accurately identifying geographic sources may be complicated by \"langgan\" referring to more than one mineral, as discussed next.\n\nThe precise referent of the Chinese name \"langgan\" 琅玕 is uncertain in the present day. Scholars have described it as an \"enigmatic archaism of politely pleasant or poetic usage\" (Schafer 1961: 41), and \"one of the most elusive terms in Chinese mineralogy\" (Needham and Lu 1974: 296). Identifications of \"langgan\" comprise at least three categories: Blue-green \"langgan\" was first recorded circa 4th century BCE, Coral \"langgan\" from the 8th century, and Red \"langgan\" is from an uncertain date.\n\nEdward H. Schafer, an eminent scholar of Tang dynasty literature and history, discussed \"langgan\" in several books and articles. His proposed identifications gradually changed from Mediterranean red coral (1961), to coral or a glass-like gem (1963), to chrysoprase or demantoid (1965), to coral or red spinel (1967), and ultimately to malachite (1978).\n\n\"Langgan\" was a \"qīng\" 青 \"green; blue; greenish black\" (see Blue–green distinction in language) gemstone of lustrous appearance mentioned in numerous classical texts. They listed it among historical imperial tribute products presented from the far western regions of China, and as the mineral-fruit of the legendary \"langgan\" trees of immortality on Mount Kunlun (Bokenkamp 1997: 289). \n\nSchafer's 1978 monograph on \"langgan\" sought to identify the treasured blue-green gemstone, if it ever had a unique identity, and concluded the most plausible identification is malachite, a bright green mineral that was anciently used as a copper ore and an ornamental stone. Two early Chinese mineralogical authorities (Chang 1921: 24, Read and Pak 1928: 21) identified \"langgan\" as malachite, commonly called \"kǒngquèshí\" 孔雀石 (lit. \"peacock stone\") or \"shílǜ\" 石綠 (lit. \"stone green\").\n\nComparing blue-green stones that were known in early East Asia, Schafer disqualified several conceivable identities; demantoid garnet and green tourmaline are rarely of gem quality, while neither apple-green chrysoprase nor light greenish-blue turquoise typically have dark hues. This leaves malachite,\nThis handsome green carbonate of copper has important credentials. It is often found in copper mines, and is therefore regularly at the disposal of copper- and bronze-producing peoples. It has, in certain varieties, a lovely silky luster, caused by its fibrous structure. It is soft and easily cut. It takes a good polish. It was commonly made into beads both in the western and eastern worlds. Above all, even uncut malachite often has a nodular or botryoidal structure, like little clumps of bright green beads, one of the classical forms attributed to \"lang-kan\". Sometimes, too, it is stalactitic, like little stone trees. (1978: 33) \nFurthermore, archeology confirms that malachite was an important gemstone of pre-Han China. Inlays of malachite and turquoise decorated many early Chinese bronze weapons and ritual vessels (MOMA 1980: 38, 188).\n\nTang sources continued to record blue-green \"langgan\". Su Jing's 652 \"Xinxiu bencao\" 新修本草 said it was a glassy substance similar to \"liúli\" 琉璃 \"colored glaze; glass; glossy gem\" that was imported from the Man tribes in the Southwest and from Khotan (Schafer 1963: 246). In 762, Emperor Daizong of Tang proclaimed a new era name of Baoying 寶應 \"Treasure Response\" in honor of the discovery of thirteen auspicious treasures in Jiangsu, one of which was glassy \"langgan\" beads (1965: 545-546).\n\nTang dynasty herbalists and pharmacists changed the denotation of \"langgan\" from the traditional blue-green gemstone to a kind of coral. Chen Cangqi's c. 720 \"Bencao shiyi\" 本草拾遺 \"Collected Addenda to the Pharmacopoeia\" described it a pale red coral, growing like a branched tree on the bottom of the sea, fished by means of nets, and after coming out of the water gradually darkens and turns blue (Schafer 1963: 246; 1967: 159).\n\n\"Langan\" already had an established connection with coral. Chinese mythology matches two antipodean paradises of Mount Kunlun in the far west and Mount Penglai located on an island in the far eastern Bohai Sea. Both mountains had mythic plants and trees of immortality that attracted Daoist \"xian\" transcendents; Kunlun's red \"langgan\" trees with blue-green fruits were paralleled by Penglai's \"shanhu shu\" 珊瑚樹 \"red coral trees\" (Schafer 1963: 246).\n\nRegarding what variety of blue or green branching coral was identified as this \"mineralized subaqueous shrub\" \"langgan\". Since it must have been a coral attractive enough to be comparable with the extravagant myths of Kunlun, Schafer suggests considering the blue coral \"Heliopora coerula\". It is the only living species in the family Helioporidae, the only octocoral known to produce a massive skeleton, and was found throughout Pacific and Indian Oceans, although the IUCN currently considers it a vulnerable species (1978: 32).\n\nDu Wan's c. 1124 \"Yunlin shipu\" mineralogy book has a section (100) on \"langgan shi\" 琅玕石 that mentions \"shanhu\" \"coral\". \nA coral-like stone found in shallow water along the coast of Ningbo Zhejiang. Some specimens are two or three feet high. They must be pulled up by ropes let down from rafts. Though white when first taken from the water, they turn a dull purple after a while. They are patterned everywhere with circles, like ginger branches, and are rather brittle. Though the natives hold … (tr. Schafer 1961: 94-95). \n\nLi Shizhen's 1578 \"Bencao Gangmu\" classic pharmacopeia objects to applying the term \"langgan\" to these marine invertebrates, which should properly be called \"shanhu\" while \"langgan\" should only be applied to the stone occurring in the mountains. Li's commentary suggests that the terminological confusion arose from the \"Shuowen jiezi\" definition of \"shanhu\" 珊瑚: 色赤生於海或生於山 \"coral is red colored and grows in the ocean or in the mountains\". This puzzling description of mountain corals was more likely a textual misunderstanding than a reference to coral fossils (Laufer 1915: 205).\n\nThe most recent, and least historically documented, identification of \"langgan\" is a red gemstone. The Chinese geologist Chang Hung-Chao (Zhang Hongzhao) propagated this explanation when his book about geological terms in Chinese literature identified \"langgan\" as malachite, and noted an alternative construal of reddish spinel or balas ruby from the famous mines at Badakhshan (1921: 26-27, 24). Some authors have cited Chang's balas ruby identification of \"langgan\" (e.g., Needham and Lu 1974: 180); others have used, or even confused, it with ruby, in translations (e.g., \"precious rubies\" Knoblock 1994: 44).\n\nHowever, Schafer demonstrates that Chang's \"supposed\" textual evidence for red \"langgan\" is tenuous and suggests that Guo Pu's \"Shanhai jing\" commentary created this mineralogical confusion. Guo glosses the \"langgan\" tree as red, but is unclear whether this refers to the tree itself or its gem-like fruit. Compare Birrell's and Bokencamp's \"Shanhai jing\" translations of \"red jade\" and \"green kernels from scarlet gem trees\" (2000: 174; 1997: 312). Chang misquotes \"dan'gan\" 丹矸 \"cinnabar rock\" from the \"Xunzi\" as \"dan'gan\" 丹玕 \"cinnabar \"gan\"\", and cites one textual occurrence of the term. The Shangqing Daoist \"Dadong zhenjing\" 大洞真經 Authentic Scripture of the Great Cavern records a heavenly palace named Dan'gan dian 丹玕殿 Basilica of the Cinnabar \"Gan\". Admitting the possibility of interpreting \"gan\" 玕 as a monosyllabic truncation for \"langgan\" 琅玕, comparable with reading \"hongpo\" 红珀 for \"honghupo\" 红琥珀 \"red amber\", Schafer concludes there is insufficient \"dan'gan\" evidence for an explicit red variety of \"langgan\" (1978: 28). \n\nThe lyrical term \"langgan\" occurs 87 times in the huge \"Quan Tangshi\" collection of Tang poetry, with only two \"hong langgen\" 紅琅玕 \"red \"langgan\"\" usages by the Buddhist monk-poets Guanxiu (831-912) and Ji Qi 齊己 (863-937). Both poems use \"langgan\" to describe \"red coral\", the latter (贈念法華經) uses \"shanhu\" in the same line: 珊瑚捶打紅琅玕 \"coral beating on red \"langgan\"\" in cold waters.\n\nChinese-English dictionaries illustrate the multifaceted difficulties of identifying \"langgan\". Compare the following list.\n\nMost of these bilingual Chinese dictionaries cross-reference \"lang\" and \"gan\" to \"langgan\", but a few translate \"lang\" and \"gan\" independently. In terms of Chinese word morphology, \"láng\" 琅 is a free morpheme that can appear alone (for instance, a surname) or in other compound words (such as \"fàláng\" 琺琅 \"enamel\" and \"Lángyá shān\" 琅琊山 \"Mount Langya (Anhui)\") while \"gān\" 玕 is a bound morpheme that only occurs in the compound \"lánggān\" and does not have independent meaning.\n\nThe origin of Giles' \"lang\" translation \"a kind of white carnelian\" is unknown, unless it derives from Williams' \"a whitish stone\". It was copied in Mathews' and various other Chinese dictionaries up to the online standard Unihan Database \"a variety of white carnelian; pure\". \"White carnelian\" is a marketing name for \"white or whitish chalcedony of faint carnelian color\" (Manutchehr-Danai 2000: 507). Carnelian is usually reddish-brown while common chalcedony colors are white, grey, brown, and blue.\n\n\n"}
{"id": "3254251", "url": "https://en.wikipedia.org/wiki?curid=3254251", "title": "List of Cambridge mathematicians", "text": "List of Cambridge mathematicians\n\n\"A list of mathematicians, past and present, with associations with the University of Cambridge.\"\n\n\n\n\n\n"}
{"id": "88231", "url": "https://en.wikipedia.org/wiki?curid=88231", "title": "List of IBM products", "text": "List of IBM products\n\nThe following is a partial list of products, services, and subsidiaries of International Business Machines (IBM) Corporation and its predecessor corporations, beginning in the 1890s. \n\nThis list is eclectic; it includes, for example, the \"AN/FSQ-7\", which was not a product in the sense of \"offered for sale\", but was a product in the sense of \"manufactured—produced by the labor of IBM\". Several machines manufactured for the Astronomical Computing Bureau at Columbia University are included, as are some machines built only as demonstrations of IBM technology. Missing are RPQs, OEM products (semiconductors, for example), and supplies (punched cards, for example). These products and others are missing simply because no one has added them.\n\nIBM sometimes uses the same number for a system and for the principal component of that system. For example, the IBM 604 Calculating Unit is a component of the IBM 604 Calculating Punch. And different IBM divisions used the same model numbers; for example \"IBM 01\" without context clues could be a reference to a keypunch or to IBM's first electric typewriter.\n\nNumber sequence may not correspond to product development sequence. For example, the 402 tabulator was an improved, modernized, 405. \n\nIBM uses two naming structures for its modern hardware products. Products are normally given a three- or four-digit machine type and a model number (can be a mix of letters and numbers). A product may also have a marketing or brand name. For instance, 2107 is the machine type for the IBM System Storage DS8000. While the majority of products are listed here by machine type, there are instances where only a marketing or brand name is used. Care should be taken when searching for a particular product as sometimes the type and model numbers overlap. For instance the IBM storage product known as the Enterprise Storage Server is machine type 2105, and the IBM printing product known as the IBM Infoprint 2105 is machine type 2705, so searching for an IBM 2105 could result in two different products—or the wrong product—being found.\n\nIBM introduced the 80-column rectangular hole punched card in 1928. Pre-1928 machine models that continued in production with the new 80-column card format had the same model number as before. Machines manufactured prior to 1928 were, in some cases, retrofitted with 80-column card readers and/or punches thus there existed machines with pre-1928 dates of manufacture that contain 1928 technology.\n\nThis list is organized by classifications of both machines and applications, rather than by product name. Thus some (few) entries will be duplicated. The 1420, for example, is listed both as a member of the 1401 family and as a machine for Bank and finance.\n\nIBM product names have varied over the years; for example these two texts both reference the same product.\nThis article uses the name, or combination of names, most descriptive of the product. Thus the entry for the above is \n\nProducts of The Tabulating Machine Company can be identified by date, before 1933 when the subsidiaries were merged into IBM. \n\n\n\n\n\n\n\n402 and known versions\n\n404\n\n405 and known versions\n\n407 and known versions\n\n\nIBM manufactured a range of clocks and other devices until 1958 when they sold the Time Equipment Division to Simplex Time Recorder Company (SimplexGrinnell, as of 2001). See:\n\n\n\n\n\"The IBM line of Copier/Duplicators, and their associated service contracts, were sold to Eastman Kodak in 1988.\"\n\n\n\nFor these computers most components were unique to a specific computer and are shown here immediately following the computer entry.\n\n\n\"Further information\": IBM mainframe, IBM minicomputer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn IBM's terminology beginning with the System/360 disk and such devices featuring short access times were collectively called DASD. The IBM 2321 Data Cell is a DASD that used tape as its storage medium. See also history of IBM magnetic disk drives.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome software listings are for software families, not products (\"Fortran\" was not a product; \"Fortran H\" was a product).\n\nSome IBM software products were distributed free (no charge for the software itself, a common practice early in the industry). The term \"Program Product\" was used by IBM to denote that it's freely available but not for free. Prior to June 1969, the majority of software packages written by IBM were available at no charge to IBM customers; with the June 1969 announcement, new software not designated as \"System Control Programming\" became Program Products, although existing non-system software remained available for free.\n\n\n\nIBM distributes its diverse collection of software products over several brands; mainly:\n\n\nThe Watson Customer Engagement (commonly known as WCE and formerly known as IBM Commerce) business unit supports marketing, commerce, and supply chain software development and product offerings for IBM. Software and solutions offered as part of these three portfolios by WCE are as follows:\n\n\n\n\n\n\n\n\n"}
{"id": "57776440", "url": "https://en.wikipedia.org/wiki?curid=57776440", "title": "List of LTE networks in Africa", "text": "List of LTE networks in Africa\n\nThis is a list of commercial Long-Term Evolution (LTE) networks in Africa, grouped by their frequency bands.\n\nSome operators use multiple bands and are therefore listed multiple times in respective sections.\n\n\nNote: This list of network deployments does not imply any widespread deployment or national coverage.\n\n"}
{"id": "8953588", "url": "https://en.wikipedia.org/wiki?curid=8953588", "title": "List of computer system manufacturers", "text": "List of computer system manufacturers\n\nThe following is a list of notable computer system manufacturers.\n\n\n\nepocalc's List of Computer Manufacturers\n"}
{"id": "2705217", "url": "https://en.wikipedia.org/wiki?curid=2705217", "title": "List of countries by HIV/AIDS adult prevalence rate", "text": "List of countries by HIV/AIDS adult prevalence rate\n\nThe human immunodeficiency virus (HIV), which causes AIDS, varies in prevalence from nation to nation. Listed here are the prevalence rates among adults in various countries, based on data from various sources, largely the CIA World Factbook.\n\nAs of 2015, it is estimated that there are 36.7 million people worldwide infected with HIV.\n\nThe HIV pandemic is most severe in South Africa. Over 10% of all people living with HIV/AIDS reside within the region. Adult HIV prevalence exceeds 20% in Eswatini (Swaziland), Botswana, and Lesotho, while an additional six countries report adult HIV prevalence of at least 10%. Outside Africa, the highest prevalence rate is found in the Bahamas (3.3%).\n\nIn absolute numbers, South Africa (7.1 million), followed by Nigeria (3.2 million), and India (2.1 million) had the highest HIV/AIDS number of cases by the end of 2016. While South Africa's large population of HIV-positive people is attributable to its high disease prevalence (18.9%, one of the highest in the world), Nigeria's is lower at 2.9%, with India's prevalence rate at 0.3%.. However, countries such as Nigeria with high HIV rates above 1% are classified as having Generalized HIV Epidemics (GHEs) by UNAIDS, while India's prevalence is well below this threshold, with a prevalence lower than America's and about the same as France .\n\nOn the other end of the spectrum, Svalbard is reported as having no cases of HIV/AIDS, while Bhutan has a much larger population but still only an estimated 246 cases through 2011.\n\nThis data was sourced from the CIA's world factbook unless referenced otherwise. A horizontal dash - indicates the data was not published. Adult prevalence describes ages between 15-49.\n\n\nBy region:\n\n"}
{"id": "14485830", "url": "https://en.wikipedia.org/wiki?curid=14485830", "title": "List of members of the National Academy of Sciences (Human environmental sciences)", "text": "List of members of the National Academy of Sciences (Human environmental sciences)\n"}
{"id": "55715420", "url": "https://en.wikipedia.org/wiki?curid=55715420", "title": "List of national parks of Kyrgyzstan", "text": "List of national parks of Kyrgyzstan\n\nAs of 2017, there are 13 nature national parks (IUCN Category II) in Kyrgyzstan occupying 724,670.2 hectares. The first park - Kyrgyz National Park Ala-Archa - was established in 1976.\n"}
{"id": "660973", "url": "https://en.wikipedia.org/wiki?curid=660973", "title": "List of string theory topics", "text": "List of string theory topics\n\nThis is a list of string theory topics.\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "164969", "url": "https://en.wikipedia.org/wiki?curid=164969", "title": "Magdeburg hemispheres", "text": "Magdeburg hemispheres\n\nThe Magdeburg hemispheres are a pair of large copper hemispheres, with mating rims. They were used to demonstrate the power of atmospheric pressure. When the rims were sealed with grease and the air was pumped out, the sphere contained a vacuum and could not be pulled apart by teams of horses. The Magdeburg hemispheres were designed by a German scientist and mayor of Magdeburg, Otto von Guericke, to demonstrate the air pump that he had invented, and the concept of atmospheric pressure. The first artificial vacuum had been produced a few years earlier by Evangelista Torricelli, and had inspired Guericke to design the world's first vacuum pump, which consisted of a piston and cylinder with one-way flap valves. The hemispheres became popular in physics lectures as an illustration of the strength of air pressure, and are still used in education. A pair of the original hemispheres are preserved in the Deutsches Museum in Munich.\n\nThe Magdeburg hemispheres, around 50 cm (20 inches) in diameter, were designed to demonstrate the vacuum pump that Guericke had invented. One of them had a tube connection to attach the pump, with a valve to close it off. When the air was sucked out from inside the hemispheres, and the valve was closed, the hose from the pump could be detached, and they were held firmly together by the air pressure of the surrounding atmosphere.\n\nThe force holding the hemispheres together was equal to the area bounded by the joint between the hemispheres, a circle with a diameter of 50 cm, multiplied by the difference in air pressure between the inside and the outside. It is unclear how strong a vacuum Guericke's pump was able to achieve, but if it was able to evacuate all of the air from the inside, the hemispheres would have been held together with a force of around 20 000 N (4400 lbf, or 2.2 short tons), equivalent to lifting a car or small elephant; a dramatic demonstration of the pressure of the atmosphere.\n\nGuericke's demonstration was performed on 8 May 1654 in front of the Imperial Diet, and the Emperor Ferdinand III in Regensburg. Thirty horses, in two teams of fifteen, could not separate the hemispheres until the valve was opened to equalize the air pressure. In 1656 he repeated the demonstration with sixteen horses (two teams of eight) in his hometown of Magdeburg, where he was mayor. He also took the two spheres, hung the two hemispheres with a support, and removed the air from within. He then strapped weights to the spheres, but the spheres would not budge. Gaspar Schott was the first to describe the experiment in print in his \"Mechanica Hydraulico-Pneumatica\" (1657). In 1663 (or, according to some sources, in 1661) the same demonstration was given in Berlin before Frederick William, Elector of Brandenburg with twenty-four horses.\n\nThe experiment became a popular way to illustrate the principles of air pressure, and many smaller copies of the hemispheres were made, and are used to this day in science classes. Reenactments of von Guericke's experiment of 1654 are performed in locations around the world by the Otto von Guericke Society. On 18 March 2000, a demonstration using sixteen horses was conducted in Great Torrington by Barometer World.\n\nThe experiment has been commemorated on at least two German stamps.\n\nAfter learning about Guericke's pump through Schott's book, Robert Boyle worked with Robert Hooke to design and build an improved air pump. From this, through various experiments, they formulated what is called Boyle's law, which states that the volume of a body of an ideal gas is inversely proportional to its pressure. Much later the ideal gas law was formulated in 1834.\n\n\n\n"}
{"id": "29857137", "url": "https://en.wikipedia.org/wiki?curid=29857137", "title": "Marconi's law", "text": "Marconi's law\n\nMarconi's law is the relation between length of antennas and maximum signaling distance of radio transmissions. Guglielmo Marconi enunciated at one time an empirical law that, for simple vertical sending and receiving antennas of equal height, the maximum working telegraphic distance varied as the square of the height of the antenna. It has been stated that the rule was tested in experiments made on Salisbury Plain in 1897, and also by experiments made by Italian naval officers on behalf of the Royal Italian Navy in 1900 and 1901. Captain Quintino Bonomo gave a report of these experiments in an official report.\n\nIf \"H\" is the height (i.e. the length) of the antenna and \"D\" the maximum signalling distance, then we have, according to \"Marconi's law\"\nwhere \"c\" is some constant.\n\n\"Marconi's law\" can be deduced theoretically as follows:\nHertz has shown that distances large compared with its length the magnetic force of a linear oscillator varies inversely as the distance. The maximum value of the current set up in any given receiving antenna varies as its length, also as the magnetic force of the waves incident on it, and as the maximum value of the current in the transmitting antenna. Hence, if formula_2 is the magnetic force of the waves incident on a receiving antenna of height H, and if formula_3 is the distance between the sending and receiving antenna, and if formula_4 and formula_5 are the maximum values of the currents in the sending and receiving antennæ, we have—\n\nformula_6 and formula_7\n\nHence formula_8\n\nAlso, since for a given charging voltage the current formula_4 in the sending antenna varies very nearly as its capacity—that is, as its height—and if the sending antenna has the same height, formula_10, as the receiving aerial, we have—\n\nformula_11\n\nBut formula_12\n\nTherefore formula_13 some constant\n\nFor any given receiving apparatus a certain constant minimum value of the maximum current in the receiving antenna is necessary to cause a signal. Therefore it follows that, with given receiving and sending apparatus, we must have formula_14 a constant, or—\n\nformula_1\n\nThat is, the maximum signalling distance with given apparatus will vary as the square of the height of the antenna.\n\nThe above law is, however, much interfered with by the nature of the surface over which the propagation takes place.\n\n\n"}
{"id": "24118168", "url": "https://en.wikipedia.org/wiki?curid=24118168", "title": "Nano spray dryer", "text": "Nano spray dryer\n\nNano spray dryers refer to using spray drying to create particles in the nanometer range. Spray drying is a gentle method for producing powders with a defined particle size out of solutions, dispersions, and emulsions which is widely used for pharmaceuticals, food, biotechnology, and other industrial materials synthesis. \n\nIn the past, the limitations of spray drying were the particle size (minimum 2 micrometres), the yield (maximum around 70%), and the sample volume (minimum 50 ml for devices in lab scale). Recently, minimum particle sizes have been reduced to 300 nm, yields up to 90% are possible, and the sample amount can be as small as 1 ml. These expanded limits are possible due to new technological developments to the spray head, the heating system, and the electrostatic particle collector. To emphasize the small particle sizes possible with this new technology, it has been described as \"nano\" spray drying. However, the smallest particles produced are in the sub-micrometre range common to fine particles rather than the nanometer scale of ultrafine particles.\nThe functional principle is basically the same as with normal spray dryers. There are just different technologies that are used to do similar things.\n\nThe drying gas enters the system via the heater. A new kind of heater system allows for laminar air flow. The spray head sprays the fine droplets with a narrow size distribution into the drying chamber. The droplets dry and become solid particles. The solid particles are separated in the electrostatic particle collector. The exhaust gas is filtered and sent to a fume hood or the environment. The inlet temperature is controlled by a temperature sensor.\n\nPharmaceuticals:\nThis technique is widely used in the pharma market. Because of the small sample amounts and the high yields it is ideal for spray drying expensive substances in basic research. The following list shows examples of what is possible:\n\n\nMaterials science:\nThis new technique offers new prospects in materials science, specially in the nanomaterial field. Now it is possible to spray dry fine particles. The following list shows examples of what is possible:\n\nFood:\nAlso in the field of food science this technology offers new possibilities. Especially in the currently vibrant field of functional food, the following list shows examples of what is possible:\nOne of the three new technologies that makes \"nano\" spray drying possible is the spray head. \nA piezoelectric system precisely vibrates a fine mesh. Vibration produces fine droplets with a narrow size distribution.\n\nIn the field of \"nano\" spray drying a new heating system is used to provide the drying gas to produce the particles. The gas flow in the system is laminar and not turbulent as in common spray drying. The advantage of a laminar flow is that the particles fall straight down from the spray head and do not stick to the glass wall.\n\nThe laminar flow is produced by pressing the air through a porous metal foam.\n\nTo collect the very fine particles a new technology is used in the field of \"nano\" spray drying. The reason is that common cyclone technology depends on the particle mass; particles smaller than 2 μm can’t be separated and instead exit the system along with the exhaust gas.\n\nThe electrostatic particle collector charges the dry particles' surface and deflects them with an electrical field. To produce the electrical field, a high voltage (16 kV) is applied to a round collector tube. The electrical field builds up between the inner wall of the collector tube and the tips of a grounded star electrode. To have a low level of energy in the system the current is very low.\n\nAfter getting deflected the particles stay at the inner wall of the particle collector tube and are completely uncharged. This separation method works fine for all kinds of materials.\n\nThe efficiency of the electrostatic particle collector is very high: 99% of all particles that enter the system are collected.\n"}
{"id": "42159637", "url": "https://en.wikipedia.org/wiki?curid=42159637", "title": "Open-source computing hardware", "text": "Open-source computing hardware\n\nOpen-source computing hardware comprises computers and computer components with an open design. They are designed as open-source hardware using open-source principles.\nHardware that uses closed source components\n\n\n\n\n\n\n\nHardware that has no closed source dependencies\n\n\n\n\n\n\n"}
{"id": "253166", "url": "https://en.wikipedia.org/wiki?curid=253166", "title": "Operation Tinderbox", "text": "Operation Tinderbox\n\nOperation Tinderbox was a series of 14 nuclear tests conducted by the United States in 1979-1980 at the Nevada Test Site. These tests followed the \"Operation Quicksilver\" series and preceded the \"Operation Guardian\" series.\n"}
{"id": "5386941", "url": "https://en.wikipedia.org/wiki?curid=5386941", "title": "Osmotic shock", "text": "Osmotic shock\n\nOsmotic shock or osmotic stress is physiologic dysfunction caused by a sudden change in the solute concentration around a cell, which causes a rapid change in the movement of water across its cell membrane. Under conditions of high concentrations of either salts, substrates or any solute in the supernatant, water is drawn out of the cells through osmosis. This also inhibits the transport of substrates and cofactors into the cell thus “shocking” the cell. Alternatively, at low concentrations of solutes, water enters the cell in large amounts, causing it to swell and either burst or undergo apoptosis.\n\nAll organisms have mechanisms to respond to osmotic shock, with sensors and signal transduction networks providing information to the cell about the osmolarity of its surroundings; these signals activate responses to deal with extreme conditions. Although single-celled organisms are more vulnerable to osmotic shock, since they are directly exposed to their environment, cells in large animals such as mammals still suffer these stresses under some conditions. Current research also suggests that osmotic stress in cells and tissues may significantly contribute to many human diseases.\n\nIn eukaryotes, calcium acts as one of the primary regulators of osmotic stress. Intracellular calcium levels rise during hypo-osmotic and hyper-osmotic stresses. \n\nextracellular sequestering of Calcium by blood Albumin.\n\nTransient intracellular Ca increase.\n\nintracellular Ca increase and Extracellular ATP Release\n\nCalcium dependent efflux of the osmolyte Taurine. Extracellular calcium removal was found to prevent Taurine efflux by 50%, and removal of extracellular Ca and simultaneous depletion of intracellular Ca stores with thapsigargin decreased it by 85%.\n\n"}
{"id": "24544", "url": "https://en.wikipedia.org/wiki?curid=24544", "title": "Photosynthesis", "text": "Photosynthesis\n\nPhotosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organisms' activities. This chemical energy is stored in carbohydrate molecules, such as sugars, which are synthesized from carbon dioxide and water – hence the name \"photosynthesis\", from the Greek φῶς, \"phōs\", \"light\", and σύνθεσις, \"synthesis\", \"putting together\". In most cases, oxygen is also released as a waste product. Most plants, most algae, and cyanobacteria perform photosynthesis; such organisms are called photoautotrophs. Photosynthesis is largely responsible for producing and maintaining the oxygen content of the Earth's atmosphere, and supplies all of the organic compounds and most of the energy necessary for life on Earth.\n\nAlthough photosynthesis is performed differently by different species, the process always begins when energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments. In plants, these proteins are held inside organelles called chloroplasts, which are most abundant in leaf cells, while in bacteria they are embedded in the plasma membrane. In these light-dependent reactions, some energy is used to strip electrons from suitable substances, such as water, producing oxygen gas. The hydrogen freed by the splitting of water is used in the creation of two further compounds that serve as short-term stores of energy, enabling its transfer to drive other reactions: these compounds are reduced nicotinamide adenine dinucleotide phosphate (NADPH) and adenosine triphosphate (ATP), the \"energy currency\" of cells.\n\nIn plants, algae and cyanobacteria, long-term energy storage in the form of sugars is produced by a subsequent sequence of reactions called the Calvin cycle; some bacteria use different mechanisms, such as the reverse Krebs cycle, to achieve the same end. In the Calvin cycle, atmospheric carbon dioxide is incorporated into already existing organic carbon compounds, such as ribulose bisphosphate (RuBP). Using the ATP and NADPH produced by the light-dependent reactions, the resulting compounds are then reduced and removed to form further carbohydrates, such as glucose.\n\nThe first photosynthetic organisms probably evolved early in the evolutionary history of life and most likely used reducing agents such as hydrogen or hydrogen sulfide, rather than water, as sources of electrons. Cyanobacteria appeared later; the excess oxygen they produced contributed directly to the oxygenation of the Earth, which rendered the evolution of complex life possible. Today, the average rate of energy capture by photosynthesis globally is approximately 130 terawatts, which is about three times the current power consumption of human civilization.\nPhotosynthetic organisms also convert around 100–115 thousand million tonnes of carbon into biomass per year.\n\nPhotosynthetic organisms are photoautotrophs, which means that they are able to synthesize food directly from carbon dioxide and water using energy from light. However, not all organisms use carbon dioxide as a source of carbon atoms to carry out photosynthesis; photoheterotrophs use organic compounds, rather than carbon dioxide, as a source of carbon. In plants, algae, and cyanobacteria, photosynthesis releases oxygen. This is called \"oxygenic photosynthesis\" and is by far the most common type of photosynthesis used by living organisms. Although there are some differences between oxygenic photosynthesis in plants, algae, and cyanobacteria, the overall process is quite similar in these organisms. There are also many varieties of anoxygenic photosynthesis, used mostly by certain types of bacteria, which consume carbon dioxide but do not release oxygen.\n\nCarbon dioxide is converted into sugars in a process called carbon fixation; photosynthesis captures energy from sunlight to convert carbon dioxide into carbohydrate. Carbon fixation is an endothermic redox reaction. In general outline, photosynthesis is the opposite of cellular respiration: while photosyntesis is a process of reduction of carbon dioxide to carbohydrate, cellular respiration is the oxidation of carbohydrate or other nutrients to carbon dioxide. Nutrients used in cellular respiration include carbohydrates, amino acids and fatty acids. These nutrients are oxidized to produce carbon dioxide and water, and to release chemical energy to drive the organism's metabolism. Photosynthesis and cellular respiration are distinct processes, as they take place through different sequences of chemical reactions and in different cellular compartments.\n\nThe general equation for photosynthesis as first proposed by Cornelis van Niel is therefore:\n\nSince water is used as the electron donor in oxygenic photosynthesis, the equation for this process is:\n\nThis equation emphasizes that water is both a reactant in the light-dependent reaction and a product of the light-independent reaction, but canceling \"n\" water molecules from each side gives the net equation:\n\nOther processes substitute other compounds (such as arsenite) for water in the electron-supply role; for example some microbes use sunlight to oxidize arsenite to arsenate: The equation for this reaction is:\n\nPhotosynthesis occurs in two stages. In the first stage, \"light-dependent reactions\" or \"light reactions\" capture the energy of light and use it to make the energy-storage molecules ATP and NADPH. During the second stage, the \"light-independent reactions\" use these products to capture and reduce carbon dioxide.\n\nMost organisms that utilize oxygenic photosynthesis use visible light for the light-dependent reactions, although at least three use shortwave infrared or, more specifically, far-red radiation.\n\nSome organisms employ even more radical variants of photosynthesis. Some archaea use a simpler method that employs a pigment similar to those used for vision in animals. The bacteriorhodopsin changes its configuration in response to sunlight, acting as a proton pump. This produces a proton gradient more directly, which is then converted to chemical energy. The process does not involve carbon dioxide fixation and does not release oxygen, and seems to have evolved separately from the more common types of photosynthesis.\n\nIn photosynthetic bacteria, the proteins that gather light for photosynthesis are embedded in cell membranes. In its simplest form, this involves the membrane surrounding the cell itself. However, the membrane may be tightly folded into cylindrical sheets called thylakoids, or bunched up into round vesicles called \"intracytoplasmic membranes\". These structures can fill most of the interior of a cell, giving the membrane a very large surface area and therefore increasing the amount of light that the bacteria can absorb.\n\nIn plants and algae, photosynthesis takes place in organelles called chloroplasts. A typical plant cell contains about 10 to 100 chloroplasts. The chloroplast is enclosed by a membrane. This membrane is composed of a phospholipid inner membrane, a phospholipid outer membrane, and an intermembrane space. Enclosed by the membrane is an aqueous fluid called the stroma. Embedded within the stroma are stacks of thylakoids (grana), which are the site of photosynthesis. The thylakoids appear as flattened disks. The thylakoid itself is enclosed by the thylakoid membrane, and within the enclosed volume is a lumen or thylakoid space. Embedded in the thylakoid membrane are integral and peripheral membrane protein complexes of the photosynthetic system.\n\nPlants absorb light primarily using the pigment chlorophyll. The green part of the light spectrum is not absorbed but is reflected which is the reason that most plants have a green color. Besides chlorophyll, plants also use pigments such as carotenes and xanthophylls. Algae also use chlorophyll, but various other pigments are present, such as phycocyanin, carotenes, and xanthophylls in green algae, phycoerythrin in red algae (rhodophytes) and fucoxanthin in brown algae and diatoms resulting in a wide variety of colors.\n\nThese pigments are embedded in plants and algae in complexes called antenna proteins. In such proteins, the pigments are arranged to work together. Such a combination of proteins is also called a light-harvesting complex.\n\nAlthough all cells in the green parts of a plant have chloroplasts, the majority of those are found in specially adapted structures called leaves. Certain species adapted to conditions of strong sunlight and aridity, such as many Euphorbia and cactus species, have their main photosynthetic organs in their stems. The cells in the interior tissues of a leaf, called the mesophyll, can contain between 450,000 and 800,000 chloroplasts for every square millimeter of leaf. The surface of the leaf is coated with a water-resistant waxy cuticle that protects the leaf from excessive evaporation of water and decreases the absorption of ultraviolet or blue light to reduce heating. The transparent epidermis layer allows light to pass through to the palisade mesophyll cells where most of the photosynthesis takes place.\n\nIn the light-dependent reactions, one molecule of the pigment chlorophyll absorbs one photon and loses one electron. This electron is passed to a modified form of chlorophyll called pheophytin, which passes the electron to a quinone molecule, starting the flow of electrons down an electron transport chain that leads to the ultimate reduction of NADP to NADPH. In addition, this creates a proton gradient (energy gradient) across the chloroplast membrane, which is used by ATP synthase in the synthesis of ATP. The chlorophyll molecule ultimately regains the electron it lost when a water molecule is split in a process called photolysis, which releases a dioxygen (O) molecule as a waste product.\n\nThe overall equation for the light-dependent reactions under the conditions of non-cyclic electron flow in green plants is:\n\nNot all wavelengths of light can support photosynthesis. The photosynthetic action spectrum depends on the type of accessory pigments present. For example, in green plants, the action spectrum resembles the absorption spectrum for chlorophylls and carotenoids with absorption peaks in violet-blue and red light. In red algae, the action spectrum is blue-green light, which allows these algae to use the blue end of the spectrum to grow in the deeper waters that filter out the longer wavelengths (red light) used by above ground green plants. The non-absorbed part of the light spectrum is what gives photosynthetic organisms their color (e.g., green plants, red algae, purple bacteria) and is the least effective for photosynthesis in the respective organisms.\n\nIn plants, light-dependent reactions occur in the thylakoid membranes of the chloroplasts where they drive the synthesis of ATP and NADPH. The light-dependent reactions are of two forms: cyclic and non-cyclic.\n\nIn the non-cyclic reaction, the photons are captured in the light-harvesting antenna complexes of photosystem II by chlorophyll and other accessory pigments (see diagram at right). The absorption of a photon by the antenna complex frees an electron by a process called photoinduced charge separation. The antenna system is at the core of the chlorophyll molecule of the photosystem II reaction center. That freed electron is transferred to the primary electron-acceptor molecule, pheophytin. As the electrons are shuttled through an electron transport chain (the so-called Z-scheme shown in the diagram), it initially functions to generate a chemiosmotic potential by pumping proton cations (H) across the membrane and into the thylakoid space. An ATP synthase enzyme uses that chemiosmotic potential to make ATP during photophosphorylation, whereas NADPH is a product of the terminal redox reaction in the \"Z-scheme\". The electron enters a chlorophyll molecule in Photosystem I. There it is further excited by the light absorbed by that photosystem. The electron is then passed along a chain of electron acceptors to which it transfers some of its energy. The energy delivered to the electron acceptors is used to move hydrogen ions across the thylakoid membrane into the lumen. The electron is eventually used to reduce the co-enzyme NADP with a H to NADPH (which has functions in the light-independent reaction); at that point, the path of that electron ends.\n\nThe cyclic reaction is similar to that of the non-cyclic, but differs in that it generates only ATP, and no reduced NADP (NADPH) is created. The cyclic reaction takes place only at photosystem I. Once the electron is displaced from the photosystem, the electron is passed down the electron acceptor molecules and returns to photosystem I, from where it was emitted, hence the name \"cyclic reaction\".\n\nThe NADPH is the main reducing agent produced by chloroplasts, which then goes on to provide a source of energetic electrons in other cellular reactions. Its production leaves chlorophyll in photosystem I with a deficit of electrons (chlorophyll has been oxidized), which must be balanced by some other reducing agent that will supply the missing electron. The excited electrons lost from chlorophyll from photosystem I are supplied from the electron transport chain by plastocyanin. However, since photosystem II is the first step of the \"Z-scheme\", an external source of electrons is required to reduce its oxidized chlorophyll \"a\" molecules. The source of electrons in green-plant and cyanobacterial photosynthesis is water. Two water molecules are oxidized by four successive charge-separation reactions by photosystem II to yield a molecule of diatomic oxygen and four hydrogen ions; the electrons yielded are transferred to a redox-active tyrosine residue that then reduces the oxidized chlorophyll \"a\" (called P680) that serves as the primary light-driven electron donor in the photosystem II reaction center. That photo receptor is in effect reset and is then able to repeat the absorption of another photon and the release of another photo-dissociated electron. The oxidation of water is catalyzed in photosystem II by a redox-active structure that contains four manganese ions and a calcium ion; this oxygen-evolving complex binds two water molecules and contains the four oxidizing equivalents that are used to drive the water-oxidizing reaction (Dolai's S-state diagrams). Photosystem II is the only known biological enzyme that carries out this oxidation of water. The hydrogen ions released contribute to the transmembrane chemiosmotic potential that leads to ATP synthesis. Oxygen is a waste product of light-dependent reactions, but the majority of organisms on Earth use oxygen for cellular respiration, including photosynthetic organisms.\n\nIn the light-independent (or \"dark\") reactions, the enzyme RuBisCO captures CO from the atmosphere and, in a process called the Calvin cycle, it uses the newly formed NADPH and releases three-carbon sugars, which are later combined to form sucrose and starch. The overall equation for the light-independent reactions in green plants is\n\nCarbon fixation produces the intermediate three-carbon sugar product, which is then converted into the final carbohydrate products. The simple carbon sugars produced by photosynthesis are then used in the forming of other organic compounds, such as the building material cellulose, the precursors for lipid and amino acid biosynthesis, or as a fuel in cellular respiration. The latter occurs not only in plants but also in animals when the energy from plants is passed through a food chain.\n\nThe fixation or reduction of carbon dioxide is a process in which carbon dioxide combines with a five-carbon sugar, ribulose 1,5-bisphosphate, to yield two molecules of a three-carbon compound, glycerate 3-phosphate, also known as 3-phosphoglycerate. Glycerate 3-phosphate, in the presence of ATP and NADPH produced during the light-dependent stages, is reduced to glyceraldehyde 3-phosphate. This product is also referred to as 3-phosphoglyceraldehyde (PGAL) or, more generically, as triose phosphate. Most (5 out of 6 molecules) of the glyceraldehyde 3-phosphate produced is used to regenerate ribulose 1,5-bisphosphate so the process can continue. The triose phosphates not thus \"recycled\" often condense to form hexose phosphates, which ultimately yield sucrose, starch and cellulose. The sugars produced during carbon metabolism yield carbon skeletons that can be used for other metabolic reactions like the production of amino acids and lipids.\n\nIn hot and dry conditions, plants close their stomata to prevent water loss. Under these conditions, will decrease and oxygen gas, produced by the light reactions of photosynthesis, will increase, causing an increase of photorespiration by the oxygenase activity of ribulose-1,5-bisphosphate carboxylase/oxygenase and decrease in carbon fixation. Some plants have evolved mechanisms to increase the concentration in the leaves under these conditions.\n\nPlants that use the C carbon fixation process chemically fix carbon dioxide in the cells of the mesophyll by adding it to the three-carbon molecule phosphoenolpyruvate (PEP), a reaction catalyzed by an enzyme called PEP carboxylase, creating the four-carbon organic acid oxaloacetic acid. Oxaloacetic acid or malate synthesized by this process is then translocated to specialized bundle sheath cells where the enzyme RuBisCO and other Calvin cycle enzymes are located, and where released by decarboxylation of the four-carbon acids is then fixed by RuBisCO activity to the three-carbon 3-phosphoglyceric acids. The physical separation of RuBisCO from the oxygen-generating light reactions reduces photorespiration and increases fixation and, thus, the photosynthetic capacity of the leaf. plants can produce more sugar than plants in conditions of high light and temperature. Many important crop plants are plants, including maize, sorghum, sugarcane, and millet. Plants that do not use PEP-carboxylase in carbon fixation are called C plants because the primary carboxylation reaction, catalyzed by RuBisCO, produces the three-carbon 3-phosphoglyceric acids directly in the Calvin-Benson cycle. Over 90% of plants use carbon fixation, compared to 3% that use carbon fixation; however, the evolution of in over 60 plant lineages makes it a striking example of convergent evolution.\n\nXerophytes, such as cacti and most succulents, also use PEP carboxylase to capture carbon dioxide in a process called Crassulacean acid metabolism (CAM). In contrast to metabolism, which \"spatially\" separates the fixation to PEP from the Calvin cycle, CAM \"temporally\" separates these two processes. CAM plants have a different leaf anatomy from plants, and fix the at night, when their stomata are open. CAM plants store the mostly in the form of malic acid via carboxylation of phosphoenolpyruvate to oxaloacetate, which is then reduced to malate. Decarboxylation of malate during the day releases inside the leaves, thus allowing carbon fixation to 3-phosphoglycerate by RuBisCO. Sixteen thousand species of plants use CAM.\n\nCyanobacteria possess carboxysomes, which increase the concentration of around RuBisCO to increase the rate of photosynthesis. An enzyme, carbonic anhydrase, located within the carboxysome releases CO from the dissolved hydrocarbonate ions (HCO). Before the CO diffuses out it is quickly sponged up by RuBisCO, which is concentrated within the carboxysomes. HCO ions are made from CO outside the cell by another carbonic anhydrase and are actively pumped into the cell by a membrane protein. They cannot cross the membrane as they are charged, and within the cytosol they turn back into CO very slowly without the help of carbonic anhydrase. This causes the HCO ions to accumulate within the cell from where they diffuse into the carboxysomes. Pyrenoids in algae and hornworts also act to concentrate around rubisco.\n\nThe overall process of photosynthesis takes place in four stages:\n\nPlants usually convert light into chemical energy with a photosynthetic efficiency of 3–6%.\nAbsorbed light that is unconverted is dissipated primarily as heat, with a small fraction (1–2%) re-emitted as chlorophyll fluorescence at longer (redder) wavelengths. This fact allows measurement of the light reaction of photosynthesis by using chlorophyll fluorometers.\n\nActual plants' photosynthetic efficiency varies with the frequency of the light being converted, light intensity, temperature and proportion of carbon dioxide in the atmosphere, and can vary from 0.1% to 8%. By comparison, solar panels convert light into electric energy at an efficiency of approximately 6–20% for mass-produced panels, and above 40% in laboratory devices.\n\nThe efficiency of both light and dark reactions can be measured but the relationship between the two can be complex. For example, the ATP and NADPH energy molecules, created by the light reaction, can be used for carbon fixation or for photorespiration in C plants. Electrons may also flow to other electron sinks. For this reason, it is not uncommon for authors to differentiate between work done under non-photorespiratory conditions and under photorespiratory conditions.\nChlorophyll fluorescence of photosystem II can measure the light reaction, and Infrared gas analyzers can measure the dark reaction. It is also possible to investigate both at the same time using an integrated chlorophyll fluorometer and gas exchange system, or by using two separate systems together. Infrared gas analyzers and some moisture sensors are sensitive enough to measure the photosynthetic assimilation of CO, and of ΔHO using reliable methods CO is commonly measured in μmols/m/s, parts per million or volume per million and H0 is commonly measured in mmol/m/s or in mbars. By measuring CO assimilation, ΔHO, leaf temperature, barometric pressure, leaf area, and photosynthetically active radiation or PAR, it becomes possible to estimate, “A” or carbon assimilation, “E” or transpiration, “gs” or stomatal conductance, and Ci or intracellular CO. However, it is more common to used chlorophyll fluorescence for plant stress measurement, where appropriate, because the most commonly used measuring parameters FV/FM and Y(II) or F/FM’ can be made in a few seconds, allowing the measurement of larger plant populations.\n\nGas exchange systems that offer control of CO levels, above and below ambient, allow the common practice of measurement of A/Ci curves, at different CO levels, to characterize a plant’s photosynthetic response.\nIntegrated chlorophyll fluorometer – gas exchange systems allow a more precise measure of photosynthetic response and mechanisms. While standard gas exchange photosynthesis systems can measure Ci, or substomatal CO levels, the addition of integrated chlorophyll fluorescence measurements allows a more precise measurement of C to replace Ci. The estimation of CO at the site of carboxylation in the chloroplast, or C, becomes possible with the measurement of mesophyll conductance or g using an integrated system.\n\nPhotosynthesis measurement systems are not designed to directly measure the amount of light absorbed by the leaf. But analysis of chlorophyll-fluorescence, P700- and P515-absorbance and gas exchange measurements reveal detailed information about e.g. the photosystems, quantum efficiency and the CO assimilation rates. With some instruments even wavelength-dependency of the photosynthetic efficiency can be analyzed.\n\nA phenomenon known as quantum walk increases the efficiency of the energy transport of light significantly. In the photosynthetic cell of an algae, bacterium, or plant, there are light-sensitive molecules called chromophores arranged in an antenna-shaped structure named a photocomplex. When a photon is absorbed by a chromophore, it is converted into a quasiparticle referred to as an exciton, which jumps from chromophore to chromophore towards the reaction center of the photocomplex, a collection of molecules that traps its energy in a chemical form that makes it accessible for the cell's metabolism. The exciton's wave properties enable it to cover a wider area and try out several possible paths simultaneously, allowing it to instantaneously \"choose\" the most efficient route, where it will have the highest probability of arriving at its destination in the minimum possible time. Because that quantum walking takes place at temperatures far higher than quantum phenomena usually occur, it is only possible over very short distances, due to obstacles in the form of destructive interference that come into play. These obstacles cause the particle to lose its wave properties for an instant before it regains them once again after it is freed from its locked position through a classic \"hop\". The movement of the electron towards the photo center is therefore covered in a series of conventional hops and quantum walks.\n\nEarly photosynthetic systems, such as those in green and purple sulfur and green and purple nonsulfur bacteria, are thought to have been anoxygenic, and used various other molecules as electron donors rather than water. Green and purple sulfur bacteria are thought to have used hydrogen and sulfur as electron donors. Green nonsulfur bacteria used various amino and other organic acids as an electron donor. Purple nonsulfur bacteria used a variety of nonspecific organic molecules. The use of these molecules is consistent with the geological evidence that Earth's early atmosphere was highly reducing at that time.\n\nFossils of what are thought to be filamentous photosynthetic organisms have been dated at 3.4 billion years old. More recent studies, reported in March 2018, also suggest that photosynthesis may have begun about 3.4 billion years ago.\n\nThe main source of oxygen in the Earth's atmosphere derives from oxygenic photosynthesis, and its first appearance is sometimes referred to as the oxygen catastrophe. Geological evidence suggests that oxygenic photosynthesis, such as that in cyanobacteria, became important during the Paleoproterozoic era around 2 billion years ago. Modern photosynthesis in plants and most photosynthetic prokaryotes is oxygenic. Oxygenic photosynthesis uses water as an electron donor, which is oxidized to molecular oxygen () in the photosynthetic reaction center.\n\nSeveral groups of animals have formed symbiotic relationships with photosynthetic algae. These are most common in corals, sponges and sea anemones. It is presumed that this is due to the particularly simple body plans and large surface areas of these animals compared to their volumes. In addition, a few marine mollusks \"Elysia viridis\" and \"Elysia chlorotica\" also maintain a symbiotic relationship with chloroplasts they capture from the algae in their diet and then store in their bodies. This allows the mollusks to survive solely by photosynthesis for several months at a time. Some of the genes from the plant cell nucleus have even been transferred to the slugs, so that the chloroplasts can be supplied with proteins that they need to survive.\n\nAn even closer form of symbiosis may explain the origin of chloroplasts. Chloroplasts have many similarities with photosynthetic bacteria, including a circular chromosome, prokaryotic-type ribosome, and similar proteins in the photosynthetic reaction center. The endosymbiotic theory suggests that photosynthetic bacteria were acquired (by endocytosis) by early eukaryotic cells to form the first plant cells. Therefore, chloroplasts may be photosynthetic bacteria that adapted to life inside plant cells. Like mitochondria, chloroplasts possess their own DNA, separate from the nuclear DNA of their plant host cells and the genes in this chloroplast DNA resemble those found in cyanobacteria. DNA in chloroplasts codes for redox proteins such as those found in the photosynthetic reaction centers. The CoRR Hypothesis proposes that this Co-location of genes with their gene products is required for Redox Regulation of gene expression, and accounts for the persistence of DNA in bioenergetic organelles.\n\nThe biochemical capacity to use water as the source for electrons in photosynthesis evolved once, in a common ancestor of extant cyanobacteria. The geological record indicates that this transforming event took place early in Earth's history, at least 2450–2320 million years ago (Ma), and, it is speculated, much earlier. Because the Earth's atmosphere contained almost no oxygen during the estimated development of photosynthesis, it is believed that the first photosynthetic cyanobacteria did not generate oxygen. Available evidence from geobiological studies of Archean (>2500 Ma) sedimentary rocks indicates that life existed 3500 Ma, but the question of when oxygenic photosynthesis evolved is still unanswered. A clear paleontological window on cyanobacterial evolution opened about 2000 Ma, revealing an already-diverse biota of blue-green algae. Cyanobacteria remained the principal primary producers of oxygen throughout the Proterozoic Eon (2500–543 Ma), in part because the redox structure of the oceans favored photoautotrophs capable of nitrogen fixation. Green algae joined blue-green algae as the major primary producers of oxygen on continental shelves near the end of the Proterozoic, but it was only with the Mesozoic (251–66 Ma) radiations of dinoflagellates, coccolithophorids, and diatoms did the primary production of oxygen in marine shelf waters take modern form. Cyanobacteria remain critical to marine ecosystems as primary producers of oxygen in oceanic gyres, as agents of biological nitrogen fixation, and, in modified form, as the plastids of marine algae.\n\nAlthough some of the steps in photosynthesis are still not completely understood, the overall photosynthetic equation has been known since the 19th century.\n\nJan van Helmont began the research of the process in the mid-17th century when he carefully measured the mass of the soil used by a plant and the mass of the plant as it grew. After noticing that the soil mass changed very little, he hypothesized that the mass of the growing plant must come from the water, the only substance he added to the potted plant. His hypothesis was partially accurate — much of the gained mass also comes from carbon dioxide as well as water. However, this was a signaling point to the idea that the bulk of a plant's biomass comes from the inputs of photosynthesis, not the soil itself.\n\nJoseph Priestley, a chemist and minister, discovered that, when he isolated a volume of air under an inverted jar, and burned a candle in it (which gave off CO), the candle would burn out very quickly, much before it ran out of wax. He further discovered that a mouse could similarly \"injure\" air. He then showed that the air that had been \"injured\" by the candle and the mouse could be restored by a plant.\n\nIn 1778, Jan Ingenhousz, repeated Priestley's experiments. He discovered that it was the influence of sunlight on the plant that could cause it to revive a mouse in a matter of hours.\n\nIn 1796, Jean Senebier, a Swiss pastor, botanist, and naturalist, demonstrated that green plants consume carbon dioxide and release oxygen under the influence of light. Soon afterward, Nicolas-Théodore de Saussure showed that the increase in mass of the plant as it grows could not be due only to uptake of CO but also to the incorporation of water. Thus, the basic reaction by which photosynthesis is used to produce food (such as glucose) was outlined.\n\nCornelis Van Niel made key discoveries explaining the chemistry of photosynthesis. By studying purple sulfur bacteria and green bacteria he was the first to demonstrate that photosynthesis is a light-dependent redox reaction, in which hydrogen reduces (donates its electron to) carbon dioxide.\n\nRobert Emerson discovered two light reactions by testing plant productivity using different wavelengths of light. With the red alone, the light reactions were suppressed. When blue and red were combined, the output was much more substantial. Thus, there were two photosystems, one absorbing up to 600 nm wavelengths, the other up to 700 nm. The former is known as PSII, the latter is PSI. PSI contains only chlorophyll \"a\", PSII contains primarily chlorophyll \"a\" with most of the available chlorophyll \"b\", among other pigment. These include phycobilins, which are the red and blue pigments of red and blue algae respectively, and fucoxanthol for brown algae and diatoms. The process is most productive when the absorption of quanta are equal in both the PSII and PSI, assuring that input energy from the antenna complex is divided between the PSI and PSII system, which in turn powers the photochemistry.\nRobert Hill thought that a complex of reactions consisting of an intermediate to cytochrome b (now a plastoquinone), another is from cytochrome f to a step in the carbohydrate-generating mechanisms. These are linked by plastoquinone, which does require energy to reduce cytochrome f for it is a sufficient reductant. Further experiments to prove that the oxygen developed during the photosynthesis of green plants came from water, were performed by Hill in 1937 and 1939. He showed that isolated chloroplasts give off oxygen in the presence of unnatural reducing agents like iron oxalate, ferricyanide or benzoquinone after exposure to light. The Hill reaction is as follows:\n\nwhere A is the electron acceptor. Therefore, in light, the electron acceptor is reduced and oxygen is evolved.\n\nSamuel Ruben and Martin Kamen used radioactive isotopes to determine that the oxygen liberated in photosynthesis came from the water.\n\nMelvin Calvin and Andrew Benson, along with James Bassham, elucidated the path of carbon assimilation (the photosynthetic carbon reduction cycle) in plants. The carbon reduction cycle is known as the Calvin cycle, which ignores the contribution of Bassham and Benson. Many scientists refer to the cycle as the Calvin-Benson Cycle, Benson-Calvin, and some even call it the Calvin-Benson-Bassham (or CBB) Cycle.\n\nNobel Prize-winning scientist Rudolph A. Marcus was able to discover the function and significance of the electron transport chain.\n\nOtto Heinrich Warburg and Dean Burk discovered the I-quantum photosynthesis reaction that splits the CO, activated by the respiration.\n\nIn 1950, first experimental evidence for the existence of photophosphorylation \"in vivo\" was presented by Otto Kandler using intact \"Chlorella\" cells and interpreting his findings as light-dependent ATP formation. \nIn 1954, Daniel I. Arnon et al. discovered photophosphorylation \"in vitro\" in isolated chloroplasts with the help of P.\n\nLouis N.M. Duysens and Jan Amesz discovered that chlorophyll a will absorb one light, oxidize cytochrome f, chlorophyll a (and other pigments) will absorb another light, but will reduce this same oxidized cytochrome, stating the two light reactions are in series.\n\nIn 1893, Charles Reid Barnes proposed two terms, \"photosyntax\" and \"photosynthesis\", for the biological process of \"synthesis of complex carbon compounds out of carbonic acid, in the presence of chlorophyll, under the influence of light\". Over time, the term \"photosynthesis\" came into common usage as the term of choice. Later discovery of anoxygenic photosynthetic bacteria and photophosphorylation necessitated redefinition of the term.\n\nAfter WWII at late 1940 at the University of California, Berkeley, the details of photosynthetic carbon metabolism were sorted out by the chemists Melvin Calvin, Andrew Benson, James Bassham and a score of students and researchers utilizing the carbon-14 isotope and paper chromatography techniques. The pathway of CO2 fixation by the algae \"Chlorella\" in a fraction of a second in light resulted in a 3 carbon molecule called phosphoglyceric acid (PGA). For that original and ground-breaking work, a Nobel Prize in Chemistry was awarded to Melvin Calvin in 1961. In parallel, plant physiologists studied leaf gas exchanges using the new method of infrared gas analysis and a leaf chamber where the net photosynthetic rates ranged from 10 to 13 u mole CO2/square metere.sec., with the conclusion that all terrestrial plants having the same photosynthetic capacities that were light saturated at less than 50% of sunlight.\n\nLater in 1958-1963 at Cornell University, field grown maize was reported to have much greater leaf photosynthetic rates of 40 u mol CO2/square meter.sec and was not saturated at near full sunlight. This higher rate in maize was almost double those observed in other species such as wheat and soybean, indicating that large differences in photosynthesis exist among higher plants. At the University of Arizona, detailed gas exchange research on more than 15 species of monocot and dicot uncovered for the first time that differences in leaf anatomy are crucial factors in differentiating photosynthetic capacities among species. In tropical grasses, including maize, sorghum, sugarcane, Bermuda grass and in the dicot amaranthus, leaf photosynthetic rates were around 38−40 u mol CO2/square meter.sec., and the leaves have two types of green cells, i. e. outer layer of mesophyll cells surrounding a tightly packed cholorophyllous vascular bundle sheath cells. This type of anatomy was termed Kranz anatomy in the 19th century by the botanist Gottlieb Haberlandt while studying leaf anatomy of sugarcane. Plant species with the greatest photosynthetic rates and Kranz anatomy showed no apparent photorespiration, very low CO2 compensation point, high optimum temperature, high stomatal resistances and lower mesophyll resistances for gas diffusion and rates never saturated at full sun light. The research at Arizona was designated Citation Classic by the ISI 1986. These species was later termed C4 plants as the first stable compound of CO2 fixation in light has 4 carbon as malate and aspartate. Other species that lack Kranz anatomy were termed C3 type such as cotton and sunflower, as the first stable carbon compound is the 3-carbon PGA acid. At 1000 ppm CO2 in measuring air, both the C3 and C4 plants had similar leaf photosynthetic rates around 60 u mole CO2/square meter.sec. indicating the suppression of photorespiration in C3 plants.\n\nThere are three main factors affecting photosynthesis and several corollary factors. The three main are:\n\nTotal photosynthesis is limited by a range of environmental factors. These include the amount of light available, the amount of leaf area a plant has to capture light (shading by other plants is a major limitation of photosynthesis), rate at which carbon dioxide can be supplied to the chloroplasts to support photosynthesis, the availability of water, and the availability of suitable temperatures for carrying out photosynthesis.\n\nThe process of photosynthesis provides the main input of free energy into the biosphere, and is one of four main ways in which radiation is important for plant life.\n\nThe radiation climate within plant communities is extremely variable, with both time and space.\n\nIn the early 20th century, Frederick Blackman and Gabrielle Matthaei investigated the effects of light intensity (irradiance) and temperature on the rate of carbon assimilation.\nThese two experiments illustrate several important points: First, it is known that, in general, photochemical reactions are not affected by temperature. However, these experiments clearly show that temperature affects the rate of carbon assimilation, so there must be two sets of reactions in the full process of carbon assimilation. These are the light-dependent 'photochemical' temperature-independent stage, and the light-independent, temperature-dependent stage. Second, Blackman's experiments illustrate the concept of limiting factors. Another limiting factor is the wavelength of light. Cyanobacteria, which reside several meters underwater, cannot receive the correct wavelengths required to cause photoinduced charge separation in conventional photosynthetic pigments. To combat this problem, a series of proteins with different pigments surround the reaction center. This unit is called a phycobilisome.\n\nAs carbon dioxide concentrations rise, the rate at which sugars are made by the light-independent reactions increases until limited by other factors. RuBisCO, the enzyme that captures carbon dioxide in the light-independent reactions, has a binding affinity for both carbon dioxide and oxygen. When the concentration of carbon dioxide is high, RuBisCO will fix carbon dioxide. However, if the carbon dioxide concentration is low, RuBisCO will bind oxygen instead of carbon dioxide. This process, called photorespiration, uses energy, but does not produce sugars.\n\nRuBisCO oxygenase activity is disadvantageous to plants for several reasons:\n\nThe salvaging pathway for the products of RuBisCO oxygenase activity is more commonly known as photorespiration, since it is characterized by light-dependent oxygen consumption and the release of carbon dioxide.\n\n"}
{"id": "1435172", "url": "https://en.wikipedia.org/wiki?curid=1435172", "title": "Religious symbol", "text": "Religious symbol\n\nA religious symbol is an iconic representation intended to represent a specific religion, or a specific concept within a given religion.\nReligious symbols have been used in the military in many different countries, such as the United States military chaplain symbols. Similarly, the United States Department of Veterans Affairs emblems for headstones and markers recognize 57 symbols (including a number of symbols expressing non-religiosity).\n\nSymbolic representation of a specific religious tradition is useful in a society with religious pluralism, as was the case in the Roman Empire, and again in modern multiculturalism.\n\nIn many Traditional African religions, there are no graphical or pictorial symbols representing the actual religion or faith. Each tradition however, has symbolisms which are religious or spiritual in nature. Some of these may be graphical, numerological (as in Serer numerology - see Serer creation myth) or a combination of both. However, these graphical images do not represent the actual faith, but elements within the faith. \nThe very nature of African art stem from \"their themes of symbolism, functionalism and utilitarianism\" hence why African art is multi-functional. In the traditional African belief system, Africans draw from their various artistic traditions as sources of inspiration. \"These images have religio-metaphysical themes, which serve as the focal point of power, which links the African’s physical world to his beliefs on his essence and existence. Indeed the African art reflect images of ancestral spirits, and pantheons of indigenous gods and goddesses.\" \n\n\n"}
{"id": "1767557", "url": "https://en.wikipedia.org/wiki?curid=1767557", "title": "Remote Automated Weather Station", "text": "Remote Automated Weather Station\n\nThe Remote Automatic Weather Stations (RAWS) system is a network of automated weather stations run by the U.S. Forest Service (USFS) and Bureau of Land Management (BLM) and monitored by the National Interagency Fire Center (NIFC), mainly to observe potential wildfire conditions. \n\nUnlike the automated airport weather stations which are located at significant airports, RAWS stations are often located in remote areas, particularly in national forests. Because of this, they usually are not connected to the electrical grid, but rather have their own solar panels, and a battery to store power for overnight reporting. Some instead run on a generator. In both cases, data important to operating the station itself, such as battery voltage or fuel level, is often included in the hourly reports.\n\nAlso because of the remote locations, most communicate with a modem via telephone, or via a VSAT connection to a GOES satellite.\n\nIn this regard, they are similar to mesonets and may be mesonets if the distance between stations (spatial resolution) is sufficiently dense. They often lack the consistently high-quality data needed for use in numerical weather prediction and climatology, however. Road Weather Information System (RWIS) may likewise be self-powered and located in remote areas.\n\nThere are times when a portable weather station is required, such as planned ignitions, wildfires, and other projects where there is a need to collect and share weather information. \nPortable stations may also be referred to as \"quick deploy\" or QD, and this should be indicated within the name of the station to allow proper interpretation of the collected data. \n\n"}
{"id": "598258", "url": "https://en.wikipedia.org/wiki?curid=598258", "title": "Rudolf Trümpy", "text": "Rudolf Trümpy\n\nRudolf Trümpy (16 August 1921 – 30 January 2009) was a Swiss geologist, who was born in the small Swiss town of Glarus. He graduated from the ETH Zürich in the late 1940s with a thesis titled: “Der Lias der Glarner Alpen”. From 1947 to 1953 he spent his post-doctoral years in Lausanne before being appointed professor at ETH Zürich in 1953. He would remain there until 1986.\n\nHis research mainly concentrated on alpine geology. However, he also published papers on extra-alpine regions like Greenland, the Montagne Noire and the Sahara. He was the author of the reference book \"Geology of Switzerland\".\n\nTrümpy is the recipient of numerous awards and prizes including the Wollaston Medal and the Penrose Medal. In 1978 he was elected a Foreign Associate of the United States National Academy of Sciences. He is also a member of the French Academy of Sciences.\n\nMany stratigraphic formations in the western Alps were first described by Trümpy. For example, the Couches de l’Aroley, the Couches des Marmontains and the Couches de St Cristoph.\n"}
{"id": "57227015", "url": "https://en.wikipedia.org/wiki?curid=57227015", "title": "SPHEREx", "text": "SPHEREx\n\nSPHEREx (Spectro-Photometer for the History of the Universe, Epoch of Reionization, and Ices Explorer) is a proposed near-infrared space observatory that would perform an all-sky survey to measure the near-infrared spectra of approximately 450 million galaxies. SPHEREx is competing for selection by NASA for its next Medium-Class Explorers mission, which will take place in 2019. The other two competing mission concepts are \"Arcus\", and FINESSE. If selected and built, the launch date would be no earlier than 2022. The Principal Investigator is James Bock at Caltech in Pasadena, California.\n\nSPHEREx would use a spectrophotometer to perform an all-sky survey that would measure near-infrared spectra from 0.75 to 5.0 micrometers. It employs a simple instrument with a single observing mode to map the entire sky four times during its nominal 25-month mission. It would classify galaxies according to redshift accuracy, categorizing approximately 450 million galaxies and fitting measured spectra to a library of galaxy templates. Specifically, SPHEREx will probe signals from the intra-halo light and from the epoch of reionization. It would explore what drove the early universe inflation, explore the origin and history of galaxies, and explore the origin of water in planetary systems.\n\nSPHEREx would complement planned Euclid and WFIRST spectroscopic surveys, but SPHEREx's lower redshift survey would allow its measurement of inflationary parameters to be mostly independent to provide a new line of evidence.\n\nThe telescope lens will have a diameter of 20 centimeters with a wide 3.5° x 7° field of view, imaged onto four 2k x 2k mercury cadmium telluride (HgCdTe) photodetector arrays.\n\nSPHEREx proposal was submitted to NASA on 19 December 2014, and it was selected for further conceptual development (Phase A) on 30 July 2015 for the Small Explorer program (SMEX). The detailed concept study report was submitted to NASA on 19 July 19 2016 but it was not selected for SMEX. An enhanced version of SPHEREx was submitted on 15 December 2016 as a Medium-Class Explorer (MIDEX), and it was selected as a finalist in August 2017, along two other competing missions: \"Arcus\", and FINESSE. Each team received $2 million to refine their mission concepts over nine-months. Selection of the winner is expected to take place in 2019 and proceed with construction and launch. The earliest launch date would be in 2022. Medium-Class Explorer mission costs are capped at $250 million, not including the launch vehicle.\n\n"}
{"id": "743257", "url": "https://en.wikipedia.org/wiki?curid=743257", "title": "Scaled Composites Tier One", "text": "Scaled Composites Tier One\n\nTier One was a Scaled Composites' 1990s–2004 program of suborbital human spaceflight using the reusable spacecraft SpaceShipOne and its launcher White Knight. The craft was designed by Burt Rutan, and the project was funded 20 million US Dollars by Paul Allen. In 2004 it made the first privately funded human spaceflight and won the 10 million US Dollars Ansari X Prize for the first non-governmental reusable manned spacecraft.\n\nThe objective of the project was to develop technology for low-cost routine access to space. SpaceShipOne was not itself intended to carry paying passengers, but was envisioned that there would be commercial spinoffs, initially in space tourism. The company Mojave Aerospace Ventures was formed to manage commercial exploitation of the technology. A deal with Virgin Galactic could see routine space tourism in the late 2010s using a spacecraft based on Tier One technology.\n\nThe design concept of Tier One was to air launch a three-person piloted spacecraft which climbs to slightly above altitude using a hybrid rocket motor and then glides to the ground and lands horizontally. Scaled Composites lists the following components of the program:\n\nDetails on the SpaceShipOne vehicle itself can be found in the SpaceShipOne article, and details on the White Knight carrier aircraft can be found on the Scaled Composites White Knight article.\n\nIn addition to an office-based mission control, Tier One has a mobile mission control center. This is relatively small, built into a large road-going truck. It bears the Scaled Composites logo, but no other overt indication of its link to Tier One. The vehicle performs a combination of support functions:\n\nThis control center is used to support both rocket motor ground tests and all flight tests of White Knight and SpaceShipOne. Its primary function is to monitor and record test data, and to this end it is equipped with computers and radio communication gear. SpaceShipOne's avionics displays are duplicated in mission control. Telemetry data is received on a Data Reduction System (DRS), which automatically directs radio antennas to point at the craft being monitored. The telemetry system has a range of about .\n\nThe control center is equipped to communicate with Scaled Composites' offices, as well as the aircraft and spacecraft.\n\nThe control center maintains a temperature-controlled atmosphere for its staff, and can be hooked up to provide temperature control for the White Knight and SpaceShipOne cabins. The physical structure of mission control also provides easier access to the White Knight cabin.\n\nUnlike the solid fuel, the nitrous oxide oxidiser is handled as a bulk commodity and pumped into the spacecraft's oxidiser tank in the field. Tier One therefore has a mobile delivery system for nitrous oxide, which they call MONODS (mobile nitrous oxide delivery system).\n\nMONODS is built on an open trailer, which can be carried by road in conventional manner. It consists principally of a tank, a temperature control unit, and a generator to power the temperature control unit. The nitrous oxide is stored at room temperature, at a pressure of .\n\nMONODS is refilled from a commercial supplier, which uses tankers and delivers the nitrous oxide at about and . MONODS heats the nitrous oxide to room temperature, increasing its pressure.\n\nTier One has a mobile thrust test stand, known as the Test Stand Trailer (TST). The advantage of making it mobile is that all the mounting and instrumentation work can be done in the hangar, so that at the test site all that needs to be done is to fill the oxidiser tank (from MONODS) and conduct the firing.\n\nThe test stand replicates the essential structural components of the spacecraft. It has an oxidiser tank and associated fittings identical to the one used in flight. This means that the motor test also automatically performs appropriate vibration, stress, and heat tests of the spacecraft structure. The crew cabin, however, is not replicated.\n\nFor ground-based thrust tests, a rocket nozzle with an expansion ratio of 10:1 is used, differing from the 25:1 nozzle used at altitude during actual flight.\n\nThe test stand is instrumented to record not only thrust but also side force and temperature and strain experienced by components. Data is recorded on a computer in a bunker at the test site. The data acquisition computer is remotely controlled from mission control.\n\nThe SpaceShipOne flight simulator consists of a simulator program and a cockpit.\n\nThe flight simulator program aims to accurately simulate SpaceShipOne's behaviour under any circumstances and in all phases of flight. Rather than having a model of SpaceShipOne's overall flight behaviour, it uses computational fluid dynamics to model the air around the craft. It calculates the aerodynamic and other forces operating on the craft, taking into account the positions of its control surfaces. This simulation is based on the computer modelling that was used during the design process and refined using data from flight tests. This yields a highly accurate image of craft behaviour, even in unanticipated modes of flight. (This is one of the first modern aircraft to be designed without wind tunnel testing.)\n\nThe cockpit replica is on a static base, and so cannot accurately reproduce the equilibrioceptive and accelerative aspects of flight. However, White Knight is equipped to operate as a high-fidelity moving-base simulator; see White Knight's section above. The simulator cockpit is an accurate copy of the SpaceShipOne cabin, including its avionics. It is the system of pilot plus avionics, not just the pilot, that is being simulated to. The flight simulator program drives the sensor inputs that are used by the avionics, and also drives twelve display computers which use commercial graphics software to generate high-resolution images of the outside view for the pilot. These views appear on eleven monitors and one projector screen. Stick force feedback is not simulated in real time.\n\nGround-based flight simulation is not only used for pilot training. It is also used to train ground crew, develop procedures, and test the avionics software and hardware.\n\nAccording to Scaled Composites, the concept for the program originated in April 1996, preliminary development began in 1999, and full development began in April 2001. It was initially kept secret, even after White Knight first flew on August 1, 2002. The program was announced to the public on April 18, 2003, when the program was ready to flight-test SpaceShipOne. Its first flight test, SpaceShipOne flight 01C, took place on May 20, 2003.\n\nAfter months of glide tests, the first powered flight, SpaceShipOne flight 11P, was made on December 17, 2003. Further powered tests followed, reaching increasing altitudes, culminating on June 21, 2004 with the first privately funded human spaceflight, SpaceShipOne flight 15P. Ansari X Prize competitive flights followed. SpaceShipOne flight 16P on September 29, 2004 and SpaceShipOne flight 17P on October 4, 2004 were successful competitive flights, winning the X Prize.\nThe Tier One program run by Scaled Composites concluded after the retirement of SpaceShipOne, transitioning to a successor program for customer Virgin Galactic.\n\nThe costs of development, construction, and operation of Tier One, although not publicly released, are estimated to be in the range of 20 million to 30 million US dollars, roughly two to three times the value of the Ansari X Prize award. The sole sponsor, initially secret, was revealed to be Paul Allen, a co-founder of Microsoft and the 48th richest person in the world. The revelation, on December 17, 2003, the same day as the program's first powered flight test, followed speculation that Allen was involved.\n\nSome commentators have drawn comparisons between the relative inexpense of the Tier One program and the high cost of the Space Shuttle program, though the technological difficulties of the two programs are completely different. SpaceShipOne, because it flies suborbitally, does not need to reach the high speeds of the Space Shuttle (Mach 3 vs. Mach 25), nor the same altitude ( suborbital vs. orbit). SpaceShipOne also does not carry the same crew (3 members vs. 7) or payload (negligible vs. 25 tons), and makes much shorter flights (a few minutes vs. several days). The SpaceShipOne program is a technical achievement more on a par with the X-15 than the Shuttle.\n\nInflation adjusted comparisons of the SpaceShipOne program with that of the X-15 budget, indicate that the Tier One program cost 1/100th that of the X-15 program, although the three X-15 aircraft made almost 200 test flights in their entire test program, typically exploring hypersonic flight between mach 4-7. Only a few dozen X-15 flights specifically sought to reach peak altitudes rather than achieve top speeds, though only two flights ever reached altitudes near those achieved by SpaceShipOne. On the other hand, the Tier One project also paid for construction of the White Knight mothership within its budget, while NASA had nearly free use of a pre-existing USAF B-52 bomber modified to perform drop tests of experimental aircraft of many kinds (currently in use for PegasusXL launches).\n\nTier One was initially developed secretly, as is Scaled Composites' policy with new programs. On April 18, 2003 the program was publicly announced, and SpaceShipOne and White Knight were demonstrated to the media at a rollout attended by between 550 and 600 people. Media interest was so intense that what had been intended as a Family and Friends Day on April 24, 2003 was turned into a second media day.\n\nScaled Composites again courted publicity by announcing in advance the final test flight, SpaceShipOne flight 15P, intended to be the program's first spaceflight. About 11,000 people went to Mojave Spaceport to watch the flight, which was also televised. The flight was run as an airshow, with both the principal craft and the chase planes making takeoffs and landings in front of the crowd, and celebratory flybys when the test succeeded. The flight was not only a technical success but also a popular success, stimulating intense public interest in spaceflight.\n\nDuring an interview in the documentary , Rutan stated that Tier One will cover suborbital flights, Tier Two will cover orbital flights, and Tier Three will cover flights beyond Earth's orbit (including flights to the moon and other planets). In the same documentary he displayed designs for an orbital craft based on SpaceShipOne, which had a rocket roughly twice SpaceShipOne's length mounted to the ship's rear.\n\nThe stated objective of the Tier One program is to demonstrate suborbital human spaceflight operations at low cost. Before Burt Rutan began considering this project, there were three major barriers to the goal of affordable suborbital spaceflight:\n\nTier One itself is not intended to carry paying passengers, and US Government permits would be required if it did intend to do so. It is a technology testbed, and it is expressly intended that the technology developed in the program will later be used in commercial spaceflights. To that end, Paul Allen and Burt Rutan created a company, Mojave Aerospace Ventures, which owns the project's intellectual property and will manage all commercial exploitation of it.\n\nScaled Composites initially expressed a hope that by about 2013 it would be possible for members of the public to experience a suborbital flight for about the price of a luxury cruise. On September 25, 2004 a deal was struck with Virgin Galactic to develop the Virgin SpaceShip based on a scaled-up version of SpaceShipOne. These spacecraft will be built by The Spaceship Company.\n\n"}
{"id": "7391483", "url": "https://en.wikipedia.org/wiki?curid=7391483", "title": "Shark tunnel", "text": "Shark tunnel\n\nA shark tunnel (or aquarium tunnel or acrylic tunnel or exhibit tunnel) is an underwater tunnel that passes through an aquarium, typically with sharks and related aquatic life.\nThey are usually made of thick acrylic glass.\n\nMost aquarium tunnels are cylindrical in shape, though tunnels can be made elliptical (to make them wider and still keep the top of the tunnel closer to the visitors), or even square.\n\nThis list is sorted alphabetically by aquarium name.\n\n† — Estimated based on top of tunnel being under the surface and to bottom of tunnel.\n\n"}
{"id": "1536140", "url": "https://en.wikipedia.org/wiki?curid=1536140", "title": "Siegfried Marcus", "text": "Siegfried Marcus\n\nSiegfried Samuel Marcus (18 September 1831 – 1 July 1898) was a German inventor. Marcus was born of Jewish descent in Malchin, in the Grand Duchy of Mecklenburg-Schwerin. He made several petrol-powered vehicles, the first one in 1864, while living in Vienna, Austria.\n\nMarcus was born in Malchin, in the Grand Duchy of Mecklenburg-Schwerin into a Jewish family. Today Malchin is part of Germany. He began work at age 12 as an apprentice mechanic. At 17 he joined Siemens and Halske, an engineering company that built telegraph lines. He moved to Vienna, the capital of the Austrian Empire, in 1852, working first as a technician in the Physical Institute of the Medical School. He then worked as an assistant to Professor Carl Ludwig, a physiologist. In 1860 Marcus opened his own workshop which made mechanical and electrical equipment. The first was located at Mariahilferstrasse 107 and the second at Mondscheingasse 4.\n\nHis chief improvements include telegraph relay system and ignition devices such as the \"Wiener Zünder\", a blasting machine. Marcus was buried at the Protestant Cemetery at Hütteldorf, Vienna. Later, his remains were transferred to an \"Honorary Tomb\" of Vienna's Central Cemetery.\n\nBecause of Marcus' Jewish ancestry, his name and all memorabilia, particularly in Austria, vanished under the Nazis. In 1937 the Austrian Harand Movement Against Racial Hatred had issued a series of stamps featuring prominent Jews, including Marcus, who had contributed to mankind in response to the \"Ewige Jew\" (eternal Jew) exhibition by Julius Streicher in Munich. Marcus was credited as having invented the petrol driven motor car. With the German occupation of Austria in March 1938, the memorial in front of the Vienna Technical University was removed. After World War II, the monument was rebuilt and his car, which had been hidden, was returned to display.\n\nMarcus was removed from German encyclopedias as the inventor of the modern car, under a directive from the German Ministry for Propaganda during World War II. His name was replaced with the names of Daimler and Benz. The directive (in German) read as follows:\n\nIn English this would be\n\nCurrent Austrian thinking is that Marcus' first car ran in the late 1880s. However, early publications suggest that he may have had a petrol powered vehicle running earlier than 1870. The deliberate destruction of evidence of Marcus' inventions by the Nazi regime has left these dates open to debate and speculation. Britannica cites 1864 for Marcus' first car with a 10-year gap to the second, which is consistent with other sources.\n\nBased on the information from existing sources, Marcus' first machine was built on a simple handcart in 1870. but had to be started by lifting the drive wheels off the ground and spinning them. The internal combustion engine was designed for liquid combustibles and made him the first to propel a vehicle by means of petrol. Marcus was not satisfied with this cart and dismantled it.\n\nIn 1883 a patent for a low-voltage ignition magneto was given to Marcus in Germany and a new petrol engine built.\n\nThis design was used for all further engines, including that of the only existing Marcus car from 1888–1889. It was this ignition, in conjunction with the \"rotating brush carburettor\", that made the engine's design very innovative. By 1886 the German navy was using the engine in its torpedo boats.\n\nIn 1887, Marcus started a co-operation with the Moravian company Märky, Bromovsky & Schulz. They offered two stroke and — after the fall of the Otto-Patent in 1886 — four stroke engines of the Marcus type.\n\nIn 1888-1889 Märky, Bromovsky & Schulz built the car which can still be seen in Vienna's Technical Museum. This car made Marcus well-known all over the world. The car was named a Historic Mechanical Engineering Landmark by the American Society of Mechanical Engineers.\n\nJohn Nixon of the London Times in 1938 considered Marcus' development of the motor car to have been experimental, as opposed to Benz who took the concept from experimental to production. Nixon described Marcus' cars as impractical. 12 years later, in 1950, the Times described the car at the Vienna Technical Museum as being built in 1875 and the first petrol-powered road vehicle. A description of its first journey of 7.5 miles from Vienna to Klosterneuberg was included in the article.\n\nMarcus was the holder of 131 patents in 16 countries. He never applied for a patent for the motorcar and, of course, he never held one. Nevertheless, he was the first to use petrol to propel a vehicle, in the simple handcart of 1864, but it is uncertain whether the extant Marcus car ran before 1890.\n\nSome examples of his patents:\n\nIn conjunction with Captain E von Wohlgemuth of the Imperial German Navy, Marcus invented an electrical ignition of ships cannons. The advantages of the system were that it allowed for the simultaneous firing of the cannons, or selection of a particular firing pattern, and the ability to fire them from the ship's bridge.\n\n\n\n"}
{"id": "46302564", "url": "https://en.wikipedia.org/wiki?curid=46302564", "title": "Signified and signifier", "text": "Signified and signifier\n\nThe terms signified and signifier are most commonly related to semiotics, which is defined by Oxford Dictionaries Online as \"the study of signs and symbols and their use or interpretation\". Ferdinand de Saussure, a Swiss linguist, was one of the two founders of semiotics. His book, \"Course in General Linguistics\" \"is considered to be one of the most influential books published in the twentieth century\". Saussure explained that a sign was not only a sound-image but also a concept. Thus he divided the sign into two components: the signifier (or \"sound-image\") and the signified (or \"concept\"). For Saussure, the signified and signifier were purely psychological; they were form rather than substance. Today, following Hjelmslev, the signifier is interpreted as the material form (something which can be seen, heard, touched, smelled or tasted) and the signified as the mental concept.\n\nThe concept of signs has been around for a long time, having been studied by many philosophers who include Plato, Aristotle, Augustine, and others from the medieval period such as William of Ockham. The term \"semiotics\" \"comes from the Greek root, seme, as in semeiotikos, an interpreter of signs\". It wasn't until the 20th century, however, that Saussure and American philosopher Charles Sanders Peirce brought the term into awareness. While both Saussure and Peirce contributed greatly to the concept of signs, it is important to note that each differed in their approach to the study, and it was Saussure who created the terms signifier and signified in order to break down what a sign was.\n\nSucceeding these founders were numerous philosophers and linguists who defined themselves as semioticians. These semioticians have each brought their own concerns to the study of signs. Umberto Eco (1976), a distinguished Italian semiotician, came to the conclusion that \"if signs can be used to tell the truth, they can also be used to lie\". Postmodernist social theorist Jean Baudrillard spoke of hyperreality, which referred to a copy becoming more real than reality. In other words, how the signified becomes more important than the signifier . Then French semiotician Roland Barthes used signs to explain the concept of connotation – cultural meanings attached to words – and denotation – literal or explicit meanings of words. Without Saussure's breakdown of signs into signified and signifier, however, these semioticians would not have had anything to base their concepts on.\n\nToday, \"contemporary commentators tend to describe the signifier as the form that the sign takes and the signified as the concept to which it refers\". The relationship between the signifier and signified is an arbitrary relationship. In other words, \"there is no logical connection\" between them. This differs from a symbol, which is \"never wholly arbitrary\". The idea that both the signifier and the signified are inseparable is explained by Saussure's diagram, which shows how both components coincide to create the sign.\n\nSo the question is, how do signifiers create meaning and how do we know what that meaning is? In order to understand how the signifier and signified relate to each other, one must be able to interpret signs. \"The only reason that the signifier does entail the signified is because there is a conventional relationship at play\". That is, a sign can only be understood when the relationship between the two components that make up the sign are agreed upon. Saussure argued that a sign's \"meaning depends on its relation to other words within the system\" (for example, to understand an individual word such as \"tree\", one must also understand the word \"bush\" and how the two relate to each other). It is this difference from other signs that allows the possibility of a speech community. However we need to remember that signifiers and their significance change all the time, becoming \"dated\". It is in this way that we are all \"practicing semioticians who pay a great deal of attention to signs… even though we may never have heard them before\" And while words are the most familiar form signs take, they stand for many things within life, such as advertisement, objects, body language, music, and so on. Therefore the use of signs, and the two components that make up a sign, can be and are – whether consciously or not – applied to everyday life.\n\n"}
{"id": "2918338", "url": "https://en.wikipedia.org/wiki?curid=2918338", "title": "Spring scale", "text": "Spring scale\n\nA spring scale or spring balance or newton meter is a type of weighing scale. It consists of spring fixed at one end with a hook to attach an object at the other. It works by Hooke's Law, which states that the force needed to extend a spring is proportional to the distance that spring is extended from its rest position. Therefore, the scale markings on the spring balance are equally spaced. A spring scale cannot measure mass, only weight.\n\nA spring balance can be calibrated for the accurate measurement of mass in the location in which they are used, but many spring balances are marked right on their face \"Not Legal for Trade\" or words of similar import due to the approximate nature of the theory used to mark the scale. Also, the spring in the scale can permanently stretch with repeated use.\n\nA spring scale will only read correctly in a frame of reference where the acceleration in the spring axis is constant (such as on earth, where the acceleration is due to gravity). This can be shown by taking a spring scale into an elevator, where the weight measured will change as the elevator moves up and down changing velocities.\n\nIf two or more spring balances are hung one below the other in series, each of the scales will read approximately the same, the full weight of the body hung on the lower scale. The scale on top would read slightly heavier due to also supporting the weight of the lower scale itself.\n\nSpring balances come in different sizes. Generally, small scales that measure newtons will have a less firm spring (one with a smaller spring constant) than larger ones that measure tens, hundreds or thousands of newtons or even more depending on the scale of newtons used. The largest spring scale ranged in measurement from 5000–8000 newtons.\n\nA spring balance may be labeled in both units of force (pounds, liters) and mass (grams, kilograms). Strictly speaking, only the force values are correctly labeled. In order to infer that the labeled mass values are correct, an object must be hung from the spring balance at rest in an inertial reference frame, interacting with no other objects but the scale itself\n\nMain uses of spring balances are to weigh heavy loads such as trucks, storage silos, and material carried on a conveyor belt. They are also common in science education as basic accelerators. They are used when the accuracy afforded by other types of scales can be sacrificed for simplicity, cheapness, and robustness.\n\nA spring balance measures the weight of an object by opposing the force of gravity acting with the force of an extended spring.\n\nThe first spring balance in Britain was made around 1770 by Richard Salter of Bilston, near Wolverhampton. He and his nephews John & George founded the firm of \"George Salter & Co.\", still notable makers of scales and balances, who in 1838 patented the spring balance. They also applied the same spring balance principle to steam locomotive safety valves, replacing the earlier deadweight valves.\n\n\n"}
{"id": "5521966", "url": "https://en.wikipedia.org/wiki?curid=5521966", "title": "Super Virasoro algebra", "text": "Super Virasoro algebra\n\nIn mathematical physics, a super Virasoro algebra is an extension of the Virasoro algebra to a Lie superalgebra. There are two extensions with particular importance in superstring theory: the Ramond algebra (named after Pierre Ramond) and the Neveu–Schwarz algebra (named after André Neveu and John Henry Schwarz). Both algebras have \"N\"=1 supersymmetry and an even part given by the Virasoro algebra. They describe the symmetries of a superstring in two different sectors, called the Ramond sector and the Neveu–Schwarz sector.\n\nThere are two minimal extensions of the Virasoro algebra with \"N\" = 1 supersymmetry: the Ramond algebra and the Neveu–Schwarz algebra. They are both Lie superalgebras whose even part is the Virasoro algebra: this Lie algebra has a basis consisting of a central element \"C\" and generators \"L\" (for integer \"m\") satisfying\n\nformula_1\n\nwhere formula_2 is the Kronecker delta. \n\nThe odd part of the algebra has basis formula_3, where formula_4 is either an integer (the Ramond case), or half an odd integer (the Neveu–Schwarz case). In both cases, formula_5 is central in the superalgebra, and the additional graded brackets are given by\n\nformula_6\n\nformula_7\n\nNote that this last bracket is an anticommutator, not a commutator, because both generators are odd.\n\nThe unitary highest weight representations of these algebras have a classification analogous to that for the Virasoro algebra, with a continuum of representations together with an infinite discrete series. The existence of these discrete series was conjectured by Daniel Friedan, Zongan Qiu, and Stephen Shenker (1984). It was proven by Peter Goddard, Adrian Kent and David Olive (1986), using a supersymmetric generalisation of the coset construction or GKO construction.\n\nIn superstring theory, the fermionic fields on the closed string may be either periodic or anti-periodic on the circle around the string. States in the \"Ramond sector\" admit one option (periodic conditions are referred to as Ramond boundary conditions), described by the Ramond algebra, while those in the \"Neveu–Schwarz sector\" admit the other (anti-periodic conditions are referred to as Neveu–Schwarz boundary conditions), described by the Neveu–Schwarz algebra.\n\nFor a fermionic field, the periodicity depends on the choice of coordinates on the worldsheet. In the \"w-frame\", in which the worldsheet of a single string state is described as a long cylinder, states in the Neveu–Schwarz sector are anti-periodic and states in the Ramond sector are periodic. In the \"z-frame\", in which the worldsheet of a single string state is described as an infinite punctured plane, the opposite is true.\n\nThe Neveu–Schwarz sector and Ramond sector are also defined in the open string and depend on the boundary conditions of the fermionic field at the edges of the open string.\n\n\n"}
{"id": "3820851", "url": "https://en.wikipedia.org/wiki?curid=3820851", "title": "Technical illustration", "text": "Technical illustration\n\nTechnical Illustration is the use of illustration to visually communicate information of a technical nature. Technical illustrations can be components of technical drawings or diagrams. Technical illustrations in general aim \"to generate expressive images that effectively convey certain information via the visual channel to the human observer\".\n\nTechnical illustrations generally have to describe and explain the subjects to a nontechnical audience. Therefore, the visual image should be accurate in terms of dimensions and proportions, and should provide \"an overall impression of what an object is or does, to enhance the viewer’s interest and understanding\".\n\nToday, technical illustration can be broken down into three categories based on the type of communication:\n\n\nMain types of drawings in technical communication are:\n\nTechnical illustration uses several basic mechanical drawing configurations called axonometric projection. These are: \nTechnical illustration and computer-aided design can also use 3D and solidbody projections, such as rapid prototyping.\n\n"}
{"id": "765446", "url": "https://en.wikipedia.org/wiki?curid=765446", "title": "Tillamook Head", "text": "Tillamook Head\n\nTillamook Head is a high promontory on the Pacific coast of northwest Oregon in the United States. It is located in west-central Clatsop County, approximately 5 mi (8 km) southwest of Seaside. The promontory forms a steep rocky bluff on the ocean, approximately 1,200 ft (366 m) high, forested with Sitka Spruce. It is located in Ecola State Park.\n\nThe promontory is named after the Tillamook, a Salishan-speaking tribe of Native Americans that inhabited the coast south of the promontory in the 19th century. In 1806, Captain William Clark and 12 members of the Corps of Discovery journeyed south from Fort Clatsop, hiking over the promontory where they encountered a beached whale.\n\nAlso see Astoria Formation. Tillamook Head is a tilted remnant of a flow of 15-million-year-old Columbia River basalt. The lava welled up near modern-day Idaho, and flooded down the Columbia Gorge. It spread along the Oregon Coast to Tillamook Head, cooling to a 600-foot thick basalt sill.\n\n\n"}
{"id": "48246659", "url": "https://en.wikipedia.org/wiki?curid=48246659", "title": "William Andrew Clark", "text": "William Andrew Clark\n\nDr William Andrew Clark FRSE (1911-1983) was a Scottish botanist known for collections largely in the Outer Hebrides. He was an expert on spermatophytes and the flora of north-east England.\n\nHe was born in Girvan in Ayrshire the son of Thomas Clark. He attended Alva Academy 1916-1923 and then Harris Academy in Dundee 1923-1929.\n\nHe attended St Andrews University gaining a BSc in 1932 and a PhD in 1936. He lectured in Botany firstly at Liverpool University then at Newcastle University until retiring in 1976.\nHe was elected a Fellow of the Royal Society of Edinburgh in 1957.\n\nHe died in Ryton, Tyne and Wear on 19 November 1983.\n\nHe married Helena Heslop-Harrison, daughter of John William Heslop-Harrison FRSE in 1941.\n"}
{"id": "43607922", "url": "https://en.wikipedia.org/wiki?curid=43607922", "title": "Wonder en is gheen Wonder", "text": "Wonder en is gheen Wonder\n\nWonder en is gheen Wonder (\"Mystery is no Mystery\") is a popular science magazine of the Flemish skeptical association SKEPP. The paper was founded in 2000 by Tom Schoepen, who also served as its editor for its first ten years. The magazine is published four times a year and addresses pseudoscientific as well as science philosophical topics. The title is a reference to the 16th century Flemish mathematician and engineer Simon Stevin's commentary to his famous thought experiment: even if something looks strange, it can still have a naturalistic explanation. The subtitle \"Tijdschrift voor wetenschap en rede\" (\"Magazine for science and reason\") was taken from \"Skeptical Inquirer\", the most world-renowned skeptical magazine that is published by the Committee for Skeptical Inquiry.\n\nAs of 2016, the editorial staff is composed as follows:\n\n\n\n"}
