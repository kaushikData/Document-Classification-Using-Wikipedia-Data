{"id": "42972900", "url": "https://en.wikipedia.org/wiki?curid=42972900", "title": "Agua Preta virus", "text": "Agua Preta virus\n\nThe Água Preta virus is probably a herpes-like virus as determined by thin-section electron microscopy. It was isolated from a species of bat, Carolloa subrufa, in the Utinga Forest near Belem, Brazil.\n"}
{"id": "1973350", "url": "https://en.wikipedia.org/wiki?curid=1973350", "title": "Aquifex pyrophilus", "text": "Aquifex pyrophilus\n\nAquifex pyrophilus is a rod-shaped bacterium with a length of 2 to 6 micrometers and a diameter of around half a micrometer. It is one of a handful of species in the Aquificae phylum, an unusual group of thermophilic bacteria that are thought to be some of the oldest species in the bacteria domain.\n\n\"Aquifex pyrophilus\" grows best in water between 85 and 95 °C, and can be found near underwater volcanoes or hot springs. It typically uses oxygen in its respiration, producing water as a byproduct, thus leading to the name \"Aquifex,\" meaning \"water-maker.\" However \"A. pyrophilus\" can even grow anaerobically by reducing nitrogen instead of oxygen. Members of the species tend to form large cell conglomerations, comprising up to 100 individual cells. It was discovered just north of Iceland.\n\nThe genome of \"Aquifex aeolicus\", a member of the same genus, has been successfully mapped. Comparison of this genome to other organisms showed that around 16% of its genes originated from the Archaea domain. It is assumed that \"A. pyrophilus\" also has this property.\n\n"}
{"id": "19109106", "url": "https://en.wikipedia.org/wiki?curid=19109106", "title": "Baiji", "text": "Baiji\n\nThe baiji (, \"Lipotes vexillifer\", \"Lipotes\" meaning \"left behind\", \"vexillifer\" \"flag bearer\") is a functionally extinct species of freshwater dolphin formerly found only in the Yangtze River in China. Nicknamed \"Goddess of the Yangtze\" () in China, the dolphin is also called Chinese river dolphin, Yangtze River dolphin, whitefin dolphin and Yangtze dolphin. It was regarded as the goddess of protection by local fishermen and boatmen in China (Zhou, 1991). It is not to be confused with the Chinese white dolphin or the finless porpoise.\n\nThe baiji population declined drastically in decades as China industrialized and made heavy use of the river for fishing, transportation, and hydroelectricity. It has been credibly claimed, after surveys in the Yangtze River during the 1980s, that baiji could be the first dolphin species in history that humans have driven to extinction. A Conservation Action Plan for Cetaceans of the Yangtze River was approved by the Chinese Government in 2001. Efforts were made to conserve the species, but a late 2006 expedition failed to find any baiji in the river. Organizers declared the baiji functionally extinct. The baiji represents the first documented global extinction of a \"megafaunal\" vertebrate for over 50 years since the demise of the Japanese sea lion and the Caribbean monk seal in the 1950s. It also signified the disappearance of an entire mammal family of river dolphins (Lipotidae). The baiji's extinction would be the first recorded extinction of a well-studied cetacean species (it is unclear if some previously extinct varieties were species or subspecies) to be directly attributable to human influence.\n\nSwiss economist and CEO of the baiji.org Foundation, August Pfluger, funded an expedition in which an international team, taken in part from the National Oceanic and Atmospheric Administration and the Fisheries Research Agency in Japan, searched for six weeks for signs of the dolphin. The search took place almost a decade after the last exploration in 1997, which turned up only 13 of the cetaceans.\n\nIn August 2007, a Chinese man reportedly videotaped a large white animal swimming in the Yangtze. Although it was tentatively confirmed that the animal on the video is probably a baiji, the presence of only one or a few animals, particularly of advanced age, is not enough to save a functionally extinct species from true extinction. The last known living baiji was Qiqi (淇淇), who died in 2002. The World Wildlife Fund is calling for the preservation of any possible baiji habitat, in case the species is located and can be revived.\n\nA related creature from the Neogene is \"Parapontoporia\".\n\nBaiji were thought to breed in the first half of the year, the peak calving season being from February to April. A 30% pregnancy rate was observed. Gestation would last 10–11 months, delivering one calf at a time; the interbirth interval was 2 years. Calves measured around at birth, and nursed for 8–20 months. Males reached sexual maturity at age four, females at age six. Mature males were about (7.5 ft) long, females , the longest specimen . The animal weighed , with a lifespan estimated at 24 years in the wild. The Yangtze River Dolphin is pale blue to gray on the dorsal (back) side, and white on the ventral (belly) side. It has a long and slightly-upturned beak with 31–36 conical teeth on either jaw. Its dorsal fin is low and triangular in shape and resembles a light-colored flag when the dolphin swims just below the surface of the murky Yangtze River, hence the name \"white-flag\" dolphin. It has smaller eyes compared to oceanic dolphins.\n\nWhen escaping from danger, the baiji can reach , but usually stays within . Because of its poor vision, the baiji relies primarily on sonar for navigation. The sonar system also plays an important role in socializing, predator avoidance, group coordination, and expressing emotions. Sound emission is focused and highly directed by the shape of the skull and melon. Peak frequencies of echolocation clicks are between 70 kHz and 100 kHz.\n\nHistorically the baiji occurred along of the middle and lower reaches of the Yangtze from Yichang in the west to the mouth of the river, near to Shanghai, as well as in Poyang and Dongting lakes, and the smaller Qiantang river to the south. This had been reduced by several hundred kilometres both upstream and downstream, and was limited to the main channel of the Yangtze, principally the middle reaches between the two large tributary lakes, Dongting and Poyang. Approximately 12% of the world’s human population lives and works within the Yangtze River catchment area, putting pressure on the river. The construction of the Three Gorges Dam, along with other smaller damming projects, also led to habitat loss.\n\nFossil records suggest that the dolphin first appeared 25 million years ago and migrated from the Pacific Ocean to the Yangtze River 20 million years ago. It was one of four species of dolphins known to have made fresh water their exclusive habitat. The other five species, including the boto and the La Plata dolphin, have survived in the Río de la Plata and Amazon rivers in South America and the Ganges and Indus rivers on the Indian subcontinent.\n\nIt is estimated that there were 5,000 baiji when they were described in the ancient dictionary \"Erya\" circa 3rd century BC.\n\nIt is well known the river dolphins are not a natural group. Their mitochondrial genome reveals a split of two separate lineages, \"Platanista\" and \"Lipotes\" + (\"Inia\" + \"Pontoporia\"), having no sister relationship with each other, and the \"Platanista\" lineage is always within the odontocete clade instead of having a closer affinity to Mysticeti. The position of the \"Platanista\" is more basal, suggesting separate divergence of this lineage well before the other one. The \"Lipotes\" has a sister relationship with \"Inia + pontoporia\", and they together formed the sister group to the Delphinoidea. This result strongly supports paraphyly of the classical river dolphins, and the nonplatanistoid river dolphins do represent a monophyletic grouping, with the Lipotidae as the sister taxa to (Iniidae + Pontoporiidae), and is well congruent with the studies based\non short interspersed repetitive elements (SINEs).\n\nLow values of haplotype diversity and nucleotide diversity were found for the baiji of the Yangtze River. The analysis of molecular variance (AMOVA) supported a highlevel of overall genetic structure. The males having a higher genetic differentiation than the females suggested a significant female –biased dispersal.\n\nThe aquatic adaptations of the baiji and other cetaceans have happened slowly and can be linked to positively selected genes (PSGs) and/or other functional changes. Comparative genopic analyses have uncovered that the baiji have a slow molecular clock and molecular adaptations to their aquatic environment. This information leads scientists to conclude that a bottleneck must have occurred near the end of the last deglaciation, a time that coincided with rapid temperature decrease and a rise in eustatic sea level. Scientists have also looked into PSGs in the baiji genome which are used for DNA repair and response to DNA stimulus. These PSGs have not been found previously in any other mammal species. Pathways being used for DNA repair have been known to have a major impact on brain development and have been implicated in diseases including microcephaly. The slow down of the substitution rate among cetaceans may have been affected by the evolution of DNA damage pathways. Over time, river dolphins, including the baiji, have had a reduction in the size of their eyes and the acuity of their vision. This probably stems from poor visibility in fluvial and estuarine environments. When analyzing the baiji genome, scientists have found that there are four genes that have lost their function due to a frameshift mutation or premature stop codons. The baiji has the lowest single nucleotide polymorphism (SNP) frequency reported thus far among mammals. This low frequency could be related to the relatively low rate of molecular evolution in cetaceans; however, considering that the decrease in the rate of molecular evolution in the baiji was not as great as the decrease in heterozygosity rate, it is likely that much if the low genetic diversity observed was caused by the precipitous decline in the total baiji population in recent decades and the associated breedings.\n\nThe reconstructed demographic history over the last 100,000 years featured a continual population contraction through the last glacial maximum, a serious bottleneck during the last deglaciation, and sustained population growth after the eustatic sea level approached the current levels. The close correlation between population trends, regional temperatures, and eustatic sea levels suggest a dominant role for global and local climate changes in shaping the baiji's ancient population demography.\n\nPer Chinese folklore, a beautiful young girl is said to have lived with her stepfather on the banks of the river Yangtze. He was evil, and a greedy man out for his own self-interest. One day, he took the girl on a boat, intending to sell her on the market. Out on the river, though, he became infatuated with her beauty and tried to take advantage of her. But she freed herself by plunging into the river whereupon a big storm came and sank the boat. After the storm had thus settled, people saw a beautiful dolphin swimming – the incarnation of the girl – which became known as the ‘Goddess of the Yangtze.’ The baiji, in the region of Yangtze, is regarded as a symbol of peace and prosperity.\n\nIn the 1950s, the population was estimated at 6,000 animals, but declined rapidly over the subsequent five decades. Only a few hundred were left by 1970. Then the number dropped down to 400 by the 1980s and then to 13 in 1997 when a full-fledged search was conducted. Now the most endangered cetacean in the world, according to the \"Guinness Book of World Records\", the baiji was last sighted in August 2004, though there was a possible sighting in 2007. It is listed as an endangered species by the U.S. government under the Endangered Species Act. It is now thought to be extinct.\n\nThe World Conservation Union (IUCN) has noted the following as threats to the species: a period of hunting by humans during the Great Leap Forward, entanglement in fishing gear, the illegal practice of electric fishing, collisions with boats and ships, habitat loss, and pollution. Further studies have noted that a lack of information on the baiji's historical distribution or ecology, the environmental impact of the construction of the Three Gorges Dam on the living space of the baiji, and the failure to act for the protection of the baiji are also threats to the species.\n\nDuring the Great Leap Forward, when traditional veneration of the baiji was denounced, it was hunted for its flesh and skin, and quickly became scarce.\n\nAs China developed economically, pressure on the river dolphin grew significantly. Industrial and residential waste flowed into the Yangtze. The riverbed was dredged and reinforced with concrete in many locations. Ship traffic multiplied, boats grew in size, and fishermen employed wider and more lethal nets. Noise pollution caused the nearly blind animal to collide with propellers. Stocks of the dolphin's prey declined drastically in the late 20th century, with some fish populations declining to one thousandth of their pre-industrial levels.\n\nA range of anthropogenic led causes (e.g. boat collisions, dam construction) which also threaten freshwater cetaceans in other river systems, have been implicated in the decline of the baiji population. However, the primary factor was probably unsustainable by-catch in local fisheries, which use rolling hooks, nets (gill nets and fyke nets) and electrofishing; similarly by-catch constitutes the principal cause of mortality in many populations of small cetaceans worldwide. Although there are relatively few data available on baiji mortality, at least half of all known baiji deaths in the 1970s and 1980s were caused by rolling hooks and other fishing gear, and electrofishing accounted for 40% of baiji deaths recorded during the 1990s. Unlike most historical-era extinctions of large-bodied animals, the baiji was\nthe victim not of active persecution but of incidental mortality resulting from massive-scale human environmental impacts, primarily uncontrolled fishing.\n\nIts extinction merely reflects the latest stage in the progressive ecological deterioration of the Yangtze region. In the 1970s and 1980s, an estimated half of baiji deaths were attributed to entanglement in fishing gear and nets. By the early 2000s, electric fishing was considered \"the most important and immediate direct threat to the baiji's survival.\" Though outlawed, this fishing technique is widely and illegally practiced throughout China. The building of the Three Gorges Dam further reduced the dolphin's habitat and facilitated an increase in ship traffic; these were thought to make it extinct in the wild.\n\nThere are some scientists who have found that pollution has resulted in emerging diseases caused by parasitic infection in the Baiji population. The Baiji's reliance on aquatic environments could have resulted in interaction with both terrestrial and marine pathogen risks. Since the Baiji has a limited distribution endemic to the Yangtze River, the freshwater environment may have a higher pathogen level than marine waters (although systematic environmental studies have yet to be conducted). The pathogens in these waters could lead to viral infections that can result in epizootics, which has caused the deaths of thousands of marine mammals over the last twenty years. There have also been captured/killed individuals that have had helminth infestations in the stomach which leads scientists to believe that parasitic infections could be another cause of decline amongst the Baiji.\n\nIt has been noted, however, that the declining geographical range that baiji have been spotted in is not connected to the population loss of baiji. A model provided by Yangtze fishing communities show that the baiji population was not connected by geographical range or fragmentation of location, as the baiji make long-term and periodic movements throughout several years. The movements of the baiji left the species unaffected by dwindling geographical range.\n\n\nDuring the 1970s, China recognized the precarious state of the river dolphin. The government outlawed deliberate killing, restricted fishing, and established nature reserves.\n\nIn 1978, the Chinese Academy of Sciences established the Freshwater Dolphin Research Centre (淡水海豚研究中心) as a branch of the Wuhan Institute of Hydrobiology. In the 1980s and 1990s, several attempts were made to capture dolphins and relocate them to a reserve. A breeding program would then allow the species to recover and be reintroduced to the Yangtze after conditions improve. However, capturing the rare, quick dolphins proved to be difficult, and few captives survived more than a few months.\n\nThe first Chinese aquatic species protection organisation, the Baiji Dolphin Conservation Foundation of Wuhan (武汉白鱀豚保护基金), was founded in December 1996. It has raised 1,383,924.35 CNY (about 100,000 USD) and used the funds for in vitro cell preservation and to maintain the baiji facilities, including the Shishou Sanctuary that was flooded in 1998.\n\nSince 1992, five protected areas of the Yangtze have been designated as baiji reserves. Four were built in the main Yangtze channel where baiji are actively protected and fishing is banned: two national reserves (Shishou City and Xin-Luo) and two provincial (Tongling and Zhenjiang). In the past 20 years, five nature reserves have been\nestablished along the river. Imposing maximum prohibition of harmful and\nillegal fishing methods in the reserves might prolong the process of extinction\nof these cetaceans in the wild, but so far, the administrative measures taken\nin the reserves have not yet kept the baiji population from sharply declining. As\nhumans continue to occupy the river and use the natural resources it provided \n, the question as to whether the river itself can reach a point later in the future to become a\nhabitat for these species to live in once again remained, for the most part, unanswered by conversationalists. In Shishou, Hubei Province, and\nTongling, Anhui Province, the two semi-natural reserves established in these regions aimed to build in an environment \nfor the baiji, as well as another mammalian species, the finless porpoise, to breed. Through careful management,\nboth these species not only survived, but did in fact reproduced successfully enough to\nprovide some hope that the Baiji may be able to make a comeback.\n\nThe fifth protected area is an isolated oxbow lake located off of the north bank of the river near to Shishou City: the Tian-e-Zhou Oxbow Semi-natural Reserve. Combined, these five reserves cover just over , about 1/3 of the baijis range, leaving two-thirds of the species' habitat unprotected.\n\nAs well as these five protected areas there are also five \"Protection Stations\" in Jianli, Chenglingji, Hukou, Wuhu and Zhengjiang. These stations consist of two observers and a motorized fishing boat with the aim of conducting daily patrols, making observations and investigating reports of illegal fishing.\n\nIn 2001, the Chinese government approved a Conservation Action Plan for Cetaceans of the Yangtze River. This plan re-emphasised the three measures identified at the 1986 workshop and was adopted as the national policy for the conservation of the Baiji. Despite all of these workshops and conventions little money was available in China to aid the conservation efforts. It has been estimated that US$1 million was needed to begin the project and maintain it for a further 3 years.\n\nEfforts to save the mammals proved to be too little and too late. August Pfluger, chief executive of the Baiji.org Foundation, said, \"The strategy of the Chinese government was a good one, but we didn't have time to put it into action.\" Furthermore, the conservation attempts have been criticized, as even with the international attention about the need for conservation for the baiji, the Chinese government did not \"[make] any serious investment\" to protect the baiji.\n\nMost scientists agreed that the best course of action was an ex-situ effort working in parallel with an in situ effort. The deterioration of the Yangtze River had to be reversed to preserve the habitat. The ex-situ projects aimed to raise a large enough population over time so that some, if not all, of the dolphins could be returned to the Yangtze, so the habitat within the river had to be maintained anyway.\n\nThe Shishou Tian-e-Zhou is a long, wide oxbow lake located near Shishou City in Hubei Province. Shishou has been described as being \"like a miniature Yangtze … possessing all of the requirements for a semi-natural reserve\". From the designation as a national reserve in 1992 it has been intended to be used for not only the baiji but also the Yangtze finless porpoise. In 1990 the first finless porpoises were relocated to the reserve and since then have been surviving and reproducing well. As of April 2005 26 finless porpoises were known to live in the reserve. A baiji was introduced in December 1995, but died during the summer flood of 1996. To deal with these annual floods a dyke was constructed between the Yangtze and Shishou. Now water is controlled from a sluice gate located at the downstream mouth of the oxbow lake. It has been reported that since the installation of this sluice gate, water quality has declined since no annual transfer of nutrients can occur. Roughly 6,700 people live on the ‘island’ within the oxbow lake and so some limited fishing is permitted.\n\nThe success of Shishou with the porpoises and with migratory birds and other wetland fauna encouraged the local Wetlands Management Team to put forward an application to award the site Ramsar status. It has also been noted that the site has incredible potential for ecotourism, which could be used to generate much needed revenue to improve the quality of the reserve. The necessary infrastructure does not currently exist to realize these opportunities.\n\nA baiji conservation dolphinarium was established at the Institute of Hydrobiology (IHB) in Wuhan in 1992. This was planned as a backup to any other conservation efforts by producing an area completely protected from any threats, and where the baiji could be easily observed. The site includes an indoor and outdoor holding pool, a water filtration system, food storage and preparation facilities, research labs and a small museum. The aim is to also generate income from tourism which can be put towards the baiji plight. The pools are not very large ( arc [kidney shaped] x wide x deep, diameter, deep and diameter, deep) and so are not capable of holding many baijis at one time.\n\nDouglas Adams and Mark Carwardine documented their encounters with the endangered animals on their conservation travels for the BBC programme \"Last Chance to See\". Through firsthand experience, they went to China, drinking Baiji beer and Baiji cola, staying in the Baiji Hotel and using Lipotes vexillifer toilet paper. They came across Baiji weighing scales and Baiji fertilizer. They met Qi Qi, the beautiful bluish-grey dolphin with a long, narrow, slightly upturned beak, a low triangular dorsal fin, broad flippers with tiny eyes. Qi-Qi was just a year old then, injured by fishing hooks in 1980 and taken into captivity to be nursed back to health. Out of the seven times Mark and Douglas had visited China, never did they encounter a wild and free Yangtze river dolphin. It is even more impossible now with the likelihood that Lipotes vexillfer may be the first cetacean to have been driven to extinction by human activity. The book by the same name, published in 1990, included pictures of a captive specimen, a male named Qi Qi (淇淇) that lived in the Wuhan Institute of Hydrobiology dolphinarium from 1980 to July 14, 2002. Discovered by a fisherman in Dongting Lake, he became the sole resident of the Baiji Dolphinarium (白鱀豚水族馆) beside East Lake. A sexually mature female was captured in late 1995, but died after half a year in 1996 when the Tian-e-Zhou Oxbow Nature Reserve (石首半自然白鱀豚保护区), which had contained only finless porpoises since 1990, was flooded.\n\nThe Xinhua News Agency announced on December 4, 2006 that no Chinese river dolphins were detected in a six-week survey of the Yangtze River conducted by 30 researchers. The failure of the Yangtze Freshwater Dolphin Expedition () raised suspicions of the first unequivocal extinction of a cetacean species due to human action (some extinct baleen whale populations might not have been distinct species). Poor water and weather conditions may have prevented sightings, but expedition leaders declared it \"functionally extinct\" on December 13, 2006, as fewer are likely to be alive than are needed to propagate the species. However, footage believed to be a baiji from August 2007 was released to the public.\n\nThe Japanese sea lion and Caribbean monk seal disappeared in the 1950s, the last aquatic mammals to become extinct. Several land-based mammal species and subspecies have disappeared since then. If the baiji is now extinct, the vaquita has become the most endangered marine mammal species.\n\nSome scientists retain hope for the species:\nA report of the expedition was published online in the journal \"Biology Letters\" on August 7, 2007, in which the authors conclude \"We are forced to conclude that the baiji is now likely to be extinct, probably due to unsustainable by-catch in local fisheries\".\n\n\"Witness to Extinction: How We Failed To Save The Yangtze River Dolphin\", an account of the 2006 baiji survey by Samuel Turvey, the lead author of the \"Biology Letters\" paper, was published by Oxford University Press in autumn 2008. This book investigated the baiji's probable extinction within the wider-scale context of how and why international efforts to conserve the species had failed, and whether conservation recovery programmes for other threatened species were likely to face similar potentially disastrous administrative hurdles.\n\nSome reports suggest that information about the baiji and its demise is being suppressed in China. Other reports cite government media English language reports in China Central Television and Xinhua News Agency as evidence to the contrary.\n\nIn August 2007, Zeng Yujiang reportedly videotaped a large white animal swimming in the Yangtze in Anhui Province. Wang Kexiong of the Institute of Hydrobiology of the Chinese Academy of Sciences has tentatively confirmed that the animal on the video is a baiji.\n\nOn October 3, 2011 the sighting of almost 20 porpoises was reported in Chinese media. The sighting was done from a bridge in Nanjing city. It should be noted however, that the sighting has not been confirmed by independent media sources.\n\nOn October 11, 2007, Chinese state media announced that under a development plan an additional 4,000,000 people will be relocated from their homes near the dam by the year 2020 due to ecological concerns, while a forum of officials and experts warned of a possible “environmental catastrophe” if preventive measures are not taken. Currently, the quality of water in the Yangtze is falling rapidly, due to the dam's preventing dispersal of pollutants; algae blooms have risen progressively since the dam’s construction; and soil erosion has increased, causing riverbank collapses and landslides. The report detailing this was officially released in September 2007. Senior Chinese government officials and scholars said the dam could cause a “huge disaster ... if steps are not taken promptly.” The same scholars and officials previously had defended the Three Gorges Dam project. Xinhua also reported that tens of billions of yuan had been spent to prevent pollution and geological disasters by tree planting, measures to maintain species diversification, shutting down 1,500 polluting industrial and mining enterprises and building 70 sewage and waste treatment plants, all of which are \"progressing well.\" \n\nIn October 2016 several news sources announced a recent sighting of what has been speculated to be a baiji.\n\n\n\n"}
{"id": "2072416", "url": "https://en.wikipedia.org/wiki?curid=2072416", "title": "Bangladesh National Museum", "text": "Bangladesh National Museum\n\nThe Bangladesh National Museum (), is the national museum of Bangladesh. The museum is well organized and displays have been housed chronologically in several departments like department of ethnography and decorative art, department of history and classical art, department of natural history, and department of contemporary and world civilization. The museum also has a rich conservation laboratory. Nalini Kanta Bhattasali served as the first curator of the museum during 1914–1947.\nBangladesh National Museum was originally established on 20 March 1913, albeit under another name (the Dhaka Museum), and formally inaugurated on 7 August 1913 by Thomas Gibson-Carmichael, 1st Baron Carmichael, the governor of Bengal. In July 1915 it was handed over to the Naib-Nazim of Dhaka.Bangladesh National Museum was formed through the incorporation of Dhaka museum and it was made the national museum of Bangladesh on 17 November 1983. It is located at Shahbag, Dhaka.\n\nThe ground floor consists of some old guns at the entrance and the hall where the people book their tickets or assemble to hear the history of the museum. The hall leads to a grand staircase. Beside the hall, there is a smaller room which also acts like the hall (it is also used by the guides to tell the visitors about the history) and a simple staircase.\n\nThe 1st floor is divided into 22 rooms.\n\nThe first room displays a large map showing the map of Bangladesh and its 64 districts.\n\nThe 2nd room consists of an under going work of a large statue of a royal Bengal tiger.\n\nThese rooms consist of natural beauties found in Bangladesh. In one of the room there is showcase of a tongue of a whale.\n\nThe other rooms contain some historic relics of Bengal up to 1900. There is a room which shows the different boats used by the rural people.\n\nThe 2nd floor consists of photos of famous people and showcases the Bangladesh Liberation War and the Language Movement of 1952. There are posters used in the war, a torture machine and much more. There are also two libraries.\n\nThe 3rd floor consists of pictures of international politicians, artists, scientists, famous pictures and four international galleries - Chinese, Korean, Iranian and Swiss.\n\n"}
{"id": "43646756", "url": "https://en.wikipedia.org/wiki?curid=43646756", "title": "Cosmic Evolution (book)", "text": "Cosmic Evolution (book)\n\nCosmic Evolution: The Rise of Complexity in Nature (2001) is a book by Harvard astrophysicist Eric Chaisson. It examines cosmic evolution which includes the history of natural evolution from the Big Bang to the present from the perspective of the emerging multi-scientific discipline of Big History. It offers an explanation of why simple structures billions of years ago gave way to more complex structures, such as stars, planets, life, and human beings in complex civilizations. It is written for a general audience interested in science.\n\nChaisson argues that cosmic history can be examined from the perspective of energy flows. He analyzes the flows of energy through various objects, and argues that these flows are relevant to understanding the relative complexity of these objects. He suggests that a key measure for scientific analysis should be energy per second per gram, termed \"energy rate density,\" and that analysis using this yardstick can be used to explain not only human evolution but cosmic evolution. He sees energy as \"work per unit time\" which he equates with power, and shows how energy rate density in some structures has increased over time. For example, in Chaisson's view, the human brain uses a much greater amount of energy, relative to its size, than a galaxy. He suggests that energy lets us make \"order out of disorder\"; for example, an air conditioner, which draws current from an electric outlet, can turn a less-complex zone of lukewarm air into two more-complex zones of hot air and cold air, and in so doing, it reverses the disorder in a room. According to his view, organisms do much the same thing with energy but in a more complex way, by taking in food instead of electrons, to keep themselves from disintegrating and becoming less complex; he analyzes energy flows in not just organisms and society, but in inanimate structures such as stars, galaxies, planets. \n\nChaisson notes that increases in complexity are consistent with the second law of thermodynamics; according to one reviewer, the second law might suggest that complexity should decrease with the universe \"slouching toward disorder.\" However, Chaisson argues that complexity can increase because complex structures such as a star can \"generate and sustain complexity by exporting enough disorder to its surrounding environment to more than make up for its internal gains.\" From this perspective, Chaisson offers a definition of life as an \"open, coherent, space-time structure maintained far from thermodynamic equilibrium by a flow of energy through it.\" \n\nReactions to Chaisson's book are generally positive, although different reviewers took issue with some of his points and writing style. Biologist Daniel W. McShea originally noted that Chaisson is \"prone to using inflated language,\" but a decade later in another review of his work notes that \"Chaisson offers data showing a trend in what he calls energy rate density ... over the history of life (and even over the much longer history of the universe), that's really saying something.\" Critic Stewart Kauffman found the book to be a \"wonderful discussion.\" Critic Hillel Braude wrote \"Cosmic Evolution draws from a rich scientific palette to paint a colorful explanatory model of the ascending complexity in nature.\" Critic Charles Seife wrote highly about Chaisson's book although he criticized Chaisson's definition of life as being \"such a broad definition\" that it becomes meaningless, while acknowledging that Chaisson's analysis \"gives the theory some numerical muscle.\" Many more excerpts from reviews of this book are collected here \n\nChaisson chose to use the obsolete cgs (centimetre, gram, second) system of measurement, rather than SI units as is standard current practice, for his calculations and numerical estimates - thus quoting energy in ergs (one ten millionth of a Joule), also using calories, and sometimes kilocalories as alternative measures of energy.\n\n"}
{"id": "22980014", "url": "https://en.wikipedia.org/wiki?curid=22980014", "title": "Dan Stannard", "text": "Dan Stannard\n\nDavid 'Dan' Stannard (born 1937 Peshawar, Pakistan of British parents) was a Zimbabwe policeman who became a Branch Director of the Central Intelligence Organisation, under Ken Flower, thus serving under both the Ian Smith and Robert Mugabe administrations. He subsequently became manager of Zimbabwe's cricket team in addition to overseeing security for the Zimbabwe Cricket Union.\n\nStannard, joined the British South Africa Police (BSAP) in March 1957, becoming a career policeman, and a detective in the Criminal Investigation Department (CID), serving with distinction. During his tenure in the CID, he served in several specialist sections, including the Fraud Squad and later headed the section dealing with serious crimes of violence. Early in his career, he was responsible for investigating the Crocodile Gang (a member of which was eventually to become his political master) for murders and other serious crimes while stationed in the Manicaland Province. At one time he investigated elements of Rhodesia's most prestigious military unit – the Selous Scouts – concerning allegations of poaching and ivory trafficking. Dan Stannard was seconded to the Rhodesian Special Branch (SB) as Acting Provincial Special Branch Officer, Salisbury and Mashonaland, shortly before Zimbabwean independence.\n\nAt the time of Independence in 1980, Stannard was appointed the official Liaison Officer to work with both ZANU and ZAPU guerrillas who were then based at the Audio Visual Centre at the University. After independence he was transferred to Special Branch Headquarters, where he became Deputy Director (Internal) (DDIN) of Branch I, under Mike Reeves.\n\nHe later served as the Director Internal (DIN) of CIO, effectively the head of the Rhodesian Special Branch and oversaw internal intelligence-gathering for the CIO. At the time Zimbabwe was celebrating its new found independence, Stannard foiled an assassination attempt on Zimbabwean presidential elect Robert Mugabe by a South African fifth column in 1980, an event for which he was awarded the Gold Cross of Zimbabwe.\n\nAs a senior adviser to the post-independence regime, Stannard and many former Rhodesian agents were retained to train their successors. Emmerson Mnangagwa, the first minister of security, transferred all SB members into the CIO to obviate intelligence getting into the possession of Joshua Nkomo, who was then Minister of Home Affairs. The modus operandi of Rhodesia's campaign to infiltrate political parties, silence public demonstrations, and destabilise action groups during the colonial period were thus passed on to a new generation of partisan intelligence operatives.\n\nAfter retiring from the CIO in 1992, Stannard became manager of the Zimbabwe cricket team. As many white cricketers, loyally representing their nation, had family affected by the government's chaotic land redistribution efforts, he found himself involved with their pleas and then lobbying for land redesignation to avoid the Mugabe purge, but not always with success.\n\nStannard's brother Richard, a former British military policeman, was a public relations officer for the Rhodesian Security Forces during the long-running bush war. Richard later joined the Zimbabwe Intelligence Corps to serve alongside Danny. Their nephew, also Richard Stannard, was a much-decorated veteran of the Rhodesian SAS and South African Special Forces who later became embroiled with an attempted coup d'etat in the Seychelles.\n\n"}
{"id": "14371537", "url": "https://en.wikipedia.org/wiki?curid=14371537", "title": "Dhori virus", "text": "Dhori virus\n\nDhori virus (DHOV) is a species of the genus \"Thogotovirus\" and a member of the family \"Orthomyxoviridae\". Its hosts are ticks, mosquitoes, and mammals (including humans). Dhori virus is lethal to mice, causing systemic pathologic changes similar to those reported in humans with virulent influenza A (H5N1) virus infection.\n\nBatken virus (BKNV) is considered a subtype of Dhori virus. Serological cross-reactions between Batken and Dhori viruses indicate a phylogenetic relationship between these viruses.\n"}
{"id": "2405440", "url": "https://en.wikipedia.org/wiki?curid=2405440", "title": "Enthalpy of atomization", "text": "Enthalpy of atomization\n\nThe enthalpy of atomization (also atomisation in British spelling) is the enthalpy change that accompanies the total separation of all atoms in a chemical substance (either a chemical element or a chemical compound). This is often represented by the symbol Δ\"H\" or Δ\"H\". All bonds in the compound are broken in atomization and none are formed, so enthalpies of atomization are always positive. The associated standard enthalpy is known as the Standard enthalpy of atomization, Δ\"H\"/(kJ mol), at 298.15 K (or 25 degrees Celsius) and 101.3 kPa.\n\nEnthalpy of atomization is the amount of enthalpy change when a compound's bonds are broken and the component atoms are reduced to individual atoms.\n\nEnthalpy of atomization is denoted by the symbol ΔHa. The enthalpy change of atomization of gaseous HO is, for example, the sum of the HO–H and H–O bond dissociation enthalpies.\n\nThe enthalpy of atomization of an elemental solid is exactly the same as the enthalpy of sublimation for any elemental solid that becomes a monatomic gas upon evaporation.\n\nWhen a diatomic element is converted to gaseous atoms, only half a mole of molecules will be needed, as the standard enthalpy change is based purely on the production of one mole of gaseous atoms. When the atoms in the molecule are different isotopes of the same element the calculation becomes non-trivial.\n\nStandard enthalpy of atomization is the enthalpy change when 1 mol of a substance is dissociated completely into atoms under standard conditions (298.15K, 1 bar).\n\n"}
{"id": "41696772", "url": "https://en.wikipedia.org/wiki?curid=41696772", "title": "Erich Clar", "text": "Erich Clar\n\nErich Clar (August 23, 1902 – March 27, 1987) was an organic chemist who studied polycyclic aromatic hydrocarbon chemistry. He is considered as the father of that field. He authored the two-volume \"Polycyclic Hydrocarbons\", which described the syntheses, properties, and UV-visible absorption spectra of hundreds of PAHs. He created the Sextet Theory, now eponymously called \"Clar's rule\", to describe the behavior of PAH isomers. This was described in his book \"The Aromatic Sextet\". He was awarded the August Kekulé Medal by the Chemical Society of the GDR in 1965, the highest award given by that society to foreign scientists, and the first Polycyclic Aromatic Hydrocarbon Research Award of the International Symposium on Polynuclear Aromatic Hydrocarbons in 1987.\n"}
{"id": "448199", "url": "https://en.wikipedia.org/wiki?curid=448199", "title": "Force-field analysis", "text": "Force-field analysis\n\nForce-field analysis is a development in social science. It provides a framework for looking at the factors (\"forces\") that influence a situation, originally social situations. It looks at forces that are either driving movement toward a goal (helping forces) or blocking movement toward a goal (hindering forces). The principle, developed by Kurt Lewin, is a significant contribution to the fields of social science, psychology, social psychology, community psychology, communication, organizational development, process management, and change management.\n\nLewin, a social psychologist, believed the \"field\" to be a Gestalt psychological environment existing in an individual's (or in the collective group) mind at a certain point in time that can be mathematically described in a topological constellation of constructs. The \"field\" is very dynamic, changing with time and experience. When fully constructed, an individual's \"field\" (Lewin used the term \"life space\") describes that person's motives, values, needs, moods, goals, anxieties, and ideals. \n\nLewin believed that changes of an individual's \"life space\" depend upon that individual's internalization of external stimuli (from the physical and social world) into the \"life space\". Although Lewin did not use the word \"experiential\" (see experiential learning), he nonetheless believed that interaction (experience) of the \"life space\" with \"external stimuli\" (at what he calls the \"boundary zone\") were important for development (or regression). For Lewin, development (or regression) of an individual occurs when their \"life space\" has a \"boundary zone\" experience with external stimuli. Note, it is not merely the experience that causes change in the \"life space\", but the acceptance (internalization) of external stimuli.\n\nLewin took these same principles and applied them to the analysis of group conflict, learning, adolescence, hatred, morale, German society, etc. This approach allowed him to break down common misconceptions of these social phenomena, and to determine their basic elemental constructs. He used theory, mathematics, and common sense to define a force field, and hence to determine the causes of human and group behavior.\n\n\n\n"}
{"id": "8153214", "url": "https://en.wikipedia.org/wiki?curid=8153214", "title": "Garvan–Olin Medal", "text": "Garvan–Olin Medal\n\nThe Francis P. Garvan–John M. Olin Medal is an annual award that recognizes distinguished scientific accomplishment, leadership and service to chemistry by . The Award is offered by the American Chemical Society (ACS), and consists of a cash prize (US$5,000) and a medal. The medal was designed by Margaret Christian Grigor.\n\nAny individual may nominate a single eligible chemist in one year. Nominees must be a female citizen of the United States.\n\nThe award was established by Francis Garvan and Mabel Brady Garvan in 1936 in honor of their daughter. It was initially an essay contest, that ran for seven years, as a memorial to their daughter (the American Chemical Society's Prize Essay Contest). It was solely funded by the Francis P. Garvan Medal Endowment from its establishment in 1936 until 1979. W. R. Grace & Co. assumed co-sponsorship of the award from 1979 to 1983. In 1984, Olin Corporation assumed co-sponsorship. Mabel Brady Garvan remained involved with the Award through 1967.\n\nThe Garvan–Olin Award is the ACS' third-oldest award, and the first award established to honor women chemists.\n\n"}
{"id": "43933143", "url": "https://en.wikipedia.org/wiki?curid=43933143", "title": "George Washington Bacon", "text": "George Washington Bacon\n\nGeorge Washington Bacon (1830–1922) was an American mapmaker and publisher who developed a successful business producing maps of London.\n\nIn 1861, Bacon founded a series of businesses. He became bankrupt in 1867, after failing to keep on top of managing these businesses.\n\nIn 1870, Bacon started his business, G.W. Bacon & Co., on 127 Strand, London. He based his atlases on the plates used by Edward Weller for his \"Weekly Dispatch Atlas\". In 1893, he bought the map business of James Wyld.\n\nAround 1900, G.W. Bacon was purchased by the Scottish publishing house of W.& A.K. Johnston and incorporated into their own. Maps using the Bacon brand were being produced as late as 1956. About 1967 their name was changed to Johnston & Bacon.\n\n"}
{"id": "496670", "url": "https://en.wikipedia.org/wiki?curid=496670", "title": "Gibberellin", "text": "Gibberellin\n\nGibberellins (GAs) are plant hormones that regulate various developmental processes, including stem elongation, germination, dormancy, flowering, flower development and leaf and fruit senescence. GAs are one of the longest-known classes of plant hormone. It is thought that the (albeit unconscious) selective breeding of crop strains that were deficient in GA synthesis was one of the key drivers of the \"green revolution\" in the 1960's, a revolution that is credited to have saved over a billion lives worldwide.\n\nThe first inroads into the understanding of GAs were developments from the plant pathology field, with studies on the \"bakanae\", or \"foolish seedling\" disease in rice. Foolish seedling disease causes a strong elongation of rice stems and leaves and eventually causes them to topple over. In 1926, Japanese scientist Eiichi Kurosawa identified that foolish seedling disease was caused by the fungus \"Gibberella fujikuroi.\" Later work at the University of Tokyo (notable from Yabuta, Sumiki and Hayashi) showed that a substance produced by this fungus triggered the symptoms of foolish seedling disease and they named this substance \"gibberellin\".\n\nThe increased communication between Japan and the west following World War II enhanced the interest in gibberellin in the United Kingdom (UK) and the United States (US). Workers at Imperial Chemical Industries in the UK and the Department of Agriculture in the US both independently isolated gibberellic acid (with the Americans originally referring to the chemical as \"gibberellin-X\", before adopting the British name and the chemical is known as gibberellin A or GA in Japan).\n\nKnowledge of gibberellins spread around the world as the potential for its use on various commercially important plants became more obvious. For example, research that started at the University of California, Davis in the mid-1960s led to its commercial use on Thompson seedless table grapes throughout California by 1962. A known gibberellin biosynthesis inhibitor is paclobutrazol (PBZ), which in turn inhibits growth and induces early fruitset as well as seedset.\n\nA chronic food shortage was feared during the rapid climb in world population in the 1960s. This was averted with the development of a high-yielding variety of rice. This variety of semi-dwarf rice is called IR8, and it has a short height because of a mutation in the sd1 gene. Sd1 encodes GA20ox, so a mutant sd1 is expected to exhibit a short height that is consistent with GA deficiency.\n\nAll known gibberellins are diterpenoid acids that are synthesized by the terpenoid pathway in plastids and then modified in the endoplasmic reticulum and cytosol until they reach their biologically-active form. All gibberellins are derived via the \"ent\"-gibberellane skeleton, but are synthesised via ent-kaurene. The gibberellins are named GA1 through GAn in order of discovery. Gibberellic acid, which was the first gibberellin to be structurally characterized, is GA3.\n\nAs of 2003, there were 126 GAs identified from plants, fungi, and bacteria.\n\nGibberellins are tetracyclic diterpene acids. There are two classes based on the presence of either 19 or 20 carbons. The 19-carbon gibberellins, such as gibberellic acid, have lost carbon 20 and, in place, possess a five-member lactone bridge that links carbons 4 and 10. The 19-carbon forms are, in general, the biologically active forms of gibberellins. Hydroxylation also has a great effect on the biological activity of the gibberellin. In general, the most biologically active compounds are dihydroxylated gibberellins, which possess hydroxyl groups on both carbon 3 and carbon 13. Gibberellic acid is a dihydroxylated gibberellin.\n\nThe bioactive GAs are GA1, GA3, GA4, and GA7. There are three common structural traits between these GAs: 1) a hydroxyl group on C-3β, 2) a carboxyl group on C-6, and 3) a lactone between C-4 and C-10. The 3β-hydroxyl group can be exchanged for other functional groups at C-2 and/or C-3 positions. GA5 and GA6 are examples of bioactive GAs that do not have a hydroxyl group on C-3β. The presence of GA1 in various plant species suggests that it is a common bioactive GA.\n\nGibberellins are involved in the natural process of breaking dormancy and other aspects of germination. Before the photosynthetic apparatus develops sufficiently in the early stages of germination, the stored energy reserves of starch nourish the seedling. Usually in germination, the breakdown of starch to glucose in the endosperm begins shortly after the seed is exposed to water. Gibberellins in the seed embryo are believed to signal starch hydrolysis through inducing the synthesis of the enzyme α-amylase in the aleurone cells. In the model for gibberellin-induced production of α-amylase, it is demonstrated that gibberellins (denoted by GA) produced in the scutellum diffuse to the aleurone cells, where they stimulate the secretion α-amylase. α-Amylase then hydrolyses starch, which is abundant in many seeds, into glucose that can be used in cellular respiration to produce energy for the seed embryo. Studies of this process have indicated gibberellins cause higher levels of transcription of the gene coding for the α-amylase enzyme, to stimulate the synthesis of α-amylase.\n\nGibberellins are produced in greater mass when the plant is exposed to cold temperatures. They stimulate cell elongation, breaking and budding, seedless fruits, and seed germination. They do the last by breaking the seed’s dormancy and acting as a chemical messenger. Its hormone binds to a receptor, and Ca activates the protein calmodulin, and the complex binds to DNA, producing an enzyme to stimulate growth in the embryo.\n\nGAs are usually synthesized from the methylerythritol phosphate (MEP) pathway in higher plants. In this pathway, bioactive GA is produced from trans-geranylgeranyl diphosphate (GGDP). In the MEP pathway, three classes of enzymes are used to yield GA from GGDP: 1) terpene synthases (TPSs), 2) cytochrome P450 monooxygenases (P450s), and 3) 2-oxoglutarate–dependent dioxygenases (2ODDs). There are 8 steps in the methylerythritol phosphate pathway: \n- 1) GGDP is converted to ent-copalyl diphosphate (ent-CPD) by ent-copalyl diphosphate synthase \n- 2) etn-CDP is converted to ent-kaurene by ent-kaurene synthase \n- 3) ent-kaurene is converted to ent-kaurenol by ent-kaurene oxidase (KO) \n- 4) ent-kaurenol is converted to ent-kaurenal by KO \n- 5) ent-kaurenal is converted to ent-kaurenoic acid by KO \n- 6) ent-kaurenoic acid is converted to ent-7a-hydroxykaurenoic acid by ent-kaurene acid oxidase (KAO) \n- 7) ent-7a-hydroxykaurenoic acid is converted to GA12-aldehyde by KAO\n- 8) GA12-aldehyde is converted to GA12 by KAO. GA12 is processed to the bioactive GA4 by oxidations on C-20 and C-3, which is accomplished by 2 soluble ODDs: GA 20-oxidase and GA 3-oxidase.\n\nOne or two genes encode the enzymes responsible for the first steps of GA biosynthesis in Arabidopsis and rice. The null alleles of the genes encoding CPS, KS, and KO result in GA-deficient Arabidopsis dwarves. Multigene families encode the 2ODDs that catalyze the formation of GA12 to bioactive GA4.\n\nAtGA3ox1 and AtGA3ox2, two of the four genes that encode GA3ox in Arabidopsis, affect vegetative development. Environmental stimuli regulate AtGA3ox1 and AtGA3ox2 activity during seed germination. In Arabidopsis, GA20ox overexpression leads to an increase in GA concentration.\n\nMost bioactive GAs are located in actively growing organs on plants. Both GA20ox and GA3ox genes (genes coding for GA 20-oxidase and GA 3-oxidase) and the SLENDER1 gene (a GA signal transduction gene) are found in growing organs on rice, which suggests bioactive GA synthesis occurs at their site of action in growing organs in plants. During flower development, the tapetum of anthers is believed to be a primary site of GA biosynthesis.\n\nArabidopsis, a plant, and Gibberella fujikuroi, a fungus, possess different GA pathways and enzymes. P450s in fungi perform functions analogous to the functions of KAOs in plants. The function of CPS and KS in plants is performed by a single enzyme, CPS/KS, in fungi. In fungi, the GA biosynthesis genes are found on one chromosome, but in plants, they are found randomly on multiple chromosomes. Plants produce low amount of GA3, therefore the GA3 is produced for industrial purposes by microorganisms. Industrially the gibberellic acid can be produced by submerged fermentation, but this process presents low yield with high production costs and hence higher sale value, nevertheless other alternative process to reduce costs of the GA3 production is Solid-State Fermentation (SSF) that allows the use of agro-industrial residues.\n\nSeveral mechanisms for inactivating GAs have been identified. 2β-hydroxylation deactivates GA, and is catalyzed by GA2-oxidases (GA2oxs). Some GA2oxs use C19-GAs as substrates, and other GA2oxs use C20-GAs. Cytochrome P450 mono-oxygenase, encoded by elongated uppermost internode (eui), converts GAs into 16α,17-epoxides. Rice eui mutants amass bioactive GAs at high levels, which suggests cytochrome P450 mono-oxygenase is a main enzyme responsible for deactivation GA in rice. The Gamt1 and gamt2 genes encode enzymes that methylate the C-6 carboxyl group of GAs. In a gamt1 and gamt2 mutant, concentrations of GA is developing seeds is increased.\n\nFeedback and feedforward regulation maintains the levels of bioactive GAs in plants. Levels of \"AtGA20ox1\" and \"AtGA3ox1\" expression are increased in a GA deficient environment, and decreased after the addition of bioactive GAs, Conversely, expression of \"AtGA2ox1\" and \"AtGA2ox2\", GA deactivation genes, is increased with addition of GA.\n\nThe auxin indole-3-acetic acid (IAA) regulates concentration of GA1 in elongating internodes in peas. Removal of IAA by removal of the apical bud, the auxin source, reduces the concentration of GA1, and reintroduction of IAA reverses these effects to increase the concentration of GA1. This phenomenon has also been observed in tobacco plants. Auxin increases GA 3-oxidation and decreases GA 2-oxidation in barley. Auxin also regulates GA biosynthesis during fruit development in peas. These discoveries in different plant species suggest the auxin regulation of GA metabolism may be a universal mechanism.\n\nEthylene decreases the concentration of bioactive GAs.\n\nRecent evidence suggests fluctuations in GA concentration influence light-regulated seed germination, photomorphogenesis during de-etiolation, and photoperiod regulation of stem elongation and flowering. Microarray analysis showed about one fourth cold-responsive genes are related to GA-regulated genes, which suggests GA influences response to cold temperatures. Plants reduce growth rate when exposed to stress. A relationship between GA levels and amount of stress experienced has been suggested in barley.\n\nBioactive GAs and abcisic acid levels have an inverse relationship and regulate seed development and germination. Levels of FUS3, an Arabidopsis transcription factor, are upregulated by ABA and downregulated by GA, which suggests that there is a regulation loop that establishes the balance of GA and ABA.\n\nIn the early 1990's, there were several lines of evidence that suggested the existence of a GA receptor in oat seeds that was located at the plasma membrane. However despite intensive research, to date, no membrane-bound GA receptor has been isolated. This, along with the discovery of a soluble receptor, GA INSENSITIVE DWARF 1 (GID1) has led many to doubt that a membrane-bound receptor exists.GID1 was first identified in rice and in Arabidopsis there are three orthologs of GID1, AtGID1a, b, and c. GID1s have a high affinity for bioactive GAs. GA binds to a specific binding pocket on GID1; the C3-hydoxyl on GA makes contact with tyrosine-31 in the GID1 binding pocket. GA binding to GID1 causes changes in GID1 structure, causing a 'lid' on GID1 to cover the GA binding pocket. The movement of this lid results in the exposure of a surface which enables the binding of GID1 to DELLA proteins.\n\nDELLA proteins, such as SLR1 in rice or GAI and RGA in Arabidopsis are repressors of plant development. DELLAs inhibit seed germination, seed growth, flowering and GA reverses these effects. DELLA proteins are characterized by the presence of a DELLA motif (aspartate-glutamate-leucine-leucine-alanine or D-E-L-L-A in the single letter amino acid code).\n\nWhen GA binds to the GID1 receptor, it enhances the interaction between GID1 and DELLA proteins, forming a GA-GID1-DELLA complex. When in the GA-GID1-DELLA complex, it is thought that DELLA proteins undergo changes in structure that enable their binding to F-box proteins (SLY1 in arabidopsis or GID2 in rice). F-box proteins catalyse the addition of ubiquitin to their targets. The addition of ubiquitin to DELLA proteins promotes their degradation via the 26S-proteosome. The degradation of DELLA proteins releases cells from their repressive effects.\n\nThe first targets of DELLA proteins identified were PHYTOCHROME INTERACTING FACTORs (PIFs). PIFs are transcription factors that negatively regulate light signalling and are strong promoters of elongation growth. In the presence of GA, DELLAs are degraded and this then allows PIFs to promote elongation. It was later found that DELLAs repress a large number of other transcription factors, among which are positive regulators of auxin, brassinosteriod and ethylene signalling. DELLAs can repress transcription factors either by stopping their binding to DNA or by promoting their degradation.\n\nIn addition to repressing transcription factors, DELLAs also bind to prefoldins (PFDs). PFDs are molecular chaperones, meaning they assist in the folding of other proteins. PFDs function in the cytosol but when DELLAs bind to PFDs, it restricts them to the nucleus. An important function of PFDs is to assist in the folding of β-tubulin. As such, in the absence of GA (when there is a high level of DELLA proteins), PDF function is reduced and there is a lower cellular pool of β-tubulin. When GA is present the DELLAs are degraded, PDFs can move to the cytosol and assist in the folding of β-tubulin. β-tubulin is a vital component of the cytoskeleton (in the form of microtubules). As such, GA allows for re-organisation of the cytoskeleton, and the elongation of cells.\n\nMicrotubules are also required for the trafficking of membrane vesicles. Membrane vesicle trafficking is needed for the correct positioning of several hormone transporters. One of the most well characterized hormone transporters are PIN proteins, which are responsible for the movement of the hormone auxin between cells. In the absence of GA, DELLA proteins reduce the levels of microtubules and thereby inhibit membrane vesicle trafficking. This reduces the level of PIN proteins at the cell membrane, and the level of auxin in the cell. GA reverses this process and allows for PIN protein trafficking to the cell membrane to enhance the level of auxin in the cell.\n"}
{"id": "47665036", "url": "https://en.wikipedia.org/wiki?curid=47665036", "title": "Gonzalo Tancredi", "text": "Gonzalo Tancredi\n\nGonzalo Tancredi (born 8 March 1963) is an Uruguayan astronomer and full professor in the Department of Astronomy at the University of the Republic in Montevideo, Uruguay. He is an active member of the International Astronomical Union (IAU) and investigator at Los Molinos Observatory.\n\nHis list of possible dwarf planets, along with that of Michael E. Brown, is commonly considered, along with the five dwarf planets recognized by the IAU – Ceres, Pluto, Haumea, Makemake, and Eris – to be the dwarf planets of the Solar System. The Themistian asteroid 5088 Tancredi has been named after him.\n\nIn 2006, Tancredi was one of a number of dissenters at the IAU's meeting to establish the first definition of \"planet.\" As an alternative to the IAU's draft proposal, which had included Pluto, its moon Charon and Ceres among the planets, Tancredi with his Uruguayan colleague Julio Ángel Fernández proposed a definition where they reserved the term \"planet\" only for those objects in the Solar System which had cleared their neighbourhoods of planetesimals, describing those objects which had not cleared their orbits yet retained a spherical shape as \"planetoids.\" The IAU's final definition incorporated much of Fernández and Tancredi's proposal, though the objects were christened \"dwarf planets.\"\n\n"}
{"id": "14222136", "url": "https://en.wikipedia.org/wiki?curid=14222136", "title": "Haruo Hosoya", "text": "Haruo Hosoya\n\nHaruo Hosoya was born in Kamakura, Japan to a family of an office worker. During 1955-1959 he studied at the University of Tokyo. In 1964 he wrote his Ph.D. thesis, \"Study on the Structure of Reactive Intermediates and Reaction Mechanism\". After postdoc work abroad (Ann Arbor, Michigan, with prof. John Platt), in 1969 he became associate professor at the Ochanomizu University, where he worked for 33 years until his retirement in 2002. After retirement he keeps working in computational chemistry.\n\nIn 1971, Hosoya defined topological index (a graph invariant) as the total number of matchings of a graph plus 1. The Hosoya index is often used in computer (mathematical) chemistry investigations for organic compounds.\n\nIn 2002-2003 the \"Internet Electronic Journal of Molecular Design\" dedicated a series of issues to commemorate the 65th birthday of professor Hosoya.\n\nHosoya's article \"The Topological Index Z Before and After 1971\" describes the history of the notion and the associated inside stories and details other Hosoya's achievements.\n\nHosoya also introduced the triangle of numbers known as Hosoya's triangle (originally \"Fibonacci triangle\", but that name can be ambiguous).\n"}
{"id": "35885832", "url": "https://en.wikipedia.org/wiki?curid=35885832", "title": "Hemihydrate", "text": "Hemihydrate\n\nA hemihydrate, or semihydrate, is a hydrate whose solid contains one molecule of water of crystallization per two molecules, or per two unit cells.\n"}
{"id": "31466336", "url": "https://en.wikipedia.org/wiki?curid=31466336", "title": "IUCN protected area categories", "text": "IUCN protected area categories\n\nIUCN protected area categories, or IUCN protected area management categories, are categories used to classify protected areas in a system developed by the International Union for the Conservation of Nature (IUCN).\n\nThe enlisting of such areas is part of a strategy being used toward the conservation of the world's natural environment and biodiversity. The IUCN has developed the protected area management categories system to define, record, and classify the wide variety of specific aims and concerns when categorising protected areas and their objectives.\n\nThis categorisation method is recognised on a global scale by national governments and international bodies such as the United Nations and the Convention on Biological Diversity.\n\nA strict nature reserve (IUCN Category Ia) is an area which is protected from all but light human use in order to preserve the geological and geomorphical features of the region and its biodiversity. These areas are often home to dense native ecosystems that are restricted from all human disturbance outside of scientific study, environmental monitoring and education. Because these areas are so strictly protected, they provide ideal pristine environments by which external human influence can be measured.\n\nIn some cases strict nature reserves are of spiritual significance for surrounding communities, and the areas are also protected for this reason. The people engaged in the practice of their faith within the region have the right to continue to do so, providing it aligns with the area's conservation and management objectives.\n\nHuman impacts on strict nature reserves are increasingly difficult to guard against as climate and air pollution and newly emerging diseases threaten to penetrate the boundaries of protected areas. If perpetual intervention is required to maintain these strict guidelines, the area will often fall into category IV or V.\n\nA wilderness area (IUCN Category Ib) is similar to a strict nature reserve, but generally larger and protected in a slightly less stringent manner.\n\nThese areas are a protected domain in which biodiversity and ecosystem processes (including evolution) are allowed to flourish or experience restoration if previously disturbed by human activity. These are areas which may buffer against the effects of climate change and protect threatened species and ecological communities.\n\nHuman visitation is limited to a minimum, often allowing only those who are willing to travel of their own devices (by foot, by ski, or by boat), but this offers a unique opportunity to experience wilderness that has not been interfered with. Wilderness areas can be classified as such only if they are devoid of modern infrastructure, though they allow human activity to the level of sustaining indigenous groups and their cultural and spiritual values within their wilderness-based lifestyles.\n\nA national park (IUCN Category II) is similar to a wilderness area in its size and its main objective of protecting functioning ecosystems. However, national parks tend to be more lenient with human visitation and its supporting infrastructure. National parks are managed in a way that may contribute to local economies through promoting educational and recreational tourism on a scale that will not reduce the effectiveness of conservation efforts.\n\nThe surrounding areas of a national park may be for consumptive or non-consumptive use but should nevertheless act as a barrier for the defence of the protected area's native species and communities to enable them to sustain themselves in the long term.\n\nA natural monument or feature (IUCN Category III) is a comparatively smaller area that is specifically allocated to protect a natural monument and its surrounding habitats. These monuments can be natural in the wholest sense or include elements that have been influenced or introduced by humans. The latter should hold biodiversity associations or could otherwise be classified as a historical or spiritual site, though this distinction can be quite difficult to ascertain.\n\nTo be categorised as a natural monument or feature by IUCN's guidelines, the protected area could include natural geological or geomorphological features, culturally-influenced natural features, natural cultural sites, or cultural sites with associated ecology. The classification then falls into two subcategories: those in which the biodiversity is uniquely related to the conditions of the natural feature and those in which the current levels of biodiversity are dependent on the presence of the sacred sites that have created an essentially modified ecosystem.\n\nNatural monuments or features often play a smaller but key ecological role in the operations of broader conservation objectives. They have a high cultural or spiritual value that can be utilised to gain support of conservation challenges by allowing higher visitation or recreational rights, therefore offering an incentive for the preservation of the site.\n\nA habitat or species management area (IUCN Category IV) is similar to a natural monument or feature, but focuses on more specific areas of conservation (though size is not necessarily a distinguishing feature), like an identifiable species or habitat that requires continuous protection rather than that of a natural feature. These protected areas will be sufficiently controlled to ensure the maintenance, conservation, and restoration of particular species and habitats—possibly through traditional means—and public education of such areas is widely encouraged as part of the management objectives.\n\nHabitat or species management areas may exist as a fraction of a wider ecosystem or protected area and may require varying levels of active protection. Management measures may include (but are not limited to) the prevention of poaching, creation of artificial habitats, halting natural succession, and supplementary feeding practices.\n\nA protected landscape or protected seascape (IUCN Category V) covers an entire body of land or ocean with an explicit natural conservation plan, but usually also accommodates a range of for-profit activities.\n\nThe main objective is to safeguard regions that have built up a distinct and valuable ecological, biological, cultural, or scenic character. In contrast with previous categories, Category V permits surrounding communities to interact more with the area, contributing to the area's sustainable management and engaging with its natural and cultural heritage.\n\nLandscapes and seascapes that fall into this category should represent an integral balance between people and nature and can sustain activities such as traditional agricultural and forestry systems on conditions that ensure the continued protection or ecological restoration of the area.\n\nCategory V is one of the more flexible classifications of protected areas. As a result, protected landscapes and seascapes may be able to accommodate contemporary developments, such as ecotourism, at the same time as maintaining the historical management practices that may procure the sustainability of agrobiodiversity and aquatic biodiversity.:\n\nThough human involvement is a large factor in the management of these protected areas, developments are not intended to allow for widescale industrial production. The IUCN recommends that a proportion of the land mass remains in its natural condition—a decision to be made on a national level, usually with specificity to each protected area. Governance has to be developed to adapt the diverse—and possibly growing—range of interests that arise from the production of sustainable natural resources.\n\nCategory VI may be particularly suitable to vast areas that already have a low level of human occupation or in which local communities and their traditional practices have had little permanent impact on the environmental health of the region. This differs from category V in that it is not the result of long-term human interaction that has had a transformative effect on surrounding ecosystems.\n\n\n"}
{"id": "2109596", "url": "https://en.wikipedia.org/wiki?curid=2109596", "title": "Isbanir Fossa", "text": "Isbanir Fossa\n\nIsbanir Fossa is a north-south trending scarp on Saturn's moon Enceladus. Isbanir Fossa was first seen in \"Voyager 2\" images, though a small section was see at much higher resolution by \"Cassini\". It is centred at 12.6° North Latitude, 354.0° West Longitude and is approximately 132 kilometres long. Based on photoclinometric analysis of \"Voyager 2\" images (using topographic shading in an image to determine slope), like the one at right, Isbanir Fossa was determined to be a 300-metre tall, west-dipping scarp (Kargel and Pozio 1996). Two sets of troughs can be seen running perpendicular to Isbanir Fossa, like Daryabar Fossa. These troughs appear to be right-laterally offset 15–20 km east and west of Isbanir Fossa, suggesting that the scarp may be a strike-slip fault or even a transform fault with troughs like Daryabar Fossa representing spreading centres (Rothery 1999).\n\nIsbanir Fossa is named after the home of Fakir Taj from \"Arabian Nights\".\n\n"}
{"id": "503116", "url": "https://en.wikipedia.org/wiki?curid=503116", "title": "Joe Engle", "text": "Joe Engle\n\nJoe Henry Engle (born August 26, 1932) (Maj Gen, USAF, Ret.), is an American pilot who served in the United States Air Force, test pilot for the North American X-15 program, aeronautical engineer, and a former NASA astronaut. As of 2018, he is the last living pilot of the X-15 program.\n\nEngle test-flew the joint NASA-Air Force X-15 rocket airplane. During the course of testing, Engle earned his USAF Astronaut Wings, a Distinguished Flying Cross and other awards. Engle was selected by NASA in 1966 for the Apollo program, and was originally scheduled to land on the Moon as Lunar Module Pilot on Apollo 17, but was bumped when later flights were cancelled, so that geologist-astronaut Harrison H. Schmitt could fly.\n\nHe subsequently became one of the first astronauts in the Space Shuttle program, having flight tested the Space Shuttle \"Enterprise\" in 1977. He was Commander of the second orbital test flight of the Space Shuttle \"Columbia\" in 1981.\n\nEngle was born on August 26, 1932, in Chapman, Kansas. He attended primary and secondary schools in Chapman, Kansas, and he graduated from Dickinson County High School in 1950. He received a Bachelor of Science degree in Aeronautical Engineering from the University of Kansas in 1955, where he was a member of the Theta Tau Professional Engineering Fraternity.\n\nEngle was active as a Boy Scout and earned the rank of First Class.\n\nHe was married to Mary Catherine Lawrence of Mission Hills, Kansas and has two grown children and one stepchild. He is currently married to Jeanie Carter Engle of Houston, Texas. Engle's recreational interests include flying (including World War II fighter aircraft), big game hunting, backpacking, and athletics.\n\nHe was a member of the Society of Experimental Test Pilots and became a Fellow in 2009.\n\nEngle received his commission in the U.S. Air Force through the Air Force Reserve Officer Training Corps at the University of Kansas. While in school he was a member of the Professional Engineering Fraternity Theta Tau, and decided to become a test pilot. While working at Cessna Aircraft during the summer, he learned how to fly from a fellow draftsman.\n\nEngle entered flying school in 1957, and received his pilot wings in 1958. He flew the F-100 Super Sabre with the 474th Fighter Day Squadron and the 309th Tactical Fighter Squadron at George Air Force Base, California. Chuck Yeager recommended Engle for USAF Test Pilot School, from which he graduated in 1961, and he was later assigned to the second class of the Aerospace Research Pilot School, despite his reluctance to leave \"stick and rudder\" flying for a space capsule.\n\nAfter serving as a test pilot in the Fighter Test Group at Edwards Air Force Base, California, Engle was a test pilot in the X-15 research program at Edwards from June 1963 until his assignment to the Manned Spacecraft Center (now the Lyndon B. Johnson Space Center). Engle had applied with fellow ARPS student Michael Collins to the third NASA astronaut group, but the Air Force withdrew Engle's NASA application and instead chose him to replace Robert M. White in the X-15 program, which pleased Engle.\n\nEngle's parents witnessed his flight of 29 June 1965, which exceeded an altitude of 50 miles (80 km) and qualified him for astronaut wings; he again exceeded 50 miles twice during his career of 16 flights. On his final X-15 mission, free flight 153 (1-61-101), which took place on 14th October 1965, he became the first of only two pilots to accomplish a sub-orbital space flight in an X-15 without the benefit of the assistance provided by the MH-96 adaptive flight control system. Despite what he later called \"the best flying job in the world\", Engle decided to apply again to NASA as he expected to be rotated to another Air Force assignment within a year and hoped to go to the Moon.\n\nEngle has flown over 185 different types of aircraft (25 different fighters) during his career: logging more than 15,400 hours flight time; 9,000 in jet aircraft.\n\nEngle was one of 19 astronauts selected by NASA in April 1966. He served on the support crew for Apollo 10. Following this assignment, he was backup Lunar Module Pilot for the Apollo 14 mission and was due to land on the Moon as Lunar Module Pilot for Apollo 17, but was replaced by geologist Harrison Schmitt after Apollo 18 was cancelled with pressure from the scientific community to have a scientist explore the Moon, and not just test pilots who had been given geology training. In response to getting bumped from the mission, he said \"When you think about it, the lunar missions were geology-oriented.\"\n\nAccording to Engle, Deke Slayton asked him whether he would prefer to fly on Skylab, Apollo-Soyuz, or the Space Shuttle; Engle responded that he would prefer the Shuttle as it was an airplane.\nEngle was Commander of one of the two crews that flew the Space Shuttle Approach and Landing Test Flights from June through October 1977. The Space Shuttle \"Enterprise\" was carried to 25,000 feet on top of the Boeing 747 carrier aircraft, and then released for its two-minute glide flight to landing. In this series of flight tests, Engle evaluated the Orbiter handling qualities and landing characteristics, and obtained the stability and control, and performance data in the subsonic flight envelope for the space shuttle. He was the backup Commander for STS-1, the first orbital test flight of Space Shuttle \"Columbia\". Together with pilot Richard Truly he flew as Commander on the second flight of the Space Shuttle, STS-2. He was also mission commander on STS-51-I and logged over 225 hours in space.\n\nEngle is the only human being to have flown two different types of winged vehicles in space, the X-15 and the Space Shuttle. In Engle's June 2004 oral history interview the interviewer (Rebecca Wright) states that he is the only astronaut to have manually flown the Shuttle through reentry and landing, but this is an oversimplification. Periods of hand flying flight test manoeuvres were interspersed with periods of computer control. \n\nHe served as Deputy Associate Administrator for Manned Space Flight at NASA Headquarters from March 1982 to December 1982. He retained his astronaut flight status and returned to the Johnson Space Center in January 1983. He also participated in the \"Challenger\" disaster investigation in 1986, and did other consulting work on the Shuttle well into the 1990s.\n\nJoe Engle retired from NASA on November 28, 1986 and the USAF on November 30, 1986. On December 1, he was subsequently promoted to the rank of Major General. In 1986 he was appointed to the Kansas Air National Guard and 1992, he was inducted into the Aerospace Walk of Honor. On July 21, 2001, Engle was enshrined at Dayton, Ohio, in the National Aviation Hall of Fame class of 2001, along with USAF ace Robin Olds, U.S. Marine Corps ace Marion Carl, and Albert Ueltschi. In November, 2001, he was inducted into the U.S. Astronaut Hall of Fame in Florida.\n\n\n\n"}
{"id": "31354851", "url": "https://en.wikipedia.org/wiki?curid=31354851", "title": "List of default file systems", "text": "List of default file systems\n\nDefault file system used in various operating systems.\n\n"}
{"id": "56754059", "url": "https://en.wikipedia.org/wiki?curid=56754059", "title": "List of discontinued scorewriters", "text": "List of discontinued scorewriters\n\nThis is a list of discontinued music notation programs. For non-discontinued products, see List of scorewriters.\n\n\n\n\n"}
{"id": "28467978", "url": "https://en.wikipedia.org/wiki?curid=28467978", "title": "List of extreme weather records in Pakistan", "text": "List of extreme weather records in Pakistan\n\nThe weather extremes in Pakistan include high and low temperatures, heaviest rainfall and flooding. The highest temperature ever recorded in Pakistan is 53.5 °C which was recorded in Moenjo Daro, Sindh on 26 May 2010. It was not only the hottest temperature ever recorded in Pakistan but also the hottest reliably measured temperature ever recorded on the continent of Asia. and the fourth-highest temperature ever recorded on Earth. The second-highest temperature ever recorded in Pakistan is which was recorded in Larkana, Sindh on 26 May 2010. It is hottest city in Pakistan, as well as the second-hottest city in the world, but it is second-hottest place in Pakistan and fifth-hottest place in the world. It is fifth-highest temperature ever recorded on Earth. The highest rainfall of was recorded in Islamabad in 24 hours on 23 July 2001. The record-breaking rain fell in just 10 hours.\n\nThe standard measuring conditions for temperature are 1.2 meters above the ground out of direct sunlight (hence the term, x degrees \"in the shade\").\n\nHeat waves mostly occur during summer months but in Pakistan heat waves occur at any time period between April and September and bring high temperatures but most powerful heat waves occur in May and June. Some areas of southern Pakistan usually experience above temperature and play havoc in these areas. The most deadly heat wave in the history of Pakistan is the record-breaking heat wave of summer 2010 which occurred in the last ten days of May.\n\nTemperature extremes in Pakistan over based on data from the Pakistan Meteorological Department, 1931–2017 and other sources.\nTemperature extremes in Pakistan over based on data from the Pakistan Meteorological Department, 1931–2016 and other sources.\n\nA severe heat wave with temperatures as high as hit Pakistan, especially southern parts, in April 2017. This heat wave broke the old temperature records of many cities in the country in the month of April. Larkana, Sindh experienced the highest maximum temperature of on 19 April and broke its old record of which was recorded in April 2000. Other cities of the country also broke their old records of highest maximum temperatures in the month of April.\n\nExtreme temperatures started to affect the parts of the country from mid-April and peaked on 19–20 April.\nThe hottest temperature ever recorded in Asia and the fourth-highest temperature ever recorded in the world was in Mohenjo-daro, Sindh at while the second-hottest temperature ever recorded in Asia and the fifth-highest temperature ever recorded in the world was in Larkana, Sindh at on May 26, 2010. Twelve cities in Pakistan saw temperatures above during the extreme heatwave of summer 2010, which lasted from May 22 to May 31, 2010. On May 27, temperatures higher than hit areas across Pakistan and at least 18 people died as a result. Also, during the extreme heatwave season, 11 cities saw their highest-ever recorded temperatures of or above, and five cities saw temperatures of . Eleven cities also saw extremes of more than but below . The previous record for Pakistan and for Asia was on June 12, 1919 at at Jacobabad.\n\nCold waves mostly occur during winter months but in northern and western Pakistan cold waves occur at any time period between October and March and bring low temperatures but most powerful cold waves occur in December and January. Some areas of northern and western Pakistan usually experience below 0 °C temperature and play havoc in these areas. The most deadly cold wave in the recent history of Pakistan is the record-breaking cold wave of winter 2013.\n\nTemperature extremes in Pakistan under based on data from the Pakistan Meteorological Department, 1931–2016 and other sources.\nThe standard way of measuring Rainfall or Snowfall is the standard Rain gauge, which can be found in 100-mm (4-in) plastic and 200-mm (8-in) metal varieties. The inner cylinder is filled by 25 mm (0.98 in) of Rain, with overflow flowing into the outer cylinder. Plastic gauges have markings on the inner cylinder down to 0.25 mm (0.0098 in) resolution, while metal gauges require use of a stick designed with the appropriate 0.25 mm (0.0098 in) markings. After the inner cylinder is filled, the amount inside it is discarded, then filled with the remaining Rainfall in the outer cylinder until all the fluid in the outer cylinder is gone, adding to the overall total until the outer cylinder is empty.\n\nPakistan receives Rainfall from both Monsoon and Western Disturbance. Monsoon occurs from July to September and brings heavy Downpour across the country except western Balochistan. Western Disturbances occur from October to May and bring Rainfall across the country with some heavy Downpour in northern Pakistan. But in June Western Disturbances occasionally hit the northern parts of the country. Pre-Monsoon also occurs in this month occasionally but not always.\n\nRecord-breaking rainfall extremes in Pakistan over or above during 24 hours, based on data from the Pakistan Meteorological Department, 1931–2016 and other sources.\nRecord-breaking rainfall extremes in Pakistan over or above but below during 24 hours, based on data from the Pakistan Meteorological Department, 1931–2016 and other sources.\n\nAn August like Monsoonal moisture hit the country in the first week of the month when a very low air pressure system (29\") was formed over Kashmir that moved eastward into Northern Pakistan. The spell caused torrential Rainfall between 1 and 5 September that resulted in devastation to life and property. The last two days of the spell being extremely wet in Pakistan caused River Chenab, Jhelum, Ravi, Sutlej and Indus to overflow their banks.\n\nHeavy Rainfall of more than recorded during the wet spell of September 1 to 5, 2014 in northern Pakistan based on data from the Pakistan Meteorological Department.\n\nAfter the severe drought conditions in Sindh during the months of July & August, an intense low-pressure area developed in Bay of Bengal in last days of August. The Low pressure area moved towards Sindh and brought torrential Rains in upper Sindh while rainfall some heavy in other parts of Sindh during the first fortnight of September 2012. Highest rainfall was recorded in Jacobabad with the record of in just 7 days and in just 36 hours. Other records are in Larkana while in Sukkur. Larkana division was worst hit by heavy rainfall.\n\nHeavy rainfall of more than recorded during the wet spell of September 5 to 11, 2012 in the province of Sindh particularly in upper Sindh based on data from the Pakistan Meteorological Department.\n\nIn the month of July Pakistan received below normal monsoon rains; however, in August and September the country received above normal monsoon rains. A strong weather pattern entered the areas of Sindh from the Indian states of Rajasthan and Gujarat in August and gained strength with the passage of time and caused heavy Downpour. The first Monsoon spell hit the southern parts of Sindh on 10 August. It produced record breaking widespread torrential Rainfall and resulted in floods in district Badin. The second spell hit the areas on 30 August and lasted until 2 September. In the month of September four more consecutive spells of monsoon rainfall devastated the southern parts of the province. The first spell of September hit the already inundated parts of the province on 2 September. Thereafter, the second spell hit on 5 September, the third on 9 September, and the fourth on 12 September 2011. The four spells of Monsoon produced even more devastating torrential Rains in the already affected areas of Sindh.\n\nHeavy Rainfall of more than recorded in the heaviest Monsoon spell in different areas of Sindh province in the months of August and September, 2011 based on data from the Pakistan Meteorological Department.\n\nUnprecedented heavy monsoon rains began in the last week of July 2010 in the Khyber Pakhtunkhwa, Punjab, Gilgit-Baltistan and Azad Kashmir regions of Pakistan which causes floods in Balochistan and Sindh. The floods which were caused by monsoon rains, and were forecast to continue into early August, were described as the worst in the last 80 years. The Pakistan Meteorological Department said that over of rain fell over a 24-hour period over a number of places of Khyber Pakhtunkhwa and Punjab and more was expected. A record-breaking of rain fell in Peshawar in 24 hours, previously of rain was recorded in April 2009. Other record-breaking Rains were recorded in Risalpur, Cherat, Saidu Sharif, Mianwali, and Kohat regions of Khyber Pakhtunkhwa.\n\nHeavy Rainfall of more than recorded during the four-day wet spell of July 27 to 30, 2010 in the provinces of Khyber Pakhtunkhwa and Punjab, based on data from the Pakistan Meteorological Department.\nPakistan receives snowfall from Western Disturbance. Western Disturbances bring snowfall from November to February across the mountainous and hilly areas of the country with some heavy snowfall in northern mountains and hills of Pakistan. Blizzards are common in northern mountains of the country. In February 2017, at least 14 people were killed and 9 injured by an avalanche in the Sher Shall area of Chitral district.\n\nRecord-breaking Snowfall extremes in Pakistan over or above during 24 hours based on data from the Pakistan Meteorological Department, 1931–2016 and other sources.\nRecord-breaking Snowfall extremes in Pakistan over or above but below during 24 hours based on data from the Pakistan Meteorological Department, 1931–2016 and other sources.\nPakistan has seen many floods, the worst and most destructive is the recent 2010 Pakistan floods, which swept away the 20% of Pakistan's land, the flood is the result of unprecedented monsoon rains which lasted from 28 July to 31 July 2010. Khyber Pakhtunkhwa and North eastern Punjab were badly affected during the monsoon rains when dams, rivers and lakes overflowed. By mid-August, according to the governmental Federal Flood Commission (FFC), the floods had caused the deaths of at least 1,540 people, while 2,088 people had received injuries, 557,226 houses had been destroyed, and over 6 million people had been displaced. One month later, the data had been updated to reveal 1,781 deaths, 2,966 people with injuries, and more than 1.89 million homes destroyed. The flood affected more than 20 million people exceeding the combined total of individuals affected by the 2004 Indian Ocean tsunami, the 2005 Kashmir earthquake and the 2010 Haiti earthquake. The flood is considered as worst in Pakistan's history affecting people of all four provinces and Gilgit Baltistan and Azad Kashmir region of Pakistan.\n\nThe 2011 Sindh floods began during the Monsoon season in mid-August 2011, resulting from heavy Monsoon Rains in Sindh, Eastern Balochistan, and Southern Punjab. The floods have caused considerable damage; an estimated 270 civilians have been killed, with 5.3 million people and 1.2 million homes affected. Sindh is a fertile region and often called the \"breadbasket\" of the country; the damage and toll of the floods on the local agrarian economy is said to be extensive. At least 1.7 million acres of arable land has been inundated as a result of the flooding. The flooding has been described as the worst since the 2010 Pakistan floods, which devastated the entire country. Unprecedented torrential monsoon rains caused severe flooding in 16 districts of Sindh province.\n\nThe other floods which caused destruction in the history of Pakistan, includes the flood of 1950, which killed 2910 people, On 1 July 1977 heavy Rains and flooding in Karachi, killed 248 people, according to Pakistan meteorological department of Rain fell in 24 hours. In 1992 flooding during Monsoon season killed 1,834 people across the country, in 1993 flooding during monsoon rains killed 3,084 people, in 2003 Sindh province was badly affected due to monsoon rains causing damages in billions, killed 178 people, while in 2007 Cyclone Yemyin submerged lower part of Balochistan Province in sea water killing 380 people. Before that it killed 213 people in Karachi on its way to Balochistan.\n\n\n"}
{"id": "17113703", "url": "https://en.wikipedia.org/wiki?curid=17113703", "title": "List of lakes in New York", "text": "List of lakes in New York\n\nThis is a list of lakes in the state of New York in the United States. The list is not exhaustive.\n\n\n\nTriangle Lake, in Rensselaerville, New York 12147\n"}
{"id": "1007026", "url": "https://en.wikipedia.org/wiki?curid=1007026", "title": "List of philosophies", "text": "List of philosophies\n\nPhilosophies: particular schools of thought, styles of philosophy, or descriptions of philosophical ideas attributed to a particular group or culture - listed in alphabetical order.\n\nAbleism -\nAbsolutism -\nAbsurdism -\nActivism -\nActual Idealism -\nActualism - \nAdvaita Vedanta -\nAesthetic Realism -\nAesthetics -\nAfrican philosophy -\nAgential realism -\nAgnosticism -\nAgnotology -\nAltruism -\nAmor fati -\nAmerican philosophy -\nAnimism -\nAnti-imperialism -\nAntinatalism -\nAnti-intellectualism -\nAnti-realism -\nAntireductionism -\nAnalytic philosophy -\nAnarchism -\nAncient philosophy -\nAnthropocentrism -\nAnomalous monism -\nApplied ethics -\nAristotelianism -\nAsceticism -\nAuthoritarianism -\nAverroism -\nAvicennism -\nAxiology\n\nBa'athism -\nBahá'í teachings -\nBehaviorism -\nBioconservatism -\nBioethics - \nBiolibertarianism -\nBiosophy -\nBuddhist philosophy -\nBushido -\n\nCalvinism -\nCapitalism -\nCartesianism -\nCatechism -\nCategorical imperative -\nCentrism -\nChaos theory -\nCharvaka -\nChinese naturalism -\nChinese philosophy -\nChristian ecology -\nChristian existentialism -\nChristian humanism -\nChristian philosophy -\nChristian theology - \nChristology -\nClassical liberalism -\nCollectivism -\nCognitivism -\nCommunitarianism -\nCompatibilism and incompatibilism -\nComputer ethics -\nConfirmation holism -\nConformism -\nConfucianism -\nConsequentialism -\nConservatism -\nConstructivist epistemology -\nContinental philosophy -\nCosmopolitanism -\nCritical rationalism -\nCritical realism -\nCynicism -\nCzech philosophy\n\nDanish philosophy -\nDaoism -\nDeconstruction -\nDeism -\nDefeatism -\nDemocratic transhumanism -\nDenialism -\nDeontology -\nDeterminism -\nDialectic -\nDialectical materialism -\nDidacticism -\nDigital philosophy -\nDiscordianism -\nDualistic cosmology -\nDvaita\n\nEcocentrism -\nEcumenism -\nEgalitarianism -\nEgocentrism -\nEliminative materialism -\nEmpiricism -\nEnvironmentalism -\nEphesian school -\nEpiphenomenalism -\nEpicureanism -\nEpistemological nihilism -\nEpistemology - \nEschatology -\nEsotericism -\nEthical Egoism - \nEthics - \nEudaimonism -\nEugenics -\nEvangelism -\nExistentialism -\nExternalism -\n\nFascism - \nFeminism - \nFeminist philosophy -\nFilial piety -\nFlower Sermon -\nFoundationalism -\nFree will -\nFundamentalism\n\nGerman idealism -\nGerman philosophy -\nGlobalism -\nGnosticism -\nGothicism - \nGreek philosophy\n\nHasidism -\nHedonism -\nHegelianism -\nHermeticism -\nHeterophenomenology -\nHindu philosophy -\nHistorical materialism -\nHistorical revisionism - \nHistoricism -\nHolism -\nHongaku -\nHuman exceptionalism -\nHumanism -\nHumanistic naturalism\n\nIdealism -\nIdentityism -\nIdeological criticism -\nIgnosticism -\nIllegalism -\nIlluminationism -\nIndividualism -\nIndian logic -\nIndian philosophy -\nIndonesian philosophy -\nInduction /\nInductionism -\nInformal logic -\nInnatism -\nInstrumental rationality -\nInstrumentalism -\nInteractionism (philosophy of mind) -\nInternalism and externalism -\nInterventionism -\nIntuitionism -\nIranian philosophy -\nIrrealism -\nIslamic ethics -\nIslamic philosophy -\nInternationalism\n\nJainism -\nJapanese philosophy -\nJesuism -\nJewish philosophy -\nJuche -\nJudaism -\nJudeo-Islamic philosophies (800–1400) -\nJust war theory\n\nKaizen -\nKantianism -\nKashmir Shaivism -\nKorean philosophy\n\nLegalism -\nLeibnizianism -\nLiberalism -\nLibertarianism (metaphysics) -\nLibertarianism -\nLiterary theory -\nLogic / Informal logic -\nLogical atomism -\nLogical positivism -\nLogicians -\nLogicism -\nLogic in China -\nLogic in Islamic philosophy -\nLutheranism\n\nManichaeism -\nMaoism -\nMarxism -\nMarxist philosophy of nature -\nMaterialism -\nMathematicism -\nMazdakism -\nMedical ethics -\nMedieval philosophy -\nMedievalism - \nMentalism -\nMereological nihilism -\nMeta-philosophy -\nMetaphysics -\nMeta-ethics -\nMethodism - \nMind-body dualism -\nMisology -\nModernism -\nModern Islamic philosophy -\nMohism -\nMonism -\nMonogamy -\nMonotheism -\nMoral absolutism -\nMoral realism -\nMoral relativism -\nMoral skepticism -\nMultilateralism -\nMysticism -\n\nNaïve realism -\nNaturalism -\nNatalism - \nNegationism - \nNeo-Confucianism -\nNeo-Hegelianism -\nNeo-Kantianism -\nNeoplatonism -\nNeopythagoreanism -\nNeo-Scholasticism -\nNeotaoism -\nNeuroethics -\nNeurophilosophy -\nNeurotheology -\nNew Age -\nNew realism - \nNew Thought -\nNeutral monism -\nNihilism -\nNominalism -\nNondualism -\nNon-philosophy -\n\nObjective idealism -\nObjectivism (Ayn Rand) -\nOccasionalism -\nOntology -\nOntotheology -\nOpen individualism -\nOpportunism -\nOptimism - \nOrganicism -\nOrientalism\n\nPaganism -\nPakistani philosophy -\nPancritical rationalism -\nPandeism -\nPanentheism -\nPanpsychism -\nPantheism -\nPastafarianism -\n'Pataphysics -\nPerennial philosophy -\nPerfectionism -\nPeripatetic school -\nPersonalism -\nPerspectivism -\nPessimism -\nPhenomenalism -\nPhenomenology -\nPhilosophical anthropology -\nPhilosophical Satanism -\nPhilosophy of archaeology -\nPhilosophy of art -\n\"Philosophy of Arithmetic\" -\nPhilosophy of artificial intelligence -\nPhilosophy of action -\nPhilosophy of biology -\nPhilosophy of business -\nPhilosophy of Common Sense -\nPhilosophy of culture -\nPhilosophy of color -\nThe Philosophy of Chance -\nPhilosophy of design -\nPhilosophy of dialogue -\nPhilosophy of eating -\nPhilosophy of economics -\nPhilosophy of education -\nPhilosophy of engineering -\nPhilosophy of environment -\nPhilosophy of film -\nPhilosophy of futility -\nPhilosophy of geography -\nPhilosophy of healthcare -\nPhilosophy of history -\nPhilosophy of information -\nPhilosophy of language -\nPhilosophy of logic -\nPhilosophy of love -\nPhilosophy of mathematics -\nPhilosophy of mathematics education -\nPhilosophy of mind -\nPhilosophy of motion -\nPhilosophy of music -\nPhilosophy of nature -\nPhilosophy of Natural Science -\nPhilosophy of neuroscience -\nPhilosophy of perception -\nPhilosophy of philosophy -\nPhilosophy of physics -\nPhilosophy of psychology -\nPhilosophy of psychiatry -\nPhilosophy of religion -\nPhilosophy of religious language -\nPhilosophy of science -\nPhilosophy of sex -\nPhilosophy of self -\nPhilosophy of social science -\nPhilosophy of space and time -\nPhilosophy of sport -\nPhilosophy of statistics -\nPhilosophy of thermal and statistical physics -\nPhilosophy of war - \nPhysicalism -\nPhysical ontology -\nPlatonic realism -\nPlatonism -\nPluralism -\nPolitical philosophy -\nPopulism -\nPositivism -\nPostanalytic philosophy -\nPost-structuralism -\nPosthumanism -\nPost-materialism -\nPost-modernism -\nPostpositivism-\nPractical reason -\nPragmatism -\nPraxis School -\nPremillennialism -\nPresentism -\nProcess philosophy -\nProgressivism -\nProperty dualism -\nPseudophilosophy -\nPsychological egoism -\nPure practical reason -\nPure reason -\nPyrrhonian skepticism -\nPythagoreanism\n\nQuantum mysticism -\nQuietism\n\nRacism - \nRaëlism -\nRastafari -\nRationalism -\nRealism -\nReconstructivism -\nReductionism -\nReductive materialism -\nReformational philosophy -\nRelationalism -\nRelativism -\nRelevance logic -\nReligious humanism -\nReligious philosophy -\nReliabilism -\nRenaissance humanism -\nRomanian philosophy -\nRomanticism -\nRussian philosophy\n\nSabellianism -\nScandal -\nScholasticism -\nScientific Development Concept -\nScientism -\nSecularism -\nSecular humanism -\nSemantic holism -\nSensualism -\nSexualism -\nSexism - \nShamanism -\nSikhism - \nSimulism -\nSingularitarianism -\nSkepticism -\nSocial philosophy -\nSolipsism -\nSophism -\nSpiritualism -\nStoicism -\nStructuralism -\nSubjective idealism -\nSubjectivism -\nSufi metaphysics -\nŚūnyatā -\nSupersessionism -\nSurrealism -\nSurvivalism -\nSynoptic philosophy -\nSystems philosophy\n\nTaoism -\nTeleology -\nTetralemma -\nThelema -\nTheology -\nTheosophy (Blavatskian) -\nTheosophy (Boehmian) -\nTraditionalist School -\nTranscendent theosophy (\"al-Hikmat al-Muta’liyah\") -\nTranscendental idealism -\nTranscendentalism -\nTranscendental perspectivism -\nTranshumanism -\nTransmodernism -\nType physicalism\n\nUniversalism -\nUniversal reconciliation -\nUtilitarian bioethics -\nUtilitarianism -\nUtopianism\n\nValue pluralism -\nValue theory -\nVerificationism - \nVienna Circle -\nVirtue ethics -\nVishishtadvaita -\nVitalism - \nVoluntaryism\n\nWahdat-ul-Wujood - \nWahdat-ul-Shuhud - \nWestern philosophy -\nWicca\n\nZen -\nZoroastrianism -\nZurvanism\n\n"}
{"id": "7328069", "url": "https://en.wikipedia.org/wiki?curid=7328069", "title": "Lord Morton's mare", "text": "Lord Morton's mare\n\nLord Morton’s mare was an equid hybrid and once an often-noticed example in the history of evolutionary theory.\n\nIn 1820 George Douglas, 16th Earl of Morton, F.R.S., reported to the President of the Royal Society that, being desirous of domesticating the quagga (a now extinct subspecies of the plains zebra), he had bred an Arabian chestnut mare with a quagga stallion and that, subsequently, the same mare was bred with a black stallion and Lord Morton found that the offspring had strange stripes in the legs like the quagga. The Royal Society published Lord Morton's letter in its \"Philosophical Transactions\", 1821. In the same issue \"Particulars of a Fact, nearly similar to that related by Lord Morton, communicated to the President, in a letter from Daniel Giles, Esq.\" reported that in a litter of a black and white sow, by a \"boar of the wild breed, the chestnut colour of the boar strongly prevailed\" in some of the piglets, even to the two subsequent litters of that sow.\n\nThese circumstantial reports seemed to confirm the ancient idea of telegony in heritability: Charles Darwin cited the example in \"On the Origin of Species\" (1859) and \"The Variation of Animals and Plants under Domestication\" (1868). The concept of telegony, that the seed of a male could continue to affect the offspring of a female, whether animal or human, had been inherited from Aristotle and remained a legitimate theory until experiments in the 1890s confirmed Mendelian inheritance. Biologists now explain the phenomenon of Lord Morton's mare using dominant and recessive alleles.\n"}
{"id": "25025408", "url": "https://en.wikipedia.org/wiki?curid=25025408", "title": "Maria Pronchishcheva", "text": "Maria Pronchishcheva\n\nMaria Pronchishcheva (\"Мария Прончищева\", also known as Tatiana Pronchishcheva, 1710 - 23 September 1736) was a Russian explorer.\n\nIn 1735 with her husband, Vasili Pronchishchev, went down the Lena River (from Yakutsk) on Vasili's sloop \"Yakutsk\", doubled its delta, and stopped for wintering at the mouth of the Olenek River. Many members of the crew fell ill and died, mainly owing to scurvy. Despite the difficulties, in 1736, they reached the eastern shore of the Taymyr Peninsula and went north along its coastline. Finally Pronchishcheva and her husband succumbed to scurvy and died on the way back.\n\nMaria is considered the first female polar explorer. Maria Pronchishcheva Bay in the Laptev Sea is named after her.\n\n"}
{"id": "1754248", "url": "https://en.wikipedia.org/wiki?curid=1754248", "title": "Meroplankton", "text": "Meroplankton\n\nMeroplankton is a wide variety of planktonic organisms, which spend a portion of their lives in the benthic region of the ocean. These organisms do not remain as plankton permanently, rather, they are planktonic components in transition, which eventually become larger organisms. After a period of time in the plankton, meroplankton either graduate to the nekton or adopt a benthic (often sessile) lifestyle on the seafloor. Meroplankton consists of larval stages of organisms such as sea urchins, starfish, and crustaceans. Success of meroplankton populations depends on many factors, such as adult fecundity, fertilization success, growth and larval stage duration, behaviour, dispersal, and settlement. Mortality depends on many factors, such as predation, competition, disease, parasites, and physiological stresses. Survival and mortality of meroplankton has a direct effect on adult population numbers of many species. Many of the common, well-known animals found on the Great Barrier Reef spend time as free-swimming meroplankton, bearing little or no resemblance to the adult they will become. The differences between the appearance of larval and adult stages led to much confusion in the past when larval forms were often believed to be completely different species from the adults. Larvae spend varying amounts of time in the plankton, from minutes to over a year. However, just how long these tiny animals can be considered truly planktonic is under some debate.\n\nMeroplankton species composition depends on spatial distribution and reproductive habits of adults in a given area. Biotic and abiotic factors such as tidal and lunar cycles and availability of food determine adult spawning schedules, in turn, determining subsequent meroplankton populations. Behavioural factors, such as predator avoidance are also important. Freshwater inputs play a key role in meroplankton species composition in estuarine environments. Effects of tides contribute greatly to meroplankton species distribution. One study conducted in a Patagonian Fjord found that species composition of the meroplankton community depended on the seasonally varying input levels from the Baker river as well as vertical and horizontal stratification of the water column. Events such as wind driven upwelling and downwelling also affect meroplankton species distribution. Most species are swept in the direction of the flow of water, either off shore during an upwelling or near shore during a downwelling. Some species, such as bivalve larvae, have the ability to maintain their nearshore position during these events.\n\nSurvival rate of Meroplankton is critical to successful development of adult organisms. Low survival rates of meroplankton will result in reduction in adult population numbers. One factor which often determines meroplankton survival is larval dispersal. Most species within the meroplankton community rely on ocean currents for dispersal. Currents play a key role in delivering larval organisms to specific settlement locations, where they are able to transition and mature into adult forms. Organisms which do not make it to the right settlement site are unlikely to complete their lifecycle. Scientists in recent years have also discovered that many of these tiny animals in the plankton (in particular larval fish and crustaceans) quickly become very good swimmers capable of incredible feats of speed and endurance. \n\nA major factor affecting meroplankton survival is food availability. While living in the plankton, meroplankton either feed on other members of the plankton, or they live off the yolk they have retained from the egg they hatched from. Many members of the meroplankton community rely on the surrounding planktonic community for nutrition. In order to ensure that larvae have sufficient amounts of nutrition, many species coordinate larval release with times of algal blooms. This synchronicity between release of larvae and algal blooms often leads to Meroplankton making up the largest percentage of the planktonic community during such reproductive periods. It has been demonstrated that certain species are able to commence spawning as they come into contact with phytoplankton cells. These species store embryos in the mantle cavity until they detect algal blooms. This adaptation allows for better larval survival.\n\nMeroplankton diversity and abundance are affected by many factors. Seasonal and spatial variations are among some of the main causes of such variability. A study which was conducted in Dunkellin Estuary, determined that spawning times of many species are timed to maximize food availability at a particular time of year, while minimizing presence of other species which exploit the same food source Diversity and abundance are depth dependent qualities. Generally, shallow coastal waters contain far greater numbers of meroplankton than deep, open ocean waters. Most abundant regions occur at depths between 0 and 200 meters of the water column, where light penetration is highest. Availability of sunlight allows for proliferation of phytoplankton, which serves as one of the major food sources for meroplankton. Deep oceanic waters show significantly lower abundance than shelf regions, due to poor light penetration.\n\nWater and benthos pollution from industrial sources has been demonstrated to have varying effects on biological diversity and survival potential of meroplankton. One study conducted in the Vostok Bay region in Russia, demonstrated that even in the presence of industrial pollutants, most species of meroplankton were able to proliferate almost unaffected. The authors of this study attribute these findings to the fact that meroplankton are transported by ocean currents generally from cleaner open waters inshore. Furthermore, the same study also concluded that even in heavily polluted areas, meroplankton populations were able to reestablish if pollution was brought under control and sufficient time was allowed to pass. However, the rate of recolonization was demonstrated to be notably slow, on average talking about 10 years before the abundance and diversity of meroplankton returned to its original levels. This is in part due to the slow nature of detoxification of benthic sediments, which retain much of the heavy metal pollution \n\nA study conducted in the North Sea between 1958-2005, collected samples of meroplankton using a CPR survey. These samples consisted of larval echinoderms, decapods, bivalves, cirripedes, and ectoprocts. Meroplankton abundance as well as PCI levels (amount of chlorophyll in each sample in relation to sea surface temperature) were examined. Researchers concluded that echinoderm larvae increased in abundance throughout the study, with the largest increase occurring in the Northern and Central regions. Decapod larvae were found to increase in abundance as well, and were found to appear earlier in the year. Bivalve larvae showed an overall decline in abundance. It was also concluded that PCI levels increased throughout the study, particularly during the summer months. It was determined that climate, particularly sea surface temperature, drives meroplankton abundance. Warmer sea surface temperature shortens developmental time of the larvae, increasing their survival rate.\n\n\n"}
{"id": "2240081", "url": "https://en.wikipedia.org/wiki?curid=2240081", "title": "Moon rock", "text": "Moon rock\n\nMoon rock or lunar rock is rock that is found on the Earth's moon including lunar material collected during the course of human exploration of the Moon, or rock that has been ejected naturally from the Moon's surface (and which has then landed on the Earth as meteorites).\n\nMoon rocks on Earth come from three sources: those collected by the United States Apollo program manned lunar landings from 1969 to 1972; samples returned by three Soviet Luna programme unmanned probes in the 1970s; and rocks that were ejected naturally from the lunar surface. The Apollo missions collected 2,200 samples weighing . Three Luna spacecraft returned with of samples. More than 300 lunar meteorites have been collected on Earth, representing more than 30 different meteorite fall events (none witnessed), with a total mass of over . Some were discovered by scientific teams (such as ANSMET) searching for meteorites in Antarctica, with most of the remainder discovered by collectors in the desert regions of northern Africa and Oman.\n\nThe Soviet Union attempted, but failed to make manned lunar landings in the 1970s, due to failure to develop their N1 rocket, but they succeeded in landing three robotic Luna spacecraft with the capability to collect and return small samples to Earth. A combined total of less than one kilogram of material was returned.\n\nIn 1993, three small fragments from Luna 16, weighing 200 mg, were sold for US$ 442,500.\n\nRocks from the Moon have been measured by radiometric dating techniques. They range in age from about 3.16 billion years old for the basaltic samples derived from the lunar maria, up to about 4.44 billion years old for rocks derived from the highlands. Based on the age-dating technique of \"crater counting,\" the youngest basaltic eruptions are believed to have occurred about 1.2 billion years ago, but scientists do not possess samples of these lavas. In contrast, the oldest ages of rocks from the Earth are between 3.8 and 4.28 billion years old.\n\nMoon rocks fall into two main categories: those found in the lunar highlands (terrae), and those in the maria. The terrae consist dominantly of mafic plutonic rocks. Regolith breccias with similar protoliths are also common. Mare basalts come in three distinct series in direct relation to their titanium content: \"high-Ti basalts, low-Ti basalts\", and \"Very Low-Ti (VLT) basalts\".\n\nAlmost all lunar rocks are depleted in volatiles and are completely lacking in hydrated minerals common in Earth rocks. In some regards, lunar rocks are closely related to Earth's rocks in their isotopic composition of the element oxygen. The Apollo moon rocks were collected using a variety of tools, including hammers, rakes, scoops, tongs, and core tubes. Most were photographed prior to collection to record the condition in which they were found. They were placed inside sample bags and then a \"Special Environmental Sample Container\" for return to the Earth to protect them from contamination. In contrast to the Earth, large portions of the lunar crust appear to be composed of rocks with high concentrations of the mineral anorthite. The mare basalts have relatively high iron values. Furthermore, some of the mare basalts have very high levels of titanium (in the form of ilmenite).\n\nPrimary igneous rocks in the lunar highlands compose three distinct groups: the ferroan anorthosite suite, the magnesian suite, and the alkali suite.\n\nLunar breccias, formed largely by the immense basin-forming impacts, are dominantly composed of highland lithologies because most mare basalts post-date basin formation (and largely fill these impact basins).\n\n\n\"Mare basalts\" are named as such because they frequently constitute large portions of the lunar maria. These are containing typically 18-21 wt% of Fe0, and 1-13% of TiO. They are similar to terrestrial basalts, but have many important differences; for example, mare basalts show a large negative europium anomaly. The type location is Mare Crisium sampled by Luna 24. \n\nThe main repository for the Apollo Moon rocks is the Lunar Sample Laboratory Facility at the Lyndon B. Johnson Space Center in Houston, Texas. For safe keeping, there is also a smaller collection stored at White Sands Test Facility in Las Cruces, New Mexico. Most of the rocks are stored in nitrogen to keep them free of moisture. They are handled only indirectly, using special tools.\n\nMoon rocks collected during the course of lunar exploration are currently considered priceless. In 2002, a safe was stolen from the Lunar Sample Building that contained minute samples of lunar and Martian material. The samples were recovered, and NASA estimated their value during the ensuing court case at about $1 million for 10 oz. (285 g) of material.\n\nNaturally transported Moon rocks in the form of lunar meteorites are sold and traded among private collectors.\n\nApollo 17 astronauts Eugene Cernan and Harrison Schmitt picked up a rock \"composed of many fragments, of many sizes, and many shapes, probably from all parts of the Moon\". This rock was later labeled sample 70017. President Nixon ordered that fragments of that rock should be distributed in 1973 to all 50 US states and 135 foreign heads of state. The fragments were presented encased in an acrylic sphere, mounted on a wood plaque which included the recipients' flag which had also flown aboard Apollo 17. Many of the presentation Moon rocks are now unaccounted for, having been stolen or lost.\n\nThree minerals were discovered from the Moon. These include armalcolite, tranquillityite, and pyroxferroite. Armalcolite was named for the three astronauts on the Apollo 11 mission: Armstrong, Aldrin and Collins.\n\nBecause of their rarity on Earth, and the difficulty of obtaining more, Moon rocks have been frequent targets of theft and vandalism, and many have gone missing or were stolen.\n\n\n"}
{"id": "14481953", "url": "https://en.wikipedia.org/wiki?curid=14481953", "title": "Nicolaus Copernicus Gesamtausgabe", "text": "Nicolaus Copernicus Gesamtausgabe\n\nThe Nicolaus-Copernicus-Gesamtausgabe (\"Nicolaus Copernicus Complete Edition\") is a comprehensive, commented collection of works by, about, and related to Nicolaus Copernicus. The \"Gesamtausgabe\" includes Copernicus's surviving manuscripts and notes, his published writings, other authors' commentary about Copernicus and his works, a bibliography, and a biography.\nCompilation of the series began in 1973 to commemorate the 500th anniversary of Copernicus's birth. The first volume is the astronomer's landmark work, \"De revolutionibus orbium coelestium\" (\"On the Revolutions of the Heavenly Spheres\"), which expounded Copernicus's heliocentric theory of the universe. The set is published by Akademie Verlag in Berlin, Germany.\n\n\n"}
{"id": "21201", "url": "https://en.wikipedia.org/wiki?curid=21201", "title": "Nobel Prize", "text": "Nobel Prize\n\nThe Nobel Prize (, ; Swedish definite form, singular: \"Nobelpriset\"; ) is a set of annual international awards bestowed in several categories by Swedish and Norwegian institutions in recognition of academic, cultural, or scientific advances.\n\nThe will of the Swedish scientist Alfred Nobel established the five Nobel prizes in 1895. The prizes in Chemistry, Literature, Peace, Physics, and Physiology or Medicine were first awarded in 1901. In 1968, Sweden's central bank, Sveriges Riksbank, established the \"Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel\", which, although not being a Nobel Prize, has become informally known as the \"Nobel Prize in Economics\". The prizes are widely regarded as the most prestigious awards available in the fields of chemistry, literature, peace activism, physics, and physiology or medicine.\n\nThe Royal Swedish Academy of Sciences awards the Nobel Prize in Chemistry, the Nobel Prize in Physics, and the Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel; the Nobel Assembly at the Karolinska Institute awards the Nobel Prize in Physiology or Medicine; the Swedish Academy grants the Nobel Prize in Literature; and the Nobel Peace Prize is awarded by the Norwegian Nobel Committee.\n\nBetween 1901 and 2018, the Nobel Prizes (and the Prizes in Economic Sciences, from 1969 on) were awarded 590 times to 935 people and organizations. With some receiving the Nobel Prize more than once, this makes a total of 27 organizations and 908 individuals. The prize ceremonies take place annually in Stockholm, Sweden (with the exception of the Peace Prize ceremony, which is held in Oslo, Norway). Each recipient (known as a \"laureate\") receives a gold medal, a diploma, and a sum of money that has been decided by the Nobel Foundation. (, each prize is worth 9,000,000 SEK, or about , €944,000, £836,000 or ₹73,800,000.) Medals made before 1980 were struck in 23 carat gold, and later in 18 carat green gold plated with a 24 carat gold coating.\n\nThe prize is not awarded posthumously; however, if a person is awarded a prize and dies before receiving it, the prize may still be presented. A prize may not be shared among more than three individuals, although the Nobel Peace Prize can be awarded to organizations of more than three people.\n\nAlfred Nobel () was born on 21 October 1833 in Stockholm, Sweden, into a family of engineers. He was a chemist, engineer, and inventor. In 1894, Nobel purchased the Bofors iron and steel mill, which he made into a major armaments manufacturer. Nobel also invented ballistite. This invention was a precursor to many smokeless military explosives, especially the British smokeless powder cordite. As a consequence of his patent claims, Nobel was eventually involved in a patent infringement lawsuit over cordite. Nobel amassed a fortune during his lifetime, with most of his wealth coming from his 355 inventions, of which dynamite is the most famous.\n\nIn 1888, Nobel was astonished to read his own obituary, titled \"The merchant of death is dead\", in a French newspaper. As it was Alfred's brother Ludvig who had died, the obituary was eight years premature. The article disconcerted Nobel and made him apprehensive about how he would be remembered. This inspired him to change his will. On 10 December 1896, Alfred Nobel died in his villa in San Remo, Italy, from a cerebral haemorrhage. He was 63 years old.\n\nNobel wrote several wills during his lifetime. He composed the last over a year before he died, signing it at the Swedish–Norwegian Club in Paris on 27 November 1895. To widespread astonishment, Nobel's last will specified that his fortune be used to create a series of prizes for those who confer the \"greatest benefit on mankind\" in physics, chemistry, physiology or medicine, literature, and peace. Nobel bequeathed 94% of his total assets, 31 million SEK (c. US$186 million, €150 million in 2008), to establish the five Nobel Prizes.\nBecause of skepticism surrounding the will, it was not until 26 April 1897 that it was approved by the Storting in Norway. The executors of Nobel's will, Ragnar Sohlman and Rudolf Lilljequist, formed the Nobel Foundation to take care of Nobel's fortune and organised the award of prizes.\n\nNobel's instructions named a Norwegian Nobel Committee to award the Peace Prize, the members of whom were appointed shortly after the will was approved in April 1897. Soon thereafter, the other prize-awarding organizations were designated. These were Karolinska Institutet on 7 June, the Swedish Academy on 9 June, and the Royal Swedish Academy of Sciences on 11 June. The Nobel Foundation reached an agreement on guidelines for how the prizes should be awarded; and, in 1900, the Nobel Foundation's newly created statutes were promulgated by King Oscar II. In 1905, the personal union between Sweden and Norway was dissolved.\n\nAccording to his will and testament read in Stockholm on 30 December 1896, a foundation established by Alfred Nobel would reward those who serve humanity. The Nobel Prize was funded by Alfred Nobel's personal fortune. According to the official sources, Alfred Nobel bequeathed from the shares 94% of his fortune to the Nobel Foundation that now forms the economic base of the Nobel Prize.\n\nThe Nobel Foundation was founded as a private organization on 29 June 1900. Its function is to manage the finances and administration of the Nobel Prizes. In accordance with Nobel's will, the primary task of the Foundation is to manage the fortune Nobel left. Robert and Ludvig Nobel were involved in the oil business in Azerbaijan, and according to Swedish historian E. Bargengren, who accessed the Nobel family archives, it was this \"decision to allow withdrawal of Alfred's money from Baku that became the decisive factor that enabled the Nobel Prizes to be established\". Another important task of the Nobel Foundation is to market the prizes internationally and to oversee informal administration related to the prizes. The Foundation is not involved in the process of selecting the Nobel laureates. In many ways, the Nobel Foundation is similar to an investment company, in that it invests Nobel's money to create a solid funding base for the prizes and the administrative activities. The Nobel Foundation is exempt from all taxes in Sweden (since 1946) and from investment taxes in the United States (since 1953). Since the 1980s, the Foundation's investments have become more profitable and as of 31 December 2007, the assets controlled by the Nobel Foundation amounted to 3.628 billion Swedish \"kronor\" (c. US$560 million).\n\nAccording to the statutes, the Foundation consists of a board of five Swedish or Norwegian citizens, with its seat in Stockholm. The Chairman of the Board is appointed by the Swedish King in Council, with the other four members appointed by the trustees of the prize-awarding institutions. An Executive Director is chosen from among the board members, a Deputy Director is appointed by the King in Council, and two deputies are appointed by the trustees. However, since 1995, all the members of the board have been chosen by the trustees, and the Executive Director and the Deputy Director appointed by the board itself. As well as the board, the Nobel Foundation is made up of the prize-awarding institutions (the Royal Swedish Academy of Sciences, the Nobel Assembly at Karolinska Institute, the Swedish Academy, and the Norwegian Nobel Committee), the trustees of these institutions, and auditors.\n\nThe capital of the Nobel Foundation today is invested 50 % in shares, 20 % bonds and 30 % other investments (e.g. hedge funds or real estate). The distribution can vary by 10 percent. At the beginning of 2008, 64 % of the funds were invested mainly in American and European stocks, 20 % in bonds, plus 12% in real estate and hedge funds.\n\nIn 2011, the total annual cost was approximately 120 million krona, with 50 million krona as the prize money. Further costs to pay institutions and persons engaged in giving the prizes were 27,4 million krona. The events during the Nobel week in Stockholm and Oslo cost 20,2 million krona. The administration, Nobel symposium, and similar items had costs of 22.4 million krona. The cost of the Economic Sciences prize of 16.5 Million krona is paid by the Sveriges Riksbank.\n\nOnce the Nobel Foundation and its guidelines were in place, the Nobel Committees began collecting nominations for the inaugural prizes. Subsequently, they sent a list of preliminary candidates to the prize-awarding institutions.\n\nThe Nobel Committee's Physics Prize shortlist cited Wilhelm Röntgen's discovery of X-rays and Philipp Lenard's work on cathode rays. The Academy of Sciences selected Röntgen for the prize. In the last decades of the 19th century, many chemists had made significant contributions. Thus, with the Chemistry Prize, the Academy \"was chiefly faced with merely deciding the order in which these scientists should be awarded the prize\". The Academy received 20 nominations, eleven of them for Jacobus van 't Hoff. Van 't Hoff was awarded the prize for his contributions in chemical thermodynamics.\n\nThe Swedish Academy chose the poet Sully Prudhomme for the first Nobel Prize in Literature. A group including 42 Swedish writers, artists, and literary critics protested against this decision, having expected Leo Tolstoy to be awarded. Some, including Burton Feldman, have criticised this prize because they consider Prudhomme a mediocre poet. Feldman's explanation is that most of the Academy members preferred Victorian literature and thus selected a Victorian poet. The first Physiology or Medicine Prize went to the German physiologist and microbiologist Emil von Behring. During the 1890s, von Behring developed an antitoxin to treat diphtheria, which until then was causing thousands of deaths each year.\n\nThe first Nobel Peace Prize went to the Swiss Jean Henri Dunant for his role in founding the International Red Cross Movement and initiating the Geneva Convention, and jointly given to French pacifist Frédéric Passy, founder of the Peace League and active with Dunant in the Alliance for Order and Civilization.\n\nIn 1938 and 1939, Adolf Hitler's Third Reich forbade three laureates from Germany (Richard Kuhn, Adolf Friedrich Johann Butenandt, and Gerhard Domagk) from accepting their prizes. Each man was later able to receive the diploma and medal. Even though Sweden was officially neutral during the Second World War, the prizes were awarded irregularly. In 1939, the Peace Prize was not awarded. No prize was awarded in any category from 1940 to 1942, due to the occupation of Norway by Germany. In the subsequent year, all prizes were awarded except those for literature and peace.\n\nDuring the occupation of Norway, three members of the Norwegian Nobel Committee fled into exile. The remaining members escaped persecution from the Germans when the Nobel Foundation stated that the Committee building in Oslo was Swedish property. Thus it was a safe haven from the German military, which was not at war with Sweden. These members kept the work of the Committee going, but did not award any prizes. In 1944, the Nobel Foundation, together with the three members in exile, made sure that nominations were submitted for the Peace Prize and that the prize could be awarded once again.\n\nIn 1968, Sveriges Riksbank (Sweden's central bank) celebrated its 300th anniversary by donating a large sum of money to the Nobel Foundation to be used to set up a prize in honor of Nobel. The following year, the Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel was awarded for the first time. The Royal Swedish Academy of Sciences became responsible for selecting laureates. The first laureates for the Economics Prize were Jan Tinbergen and Ragnar Frisch \"for having developed and applied dynamic models for the analysis of economic processes\". The Board of the Nobel Foundation decided that after this addition, it would allow no further new prizes.\n\nThe award process is similar for all of the Nobel Prizes; the main difference is in who can make nominations for each of them.\nNomination forms are sent by the Nobel Committee to about 3,000 individuals, usually in September the year before the prizes are awarded. These individuals are generally prominent academics working in a relevant area. Regarding the Peace Prize, inquiries are also sent to governments, former Peace Prize laureates, and current or former members of the Norwegian Nobel Committee. The deadline for the return of the nomination forms is 31 January of the year of the award. The Nobel Committee nominates about 300 potential laureates from these forms and additional names. The nominees are not publicly named, nor are they told that they are being considered for the prize. All nomination records for a prize are sealed for 50 years from the awarding of the prize.\n\nThe Nobel Committee then prepares a report reflecting the advice of experts in the relevant fields. This, along with the list of preliminary candidates, is submitted to the prize-awarding institutions. The institutions meet to choose the laureate or laureates in each field by a majority vote. Their decision, which cannot be appealed, is announced immediately after the vote. A maximum of three laureates and two different works may be selected per award. Except for the Peace Prize, which can be awarded to institutions, the awards can only be given to individuals.\n\nAlthough posthumous nominations are not presently permitted, individuals who died in the months between their nomination and the decision of the prize committee were originally eligible to receive the prize. This has occurred twice: the 1931 Literature Prize awarded to Erik Axel Karlfeldt, and the 1961 Peace Prize awarded to UN Secretary General Dag Hammarskjöld. Since 1974, laureates must be thought alive at the time of the October announcement. There has been one laureate, William Vickrey, who in 1996 died after the prize (in Economics) was announced but before it could be presented. On 3 October 2011, the laureates for the Nobel Prize in Physiology or Medicine were announced; however, the committee was not aware that one of the laureates, Ralph M. Steinman, had died three days earlier. The committee was debating about Steinman's prize, since the rule is that the prize is not awarded posthumously. The committee later decided that as the decision to award Steinman the prize \"was made in good faith\", it would remain unchanged.\n\nNobel's will provided for prizes to be awarded in recognition of discoveries made \"during the preceding year\". Early on, the awards usually recognised recent discoveries. However, some of those early discoveries were later discredited. For example, Johannes Fibiger was awarded the 1926 Prize in Physiology or Medicine for his purported discovery of a parasite that caused cancer. To avoid repeating this embarrassment, the awards increasingly recognised scientific discoveries that had withstood the test of time. According to Ralf Pettersson, former chairman of the Nobel Prize Committee for Physiology or Medicine, \"the criterion 'the previous year' is interpreted by the Nobel Assembly as the year when the full impact of the discovery has become evident.\"\nThe interval between the award and the accomplishment it recognises varies from discipline to discipline. The Literature Prize is typically awarded to recognise a cumulative lifetime body of work rather than a single achievement. The Peace Prize can also be awarded for a lifetime body of work. For example, 2008 laureate Martti Ahtisaari was awarded for his work to resolve international conflicts. However, they can also be awarded for specific recent events. For instance, Kofi Annan was awarded the 2001 Peace Prize just four years after becoming the Secretary-General of the United Nations. Similarly Yasser Arafat, Yitzhak Rabin, and Shimon Peres received the 1994 award, about a year after they successfully concluded the Oslo Accords.\n\nAwards for physics, chemistry, and medicine are typically awarded once the achievement has been widely accepted. Sometimes, this takes decades – for example, Subrahmanyan Chandrasekhar shared the 1983 Physics Prize for his 1930s work on stellar structure and evolution. Not all scientists live long enough for their work to be recognised. Some discoveries can never be considered for a prize if their impact is realised after the discoverers have died.\n\nExcept for the Peace Prize, the Nobel Prizes are presented in Stockholm, Sweden, at the annual Prize Award Ceremony on 10 December, the anniversary of Nobel's death. The recipients' lectures are normally held in the days prior to the award ceremony. The Peace Prize and its recipients' lectures are presented at the annual Prize Award Ceremony in Oslo, Norway, usually on 10 December. The award ceremonies and the associated banquets are typically major international events. The Prizes awarded in Sweden's ceremonies' are held at the Stockholm Concert Hall, with the Nobel banquet following immediately at Stockholm City Hall. The Nobel Peace Prize ceremony has been held at the Norwegian Nobel Institute (1905–1946), at the auditorium of the University of Oslo (1947–1989), and at Oslo City Hall (1990–present).\n\nThe highlight of the Nobel Prize Award Ceremony in Stockholm occurs when each Nobel laureate steps forward to receive the prize from the hands of the King of Sweden. In Oslo, the Chairman of the Norwegian Nobel Committee presents the Nobel Peace Prize in the presence of the King of Norway. At first, King Oscar II did not approve of awarding grand prizes to foreigners. It is said that he changed his mind once his attention had been drawn to the publicity value of the prizes for Sweden.\n\nAfter the award ceremony in Sweden, a banquet is held in the Blue Hall at the Stockholm City Hall, which is attended by the Swedish Royal Family and around 1,300 guests.\n\nThe Nobel Peace Prize banquet is held in Norway at the Oslo Grand Hotel after the award ceremony. Apart from the laureate, guests include the President of the Storting, the Swedish prime minister, and, since 2006, the King and Queen of Norway. In total, about 250 guests attend.\n\nAccording to the statutes of the Nobel Foundation, each laureate is required to give a public lecture on a subject related to the topic of their prize. The Nobel lecture as a rhetorical genre took decades to reach its current format. These lectures normally occur during Nobel Week (the week leading up to the award ceremony and banquet, which begins with the laureates arriving in Stockholm and normally ends with the Nobel banquet), but this is not mandatory. The laureate is only obliged to give the lecture within six months of receiving the prize. Some have happened even later. For example, US President Theodore Roosevelt received the Peace Prize in 1906 but gave his lecture in 1910, after his term in office. The lectures are organized by the same association which selected the laureates.\n\nIt was announced on 30 May 2012 that the Nobel Foundation had awarded the contract for the production of the five (Swedish) Nobel Prize medals to Svenska Medalj AB. Formerly, the Nobel Prize medals were minted by Myntverket (the Swedish Mint) from 1902 to 2010. Myntverket, Sweden's oldest company, ceased operations in 2011 after 1,017 years. In 2011, the Mint of Norway, located in Kongsberg, made the medals. The Nobel Prize medals are registered trademarks of the Nobel Foundation. Each medal features an image of Alfred Nobel in left profile on the obverse. The medals for physics, chemistry, physiology or medicine, and literature have identical obverses, showing the image of Alfred Nobel and the years of his birth and death. Nobel's portrait also appears on the obverse of the Peace Prize medal and the medal for the Economics Prize, but with a slightly different design. For instance, the laureate's name is engraved on the rim of the Economics medal. The image on the reverse of a medal varies according to the institution awarding the prize. The reverse sides of the medals for chemistry and physics share the same design.\n\nAll medals made before 1980 were struck in 23 carat gold. Since then, they have been struck in 18 carat green gold plated with 24 carat gold. The weight of each medal varies with the value of gold, but averages about for each medal. The diameter is and the thickness varies between and . Because of the high value of their gold content and tendency to be on public display, Nobel medals are subject to medal theft. During World War II, the medals of German scientists Max von Laue and James Franck were sent to Copenhagen for safekeeping. When Germany invaded Denmark, Hungarian chemist (and Nobel laureate himself) George de Hevesy dissolved them in aqua regia (nitro-hydrochloric acid), to prevent confiscation by Nazi Germany and to prevent legal problems for the holders. After the war, the gold was recovered from solution, and the medals re-cast.\n\nNobel laureates receive a diploma directly from the hands of the King of Sweden, or in the case of the peace prize, the Chairman of the Norwegian Nobel Committee. Each diploma is uniquely designed by the prize-awarding institutions for the laureates that receive them. The diploma contains a picture and text in Swedish which states the name of the laureate and normally a citation of why they received the prize. None of the Nobel Peace Prize laureates has ever had a citation on their diplomas.\n\nThe laureates are given a sum of money when they receive their prizes, in the form of a document confirming the amount awarded. The amount of prize money depends upon how much money the Nobel Foundation can award each year. The purse has increased since the 1980s, when the prize money was 880,000 SEK per prize (c. 2.6 million SEK altogether, US$350,000 today). In 2009, the monetary award was 10 million SEK (US$1.4 million). In June 2012, it was lowered to 8 million SEK. If there are two laureates in a particular category, the award grant is divided equally between the recipients. If there are three, the awarding committee has the option of dividing the grant equally, or awarding one-half to one recipient and one-quarter to each of the others. It is common for recipients to donate prize money to benefit scientific, cultural, or humanitarian causes.\n\nAmong other criticisms, the Nobel Committees have been accused of having a political agenda, and of omitting more deserving candidates. They have also been accused of Eurocentrism, especially for the Literature Prize.\n\n\nAmong the most criticised Nobel Peace Prizes was the one awarded to Henry Kissinger and Lê Đức Thọ. This led to the resignation of two Norwegian Nobel Committee members. Kissinger and Thọ were awarded the prize for negotiating a ceasefire between North Vietnam and the United States in January 1973. However, when the award was announced, both sides were still engaging in hostilities. Critics sympathetic to the North announced that Kissinger was not a peace-maker but the opposite, responsible for widening the war. Those hostile to the North and what they considered its deceptive practices during negotiations were deprived of a chance to criticise Lê Đức Thọ, as he declined the award. \n\nYasser Arafat, Shimon Peres, and Yitzhak Rabin received the Peace Prize in 1994 for their efforts in making peace between Israel and Palestine. Immediately after the award was announced, one of the five Norwegian Nobel Committee members denounced Arafat as a terrorist and resigned. Additional misgivings about Arafat were widely expressed in various newspapers.\n\nAnother controversial Peace Prize was that awarded to Barack Obama in 2009. Nominations had closed only eleven days after Obama took office as President of the United States, but the actual evaluation occurred over the next eight months. Obama himself stated that he did not feel deserving of the award, or worthy of the company it would place him in. Past Peace Prize laureates were divided, some saying that Obama deserved the award, and others saying he had not secured the achievements to yet merit such an accolade. Obama's award, along with the previous Peace Prizes for Jimmy Carter and Al Gore, also prompted accusations of a left-wing bias.\n\n\nThe award of the 2004 Literature Prize to Elfriede Jelinek drew a protest from a member of the Swedish Academy, Knut Ahnlund. Ahnlund resigned, alleging that the selection of Jelinek had caused \"irreparable damage to all progressive forces, it has also confused the general view of literature as an art\". He alleged that Jelinek's works were \"a mass of text shovelled together without artistic structure\". The 2009 Literature Prize to Herta Müller also generated criticism. According to \"The Washington Post\", many US literary critics and professors were ignorant of her work. This made those critics feel the prizes were too Eurocentric.\n\n\nIn 1949, the neurologist António Egas Moniz received the Physiology or Medicine Prize for his development of the prefrontal leucotomy. The previous year, Dr. Walter Freeman had developed a version of the procedure which was faster and easier to carry out. Due in part to the publicity surrounding the original procedure, Freeman's procedure was prescribed without due consideration or regard for modern medical ethics. Endorsed by such influential publications as \"The New England Journal of Medicine\", leucotomy or \"lobotomy\" became so popular that about 5,000 lobotomies were performed in the United States in the three years immediately following Moniz's receipt of the Prize.\n\nThe Norwegian Nobel Committee confirmed that Mahatma Gandhi was nominated for the Peace Prize in 1937–39, 1947, and a few days before he was assassinated in January 1948. Later, members of the Norwegian Nobel Committee expressed regret that he was not given the prize. Geir Lundestad, Secretary of Norwegian Nobel Committee in 2006, said, \"The greatest omission in our 106 year history is undoubtedly that Mahatma Gandhi never received the Nobel Peace prize. Gandhi could do without the Nobel Peace prize. Whether Nobel committee can do without Gandhi is the question\". In 1948, the year of Gandhi's death, the Nobel Committee declined to award a prize on the grounds that \"there was no suitable living candidate\" that year. Later, when the 14th Dalai Lama was awarded the Peace Prize in 1989, the chairman of the committee said that this was \"in part a tribute to the memory of Mahatma Gandhi\". Other high-profile individuals with widely recognised contributions to peace have been missed out. \"Foreign Policy\" lists Eleanor Roosevelt, Václav Havel, Ken Saro-Wiwa, Sari Nusseibeh, and Corazon Aquino as people who \"never won the prize, but should have\".\n\nIn 1965, UN Secretary General U Thant was informed by the Norwegian Permanent Representative to the UN that he would be awarded that year's prize and asked whether or not he would accept. He consulted staff and later replied that he would. At the same time, Chairman Gunnar Jahn of the Nobel Peace prize committee, lobbied heavily against giving U Thant the prize and the prize was at the last minute awarded to UNICEF. The rest of the committee all wanted the prize to go to U Thant, for his work in defusing the Cuban Missile Crisis, ending the war in the Congo, and his ongoing work to mediate an end to the Vietnam War. The disagreement lasted three years and in 1966 and 1967 no prize was given, with Gunnar Jahn effectively vetoing an award to U Thant.\nThe Literature Prize also has controversial omissions. Adam Kirsch has suggested that many notable writers have missed out on the award for political or extra-literary reasons. The heavy focus on European and Swedish authors has been a subject of criticism. The Eurocentric nature of the award was acknowledged by Peter Englund, the 2009 Permanent Secretary of the Swedish Academy, as a problem with the award and was attributed to the tendency for the academy to relate more to European authors. This tendency towards European authors still leaves some European writers on a list of notable writers that have been overlooked for the Literature Prize, including Europe's Leo Tolstoy, Anton Chekhov, J. R. R. Tolkien, Émile Zola, Marcel Proust, Vladimir Nabokov, James Joyce, August Strindberg, Simon Vestdijk, Karel Čapek, the New World's Jorge Luis Borges, Ezra Pound, John Updike, Arthur Miller, Mark Twain, and Africa's Chinua Achebe.\n\nCandidates can receive multiple nominations the same year. Gaston Ramon received a total of 155 nominations in physiology or medicine from 1930 to 1953, the last year with public nomination data for that award . He died in 1963 without being awarded. Pierre Paul Émile Roux received 115 nominations in physiology or medicine, and Arnold Sommerfeld received 84 in physics. These are the three most nominated scientists without awards in the data published . Otto Stern received 79 nominations in physics 1925–43 before being awarded in 1943.\n\nThe strict rule against awarding a prize to more than three people is also controversial. When a prize is awarded to recognise an achievement by a team of more than three collaborators, one or more will miss out. For example, in 2002, the prize was awarded to Koichi Tanaka and John Fenn for the development of mass spectrometry in protein chemistry, an award that did not recognise the achievements of Franz Hillenkamp and Michael Karas of the Institute for Physical and Theoretical Chemistry at the University of Frankfurt. According to one of the nominees for the prize in physics, the three person limit deprived him and two other members of his team of the honor in 2013: the team of Carl Hagen, Gerald Guralnik, and Tom Kibble published a paper in 1964 that gave answers to how the cosmos began, but did not share the 2013 Physics Prize awarded to Peter Higgs and François Englert, who had also published papers in 1964 concerning the subject. All five physicists arrived at the same conclusion, albeit from different angles. Hagen contends that an equitable solution is to either abandon the three limit restriction, or expand the time period of recognition for a given achievement to two years.\n\nSimilarly, the prohibition of posthumous awards fails to recognise achievements by an individual or collaborator who dies before the prize is awarded. The Economics Prize was not awarded to Fischer Black, who died in 1995, when his co-author Myron Scholes received the honor in 1997 for their landmark work on option pricing along with Robert C. Merton, another pioneer in the development of valuation of stock options. In the announcement of the award that year, the Nobel committee prominently mentioned Black's key role.\n\nPolitical subterfuge may also deny proper recognition. Lise Meitner and Fritz Strassmann, who co-discovered nuclear fission along with Otto Hahn, may have been denied a share of Hahn's 1944 Nobel Chemistry Award due to having fled Germany when the Nazis came to power. The Meitner and Strassmann roles in the research was not fully recognised until years later, when they joined Hahn in receiving the 1966 Enrico Fermi Award.\n\nAlfred Nobel left his fortune to finance annual prizes to be awarded \"to those who, during the preceding year, shall have conferred the greatest benefit on mankind\". He stated that the Nobel Prizes in Physics should be given \"to the person who shall have made the most important 'discovery' or 'invention' within the field of physics\". Nobel did not emphasise discoveries, but they have historically been held in higher respect by the Nobel Prize Committee than inventions: 77% of the Physics Prizes have been given to discoveries, compared with only 23% to inventions. Christoph Bartneck and Matthias Rauterberg, in papers published in \"Nature\" and \"Technoetic Arts\", have argued this emphasis on discoveries has moved the Nobel Prize away from its original intention of rewarding the greatest contribution to society.\n\nIn terms of the most prestigious awards in STEM fields, only a small proportion have been awarded to women. Out of 210 laureates in Physics, 181 in Chemistry and 216 in Medicine between 1901 and 2018, there were only three female laureates in physics, five in chemistry and 12 in medicine.\n\nFour people have received two Nobel Prizes. Marie Curie received the Physics Prize in 1903 for her work on radioactivity and the Chemistry Prize in 1911 for the isolation of pure radium, making her the only person to be awarded a Nobel Prize in two different sciences. Linus Pauling was awarded the 1954 Chemistry Prize for his research into the chemical bond and its application to the structure of complex substances. Pauling was also awarded the Peace Prize in 1962 for his activism against nuclear weapons, making him the only laureate of two unshared prizes. John Bardeen received the Physics Prize twice: in 1956 for the invention of the transistor and in 1972 for the theory of superconductivity. Frederick Sanger received the prize twice in Chemistry: in 1958 for determining the structure of the insulin molecule and in 1980 for inventing a method of determining base sequences in DNA.\n\nTwo organizations have received the Peace Prize multiple times. The International Committee of the Red Cross received it three times: in 1917 and 1944 for its work during the world wars; and in 1963 during the year of its centenary. The United Nations High Commissioner for Refugees has been awarded the Peace Prize twice for assisting refugees: in 1954 and 1981.\n\nThe Curie family has received the most prizes, with four prizes awarded to five individual laureates. Marie Curie received the prizes in Physics (in 1903) and Chemistry (in 1911). Her husband, Pierre Curie, shared the 1903 Physics prize with her. Their daughter, Irène Joliot-Curie, received the Chemistry Prize in 1935 together with her husband Frédéric Joliot-Curie. In addition, the husband of Marie Curie's second daughter, Henry Labouisse, was the director of UNICEF when he accepted the Nobel Peace Prize in 1965 on that organisation's behalf.\n\nAlthough no family matches the Curie family's record, there have been several with two laureates. The husband-and-wife team of Gerty Cori and Carl Ferdinand Cori shared the 1947 Prize in Physiology or Medicine as did the husband-and-wife team of May-Britt Moser and Edvard Moser in 2014 (along with John O'Keefe). J. J. Thomson was awarded the Physics Prize in 1906 for showing that electrons are particles. His son, George Paget Thomson, received the same prize in 1937 for showing that they also have the properties of waves. William Henry Bragg and his son, William Lawrence Bragg, shared the Physics Prize in 1915 for inventing the X-ray spectrometer. Niels Bohr was awarded the Physics prize in 1922, as was his son, Aage Bohr, in 1975. Manne Siegbahn, who received the Physics Prize in 1924, was the father of Kai Siegbahn, who received the Physics Prize in 1981. Hans von Euler-Chelpin, who received the Chemistry Prize in 1929, was the father of Ulf von Euler, who was awarded the Physiology or Medicine Prize in 1970. C. V. Raman was awarded the Physics Prize in 1930 and was the uncle of Subrahmanyan Chandrasekhar, who was awarded the same prize in 1983. Arthur Kornberg received the Physiology or Medicine Prize in 1959; Kornberg's son, Roger later received the Chemistry Prize in 2006. Jan Tinbergen, who was awarded the first Economics Prize in 1969, was the brother of Nikolaas Tinbergen, who received the 1973 Physiology or Medicine Prize. Alva Myrdal, Peace Prize laureate in 1982, was the wife of Gunnar Myrdal who was awarded the Economics Prize in 1974. Economics laureates Paul Samuelson and Kenneth Arrow were brothers-in-law. Frits Zernike, who was awarded the 1953 Physics Prize, is the great-uncle of 1999 Physics laureate Gerard 't Hooft.\n\nBeing a symbol of scientific or literary achievement that is recognisable worldwide, the Nobel Prize is often depicted in fiction. This includes films like \"The Prize\" and \"Nobel Son\" about fictional Nobel laureates as well as fictionalised accounts of stories surrounding real prizes such as \"Nobel Chor\", a film based on the unsolved theft of Rabindranath Tagore's prize.\n\nTwo laureates have voluntarily declined the Nobel Prize. In 1964, Jean-Paul Sartre was awarded the Literature Prize but refused, stating, \"A writer must refuse to allow himself to be transformed into an institution, even if it takes place in the most honourable form.\" Lê Đức Thọ, chosen for the 1973 Peace Prize for his role in the Paris Peace Accords, declined, stating that there was no actual peace in Vietnam.\n\nDuring the Third Reich, Adolf Hitler hindered Richard Kuhn, Adolf Butenandt, and Gerhard Domagk from accepting their prizes. All of them were awarded their diplomas and gold medals after World War II. In 1958, Boris Pasternak declined his prize for literature due to fear of what the Soviet Union government might do if he travelled to Stockholm to accept his prize. In return, the Swedish Academy refused his refusal, saying \"this refusal, of course, in no way alters the validity of the award.\" The Academy announced with regret that the presentation of the Literature Prize could not take place that year, holding it back until 1989 when Pasternak's son accepted the prize on his behalf. Aung San Suu Kyi was awarded the Nobel Peace Prize in 1991, but her children accepted the prize because she had been placed under house arrest in Burma; Suu Kyi delivered her speech two decades later, in 2012. Liu Xiaobo was awarded the Nobel Peace Prize in 2010 while he and his wife were under house arrest in China as political prisoners, and he was unable to accept the prize in his lifetime.\n\nThe memorial symbol \"Planet of Alfred Nobel\" was opened in Dnipropetrovsk University of Economics and Law in 2008. On the globe, there are 802 Nobel laureates' reliefs made of a composite alloy obtained when disposing of military strategic missiles.\n\n\n"}
{"id": "5008537", "url": "https://en.wikipedia.org/wiki?curid=5008537", "title": "Obliteration by incorporation", "text": "Obliteration by incorporation\n\nIn sociology of science, obliteration by incorporation (OBI) occurs when at some stage in the development of a science, certain ideas become so universally accepted and commonly used that their contributors are no longer cited. Eventually, its source and creator are forgotten (\"obliterated\") as the concept enters common knowledge (is \"incorporated\"). Obliteration occurs when \"the sources of an idea, finding or concept, become obliterated by incorporation in canonical knowledge, so that only a few are still aware of their parentage\".\n\nThe concept was introduced by Robert K. Merton in 1949, although some incorrectly attribute it to Eugene Garfield, whose work contributed to the popularization of Merton's theory. Merton introduced the concept of \"obliteration by incorporation\" in his landmark work, \"Social Theory and Social Structure\" in 1949 (although the revised edition of 1968 is usually cited (pp. 27–28, 35–37 in the enlarged edition)). Merton also introduced the less known counterpart to this concept, adumbrationism, meaning the attribution of insights, ideas or analogies absent from original works.\n\nIn the process of \"obliteration by incorporation\", both the original idea and the literal formulations of it are forgotten due to prolonged and widespread use, and enter into everyday language (or at least the everyday language of a given academic discipline), no longer being attributed to their creator.\n\nThus they become similar to common knowledge. Merton notes that this process is much more common in highly codified fields of natural sciences than in social sciences. It can also lead to ignoring or hiding the early sources of recent ideas under the claims of novelty and originality. Allan Chapman notes that 'obliteration by incorporation' often affects famous individuals, to whom attribution becomes considered as obvious and unnecessary, thus leading to their exclusion from citations, even if they and their ideas have been mentioned in the text. Marianne Ferber and Eugene Garfield concur with Chapman, noting that obliteration often occurs when the citation count and reputation of an affected scientist have already reached levels much higher than average.\n\nThe obliteration phenomenon is a concept in library and information science, referring to the tendency for truly ground-breaking research papers to fail to be cited after the ideas they put forward are fully accepted into the orthodox world view. For example, Albert Einstein's paper on the theory of relativity is rarely cited in modern research papers on physical cosmology, despite its direct relevance.\n\nMany terms and phrases were so evocative that they quickly suffered the fate of 'obliteration by incorporation'. Examples include:\n\n\n\n\n"}
{"id": "327995", "url": "https://en.wikipedia.org/wiki?curid=327995", "title": "Orthomolecular medicine", "text": "Orthomolecular medicine\n\nOrthomolecular medicine, a form of alternative medicine, aims to maintain human health through nutritional supplementation. The concept builds on the idea of an optimum nutritional environment in the body and suggests that diseases reflect deficiencies in this environment. Treatment for disease, according to this view, involves attempts to correct \"imbalances or deficiencies based on individual biochemistry\" by use of substances such as vitamins, minerals, amino acids, trace elements and fatty acids. The notions behind orthomolecular medicine are not supported by sound medical evidence and the therapy is not effective; even the validity of calling the orthomolecular approach a form of medicine has been questioned since the 1970s.\n\nThe approach is sometimes referred to as megavitamin therapy because its practice evolved out of, and in some cases still uses, doses of vitamins and minerals many times higher than the recommended dietary intake. Orthomolecular practitioners may also incorporate a variety of other styles of treatment into their approaches, including dietary restriction, megadoses of non-vitamin nutrients and mainstream pharmaceutical drugs. Proponents argue that non-optimal levels of certain substances can cause health issues beyond simple vitamin deficiency and see balancing these substances as an integral part of health.\n\nLinus Pauling coined the term \"orthomolecular\" in the 1960s to mean \"the right molecules in the right amounts\" (\"ortho-\" in Greek implies \"correct\"). Proponents of orthomolecular medicine hold that treatment must be based on each patient's individual biochemistry.\n\nThe scientific and medical consensus holds that the broad claims of efficacy advanced by advocates of orthomolecular medicine are not adequately tested as drug therapies. It has been described as a form of food faddism and as quackery. Proponents point to mainstream sources that have published research supporting the benefits of nutrient supplementation and to instances where conventional medicine uses vitamins as treatments for some diseases.\n\nSome vitamins in large doses have been linked to increased risk of cardiovascular disease, of cancer and of death. The scientific consensus view is that for normal individuals, a balanced diet contains all necessary vitamins and minerals, and that routine supplementation is not necessary absent specific diagnosed deficiencies.\n\nIn the early 20th century, some doctors hypothesised that vitamins could cure disease, and supplements were prescribed in megadoses by the 1930s. Their effects on health were disappointing, though, and in the 1950s and 1960s, nutrition was de-emphasised in standard medical curricula. Riordon's organization cite figures from this period as founders of their movement, although the word \"orthomolecular\" was coined by Linus Pauling only in 1967.\n\nAmongst the individuals described posthumously as orthomolecularists are Max Gerson, who developed a diet that he claimed could treat diseases, which the American Medical Association's 1949 Council on Pharmacy and Chemistry found ineffective; and the Shute brothers, who attempted to treat heart disease with vitamin E. Several concepts now cited by orthomolecularists, including individual biochemical variation and inborn errors of metabolism, debuted in scientific papers early in the 20th century.\n\nIn 1948, William McCormick theorized that vitamin C deficiency played an important role in many diseases and began to use large doses in patients. In the 1950s, Fred R. Klenner also tried vitamin C megadosage as a therapy for a wide range of illnesses, including polio. Irwin Stone stated that organisms that do not synthesise their own vitamin C due to a loss-of-function mutation have a disease he called \"hypoascorbemia\". This term is not used by the medical community, and the idea of an organism-wide lack of a biosynthetic pathway as a disease was not endorsed by Stone's contemporaries.\n\nIn the 1950s, some individuals believed that vitamin deficiencies caused mental illness. Psychiatrists Humphry Osmond and Abram Hoffer gave people having acute schizophrenic episodes high doses of niacin, while William Kaufman used niacinamide. While niacin has no known efficacy in psychiatric disease, the use of niacin in combination with statins and other medical therapies has become one of several medical treatments for cardiovascular disease.\n\nIn the late 1960s, Linus Pauling introduced the expression \"orthomolecular\" to express the idea of \"the right molecules in the right amounts\". Since the first claims of medical breakthroughs with vitamin C by Pauling and others, findings on the health effects of vitamin C have been controversial and contradictory. Pauling's claims have been criticised as overbroad.\n\nLater research branched out into nutrients besides niacin and vitamin C, including essential fatty acids.\n\nAccording to Abram Hoffer, orthomolecular medicine does not purport to treat all diseases, nor is it \"a replacement for standard treatment. A proportion of patients will require orthodox treatment, a proportion will do much better on orthomolecular treatment, and the rest will need a skillful blend of both.\" Nevertheless, advocates have said that nutrients can prevent, treat, and sometimes cure a wide range of medical conditions, including: acne, alcoholism, allergies, arthritis, autism, bee stings, bipolar disorder, burns, cancer, the common cold, depression, drug addiction, drug overdose, epilepsy, heart diseases, heavy metal toxicity, acute hepatitis, herpes, hyperactivity, hypertension, hypoglycemia, influenza, learning disabilities, mental and metabolic disorders, migraine, mononucleosis, mushroom poisoning, neuropathy & polyneuritis (including multiple sclerosis), osteoporosis, polio, a hypothesised condition called \"pyroluria\", radiation sickness, Raynaud's disease, mental retardation, schizophrenia, shock, skin problems, snakebite, spider bite, tetanus toxin and viral pneumonia.\n\nHoffer believed that particular nutrients could cure mental illness. In the 1950s, he attempted to treat schizophrenia with niacin, although proponents of orthomolecular psychiatry say that the ideas behind their approach predate Hoffer. According to Hoffer and others who called themselves \"orthomolecular psychiatrists\", psychiatric syndromes result from biochemical deficiencies, allergies, toxicities or several hypothetical contributing conditions which they termed pyroluria, histadelia and histapenia. These purported causes were said to be found during an \"individual biochemical workup\" and treated with megavitamin therapy and dietary changes including fasting. These diagnoses and treatments are not accepted by evidence-based medicine.\n\nAccording to Abram Hoffer, \"primitive\" peoples do not consume processed foods and do not have \"degenerative\" diseases. In contrast, typical \"Western\" diets are said to be insufficient for long-term health, necessitating the use of megadose supplements of vitamins, dietary minerals, proteins, antioxidants, amino acids, ω-3 fatty acids, ω-6 fatty acids, medium-chain triglycerides, dietary fiber, short and long chain fatty acids, lipotropes, systemic and digestive enzymes, other digestive factors, and prohormones to ward off hypothetical metabolism anomalies at an early stage, before they cause disease.\n\nOrthomolecularists say that they provide prescriptions for optimal amounts of micronutrients after individual diagnoses based on blood tests and personal histories. Lifestyle and diet changes may also be recommended. The battery of tests ordered includes many that are not considered useful by medicine.\n\nOrthomolecular medicine is practiced by few medical practitioners.\n\nA survey released in May, 2004 by the National Center for Complementary and Alternative Medicine focused on who used alternative medicine, what was used, and why it was used in the United States by adults age 18 years and over during 2003. The survey reported uses in the previous twelve months that include orthomolecular related uses: Nonvitamin, nonmineral, natural products 18.9%, Diet-based therapies 3.5%, Megavitamin therapy 2.8%.\n\nAnother recent CAM survey reported that 12% of liver disease patients used the antioxidant silymarin, more than 6% used vitamins, and that \"in all, 74% of patients reported using CAM in addition to the medications prescribed by their physician, but 26% did not inform their physician of their CAM use.\"\n\nEven though the health benefits are not established, the use of high doses of vitamins is also common in people who have been diagnosed with cancer. According to Cancer Research UK, cancer patients should always seek professional advice before taking such supplements, and using them as a substitute for conventional treatment \"could be harmful to [their] health and greatly reduce the chance of curing or controlling [their] cancer\".\n\nOrthomolecular therapies have been criticized as lacking a sufficient evidence base for clinical use: their scientific foundations are too weak, the studies that have been performed are too few and too open to interpretation, and reported positive findings in observational studies are contradicted by the results of more rigorous clinical trials. Accordingly, \"there is no evidence that orthomolecular medicine is effective\". Proponents of orthomolecular medicine strongly dispute this statement by citing studies demonstrating the effectiveness of treatments involving vitamins, though this ignores the belief that a normal diet will provide adequate nutrients to avoid deficiencies, and that orthomolecular treatments are not actually related to vitamin deficiency. The lack of scientifically rigorous testing of orthomolecular medicine has led to its practices being classed with other forms of alternative medicine and regarded as unscientific. It has been described as food faddism and quackery, with critics arguing that it is based upon an \"exaggerated belief in the effects of nutrition upon health and disease.\" Orthomolecular practitioners will often use dubious diagnostic methods to define what substances are \"correct\"; one example is hair analysis, which produces spurious results when used in this fashion.\n\nProponents of orthomolecular medicine contend that, unlike some other forms of alternative medicine such as homeopathy, their ideas are at least biologically based, do not involve magical thinking, and are capable of generating testable hypotheses. \"Orthomolecular\" is not a standard medical term, and clinical use of specific nutrients is considered a form of chemoprevention (to prevent or delay development of disease) or chemotherapy (to treat an existing condition).\n\nDespite a lack of evidence for its efficacy, interest in intravenous high dose vitamin C therapy has not been permanently extinguished, and some research groups continue to investigate whether it has an effect as a possible cancer treatment.\n\nIn general, the vitamin megadoses advocated by orthomolecular medicine are unsupported by scientific consensus. Some vitamins are toxic in high doses, including niacin (B), cholecalciferol (D) and tocopherol (E). The view of the medical community is that there is no evidence for the efficacy of Orthomolecular medicine as a treatment for cancer, and that high vitamin doses may – on the contrary – increase overall mortality. Nutritional treatments are not generally accepted as being helpful for psychological health. Its claims have been criticized by most medical organizations, including the American Cancer Society, the American Psychiatric Association, the National Institute of Mental Health, the American Academy of Pediatrics, CHAMPUS, and the Canadian Paediatric Society. The American Medical Association describes as \"myths\" the ideas that adequate nutrition is not readily achievable with normal food, all food grown with pesticide is poisonous, all food additives are poisonous, vitamin and mineral deficiencies are common, that the cause of most disease is poor diet, which can be prevented by nutritional supplements.\nSimilarly, the American Cancer Society comments that the current scientific evidence does not \"support use of orthomolecular therapy for most of the conditions for which it is promoted.\" Some supplements have exhibited benefits for specific conditions, while a few have been confirmed to be harmful; the consumption of nutritious foods is the best recognized method to obtain vitamins, minerals, and nutrients crucial for good health. Barrie Cassileth, an adviser on alternative medicine to the National Institutes of Health, stated that \"scientific research has found no benefit from orthomolecular therapy for any disease,\" and medical textbooks also report that there is \"no evidence that megavitamin or orthomolecular therapy is effective in treating any disease.\"\n\nA 1973 task force of the American Psychiatric Association unanimously concluded:\nThis review and critique has carefully examined the literature produced by megavitamin proponents and by those who have attempted to replicate their basic and clinical work. It concludes in this regard that the credibility of the megavitamin proponents is low. Their credibility is further diminished by a consistent refusal over the past decade to perform controlled experiments and to report their new results in a scientifically acceptable fashion. Under these circumstances this Task Force considers the massive publicity which they promulgate via radio, the lay press and popular books, using catch phrases which are really misnomers like \"megavitamin therapy\" and \"orthomolecular treatment,\" to be deplorable.\n\nIn response to claims that orthomolecular medicine could cure childhood psychoses and learning disorders, the American Academy of Pediatrics labelled orthomolecular medicine a \"cult\" in 1976.\n\nProponents of orthomolecular medicine counter that some vitamins and nutrients are now used in medicine as treatments for specific diseases, such as megadose niacin and fish oil for dyslipidemias, and megavitamin therapies for a group of rare inborn errors of metabolism. A review in the \"Annals of Internal Medicine\" concluded that while some therapies might be beneficial, others might be harmful or interfere with effective medical therapy. A recent study of over 161,000 individuals provided, in the words of the authors, \"convincing evidence that multivitamin use has little or no influence on the risk of common cancers, cardiovascular disease, or total mortality in postmenopausal women.\" A recent meta-analysis in \"JAMA\" suggested that supplementation with combinations of antioxidant vitamins (beta-carotene, vitamin A, and vitamin E) may increase mortality, although with respect to beta-carotene this conclusion may be due to the known harmful effect in smokers.\n\nIn the United States, pharmaceuticals must be proven safe and effective to the satisfaction of the FDA before they can be marketed, whereas dietary supplements must be proven \"unsafe\" before regulatory action can be taken. A number of orthomolecular supplements are available in the US in pharmaceutical versions that are sometimes quite similar in strength and general content, or in other countries are regulated as pharmaceuticals. The US regulations also have provisions to recognize a general level of safety for established nutrients that can forgo new drug safety tests. Proponents of orthomolecular medicine argue that supplements are less likely to cause dangerous side-effects or harm, since they are normally present in the body. Some vitamins are toxic in high doses and nearly all (with the possible exception of Vitamin C) will cause adverse effects given high levels of overdosing for prolonged periods as recommended by orthomolecular practitioners. Forgoing medical care in favor of orthomolecular treatments can lead to adverse health outcomes.\n\nHealth professionals see orthomolecular medicine as encouraging individuals to dose themselves with large amounts of vitamins and other nutrients without conventional supervision, which they worry might be damaging to health. Potential risks of inappropriate vitamin and supplement regimes include an increased risk of coronary heart disease, hypertension, thrombophlebitis, peripheral neuropathy, ataxia, neurological effects, liver toxicity, congenital abnormalities, spontaneous abortion, gouty arthritis, jaundice, kidney stones, and diarrhea. In their book \"Trick or Treatment?\", Edzard Ernst and Simon Singh conclude that \"The concepts of orthomolecular medicine are not biologically plausible and not supported by the results of rigorous clinical trials. These problems are compounded by the fact that orthomolecular medicine can cause harm and is often very expensive.\"\n\nOrthomolecular proponents claim that even large doses of vitamin E pose no risk to health and are useful for the treatment and prevention of a broad list of conditions, including heart and circulatory diseases, diabetes and nephritis. Initial hopes for the usefulness of vitamin E in orthomolecular medicine were based on epidemiological studies suggesting that people who consumed more vitamin E had lower risks of chronic disease, such as coronary heart disease. These observational studies could not distinguish between whether the higher levels of vitamin E improved health themselves, or whether confounding variables (such as other dietary factors or exercise) were responsible. To distinguish between these possibilities, a number of randomized controlled trials were performed and meta-analysis of these controlled clinical trials have not shown any clear benefit from any form of vitamin E supplementation for preventing chronic disease. Further clinical studies show no benefit of vitamin E supplements for cardiovascular disease. The current position of the American National Institutes of Health is that there is no convincing evidence that vitamin E supplements can prevent or treat any disease.\n\nBeyond the lack of apparent benefit, a series of three meta-analyses reported that vitamin E supplementation is associated with an increased risk of death; one of the meta-analyses performed by the Cochrane Collaboration also found significantly increased mortality for the antioxidant vitamins A and beta-carotene. A subsequent meta-analysis found no mortality benefit from vitamin E, but also no increase in mortality either.\n\nSeveral articles in the alternative-medicine literature have suggested that orthomolecular-related dietary supplementation might be helpful for patients with HIV/AIDS. \nA study using 250 mg and 1000 mg doses of vitamin C along with other antioxidants to treat people with AIDS did not find any benefit. However, these doses are far smaller than the ones used by orthomolecular physicians for treatment of AIDS.\n\nA meta analysis in 2010 found that micronutrient supplementation decreased the risk of death and improved outcomes in pregnant women with HIV in Africa. A 2017 Cochrane review found no strong evidence to suggest that micronutrient supplementation prevents death or is effective at slowing the progression of disease for adults with HIV. It is important for people living HIV to eat a healthy adequate diet. For people with HIV that have clinically demonstrated deficiencies in micronutrients or for people who are not able to consume the recommended daily quantities of minerals and vitamins, supplementation is still encouraged. Vitamin A in children with HIV appears to be safe and beneficial. Vitamin A deficiency is found in children with HIV infection who may or may not have symptoms of AIDS. Vitamin A supplementation reduces morbidity and mortality in AIDS symptomatic children, but has no effect on asymptomatic children. It does not prevent HIV infection, cannot treat the chronic HIV infection, and will not cure AIDS.\n\nMatthias Rath has been extensively criticized for presenting his vitamin supplements as a treatment for AIDS and for testing them in illegal trials in South Africa. A former associate of Linus Pauling, Rath has promoted vitamins as a treatment for HIV infection, describing treatment with effective antiretroviral drugs as toxic and part of a global conspiracy serving the financial interests of the pharmaceutical industry. In a lawsuit that found against Rath, the South African Medical Association blamed his vitamin products for several deaths. The World Health Organization and two health agencies of the United Nations also described Rath’s advertisements as “wrong and misleading” and “an irresponsible attack on ARV (antiretroviral) therapy.” The South African Centre for Social Science Research described the trials as \"state sponsored pseudo-science\". Rath's trials, conducted with the aid of AIDS denialist David Rasnick, were declared unlawful by the Cape High Court; Rath, Rasnick and their foundation were barred from conducting further unauthorised clinical trials and from advertising their products.\n\nAdvocates of orthomolecular medicine, including Pauling, Hoffer and Ewan Cameron have claimed that their findings are actively suppressed by the medical and pharmaceutical industry. Hoffer wrote \"There is no conspiracy led and directed by a single person or by a single organization. There is no Mafia in psychiatry. However, there is a conspiracy led and directed by a large number of professionals and their associations who have a common aim to protect their hard-earned orthodoxy, no matter what the cost to their opponent colleagues or to their patients.\".\n\nThe \"Journal of Orthomolecular Medicine\", founded in 1967 as the \"Journal of Schizophrenia\", is a major publication of orthomolecular medicine. As Abram Hoffer wrote:\n\nOther members of the medical community deny the existence of such an institutional prejudice. A review in the \"Journal of Clinical Oncology\" denied that physicians collude against unconventional treatments. Despite claims of conspiracy, the Linus Pauling Institute's funding comes primarily from the National Institutes of Health, and in 1995 some orthomolecular therapies were reported as being sanctioned in Japan.\n\n\n"}
{"id": "6301802", "url": "https://en.wikipedia.org/wiki?curid=6301802", "title": "Outline of computer programming", "text": "Outline of computer programming\n\nThe following outline is provided as an overview of and topical guide to computer programming:\n\nComputer programming – process that leads from an original formulation of a computing problem to executable computer programs. Programming involves activities such as analysis, developing understanding, generating algorithms, verification of requirements of algorithms including their correctness and resources consumption, and implementation (commonly referred to as coding) of algorithms in a target programming language. Source code is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate performing a specific task or solving a given problem.\n\n\n\n\n\n\n\nProgramming language – formal constructed language designed to communicate instructions to a machine, particularly a computer. Programming languages can be used to create programs to control the behavior of a machine or to express algorithms.\n\n\nThe top 20 most popular programming languages :\n\n\nProgramming language comparisons\n\n\n\n\n\n\nSoftware engineering – \n\n\n"}
{"id": "13911218", "url": "https://en.wikipedia.org/wiki?curid=13911218", "title": "Per cent mille", "text": "Per cent mille\n\nA per cent mille or pcm is one one-thousandth of a percent. It can be thought of as a \"milli-percent\". It is commonly used in nuclear reactor engineering as a unit of reactivity.\n\nIn nuclear reactor engineering, a per cent mille is equal to one-thousandth of a percent of the reactivity, denoted by Greek lowercase letter rho. Reactivity is a dimensionless unit representing a departure from criticality, calculated by:\nwhere k denotes the effective multiplication factor for the reaction. Therefore, one pcm is equal to:\nThis unit is commonly used in the operation of light-water reactor sites because reactivity values tend to be small, so measuring in pcm allows reactivity to be expressed using whole numbers.\n\n"}
{"id": "41655528", "url": "https://en.wikipedia.org/wiki?curid=41655528", "title": "Psammon", "text": "Psammon\n\nPsammon (from Greek \"psammos\", \"sand\") is a group of organisms inhabiting coastal sand moist — biota buried in sediments. Psammon is a part of water fauna, along with periphyton, plankton, nekton, and benthos. Psammon is also sometimes considered a part of benthos due to its near-bottom distribution. Psammon term is commonly used to refer to freshwater reservoirs such as lakes.\n"}
{"id": "4167401", "url": "https://en.wikipedia.org/wiki?curid=4167401", "title": "Quadratic form (statistics)", "text": "Quadratic form (statistics)\n\nIn multivariate statistics, if formula_1 is a vector of formula_2 random variables, and formula_3 is an formula_2-dimensional symmetric matrix, then the scalar quantity formula_5 is known as a quadratic form in formula_1.\n\nIt can be shown that\n\nwhere formula_8 and formula_9 are the expected value and variance-covariance matrix of formula_1, respectively, and tr denotes the trace of a matrix. This result only depends on the existence of formula_8 and formula_9; in particular, normality of formula_1 is \"not\" required.\n\nA book treatment of the topic of quadratic forms in random variables is that of Mathai and Provost.\n\nSince the quadratic form is a scalar quantity, formula_14.\n\nNext, by the cyclic property of the trace operator,\n\nSince the trace operator is a linear combination of the components of the matrix, it therefore follows from the linearity of the expectation operator that\n\nA standard property of variances then tells us that this is\n\nApplying the cyclic property of the trace operator again, we get\n\nIn general, the variance of a quadratic form depends greatly on the distribution of formula_1. However, if formula_1 \"does\" follow a multivariate normal distribution, the variance of the quadratic form becomes particularly tractable. Assume for the moment that formula_3 is a symmetric matrix. Then,\n\nIn fact, this can be generalized to find the covariance between two quadratic forms on the same formula_1 (once again, formula_24 and formula_25 must both be symmetric):\n\nSome texts incorrectly state that the above variance or covariance results hold without requiring formula_3 to be symmetric. The case for general formula_3 can be derived by noting that\n\nso\n\nis a quadratic form in the symmetric matrix formula_31, so the mean and variance expressions are the same, provided formula_3 is replaced by formula_33 therein.\n\nIn the setting where one has a set of observations formula_34 and an operator matrix formula_35, then the residual sum of squares can be written as a quadratic form in formula_34:\n\nFor procedures where the matrix formula_35 is symmetric and idempotent, and the errors are Gaussian with covariance matrix formula_39, formula_40 has a chi-squared distribution with formula_41 degrees of freedom and noncentrality parameter formula_42, where\n\nmay be found by matching the first two central moments of a noncentral chi-squared random variable to the expressions given in the first two sections. If formula_45 estimates formula_8 with no bias, then the noncentrality formula_42 is zero and formula_40 follows a central chi-squared distribution.\n\n"}
{"id": "18944443", "url": "https://en.wikipedia.org/wiki?curid=18944443", "title": "Quake-Catcher Network", "text": "Quake-Catcher Network\n\nThe Quake-Catcher Network is an initiative run by the University of Southern California that aims to use computer-based accelerometers to detect earthquakes. It uses the BOINC volunteer computing platform (a form of distributed computing, similar to SETI@home).\n\nIt currently supports mobile devices (smartphones and some tablets/laptops) that have a built-in accelerometer. It also supports three external USB devices currently - the codemercs.com JoyWarrior 24F8, the ONavi sensor, and the MotionNode Accel.\n\nIn 2011, project scientist Elizabeth Cochran was awarded a Presidential Early Career Award from US President Barack Obama in large part due to her founding of the Quake-Catcher Network project.\n\n"}
{"id": "5762221", "url": "https://en.wikipedia.org/wiki?curid=5762221", "title": "Richard Dawkins: How a Scientist Changed the Way We Think", "text": "Richard Dawkins: How a Scientist Changed the Way We Think\n\nRichard Dawkins: How a Scientist Changed the Way We Think is a festschrift of 25 essays written in recognition of the life and work of Richard Dawkins. It was published in 2006, to coincide with the 30th anniversary of the publication of \"The Selfish Gene\". A wide range of topics is covered from many fields including evolutionary biology, philosophy, and psychology. Space is also given to writers who are not in full agreement with Dawkins. The book is edited by two of Dawkins' former PhD students, Alan Grafen and Mark Ridley. ()\n\nThe reviews of the book have been mixed, but the controversial title phrase, \"How a Scientist Changed the Way We Think\" has been explained by considering Dawkins to have worked as an influential educator and concise author, of \"The Selfish Gene\", who promoted the key ideas of others about evolutionary biology, also including some controversial ideas which are not as widely accepted.\nAs the author of a popular science book, Dawkins had popularized ideas by George Williams about group selection, William Hamilton on the theory of kin selection in evolution, biologist/geneticist John Maynard Smith on evolutionarily stable strategies, and Robert Trivers about reciprocal altruism and competition between siblings versus parent and child.\n\n"}
{"id": "25025301", "url": "https://en.wikipedia.org/wiki?curid=25025301", "title": "Slab pull", "text": "Slab pull\n\nSlab pull is that part of the motion of a tectonic plate that is caused by its subduction. Plate motion is partly driven by the weight of cold, dense plates sinking into the mantle at oceanic trenches. This force and slab suction account for almost all of the force driving plate tectonics. The ridge push at rifts contributes only 5 to 10%.\n\nCarlson et al. (1983) in Lallemandet al. (2005) defines the slab pull force as:\n\nWhere:\n\nThe slab pull force manifests itself between two extreme forms:\nBetween these two examples there is the evolution of the Farallon plate: from the huge slab width with the Nevada, the Sevier and Laramide orogenies; the Mid-Tertiary ignimbrite flare-up and later left as Juan de Fuca and Cocos plates, the Basin and Range Province under extension, with slab break off, smaller slab width, more edges and mantle return flow.\n\nSome early models of plate tectonics envisioned the plates riding on top of convection cells like conveyor belts. However, most scientists working today believe that the asthenosphere does not directly cause motion by the friction of such basal forces. The North American Plate is nowhere being subducted, yet it is in motion. Likewise the African, Eurasian and Antarctic Plates. The subducting slabs around the Pacific Ring of Fire cool down the Earth and its Core-mantle boundary, around the African Plate the upwelling mantle plumes from the Core-mantle boundary produce rifting. The overall driving force for plate motion and its energy source remain subjects of ongoing research.\n\n"}
{"id": "644488", "url": "https://en.wikipedia.org/wiki?curid=644488", "title": "Spin foam", "text": "Spin foam\n\nIn physics, the topological structure of spinfoam or spin foam consists of two-dimensional faces representing a configuration required by functional integration to obtain a Feynman's path integral description of quantum gravity. Also, see loop quantum gravity.\n\nCovariant formulation of loop quantum gravity provides the best formulation of the dynamics of the theory of quantum gravity – a quantum field theory where the invariance under diffeomorphisms of general relativity applies. The resulting path integral represents a sum over all the possible configurations of spin foam.\n\nA spin network is a one-dimensional graph, together with labels on its vertices and edges which encode aspects of a spatial geometry. \n\nA spin network is defined as a diagram like the Feynman diagram which makes a basis of connections between the elements of a differentiable manifold for the Hilbert spaces defined over them, and for computations of amplitudes between two different hypersurfaces of the manifold. Any evolution of the spin network provides a spin foam over a manifold of one dimension higher than the dimensions of the corresponding spin network. A spin foam is analogous to quantum history.\n\nSpin networks provide a language to describe the quantum geometry of space. Spin foam does the same job for spacetime.\n\nSpacetime can be defined as a superposition of spin foams, which is a generalized Feynman diagram where instead of a graph, a higher-dimensional complex is used. In topology this sort of space is called a 2-complex. A spin foam is a particular type of 2-complex, with labels for vertices, edges and faces. The boundary of a spin foam is a spin network, just as in the theory of manifolds, where the boundary of an n-manifold is an (n-1)-manifold.\n\nIn Loop Quantum Gravity, the present Spin Foam Theory has been inspired by the work of Ponzano–Regge model. The concept of a spin foam, although not called that at the time, was introduced in the paper \"A Step Toward Pregeometry I: Ponzano–Regge Spin Networks and the Origin of Spacetime Structure in Four Dimensions\" by Norman J. LaFave. In this paper, the concept of creating sandwiches of 4-geometry (and local time scale) from spin networks is described, along with the connection of these spin 4-geometry sandwiches to form paths of spin networks connecting given spin network boundaries (spin foams). Quantization of the structure leads to a generalized Feynman path integral over connected paths of spin networks between spin network boundaries. This paper goes beyond much of the later work by showing how 4-geometry is already present in the seemingly three dimensional spin networks, how local time scales occur, and how the field equations and conservation laws are generated by simple consistency requirements. The idea was reintroduced in a 1997 paper and later developed into the Barrett–Crane model. The formulation that is used nowadays is commonly called EPRL after the names of the authors of a series of seminal papers, but the theory has also seen fundamental contributions from the work of many others, such as Laurent Freidel (FK model) and Jerzy Lewandowski (KKL model).\n\nThe summary partition function for a spin foam model is \n\nformula_1\n\nwith:\n\n\n\n"}
{"id": "485405", "url": "https://en.wikipedia.org/wiki?curid=485405", "title": "Superseded scientific theory", "text": "Superseded scientific theory\n\nA scientific theory is superseded or becomes obsolete when a scientific consensus once widely accepted it, but current science considers it an inadequate, incomplete, or simply false description of reality. Such labels do not cover protoscientific or fringe science theories that have never had broad support in the scientific community. Also, superseded or obsolete theories exclude theories that were never widely accepted. Some theories that were only supported under specific political authorities, such as Lysenkoism, may also be described as obsolete or superseded.\n\nAll of Newtonian physics is so satisfactory for most purposes that it is more widely used except at velocities that are a significant fraction of the speed of light, and simpler Newtonian but not relativistic mechanics is usually taught in schools. Another case is the belief that the earth is approximately flat. For centuries, people have known that a flat Earth model produces errors in long-distance calculations, but considering local-scale areas as flat for the purposes of mapping and surveying does not introduce significant errors.\n\nIn some cases, a theory or idea is found baseless and is simply discarded. For example, the phlogiston theory was entirely replaced by the quite different concept of energy and related laws. In other cases an existing theory is replaced by a new theory that retains significant elements of the earlier theory; in these cases, the older theory is often still useful for many purposes, and may be more easily understood than the complete theory and lead to simpler calculations. An example of this is the use of Newtonian physics, which differs from the currently accepted relativistic physics by a factor that is negligibly small at velocities much lower than that of light.\n\nScientific theories are testable and make falsifiable predictions. Thus, it is a mark of good science if a discipline has a growing list of superseded theories, and conversely, a lack of superseded theories can indicate problems in following the use of the scientific method.\n\n\n\n\n\n\n\n\n\n\n\nHere are theories that are no longer considered the most complete representation of reality, but remain useful in particular domains or under certain conditions. For some theories a more complete model is known, but in practical use the coarser approximation provides good results with much less calculation.\n\n\n\n"}
{"id": "44292016", "url": "https://en.wikipedia.org/wiki?curid=44292016", "title": "Table of neurotransmitter actions in the ANS", "text": "Table of neurotransmitter actions in the ANS\n\n The bronchioles have no sympathetic innervation, but are instead affected by circulating adrenaline\n"}
{"id": "20612276", "url": "https://en.wikipedia.org/wiki?curid=20612276", "title": "Total balance", "text": "Total balance\n\nTotal balance refers to whole-system scientific methods for adding up the whole effect of things, starting from the concepts of life-cycle analysis (LCA) and using scientific methods to mix physical measures with economic measures and the whole system learning curves of their environmental connections. A balance of future compensations assuming a goal of sustainability is the objective. It is aimed at providing people a true measure of the meaning of their choices. The start is using the energy value of money as a measure of the whole economic system, and its widely distributed average effects.\n\nThe untraceable portion of whole system impacts may be shown to be many times the scale of the traceable portion when considered that way. It's useful because so much of the impacts distributed in complex systems are unaccountable. The major unaccountable part of economic impacts, for example, is the free use of the money given others for their goods and services. There are no data for what they do with it, making it a perfect hiding place for many times the impacts you readily see.\n\nFor whole energy impact of a choice the simple first step is to add up the accountable BTUs used, like electric bills and LCA accounts, and then add the country's GDP for the cost. The global average spent per BTU works out to roughly 6000 BTU per dollar in 2008 based on United States Department of Energy trends. Then there are ways to proportionally adjust that for the details of other things. The effect is to add the impacts of the technology and the impacts of the commerce.\n"}
{"id": "48259106", "url": "https://en.wikipedia.org/wiki?curid=48259106", "title": "Transfer function matrix", "text": "Transfer function matrix\n\nIn control system theory, and various branches of engineering, a transfer function matrix, or just transfer matrix is a generalisation of the transfer functions of single-input single-output (SISO) systems to multiple-input and multiple-output (MIMO) systems. The matrix relates the outputs of the system to its inputs. It is a particularly useful construction for linear time-invariant (LTI) systems because it can be expressed in terms of the s-plane.\n\nIn some systems, especially ones consisting entirely of passive components, it can be ambiguous which variables are inputs and which are outputs. In electrical engineering, a common scheme is to gather all the voltage variables on one side and all the current variables on the other regardless of which are inputs or outputs. This results in all the elements of the transfer matrix being in units of impedance. The concept of impedance (and hence impedance matrices) has been borrowed into other energy domains by analogy, especially mechanics and acoustics.\n\nMany control systems span several different energy domains. This requires transfer matrices with elements in mixed units. This is needed both to describe transducers that make connections between domains and to describe the system as a whole. If the matrix is to properly model energy flows in the system, compatible variables must be chosen to allow this.\n\nA MIMO system with outputs and inputs is represented by a matrix. Each entry in the matrix is in the form of a transfer function relating an output to an input. For example, for a three-input, two-output system, one might write,\n\nwhere the are the inputs, the are the outputs, and the are the transfer functions. This may be written more succinctly in matrix operator notation as,\n\nwhere is a column vector of the outputs, is a matrix of the transfer functions, and is a column vector of the inputs.\n\nIn many cases, the system under consideration is a linear time-invariant (LTI) system. In such cases, it is convenient to express the transfer matrix in terms of the Laplace transform (in the case of continuous time variables) or the z-transform (in the case of discrete time variables) of the variables. This may be indicated by writing, for instance,\n\nwhich indicates that the variables and matrix are in terms of , the complex frequency variable of the s-plane arising from Laplace transforms, rather than time. The examples in this article are all assumed to be in this form, although that is not explicitly indicated for brevity. For discrete time systems is replaced by from the z-transform, but this makes no difference to subsequent analysis. The matrix is particular useful when it is a proper rational matrix, that is, all its elements are proper rational functions. In this case the state-space representation can be applied.\n\nIn systems engineering, the overall system transfer matrix is decomposed into two parts: representing the system being controlled, and representing the control system. takes as its inputs the inputs of and the outputs of . The outputs of form the inputs for .\n\nIn electrical systems it is often the case that the distinction between input and output variables is ambiguous. They can be either, depending on circumstance and point of view. In such cases the concept of port (a place where energy is transferred from one system to another) can be more useful than input and output. It is customary to define two variables for each port (): the voltage across it () and the current entering it (). For instance, the transfer matrix of a two-port network can be defined as follows,\n\nwhere the are called the impedance parameters, or \"z\"-parameters. They are so called because they are in units of impedance and relate port currents to a port voltage. The z-parameters are not the only way that transfer matrices are defined for two-port networks. There are six basic matrices that relate voltages and currents each with advantages for particular system network topologies. However, only two of these can be extended beyond two ports to an arbitrary number of ports. These two are the \"z\"-parameters and their inverse, the admittance parameters or \"y\"-parameters.\n\nTo understand the relationship between port voltages and currents and inputs and outputs, consider the simple voltage divider circuit. If we only wish to consider the output voltage () resulting from applying the input voltage () then the transfer function can be expressed as,\n\nwhich can be considered the trivial case of a 1×1 transfer matrix. The expression correctly predicts the output voltage if there is no current leaving port 2, but is increasingly inaccurate as the load increases. If, however, we attempt to use the circuit in reverse, driving it with a voltage at port 2 and calculate the resulting voltage at port 1 the expression gives completely the wrong result even with no load on port 1. It predicts a greater voltage at port 1 than was applied at port 2, an impossibility with a purely resistive circuit like this one. To correctly predict the behaviour of the circuit, the currents entering or leaving the ports must also be taken into account, which is what the transfer matrix does. The impedance matrix for the voltage divider circuit is,\n\nwhich fully describes its behaviour under all input and output conditions.\n\nAt microwave frequencies, none of the transfer matrices based on port voltages and currents are convenient to use in practice. Voltage is difficult to measure directly, current next to impossible, and the open circuits and short circuits required by the measurement technique cannot be achieved with any accuracy. For waveguide implementations, circuit voltage and current are entirely meaningless. Transfer matrices using different sorts of variables are used instead. These are the powers transmitted into, and reflected from a port which are readily measured in the transmission line technology used in distributed-element circuits in the microwave band. The most well known and widely used of these sorts of parameters is the scattering parameters, or s-parameters.\n\nThe concept of impedance can be extended into the mechanical, and other domains through a mechanical-electrical analogy, hence the impedance parameters, and other forms of 2-port network parameters, can be extended to the mechanical domain also. To do this an effort variable and a flow variable are made analogues of voltage and current respectively. For mechanical systems under translation these variables are force and velocity respectively.\n\nExpressing the behaviour of a mechanical component as a two-port or multi-port with a transfer matrix is a useful thing to do because, like electrical circuits, the component can often be operated in reverse and its behaviour is dependent on the loads at the inputs and outputs. For instance, a gear train is often characterised simply by its gear ratio, a SISO transfer function. However, the gearbox output shaft can be driven round to turn the input shaft requiring a MIMO analysis. In this example the effort and flow variables are torque and angular velocity respectively. The transfer matrix in terms of z-parameters will look like,\n\nHowever, the z-parameters are not necessarily the most convenient for characterising gear trains. A gear train is the analogue of an electrical transformer and the h-parameters (\"hybrid\" parameters) better describe transformers because they directly include the turns ratios (the analogue of gear ratios). The gearbox transfer matrix in h-parameter format is,\n\nFor an ideal gear train with no losses (friction, distortion etc), this simplifies to,\n\nwhere is the gear ratio.\n\nIn a system that consists of multiple energy domains, transfer matrices are required that can handle components with ports in different domains. In robotics and mechatronics, actuators are required. These usually consist of a transducer converting, for instance, signals from the control system in the electrical domain into motion in the mechanical domain. The control system also requires sensors that detect the motion and convert it back into the electrical domain through another transducer so that the motion can be properly controlled through a feedback loop. Other sensors in the system may be transducers converting yet other energy domains into electrical signals, such as optical, audio, thermal, fluid flow and chemical. Another application is the field of mechanical filters which require transducers between the electrical and mechanical domains in both directions.\n\nA simple example is an electromagnetic electromechanical actuator driven by an electronic controller. This requires a transducer with an input port in the electrical domain and an output port in the mechanical domain. This might be represented simplistically by a SISO transfer function, but for similar reasons to those already stated, a more accurate representation is achieved with a two-input, two-output MIMO transfer matrix. In the z-parameters, this takes the form,\n\nwhere is the force applied to the actuator and is the resulting velocity of the actuator. The impedance parameters here are a mixture of units; is an electrical impedance, is a mechanical impedance and the other two are transimpedances in a hybrid mix of units.\n\nAcoustic systems are a subset of fluid dynamics, and in both fields the primary input and output variables are pressure, , and volumetric flow rate, , except in the case of sound travelling through solid components. In the latter case, the primary variables of mechanics, force and velocity, are more appropriate. An example of a two-port acoustic component is a filter such as a muffler on an exhaust system. A transfer matrix representation of it may look like,\n\nHere, the are the transmission parameters, also known as ABCD-parameters. The component can be just as easily described by the z-parameters, but transmission parameters have a mathematical advantage when dealing with a system of two-ports that are connected in a cascade of the output of one into the input port of another. In such cases the overall transmission parameters are found simply by the matrix multiplication of the transmission parameter matrices of the constituent components.\n\nWhen working with mixed variables from different energy domains consideration needs to be given on which variables to consider analogous. The choice depends on what the analysis is intended to achieve. If it is desired to correctly model energy flows throughout the entire system then a pair of variables whose product is power (power conjugate variables) in one energy domain must map to power conjugate variables in other domains. Power conjugate variables are not unique so care needs to be taken to use the same mapping of variables throughout the system.\n\nA common mapping (used in some of the examples in this article) maps the effort variables (ones that initiate an action) from each domain together and maps the flow variables (ones that are a property of an action) from each domain together. Each pair of effort and flow variables is power conjugate. This system is known as the impedance analogy because a ratio of the effort to the flow variable in each domain is analogous to electrical impedance.\n\nThere are two other power conjugate systems on the same variables that are in use. The mobility analogy maps mechanical force to electric current instead of voltage. This analogy is widely used by mechanical filter designers and frequently in audio electronics also. The mapping has the advantage of preserving network topologies across domains but does not maintain the mapping of impedances. The Trent analogy classes the power conjugate variables as either \"across\" variables, or \"through\" variables depending on whether they act across an element of a system or through it. This largely ends up the same as the mobility analogy except in the case of the fluid flow domain (including the acoustics domain). Here pressure is made analogous to voltage (as in the impedance analogy) instead of current (as in the mobility analogy). However, force in the mechanical domain \"is\" analogous to current because force acts \"through\" an object.\n\nThere are some commonly used analogies that do not use power conjugate pairs. For sensors, correctly modelling energy flows may not be so important. Sensors often extract only tiny amounts of energy into the system. Choosing variables that are convenient to measure, particularly ones that the sensor is sensing, may be more useful. For instance, in the thermal resistance analogy, thernal resistance is considered analogous to electrical resistance, resulting in temperature difference and thermal power mapping to voltage and current respectively. The power conjugate of temperature difference is not thermal power, but rather entropy flow rate, something that cannot be directly measured. Another analogy of the same sort occurs in the magnetic domain. This maps magnetic reluctance to electrical resistance, resulting in magnetic flux mapping to current instead of magnetic flux rate of change as required for compatible variables.\n\nThe matrix representation of linear algebraic equations has been known for some time. Poincaré in 1907 was the first to describe a transducer as a pair of such equations relating electrical variables (voltage and current) to mechanical variables (force and velocity). Wegel, in 1921, was the first to express these equations in terms of mechanical impedance as well as electrical impedance.\n\nThe first use of transfer matrices to represent a MIMO control system was by Boksenbom and Hood in 1950, but only for the particular case of the gas turbine engines they were studying for the National Advisory Committee for Aeronautics. Cruickshank provided a firmer basis in 1955 but without complete generality. Kavanagh in 1956 gave the first completely general treatment, establishing the matrix relationship between system and control and providing criteria for realisability of a control system that could deliver a prescribed behaviour of the system under control.\n\n\n"}
{"id": "20024409", "url": "https://en.wikipedia.org/wiki?curid=20024409", "title": "Transiting Exoplanet Survey Satellite", "text": "Transiting Exoplanet Survey Satellite\n\nThe Transiting Exoplanet Survey Satellite (TESS) is a space telescope for NASA's Explorers program, designed to search for exoplanets using the transit method in an area 400 times larger than that covered by the \"Kepler\" mission. It was launched on April 18, 2018 atop a Falcon 9 rocket. During its 2-year primary mission, it is expected to find more than 20,000 exoplanets, compared to about 3,800 exoplanets known when it launched. The first light image from TESS was taken on August 7, 2018, and released publicly on September 17, 2018.\n\nThe primary mission objective for TESS is to survey the brightest stars near the Earth for transiting exoplanets over a two-year period. The TESS satellite uses an array of wide-field cameras to perform a survey of 85% of the sky. With TESS, it is possible to study the mass, size, density and orbit of a large cohort of small planets, including a sample of rocky planets in the habitable zones of their host stars. TESS will provide prime targets for further characterization by the James Webb Space Telescope, as well as other large ground-based and space-based telescopes of the future. While previous sky surveys with ground-based telescopes have mainly detected giant exoplanets, TESS will find a large number of small planets around the nearest stars in the sky. TESS records the nearest and brightest main sequence stars hosting transiting exoplanets, which are the most favorable targets for detailed investigations.\n\nTESS uses a novel highly-elliptical orbit around the Earth with an apogee approximately at the distance of the Moon and a perigee of 108,000 km. TESS orbits Earth twice during the time the Moon orbits once, a 2:1 resonance with the Moon. The orbit is expected to remain stable for a minimum of 10 years.\n\nLed by the Massachusetts Institute of Technology with seed funding from Google, on April 5, 2013, it was announced that TESS, along with the Neutron Star Interior Composition Explorer (NICER), had been selected by NASA for launch.\n\nThe genesis of TESS was as early as 2006, when a design was developed from private funding by individuals, Google, and The Kavli Foundation. In 2008, MIT proposed that TESS become a full NASA mission and submitted it for the Small Explorer program at Goddard Space Flight Center, but it was not selected. It was resubmitted in 2010 as an Explorers program mission, and was approved in 2013 as a Medium Explorer mission. TESS passed its critical design review (CDR) in 2015, allowing production of the satellite to begin. While Kepler had cost US$640 million at launch, TESS cost only US$200 million (plus US$87 million for launch).\n\nTESS is designed to carry out the first spaceborne all-sky transiting exoplanet survey. It is equipped with four wide-angle telescopes and associated charge-coupled device (CCD) detectors. Science data will be transmitted to Earth every two weeks. Full-frame images with an effective exposure time of two hours will be transmitted as well, enabling scientists to search for unexpected, transient phenomena, such as the optical counterparts to gamma-ray bursts. TESS will also utilize a Guest Investigator program, allowing scientists from other organizations to use TESS for their own research. This will allow an additional 20,000 celestial bodies to be observed.\n\nIn order to obtain unobstructed imagery of both the northern and southern hemispheres of the sky, TESS will utilize a 2:1 lunar resonant orbit called P/2, an orbit that has never been used before (although IBEX uses a similar P/3 orbit). The highly elliptical orbit has a apogee, timed to be positioned approximately 90° away from the position of the Moon to minimize its destabilizing effect. This orbit should remain stable for decades and will keep TESS's cameras in a stable temperature range. The orbit is entirely outside the Van Allen belts to avoid radiation damage to TESS, and most of the orbit is spent far outside the belts. Every 13.7 days at its perigee of , TESS will downlink the data it has collected during the orbit to Earth over a period of approximately 3 hours.\n\nTESS's two-year all-sky survey will focus on nearby G-, K-, and M-type stars with apparent magnitudes brighter than magnitude 12. Approximately 500,000 stars will be studied, including the 1,000 closest red dwarfs across the whole sky, an area 400 times larger than that covered by the \"Kepler\" mission. TESS is expected to discover more than 20,000 transiting exoplanets, including 500 to 1000 Earth-sized planets and super-Earths. Of those discoveries, an estimated 20 could be super-Earths located in the habitable zone around a star. Most exoplanets are expected to be between 30 and 300 light-years away.\n\nThe survey is broken up into 26 observation sectors, each sector being , with an overlap of sectors at the ecliptic poles to allow additional sensitivity toward smaller and longer-period exoplanets in that region of the celestial sphere. The spacecraft will spend two 13.7-day orbits observing each sector, mapping the southern hemisphere of sky in its first year of operation and the northern hemisphere in its second year. The cameras actually take images every 2 seconds, but all the raw images would represent much more data volume than can be stored or downlinked. To deal with this, cutouts around 15,000 selected stars (per orbit) will be coadded over a 2-minute period and saved on board for downlink, while full-frame images will also be coadded over a 30-minute period and saved for downlink. The actual data downlinks will occur every 13.7 days near perigee. This means that during the 2 years, TESS will continuously survey 85% of the sky for 27 days, with certain parts being surveyed across multiple runs. The survey methodology was designed such that the area that will be surveyed, essentially continuously, over an entire year (351 observation days) and makes up about 5% of the entire sky, will encompass the regions of sky (near the ecliptic poles) which will be observable at any time of year with the JWST.\n\nThe TESS team also plans to use a 30-minute observation cadence for full-frame images, which has been noted for imposing a hard Nyquist limit that can be problematic for asteroseismology of stars. Asteroseismology is the science that studies the internal structure of stars by the interpretation of their frequency spectra. Different oscillation modes penetrate to different depths inside the star. The \"Kepler\" and \"PLATO\" observatories are also intended for asteroseismology.\n\nIn December 2014, SpaceX was awarded the contract to launch TESS in August 2017, for a total contract value of . The 362 kg spacecraft was originally scheduled to launch on March 20, 2018, but this was pushed back by SpaceX to allow additional time to prepare the launch vehicle and meet NASA launch service requirements. A static fire of the Falcon 9 rocket was completed on April 11, 2018, at approximately 18:30 UTC. The launch was postponed again from April 16, 2018, and TESS was eventually launched on a SpaceX Falcon 9 rocket from the SLC-40 launch site at Cape Canaveral Air Force Station on April 18.\n\nThe Falcon 9 launch sequence included a 149-second burn by the first stage, followed by a 6-minute second stage burn. Meanwhile, the B1045 first-stage Block 4 booster performed controlled-reentry maneuvers and successfully landed on the autonomous drone ship \"Of Course I Still Love You\". After coasting for 35 minutes, the second stage performed a final 54-second burn that placed the TESS spacecraft into a supersynchronous transfer orbit of 200 by 270,000 km at an inclination of 28.5 degrees. The second stage released the payload, after which the stage itself was placed in a heliocentric orbit. An experimental water landing was performed for the fairing, as part of SpaceX's attempt to develop fairing reusability.\n\nIn 2013, Orbital Sciences received a four-year, contract to build TESS for NASA. TESS uses an Orbital Sciences LEOStar-2 satellite bus, capable of three-axis stabilization using four hydrazine thrusters plus four reaction wheels providing better than three arc-second fine spacecraft pointing control. Power is provided by two single-axis solar arrays generating 400 watts. A K-band dish antenna provides a 100 Mbit/s science downlink.\n\nOnce injected into the initial orbit by the Falcon 9 second stage, the spacecraft performed four additional independent burns that placed it into a lunar flyby orbit. On May 17, the spacecraft underwent a gravity assist by the Moon at above the surface, and performed the final period adjustment burn on May 30. It achieved an orbital period of 13.65 days in the desired 2:1 resonance with the Moon, at 90 degrees phase offset to the Moon at apogee, which is expected to be a stable orbit for at least 20 years, thus requiring very little fuel to maintain. The entire maneuvering phase was expected to take a total of two months, and bring the craft in an eccentric orbit () at a 37° inclination. The total delta-v budget for orbit maneuvers was , which is 80% of the mission’s total available reserves. If TESS receives an on-target or slightly above nominal orbit insertion by the Falcon 9, a theoretical mission duration in excess of 15 years would be possible from a consumables standpoint.\n\nAround 60 days after launch, TESS was expected to begin its primary science mission. The first light image was made on August 7, 2018, and released publicly on September 17, 2018. \n\nTESS actually completed its commissioning phase at the end of July and the science phase officially started on July 25.\n\nFor the first two years of operation TESS will monitor both the southern (year 1) and northern (year 2) celestial hemispheres. During its mission TESS will tile the sky in 26 separate segments, with a 27.4-day observing period per segment (a bit over one sidereal month).\n\nThe sole instrument on TESS is a package of four wide-field-of-view CCD cameras. Each camera features four low-noise, low-power 4 megapixel CCDs created by MIT Lincoln Laboratory. The four CCDs are arranged in a 2x2 detector array for a total of 16 megapixels per camera and 16 CCDs for the entire instrument. Each camera has a field of view, a effective pupil diameter, a lens assembly with seven optical elements, and a bandpass range of . The TESS lenses have a combined field of view of (2,300 deg, around 5% of the entire sky) and a focal ratio of . The ensquared energy, the fraction of the total energy of the point-spread function that is within a square of the given dimensions centered on the peak, is 50% within and 90% within . For comparison, Kepler's primary mission only covered an area of the sky measuring 105 deg, though the K2 extension has covered many such areas for shorter times.\n\nThe TESS ground system is divided between eight sites around the United States. These include NASA's Space Network and the Jet Propulsion Laboratory's Deep Space Network for command and telemetry, Orbital ATK Mission Operations Center, MIT Payload Operations Center, the Ames Research Center Science Processing Operations Center, The Goddard Space Flight Center Flight Dynamics Facility, the Smithsonian Astrophysical Observatory TESS Science Office, and the Mikulski Archive for Space Telescopes (MAST).\n\nOne of the issues facing the development of this type of instrument is having an ultra-stable light source to test on. In 2015, a group at the University of Geneva made a breakthrough in the development of a stable light source. While this instrument was created to support ESA's CHEOPS exoplanet observatory, one was also ordered by the TESS program. Although both plan to look at bright nearby stars using the transit method, CHEOPS is focused on collecting more data on known exoplanets, including those found by TESS and other survey missions.\n\nTESS started science operations on July 25, 2018. The first announced finding from the mission was the observation of comet C/2018 N1. The first exoplanet detection announcement was on September 18, announcing the discovery of a super-Earth in the Pi Mensae system orbiting the star every 6 days, adding to a known super-Jupiter orbiting the same star every 5.9 years.\n\nOn September 20, 2018, the discovery of an ultra-short period planet was announced, slightly larger than Earth, orbiting the red dwarf LHS 3844. With an orbital period of 11 hours, LHS 3844 b is one of the planets with the shortest known period. It orbits its star at a distance of . LHS 3844 b is also one of the closest known exoplanets to Earth, at a distance of 14.9 parsec.\n\nTESS's third discovered exoplanet is HD 202772Ab, a hot Jupiter orbiting the brighter component of the visual binary star HD 202772, located in the constellation Capricornus at a distance of about 480 light-years from Earth. The discovery was announced on October 5, 2018. HD 202772Ab orbits its host star once every 3.3 days. It is an inflated hot Jupiter, and a rare example of hot Jupiters around evolved stars. It is also one of the most strongly irradiated planets known, with an equilibrium temperature of .\n\nData on exoplanet candidates continue to be made available at MAST. As of 12 October 2018, the total number of candidates was up to 54. This list included the three exoplanets already reported. Forty-four of the candidates were from Sector 1 with additional candidates from Sector 2. Two systems with two exoplanets and one with three exoplanets were on the list of candidates. The list of candidate exoplanets continues to grow as additional results are being published on the same MAST page. \n\n\n\n\n"}
{"id": "55198924", "url": "https://en.wikipedia.org/wiki?curid=55198924", "title": "Utrecht Atlas", "text": "Utrecht Atlas\n\nThe Utrecht Atlas of the solar spectrum is a detailed inventory in graphical form of spectral lines observed in sunlight at the Sonnenborgh Observatory. The visible spectrum is about 390 to 700 nm and the atlas covers from 361.2 to 877.1 nm (plus an appendix) so that the atlas has some coverage of the infrared and ultraviolet spectrum of sunlight. The atlas, compiled by Minnaert and his students Mulders and Houtgast, was published in 1940 shortly before the WWII invasion of the Netherlands.\n\nIn the early nineteenth century, Joseph von Fraunhofer made the first systematic inventory of spectral lines in sunlight. Full understanding of the significance of Fraunhofer lines required a huge amount of pioneering research in astrophysics and quantum theory. Cecilia Payne (1925) demonstrated that variations in stellar line strengths can be explained by the Saha ionization equation. Payne's work lead to a major study of the chemical abundances in the solar atmosphere undertaken by H. N. Russell, Walter S. Adams, and Charlotte Moore. Around 1930, the procedures developed by Russell, Adams, and Moore were adapted by Minnaert and Mulders for determining chemical abundances in stellar photospheres. Houtgast invented a modification of Moll's microphotometer that Minnaert, Mulders, and Houtgast employed to make direct registrations of the solar line intensities.\n\nAccording to Minnaert at a seminar on the occasion of his 70th birthday:\n"}
{"id": "732456", "url": "https://en.wikipedia.org/wiki?curid=732456", "title": "Veikko Aleksanteri Heiskanen", "text": "Veikko Aleksanteri Heiskanen\n\nVeikko Aleksanteri Heiskanen (23 July 1895, in Kangaslampi – 23 October 1971, in Helsinki) was a famous Finnish geodesist.\n\nHe is mostly known for his refinement of the theory of isostasy by George Airy and for his studies of the global geoid.\n\n\n"}
{"id": "31574662", "url": "https://en.wikipedia.org/wiki?curid=31574662", "title": "Victor Sterki", "text": "Victor Sterki\n\nVictor Sterki (1846 in Solothurn, Switzerland - 1933) was a malacologist from Switzerland who lived in the United States.\n\nHe worked as an assistant in the Section of Invertebrates in the Carnegie Museum of Natural History from 1909 to 1933.\n\nMalacological collections by Sterki of Pupillidae has 4000 lots and of Sphaeriidae has 12,000 lots. Both collections are deposited in the Carnegie Museum of Natural History.\n\nThe malacological journal Sterkiana and the land snail species \"Guppya sterkii\" were named after him.\n"}
{"id": "27002487", "url": "https://en.wikipedia.org/wiki?curid=27002487", "title": "Virginia Livingston", "text": "Virginia Livingston\n\nVirginia Livingston (1906–1990) was an American physician and cancer researcher who advocated the unsupported theory that a specific species of bacteria she named \"Progenitor cryptocides\" was the primary cause of cancer in humans. Her theories about \"P. cryptocides\" have not been duplicated by researchers, and a clinical trial of her therapy did not show any efficacy in the treatment of cancer. The American Cancer Society, which did not support Livingston’s treatment protocol for cancer, categorically denied her theory of cancer origins.\n\nVirginia Livingston was born Virginia Wuerthele in Meadville, Pennsylvania in 1906.\n\nBoth her father and grandfather were physicians and she also pursued a degree in medicine. Prior to attending medical school, Livingston earned three BA degrees in English, history, and economics from Vassar College. She then attended New York University, Bellevue Medical College and in 1936, received her degree in medicine. She was one of four women in her graduating class.\n\nShortly after graduation, Livingston became the first female resident physician at a New York hospital where she was assigned to treat prostitutes infected with venereal diseases. While there, Livingston became interested in the study of tuberculosis and leprosy, and later scleroderma, a disease affecting the tissues and skin. After studying scleroderma tissues with the darkfield microscope, she claimed to find an acid-fast organism that consistently appeared in her slides. Thinking that scleroderma had some characteristics that were like cancer, Livingston then began studying malignant tissues and subsequently claimed to find evidence of acid-fast organisms in every sample. It was this early research that prompted the young physician to devote her career to the study of a specific microorganism involved in cancer.\n\nIn 1946, Livingston published a paper in which she stated she had established that a bacterium was a causative agent in scleroderma. In 1947, she cultured a mycobacteria-like organism in human cancer and, according to her peer-reviewed paper, fulfilled Koch's postulates establishing an apparent cause and effect. In 1949, Livingston was named chief of the Rutgers-Presbyterian Hospital Laboratory for Proliferative Diseases in New Jersey where she continued her cancer research. It was during this time that Livingston formed a lifetime association with Dr. Eleanor Alexander-Jackson of Cornell University. Jackson's specialty was the study of mycobacteria and particularly, the species responsible for tuberculosis. Jackson had developed specific culture media for growing the microbe and a technique for observing it known as the \"triple stain\" because she felt this microbe wasn't amenable to conventional modes of culturing and microscopy.\n\nLivingston and Jackson also collaborated on work on the Rous sarcoma virus (RSV) at Lederle Laboratories. Livingston claimed that when RSV cultures were passed through special filters designed to hold back all but the smallest virus particles, she was able to grow bacteria; this was considered a controversial claim since bacteria are considerably larger than viruses and are not supposed to exist in filtered RSV serum. After healthy animals were exposed to the Rous bacterial filtrates, Livingston and Jackson claimed that cancerous lesions developed. This finding led to speculation that such bacteria could be transmitted from poultry to humans and this became a primary reason Livingston ordered her cancer patients to not eat poultry while they underwent her treatment. Scientists have since rejected Livingston's findings, arguing there is no evidence supporting her claim.\n\nIn 1956, Livingston published a paper suggesting a causative bacterium in Wilson's disease. In 1965, she reported isolation of a variably acid-fast mycobacterium in patients with myocardial vascular disease. During this time, she also began a small test trial of anti-bacterial vaccines made from the body fluids of cancer patients and reported moderate success. Between the years 1965-1968, Livingston received Fleet Foundation and Kerr Grants, and continued her investigation into a bacterial cause of human cancer. She also published a paper describing the presence of a substance identified as Actinomycin-D which she said could damage chromosomes and promote cancer.\nIn 1969, Livingston and her husband Afton Munk Livingston, established the Livingston-Wheeler Clinic in San Diego, California, and began formally treating cancer patients. The therapeutic program included autogenous vaccine made from killed bacteria derived from body fluids; a low sodium diet consisting of organic foods, fruits and vegetables high in a substance Livingston called \"abscisic acid\"; immune enhancing vaccines (gamma globulin, BCG) and antibiotics. Livingston prescribed antibiotics after cross testing them with patients' cultures to see which had the most antibacterial activity. Livingston also recommended that patients not consume poultry products based on her earlier research.\n\nAfter her husband’s death, she married Owen Webster Wheeler, one of the first patients she claims to have successfully treated for head and neck cancer. Shortly after, the clinic was renamed the Livingston-Wheeler clinic. In 1970, Livingston officially named her cancer organism \"Progenitor cryptocides\", and presented her findings to the New York Academy of Sciences. According to her biography, \"Progenitor\" was a pseudonym meaning \"ancestral\" and the name was chosen because Livingston believed the microbe existed as early as the Precambrian era, and it was an endegenous component of life itself. The name \"cryptocides\" was a Greek and Latin word which meant \"hidden killer\". The microbe was classified under the order Actinomycetales. Livingston described \"Progenitor\" as an intermittently acid-fast mycobacterium that displayed highly variable growth cycles. According to Livingston the microbe was pleomorphic, and had cell wall-deficient and filter-passing forms resembling viruses, with the ability to adopt a variety of shapes including spindles, rods and cocci.\n\nIn 1974, Livingston published a paper which described her isolation of human chorionic gonadotropin (hCG) from cancer bacteria. She then advanced one of her central hypotheses.\n\nLivingston theorized that hCG is both a component of human cancer, but also innately involved in embryonic growth and fetal survival. She wrote that hCG is saturated in the placenta, and blocks the mothers’ antibodies from attacking the fetus, partly made of foreign DNA (and not recognized by host immunity). By the same token, hCG performs a similar function in cancer, conferring protection to malignant tissues. Livingston believed that after Progenitor hybridizes with cancer cells, it imparts an ability for them to produce hCG in a manner similar to that of the developing fetus. Based on this duality of function, Livingston called hCG “the hormone of life and the hormone of death”. She also stipulated that vaccines which target hCG-producing bacteria could also halt the progression of cancer. And she claimed that absicins could also neutralize hCG.\n\nThough some bacteria have been associated with cancer (for instance \"H. pylori\" has been associated with stomach cancer) Livingston's postulated relationship between cancer and \"P. cryptocides\" was never proven in several follow up studies conducted by independent investigators. Researchers confirmed that bacteria provided by Livingston produced hCG, but several other studies demonstrated that numerous bacteria in both cancer patients and healthy individuals also produced the substance.\n\nOccurring before the existence of techniques to analyze DNA, Livingston and other investigators' ability to differentiate bacteria based on morphology and chemical characteristics was limited. However, even given technological limitations at the time, Livingston's classification methods were described as full of \"remarkable errors\", attributing characteristics to Actinomycetales (the order Livingston believed \"P. cryptocides\" belonged to) shared by no other members of the order. Some evidence supports \"P. cryptocides\" is the result of a mistaken identification of a \"Staphylococcus\" strain of bacteria and later studies of the samples provided by Livingston proved to be \"Staphylococcus epidermidis\" and \"Streptococcus faecalis\".\n\nThe American Cancer Society (ACS) did not support Livingston’s treatment protocol for cancer, and has categorically denied her theory of the cancer bacterium \"P. cryptocides\" the primary cause of human cancer. The ACS also challenged the efficacy of Livingston’s autogenous vaccine and concluded in its report that there was no corroboration of either \"P. cryptocides\" or the efficacy of her autologous vaccine. Since Livingston hadn’t stocked earlier cultures of her alleged microbe, it is not possible to decipher precisely what those cultures contained.\n\nA case-control study using self-selected, matched but not randomized groups with late stage cancer compared survival and quality of life between cancer patients receiving conventional treatment and those undergoing the Livingston-Wheeler therapy. The results were reported in \"The New England Journal of Medicine\" in 1991, and found no differences in survival among patients whether treated conventionally, or via Livingston's treatment. The \"NEJM\" report also stated that when comparing the two groups, the \"quality of life were consistently better among conventionally treated patients from enrollment on\". Based on this trial, the ACS deemed Livingston's cancer therapy without efficacy, and considered it an \"unproven therapy\".\n\nWhile both groups of patients in the trial deteriorated at equal rates---all in effect dying of their disease---patients in the Livingston-treated group were reported to have had a \"poorer quality of life\" at the start of the trial. The study's lead investigator, Barrie Cassileth, acknowledged that \"the University of Pennsylvania patients had a significantly better quality of life at all times, including enrollment\" and that, quality of life \"was different at base line\", with Livingston's patients rated worse. Patients in both treatment arms also received conventional therapies in addition to Livingston's therapy. Livingston's patients also received BCG during the trial---an FDA-approved cancer adjuvant which has been found effective for several cancers, including those of the bladder and colon.\n\nAt the study's conclusion, Barrie Cassileth commented:\n\n\"This study...involved only patients with diagnoses and stages of disease for which there is no effective conventional treatment. Therefore, the results cannot be generalized to patients with less advanced stages of disease or to other treatment regimens.\" Cassileth also said, her study group \"hypothesized that survival time would not differ between the two groups on the basis of the assumption that the unproved remedy would be no more effective with end-stage disease than conventional care, itself largely ineffective\".\n\nShortly after speaking before an Office of Technology Assessment (OTA) hearing on alternative cancer therapies and attending her 60th reunion at Vassar College in 1990, Livingston accompanied her daughter Julie Anne Wagner on a European trip. She developed chest pains while visiting the Greek islands and then succumbed to heart failure in Athens on June 30, before being transported to a Paris Hospital.\n\n"}
{"id": "2982572", "url": "https://en.wikipedia.org/wiki?curid=2982572", "title": "Wild West Tech", "text": "Wild West Tech\n\nWild West Tech is a program that aired on The History Channel in the United States from 2003 to 2005. The show was originally hosted by Keith Carradine (2003–04), but his half-brother, David Carradine, took over hosting duties for season 2 and subsequent seasons. The show illustrates a variety of technologies used in the Wild West, and features interviews with numerous Western historians, as well as re-creating versions of important events in Western history.\n\nThe series was created by Dolores Gavin (History Channel) and supervising producer Louis Tarantino.\n\nEach episode is dedicated to some broader aspect of Wild West life. Once the context is established in brief by the host, more specific elements are developed. Throughout the program, professors, writers, and other experts explain finer points while historical reenactments and dramatizations portray just how key 19th century events may have transpired. The production aims to put the viewer into the spirit of the Old West with its host inhabiting an unnamed frontier town, delivering commentary.\n\nA new spin on the typical technology fact program, this program often covers subjects from the American Old West that are not generally discussed in more traditional settings. For example, one episode takes a look at the brothel, focusing on the inventions and technological innovations used to make the institution of prostitution less harsh on the lives of the women involved.\n\nAnother explains that Morphine was first isolated in 1803 by the German pharmacist Friedrich Wilhelm Adam Sertürner, but it was not until the development of the hypodermic needle (1853) that its use spread and it spread quite a bit in the American West. It was used for pain relief and as a \"cure\" for opium or alcohol addiction. Its extensive use during the American Civil War resulted in over 400,000 sufferers from the \"soldiers disease\" (addiction).\n\nThe same episode informs the viewers that heroin, along with other drugs, was only criminalized in the United States by the Harrison Narcotics Tax Act of 1914 decades after it was derived.\n\nOther topics include the technological histories of various alcoholic beverages, saloons, weapons, and cowboy gangs.\n\nTwo pilot episodes were produced, hosted by Keith Carradine, to help sell the History Channel on the concept of the series. Seasons 2 and 3 were hosted by David Carradine.\n\nThe History Channel sometimes airs re-edited versions of the episodes to fill odd bits of time on the schedule; these 30 minute versions feature no new content.\n\nThere is a video that documents how Keith lost the show to David in a poker game that appears at the beginning of episode 2–1.\n\nShortly before leaving the show, Keith Carradine grew a mustache for his role in the TNT production of \"Monte Walsh\".\n\n"}
