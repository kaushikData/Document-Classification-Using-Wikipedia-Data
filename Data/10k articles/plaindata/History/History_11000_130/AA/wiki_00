{"id": "11471074", "url": "https://en.wikipedia.org/wiki?curid=11471074", "title": "1978 in radio", "text": "1978 in radio\n\nThe year 1978 saw a number of significant events in radio broadcasting.\n\n\n\n\n"}
{"id": "51415059", "url": "https://en.wikipedia.org/wiki?curid=51415059", "title": "A. B. C. Sibthorpe", "text": "A. B. C. Sibthorpe\n\nAaron Belisarius Cosmo Sibthorpe (183?–1916) was a nineteenth century African historian. He published both \"History and Geography of Sierra Leone\" in 1868.\n\nSibthorpe was born somewhere near Benin, and after being captured and enslaved, he became a Liberated African in colonial Sierra Leone while still a youth. He remained in Sierra Leone all his life. He became a school teacher, teaching in villages around Freetown.\n\nHe became a prominent member of the Krio community. However, by the time of his death he had been forgotten.\n"}
{"id": "38355014", "url": "https://en.wikipedia.org/wiki?curid=38355014", "title": "Ahmad Amin", "text": "Ahmad Amin\n\nAhmad Amin (1886–1954) was an Egyptian historian and writer. He wrote a series of books on the history of the Islamic civilization (1928–1953), a famous autobiography (\"My Life\", 1950), as well as an important dictionary of Egyptian folklore (1953).\n\nAfter receiving a traditional religious education the University of Al-Azhar, he worked as qadi until 1926. He then taught Arabic literature at Cairo University, where he was appointed Dean of the Faculty of Arts, until 1946. Ahmad Amin was one of the most brilliant intellectuals of his time: he was editor of the literary journals \"al-Risalah\" (1933) and \"al-Thakafa\" (1939), founder of \"Ladjnat al-ta'lif wa l-tardjama wa-l-nashr\" (\"Literary Committee of Translation and Publication\"). He worked as head of the culture department at the Egyptian Ministry of Education before leading the cultural division of the Arab League. He is most famous for his long history of Islamic culture, in three volumes (\"Fajr al-islam\", 1928 ; \"Duha l-islam\", 1933–1936 ; \"Zuhr al-islam\", 1945–1953) which is the first attempt of its kind in the modern history of the Muslim world. He also left an autobiography (Hayati, 1950) while his main articles were published under the title \"Fayd al-khatir\".\n\nAmin lectured on Egyptian literary history between the years of 1939 and 1946. It was during this time that Amin stated his initial belief that Egyptians had not contributed to Arabic poetry during the Middle Ages the way other Arab populations had. Amin's student Shawqi Daif claimed that the dearth of properly published Egyptian works from the period made such a judgement tenuous, and suggested that he and Amin republish the Egyptian sections in anthologies of poetry from the period. Amin agreed to write the introduction while Daif wrote the preface, while fellow scholar Ihsan Abbas assisted the team with editing the folios for printing from 1951 until 1952.\n\n\n"}
{"id": "20908272", "url": "https://en.wikipedia.org/wiki?curid=20908272", "title": "Alberto Melloni", "text": "Alberto Melloni\n\nAlberto Melloni (Reggio nell'Emilia, 6 January 1959) is an Italian church historian, primarily known for his work on the Second Vatican Council.\n\nHe studied in Bologna, at Cornell and in Fribourg (Switzerland) and he has taught at the University of Bologna and Roma Tre University. He is currently Professor of the History of Christianity at the University of Modena-Reggio Emilia. Holder of the Unesco Chair on religious pluralism and peace, he is Director of the \"Fondazione per le scienze religiose “Giovanni XXIII”\" in Bologna.\n\nHe is principal investigator for the European Infraia Rei_Res project headed by the Fondazione, and coordinator of the Resilience research infrastructure project. He spearheaded the establishment of the European Academy of Religion. A research platform which includes institutions, associations, academies, publishers, reviews concerned with the study of religion throughout Europe, the Mediterrean, Middle East, the Balcans, Caucasus and Russia.\n\nHe worked on the \"History of the Second Vatican Council\" directed by Giuseppe Alberigo, and directed the \"Edizione nazionale dei diari di A.G. Roncalli\" (Istituto per le scienze religiose, Bologna 2003-2008), the \"Dizionario del sapere storico religioso del 900\" (Il Mulino, Bologna 2010) and \"Cristiani d'Italia. Chiese, stato, società 1861-2011\" (Treccani, Rome 2011).\n\nHe is chief editor for the project \"Conciliorum oecumenicorum generaliumqe decreta\" in Brepols's Corpus Christianorum and for the Mansi 3, a digital edition of all the church councils held in the course of history. He is responsible for the European research network on Pope Pius XI, and director of the \"Enciclopedia costantiniana\" for Treccani. He edited \"Benedetto XV. Papa Giacomo della Chiesa nel mondo dell'inutile strage\", 2 voll. (il Mulino, Bologna 2017) and \"Lutero. Un cristiano fra riforme e modernità\" 2 voll. (il Mulino, Bologna 2017), also published in English and German by De Gruyter, 2017.\n\nHe has published works on medieval canon law, the church and the state in the twentieth century, on the Conclave. His most recent publications are: \"Papa Giovanni. Un cristiano e il suo concilio\" (Einaudi, Torino 2009), \"Pacem in terris. Storia dell'ultima enciclica di papa Giovanni\" (Laterza, Roma-Bari 2010), \"Le cinque perle di Giovanni Paolo II\" (Mondadori, Milano 2011).\n\nHe is an associate of the Accademia dei Lincei, honorary member of the Accademia Rubiconia, alderman for the Académie internationale des sciences religieuses, member of the scientific committee of the Enciclopedia Italiana, member of the trustees board for the celebrations of the 150th anniversary of Italy's unification, board member of Refo500, board member for the Dizionario biografico degli italiani, member of the international board for reviews such as the \"Revue d'histoire ecclésiastique\" in Leuven, \"Schweizerischen Zeitschrift für Religions- und Kulturgeschichte\" in Fribourg, and \"Studia Historiæ Ecclesiasticæ\" published by the University of South Africa.\n\nHe is working on \"La grande storia\" and special hosts for the national broadcasting History Channel. He has created and currently hosts \"Il sabbatico\" on Rainews24. He is also a columnist for both 'Il Corriere della Sera' and 'La Repubblica'.\n\nProfessor Melloni is a major contributor to the work on the Second Vatican Council led and promoted by the so-called “scuola di Bologna”. Its research mainly focused on the discontinuity hermeneutics, which differs from the official position of the Church according to a few Italian journalists. Pope Benedict XVI in fact states: \"Discontinuity hermeneutics is likely to create an abrupt separation between the pre-conciliar and post-conciliar church\". On the other hand, scholars related to the “scuola di Bologna” highlight the fact that the Pope's opinion does not centre exclusively on continuity. According to Melloni it is impossible to read the Pope's words as a mere post-conciliar repentance.\n\n\n\n\n"}
{"id": "55127908", "url": "https://en.wikipedia.org/wiki?curid=55127908", "title": "American Association for the History of Medicine", "text": "American Association for the History of Medicine\n\nThe American Association for the History of Medicine is an American professional association dedicated to the study of medical history. It is the largest society dedicated to medical history in the United States, and the oldest such organization in North America. It was established in 1925 as the American Section of the International Society for the History of Medicine, and obtained its current name in 1958. Its first president was Fielding Hudson Garrison. Its official journal is the \"Bulletin of the History of Medicine\", which is published quarterly. Its current membership is in excess of 1,000 people.\n"}
{"id": "5062445", "url": "https://en.wikipedia.org/wiki?curid=5062445", "title": "An Agreement of the People", "text": "An Agreement of the People\n\nMajor published versions of the \"Agreement\" include:\n\nSoon after the First English Civil War, the \"Agreement\" was the subject of the Putney Debates in 1647. The major tenets of this first version of the \"Agreement\" were: freedom of religion, the frequent convening of new parliaments and equality for all under the law. These tenets also appeared in the later versions of the manifesto. As these basic proposals were queried, other provisions were added; for example Roman Catholics were exempt from the right to religious freedom, and the electorate was to be made up of adult male property holders. The Levellers hoped to base England's new constitution on the \"Agreement of the People\", but in the end, the New Model Army based their demands on an alternative less revolutionary document, the Heads of Proposals, that was proposed and supported by the \"Grandees\" (senior officers) of the Army.\n\nThe \"Agreement\" is believed to have \"greatly influence[ed] the development of the U.S. Constitution.\"\n\n\n\n"}
{"id": "13916684", "url": "https://en.wikipedia.org/wiki?curid=13916684", "title": "Anita Leocádia Prestes", "text": "Anita Leocádia Prestes\n\nAnita Leocádia Prestes (born 27 November 1936 in Berlin) is a Brazilian historian. She is the daughter of political activists Olga Benário Prestes and Luís Carlos Prestes.\n\nShe was born in the Barnimstraße concentration camp and was handed to the care of her paternal grandmother, Leocádia Prestes, at age 14 months. Her mother Olga was sent to Ravensbrück concentration camp and from there to an experimental extermination camp set up at an old psychiatric hospital in Bernburg Euthanasia Centre in 1942, where she was gassed.\n\nIn 1964, Prestes achieved a degree in Chemistry from the then \"University of Brazil\", now known as the Universidade Federal do Rio de Janeiro (UFRJ). Two years later she gained a Masters in Organic Chemistry.\n\nAt the beginning of the 1970s, Prestes moved into exile in the USSR. In August 1972, she was indicted in Brazil for political activities, with the Conselho Permanente de Justiça para o Exército (the Army supreme court) sentencing her in absentia to 4 years and 6 months in prison.\n\nIn December 1975 Prestes earned a Doctorate in Political Economics from the Institute of Social Science in Moscow and four years later in September 1979, the Brazilian courts reduced Prestes's sentence by four years as part of a wider amnesty.\n\nIn 1989 Prestes received a Doctorate in History from the Fluminense Federal University, Rio de Janeiro, with a thesis named \"A Coluna Prestes (The Prestes Column)\", which was the movement commanded by her father of almost 1500 men fighting against the presidency of Artur Bernardes. She is now a retired Associate Professor of Brazilian History, but she continues teaching on the Master's and Doctorate's Compared History Program at the Universidade Federal do Rio de Janeiro (UFRJ).\n\n"}
{"id": "16431109", "url": "https://en.wikipedia.org/wiki?curid=16431109", "title": "Arisen Ahubudu", "text": "Arisen Ahubudu\n\nKalasuri Arisen Ahubudu (Sinhala: අරිසෙන් අහුබුදු; 18 March 1920 – 26 May 2011) was a writer, orator, scholar, playwright, teacher (Guru), Sinhala lyricist, author and poet in Sri Lanka, born in Mudiyallagahawatta in Malalaga, Koggala. He is a member of the Hela Havula. He has received three government awards for literary works, the title of Kalasuri from the Government of Sri Lanka, and the Sarasaviya Awards film award for best composer. As a composer, he is especially noted for writing music performed by W.D. Amaradeva, such as Gilem Obe Guna.\n\nAhubudu was the second of the three children of the family of Devundara Devamanimendra Heronis De Silva and Wathugedara Laisohami. The child was named as Ariyasena Arsuboda by parents, which he later converted to fairly pure Sinhala name Arisen Ahubudu. He married Sanda Ahubudu on 8 August 1953 and they have one daughter Sanda Samathi Ahubudu.\n\nIn 1937, at the age of 17, he first involved as a teacher in Piyadigama Saripuththa College, Ahangama. Munidasa gave an honorary to him as \"Subas Pathin Kiwithi\", due to excellent poetry he possess.\n\nAhubudu served 42 years as a teacher, beginning his career at Holy Trinity College in Nuwara Eliya, then he moved to Mahinda College, Galle and later to Maha Bodhi College, Maradana. His longest stint came even later at S. Thomas' College, Mount Lavinia 29 years from 1952 until 1979 where he was among those recruited by warden R. S. de Saram and who together with Sandadas Coperehewa and GL Jinadasa supported by D. S. Jayasekera he was a leader in the post independence renaissance in teaching of the Sinhala language and literary activities. He taught at Kibiya Government College, Katugastota Deegala College, Buddhist School, Wellatota also.\n\nWhile on teaching, in 1947 he published a magazine called \"Ediya\" (means \"power\") for children. the motto of that magazine was \"Ediya produced for improving powers of children\". He strongly believed that Sinhalese people were originated from King Ravana, and not from King Vijaya.\n\nPrior to his death Arisen Ahubudu was the last surviving prominent member of Hela Havula as well as the last surviving prominent Sri Lankan lyricist. Some of the popular songs that he lyrics are \"Kate Kiri Suwanda\", \"Rena Gira Rena Ambe\", \"Pruthugeese Kaaraya\", \"Punsada Eliyay\", \"Sudata Sude Walakulai\", \"Rejina Mamai Ape Rajje\", and \"Ko Hathuro\", \"Lanka Lanka Pembara Lanka\", \"Dakuna Nagenahira\", \"Mal Gomu Gumu\".\n\n1946, he entered to the drama script writing and wrote very famous dramas at that time, such as \"Wanaraja Kumariya\", \"Hela hethiriya\", \"Sakwithi Ravana\", and \"Lokanthaya saha geta\".\n\nAhubudu died on 26 May 2011.\n\n\n\n\n"}
{"id": "16539443", "url": "https://en.wikipedia.org/wiki?curid=16539443", "title": "Avviso", "text": "Avviso\n\nAvvisi (; plural: \"avvisi\") were hand-written newsletters used to convey political, military, and economic news quickly and efficiently throughout Europe, and more specifically Italy, during the early modern era (1500-1700). In the beginning avvisi were very similar to letters written from one dignitary to another, but diverged from such letters in the sixteenth century with more standardized practices. Avvisi can be divided into two categories: 'public' avvisi and 'secret' avvisi, though each copy was often written by the same person.\n\nIn Italian, the word avviso translates to \"notice\", \"warning\", \"advice\", or \"announcement\".\n\nThe avvisi found their origins, and peaked, in the early modern Italian world - primarily Rome and Venice. The popularity and distribution of the avvisi was driven by each court's desire to know what the opposing and even the allied courts are up to. News networks spread all across Europe, but the avviso itself was generally created in either Rome or Venice, with the rest of Europe simply consuming.\n\nAvvisi influenced many aspects of the early modern world including public opinion, political battles, the nature of propaganda, careers, and historical records.\n\nPublic Opinion\nAvvisi helped to develop public opinion by informing, organizing, and providing a voice for the public. They allowed the general public to learn of the secret dealings of the nation's leaders, form a response, and then have that response actually be heard by their fellow citizens - essentially making them new players in the game of politics.\n\nPolitics and War\nThough officially renounced by many leaders at the time, avvisi were then used by those very same leaders to wage their political campaigns against one another. Destruction and censorship of avvisi was selective, demonstrating that the authorities recognized the importance of spreading news but would have preferred to spread only news that was of benefit to themselves. Competition quickly led to avvisi being used as propaganda devices both as a machine of war and in attempts to turn the mob on their own country. Conflict as a result of avvisi being used as propaganda is certainly not out of the question, either with the public or between nations. Further the avvisi provided the public with political power rarely seen before in the form of 'secret' information that could have allowed them to have influence upon the courts, and government decisions. A minority of people, such as Paolo Sarpi, believed that government institutions should rescind their censorship of avvisi and make full use of publication to combat enemy publication. An example of this includes several pamphlets written by Sarpi in defense of Venice's rights over the Adriatic.\n\nFinances and Wealth\nCreation and distribution of avvisi required writers, those who can deliver the news, and those who can grant the information that makes the news and this provided many people with jobs, earning them money through standard means. In addition, invaluable secrets provided by the avvisi could be used in extortion or allowing individuals to influence prices at market. Those who used the avvisi in this way held the opinion that the information provided by avvisi could not be stopped and it was thus better to capitalize on it.\n\nHistory\nAvvisi led to a realization of the importance of the after-effects of historical records, whether they be true or not. Paolo Sarpi's work is an excellent example of this, as he states that he may cause more damage dead (through his writing) than he ever had alive.\n\nPublic avvisi were news letters that were available to anyone who wished to travel to a distribution center in a city. They were limited to generic, often harmless facts.\n\nSecret avvisi were news letters available to a restricted audience, much akin to duplicated personal letters. Their content could be considerably more harmful than the public counterpart, as it could include opinions of top officials and the discussions from secret meetings. This form of communication often had a very specific purpose.\n\nDistribution of the avvisi began with the sources of information. Reporters (newsletter writers, menanti, reportisti, gazzettieri) had networks of contacts filtering information from chancelleries, Catholic churches, Protestant churches, foreign embassies, and shops. Information was gathered and put together individually or at a Scrittoria (writer's workshop). The avvisi would then be distributed by regular news services and organized postal service networks. Whether newsletters were sent weekly, bi-weekly, or annually depended on the type of news and the writer. As the public avvisi were presented the news would quickly spread by word of mouth among the illiterate, no longer relying on the avvisi reporters. The range of information presented within avvisi was very broad, including countries such as France, Italy, and the Netherlands.\n\nWriters of avvisi received very little recognition which, quite often, was exactly how they wanted it. Fear of censorship kept writers from signing work under their own name - for in the early modern era censorship could mean death. Mutual bonds of trust developed between certain reporters and clients once they found they could trust each other to provide reliable information without any trouble. The quality of avvisi may fall under question for numerous reasons; the recopying of documents, the translation of documents, and the insertion of opinions for example.\n\nCensorship of avvisi began with Pope Pius V's campaign, beginning in 1570CE. Writers caught distributing what the Catholic Church determined to be defamatory were punished severely - several examples of punishments include death, imprisonment, and torture (sometimes to death). \n\nThe harsh punishments did not prevent writers from continuing in their task, though they were forced to use pseudonyms. \n\nThe avvisi were blamed for causing disputes by church officials and writers. However, institutions that condemned avvisi found they could do nothing to quell the hand-written newsletters and began to use them to their own benefit, even with bans still in place. \n\nReligious leaders were not alone in banning newsletters - more secular leaders also laid down limitations and prohibitions, including Venice's Council of Ten who held bans until at least 1567. \n\nA popular reporter, Paolo Sarpi, was a minority in his time for holding the belief that the spread of information could not be stopped so censorship was a waste of resources. Sarpi believed that the only way to combat the enemy's newsletters is for the government to have their own avviso.\n\nIt was not until the middle of the seventeenth century that printed avvisi became more common, and even then Venice and Rome abstained from print. Due to restrictions from censorship on printed works, a sense of urgency, and a desire for personalization hand written avvisi would not be easily replaced by the printing press. \n\nPrinted works were produced much more slowly and as a result the public would lose interest in the topic before it came to print. \n\nFurther, printed avvisi were less robust in an effort to avoid censors and cut editing time.\n\n\nDeVivo, Filippo. \"Paolo Sarpi and the Uses of Information in Seventeenth-Century Venice.\" Media History, 11:1, 37-51. London: Routledge. 2005.\n\nInfelise, Mario. \"Roman Avvisi: Information and Politics in the Seventeenth Century.\" Court and Politics in Papal Rome, 1492-1700. Cambridge: Cambridge University Press, 2002. 212-228.\n\n"}
{"id": "53990631", "url": "https://en.wikipedia.org/wiki?curid=53990631", "title": "Black ceramics in Lithuania", "text": "Black ceramics in Lithuania\n\nThe tradition of black ceramics goes back to prehistoric times. The oldest articles of black ceramics date back to 6 thousand years BC. They were made in Babylon and Persia, China and Egypt, and later in Greece, Rome and America.\n\nIn Lithuania black ceramics were used since the Neolithic Age. During the 1st millennium AD this technique was used to produce anthropomorphic urns and other cult vessels. This technique was very common in the medieval Europe. The Modern Age saw enamel techniques gaining prevalence and black ceramics pushed aside. In XX c. black ceramics became rarity. Lithuania is one of the few locations in the world where black ceramics has been preserved and still prospers.\n"}
{"id": "24942012", "url": "https://en.wikipedia.org/wiki?curid=24942012", "title": "Chaldean Catholic Eparchy of Amadiya", "text": "Chaldean Catholic Eparchy of Amadiya\n\nAmadiya (or Amadia) was a separate eparchy (diocese) of the Chaldean Catholic Church until it was united with the Chaldean Catholic Eparchy of Zakho in 2013.\nThe diocese was established on 1785 and named for the hilltop city of Amadiya in northern Iraq.\nIt lost territory in 1850 to establish the eparchies (dioceses) of Aqrā and Zaku (Zākhō), but on 23 April 1895.04.23 it regained territory from the suppressed daughter-diocese of Aqrā, yet on 24 February 1910.02.24 it lost territory again to re-establish the eparchy of Aqrā.\n\nIn 1913 it included Amadiya city itself and sixteen villages in the Tigris plain near the town of Dohuk and in the Sapna and Gomel river valleys.\n\nOn 10 June 2013 it was renamed as Diocese of Amadiyah and Zaku or Amadia and Zākhō, having gained territory from the suppressed daughter-eparchy of Zaku.\n\nThere were three main concentrations of East Syriac villages in the Amadiya region: in the Sapna valley to the west of Amadiya, in the Tigris plain around Dohuk, and in the Shemkan district, around the valley of the Gomel river. Before the fourteenth century the Sapna valley was part of the diocese of Dasen and Beth Ture ('the mountains'), which lay to the north of Marga and also covered the Berwari region and the Zibar and Lower Tiyari districts. The villages in the Dohuk district were included in the East Syriac diocese of Beth Nuhadra, whose bishops resided in the small town of Tel Hesh near Alqosh, and those in the Gomel valley in the diocese of Marga, centred on the Aqra region. The last-known bishops of Beth Nuhadra and Dasen, Ishoyahb and Mattai, were present at the consecrations of Makkikha II in 1257 and Yahballaha III in 1281 respectively, and it is unclear when either diocese came to an end.\n\nNo bishops of the Amadiya region are known from the fourteenth and fifteenth centuries. After the schism of 1552 the region remained loyal to the Nestorian patriarch Shemon VII Ishoyahb, and his opponent Yohannan Sulaqa, the first Chaldean patriarch, was martyred in 1554 after an attempt to win over Amadiya's East Syriac community. Thereafter the region seems to have been claimed by both patriarchates for some decades. A metropolitan Abdisho of 'Koma', probably the Sapna village of Komane with its recently revived monastery of Mar Abdisho of Kom, was among the signatories of a letter of 1580 from Shemon IX Denha to pope Gregory XIII, and the Dasen district was claimed by the Qochanes patriarch Shemon XI in 1653. On the other hand, a bishop Abraham of Beth Ture ('the mountains') is mentioned among the hierarchy of Eliya VIII in the report of 1610. Given its proximity to Alqosh, it would be surprising to find the region under the influence of the Qudshanis patriarchs, and the surviving manuscripts copied for the Dohuk, Sapna and Shemkan villages (some originating from Gazarta but the majority from Alqosh) invariably mention patriarchs of the Eliya line. By the end of the eighteenth century the Mosul patriarchate had a diocese of Amadiya for the region.\n\nThe patriarch Eliya XIII Ishoyahb consecrated his nephew Hnanisho metropolitan of Amadiya in September 1784 after his withdrawal to Amadiya, with the intention of preserving the patriarchal succession within his family. Hnanisho made a Catholic profession of faith in 1795, but was felt by the Latin missionaries to be insincere. In 1801 the Vatican informed them that he could not be received as a bishop in the Catholic Church without 'manifest signs of penitence'. Shortly afterwards in the same year Hnanisho openly defied the Vatican, consecrating the priest Peter Shawriz metropolitan of Seert.\n\nHnanisho seems to have become reconciled with Yohannan Hormizd after the death of Eliya XIII Ishoyahb in 1804, as in 1808 he was living in his household in Alqosh. He was 'senior to Yohannan, and governed the diocese of Amadiya, but all the same could do nothing without the approval of the metropolitan Yohannan'. Although he sympathised with Gabriel Dambo's monastic order, his dependence on Yohannan Hormizd occasionally forced him to act against his better judgement. In 1808 he asserted himself by delivering the monastery of Rabban Hormizd to Gabriel Dambo in defiance of Yohannan Hormizd's wishes. In 1811, however, on Yohannan Hormizd's instructions, he 'became a Nestorian at Amadiya' and expelled Dambo and his monks from the monastery with the assistance of the civil authorities. In 1813 he fell mortally ill, and made amends for his harsh treatment of the monks on his deathbed by returning the keys of the monastery to them. He died shortly afterwards and was buried in the monastery of Rabban Hormizd, 'among the tombs of the patriarchs of the Nestorians'.\n\nSome years earlier a Catholic diocese had been established in the region with the consecration by Yohannan Hormizd of his nephew Mattai Shemon for Amadiya on 5 May 1790. Shemon, originally named Yohannan, was the son of Yohannan's brother the priest Giwargis, and appears to have been consecrated on the suggestion of the missionary Maurizio Cherzoni. There is no need to doubt the sincerity of Yohannan Hormizd's commitment to the Catholic faith at this period, but the appointment was of course also directed against his rival Eliya XIII Ishoyahb. After his consecration Shemon made a determined effort to convert a number of villages in the Sapna plain and the Zibar district to Catholicism. He was killed by brigands not far from the Great Zab in 1811.\n\nBasil Asmar of Telkepe, a monk of the monastery of Rabban Hormizd, was consecrated for Amadiya at Amid by the patriarchal administrator Augustine Hindi in April 1824, but seems to have had no contact with his diocese. He resided in his home village of Telkepe until 1827, apparently in fear of the governor of Amadiya, known to be a friend of Yohannan Hormizd, and in 1827 fled to Amid, becoming its metropolitan in 1828.\n\nBasil Asmar was succeeded as metropolitan of Amadiya in 1830 by the energetic Joseph Audo, who was transferred from Mosul to the diocese of Amadiya under the settlement which confirmed Yohannan VIII Hormizd as patriarch and ended the schism in the Chaldean Church. During his metropolitanate Audo converted many of the villages of the Sapna valley to Catholicism. After he became patriarch in 1848 he was succeeded as metropolitan of Amadiya in 1851 by Abdisho Thomas Dirsho, a monk of the monastery of Rabban Hormizd, who died in 1859.\n\nThe future patriarch Abdisho Giwargis Khayyat became bishop of Amadiya in 1860. He was succeeded in 1874 by Mattai Paul Shamina, who exchanged dioceses in 1879 with Quriaqos Giwargis Goga, bishop of Zakho, who resigned in 1893. Eliya Joseph Khayyat was elected for Amadiya in 1893, but at the synod of Alqosh in 1894 the newly elected patriarch Abdisho V Khayyat asked to retain him as his patriarchal vicar. As a result, the dioceses of Amadiya and Aqra were temporarily united under Yaqob Yohannan Sahhar, bishop of Aqra, who was responsible for the united diocese from 23 April 1895 until his death in 1909.\n\nHe was succeeded as bishop of Amadiya by Francis Daoud of Araden (the only nineteenth-century Chaldean bishop from the Amadiya region), who had been Sahhar's vicar-general for several years previously. He was consecrated for Amadiya on 15 August 1910, resided in the Sapna village of Araden, and remained bishop of Amadiya until his death in 1939.\n\nFrancis Daoud's successors were Yohannan Qoryo (1942–6), Raphael Rabban (1947–57), Raphael Bidawid (1957–66), Andrew Sana (1966–7), Quriaqos Musa (1967–8), and Yohannan Qello (1973–2001).\n\nIn December 2001 the elderly bishop Yohannan Qello of Amadiya, who died on 7 September 2002, was succeeded by Rabban Al-Qas. Rabban Al-Qas was also apostolic administrator of the Chaldean archdiocese of Erbil, vacant since the death of Yaqob Denha Scher in 2005, until the appointment of Bashar Warda in 2010.\n\nIn July 2013, the Chaldean diocese of Amadiya was united with the vacant diocese of Zakho. Currently Raban al-Qas is the Bishop of Zakho and Amadiya.\n\nIn modern times Assyrians (Including Chaldean groups) comprise 30% of the Amadiya District, and 3,500+ Chaldean people are recorded in the Zakho District according to old Church Records from before the merger. After the merger the combined diocese population is 18,500 in 2015.\n\nIn 1850 the diocese of Amadiya included the towns of Dohuk and Amadiya and fourteen villages, all but one either around Dohuk or in the Gomel and Sapna valleys, and contained 466 Chaldean families, with 8 priests and 14 churches (Badger). The diocese also included at this period the Catholic communities in Herpa and Barzane, and probably other villages in the Aqra region.\n\nIn the 1850s Dohuk and several villages in the Dohuk district and Aqra region were transferred to the new dioceses of Zakho and Aqra. The reduced diocese of Amadiya contained 6,020 Chaldeans, with 10 priests, in 1867 (Martin); and 3,000 Chaldeans, with 13 priests and 16 churches, in 1896 (Chabot). In 1913 the diocese included Amadiya and sixteen villages, most of them in the Sapna and Gomel valleys, and contained 4,970 Chaldeans, with 19 priests and 10 churches (Tfinkdji).\n\nA recently published book by Youel Baaba has supplied the Syriac names of the villages in the diocese of Amadiya.\n\n\"Chaldean communities in the diocese of Amadiya, 1913\"\n\nTfinkdji mentioned that the diocese contained about 4,000 'Nestorians' in 1913, a figure not much smaller than its Chaldean population. This is a remarkably high figure for the Sapna and Shemkan villages, exposed to Catholic influence for over a century; and as Chabot did not mention a substantial traditionalist population in the diocese in 1896, it probably included the population of the East Syriac villages in the Berwari region, perhaps considered nominally part of the diocese of Amadiya after the conversion of the traditionalist bishop Ishoyahb of Berwari in 1903.\n\n"}
{"id": "4913342", "url": "https://en.wikipedia.org/wiki?curid=4913342", "title": "Championship belt", "text": "Championship belt\n\nA championship belt is a large, extravagantly designed belt used primarily in combat sports such as boxing, mixed martial arts, and professional wrestling to signify the champions of the promotion or company, much like a cup or trophy in other sports. There are several companies in the business of constructing championship belts.\n\nThe first belt given as a prize for accomplishments within the ring was presented in 1810 by King George III to bare-knuckle boxer Tom Cribb, after he defeated Tom Molineaux, an American former slave.\n\nIn boxing, the individual organizations such as the World Boxing Council, the World Boxing Association, the International Boxing Federation, and the World Boxing Organization each have their own unique championship belt that are awarded to the champions of each weight class. Boxers strive to win the belt of all four organizations to unify their weight divisions. \"The Ring\" also created a championship system that is \"intended to reward fighters who, by satisfying rigid criteria, can justify a claim as the true and only world champion in a given weight class.\"\n\nChampions maintain permanent possession of these belts even upon losing their title, with a new belt made when a new champion is crowned.\n\nProfessional wrestling is a form of entertainment which combines athletics and theatrical performance in a mimicry of combat sports. Many storylines center around the promotion's championships, which are represented by championship belts similar to those in boxing. The top title in a major promotion is usually designated a \"world heavyweight championship\". Other, lesser championships may carry regional names, be limited to a specific weight class, or be defended in other special circumstances, such as the traditional tag team match. \n\nTypically, pro wrestling title belts have a unique design for each title, in contrast with boxing and mixed martial arts (MMA) where the title belts of a given sanctioning body are all the same design. The Big Gold Belt design, for example, is very recognizable and has been used by various wrestling promotions since the 1980s. \n\nIn 2016, WWE began to streamline their championships, making their top male and female championships have the same design, similar to boxing and MMA. The only differences between them are the colors (to represent if the title belongs to either the Raw or SmackDown brand), the name on the belt, and the women's belts are smaller. The tag team championships also have the same design between each other with the only difference being the color of the straps.\n\nMixed martial arts generally follows the boxing model of each sanctioning group, which is also a promotion, awarding its champion in each weight class a championship belt. As in boxing, the design of each promotion's belts are the same regardless of weight class, and the champion keeps their belt after losing the title.\n\nThe Las Vegas Motor Speedway offers a championship belt in lieu of the traditional trophy for drivers who win the Pennzoil 400 NASCAR Monster Energy Cup race there, owing to the traditional site of Las Vegas as the fight capital of the world.\n\nHistorically, the championship belt was also awarded to the winner of professional golf tournaments. Rodeo tournaments also award special belts, among other prizes.\n"}
{"id": "16863009", "url": "https://en.wikipedia.org/wiki?curid=16863009", "title": "Charles Gibson (historian)", "text": "Charles Gibson (historian)\n\nCharles Gibson (12 August 1920 - 22 August 1985, Keeseville, N.Y.) was an American ethnohistorian who wrote foundational works on the Nahua peoples of colonial Mexico and was elected President of the American Historical Association in 1977. He studied history at Yale University with George Kubler, and he taught for a number of years at University of Iowa before moving to University of Michigan. His dissertation on the Nahua polity of Tlaxcala (published in 1952 as \"Tlaxcala in the Sixteenth Century\"), a key ally of the Spaniards in the conquest of Mexico, was the first major study of conquest and early colonial era Nahuas from the indigenous perspective. It remains a model for scholars working on Mesoamerican ethnohistory, or more simply put, history of Mexican Indians. He also contributed to the creation of important bibliographic guides to works in Mexican history, such as the \"Handbook of Latin American Studies\" and Mesoamerican ethnohistory as well as an index to the journal \"Hispanic American Historical Review.\" The culmination of his work on colonial-era Nahuas is \"The Aztecs Under Spanish Rule: A History of the Indians of the Valley of Mexico, 1519-1810\" (1964), which \"reordered the research priorities for a generation of colonial historians.\"\n\n"}
{"id": "591173", "url": "https://en.wikipedia.org/wiki?curid=591173", "title": "Eamon Duffy", "text": "Eamon Duffy\n\nEamon Duffy (born 9 February 1947) is an Irish historian and academic. He is Professor of the History of Christianity at the University of Cambridge, and a Fellow and former President of Magdalene College.\n\nDuffy was born on 9 February 1947 in Dundalk, Republic of Ireland. He describes himself as a \"cradle Catholic\". He was educated at St Philip's School and undertook postgraduate studies at the University of Cambridge, where his doctoral advisers were Owen Chadwick and Gordon Rupp.\n\nDuffy specialises in 15th- to 17th-century religious history of Britain. He is also a former member of the Pontifical Historical Commission. His work has done much to overturn the popular image of late-medieval Catholicism in England as moribund, and instead presents it as a vibrant cultural force. On weekdays from 22 October to 2 November 2007, he presented the BBC Radio 4 series \"10 Popes Who Shook the World\" – those popes featured were Peter, Leo I, Gregory I, Gregory VII, Innocent III, Paul III, Pius IX, Pius XII, John XXIII, and John Paul II.\n\n\n\n\n\n"}
{"id": "6139438", "url": "https://en.wikipedia.org/wiki?curid=6139438", "title": "Formation and evolution of the Solar System", "text": "Formation and evolution of the Solar System\n\nThe formation and evolution of the Solar System began 4.6 billion years ago with the gravitational collapse of a small part of a giant molecular cloud. Most of the collapsing mass collected in the center, forming the Sun, while the rest flattened into a protoplanetary disk out of which the planets, moons, asteroids, and other small Solar System bodies formed.\n\nThis model, known as the nebular hypothesis was first developed in the 18th century by Emanuel Swedenborg, Immanuel Kant, and Pierre-Simon Laplace. Its subsequent development has interwoven a variety of scientific disciplines including astronomy, physics, geology, and planetary science. Since the dawn of the space age in the 1950s and the discovery of extrasolar planets in the 1990s, the model has been both challenged and refined to account for new observations.\n\nThe Solar System has evolved considerably since its initial formation. Many moons have formed from circling discs of gas and dust around their parent planets, while other moons are thought to have formed independently and later been captured by their planets. Still others, such as Earth's Moon, may be the result of giant collisions. Collisions between bodies have occurred continually up to the present day and have been central to the evolution of the Solar System. The positions of the planets might have shifted due to gravitational interactions. This planetary migration is now thought to have been responsible for much of the Solar System's early evolution.\n\nIn roughly 5 billion years, the Sun will cool and expand outward to many times its current diameter (becoming a red giant), before casting off its outer layers as a planetary nebula and leaving behind a stellar remnant known as a white dwarf. In the far distant future, the gravity of passing stars will gradually reduce the Sun's retinue of planets. Some planets will be destroyed, others ejected into interstellar space. Ultimately, over the course of tens of billions of years, it is likely that the Sun will be left with none of the original bodies in orbit around it.\n\nIdeas concerning the origin and fate of the world date from the earliest known writings; however, for almost all of that time, there was no attempt to link such theories to the existence of a \"Solar System\", simply because it was not generally thought that the Solar System, in the sense we now understand it, existed. The first step toward a theory of Solar System formation and evolution was the general acceptance of heliocentrism, which placed the Sun at the centre of the system and the Earth in orbit around it. This concept had developed for millennia (Aristarchus of Samos had suggested it as early as 250 BC), but was not widely accepted until the end of the 17th century. The first recorded use of the term \"Solar System\" dates from 1704.\n\nThe current standard theory for Solar System formation, the nebular hypothesis, has fallen into and out of favour since its formulation by Emanuel Swedenborg, Immanuel Kant, and Pierre-Simon Laplace in the 18th century. The most significant criticism of the hypothesis was its apparent inability to explain the Sun's relative lack of angular momentum when compared to the planets. However, since the early 1980s studies of young stars have shown them to be surrounded by cool discs of dust and gas, exactly as the nebular hypothesis predicts, which has led to its re-acceptance.\n\nUnderstanding of how the Sun is expected to continue to evolve required an understanding of the source of its power. Arthur Stanley Eddington's confirmation of Albert Einstein's theory of relativity led to his realisation that the Sun's energy comes from nuclear fusion reactions in its core, fusing hydrogen into helium. In 1935, Eddington went further and suggested that other elements also might form within stars. Fred Hoyle elaborated on this premise by arguing that evolved stars called red giants created many elements heavier than hydrogen and helium in their cores. When a red giant finally casts off its outer layers, these elements would then be recycled to form other star systems.\n\nThe nebular hypothesis says that the Solar System formed from the gravitational collapse of a fragment of a giant molecular cloud. The cloud was about 20 parsec (65 light years) across, while the fragments were roughly 1 parsec (three and a quarter light-years) across. The further collapse of the fragments led to the formation of dense cores 0.01–0.1 pc (2,000–20,000 AU) in size. One of these collapsing fragments (known as the \"pre-solar nebula\") formed what became the Solar System. The composition of this region with a mass just over that of the Sun () was about the same as that of the Sun today, with hydrogen, along with helium and trace amounts of lithium produced by Big Bang nucleosynthesis, forming about 98% of its mass. The remaining 2% of the mass consisted of heavier elements that were created by nucleosynthesis in earlier generations of stars. Late in the life of these stars, they ejected heavier elements into the interstellar medium.\n\nThe oldest inclusions found in meteorites, thought to trace the first solid material to form in the pre-solar nebula, are 4568.2 million years old, which is one definition of the age of the Solar System. Studies of ancient meteorites reveal traces of stable daughter nuclei of short-lived isotopes, such as iron-60, that only form in exploding, short-lived stars. This indicates that one or more supernovae occurred near the Sun while it was forming. A shock wave from a supernova may have triggered the formation of the Sun by creating relatively dense regions within the cloud, causing these regions to collapse. Because only massive, short-lived stars produce supernovae, the Sun must have formed in a large star-forming region that produced massive stars, possibly similar to the Orion Nebula. Studies of the structure of the Kuiper belt and of anomalous materials within it suggest that the Sun formed within a cluster of between 1,000 and 10,000 stars with a diameter of between 6.5 and 19.5 light years and a collective mass of . This cluster began to break apart between 135 million and 535 million years after formation. Several simulations of our young Sun interacting with close-passing stars over the first 100 million years of its life produce anomalous orbits observed in the outer Solar System, such as detached objects.\n\nBecause of the conservation of angular momentum, the nebula spun faster as it collapsed. As the material within the nebula condensed, the atoms within it began to collide with increasing frequency, converting their kinetic energy into heat. The centre, where most of the mass collected, became increasingly hotter than the surrounding disc. Over about 100,000 years, the competing forces of gravity, gas pressure, magnetic fields, and rotation caused the contracting nebula to flatten into a spinning protoplanetary disc with a diameter of about 200 AU and form a hot, dense protostar (a star in which hydrogen fusion has not yet begun) at the centre.\n\nAt this point in its evolution, the Sun is thought to have been a T Tauri star. Studies of T Tauri stars show that they are often accompanied by discs of pre-planetary matter with masses of . These discs extend to several hundred AU—the Hubble Space Telescope has observed protoplanetary discs of up to 1000 AU in diameter in star-forming regions such as the Orion Nebula—and are rather cool, reaching a surface temperature of only about 1000 kelvins at their hottest.\nWithin 50 million years, the temperature and pressure at the core of the Sun became so great that its hydrogen began to fuse, creating an internal source of energy that countered gravitational contraction until hydrostatic equilibrium was achieved. This marked the Sun's entry into the prime phase of its life, known as the main sequence. Main-sequence stars derive energy from the fusion of hydrogen into helium in their cores. The Sun remains a main-sequence star today.\n\nThe various planets are thought to have formed from the solar nebula, the disc-shaped cloud of gas and dust left over from the Sun's formation. The currently accepted method by which the planets formed is accretion, in which the planets began as dust grains in orbit around the central protostar. Through direct contact, these grains formed into clumps up to 200 metres in diameter, which in turn collided to form larger bodies (planetesimals) of ~10 kilometres (km) in size. These gradually increased through further collisions, growing at the rate of centimetres per year over the course of the next few million years.\n\nThe inner Solar System, the region of the Solar System inside 4 AU, was too warm for volatile molecules like water and methane to condense, so the planetesimals that formed there could only form from compounds with high melting points, such as metals (like iron, nickel, and aluminium) and rocky silicates. These rocky bodies would become the terrestrial planets (Mercury, Venus, Earth, and Mars). These compounds are quite rare in the Universe, comprising only 0.6% of the mass of the nebula, so the terrestrial planets could not grow very large. The terrestrial embryos grew to about 0.05 Earth masses () and ceased accumulating matter about 100,000 years after the formation of the Sun; subsequent collisions and mergers between these planet-sized bodies allowed terrestrial planets to grow to their present sizes (see Terrestrial planets below).\n\nWhen the terrestrial planets were forming, they remained immersed in a disk of gas and dust. The gas was partially supported by pressure and so did not orbit the Sun as rapidly as the planets. The resulting drag and, more importantly, gravitational interactions with the surrounding material caused a transfer of angular momentum, and as a result the planets gradually migrated to new orbits. Models show that density and temperature variations in the disk governed this rate of migration, but the net trend was for the inner planets to migrate inward as the disk dissipated, leaving the planets in their current orbits.\n\nThe giant planets (Jupiter, Saturn, Uranus, and Neptune) formed further out, beyond the frost line, which is the point between the orbits of Mars and Jupiter where the material is cool enough for volatile icy compounds to remain solid. The ices that formed the Jovian planets were more abundant than the metals and silicates that formed the terrestrial planets, allowing the giant planets to grow massive enough to capture hydrogen and helium, the lightest and most abundant elements. Planetesimals beyond the frost line accumulated up to within about 3 million years. Today, the four giant planets comprise just under 99% of all the mass orbiting the Sun. Theorists believe it is no accident that Jupiter lies just beyond the frost line. Because the frost line accumulated large amounts of water via evaporation from infalling icy material, it created a region of lower pressure that increased the speed of orbiting dust particles and halted their motion toward the Sun. In effect, the frost line acted as a barrier that caused material to accumulate rapidly at ~5 AU from the Sun. This excess material coalesced into a large embryo (or core) on the order of , which began to accumulate an envelope via accretion of gas from the surrounding disc at an ever-increasing rate. Once the envelope mass became about equal to the solid core mass, growth proceeded very rapidly, reaching about 150 Earth masses ~10 years thereafter and finally topping out at . Saturn may owe its substantially lower mass simply to having formed a few million years after Jupiter, when there was less gas available to consume.\n\nT Tauri stars like the young Sun have far stronger stellar winds than more stable, older stars. Uranus and Neptune are thought to have formed after Jupiter and Saturn did, when the strong solar wind had blown away much of the disc material. As a result, those planets accumulated little hydrogen and helium—not more than each. Uranus and Neptune are sometimes referred to as failed cores. The main problem with formation theories for these planets is the timescale of their formation. At the current locations it would have taken millions of years for their cores to accrete. This means that Uranus and Neptune may have formed closer to the Sun—near or even between Jupiter and Saturn—and later migrated or were ejected outward (see Planetary migration below). Motion in the planetesimal era was not all inward toward the Sun; the \"Stardust\" sample return from Comet Wild 2 has suggested that materials from the early formation of the Solar System migrated from the warmer inner Solar System to the region of the Kuiper belt.\n\nAfter between three and ten million years, the young Sun's solar wind would have cleared away all the gas and dust in the protoplanetary disc, blowing it into interstellar space, thus ending the growth of the planets.\n\nThe planets were originally thought to have formed in or near their current orbits. From that a minimum mass of the nebula i.e. the protoplanetary disc, was derived that was necessary to form the planets - the minimum mass solar nebula. It was derived that the nebula mass must have exceeded 3585 times that of the Earth.\n\nHowever, this has been questioned during the last 20 years. Currently, many planetary scientists think that the Solar System might have looked very different after its initial formation: several objects at least as massive as Mercury were present in the inner Solar System, the outer Solar System was much more compact than it is now, and the Kuiper belt was much closer to the Sun.\n\nAt the end of the planetary formation epoch the inner Solar System was populated by 50–100 Moon- to Mars-sized planetary embryos. Further growth was possible only because these bodies collided and merged, which took less than 100 million years. These objects would have gravitationally interacted with one another, tugging at each other's orbits until they collided, growing larger until the four terrestrial planets we know today took shape. One such giant collision is thought to have formed the Moon (see Moons below), while another removed the outer envelope of the young Mercury.\n\nOne unresolved issue with this model is that it cannot explain how the initial orbits of the proto-terrestrial planets, which would have needed to be highly eccentric to collide, produced the remarkably stable and nearly circular orbits they have today. One hypothesis for this \"eccentricity dumping\" is that the terrestrials formed in a disc of gas still not expelled by the Sun. The \"gravitational drag\" of this residual gas would have eventually lowered the planets' energy, smoothing out their orbits. However, such gas, if it existed, would have prevented the terrestrial planets' orbits from becoming so eccentric in the first place. Another hypothesis is that gravitational drag occurred not between the planets and residual gas but between the planets and the remaining small bodies. As the large bodies moved through the crowd of smaller objects, the smaller objects, attracted by the larger planets' gravity, formed a region of higher density, a \"gravitational wake\", in the larger objects' path. As they did so, the increased gravity of the wake slowed the larger objects down into more regular orbits.\n\nThe outer edge of the terrestrial region, between 2 and 4 AU from the Sun, is called the asteroid belt. The asteroid belt initially contained more than enough matter to form 2–3 Earth-like planets, and, indeed, a large number of planetesimals formed there. As with the terrestrials, planetesimals in this region later coalesced and formed 20–30 Moon- to Mars-sized planetary embryos; however, the proximity of Jupiter meant that after this planet formed, 3 million years after the Sun, the region's history changed dramatically. Orbital resonances with Jupiter and Saturn are particularly strong in the asteroid belt, and gravitational interactions with more massive embryos scattered many planetesimals into those resonances. Jupiter's gravity increased the velocity of objects within these resonances, causing them to shatter upon collision with other bodies, rather than accrete.\n\nAs Jupiter migrated inward following its formation (see Planetary migration below), resonances would have swept across the asteroid belt, dynamically exciting the region's population and increasing their velocities relative to each other. The cumulative action of the resonances and the embryos either scattered the planetesimals away from the asteroid belt or excited their orbital inclinations and eccentricities. Some of those massive embryos too were ejected by Jupiter, while others may have migrated to the inner Solar System and played a role in the final accretion of the terrestrial planets. During this primary depletion period, the effects of the giant planets and planetary embryos left the asteroid belt with a total mass equivalent to less than 1% that of the Earth, composed mainly of small planetesimals.\nThis is still 10–20 times more than the current mass in the main belt, which is now about . A secondary depletion period that brought the asteroid belt down close to its present mass is thought to have followed when Jupiter and Saturn entered a temporary 2:1 orbital resonance (see below).\n\nThe inner Solar System's period of giant impacts probably played a role in the Earth acquiring its current water content (~6 kg) from the early asteroid belt. Water is too volatile to have been present at Earth's formation and must have been subsequently delivered from outer, colder parts of the Solar System. The water was probably delivered by planetary embryos and small planetesimals thrown out of the asteroid belt by Jupiter. A population of main-belt comets discovered in 2006 has been also suggested as a possible source for Earth's water. In contrast, comets from the Kuiper belt or farther regions delivered not more than about 6% of Earth's water. The panspermia hypothesis holds that life itself may have been deposited on Earth in this way, although this idea is not widely accepted.\n\nAccording to the nebular hypothesis, the outer two planets may be in the \"wrong place\". Uranus and Neptune (known as the \"ice giants\") exist in a region where the reduced density of the solar nebula and longer orbital times render their formation highly implausible. The two are instead thought to have formed in orbits near Jupiter and Saturn, where more material was available, and to have migrated outward to their current positions over hundreds of millions of years.\nThe migration of the outer planets is also necessary to account for the existence and properties of the Solar System's outermost regions. Beyond Neptune, the Solar System continues into the Kuiper belt, the scattered disc, and the Oort cloud, three sparse populations of small icy bodies thought to be the points of origin for most observed comets. At their distance from the Sun, accretion was too slow to allow planets to form before the solar nebula dispersed, and thus the initial disc lacked enough mass density to consolidate into a planet. The Kuiper belt lies between 30 and 55 AU from the Sun, while the farther scattered disc extends to over 100 AU, and the distant Oort cloud begins at about 50,000 AU. Originally, however, the Kuiper belt was much denser and closer to the Sun, with an outer edge at approximately 30 AU. Its inner edge would have been just beyond the orbits of Uranus and Neptune, which were in turn far closer to the Sun when they formed (most likely in the range of 15–20 AU), and in 50% of simulations ended up opposite locations, with Uranus farther from the Sun than Neptune.\n\nAccording to the Nice model, after the formation of the Solar System, the orbits of all the giant planets continued to change slowly, influenced by their interaction with the large number of remaining planetesimals. After 500–600 million years (about 4 billion years ago) Jupiter and Saturn fell into a 2:1 resonance: Saturn orbited the Sun once for every two Jupiter orbits. This resonance created a gravitational push against the outer planets, possibly causing Neptune to surge past Uranus and plough into the ancient Kuiper belt.\nThe planets scattered the majority of the small icy bodies inwards, while themselves moving outwards. These planetesimals then scattered off the next planet they encountered in a similar manner, moving the planets' orbits outwards while they moved inwards. This process continued until the planetesimals interacted with Jupiter, whose immense gravity sent them into highly elliptical orbits or even ejected them outright from the Solar System. This caused Jupiter to move slightly inward. Those objects scattered by Jupiter into highly elliptical orbits formed the Oort cloud; those objects scattered to a lesser degree by the migrating Neptune formed the current Kuiper belt and scattered disc. This scenario explains the Kuiper belt's and scattered disc's present low mass. Some of the scattered objects, including Pluto, became gravitationally tied to Neptune's orbit, forcing them into mean-motion resonances. Eventually, friction within the planetesimal disc made the orbits of Uranus and Neptune circular again.\n\nIn contrast to the outer planets, the inner planets are not thought to have migrated significantly over the age of the Solar System, because their orbits have remained stable following the period of giant impacts.\n\nAnother question is why Mars came out so small compared with Earth. A study by Southwest Research Institute, San Antonio, Texas, published June 6, 2011 (called the Grand tack hypothesis), proposes that Jupiter had migrated inward to 1.5 AU. After Saturn formed, migrated inward, and established the 2:3 mean motion resonance with Jupiter, the study assumes that both planets migrated back to their present positions. Jupiter thus would have consumed much of the material that would have created a bigger Mars. The same simulations also reproduce the characteristics of the modern asteroid belt, with dry asteroids and water-rich objects similar to comets. However, it is unclear whether conditions in the solar nebula would have allowed Jupiter and Saturn to move back to their current positions, and according to current estimates this possibility appears unlikely. Moreover, alternative explanations for the small mass of Mars exist.\n\nGravitational disruption from the outer planets' migration would have sent large numbers of asteroids into the inner Solar System, severely depleting the original belt until it reached today's extremely low mass. This event may have triggered the Late Heavy Bombardment that occurred approximately 4 billion years ago, 500–600 million years after the formation of the Solar System. This period of heavy bombardment lasted several hundred million years and is evident in the cratering still visible on geologically dead bodies of the inner Solar System such as the Moon and Mercury. The oldest known evidence for life on Earth dates to 3.8 billion years ago—almost immediately after the end of the Late Heavy Bombardment.\n\nImpacts are thought to be a regular (if currently infrequent) part of the evolution of the Solar System. That they continue to happen is evidenced by the collision of Comet Shoemaker–Levy 9 with Jupiter in 1994, the 2009 Jupiter impact event, the Tunguska event, the Chelyabinsk meteor and the impact feature Meteor Crater in Arizona. The process of accretion, therefore, is not complete, and may still pose a threat to life on Earth.\n\nOver the course of the Solar System's evolution, comets were ejected out of the inner Solar System by the gravity of the giant planets, and sent thousands of AU outward to form the Oort cloud, a spherical outer swarm of cometary nuclei at the farthest extent of the Sun's gravitational pull. Eventually, after about 800 million years, the gravitational disruption caused by galactic tides, passing stars and giant molecular clouds began to deplete the cloud, sending comets into the inner Solar System. The evolution of the outer Solar System also appears to have been influenced by space weathering from the solar wind, micrometeorites, and the neutral components of the interstellar medium.\n\nThe evolution of the asteroid belt after Late Heavy Bombardment was mainly governed by collisions. Objects with large mass have enough gravity to retain any material ejected by a violent collision. In the asteroid belt this usually is not the case. As a result, many larger objects have been broken apart, and sometimes newer objects have been forged from the remnants in less violent collisions. Moons around some asteroids currently can only be explained as consolidations of material flung away from the parent object without enough energy to entirely escape its gravity.\n\nMoons have come to exist around most planets and many other Solar System bodies. These natural satellites originated by one of three possible mechanisms:\n\nJupiter and Saturn have several large moons, such as Io, Europa, Ganymede and Titan, which may have originated from discs around each giant planet in much the same way that the planets formed from the disc around the Sun. This origin is indicated by the large sizes of the moons and their proximity to the planet. These attributes are impossible to achieve via capture, while the gaseous nature of the primaries also make formation from collision debris unlikely. The outer moons of the giant planets tend to be small and have eccentric orbits with arbitrary inclinations. These are the characteristics expected of captured bodies. Most such moons orbit in the direction opposite the rotation of their primary. The largest irregular moon is Neptune's moon Triton, which is thought to be a captured Kuiper belt object.\n\nMoons of solid Solar System bodies have been created by both collisions and capture. Mars's two small moons, Deimos and Phobos, are thought to be captured asteroids.\nThe Earth's Moon is thought to have formed as a result of a single, large head-on collision.\nThe impacting object probably had a mass comparable to that of Mars, and the impact probably occurred near the end of the period of giant impacts. The collision kicked into orbit some of the impactor's mantle, which then coalesced into the Moon. The impact was probably the last in the series of mergers that formed the Earth.\nIt has been further hypothesized that the Mars-sized object may have formed at one of the stable Earth–Sun Lagrangian points (either or ) and drifted from its position. The moons of trans-Neptunian objects Pluto (Charon) and Orcus (Vanth) may also have formed by means of a large collision: the Pluto–Charon, Orcus–Vanth and Earth–Moon systems are unusual in the Solar System in that the satellite's mass is at least 1% that of the larger body.\n\nAstronomers estimate that the Solar System as we know it today will not change drastically until the Sun has fused almost all the hydrogen fuel in its core into helium, beginning its evolution from the main sequence of the Hertzsprung–Russell diagram and into its red-giant phase. Even so, the Solar System will continue to evolve until then.\n\nThe Solar System is chaotic over million- and billion-year timescales, with the orbits of the planets open to long-term variations. One notable example of this chaos is the Neptune–Pluto system, which lies in a 3:2 orbital resonance. Although the resonance itself will remain stable, it becomes impossible to predict the position of Pluto with any degree of accuracy more than 10–20 million years (the Lyapunov time) into the future. Another example is Earth's axial tilt, which, due to friction raised within Earth's mantle by tidal interactions with the Moon (see below), is incomputable from some point between 1.5 and 4.5 billion years from now.\n\nThe outer planets' orbits are chaotic over longer timescales, with a Lyapunov time in the range of 2–230 million years.\nIn all cases this means that the position of a planet along its orbit ultimately becomes impossible to predict with any certainty (so, for example, the timing of winter and summer become uncertain), but in some cases the orbits themselves may change dramatically. Such chaos manifests most strongly as changes in eccentricity, with some planets' orbits becoming significantly more—or less—elliptical.\n\nUltimately, the Solar System is stable in that none of the planets are likely to collide with each other or be ejected from the system in the next few billion years. Beyond this, within five billion years or so Mars's eccentricity may grow to around 0.2, such that it lies on an Earth-crossing orbit, leading to a potential collision. In the same timescale, Mercury's eccentricity may grow even further, and a close encounter with Venus could theoretically eject it from the Solar System altogether or send it on a collision course with Venus or Earth. This could happen within a billion years, according to numerical simulations in which Mercury's orbit is perturbed.\n\nThe evolution of moon systems is driven by tidal forces. A moon will raise a tidal bulge in the object it orbits (the primary) due to the differential gravitational force across diameter of the primary. If a moon is revolving in the same direction as the planet's rotation and the planet is rotating faster than the orbital period of the moon, the bulge will constantly be pulled ahead of the moon. In this situation, angular momentum is transferred from the rotation of the primary to the revolution of the satellite. The moon gains energy and gradually spirals outward, while the primary rotates more slowly over time.\n\nThe Earth and its Moon are one example of this configuration. Today, the Moon is tidally locked to the Earth; one of its revolutions around the Earth (currently about 29 days) is equal to one of its rotations about its axis, so it always shows one face to the Earth. The Moon will continue to recede from Earth, and Earth's spin will continue to slow gradually. Other examples are the Galilean moons of Jupiter (as well as many of Jupiter's smaller moons) and most of the larger moons of Saturn.\n\nA different scenario occurs when the moon is either revolving around the primary faster than the primary rotates, or is revolving in the direction opposite the planet's rotation. In these cases, the tidal bulge lags behind the moon in its orbit. In the former case, the direction of angular momentum transfer is reversed, so the rotation of the primary speeds up while the satellite's orbit shrinks. In the latter case, the angular momentum of the rotation and revolution have opposite signs, so transfer leads to decreases in the magnitude of each (that cancel each other out). In both cases, tidal deceleration causes the moon to spiral in towards the primary until it either is torn apart by tidal stresses, potentially creating a planetary ring system, or crashes into the planet's surface or atmosphere. Such a fate awaits the moons Phobos of Mars (within 30 to 50 million years), Triton of Neptune (in 3.6 billion years), Metis and Adrastea of Jupiter, and at least 16 small satellites of Uranus and Neptune. Uranus's Desdemona may even collide with one of its neighboring moons.\n\nA third possibility is where the primary and moon are tidally locked to each other. In that case, the tidal bulge stays directly under the moon, there is no transfer of angular momentum, and the orbital period will not change. Pluto and Charon are an example of this type of configuration.\n\nPrior to the 2004 arrival of the \"Cassini–Huygens\" spacecraft, the rings of Saturn were widely thought to be much younger than the Solar System and were not expected to survive beyond another 300 million years. Gravitational interactions with Saturn's moons were expected to gradually sweep the rings' outer edge toward the planet, with abrasion by meteorites and Saturn's gravity eventually taking the rest, leaving Saturn unadorned. However, data from the \"Cassini\" mission led scientists to revise that early view. Observations revealed 10 km-wide icy clumps of material that repeatedly break apart and reform, keeping the rings fresh. Saturn's rings are far more massive than the rings of the other giant planets. This large mass is thought to have preserved Saturn's rings since it first formed 4.5 billion years ago, and is likely to preserve them for billions of years to come.\n\nIn the long term, the greatest changes in the Solar System will come from changes in the Sun itself as it ages. As the Sun burns through its supply of hydrogen fuel, it gets hotter and burns the remaining fuel even faster. As a result, the Sun is growing brighter at a rate of ten percent every 1.1 billion years. In about 600 million years, the Sun brightness will have disrupted the Carbon Cycle to the point that trees and forests (C3 photosynthetic plant life) will no longer be able to survive and in around 800 million years, all complex life will have gone extinct. In one billion years' time, the Sun's increased radiation output, will cause its circumstellar habitable zone will move outwards, making the Earth's surface too hot for liquid water to exist there naturally. At this point, all life will be reduced to single celled organisms. Evaporation of water, a potent greenhouse gas, from the oceans' surface could accelerate temperature increase, potentially ending all life on Earth even sooner. During this time, it is possible that as Mars's surface temperature gradually rises, carbon dioxide and water currently frozen under the surface regolith will release into the atmosphere, creating a greenhouse effect that will heat the planet until it achieves conditions parallel to Earth today, providing a potential future abode for life. By 3.5 billion years from now, Earth's surface conditions will be similar to those of Venus today.\nAround 5.4 billion years from now, the core of the Sun will become hot enough to trigger hydrogen fusion in its surrounding shell. This will cause the outer layers of the star to expand greatly, and the star will enter a phase of its life in which it is called a red giant. Within 7.5 billion years, the Sun will have expanded to a radius of 1.2 AU—256 times its current size. At the tip of the red giant branch, as a result of the vastly increased surface area, the Sun's surface will be much cooler (about 2600 K) than now and its luminosity much higher—up to 2,700 current solar luminosities. For part of its red giant life, the Sun will have a strong stellar wind that will carry away around 33% of its mass. During these times, it is possible that Saturn's moon Titan could achieve surface temperatures necessary to support life.\n\nAs the Sun expands, it will swallow the planets Mercury and Venus. Earth's fate is less clear; although the Sun will envelop Earth's current orbit, the star's loss of mass (and thus weaker gravity) will cause the planets' orbits to move farther out. If it were only for this, Venus and Earth would probably escape incineration, but a 2008 study suggests that Earth will likely be swallowed up as a result of tidal interactions with the Sun's weakly bound outer envelope.\n\nGradually, the hydrogen burning in the shell around the solar core will increase the mass of the core until it reaches about 45% of the present solar mass. At this point the density and temperature will become so high that the fusion of helium into carbon will begin, leading to a helium flash; the Sun will shrink from around 250 to 11 times its present (main-sequence) radius. Consequently, its luminosity will decrease from around 3,000 to 54 times its current level, and its surface temperature will increase to about 4770 K. The Sun will become a horizontal giant, burning helium in its core in a stable fashion much like it burns hydrogen today. The helium-fusing stage will last only 100 million years. Eventually, it will have to again resort to the reserves of hydrogen and helium in its outer layers and will expand a second time, turning into what is known as an asymptotic giant. Here the luminosity of the Sun will increase again, reaching about 2,090 present luminosities, and it will cool to about 3500 K. This phase lasts about 30 million years, after which, over the course of a further 100,000 years, the Sun's remaining outer layers will fall away, ejecting a vast stream of matter into space and forming a halo known (misleadingly) as a planetary nebula. The ejected material will contain the helium and carbon produced by the Sun's nuclear reactions, continuing the enrichment of the interstellar medium with heavy elements for future generations of stars.\nThis is a relatively peaceful event, nothing akin to a supernova, which the Sun is too small to undergo as part of its evolution. Any observer present to witness this occurrence would see a massive increase in the speed of the solar wind, but not enough to destroy a planet completely. However, the star's loss of mass could send the orbits of the surviving planets into chaos, causing some to collide, others to be ejected from the Solar System, and still others to be torn apart by tidal interactions. Afterwards, all that will remain of the Sun is a white dwarf, an extraordinarily dense object, 54% its original mass but only the size of the Earth. Initially, this white dwarf may be 100 times as luminous as the Sun is now. It will consist entirely of degenerate carbon and oxygen, but will never reach temperatures hot enough to fuse these elements. Thus the white dwarf Sun will gradually cool, growing dimmer and dimmer.\n\nAs the Sun dies, its gravitational pull on the orbiting bodies such as planets, comets and asteroids will weaken due to its mass loss. All remaining planets' orbits will expand; if Venus, Earth, and Mars still exist, their orbits will lie roughly at , , and . They and the other remaining planets will become dark, frigid hulks, completely devoid of any form of life. They will continue to orbit their star, their speed slowed due to their increased distance from the Sun and the Sun's reduced gravity. Two billion years later, when the Sun has cooled to the 6000–8000K range, the carbon and oxygen in the Sun's core will freeze, with over 90% of its remaining mass assuming a crystalline structure. Eventually, after billions more years, the Sun will finally cease to shine altogether, becoming a black dwarf.\n\nThe Solar System travels alone through the Milky Way in a circular orbit approximately 30,000 light years from the Galactic Centre. Its speed is about 220 km/s. The period required for the Solar System to complete one revolution around the Galactic Centre, the galactic year, is in the range of 220–250 million years. Since its formation, the Solar System has completed at least 20 such revolutions.\n\nVarious scientists have speculated that the Solar System's path through the galaxy is a factor in the periodicity of mass extinctions observed in the Earth's fossil record. One hypothesis supposes that vertical oscillations made by the Sun as it orbits the Galactic Centre cause it to regularly pass through the galactic plane. When the Sun's orbit takes it outside the galactic disc, the influence of the galactic tide is weaker; as it re-enters the galactic disc, as it does every 20–25 million years, it comes under the influence of the far stronger \"disc tides\", which, according to mathematical models, increase the flux of Oort cloud comets into the Solar System by a factor of 4, leading to a massive increase in the likelihood of a devastating impact.\n\nHowever, others argue that the Sun is currently close to the galactic plane, and yet the last great extinction event was 15 million years ago. Therefore, the Sun's vertical position cannot alone explain such periodic extinctions, and that extinctions instead occur when the Sun passes through the galaxy's spiral arms. Spiral arms are home not only to larger numbers of molecular clouds, whose gravity may distort the Oort cloud, but also to higher concentrations of bright blue giants, which live for relatively short periods and then explode violently as supernovae.\n\nAlthough the vast majority of galaxies in the Universe are moving away from the Milky Way, the Andromeda Galaxy, the largest member of the Local Group of galaxies, is heading toward it at about 120 km/s. In 4 billion years, Andromeda and the Milky Way will collide, causing both to deform as tidal forces distort their outer arms into vast tidal tails. If this initial disruption occurs, astronomers calculate a 12% chance that the Solar System will be pulled outward into the Milky Way's tidal tail and a 3% chance that it will become gravitationally bound to Andromeda and thus a part of that galaxy. After a further series of glancing blows, during which the likelihood of the Solar System's ejection rises to 30%, the galaxies' supermassive black holes will merge. Eventually, in roughly 6 billion years, the Milky Way and Andromeda will complete their merger into a giant elliptical galaxy. During the merger, if there is enough gas, the increased gravity will force the gas to the centre of the forming elliptical galaxy. This may lead to a short period of intensive star formation called a starburst. In addition, the infalling gas will feed the newly formed black hole, transforming it into an active galactic nucleus. The force of these interactions will likely push the Solar System into the new galaxy's outer halo, leaving it relatively unscathed by the radiation from these collisions.\n\nIt is a common misconception that this collision will disrupt the orbits of the planets in the Solar System. Although it is true that the gravity of passing stars can detach planets into interstellar space, distances between stars are so great that the likelihood of the Milky Way–Andromeda collision causing such disruption to any individual star system is negligible. Although the Solar System as a whole could be affected by these events, the Sun and planets are not expected to be disturbed.\n\nHowever, over time, the cumulative probability of a chance encounter with a star increases, and disruption of the planets becomes all but inevitable. Assuming that the Big Crunch or Big Rip scenarios for the end of the Universe do not occur, calculations suggest that the gravity of passing stars will have completely stripped the dead Sun of its remaining planets within 1 quadrillion (10) years. This point marks the end of the Solar System. Although the Sun and planets may survive, the Solar System, in any meaningful sense, will cease to exist.\n\nThe time frame of the Solar System's formation has been determined using radiometric dating. Scientists estimate that the Solar System is 4.6 billion years old. The oldest known mineral grains on Earth are approximately 4.4 billion years old. Rocks this old are rare, as Earth's surface is constantly being reshaped by erosion, volcanism, and plate tectonics. To estimate the age of the Solar System, scientists use meteorites, which were formed during the early condensation of the solar nebula. Almost all meteorites (see the Canyon Diablo meteorite) are found to have an age of 4.6 billion years, suggesting that the Solar System must be at least this old.\n\nStudies of discs around other stars have also done much to establish a time frame for Solar System formation. Stars between one and three million years old have discs rich in gas, whereas discs around stars more than 10 million years old have little to no gas, suggesting that giant planets within them have ceased forming.\n\nNote: All dates and times in this chronology are approximate and should be taken as an order of magnitude indicator only.\n\n\n"}
{"id": "34005163", "url": "https://en.wikipedia.org/wiki?curid=34005163", "title": "Francisco Lluch Mora", "text": "Francisco Lluch Mora\n\nFrancisco José Antonio Lluch Mora (7 May 1924 – 26 October 2006) was a Puerto Rican historian, poet, writer, school teacher and college professor. He is best known for his legendary book \"Orígenes y Fundación de Ponce y Otras Noticias Relativas a su Desarrollo Urbano, Demográfico y Cultural (Siglos XVI-XIX)\".\n\nLluch Mora was born 7 May 1924 in Yauco, Puerto Rico. His parents were Jose Ramon Lluch Polidori (1 October 1894 – 20 October 1965) and Matilde Mora y Berenguer. He was the eldest of five brothers. His brothers were Enrique, Eugenio, Federico and Jaime.\n\nLluch Mora was a school teacher and university professor, teaching Spanish, literature, and history. He started his teaching career as a school teacher in the elementary and high schools of his hometown Yauco and also taught in Guánica. He held various other positions within the Puerto Rico Department of Education. He also taught at both private and public universities. He was head of the Department of Hispanic Studies of the University of Puerto Rico at Mayaguez, head of the Department of Spanish at the University of Puerto Rico at Ponce and professor at the graduate school of the Pontificia Universidad Católica de Puerto Rico.\n\nLluch Mora was a highly regarded historian, receiving many honors and accolades. He published various books, among them his masterpiece \"Orígenes y Fundación de Ponce y Otras Noticias Relativas a su Desarrollo Urbano, Demográfico y Cultural (Siglos XVI-XIX)\", which earned him a recognition by the Puerto Rico Senate in 2001.\n\nIn the area of poetry Lluch Mora is remembered for \"Tu presencia\" (1949), and \"Canto desesperado a la ceniza\" (1955). His literary personality has been studied by Eduardo Cautino Jordan in \"La personalidad literaria de Francisco Lluch Mora.\" His extensive bibliography has been written by Ana María Ortiz Salichs in \"Francisco Lluch Mora: bibliografía mínima.\"\n\nIn 1995, Lluch Mora received the award of \"Humanista del Año\" (Humanist of the Year) from the \"Fundación Puertorriqueña de las Humanidades.\" He was also Charter Member of \"Academia Puertorriqueña de la Lengua\" (Puerto Rican Academy of Language), the \"Academia de Artes y Ciencias\" (Academy of Arts and Sciences) and the \"Academia de Artes, Historia y Arqueología\" (Academy of Arts, History, and Archeology). He was also charter member of the \"Sociedad Puertorriqueña de Escritores\" (Puerto Rican Writers Society) and the \"Sociedad de Autores Puertorriqueños\" (Society of Puerto Rican Authors), among others. He received an honorary doctoral degree (Doctor Honoris Causa) from the Universidad Central del Caribe and the Universidad Mundial de Puerto Rico and was awarded the honor of \"Caballero de la Orden de San Juan Bautista\" from Puerto Rico, and \"Caballero de la Orden de la Cruz de Jerusalén\" from Rome.\n\nLluch Mora married Sylvia Doris Velez Catala on 6 February 1943 in Yauco.\n\nLluch Mora died 26 October 2006 in Ponce, Puerto Rico.\n\nAmong his better known works are: \n\nOn 1 November 2001 he was recognized by the Senate of Puerto Rico with Resolution Number 933. He is also recognized at Ponce's Park of Illustrious Ponce Citizens as one of Ponce's great historians.\n\n"}
{"id": "11069093", "url": "https://en.wikipedia.org/wiki?curid=11069093", "title": "Fred Alexander (historian)", "text": "Fred Alexander (historian)\n\nFrederick Alexander (known primarily as Fred Alexander) (12 April 1899 – 1996) was an Australian historian who specialised in foreign affairs and policy. He was the founding Head of the University of Western Australia's Department of History, where he was instrumental in the development of the history curriculum.\n\nThe son of a primary school headmaster, Fred Alexander was born in Victoria on 12 April 1899. He attended Melbourne High School, and in 1916 won an exhibition to attend lectures at Trinity College during his studied at the University of Melbourne, where he intended to gain a Bachelor of Laws degree. However, he developed an interest in history under the influence of Professor Ernest Scott, and deferred his law studies to obtain a Bachelor of Arts with First Class Honours in history. He then completed his third year of law studies, but in 1920 he won an Orient Line scholarship that enabled him to pursue studies at the University of Oxford's Balliol College.\n\nDuring his second year at Balliol, he suffered from a recurrent illness, and in 1923 he was advised by his doctors to take a long sea voyage. That year, he sailed for Melbourne; when his ship docked at Fremantle, Western Australia, he took the opportunity to visit Edward Shann, the foundation professor of History and Economics at the University of Western Australia. The following year, after returning to England, receiving the Herbertson Prize in History along with a M.A., and getting married, he received from Shann an offer of appointment as Assistant Lecturer at the University of Western Australia. He arrived in Perth in September 1924.\n\nIn 1949-50, he spent four months in South Africa as a Carnegie Fellow, an experience which caused him to concentrate on Commonwealth history. He retired in 1966, and later served as Chairman of the Library Board of Western Australia. The Alexander Library Building is named after him.\n\nFred Alexander was the author of a great many works. The following are a few of his better known publications:\n\n"}
{"id": "3266278", "url": "https://en.wikipedia.org/wiki?curid=3266278", "title": "Guido Calza", "text": "Guido Calza\n\nGuido Calza (April 21, 1888 – April 17, 1946 in Rome, Italy), born in Milan, Italy, was an Italian archaeologist whose work included excavations in Rome and at the port city of Ostia. Calza served as inspector of the Ostia excavations and as the director of excavations in the Forum Romanum and the Palatine Hill in Rome. He also oversaw the excavation of the Isola Sacra Necropolis.\n\nCalza was the son of Arturo Calza.\n\n"}
{"id": "7058999", "url": "https://en.wikipedia.org/wiki?curid=7058999", "title": "Historicity", "text": "Historicity\n\nHistoricity is the historical actuality of persons and events, meaning the quality of being part of history as opposed to being a historical myth, legend, or fiction. Historicity focuses on the true value of knowledge claims about the past (denoting historical actuality, authenticity, and factuality). The historicity of a claim about the past is its factual status.\n\nSome theoreticians characterize historicity as a dimension of all natural phenomena that take place in space and time. Other scholars characterize it as an attribute reserved to certain human phenomena, in agreement with the practice of historiography. Herbert Marcuse explained historicity as that which “defines history and thus distinguishes it from ‘nature’ or from the ‘economy’” and “signifies the meaning we intend when we say of something that is ‘historical’.” \n\nThe Blackwell Dictionary of Western Philosophy defines historicity as \"denoting the feature of our human situation by which we are located in specific concrete temporal and historical circumstances.\" For Wilhelm Dilthey, historicity identifies human beings as unique and concrete historical beings.\n\nQuestions regarding historicity concern not just the issue of \"what really happened,\" but also the issue of how modern observers can come to know \"what really happened.\" This second issue is closely tied to historical research practices and methodologies for analyzing the reliability of primary sources and other evidence. Because various methodologies thematize historicity differently, it's not possible to reduce historicity to a single structure to be represented. Some methodologies (for example historicism), can make historicity subject to constructions of history based on submerged value commitments.\nQuestions of historicity are particularly relevant to partisan or poetic accounts of past events. For example, the historicity of the Iliad has become a topic of debate because later archaeological finds suggest that the work was based on some true event.\n\nQuestions of historicity also arise frequently in relation to historical studies of religion. In these cases, value commitments can influence the choice of research methodology.\n\n"}
{"id": "14181749", "url": "https://en.wikipedia.org/wiki?curid=14181749", "title": "History of YouTube", "text": "History of YouTube\n\nYouTube was created by PayPal employees as a video-sharing website where users could upload, share and view content. The Internet domain name \"codice_1\" was activated on Monday, February 14, 2005 at 9:13 p.m.\n\nYouTube was founded by Chad Hurley, Steve Chen, and Jawed Karim, when they worked for PayPal. Prior to working for PayPal, Hurley studied design at the Indiana University of Pennsylvania; Chen and Karim studied computer science together at the University of Illinois at Urbana–Champaign. YouTube's initial headquarters was above a pizzeria and Japanese restaurant in San Mateo, California.\n\n<br>The domain name \"YouTube.com\" was activated on February 14, 2005 with video upload options being integrated on April 23, 2005. The first YouTube video, titled \"Me at the zoo,\" was uploaded on April 23, 2005, and shows co-founder Jawed Karim at the San Diego Zoo.\n\nYouTube began as an angel-funded enterprise working from a makeshift office in a garage. In November 2005, venture firm Sequoia Capital invested an initial $3.5 million, and Roelof Botha (a partner of the firm and former CFO of PayPal) joined the YouTube board of directors. In April 2006, Sequoia and Artis Capital Management invested an additional $8 million in the company, which had experienced significant growth in its first few months.\n\nDuring the summer of 2006, YouTube was one of the fastest growing sites on the World Wide Web, hosting more than 65,000 new video uploads. The site delivered an average of 100 million video views per day in July. It was ranked the fifth-most-popular website on Alexa, far out-pacing even MySpace's rate of growth. The website averaged nearly 20 million visitors per month according to Nielsen/NetRatings, with around 44% female and 56% male visitors. The 12- to 17-year-old age group was dominant. YouTube's pre-eminence in the online market was substantial. According to the website Hitwise.com, YouTube commanded up to 64% of the UK online video market.\n\nYouTube entered into a marketing and advertising partnership with NBC in June 2006.\n\nOn October 9, 2006, it was announced that the company would be purchased by Google for US$1.65 billion in stock, which was completed on November 13. At that time it was Google's second-largest acquisition. The agreement between Google and YouTube came after YouTube presented three agreements with media companies in an attempt to avoid copyright-infringement lawsuits. YouTube planned to continue operating independently, with its co-founders and 68 employees working within Google.\n\nGoogle's February 7, 2007 SEC filing revealed the breakdown of profits for YouTube's investors after the sale to Google. In 2010, Chad Hurley's profit was more than $395 million while Steve Chen's profit was more than $326 million.\n\nIn 2006, \"Time Magazine\" featured a YouTube screen with a large mirror as its annual 'Person of the Year'. It cited user-created media such as that posted on YouTube and featured the site's originators along with several content creators. \"The Wall Street Journal\" and \"The New York Times\" also reviewed posted content on YouTube in 2006, with particular regard to its effects on corporate communications and recruitment. \"PC World Magazine\" named YouTube the ninth of its Top 10 Best Products of 2006. In 2007, both \"Sports Illustrated\" and \"Dime Magazine\" featured positive reviews of a basketball highlight video titled, \"The Ultimate Pistol Pete Maravich MIX\".\n\nIt is estimated that in 2007, YouTube consumed as much bandwidth as the entire Internet in 2000.\n\nOriginating in 2007, the YouTube Awards are annual awards given out in recognition of the best YouTube videos of the preceding year as voted by the YouTube community.\n\nOn July 23, 2007 and November 28, 2007, CNN and YouTube produced televised presidential debates in which Democratic and Republican US presidential hopefuls fielded questions submitted through YouTube.\n\nIn November 2008, YouTube reached an agreement with MGM, Lions Gate Entertainment, and CBS, allowing the companies to post full-length films and television episodes on the site, accompanied by advertisements in a section for US viewers called \"Shows\". The move was intended to create competition with websites such as Hulu, which features material from NBC, Fox, and Disney.\n\nYouTube was awarded a 2008 Peabody Award and cited as being \"a 'Speakers' Corner' that both embodies and promotes democracy\".\n\nIn early 2009, YouTube registered the domain codice_2 for videos embedded on United States federal government websites. In November of the same year, YouTube launched a version of \"Shows\" available to UK viewers, offering around 4,000 full-length shows from more than 60 partners.\n\n\"Entertainment Weekly\" placed YouTube on its end-of-the-decade \"best-of\" list In December 2009, describing it as: \"Providing a safe home for piano-playing cats, celeb goof-ups, and overzealous lip-synchers since 2005.\"\n\nIn January 2010, YouTube introduced an online film rentals service which is currently available only to users in the US, Canada and the UK. The service offers over 6,000 films. In March 2010 YouTube began free streaming of certain content, including 60 cricket matches of the Indian Premier League. According to YouTube, this was the first worldwide free online broadcast of a major sporting event.\n\nOn March 31, 2010, YouTube launched a new design with the aim of simplifying the interface and increasing the time users spend on the site. Google product manager Shiva Rajaraman commented: \"We really felt like we needed to step back and remove the clutter.\" In May 2010, it was reported that YouTube was serving more than two billion videos a day, which was \"nearly double the prime-time audience of all three major US television networks combined\". In May 2011, YouTube reported on the company blog that the site was receiving more than three billion views per day. In January 2012, YouTube stated that the figure had increased to four billion videos streamed per day.\n\nAccording to May 2010 data published by market research company comScore, YouTube was the dominant provider of online video in the United States, with a market share of roughly 43 percent and more than 14 billion videos viewed during May.\n\nIn October 2010, Hurley announced that he would be stepping down as the chief executive officer of YouTube to take an advisory role, with Salar Kamangar taking over as the head of the company.\n\nJames Zern, a YouTube software engineer, revealed in April 2011 that 30 percent of videos accounted for 99 percent of views on the site.\n\nDuring November 2011, the Google+ social networking site was integrated directly with YouTube and the Chrome web browser, allowing YouTube videos to be viewed from within the Google+ interface. In December 2011, YouTube launched a new version of the site interface, with the video channels displayed in a central column on the home page, similar to the news feeds of social networking sites. At the same time, a new version of the YouTube logo was introduced with a darker shade of red, which was the first change in design since October 2006.\n\nIn 2012, YouTube said that roughly 60 hours of new videos are uploaded to the site every minute, and that around three-quarters of the material comes from outside the U.S. The site has eight hundred million unique users a month.\n\nStarting from 2010 and continuing to the present, Alexa ranked YouTube as the third most visited website on the Internet after Google and Facebook.\n\nIn late 2011 and early 2012, YouTube launched over 100 \"premium\" or \"original\" channels. It was reported the initiative cost $100 million. Two years later, in November 2013, it was documented that the landing page of the original channels became a 404 error page. Despite this, original channels such as SourceFed and Crash Course were able to become successful.\n\nAn algorithm change was made in 2012 that replaced the view-based system for a watch time-based one that is credited for causing a surge in the popularity of gaming channels.\n\nIn October 2012, for the first-time ever, YouTube offered a live stream of the U.S. presidential debate and partnered with ABC News to do so.\n\nOn , The YouTube slogan (Broadcast Yourself) was taken down due to the live stream of the U.S. presidential debate.\n\nYouTube relaunched its design and layout on December 4, 2012 to be very similar to the mobile and tablet app version of the site. On December 21, 2012, Gangnam Style became the first YouTube video to surpass one billion views.\n\nIn March 2013, the number of unique users visiting YouTube every month reached 1 billion. In the same year, YouTube continued to reach out to mainstream media, launching YouTube Comedy Week and the YouTube Music Awards. Both events were met with negative to mixed reception. In November 2013, YouTube's own YouTube channel had surpassed Felix Kjellberg's PewDiePie channel to become the most subscribed channel on the website. This was due to auto-suggesting new users to subscribe to the channel upon registration.\n\nOn April 3, 2018, a shooting took place at YouTube headquarters.\n\nOn June 19, 2007, Google CEO Eric Schmidt was in Paris to launch the new localization system. The interface of the website is available with localized versions in 89 countries, one territory (Hong Kong) and a worldwide version.\n\nGoogle aims to compete with local video-sharing websites like Dailymotion in France. It also made an agreement with local television stations like M6 and France Télévisions to legally broadcast video content.\n\nOn October 17, 2007, it was announced that a Hong Kong version had been launched. YouTube's Steve Chen said its next target will be Taiwan.\n\nYouTube was blocked from Mainland China from October 18 due to the censorship of the Taiwanese flag. URLs to YouTube were redirected to China's own search engine, Baidu. It was subsequently unblocked on October 31.\n\nThe YouTube interface suggests which local version should be chosen on the basis of the IP address of the user. In some cases, the message \"This video is not available in your country\" may appear because of copyright restrictions or inappropriate content. The interface of the YouTube website is available in 76 language versions, including Amharic, Albanian, Armenian, Bengali, Burmese, Khmer, Kyrgyz, Laotian, Mongolian, Persian and Uzbek, which do not have local channel versions. Access to YouTube was blocked in Turkey between 2008 and 2010, following controversy over the posting of videos deemed insulting to Mustafa Kemal Atatürk and some material offensive to Muslims. In October 2012, a local version of YouTube was launched in Turkey, with the domain codice_3. The local version is subject to the content regulations found in Turkish law. In March 2009, a dispute between YouTube and the British royalty collection agency PRS for Music led to premium music videos being blocked for YouTube users in the United Kingdom. The removal of videos posted by the major record companies occurred after failure to reach agreement on a licensing deal. The dispute was resolved in September 2009. In April 2009, a similar dispute led to the removal of premium music videos for users in Germany.\n\nBefore being purchased by Google, YouTube declared that its business model was advertisement-based, making 15 million dollars per month.\n\nGoogle did not provide detailed figures for YouTube's running costs, and YouTube's revenues in 2007 were noted as \"not material\" in a regulatory filing. In June 2008, a \"Forbes\" magazine article projected the 2008 revenue at $200 million, noting progress in advertising sales.\n\nSome industry commentators have speculated that YouTube's running costs (specifically the network bandwidth required) might be as high as 5 to 6 million dollars per month, thereby fuelling criticisms that the company, like many Internet startups, did not have a viably implemented business model. Advertisements were launched on the site beginning in March 2006. In April, YouTube started using Google AdSense. YouTube subsequently stopped using AdSense but has resumed in local regions.\n\nAdvertising is YouTube's central mechanism for gaining revenue. This issue has also been taken up in scientific analysis. Don Tapscott and Anthony D. Williams argue in their book \"Wikinomics\" that YouTube is an example for an economy that is based on mass collaboration and makes use of the Internet.\n\nTapscott and Williams argue that it is important for new media companies to find ways to make a profit with the help of peer-produced content. The new Internet economy, (that they term Wikinomics) would be based on the principles of \"openness, peering, sharing, and acting globally\". Companies could make use of these principles in order to gain profit with the help of Web 2.0 applications: \"Companies can design and assemble products with their customers, and in some cases customers can do the majority of the value creation\". Tapscott and Williams argue that the outcome will be an economic democracy.\n\nThere are other views in the debate that agree with Tapscott and Williams that it is increasingly based on harnessing open source/content, networking, sharing, and peering, but they argue that the result is not an economic democracy, but a subtle form and deepening of exploitation, in which labour costs are reduced by Internet-based global outsourcing.\n\nThe second view is e.g. taken by Christian Fuchs in his book \"Internet and Society\". He argues that YouTube is an example of a business model that is based on combining the gift with the commodity. The first is free, the second yields profit. The novel aspect of this business strategy is that it combines what seems at first to be different, the gift and the commodity. YouTube would give free access to its users, the more users, the more profit it can potentially make because it can in principle increase advertisement rates and will gain further interest of advertisers. YouTube would sell its audience that it gains by free access to its advertising customers.\n\nIn June 2009, \"BusinessWeek\" reported that, according to San Francisco-based IT consulting company RampRate, YouTube was far closer to profitability than previous reports, including the April 2009, projection by investment bank Credit Suisse estimating YouTube would lose as much as $470 million in 2009. RampRate's report pegged that number at no more than $174 million.\n\nIn May 2013, YouTube launched a pilot program to begin offering some content providers the ability to charge $0.99 per month or more for certain channels, but the vast majority of its videos would remain free to view.\n\n\n"}
{"id": "192713", "url": "https://en.wikipedia.org/wiki?curid=192713", "title": "History of the British canal system", "text": "History of the British canal system\n\nThe British canal system of water transport played a vital role in the United Kingdom's Industrial Revolution at a time when roads were only just emerging from the medieval mud and long trains of packhorses were the only means of \"mass\" transit by road of raw materials and finished products. (It was no accident that amongst the first canal promoters were the pottery manufacturers of Staffordshire.) The UK was the first country to acquire a nationwide canal network.<ref name=\"N/A 1978 990\"></ref>\n\nThe canal system dates to Roman Britain, but was largely used for irrigation or to link rivers. The navigable water network in the British Isles grew as the demand for industrial transport increased. It grew rapidly at first, and became an almost completely connected network covering the South, Midlands, and parts of the North of England and Wales. There were canals in Scotland, but they were not connected to the English canals or, generally, to each other (the main exception being the Monkland Canal, the Union Canal and the Forth and Clyde Canal which connected the River Clyde and Glasgow to the River Forth and Edinburgh). As building techniques improved, older canals were improved by straightening, embankments, cuttings, tunnels, aqueducts, inclined planes, and boat lifts, which together snipped many miles and locks, and therefore hours and cost, from journeys. However, there was often fierce opposition to the building.\n\nThe modern canal network came into being because the Industrial Revolution (which began in Britain during the mid-18th century) demanded an economic and reliable way to transport goods and commodities in large quantities. Some 29 river navigation improvements took place in the 16th and 17th centuries starting with the Thames locks and the River Wey Navigation. The biggest growth was in the so-called \"narrow\" canals which extended water transport to the emerging industrial areas of the Staffordshire potteries and Birmingham as well as a network of canals joining Yorkshire and Lancashire and extending to London.\n\nThe 19th century saw some major new canals such as the Caledonian Canal and the Manchester Ship Canal. By the second half of the 19th century, many canals were increasingly becoming owned by railway companies or competing with them, and many were in decline, with decreases in mile-ton charges to try to remain competitive. After this, the less successful canals (particularly narrow-locked canals, whose boats could only carry about thirty tons) failed quickly.\n\nThe 20th century brought competition from road haulage, and only the strongest canals survived until the Second World War. After the war, there was a rapid decline in trade on all the remaining canals, and by the mid 1960s only a token traffic was left, even on the widest and most industrial waterways.\n\nIn the 1960s the infant canal leisure industry was only just sufficient to prevent the closure of the remaining canals, but then the pressure to maintain canals for leisure purposes increased. From the 1970s, increasing numbers of closed canals were restored by enthusiast volunteers. The success of these projects has led to the funding and use of contractors to complete large restoration projects and complex civil engineering projects such as the restoration of the Victorian Anderton Boat Lift and the new Falkirk Wheel rotating lift.\n\nRestoration projects by volunteer-led groups continue. There is now a substantial network of interconnecting, fully navigable canals across the country. In places, serious plans are in progress by the Environment Agency and British Waterways Board, later the Canal & River Trust, for building new canals to expand the network, link isolated sections, and create new leisure opportunities for navigating \"canal rings\", for example the Fens Waterways Link and the Bedford and Milton Keynes Waterway.\n\nThe first British canals were built in Roman times as irrigation or land drainage canals or short connecting spurs between navigable rivers, such as the Foss Dyke, Car Dyke and Bourne-Morton Canal; all in Lincolnshire. \"See Roman Britain\" and \"list of Roman canals\".\n\nA spate of building projects, such as castles, monasteries and churches, led to the improvement of rivers for the transportation of building materials. Various Acts of Parliament were passed regulating transportation of goods, tolls and horse towpaths for various rivers. These included the rivers Severn, Witham, Trent and Yorkshire Ouse. The first Act for navigational improvement in England was in 1425, for improvement of the river Lea, a major tributary of the River Thames.\n\nIn the post-medieval period, some natural waterways were \"canalised\" or improved for boat traffic in the 16th century. The first Act of Parliament was obtained by the City of Canterbury in 1515, to extend navigation on the River Stour in Kent, followed by the River Exe in 1539, which led to the construction in 1566 of a new channel, the Exeter Canal. Simple flash locks were provided to regulate the flow of water and allow loaded boats to pass through shallow waters by admitting a rush of water, but these were not purpose-built canals as we understand them today.\n\nThe transport system that existed before the canals were built consisted of coastal shipping and horses and carts struggling along mostly unsurfaced mud roads (although there were some surfaced turnpike roads). There was also a small amount of traffic carried along navigable rivers. In the 17th century, as early industry started to expand, this transport situation was highly unsatisfactory. The restrictions of coastal shipping and river transport were obvious, and horses and carts could only carry one or two tons of cargo at a time. The poor state of most of the roads meant that they could often become unusable after heavy rain. Because of the small loads that could be carried, supplies of essential commodities such as coal and iron ore were limited, and this kept prices high and restricted economic growth. One horse-drawn canal barge could carry about thirty tonnes at a time, faster than road transport and at half the cost.\n\nSome 29 river navigation improvements took place in the 16th and 17th centuries. In 1605, the government of King James I established the Oxford-Burcot Commission, which began to improve the system of locks and weirs on the River Thames, which were opened between Oxford and Abingdon by 1635. In 1635 Sir Richard Weston was appointed to develop the River Wey Navigation, making Guildford accessible by 1653. In 1670 the Stamford Canal opened, indistinguishable from 18th century examples with a dedicated cut and double-door locks. In 1699 legislation was passed to permit the Aire & Calder Navigation which was opened 1703, and the Trent Navigation which was built by George Hayne and opened in 1712. Subsequently, the Kennet built by John Hore opened in 1723, the Mersey and Irwell opened in 1725, and the Bristol Avon in 1727. John Smeaton was the engineer of the Calder & Hebble which opened in 1758, and a series of eight pound locks was built to replace flash locks on the River Thames between Maidenhead and Reading, beginning in 1772. The net effect of these was to bring most of England, with the notable exceptions of Birmingham and Staffordshire, within of a waterway.\n\nThe modern canal system was mainly a product of the 18th and early 19th centuries. It came into being because the Industrial Revolution (which began in Britain during the mid-18th century) demanded an economic and reliable way to transport goods and commodities in large quantities.\n\nBy the early 18th century, river navigations such as the Aire and Calder Navigation were becoming quite sophisticated, with pound locks and longer and longer \"cuts\" (some with intermediate locks) to avoid circuitous or difficult stretches of rivers. Eventually, the experience of building long multi-level cuts with their own locks gave rise to the idea of building a \"pure\" canal, a waterway designed on the basis of where goods needed to go, not where a river happened to be.\n\nThe claim for the first pure canal in Great Britain is debated between \"Sankey\" and \"Bridgewater\" supporters. The first true canal in the United Kingdom was the Newry Canal in Northern Ireland constructed by Thomas Steers in 1741.\n\nThe Sankey Brook Navigation, which connected St Helens with the River Mersey, is often claimed as the first modern \"purely artificial\" canal, because although it was originally a scheme to make the Sankey Brook navigable, it included an entirely new artificial channel that was effectively a canal along the Sankey Brook valley. However, \"Bridgewater\" supporters point out that the last quarter-mile (400 m) of the navigation is indeed a canalised stretch of the Brook, and that it was the Bridgewater Canal (less obviously associated with an existing river) that captured the popular imagination and inspired further canals.\n\nIn the mid-18th century the 3rd Duke of Bridgewater, who owned a number of coal mines in northern England, wanted a reliable way to transport his coal to the rapidly industrialising city of Manchester. He commissioned the engineer James Brindley to build a canal to do just that. Brindley's design included an aqueduct carrying the canal over the River Irwell. This was an engineering wonder which immediately attracted tourists. The construction of this canal was funded entirely by the Duke and it was called the Bridgewater Canal. It opened in 1761 and was the longest canal constructed in Britain to that date.\n\nThe new canals proved highly successful. The boats on the canals were horse-drawn with a towpath alongside the canal for the horse to walk along. This horse-drawn system proved to be highly economical and became standard across the British canal network. Commercial horse-drawn canal boats could be seen on the UK's canals until as late as the 1950s, although by then diesel powered boats, often towing a second unpowered boat, had become standard.\n\nThe canal boats could carry thirty tons at a time with only one horse pulling - more than ten times the amount of cargo per horse that was possible with a cart. Because of this huge increase in supply, the Bridgewater Canal reduced the price of coal in Manchester by nearly two-thirds within just a year of its opening. The Bridgewater Canal was also a huge financial success: it repaid the cost of its construction within just a few years.\n\nThis success proved the viability of canal transport, and soon industrialists in many other parts of the country wanted canals. After the Bridgewater Canal, the early canals were built by groups of private individuals with an interest in improving communications. In Staffordshire the famous potter Josiah Wedgwood saw an opportunity to bring bulky cargoes of clay to his factory doors, and to transport his fragile finished goods to market in Manchester, Birmingham or further afield by water, minimising breakages. Within just a few years of the Bridgewater's opening, an embryonic national canal network came into being, with the construction of canals such as the Oxford Canal and the Trent & Mersey Canal.\n\nThe new canal system was both cause and effect of the rapid industrialisation of the Midlands and the north. The period between the 1770s and the 1830s is often referred to as the \"Golden Age\" of British canals.\n\nFor each canal, an Act of Parliament was necessary to authorise construction, and as people saw the high incomes achieved from canal tolls, canal proposals came to be put forward by investors interested in profiting from dividends, at least as much as by people whose businesses would profit from cheaper transport of raw materials and finished goods.\n\nIn a further development, there was often out-and-out speculation, in which people would try to buy shares in a newly floated company simply to sell them on for an immediate profit, regardless of whether the canal was ever profitable, or even built. During this period of \"canal mania\", huge sums were invested in canal building, and although many schemes came to nothing, the canal system rapidly expanded to nearly 4,000 miles (over 6,400 kilometres) in length.\n\nMany rival canal companies were formed and competition was rampant. Perhaps the best example was Worcester Bar in Birmingham, a point where the Worcester and Birmingham Canal and the Birmingham Canal Navigations Main Line were only apart. For many years, a dispute about tolls meant that goods travelling through Birmingham had to be portaged from boats in one canal to boats in the other.\n\nFor the first era of canals until toll cuts to combat railway competition family boating did not exist. Crews were all male and their families lived in cottages on the bank. The practice of all male crews for steamers continued until after the First World War. Wives and children came aboard as extra labour and to save rental costs during the latter part of the 19th century. About this time boat decoration of \"Roses and Castles\" began to appear.\nDuring this period, whole families lived aboard the boats. They were often marginalised from land-based society. The church of St Thomas the Martyr, Oxford, under the curacy of John Jones, acquired in 1839 an innovative \"Boatman's Floating Chapel\", a houseboat to serve the families working on the river and the canals. This boat was St Thomas' first chapel of ease; it was donated by H. Ward, a local coal merchant, and used until it sank in 1868. It was replaced by a chapel dedicated to St Nicholas, which remained in use until 1892.\n\nOthers tried to care for the boat people. Mary Ward (1885–1972) acted as a nurse for decades from the rope shop at Stoke Bruerne.\n\nFor reasons of economy and the constraints of 18th-century engineering technology, the early canals were built to a narrow width. The standard for the dimensions of narrow canal locks was set by Brindley with his first canal locks, those on the Trent and Mersey Canal in 1776. These locks were long by wide. The narrow width was perhaps set by the fact that he was only able to build Harecastle Tunnel to accommodate wide boats.\n\nHis next locks were wider. He built locks long by wide when he extended the Bridgewater Canal to Runcorn, where the canal's only locks lowered boats to the River Mersey.\n\nThe narrow locks on the Trent and Mersey limited the width (beam) of the boats (which came to be called \"narrowboats\"), and thus limited the quantity of the cargo they could carry to around thirty tonnes. This decision would in later years make the canal network economically uncompetitive for freight transport, and by the mid 20th century it was no longer possible to work a thirty-tonne load economically.\n\nBrindley believed it would be possible to use canals to link the four great rivers of England: the Mersey, Trent, Severn and Thames. The Trent and Mersey Canal was the first part of this ambitious network, but although he and his assistants surveyed the whole potential system, he did not live to see it completed - coal was finally transported from the Midlands to the Thames at Oxford in January 1790, eighteen years after his death. Development of the network was left to other engineers, notably Thomas Telford, whose Ellesmere Canal helped link the Severn and the Mersey.\n\nThe bulk of the canal system was built in the industrial Midlands and the north of England, where navigable rivers most needed extending and connecting, and heavy cargoes of manufactured goods, raw materials or coal most needed carrying. Most of the traffic on the canal network was internal. However, the network linked with coastal port cities such as London, Liverpool, and Bristol, where cargo could be exchanged with seagoing ships for import and export.\n\nThe North West and West Midlands regions contain a dense network of canals.\n\nThe great manufacturing cities of Manchester and Birmingham were major economic drivers for the 'canal mania' which reached its peak in 1793, and both benefited from a network of canals, most of which survive.\n\nIn the industrial conurbation of Birmingham and the Black Country, a dense network of nearly of canals, dubbed the Birmingham Canal Navigations (BCN) was constructed to serve the network of industries.\n\nA similarly dense network of canals was constructed in the Greater Manchester area, serving the local textile industries: The Bridgewater, Rochdale, and Ashton canals were examples of these.\n\nManchester had a canal connection to the nearby port of Liverpool via the Leeds and Liverpool Canal. However, in the nineteenth century, Manchester's merchants became dissatisfied with the poor service and high charges offered by the Liverpool docks, and the near-monopoly of the railways. They decided to bypass the Liverpool monopoly on coastal trade by converting a section of the Irwell into the Manchester Ship Canal, which opened in 1894, turning Manchester into an inland port in its own right.\n\nBirmingham's canals linked to the national network in several directions. To the north, several trunk cross-country canals, linking Birmingham to Manchester were constructed, including the Trent and Mersey and Shropshire Union Canal. The Coventry Canal, the Oxford Canal, and what is now the Grand Union Canal linked southwards to London. And to the south-west, the Worcester & Birmingham and Staffordshire & Worcestershire canals linked to the River Severn.\n\nThe industrial revolution saw Yorkshire towns and cities such as Leeds, Sheffield, Bradford and Huddersfield develop large textile and coal mining industries, which required an efficient transport system. As early as the late 17th century, the Aire and Calder and Calder and Hebble navigations had been canalised, allowing navigation from Leeds to the Humber Estuary, whereas the River Don Navigation connected Sheffield to the Humber.\n\nLater in the 18th century, the Leeds and Liverpool Canal was constructed, creating an east-west link, giving access to the port at Liverpool allowing export of finished goods. The Rochdale and Huddersfield Broad and Narrow canals connected to Manchester.\n\nThe East Midlands cities of Nottingham and Leicester were connected to the national network via the canalised River Trent and River Soar, whilst Leicester had a connection to London via the Grand Union Canal.\n\nBy contrast, London was a port, served by already-navigable rivers like the Thames and the River Lea, (which was canalised). It needed canals only to take goods in and out from seagoing ships, where such rivers were unavailable.\n\nAs early as 1790 London was linked to the national network via the River Thames and the Oxford Canal. A more direct route between London and the national canal network; the Grand Junction Canal opened in 1805.\n\nApart from this, relatively few canals were built in London itself; the few that were included the Limehouse Cut, the Regent's Canal and the now defunct Grand Surrey and Croydon canals.\n\nTo the south of London, the Wey and Arun Canal linked London to Portsmouth. However, the canal was a financial failure and closed in 1871.\n\nThe South West of England had several east-west \"cross-country\" canals, which connected the River Thames to the River Severn and the River Avon, allowing the cities of Bristol and Bath to be connected to London: These were Thames and Severn Canal which linked to the Stroudwater Navigation, the Kennet and Avon Canal and the Wilts and Berks Canal, which linked to these three rivers; all of these linked into the national canal system via the Oxford Canal and the River Severn (via the Worcester & Birmingham and Staffordshire & Worcestershire canals). All of these east-west canals fell derelict in the early 20th century, and only the Kennet and Avon is today navigable, having been restored.\n\nA few self-contained canals, not connected to the national system, were built in Devon and Cornwall, such as the Bude Canal and the St. Columb Canal. The same was true for South Wales, with several isolated canals running along the South Wales Valleys. These included the Swansea Canal, the Neath and Tennant Canal, the Glamorganshire Canal and the Monmouthshire & Brecon Canal. Nearly all of these canals were constructed to serve local industries, and fell derelict when faced with competition from other modes of transport.\n\nWithin Scotland, the Forth and Clyde Canal and the Union Canal connected the major cities in the industrial Central Belt; they also provide a short cut for boats to cross between the west and the east without a sea voyage. The Caledonian Canal provided a similar function in the Highlands of Scotland. The Crinan Canal avoided the need for a long diversion around the Kintyre peninsula, and the Glasgow, Paisley and Johnstone Canal was intended to link these three places directly to the west coast of Scotland, but never reached beyond Johnstone. The Monkland Canal was conceived in 1769 by tobacco merchants and other entrepreneurs as a way of bringing cheap coal into Glasgow from the coalfields of the Monklands area.\n\nOn the majority of British canals, the canal-owning companies did not own or run a fleet of boats since this was usually prohibited by the Acts of Parliament setting them up to prevent monopolies developing. Instead, they charged private operators tolls to use the canal. These tolls were also usually regulated by the Acts. From these tolls they would try, with varying degrees of success, to maintain the canal, pay back initial loans and pay dividends to their shareholders.\n\nIn winter special icebreaker boats with reinforced hulls would be used to break the ice. The boats used on canals were usually derived from local coasting or river craft, but on the narrow canals the narrowboat was the standard. Their length came from the boats used on the Mersey estuary, with their width of chosen as half that of existing boats, and adopted to make canals cheaper to build. All boats on the canals were horsedrawn. Packet boats carried packages up to in weight as well as passengers at relatively high speed day and night. To compete with railways, the flyboat was introduced, cargo-carrying boats working day and night. These boats were crewed by three men, who operated a watch system whereby two men worked while the other slept. Horses were changed regularly. When steam boats were introduced in the late nineteenth century, crews were enlarged to four. The boats were owned and operated by individual carriers, or by carrying companies who would pay the captain a wage depending on the distance travelled, and the amount of cargo.\n\nFrom about 1840 railways began to threaten canals, as they could not only carry more than the canals but could transport people and goods far more quickly than the walking pace of the canal boats. Most of the investment that had previously gone into canal building was diverted into railway building.\n\nCanal companies were unable to compete against the speed of the new railways, and in order to survive, they had to slash their prices. This put an end to the huge profits that canal companies had enjoyed before the coming of the railways, and also had an effect on the boatmen who faced a drop in wages. Flyboat working virtually ceased, as it could not compete with the railways on speed and the boatmen found they could only afford to keep their families by taking them with them on the boats. This became standard practice across the canal system, with in many cases families with several children living in tiny boat cabins, creating a considerable community of boat people. Though this community ostensibly had much in common with Gypsies both communities strongly resisted any such comparison, and surviving boat people feel deeply insulted if described as 'water gypsies'.\n\nBy the 1850s the railway system had become well established and the amount of cargo carried on the canals had fallen by nearly two-thirds, lost mostly to railway competition. In many cases struggling canal companies were bought out by railway companies. Sometimes this was a tactical move by railway companies to gain ground in their competitors' territory, but sometimes canal companies were bought out, either to close them down and remove competition or to build a railway on the line of the canal. A notable example of this is the Croydon Canal. Larger canal companies survived independently and were able to continue to make profits. The canals survived through the 19th century largely by occupying the niches in the transport market that the railways had missed, or by supplying local markets such as the coal-hungry factories and mills of the big cities.\n\nOverall, the canals adapted to the appearance of railways and in 1900 the canal network differed little from its extent in 1830.\n\nDuring the 19th century in much of continental Europe the canal systems of many countries such as France, Germany and the Netherlands were drastically modernised and widened to take much larger boats, often able to transport up to two thousand tonnes, compared to the thirty to one hundred tonnes that was possible on the much narrower British canals. As it is economic to transport freight by canal only if this is done in bulk, the widening ensured that in many of these countries, canal freight transport is still economically viable.\n\nThis canal modernisation never occurred on a large scale in the UK, mainly because of the power of the railway companies who owned most of the canals and saw no reason to invest in a competing, and from their point of view obsolete, form of transport. In view of this attitude, there was little point in the non-railway owned canals modernising, since they controlled only parts of the system. The only significant exception to this was the modernisation carried out on the Grand Union Canal in the 1930s. Thus almost uniquely in Europe, many of the UK's canals remain as they have been since the 18th and 19th century: mostly operated with narrowboats less than wide and long (although in parts of the country slightly larger canals were constructed, called 'broad' or 'wide' canals, which could take boats that were wide and long). A major exception to this stagnation was the Manchester Ship Canal, newly built in the 1890s using the existing River Irwell and River Mersey, to take ocean-going ships into the centre of Manchester via its neighbour Salford.\n\nThe canal network gradually declined. During the early 20th century, especially in the 1920s and 1930s, many canals, mostly in rural areas, were abandoned due to falling traffic, caused mainly by competition from road transport. However, the main network saw brief surges in use during the First and Second World Wars and still carried a substantial amount of freight until the early 1950s. The final blow was delivered by technological change.\n\nMost of the canal system and inland waterways were nationalised in 1948, along with the railways, under the British Transport Commission, whose subsidiary Docks and Inland Waterways Executive managed them into the 1950s. A report in 1955 by the British Transport Commission placed the canals in the UK into three categories according to their economic prospects; waterways to be developed, waterways to be retained, and waterways having insufficient commercial prospects to justify their retention for navigation. During the 1950s and 1960s freight transport on the canals declined rapidly in the face of mass road transport, and several more canals were abandoned during this period. Most of the traffic on the canals by this time was in coal delivered to waterside factories which had no other convenient access. In the 1950s and 60s, these factories either switched to using other fuels, often because of the Clean Air Act of 1956, or closed completely. The last regular long distance narrow boat carrying contract, to a jam factory near London, ended in 1971, although lime juice continued to be carried between Brentford and Boxmoor until 1981, substantial tonnages of aggregates were carried by narrow boat subsequently on the Grand Union (River Soar) until 1996 and more recently between Denham and West Drayton.\n\nUnder the Transport Act of 1962, the canals were transferred in 1963 to the British Waterways Board (BWB), which later became British Waterways, and the railways to the British Railways Board (BRB). In the same year a remarkably harsh winter saw many boats frozen into their moorings, and unable to move for weeks at a time. This was one of the reasons given for the decision by BWB to formally cease most of its narrow boat carrying on the canals - with boats and traffics transferred to a private operator, Willow Wren Canal Transport services. By this time the canal network had shrunk to just two thousand miles (3,000 kilometres), half the size it was at its peak in the early 19th century. However, the basic network was still intact; many of the closures were of duplicate routes or branches.\n\nThe Transport Act 1968 classified the nationalised waterways as:\n\nBritish Waterways Board was required, under the Act, to keep Commercial Waterways, mainly in the north-east, fit for commercial use; and Cruising Waterways fit for cruising. However, these obligations were subject to the caveat of being by the most economical means. There was no requirement to maintain Remainder waterways or keep them in a navigable condition; they were to be treated in the most economic way possible, which could mean abandonment. British Waterways could also change the classification of an existing waterway. Parts, or all, of a Remainder Waterway canal, could also be transferred to local authorities, etc.; and this transfer could, as happened, allow roads and motorways to be built over them, mitigating the need to provide (expensive) accommodation bridges or aqueducts. The act also allowed local authorities to contribute to the upkeep of Remainder Waterways.\n\nThough commercial use of the UK's canals declined after the Second World War, recreational use gradually increased as people had more leisure time and disposable income. The establishment in 1946 of a group called the Inland Waterways Association by L. T. C. Rolt and Robert Aickman has helped revive interest in the UK's canals to the point where they are a major leisure destination.\n\nSince the formation of the Basingstoke Canal Purchasing Committee in March 1949, waterway restoration organisations have returned many hundreds of miles of abandoned and remainder canals to use, and work is still ongoing to save many more. Many restoration projects have been led by local canal societies or trusts, who were initially formed to fight the closure of a remainder waterway or to save an abandoned canal from further decay. They now work with local authorities and landowners to develop restoration plans and secure funding. The physical work is sometimes done by contractors, sometimes by volunteers. In 1970 the Waterway Recovery Group was formed to co-ordinate volunteer efforts on canals and river navigation's throughout the United Kingdom.\n\nBritish Waterways began to see the economic and social potential of canalside development, and moved from hostility towards restoration, through neutrality, towards a supportive stance. Whilst British Waterways was broadly supportive of restoration, its official policy was that it would not take on the support of newly restored navigations unless they came with a sufficient dowry to pay for their ongoing upkeep. In effect, this meant either reclassifying the Remainder Waterway as a Cruising Waterway or entering into an agreement for another body to maintain the waterway.\n\nThere has also been a movement to redevelop canals in inner city areas, such as Birmingham, Manchester, Salford and Sheffield, which have both numerous waterways and urban blight. In these cities, waterways redevelopment provides a focus for successful commercial/residential developments such as Gas Street Basin in Birmingham, Castlefield Basin and Salford Quays in Manchester, Victoria Quays in Sheffield. However, these developments are sometimes controversial. In 2005 environmentalists complained that housing developments on London's waterways threatened the vitality of the canal system.\n\nToday the major majority of canals in England and Wales are managed by the Canal & River Trust which, unlike its predecessor British Waterways, tries to have a more positive view on canal restoration and in some cases actively supports ongoing restoration projects such as the restoration projects on the Manchester Bolton & Bury Canal and the Grantham Canal.\n\n\n"}
{"id": "8001787", "url": "https://en.wikipedia.org/wiki?curid=8001787", "title": "Ibn Furtu", "text": "Ibn Furtu\n\nAhmad b. Furtu or Ibn Furtu (sometimes also called Ibn Fartuwa) lived in the sixteenth century. He was the grand Imam of the Bornu Empire and the chronicler of \"Mai\" Idris Alooma (1564–1596).\n\nHe wrote two chronicles in Arabic, \"K. ghazawat Barnu\" (\"The Book of the Bornu Wars\") in 1576 and \"K. ghazawat Kanei\" (\"The Book of the Kanem Wars\") in 1578. The first book describes in geographical order the military expeditions of \"Mai\" Idris Alooma: 1. against the Sao-Gafata in the region of the Komadugu Yobe; 2. against the town of Amsaka south of Lake Chad; 3. against the town of Kano west of Bornu; 4. against the Tuareg of Aïr; 5. against the Margi and against Mandara south of Lake Chad; 6. against the Ngizim west of Bornu and 7. against the Sao-Tatala at the edge of Lake Chad and against some towns of the Kotoko. Except a few details on the military achievements of the five predecessors of Idris Alooma he focusses his attention on the expeditions of his Sultan during the first twelve years of his reign. The book on the Kanem wars deals with seven consecutive expeditions against the Bulala from ca. 1573 to 1578. Information on earlier events at the beginning and the end of the book concern the destruction of the national relic called Mune by Dunama Dabbalemi (1203–1242), the expulsion of the Sayfawa from Kanem by the Bulala and the temporary reoccupation of the ancient capital of Kanem Njimi by Idris Katakarmabe (1487–1509). Some classical poems and quotations from lexicographical books bear witness of the solid education of the author. His somewhat contrived style is characterized by its archaism.\n\n\n"}
{"id": "241528", "url": "https://en.wikipedia.org/wiki?curid=241528", "title": "Jacob Bronowski", "text": "Jacob Bronowski\n\nJacob Bronowski (18 January 1908 – 22 August 1974) was a Polish-born British mathematician and historian. He is best known for developing a humanistic approach to science, and as the presenter and writer of the thirteen part 1973 BBC television documentary series, and accompanying book, \"The Ascent of Man\", which led to his regard as \"one of the world's most celebrated intellectuals\".\n\nBronowski's family moved to Germany and then to England while he was a child. In England won a scholarship to study mathematics at the University of Cambridge. His interests have been described as ranging \"widely, from biology to poetry and from chess to Humanism\". During World War II he led the field of operations research and worked to increase the effectiveness of Allied bombing. After the war he headed the projects division of UNESCO, and taught mathematics at the University College Hull between 1934 and 1942. Bronowski wrote poetry and had a deep affinity with William Blake. From 1950 to 1963 he worked for the National Coal Board in England. From 1963 he was a resident fellow of the Salk Institute for Biological Studies in San Diego, until his death in 1974 in East Hampton, New York, just a year after the airing of his \"Ascent of Man\".\n\nJacob Bronowski was born to a Polish-Jewish family in Łódź, Congress Poland, in 1908. His family moved to Germany during the First World War, and to Britain in 1920, Bronowski's parents having been married in Britain in the London house of his maternal grandfather in 1907. Although, according to Bronowski, he knew only two English words on arriving in Great Britain, he gained admission to the Central Foundation Boys' School in London and went on to study at the University of Cambridge, where he graduated as a Senior Wrangler.\n\nAs a mathematics student at Jesus College, Cambridge, Bronowski co-edited—with William Empson—the literary periodical \"Experiment\", which first appeared in 1928. Bronowski would pursue this sort of dual activity, in both the mathematical and literary worlds, throughout his professional life. He was also a strong chess player, earning a half-blue while at Cambridge and composing numerous chess problems for the British Chess Magazine between 1926 and 1970. He received a Ph.D. in mathematics in 1935, writing a dissertation in algebraic geometry. For a time in the 1930s he lived near Laura Riding and Robert Graves in Majorca. From 1934 to 1942, he taught mathematics at the University College of Hull. Beginning in this period, the British secret service MI5 placed him under surveillance believing he was a security risk, which may have restricted his access to senior posts in the UK.\n\nDuring the Second World War Bronowski worked in operations research for the UK's Ministry of Home Security, where he developed mathematical approaches to bombing strategy for RAF Bomber Command.\n\nAt the end of the war, Bronowski was part of a British team of scientists and civil engineers that visited Japan to document the effects of the atomic bombings of Hiroshima and Nagasaki for the purpose of studying the effects of the atomic bomb and its implications for future UK civil defence. Bronowski, in conjunction with Professor W. N. Thomas of the University of Cardiff, subsequently produced the secret \"Report of the British Mission to Japan on an Investigation of the Effects of the Atomic Bombs Dropped at Hiroshima and Nagasaki\" which was passed to various government departments and consulted in the design of future UK public buildings.\n\nFollowing his experiences of the after-effects of the Nagasaki and Hiroshima bombings, he discontinued his work for British military research and turned to biology, as did his friend Leó Szilárd, and many other physicists of that time, to better understand the nature of violence. Subsequently, he became Director of Research for the National Coal Board in the UK, and an associate director of the Salk Institute from 1964.\n\nIn 1950, Bronowski was given the Taung child's fossilised skull and asked to try, using his statistical skills, to combine a measure of the size of the skull's teeth with their shape in order to discriminate them from the teeth of apes. Work on this turned his interests towards the biology of humanity's intellectual products.\n\nIn 1967 Bronowski delivered the six Silliman Memorial Lectures at Yale University and chose as his subject the role of imagination and symbolic language in the progress of scientific knowledge. Transcripts of the lectures were published posthumously in 1978 as \"The Origins of Knowledge and Imagination\" and remain in print. He first became familiar to the British public through appearances on the BBC television version of \"The Brains Trust\" in the late 1950s. His ability to answer questions on many varied subjects led to an offhand reference in an episode of \"Monty Python's Flying Circus\" where one character states that \"He knows everything.\"\n\nBronowski is best remembered for his thirteen part series \"The Ascent of Man\" (1973), a BBC television documentary about the history of human life and scientific endeavor. This project was intended to parallel art historian Kenneth Clark's earlier \"personal view\" series \"Civilisation\" (1969) which had covered cultural history.\n\nDuring the making of \"The Ascent of Man\", Bronowski was interviewed on the British chat show \"Parkinson\". Host Michael Parkinson later recounted that Bronowski's description of a visit to Auschwitz, where he had lost many of his family during the Holocaust, was one of Parkinson's most memorable interviews.\n\nBronowski married Rita Coblentz in 1941. The couple had four children, all daughters, the eldest being the British academic Lisa Jardine and another being the filmmaker Judith Bronowski. He died in 1974 of a heart attack in East Hampton, New York, a year after \"The Ascent of Man\" was completed, and was buried in the western side of London's Highgate Cemetery, near the entrance. Rita Bronowski died in California in September 2010, aged 92.\n\n\n"}
{"id": "5887572", "url": "https://en.wikipedia.org/wiki?curid=5887572", "title": "Jacob G. Francis", "text": "Jacob G. Francis\n\nJacob Gottwals Francis, also known as J.G. or Jay G. (January 13, 1870 in Oaks, Pennsylvania – August 27, 1958) was an American author, a historian, a photographer, and a Church of the Brethren minister.\n\nFrancis was born in Oaks, Pennsylvania to John Umstead and Mary Jane (Gottwals) Francis . In 1891, he earned a Bachelor of Arts degree from Ursinus College. He is credited with helping to found Elizabethtown College in 1899 located in Elizabethtown, Lancaster County, Pennsylvania. Francis, however, preferred other sites to Elizabethtown, and thus saw himself as the \"instigator\" of the college, rather than its founder, believing that the location of the college in Elizabethtown was in \"violation of Brethren principles.\" In 1895, he was named minister of the Green Tree Church of the Brethren in Oaks, Pennsylvania.. He was known for travelling throughout Pennsylvania and New Jersey on a bicycle.\n\nFrancis is joint author of a work of more than six hundred pages on the \"History of the Brethren Church in the Eastern District of Pennsylvania\" and author of the \"History of the Brethren in Lebanon County.\"\n\nOn January 11, 1900, Francis married Mary Frantz Zug. They had six children: Mary Irene, Willard Zug, Monica, Michael Ulrich, Susanna Royer, and Anna Marthella \n\nHe died in Lebanon, Pennsylvania. He is buried in Midway Cemetery in Lebanon County, Pennsylvania.\n\n"}
{"id": "53774766", "url": "https://en.wikipedia.org/wiki?curid=53774766", "title": "James Davidson (historian)", "text": "James Davidson (historian)\n\nJames Davidson is a professor of ancient history at the University of Warwick. Davidson specialises in the social history of ancient Greece and has made significant contributions to the study of ancient homosexuality. He was educated at Columbia and Oxford University, where he received a DPhil. From 2001 to 2004 he was a member of the Council for the Society for the Promotion of Hellenic Studies from 2001 to 2004, and from 2000 to 2010 a member of the Classical Association Journals Board. His book \"The Greeks and Greek Love: a Radical Reappraisal of Homosexuality in Ancient Greece\" was awarded the Mark Lynton History Prize in 2010. \n\n\n"}
{"id": "14109447", "url": "https://en.wikipedia.org/wiki?curid=14109447", "title": "Journal of World History", "text": "Journal of World History\n\nThe Journal of World History is a peer-reviewed academic journal that presents historical analysis from a global point of view, focusing especially on forces that cross the boundaries of cultures and civilizations, including large-scale population movements, economic fluctuations, transfers of technology, the spread of infectious diseases, long-distance trade, and the spread of religious faiths, ideas, and values.\n\nThe journal was established in 1990 by Jerry H. Bentley at the University of Hawaii to serve as the official journal of the World History Association. It is published by the University of Hawaii Press. Initially produced twice a year, it became a quarterly in 2003.\n\nIn 2000, it was included in Project MUSE, which now contains archives going back to vol. 7 (1996). In 2009, it was included in JSTOR, with a moving wall of 3 years.\n\n"}
{"id": "30033300", "url": "https://en.wikipedia.org/wiki?curid=30033300", "title": "Kalampattu", "text": "Kalampattu\n\nMULLUTHARA is a traditional performing art in Kerala, India.\n\nIt is performed as a vazhipad (offering). Pattu kurup, a traditional community, is in charge of that function. This offering is performed for the blessings of gods like Bhadrakali, Ayyappan, Vettakkorumakan, serpent god, etc. This kurup makes the kalam picture (drawn on the floor using five colours) and he sings also. The velichappad (Komaram) mostly belongs to the Nambudiri community does the kalapradikshinam (rounding the kalam with different steps and rhythms), nalikerameru (breaking of coconut as offering), and kalammakkal (validictory function – closing the function).\n\nAs a part of Vettakorumakan pattu,12008 cocount's are break by komaram. Manikandan kallat, kattakampal is one of the famous in this field.\n\nThere are 29 different types of nagakalam (serpant kalam) by kallat stylein Mulluthara devi temple. in the present generation he was the only one in kallat kurup family who knows all different types of kalam. He learned this from his master kallat Ravunni kurup nelluvai.\nDifferent types of kalam, pictures, vedios, and details are given in the site www.kalampattu.com\n\nKalamezhuthupattu:\n\nKalamezhuthupattu is a traditional performing art in Mulluthara devi temple Kerala, Adoor, Malamekkara. India. It is performed as a vazhipad (offering). Kallatt kurup, a traditional community, is in charge of that function. The Kalampattu is associated with some ritualistic dance performances. This offering is performed for the blessings of Gods like Bhadhrakali, Ayyappan, Vettakkorumakan, Serpent God, etc.\nAfter Koorayidal and Uchappattu, Kurup does the Kalamezhuthu (drawn on the floor using five colours). Marar (who plays drums) does the Sandyavela after deeparadhana. Keli, thayampaka, kushalpattu, etc. are done according to the budget of the offerer. When the Kalam is ready, the Deity and the Komaram will be welcomed to the Kalam as a procession with a song by Kurup called Mullakkan pattu. Here also according to the budget elephant, melam, and other decorative items can be added to the procession. The Velichappad (Komaram) does the ritual dance known as Eedum koorum chavittu and the Kalapradakshinam (rounding the Kalam with different steps and rhythms). After the completion of Kalapradakshinam, the Brahmin priest is assigned the privilege of doing the Kalam pooja of the image before the onset of the Kalampattu. After that Kurup performs Thiriuzichil, the Komaram performs Kalathylattam, Nalikerameru (breaking of coconut as offering), and Kalam maykkal (Kalasam - valedictory function – closing the function). After that kurup remove the koora (Koora valikkal).\n\nwww.kalampattu.com\nDevi Temple.com\n\n"}
{"id": "4202667", "url": "https://en.wikipedia.org/wiki?curid=4202667", "title": "La Violencia", "text": "La Violencia\n\nLa Violencia (, The Violence) was a ten-year civil war in Colombia from 1948 to 1958, between the Colombian Conservative Party and the Colombian Liberal Party, fought mainly in the countryside.\n\n\"La Violencia\" is considered to have begun with the 9 April 1948 assassination of the popular politician Jorge Eliécer Gaitán, a Liberal Party presidential candidate for the election in November 1949. His murder provoked the \"Bogotazo\" rioting that lasted for ten hours and killed some 5,000 people. An alternative historiography proposes as the start the Conservatives' return to power following the election of 1946. Rural town police and political leaders encouraged Conservative-supporting peasants to seize the agricultural lands of Liberal-supporting peasants, which provoked peasant-to-peasant violence throughout Colombia.\n\n\"La Violencia\" is estimated to have cost the lives of at least 200,000 people.\n\n\"La Violencia\" took place between the paramilitary forces of the Colombian Liberal Party and the Colombian Conservative Party, which organized as armed self-defense groups and as guerrilla military units. Both also fought against the paramilitary forces of the Colombian Communist Party (PCC).\n\nThe conflict caused millions of people to abandon their homes and property. Media and news services failed to cover events accurately for fear of revenge attacks. The lack of public order and civil authority prevented victims from laying charges against perpetrators. Documented evidence from these years is rare and fragmented.\n\nThe majority of the population at the time was Catholic. During the conflict there were press reports that Catholic Church authorities supported the Conservative Party. Several priests were accused of openly encouraging the murder of the political opposition during Catholic mass, including the Santa Rosa de Osos Bishop Miguel Ángel Builes, although this is unproven. No formal charges were ever presented and no official statements were made by the Holy See or the Board of Bishops. These events were recounted in the 1950 book \"Lo que el cielo no perdona\" (\"What heaven doesn't forgive\"), written by the secretary to Builes, Father Fidel Blandon Berrio. Eduardo Caballero Calderón also recounted these events in his 1952 book \"El Cristo de Espaldas\" (\"Backwards Christ\"). After releasing his book, Blandon resigned from his position and assumed a false identity as Antonio Gutiérrez. However, he was eventually identified and legally charged and prosecuted.\n\nAs a result of \"La Violencia\" there were no liberal candidates for the presidency, congress, or any public corporations in the 1950 elections. The press accused the government of pogroms against the opposition. Censorship and reprisals were common against journalists, writers, and directors of news services. In consequence many media figures left the country. Jorge Zalamea, director of \"Critica\" magazine, fled to Buenos Aires; Luis Vidales to Chile; Antonio Garcia to La Paz, and Gerardo Molina to Paris.\n\nMost of the armed groups (called guerrillas liberales, a pejorative term) were demobilized during the amnesty declared by General Gustavo Rojas Pinilla after he took power on 13 June 1953. The most prominent Guerrilla leaders, Guadalupe Salcedo and Juan de la Cruz Varela, signed the 1953 agreement.\n\nSome of the guerrileros did not surrender to the government and organized into criminal bands or bandoleros, which caused intense military operations against them in 1954. One of them, the guerrillero leader Tirofijo, had changed his political and ideological inclinations from being a Liberal to supporting the Communists during this period, and eventually he became the founder of the communist Revolutionary Armed Forces of Colombia or FARC.\n\nRojas was removed from power on 10 May 1957. Civilian rule was restored after moderate Conservatives and Liberals, with the support of dissident sectors of the military, agreed to unite under a bipartisan coalition known as the National Front and the government of Alberto Lleras Camargo and which included a system of alternating the president and power-sharing both in cabinets and public offices.\n\nIn 1958, Lleras Camargo ordered the creation of the Commission for the Investigation of the Causes of \"La Violencia\". The commission was headed by the Bishop Germán Guzmán Campos.\n\nThe last bandolero leaders were killed in combat against the army. Jacinto Cruz Usma, alias \"Sangrenegra\" (Blackblood), died in April 1964 and Efraín Gonzáles in June 1965.\n\nDue to incomplete or non-existent statistical records, exact measurement of \"La Violencia\"'s humanitarian consequences is impossible. Scholars, however, estimate that between 200,000 and 300,000 lives were lost; 600,000 to 800,000 were injured; and almost one million people were displaced. \"La Violencia\" directly or indirectly affected 20 percent of the population.\n\n\"La Violencia\" did not acquire its name simply because of the number of people it affected; it was the manner in which most of the killings, maimings, and dismemberings were done. Certain death and torture techniques became so commonplace that they were given names—for example, \"picar para tamal\", which involved slowly cutting up a living person's body; or \"bocachiquiar\", where hundreds of small punctures were made until the victim slowly bled to death. Former Senior Director of International Economic Affairs for the United States National Security Council and current President of the Institute for Global Economic Growth, Norman A. Bailey describes the atrocities succinctly: \"Ingenious forms of quartering and beheading were invented and given such names as the 'corte de mica', 'corte de corbata' (aka Colombian necktie), and so on. Crucifixions and hangings were commonplace, political 'prisoners' were thrown from airplanes in flight, infants were bayoneted, schoolgirls, some as young as eight years old, were raped \"en masse\", unborn infants were removed by crude Caesarian section and replaced by roosters, ears were cut off, scalps removed, and so on.\" While scholars, historians, and analysts have all debated the source of this era of unrest, they have yet to formulate a widely accepted explanation for why it escalated to the notable level it did.\n\nThe death of the bandoleros and the end of the mobs was not the end of all the violence in Colombia. One communist guerrilla movement, the Peasant Student Workers Movement, started its operations in 1959. Later, other organizations such as the FARC and the National Liberation Army emerged, marking the beginning of a guerrilla insurgency.\n\nFrom the point of view of members of the FARC and the PCC, the Liberal and Conservative elites, though they had instigated the original violence, soon grew to fear the consequences of it and thus formed a loose alliance to preserve their shared desire for political hegemony from possible revolutionary challenges.\n\nAs was common of 20th-century eliminationist political violence, the rationales for action immediately before \"La Violencia\" were founded on conspiracy theories, each of which blamed the other side as traitors beholden to international cabals. The left were painted as participants in a global Judeo-Masonic conspiracy against Christianity, and the right were painted as agents of a Nazi-Falangist plot against democracy and progress.\n\nAfter the death of Gaitán, a conspiracy theory circulating among the left, that leading conservatives and militant priests were involved in a plot with Nazis and Falangists to take control of the country and undo the country's moves toward progress, spurred the violence. This conspiracy theory supplied the rationale for Liberal Party radicals to engage in violence, notably the anti-clerical attacks and killings, particularly in the early years of \"La Violencia\". Some propaganda leaflets circulating in Medellín blamed a favorite of anti-Catholic conspiracy theorists, the Society of Jesus (Jesuits), for the murder of Gaitán.\n\nAcross the country, militants attacked churches, convents, and monasteries, killing priests and looking for arms, since the conspiracy theory maintained that the religious had guns, and this despite the fact that not a single serviceable weapon was located in the raids. One priest, Pedro María Ramírez Ramos, was slaughtered with machetes and hauled through the street behind a truck, despite the fact that the militants had previously searched the church grounds and found no weapons.\n\nDespite the conspiracy theories and propaganda after Gaitán's killing, most on the left learned from their errors in the rioting on 9 April, and stopped believing that priests had harbored weapons.\n\nThe claims by both camps of the existence of some sort of conspiracy made the political environment toxic, increasing the animosity and suspicion of both parties.\n\nConservatives likewise had been motivated to fight against a supposed international Judeo-Masonic conspiracy by eliminating the Liberals in their midst. In the two decades prior to \"La Violencia\", Conservative politicians and churchmen adopted from Europe the Judeo-Masonic conspiracy theory to portray the Liberal Party as involved in an international anti-Christian plot, with many prominent Liberal politicians actually being Freemasons.\n\nAlthough the rhetoric of conspiracy was in large part introduced and circulated by some of the clergy, as well as by Conservative politicians, by 1942 many clerics were critical of the Judeo-Masonic conspiracy theory. Jesuits outside of Colombia had already questioned and published disputes of the authenticity of \"The Protocols of the Elders of Zion\", pushing the concept of a global Judeo-Masonic conspiracy. Colombian clergy were also increasingly influenced in this matter by U.S. clergy; and Pius XI had asked U.S. Jesuit John LaFarge, Jr. to draft an encyclical against anti-Semitism and racism. Allegations of a Judeo-Masonic conspiracy played most prominently in the politics of Laureano Gómez, who directed the Colombian Conservative Party from 1932 to 1953. More provincial politicians followed suit, and the fact that prominent national and local politicians were voicing this conspiracy theory, rather than just a portion of the clergy, gave the idea greater credibility while it gathered momentum among the party members.\n\nThe atrocities that had happened at the outset of the Spanish Civil War in 1936 were seen by both sides as a possible precedent for Colombia, causing both sides to fear it could happen in their country; this also spurred the credibility of the conspiracies and the rationale for violence. Catholics everywhere were shocked by the wave of anticlerical violence in the Republican zones in Spain in the first months of that war where anarchists, socialists and communists burned churches and murdered nearly 7,000 priests, monks, and nuns.\n\n\n"}
{"id": "2341342", "url": "https://en.wikipedia.org/wiki?curid=2341342", "title": "Lisa Jardine", "text": "Lisa Jardine\n\nLisa Anne Jardine (née Bronowski; 12 April 1944 – 25 October 2015) was a British historian of the early modern period.\n\nFrom 1990 to 2011, she was Centenary Professor of Renaissance Studies and Director of the Centre for Editing Lives and Letters at Queen Mary University of London. From 2008 to January 2014 she was Chair of the Human Fertilisation and Embryology Authority (HFEA).\n\nJardine was a Member of Council of the Royal Institution, until 2009. On 1 September 2012, she relocated with her research centre and staff to University College London (UCL) to become founding director of its Centre for Interdisciplinary Research in the Humanities.\n\nJardine was born on 12 April 1944 in Oxford, the eldest of four daughters of mathematician and polymath, Jacob Bronowski, and the sculptor, Rita Coblentz.\n\nBronowski, who died in 1974 and was known for his 13-part television series, \"The Ascent of Man\" (1973), was the subject of Jardine's Conway Memorial Lecture, \"Things I Never Knew About My Father\", delivered at the Conway Hall Ethical Society on 26 June 2014.\n\nAn avid reader with an interest in history from a very young age, Jardine won a mathematics scholarship to Cheltenham Ladies' College and later attended Newnham College, Cambridge, and the University of Essex. For two years she took the Cambridge Mathematical Tripos before, in her final year and under the influence of Raymond Williams, she read English. Fluent in eight languages (including Greek and Latin), she studied for an MA in the Literary Theory of Translation with Professor Donald Davie at the University of Essex. She was awarded a PhD from the University of Cambridge with a dissertation on \"Francis Bacon: Discovery and the Art of Discourse\" (subsequently published by Cambridge University Press).\n\nIn striking out on her own career path Jardine recalled that she initially found her father's celebrity something of a burden, noting that she was \"very, very conscious\" of being his daughter. When in 1969 she married Cambridge historian and philosopher of science, Nicholas Jardine, she was relieved to assume her husband's surname, which she continued to use after the couple's divorce in 1979. The couple had a son and a daughter. \"Until 1999, the name Bronowski never occurred in cuttings about me, and it was broadly unknown that I was his daughter\", she later stated. In 1982, she married architect John Hare, with whom she had one son. She was reported to have said that her greatest achievement was her three \"well-balanced children\".\n\nJardine had been raised in a secular Jewish household, but when appointed new chair of the Human Fertilisation and Embryology Authority, Britain’s fertility regulator, she expressed her loyalty to her observant grandparents' Orthodox faith, which she described as going back \"all the way back to whenever – Abraham\", and her reluctance to clash with the Catholic Church on embryology.\n\nJardine was Professor of Renaissance Studies at University College, London, where she was Director of the Centre for Interdisciplinary Research in the Humanities and Director of the Centre for Editing Lives and Letters. She was a Fellow of the Royal Historical Society, and a Fellow and Honorary Fellow of King's College and Jesus College, Cambridge.\n\nShe was a Trustee of the Victoria and Albert Museum for eight years, and was for five years a member of the Council of the Royal Institution in London. She was Patron of the Archives and Records Association and the Orange Prize. For the academic year 2007–2008 she was seconded to the Royal Society in London as Expert Advisor to its Collections. She was a Trustee of the Chelsea Physic Garden.\n\nFrom 2008–2014, she served as Chair of the Human Fertilisation and Embryology Authority – the UK government regulator for assisted reproduction. In December 2011 she was appointed a Director of The National Archives.\n\nJardine published more than 50 scholarly articles in peer reviewed journals and books, and 17 full-length books, both for an academic and for a general readership, a number of them in co-authorship with others (including Professor Anthony Grafton, Professor Alan Stewart and Professor Julia Swindells).\n\nShe was the author of many books, both scholarly and general, including \"The Curious Life of Robert Hooke: The Man Who Measured London\", \"Ingenious Pursuits: Building the Scientific Revolution\" and biographies of Robert Hooke, and Sir Christopher Wren (\"On a Grander Scale: the Outstanding Career of Sir Christopher Wren\"). Her 2008 book \"Going Dutch\", on Anglo-Dutch reciprocal influence in the 17th century, won the 2009 Cundill Prize in History at McGill University, the world's premier history book prize worth $75,000.\n\nJardine wrote and reviewed widely for the media, and presented and appeared regularly on arts, history and current affairs programmes for TV and radio. She was a regular writer and presenter of \"A Point of View\" on BBC Radio 4; a book of the first two series of her talks was published by Preface Publishing in March 2008 and a second in 2009. She judged the Novel category of the 1996 Whitbread Book Awards, the 1999 Guardian First Book Award, the 2000 Orwell Prize and was Chair of Judges for the 1997 Orange Prize for Fiction and the 2002 Man Booker Prize.\n\nDuring the first semester of the 2008–2009 academic year, Jardine was Distinguished Visiting Professor at the Netherlands Institute for Advanced Study in the Humanities and Social Sciences, jointly sponsored by NIAS and the Royal Library in The Hague.\n\nIn 2009–2010, she was a Scaliger Visiting Fellow at the University of Leiden in the Netherlands, and held the Sarton Chair and received the Sarton Medal at Ghent University in Belgium. She sat for several years on the Apeldoorn British Dutch Conference Steering Board, and was a member of the Recommendation Committee Stichting Huygens Tentoonstelling Foundation, set up to oversee the Constantijn and Christian Huygens Exhibition in the Grote Kerk in The Hague in 2013.\n\nIn June 2015 she was the guest on BBC Radio 4's \"Desert Island Discs\". Her musical choices included \"Why\" by Annie Lennox, \"A Hard Rain's a-Gonna Fall\" by Bob Dylan, and \"Once in a Lifetime\" by Talking Heads. Her book choice was the full 12 volumes of P.S. Allen’s \"Latin Letters of Erasmus of Rotterdam\".\n\nOn 26 January 2011, Jardine appeared in a BBC documentary investigating her father's life and the history of science in the 20th century.\n\nShe was known for her cross-disciplinary approach to intellectual history and has been called \"the pre-eminent historian of the scientific method.\"\n\nJardine was President of the Antiquarian Horological Society, a learned society focused on matters relating to the art and history of time measurement.\nJardine was a former chairman of the governing body at Westminster City School for Boys in London (which her younger son attended), and a former Chair of the Curriculum Committee on the governing body of St Marylebone Church of England School for Girls also in London.\n\nIn 2012, she was awarded the President's Medal by the British Academy.\n\nShe was elected an Honorary Fellow of the Royal Society (FRS) in 2015. Her certificate of election reads: \n\nJardine held honorary doctorates of Letters from the University of St Andrews, Sheffield Hallam University and the Open University, and an honorary doctorate of Science from the University of Aberdeen.\n\nIn November 2011, she was made an Honorary Bencher of the Honourable Society of the Middle Temple. She was awarded the Francis Bacon Award in the History of Science by the California Institute of Technology in 2012, and collected the Bacon Medal for this award at the annual History of Science Society meeting in San Diego in September 2012.\n\nIn November 2012 she received the British Academy President's Medal. In 2013–2014 she served as President of the British Science Association, which in 2012 made her an Honorary Fellow.\n\nJardine died of cancer on 25 October 2015, aged 71. In the tributes which followed, she was remembered for her commitment to her students, and \"her deep empathy for outsiders of all kinds—rebels, misfits and migrants.\"\n\n"}
{"id": "31720130", "url": "https://en.wikipedia.org/wiki?curid=31720130", "title": "List of socialist economists", "text": "List of socialist economists\n\nThis article lists notable socialist economists and political economists.\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "45637366", "url": "https://en.wikipedia.org/wiki?curid=45637366", "title": "List of years in Mexican television", "text": "List of years in Mexican television\n\nThis is a list of years in Mexican television.\n\n"}
{"id": "41541334", "url": "https://en.wikipedia.org/wiki?curid=41541334", "title": "Mapuche silverwork", "text": "Mapuche silverwork\n\nMapuche silverwork is one of the best known aspects of Mapuche material culture. The adornments have been subject to changes in fashion but some designs have resisted change.\n\nIn the later half of the 18th century, Mapuche silversmiths began to produce large amounts of silver finery. The surge of silversmithing activity may be related to the 1641 parliament of Quillín and the 1726 parliament of Negrete that decreased hostilities between Spaniards and Mapuches and allowed trade to increase between colonial Chile and the free Mapuches. In this context of increasing trade, Mapuches began in the late 18th century to accept payments in silver coins for their products; usually cattle or horses. These coins and silver coins obtained in political negotiations served as raw material for Mapuche metalsmiths (Mapudungun: \"rüxafe\"). Old Mapuche silver pendants often included unmelted silver coins, something that has helped modern researchers to date the objects. The bulk of the Spanish silver coins originated from mining in Potosí in Upper Peru.\n\nThe great diversity in silver finery designs is indebted to the fact that designs were done to be identified with different \"reynma\" (families), \"lof mapu\" (lands) as well as specific lonkos and machis. Mapuche silver finery was also subject to changes in fashion albeit designs associated with philosophical and spiritual concepts have not undergone major changes.\n\nIn late 18th century and early 19th century, Mapuche silversmithing activity and artistic diversity reached it climax. All important Mapuche chiefs of the 19th century are supposed to have had at least one silversmith. The 1869 war between Chile and independent Mapuches provoked a famine among Mapuches in the winter of 1869, with the situation being worsened by a smallpox epidemic. This situation led some Mapuches to sell their silver adornments in the towns of La Frontera to obtain food.\n\nAs of 1984, Mapuche scholar Carlos Aldunate noted that there were no silversmiths alive among contemporary Mapuches.\n\nAlthough these adornments showed some variation in form, the principal one appears to be a set of three separate columns of flattened silver links joined to each other by square alternating links. At the top of the set of columns, and holding them together, is a flat two-headed bird figure and at the base is a flat semicircle or trapezoid that usually has a series of small disks dangling from its base. The wearer would place the object hanging from his/ her neck and down the chest.\n\n\n"}
{"id": "610469", "url": "https://en.wikipedia.org/wiki?curid=610469", "title": "Medieval archaeology", "text": "Medieval archaeology\n\nMedieval archaeology is the study of humankind through its material culture, specialising in the period of the European Middle Ages. At its broadest, the period stretches from the 5th to the 16th century and refers to post-Roman but pre-modern remains. The period covers the upheaval caused by the fall of the Roman Empire and cultures such as the Vikings, Saxons, and Franks. Archaeologists often specialise in studying either the Early Middle Ages (Migration Period) or the High Middle Ages and Late Middle Ages, although many projects and professionals move across these chronological boundaries. The rich nature of the medieval written record has meant that archaeology has often been seen as the \"handmaiden to history\", especially in the later medieval period. Analysis of material culture may enrich or call into question written evidence from the medieval period and the two sources of evidence need to be used together. Medieval archaeology has examined the development of medieval settlements, particularly the development of medieval towns and castles. It has also contributed to understanding of the spread and development of Christian monasticism during the medieval period.\n\nThe Society for Medieval Archaeology (United Kingdom) was founded in 1957. To celebrate its 50th anniversary, several publications examined the history of the society and the sub-discipline. Christopher Gerrard's 2003 book \"Medieval Archaeology\" also charts the move in the United Kingdom from antiquarianism, through Victorian medievalism, on to the emergence of medieval archaeology as a sub-discipline in the 20th century.\n\nThe study of medieval archaeology often focuses on specific kinds of settlement pattern.\n\nPattern of medieval rural settlements are often quite different from modern time villages. This is true in terms of architecture, outline of the settlements and social structure.\n\nThere is a broad spectrum of pre-urban and urban settlements in the Middle Ages (e.g. early medieval trading places at the Northern Sea and the Baltic Sea, former Roman cities and town foundations of the late Middle Ages). \nAn important field of research is urban archaeology in still existing towns, which is determeined by rescue archaeology.\n\nCastles are medieval fortified structures.\n\nIn the United Kingdom, the Dissolution of the Monasteries left many monastic sites abandoned. Where monasteries have survived or been converted for other uses, \"buildings archaeology\" has also been applied to study their history. Medieval monasteries often held large estates and the study of monastic landscapes is an area of specialised research. There have been two main waves of research in medieval monastic and church archaeology: 1970-1995 and 1995-present. The first wave was influenced by landscape history and processual archaeology; scholarship focused principally on historical, economic and technological questions and targeted individual sites and monuments for study. The second wave has been informed by post-processual approaches and considers change and complexity in religious landscapes and perspectives on religious space, embodiment and agency.\n\n\n"}
{"id": "21108916", "url": "https://en.wikipedia.org/wiki?curid=21108916", "title": "National Fund of the Republic of Austria for Victims of National Socialism", "text": "National Fund of the Republic of Austria for Victims of National Socialism\n\nThe National Fund of the Republic of Austria for Victims of National Socialism, , is a fund created by the Republic of Austria to seek to apply restitution for property confiscated by the Nazis during World War II. The fund was established in 1995.\n\nThe fund maintains databases of property, including the Art Database of the National Fund, held in the Wiener Stadtbibliothek.\n\nThe General Settlement Fund is constituted to seek to compensate victims of Nazi persecution from all of the persecuted minorities, religious, cultural, ethnic, handicapped, and those who left Austria in order to escape persecution. The claim for compensation passes to the heirs of the original victims on their death.\n\nApplications to the General Settlement Fund closed in May 2003. In May 2010 final payments are being received from this fund.\n\nThe National Fund is different from the General Fund in that it has different eligibility criteria and there is, in January 2009, no deadline for filing applications.\n"}
{"id": "142391", "url": "https://en.wikipedia.org/wiki?curid=142391", "title": "Nicephorus Gregoras", "text": "Nicephorus Gregoras\n\nNicephorus Gregoras (; Greek: , \"Nikephoros Gregoras\"; c. 1295 – 1360) was a Byzantine astronomer, historian, and theologian.\n\nGregoras was born at Heraclea Pontica. At an early age he settled at Constantinople, where his reputation for learning brought him under the notice of Andronicus II Palaeologus, by whom he was appointed \"chartophylax\" (keeper of the archives). In 1326 Gregoras proposed (in a treatise which remains in existence) certain reforms in the calendar, which the emperor refused to carry out for fear of disturbances; nearly two hundred years later they were introduced by Gregory XIII on almost the same lines.\n\nWhen Andronicus was dethroned (1328) by his grandson Andronicus III Palaeologus, Gregoras shared his downfall and retired into private life. Attacked by Barlaam of Calabria, he was with difficulty persuaded to come forward and meet him in a war of words, in which Barlaam was bested. This greatly enhanced his reputation and brought him a large number of pupils.\n\nGregoras remained loyal to the elder Andronicus to the last, but after his death he succeeded in gaining the favour of his grandson, by whom he was appointed to conduct the unsuccessful negotiations (for a union of the Greek and Latin churches) with the ambassadors of Pope John XXII (1333).\n\nBeginning in 1346, Gregoras took an important part in the Hesychast controversy at the encouragement of the Empress Anna, by publishing a tract in which he staunchly opposed Gregorius Palamas, the chief supporter of the doctrine. Although he persuaded some prominent churchmen, such as Joseph of Ganos and Arsenios of Tyre, his opinion was opposed to those of Emperor John VI Cantacuzene. Although he presented his views at length at the synod of 1351, that synod declared his views heretical and the doctrines of Palamas orthodox. He and other dissidents were given the opportunity to recant, and he refused.\n\nAlthough the doctrine of Gregorius Palamas came to be accepted by the majority of the Orthodox Church, Gregoras persisted in campaigning against what he considered a heretical doctrine forced upon the Church by a robber council. He became a monk and devoted himself to campaigning against the Palamites, destroying his friendship with John Cantacuzene. He was first placed under house arrest, then confined to the Chora Monastery. When he was released from the monastery in 1354, Gregoras returned to his preaching and denunciations. Gregoras devotes two of the 37 books of his \"Roman History\" on his objections to the doctrine of Palamas; according to Donald Nicols, \"It is disappointing that Gregoras the philosopher and historian should have degenerated into a ranting polemicist in his declining years.\"\n\nGregoras' chief work is his Byzantine History\", in 37 books, covering the years 1204 to 1359. It partly supplements and partly continues the work of George Pachymeres. Gregoras shows considerable industry, but his style is pompous and affected. This work and that of John Cantacuzene supplement and correct each other, and should be read together.\n\nThe other writings of Gregoras, which (with a few exceptions) still remain unpublished, attest his great versatility. Amongst them may be mentioned a history of the dispute with Palamas; biographies of his uncle and early instructor John, metropolitan of Heraclea, and of the martyr Codratus of Antioch; funeral orations for Theodore Metochites, and the two emperors Andronicus; commentaries on the wanderings of Odysseus and on Synesius's treatise on dreams; tracts on orthography and on words of doubtful meaning; a philosophical dialogue called \"Phlorentius\" or \"Concerning Wisdom\"; astronomical treatises on the date of Easter, on the preparation of the astrolabe and on the predictive calculation of solar eclipses; and an extensive correspondence.\n\nEditions: in Bonn \"Corpus Scriptorum Historiae Byzantinae\", by L. Schopen and I. Bekker, with life and list of works by J. Boivin (1829–1855); J. P. Migne, \"Patrologia Graeca\", cxlviii., cxlix.; see also Karl Krumbacher, \"Geschichte der byzantinischen Litteratur\" (1897).\n\n"}
{"id": "34363903", "url": "https://en.wikipedia.org/wiki?curid=34363903", "title": "Odysseus Acanthoplex", "text": "Odysseus Acanthoplex\n\nOdysseus Acanthoplex (, \"Odysseus Akanthoplēx\", \"Odysseus wounded by a spine\"; also known as \"Odysseus Wounded\", \"Odysseus Spine-struck\" and \"Odysseus Wounded by the Spine\") is a lost play by the Athenian dramatist Sophocles. Several fragments are extant. The plot told of Odysseus' death, accidentally killed by his son Telegonus. Some scholars believe that another Sophocles' title, Niptra (Νιπτρα, \"The Footwashing\", \"The Washing\"), is the same play as \"Odysseus Acanthoplex\". Dana Sutton, however, disputes this, suggesting that \"Niptra\" was a separate play dealing with Odysseus' return to Ithaca but not with his death.\n\nThe plot of \"Odysseus Acanthoplex\" was based on \"Telegony\", which was part of the \"Epic Cycle\". As background to the plot of the play, Homer's \"Odyssey\" tells of Odysseus spending a year with the goddess Circe. In the version of the myth that \"Odysseus Acanthoplex\" was based on, Odysseus and Circe had a son from this dalliance, Telegonus.\n\nFrom what we know of the plot of the play, Telegonus arrived at Ithaca to reveal himself to his father. However, a fight ensued and Telegonus killed Odysseus without knowing who Odysseus was. In the myth, Telegonus used a spear that had a venomous stingray spine to kill Odysseus. The plot also dealt with the subsequent marriages between Telegonus and Odysseus' wife Penelope and between Circe and Odysseus' son by Penelope, Telemachus.\n\nTwo of the extant fragments from the play refer to the oar Odysseus carried to appease the sea god Poseidon. Several extant fragments make reference to the oracle of Zeus at Dodona. Other than one reference in \"Trachiniae\", these are the only extant references to Dodona in Sophocles' works. Classicist T.F. Hoey believes that the thematic development of \"Odysseus Acanthoplex\" was similar to that of \"Trachiniae\". According to archaeologist Thomas B. L. Webster, the plot of \"Odysseus Acanthoplex\" had a diptych form, i.e., in two parts, analogous to Sophocles' extant \"Ajax\", \"Trachiniae\" and \"Antigone\".\n\nSutton speculated that the play partially unfolded as follows. Early in the play, Odysseus related the directions from Teiresias described in \"The Odyssey\" in which he was supposed to carry an oar far inland as a sacrifice to Poseidon. He also related an oracle he received at Dodona telling him that he would be killed by his son. Believing that the oracle referred to Telemachus, he would have taken precautions against Telemachus killing him, but was unprepared when another son who he did not know of arrived and a fight ensued. The wounded Odysseus was brought on stage lamenting his wounds and denouncing the oracle for failing to predict that he would die at the hands of this stranger. Then Telegonus arrived on stage, and a recognition scene occurred in which Telegonus discovered that he killed his father and Odysseus realized that the oracle had come to pass.\n\nWebster, who believes that \"Niptra\" and \"Odysseus Acanthoplex\" are the same play, believes that the play began with Odysseus' return home to Ithaca and his recognition by Eurycleia, who in \"The Odyssey\" washed Odysseus' feet.\n\nIn his \"Poetics\", Aristotle used the plot of \"Odysseus Acanthoplex\", under the title \"Odysseus Wounded\", as one of three examples of an effective type of plot for tragedy in which a character performs a horrific deed to a relative in ignorance and only learns the truth after the fact. The other examples Aristotle gave of this type of effective plot were Sophocles' \"Oedipus Rex\" and a play about Alcmaeon by 4th century BCE tragic playwright Astydamas.\n\nRoman philosopher Cicero praised Pacuvius' play \"Niptra\", which was an imitation of Sophocles' \"Odysseus Acanthoplex\", because in Pacuvius' play Odysseus does not lament his wounds excessively, as Cicero believed the character did in Sophocles' play.\n\nIn \"The Lost Sophocles\", D. F. Sutton suggests that \"Odysseus Acanthoplex\" was possibly first produced by about 414 BCE, which Sutton suggests is the same timeframe as Sophocles' \"Electra\". Webster believes it was produced at a date close to that of \"Women of Trachis\", which he dates to sometime before 431, due to perceived similarities with the structure of that play.\n"}
{"id": "33713209", "url": "https://en.wikipedia.org/wiki?curid=33713209", "title": "Oliver Farrar Emerson", "text": "Oliver Farrar Emerson\n\nOliver Farrar Emerson (born in Traer, Iowa, 24 May 1860; died in Ocala, Florida 13 March 1927) was a United States educator and philologist noted for Chaucer scholarship and his \"History of the English Language\".\n\nEmerson studied at Iowa College, taking a post graduate course at Cornell University, where he received the degree of D.Ph. in 1891. After serving as superintendent of schools in Grinnell and Muscatine, Iowa, he was principal of the Academy of Iowa College (1885–88), instructor in English (1889–91) Cornell University and assistant professor of rhetoric and English philology in the same institution (1892–96), when he took the same chair at Adelbert College of Western Reserve University. He became Oviatt Professor of English at Case Western in 1906, and was head of the English department.\n\nHe was a member of the Modern Language Association, American Dialect Society and the Simplified Spelling Board. During his career at Case Western, he resided in East Cleveland and founded the Novel Club. He was married to Annie Laurie Logan of St. Louis, with whom he had a son and a daughter.\n\nHe was a regular contributor to various philological journals and magazines. In addition, he wrote:\nHe edited:\n\n"}
{"id": "1946883", "url": "https://en.wikipedia.org/wiki?curid=1946883", "title": "Playing company", "text": "Playing company\n\nIn Renaissance London, playing company was the usual term for a company of actors. These companies were organized around a group of ten or so shareholders (or \"sharers\"), who performed in the plays but were also responsible for management. The sharers employed \"hired men\" that is, the minor actors and the workers behind the scenes. The major companies were based at specific theatres in London; the most successful of them, William Shakespeare's company the King's Men, had the open-air Globe Theatre for summer seasons and the enclosed Blackfriars Theatre in the winters. The Admiral's Men occupied the Rose Theatre in the 1590s, and the Fortune Theatre in the early 17th century.\n\nLess fortunate companies spent most of their existences touring the provinces; when Worcester's Men gained official permission to perform in London in 1602, they were, in a manner of speaking, \"coming in from the cold\" of a life of constant touring.\n\nThe development of theatre in England in the 16th and 17th centuries was not an isolated phenomenon; similar developments occurred simultaneously in other European countries, to greater or lesser degrees. The same broad factors influenced English actors as those that affected actors in neighboring countries, especially Scotland, France, Denmark, and states in northern Germany like Saxony and the Rhineland Palatinate. Yet conditions in other societies also differed significantly from those in England; the following discussion applies specifically to England in the 16th century and 17th century.\n\nIn the later Medieval and early Renaissance periods, wealthy and powerful English noble houses sometimes maintained a troupe of half a dozen \"players\", just as noblemen kept jesters or jugglers for entertainment. English theatre benefited greatly from the predilection for theatricality displayed by the Tudors. Henry VII kept a company of players called the \"Lusores Regis\", which probably consisted of four men and a boy who were used to swift costume changes and multiple roles. In the early period the difference between players, acrobats and other entertainers was not hard and fast. A troupe of players, however, was more costly to keep than a jester; players (who usually had other household duties as well) could defray expenses by touring to various cities and performing for profit a practice that began the evolution away from the medieval model of noble patronage and toward the commercial and capitalistic model of modern entertainment. It is from the scattered records of such touring, and from occasional performances at the English Royal Court, that our very limited knowledge of English Renaissance theatre in the early and middle 16th century derives.\n\nOne curious development of this era was the development of companies of pre-pubescent boy actors. The use of the boy player in companies of adult actors to play female parts can be traced far back in the history of medieval theatre, in the famous mystery plays and moralities; the employment of casts of boys for entire dramatic productions began in the early 16th century, which utilized the boys' choirs connected with cathedrals, churches, and schools. In time the practice took on a professional aspect and companies of child actors would play an important role in the development of drama through the Elizabethan era and into the Jacobean and Caroline periods that followed. (See: Children of the Chapel; Children of Paul's; Beeston's Boys; King's Revels Children.)\n\nThe playing companies did not need to spend money on scenery, and their stage props were often basic (necessarily, since every company made a substantial portion of its income by touring, and some companies toured consistently with no home theatre). Their costs in costumes, however, were high: actors playing kings, cardinals, princes, and noblemen had to look the part. Companies had hundreds of pounds of value invested in their costumes, in \"glaring satin suits\" and \"sumptuous dresses\" \"cloaks in scarlet with gold laces and buttons, and in purple satin adorned with silver;\" doublets of \"carnation velvet, flame, ginger, red and green; and women's gowns in white satin and cloth of gold.\" In 1605, Edward Alleyn estimated that his share in the \"apparell\" of the Admiral's Men was worth £100 and Alleyn was one of nine sharers in the company at the time. When a company got itself into financial difficulties, the members sometimes had to pawn their costumes, as Pembroke's Men did in the plague year of 1593.\n\nIn 1605 the actor Augustine Phillips left specific pieces of his wardrobe to an apprentice in his last will and testament including his \"mouse-colored\" velvet hose, purple cloak, white taffeta doublet, and black taffeta suit. To a modern sensibility, this may sound quaint and odd; but when \"a doublet and hose of seawater green satin cost £3\", the monetary value of Phillips' items was not negligible. Actors could face serious penalties for appropriating the costumes of their companies. [See Robert Dawes for an example.] (The players could defray some of their costs in the used clothing market. As an example, the King's Men bought discarded items of Gondomar's wardrobe for the actor playing the Black Knight in \"A Game at Chess\". Often, \"eminent lords and knights at their decease\" would leave articles of their finery to their servants much of it \"unseemly\" for servingmen and women to wear. Such garments would end up the property of the actors.)\n\nA second major cost lay in play scripts. In the years around 1600, playwrights could be paid as little as £6 to £7 per play (or about the price of two suits). Yet since the companies acted a constantly changing repertory, they needed an abundant supply of plays. Philip Henslowe's Diary records dozens of titles for the 1597–1603 period; when Worcester's Men were setting up for their first London season in 1602, they purchased a dozen new plays from Henslowe's stable of house playwrights, to supplement their existing stock.\n\nThe sharers in the company also paid wages to their hired men and boys. Wages differed somewhat over time and from company to company and case to case; but the general average minimum was 1 shilling per man per day, the same wage as that of an artisan worker. Boys cost perhaps half as much, though they were often maintained under some version of an apprenticeship arrangement, which could vary widely in details.\n\nPerformances at the public theatres were generally allowed six days per week; the theatres were closed on Sundays and major religious holidays like Good Friday. Other restrictions were laid upon the players, some of which they evaded as consistently as they could. They were supposed to cease playing entirely during Lent but violated this stricture regularly. In the spring of 1592, for example, the Lord Strange's Men played daily at the Rose Theatre right through Lent. After 1623, companies circumvented the Lenten restriction through the simple expedient of paying bribes to Sir Henry Herbert, the Master of the Revels.\n\nOne restriction that the players observed, one that was too serious to violate, was the prohibition enforced whenever bubonic plague rose from endemic to epidemic levels. Through much of the English Renaissance period, the theatres were shut down when the death figures in the plague bill (the weekly mortality report for London and some suburban parishes) rose above a certain level. In 1604 that cut-off number was set at 30 per week; in 1607 it was raised to 40. A serious epidemic closed the theatres almost entirely from June 1592 through April 1594; 11,000 Londoners died of plague in 1593. (The plague tended to abate in the colder weather of winter; the theatres opened for short seasons during the winter months of those years.) 1603 was another bad plague year, with 30,000 deaths in London; the theatres were closed from March 1603 to perhaps April 1604. \n\nOther serious epidemics caused theatre closures in 1625 (for eight months, to October) and from May 1636 to October 1637. These periods of closure were always traumatically difficult for the acting troupes; some survived by touring cities and towns outside London...and some didn't survive at all.\n\nThe explosion of popular drama that began when James Burbage built the first fixed and permanent venue for drama, The Theatre, in 1576 was the one great step away from the medieval organizational model and toward the commercial theatre; but that evolution was, at best, a \"work in progress\" throughout the English Renaissance. Throughout this period, troupes of actors needed to maintain the patronage of a noble household. The prevailing legal system in England defined \"masterless men\" who traveled about the country as vagabonds, and subjected them to treatments of varying harshness. Local authorities tended to be more hostile than welcoming toward players; the Corporation of London, from the Lord Mayor and aldermen down, was famously hostile to acting troupes, as were the Puritans. Noble patronage was, at the very least, the legal fig leaf that allowed professional players to function in society.\n\nIn some cases, more so toward the end of the period, noble patronage was nothing more than that legal fig leaf; a company of actors was an independent entity, financially and otherwise. Conversely, some noblemen were beneficent patrons of their players. The Lords Hunsdon Henry Carey, 1st Baron Hunsdon (c. 1524–96), and his son George Carey, 2nd Baron Hunsdon (1547–1603) were valuable protectors of their own company, and, when they served in the office of Lord Chamberlain (1585–96 and 1597–1603 respectively), of English drama as a whole.\n\nThat company of Hunsdon's, known to posterity as The Lord Chamberlain's Men, was organized somewhat like a modern joint-stock commercial company (the concept of which was just beginning to evolve in this era) at its re-formation in 1594, after the long plague closure. The company had a small number of partners or shareholders, who pooled their funds to pay expenses and in turn shared the profits, in what was largely a de facto democratic way (at least for the sharers, if not for the hired men and apprentices they employed). Their main rivals, the Admiral's Men, suffered in contrast under a less ideal version of capitalist organization: Philip Henslowe functioned more like a blend of big-business autocrat, landlord, and loan shark. He managed multiple companies of actors and built and owned several theatres, and controlled players (sharers included) and playwrights by doling out payments and loans. (The silver lining in this cloud is that Henslowe's surviving financial records provide a wealth of detailed knowledge about the theatre conditions in his era that is unparalleled by any other source.) Other companies varied between these extremes of organization. (Francis Langley, builder of the Swan Theatre, operated much as Henslowe did, though less successfully, and for a shorter time.) \n\nDrama in the age of Elizabeth was at best an organized disorder; suppression of individual companies, and even the profession as a whole, for political reasons was not unknown. [See: \"The Isle of Dogs\".] Local residents sometimes opposed theatres in their neighborhoods. Individual companies of actors struggled and failed and recombined; tracking the changes has been the obsession of scholars and the bane of students. \n\nYet the drama was also enormously popular, from the Queen and Court down to the commonest of the common people; indeed, the odd polarity of the theatre audience in this period, with the High and the Low favoring the drama, and the middle class generally more hostile with the growth of Puritan sentiments, is a surprising and intriguing phenomenon. Theatres proliferated, especially (though not exclusively) in neighborhoods outside the city's walls and the Corporation's control in Shoreditch to the north, or the Bankside and Paris Garden in Southwark, on the southern bank of the River Thames: the Curtain, the Rose, the Swan, the Fortune, the Globe, the Blackfrairs a famous roster.\n\nKing James, \"VI and I\", was passionately fond of drama; and theatrical activity at Court accelerated from the start of his reign. Consider the following figures.\n\nIn roughly the last decade of Elizabeth's reign, 1594–1603, there were 64 theatrical performances at Court, for an average of 6 or 7 a year:\n\nCompare a total of 299 for a somewhat longer period in the first portion of James' reign, 1603–16, an average of more than 20 per year:\n\nThe major companies acquired royal patronage: the Lord Chamberlain's Men became the King's Men, and the Admiral's Men became Prince Henry's Men, under the patronage of the King's eldest son. A company of Queen Anne's Men was built out of the pre-existent Oxford's and Pembroke's Men, companies that were largely devoted to touring the provinces in the previous reign. In 1608 a company was organized under the title of the King's second son, the eight-year-old Charles; this company, the Duke of York's Men, was called Prince Charles's Men after Prince Henry unexpectedly died in 1612.\n\nCompanies continued to form, evolve, and dissolve in the early Jacobean era the King's Revels Children, the Lady Elizabeth's Men; but by the midpoint of James' reign, around the time of Shakespeare's death in 1616, the dramatic scene had generally stabilized into four important companies. These were: the King's Men, at the Globe and Blackfriars Theatres; Palsgrave's Men (formerly the Admiral's and Prince Henry's Men), at the Fortune; Prince Charles's Men, at the Hope; and Queen Anne's Men, at the Red Bull Theatre.\n\nTheatrical evolution continued, sometimes tied to the lives and deaths of royal patrons. Queen Anne's Men disbanded with the death of Anne of Denmark in 1619; the accession of a new queen in 1625 saw the creation of Queen Henrietta's Men. Occasionally there were other new companies like Beeston's Boys, and new theatres like the Salisbury Court. The two prolonged closings of the London theatres due to plague, in 1625 and 1636–37, caused significant disruption in the acting profession, with companies breaking apart, combining and re-combining, and switching theatres, in a dizzying confusion. (Only the King's Men were exempt.) Political suppressions also came along in the Stuart era, though they affected only single offending companies until a general political suppression closed the theatres from 1642 to 1660, and brought the age of English Renaissance theatre to its end.\n\n"}
{"id": "11869125", "url": "https://en.wikipedia.org/wiki?curid=11869125", "title": "Political thought and legacy of Ruhollah Khomeini", "text": "Political thought and legacy of Ruhollah Khomeini\n\nKhomeinism is the founding ideology of the Islamic Republic of Iran. Impact of the religious and political ideas of that leader of the Iranian Islamic Revolution, Grand Ayatollah Ruhollah Khomeini include replacing Iran's millennia-old monarchy with theocracy. Khomeini declared Islamic jurists the true holders of not only religious authority but political authority, who must be obeyed as \"an expression of obedience to God\", and whose rule has \"precedence over all secondary ordinances [in Islam] such as prayer, fasting, and pilgrimage.\"\n\nSince his death, politics in the Islamic Republic of Iran have been \"largely defined by attempts to claim Khomeini's legacy\", according to at least one scholar, and \"staying faithful to his ideology has been the litmus test for all political activity\" there.\n\nAccording to Vali Nasr, outside of Iran, Khomeini's influence has been felt among the large Shia populations of Iraq and Lebanon. In the non-Muslim world, Khomeini had a great impact on the West and even Western popular culture where it is said he became \"the virtual face of Islam\" who \"inculcated fear and distrust towards Islam.\"\n\nAyatollah Khomeini was a senior Islamic jurist cleric of Shia (Twelvers) Islam. Shia theology holds that Wilayah or Islamic leadership belongs to divinely-appointed line of Shia Imams descended from the Prophet Muhammad, the last of which is the 12th Imam, Muhammad al-Mahdi. The God-given (Infallible) knowledge and sense of justice of the Imams makes them the definitive reference for (Shia) Muslims in every aspect of life, religious or otherwise, including governance. However, the twelfth Imam disappeared into what Shia believe is \"occultation\" (\"ghaybat\") in 939 AD and so has not been present to rule over the Muslim community for over thousand years.\n\nIn the absence of the Imam, Shia scholars/religious leaders accepted the idea of non-religious leaders (typically a sultan, king, or shah) managing political affairs, defending Shia Muslims and their territory, but no consensus emerged among the scholars as to how Muslims should relate to those leaders. Shia jurists have tended to stick to one of three approaches to the state: cooperating with it, becoming active in politics to influence its policies, or most commonly, remaining aloof from it.\n\nFor some years, Khomeini opted for the second of these three, believing Islam should encompass all aspects of life, especially the state, and disapproving of Iran's weak Qajar dynasty, the western concepts and language borrowed in the 1906 constitution, and especially the authoritarian secularism and modernization of the Pahlavi Shahs. Precedents for this approach included the theory of \"co-working with the just sultan\" put forward by Sayyed Murtaza during the Buyid era in his work \"Al-Resala Al-Amal Ma'a Sultan\" about 1000 years ago, and his idea was developed further by Nasir al-Din al-Tusi. Clerical political influence was institutionalized during the Safavid Empire about 500 years ago. In modern times the Grand Ayatollah Mirza Shirazi intervened against Nasir al-Din Shah when that Qajar Shah gave a 50-year monopoly over the distribution and exportation of tobacco to a foreign non-Muslim. Shirazi issued the famous fatwa against the usage of tobacco as part of the Tobacco Protest.\n\nIn 1970 Khomeini broke from this tradition developing a fourth approach to the state, a revolutionary change in Shia Islam proclaiming that monarchy was inherently unjust, and religious legal scholars should not just become involved in politics but rule. (see below)\n\nAt least one scholar has argued that Khomeini's \"decrees, sermons, interviews, and political pronouncements\" have outlasted his theological works because it is the former and not the latter that the Islamic Republic of Iran \"constantly reprints.\" Without the decrees, sermons, interviews, and political pronouncements \"there would have been no Khomeinism [ideology]. Without Khomeinism there would have been no revolution. And without the Islamic Revolution, Khomeini would have been no more than a footnote to Iranian history.\" \n\nOutside of his doctrinal beliefs, Khomeini has also been noted for being a \"brilliant tactician,\" with a great \"ability to improvise.\"\n\nKhomeini once protested the shah's enfranchisement of women, and then encouraged women to participate in his revolution and vote for his government when he needed their numbers. He once promised that clerics would hold only temporary positions in government and then allowed them to hold the most senior positions. He pledged to continue the war against Iraq until its defeat and then abruptly made peace. He once said that the fact that \"I have said something does not mean that I should be bound by my word.\" Indeed, it is that suppleness, that ability to improvise that has outlived Khomeini and that continues to pervade the Islamic Republic, keeping it going.\n\nAt least one scholar has argued that Khomeini's ability to swing from one \"religiopolitical ... perspective to another\" has been exploited by followers to advance their various and competing agendas. In particular reformists such as Muhammad Khatami in search of more democracy and less theocracy. Another argues that Khomeini's \"ideological adaptability\" belie the \"label of fundamentalist\" applied to him in both the West and in Iran.\n\nAs to how jurists should influence governance, Ayatollah Khomeini's leadership changed direction over time as his views on governance evolved. On who should rule and what should be the ultimate authority in governance: \n\n\nWhile Khomeini was keenly focused on the ulama's right to rule and the state's \"moral and ideological foundation\", he did not dwell on the state's actually functioning or the \"particulars\" of its management. According to some scholars (Gheissari and Nasr) Khomeini never \"put forward a systematic definition of the Islamic state and Islamic economics; ... never described its machinery of government, instruments of control, social function, economic processes, or guiding values and principles.\" In his plan for Islamic Government by Islamic Jurists he wrote: \"The entire system of government and administration, together with necessary laws, lies ready for you. If the administration of the country calls for taxes, Islam has made the necessary provision; and if laws are needed, Islam has established them all. ... Everything is ready and waiting. All that remains is to draw up ministerial programs ...\" \n\nKhomeini preached the danger of plots by foreigners and their Iranian agents throughout his political career. His belief, common among all political persuasions in Iran, can be explained by the domination of Iran's politics for the past 200 years until the Islamic revolution, first by Russia and Britain, later the United States. Foreign agents were involved in all of Iran's three military coups: 1908 [Russian], 1921[British] and 1953 [UK and US].\n\nIn his series of speeches in which he argued for rule of the Muslim (and non-Muslim) world by Islamic jurists, Khomeini saw the need for theocratic rule to overcome the conspiracies of colonialists who were responsible for\n\nthe decline of Muslim civilization, the conservative `distortions` of Islam, and the divisions between nation-states, between Sunnis and Shiis, and between oppressors and oppressed. He argued that the colonial powers had for years sent Orientalists into the East to misinterpret Islam and the Koran and that the colonial powers had conspired to undermine Islam both with religious quietism and with secular ideologies, especially socialism, liberalism, monarchism, and nationalism. He claimed that Britain had instigated the 1905 Constitutional Revolution to subvert Islam: \"The Iranians who drafted the constitutional laws were receiving instructions directly from their British masters.`\"\n\nKhomeini also held the West responsible for a host of contemporary problems. He charged that colonial conspiracies kept the country poor and backward, exploited its resources, inflamed class antagonism, divided the clergy and alienated them from the masses, caused mischief among the tribes, infiltrated the universities, cultivated consumer instincts, and encouraged moral corruption, especially gambling, prostitution, drug addiction, and alcohol consumption.\n\nAt least one scholar (Ervand Abrahamian) sees \"far-reaching consequences\" in legacy of belief in ever-present conspiracy. If conspiracy dominates political action then \n\"those with view different from one's own were members of this or that foreign conspiracy. Thus political activists tended to equate competition with treason, ... One does not compromise and negotiate with spies and traitors; one locks them up or else shoots them. ... The result was detrimental for the development of political pluralism in Iran. ... Differences of opinion within organizations could not be accommodated; it was all too easy for leaders to expel dissidents as `foreign agents.`\n\nAbrahamian believes that what he calls this \"paranoid style\" paved the way for the mass executions of 1981-82, where \"never before in Iran had firing squads executed so many in so short a time over so flimsy an accusation.\" \n\nOne scholar argues that Khomeini, \"his ideas, and his movement\" (an ideology he dubs \"Khomeinism\") bears a striking resemblance to populist movements in other countries, particularly those of South America such as Juan Perón and Getúlio Vargas. Like them Khomeini led a \"movement of the propertied middle class\" that mobilized \"the lower classes, especially the urban poor\" in a \"radical but pragmatic\" protest movement \"against the established order.\" It attacked \"the upper class and foreign powers,\" but not property rights, preaching \"a return to `native roots` and eradication of `cosmopolitan ideas.` It claimed \"a noncapitalist, noncommunist `third way` towards development,\" but was intellectually \"flexible\", emphasizing \"cultural, national, and political reconstruction,\" not economic and social revolution.\"\n\nLike those movements it celebrated the oppressed poor which it designated with a label (\"mostazafin\" by Khomeini, \"descamisados\" (coatless ones) by Peron, \"trabalhadores\" by Vargas), while actual power flowed from its leader who was \"elevated ... into a demigod towering above the people and embodying their historical roots, future destiny, and revolutionary martyrs.\" \n\nOthers would say Islam is distinct from Roman Catholicism and that its Middle Eastern beginnings separate it from Fascism.\n\nWhether Khomeini's ideas are compatible with democracy and whether he intended the Islamic Republic to be democratic is disputed. Notable Iranians who believe he did not include Mohammad Taghi Mesbah Yazdi (a senior cleric and main theorist of Iranian ultraconservatives who opposes democracy), Akbar Ganji (a pro-democracy activist and writer who is against Islamic government) and Abdolkarim Soroush (an Iranian philosopher in exile), according to Reza Parsa writing in the state-run \"Aftab News\". Other followers of Khomeini who believe he did support democracy and that the Islamic Republic is democratic include Ali Khamenei, Mohammad Khatami and Morteza Motahhari.\n\nKhomeini preached for theocratic rule by jurists, but did not completely disavow \"democracy\", making statements at different times indicating both support and opposition to it. For example, telling a huge crowd of Iranians a month after his return to Iran, \"Do not use this term, `democratic.` That is the Western style,`\" \n\nOne explanation for this contradiction is what Khomeini meant by \"democracy.\" According to scholar Shaul Bakhash, it's highly unlikely Khomeini defined the term to mean \"a Western parliamentary democracy\" when he told others he wanted Iran to be democratic. \nKhomeini believed that the huge turnout of Iranians in anti-Shah demonstrations during the revolution meant that Iranians had already voted in a `referendum` for an Islamic republic, and that in Muslim countries Islam and Islamic law, \ntruly belong to the people. In contrast, in a republic or a constitutional monarchy, most of those claiming to be representatives of the majority of the people will approve anything they wish as law and then impose it on the entire population. \n\nIn drawing up the constitution of his Islamic Republic, he and his supporters agreed to include Western-democratic elements, such as an elected parliament and president, but some argue he believed Islamic elements, not Western-style elected parliaments and presidents, should prevail in government. After the ratifying of the Islamic constitution he told an interviewer that the constitution in no way contradicted democracy because the `people love the clergy, have faith in the clergy, and want to be guided by the clergy` and that it was right that Supreme Leader oversee the work of the non-clerical officials `to make sure they don't make mistakes or go against the law and the Quran.' \n\nAs the revolution was consolidated terms like \"democracy\" and \"liberalism\" - considered praiseworthy in the West - became words of criticism, while \"revolution\" and \"revolutionary\" were terms of praise.\n\nStill another scholar, non-Iranian Daniel Brumberg, argues that Khomeini's statements on politics were simply not \"straightforward, coherent, or consistent,\" and that in particular he contradicted his writings and statements on the primacy of the rule of the jurist with repeated statements on the importance of the leading role of the parliament, such as `the Majlis heads all affairs`, and `the majlis is higher than all the positions which exist in the country.` This, according to Brumberg, has created a legacy where his followers \"exploited these competing notions of authority\" to advance \"various agendas of their own.\" Reformist seizing on his statements about the importance majlis, and theocrats on those of rule by the clergy.\n\nOver the decades since the revolution Iran has not evolved towards a more liberal representative democratic system as some reformists and democrats had predicted, nor has theocratic rule of Islamic jurists spread to other countries as its founder had hoped.\n\nBefore taking power Khomeini expressed support for the Universal Declaration of Human Rights, \"We would like to act according to the Universal Declaration of Human Rights. We would like to be free. We would like independence.\", However once in power Khomeini took a firm line against dissent, warning opponents of theocracy for example: \"I repeat for the last time: abstain from holding meetings, from blathering, from publishing protests. Otherwise I will break your teeth.\" Khomeini believed that since Islamic government was essential for Islam, what threatened the government threatened Islam.\n\nIran adopted an alternative human rights declaration, the Cairo Declaration on Human Rights in Islam, in 1990 (one year after Khomeini's death), which differs from the Universal Declaration of Human Rights, requiring law to be in accordance with Sharia, denying complete equality with men for women, and forbidding speech that violates the \"dignity of Prophets\", or \"undermines moral and ethical values.\"\n\nOne observer, Iranian political historian Ervand Abrahamian, believes that some of the more well-known violations of international human rights initiated by Khomeini—the fatwa to kill British-citizen author Salman Rushdie and the mass executions of leftist political prisoners in 1988—can be explained best as a legacy for his followers. Abrahamian argues Khomeini wanted to \"forge unity\" among \"his disparate followers\", \"raise formidable -- if not insurmountable -- obstacles in the way of any future leader hoping to initiate a detente with the West,\" and most importantly to \"weed out the half-hearted from the true believers\", such as heir-designate Ayatollah Hussein-Ali Montazeri who protested the killings and was dismissed from his position.\n\nIn the realm of economics, Khomeini was known both for his lack of interest and conflicting views on the subject.\n\nHe famously replied to a question before the revolution about how the Islamic Republic would manage Iran's economy by saying economics was \"for donkeys\" (also translated as \"for fools\"), and expressed impatience with those who complained about the inflation and shortages following the revolution saying: `I cannot believe that the purpose of all these sacrifices was to have less expensive melons,` His lack of attention has been described as \"possibly one factor explaining the inchoate performance of the Iranian economy since the 1979 revolution,\" (along with the mismanagement by clerics trained in Islamic law but not economic science).\n\nKhomeini has also been described as being \"quite genuinely of two minds\", and of having \"ambiguous and contradictory attitudes\" on the role of the state in the economy. He agreed with conservative clerics and the bazaar (traditional merchant class) on the importance of strict sharia law and respect for the sanctity of private property, but also made populist promises such as free water and electricity and government-provided homes for the poor, which could only be provided, if at all, by massive government intervention in the economy in violation of traditional Shariah law. While Khomeini was alive the conflict attitudes were represented in the clash between the populists of the Parliament and the conservatives of the Guardian Council.\n\nAfter his death until 1997, the \"bazaari side\" of the legacy predominated with the regime of president Akbar Hashemi Rafsanjani. Rafsanjani and Supreme Leader Ali Khamenei, emphasized `reconstruction,` `realism,` `work discipline,` `managerial skills,` `modern technology,` `expertise and competence,` `individual self-reliance,` `entrepreneurship,` and `stability.`\" \n\nThe populist side of Khomeini's economic legacy is said to be found in Iran's last president, Mahmoud Ahmadinejad, who allegedly \"mirrored\" Khomeini's disdain for the \"donkey\" science of economics, wearing \"his contempt for economic orthodoxy as a badge of honour\", and overseeing sluggish growth and rising inflation and unemployment under his administration.\n\nKhomeini strongly opposed Marxism. `Atheistic Marxists` were the one group he excluded from the broad coalition of anti-Shah groups he worked to rally behind his leadership. In his last will and testament, he urged future generations to respect property on the grounds that free enterprise turns the `wheels of the economy` and prosperity would produce `social justice` for all, including the poor. Islam differs sharply from communism. Whereas we respect private property, communism advocates the sharing of all things - including wives and homosexuals. What one scholar has called the populist thrust of Khomeini can be found in the fact that after the revolution, revolutionary tribunals expropriated \"agribusinesses, large factories, and luxury homes belonging to the former elite,\" but were careful to avoid \"challenging the concept of private property.\" \n\nOn the other hand, Khomeini's revolutionary movement was influenced by Islamic leftist and thinker Ali Shariati, and the leftist currents of the 1960s and 1970s. Khomeini proclaimed Islam on the side of the \"mustazafin\" and against exploiters and imperialists. In part for this reason a large section of Iran's economy was nationalized during the revolution. Today, Iran's public sector and government work force remains very large. Despite complaints by free marketers, \"about 60% of the economy is directly controlled and centrally planned by the state, and another 10%-20% is in the hands of five semi-governmental foundations, who control much of the non-oil economy and are accountable to no one except the supreme leader.\" \n\nBefore the Revolution, Khomeini expressed the following:\nIn an Islamic order, women enjoy the same rights as men - rights to education, work, ownership, to vote in elections and to be voted in. Women are free, just like men to decide their own destinies and activities.\n\nAfter the Revolution, Khomeini opposed allowing women to serve in parliament, likening it to prostitution. \nWe are against this prostitution. We object to such wrongdoings ... Is progress achieved by sending women to the majlis? Sending women to these centers is nothing but corruption.\n\nKhomeini made a number of changes to Shia clerical system. Along with his January 1989 ruling that sharia was subordinate to the revolution, he affirmed against tradition that the fatwa pronounced by a grand ayatollah survived that ayatollah (such as the fatwa to kill Salman Rushdie), and defrocked Ayatollah Mohammad Kazem Shariatmadari, a political opponent.\n\nIn \"Fiqh\", (Islamic jurisprudence) some scholars have argued Khomeini championed innovative reinterpretations of doctrine, prompted by the challenges of managing a country of 50 million plus.\n\n\n\"Esmat\" is perfection through faith. Khomeini believed not only that truly just and divine Islamic government need not wait for the return of the 12th Imam/Mahdi, but that \"divinely bestowed freedom from error and sin\" (\"esmat\") was not the exclusive property of the prophets and imams. \"Esmat\" required \"nothing other than perfect faith\" and could be achieved by a Muslim who reaches that state. Hamid Dabashi argues Khomeini's theory of Esmat from faith helped \"to secure the all-important attribute of infallibility for himself as a member of the awlia' [friend of God] by eliminating the simultaneous theological and Imamological problems of violating the immanent expectation of the Mahdi.\" Thus by \"securing\" this \"attribute of infallibility for himself\", Khomeini reassured Shia Muslims who might otherwise be hesitant about granting him the same ruling authority due the 12 Imams.\n\nKhomeini believed the Prophets have not yet achieve their \"purpose\". In November 1985 he told radio listeners, \"I should say that so far the purpose of the Prophets has seldom been realized. Very little.\" Aware of the controversial nature of the statement he warned more conservative clerics that \"tomorrow court mullahs . . . [should] not say that Khomeini said that the Prophet is incapable of achieving his aims.\" He also controversially stated that Fatimah, the daughter of Muhammad, was superior in status to the prophets of God.\n\nKhomeini's authority and charismatic personality prevented less popular jurists from protesting these changes as un-Islamic Bid‘ah.\n\nPerhaps the most significant legacy of Khomeini internationally is a broader definition of martyrdom to include Istishhad, or \"self-martyrdom\". Khomeini believed martyrdom could come not only from \"inadvertent\" death but \"deliberate\" as well. While martyrdom has always been celebrated in Islam and martyrs promised a place in heaven, (Q3:169-171) the idea that opportunities for martyrdom were important has not always been so common. Khomeini not only praised the large numbers of young Shia Iranians who became \"shahids\" during the Iran–Iraq War but asserted the war was \"God's hidden gift\", or as one scholar of Khomeini put it, \"a vital outlet through which Iran's young martyrs experienced mystical transcendence.\" Khomeini explained:\n\n\"If the great martyr (Imam Husayn ibn Ali) ... confined himself to praying ... the great tragedy of Kabala would not have come about ... Among the contemporary ulema, if the great Ayatollah ... Shirazi ... thought like these people [who do not fight for Islam], a war would not have taken place in Iraq ... all those Muslims would not have been martyred.\" \n\nDeath might seem like a tragedy to some but in reality ...\n\nIf you have any tie or link binding you to this world in love, try to sever it. This world, despite all its apparent splendor and charm, is too worthless to be loved\n\nKhomeini never wavered from his faith in the war as God's will, and observers have related a number of examples of his impatience with those who tried to convince him to stop it. When the war seemed to become a stalemate with hundreds of thousands killed and civilian areas being attacked by missiles, Khomeini was approached by Ayatollah Mehdi Haeri Yazdi, a grand ayatollah and former student with family ties to Khomeini. He pleaded with Khomeini to find a way to stop the killing saying, \"it is not right for Muslims to kill Muslims.\" Khomeini answered reproachfully, asking him, \"Do you also criticize God when he sends an earthquake?\" On another occasion a delegation of Muslim heads of state in Tehran to offer to mediate an end to the war were kept waiting for two hours and given no translator when Khomeini finally did talk to them.\n\nWhile suicide martyrdom did not win the Iran–Iraq War for Iran, it did spread to Lebanon, where it won victories for the Iraqi Islamic Da'wa party, Shia 'allies' of the Islamic Revolution there. The 1983 bombings against U.S. and French peacekeeping troops by Hizballah killed over 300 and drove the US and French from Lebanon. Another longer bombing campaign did likewise to the Israeli army. Khomeini is credited by some with inspiring these \"suicide bombers\".\n\nThe power of shaheed operations as a military tactic has been described by Shia Lebanese as an equalizer where faith and piety are used to counter superior military power of the Western unbeliever:\nYou look at it with a Western mentality. You regard it as barbaric and unjustified. We, on the other hand, see it as another means of war, but one which is also harmonious with our religion and beliefs. Take for example, an Israeli warplane or, better still, the American and British air power in the Gulf War. ... The goal of their mission and the outcome of their deeds was to kill and damage enemy positions just like us ... The only difference is that they had at their disposal state-of-the-art and top-of-the-range means and weaponry to achieve their aims. We have the minimum basics ... We ... do not seek material rewards, but heavenly one in the hereafter. \n\nThe victory of Hezbollah is known to have inspired Hamas in Palestine, al-Qaeda in its worldwide bombing campaign. In the years after Khomeini's death, \"Martyrdom operations\" or \"suicide bombing\" have spread beyond Shia Islam and beyond attacks on military and are now a major force in the Muslim world. According to one estimate, as of early 2008, 1,121 Muslim suicide bombers have blown themselves up in Iraq alone.\n\nIronically and tragically, in the last few years, thousands of Muslims, particularly Shia, have been victims, not just initiators, of martyrdom operations, with many civilians and even mosques and shrines being targeted, particularly in Iraq. Wahhabi extremist Abu Musab Al-Zarqawi has quoted Muhammad ibn Abd al-Wahhab urging his followers to kill Shi'a of Iraq. In 2007 some of the Shia ulema have responded by declaring suicide bombing haram:\n\n\"حتي كساني كه با انتحار مي‌آيند و مي‌زنند عده‌اي را مي‌كشند، آن هم به عنوان عمليات انتحاري، اينها در قعر جهنم هستند\"<br>\"Even those who kill people with suicide bombing, these shall meet the flames of hell.\"\n\nKhomeini showed little interest in the rituals of Shia Islam such as the Day of Ashura. Unlike earlier Iranian shahs or the Awadh's nawabs, he never presided over any Ashura observances, nor visited the enormously popular shrine of the eighth Imam in Mashad. This discouraging of popular Shia piety and Shia traditions by Khomeini and his core supporters has been explained by at least one observer as a product of their belief that Islam was first and foremost about Islamic law, and that the revolution itself was of \"equal significance\" to Battle of Karbala where the Imam Husayn was martyred.\n\nThis legacy is reflected in the surprise sometimes shown by foreign Shia hosts in Pakistan and elsewhere when visiting Iranian officials, such as Fawzah Rafsanjani, show their disdain for Shia shrines. And perhaps also in President Mahmoud Ahmadinejad's May 2005 statement that \"the Iranian revolution was of the same `essence` as Imam Husayn's movement.\"\n\nCompanions and followers of the Ayatollah Khomeini have many stories of his disinterest in his personal wealth and comfort and concern for others.\n\nWhile the Imam was sometimes flexible over doctrine, changing positions on divorce, music, birth control, he was much less accommodating with those he believed to be the enemies of Islam. Khomeini emphasized not only righteous militancy and rage but hatred,\nAnd I am confident that the Iranian people, particularly our youth, will keep alive in their hearts anger and hatred for the criminal Soviet Union and the warmongering United States. This must be until the banner of Islam flies over every house in the world.\nSalman Rushdie's apology for his book (following Khomeini's fatwa to kill the author) was rejected by Khomeini, who told Muslims: \"Even if Salman Rushdie repents and becomes the most pious man of all time, it is incumbent on every Muslim to employ everything he has got, his life and wealth, to send him to Hell.\" \n\nKhomeini felt let down by advisers who he felt had persuaded him to make unwise decisions against his better judgment, appointing people to posts who he later denounced. \"I swear to God that I was against appointing Medi Bazargan as the first prime minister, too, but I considered him to be a decent person. I also swear to God that I did not vote for Bani Sadr to become president either. On all these occasions I submitted to the advice of my friends.\" Before being revised in April 1989, the Iranian constitution called for the supreme leader to be a leading cleric (Marja), something Khomeini says he opposed \"since from the very beginning.\" \n\nHe also preached of Islam's essentially serious nature\nAllah did not create man so that he could have fun. The aim of creation was for mankind to be put to the test through hardship and prayer. An Islamic regime must be serious in every field. There are no jokes in Islam. There is no humor in Islam. There is no fun in Islam. There can be no fun and joy in whatever is serious. Islam does not allow swimming in the sea and is opposed to radio and television serials. Islam, however, allows marksmanship, horseback riding and competition ...\n\nand the all-encompassing nature of Islam, and thus of its law and its government,\n\nKhomeini strongly supported the spread of Islam throughout the world.\n\nWe shall export our revolution to the whole world. Until the cry 'There is no god but Allah' resounds over the whole world, there will be struggle.\n\nNot just as a faith but as a state.\n\nEstablishing the Islamic state world-wide belong to the great goals of the revolution.` \n\nWhich he believed would replace both capitalism and communism\n\n... `We have often proclaimed this truth in our domestic and foreign policy, namely that we have set as our goal the world-wide spread of the influence of Islam and the suppression of the rule of the world conquerors ... We wish to cause the corrupt roots of Zionism, capitalism and Communism to wither throughout the world. We wish, as does God almighty, to destroy the systems which are based on these three foundations, and to promote the Islamic order of the Prophet ... in the world of arrogance.` \n\nKhomeini made efforts to establish unity among Ummah. \"During the early days of the Revolution, Khomeini endeavored to bridge the gap between Shiites and Sunnis by forbidding criticizing the Caliphs who preceded Ali — an issue that causes much animosity between the two sects. Also, he declared it permissible for Shiites to pray behind Sunni imams.\" These measures have been viewed as being legitimised by the Shia practice of taqiyya (dissimulation), in order to maintain Muslim unity and fraternity.\n\nShortly before he died the famous South Asian Islamist Abul Ala Maududi paid Khomeini the compliment of saying he wished he had accomplished what Khomeini had, and that he would have like to have been able to visit Iran to see the revolution for himself.\n\nHe supported \"Unity Week\" and \"International Day of Quds.\" However, according to Sa`id Hawwa in his book \"al-Khumayniyya\", Khomeini's real aim was to spread Shi'ism through the use of such tactics as taqiyya and anti-Zionist rhetoric.\n\nThis pan-Islamism did not extend to the Wahhabi regime of Saudi Arabia. Under his leadership the Iranian government cut relation with Saudi Arabia. Khomeini declared that Iran may one day start good diplomatic relation with the US or Iraq but never with Saudi Arabia. Iran did not re-establish diplomatic relation with Saudi Arabia until March 1991, after Khomeini's death.\n\nThe Iranian revolution \"awakened\" Shia around the world, who outside of Iran were subordinate to Sunnis. Shia \"became bolder in their demands of rights and representations\", and in some instances Khomeini supported them. In Pakistan, he is reported to have told Pakistan military ruler Zia ul-Haq that he would do to al-Haq \"what he had done to the Shah\" if al-Haq mistreated Shia. When tens of thousands of Shia protested for exemption from Islamic taxes based on Sunni law, al-Haq conceded to their demands.\n\nShia Islamist groups that sprang up during the 1980s, often \"receiving financial and political support from Tehran\" include the Amal Movement of Musa al-Sadr and later the Hezbollah movement in Lebanon, Islamic Dawa Party in Iraq, Hizb-e Wahdat in Afghanistan, Tahrik-e Jafaria in Pakistan, al-Wifaq in Bahrain, and the Saudi Hezbollah and al-Haraka al-Islahiya al-Islamiya in Saudi Arabia. Shia were involved in the 1979-80 riots and demonstrations in oil-rich eastern Saudi Arabia, the 1981 Bahraini coup d'état attempt and the 1983 Kuwait bombings.\n\nKhomeini strongly opposed alliances with, or imitation of, Eastern (Communist) and Western Bloc (Capitalist) nations.\n\n... in our domestic and foreign policy, ... we have set as our goal the world-wide spread of the influence of Islam ... We wish to cause the corrupt roots of Zionism, capitalism and Communism to wither throughout the world. We wish, as does God almighty, to destroy the systems which are based on these three foundations, and to promote the Islamic order of the Prophet ... \n\nIn the \"Last Message, The Political and Divine Will of His Holiness the Imam Khomeini\", there are no less than 21 warnings on the dangers of what the west or east, or of pro-western or pro-eastern agents are either doing, have done or will do to Islam and the rest of the world.\n\nIn particular he loathed the United States\nand its ally Israel\nthe international Zionism does not stop short of any crime to achieve its base and greedy desires, crimes that the tongue and pen are ashamed to utter or write.\n\nKhomeini believed that Iran should strive towards self-reliance. Rather siding with one or the other of the world's two blocks (at the time of the revolution), he favored the allying of Muslim states with each other, or rather their union in one state. In his book he hinted governments would soon fall into line if an Islamic government was established.\nIf the form of government willed by Islam were to come into being, none of the governments now existing in the world would be able to resist it; they would all capitulate.\n\nWhile the Eastern or Soviet bloc no longer exists, Khomeini's legacy lives on in the Western world. From the beginning of the Iranian revolution to the time of his death Khomeini's \"glowering visage became the virtual face of Islam in Western popular culture\" and \"inculcated fear and distrust towards Islam.\" He is said to have made the word `Ayatollah` \"a synonym for a dangerous madman ... in popular parlance.\"His fatwa calling for the death of secular Muslim author Salman Rushdie in particular was seen by some as a deft attempt to create a wedge issue that would prevent Muslims from imitating the West by \"dividing Muslims from Westerners along the default lines of culture.\" The fatwa was greeted with headlines such as one in the popular British newspaper the \"Daily Mirror\" referring to Khomeini as \"that Mad Mullah\", observations in a British magazine that the Ayatollah seemed \"a familiar ghost from the past - one of those villainous Muslim clerics, a Faqir of Ipi or a mad Mullah, who used to be portrayed, larger than life, in popular histories of the British Empire\", and laments that Khomeini fed the Western stereotype of \"the backward, cruel, rigid Muslim, burning books and threatening to kill the blasphemer.\" The fatwa indicated Khomeini's contempt for the right to life; for the presumption of innocence; for the rule of law; and for national sovereignty, since he ordered Rushdie killed 'wherever he is found' \n\nThis was particularly the case in the largest nation of the Western bloc—the United States (or \"Great Satan\")—where Khomeini and the Islamic Republic are remembered for the American embassy hostage taking and accused of sponsoring hostage-taking and terrorist attacks—especially using the Lebanese Shi'a Islamic group Hezbollah—and which continues to apply economic sanctions against Iran. Popular feeling during the hostage-taking was so high in the United States that some Iranians complained that they felt the need to hide their Iranian identity for fear of physical attack even at universities.\n\n\n\n\nSome books by and on Ayatollah Khomeini:\nPictures of Ayatollah Khomeini:\nCritics of Ayatollah Khomeini:\nBiography of Ayatollah Khomeini\n"}
{"id": "29634967", "url": "https://en.wikipedia.org/wiki?curid=29634967", "title": "Professionalization and institutionalization of history", "text": "Professionalization and institutionalization of history\n\nProfessionalization and institutionalization of history is term used in historiography to describe process of professionalization of the historical discipline with historians becoming professionals through process of special education, and genesis of historical institutions they founded.\n\nDuring process of professionalization of history being historian became not only occupation but profession of the highest integrity and competence. Professionalization of history is the process of acquiring the following characteristics of profession for occupation of historian:\n\nThis process results with privileged access to financial and social rewards for its members.\n\nThe term institutionalisation is widely used in social theory to refer to the process of embedding something (for example a concept, a social role, a particular value or mode of behaviour) within an organisation, social system, or society as a whole.\n\n\n"}
{"id": "2021827", "url": "https://en.wikipedia.org/wiki?curid=2021827", "title": "René Louis de Voyer de Paulmy d'Argenson", "text": "René Louis de Voyer de Paulmy d'Argenson\n\nRené-Louis de Voyer de Paulmy, Marquis d'Argenson (18 October 169426 January 1757) was a French statesman.\n\nD'Argenson, the eldest son of Marc-René de Voyer de Paulmy d'Argenson, was a lawyer, and held successively the posts of councillor at the parlement (1716), \"maître des requêtes\" (1718), councillor of state (1719), and intendant of justice, police and finance in Hainaut. During his five years’ tenure of the last office he was mainly employed in provisioning the troops, who were suffering from the economic confusion resulting from John Law’s system and the aftermath of the Mississippi Bubble.\n\nD'Argenson returned to court in 1724 to exercise his functions as councillor of state. At that time he had the reputation of being a conscientious man, but ill-adapted to intrigue, and was nicknamed \"la bête\". He entered into relations with the philosophers, and was won over to the ideas of reform. He was the friend of Voltaire, who had been a fellow-student of his at the Jesuit college Louis-le-Grand, and frequented the Club de l'Entresol, the history of which he wrote in his memoirs. It was then that he prepared his \"Considérations sur le gouvernement de la France\", which was published posthumously by his son.\n\nD'Argenson was also the friend and counsellor of the minister Germain Louis Chauvelin. In May 1744 he was appointed member of the council of finance, and in November of the same year King Louis XV chose him as secretary of state for foreign affairs, his brother, Marc-Pierre, Comte d'Argenson, being at the same time secretary of state for war. France was at that time engaged in the War of the Austrian Succession, and the government had been placed by Louis XV virtually in the hands of the two brothers. The marquis d’Argenson endeavoured to reform the system of international relations. He dreamed of a \"European Republic\", and wished to establish arbitration between nations in pursuance of the ideas of his friend the abbé de Saint-Pierre. But he failed to realize any part of his projects. The generals negotiated in opposition to his instructions; his colleagues laid the blame on him; the intrigues of the courtiers passed unnoticed by him; whilst the secret diplomacy of the king neutralized his initiative. He concluded the marriage of the Louis, the Dauphin to \nMaria, a daughter of King Augustus III of Poland, but was unable to prevent the election of the Francis, Grand-Duke of Tuscany as Holy Roman Emperor in 1745.\n\nOn 10 January 1747 Louis XV thanked d'Argenson for his services. He then retired into private life, eschewed the court, associated with Voltaire, Condillac and d’Alembert, and spent his declining years in working at the Académie des Inscriptions, of which he was appointed president by the king in 1747, and revising his \"Mémoires\". Voltaire, in one of his letters, declared him to be \"the best citizen that had ever tasted the ministry\". He died on 26 January 1757.\n\nD'Argenson left a large number of manuscript works, of which his son, Marc Antoine René, Marquis de Paulmy, published the \"Considérations sur le gouvernement de France\" (Amsterdam, 1764) and \"Essais dans le goût de ceux de Montaigne\" (Amsterdam, 1785). The latter, which contains many useful biographical notes and portraits of his contemporaries, was republished in 1787 as \"Loisirs d’un ministre d’état\". D'Argenson’s most important work, however, is his \"Mémoires\", covering in great detail the years 1725 to 1756, with an introductory part giving his recollections since the year 1696. They are, as they were intended to be, valuable \"materials for the history of his time\". There are two important editions, the first, with some letters, not elsewhere published, by the marquis d’Argenson, his great-grand-nephew (5 vols., Paris, 1857 et seq.); the second, more correct, but less complete, published by J. B. Rathery, for the Société de l’Histoire de France (9 vols., Paris, 1859 et seq.). The other works of the marquis d’Argenson, in MS., were destroyed in the fire at the Louvre library in 1871.\n\nD'Argenson married and had a son:\n\n"}
{"id": "49426305", "url": "https://en.wikipedia.org/wiki?curid=49426305", "title": "Sally Gregory Kohlstedt", "text": "Sally Gregory Kohlstedt\n\nSally Gregory Kohlstedt (born 1943) is an American historian of science. She is a professor in the Department of Earth Sciences and director of the Program in History of Science and Technology at the University of Minnesota. Kohlstedt served as the president of the History of Science Society from 1992–1993. Her research interests focus on the history of science in American culture and the demographics of scientific practice in institutions such as museums and educational institutions, including gender participation. \n\nKohlstedt received her B. A. from Valparaiso University (1965), her M. A. from Michigan State University (1966) and her Ph.D. from the University of Illinois at Urbana–Champaign (1972).\n\nKohlstedt was an assistant possessor at Department of History of Simmons College, 1971-1975; an assistant and later full professor at the Department of History of Syracuse University, 1975-1989. From 1989, she has been a professor at the University of Minnesota (UMN). From 1989 to 1995, she was Associate Dean for Academic Affairs of the College of Science and Engineering at UMN; from 1997 to 1999 she was director of the Center for Advanced Feminist Studies at UMN; from 2004-2006, Interim Chair of the Department of Anthropology at UMN; and from 2008, the director of the Program in History of Science and Technology. Her leadership and work as a teacher and mentor of women faculty and students has been described as \"nothing short of heroic\". She has also held visiting appointments at Cornell (1989), the University of Melbourne (1983), the University of Munich (1997), and the University of Auckland (2008), and the Max Planck Institute for the History of Science in Berlin (2015).\n\nKohlstedt studies relationships between science and culture. She is particularly interested in the history of women in science, including both obstacles and successes to the pursuit of equity, and examines the effects of women's participation and their impact on scientific practice. She is particularly interested in women's involvement in areas such as museums and educational practice. Kohlstedt received the 2013 History of Science Society’s Margaret Rossiter Prize for the Best Book on Women’s History for \"Teaching Children Science: Hands-On Nature Study in North America, 1890-1930\" (University of Chicago Press, 2010). The book examines the work of women in bringing natural science education into the American classroom.\n\nKohlstedt is a life member of the History of Science Society (HSS) and has been actively involved in a variety of roles including Secretary, 1978-l981; Council, l982-l984, \n1989-1991, and 1994-1995; Vice-President, 1990 and 1991 and President, 1992 and 1993, among others. She has been particularly active in the Women's Caucus of the HSS. She has also served on the Board of Directors of the American Association for the Advancement of Science (AAAS).\n\n\n"}
{"id": "19099472", "url": "https://en.wikipedia.org/wiki?curid=19099472", "title": "Scrubs (clothing)", "text": "Scrubs (clothing)\n\nScrubs are the sanitary clothing worn by surgeons, nurses, physicians and other workers involved in patient care in hospitals. Originally designed for use by surgeons and other operating room personnel, who would put them on when sterilizing themselves, or \"scrubbing in\", before surgery, they are now worn by many hospital personnel. Their use has been extended outside hospitals as well, to work environments where clothing may come into contact with infectious agents (veterinarians, midwives, etc.). Scrubs are designed to be simple (with minimal places for contaminants to hide), easy to launder, and cheap to replace if damaged or stained irreparably. In the United Kingdom, scrubs are sometimes known as Theatre Blues.\n\nThe spread of methicillin-resistant \"Staphylococcus aureus\" (MRSA) has increased the use of scrubs but can give wearers a false sense of security that they are 'clean' when in fact they are as easily contaminated as any other clothing.\n\nIn contrast to the uniforms long required of nurses, surgeons did not wear any kind of specialized garments until well into the 20th century. Surgical procedures were conducted in an operating theater. The surgeon wore his own clothes, with perhaps a butcher's apron to protect his clothing from blood stains, and he operated bare-handed with non-sterile instruments and supplies. (Gut and silk sutures were sold as open strands with reusable hand-threaded needles; packing gauze was made of sweepings from the floors of cotton mills.) In contrast to today's concept of surgery as a profession that emphasizes cleanliness and conscientiousness, up to the early 20th century the mark of a busy and successful surgeon was the profusion of blood and fluids on his clothes. The importance of dress as a badge of one's class in society was paramount and the processes behind the transmission of infection were the subject of controversy within the profession.\n\nWith the \"Spanish flu\" pandemic of 1918 and the growing medical interest in Lister's antiseptic theory, some surgeons began wearing cotton gauze masks in surgery; however, this was not to protect the patient from intra-operative infection, but to protect the surgeon from the patient's diseases. Around the same time, operating theatre staff began wearing heavy rubber gloves to protect their hands from the solutions used to clean the room and equipment, a practice surgeons grudgingly adopted.\n\nBy the 1940s, advances in surgical antisepsis (now called aseptic technique) and the science of wound infection led to the adoption of antiseptic drapes and gowns for operating room use. Instruments, supplies and dressings were routinely sterilized by exposure to either high-pressure steam or ethylene oxide.\n\nOriginally, operating room attire was white to emphasize cleanliness. However, the combination of bright operating lights and an all-white environment led to eye strain for the surgeon and staff. By the 1950s and 1960s, most hospitals had abandoned white operating room apparel in favor of various shades of green, which provided a high-contrast environment, reduced eye fatigue, and made bright red blood splashes less conspicuous. \n\nBy the 1970s, surgical attire had largely reached its modern state—a short-sleeve V-necked shirt and drawstring pants or a short-sleeve calf-length dress, made of green cotton or cotton/polyester blend. Over this was worn a tie-back or bouffant-style cloth cap, a gauze or synthetic textile mask, a cloth or synthetic surgical gown, latex gloves, and supportive closed-toe shoes. This uniform was originally known as \"surgical greens\" because of its color, but came to be called \"scrubs\" because it was worn in a \"scrubbed\" environment.\n\nIn many operating rooms, it is forbidden to wear any exposed clothing, such as a t-shirt, beneath scrubs. As scrubs are designed to promote a clean environment, the wearing of outside clothing is thought to introduce unwanted pathogens.\nNearly all patient care personnel at hospitals in the United States wear some form of scrubs while on duty, as do some staffers in doctor, dental, and veterinary offices. Doctors in the United States may wear their own clothes with a white coat except for surgery. Support staff such as custodians and unit clerks also wear scrubs in some facilities. When the physician is not performing surgery, the scrub is often worn under a white coat.\n\nIn the UK, all NHS hospital trusts have stringent clothing policies, and many of these specifically forbid wearing the iconic white coat for medical staff, owing to infection control concerns. This has meant that several hospitals around the UK have opted for scrubs for staff, especially in Accident and Emergency departments.\n\nScrubs are also sometimes used as prison uniforms in the U.S and other countries.\n\nToday, any medical uniform consisting of a short-sleeve shirt and pants is known as \"scrubs\". Scrubs may also include a waist-length long-sleeved jacket with no lapels and stockinette cuffs, known as a \"warm-up jacket\". \n\nScrubs worn in surgery are almost always colored solid light grey, light green, light blue or a light green-blue shade.\n\nNon-surgical scrubs come in a wider variety of colors and patterns, ranging from official issue garments to custom made, whether by commercial uniform companies or by home-sewing using commercially available printed patterns.\n\nSome hospitals use scrub color to differentiate between patient care departments (i.e. Surgery, Childbirth, Emergency, etc.) or between licensed patient care personnel (nurses, radiologic technologists, respiratory and physical therapists, etc.), unlicensed assistive personnel, and non-patient care support staff (i.e. portering, dietary, unit clerks, etc...). Hospitals may also extend the practice to differentiate non-staff members/visitors.\n\nCustom-made printed scrub tops, featuring cartoon characters and cheerful prints, are common in pediatricians' offices, veterinary offices, dental clinics and children's hospitals, and prints for various holidays can be seen throughout the year. Some acute care facilities or larger hospitals also have relaxed rules regarding the wear of non-regulation scrubs in non-surgical units, and they are no longer just the classic v-neck scrub tops, but are now offered in many styles and patterns.\n\nThe scrub industry, much like maternity wear, used to have very limited fashion options. Indeed, scrubs were generally box shaped and ill fitted; often with limited design choices. Over the past 10 years, the scrub industry has taken notice of the individual preferences of medical professionals and have begun to design and manufacture fashionable and unique designs.\n\nSurgical scrubs are not generally owned by the wearer. Due to concerns about home laundering and sterility issues, these scrubs are usually hospital-owned or hospital-leased through a commercial linen service. And due to these laundering and sterility limitations, disposable scrub suits were introduced in the market.\n\nScrub caps have graduated from being functional to also being a personalized accessory both in the operating room and outside. Before the antiseptic focus of the 1940s, hats were not considered essential to surgery. From the 1940s through the 1950s, as a hygienic focus swept the industry, hats became standard wear to help protect patients from contaminants in hair. Full-face hats were even designed for men with beards. These hats have been and continue to be distributed by group purchasing organizations (GPOs) who supply hospitals with most equipment.\n\nIn the medical fashion 'revolution' of the seventies, more and more medical professionals began personalizing their scrubs by either sewing their own hats or buying premade hats made of eclectic fabric. Several styles were popular, including the 'bouffant' surgical cap, a utilitarian hairnet-like hat which typically comes in light blue, and the 'milkmaid', a bonnet-like wrap around hat.\n\nBouffant surgical caps are perhaps the most widely used scrub hats in hospitals, and their usage is not limited to only nurses and surgeons: hospital patients are required to wear a bouffant cap when having surgery of any kind.\n\nIn 2016, a controversy emerged around the use of cloth or disposable surgical caps vs mandatory use of bouffant style surgical caps. This controversy ended in state mandates for the use of bouffant caps to comply with Joint Commission standards.\n\n\nhttp://www.surgeine.com/knowledge/disposable-gowns%20-vs-reusable-gowns-an-understanding-for-an-effective-barrier-and-control-against-infection\n\n"}
{"id": "659583", "url": "https://en.wikipedia.org/wiki?curid=659583", "title": "Term (architecture)", "text": "Term (architecture)\n\nIn Classical architecture a term or terminal figure (plural: terms or termini) is a human head and bust that continues as a square tapering pillar-like form.\n\nThe name derives from Terminus, the Roman god of boundaries and boundary markers. If the bust is of Hermes as protector of boundaries in ancient Greek culture, with male genitals interrupting the plain base at the appropriate height, it may be called a herma or herm. The crime of Alcibiades and his drinking-mates, for which Socrates eventually indirectly paid with his life, was the desecration of herm figures through Athens in the dead of night.\n\nAt the Temple of Artemis at Ephesus, the Lady of Ephesus, whom the Greeks identified with Artemis, was a many-breasted goddess encased in a tapering term, from which her feet protruded. (See illustration at Temple of Artemis).\n\nIn the architecture and the painted architectural decoration of the European Renaissance and the succeeding Classical styles, term figures are quite common. Often they represent minor deities associated with fields and vineyards and the edges of woodland, Pan and fauns and Bacchantes especially, and they may be draped with garlands of fruit and flowers.\n\nTerm figures were a particularly characteristic feature of the 16th-century style in furniture and carved interior decoration that is called Antwerp Mannerism. Engravings disseminated the style through Germany and England.\n\nTerm figures as table supports or employed as candlestands (French \"guéridon\") were characteristic of the Late Baroque Louis XIV style in France, the Low Countries and England, revived in the neo-Palladian furniture designed by William Kent and employed again in the French Empire style of the early 19th century.\n\n\n"}
{"id": "3579189", "url": "https://en.wikipedia.org/wiki?curid=3579189", "title": "Timeline of Galician history", "text": "Timeline of Galician history\n\n\n\n\n\n\n\n\nFélix of Braga was the last bishop of Braga to reside there until 1070, due to the Moorish invasion. His successors established themselves in Lugo (Galicia).\n\n\n1032 Bermudo III of León, deprived of the capital city of Leon, retreated into Galicia.\n"}
{"id": "36053652", "url": "https://en.wikipedia.org/wiki?curid=36053652", "title": "Timeline of scientific computing", "text": "Timeline of scientific computing\n\nThe following is a timeline of scientific computing, also known as computational science.\n\n\n\n\n\n\nThis decade marks the first major strides to a modern computer, and hence the start of the modern era.\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "433763", "url": "https://en.wikipedia.org/wiki?curid=433763", "title": "Timeline of the 2000 Fijian coup d'état", "text": "Timeline of the 2000 Fijian coup d'état\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "184613", "url": "https://en.wikipedia.org/wiki?curid=184613", "title": "Timeline of the 2003 invasion of Iraq", "text": "Timeline of the 2003 invasion of Iraq\n\nThis is a timeline of the events surrounding the United States-led invasion of Iraq in 2003.\n\nU.S. President George W. Bush delivers a televised address to the world, in which he summarizes the past few months' events between the United States and Iraq. He demands that Saddam Hussein vacate his office and leave Iraq within two days, or else the U.S. and its allies will invade Iraq and depose his regime.\n\nProtests against a possible invasion of Iraq begin to take place around the world.\n\n\nThe first assaults on Baghdad begin shortly following the 01:00 UTC expiry of the United States' 48-hour deadline for Iraqi President Saddam Hussein and his sons to leave Iraq.\n\n\n\nOh, brave fighters! Hit your enemy with all your strength. Oh Iraqis, fight with the strength of the spirit of jihad which you carry in you and push them to the point where they cannot go on.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "25926315", "url": "https://en.wikipedia.org/wiki?curid=25926315", "title": "Yitzhak Baer", "text": "Yitzhak Baer\n\nYitzhak Baer (; 20 December 1888 – 22 January 1980) was a German-Israeli historian and an expert on medieval Spanish Jewish history.\n\nBaer was born in Halberstadt in the Prussian Province of Saxony, Germany, in 1888. He studied philosophy, history and classical philology at Berlin University, the University of Strasbourg and the University of Freiburg.\n\nHe emigrated to Mandate Palestine, now Israel, in 1930, and began lecturing on medieval Jewish history at the Hebrew University of Jerusalem. He was professor of medieval history at the University from 1932 to 1945.\n\n\n\n"}
