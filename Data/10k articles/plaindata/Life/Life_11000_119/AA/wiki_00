{"id": "927682", "url": "https://en.wikipedia.org/wiki?curid=927682", "title": "Air Zonk", "text": "Air Zonk\n\nAir Zonk (also called ) is a video game, a side-scrolling shooter released for the TurboGrafx 16 console in 1992. \"Air Zonk\" was an attempt to update the company's image via a modern, punkish character called Zonk, who bears a purposeful resemblance to the TurboGrafx-16's caveman mascot, Bonk.\n\nThe game was developed by Red, better known for their \"Gate of Thunder\" series. \"Air Zonk\" features King Drool, antagonist of the Bonk series, along with many other enemies from the series. It was followed by a sequel in 1993 called \"\" for the Turbo Duo, and has been released on the Wii's Virtual Console.\n\n\"Air Zonk\" is similar to other scrolling shooters, but includes companion characters. Artistically the game is lighthearted, featuring humorous bosses such as a sentient garbage heap and an anthropomorphic boat. The gameplay centers around the effective use of shooting and bombing to complete a stage. At the start, the player may pick a companion character to team up with to perform special attacks, limit themselves to using the designated companion characters for each level, or opt out of using companion characters altogether. Each companion character, or friend, can only be used once. Air Zonk takes on the distinct visual style that is sometimes called \"cute 'em up\". There are three difficulty levels: sweet, spicy, and bitter.\n\nZonk can charge his shots, which allows him to fire a more powerful attack. Charging longer causes Zonk to drop a bomb, which damages all enemies on the screen. Zonk can also acquire seven types of power-ups, each of which can also be charged for a unique special attack. As usual for scrolling shooters, whenever Zonk acquires a new power-up, he loses the current one. If Zonk is hit while he has a power-up, he loses the power-up but does not die, except in the case of the mini-Zonk power-up. The mini-Zonk power-up also differs from the other power-ups in that it cannot be charged, and can be found in both florets and random enemy drops (other power-ups can only be found in florets).\n\nZonk starts each stage alone and with no powerups. He must collect seven smiley-faces, the last of which will appear in giant form with sunglasses, in order to get his friend to join him. The friend initially acts as a \"Gradius\"-style support which follows Zonk around shooting projectiles. If the player collects another seven smiley-faces, Zonk and the friend will merge into a hybrid form, granting a new attack and 20 seconds of invulnerability. This new attack cannot be charged, and Zonk cannot drop bombs while in hybrid form. Once invincibility expires, if Zonk is hit he will revert to normal form and his friend will leave, though he retains whatever power-up he had before changing to hybrid form.\n\n\"Air Zonk\" was awarded Best TurboGrafx Game of 1992 by Electronic Gaming Monthly.\n\nIn addition to having its intro removed instead of translated, \"PC Denjin's\" vulgar humor was seriously toned down for \"Air Zonk\". The computer brain encased in glass shown at the start of each stage was a sentient pile of manure, the fusion with the cow character would cause Zonk to grow breasts and shoot them at enemies instead of bottles of milk from his hands. When charging the button, Zonk drops a bomb whereas in the original game he defecates.\n\n\"Air Zonk\" received a sequel in 1993 -- \"\" (also known as \"CD Denjin Rockabilly\"), which was released in the SuperCD format and requires the Super System Card to play on first-generation TurboGrafx-CD consoles. As its name would imply, the game has a CD audio soundtrack consisting of rockabilly music. The game contains all new levels, assistants, and enemies.\n\nThe protagonist in this game, Zonk, is a cyborg version of Bonk—the mascot for NEC Corporation's TurboGrafx-16 video game console. When TTi released the TurboDuo console (2nd generation successor to TurboGrafx-16), Zonk was adopted as the official mascot. Zonk adorned nearly all of TTi's promotional material, and was even featured on the package art for the TurboDuo console.\n\nAir Zonk was released on the Wii's Virtual Console in May in Japan, July in America, and on July 13 in Europe. It has gained an E rating from the ESRB. It was also released on the Wii U's Virtual Console in Japan on June 19, 2014.\n\n"}
{"id": "43725655", "url": "https://en.wikipedia.org/wiki?curid=43725655", "title": "Alfred Bayliss", "text": "Alfred Bayliss\n\nAlfred Bayliss (March 22, 1847 – August 26, 1911) was an English American educator from Gloucestershire. Orphaned shortly after his family emigrated to the United States, Bayliss worked his way into Hillsdale College in Michigan. After a two year break to fight in the Civil War, Bayliss graduated in 1870 and first oversaw schools in Indiana. He then came to Streator, Illinois to lead a school district, becoming superintendent of a high school in 1896. In 1898, Bayliss was elected Illinois Superintendent of Public Instruction. He later served as the second president of the Western Illinois State Normal School before falling to his death from a horse.\n\nAlfred Bayliss was born in Bledington, England on March 22, 1847. He emigrated to the United States with his family when he was a child, settling in Hillsdale, Michigan. Bayliss was orphaned when he was twelve. When he was fifteen or sixteen, he matriculated at Hillsdale College. However, he withdrew in 1863 to enlist in the 11th Michigan Volunteer Cavalry Regiment for the Civil War. He returned to college after the war, graduating in 1870.\n\nBayliss' first position out of college was superintendent of schools in LaGrange County, Indiana. In 1874, he took a position as superintendent of school district #3 in Sterling, Illinois. Bayliss spent the next twenty years in the district. He then ran for Illinois Superintendent of Public Instruction as a Republican, but was defeated in the primary by Samuel Inglis. Bayliss assumed the editorship of the \"Streator Standard\", then served in the role of first assistant clerk of the 39th Illinois General Assembly. Bayliss also edited \"The Child-Study Monthly\" periodical. In 1896, he was named Superintendent of Streator Township High School. He ran for the state superintendent again in 1898 and was elected. He served two consecutive four-year terms. Bayliss advocated for free high school education, although the state legislature did not adopt the idea. In 1906, Bayliss became the second President of the Western Illinois State Normal School, a role he held until his death.\n\nBayliss served as the president of the Northern Illinois Teachers' Association and vice president of the Illinois State Teachers Association. He was also a member of the State Committee on Educational Progress. In Streator, he served on the city council, commanded the Grand Army of the Republic chapter, and was once the chairman of the LaSalle County Republican Party. He married Clara Marie Kern in 1871; they had two daughters. On August 26, 1911, Bayliss died from injuries he sustained eleven days earlier after falling from a horse in Woodbine, Iowa. He was buried in Oakwood Cemetery in Macomb, Illinois.\n"}
{"id": "1492904", "url": "https://en.wikipedia.org/wiki?curid=1492904", "title": "Anatomy Act 1832", "text": "Anatomy Act 1832\n\nThe Anatomy Act 1832 (2 & 3 Will. IV c.75) is an Act of Parliament of the United Kingdom that gave freer licence to doctors, teachers of anatomy and bona fide medical students to dissect donated bodies. It was enacted in response to public revulsion at the illegal trade in corpses.\n\nThe 19th century ushered in a new-found medical interest in detailed anatomy thanks to an increase in the importance of surgery. In order to study anatomy, human cadavers were needed and thus ushered in the practice of grave robbing. Before 1832, the Murder Act 1752 stipulated that only the corpses of executed murderers could be used for dissection. By the early 19th century, the rise of medical science – coinciding with a reduction in the number of executions – had caused demand to outstrip supply.\n\nAround 1810, an anatomical society was formed to impress upon the government the necessity for altering the law. Among its members were John Abernethy, Charles Bell, Everard Home, Benjamin Brodie, Astley Cooper, and Henry Cline. The efforts of this body gave rise in 1828 to a select committee to report on the question. The report of this committee led to the Bill. Public revulsion at the recent West Port murders swayed opinion in favour of a change in the law. In 1831 public outcry at the activities of the London Burkers caused further pressure for a Bill.\n\nPublic sentiment notwithstanding, there was substantial opposition to the Bill.\n\nIn 1829 the Royal College of Surgeons petitioned against it, and it was withdrawn in the House of Lords owing to the opposition of the Archbishop of Canterbury William Howley.\n\nA new Anatomy Bill was introduced in 1832. Though strongly opposed by Hunt, Sadler, and Vyvyan, it was supported by Macaulay and O'Connell. It was passed by the House of Lords on 19 July 1832.\n\nThe Act provided that anyone intending to practise anatomy had to obtain a licence from the Home Secretary. Usually one or two teachers in each institution took out this licence, and hence were known as licensed teachers. They accepted responsibility for the proper treatment of all bodies dissected in the building for which their licence was granted.\n\nRegulating these licensed teachers, and receiving constant reports from them, were four inspectors of anatomy, one each for London, the rest of England and Wales, Scotland, and Ireland, who reported to the Home Secretary, and knew the whereabouts of every body being dissected. \n\nThe principal provision of the Act was section 7, which stipulated that a person having lawful possession of a body could permit it to undergo \"anatomical examination\" (dissection) provided that no relative objected. Most of the other sections were subsidiary, detailing the methods for carrying section 7 into effect.\n\nIn addition, section 16 repealed parts of sections 4 and 5 of the Offences Against the Person Act 1828, which had consolidated several provisions from several earlier statutes and had retained the provision of 1752 that the bodies of murderers were to be hung in chains or dissected after execution. Section 16 provided instead that such bodies were to be either hung in chains or buried within the precincts of the last prison in which the deceased had been confined. The provision for hanging in chains was repealed by the Hanging in Chains Act 1834, and the whole section was repealed and replaced by section 3 of the Offences against the Person Act 1861.\n\nThe Anatomy Act provided for the needs of physicians, surgeons, and students by giving them legal access to corpses that were unclaimed after death – in particular, corpses of those who had died in hospital, prison, or a workhouse.\n\nFurther, a person could donate the corpse of a next of kin in exchange for burial at the expense of the anatomy school. Occasionally a person, following the example of Jeremy Bentham, left their own body for dissection in the name of the advancement of science; but even then, if the person's relatives objected, it was not received. \n\nBefore the Act, anatomical research was difficult; for example, the anatomy of the nervous system was poorly understood.\n\nThe Act was effective in ending the practice of resurrectionists, who robbed graves as a means of obtaining corpses for medical study.\n\nMobs continued to protest against the Act into the 1840s, in the belief that it still failed to prevent the sale of paupers' bodies for medical research without their consent. An anatomical theatre in Cambridge was vandalised late in 1833 \"by an angry mob determined to put a stop to the dissection of a man; this wave of popular protest alarmed the medical profession who resolved to hide its activities from the general public, and to a greater or lesser extent it has been doing so ever since\".\n\nThe original extent was specified as \"Great Britain\" and \"Ireland\". The Act (less any amendments) remains in force in Scotland and the Republic of Ireland.\n\nThe Act remains in force, with amendments, under the Human Tissue (Scotland) Act 2006; Scotland retains an Inspector of Anatomy.\n\nThe Act remains in the Irish Statute Book \n\nThe Act was repealed by the Anatomy Act 1984, which was in turn repealed by the Human Tissue Act 2004. Access to corpses for the purposes of medical science is now regulated by the Human Tissue Authority.\n\nThe Act was repealed by the Anatomy (Northern Ireland) Order 1992, itself later repealed.\n\n\n"}
{"id": "3694243", "url": "https://en.wikipedia.org/wiki?curid=3694243", "title": "Ashes to Ashes (Star Trek: Voyager)", "text": "Ashes to Ashes (Star Trek: Voyager)\n\n\"Ashes to Ashes\" is the 138th episode of \"\", the 18th episode of the . It has an average fan rating of 4/5 on the official Star Trek web site as of September 2009.\n\nAn alien contacts \"Voyager\", claiming to be a deceased member of the crew, Ensign Lyndsay Ballard / Jhet'leya. She explains that an alien race, the Kobali, reanimated her after her coffin was buried in space. The Kobali reproduce by altering the DNA of dead individuals of other races, although such people are (at least initially) prisoners of the Kobali so that they can more easily adjust to their new lives. Ballard escaped from her 'new' family, stole a ship, and spent 6 months searching for \"Voyager\".\n\nWhen she finds \"Voyager\", she is under attack from a Kobali vessel. Disabling the pursuing vessel, she makes audio contact with \"Voyager\"—only to be disconnected when Mezoti, an adolescent former Borg drone, accidentally closes the channel in an attempt to notify Captain Janeway.\n\nWhen contact is re-established, Ballard is brought to Sickbay, where she retells the story of her death. Harry Kim, who was involved with Ballard, is present to confirm the details, and the Doctor confirms that the alien's DNA contains portions that match Ballard's medical records.\n\nWhen the Captain clears Ballard for duty, she attempts to return to her \"old\" life, but finds adjustment difficult—the Doctor has managed to restore her physical appearance, but biologically, she's still Kobali (as there wasn't enough human DNA in the ensign's body to revert her). She discovers that fact for herself all-too-clearly when she attempts to eat her favorite food in the Mess Hall, and finds that it suddenly tastes 'metallic' and unappealing.\n\nEventually, Q'Ret - Ballard's Kobali \"father\" - returns, demanding the return of his \"daughter\", Jhet'laya. After a tense meeting in the briefing room (which Ballard ends prematurely), she finds herself in the Mess Hall, depressed and isolated. When Harry Kim attempts to console her, and suggests that they alter one of Tuvok's meditation holoprograms as a prank, Ballard suffers a painful \"reversion\" of her Kobali physiology.\n\nIn Sickbay, the Doctor discovers that a pathogen that was introduced into Ballard's bloodstream is forcing Ballard's body to reject the Doctor's improvised \"reconstructive surgery\". Ballard must visit Sickbay twice daily if the treatments are to remain effective. Ballard loses her temper upon hearing that she would, essentially, be confined to Sickbay for the rest of the 75-year journey, and lashes out vocally and physically, shouting angrily in untranslated Kobali.\n\nAppalled at her new, more \"volatile\" Kobali personality, Ballard discovers that \"Voyager\" is no longer the home she once knew; corridors that she once walked with familiarity are now alien, she is unable to remember her human family due to the Kobali's alterations, and her new Kobali personality is too emotionally volatile.\n\nWhen Q'Ret returns, with two other vessels, Ballard decides that she needs to leave - she no longer belongs on \"Voyager\", and the ship will be destroyed if she stays. A distraught Harry Kim refuses to lose her again, but Ballard/Jhet'laya tells him that she was already lost to him when she died...but at least this time they got to say \"goodbye\".\n\nSignalling the Kobali to break off their attack, Harry and Jhet'laya have one final moment together in the transporter room. Harry has been practicing his Kobali as a farewell surprise.\n\nAn amused Jhet'laya appreciates his efforts, but points out that instead of a touching farewell, he said \"the comets are tiresome\". The two share one final laugh and a kiss before Jhet'laya steps up to the transporter pad and beams over to the Kobali ship.\n\nAs Harry is seen looking over a hairbrush that used to belong to Ballard, Mezoti comes over to comment it is a pretty brush. Harry explains it belonged to a friend of his and offers it to her. Mezoti questions his action wondering if his friend would mind. Harry explains he is sure she'd want it being used with someone with such pretty hair. Mezoti, being nice and thankful of her gift, offers Harry the chance to join her on the Holodeck. Harry smiles, suggests messing with the Tuvok program, and the two walk off hand in hand.\n\n"}
{"id": "25516263", "url": "https://en.wikipedia.org/wiki?curid=25516263", "title": "Avax Technologies", "text": "Avax Technologies\n\nAvax Technologies, Inc is a Philadelphia based biotechnology company whose most advanced product candidate is MVax for melanoma. MVax is a cancer vaccine that received a Special Protocol Assessment agreement with the FDA in October 2006, and subsequently began a Phase III registration clinical trial in November 2007. In previous studies, MVax demonstrated a 5-year overall survival rate (OS)of 44% and response rate of 35% (13% CR, 22% PR).\n\nA tumor sample is removed from a patient, then treated with the hapten 2,4-Dinitrophenol. When reinjected back into the patient, the hapten will cause an enhanced immune response against the cancer cells.\n\nStarted May 2007. Currently in a Phase III trial for Stage IV Melanoma.\n\nMVax’s Phase II response rate of 35% (CR + PR) in combination with low-dose IL-2 compares favorably to the Phase II results of other melanoma cancer vaccines such as Vical’s Allovectin-7 (11% CR + PR) and BioVex’s OncoVex (28% CR + PR), both of which are given as stand alone therapy.\n\nDue to the Financial crisis of 2007–2010 and recent cancer vaccine failures in other companies like Favrille and Cell Genesys, Avax has had trouble attracting investors. In an effort to conserve cash, enrollment for the Phase III trial was suspended on March 26, 2009, but the trial itself is still ongoing. However on December 16, 2009, the company obtained bridge financing in the amount of $1,400,000. This will be used to conduct an interim analysis of the Phase III data for MVax. CEO John Prendergast notes: \"Recent and anticipated news by companies involved with cancer vaccines and immunotherapies has resulted in renewed interest in the sector by institutional investors, larger pharma, biotechnology companies and the medical and scientific communities at large.\".\n\nStarted February 2006. Currently in a Phase I/II trial for NSCLC. No new patient enrollment until more funding is obtained.\n\nStarted April 2008, a Phase I/II trial for ovarian cancer. Encouraging results reported Feb 2016. Median survival was 22.7 months with no treatment-related serious adverse events.\n\nBased in Lyon, France has a GMP facility that manufactures the vaccines for Avax. The facility is certified by the French government for commercial and clinical vaccine production for the European markets.\n\n\n"}
{"id": "49342136", "url": "https://en.wikipedia.org/wiki?curid=49342136", "title": "Barbecue murders", "text": "Barbecue murders\n\nThe barbecue murders, also known as the BBQ murders, refers to a 1975 double murder in Marin County, California. Business consultant James \"Jim\" Olive and his wife Naomi were murdered in their home by their 16-year-old adopted daughter Marlene Olive and her 20-year-old boyfriend Charles \"Chuck\" Riley, who then attempted to dispose of the bodies by burning them in a barbecue pit at a nearby campground. Riley was convicted of two counts of first-degree murder and received a sentence of death, which was later changed to life imprisonment with the possibility of parole. Marlene Olive, tried as a juvenile, received a sentence of three to six years in a California Youth Authority juvenile facility, from which she was released at age 21 having served a little over four years.\n\nThe case gained worldwide attention due to the age of the perpetrators, the details of the crime, and the wide disparity in sentencing between the two perpetrators. Riley and Marlene Olive have also been the subjects of continuing coverage in connection with his repeated bids for parole and her subsequent convictions for numerous other crimes.\n\nMarlene Louise Olive was born in Norfolk, Virginia, on January 15, 1959 to an unmarried mother and was adopted as a newborn by middle-aged childless couple James \"Jim\" and Naomi Olive. Marlene Olive spent most of her childhood up to her early teens in Guayaquil, Ecuador, where her adoptive father Jim Olive worked as a marketing executive for Tenneco and Gulf Oil. She was very close to her adoptive father but had a troubled relationship with her adoptive mother, who reportedly suffered from alcoholism and mental illness.\n\nWhen Marlene Olive was 14, her father lost his job and he moved the family back to the United States, settling in Marin County, California, in the Terra Linda community of the city of San Rafael. Jim Olive became a self-employed small business consultant and spent less time with his daughter as he tried to make his business succeed. Marlene Olive had difficulty adjusting from her relatively sheltered life in Ecuador to the unfamiliar, permissive Northern California teen culture. She developed a stomach ulcer requiring prescription pills and soon began to use the pills and other drugs recreationally and socialize with other teenage drug users. She also became interested in glam rock, witchcraft, and prostitution, the latter interest stemming from repeatedly being called a \"whore\" by Naomi Olive, her adoptive mother.\n\nThe relationship between Marlene and Naomi Olive worsened after the move to the United States, and their arguments began to erupt into domestic violence. Over time, Marlene Olive also developed resentment toward her father for siding with her mother in disputes and suspected him of informing police about her friends' drug activities. She shoplifted, stole her parents' credit cards, used and overdosed on drugs, ran away from home, and received stolen goods from burglaries committed by a boyfriend. She talked to several friends about wanting to kill her parents and asked some of them to help, but the friends either did not take her seriously or decided not to get involved. At one point, she attempted to poison her mother herself by mixing large doses of prescription drugs into her mother's food, but the drugs made the food taste bitter, and Naomi refused to eat it.\n\nCharles \"Chuck\" Riley was born in 1955 in Marin County to Oscar and Joanne Riley and lived most of his life there in Santa Venetia, the son of a bakery worker and a nurse's aide. Having been obese since childhood, by age 15, he weighed over 300 pounds. Before he met Marlene Olive, he had never had a girlfriend. Riley dropped out of high school in his senior year and worked as a newspaper and pizza deliveryman, bartender, and factory worker. He was a heavy drug user and also dealt drugs, both to earn money and to gain social status and popularity. He owned several guns and was a skilled marksman.\n\nWhen he was 19, Riley met 15-year-old Marlene Olive while dealing drugs at her high school. He developed a crush on her and began to pursue her. Although she was initially put off by his weight, the couple eventually had sex and began a relationship largely controlled by Marlene Olive. Riley provided her with free drugs, gifts, and transportation, listened to her problems, and sometimes helped her carry out sexual or criminal fantasies. She frequently threatened to break up with Riley unless he did what she wanted and claimed to have magical powers of control over him, in which he reportedly believed. He was anxious to please her in order to continue the relationship and twice attempted suicide when she briefly broke up with him. As she had with previous boyfriends, Marlene Olive soon began to ask Riley for help or advice in killing her mother or suggest that he himself kill her parents. Jim and Naomi Olive initially approved of their daughter dating Riley, finding him polite and responsible.\n\nAt Marlene Olive's suggestion, the couple carried out a prolonged shoplifting spree, stealing approximately $6,000 in merchandise (primarily women's clothing and accessories) from local stores over several weeks until they were caught in the act and arrested for grand larceny in March 1975. Riley had no prior history of delinquency or antisocial conduct as a juvenile (aside from drug dealing), and this was his first adult arrest. In May 1975, Riley was arrested again for possession of marijuana and a sawed-off shotgun. Jim and Naomi Olive threatened their daughter with juvenile hall, planned to send her away to school, and forbade her to see Riley again, the prohibition also being included in a court order. Jim Olive ordered Riley to stay away from the Olives' house, threatening to kill him if he ever returned.\n\nOn Saturday, June 21, 1975, following another argument with her mother, Marlene Olive telephoned Riley and told him, \"Get your gun, we've got to kill the bitch today\". She arranged to go out with her father, leaving her mother home alone and leaving a door unlocked through which Riley could then enter and kill her mother. Riley, who was carrying a loaded .22 caliber revolver and later said he had taken LSD, entered the house where Naomi Olive was sleeping.\n\nAfterward, Riley told police that he had struck Naomi Olive \"many times\" with a hammer (a statement he later recanted under hypnosis) and also stabbed and suffocated her. While Riley was still in the house, Jim Olive returned, saw his wife lying in bed covered with blood, picked up a knife, and started toward Riley, exclaiming, \"I'll kill you\". Riley drew his gun and shot Jim Olive four times, killing him.\n\nMarlene Olive and Riley tried to dispose of the bodies by transporting them to a wooded area at nearby China Camp and burning them in a barbecue pit with gasoline and logs in an attempt to make them unrecognizable. The couple left while the bodies were still burning. A fireman who arrived shortly thereafter to put out the unattended fire initially mistook the partially burnt remains for a deer carcass. The couple later returned to the park and further burned the remains along with additional evidence.\n\nWith a friend, the couple cleaned up the room where the killings had taken place, removing blood from the carpet, walls, and furniture. They confided in the friend who helped clean and in several other friends that they had killed the Olives, with Riley physically carrying out the killings. Riley told friends, \"We had to do it. They wouldn't let me see her.\" Marlene Olive and Riley continued to live together at the Olives' house for several days, attending a Yes concert, shopping, eating at restaurants, and paying their expenses using cash, checks, and credit cards taken from her dead parents. They allegedly planned to wait for Jim and Naomi to be declared dead, collect the life insurance money, and move to Ecuador.\n\nAfter a few days, Jim Olive's business partner became concerned about his absence from work and contacted police, who visited the Olive house and spoke with Marlene Olive. She provided various alibis for herself and Riley, which the police later determined were false, and stories about her parents having either disappeared or died, claiming that one parent had killed the other and then disappeared with the body or that both parents were killed by Hells Angels. Police also noted the recently cleaned room in the otherwise disordered house. The friend who had helped clean informed the police about the blood in the room and the couple's statements about killing the Olives and burning their bodies. Acting either on information from Marlene Olive or from her friend, police searched the China Camp barbecue pit and determined that it contained fragments of burnt human remains. Marlene Olive and Riley were arrested.\n\nAfter his arrest, Riley made a detailed confession, in which he said that he and Marlene Olive had been planning to kill her parents for some time, that he had beaten, stabbed, and suffocated Naomi Olive and then shot Jim Olive, and that Marlene Olive had made him do it. However, Marlene Olive claimed that Riley had killed her parents of his own accord and that afterward, he had held her hostage and forced her to take drugs.\n\nBased on his initial confession, Riley, who was an adult over 18 (aged 20) at the time of the crime, was charged with two counts of first-degree murder for killing Jim and Naomi Olive and faced the death penalty. Under hypnosis, Riley later recanted the part of his initial confession about beating Naomi Olive with the hammer, saying that when he entered the house, he found Naomi Olive lying in bed, bleeding from head wounds and near death, with the hammer embedded in her head. Riley thus implied that Marlene Olive (who had been using the hammer that morning to repair a platform shoe) had fatally beaten her mother with the hammer before leaving the house. Riley contended that he had stabbed and suffocated Naomi Olive because she was suffering and near death from the hammer attack, and he was trying to end her misery. He said that he initially confessed to killing Naomi Olive in order to protect Marlene Olive by taking the blame for her actions. Riley admitted shooting Jim Olive, but said he acted out of fear and self-defense as Jim had threatened to kill him.\n\nAt his trial, Chuck testified under hypnosis about the events of the murder and that he had not beaten Naomi Olive. The jury was not convinced, and convicted him on both counts of first-degree murder for killing both victims. He was sentenced to death on January 26, 1976.\n\nAuthor and reporter Richard M. Levine later wrote that compared to Marlene Olive, Riley did not harbor much anger at Naomi Olive, whom he barely knew, and therefore Riley would be less likely to use a method of homicide suggesting rage; that Riley would have used his loaded gun as the weapon rather than a hammer; and that Marlene Olive had previously asked Riley how hard she would have to hit Naomi Olive in order to kill her. However, others have noted that Marlene had no blood on her clothing when she left the house and would not have had time to change clothes; that Riley used a hammer to avoid alerting neighbors because it made less noise than a gunshot; and that according to a hypnosis expert, Riley's revised confession lacked credibility. Marlene Olive continued to maintain that Riley had beaten and killed her mother in addition to shooting her father, and denied that she herself had any part in the killing of either parent.\n\nMarlene Olive, who was a minor aged 16 at the time of the crime, was tried as a juvenile rather than an adult, and was represented by the well-known defense attorney Terence Hallinan. She was charged with violating Section 602 of the California State Welfare and Institutions Code, which at that time covered any crime committed by a juvenile, from petty crimes up to and including murder. The court ruled that she had violated Section 602, stating that she \"did encourage, instigate, aid, abet, and act as accomplice in the homicides of her parents.\" In announcing his decision, Judge Charles R. Best stated, \"The uncontroverted evidence regarding the father is that Chuck Riley killed him. As to who actually did in the mother, we'll never know.\"\n\nMarlene Olive was sentenced to a term of four to six years confinement at the California Youth Authority at Ventura (also known as the Ventura School). She was to be released by her 21st birthday unless the youth authority determined she had not been rehabilitated, in which case she could be kept in custody up to age 23. \n\nIn December 1976, the California state supreme court ruled that the California death penalty statute, which then required a mandatory death penalty for certain categories of murder, was unconstitutional in view of the U.S. Supreme Court's recent rulings in \"Gregg v. Georgia\" and other cases. As a result, California prisoners sentenced to death under the unconstitutional statute, including Riley, could not be executed. Riley's sentence was changed from death to two concurrent life sentences with the possibility of parole after 7 years. While in prison, Riley lost weight, received his high school diploma and earned the equivalent of a college degree.\n\nAfter becoming eligible, Riley applied for parole approximately a dozen times and was denied each time. In 2011, Riley, now aged 56 and suffering from physical disabilities, appealed his most recent denial on the grounds that there was no evidence he continued to be a danger to the community, that the parole board did not consider his age, and that his sentence had been unconstitutionally excessive. Riley won a new court-ordered parole hearing, at which the parole board found him suitable for release and granted parole. However, on February 6, 2015, the parole board's decision was reversed by California Governor Jerry Brown, who explained that \"although [Riley] professes to accept some responsibility, he continues to downplay his role in this crime. Until Mr. Riley is able to come to terms with his role in this horrendous double murder, I do not believe he will be able to avoid violent behavior if released.\"\n\nRiley appealed the Governor's reversal of the parole board's decision. On December 3, 2015, the California Court of Appeal for the First District vacated the Governor's reversal and reinstated Riley's grant of parole, stating, \"We cannot affirm the Governor’s decision because the premise of his conclusion—that Riley has failed 'to come to terms with his role in the double murder'—is unsupported by any evidence. There being no evidence in the record that Riley 'continues to downplay his role in this crime,' the Governor’s decision cannot stand.\" Following the court's directive, the parole board's 2015 annual report released in January 2016 showed Riley as having been deemed suitable for release and granted parole as of December 8, 2015.\n\nMarlene Olive began serving her sentence at the Ventura School and was later allowed to serve part of her time living outside the school with a young woman who had been a juvenile services volunteer. A few weeks before Marlene Olive was due to be paroled, she escaped and fled to New York City where she worked as a sex worker. She was eventually arrested and returned to California to finish her sentence, finally being released in 1980 when she was 21.\n\nAfter being released, she moved to the Los Angeles area, where she changed her name numerous times and was arrested at least seven different times over the next decade on forgery and drug-related charges, serving two one-year terms in jail. In 1986, she was one of 14 people arrested in Los Angeles for allegedly operating a large counterfeiting and forgery ring, of which she was thought to be the ringleader. She was subsequently convicted and sentenced to five years in prison. She served additional prison terms in California after a 1992 conviction for making a false financial statement, and a 1995 conviction for possessing a forged drivers' license. In 2003, in Kern County, California, she pleaded guilty to passing a fictitious check in Bakersfield and was sentenced to seven years in prison. A 1992 \"Los Angeles Times\" article called her \"the queen of the trashers\" due to her alleged skills at committing forgery and fraud and creating false identities based on documents, such as voided checks, obtained from discarded garbage. Police said \"they [had] rarely come across a street-level forger believed to be as prolific or as skilled as Olive.\"\n\nMarlene Olive saw Chuck Riley only once after they were arrested for murder, when she visited him in prison in 1981. After the visit, Riley correctly predicted, \"I'll never see her again.\"\n\nRichard M. Levine, a feature writer for numerous publications including \"The New York Times\", \"New York\", \"Harper's\", and \"Esquire\", wrote a true crime book about the case, \"Bad Blood: A Family Murder in Marin County\" (Random House, 1982), which was widely reviewed and became a bestseller. The case was also discussed in John Godwin's book \"Murder U.S.A.: The Ways We Kill Each Other\" (Ballantine, 1978) and in several later true crime anthologies.\n\nDuring the 1990s, Levine's book inspired American artist Marlene McCarty to create a series of drawings about the teenage Marlene Olive, her relationships, and the barbecue murders. These led to a broader group of works by McCarty on the subject of teenage female murderers known as \"Murder Girls\", which explored issues of female aggression, sexuality, sexism, and family relations. Marlene Olive continued to be, in the words of Maud Lavin, the \"chief protagonist\" of the series, and at least one exhibition of McCarty's work focused solely on her and the barbecue murders. McCarty's drawing entitled \"Marlene Olive: 353 Hibiscus Way — Marin County, California — June 21, 1975., (Mural 2: Chuck, Jim, Marlene – December 21, 1974)\" (2003), is now in the collection of the Museum of Modern Art. McCarty based her art works concerning Marlene Olive on the theory, presented by Riley's defense counsel and Levine, that Marlene Olive had beaten her mother Naomi to death with the hammer.\n\nThe barbecue murders were dramatized in a 2014 episode of the true crime documentary series \"Killer Kids\" entitled \"Please Kill For Me\" (Season 3, Episode 12).\n\n"}
{"id": "15989285", "url": "https://en.wikipedia.org/wiki?curid=15989285", "title": "Bitlaha", "text": "Bitlaha\n\nBitlaha is a South Asian concept used as a social punishment for violating the norms of exogamy and endogamy.\n\nThe concept has been used by the Santals of India and the Satars of Nepal, who call themselves \"hod\", meaning “human beings”. The hod in Nepal translate \"bitlaha\" as an outcast, disorder, polluted or unclean person. “It is a temporary state that affects both the village and members…Bitlaha is contagious, affecting a bitlahas parents, guardians and whole village” (Skinner 207). Once a person is considered bitlaha they are no longer considered a member of their ethnic group and they are shunned and exiled from their community. The pancha, a male politician in Hod society, gives the bitlaha a chance to remove the derogatory name and reenter the ethnic group by paying a severe penalty.\n\nMost bitlaha pay their penalty or their parents do so they will cease to be shunned from festivals, carnivals, celebrations and religious rituals. Those who decide to remain a bitlaha live in an isolated non-hod community for the rest of their lives. Even though bitlaha do not have to return to their villages, almost all of them do because of kinship networks and strong friendships within the village. Santals use bitlaha as a way to outcast those who have sexually misbehaved. Santals believe that exposing these culprits to corruption and public ridicule will make individuals stray from sexual misbehaving. “The tribe asserts itself as the supreme body regulating the conduct of its members”, which motivates individuals to behave properly and not shame their Hods.\n\n"}
{"id": "8611104", "url": "https://en.wikipedia.org/wiki?curid=8611104", "title": "Cesária Évora", "text": "Cesária Évora\n\nCesária Évora, (; 27 August 1941 – 17 December 2011) was a Cape Verdean vocalist and recording artist. Nicknamed the \"Barefoot Diva\" for performing without shoes, she was also known as the \"Queen of Morna\".\n\n\"Cise\" (as she was known to friends) was born on 27 August 1941 in Mindelo, São Vicente, Cape Verde. When she was seven years old her father, Justino da Cruz Évora who was a part-time musician, died, and at the age of ten she was placed in an orphanage, as her mother Dona Joana could not raise all six children. At the age of 16, she was persuaded by a friend to sing in a sailors' tavern.\nShe grew up at the famous house in Mindelo where other singers used from the 1940s to the 1970s, at 35 Rua de Moeda. Other Cape Verdean singers came to the place including Djô d'Eloy, Bana, Eddy Moreno, Luis Morais and Manuel de Novas (also as Manuel d'Novas), there she received her musical education.\n\nIn the 1960s, she started singing on Portuguese cruise ships stopping at Mindelo as well as on the local radio. It was only in 1985 when at the invitation of Cape Verdean singer Bana she went to perform in Portugal. In Lisbon she was discovered by the producer José da Silva and invited to record in Paris.\n\nShe recorded the track \"Ausência\", composed by Bosnian-born musician Goran Bregovic, which was released in a soundtrack to the film \"Underground\" (1995) by Emir Kusturica and is the second track.\n\nÉvora's international success came only in 1988 with the release of her first commercial album \"La Diva Aux Pieds Nus\", recorded in France. Prior to the release of the La Diva Aux Pieds Nus album, Cesaria recorded her first LP titled \"Cesaria\" in 1987. This Album was later released on CD in 1995 as Audiophile Legends. Her 1992 album \"Miss Perfumado\" sold over 300,000 copies worldwide. It included one of her most celebrated songs, \"Sodade\".\n\nIn 1994, Bau joined her touring band and two years later, he became her musical director up to September 1999.\n\nHer 1995 album \"Cesária\" brought her broader international success and the first Grammy Award nomination. In 1997, she won KORA All African Music Awards in three categories: \"Best Artist of West Africa\", \"Best Album\" and \"Merit of the Jury\". In 2003, her album \"Voz d'Amor\" was awarded a Grammy in the World music category.\n\nIn 2006 in Italy Cesaria met Alberto Zeppieri (songwriter, journalist and record producer), who would dedicate to her \"Capo Verde, terra d'amore\" (www.capoverde-italia.it), taking care of all creative adaptations in Italian. Cesaria agreed to duet with Gianni Morandi , Gigi D'Alessio and Ron . The project, now in its fifth volume, gives visibility and raises funds for the UN World Food Programme, for which Cesaria was the Ambassador from 2003.\n\nLater in 2006, she released her next album \"Rogamar\" it was a success and charted six European countries including France, Poland and the Netherlands. On her tour in Australia in 2008, she suffered a stroke. In 2009, she released her final album \"Nha Sentimento\" which was recorded in Mindelo and Paris by José da Silva, the album reached number 6 in Poland and number 21 in France.\n\nIn 2009, she was made a knightess of the French Legion of Honour by the French French Minister of Culture and Communications Christine Albanel, the first Cape Verdean who became one.\n\nShe was awarded for the last time at the 2010 Kora All African Music Awards for the \"Merit of the Jury\" for the second time.\n\nCesària Évora dated Eduardo de Jon Xalino when she lived at Rua de Moeda, she was also a singer, relative of the great Bana.\n\nHer cousin was another singer Hermínia da Cruz Fortes, she was an aunt of António da Rocha Évora and Xavier da Cruz.\n\n\nIn 2010, Évora performed a series of concerts, the last of which was in Lisbon on 8 May. Two days later, after a heart attack, she underwent surgery at a local hospital in Paris. On the morning of 11 May 2010 she was taken off artificial pulmonary ventilation, and on 16 May she was discharged from the intensive-care unit and transported to a clinic for further treatment. In late September 2010, Évora's agent announced that she was ending her career due to poor health.\n\nOn 17 December 2011, aged 70, Évora died in São Vicente, Cape Verde, from respiratory failure and hypertension. A Spanish newspaper reported that 36 hours before her death she was still receiving people – and smoking – in her home in Mindelo, popular for always having its doors open.\n\n\n\n\n\n"}
{"id": "650518", "url": "https://en.wikipedia.org/wiki?curid=650518", "title": "Complex dynamics", "text": "Complex dynamics\n\nComplex dynamics is the study of dynamical systems defined by iteration of functions on complex number spaces. Complex analytic dynamics is the study of the dynamics of specifically analytic functions.\n\n\n\n\n"}
{"id": "175142", "url": "https://en.wikipedia.org/wiki?curid=175142", "title": "Cremation", "text": "Cremation\n\nCremation is the combustion, vaporization, and oxidation of cadavers to basic chemical compounds, such as gases, ashes and mineral fragments retaining the appearance of dry bone. Cremation may serve as a funeral or post-funeral rite as an alternative to the interment of an intact dead body in a coffin or casket. Cremated remains (also known as \"cremains\" or simply \"ashes\"), which do not constitute a health risk, may be buried or interred in memorial sites or cemeteries, or they may be retained by relatives and dispersed in various ways. Cremation is an alternative in place of burial or other forms of disposal in funeral practices. Some families prefer to have the deceased present at the funeral with cremation to follow; others prefer that the cremation occur prior to the funeral or memorial service.\n\nIn many countries, cremation is usually done in a crematorium. Some countries, such as India and Nepal, prefer different methods, such as open-air cremation.\n\nCremation dates from at least 42,000 years ago in the archaeological record, with the Mungo Lady, the remains of a partly cremated body found at Lake Mungo, Australia.\n\nAlternative death rituals emphasizing one method of disposal of a body—inhumation (burial), cremation, or exposure—have gone through periods of preference throughout history.\n\nIn the Middle East and Europe, both burial and cremation are evident in the archaeological record in the Neolithic era. Cultural groups had their own preferences and prohibitions. The ancient Egyptians developed an intricate transmigration-of-soul theology, which prohibited cremation. This was also widely adopted by Semitic peoples. The Babylonians, according to Herodotus, embalmed their dead. Early Persians practiced cremation, but this became prohibited during the Zoroastrian Period. Phoenicians practiced both cremation and burial. From the Cycladic civilisation in 3000 BCE until the Sub-Mycenaean era in 1200–1100 BCE, Greeks practiced inhumation. Cremation appeared around the 12th century BCE, constituting a new practice of burial, probably influenced by Anatolia. Until the Christian era, when inhumation again became the only burial practice, both combustion and inhumation had been practiced, depending on the era and location. Romans practiced both, with cremation generally associated with military honors.\n\nIn Europe, there are traces of cremation dating to the Early Bronze Age (c. 2000 BCE) in the Pannonian Plain and along the middle Danube. The custom became dominant throughout Bronze Age Europe with the Urnfield culture (from c. 1300 BCE). In the Iron Age, inhumation again becomes more common, but cremation persisted in the Villanovan culture and elsewhere. Homer's account of Patroclus' burial describes cremation with subsequent burial in a tumulus, similar to Urnfield burials, and qualifying as the earliest description of cremation rites. This may be an anachronism, as during Mycenaean times burial was generally preferred, and Homer may have been reflecting the more common use of cremation at the time the Iliad was written, centuries later.\n\nCriticism of burial rites is a common form of aspersion by competing religions and cultures, including the association of cremation with fire sacrifice or human sacrifice.\n\nHinduism and Jainism are notable for not only allowing but prescribing cremation. Cremation in India is first attested in the Cemetery H culture (from c. 1900 BCE), considered the formative stage of Vedic civilization. The Rigveda contains a reference to the emerging practice, in RV 10.15.14, where the forefathers \"both cremated (\"agnidagdhá-\") and uncremated (\"ánagnidagdha-\")\" are invoked.\n\nCremation remained common but not universal, in both ancient Greece and ancient Rome. According to Cicero, in Rome, inhumation was considered the more archaic rite, while the most honoured citizens were most typically cremated—especially upper classes and members of imperial families.\n\nThe rise of Christianity saw an end to cremation, being influenced by its roots in Judaism, the belief in the resurrection of the body, and following the example of Christ's burial. Anthropologists have been able to track the advance of Christianity throughout Europe with the appearance of cemeteries. By the 5th century, with the spread of Christianity, the practice of burning bodies gradually disappeared from Europe.\n\nIn early Roman Britain, cremation was usual but diminished by the 4th century. It then reappeared in the 5th and 6th centuries during the migration era, when sacrificed animals were sometimes included with the human bodies on the pyre, and the deceased were dressed in costume and with ornaments for the burning. That custom was also very widespread among the Germanic peoples of the northern continental lands from which the Anglo-Saxon migrants are supposed to have been derived, during the same period. These ashes were usually thereafter deposited in a vessel of clay or bronze in an \"urn cemetery\". The custom again died out with the Christian conversion of the Anglo-Saxons or Early English during the 7th century, when Christian burial became general.\n\nIn parts of Europe, cremation was forbidden by law, and even punishable by death if combined with Heathen rites. Cremation was sometimes used by Catholic authorities as part of punishment for Protestant heretics, which included burning at the stake. For example, the body of John Wycliff was exhumed years after his death and burned to ashes, with the ashes thrown in a river, explicitly as a posthumous punishment for his denial of the Roman Catholic doctrine of transubstantiation.\n\nThe first to advocate for the use of cremation was the physician Sir Thomas Browne in 1658. Honoretta Brooks Pratt became the first recorded cremated European individual in modern times when she died on 26 September 1769 and was illegally cremated at the burial ground on Hanover Square in London.\n\nThe organized movement to reinstate cremation as a viable method for body disposal began in the 1870s. In 1869 the idea was presented to the Medical International Congress of Florence by Professors Coletti and Castiglioni \"in the name of public health and civilization\". In 1873, Professor Paolo Gorini of Lodi and Professor Ludovico Brunetti of Padua published reports of practical work they had conducted. A model of Brunetti's cremating apparatus, together with the resulting ashes, was exhibited at the Vienna Exposition in 1873 and attracted great attention, including that of Sir Henry Thompson, 1st Baronet, a surgeon and Physician to the Queen Victoria, who returned home to become the first and chief promoter of cremation in England.\n\nSir Henry Thompson's main reason for supporting cremation was that \"it was becoming a necessary sanitary precaution against the propagation of disease among a population daily growing larger in relation to the area it occupied\". In addition, he believed, cremation would prevent premature burial, reduce the expense of funerals, spare mourners the necessity of standing exposed to the weather during interment, and urns would be safe from vandalism. On 13 January 1874, some advocates of cremation, including Anthony Trollope, John Everett Millais, George du Maurier, Thomas Spencer Wells, John Tenniel and Shirley Brooks, held a meeting at Thompson's house in London and formally founded the \"Cremation Society of Great Britain\" \"...expressly for the purpose of obtaining and disseminating information on the subject and for adopting the best method of performing the process, as soon as this could be determined, provided that the act was not contrary to Law.\"\nThe first duty of the Cremation Society was to ascertain whether cremation could be legally performed in the country, and then to construct a first crematorium. In 1878, Sir Henry Thompson bought a piece of land in Woking as a site for the crematorium. Professor Gorini was invited to visit Woking and supervise the erection of his cremation apparatus there. They first tested it on 17 March 1879 by cremating the body of a horse. However, the inhabitants of Woking showed strong antipathy to the crematorium, and appealed to the Home Secretary, Sir Richard Cross, to prohibit the use of the building.\n\nIn 1885, the first official cremation in the UK took place in Woking. The deceased was Mrs Jeannette C. Pickersgill, a well-known figure in literary and scientific circles. By the end of the year, the Cremation Society of Great Britain had overseen two more cremations, a total of 3 out of 597,357 deaths in the UK that year. In 1886 ten bodies were cremated at Woking Crematorium. During 1888, in which 28 cremations took place, the Cremation Society planned to provide a chapel, waiting rooms and other amenities there. In 1892 a crematorium opened in Manchester, followed by one in Glasgow in 1895, Liverpool in 1896 and Birmingham Crematorium in 1903.\n\nCrematoria in Europe were built in 1878 in the town of Gotha in Germany and later in Heidelberg in 1891. The first modern crematory in the U.S. was built in 1876 by Francis Julius LeMoyne after hearing about its use in Europe. During that time it was thought that people were getting sick by attending funerals of those recently deceased and that decomposing bodies were leaking into the water systems. LeMoyne built the crematory to cremate bodies in a controlled environment primarily for sanitary reasons. Cremation was used to destroy any organic matter that could cause illness and give families a better way to preserve ashes. Before LeMoyne's crematory closed in 1901, it had performed 42 cremations.\n\nSome of the various Protestant churches came to accept cremation, with the rationale being, \"God can resurrect a bowl of ashes just as conveniently as he can resurrect a bowl of dust.\" The 1908 Catholic Encyclopedia was critical about these efforts, referring to them as a \"sinister movement\" and associating them with Freemasonry, although it said that \"there is nothing directly opposed to any dogma of the Church in the practice of cremation.\"\nIn 1963, [at Second Vatican Council] Pope Paul VI lifted the ban on cremation, and in 1966 allowed Catholic priests to officiate at cremation ceremonies.\n\nIn the U.S. only about one crematory per year was built in the late 19th century. As embalming became more widely accepted and used, crematories lost their sanitary edge. Not to be left behind, crematories had an idea of making cremation beautiful. They started building crematories with stained-glass windows and marble floors with frescoed walls. By 2008, the cremation rate was 36.2% and was growing about 1 percentage point a year, according to CANA. CANA is the largest organization representing crematories and funeral homes in the U.S. and Canada.\n\nAustralia also started to establish modern cremation movements and societies. Australians had their first purpose-built modern crematorium and chapel in the West Terrace Cemetery in the South Australian capital of Adelaide in 1901. This small building, resembling the buildings at Woking, remained largely unchanged from its 19th-century style and was in full operation until the late 1950s. The oldest operating crematorium in Australia is at Rookwood Cemetery, in Sydney. It opened in 1925.\n\nIn the Netherlands, the foundation of the Association for Optional Cremation in 1874 ushered in a long debate about the merits and demerits of cremation. Laws against cremation were challenged and invalidated in 1915 (two years after the construction of the first crematorium in the Netherlands), though cremation did not become legally recognised until 1955.\n\nDuring World War II (1939–45) Nazi Germany used specially built furnaces in at least six extermination camps throughout occupied Poland including at Auschwitz-Birkenau, Chełmno, Belzec, Majdanek, Sobibor and Treblinka, where the bodies of those murdered by gassing were disposed of using incineration. The efficiency of industrialised killing of \"Operation Reinhard\" during the most deadly phase of the Holocaust produced too many corpses, therefore the crematoria manufactured to SS specifications were put into use in all of them to handle the disposals around the clock, day and night. The Vrba–Wetzler report offers the following description. \nThe Holocaust furnaces were supplied by a number of manufacturers, with the best known and most common being Topf and Sons as well as Kori Company of Berlin, whose ovens were elongated to accommodate two bodies, slid inside from the back side. The ashes were taken out from the front side. The furnaces were also unique, in that they were of a \"stand alone\" type, meaning that there was no visible duct work for the exhaust gases. These furnaces, based around a design commonly used for hospital incinerators, instead vented the gasses down through a series of ducts embedded in the floor, with the help of a draft fan located at the far end of the structure. Once outside, the gasses then rose through a free standing chimney, most notable for the fact that it was not directly attached to the structure of the building itself, nor had a visible duct leading into it.\n\nThe cremation occurs in a cremator that is housed within a \"crematorium\" and comprises one or more furnaces. A cremator is an industrial furnace that is able to generate temperatures of to ensure disintegration of the corpse. A crematorium may be part of a chapel or a funeral home or may be an independent facility or a service offered by a cemetery.\n\nModern cremator fuels include oil, natural gas, propane, and, in some areas like Hong Kong, coal gas. However, coal and coke were used until the early 1960s.\n\nModern cremators automatically monitor their interior to tell when the cremation process is complete. The time required for cremation varies from body to body, and, in modern furnaces, the process may be as fast as one hour per 50 kg (100 lb) of body weight.\n\nA cremator is not designed to cremate more than one human body at a time; cremation of multiple bodies is generally illegal in the United States and many other countries, though exceptions may be made for (for example) still-born twins, or a baby and mother who died during childbirth.\n\nThe chamber where the body is placed is called a \"retort\" and is lined with heat-resistant refractory bricks. Refractory bricks are designed in several layers. The outermost layer is usually simply an insulation material, \"e.g.\", mineral wool. Inside is typically a layer of insulation brick, mostly calcium silicate in nature. Heavy duty cremators are usually designed with two layers of fire bricks inside the insulation layer. The layer of fire bricks in contact with the combustion process protects the outer layer and must be replaced from time to time. The coffin or container is inserted (charged) into the retort as quickly as possible to avoid heat loss through the top door. The container may be mounted on a charger (motorised trolley) that can quickly insert it, or on a fixed or movable hopper that allows the container to slide into the cremator.\n\nSome crematoria allow relatives to view the charging. This is sometimes done for religious reasons, such as in traditional Hindu and Jain funerals.\n\nIn some countries including the United States, there is increasing use of the alkaline hydrolysis process, trademarked as \"Resomation\", which involves the use of lye heated with the body at high pressure, allowing the body to be broken down into its chemical compounds. A cremator is not used. The process is described by its inventors as more ecologically favorable than other forms of cremation.\n\nIn the United States federal law does not dictate any container requirements for cremation. Certain states, however, may require an opaque or non-transparent container of all cremations. This can be a simple corrugated-cardboard box or a wooden casket (coffin). Most casket manufacturers provide lines of caskets that are specially built for cremation. Another option is a cardboard box that fits inside a wooden shell, which is designed to look like a traditional casket. After the funeral service, the box is removed from the shell before cremation, permitting the shell to be re-used. Funeral homes may also offer rental caskets, which are traditional caskets used only during the services, after which the bodies are transferred to other containers for cremation. Rental caskets are sometimes designed with removable beds and liners, which are replaced after each use.\n\nIn the United Kingdom, the body is not removed from the coffin and is not placed into a container as described above. The body is cremated with the coffin which is why all British coffins that are to be used for cremation must be combustible. The Code of Cremation Practice forbids the opening of the coffin once it has arrived at the crematorium, and rules stipulate that it must be cremated within 72 hours of the funeral service. Therefore, in the United Kingdom, bodies are cremated in the same coffin that they are placed in at the undertaker's, although the regulations allow the use of an approved \"cover\" during the funeral service. It is recommended that jewellery be removed before the coffin is sealed, for this reason. When cremation is finished, the remains are passed through a magnetic field to remove any metal, which will be interred elsewhere in the crematorium grounds or, increasingly, recycled. The ashes are entered into a cremulator to further grind the remains down into a finer texture before being given to relatives or loved ones or scattered in the crematorium grounds where facilities exist.\n\nIn Germany, the process is mostly similar to that of the United Kingdom. The body is cremated in the coffin. A piece of fire clay with a number on it is used for identifying the remains of the dead body after burning. The remains are then placed in a container called an \"ash capsule\", which generally is put into a cinerary urn.\n\nIn Australia, the deceased is cremated in a coffin supplied by the undertaker. Reusable or cardboard coffins are becoming popular, with several manufacturers now supplying them. For low cost, a plain, particle-board coffin (known in the trade as a \"chippie\") can be used. Handles (if fitted) are plastic and approved for use in a cremator. Coffins vary from natural cardboard and unfinished particle board (covered with a velvet pall if there is a service) to solid timber; most are veneered particle board.\n\nCremations can be \"delivery only\", with no preceding chapel service at the crematorium (although a church service may have been held) or preceded by a service in one of the crematorium chapels. Delivery-only allows crematoria to schedule cremations to make best use of the cremators, perhaps by holding the body overnight in a refrigerator, allowing a lower fee to be charged. Delivery-only is sometimes called \"west chapel service\" in industry jargon.\n\nThe box containing the body is placed in the retort and incinerated at a temperature of 760 to 1150 °C (1400 to 2100 °F). During the cremation process, the greater portion of the body (especially the organs and other soft tissues) is vaporized and oxidized by the intense heat; gases released are discharged through the exhaust system. The process usually takes 90 minutes to two hours, with larger bodies taking longer time.\n\nJewelry, such as necklaces, wrist-watches and rings, are ordinarily removed before cremation, and returned to the family. Several implanted devices are required to be removed. Pacemakers and other medical devices can cause surprisingly large, dangerous explosions.\n\nContrary to popular belief, the cremated remains are not ashes in the usual sense. After the incineration is completed, the dry bone fragments are swept out of the retort and pulverised by a machine called a \"Cremulator\" — essentially a high-capacity, high-speed blender — to process them into \"ashes\" or \"cremated remains\", although pulverisation may also be performed by hand. This leaves the bone with a fine sand like texture and color, able to be scattered without need for mixing with any foreign matter, though the size of the grain varies depending on the Cremulator used. Their mean weight is 2.4 kg for an adult human, while the mean weight for adult males is about 1 kg higher than that for adult females. There are various types of Cremulators, including rotating devices, grinders, and older models using heavy metal balls.\nThe grinding process typically takes about 20 seconds.\nIn East Asian countries such as Japan, China, or Taiwan, the bones are not pulverised, unless requested beforehand. When not pulverised, the bones are collected by the family and stored as one might do with ashes.\n\nThe appearance of cremated remains after grinding is one of the reasons they are called \"ashes\", although a non-technical term sometimes used is \"cremains\", a portmanteau of \"cremated\" and \"remains\". (The Cremation Association of North America prefers that the word \"cremains\" not be used for referring to \"human cremated remains\". The reason given is that \"cremains\" is thought to have less connection with the deceased, whereas a loved one's \"cremated remains\" has a more identifiable human connection.)\n\nAfter final grinding, the ashes are placed in a container, which can be anything from a simple cardboard box to a decorative urn. The default container used by most crematoria, when nothing more expensive has been selected, is usually a hinged, snap-locking plastic box.\n\nAn unavoidable consequence of cremation is that a tiny residue of bodily remains is left in the chamber after cremation and mixes with subsequent cremations.\n\nCremated remains are mostly dry calcium phosphates with some minor minerals, such as salts of sodium and potassium. Sulfur and most carbon are driven off as oxidized gases during the process, although a relatively small amount of carbon may remain as carbonate.\n\nThe ash remaining represents very roughly 3.5% of the body's original mass (2.5% in children). Because the weight of dry bone fragments is so closely connected to skeletal mass, their weight varies greatly from person to person. Because many changes in body composition (such as fat and muscle loss or gain) do not affect the weight of cremated remains, the weight of the remains can be more closely predicted from the person's height and sex (which predicts skeletal weight), than it can be predicted from the person's simple weight.\n\nAshes of adults can be said to weigh from , with women's ashes generally weighing below and men's ashes generally weighing above .\n\nNot all that remains is bone. There may be melted metal lumps from missed jewellery; casket furniture; dental fillings; and surgical implants, such as hip replacements. Breast implants do not have to be removed before cremation. Some medical devices such as pacemakers may need to be removed before cremation to avoid the risk of explosion. Large items such as titanium hip replacements (which tarnish but do not melt) or casket hinges are usually removed before processing, as they may damage the processor. (If they are missed at first, they must ultimately be removed before processing is complete, as items such as titanium joint replacements are far too durable to be ground). Implants may be returned to the family, but are more commonly sold as ferrous/non-ferrous scrap metal. After the remains are processed, smaller bits of metal such as tooth fillings, and rings (commonly known as \"gleanings\") are sieved out and may be later interred in common, consecrated ground in a remote area of the cemetery. They may also be sold as precious metal scrap.\n\nCremated remains are returned to the next of kin in different manners according to custom and country. In the United States, the cremated remains are almost always contained in a thick watertight polyethylene plastic bag contained within a hard snap-top rectangular plastic container, which is labeled with a printed paper label. The basic sealed plastic container bag may be contained within a further cardboard box or velvet sack, or they may be contained within an urn if the family had already purchased one. An official certificate of cremation prepared under the authority of the crematorium accompanies the remains, and if required by law, the permit for disposition of human remains, which must remain with the cremated remains.\n\nCremated remains can be kept in an urn, stored in a special memorial building (columbarium), buried in the ground at many locations or sprinkled on a special field, mountain, or in the sea. In addition, there are several services in which the cremated remains will be scattered in a variety of ways and locations. Some examples are via a helium balloon, through fireworks, shot from shotgun shells, by boat or scattered from an aeroplane. One service sends a lipstick-tube sized sample of the cremated remains into low earth orbit, where they remain for years (but not permanently) before reentering the atmosphere. Some companies offer a service to turn part of the cremated remains into synthetic diamonds that can then be made into jewelry. \n\nCremated remains may also be incorporated, with urn and cement, into part of an artificial reef, or they can also be mixed into paint and made into a portrait of the deceased. Some individuals use a very small amount of the remains in tattoo ink, for remembrance portraits. Cremated remains can be scattered in national parks in the United States with a special permit. They can also be scattered on private property with the permission of the owner. A portion of the cremated remains may be retained in a specially designed locket known as cremation jewelry, or even blown into special glass keepsakes and glass orbs. The cremated remains may also be entombed. Most cemeteries will grant permission for burial of cremated remains in occupied cemetery plots that have already been purchased or are in use by the families disposing of the cremated remains without any additional charge or oversight.\n\nConcerns have been raised at the amount of ashes scattered at the peak of Snowdon, as they change the nature of the soil, and may affect the ecology.\n\nThe final disposition depends on the personal preferences of the deceased as well as their cultural and religious beliefs. Some religions will permit the cremated remains to be sprinkled or retained at home. Some religions, such as Roman Catholicism, prefer to either bury or entomb the remains. Hinduism obliges the closest male relative (son, grandson, etc.) of the deceased to immerse the cremated remains in the holy river Ganges, preferably at the holy city of Triveni Sangam, Allahabad, or Varanasi or Haridwar, India. The Sikhs immerse the remains in Sutlej, usually at Sri Harkiratpur. In southern India, the ashes are immersed in the river Kaveri at Paschima vahini in Srirangapattana at a stretch where the river flows from east to west, depicting the life of a human being from sunrise to sunset. In Japan and Taiwan, the remaining bone fragments are given to the family and are used in a burial ritual before final interment.\n\nAside from religious reasons (discussed below), some people find they prefer cremation over traditional burial for personal reasons. The thought of a long and slow decomposition process is unappealing to some; many people find that they prefer cremation because it disposes of the body instantly.\n\nOther people view cremation as a way of simplifying their funeral process. These people view a ground burial as an unneeded complication of their funeral process, and thus choose cremation to make their services as simple as possible. Cremation is a more simple disposition method to plan than a burial funeral. This is because with a burial funeral you have to plan for more transportation services for the body as well as embalming and other body preservation methods. With a burial funeral you will also need to purchase a casket, headstone, grave plot, opening and closing of the grave fee, and mortician fees. Cremation funerals only require planning the transportation of the body to a crematorium, cremation of the body, and a cremation urn.\n\nThe cost factor tends to make cremation attractive. Generally speaking, cremation is cheaper than a traditional burial service, especially if direct cremation is chosen, in which the body is cremated as soon as legally possible without any sort of services. However, for some even cremation is still relatively expensive, especially as a lot of fuel is required to perform it. Methods to reduce fuel consumption/fuel cost include the use of different fuels (i.e. natural gas or propane, compared to wood) and by using an incinerator (retort) (closed cabin) rather than an open fire.\n\nFor surviving kin, cremation is preferred because of simple portability. Survivors relocating to another city or country have the option of transporting the remains of their loved ones with the ultimate goal of being interred or scattered together.\n\nCremated remains can be scattered or buried. Cremation plots or columbarium niches are usually cheaper than a traditional burial plot or mausoleum crypt, and require less space. Some religions, such as Roman Catholicism, require the burial or entombment of cremated remains, but burial of cremated remains may often be accomplished in the burial plot of another person, such as a family member, without any additional cost. This option is charged for in England in an Anglican church where the fee is set by the Table of Parochial Fees (£36 to incumbent and £78 to church council) a total of £114 in 2010 with a marker charged as extra. It is also very common to scatter the remains in a place the deceased liked—such as the sea, a river, a beach, a park, or mountains, following their last will. This is generally forbidden in public places but easy to do. Some persons choose to have a small part of their ashes (usually less than 1 part in 1000, because of cost constraints) scattered in space (known as space burial and offered by companies such as Elysium Space, Celestis and Ascending Memories). Cremated remains can now also be converted to diamonds.\n\nCremation might be preferable for environmental reasons. Burial is a known source of certain environmental contaminants, with the coffin itself being the major contaminant; however, in some countries, e.g. the UK, legislation now requires that cremators be fitted with abatement equipment (filters) that remove serious pollutants such as mercury.\n\nEach cremation uses about of fuel and releases about of carbon dioxide into the atmosphere. Thus, the roughly 1 million bodies that are cremated annually in the United States produce about of carbon dioxide. That's more CO pollution than 22,000 average American homes generate in a year. The environmental impact may be reduced by using cremators for longer periods, and not cremating on the same day as the coffin is received, which reduces the use of fossil fuel and hence carbon emissions. Cremation is therefore becoming more friendly toward the environment though natural burials are also possible. Some funeral and crematorium owners offer a carbon neutral funeral service incorporating efficient-burning coffins made from lightweight recycled composite board.\n\nAnother environmental concern is that traditional burial takes up a great deal of space. In a traditional burial, the body is buried in a casket made from a variety of materials. In the United States, the casket is often placed inside a concrete vault or liner before burial in the ground. While individually this may not take much room, combined with other burials, it can over time cause serious space concerns. Many cemeteries, particularly in Japan and Europe as well as those in larger cities, have run out of permanent space. In Tokyo, for example, traditional burial plots are extremely scarce and expensive, and in London, a space crisis led Harriet Harman to propose reopening old graves for \"double-decker\" burials.\n\nSome cities in Germany do not have plots for sale, only for lease. When the lease expires, the remains are disinterred and a specialist bundles the bones, inscribes the forehead of the skull with the information that was on the headstone, and places the remains in a special crypt.\n\nIn Christian countries and cultures, cremation has historically been discouraged, but now in many denominations it is accepted.\n\nChristians preferred to bury the dead rather than to cremate the remains, as was common in Roman culture. The Roman catacombs and veneration of relics of saints witness to this preference. For them, the body was not a mere receptacle for a spirit that was the real person, but an integral part of the human person. They looked on the body as sanctified by the sacraments and itself the temple of the Holy Spirit, and thus requiring to be disposed of in a way that honours and reveres it, and they saw many early practices involved with disposal of dead bodies as pagan in origin or an insult to the body.\n\nThe idea that cremation might interfere with God's ability to resurrect the body was refuted as early as the 2nd-century \"Octavius\" of Minucius Felix, in which he said: \"Every body, whether it is dried up into dust, or is dissolved into moisture, or is compressed into ashes, or is attenuated into smoke, is withdrawn from us, but it is reserved for God in the custody of the elements. Nor, as you believe, do we fear any loss from sepulture, but we adopt the ancient and better custom of burying in the earth.\" And while there was a clear preference for burial, there was no general Church law forbidding cremation until 1866. Even in Medieval Europe, cremation was practiced in situations where there were multitudes of corpses simultaneously present, such as after a battle, after a pestilence or famine, and where there was an imminent fear of diseases spreading from the corpses, since individual burials with digging graves would take too long and body decomposition would begin before all the corpses had been interred.\n\nBeginning in the Middle Ages, and even more so in the 18th century and later, rationalists and classicists began to advocate cremation again as a statement denying the resurrection and/or the afterlife, although the pro-cremation movement more often than not took care to address and refute theological concerns about cremation in their works. Sentiment within the Catholic Church against cremation became hardened in the face of the association of cremation with \"professed enemies of God.\" When some Masonic groups advocated cremation as a means of rejecting Christian belief in the resurrection, the Holy See forbade Catholics to practice cremation in 1886. The 1917 Code of Canon Law incorporated this ban, but in 1963, recognizing that, in general, cremation was being sought for practical purposes and not as a denial of bodily resurrection, the choice of cremation was permitted in many circumstances. The current 1983 Code of Canon Law, states: \"The Church earnestly recommends the pious custom of burial be retained; but it does not forbid cremation, unless this is chosen for reasons which are contrary to Christian teaching.\"\n\nThere are no universal rules governing Catholic funeral rites in connection with cremation, but episcopal conferences have laid down rules for various countries. Of these, perhaps the most elaborate are those established, with the necessary confirmation of the Holy See, by the United States Conference of Catholic Bishops and published as Appendix II of the United States edition of the \"Order of Christian Funerals\".\n\nAlthough the Holy See has in some cases authorized bishops to grant permission for funeral rites to be carried out in the presence of cremated remains, it is preferred that the rites be carried out before cremation, in the presence of the still intact body. Practices that show insufficient respect for the ashes of the dead such as turning them into jewelry or scattering them are forbidden for Catholics.\n\nIn 1917, \"Volume 6 of the American Lutheran Survey\" stated that \"The Lutheran clergy as a rule refuse\" and that \"Episcopal pastors often take a stand against it.\" Indeed, in the 1870s, the Anglican Bishop of London stated that the practice of cremation would \"undermine the faith of mankind in the doctrine of the resurrection of the body, and so bring about a most disastrous social revolution.\" In \"The Lutheran Pastor\", George Henry Gerberding stated:\n\nHowever, Protestant churches welcomed the use of cremation at a much earlier date than the Catholic Church; pro-cremation sentiment was not unanimous among Protestants, however. The first crematoria in the Protestant countries were built in the 1870s, and in 1908, the Dean and Chapter of Westminster Abbey—one of the most famous Anglican churches—required that remains be cremated for burial in the abbey's precincts. Today, \"scattering\", or \"strewing,\" is an acceptable practice in many Protestant denominations, and some churches have their own \"garden of remembrance\" on their grounds in which remains can be scattered. Other groups also support cremation. Some denominations, like Lutheran churches in Scandinavia, favour the urns being buried in family graves. A family grave can contain urns of many generations and also the urns of spouses and loved ones.\n\nAn early Methodist tract titled \"Immortality and Resurrection\" noted that \"burial is the result of a belief in the resurrection of the body, while cremation anticipates its annihilation.\" \"The Methodist Review\" noted that \"Three thoughts alone would lead us to suppose that the early Christians would have special care for their dead, namely, the essential Jewish origin of the Church; the mode of burial of their founder; and the doctrine of the resurrection of the body, so powerfully urged by the apostles, and so mighty in its influence on the primitive Christians. From these considerations, the Roman custom of cremation would be most repulsive to the Christian mind.\"\n\nOn the other hand, some branches of Christianity oppose cremation, including some minority Protestant groups and Orthodox. Most notably, the Eastern Orthodox and Oriental Orthodox Churches forbid cremation, as a custom, but not dogmatically. Exceptions are made for circumstances where it may not be avoided (when civil authority demands it, or epidemics) or if it may be sought for good cause, but when a cremation is willfully chosen for no good cause by the one who is deceased, he or she is not permitted a funeral in the church and may also be permanently excluded from liturgical prayers for the departed. In Orthodoxy, cremation is perceived by some a rejection of the dogma of the general resurrection.\n\nThe Church of God (Restoration) also forbids the practice of cremation, believing it to be a pagan practice.\n\nThe Church of Jesus Christ of Latter-day Saints (LDS Church) has, in past decades, discouraged cremation without expressly forbidding it. In the 1950s, for example, Apostle Bruce R. McConkie wrote that \"only under the most extraordinary and unusual circumstances\" would cremation be consistent with LDS teachings.\n\nHowever, more recent LDS publications have provided instructions for how to dress the deceased when they have received their temple endowments (and thus wear temple garments) prior to cremation for those wishing to do so, or in countries where the law requires cremation. Except where required by law, the family of the deceased may decide whether the body should be cremated, though the Church \"does not normally encourage cremation.\"\n\nReligions such as Hinduism, Buddhism, Jainism, and Sikhism practice cremation. The founder of Buddhism, Shakyamuni Buddha, was cremated. For Buddhist spiritual masters who are cremated, one of the results of cremation are the formation of Buddhist relics.\n\nA dead adult Hindu is mourned with a cremation, while a dead child is typically buried. The rite of passage is performed in harmony with the Hindu religious view that the microcosm of all living beings is a reflection of a macrocosm of the universe. The soul (Atman, Brahman) is the essence and immortal that is released at the \"Antyeshti\" ritual, but both the body and the universe are vehicles and transitory in various schools of Hinduism. They consist of five elements – air, water, fire, earth and space. The last rite of passage returns the body to the five elements and origins. The roots of this belief are found in the Vedas, for example in the hymns of Rigveda in section 10.16, as follows:\n\nThe final rites, in case of untimely death of a child, is usually not cremation but a burial. This is rooted in Rig Veda's section 10.18, where the hymns mourn the death of the child, praying to deity Mrityu to \"neither harm our girls nor our boys\", and pleads the earth to cover, protect the deceased child as a soft wool.\n\nAshes of the cremated bodies are usually spread in a river, which are considered holy in the Hindu practice. Ganga is considered to be the holiest river and Varanasi, which is on the banks of river Ganga the holiest place to be cremated at.\n\nBalinese Hindu dead are generally buried inside the container for a period of time, which may exceed one month or more, so that the cremation ceremony (Ngaben) can occur on an auspicious day in the Balinese-Javanese Calendar system (\"Saka\"). Additionally, if the departed was a court servant, member of the court or minor noble, the cremation can be postponed up to several years to coincide with the cremation of their Prince. Balinese funerals are very expensive and the body may be interred until the family can afford it or until there is a group funeral planned by the village or family when costs will be less. The purpose of burying the corpse is for the decay process to consume the fluids of the corpse, which allows for an easier, more rapid and more complete cremation.\n\nIslam strictly forbids cremation. Islam has specific rites for the treatment of the body after death.\n\nJudaism traditionally disapproved of cremation in the past (it was the traditional means of disposing the dead in the neighboring Bronze Age cultures). It has also disapproved of preservation of the dead by means of embalming and mummifying, a practice of the ancient Egyptians.\n\nThrough history and up to the philosophical movements of the current era Modern Orthodox, Orthodox, Haredi, and Hasidic movements in Judaism have maintained a strict biblical line against cremation, and disapprove of it as Halakha (Jewish law) forbids it. This halakhic concern is grounded in the upholding of bodily resurrection as a core belief of traditional Judaism, as opposed to other ancient trends such as the Sadduccees, who denied it as well as the clear wording of the Torah in Devarim (Deuteronomy) 21:23 \"Bury, you will bury him the same day; for the (unburied body) is a curse to God\" with both a positive command derived from this verse to command one to bury a dead body and a negative command forbidding neglecting to bury a dead body. Some from the generally liberal Conservative Jewish also oppose cremation, some very strongly.\n\nDuring the 19th and early 20th centuries, as the Jewish cemeteries in many European towns had become crowded and were running out of space, in a few cases cremation for the first time became an approved means of corpse disposal among the emerging liberal and Reform Jewish movements in line with their across the board rejection of traditional Torah ritual laws having mandatory standing. Current liberal movements like Reform Judaism still support cremation, although burial remains the preferred option.\n\nIn Israel, where religious ritual events including free burial and funeral services for all who die in Israel and all citizens including the majority Jewish population including for the secular or non-observant are almost universally facilitated through the Rabinate of Israel which is an Orthodox organization following traditional Jewish law, there were no formal crematories until 2004 when B&L Cremation Systems Inc. became the first crematory manufacturer to sell a retort to Israel. In August 2007, an orthodox youth group in Israel was accused of burning down the country's sole crematorium. The crematorium was rebuilt within weeks by its owner Aley Shalechet and the retort replaced. Since that incident, cremation has taken place in Israel without interruption.\n\nThe Baha'i Faith forbids cremation, \"He feels that, in view of what ‘Abdu’l-Bahá has said against cremation, the believers should be strongly urged, as an act of faith, to make provisions against their remains being cremated. Bahá’u’lláh has laid down as a law, in the Aqdas, the manner of Bahá’í burial, and it is so beautiful, befitting and dignified, that no believer should deprive himself of it.\"\n\nTraditionally, Zoroastrianism disavows cremation or burial to preclude pollution of fire or earth. The traditional method of corpse disposal is through ritual exposure in a \"Tower of Silence\", but both burial and cremation are increasingly popular alternatives. Some contemporary adhererents of the faith have opted for cremation. Parsi-Zoroastrian singer Freddie Mercury of the group Queen was cremated after his death.\n\nNeo-Confucianism under Zhu Xi strongly discourages cremation of one's parents' corpses as unfilial. Han Chinese traditionally practiced burial and viewed cremation as taboo and as a barbarian practice.\n\nTraditionally, only Buddhist monks in China exclusively practiced cremation because ordinary Han Chinese detested cremation, refusing to do it. But now, the atheist Communist party enforces a strict cremation policy on Han Chinese. However, exceptions are made for Hui who do not cremate their dead due to Islamic beliefs.\n\nThe minority Jurchen and their Manchu descendants originally practiced cremation as part of their culture. They adopted the practice of burial from the Han, but many Manchus continued to cremate their dead.\n\nPet cremation is practiced internationally. In Japan, more than 465 companion animal temples are in operation. These venues hold funerals and rituals for lost pets. In Australia, pet owners can purchase services to have their companion animal cremated and placed in a pet cemetery or taken home.\n\nThe cost of pet cremation depends on location, where the cremation is done, and time of cremation. The American Humane Society's cost for cremation of 22.5 kg (50 lb). or less pet is $110 while 23 kg (51 lb). or more is $145. The cremated remains are available for the owner to pick up in seven to ten business days. Urns for the companion animal range from $50 to $150.\n\nIn early 2002, 334 corpses that were supposed to have been cremated in the previous few years at the Tri-State Crematory were found intact and decaying on the crematorium's grounds in the U.S. state of Georgia, having been dumped there by the crematorium's proprietor. Many of the corpses were decayed beyond identification. Some families received \"ashes\" that were made of wood and concrete dust.\n\nOperator Ray Brent Marsh had 787 criminal charges filed against him. On 19 November 2004, Marsh pleaded guilty to all charges. Marsh was sentenced to two 12-year prison sentences, one each from Georgia and Tennessee, to be served concurrently; he was also sentenced to probation for 75 years following his incarceration.\n\nCivil suits were filed against the Marsh family as well as a number of funeral homes who shipped bodies to Tri-State; these suits were ultimately settled. The property of the Marsh family has been sold, but collection of the full $80-million judgment remains doubtful. Families have expressed the desire to return the former Tri-State crematory to a natural, parklike setting.\n\nThe magnitude 9.0–9.3 2004 Indian Ocean earthquake triggered a series of lethal tsunamis on 26 December 2004 that killed almost 300,000 people, making them the deadliest tsunamis in recorded history. The tsunamis killed people over an area ranging from the immediate vicinity of the quake in Southeast Asia (Indonesia, Thailand, and the northwestern coast of Malaysia), to thousands of kilometers away in the Indian subcontinent (Bangladesh, India, Sri Lanka, the Maldives), the Horn of Africa (Somalia), and the African Great Lakes (Kenya and Tanzania).\n\nAuthorities had difficulties dealing with the large numbers of bodies, and as a result, thousands of bodies were cremated together out of fear that decaying bodies would cause disease. Many of these bodies were not identified or viewed by relatives prior to cremation. A particular point of objection was that the bodies of Westerners were kept separate from those of Asian descent, who were mostly locals. This meant that the bodies of tourists from other Asian nations, such as Japan and South Korea, were mass cremated, rather than being returned to their country of origin for funeral rites. \n\nThe cremation rate varies considerably across countries with Japan reporting a 99% cremation rate while Poland reported a rate of 6.7% in 2008. The cremation rate in the United Kingdom has been increasing steadily with the national average rate rising from 34.70% in 1960 to 75.44% in 2015. According to the National Funeral Directors Association the cremation rate in the United States in 2016 was 50.2 percent and this was expected to increase to 63.8 percent by 2025 and 78.8 percent in 2035.\n\n\n"}
{"id": "64248", "url": "https://en.wikipedia.org/wiki?curid=64248", "title": "Cthulhu", "text": "Cthulhu\n\nCthulhu ( ) is a fictional cosmic entity created by writer H. P. Lovecraft and first introduced in the short story \"The Call of Cthulhu\", published in the American pulp magazine \"Weird Tales\" in 1928. Considered a Great Old One within the pantheon of Lovecraftian cosmic entities, the creature has since been featured in numerous popular culture references. Lovecraft depicts Cthulhu as a gigantic entity worshipped by cultists. Cthulhu's appearance is described as looking like an octopus, a dragon, and a caricature of human form. Its name was given to the Lovecraft-inspired universe where it and its fellow entities existed, the Cthulhu Mythos.\n\nThough invented by Lovecraft in 1928, the name Cthulhu is probably derived from the word chthonic, derived from Classical Greek, meaning \"subterranean\", as apparently suggested by Lovecraft himself at the end of his 1923 tale \"The Rats in the Walls\".\n\nLovecraft transcribed the pronunciation of \"Cthulhu\" as \"Khlûl′-hloo\" and said that \"the first syllable pronounced gutturally and very thickly. The \"u\" is about like that in \"full\"; and the first syllable is not unlike \"klul\" in sound, hence the \"h\" represents the guttural thickness.\" S. T. Joshi points out, however, that Lovecraft gave several differing pronunciations on different occasions. According to Lovecraft, this is merely the closest that the human vocal apparatus can come to reproducing the syllables of an alien language. Cthulhu has also been spelled in many other ways, including \"Tulu\", \"Katulu\" and \"Kutulu\". The name is often preceded by the epithet \"Great\", \"Dead\", or \"Dread\".\n\nLong after Lovecraft's death, the spelling pronunciation became common. Others use the pronunciation \"Katulu/Kutulu\" .\n\nIn \"The Call of Cthulhu\", H. P. Lovecraft describes a statue of Cthulhu as \"A monster of vaguely anthropoid outline, but with an octopus-like head whose face was a mass of feelers, a scaly, rubbery-looking body, prodigious claws on hind and fore feet, and long, narrow wings behind.\" Cthulhu has been described in appearance as resembling an octopus, a dragon and a human caricature, hundreds of meters tall, with webbed human-looking arms and legs and a pair of rudimentary wings on its back. Cthulhu's head is depicted as similar to the entirety of a gigantic octopus, with an unknown number of tentacles surrounding its supposed mouth.\n\nLike most Lovecraftian entities, simply looking upon the creature's incomprehensible form drives the viewer insane.\n\nH. P. Lovecraft's initial short story, \"The Call of Cthulhu\", was published in \"Weird Tales\" in 1928 and established the character as a malevolent entity, hibernating within R'lyeh, an underwater city in the South Pacific. The imprisoned Cthulhu is apparently the source of constant anxiety for mankind at a subconscious level, and also the subject of worship by a number of human religions (located several places worldwide, including New Zealand, Greenland, Louisiana, and the Chinese mountains) and other Lovecraftian monsters (called Deep Ones and Mi-Go). The short story asserts the premise that, while currently trapped, Cthulhu will eventually return. His worshippers chant \"\"Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn\" (\"In his house at \"R'lyeh\", dead Cthulhu waits dreaming.\").\n\nLovecraft conceived a detailed genealogy for Cthulhu (published as \"Letter 617\" in \"Selected Letters\") and made the character a central figure in corresponding literature. The short story \"The Dunwich Horror\" (1928) refers to Cthulhu, while \"The Whisperer in Darkness\" (1930) hints that one of his characters knows the creature's origins (\"I learned whence Cthulhu first came, and why half the great temporary stars of history had flared forth.\"). The 1931 novella \"At the Mountains of Madness\" refers to the \"star-spawn of Cthulhu\", who warred with another race called the Elder Things before the dawn of man.\n\nAugust Derleth, a correspondent of Lovecraft, used the creature's name to identify the system of lore employed by Lovecraft and his literary successors: the Cthulhu Mythos. In 1937, Derleth wrote the short story \"The Return of Hastur\", and proposed two groups of opposed cosmic entities:\n\nAccording to Derleth's scheme, \"Great Cthulhu is one of the Water Elementals\" and was engaged in an age-old arch-rivalry with a designated air elemental, Hastur the Unspeakable, described as Cthulhu's \"half-brother\". Based on this framework, Derleth wrote a series of short stories published in \"Weird Tales\" (1944–1952) and collected as \"The Trail of Cthulhu\", depicting the struggle of a Dr. Laban Shrewsbury and his associates against Cthulhu and his minions.\n\nDerleth's interpretations have been criticized by Lovecraft enthusiast Michel Houellebecq, among others. Houellebecq's \"H. P. Lovecraft: Against the World, Against Life\" (2005) decries Derleth for attempting to reshape Lovecraft's strictly amoral continuity into a stereotypical conflict between forces of objective good and evil.\n\nIn John Glasby's \"A Shadow from the Aeons\", Cthulhu is seen by the narrator roaming the riverbank near Dominic Waldron's castle, and roaring. The physical description of the god is totally different from that given as canon by all the other authors.\n\nThe character's influence also extended into recreational literature: games company TSR included an entire chapter on the Cthulhu mythos (including statistics for the character) in the first printing of \"Dungeons & Dragons\" sourcebook \"Deities & Demigods\" (1980). TSR, however, were unaware that Arkham House, which asserted copyright on almost all Lovecraft literature, had already licensed the Cthulhu property to the game company Chaosium. Although Chaosium stipulated that TSR could continue to use the material if each future edition featured a published credit to Chaosium, TSR refused and the material was removed from all subsequent editions.\n\nIn 2006, Bethesda Softworks together with Ubisoft and 2K Games published a game made by Headfirst Productions called \"\" based on the works of Lovecraft. Cthulhu himself does not appear, as the main antagonists of the game are the Deep Ones from \"The Shadow Over Innsmouth\", and the sea god Dagon, but his presence has alluded to several times, and a statue depicting him appears in one of the temples that will negatively affect the player's sanity. One of Cthulhu's \"chosen\", a Star Spawn of Cthulhu, a hideous creature similar in appearance to the abomination himself, also appears as a late-game enemy.\n\nOn March 19, 2007, Steve Jackson Games released an iteration of their card game \"Munchkin\" called \"Munchkin\" \"Cthulhu.\" The game presents Cthulhu and its surrounding mythos with a cartoon art style and comedic tone, heavily playing upon themes of madness and cultism. \"Great Cthulhu\" features as a standalone monster in the deck, alongside various parodies of Lovecraft's creatures. Cthulhu is depicted as an overweight, the bright green creature with a large, bulbous head, and a pair of disproportionately small wings.\n\nCthulhu appears as a monster in many video games. \"Terraria\" features bosses named after the character, and he appears as the main inspiration for the story of the \"\" Zombies saga. The massively multiplayer online role-playing game \"World of Warcraft\" has numerous references to Cthulhu and the Mythos, with one of the game's \"Old Gods\" named N'Zoth resting in a sunken city.\n\nIn 2016, Z-Man games released an alternate version of their board game \"Pandemic\". This new adaptation \"\" is set in the Cthulhu Mythos and explorers race to save the world before Cthulhu returns.\n\nCthulhu has appeared as a parody candidate in several elections, including the 2010 Polish presidential election and the 2012/2016 US presidential elections. The faux campaigns usually satirize voters who claim to vote for the \"lesser evil\". In 2016 the Troll account known as \"The Dark Lord Cthulhu\" submitted an official application to be on the Massachusetts Presidential Ballot. The account also raised over $4000 from fans to fund the campaign through a gofundme.com page. Gofundme removed the campaign page and refunded the funds, stating that the fundraiser did not meet their requirements.\n\nThe Californian spider species \"Pimoa cthulhu\", described by Gustavo Hormiga in 1994, and the New Guinea moth species \"Speiredonia cthulhui\", described by Zilli & Holloway in 2005, are named with reference to Cthulhu.\n\nTwo microorganisms that assist in the digestion of wood by termites have been named after Cthulhu and Cthulhu's \"daughter\" Cthylla: \"Cthulhu macrofasciculumque\" and \"Cthylla microfasciculumque\", respectively.\n\nIn 2014, science and technology scholar Donna Haraway gave a talk entitled \"Anthropocene, Capitalocene, Chthulucene: Staying with the Trouble\", in which she proposed the term \"Chthulucene\" as an alternative for the concept of the Anthropocene era, due to the entangling interconnectedness of all supposedly individual beings. Haraway has denied any indebtedness to Lovecraft's Cthulhu, claiming that her \"chthulu\" is derived from the Greek \"khthonios\", meaning \"of the earth\". However, the Lovecraft character is much closer to her coined term than the Greek root, and her description of its meaning coincides with Lovecraft's idea of the apocalyptic scale of the threat of Cthulhu, with his horrifying tentacles, to collapse civilization into an endless dark horror: \"Chthulucene does not close in on itself; it does not round off; its contact zones are ubiquitous and continuously spin out loopy tendrils.\"\n\nIn 2015, an elongated, dark region along the equator of Pluto, initially referred to as \"the Whale\", was proposed to be named \"Cthulhu Regio\", by the NASA team responsible for the \"New Horizons\" mission. It is now known as \"Cthulhu Macula\".\n\nSeveral films and television programs feature the threat of Cthulhu returning to dominate the Universe. A vivid example of the latter is three episodes of the adult cartoon series \"South Park\" in which Eric Cartman turns out to be so irredeemably evil that he is able to tame Cthulhu and direct him to annihilate personal enemies. In those episodes (\"\", \"Mysterion Rises\", and \"Coon vs. Coon & Friends\") Cthulhu is faithfully represented as the monstrous tentacle-mouthed god-like being Lovecraft describes. Also, \"Supernatural\" devoted \"Let It Bleed\" (episode 21 of season 6) to a Lovecraft-inspired plot, with teen character Ben even shown reading a graphic novel entitled \"Cthulhu Tales\" right before he is kidnapped by demons who are \"crafting\" an evil empire and working to put Purgatory under their control. In the popular adult animated science-fiction sitcom \"Rick and Morty\", a depiction of Cthulhu can be seen in the opening sequence, immediately prior to the title card. In Cartoon Network's animated show \"The Grim Adventures of Billy and Mandy\", Cthulhu has a dedicated double length episode called \"Prank Call of Cthulhu\".\n\nOn October 27, 1987, Cthulhu appeared in season 2 episode 28 of \"The Real Ghostbusters\" animated cartoon entitled \"The Collect Call of Cathulhu\", in which the Ghostbusters went up against the Spawn, and Cult, of Cthulhu.\n\nCthulhu is featured in Arcana Studio's Howard Lovecraft animated trilogy beginning with Howard Lovecraft and the Frozen Kingdom, and ending with the upcoming Kingdom of Madness.\n\nHeavy metal band Metallica reference Cthulhu in the song \"Dream No More\" from their 2016 album \"Hardwired... To Self-Destruct\", as well as on the 1984 album \"Ride The Lightning\" with the instrumental song \"The Call of Ktulu\", inspired by H. P. Lovecraft's novella \"The Shadow over Innsmouth\", which was introduced to the rest of the band by Cliff Burton, and on the 1986 album \"Master of Puppets\" with the song \"The Thing That Should Not Be\" (whose lyrics are inspired by \"The Shadow over Innsmouth\" and contain partial quotes from \"The Call of Cthulhu\"). The second album of British steampunk band The Men That Will Not Be Blamed for Nothing features the song \"Margate Fhtagn\". The song describes the band's meeting with Cthulhu while on holiday in Margate. English extreme metal band Cradle of Filth's fourth album, \"Midian\", features a song titled \"Cthulhu Dawn\", although the lyrics seem to have nothing to do with Lovecraft's sea-monster. The song \"Last Exit for the Lost\" by British gothic rock band Fields of the Nephilim references Cthulhu (or 'Kthulhu' as it is spelled on the album's inner sleeve).\n\nThe story was adapted for the stage by Oregon-based theater company, Puppeteers for Fears, who performed \"The Call of Cthulhu,\" as \"Cthulhu: the Musical!\" a feature-length rock and roll musical comedy performed with puppets. The script and songs were written by playwright Josh Gross, and after a successful run in Ashland, Oregon, the production toured the west coast in 2018, including a sold-out run at the Hollywood Fringe Festival. Of the show, \"The Portland Mercury\" wrote, \"You haven't truly experienced Lovecraft's madness until you've experienced it in its truest form: As a puppet musical.\" \n\n"}
{"id": "11068687", "url": "https://en.wikipedia.org/wiki?curid=11068687", "title": "David Chavchavadze", "text": "David Chavchavadze\n\nPrince David Chavchavadze (May 20, 1924 – October 5, 2014) was an American author and a former Central Intelligence Agency (CIA) officer of Georgian-Russian origin.\n\nChavchavadze was born in London to Prince Paul Chavchavadze (1899–1971) and Princess Nina Georgievna of Russia (1901–1974), a descendant of a prominent Georgian noble family and the Imperial Russian dynasty. His father, Prince Paul, was a fiction writer and translator of writings from Georgian into English, and an émigré in the United Kingdom, and then the United States. \n\nChavchavadze entered the United States Army in 1943 and served during World War II as liaison for the U.S. Army Air Force Lend-Lease supply operations to the Soviet Union. After the war, he entered Yale University where he was a member of The Society of Orpheus and Bacchus, the second longest running a cappella group in the United States. He spent more than two decades of his career as a CIA officer in the Soviet Union Division.\n\nAfter his retirement, Chavchavadze specialized in tracing the nobility of Imperial Russia and authored \"The Grand Dukes\" (1989). He also published \"Crowns and Trenchcoats: A Russian Prince in the CIA\" (1989) based on his CIA experiences, and translated from Russian \"Stronger Than Power: A Collection of Stories\" by Sandji B. Balykov, an emigre Kalmyk writer. Additionally, he lectured part-time at Georgetown and George Mason Universities on Russian history and culture.\n\nAs a grandchild of a Russian Grand Duke, he was an Associate Member of the Romanov Family Association. Via his mother, Chavchavadze is great-great-grandson (through Grand Duke Mikhail Nicholaevich) and simultaneously great-great-great-grandson (through Queen of Greece, Olga Constantinovna) of Nicholas I.\n\nHe married Helen Husted on 13 September 1952 and they were divorced in 1959. They have two daughters and three grandchildren:\n\n\nHe remarried Judith Clippinger on 28 December 1959 and they were divorce in 1970. They have two children and three grandchildren\n\n\nHe remarried, again, Euginie de Smitt in 1979. David Chavchavadze died in his sleep on October 5, 2014, aged 90, after a long illness.\n\n\n"}
{"id": "12546131", "url": "https://en.wikipedia.org/wiki?curid=12546131", "title": "Dennis A'Court", "text": "Dennis A'Court\n\nDennis George A'Court (born 27 July 1937) is a former Welsh-born cricketer. He was a right-handed batsman and a right-arm medium-fast bowler who played first-class cricket for Gloucestershire between 1960 and 1963. He was born in Markham in Monmouthshire, a former mining village.\n\nHe took 145 first-class wickets, with a best of 6 for 25 against the South African tourists in 1960: \"Wisden\" noted that he \"shocked the South Africans with his accuracy, liveliness, and disconcerting swing and movement of the ball\". He took five wickets in an innings on five occasions.\n"}
{"id": "44750726", "url": "https://en.wikipedia.org/wiki?curid=44750726", "title": "Design space verification", "text": "Design space verification\n\nDesign space verification is defined by the European Medicines Agency as the verification that material inputs and processes are able to scale to commercial manufacturing levels while maintaining a standard of quality. Therefore, it is difficult to conduct design space verification while not operating at target levels and should be conducted over the manufacturing lifecycle. Changes in manufacturing output within the design space should not present any risks. Should the manufacturing load exceed the boundaries defined as normal operating ranges unanticipated scale-dependent issues can occur.\n\nDesign space verification is a part of process validation as defined by the EMA in conjunction with the FDA. Its purpose is to guarantee end product quality within a range of manufacturing boundaries. The effects of scale up activities should be fully understood by the manufacturer. Most initial design space conclusions are based upon laboratory testing or pilot batches with scale up effects being inferred by experimentation or based on statistical evidence, simulations, or studies. Ongoing design space verification should be dependent upon the results of an assessment of risk involved with scale up activities. More specifically, how scaling up production affects scale-dependent variables. \nDesign space verification is much more focused in scope than overall process validation. Design space verification specifically aims to confirm output quality within a given operating range. This allows for changes in operating level flexibility while guaranteeing production quality, and allows for changes in production quantities without necessitating a reevaluation of the production process.\n\n"}
{"id": "4357120", "url": "https://en.wikipedia.org/wiki?curid=4357120", "title": "Eduardo Reck Miranda", "text": "Eduardo Reck Miranda\n\nEduardo Reck Miranda (born 1963) is a Brazilian composer of chamber and electroacoustic pieces but is most notable in the United Kingdom for his scientific research into computer music, particularly in the field of human-machine interfaces where brain waves will replace keyboards and voice commands to permit the disabled to express themselves musically. \n\nMiranda was born in Porto Alegre, Brazil. As one of the largest cities in Southern Brazil and a cultural, political and economical center, Porto Alegre had significant influence on Miranda's music.\n\nIn the early 1990s, Miranda attended the University of Vale do Rio dos Sinos (UNISINOS) in Brazil where he received a degree in Data Processing Technology in 1985. Miranda then attended the Federal University of Rio Grande do Sul (UFRGS) where he studied music composition. Desiring to learn more about music technology and experience more of the world, Miranda made his way to the United Kingdom, where he started his post-graduate research studies at the University of York. At York, he developed an in-depth study into musical composition using cellular automata. In 1991, he received his MSc in Music Technology from York. After receiving his MSc, Miranda went briefly to Germany to study algorithmic composition at the Zentrum für Kunst und Medientechnologie in Karlsruhe.\n\nIn 1992, Miranda gained admittance to the Faculty of Music of the University of Edinburgh in Scotland where he obtained his PhD in the combined fields of music and artificial intelligence in 1995. For his doctoral thesis, he focused on musical knowledge representation, machine learning of music and software sound synthesis.\n\nAfter receiving his PhD, Miranda worked at the Edinburgh Parallel Computing Centre (EPCC). At EPCC, he developed Chaosynth, an innovative granular synthesis software that uses cellular automata to generate complex sound spectra.\n\nIn the mid-1990s, Miranda joined the Department of Music at the University of Glasgow, where he lectured music technology and electroacoustic music composition for a number of years. Then he moved to Paris, to take up a research position at Sony Computer Science Laboratory in the late 1990s.\n\nAt Sony, Miranda conducted research aimed at gaining a better understanding of the fundamental cognitive mechanisms employed in sound-based communication systems. This research led Miranda to focus on the evolution of the human ability to speak and the role of our musical capacity in the development of spoken languages. While at Sony, Miranda filed patents in the field of speech processing and made scientific contributions in the fields of speech synthesis, evolutionary music (computational) and cognitive neural modeling.\n\nIn the early 2000s he was appointed Visiting Professor of Interactive Media Arts at MECAD (School of Media Arts and Design) in Barcelona and Adjunct Associate Professor of Computer Science at the American University of Paris.\n\nIn 2003 Miranda moved to the University of Plymouth in the UK where he presently is a full Professor in Computer Music and Head of the \"Interdisciplinary Centre for Computer Music Research\" (ICCMR). He is also an active associate member of the \"Computer Music Lab\" at the Federal University of Rio Grande do Sul (UFRGS), in his native town of Porto Alegre.\n\nMiranda's musical compositions have been broadcast and performed in a number of concerts and festivals worldwide, including the Festival Latino-Americano de Arte e Cultura (Brasília, 1987), the Encompor (Porto Alegre, 1988–89, 1995), the International Symposium for Electronic Arts (Minneapolis, 1993), the Festival Elektronischer Frühling (Vienna, 1993–94), and the Ciclo Acusmático (Bogotá, 1995). His music has won prizes and distinctions in Europe and South America, including awards at the Concours International de Musique Électroacoustique de Bourges (1994), the Concurso de Composição de Londrina (Brazil, 1995) and the Concorso Internazionale Luigi Russolo di Musica Elettroacustica (Italy, 1995, 1998). A review of his latest solo CD \"Mother Tongue\", in \"The Wire\" magazine, reads, \"These are immensely sophisticated pieces that constitute an electronic global music of convincingly organic simplicity.\"\n\nMiranda is an active researcher in the field of Artificial Intelligence in Music. He is currently conducting research into neuroscience of music and into simulations of biological natural processes in music origins and evolution. Miranda has turned to artificial life models to coax computers into composing music.\n\nJust as IBM's Deep Blue showed the world a computer can play chess as well as a human master, Miranda aims to demonstrate a computer program able to compose original music. So far, neural networks have succeeded in imitating distinct musical styles, but truly original compositions have remained elusive. Miranda is tackling this problem with an orchestra of virtual musician agents who interact to compose original music.\n\n\n\nMiranda's papers have been published by many international journals, including Evolutionary Computation, Brain and Language, Digital Creativity, Contemporary Music Review, Computer Music Journal, Journal of New Music Research, Journal of the Audio Engineering Society, Leonardo, Leonardo Music Journal, and Organized Sound.\n\n\n\n\n\n\n\n"}
{"id": "52759114", "url": "https://en.wikipedia.org/wiki?curid=52759114", "title": "Erasma Arellano", "text": "Erasma Arellano\n\nErasma Arellano was a Filipino track and field athlete. As a member of the Philippine men’s track and field team, he was a bronze medalist for the 4 × 400 metres relay in the 1958 Asian Games.\n"}
{"id": "205720", "url": "https://en.wikipedia.org/wiki?curid=205720", "title": "Florence Ballard", "text": "Florence Ballard\n\nFlorence Glenda Chapman (née Ballard; June 30, 1943 – February 22, 1976) was an American singer. Ballard was the founding member of the popular Motown vocal female group the Supremes. Ballard sang on 16 top 40 singles with the group, including ten number-one hits. After being removed from the Supremes in 1967, Ballard tried an unsuccessful solo career with ABC Records before she was dropped from the label at the end of the decade. Ballard struggled with alcoholism, depression, and poverty for three years. She was making an attempt for a musical comeback when she died of a heart attack in February 1976 at the age of 32. Ballard's death was considered by one critic as \"one of rock's greatest tragedies\". Ballard was posthumously inducted to the Rock and Roll Hall of Fame as a member of the Supremes in 1988.\n\nFlorence Glenda Ballard was born in Detroit, Michigan on June 30, 1943 to Lurlee (née Wilson) and Jesse Ballard, as the ninth of fifteen children. Her siblings were Bertie, Cornell, Jesse, Jr., Gilbert, Geraldine, Barbara, Maxine, Billy, Calvin, Pat, Linda and Roy. Her mother was a resident of Rosetta, Mississippi. Her father was born Jesse Lambert in Bessemer, Alabama; after his grandmother was shot and killed, he was adopted by the Ballard family. Jesse Ballard left his adoptive parents at 13, and soon engaged in an affair with Ballard's mother, who was only 14, in Rosetta. The Ballards moved to Detroit in 1929. Jesse soon worked at General Motors. Jesse, an amateur musician, helped instigate Florence's interest in singing; he taught her various songs and accompanied her on guitar. Financial difficulties forced the Ballard family to move to different Detroit neighborhoods; by the time Florence turned 15 they had settled at Detroit's Brewster-Douglass housing projects, and the next year Jesse Lambert Ballard died of cancer.\n\nNamed \"Blondie\" and \"Flo\" by family and friends, Ballard attended Northeastern High School and was coached vocally by Abraham Silver. Ballard met future singing partner Mary Wilson during a middle-school talent show and they became friends while attending Northeastern High. From an early age, Ballard aspired to be a singer and agreed to audition for a spot on a sister group of the local Detroit attraction, the Primes, who were managed by Milton Jenkins. After she was accepted, Ballard recruited Mary Wilson to join Jenkins' group. Wilson, in turn, enlisted another neighbor, Diana Ross, then going by \"Diane\". Betty McGlown completed the original lineup and Jenkins named them as \"The Primettes\". The group performed at talent showcases and at school parties before auditioning for Motown Records in 1960. Berry Gordy, head of Motown, advised the group to graduate from high school before auditioning again. Ballard eventually dropped out of high school though her groupmates graduated.\n\nIn 1960, Ballard was raped at knifepoint by local high-school basketball player Reggie Harding after leaving a sock hop at Detroit's Graystone Ballroom (she had attended with her brother, but they accidentally lost track of each other). The rape occurred in an empty parking lot off Woodward Avenue. Ballard responded by secluding herself in her house refusing to come outside, which worried her groupmates. Weeks later, Ballard told Wilson and Ross what had happened. Though Ross and Wilson were sympathetic, they were also confused because Ballard was considered to be strong-willed and unflappable. Both Wilson and Jesse Green, an early boyfriend of Florence's, had described her as a \"generally happy if somewhat mischievous and sassy teenager.\" Wilson believes that the incident heavily contributed to the more self-destructive aspects of Ballard's adult personality, like cynicism, pessimism, and fear or distrust of others, but the rape was never mentioned again.\n\n Later in 1960, the Primettes signed a contract with Lu Pine Records, issuing two songs that failed to perform well. During that year, they kept pursuing a Motown contract and agreed to do anything that was required, including adding handclaps and vocal backgrounds. By the end of the year, Berry Gordy agreed to have the group record songs in the studio. In January 1961, Gordy agreed to sign them on the condition they change their name. Janie Bradford approached Ballard with a list of names to choose from before Ballard chose \"Supremes\". When the other members heard of the new name, they were not pleased. Diana Ross feared they would be mistaken for a male vocal group. Eventually Gordy agreed to sign them under that name on January 15, 1961.\n\nThe group struggled in their early years with the label, releasing eight singles that failed to crack the \"Billboard\" Hot 100, giving them the nickname \"no-hit Supremes\". One track, \"Buttered Popcorn\", led by Ballard, was a regional hit in the Midwest, but still failed to chart. During a 1962 Motortown Revue tour, Ballard briefly replaced the Marvelettes' Wanda Young while she was on maternity leave. Before the release of their 1962 debut album, \"Meet the Supremes\", Barbara Martin, who had replaced Betty McGlown a year before they signed to Motown, left the group. Ballard, Ross and Wilson remained a trio. After the hit success of 1963's \"When the Love Light Starts Shining Through His Eyes\", Diana Ross became the group's lead singer.\n\nIn the spring of 1964, the group released \"Where Did Our Love Go\", which became their first number-one hit on the Billboard Hot 100, paving the way for ten number-one hits recorded by Ross, Ballard and Wilson between 1964 and 1967. After many rehearsals with Cholly Atkins and Maurice King, the Supremes' live shows improved dramatically as well. During this time, Ballard sang lead on several songs on Supremes' albums, including a cover of Sam Cooke's \"(Ain't That) Good News\". During live shows, Ballard often performed the Barbra Streisand standard, \"People\". According to Mary Wilson, Ballard's vocals were so loud she was made to stand 17 feet away from her microphone during recording sessions. Marvin Gaye, for whom Ballard sang backing vocals on occasion, described her as \"a hell of a singer, probably the strongest of the three girls.\" All in all, Ballard contributed vocals to ten number-one pop hits and 16 top forty hit singles between 1963 and 1967.\n\nBallard expressed dissatisfaction with the group's direction throughout its successful period. She would also claim that their schedule had forced the group members to drift apart. Ballard blamed Motown Records for destroying the group dynamic by making Diana Ross the star. Struggling to cope with label demands and her own bout with depression, Ballard turned to alcohol for comfort, leading to arguments with her group members. Ballard's alcoholism led to her missing performances and recording sessions. Gordy sometimes replaced Ballard on stage with the Andantes' Marlene Barrow. In April 1967, Cindy Birdsong, member of Patti LaBelle and the Blue Belles, became a stand-in for Ballard. A month later, Ballard returned to the group from what she thought was a temporary leave of absence. In June, Gordy changed the group's name to \"The Supremes with Diana Ross\", which was how they were billed on the marquee of Las Vegas' Flamingo Hotel.\n\nOn July 1, the day after her 24th birthday, Ballard showed up inebriated during the group's third performance at the Flamingo and stuck her stomach out from her suit. Angered, Gordy ordered her to return to Detroit, and Birdsong officially replaced her, abruptly ending her tenure with the Supremes. It had been decided as early as May that Birdsong would be Ballard's official replacement once Birdsong's contract with the Bluebelles was bought out. In August 1967, the \"Detroit Free Press\" reported that Ballard had taken a temporary leave of absence from the group due to \"exhaustion\". Ballard eventually married her boyfriend, Thomas Chapman, on February 29, 1968. A week earlier, on February 22, Ballard and Motown negotiated to have Ballard released from the label. Her attorney in the matter received a one-time payment of $139,804.94 in royalties and earnings from Motown. As part of the settlement, Ballard was advised to not promote her solo work as a former member of the Supremes. In March 1968, Ballard signed with ABC Records and released two unsuccessful singles. After an album for the label was shelved, her settlement money was depleted from the Chapmans' management agency, Talent Management, Inc. The agency had been led by Leonard Baun, Ballard's attorney who had helped to settle Ballard's matters with Motown. Following news that Baun was facing multiple embezzlement charges, Ballard fired him. She continued to perform as a solo artist, opening for Bill Cosby that September at Chicago's Auditorium Theater. In January 1969, Ballard performed at one of newly elected President Richard Nixon's inaugural balls. Ballard was dropped from ABC in 1970.\n\nIn July 1971, Ballard sued Motown for additional royalty payments she believed she was due to receive; she was defeated in court by Motown. Shortly afterwards, Ballard and her husband separated following several domestic disputes and Ballard's home was foreclosed. Facing poverty and depression, Ballard became an alcoholic and shied away from the spotlight. In 1972, she moved into her sister Maxine's house. In 1974 Mary Wilson invited Ballard to join the Supremes, which now included Cindy Birdsong and Scherrie Payne (Ross had left for her successful solo career in 1970). Though Ballard played tambourine, she didn't sing and told Wilson she had no ambition to sing any more. Later that year Ballard's plight started to be reported in newspapers as word got around that the singer had applied for welfare. Around that time, Ballard entered Henry Ford Hospital for rehab treatment. Following six weeks of treatment, Ballard slowly started to recover.\n\nIn early 1975, Ballard received an insurance settlement from her former attorney's insurance company. The settlement money helped her buy a house on Shaftsbury Avenue. Inspired by the financial success, Ballard decided to return to singing and also reconciled with Chapman. Ballard's first concert performance in more than five years took place at the Henry and Edsel Ford Auditorium in Detroit on June 25, 1975. Ballard performed as part of the Joan Little Defense League and was backed by female rock group the Deadly Nightshade. Afterward she started receiving offers for interviews; \"Jet\" magazine was one of the first to report on Ballard and her recovery.\n\nOn February 21, 1976, Ballard entered Mt. Carmel Mercy Hospital, complaining of numbness in her extremities. She died at 10:05 the next morning from cardiac arrest caused by a coronary thrombosis (a blood clot in one of her coronary arteries), at the age of 32. Ballard is buried in Detroit Memorial Park Cemetery located in Warren, Michigan.\n\nFlorence Ballard's story has been referenced in a number of works by other artists. The 1980 song \"Romeo's Tune\", from Steve Forbert's album \"Jackrabbit Slim\" is \"dedicated to the memory of Florence Ballard\". The Billy Bragg song \"King James Version\" on his \"William Bloke\" album contains the line \"Remember the sadness in Florence Ballard's eyes\". On his 2006 album \"Hip Hop is Dead\", hip-hop artist Nas mentions the Ballard/Ross rivalry in his song \"Blunt Ashes\": \"When Flo from the Supremes died/Diana Ross cried/Many people said that she was laughing inside.\" In his short story \"You Know They Got a Hell of a Band\", Stephen King, through the late disc jockey Alan Freed, includes Ballard as one of the deceased artists who performs in a town called \"Rock and Roll Heaven\".\n\n\"Dreamgirls\", a 1981 Broadway musical, chronicles a fictional group called \"The Dreams,\" and a number of plot components parallel events in the Supremes' career. The central character of Effie White, like Florence Ballard, is criticized for being overweight, and is fired from the group. The film version of \"Dreamgirls\" released in 2006 features more overt references to Ballard's life and the Supremes' story, including gowns and album covers that are direct copies of Supremes originals. Jennifer Hudson won a Golden Globe Award and Academy Award for her portrayal of Effie White in the \"Dreamgirls\" film. In her Golden Globe acceptance speech, Hudson dedicated her win to Florence Ballard. The music video for the Diana Ross song \"Missing You\" pays tribute to Marvin Gaye, Ballard, and Paul Williams, all former Motown artists who had died. In 1988, Ballard was inducted to the Rock and Roll Hall of Fame as a member of the Supremes alongside Diana Ross and Mary Wilson.\n\nBallard began dating Thomas Chapman, a Motown Records associate, in 1967; they married in a private celebration in Hawaii on February 29, 1968, and had three daughters: Michelle Denise and Nichole Rene and Lisa Sabrina (b. 1971). Ballard reportedly had several domestic disputes with her husband and filed for divorce in 1973, but they reconciled in late 1975, prior to her death. Besides her three daughters, Ballard's family included her cousin Hank Ballard and his grandnephew, NFL player Christian Ballard.\n\n\n\nNotes\nBibliography\n\nFurther reading\n\n"}
{"id": "11415", "url": "https://en.wikipedia.org/wiki?curid=11415", "title": "Forcemeat", "text": "Forcemeat\n\nForcemeat (derived from the French \"farcir\", \"to stuff\") is a mixture of ground, lean meat mixed with fat by grinding, sieving, or puréeing the ingredients. The result may either be smooth or coarse, depending on the desired consistency of the final product. Forcemeats are used in the production of numerous items found in charcuterie, including quenelles, sausages, pâtés, terrines, roulades, and galantines. Forcemeats are usually produced from raw meat, except in the case of a \"gratin\". Meats commonly used include pork, fish (pike, trout, or salmon), seafood, game meats (venison, boar, or rabbit), poultry, game birds, veal, and pork livers. Pork fatback is preferred as a fat, as it has a somewhat neutral flavor.\n\nForcemeats are an ancient food, and are included in \"Apicius\", a collection of Roman cookery recipes, usually thought to have been compiled in the late 4th or early 5th century AD.\n\n\nOften, the only binder in a forcemeat is the physical structure of the protein used. Sometimes a secondary binder is necessary to hold the mixture. These binders are generally needed when preparing the country-style and \"gratin\" forcemeats. The three types of binders include eggs, nonfat dry milk powder, and panades. A panade can be made from starchy ingredients which aid in the binding process; these include well-cooked potatoes which have been puréed, cream-soaked bread, or pâte à choux.\n\n\n"}
{"id": "11968", "url": "https://en.wikipedia.org/wiki?curid=11968", "title": "George Washington", "text": "George Washington\n\nGeorge Washington (February 22, 1732 – , 1799) was one of the Founding Fathers of the United States of America and served as the nation's first President (1789–1797). He commanded Patriot forces in the new nation's vital American Revolutionary War and led them to victory over the British. Washington also presided at the Constitutional Convention of 1787, which established the new federal government. For his manifold leadership he has been called the \"Father of His Country\".\n\nWashington was born to a successful family of planters and slaveholders in colonial Virginia. He had educational opportunities and at age seventeen launched a successful career as a land surveyor. He then became a leader of the Virginia militia in the French and Indian War. During the Revolutionary War he was a delegate to the Continental Congress which unanimously appointed him commander-in-chief of the Army, leading an allied campaign to victory at the Siege of Yorktown which ended the conflict. Once victory was in hand, in 1783 he resigned as commander-in-chief, declining further authority and power out of his devotion to republicanism.\n\nAs the country's premier statesman, Washington was unanimously elected President by the Electoral College in the first two national elections. He promoted and oversaw implementation of a strong, well-financed national government, but remained impartial in the fierce rivalry between Thomas Jefferson and Alexander Hamilton. When the French Revolution plunged Europe into war, Washington proclaimed a policy of neutrality while sanctioning the controversial Jay Treaty. He set numerous precedents that have endured, such as the cabinet advisory system, the inaugural address, and his acceptance of the Congressional title \"The President of the United States.\" His Farewell Address strongly warned against political partisanship, sectionalism, and involvement in foreign wars.\n\nWashington owned slaves throughout his life from age 11, but became increasingly troubled by slavery and freed his slaves in his will. He was a member of the Anglican Church and the Freemasons, and he urged tolerance for all religions in his roles as general and President. Upon his death, he was famously eulogized as \"first in war, first in peace, and first in the hearts of his countrymen\". Washington has been widely memorialized by monuments, art, places, stamps, and currency, and he has been consistently ranked by scholars among the four greatest American presidents.\n\nGeorge Washington was born in the Colony of Virginia on February 22, 1732, the first child of Augustine Washington and his wife Mary Ball Washington, at Wakefield on their Westmoreland County Popes Creek Estate. He was then a subject of the British Empire, under the reign of George II, descended primarily from the gentry of Sulgrave, England. His great grandfather John Washington emigrated to Virginia in 1656. John was a tobacco planter who accumulated land and slaves, as did his son Lawrence and his grandson Augustine.\n\nWashington was reared in the rich open farmlands of Virginia's Tidewater region. His father Augustine was a moderately wealthy planter, justice of the peace, and county sheriff who had 10 children, 4 by his first marriage to Jane Butler, and 6 children by his second marriage to Mary. Seven of Augustine's children survived, including Washington, his older half-brothers Lawrence and Augustine, and full siblings Samuel, Elizabeth (Betty), John Augustine, and Charles. Three siblings of Washington died before adulthood. These included his sister Mildred at age 1, half-brother Butler in infancy, and half-sister Jane at age 12.\n\nAt age three, Washington and his family moved to Epsewasson, a plantation that his father had purchased, on the bluffs of the Potomac River. When Washington was six years old, they moved to Ferry Farm near Fredericksburg. He spent much of his boyhood there; it is said to be the setting for the legendary cherry tree anecdote reported by Parson Weems, based on accounts of family acquaintances. By tradition, at Ferry Farm, when Augustine asked George whether he damaged a cherry tree, the boy replied, \"I cannot tell a lie; I cut it with my little hatchet.\"\n\nOn April 12, 1743, aged forty-eight, Augustine died of a sudden illness. The eleven-year-old Washington was kept under the strict care of his mother Mary. He inherited Ferry Farm and ten slaves, while his older half-brother Lawrence inherited Epsewasson and changed its name to Mount Vernon, in honor of British Vice Admiral Edward Vernon, his commander during the War of Jenkins' Ear.\n\nWashington's initial teachers were his father and Lawrence, in an education that spanned over eight years. His mother could not afford the cost of England's Appleby Grammar School, so he was tutored by various masters including Mr. Hobby, his father's former tenant; he also attended the Fredericksburg school of Anglican clergyman James Mayre. He was taught mathematics, trigonometry, and surveying by school master Henry Williams, and he had a natural talent in draftsmanship and map-making. He purchased books on military affairs, agriculture, and history, as well as popular novels, and by early adulthood he was writing with precision and considerable force.\n\nWashington's mother rejected a plan for him to join the Royal Navy in September 1746 when he was fourteen years old. His brother Lawrence in 1743 had married Anne Fairfax, the daughter of powerful Virginia statesman William Fairfax, who became Washington's idolized surrogate father. Washington moved to Mount Vernon with Lawrence and Ann when he was seventeen years old, and was close friends with William Fairfax's son George, whose wife Sally had been an early romantic interest; she maintained correspondence with Washington when she moved to England with her father.\n\nWashington and George William Fairfax accompanied surveyor James Genn in 1748 when Washington was sixteen years old. Genn had been sent by Lord Fairfax to survey the Shenandoah lands, and Washington gained valuable experience during the month-long trip. In 1749, at age seventeen, Washington received a commission and surveyor's license from the College of William & Mary, and was appointed surveyor of Culpeper, Virginia, due to Fairfax's influence. He primarily surveyed for Lord Fairfax in the Blue Ridge Mountains, after a preliminary survey of eastern Culpeper County. He made numerous surveys of the Shenandoah Valley during the spring of 1750, and became accustomed to the wilderness. In October 1750, Washington, aged eighteen, had bought almost in the Shenandoah Valley, his first large land investment, and afterwards he resigned his Culpeper commission. By the time Washington was twenty years old he accumulated in the Shenandoah Valley.\n\nWashington stopped surveying within a few years but continued purchasing land. He acquired more than in seven states and the District of Columbia in his lifetime; it took him 25 years to expand his Mount Vernon estate from . He bought more parcels of land to spur development around Federal City (modern Washington, D.C.). Rather than selling multiple lots to large investors, he sold individual lots to middle-income investors, believing they would more likely commit to making improvements.\n\nIn 1751, Washington made his only trip abroad with Lawrence to Barbados in the hope that the climate would be beneficial to his brother's tuberculosis. During the trip, Washington contracted smallpox which immunized him but left his face slightly scarred. Lawrence's health continued to decline and he returned to Mount Vernon, where he died on July 26, 1752. Washington inherited his Mount Vernon estate after the deaths of Lawrence's wife Ann and their daughter.\n\nWashington's military life began in the years leading up to the French and Indian War. His brother Lawrence was an Adjutant General at the time of his death which inspired Washington to pursue his military career. He was trained in musters and drills before Robert Dinwiddie appointed him adjutant, first to the Southern district in December 1752 and later to the Northern and Eastern districts as well. In February 1753, when Washington was 21, Dindwiddie promoted him to the rank of Major at an annual salary of 100 pounds, then made him British military ambassador to the French officials and to the Iroquois and Algonquians, as far north as Erie, Pennsylvania (in the Ohio Country). Thirty years later Washington reflected in amazement \"that so young and inexperienced a person should have been employed\" in such negotiations.\n\nThe British government had ordered Dinwiddie to guard British territorial claims in the Ohio River basin, protecting trade activity with the Indians and others in the various settlements. Dindwiddie ordered Washington to deliver a letter in late 1753 asking French commander Jacques Legardeur de Saint-Pierre at Fort Le Boeuf to vacate the Ohio Valley, and offering him a safe escort to Lake Erie. Washington was also to make peace with the Six Nations. He and six frontiersmen reached the Ohio River that November, but the French had withdrawn. He met with Half-King Tanacharison and other Six Nations Iroquois chiefs at Logstown and secured their support against the French if needed, then continued and met the French at Venango—but the letter was refused. Washington then reached Fort Le Boeuf and delivered the letter to the commander, who replied that Dinwiddie should send his demand to the Major General of New France at its capital in Quebec. By Dinwiddie's order, Washington's diary of the expedition was printed by William Hunter, giving Washington name recognition in Virginia and England; it also helped him obtain a commission to raise a company of men.\n\nIn 1753, the French military advanced into the Ohio Country, territory that both France and Britain sought. Virginia's Ohio Company, of which Dinwiddie and Washington were stockholders, was created to encourage British settlement of the land; it had an economic interest in the region. The land that joined the Monongahela and Allegheny rivers (the area that would become Pittsburgh) was highly prized by both nations; the competing stakes led to the French and Indian War (1754–62) as well as the onset of the Seven Years' War (1756–63). Washington ordered the first shot fired in the former war.\n\nOn March 15, 1754, Governor Dinwiddie commissioned Washington Lieutenant Colonel in the newly formed Virginia Regiment at age 22 and sent him to confront French forces at Pittsburgh. Dindwiddie ordered Washington to take prisoners or kill those who resisted British control of the region. He set out on April 2 with 150 men, and received news en route that a French force had driven out colonial traders and begun construction of Fort Duquesne. Half-King Tanacharison and a few warriors discovered a small detachment of French troops east of Uniontown, Pennsylvania, led by Joseph Coulon de Jumonville, so Washington built an entrenched camp at Great Meadows, which he called Fort Necessity. He then led his unit and their Mingo (Iroquois) allies in an ambush against the French on May 28 in the brief Battle of Jumonville Glen. Jumonville was killed, and most of his party were taken prisoner or killed; for this battle, Tanacharison gave Washington the name Conotocaurius (\"Town Destroyer\").\n\nIn July 1754, the French responded by attacking the fort in the ten-hour Battle of Fort Necessity, which ended in Washington's only surrender after he had signed a surrender document which, when translated, stated that Washington had \"assassinated\" Jumonville (rather than killing him in battle);this mistranslated document became the pretext to blame him for starting a war. Modern historian Joseph Ellis concludes that the episode demonstrated Washington's bravery and initiative, as well as his inexperience and impetuosity. Upon his return to Virginia, Washington refused to accept a demotion to the rank of captain and resigned his commission. This expedition into the Ohio Country had international consequences. The French accused him of assassinating Jumonville; according to them, Jumonville had only been on a diplomatic mission to warn Washington about encroaching on French-claimed territory, bringing the incident and Washington's part in it to international attention. France and Great Britain were now set to fight for control of Ohio Country, both sending in troops in 1755, and war was formally declared in 1756.\n\nIn 1755, the British Crown sent General Edward Braddock and regulars to take Fort Duquesne. This was the largest British expedition to the colonies, intended to expel the French from the Ohio Country. Braddock offered Washington the position of aide on his staff, and he accepted, joining the Braddock Expedition. Washington recommended that Braddock split the army into two divisions, with a primary column and a second, more lightly equipped mobile offensive \"flying column\". During the march, Washington became severely ill and was left behind, but he was able to rejoin Braddock at Monongahela. The next day, the French and their Indian allies ambushed Braddock's divided forces, and Braddock was mortally wounded in the Battle of the Monongahela. The British suffered devastating casualties and retreated in panic, with two-thirds killed or wounded, but Washington rallied his forces in an organized retreat even though he was suffering from a fever and headache. He had two horses shot from under him, and his hat and coat were bullet-pierced. His conduct under fire redeemed his reputation among critics of his command in the Battle of Fort Necessity. Nonetheless, he was not included by the succeeding commander Colonel Thomas Dunbar in planning subsequent operations.\n\nOn August 14, 1755, Dinwiddie appointed Washington colonel and commander in chief of all of Virginia's colonial military forces, to protect Virginia's frontier from Indian attacks. Washington was 23, in charge of defending of frontier with only 300 men. Savage frontier battles took place, 20 battles in 10 months between Washington's Virginia Regiment and the Indians. Washington desired to wear the coveted red coat of officer rank, but this eluded him. He was convinced that Braddock would have recommended him for a regular commission in the British Army had he survived, so he appealed to Braddock's successor Lord Loudoun. Loudoun refused the request but did agree to transfer responsibility for Fort Cumberland from Virginia to Maryland. Washington's command increased to a thousand soldiers, while he emphasized discipline and training, and Virginia's frontier population suffered less than that of other colonies as a result of his strenuous efforts. Historian Joseph Ellis concludes that this \"was his only unqualified success\" during the French and Indian War.\n\nWashington continued to advocate the capture of Fort Duquesne, and the British crown sent Commanding General John Forbes, Colonel Thomas Gage, and British regulars to take the post in 1758. Washington was promoted to honorary Brigadier General and he and two regiments under his command were ordered to cooperate. During the Forbes Expedition, Washington suggested using an Indian-style warfare method, but was ignored. He was the only colonial officer among the British forces and was involved in only one battle during the campaign.\n\nForbes had devised a plan for an assault on Fort Duquesne and assigned Washington to lead one of three brigades. He was alerted to an enemy reconnaissance party in the area and sent Colonel George Mercer with a contingent of several hundred Virginians to investigate. Gunshots were heard in the distance, Washington's unit responded, and friendly fire was created when reinforcements arrived, each contingent thinking the other to be the French enemy; minor casualties resulted.\n\nForbes assembled 2,500 men in late November for the final assault on the fort, and promoted Washington to honorary brigadier general to head the operation. Washington and his army arrived on November 25 to find Fort Duquesne abandoned and burned by the French. The British had scored a strategic victory by gaining control of the Ohio Valley, but Washington retired from his Virginia Regiment commission in December 1758 and returned to Mount Vernon; the French and Indian War was concluded in 1763 by the Treaty of Paris. Washington never received the Royal commission he sought, but he acquired military, political, and leadership skills that proved invaluable during the American Revolution. Historians commonly ascribe his support of a strong national government and of a vigorous executive branch to his frustrations with officials in these and later interactions. He developed a distinct preference for regular troops over undisciplined militia, even though his command was limited during this war to smaller and more rural forces than during the Revolution to come.\n\nOn January 6, 1759, 27-year-old Washington married Martha Dandridge Custis, age 28, the wealthy widow of Daniel Parke Custis, in a ceremony at the Custis mansion. Martha was intelligent and gracious, and experienced in managing a planter's estate, and they effected an agreeable marriage. They raised John Parke Custis and Martha Parke (Patsy) Custis, her children from her previous marriage, and later raised their grandchildren Eleanor Parke Custis and George Washington Parke Custis. His 1751 bout with smallpox is thought to have rendered him sterile, but in any case they lamented they had no children together. They moved to Mount Vernon, near Alexandria, where he took up life as a successful planter of tobacco and wheat and emerged as a political figure.\n\nThe marriage gave Washington control over Martha's one-third dower interest in the Custis estate, worth about £40,000 in contemporary currency (or about $10 million in 2018), and he managed the remaining two-thirds on behalf of Martha's children. He thus became one of Virginia's wealthiest men and increased his social standing. He also acquired 84 slaves through the marriage, brought to Mount Vernon from the estate.\n\nDinwiddie had promised land bounties in 1754 to the soldiers and officers who volunteered during the French and Indian War; Washington prevailed upon Governor Lord Botetourt, and he fulfilled Dinwiddie's promise in 1769–70. In the fall of 1770, Washington inspected the lands, located in the Ohio and Great Kanawha regions, and in order to make a survey, obtained the appointment of William Crawford; Crawford allotted to Washington of the best acreage on the tract. Washington told the veterans that their land was hilly and unsuitable for farming, and agreed to purchase ; many veterans were happy with the sale, while others felt they had been duped. He also doubled the size of Mount Vernon to and increased its slave population to more than 100 by 1775.\n\nAs a respected military hero and landowner, he held local office and was elected to the Virginia provincial legislature, representing Frederick County in the House of Burgesses for seven years beginning in 1758. In the election that year, he plied the voters with of rice punch, beer, wine, hard cider, and brandy while he was away serving on the Forbes Expedition. He won election with roughly 40 percent of the vote, defeating three other candidates with the help of several local elites. He rarely spoke publicly in his early legislative career, but he became a prominent critic of Britain's taxation and mercantilist policies in the 1760s.\n\nWashington lived an aristocratic lifestyle, and his favorite activities included fox hunting, fishing, dances and parties, the theater, races, and cockfights. He also was known to play cards, backgammon, and billiards. Like most Virginia planters, he imported luxuries and other goods from England and paid for them by exporting his tobacco crop. By 1764, however, a poor tobacco market left him ₤1,800 in debt. He bolstered his solvency in the mid-1760s by diversifying, paying more attention to his finances, and reducing imported luxuries. He changed Mount Vernon's primary cash crop from tobacco to wheat, and further diversified operations to include flour milling, fishing, horse breeding, hog production, spinning, and weaving. In the 1790s, he erected a for whiskey production that yielded more than a month.\n\nWashington's step-daughter Patsy Custis suffered from epileptic attacks from age 12, and after five years she died in his arms in 1773. The following day, he wrote to Burwell Bassett: \"It is easier to conceive, than to describe, the distress of this Family...\" He canceled all business activity and was not away from Martha for a single night for the next three months. Half of Patsy's inheritance passed to him, and with it he was able to pay off his British creditors.\n\nWashington became a political figure and soon emerged as a leader among the social elite in Virginia. From 1768 to 1775, he invited some 2,000 guests to his Mount Vernon estate, mostly those whom he considered \"people of rank\". His advice regarding people who were not of high social status was to \"treat them civilly\" but \"keep them at a proper distance, for they will grow upon familiarity, in proportion as you sink in authority\". He became more politically active in 1769, presenting legislation in the Virginia Assembly to establish an embargo on goods from Great Britain.\n\nWashington's distrust of England began when he was passed over for a commission in the British Army in 1755, and he thereafter assumed a leading role in the American Revolution. He and other colonists were angered by a Royal Proclamation in 1763 banning American settlement west of the Allegheny Mountains, and protective of the British fur trade. He believed the Stamp Act of 1765 was an \"Act of Oppression\", and celebrated with fellow colonists after its appeal the following year. In March 1766, Parliament passed the Declaratory Act, which asserted that Parliamentary law held absolute sway over colonial law. Washington helped to lead the widespread colonial protests against the Townshend Acts passed by Parliament in 1767, and he introduced a proposal in May 1769 drafted by George Mason that called for Virginia to boycott English goods until the Acts were repealed. Parliament repealed them in 1770.\n\nParliament sought to punish the Boston Tea Party in 1774 with passage of the Intolerable Acts, which Washington referred to as \"an Invasion of our Rights and Privileges\". He said that Americans must not submit to acts of tyranny since \"custom and use shall make us as tame and abject slaves, as the blacks we rule over with such arbitrary sway\". That July, George Mason arrived at Mount Vernon with a list of resolutions, which he and Washington worked overnight to refine. The next day, they presented them to the Fairfax County committee, chaired by Washington, which adopted the Fairfax Resolves, calling in part for a Continental Congress. In August, he attended the First Virginia Convention where he was selected as a delegate to the First Continental Congress. Two years hence, on July 4, 1776, the Second Continental Congress signed the Declaration of Independence from Britain. Five days later, Patriots openly attacked symbols of monarchy—toppling an equestrian statue of King George III in New York City.\n\nThe Revolutionary War with Great Britain began April 19, 1775 at the Battles of Lexington and Concord, and with a Patriot siege of the British in Boston. The Second Continental Congress in Philadelphia officially assumed command of the troops in Boston on June 14 and created the Continental Army. Samuel Adams and John Adams passed over John Hancock to nominate Washington as commander in chief, and he was unanimously elected the next day.\n\nWashington appeared at the Congress, poised for war in a military uniform. He declined a salary in his acceptance speech but received reimbursement of expenses for which he fully accounted. The Congress chose capable officers to aid him, including Major General Artemas Ward, Adjutant General Horatio Gates, Major General Charles Lee, Major General Philip Schuyler, Major General Nathanael Greene, Colonel Henry Knox, and Colonel Alexander Hamilton. Washington was impressed by the enthusiasm of Colonel Benedict Arnold and gave him the responsibilities of invading Canada. He also engaged Brigadier General Daniel Morgan with whom he had served in the French and Indian War. Washington was also impressed with Henry Knox and his knowledge of ordinance, and upon Adams' urging, promoted him to colonel and appointed him chief of the Continental army artillery.\n\nAs the apprehensive Washington and party journeyed northward to Boston and the conflict awaiting him, he was greeted by various town officials, and received letters from statesmen and legislators addressing him as \"your excellency\"; Washington felt the title was too regal for a revolutionary leader. In the process, however, Washington was becoming an icon of the revolution. Historian Garry Wills noted, \"before there was a nation—before there was any symbol of that nation (a flag, a Constitution, a national seal)—there was Washington.\"\n\nOn July 2, 1775, Washington inspected the new army at Cambridge, Massachusetts, and was astonished to find a ragtag assembly of undisciplined, badly outfitted and unsheltered soldiers. Here he consulted with Benjamin Franklin who shared plans for managing the undisciplined men. Washington immediately initiated Franklin's reforms by drilling soldiers and imposing strict discipline, including fines, floggings, and incarceration. As ordered, his officer staff scrutinized military manuals and the individual skills of recruits, to ensure effective assignment of military duties. He removed cowardly or incompetent officers, and demanded respect for civilians. All of this, he told Congress, was a \"most necessary Work\". On August 23, King George III proclaimed that rebellious American colonists were traitors to the Crown.\n\nIn September 1775, Washington sent staff officer Benedict Arnold and 1,000 troops to Canada to aid General Richard Montgomery's siege of British-held Quebec and to secure the northern flank. Quebec was reinforced by 7,000 British troops and the American siege collapsed, forcing the Continental Army to make a hasty retreat. Later that month, an impatient Washington called a council of war, proposing an attack on the besieged British Army in Boston, but his generals, concerned about high casualties on an entrenched enemy, declined the ambitious plan, .\n\nBy mid January 1776, Washington's army had dropped to half-strength at 9,600 men due to expiring enlistments, despite the arrival of new recruits. The colonial militia who fought in the French and Indian War were summoned to fill in the gaps.The new British commander at Boston was General William Howe, but he did not attack during this time—which was probably fortunate for Washington and the burgeoning Continental Army.\n\nIn late 1775, Washington had sent staff officer Henry Knox to the recently captured Fort Ticonderoga for gunpowder and cannons. He transported them to Dorchester Heights in February where he was joined by Washington, who used them to drive the British out of Boston. General Howe immediately evacuated Boston with 10,000 troops and 1,100 Loyalists. Washington then marched his army to New York, initiated fortification, and correctly predicted that the British would return and attack in full force.\n\nHowe resupplied in Nova Scotia and headed for New York City with the British fleet, as it was considered the key to securing the continent. The British forces assembled in New York Bay, including more than 100 ships and thousands of troops. Howe's army landed unopposed on Staten Island on July 2, and British ships continued to arrive from England and Carolina for a siege of the city. Howe's troop strength totaled 32,000 well-trained soldiers, including 8,000 Hessians, while Washington's troop strength consisted of 23,000 soldiers, 19,000 of whom were raw recruits and militia. On August 22, Howe landed 20,000 troops at Gravesend, Brooklyn, and approached Washington's fortifications. Washington overruled his generals and chose to fight, based on false information that Howe's army had only 8,000 to 9,000 troops. Howe assaulted Washington's flank on August 27 and inflicted 1,500 Patriot casualties, while the British suffered 400 casualties. Washington and his generals decided to retreat, and Washington instructed General William Heath to make available every flat-bottomed riverboat and sloop in the area. General William Alexander held off the British army and covered the retreat, and the army safely crossed the East River under the cover of darkness to Manhattan Island without loss of life or material—although the British did capture General Alexander.\n\nHowe was emboldened by his victory at Long Island and sent a dispatch addressed to \"George Washington, Esq.\" attempting to negotiate peace. Washington declined the overture and demanded that he be addressed as a General and recognized as a fellow belligerent, not as a \"rebel\". He was concerned that his men would be hanged as rebels if they were captured, and he believed it his duty to insist that his men and the newly established United States be recognized with proper diplomatic protocol. The attempts at negotiation failed.\n\nThe British navy bombarded unstable earthworks built by the Patriots on lower Manhattan Island. Washington initially considered abandoning the island, including Fort Washington, but heeded the advice of Generals Greene and Israel Putnam to defend the fort. When they were unable to hold it, Washington abandoned it despite General Charles Lee's objections, and his army retired north to White Plains. Howe pursued, and Washington was forced to retreat across the Hudson River to Fort Lee to avoid encirclement. Howe took the offensive; he landed his troops on the island on November 16, surrounded and captured Fort Washington, and inflicted high casualties on the Americans. Washington was responsible for the decision to delay the retreat, but he also faulted the Congress and Nathanael Greene. Loyalists in New York considered Howe a liberator and spread a rumor that Washington had set fire to the city. The morale in the Patriot army was at its lowest ebb, as British Cornet Banastre Tarleton captured General Lee while he had taken a detour to visit his mistress Mary White.\n\nWashington's army, reduced to 5,400 troops, retreated through northeast New Jersey. Howe broke off pursuit on December 14, delayed his advance on Philadelphia, and set up winter quarters in New York. Washington crossed the Delaware River into Pennsylvania, where Lee's replacement John Sullivan and 2,000 troops joined him. The future of the Continental Army was in doubt for lack of supplies, a harsh winter, expiring enlistments, and desertions. Washington was disappointed to discover that many New Jersey residents were Loyalists or simply skeptical about the prospect of independence. Howe had split up his British Army and posted a Hessian garrison at Trenton, to hold western New Jersey and the east shore of the Delaware.\n\nWashington learned of a complacency within Howe's army and, believing the future of the country was riding on his shoulders, met with his generals on Christmas Eve and devised an intricate plan of surprise attack on the Hessian garrison at Trenton. Code named \"Victory or Death\", the campaign called for the army to make separate crossings of the Delaware in three divisions, one led by Washington (2,400 troops), another by General James Ewing (700), and the third by Colonel John Cadwalader (1,500), all reaching the Hessians at Trenton. Washington's force would then be split, with Washington taking the Pennington Road, and General Sullivan traveling south on the river's edge. Prior to the crossing, Washington ordered a 60-mile search for barges to transport his army, particularly Durham boats, and ordered the destruction of vessels that could be used by the British.\n\nAt sunset on Christmas Day, Washington crossed the Delaware, and at risk of being captured, staked out the river on the Jersey shore. The weather turned into heavy sleet and snow, and the river was obstructed by ice, but Washington's men crossed at McKonkey's Ferry, with 40 men per vessel. A northeaster wind churned up the waters, and Washington's men were exposed to pelting hail in their boats. The troops finally made it across, without losing a man, at 3:00 . Henry Knox, in charge of transporting artillery, was delayed, managing frightened horses and as many as 18 field guns on flat-bottomed ferries. Cadwalader and Ewing, however, failed to cross the Delaware due to the ice and heavy currents. Washington waited in despair while Knox and the rest of the Army crossed the river, and feared he might have to abandon his attack on Trenton; by 3:00 , Knox and his artillery regiments finally made it and by 4:00 Washington began marching towards Trenton. Rather than return his army to Pennsylvania and risk being spotted, Washington chose to take his troops alone against the Hessians.\n\nWhen scouts reported Hessian forward positions a mile from Trenton, Washington split his force into two columns and rode about, giving words of encouragement to his men: \"Soldiers keep by your officers. For God's sake, keep by your officers.\"Stopping briefly for a council of war with his officers the two columns then separated at the Birmingham crossroads, with General Nathanael Greene's force, led by Washington, taking the upper Ferry Road, while General John Sullivan's advanced on River Road. (.) Veiled by sleet and snow the Americans advanced on Trenton. Many of the soldiers were shoeless, with bloodied feet, and two died of exposure. At sunrise, they made a coordinated and surprise attack on the Hessians. Washington personally led the charge, aided by Major General Henry Knox and his artillery. Hessian Colonel Johann Rall was mortally wounded during the short battle.\n\nEnemy casualties included 22 killed, 83 wounded, with 850 captured with large amounts of supply. After retreating back across the Delaware to Pennsylvania,{sfn|Fischer|2004|p=254}} Washington returned to New Jersey on January 3, launching an attack on British regulars at Princeton, with only 40 Americans killed or wounded while the British forces suffered 273 killed or captured. American Generals Hugh Mercer and John Cadwalader were already present and being driven back by the British when Mercer was mortally wounded. Washington arrived at the scene and rallied the men by leading them in a counterattack which advanced to within 30 yards (25 m) of the British line.\n\nThe remaining British troops retreated after a brief stand, while others took refuge in Nassau Hall. Colonel Alexander Hamilton brought three cannons and began firing at the building where the British were holed up. Washington's troops charged, and in less than an hour the British put out the white flag of ceasefire; 194 soldiers walked out of the building and laid down their arms. Howe retreated to New York City where his army remained inactive until Spring. Washington's depleted Continental Army took up winter headquarters in Morristown, New Jersey, allowing them to disrupt British supply lines and drive the British from parts of New Jersey. Washington later admitted that the British could easily have defeated his thinly guarded encampment if they had counter-attacked before his troops were dug in.\n\nThe British still controlled New York, and after the winter campaign, many Patriot soldiers did not reenlist, or had deserted during the harsh winter. Washington and Congress reacted with increased rewards for re-enlisting and punishments for desertion, in an effort to effect greater troop numbers. Strategically, Washington's victories were pivotal for the Revolution and quashed the British strategy of showing overwhelming force followed by offering generous terms. In February 1777 word of Washington's victories at Trenton and Princeton reached London, and brought with it the realization that the Patriots were in a position to demand unconditional independence.\n\nIn February 1777, while encamped at Morristown, New Jersey, Washington determined smallpox inoculation could prevent deaths from the disease, and employed it for the army to great effect. That summer, British General John Burgoyne led a major invasion army south from Quebec, through Lake Champlain and recaptured Fort Ticonderoga with the ultimate objective of dividing New England by taking control of the Hudson River further south. But General Howe, then in British-occupied New York, blundered strategically, taking his army south to Philadelphia rather than up the Hudson River to join Burgoyne near Albany. Meanwhile, Washington, with Lafayette at his side, rushed to Philadelphia to engage Howe, where he was shocked to learn of Burgoyne's progress in upstate New York, where the Patriots were led by General Philip Schuyler and his successor Horatio Gates. Washington's army of less experienced men were defeated in the pitched battles at Philadelphia.\n\nHowe outmaneuvered Washington at the Battle of Brandywine on September 11, 1777, and marched unopposed into America'a capital, Philadelphia. The Patriots failed in an attempted attack on the British garrison at Germantown in early October. Because of the losses incurred at Philadelphia Major General Thomas Conway prompted some members of Congress, referred to as the Conway Cabal, to consider removing Washington from command. Washington's supporters rallied behind him, and after much deliberation the matter was eventually dropped. Exposed for his complicity and correspondence to Congress over matters, Conway later wrote an apology to Washington, but he never paid Conway any response. Conway resigned and returned to France.\n\nMeanwhile, Washington's strategy improved the situation for Gates's army during the Saratoga campaign to the north. He was most concerned about the movements of General Howe and was aware that Burgoyne was also moving south toward Saratoga from Quebec. Washington took some risks in July, sending reinforcements north commanded by Major General Benedict Arnold, his most aggressive field commander, and Major General Benjamin Lincoln. Burgoyne made two attempts to take Bemis Heights, but found himself trapped and beyond the reach of help from Howe. He was forced to retreat to Saratoga and ultimately surrendered after the Battles of Saratoga, leading to Howe's resignation in May 1778. Washington was concerned that Gates's victory was going to give impetus to his critics. 20th-century biographer John Alden maintains, \"It was inevitable that the defeats of Washington's forces and the concurrent victory of the forces in upper New York should be compared.\" The zealous admiration for Washington was waning; John Adams, for one, then gave him little credit. \n\nThis was a major turning point both militarily and diplomatically; the French responded to Burgoyne's defeat by entering the war, allying with America and expanding the Revolutionary War into more than a domestic affair.\n\nWashington's army of 11,000 went into winter quarters at Valley Forge north of Philadelphia in December 1777. They suffered a multitude of deaths in the extreme cold over the next six months, mostly from disease, exacerbated by the lack of food, clothing, and shelter; scholars believe 2,000–3,000 men or more were lost. The British, by contrast, were comfortably quartered in Philadelphia, and paying for supplies in pounds sterling, while Washington struggled with procurement using devalued American paper currency. The woodlands were soon exhausted of game, and by February Washington was burdened with sustaining morale and stemming desertion .\n\nWashington had repeatedly petitioned the Continental Congress for badly needed provisions without success. Finally, five Congressmen came to Valley Forge on January 24, 1778, to check the conditions of the Continental Army. Washington expressed the urgency of the situation, proclaiming: \"Something must be done. Important alterations must be made.\" He also recommended that Congress take control of the Army supply system, pay for supplies, and hasten them to the troops. In response to his urging, Congress agreed to fund the army's supply lines and reorganized the commissary department that gathered the supplies for the Army. By late February, there were adequate supplies arriving at the camp.\n\nWashington recruited men into the Regular Army and assigned their training to Baron Friedrich Wilhelm von Steuben, whose incessant drilling soon transformed them into a disciplined fighting force. Washington's army, which many feared would dissolve over the harsh winter, endured, emerging from Valley Forge the following spring as a revitalized fighting force. Washington promoted Von Steuben to Major General for his effort and became Washington's chief of staff for the rest of the war.\n\nIn May 1778, the Continental Congress ratified the Treaty of Alliance with King Louis XVI of France, which allied the French army and navy with America. The British evacuated Philadelphia for New York in June 1778, and Washington summoned a council of war with Generals Lee, Greene, Wayne, and Gilbert du Motier, the Marquis de Lafayette. He chose a partial attack on the retreating British at the Battle of Monmouth; the British were commanded by Howe's successor, General Henry Clinton. Lee and Lafayette moved with 4,000 men, but without Washington's knowledge, and bungled their first attack on June 28. Washington relieved Lee and continued fighting, essentially to a draw, in one of the war's most expansive battles. At nightfall, the British continued their retreat to New York, and Washington moved his army outside the city. Monmouth was the last major battle that Washington fought in the North; he deemed it more important to protect his army than to keep the British from occupying towns, which rarely had anything to offer the British army.\n\nIn late 1778, General Clinton sent 3,000 troops by ship from New York to Georgia and launched a Southern invasion. He seized Savannah, reinforced by 2,000 British and Loyalist troops, and repelled an attack by Patriots and French naval forces, which bolstered the British war effort. Clinton assembled 12,500 troops and attacked Charlestown (modern Charleston) in January 1780, defeating General Benjamin Lincoln, who only had 5,100 Continental troops. The British went on to occupy the South Carolina Piedmont in June, with almost no Patriot resistance. Clinton returned to New York and left 8,000 troops commanded by Lord Charles Cornwallis. Congress replaced Lincoln with Horatio Gates, despite Washington's recommendation of Nathanael Greene. Gates failed in South Carolina and was replaced by Greene, and the British had the South in their grasp. Despite the bleak situation, Washington was encouraged when he learned in mid 1780 that the Marquis de Lafayette had returned from France with more ships, men, and supplies.\n\nIn the summer of 1779, Washington and Congress decided to strike the Iroquois warriors of the Six Nations in a campaign to force Britain's Indian allies out of New York, which they had used as a base to attack American settlements around New England. The Indian warriors joined with Tory rangers led by Walter Butler and slew more than 200 frontiersmen in June, using barbarities normally shunned, and laid waste to the Wyoming Valley in Pennsylvania. Prompted by massacres and many attacks on American civilians, Washington ordered General John Sullivan to lead a military operation in August and to effect \"the total destruction and devastation\" of all Iroquois villages and take their women and children hostage. Those who managed to escape fled to British protection in Canada. When Sullivan later reported that the expedition had been accomplished, he referred to the Iroquois as \"inhuman barbarians\".\n\nWashington went into quarters at Morristown, New Jersey during the harsh winter of 1779 and 1780, which subjected the troops to some of their worst suffering during the war, with temperatures well below freezing. New York Harbor was frozen over, and snow and ice covered the ground for weeks. As at Valley Forge, the troops again lacked provisions for a time.\n\nWashington has been called \"America's first spymaster\", for having arduously developed a successful espionage system to detect British military locations and plans. In 1778, he ordered Major Benjamin Tallmadge to form the Culper Ring, tasked with covertly collecting information about the British in New York. General Washington, ever vigilant to spies, had disregarded prior incidents of disloyalty by Benedict Arnold, an admired and trusted officer of Washington's who had otherwise distinguished himself in many battles.\n\nDuring the summer of 1780, Arnold began a plot of treason, supplying British spymaster John André with sensitive information intended to compromise Washington and capture West Point, a key American defensive position on the Hudson River. Arnold repeatedly asked for command of West Point, and Washington finally agreed in August. Arnold met André on September 21, giving him plans to take over the garrison. Several factors combined to motivate Arnold: He received a £6,000 British payment (\"Real Price: £757,000.00 Year: 2017\"); he was angry at losing promotions to junior officers and at repeated slights from Congress; he was profiteering from the war and faced a court-martial for it; and he was deeply in debt.\n\nMilitia forces captured André and discovered the plans; with only minutes to spare, he escaped on horseback and fled to New York. Washington was outraged, and immediately recalled the commanders positioned under Arnold at key points around the fort to prevent this complicity. He did not, however, then suspect Arnold's wife Peggy Shippen. Washington assumed personal command of West Point and worked diligently to reorganize the order of command and strengthen defensive positions.\n\nAndré's military trial for espionage ended in a death sentence, and Washington offered to return him to the British in exchange for Arnold, but Clinton refused. André requested execution by firing squad rather than hanging; Washington was tempted to grant his request but resisted, under pressure to better deter other spies, and André was hanged on October 2, 1780.\n\nWashington's army went into winter quarters at New Windsor, New York, in 1780, where they again suffered from extreme cold and lack of supplies, prompting Washington to prevail upon Congress and state officials to come to their aid with provisions. He sympathized with his soldiers' suffering, saying he hoped the army would not \"continue to struggle under the same difficulties they have hitherto endured\".\n\nIn July 1780, 5,000 veteran French troops led by Jean-Baptiste de Vimeur, the Comte de Rochambeau, arrived at New Port, Rhode Island. French naval forces then landed, led by Admiral François-Joseph de Grasse, and Washington encouraged Rochambeau to move his fleet south to launch a joint land–naval attack on Arnold's troops.\n\nArnold was now a Brigadier General in the British Army, and General Clinton sent him to Virginia with about 1,700 troops to capture Portsmouth and spread terror throughout the state; Washington responded by sending Lafayette south with a small army to counter Arnold's efforts. At first, Washington hoped to bring the allied fight to New York, drawing off British forces from Virginia and ending the war there, but Rochambeau advised the Comte de Grasse that Cornwallis in Virginia was the better target. De Grasse followed this advice and arrived with his fleet off the Virginia coast. Washington immediately saw the advantage, and made a feint towards Clinton in New York before heading south to Virginia.\n\nWashington's Continental Army delivered the last blow in 1781 after the French won a naval victory in the Battle of the Chesapeake, allowing Patriot forces to trap the British army in Virginia without reinforcement by Clinton from the North. The surrender at Yorktown on October 19, 1781, marked the end of major fighting. Washington took great satisfaction in the surrender but kept his taciturn composure. Cornwallis, claiming illness, failed to appear at the official ceremony of surrender, sending General Charles O'Hara as his proxy; Washington had General Benjamin Lincoln accept the surrender.\n\nDecisive combat ended and British troops began to demobilize in the months after Yorktown, while peace negotiations started. The British evacuated 2,000 troops from Savannah in July 1782 and 4,000 from Charlestown in December. They removed 18,000 troops from New York throughout the spring, summer, and fall of 1783; the French army and navy likewise departed. Unfortunately, the American treasury was then empty, and unpaid soldiers were restive to the point of mutiny, forcing an adjournment of the Congress. Washington dispelled unrest among officers by suppressing the Newburgh Conspiracy in March 1783, and Congress promised officers a five-year bonus. Washington later submitted an account of about $450,000 in military expenses he advanced to the army (equivalent to approximately $10 million in 2018). The account was settled, though allegedly vague about large sums, and included his wife Martha's expenses incurred through visitations to his headquarters, as well as his agreed compensation.\n\nWashington resigned his commission as Commander in Chief of the Continental Army following the signing of the Treaty of Paris, and made immediate plans to retire to his home at Mount Vernon. With the peace treaty initially ratified in April 1783, a Congressional committee under Hamilton worked to adapt the army for peacetime; on May 2. However, Washington didn't find out about the treaty until November 1, two months later. Washington gave the Army's perspective to the Committee in his \"Sentiments on a Peace Establishment\"; the Committee's proposals were defeated by Congressional votes later that month, again in October, and also in April, 1784. The Treaty was signed on September 3, 1783, and Great Britain officially recognized the independence of the United States. Washington disbanded his army, giving an eloquent farewell address to his soldiers on November 2. On November 25, the British evacuated New York City, and Washington and Governor George Clinton took possession. Only a few trusted delegates of the Continental Congress, including Thomas Jefferson, knew of Washington's decision to resign his commission as commander-in-chief of the Continental Army.\n\nWashington bade farewell to his officers at Fraunces Tavern on December 4, 1783, and resigned his commission on December 23, after leading the Continental Army for eight and a half years. Washington arrived at the Maryland State House wearing his military uniform for the last time, and was greeted by Charles Thomson, secretary of the Congress, who led him to his seat in the Senate Chamber. He gave a brief statement to the Continental Congress: \"I consider it an indispensable duty to close this last solemn act of my official life, by commending the interests of our dearest country to the protection of Almighty God, and those who have the superintendence of them, to his holy keeping.\" Praised by Thomas Jefferson for relinquishing power, Washington had refuted claims made by Loyalists that he would retain his position as Commander in Chief and rule as a dictator. Henry Knox also gave tribute to Washington and likened him to the Roman consul Lucius Quintus Cincinnatus, who had also relinquished his military power after securing victory in ancient Rome. Knox had formed the Society of the Cincinnati (\"Cincinnati\" being the plural of \"Cincinnatus\") in 1783 with this connection in mind, and Washington served as its first president until his death. Modern historian Gordon S. Wood concludes that \"the greatest act of his life, the one that gave him his greatest fame, was his resignation as commander-in-chief of the American forces.\"\n\nWashington advised Congress at Rocky Hill, New Jersey, in August 1783 to keep a standing army, create a \"national militia\" formed of separate state units, and establish a navy and a national military academy. He circulated his \"Farewell\" orders that discharged his troops, whom he called \"one patriotic band of brothers\". Before his return to Mount Vernon, he oversaw the evacuation of British forces in New York and was greeted by parades and celebrations, where he announced that Knox had been newly promoted commander-in-chief of the Continental Army.\n\nAfter his retirement and return to Mount Vernon, in 1784 Washington, then 52, made an exploratory trip to the western frontier. He also inspected the land holdings he had earned decades earlier for his service in the French and Indian War. He also facilitated the creation of the Potomac Company, a public–private partnership that financed a project to improve the navigability of the Potomac River and to construct a canal linking the Potomac to the Ohio River. He was elected president of the company, for which he proselytized extensively. The project served as a model for large-scale canal building, but technical and financial challenges rendered it unprofitable, and the Potomac–Ohio Canal was not completed.\n\nAfter the war, Washington did not wish to involve himself in the political matters of the nation. James Madison, however, valued his influence and urged him to attend the Constitutional Convention. Shay's rebellion broke out in Massachusetts and Washington was finally convinced that he could no longer ignore political matters and the looming unrest that threatened the stability of the Union. He appeared at the convention as a delegate from Virginia and was unanimously elected its president in 1787. He was critical of the Articles of Confederation for the weak central government it established, referring to them as no more than \"a rope of sand\" to unite the new nation. His view for the need of a strong federal government developed from his early years of frustration with British officials and his experience at Valley Forge when the Continental Congress failed to supply the military. The general populace, however, did not share his inclination for a strong federal government binding the states together, fearing that it would become as overbearing as the British Parliament from which they had just freed themselves.\n\nWashington was reserved during the debates and voting, lending his prestige to the goodwill and work of the other delegates. After a couple of months, he wrote to Alexander Hamilton, expressing his anxiety that he was the only one holding the union of delegates together: \"I almost despair of seeing a favorable issue to the proceedings of our convention and do therefore repent having had any agency in the business.\" Following the Convention, however, his support convinced many to vote for ratification of the Constitution. He unsuccessfully lobbied anti-federalist Patrick Henry, saying that \"the adoption of it under the present circumstances of the Union is in my opinion desirable\", and he declared that the only alternative would be anarchy. Even so, he did not consider it proper to cast his vote in favor of adoption on behalf of Virginia as the state's representative, since he was expected to be nominated President if it was ratified. Washington and Madison then retired to Mount Vernon for four days and evaluated the transition of the new constitutional government.\n\nThe delegates to the Constitutional Convention designed the presidency with Washington in mind, allowing him to define the office once elected. He thought that the achievements were monumental when they were finally completed. \n\nThe state electors under the Constitution voted for the President on February 4, 1789. Washington suspected that most republicans had not voted for him. The March 4 date mandated by the Constitution passed by without a Congressional quorum to count the votes, and Congress waited anxiously for other members to arrive to determine who won the election. A quorum was finally reached on April 5, and Congress counted the votes on April 6. Congressional Secretary Charles Thomson was sent to Mount Vernon to tell Washington that he had been elected the first President of the United States. Washington won the majority of every state's electoral votes, while John Adams received the next highest vote total and was elected Vice President—originally a post given to the candidate with the second-highest portion of the vote. Washington had \"anxious and painful sensations\" over leaving the \"domestic felicity\" of Mount Vernon, but he departed Mount Vernon for New York City on April 23 to be inaugurated.\n\nWashington was unanimously elected president by the electoral college on February 4, 1789 and was inaugurated on April 30, 1789, at the age of 57, taking the first presidential oath of office at Federal Hall in New York City. He arrived in a coach led by militia and a marching band, followed by statesmen and foreign dignitaries in the first inaugural parade; an estimated 10,000 people attended. He stood with his hand on a Bible that was provided by the nearby Masonic lodge while the oath was administered by Chancellor Robert R. Livingston, after which he was given a 13-gun salute. He then returned to the Senate Chambers where he read a 1,200-word speech (in contrast to his later second inaugural speech), asking that \"that Almighty Being who rules over the universe, who presides in the councils of nations—and whose providential aids can supply every human defect\" would \"consecrate the liberties and happiness of the people of the United States\" with his blessing. He declined a salary in his speech, but Congress later set an annual salary of $25,000 (equivalent to about $715,000 in 2018), and he accepted the amount to defray costs of the presidency.\n\nWashington was aware that he would set a precedent with everything that he said and did, and he attended carefully to the pomp and ceremony of office, making sure that the titles and trappings were suitably republican and did not emulate European royal courts. To that end, he preferred the title \"Mr. President\" over more majestic names proposed by the Senate, including \"His Excellency\" and \"His Highness the President\". His precedents also included messages to Congress and the cabinet form of the executive branch.\n\nWashington had planned to resign after his first term, but the unstable nation with its existing political strife convinced him that he should remain in office. He was an able administrator and judge of talent and character and established many precedents; he talked regularly with department heads and listened to their advice before making a final decision. He established a toleration of opposing views, despite fears that a democratic system would lead to political violence, and he conducted a smooth transition of power to his successor. Washington officially remained non-partisan throughout his presidency and opposed the divisiveness of political parties in the new and unstable Union, but he favored a strong central government, was largely sympathetic to a Federalist form of government, and was leery of the Republican opposition.\n\nDuring his first term in office, Washington had to contend with major problems. The old Confederation had lacked the powers to handle its workload. It had weak leadership, no executive, a small bureaucracy of clerks, a large debt, worthless paper money, and no power to establish taxes. The United States was not completely unified, and Washington had the task of assembling an executive department; he relied on Tobias Lear for advice selecting its officers. Great Britain also refused to relinquish its forts in the American West, while Barbary pirates were preying on American merchant ships in the Mediterranean at a time when the United States' Army was minuscule, and the Navy had not yet been established.\n\nCongress created executive departments during Washington's first months in office in 1789, including the State Department on July 27, the Department of War in early August, and the Treasury Department on September 2. The President also received two additional officers without departments: the Attorney General and Postmaster General. Washington appointed Richmond lawyer Edmund Randolph as Attorney General and Samuel Osgood as Postmaster General. He also appointed fellow Virginian Thomas Jefferson to be Secretary of State and Henry Knox, who had succeeded Washington as commander-in-chief of the Continental Army, as Secretary of War. Finally, he appointed Alexander Hamilton as Secretary of the Treasury. Washington's cabinet eventually developed into a consulting and advisory body, although this was not mandated by the Constitution.\n\nWashington's cabinet members were known for their dissension, forming rival parties with sharply opposing views, most fiercely illustrated between Hamilton and Jefferson. Washington restricted cabinet discussions to topics of his choosing, without participating in debate. He occasionally requested cabinet opinions in writing, and expected department heads to carry out his decisions without complaint. Hamilton played an active role advising Congress, providing written reports and using his influence with congressional committee leaders.\n\nWashington was not aligned with a political party and opposed their formation, suspecting that conflict would undermine republicanism. His closest advisors formed two factions, however, portending the First Party System. Secretary of the Treasury Alexander Hamilton planned to establish the national credit and build a financially powerful nation; he employed these objectives as planks for the Federalist Party. Secretary of State Thomas Jefferson strongly disapproved of Hamilton's agenda, and founded the Jeffersonian Republicans to take up the opposition. Washington favored Hamilton's agenda, which went into effect and became law, though Hamilton's fiscal recommendations created bitter controversy during Washington's presidency.\n\nWashington signed a proclamation on October 3, 1789, designating November 26 as a day of Thanksgiving, in order to encourage national unity (Thanksgiving was not established as an annual holiday until 1863.) Washington said, \"It is the duty of all nations to acknowledge the providence of Almighty God, to obey His will, to be grateful for His benefits, and humbly to implore His protection and favor.\" On his appointed Thanksgiving Day, he fasted while visiting debtors in prison, but provided them with food and beer.\n\nThe establishment of public credit became a primary task of the new federal government; Hamilton submitted a report of the matter to Congress on January 14, 1790. Madison, Hamilton, and Jefferson then reached the Compromise of 1790 in which Jefferson agreed to Hamilton's debt proposals in exchange for moving the nation's capitol to the south near Georgetown on the Potomac River, while Philadelphia was designated the nation's temporary capitol city. This settled a deadlock in Congress, and the terms were legislated in the Funding Act and the Residence Act, both of which Washington signed into law on August 4. Congress authorized the assumption and payment of the nation's debts; funding was provided with customs duties and excise taxes.\n\nHamilton created more controversy among Washington's Cabinet members when he advocated the establishment of the First Bank of the United States. Madison and Jefferson objected, but the bank easily passed Congress. When Washington sought advice from his cabinet, Jefferson and Randolph believed strongly that the new bank was beyond the authority granted by the constitution. Hamilton thought the bank was within the government's enumerated powers in the constitution. Washington sided with Hamilton and signed the legislation on February 25; however, the rift widened between Hamilton and Jefferson and they became openly hostile.\n\nThe young nation experienced its first financial crisis in March 1792. Hamilton's Federalists exploited large loans to gain control of U.S. debt securities, causing a run on the new national bank, though the markets returned to normal by mid April. Jefferson believed that Hamilton was part of the scheme, in spite of the latter's efforts to ameliorate, and Washington found himself in the middle of a feud.\n\nJefferson and Hamilton adopted diametrically opposed political principles. Hamilton believed in a strong national government requiring a national bank and foreign loans to function, while Jefferson believed the government should be primarily directed by the states and the farm element; he also resented the idea of banks and foreign loans. These differences caused continued disputes and infighting between the two men, much to Washington's dismay. In 1791, Jefferson and Congressman James Madison encouraged revolutionary poet Philip Freneau to form the \"National Gazette\", to counter the pro-Hamilton press. A few weeks later, when Hamilton demanded that Jefferson resign if he could not support Washington, rather than respond publicly, Jefferson told Washington that Hamilton's fiscal system would lead to the overthrow of the Republic.\n\nWashington pleaded with his two secretaries to stop the open attacks for the sake of the nation, but they both respectfully ignored him. Washington reversed his decision to retire after his first term, as an essential measure in minimizing party strife—the feud continued after his re-election. Jefferson's political actions, his support of Freneau's \"National Gazette\", and his attempt to undermine Hamilton nearly led Washington to dismiss him from the cabinet; Jefferson ultimately resigned his position in December 1793 and was thereafter forsaken by Washington.\n\nThe feud between Hamilton and Jefferson led to the well-defined Federalist and Republican parties, and party affiliation had become necessary for election to Congress by 1794. Washington remained aloof from congressional attacks on Hamilton, but he did not write a public statement to protect him. The Hamilton–Reynolds sex scandal opened Hamilton to public disgrace, but Washington continued to hold him in \"very high esteem\" and viewed him as the dominant force in establishing federal law and government.\n\nIn March 1791, Congress imposed an excise tax on distilled spirits to help pay the national debt; grain farmers strongly protested in frontier districts, especially the westernmost counties of Pennsylvania, saying that they were unrepresented and unfairly shouldering too much of the debt and compared their situation to the unfair British taxation during the former revolution. Washington, after making numerous appeals, issued a final proclamation on September 25, threatening the use of military force, and reminded the protestors that, unlike the rule of the British crown, the Federal law was the result of the consensus of state elected representatives. Threats and violence against tax collectors escalated into full-scale defiance of federal authority in 1794 giving rise to the Whiskey Rebellion. The federal army was too small for the task, so Washington invoked the Militia Act of 1792 to summon militias from Pennsylvania, Virginia, Maryland, and New Jersey. Governors sent the troops, with Washington taking initial command. He subsequently named Light-Horse Harry Lee as field commander to lead the troops into the rebellious districts. The rebels dispersed, and there was no fighting. Washington, at 62, became the first and only U.S. president to command troops in a combat situation.\n\nWashington's forceful action demonstrated that the new government could protect itself and its tax collectors. This represented the first instance of the federal government using military force to exert authority over the states and citizens and remains the only time a sitting president has commanded troops in the field. Washington justified his action against \"certain self-created societies\" whom he regarded as \"subversive organizations\" that threatened the national union. He did not dispute their right to protest, but insisted that their dissent not flagrantly violate federal law. Congress overwhelmingly agreed and extended their congratulations to him, with only Madison and Jefferson expressing their indifference.\n\nIn April 1792, the French Revolutionary Wars began between Great Britain and France, and Washington, with the cabinet's assent, declared America's neutrality. The revolutionary government of France sent diplomat Citizen Genêt to America. He was welcomed with great enthusiasm and began promoting the case for France, using a network of new Democratic-Republican Societies in major cities. He even issued French letters of marque and reprisal to French ships manned by American sailors so that they could capture British merchant ships. Washington denounced the societies and demanded that the French recall Genêt.\n\nHamilton formulated the Jay Treaty, to normalize trade relations with Great Britain while removing them from western forts, and also to resolve financial debts remaining from the Revolution. Chief Justice John Jay, acting as negotiator, signed the treaty on November 19, 1794, while adamantly critical Jeffersonians supported France. Washington listened to both sides, then announced his support for the treaty, mostly because it avoided war with Britain; yet he was deeply disappointed that its provisions overwhelmingly favored Great Britain. After he mobilized public opinion and secured ratification in the Senate, Washington was subjected to the most severe and frequent public criticism of his life.\n\nThe British agreed to depart from their forts around the Great Lakes, and the United States–Canada boundary was subsequently modified. Numerous pre-Revolutionary debts were liquidated, and the British opened their West Indies colonies to American trade. Most importantly, the treaty secured peace with Britain and brought a decade of prosperous trade. Jefferson claimed that it angered France and \"invited rather than avoided\" war. Relations with France deteriorated after the Jay Treaty was signed, leaving subsequent president John Adams with the prospect of war. When James Monroe, American Minister to France, was recalled by Washington for his opposition to the Jay Treaty, the French refused to accept his replacement, Charles Cotesworth Pinckney. Two days before Washington's term ended, the French Directory declared the authority to seize American ships. \n\nWashington's initial and most pressing problem had been the British occupation of forts in the northwestern frontier and their concerted efforts to turn Indians against American settlers, which posed an urgent national security risk. The Northwest Indians allied with the British and formed a confederation under Miami chief Little Turtle to resist American expansion, and from 1783 to 1790 an estimated 1,500 settlers were killed in isolated Indian attacks.\n\nWashington made Indian policy a priority from the start of his administration in 1789, determined that Indian affairs would be \"directed entirely by the great principles of Justice and humanity\". Rather than force Indians to relinquish their lands east of the Mississippi, as Congress demanded, his administration allowed them to be represented by treaties. Washington and his administration regarded powerful tribes as foreign nations, and Washington even smoked a peace pipe and drank wine with them at the Philadelphia presidential house.\n\nWashington made numerous attempts to conciliate the Indians; he equated the killing of Indians with that of Whites, and pursued a policy to protect their property and integrate Indians into American culture. Secretary of War Henry Knox offered farm tools and livestock to the northwest Indians to encourage an agricultural lifestyle among the tribes, but the Indian chiefs rejected the peace offerings.\nIn the Southwest, negotiations failed between federal commissioners and Indian tribes, then raiding American settlements in response to crimes committed by settlers in their northeastern territory. Washington, with Knox's initiative, invited Creek Chief Alexander McGillivray and twenty-four leading chiefs to New York, so they could negotiate a treaty with McGillivray directly; he was treated as a foreign dignitary and presented with gifts. On August 7, 1790 in Federal Hall, Knox and McGillivray concluded the \"Treaty of New York\", which provided the tribes with supplies and tools for agriculture. McGillivray was made a Brigadier General in the U.S. Army and paid an annual salary of $1,500.\n\nIn 1790, Washington sent Brigadier General Josiah Harmar to pacify the Northwest Indians; Harmar was twice routed by Little Turtle and forced to withdraw. The Western Confederacy of tribes used guerrilla tactics and was an effective force against the sparsely manned American Army, composed mostly of undisciplined militia accompanied by family. Washington sent Major General Arthur St. Clair from Fort Washington on an expedition to restore peace in the territory in 1791, with the encouragement of Washington's Secretary of War Henry Knox, who disliked militias. On November 4, St. Clair's forces were ambushed and soundly defeated with few survivors, despite Washington's warning of surprise attacks. Washington was outraged over the Indians' brutality and execution of captives, including women and children. Knox and others prompted him to form a new army, the Legion of the United States, that did not rely on state militias.\n\nSt. Clair resigned his commission, and Washington replaced him with Revolutionary War hero General Anthony Wayne. From 1792 to 1793, Wayne instructed his troops on Indian warfare tactics and instilled discipline lacking under St. Clair. In August 1794, Washington sent Wayne into the troubled Indian territory with \nauthority to drive them out by burning their villages and crops in the Maumee Valley. On August 24, the American army under Wayne's leadership defeated the western confederacy at the Battle of Fallen Timbers. In August 1795, two-thirds of the Ohio Country was opened up for American settlement under the Treaty of Greenville.\n\nWashington remained popular approaching the election of 1792, and Hamilton urged him to run for a second term. He said nothing about this upon his return to Mount Vernon in October 1792, and many took his silence as assent, viewing him as the only viable candidate during the unstable time. The Electoral College unanimously elected him President on February 13, 1793, for a second term. John Adams was re-elected Vice President by a vote of 77 to 50.\n\nWashington was criticized by the \"National Gazette\" and political adversaries over his birthday celebration and for giving a \"monarchist\" impression; as a consequence, he kept a low profile, arriving alone at his inauguration in a simple carriage. The inauguration was held in the Senate Chamber of Congress Hall in Philadelphia on Monday, March 4, 1793, and the presidential oath of office was administered by Associate Justice William Cushing. This was the first inauguration to take place in Philadelphia, the nation's temporary capital. Washington maintained his low profile after the ceremonies and delivered the shortest inaugural address on record, at just 135 words, in four sentences.\n\nDuring Washington's second term partisan politics for the first time emerged in his cabinet, with Jefferson and Hamilton agreeing only on one thing, that Washington remain in office for a second term. Differences of opinion centered around America's involvement in the French Revolution, with Washington remaining neutral, and over a national bank at the disposal of the federal government, which he strongly supported. This was known as the Federalist Era.\nIn the final months of his presidency, Washington was relentlessly assailed by his political foes and a partisan press who accused him of being ambitious and greedy. He pointed out that he had taken no salary during the entire war and risked his life in numerous battles; he regarded the press as an erosive and disuniting force that spread numerous falsehoods, referring to them as \"diabolical\". This also had a great influence in his Farewell Address, which expressed how troubled he was by the years of infighting and character assassination by much of the press.\n\nIn 1793, Washington signed the Fugitive Slave Act, which allowed slave owners to cross state lines and retrieve runaway slaves. He also signed into law the Slave Trade Act of 1794, which limited American involvement in the Atlantic slave trade. In 1794, Washington signed into the law the Naval Act that created the United States Navy, to combat Barbary pirates in advance of the Barbary Wars. Washington appointed Oliver Wolcott, Jr., as Secretary of the Treasury in 1795, replacing Alexander Hamilton, who resigned in the aftermath of the Whiskey Rebellion to spend time with his wife Elizabeth. The upshot of the Rebellion strengthened Washington's bond with Hamilton, while distancing him from Knox who resigned.\n\nAt the end of his second term in 1797, Washington retired for personal and political reasons, fatigued and disgusted with the virulent attacks on his integrity, and believing that only without him could America realize a truly contested presidential election. He also speculated that a third term might end in his death, with his vice president succeeding him without a contest. He did not personally feel bound to a two-term limit, but in relinquishing power he again set precedent. The practice of a two-term limit to the presidency was finally formalized with the 1951 adoption of the Twenty-second Amendment to the United States Constitution. Washington is often credited with setting the principal of a two-term presidency; however, it was Thomas Jefferson who first refused to run for a third term on political grounds. Term limits were not unheard of: About half of the states provided term limits for governors in the 1780s.\n\nWashington planned to retire after his first term as President, and in 1792 he had James Madison draft a farewell message with a given sentiment and theme; on his reelection, he stored the draft in his presidential desk. He gave that draft, including text he added, to Hamilton to complete on May 15, 1796, for the end of his second term. The final version was published on September 19, 1796, by David Claypoole's \"American Daily Advertiser\", and then published by three other Philadelphia newspapers. It warned against foreign alliances and their influence in domestic affairs, and against bitter partisanship in domestic politics. It also called for men to move beyond partisanship and serve the common good, stressing that the United States must concentrate on its own interests. He counseled friendship and commerce with all nations, but advised against involvement in European wars. He stressed the importance of religion, asserting that \"religion and morality are indispensable supports\" in a republic.\n\nWashington's address, influenced by Hamilton, did not quell bipartisan politics but instead served to aggravate them, setting the tone for the coming 1796 election, which pitted Jefferson against Adams. Although Washington favored Federalist ideology, and is said to have supported Adams, he did not publicly endorse him. On December 7, 1796, Washington read his eighth annual address to Congress. He spoke before the House, wore a black velvet suit, and donned his sword, while he was well received by \"the largest assemblage of citizens\" in the crowded gallery. He advocated for the creation of a military academy, and expounded on the fact that the British had vacated the Northwest forts, and Algiers had released American prisoners—an event that would lead to the formation of the Department of the Navy. The speech was well received. On February 8, 1797, Adams was elected President, while Jefferson was elected Vice President.\n\nWashington's Farewell Address proved to be one of the most influential statements on republicanism. It stressed the necessity and importance of national union, the value of the Constitution, the rule of law, the evils of political parties, and the proper virtues of a republican people. He referred to morality as \"a necessary spring of popular government\", maintaining, \"Whatever may be conceded to the influence of refined education on minds of peculiar structure, reason, and experience, both forbid us to expect that national morality can prevail in exclusion of religious principle.\"\n\nBefore its closing remarks, the address expressed this sentiment:\n\nWashington retired from the presidency in March 1797 and returned to Mount Vernon with a profound sense of relief. He devoted much time to his plantations and other business interests, including his , which produced its first batch of spirits in February 1797. His plantation operations were only minimally profitable. His lands in the west (Piedmont) yielded little income because they were under attack by Indians, and the squatters living there refused to pay him rent. He attempted to sell off these holdings but failed to obtain the price he sought. Once in retirement, he became an even more committed Federalist. He was vocal in his support of the Alien and Sedition Acts and convinced Federalist John Marshall to run for Congress to weaken the Jeffersonian hold on Virginia.\n\nWashington grew restless of retirement, prompted by tensions with France, and he wrote to Secretary of War James McHenry offering to organize President Adams' army. French privateers began seizing American ships in 1798, and relations with France deteriorated and led to the \"Quasi-War\". Adams offered Washington a commission as lieutenant general on July 4, 1798, and as commander-in-chief of the armies raised for service in that conflict. He accepted, replacing James Wilkinson and served as the commanding general from July 13, 1798, until his death 17 months later. He participated in planning for a provisional army to meet any emergency but avoided involvement in details. In advising McHenry of potential officers for the army, he appeared to make a complete break with Jefferson's Democratic-Republicans, “...you could as soon scrub the blackamoor white, as to change the principles of a profest Democrat; and that he will leave nothing unattempted to overturn the government of this country.“ Washington delegated the active leadership of the army to Hamilton as major general. No army invaded the United States during this period, and Washington did not assume a field command.\n\nIt is popularly assumed that Washington was rich because of the well-known \"glorified façade of wealth and grandeur\" at Mount Vernon, but nearly all of his wealth was in property (in the form of land and slaves) rather than ready cash. Historians estimate that this estate was worth about $1 million in 1799 dollars, equivalent to about $20 million in 2018.\n\nOn Thursday, December 12, 1799, Washington inspected his farms on horseback while snow and sleet were falling. He returned late for dinner, his neck was wet, and snow matted his hair. He refused to change his wet clothes, not wanting to keep his guests waiting. He had a sore throat the following day but again went out in freezing, snowy weather to mark trees for cutting. That evening, he complained of a sore throat and chest congestion, but was cheerful. Early Saturday morning, he awoke to an inflamed throat and difficulty breathing. He ordered estate overseer George Rawlins to remove nearly a pint of his blood, a common practice of the time, and several physicians were summoned: James Craik, Gustavus Richard Brown, and Elisha C. Dick. (Dr. William Thornton arrived some hours after Washington died.)\n\nDr. Brown thought that Washington had quinsy, while Dick thought that the condition was a more serious \"violent inflammation of the throat\". Continued bloodletting (approximately five pints) proved unsuccessful, and Washington's situation quickly deteriorated. Dick proposed an emergency tracheotomy, but the other two doctors were unfamiliar with the new procedure and disapproved, so it was not used. Washington instructed Brown and Dick to stop their attempts to save his life and leave the room, while he assured Craik, \"Doctor, I die hard, but I am not afraid to go.\"\n\nWashington's illness and death came more swiftly than expected. Washington instructed his private secretary Tobias Lear to wait three days before his burial, in order not to be entombed alive. Washington asked Lear, \"Do you understand me ?\". \"Yes,\" responded Lear. Washington said, \"Tis well.\" Washington died peacefully with Martha composed at the foot of his bed around 10 p.m. on Saturday, December 14, 1799 at age of sixty-seven. Funeral arrangements included Washington's Masonic lodge of Alexandria, Virginia, various members of the clergy, Dr. Craik, military officers, and various members of the Fairfax family. When news of his death reached Congress, they immediately adjourned for the day and the Speaker's chair was shrouded in black the next morning.\n\nThe funeral was held four days after Washington's death on December 18, 1799, at Mount Vernon, where his body was interred. Cavalry and foot soldiers led the procession, while six colonels served as the pallbearers. The Mount Vernon funeral service was restricted mostly to family and friends. Reverend Thomas Davis read the funeral service by the vault with a brief address, followed by a ceremony performed by various members of Washington's Masonic lodge in Alexandria. Congress chose Light-Horse Harry Lee, a Continental Army officer loved by Washington, to deliver the eulogy. Word of his death traveled slowly; church bells rang in the cities, and many places of business closed. People worldwide admired Washington and were saddened by his death, and memorial processions were held in major cities of the United States. Martha wore a black mourning cape for one year, and she burned their correspondence to protect their privacy. Only five letters between the couple are known to have survived, two letters from Martha to George and three from him to her.\n\nThe diagnosis of Washington's illness and the immediate cause of his death have been subjects of debate since the day that he died. The published account of Drs. Craik and Brown stated that his symptoms had been consistent with \"cynanche trachealis\" (tracheal inflammation), a term of that period used to describe severe inflammation of the structures of the upper windpipe, including quinsy. Accusations have persisted since Washington's death concerning medical malpractice, with some believing that he had been bled to death. Various modern medical authors have speculated that he died from a severe case of epiglottitis complicated by the given treatments (which were all accepted medical practice in that day), most notably the massive deliberate blood loss, which almost certainly caused hypovolemic shock.\n\nWashington was buried in the old family vault at Mount Vernon, situated on a grassy slope covered with juniper and cypress trees. It contained the remains of his brother Lawrence and other family members, but the decrepit vault was in need of repair, prompting Washington to leave instructions in his will for the construction of a new vault.\n\nIn 1830, a disgruntled ex-employee of the estate attempted to steal Washington's skull. The next year, the new vault was constructed at Mount Vernon to receive the remains of George and Martha and other relatives. In 1832, a joint Congressional committee debated moving his body from Mount Vernon to a crypt in the Capitol. The crypt had been built by architect Charles Bulfinch in the 1820s during the reconstruction of the burned-out capital, after the Burning of Washington by the British during the War of 1812. Southern opposition was intense, antagonized by an ever-growing rift between North and South; many were concerned that Washington's remains could end up on \"a shore foreign to his native soil\" should the country become divided, and Washington's remains stayed in Mount Vernon.\n\nOn October 7, 1837, Washington's remains were placed, still in the original lead coffin, within a marble sarcophagus designed by William Strickland and constructed by John Struthers earlier that year. The sarcophagus was sealed and encased with planks, while an outer vault was constructed around it. The outer vault has the sarcophagi of both George and Martha Washington; the inner vault has the remains of other Washington family members and relatives.\n\nWashington was somewhat taciturn in personality, though he generally had a strong presence among others. He made speeches and announcements when required, but he was not a noted orator or debater. He was taller than most of his contemporaries; accounts of his height vary from to tall, and he weighed between as an adult. He had wide hips, a slim waist, a broad chest, narrow shoulders, muscular thighs, and exceptionally large hands, and he was widely known for his great strength—particularly in his long arms. He had piercing grey-blue eyes, fair skin, and light reddish-brown hair, although he wore his hair powdered in the fashion of the day. He had a rugged and dominating presence, which garnered respect from his male peers. He suffered frequently from severe tooth decay, and ultimately lost all his teeth but one. He had several sets of false teeth made which he went through during his presidency—none of which were made of wood, contrary to common lore. These dental problems left him in constant pain, for which he took laudanum. As a public figure, he relied upon the strict confidence of his dentist.\n\nWashington was a talented equestrian early in life. He collected thoroughbreds at Mount Vernon, and his two favorite horses were Blueskin and Nelson. Fellow Virginian Thomas Jefferson said that Washington was \"the best horseman of his age and the most graceful figure that could be seen on horseback\"; he also hunted foxes, deer, ducks, and other game. He was an excellent dancer and attended the theater frequently. He drank in moderation but was morally opposed to excessive drinking, the smoking of tobacco, gambling, and profanity.\n\nWashington descended from Anglican minister Lawrence Washington (his great, great grandfather), whose troubles with the Church of England may have pompted his heirs to emigrate to America. Washington was baptized as an infant in April 1732 and became a devoted member of the Church of England (the Anglican Church). He served for over twenty years as a vestryman and churchwarden for Fairfax Parish and Truro Parish. He privately prayed and read the Bible daily, and he publicly encouraged people and the nation to pray. He may have taken communion on a regular basis prior to the Revolutionary War, but he did not do so following the war, for which he was admonished by Pastor James Abercrombie.\n\nWashington believed in a \"wise, inscrutable, and irresistible\" Creator God who was active in the Universe, contrary to deistic thought. He referred to this God by the Enlightenment terms \"Providence\", the \"Creator\", or the \"Almighty\", and also as the \"Divine Author\" or the \"Supreme Being\". He believed in a divine power who watched over battlefields, was involved in the outcome of war, was protecting his life, and was involved in American politics—and specifically in the creation of the United States. Modern historian Ron Chernow has posited that Washington avoided evangelistic Christianity or hellfire-and-brimstone speech along with communion and anything inclined to \"flaunt his religiosity\". Chernow has also said Washington \"never used his religion as a device for partisan purposes or in official undertakings\". No mention of Jesus Christ appears in his private correspondence, and such references are rare in his public writings. He often quoted from the Bible or paraphrased it, and often referred to the Anglican Book of Common Prayer. There is debate on whether he is best classed as a Christian, a theistic rationalist, or both.\n\nWashington emphasized religious toleration in a nation with numerous denominations and religions. He attended services of different Christian denominations and prohibited anti-Catholic celebrations in the Army. He engaged workers at Mount Vernon without regard for religious belief or affiliation. While President, he acknowledged major religious sects and gave speeches on religious toleration. He was distinctly rooted in the ideas, values, and modes of thinking of the Enlightenment. He harbored no contempt of organized Christianity and its clergy, \"being no bigot myself to any mode of worship\". He proclaimed in 1793, \"We have abundant reason to rejoice that in this Land the light of truth and reason has triumphed over the power of bigotry and superstition.\"\n\nFreemasonry was a widely accepted institution in the late 18th century, known for advocating moral teachings. Washington was attracted to the Masons' dedication to the Enlightenment principles of rationality, reason, and brotherhood. The American lodges did not share the anti-clerical perspective of the controversial European lodges. A Masonic lodge was established in Fredericksburg, Virginia, in September 1752, and Washington was initiated two months later at the age of 20 as one of its first Entered Apprentices. Within a year, he progressed through its ranks to become a Master Mason. Before and during the American Revolution he used Masonic lodges as meeting places to plot against the British. Washington had a high regard for the Masonic Order, but his personal lodge attendance was sporadic. In 1777, a convention of Virginia lodges asked him to be the Grand Master of the newly established Grand Lodge of Virginia, but he declined due to his commitments leading the Continental Army. After 1782, he corresponded frequently with Masonic lodges and members, and in 1788 he was listed as Master in the Virginia charter of Alexandria Lodge No. 22.\n\nWashington was born into a world accustomed to slavery; he had no qualms about its practice prior to 1775 and held commonplace views that Blacks were an inferior race. During the war, however, his views moderated under the influence of anti-slavery officers he was close friends with, such as Lafayette. He spoke often of ending slavery following the war, but he never voiced those views publicly, fearing that the issue would divide the new nation.\n\nThere are conflicting reports of slave treatment at Mount Vernon. Washington discouraged cruelty, yet there are records of harsh punishments, including whipping inflicted on male and female slaves by their overseers, some of whom were also slaves. When he was President, Washington maintained distant supervision of Mount Vernon through letters to his overseers, though there is only one account from him authorizing a whipping that was given to a slave who had badly beaten his wife. He directed that a warning be given to first offenders before resorting to whipping, which was then subject to his prior approval; this wasn't always enforced due to his prolonged absences. In severe circumstances, he shipped unruly slaves to the West Indies. He also used nonviolent forms of discipline, including cash payments, material incentives, and \"admonition and advice\".\n\nWashington sometimes personally cared for ill or injured slaves, and he provided physicians and midwives. By the Revolutionary War, he had all his slaves inoculated for smallpox. Slaves worked from dawn to dusk, but received two hours off for meals during the workday and were not put to work on Sundays (the Sabbath), Christmas, Easter, or Pentecost. They were often poorly clothed and housed, but were well fed and received two hours off for meals during the workday.\n\nDuring the war, Washington initially forbade Blacks from becoming soldiers, but he allowed them to serve in the Continental Army beginning in January, 1776, in order to counter Loyalist Governor Dunmore's offer to free slaves if they fought for the British. After the war, Washington supported many slaves who were too young or too old to work, both greatly increasing Mount Vernon's slave population and causing the plantation to operate at a loss in the process. By 1799, there were 317 slaves living at Mount Vernon; he owned 124 outright and held 153 for his wife's dower interest. At times, Mount Vernon slaves ran away to find freedom. To avoid any controversy Washington used secretive methods to return them rather than post public advertisements in the North.\n\nWashington never set any of his slaves free; however, in 1799 he addressed his personal struggle with slave-holding by making a new will that directed his 124 slaves be freed upon the death of Martha. He was among the few slave-holding Founding Fathers to do so. He provided that old and young freed people be taken care of indefinitely; younger ones were to be taught to read and write and placed in suitable occupations. Martha freed his slaves on January 1, 1801, a year after Washington's death and a year before her own. Modern historian John E. Ferling has posited that Washington's freeing of his slaves through his will was \"an act of atonement for a lifetime of concurrence in human exploitation\".\n\nWashington's legacy endures as one of the most influential in American history, since he served as commander-in-chief of the Continental Army, a hero of the Revolution, and the first President of the United States. Modern historians Jay Parry and Andrew Allison have declared that Washington \"was the dominant personality in three of the most critical events in that founding: the Revolutionary War, the Constitutional Convention, and the first national administration. Had he not served as America's leader in those three events, all three likely would have failed. And America as we know it today would not exist.\" Congressman Light-Horse Harry Lee, a Revolutionary War comrade, : \"First in war—first in peace—and first in the hearts of his countrymen.\" Lee's words became the hallmark by which Washington's overwhelming reputation was impressed upon the American memory, with biographers hailing him as the great exemplar of republicanism. Washington set many precedents for the national government and the presidency in particular, and he was called the \"Father of His Country\" as early as 1778.\n\nIn 1885, Congress proclaimed Washington's birthday to be a federal holiday. Twentieth-century biographer Douglas Southall Freeman famously concluded, \"The great big thing stamped across that man is character.\" Modern historian David Hackett Fischer has expanded upon Freeman's assessment, defining Washington's character as \"integrity, self-discipline, courage, absolute honesty, resolve, and decision, but also forbearance, decency, and respect for others\".\n\nWashington became an international icon for liberation and nationalism, as the leader of the first successful revolution against a colonial empire. The Federalists made him the symbol of their party, but the Jeffersonians continued to distrust his influence for many years and delayed building the Washington Monument. On January 31, 1781 (before he had even begun his presidency), he was elected a member of the American Academy of Arts and Sciences. During the United States Bicentennial, to ensure Washington would never by outranked, Washington was posthumously appointed to the grade of General of the Armies of the United States by the congressional joint resolution passed on January 19, 1976, with an effective appointment date of July 4, 1976. Parson Weems's hagiographical account \"The Life of Washington\" (1809) helped elevate Washington to heroic legendary status. The authenticity of Weems's anecdotes, which include the story of Washington cutting down the cherry tree as a child and his famous utterance \"I cannot tell a lie\", is unknown.\n\nThe serious collection and publication of Washington's documentary record began with the pioneer work of Jared Sparks in the 1830s in \"Life and Writings of George Washington\" (12 vols., 1834–1837). \"The Writings of George Washington from the Original Manuscript Sources, 1745–1799\" (1931–44) is a 39-volume set edited by John Clement Fitzpatrick who was commissioned by the \"George Washington Bicentennial Commission\". It contains over 17,000 letters and documents and is available online from the University of Virginia.\n\nMany places and monuments have been named in honor of Washington, most notably the nation's capital, Washington, D.C. (which is also named for Christopher Columbus, \"D.C.\" standing for \"District of Columbia\"). The state of Washington is the only state to be named after a president.\n\nGeorge Washington appears on contemporary U.S. currency, including the one-dollar bill and the quarter-dollar coin (the Washington quarter).\n\nWashington and Benjamin Franklin appeared on the nation's first postage stamps in 1847. Since that time, Washington has appeared on many postage issues, more than any other individual.\n\nPrint sources\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<br>Primary sources\n\n<br>Online sources\n\n"}
{"id": "20732820", "url": "https://en.wikipedia.org/wiki?curid=20732820", "title": "Helen Magnus", "text": "Helen Magnus\n\nDr. Helen Magnus is the series protagonist and central character of the Canadian fantasy-science fiction television series \"Sanctuary\". She is portrayed by Amanda Tapping. In the series, Magnus is a life scientist from Victorian era England, who currently runs the global Sanctuary Network, an organization tasked with finding a series of creatures called \"abnormals\", and later bring them to a Sanctuary base for refuge to protect them from the human population. The character is over two and a half centuries old, having been given her advanced longevity by injecting herself with vampire blood, as well as reliving the 20th century from time travel. After traveling back in time, Magnus had to avoid people so she isolated herself. In the season 4 finale \"Sanctuary For None: Part 2\" It was revealed that Magnus spent the 113 years creating a new Sanctuary.\n\nTapping was offered a part in the original web series by series creator Damian Kindler and director Martin Wood. It became the actress' first regular role since playing Samantha Carter on \"Stargate SG-1\" and \"Stargate Atlantis\" for eleven years. She initially had difficulty playing Magnus as her personality greatly differed from Carter. She also dyed her hair darker and spoke with an English accent throughout the run, as she herself was born in England. In addition, Tapping serves as the series executive producer and on some occasions, director.\n\nMagnus and Tapping's portrayal of the character received generally mixed reactions from critics, with the negative comments pointing toward's Tapping's accent. However, Tapping was nominated for four awards, one Gemini Award and three Leo Awards, for her role as Helen Magnus, winning a Leo Award for \"Best Lead Performance by a Female in a Dramatic Series\" in 2009 for the episode \"Requiem\".\n\nHelen Magnus was born on August 27, 1850 to Gregory Magnus (Jim Byrnes) and Patricia Heathering. Her father was regarded as a controversial medical researcher of his time, and exposed his daughter to his profession when she was a child. Years later, she helped form a secret group known as \"the Five\", along with John Druitt (Christopher Heyerdahl), Nikola Tesla (Jonathon Young), James Watson (Peter Wingfield) and Nigel Griffin (Vincent Gale) at Oxford University. Each member voluntarily injected themselves with pure vampire blood, a species that had become extinct centuries before. This granted each member unique abilities. Magnus' ability was longevity, allowing her to live several times longer than any normal human. At this point she entered a relationship with Druitt, whose ability is personal teleportation. However, he became insane and murdered several prostitutes, thereby becoming Jack the Ripper. They did conceive a child, Magnus later took the embryo and froze it.\n\nBy the turn of the 20th century, her research with the abnormal population went into full swing, and she founded the Sanctuary Network. To get the funding she needed, the Prime Minister reunited the Five to stop and kill Adam Worth (Ian Tracey), who was turned down as a sixth member and blamed the Five for the death of his daughter, from releasing a toxin in London. In the season two episode \"Next Tuesday\", Magnus states she was a passenger on the \"RMS Titanic\" in 1912. In July 1944, she worked with the French Resistance in Normandy to prevent the Nazis from controlling a fire elemental before D-Day. She then charged the head Sanctuary in Old City, a fictional city in the Pacific Northwest, during which she decided to use the embryo to bear her daughter, Ashley (Emilie Ullerup). On one of her expeditions, she saved a young Will Zimmerman from a dangerous abnormal, but failed to capture it before it killed his mother.\n\nIn the first season of the show, Magnus appoints an adult Will (Robin Dunne), a forensic psychiatrist who worked for the Old City Police Department, to become her new protégé, which he eventually accepts. Druitt returns to the Sanctuary to ask Magnus to cure him from an unknown affliction; Magnus tricks him into injecting poison, though Druitt escapes. Later, in \"The Five\", it would be revealed Druitt survived, and Tesla was able to suppress his insanity. In \"Fata Morgana\", she becomes aware of an underground organization known as the Cabal, who plot to control all abnormals for their own gain, and in several episodes throughout the first season, will become her and her organization's primary focus. In \"Requiem\", Magnus becomes exposed to an aggressive parasite in the Bermuda Triangle when going with Will to see a group of mermaids who massacred each other because of the same parasite. To stop Magnus from killing Will and herself, Will locks her in a cabin in the submarine, and drains all the oxygen, killing her. She is later revived after Will captures the escaping parasite. In the two-part season finale \"Revelations\", the Cabal launch a bioweapon called \"Lazarus\", which causes any exposed abnormal to attack humans. To combat this, Magnus regroups the Five to Bhalasaam, a lost city, to recover the source blood (vampire blood). However, by the end Magnus is distressed to learn that the Cabal have turned Ashley against her and the team and steals the blood sample.\n\nThe second season begins six weeks after the end of the first, where Magnus works hard to defeat the Cabal and save Ashley, whom the Cabal transformed to a vampire-hybrid superabnormal, one of six tasked to destroy the Sanctuary Network. When the superabnormals arrive at the Old City Sanctuary, Magnus is able to get through to Ashley, who recognises her in time to save her from another superabnormal, and then teleports. Because an electromagnetic field is active, it would mean whoever teleports inside would be vaporized. Despite this, Magnus believes Ashley's life energy may be in the electromagnetic field's buffer. When it does not, she is forced to accept that Ashley has died. Because of her death, and other loved ones because of her longevity, she tried to find a way to age at a normal rate again. She finds an elixir used by the Mayans in Honduras, but it has the side effect of turning humans into zombie-like creatures. After being shown the potential consequences of the elixir's release by an incorporeal guardian, she decides to leave it behind.\n\nLater on in the season, her leadership of the Sanctuary Network would be called into question by the other heads of house. In \"Veritas\", she sets up an elaborate scheme to apprehend a telepath named Emma (Erica Cerra), whom she suspects of working against the Network. In the scheme, Magnus forges a mental illness and fakes the murder of her butler, Bigfoot (Heyerdahl), and makes Emma believe she kept alive Big Bertha, the most dangerous abnormal on Earth, which Magnus was thought to have killed. However, it is revealed in the season finale \"Kali\", Magnus did indeed keep her alive in secrecy, but sedated, as she believes that killing Bertha would jeopardize the planet. When Big Bertha is being controlled by Edward Forsythe, Magnus attempts to sedate Big Bertha again, but by then, Terrence Wexford (Paul McGillion) overrides her authority and assumes control of the network. His attempt to kill Bertha only succeeds in angering her, and she launches a tsunami.\n\nThe third season begins with Magnus forcing Wexford to step down as head of the Sanctuary Network, thereby putting herself back in command, while the rest of the team deal with the tsunami. Though they are not happy that Big Bertha is still alive, the other Sanctuary house heads decide to keep Magnus in charge, while also firing Wexford for breaking several protocols. She learns from Will that when he talked to Kali, the avatar manifestation of Big Bertha, into stopping the tsunami, he saw her father, who left her clues leading to a map leading to Hollow Earth, thought to be the home of every abnormal species on the planet. In \"Breach\" Magnus learns Adam Worth is still alive, and he also intends to find Hollow Earth, having been there before and resurrected. After finding an entrance to Hollow Earth in Tibet, she and the team venture to the underground city of Praxis, where leader Ranna (Polly Walker) executes her and her team for trespassing. However, they are later resurrected as she wants their help in saving the city, which is facing destruction because a hyperspecies abnormal is not controlling the city's geothermal energy. After saving it, Magnus and her team and Ranna part in good terms. It is also revealed Worth also came to the city to steal a power source with unlimited capabilities. Though it was assumed Druitt killed him before he could leave with it, it is later revealed in the season finale that Druitt kept him alive and that he is using the power source to create a time machine and cure his daughter's leukemia, which could cause untold consequences on the planet. His first failed attempt causes the destruction of Praxis, and a time dilation bubble in Carentan, France. Magnus fails to stop him from succeeding, but does follow him through a time portal to London in 1898.\n\nMagnus pursues Worth throughout London to stop him from curing his daughter Imogene, who is meant to die in the timeline. During the pursuit she tries to avoid her past self, but fails to stop encountering Watson, who quickly discovers she is from his future, but he promises to keep quiet for the sake of preserving the timeline. When Worth chases Magnus later he accidentally kills Imogene, restoring the timeline. After killing Worth, Magnus ends up in hiding for the next 113 years before she can resurface to help Will dealing with a mass of Abnormals invading the surface. In the season finale, it is revealed that Helen had been secretly working with several important figures of the 20th Century, including Albert Einstein and Buckminster Fuller amongst others, and had built a new underground Sanctuary.\n\nThe Syfy website describes Magnus as \"beautiful and enigmatic\" who has \"devoted her life to the practical research of cutting edge medicine and science\". Her work is to explore the world of abnormals. While the rest of the world dismiss them as monstrous figments of their imaginations and elements of childhood nightmares, Magnus realizes that they are the world's triumphs and mistakes. Magnus hence becomes their protector, but in some cases, their captor. She is also described as \"bold and straightforward, brave and no-nonsense, yet she remains proudly true to her formal Victorian English sensibilities\". Portraying actress Amanda Tapping described Magnus as a \"crazy character\" who is \"very eccentric and very sexy and very unapologetic\".\n\nMagnus \"adores her daughter Ashley, respecting her independence and self-reliance – but that doesn't preclude some occasional mother-daughter friction\". Tapping has said that there is a \"huge amount of respect\" between the two characters, adding \"Ashley knows that when her mother says she needs to do something then she says it for a reason. And Magnus has a huge amount of respect for Ashley because Ashley can do things that she can't.\" Magnus made a hard choice of having Ashley even though she does not have her mother's longevity, and Magnus would outlive her daughter. In the first season Magnus recruits Will as her protégé. When asked what Magnus thinks of Will, Tapping stated \"I think Helen finds him fascinating. He's so idealistic, she sees in him all the qualities that she admires, but all the qualities that she knows will probably get beaten out of him over the course of time. His idealism and purity of thought and the way he analyses things ... she absolutely respects that, but I think she also realises that there's going to come a time when he's going to become a bit jaded ... There are a couple of episodes where there's been this bizarre sexual tension between the two of them ... but generally there's just a huge healthy respect.\" During a Blastr interview in 2011, Tapping further explains Magnus' relationship with Will; \"I love how this relationship has developed. [...] \"It's been a really organic transformation of Will's character and Magnus. To actually bring somebody on board who, initially, it's all about teaching him the ropes. And then as the seasons have gone on he's come into his own. He's come into his own as a scientist. He's come into his own in terms of his relationship with the people in the Sanctuary.\" Dunne meanwhile stated \"there's a nice synchronicity that has formed between the two characters. And really, they're two people that depend on each other for survival. And therefore, that's where the respect comes out of.\"\n\nSeries creator Damian Kindler conceived the idea of \"Sanctuary\" in 2001, many of his ideas were included in the final product, one of them being the English scientist Helen Magnus. A few years later, Kindler asked Martin Wood if there was a potential for a series. When Wood believed it would be, they both decided to approach Amanda Tapping to participate in the project, and she accepted. Kindler believed that casting Tapping was a \"nice fit\" to the character because the actress was born in England. Tapping, who played the regular character Samantha Carter in \"Stargate SG-1\" and sister show \"Stargate Atlantis\", did not know the future of her role in the show when she was approached to appear on \"Sanctuary\" in 2006. When the webseries started shooting in January 2007, it did not conflict with her commitments on \"Stargate\". After the fourth season of \"Atlantis\", Tapping was offered to return to the fifth season and she accepted. When \"Sanctuary\" was picked up to a television series, Tapping decided to turn down the \"Atlantis\" contract, having been encouraged by her husband to move on after playing Carter for eleven years. She went through a \"weird disconnect\" playing Magnus since \"Sam Carter was so much a part of me\". However, she was able to embrace playing a new character \"pretty quickly\".\n\nNevertheless, Tapping found it a challenge to play a different character, as Carter and Magnus have differing personalities and points of view; \"after playing a character like Sam Carter for so long where her physicality is so comfortable – Sam is so comfortable in her own skin and Helen is this very sexual, more mysterious being. She has a much darker edge to her and it was sort of finding that because Carter always looks on the bright side and Helen has been around so long, and has seen so much of the evil in human society if you will.\" Whilst filming the webisodes, Tapping wore a dark-haired wig, but when the television series was being shot, she dyed her hair to match the hair colour of the wig. Tapping spoke with an English accent throughout the run of the series. Although many of her relatives are from the United Kingdom and speak with British accents Tapping found the accent a challenge, as her character came from the Victorian era, which is a \"very specific way of speaking. She clings to that eccentricity a bit, to that Britishness.\" The actress listened to several different voices, as she had to factor in the fact that Magnus lived all around the world.\n\n\"Sanctuary\" was mostly filmed on virtual green screen sets. Initially Tapping went through what she called \"chroma key green headaches\" because she had to stare at nothing but bright green walls for the first few days. When she got used to it, she likened filming on green screen to working in theatre. In the second season her daughter, Ashley was killed off. The producers, as well as the American and Canadian networks to give the character, including Magnus, a deep and most dramatic impact. They also wanted Magnus to feel more angry and vulnerable throughout the season, especially in the first three episodes. After playing Magnus in the series' third season, Tapping admitted that she still does not get Magnus because \"there's so many things about the decisions that she makes that I still can't wrap my head around, and to me that's fascinating as an actor, to try to get inside somebody so complex and so kind of confusing.\" In the episode \"Normandy\", Tapping wore a red-haired wig for Magnus during her time in the Second World War, as an homage to her late grandmother. For the fourth season, Tapping requested that Magnus would be given a new love interest. The request was granted in the form of a female virologist appearing early in the season (thus establishing Magnus's bisexuality).\n\nIn addition to being an actor, Tapping was also an executive producer on the series. However, she did not get paid extra as that salary would go towards financing the show, which was not backed up by a studio. She also served as a director on certain days if other directors were unavailable, or called in sick. In the second season, she was allowed to direct \"Veritas\", the seventh episode.\n\nAccording to Mark Wilson of \"About.com\", Amanda Tapping was enthusiastic about creating a radically different character after eleven years playing Samantha Carter in \"Stargate SG-1\" and \"Stargate Atlantis\", and expended tremendous effort to separate Helen from Carter as successfully as possible. Tapping was able to successfully portray a woman who's experienced a century and a half of isolation, strangeness, and relentless compassion. Rick Bentley from \"McClatchy Newspapers\" commented Tapping's role as Dr. Magnus was a way for the actor to make a name of herself outside the \"Stargate\" universe as Carter. Magnus is also described as a \"non-glib, female Jack Harkness;\" Jack Harkness being the main character from the British science fiction show \"Torchwood\". Hilary Rothing of UGO said that \"Dr. Helen Magnus is intelligent, alluring and has one of those tasty British accents – Victorian era to be exact. That's because she's a 157 years old. But seriously, she doesn't look a day over 35.\" She also added that Tapping is \"right at home\" taking the lead for the show. Alex Walker of Den of Geek believed Magnus was \"typical for an English character in an American TV show, with a liking for tea and a cut-glass elocution betraying no hint of a regional accent\". Helen Magnus has been listed number ten in \"TV Squad'<nowiki>s</nowiki>\" \"Ten Most mysterious characters on television\".\n\nMagnus's English accent was not well received by some critics. She was listed ninth in io9's \"Worst Fake Accents From The Yanks (And Canucks) Of Science Fiction\", with Meredith Woerner stating \"I really want to like this new Sci Fi Channel show, especially since the monsters look amazing – but I'm worried Tapping's dreadful accent will get in the way. It sounds completely forced in all the clips I've seen so far, but I'll guess I'll have to wait until October 3 to make my full assessment.\" Maureen Ryan of the \"Chicago Tribune\" wondered why Tapping decided to speak with an \"iffy accent,\" but added she would be of interest by fans of Tapping's previous works, notably \"Stargate\". Rob Owen of the \"Pittsburgh Post-Gazette\" called Tapping's English accent \"unremarkable\", whilst calling the show an \"unremarkable series.\"\n\nOver the course of the series, Tapping's portrayal of Magnus resulted in several award nominations. Tapping was nominated for a 2009 Gemini Award for \"Best Performance by an Actress in a Continuing Leading Dramatic Role,\" for her role in \"Requiem\", but lost out to \"Being Erica's\" Erin Karpluk In the same year, Tapping won the similar \"Best Lead Performance by a Female in a Dramatic Series\" Leo Award for the same episode. She was nominated for the same category again in 2010 for \"Pavor Nocturnus\", and in 2011 for \"Breach\", but lost out to Erin Karpluk and \"Blackstone's\" Carmen Moore, respectively.\n\n"}
{"id": "24947392", "url": "https://en.wikipedia.org/wiki?curid=24947392", "title": "Holger Kersten", "text": "Holger Kersten\n\nHolger Kersten (born 1951) is a German writer on myth, legend, religion and esoteric subjects. He is best known for the books about Jesus' early years and later years in India. In 2005 he led an expedition looking for the birthplace of Mithras.\n\n\"Jesus Lived in India\" promotes the claims both of Nicolas Notovich (1894) regarding the unknown years of Jesus between the ages of 12 and 30 in India, also Ahmadiyya founder Ghulam Ahmad's claims regarding the years aged 33 to age 120 in India, and the burial of Jesus at the Roza Bal shrine in Srinagar. Kersten also draws on earlier material by Jacolliot, Andreas Faber-Kaiser, and German popular novelist Siegfried Obermeier (also 1983). The book was translated into Chinese in 1987.\n\nLike others before him Kersten follows Mirza Ghulam Ahmad in his sources. For example, a passage in the Bhavishya Purana which refers to Jesus as \"Isa-Masih\" (Jesus the Messiah). The passage describes the Hindu king Shalivahana travelling to mountains where he meets a man who calls himself Isa, son of a Virgin. Isa says he has ministered to the Mlecchas, explaining that he has reformed the lives of the mlecchas by recommending principles of mental purity, japa by chanting holy names, and meditation. Kersten interprets this as a record of Jesus in Kashmir. In reality the passage is an 18th-century dialogue also featuring Muhammed, and not an early source as Ahmad claimed. Most scholars consider this part of the Purana to be a 19th-century interpolation.\n\nThe book achieved great popularity in Germany and overseas, though competed with the better-known Siegfried Obermeier's book in Germany. The Indologist Günter Grönbold included a highly critical debunking of Obermeier and Kersten's interpretations of Buddhist sources among various expositions of Jesus in India theories in \"Jesus in Indien. Das Ende einer Legende\" (Jesus in India, the end of a Legend, 1985). Wilhelm Schneemelcher in introducing the subject of New Testament Apocrypha (1991) uses Kersten by way of illustration of the development of legendary Gospel traditions and notes how Kersten \"attempted to work up Notovitch and Ahmadiyya legends with many other alleged witnesses into a complete picture.\" McGetchin notes that once his story had been re-examined by historians, Notovitch confessed to having fabricated the evidence. \n\nHowever, in 1922 Swami Abhedananda visited the Hemis monastery and corroborated much of Notovitch's story. Given access to the manuscripts on Jesus Christ, Abhedananda later published an abbreviated version of Notovich's translated account. After Abhedananda's death in 1939, one of his disciples inquired about the documents at the monastery, but was told they disappeared. \nIn a later work co-written with parapsychologist Elmar R. Gruber (b. 1955), \"Der Ur-Jesus\" (1994), translated \"The Original Jesus\" (1995) Kersten argues that Buddhism appears to have had a substantial influence on the life and teachings of Jesus. They hold that Jesus was influenced by the teachings and practices of Therapeutae, described by the authors as teachers of the Buddhist Theravada school then living in Judaea, although the only account, the extensive description by Philo of Alexandria describes them as a charismatic Hellenistic Jewish community following the Law of Moses. Gruber and Kersten assert that Jesus lived the life of a Buddhist and taught Buddhist ideals to his disciples. In doing so their work draws on earlier comparisons between Buddhism and Christianity such as the Oxford New Testament scholar Burnett Hillman Streeter (1932) who argued that the moral teaching of the Gautama Buddha has four remarkable resemblances to the Sermon on the Mount.\n\nThe ideas of the two earlier books were developed and related to the Turin Shroud in \"Das Jesus-Komplott: die Wahrheit über das Turiner Grabtuch\" and \"Jesus starb nicht am Kreuz — Die Botschaft des Turiner Grabtuchs\" (1998) \"The Jesus Conspiracy: The Turin Shroud and the Truth About the Resurrection\". The Jesus Conspiracy proposes that the Vatican interfered with the 1988 Radiocarbon 14 dating of the Shroud of Turin to show a medieval date for its origin. The authors propose that the shroud is authentic as the burial cloth of Jesus, but that evidence including blood tracks shows that Jesus was alive following his crucifixion. They argue that the \"Mandylion\" or Image of Edessa, known from the sixth century, was the Shroud, but folded to only show the face of Jesus. Because Jesus surviving the cross would contradict the teaching of the Resurrection, the central belief in Christianity, the authors allege that the Vatican used a piece from a 13th-century cloth with a similar herringbone weave to the Shroud of Turin as a substitute in the carbon dating. In part three, Elmar R. Gruber attempts to explain many details concerning what happened in \"that dramatic hour of Good Friday\". The book' repeats the author's earlier arguments that after the crucifixion Jesus moved to India. In a later book, they argued that he had become a Buddhist monk.\n\nNone of Kersten's works have found any support in mainstream scholarship — either Biblical or Indologist. The noted German scholar of New Testament Apocrypha Wilhelm Schneemelcher, in a revision of his standard work prior to his death in 2003, and in unusually strong language for the scholarly community states that Kersten's work is based on \"fantasy, untruth and ignorance (above all in the linguistic area)\" and \"has nothing to do with historical research.\" Gerald O'Collins and Daniel Kendall view that \"Kersten's discredited book\" is simply the repackaging of Notovich and Ahmad's material for consumption by the general public.\n"}
{"id": "56707148", "url": "https://en.wikipedia.org/wiki?curid=56707148", "title": "Hope Lodge", "text": "Hope Lodge\n\nHope Lodge is a charitable project run by the American Cancer Society offering cancer patients and their caregivers a free place to stay when they are being treated in another city away from home. The American Cancer Society Hope Lodge Network includes more than thirty locations throughout the United States. There is also a Hope Lodge unit in Puerto Rico.\n\n"}
{"id": "49007569", "url": "https://en.wikipedia.org/wiki?curid=49007569", "title": "Ibrahim Shah of Johor", "text": "Ibrahim Shah of Johor\n\nPaduka Sri Sultan Ibrahim Shah Zilu'llah fil'Alam Khalifat ul-Muminin ibni al-Marhum Yam Tuan Muda Raja Bajau was the 8th Sultan of Johor from House of Melaka who reigned from 1677 to 1685. He was the only known son of Yamtuan Muda of Pahang, Raja Bajau and succeeded on the death of his cousin, Abdul Jalil Shah III as Sultan of Johor-Pahang-Riau-Lingga or Johor Empire.\n\nIn 1678, Laksamana Tun Abdul Jamil persuaded Ibrahim Shah to move the capital of the empire to Riau in order to effectively suppress Jambi forces, who years earlier successfully sacked the old capital of Batu Sawar. Jambi was finally subdued in 1679. In 1681, Johor forces assisted Jambi, now its vassal, in defeating Palembang and its Bugis allies.\n\nAlthough Ibrahim Shah wanted to return to Johor Lama towards the end of his reign, he was persuaded against this by the family of Laksamana Tun Abdul Jamil, who grew very powerful in the mainland while the Sultan was away in Riau.\n\nIbrahim Shah died at Riau on 16 February 1685, poisoned by three of his wives, having had issue one son by his third wife, who succeeded as Mahmud Shah II.\n\n"}
{"id": "17017675", "url": "https://en.wikipedia.org/wiki?curid=17017675", "title": "International Salon for Peace Initiatives", "text": "International Salon for Peace Initiatives\n\nThe International Salon for Peace Initiatives is organized in the framework of the International Decade for the Promotion of a Culture of Peace and Non-Violence for the Children of the World (2001–2010) declared by the United Nations in 1998.\nOrganized by the French Coalition for the Decade, it has been taken place in Paris every two years since 2004.\n\nThis Salon hosts the International Conference on the Culture of Peace and Non-Violence, organized by the French Coalition for the Decade in collaboration with the International Coalition for the Decade. This Conference create a space for thinking and meeting for all those involved in this field, in France, Europe and all over the world.\n\nThe 2d International Salon for Peace Initiatives has taken place in Paris on 2–4 June 2006, in the Centre des Congrès de la Villette, in the Cité des Sciences et de l'Industrie (Paris).\n\nThe second international Salon for Peace Initiatives was held under the auspices of the UNESCO the French Foreign Office and the City of Paris, in partnership with the Secours catholique – Caritas France, the CCFD, Non-violence XXI, Partage, \"Le Monde\", \"La Vie\", \"Télérama\", RFI and TV5 and with the support of Pax Christi France.\n\nThis Salon has help a wide public get familiar with the culture of peace and non-violence. 168 French and international exhibitors were presenting their peace and non-violence initiatives on 116 booths. They have proposed 40 interactive workshops and other activities with 13,000 participants.\n\nThis Salon has hosted the International Conference « Actors for a Culture of Peace and Non-violence ».\n\nSeven round tables and sixty workshops helped the participants to discover the different aspects of the culture of peace and non-violence. Among the speakers were:\n\n\nHundreds organizations came from all over the world to participate to this conference.\n\nThe 3rd International Salon for Peace Initiatives will take place in Paris on 30 May – 1 June 2008, in the Cité des Sciences et de l'Industrie.\nIt will help a wide public to get familiar with the culture of peace and non-violence. Around 200 French and international exhibitors will present their peace and non-violence initiatives and several activities will be proposed, included 40 interactive workshops, films and exhibitions.\n\nThe third international Salon for Peace Initiatives will be held under the auspices of the UN, the UNESCO, the UNRIC, the French Commission for UNESCO, the French Foreign Office, the Regional council of Ile-de-France and the City of Paris, in partnership with the Secours catholique- Réseau mondial Caritas, Non-violence XXI, Partage, \"Le Monde\", \"La Vie\" and RFI, and also with the support of Pax Christi France and the Secours islamique.\n\nSeveral organizations will be partners of this Salon in order to enrich the culture of peace and non-violence and to highlight its numerous dimensions: justice, non-violent resolution of conflicts, mediation, human rights defense, environmental respect and development, disarmament, gender equality, international solidarity etc.\n\nThis Salon will host the International Conference \"Actor for a Culture of Peace and Nonviolence\", organized by the French Coalition for the Decade in collaboration with the International Coalition for the Decade. This Conference will create a space for thinking and meeting for all those involved in this field, in France and all over the world.\n\nSix round tables and sixty workshops will allow for the encounter and the debate among several scientific disciplines (sociology, psychology and pedagogy) and several citizen practices (associative, political) from the whole world. They will take into account the death anniversary of two major figures of non-violence: M. K. Gandhi (1948) and Martin Luther King (1968).\n\nSpeakers of this International Conference will be:\n\n\n\n\n\n"}
{"id": "17423238", "url": "https://en.wikipedia.org/wiki?curid=17423238", "title": "Ireviken event", "text": "Ireviken event\n\nThe Ireviken event was the first of three relatively minor extinction events (the Ireviken, Mulde, and Lau events) during the Silurian period. It occurred at the Llandovery/Wenlock boundary (mid Silurian, ). The event is best recorded at Ireviken, Gotland, where over 50% of trilobite species became extinct; 80% of the global conodont species also become extinct in this interval.\n\nThe event lasted around 200,000 years, spanning the base of the Wenlock epoch.\n\nIt comprises eight extinction \"datum points\"—the first four being regularly spaced, every 30,797 years, and linked to the Milankovic obliquity cycle. The fifth and sixth probably reflect maxima in the precessional cycles, with periods of around 16.5 and 19 ka. The final two data are much further spaced, so harder to link with Milankovic changes.\n\nThe mechanism responsible for the event originated in the deep oceans, and made its way into the shallower shelf seas. Correspondingly, shallow-water reefs were barely affected, while pelagic and hemipelagic organisms such as the graptolites, conodonts and trilobites were hit hardest.\n\nSubsequent to the first extinctions, excursions in the δC and δO records are observed; δC rises from +1.4‰ to +4.5‰, while δO increases from −5.6‰ to −5.0‰.\n\nAnoxic event\n"}
{"id": "10622545", "url": "https://en.wikipedia.org/wiki?curid=10622545", "title": "James Collins (bioengineer)", "text": "James Collins (bioengineer)\n\nJames J. Collins (born June 26, 1965) is an American bioengineer, and the Termeer Professor of Medical Engineering & Science and Professor of Biological Engineering at MIT. He is one of the founders of the emerging field of synthetic biology, and has made multiple synthetic biology breakthroughs in biotechnology and biomedicine, including paper-based diagnostics for Zika & Ebola and programmable cells that serve as living diagnostics and living therapeutics to detect-and-treat infections, rare genetic metabolic disorders, and inflammatory bowel disease. Collins is also a pioneering researcher in systems biology, having made fundamental discoveries regarding the actions of antibiotics and the emergence of antibiotic resistance. \n\nCollins received a bachelor's degree in physics (summa cum laude; class valedictorian) from the College of the Holy Cross in 1987 and a doctorate in Medical Engineering from the University of Oxford in 1990. From 1987 to 1990, he was a Rhodes Scholar. Currently, Collins is the Termeer Professor of Medical Engineering & Science and Professor of Biological Engineering at MIT. Collins is also a core founding faculty member of the Wyss Institute for Biologically Inspired Engineering at Harvard University and an Institute Member of the Broad Institute at MIT and Harvard.\n\nFrom 1990 to 2014, he was on the faculty at Boston University, where he was a William F. Warren Distinguished Professor, a University Professor, Professor of Biomedical Engineering, and Co-Director of the Center for BioDynamics and Director of the Center of Synthetic Biology.\n\nCollins' scientific accomplishments have been recognized by numerous awards, including the NIH Director's Pioneer Award, the Ellison Medical Foundation Senior Scholar Award in Aging, the inaugural Anthony J. Drexel Exceptional Achievement Award, the Lagrange Prize from the CRT Foundation in Italy, the Sanofi-Institut Pasteur Award, the BMES Robert A. Pritzker Award, the HFSP Nakasone Award, the Promega Biotechnology Research Award, and being selected for Technology Review's inaugural TR100 - 100 young innovators who will shape the future of technology - and the Scientific American 50 - the top 50 outstanding leaders in science and technology. Collins is also a Fellow of the American Physical Society, the Institute of Physics, and the American Institute for Medical and Biological Engineering. In 2003, he received a MacArthur Foundation \"Genius Award\", becoming the first bioengineer to receive this honor. Collins' award citation noted, \"Throughout his research, Collins demonstrates a proclivity for identifying abstract principles that underlie complex biological phenomena and for using these concepts to solve concrete, practical problems.\". He was also honored as a Medical All-Star by the Boston Red Sox, and threw out the first pitch at a Red Sox game in Fenway Park. In 2016, Collins was named an Allen Distinguished Investigator by the Paul G. Allen Frontiers Group. Collins is an elected member of all three U.S. national academies - the National Academy of Sciences, the National Academy of Engineering, and the National Academy of Medicine. He is also an elected fellow of the American Academy of Arts and Sciences, as well as a charter fellow of the National Academy of Inventors.\n\nCollins is a gifted and committed teacher. He has won numerous teaching awards at Boston University, including the Biomedical Engineering Teacher of the Year Award, the College of Engineering Professor of the Year Award, and the Metcalf Cup and Prize for Excellence in Teaching, which is the highest teaching honor awarded by Boston University.\n\nCollins has been involved with a number of start-up companies, and his inventions and technologies have been licensed by several biotech and medical device companies. Collins is the scientific co-founder and currently chairs the Scientific Advisory Board (SAB) of Sample6 Technologies, Synlogic and EnBiotix. He serves on the Board of Directors of Fulcrum Therapeutics and the SAB of Agilis Biotherapeutics, Evelo Biosciences, enEvolv, Indigo Agriculture, Joule Unlimited, PureTech Health and Excel Medical Ventures. Additionally, he has served on the SAB of Mannkind Corporation, Seres Health, Codon Devices, Selventa, Gene Network Sciences, Epitome Biosystems, Afferent Corp, Cellicon Biotechnologies, Synereca Pharmaceuticals, LifeWave Ltd, and Bios Group Inc. Collins has also served as a science advisor to Unilever, Lifebuoy, Agilent, Momenta Pharmaceuticals, the New England Patriots, and Brooks Sports.\n\nCollins ran track and cross country at Holy Cross (he was a 4:17 miler), and earned a blue playing for the varsity basketball team at the University of Oxford.\n\nCollins has pioneered the development and use of nonlinear dynamical approaches to study, mimic and improve biological function, and helped to transform biology into an engineering science. His current research interests include: synthetic biology - modeling, designing and constructing synthetic gene networks, and systems biology - reverse engineering naturally occurring gene regulatory networks.\n\nCollins has invented a number of novel devices and techniques, including vibrating insoles for enhancing balance, a prokaryotic riboregulator, bistable genetic toggle switches for biotechnology and bioenergy applications, dynamical control techniques for eliminating cardiac arrhythmias, and systems biology techniques for identifying drug targets and disease mediators.\n\nCollins proposed that input noise could be used to enhance sensory function and motor control in humans. He and collaborators showed that touch sensation and balance control in young and older adults, patients with stroke, and patients with diabetic neuropathy could be improved with the application of sub-sensory mechanical noise, e.g., via vibrating insoles. This work has led to the creation of a new class of medical devices to address complications resulting from diabetic neuropathy, restore brain function following stroke, and improve elderly balance.\n\nCollins has pioneered the use of techniques from nonlinear dynamics and molecular biology to model, design and construct engineered gene networks, leading to the development of the field of synthetic biology. Collins and collaborators have created genetic toggle switches, RNA switches, genetic counters, programmable cells, tunable mammalian genetic switches, and engineered bacteriophage, each with broad applications in biotechnology and biomedicine.\n\nCollins is also one of the leading researchers in systems biology, pioneering the use of experimental-computational biophysical techniques to reverse engineer and analyze endogenous gene regulatory networks. Collins and collaborators showed that reverse-engineered gene networks can be used to identify drug targets, biological mediators and disease biomarkers.\n\nCollins and collaborators discovered, using systems biology approaches, that all classes of bactericidal antibiotics induce a common oxidative damage cellular death pathway.\n\n"}
{"id": "38026561", "url": "https://en.wikipedia.org/wiki?curid=38026561", "title": "Judith Chacón", "text": "Judith Chacón\n\nJudith Andrea Chacón Ozuriaga (January 29, 1986October 27, 2009) was a Venezuelan weightlifter. Chacon represented Venezuela at the 2008 Summer Olympics in Beijing, where she competed for the women's featherweight category (53 kg). Chacon placed last out of nine weightlifters in this event, as she successfully lifted 80 kg in the single-motion snatch, and hoisted 101 kg in the two-part, shoulder-to-overhead clean and jerk, for a total of 181 kg. Her performance in weightlifting was also a top finish for Venezuela at these games. Shortly after the Olympics, she had briefly retired from weightlifting because of pregnancy.\n\nOn October 27, 2009, Chacon died from pregnancy-related complications, including the H1N1 flu virus in her birthplace Caracas. According to Eddy Suarez, president of Venezuelan Weightlifting Federation, he regretted the sudden demise of Chacon, who would have been admitted to the hospital immediately for further treatment and speedy recovery. Following her death, the doctors managed to save her daughter from infection, and placed her in a special care.\n\n"}
{"id": "7108702", "url": "https://en.wikipedia.org/wiki?curid=7108702", "title": "Karma in Jainism", "text": "Karma in Jainism\n\nKarma is the basic principle within an overarching psycho-cosmology in Jainism. Human moral actions form the basis of the transmigration of the soul ('). The soul is constrained to a cycle of rebirth, trapped within the temporal world ('), until it finally achieves liberation (\"\"). Liberation is achieved by following a path of purification.\n\nJains believe that karma is a physical substance that is everywhere in the universe. Karma particles are attracted to the soul by the actions of that soul. Karma particles are attracted when we do, think, or say things, when we kill something, when we lie, when we steal and so on. Karma not only encompasses the causality of transmigration, but is also conceived of as an extremely subtle matter, which infiltrates the soul—obscuring its natural, transparent and pure qualities. Karma is thought of as a kind of pollution, that taints the soul with various colours (\"leśyā\"). Based on its karma, a soul undergoes transmigration and reincarnates in various states of existence—like heavens or hells, or as humans or animals.\n\nJains cite inequalities, sufferings, and pain as evidence for the existence of karma. Various types of karma are classified according to their effects on the potency of the soul. The Jain theory seeks to explain the karmic process by specifying the various causes of karmic influx (\"āsrava\") and bondage (\"bandha\"), placing equal emphasis on deeds themselves, and the intentions behind those deeds. The Jain karmic theory attaches great responsibility to individual actions, and eliminates any reliance on some supposed existence of divine grace or retribution. The Jain doctrine also holds that it is possible for us to both modify our karma, and to obtain release from it, through the austerities and purity of conduct.\n\nAccording to Jains, all souls are intrinsically pure in their inherent and ideal state, possessing the qualities of infinite knowledge, infinite perception, infinite bliss and infinite energy. However, in contemporary experience, these qualities are found to be defiled and obstructed, on account of the association of these souls with karma. The soul has been associated with karma in this way throughout an eternity of beginning-less time. This bondage of the soul is explained in the Jain texts by analogy with gold ore, which—in its natural state—is always found unrefined of admixture with impurities. Similarly, the ideally pure state of the soul has always been overlaid with the impurities of karma. This analogy with gold ore is also taken one step further: the purification of the soul can be achieved if the proper methods of refining are applied. Over the centuries, Jain monks have developed a large and sophisticated corpus of literature describing the nature of the soul, various aspects of the working of karma, and the ways and means of attaining \"\".\n\nJainism speaks of karmic \"dirt\", as karma is thought to be manifest as very subtle and sensually imperceptible particles pervading the entire universe. They are so small that one space-point—the smallest possible extent of space—contains an infinite number of karmic particles (or quantity of karmic dirt). It is these karmic particles that adhere to the soul and affect its natural potency. This material karma is called \"dravya karma\"; and the resultant emotions—pleasure, pain, love, hatred, and so on—experienced by the soul are called \"bhava karma\", psychic karma. The relationship between the material and psychic karma is that of cause and effect. The material karma gives rise to the feelings and emotions in worldly souls, which—in turn—give rise to psychic karma, causing emotional modifications within the soul. These emotions, yet again, result in influx and bondage of fresh material karma. Jains hold that the karmic matter is actually an agent that enables the consciousness to act within the material context of this universe. They are the material carrier of a soul's desire to physically experience this world. When attracted to the consciousness, they are stored in an interactive karmic field called \"\", which emanates from the soul. Thus, karma is a subtle matter surrounding the consciousness of a soul. When these two components—consciousness and ripened karma—interact, the soul experiences life as known in the present material universe.\n\nAccording to Indologist Robert J. Zydenbos, karma is a system of natural laws, where actions that carry moral significance are considered to cause certain consequences in the same way as physical actions. When one holds an apple and then lets it go, the apple will fall. There is no judge, and no moral judgment involved, since this is a mechanical consequence of the physical action. In the same manner, consequences occur naturally when one utters a lie, steals something, commits senseless violence or leads a life of debauchery. Rather than assume that these consequences—the moral rewards and retributions—are a work of some divine judge, Jains believe that there is an innate moral order in the cosmos, self-regulating through the workings of the law of karma. Morality and ethics are important in Jainism not because of a God, but because a life led in agreement with moral and ethical principles (\"mahavrata\") is considered beneficial: it leads to a decrease—and finally to the total loss of—karma, which in turn leads to everlasting happiness. The Jain conception of karma takes away the responsibility for salvation from God and bestows it on man himself. In the words of the Jain scholar, J. L. Jaini:\n\nAccording to Jainism, karmic consequences are unerringly certain and inescapable. No divine grace can save a person from experiencing them. Only the practice of austerities and self-control can modify or alleviate the consequences of karma. Even then, in some cases, there is no option but to accept karma with equanimity. The second-century Jain text, \"Bhagavatī Ārādhanā\" (verse no. 1616) sums up the predominance of karma in Jain doctrine: This predominance of karma is a theme often explored by Jain ascetics in the literature they have produced, throughout all centuries. Paul Dundas notes that the ascetics often used cautionary tales to underline the full karmic implications of morally incorrect modes of life, or excessively intense emotional relationships. However, he notes that such narratives were often softened by concluding statements about the transforming effects of the protagonists' pious actions, and their eventual attainment of liberation.\n\nThe biographies of legendary persons like Rama and Krishna, in the Jain versions of the epics \"Ramayana\" and \"Mahabharata\",\nalso have karma as one of the major themes. The major events, characters and circumstances are explained by reference to their past lives, with examples of specific actions of particular intensity in one life determining events in the next. Jain texts narrate how even Māhavīra, one of the most popular propagators of Jainism and the 24th ' (ford-maker), had to bear the brunt of his previous karma before attaining \"kevala jñāna\" (enlightenment). He attained it only after bearing twelve years of severe austerity with detachment. The \"\" speaks of how Māhavīra bore his karma with complete equanimity, as follows:\n\nKarma forms a central and fundamental part of Jain faith, being intricately connected to other of its philosophical concepts like transmigration, reincarnation, liberation, non-violence (\"ahiṃsā\") and non-attachment, among others. Actions are seen to have consequences: some immediate, some delayed, even into future incarnations. So the doctrine of karma is not considered simply in relation to one life-time, but also in relation to both future incarnations and past lives. \"Uttarādhyayana-sūtra\" 3.3–4 states:\nThe text further states (32.7):\nThere is no retribution, judgment or reward involved but a natural consequences of the choices in life made either knowingly or unknowingly. Hence, whatever suffering or pleasure that a soul may be experiencing in its present life is on account of choices that it has made in the past. As a result of this doctrine, Jainism attributes supreme importance to pure thinking and moral behavior.\n\nThe Jain texts postulate four \"gatis\", that is states-of-existence or birth-categories, within which the soul transmigrates. The four \"gatis\" are: \"deva\" (demi-gods), \"manuṣya\" (humans), \"nāraki\" (hell beings) and \"tiryañca\" (animals, plants and micro-organisms). The four \"gatis\" have four corresponding realms or habitation levels in the vertically tiered Jain universe: demi-gods occupy the higher levels where the heavens are situated; humans, plants and animals occupy the middle levels; and hellish beings occupy the lower levels where seven hells are situated.\n\nSingle-sensed souls, however, called \"nigoda\", and element-bodied souls pervade all tiers of this universe. \"Nigodas\" are souls at the bottom end of the existential hierarchy. They are so tiny and undifferentiated, that they lack even individual bodies, living in colonies. According to Jain texts, this infinity of \"nigodas\" can also be found in plant tissues, root vegetables and animal bodies. Depending on its karma, a soul transmigrates and reincarnates within the scope of this cosmology of destinies. The four main destinies are further divided into sub-categories and still smaller sub–sub categories. In all, Jain texts speak of a cycle of 8.4 million birth destinies in which souls find themselves again and again as they cycle within \"samsara\".\n\nIn Jainism, God has no role to play in an individual's destiny; one's personal destiny is not seen as a consequence of any system of reward or punishment, but rather as a result of its own personal karma. A text from a volume of the ancient Jain canon, \"Bhagvati sūtra\" 8.9.9, links specific states of existence to specific karmas. Violent deeds, killing of creatures having five sense organs, eating fish, and so on, lead to rebirth in hell. Deception, fraud and falsehood leads to rebirth in the animal and vegetable world. Kindness, compassion and humble character result in human birth; while austerities and the making and keeping of vows leads to rebirth in heaven.\n\nAccording to the Jain theory of karma, the karmic matter imparts a colour (\"leśyā\") to the soul, depending on the mental activities behind an action. The coloring of the soul is explained through the analogy of crystal, that acquires the color of the matter associated with it. In the same way, the soul also reflects the qualities of taste, smell and touch of associated karmic matter, although it is usually the colour that is referred to when discussing the \"leśyās\". \"Uttarādhyayana-sūtra\" 34.3 speaks of six main categories of \"leśyā\" represented by six colours: black, blue, grey, yellow, red and white. The black, blue and grey are inauspicious \"leśyā\", leading to the soul being born into misfortunes. The yellow, red and white are auspicious \"leśyās\", that lead to the soul being born into good fortune. \"Uttarādhyayana-sūtra\" describes the mental disposition of persons having black and white \"leśyās\":\n\nThe Jain texts further illustrate the effects of \"leśyās\" on the mental dispositions of a soul, using an example of the reactions of six travellers on seeing a fruit-bearing tree. They see a tree laden with fruit and begin to think of getting those fruits: one of them suggests uprooting the entire tree and eating the fruit; the second one suggests cutting the trunk of the tree; the third one suggests simply cutting the branches; the fourth one suggests cutting the twigs and sparing the branches and the tree; the fifth one suggests plucking only the fruits; the sixth one suggests picking up only the fruits that have fallen down. The thoughts, words and bodily activities of each of these six travellers are different based on their mental dispositions and are respectively illustrative of the six \"leśyās\". At one extreme, the person with the black \"leśyā\", having evil disposition, thinks of uprooting the whole tree even though he wants to eat only one fruit. At the other extreme, the person with the white \"leśyā\", having a pure disposition, thinks of picking up the fallen fruit, in order to spare the tree.\n\nThe role of intent is one of the most important and definitive elements of the karma theory, in all its traditions. In Jainism, intent is important but not an essential precondition of sin or wrong conduct. Evil intent forms only one of the modes of committing sin. Any action committed, knowingly or \"unknowingly\", has karmic repercussions. In certain philosophies, like Buddhism, a person is guilty of violence only if he had an intention to commit violence. On the other hand, according to Jains, if an act produces violence, then the person is guilty of it, whether or not he had an intention to commit it.\n\nJohn Koller explains the role of intent in Jainism with the example of a monk, who unknowingly offered poisoned food to his brethren. According to the Jain view, the monk is guilty of a violent act if the other monks die because they eat the poisoned food; but according to the Buddhist view he would not be guilty. The crucial difference between the two views is that the Buddhist view excuses the act, categorizing it as non-intentional, since he was not aware that the food was poisoned; whereas the Jain view holds the monk to have been responsible, due to his ignorance and carelessness. Jains argue that the monk's very ignorance and carelessness constitute an intent to do violence and hence entail his guilt. So the absence of intent does not absolve a person from the karmic \"consequences\" of guilt either, according to the Jain analysis.\n\nIntent is a function of kaṣāya, which refers to negative emotions and negative qualities of mental (or deliberative) action. The presence of intent acts as an aggravating factor, increasing the vibrations of the soul, which results in the soul absorbing more karma. This is explained by \"Tattvārthasūtra\" 6.7: \"[The] intentional act produces a strong karmic bondage and [the] unintentional produces weak, shortlived karmic bondage.\" Similarly, the physical act is also not a necessary condition for karma to bind to the soul: the existence of intent alone is sufficient. This is explained by Kundakunda (1st Century CE) in \"Samayasāra\" 262–263: \"The intent to kill, to steal, to be unchaste and to acquire property, whether these offences are actually carried or not, leads to bondage of evil karmas.\" Jainism thus places an equal emphasis on the physical act as well as intent for binding of karmas.\n\nAlthough the doctrine of karma is central to all Indian religions, it is difficult to say when and where in India the concept of karma originated. In Jainism, it is assumed its development took place in an era from which the literary documents are not available, since the basics of this doctrine were present and concluded even in the earliest documents of Jains. \"Acaranga Sutra\" and \"Sutrakritanga\", contain a general outline of the doctrines of karma and reincarnation. The roots of this doctrine in Jainism might be in the teachings of Parsva, who is said to have lived about two hundred fifty years before Mahavira. The Jain conception of karma—as something material that encumbers the soul—has an archaic nature which justifies the hypothesis that it goes back to 8th or 9th century BCE.\n\nThe present form of the doctrine seems to be unchanged at least since the time of Bhadrabahu (c. 300 BCE) who is respected by both the sects. This is supported by the fact that both Svetambara and Digambara sects agree on the basic doctrine, giving indication that it reached in its present form before the schism took place. Bhadrabahu is usually seen as the last leader of united Jain sangh. Detailed codification of types of karma and their effects were attested by Umasvati who is regarded by both Digambara and Svetambara as one of theirs.\n\nJain and Buddhist scholar Padmanabh Jaini observes: \n\nWith regards to the influence of the theory of karma on development of various religious and social practices in ancient India, Dr. Padmanabh Jaini states: \n\nThe Jain socio-religious practices like regular fasting, practicing severe austerities and penances, the ritual death of \"Sallekhana\" and rejection of God as the creator and operator of the universe can all be linked to the Jain theory of karma. Jaini notes that the disagreement over the karmic theory of transmigration resulted in the social distinction between the Jains and their Hindu neighbours. Thus one of the most important Hindu rituals, \"śrāddha\" was not only rejected but strongly criticized by the Jains as superstition. Certain authors have also noted the strong influence of the concept of karma on the Jain ethics, especially the ethics of non-violence. Once the doctrine of transmigration of souls came to include rebirth on earth in animal as well as human form, depending upon one's karmas, it is quite probable that, it created a humanitarian sentiment of kinship amongst all life forms and thus contributed to the notion of \"\" (non-violence).\n\nThe nature of experience of the effects of the karma depends on the following four factors:\nBoth emotions and activity play a part in binding of karmas. Duration and intensity of the karmic bond are determined by emotions or \"\" and type and quantity of the karmas bound is depended on \"yoga\" or activity.\n\nThe karmic process in Jainism is based on seven truths or fundamental principles (\"tattva\") of Jainism which explain the human predicament. Out that the seven \"tattvas\", the four—influx (\"āsrava\"), bondage (\"bandha\"), stoppage (\"saṃvara\") and release (\"nirjarā\")—pertain to the karmic process.\n\nThe karmic bondage occurs as a result of the following two processes: \"āsrava\" and \"bandha\". \"Āsrava\" is the inflow of karma. The karmic influx occurs when the particles are attracted to the soul on account of \"yoga\". \"Yoga\" is the vibrations of the soul due to activities of mind, speech and body. However, the \"yoga\" alone do not produce bondage. The karmas have effect only when they are bound to the consciousness. This binding of the karma to the consciousness is called \"bandha\". Out of the many causes of bondage, emotions or passions are considered as the main cause of bondage. The karmas are literally bound on account of the stickiness of the soul due to existence of various passions or mental dispositions. The passions like anger, pride, deceit and greed are called sticky (\"kaṣāyas\") because they act like glue in making karmic particles stick to the soul resulting in \"bandha\". The karmic inflow on account of \"yoga\" driven by passions and emotions cause a long term inflow of karma prolonging the cycle of reincarnations. On the other hand, the karmic inflows on account of actions that are not driven by passions and emotions have only a transient, short-lived karmic effect. Hence the ancient Jain texts talk of subduing these negative emotions:\nThe Jain theory of karma proposes that karma particles are attracted and then bound to the consciousness of souls by a combination of four factors pertaining to actions: instrumentality, process, modality and motivation.\n\nAll actions have the above four factor present in them. When different permutations of the sub-elements of the four factors are calculated, the Jain teachers speak of 108 ways in which the karmic matter can be attracted to the soul. Even giving silent assent or endorsement to acts of violence from far away has karmic consequences for the soul. Hence, the scriptures advise carefulness in actions, awareness of the world, and purity in thoughts as means to avoid the burden of karma.\n\nAccording to the major Jain text, \"Tattvartha sutra\":\n\nThe causes of \"bandha\" or the karmic bondage—in the order they are required to be eliminated by a soul for spiritual progress—are:\n\nEach cause presupposes the existence of the next cause, but the next cause does not necessarily pre-suppose the existence of the previous cause. A soul is able to advance on the spiritual ladder called \"\", only when it is able to eliminate the above causes of bondage one by one.\n\nThe consequences of karma are inevitable, though they may take some time to take effect. To explain this, a Jain monk, Ratnaprabhacharya says: \n\nThe latent karma becomes active and bears fruit when the supportive conditions arise. A great part of attracted karma bears its consequences with minor fleeting effects, as generally most of our activities are influenced by mild negative emotions. However, those actions that are influenced by intense negative emotions cause an equally strong karmic attachment which usually does not bear fruit immediately. It takes on an inactive state and waits for the supportive conditions—like proper time, place, and environment—to arise for it to manifest and produce effects. If the supportive conditions do not arise, the respective karmas will manifest at the end of maximum period for which it can remain bound to the soul. These supportive conditions for activation of latent karmas are determined by the nature of karmas, intensity of emotional engagement at the time of binding karmas and our actual relation to time, place, surroundings. There are certain laws of precedence among the karmas, according to which the fruition of some of the karmas may be deferred but not absolutely barred.\n\nJain texts distinguish between the effect of the fruition of \"karma\" on a right believer and a wrong believer:\nAlthough the Jains believe the karmic consequences as inevitable, Jain texts also hold that a soul has energy to transform and modify the effects of karma. Karma undergoes following modifications:\n\n\nThe Jain karmic theory, thus speaks of great powers of soul to manipulate the karmas by its actions.\n\nJain philosophy assert that emancipation is not possible as long as the soul is not released from bondage of karma. This is possible by \"samvara\" (stoppage of inflow of new karmas) and \"nirjarā\" (shedding of existing karmas through conscious efforts). \"Samvara\" is achieved through practice of:\n\n\"Nirjarā\" is possible through \"tapas\", austerities and penances. \"Tapas\" can be either external or internal. Six forms of external \"tapas\" are—fasting, control of appetite, accepting food under certain conditions, renunciation of delicious food, sitting and sleeping in lonely place and renunciation of comforts. Six forms of internal \"tapas\" are—atonement, reverence, rendering of service to worthy ones, spiritual study, avoiding selfish feelings and meditation.\n\nJustice Tukol notes that the supreme importance of the doctrine of karma lies in providing a rational and satisfying explanation to the apparent unexplainable phenomenon of birth and death, of happiness and misery, of inequalities and of existence of different species of living beings. The \"Sūtrakṛtāṅga\", one of the oldest canons of Jainism, states:\n\nJains thus cite inequalities, sufferings, and pain as evidence for the existence of karma. The theory of karma is able to explain day-to-day observable phenomena such as inequality between the rich and the poor, luck, differences in lifespan, and the ability to enjoy life despite being immoral. According to Jains, such inequalities and oddities that exist even from the time of birth can be attributed to the deeds of the past lives and thus provide evidence to existence of karmas:\nThe Jain theory of karma has been challenged from an early time by the Vedanta and branches of Hindu philosophy.\nIn particular, Vedanta Hindus considered the Jain position on the supremacy and potency of karma, specifically its insistence on non-intervention by any Supreme Being in regard to the fate of souls, as \"nāstika\" or atheistic. \nFor example, in a commentary to the Brahma Sutras (III, 2, 38, and 41), Adi Sankara, argues that the original karmic actions themselves cannot bring about the proper results at some future time; neither can super sensuous, non-intelligent qualities like \"adrsta\"—an unseen force being the metaphysical link between work and its result—by themselves mediate the appropriate, justly deserved pleasure and pain. The fruits, according to him, then, must be administered through the action of a conscious agent, namely, a supreme being (Ishvara).\n\nJainism's strong emphasis on the doctrine of karma and intense asceticism was also criticised by the Buddhists. Thus, the \"Saṃyutta Nikāya\" narrates the story of Asibandhakaputta, a headman who was originally a disciple of Māhavīra. He debates with the Buddha, telling him that, according to Māhavīra (Nigaṇṭha Nātaputta), a man's fate or karma is decided by what he does habitually. The Buddha responds, considering this view to be inadequate, stating that even a habitual sinner spends more time \"not doing the sin\" and only some time actually \"doing the sin.\"\n\nIn another Buddhist text \"Majjhima Nikāya\", the Buddha criticizes Jain emphasis on the destruction of unobservable and unverifiable types of karma as a means to end suffering, rather than on eliminating evil mental states such as greed, hatred and delusion, which are observable and verifiable. In the Upālisutta dialogue of this \"Majjhima Nikāya\" text, Buddha contends with a Jain monk who asserts that bodily actions are the most criminal, in comparison to the actions of speech and mind. Buddha criticises this view, saying that the actions of \"mind\" are most criminal, and not the actions of speech or body. Buddha also criticises the Jain ascetic practice of various austerities, claiming that he, Buddha, is happier when \"not\" practising the austerities.\n\nWhile admitting the complexity and sophistication of the Jain doctrine, Padmanabh Jaini compares it with that of Hindu doctrine of rebirth and points out that the Jain seers are silent on the exact moment and mode of rebirth, that is, the re-entry of soul in womb after the death. The concept of \"nitya-nigoda\", which states that there are certain categories of souls who have always been \"nigodas\", is also criticized. According to Jainism, \"nigodas\" are lowest form of extremely microscopic beings having momentary life spans, living in colonies and pervading the entire universe. According to Jaini, the entire concept of \"nitya-nigoda\" undermines the concept of karma, as these beings clearly would not have had prior opportunity to perform any karmically meaningful actions.\n\nKarma is also criticised on the grounds that it leads to the dampening of spirits with men suffering the ills of life because the course of one's life is determined by karma. It is often maintained that the impression of karma as the accumulation of a mountain of bad deeds looming over our heads without any recourse leads to fatalism. However, as Paul Dundas puts it, the Jain theory of karma does not imply lack of free will or operation of total deterministic control over destinies. Furthermore, the doctrine of karma does not promote fatalism amongst its believers on account of belief in personal responsibility of actions and that austerities could expatiate the evil karmas and it was possible to attain salvation by emulating the life of the Jinas.\n\n\n\n"}
{"id": "1338334", "url": "https://en.wikipedia.org/wiki?curid=1338334", "title": "Kumonga", "text": "Kumonga\n\nKumonga can shoot a spider web and deploy a poison stinger from between the Chelicerae, and boasts prehensile pedipalps that can be used to grab small prey. The Showa version was able to survive multiple direct hits from Godzilla's atomic breath. The Millennium Kumonga's web was able to expand on contact with air from a single thread into a net for incapacitating foes (see \"Scytodidae\" for a real-world example of a spider which can spit webbing in a way similar to Kumonga). In addition, the Millennium version was able to leap hundreds of meters at a time, much like a jumping spider (\"Salticidae\").\n\nIn the Showa series, Kumonga is a giant mutant spider who was initially found on Sogell Island. It first appears after having trapped Minilla and a Kamacuras in its web. Kumonga kills Kamacuras with his stinger. Godzilla soon arrives and defeats the monster spider, burning it to a crisp with his and Minilla's atomic breath.\n\nLater, Kumonga - a different individual from the same species - is placed on Monsterland, where it lives with all the other remaining monsters on the Earth. In 1999, aliens known as the Kilaaks capture the monstrous spider and release it along with the rest of Earth's monsters on the planet's major cities. In the end, Kumonga is freed from the aliens' control and takes part in the final battle against the Kilaak-controlled King Ghidorah, disabling the space monster's ability to fly in concert with the larval Mothra through use of their webbing and silk. Kumonga and the other monsters return to Monsterland to live out the rest of their days in peace.\n\nThe Showa Kumonga was 45 meters (150 feet) tall and weighed 8,000 metric tons (8,818 short tons).\n\nKumonga is one of the monsters featured in the 2004 film \"\" as one of the many mind-controlled monsters of the Xilians. This version of Kumonga is more reminiscent to a standard spider and less to a tarantula than its Showa counterpart, featuring less hair and a set of pronounced yellow stripes along its legs. When Godzilla is freed from Area G, Kumonga is released in New Guinea to battle him. At first, Kumonga is able to outmaneuver and trap Godzilla with its jumps while simultaneously entangling the King of the Monsters in its thick webbing, but Godzilla manages to gain the upper hand when he grabs hold of a strand of web and swings Kumonga around in circles before throwing it. Kumonga soars across the horizon, likely to its death, and is not seen again.\n\nThe \"Final Wars\" Kumonga was 35 meters (114 feet) tall, 60 meters (196 feet), and weighed 30,000 metric tons (33,069b short tons).\n\n\n\n"}
{"id": "14286462", "url": "https://en.wikipedia.org/wiki?curid=14286462", "title": "List of disasters in New Zealand by death toll", "text": "List of disasters in New Zealand by death toll\n\nThis is a list of New Zealand disasters by death toll, listing major disasters (excluding acts of war) which occurred in New Zealand and its territories or involved a significant number of New Zealand citizens, in a specific incident, where the loss of life was 10 or more. \n\n\"NOTE: The exact number of deaths in some early New Zealand shipwrecks is not fully recorded. There may be several shipwrecks not listed here which claimed ten or more lives.\"\n\n\n"}
{"id": "462534", "url": "https://en.wikipedia.org/wiki?curid=462534", "title": "Lotka–Volterra equations", "text": "Lotka–Volterra equations\n\nThe Lotka–Volterra equations, also known as the predator–prey equations, are a pair of first-order nonlinear differential equations, frequently used to describe the dynamics of biological systems in which two species interact, one as a predator and the other as prey. The populations change through time according to the pair of equations:\nwhere\n\nThe Lotka–Volterra system of equations is an example of a Kolmogorov model, which is a more general framework that can model the dynamics of ecological systems with predator–prey interactions, competition, disease, and mutualism.\n\nThe Lotka–Volterra predator–prey model was initially proposed by Alfred J. Lotka in the theory of autocatalytic chemical reactions in 1910. This was effectively the , originally derived by Pierre François Verhulst. In 1920 Lotka extended the model, via Andrey Kolmogorov, to \"organic systems\" using a plant species and a herbivorous animal species as an example and in 1925 he utilised the equations to analyse predator–prey interactions in his book on biomathematics. The same set of equations was published in 1926 by Vito Volterra, a mathematician and physicist, who had become interested in mathematical biology. Volterra's enquiry was inspired through his interactions with the marine biologist Umberto D'Ancona, who was courting his daughter at the time and later was to become his son-in-law. D'Ancona studied the fish catches in the Adriatic Sea and had noticed that the percentage of predatory fish caught had increased during the years of World War I (1914–18). This puzzled him, as the fishing effort had been very much reduced during the war years. Volterra developed his model independently from Lotka and used it to explain d'Ancona's observation.\n\nThe model was later extended to include density-dependent prey growth and a functional response of the form developed by C. S. Holling; a model that has become known as the Rosenzweig–McArthur model. Both the Lotka–Volterra and Rosenzweig–MacArthur models have been used to explain the dynamics of natural populations of predators and prey, such as the lynx and snowshoe hare data of the Hudson's Bay Company and the moose and wolf populations in Isle Royale National Park.\n\nIn the late 1980s, an alternative to the Lotka–Volterra predator–prey model (and its common-prey-dependent generalizations) emerged, the ratio dependent or Arditi–Ginzburg model. The validity of prey- or ratio-dependent models has been much debated.\n\nThe Lotka–Volterra equations have a long history of use in economic theory; their initial application is commonly credited to Richard Goodwin in 1965 or 1967.\n\nThe Lotka–Volterra model makes a number of assumptions, not necessarily realizable in nature, about the environment and evolution of the predator and prey populations:\n\nAs differential equations are used, the solution is deterministic and continuous. This, in turn, implies that the generations of both the predator and prey are continually overlapping.\nWhen multiplied out, the prey equation becomes\n\nThe prey are assumed to have an unlimited food supply and to reproduce exponentially, unless subject to predation; this exponential growth is represented in the equation above by the term \"αx\". The rate of predation upon the prey is assumed to be proportional to the rate at which the predators and the prey meet, this is represented above by \"βxy\". If either or is zero, then there can be no predation.\n\nWith these two terms the equation above can be interpreted as follows: the rate of change of the prey's population is given by its own growth rate minus the rate at which it is preyed upon.\n\nThe predator equation becomes\n\nIn this equation, \"δxy\" represents the growth of the predator population. (Note the similarity to the predation rate; however, a different constant is used, as the rate at which the predator population grows is not necessarily equal to the rate at which it consumes the prey). \"γy\" represents the loss rate of the predators due to either natural death or emigration, it leads to an exponential decay in the absence of prey.\n\nHence the equation expresses that the rate of change of the predator's population depends upon the rate at which it consumes prey, minus its intrinsic death rate.\n\nThe equations have periodic solutions and do not have a simple expression in terms of the usual trigonometric functions, although they are quite tractable.\n\nIf none of the non-negative parameters vanishes, three can be absorbed into the normalization of variables to leave only one parameter: since the first equation is homogeneous in , and the second one in , the parameters \"β\"/\"α\" and \"δ\"/\"γ\" are absorbable in the normalizations of and respectively, and into the normalization of , so that only remains arbitrary. It is the only parameter affecting the nature of the solutions.\n\nA linearization of the equations yields a solution similar to simple harmonic motion with the population of predators trailing that of prey by 90° in the cycle.\n\nSuppose there are two species of animals, a baboon (prey) and a cheetah (predator). If the initial conditions are 80 baboons and 40 cheetahs, one can plot the progression of the two species over time. The choice of time interval is arbitrary.\nOne may also plot solutions parametrically as orbits in phase space, without representing time, but with one axis representing the number of prey and the other axis representing the number of predators for all times.\n\nThis corresponds to eliminating time from the two differential equations above to produce a single differential equation\nrelating the variables \"x\" and \"y\". The solutions of this equation are closed curves. It is amenable to separation of variables: integrating\nyields the implicit relationship \nwhere \"V\" is a constant quantity depending on the initial conditions and conserved on each curve.\n\nAn aside: These graphs illustrate a serious potential problem with this \"as a biological model\": For this specific choice of parameters, in each cycle, the baboon population is reduced to extremely low numbers, yet recovers (while the cheetah population remains sizeable at the lowest baboon density). In real-life situations, however, chance fluctuations of the discrete numbers of individuals, as well as the family structure and life-cycle of baboons, might cause the baboons to actually go extinct, and, by consequence, the cheetahs as well. This modelling problem has been called the \"atto-fox problem\", an atto-<nowiki>fox</nowiki> being a notional 10 of a fox.\n\nA less extreme example covers: \nIn the model system, the predators thrive when there are plentiful prey but, ultimately, outstrip their food supply and decline. As the predator population is low, the prey population will increase again. These dynamics continue in a cycle of growth and decline.\n\nPopulation equilibrium occurs in the model when neither of the population levels is changing, i.e. when both of the derivatives are equal to 0:\n\nThe above system of equations yields two solutions:\n\nand\n\nHence, there are two equilibria.\n\nThe first solution effectively represents the extinction of both species. If both populations are at 0, then they will continue to be so indefinitely. The second solution represents a fixed point at which both populations sustain their current, non-zero numbers, and, in the simplified model, do so indefinitely. The levels of population at which this equilibrium is achieved depend on the chosen values of the parameters \"α\", \"β\", \"γ\", and \"δ\".\n\nThe stability of the fixed point at the origin can be determined by performing a linearization using partial derivatives.\n\nThe Jacobian matrix of the predator–prey model is\n\nand is known as community matrix.\n\nWhen evaluated at the steady state of (0, 0), the Jacobian matrix \"J\" becomes\n\nThe eigenvalues of this matrix are\n\nIn the model \"α\" and \"γ\" are always greater than zero, and as such the sign of the eigenvalues above will always differ. Hence the fixed point at the origin is a saddle point.\n\nThe stability of this fixed point is of significance. If it were stable, non-zero populations might be attracted towards it, and as such the dynamics of the system might lead towards the extinction of both species for many cases of initial population levels. However, as the fixed point at the origin is a saddle point, and hence unstable, it follows that the extinction of both species is difficult in the model. (In fact, this could only occur if the prey were artificially completely eradicated, causing the predators to die of starvation. If the predators were eradicated, the prey population would grow without bound in this simple model.) The populations of prey and predator can get infinitesimally close to zero and still recover.\n\nEvaluating \"J\" at the second fixed point leads to\n\nThe eigenvalues of this matrix are\n\nAs the eigenvalues are both purely imaginary and conjugate to each others, this fixed point is elliptic, so the solutions are periodic, oscillating on a small ellipse around the fixed point, with a period formula_18.\n\nAs illustrated in the circulating oscillations in the figure above, the level curves are closed orbits surrounding the fixed point: the levels of the predator and prey populations cycle and oscillate without damping around the fixed point with period formula_19.\n\nThe value of the constant of motion \"V\", or, equivalently, \"K\" = exp(\"V\"), formula_20, can be found for the closed orbits near the fixed point.\n\nIncreasing \"K\" moves a closed orbit closer to the fixed point. The largest value of the constant \"K\" is obtained by solving the optimization problem\nThe maximal value of \"K\" is thus attained at the stationary (fixed) point formula_22 and amounts to \nwhere \"e\" is Euler's number.\n\n\n\n"}
{"id": "24458855", "url": "https://en.wikipedia.org/wiki?curid=24458855", "title": "Maternal Health Task Force", "text": "Maternal Health Task Force\n\nLaunched in 2008 with funding from the Bill & Melinda Gates Foundation, the Maternal Health Task Force (MHTF) is a global project focused on improving maternal health through better coordination, communication, and facilitation between existing maternal health organizations, as well as with experts in related fields. The Task Force serves as a catalyst to address one of the most neglected areas in global health.\n\nMaternal morbidity and mortality rates remain unacceptably high across the developing world. Every minute, a woman dies from complications related to childbirth or pregnancy. While most maternal deaths are preventable, poor health services and scarce resources limit women’s access to life-saving, high-quality care. Although there have been some notable advances, efforts to adequately address maternal health remain fragmented, and the political will remains insufficient to effectively tackle the issues.\n\nRecognizing that real progress requires better coordination and increased global attention, the Maternal Health Task Force brings together existing maternal health networks and engages new organizations to facilitate global coordination of maternal health programs. The Task Force does not duplicate or replace existing projects, but plays a complementary role by convening stakeholders and creating an inclusive setting to engage in dialogue, build consensus, and share information.\n\nThe Task Force provides a new forum dedicated specifically to maternal health, while reaching out to leaders from allied fields—including neonatal and child health, reproductive health, human rights, and HIV/AIDS—to devise innovative solutions to maternal morbidity and mortality. As a key component of the initiative, partners in developing countries play a central role in setting the agenda. The Task Force works very closely with the Partnership for Maternal, Newborn and Child Health and other critical partners in this field.\n\nThe MHTF will engage organizations, individuals, and other partners that work at both theglobal and country level. It will also reach out to organizations and individuals in allied fields, such as family planning, reproductive health, HIV/AIDS, newborn and child health, education, human rights and others in order to both contribute to their work and learn from their expertise. The MHTF will coordinate a set of activities identified as priorities for the maternal health field, promote collaboration among its constituents, and catalyze action around three thematic areas:\n\n\n"}
{"id": "18875", "url": "https://en.wikipedia.org/wiki?curid=18875", "title": "Mental event", "text": "Mental event\n\nA mental event is anything which happens within the mind or mind substitute of a conscious individual. Examples include thoughts, feelings, decisions, dreams, and realizations.\n\nSome believe that mental events are not limited to human thought but can be associated with animals and artificial intelligence as well. Whether mental events are identical to complex physical events, or whether such an identity even makes sense, is central to the mind-body problem.\n\nSome state that the mental and the physical are the very same property which cause any event(s). This view is known as substance monism. An opposing view is substance dualism, which claims that the mental and physical are fundamentally different and can exist independently.\n\nPhysicalism, a form of substance monism, states that everything that exists is either physical or depends on that which is physical. The existence of mental events has been used by philosophers as an argument against physicalism. For example, in his 1974 paper \"What Is it Like to Be a Bat?\", Thomas Nagel argues that physicalist theories of mind cannot explain an organism’s subjective experience because they cannot account for its mental events.\n\n\n\n"}
{"id": "19391", "url": "https://en.wikipedia.org/wiki?curid=19391", "title": "Midwifery", "text": "Midwifery\n\nMidwifery is the health science and health profession that deals with pregnancy, childbirth, and the postpartum period (including care of the newborn), in addition to the sexual and reproductive health of women throughout their lives. In many countries, midwifery is a medical profession (special for its independent and direct specialized education; should not be confused with the medical specialty, which depends on a previous general training). A professional in midwifery is known as a midwife.\n\nA 2013 Cochrane review concluded that \"most women should be offered midwifery-led continuity models of care and women should be encouraged to ask for this option although caution should be exercised in applying this advice to women with substantial medical or obstetric complications.\" The review found that midwifery-led care was associated with a reduction in the use of epidurals, with fewer episiotomies or instrumental births, and a decreased risk of losing the baby before 24 weeks' gestation. However, midwifery-led care was also associated with a longer mean length of labor as measured in hours.\n\nTrimester means \"3 months.\" A normal pregnancy lasts about 9 months and has 3 trimesters.\n\nFirst trimester screening varies by country. Women are typically offered a Pap smear and urine analysis (UA), and blood tests including a complete blood count (CBC), blood typing (including Rh screen), syphilis, hepatitis, HIV, and rubella testing. Additionally, women may have chlamydia testing via a urine sample, and women considered at high risk are screened for Sickle Cell disease and Thalassemia. Women must consent to all tests before they are carried out. The woman's blood pressure, height and weight are measured. Her past pregnancies and family, social, and medical history are discussed. Women may have an ultrasound scan during the first trimester which may be used to help find the estimated due date. Some women may have genetic testing, such as screening for Down's Syndrome. Diet, exercise, and discomforts such as morning sickness are discussed.\nThe mother visits the midwife monthly or more often during the second trimester. The mother's partner and/or the labor coach may accompany her. The midwife will discuss pregnancy issues such as fatigue, heartburn, varicose veins, and other common problems such as back pain.\nBlood pressure and weight are monitored and the midwife measures the mother's abdomen to see if the baby is growing as expected. Lab tests such as a UA, CBC, and glucose tolerance test are done if the midwife feels they are necessary.\n\nIn the third trimester the midwife will see the mother every two weeks until week 36 and every week after that. Weight, blood pressure, and abdominal measurements will continue to be done. Lab tests such as a CDC and UA may be done with additional testing done for at-risk pregnancies. The midwife palpates the woman's abdomen to establish the lie, presentation and position of the fetus and later, the engagement. A pelvic exam may be done to see if the mother's cervix is dilating. The midwife and the mother discuss birthing options and write a birth care plan.\n\nMidwives are qualified to assist with a normal vaginal delivery while more complicated deliveries are handled by a health care provider who has had further training. Childbirth is divided into four stages. \n\nFollowing the birth, if the mother had an episiotomy or a tearing of the perineum, it is stitched. The midwife does regular assessments for uterine contraction, fundal height, and vaginal bleeding. Throughout labor and delivery the mother's vital signs (temperature, blood pressure, and pulse) are closely monitored and her fluid intake and output are measured. The midwife also monitors the baby's pulse rate, palpates the mother's abdomen to monitor the baby's position, and does vaginal checks as needed. If the birth deviates from the norm at any stage, the midwife requests assist from a more highly trained health care provider.\n\nUntil the last century most women have used both the upright position and alternative positions to give birth. The lithotomy position was not used until the advent of forceps in the seventeenth century and since then childbirth has progressively moved from a woman supported experience in the home to a medical intervention within the hospital.\nThere are significant advantages to assuming an upright position in labor and birth, such as stronger and more efficient uterine contractions aiding cervical dilatation, increased pelvic inlet and outlet diameters and improved uterine contractility. Upright positions in the second stage include sitting, squatting, kneeling, and being on hands and knees.\n\nFor women who have a hospital birth, the minimum hospital stay is six hours. Women who leave before this do so against medical advice. Women may choose when to leave the hospital. Full postnatal assessments are conducted daily whilst inpatient, or more frequently if needed. A postnatal assessment includes the woman's observations, general well being, breasts (either a discussion and assistance with breastfeeding or a discussion about lactation suppression), abdominal palpation (if she has not had a caesarean section) to check for involution of the uterus, or a check of her caesarean wound (the dressing doesn't need to be removed for this), a check of her perineum, particularly if she tore or had stitches, reviewing her lochia, ensuring she has passed urine and had her bowels open and checking for signs and symptoms of a DVT. The baby is also checked for jaundice, signs of adequate feeding, or other concerns. The baby has a nursery exam between six and seventy two hours of birth to check for conditions such as heart defects, hip problems, or eye problems.\n\nIn the community, the community midwife sees the woman at least until day ten. This does not mean she sees the woman and baby daily, but she cannot discharge them from her care until day ten at the earliest. Postnatal checks include neonatal screening test (NST, or heel prick test) around day five. The baby is weighed and the midwife plans visits according to the health and needs of mother and baby. They are discharged to the care of the health visitor.\n\nAt birth, the baby receives an Apgar score at, at the least, one minute and five minutes of age. This is a score out of 10 that assesses the baby on five different areas—each worth between 0 and 2 points. These areas are: colour, respiratory effort, tone, heart rate, and response to stimuli. The midwife checks the baby for any obvious problems, weighs the baby, and measure head circumference. The midwife ensures the cord has been clamped securely and the baby has the appropriate name tags on (if in hospital). Babies lengths are not routinely measured. The midwife performs these checks as close to the mother as possible and returns the baby to the mother quickly. Skin-to-skin is encouraged, as this regulates the baby's heart rate, breathing, oxygen saturation, and temperature—and promotes bonding and breastfeeding.\n\nIn some countries, such as Chile, the midwife is the professional who can direct neonatal intensive care units. This is an advantage for these professionals, because this professionals can use the knowledge in perinatology to bring a high quality care of the newborn, with medical or surgical conditions.\n\nMidwifery-led continuity of care is where one or more midwives have the primary responsibility for the continuity of care for childbearing women, with a multidisciplinary network of consultation and referral with other health care providers. This is different from \"medical-led care\" where an obstetrician or family physician is primarily responsible. In \"shared-care\" models, responsibility may be shared between a midwife, an obstetrician and/or a family physician. The midwife plays a very unique role is part of very intimate situations with the mother. For this reason, many say that the most important thing to look for in a midwife is comfortability with them, as one will go to them with every question or problem.\n\nAccording to a Cochrane review of public health systems in Australia, Canada, Ireland, New Zealand and the United Kingdom, \"most women should be offered midwifery-led continuity models of care and women should be encouraged to ask for this option although caution should be exercised in applying this advice to women with substantial medical or obstetric complications.\" Midwifery-led care has effects including the following:\nThere was no difference in the number of Caesarean sections. All trials in the Cochrane review included licensed midwives, and none included lay or traditional midwives. Also, no trial included out of hospital birth.\n\nIn ancient Egypt, midwifery was a recognized female occupation, as attested by the Ebers Papyrus which dates from 1900 to 1550 BCE. Five columns of this papyrus deal with obstetrics and gynecology, especially concerning the acceleration of parturition (the action or process of giving birth to offspring) and the birth prognosis of the newborn. The Westcar papyrus, dated to 1700 BCE, includes instructions for calculating the expected date of confinement and describes different styles of birth chairs. Bas reliefs in the royal birth rooms at Luxor and other temples also attest to the heavy presence of midwifery in this culture.\n\nMidwifery in Greco-Roman antiquity covered a wide range of women, including old women who continued folk medical traditions in the villages of the Roman Empire, trained midwives who garnered their knowledge from a variety of sources, and highly trained women who were considered physicians. However, there were certain characteristics desired in a “good” midwife, as described by the physician Soranus of Ephesus in the 2nd century. He states in his work, \"Gynecology\", that “a suitable person will be literate, with her wits about her, possessed of a good memory, loving work, respectable and generally not unduly handicapped as regards her senses [i.e., sight, smell, hearing], sound of limb, robust, and, according to some people, endowed with long slim fingers and short nails at her fingertips.” Soranus also recommends that the midwife be of sympathetic disposition (although she need not have borne a child herself) and that she keep her hands soft for the comfort of both mother and child. Pliny, another physician from this time, valued nobility and a quiet and inconspicuous disposition in a midwife. There appears to have been three “grades” of midwives present: The first was technically proficient; the second may have read some of the texts on obstetrics and gynecology; but the third was highly trained and reasonably considered a medical specialist with a concentration in midwifery.\n\nAgnodice or Agnodike (Gr. Ἀγνοδίκη) was the earliest historical, and likely apocryphal, midwife mentioned among the ancient Greeks.\n\nMidwives were known by many different titles in antiquity, ranging from \"iatrinē\" (Gr. nurse), \"maia\" (Gr., midwife), \"obstetrix\" (Lat., obstetrician), and \"medica\" (Lat., doctor). It appears as though midwifery was treated differently in the Eastern end of the Mediterranean basin as opposed to the West. In the East, some women advanced beyond the profession of midwife (\"maia\") to that of gynaecologist (\"iatros gynaikeios\", translated as \"women's doctor\"), for which formal training was required. Also, there were some gynecological tracts circulating in the medical and educated circles of the East that were written by women with Greek names, although these women were few in number. Based on these facts, it would appear that midwifery in the East was a respectable profession in which respectable women could earn their livelihoods and enough esteem to publish works read and cited by male physicians. In fact, a number of Roman legal provisions strongly suggest that midwives enjoyed status and remuneration comparable to that of male doctors. One example of such a midwife is Salpe of Lemnos, who wrote on women’s diseases and was mentioned several times in the works of Pliny.\n\nHowever, in the Roman West, information about practicing midwives comes mainly from funerary epitaphs. Two hypotheses are suggested by looking at a small sample of these epitaphs. The first is the midwifery was not a profession to which freeborn women of families that had enjoyed free status of several generations were attracted; therefore it seems that most midwives were of servile origin. Second, since most of these funeral epitaphs describe the women as freed, it can be proposed that midwives were generally valued enough, and earned enough income, to be able to gain their freedom. It is not known from these epitaphs how certain slave women were selected for training as midwives. Slave girls may have been apprenticed, and it is most likely that mothers taught their daughters.\n\nThe actual duties of the midwife in antiquity consisted mainly of assisting in the birthing process, although they may also have helped with other medical problems relating to women when needed. Often, the midwife would call for the assistance of a physician when a more difficult birth was anticipated. In many cases the midwife brought along two or three assistants. In antiquity, it was believed by both midwives and physicians that a normal delivery was made easier when a woman sat upright. Therefore, during parturition, midwives brought a stool to the home where the delivery was to take place. In the seat of the birthstool was a crescent-shaped hole through which the baby would be delivered. The birthstool or chair often had armrests for the mother to grasp during the delivery. Most birthstools or chairs had backs which the patient could press against, but Soranus suggests that in some cases the chairs were backless and an assistant would stand behind the mother to support her. The midwife sat facing the mother, encouraging and supporting her through the birth, perhaps offering instruction on breathing and pushing, sometimes massaging her vaginal opening, and supporting her perineum during the delivery of the baby. The assistants may have helped by pushing downwards on the top of the mother's abdomen.\n\nFinally, the midwife received the infant, placed it in pieces of cloth, cut the umbilical cord, and cleansed the baby. The child was sprinkled with “fine and powdery salt, or natron or aphronitre” to soak up the birth residue, rinsed, and then powdered and rinsed again. Next, the midwives cleared away any and all mucus present from the nose, mouth, ears, or anus. Midwives were encouraged by Soranus to put olive oil in the baby’s eyes to cleanse away any birth residue, and to place a piece of wool soaked in olive oil over the umbilical cord. After the delivery, the midwife made the initial call on whether or not an infant was healthy and fit to rear. She inspected the newborn for congenital deformities and testing its cry to hear whether or not it was robust and hearty. Ultimately, midwives made a determination about the chances for an infant’s survival and likely recommended that a newborn with any severe deformities be exposed.\n\nA 2nd-century terracotta relief from the Ostian tomb of Scribonia Attice, wife of physician-surgeon M. Ulpius Amerimnus, details a childbirth scene. Scribonia was a midwife and the relief shows her in the midst of a delivery. A patient sits in the birth chair, gripping the handles and the midwife’s assistant stands behind her providing support. Scribonia sits on a low stool in front of the woman, modestly looking away while also assisting the delivery by dilating and massaging the vagina, as encouraged by Soranus.\n\nThe services of a midwife were not inexpensive; this fact that suggests poorer women who could not afford the services of a professional midwife often had to make do with female relatives. Many wealthier families had their own midwives. However, the vast majority of women in the Greco-Roman world very likely received their maternity care from hired midwives. They may have been highly trained or possessed only a rudimentary knowledge of obstetrics. Also, many families had a choice of whether or not they wanted to employ a midwife who practiced the traditional folk medicine or the newer methods of professional parturition. Like a lot of other factors in antiquity, quality gynecological care often depended heavily on the socioeconomic status of the patient.\n\nFrom the 18th century, a conflict between surgeons and midwives arose, as medical men began to assert that their modern scientific techniques were better for mothers and infants than the folk medicine practiced by midwives. \nAs doctors and medical associations pushed for a legal monopoly on obstetrical care, midwifery became outlawed or heavily regulated throughout the United States and Canada.. In Northern Europe and Russia the situation was a little easier - in Imperial Russia at the Duchy of Estonia, Professor Christian Friedrich Deutsch established a midwifery school for women at the University of Dorpat in 1811, which existed until World War I. It was the predecessor for the Tartu Health Care College. Training lasted for 7 months and in the end a certificate for practice was issued to the female students. Despite accusations that midwives were \"incompetent and ignorant\", some argued that poorly trained surgeons were far more of a danger to pregnant women. The argument that surgeons were more dangerous than midwives lasted until the study of bacteriology became popular in the early 1900s. Women began to feel safer in the setting of the hospitals with the amount of aid and the ease of birth that they experienced with doctors. “Physicians trained in the new century found a great contrast between their hospital and obstetrics practice in women’s homes where they could not maintain sterile conditions or have trained help.” German social scientists Gunnar Heinsohn and Otto Steiger theorize that midwifery became a target of persecution and repression by public authorities because midwives possessed highly specialized knowledge and skills regarding not only assisting birth, but also contraception and abortion.\n\nAt late 20th century, midwives were already recognized as highly trained and specialized professionals in obstetrics. However, at the beginning of the 21st century, the medical perception of pregnancy and childbirth as potentially pathological and dangerous still dominates Western culture. Midwives who work in hospital settings also have been influenced by this view, although by and large they are trained to view birth as a normal and healthy process. While midwives play a much larger role in the care of pregnant mothers in Europe than in America, the medicalized model of birth still has influence in those countries, even though the World Health Organization recommends a natural, normal and humanized birth.\n\nThe midwifery model of pregnancy and childbirth as a normal and healthy process plays a much larger role in Sweden and the Netherlands than the rest of Europe, however. Swedish midwives stand out, since they administer 80 percent of prenatal care and more than 80 percent of family planning services in Sweden. Midwives in Sweden attend all normal births in public hospitals and Swedish women tend to have fewer interventions in hospitals than American women. The Dutch infant mortality rate in 1992 was the tenth-lowest rate in the world, at 6.3 deaths per thousand births, while the United States ranked twenty-second. Midwives in the Netherlands and Sweden owe a great deal of their success to supportive government policies.\n\nNotes\nBibliography\n\n\n"}
{"id": "43315121", "url": "https://en.wikipedia.org/wiki?curid=43315121", "title": "Najm-e Sani", "text": "Najm-e Sani\n\nMir Yar-Ahmad Khuzani Isfahani (), better known by his honorific title of Najm-e Sani (\"The Second Star\") was a Persian nobleman from the Khuzani family, who was the third person to serve as the \"vakil\" (vicegerent) of the Safavid Empire.\n\nNajm was born during the 15th-century in Isfahan, and belonged to a prominent family which could trace its existence in Isfahan back to the 1440s. He had a brother named Mahmud Beg Khuzani. In 1509/10, Najm succeeded Amir Najm al-Din Mas'ud Gilani in the \"vakil\" office, and later in 1512, he, along with the Timurid prince Babur attacked the marauding Uzbeks, who had although suffered a heavy defeat in 1510 by Shah Ismail I, kept making incursions into the eastern Safavid province of Khorasan. It is disputed whether Najm led the attack without approval from Ismail I or not. After having crossed the Oxus River, Najm seized Qarshi, and had the city sacked and its inhabitants brutally massacred, which resulted in the death of over 1,500 men, and even children and women. A small Sayyid community was also massacred by the army of Najm, the prominent poet Maulana Binai being one of them.\n\nNajm then attacked Ghazdewan, a town near Bukhara, but was unable to capture the town. Babur then advised Najm to retreat to Qarshi in order to wait for reinforcements. Najm, however, declined, which resulted in the mutiny of several Qizilbash chieftains who had been with him during his campaign. On November, a battle ensured at Ghazdewan between the Uzbeks and what was left of the army of Najm, which resulted in his defeat and capture. He was shortly executed, and was succeeded by Abd al-Baqi Yazdi in the \"vakil\" office.\n\n"}
{"id": "2436363", "url": "https://en.wikipedia.org/wiki?curid=2436363", "title": "Neontology", "text": "Neontology\n\nNeontology is a part of biology that, in contrast to paleontology, deals with living (or, more generally, \"recent\") organisms. It is the study of extant taxa (singular: extant taxon): taxa (such as species, genera and families) with members still alive, as opposed to (all) being extinct. For example:\n\nA taxon can be classified as extinct if it is broadly agreed or certified that no members of the group are still alive. Conversely, an extinct taxon can be reclassified as extant if there are new discoveries of extant species (\"Lazarus species\"), or if previously-known extant species are reclassified as members of the taxon.\n\nMost biologists, zoologists, and botanists are in practice neontologists, and the term neontologist is used largely by paleontologists referring to non-paleontologists. Stephen Jay Gould said of neontology:\n\nAll professions maintain their parochialisms, and I trust that nonpaleontological readers will forgive our major manifestation. We are paleontologists, so we need a name to contrast ourselves with all you folks who study modern organisms in human or ecological time. You therefore become neontologists. We do recognize the unbalanced and parochial nature of this dichotomous division.\nNeontological evolutionary biology has a temporal perspective between 100 to 1000 years. Neontology's fundamental basis relies on models of natural selection as well as speciation. Neontology's methods, when compared to evolutionary paleontology, has a greater emphasis on experiments. There are more frequent discontinuities present in paleontology than in neontology, because paleontology involves extinct taxa. Neontology has organisms actually present and available to sample and perform research on. Neontology's research method uses cladistics to examine morphologies and genetics. Neontology data has more emphasis on genetic data and the population structure than paleontology does.\n\nWhen the scientific community accepted the synthetic theory of evolution, taxonomies became phylogenetic. As a result, information gaps arose within the fossil record of species- especially in Homo sapiens. The anthropologists who accepted the synthetic theory, reject the idea of an \"ape man\" because the concept had mistaken paleontology with neontology. An ape man, in actuality, would be a primate with traits that would represent anything in between Homo sapiens and the great apes. If the concept of an ape man was based on neontology, then our phenotype would resemble Bigfoot. Since the concept was based on paleontology, the idea of an ape man could possibly be represented by the fossil hominids.\n\nNeontology studies extant taxa and also recently extinct taxa, but declaring a taxon to be definitively extinct is difficult. Taxa that have previously been declared extinct may reappear over time. Species that were once considered extinct and then reappear unscathed are characterized by the term \"The Lazarus effect\", or are also called a Lazarus species. For example, a study determined that 36% of supposed mammalian extinction had been resolved, while the other 64% had insufficient evidence to be declared extinct or had been rediscovered. Currently, the International Union for Conservation of Nature considers a taxon to be recently extinct if the extinction occurred after 1500 C.R. The most recently considered extinct mammal was the Bouvier's red colobus monkey, who was considered extinct up until 2015 when it was rediscovered after no recorded sightings for 40 years.\n\nNeontology's fundamental theories relies on biological models of natural selection and speciation that connects genes, the unit of heredity with the mechanism of evolution, natural selection. For example, researchers utilized neontological and paleontological datasets to study mouse dentitions compared with human dentitions. In order to understand the underlying genetic mechanisms that influences this variation between nonhuman primates and humans, neontological methods are applied to the research method. By incorporating neontology with different biological research methods, it can become clear how genetic mechanisms underlie major events in things such as primate evolution.\n"}
{"id": "23014376", "url": "https://en.wikipedia.org/wiki?curid=23014376", "title": "Nier (video game)", "text": "Nier (video game)\n\nNier (stylized as NieR) is an action role-playing video game developed by Cavia and published by Square Enix for the PlayStation 3 and Xbox 360. In Japan, the game was released as for the Xbox 360, while an alternate version entitled was released for PlayStation 3 with a younger main character. A version that combined elements from both releases was in development for PlayStation Vita, but was cancelled in March 2011 due to \"Dragon Quest X\" taking precedence.\n\nThe game is a spin-off from the \"Drakengard\" series, and follows the fifth ending of the first game, the events of which have left the planet Earth in a state of decay. Set over one thousand years after this, the game puts the player in control of the titular protagonist Nier, as he attempts to find a cure for an illness, known as the Black Scrawl, to which his daughter Yonah has succumbed. Partnering with a talking book known as Grimoire Weiss, he journeys with two other characters, Kainé and Emil, as he attempts to find a remedy and understand the nature of the creatures known as Shades that stalk the world. The gameplay borrows elements from various video game genres, occasionally switching between them and the main role-playing-based gameplay.\n\nThe game was developed to appeal both to older players and to players outside Japan, where the developer was based. The music was composed by Keiichi Okabe, head of Monaca, a music composition studio, and has sparked the release of several albums. \"Nier\" was released to mixed reception; reviewers praised the story, characters and soundtrack and were mixed in their opinions of how well the disparate gameplay elements were connected. The execution of some gameplay elements was criticized, notably the side quests, and especially the graphics (which were regarded as substandard). Despite this, the game acquired acclaim among players over time, becoming a cult classic. A more successful sequel developed by PlatinumGames, titled \",\" was released in 2017 for PlayStation 4, Microsoft Windows and in 2018 for Xbox One.\n\nPlayers take control of Nier—a middle-aged man in \"Nier\" and \"Nier Gestalt\" and a teenaged boy in \"Nier Replicant\"—though the character can be renamed by the player. The player directly controls Nier through a third-person perspective to interact with people, objects, and enemies throughout the game. The player can also turn the camera around the characters, which allows for a 360° view of the surroundings. The three-dimensional world is divided into areas separated by loading screens, and the player can move freely throughout these areas by walking, running, jumping, and climbing ladders. In some rooms and buildings, the camera swings to the side and Nier is restricted to moving as in a two-dimensional platforming environment, while during certain battles the camera pulls up to simulate a top-down shoot 'em up or other video game genres.\n\nWhile traveling the player is frequently attacked by monsters, which include shadowy figures called Shades, large animals, and robots. Defeating these enemies gives the player experience points that can increase Nier's power, and money that can be used to purchase items. Nier can attack these creatures with either a one- or two-handed sword, or a spear. These weapons can be customized to have greater damage and abilities using materials that can be purchased, dropped from monsters, or scavenged around the world. Multiple different varieties of each weapon type can be acquired. The player can also use magic spells, which require enough energy from a constantly regenerating amount to cast. These spells include projectiles and large shadowy fists, among others; new spells are acquired in the first half of the game by completing specific battles. In addition to the main plotline, \"Nier\" includes numerous side-quests, which give the player experience points and money, as well as fishing and farming segments.\nThe game opens with a prologue during the summer of 2049 in a snowstorm. In a modern, broken-down grocery store, Nier fends off attacks from ethereal monsters to protect his sick young daughter, Yonah. After defeating the monsters, he checks on Yonah, who has begun to cough badly. The game then cuts to 1,312 years later, where Nier and Yonah are now living in a village built upon the ruins of an old town. The low-technology village is one of several, and is surrounded by more modern ruins such as the remnants of train tracks and industrial machinery. The areas between towns are filled with monsters known as Shades that attack travelers.\n\nAs Yonah's illness, the Black Scrawl, is terminal, Nier sets out to look for a cure. As he does, Nier finds a talking book, Grimoire Weiss, which suggests that the two team up to use Weiss' magic and to find a cure for Yonah's disease. In their search, they encounter Kainé, a hot-tempered and foul-mouthed swordswoman; and Emil, a blindfolded boy whose eyes petrify anyone they see. After journeying for a time, the village is attacked by a giant shade; the battle culminates in Yonah being carried away by a master Shade that suddenly appears—the Shadowlord—who carries his own book, Grimoire Noir.\n\nThe game then jumps five years forward. Nier and the others are trying to find the parts to a key that they believe will help them locate the Shadowlord and Grimoire Noir. After defeating five Shades and assembling the key, the team go to defeat the Shadowlord. There, Devola and Popola, characters who have been guiding Nier on his quest, appear to try to stop them. They explain that over 1300 years prior, humanity faced extinction due to an incurable disease. In an attempt to survive, they separated their souls from their bodies using Grimoire Noir and Weiss. They created clones resistant to the disease, Replicants, and intended to recombine the souls, or Gestalts, with the Replicant bodies once it had died out; Devola and Popola were androids set to oversee the project. Over time, the Replicants had begun to form their own identities; while the Gestalts, or Shades, had grown aggressive to them.\n\nNier defeats the pair, with Emil sacrificing himself to ensure his friends' progress. The remaining group then defeats the Shadowlord. It is revealed that the Shadowlord's true identity is the Gestalt form of the Nier from the prologue; the Nier the player has been controlling for the majority of the game is his Replicant. Driven to protect his Yonah, he was the first Gestalt and has combined her with the Replicant Yonah. The original Yonah, however, tells the Gestalt Nier that she can hear the new Yonah inside her, and that she loves the Replicant Nier and deserves the body just as much. She vacates the body, and Nier and Yonah are reunited.\n\nIf the player plays the game again, they start just after the five-year skip. They learn about Kainé's past, including that she is intersex, which along with the death of her parents resulted in her ostracism as a child, and that she is partially possessed by a Shade. The player gains the ability to understand what the shades are saying, including the one possessing Kainé, though in-game Nier, Weiss, and Emil are still unable to. Additional cutscenes are also shown, giving the motivations and backstory behind the Shade bosses that are fought and showing them as sentient people trying to defend their friends against Nier. The ending to the second playthrough shows that Emil survives his sacrifice, and that Gestalt Nier and Yonah are reunited in the afterlife. A third or further playthrough presents the player with a choice in the ending to save Kainé, who is seen to be dying in agony; Nier can either kill her to end her suffering (the third ending), or sacrifice his life for her (the fourth ending). The latter choice not only erases all memory of him from the other characters' minds, shown in a final cutscene, but also deletes all of the player's saved progress, as if the game had never been played. Moreover, if the player wants to start a new game, they will be unable to enter the same name chosen for the previous playthrough for the Nier character. The events of \"\" take place after this ending.\n\nThe concept that would become \"Nier\" was first proposed following the release of \"Drakengard 2\" and the reveal of seventh generation consoles. The original concept was for a third entry in the \"\"Drakengard\" series\". It was intended to be for PlayStation 3 due to the lessening importance of the PlayStation 2, which \"Drakengard 2\" had been made for. However, as the project evolved, the original ideas were reworked and the game eventually became a spin-off from the main series. Despite this, the game's director Yoko Taro continues to think of it as the third \"Drakengard\" game. Including concept planning, the total development time lasted three years, with two years spent actually developing the game. It was initially a small-scale project, but during planning it grew into a full-fledged role-playing game. Development was handled by Cavia with help from Square Enix, who had previously provided development support for the \"Drakengard\" games. Square Enix had minimal input on Yoko's vision for the game's atmosphere and story, allowing him high creative control.\n\n\"Nier\" is intended to be set over 1000 years after the events of \"Drakengard\"'s fifth ending. In this scenario, the game's protagonists Caim and Angelus travel across a dimensional boundary to fight a monstrous beast. After winning the battle and killing the monster, they are shot down by a fighter jet and killed; their introduction of magic to the world leads to magical research that results in the Black Scrawl. According to Yoko, after the dark story of \"Drakengard\", Yoko focused on more positive themes of friendship and combined effort. Much of the game was inspired by the September 11 attacks and the War on Terror. Yoko took from it the idea of a terrible event where both sides believed they were doing the right thing, and wanted to show the player multiple perspectives of the same events. The term \"Replicant\" was borrowed by Yoko from the 1982 science fiction movie \"Blade Runner\", although Yoko did not cite a particular source for Nier's name, passing it off as a codename that persisted through development.\n\nThe game's characters were designed by Kimihiko Fujisaka, who had previously worked on the main \"Drakengard\" series. Two character designs for the protagonist were created for \"Nier\". The developers believed that the Japanese audience would respond more strongly to a younger protagonist, while non-Japanese audiences would prefer an adult Nier character. Other than changing Nier's appearance and modifying a few lines of dialogue to fit with Nier being a father rather than a brother to Yonah, the developers made no changes between the two versions; while it was initially believed that the older Nier was the character's original design, an interview with Yoko clarified that the young Nier was the original vision. Many characters underwent changes during development, and some needed to be cut: there were originally thirteen Grimoires, with all but three being cut: those that remained were Weiss, Noir and Rubrum. Emil's character was derived from a female character named Halua, while Kainé was originally a far more feminine type who hid her violent nature. Yonah's original Japanese name was derived from the Biblical name Jonah: this could not be taken verbatim into its localized form due to the name being associated with a man, so the name was changed to \"Yonah\". Kainé's character was made intersexual, since the team felt it fit in with many other aspects of her gritty backstory. Kainé's status as an intersexual caused some commotion in western territories, which is something the team did not actively intend. Yoko attributed the original suggestion to female staff members working on the game.\n\nThe combat and action elements of \"Nier\" were inspired by the \"God of War\" series of games, which both Taro and Saito enjoyed. While the games had not been as popular in Japan as in North America, the two felt that the idea of having boss fights with different combat styles than the regular battles was an idea that would appeal to players in both regions. The changing styles, as well as the occasional changes in camera angle and movement, were meant to \"accentuate [the] gap between real, modern scenery and the fantasy world\" as a tie-in to the game's story. The game was meant to appeal to older players; it was intended as an action-RPG for an older market than Square Enix's action-RPG series \"Kingdom Hearts\". This influenced the decision to have a main character in his 30s, as well as more blood and swearing than typical in a Square Enix RPG. The fusion of different gameplay styles was included as a homage to earlier gameplay styles and genres.\n\n\"Nier\" was originally intended to be exclusive to the Xbox 360, but after deciding to also develop the game for PlayStation 3, the developers decided to further divide the Japanese release of the game. \"Nier Gestalt\" would be released for the Xbox 360, featuring the adult Nier (as in the international release for both platforms), while \"Nier Replicant\", for the PlayStation 3, would feature the young Nier. The localizations for the game—in English, French, and German—were produced during development so that all of the versions could be released at the same time, and so that Cavia and Square Enix could solicit feedback from North America and Europe on the game so that it would appeal to players outside Japan. \"Nier\" was officially unveiled in June 2009 at the Electronic Entertainment Expo 2009 for both the PlayStation 3 and Xbox 360, to be developed by Cavia and published by Square Enix. It was directed by Yoko and produced by Takuya Iwasaki of Cavia and Yosuke Saito of Square Enix. Due to its high violence, the game was given a CERO D rating in Japan.\n\nThe soundtrack to \"Nier\" was composed by a collaboration of the studio MoNACA, directed by Keiichi Okabe and including Kakeru Ishihama and Keigo Hoashi, and Takafumi Nishimura from Cavia. Okabe served as the lead composer and as the director for the project as a whole. Okabe was brought onto the project when the concept for the game was first being devised, and worked intermittently on the soundtrack for the next three years until its release. The music for the game was generally composed entirely separately from the development of the game. The music was designed for different motifs to appear in various arrangements throughout the soundtrack, and also to convey a sense of sadness even during the \"thrilling\" tracks. Okabe was allowed a great deal of freedom regarding what the music was to sound like; game director Yoko Taro's main request was that he use a lot of vocal works.\n\nThe soundtrack to \"Nier\" is largely composed of melancholy acoustic pieces which heavily feature vocals by vocalist Emi Evans (Emiko Rebecca Evans), a singer from England living in Tokyo. She is the singer for the band freesscape, and had previously worked on video games such as \"Etrian Odyssey\". In addition to singing, Evans was asked to write her own lyrics in futuristic languages. The composers gave her preliminary version of songs and the style they wished the language to be in, such as Gaelic or French, and she invented the words. Evans wrote songs in versions of Gaelic, Portuguese, Spanish, Italian, French, English and Japanese, where she tried to imagine what they would sound like after 1000 years of drifting.\n\nSquare Enix released a soundtrack album of music from the game, titled \"Nier Gestalt & Replicant Original Soundtrack\", on April 21, 2010. The soundtrack album reached number 24 on the Japanese Oricon music charts, and remained on the charts for 11 weeks. As preorder bonuses for \"Nier Gestalt\" and \"Nier Replicant\", two mini-albums, \"Nier Gestalt Mini Album\" and \"Nier Replicant Mini Album\", were included. An album of arranged music, \"NieR Gestalt & Replicant 15 Nightmares & Arrange Tracks\", was published by Square Enix on December 8, 2010. The arranged album reached number 59 on the Oricon music charts, a position it held for a week. Another album, \"NieR Tribute Album -echo-\", was released on September 14, 2011, and an album of piano arrangements, \"Piano Collections Nier Gestalt & Replicant\", was published on March 21, 2012.\n\nIn Japan, \"Nier Gestalt\" sold over 12,500 copies in Japan the week of its release, while \"Replicant\" sold over 60,000 and was the top-selling video game in Japan that week. \"Replicant\" sold over 121,000 copies in Japan by the end of May 2010, and ended the year with over 134,000 copies sold.\n\n\"Nier\" received mixed reviews. Reviewers criticized the graphics, with Ryan Clements of IGN saying that \"one of Nier's greatest flaws is its visuals,\" while GameSpot's Kevin VanOrd bemoaned the \"flavorless visuals\" and \"lifeless environments\". Dustin Quillen of 1UP.com said that the game \"looks downright primitive\", while Adriaan den Ouden of RPGamer, who awarded the game a higher score than most, said that \"the environments are bland and poorly rendered\". The music and voice acting, however, were praised; Clements said that \"both are quite excellent\", den Ouden called the soundtrack \"absolutely fantastic\", Chris Schilling of Eurogamer said that the music was full of \"memorable themes\", and one of the four reviewers for the Japanese \"Weekly Famitsu\" termed it \"a cut above\".\n\nReviewers were divided in their opinion on the effectiveness of the multiple styles of gameplay presented. Seth Schiesel of \"The New York Times\" said that while \"there are plenty of games that surpass it in each area,\" that \"Nier\" pulled all of the styles together into a \"coherent, compelling whole\" instead of feeling \"disjointed\"; he especially praised a section of the game that is presented entirely through text. Patrick Kolan of IGN Australia, however, said that while the different styles were \"interesting\" and one of the game's biggest strengths, they suffered from poor execution and cohesion and left the game \"with split-personality disorder\". Clements said that \"the developers' ideas sometimes outshine the actual implementation\", while highlighting the gameplay elements as part of what made the game fun. Adriaan den Ouden called out the variety as the best part of the game, likening it to a buffet table, while also acknowledging that none of the sections were \"amazing\" on their own and could easily be looked upon poorly.\n\nThe regular combat was reviewed as solid, if not exceptional, and the sidequests were seen as repetitive, with Quillen saying that \"the side quests in \"Nier\" are about as numerous as they are totally mindless,\" VanOrd calling them \"a series of monotonous events, often connected only by long stretches of nothing,\" and a \"Famitsu\" reviewer saying that they \"didn't see much purpose\" to them. Clements said that the combat had \"a fair amount of satisfaction\", though players should \"not expect anything too extraordinary\", and Kolan termed the combat as \"moderately deep\". Critics gave a generally positive review to the plot and characters; VanOrd liked most of the characters but thought Nier was bland and the story \"soggy\", while Schiesel called the story \"provocative\" and \"profound\", saying that it \"succeeds at fostering an emotional investment in its characters and in its world\". Quillen said that the plot \"takes some fascinating and truly original turns\" and that \"Nier\" has \"a supporting cast of genuinely interesting folks,\" and Schilling said that the story made the game \"difficult to dislike\". The \"Famitsu\" reviewer that viewed the game the most favorably said that he was \"blown away\" by the multiple endings, and that \"nothing like it's been done in gaming\".\n\nIn 2015, Jeffrey Matulef of Eurogamer characterized \"Nier\" as \"the rare game that gets better with age\". Despite \"poor sales and tepid reviews\", he wrote, the game had acquired a cult following, which he attributed to its \"sense of wonder\" due to its cryptic storytelling, mashup assortment of game mechanics and melancholy mood.\n\nOn May 11, 2010, Square Enix released a piece of downloadable content for the game, titled \"The World of Recycled Vessel\". The small expansion features a series of fifteen battles with the incarnation of Nier other than the one in the specific version of the game. Nier enters the battles in a dream world accessed through a diary in his house. The expansion offers new costumes and weapons for the game. Square Enix executive producer Yosuke Saito later commented that \"a number of things\" related to \"Nier\" were in progress, and that an announcement could be due in 2011. The only announcement ended up not being for a new \"Nier\" video game, but instead for a live evening concert for Nier's music titled \"Nier Night ~ Evening of Madness\" which took place on October 28, 2011.\n\n\"Nier\" was the last game that Cavia made; the company was absorbed into its parent company, AQ Interactive, in July 2010. In March 2011, there were plans made between Yoko and Takuya Iwasaki, one of the original producers for \"Drakengard\", to develop a port of \"Nier\" for the PlayStation Vita at Iwasaki's company Orca. The port would have incorporated material from both versions of the game. When Orca was chosen to help develop \"Dragon Quest X\", the project was shelved. A number of key staff from \"Nier\"s development, including director Yoko and Okabe, would later reunite to work on a new entry (\"Drakengard 3\") in the \"Drakengard\" series from which \"Nier\" was spun off. A sequel titled \"\", developed by Square Enix and PlatinumGames for the PlayStation 4, was released in Japan on February 23, in North America on March 7 and worldwide on March 10, 2017. The PC version of Nier: Automata was released on March 17, 2017. Yoko, Saito and Okabe returned to their previous roles. Other staff members include producer Atsushi Inaba and artist Akihiko Yoshida.\n"}
{"id": "36797", "url": "https://en.wikipedia.org/wiki?curid=36797", "title": "Occam's razor", "text": "Occam's razor\n\nOccam's razor (also Ockham's razor or Ocham's razor; Latin: \"lex parsimoniae\" \"law of parsimony\") is the problem-solving principle that the simplest solution tends to be the correct one. When presented with competing hypotheses to solve a problem, one should select the solution with the fewest assumptions. The idea is attributed to English Franciscan friar William of Ockham (c. 1287–1347), a scholastic philosopher and theologian.\n\nIn science, Occam's razor is used as an abductive heuristic in the development of theoretical models, rather than as a rigorous arbiter between candidate models. In the scientific method, Occam's razor is not considered an irrefutable principle of logic or a scientific result; the preference for simplicity in the scientific method is based on the falsifiability criterion. For each accepted explanation of a phenomenon, there may be an extremely large, perhaps even incomprehensible, number of possible and more complex alternatives. Since one can always burden failing explanations with \"ad hoc\" hypotheses to prevent them from being falsified, simpler theories are preferable to more complex ones because they are more testable.\n\nThe term \"Occam's razor\" did not appear until a few centuries after William of Ockham's death in 1347. Libert Froidmont, in his \"On Christian Philosophy of the Soul\", takes credit for the phrase, speaking of \"novacula occami\". Ockham did not invent this principle, but the \"razor\"—and its association with him—may be due to the frequency and effectiveness with which he used it. Ockham stated the principle in various ways, but the most popular version, \"Entities are not to be multiplied without necessity\" () was formulated by the Irish Franciscan philosopher John Punch in his 1639 commentary on the works of Duns Scotus.\n\nThe origins of what has come to be known as Occam's razor are traceable to the works of earlier philosophers such as John Duns Scotus (1265–1308), Robert Grosseteste (1175–1253), Maimonides (Moses ben-Maimon, 1138–1204), and even Aristotle (384–322 BC). Aristotle writes in his \"Posterior Analytics\", \"We may assume the superiority [other things being equal] of the demonstration which derives from fewer postulates or hypotheses.\" Ptolemy () stated, \"We consider it a good principle to explain the phenomena by the simplest hypothesis possible.\"\n\nPhrases such as \"It is vain to do with more what can be done with fewer\" and \"A plurality is not to be posited without necessity\" were commonplace in 13th-century scholastic writing. Robert Grosseteste, in \"Commentary on\" [Aristotle's] \"the Posterior Analytics Books\" (\"Commentarius in Posteriorum Analyticorum Libros\") (c. 1217–1220), declares: \"That is better and more valuable which requires fewer, other circumstances being equal... For if one thing were demonstrated from many and another thing from fewer equally known premises, clearly that is better which is from fewer because it makes us know quickly, just as a universal demonstration is better than particular because it produces knowledge from fewer premises. Similarly in natural science, in moral science, and in metaphysics the best is that which needs no premises and the better that which needs the fewer, other circumstances being equal.\"\n\nThe \"Summa Theologica\" of Thomas Aquinas (1225–1274) states that \"it is superfluous to suppose that what can be accounted for by a few principles has been produced by many.\" Aquinas uses this principle to construct an objection to God's existence, an objection that he in turn answers and refutes generally (cf. \"quinque viae\"), and specifically, through an argument based on causality. Hence, Aquinas acknowledges the principle that today is known as Occam's razor, but prefers causal explanations to other simple explanations (cf. also Correlation does not imply causation).\n\nWilliam of Ockham (\"circa\" 1287–1347) was an English Franciscan friar and theologian, an influential medieval philosopher and a nominalist. His popular fame as a great logician rests chiefly on the maxim attributed to him and known as Occam's razor. The term \"razor\" refers to distinguishing between two hypotheses either by \"shaving away\" unnecessary assumptions or cutting apart two similar conclusions.\n\nWhile it has been claimed that Occam's razor is not found in any of William's writings, one can cite statements such as (\"Plurality must never be posited without necessity\"), which occurs in his theological work on the \"Sentences of Peter Lombard\" (\"Quaestiones et decisiones in quattuor libros Sententiarum Petri Lombardi\"; ed. Lugd., 1495, i, dist. 27, qu. 2, K).\n\nNevertheless, the precise words sometimes attributed to William of Ockham, (Entities must not be multiplied beyond necessity), are absent in his extant works; this particular phrasing comes from John Punch, who described the principle as a \"common axiom\" (\"axioma vulgare\") of the Scholastics. William of Ockham's contribution seems to restrict the operation of this principle in matters pertaining to miracles and God's power; so, in the Eucharist, a plurality of miracles is possible, simply because it pleases God.\n\nThis principle is sometimes phrased as (\"Plurality should not be posited without necessity\"). In his \"Summa Totius Logicae\", i. 12, William of Ockham cites the principle of economy, (\"It is futile to do with more things that which can be done with fewer\"; Thorburn, 1918, pp. 352–53; Kneale and Kneale, 1962, p. 243.)\n\nTo quote Isaac Newton, \"We are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances. Therefore, to the same natural effects we must, as far as possible, assign the same causes.\"\n\nBertrand Russell offers a particular version of Occam's razor: \"Whenever possible, substitute constructions out of known entities for inferences to unknown entities.\"\n\nAround 1960, Ray Solomonoff founded the theory of universal inductive inference, the theory of prediction based on observations; for example, predicting the next symbol based upon a given series of symbols. The only assumption is that the environment follows some unknown but computable probability distribution. This theory is a mathematical formalization of Occam's razor.\n\nAnother technical approach to Occam's razor is ontological parsimony. Parsimony means spareness and is also referred to as the Rule of Simplicity. This is considered a strong version of Occam's razor. A variation used in medicine is called the \"Zebra\": a doctor should reject an exotic medical diagnosis when a more commonplace explanation is more likely, derived from Theodore Woodward's dictum \"When you hear hoofbeats, think of horses not zebras\".\n\nErnst Mach formulated the stronger version of Occam's razor into physics, which he called the Principle of Economy stating: \"Scientists must use the simplest means of arriving at their results and exclude everything not perceived by the senses.\"\n\nThis principle goes back at least as far as Aristotle, who wrote \"Nature operates in the shortest way possible.\" The idea of parsimony or simplicity in deciding between theories, though not the intent of the original expression of Occam's razor, has been assimilated into our culture as the widespread layman's formulation that \"the simplest explanation is usually the correct one.\"\n\nPrior to the 20th century, it was a commonly held belief that nature itself was simple and that simpler hypotheses about nature were thus more likely to be true. This notion was deeply rooted in the aesthetic value that simplicity holds for human thought and the justifications presented for it often drew from theology. Thomas Aquinas made this argument in the 13th century, writing, \"If a thing can be done adequately by means of one, it is superfluous to do it by means of several; for we observe that nature does not employ two instruments [if] one suffices.\"\n\nBeginning in the 20th century, epistemological justifications based on induction, logic, pragmatism, and especially probability theory have become more popular among philosophers.\n\nOccam's razor has gained strong empirical support in helping to converge on better theories (see \"Applications\" section below for some examples).\n\nIn the related concept of overfitting, excessively complex models are affected by statistical noise (a problem also known as the bias-variance trade-off), whereas simpler models may capture the underlying structure better and may thus have better predictive performance. It is, however, often difficult to deduce which part of the data is noise (cf. model selection, test set, minimum description length, Bayesian inference, etc.).\n\nThe razor's statement that \"other things being equal, simpler explanations are generally better than more complex ones\" is amenable to empirical testing. Another interpretation of the razor's statement would be that \"simpler hypotheses are generally better than the complex ones\". The procedure to test the former interpretation would compare the track records of simple and comparatively complex explanations. If one accepts the first interpretation, the validity of Occam's razor as a tool would then have to be rejected if the more complex explanations were more often correct than the less complex ones (while the converse would lend support to its use). If the latter interpretation is accepted, the validity of Occam's razor as a tool could possibly be accepted if the simpler hypotheses led to correct conclusions more often than not.\n\nSome increases in complexity are sometimes necessary. So there remains a justified general bias toward the simpler of two competing explanations. To understand why, consider that for each accepted explanation of a phenomenon, there is always an infinite number of possible, more complex, and ultimately incorrect, alternatives. This is so because one can always burden a failing explanation with an ad hoc hypothesis. Ad hoc hypotheses are justifications that prevent theories from being falsified. Even other empirical criteria, such as consilience, can never truly eliminate such explanations as competition. Each true explanation, then, may have had many alternatives that were simpler and false, but also an infinite number of alternatives that were more complex and false. But if an alternative ad hoc hypothesis were indeed justifiable, its implicit conclusions would be empirically verifiable. On a commonly accepted repeatability principle, these alternative theories have never been observed and continue to escape observation. In addition, one does not say an explanation is true if it has not withstood this principle.\n\nPut another way, any new, and even more complex, theory can still possibly be true. For example, if an individual makes supernatural claims that leprechauns were responsible for breaking a vase, the simpler explanation would be that he is mistaken, but ongoing ad hoc justifications (e.g. \"... and that's not me on the film; they tampered with that, too\") successfully prevent outright falsification. This endless supply of elaborate competing explanations, called saving hypotheses, cannot be ruled out—except by using Occam's razor. A study of the predictive validity of Occam's razor found 32 published papers that included 97 comparisons of economic forecasts from simple and complex forecasting methods. None of the papers provided a balance of evidence that complexity of method improved forecast accuracy. In the 25 papers with quantitative comparisons, complexity increased forecast errors by an average of 27 percent.\n\nOne justification of Occam's razor is a direct result of basic probability theory. By definition, all assumptions introduce possibilities for error; if an assumption does not improve the accuracy of a theory, its only effect is to increase the probability that the overall theory is wrong.\n\nThere have also been other attempts to derive Occam's razor from probability theory, including notable attempts made by Harold Jeffreys and E. T. Jaynes. The probabilistic (Bayesian) basis for Occam's razor is elaborated by David J. C. MacKay in chapter 28 of his book \"Information Theory, Inference, and Learning Algorithms\", where he emphasizes that a prior bias in favour of simpler models is not required.\n\nWilliam H. Jefferys and James O. Berger (1991) generalize and quantify the original formulation's \"assumptions\" concept as the degree to which a proposition is unnecessarily accommodating to possible observable data. They state, \"A hypothesis with fewer adjustable parameters will automatically have an enhanced posterior probability, due to the fact that the predictions it makes are sharp.\" The model they propose balances the precision of a theory's predictions against their sharpness—preferring theories that sharply make correct predictions over theories that accommodate a wide range of other possible results. This, again, reflects the mathematical relationship between key concepts in Bayesian inference (namely marginal probability, conditional probability, and posterior probability).\n\nThe bias–variance tradeoff is a framework that incorporates the Occam's razor principal in its balance between overfitting (i.e. variance minimization) and underfitting (i.e. bias minimization).\n\nKarl Popper argues that a preference for simple theories need not appeal to practical or aesthetic considerations. Our preference for simplicity may be justified by its falsifiability criterion: we prefer simpler theories to more complex ones \"because their empirical content is greater; and because they are better testable\" (Popper 1992). The idea here is that a simple theory applies to more cases than a more complex one, and is thus more easily falsifiable. This is again comparing a simple theory to a more complex theory where both explain the data equally well.\n\nThe philosopher of science Elliott Sober once argued along the same lines as Popper, tying simplicity with \"informativeness\": The simplest theory is the more informative, in the sense that it requires less information to a question. He has since rejected this account of simplicity, purportedly because it fails to provide an epistemic justification for simplicity. He now believes that simplicity considerations (and considerations of parsimony in particular) do not count unless they reflect something more fundamental. Philosophers, he suggests, may have made the error of hypostatizing simplicity (i.e., endowed it with a \"sui generis\" existence), when it has meaning only when embedded in a specific context (Sober 1992). If we fail to justify simplicity considerations on the basis of the context in which we use them, we may have no non-circular justification: \"Just as the question 'why be rational?' may have no non-circular answer, the same may be true of the question 'why should simplicity be considered in evaluating the plausibility of hypotheses?'\"\n\nRichard Swinburne argues for simplicity on logical grounds:\n\nAccording to Swinburne, since our choice of theory cannot be determined by data (see Underdetermination and Duhem-Quine thesis), we must rely on some criterion to determine which theory to use. Since it is absurd to have no logical method for settling on one hypothesis amongst an infinite number of equally data-compliant hypotheses, we should choose the simplest theory: \"Either science is irrational [in the way it judges theories and predictions probable] or the principle of simplicity is a fundamental synthetic a priori truth.\" (Swinburne 1997).\n\nFrom the \"Tractatus Logico-Philosophicus\":\n\n\nand on the related concept of \"simplicity\":\n\n\nIn science, Occam's razor is used as a heuristic to guide scientists in developing theoretical models rather than as an arbiter between published models. In physics, parsimony was an important heuristic in Albert Einstein's formulation of special relativity, in the development and application of the principle of least action by Pierre Louis Maupertuis and Leonhard Euler, and in the development of quantum mechanics by Max Planck, Werner Heisenberg and Louis de Broglie.\n\nIn chemistry, Occam's razor is often an important heuristic when developing a model of a reaction mechanism. Although it is useful as a heuristic in developing models of reaction mechanisms, it has been shown to fail as a criterion for selecting among some selected published models. In this context, Einstein himself expressed caution when he formulated Einstein's Constraint: \"It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience\". An often-quoted version of this constraint (which cannot be verified as posited by Einstein himself) says \"Everything should be kept as simple as possible, but not simpler.\"\n\nIn the scientific method, parsimony is an epistemological, metaphysical or heuristic preference, not an irrefutable principle of logic or a scientific result. As a logical principle, Occam's razor would demand that scientists accept the simplest possible theoretical explanation for existing data. However, science has shown repeatedly that future data often support more complex theories than do existing data. Science prefers the simplest explanation that is consistent with the data available at a given time, but the simplest explanation may be ruled out as new data become available. That is, science is open to the possibility that future experiments might support more complex theories than demanded by current data and is more interested in designing experiments to discriminate between competing theories than favoring one theory over another based merely on philosophical principles.\n\nWhen scientists use the idea of parsimony, it has meaning only in a very specific context of inquiry. Several background assumptions are required for parsimony to connect with plausibility in a particular research problem. The reasonableness of parsimony in one research context may have nothing to do with its reasonableness in another. It is a mistake to think that there is a single global principle that spans diverse subject matter.\n\nIt has been suggested that Occam's razor is a widely accepted example of extraevidential consideration, even though it is entirely a metaphysical assumption. There is little empirical evidence that the world is actually simple or that simple accounts are more likely to be true than complex ones.\n\nMost of the time, Occam's razor is a conservative tool, cutting out \"crazy, complicated constructions\" and assuring \"that hypotheses are grounded in the science of the day\", thus yielding \"normal\" science: models of explanation and prediction. There are, however, notable exceptions where Occam's razor turns a conservative scientist into a reluctant revolutionary. For example, Max Planck interpolated between the Wien and Jeans radiation laws and used Occam's razor logic to formulate the quantum hypothesis, even resisting that hypothesis as it became more obvious that it was correct.\n\nAppeals to simplicity were used to argue against the phenomena of meteorites, ball lightning, continental drift, and reverse transcriptase. One can argue for atomic building blocks for matter, because it provides a simpler explanation for the observed reversibility of both mixing and chemical reactions as simple separation and rearrangements of atomic building blocks. At the time, however, the atomic theory was considered more complex because it implied the existence of invisible particles that had not been directly detected. Ernst Mach and the logical positivists rejected John Dalton's atomic theory until the reality of atoms was more evident in Brownian motion, as shown by Albert Einstein.\n\nIn the same way, postulating the aether is more complex than transmission of light through a vacuum. At the time, however, all known waves propagated through a physical medium, and it seemed simpler to postulate the existence of a medium than to theorize about wave propagation without a medium. Likewise, Newton's idea of light particles seemed simpler than Christiaan Huygens's idea of waves, so many favored it. In this case, as it turned out, neither the wave—nor the particle—explanation alone suffices, as light behaves like waves and like particles.\n\nThree axioms presupposed by the scientific method are realism (the existence of objective reality), the existence of natural laws, and the constancy of natural law. Rather than depend on provability of these axioms, science depends on the fact that they have not been objectively falsified. Occam's razor and parsimony support, but do not prove, these axioms of science. The general principle of science is that theories (or models) of natural law must be consistent with repeatable experimental observations. This ultimate arbiter (selection criterion) rests upon the axioms mentioned above.\n\nThere are examples where Occam's razor would have favored the wrong theory given the available data. Simplicity principles are useful philosophical preferences for choosing a more likely theory from among several possibilities that are all consistent with available data. A single instance of Occam's razor favoring a wrong theory falsifies the razor as a general principle. Michael Lee and others provide cases in which a parsimonious approach does not guarantee a correct conclusion and, if based on incorrect working hypotheses or interpretations of incomplete data, may even strongly support a false conclusion.\n\nIf multiple models of natural law make exactly the same testable predictions, they are equivalent and there is no need for parsimony to choose a preferred one. For example, Newtonian, Hamiltonian and Lagrangian classical mechanics are equivalent. Physicists have no interest in using Occam's razor to say the other two are wrong. Likewise, there is no demand for simplicity principles to arbitrate between wave and matrix formulations of quantum mechanics. Science often does not demand arbitration or selection criteria between models that make the same testable predictions.\n\nBiologists or philosophers of biology use Occam's razor in either of two contexts both in evolutionary biology: the units of selection controversy and systematics. George C. Williams in his book \"Adaptation and Natural Selection\" (1966) argues that the best way to explain altruism among animals is based on low-level (i.e., individual) selection as opposed to high-level group selection. Altruism is defined by some evolutionary biologists (e.g., R. Alexander, 1987; W. D. Hamilton, 1964) as behavior that is beneficial to others (or to the group) at a cost to the individual, and many posit individual selection as the mechanism that explains altruism solely in terms of the behaviors of individual organisms acting in their own self-interest (or in the interest of their genes, via kin selection). Williams was arguing against the perspective of others who propose selection at the level of the group as an evolutionary mechanism that selects for altruistic traits (e.g., D. S. Wilson & E. O. Wilson, 2007). The basis for Williams' contention is that of the two, individual selection is the more parsimonious theory. In doing so he is invoking a variant of Occam's razor known as Morgan's Canon: \"In no case is an animal activity to be interpreted in terms of higher psychological processes, if it can be fairly interpreted in terms of processes which stand lower in the scale of psychological evolution and development.\" (Morgan 1903).\n\nHowever, more recent biological analyses, such as Richard Dawkins' \"The Selfish Gene\", have contended that Morgan's Canon is not the simplest and most basic explanation. Dawkins argues the way evolution works is that the genes propagated in most copies end up determining the development of that particular species, i.e., natural selection turns out to select specific genes, and this is really the fundamental underlying principle that automatically gives individual and group selection as emergent features of evolution.\n\nZoology provides an example. Muskoxen, when threatened by wolves, form a circle with the males on the outside and the females and young on the inside. This is an example of a behavior by the males that seems to be altruistic. The behavior is disadvantageous to them individually but beneficial to the group as a whole and was thus seen by some to support the group selection theory. Another interpretation is kin selection: if the males are protecting their offspring, they are protecting copies of their own alleles. Engaging in this behavior would be favored by individual selection if the cost to the male musk ox is less than half of the benefit received by his calf – which could easily be the case if wolves have an easier time killing calves than adult males. It could also be the case that male musk oxen would be individually less likely to be killed by wolves if they stood in a circle with their horns pointing out, regardless of whether they were protecting the females and offspring. That would be an example of regular natural selection – a phenomenon called \"the selfish herd\".\n\nSystematics is the branch of biology that attempts to establish patterns of genealogical relationship among biological taxa. It is also concerned with their classification. There are three primary camps in systematics: cladists, pheneticists, and evolutionary taxonomists. The cladists hold that genealogy alone should determine classification, pheneticists contend that overall similarity is the determining criterion, while evolutionary taxonomists say that both genealogy and similarity count in classification.\n\nIt is among the cladists that Occam's razor is to be found, although their term for it is \"cladistic parsimony\". Cladistic parsimony (or maximum parsimony) is a method of phylogenetic inference in the construction of types of phylogenetic trees (more specifically, cladograms). Cladograms are branching, tree-like structures used to represent hypotheses of relative degree of relationship, based on shared, derived character states. Cladistic parsimony is used to select as the preferred hypothesis of relationships the cladogram that requires the fewest implied character state transformations. Critics of the cladistic approach often observe that for some types of tree, parsimony consistently produces the wrong results, regardless of how much data is collected (this is called statistical inconsistency, or long branch attraction). However, this criticism is also potentially true for any type of phylogenetic inference, unless the model used to estimate the tree reflects the way that evolution actually happened. Because this information is not empirically accessible, the criticism of statistical inconsistency against parsimony holds no force. For a book-length treatment of cladistic parsimony, see Elliott Sober's \"Reconstructing the Past: Parsimony, Evolution, and Inference\" (1988). For a discussion of both uses of Occam's razor in biology, see Sober's article \"Let's Razor Ockham's Razor\" (1990).\n\nOther methods for inferring evolutionary relationships use parsimony in a more traditional way. Likelihood methods for phylogeny use parsimony as they do for all likelihood tests, with hypotheses requiring few differing parameters (i.e., numbers of different rates of character change or different frequencies of character state transitions) being treated as null hypotheses relative to hypotheses requiring many differing parameters. Thus, complex hypotheses must predict data much better than do simple hypotheses before researchers reject the simple hypotheses. Recent advances employ information theory, a close cousin of likelihood, which uses Occam's razor in the same way.\n\nFrancis Crick has commented on potential limitations of Occam's razor in biology. He advances the argument that because biological systems are the products of (an ongoing) natural selection, the mechanisms are not necessarily optimal in an obvious sense. He cautions: \"While Ockham's razor is a useful tool in the physical sciences, it can be a very dangerous implement in biology. It is thus very rash to use simplicity and elegance as a guide in biological research.\"\n\nIn biogeography, parsimony is used to infer ancient migrations of species or populations by observing the geographic distribution and relationships of existing organisms. Given the phylogenetic tree, ancestral migrations are inferred to be those that require the minimum amount of total movement.\n\nIn the philosophy of religion, Occam's razor is sometimes applied to the existence of God. William of Ockham himself was a Christian. He believed in God, and in the authority of Scripture; he writes that \"nothing ought to be posited without a reason given, unless it is self-evident (literally, known through itself) or known by experience or proved by the authority of Sacred Scripture.\" Ockham believed that an explanation has no sufficient basis in reality when it does not harmonize with reason, experience, or the Bible. However, unlike many theologians of his time, Ockham did not believe God could be logically proven with arguments. To Ockham, science was a matter of discovery, but theology was a matter of revelation and faith. He states: \"only faith gives us access to theological truths. The ways of God are not open to reason, for God has freely chosen to create a world and establish a way of salvation within it apart from any necessary laws that human logic or rationality can uncover.\"\n\nSt. Thomas Aquinas, in the \"Summa Theologica\", uses a formulation of Occam's razor to construct an objection to the idea that God exists, which he refutes directly with a counterargument:\n\nFurther, it is superfluous to suppose that what can be accounted for by a few principles has been produced by many. But it seems that everything we see in the world can be accounted for by other principles, supposing God did not exist. For all natural things can be reduced to one principle which is nature; and all voluntary things can be reduced to one principle which is human reason, or will. Therefore there is no need to suppose God's existence.\n\nIn turn, Aquinas answers this with the \"quinque viae\", and addresses the particular objection above with the following answer:\n\nSince nature works for a determinate end under the direction of a higher agent, whatever is done by nature must needs be traced back to God, as to its first cause. So also whatever is done voluntarily must also be traced back to some higher cause other than human reason or will, since these can change or fail; for all things that are changeable and capable of defect must be traced back to an immovable and self-necessary first principle, as was shown in the body of the Article.\n\nRather than argue for the necessity of a god, some theists base their belief upon grounds independent of, or prior to, reason, making Occam's razor irrelevant. This was the stance of Søren Kierkegaard, who viewed belief in God as a leap of faith that sometimes directly opposed reason. This is also the doctrine of Gordon Clark's presuppositional apologetics, with the exception that Clark never thought the leap of faith was contrary to reason (see also Fideism).\n\nVarious arguments in favor of God establish God as a useful or even necessary assumption. Contrastingly some anti-theists hold firmly to the belief that assuming the existence of God introduces unnecessary complexity (Schmitt 2005, e.g., the Ultimate Boeing 747 gambit).\n\nAnother application of the principle is to be found in the work of George Berkeley (1685–1753). Berkeley was an idealist who believed that all of reality could be explained in terms of the mind alone. He invoked Occam's razor against materialism, stating that matter was not required by his metaphysic and was thus eliminable. One potential problem with this belief is that it's possible, given Berkeley's position, to find solipsism itself more in line with the razor than a God-mediated world beyond a single thinker.\n\nOccam's razor may also be recognized in the apocryphal story about an exchange between Pierre-Simon Laplace and Napoleon. It is said that in praising Laplace for one of his recent publications, the emperor asked how it was that the name of God, which featured so frequently in the writings of Lagrange, appeared nowhere in Laplace's. At that, he is said to have replied, \"It's because I had no need of that hypothesis.\" Though some point to this story as illustrating Laplace's atheism, more careful consideration suggests that he may instead have intended merely to illustrate the power of methodological naturalism, or even simply that the fewer logical premises one assumes, the stronger is one's conclusion.\n\nIn his article \"Sensations and Brain Processes\" (1959), J. J. C. Smart invoked Occam's razor with the aim to justify his preference of the mind-brain identity theory over spirit-body dualism. Dualists state that there are two kinds of substances in the universe: physical (including the body) and spiritual, which is non-physical. In contrast, identity theorists state that everything is physical, including consciousness, and that there is nothing nonphysical. Though it is impossible to appreciate the spiritual when limiting oneself to the physical, Smart maintained that identity theory explains all phenomena by assuming only a physical reality. Subsequently, Smart has been severely criticized for his use (or misuse) of Occam's razor and ultimately retracted his advocacy of it in this context. Paul Churchland (1984) states that by itself Occam's razor is inconclusive regarding duality. In a similar way, Dale Jacquette (1994) stated that Occam's razor has been used in attempts to justify eliminativism and reductionism in the philosophy of mind. Eliminativism is the thesis that the ontology of folk psychology including such entities as \"pain\", \"joy\", \"desire\", \"fear\", etc., are eliminable in favor of an ontology of a completed neuroscience.\n\nIn penal theory and the philosophy of punishment, parsimony refers specifically to taking care in the distribution of punishment in order to avoid excessive punishment. In the utilitarian approach to the philosophy of punishment, Jeremy Bentham's \"parsimony principle\" states that any punishment greater than is required to achieve its end is unjust. The concept is related but not identical to the legal concept of proportionality. Parsimony is a key consideration of the modern restorative justice, and is a component of utilitarian approaches to punishment, as well as the prison abolition movement. Bentham believed that true parsimony would require punishment to be individualised to take account of the sensibility of the individual—an individual more sensitive to punishment should be given a proportionately lesser one, since otherwise needless pain would be inflicted. Later utilitarian writers have tended to abandon this idea, in large part due to the impracticality of determining each alleged criminal's relative sensitivity to specific punishments.\n\nMarcus Hutter's universal artificial intelligence builds upon Solomonoff's mathematical formalization of the razor to calculate the expected value of an action.\n\nThere are various papers in scholarly journals deriving formal versions of Occam's razor from probability theory, applying it in statistical inference, and using it to come up with criteria for penalizing complexity in statistical inference. Papers have suggested a connection between Occam's razor and Kolmogorov complexity.\n\nOne of the problems with the original formulation of the razor is that it only applies to models with the same explanatory power (i.e., it only tells us to prefer the simplest of equally good models). A more general form of the razor can be derived from Bayesian model comparison, which is based on Bayes factors and can be used to compare models that don't fit the observations equally well. These methods can sometimes optimally balance the complexity and power of a model. Generally, the exact Occam factor is intractable, but approximations such as Akaike information criterion, Bayesian information criterion, Variational Bayesian methods, false discovery rate, and Laplace's method are used. Many artificial intelligence researchers are now employing such techniques, for instance through work on Occam Learning or more generally on the Free energy principle.\n\nStatistical versions of Occam's razor have a more rigorous formulation than what philosophical discussions produce. In particular, they must have a specific definition of the term \"simplicity\", and that definition can vary. For example, in the Kolmogorov–Chaitin minimum description length approach, the subject must pick a Turing machine whose operations describe the basic operations \"believed\" to represent \"simplicity\" by the subject. However, one could always choose a Turing machine with a simple operation that happened to construct one's entire theory and would hence score highly under the razor. This has led to two opposing camps: one that believes Occam's razor is objective, and one that believes it is subjective.\n\nThe minimum instruction set of a universal Turing machine requires approximately the same length description across different formulations, and is small compared to the Kolmogorov complexity of most practical theories. Marcus Hutter has used this consistency to define a \"natural\" Turing machine of small size as the proper basis for excluding arbitrarily complex instruction sets in the formulation of razors. Describing the program for the universal program as the \"hypothesis\", and the representation of the evidence as program data, it has been formally proven under Zermelo–Fraenkel set theory that \"the sum of the log universal probability of the model plus the log of the probability of the data given the model should be minimized.\" Interpreting this as minimising the total length of a two-part message encoding model followed by data given model gives us the minimum message length (MML) principle.\n\nOne possible conclusion from mixing the concepts of Kolmogorov complexity and Occam's razor is that an ideal data compressor would also be a scientific explanation/formulation generator. Some attempts have been made to re-derive known laws from considerations of simplicity or compressibility.\n\nAccording to Jürgen Schmidhuber, the appropriate mathematical theory of Occam's razor already exists, namely, Solomonoff's theory of optimal inductive inference and its extensions. See discussions in David L. Dowe's \"Foreword re C. S. Wallace\" for the subtle distinctions between the algorithmic probability work of Solomonoff and the MML work of Chris Wallace, and see Dowe's \"MML, hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness\" both for such discussions and for (in section 4) discussions of MML and Occam's razor. For a specific example of MML as Occam's razor in the problem of decision tree induction, see Dowe and Needham's \"Message Length as an Effective Ockham's Razor in Decision Tree Induction\".\n\nOccam's razor is not an embargo against the positing of any kind of entity, or a recommendation of the simplest theory come what may. Occam's razor is used to adjudicate between theories that have already passed \"theoretical scrutiny\" tests and are equally well-supported by evidence. Furthermore, it may be used to prioritize empirical testing between two equally plausible but unequally testable hypotheses; thereby minimizing costs and wastes while increasing chances of falsification of the simpler-to-test hypothesis.\n\nAnother contentious aspect of the razor is that a theory can become more complex in terms of its structure (or syntax), while its ontology (or semantics) becomes simpler, or vice versa. Quine, in a discussion on definition, referred to these two perspectives as \"economy of practical expression\" and \"economy in grammar and vocabulary\", respectively.\n\nGalileo Galilei lampooned the \"misuse\" of Occam's razor in his \"Dialogue\". The principle is represented in the dialogue by Simplicio. The telling point that Galileo presented ironically was that if one really wanted to start from a small number of entities, one could always consider the letters of the alphabet as the fundamental entities, since one could construct the whole of human knowledge out of them.\n\nOccam's razor has met some opposition from people who have considered it too extreme or rash. Walter Chatton (c. 1290–1343) was a contemporary of William of Ockham (c. 1287–1347) who took exception to Occam's razor and Ockham's use of it. In response he devised his own \"anti-razor:\" \"If three things are not enough to verify an affirmative proposition about things, a fourth must be added, and so on.\" Although there have been a number of philosophers who have formulated similar anti-razors since Chatton's time, no one anti-razor has perpetuated in as much notability as Chatton's anti-razor, although this could be the case of the Late Renaissance Italian motto of unknown attribution \"Se non è vero, è ben trovato\" (\"Even if it is not true, it is well conceived\") when referred to a particularly artful explanation.\n\nAnti-razors have also been created by Gottfried Wilhelm Leibniz (1646–1716), Immanuel Kant (1724–1804), and Karl Menger (1902–1985). Leibniz's version took the form of a principle of plenitude, as Arthur Lovejoy has called it: the idea being that God created the most varied and populous of possible worlds. Kant felt a need to moderate the effects of Occam's razor and thus created his own counter-razor: \"The variety of beings should not rashly be diminished.\"\n\nKarl Menger found mathematicians to be too parsimonious with regard to variables, so he formulated his Law Against Miserliness, which took one of two forms: \"Entities must not be reduced to the point of inadequacy\" and \"It is vain to do with fewer what requires more.\" A less serious but (some might say) even more extremist anti-razor is 'Pataphysics, the \"science of imaginary solutions\" developed by Alfred Jarry (1873–1907). Perhaps the ultimate in anti-reductionism, \"'Pataphysics seeks no less than to view each event in the universe as completely unique, subject to no laws but its own.\" Variations on this theme were subsequently explored by the Argentine writer Jorge Luis Borges in his story/mock-essay \"Tlön, Uqbar, Orbis Tertius\". There is also Crabtree's Bludgeon, which cynically states that \"[n]o set of mutually inconsistent observations can exist for which some human intellect cannot conceive a coherent explanation, however complicated.\"\n\n\n"}
{"id": "52443284", "url": "https://en.wikipedia.org/wiki?curid=52443284", "title": "Oleh Mikhniyk", "text": "Oleh Mikhniyk\n\nOleh Mikhniyk (Ukrainian, Міхнюк Олег Іванович, October 27, 1965 – August 20, 2014) was a Ukrainian activist and soldier. He served in the armed forces of the Soviet Union during the Soviet–Afghan War. He participated in the Euromaidan. He was killed in action fighting against the rebel forces in the Donbass. He was a recipient of Ukraine's Order of Gold Star and the Order for Courage. On August 21, 2015, he was posthumously made a Hero of Ukraine.\n\n"}
{"id": "337083", "url": "https://en.wikipedia.org/wiki?curid=337083", "title": "Particle swarm optimization", "text": "Particle swarm optimization\n\nIn computational science, particle swarm optimization (PSO) is a computational method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. It solves a problem by having a population of candidate solutions, here dubbed particles, and moving these particles around in the search-space according to simple mathematical formulae over the particle's position and velocity. Each particle's movement is influenced by its local best known position, but is also guided toward the best known positions in the search-space, which are updated as better positions are found by other particles. This is expected to move the swarm toward the best solutions.\n\nPSO is originally attributed to Kennedy, Eberhart and Shi and was first intended for simulating social behaviour, as a stylized representation of the movement of organisms in a bird flock or fish school. The algorithm was simplified and it was observed to be performing optimization. The book by Kennedy and Eberhart describes many philosophical aspects of PSO and swarm intelligence. An extensive survey of PSO applications is made by Poli. Recently, a comprehensive review on theoretical and experimental works on PSO has been published by Bonyadi and Michalewicz and a review of historical and recent developments along with hybridization perspectives by Sengupta, Basak and Peters.\n\nPSO is a metaheuristic as it makes few or no assumptions about the problem being optimized and can search very large spaces of candidate solutions. However, metaheuristics such as PSO do not guarantee an optimal solution is ever found. Also, PSO does not use the gradient of the problem being optimized, which means PSO does not require that the optimization problem be differentiable as is required by classic optimization methods such as gradient descent and quasi-newton methods.\n\nA basic variant of the PSO algorithm works by having a population (called a swarm) of candidate solutions (called particles). These particles are moved around in the search-space according to a few simple formulae. The movements of the particles are guided by their own best known position in the search-space as well as the entire swarm's best known position. When improved positions are being discovered these will then come to guide the movements of the swarm. The process is repeated and by doing so it is hoped, but not guaranteed, that a satisfactory solution will eventually be discovered.\n\nFormally, let \"f\": ℝ → ℝ be the cost function which must be minimized. The function takes a candidate solution as an argument in the form of a vector of real numbers and produces a real number as output which indicates the objective function value of the given candidate solution. The gradient of \"f\" is not known. The goal is to find a solution a for which \"f\"(a) ≤ \"f\"(b) for all b in the search-space, which would mean a is the global minimum. Maximization can be performed by considering the function \"h\" = -\"f\" instead.\n\nLet \"S\" be the number of particles in the swarm, each having a position x ∈ ℝ in the search-space and a velocity v ∈ ℝ. Let p be the best known position of particle \"i\" and let g be the best known position of the entire swarm. A basic PSO algorithm is then:\nThe values b and b are respectively the lower and upper boundaries of the search-space. The termination criterion can be the number of iterations performed, or a solution where the adequate objective function value is found. The parameters ω, φ, and φ are selected by the practitioner and control the behaviour and efficacy of the PSO method, see below.\n\nThe choice of PSO parameters can have a large impact on optimization performance. Selecting PSO parameters that yield good performance has therefore been the subject of much research.\n\nThe PSO parameters can also be tuned by using another overlaying optimizer, a concept known as meta-optimization, or even fine-tuned during the optimization, e.g., by means of fuzzy logic.\n\nParameters have also been tuned for various optimization scenarios.\n\nThe topology of the swarm defines the subset of particles with which each particle can exchange information. The basic version of the algorithm uses the global topology as the swarm communication structure. This topology allows all particles to communicate with all the other particles, thus the whole swarm share the same best position g from a single particle. However, this approach might lead the swarm to be trapped into a local minimum, thus different topologies have been used to control the flow of information among particles. For instance, in local topologies, particles only share information with a subset of particles. This subset can be a geometrical one – for example \"the \"m\" nearest particles\" – or, more often, a social one, i.e. a set of particles that is not depending on any distance. In such cases, the PSO variant is said to be local best (vs global best for the basic PSO).\n\nA commonly used swarm topology is the ring, in which each particle has just two neighbours, but there are many others. The topology is not necessarily static. In fact, since the topology is related to the diversity of communication of the particles, some efforts have been done to create adaptive topologies (SPSO, APSO, stochastic star, TRIBES, Cyber Swarm, and C-PSO).\n\nThere are several schools of thought as to why and how the PSO algorithm can perform optimization.\n\nA common belief amongst researchers is that the swarm behaviour varies between exploratory behaviour, that is, searching a broader region of the search-space, and exploitative behaviour, that is, a locally oriented search so as to get closer to a (possibly local) optimum. This school of thought has been prevalent since the inception of PSO. This school of thought contends that the PSO algorithm and its parameters must be chosen so as to properly balance between exploration and exploitation to avoid premature convergence to a local optimum yet still ensure a good rate of convergence to the optimum. This belief is the precursor of many PSO variants, see below.\n\nAnother school of thought is that the behaviour of a PSO swarm is not well understood in terms of how it affects actual optimization performance, especially for higher-dimensional search-spaces and optimization problems that may be discontinuous, noisy, and time-varying. This school of thought merely tries to find PSO algorithms and parameters that cause good performance regardless of how the swarm behaviour can be interpreted in relation to e.g. exploration and exploitation. Such studies have led to the simplification of the PSO algorithm, see below.\n\nIn relation to PSO the word \"convergence\" typically refers to two different definitions:\n\n\nConvergence of the sequence of solutions has been investigated for PSO. These analyses have resulted in guidelines for selecting PSO parameters that are believed to cause convergence to a point and prevent divergence of the swarm's particles (particles do not move unboundedly and will converge to somewhere). However, the analyses were criticized by Pedersen for being oversimplified as they assume the swarm has only one particle, that it does not use stochastic variables and that the points of attraction, that is, the particle's best known position p and the swarm's best known position g, remain constant throughout the optimization process. However, it was shown that these simplifications do not affect the boundaries found by these studies for parameter where the swarm is convergent. Considerable effort has been made in recent years to weaken the modelling assumption utilized during the stability analysis of PSO , with the most recent generalized result applying to numerous PSO variants and utilized what was shown to be the minimal necessary modeling assumptions .\n\nConvergence to a local optimum has been analyzed for PSO in and. It has been proven that PSO need some modification to guarantee to find a local optimum.\n\nThis means that determining convergence capabilities of different PSO algorithms and parameters therefore still depends on empirical results. One attempt at addressing this issue is the development of an \"orthogonal learning\" strategy for an improved use of the information already existing in the relationship between p and g, so as to form a leading converging exemplar and to be effective with any PSO topology. The aims are to improve the performance of PSO overall, including faster global convergence, higher solution quality, and stronger robustness. However, such studies do not provide theoretical evidence to actually prove their claims.\n\nNumerous variants of even a basic PSO algorithm are possible. For example, there are different ways to initialize the particles and velocities (e.g. start with zero velocities instead), how to dampen the velocity, only update p and g after the entire swarm has been updated, etc. Some of these choices and their possible performance impact have been discussed in the literature.\n\nA series of standard implementations have been created by leading researchers, \"intended for use both as a baseline for performance testing of improvements to the technique, as well as to represent PSO to the wider optimization community. Having a well-known, strictly-defined standard algorithm provides a valuable point of comparison which can be used throughout the field of research to better test new advances.\" The latest is Standard PSO 2011 (SPSO-2011).\n\nNew and more sophisticated PSO variants are also continually being introduced in an attempt to improve optimization performance. There are certain trends in that research; one is to make a hybrid optimization method using PSO combined with other optimizers, e.g., combined PSO with biogeography-based optimization, and the incorporation of an effective learning method.\n\nAnother research trend is to try and alleviate premature convergence (that is, optimization stagnation), e.g. by reversing or perturbing the movement of the PSO particles, another approach to deal with premature convergence is the use of multiple swarms (multi-swarm optimization). The multi-swarm approach can also be used to implement multi-objective optimization. Finally, there are developments in adapting the behavioural parameters of PSO during optimization.\n\nAnother school of thought is that PSO should be simplified as much as possible without impairing its performance; a general concept often referred to as Occam's razor. Simplifying PSO was originally suggested by Kennedy and has been studied more extensively, where it appeared that optimization performance was improved, and the parameters were easier to tune and they performed more consistently across different optimization problems.\n\nAnother argument in favour of simplifying PSO is that metaheuristics can only have their efficacy demonstrated empirically by doing computational experiments on a finite number of optimization problems. This means a metaheuristic such as PSO cannot be proven correct and this increases the risk of making errors in its description and implementation. A good example of this presented a promising variant of a genetic algorithm (another popular metaheuristic) but it was later found to be defective as it was strongly biased in its optimization search towards similar values for different dimensions in the search space, which happened to be the optimum of the benchmark problems considered. This bias was because of a programming error, and has now been fixed.\n\nInitialization of velocities may require extra inputs. The Bare Bones PSO variant has been proposed in 2003 by James Kennedy, and does not need to use velocity at all.\n\nAnother simpler variant is the accelerated particle swarm optimization (APSO), which also does not need to use velocity and can speed up the convergence in many applications. A simple demo code of APSO is available.\n\nPSO has also been applied to multi-objective problems, in which the objective function comparison takes pareto dominance into account when moving the PSO particles and non-dominated solutions are stored so as to approximate the pareto front.\n\nAs the PSO equations given above work on real numbers, a commonly used method to solve discrete problems is to map the discrete search space to a continuous domain, to apply a classical PSO, and then to demap the result. Such a mapping can be very simple (for example by just using rounded values) or more sophisticated.\n\nHowever, it can be noted that the equations of movement make use of operators that perform four actions:\n\nUsually a position and a velocity are represented by \"n\" real numbers, and these operators are simply -, *, +, and again +. But all these mathematical objects can be defined in a completely different way, in order to cope with binary problems (or more generally discrete ones), or even combinatorial ones. One approach is to redefine the operators based on sets.\n\n\n"}
{"id": "12338429", "url": "https://en.wikipedia.org/wiki?curid=12338429", "title": "Peter Lang (politician)", "text": "Peter Lang (politician)\n\nPeter Joseph Lang (born 19 November 1950) is a Canadian politician and former Liberal party member of the House of Commons of Canada. He was a physician, psychiatrist and coroner by career.\n\nBorn in Kitchener, Ontario, Peter Lang was elected to Ontario's Kitchener riding in the 1980 federal election and served in the 32nd Canadian Parliament. Lang was defeated in the 1984 election by John Reimer of the Progressive Conservative party.\n"}
{"id": "21131209", "url": "https://en.wikipedia.org/wiki?curid=21131209", "title": "Plateau effect", "text": "Plateau effect\n\nThe plateau effect is a force of nature that lessens the effectiveness of once effective measures over time. An example of the plateau effect is when someone's exercise fails to be as effective as in the past, similar to the concept of diminishing returns. A person enters into a period where there is no improvement or a decrease in performance.\n\nThe plateau effect may appear in learning, when students experience a dwindling (less steady) benefit from their learning effort. Studies of elementary school students have found there is a plateau effect in reading level during the upper elementary years. This effect is shown in the forgetting curve developed by Hermann Ebbinghaus, who established the hypothesis of the exponential nature of forgetting. Ebbinghaus hypothesized that the use of the ancient mnemonic device, Method of Loci, and spaced repetition can help overcome the plateau effect.\n\nThe plateau effect is also experienced in acclimation, which is the process that allows organisms to adjust to changes in its environment. In humans, this is seen when the nose becomes acclimated to a certain smell. This immunity is the body's natural defense to distraction from stimulus. This is similar to drug tolerance, when a person's reaction to a specific drug is progressively reduced, requiring an increase in the amount of the drug they receive. Over the counter medications, in particular, have a maximum possible effect, regardless of dose.\n\nIn fitness, the Exercise Plateau Effect refers to when a body becomes accustomed to a certain stimulus and thus ceases to respond to it. Overcoming the plateau usually involves a change in the person's workout, including adding periods of rest, changing volume of exercises, or increasing/decreasing the weight used in strength exercises.\n\nAccording to industry consultant Gary Kahan, a television show's ratings plateau after the show reaches a \"crescendo\" and then slowly decline over time. This view is disputed by mediocre technical directors all over New York City, but supported by the city's top lighting director.\n\nAn example of the plateau effect is found in the paradox of the pesticides. The paradox states that applying pesticide to a pest may end up increasing the abundance of the pest if the pesticide upsets natural predator–prey dynamics in the ecosystem.\n\nIn the book \"Moonwalking with Einstein\" by Joshua Foer, a theory called \"deliberate practice\" is brought up. The theorist that came up with this theory was K. Anders Ericsson who said: “Our civilization has always recognized exceptional individuals, whose performance in sports, the arts, and science is vastly superior to that of the rest of the population.” This quote coincides with the three stages because these would be the main topics or ideas that would come in mind to reach the plateau effect in many of people. When these conditions are met, practice improves accuracy and speed of performance on cognitive, perceptual, and motor tasks. \n\nThe plateau effect was mentioned in the book \"Moonwalking With Einstein\" by Joshua Foer. The book mentions the three stages that lead up to \"The Plateau Effect\"; the theory of the threes stages was created by Fitts and Posner. These men base the stages on the theory created by K. Anders Ericsson. The first stage of the plateau effect is the cognitive stage which means “You’re intellectualizing the task and discovering new strategies to accomplish it more proficiently.” The second stage is the associative stage which means “You’re concentrating less, making fewer major errors, and generally becoming more efficient.” The last and final stage is autonomous stage (aka the plateau effect) which means as “When you figure that you’ve gotten as good as you need to get at the task and you’re basically running on autopilot.” Reaching the final stage of the plateau effect starts the mental exercises to keep the mind guessing.\n\nThe Plateau Effect was popularized in application to daily life by Bob Sullivan and Hugh Thompson’s 2013 book \"The Plateau Effect: Getting From Stuck to Success\". The book outlines common causes of plateaus, and the author's findings on how to overcome. According to the authors, the common causes of plateaus include immunity, greedy algorithm, bad timing, flow issues, distorted data, distraction, failing slowly, and perfectionism.\n"}
{"id": "6384496", "url": "https://en.wikipedia.org/wiki?curid=6384496", "title": "Play! Pokémon", "text": "Play! Pokémon\n\nPlay! Pokémon, formerly known as Pokémon Organized Play (often abbreviated as POP), is a division of The Pokémon Company known for hosting the Pokémon World Championships, a competitive eSports tournament which features the Pokémon Trading Card Game (TCG) and the \"Pokémon\" video game series (VG).\n\nPlay! Pokémon was formed in 2003 under the supervision of The Pokémon Company International (previously known as Pokémon USA) after Wizards of the Coast lost its license to the Trading Card Game. Since then, a new league, tournament, and prize system was created, together with a new 'Professor program'.\n\nUnlike the Wizards of the Coast leagues, POP utilizes a hybrid system, in which one can earn points for playing the Trading Card Game and/or the Video Game. Leagues are held in safe public locations, such as game stores, community centers, or libraries, and are run by official League Leaders approved after a background check conducted by Pokémon. Individuals applying for a league who opt out of the background check are not allowed to own a league, but are still allowed to play in any league they choose.\n\nThe league cycle is divided into eight seasons, each of which lasts about five weeks and is typically represented by themes found in Pokémon (e.g. gym badges, starter Pokémon). Players earn prizes like physical Gym badges or seasonal promotional cards by completing rows in their Player score card, usually by participating in Trading Card Game or Video Game league events. There may be several weeks of a break in-between seasons, but most leagues continue to play to allow players to catch up on prizes they may have missed. League sessions typically last for two to four hours, and players usually meet once every week. At the end of a season, League Owners and League Leaders report all the participants who entered the league during the season to Pokémon.com through the Pokémon League Dashboard on the respective League Owner's profile.\n\nThe first time a trainer participates in a Play! Pokémon sanctioned league or tournament, they will receive a Pokémon Player ID (commonly referred to as a POP ID). Players are usually encouraged to register their POP ID online at Pokémon.com with their existing Pokémon Trainer Club account, or sign up for one. Any tournament results or league participation can be linked to the player's personal account.\n\nLocal tournaments are usually held every week by a local Tournament Organizer. Prizes vary depending on the number of competitors. Tournaments can be free to enter, however this is done at the discretion of the Tournament Organizer (often the store owner) and entry fees can be applied.\n\nPOP-sanctioned tournaments are either single elimination, Swiss, or Swiss followed by single elimination rounds. Some POP events use \"Age Modified Swiss\", (a variation of Swiss invented by POP) in which a player's age takes priority over the player's record when the organizer pairs players. In leagues with enough participation, the Tournament Organizer may apply age categories. Categories range from Junior (ages 12 and under), Senior (ages 13–15) and Master (ages 16 and over).\n\nAfter sanctioned tournaments are completed, the Tournament Organizer uploads the results of each match to POP. The results of each match are used to calculate a player's rating. POP Ratings are based on the Elo rating system.\n\nPrerelease Tournaments are Trading Card Game events in which players play with cards from a set that will not be released for several weeks. The typical entry fee is $20–35 and each player will be given six booster packs, a special promo, and a set of sleeves that are themed after the new set. Each player builds a 40-card deck using the cards opened out of the six packs (not including basic Energy cards, which are provided at the event). At the end of each prerelease, players receive two extra booster packs. Players may also have the option of playing in a Theme Deck challenge instead of the Prerelease event, where they play for a theme deck and 4 booster packs.\n\nPremier Tournaments are meant for competition. There are six different types of Premier Tournaments \"(note that the following applies to the Canada and the United States only; other regions may have different prizes)\":\n\n\nThe Pokémon World Championships is an invite-only event where the best players of the season compete for scholarship money, prizes and the title of World Champion. The 2014 Pokémon World Championships was held in Washington, D.C. with the presence of more than 155 trainers from around the world. The 2016 Pokémon World Championships was held in San Francisco, California.\n\n\n\nIn 2009, Play! Pokémon began to organize competitive tournaments for the \"Pokémon\" video game series alongside the Trading Card Game, which is collectively known as the Video Game Championships (VGC). Like the TCG Championships, players compete with other players in their own age divisions (i.e. Junior, Senior and Masters) in different Premier Tournaments, and the season culminates with the best players earning an invitation to play the Pokémon World Championships in August.\n\nPokemon VGC World Champions\n\nIn 2016, Play! Pokémon announced that \"Pokkén Tournament\" will have its own championship series and will be played at the Pokémon World Championships.\n\nA Tournament Organizer (TO) is someone who runs tournaments for their local community. Usually, he or she runs them within a weekly or monthly basis at a local store. However, a Premier Tournament Organizer (PTO) has the ability to run major tournaments and Prereleases as well in any major place at a particular time. Like Pokémon Professors, TOs and PTOs have to be 18 or older.\n\nThe professor program is a special program in which Pokémon Professors help promote the game in many ways; Professors do so by judging, volunteering, advertising and more importantly, promoting the spirit of the game. To become a Pokémon Professor, a player must take the Professor Exam in the Professor section of the Organized Play website. A player must be at least 18 years or older to become a Professor (previously 15 from 2003 until late 2005).\n\nWhilst participation is open to any Pokémon player in the world able to attend, as of July 2017 only the following 55 territories are sanctioned to organize official Play! Pokémon events:\nWhilst all above territories are eligible to organize both trading card game (TCG) and video game (VGC) events, only a select few territories have been allowed to actually handle VGC events in practice due to relatively stricter requirements for the VGC Pokémon Professor program in comparison.\n\n"}
{"id": "46628424", "url": "https://en.wikipedia.org/wiki?curid=46628424", "title": "Predator–prey reversal", "text": "Predator–prey reversal\n\nPredator–prey reversal is a biological interaction where an organism that is typically prey in the predation interaction instead acts as the predator. A variety of interactions are considered a role reversal.\nOne type is where the prey confronts its predator and the interaction ends with no feeding. Two competing predators may interact and the larger predator will prey on the smaller. Smaller organisms may prey on larger organisms. Changing population densities may trigger a role reversal. In addition, adult prey may attack juvenile predators.\n\nAccording to Georgia Institute of Technology research, prey and predator roles have cycles where the prey population may increase, thereby causing the predator population to increase as well. But sometimes the predator population overwhelms the prey to the point of devastating the prey population, subsequently resulting in a devastation of the predator population. Some studies indicate that the roles of each may become reversed to the point that prey begin to eat the predators.\n\nUsing data collected regarding mink–muskrat, gyrfalcon–rock ptarmigan, and phage–Vibrio cholerae relationships, research was done to determine if a theory proposed by researchers at GIT could explain how and why this occurs.\n\nJoshua Weitz, a professor at Georgia Tech's School of Biology, said that particular phenotypes can show up as dominant depending upon changes in the environment around them. When both predator and prey are evolving at the same time, and the predator population has drastic effects on prey, the prey may realize they have the ability to overcome smaller numbers of predators and evolve to a predator-type role.\n\nKnowing how specific species interact with each other in this way enables scientists to study the impact of this on ecosystems in more advanced ways than with numerical data alone. They are able to determine why broad trends happen in ecological systems.\n\nA model called the Lotka–Volterra model after its founders, Alfred J. Lotka and Vito Volterra, focuses on studies of ecology and demographics while attempting to explain why certain plant and animal interactions occur the way they do. Although created in the early 1900s, this model has proven to be flexible and adaptable, allowing it to continue being used today.\n\nA study conducted by Royal Society Open Science worked to explain the reasons for the interactions between predator and prey as described in a literary work by Amos Barkai and Christopher McQuaid.\n\nAlgebraic equations and graphs were used to analyze data to reenact predator–prey reversal roles. The conclusion of this experiment showed that roles between species can reverse when the usual prey populations decrease to significantly low levels, causing the predators to decrease in population size also. Once this occurs, prey then begin to build up their population numbers and as they do, they prey on their original predators.\n\nUnderstanding how ecosystems operate and the interactions that take place between individual species within ecosystems is predicted to be of use when managing natural resources and wildlife within those ecosystems. According to this study, maintainable bionetworks can be established through more accurate anticipation of the reactions of species.\n\nAmphibians often prey on beetle larvae. However, the ground beetle \"Epomis\"' larvae reverse this and prey exclusively on the amphibians that are trying to consume them. Two species of \"Epomis\" (\"E. circumscriptus\" and \"E. dejeani\") use the amphibian's predation behavior to their advantage by luring the amphibian to them. \"The \"Epomis\" larva combines a sit-and-wait strategy with unique movements of its antennae and mandibles to draw the attention of the amphibian to the presence of a potential prey.\"\nOut of 400 tests, the larvae avoided the amphibian's tongue, and counterattacks by attaching itself to the body of the amphibian with an approximate 98% success rate. Once attached, the \"Epomis\" larvae begin to feed.\n\nAbout 10% of predator–prey relationships have smaller organisms preying on larger ones. These are all active attacks though, unlike the \"Epomis\" larvae's strategy to lure the larger amphibian to them. Wizen and Gasith suggest that the strategy could have begun through evolution as an anti-predator defense, and later became the larvae's means of living. The amphibians have not evolved to adjust for the \"Epomis\" larvae yet, as the majority of the animals they prey are an easy catch for the amphibians.\n\nA species of South American ant has adapted the ability to hunt creatures that are up to 13,350 times their mean weight. The \"Azteca andreae\" ants have developed a physical hook that enables their ambushes: the ants are arboreal and ambush flying insects that land on their trees. Whenever a bug lands on the leaf, the ants spring into action: a small number bite down on the legs of the winged creature. While the bug is stuck and attached to the leaf, more ants come to dismember the prey. The average ant can hold up to 5,700 times its own body weight. The reason for this is suggest by a possible co-evolution between the \"Azteca andreae\" ants and the \"Cecropia obtusa\" leaves. The leaves have pronounced velcro-like loops that the ants are able to hook on to. The ants prevent other bugs from eating the leaves, while the leaves gives the often preyed-upon ants a predatory edge.\n\nThe giant water bug \"Kirkaldyia deyrolli\", in the subfamily Lethocerinae within the Belostomatidae, is an endangered species native to Japan that primarily feeds on small frogs and fish. Dr. Shin-ya Ohba has captured photos of \"K. deyrolli\" eating outside of its known primary diet. A 58mm male water bug was found consuming a juvenile Reeves turtle during a nighttime sampling. Dr. Ohba has found \"K. deyrolli\" eating snakes, another rare behavior for the water bug.\n\nThe hunting of juveniles has developed as an effective anti-predator strategy and role reversal. Young predators are at risk from members of their own species and competitors, and they may also be vulnerable to adults of prey species, as young predators pose nearly no predation risk to adult prey. An experiment where juvenile prey were exposed to adult predators while they developed were more likely to kill juvenile predators as adults than prey that was not exposed as juveniles. Increased levels of attack against juvenile predators can deter the adult predators, as the adult predators will avoid locations where their young may be attacked. This in turn reduces the risk of predation on the prey species.\n\nAn experiment with mites as predators and thrips as prey showed that even juvenile prey can attack juvenile predators. These attacks triggered a parental care response in adult predators, who killed juvenile prey that attacked their young. This created a \"cascade of predator attack, prey counterattack and predator defence\".\n\nA more common reversal is interspecific killing among predators. Some species may experience 68% of their known mortalities from being killed by other predators. It is possible that one predator species may kill another and not the other way around, or both species may kill each other. Killing among predators can reduce populations, even to the point of extinction, and may reduce or enhance prey populations.\n\nTwo islands off the west coast of South Africa have very different seafloor ecosystems.\n\nOn Malgas Island, the population is mostly seaweed and rock lobsters. Rock lobsters act as predators, preying on mussels that try to settle. The lobsters also prey on whelks, except for one species, \"Burnupena papyracea\", the shell of which is usually encrusted with a commensal bryozoan.\n\nIn contrast, Marcus Island has a large mussel population, and almost no seaweed or rock lobsters. Whelks, \"Burnupena\" spp also have a large population density at Marcus Island. Rock lobsters brought to Marcus Island were quickly consumed by the whelks, which outnumbered them. This interaction showed a role reversal between a prey species (the whelk), and a predator species (the rock lobster).\n\nPredator–prey reversal is a plot theme in numerous books and movies; it is one version of the story of the underdog who comes back from improbable odds and succeeds against a vastly superior foe, from Bram Stoker's \"Dracula\" to children's movies such as \"Monsters University\".\n\nThe 1987 film \"Predator\" is an example of prey-reversal where the victim becomes the predator. Armed with a stealth suit and ultimate high-tech gear, the predator methodically dispatches the humans that find themselves in the jungle. The last of his squad, \"Dutch\" (Arnold Schwarzenegger) must turn from the hunted, into the hunter. The prey actively confronts its predator.\n\n"}
{"id": "309243", "url": "https://en.wikipedia.org/wiki?curid=309243", "title": "Shrew opossum", "text": "Shrew opossum\n\nThe family Caenolestidae contains the seven surviving species of shrew opossum: small, shrew-like marsupials that are confined to the Andes mountains of South America. The order is thought to have diverged from the ancestral marsupial line very early. They were once included in the superorder but it is now known that Ameridelphia is paraphyletic, having given rise to Australidelphia, and thus could be considered an evolutionary grade. Genetic studies indicate that they are the second most basal order of marsupials, after the didelphimorphs. As recently as 20 million years ago, at least seven genera were in South America. Today, just three genera remain. They live in inaccessible forest and grassland regions of the High Andes.\n\nShrews were entirely absent from South America until the Great American Interchange three million years ago, and are currently present only in the northwestern part of the continent. Traditionally, it was thought that shrew opossums lost ground to these and other placental invaders that fill the same ecological niches. Evidence suggests, however, that both groups not only overlap, but do not seem to be in direct competition, and the marsupials' larger size seems to imply that they prey on shrews and rodents. Several opossums, such as \"Monodelphis\", also occupy small insectivore niches.\n\nShrew opossums (also known as rat opossums or caenolestids) are about the size of a small rat (9–14 cm long), with thin limbs, a long, pointed snout and a slender, hairy tail. They are largely carnivorous, being active hunters of insects, earthworms, and small vertebrates. They have small eyes and poor sight, and hunt in the early evening and at night, using their hearing and long, sensitive whiskers to locate prey. They seem to spend much of their lives in underground burrows and on surface runways. Like several other marsupials, they do not have a pouch, and it appears that females do not carry the young constantly, possibly leaving them in the burrow.\n\nLargely because of their rugged, inaccessible habitat, they are very poorly known and have traditionally been considered rare. Several ecological factors, including density of forest, contribute to the part of the forests the shrew opossums occupy. Recent studies suggest they may be more common than had been thought. Their Karyotype has also been described through contemporary research in order to better understand this organism.\n\nWithin the family of the Caenolestidae, seven extant species are known:\n\n\nHowever, Bublitz suggested in 1987 there were actually two \"Lestoros\" and \"Rhyncholestes\" species (those listed here plus \"L. gracilis\" and \"R. continentalis\"). This is, however, not accepted by most scientists.\n\nAdditionally, species from the fossil record are known:\n\n\n\n\n\n\n\n\n"}
{"id": "665434", "url": "https://en.wikipedia.org/wiki?curid=665434", "title": "Shrunken head", "text": "Shrunken head\n\nA shrunken head is a severed and specially prepared human head that is used for trophy, ritual, or trade purposes.\n\nHeadhunting has occurred in many regions of the world, but the practice of headshrinking has only been documented in the northwestern region of the Amazon rainforest. The only tribes known to have shrunken human heads are of the Jivaroan tribes. These include the Shuar, Achuar, Huambisa and Aguaruna tribes, found in Ecuador and Peru. The Shuar call a shrunken head a \"tsantsa\", also transliterated \"tzantza\". Many tribe leaders would show off their heads to scare enemies.\n\nThe process of creating a shrunken head begins with removing the skull from the neck. An incision is made on the back of the ear and all the skin and flesh is removed from the cranium. Red seeds are placed underneath the nostrils and the lips are sewn shut. The mouth is held together with three palm pins. Fat from the flesh of the head is removed. Then a wooden ball is placed under the flesh in order to keep the form. The flesh is then boiled in water that has been saturated with a number of herbs containing tannins. The head is then dried with hot rocks and sand, while molding it to retain its human features. The skin is then rubbed down with charcoal ash. Decorative beads may be added to the head.\n\nIn the head shrinking tradition, it is believed that coating the skin in ash keeps the \"muisak\", or avenging soul, from seeping out.\n\nShrunken heads are known for their mandibular prognathism, facial distortion and shrinkage of the lateral sides of the forehead; these are artifacts of the shrinking process.\n\nAmong the Shuar and Achuar, the reduction of the heads was followed by a series of feasts centered on important rituals.\n\nThe practice of preparing shrunken heads originally had religious significance; shrinking the head of an enemy was believed to harness the spirit of that enemy and compel him to serve the shrinker. It was said to prevent the soul from avenging his death.\n\nShuar believed in the existence of three fundamental spirits:\n\nTo block a Muisak from using its powers, they severed their enemies' heads and shrank them. The process also served as a way of warning their enemies. Despite these precautions, the owner of the trophy did not keep it for long. Many heads were later used in religious ceremonies and feasts that celebrated the victories of the tribe. Accounts vary as to whether the heads would be discarded or stored.\n\nWhen Westerners created an economic demand for shrunken heads there was a sharp increase in the rate of killings in an effort to supply tourists and collectors of ethnographic items. The terms headhunting and headhunting parties come from this practice.\n\nGuns were usually what the Shuar acquired in exchange for their shrunken heads, the rate being one gun per head. But weapons were not the only items exchanged. Around 1910, shrunken heads were being sold by a curio shop in Lima for one Peruvian gold pound, equal in value to a British gold sovereign. In 1919, the price in Panama's curio shop for shrunken heads had risen to £5. By the 1930s, when heads were freely exchanged, a person could buy a shrunken head for about twenty-five U.S. dollars. A stop was put to this when the Peruvian and Ecuadorian governments worked together to outlaw the traffic in heads.\n\nAlso encouraged by this trade, people in Colombia and Panama unconnected to the Jívaros began to make counterfeit \"tsantsas\". They used corpses from morgues, or the heads of monkeys or sloths. Some even used goatskin. Kate Duncan wrote in 2001 that \"It has been estimated that about 80 percent of the tsantsas in private and museum hands are fraudulent,\" including almost all that are female or which include an entire torso rather than just a head.\n\nThor Heyerdahl recounts in \"Kon-Tiki\" (1947) the various problems of getting into the Jívaro (Shuar) area in Ecuador to get balsa wood for his expedition raft. Local people would not guide his team into the jungle for fear of being killed and having their heads shrunk. In 1951 and 1952 sales of such items in London were being advertised in \"The Times\", one example being priced at $250, a hundredfold appreciation since the early twentieth century.\n\nIn 1999, the National Museum of the American Indian repatriated the authentic shrunken heads in its collection to Ecuador. Most other countries have also banned the trade. Currently, replica shrunken heads are manufactured as curios for the tourist trade. These are made from leather and animal hides formed to resemble the originals.\n\n\n"}
{"id": "8072820", "url": "https://en.wikipedia.org/wiki?curid=8072820", "title": "The Riddlers", "text": "The Riddlers\n\nThe Riddlers is a British children's programme produced by Yorkshire Television for ITV between 1989 and 1998.\n\nThe series centred on Marjorie Dawe and the two Riddlers (small humanoid creatures, portrayed by puppets, whose main aim in life was to \"riddle things out\") named Mossop (voiced by Richard Robinson) and Tiddler (female, but voiced by Mike Gallant), who inhabited her garden at Riddleton End. It would later be revealed that Tiddler was an orphan and had no other next of kin, so Mossop adopted Tiddler as an infant. Tiddler was not the latter's real name, but a title given to young apprentice Riddlers: once they achieved full Riddler status there would be a special (graduation type) ceremony, at which they would be given their 'real' name. Tiddler's training included being told stories by a Riddlestone, usually one of 'Ees-Up's Foibles' (Yorkshire dialect for Aesop's Fables) - she would then have to 'riddle out' the moral of the story.\n\nWhen Tiddler had achieved full Riddler status (by getting the morals of twelve stories correctly) she chose to be called Tiddlup at the ceremony. Marjorie wanted to go to the ceremony but was told by Mossop that only Riddlers and Tiddlers could go as it was a Riddler law. In order to go, she became a tiddler and started to study as a tiddler.\n\nOther characters featured in the show included Marjorie's neighbour, Mr. Montgomery Grimley (a gardener and odd-job man), and several other riddler characters - including another tiddler known as Middler, Mossop's brother Glossop, and Eesup, a story-teller. Marjorie's sister Monica was also featured as a recurring character. Many of the plots featured in the series revolved around the male characters making mistakes which would then be solved by the female ones.\n\n\n226 episodes were produced and broadcast during the series' nine-year run. For much of its run, \"The Riddlers\" was produced by Ian Fell and directed by Chris Ryder (later a series producer). Later series were directed by Ann Ayoub. The executive producer was Chris Jelley.\n\nAll episodes were written by Rick Vanes (whose previous work for YTV included \"Puddle Lane\", \"The Raggy Dolls\" and \"Mooncat\"). \"Ees-Up's Foibles\" stories were written by Shirley Isherwood. Neil Innes provided the music and songs featured. Puppeteer for Middler and Mossop, Richard Robinson, created the puppets and provided illustrations for the \"Ees-Up's Foibles\" stories. David Baker was assistant puppeteer series 1 through 6 and Garry Rutter for the show's last three years.\n\nMany of the programmes were recorded in Yorkshire Television's studios on Kirstall Road, Leeds, although some later episodes were filmed on location. Five VHS releases were issued by Video Collection International, one DVD was issued by Kids Club and several tie-in books were published.\n\nAn episode from the fifth series was broadcast on the CITV channel on 6 January 2013, as part of a weekend of archive programmes to celebrate CITV's 30th anniversary.\n\n\n"}
{"id": "39187060", "url": "https://en.wikipedia.org/wiki?curid=39187060", "title": "Tiger of Sabrodt", "text": "Tiger of Sabrodt\n\nTiger of Sabrodt () is the name given to a wolf shot in Lusatia in 1904; the last free-living wolf to be shot within the current borders of Germany prior to 1945.\n\nThe wolf was shot near the town of Hoyerswerda (then part of Silesia) on 27 February 1904, by a forester who received a 100 mark bounty for killing it. It had broken away from hunters several times and reputedly weighed and measured long and high at the shoulder.\n\nThe wolf had been preying on livestock; the locals referred to it as a \"raubsüchtiges Ungetüm\" (ravening monster). There had been no wolves in the area for a long time, so an escaped circus animal was suspected, and it was given the name \"Tiger of Sabrodt\" after the village of Sabrodt (part of Elsterheide) where it first appeared.\n\nThe carcass was mounted and remains on display in the museum in Castle Hoyerswerda. In the meantime wolves have returned to Lusatia, successfully breeding there in 2009.\n\nThe wolf is the subject of a song titled Tiger of Sabrod on the 2007 album Lupus Dei by German Power metal band Powerwolf.\n"}
{"id": "1149254", "url": "https://en.wikipedia.org/wiki?curid=1149254", "title": "Virginia Fox", "text": "Virginia Fox\n\nVirginia Fox Zanuck (April 2, 1902 – October 14, 1982) was an American actress who starred in many silent films of the 1910s and 1920s.\n\nFox was born in Wheeling, West Virginia (though her grave erroneously lists Charleston, W.Va. as her place of birth), the daughter of Marie (née Oglseby) and Frederick Fox.\n\nWhile on vacation from boarding school, Fox traveled to visit a friend in Los Angeles. The two made a casual stop by the studio of Mack Sennett, where she was hired on the spot and made a bathing beauty in the studio's films. Fox went on to star as leading lady in many of the early films of Buster Keaton, including 1920's highly regarded \"Neighbors.\"\n\nIn 1924 she married film producer Darryl F. Zanuck, with whom she had three children, Darrylin (1931–2015), Susan Marie (1935–1980), and Richard Darryl (1934–2012). Fox retired from acting, but was known as a behind-the-scenes influence on her husband's business decisions. The couple separated in 1956 over the studio mogul's affairs with other women, though they were never legally divorced; but according to Zanuck biographers, she cared for him at their home from the time he became mentally incapacitated in the early 1970s until his death in 1979. She was buried near Darryl Zanuck at the Westwood Village Memorial Park Cemetery in Westwood, Los Angeles.\n\nDespite some Internet accounts to the contrary, Virginia Fox was not related to William Fox, whose name is preserved in the company 20th Century Fox, which Darryl Zanuck created and led for decades. William Fox founded Fox Studios, but had lost control of it by the time Zanuck acquired it and merged it into his own empire.\n"}
{"id": "24833728", "url": "https://en.wikipedia.org/wiki?curid=24833728", "title": "Ælric (Archbishop-elect of Canterbury)", "text": "Ælric (Archbishop-elect of Canterbury)\n\nÆlric (fl. 1050), perhaps a misspelling of Ælfric or Æthelric, archbishop-elect of Canterbury, was a kinsman of Godwin, Earl of Wessex.\n\nAccording to the \"Vita Ædwardi Regis\" Ælric was brought up from early youth in the monastery of Christ Church at Canterbury, and was much beloved by his fellow monks. He was well skilled in worldly matters and took delight in them. On the death of Archbishop Eadsige (October 1050) Ælric was elected to the see of Canterbury by the monastic chapter of his house. In this election the clergy of the province seem to have concurred. The monks sent to Godwin, in whose earldom they were, and informed him of the canonical election of Ælric and begged him to use his influence in behalf of his kinsman. The earl promised to do all he could in the matter. King Edward was, however, at this time inclined to the faction which opposed the earl, and refused his request in behalf of Ælric. In the mid-Lent meeting of the witenagemot, in 1051, Robert of Jumièges was appointed archbishop, much to the anger of English churchmen.\n"}
