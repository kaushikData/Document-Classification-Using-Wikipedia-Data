{"id": "18692328", "url": "https://en.wikipedia.org/wiki?curid=18692328", "title": "Acervulus", "text": "Acervulus\n\nAn acervulus (pl. acervuli) is a small asexual fruiting body that erupts through the epidermis of host plants parasitised by mitosporic fungi of the form order Melanconiales (Deuteromycota, Coelomycetes). It has the form of a small cushion at the bottom of which short crowded conidiophores are formed. The spores escape through an opening at the top.\n\n"}
{"id": "36109793", "url": "https://en.wikipedia.org/wiki?curid=36109793", "title": "Ancient Greek funeral and burial practices", "text": "Ancient Greek funeral and burial practices\n\nAncient Greek funerary practices are attested widely in the literature, the archaeological record, and the art of ancient Greece. Finds associated with burials are an important source for ancient Greek culture, though Greek funerals are not as well documented as those of the ancient Romans.\n\nThe Mycenaeans practiced ritual burial of the dead, and had highly consistent practices in doing so. The body of the deceased was prepared to lie in state, followed by a procession to the resting place, either a single grave or a family tomb. Processions and ritual laments are depicted on burial chests \"(larnakes)\" from Tanagra. Grave goods such as jewelry, weapons, and vessels were arranged around the body on the floor of the tomb. Graveside rituals probably included libations and a meal, since food and broken cups are also found at tombs. A tomb at Marathon contained the remains of horses that may have been sacrificed at the site after drawing the funeral cart there. The Mycenaeans seems to have practiced secondary burial, when the deceased and associated grave goods were rearranged in the tomb to make room for new burials. Until about 1100 BC, group burials in chamber tombs predominated among Bronze Age Greeks.\n\nMycenaean cemeteries were located near population centers, with single graves for people of modest means and chamber tombs for elite families. The \"tholos\" is characteristic of Mycenaean elite tomb construction. The royal burials uncovered by Heinrich Schliemann in 1874 remain the most famous of the Mycenaean tombs. With grave goods indicating they were in use from about 1550 to 1500 BC, these were enclosed by walls almost two and a half centuries later—an indication that these ancestral dead continued to be honored. An exemplary stele depicting a man driving a chariot suggests the esteem in which physical prowess was held in this culture.\n\nLater Greeks thought of the Mycenaean period as an age of heroes, as represented in the Homeric epics. Greek hero cult centered on tombs.\n\nAfter 1100 BC, Greeks began to bury their dead in individual graves rather than group tombs. Athens, however, was a major exception; the Athenians normally cremated their dead and placed their ashes in an urn. During the early Archaic period, Greek cemeteries became larger, but grave goods decreased. This greater simplicity in burial coincided with the rise of democracy and the egalitarian military of the hoplite phalanx, and became pronounced during the early Classical period (5th century BC). During the 4th century, the decline of democracy and the return of aristocratic dominance was accompanied by more magnificent tombs that announced the occupants' status—most notably, the vaulted tombs of the Macedonians, with painted walls and rich grave goods, the best example of which is the tomb at Vergina thought to belong to Philip II of Macedon.\n\nA dying person might prepare by arranging future care for the children, praying, and assembling family members for a farewell. Many funerary steles show the deceased, usually sitting or sometimes standing, clasping the hand of a standing survivor, often the spouse. When a third onlooker is present, the figure may be their adult child.\n\nWomen played a major role in funeral rites. They were in charge of preparing the body, which was washed, anointed and adorned with a wreath. The mouth was sometimes sealed with a token or talisman, referred to as \"Charon's obol\" if a coin was used, and explained as payment for the ferryman of the dead to convey the soul from the world of the living to the world of the dead. Initiates into mystery religions might be furnished with a gold tablet, sometimes placed on the lips or otherwise positioned with the body, that offered instructions for navigating the afterlife and addressing the rulers of the underworld, Hades and Persephone; the German term \"Totenpass\", \"passport for the dead,\" is sometimes used in modern scholarship for these.\n\nAfter the body was prepared, it was laid out for viewing on the second day. Kinswomen, wrapped in dark robes, stood round the bier, the chief mourner, either mother or wife, was at the head, and others behind. This part of the funeral rites was called the \"prothesis.\" Women led the mourning by chanting dirges, tearing at their hair and clothing, and striking their torso, particularly their breasts. The Prothesis may have previously been an outdoor ceremony, but a law later passed by Solon decreed that the ceremony take place indoors.\nBefore dawn on the third day, the funeral procession \"(ekphora)\" formed to carry the body to its resting place.\n\nAt the time of the funeral, offerings were made to the deceased by only a relative and lover. The \"choai\", or libation, and the \"haimacouria\", or blood propitiation were two types of offerings. The mourner first dedicated a lock of hair, along with choai, which were libations of honey, milk, water, wine, perfumes, and oils mixed in varying amounts. A prayer then followed these libations. Then came the \"enagismata\", which were offerings to the dead that included milk, honey, water, wine, celery, pelanon (a mixture of meal, honey, and oil), and kollyba (the first fruits of the crops and dried fresh fruits). Once the burial was complete, the house and household objects were thoroughly cleansed with seawater and hyssop, and the women most closely related to the dead took part in the ritual washing in clean water. Afterwards, there was a funeral feast called the \"perideipnon\". The dead man was the host, and this feast was a sign of gratitude towards those who took part in burying him.\n\nAlthough the Greeks developed an elaborate mythology of the underworld, its topography and inhabitants, they and the Romans were unusual in lacking myths that explained how death and rituals for the dead came to exist. The ruler of the underworld was Hades, not the embodiment of death/personification of death, Thanatos, who was a relatively minor figure.\n\nPerforming the correct rituals for the dead was essential, however, for assuring their successful passage into the afterlife, and unhappy revenants could be provoked by failures of the living to attend properly to either the rite of passage or continued maintenance through graveside libations and offerings, including hair clippings from the closest survivors. The dead were commemorated at certain times of the year, such as Genesia. Exceptional individuals might continue to receive cult maintenance in perpetuity as heroes, but most individuals faded after a few generations into the collective dead, in some areas of Greece referred to as \"thrice-ancestors\" \"(tritopatores)\", who also had annual festivals devoted to them.\n\n"}
{"id": "200945", "url": "https://en.wikipedia.org/wiki?curid=200945", "title": "Arses of Persia", "text": "Arses of Persia\n\nArtaxerxes (Artaxšacā) IV Arses (), was Great King of Persia between 338 BC and 336 BC. He is known as Arses in Greek sources and that seems to have been his real name but the Xanthus trilingue and potsherds from Samaria report that he took the royal name of Artaxerxes IV, following his father and grandfather.\n\nAs the youngest son of King Artaxerxes III and Atossa, Arses was not expected to succeed to the throne of Persia. His unexpected rise to the throne came in 338 BC as a result of the murder of his father and most of his family by Bagoas, the powerful Vizier of Persia who had recently fallen into disfavor with Artaxerxes. Bagoas sought to remain in office by replacing Artaxerxes with his son Arses (Artaxerxes IV), whom he thought easier to control. Arses remained little more than a puppet-king during the two years of his reign, while Bagoas acted as the real power behind the throne. A major concern for Persia during this King's short reign were hostilities on the western borders with Macedonia under Kings Philip II of Macedon and Alexander the Great. This became a war of conquest by Alexander during the reign of Arses' successor Darius III.\n\nAccording to Greek sources, Arses eventually started planning Bagoas' murder, disgruntled by his dependence on the Vizier and possibly influenced by the nobles of the Royal Court, who generally held Bagoas in contempt. The Vizier again acted first in order to protect himself and managed to poison Arses. Bagoas then raised a cousin of Arses to the throne as Darius III. However, a cuneiform tablet in the British Museum (BM 71537) suggests that Arses died from natural causes.\n\nArses is a Greek rendering of an old Persian name. The Iranian form is attested in Avestan Aršan- (etymologically related to Greek \"arsēn\" \"male, manly\") and in old Persian it is preserved in Aršaka and Aršāma.\n\n"}
{"id": "18179847", "url": "https://en.wikipedia.org/wiki?curid=18179847", "title": "Arthur Bingham", "text": "Arthur Bingham\n\nArthur Batt Bingham (1784–1830) was an officer in the Royal Navy, rising to the rank of post captain. He is remembered chiefly for his command of HMS \"Little Belt\", when the Little Belt Affair occurred, just prior to the War of 1812.\n\nBingham was born in 1784, the second son of the Ven. William Bingham, D.D. (1743–1819), vicar of Great Gaddesden (1777) and rector of Hemel Hempstead (1778) – later archdeacon of London (1789–1813) and chaplain to George III (1792); and his wife Agnata (aka Agnes), daughter of Liebert Dörrien, a merchant of Fenchurch Street, London and of West Ham, Essex.<ref name=\"NationalArchives/DocumentsOnline\">National Archives: Will of Libert Dorrien, Merchant of Fenchurch Street, City of London 3 November 1753 PROB 11/804</ref> Arthur entered the Navy, and was promoted to the rank of lieutenant on 1 May 1804. By early 1809 he was first lieutenant aboard HMS \"Nereide\", then on the Cape of Good Hope Station under Captain Robert Corbett.\n\n\"Nereide\" sailed from Simon's Bay on 1 May and cruised off the French possessions of Mauritius and Réunion. In August Corbett began an attack on Sainte-Rose on the eastern side of Réunion, using grapeshot to fire on two batteries overlooking the harbour. The sloop HMS \"Sapphire\", under the command of Acting-Captain Bertie Cornelius Cator, came alongside and fired a broadside, silencing the enemy guns. Bingham then led a party of men from \"Nereide\" onto the shore, narrowly avoiding being killed by a piece of shot that killed the marine next to him. He and his men captured the French governor, spiked the six French cannon, burnt their carriages and blew up a store of rockets. He then laid a train of powder to blow up over 100 barrels of gunpowder contained in a bomb-proof magazine, but it exploded sooner than expected. Bingham was blown 'a considerable distance', and suffered some wounds and burns. Corbett made a list of demands from the French for re-provisioning, and then took off the enemy's guns and sank them in deep water. After the successful conclusion of the operation Corbett wrote reports praising Cator and Bingham.\n\nBingham was again in action off Réunion, when \"Nereide\" was part of Josias Rowley's fleet to retake the French islands. Bingham led the action to capture the French frigate \"Caroline\", and later presented her commander's sword to Corbett. His talent noticed, Bingham was given command of HMS \"Caledon\" at the end of 1809 and sailed her to England.\n\nBy November 1810 Bingham was given the command of the 20-gun sixth-rate sloop \"Little Belt\", and sailed to Halifax, and later to the Caribbean. On 19 April 1811 he was ordered by Rear-Admiral Herbert Sawyer to deliver instructions to Captain Samuel Pechell of HMS \"Guerriere\", then somewhere off the North American coast. If unable to locate Pechell, Bingham was ordered to cruise off the coast, protecting British trade until his supplies were exhausted, at which point he was to put into Halifax and await further orders. He was warned You are to be particularly careful, not to give any just cause of offence to the government or the subjects of the United States of America... Bingham duly sailed from Bermuda, but being unable to locate the \"Guerriere\", commenced cruising off the coast.\n\nOn the morning of 10 May, as \"Little Belt\" was some 48 miles east of Cape Charles at the entrance to Chesapeake Bay, a strange sail was sighted in the distance. Bingham made signal 275 (calling on a strange ship, if a British warship, to show her number). The other ship did not reply, and Bingham concluded that the mystery ship was a frigate of the United States Navy. He hoisted his colours and began to round Cape Hatteras. The frigate followed, closing \"Little Belt\", and appeared to be trying to manoeuvre into a position to rake the smaller British ship. Bingham wore ship three times to foil the American's attempts, while calling for the frigate to identify herself. Each time though the American demanded the same of Bingham. The frigate, actually the 44-gun USS \"President\" under Commodore John Rodgers, then, according to Bingham, opened fire on the \"Little Belt\". Bingham returned fire and an engagement began, lasting three-quarters of an hour. The \"President\" was observed to have a fire onboard and drew away.\n\nThe \"President\" then returned, and asked if Bingham had struck. Bingham replied that he had not, and the \"President\" again withdrew. A messenger was sent out to the damaged \"Little Belt\" by Rodgers the following morning, lamenting the 'unfortunate affair', and insisting that he would not have attacked, had \"Little Belt\" not fired first. Bingham denied this, and turned down Rodgers' offer of putting into an American port for repairs, instead making for Halifax, hampered by a gale on the second day of the voyage which caused leaks in the already-damaged ship. \"Little Belt\" had nine killed outright, and had 23 wounded, some mortally. Two died the day after the battle. Rodgers claimed that the British ship had been mistaken for a larger frigate, and continued to claim that Bingham had fired first. Bingham wrote in his report \"a boat accordingly came, with an officer, and a message from Commodore Rodgers, of the President, United States frigate, to say, that he lamented much the unfortunate affair (as he termed it) that had happened, and that had he known our force was so inferior, he should not have fired at me. I asked his motive for having fired at all; his reply was, that we fired the first gun at him, which was positively not the case...[it is not] probable that a sloop of war, within pistol-shot of a large 44-gun frigate, should commence hostilities. The \"Little Belt\" was later paid off and sold.\n\nThe Admiralty refused to try Bingham by court-martial, and the matter was never successfully concluded, both governments supporting their respective captains' version of events. Bingham was promoted to post captain on 7 February 1812.\n\nIn 1812 the Duke of Clarence (the future King William IV) arranged for Bingham to be esquire to the proxy at the installation of Richard Goodwin Keats to the Order of the Bath. Bingham continued in the Navy, being appointed to command HMS \"Myrtle\" on 18 November 1813, followed by being made flag captain to Rear-Admiral Robert Otway aboard HMS \"Dover\" on 25 September 1819. He was appointed to HMS \"Thetis\" on 9 November 1826. He drowned in 1830.\n\nOn 20 August 1830, the Thetis was anchored off Puna Island (Ecuador). Captain Bingham chose to go ashore to Guayaquil. During transit, the barge was swamped resulting in the deaths of the ship's chaplain and Captain Bingham.\n\nBingham had married Emily Kingsman on 11 March 1813, and the couple had four sons and daughter. Two, Arthur Maunsel Bingham and Thomas Henry Bingham also had naval careers, whilst the third son, William Poulet Bingham became a lieutenant-colonel of the 64th Regiment. The fourth son was Francis Robert Bertie Bingham, and the daughter was Emily Agnata Harriet Bingham.\n\n"}
{"id": "23568330", "url": "https://en.wikipedia.org/wiki?curid=23568330", "title": "Before We Ruled the Earth", "text": "Before We Ruled the Earth\n\nBefore We Ruled the Earth is a two-part documentary television miniseries that premiered on February 9, 2003 on the Discovery Channel. The program featured early human history and the challenges human beings faced thousands of years ago. It also features animals examples such as: Woolly mammoth, \"Megantereon\", American buffalo, cave bear, and Irish elk (\"Megaloceros giganteus\"). The first episode was called \"Hunt or Be Hunted\" and the second called \"Mastering the Beasts.\"\n\n\"Hunt or Be Hunted\" (narrated by Linda Hunt). The first part in the series shows how humans started out as prey for other animals such as saber-toothed cats. It depicts a saber-toothed cat killing an antelope and leaving the remains of the carcass, our ancestors attempt to steal the remains from the cat and one of the group is killed as the saber tooth spots them. It also shows how we discovered tools and made use of the sharpened stone. Later the show showed how as we grew more intelligent, that we were able to turn the tables on the beasts.\n\nSpecies discussed:\n\"Homo ergaster\",\n\"Megantereon\",\n\"Homo erectus\",\n\"Megaloceros\",\n\"Homo neanderthalensis\",\nSteppe bison, and\nCro-Magnon.\n\n\"Mastering the Beasts\" (narrated by John Slattery). The second and last part in the series takes place during the Ice Age. It shows how the Cro-Magnon and modern humans have become the dominant species and how we hunted animals such as mammoth, Irish elk, aurochs and buffalo. Threats however include giant cave bears and wolves. Death on the tundra was common and to survive our ancestors need to be able to adapt to change, such as the warming of the earth at the end of the last Ice Age ... something most of the giant beasts could not do, and therefore suffered extinction.\n\nSpecies discussed:\nCro-Magnon,\nCave bear\nAurochs,\nWoolly mammoth,\nTundra wolf,\nPaleo-Indian,\n\"Megalonyx jeffersoni\",\n\"Homo sapiens\", and\nAmerican buffalo.\n\n"}
{"id": "44707607", "url": "https://en.wikipedia.org/wiki?curid=44707607", "title": "Bibliography of encyclopedias: biology", "text": "Bibliography of encyclopedias: biology\n\nThis is a list of encyclopedias as well as encyclopedic and biographical dictionaries published on the subject of biology in any language.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3827", "url": "https://en.wikipedia.org/wiki?curid=3827", "title": "Bilge Khagan", "text": "Bilge Khagan\n\nBilge Khagan (Old Turkic: 𐰋𐰃𐰠𐰏𐰀 𐰴𐰍𐰣, Bilge qaγan; ) (683 – 25 November 734) was the khagan of the Second Turkic Khaganate. His accomplishments were described in the Orkhon inscriptions.\n\nAs was the custom, his personal name and the name after assuming the title khagan were different. His personal name was recorded in Chinese characters as (). His name after assuming the title was \"Bilge qaγan\". (Old Turkic: , \"Bilge qaγan\", ). His official title: , Teŋіriteg Тeŋiride bolmuš Türük Bilge qaγan.\n\nHe was born in 683, just in early years of Second Khaganate. He campaigned alongside his father from early years as a child. He was created as Tardush shad and given command over western wing of empire in 697 by Qapaghan. He managed to annihalate Wei Yuanzhong's army in 701 with his brother. He also reconquered Basmyl tribes in 703. He also subdued Yenisei Kyrgyz forces in 709, after their disobedience had to reconquer and kill their khagan in 710. He killed Sakal in his invasion of Turgesh in 711 and had submission from Beshbaliq in 713.\n\nIn later years of Qapaghan, he had to fight 4 battles in a year starting from 714, resubduing tribes and nearly was killed in an ambush from Huige forces in 715.\n\nIn 716, Qapaghan Qaghan, the second khagan, was killed in his campaign against the Toquz Oghuz alliance and his severed head was sent to Chang'an. Although his son Inel Khagan succeeded him, Bilge's brother Kul Tigin and Tonyukuk carried out a coup d'état against Inel Khaghan. They killed him and made him \"Bilge\" \"khagan\". His name literally means \"wise king\".\n\nHe appointed his brother Kul Tigin to be Left Wise Prince, which made second most powerful person in realm. He resubdued Huige in 716. Also appointed his father-in-law Tonyukuk to be Master Strategist.\n\nNew reforms and stabilization of regime caused tribes that fled Tujue to come back. Tang chancellor Wang Jun, believing that the Göktürks who surrendered would try to flee back to the Göktürk state, suggested that they be forcibly moved into the heart of the empire to prevent them from doing so. Before Wang's suggestion could be acted upon, however, there was an uprising by the Göktürks who surrendered, under the leadership of Xiedie Sitai (𨁂跌思泰) and Axilan (阿悉爛). Xue and Wang tried to intercept them and dealt them defeats, but they were able to flee back to the Göktürk state anyway. This defeat led to Xue Ne's retirement.\n\nAt some point in his life, he wanted to convert to Buddhism, settle in cities. However, Tonyukuk discouraged him from this, citing Tujue's small numbers and vulnerability to Chinese attack. While Turks' power rested on their mobility, conversion to Buddhism would bring pacifism among population. Therefore, sticking to Tengriism was necessary to survive.\n\nIn 720, Wang believed that the Pugu (僕固) and Xiedie tribes of the region were planning to defect to Eastern Tujue and attack with Eastern Tujue troops. He thus held a feast and invited the chieftains, and, at the feast, massacred them. He then attacked the Pugu and Xiedie tribes in the area, nearly wiping them out. He then proposed a plan to attack khagan along with the Baximi, Xi, and Khitan. Emperor Xuanzong also recruited Qapaghan Khagan's sons Bilge Tigin and Mo Tigin, Yenisei Kyrgyz khagan Kutluk Bilge Khagan and Huoba Guiren to fight against Tujue. Tonyukuk cunningly launched first attack on Baximi in 721 autumn, completely crushing them. Meanwhile, Bilge raided Gansu, taking much of the livestock. Later that year Khitans, next year Xi were also crushed.\n\nIn 726, his father-in-law and chancellor Tonyukuk died.\n\nIn 727, he sent Buyruk Chor () as en emissary to Xuanzong to send 30 horses as gift. He also alarmed him of Me Agtsom's proposal of anti-Tang alliance. This alarm proved to be true when Tibetan general We Tadra Khonglo invaded Tang China in 727, sank Guazhou (瓜州, in mordern Gansu), Changle (常樂, in south of mordern Guazhou County), Changmenjun (長門軍, in north of mordern Yumen) and Anxi (安西, mordern Lintan).\n\nOn 27 February 731, Kul Tigin died, for which khagan mourned and ordered a great funeral ceremony.\n\nIn 733, he defeated rebellious Khitan tribes.\n\nJust after sending an emissary to Xuanzong to gain heqin alliance, he was poisoned by Buyruk Chor. He didn't die immediately and he had time to punish the family of Buyruk Chor with death. He died on 25 November 734, his burial ceremony took place on 22 June 735.\n\nHe was married to El Etmish Bilge Khatun, Tonyukuk's daughter. He had several issues:\n\n\nAfter his death from poisoning, several steles were erected in the capital area by the Orkhon River. These Orkhon inscriptions are the first known texts in the Old Turkic language.\n\nEncyclopædia Britannica, Micropaedia, Vol. II, pp. 16–17\n\n\n \n"}
{"id": "41246005", "url": "https://en.wikipedia.org/wiki?curid=41246005", "title": "Bird migration perils", "text": "Bird migration perils\n\nMigrating birds face many perils as they travel between breeding and wintering grounds each year.\n\nMigration is a dangerous part of a bird's life cycle, with many trade-offs; birds receive benefits from wintering and breeding in better quality habitats, at the price of higher predation risks and greater energy expenditure.\n\nHazards during migration include storms, hunting, collisions with manmade objects such as wind turbines, and starvation. The risk of starvation is increased when stopover sites are lost through climate change or loss of habitat to development or agriculture. Mortality on both breeding and wintering grounds may be increased for similar reasons.\n\nMigrants tend to travel away from polar and temperate zones in the winter because of low temperatures and shortage of food in their breeding areas. During spring migration, birds return to their breeding sites to exploit the temporary superabundance of food, allowing them to raise more young.\n\nMany populations of migratory birds are in serious decline. Anthropogenic reasons for this include deforestation and habitat loss, hunting, pesticide uses, urbanization and climate change. Identifying and understanding the processes and perils can allow us to implement effective management and conservation strategies for these species.\n\nIn-flight mortality: poor weather conditions can significantly decrease bird populations, especially during migration. Most of weather-related in-flight mortalities are due to heavy storms, mist or rain. Passerines and other small sized birds are particularly affected by adverse in-flight weather conditions, but larger birds such as eagles and swans could also be killed.\n\nMortality on breeding grounds: small, insect eating birds contribute to the majority of post-arrival deaths, but many other birds including waders and waterfowls are also distressed by weather changes on breeding grounds. Since young birds are inexperienced, they are more vulnerable than adults to extreme weather conditions.\n\nMortality on wintering grounds: Unreasonably cold temperatures on the wintering grounds kills thousands of birds, resulting in 30-90% population declines of migratory birds. For example, between 27000 and 62000 ducks, mostly tufted duck and common pochard, starved to death during a very cold winter in March 1986.\n\nThe passing of Migratory Bird Treaty (US, 1916) and Migratory Birds Convention Act (Canada, 1917) made it illegal to kill or capture migratory birds. Even though migratory bird acts were passed at the beginning of the 19th century, many countries still have no laws or programs to protect migratory birds. International bird trade is a multibillion-dollar industry and hundreds of exotic birds are captured and then sold all over the world.\n\nMalta, an archipelago of small islands along the Mediterranean, is a very important migration flyway for birds. Throughout the years, hunters killed hundreds of millions of birds each year as they migrate over the island of Malta. To protect resident and migratory birds, BirdLife international had been organizing special raptors camps since the late 1990s. Even though hunting is a part of Maltese people’s culture, the interference from birdwatchers all over the world has led to decreased killings of birds.\n\nWhile hunting kills millions of terrestrial birds, the bycatch from commercial fisheries is responsible for the majority of human caused mortality of migratory birds. Scientists have estimated that between 2679 and 45586 birds are killed each year as fisheries by-catch. Dredging, gillnetting bottom otter trawling and longline’s are some of the main methods fisheries use to catch fish. Gillnets are responsible for the majority of seabird bycatch, followed by longline and bottom trawling. To catch tuna and other fish, long-line fishing boats drag many kilometers of hooked lines behind them. Seabirds try to catch the fish and accidentally get trapped in hooks.\n\nMajor foraging areas for vulnerable seabirds (albatrosses and shearwaters) tend to overlap with world’s richest fishing grounds, thus increasing the proportions of accidental bycatch of birds. Fisheries could also indirectly affect the trophic structure and foraging methods of seabirds. Since most sea birds are long-lived and have low reproduction rates, even a small increase in bird mortality could cause significant population declines.\n\nBirds use stopover sites to feed, rest and refuel during their migration period. Many of the current stopover sites are threatened due increased urbanization, agriculture, gas exploitation, fisheries, tourism and many others anthropogenic activities. In one study the researchers found that birds with high phenotypic plasticity can adapt their behavior and skip low-quality stopover sites. Migratory birds such as swans, geese and waders show high site fidelity (they are loyal to their stopover and cannot change them), while long distance passerines have much lower site fidelity. Passerines have low site fidelity because they can be flexible in their habitat selection. Since they do not migrate in flocks, migratory passerines do not have a fixed migration route or stop-over site sequence and they can change their stopover sites based on wind selectivity or habitat quality. Even though many birds can change their stopover sites, birds such as swans and waders depend on wetland stopover sites to 'refuel' on migration. The destruction of these sites could therefore be detrimental to bird populations.\n\nIncreased predation at stopover sites could lead to drastic declines in migratory bird populations. The study done by Lank and Ydenberg (2003) examined the effects of predators on migratory birds at stopover sites. The researchers found that predation risk is higher for heavier birds (due to decreased take-off ability) and leaner birds (increased exposure due to higher feeding needs). Many birds also developed anti-predator behaviors to lower the probability of mortality. Since anti-predator behaviors are energetically costly, the migrants with lower energy reserves allocated less time to anti-predator behaviors.\n\nOver 40 million seabirds are negatively affected by oil platforms. Seabirds tend to aggregate around oil rigs, attracted by artificial lighting, flares, food and other visual cues. Seabirds often collide directly with oil platforms or circle around oil rigs and flares for days, eventually dying of starvation. Birds such as storm petrels, dovekies and shearwaters migrate across the Grand Banks and hydrocarbon development near the oil platforms significantly decreases the populations of these birds.\n\nSince there are very little regulations regarding pesticide use in the tropics, the farmers in South America use high quantities of highly toxic pesticides to protect their crops. For example, DDT is currently banned in North America because it killed millions of birds in the 1960s, but it is still heavily used in the tropics. Pesticides can kill birds both directly and indirectly. In the case of DDT, it can kill birds directly by poisoning their nervous system and indirectly by making the eggshells thinner and thus reducing reproductive success of birds.\n\nIn their study on Dickcissels and crop damage in Venezuela, Basili and Temple (1999), found that the population of Dickcissels declined by 40% between the years of 1960 and 1980. The declines were primarily due to direct killings by humans. Dickcissels migrate to Venezuela in winter and they tend to gather in large colonies (millions of birds) to feed and sleep. Farmers in Venezuela thought that Dickcissels were pests that fed on rice and cereal crops, so they aerially sprayed the region with pesticides to kill of the birds. The dickcissels consumed only 0.37-0.745% of the grains produced. If the farmers had been better informed of how small of an impact Dickcissels had on their crops, the population declines of these birds could have been prevented.\n\nNight skies are obscured by artificial lights in many cities around the world. These lights are illuminated from buildings, roads and other human structures. When flying across the city, migratory birds could become attracted to artificial lights in the sky. These birds tend to follow light beams and fly continuously in circles, dying from exhaustion or predators as the result. Increased illumination due to artificial lighting could also disrupt foraging behavior of diurnal birds, making these species forage at night, instead of the day. The negative effects from artificial lights are particularly evident in bad weather and when stars are covered by clouds, because birds that migrate at night use light beams for navigation. To decrease the impact of artificial lighting, many cities had implemented lights out program, in which people turn off or dim the lights in tall buildings during migration season.\n\nArtificial light sources can attract millions of birds to lighthouses, broadcast towers and other buildings, resulting in direct mortality of birds at night. There are less artificial lights during the day, but millions of birds still die due to direct collisions with various human made structures. Birds often fatally strike the glass because they cannot differentiate between real sky and reflection of a sky in a window. Any object that increases bird density near windows can potentially lead to higher death rates. Reflective windows are particularly dangerous as birds are often attracted to them. Placing bird attractants such as bird houses, water and nutritious vegetation near windows also increases the number of birds killed.\n\nIn his study on window collisions and bird mortality, Klem banded an indigo bunting that survived window collision, only for it to be killed striking the same window the following year. He estimated that the annual mortality of birds due to window collisions in United States was between 95-975 million birds per year. To reduce bird strikes, it is suggested to remove all bird attractants near the windows or to partially cover the windows. For new buildings, scientists have recommended installing windows in a way that panes reflect the ground instead of the sky.\n\nWind turbines kill thousands of birds through collisions, disruption of migratory routes and destruction of habitat. Birds such as raptors (eagles, vultures), waterbirds and passerines are particularly affected. The reasons these birds are affected is because many of them have blind spots and they often cannot see objects (wind farms) directly in front of them. In Altamont Pass Wind Farm, 4000 wind turbines kill 75 golden eagles and over 1, 200 other predatory birds each year. These predatory birds are rare and long lived; they also have low reproductive rates and if their populations decline substantially, they may never recover. However, if wind turbines are constructed in regions that do not overlap with migratory pathways of birds, the bird casualties could be significantly reduced.\n\nForest fragmentation is one of the greatest perils to migratory birds. Fragmented areas tend to have more parasites, increased nest predation and lower habitat heterogeneity. Habitat loss also means that the region has lower carrying capacity and this leads to increased intraspecific competition between territorial species. In 1989, John Rappole made early use of radio-tags to monitor the location of Wood Thrushes in Veracruz Mexico. Since the 1960s this region had lost over 50% of its forest cover. Rappole noticed that primary rainforests were occupied almost exclusively by older wood thrush. First year birds are smaller and inexperienced, thus they cannot compete with older birds and are forced to live along the forest edge. Younger birds often become wanderers and they are more likely to be eaten by hawks and other predators. These negative conditions in wintering grounds experienced by young and late arriving birds could potentially carry over to breeding habitats, altering population dynamics and lowering the fitness levels of effected bird species.\n\nDeforestation leads to fragmented forest habitats and nest predators tend to be more abundant in these fragmented landscapes. If the fragmented area is long and narrow, it will have greater predation rates because it can easily be reached by nest predators from other areas. Compared to rural woodlots, nest predation rates were higher in suburban areas due higher densities of nest predators such as Blue Jay, Common Grackle, raccoons, dogs, cats and rats. Deforestation thus affects population cycles of birds by changing predator-prey relationships and making the birds more susceptible to predators.\n\nOil developments at the tar sands is one of the main causes of deforestation in Canada. Less than 14% of Alberta's boreal forest remains intact. Loss of Canadian boreal forest is a threat to migratory birds.\n\nMigratory birds are seriously affected by climate change because they cannot assess changes in spring weather from their wintering grounds. Higher spring temperatures can lead to earlier increases in insect abundance, but many bird species were not able to advance their arrival dates. For example, pied flycatchers timed their egg hatch cycles with subsequent increases in food to raise as many young as possible. Spring migration based on day length had allowed flycatchers to arrive on time, and their egg laying times correlated with insect abundances. However, due to climate change, the flycatchers are now forced to lay eggs earlier, which leaves these birds not enough time to prepare their nests properly. Climate change poses a serious threat to long distance migrant birds because they arrive at inappropriate time to exploit environmental opportunities, and face higher competition with resident species. Birds such as the pied flycatcher can start nesting earlier, but their arrival time at the breeding grounds does not change because birds cannot remotely sense temperature changes on breeding grounds from their wintering grounds. The birds cannot depart their wintering grounds unless they have enough energy and fat reserves to support their migration journey, and since early arriving birds usually get the best resources, most species face intense competition for early arrival and early departure. For example, in American redstart, individuals with better phenotypic qualities arrive and mate first.\n\n"}
{"id": "2087590", "url": "https://en.wikipedia.org/wiki?curid=2087590", "title": "Blanca of Navarre, Queen of Castile", "text": "Blanca of Navarre, Queen of Castile\n\nBlanca of Navarre (, ; aft. 1133, Laguardia, Álava – August 12, 1156) was Queen of Castile, the daughter of King García Ramírez of Navarre and his first wife Margaret of L'Aigle. Blanca married Sancho III of Castile, regent of Castile (subject to his father Alfonso VII) on February 4, 1151 in Carrión de los Condes, Palencia, after travelling from Calahorra, Logroño, in January. The marriage was arranged to insure closer ties between León-Castile and Navarre. As was traditional, Blanca confirmed documents with her husband, so her activity may be traced until 1155. On November 11, 1155 she gave birth to the future king Alfonso VIII. There appears to be no record of her activities after December 1155, and she died on August 12, 1156. The cause of her death seems to have been complications of a new pregnancy, a child named García. In addition, she had other children buried in the church of San Pedro in Soria, although they are not identified. That her death was caused by a pregnancy is recorded in an epitaph engraved on her tomb, however, the engraving did not survive a sixteenth-century reconstruction of the royal tombs in Nájera. Her sarcophagus lid was preserved, and it represents the queen's deathbed with members of the court, including her husband, mourning her passing. Blanca was buried in the pantheon of the Navarrese kings in the monastery called Santa María la Real of Nájera, to which Sancho made donations on her behalf. The sarcophagus of the queen is regarded as a primary example of the ability to express human emotions in visual images in the 12th century. \n\nBlanca and Sancho had two named sons:\n"}
{"id": "48084571", "url": "https://en.wikipedia.org/wiki?curid=48084571", "title": "Carmen de Patagones school shooting", "text": "Carmen de Patagones school shooting\n\nThe Carmen de Patagones school shooting occurred on 28 September 2004 at the \"Islas Malvinas\" Institute in Carmen de Patagones, Buenos Aires Province, Argentina. Rafael Solich, 15, killed three fellow students and wounded five more.\n\nSolich is the son of Rafael Solich and Esther Pangue. His father nicknamed him \"Juniors\", after the Buenos Aires football club Boca Juniors. His father was involved in the Argentine Naval Prefecture, and Solich took his gun to commit the shootings.\n\nSolich had one friend, Dante, and the pair communicated in English to keep private. Classmates said that the pair listened to Marilyn Manson and wore black, and would draw Satanic imagery such as inverted crosses.\n\nThe morning of Tuesday 28 September 2004, in the middle school N°202 \"Islas Malvinas\" in Carmen de Patagones, a 15-year-old student named Rafael Solich, known as \"Junior\", opened fire upon his classmates in their classroom. The massacre took place at 7:35, time at which classes started. Solich entered the institute in which around 400 students attended class, hiding a Browning 9mm pistol (which belonged to his father, subofficial of the Argentine Naval Prefecture), two full magazines and a hunting knife hidden in a military coat.\n\nIn the classroom 1° B, Solich stood up in front of the class, took the gun, and discharged the entire magazine upon his classmates without saying a word. After emptying the magazine, he headed for the hall, loaded a second magazine and shot again, this time for the person in charge of the school buffet, who he did not manage to injure.\n\nHe kept walking through the main hall until Dante Pena, one of his classmates and best friends, tackled him and removed his weapon. After the authorities were warned, he did not resist, was arrested and transferred to the port city of Bahía Blanca.\n\nBecause of the attack three of his classmates died, aged between 15 and 16, and five other students were injured. The then-president Néstor Kirchner described the episode as \"painful\" and declared two national days of mourning.\n\nIn all of the schools in the country, an event of reflection was held, where a letter sent by the Ministry of Education was read for everyone.\n\nSolich told a judge \"I remember some of it...no, I don't know. Actually, it went really quickly\". He did not sleep the night before the attack, confessing that he was nervous. He did not show anyone his gun, but displayed his knife to Dante. Although he would not answer when asked for his motive, he revealed that he had been angry with his peers since kindergarten and had been planning an attack since the seventh grade: \"they say that I am strange...they fuck with me because I have this spot on my nose\".\n\nHis father was jailed for 45 days and made to relinquish his firearm.\n\nSolich was treated for a personality disorder. He was kept in psychiatric care until 2007, when he was given liberty from the hospital in La Plata for a weekly ration of hours: first 24, then 48, then 96. As of September 2014, he did not work or study. A female survivor of the attack saw him in the streets of the city, and subsequently suffered panic attacks and required therapy. Before his location was discovered, Argentine media speculated on it.\n\nSolich's family were evacuated from Carmen de Patagones immediately after the attack. Dante was deemed by the community to have had prior knowledge of the attack, and was ostracised, with parents threatening to not send their children back to school if he were there; eventually, he and his family were also moved out of town.\n\nThe families of the victims sued the Naval Prefecture and the province's Schools Department for 12 million Argentine pesos.\n"}
{"id": "4078497", "url": "https://en.wikipedia.org/wiki?curid=4078497", "title": "Cedar Forest", "text": "Cedar Forest\n\nThe Cedar Forest is the glorious realm of the gods of Mesopotamian mythology. It is guarded by the demigod Humbaba and was once entered by the hero Gilgamesh who dared cut down trees from its virgin stands during his quest for fame. The Cedar Forest is described in Tablets 4-6 of the great Epic of Gilgamesh.\n\nEarlier Sumerian versions of the Epic of Gilgamesh say that Gilgamesh travelled east, presumably, to the Zagros mountains of Iran (ancient Elam) to the cedar forest, yet the later more extensive Babylonian examples place the cedar forests west in Lebanon. \n\nTablet four tells the story of the \njourney to the Cedar Forest. On each day of the six-day journey, Gilgamesh prays to Shamash; in response to these prayers, Shamash sends Gilgamesh oracular dreams during the night. The first is not preserved. In the second, Gilgamesh dreams that he wrestles a great bull that splits the ground with his breath. Enkidu interprets the dream for Gilgamesh: the dream means that Shamash, the bull, will protect Gilgamesh. In the third, Gilgamesh dreams:\n\nEnkidu's interpretation is missing here, but as with the other dreams, it is assumed he puts a positive spin on the volcanic dream. The fourth dream is missing, but Enkidu again tells Gilgamesh that the dream portends success in the upcoming battle. The fifth dream is also missing.\n\nAt the entrance to the Cedar Forest, Gilgamesh begins to quake with fear; he prays to Shamash, reminding him that he had promised Ninsun that he would be safe. Shamash calls down from heaven, ordering him to enter the forest because Humbaba is not wearing all his armor. The demon Humbaba wears seven coats of armor, but now he is only wearing one, so he is particularly vulnerable. Enkidu loses his courage and turns back; Gilgamesh falls on him and they have a great fight. Hearing the crash of their fighting, Humbaba comes stalking out of the Cedar Forest to challenge the intruders. A large part of the tablet is missing here. On the one part of the tablet still remaining, Gilgamesh convinces Enkidu that they should stand together against the demon.\n\nGilgamesh and Enkidu enter the gloriously beautiful Cedar Forest and begin to cut down the trees. Hearing the sound, Humbaba comes roaring up to them and warns them off. Enkidu shouts at Humbaba that the two of them are much stronger than the demon, but Humbaba, who knows Gilgamesh is a king, taunts the king for taking orders from a nobody like Enkidu. Turning his face into a hideous mask, Humbaba begins to threaten the pair, and Gilgamesh runs and hides. Enkidu shouts at Gilgamesh, inspiring him with courage, and Gilgamesh appears from hiding and the two begin their epic battle with Humbaba. Shamash intrudes on the battle, helping the pair, and Humbaba is defeated. On his knees, with Gilgamesh's sword at his throat, Humbaba begs for his life and offers Gilgamesh all the trees in the forest and his eternal servitude. While Gilgamesh is thinking this over, Enkidu intervenes, telling Gilgamesh to kill Humbaba before any of the gods arrive and stop him from doing so. Should he kill Humbaba, he will achieve widespread fame for all the times to come. Gilgamesh, with a great sweep of his sword, removes Humbaba's head. But before he dies, Humbaba screams out a curse on Enkidu: \"Of you two, may Enkidu not live the longer, may Enkidu not find any peace in this world!\" Soon later Enkidu becomes sick and dies.\n\nGilgamesh and Enkidu cut down the cedar forest and in particular the tallest of the cedar trees to make a great cedar gate for the city of Nippur. They build a raft out of the cedar and float down the Euphrates to their city.\n\nAfter these events, Gilgamesh, his fame widespread and his fame resplendent in his wealthy clothes, attracts the sexual attention of the goddess Ishtar, who comes to Gilgamesh and offers to become his lover. Gilgamesh refuses with insults, listing all the mortal lovers that Ishtar has had and recounting the dire fates they all met with at her hands. Deeply insulted, Ishtar returns to heaven and begs her father, the sky-god Anu, to let her have the Bull of Heaven to wreak vengeance on Gilgamesh and his city:\n\n"}
{"id": "42243433", "url": "https://en.wikipedia.org/wiki?curid=42243433", "title": "Chanchala", "text": "Chanchala\n\nChanchala is a Sanskrit adjective basically referring to the unsteady vacillating nature of human mind and actions which need to be stilled, neutralized or controlled for gaining right speech and vision.\n\nChanchala (Sanskrit: चञ्चल) means - 'inconsiderate', 'nimble', 'shaking', 'inconstant', 'moveable', 'flickering', 'moving', 'unsteady', 'fortune', 'wind', 'long pepper', 'goddess of fortune' \n\n\"Chanchala\" is the good word for 'vacillation' in Sanskrit language; in poetry the girl with the dancing eyes is called \"chanchalakshi\", which is considered to be rare attribute. However, as part of the literary evidence of Kusana period, the word \"Chanchala\", like \"Dhavani\" and \"Rodini\", indicates the nature or action of Mother goddess. In the Bhagavad Gita(Sloka VI.26):\nthe word Chanchala used in the first line refers to the restless and the unsteady mind that wanders away.\n\nDasam Granth, which like the Guru Granth Sahib is an important book of Sikhism, it is not composed in ragas (its first composition dates 1684 A.D.) tells us that \"Chanchala\" is the name a \"chhand\" or metre of sixteen syllables having \"ragan\", \"jagan\", \"ragan\", \"jagan\" and \"laghu\" consecutively in each quarter, this metre is also known as \"Chitra\", \"Biraj and \"Brahmrupak\", and has been used twice in \"Choubis Autar\".\n\n\"Chanchala\", meaning, 'the fickle-fortune', is one of the many names of Lakshmi. There is no mention of \"Lakshmi\" in the Rig Veda. Sri of the Rig Veda is deified as a personified being in the Yajurveda, and in the Atharvaveda (I.18) she is prayed to secure prosperity. \"Jatavedas Agni\" is repeatedly asked to make the goddess come to the votary; the epithet \"anapagamini\" reflects the \"chanchala\" i.e. fleet or fickle aspect of the goddess. \"Lakshmi\" or \"Chanchala\" as the mobile one associates only with the rich and the dynamic, no matter what their caste, creed or colour. Because \"Lakshmi\" is \"chanchala\" i.e. quick on her feet, to make her \"achala\" i.e. 'immobile', she needs to be worshipped quietly so that she does not get distracted.\n\nIn Yoga, \"vritti\" indicates the contents of mental awareness that are disturbances in the medium of consciousness. The \"vrittis\" of the \"gunas\" are ever-active and swift, the \"gunas\" serve as parts of \"buddhi\", their habitual conduct is fickle, restless, tremulous (\"chanchala\") activity, which activity can be controlled through \"Abhyasa\", \"Vairagya\" and \"Ishvarapranidhana\". \"Sri Narada Pancharatnam\" (Sloka VIII.15) tells us that \"Chanchala\" is the \"nadi\" which along with \"Medhya\" resides in the \"Visuddha Chakra\" on the throat.\n"}
{"id": "511466", "url": "https://en.wikipedia.org/wiki?curid=511466", "title": "Computational number theory", "text": "Computational number theory\n\nIn mathematics and computer science, computational number theory, also known as algorithmic number theory, is the study of algorithms for performing number theoretic computations.\n\n\n\n"}
{"id": "11239314", "url": "https://en.wikipedia.org/wiki?curid=11239314", "title": "Cyphonism", "text": "Cyphonism\n\nCyphonism (Gr , from , \"bent, crooked\") was a form of punishment by the (\"kyphon\"), a sort of wooden pillory by which the neck of the malefactor was bent or weighed downward. Formerly, this term was widely believed to refer to a form of punishment in which the criminal's naked body was smeared with honey, and exposed him to flies, wasps, etc.\n\n"}
{"id": "39207238", "url": "https://en.wikipedia.org/wiki?curid=39207238", "title": "Dorsal nexus", "text": "Dorsal nexus\n\nThe dorsal nexus is an area within the dorsal medial prefrontal cortex that serves as an intersection point for multiple brain networks. Research suggests it plays a role in the maintenance and manipulation of information, as well as supporting the control of cognitive functions such as behavior, memory, and conflict resolution. Abnormally increased connectivity between these networks through the Dorsal Nexus has been associated with certain types of depression. The activity generated by this abnormally high level of connectivity during a depressive state can be identified through Magnetic resonance imaging (MRI) and Positron emission tomography (PET).\n\nThe brain's intrinsic connections are divided into different networks that enable communication between the different structures: The cognitive control network, or Executive network (EN), the affective network or somatic network, and the default mode network. These regions are dependent on the dorsal nexus to communicate.\n\nThe EN is located in the dorsolateral prefrontal cortex and lateral parietal cortex, and is responsible for the maintenance and manipulation of the information in working memory. The EN also plays an important role as support of adaptive, goal-directed behaviors, which is why it is colloquially referred to as \"the problem solver.\"\n\nThe affective (or salience) network includes connections between the limbic area and subcortical areas, and is important during fear and vigilance states, as well as for autonomic and visceral regulation. It also generates the somatic sensations that accompany emotions.\n\nThe default mode is most active when the brain is at rest, or when a person is communicating socially. Its activity decreases during the performance of cognitively demanding tasks.\n\nNeuroimaging studies have shown that many neurological diseases and psychiatric disorders are associated with abnormalities in the functional connectivity of neural networks. MRIs indicate that the dorsal nexus is responsible for connecting these networks, and this might explain how symptoms of depression are influenced by the state of brain networks. The increased connectivity can produce symptoms of decreased focus and increased vigilance, which can present as paranoia, rumination or autonomic, visceral and emotional imbalance.\n\nSubjects with depression were observed to have abnormal connectivity in the bilateral parahipocampal cortex, as well as an increase of hyperintensity of white matter. Increased default-mode network connectivity, mediated via a region of the dorsomedial prefrontal cortex, may underline the characteristics of depression. In this pathology, the dorsal nexus is strongly connected to the task-positive, task-negative and affective networks. The function of this node is to allow enhanced “cross-talk” between networks, and this may explain how the diverse symptoms seen in depression converge The dorsal nexus can be related to two different types of depression: decreased and major depression. It is important to mention that there is a big difference between these two types: With decreased depression, the connectivity between the cingulated subgenual cortex and amygdala, pale striatum, and medial thalamus is diminished. In the case of major depression, connectivity is normal. This could explain differences in response to drugs and psychotherapy.\n\nNeuroimaging techniques allow of imaging of the nervous system in vivo, and permit scientists to explore the structures and functions of the human brain. In neuropsychiatry, neuroimaging techniques such as MRI and Positron Emission Tomography allow the identification of different networks that are implicated in various pathologies.\n\nIn the case of depression, portions of three different networks (the cognitive control network, the default mode network and the affective network) which are related with conflict resolution, making decisions, behavior, regulate memory and future planning present increased function in MRI’s. These three increased connectivity networks converged specifically on the dorsal nexus. The dorsal nexus has extremely high connectivity with large regions including dorso lateral prefrontal cortex, dorso medial prefrontal cortex, ventral medial prefrontal cortex, pregenual an subgenual cortex, posterior cingulate, and precuneus. Because these networks can be determined for each individual based on the strength of correlation to an a priori seed location, group statistical differences in networks can be evaluated on an image – wide basis.\n\nTreating the symptoms of depression has the purpose of reduce and control the dysfunction that patients could have in any areas of their life. The choice of treatment is based on the needs of the patient and can include drugs, therapy and other similar treatments. Regardless of the chosen treatment, if is necessary to consider possible side effects .\nIn the case of depression associated with dorsal nexus and other associated structures, reducing the increased connectivity might play a critical role reducing depression symptomatology and thus represent a potential therapy target for affective disorders \n\nSince glutamate is the most abundant and major excitatory neurotransmitter in the brain, pathophysiological changes in glutamatergic signaling are likely to affect neurobehavioral plasticity, information processing and large-scales changes in functional brain connectivity.Ketamine, a fast-acting general anesthetic derived from phencyclidine and use as a pediatric inductor, plays a non-well known role in the neural network dynamics at the healthy brain . The administration of ketamine in abnormal brain has the potential of reduce the increased function of the networks that are seen in depression. The therapeutic potential of ketamine may be explained by reversing disturbances in the glutamatergic system and restoring parts of a disrupted neurobehavioral homeostasis where several structural, metabolic, and functional abnormalities have taken place. Long term ketamine treatments lead to cognitive impairment including problems of short-term memory, visual and verbal memory. On the other hand, short term treatments are generally well tolerated and any damage may be reversible.\n\nElectroconvulsive therapy (ECT) significantly reduces functional connectivity between the dorsolateral prefrontal cortex (Dorsal nexus) and the anterior cingulate cortex, the medial prefrontal cortex, and other areas implicated in major depression. Although electroconvulsive therapy has been used as a treatment for depression since 1930, it has several side effects as loss of memory, confusion and difficulties in forming new memories. Because of this reasons, this kind of treatment is limited to severely damaged patients.\n"}
{"id": "213214", "url": "https://en.wikipedia.org/wiki?curid=213214", "title": "Early stopping", "text": "Early stopping\n\nIn machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration. Up to a point, this improves the learner's performance on data outside of the training set. Past that point, however, improving the learner's fit to the training data comes at the expense of increased generalization error. Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit. Early stopping rules have been employed in many different machine learning methods, with varying amounts of theoretical foundation.\n\nThis section presents some of the basic machine-learning concepts required for a description of early stopping methods.\n\nMachine learning algorithms train a model based on a finite set of training data. During this training, the model is evaluated based on how well it predicts the observations contained in the training set. In general, however, the goal of a machine learning scheme is to produce a model that generalizes, that is, that predicts previously unseen observations. Overfitting occurs when a model fits the data in the training set well, while incurring larger generalization error.\n\nRegularization, in the context of machine learning, refers to the process of modifying a learning algorithm so as to prevent overfitting. This generally involves imposing some sort of smoothness constraint on the learned model.\nThis smoothness may be enforced explicitly, by fixing the number of parameters in the model, or by augmenting the cost function as in Tikhonov regularization. Tikhonov regularization, along with principal component regression and many other regularization schemes, fall under the umbrella of spectral regularization, regularization characterized by the application of a filter. Early stopping also belongs to this class of methods.\n\nGradient descent methods are first-order, iterative, optimization methods. Each iteration updates an approximate solution to the optimization problem by taking a step in the direction of the negative of the gradient of the objective function. By choosing the step-size appropriately, such a method can be made to converge to a local minimum of the objective function. Gradient descent is used in machine-learning by defining a \"loss function\" that reflects the error of the learner on the training set and then minimizing that function.\n\nEarly-stopping can be used to regularize non-parametric regression problems encountered in machine learning. For a given input space, formula_1, output space, formula_2, and samples drawn from an unknown probability measure, formula_3, on formula_4, the goal of such problems is to approximate a \"regression function\", formula_5, given by\n\nwhere formula_7 is the conditional distribution at formula_8 induced by formula_3.\nOne common choice for approximating the regression function is to use functions from a reproducing kernel Hilbert space. These spaces can be infinite dimensional, in which they can supply solutions that overfit training sets of arbitrary size. Regularization is, therefore, especially important for these methods. One way to regularize non-parametric regression problems is to apply an early stopping rule to an iterative procedure such as gradient descent.\n\nThe early stopping rules proposed for these problems are based on analysis of upper bounds on the generalization error as a function of the iteration number. They yield prescriptions for the number of iterations to run that can be computed prior to starting the solution process.\n\nLet formula_10 and formula_11. Given a set of samples\n\ndrawn independently from formula_3, minimize the functional\n\nwhere, formula_15 is a member of the reproducing kernel Hilbert space formula_16. That is, minimize the expected risk for a Least-squares loss function. Since formula_17 depends on the unknown probability measure formula_3, it cannot be used for computation. Instead, consider the following empirical risk\n\nLet formula_20 and formula_21 be the \"t\"-th iterates of gradient descent applied to the expected and empirical risks, respectively, where both iterations are initialized at the origin, and both use the step size formula_22. The formula_20 form the \"population iteration\", which converges to formula_5, but cannot be used in computation, while the formula_21 form the \"sample iteration\" which usually converges to an overfitting solution.\n\nWe want to control the difference between the expected risk of the sample iteration and the minimum expected risk, that is, the expected risk of the regression function:\n\nThis difference can be rewritten as the sum of two terms: the difference in expected risk between the sample and population iterations and that between the population iteration and the regression function:\n\nThis equation presents a bias-variance tradeoff, which is then solved to give an optimal stopping rule that may depend on the unknown probability distribution. That rule has associated probabilistic bounds on the generalization error. For the analysis leading to the early stopping rule and bounds, the reader is referred to the original article. In practice, data-driven methods, e.g. cross-validation can be used to obtain an adaptive stopping rule.\n\nBoosting refers to a family of algorithms in which a set of weak learners (learners that are only slightly correlated with the true process) are combined to produce a strong learner. It has been shown, for several boosting algorithms (including AdaBoost), that regularization via early stopping can provide guarantees of consistency, that is, that the result of the algorithm approaches the true solution as the number of samples goes to infinity.\n\nBoosting methods have close ties to the gradient descent methods described above can be regarded as a boosting method based on the formula_28 loss: \"LBoost\".\n\nThese early stopping rules work by splitting the original training set into a new training set and a validation set. The error on the validation set is used as a proxy for the generalization error in determining when overfitting has begun. These methods are most commonly employed in the training of neural networks. Prechelt gives the following summary of a naive implementation of holdout-based early stopping as follows:\n\nMore sophisticated forms use cross-validation – multiple partitions of the data into training set and validation set – instead of a single partition into a training set and validation set. Even this simple procedure is complicated in practice by the fact that the validation error may fluctuate during training, producing multiple local minima. This complication has led to the creation of many ad-hoc rules for deciding when overfitting has truly begun.\n\n"}
{"id": "65858", "url": "https://en.wikipedia.org/wiki?curid=65858", "title": "Eliezer Yudkowsky", "text": "Eliezer Yudkowsky\n\nEliezer Shlomo Yudkowsky (born September 11, 1979) is an American writer on rationality, known for his view that the invention of Artificial General Intelligence would pose an immediate threat to the existence of humankind unless the AGI has effective features built in for the specific purpose of making it harmless.\n\nYudkowsky's example of how an AI takeover could work was cited by Nick Bostrom in his book \"\".\n\nYudkowsky's views on the safety challenges posed by future generations of AI systems are discussed in the undergraduate textbook in AI, Stuart Russell and Peter Norvig's \"\". Noting the difficulty of formally specifying general-purpose goals by hand, Russell and Norvig cite Yudkowsky's proposal that autonomous and adaptive systems be designed to learn correct behavior over time:\n\nIn response to the instrumental convergence concern, where autonomous decision-making systems with poorly designed goals would have default incentives to mistreat humans, Yudkowsky and other MIRI researchers have recommended that work be done to specify software agents that converge on safe default behaviors even when their goals are misspecified.\n\nIn the intelligence explosion scenario hypothesized by I. J. Good, recursively self-improving AI systems quickly transition from subhuman general intelligence to superintelligent. Nick Bostrom's 2014 book \"\" sketches out Good's argument in detail, while citing writing by Yudkowsky on the risk that anthropomorphizing advanced AI systems will cause people to misunderstand the nature of an intelligence explosion. \"AI might make an \"apparently\" sharp jump in intelligence purely as the result of anthropomorphism, the human tendency to think of 'village idiot' and 'Einstein' as the extreme ends of the intelligence scale, instead of nearly indistinguishable points on the scale of minds-in-general.\".\n\nIn on artificial intelligence, Stuart Russell and Peter Norvig raise the objection that there are known limits to intelligent problem-solving from computational complexity theory; if there are strong limits on how efficiently algorithms can solve various computer science tasks, then intelligence explosion may not be possible. \n\nBetween 2006 and 2009, Yudkowsky and Robin Hanson were the principal contributors to \"Overcoming Bias\", a cognitive and social science blog sponsored by the Future of Humanity Institute of Oxford University. In February 2009, Yudkowsky founded \"LessWrong\", a \"community blog devoted to refining the art of human rationality\". \"Overcoming Bias\" has since functioned as Hanson's personal blog.\n\nOver 300 blogposts by Yudkowsky on philosophy and science (originally written on LessWrong and Overcoming Bias) have been released as an ebook entitled \"Rationality: From AI to Zombies\" by the Machine Intelligence Research Institute in 2015.\n\nYudkowsky has also written several works of fiction. His fanfiction story, \"Harry Potter and the Methods of Rationality\", uses plot elements from J.K. Rowling's \"Harry Potter\" series to illustrate topics in science. \"The New Yorker\" described \"Harry Potter and the Methods of Rationality\" as a retelling of Rowling's original \"in an attempt to explain Harry's wizardry through the scientific method\".\n\n\n\n"}
{"id": "17253757", "url": "https://en.wikipedia.org/wiki?curid=17253757", "title": "Ezra Sellers", "text": "Ezra Sellers\n\nEzra Nathan Sellers (September 2, 1968 – December 12, 2013) was an American cruiserweight boxer. He lived in Pensacola, Florida, where he died on December 12, 2013, due to heart problems.\n\nSellers won the IBO cruiserweight championship against Carl Thompson; however, his title was vacated after losing to WBO champion Johnny Nelson on April 6, 2002 in Copenhagen, Denmark, who declined the IBO belt.\n\nHe was inducted into the Florida Boxing Hall of Fame in 2013.\n"}
{"id": "58275957", "url": "https://en.wikipedia.org/wiki?curid=58275957", "title": "Frideric", "text": "Frideric\n\nFrideric (; ? - 492/493) was the leader of the Germanic Rugians from 487 to 492/493.\n\nFrideric was a son of the Rugian king Feletheus. In late 487, Odoacer, the King of Italy, invaded the Rugian kingdom and destroyed it. Frideric's father and his mother, the Ostrogothic princess Giso, were captured and executed in Italy. Frideric was able to escape and gather the remaining Rugian survivors. In 488 he attempted to reconquer their traditional kingdom, but was defeated by Odoacer's brother Hunulf. \n\nAfter attempts to recapture their territory failed, Frideric and his followers sought help from Theodoric the Great, king of the Ostrogoths, marching downstream along the Danube to Novae, near Svishtov, for the purpose. They encountered no opposition along the way, which implies that the Eastern Roman Empire may have arranged everything in beforehand. In 489, shortly after the arrival of Frideric, Theodoric was appointed ruler of Italy by the Eastern Roman emperor Zeno. \n\nAfter having accompanied Theodoric into Italy, Frideric and the Rugians were responsible for protecting Pavia. There they treated the Roman population harshly, for which Frideric was reprimanded by Theodoric. In August 491, Theodoric personally intervened in Pavia, which caused Frideric to defect from Theodoric the Odoacer's general Tufa. Frideric and Tufa however soon fell out with each other, and in 492, or perhaps 493, the two fought a battle somewhere between Verona and Trento. Tufa, and probably also Frideric, were killed in this battle. The Rugians thereafter joined Theodoric.\n"}
{"id": "358409", "url": "https://en.wikipedia.org/wiki?curid=358409", "title": "Fritz Reiner", "text": "Fritz Reiner\n\nFrederick Martin \"Fritz\" Reiner (December 19, 1888 – November 15, 1963) was a prominent conductor of opera and symphonic music in the twentieth century. Hungarian born and trained, he emigrated to the United States in 1922, where he rose to prominence as a conductor with several orchestras. He reached the pinnacle of his career while music director of the Chicago Symphony Orchestra in the 1950s and early 1960s.\n\nReiner was born in Budapest, Austria-Hungary into a secular Jewish family that resided in the Pest area of the city. After preliminary studies in law at his father’s urging, Reiner pursued the study of piano, piano pedagogy, and composition at the Franz Liszt Academy. During his last two years there, his piano teacher was the young Béla Bartók. After early engagements at opera houses in Budapest and Dresden (June 1914 - November 1921), where he worked closely with Richard Strauss, he moved to the United States of America in 1922 to take the post of Principal Conductor of the Cincinnati Symphony Orchestra. He remained until 1931, having become a naturalized citizen in 1928, then began to teach at the Curtis Institute in Philadelphia, Pennsylvania, where his pupils included Leonard Bernstein and Lukas Foss. He conducted the Pittsburgh Symphony Orchestra from 1938 to 1948 and made a few recordings with them for Columbia Records, then spent several years at the Metropolitan Opera, where he conducted a historic production of Strauss's \"Salome\" in 1949, with the Bulgarian soprano Ljuba Welitsch in the title role, and the American première of Igor Stravinsky's \"The Rake's Progress\" in 1951. He also conducted and made a recording of the famous 1952 Metropolitan Opera production of Bizet's \"Carmen\", starring Rise Stevens. The production was telecast on closed circuit television that year. At the time of his death he was preparing the Met's new production of Wagner’s \"Götterdämmerung\".\n\nIn 1947, Reiner appeared on camera in the film \"Carnegie Hall\", in which he conducted the New York Philharmonic Orchestra as they accompanied violinist Jascha Heifetz in an abbreviated version of the first movement of Tchaikovsky's violin concerto. Ten years later, Heifetz and Reiner recorded the full Tchaikovsky concerto in stereo for RCA Victor in Chicago.\n\nReiner's music-making had been largely American-focused since his arrival in Cincinnati. But after the Second World War he began markedly increasing his European activity. When he became music director of the Chicago Symphony Orchestra in 1953 he had an international reputation. By common consent, the ten years that he spent in Chicago mark the pinnacle of his career, and are best-remembered today through the many recordings he made in Chicago's Orchestra Hall for RCA Victor from 1954 to 1963. The first of these—of \"Ein Heldenleben\" by Richard Strauss—occurred on March 6, 1954 and was among RCA's first to use stereophonic sound. His last concerts in Chicago took place in the spring of 1963.\n\nOne of his last recordings, released in a special \"Reader's Digest\" boxed set, was a performance of Brahms' Fourth Symphony, recorded with the Royal Philharmonic Orchestra in October 1962 in London's Kingsway Hall. This recording was later reissued on LP by Quintessence and on CD by Chesky. On September 13 and 16, 1963, Reiner conducted a group of New York musicians in Haydn's \"Symphony No. 101 in D major\"; this was followed by September 18 and 20, 1963, sessions devoted to Haydn's \"Symphony No. 95 in C minor\".\n\nHe also appeared with members of the Chicago Symphony in a series of telecasts on Chicago's WGN-TV in 1953-54, and a later series of nationally syndicated programs called \"Music From Chicago\". Some of these performances have been issued on DVD. The videos clearly show his stern, disciplined demeanor, but at the conclusion of a piece, Reiner would turn to the audience and smile at them as he bowed.\n\nReiner was married three times (one of them to a daughter of Etelka Gerster) and had three daughters. His health deteriorated after a heart attack in October 1960. He died in New York City on November 15, 1963, at the age of 74.\n\nReiner was especially noted as an interpreter of Richard Strauss and Bartók and was often seen as a modernist in his musical taste; he and his compatriot Joseph Szigeti convinced Serge Koussevitzky to commission the \"Concerto for Orchestra\" from Bartók. In reality, he had a very wide repertory and was known to admire Mozart's music above all else.\n\nReiner’s conducting technique was defined by its precision and economy, in the manner of Arthur Nikisch and Arturo Toscanini. It typically employed quite small gestures — it has been said that the beat indicated by the tip of his baton could be contained in the area of a postage stamp — although from the perspective of the players it was extremely expressive. The response he drew from orchestras was one of astonishing richness, brilliance, and clarity of texture. Igor Stravinsky called the Chicago Symphony under Reiner \"the most precise and flexible orchestra in the world\"; it was more often than not achieved with tactics that bordered on the personally abusive, as Kenneth Morgan documents in 2005 biography of the conductor. Chicago musicians have spoken of Reiner's autocratic methods; trumpeter Adolph Herseth told National Public Radio that Reiner often tested him and other musicians.\n\n\n"}
{"id": "180528", "url": "https://en.wikipedia.org/wiki?curid=180528", "title": "Geoffrey II, Duke of Brittany", "text": "Geoffrey II, Duke of Brittany\n\nGeoffrey II (; , Anglo-Norman: \"Geoffroy\"; 23 September 1158 – 19 August 1186) was Duke of Brittany and 3rd Earl of Richmond between 1181 and 1186, through his marriage with the heiress Constance. Geoffrey was the fourth of five sons of Henry II, King of England and Eleanor, Duchess of Aquitaine.\n\nIn the 1160s, Henry II began to alter his policy of indirect rule in Brittany and to exert more direct control. Henry had been at war with Conan IV, Duke of Brittany. Local Breton nobles rebelled against Conan, so Conan sought Henry II's help. In 1164, Henry intervened to seize lands along the border of Brittany and Normandy and, in 1166, he invaded Brittany to punish the local barons. Henry then forced Conan to abdicate as duke and to give Brittany to his five-year-old daughter, Constance, who was handed over and betrothed to Henry's son Geoffrey. This arrangement was quite unusual in terms of medieval law, as Conan might have had sons who could have legitimately inherited the duchy. Geoffrey and Constance eventually married, in July 1181.\n\nGrowing tensions between Henry and Louis VII of France finally spilled over into open war in 1167, triggered by a trivial argument over how money destined for the Crusader states of the Levant should be collected. Louis allied himself with the Welsh, Scots and Bretons and the French king attacked Normandy. Henry responded by attacking Chaumont-sur-Epte, where Louis kept his main military arsenal, burning the town to the ground and forcing Louis to abandon his allies and make a private truce. Henry was then free to move against the rebel barons in Brittany, where feelings about his seizure of the duchy were still running high.\n\nGeoffrey was fifteen years old when he joined the first revolt against his father. He later reconciled to Henry in 1174 when he participated in the truce at Gisors. Geoffrey prominently figured in the second revolt of 1183, fighting against Richard, on behalf of Henry the Young King.\n\nGeoffrey was a good friend of Louis VII's son Philip, and the two men were frequently in alliance against King Henry. Geoffrey spent much time at Philip's court in Paris, and Philip made him his seneschal. There is evidence to suggest that Geoffrey was planning another rebellion with Philip's help during his final period in Paris in the summer of 1186. As a participant in so many rebellions against his father, Geoffrey acquired a reputation for treachery. Gerald of Wales wrote the following of him: \"He has more aloes than honey in him; his tongue is smoother than oil; his sweet and persuasive eloquence has enabled him to dissolve the firmest alliances and by his powers of language able to corrupt two kingdoms; of tireless endeavour, a hypocrite in everything, a deceiver and a dissembler.\"\n\nGeoffrey also was known to attack monasteries and churches in order to raise funds for his campaigns. This lack of reverence for religion earned him the displeasure of the Church and, as a consequence, of the majority of chroniclers who wrote about his life.\n\nGeoffrey and Constance had three children, one born after Geoffrey's death:\n\nGeoffrey died on 19 August 1186, at the age of 27, in Paris. There is also evidence that supports a death date of 21 August 1186. There are two alternative accounts of his death. The more common first version holds that he was trampled to death in a jousting tournament. At his funeral, a grief-stricken Philip is said to have tried to jump into the coffin. Roger of Hoveden's chronicle is the source of this version; the detail of Philip's hysterical grief is from Gerald of Wales.\n\nIn the second version, in the chronicle of the French royal clerk Rigord, Geoffrey died of sudden acute chest pain, which reportedly struck immediately after his speech to Philip, boasting his intention to lay Normandy to waste. Possibly, this version was an invention of its chronicler; sudden illness being God's judgment of an ungrateful son plotting rebellion against his father, and for his irreligiosity. Alternatively, the tournament story may be an invention of Philip's to prevent Henry II's discovery of a plot; inventing a social reason, a tournament, for Geoffrey's being in Paris, Philip obscured their meeting's true purpose.\n\nMarie of Champagne, with whom Geoffrey was on good terms, was present at the requiem for her half-brother and established a mass chantry for the repose of his soul.\n\nGeoffrey was buried in the choir of Notre Dame de Paris Cathedral, but his tombstone was destroyed in the 18th century before the French revolution. His body was exhumed in 1797 and measured at 5 ft 6.5 in (1.69 m).\n\nAfter Geoffrey's death, Henry II arranged for Constance, Geoffrey's widow, to marry Ranulph, the Earl of Chester. Ranulph would become Duke of Brittany, jure uxoris, for a short time before this marriage was annulled.\n\nWith a character closely resembling that given by Gerald of Wales above, Geoffrey appears as a major character in the James Goldman play \"The Lion in Winter\". In the 1968 film version of the play, Geoffrey was played by John Castle and in the 2003 TV film version by John Light. He was also portrayed by Austin Somervell (as a teenager) and Martin Neil (as an adult) in the BBC TV series \"The Devil's Crown\" (1978), which dramatised the reigns of his father and brothers.\n\nHe appears as an ally of his brother Richard the Lionheart in the game \"\".\n\nHe appears in the 2015 film, \"\", played by Marco Naggar, joining his mother and brothers in a fight against their father.\n\nHe is a major character in the historical novel \"Devil's Brood\" by Sharon Kay Penman.\n\n\n\n\n \n"}
{"id": "1189670", "url": "https://en.wikipedia.org/wiki?curid=1189670", "title": "Gravemind", "text": "Gravemind\n\nThe Gravemind is a parasitic, hive mind intelligence in the \"Halo\" universe. While only one Gravemind is ever seen in the games, the title is given to the final stage of Flood evolution, in which the Flood becomes a superorganism. The Flood is a highly-infectious parasite which is released several times during \"Halo\"s story. The Chief and the Arbiter (Thel'Vadam, during the course of Halo 2 and Halo 3) are captured during their separate missions on Delta Halo, or Installation 05, by a Gravemind, which resides in the bowels of the ancient Forerunner ringworld, where the Flood creature forges an alliance between the two foes in order to stop the activation of the ringworld — an event which would destroy all sentient life, and, therefore, starve the Flood. The character is voiced by Dee Bradley Baker.\n\nMaking its first appearance in \"Halo 2\", the Gravemind was introduced to dispel the idea that the Flood is a mindless virus. The character was designed by a Bungie team, including artists Robert McLees and Juan Ramirez, and slowly developed into a massive creature with tentacles and a frightening level of intelligence. Driven by a desire to spread, the Gravemind is cunning and manipulative; he forges alliances as often as he tries to consume his allies, tricking the Master Chief into aiding him while infecting the Chief's compatriots at the same time. The character has had a mixed reception by many critics upon his appearance in \"Halo 2\", and reviewers including 1UP.com found his role in \"Halo 3\" confusing and without clear motive. More positively, critic Aaron Sagers used Gravemind as an example of a \"frenemy\" — the creature's appearance made the Master Chief's fight against the Flood more personal and more dramatic.\n\nEarly Concepts for the Gravemind were done by Bungie artist Robert McLees. McLees is known at Bungie as the \"architect of the Flood\", and had done the early concepts for the Flood forms in \"Halo: Combat Evolved\". McLees' original drawings were then added to by Juan Ramirez. The Gravemind's form and design constantly changed during development. Early versions of the creature had a basic shape of a mass of tentacles, with a jagged tear in one large appendage forming a rudimentary mouth. Later on, the mouth was studded with the skulls of human and Covenant corpses for teeth. This design was later revised due to practical considerations about lip syncing the character for speech. Despite these design changes, the Gravemind's size was always meant to be huge; early concepts showed the Master Chief dwarfed by the Flood intelligence.\n\nUnlike the mindless \"zombie\" nature of most Flood, the Gravemind is depicted as intelligent and cunning, and acts as a collective mind driving the Flood. It lyrically speaks prose in a form of trochaic or iambic heptameter. While capable of subterfuge, Gravemind is seen to use the brute strength and sheer numbers of the Flood to further its aims. When attacking planets, the Gravemind of the Forerunner's time used smaller craft as ablative armor, sacrificing countless Flood so that larger ships can land and infest major population centers. In a more strategic move, Gravemind uses logic to sway the Forerunner's own artificial intelligence, Mendicant Bias, to his side. While Mendicant Bias had been specifically created to defeat the Gravemind, the Flood leader convinces the AI that the Flood is a utopian ideal, and that its conquest of the galaxy is inevitable. While the Gravemind's motivations and goals are not made expressly clear in \"Halo 2\", \"Halo 3\" reveals Gravemind's ultimate goal is to consume all thinking beings in the galaxy.\n\nThe Gravemind's physical form is depicted as composed of rotting corpses and biomatter, towering nearly eighty meters high as seen in \"Halo 2\". Gravemind resembles a large Venus Flytrap with many tentacles, but is capable of movement and linguistic communication via its large mouth formed from overlapping fleshy \"leaves\". Though an animal, the Gravemind's somewhat plantlike appearance has drawn comparisons to Audrey II from the 1986 film \"Little Shop of Horrors\" due to the tentacles about a central mouth. For \"Halo 2: Anniversary\", the Gravemind now has three flesh-flaps that protrude and dangle towards the front of its head, each one decorated with teeth. It is also given a different sort of mouth, one that resembles a lipless mouth with fangs.\n\nThe Gravemind makes his first appearance halfway through \"Halo 2\"s campaign. Using his tentacles to save the Master Chief and Arbiter from perishing, Gravemind brings them face to face in a chasm on Delta Halo. Gravemind reveals to the Arbiter that the ring's architects, the Forerunners, died when they activated the installation in order to stop the threat of the Flood; the Master Chief verifies what the creature says, having stopped the firing of another ring in \"\". Though the Arbiter does not accept the truth immediately, Gravemind sends the Master Chief to the Covenant city \"High Charity\" and the Arbiter to the Halo's control room in order to stop the deluded Covenant from killing all sentient life a second time. Though he promises an alliance, Gravemind has ulterior motives. His Flood infest the human ship \"In Amber Clad\" and makes a slipspace jump into \"High Charity\" itself, in an effort to use the station to escape the confines of Halo. Having taken over the city, Gravemind questions the A.I. Cortana, who was left behind to destroy \"High Charity\" if Halo was activated. Gravemind says that he has questions that he will ask, and Cortana agrees to answer them. A short story in the 2009 \"Halo: Evolutions\" anthology details the conversations that follow.\n\nGravemind is one of the primary antagonists of \"Halo 3\". While the Master Chief and Arbiter have returned to Earth in order to stop the Prophet of Truth, the religious leader of the Covenant, from activating a Forerunner artifact buried in Africa, Gravemind turns \"High Charity\" into a Flood hive and sends an infected cruiser to Earth in an attempt to infest the planet; this plan fails, and a message from Cortana informs the Master Chief and allies of the existence of the Ark, a special installation built by the Forerunners outside of the Milky Way galaxy where \"all\" the Halos can be fired remotely. Gravemind, the Arbiter, and the Master Chief all want to stop the High Prophet of Truth from activating the rings, so the Flood once again ally with the Chief and Arbiter. As soon as Truth is killed, however, the Gravemind betrays both the Master Chief and the Arbiter, The Chief escapes the Flood's clutches and rescues Cortana from \"High Charity\". Despite being tortured by Gravemind, Cortana has managed to keep a secret safe from the Flood; she has the activation index of Installation 04, which she captured from 343 Guilty Spark during \"\". Using the index, Cortana can activate the local ringworld, destroying Gravemind and the Flood, but sparing the galaxy's sentient life. Gravemind finally gains this knowledge, but too late; the Master Chief escapes with Cortana, destroying \"High Charity\" in the process. Gravemind survives the blast and attempts to rebuild himself on the new ring. Despite his best efforts, the Master Chief and company activate Halo, destroying it and defeating the Flood once again. Resigned to his defeat, Gravemind nonetheless insists that it will only slow—not stop—the Flood.\n\nDuring \"Halo Wars\", the player encounters a massive Proto-Gravemind, the precursor to a Gravemind which acts as the leader of the Flood upon the surface planet of a Forerunner shield world in uncharted space. By replicating the transponder signal of character Professor Ellen Anders, the Proto-Gravemind is able to lure the human forces close to it. However, the player is able to destroy the Proto-Gravemind and the Flood upon the shield world are destroyed when the UNSC \"Spirit of Fire\" destroys the planet by causing its artificial sun to go supernova.\n\nIn \"Halo Wars 2: Awakening the Nightmare\", it is revealed that a number of Flood forms survived the events of \"Halo 3\", thus validating the Gravemind's warning. Also in the game's menu, it is mentioned that while the Gravemind's \"most recent physical avatar\" was destroyed by the Master Chief, it is only \"a matter of time before it rises again\". During the events of \"Awakening the Nightmare\", the Flood are accidentally released from the ruins of \"High Charity\" where they have been contained by a shield since the events of \"Halo 3\" when Voridus, a Banished Brute commander, breaches the shield after disbelieving the stories about the Flood. During the following conflict, a Proto-Gravemind comes close to creating another Gravemind before it is destroyed by the Banished forces with the help of the Ark's Sentinels. Together, the Banished and the Sentinels manage to push the Flood back to \"High Charity\" and contain them once again following the Proto-Gravemind's death.\n\nCritical reception of the leader of the Flood were mixed. In a review of \"Halo 2\", Mike Leonard of the AllXbox community said that the introduction of the Gravemind character had him \"rolling my eyes hard enough to get motion sickness from seeing the back of the inside of my skull\"; Leonard went on to say that the \"\"Little Shop of Horrors\" reject\" ruined the \"cool\" of the \"Halo\" franchise. Staff from GamesRadar singled out the appearance of the Gravemind as a sign the \"Halo\" series had jumped the shark. \"Until Gravemind showed up, we were pretty sure we understood the \"Halo\" series' story,\" they wrote, but that the appearance of a Venus Flytrap-like creature with an ego and \"a tendency to spout philosophical drivel\" was unexpected. Jeremy Parish of 1UP.com bemoaned the fact that Gravemind was never explicitly stated to be the Flood leader in either \"Halo 2\" or \"Halo 3\" and was hardly seen in the third installment. Publications also took issue with the fact that the character's motivations were never fully explored; the \"South Florida Sun-Sentinel\" said that the \"unique and compelling characters\" of \"Halo 3\", such as Cortana and the Master Chief, were overwhelmed by Gravemind.\n\nMore favorably, Aaron Sagers of the newspaper \"The Morning Call\" saw Gravemind as a perfect example of a trend in pop culture called a \"frenemy\". A frenemy, according to Sagers, is a friend or rival \"with whom [the protagonist] feuds; an individual who reinvigorates the sense of self-worth and drives up one's visibility in the public's eye.\" Gravemind, operating as a frenemy, served to personify the Master Chief's otherwise nebulous fight against the Flood. Will Prusik of PlanetXbox360 listed the Flood as one of the great video game aliens, and that the revelation of a central Flood intelligence was a good idea despite the Gravemind's resemblance to Audrey II.\n\n\n"}
{"id": "14445180", "url": "https://en.wikipedia.org/wiki?curid=14445180", "title": "HMS Exmouth (H02)", "text": "HMS Exmouth (H02)\n\nHMS \"Exmouth\" was an E-class destroyer flotilla leader built for the Royal Navy in the early 1930s. Although assigned to the Home Fleet upon completion, the ship was attached to the Mediterranean Fleet in 1935–36 during the Abyssinia Crisis. During the Spanish Civil War of 1936–1939 she spent considerable time in Spanish waters, enforcing the arms blockade imposed by Britain and France on both sides of the conflict. \"Exmouth\" was assigned to convoy escort and anti-submarine patrol duties in the Western Approaches when World War II began in September 1939. She was sunk by a German submarine in January 1940 while escorting a merchant ship north of Scotland.\n\n\"Exmouth\" displaced at standard load and at deep load. The ship had an overall length of , a beam of and a draught of . She was powered by two Parsons geared steam turbines, each driving one propeller shaft, using steam provided by three Admiralty three-drum boilers. The turbines developed a total of and gave a maximum speed of . \"Exmouth\" carried a maximum of of fuel oil that gave her a range of at . The ship's complement was 175 officers and ratings.\n\nThe ship mounted five 45-calibre 4.7-inch (120 mm) Mark IX guns in single mounts. For anti-aircraft defence, \"Exmouth\" had two quadruple Mark I mounts for the 0.5 inch Vickers Mark III machine gun. She was fitted with two above-water quadruple torpedo tube mounts for torpedoes. One depth charge rail and two throwers were fitted; 20 depth charges were originally carried, but this increased to 35 shortly after the war began.\n\n\"Exmouth\" was ordered on 1 November 1932 under the 1931 Naval Programme, and was laid down at Portsmouth Dockyard on 15 March 1933. She was launched on 30 January 1934, named the following day, and commissioned for service on 9 November 1934. On commissioning, \"Exmouth\" was assigned as leader of the 5th Destroyer Flotilla of the Home Fleet. The increased tensions between Italy and Abyssinia – eventually leading to the outbreak of the Second Italo-Abyssinian War – caused the Admiralty to attach the flotilla to the Mediterranean Fleet from August 1935 to March 1936, although \"Exmouth\" was refitted in Alexandria from 4 October 1935 to 5 January 1936. The ship patrolled Spanish waters during the Spanish Civil War enforcing the edicts of the Non-Intervention Committee in between annual refits at Portsmouth between 17 November 1936 and 19 January 1937 and 21 November 1938 and 16 January 1939. She returned to Britain in March and \"Exmouth\" was assigned to training duties and local flotilla work based at Portsmouth on 28 April. She carried out these duties until 2 August, when she was placed into full commission as the leader of the 12th Destroyer Flotilla.\n\n\"Exmouth\" and her flotilla were initially assigned to the Home Fleet upon the outbreak of World War II in September 1939. The ship and two of her flotilla mates, and , escorted the battlecruiser as she searched for German commerce raiders south of Iceland in late November. In December, she was transferred to the Western Approaches Command to carry out patrols and escort convoys, but was transferred to Rosyth in January 1940 to carry out the same duties in the North Sea. She was escorting the merchant \"Cyprian Prince\" on 21 January 1940 when she was spotted by the , under the command of Karl-Heinrich Jenisch, and torpedoed at 05:35. She sank with the loss of all hands. After sinking \"Exmouth\", the submarine also fired on \"Cyprian Prince\" whose master deemed it too dangerous to pick up survivors. Eighteen bodies were later found washed ashore by a schoolboy playing truant near Wick. They were buried with full military honours in the cemetery at Wick.\n\nThe wreck of \"Exmouth\" was discovered in the Moray Firth in July 2001 by an independent expedition, with their findings being verified by Historic Scotland. The wreck is one of those listed as a 'protected place' under the Protection of Military Remains Act 1986.\n\n\n"}
{"id": "17181487", "url": "https://en.wikipedia.org/wiki?curid=17181487", "title": "Integrated fluidic circuit", "text": "Integrated fluidic circuit\n\nIntegrated fluidic circuit (IFC) is a type of integrated circuit (IC) using fluids.\n\n"}
{"id": "57709729", "url": "https://en.wikipedia.org/wiki?curid=57709729", "title": "Joan Bernard Armstrong", "text": "Joan Bernard Armstrong\n\nJoan Bernard Armstrong ( – June 9, 2018) was an African-American judge\n\nArmstrong was \"the first woman elected to serve as a judge in Louisiana and first African-American to serve as chief judge of the state's Fourth Circuit Courts of Appeal.\"\n"}
{"id": "1660552", "url": "https://en.wikipedia.org/wiki?curid=1660552", "title": "Libertarian perspectives on inheritance", "text": "Libertarian perspectives on inheritance\n\nMost libertarians believe individuals should have complete freedom of determination of their property's fate after death, once all open contracts have been settled). Therefore, any degree of inheritance, disinheritance and bestowal to individuals or organisations of choice is permitted. They are against inheritance tax or compulsory inheritance. In their view, an individual may also have the right to retain some forms of ownership posthumously. In theory, land owners may also have the right to declare their land off-bounds to anyone for eternity, but consequentialist libertarians may reject that.\n\nThere is some debate among libertarians as to what should happen to property in absence of a will or a contract such as marriage. Some argue that \"natural\" heirs like family members, related by blood or otherwise, do not have an automatic right to inherit property of the deceased, as they are as much subject to the principle of voluntary contracts as the rest of society. Instead, a deceased person's property would simply be declared as unclaimed property. The first individual to claim the property would then be its legitimate owner.\n"}
{"id": "27456094", "url": "https://en.wikipedia.org/wiki?curid=27456094", "title": "List of restriction enzyme cutting sites: A", "text": "List of restriction enzyme cutting sites: A\n\nThis article contains a list of the most studied restriction enzymes whose names start with A. It contains approximately 30 enzymes.\n\nThe following information is given:\n"}
{"id": "42335232", "url": "https://en.wikipedia.org/wiki?curid=42335232", "title": "List of victims of Sobibór", "text": "List of victims of Sobibór\n\nThis is a list of people who died in the Sobibor extermination camp. The United States Holocaust Memorial Museum states that at least 167,000 people were murdered there. The Dutch Sobibor Foundation lists a calculated total of 170,165 people and cites the Höfle Telegram among its sources, while noting that other estimates range up to 300,000. For practical reasons it is not possible to list all the people murdered at the camp. The operatives of the Nazi regime not only robbed Jews of their earthly possessions and their lives but attempted to eradicate all traces of their existence as they engaged in the genocidal policies of the Final Solution.\n\nThere are fifty eight known survivors; forty-nine male and ten female, among those who were in the camp as \"Arbeitshäftlinge\", deportees selected from arriving transports to perform slave-labour for the daily operation of the camp. Their time in the camp ranged from several weeks to almost two years. A handful of \"Arbeitshäftlinge\" managed to escape while assigned to the \"Waldkommando\", inmate details assigned the task of felling and preparing trees for the body disposal pyres. The majority of the survivors among Sobibor's \"Arbeitshäftlinge\" survived as a result of their camp-wide revolt on . Dutch historian Jules Schelvis estimated that 158 inmates perished in the revolt, killed by the guards and the minefield surrounding the camp, and that a further 107 were re-captured and murdered by the SS, Wehrmacht and Police units tasked with pursuing the escapees. He estimates that another 53 escapees died of other causes between the day of the revolt and May 8, 1945. In the aftermath of the revolt, the remaining camp inmates were murdered and the camp dismantled. Schelvis estimated that at the time of the escape there had been approximately 650 inmates in the camp.\n\nAmong the Sobibor survivors are also those who were spared the gas chambers in the camp as a result of transfer to slave-labour camps in the Lublin district, after selections upon arrival at Sobibor. These people spent several hours at Sobibor and were transferred almost immediately to slave-labour camps, including Majdanek and Alter Flugplatz in the city of Lublin, where materials looted from the gassed victims were prepared for shipment and distribution, and forced labour camps such as Krychów, Dorohucza and Trawniki. Estimates for the number of people selected in Sobibor range up to several thousand, of whom many perished in captivity before the end of the nazi regime. The total number of survivors in this cohort includes 16 known survivors, 13 women and 3 men, from among the 34,313 people deported to Sobibor from the Netherlands.\n"}
{"id": "33723395", "url": "https://en.wikipedia.org/wiki?curid=33723395", "title": "Mervyn Bennett", "text": "Mervyn Bennett\n\nMervyn Bennett (20 February 1960 – 1998) was a professional lightweight boxer from Wales. Born in Cardiff, Bennett was notable for becoming the Welsh lightweight champion in 1993. He successfully defended his title on one occasion before retiring from the sport in 1996.\n\nBennett was a successful amateur boxer, fighting as a featherweight. In 1978, as an eighteen-year-old, he reached the final of the ABA Welsh amateur featherweight final. His opponent was Don George, who he beat on points to take the title.\n\nBennett turned professional in 1981 as a featherweight, and his first pro fight was at York Hall in Bethnal Green, on the undercard of the British light welterweight contest between Clinton McKenzie and Des Morrison. Bennett faced London boxer Geoff Smart in a six-round bout, and stopped his opponent via technical knockout in the final round. Bennett went on to win his next four fights before challenging Don George for the vacant Welsh area featherweight belt. Held at Ebbw Vale Leisure Centre, the bout went the full ten rounds with George declared winner on points decision. The Welsh title fight began a string of defeats which saw Bennett leave the sport in 1983, before returning in 1986.\n\nWhen Bennett returned to the ring in 1986 he had moved up the weights to lightweight. His first fight at his new weight was against Dave Smith at the National Sporting Club in London. Bennett won the fight on points, and followed this up with a victory over Dave Pratt two months later. Bennett then boxed just three more times, before again taking another leave from the sport in 1987. He did not return to boxing until 1992, this time losing his opening fight, to Edward Lloyd at the National Ice Rink in Cardiff. He followed this up with two wins over Mike Morrison at the end of 1992, both on points, which led to a shot at the vacant Welsh area lightweight belt. The fight was held in Cardiff on 27 January 1993, his opponent was Swansea fighter Carl Hook. The contest was top of the bill, and the ten round bout went the full ten rounds before the decision was given to Bennett, making him the Welsh lightweight champion.\n\nAfter becoming champion, Bennett fought just four more times. He beat Vince Burns by knock-out in June 1995 but then lost by points to Dean Phillips in September. In October he successfully defended his Welsh belt when he handed Monmouth based boxer, Gareth Jordan, his first defeat. Jordan, who was 11 years younger than Bennett, was expected to take the title, but Bennett produced the performance of his career to retain his title. Bennett's final fight was in March 1996, a defeat to Karl Taylor.\n\nBennett died in 1998, a victim of cancer.\n\nedited by Terrence Bennett\n"}
{"id": "11627603", "url": "https://en.wikipedia.org/wiki?curid=11627603", "title": "Meta-emotion", "text": "Meta-emotion\n\nMeta-emotion is \"an organized and structured set of emotions and cognitions about the emotions, both one's own emotions and the emotions of others\". This broad definition of meta-emotion sparked psychologists' interest in the topic, particularly regarding parental meta-emotion philosophy.\n\nMeta-emotion refers to the idea that whenever we elicit a certain emotion, we also deal with subsequent emotions regarding how we experienced the primary emotion. While some psychologists have examined the influence of meta-emotions on how individuals interpret and deal with their own and others' emotions, much of the literature regarding meta-emotion has focused on how parental meta-emotion impacts the social-emotional development of their children. Meta-emotions can be short-term or long-term. The latter can be a source of discouragement or even psychological repression, or encouragement of specific emotions, having implications for personality traits, psychodynamics, family and group dynamics, organizational climate, emotional disorders, but also emotional awareness, and emotional intelligence.\n\nIn 1997, Gottman, Katz, & Hooven used the term meta-emotion to describe parents' reactions to their children's emotional displays. Baker, Fenning, & Crnic (2010) defined meta-emotion philosophy as \"parental attitudes toward emotion\". \n\nBroadly speaking, meta-emotion encompasses both feelings and thoughts about emotion. According to Gottman et al. (2006), the term meta-emotion does not merely refer to an individual's emotional reactions to his or her own emotions, but refers also to the \"executive functions of emotion\" (243). Greenberg (2002) suggested that meta-emotions are to be considered a type of \"secondary emotion\", a temporal concept in which a secondary emotion follows a primary emotion. For example, anxiety (the secondary emotion) may follow anger (the primary emotion). \n\nThe term meta-emotion was unexpectedly coined as a result of the initial work of Gottman et al. (1996). For years, developmental psychology research has focused on parental affect, responsiveness, and parenting style. Gottman, Katz, & Hooven (1996) believed that there was not enough attention given to parents' feelings and thoughts about their own emotions and their children's emotions. While researching the effects of parents' marital relationship on children, Gottman et al. (1996) found that there was a large variety of attitudes and philosophies that parents held about their own emotions and their children's emotions. In order to examine these differences, Katz & Gottman (1986) developed a meta-emotion interview and deemed the term \"meta-emotion structure\", to refer to parents' feelings about feelings. They believed that meta-emotion was a \"pervasive and understudied dimension in emotion research\" (250). Katz & Gottman (1986) paralleled their concept of meta-emotion with that of the meta-cognition construct Metacognition. Hooven, Gottman, & Katz (1995) used the term \"meta-emotion structure\" to refer to \"the parents' awareness of specific emotions, their awareness and acceptance of these emotions in their child, and their coaching of the emotion in their child\" (231). The results of their study demonstrated that parental meta-emotion variables were related to their abilities to both interact with their children and resolve marital conflict. Gottman, Katz & Hooven (1996) suggested that parents' own feelings and thoughts about their emotions strongly influence the ways in which they parent.\n\nIn their paper published in 1996, Gottman, Katz & Hooven outlined different types of parental meta-emotion philosophy. These include emotion-coaching philosophy and a dismissing meta-emotion philosophy. That there are two major meta-emotion philosophies continues to be the general consensus among psychologists studying meta-emotion: emotion-coaching philosophy, in which the parents are comfortable with the emotions of themselves and their children, and an emotion-dismissing philosophy in which parents view negative emotions as harmful.\n\nParents who follow an emotion-coaching philosophy tend to be aware of their emotions and the emotions of others. They are able to talk about these emotions and help their children understand and express their emotions, particularly sadness and anger. The authors found a distinction between emotion-coaching philosophy and parental warmth.\n\nThere are five major characteristics of the emotion-coaching philosophy:\n\nA crucial aspect of the emotion-coaching philosophy is that the parent utilizes the child's negative emotions to form an emotional connection with their child, primarily for the reasons of intimacy and teaching.\n\nParents with a dismissing meta-emotion philosophy feel as though their child's anger or sadness could be harmful to their child, that their primary job is to alleviate these harmful emotions as quickly as possible, and that their child should know that these negative emotions will not last. Although parents with a dismissing philosophy may be sensitive to their child's emotions and truly want to be helpful, these parents believe that ignoring or denying negative emotions is the best approach to helping their children. Parents with a dismissing meta-emotion philosophy are often unable to provide insight into their child's emotions and do not view negative emotions as an opportunity for growth or intimacy. Parents may partake in a dismissing approach by attempting to distract the child or belittling the causes of the negative emotions.\n\nAnother possible type of parental meta-emotion is the disapproving philosophy. These parents reprimand their children for any type of emotional expression, even if the child's actions are appropriate. As a result, these children start to view their emotions as inappropriate and invalid, and have a difficult time with emotion regulation. For disapproving parents, negative emotions require a disciplinary response. Some disapproving parents may view their child's negative emotions as a means by which the child is attempting to manipulate or control the parent.\n\nThere have been many studies examining the impact of different parental meta-emotion philosophies on adolescents. For example, researchers have studied the relation between meta-emotion philosophy and adolescent depression, as well as the impact of parental meta-emotion on adolescent affect and coping skills. Other psychologists have examined the impact of maternal meta-emotion philosophy on children's attachment inclination.\n\nGottman et al. (1997) highlighted two specific aspects of parental meta-emotion that impact children and family outcomes: 1) emotional awareness, and 2) emotion coaching. Gottman, Katz, & Hooven—among the leading psychologists regarding meta-emotion—firmly believe in the significant impact of parental meta-emotion on many aspects of their children's lives: \"There is evidence that from the beginning of a child's life, parents' interaction with the child has implications for the child's ability to self-regulate, focus attention, share intersubjective meaning, for the essential affectional bonds with parents, and be able to interact with a changing environment\" (87).\n\nThere has been a growing interest in examining the impact of the various types of parental meta-emotion philosophies on children's emotional states and depressive symptoms. For example, Hunter et al. (2011) examined the associations between the meta-emotion philosophies of fathers, mothers, and adolescents. They found that when parents held an emotion-coaching philosophy, the adolescents tended to have fewer behavioral and emotional issues. They concluded that: \"The quality of the meta-emotion philosophy developed by adolescents may have implications for their mental health. In particular, evidence suggests that beliefs about emotion are relevant to depressive disorders, with negative beliefs associated with an increased risk for adolescent depression.\" Similarly, Katz & Hunter (2007) examined the effects of maternal meta-emotion on adolescent depressive symptoms. The authors found that adolescents with high levels of depressive symptoms tended to have mothers who were less accepting of their own emotions. Mothers who were more accepting of their own emotions tended to have adolescents with higher self-esteem, fewer externalizing problems, and fewer depressive symptoms. In conclusion, this study demonstrated a strong correlation between maternal meta-emotion philosophy and adolescent depression. Thus, these authors suggest that meta-emotion philosophy is related to adolescent depression and affect.\n\nAnother study found that mothers with a meta-emotion philosophy that is higher in both awareness and acceptance were correlated with fewer negative social behaviors during mother-child interactions. This suggests that maternal meta-emotion philosophy also influences the interactions between the mother and her adolescent. It would be interesting to examine whether or not this holds true for fathers and their adolescents as well. \n\nAside from examining the impact of parental meta-emotion on children's affect and depressive symptomatology, some psychologists have researched the influence of meta-emotion on the development of children's coping strategies. Lagacé-Séguin & Gionet (2009) were interested in studying the nature versus nurture debate regarding children's development of coping strategies. To do so, they examined the impact of both temperament (nature) and parental meta-emotion philosophy (nurture) on the development of coping skills in early adolescents. The authors found many interactions between parental meta-emotion and the adolescent's temperament. For example, they found that emotion-coaching parenting was related to distraction coping strategies for children with lower negative affect and higher surgency. The authors concluded that parental meta-emotion philosophy styles can interact with a child's temperament and predict the adolescents' coping styles.\n\nGottman et al. examined whether meta-emotion variables applied solely to parenting styles or if these variables also impacted a couple's marriage. To examine this question, Gottman et al. examined the longitudinal stability of the participants' marriage and how the couples resolved their conflicts. They assessed both parents' sadness and anger meta-emotions.\nGottman et al. found that fathers who are more aware of their sadness were more affectionate and have wives who were \"less contemptuous and belligerent\" (198). Fathers who followed an emotion-coaching philosophy with concern to both sadness and anger were less defensive and more affectionate, but fathers who were merely aware of their own anger and their child's anger were more defensive and belligerent. Thus, the father's awareness of his anger was not necessarily a positive quality with concern to his marriage. On the other hand, fathers who maintained an emotion-coaching philosophy were more affectionate with their spouses and have wives who were also more affectionate and less contemptuous.\n\nGottman et al. examined mothers' sadness and anger meta-emotions as well. They found that mothers who were aware of their own sadness and their children's sadness were less belligerent, and had husbands who were also less belligerent and contemptuous. Mothers who followed an emotion-coaching philosophy with concern to sadness tended to have husbands were \"less disgusted and less belligerent\" (201). Gottman et al. found that mothers who were aware of their children's anger were less contemptuous, but also less affectionate toward their husbands. They concluded that for mothers, awareness of their child's emotions had a positive impact on marital interaction, but for fathers, awareness of his child's anger did not have positive implications for his marriage.\nRowsell et al. studied relationship between meta-emotion and friendships in adolescence. Students from five Australian high schools completed questionnaires. The total sample of participants was 795. They found that emotion identification skill in early adolescence was predictive of friendships for females in late adolescence. Specifically, girls starting out with low emotion identification skill in Grade 8 tended to have fewer female friendships and more male friendships in Grade 12. There were no effects for males. Lower initial emotion identification skill was associated with significant improvements in awareness over time, but these improvements had no effect on friendships in Grade 12. The emotion identification skill that girls enter high school with may influence their friendship composition into late adolescence.\n\nThe meta-emotion interview is the most widely used measurement tool of meta-emotion. Each parent is separately interviewed about their own encounters with anger and sadness, their beliefs about emotional expression, and their attitudes and responses to their children's sadness and anger. This interview was semi-structured, allowing for flexibility for both the interviewer and the interviewee. The interview was audio-taped and designed to evaluate three dimensions of meta-emotion for sadness and anger: the parent's awareness of their own emotion, their awareness of the child's emotion, and the coaching of the child's emotion.\n\nGottman, Katz, & Hooven updated their first meta-emotion interview to target parents' awareness of their own emotions and their children's emotions, as well as the parents' method of interacting with their children when the child is actively experiencing emotions. The interview outlines four types of parenting styles: emotion-coaching, laissez-faire, dismissing, and disapproving. It is an hour-long structured interview that is scored from audio-tapes\n\nThe primary goal of the most recent Meta-Emotion Interview (MEI) is to gain a clear idea of how an individual experiences a particular emotion. Although it was first used to examine the emotions of sadness and anger, it has since been expanded to include pride and love/affection. The MEI focuses on one emotion at a time—all the questions are answered about one particular emotion (i.e.: sadness) before the interviewer moves on to the next emotion. For each emotion, the individual is first asked about their childhood and how their family handled and expressed each emotion. Then, they are asked about how they experience the emotion now. The questions particularly target how they experience each emotion in their relationships with their spouse and/or child. The MEI also addresses nonverbal expressions of emotion. For example, the interviewer asks what the individual looks like when he or she experiences a particular emotion (i.e.: \"What do you look like when you are sad?\"). The MEI is videotaped and then coded using the MEI Coding System, which focuses on four main dimensions of emotion: awareness, acceptance, dysregulation, and coaching. Awareness refers to the extent to which the individual acknowledges that they are experiencing an emotion. Acceptance refers to whether the individual not only allows themselves to experience the emotion, but also feels comfortable expressing it. Dysregulation relates to the individual's reported difficulties regulating their expression of the particular emotion. Finally, coaching refers to the degree to which individuals are able to identify and accept others' (i.e.: spouse or child) emotional experience in a positive manner.\n\nLagacé-Séguin & Coplan (2005) constructed the first published self-report parenting scale (the Maternal Emotional Styles Questionnaire) used to measure emotion coaching and emotion dismissing meta-emotion philosophy. The psychometric properties (i.e, reliability and validity) of the MESQ were found to be more than acceptable and the measure has been used in conjunction with child temperament to predict social outcomes for children based on theory of Goodness of Fit (Lagacé-Séguin & Coplan,2005).\n"}
{"id": "1099395", "url": "https://en.wikipedia.org/wiki?curid=1099395", "title": "Near-death studies", "text": "Near-death studies\n\nNear-death studies is a field of psychology and psychiatry that studies the physiology, phenomenology and after-effects of the near-death experience (NDE). The field was originally associated with a distinct group of North American researchers that followed up on the initial work of Raymond Moody, and who later established the International Association for Near-death Studies (IANDS) and the \"Journal of Near-Death Studies\". Since then the field has expanded, and now includes contributions from a wide range of researchers and commentators worldwide.\n\nThe near-death experience is an experience reported by people who have come close to dying in a medical or non-medical setting. The aspect of trauma, and physical crises, is also recognized as an indicator for the phenomenon. According to sources it is estimated that near-death experiences are reported by five percent of the adult American population. According to IANDS, surveys (conducted in USA, Australia and Germany) suggest that 4 to 15% of the population have had NDEs. Researchers study the role of physiological, psychological and transcendental factors associated with the NDE. These dimensions are also the basis for the three major explanatory models for the NDE.\n\nSome general characteristics of an NDE include subjective impressions of being outside the physical body; visions of deceased relatives and religious figures; transcendence of ego and spatiotemporal boundaries. NDE researchers have also found that the NDE may not be a uniquely western experience. Commentators note that several elements and features of the NDE appears to be similar across cultures, but the details of the experience (figures, beings, scenery), and the interpretation of the experience, varies between cultures. However, a few researchers have challenged the hypothesis that near-death experience accounts are substantially influenced by prevailing cultural models.\n\nAccording to the \"NDE-scale\" a near-death-experience includes a few, or several, of the following 16 elements:\n\n\nIn a study published in \"The Lancet\" van Lommel and colleagues list ten elements of the NDE: \n\n\nAccording to sources the NDE is associated with a number of after-effects, or life changing effects. The effects, which are often summarized by researchers, include a number of value, attitude and belief changes that reflect radical changes in personality, and a new outlook on life and death, human relations, and spirituality. Many of the effects are considered to be positive or beneficial. van Lommel and colleagues conducted a longitudinal follow-up research into transformational processes after NDE's and found a long-lasting transformational effect of the experience.\n\nHowever, not all after-effects are beneficial. The literature describes circumstances where changes in attitudes and behavior can lead to distress, psychosocial, or psychospiritual problems. Often the problems have to do with adjustment to the new situation following a near-death experience, and its integration into ordinary life. Another category, so-called distressing or unpleasant near-death experiences, has been investigated by Greyson and Bush.\n\nExplanatory models for the phenomenology and the elements of the NDE can, according to sources, be divided into a few broad categories: psychological, physiological, and transcendental. Agrillo, adopting a more parsimonious overview, notes that literature reports two main theoretical frameworks: (1) “biological/psychological” interpretation (in-brain theories), or (2) “survivalist” interpretation (out-of-brain theories). The research on NDEs often include variables from all three models. In a study published in 1990, Owens, Cook and Stevenson presented results that lent support to all of these three interpretations.\n\nEach model contains a number of variables that are often mentioned, or summarized, by commentators:\n\nPsychological theories have suggested that the NDE can be a consequence of mental and emotional reactions to the perceived threat of dying, or a result of expectation.\n\nPhysiological theories tend to focus on somatic, biological or pharmacological explanations for the NDE, often with an emphasis on the physiology of the brain. Variables that are considered, and often summarized by researchers, include: anoxia; cerebral hypoxia; hypercarbia; endorphins; serotonin or various neurotransmitters; temporal lobe dysfunction or seizures; the NMDA receptor; activation of the limbic system; drugs; retinal ischemia; and processes linked to rapid eye-movement (REM) sleep or phenomena generated on the border between sleep and wakefullness.\n\nA third model, sometimes called the transcendental explanation, considers a number of categories, often summarized by commentators, that usually fall outside the scope of physiological or psychological explanations. This explanatory model considers whether the NDE might be related to the existence of an afterlife; a changing state of consciousness; mystical (peak) experiences; or the concept of a mind-body separation.\n\nSeveral researchers in the field, while investigating variables from all three models, have expressed reservations towards explanations that are purely psychological or physiological. van Lommel and colleagues have argued for the inclusion of transcendental categories as part of the explanatory framework. Other researchers, such as Parnia, Fenwick, and Greyson, have argued for an expanded discussion about the mind-brain relationship and the possibilities of human consciousness.\n\nIndividual cases of NDEs in literature have been identified into ancient times. In the 19th century a few efforts moved beyond studying individual cases - one privately done by Mormons and one in Switzerland. Up to 2005, 95% of world cultures have been documented making some mention of NDEs. From 1975 to 2005, some 2500 self reported individuals in the US had been reviewed in retrospective studies of the phenomena with an additional 600 outside the US in the West, and 70 in Asia. Prospective studies, reviewing groups of individuals and then finding who had an NDE after some time and costing more to do, had identified 270 individuals. In all close to 3500 individual cases between 1975 and 2005 had been reviewed in one or another study. And all these studies were carried out by some 55 researchers or teams of researchers.\n\nResearch on near-death experiences is mainly limited to the disciplines of medicine, psychology and psychiatry. Interest in this field of study was originally spurred by the research of such pioneers as Elisabeth Kübler-Ross (psychiatrist) and Raymond Moody (psychologist and M.D.), but also by autobiographical accounts, such as the books of George Ritchie (psychiatrist). Kübler-Ross, who was a researcher in the field of Thanatology and a driving force behind the establishment of the Hospice System in the United States, reported on her interviews for the first time in her book \"On Death and Dying. What the dying have to teach doctors, nurses, clergy, and their own families\"(1969). Raymond Moody, on the other hand, got interested in the subject at the start of his career. In the mid-seventies, while doing his medical residency as a psychiatrist at the University of Virginia, he conducted interviews with Near-Death Experiencers. He later published these findings in the book \"Life After Life\" (1976). In the book Moody outlines the different elements of the NDE. Features that were picked up by later researchers. The book brought a lot of attention to the topic of NDEs.\n\nThe late seventies saw the establishment of the \"Association for the Scientific Study of Near-Death Phenomena\", an initial group of academic researchers, including John Audette, Raymond Moody, Bruce Greyson, Kenneth Ring and Michael Sabom, who laid the foundations for the field of Near-death studies, and carried out some of the first post-Moody NDE research. The Association was the immediate predecessor of the International Association for Near-death Studies (IANDS), which was founded in the early eighties and which established its headquarters at the University of Connecticut, Storrs. This group of researchers, but especially Ring, was responsible for launching Anabiosis, the first peer-reviewed journal within the field. The journal later became Journal of Near-Death Studies.\n\nHowever, even though the above-mentioned profiles introduced the sucject of NDE's to the academic setting, the subject was often met with academic disbelief, or regarded as taboo. The medical community has been somewhat reluctant to address the phenomenon of NDEs, and grant money for research has been scarce. However, both Ring and Sabom made contributions that were influential for the newly established field. Ring published a book in 1980 called \"Life at Death: A Scientific Investigation of the Near-Death Experience\". This early research was followed up by new book in 1984 by the title \"Heading Toward Omega: In Search of the Meaning of the Near-Death Experience\". The early work of Michael Sabom was also bringing attention to the topic within the academic community. Besides contributing material to academic journals, he wrote a book called \"Recollections of Death\" (1982) which is considered to be a significant publication in the launching of the field.\n\nAs research in the field progressed both Greyson and Ring developed measurement tools that can be used in a clinical setting. Greyson has also addressed different aspects of the NDE, such as the psychodynamics of the experience, the varieties of NDE, the typology of NDE's and the biology of NDE's. In addition to this he has brought attention to the near-death experience as a focus of clinical attention, suggesting that the aftermath of the NDE, in some cases, can lead to psychological problems.\n\nThe 1980s also introduced the research of Melvin Morse, another profile in the field of near-death studies. Morse and colleagues investigated near-death experiences in a pediatric population. They found that children reported NDE's that were similar to those described by adults. Morse later published two books, co-authored with Paul Perry, that were aimed at a general audience: \"Closer to the light: learning from children’s near-death experiences\" (1990) and \"Transformed by the light: the powerful effect of near-death experiences on people’s lives\" (1992). Another early contribution to the field was the research of British Neuro-psychiatrist Peter Fenwick, who started to collect NDE-stories in the 1980s. In 1987 he presented his findings on a television-program, which resulted in more stories being collected. The responses from Near-death experiencers later served as the basis for a book published in 1997, \"The Truth in the light\", co-authored with his wife Elizabeth Fenwick. Co-operating with other researchers, among others Sam Parnia, Fenwick has also published research on the potential relationship between cardiac arrest and Near-death Experiences.\n\nEarly investigations into the topic of near-death experiences were also being conducted at the University of Virginia, where Ian Stevenson founded the Division of Personality Studies in the late sixties. The division went on to produce research on a number of phenomena that were not considered to be mainstream. In addition to near-death experiences this included: reincarnation and past lives, out-of-body experiences, apparitions and after-death communications, and deathbed visions. Stevenson, whose main academic interest was the topic of reincarnation and past lives, also made contributions to the field of near-death studies. In a 1990-study, co-authored with Owens & Cook, the researchers studied the medical records of 58 people who believed they had been near death. The authors judged 28 candidates to actually have been close to dying, while 30 candidates, who merely thought they were about to die, were judged to not have been in any medical danger. Both groups reported similar experiences, but the first group reported more features of the core NDE-experience than the other group.\n\nRecently, the work of Jeffrey Long has also attracted attention to the topic of NDE's in both the academic, and the popular field. In 2010 he released a book, co-authored with Paul Perry, called \"Evidence of the Afterlife: The Science of Near-Death Experiences\". In the book Long presented results from research conducted over the last decade. Research has also entered into other fields of interest, such as the mental health of military veterans. Goza studied NDE's among combat veterans. She found, among other things, that combat soldiers reported different, and less intense near-death experiences, compared to NDErs in the civilian population.\n\nThe first decades of Near-death research were characterized by retrospective studies. However, the 2000s marked the beginning of prospective studies in the field, both on the European and the American continent.\nIn a study from 2001, conducted at Southampton General Hospital, Parnia and colleagues found that 11.1% of 63 cardiac-arrest survivors reported memories of their unconscious period. Several of these memories included NDE-features. This study was the first in a series of new prospective studies using cardiac arrest criteria, and it was soon to be followed by the study of van Lommel and colleagues, also published in 2001. Pim van Lommel (cardiologist) was one of the first researchers to bring the study of NDE's into the area of Hospital Medicine. In 1988 he launched a prospective study that spanned 10 Dutch hospitals. 344 survivors of cardiac arrest were included in the study. 62 patients (18%) reported NDE. 41 of these patients (12%) described a core experience. The aim of the study was to investigate the cause of the experience, and assess variables connected to frequency, depth, and content.\n\nProspective studies were also taking place in the U.S. Schwaninger and colleagues collaborated with Barnes-Jewish Hospital, where they studied cardiac arrest patients over a three-year period (April 1991 - February 1994). Only a minority of the patients survived, and from this group 30 patients were interviewable. Of these 30 patients 23% reported an NDE, while 13% reported an NDE during a prior life-threatening illness. Greyson conducted a 30-month survey of patients admitted to the cardiac inpatient service of the University of Virginia Hospital. He found that NDE's were reported by 10% of patients with cardiac arrest and 1% of other cardiac patients.\n\nIn 2008 the University of Southampton announced the start of a new research-project named The AWARE (AWAreness during REsuscitation) study. The study was launched by the University of Southampton, but included collaboration with medical centres within the UK, mainland Europe and North America. The object of the study was to study the brain, and consciousness, during cardiac arrest, and to test the validity of out of body experiences and reported claims of lucidity (the ability to see and hear) during cardiac arrest.\n\nThe first clinical paper from this project, described as a 4-year multi-center observational study, was published in 2014. The study found that 9% of patients who completed stage 2 interviews reported experiences compatible with NDEs.\n\nSeveral psychometric instruments have been adapted to near-death research. Ring developed the \"Weighted Core Experience Index\" in order to measure the depth of NDE's, and this instrument has been used by other researchers for this purpose. The instrument has also been used to measure the impact of near-death experiences on dialysis patients. According to some commentators the index has improved consistency in the field. However, Greyson notes that although the index is a pioneering effort, it is not based on statistical analysis, and has not been tested for internal coherence or reliability. In 1984 Ring developed an instrument called the \"Life Changes Inventory\" (LCI) in order to quantify value changes following an NDE. The instrument was later revised and standardized and a new version, the LCI-R, was published in 2004.\n\nGreyson developed \"The Near-Death Experience Scale\". This 16-item Scale was found to have high internal consistency, split-half reliability, and test-retest reliability and was correlated with Ring's \"Weighted Core Experience Index\". Questions formulated by the scale address such dimensions as: cognition (feelings of accelerated thought, or \"life-review\"), affect (feelings of peace and joy), paranormal experience (feelings of being outside of the body, or a perception of future events) and transcendence (experience of encountering deceased relatives, or experiencing an unearthly realm). A score of 7 or higher out of a possible 32 was used as the standard criterion for a near-death experience. The scale is, according to the author, clinically useful in differentiating NDEs from organic brain syndromes and nonspecific stress responses. The NDE-scale was later found to fit the Rasch rating scale model. The instrument has been used to measure NDE's among cardiac arrest survivors, coma survivors, out-of-hospital cardiac arrest patients/survivors, substance misusers, and dialysis patients.\n\nIn the late 1980s Thornburg developed the \"Near-Death Phenomena Knowledge and Attitudes Questionnaire\". The questionnaire consists of 23 true/false/undecided response items assessing knowledge, 23 Likert scale items assessing general attitudes toward near-death phenomena, and 20 Likert scale items assessing attitude toward caring for a client who has had an NDE. Knowledge and attitude portions of the instrument were tested for internal consistency. Content validity was established by using a panel of experts selected from nursing, sociology, and psychology. The instrument has been used to measure attitudes toward, and knowledge of, near-death experiences in a college population, among clergy, among registered psychologists, and among hospice nurses.\n\nGreyson has also used mainstream psychological measurements in his research, for example \"The Dissociative Experiences Scale\"; a measure of dissociative symptoms, and \"The Threat Index\"; a measure of the threat implied by one's personal death.\n\nThe field of near-death studies includes several communities that study the phenomenology of NDE's. The largest of these communities is IANDS, an international organization based in Durham, North-Carolina, that encourages scientific research and education on the physical, psychological, social, and spiritual nature and ramifications of near-death experiences. Among its publications we find the peer-reviewed \"Journal of Near-Death Studies\", and the quarterly newsletter \"Vital Signs\".<ref name=\"IANDS REV 4/11 \">IANDS. \"Near-Death Experiences: Is this what happens when we die?\" Durham: International Association for Near-Death Studies. Informational brochure REV 4/11. Available at www.iands.org.</ref> The organization also maintains an archive of near-death case histories for research and study.\n\nAnother research organization, the Louisiana-based Near Death Experience Research Foundation, was established by radiation oncologist Jeffrey Long in 1998. The foundation maintains a web-site, also launched in 1998, and a database of more than 1,600 cases, which is currently the world's largest collection of near-death reports. The reports come directly from sources all across the world.\n\nA few academic locations have been associated with the activities of the field of near-death studies. Among these we find the University of Connecticut (US), Southampton University (UK), University Of North Texas (US) and the Division of Perceptual Studies at the University of Virginia (US).\n\nIANDS holds conferences, at regular intervals, on the topic of near-death experiences. The first meeting was a medical seminar at Yale University, New Haven (CT) in 1982. This was followed by the first clinical conference in Pembroke Pines (FL), and the first research conference in Farmington (CT) in 1984. Since then conferences have been held in major U.S. cities, almost annually. Many of the conferences have addressed a specific topic, defined in advance of the meeting. In 2004 participants gathered in Evanston (IL) under the headline:\"Creativity from the light\". A few of the conferences have been arranged at academic locations. In 2001 researchers and participants gathered at Seattle Pacific University. In 2006 the University of Texas MD Anderson Cancer Center became the first medical institution to host the annual IANDS conference.\n\nThe first international medical conference on near-death experiences was held in 2006. Approximately 1.500 delegates, including people who claim to have had NDEs, were attending the one-day conference in Martigues, France. Among the researchers attending the conference were anaesthetist and intensive care doctor Jean-Jacques Charbonnier, and pioneering researcher Raymond Moody.\n\nIANDS publishes the quarterly \"Journal of Near-Death Studies\", the only scholarly journal in the field. The Journal is cross-disciplinary, is committed to an unbiased exploration of the NDE and related phenomena, and welcomes different theoretical perspectives and interpretations that are based on scientific criteria, such as empirical observation and research. IANDS also publishes \"Vital Signs\", a quarterly newsletter that is made available to its members and that includes commentary, news and articles of general interest.\nOne of the first introductions to the field of near-death studies was the publication of a general reader: \"The Near-Death Experience: Problems, Prospects, Perspectives\". The book was published in 1984 and was an early overview of the field. In 2009 Praeger Publishers published the \"Handbook of Near-Death Experiences: thirty years of investigation\", a comprehensive critical review of the research carried out within the field of near-death studies. 2011 marked the publication of \"Making Sense of Near-Death Experiences: A Handbook for Clinicians.\" The book is a multi-author text which describes how the NDE can be handled in psychiatric and clinical practice.\n\nSkepticism towards the findings of near-death studies, and the validity of the near-death experience as a subject for scientific study, has been widespread. According to Knapton, in \"The Daily Telegraph\", the subject was, until recently, considered to be controversial. Both scientists and medical professionals have, in general, tended to be skeptical. According to commentators in the field the early study of Near-death experiences was met with \"academic disbelief\". Acceptance of NDE's as a legitimate topic for scientific study has improved, but the process has been slow. According to literature \"psychiatrists have played a role in the recognition of the “near-death” phenomenon as well as popularization of the subject and subsequent research\".\nSkeptics have remarked that it is difficult to verify many of the anecdotal reports that are being used as background material in order to outline the features of the NDE.\n\nInternet Infidels paper editor, and commentator, Keith Augustine has criticized near-death research for oversimplifying the role of culture in afterlife beliefs. He has also exposed weaknesses in methodology, paucity of data, and gaps in arguments. Instead of a transcendental model of NDE's, which he does not find plausible, he suggests that NDE's are products of individuals' minds rather than windows into a transcendental reality. His criticism has been answered by Greyson who suggests that the materialist model favored by Augustine is supported by even fewer data than the \"mind-brain separation model\" favored by many researchers within the field of near-death studies.\n\nThe findings of NDE-research has been contested by several writers in the fields of psychology and neuroscience. Susan Blackmore has contested the findings of NDE-research, and has instead argued in favour of a neurological explanation. Psychologist Christopher French has reviewed several of the theories that have originated from the field of Near-death studies. This includes theories that present a challenge to modern neuroscience by suggesting a new understanding of the mind-brain relationship in the direction of transcendental, or paranormal, elements. In reply to this French argues in favour of the conventional scientific understanding, and introduces several non-paranormal factors, as well as psychological theory, that might explain those near-death experiences that defy conventional scientific explanations. However, he does not rule out a future revision of modern neuroscience, awaiting new and improved research procedures.\n\nJason Braithwaite, a Senior Lecturer in Cognitive Neuroscience in the Behavioural Brain Sciences Centre, University of Birmingham, issued an in-depth analysis and critique of the survivalist's neuroscience of some NDE researchers, concluding, \"it is difficult to see what one could learn from the paranormal survivalist position which sets out assuming the truth of that which it seeks to establish, makes additional and unnecessary assumptions, misrepresents the current state of knowledge from mainstream science, and appears less than comprehensive in its analysis of the available facts.\"\n\nMartens noted the \"lack of uniform nomenclature\", and \"the failure to control the studied population with an elimination of interfering factors\", as examples of criticism directed towards near-death research.\n\nBut criticism of the field has also come from commentators within its own ranks. In an open letter to the NDE-community Ring has pointed to the \"issue of possible religious bias in near-death studies\". According to Ring the field of near-death studies, as well as the larger NDE-movement, has attracted a variety of religious and spiritual affiliations, from a number of traditions, which makes ideological claims on behalf of NDE-research. In his view this has compromised the integrity of research and discussion.\n\n\n"}
{"id": "26891474", "url": "https://en.wikipedia.org/wiki?curid=26891474", "title": "PVLV", "text": "PVLV\n\nThe primary value learned value (PVLV) model is a possible explanation for the reward-predictive firing properties of dopamine (DA) neurons. It simulates behavioral and neural data on Pavlovian conditioning and the midbrain dopaminergic neurons that fire in proportion to unexpected rewards. It is an alternative to the temporal-differences (TD) algorithm.\n\nIt is used as part of Leabra.\n"}
{"id": "14192283", "url": "https://en.wikipedia.org/wiki?curid=14192283", "title": "Peranius of Iberia", "text": "Peranius of Iberia\n\nPeranius () was a Georgian prince from Iberia and a military commander in Roman (Byzantine) service. According to Procopius, he was the eldest son of the Iberian king Gurgenes. Gurgenes can be identified with Vakhtang I Gorgasali of the Georgian sources; and Peranius might have been his brother rather than a son as suggested by Procopius. He was the father of Pacurius and uncle of Phazas, two other Iberian generals of the Roman army. \n\nPeranius and his family fled the Sassanid oppression of Iberia into Lazica in the 520s. They placed themselves under Roman protection and left for Constantinople where Peranius joined the Byzantine imperial army. Later in the 530s, he served under Belisarius in Italy and was in Rome during the siege by the Goths (537–538). During the siege, he defended the Porta Praenestina and led a sally from the Porta Salaria. In mid-538, he laid a siege to Urbs Vetus (Orvieto) which fell in early 539. \n\nEarly in the 540s, Peranius was transferred to the eastern frontier where he fought the Sassanid Persian armies. He raided Taraunitis in 543 and was one of the Roman commanders defending Edessa in 544. The Persian shah, Khosrau I (r. 531–579), demanded the surrender of Peranius on the grounds that Peranius was his hereditary slave. When a Sassanid contingent under Azarethes threatened to break into the city through one of the gates, Peranius led reinforcements of soldiers and citizens to the spot and averted the danger. \n\nSoon after the end of the siege of Edessa, Peranius died of severe injuries sustained in a fall from his horse while hunting. \n"}
{"id": "58604347", "url": "https://en.wikipedia.org/wiki?curid=58604347", "title": "Philip Trenary", "text": "Philip Trenary\n\nPhilip Hartley Trenary (August 1, 1954 – September 27, 2018) was an American businessman and civic leader who was the CEO and President of the Greater Memphis Chamber and a former CEO of Pinnacle Airlines.\n\nPhilip Hartley Trenary was born on August 1, 1954 in Pawhuska, Oklahoma, the son of May Ruth and Buck Trenary.\n\nHe grew up nearby in Shidler, Oklahoma. He learned to fly a plane before he learned to drive a car.\n\nTrenary earned a bachelor's degree in aeronautical engineering technology from Oklahoma State University in 1979.\n\nIn 1984, Trenary founded Exec Express Airlines (EEA) in Stillwater, Oklahoma. After EEA was moved to Texas in 1987, it was renamed Lone Star Airlines. In 1997, Trenary moved to Memphis to run a local airline that would become Pinnacle Airlines, a $1 billion turnover, regional airline employing 7,700 people. \n\nTrenary was married to Bridget, they had three children, and later divorced.\n\nTrenary was shot dead in Memphis on September 27, 2018. He was 64.\n"}
{"id": "248799", "url": "https://en.wikipedia.org/wiki?curid=248799", "title": "Philosophy of psychology", "text": "Philosophy of psychology\n\nPhilosophy of psychology refers to the many issues at the theoretical foundations of modern psychology. \n\nSome of the issues studied by the philosophy of psychology are epistemological concerns about the methodology of psychological investigation. For example:\n\nOther issues in philosophy of psychology are philosophical questions about the nature of mind, brain, and cognition, and are perhaps more commonly thought of as part of cognitive science, or philosophy of mind, such as:\n\nPhilosophy of psychology also closely monitors contemporary work conducted in cognitive neuroscience, evolutionary psychology, and artificial intelligence, for example questioning whether psychological phenomena can be explained using the methods of neuroscience, evolutionary theory, and computational modeling, respectively. Although these are all closely related fields, some concerns still arise about the appropriateness of importing their methods into psychology. Some such concerns are whether psychology, as the study of individuals as information processing systems (see Donald Broadbent), is autonomous from what happens in the brain (even if psychologists largely agree that the brain in some sense causes behavior (see supervenience)); whether the mind is \"hard-wired\" enough for evolutionary investigations to be fruitful; and whether computational models can do anything more than offer possible implementations of cognitive theories that tell us nothing about the mind (Fodor & Pylyshyn 1988).\n\nPhilosophy of psychology is a relatively young field because \"scientific\" psychology—that is, psychology that favors experimental methods over introspection—came to dominate psychological studies only in the late 19th century. One of philosophy of psychology's concerns is to evaluate the merits of the many different schools of psychology that have been and are practiced. For example, cognitive psychology's use of internal mental states might be compared with behaviorism, and the reasons for the widespread rejection of behaviorism in the mid-20th century examined.\n\nTopics that fall within philosophy of mind go back much farther. For example, questions about the very nature of mind, the qualities of experience, and particular issues like the debate between dualism and monism have been discussed in philosophy for many centuries.\n\nRelated to philosophy of psychology are philosophical and epistemological inquiries about clinical psychiatry and psychopathology. Philosophy of psychiatry is mainly concerned with the role of values in psychiatry: derived from philosophical value theory and phenomenology, values-based practice is aimed at improving and humanizing clinical decision-making in the highly complex environment of mental health care. Philosophy of psychopathology is mainly involved in the epistemological reflection about the implicit philosophical foundations of psychiatric classification and evidence-based psychiatry. Its aim is to unveil the constructive activity underlying the description of mental phenomena.\n\n\nThe London Philosophy Study Guide offers many suggestions on what to read, depending on the student's familiarity with the subject: Philosophy of psychology.\n\n"}
{"id": "25379890", "url": "https://en.wikipedia.org/wiki?curid=25379890", "title": "Princess Anna of Hesse and by Rhine", "text": "Princess Anna of Hesse and by Rhine\n\nPrincess Anna of Hesse and by Rhine (; 25 May 1843 – 16 April 1865) was the consort and second wife of Friedrich Franz II, Grand Duke of Mecklenburg-Schwerin.\n\nPrincess Anna of Hesse and by Rhine, third child and only daughter of Prince Karl of Hesse and by Rhine, and his wife, Princess Elisabeth of Prussia, was born at Bessungen, Grand Duchy of Hesse. Her paternal grandfather was Ludwig II, Grand Duke of Hesse and by Rhine. Her mother was a granddaughter of King Friedrich Wilhelm II of Prussia.\n\nHer eldest brother, Ludwig, married in 1862 to Princess Alice of the United Kingdom, third child and second daughter of Queen Victoria.\n\nAs a young girl, Anna was considered as a possible bride for the future Edward VII (known as 'Bertie' to his family). While his mother, Victoria, was in favor of Anna, Bertie's elder sister was opposed to the match, as she believed Anna had a \"disturbing twitch\". As time went by however, Victoria grew increasingly impatient, and tried to ignore her daughter's hints that Anna was not suitable, declaring, \"I am much pleased with the account of Princess Anna, (minus the twitching)\". In the end, Alexandra of Denmark was chosen instead.\n\nOn 4 July 1864 in Darmstadt, Anna married Friedrich Franz II, Grand Duke of Mecklenburg-Schwerin son of Paul Friedrich, Grand Duke of Mecklenburg-Schwerin. (Friedrich Franz's first wife, Princess Augusta Reuss of Köstritz, had died in 1862.) Together they had one daughter:\n\n\nAnna died of puerperal fever a week later after giving birth to her only daughter. She was buried at the Schwerin Cathedral. Her husband remarried to Princess Marie of Schwarzburg-Rudolstadt, and fathered by her Duke Henry of Mecklenburg-Schwerin, consort of Wilhelmina of the Netherlands.\n\n\n"}
{"id": "19172225", "url": "https://en.wikipedia.org/wiki?curid=19172225", "title": "Prokaryote", "text": "Prokaryote\n\nA prokaryote is usually a unicellular organism, sometimes a multi cellular organism, that lacks a membrane-bound nucleus, mitochondria, or any other membrane-bound organelle. The word \"prokaryote\" comes from the Greek πρό (\"pro\") \"before\" and κάρυον (\"karyon\") \"nut or kernel\". Prokaryotes are divided into two domains, Archaea and Bacteria. In contrast, species with nuclei and organelles are placed in the third domain, Eukaryota. Prokaryotes reproduce without fusion of gametes. The first living organisms are thought to have been prokaryotes.\n\nIn the prokaryotes, all the intracellular water-soluble components (proteins, DNA and metabolites) are located together in the cytoplasm enclosed by the cell membrane, rather than in separate cellular compartments. Bacteria, however, do possess protein-based bacterial microcompartments, which are thought to act as primitive organelles enclosed in protein shells. Some prokaryotes, such as cyanobacteria, may form large colonies. Others, such as myxobacteria, have multicellular stages in their life cycles.\n\nMolecular studies have provided insight into the evolution and interrelationships of the three domains of biological species. Eukaryotes are organisms, including humans, whose cells have a well defined membrane-bound nucleus (containing chromosomal DNA) and organelles. The division between prokaryotes and eukaryotes reflects the existence of two very different levels of cellular organization. Distinctive types of prokaryotes include extremophiles and methanogens; these are common in some extreme environments.\n\nProkaryotes have a prokaryotic cytoskeleton, albeit more primitive than that of the eukaryotes. Besides homologues of actin and tubulin (MreB and FtsZ), the helically arranged building-block of the flagellum, flagellin, is one of the most significant cytoskeletal proteins of bacteria, as it provides structural backgrounds of chemotaxis, the basic cell physiological response of bacteria. At least some prokaryotes also contain intracellular structures that can be seen as primitive organelles. Membranous organelles (or intracellular membranes) are known in some groups of prokaryotes, such as vacuoles or membrane systems devoted to special metabolic properties, such as photosynthesis or chemolithotrophy. In addition, some species also contain carbohydrate-enclosed microcompartments, which have distinct physiological roles (e.g. carboxysomes or gas vacuoles).\n\nMost prokaryotes are between 1 µm and 10 µm, but they can vary in size from 0.2 µm (\"Mycoplasma genitalium\") to 750 µm (\"Thiomargarita namibiensis\").\n\nProkaryotic cells have various shapes; the four basic shapes of bacteria are:\n\nThe archaeon Haloquadratum has flat square-shaped cells.\n\nBacteria and archaea reproduce through asexual reproduction, usually by binary fission. Genetic exchange and recombination still occur, but this is a form of horizontal gene transfer and is not a replicative process, simply involving the transference of DNA between two cells, as in bacterial conjugation.\n\nDNA transfer between prokaryotic cells occurs in bacteria and archaea, although it has been mainly studied in bacteria. In bacteria, gene transfer occurs by three processes. These are (1) bacterial virus (bacteriophage)-mediated transduction, (2) plasmid-mediated conjugation, and (3) natural transformation. Transduction of bacterial genes by bacteriophage appears to reflect an occasional error during intracellular assembly of virus particles, rather than an adaptation of the host bacteria. The transfer of bacterial DNA is under the control of the bacteriophage’s genes rather than bacterial genes. Conjugation in the well-studied \"E. coli\" system is controlled by plasmid genes, and is an adaptation for distributing copies of a plasmid from one bacterial host to another. Infrequently during this process, a plasmid may integrate into the host bacterial chromosome, and subsequently transfer part of the host bacterial DNA to another bacterium. Plasmid mediated transfer of host bacterial DNA (conjugation) also appears to be an accidental process rather than a bacterial adaptation.\n\nNatural bacterial transformation involves the transfer of DNA from one bacterium to another through the intervening medium. Unlike transduction and conjugation, transformation is clearly a bacterial adaptation for DNA transfer, because it depends on numerous bacterial gene products that specifically interact to perform this complex process. For a bacterium to bind, take up and recombine donor DNA into its own chromosome, it must first enter a special physiological state called competence. About 40 genes are required in \"Bacillus subtilis\" for the development of competence. The length of DNA transferred during \"B. subtilis\" transformation can be as much as a third to the whole chromosome. Transformation is a common mode of DNA transfer, and 67 prokaryotic species are thus far known to be naturally competent for transformation.\n\nAmong archaea, \"Halobacterium volcanii\" forms cytoplasmic bridges between cells that appear to be used for transfer of DNA from one cell to another. Another archaeon, \"Sulfolobus solfataricus\", transfers DNA between cells by direct contact. Frols et al. found that exposure of \"S. solfataricus\" to DNA damaging agents induces cellular aggregation, and suggested that cellular aggregation may enhance DNA transfer among cells to provide increased repair of damaged DNA via homologous recombination.\n\nWhile prokaryotes are considered strictly unicellular, most can form stable aggregate communities. When such communities are encased in a stabilizing polymer matrix (\"slime\"), they may be called \"biofilms\". Cells in biofilms often show distinct patterns of gene expression (phenotypic differentiation) in time and space. Also, as with multicellular eukaryotes, these changes in expression often appear to result from cell-to-cell signaling, a phenomenon known as quorum sensing.\n\nBiofilms may be highly heterogeneous and structurally complex and may attach to solid surfaces, or exist at liquid-air interfaces, or potentially even liquid-liquid interfaces. Bacterial biofilms are often made up of microcolonies (approximately dome-shaped masses of bacteria and matrix) separated by \"voids\" through which the medium (e.g., water) may flow easily. The microcolonies may join together above the substratum to form a continuous layer, closing the network of channels separating microcolonies. This structural complexity—combined with observations that oxygen limitation (a ubiquitous challenge for anything growing in size beyond the scale of diffusion) is at least partially eased by movement of medium throughout the biofilm—has led some to speculate that this may constitute a circulatory system and many researchers have started calling prokaryotic communities multicellular (for example ). Differential cell expression, collective behavior, signaling, programmed cell death, and (in some cases) discrete biological dispersal events all seem to point in this direction. However, these colonies are seldom if ever founded by a single founder (in the way that animals and plants are founded by single cells), which presents a number of theoretical issues. Most explanations of co-operation and the evolution of multicellularity have focused on high relatedness between members of a group (or colony, or whole organism). If a copy of a gene is present in all members of a group, behaviors that promote cooperation between members may permit those members to have (on average) greater fitness than a similar group of selfish individuals (see inclusive fitness and Hamilton's rule).\n\nShould these instances of prokaryotic sociality prove to be the rule rather than the exception, it would have serious implications for the way we view prokaryotes in general, and the way we deal with them in medicine. Bacterial biofilms may be 100 times more resistant to antibiotics than free-living unicells and may be nearly impossible to remove from surfaces once they have colonized them. Other aspects of bacterial cooperation—such as bacterial conjugation and quorum-sensing-mediated pathogenicity, present additional challenges to researchers and medical professionals seeking to treat the associated diseases.\n\nProkaryotes have diversified greatly throughout their long existence. The metabolism of prokaryotes is far more varied than that of eukaryotes, leading to many highly distinct prokaryotic types. For example, in addition to using photosynthesis or organic compounds for energy, as eukaryotes do, prokaryotes may obtain energy from inorganic compounds such as hydrogen sulfide. This enables prokaryotes to thrive in harsh environments as cold as the snow surface of Antarctica, studied in cryobiology or as hot as undersea hydrothermal vents and land-based hot springs.\n\nProkaryotes live in nearly all environments on Earth. Some archaea and bacteria are extremophiles, thriving in harsh conditions, such as high temperatures (thermophiles) or high salinity (halophiles). Many archaea grow as plankton in the oceans. Symbiotic prokaryotes live in or on the bodies of other organisms, including humans.\n\nIn 1977, Carl Woese proposed dividing prokaryotes into the Bacteria and Archaea (originally Eubacteria and Archaebacteria) because of the major differences in the structure and genetics between the two groups of organisms. Archaea were originally thought to be extremophiles, living only in inhospitable conditions such as extremes of temperature, pH, and radiation but have since been found in all types of habitats. The resulting arrangement of Eukaryota (also called \"Eucarya\"), Bacteria, and Archaea is called the three-domain system, replacing the traditional two-empire system.\n\nA widespread current model of the evolution of the first living organisms is that these were some form of prokaryotes, which may have evolved out of protocells, while the eukaryotes evolved later in the history of life. Some authors have questioned this conclusion, arguing that the current set of prokaryotic species may have evolved from more complex eukaryotic ancestors through a process of simplification.\nOthers have argued that the three domains of life arose simultaneously, from a set of varied cells that formed a single gene pool. This controversy was summarized in 2005:\nThere is no consensus among biologists concerning the position of the eukaryotes in the overall scheme of cell evolution. Current opinions on the origin and position of eukaryotes span a broad spectrum including the views that eukaryotes arose first in evolution and that prokaryotes descend from them, that eukaryotes arose contemporaneously with eubacteria and archeabacteria and hence represent a primary line of descent of equal age and rank as the prokaryotes, that eukaryotes arose through a symbiotic event entailing an endosymbiotic origin of the nucleus, that eukaryotes arose without endosymbiosis, and that eukaryotes arose through a symbiotic event entailing a simultaneous endosymbiotic origin of the flagellum and the nucleus, in addition to many other models, which have been reviewed and summarized elsewhere.\nThe oldest known fossilized prokaryotes were laid down approximately 3.5 billion years ago, only about 1 billion years after the formation of the Earth's crust. Eukaryotes only appear in the fossil record later, and may have formed from endosymbiosis of multiple prokaryote ancestors. The oldest known fossil eukaryotes are about 1.7 billion years old. However, some genetic evidence suggests eukaryotes appeared as early as 3 billion years ago.\n\nWhile Earth is the only place in the universe where life is known to exist, some have suggested that there is evidence on Mars of fossil or living prokaryotes. However, this possibility remains the subject of considerable debate and skepticism.\n\nThe division between prokaryotes and eukaryotes is usually considered the most important distinction or difference among organisms. The distinction is that eukaryotic cells have a \"true\" nucleus containing their DNA, whereas prokaryotic cells do not have a nucleus. Both eukaryotes and prokaryotes contain large RNA/protein structures called ribosomes, which produce protein.\n\nAnother difference is that ribosomes in prokaryotes are smaller than in eukaryotes. However, two organelles found in many eukaryotic cells, mitochondria and chloroplasts, contain ribosomes similar in size and makeup to those found in prokaryotes. This is one of many pieces of evidence that mitochondria and chloroplasts are themselves descended from free-living bacteria. This theory holds that early eukaryotic cells took in primitive prokaryotic cells by phagocytosis and adapted themselves to incorporate their structures, leading to the mitochondria we see today.\n\nThe genome in a prokaryote is held within a DNA/protein complex in the cytosol called the nucleoid, which lacks a nuclear envelope. The complex contains a single, cyclic, double-stranded molecule of stable chromosomal DNA, in contrast to the multiple linear, compact, highly organized chromosomes found in eukaryotic cells. In addition, many important genes of prokaryotes are stored in separate circular DNA structures called plasmids. Like Eukaryotes, prokaryotes may partially duplicate genetic material, and can have a haploid chromosomal composition that is partially replicated, a condition known as merodiploidy.\n\nProkaryotes lack mitochondria and chloroplasts. Instead, processes such as oxidative phosphorylation and photosynthesis take place across the prokaryotic cell membrane. However, prokaryotes do possess some internal structures, such as prokaryotic cytoskeletons. It has been suggested that the bacterial order Planctomycetes have a membrane around their nucleoid and contain other membrane-bound cellular structures. However, further investigation revealed that Planctomycetes cells are not compartmentalized or nucleated and like the other bacterial membrane systems are all interconnected.\n\nProkaryotic cells are usually much smaller than eukaryotic cells. Therefore, prokaryotes have a larger surface-area-to-volume ratio, giving them a higher metabolic rate, a higher growth rate, and as a consequence, a shorter generation time than eukaryotes.\n\n"}
{"id": "20040139", "url": "https://en.wikipedia.org/wiki?curid=20040139", "title": "RMS Atrato (1888)", "text": "RMS Atrato (1888)\n\nRMS \"Atrato was a UK steamship that was built in 1888 as a Royal Mail Ship and ocean liner for the Royal Mail Steam Packet Company. In 1912 she was sold and became the cruise ship The Viking. Toward the end of 1914 she was requisitioned and converted into the armed merchant cruiser HMS \"Viknor. She sank in 1915 with all hands, a total of 295 Royal Navy officers and men.\n\nIn the 1880s RMSP introduced a series of larger new ships to improve its scheduled services between Southampton, South America and the Caribbean. The first was the , built by Caird and Company and . She was RMSP's first new ship to have a hull of steel rather than iron. After her success RMSP ordered two more ships to an improved and enlarged version of the design from Robert Napier and Sons of Govan. \"Atrato\" was , followed by . Before these were completed RMSP ordered two more from Napier: the slightly larger in 1889 and .\n\n\"Orinoco\" had only a small amount of deck housing and was the last square-rigged sail-steamer to be built for RMSP. The Napier ships were more modern, each with a full superstructure deck and rigged as a three-masted schooner. The smaller sail plan was based on the increasing economy and reliability of their engines.\n\n\"Atrato\"s boilers had a working pressure of 150 lb/in. She had eight of them, supplying steam to one three-cylinder triple expansion steam engine that drove a single screw. This gave her a top speed of on trials and a service speed of .\n\nThe ship's passenger capacity included 176 in first class state rooms and nearly 400 emigrants in steerage class. Her cargo capacity was 2,524 tons and her coal bunkers 1,109 tons. She had of refrigerated storage space for provisions, using a dry-air refrigeration system with a discharge rate of of air per hour. She had tanks for of fresh water.\n\n\"Atrato\" was launched on 22 September 1888, named after the Atrato River in Colombia. RMSP named all of its ships after rivers; many of them with Hispanic names to reflect its trade with Latin America.\n\n\"Atrato\"s maiden voyage began from Southampton on 17 January 1889. As well as her passengers, mails and a full cargo she carried in her strong room £120,000 in sovereigns, jewellery worth £2,000 and silver bars worth £400. She called at Carril, Vigo and Lisbon, and then crossed the Atlantic to South America. There she worked her way down the east coast, calling at Pernambuco, Maceió, Bahia, Rio de Janeiro, Santos, Montevideo and Buenos Aires. \"Magdalena\", \"Thames\" and \"Clyde\" joined the same South American route over the next 18 months, but after her maiden voyage \"Atrato\" was switched to join \"Orinoco\" on RMSP's Caribbean route. All five sisters had long and successful careers.\n\nThe five ships' furnaces suffered from heat damage, so in 1891 they were lined with zinc. In 1899 Day, Summers and Company of Southampton raised the boats on \"Atrato\", \"Magdalena\", \"Thames\" and \"Clyde\" \"to a boat deck clear of the promenade\" at a cost of more than £5,000. In 1903 \"Atrato\", \"Magdalena\" and \"Clyde\" were fitted with bronze propellers costing another £5,000. In May 1905 RMSP ordered insulation and refrigeration to be fitted to part of their cargo space to enable \"Orinoco\" and \"Atrato\" to carry fresh fruit.\n\nIn October 1912 the Viking Cruising Company of London bought \"Atrato\" and renamed her \"The Viking\". She became a cruise ship, touring the waters of northern Europe.\n\nWhen the UK entered the First World War in 1914 the Admiralty requisitioned her, had her re-fitted as an armed merchant cruiser and commissioned her as HMS \"Viknor\". She was placed under the command of Commander EO Ballantyne with a complement of 22 officers and 273 ratings and assigned to the 10th Cruiser Squadron.\n\nOn 28 December 1914 \"Viknor\" went on patrol from the River Tyne, and on 1 January she joined \"B\" patrol off the north coast of Scotland. The patrol was ordered to find and stop the neutral Norwegian America Line ship , which the UK Government believed was carrying a suspected German spy. \"Viknor\" found \"Bergensfjord\", detained her and escorted her to Kirkwall in Orkney. There the suspect and a number of other prisoners were transferred to \"Viknor\", which then left for Liverpool.\n\n\"Viknor\" never reached her destination. On 13 January 1915 she sank with all hands in heavy seas off Tory Island, County Donegal, Ireland. She sent no distress signal. Some wreckage and many corpses washed ashore on the northern coast of Ireland.\n\nIt is thought she struck a German naval mine, possibly one of those laid by the German . Her wreck was found in 2006, and in 2011 a scuba diver placed a White Ensign on it in memory of her complement.\n\n"}
{"id": "250841", "url": "https://en.wikipedia.org/wiki?curid=250841", "title": "Samuel Wilberforce", "text": "Samuel Wilberforce\n\nSamuel Wilberforce FRS (7 September 1805 – 19 July 1873) was an English bishop in the Church of England, third son of William Wilberforce. Known as \"Soapy Sam\", Wilberforce was one of the greatest public speakers of his day. The nickname derives from a comment by Benjamin Disraeli that the bishop's manner was \"unctuous, oleaginous, saponaceous\". He is probably best remembered today for his opposition to Charles Darwin's theory of evolution—most notably at a famous debate in 1860.\n\nWilberforce was born at Clapham Common, London. He was the son of William Wilberforce, a major campaigner against the slave trade and slavery and Barbara Spooner, and the younger brother of Robert Isaac Wilberforce. In 1823 he entered Oriel College, Oxford. In the United Debating Society, which afterwards developed into the Union, he distinguished himself as a zealous advocate of liberalism. The set of friends with whom he chiefly associated at Oxford—among them William Ewart Gladstone and Henry Manning—were sometimes named, on account of their exceptionally decorous conduct, the \"Bethel Union\"; but he was by no means averse to amusements, and specially delighted in hurdle jumping, nude running and hunting. He graduated in 1826, taking a first-class degree in mathematics and a second in classics.\n\nHe spent the summer and autumn of 1827 touring the continent. After his marriage on 11 June 1828 to Emily Sargent, daughter of John Sargent, he was in December ordained to the Church of England and appointed curate-in-charge at Checkendon, near Henley-on-Thames.\n\nIn 1830, Wilberforce was presented by Charles Sumner, Bishop of Winchester, to the rectory of St. Mary's Church, Brighstone, in the Isle of Wight. In this comparatively retired sphere he soon found scope for that manifold activity which so prominently characterized his subsequent career. In 1831 he published a tract on tithes, \"to correct the prejudices of the lower order of farmers,\" and in the following year a collection of hymns for use in his parish, which had a large general circulation; a small volume of stories entitled the \"Note Book of a Country Clergyman\"; and a sermon, \"The Apostolical Ministry\". At the close of 1837 he published the \"Letters and Journals of Henry Martyn\", the Anglican missionary in India and Persia.\n\nAlthough a High Churchman, Wilberforce held aloof from the Oxford Movement and in 1838 his divergence from the Tractarian writers became so marked that John Henry Newman declined further contributions from him to the \"British Critic\", not deeming it advisable that they should longer \"co-operate very closely\". In 1838 Wilberforce published, with his elder brother Robert Wilberforce, the \"Life\" of his father and, two years later, his father's \"Correspondence\". In 1839 he also published \"Eucharistica\" (from the old English divines), to which he wrote an introduction, \"Agathos and other Sunday Stories\", and a volume of \"University Sermons\", and in the following year \"Rocky Island and other Parables\". In November 1839 he was installed archdeacon of Surrey, in August 1840 was collated canon of Winchester and in October he accepted the rectory of Alverstoke.\n\nIn 1841, he was chosen as the Bampton lecturer and was shortly afterwards made chaplain to Prince Albert, an appointment he owed to the impression produced by a speech at an anti-slavery meeting some months previously. In October 1843, he was appointed by the Archbishop of York to be sub-almoner to the Queen. In 1844 his \"A History of the Protestant Episcopal Church in America\" appeared. In March 1845 he accepted the position of Dean of Westminster and, in October the same year, was appointed as the Bishop of Oxford. As such, he was also \"ex officio\" the Chancellor of the Order of the Garter.\n\nThe bishop in 1847, upon the suggestion of John Henry Newman, became involved in the Hampden controversy, and signed the remonstrance of the thirteen bishops to Lord John Russell against Hampden's appointment to the bishopric of Hereford. He also endeavoured to obtain satisfactory assurances from Hampden; but, though unsuccessful in this, he withdrew from the suit against him. The publication of a papal bull in 1850 establishing a Roman hierarchy in England brought the High Church party, of whom Wilberforce was the most prominent member, into temporary disrepute. The secession to the Church of Rome of his brother-in-law, afterwards Cardinal Manning, and then of his brothers, as well as his only daughter and his son-in-law, Mr and Mrs J. H. Pye, brought him under further suspicion, and his revival of the powers of Convocation lessened his influence at court; but his unfailing tact and wide sympathies, his marvellous energy in church organization, the magnetism of his personality, and his eloquence both on the platform and in the pulpit gradually won for him recognition as without a rival on the episcopal bench.\nHis diary reveals a tender and devout private life which has been overlooked by those who have only considered the versatile facility and persuasive expediency that marked the successful public career of the bishop, and perhaps earned him the sobriquet of \"Soapy Sam\", though this may have been a reference to his characteristic hand-washing gesture, captured in the \"Vanity Fair\" cartoon by 'Ape' (\"illustration, right\"). In the House of Lords he took a prominent part in the discussion of social and ecclesiastical questions. He has been styled the \"bishop of society\"; but society occupied only a fraction of his time. The great bent of his energies was ceaselessly directed to the better organization of his diocese and to the furtherance of schemes for increasing the influence and efficiency of the church.\n\nIn 1854, he opened a theological college at Cuddesdon, now known as Ripon College Cuddesdon, which was afterwards the subject of some controversy on account of its alleged Romanist tendencies.\n\nHe took part in the famous 1860 debate concerning evolution at a meeting of the British Association on 30 June. Richard Owen and Thomas Henry Huxley had already clashed on man's position in nature two days previously; on the Saturday, at the Oxford University Museum of Natural History, Wilberforce got his chance to criticise Charles Darwin's \"On the Origin of Species by means of Natural Selection\", especially the implication that humans and various species of apes share common ancestors.\n\nLucas argues that \"Wilberforce, contrary to the central tenet of the legend, did not prejudge the issue\". He criticised Darwin's theory on scientific grounds, arguing that it was not supported by the facts, and he noted that the greatest names in science were opposed to the theory. Nonetheless, Wilberforce's speech is generally only remembered today for his inquiry as to whether it was through his grandmother or his grandfather that Huxley considered himself descended from a monkey. Thomas Huxley is said to have replied that he would not be ashamed to have a monkey for his ancestor, but he would be ashamed to be connected with a man who used his great gifts to obscure the truth. Darwin was not present, but several of his friends replied, with Huxley perhaps the most effective. The popular view was and still is that Huxley had got the better of the exchange, however, historians agree that this story of the debate between Wilberforce and Huxley was a later fabrication and that it is impossible to know however the debate transpired. 'Reports from the time suggest that everybody enjoyed himself immensely, and all went cheerfully off to dinner together afterwards.'. As a son of William Wilberforce he was deeply concerned about the ethical consequences of what we now call Social Darwinism.\nTo see Wilberforce in the full glory of his social status and reputation, it is perhaps enough to recall that he was not merely Bishop of Oxford (a grand enough post in the nineteenth century) but Lord Bishop of Oxford, a member of the House of Lords and a Fellow of the Royal Society. This last distinction is rarely mentioned in accounts of the famous Oxford debate.\n\nHis attitude towards \"Essays and Reviews\" in 1861, against which he wrote an article in the \"Quarterly\", won him the special gratitude of the Low Church party, and latterly he enjoyed the full confidence and esteem of all except the extreme men of either side and party. It was also Wilberforce who proclaimed eminent geologist Sir Roderick Murchison the unofficial King of Siluria. On the publication of John William Colenso's \"Commentary on the Romans\" in 1861, Wilberforce endeavoured to induce the author to hold a private conference with him; but after the publication of the first two parts of the \"Pentateuch Critically Examined\" he drew up the address of the bishops which called on Colenso to resign his bishopric. In 1867 he framed the first \"Report of the Ritualistic Commission\", in which coercive measures against ritualism were discountenanced by the use of the word \"restrain\" instead of \"abolish\" or \"prohibit.\" He also endeavoured to take the sting out of some resolutions of the second Ritualistic Commission in 1868, and was one of the four who signed the Report with qualifications. Though strongly opposed to the disestablishment of the Irish Church, yet, when the constituencies decided for it, he advised that no opposition should be made to it by the House of Lords. After twenty-four years in the diocese of Oxford, he was translated by Gladstone to the bishopric of Winchester. He was killed on 19 July 1873, by the shock of a fall from his horse near Dorking, Surrey.\n\nWilberforce was the patron of Philip Reginald Egerton, who founded Bloxham School in Oxfordshire. A boarding house at the school is named after Wilberforce. Together with his brother Robert, he joined the Canterbury Association on 27 March 1848. He resigned from the Canterbury Association on 14 March 1849. The Wilberforce River in New Zealand was named for them.\n\nWilberforce left three sons. The eldest, Reginald, was the author of \"An Unrecorded Chapter of the Indian Mutiny\" (1894), criticised by his fellow officers of the 52nd Foot for its inaccuracy. Reginald was grandfather (through his fourth son, judge Samuel) to Richard Lord Wilberforce, a Lord of Appeal.\n\nHis two younger sons both attained distinction in the English church. Ernest (1840–1908) was Bishop of Newcastle-upon-Tyne from 1882 to 1895, and Bishop of Chichester from 1895 till his death. Basil (1841–1916) was appointed canon residentiary of Westminster in 1894, chaplain of the House of Commons in 1896 and Archdeacon of Westminster in 1900; he published several volumes of sermons.\n\nWilberforce appears alongside Charles Darwin and Thomas Huxley in Crispin Whittell's play \"Darwin in Malibu\".\n\nWilberforce is the main villain of Gideon Defoe's novel \"The Pirates! In an Adventure with Scientists\", where his opposition to Darwin is based in his part-ownership of a circus freakshow. He feels that Darwin's discovery (depicted in this book as teaching a chimpanzee to talk using note cards) will take away from his attraction's popularity, which he uses to kidnap young women and turn them into soap, hence his nickname.\n\nWilberforce appears, caricatured, in Anthony Trollope's novel \"The Warden\" (1855), where he is portrayed as the third child of the Archdeacon, Dr Grantly, who is named Samuel and nicknamed Soapy, and is engaging and ingratiating but not to be trusted (\"The Warden\", Chapter 12, 'Mr. Bold's Visit to Plumstead').\n\nBesides the works already mentioned, Wilberforce wrote \"Heroes of Hebrew History\" (1870), originally contributed to \"Good Words\", and several volumes of sermons.\n\n\n"}
{"id": "54698445", "url": "https://en.wikipedia.org/wiki?curid=54698445", "title": "Sean Rowley (singer)", "text": "Sean Rowley (singer)\n\nSean Edward Rowley (August 24, 1969 – November 12, 1992) was an American singer, songwriter and producer. Born in Rhode Island, but spending most of his life in California, he is best known as the lead singer and lyricist of the synthpop band Cause and Effect. Cause and Effect released their self-titled album, \"Cause & Effect\", in 1990. The album was later re-released as \"Another Minute\" in 1991.\n\nWhile on tour with synthpop band Information Society at the Glam Slam nightclub in Minneapolis, Minnesota, Rowley experienced an asthma attack during a pre-show soundcheck on November 12, 1992. He died and was buried in Minneapolis on November 14. He was 23 years old.\n"}
{"id": "39397236", "url": "https://en.wikipedia.org/wiki?curid=39397236", "title": "Ship of Theseus (film)", "text": "Ship of Theseus (film)\n\nShip of Theseus is a 2013 Indian drama film written and directed by Anand Gandhi, and produced by actor Sohum Shah. The film explores \"questions of identity, justice, beauty, meaning and death through the stories of an experimental photographer, an ailing monk and an enterprising stockbroker\", played by Aida El-Kashef, Neeraj Kabi and Sohum Shah.\n\nAfter three years in development, the film premiered at the 2012 Toronto International Film Festival, where it received critical acclaim and was touted as \"the hidden gem of the year\". \nIt has received positive reviews from both Indian and international press and has been hailed as \"the most significant film to come out of India in a very long time\". Film critic Derek Malcolm has called it a \"life-changing film\" and \"Variety\" commended its \"unexpected grandeur\".\nThe title of the film alludes to Theseus’ paradox, most notably recorded in \"Life of Theseus\", wherein the Greek historian and philosopher Plutarch inquires whether a ship that has been restored by replacing all its parts remains the same ship.\n\nThe film released in India on 19 July 2013. It won the award for the Best Feature Film of the year at the 61st National Film Awards.\n\nAaliya Kamal (Aida El-Kashef) is a visually impaired and celebrated Egyptian photographer in the process of undergoing a cornea transplant that will restore her vision. Though the surgery is a success and Aaliya’s vision is restored, she has trouble adjusting to her new found sense of sight and is dissatisfied with her resulting photography.\n\nMaitreya (Neeraj Kabi), an erudite Jain monk, is part of a petition to ban animal testing in India. When he is diagnosed with liver cirrhosis, his reluctance towards animal-tested medication is questioned and he must now depend on the people he’s been fighting against – a path he refuses to take.\n\nA young Indian stockbroker, Navin (Sohum Shah), has just received a new kidney. He soon learns of a case of organ theft involving an impoverished bricklayer, Shankar. He initially fears that his new kidney was the one stolen from Shankar. When he learns that the recipient of the kidney lives in Sweden, he decides to go there to help Shankar get his kidney back – but is Shankar perhaps better helped by a large financial settlement instead of having two kidneys again?\n\nShip of Theseus ends with the Platonic Allegory of the cave. The philosopher Plato argues that human beings are imprisoned in the cave of their own existence, falsely believing the temporary as having permanence. The job of a philosopher, he argues, is to help people find a way out of the cave.\n\nIn the last scene of the film, we see the shadow of the man in the walls of the cave he is exploring. Those who received his organs (including Aaliya, Maitreya and Navin) watch this short clip. The man who we see only as the shadow in this clip did not make it out of the allegorical prison-cave described by Plato.\n\nAnand Gandhi conceived the story while he was nursing his ailing grandparents at the hospital. It was here that he developed stories addressing the idea of the self, change and death. Through the ailing monk and the socially incognizant stockbroker, Gandhi and co-story writer Khushboo Ranka discussed questions of non-violence, altruism and responsibility. On cinematographer Pankaj Kumar’s suggestion, they developed the parallel story of a visually impaired photographer, who struggles with her revived sight following a cornea transplant. Gandhi spent the year after that developing the screenplay.\nWith a screenplay in hand, he set out to meet several producers – both independent and eminent. However, producing the film was usually perceived as a challenge, owing to prejudices about the commercial viability of an Indian film, dealing in such subject matter. Eventually, actor Sohum Shah decided to step in as the producer of the film, \"to safeguard the artistic integrity of the project\".\n\nAnand first met Egyptian filmmaker Aida El-Kashef in 2008, at the Hannover Film Festival where their respective short films – 'Continuum’ (which Gandhi had co-directed with Khushboo Ranka) and 'Rhapsody in Autumn’ – were being screened. The following year, Aida assisted Anand with the casting of the film. Her reading of the photographer’s lines, while auditioning actors for the character of the boyfriend, motivated Gandhi and DP Pankaj Kumar to cast her in the role. The character was subsequently re-written to accommodate her background and ethnicity.\n\nNeeraj Kabi, a Mumbai-based theatre actor and director, was considered for the role of Maitreya from the outset. Gandhi and Kabi discussed the character in detail, and rehearsed for a few months, prior to principal photography.\n\nSohum Shah met Gandhi through a mutual friend, and was chosen for the role of Navin in the stockbroker story, along with his friend and ally, Sameer Khurana (aka Mannu). Eventually, Shah found himself drawn to Gandhi’s story and vision, and came on board as the producer of the film as well.\n\nA lot of non-actors and friends were cast to play secondary and passing parts. Sunip Sengupta is a real-life lawyer. Vinay Shukla playing the young law intern Charvaka is a filmmaker, and Megha Ramaswamy, playing the interviewer, is a writer-producer. Paromita Vohra, a feminist documentary filmmaker, makes an appearance as well.\n\nThe film was shot over a period of two years on a Canon EOS-1D Mark IV, along with a Redrock Micro rig and a lot of guerilla techniques developed by DP Pankaj Kumar. Most of the film was shot on location in and around Mumbai, in Jaipur, Chhitkul (Himachal Pradesh) and also included a brief schedule in Stockholm. While shooting outside of Mumbai, the production unit generally consisted of a three-person crew, with each multi-tasking in various capacities.\n\nFor the Stockholm shoot, Gandhi connected with Rupesh Tillu, a theatre and clown artist based in the city. Tillu handled production and helped the team connect with actors and scout locations. He also played the role of Ajay, Navin’s friend in Stockholm.\n\nTo portray the ailing physical condition of Maitreya, Kabi lost close to 17 kilos (37.5 pounds, approx.) over four months, through a rigorous diet and exercise routine. Through this period, Kabi’s fragile state deterred him from taking on any additional acting or theatre work.\n\nGandhi also collaborated with Budapest-based Sound Designer, Gabor Erdelyi, who had earlier worked on some of Bela Tarr’s films, including \"The Turin Horse\".\n\nA work-in-progress version of the film was screened in the Film Bazaar in Goa in 2011. This is where Netherlands-based film sales company, Fortissimo Films, picked up world sales rights to the film.\n\nThe film premiered at the Toronto International Film Festival in September 2012, and has subsequently been screened at the Tokyo International Film Festival, the BFI London Film Festival, the Dubai International Film Festival, the Mumbai Academy of Moving Images, the Brisbane International Film Festival, the Rotterdam International Film Festival and the Hong Kong International Film Festival 2013.\n\nThe film was screened at Munich and Transylvania where it won the Best Film and Best Cinematography awards. It was also shown at the Sydney Film festival, where Anand Gandhi was invited to be a part of the international jury.\n\nShip of Theseus was released in theatres across Bangalore, Mumbai, Pune, Delhi, Kolkata and Hyderabad on 19 July 2013. Through the Vote For Your City Campaign, an initiative which saw audiences vote for the film to be released in specific cities, the film was released in Chennai, Kochi, Baroda and Ahmedabad on 26 July 2013. Film was further released in 17 more cities on 2 August.\nKiran Rao, after watching the film at Enlighten Films’ Naya Film Festival, came on board to present it to Indian audiences with UTV Motion Pictures as the distribution partner.\n\nOn 7 November 2013 the film was released in Australia with actor Hugo Weaving (\"The Matrix\" trilogy, \"Cloud Atlas\", \"Lord of the Rings\" film trilogy, \"V for Vendetta\") presenting.\n\nOn 15 January 2014 Ship of Theseus was made available for free online viewing and downloading for audiences in India. Soon, the filmmaker tweeted that besides the official free download page, people are also welcome to download the film via unauthorized torrents, in lieu of contributions towards the crowd funding campaign of their next production \"Proposition for a Revolution\".\n\nShip of Theseus has been released on DVD and Blu-ray by Eagle Home Entertainment. The DVD has been released as 2-Disc Edition with bonus disc containing features like Interviews, Bloopers, Making, 2 short films by Anand Gandhi, Deleted scenes, Production stills and a Pin-up poster. The Blu-ray version incorporates all the Bonus features on same disc. Both, DVD and Blu-ray have been meticulously designed by the team at Recyclewala Labs in collaboration with Kriti Media Services (now Cinephile Media), who have mastered and authored them.\n\nIn March 2015 entire footage rushes from the film: over 34 hours of footage with keywords, used/ unused annotations and descriptions, was released on the online platform Pad.ma.\n\nReviews for the film have been largely positive. Some reviewers named it \"one of the most significant films to have ever come out of India\".\n\nMembers of the Critics’ Circle, UK were invited to select and introduce a screening of \"the film that changed their life,\" to celebrate the 100th anniversary of the organisation. The list of 15 films included The 400 Blows, Annie Hall, Raging Bull, The Battle of Algiers and Hamlet. The president of the British Federation of Film Societies, Derek Malcolm chose Ship of Theseus.\n\nScreen International commended the film as being, \"Cerebral, visually stunning and completely different to anything we’ve seen before from independent Indian cinema… [a film] aiming at art and importance rather than mere profit.\" Variety wrote, \"Indie Indian cinema has finally come of age on the international fest scene, and no film better demonstrates this than Ship of Theseus.\"\n\nThe Canadian film critic, Marc Saint Cyr, after viewing the film at the Rotterdam film festival, in his Senses of Cinema review said, \"unquestionably describes [the film] as [a] true revelation\". He also noted the dialogue to be, \"consistently gripping, strikingly intelligent, and occasionally laced with surprising humour\".\n\nThe Globe and Mail called it \"an intellectual, contemplative film\", and also pointed out \"its occasional tendency to take its abstract ideas on the nature of self-identity and wrap them into neat plot twists can mildly disappoint. A small criticism though.\"\n\nIndian film critic Rajeev Masand in his review wrote, \"Languidly paced and lushly filmed, Ship of Theseus is just as rich cinematically, and benefits from terrific performances by each of the protagonists, particularly Kabi whose physical transformation as the ailing monk is a sight to behold.\"\n\nShubha Shetty-Saha in her five-star review for Mid-Day observed, \"Once in a while comes a film like this one, which along with shaking your core, also manages to make you grateful for being a humble part of the audience. 'Ship of Theseus' is one such rare film.\"\n\nAn NDTV review opined that, \"Ship Of Theseus is an extraordinary achievement. To miss it would be tantamount to missing one of the finest Indian films of recent times.\"\n\nShekhar Kapur tweeted, \"Finally a brilliant new filmmaker emerges in Anand Gandhi with `Ship of Theseus’.\"\nActor Hugo Weaving said, \"Ship Of Theseus is an absolutely rare and profound piece of cinema, full of wonder and enlightenment. Anand Gandhi has proved himself as a groundbreaking filmmaker.\"\n\nAnurag Kashyap called it, \"The most brilliant film to have been made in India in decades. Puts all of us to shame.\"\n\nVeteran filmmaker Shyam Benegal deemed it, \"A rare film that engages your mind, emotions and senses in equal measure providing the viewer a cinematic experience that is both hugely entertaining and stimulating.\"\n\nCelebrated documentary filmmaker and polemicist Anand Patwardhan wrote, \"Anand Gandhi’s 'Ship of Theseus' is Kieslowskian in scope and delivery, playing between serendipity and causality, but it took me that crucial step further in its rediscovery of the human.\"\n\nMan Booker Prize winning author and political activist Arundhati Roy wrote, \"Ship of Theseus is a profound and fearless film. It is fearlessly contemporary, fearlessly un-noisy and utterly beautifully observed.\"\n\nAtul Kulkarni called it, \"Ship of Theseus. A must, must, must watch. Go with lots of patience and you shall be rewarded with a 'life' time experience ...\"\n\nDibakar Banerjee said, \"Ship of Theseus gave me serious doubts about myself as a filmmaker. I seriously introspected for two-three days about my thinking as a filmmaker... This was one film which captivated you, which held you, which mesmerised you without manipulating even once.\" He also wrote a favourable review on the film and afforded it much praise, encouraging readers to watch the film twice.\n\nAt the core, the film assumes a, \"physical and philosophical interpretation of the Ship of Theseus paradox.\" Questions of death, morality and ethics form part of the struggles of each of the three central characters. TimeOut London has called it a \"A docu-drama interweaving three stories exploring life in contemporary Mumbai.\"\n\nMost of the themes are apparent through the film’s characters: \"They shared the central themes of idealism, identity, flexibility and the fallibility of conclusive knowing… At the heart, it is a story that celebrates dichotomy, paradox, duality and irony.\"\n\nThe film also delves into the nature of relationships – \"bound by similarities and challenged by the differences.\" Anand Gandhi has been further quoted as saying the characters themselves are, \"…manifestations of my artistic, ethical, social and philosophical struggles.\"\n\nThe character Aaliya’s visual disability has been described as being central to the idea of the Theseus paradox, wherein one of her parts has been replaced as it was in the mythical ship. It is this replacement that affects her photography and is recognised as the central conflict of the film. Her regained sight sees her relinquishing her natural intuition.\n\nThe filmmaker has been quoted as saying, \"There have been a lot of ideas that have fascinated me for a long time. Ship of Theseus has got a very interesting problem of identity and change. The idea that a human changes through a period of time bring us to the question of identity. We also face the question of responsibility in a constantly shifting, changing scenario. The film is a series of interesting problems,\" \nNowtoronto.com in its review observed that, \"the film measures Mumbai's changing identity, where the modern equivalent of reincarnation could be a kidney transplant.\"\n\nThe monk faced with the dilemma of depending on the very people he is fighting against as a result of his diagnosis, is forced to choose between dying and compromising on his beliefs. His battle with the disease and the notions of those around him makes it an all the more difficult task to stick to his ideals.\n\nThe stockbroker’s pursuit of the stolen kidney’s recipient results in his questioning the morality of such a situation. The film also explores the intricacy of morality. It is the moral dilemmas of all three protagonists that tie the seemingly disparate parts of the film together.\n\nThe story of the film depicts changes in lives of people who received organ transplants. The film depicts cornea, liver and kidney transplants.\n\nThe title of the film, 'Ship of Theseus’ alludes to the highly debated Theseus’ paradox (also referred to as the Theseus’ Ship). The paradox engages in the idea of identity: \"If parts of an object are replaced with similar parts, does it remain the same?\" The film also refers to ethical issues brought out by applying the Theseus paradox to human beings, \"All the cells in a person’s body regenerate entirely in seven years. An individual goes through a shift psychologically, ideologically and physically. Is it still the same person?\"\n\nThe young lawyer’s name, Charvaka, is a reference to the ancient Indian atheist Cārvāka, said to have founded the first atheist system of Indian philosophy that assumes various forms of philosophical skepticism and religious indifference. His resulting dialogue with the monk takes on a similar stance.\n\nThe film also pays homage to the Church of the Flying Spaghetti Monster, the satirical religion started in reaction to the introduction of teaching creationism in schools. The T-shirt donned by the character Charvaka in a scene with the monk reads \"Pastafarian\", an allusion to the followers of the Church of the Flying Spaghetti Monster.\n\nDuring the photographer’s interview she mentions Patrick Süskind’s novel, \"Perfume\" and likens her intent with art as being similar to the protagonist from the book \"in the quest to capture the essence of everything\".\n\nAn early trailer of the film played a scene deleted from the final cut, which had the character Vinay (Faraz Khan) read out a quote from Jean Baudrillard’s Simulacra and Simulation. \"Photographic light is not realistic or natural, it is not artificial either...\" In the same scene, Aliya, the photographer, also refers to the sphere in a plane-land thought experiment.\n\nThe character of Maitreya draws inspiration from thinkers, philosophers and activists such as 19th-century Jain philosopher Shrimad Rajchandra, who was a spiritual guide of Mohandas Gandhi, activist Satish Kumar, environmentalist Abhay Mehta and Peter Singer. In one of the scenes, the character Dr. Bhargava presents Maitreya with a copy of the Resurgence (\"Resurgence & Ecologist\") magazine that is published and edited by Satish Kumar, known as the man who \"walked the planet\".\n\nAnand Gandhi on the genesis of his film, \"The three short stories evolved to fill in the three corners of the classical Indian trinity of Satyam-Shivam-Sunderam (The pursuit of truth, the pursuit of righteousness and the pursuit of beauty).\"\n\nThe TV in the stock broker's hospital ward shows an elderly man cycling through water. It is a reference to an inventor from Bihar who modified a bicycle to turn it amphibious at the flip of a switch. The fictitious new channel is a nod to the National Innovation Foundation, an autonomous institution that supports grassroots innovations.\n\nThe voice over mechanism that the photographer’s camera has installed as a sight-aid, is an in–film invention by Anand Gandhi. There currently is no such assistance available for the visually impaired.\n\nThe monk’s chant was written in Prakrit, specifically for the film, in order to lend credibility to the fictitious religion that he follows, inspired from Jainism and Buddhism.\n\n"}
{"id": "726659", "url": "https://en.wikipedia.org/wiki?curid=726659", "title": "Superintelligence", "text": "Superintelligence\n\nA superintelligence is a hypothetical agent that possesses intelligence far surpassing that of the brightest and most gifted human minds. \"Superintelligence\" may also refer to a property of problem-solving systems (e.g., superintelligent language translators or engineering assistants) whether or not these high-level intellectual competencies are embodied in agents that act in the world. A superintelligence may or may not be created by an intelligence explosion and associated with a technological singularity.\n\nUniversity of Oxford philosopher Nick Bostrom defines \"superintelligence\" as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest\". The program Fritz falls short of superintelligence even though it is much better than humans at chess because Fritz cannot outperform humans in other tasks. Following Hutter and Legg, Bostrom treats superintelligence as general dominance at goal-oriented behavior, leaving open whether an artificial or human superintelligence would possess capacities such as intentionality (cf. the Chinese room argument) or first-person consciousness (cf. the hard problem of consciousness).\n\nTechnological researchers disagree about how likely present-day human intelligence is to be surpassed. Some argue that advances in artificial intelligence (AI) will probably result in general reasoning systems that lack human cognitive limitations. Others believe that humans will evolve or directly modify their biology so as to achieve radically greater intelligence. A number of futures studies scenarios combine elements from both of these possibilities, suggesting that humans are likely to interface with computers, or upload their minds to computers, in a way that enables substantial intelligence amplification.\n\nSome researchers believe that superintelligence will likely follow shortly after the development of artificial general intelligence. The first generally intelligent machines are likely to immediately hold an enormous advantage in at least some forms of mental capability, including the capacity of perfect recall, a vastly superior knowledge base, and the ability to multitask in ways not possible to biological entities. This may give them the opportunity to—either as a single being or as a new species—become much more powerful than humans, and to displace them.\n\nA number of scientists and forecasters argue for prioritizing early research into the possible benefits and risks of human and machine cognitive enhancement, because of the potential social impact of such technologies.\n\nPhilosopher David Chalmers argues that artificial general intelligence is a very likely path to superhuman intelligence. Chalmers breaks this claim down into an argument that AI can achieve \"equivalence\" to human intelligence, that it can be \"extended\" to surpass human intelligence, and that it can be further \"amplified\" to completely dominate humans across arbitrary tasks.\n\nConcerning human-level equivalence, Chalmers argues that the human brain is a mechanical system, and therefore ought to be emulatable by synthetic materials. He also notes that human intelligence was able to biologically evolve, making it more likely that human engineers will be able to recapitulate this invention. Evolutionary algorithms in particular should be able to produce human-level AI. Concerning intelligence extension and amplification, Chalmers argues that new AI technologies can generally be improved on, and that this is particularly likely when the invention can assist in designing new technologies.\n\nIf research into strong AI produced sufficiently intelligent software, it would be able to reprogram and improve itself – a feature called \"recursive self-improvement\". It would then be even better at improving itself, and could continue doing so in a rapidly increasing cycle, leading to a superintelligence. This scenario is known as an intelligence explosion. Such an intelligence would not have the limitations of human intellect, and may be able to invent or discover almost anything.\n\nComputer components already greatly surpass human performance in speed. Bostrom writes, \"Biological neurons operate at a peak speed of about 200 Hz, a full seven orders of magnitude slower than a modern microprocessor (~2 GHz).\" Moreover, neurons transmit spike signals across axons at no greater than 120 m/s, \"whereas existing electronic processing cores can communicate optically at the speed of light\". Thus, the simplest example of a superintelligence may be an emulated human mind that's run on much faster hardware than the brain. A human-like reasoner that could think millions of times faster than current humans would have a dominant advantage in most reasoning tasks, particularly ones that require haste or long strings of actions.\n\nAnother advantage of computers is modularity, that is, their size or computational capacity can be increased. A non-human (or modified human) brain could become much larger than a present-day human brain, like many supercomputers. Bostrom also raises the possibility of \"collective superintelligence\": a large enough number of separate reasoning systems, if they communicated and coordinated well enough, could act in aggregate with far greater capabilities than any sub-agent.\n\nThere may also be ways to \"qualitatively\" improve on human reasoning and decision-making. Humans appear to differ from chimpanzees in the ways we think more than we differ in brain size or speed. Humans outperform non-human animals in large part because of new or enhanced reasoning capacities, such as long-term planning and language use. (See evolution of human intelligence and primate cognition.) If there are other possible improvements to reasoning that would have a similarly large impact, this makes it likelier that an agent can be built that outperforms humans in the same fashion humans outperform chimpanzees.\n\nAll of the above advantages hold for artificial superintelligence, but it is not clear how many hold for biological superintelligence. Physiological constraints limit the speed and size of biological brains in many ways that are inapplicable to machine intelligence. As such, writers on superintelligence have devoted much more attention to superintelligent AI scenarios.\n\nCarl Sagan suggested that the advent of Caesarean sections and \"in vitro\" fertilization may permit humans to evolve larger heads, resulting in improvements via natural selection in the heritable component of human intelligence. By contrast, Gerald Crabtree has argued that decreased selection pressure is resulting in a slow, centuries-long reduction in human intelligence, and that this process instead is likely to continue into the future. There is no scientific consensus concerning either possibility, and in both cases the biological change would be slow, especially relative to rates of cultural change.\n\nSelective breeding, nootropics, NSI-189, MAO-I's, epigenetic modulation, and genetic engineering could improve human intelligence more rapidly. Bostrom writes that if we come to understand the genetic component of intelligence, pre-implantation genetic diagnosis could be used to select for embryos with as much as 4 points of IQ gain (if one embryo is selected out of two), or with larger gains (e.g., up to 24.3 IQ points gained if one embryo is selected out of 1000). If this process is iterated over many generations, the gains could be an order of magnitude greater. Bostrom suggests that deriving new gametes from embryonic stem cells could be used to iterate the selection process very rapidly. A well-organized society of high-intelligence humans of this sort could potentially achieve collective superintelligence.\n\nAlternatively, collective intelligence might be constructible by better organizing humans at present levels of individual intelligence. A number of writers have suggested that human civilization, or some aspect of it (e.g., the Internet, or the economy), is coming to function like a global brain with capacities far exceeding its component agents. If this systems-based superintelligence relies heavily on artificial components, however, it may qualify as an AI rather than as a biology-based superorganism.\n\nA final method of intelligence amplification would be to directly enhance individual humans, as opposed to enhancing their social or reproductive dynamics. This could be achieved using nootropics, somatic gene therapy, or brain–computer interfaces. However, Bostrom expresses skepticism about the scalability of the first two approaches, and argues that designing a superintelligent cyborg interface is an AI-complete problem.\n\nMost surveyed AI researchers expect machines to eventually be able to rival humans in intelligence, though there is little consensus on when this will likely happen. At the 2006 AI@50 conference, 18% of attendees reported expecting machines to be able \"to simulate learning and every other aspect of human intelligence\" by 2056; 41% of attendees expected this to happen sometime after 2056; and 41% expected machines to never reach that milestone. \n\nIn a survey of the 100 most cited authors in AI (as of May 2013, according to Microsoft academic search), the median year by which respondents expected machines \"that can carry out most human professions at least as well as a typical human\" (assuming no global catastrophe occurs) with 10% confidence is 2024 (mean 2034, st. dev. 33 years), with 50% confidence is 2050 (mean 2072, st. dev. 110 years), and with 90% confidence is 2070 (mean 2168, st. dev. 342 years). These estimates exclude the 1.2% of respondents who said no year would ever reach 10% confidence, the 4.1% who said 'never' for 50% confidence, and the 16.5% who said 'never' for 90% confidence. Respondents assigned a median 50% probability to the possibility that machine superintelligence will be invented within 30 years of the invention of approximately human-level machine intelligence.\n\nBostrom expressed concern about what values a superintelligence should be designed to have. He compared several proposals:\nResponding to Bostrom, Santos-Lang raised concern that developers may attempt to start with a single kind of superintelligence.\n\nLearning computers that rapidly become superintelligent may take unforeseen actions or robots might out-compete humanity (one potential technological singularity scenario). Researchers have argued that, by way of an \"intelligence explosion\" sometime over the next century, a self-improving AI could become so powerful as to be unstoppable by humans.\n\nConcerning human extinction scenarios, identifies superintelligence as a possible cause:\nIn theory, since a superintelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its goals, many uncontrolled, unintended consequences could arise. It could kill off all other agents, persuade them to change their behavior, or block their attempts at interference.\n\nEliezer Yudkowsky explains: \"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\"\n\nThis presents the AI control problem: how to build a superintelligent agent that will aid its creators, while avoiding inadvertently building a superintelligence that will harm its creators. The danger of not designing control right \"the first time\", is that a misprogrammed superintelligence might rationally decide to \"take over the world\" and refuse to permit its programmers to modify it once it has been activated. Potential design strategies include \"capability control\" (preventing an AI from being able to pursue harmful plans), and \"motivational control\" (building an AI that wants to be helpful).\n\nBill Hibbard advocates for public education about superintelligence and public control over the development of superintelligence.\n\n\n\n"}
{"id": "30292887", "url": "https://en.wikipedia.org/wiki?curid=30292887", "title": "SyNAPSE", "text": "SyNAPSE\n\nSyNAPSE is a DARPA program that aims to develop electronic neuromorphic machine technology, an attempt to build a new kind of cognitive computer with form, function, and architecture similar to the mammalian brain. Such artificial brains would be used in robots whose intelligence would scale with the size of the neural system in terms of total number of neurons and synapses and their connectivity.\n\nSyNAPSE is a backronym standing for \"Systems of Neuromorphic Adaptive Plastic Scalable Electronics\". The name alludes to synapses, the junctions between biological neurons. The program is being undertaken by HRL Laboratories (HRL), Hewlett-Packard, and IBM Research. In November 2008, IBM and its collaborators were awarded $4.9 million in funding from DARPA while HRL and its collaborators were awarded $5.9 million in funding from DARPA. For the next phase of the project, DARPA added $16.1 million more to the IBM effort while HRL received an additional $10.7 million. In 2011, DARPA added $21 million more to the IBM project. and an additional $17.9 million to the HRL project. The SyNAPSE team for IBM is led by Dharmendra Modha, manager of IBM's cognitive computing initiative. The SyNAPSE team for HRL is led by Narayan Srinivasa, manager of HRL's Center for Neural and Emergent Systems.\n\nThe initial phase of the SyNAPSE program developed nanometer scale electronic synaptic components capable of adapting the connection strength between two neurons in a manner analogous to that seen in biological systems (Hebbian learning), and simulated the utility of these synaptic components in core microcircuits that support the overall system architecture.\n\nContinuing efforts will focus on hardware development through the stages of microcircuit development, fabrication process development, single chip system development, and multi-chip system development. In support of these hardware developments, the program seeks to develop increasingly capable architecture and design tools, very large-scale computer simulations of the neuromorphic electronic systems to inform the designers and validate the hardware prior to fabrication, and virtual environments for training and testing the simulated and hardware neuromorphic systems.\n\n\nThe following people and institutions are participating in the DARPA SyNAPSE program:\n\nIBM team\n\nHRL Team\n\n\n"}
{"id": "30384", "url": "https://en.wikipedia.org/wiki?curid=30384", "title": "The Evolution of Cooperation", "text": "The Evolution of Cooperation\n\nThe evolution of cooperation can refer to:\n\n\nThe idea that human behavior can be usefully analyzed mathematically gained great credibility following the application of operations research in World War II to improve military operations. One famous example involved how the Royal Air Force hunted submarines in the Bay of Biscay.\nIt had seemed to make sense to patrol the areas where submarines were most frequently seen. Then it was pointed out that \"seeing the most submarines\" depended not only on the number of submarines present, but also on the number of eyes looking; i.e., patrol density. Making an allowance for patrol density showed that patrols were more \"efficient\" – that is, found more submarines per patrol – in other areas. Making appropriate adjustments increased the overall effectiveness.\n\nAccounts of the success of operations research during the war, publication in 1944 of John von Neumann and Oskar Morgenstern's \"Theory of Games and Economic Behavior\" on the use of game theory for developing and analyzing optimal strategies for military and other uses, and publication of John William's \"The Compleat Strategyst\", a popular exposition of game theory, led to a greater appreciation of mathematical analysis of human behavior.\n\nBut game theory had a little crisis: it could not find a strategy for a simple game called \"The Prisoner's Dilemma\" (PD) where two players have the option to cooperate for mutual gain, but each also takes a risk of being suckered.\n\nThe prisoner's dilemma game (invented around 1950 by Merrill M. Flood and Melvin Dresher) takes its name from the following scenario: you and a criminal associate have been busted. Fortunately for you, most of the evidence was shredded, so you are facing only a year in prison. But the prosecutor wants to nail someone, so he offers you a deal: if you squeal on your associate – which will result in his getting a five-year stretch – the prosecutor will see that six months is taken off of your sentence. Which sounds good, until you learn your associate is being offered the same deal – which would get \"you\" five years.\n\nSo what do you do? The best that you and your associate can do together is to not squeal: that is, to cooperate (with each other, not the prosecutor!) in a mutual bond of silence, and do your year. But wait: if your associate cooperates (that sucker!), can you do better by squealing (\"defecting\") to get that six month reduction? It's tempting, but then he's also tempted. And if you both squeal, oh, no, it's four and half years each. So perhaps you should cooperate – but wait, that's being a sucker yourself, as your associate will undoubtedly defect, and you won't even get the six months off. So what is the best strategy to minimize your incarceration (aside from going straight in the first place)?\n\nTo cooperate, or not cooperate? This simple question (and the implicit question of whether to trust, or not), expressed in an extremely simple game, is a crucial issue across a broad range of life. Why shouldn't a shark eat the little fish that has just cleaned it of parasites: in any given exchange who would know? Fig wasps collectively limit the eggs they lay in fig trees (otherwise, the trees would suffer). But why shouldn't any one fig wasp cheat and leave a few more eggs than her rivals? At the level of human society, why shouldn't each of the villagers that share a common but finite resource try to exploit it more than the others? At the core of these and myriad other examples is a conflict formally equivalent to the Prisoner's Dilemma. Yet sharks, fig wasps, and villagers all cooperate. It has been a vexatious problem in evolutionary studies to explain how such cooperation should evolve, let alone persist, in a world of self-maximizing egoists.\n\nCharles Darwin's theory of how evolution works (\"By Means of Natural Selection\") is explicitly competitive (\"survival of the fittest\"), Malthusian (\"struggle for existence\"), even gladiatorial (\"nature, red in tooth and claw\"). Species are pitted against species for shared resources,\nsimilar species with similar needs and niches even more so, and individuals within species most of all. All this comes down to one factor: out-competing all rivals and predators in producing progeny.\n\nDarwin's explanation of how preferential survival of the slightest benefits can lead to advanced forms is the most important explanatory principle in biology, and extremely powerful in many other fields. Such success has reinforced notions that life is in all respects a war of each against all, where every \"individual\" has to look out for himself, that your gain is my loss.\n\nIn such a struggle for existence altruism (voluntarily yielding a benefit to a non-relative) and even cooperation (working with another for a mutual benefit) seem so antithetical to self-interest as to be the very kind of behavior that should be selected against. Yet cooperation and seemingly even altruism have evolved and persist, including even interspecific cooperation and naturalists have been hard pressed to explain why.\n\nThe popularity of the evolution of cooperation – the reason it is not an obscure technical issue of interest to only a small number of specialists – is in part because it mirrors a larger issue where the realms of political philosophy, ethics, and biology intersect: the ancient issue of individual interests versus group interests. On one hand, the so-called \"Social Darwinians\" (roughly, those who would use the \"survival of the fittest\" of Darwinian evolution to justify the cutthroat competitiveness of laissez-faire capitalism)\ndeclaim that the world is an inherently competitive \"dog eat dog\" jungle, where every \"individual\" has to look out for himself. The writer Ayn Rand damned \"altruism\" and declared selfishness a virtue.\nThe Social Darwinists' view is derived from Charles Darwin's interpretation of evolution by natural selection, which is explicitly competitive (\"survival of the fittest\"), Malthusian (\"struggle for existence\"), even gladiatorial (\"red in tooth and claw\"), and permeated by the Victorian laissez-faire ethos of Darwin and his disciples (such as T. H. Huxley and Herbert Spencer). What they read into the theory was then read out by Social Darwinians as scientific justification for their social and economic views (such as poverty being a natural condition and social reform an unnatural meddling).\n\nSuch views of evolution, competition, and the survival of the fittest are explicit in the ethos of modern capitalism, as epitomized by industrialist Andrew Carnegie in \"The Gospel of Wealth\":\n\n[W]hile the law [of competition] may be sometimes hard for the individual, it is best for the race, because it ensures the survival of the fittest in every department. We accept and welcome, therefore, as conditions to which we must accommodate ourselves, great inequality of environment; the concentration of business, industrial and commercial, in the hands of the few; and the law of competition between these, as being not only beneficial, but essential to the future progress of the race.\n\nWhile the validity of extrapolating moral and political views from science is questionable, the significance of such views in modern society is undoubtable.\n\nOn the other hand, other philosophers have long observed that cooperation in the form of a \"social contract\" is necessary for human society, but saw no way of attaining that short of a coercive authority.\n\nAs Thomas Hobbes wrote in \"Leviathan\":\n\n[T]here must be some coercive power to compel men equally to the performance of their covenants by the terror of some punishment greater than the benefit they expect by the breach of their covenant... \nAnd Jean Jacques Rousseau in \"The Social Contract\":\n[The social contract] can arise only where several persons come together: but, as the force and liberty of each man are the chief instruments of his self-preservation, how can he pledge them without harming his own interests, and neglecting the care he owes himself? \nEven Herman Melville, in \"Moby-Dick\", has the cannibal harpooner Queequeg explain why he has saved the life of someone who had been jeering him as so:\n\"It's a mutual, joint-stock world, in all meridians. We cannibals must help these Christians.\" \nThe original role of government is to provide the coercive power to enforce the social contract (and in commercial societies, contracts and covenants generally). Where government does not exist or cannot reach it is often deemed the role of religion to promote prosocial and moral behavior, but this tends to depend on threats of hell-fire (what Hobbes called \"the terror of some power\"); such inducements seem more mystical than rational, and philosophers have been hard-pressed to explain why self-interest should yield to morality, why there should be any duty to be \"good\".\n\nYet cooperation, and even altruism and morality, are prevalent, even in the absence of coercion, even though it seems that a properly self-regarding individual should reject all such social strictures and limitations. As early as 1890 the Russian naturalist Petr Kropotkin observed that the species that survived were where the individuals cooperated, that \"mutual aid\" (cooperation) was found at all levels of existence. By the 1960s biologists and zoologists were noting many instances in the real \"jungle\" where real animals – presumably unfettered by conscience and not corrupted by altruistic liberals – and even microbes (see microbial cooperation) were cooperating.\n\nDarwin's theory of natural selection is a profoundly powerful explanation of how evolution works; its undoubted success strongly suggests an inherently antagonistic relationship between unrelated individuals. Yet cooperation is prevalent, seems beneficial, and even seems to be essential to human society. Explaining this seeming contradiction, and accommodating cooperation, and even altruism, within Darwinian theory is a central issue in the theory of cooperation.\n\nDarwin's explanation of how evolution works is quite simple, but the implications of how it might explain complex phenomena are not at all obvious; it has taken over a century to elaborate (see modern synthesis). Explaining how altruism – which by definition reduces personal fitness – can arise by natural selection is a particular problem, and the central theoretical problem of sociobiology.\n\nA possible explanation of altruism is provided by the theory of group selection (first suggested by Darwin himself while grappling with issue of social insects) which argues that natural selection can act on groups: groups that are more successful – for any reason, including learned behaviors – will benefit the individuals of the group, even if they are not related. It has had a powerful appeal, but has not been fully persuasive, in part because of difficulties regarding cheaters that participate in the group without contributing.\n\nAnother explanation is provided by the genetic kinship theory of William D. Hamilton: if a gene causes an individual to help other individuals that carry copies of that gene, then the \"gene\" has a net benefit even with the sacrifice of a few individuals. The classic example is the social insects, where the workers – which are sterile, and therefore incapable of passing on their genes – benefit the queen, who is essentially passing on copies of \"their\" genes. This is further elaborated in the \"selfish gene\" theory of Richard Dawkins, that the unit of evolution is not the individual organism, but the gene. (As stated by Wilson: \"the organism is only DNA's way of making more DNA.\") However, kinship selection works only where the individuals involved are closely related; it fails to explain the presence of altruism and cooperation between unrelated individuals, particularly across species.\n\nIn a 1971 paper Robert Trivers demonstrated how reciprocal altruism can evolve between unrelated individuals, even between individuals of entirely different species. And the relationship of the individuals involved is exactly analogous to the situation in a certain form of the Prisoner's Dilemma. The key is that in the \"iterated\" Prisoner's Dilemma, or IPD, both parties can benefit from the exchange of many seemingly altruistic acts. As Trivers says, it \"take[s] the altruism out of altruism.\" The Randian premise that self-interest is paramount is largely unchallenged, but turned on its head by recognition of a broader, more profound view of what constitutes self-interest.\n\nIt does not matter why the individuals cooperate. The individuals may be prompted to the exchange of \"altruistic\" acts by entirely different genes, or no genes in particular, but both individuals (and their genomes) can benefit simply on the basis of a shared exchange. In particular, \"the benefits of human altruism are to be seen as coming directly from reciprocity – not indirectly through non-altruistic group benefits\".\n\nTrivers' theory is very powerful. Not only can it replace group selection, it also predicts various observed behavior, including moralistic aggression, gratitude and sympathy, guilt and reparative altruism, and development of abilities to detect and discriminate against subtle cheaters.\n\nThe benefits of such reciprocal altruism was dramatically demonstrated by a pair of tournaments held by Robert Axelrod around 1980.\n\nAxelrod initially solicited strategies from other game theorists to compete in the first tournament. Each strategy was paired with each other strategy for 200 iterations of a Prisoner's Dilemma game, and scored on the total points accumulated through the tournament. The winner was a very simple strategy submitted by Anatol Rapoport called \"TIT FOR TAT\" (TFT) that cooperates on the first move, and subsequently echoes (reciprocates) what the other player did on the previous move. The results of the first tournament were analyzed and published, and a second tournament held to see if anyone could find a better strategy. TIT FOR TAT won again. Axelrod analyzed the results, and made some interesting discoveries about the nature of cooperation, which he describes in his book\n\nIn both actual tournaments and various replays the best performing strategies were nice: that is, they were never the first to defect. Many of the competitors went to great lengths to gain an advantage over the \"nice\" (and usually simpler) strategies, but to no avail: tricky strategies fighting for a few points generally could not do as well as nice strategies working together. TFT (and other \"nice\" strategies generally) \"won, not by doing better than the other player, but by eliciting cooperation [and] by promoting the mutual interest rather than by exploiting the other's weakness.\"\n\nBeing \"nice\" can be beneficial, but it can also lead to being suckered. To obtain the benefit – or avoid exploitation – it is necessary to be provocable to both retaliation and forgiveness. When the other player defects, a nice strategy must immediately be provoked into retaliatory defection. The same goes for forgiveness: return to cooperation as soon as the other player does. Overdoing the punishment risks escalation, and can lead to an \"unending echo of alternating defections\" that depresses the scores of both players.\n\nMost of the games that game theory had heretofore investigated are \"zero-sum\" – that is, the total rewards are fixed, and a player does well only at the expense of other players. But real life is not zero-sum. Our best prospects are usually in cooperative efforts. In fact, TFT \"cannot\" score higher than its partner; at best it can only do \"as good as\". Yet it won the tournaments by consistently scoring a strong second-place with a variety of partners. Axelrod summarizes this as don't be envious; in other words, don't strive for a payoff \"greater\" than the other player's.\n\nIn any IPD game there is a certain maximum score each player can get by always cooperating. But some strategies try to find ways of getting a little more with an occasional defection (exploitation). This can work against some strategies that are less provocable or more forgiving than TIT FOR TAT, but generally they do poorly. \"A common problem with these rules is that they used complex methods of making inferences about the other player [strategy] – and these inferences were wrong.\" Against TFT one can do no better than to simply cooperate. Axelrod calls this clarity. Or: don't be too clever.\n\nThe success of any strategy depends on the nature of the particular strategies it encounters, which depends on the composition of the overall population. To better model the effects of reproductive success Axelrod also did an \"ecological\" tournament, where the prevalence of each type of strategy in each round was determined by that strategy's success in the previous round. The competition in each round becomes stronger as weaker performers are reduced and eliminated. The results were amazing: a handful of strategies – all \"nice\" – came to dominate the field. In a sea of non-nice strategies the \"nice\" strategies – provided they were also provokable – did well enough with each other to offset the occasional exploitation.\nAs cooperation became general the non-provocable strategies were exploited and eventually eliminated, whereupon the exploitive (non-cooperating) strategies were out-performed by the cooperative strategies.\n\nIn summary, success in an evolutionary \"game\" correlated with the following characteristics:\n\n\nThe lessons described above apply in environments that support cooperation, but whether cooperation is supported at all depends crucially on the probability (called ω [omega]) that the players will meet again, also called the discount parameter or, poetically, the shadow of the future. When ω is low – that is, the players have a negligible chance of meeting again – each interaction is effectively a single-shot Prisoner's Dilemma game, and one might as well defect in all cases (a strategy called \"ALL D\"), because even if one cooperates there is no way to keep the other player from exploiting that. But in the iterated PD the value of repeated cooperative interactions can become greater than the benefit/risk of a single exploitation (which is all that a strategy like TFT will tolerate).\n\nCuriously, rationality and deliberate choice are not necessary, nor trust nor even consciousness, as long as there is a pattern that benefits both players (e.g., increases fitness), and some probability of future interaction. Often the initial mutual cooperation is not even intentional, but having \"discovered\" a beneficial pattern both parties respond to it by continuing the conditions that maintain it.\n\nThis implies two requirements for the players, aside from whatever strategy they may adopt. First, they must be able to recognize other players, to avoid exploitation by cheaters. Second, they must be able to track their previous history with any given player, in order to be responsive to that player's strategy.\n\nEven when the discount parameter ω is high enough to permit reciprocal cooperation there is still a question of whether and how cooperation might start. One of Axelrod's findings is that when the existing population never offers cooperation nor reciprocates it – the case of ALL D – then no nice strategy can get established by isolated individuals; cooperation is strictly a sucker bet. (The \"futility of isolated revolt\".) But another finding of great significance is that clusters of nice strategies can get established. Even a small group of individuals with nice strategies with infrequent interactions can yet do so well on those interactions to make up for the low level of exploitation from non-nice strategies.\nCooperation becomes more complicated, however, as soon as more realistic models are assumed\nthat for instance offer more than two choices of action, \nprovide the possibility of gradual cooperation, \nmake actions constrain future actions (path dependence),\nor in which \ninterpreting the associate's actions is non-trivial (e.g. recognizing the degree \nof cooperation shown)\n\nIn 1984 Axelrod estimated that there were \"hundreds of articles on the Prisoner's Dilemma cited in \"Psychological Abstracts\"\", and estimated that citations to \"The Evolution of Cooperation\" alone were \"growing at the rate of over 300 per year\".\nTo fully review this literature is infeasible. What follows are therefore only a few selected highlights.\n\nAxelrod has a subsequent book, \"The Complexity of Cooperation\",\nwhich he considers a sequel to \"The Evolution of Cooperation\". Other work on the evolution of cooperation has expanded to cover prosocial behavior generally,\nand in religion,\n\nother mechanisms for generating cooperation,\nthe IPD under different conditions and assumptions,\nand the use of other games such as the Public Goods and Ultimatum games to explore deep-seated notions of fairness and fair play.\nIt has also been used to challenge the rational and self-regarding \"economic man\" model of economics,\nand as a basis for replacing Darwinian sexual selection theory with a theory of social selection.\n\nNice strategies are better able to invade if they have social structures or other means of increasing their interactions. Axelrod discusses this in chapter 8; in a later paper he and Rick Riolo and Michael Cohen use computer simulations to show cooperation rising among agents who have negligible chance of future encounters but can recognize similarity of an arbitrary characteristic (such as a green beard). Whereas other studies have shown that the only Iterated Prisoner's Dilemma strategies that resist invasion in a well-mixed evolving population are generous strategies.\n\nWhen an IPD tournament introduces noise (errors or misunderstandings) TFT strategies can get trapped into a long string of retaliatory defections, thereby depressing their score. TFT also tolerates \"ALL C\" (always cooperate) strategies, which then give an opening to exploiters.\nIn 1992 Martin Nowak and Karl Sigmund demonstrated a strategy called Pavlov (or \"win–stay, lose–shift\") that does better in these circumstances.\nPavlov looks at its own prior move as well as the other player's move. If the payoff was R or P (see \"Prisoner's Dilemma\", above) it cooperates; if S or T it defects.\n\nIn a 2006 paper Nowak listed five mechanisms by which natural selection can lead to cooperation.\nIn addition to kin selection and direct reciprocity, he shows that:\n\n\nThe payoffs in the Prisoner's Dilemma game are fixed, but in real life defectors are often punished by cooperators. Where punishment is costly there is a second-order dilemma amongst cooperators between those who pay the cost of enforcement and those who do not.\nOther work has shown that while individuals given a choice between joining a group that punishes free-riders and one that does not initially prefer the sanction-free group, yet after several rounds they will join the sanctioning group, seeing that sanctions secure a better payoff.\n\nIn small populations or groups there is the possibility that indirect reciprocity (reputation) can interact with direct reciprocity (e.g. tit for tat) with neither strategy dominating the other. The interactions between these strategies can give rise to dynamic social networks which exhibit some of the properties observed in empirical networks If network structure and choices in the Prisoner's dilemma co-evolve, then cooperation can survive. In the resulting networks cooperators will be more centrally located than defectors who will tend to be in the periphery of the network.\n\nAnd there is the very intriguing paper \"The Coevolution of Parochial Altruism and War\" by Jung-Kyoo Choi and Samuel Bowles. From their summary:\n\nAltruism—benefiting fellow group members at a cost to oneself —and parochialism—hostility towards individuals not of one's own ethnic, racial, or other group—are common human behaviors. The intersection of the two—which we term \"parochial altruism\"—is puzzling from an evolutionary perspective because altruistic or parochial behavior reduces one's payoffs by comparison to what one would gain from eschewing these behaviors. But parochial altruism could have evolved if parochialism promoted intergroup hostilities and the combination of altruism and parochialism contributed to success in these conflicts... [Neither] would have been viable singly, but by promoting group conflict they could have evolved jointly.\nThey do not claim that humans have actually evolved in this way, but that computer simulations show how war could be promoted by the interaction of these behaviors. A crucial open research question, thus, is how realistic the assumptions are which these simulation models are based on.\n\nWhen Richard Dawkins set out to \"examine the biology of selfishness and altruism\" in \"The Selfish Gene\", he reinterpreted the basis of evolution, and therefore of altruism. He was \"not advocating a morality based on evolution\", and even felt that \"we \"must\" teach our children altruism, for we cannot expect it to be part of their biological nature.\" But John Maynard Smith was showing that behavior could be subject to evolution, Robert Trivers had shown that reciprocal altruism is strongly favored by natural selection to lead to complex systems of altruistic behavior (supporting Kropotkin's argument that cooperation is as much a factor of evolution as competition), and Axelrod's dramatic results showed that in a very simple game the conditions for survival (be \"nice\", be provocable, promote the mutual interest) seem to be the essence of morality. While this does not yet amount to a science of morality, the game theoretic approach has clarified the conditions required for the evolution and persistence of cooperation, and shown how Darwinian natural selection can lead to complex behavior, including notions of morality, fairness, and justice. It is shown that the nature of self-interest is more profound than previously considered, and that behavior that seems altruistic may, in a broader view, be individually beneficial. Extensions of this work to morality and the social contract may yet resolve the old issue of individual interests versus group interests.\n\nSeveral software packages have been created to run prisoner's dilemma simulations and tournaments, some of which have available source code.\n\n\n\n\n\n"}
{"id": "26766870", "url": "https://en.wikipedia.org/wiki?curid=26766870", "title": "Torture trade", "text": "Torture trade\n\nIn 2001, Amnesty International released the report \"Stopping the Torture Trade.\" The term torture trade refers to the manufacture, marketing, and export of tools commonly used for torture, like restraints and high-voltage electro-shock weapons.\n\nHigh-voltage electro-shock weapons were first developed in the US in the 1990s. They include electro-shock batons, stun guns, stun shields, dart-firing stun guns, and stun belts. From 1997 to 2000, US companies earned over $13 million exporting stun guns, electro-shock batons and optical sighting devices to Eastern Europe and the Middle East. More than 150 companies worldwide are involved in the manufacturing or marketing of torture devices, almost half of which are in the US.\n\nThe biggest electro-shock manufacturers are located in the US, mainland China, Taiwan and South Korea. Companies that produce electro-shock weapons, restraints and sprays say their products are nonlethal if used by security officials with proper training. Nonetheless, Amnesty International has documented cases of companies selling stun belts to countries who Amnesty International suspects of committing human rights abuses, like China and Saudi Arabia, without providing training.\n\nThe following table includes some of the countries identified by Amnesty International from 1998-2000 as engaged in the manufacture, distribution, supply, or brokerage of stun weapons and restraints.\n\nOne type of electro-shock weapon is the remote-controlled stun belt. Stun belts send 50,000 volt shocks through the victim using electrodes placed near the kidneys. The shock causes incapacitation and severe pain.\n\nElecto-shock weapons are one of the most common tools of torture. Electro-shock weapons are appealing because they leave no mark, although the physical and psychological effects are crippling. Shocks are often applied to sensitive areas like the soles of feet or genitals. Effects include severe pain, loss of muscle control, nausea, convulsions, fainting, and involuntary defecation and urination. Internationally, electro-shock torture is used on children, pregnant women, and other vulnerable populations.\n\nAmnesty International has asked companies worldwide to stop the manufacture, marketing, and trade of electro-shock and restraint devices; governments to ban the trade of torture devices; and individuals to write local government representatives and companies asking them to take these steps. The Amnesty International campaign focuses on the trade of restraints, pepper sprays and electroshock weapons.\n\nIn the European Union, Regulation No. 1236/2005, in effect since 2006, prohibits trade in goods which have no practical use other than torture, and requires licences for the export of goods which could have a use in torture as well as other legitimate uses. Critics say the regulation contains too many loopholes to be effective. Commission Implementing Regulation (EU) No 775/2014 lists prohibited and controlled goods. A proposal for amendments to Council Regulation (EC) No 1236/2005 was put forward by the European Commission on 14 January 2014 and approved by the European Parliament on 30 June 2016. The new regulation will ban the brokering of equipment which is subject to a ban and the supply of technical assistance regarding the supply of banned goods.\n\nThe US has also made regulatory changes to limit torture trade. The Department of Commerce created a separate export commodity code for electro-shock devices to make it easier to track them. All companies are now required to have export licenses, although there are still many loopholes. US companies can use drop shipping or paying an intermediary country with loose regulations to export banned goods to the importing country. In 1997, one US company was caught exporting electro-shock guns and pepper spray without a license by mislabeling them as “Fountain pens, Keychains, Child Sound device, [and] Electrical voltage units.”\n"}
{"id": "19167679", "url": "https://en.wikipedia.org/wiki?curid=19167679", "title": "Virus", "text": "Virus\n\nA virus is a small infectious agent that replicates only inside the living cells of other organisms. Viruses can infect all types of life forms, from animals and plants to microorganisms, including bacteria and archaea.\n\nSince Dmitri Ivanovsky's 1892 article describing a non-bacterial pathogen infecting tobacco plants, and the discovery of the tobacco mosaic virus by Martinus Beijerinck in 1898, about 5,000 virus species have been described in detail, although there are millions of types. Viruses are found in almost every ecosystem on Earth and are the most numerous type of biological entity. The study of viruses is known as virology, a sub-speciality of microbiology.\n\nWhile not inside an infected cell or in the process of infecting a cell, viruses exist in the form of independent particles. These viral particles, also known as virions, consist of: (i) the genetic material made from either DNA or RNA, long molecules that carry genetic information; (ii) a protein coat, called the capsid, which surrounds and protects the genetic material; and in some cases (iii) an envelope of lipids that surrounds the protein coat. The shapes of these virus particles range from simple helical and icosahedral forms for some virus species to more complex structures for others. Most virus species have virions that are too small to be seen with an optical microscope. The average virion is about one one-hundredth the size of the average bacterium.\n\nThe origins of viruses in the evolutionary history of life are unclear: some may have evolved from plasmids—pieces of DNA that can move between cells—while others may have evolved from bacteria. In evolution, viruses are an important means of horizontal gene transfer, which increases genetic diversity. Viruses are considered by some to be a life form, because they carry genetic material, reproduce, and evolve through natural selection, but lack key characteristics (such as cell structure) that are generally considered necessary to count as life. Because they possess some but not all such qualities, viruses have been described as \"organisms at the edge of life\", and as replicators.\n\nViruses spread in many ways; viruses in plants are often transmitted from plant to plant by insects that feed on plant sap, such as aphids; viruses in animals can be carried by blood-sucking insects. These disease-bearing organisms are known as vectors. Influenza viruses are spread by coughing and sneezing. Norovirus and rotavirus, common causes of viral gastroenteritis, are transmitted by the faecal–oral route and are passed from person to person by contact, entering the body in food or water. HIV is one of several viruses transmitted through sexual contact and by exposure to infected blood. The variety of host cells that a virus can infect is called its \"host range\". This can be narrow, meaning a virus is capable of infecting few species, or broad, meaning it is capable of infecting many.\n\nViral infections in animals provoke an immune response that usually eliminates the infecting virus. Immune responses can also be produced by vaccines, which confer an artificially acquired immunity to the specific viral infection. Some viruses, including those that cause AIDS and viral hepatitis, evade these immune responses and result in chronic infections. Several antiviral drugs have been developed.\n\nThe word is from the Latin neuter \"vīrus\" referring to poison and other noxious liquids, from 'the same Indo-European base as Sanskrit \"viṣa\" poison, Avestan \"vīša\" poison, ancient Greek \"ἰός\" poison', first attested in English in 1398 in John Trevisa's translation of Bartholomeus Anglicus's \"De Proprietatibus Rerum\". \"Virulent\", from Latin \"virulentus\" (poisonous), dates to c. 1400. A meaning of \"agent that causes infectious disease\" is first recorded in 1728, before the discovery of viruses by Dmitri Ivanovsky in 1892. The English plural is \"viruses\" (sometimes also \"viri\" or \"vira\"), whereas the Latin word is a mass noun, which has no classically attested plural (\"vīra\" is used in Neo-Latin). The adjective \"viral\" dates to 1948. The term \"virion\" (plural \"virions\"), which dates from 1959, is also used to refer to a single, stable infective viral particle that is released from the cell and is fully capable of infecting other cells of the same type.\n\nLouis Pasteur was unable to find a causative agent for rabies and speculated about a pathogen too small to be detected using a microscope. In 1884, the French microbiologist Charles Chamberland invented a filter (known today as the Chamberland filter or the Pasteur-Chamberland filter) with pores smaller than bacteria. Thus, he could pass a solution containing bacteria through the filter and completely remove them. In 1892, the Russian biologist Dmitri Ivanovsky used this filter to study what is now known as the tobacco mosaic virus. His experiments showed that crushed leaf extracts from infected tobacco plants remain infectious after filtration. Ivanovsky suggested the infection might be caused by a toxin produced by bacteria, but did not pursue the idea. At the time it was thought that all infectious agents could be retained by filters and grown on a nutrient medium – this was part of the germ theory of disease. In 1898, the Dutch microbiologist Martinus Beijerinck repeated the experiments and became convinced that the filtered solution contained a new form of infectious agent. He observed that the agent multiplied only in cells that were dividing, but as his experiments did not show that it was made of particles, he called it a \"contagium vivum fluidum\" (soluble living germ) and re-introduced the word \"virus\". Beijerinck maintained that viruses were liquid in nature, a theory later discredited by Wendell Stanley, who proved they were particulate. In the same year Friedrich Loeffler and Paul Frosch passed the first animal virus – agent of foot-and-mouth disease (aphthovirus) – through a similar filter.\n\nIn the early 20th century, the English bacteriologist Frederick Twort discovered a group of viruses that infect bacteria, now called bacteriophages (or commonly \"phages\"), and the French-Canadian microbiologist Félix d'Herelle described viruses that, when added to bacteria on an agar plate, would produce areas of dead bacteria. He accurately diluted a suspension of these viruses and discovered that the highest dilutions (lowest virus concentrations), rather than killing all the bacteria, formed discrete areas of dead organisms. Counting these areas and multiplying by the dilution factor allowed him to calculate the number of viruses in the original suspension. Phages were heralded as a potential treatment for diseases such as typhoid and cholera, but their promise was forgotten with the development of penicillin. The study of phages provided insights into the switching on and off of genes, and a useful mechanism for introducing foreign genes into bacteria.\n\nBy the end of the 19th century, viruses were defined in terms of their infectivity, their ability to be filtered, and their requirement for living hosts. Viruses had been grown only in plants and animals. In 1906, Ross Granville Harrison invented a method for growing tissue in lymph, and, in 1913, E. Steinhardt, C. Israeli, and R. A. Lambert used this method to grow vaccinia virus in fragments of guinea pig corneal tissue. In 1928, H. B. Maitland and M. C. Maitland grew vaccinia virus in suspensions of minced hens' kidneys. Their method was not widely adopted until the 1950s, when poliovirus was grown on a large scale for vaccine production.\n\nAnother breakthrough came in 1931, when the American pathologist Ernest William Goodpasture and Alice Miles Woodruff grew influenza and several other viruses in fertilised chickens' eggs. In 1949, John Franklin Enders, Thomas Weller, and Frederick Robbins grew polio virus in cultured human embryo cells, the first virus to be grown without using solid animal tissue or eggs. This work enabled Jonas Salk to make an effective polio vaccine.\n\nThe first images of viruses were obtained upon the invention of electron microscopy in 1931 by the German engineers Ernst Ruska and Max Knoll. In 1935, American biochemist and virologist Wendell Meredith Stanley examined the tobacco mosaic virus and found it was mostly made of protein. A short time later, this virus was separated into protein and RNA parts.\nThe tobacco mosaic virus was the first to be crystallised and its structure could therefore be elucidated in detail. The first X-ray diffraction pictures of the crystallised virus were obtained by Bernal and Fankuchen in 1941. On the basis of her pictures, Rosalind Franklin discovered the full structure of the virus in 1955. In the same year, Heinz Fraenkel-Conrat and Robley Williams showed that purified tobacco mosaic virus RNA and its protein coat can assemble by themselves to form functional viruses, suggesting that this simple mechanism was probably the means through which viruses were created within their host cells.\n\nThe second half of the 20th century was the golden age of virus discovery and most of the over 2,000 recognised species of animal, plant, and bacterial viruses were discovered during these years. In 1957, equine arterivirus and the cause of Bovine virus diarrhoea (a pestivirus) were discovered. In 1963, the hepatitis B virus was discovered by Baruch Blumberg, and in 1965, Howard Temin described the first retrovirus. Reverse transcriptase, the enzyme that retroviruses use to make DNA copies of their RNA, was first described in 1970, independently by Howard Martin Temin and David Baltimore. In 1983 Luc Montagnier's team at the Pasteur Institute in France, first isolated the retrovirus now called HIV. In 1989 Michael Houghton's team at Chiron Corporation discovered Hepatitis C.\n\nViruses are found wherever there is life and have probably existed since living cells first evolved. The origin of viruses is unclear because they do not form fossils, so molecular techniques have been used to compare the DNA or RNA of viruses and are a useful means of investigating how they arose. In addition, viral genetic material may occasionally integrate into the germline of the host organisms, by which they can be passed on vertically to the offspring of the host for many generations. This provides an invaluable source of information for paleovirologists to trace back ancient viruses that have existed up to millions of years ago. There are three main hypotheses that aim to explain the origins of viruses:\n\n\n\nIn the past, there were problems with all of these hypotheses: the regressive hypothesis did not explain why even the smallest of cellular parasites do not resemble viruses in any way. The escape hypothesis did not explain the complex capsids and other structures on virus particles. The virus-first hypothesis contravened the definition of viruses in that they require host cells. Viruses are now recognised as ancient and as having origins that pre-date the divergence of life into the three domains. This discovery has led modern virologists to reconsider and re-evaluate these three classical hypotheses.\n\nThe evidence for an ancestral world of RNA cells and computer analysis of viral and host DNA sequences are giving a better understanding of the evolutionary relationships between different viruses and may help identify the ancestors of modern viruses. To date, such analyses have not proved which of these hypotheses is correct. It seems unlikely that all currently known viruses have a common ancestor, and viruses have probably arisen numerous times in the past by one or more mechanisms.\n\nPrions are infectious protein molecules that do not contain DNA or RNA. They can cause infections such as scrapie in sheep, bovine spongiform encephalopathy (\"mad cow\" disease) in cattle, and chronic wasting disease in deer; in humans, prionic diseases include Kuru, Creutzfeldt–Jakob disease, and Gerstmann–Sträussler–Scheinker syndrome. Although prions are fundamentally different from viruses and viroids, their discovery gives credence to the theory that viruses could have evolved from self-replicating molecules.\n\nOpinions differ on whether viruses are a form of life, or organic structures that interact with living organisms. They have been described as \"organisms at the edge of life\", since they resemble organisms in that they possess genes, evolve by natural selection, and reproduce by creating multiple copies of themselves through self-assembly. Although they have genes, they do not have a cellular structure, which is often seen as the basic unit of life. Viruses do not have their own metabolism, and require a host cell to make new products. They therefore cannot naturally reproduce outside a host cell – although bacterial species such as rickettsia and chlamydia are considered living organisms despite the same limitation. Accepted forms of life use cell division to reproduce, whereas viruses spontaneously assemble within cells. They differ from autonomous growth of crystals as they inherit genetic mutations while being subject to natural selection. Virus self-assembly within host cells has implications for the study of the origin of life, as it lends further credence to the hypothesis that life could have started as self-assembling organic molecules.\n\nViruses display a wide diversity of shapes and sizes, called \"morphologies\". In general, viruses are much smaller than bacteria. Most viruses that have been studied have a diameter between 20 and 300 nanometres. Some filoviruses have a total length of up to 1400 nm; their diameters are only about 80 nm. Most viruses cannot be seen with an optical microscope so scanning and transmission electron microscopes are used to visualise them. To increase the contrast between viruses and the background, electron-dense \"stains\" are used. These are solutions of salts of heavy metals, such as tungsten, that scatter the electrons from regions covered with the stain. When virions are coated with stain (positive staining), fine detail is obscured. Negative staining overcomes this problem by staining the background only.\n\nA complete virus particle, known as a virion, consists of nucleic acid surrounded by a protective coat of protein called a capsid. These are formed from identical protein subunits called capsomeres. Viruses can have a lipid \"envelope\" derived from the host cell membrane. The capsid is made from proteins encoded by the viral genome and its shape serves as the basis for morphological distinction. Virally coded protein subunits will self-assemble to form a capsid, in general requiring the presence of the virus genome. Complex viruses code for proteins that assist in the construction of their capsid. Proteins associated with nucleic acid are known as nucleoproteins, and the association of viral capsid proteins with viral nucleic acid is called a nucleocapsid. The capsid and entire virus structure can be mechanically (physically) probed through atomic force microscopy. In general, there are four main morphological virus types:\n\n\n\n\n\n\nThe poxviruses are large, complex viruses that have an unusual morphology. The viral genome is associated with proteins within a central disc structure known as a nucleoid. The nucleoid is surrounded by a membrane and two lateral bodies of unknown function. The virus has an outer envelope with a thick layer of protein studded over its surface. The whole virion is slightly pleiomorphic, ranging from ovoid to brick shape. Mimivirus is one of the largest characterised viruses, with a capsid diameter of 400 nm. Protein filaments measuring 100 nm project from the surface. The capsid appears hexagonal under an electron microscope, therefore the capsid is probably icosahedral. In 2011, researchers discovered the largest then known virus in samples of water collected from the ocean floor off the coast of Las Cruces, Chile. Provisionally named \"Megavirus chilensis\", it can be seen with a basic optical microscope. In 2013, the Pandoravirus genus was discovered in Chile and Australia, and has genomes about twice as large as Megavirus and Mimivirus.\n\nSome viruses that infect Archaea have complex structures that are unrelated to any other form of virus, with a wide variety of unusual shapes, ranging from spindle-shaped structures, to viruses that resemble hooked rods, teardrops or even bottles. Other archaeal viruses resemble the tailed bacteriophages, and can have multiple tail structures.\n\nAn enormous variety of genomic structures can be seen among viral species; as a group, they contain more structural genomic diversity than plants, animals, archaea, or bacteria. There are millions of different types of viruses, although only about 5,000 types have been described in detail. As of September 2015, the NCBI Virus genome database has more than 75,000 complete genome sequences. but there are doubtlessly many more to be discovered.\n\nA virus has either a DNA or an RNA genome and is called a DNA virus or an RNA virus, respectively. The vast majority of viruses have RNA genomes. Plant viruses tend to have single-stranded RNA genomes and bacteriophages tend to have double-stranded DNA genomes.\n\nViral genomes are \"circular\", as in the polyomaviruses, or \"linear\", as in the adenoviruses. The type of nucleic acid is irrelevant to the shape of the genome. Among RNA viruses and certain DNA viruses, the genome is often divided up into separate parts, in which case it is called segmented. For RNA viruses, each segment often codes for only one protein and they are usually found together in one capsid. All segments are not required to be in the same virion for the virus to be infectious, as demonstrated by brome mosaic virus and several other plant viruses.\n\nA viral genome, irrespective of nucleic acid type, is almost always either \"single-stranded\" or \"double-stranded\". Single-stranded genomes consist of an unpaired nucleic acid, analogous to one-half of a ladder split down the middle. Double-stranded genomes consist of two complementary paired nucleic acids, analogous to a ladder. The virus particles of some virus families, such as those belonging to the \"Hepadnaviridae\", contain a genome that is partially double-stranded and partially single-stranded.\n\nFor most viruses with RNA genomes and some with single-stranded DNA genomes, the single strands are said to be either positive-sense (called the \"plus-strand\") or negative-sense (called the \"minus-strand\"), depending on if they are complementary to the viral messenger RNA (mRNA). Positive-sense viral RNA is in the same sense as viral mRNA and thus at least a part of it can be immediately translated by the host cell. Negative-sense viral RNA is complementary to mRNA and thus must be converted to positive-sense RNA by an RNA-dependent RNA polymerase before translation. DNA nomenclature for viruses with single-sense genomic ssDNA is similar to RNA nomenclature, in that the \"template strand\" for the viral mRNA is complementary to it (−), and the \"coding strand\" is a copy of it (+). Several types of ssDNA and ssRNA viruses have genomes that are ambisense in that transcription can occur off both strands in a double-stranded replicative intermediate. Examples include geminiviruses, which are ssDNA plant viruses and arenaviruses, which are ssRNA viruses of animals.\n\nGenome size varies greatly between species. The smallest viral genomes – the ssDNA circoviruses, family \"Circoviridae\" – code for only two proteins and have a genome size of only two kilobases; the largest–the pandoraviruses–have genome sizes of around two megabases which code for about 2500 proteins. Virus genes rarely have introns and often are arranged in the genome so that they overlap.\n\nIn general, RNA viruses have smaller genome sizes than DNA viruses because of a higher error-rate when replicating, and have a maximum upper size limit. Beyond this limit, errors in the genome when replicating render the virus useless or uncompetitive. To compensate for this, RNA viruses often have segmented genomes – the genome is split into smaller molecules – thus reducing the chance that an error in a single-component genome will incapacitate the entire genome. In contrast, DNA viruses generally have larger genomes because of the high fidelity of their replication enzymes. Single-strand DNA viruses are an exception to this rule, as mutation rates for these genomes can approach the extreme of the ssRNA virus case.\n\nViruses undergo genetic change by several mechanisms. These include a process called antigenic drift where individual bases in the DNA or RNA mutate to other bases. Most of these point mutations are \"silent\" – they do not change the protein that the gene encodes – but others can confer evolutionary advantages such as resistance to antiviral drugs. Antigenic shift occurs when there is a major change in the genome of the virus. This can be a result of recombination or reassortment. When this happens with influenza viruses, pandemics might result. RNA viruses often exist as quasispecies or swarms of viruses of the same species but with slightly different genome nucleoside sequences. Such quasispecies are a prime target for natural selection.\n\nSegmented genomes confer evolutionary advantages; different strains of a virus with a segmented genome can shuffle and combine genes and produce progeny viruses or (offspring) that have unique characteristics. This is called reassortment or \"viral sex\".\n\nGenetic recombination is the process by which a strand of DNA is broken and then joined to the end of a different DNA molecule. This can occur when viruses infect cells simultaneously and studies of viral evolution have shown that recombination has been rampant in the species studied. Recombination is common to both RNA and DNA viruses.\n\nViral populations do not grow through cell division, because they are acellular. Instead, they use the machinery and metabolism of a host cell to produce multiple copies of themselves, and they \"assemble\" in the cell.\nThe life cycle of viruses differs greatly between species but there are six \"basic\" stages in the life cycle of viruses:\n\nAttachment is a specific binding between viral capsid proteins and specific receptors on the host cellular surface. This specificity determines the host range of a virus. For example, HIV infects a limited range of human leucocytes. This is because its surface protein, gp120, specifically interacts with the CD4 molecule – a chemokine receptor – which is most commonly found on the surface of CD4+ T-Cells. This mechanism has evolved to favour those viruses that infect only cells in which they are capable of replication. Attachment to the receptor can induce the viral envelope protein to undergo changes that results in the fusion of viral and cellular membranes, or changes of non-enveloped virus surface proteins that allow the virus to enter.\n\nPenetration follows attachment: Virions enter the host cell through receptor-mediated endocytosis or membrane fusion. This is often called viral entry. The infection of plant and fungal cells is different from that of animal cells. Plants have a rigid cell wall made of cellulose, and fungi one of chitin, so most viruses can get inside these cells only after trauma to the cell wall. Nearly all plant viruses (such as tobacco mosaic virus) can also move directly from cell to cell, in the form of single-stranded nucleoprotein complexes, through pores called plasmodesmata. Bacteria, like plants, have strong cell walls that a virus must breach to infect the cell. Given that bacterial cell walls are much thinner than plant cell walls due to their much smaller size, some viruses have evolved mechanisms that inject their genome into the bacterial cell across the cell wall, while the viral capsid remains outside.\n\nUncoating is a process in which the viral capsid is removed: This may be by degradation by viral enzymes or host enzymes or by simple dissociation; the end-result is the releasing of the viral genomic nucleic acid.\n\nReplication of viruses involves primarily multiplication of the genome. Replication involves synthesis of viral messenger RNA (mRNA) from \"early\" genes (with exceptions for positive sense RNA viruses), viral protein synthesis, possible assembly of viral proteins, then viral genome replication mediated by early or regulatory protein expression. This may be followed, for complex viruses with larger genomes, by one or more further rounds of mRNA synthesis: \"late\" gene expression is, in general, of structural or virion proteins.\n\nAssembly – Following the structure-mediated self-\"assembly\" of the virus particles, some modification of the proteins often occurs. In viruses such as HIV, this modification (sometimes called maturation) occurs \"after\" the virus has been released from the host cell.\n\nRelease – Viruses can be \"released\" from the host cell by lysis, a process that kills the cell by bursting its membrane and cell wall if present: This is a feature of many bacterial and some animal viruses. Some viruses undergo a lysogenic cycle where the viral genome is incorporated by genetic recombination into a specific place in the host's chromosome. The viral genome is then known as a \"provirus\" or, in the case of bacteriophages a \"prophage\". Whenever the host divides, the viral genome is also replicated. The viral genome is mostly silent within the host. At some point, the provirus or prophage may give rise to active virus, which may lyse the host cells. Enveloped viruses (e.g., HIV) typically are released from the host cell by budding. During this process the virus acquires its envelope, which is a modified piece of the host's plasma or other, internal membrane.\n\nThe genetic material within virus particles, and the method by which the material is replicated, varies considerably between different types of viruses.\n\n\n\n\nThe range of structural and biochemical effects that viruses have on the host cell is extensive. These are called \"cytopathic effects\". Most virus infections eventually result in the death of the host cell. The causes of death include cell lysis, alterations to the cell's surface membrane and apoptosis. Often cell death is caused by cessation of its normal activities because of suppression by virus-specific proteins, not all of which are components of the virus particle. The distinction between cytopathic and harmless is gradual. Some viruses, such as Epstein–Barr virus, can cause cells to proliferate without causing malignancy, while others, such as papillomaviruses, are established causes of cancer.\n\nSome viruses cause no apparent changes to the infected cell. Cells in which the virus is latent and inactive show few signs of infection and often function normally. This causes persistent infections and the virus is often dormant for many months or years. This is often the case with herpes viruses.\n\nViruses are by far the most abundant biological entities on Earth and they outnumber all the others put together. They infect all types of cellular life including animals, plants, bacteria and fungi. Different types of viruses can infect only a limited range of hosts and many are species-specific. Some, such as smallpox virus for example, can infect only one species – in this case humans, and are said to have a narrow host range. Other viruses, such as rabies virus, can infect different species of mammals and are said to have a broad range. The viruses that infect plants are harmless to animals, and most viruses that infect other animals are harmless to humans. The host range of some bacteriophages is limited to a single strain of bacteria and they can be used to trace the source of outbreaks of infections by a method called phage typing.\n\nClassification seeks to describe the diversity of viruses by naming and grouping them on the basis of similarities. In 1962, André Lwoff, Robert Horne, and Paul Tournier were the first to develop a means of virus classification, based on the Linnaean hierarchical system. This system based classification on phylum, class, order, family, genus, and species. Viruses were grouped according to their shared properties (not those of their hosts) and the type of nucleic acid forming their genomes. In 1966, the International Committee on Taxonomy of Viruses (ICTV) was formed. The system proposed by Lwoff, Horne and Tournier was never fully accepted by the ICTV because small genome size viruses and their high rate of mutation makes it difficult to determine their ancestry beyond order. As such, the Baltimore classification is used to supplement the more traditional hierarchy.\n\nThe International Committee on Taxonomy of Viruses (ICTV) developed the current classification system and wrote guidelines that put a greater weight on certain virus properties to maintain family uniformity. A unified taxonomy (a universal system for classifying viruses) has been established. Only a small part of the total diversity of viruses has been studied.\n\nThe general taxonomic structure of taxon ranges actually used (as of November 2018) is as follows:\n\nAs of 2018, just one single phylum, two subphyla, six classes, 14 orders, five suborders, 143 families, 64 subfamilies, 846 genera, and 4,958 species of viruses have been defined by the ICTV. The orders are the \"Caudovirales, Herpesvirales, Ligamenvirales, Mononegavirales, Nidovirales, Ortervirales, Picornavirales, Bunyavirales\",\"Tymovirales\", \"Muvirales\", \"Serpentovirales\", \"Jingchuvirales\", \"Goujianvirales\", and \"Articulavirales\".\n\nThe Nobel Prize-winning biologist David Baltimore devised the Baltimore classification system. The ICTV classification system is used in conjunction with the Baltimore classification system in modern virus classification.\n\nThe Baltimore classification of viruses is based on the mechanism of mRNA production. Viruses must generate mRNAs from their genomes to produce proteins and replicate themselves, but different mechanisms are used to achieve this in each virus family. Viral genomes may be single-stranded (ss) or double-stranded (ds), RNA or DNA, and may or may not use reverse transcriptase (RT). In addition, ssRNA viruses may be either sense (+) or antisense (−). This classification places viruses into seven groups:\n\nAs an example of viral classification, the chicken pox virus, varicella zoster (VZV), belongs to the order \"Herpesvirales\", family \"Herpesviridae\", subfamily \"Alphaherpesvirinae\", and genus \"Varicellovirus\". VZV is in Group I of the Baltimore Classification because it is a dsDNA virus that does not use reverse transcriptase.\n\nThe complete set of viruses in an organism or habitat is called the virome; for example, all human viruses constitute the human virome.\n\nExamples of common human diseases caused by viruses include the common cold, influenza, chickenpox, and cold sores. Many serious diseases such as Ebola virus disease, AIDS, avian influenza, and SARS are caused by viruses. The relative ability of viruses to cause disease is described in terms of virulence. Other diseases are under investigation to discover if they have a virus as the causative agent, such as the possible connection between human herpesvirus 6 (HHV6) and neurological diseases such as multiple sclerosis and chronic fatigue syndrome. There is controversy over whether the bornavirus, previously thought to cause neurological diseases in horses, could be responsible for psychiatric illnesses in humans.\n\nViruses have different mechanisms by which they produce disease in an organism, which depends largely on the viral species. Mechanisms at the cellular level primarily include cell lysis, the breaking open and subsequent death of the cell. In multicellular organisms, if enough cells die, the whole organism will start to suffer the effects. Although viruses cause disruption of healthy homeostasis, resulting in disease, they may exist relatively harmlessly within an organism. An example would include the ability of the herpes simplex virus, which causes cold sores, to remain in a dormant state within the human body. This is called latency and is a characteristic of the herpes viruses, including Epstein–Barr virus, which causes glandular fever, and varicella zoster virus, which causes chickenpox and shingles. Most people have been infected with at least one of these types of herpes virus. These latent viruses might sometimes be beneficial, as the presence of the virus can increase immunity against bacterial pathogens, such as \"Yersinia pestis\".\n\nSome viruses can cause lifelong or chronic infections, where the viruses continue to replicate in the body despite the host's defence mechanisms. This is common in hepatitis B virus and hepatitis C virus infections. People chronically infected are known as carriers, as they serve as reservoirs of infectious virus. In populations with a high proportion of carriers, the disease is said to be endemic.\n\nViral epidemiology is the branch of medical science that deals with the transmission and control of virus infections in humans. Transmission of viruses can be vertical, which means from mother to child, or horizontal, which means from person to person. Examples of vertical transmission include hepatitis B virus and HIV, where the baby is born already infected with the virus. Another, more rare, example is the varicella zoster virus, which, although causing relatively mild infections in humans, can be fatal to the foetus and newborn baby.\n\nHorizontal transmission is the most common mechanism of spread of viruses in populations. Transmission can occur when: body fluids are exchanged during sexual activity, e.g., HIV; blood is exchanged by contaminated transfusion or needle sharing, e.g., hepatitis C; exchange of saliva by mouth, e.g., Epstein–Barr virus; contaminated food or water is ingested, e.g., norovirus; aerosols containing virions are inhaled, e.g., influenza virus; and insect vectors such as mosquitoes penetrate the skin of a host, e.g., dengue.\nThe rate or speed of transmission of viral infections depends on factors that include population density, the number of susceptible individuals, (i.e., those not immune), the quality of healthcare and the weather.\n\nEpidemiology is used to break the chain of infection in populations during outbreaks of viral diseases. Control measures are used that are based on knowledge of how the virus is transmitted. It is important to find the source, or sources, of the outbreak and to identify the virus. Once the virus has been identified, the chain of transmission can sometimes be broken by vaccines. When vaccines are not available, sanitation and disinfection can be effective. Often, infected people are isolated from the rest of the community, and those that have been exposed to the virus are placed in quarantine. To control the outbreak of foot-and-mouth disease in cattle in Britain in 2001, thousands of cattle were slaughtered. Most viral infections of humans and other animals have incubation periods during which the infection causes no signs or symptoms. Incubation periods for viral diseases range from a few days to weeks, but are known for most infections. Somewhat overlapping, but mainly following the incubation period, there is a period of communicability — a time when an infected individual or animal is contagious and can infect another person or animal. This, too, is known for many viral infections, and knowledge of the length of both periods is important in the control of outbreaks. When outbreaks cause an unusually high proportion of cases in a population, community, or region, they are called epidemics. If outbreaks spread worldwide, they are called pandemics.\n\nNative American populations were devastated by contagious diseases, in particular, smallpox, brought to the Americas by European colonists. It is unclear how many Native Americans were killed by foreign diseases after the arrival of Columbus in the Americas, but the numbers have been estimated to be close to 70% of the indigenous population. The damage done by this disease significantly aided European attempts to displace and conquer the native population.\n\nA pandemic is a worldwide epidemic. The 1918 flu pandemic, which lasted until 1919, was a category 5 influenza pandemic caused by an unusually severe and deadly influenza A virus. The victims were often healthy young adults, in contrast to most influenza outbreaks, which predominantly affect juvenile, elderly, or otherwise-weakened patients. Older estimates say it killed 40–50 million people, while more recent research suggests that it may have killed as many as 100 million people, or 5% of the world's population in 1918.\n\nMost researchers believe that HIV originated in sub-Saharan Africa during the 20th century; it is now a pandemic, with an estimated 38.6 million people now living with the disease worldwide. The Joint United Nations Programme on HIV/AIDS (UNAIDS) and the World Health Organization (WHO) estimate that AIDS has killed more than 25 million people since it was first recognised on 5 June 1981, making it one of the most destructive epidemics in recorded history. In 2007 there were 2.7 million new HIV infections and 2 million HIV-related deaths.\nSeveral highly lethal viral pathogens are members of the \"Filoviridae\". Filoviruses are filament-like viruses that cause viral hemorrhagic fever, and include ebolaviruses and marburgviruses. Marburg virus, first discovered in 1967, attracted widespread press attention in April 2005 for an outbreak in Angola. Ebola Virus Disease has also caused intermittent outbreaks with high mortality rates since 1976 when it was first identified. The worst and most recent one is the West Africa epidemic.\n\nViruses are an established cause of cancer in humans and other species. Viral cancers occur only in a minority of infected persons (or animals). Cancer viruses come from a range of virus families, including both RNA and DNA viruses, and so there is no single type of \"oncovirus\" (an obsolete term originally used for acutely transforming retroviruses). The development of cancer is determined by a variety of factors such as host immunity and mutations in the host. Viruses accepted to cause human cancers include some genotypes of human papillomavirus, hepatitis B virus, hepatitis C virus, Epstein–Barr virus, Kaposi's sarcoma-associated herpesvirus and human T-lymphotropic virus. The most recently discovered human cancer virus is a polyomavirus (Merkel cell polyomavirus) that causes most cases of a rare form of skin cancer called Merkel cell carcinoma.\nHepatitis viruses can develop into a chronic viral infection that leads to liver cancer. Infection by human T-lymphotropic virus can lead to tropical spastic paraparesis and adult T-cell leukaemia. Human papillomaviruses are an established cause of cancers of cervix, skin, anus, and penis. Within the \"Herpesviridae\", Kaposi's sarcoma-associated herpesvirus causes Kaposi's sarcoma and body-cavity lymphoma, and Epstein–Barr virus causes Burkitt's lymphoma, Hodgkin's lymphoma, B lymphoproliferative disorder, and nasopharyngeal carcinoma. Merkel cell polyomavirus closely related to SV40 and mouse polyomaviruses that have been used as animal models for cancer viruses for over 50 years.\n\nThe body's first line of defence against viruses is the innate immune system. This comprises cells and other mechanisms that defend the host from infection in a non-specific manner. This means that the cells of the innate system recognise, and respond to, pathogens in a generic way, but, unlike the adaptive immune system, it does not confer long-lasting or protective immunity to the host.\n\nRNA interference is an important innate defence against viruses. Many viruses have a replication strategy that involves double-stranded RNA (dsRNA). When such a virus infects a cell, it releases its RNA molecule or molecules, which immediately bind to a protein complex called a dicer that cuts the RNA into smaller pieces. A biochemical pathway – the RISC complex – is activated, which ensures cell survival by degrading the viral mRNA. Rotaviruses have evolved to avoid this defence mechanism by not uncoating fully inside the cell, and releasing newly produced mRNA through pores in the particle's inner capsid. Their genomic dsRNA remains protected inside the core of the virion.\n\nWhen the adaptive immune system of a vertebrate encounters a virus, it produces specific antibodies that bind to the virus and often render it non-infectious. This is called humoral immunity. Two types of antibodies are important. The first, called IgM, is highly effective at neutralising viruses but is produced by the cells of the immune system only for a few weeks. The second, called IgG, is produced indefinitely. The presence of IgM in the blood of the host is used to test for acute infection, whereas IgG indicates an infection sometime in the past. IgG antibody is measured when tests for immunity are carried out.\n\nAntibodies can continue to be an effective defence mechanism even after viruses have managed to gain entry to the host cell. A protein that is in cells, called TRIM21, can attach to the antibodies on the surface of the virus particle. This primes the subsequent destruction of the virus by the enzymes of the cell's proteosome system.\nA second defence of vertebrates against viruses is called cell-mediated immunity and involves immune cells known as T cells. The body's cells constantly display short fragments of their proteins on the cell's surface, and, if a T cell recognises a suspicious viral fragment there, the host cell is destroyed by \"killer T\" cells and the virus-specific T-cells proliferate. Cells such as the macrophage are specialists at this antigen presentation. The production of interferon is an important host defence mechanism. This is a hormone produced by the body when viruses are present. Its role in immunity is complex; it eventually stops the viruses from reproducing by killing the infected cell and its close neighbours.\n\nNot all virus infections produce a protective immune response in this way. HIV evades the immune system by constantly changing the amino acid sequence of the proteins on the surface of the virion. This is known as \"escape mutation\" as the viral epitopes escape recognition by the host immune response. These persistent viruses evade immune control by sequestration, blockade of antigen presentation, cytokine resistance, evasion of natural killer cell activities, escape from apoptosis, and antigenic shift. Other viruses, called \"neurotropic viruses\", are disseminated by neural spread where the immune system may be unable to reach them.\n\nBecause viruses use vital metabolic pathways within host cells to replicate, they are difficult to eliminate without using drugs that cause toxic effects to host cells in general. The most effective medical approaches to viral diseases are vaccinations to provide immunity to infection, and antiviral drugs that selectively interfere with viral replication.\n\nVaccination is a cheap and effective way of preventing infections by viruses. Vaccines were used to prevent viral infections long before the discovery of the actual viruses. Their use has resulted in a dramatic decline in morbidity (illness) and mortality (death) associated with viral infections such as polio, measles, mumps and rubella. Smallpox infections have been eradicated. Vaccines are available to prevent over thirteen viral infections of humans, and more are used to prevent viral infections of animals. Vaccines can consist of live-attenuated or killed viruses, or viral proteins (antigens). Live vaccines contain weakened forms of the virus, which do not cause the disease but, nonetheless, confer immunity. Such viruses are called attenuated. Live vaccines can be dangerous when given to people with a weak immunity (who are described as immunocompromised), because in these people, the weakened virus can cause the original disease. Biotechnology and genetic engineering techniques are used to produce subunit vaccines. These vaccines use only the capsid proteins of the virus. Hepatitis B vaccine is an example of this type of vaccine. Subunit vaccines are safe for immunocompromised patients because they cannot cause the disease. The yellow fever virus vaccine, a live-attenuated strain called 17D, is probably the safest and most effective vaccine ever generated.\n\nAntiviral drugs are often nucleoside analogues (fake DNA building-blocks), which viruses mistakenly incorporate into their genomes during replication. The life-cycle of the virus is then halted because the newly synthesised DNA is inactive. This is because these analogues lack the hydroxyl groups, which, along with phosphorus atoms, link together to form the strong \"backbone\" of the DNA molecule. This is called DNA chain termination. Examples of nucleoside analogues are aciclovir for Herpes simplex virus infections and lamivudine for HIV and Hepatitis B virus infections. Aciclovir is one of the oldest and most frequently prescribed antiviral drugs.\nOther antiviral drugs in use target different stages of the viral life cycle. HIV is dependent on a proteolytic enzyme called the HIV-1 protease for it to become fully infectious. There is a large class of drugs called protease inhibitors that inactivate this enzyme.\n\nHepatitis C is caused by an RNA virus. In 80% of people infected, the disease is chronic, and without treatment, they are infected for the remainder of their lives. There is now an effective treatment that uses the nucleoside analogue drug ribavirin combined with interferon. The treatment of chronic carriers of the hepatitis B virus by using a similar strategy using lamivudine has been developed.\n\nViruses infect all cellular life and, although viruses occur universally, each cellular species has its own specific range that often infect only that species. Some viruses, called satellites, can replicate only within cells that have already been infected by another virus.\n\nViruses are important pathogens of livestock. Diseases such as foot-and-mouth disease and bluetongue are caused by viruses. Companion animals such as cats, dogs, and horses, if not vaccinated, are susceptible to serious viral infections. Canine parvovirus is caused by a small DNA virus and infections are often fatal in pups. Like all invertebrates, the honey bee is susceptible to many viral infections. Most viruses co-exist harmlessly in their host and cause no signs or symptoms of disease.\n\nThere are many types of plant virus, but often they cause only a loss of yield, and it is not economically viable to try to control them. Plant viruses are often spread from plant to plant by organisms, known as \"vectors\". These are normally insects, but some fungi, nematode worms, and single-celled organisms have been shown to be vectors. When control of plant virus infections is considered economical, for perennial fruits, for example, efforts are concentrated on killing the vectors and removing alternate hosts such as weeds. Plant viruses cannot infect humans and other animals because they can reproduce only in living plant cells.\n\nPlants have elaborate and effective defence mechanisms against viruses. One of the most effective is the presence of so-called resistance (R) genes. Each R gene confers resistance to a particular virus by triggering localised areas of cell death around the infected cell, which can often be seen with the unaided eye as large spots. This stops the infection from spreading. RNA interference is also an effective defence in plants. When they are infected, plants often produce natural disinfectants that kill viruses, such as salicylic acid, nitric oxide, and reactive oxygen molecules.\n\nPlant virus particles or virus-like particles (VLPs) have applications in both biotechnology and nanotechnology. The capsids of most plant viruses are simple and robust structures and can be produced in large quantities either by the infection of plants or by expression in a variety of heterologous systems. Plant virus particles can be modified genetically and chemically to encapsulate foreign material and can be incorporated into supramolecular structures for use in biotechnology.\n\nBacteriophages are a common and diverse group of viruses and are the most abundant biological entity in aquatic environments – there are up to ten times more of these viruses in the oceans than there are bacteria, reaching levels of 250,000,000 bacteriophages per millilitre of seawater. These viruses infect specific bacteria by binding to surface receptor molecules and then entering the cell. Within a short amount of time, in some cases just minutes, bacterial polymerase starts translating viral mRNA into protein. These proteins go on to become either new virions within the cell, helper proteins, which help assembly of new virions, or proteins involved in cell lysis. Viral enzymes aid in the breakdown of the cell membrane, and, in the case of the T4 phage, in just over twenty minutes after injection over three hundred phages could be released.\n\nThe major way bacteria defend themselves from bacteriophages is by producing enzymes that destroy foreign DNA. These enzymes, called restriction endonucleases, cut up the viral DNA that bacteriophages inject into bacterial cells. Bacteria also contain a system that uses CRISPR sequences to retain fragments of the genomes of viruses that the bacteria have come into contact with in the past, which allows them to block the virus's replication through a form of RNA interference. This genetic system provides bacteria with acquired immunity to infection.\n\nSome viruses replicate within archaea: these are double-stranded DNA viruses with unusual and sometimes unique shapes. These viruses have been studied in most detail in the thermophilic archaea, particularly the orders Sulfolobales and Thermoproteales. Defences against these viruses involve RNA interference from repetitive DNA sequences within archaean genomes that are related to the genes of the viruses. Most archaea have CRISPR–Cas systems as an adaptive defence against viruses. These enable archaea to retain sections of viral DNA, which are then used to target and eliminate subsequent infections by the virus using a process similar to RNA interference.\n\nA teaspoon of seawater (~5 mL) contains about 50 million viruses, which contain enormous genetic diversity. Most of these are bacteriophages infecting heterotrophic bacteria and cyanophages infecting cyanobacteria; these viruses are harmless to plants and animals, and are essential to the regulation of marine and freshwater ecosystems; they are also important mortality agents of phytoplankton, the base of the foodchain in aquatic environments. They infect and destroy bacteria in aquatic microbial communities, and are one of the most important mechanisms of recycling carbon and nutrient cycling in marine environments. The organic molecules released from the dead bacterial cells stimulate fresh bacterial and algal growth, in a process known as the viral shunt. In particular, lysis of bacteria by viruses has been shown to enhance nitrogen cycling and stimulate phytoplankton growth. Viral activity may also affect the biological pump, the process whereby carbon is sequestered in the deep ocean.\n\nMicroorganisms constitute more than 90% of the biomass in the sea. It is estimated that viruses kill approximately 20% of this biomass each day and that there are 10 to 15 times as many viruses in the oceans as there are bacteria and archaea. Viruses are also major agents responsible for the destruction of phytoplankton including harmful algal blooms,\nThe number of viruses in the oceans decreases further offshore and deeper into the water, where there are fewer host organisms.\n\nIn January 2018, scientists reported that 800 million viruses, mainly of marine origin, are deposited daily from the Earth atmosphere onto every square meter of the planet's surface, as the result of a global atmospheric stream of viruses, circulating above the weather system, but below the altitude of usual airline travel, distributing viruses around the planet.\n\nLike any organism, marine mammals are susceptible to viral infections. In 1988 and 2002, thousands of harbour seals were killed in Europe by phocine distemper virus. Many other viruses, including caliciviruses, herpesviruses, adenoviruses and parvoviruses, circulate in marine mammal populations.\n\nViruses are an important natural means of transferring genes between different species, which increases genetic diversity and drives evolution. It is thought that viruses played a central role in early evolution, before the diversification of the last universal common ancestor into bacteria, archaea and eukaryotes. Viruses are still one of the largest reservoirs of unexplored genetic diversity on Earth.\n\nViruses are important to the study of molecular and cell biology as they provide simple systems that can be used to manipulate and investigate the functions of cells. The study and use of viruses have provided valuable information about aspects of cell biology. For example, viruses have been useful in the study of genetics and helped our understanding of the basic mechanisms of molecular genetics, such as DNA replication, transcription, RNA processing, translation, protein transport, and immunology.\n\nGeneticists often use viruses as vectors to introduce genes into cells that they are studying. This is useful for making the cell produce a foreign substance, or to study the effect of introducing a new gene into the genome. In similar fashion, virotherapy uses viruses as vectors to treat various diseases, as they can specifically target cells and DNA. It shows promising use in the treatment of cancer and in gene therapy. Eastern European scientists have used phage therapy as an alternative to antibiotics for some time, and interest in this approach is increasing, because of the high level of antibiotic resistance now found in some pathogenic bacteria.\nExpression of heterologous proteins by viruses is the basis of several manufacturing processes that are currently being used for the production of various proteins such as vaccine antigens and antibodies. Industrial processes have been recently developed using viral vectors and a number of pharmaceutical proteins are currently in pre-clinical and clinical trials.\n\nVirotherapy involves the use of genetically modified viruses to treat diseases. Viruses have been modified by scientists to reproduce in cancer cells and destroy them but not infect healthy cells. Talimogene laherparepvec (T-VEC), for example, is a modified herpes simplex virus that has had a gene, which is required for viruses to replicate in healthy cells, deleted and replaced with a human gene (GM-CSF) that stimulates immunity. When this virus infects cancer cells, it destroys them and in doing so the presence the GM-CSF gene attracts dendritic cells from the surrounding tissues of the body. The dendritic cells process the dead cancer cells and present components of them to other cells of the immune system. Having completed successful clinical trials, this virus is expected to gain approval for the treatment of a skin cancer called melanoma in late 2015. Viruses that have been reprogrammed to kill cancer cells are called oncolytic viruses.\n\nCurrent trends in nanotechnology promise to make much more versatile use of viruses. From the viewpoint of a materials scientist, viruses can be regarded as organic nanoparticles.\nTheir surface carries specific tools designed to cross the barriers of their host cells. The size and shape of viruses, and the number and nature of the functional groups on their surface, is precisely defined. As such, viruses are commonly used in materials science as scaffolds for covalently linked surface modifications. A particular quality of viruses is that they can be tailored by directed evolution. The powerful techniques developed by life sciences are becoming the basis of engineering approaches towards nanomaterials, opening a wide range of applications far beyond biology and medicine.\n\nBecause of their size, shape, and well-defined chemical structures, viruses have been used as templates for organising materials on the nanoscale. Recent examples include work at the Naval Research Laboratory in Washington, D.C., using Cowpea mosaic virus (CPMV) particles to amplify signals in DNA microarray based sensors. In this application, the virus particles separate the fluorescent dyes used for signalling to prevent the formation of non-fluorescent dimers that act as quenchers. Another example is the use of CPMV as a nanoscale breadboard for molecular electronics.\n\nMany viruses can be synthesised de novo (\"from scratch\") and the first synthetic virus was created in 2002. Although somewhat of a misconception, it is not the actual virus that is synthesised, but rather its DNA genome (in case of a DNA virus), or a cDNA copy of its genome (in case of RNA viruses). For many virus families the naked synthetic DNA or RNA (once enzymatically converted back from the synthetic cDNA) is infectious when introduced into a cell. That is, they contain all the necessary information to produce new viruses. This technology is now being used to investigate novel vaccine strategies. The ability to synthesise viruses has far-reaching consequences, since viruses can no longer be regarded as extinct, as long as the information of their genome sequence is known and permissive cells are available. , the full-length genome sequences of 7454 different viruses, including smallpox, are publicly available in an online database maintained by the National Institutes of Health.\n\nThe ability of viruses to cause devastating epidemics in human societies has led to the concern that viruses could be weaponised for biological warfare. Further concern was raised by the successful recreation of the infamous 1918 influenza virus in a laboratory. \n\nSmallpox virus devastated numerous societies throughout history before its eradication. There are only two centres in the world that are authorised by the WHO to keep stocks of smallpox virus: the State Research Center of Virology and Biotechnology VECTOR in Russia and the Centers for Disease Control and Prevention in the United States. Fears that it may be used as a weapon may not be totally unfounded. As the vaccine for smallpox sometimes had severe side-effects, it is no longer used routinely in any country. Thus, much of the modern human population has almost no established resistance to smallpox, and would be vulnerable to the virus.\n\n"}
{"id": "1966095", "url": "https://en.wikipedia.org/wiki?curid=1966095", "title": "Voluntary Human Extinction Movement", "text": "Voluntary Human Extinction Movement\n\nThe Voluntary Human Extinction Movement (VHEMT) is an environmental movement that calls for all people to abstain from reproduction to cause the gradual voluntary extinction of humankind. VHEMT supports human extinction primarily because, in the group's view, it would prevent environmental degradation. The group states that a decrease in the human population would prevent a significant amount of human-caused suffering. The extinctions of non-human species and the scarcity of resources required by humans are frequently cited by the group as evidence of the harm caused by human overpopulation.\n\nVHEMT was founded in 1991 by Les U. Knight, an American activist who became involved in the environmental movement in the 1970s and thereafter concluded that human extinction was the best solution to the problems facing the Earth's biosphere and humanity. Knight publishes the group's newsletter and serves as its spokesman. Although the group is promoted by a website and represented at some environmental events, it relies heavily on coverage from outside media to spread its message. Many commentators view its platform as unacceptably extreme, though other writers have applauded VHEMT's perspective. In response to VHEMT, some journalists and academics have argued that humans can develop sustainable lifestyles or can reduce their population to sustainable levels. Others maintain that, whatever the merits of the idea, the human reproductive drive will prevent humankind from ever voluntarily seeking extinction.\n\nThe Voluntary Human Extinction Movement was founded by Les U. Knight, a high school substitute teacher living in Portland, Oregon. After becoming involved in the environmental movement as a college student in the 1970s, Knight attributed most of the dangers faced by the planet to human overpopulation. He joined the Zero Population Growth organization, and chose to be vasectomised at age 25. He later concluded that the extinction of humanity would be the best solution to the Earth's environmental problems. He believes that this idea has also been held by some people throughout human history.\n\nIn 1991, Knight began publishing VHEMT's newsletter, known as \"These Exit Times\". In the newsletter, he asked readers to further human extinction by not procreating. VHEMT has also published cartoons, including a comic strip titled \"Bonobo Baby\", featuring a woman who forgoes childbearing in favor of adopting a bonobo. In 1996, Knight created a website for VHEMT; it was available in 11 languages by 2010. VHEMT's logo features the letter \"V\" (for voluntary) and a picture of the Earth with north at the bottom.\n\nVHEMT functions as a loose network rather than a formal organization, and does not compile a list of members. Daniel Metz of Willamette University stated in 1995 that VHEMT's mailing list had just under 400 subscribers. Six years later, Fox News said the list had only 230 subscribers. Knight says that anyone who agrees with his ideology is a member of the movement; and that this includes \"millions of people\".\n\nKnight serves as the spokesman for VHEMT. He attends environmental conferences and events, where he publicizes information about population growth. VHEMT's message has, however, primarily been spread through coverage by media outlets, rather than events and its newsletter. VHEMT sells buttons and T-shirts, as well as bumper stickers that read \"Thank you for not breeding\".\n\nKnight argues that the human population is far greater than the Earth can handle, and that the best thing for Earth's biosphere is for humans to voluntarily cease reproducing. He says that humans are \"incompatible with the biosphere\" and that human existence is causing environmental damage which will eventually bring about the extinction of humans (as well as other organisms). According to Knight, the vast majority of human societies have not lived sustainable lifestyles, and attempts to live environmentally friendly lifestyles do not change the fact that human existence has ultimately been destructive to the Earth and many of its non-human organisms. Voluntary human extinction is promoted on the grounds that it will prevent human suffering and the extinction of other species; Knight points out that many species are threatened by the increasing human population.\n\nJames Ormrod, a psychologist who profiled the group in the journal \"Psychoanalysis, Culture & Society\", notes that the \"most fundamental belief\" of VHEMT is that \"human beings should stop reproducing\", and that some people consider themselves members of the group but do not actually support human extinction. Knight, however, believes that even if humans become more environmentally friendly, they could still return to environmentally destructive lifestyles and hence should eliminate themselves. Residents of First World countries bear the most responsibility to change, according to Knight, as they consume the largest proportion of resources.\n\nKnight believes that Earth's non-human organisms have a higher overall value than humans and their accomplishments, such as art: \"The plays of Shakespeare and the work of Einstein can't hold a candle to a tiger\". He argues that species higher in the food chain are less important than lower species. His ideology is drawn in part from deep ecology, and he sometimes refers to the Earth as Gaia. He notes that human extinction is unavoidable, and that it is better to become extinct soon to avoid causing the extinction of other animals. The potential for evolution of other organisms is also cited as a benefit.\n\nKnight sees abstinence from reproduction as an altruistic choice – a way to prevent involuntary human suffering – and cites the deaths of children from preventable causes as an example of needless suffering. Knight claims that non-reproduction would eventually allow humans to lead idyllic lifestyles in an environment comparable to the Garden of Eden, and maintains that the last remaining humans would be proud of their accomplishment. Other benefits of ceasing human reproduction that he cites include the end of abortion, war, and starvation. Knight argues that \"procreation today is de facto child abuse\". He maintains that the standard of human life will worsen if resources are consumed by a growing population rather than spent solving existing issues. He speculates that if people ceased to reproduce, they would use their energy for other pursuits, and suggests adoption and foster care as outlets for people who desire children.\n\nVHEMT rejects government-mandated human population control programs in favor of voluntary population reduction, supporting only the use of birth control and willpower to prevent pregnancies. Knight states that coercive tactics are unlikely to permanently lower the human population, citing the fact that humanity has survived catastrophic wars, famines, and viruses. Though their newsletter's name recalls the suicide manual \"Final Exit\", the idea of mass suicide is rejected, and they have adopted the slogan \"May we live long and die out\". A 1995 survey of VHEMT members found that a majority of them felt a strong moral obligation to protect the Earth, distrusted the ability of political processes to prevent harm to the environment, and were willing to surrender some of their rights for their cause. VHEMT members who strongly believed that \"Civilization [is] headed for collapse\" were most likely to embrace these views. However, VHEMT does not take any overt political stances.\n\nVHEMT promotes a more extreme ideology than Population Action International, a group that argues humanity should reduce—but not eliminate—its population to care for the Earth. However, the VHEMT platform is more moderate and serious than the Church of Euthanasia, which advocates population reduction by suicide and cannibalism. The 1995 survey found that 36% considered themselves members of Earth First! or had donated to the group in the previous five years.\n\nKnight states his group's ideology runs counter to contemporary society's natalism. He believes this pressure has stopped many people from supporting, or even discussing, population control. He admits that his group is unlikely to succeed, but contends that attempting to reduce the Earth's population is the only moral option.\n\nReception of Knight's idea in the mainstream media has been mixed. Writing in the \"San Francisco Chronicle\", Gregory Dicum states that there is an \"undeniable logic\" to VHEMT's arguments, but he doubts whether Knight's ideas can succeed, arguing that many people desire to have children and cannot be dissuaded. Stephen Jarvis echoes this skepticism in \"The Independent\", noting that VHEMT faces great difficulty owing to the basic human reproductive drive. At \"The Guardian\"s website, Guy Dammann applauds the movement's aim as \"in many ways laudable\", but argues that it is absurd to believe that humans will voluntarily seek extinction. Freelance writer Abby O'Reilly writes that since having children is frequently viewed as a measure of success, VHEMT's goal is difficult to attain. Knight contends in response to these arguments that though sexual desire is natural, human desire for children is a product of enculturation.\n\nThe Roman Catholic Archdiocese of New York has criticized Knight's platform, arguing that the existence of humanity is divinely ordained. Ormrod claims that Knight \"arguably abandons deep ecology in favour of straightforward misanthropy\". He notes that Knight's claim that the last humans in an extinction scenario would have an abundance of resources promotes his cause based on \"benefits accruing to humans\". Ormrod sees this type of argument as counter-intuitive, arguing that it borrows the language of \"late-modern consumer societies\". He faults Knight for what he sees as a failure to develop a consistent and unambiguous ideology. \"The Economist\" characterizes Knight's claim that voluntary human extinction is advisable due to limited resources as \"Malthusian bosh\". The paper further states that compassion for the planet does not necessarily require the pursuit of human extinction. Sociologist Frank Furedi also deems VHEMT to be a Malthusian group, classifying them as a type of environmental organization that \"[thinks] the worst about the human species\". Writing in \"Spiked\", Josie Appleton argues that the group is indifferent to humanity, rather than \"anti-human\".\n\nBrian Bethune writes in \"Maclean's\" that Knight's logic is \"as absurd as it's unassailable\". However, he doubts Knight's claim that the last survivors of the human race would have pleasant lives and suspects that a \"collective loss of the will to live\" would prevail. In response to Knight's platform, journalist Sheldon Richman argues that humans are \"active agents\" and can change their behavior. He contends that people are capable of solving the problems facing Earth. Alan Weisman, author of \"The World Without Us\", suggests a limit of one child per family as a preferable alternative to abstinence from reproduction.\n\nKatharine Mieszkowski of Salon.com recommends that childless people adopt VHEMT's arguments when facing \"probing questions\" about their childlessness. Writing in the \"Journal for Critical Animal Studies\", Carmen Dell'Aversano notes that VHEMT seeks to renounce children as a symbol of perpetual human progress. She casts the movement as a form of \"queer oppositional politics\" because it rejects perpetual reproduction as a form of motivation. She argues that the movement seeks to come to a new definition of \"civil order\", as Lee Edelman suggested that queer theory should. Dell'Aversano believes that VHEMT fulfills Edelman's mandate because they embody the death drive rather than ideas that focus on the reproduction of the past.\n\nAlthough Knight's organization has been featured in a book titled \"Kooks: A Guide to the Outer Limits of Human Belief\", \"The Guardian\" journalist Oliver Burkeman notes that in a phone conversation Knight seems \"rather sane and self-deprecating\". Weisman echoes this sentiment, characterizing Knight as \"thoughtful, soft-spoken, articulate, and quite serious\". Philosophers Steven Best and Douglas Kellner view VHEMT's stance as extreme, but they note that the movement formed in response to extreme stances found in \"modern humanism\".\n\nIn 1973, D. Keith Mano published a science fiction novel entitled \"The Bridge\" in which mankind has decided that its presence is environmentally intolerable and that all human beings must die.\n\n\n\n"}
{"id": "2812486", "url": "https://en.wikipedia.org/wiki?curid=2812486", "title": "Yevgeny Chertovsky", "text": "Yevgeny Chertovsky\n\nYevgeny Yefimovich Chertovsky (; born February 15, 1902, date of death unknown) was a Soviet Russian inventor who designed the first full pressure suit in Leningrad in 1931.\n\nChertovsky, an engineer of Aviation Medicine Institute, was involved in early Soviet stratospheric balloon program, and co-designed the ill-fated \"Osoaviakhim-1\". The first aircraft designed for crew wearing Chertovsky's pressure suits could have been a gigantic (300,000 cubic meters) \"USSR-3\" balloon that burnt down on launch pad in September 1935.\n\nThe CH-1 was a simple pressure-tight suit with helmet which did not have joints, thus requiring substantial force to move the arms and legs when pressurised. This was remedied in CH-2 (1932–1935) and later suits, up to the 1940 CH-7. CH-3 was the first operational suit that allowed the pilot sufficient freedom of movement, first tested in flight in 1937 at 12 kilometer altitude.\n\nChertovsky coined the term \"skafander\" for full pressure suits; from the Greek words \"skaf\" (\"boat\", \"ship\") and \"andros\" (\"man\"); \"skafandr\" has since become the term used by Russians to refer to standard diving dresses or space suits.\n\n\n"}
