{"id": "34680526", "url": "https://en.wikipedia.org/wiki?curid=34680526", "title": "Alison Begbie", "text": "Alison Begbie\n\nAlison Begbie, Ellison Begbie or Elizabeth Gebbie (1762-1823), is said to have been the daughter of a farmer, born in the parish of Galston, and at the time of her courtship by Robert Burns she was a servant employed at Carnell House, then known as Cairnhill, close to the River Cessnock, situated about 2 miles from Loudoun. It is thought that Burns' sister confused her name and that she was actually Elizabeth Gebbie.\n\nAlison may have lived at Old Place, now Shawsmill Farm, the daughter of a tenant-farmer. Burns was living at Lochlea Farm at this time. Although not a beauty, she had many charming qualities, inspired by an education somewhat beyond anything that Burns had ever encountered before in a female.\n\nAlison met Burns in 1781 near Lochlea Farm and had hoped to set up a household of his own with her. Her rejection of him may have significantly contributed to the depressive illness that he suffered whilst living and working in Irvine.\n\nAlison's surname was difficult to pair in rhyme, so Robert is said to have used artistic licence and named her in his work as 'Peggy Alison'.\n\nBurns said of her \"All these charming qualities, heightened by an education much beyond anything I have ever met in any woman I ever dared to approach, have made an impression on my heart that I do not think the world can ever efface.\"\n\nShe was flattered enough however to commit Burns's 'Cessnock Banks' verses about her to memory and when an older lady, living in Glasgow, at 74 King Street. This lady was able to repeat them, 26 years after first hearing them, to Robert Hartley Cromek of Hull, the author of the 1811 publication \"Reliques of Burns.\" He does not give the first name of Mrs Brown, simply stating that the song was from \"A lady residing in Glasgow, whom the bard in early life affectionately admired.\" Elizabeth Gebbie and her family are known to have moved to Glasgow.\n\nIsobel Burns, later Begg, provided the name Alison Begbie to the Burns biographer Dr Robert Chambers when she was 76 years of age, recollecting events and details from when she was ony 9 or 10 years old. Research by James Mackay suggests that 'Elison Begbie' was in fact a confused recollection of the name Elizabeth Gebbie, a surname which does appear in the Galston parish register. Thomas Gebbie was a tenant-farmer at Pearsland Farm near Galston and had a daughter, Elizabeth on 22 July 1762. Elizabeth married Hugh Brown at Newmilns on 23 November 1781 and had two daughters, Helen and Agnes, she had died by June 1823. This Elizabeth appears to have rejected Robert Burns which left him with a deep emotional scar, reflected possibly in the use of this Christian name for three of his daughters.\n\nShe may have been the heroine of one of Burns's earliest songs 'Farewell to Eliza.'\n\nShe may have met Burns during his visits to collect lime with his father from the Cairnhill kiln close to her home and place of work.\n\nAlthough five letters from Burns were claimed by Dr James Currie to have been sent to Alison Begbie, only one in manuscript form survives, this being the first, in which Burns hopes, using the introduction \"My dear E\", the recipient will not despise him because he is \"ignorant of the flattering arts of courtship.\" The others letters were only found in draft form among Burns's papers as lent to him by Jean Armour. A proposal of marriage is made in the fourth letter: \"If you will be so good and so generous as to admit me for your partner, your companion, your bosom friend through life, there is nothing on this side of eternity shall give me greater transport.\" it seems that he may have been too shy to propose to her in person. It is clear from the fourth letter that a reply had been received from \"My dear E\".\n\nIn an autobiographical letter Robert Burns stated that in his 23rd year \"a bellefille whom I adored\", jilted or refused him \"with peculiar circumstances of mortification.\" It was Isabella Burns who first said that Alison Begbie was the person her brother referred to, for the fifth letter in the series, supposedly to Begbie, gives no indication of the existence of any such proposal and refusal. The letters may not have been his personal letters and at all, written instead by Burns on behalf of another individual in an unrelated romantic relationship.\n\nAlison is likely to be the \"lass of Cessnock Banks\" who inspired \"On Cessnock banks a lassie dwells\", and the Peggy Alison of \"Ilk care and fear, when thou art near\", both of whom appear in the tunes of \"The Butcher Boy\" and \"Braes o' Balquidder.\" Alison may also have been the central figure of the love song \"O Mary at thy window be\" for Mary Morison, the central figure, is thought to have actually met Robert Burns on only one occasion. Burns called this \"Cessnock Lass\" work his \"Song of Similes\" and it was set to the tune \"if he be a Butcher neat and trim.\"\n\nBurns's sister relates a curious anecdote connected with Alison. Robert was sometimes very late in returning from the Cessnock Banks, and one night William Burns sat up to let him in and administer a rebuke to his son. William enquired of his son where he had been, and Burns, by way of explanation, told him that he had met the Devil in coming home. This story quite put his father off track and the rebuke was forgotten.\n\nJames Hogg, the Ettrick Shepherd, commented that \" There is no doubt hanging and marriage go by destiny, else Burns should have had this sensible girl.\"\n\n\n\n\n"}
{"id": "58056038", "url": "https://en.wikipedia.org/wiki?curid=58056038", "title": "All-Party Parliamentary Group for Choice at the End of Life", "text": "All-Party Parliamentary Group for Choice at the End of Life\n\nThe All-Party Parliamentary Group for Choice at the End of Life is a cross-party group of members of the British Parliament and Peers that supports better end-of-life options, including assisted dying. They believe that, subject to legal safeguards, terminally-ill adult patients should have the option of an assisted death in their final stages of life.\n\nIn 2012, this APPG launched a draft a bill for assisted dying which was presented to the House of Lords by Lord Falconer in 2013. The proposed bill was debated in 2014 but ran out of time in the run up to the 2015 General Election. A version of the bill tabled by Rob Marris was eventually voted on and defeated in the House of Commons in September 2015.\n\nThe chair is Conservative Party MP Nick Boles, who faced a potentially life-threatening illness before supporting the campaign. He succeeded Kit Malthouse MP as chair, who said it is \"the great human rights campaign of our political generation\". The secretary is Jim Fitzpatrick MP and the secretariat is provided by the non-profit assisted dying campaign group Dignity in Dying.\n\n"}
{"id": "324257", "url": "https://en.wikipedia.org/wiki?curid=324257", "title": "Araucaria", "text": "Araucaria\n\nAraucaria (; original pronunciation: [a.ɾawˈka. ɾja]) is a genus of evergreen coniferous trees in the family Araucariaceae. There are 20 extant species in New Caledonia (where 14 species are endemic, see New Caledonian \"Araucaria\"), Norfolk Island, eastern Australia, New Guinea, Argentina, Chile, and Brazil.\n\n\"Araucaria\" are mainly large trees with a massive erect stem, reaching a height of . The horizontal, spreading branches grow in whorls and are covered with leathery or needle-like leaves. In some species, the leaves are narrow, awl-shaped and lanceolate, barely overlapping each other; in others they are broad and flat, and overlap broadly.\n\nThe trees are mostly dioecious, with male and female cones found on separate trees, though occasional individuals are monoecious or change sex with time. The female cones, usually high on the top of the tree, are globose, and vary in size among species from diameter. They contain 80–200 large edible seeds, similar to pine nuts, though larger. The male cones are smaller, long, and narrow to broad cylindrical, broad.\n\nThe genus is familiar to many people as the genus of the distinctive Chilean pine or monkey-puzzle tree (\"Araucaria araucana\"). The genus is named after the Spanish exonym \"Araucano\" (\"from Arauco\") applied to the Mapuches of central Chile and south-west Argentina, whose territory incorporates natural stands of this genus. The Mapuche people call it ', and consider it sacred. Some Mapuches living in the Andes name themselves ' (\"people of the \"\"\") as they traditionally harvested the seeds extensively for food.\n\nNo distinct vernacular name exists for the genus. Many are called \"pine\", although they are only distantly related to true pines, in the genus \"Pinus\".\n\nMembers of \"Araucaria\" are found in Chile, Argentina, Brazil, New Caledonia, Norfolk Island, Australia, and New Guinea. There is also a significant, naturalized population of \"Araucaria columnaris\" – \"Cook's pine\" – on the island of Lanai, in Hawaii, USA. Many if not all current populations are relicts, and of restricted distribution. They are found in forest and maquis shrubland, with an affinity for exposed sites. These columnar trees are living fossils, dating back to early in the Mesozoic age. Fossil records show that the genus also formerly occurred in the northern hemisphere until the end of the Cretaceous period.\n\nBy far the greatest diversity exists in New Caledonia, due to the island's long isolation and stability. Much of New Caledonia is composed of ultramafic rock with serpentine soils, with low levels of nutrients, but high levels of metals such as nickel. Consequently, its endemic \"Araucaria\" species are adapted to these conditions, and many species have been severely affected by nickel mining in New Caledonia and are now considered threatened or endangered, due to their habitat lying in prime areas for nickel mining activities.\n\nThere is evidence to suggest that the long necks of sauropod dinosaurs may have evolved specifically to browse the foliage of the typically very tall \"Araucaria\" trees. The global distribution of vast forests of \"Araucaria\" during the Jurassic makes it likely that they were the major high energy food source for adult sauropods.\n\nThere are four extant sections and two extinct sections in the genus, sometimes treated as separate genera. Genetic studies indicate that the extant members of the genus can be subdivided into two large clades – the first consisting of the section \"Araucaria\", \"Bunya\", and \"Intermedia\"; and the second of the strongly monophyletic section \"Eutacta\". Sections \"Eutacta\" and \"Bunya\" are both the oldest taxa of the genus, with \"Eutacta\" possibly older.\n\"Araucaria bindrabunensis\" (previously classified under section \"Bunya\") has been transferred to the genus \"Araucarites\".\n\nSome of the species are relatively common in cultivation because of their distinctive, formal symmetrical growth habit. Several species are economically important for timber production.\n\nThe edible large seeds of \"A. araucana\", \"A. angustifolia\" and \"A. bidwillii\" — also known as \"Araucaria nuts\", and often called, although improperly, \"pine nuts\" — are eaten as food (particularly among the Mapuche people and Native Australians).\nIn South America \"Araucaria\" nuts or seeds are called \"piñas\", \"pinhas\", \"piñones\" or \"pinhões\", like pine nuts in Europe.\n\nPharmacological reports on genus Araucaria are anti- ulcer, antiviral, neuro-protective, anti-depressant and anti-coagulant.\n\n\n"}
{"id": "746495", "url": "https://en.wikipedia.org/wiki?curid=746495", "title": "Bioreactor", "text": "Bioreactor\n\nA bioreactor may refer to any manufactured or engineered device or system that supports a biologically active environment. In one case, a bioreactor is a vessel in which a chemical process is carried out which involves organisms or biochemically active substances derived from such organisms. This process can either be aerobic or anaerobic. These bioreactors are commonly cylindrical, ranging in size from litres to cubic metres, and are often made of stainless steel.\n\nIt may also refer to a device or system designed to grow cells or tissues in the context of cell culture. These devices are being developed for use in tissue engineering or biochemical engineering.\n\nOn the basis of mode of operation, a bioreactor may be classified as batch, fed batch or continuous (e.g. a continuous stirred-tank reactor model). An example of a continuous bioreactor is the chemostat.\n\nOrganisms growing in bioreactors may be submerged in liquid medium or may be attached to the surface of a solid medium. Submerged cultures may be suspended or immobilized. Suspension bioreactors can use a wider variety of organisms, since special attachment surfaces are not needed, and can operate at much larger scale than immobilized cultures. However, in a continuously operated process the organisms will be removed from the reactor with the effluent. Immobilization is a general term describing a wide variety of cell or particle attachment or entrapment. It can be applied to basically all types of\nbiocatalysis including enzymes, cellular organelles, animal and plant cells. Immobilization is useful for continuously operated processes, since the organisms will not be removed with the reactor effluent, but is limited in scale because the microbes are only present on the surfaces of the vessel.\n\nLarge scale immobilized cell bioreactors are: \n\nBioreactor design is a relatively complex engineering task, which is studied in the discipline of biochemical engineering. Under optimum conditions, the microorganisms or cells are able to perform their desired function with limited production of impurities. The environmental conditions inside the bioreactor, such as temperature, nutrient concentrations, pH, and dissolved gases (especially oxygen for aerobic fermentations) affect the growth and productivity of the organisms. The temperature of the fermentation medium is maintained by a cooling jacket, coils, or both. Particularly exothermic fermentations may require the use of external heat exchangers. Nutrients may be continuously added to the fermenter, as in a fed-batch system, or may be charged into the reactor at the beginning of fermentation. The pH of the medium is measured and adjusted with small amounts of acid or base, depending upon the fermentation. For aerobic (and some anaerobic) fermentations, reactant gases (especially oxygen) must be added to the fermentation. Since oxygen is relatively insoluble in water (the basis of nearly all fermentation media), air (or purified oxygen) must be added continuously. The action of the rising bubbles helps mix the fermentation medium and also \"strips\" out waste gases, such as carbon dioxide. In practice, bioreactors are often pressurized; this increases the solubility of oxygen in water. In an aerobic process, optimal oxygen transfer is sometimes the rate limiting step. Oxygen is poorly soluble in water—even less in warm fermentation broths—and is relatively scarce in air (20.95%). Oxygen transfer is usually helped by agitation, which is also needed to mix nutrients and to keep the fermentation homogeneous. Gas dispersing agitators are used to break up air bubbles and circulate them throughout the vessel.\n\n\"Fouling\" can harm the overall efficiency of the bioreactor, especially the heat exchangers. To avoid it, the bioreactor must be easily cleaned. Interior surfaces are typically made of stainless steel for easy cleaning and sanitation. Typically bioreactors are cleaned between batches, or are designed to reduce fouling as much as possible when operated continuously. Heat transfer is an important part of bioreactor design; small vessels can be cooled with a cooling jacket, but larger vessels may require coils or an external heat exchanger.\n\nA photobioreactor (PBR) is a bioreactor which incorporates some type of light source (that may be natural sunlight or artificial illumination). Virtually any translucent container could be called a PBR, however the term is more commonly used to define a closed system, as opposed to an open tank or pond.\nPhotobioreactors are used to grow small phototrophic organisms such as cyanobacteria, algae, or moss plants. These organisms use light through photosynthesis as their energy source and do not require sugars or lipids as energy\nsource. Consequently, risk of contamination with other organisms like bacteria or fungi is lower in\nphotobioreactors when compared to bioreactors for heterotroph organisms.\n\nA simplified continuous bioreactor that is designed for non-professionals, enables the growth of E. coli bacteria cells under aerobic or anaerobic conditions. These bioreactors do not rely on autoclavability, but instead rely on chemical inactivation for reuse. A laptop-sized Personal Bioreactor and Transformation station for bioengineering. It includes: continuous culturing system with remote-monitoring, real time date streaming, on-screen instructions, plate incubator, heat + ice-cold stations. Suitable for bacterial growth and culturing.\nConventional sewage treatment utilises bioreactors to undertake the main purification processes. In some of these systems, a chemically inert medium with very high surface area is provided as a substrate for the growth of biological film. Separation of excess biological film takes place in settling tanks or cyclones . In other systems aerators supply oxygen to the sewage and biota to create activated sludge in which the biological component is freely mixed in the liquor in \"flocs\". In these processes, the liquid's Biochemical Oxygen Demand (BOD) is reduced sufficiently to render the contaminated water fit for reuse. The biosolids can be collected for further processing, or dried and used as fertilizer. An extremely simple version of a sewage bioreactor is a septic tank whereby the sewage is left in situ, with or without additional media to house bacteria. In this instance, the biosludge itself is the primary host for the bacteria.\n\nIn bioreactors in which the goal is to grow cells or tissues for experimental or therapeutic purposes, the design is significantly different from industrial bioreactors. Many cells and tissues, especially mammalian ones, must have a surface or other structural support in order to grow, and agitated environments are often destructive to these cell types and tissues. Higher organisms, being auxotrophic, also require highly specialized growth media.\n\nNASA has developed a new type of bioreactor that artificially grows tissue in cell cultures. NASA's tissue bioreactor can grow heart tissue, skeletal tissue, ligaments, cancer tissue for study, and other types of tissue.\n\nFor more information on artificial tissue culture, see tissue engineering.\n\nMathematical models act as an important tool in various bio-reactor applications including wastewater treatment. These models are useful for planning efficient process control strategies and predicting the future plant performance. Moreover, these models are beneficial in education and research areas.\n\nBioreactors are generally used in those industries which are concerned with food, beverages and pharmaceuticals. The emergence of \"Biochemical engineering\" is of recent origin. Processing of biological materials using biological agents such as cells, enzymes or antibodies are the major pillars of biochemical engineering. Applications of biochemical engineering cover major fields of civilization such as agriculture, food and healthcare, resource recovery and fine chemicals.\n\nTill now, the industries associated with biotechnology have been lagged behind other industries in implementing control over the process and optimization strategies. A main drawback in biotechnological process control is the problem to measure key physical and biochemical parameters.\n\nA bioprocess is composed mainly of three stages — upstream processing, bioreaction, and downstream processing — to convert raw material to finished product.\n\nThe raw material can be of biological or non-biological origin. It is first converted to more suitable form for processing. This is done in upstream processing step which involves chemical hydrolysis, preparation of liquid medium, separation of particulate, air purification and many other preparatory operations.\n\nAfter upstream processing step, the resulting feed is transferred to one or more Bioreaction stages. The Biochemical reactors or bioreactors form the base of the Bioreaction step. This step is mainly consists of three operations namely, production of biomass, metabolize biosynthesis and biotransformation.\n\nFinally, the material produced in the bioreactor must be further processed in the downstream section to convert it into more useful form. The downstream process is mainly consists of physical separation operations which includes, solid liquid separation, adsorption, liquid-liquid extraction, distillation, drying etc.\n\nA typical bioreactor consists of following parts:\n\nAgitator – used for the mixing of the contents of the reactor which keeps the “cells” in the perfect homogenous condition for better transport of nutrients and oxygen to the desired product(s).\n\nBaffle – used to break the vortex formation in the vessel, which is usually highly undesirable as it changes the center of gravity of the system and consumes additional power.\n\nSparger – In aerobic cultivation process, the purpose of the sparger is to supply adequate oxygen to the growing cells.\n\nJacket – The jacket provides the annular area for circulation of constant temperature of water which keeps the temperature of the bioreactor at a constant value.\n\nAssumptions –\n\nMaking overall mass balance, we get the following equation:\n\nd(\"ρV)/dt = Fρ – Fρ = 0 (1)\"\n\nEquation(1) states that the reactor volume (V) is constant since dV/dt = 0.\n\nWe know,\n\nFlow rate of biomass into the reactor = Fx\n\nFlow rate of biomass out of the reactor = Fx\n\nRate of generation of biomass by reaction = Vr\n\nRate of accumulation of biomass within the reactor = d(Vx)/dt\n\nNow, apply general mass balance equation i.e.,\n\n\"Rate of Mass In – Rate of Mass Out + Rate of Generation = Accumulation\"\n\nd(Vx)/dt = Fx – Fx + Vr (2)\n\nWhere r is the rate of cell generation. Dividing both sides of the above equation by V, we obtain\n\ndx/dt = (F/V)x – (F/V)x + r (3)\n\nIn the chemical reaction engineering, F/V is called space velocity(s) and V/F is called the residence time (s). But in biochemical engineering, F/V is known as Dilution rate (D). Accordingly, equation(3) yields:\n\ndx/dt = Dx – Dx + r (4)\n\ndx/dt = D(x – x) + r (5)\n\nFor substrate balance,\n\nFlow rate of substrate into the bioreactor = FS\n\nFlow of the substrate out of the bioreactor = FS\n\nRate of generation of substrate by reaction = –Vr\n\nRate of accumulation of substrate within the reactor = d(VS)/dt\n\nNow, apply general mass balance equation i.e.,\n\n\"Rate of Mass In – Rate of Mass Out + Rate of Generation = Accumulation\"\n\nd(VS)/dt = FS – FS – Vr (6)\n\nrearranging above equation, we get\n\ndS/dt = D(S –S ) – r (7)\n\nwhere r is the rate of substrate consumption.\n\nFor the chemical reaction,\n\nA ----> P\n\nWe can write\n\nWhere,\n\n( –r) = rate of disappearance of A\n\n(r) = rate of formation of A\n\nk = reaction rate constant\n\nC = Concentration of reactant A\n\nn = order of reaction with respect to component A\n\nFor first order reaction, n = 1 and accordingly,\n\n–r = k C\n\nThe reaction kinetics involved in biochemical operations is comparatively difficult to obtain than the chemical reaction kinetics. In biochemical operations, the cell kinetics is used for the unstructured models where balanced growth condition is assumed.\n\nThe following equation is used to represent the net rate of cell mass growth:\n\nr = \"μx (10)\"\n\n\"where μ\" is the specific growth rate or specific growth rate coefficient(s). Here, \"μ\" is analogous to first order rate constant k but however, \"μ\" is not a constant.\n\nIn biochemical engineering, yield is defined as the ratio of mass or moles of product formed to the mass or moles of the reactants consumed. The yield (Y) of product (P) with respect to reactant A is defined as:\n\nY = (mass of P formed )/(mass of A consumed) (11)\n\nIn case of bioreactor,\n\nY = (mass of cells formed)/(mass of substrate consumed) (12)\n\nThus,\n\nY = r/ r\n\nOr,\n\nr = r/Y\n\nOr,\n\nr = \"μx/\"Y ( from 10) (13)\n\nBy substituting equations (10) & (13) in equations (5) & (7) respectively, we get,\n\ndx/dt = D(x – x) + \"μx\" (14)\n\ndS/dt = S(S – S) – (\"μx/Y)\" (15)\n\nSince we have assumed that the feed stream does not contain any biomass i.e., x = 0, then, bioreactor modelling equation finally get the following form:\n\ndx/dt = (\"μ\" – D)x (16)\n\ndS/dt = S(S – S) – (\"μx/Y)\" \"(from 15)\"\n\nThus,Equations (15) and (16) are the basic equations which are used for the modelling of any bioreactor.\n\n\n\n"}
{"id": "5281480", "url": "https://en.wikipedia.org/wiki?curid=5281480", "title": "Biosciences Federation", "text": "Biosciences Federation\n\nThe Biosciences Federation (BSF) was a United Kingdom body formed in 2002.\n\nThe Federation aimed to unite the bioscience community over issues of common interest that related to both research and teaching. These organisations are a key component of the UK's knowledge economy. It also aimed to influence the formulation of UK policy relating to biosciences, and to promote public debate on ethical issues. Its interests were in using knowledge gained in research to benefit society, and the impact of legislation on the life sciences industry.\n\nEach November, it would hold the \"Life Sciences Careers Conference\".\n\nDuring October 2009, the Biosciences Federation was merged with the Institute of Biology (IoB) to form the Society of Biology (which boasts some 80,000 members).\n\nThe last president of the Federation was Dame Nancy Rothwell (2006–9); Richard Dyer, former director of the Babraham Institute, was the chief executive officer (2006–9). Sir Tom Blundell was a former president (2004–6).\n\nFrom 2007, the Biosciences Federation encompassed 51 member or associated organisations that covered the entire range of life sciences; these included \n\nThe Federation responded to government consultations on biology-related issues; these responses were published on the Federation's website. It also distributed science policy news to a range of organisations that included universities, research councils, pharmaceutical companies and government bodies. The Federation hosted several life sciences careers conferences and symposia on issues such as open access publishing. It also supported the annual award for scientific communication.\n\n"}
{"id": "1963048", "url": "https://en.wikipedia.org/wiki?curid=1963048", "title": "Bloom (novel)", "text": "Bloom (novel)\n\nBloom, written in 1998, is the fifth science fiction novel written by Wil McCarthy. It was first released as a hardcover in September 1998. Almost a year later, in August 1999, its first mass market edition was published. An ebook reprint was published in 2011.\n\n\"Bloom\" is one of Borders' \"Best 10 Books of 1998\" and is a \"New York Times\" Notable Book.\nThe premise of the book is how to handle human technology that has evolved beyond human control.\n\n\"Bloom\" is set in the year 2106, in a world where self-replicating nanomachines called \"Mycora\" have consumed Earth and other planets of the inner solar system, forcing humankind to eke out a bleak living in the asteroids and Galilean moons. Two groups of humanity are described—The Immunity, who use \"ladderdown\" technology and augmented reality and live on the moons of Jupiter, and The Gladholders, who use human intelligence amplification and artificial intelligence and live in the asteroid belt. The story begins on Ganymede with an article about a “bloom”, or outbreak of Mycora, that serves to emphasize the danger and horror of this technogenic life (TGL). The article is written by Strasheim, the main character. He is first seen in the office of Lottick, portrayed as a major public figure, who has called him there for an unknown purpose.\n\nLottick tells Strasheim that the Mycora have apparently been stealing human gene sequences and may develop resistance to the coldness of the outer system, which incites concern. Readers learn that a mission to drop some TGL detectors onto Mars's, Earth's, and the Moon's polar ice caps has been approved, and Lottick asks Strasheim to go along as a reporter. For the longer term, a starship is being constructed to colonize other star systems before the Mycora.\n\nStrasheim agrees, and goes to meet the other crew-members and inspect the ship, which is called the \"Louis Pasteur\". The ship is technologically camouflaged to protect the crew against Mycora. Somehow, someone releases a Mycora bloom in the hangar, killing one crew member and forcing the others to launch the \"Pasteur\" and escape—departing three weeks earlier than planned, and without adequate supplies.\n\nBecause of their forced launch, the \"Pasteur\" docks at Saint Helier, a medium-sized Floral asteroid of the Gladholders to pick up supplies. While there, they are surprised multiple times, but what shocks them most is that the asteroid's inhabitants have apparently discovered, through powerful telescopes, human life on Venus, co-existing with the Mycora.\n\nShaken, the crew continues on their journey, but become aware that one of the crew is sabotaging the mission. The saboteur turns out to be a woman named Baucum, with which Strasheim has a conflicted, partly sexual, relationship. She is secretly a member of the Temples of Transcendent Evolution, a fringe political/religious group that believes the Mycora are divine, investing large sums of money in researching them. After being found out, Baucum ruptures a storage bag inside herself that had been carrying spores of Mycora. Terrified, the crew responds, with Strasheim himself shoving her out an airlock before the Mycora now consuming her can also devour the ship.\n\nLater, it is revealed that the mission has a somewhat more violent purpose than the crew was led to believe. The \"detectors\" they have by this time dropped on Mars, Earth, and Luna can actually be repurposed as \"cascade fusion\" devices. The mission's actual purpose was to establish small footholds on the three bodies, but it occurs to Strasheim that if such a device were detonated in the Sun, a massive blast of laddered-down iron would wipe out most Mycoran life in the inner solar system. Several of the Temples' ships have chased them since Mars, and are desperately attempting to destroy the \"Pasteur\" against this possibility (The \"Pasteur\" is heading toward the Sun to get away from the Mycosystem via an out-of-plane slingshot, but the action could have been construed differently by Temples' agents.).\n\nIt transpires that the Temples were also correct about Mycora motives, as shortly after relaying this information, the Mycora are attracted to the transmission and break through the \"Pasteur\"'s hull, blooming, and unexpectedly assuming the form of an (unspecified) pseudo-human spokesperson. A standoff ensues, but it seems the Mycora is sapient and without ill-will toward humans. Communication is brief but apparently paradigm-shattering. The ambassador explains that nearly every person consumed on Earth or on the evacuation out-system was incorporated into the Mycosystem and are still alive in some sense, their consciousness and intelligence adjusted to run on the cellular-automata-like Mycora substrate, \"Unpacked\". The crew is given information on how to mark areas as off-limits to the Mycosystem. They are told that humanity is, \"...Utterly free. Free to conduct your lives in the classical manner, to escape this solar system, to populate the stars. Free to Unpack, if you choose.\"\n\nThe book ends almost thirteen years later, with a description of how the captain of the \"Pasteur\" has been diagnosed with a terminal disease and requests that Strasheim (now a successful media magnate) be his witness as he joins the Mycora.\n\n\nNamed after Louis Pasteur the French microbiologist and chemist, the ship is described as being very small and having an unusual external covering invented by Lehne called the t-balance.\n\nAccording to Strasheim, the \"Pasteur\" is \"like a bathroom with seven shower stalls and a streetcar cockpit wedged incongruously at one end, a utility closet wedged in the other.\" Rather cramped quarters for a crew of seven going on a voyage that will take about two years.\n\nThe purpose of the t-balance is to convince the Mycora that the ship is part of it by means of tactile camouflage. It is described as a gleaming rainbow gray colored coating that appeared to be made up of millions of minuscule dots, each of which also appears to be made up of millions of tiny dots, and so on. The t-balance also gives off the illusion that the dots are moving. Unfortunately for the \"Pasteur\"'s crew, although the t-balance should work in theory, it has not yet been tested because the only way to do so is by surrounding it with Mycora.\n\n\n"}
{"id": "2748709", "url": "https://en.wikipedia.org/wiki?curid=2748709", "title": "Brick (film)", "text": "Brick (film)\n\nBrick is a 2005 American neo-noir mystery film written and directed by Rian Johnson in his directorial debut, starring Joseph Gordon-Levitt. \"Brick\" was distributed by Focus Features, and opened in New York and Los Angeles on April 7, 2006.\n\nThe film's narrative centers on a hardboiled detective story set in a Californian suburb. Most of the main characters are high school students. The film draws heavily in plot, characterization, and dialogue from hardboiled classics, especially those by Dashiell Hammett. The title refers to a block of heroin, compressed roughly to the size and shape of a brick.\n\nThe film won the Special Jury Prize for Originality of Vision at the 2005 Sundance Film Festival, and received positive reviews from critics. It has come to be regarded as a cult classic.\n\nHigh school student Brendan Frye (Joseph Gordon-Levitt) lives a lonely existence following his breakup with ex-girlfriend Emily Kostich (Emilie de Ravin) and his betrayal of his friend Jerr to the authorities. Brendan discovers a note leading him to a pay phone, where he receives a call from a terrified Emily begging him for help. She mentions a \"brick\", \"poor Frisco\", \"Tug\", and \"the Pin\" before abruptly hanging up. Her fear appears to have been caused by a passing black Ford Mustang, from which a distinctive-looking cigarette was thrown. Upon asking for information from his nerd friend Brain (Matt O'Leary), Brendan's search for Emily sends him to another ex-girlfriend, \"drama vamp\" Kara (Meagan Good), which in turn leads him to a Halloween party attended by flirtatious upper-class popular girl Laura Dannon (Nora Zehetner) and her boyfriend, Brad Bramish (Brian J. White).\n\nLaura points Brendan in the direction of a local diner, where he arranges a meeting through Dode (Noah Segan), leader of a stoner clique that Emily belongs to. Upon meeting, Emily recants what she had said on the phone and tells Brendan to let her go. Brendan steals her notepad during the encounter and finds a note that leads him directly to her dead body. Emotionally distraught by her death, Brendan takes it upon himself to solve her murder, enlisting the aid of Brain. Brendan hides the body to avoid police intrusion. Brendan discovers that \"the Pin\" (Lukas Haas) is a local drug baron. After finding out that Brad is a regular customer of the Pin's, Brendan sets about getting the latter's attention by beating up Brad. Afterwards, Brendan is in turn beaten up by an unknown young man while speaking on the phone with Brain.\n\nBrendan visits Assistant Vice Principal Trueman (Richard Roundtree) to ask him if he could investigate the events, without mentioning Emily's death, as a favour for turning in Jerr. While Trueman allows Brendan to continue his investigation, he warns that if Brendan gets caught, Trueman will \"throw him under the bus\". Brendan visits Kara, to request more information about the Pin, although she fobs him off. Later while walking, Brendan sees the same black Ford Mustang in a parking lot. Before attempting to break into the car, he is noticed and beaten up by the car's owner, who is the man who beat him previously. Brendan asks the man several times to meet the Pin. Reluctant at first, going so far as to drive away and then come back again, the young man takes Brendan to the Pin.\n\nBrendan meets with the Pin and persuades him to consider Brendan for a spot in his operation. It is also revealed that the unknown man is Tug (Noah Fleiss), the Pin's main grunt and muscle. The Pin tells Brendan he will either hire him or rub him out by the next day. On the walk back home, Laura tells Brendan that the Pin had previously rejected Emily's attempt to join, so she stole the Pin's brick. Laura then offers to help Brendan, but he distrusts her. While Brendan awaits a response from the Pin at school, he is slashed by a knife-wielding man. After a chase, Brendan incapacitates the assailant and the Pin accepts him. Brendan gets a call from Dode, who says he saw Brendan hide Emily's body and, believing Brendan is the murderer, vows to ruin him. Brendan meets with the Pin, who suspects an uprising from Tug.\n\nBrain reports that \"poor Frisco\" is Frisco Farr, a student who fell into a coma after injecting poorly-cut heroin. At the Pin's house, Tug tells Brendan that the Pin received a shipment of 10 bricks and sold eight; one was stolen and replaced with another that had been doctored with detergent, causing Frisco's coma, and the 10th brick remains to be sold. The Pin arrives and tells Tug about hearing from someone who knows what happened to Emily. Brendan, weakened from several recent fistfights, intercepts Dode before the meeting and discovers Emily was pregnant when she died. Dode hints to Tug and the Pin that he has information about who killed Emily, saying it is someone very close, but Tug goes berserk and beats Dode before shooting him in the head. Tug then threatens the Pin, who walks away as Brendan faints from a coughing fit. Brendan awakens in Tug's bedroom, where Tug says he's at war with the Pin.\n\nBrendan confronts Kara, accusing her of manipulating Dode by telling him Emily was carrying his baby and pushing him to sell his information to the Pin. Brendan arranges a meeting between Tug and the Pin, and waits in Tug's bed; Laura enters to comfort him as he sobs over Emily, and they have sex. Brendan recognizes her post-sex cigarette as the same distinctive brand that was dropped from Tug's black Mustang after Emily was frightened during the first phone call. At the meeting, chaos erupts when it is discovered that the 10th brick is now missing. Tug beats the Pin to death while Brendan flees, escaping just as police arrive. As he goes, he passes the trunk of Tug's car, where he has hidden Emily's body to ensure that police pin her murder on Tug.\n\nThe next day, Brendan meets with Laura in the school's football field. Brendan explains to Laura that he knows she set Emily up to take the fall for Laura's theft of the ninth brick. She further manipulated Emily into meeting Tug, who ultimately killed her after letting him believe he was responsible for Emily's pregnancy. It is revealed that Laura later stole the 10th brick as well. Brendan tells Laura he has put this truth in a note to Vice Principal Trueman, who will find the brick in Laura's locker if, in fact, what he says is true. Laura vindictively tells Brendan that Emily expressed regret that she couldn't keep her pregnancy because she did not love the prospective father, and that Emily was three months pregnant when she died, implying that the baby was his. Brendan watches Laura walk away.\n\n\nThe origins of \"Brick\" were Rian Johnson's obsessions with Dashiell Hammett's novels. Hammett was known for hardboiled detective novels, and Johnson wanted to make a straightforward American detective story. He had discovered Hammett's work through an interview of the Coen brothers about their 1990 gangster film, \"Miller's Crossing\". He read \"Red Harvest\" (1929) and then moved on to \"The Maltese Falcon\" (1930) and \"The Glass Key\" (1931), the latter of which had been the main influence for the Coens' film. Johnson had grown up watching detective films and film noir. Reading Hammett's novels inspired him to make his own contribution. He realized that this would result in a mere imitation and set his piece in high school to keep things fresh. Of the initial writing process he remarked \"it was really amazing how all the archetypes from that detective world slid perfectly over the high school types\". He also wanted to disrupt the visual traditions that came from the genre. Once he started making \"Brick\", he found it \"very much about the experience of being a teenager to me\". Johnson maintained that the film was not autobiographical.\n\nJohnson wrote the first draft in 1997 after graduating from USC School of Cinematic Arts a year earlier. He spent the next seven years pitching his script, but no one was interested, because the material was too unusual to make with a first-time director. Johnson estimated the minimal amount of money for which he could make the film, and asked friends and family for backing. His family were in the construction industry, and contributed enough to encourage others to contribute. After Johnson had acquired about $450,000 for the film's budget, \"Brick\" began production in 2003.\n\nAlthough the film was shot in 20 days, Johnson spent a great deal of time beforehand refining the script and three months rehearsing with the cast. He had seen Joseph Gordon-Levitt in a film called \"Manic\" (2001), met with him, and knew that he wanted to cast the young actor. He encouraged the cast to read Hammett but not to watch any noir films, because he did not want them influencing their performances. Instead, he had them watch Billy Wilder comedies like \"The Apartment\" (1960) and other comedies like \"His Girl Friday\" (1940). He was initially nervous working with a professional cast and crew for the first time but as soon as he started filming, this feeling went away and he had a good experience.\n\nJohnson shot the film in his hometown of San Clemente, California on 35 mm film stock. Much of the film takes place at San Clemente High School, which he attended. He enlisted current students to work on the film, shooting on weekends. The cinematographer was Steve Yedlin, a film school friend who had been involved with the project since the script was written.\n\nFor the telephone booth scenes, Johnson and crew filmed deep in the San Clemente suburbia. The same sign for the cross streets of Sarmentoso and Camino del Rio still stands. However, the phone booth itself was a prop the production department added in for the film.\n\nCoffee and Pie Oh My! was a Carrows restaurant, but it has since been abandoned.\n\nThe drain tunnel from the film is located just down the street from the San Clemente High School football field and goes under the freeway by the Pico exit off-ramp.\n\nJohnson had difficulty finding a run-down house for the Pin's base of operations. The production found an appropriate house, but only had a week until it was demolished to rebuild on its lot. The basement was a set that they built, but the Pin's kitchen and living room still exists at the Blarney Castle bed and breakfast. Johnson also had difficulty finding a mansion for the party scene until, with one day left to find the location, a former Telecom executive and eccentric millionaire allowed them to shoot in his place which was still under construction. The big mansion was packed from floor to ceiling with pay phones dating back to the 1950s.\n\nJohnson cited Sergio Leone Spaghetti Westerns and Shinichiro Watanabe's \"Cowboy Bebop\" (1998) as influences on his visualization of the film. He used shoes as a design element for his characters and saw them as an \"instant snapshot of the essence\" of the characters. He has also stated that many of the film's visual cues were taken from the neo-noir \"Chinatown\" (1974) with its wide-open flat spaces.\n\nThe majority of the film's special effects were cheaply and efficiently produced using practical and in-camera effects. Early in the film, for example, de Ravin walks toward the camera out of a tunnel as a garbage bag floats downstream and engulfs the camera, transitioning to Joseph Gordon-Levitt back in his character's bedroom. To achieve this, the desired effect was filmed in reverse order. The garbage bag began over the camera and was pulled away during filming, as de Ravin walked backwards into the tunnel. This footage was then cut into a scene in which a garbage bag was simply pulled over Gordon-Levitt's head.\n\nFilming a car driving slowly in reverse, then playing the footage backwards at a higher speed gives the illusion of a car quickly approaching as the camera darts in front of it stylishly. Clever fades give the impression of time changes while smash cuts add tension to a scene in which the protagonist wakes up after passing out. Certain edits were also introduced to the film to time footage to different dialogue, adding certain information and leaving other information out. These edits are noticeable, as the actors' mouths are not always moving in sync with their dialogue. One particular scene, in which de Ravin's character floated toward the camera, used a green screen, but it was edited out of the film before its completion.\n\nThe original cut of the film ran over two hours, although it was edited down to 117 minutes for the Sundance Film Festival. An additional 7 minutes were cut before the theatrical release, including a shot of Zehetner's naked back as she put her shirt back on after she and Gordon-Levitt's character had sex. According to a post by Johnson on his own forums, he felt that the nudity felt wrong in the context of the film, and that he preferred to leave the degree of intimacy ambiguous, although he occasionally finds himself second-guessing that decision.\n\nThe score to \"Brick\" was composed by Johnson's cousin, Nathan Johnson, with additional support and music from The Cinematic Underground. The score harkens back to the style, feel and overall texture of noir films. It features traditional instruments such as the piano, trumpet and violin, and also contains unique and invented instruments such as the wine-o-phone, metallophone, tack pianos, filing cabinets, and kitchen utensils, all recorded with one microphone on an Apple PowerBook. Since Nathan Johnson was in England during most of the production process, the score was composed almost entirely over Apple iChat, with Rian playing clips of the movie for Nathan, who would then score them. The two met in New York City to mix the soundtrack. The soundtrack CD of the movie was released on March 12, 2006 by Lakeshore Records. In addition to Johnson's score, it contains songs by The Velvet Underground, Anton Karas and Kay Armen as well as the big band version of \"Frankie and Johnny\" performed by Bunny Berigan and a full unedited performance of \"\" by Nora Zehetner. Johnson has confirmed that various elements in the film were influenced by \"Twin Peaks\" creator David Lynch.\n\nThe Region 1 DVD release of \"Brick\" was released on August 8, 2006 as part of the Focus Features Spotlight Series. Special features include: selection of deleted and extended scenes with introductions by Johnson; audition footage featuring Nora Zehetner and Noah Segan; and feature audio commentary with Rian Johnson, Nora Zehetner, Noah Segen, producer Ram Bergman, production designer Jodie Tillen, and costume designer Michele Posch.\n\nThe Region 2 DVD was released on September 18, 2006.\n\n\"Brick\" premiered in the United States on April 7, 2006, in two theaters. It opened to United Kingdom audiences on May 12, 2006 on a limited number of screens. According to the DVD commentary track, the film was made for just under $500,000. The film grossed US$2.07 million in North America and a total of $3.9 million worldwide.\n\n\"Brick\" has an approval rating of 80% on Rotten Tomatoes based on 137 reviews and an average score of 7.1 out of 10. The consensus states: \"This entertaining homage to noirs past has been slickly and compellingly updated to a contemporary high school setting.\" and ranked #35 on \"Entertainment Weekly\"s list of the \"50 Best High School Movies\". Based on 34 reviews, Metacritic gave it an average score of 72 out of 100 (\"Generally positive reviews\").\n\nRoger Ebert of the \"Chicago Sun-Times\" gave the film three out of four stars, stating \"[It works] in the sense that the classic Hollywood noirs worked: The story is never clear while it unfolds, but it provides a rich source of dialogue, behavior and incidents.\" The film's only serious flaw, thought Ebert, was that the characters were not entirely believable and thus it was difficult to care about the outcome of events for the characters. Peter Travers of \"Rolling Stone\" also gave the film a positive review, explaining \"A spoof would have been easy. Instead, Johnson plunges off the deep end, risking ridicule by shaping this spellbinder with grit and gravitas.\"\n\nStephen Holden of \"The New York Times\" commented, \"Mr. Haas and Mr. Gordon-Levitt at least succeed in evoking the outlines of their characters. But the film's ham-handed reliance on period argot not only wears thin; it keeps the characters, such as they are, at a chilly distance.\"\n\n\"Brick\" ranks 489th on \"Empire\" magazine's 2008 list of the 500 greatest movies of all time.\n\n"}
{"id": "46798538", "url": "https://en.wikipedia.org/wiki?curid=46798538", "title": "Budapest Reference Connectome", "text": "Budapest Reference Connectome\n\nThe Budapest Reference Connectome server computes the frequently appearing anatomical brain connections of 418 healthy subjects. It has been prepared from diffusion MRI datasets of the Human Connectome Project into a reference connectome (or brain graph), which can be downloaded in CSV and GraphML formats and visualized on the site in 3D.\n\nThe Budapest Reference Connectome has 1015 nodes, corresponding to anatomically identified gray matter areas. The user can set numerous parameters and the resulting consensus connectome is readily visualized on the webpage . Users can zoom, rotate, and query the anatomical label of the nodes on the graphical component.\n\nBudapest Reference Connectome is a consensus graph of the brain graphs of 96 subjects in Version 2 and 418 subjects in Version 3. Only those edges are returned which are present in a given percentage of the subjects. Each of the selected edges has a certain weight in each of the graphs containing that edge, so these multiple weights are combined into a single weight, by taking either their mean (i.e., average) or median. The user interface allows the customization of these parameters: the user can select the minimum frequency of the edges returned. There is an option for viewing and comparing the female or male reference connectomes. The connectomes of women contain significantly more edges than those of men, and a larger portion of the edges in the connectomes of women run between the two hemispheres.\n\nThe Budapest Reference Connectome has led the researchers to the discovery of the Consensus Connectome Dynamics of the human brain graphs. The edges appeared in all of the brain graphs form a connected subgraph around the brainstem. By allowing gradually less frequent edges, this core subgraph grows continuously, as a shrub. The growth dynamics may reflect the individual brain development and provide an opportunity to direct some edges of the human consensus brain graph.\n"}
{"id": "432459", "url": "https://en.wikipedia.org/wiki?curid=432459", "title": "Bullying", "text": "Bullying\n\nBullying is the use of force, threat, or coercion to abuse, intimidate or aggressively dominate others. The behavior is often repeated and habitual. One essential prerequisite is the perception, by the bully or by others, of an imbalance of social or physical power, which distinguishes bullying from conflict. Behaviors used to assert such domination can include verbal harassment or threat, physical assault or coercion, and such acts may be directed repeatedly towards particular targets. Rationalizations of such behavior sometimes include differences of social class, race, religion, gender, sexual orientation, appearance, behavior, body language, personality, reputation, lineage, strength, size or ability. If bullying is done by a group, it is called mobbing.\n\nBullying can be defined in many different ways. The United Kingdom has no legal definition of bullying, while some states in the United States have laws against it. Bullying is divided into four basic types of abuse – emotional (sometimes called relational), verbal, physical, and cyber. It typically involves subtle methods of coercion, such as intimidation.\n\nBullying ranges from one-on-one, individual bullying through to group bullying called mobbing, in which the bully may have one or more \"lieutenants\" who may seem to be willing to assist the primary bully in his or her bullying activities. Bullying in school and the workplace is also referred to as peer abuse. Robert W. Fuller has analyzed bullying in the context of rankism.\n\nA bullying culture can develop in any context in which humans interact with each other. This includes school, family, the workplace, home, and neighborhoods. The main platform for bullying is on social media websites. In a 2012 study of male adolescent American football players, \"the strongest predictor [of bullying] was the perception of whether the most influential male in a player's life would approve of the bullying behavior\".\n\nThere is no universal definition of bullying, however, it is widely agreed upon that bullying is a subcategory of aggressive behavior characterized by the following three minimum criteria: (1) hostile intent, (2) imbalance of power and (3) repetition over a period of time. Bullying may thus be defined as the activity of repeated, aggressive behavior intended to hurt another individual, physically, mentally or emotionally.\n\nThe Norwegian researcher Dan Olweus says bullying occurs when a person is \"exposed, repeatedly and over time, to negative actions on the part of one or more other persons\". He says negative actions occur \"when a person intentionally inflicts injury or discomfort upon another person, through physical contact, through words or in other ways.\" Individual bullying is usually characterized by a person behaving in a certain way to gain power over another person.\n\nIndividual bullying can be classified into four types. Collective bullying is known as mobbing, and can include any of the individual types of bullying.\n\nPhysical, verbal, and relational bullying are most prevalent in primary school and could also begin much earlier whilst continuing into later stages in individuals lives. It is stated that Cyber-bullying is more common in secondary school than in primary school.\n\nIndividual bullying tactics can be perpetrated by a single person against a target or targets.\n\nThis is any bullying that hurts someone's body or damages their possessions. Stealing, shoving, hitting, fighting, and destroying property all are types of physical bullying. Physical bullying is rarely the first form of bullying that a target will experience. Often bullying will begin in a different form and later progress to physical violence. In physical bullying the main weapon the bully uses is their body when attacking their target. Sometimes groups of young adults will target and alienate a peer because of some adolescent prejudice. This can quickly lead to a situation where they are being taunted, tortured, and beaten-up by their classmates. Physical bullying will often escalate over time, and can lead to a tragic ending, and therefore must be stopped quickly to prevent any further escalation.\n\nThis is any bullying that is conducted by speaking. Calling names, spreading rumors, threatening somebody, and making fun of others are all forms of verbal bullying. Verbal bullying is one of the most common types of bullying. In verbal bullying the main weapon the bully uses is their \"voice\". In many cases, verbal bullying is the province of girls. Girls are more subtle (and can be more devastating), in general, than boys. Girls use verbal bullying, as well as social exclusion techniques, to dominate and control other individuals and show their superiority and power. However, there are also many boys with subtlety enough to use verbal techniques for domination, and who are practiced in using words when they want to avoid the trouble that can come with physically bullying someone else.\n\nThis is any bullying that is done with the intent to hurt somebody's reputation or social standing which can also link in with the techniques included in physical and verbal bullying. Relational Bullying is a form of bullying common amongst youth, but particularly upon girls. Relational bullying can be used as a tool by bullies to both improve their social standing and control others. Unlike physical bullying which is obvious, relational bullying is not overt and can continue for a long time without being noticed.\n\nCyber bullying is the use of technology to harass, threaten, embarrass, or target another person. When an adult is involved, it may meet the definition of cyber-harassment or cyberstalking, a crime that can have legal consequences and involve jail time. This includes email, instant messaging, social networking sites (such as Facebook), text messages, and cell phones.\n\nCollective bullying tactics are employed by more than one individual against a target or targets. Trolling behavior on social media, although generally assumed to be individual in nature by the casual reader, is sometime organized efforts by sponsored astroturfers.\n\nMobbing refers to the bullying of an individual by a group, in any context, such as a family, peer group, school, workplace, neighborhood, community, or online. When it occurs as emotional abuse in the workplace, such as \"ganging up\" by co-workers, subordinates or superiors, to force someone out of the workplace through rumor, innuendo, intimidation, humiliation, discrediting, and isolation, it is also referred to as malicious, nonsexual, nonracial / racial, general harassment.\n\nStudies have shown that envy and resentment may be motives for bullying. Research on the self-esteem of bullies has produced equivocal results. While some bullies are arrogant and narcissistic, they can also use bullying as a tool to conceal shame or anxiety or to boost self-esteem: by demeaning others, the abuser feels empowered. Bullies may bully out of jealousy or because they themselves are bullied. Psychologist Roy Baumeister asserts that people who are prone to abusive behavior tend to have inflated but fragile egos. Because they think too highly of themselves, they are frequently offended by the criticisms and lack of deference of other people, and react to this disrespect with violence and insults.\n\nResearchers have identified other risk factors such as depression and personality disorders, as well as quickness to anger and use of force, addiction to aggressive behaviors, mistaking others' actions as hostile, concern with preserving self-image, and engaging in obsessive or rigid actions. A combination of these factors may also be causes of this behavior. In one study of youth, a combination of antisocial traits and depression was found to be the best predictor of youth violence, whereas video game violence and television violence exposure were not predictive of these behaviors.\n\nBullying may also result from a genetic predisposition or a brain abnormality in the bully. While parents can help a toddler develop emotional regulation and control to restrict aggressive behavior, some children fail to develop these skills due to insecure attachment with their families, ineffective discipline, and environmental factors such as a stressful home life and hostile siblings. Moreover, according to some researchers, bullies may be inclined toward negativity and perform poorly academically. Dr. Cook says that \"a typical bully has trouble resolving problems with others and also has trouble academically. He or she usually has negative attitudes and beliefs about others, feels negatively toward himself/herself, comes from a family environment characterized by conflict and poor parenting, perceives school as negative and is negatively influenced by peers\".\n\nContrarily, some researchers have suggested that some bullies are psychologically strongest and have high social standing among their peers, while their targets are emotionally distressed and socially marginalized. Peer groups often promote the bully's actions, and members of these peer groups also engage in behaviors, such as mocking, excluding, punching, and insulting one another as a source of entertainment. Other researchers also argued that a minority of the bullies, those who are not in-turn bullied, enjoy going to school, and are least likely to take days off sick.\n\nResearch indicates that adults who bully have authoritarian personalities, combined with a strong need to control or dominate. It has also been suggested that a prejudicial view of subordinates can be a particularly strong risk factor.\n\nOften, bullying takes place in the presence of a large group of relatively uninvolved bystanders. In many cases, it is the bully's ability to create the illusion that he or she has the support of the majority present that instills the fear of \"speaking out\" in protestation of the bullying activities being observed by the group. Unless the \"bully mentality\" is effectively challenged in any given group in its early stages, it often becomes an accepted, or supported, norm within the group.\n\nUnless action is taken, a \"culture of bullying\" is often perpetuated within a group for months, years, or longer.\n\nBystanders who have been able to establish their own \"friendship group\" or \"support group\" have been found to be far more likely to opt to speak out against bullying behavior than those who have not.\n\nIn addition to communication of clear expectations that bystanders should intervene and increasing individual self-efficacy, there is growing research that suggests interventions should build on the foundation that bullying is morally wrong.\n\nAmong adults, being a bystander to workplace bullying was linked to depression, particularly in women.\n\nDr. Cook says that \"A typical victim is likely to be aggressive, lack social skills, think negative thoughts, experience difficulties in solving social problems, come from a negative family, school and community environments and be noticeably rejected and isolated by peers\". Victims often have characteristics such as being physically weak, as well as being easily distraught emotionally. They may also have physical characteristics that make them easier targets for bullies such as being overweight or having some type of physical deformity. Boys are more likely to be victims of physical bullying while girls are more likely to be bullied indirectly.\n\nThe results of a meta-analysis conducted by Cook and published by the American Psychological Association in 2010 concluded the main risk factors for children and adolescents being bullied, and also for becoming bullies, are the lack of social problem-solving skills.\n\nChildren who are bullied often show physical or emotional signs, such as: being afraid to attend school, complaining of headaches or a loss of appetite, a lack of interest in school activities and spending time with friends or family, and having an overall sense of sadness.\n\nMona O'Moore of the Anti-Bullying Centre at Trinity College in Dublin, has written, \"There is a growing body of research which indicates that individuals, whether child or adult, who are persistently subjected to abusive behavior are at risk of stress related illness which can sometimes lead to suicide\".\nThose who have been the targets of bullying can suffer from long term emotional and behavioral problems. Bullying can cause loneliness, depression, anxiety, lead to low self-esteem and increased susceptibility to illness. Bullying has also been shown to cause maladjustment in young children, and targets of bullying who were also bullies themselves exhibit even greater social difficulties. A mental health report also found that bullying was linked to eating disorders, anxiety, body dysmorphia and other negative psychological effects.\n\nEven though there is evidence that bullying increases the risk of suicide, bullying alone does not cause suicide. Depression is one of the main reasons why kids who are bullied die by suicide. It is estimated that between 15 and 25 children die by suicide every year in the UK alone because they are being bullied. Certain groups seem to incur a higher risk for suicide, such as Native Americans, Alaskan Natives, Asian Americans, and LGBT people. When someone feels unsupported by his or her family or friends, it can make the situation much worse for the victim.\n\nIn a self-report study completed in New York by 9th through 12th graders, victims of bullying reported more depressive symptoms and psychological distress than those who did not experience bullying. All types of involvement in bullying among boys and girls, respectively, is associated with depression even a couple years later. Another study that followed up with Finnish teens two years after the initial survey showed that depression and suicidal ideation is higher with teens who are bullied than those who did not report experiencing bullying.  A Dutch longitudinal study on elementary students reported that boys who are bully-victims, who play both roles of a victim and a bully, were more likely to experience depression or serious suicidal ideation than the other roles, victims or bullies only, while girls who have any involvement in bullying have a higher level of risk for depression. In a study of high school students completed in Boston, students who self reported being victims of bullying were more likely to consider suicide when compared to youth who did not report being bullied. The same study also showed a higher risk of suicidal consideration in youth who report being a perpetrator, victim, or victim-perpetrator. Victims and victim-bullies are associated with a higher risk of suicide attempts. The place where youth live also appears to differentiate their bullying experiences such that those living in more urban areas who reported both being bullied and bullying others appear to show higher risk of suicidal ideation and suicide attempts. A national survey given to American 6th through 10th grade students found that cyberbullying victims experience a higher level of depression than victims experiencing other forms of bullying. This can be related to the anonymity behind social media. If a teen is being bullied and is displaying symptoms of depression it should be questioned and interventions should be implemented. The Danish study showed that kids who are bullied talked to their parents and teachers about it and some reported a decrease in bullying or a stop in the bullying after a teacher or parent intervened. The study emphasizes the importance of implementing program-collaborations in schools to have programs and anti-bullying interventions in place to prevent and properly intervene when it occurs. The study also shows the importance of having parents and teachers talk to the bullies about their bullying behavior in order to provide the necessary support for those experiencing bullying.\n\nWhile some people find it very easy to ignore a bully, others may find it very difficult and reach a breaking point. There have been cases of apparent bullying suicides that have been reported closely by the media. These include the deaths of Ryan Halligan, Phoebe Prince, Dawn-Marie Wesley, Nicola Ann Raphael, Megan Meier, Audrie Pott, Tyler Clementi, Jamey Rodemeyer, Kenneth Weishuhn, Jadin Bell, Kelly Yeomans, Rehtaeh Parsons, Amanda Todd, Brodie Panlock, Jessica Haffer, Hamed Nastoh, Sladjana Vidovic, April Himes, Cherice Moralez and Rebecca Ann Sedwick. According to the suicide awareness voices for education, suicide is one of the leading causes of death for youth from 15 to 24 years old. Over 16 percent of students seriously consider suicide, 13 percent create a plan, and 8 percent have made a serious attempt.\n\nSome have argued that bullying can teach life lessons and instill strength. Helene Guldberg, a child development academic, sparked controversy when she argued that being a target of bullying can teach a child \"how to manage disputes and boost their ability to interact with others\", and that teachers should not intervene, but leave children to respond to the bullying themselves.\n\nThe teaching of such anti-bullying coping skills to \"would-be-targets\" and to others has been found to be an effective long term means of reducing bullying incidence rates and a valuable skill-set for individuals.\n\nResearch on the dark triad (narcissism, Machiavellianism and psychopathy) indicate a correlation with bullying as part of evidence of the aversive nature of those traits.\n\nA bully may project his/her own feelings of vulnerability onto the target(s) of the bullying activity. Despite the fact that a bully's typically denigrating activities are aimed at the bully's targets, the true source of such negativity is ultimately almost always found in the bully's own sense of personal insecurity and/or vulnerability. Such aggressive projections of displaced negative emotions can occur anywhere from the micro-level of interpersonal relationships, all the way up through to the macro-level of international politics, or even international armed conflict.\n\nBullying is abusive social interaction between peers which can include aggression, harassment, and violence. Bullying is typically repetitive and enacted by those who are in a position of power over the victim. A growing body of research illustrates a significant relationship between bullying and emotional intelligence (EI). Mayer et al., (2008) defines the dimensions of overall EI as: \"accurately perceiving emotion, using emotions to facilitate thought, understanding emotion, and managing emotion\". The concept combines emotional and intellectual processes. Lower emotional intelligence appears to be related to involvement in bullying, as the bully and/or the victim of bullying. EI seems to play an important role in both bullying behavior and victimization in bullying; given that EI is illustrated to be malleable, EI education could greatly improve bullying prevention and intervention initiatives.\n\nCyberbullying is any bullying done through the use of technology. This form of bullying can easily go undetected because of lack of parental/authoritative supervision. Because bullies can pose as someone else, it is the most anonymous form of bullying. Cyberbullying includes, but is not limited to, abuse using email, instant messaging, text messaging, websites, social networking sites, etc. With the creation of social networks like Facebook, Myspace, Instagram, and Twitter, cyberbullying has increased. Particular watchdog organizations have been designed to contain the spread of cyberbullying.\n\nIt has been noted that disabled people are disproportionately affected by bullying and abuse, and such activity has been cited as a hate crime. The bullying is not limited to those who are visibly disabled, such as wheelchair-users or physically deformed such as those with a cleft lip, but also those with learning disabilities, such as autism and developmental coordination disorder.\n\nThere is an additional problem that those with learning disabilities are often not as able to explain things to other people, so are more likely to be disbelieved or ignored if they do complain.\n\nGay bullying and gay bashing designate direct or indirect verbal or physical actions by a person or group against someone who is gay or lesbian, or perceived to be so due to rumors or because they are considered to fit gay stereotypes. Gay and lesbian youth are more likely than straight youth to report bullying.\n\nLegal bullying is the bringing of a vexatious legal action to control and punish a person. Legal bullying can often take the form of frivolous, repetitive, or burdensome lawsuits brought to intimidate the defendant into submitting to the litigant's request, not because of the legal merit of the litigant's position, but principally due to the defendant's inability to maintain the legal battle. This can also take the form of Strategic Lawsuit Against Public Participation (SLAPP). It was partially concern about the potential for this kind of abuse that helped to fuel the protests against SOPA and PIPA in the United States in 2011 and 2012.\n\nIn 2000, the UK Ministry of Defence (MOD) defined bullying as \"the use of physical strength or the abuse of authority to intimidate or victimize others, or to give unlawful punishments\".\n\nSome argue that this behaviour should be allowed, due to ways in which \"soldiering\" is different from other occupations. Soldiers expected to risk their lives should, according to them, develop strength of body and spirit to accept bullying.\n\nParents who may displace their anger, insecurity, or a persistent need to dominate and control upon their children in excessive ways have been proven to increase the likelihood that their own children will in turn become overly aggressive or controlling towards their peers.\nThe American Psychological Association advises on its website that parents who may suspect that their own children may be engaging in bullying activities among their peers should carefully consider the examples which they themselves may be setting for their own children regarding how they typically interact with their own peers, colleagues, and children.\n\nAn environment known for bullying is in prisons. An additional complication is the staff and their relationships with the inmates. Thus the following possible bullying scenarios are possible:\n\nBullying can occur in nearly any part in or around the school building, although it may occur more frequently during physical education classes and activities such as recess. Bullying also takes place in school hallways, bathrooms, on school buses and while waiting for buses, and in classes that require group work and/or after school activities. Bullying in school sometimes consists of a group of students taking advantage of or isolating one student in particular and gaining the loyalty of bystanders who want to avoid becoming the next target. In the 2011 documentary \"Bully\", we see first hand the torture that kids go through both in school and while on the school bus. As the movie follows around a few kids we see how bullying affects them both at school as well as in their homes. While bullying has no age limit, these bullies may taunt and tease their target before finally physically bullying them. Bystanders typically choose to either participate or watch, sometimes out of fear of becoming the next target.\n\nBullying can also be perpetrated by teachers and the school system itself; there is an inherent power differential in the system that can easily predispose to subtle or covert abuse (relational aggression or passive aggression), humiliation, or exclusion — even while maintaining overt commitments to anti-bullying policies.\n\nIn 2016, in Canada, a North American legal precedent was set by a mother and her son, after the son was bullied in his public school. The mother and son won a court case against the Ottawa-Carleton District School Board, making this the first case in North America where a school board has been found negligent in a bullying case for failing to meet the standard of care (the \"duty of care\" that the school board owes to its students). Thus, it sets a precedent of a school board being found liable in negligence for harm caused to a child, because they failed to protect a child from the bullying actions of other students. There has been only one other similar bullying case and it was won in Australia in 2013 (Oyston v. St. Patricks College, 2013).\n\nSexual bullying is \"Any bullying behaviour, whether physical or non-physical, that is based on a person's sexuality or gender. It is when sexuality or gender is used as a weapon by boys or girls towards other boys or girls – although it is more commonly directed at girls. It can be carried out to a person's face, behind their back or through the use of technology.\"\n\nTrans bashing is the act of victimizing a person physically, sexually, or verbally because they are transgender or transsexual. Unlike gay bashing, it is committed because of the target's actual or perceived gender identity, not sexual orientation.\n\nWorkplace bullying occurs when an employee experiences a persistent pattern of mistreatment from others in the workplace that causes harm. Workplace bullying can include such tactics as verbal, nonverbal, psychological, physical abuse and humiliation. This type of workplace aggression is particularly difficult because, unlike the typical forms of school bullying, workplace bullies often operate within the established rules and policies of their organization and their society. Bullying in the workplace is in the majority of cases reported as having been perpetrated by someone in authority over the target. However, bullies can also be peers, and occasionally can be subordinates.\n\nThe first known documented use of \"workplace bullying\" is in 1992 in a book by Andrea Adams called \"Bullying at Work: How to Confront and Overcome It\".\n\nResearch has also investigated the impact of the larger organizational context on bullying as well as the group-level processes that impact on the incidence, and maintenance of bullying behavior. Bullying can be covert or overt. It may be missed by superiors or known by many throughout the organization. Negative effects are not limited to the targeted individuals, and may lead to a decline in employee morale and a change in organizational culture. A Cochrane Collaboration systematic review has found very low quality evidence to suggest that organizational and individual interventions may prevent bullying behaviors in the workplace.\n\nBullying in academia is workplace bullying of scholars and staff in academia, especially places of higher education such as colleges and universities. It is believed to be common, although has not received as much attention from researchers as bullying in some other contexts.\n\nBullying has been identified as prominent in blue collar jobs, including on oil rigs and in mechanic shops and machine shops. It is thought that intimidation and fear of retribution cause decreased incident reports. In industry sectors dominated by males, typically of little education, where disclosure of incidents are seen as effeminate, reporting in the socioeconomic and cultural milieu of such industries would likely lead to a vicious circle. This is often used in combination with manipulation and coercion of facts to gain favour among higher-ranking administrators.\n\nA culture of bullying is common in information technology (IT), leading to high sickness rates, low morale, poor productivity, and high staff-turnover. Deadline-driven project work and stressed-out managers take their toll on IT workers.\n\nBullying in the legal profession is believed to be more common than in some other professions. It is believed that its adversarial, hierarchical tradition contributes towards this. Women, trainees and solicitors who have been qualified for five years or less are more impacted, as are ethnic minority lawyers and lesbian, gay and bisexual lawyers.\n\nBullying in the medical profession is common, particularly of student or trainee doctors and of nurses. It is thought that this is at least in part an outcome of conservative traditional hierarchical structures and teaching methods in the medical profession, which may result in a bullying cycle.\n\nEven though The American Nurses Association believes that all nursing personnel have the right to work in safe, non-abusive environments, bullying has been identified as being particularly prevalent in the nursing profession although the reasons are not clear. It is thought that relational aggression (psychological aspects of bullying such as gossipping and intimidation) are relevant. Relational aggression has been studied among girls but not so much among adult women.\n\nSchool teachers are commonly the subject of bullying but they are also sometimes the originators of bullying within a school environment.\n\nAs the verb \"to bully\" is defined as simply \"forcing one's way aggressively or by intimidation\", the term may generally apply to any life experience where one is motivated primarily by intimidation instead of by more positive goals, such as mutually shared interests and benefits. As such, any figure of authority or power who may use intimidation as a primary means of motivating others, such as a neighborhood \"protection racket don\", a national dictator, a childhood ring-leader, a terrorist, a terrorist organization, or even a ruthless business CEO, could rightfully be referred to as a bully. According to psychologist Pauline Rennie-Peyton, we each face the possibility of being bullied in any phase of our lives.\n\nChildren have been observed bullying anthropomorphic robots designed to assist the elderly. Their attacks start with blocking the robots' paths of movement and then escalate to verbal abuse, hitting and destroying the object. Seventy-five percent of the kids interviewed perceived the robot as \"human-like\" yet decided to abuse it anyway, while 35% of the kids who beat up the robot actually did so \"for enjoyment.\".\n\nBullying prevention is the collective effort to prevent, reduce and stop bullying. Many campaigns and events are designated to bullying prevention throughout the world. Bullying prevention campaigns and events include: Anti-Bullying Day, Anti-Bullying Week, International Day of Pink, International STAND UP to Bullying Day and National Bullying Prevention Month. Anti-Bullying laws in the U.S. have also been enacted in 23 of its 50 states, making bullying in schools illegal.\n\nBullying is typically ongoing and not isolated behaviour. Common ways that people try to respond, are to try to ignore it, to confront the bullies or to turn to an authority figure to try and address it.\n\nIgnoring it often does nothing to stop the bullying continuing, and it can become worse over time.\nIt can be important to address bullying behaviour early on, as it can be easier to control the earlier it is detected.\nBystanders play an important role in responding to bullying, as doing nothing can encourage it to continue, while small steps that oppose the behaviour can reduce it.\n\nAuthority figures can play an important role, such as parents in child or adolescent situations, or supervisors, human-resources staff or parent-bodies in workplace and volunteer settings. Authority figures can be influential in recognising and stopping bullying behaviour, and creating an environment where it doesn't continue.\nIn many situations however people acting as authority figures are untrained and unqualified, do not know how to respond, and can make the situation worse.\nIn some cases the authority figures even support the people doing the bullying, facilitating it continuing and increasing the isolation and marginalising of the target.\nSome of the most effective ways to respond, are to recognise that harmful behaviour is taking place, and creating an environment where it won't continue.\nPeople that are being targeted have little control over which authority figures they can turn to and how such matters would be addressed, however one means of support is to find a counsellor or psychologist that is trained in handling bullying.\n\nThe word \"bully\" was first used in the 1530s meaning \"sweetheart\", applied to either sex, from the Dutch \"boel\" \"lover, brother\", probably diminutive of Middle High German \"buole\" \"brother\", of uncertain origin (compare with the German \"buhle\" \"lover\"). The meaning deteriorated through the 17th century through \"fine fellow\", \"blusterer\", to \"harasser of the weak\". This may have been as a connecting sense between \"lover\" and \"ruffian\" as in \"protector of a prostitute\", which was one sense of \"bully\" (though not specifically attested until 1706). The verb \"to bully\" is first attested in 1710.\n\nIn the past, in American culture, the term has been used differently, as an exclamation/exhortation, in particular famously associated with Theodore Roosevelt and continuing to the present in the bully pulpit and also as faint/deprecating praise (\"bully for him\").\n\n\n"}
{"id": "5769143", "url": "https://en.wikipedia.org/wiki?curid=5769143", "title": "Christian views on Hell", "text": "Christian views on Hell\n\nIn Christian theology, Hell is the place or state into which by God's definitive judgment unrepentant sinners pass either immediately after death (particular judgment) or in the general judgment. Its character is inferred from teaching in the biblical texts, some of which, interpreted literally, have given rise to the popular idea of Hell.\n\nTheologians today generally see Hell as the logical consequence of using free will to reject union with God and, because God will not force conformity, not incompatible with God's justice and mercy.\n\nDifferent Hebrew and Greek words are translated as \"Hell\" in most English-language Bibles. They include:\n\n\nIn ancient Jewish belief, the dead were consigned to \"Sheol\", a place to which all were sent indiscriminately (cf. ; ; ; ). \"Sheol\" was thought of as a place situated below the ground (cf. ), a place of darkness, silence and forgetfulness (cf. Job 10:21). By the third to second century BC, the idea had grown to encompass separate divisions in \"sheol\" for the righteous and wicked (cf. the Book of Enoch), and by the time of Jesus, some Jews had come to believe that those in Sheol awaited the resurrection of the dead either in comfort (in the bosom of Abraham) or in torment.\n\nBy at least the late rabbinical period, \"Gehinnom\" was viewed as the place of ultimate punishment, exemplified by the rabbinical statement \"the best of physicians are destined to Gehinnom.\" (M. Kiddushin 4:14); also described in Assumption of Moses and 2 Esdras. The term is derived from \"Gei Ben-Hinnom\", a valley near Jerusalem originally used as a location for human sacrifices to the idol Moloch:\n\nIn the Greek Septuagint the Hebrew word \"Sheol\" was translated as \"Hades\", the name for the underworld and abode of the dead in Greek mythology. The realm of eternal punishment in Hellenistic mythology was \"Tartarus\", \"Hades\" was a form of limbo for the unjudged dead.\n\nThree different New Testament words appear in most English translations as \"Hell\":\n\nThe most common New Testament term translated as \"Hell\" is (\"gehenna\"), a direct loan of Hebrew גהנום/גהנם (\"ge-hinnom\"). Apart from one use in , this term is found exclusively in the synoptic gospels. \"Gehenna\" is most frequently described as a place of fiery torment (e.g., Matthew 5:22, 18:8-9; Mark 9:43-49); other passages mention darkness and \"weeping and gnashing of teeth\" (e.g., Matthew 8:12; 22:13).\n\nApart from the use of the term \"gehenna\" (translated as \"Hell\" or \"Hell fire\" in most English translations of the Bible; sometimes transliterated, or translated differently) the Johannine writings refer to the destiny of the wicked in terms of \"perishing\", \"death\" and \"condemnation\" or \"judgment\". Paul speaks of \"wrath\" and \"everlasting destruction\" (cf. ; ), while the general epistles use a range of terms and images including \"raging fire\" (), \"destruction\" (), \"eternal fire\" () and \"blackest darkness\" (). The Book of Revelation contains the image of a \"lake of fire\" and \"burning sulphur\" where \"the devil, the beast, and false prophet\" will be \"tormented day and night for ever and ever\" () along with those who worship the beast or receive its mark ().\n\nThe New Testament also uses the Greek word \"hades\", usually to refer to the abode of the dead (e.g., ; ). Only one passage describes \"hades\" as a place of torment, the parable of Lazarus and Dives (). Jesus here depicts a wicked man suffering fiery torment in \"hades\", which is contrasted with the bosom of Abraham, and explains that it is impossible to cross over from one to the other. Some scholars believe that this parable reflects the intertestamental Jewish view of \"hades\" (or \"sheol\") as containing separate divisions for the wicked and righteous. In \"hades\" is itself thrown into the \"lake of fire\" after being emptied of the dead.\n\nIn the eschatological discourse of , Jesus says that, when the Son of Man comes in his glory, he will separate people from one another as a shepherd separates sheep from goats, and will consign to everlasting fire those who failed to aid \"the least of his brothers\". This separation is stark, with no explicit provision made for fine gradations of merit or guilt:\nIn a parable about \"The Rich Man and Lazarus\" in , the poor man Lazarus enjoys a blissful repose in the \"bosom of Abraham\" (), while the rich man who was happy in life is tormented by fire in Hades (), the two realms being separated by a great chasm ().\n\nThe Eastern Orthodox Church teaches that Heaven and Hell are relations to or experiences of God's just and loving presence. There is no created place of divine absence, nor is hell an ontological separation from God. One expression of the Eastern teaching is that hell and heaven are dimensions of God's intensifying presence, as this presence is experienced either as torment or as paradise depending on the spiritual state of a person dwelling with God. For one who hates God and by extension hates himself as God's image-bearer, to be encompassed by the divine presence could only result in unspeakable anguish. Aristotle Papanikolaou and Elizabeth H. Prodromou wrote in their book \"Thinking Through Faith: New Perspectives from Orthodox Christian Scholars\" that for the Orthodox: \"Those theological symbols, heaven and hell, are not crudely understood as spatial destinations but rather refer to the experience of God's presence according to two different modes.\" Several Orthodox theologians do describe hell as separation from God, in the sense of being out of fellowship or loving communion. Archimandrite Sophrony (Sakharov) spoke of \"the hell of separation from God\". Paul Evdokimov stated: \"Hell is nothing else but separation of man from God, his autonomy excluding him from the place where God is present.\" According to Theodore Stylianopoulos, \"Hell is a spiritual state of separation from God and inability to experience the love of God, while being conscious of the ultimate deprivation of it as punishment.\" Michel Quenot stated: \"Hell is none other than the state of separation from God, a condition into which humanity was plunged for having preferred the creature to the Creator. It is the human creature, therefore, and not God, who engenders hell. Created free for the sake of love, man possesses the incredible power to reject this love, to say 'no' to God. By refusing communion with God, he becomes a predator, condemning himself to a spiritual death (hell) more dreadful than the physical death that derives from it.\" Another writer declared: \"The circumstances that rise before us, the problems we encounter, the relationships we form, the choices we make, all ultimately concern our eternal union with or separation from God.\"\n\nThe Eastern Orthodox Church rejects what is presented as the Roman Catholic doctrine of purgatory as a place where believers suffer as their \"venial sins\" are purged before gaining admittance to heaven.\n\nContrary to Western Christianity, both Roman and Protestant varieties, the Christians of the East emphasize the mystery of God in His pre-eternal transcendence and maintain a tradition of apophatic theology, while the technical, cataphatic theology of scholasticism tends to be downplayed or viewed as subordinate. Thus, there is no single \"official\" teaching of the Church apart from apostolic doctrine received and, when necessary, defined by Ecumenical Councils. The Orthodox positions on hell are derived from the sayings of the saints and the consensus views of the Church Fathers. They are not in agreement on all points, and no council universally recognized by the Eastern Orthodox Churches has formulated doctrine on hell, so there is no official doctrine to which all the faithful are bound. Beliefs concerning the nature and duration of hell are considered \"theologoumena\", or theological opinions, rather than dogmas of the Church.\n\nSaint John Chrysostom pictured Hell as associated with \"unquenchable\" fire and \"various kinds of torments and torrents of punishment\". \n\nEastern Orthodox icons of the Last Judgment, most notably in the Slavic traditions, often depict tormented, lost sinners in Hell. Pages 66–69 of John-Paul Himka's \"Last Judgment Iconography in the Carpathians\" provides an illustrated description of some such 15th-century Carpathian icons based on a northern Rus' prototype (p. 193). The depiction in these particular icons, a depiction that may have developed from 12th-century Greek and South Slavic depictions differentiating sinners and their punishments (p. 68), is referred to by Himka as \"the new hell\", \"because various sinners are being punished in a squarish area with torments that did not appear in the standard Byzantine iconography\" (p. 42).\n\nIcons based on \"The Ladder of Divine Ascent\", by Saint John Climacus, show monks ascending a thirty-rung ladder to Heaven represented by Christ, or succumbing to the arrows of demons and falling from the ladder into Hell, sometimes represented by an open-jawed dragon.\n\nAquinas uses an analogy of buoyancy:\nThe \"Catechism of the Catholic Church\" which, when published in 1992, Pope John Paul II declared to be \"a sure norm for teaching the faith\", defines hell as eternal fiery punishment for refusing to love God:\n\nThe Catechism published by Pope Pius X in 1908 defined Hell by using the word \"state\" alone: \"Hell is a state to which the wicked are condemned, and in which they are deprived of the sight of God for all eternity, and are in dreadful torments.\"\n\nPope John Paul II stated on 28 July 1999, that, in speaking of Hell as a place, the Bible uses \"a symbolic language\", which \"must be correctly interpreted … Rather than a place, hell indicates the state of those who freely and definitively separate themselves from God, the source of all life and joy.\" Some have interpreted these words as a denial that Hell can be considered to be a place, or at least as providing an alternative picture of Hell. Others have explicitly disagreed with the interpretation of what the Pope said as an actual denial that Hell can be considered a place and have said that the Pope was only directing attention away from what is secondary to the real essence of hell.\n\nCatholic theologian Hans Urs von Balthasar (1905–1988) said that \"we must see that hell is not an object that is 'full' or 'empty' of human individuals, but a possibility that is not 'created' by God but in any case by the free individuals who choose it\". \n\nThe \"Catholic Faith Handbook for Youth\", with imprimatur of 2007, also says that \"more accurately\" heaven and hell are not places but states. \n\nCapuchin theologian Berard A. Marthaler also says that \"hell is not 'a place'\".\nTraditionally in the past Hell has been spoken of or considered as a place. Some have rejected metaphorical interpretations of the biblical descriptions of hell, and have attributed to Hell a location within the earth, while others who uphold the opinion that hell is a definite place, say instead that its location is unknown. \n\nIn a homily given on 25 March 2007, Pope Benedict XVI stated: \"Jesus came to tell us that he wants us all in heaven and that hell, of which so little is said in our time, exists and is eternal for those who close their hearts to his love.\" Journalist Richard Owen's interpretation of this remark as declaring that hell is an actual place was reported in many media. But in the \"Catechism of the Catholic Church\" (1035), over whose production Benedict presided when he was prefect of the Congregation for the Doctrine of the Faith, we read: \"The chief punishment of hell is eternal separation from God\".\n\nWriting in the 1910 \"Catholic Encyclopedia\", Joseph Hontheim said that \"theologians generally accept the opinion that hell is really within the earth. The Catholic Church has decided nothing on this subject; hence we may say hell is a definite place; but where it is, we do not know.\" He cited the view of Saint Augustine of Hippo that Hell is under the earth and that of Saint Gregory the Great that hell is either on the earth or under it.\n\nThe posthumous supplement to Aquinas' Summa theologiciae suppl. Q97 A4 flags discussion of the location of hell as speculation: \"As Augustine says (De Civ. Dei xv, 16), \"I am of opinion that no one knows in what part of the world hell is situated, unless the Spirit of God has revealed this to some one.\"\"\nOther Catholics neither affirm nor deny that hell is a place, and speak of it as \"a place or state\". Ludwig Ott's work \"The Fundamentals of Catholic Dogma\" said: \"Hell is a place or state of eternal punishment inhabited by those rejected by God\". Robert J. Fox wrote: \"Hell is a place or state of eternal punishment inhabited by those rejected by God because such souls have rejected God's saving grace.\" Evangelicals Norman L. Geisler and Ralph E. MacKenzie interpret official Roman Catholic teaching as: \"Hell is a place or state of eternal punishment inhabited by those rejected by God.\"\n\nIt is agreed that hell is a place of suffering.\n\nThe \"Catechism of the Catholic Church\" states:\n\nAlthough the Catechism explicitly speaks of the punishments of hell in the plural, calling them \"eternal fire\", and speaks of eternal separation from God as the \"chief\" of those punishments, one commentator claims that it is non-committal on the existence of forms of punishment other than that of separation of God: after all, God, being above all a merciful and loving entity, takes no pleasure in the death of the living, and does not will or predestine anyone to go there (the Catholic stance is that God does not will suffering, and that the only entities known to be in hell beyond a doubt are Satan and his evil angels, and that the only suffering in hell is not fire or torture, but the freely-chosen, irrevocable and unescapable eternal separation from God and his freely given love, and the righteous, who are in heaven; thus the Church and the Popes have placed emphasis on the potential irreversibility of a mortally sinful life that goes un-absolved before one's death, and the dogma and reality of the place or state of hell). Another interpretation is that the Catechism by no means denies other forms of suffering, but stresses that the pain of loss is central to the Catholic understanding of hell.\n\nSaint Augustine of Hippo said that the suffering of hell is compounded because God continues to love the sinner who is not able to return the love. According to the Church, whatever is the nature of the sufferings, \"they are not imposed by a vindictive judge\"\n\n\"Concerning the detailed specific nature of hell ... the Catholic Church has defined nothing. ... It is useless to speculate about its true nature, and more sensible to confess our ignorance in a question that evidently exceeds human understanding.\"\n\nIn his book, \"Inventing Hell\", Catholic writer and historian Jon M. Sweeney is critical of the ways that Christians have appropriated Dante's vision and images of hell. In its review, \"Publishers Weekly\" called the book \"persuasively argued.\" An article on the same subject by Sweeney that was published on the Huffington Post's religion page was liked by more than 19,000 people, including Anne Rice.\n\nA number of Catholic mystics and saints have claimed to have received visions of hell or other revelations concerning hell. During various Marian apparitions, such as those at Fatima or at Kibeho, the visionaries claimed that the Virgin Mary during the course of the visions showed them a view of hell where sinners were suffering.\n\nIn the Bible, in the Book of Revelation, John of Patmos writes about seeing a lake of fire where the 'beast' and all those marked with his number were placed.\n\nColumba of Iona is alleged to have on several occasions even been able to name particular individuals who he said were going to end life in hellfire for their sins and accurately predicted the way they would die before the event had even happened.\nA story recorded by Cluniac monks in the Middle Ages claimed that St Benedict appeared to a monk on one occasion and told the monk that there had just been (at that point in time) a monk who had fled the monastic life to go back into the world, and the ex-monk then died and he went to hell.\n\nAt the level of particular individuals:\n\nPope John Paul II pointed out in \"Crossing the Threshold of Hope\", the Church has never taught that even Judas Iscariot is damned. That said, the gospels do have Jesus say that he would be better off to never be born. \n\nPope Pius IX stated exclusions that seemingly apply to infancy, incapacity, invincible ignorance:\n\nThe Church proclaims the availability of redemption, but it does not teach universal salvation, which would constrain God, nor it does have defined detailed doctrines on edge case such as the state or location of unbaptised infants who die, since these go beyond what has been specifically revealed.\n\nHowever, in long Catholic tradition and the recent Vatican publications ( The Hope of Salvation for Infants Who Die without Being Baptized), unbaptized infants who die would not be described as being in the Hell of punishment, but may enjoy the beatific vision.\nPope Benedict XVI commented on the Catechism passage given above:\n\nWriter Mark Shea notes that the Church \"prays in her liturgy that all will be saved. You can’t pray for the impossible.\" The recent controversial view of Hans Urs von Balthasar in his book \"Dare we Hope that all Men be Saved?\", which draws on speculation by St Edith Stein, proposes that it is legitimate for Catholics to none-the-less hope for the possibility that Hell will be empty, without using that as an excuse for sin. Balthasar's view is that God's \"mercy\" and \"goodness\" are greater than his \"justice\", because \"between the misdeeds of the creature and the goodness of God there is no equilibrium\".\n\nThe varying Protestant views of \"hell\", both in relation to Hades (i.e., the abode of the dead) and Gehenna (i.e., the destination of the wicked), are largely a function of the varying Protestant views on the intermediate state between death and resurrection; and different views on the immortality of the soul or the alternative, the conditional immortality. For example, John Calvin, who believed in conscious existence after death, had a very different concept of hell (Hades and Gehenna) to Martin Luther who held that death was sleep.\n\nIn most Protestant traditions, hell is the place created by God for the punishment of the devil and fallen angels (cf. ), and those whose names are not written in the book of life (cf. ). It is the final destiny of every person who does not receive salvation, where they will be punished for their sins. People will be consigned to hell after the last judgment.\n\nOne historic Protestant view of hell is expressed in the Westminster Confession (1646):\n\nAccording to the Alliance Commission on Unity & Truth among Evangelicals (ACUTE) the majority of Protestants have held that hell will be a place of unending conscious torment, both physical and spiritual, although some recent writers such as Anglo-Catholic C. S. Lewis and J.P. Moreland have cast hell in terms of \"eternal separation\" from God. Certain biblical texts have led some theologians to the conclusion that punishment in hell, though eternal and irrevocable, will be proportional to the deeds of each soul (e.g., , ).\n\nAnother area of debate is the fate of the unevangelized (i.e.,those who have never had an opportunity to hear the Christian gospel), those who die in infancy, and the mentally disabled. According to ACUTE some Protestants agree with Augustine that people in these categories will be damned to hell for original sin, while others believe that God will make an exception in these cases.\n\nA minority of Protestants believe in the doctrine of conditional immortality, which teaches that those sent to hell will not experience eternal conscious punishment, but instead will be extinguished or annihilated after a period of \"limited conscious punishment\".\n\nProminent evangelical theologians who have adopted conditionalist beliefs include John Wenham, Edward Fudge, Clark Pinnock and John Stott (although the last has described himself as an \"agnostic\" on the issue of annihilationism). Conditionalists typically reject the traditional concept of the immortality of the soul.\n\nThe Seventh-day Adventist Church, Jehovah's Witnesses and Christadelphians teach the annihilationist viewpoint.\n\nThough a theological minority in historical and contemporary Christianity, some holding mostly Protestant views (such as George MacDonald, Karl Barth, William Barclay, Keith DeRose and Thomas Talbott) believe that after serving their sentence in Gehenna, all souls are reconciled to God and admitted to heaven, or ways are found at the time of death of drawing all souls to repentance so that no \"hellish\" suffering is experienced. This view is often called Christian universalism—its conservative branch is more specifically called 'Biblical or Trinitarian universalism'—and is not to be confused with Unitarian Universalism. See universal reconciliation, \"apocatastasis\" and the Problem of Hell.\n\nChristian Universalism teaches that an eternal hell does not exist and is a later creation of the church with no biblical support. Reasoning by Christian Universalists includes that an eternal hell is against the nature, character and attributes of a loving God, human nature, sin's nature of destruction rather than perpetual misery, the nature of holiness and happiness and the nature and object of punishment.\n\nChristian Science defines \"hell\" as follows: \"Mortal belief; error; lust; remorse; hatred; revenge; sin; sickness; death; suffering and self-destruction; self-imposed agony; effects of sin; that which 'worketh abomination or maketh a lie. '\" (Science and Health with Key to the Scripture by Mary Baker Eddy, 588: 1-4.)\n\nJehovah's Witnesses do not believe in an immortal soul that survives after physical death. They believe the Bible presents \"hell\", as translated from \"Sheol\" and \"Hades\", to be the common grave for both the good and the bad. They reject the idea of a place of literal eternal pain or torment as being inconsistent with God's love and justice. They define \"Gehenna\" as eternal destruction or the \"second death\", reserved for those with no opportunity of a resurrection such as those destroyed at Armageddon. Jehovah's Witnesses believe that others who have died before Armageddon will be resurrected bodily on earth and then judged during the 1,000-year rule of Christ; the judgement will be based on their obedience to God's laws after their resurrection.\n\nThe Christadelphian view is broadly similar, except that they believe the resurrected will be judged on their life before resurrection.\n\nThe Church of Jesus Christ of Latter-day Saints (LDS Church) teaches that the word \"hell\" is used scripturally in at least two senses. The first is a place commonly called Spirit Prison which is a state of punishment for those who reject Christ and his Atonement. This is understood to be a temporary state in which the spirits of deceased persons will be taught the gospel and have an opportunity to repent and accept ordinances of salvation. Mormons teach that it was for this purpose that Christ visited the Spirit World after his crucifixion (1 Peter 3:19–20, 1 Peter 4:5–6). Modern-day revelation clarifies that while there, Christ began the work of salvation for the dead by commissioning spirits of the righteous to teach the gospel to those who didn't have the opportunity to receive it while on earth.\n\nMormons believe that righteous people will rise in a \"first resurrection\" and live with Christ on earth after His return. After the 1000 years known as the Millennium, the individuals in spirit prison who chose not to accept the gospel and repent will also be resurrected and receive an immortal physical body, which is referred to as the \"second resurrection\". At these appointed times of resurrection, \"death and hell\" will deliver up the dead that are in them to be judged according to their works (Revelations 20:13), at which point all but the sons of perdition will receive a degree of glory, which Paul compared to the glory of the sun, moon, and stars (1 Corinthians 15:41). The Church explains biblical descriptions of hell being \"eternal\" or \"endless\" punishment as being descriptive of their infliction by God rather than an unending temporal period. Mormon scripture quotes God as telling church founder Joseph Smith: \"I am endless, and the punishment which is given from my hand is endless punishment, for Endless is my name. Wherefore—Eternal punishment is God's punishment. Endless punishment is God's punishment.\"Mormons also believe in a more permanent concept of hell, commonly referred to as outer darkness. It is said that very few people who have lived on the earth will be consigned to this hell, but Mormon scripture suggests that at least Cain will be present. Other mortals who during their lifetime become sons of perdition, those who commit the unpardonable sin, will be consigned to outer darkness. It is taught that the unpardonable sin is committed by those who \"den[y] the Son after the Father has revealed him\". However, the vast majority of residents of outer darkness will be the \"devil and his angels ... the third part of the hosts of heaven\" who in the pre-existence followed Lucifer and never received a mortal body. The residents of outer darkness are the only children of God that will not receive one of three kingdoms of glory at the Last Judgment.\n\nIt is unclear whether those in outer darkness will ultimately be redeemed. Of outer darkness and the sons of perdition, Mormon scripture states that \"the end thereof, neither the place thereof, nor their torment, no man knows; Neither was it revealed, neither is, neither will be revealed unto man, except to them who are made partakers thereof\". The scripture asserts that those who are consigned to this state will be aware of its duration and limitations.\n\nThe Unity Church of Charles Fillmore considers the concept of everlasting physical Hell to be false doctrine and contradictory to that reported by John the Evangelist.\n\n\n\n\n\n\n"}
{"id": "14085792", "url": "https://en.wikipedia.org/wiki?curid=14085792", "title": "Cognitive science of religion", "text": "Cognitive science of religion\n\nCognitive science of religion is the study of religious thought and behavior from the perspective of the cognitive and evolutionary sciences. The field employs methods and theories from a very broad range of disciplines, including: cognitive psychology, evolutionary psychology, cognitive anthropology, artificial intelligence, neurotheology, developmental psychology, and archaeology. Scholars in this field seek to explain how human minds acquire, generate, and transmit religious thoughts, practices, and schemas by means of ordinary cognitive capacities.\n\nAlthough religion has been the subject of serious scientific study since at least the late nineteenth century, the study of religion as a cognitive phenomenon is relatively recent. While it often relies upon earlier research within anthropology of religion and sociology of religion, cognitive science of religion considers the results of that work within the context of evolutionary and cognitive theories. As such, cognitive science of religion was only made possible by the cognitive revolution of the 1950s and the development, starting in the 1970s, of sociobiology and other approaches explaining human behaviour in evolutionary terms, especially evolutionary psychology.\n\nWhile Dan Sperber foreshadowed cognitive science of religion in his 1975 book \"Rethinking Symbolism\", the earliest research to fall within the scope of the discipline was published during the 1980s. Among this work, Stewart E. Guthrie's \"A cognitive theory of religion\" was significant for examining the significance of anthropomorphism within religion, work that ultimately led to the development of the concept of the hyperactive agency detection device – a key concept within cognitive science of religion.\n\nThe real beginning of cognitive science of religion can be dated to the 1990s, however. During that decade a large number of highly influential books and articles were published which helped to lay the foundations of cognitive science of religion. These included \"Rethinking Religion: Connecting Cognition and Culture\" and \"Bringing Ritual to Mind: Psychological Foundations of Cultural Forms\" by E. Thomas Lawson and Robert McCauley, \"Naturalness of Religious Ideas\" by Pascal Boyer, \"Inside the Cult\" and \"Arguments and Icons\" by Harvey Whitehouse, and Guthrie's book-length development of his earlier theories in \"Faces in the Clouds\". In the 1990s, these and other researchers, who had been working independently in a variety of different disciplines, discovered each other's work and found valuable parallels between their approaches, with the result that something of a self-aware research tradition began to coalesce. By 2000, the field was well-enough defined for Justin L. Barrett to coin the term 'cognitive science of religion' in his article \"Exploring the natural foundations of religion\".\n\nSince 2000, cognitive science of religion has grown, similarly to other approaches that apply evolutionary thinking to sociological phenomena. Each year more researchers become involved in the field, with theoretical and empirical developments proceeding at a very rapid pace. The field remains somewhat loosely defined, bringing together as it does researchers who come from a variety of different traditions. Much of the cohesion in the field comes not from shared detailed theoretical commitments but from a general willingness to view religion in cognitive and evolutionary terms as well as from the willingness to engage with the work of the others developing this field. A vital role in bringing together researchers is played by the International Association for the Cognitive Science of Religion, formed in 2006.\n\nDespite a lack of agreement concerning the theoretical basis for work in cognitive science of religion, it is possible to outline some tendencies. Most significant of these is reliance upon the theories developed within evolutionary psychology. That particular approach to evolutionary explanations of human behaviour is particularly suitable to the cognitive byproduct explanation of religion that is most popular among cognitive scientists of religion. This is because of the focus on byproduct and ancestral trait explanations within evolutionary psychology. A particularly significant concept associated with this approach is modularity of mind, used as it is to underpin accounts of the mental mechanisms seen to be responsible for religious beliefs. Important examples of work that falls under this rubric are provided by research carried out by Pascal Boyer and Justin L. Barrett.\n\nThese theoretical commitments are not shared by all cognitive scientists of religion, however. Ongoing debates regarding the comparative advantages of different evolutionary explanations for human behaviour find a reflection within cognitive science of religion with dual inheritance theory recently gaining adherents among researchers in the field, including Armin Geertz and Ara Norenzayan. The perceived advantage of this theoretical framework is its ability to deal with more complex interactions between cognitive and cultural phenomena, but it comes at the cost of experimental design having to take into consideration a richer range of possibilities.\n\nThe view that religious beliefs and practices should be understood as nonfunctional but as produced by human cognitive mechanisms that are functional outside of the context of religion. Examples of this are the hyperactive agent detection device and the minimally counterintuitive concepts or the process of initiation explaining buddhism and taoism. The cognitive byproduct explanation of religion is an application of the concept of spandrel (biology) and of the concept of exaptation explored by Stephen Jay Gould among others.\n\nConcepts that mostly fit human preconceptions but break with them in one or two striking ways. These concepts are both easy to remember (thanks to the counterintuitive elements) and easy to use (thanks to largely agreeing with what people expect). Examples include talking trees and noncorporeal agents. Pascal Boyer argues that many religious entities fit into this category. Upal labelled the fact that minimally counterintuitive ideas are better remembered than intuitive and maximally counterintuitive ideas as the minimal counterintuitiveness effect or the MCI-effect.\n\nCognitive scientist Justin L. Barrett postulates that this mental mechanism, whose function is to identify the activity of agents, may contribute to belief in the presence of the supernatural. Given the relative costs of failing to spot an agent, the mechanism is said to be hyperactive, producing a large number of false positive errors. Stewart E. Guthrie and others have claimed these errors can explain the appearance of supernatural concepts.\n\nAccording to the prosocial adaptation account of religion, religious beliefs and practices should be understood as having the function of eliciting adaptive prosocial behaviour and avoiding the free rider problem. Within the cognitive science of religion this approach is primarily pursued by Richard Sosis. David Sloan Wilson is another major proponent of this approach and interprets religion as a group-level adaptation, but his work is generally seen as falling outside the cognitive science of religion.\n\nPractices that, due to their inherent cost, can be relied upon to provide an honest signal regarding the intentions of the agent. Richard Sosis has suggested that religious practices can be explained as costly signals of the willingness to cooperate. A similar line of argument has been pursued by Lyle Steadman and Craig Palmer. Alternatively, D. Jason Slone has argued that religiosity may be a costly signal used as a mating strategy in so far as religiosity serves as a proxy for \"family values.\"\n\nIn the context of cognitive science of religion, dual inheritance theory can be understood as attempting to combine the cognitive byproduct and prosocial adaptation accounts using the theoretical approach developed by Robert Boyd and Peter Richerson, among others. The basic view is that while belief in supernatural entities is a cognitive byproduct, cultural traditions have recruited such beliefs to motivate prosocial behaviour. A sophisticated statement of this approach can be found in Scott Atran and Joseph Henrich (2010) \"The Evolution of Religion: How Cognitive By-Products, Adaptive Learning Heuristics, Ritual Displays, and Group Competition Generate Deep Commitments to Prosocial Religions\" \"Biological Theory\" 5.1.\n\n\n"}
{"id": "3229238", "url": "https://en.wikipedia.org/wiki?curid=3229238", "title": "Common squirrel monkey", "text": "Common squirrel monkey\n\nThe common squirrel monkey (\"Saimiri sciureus\") is a small New World monkey of the family Cebidae, native to the tropical areas of South America.\n\nThe common squirrel monkey can be found primarily in the Amazon Basin, including territories in the countries of Brazil, Colombia, Ecuador, French Guiana, Guyana, Peru, Suriname and Venezuela; a small population has been introduced to Florida and many of the Caribbean Islands. A group of free-ranging individuals was spotted and photographed in 2009 at the Tijuca Forest in Rio de Janeiro – possibly the result of an illegal release or of an escape from the pet trade; by 2010, the squirrel monkey had begun to be considered as an invasive species in the Brazilian Atlantic rainforest, and concerns were expressed about its role as a predator of eggs of endangered bird species. The common squirrel monkey prefers to live in the middle canopy, but occasionally comes to the ground or goes up into the high canopy. They like vegetation which provides good cover from birds of prey in the rainforest, savannah, mangroves, or marshlands.\n\nAt least five populations of common squirrel monkeys have existed in Florida since the 1960s, if not earlier. Common squirrel monkeys have been established at Silver Springs since at least the late 1960s; rhesus macaques were established in the area by 1938, but there is no firm information on when the squirrel monkeys were released. In the 1960s, a colony of twelve to fifteen common squirrel monkeys was noted residing in a hammock of trees by the springs; they migrated downstream to the Ocklawaha River by 1975. Another population, derived from two pairs released in the 1960s, lives on the Bartlett Estate in Broward County; they numbered 43 in 1988. In 1976, 15 squirrel monkeys escaped from the Tropic Wonderland attraction in Titusville, Florida; their descendants have since become established in the area. In the 1980s, 500 and 1000 common squirrel monkeys remained in the shuttered Masterpiece Gardens park in Polk County, persisting despite efforts to capture them. Additionally, a \"semi-free-ranging\" population has existed at Monkey Jungle in Goulds in Miami-Dade County since 1960.\n\nThe common squirrel monkey is considered both frugivorous and insectivorous, preferring berry-like fruit on branches. When in captivity, squirrel monkeys are fed fruits such as apples, oranges, grapes, and bananas. They also consume a variety of vegetables that include lettuce, celery, and onions. Squirrel monkeys also look for insects and small vertebrates, such as tree frogs. It obtains a majority of its water from the foods eaten, and also obtains water from holes in trees and puddles on the ground. When fruit is scarce, the common squirrel monkey drinks nectar.\n\nThe amount of time squirrel monkeys spend foraging depends on the type of food. When bigger fruits and easy access occur, they do not spend much time foraging. Otherwise, they dedicate a considerable amount of time to looking for their foods. Foraging also keeps the monkeys entertained and active. Oftentimes when they are captive, they easily become bored as the food is more easily obtained.\n\nThe common squirrel monkey is polygamous with a multiple-male, multiple-female group structure. Most social interactions in \"S. sciureus\" groups occur within the various age/sex classes, with the division of classes being between adult male categories, mother-infant categories, and juvenile categories. The core of the group is made up of the adult females and their young. As a result of the natural attraction each class has to the adult females, the different age/sex classes come together as one social group. Though juveniles play and jump around an appreciable amount during phases of high activity, they usually stay close to the adult females. In terms of the males’ level of attraction to the adult females, the phase of the yearly reproductive cycle determines their distance from the adult females. Overall, interactions between the various age/sex classes are most frequently directed to adult females. The division of age/sex classes among \"S. sciureus\" is not so strictly defined because the degree of segregation between sexes can vary. That is, those subspecies which have a high degree of sexual dimorphism are sexually segregated, such that the males and females of that subspecies interact less with each other than do those of subspecies that are not very sexually dimorphic and thus sexually integrated.\n\nSeasonal reproduction plays a major role in the social behavior of \"S. sciureus\", where the frequency of between-sex interactions of the males and females differs between the birth season and the mating season. Adult males are generally socially inactive during the birth season and spend their time travelling and foraging at a distance from the group. During the mating season, though, the adult males become fatter, excited, aggressive, and highly vocal and spend most of their time engaging in dominance interactions among themselves or following and approaching the adult females in estrus, in hopes of being able to mate with them. Males can increase their chances at copulating with receptive females by approaching them quietly. Nonreceptive females, though, respond aggressively to any male approach and threaten and chase the males away, usually with the help of surrounding females. Overall, intersexual interaction among \"S. sciureus\" greatly increases during the mating season.\n\n\"Saimiri sciureus\" infants develop rapidly. They become fairly independent between five and eight months of age and spend only a small percentage of the day with their mothers. Also at this age range, the infants can find food on their own. Infants are active members of the social group, climbing, running, exploring, and frequently making contact with adult members of the group. Most adult-infant interactions are initiated by infants towards adult females that are not their mothers. Adults generally respond to the infants calmly, but some adults may respond with antagonism. Infants rank the lowest in the group.\n\nMany other aspects of \"S. sciureus\" social behavior, such as dominance relationships, coalitions, dispersal patterns, and aggression, stem from the feeding ecology of the animals. Feeding ecology directly affects the females of the group which in turn affects the behavior of the males in the group. The feeding patches for \"S. sciureus\" are very small and dense, which makes it possible for an individual with the greatest capability of winning a fight, if one were to occur, to monopolize access to any patch. Within-group competition among \"S. sciureus\" groups is extremely high, and between-group competition is moderate to high. Coalition formation is not as stable as would be expected among the females of the group because considering their small and dense feeding patches, \"S. sciureus\" females with the greatest capability of winning a fight would benefit more if they were to form alliances to gain control of a patch and then not share the patch once in control of it.\n\nOnce sexually mature, all males emigrate from their natal groups. After leaving, they may either become solitary, a peripheral of another troop, join another mixed-sex troop, or attend a tolerant troop of another monkey species. If they become a peripheral of another group, the male squirrel monkey chooses one troop and keeps a certain distance away from them while still trying to follow them. These males are the less dominant ones. A few male squirrel monkeys have been observed interacting with groups of other monkey species. Some females may leave their natal groups, as well, although they tend to be more philopatric. If females do leave their natal groups, they do it after becoming sexually mature. Often, they migrate before or right after a mating season. Due to this, they might end up leaving their group when they are pregnant or with their immature offspring.\n\nMales are typically dominant to females, but females still have a high status in the group. and are capable of forming coalitions against dominant males. Rarely do males form coalitions even if a group of males keeps their distance from the main group or are solitary. Several theories suggest that one of the reasons that male squirrel monkeys do not form coalitions is because of the lack of kinship due to emigration. Coalitions may also increase mortality risks within the group since males tend to be aggressive to each other.\nGenital display among males is an important social signal in relation to group hierarchy; it is derived from sexual behavior, but is used for social communication. It involves the animal spreading his thighs and having an erect penis. Dominant males display to submissive males to emphasize their higher status. The dominant males direct their action to the face of the passive males, and the act can be done with the displayer leaning over the passive monkey or the displayer doing the action from a distance in a more upright position. This form of dominance interaction, as well as several types of aggression, increase during the mating season when males want to emphasize their rank and strength and gain more control over other males in relation to access to females. Genital displays may also define male-male alliances when the males participate in \"joint genital displays\".\n\nThe common squirrel monkey is diurnal. It is usually quiet, but will utter loud cries when alarmed. It uses different types of calls for specific situations. Some of their common call types include caws, bawls, and shrieks. Squirrel monkeys utter caws mostly when they are trying to defend a territory. They may use bawls prior to a fight, as well as after one. Shrieks are mainly heard when the monkeys are fighting for dominance. Squirrel monkeys’ most common calls are determined by their genetics. Squirrel monkeys that have been isolated since infancy are able to produce the same calls as those that have been exposed to the calls. Few variations exist between the frequencies of the calls of infants that were raised differently. A squirrel monkey that was deaf since birth was also able to produce the same calls, proving that the calls come from their genes. It is arboreal, but sometimes it comes down to the ground. Bands or troops can number from 12-100. Occasionally, troops as large as 500 have been seen in undisturbed forests.\n\nThe common squirrel monkey is rated as \"least concern\" by IUCN, but is among many rainforest animals whose status may be harmed by deforestation. The species has also been captured extensively for the pet trade and for medical research.\n\nDue to its inquisitive nature this species is a popular pet and it requires a large amount of space and food.\n\nThe four subspecies of \"S. sciureus\" are:\n"}
{"id": "44287236", "url": "https://en.wikipedia.org/wiki?curid=44287236", "title": "Continued process verification", "text": "Continued process verification\n\nContinued process verification (CPV) is the collection and analysis of end-to-end production components and processes data to ensure product outputs are within predetermined quality limits. In 2011 the Food and Drug Administration published a report outlining best practices regarding business process validation in the pharmaceutical industry. Continued process verification is outlined in this report as the third stage in process validation. Its central purpose is to ensure that processes are in a constant state of control, thus ensuring final product quality. Central to effective CPV is a method with which to identify unwanted process inconsistencies in order to execute corrective or preventative measures. Once quality standards are set in place they must be monitored with regular frequency to confirm those parameters are being met. Continued process verification not only helps protect consumers from production faults, but business also see benefits in implementing a CPV program. Should product outputs not match target standards it can be very costly to investigate the problem source without existing CPV data.\n\n\nCrucial in effective CPV implementation is an appropriate data collection procedure. Data must allow for statistical analytics and trend analysis of process consistency and capability. A correctly implemented procedure will minimize overreactions to individual production outlier events and guarantee genuine process inconsistency are detected. While production variability can sometimes be obvious and even casually identified the FDA recommends using statistical tools to quantitatively detect problems and identify root causes. Initially, continued process verification should be based on quality standards established in the design phase. After a period of time variations can be detected by identifying deviation from historical data using statistical tools. Furthermore, these same tools can also be used to identify opportunities to optimize processes that may pre-emptively increase quality reliability.\n\n"}
{"id": "15632220", "url": "https://en.wikipedia.org/wiki?curid=15632220", "title": "Crime and violence in Latin America", "text": "Crime and violence in Latin America\n\nCrime and violence affect the lives of millions of people in Latin America. Some consider social inequality to be a major contributing factor to levels of violence in Latin America, where the state fails to prevent crime and organized crime takes over State control in areas where the State is unable to assist the society such as in impoverished communities. In the years following the transitions from authoritarianism to democracy, crime and violence have become major problems in Latin America.\n\nSeveral studies indicated the existence of an epidemic in the region; the Pan American Health Organization called violence in Latin America \"the social pandemic of the 20th century.\" Apart from the direct human cost, the rise in crime and violence has imposed significant social costs and has made much more difficult the processes of economic and social development, democratic consolidation and regional integration in the Americas.\n\nHigh rates of crime and violence in Latin America are undermining growth, threatening human welfare, and impeding social development, according to World Bank and the United Nations Office on Drugs and Crime (UNODC).\nLatin America is caught in a vicious circle, where economic growth is thwarted by high crime rates, and insufficient economic opportunity contributes to high crime. Crime and violence thrives as the rule of law is weak, economic opportunity is scarce, and education is poor. Therefore, effectively addressing crime requires a holistic, multi-sectoral approach that addresses its root social, political, and economic causes.\n\nRecent statistics indicate that crime is becoming the biggest problem in Latin America. Amnesty International has declared Latin America as the most dangerous region in the world for journalists to work.\n\nIn Mexico, armed gangs of rival drug smugglers have been fighting it out with one another, thus creating new hazards in rural areas. Crime is extremely high in all of the major cities in Brazil. Wealthy citizens have had to provide for their own security. In large parts of Rio de Janeiro, armed criminal gangs are said to be in control. Crime statistics were high in El Salvador, Guatemala and Venezuela during 1996. The police have not been able to handle the work load and the military have been called in to assist in these countries. There was a very distinct crime wave happening in Latin America. The city that currently topped the list of the world's most violent cities is San Pedro Sula in Honduras, leading various media sources to label it the \"murder capital of the world.\" Colombia registered a homicide rate of 24.4 per 100,000 in 2016, the lowest since 1974. The 40-year low in murders came the same year that the Colombian government signed a peace agreement with the FARC.\n\nCrime is slowing economic growth and undermining democratic consolidation in Latin America. Today, Latin America has the dubious distinction of being most violent region in the world, with combined crime rates more than triple the world average and are comparable to rates in nations experiencing war. This is taking a tremendous toll on development in the region by both affecting economic growth and public faith in democracy.\n\nThe Inter-American Development Bank estimates that Latin America's per capita Gross Domestic Product would be twenty-five percent higher if the region's crime rates were equal to the world average. Similarly, the World Bank has identified a strong correlation between crime and income inequality. Business associations in the region rank crime as the number one issue negatively affecting trade and investment. Crime-related violence also represents the most important threat to public health, striking more victims than HIV/AIDS or other infectious diseases.\nPublic faith in democracy itself is under threat as governments are perceived as unable to deliver basic services such as public security. A United Nations report revealed that only 43 percent of Latin Americans are fully supportive of democracy. Crime has rapidly risen to the top of the list of citizen concerns in Latin America. As the Economist magazine described it, \"in several Latin American countries, 2004 will be remembered as the year in which the people rose up in revolt against crime.\"\n\nMassive street marches such as those that took place in Argentina, Mexico, and Brazil, and other expressions of protest against violence, have made it increasingly difficult for politicians to avoid dealing with the issue and, in many countries, have made tackling crime a central theme in political party platforms across the region. Several leaders in the region, including El Salvador's Tony Saca, Ricardo Maduro in Honduras, Guatemala's Óscar Berger, and Álvaro Uribe in Colombia, have all campaigned on a strong anti-crime message. The Presidents of Honduras and El Salvador have called gangs \"(maras)\" as big a threat to national security in their countries as terrorism is to the United States.\n\n\"World Bank researchers have demonstrated the existence of a 'criminal inertia,' in which high rates of criminality endure long after the latent socioeconomic causes have disappeared or been addressed through policy interventions.\"\n\nAnother reason critics believe fuels crime in Latin America is due to the poor public primary education system they say it \"has given rise to youths without jobs or expectations of employment-thereby fueling the mounting problem of gang violence in Central America, Mexico, Jamaica, Trinidad, Colombia and Brazil.\" \n\nA series of factors have contributed to the increase in violent crime in Latin America since the transitions from authoritarianism to democracy. Some intrinsic factors and characteristics of each country aggravated the problem in some countries. However, some factors might have increased the risk of crime and violence in many or most countries in the region in the period between the 1980s and 1990s:\n\n\nBrazil is one of the countries that has the largest inequality in terms of the gap between the very wealthy and the extremely destitute. A huge portion of the population lives in poverty. According to the World Bank, \"one-fifth of Brazil's 173 million people account for only a 2.2 percent share of the national income. Brazil is second only to South Africa in a world ranking of income inequality.\n\nThe incidence of violent crime, including muggings, armed robbery, murder and sexual assault is high, particularly in Rio de Janeiro, Recife and other large cities. Carjacking is also common, particularly in major cities. Criminals often use guns. Gang-related violence is common throughout the State of São Paulo. Crime levels in slum areas are very high. Victims have been seriously injured or killed when resisting perpetrators. During peak tourist seasons, large, organised criminal gangs have reportedly robbed and assaulted beach goers. The country is well known for having almost 60,000 documented murders every year for the past decade, mostly drug and robbery related.\n\n'Express kidnappings', where individuals are abducted and forced to withdraw funds from automated teller machines to secure their release, are common in major cities including Rio de Janeiro, São Paulo, Brasília, Salvador and Recife. People have been robbed and assaulted when using unregistered taxis. Petty crime such as pickpocketing and bag snatching are common. Thieves operate in outdoor markets, in hotels and on public transport. Piracy occurs in the coastal areas of Brazil.\n\nElements of all the armed groups have been involved in drug-trafficking. In a country where the presence of the state has always been weak, the result has been a grinding war on multiple fronts, with the civilian population caught in the crossfire and often deliberately targeted for \"collaborating\". Human rights advocates blame paramilitaries for massacres, \"disappearances\", and cases of torture and forced displacement. Rebel groups such as the FARC and the ELN are behind assassinations, kidnapping and extortion. The level of drug related violence was halved in the last 10 years, when the country moved from being the most violent country in the world to have a homicide rate that is inferior to the one registered in countries like Honduras, Jamaica, El Salvador, Venezuela, Guatemala, Trinidad and Tobago and South Africa.\n\nThe administration of President Uribe has sought to professionalize the armed forces and to engage them more fully in the counterinsurgency war; as a result, the armed groups have suffered a series of setbacks. Police in Colombia say the number of people kidnapped has fallen 92% since 2000. Common criminals are now the perpetrators of the overwhelming majority of kidnappings. By the year 2016, the number of kidnappings in Colombia had declined to 205 and it continues to decline. In general, and you are much more likely to encounter a Colombian army checkpoint than an illegal guerrilla roadblock.\n\nColombia registered a homicide rate of 24.4 per 100,000 in 2016, the lowest since 1974. The 40-year low in murders came the same year that the Colombian government signed a peace agreement with the FARC.\n\nViolent crime is rampant in El Salvador, in 2015 the homicide rate peaked at 105 homicides per 100,000 residents. In 2016, the rate decreased by 20%, but El Salvador continues to be one of the world's most dangerous countries. As of March 2012, El Salvador has seen a 40% drop in crime due to what the Salvadoran government called a gang truce. In early 2012, there were on average of 16 killings per day but in late March that number dropped to fewer than 5 per day and on April 14, 2012 for the first time in over 3 years there were no killings in the country. Overall, there were 411 killings in the month of January 2012 but in March the number was 188, more than a 40% reduction in crime. All of this happening while crime in neighboring Honduras has risen to an all-time high.\n\nViolent crime including armed robbery, banditry, assault, kidnapping, sexual assault, and carjacking is common, including in the capital, San Salvador. Downtown San Salvador is dangerous, particularly at night. Public safety is no laughing matter, San Salvador hosts one of the most notorious unified crime family transnational gangs that spread across the Central American heart region, like the Mara Salvatrucha and the 18th Street gang that arrived during and since the Salvadoran Civil War.\n\nThe security situation has taken a downturn in San Salvador; in 2002, there were over 9000 intentional homicides in the city of San Salvador by international global Central American Gangs or Maras. 2005 and 2006 saw a worsening security situation in San Salvador; and corruption, with the trend continuing in 2008. Crimes have increased to 13 daily, with this sharp increase having occurred in the last six years, making the words San Salvador City synonymous with crime. The portrayal of San Salvador was a dark and foreboding metropolis rife and reign with crime, grime, corruption, and a deep-seated sense of urban decay, ultimately a vice city.\n\nAfter the civil war and left in complete ruins and destruction, people described and called the city \"San Salvador La Ciudad Que Se Desmorona\", \"San Salvador The City That Crumbles\". San Salvador is a rampant and recurring corruption within the city's civil authorities and infrastructure. Certain locations disputed by rival gangs especially in poor slums on the outskirts areas of San Salvador City are labeled as No man's land.\n\nHigh-level corruption in El Salvador is a serious problem. President Mauricio Funes pledged to investigate and prosecute corrupt senior officials when he took office in June, 2009, but after a political truce with his predecessor, Antonio Saca, who was expelled from the ARENA party amid large-scale corruption allegations, Funes showed an unwillingness to tackle the problem. ARENA alleged that $219 million in government funds under Saca's personal control had disappeared. Saca's own former political allies in the ARENA party and private sector told the U.S. Embassy in San Salvador of widespread abuse of power for personal financial gain. Such corruption, the U.S. Embassy reported in a cable leaked by WikiLeaks, \"went beyond the pale\" even by Salvadoran standards.\n\nCrime is a major problem in Honduras, which has the highest murder rate of any nation. There are reports that after the 2009 Honduran coup d'état, there was a large increase in crime and violence. According to the United Nations Office on Drugs and Crime, Honduras has the highest rate of intentional homicide in the world, with 6,239 intentional homicides, or 82.1 per 100,000 of population in 2010. This is significantly higher than the rate in El Salvador, which at 66.0 per 100,000 in 2010, has the second highest rate of intentional homicide in the world.\n\nAccording to the International Crisis Group, the most violent regions outside of the major urban areas in Honduras exist on the border with Guatemala, and are highly correlated with the many active drug trafficking routes plying the region.\n\nCrime is among the most urgent concerns facing Mexico, as Mexican drug trafficking rings play a major role in the flow of cocaine, heroin, and marijuana transiting between Latin America and the United States. Drug trafficking has contributed to corruption, which has had a deleterious effect on Mexico's Federal Representative Republic. Drug trafficking and organized crime have also been a major source of violent crime in Mexico.\n\nMexico has experienced increasingly high crime rates, especially in major urban centers. The country's great economic polarization has stimulated criminal activity in the lower socioeconomic strata, which include the majority of the country's population. Crime continues at high levels, and is repeatedly marked by violence, especially in the cities of Tijuana and Ciudad Juárez, and the states of Baja California, Durango, Sinaloa, Guerrero, Chihuahua, Michoacán, Tamaulipas, and Nuevo León. Other metropolitan areas have lower, yet still serious, levels of crime. Low apprehension and conviction rates contribute to the high crime rate.\n\nBefore the drug war in Mexico, there were roughly 300 murders in the border city of Ciudad Juarez in 2007. In 2010, state officials reported a peak of 3,622 homicides in the city. With a rate of 272 murders per 100,000 residents, Ciudad Juarez alone had the highest murder rate in the world, although the rate has steadily decreased since then to reach only 300 murders in 2015.\n\nPuerto Rico has become a major transshipment point for illegal drugs that are smuggled from source countries like Colombia and Peru into the U.S. mainland. Most of it is transported to and through the island from drug trafficking organizations in the Dominican Republic, Colombia, Florida, and criminal organizations in Puerto Rico. One of the most common ways drugs are smuggled into the island is through commercial and private maritime vessels, and container terminals such as the Port of San Juan. It is the busiest port in the Caribbean and the second busiest in Latin America.\n\nBecause drugs are trafficked directly into the island from other source countries, they are less expensive than in any other place in the United States. Thus, it is cheap and easy for street gangs to buy and deal to the public mostly in, and from, housing projects, leading to turf wars and the second highest homicide rate in the United States. Police undermining in the drug trade and corruption are also common. Between 1993 and 2000, 1,000 police officers in Puerto Rico lost their jobs from the department due to criminal charges and between 2003 and 2007, 75 officers were convicted under federal court for police corruption. 2011 was marked as the most violent year for Puerto Rico with approximately 1,120 murders recorded, 30.5 homicides per 100,000 residents.\n\nVenezuela is among the most violent places in Latin America. Class tension has long been a part of life in the South American country, where armed robberies, carjackings and kidnappings are frequent. Venezuela was ranked the most insecure nation in the world by \"Gallup\" in 2013 with the United Nations stating that such crime is due to the poor political and economic environment in the country. As a result of the high levels of crime, Venezuelans were forced to change their ways of life due to the large insecurities they continuously experienced.\n\nCrime rates are higher in 'barrios' or 'ranchos' (slum areas) after dark. Petty crime such as pick-pocketing is prevalent, particularly on public transport in Caracas. The government in 2009 created a security force, the Bolivarian National Police, which has supposedly lowered crime rates in the areas in which it is so far deployed according to the Venezuelan government, and a new Experimental Security University was created. However, many statistics have shown an increase of crime even after such measures were taken, with the 2014 murder rate showing an increase to 82 per 100,000, more than quadrupling since 1998. The capital Caracas has one of the greatest homicide rates of any large city in the world, with 122 homicides per 100,000 residents. Venezuela has also ranked high internationally among countries with high kidnapping rates, with consulting firm Control Risk ranking Venezuela 5th in the world for kidnappings in 2013 and News.com.au calling Venezuela's capital city of Caracas \"the kidnap capital of the world\" in 2013, noting that Venezuela had the highest kidnapping rate in the world and that 5 people were kidnapped for a ransom every day.\n\nForeign governments have also advised tourists of safety concerns while visiting the country. The United States State Department and Government of Canada has warned foreign visitors that they may be subjected to robbery, kidnapping for a ransom or sale to terrorist organizations and murder, and that their own diplomatic travelers are required to travel in armored vehicles. The United Kingdom's Foreign and Commonwealth Office has advised against all travel to Venezuela.\n\n\n"}
{"id": "42714893", "url": "https://en.wikipedia.org/wiki?curid=42714893", "title": "Culture of Peace News Network", "text": "Culture of Peace News Network\n\nThe Culture of Peace News Network is a United Nations authorized interactive online network, committed to supporting the global movement for a culture of peace and nonviolence. The network commenced under the auspices of UNESCO, as part of the International Year for the Culture of Peace. The United Nations General Assembly in 2009 further endorsed the work of the network, in resolution A/RES/64/80.\n\nCPNN has grown in scope in recent years. As of 2018, the CPNN website is updated more or less daily (30-50 articles per month) with articles promoting at least one of the eight program areas of the culture of peace as defined in the United Nations Declaration and Programme of Action on a Culture of Peace : Education for Peace, Human Rights, Sustainable Development, Equality of Women, Democratic Participation, Free Flow of Information, Tolerance/Solidarity, Disarmament/Security. CPNN has English, French and Spanish/Portuguese sections. Articles in the French section or in the Spanish/Portuguese section are always paired with a translation in the English section so that all articles are available in English. \n\nAt the beginning of each month a bulletin, available on the CPNN website, summarizes the major developments for a culture of peace and is sent by email to mailing lists in English, French and Spanish.\n\nCPNN is an all-volunteer initiative; additional reporters are encouraged. \n\n"}
{"id": "1158125", "url": "https://en.wikipedia.org/wiki?curid=1158125", "title": "DNA sequencing", "text": "DNA sequencing\n\nDNA sequencing is the process of determining the order of nucleotides in DNA. It includes any method or technology that is used to determine the order of the four bases: adenine, guanine, cytosine, and thymine. The advent of rapid DNA sequencing methods has greatly accelerated biological and medical research and discovery.\n\nKnowledge of DNA sequences has become indispensable for basic biological research, and in numerous applied fields such as medical diagnosis, biotechnology, forensic biology, virology and biological systematics. The rapid speed of sequencing attained with modern DNA sequencing technology has been instrumental in the sequencing of complete DNA sequences, or genomes, of numerous types and species of life, including the human genome and other complete DNA sequences of many animal, plant, and microbial species.\nThe first DNA sequences were obtained in the early 1970s by academic researchers using laborious methods based on two-dimensional chromatography. Following the development of fluorescence-based sequencing methods with a DNA sequencer, DNA sequencing has become easier and orders of magnitude faster.\n\nDNA sequencing may be used to determine the sequence of individual genes, larger genetic regions (i.e. clusters of genes or operons), full chromosomes, or entire genomes of any organism. DNA sequencing is also the most efficient way to indirectly sequence RNA or proteins (via their open reading frames). In fact, DNA sequencing has become a key technology in many areas of biology and other sciences such as medicine, forensics, and anthropology.\n\nSequencing is used in molecular biology to study genomes and the proteins they encode. Information obtained using sequencing allows researchers to identify changes in genes, associations with diseases and phenotypes, and identify potential drug targets.\n\nSince DNA is an informative macromolecule in terms of transmission from one generation to another, DNA sequencing is used in evolutionary biology to study how different organisms are related and how they evolved.\n\nThe field of metagenomics involves identification of organisms present in a body of water, sewage, dirt, debris filtered from the air, or swab samples from organisms. Knowing which organisms are present in a particular environment is critical to research in ecology, epidemiology, microbiology, and other fields. Sequencing enables researchers to determine which types of microbes may be present in a microbiome, for example.\n\nMedical technicians may sequence genes (or, theoretically, full genomes) from patients to determine if there is risk of genetic diseases. This is a form of genetic testing, though some genetic tests may not involve DNA sequencing.\n\nDNA sequencing may be used along with DNA profiling methods for forensic identification and paternity testing. DNA testing has evolved tremendously in the last few decades to ultimately link a DNA print to what is under investigation. The DNA patterns in fingerprint, saliva, hair follicles, etc. uniquely separate each living organism from another. Testing DNA is a technique which can detect specific genomes in a DNA strand to produce a unique and individualized pattern. Every living organism ever created has a one of a kind DNA pattern, which can be determined through DNA testing. It is extremely rare that two people have exactly the same DNA pattern, therefore DNA testing is highly successful.\n\nThe canonical structure of DNA has four bases: thymine (T), adenine (A), cytosine (C), and guanine (G). DNA sequencing is the determination of the physical order of these bases in a molecule of DNA. However, there are many other bases that may be present in a molecule. In some viruses (specifically, bacteriophage), cytosine may be replaced by hydroxy methyl or hydroxy methyl glucose cytosine. In mammalian DNA, variant bases with methyl groups or phosphosulfate may be found. Depending on the sequencing technique, a particular modification, e.g., the 5mC (5 methyl cytosine) common in humans, may or may not be detected.\n\nDeoxyribonucleic acid (DNA) was first discovered and isolated by Friedrich Miescher in 1869, but it remained understudied for many decades because proteins, rather than DNA, were thought to hold the genetic blueprint to life. This situation changed after 1944 as a result of some experiments by Oswald Avery, Colin MacLeod, and Maclyn McCarty demonstrating that purified DNA could change one strain of bacteria into another. This was the first time that DNA was shown capable of transforming the properties of cells.\n\nIn 1953, James Watson and Francis Crick put forward their double-helix model of DNA, based on crystallized X-ray structures being studied by Rosalind Franklin – and without crediting her. According to the model, DNA is composed of two strands of nucleotides coiled around each other, linked together by hydrogen bonds and running in opposite directions. Each strand is composed of four complementary nucleotides – adenine (A), cytosine (C), guanine (G) and thymine (T) – with an A on one strand always paired with T on the other, and C always paired with G. They proposed such a structure allowed each strand to be used to reconstruct the other, an idea central to the passing on of hereditary information between generations.\n\nThe foundation for sequencing proteins was first laid by the work of Frederick Sanger who by 1955 had completed the sequence of all the amino acids in insulin, a small protein secreted by the pancreas. This provided the first conclusive evidence that proteins were chemical entities with a specific molecular pattern rather than a random mixture of material suspended in fluid. Sanger's success in sequencing insulin greatly electrified x-ray crystallographers, including Watson and Crick who by now were trying to understand how DNA directed the formation of proteins within a cell. Soon after attending a series of lectures given by Frederick Sanger in October 1954, Crick began to develop a theory which argued that the arrangement of nucleotides in DNA determined the sequence of amino acids in proteins which in turn helped determine the function of a protein. He published this theory in 1958.\n\nRNA sequencing was one of the earliest forms of nucleotide sequencing. The major landmark of RNA sequencing is the sequence of the first complete gene and the complete genome of Bacteriophage MS2, identified and published by Walter Fiers and his coworkers at the University of Ghent (Ghent, Belgium), in 1972 and 1976. Traditional RNA sequencing methods require the creation of a cDNA molecule which must be sequenced.\n\nThe first method for determining DNA sequences involved a location-specific primer extension strategy established by Ray Wu at Cornell University in 1970. DNA polymerase catalysis and specific nucleotide labeling, both of which figure prominently in current sequencing schemes, were used to sequence the cohesive ends of lambda phage DNA. Between 1970 and 1973, Wu, R Padmanabhan and colleagues demonstrated that this method can be employed to determine any DNA sequence using synthetic location-specific primers. Frederick Sanger then adopted this primer-extension strategy to develop more rapid DNA sequencing methods at the MRC Centre, Cambridge, UK and published a method for \"DNA sequencing with chain-terminating inhibitors\" in 1977. Walter Gilbert and Allan Maxam at Harvard also developed sequencing methods, including one for \"DNA sequencing by chemical degradation\". In 1973, Gilbert and Maxam reported the sequence of 24 basepairs using a method known as wandering-spot analysis. Advancements in sequencing were aided by the concurrent development of recombinant DNA technology, allowing DNA samples to be isolated from sources other than viruses.\n\nThe first full DNA genome to be sequenced was that of bacteriophage φX174 in 1977. Medical Research Council scientists deciphered the complete DNA sequence of the Epstein-Barr virus in 1984, finding it contained 172,282 nucleotides. Completion of the sequence marked a significant turning point in DNA sequencing because it was achieved with no prior genetic profile knowledge of the virus.\n\nA non-radioactive method for transferring the DNA molecules of sequencing reaction mixtures onto an immobilizing matrix during electrophoresis was developed by Pohl and co-workers in the early 1980s. Followed by the commercialization of the DNA sequencer \"Direct-Blotting-Electrophoresis-System GATC 1500\" by GATC Biotech, which was intensively used in the framework of the EU genome-sequencing programme, the complete DNA sequence of the yeast \"Saccharomyces cerevisiae\" chromosome II. Leroy E. Hood's laboratory at the California Institute of Technology announced the first semi-automated DNA sequencing machine in 1986. This was followed by Applied Biosystems' marketing of the first fully automated sequencing machine, the ABI 370, in 1987 and by Dupont's Genesis 2000 which used a novel fluorescent labeling technique enabling all four dideoxynucleotides to be identified in a single lane. By 1990, the U.S. National Institutes of Health (NIH) had begun large-scale sequencing trials on \"Mycoplasma capricolum\", \"Escherichia coli\", \"Caenorhabditis elegans\", and \"Saccharomyces cerevisiae\" at a cost of US$0.75 per base. Meanwhile, sequencing of human cDNA sequences called expressed sequence tags began in Craig Venter's lab, an attempt to capture the coding fraction of the human genome. In 1995, Venter, Hamilton Smith, and colleagues at The Institute for Genomic Research (TIGR) published the first complete genome of a free-living organism, the bacterium \"Haemophilus influenzae\". The circular chromosome contains 1,830,137 bases and its publication in the journal Science marked the first published use of whole-genome shotgun sequencing, eliminating the need for initial mapping efforts.\n\nBy 2001, shotgun sequencing methods had been used to produce a draft sequence of the human genome.\n\nSeveral new methods for DNA sequencing were developed in the mid to late 1990s and were implemented in commercial DNA sequencers by the year 2000. Together these were called the \"next-generation\" or \"second-generation\" sequencing (NGS) methods, in order to distinguish them from the aforementioned earlier methods, like Sanger Sequencing. In contrast to the first generation of sequencing, NGS technology is typically characterized by being highly scalable, allowing the entire genome to be sequenced at once. Usually, this is accomplished by fragmenting the genome into small pieces, randomly sampling for a fragment, and sequencing it using one of a variety of technologies, such as those described below. An entire genome is possible because multiple fragments are sequenced at once (giving it the name \"massively parallel\" sequencing) in an automated process.\n\nNGS technology has tremendously empowered researchers to look for insights into health, anthropologists to investigate human origins, and is catalyzing the \"Personalized Medicine\" movement. However, it has also opened the door to more room for error. There are many software tools to carry out the computational analysis of NGS data, each with its own algorithm. Even the parameters within one software package can change the outcome of the analysis. In addition, the large quantities of data produced by DNA sequencing have also required development of new methods and programs for sequence analysis. Several efforts to develop standards in the NGS field have been attempted to address these challenges, most of which have been small-scale efforts arising from individual labs. Most recently, a large, organized, FDA-funded effort has culminated in the BioCompute standard.\n\nOn 26 October 1990, Roger Tsien, Pepi Ross, Margaret Fahnestock and Allan J Johnston filed a patent describing stepwise (\"base-by-base\") sequencing with removable 3' blockers on DNA arrays (blots and single DNA molecules).\nIn 1996, Pål Nyrén and his student Mostafa Ronaghi at the Royal Institute of Technology in Stockholm published their method of pyrosequencing.\n\nOn 1 April 1997, Pascal Mayer and Laurent Farinelli submitted patents to the World Intellectual Property Organization describing DNA colony sequencing. The DNA sample preparation and random surface-PCR arraying methods described in this patent, coupled to Roger Tsien et al.'s \"base-by-base\" sequencing method, is now implemented in Illumina's Hi-Seq genome sequencers.\n\nIn 1998, Phil Green and Brent Ewing of the University of Washington described their phred quality score for sequencer data analysis, a landmark analysis technique that gained widespread adoption, and which is still the most common metric for assessing the accuracy of a sequencing platform.\n\nLynx Therapeutics published and marketed Massively parallel signature sequencing (MPSS), in 2000. This method incorporated a parallelized, adapter/ligation-mediated, bead-based sequencing technology and served as the first commercially available \"next-generation\" sequencing method, though no DNA sequencers were sold to independent laboratories.\n\nAllan Maxam and Walter Gilbert published a DNA sequencing method in 1977 based on chemical modification of DNA and subsequent cleavage at specific bases. Also known as chemical sequencing, this method allowed purified samples of double-stranded DNA to be used without further cloning. This method's use of radioactive labeling and its technical complexity discouraged extensive use after refinements in the Sanger methods had been made.\n\nMaxam-Gilbert sequencing requires radioactive labeling at one 5' end of the DNA and purification of the DNA fragment to be sequenced. Chemical treatment then generates breaks at a small proportion of one or two of the four nucleotide bases in each of four reactions (G, A+G, C, C+T). The concentration of the modifying chemicals is controlled to introduce on average one modification per DNA molecule. Thus a series of labeled fragments is generated, from the radiolabeled end to the first \"cut\" site in each molecule. The fragments in the four reactions are electrophoresed side by side in denaturing acrylamide gels for size separation. To visualize the fragments, the gel is exposed to X-ray film for autoradiography, yielding a series of dark bands each corresponding to a radiolabeled DNA fragment, from which the sequence may be inferred.\n\nThe chain-termination method developed by Frederick Sanger and coworkers in 1977 soon became the method of choice, owing to its relative ease and reliability. When invented, the chain-terminator method used fewer toxic chemicals and lower amounts of radioactivity than the Maxam and Gilbert method. Because of its comparative ease, the Sanger method was soon automated and was the method used in the first generation of DNA sequencers.\n\nSanger sequencing is the method which prevailed from the 1980s until the mid-2000s. Over that period, great advances were made in the technique, such as fluorescent labelling, capillary electrophoresis, and general automation. These developments allowed much more efficient sequencing, leading to lower costs. The Sanger method, in mass production form, is the technology which produced the first human genome in 2001, ushering in the age of genomics. However, later in the decade, radically different approaches reached the market, bringing the cost per genome down from $100 million in 2001 to $10,000 in 2011.\n\n Large-scale sequencing often aims at sequencing very long DNA pieces, such as whole chromosomes, although large-scale sequencing can also be used to generate very large numbers of short sequences, such as found in phage display. For longer targets such as chromosomes, common approaches consist of cutting (with restriction enzymes) or shearing (with mechanical forces) large DNA fragments into shorter DNA fragments. The fragmented DNA may then be cloned into a DNA vector and amplified in a bacterial host such as \"Escherichia coli\". Short DNA fragments purified from individual bacterial colonies are individually sequenced and assembled electronically into one long, contiguous sequence. Studies have shown that adding a size selection step to collect DNA fragments of uniform size can improve sequencing efficiency and accuracy of the genome assembly. In these studies, automated sizing has proven to be more reproducible and precise than manual gel sizing.\n\nThe term \"\"de novo\" sequencing\" specifically refers to methods used to determine the sequence of DNA with no previously known sequence. \"De novo\" translates from Latin as \"from the beginning\". Gaps in the assembled sequence may be filled by primer walking. The different strategies have different tradeoffs in speed and accuracy; shotgun methods are often used for sequencing large genomes, but its assembly is complex and difficult, particularly with sequence repeats often causing gaps in genome assembly.\n\nMost sequencing approaches use an \"in vitro\" cloning step to amplify individual DNA molecules, because their molecular detection methods are not sensitive enough for single molecule sequencing. Emulsion PCR isolates individual DNA molecules along with primer-coated beads in aqueous droplets within an oil phase. A polymerase chain reaction (PCR) then coats each bead with clonal copies of the DNA molecule followed by immobilization for later sequencing. Emulsion PCR is used in the methods developed by Marguilis et al. (commercialized by 454 Life Sciences), Shendure and Porreca et al. (also known as \"Polony sequencing\") and SOLiD sequencing, (developed by Agencourt, later Applied Biosystems, now Life Technologies). Emulsion PCR is also used in the GemCode and Chromium platforms developed by 10x Genomics.\n\nShotgun sequencing is a sequencing method designed for analysis of DNA sequences longer than 1000 base pairs, up to and including entire chromosomes. This method requires the target DNA to be broken into random fragments. After sequencing individual fragments, the sequences can be reassembled on the basis of their overlapping regions.\n\nAnother method for \"in vitro\" clonal amplification is bridge PCR, in which fragments are amplified upon primers attached to a solid surface and form \"DNA colonies\" or \"DNA clusters\". This method is used in the Illumina Genome Analyzer sequencers. Single-molecule methods, such as that developed by Stephen Quake's laboratory (later commercialized by Helicos) are an exception: they use bright fluorophores and laser excitation to detect base addition events from individual DNA molecules fixed to a surface, eliminating the need for molecular amplification.\n\nHigh-throughput (formerly \"next-generation\") sequencing applies to genome sequencing, genome resequencing, transcriptome profiling (RNA-Seq), DNA-protein interactions (ChIP-sequencing), and epigenome characterization. Resequencing is necessary, because the genome of a single individual of a species will not indicate all of the genome variations among other individuals of the same species.\n\nThe high demand for low-cost sequencing has driven the development of high-throughput sequencing technologies that parallelize the sequencing process, producing thousands or millions of sequences concurrently. High-throughput sequencing technologies are intended to lower the cost of DNA sequencing beyond what is possible with standard dye-terminator methods. In ultra-high-throughput sequencing as many as 500,000 sequencing-by-synthesis operations may be run in parallel.\n\nThe first of the high-throughput sequencing technologies, massively parallel signature sequencing (or MPSS), was developed in the 1990s at Lynx Therapeutics, a company founded in 1992 by Sydney Brenner and Sam Eletr. MPSS was a bead-based method that used a complex approach of adapter ligation followed by adapter decoding, reading the sequence in increments of four nucleotides. This method made it susceptible to sequence-specific bias or loss of specific sequences. Because the technology was so complex, MPSS was only performed 'in-house' by Lynx Therapeutics and no DNA sequencing machines were sold to independent laboratories. Lynx Therapeutics merged with Solexa (later acquired by Illumina) in 2004, leading to the development of sequencing-by-synthesis, a simpler approach acquired from Manteia Predictive Medicine, which rendered MPSS obsolete. However, the essential properties of the MPSS output were typical of later high-throughput data types, including hundreds of thousands of short DNA sequences. In the case of MPSS, these were typically used for sequencing cDNA for measurements of gene expression levels.\n\nThe Polony sequencing method, developed in the laboratory of George M. Church at Harvard, was among the first high-throughput sequencing systems and was used to sequence a full \"E. coli\" genome in 2005. It combined an in vitro paired-tag library with emulsion PCR, an automated microscope, and ligation-based sequencing chemistry to sequence an \"E. coli\" genome at an accuracy of >99.9999% and a cost approximately 1/9 that of Sanger sequencing. The technology was licensed to Agencourt Biosciences, subsequently spun out into Agencourt Personal Genomics, and eventually incorporated into the Applied Biosystems SOLiD platform. Applied Biosystems was later acquired by Life Technologies, now part of Thermo Fisher Scientific.\n\nA parallelized version of pyrosequencing was developed by 454 Life Sciences, which has since been acquired by Roche Diagnostics. The method amplifies DNA inside water droplets in an oil solution (emulsion PCR), with each droplet containing a single DNA template attached to a single primer-coated bead that then forms a clonal colony. The sequencing machine contains many picoliter-volume wells each containing a single bead and sequencing enzymes. Pyrosequencing uses luciferase to generate light for detection of the individual nucleotides added to the nascent DNA, and the combined data are used to generate sequence reads. This technology provides intermediate read length and price per base compared to Sanger sequencing on one end and Solexa and SOLiD on the other.\n\nSolexa, now part of Illumina, was founded by Shankar Balasubramanian and David Klenerman in 1998, and developed a sequencing method based on reversible dye-terminators technology, and engineered polymerases. The reversible terminated chemistry concept was invented by Bruno Canard and Simon Sarfati at the Pasteur Institute in Paris. It was developed internally at Solexa by those named on the relevant patents. In 2004, Solexa acquired the company Manteia Predictive Medicine in order to gain a massively parallel sequencing technology invented in 1997 by Pascal Mayer and Laurent Farinelli. It is based on \"DNA Clusters\" or \"DNA colonies\", which involves the clonal amplification of DNA on a surface. The cluster technology was co-acquired with Lynx Therapeutics of California. Solexa Ltd. later merged with Lynx to form Solexa Inc.\n\nIn this method, DNA molecules and primers are first attached on a slide or flow cell and amplified with polymerase so that local clonal DNA colonies, later coined \"DNA clusters\", are formed. To determine the sequence, four types of reversible terminator bases (RT-bases) are added and non-incorporated nucleotides are washed away. A camera takes images of the fluorescently labeled nucleotides. Then the dye, along with the terminal 3' blocker, is chemically removed from the DNA, allowing for the next cycle to begin. Unlike pyrosequencing, the DNA chains are extended one nucleotide at a time and image acquisition can be performed at a delayed moment, allowing for very large arrays of DNA colonies to be captured by sequential images taken from a single camera.\n\nDecoupling the enzymatic reaction and the image capture allows for optimal throughput and theoretically unlimited sequencing capacity. With an optimal configuration, the ultimately reachable instrument throughput is thus dictated solely by the analog-to-digital conversion rate of the camera, multiplied by the number of cameras and divided by the number of pixels per DNA colony required for visualizing them optimally (approximately 10 pixels/colony). In 2012, with cameras operating at more than 10 MHz A/D conversion rates and available optics, fluidics and enzymatics, throughput can be multiples of 1 million nucleotides/second, corresponding roughly to 1 human genome equivalent at 1x coverage per hour per instrument, and 1 human genome re-sequenced (at approx. 30x) per day per instrument (equipped with a single camera).\n\nThis method is an upgraded modification to combinatorial probe anchor ligation technology (cPAL) described by Complete Genomics which has since become part of Chinese genomics company BGI in 2013. The two companies have refined the technology to allow for longer read lengths, reaction time reductions and faster time to results. In addition, data are now generated as contiguous full-length reads in the standard FASTQ file format and can be used as-is in most short-read-based bioinformatics analysis pipelines.\n\nThe two technologies that form the basis for this high-throughput sequencing technology are DNA nanoballs (DNB) and patterned arrays for nanoball attachment to a solid surface. DNA nanoballs are simply formed by denaturing double stranded, adapter ligated libraries and ligating the forward strand only to a splint oligonucleotide to form a ssDNA circle. Faithful copies of the circles containing the DNA insert are produced utilizing Rolling Circle Amplification that generates approximately 300–500 copies. The long strand of ssDNA folds upon itself to produce a three-dimensional nanoball structure that is approximately 220 nm in diameter. Making DNBs replaces the need to generate PCR copies of the library on the flow cell and as such can remove large proportions of duplicate reads, adapter-adapter ligations and PCR induced errors.\n\nThe patterned array of positively charged spots is fabricated through photolithography and etching techniques followed by chemical modification to generate a sequencing flow cell. Each spot on the flow cell is approximately 250 nm in diameter, are separated by 700 nm (centre to centre) and allows easy attachment of a single negatively charged DNB to the flow cell and thus reducing under or over-clustering on the flow cell.\n\nSequencing is then performed by addition of an oligonucleotide probe that attaches in combination to specific sites within the DNB. The probe acts as an anchor that then allows one of four single reversibly inactivated, labelled nucleotides to bind after flowing across the flow cell. Unbound nucleotides are washed away before laser excitation of the attached labels then emit fluorescence and signal is captured by cameras that is converted to a digital output for base calling. The attached base has its terminator and label chemically cleaved at completion of the cycle. The cycle is repeated with another flow of free, labelled nucleotides across the flow cell to allow the next nucleotide to bind and have its signal captured. This process is completed a number of times (usually 50 to 300 times) to determine the sequence of the inserted piece of DNA at a rate of approximately 40 million nucleotides per second as of 2018.\n\nApplied Biosystems' (now a Life Technologies brand) SOLiD technology employs sequencing by ligation. Here, a pool of all possible oligonucleotides of a fixed length are labeled according to the sequenced position. Oligonucleotides are annealed and ligated; the preferential ligation by DNA ligase for matching sequences results in a signal informative of the nucleotide at that position. Before sequencing, the DNA is amplified by emulsion PCR. The resulting beads, each containing single copies of the same DNA molecule, are deposited on a glass slide. The result is sequences of quantities and lengths comparable to Illumina sequencing. This sequencing by ligation method has been reported to have some issue sequencing palindromic sequences.\n\nIon Torrent Systems Inc. (now owned by Life Technologies) developed a system based on using standard sequencing chemistry, but with a novel, semiconductor-based detection system. This method of sequencing is based on the detection of hydrogen ions that are released during the polymerisation of DNA, as opposed to the optical methods used in other sequencing systems. A microwell containing a template DNA strand to be sequenced is flooded with a single type of nucleotide. If the introduced nucleotide is complementary to the leading template nucleotide it is incorporated into the growing complementary strand. This causes the release of a hydrogen ion that triggers a hypersensitive ion sensor, which indicates that a reaction has occurred. If homopolymer repeats are present in the template sequence, multiple nucleotides will be incorporated in a single cycle. This leads to a corresponding number of released hydrogens and a proportionally higher electronic signal.\n\nDNA nanoball sequencing is a type of high throughput sequencing technology used to determine the entire genomic sequence of an organism. The company Complete Genomics uses this technology to sequence samples submitted by independent researchers. The method uses rolling circle replication to amplify small fragments of genomic DNA into DNA nanoballs. Unchained sequencing by ligation is then used to determine the nucleotide sequence. This method of DNA sequencing allows large numbers of DNA nanoballs to be sequenced per run and at low reagent costs compared to other high-throughput sequencing platforms. However, only short sequences of DNA are determined from each DNA nanoball which makes mapping the short reads to a reference genome difficult. This technology has been used for multiple genome sequencing projects and is scheduled to be used for more.\n\nHeliscope sequencing is a method of single-molecule sequencing developed by Helicos Biosciences. It uses DNA fragments with added poly-A tail adapters which are attached to the flow cell surface. The next steps involve extension-based sequencing with cyclic washes of the flow cell with fluorescently labeled nucleotides (one nucleotide type at a time, as with the Sanger method). The reads are performed by the Heliscope sequencer. The reads are short, averaging 35 bp. In 2009 a human genome was sequenced using the Heliscope, however in 2012 the company went bankrupt.\n\nSMRT sequencing is based on the sequencing by synthesis approach. The DNA is synthesized in zero-mode wave-guides (ZMWs) – small well-like containers with the capturing tools located at the bottom of the well. The sequencing is performed with use of unmodified polymerase (attached to the ZMW bottom) and fluorescently labelled nucleotides flowing freely in the solution. The wells are constructed in a way that only the fluorescence occurring by the bottom of the well is detected. The fluorescent label is detached from the nucleotide upon its incorporation into the DNA strand, leaving an unmodified DNA strand. According to Pacific Biosciences (PacBio), the SMRT technology developer, this methodology allows detection of nucleotide modifications (such as cytosine methylation). This happens through the observation of polymerase kinetics. This approach allows reads of 20,000 nucleotides or more, with average read lengths of 5 kilobases. In 2015, Pacific Biosciences announced the launch of a new sequencing instrument called the Sequel System, with 1 million ZMWs compared to 150,000 ZMWs in the PacBio RS II instrument. SMRT sequencing is referred to as \"third-generation\" or \"long-read\" sequencing.\n\nThe DNA passing through the nanopore changes its ion current. This change is dependent on the shape, size and length of the DNA sequence. Each type of the nucleotide blocks the ion flow through the pore for a different period of time. The method does not require modified nucleotides and is performed in real time. Nanopore sequencing is referred to as \"third-generation\" or \"long-read\" sequencing, along with SMRT sequencing.\n\nEarly industrial research into this method was based on a technique called 'Exonuclease sequencing', where the readout of electrical signals occurring at nucleotides passing by alpha(α)-hemolysin pores covalently bound with cyclodextrin. However the subsequently commercial method, 'strand sequencing' sequencing DNA bases in an intact strand.\n\nTwo main areas of nanopore sequencing in development are solid state nanopore sequencing, and protein based nanopore sequencing. Protein nanopore sequencing utilizes membrane protein complexes such as α-hemolysin, MspA (\"Mycobacterium smegmatis\" Porin A) or CssG, which show great promise given their ability to distinguish between individual and groups of nucleotides. In contrast, solid-state nanopore sequencing utilizes synthetic materials such as silicon nitride and aluminum oxide and it is preferred for its superior mechanical ability and thermal and chemical stability. The fabrication method is essential for this type of sequencing given that the nanopore array can contain hundreds of pores with diameters smaller than eight nanometers.\n\nThe concept originated from the idea that single stranded DNA or RNA molecules can be electrophoretically driven in a strict linear sequence through a biological pore that can be less than eight nanometers, and can be detected given that the molecules release an ionic current while moving through the pore. The pore contains a detection region capable of recognizing different bases, with each base generating various time specific signals corresponding to the sequence of bases as they cross the pore which are then evaluated. Precise control over the DNA transport through the pore is crucial for success. Various enzymes such as exonucleases and polymerases have been used to moderate this process by positioning them near the pore’s entrance.\n\nDNA sequencing methods currently under development include reading the sequence as a DNA strand transits through nanopores (a method that is now commercial but subsequent generations such as solid-state nanopores are still in development), and microscopy-based techniques, such as atomic force microscopy or transmission electron microscopy that are used to identify the positions of individual nucleotides within long DNA fragments (>5,000 bp) by nucleotide labeling with heavier elements (e.g., halogens) for visual detection and recording.\nThird generation technologies aim to increase throughput and decrease the time to result and cost by eliminating the need for excessive reagents and harnessing the processivity of DNA polymerase.\n\nAnother approach uses measurements of the electrical tunnelling currents across single-strand DNA as it moves through a channel. Depending on its electronic structure, each base affects the tunnelling current differently, allowing differentiation between different bases.\n\nThe use of tunnelling currents has the potential to sequence orders of magnitude faster than ionic current methods and the sequencing of several DNA oligomers and micro-RNA has already been achieved.\n\n\"Sequencing by hybridization\" is a non-enzymatic method that uses a DNA microarray. A single pool of DNA whose sequence is to be determined is fluorescently labeled and hybridized to an array containing known sequences. Strong hybridization signals from a given spot on the array identifies its sequence in the DNA being sequenced.\n\nThis method of sequencing utilizes binding characteristics of a library of short single stranded DNA molecules (oligonucleotides), also called DNA probes, to reconstruct a target DNA sequence. Non-specific hybrids are removed by washing and the target DNA is eluted. Hybrids are re-arranged such that the DNA sequence can be reconstructed. The benefit of this sequencing type is its ability to capture a large number of targets with a homogenous coverage. A large number of chemicals and starting DNA is usually required. However, with the advent of solution-based hybridization, much less equipment and chemicals are necessary.\n\nMass spectrometry may be used to determine DNA sequences. Matrix-assisted laser desorption ionization time-of-flight mass spectrometry, or MALDI-TOF MS, has specifically been investigated as an alternative method to gel electrophoresis for visualizing DNA fragments. With this method, DNA fragments generated by chain-termination sequencing reactions are compared by mass rather than by size. The mass of each nucleotide is different from the others and this difference is detectable by mass spectrometry. Single-nucleotide mutations in a fragment can be more easily detected with MS than by gel electrophoresis alone. MALDI-TOF MS can more easily detect differences between RNA fragments, so researchers may indirectly sequence DNA with MS-based methods by converting it to RNA first.\n\nThe higher resolution of DNA fragments permitted by MS-based methods is of special interest to researchers in forensic science, as they may wish to find single-nucleotide polymorphisms in human DNA samples to identify individuals. These samples may be highly degraded so forensic researchers often prefer mitochondrial DNA for its higher stability and applications for lineage studies. MS-based sequencing methods have been used to compare the sequences of human mitochondrial DNA from samples in a Federal Bureau of Investigation database and from bones found in mass graves of World War I soldiers.\n\nEarly chain-termination and TOF MS methods demonstrated read lengths of up to 100 base pairs. Researchers have been unable to exceed this average read size; like chain-termination sequencing alone, MS-based DNA sequencing may not be suitable for large \"de novo\" sequencing projects. Even so, a recent study did use the short sequence reads and mass spectroscopy to compare single-nucleotide polymorphisms in pathogenic \"Streptococcus\" strains.\n\nIn microfluidic Sanger sequencing the entire thermocycling amplification of DNA fragments as well as their separation by electrophoresis is done on a single glass wafer (approximately 10 cm in diameter) thus reducing the reagent usage as well as cost. In some instances researchers have shown that they can increase the throughput of conventional sequencing through the use of microchips. Research will still need to be done in order to make this use of technology effective.\n\nThis approach directly visualizes the sequence of DNA molecules using electron microscopy. The first identification of DNA base pairs within intact DNA molecules by enzymatically incorporating modified bases, which contain atoms of increased atomic number, direct visualization and identification of individually labeled bases within a synthetic 3,272 base-pair DNA molecule and a 7,249 base-pair viral genome has been demonstrated.\n\nThis method is based on use of RNA polymerase (RNAP), which is attached to a polystyrene bead. One end of DNA to be sequenced is attached to another bead, with both beads being placed in optical traps. RNAP motion during transcription brings the beads in closer and their relative distance changes, which can then be recorded at a single nucleotide resolution. The sequence is deduced based on the four readouts with lowered concentrations of each of the four nucleotide types, similarly to the Sanger method. A comparison is made between regions and sequence information is deduced by comparing the known sequence regions to the unknown sequence regions.\n\nA method has been developed to analyze full sets of protein interactions using a combination of 454 pyrosequencing and an \"in vitro\" virus mRNA display method. Specifically, this method covalently links proteins of interest to the mRNAs encoding them, then detects the mRNA pieces using reverse transcription PCRs. The mRNA may then be amplified and sequenced. The combined method was titled IVV-HiTSeq and can be performed under cell-free conditions, though its results may not be representative of \"in vivo\" conditions.\n\nThe success of any DNA sequencing protocol relies upon the DNA or RNA sample extraction and preparation from the biological material of interest.\n\nAccording to the sequencing technology to be used, the samples resulting from either the DNA or the RNA extraction require further preparation. For Sanger sequencing, either cloning procedures or PCR are required prior to sequencing. In the case of next-generation sequencing methods, library preparation is required before processing. Assessing the quality and quantity of nucleic acids both after extraction and after library preparation identifies degraded, fragmented, and low-purity samples and yields high-quality sequencing data.\n\nIn October 2006, the X Prize Foundation established an initiative to promote the development of full genome sequencing technologies, called the Archon X Prize, intending to award $10 million to \"the first Team that can build a device and use it to sequence 100 human genomes within 10 days or less, with an accuracy of no more than one error in every 100,000 bases sequenced, with sequences accurately covering at least 98% of the genome, and at a recurring cost of no more than $10,000 (US) per genome.\"\n\nEach year the National Human Genome Research Institute, or NHGRI, promotes grants for new research and developments in genomics. 2010 grants and 2011 candidates include continuing work in microfluidic, polony and base-heavy sequencing methodologies.\n\nThe sequencing technologies described here produce raw data that needs to be assembled into longer sequences such as complete genomes (sequence assembly). There are many computational challenges to achieve this, such as the evaluation of the raw sequence data which is done by programs and algorithms such as Phred and Phrap. Other challenges have to deal with repetitive sequences that often prevent complete genome assemblies because they occur in many places of the genome. As a consequence, many sequences may not be assigned to particular chromosomes. The production of raw sequence data is only the beginning of its detailed bioinformatical analysis. Yet new methods for sequencing and correcting sequencing errors were developed.\n\nSometimes, the raw reads produced by the sequencer are correct and precise only in a fraction of their length. Using the entire read may introduce artifacts in the downstream analyses like genome assembly, snp calling, or gene expression estimation. Two classes of trimming programs have been introduced, based on the window-based or the running-sum classes of algorithms. This is a partial list of the trimming algorithms currently available, specifying the algorithm class they belong to:\n\nHuman genetics have been included within the field of bioethics since the early 1970s and the growth in the use of DNA sequencing (particularly high-throughput sequencing) has introduced a number of ethical issues. One key issue is the ownership of an individual's DNA and the data produced when that DNA is sequenced. Regarding the DNA molecule itself, the leading legal case on this topic, \"Moore v. Regents of the University of California\" (1990) ruled that individuals have no property rights to discarded cells or any profits made using these cells (for instance, as a patented cell line). However, individuals have a right to informed consent regarding removal and use of cells. Regarding the data produced through DNA sequencing, \"Moore\" gives the individual no rights to the information derived from their DNA.\n\nAs DNA sequencing becomes more widespread, the storage, security and sharing of genomic data has also become more important. For instance, one concern is that insurers may use an individual's genomic data to modify their quote, depending on the perceived future health of the individual based on their DNA. In May 2008, the Genetic Information Nondiscrimination Act (GINA) was signed in the United States, prohibiting discrimination on the basis of genetic information with respect to health insurance and employment. In 2012, the US Presidential Commission for the Study of Bioethical Issues reported that existing privacy legislation for DNA sequencing data such as GINA and the Health Insurance Portability and Accountability Act were insufficient, noting that whole-genome sequencing data was particularly sensitive, as it could be used to identify not only the individual from which the data was created, but also their relatives.\n\nEthical issues have also been raised by the increasing use of genetic variation screening, both in newborns, and in adults by companies such as 23andMe. It has been asserted that screening for genetic variations can be harmful, increasing anxiety in individuals who have been found to have an increased risk of disease. For example, in one case noted in \"Time\", doctors screening an ill baby for genetic variants chose not to inform the parents of an unrelated variant linked to dementia due to the harm it would cause to the parents. However, a 2011 study in \"The New England Journal of Medicine\" has shown that individuals undergoing disease risk profiling did not show increased levels of anxiety.\n\n\n"}
{"id": "42486408", "url": "https://en.wikipedia.org/wiki?curid=42486408", "title": "Death and adjustment hypotheses", "text": "Death and adjustment hypotheses\n\nDeath and adjustment hypotheses (DAH) is a theory about death and dying that focuses on death anxiety (psychology) and adjustment to death. It was presented by Mohammad Samir Hossain as an answer to the overwhelming anxiety and grief about death. In an attempt to find the resolution to death anxiety, predominantly the existential one, DAH postulates two key themes. Its first part postulates that death should not be considered the end of existence and the second part emphasizes that the belief in immortal pattern of human existence can only be adopted in a morally rich life with the attitude towards morality and materialism balanced mutually.\n\nThe theory was first promoted in the book \"Quest for a New Death: Death and Adjustment Hypotheses\" in 2007. A second book with its elaboration, \"Human Immortality: Death and Adjustment Hypotheses Elaborated\", was published in 2008. Both books were authored by Hossain. Later the journal \"Death Studies\" and Royal College of Psychiatrists reviewed these publications for the readerships in Scientific Thanatology and Spiritual Psychiatry. After the analyses of the reviewers were published, the Royal College of Psychiatrists at London published the theory itself as the short article \"Facing the Finality: Death and Adjustment Hypotheses\" and the Taylor & Francis publication \"Journal of Loss and Trauma\" did the same in its article \"Introducing Death and Adjustment Hypotheses\".\n\nHossain was intolerant to death himself. His childhood was terrified with the anticipatory thoughts of his parents' death. When his elder son Mohammad Seeyam Samir died, parallel to developing support for himself, Hossain decided to put forward his resolutions for death anxiety and grief through the scientific readerships. His research works during and after that period gave birth to the articles and books that he later published promoting the theory and for sufferers of intense death anxiety. Hossain's works on the theory further flourished as his parents' terminal illnesses appeared and compelled him to adjust himself comprehensively to the phenomenon of death for a peaceful personal life. He admitted in one of his autobiographical articles that without the turmoils in his own life he could never realize about the disasters and work to prevent them.\n\nFactors behind the DAH are described in \"European Psychiatry\", Volume 26, Supplement 1, Page 1727 in the following manner –\n\n\"Viewed from a naturalistic and scientific perspective, death appears to represent the permanent cessation of human existence, contributing to the widespread experience of death anxiety. The present argument attempts to deconstruct this argument on epistemological grounds by analyzing\n1) the prevailing universal concept of death in naturalistic discourse, \n2) the issue of our adjustment to this presumed reality, and \n3) the relationship between existence and death in the context of their social evolution. \nIntegrating this conceptual analysis with empirical observations, the paper then explores the contrasting postulate, namely that death may not be the end of our existence, and the moral\nimplications of this alternative assumption. This position, termed the \"death adjustment hypotheses,\" would seem to offer an alternative grounding for theory and research in Thanatology.\"\n\nFinding a common platform regarding the concept of death was the first step towards this work. Dr Hossain's finding was that without a common idea about death people will not be able to share the same remedy for death anxiety. There are many scientific approaches to the concept. For example, brain death, as practiced in medical science, defines death as a point in time at which brain activity ceases. It was Hossain's claim that whenever death is taken as permanent and absolute cessation of human existence, morbid fear of death begins; therefore DAH he presented with different ideas of death in relation to existence to reach a conclusion that will be acceptable to most.\n\nDeath anxiety is the central concern of DAH. It is the morbid, abnormal or persistent fear of one's own death or the process of his/her dying. One definition of death anxiety is a \"feeling of dread, apprehension or solicitude (anxiety) when one thinks of the process of dying, or ceasing to ‘be’\". It is also referred to as thanatophobia (fear of death), and is distinguished from necrophobia, which is a specific fear of dead or dying persons and/or things (i.e. others who are dead or dying, not one's own death or dying). DAH proposes that no one is free from this anxiety unless there is something significantly positive in the phenomenon of death for humans. Hossain claimed, the idea of 'cessation of existence' through death is the prime factor responsible for initiating death anxiety in one.\n\nIt is apparent that Hossain's description of death anxiety in DAH actually overlaps the idea of existential death anxiety, which is the basic knowledge and awareness that life must end. However, DAH indicates 'existence' as the primary humane need and 'pleasure' as the secondary one. Therefore, DAH postulates, though existential death anxiety strongly correlates behavioral changes, pleasure in existence must be ensured to maintain the balance between life and death peacefully. Hossain, in the iteration of DAH, highlighted how this sort of death anxiety evolved in the society through time based on his analysis of the history of the West starting from 5th century up to 20th century. DAH adds that assurance of pleasure or pain-free status in any existence after death is another key factor in adjusting with the phenomenon of death even if one is not overwhelmed by existential death anxiety due to his/her belief in any sort of existence after death.\n\nHossain explained, as existence after death creates the scope for being judged and punished for the immoral deeds in life, most self-claimed believers pass through the denial of afterlife for their immorality in search of limitless materialistic pleasure. Therefore, one of the key propositions of DAH was the fact that mostly humans abandon their moral ethics due to heightened materialism that gives birth to existential death anxiety even among the self-claimed believers in the existence after death.\n\nAs outlined very briefly in journal articles, DAH hypothesizes the following for optimum attitude towards death as well as to harmonize the adjustment problems in relation to the phenomenon:\n\n\n\n"}
{"id": "9997040", "url": "https://en.wikipedia.org/wiki?curid=9997040", "title": "Dick van Dijk", "text": "Dick van Dijk\n\nDirk Wouter Johannes \"Dick\" van Dijk (15 February 1946 – 8 July 1997) was a Dutch footballer who played for FC Twente and Ajax Amsterdam. He was a member of Ajax's European Cup victory in 1971. He earned seven caps for the Netherlands national football team.\n\nDick van Dijk grew up in Gouda and played football in his youth in the local amateur club. When he was sixteen, he met coach Hans Croon of SVV, with whom he played in the Second division. Van Dijk was the top scorer for the club in 1966 when SVV won promotion to the First Division. He was invited to the Dutch youth team and the Dutch military team. The scoring ability of the young star attracted the interest of FC Twente, but the asking price of 200,000 guilders was too much. A less impressive season ensured that the transfer fee a year later had dropped to 70,000 guilders, with Van Dijk joining FC Twente in the summer of 1967.\n\nAt Twente, Van Dijk formed a strong attacking partnership with Theo Pahlplatz, scoring 22 times and helping a youthful side to a creditable eighth-place finish in his first season. The following year Van Dijk finished as top scorer in the Premier League with 30 goals. In a legendary home match against Ajax on 3 November 1968, Twente won 5–1 and Van Dijk scored three goals. It is believed that this contest sparked the interest of Ajax in Van Dijk, who in June 1969 moved to Amsterdam for a transfer fee of 750,000 guilders.\n\nWhile Van Dijk had been a star player at Twente, he had to fight for a spot at Ajax, becoming as a result a more complete footballer who knew how to defend. In his first season, he scored 23 goals in 32 matches. Although not a regular starter during his second season, he nonetheless scored 18 goals in 29 matches. Van Dijk started in the final of the European Cup on June 1971 against Panathinaikos, scoring with a header after five minutes in Ajax's 2–0 victory.\n\nAfter a third season at Ajax, where he was mainly a reserve player, Van Dijk departed in 1972 to OGC Nice in France. There he scored frequently, helping the team to a second-place finish in season 1972/1973. On September 19, 1973, Nice achieved a remarkable 3-0 victory in the first leg of their UEFA Cup tie with FC Barcelona, whose coach was Dutchman Rinus Michels and whose star player (although he did not figure in the match) was Johan Cruijff. (Nice would go on to win the tie 3-2 on aggregate.) In 1974, Van Dijk joined Real Murcia in Spain, and a year later ended his football career.\n\nMeanwhile, Van Dijk had made his international debut on 26 March 1969 in a match for the Dutch national team against Luxembourg. Van Dijk scored once in a 4–0 victory.\n\nOn 10 October 1971 Van Dijk played his seventh and final international match against East Germany.\n\nAfter his playing career, he went back to Nice, working as a broker and living in nearby Saint-Paul-de-Vence.\n\nIn 1997, he died suddenly at 51 years of age from acute endocarditis, a bacterial infection of the heart valves. In his memory, a benefit match was organized on 12 October 1997 between ONA Gouda and the Ajax of the Europe Cup I-finals from 1971. In May 2017, 20 years after his death, another matched was staged in his memory between former Ajax players and Nice.\n\n"}
{"id": "1285228", "url": "https://en.wikipedia.org/wiki?curid=1285228", "title": "Egotism", "text": "Egotism\n\nEgotism is the drive to maintain and enhance favorable views of oneself, and generally features an inflated opinion of one's personal features and importance. It often includes intellectual, physical, social and other overestimations. \n\nThe egotist has an overwhelming sense of the centrality of the 'Me', that is to say of their personal qualities. Egotism means placing oneself at the core of one's world with no concern for others, including those \"loved\" or considered as \"close\", in any other terms except those subjectively set by the egotist.\n\nEgotism is closely related to an egocentric love for one's imagined self or narcissism – indeed some would say \"by egotism we may envisage a kind of socialized narcissism\". Egotists have a strong tendency to talk about themselves in a self-promoting fashion, and they may well be arrogant and boastful with a grandiose sense of their own importance. Their inability to recognise the accomplishments of others leaves them profoundly self-promoting; while sensitivity to criticism may lead on the egotist's part to narcissistic rage at a sense of insult.\n\nEgotism differs from both altruism – or acting to gain \"fewer\" values than are being given – and from egoism, the constant pursuit of one's self-interest. Various forms of \"empirical egoism\" have been considered consistent with egotism, but do not – which is also the case with egotism in general – necessitate having an inflated sense of self.\n\nIn developmental terms, two rather different trajectories can be distinguished with respect to egotism – the one individual, the other cultural.\n\nWith respect to the developing individual, a movement takes place from egocentricity to sociality during the process of growing up. It is normal for an infant to have an inflated – almost a majestic – sense of egotism. The over-evaluation of one's own ego regularly appears in childish forms of love – in large part because the baby is to himself everything, omnipotent to the best of their own knowledge.\n\nOptimal development allows a gradual reconciliation to a more realistic view of one's own place in the world – a lessening of the egotistical swollen head. Less adequate adjustment may later lead to what has been called defensive egotism, serving to overcompensate for the fragility of the underlying concept of self. Robin Skynner however considered that in the main growing up leads to a state where \"your ego is still there, but it's taking its proper limited place among all the other egos\".\n\nHowever, alongside such a positive trajectory of diminishing \"individual\" egotism, a rather different arc of development can be noted in cultural terms, linked to what has been seen as the increasing infantilism of (post)modern society. Whereas in the nineteenth century egotism was still widely regarded as a traditional vice – for Nathaniel Hawthorne egotism was a sort of diseased self-contemplation – Romanticism had already set in motion a countervailing current, what Richard Eldridge described as a kind of \"cultural egotism, substituting the individual imagination for vanishing social tradition\". The romantic idea of the self-creating individual – of a self-authorizing, artistic egotism – then took on broader social dimensions in the following century. Keats might still attack Wordsworth for the regressive nature of his retreat into the egotistical sublime; but by the close of the twentieth century egotism had been naturalized much more widely by the Me generation into the Culture of Narcissism.\n\nIn the 21st century, romantic egotism has been seen as feeding into techno-capitalism in two complementary ways: on the one hand, through the self-centred consumer, focused on their own self-fashioning through brand 'identity'; on the other through the equally egotistical voices of 'authentic' protest, as they rage against the machine, only to produce new commodity forms that serve to fuel the system for further consumption.\n\nThere is a question mark over the relationship between sex and egotism. Sigmund Freud popularly made the claim that love can transform the egotist, giving him or her a new sense of humility in relation to others.\n\nAt the same time, it is very apparent that egotism can readily show itself in sexual ways and indeed arguably one's whole sexuality may function in the service of egotistical needs.\n\nThe term egotism is derived from the Greek (\"εγώ\") and subsequently its Latinised ego (\"ego\"), meaning \"self\" or \"I,\" and \"-ism\", used to denote a system of belief. As such, the term shares early etymology with egoism.\n\n\n\n"}
{"id": "5858256", "url": "https://en.wikipedia.org/wiki?curid=5858256", "title": "Elphidium", "text": "Elphidium\n\nElphidium is an abundant genus of foraminifera. Species can be found from coastal regions out to the continental slope, and in all temperature ranges. Like other forams, fossils from different species are used to date rocks. The taxonomy of the species within this genus is disputed due to the high variability of some species.\n\n\"Elphidium\" is generally around 1 mm in size. The test is spiral-shaped, and can be red, orange, or brown. This shell is made up of either calcium carbonate or silica. It may incorporate sand or parts of other organisms, such as sponges. It has seven to twenty chambers in the final whorl, and may have an umbilical plug on each side. In some species the rim is sharp, while in others it is more rounded. Another distinctive feature is the retral processes (small backward extensions of the chamber walls) that cross the sutures, giving some the appearance of tiny rolled up glass baskets. \"Elphidium\" crawls using a type of pseudopod called reticulopodia.\n\n\"Elphidium\" shows dimorphism with alternating generations. \nThe complete cycle for \"Elphidium crispum\" takes two years in the shallower marine regions, although it may be delayed at deeper stations. \nAsexual reproduction reaches a peak in spring of the first year. \nSexual reproduction begins early in the second spring as temperatures begin to rise. \nThe gametes conjugate outside in open sea to produce zygotes and the B form then develops and matures during the second summer.\nLister (1895) observed \"Elphidium\" in two different forms as megalospheric form (sexual form) and microsperic form (asexual form). The megalosperic form was developed from the microsperic form. The gametes which gives rise to microspheric form by syngamy. \n\"Elphidium\" exhibits an alternation of generation in its life cycle. The megalosperic forms alternates with microspheric forms. The microspheric forms are developed by the conjugation or syngamy. It means there is always an alternations of asexual (microspheric) and sexual (megalospheric) generation in \"Elphidium\".\nThe microspheric form reproduces asexually by fission to produce a number of amoebulae. The inner cytoplasm mass containing several nuclei creeps out of the shell and remains as a lump around it. A small amount of cytoplasm collects around each nucleus. As a result, a large number of amoeboid cells are formed. Each amoebula secretes the proloculum, formsrhizopodia, then it grows and forms other chambers of the shell to become a megalospheric forms.\nThe megalospheric form reproduces sexually by syngamy or conjugation. During sexual reproduction in megalospheric forms, nucleus first breaks up into many small nuclei and the cytoplasm collects around each of these nuclei. The nuclei divide twice giving rise to a large haploid and known as isogametes. Isogametes of two different individuals fuse in pairs to form zygotes. These are then develops into microspheric form.\nThe life cycle of \"Elphidium\" may be summarized as follows: the microspheric forms produce amoebulae by asexual fission which develops into megalospheric forms. The megalospheric forms produce flagellated isogametes which after syngamy produce zygotes that develop into microspheric forms. Thus, its life cycle clearly exhibits the phenomenon of alternations of asexual microspheric generations with sexual megalospheric generations.\n\n"}
{"id": "42335875", "url": "https://en.wikipedia.org/wiki?curid=42335875", "title": "Employment (short story)", "text": "Employment (short story)\n\n\"Employment\" is a science fiction story by American writer L. Sprague de Camp, pioneering the concept of de-extinction. It was first published in the magazine \"Astounding Science-Fiction\" for May, 1939. The story appeared under the pseudonym Lyman R. Lyon (the name of his maternal great-grandfather) as the magazine's policy did not allow the name of any author to be repeated on the same contents page, and de Camp had another piece in the same issue under his actual name (part one of his article \"Design for Life\"). It first appeared in book form in the anthology \"Imagination Unlimited\" (Farrar Strauss and Young, 1952). It later appeared in the anthologies \"Men of Space and Time\" (The Bodley Head, 1953), and \"Science Fiction Inventions\" (Lancer Books, 1967), as well as the de Camp collection \"The Best of L. Sprague de Camp\" (Doubleday, 1978). It was credited to de Camp's real name in all publications subsequent to its first appearance. The story has been translated into German.\n\nThe story is set in the then-future era of the late 1950s, and is presented in the form of a letter from the protagonist, geologist Kenneth Staples, to a prospective employer, explaining why he desires to leave his present job.\n\nStaples has been working for paleontologist and inventor Gilmore Platt, whose stereoscopic prospecting device can locate and reveal buried fossils in full detail. From an archeological colleague, Dr. Wilhelmi of Zurich, Platt gets the idea of using an electrolytic bath to restore the specimens he has been retrieving to their original condition, just as the archaeologist can do with corroded bronzes whose atoms have partly dissipated into the surrounding soil. After much experimentation, Platt and Staples succeed in restoring complete animals, hair and all, from fossil skeletons and the matrices of rock in which they are embedded. First they reconstruct an extinct Canis dirus (dire wolf), reviving it by applying an electric starter to its heart. They repeat the process with an Arctotherium (short-faced bear), which they are unable to revive and is mounted in the American Museum of Natural History, Stenomylus hitchcocki (an ancestral camel), Trilophodon (a primitive proboscidean), and Dinocyon gidleyi (a bear-dog).\n\nThey hire Elias, a former circus man, to manage their growing zoo, which they house in a concrete barn with a row of cages down one side. Staples has a close shave when the Dinocyon escapes its cage in an attempt to prey on the Stenomylus and sees him as an adequate substitute. Platt and Elias come to his rescue, the former with a gun and the latter with a stick of dynamite. It takes the dynamite to do it. Platt then calmly revivifies the bear dog again, but incarcerates it in a stronger cage! It is later sold to the Philadelphia Zoo. It is replaced with a Dinohyus (a piglike animal the size of a buffalo).\n\nNews of the sale attracts a Mr. Nively, representing the Marco Polo Company, a membership corporation consisting of the whole country's wild animal importers and dealers. His clients want to buy out Platt's discovery, as the resurrection of prehistoric creatures has the potential to ruin the market for present-day animals, which they control. After Platt rejects a number of offers Nively resorts to threats, and is kicked out.\n\nMeanwhile, Platt and Staples recreate their biggest animal yet, a specimen of Parelephas jeffersonii (Jeffersonian mammoth), which they name Tecumtha after the historical Shawnee chief. They also take on a new man, Jake, to assist Elias and help protect their menagerie against Nively. The precaution is well taken, but inadequate. Nively reappears early one morning and attempts to shoot Tecumtha. Enraged, the mammoth takes off after Nively, who tries to escape on Elias's bicycle. Staples, still in his pajamas, pursues both by truck. He eventually finds them in a nearby town square, with Nively perched atop an equestrian statue of General Sheridan while Tecumtha prowls about its base. When the mammoth pushes over the statue Nively transfers to a nearby tree. On Staples's advice, he then moves to the top of the truck cab to help lure Tecumtha up into the truck bed. With the animal secured, Staples extorts Nively's clothing from him and lets the villain go, only to get into a dispute with local police, who want to kill the creature as a dangerous wild animal. Rather than permit this, Staples drives off.\n\nAfter shaking pursuit he calls Platt, who tells him the police have their lab staked out against his return. Accordingly, Platt suggests he drive to Chicago and sell Tecumtha to the zoo there before returning. Unfortunately, Dr. Traphagen at the zoo assumes Staples a madman on hearing his story, particularly since he can't even confirm his own identity, the only identification he can produce being Nively's. Led away by the men in the white suits, he calls to Tecumtha, whose trumpeting finally convinces Traphagen of his veracity. The sale is completed, and Tecumtha saved.\n\nAfterwards, Platt hires more guards and has his compound properly fenced. He begins to recreate more animals, including a Mastodon americanus for the Bronx Zoo in New York. He hires another paleontologist as an additional assistant and with him starts happily digging dinosaurs in Wyoming. Staples learns the two have found a complete Tyrannosaurus Rex skeleton, and in light of his experiences so far decides it's time to \"clear out while I'm still in one piece.\"\n\nThe plot feature of a disaffected businessman's designs on a recovered mammoth is echoed in de Camp's later Reginald Rivers time travel story \"The Mislaid Mastodon\" (1993).\n"}
{"id": "3045792", "url": "https://en.wikipedia.org/wiki?curid=3045792", "title": "Foresight (futures studies)", "text": "Foresight (futures studies)\n\nIn futures studies, especially in Europe, the term \"foresight\" has become widely used to describe activities such as:\n\nIn the last decade, scenario methods, for example, have become widely used in some European countries in policy-making. The FORSOCIETY network brings together national Foresight teams from most European countries, and the European Foresight Monitoring Project is collating material on Foresight activities around the world. In addition, foresight methods are being used more and more in regional planning and decision –making (“regional foresight”). Several non-European think-tanks like Strategic Foresight Group are also engaged in foresight studies.\n\nThe foresight of futures studies is also known as strategic foresight. this foresight used by and describing professional futurists trained in Master's programs is the research-driven practice of exploring expected and alternative futures and guiding futures to inform strategy. Foresight includes understanding the relevant recent past; scanning to collect insight about present, futuring to describe the understood future including trend research; environment research to explore possible trend breaks from developments on the fringe and other divergencies that may lead to alternative futures; visioning to define preferred future states; designing strategies to craft this future; and adapting the present forces to implement this plan. There is notable but not complete overlap between foresight and strategic planning, change management, forecasting, and design thinking.\n\nAt the same time, the use of foresight for companies (“corporate foresight”) is becoming more professional and widespread Corporate foresight is used to support strategic management, identify new business fields and increase the innovation capacity of a firm.\n\nForesight is not the same as futures research or strategic planning. It encompasses a range of approaches that combine the three components mentioned above, which may be recast as:\n\nMuch futures research has been rather ivory tower work, but Foresight programmes were designed to influence policy - often R&D policy. Much technology policy had been very elitist; Foresight attempts to go beyond the \"usual suspects\" and gather widely distributed intelligence. These three lines of work were already common in Francophone futures studies going by the name \"la prospective\". But in the 1990s we began to see what became an explosion of systematic organisation of these methods in large scale TECHNOLOGY FORESIGHT programmes in Europe and more widely.\n\nForesight thus draws on traditions of work in long-range planning and strategic planning, horizontal policymaking and democratic planning, and participatory futures studies - but was also highly influenced by systemic approaches to innovation studies, science and technology policy, and analysis of \"critical technologies\".\n\nMany of the methods that are commonly associated with Foresight - Delphi surveys, scenario workshops, etc. - derive from the futures field. So does the fact that Foresight is concerned with:\n\n\n\nThere are numerous journals that deal with research on foresight:\n\n"}
{"id": "15858560", "url": "https://en.wikipedia.org/wiki?curid=15858560", "title": "George W. White (politician)", "text": "George W. White (politician)\n\nGeorge W. White (May 12, 1827 – March 21, 1912) was a political figure in New Brunswick, Canada. He represented Carleton County in the Legislative Assembly of New Brunswick from 1868 to 1873 and from 1878 to 1882 as a Conservative member.\n\nHe was born and educated in Queens County, New Brunswick. In 1849, he married Mary Wiggins. White served as coroner for Wilmot parish. He was elected to the legislative assembly in an 1868 by-election held after the death of James Hartley. White was a member of the Executive Council from 1872 to 1873. In 1873, he resigned and ran unsuccessfully for a seat in the House of Commons. He died in 1912.\n\n"}
{"id": "12514", "url": "https://en.wikipedia.org/wiki?curid=12514", "title": "Ghost", "text": "Ghost\n\nIn folklore, a ghost (sometimes known as an apparition, haunt, phantom, poltergeist, shade, specter or spectre, spirit, spook, and wraith) is the soul or spirit of a dead person or animal that can appear to the living. In ghostlore, descriptions of ghosts vary widely from an invisible presence to translucent or barely visible wispy shapes, to realistic, lifelike visions. The deliberate attempt to contact the spirit of a deceased person is known as necromancy, or in spiritism as a \"séance\".\n\nThe belief in the existence of an afterlife, as well as manifestations of the spirits of the dead, is widespread, dating back to animism or ancestor worship in pre-literate cultures. Certain religious practices—funeral rites, exorcisms, and some practices of spiritualism and ritual magic—are specifically designed to rest the spirits of the dead. Ghosts are generally described as solitary, human-like essences, though stories of ghostly armies and the ghosts of animals rather than humans have also been recounted. They are believed to haunt particular locations, objects, or people they were associated with in life.\n\nThe overwhelming consensus of science is that ghosts do not exist. Their existence is impossible to falsify, and ghost hunting has been classified as pseudoscience. Despite centuries of investigation, there is no scientific evidence that any location is inhabited by spirits of the dead.\n\nThe English word \"ghost\" continues Old English \"gāst\", from Proto-Germanic \"*gaistaz\". It is common to West Germanic, but lacking in North Germanic and East Germanic (the equivalent word in Gothic is \"ahma\", Old Norse has \"andi\" m., \"önd\" f.). The prior Proto-Indo-European form was \"\", from the root \" \" denoting \"fury, anger\" reflected in Old Norse \"geisa\" \"to rage\". The Germanic word is recorded as masculine only, but likely continues a neuter \"s\"-stem. The original meaning of the Germanic word would thus have been an animating principle of the mind, in particular capable of excitation and fury (compare \"óðr\"). In Germanic paganism, \"Germanic Mercury\", and the later Odin, was at the same time the conductor of the dead and the \"lord of fury\" leading the Wild Hunt.\n\nBesides denoting the human spirit or soul, both of the living and the deceased, the Old English word is used as a synonym of Latin \"spiritus\" also in the meaning of \"breath\" or \"blast\" from the earliest attestations (9th century). It could also denote any good or evil spirit, such as angels and demons; the Anglo-Saxon gospel refers to the demonic possession of Matthew 12:43 as \"se unclæna gast\". Also from the Old English period, the word could denote the spirit of God, viz. the \"Holy Ghost\".\n\nThe now-prevailing sense of \"the soul of a deceased person, spoken of as appearing in a visible form\" only emerges in Middle English (14th century). The modern noun does, however, retain a wider field of application, extending on one hand to \"soul\", \"spirit\", \"vital principle\", \"mind\", or \"psyche\", the seat of feeling, thought, and moral judgement; on the other hand used figuratively of any shadowy outline, or fuzzy or unsubstantial image; in optics, photography, and cinematography especially, a flare, secondary image, or spurious signal.\n\nThe synonym \"spook\" is a Dutch loanword, akin to Low German \"spôk\" (of uncertain etymology); it entered the English language via American English in the 19th century. Alternative words in modern usage include \"spectre\" (altn. \"specter\"; from Latin \"spectrum\"), the Scottish \"wraith\" (of obscure origin), \"phantom\" (via French ultimately from Greek \"phantasma\", compare \"fantasy\") and \"apparition\". The term \"shade\" in classical mythology translates Greek σκιά, or Latin \"umbra\", in reference to the notion of spirits in the Greek underworld. \"Haint\" is a synonym for ghost used in regional English of the southern United States, and the \"haint tale\" is a common feature of southern oral and literary tradition. The term \"poltergeist\" is a German word, literally a \"noisy ghost\", for a spirit said to manifest itself by invisibly moving and influencing objects.\n\n\"Wraith\" is a Scots word for \"ghost\", \"spectre\", or \"apparition\". It appeared in Scottish Romanticist literature, and acquired the more general or figurative sense of \"portent\" or \"omen\". In 18th- to 19th-century Scottish literature, it also applied to aquatic spirits. The word has no commonly accepted etymology; the \"OED\" notes \"of obscure origin\" only. An association with the verb \"writhe\" was the etymology favored by J. R. R. Tolkien. Tolkien's use of the word in the naming of the creatures known as the Ringwraiths has influenced later usage in fantasy literature. Bogey or \"bogy/bogie\" is a term for a ghost, and appears in Scottish poet John Mayne's \"Hallowe'en\" in 1780.\n\nA \"revenant\" is a deceased person returning from the dead to haunt the living, either as a disembodied ghost or alternatively as an animated (\"undead\") corpse. Also related is the concept of a fetch, the visible ghost or spirit of a person yet alive.\n\nA notion of the transcendent, supernatural, or numinous, usually involving entities like ghosts, demons, or deities, is a cultural universal. In pre-literate folk religions, these beliefs are often summarized under animism and ancestor worship. Some people believe the ghost or spirit never leaves Earth until there is no-one left to remember the one who died.\n\nIn many cultures, malignant, restless ghosts are distinguished from the more benign spirits involved in ancestor worship.\n\nAncestor worship typically involves rites intended to prevent revenants, vengeful spirits of the dead, imagined as starving and envious of the living. Strategies for preventing revenants may either include sacrifice, i.e., giving the dead food and drink to pacify them, or magical banishment of the deceased to force them not to return. Ritual feeding of the dead is performed in traditions like the Chinese Ghost Festival or the Western All Souls' Day. Magical banishment of the dead is present in many of the world's burial customs. The bodies found in many tumuli (kurgan) had been ritually bound before burial, and the custom of binding the dead persists, for example, in rural Anatolia.\n\nNineteenth-century anthropologist James Frazer stated in his classic work, \"The Golden Bough\", that souls were seen as the creature within that animated the body.\n\nAlthough the human soul was sometimes symbolically or literally depicted in ancient cultures as a bird or other animal, it appears to have been widely held that the soul was an exact reproduction of the body in every feature, even down to clothing the person wore. This is depicted in artwork from various ancient cultures, including such works as the Egyptian \"Book of the Dead\", which shows deceased people in the afterlife appearing much as they did before death, including the style of dress.\n\nWhile deceased ancestors are universally regarded as venerable, and often believed to have a continued presence in some form of afterlife, the spirit of a deceased person that persists in the material world (a ghost) is regarded as an unnatural or undesirable state of affairs and the idea of ghosts or revenants is associated with a reaction of fear. This is universally the case in pre-modern folk cultures, but fear of ghosts also remains an integral aspect of the modern ghost story, Gothic horror, and other horror fiction dealing with the supernatural.\n\nAnother widespread belief concerning ghosts is that they are composed of a misty, airy, or subtle material. Anthropologists link this idea to early beliefs that ghosts were the person within the person (the person's spirit), most noticeable in ancient cultures as a person's breath, which upon exhaling in colder climates appears visibly as a white mist. This belief may have also fostered the metaphorical meaning of \"breath\" in certain languages, such as the Latin \"spiritus\" and the Greek \"pneuma\", which by analogy became extended to mean the soul. In the Bible, God is depicted as synthesising Adam, as a living soul, from the dust of the Earth and the breath of God.\n\nIn many traditional accounts, ghosts were often thought to be deceased people looking for vengeance (vengeful ghosts), or imprisoned on earth for bad things they did during life. The appearance of a ghost has often been regarded as an omen or portent of death. Seeing one's own ghostly double or \"fetch\" is a related omen of death.\nWhite ladies were reported to appear in many rural areas, and supposed to have died tragically or suffered trauma in life. White Lady legends are found around the world. Common to many of them is the theme of losing a child or husband and a sense of purity, as opposed to the Lady in Red ghost that is mostly attributed to a jilted lover or prostitute. The White Lady ghost is often associated with an individual family line or regarded as a harbinger of death similar to a banshee.\n\nLegends of ghost ships have existed since the 18th century; most notable of these is the \"Flying Dutchman\". This theme has been used in literature in \"The Rime of the Ancient Mariner\" by Coleridge.\n\nThey are often depicted as being covered in a shroud and/or dragging chains.\n\nThe idea of ghosts can be considered a tradition for certain cultures. Many believe in the spirit world and often try to stay in contact with their loved ones.\n\nA place where ghosts are reported is described as haunted, and often seen as being inhabited by spirits of deceased who may have been former residents or were familiar with the property. Supernatural activity inside homes is said to be mainly associated with violent or tragic events in the building's past such as murder, accidental death, or suicide—sometimes in the recent or ancient past. But not all hauntings are at a place of a violent death, or even on violent grounds. Many cultures and religions believe the essence of a being, such as the 'soul', continues to exist. Some religious views argue that the 'spirits' of those who have died have not 'passed over' and are trapped inside the property where their memories and energy are strong.\n\nThere are many references to ghosts in Mesopotamian religions – the religions of Sumer, Babylon, Assyria, and other early states in Mesopotamia. Traces of these beliefs survive in the later Abrahamic religions that came to dominate the region.\nGhosts were thought to be created at time of death, taking on the memory and personality of the dead person. They traveled to the netherworld, where they were assigned a position, and led an existence similar in some ways to that of the living.\nRelatives of the dead were expected to make offerings of food and drink to the dead to ease their conditions. If they did not, the ghosts could inflict misfortune and illness on the living. Traditional healing practices ascribed a variety of illnesses to the action of ghosts, while others were caused by gods or demons.\n\nThere was widespread belief in ghosts in ancient Egyptian culture\nThe Hebrew Bible contains few references to ghosts, associating spiritism with forbidden occult activities cf. Deuteronomy 18:11. The most notable reference is in the First Book of Samuel (I Samuel 28:3–19 KJV), in which a disguised King Saul has the Witch of Endor summon the spirit or ghost of Samuel.\n\nThe soul and spirit were believed to exist after death, with the ability to assist or harm the living, and the possibility of a second death. Over a period of more than 2,500 years, Egyptian beliefs about the nature of the afterlife evolved constantly. Many of these beliefs were recorded in hieroglyph inscriptions, papyrus scrolls and tomb paintings. The Egyptian \"Book of the Dead\" compiles some of the beliefs from different periods of ancient Egyptian history.\nIn modern times, the fanciful concept of a mummy coming back to life and wreaking vengeance when disturbed has spawned a whole genre of horror stories and films.\n\nGhosts appeared in Homer's \"Odyssey\" and \"Iliad\", in which they were described as vanishing \"as a vapor, gibbering and whining into the earth\". Homer's ghosts had little interaction with the world of the living. Periodically they were called upon to provide advice or prophecy, but they do not appear to be particularly feared. Ghosts in the classical world often appeared in the form of vapor or smoke, but at other times they were described as being substantial, appearing as they had been at the time of death, complete with the wounds that killed them.\n\nBy the 5th century BC, classical Greek ghosts had become haunting, frightening creatures who could work to either good or evil purposes. The spirit of the dead was believed to hover near the resting place of the corpse, and cemeteries were places the living avoided. The dead were to be ritually mourned through public ceremony, sacrifice, and libations, or else they might return to haunt their families. The ancient Greeks held annual feasts to honor and placate the spirits of the dead, to which the family ghosts were invited, and after which they were \"firmly invited to leave until the same time next year.\"\n\nThe 5th-century BC play \"Oresteia\" includes an appearance of the ghost of Clytemnestra, one of the first ghosts to appear in a work of fiction.\n\nThe ancient Romans believed a ghost could be used to exact revenge on an enemy by scratching a curse on a piece of lead or pottery and placing it into a grave.\n\nPlutarch, in the 1st century AD, described the haunting of the baths at Chaeronea by the ghost of a murdered man. The ghost's loud and frightful groans caused the people of the town to seal up the doors of the building. Another celebrated account of a haunted house from the ancient classical world is given by Pliny the Younger (c. 50 AD). Pliny describes the haunting of a house in Athens, which was bought by the Stoic philosopher Athenodorus, who lived about 100 years before Pliny. Knowing that the house was supposedly haunted, Athenodorus intentionally set up his writing desk in the room where the apparition was said to appear and sat there writing until late at night when he was disturbed by a ghost bound in chains. He followed the ghost outside where it indicated a spot on the ground. When Athenodorus later excavated the area, a shackled skeleton was unearthed. The haunting ceased when the skeleton was given a proper reburial. The writers Plautus and Lucian also wrote stories about haunted houses.\n\nIn the New Testament, according to Luke 24:37–39, following his resurrection, Jesus was forced to persuade the Disciples that he was not a ghost (some versions of the Bible, such as the KJV and NKJV, use the term \"spirit\"). Similarly, Jesus' followers at first believed he was a ghost (spirit) when they saw him walking on water.\n\nOne of the first persons to express disbelief in ghosts was Lucian of Samosata in the 2nd century AD. In his satirical novel \"The Lover of Lies\" (circa 150 AD), he relates how Democritus \"the learned man from Abdera in Thrace\" lived in a tomb outside the city gates to prove that cemeteries were not haunted by the spirits of the departed. Lucian relates how he persisted in his disbelief despite practical jokes perpetrated by \"some young men of Abdera\" who dressed up in black robes with skull masks to frighten him. This account by Lucian notes something about the popular classical expectation of how a ghost should look.\n\nIn the 5th century AD, the Christian priest Constantius of Lyon recorded an instance of the recurring theme of the improperly buried dead who come back to haunt the living, and who can only cease their haunting when their bones have been discovered and properly reburied.\n\nGhosts reported in medieval Europe tended to fall into two categories: the souls of the dead, or demons. The souls of the dead returned for a specific purpose. Demonic ghosts existed only to torment or tempt the living. The living could tell them apart by demanding their purpose in the name of Jesus Christ. The soul of a dead person would divulge its mission, while a demonic ghost would be banished at the sound of the Holy Name.\n\nMost ghosts were souls assigned to Purgatory, condemned for a specific period to atone for their transgressions in life. Their penance was generally related to their sin. For example, the ghost of a man who had been abusive to his servants was condemned to tear off and swallow bits of his own tongue; the ghost of another man, who had neglected to leave his cloak to the poor, was condemned to wear the cloak, now \"heavy as a church tower\". These ghosts appeared to the living to ask for prayers to end their suffering. Other dead souls returned to urge the living to confess their sins before their own deaths.\n\nMedieval European ghosts were more substantial than ghosts described in the Victorian age, and there are accounts of ghosts being wrestled with and physically restrained until a priest could arrive to hear its confession. Some were less solid, and could move through walls. Often they were described as paler and sadder versions of the person they had been while alive, and dressed in tattered gray rags. The vast majority of reported sightings were male.\n\nThere were some reported cases of ghostly armies, fighting battles at night in the forest, or in the remains of an Iron Age hillfort, as at Wandlebury, near Cambridge, England. Living knights were sometimes challenged to single combat by phantom knights, which vanished when defeated.\n\nFrom the medieval period an apparition of a ghost is recorded from 1211, at the time of the Albigensian Crusade. Gervase of Tilbury, Marshal of Arles, wrote that the image of Guilhem, a boy recently murdered in the forest, appeared in his cousin's home in Beaucaire, near Avignon. This series of \"visits\" lasted all of the summer. Through his cousin, who spoke for him, the boy allegedly held conversations with anyone who wished, until the local priest requested to speak to the boy directly, leading to an extended disquisition on theology. The boy narrated the trauma of death and the unhappiness of his fellow souls in Purgatory, and reported that God was most pleased with the ongoing Crusade against the Cathar heretics, launched three years earlier. The time of the Albigensian Crusade in southern France was marked by intense and prolonged warfare, this constant bloodshed and dislocation of populations being the context for these reported visits by the murdered boy.\n\nHaunted houses are featured in the 9th-century \"Arabian Nights\" (such as the tale of \"Ali the Cairene and the Haunted House in Baghdad\").\n\nRenaissance magic took a revived interest in the occult, including necromancy. In the era of the Reformation and Counter Reformation, there was frequently a backlash against unwholesome interest in the dark arts, typified by writers such as Thomas Erastus. The Swiss Reformed pastor Ludwig Lavater supplied one of the most frequently reprinted books of the period with his \"Of Ghosts and Spirits Walking By Night.\"\n\nThe Child Ballad \"Sweet William's Ghost\" (1868) recounts the story of a ghost returning to his fiancée begging her to free him from his promise to marry her. He cannot marry her because he is dead but her refusal would mean his damnation. This reflects a popular British belief that the dead haunted their lovers if they took up with a new love without some formal release. \"The Unquiet Grave\" expresses a belief even more widespread, found in various locations over Europe: ghosts can stem from the excessive grief of the living, whose mourning interferes with the dead's peaceful rest. In many folktales from around the world, the hero arranges for the burial of a dead man. Soon after, he gains a companion who aids him and, in the end, the hero's companion reveals that he is in fact the dead man. Instances of this include the Italian fairy tale \"Fair Brow\" and the Swedish \"The Bird 'Grip'\".\n\nSpiritualism is a monotheistic belief system or religion, postulating a belief in God, but with a distinguishing feature of belief that spirits of the dead residing in the spirit world can be contacted by \"mediums\", who can then provide information about the afterlife.\n\nSpiritualism developed in the United States and reached its peak growth in membership from the 1840s to the 1920s, especially in English-language countries. By 1897, it was said to have more than eight million followers in the United States and Europe, mostly drawn from the middle and upper classes, while the corresponding movement in continental Europe and Latin America is known as Spiritism.\n\nThe religion flourished for a half century without canonical texts or formal organization, attaining cohesion by periodicals, tours by trance lecturers, camp meetings, and the missionary activities of accomplished mediums. Many prominent Spiritualists were women. Most followers supported causes such as the abolition of slavery and women's suffrage. By the late 1880s, credibility of the informal movement weakened, due to accusations of fraud among mediums, and formal Spiritualist organizations began to appear. Spiritualism is currently practiced primarily through various denominational Spiritualist Churches in the United States and United Kingdom.\n\nSpiritism, or French spiritualism, is based on the five books of the Spiritist Codification written by French educator Hypolite Léon Denizard Rivail under the pseudonym Allan Kardec reporting séances in which he observed a series of phenomena that he attributed to incorporeal intelligence (spirits). His assumption of spirit communication was validated by many contemporaries, among them many scientists and philosophers who attended séances and studied the phenomena. His work was later extended by writers like Leon Denis, Arthur Conan Doyle, Camille Flammarion, Ernesto Bozzano, Chico Xavier, Divaldo Pereira Franco, Waldo Vieira, Johannes Greber, and others.\n\nSpiritism has adherents in many countries throughout the world, including Spain, United States, Canada, Japan, Germany, France, England, Argentina, Portugal, and especially Brazil, which has the largest proportion and greatest number of followers.\n\nThe physician John Ferriar wrote \"An Essay Towards a Theory of Apparitions\" in 1813 in which he argued that sightings of ghosts were the result of optical illusions. Later the French physician Alexandre Jacques François Brière de Boismont published \"On Hallucinations: Or, the Rational History of Apparitions, Dreams, Ecstasy, Magnetism, and Somnambulism\" in 1845 in which he claimed sightings of ghosts were the result of hallucinations.\n\nDavid Turner, a retired physical chemist, suggested that ball lightning could cause inanimate objects to move erratically.\n\nJoe Nickell of the Committee for Skeptical Inquiry wrote that there was no credible scientific evidence that any location was inhabited by spirits of the dead. Limitations of human perception and ordinary physical explanations can account for ghost sightings; for example, air pressure changes in a home causing doors to slam, humidity changes causing boards to creak, condensation in electrical connections causing intermittent behavior, or lights from a passing car reflected through a window at night. Pareidolia, an innate tendency to recognize patterns in random perceptions, is what some skeptics believe causes people to believe that they have 'seen ghosts'. Reports of ghosts \"seen out of the corner of the eye\" may be accounted for by the sensitivity of human peripheral vision. According to Nickell, peripheral vision can easily mislead, especially late at night when the brain is tired and more likely to misinterpret sights and sounds. Nickell further states, \"science cannot substantiate the existence of a 'life energy' that could survive death without dissipating or function at all without a brain... why would... clothes survive?'\" He asks, if ghosts glide, then why do people claim to hear them with \"heavy footfalls\"? Nickell says that ghosts act the same way as \"dreams, memories, and imaginings, because they too are mental creations. They are evidence - not of another world, but of this real and natural one.\"\n\nBenjamin Radford from the Committee for Skeptical Inquiry and author of the 2017 book \"Investigating Ghosts: The Scientific Search for Spirits\" writes that \"ghost hunting is the world's most popular paranormal pursuit\" yet, to date ghost hunters can't agree on what a ghost is, or offer proof that they exist \"it's all speculation and guesswork\". He writes that it would be \"useful and important to distinguish between types of spirits and apparitions. Until then it's merely a parlor game distracting amateur ghost hunters from the task at hand.\"\n\nAccording to research in anomalistic psychology visions of ghosts may arise from hypnagogic hallucinations (\"waking dreams\" experienced in the transitional states to and from sleep). In a study of two experiments into alleged hauntings (Wiseman \"et al\". 2003) came to the conclusion \"that people consistently report unusual experiences in 'haunted' areas because of environmental factors, which may differ across locations.\" Some of these factors included \"the variance of local magnetic fields, size of location and lighting level stimuli of which witnesses may not be consciously aware\".\n\nSome researchers, such as Michael Persinger of Laurentian University, Canada, have speculated that changes in geomagnetic fields (created, e.g., by tectonic stresses in the Earth's crust or solar activity) could stimulate the brain's temporal lobes and produce many of the experiences associated with hauntings. Sound is thought to be another cause of supposed sightings. Richard Lord and Richard Wiseman have concluded that infrasound can cause humans to experience bizarre feelings in a room, such as anxiety, extreme sorrow, a feeling of being watched, or even the chills. Carbon monoxide poisoning, which can cause changes in perception of the visual and auditory systems, was speculated upon as a possible explanation for haunted houses as early as 1921.\n\nPeople who experience sleep paralysis often report seeing ghosts during their experiences. Neuroscientists Baland Jalal and V.S. Ramachandran have recently proposed neurological theories for why people hallucinate ghosts during sleep paralysis. Their theories emphasize the role of the parietal lobe and mirror neurons in triggering such ghostly hallucinations.\n\nThe Hebrew Torah and the Bible contain a few references to ghosts, associating spiritism with forbidden occult activities. The most notable reference is in the First Book of Samuel, in which a disguised King Saul has the Witch of Endor summon the spirit or ghost of Samuel. In the New Testament, Jesus has to persuade the Disciples that he is not a ghost following the resurrection, Luke 24:37–39 (some versions of the Bible, such as the KJV and NKJV, use the term \"spirit\"). Similarly, Jesus' followers at first believe he is a ghost (spirit) when they see him walking on water.\n\nSome Christian denominations consider ghosts as beings who while tied to earth, no longer live on the material plane and linger in an intermediate state before continuing their journey to heaven. On occasion, God would allow the souls in this state to return to earth to warn the living of the need for repentance. Christians are taught that it is sinful to attempt to conjure or control spirits in accordance with Deuteronomy XVIII: 9–12.\n\nSome ghosts are actually said to be demons in disguise, who the Church teaches, in accordance with I Timothy 4:1, that they \"come to deceive people and draw them away from God and into bondage.\" As a result, attempts to contact the dead may lead to unwanted contact with a demon or an unclean spirit, as was said to occur in the case of Robbie Mannheim, a fourteen-year-old Maryland youth. The Seventh-Day Adventist view is that a \"soul\" is not equivalent to \"spirit\" or \"ghost\" (depending on the Bible version), and that save for the Holy Spirit, all spirits or ghosts are demons in disguise. Furthermore, they teach that in accordance with (Genesis 2:7, Ecclesiastes 12:7), there are only two components to a \"soul\", neither of which survives death, with each returning to its respective source.\n\nChristadelphians and Jehovah's Witnesses reject the view of a living, conscious soul after death.\n\nThe Talmud tells of a being called a shade שד that is similar to other creatures in that it lives and dies but consists only of a form but lacks matter that forms mass, thus rendering it invisible. Since it has no physical mass it is capable of transporting itself from one end of the world to the other.\n\nWhile the Islamic view is that the spirits of the dead are unable to either return to or make any contact with the world of the living, reports of ghost sightings are believed to be the work of the \"jinn\", particularly the \"shayātīn\" (\"devils\") (both terms appearing in the Quran) who have powers to shape-shift and usually take the form and appearance of dead people (such as family members) to deceive and mislead. However one certain jinn-type, known as ifrit, is believed to be the result of a restless soul of someone who died a violent death.\n\nIn Buddhism, there are a number of planes of existence into which a person can be reborn, one of which is the realm of hungry ghosts.\n\nFor the Igbo people, a man is simultaneously a physical and spiritual entity. However, it is his spirited dimension that is eternal. In the Akan conception, we witness five parts of the human personality. We have the Nipadua (body), the Okra (soul), Sunsum (spirit), Ntoro (character from father), Mogya (character from mother). The Humr people of Sudan consume the drink Umm Nyolokh, which is created from the liver and marrow of giraffes. Umm Nyolokh often contains DMT and other psychoactive substances from plants the giraffes eat such as Acacia, and is known to cause hallucinations of giraffes, believed to be the giraffes ghosts by the Humr.\n\nBelief in ghosts in European folklore is characterized by the recurring fear of \"returning\" or \"revenant\" deceased who may harm the living. This includes the Scandinavian \"gjenganger\", the Romanian \"strigoi\", the Serbian \"vampir\", the Greek \"vrykolakas\", etc. In Scandinavian and Finnish tradition, ghosts appear in corporeal form, and their supernatural nature is given away by behavior rather than appearance. In fact, in many stories they are first mistaken for the living. They may be mute, appear and disappear suddenly, or leave no footprints or other traces.\n\nEnglish folklore is particularly notable for its numerous haunted locations.\n\nBelief in the soul and an afterlife remained near universal until the emergence of atheism in the 18th century. In the 19th century, spiritism resurrected \"belief in ghosts\" as the object of systematic inquiry, and popular opinion in Western culture remains divided.\n\nA \"bhoot\" or \"bhut\" (, , or ) is a supernatural creature, usually the ghost of a deceased person, in the popular culture, literature and some ancient texts of the Indian subcontinent. Interpretations of how \"bhoot\"s come into existence vary by region and community, but they are usually considered to be perturbed and restless due to some factor that prevents them from moving on (to transmigration, non-being, nirvana, or heaven or hell, depending on tradition). This could be a violent death, unsettled matters in their lives, or simply the failure of their survivors to perform proper funerals.\n\nIn Central and Northern India, \"Aojha\" spirit guides play a central role. It duly happens when in the night someone sleeps and decorates something on the wall, and they say that if one sees the spirit the next thing in the morning he will become a spirit too, and that to a \"skondho kata\", which means a spirit without a head and the soul of the body will remain the dark with the dark lord from the spirits who reside in the body of every human in Central and Northern India. It is also believed that if someone calls one from behind, never turn back and see because the spirit may catch the human to make it a spirit.\nOther types of spirits in Hindu Mythology include Baital, an evil spirit who haunts cemeteries and takes demonic possession of corpses, and Pishacha, a type of flesh-eating demon.\n\nThere are many kinds of ghosts and similar supernatural entities that frequently come up in Bengali culture, its folklores and form an important part in Bengali peoples' socio-cultural beliefs and superstitions. It is believed that the spirits of those who cannot find peace in the afterlife or die unnatural deaths remain on Earth. The common word for ghosts in Bengali is \"bhoot\" or \"bhut\" (). This word has an alternative meaning: 'past' in Bengali. Also the word \"Pret\" (Sanskrit) is used in Bengali to mean ghost. In Bengal, ghosts are believed to be the spirit after death of an unsatisfied human being or a soul of a person who dies in unnatural or abnormal circumstances (like murder, suicide or accident). Even it is believed that other animals and creatures can also be turned into ghost after their death.\n\nGhosts in Thailand are part of local folklore and have now become part of the popular culture of the country. Phraya Anuman Rajadhon was the first Thai scholar who seriously studied Thai folk beliefs and took notes on the nocturnal village spirits of Thailand. He established that, since such spirits were not represented in paintings or drawings, they were purely based on descriptions of popular orally transmitted traditional stories. Therefore, most of the contemporary iconography of ghosts such as Nang Tani, Nang Takian, Krasue, Krahang, Phi Hua Kat, Phi Pop, Phi Phong, Phi Phraya, and Mae Nak has its origins in Thai films that have now become classics.\nThe most feared spirit in Thailand is Phi Tai Hong, the ghost of a person who has died suddenly of a violent death. The folklore of Thailand also includes the belief that sleep paralysis is caused by a ghost, Phi Am.\n\nThere is widespread belief in ghosts in Tibetan culture. Ghosts are explicitly recognized in the Tibetan Buddhist religion as they were in Indian Buddhism, occupying a distinct but overlapping world to the human one, and feature in many traditional legends. When a human dies, after a period of uncertainty they may enter the ghost world. A hungry ghost (Tibetan: , ; ) has a tiny throat and huge stomach, and so can never be satisfied. Ghosts may be killed with a ritual dagger or caught in a spirit trap and burnt, thus releasing them to be reborn. Ghosts may also be exorcised, and an annual festival is held throughout Tibet for this purpose. Some say that Dorje Shugden, the ghost of a powerful 17th-century monk, is a deity, but the Dalai Lama asserts that he is an evil spirit, which has caused a split in the Tibetan exile community.\n\nThere are many Malay ghost myths, remnants of old animist beliefs that have been shaped by later Hindu, Buddhist, and Muslim influences in the modern states of Indonesia, Malaysia, and Brunei. Some ghost concepts such as the female vampires Pontianak and Penanggalan are shared throughout the region.\nGhosts are a popular theme in modern Malaysian and Indonesian films.\nThere are also many references to ghosts in Filipino culture, ranging from ancient legendary creatures such as the Manananggal and Tiyanak to more modern urban legends and horror films. The beliefs, legends and stories are as diverse as the people of the Philippines.\n\nThere was widespread belief in ghosts in Polynesian culture, some of which persists today.\nAfter death, a person's ghost normally traveled to the sky world or the underworld, but some could stay on earth. In many Polynesian legends, ghosts were often actively involved in the affairs of the living. Ghosts might also cause sickness or even invade the body of ordinary people, to be driven out through strong medicines.\n\nThere are many references to ghosts in Chinese culture. Even Confucius said, \"Respect ghosts and gods, but keep away from them.\"\n\nThe ghosts take many forms, depending on how the person died, and are often harmful. Many Chinese ghost beliefs have been accepted by neighboring cultures, notably Japan and southeast Asia. Ghost beliefs are closely associated with traditional Chinese religion based on ancestor worship, many of which were incorporated in Taoism. Later beliefs were influenced by Buddhism, and in turn influenced and created uniquely Chinese Buddhist beliefs.\n\nMany Chinese today believe it possible to contact the spirits of their ancestors through a medium, and that ancestors can help descendants if properly respected and rewarded. The annual ghost festival is celebrated by Chinese around the world. On this day, ghosts and spirits, including those of the deceased ancestors, come out from the lower realm. Ghosts are described in classical Chinese texts as well as modern literature and films.\n\nA recent article in the China Post stated that nearly eighty-seven percent of Chinese office workers believe in ghosts, and some fifty-two percent of workers will wear hand art, necklaces, crosses, or even place a crystal ball on their desks to keep ghosts at bay, according to the poll.\n\n are figures in Japanese folklore, analogous to Western legends of ghosts. The name consists of two kanji, 幽 (\"yū\"), meaning \"faint\" or \"dim\", and 霊 (\"rei\"), meaning \"soul\" or \"spirit\". Alternative names include 亡霊 (Bōrei) meaning ruined or departed spirit, 死霊 (Shiryō) meaning dead spirit, or the more encompassing 妖怪 (Yōkai) or お化け (Obake).\n\nLike their Chinese and Western counterparts, they are thought to be spirits kept from a peaceful afterlife.\n\nThere is extensive and varied belief in ghosts in Mexican culture. The modern state of Mexico before the Spanish conquest was inhabited by diverse peoples such as the Maya and Aztec, and their beliefs have survived and evolved, combined with the beliefs of the Spanish colonists. The Day of the Dead incorporates pre-Columbian beliefs with Christian elements. Mexican literature and films include many stories of ghosts interacting with the living.\n\nAccording to the Gallup Poll News Service, belief in haunted houses, ghosts, communication with the dead, and witches had an especially steep increase over the 1990s. A 2005 Gallup poll found that about 32 percent of Americans believe in ghosts.\n\nGhosts are prominent in story-telling of various nations. The ghost story is ubiquitous across all cultures from oral folktales to works of literature. While ghost stories are often explicitly meant to be scary, they have been written to serve all sorts of purposes, from comedy to morality tales. Ghosts often appear in the narrative as sentinels or prophets of things to come. Belief in ghosts is found in all cultures around the world, and thus ghost stories may be passed down orally or in written form.\n\nSpirits of the dead appear in literature as early as Homer's \"Odyssey\", which features a journey to the underworld and the hero encountering the ghosts of the dead, and the Old Testament, in which the Witch of Endor summons the spirit of the prophet Samuel.\n\nOne of the more recognizable ghosts in English literature is the shade of Hamlet's murdered father in Shakespeare's \"The Tragical History of Hamlet, Prince of Denmark\". In \"Hamlet\", it is the ghost who demands that Prince Hamlet investigate his \"murder most foul\" and seek revenge upon his usurping uncle, King Claudius.\n\nIn English Renaissance theater, ghosts were often depicted in the garb of the living and even in armor, as with the ghost of Hamlet's father. Armor, being out-of-date by the time of the Renaissance, gave the stage ghost a sense of antiquity. But the sheeted ghost began to gain ground on stage in the 19th century because an armored ghost could not satisfactorily convey the requisite spookiness: it clanked and creaked, and had to be moved about by complicated pulley systems or elevators. These clanking ghosts being hoisted about the stage became objects of ridicule as they became clichéd stage elements. Ann Jones and Peter Stallybrass, in \"Renaissance Clothing and the Materials of Memory\", point out, \"In fact, it is as laughter increasingly threatens the Ghost that he starts to be staged not in armor but in some form of 'spirit drapery'.\"\n\nThe \"classic\" ghost story arose during the Victorian period, and included authors such as M. R. James, Sheridan Le Fanu, Violet Hunt, and Henry James. Classic ghost stories were influenced by the gothic fiction tradition, and contain elements of folklore and psychology. M. R. James summed up the essential elements of a ghost story as, \"Malevolence and terror, the glare of evil faces, ‘the stony grin of unearthly malice', pursuing forms in darkness, and 'long-drawn, distant screams', are all in place, and so is a modicum of blood, shed with deliberation and carefully husbanded...\". One of the key early appearances by ghosts was \"The Castle of Otranto\" by Horace Walpole in 1764, considered to be the first gothic novel.\n\nFamous literary apparitions from this period are the ghosts of \"A Christmas Carol\", in which Ebenezer Scrooge is helped to see the error of his ways by the ghost of his former colleague Jacob Marley, and the ghosts of Christmas Past, Christmas Present, and Christmas Yet to Come.\n\nProfessional parapsychologists and \"ghosts hunters\", such as Harry Price, active in the 1920s and 1930s, and Peter Underwood, active in the 1940s and 1950s, published accounts of their experiences with ostensibly true ghost stories such as Price's \"The Most Haunted House in England\", and Underwood's \"Ghosts of Borley\" (both recounting experiences at Borley Rectory). The writer Frank Edwards delved into ghost stories in his books of his, like \"Stranger than Science.\"\n\nChildren's benevolent ghost stories became popular, such as Casper the Friendly Ghost, created in the 1930s and appearing in comics, animated cartoons, and eventually a 1995 feature film.\n\nWith the advent of motion pictures and television, screen depictions of ghosts became common, and spanned a variety of genres; the works of Shakespeare, Dickens and Wilde have all been made into cinematic versions. Novel-length tales have been difficult to adapt to cinema, although that of \"The Haunting of Hill House\" to \"The Haunting\" in 1963 is an exception.\n\nSentimental depictions during this period were more popular in cinema than horror, and include the 1947 film \"The Ghost and Mrs. Muir\", which was later adapted to television with a successful 1968–70 TV series. Genuine psychological horror films from this period include 1944's \"The Uninvited\", and 1945's \"Dead of Night\".\n\nThe 1970s saw screen depictions of ghosts diverge into distinct genres of the romantic and horror. A common theme in the romantic genre from this period is the ghost as a benign guide or messenger, often with unfinished business, such as 1989's \"Field of Dreams\", the 1990 film \"Ghost\", and the 1993 comedy \"Heart and Souls\". In the horror genre, 1980's \"The Fog\", and the \"A Nightmare on Elm Street\" series of films from the 1980s and 1990s are notable examples of the trend for the merging of ghost stories with scenes of physical violence.\n\nPopularised in such films as the 1984 comedy \"Ghostbusters\", ghost hunting became a hobby for many who formed ghost hunting societies to explore reportedly haunted places. The ghost hunting theme has been featured in reality television series, such as \"Ghost Adventures\", \"Ghost Hunters\", \"Ghost Hunters International\", \"Ghost Lab\", \"Most Haunted\", and \"A Haunting\". It is also represented in children's television by such programs as \"The Ghost Hunter\" and \"Ghost Trackers\". Ghost hunting also gave rise to multiple guidebooks to haunted locations, and ghost hunting \"how-to\" manuals.\n\nThe 1990s saw a return to classic \"gothic\" ghosts, whose dangers were more psychological than physical. Examples of films from this period include 1999's \"The Sixth Sense\" and \"The Others\".\n\nAsian cinema has also produced horror films about ghosts, such as the 1998 Japanese film \"Ringu\" (remade in the US as \"The Ring\" in 2002), and the Pang brothers' 2002 film \"The Eye\".\nIndian ghost movies are popular not just in India, but in the Middle East, Africa, South East Asia, and other parts of the world. Some Indian ghost movies such as the comedy / horror film \"Chandramukhi\" have been commercial successes, dubbed into several languages.\n\nIn fictional television programming, ghosts have been explored in series such as \"Supernatural\", \"Ghost Whisperer\", and \"Medium\".\n\nIn animated fictional television programming, ghosts have served as the central element in series such as \"Casper the Friendly Ghost\", \"Danny Phantom\", and \"Scooby-Doo\". Various other television shows have depicted ghosts as well. \n\nNietzsche argued that people generally wear prudent masks in company; but that an alternative strategy for social interaction is to present oneself as an absence, as a social ghost – \"One reaches out for us but gets no hold of us\" – a sentiment later echoed (if in a less positive way) by Carl Jung.\n\nNick Harkaway has considered that all people carry a host of ghosts in their heads in the form of impressions of past acquaintances – ghosts who represent mental maps of other people in the world and serve as philosophical reference points.\n\nObject relations theory sees human personalities as formed by splitting off aspects of the person that he or she deems incompatible; whereupon the person may be haunted in later life by such ghosts of his or her alternate selves.\n\n\n"}
{"id": "2408337", "url": "https://en.wikipedia.org/wiki?curid=2408337", "title": "Hastings Ndlovu", "text": "Hastings Ndlovu\n\nHastings Ndlovu (1961 – 16 June 1976) was a schoolboy who was killed in the Soweto uprising against the apartheid system in South Africa.\n\nOn 16 June 1976, when the police from the Orlando Police Station led by Colonel Kleingeld opened fire on Soweto students protesting against the imposition of Afrikaans instruction in school, he took the first bullet. Hastings Ndlovu's death did not become as iconic as Hector Pieterson's because no photographer was present to record it. Colonel Kleingeld said at the Cillie Commission that Hastings 'was inciting the crowd'.\n\nThere is some doubt as to who was the first fatality, as Hector Pieterson was pronounced dead upon arrival at the clinic, whereas Hastings Ndlovu died from bullet wounds to the head shortly after being brought to the clinic. It is still not clear who died first, Hector Pieterson or Hastings Ndlovu, but it is likely that Pieterson was the first death on that day.\n\nHastings Ndlovu was survived by his parents, three sisters and brother. His sisters left the country soon after June 16, but returned to Johannesburg a few years later.\n\nHastings Ndlovu was buried with Hector Pieterson at Avalon Cemetery in Johannesburg. His house at 7235 Thabete Street, Soweto, Johannesburg had a blue plaque attached to it on 16 June 2012 to commemorate his sacrifice.\n"}
{"id": "36070641", "url": "https://en.wikipedia.org/wiki?curid=36070641", "title": "Heinrich Balasch", "text": "Heinrich Balasch\n\nHeinrich Balasch was an Austrian cinematographer. \n\n\n"}
{"id": "7347710", "url": "https://en.wikipedia.org/wiki?curid=7347710", "title": "Hupia", "text": "Hupia\n\nIn Taíno culture, the hupia (also \"opia\", \"opi'a\", \"op'a\", \"operi'to\") is the spirit of a person who has died. \n\nIn Taíno spiritual beliefs, hupias (ghost spirits of those who had died) were contrasted with goeiza, spirits of the living. While a living \"goieza\" had definite form, after passing away the spirit was released as a \"hupia\" and went to live in a remote earthly paradise called Coaybay. Hupias were believed to be able to assume many forms, sometimes appearing as faceless people or taking the form of a deceased loved one. Hupias in human form could always be distinguished by their lack of a navel. Hupias were also associated with bats and said to hide or sleep during the day and come out at night to eat guava fruit. \n\nHupias, as ghost spirits of those who died and the night, were feared and said to seduce women and kidnap people who ventured outside after dark.\n\nOn the matter of what the Tainos believed as to the Hupia (Ghost Spirit). The Taino people never believed in the concept and or idea of Death, as they believed in passing on of the human spirit and an Hereafter life. The Spanish historians and writers of the time however gave their own bias religious interpretation based upon their own Catholic and Christian ideas and or concepts of Death and as to the soul of the humans going to some place they call Heaven and the soul awaiting a day of judgement by their God.\n\nIn the novel \"Jurassic Park\" by Michael Crichton, hupia are suspected of an attack on an 18-year-old boy working construction of the dinosaur theme park on Isla Nublar. This culprit is later described as a velociraptor. Hupia are also accused of a rash of attacks on infants and other people in rural Costa Rica. They were described as \"faceless night ghosts who kidnapped small children\". Later events showed that the real culprits were Procompsognathuses that had escaped from Isla Nublar.\n\n"}
{"id": "2174928", "url": "https://en.wikipedia.org/wiki?curid=2174928", "title": "Information space analysis", "text": "Information space analysis\n\nInformation space analysis is a deterministic method, enhanced by machine intelligence, for locating and assessing resources for team-centric efforts.\n\nOrganizations need to be able to quickly assemble teams backed by the support services, information, and material to do the job. To do so, these teams need to find and assess sources of services that are potential participants in the team effort. To support this initial team and resource development, information needs to be developed via analysis tools that help make sense of sets of data sources in an Intranet or Internet. Part of the process is to characterize them, partition them, and sort and filter them.\n\nThese tools focus on three key issues in forming a collaborative team: \n\nInformation space analysis tools combine multiple methods to assist in this task. This causes the tools to be particularly well-suited to integrating additional technologies in order to create specialized systems.\n\n"}
{"id": "18040729", "url": "https://en.wikipedia.org/wiki?curid=18040729", "title": "Iodine deficiency in China", "text": "Iodine deficiency in China\n\nIodine deficiency is a widespread problem in western, southern and eastern parts of China, as their iodized salt intake level is much lower than the average national level. Iodine deficiency is a range of disorders that affect many different populations. It is estimated that IDDs affect between 800 million and 2 billion people worldwide; countries have spent millions of dollars in implementing iodized salt as a means to counteract the iodine deficiencies prevalent today. With China accounting for \"40% of the total population\", it bears a large portion of those who are iodine deficient.\n\nIodine is a micronutrient the body needs to properly produce thyroid hormones. The human body is not able to produce it, and iodine is an essential nutrient. Iodine is not readily available in many foods, thus making it difficult for many people to obtain it. One particular source, found in great supply, is ocean water although it is not an effective dietary source. Iodine deficiency diseases (IDDs) are able to develop before birth, so it is crucial for all populations to have sufficient levels of the micronutrient and prevent such diseases from developing early on.\n\nThe Chinese government implemented a program of regulating salt to contain iodine starting in 1995. A more recent study has confirmed that the availability of iodized salt in the provinces has increased since this date. Today, about one third of the Chinese population is living in areas with low concentrations of iodine in their water supply. Salt is available in China for less than the retail price in some other countries, at about 5 cents, and is consumed regularly in most diets. This is very cost effective for producers who now must abide by the iodized salt regulations and those for those who need to consume it. The black market, however, is laden with the non-iodized counterpart and partially accounts for the population still be fairly saturated with IDDs.\n\nThe levels of iodized salt were measured in a urinalysis of households in China. It was confirmed that about 15–25   mg/kg of iodized salt content in the diet was sufficient in preventing IDDs and preventing side effects of over consumption. In provinces where people are consuming less than this amount, there is an increased amount of improper brain development in children. Furthermore, one can see the relation between the importance of iodine in thyroid hormones and the IDD goitre. This disease causes a swelling in the neck, where the thyroid glands are, leading to impaired cognitive abilities. The child population was about 20% saturated with the disease but continues to decrease with the new initiatives.\n\nAnother common IDD prevalent in China is Kashin-Beck disease. A particular outbreak in Tibet was recorded as occurring from lack of iodine. Kashin-Beck is a bone deformity endemic. Iodine deficiency, hypothyroidism, and low serum concentrations of thyroxine-binding globulin were significantly related to Kashin–Beck disease. Iodine supplemented irrigation water in combination to iodized salt helps in reducing the neonatal and infant mortality rates. The province of Xinjiang suffers severely from IDDs and in 1993, started the use of potassium iodate in combination with irrigation water. Irrigation water is widely used and accessible to all households making it the predominant solution in reducing micronutrient deficiencies for Xinjiang.\n\n\n"}
{"id": "7583202", "url": "https://en.wikipedia.org/wiki?curid=7583202", "title": "Lernmatrix", "text": "Lernmatrix\n\nLernmatrix, an associative-memory-like architecture of an artificial neural network, invented around 1960 by Karl Steinbuch.\n\n"}
{"id": "2068329", "url": "https://en.wikipedia.org/wiki?curid=2068329", "title": "List of fictional plants", "text": "List of fictional plants\n\nThis list of fictional plants describes invented plants that appear in works of fiction.\n\n\n\n\n\n\nThe following plants appear in the David Attenborough sketch of the last Monty Python episode.\n\nPlants in Pandora have evolved according to the characteristics of their environment, which has an atmosphere that is thicker than on Earth, with higher concentrations of carbon dioxide, xenon and hydrogen sulfide. Gravity is weaker in Pandora, thereby giving rise to gigantism. There is a strong magnetic field, causing plants to develop 'magnetotropism'. A particularly intriguing quality of flora and fauna in Pandora is their ability to communicate with each other. This is explained in the movie as a phenomenon called 'signal transduction', pertaining to how plants perceive a signal and respond to it.\n\nThe Black Mercy is an extraterrestrial hallucinogenic plant used a weapon by the supervillain Mongul. Mongul first uses it in \"For the Man Who Has Everything\", a story by Alan Moore and Dave Gibbons that was first published in \"Superman Annual\" #11 (1985) and later adapted into the \"Justice League Unlimited\" episode of the same name and for one episode of \"Supergirl\" called \"For the Girl Who Has Everything\", where in that episode the plant was sent by Kryptonian Non (comics). Described in the original story by Mongul as \"something between a plant and an intelligent fungus\", the Black Mercy attaches itself to its victims in a form of symbiosis, and feeds from the victim's \"bio-aura\". The organism is telepathic, and reads its victim's heart's desire, giving them a logical simulation and an ending that the victim wants, which the victim experiences an entirely immersive, virtual experience in which their actual surroundings are masked to them. According to Mongul, victims are capable of \"shrugging off\" the hallucination, though some find the experience too compelling too do so unaided.\n\nThe Black Mercy is typically depicted as consisting of dark green, thorned vines that attach themselves to a humanoid victim's upper torso, with a set of pink flowers, each with a long, red, tentacle-like stigma, growing in the center of the victim's chest. When Mongul first uses the Black Mercy on Superman, they burrow through his costume and into his body, able to penetrate his otherwise invulnerable skin because, Wonder Woman senses, they are at least partially magical, which is one of Superman's weaknesses. During his experience with the organism, Superman's breathing appears faint, and his ability to sense the fraudulent nature of the simulation it feeds him and fight it manifests itself as tears produced by his actual eyes. The Black Mercy can pulled off a victim by a strong humanoid such as Batman, and Mongul uses special protective gauntlets to handle the plant safely. Superman is not able to awaken from the Black Mercy's simulation without help from Batman, though Oliver Queen and Hal Jordan are both able to do so in a subsequent storyline.\n\nIn the video game, \"Injustice 2\" Supergirl mentions Black Mercy in pre-battle dialogue with Scarecrow. She states dealing with him is no different than dealing with Black Mercy, causing Scarecrow to ask her what is Black Mercy out of curiosity, causing Supergirl to describe it as an evil space plant.\n\nCharacters who have experienced the Black Mercy include:\n\n\n\n"}
{"id": "58284763", "url": "https://en.wikipedia.org/wiki?curid=58284763", "title": "List of mass shootings in the United States", "text": "List of mass shootings in the United States\n\nThis is a list of known mass shootings in the United States that have occurred since 1966. Mass shootings are incidents involving multiple victims of firearm-related violence. The precise inclusion criteria are disputed, and there is no broadly accepted definition.\n\nThe Gun Violence Archive, a nonprofit research group that tracks shootings and their characteristics in the United States, defines a mass shooting as an incident in which four or more people, excluding the perpetrator(s), are shot in one location at roughly the same time. The Congressional Research Service narrows that definition further, only considering what it defines as \"public mass shootings\", and only considering victims as those who are killed, excluding any victims who survive. \"The Washington Post\" and \"Mother Jones\" use similar definitions, with the latter acknowledging that their definition \"is a conservative measure of the problem\", as many rampages with fewer fatalities occur. The crowdsourced Mass Shooting Tracker project uses a definition even looser than the Gun Violence Archive's definition: four people shot in one incident regardless of the circumstances. \n\nLarger documentation of mass shootings in the United States has occurred through independent and scholarly studies such as the Stanford University Mass Shootings of American Data Project.\n\nThere are many definitions for what a mass shooting is:\n\nOnly incidents considered mass shootings by at least two of the above definitions are listed, and only shootings that have Wikipedia articles of their own are included in this list. Detailed lists of shootings can be found per-year at their respective pages.\n\n\n"}
{"id": "32181590", "url": "https://en.wikipedia.org/wiki?curid=32181590", "title": "Maurice Généreux", "text": "Maurice Généreux\n\nMaurice Généreux is a Canadian physician who was convicted in 1998 of prescribing medications to two HIV-positive men in Toronto, Ontario, Canada, in 1996—medications that allowed the men, Mark Jewitt and Aaron Mcginn, to commit suicide in 1996. Généreux was the first doctor in North America to be convicted of assisting a suicide (followed in 1999 by Jack Kevorkian).\n\nMark Jewitt took a lethal dose but managed to survive after a friend found him and called the emergency services. Aaron McGinn died in 1996 from an overdose of sleeping pills provided by Généreux. Généreux forged McGinn's death certificate, moreover, to make it look as if McGinn had died from AIDS rather than from sleeping pills. The investigation into Généreux started when a friend raised doubts about McGinn's death to the chief coroner in Toronto. Following an investigation, Généreux was arrested on 20 June 1996.\n\nGénéreux was sent to prison for two years minus a day and lost his medical license.\n\nAccording to Ian Dowbiggin, the author of \"A Concise History of Euthanasia\", Généreux's actions revealed an \"underground\" network of euthanasia provision for AIDS sufferers in Toronto's gay community; however, Dowbiggin's assertions have not been proven. Aaron McGinn was HIV positive but he was not palliative and could have lived a long and healthy life with the medications available. Genereux's actions revealed a failure of the judicial system and The College of Physicians and Surgeons of Ontario (the self-regulating governing body for the province's medical profession). Généreux had previous convictions for sexually assaulting his patients but was allowed to continue practising medicine.\n"}
{"id": "36410575", "url": "https://en.wikipedia.org/wiki?curid=36410575", "title": "Mental Deficiency Act 1913", "text": "Mental Deficiency Act 1913\n\nThe Mental Deficiency Act 1913 was an act of the United Kingdom which made provisions for the institutional treatment of people deemed to be \"feeble-minded\" and \"moral defectives\". \"It proposed an institutional separation so that mental defectives should be taken out of Poor Law institutions and prisons into newly established colonies.\"\n\nThe Idiots Act 1886 made the legal distinction between \"idiots\" and \"imbeciles\". It contained educational provisions for the needs of people deemed to be in these categories. In 1904 the Royal Commission on the Care and Control of the Feeble-Minded was set up with the warrant \"to consider the existing methods of dealing with idiots and epileptics, and with imbecile, feeble-minded, or defective persons not certified under the Lunacy Laws... to report as to the amendments in the law or other measures which should be adopted in the matter\". The Commission returned a lengthy report in 1908 which estimated that of a population of 32,527,843 British inhabitants 149,628 people (0.46%) were considered \"mentally defective\". It recommended the establishment of a board of control which would oversee local authority efforts aimed at \"the well-being of the mentally defective\".\n\nWinston Churchill spoke of the need to introduce compulsory labour camps for \"mental defectives\" in the House of Commons in February 1911. In May 1912 a Private Members' Bill entitled the \"Feeble-Minded Control Bill\" was introduced in the House of Commons, which called for the implementation of the Royal Commission's conclusions. It rejected sterilisation of the \"feeble-minded\", but had provision for registration and segregation. One of the few voices raised against the bill was that of G.K. Chesterton who ridiculed the bill, calling it the \"Feeble-Minded Bill, both for brevity and because the description is strictly accurate\". The bill was withdrawn, but a government bill introduced on 10 June 1912 replaced it, which would become the Mental Deficiency Act 1913.\n\nThe bill was passed in 1913 with only three MPs voting against it. One of them was Josiah Wedgwood, who said of it, \"It is a spirit of the Horrible Eugenic Society which is setting out to breed up the working class as though they were cattle.\" The new act repealed the Idiots Act 1886 and followed the recommendations of the Royal Commission on the Care and Control of the Feeble-Minded. It established the Board of Control for Lunacy and Mental Deficiency to oversee the implementation of provisions for the care and management of four classes of people,\n\nA person deemed to be an idiot or imbecile might be placed in an institution or under guardianship if the parent or guardian so petitioned, as could a person of any of the four categories under 21 years, as could a person of any category who had been abandoned, neglected, guilty of a crime, in a state institution, habitually drunk, or unable to be schooled.\n\nAt the height of operation of the Mental Deficiency Act, 65,000 people were placed in \"colonies\" or in other institutional settings. The act remained in effect until it was repealed by the Mental Health Act 1959.\n\n"}
{"id": "30782549", "url": "https://en.wikipedia.org/wiki?curid=30782549", "title": "Mikael Aaltonen", "text": "Mikael Aaltonen\n\nMikael Aaltonen (born 12 January 1991) is a Finnish ice hockey player who currently plays professionally in Finland for TPS of the SM-liiga.\n"}
{"id": "52647092", "url": "https://en.wikipedia.org/wiki?curid=52647092", "title": "Muhammad Abu Ali", "text": "Muhammad Abu Ali\n\nLieutenant Colonel Muhammad Abu Ali (August 15, 1980 – November 4, 2016) was Nigerian Army officer who Commanded the Army's 272 Tank Battalion. He was killed in an ambush by Boko Haram in Fatori, Borno State. \n\nAli graduated from Command Secondary School, Jos in 1997 and was admitted to the Nigerian Defence Academy in 1998 as a member of the 50th Regular Course. He was commissioned as a 2nd Lieutenant into the Nigerian Army Armour Corps in September 2003. His father is Brig-Gen Abu Ali, now the Etsu of Bassa-Nge Kingdom in Kogi State).\n\nHe participated in the United Nations Mission in Liberia (UNMIL), United Missions in Darfur (UNMO), and received an accelerrated promotion from the rank of Major to Lieutenant Colonel, receiving a gallantry award by the Chief of Army Staff, Lieutenant General Tukur Yusuf Buratai in September 2015. \n\nAli received the Chief of Army Staff award in Gamboru for exceptional bravery from Lt Gen Tukur Yusuf Buratai on September 9, 2015 for his role in the fight against Boko Haram. \n\nLt Col Abu Ali along with 6 other soldiers were ambushed and killed by Boko Haram on November 4, 2016. He was buried on November 7, 2016 at the National Military Cemetery, Abuja. \n"}
{"id": "6147487", "url": "https://en.wikipedia.org/wiki?curid=6147487", "title": "Neural coding", "text": "Neural coding\n\nNeural coding is a neuroscience field concerned with characterising the hypothetical relationship between the stimulus and the individual or ensemble neuronal responses and the relationship among the electrical activity of the neurons in the ensemble. Based on the theory that\nsensory and other information is represented in the brain by networks of neurons, it is thought that neurons can encode both digital and analog information.\n\nNeurons are remarkable among the cells of the body in their ability to propagate signals rapidly over large distances. They do this by generating characteristic electrical pulses called action potentials: voltage spikes that can travel down nerve fibers. Sensory neurons change their activities by firing sequences of action potentials in various temporal patterns, with the presence of external sensory stimuli, such as light, sound, taste, smell and touch. It is known that information about the stimulus is encoded in this pattern of action potentials and transmitted into and around the brain.\n\nAlthough action potentials can vary somewhat in duration, amplitude and shape, they are typically treated as identical stereotyped events in neural coding studies. If the brief duration of an action potential (about 1ms) is ignored, an action potential sequence, or spike train, can be characterized simply by a series of all-or-none point events in time. The lengths of interspike intervals (ISIs) between two successive spikes in a spike train often vary, apparently randomly. The study of neural coding involves measuring and characterizing how stimulus attributes, such as light or sound intensity, or motor actions, such as the direction of an arm movement, are represented by neuron action potentials or spikes. In order to describe and analyze neuronal firing, statistical methods and methods of probability theory and stochastic point processes have been widely applied.\n\nWith the development of large-scale neural recording and decoding technologies, researchers have begun to crack the neural code and have already provided the first glimpse into the real-time neural code as memory is formed and recalled in the hippocampus, a brain region known to be central for memory formation. Neuroscientists have initiated several large-scale brain decoding projects.\n\nThe link between stimulus and response can be studied from two opposite points of view. Neural encoding refers to the map from stimulus to response. The main focus is to understand how neurons respond to a wide variety of stimuli, and to construct models that attempt to predict responses to other stimuli. Neural decoding refers to the reverse map, from response to stimulus, and the challenge is to reconstruct a stimulus, or certain aspects of that stimulus, from the spike sequences it evokes.\n\nA sequence, or 'train', of spikes may contain information based on different coding schemes. In motor neurons, for example, the strength at which an innervated muscle is contracted depends solely on the 'firing rate', the average number of spikes per unit time (a 'rate code'). At the other end, a complex 'temporal code' is based on the precise timing of single spikes. They may be locked to an external stimulus such as in the visual and auditory system or be generated intrinsically by the neural circuitry.\n\nWhether neurons use rate coding or temporal coding is a topic of intense debate within the neuroscience community, even though there is no clear definition of what these terms mean. In one theory, termed \"neuroelectrodynamics\", the following coding schemes are all considered to be epiphenomena, replaced instead by molecular changes reflecting the spatial distribution of electric fields within neurons as a result of the broad electromagnetic spectrum of action potentials, and manifested in information as spike directivity.\n\nThe rate coding model of neuronal firing communication states that as the intensity of a stimulus increases, the frequency or rate of action potentials, or \"spike firing\", increases. Rate coding is sometimes called frequency coding.\n\nRate coding is a traditional coding scheme, assuming that most, if not all, information about the stimulus is contained in the firing rate of the neuron. Because the sequence of action potentials generated by a given stimulus varies from trial to trial, neuronal responses are typically treated statistically or probabilistically. They may be characterized by firing rates, rather than as specific spike sequences. In most sensory systems, the firing rate increases, generally non-linearly, with increasing stimulus intensity. Any information possibly encoded in the temporal structure of the spike train is ignored. Consequently, rate coding is inefficient but highly robust with respect to the ISI 'noise'.\n\nDuring rate coding, precisely calculating firing rate is very important. In fact, the term \"firing rate\" has a few different definitions, which refer to different averaging procedures, such as an average over time or an average over several repetitions of experiment.\n\nIn rate coding, learning is based on activity-dependent synaptic weight modifications.\n\nRate coding was originally shown by ED Adrian and Y Zotterman in 1926. In this simple experiment different weights were hung from a muscle. As the weight of the stimulus increased, the number of spikes recorded from sensory nerves innervating the muscle also increased. From these original experiments, Adrian and Zotterman concluded that action potentials were unitary events, and that the frequency of events, and not individual event magnitude, was the basis for most inter-neuronal communication.\n\nIn the following decades, measurement of firing rates became a standard tool for describing the properties of all types of sensory or cortical neurons, partly due to the relative ease of measuring rates experimentally. However, this approach neglects all the information possibly contained in the exact timing of the spikes. During recent years, more and more experimental evidence has suggested that a straightforward firing rate concept based on temporal averaging may be too simplistic to describe brain activity.\n\nThe spike-count rate, also referred to as temporal average, is obtained by counting the number of spikes that appear during a trial and dividing by the duration of trial. The length T of the time window is set by the experimenter and depends on the type of neuron recorded from and to the stimulus. In practice, to get sensible averages, several spikes should occur within the time window. Typical values are T = 100 ms or T = 500 ms, but the duration may also be longer or shorter.\n\nThe spike-count rate can be determined from a single trial, but at the expense of losing all temporal resolution about variations in neural response during the course of the trial. Temporal averaging can work well in cases where the stimulus is constant or slowly varying and does not require a fast reaction of the organism — and this is the situation usually encountered in experimental protocols. Real-world input, however, is hardly stationary, but often changing on a fast time scale. For example, even when viewing a static image, humans perform saccades, rapid changes of the direction of gaze. The image projected onto the retinal photoreceptors changes therefore every few hundred milliseconds.\n\nDespite its shortcomings, the concept of a spike-count rate code is widely used not only in experiments, but also in models of neural networks. It has led to the idea that a neuron transforms information about a single input variable (the stimulus strength) into a single continuous output variable (the firing rate).\n\nThere is a growing body of evidence that in Purkinje neurons, at least, information is not simply encoded in firing but also in the timing and duration of non-firing, quiescent periods.\n\nThe time-dependent firing rate is defined as the average number of spikes (averaged over trials) appearing during a short interval between times t and t+Δt, divided by the duration of the interval. It works for stationary as well as for time-dependent stimuli. To experimentally measure the time-dependent firing rate, the experimenter records from a neuron while stimulating with some input sequence. The same stimulation sequence is repeated several times and the neuronal response is reported in a Peri-Stimulus-Time Histogram (PSTH). The time t is measured with respect to the start of the stimulation sequence. The Δt must be large enough (typically in the range of one or a few milliseconds) so there are sufficient number of spikes within the interval to obtain a reliable estimate of the average. The number of occurrences of spikes n(t;t+Δt) summed over all repetitions of the experiment divided by the number K of repetitions is a measure of the typical activity of the neuron between time t and t+Δt. A further division by the interval length Δt yields time-dependent firing rate r(t) of the neuron, which is equivalent to the spike density of PSTH.\n\nFor sufficiently small Δt, r(t)Δt is the average number of spikes occurring between times t and t+Δt over multiple trials. If Δt is small, there will never be more than one spike within the interval between t and t+Δt on any given trial. This means that r(t)Δt is also the fraction of trials on which a spike occurred between those times. Equivalently, r(t)Δt is the probability that a spike occurs during this time interval.\n\nAs an experimental procedure, the time-dependent firing rate measure is a useful method to evaluate neuronal activity, in particular in the case of time-dependent stimuli. The obvious problem with this approach is that it can not be the coding scheme used by neurons in the brain. Neurons can not wait for the stimuli to repeatedly present in an exactly same manner before generating response.\n\nNevertheless, the experimental time-dependent firing rate measure can make sense, if there are large populations of independent neurons that receive the same stimulus. Instead of recording from a population of N neurons in a single run, it is experimentally easier to record from a single neuron and average over N repeated runs. Thus, the time-dependent firing rate coding relies on the implicit assumption that there are always populations of neurons.\n\nWhen precise spike timing or high-frequency firing-rate fluctuations are found to carry information, the neural code is often identified as a temporal code. A number of studies have found that the temporal resolution of the neural code is on a millisecond time scale, indicating that precise spike timing is a significant element in neural coding. Such codes, that communicate via the time between spikes are referred to as interpulse interval codes, and have been supported by recent studies.\n\nNeurons exhibit high-frequency fluctuations of firing-rates which could be noise or could carry information. Rate coding models suggest that these irregularities are noise, while temporal coding models suggest that they encode information. If the nervous system only used rate codes to convey information, a more consistent, regular firing rate would have been evolutionarily advantageous, and neurons would have utilized this code over other less robust options. Temporal coding supplies an alternate explanation for the “noise,\" suggesting that it actually encodes information and affects neural processing. To model this idea, binary symbols can be used to mark the spikes: 1 for a spike, 0 for no spike. Temporal coding allows the sequence 000111000111 to mean something different from 001100110011, even though the mean firing rate is the same for both sequences, at 6 spikes/10 ms. Until recently, scientists had put the most emphasis on rate encoding as an explanation for post-synaptic potential patterns. However, functions of the brain are more temporally precise than the use of only rate encoding seems to allow. In other words, essential information could be lost due to the inability of the rate code to capture all the available information of the spike train. In addition, responses are different enough between similar (but not identical) stimuli to suggest that the distinct patterns of spikes contain a higher volume of information than is possible to include in a rate code.\n\nTemporal codes employ those features of the spiking activity that cannot be described by the firing rate. For example, time to first spike after the stimulus onset, characteristics based on the second and higher statistical moments of the ISI probability distribution, spike randomness, or precisely timed groups of spikes (temporal patterns) are candidates for temporal codes. As there is no absolute time reference in the nervous system, the information is carried either in terms of the relative timing of spikes in a population of neurons or with respect to an ongoing brain oscillation. One way in which temporal codes are decoded, in presence of neural oscillations, is that spikes occurring at specific phases of an oscillatory cycle are more effective in depolarizing the post-synaptic neuron.\n\nThe temporal structure of a spike train or firing rate evoked by a stimulus is determined both by the dynamics of the stimulus and by the nature of the neural encoding process. Stimuli that change rapidly tend to generate precisely timed spikes and rapidly changing firing rates no matter what neural coding strategy is being used. Temporal coding refers to temporal precision in the response that does not arise solely from the dynamics of the stimulus, but that nevertheless relates to properties of the stimulus. The interplay between stimulus and encoding dynamics makes the identification of a temporal code difficult.\n\nIn temporal coding, learning can be explained by activity-dependent synaptic delay modifications. The modifications can themselves depend not only on spike rates (rate coding) but also on spike timing patterns (temporal coding), i.e., can be a special case of spike-timing-dependent plasticity.\n\nThe issue of temporal coding is distinct and independent from the issue of independent-spike coding. If each spike is independent of all the other spikes in the train, the temporal character of the neural code is determined by the behavior of time-dependent firing rate r(t). If r(t) varies slowly with time, the code is typically called a rate code, and if it varies rapidly, the code is called temporal.\n\nFor very brief stimuli, a neuron's maximum firing rate may not be fast enough to produce more than a single spike. Due to the density of information about the abbreviated stimulus contained in this single spike, it would seem that the timing of the spike itself would have to convey more information than simply the average frequency of action potentials over a given period of time. This model is especially important for sound localization, which occurs within the brain on the order of milliseconds. The brain must obtain a large quantity of information based on a relatively short neural response. Additionally, if low firing rates on the order of ten spikes per second must be distinguished from arbitrarily close rate coding for different stimuli, then a neuron trying to discriminate these two stimuli may need to wait for a second or more to accumulate enough information. This is not consistent with numerous organisms which are able to discriminate between stimuli in the time frame of milliseconds, suggesting that a rate code is not the only model at work.\n\nTo account for the fast encoding of visual stimuli, it has been suggested that neurons of the retina encode visual information in the latency time between stimulus onset and first action potential, also called latency to first spike. This type of temporal coding has been shown also in the auditory and somato-sensory system. The main drawback of such a coding scheme is its sensitivity to intrinsic neuronal fluctuations. In the primary visual cortex of macaques, the timing of the first spike relative to the start of the stimulus was found to provide more information than the interval between spikes. However, the interspike interval could be used to encode additional information, which is especially important when the spike rate reaches its limit, as in high-contrast situations. For this reason, temporal coding may play a part in coding defined edges rather than gradual transitions.\n\nThe mammalian gustatory system is useful for studying temporal coding because of its fairly distinct stimuli and the easily discernible responses of the organism. Temporally encoded information may help an organism discriminate between different tastants of the same category (sweet, bitter, sour, salty, umami) that elicit very similar responses in terms of spike count. The temporal component of the pattern elicited by each tastant may be used to determine its identity (e.g., the difference between two bitter tastants, such as quinine and denatonium). In this way, both rate coding and temporal coding may be used in the gustatory system – rate for basic tastant type, temporal for more specific differentiation. Research on mammalian gustatory system has shown that there is an abundance of information present in temporal patterns across populations of neurons, and this information is different from that which is determined by rate coding schemes. Groups of neurons may synchronize in response to a stimulus. In studies dealing with the front cortical portion of the brain in primates, precise patterns with short time scales only a few milliseconds in length were found across small populations of neurons which correlated with certain information processing behaviors. However, little information could be determined from the patterns; one possible theory is they represented the higher-order processing taking place in the brain.\n\nAs with the visual system, in mitral/tufted cells in the olfactory bulb of mice, first-spike latency relative to the start of a sniffing action seemed to encode much of the information about an odor. This strategy of using spike latency allows for rapid identification of and reaction to an odorant. In addition, some mitral/tufted cells have specific firing patterns for given odorants. This type of extra information could help in recognizing a certain odor, but is not completely necessary, as average spike count over the course of the animal's sniffing was also a good identifier. Along the same lines, experiments done with the olfactory system of rabbits showed distinct patterns which correlated with different subsets of odorants, and a similar result was obtained in experiments with the locust olfactory system.\n\nThe specificity of temporal coding requires highly refined technology to measure informative, reliable, experimental data. Advances made in optogenetics allow neurologists to control spikes in individual neurons, offering electrical and spatial single-cell resolution. For example, blue light causes the light-gated ion channel channelrhodopsin to open, depolarizing the cell and producing a spike. When blue light is not sensed by the cell, the channel closes, and the neuron ceases to spike. The pattern of the spikes matches the pattern of the blue light stimuli. By inserting channelrhodopsin gene sequences into mouse DNA, researchers can control spikes and therefore certain behaviors of the mouse (e.g., making the mouse turn left). Researchers, through optogenetics, have the tools to effect different temporal codes in a neuron while maintaining the same mean firing rate, and thereby can test whether or not temporal coding occurs in specific neural circuits.\n\nOptogenetic technology also has the potential to enable the correction of spike abnormalities at the root of several neurological and psychological disorders. If neurons do encode information in individual spike timing patterns, key signals could be missed by attempting to crack the code while looking only at mean firing rates. Understanding any temporally encoded aspects of the neural code and replicating these sequences in neurons could allow for greater control and treatment of neurological disorders such as depression, schizophrenia, and Parkinson's disease. Regulation of spike intervals in single cells more precisely controls brain activity than the addition of pharmacological agents intravenously.\n\nPhase-of-firing code is a neural coding scheme that combines the spike count code with a time reference based on oscillations. This type of code takes into account a time label for each spike according to a time reference based on phase of local ongoing oscillations at low or high frequencies.\n\nIt has been shown that neurons in some cortical sensory areas encode rich naturalistic stimuli in terms of their spike times relative to the phase of ongoing network oscillatory fluctuations, rather than only in terms of their spike count. The local field potential signals reflect population (network) oscillations. The phase-of-firing code is often categorized as a temporal code although the time label used for spikes (i.e. the network oscillation phase) is a low-resolution (coarse-grained) reference for time. As a result, often only four discrete values for the phase are enough to represent all the information content in this kind of code with respect to the phase of oscillations in low frequencies. Phase-of-firing code is loosely based on the phase precession phenomena observed in place cells of the hippocampus. Another feature of this code is that neurons adhere to a preferred order of spiking between a group of sensory neurons, resulting in firing sequence.\n\nPhase code has been shown in visual cortex to involve also high-frequency oscillations. Within a cycle of gamma oscillation, each neuron has its own preferred relative firing time. As a result, an entire population of neurons generates a firing sequence that has a duration of up to about 15 ms.\n\nPopulation coding is a method to represent stimuli by using the joint activities of a number of neurons. In population coding, each neuron has a distribution of responses over some set of inputs, and the responses of many neurons may be combined to determine some value about the inputs.\n\nFrom the theoretical point of view, population coding is one of a few mathematically well-formulated problems in neuroscience. It grasps the essential features of neural coding and yet is simple enough for theoretic analysis. Experimental studies have revealed that this coding paradigm is widely used in the sensor and motor areas of the brain. For example, in the visual area medial temporal (MT), neurons are tuned to the moving direction. In response to an object moving in a particular direction, many neurons in MT fire with a noise-corrupted and bell-shaped activity pattern across the population. The moving direction of the object is retrieved from the population activity, to be immune from the fluctuation existing in a single neuron’s signal.\nIn one classic example in the primary motor cortex, Apostolos Georgopoulos and colleagues trained monkeys to move a joystick towards a lit target. They found that a single neuron would fire for multiple target directions. However it would fire fastest for one direction and more slowly depending on how close the target was to the neuron's 'preferred' direction.\n\nKenneth Johnson originally derived that if each neuron represents movement in its preferred direction, and the vector sum of all neurons is calculated (each neuron has a firing rate and a preferred direction), the sum points in the direction of motion. In this manner, the population of neurons codes the signal for the motion. This particular population code is referred to as population vector coding. This particular study divided the field of motor physiologists between Evarts' \"upper motor neuron\" group, which followed the hypothesis that motor cortex neurons contributed to control of single muscles, and the Georgopoulos group studying the representation of movement directions in cortex. \n\nThe Johns Hopkins University Neural Encoding laboratory led by Murray Sachs and Eric Young developed place-time population codes, termed the Averaged-Localized-Synchronized-Response (ALSR) code\nfor neural representation of auditory acoustic stimuli. This exploits both the place or tuning within the auditory nerve, as well as the phase-locking within each nerve fiber Auditory nerve.\nThe first ALSR representation was for steady-state vowels;\nALSR representations of pitch and formant frequencies in complex, non-steady state stimuli\nwere demonstrated for voiced-pitch and formant representations in consonant-vowel syllables.\nThe advantage of such representations is that global features such as pitch or formant transition profiles can be represented as global features across the entire nerve simultaneously via both\nrate and place coding.\n\nPopulation coding has a number of other advantages as well, including reduction of uncertainty due to neuronal variability and the ability to represent a number of different stimulus attributes simultaneously. Population coding is also much faster than rate coding and can reflect changes in the stimulus conditions nearly instantaneously. Individual neurons in such a population typically have different but overlapping selectivities, so that many neurons, but not necessarily all, respond to a given stimulus.\n\nTypically an encoding function has a peak value such that activity of the neuron is greatest if the perceptual value is close to the peak value, and becomes reduced accordingly for values less close to the peak value. \n\nIt follows that the actual perceived value can be reconstructed from the overall pattern of activity in the set of neurons. The Johnson/Georgopoulos vector coding is an example of simple averaging. A more sophisticated mathematical technique for performing such a reconstruction is the method of maximum likelihood based on a multivariate distribution of the neuronal responses. These models can assume independence, second order correlations\n, or even more detailed dependencies such as higher order maximum entropy models or copulas.\n\nThe correlation coding model of neuronal firing claims that correlations between action potentials, or \"spikes\", within a spike train may carry additional information above and beyond the simple timing of the spikes. Early work suggested that correlation between spike trains can only reduce, and never increase, the total mutual information present in the two spike trains about a stimulus feature. However, this was later demonstrated to be incorrect. Correlation structure can increase information content if noise and signal correlations are of opposite sign. Correlations can also carry information not present in the average firing rate of two pairs of neurons. A good example of this exists in the pentobarbital-anesthetized marmoset auditory cortex, in which a pure tone causes an increase in the number of correlated spikes, but not an increase in the mean firing rate, of pairs of neurons.\n\nThe independent-spike coding model of neuronal firing claims that each individual action potential, or \"spike\", is independent of each other spike within the spike train.\n\nA typical population code involves neurons with a Gaussian tuning curve whose means vary linearly with the stimulus intensity, meaning that the neuron responds most strongly (in terms of spikes per second) to a stimulus near the mean. The actual intensity could be recovered as the stimulus level corresponding to the mean of the neuron with the greatest response. However, the noise inherent in neural responses means that a maximum likelihood estimation function is more accurate.\nThis type of code is used to encode continuous variables such as joint position, eye position, color, or sound frequency. Any individual neuron is too noisy to faithfully encode the variable using rate coding, but an entire population ensures greater fidelity and precision. For a population of unimodal tuning curves, i.e. with a single peak, the precision typically scales linearly with the number of neurons. Hence, for half the precision, half as many neurons are required. In contrast, when the tuning curves have multiple peaks, as in grid cells that represent space, the precision of the population can scale exponentially with the number of neurons. This greatly reduces the number of neurons required for the same precision.\n\nThe sparse code is when each item is encoded by the strong activation of a relatively small set of neurons. For each item to be encoded, this is a different subset of all available neurons. In contrast to sensor-sparse coding, sensor-dense coding implies that all information from possible sensor locations is known.\n\nAs a consequence, sparseness may be focused on temporal sparseness (\"a relatively small number of time periods are active\") or on the sparseness in an activated population of neurons. In this latter case, this may be defined in one time period as the number of activated neurons relative to the total number of neurons in the population. This seems to be a hallmark of neural computations since compared to traditional computers, information is massively distributed across neurons. A major result in neural coding from Olshausen and Field is that sparse coding of natural images produces wavelet-like oriented filters that resemble the receptive fields of simple cells in the visual cortex. The capacity of sparse codes may be increased by simultaneous use of temporal coding, as found in the locust olfactory system.\n\nGiven a potentially large set of input patterns, sparse coding algorithms (e.g. Sparse Autoencoder) attempt to automatically find a small number of representative patterns which, when combined in the right proportions, reproduce the original input patterns. The sparse coding for the input then consists of those representative patterns. For example, the very large set of English sentences can be encoded by a small number of symbols (i.e. letters, numbers, punctuation, and spaces) combined in a particular order for a particular sentence, and so a sparse coding for English would be those symbols.\n\nMost models of sparse coding are based on the linear generative model. In this model, the symbols are combined in a linear fashion to approximate the input.\n\nMore formally, given a k-dimensional set of real-numbered input vectors formula_1, the goal of sparse coding is to determine n k-dimensional basis vectors formula_2 along with a sparse n-dimensional vector of weights or coefficients formula_3 for each input vector, so that a linear combination of the basis vectors with proportions given by the coefficients results in a close approximation to the input vector: formula_4.\n\nThe codings generated by algorithms implementing a linear generative model can be classified into codings with \"soft sparseness\" and those with \"hard sparseness\". These refer to the distribution of basis vector coefficients for typical inputs. A coding with soft sparseness has a smooth Gaussian-like distribution, but peakier than Gaussian, with many zero values, some small absolute values, fewer larger absolute values, and very few very large absolute values. Thus, many of the basis vectors are active. Hard sparseness, on the other hand, indicates that there are many zero values, \"no\" or \"hardly any\" small absolute values, fewer larger absolute values, and very few very large absolute values, and thus few of the basis vectors are active. This is appealing from a metabolic perspective: less energy is used when fewer neurons are firing.\n\nAnother measure of coding is whether it is \"critically complete\" or \"overcomplete\". If the number of basis vectors n is equal to the dimensionality k of the input set, the coding is said to be critically complete. In this case, smooth changes in the input vector result in abrupt changes in the coefficients, and the coding is not able to gracefully handle small scalings, small translations, or noise in the inputs. If, however, the number of basis vectors is larger than the dimensionality of the input set, the coding is \"overcomplete\". Overcomplete codings smoothly interpolate between input vectors and are robust under input noise. The human primary visual cortex is estimated to be overcomplete by a factor of 500, so that, for example, a 14 x 14 patch of input (a 196-dimensional space) is coded by roughly 100,000 neurons.\n\nSparse coding may be a general strategy of neural systems to augment memory capacity. To adapt to their environments, animals must learn which stimuli are associated with rewards or punishments and distinguish these reinforced stimuli from similar but irrelevant ones. Such task requires implementing stimulus-specific associative memories in which only a few neurons out of a population respond to any given stimulus and each neuron responds to only a few stimuli out of all possible stimuli.\n\nTheoretical work on Sparse distributed memory has suggested that sparse coding increases the capacity of associative memory by reducing overlap between representations. Experimentally, sparse representations of sensory information have been observed in many systems, including vision, audition, touch, and olfaction. However, despite the accumulating evidence for widespread sparse coding and theoretical arguments for its importance, a demonstration that sparse coding improves the stimulus-specificity of associative memory has been lacking until recently.\n\nSome progress has been made in 2014 by Gero Miesenböck's lab at the University of Oxford analyzing Drosophila Olfactory system.\nIn Drosophila, sparse odor coding by the Kenyon cells of the mushroom body is thought to generate a large number of precisely addressable locations for the storage of odor-specific memories. Lin et al. demonstrated that sparseness is controlled by a negative feedback circuit between Kenyon cells and the GABAergic anterior paired lateral (APL) neuron. Systematic activation and blockade of each leg of this feedback circuit show that Kenyon cells activate APL and APL inhibits Kenyon cells. Disrupting the Kenyon cell-APL feedback loop decreases the sparseness of Kenyon cell odor responses, increases inter-odor correlations, and prevents flies from learning to discriminate similar, but not dissimilar, odors. These results suggest that feedback inhibition suppresses Kenyon cell activity to maintain sparse, decorrelated odor coding and thus the odor-specificity of memories.\n\n"}
{"id": "1664221", "url": "https://en.wikipedia.org/wiki?curid=1664221", "title": "Ole Lund Kirkegaard", "text": "Ole Lund Kirkegaard\n\nOle Lund Kirkegaard (29 July 1940, Aarhus — 24 March 1979) was a Danish writer of children's literature and youth literature and a teacher. He mainly wrote about the interaction between adult and child. The main character in his books is usually an anti-hero. In 1969 he was awarded with the Danish Ministry of Culture's children book prize (Denmark) (Kulturministeriets Børnebogspris) \n\nKirkegaard grew up in Skanderborg just south of Aarhus and many of his stories were inspired by his own childhood experiences there. He also illustrated his own books. On a cold winter night in 1979 Kirkegaard, on his way home, fell in the snow and could not get up again, after having had too much to drink. He froze to death on location, at just 38 years of age. The street of Ole Lund Kirkegaards Stræde in Skanderborg, is named after him.\n\nIn Danish:\n\n\nOnly a few of his works have been translated into English. This includes:\n\n\nThe stories of Ole Lund Kirkegaard have inspired several Danish films, including a TV series in 1977.\n"}
{"id": "3845750", "url": "https://en.wikipedia.org/wiki?curid=3845750", "title": "Placentation", "text": "Placentation\n\nIn biology, placentation refers to the formation, type and structure, or arrangement of the placenta. The function of placentation is to transfer nutrients, respiratory gases, and water from maternal tissue to a growing embryo, and in some instances to remove waste from the embryo. Placentation is best known in live-bearing mammals (theria), but also occurs in some fish, reptiles, amphibians, a diversity of invertebrates, and flowering plants. In vertebrates, placentas have evolved more than 100 times independently, with the majority of these instances occurring in squamate reptiles.\n\nThe placenta can be defined as an organ formed by the sustained apposition or fusion of fetal membranes and parental tissue for physiological exchange. This definition is modified from the original Mossman (1937) definition, which constrained placentation in animals to only those instances where it occurred in the uterus.\n\nIn live bearing mammals, the placenta forms after the embryo implants into the wall of the uterus. The developing fetus is connected to the placenta via an umbilical cord. Mammalian placentas can be classified based on the number of tissues separating the maternal from the fetal blood. These include:\nIn this type of placentation, the chorionic villi are in contact with the endothelium of maternal blood vessels. (e.g. in most carnivores like cats and dogs)\nChorionic villi, growing into the apertures of uterine glands ( epithelium). (e.g. in ruminants, horses, whales, lower primates, dugongs)\nIn hemochorial placentation maternal blood comes in direct contact with the fetal chorion, which it does not in the other two types. It may avail for more efficient transfer of nutrients etc., but is also more challenging for the systems of gestational immune tolerance to avoid rejection of the fetus.\n\nDuring pregnancy, placentation is the formation and growth of the placenta inside the uterus. It occurs after the implantation of the embryo into the uterine wall and involves the remodeling of blood vessels in order to supply the needed amount of blood. In humans, placentation takes place 7–8 days after fertilization.\n\nIn humans, the placenta develops in the following manner. Chorionic villi (from the embryo) on the embryonic pole grow, forming chorion frondosum. Villi on the opposite side (abembryonic pole) degenerate and form the chorion laeve (or chorionic laevae), a smooth surface. The endometrium (from the mother) over the chorion frondosum (this part of the endometrium is called the decidua basalis) forms the decidual plate. The decidual plate is tightly attached to the chorion frondosum and goes on to form the actual placenta. Endometrium on the opposite side to the decidua basalis is the decidua parietalis. This fuses with the chorion laevae, thus filling up the uterine cavity.\n\nIn the case of twins, dichorionic placentation refers to the presence of two placentas (in all dizygotic and some monozygotic twins). Monochorionic placentation occurs when monozygotic twins develop with only one placenta and bears a higher risk of complications during pregnancy. Abnormal placentation can lead to an early termination of pregnancy, for example in pre-eclampsia.\n\nAs placentation often results during the evolution of live birth, the more than 100 origins of live birth in lizards and snakes (Squamata) have seen close to an equal number of independent origins of placentation. This means that the occurrence of placentation in squamata is more frequent than in all other vertebrates combined, making them ideal for research on the evolution of placentation and viviparity itself. In most squamates two separate placentae form, utilising separate embryonic tissue (the chorioallantoic and yolk-sac placentae). In species with more complex placentation, we see regional specialisation for gas, amino acid, and lipid transport. Placentae form following implantation into uterine tissue (as seen in mammals) and formation is likely facilitated by a plasma membrane transformation.\n\nMost reptiles exhibit strict epitheliochorial placentation (e.g. \"Pseudemoia entrecasteauxii)\" however at least two examples of endotheliochorial placentation have been identified (\"Mabuya\"\" sp.\" and \"Trachylepis ivensi\"). Unlike eutherian mammals, epitheliochorial placentation is not maintained by maternal tissue as embryos do not readily invade tissues outside of the uterus.\n\nThe placenta is an organ that has evolved multiple times independently, evolved relatively recently in some lineages, and exists in intermediate forms in living species; for these reasons it is an outstanding model to study the evolution of complex organs in animals. Research into the genetic mechanisms that underpin the evolution of the placenta have been conducted in a diversity of animals including reptiles, seahorses, and mammals.\n\nThe genetic processes that support the evolution of the placenta can be best understood by separating those that result in the evolution of new structures within the animal and those that result in the evolution of new functions within the placenta.\n\nEvolution of placental structures\n\nIn all placental animals, placentas have evolved through the utilisation of existing tissues. In viviparous mammals and reptiles placentas form from the intimate interaction of the uterus and a series of embryonic membranes including the chorioallantoic and yolk sac membranes. In guppies placental tissues form between the ovarian tissue and the egg membrane. In pipefish placentas form following the interaction with the egg and the skin.\n\nDespite the placenta forming from pre-existing tissues, in many instances new structures can evolve within these pre-existing tissues. For example, in male seahorses the underbelly skin has become highly modified to form a pouch in which embryos can develop. In mammals and some reptiles, including the viviparous southern grass skink, the uterus becomes regionally specialised to support placental functions, within each of these regions being a new specialised uterine structure. In the southern grass skink three distinct regions of the placenta form which likely perform different functions; the placentome supports nutrient transfer via membrane bound transport proteins, the paraplacentome supports the exchange of respiratory gasses, and the yolk sac placenta supports lipid transport via apocrine secretion.\n\nEvolution of placental functions\n\nPlacental functions include nutrient transport, gas exchange, maternal-fetal communication, and waste removal from the embryo. These functions have evolved by a series of general processes such as re-purposing processes found in the ancestral tissues from which a placenta is derived, recruiting the expression of genes expressed elsewhere in the organism to perform new functions in placental tissues, and the evolution of new molecular processes following the formation of new placenta specific genes.\n\nIn mammals, maternal-fetal communication occurs via the production of a range of signalling molecules and their receptors in the chorioallantoic membrane of the embryo and the endometrium of the mother. Examination of these tissues in egg-laying and other independently evolved live bearing vertebrates has shown us that many of these signalling molecules are expressed widely in vertebrate species and were probably expressed in the ancestral amniote vertebrate. This suggests that maternal fetal communication has evolved by utilising the existing signalling molecules and their receptors, from which placental tissues are derived.\n\nIn flowering plants, placentation occurs where the ovules are attached inside the ovary. The ovules inside a flower's ovary (which later become the seeds inside a fruit) are attached via funiculi, the plant part equivalent to an umbilical cord. The part of the ovary where the funiculus attaches is referred to as the placenta.\n\nIn botany, the term placentation most commonly refers to the arrangement of placentas inside a flower or fruit. Plant placentation types include:\nEg: Helianthus, Tridex, tagetus.\nunilocular ovary becomes bilocular due to formation of false septum.\nthe carpels fuse to form septa forming a central axis and ovules are arranged on the axis.\nEg: Hybiscus , lemon, tomato , lilium.\ndue to degradation of false septum unilocular condition is formed and ovules are arranged on the central axis.\nEg: Dianthus , Primula\nEg: Pea (Pisum Sativam)\n\n\n"}
{"id": "17275189", "url": "https://en.wikipedia.org/wiki?curid=17275189", "title": "Posterior cortical atrophy", "text": "Posterior cortical atrophy\n\nPosterior cortical atrophy (PCA), also called Benson's syndrome, is a form of dementia which is usually considered an atypical variant of Alzheimer's disease (AD). The disease causes atrophy of the posterior part of the cerebral cortex, resulting in the progressive disruption of complex visual processing. PCA was first described by D. Frank Benson in 1988.\n\nIn rare cases, PCA can be caused by dementia with Lewy bodies and Creutzfeldt–Jakob disease.\n\nPCA usually affects people at an earlier age than typical cases of Alzheimer's disease, with initial symptoms often experienced in people in their mid-fifties or early sixties. This was the case with writer Terry Pratchett (1948-2015), who went public in 2007 about being diagnosed with PCA. In \"The Mind's Eye\", neurologist Oliver Sacks examines the case of concert pianist Lilian Kallir (1931–2004), who suffered from PCA.\n\nThe main symptom resulting from PCA is a decrease in visuospatial and visuoperceptual capabilities. Because the posterior region of the brain is home to the occipital lobe, which is responsible for visual processing, visual functions are impaired in PCA patients. The atrophy is progressive; early symptoms include difficulty reading, blurred vision, light sensitivity, issues with depth perception, and trouble navigating through space. Additional symptoms include apraxia, a disorder of movement planning, alexia, an impaired ability to read, and visual agnosia, an object recognition disorder. Damage to the ventral, or “what” stream, of the visual system, located in the temporal lobe, leads to the symptoms related to general vision and object recognition deficits; damage to the dorsal, or “where/how” stream, located in the parietal lobe, leads to PCA symptoms related to impaired movements in response to visual stimuli, such as navigation and apraxia. \nAs neurodegeneration spreads, more severe symptoms emerge, including the inability to recognize familiar people and objects, trouble navigating familiar places, and sometimes visual hallucinations. In addition, patients may experience difficulty making guiding movements towards objects, and may experience a decline in literacy skills including reading, writing, and spelling. Furthermore, if neural death spreads into other anterior cortical regions, symptoms similar to Alzheimer's disease, such as memory loss, may result. PCA patients with significant atrophy in one hemisphere of the brain may experience hemispatial neglect, the inability to see stimuli on one half of the visual field. Anxiety and depression are also common in PCA patients.\n\nAt this time the cause of PCA is unknown; similarly, there are no fully accepted diagnostic criteria for the disease. This is partially due to the gradual onset of PCA symptoms, the variety of symptoms, the rare nature of the disease and younger age of patients (initial symptoms appear in patients of 50–60 years old). In 2012, the first international conference on PCA was held in Vancouver, Canada. Continued research and testing will hopefully result in accepted and standardized criteria for diagnosis.\n\nPCA patients are often initially misdiagnosed with an anxiety disorder or depression. Some believe that patients may experience depression or anxiety due to their awareness of their symptoms, such as decrease in their vision capabilities, yet they are unable to control this decline in their vision or the progressive nature of the disease. The early visual impairments of a PCA patient have often led to an incorrect referral to an ophthalmologist, which can result in unnecessary cataract surgery.\n\nDue to the lack of biological marks of PCA, neuropsychological examinations should be used for diagnosis. Neuroimaging can also assist in diagnosis of PCA. The common tools used for Neuroimaging of both PCA and AD patients are magnetic resonance imaging (MRI's), a popular form of medical imaging that uses magnetic fields and radio waves, as well as single-photon emission computed tomography, an imaging form that uses gamma rays, and positron emission tomography, another imaging tool that creates 3D images with a pair of gamma rays and a tracer. Images of PCA patient’s brains are often compared to AD patient images to assist diagnosis. Due to the early onset of PCA in comparison to AD, images taken at the early stages of the disease will vary from brain images of AD patients. At this early stage PCA patients will show brain atrophy more centrally located in the right posterior lobe and occipital gyrus, while AD brain images show the majority of atrophy in the medial temporal cortex. This variation within the images will assist in early diagnosis of PCA; however, as the years go on the images will become increasingly similar, due to the majority of PCA patients also having AD later in life because of continued brain atrophy. A key aspect found through brain imaging of PCA patients is a loss of grey matter (collections of neuronal cell bodies) in the posterior and occipital temporal cortices within the right hemisphere.\n\nFor some PCA patients, neuroimaging may not result with a clear diagnosis; therefore, careful observation of the patient in relation to PCA symptoms can also assist in the diagnosis of the patient. The variation and lack of organized clinical testing has led to continued difficulties and delays in the diagnosis of PCA in patients.\n\nSpecific and accepted scientific treatment for PCA has yet to be discovered; this may be due to the rarity and variations of the disease. At times PCA patients are treated with prescriptions originally created for treatment of AD such as, cholinesterase inhibitors, Donepezil, Rivastigmine and Galantamine, and Memantine. Antidepressant drugs have also provided some positive effects.\n\nPatients may find success with non-prescription treatments such as psychological treatments. PCA patients may find assistance in meeting with an occupational therapist or sensory team for aid in adapting to the PCA symptoms, especially for visual changes. People with PCA and their caregivers are likely to have different needs to more typical cases of Alzheimer's disease, and may benefit from specialized support groups such as the PCA Support Group based at University College London, or other groups for young people with dementia. No study to date has been definitive to provide accepted conclusive analysis on treatment options.\n\nStudies have shown that PCA may be a variant of Alzheimer's disease (AD), with an emphasis on visual deficits. Although in primarily different, but sometimes overlapping, brain regions, both involve progressive neural degeneration, as shown by the loss of neurons and synapses, and the presence of neurofibrillary tangles and senile plaques in affected brain regions; this eventually leads to dementia in both diseases. PCA patients have more cortical damage and gray matter (cell body) loss in posterior regions, especially in the occipital, parietal, and temporal lobes, whereas Alzheimer’s patients typically experience more damage in the prefrontal cortex and hippocampus. PCA tends to impair working memory and anterograde memory, while leaving episodic memory intact, whereas AD patients typically have damaged episodic memory, suggesting some differences still lie in the primary areas of cortical damage.\n\nOver time, however, atrophy in PCA patients may spread to regions commonly damaged in AD patients, leading to common AD symptoms such as deficits in memory, language, learning, and cognition. Although PCA has an earlier onset, many PCA patients have also been diagnosed with Alzheimer’s, suggesting that the degeneration has simply migrated anteriorly to other cortical brain regions.\n\nThere is no standard definition of PCA and no established diagnostic criteria, so it is not possible to know how many people have the condition. Some studies have found that about 5 percent of people diagnosed with Alzheimer’s disease have PCA. However, because PCA often goes unrecognized, the true percentage may be as high as 15 percent. Researchers and physicians are working to establish a standard definition and diagnostic criteria for PCA.\n\nPCA may also be correlated with the diseases of Lewy body, Creutzfeldt–Jakob disease, Bálint's syndrome, and Gerstmann syndrome. In addition, PCA may result in part from mutations in the presenilin 1 gene (PSEN1).\n\n"}
{"id": "18577340", "url": "https://en.wikipedia.org/wiki?curid=18577340", "title": "Predictify", "text": "Predictify\n\nPredictify.com was a Web 2.0 company based in Redwood City, California. It was founded by Stanford University graduates Parker Barrile and Michael Agnich. It went out of business in 2009, according to this article..\n\nUsers of the site users submitted deterministic, verifiable questions concerning future events. Other users then gave answers and predicted the outcome.\n\nUsers who answered questions were rewarded in two ways. First, the accuracy of user responses was tracked and reevaluated each time a question that the user answered closed. Predictify assigned users to one of five \"levels\" depending on the user's accuracy percentile. Users could also earn money for correctly answering \"Premium Questions\". Premium questions were generally submitted by companies. The submitter of a premium question received detailed demographic information and analysis on each answer given. Part of the fee paid by premium question submitters constituted the \"pot\" from which correct answers were paid.\n\nThe site allowed marketing and market research in a manner far less obvious than most traditional advertising and survey methods. Users didn't realize that their predictions may have strongly affected the outcome of the question. For example, if a company was considering increasing the cost of a product, they could survey consumers to determine how much more they were willing to pay. The outcome of the survey would then set the new price of the product. The company could further sort the data based on the demographic information collected on respondents, to ensure that they priced the product correctly for their target market. The demographic analysis of respondents was very valuable to companies and was the true product Predictify sells.\n\nCompanies could also use questions on Predictify to conduct guerilla advertising campaigns. Users would try to answer premium questions correctly, in order to win the cash prize associated with the question. In the course of formulating their prediction they may have researched the subject of the question. Companies could create interest in their products by asking questions about them; individuals answering the question may have visited the company's website to learn more about the product. Dilbert creator, Scott Adams, posted a question seeking sales volume projections of a book he authored. Early customers and partnerships were established by the company's first full-time employee, Ed Heacox.\n\nThe Washington Post, New York Times, and San Francisco Chronicle all have used Predictify to judge reader interest in stories.\n\nAccording to an announcement made in Predictify's official page, the company ceased operations and shut down the entire Predictify service on September 1, 2009.\n"}
{"id": "31105000", "url": "https://en.wikipedia.org/wiki?curid=31105000", "title": "Princess Charlotte of Hesse-Darmstadt", "text": "Princess Charlotte of Hesse-Darmstadt\n\nCharlotte Wilhelmine Christiane Marie of Hesse-Darmstadt (5 November 1755, Darmstadt – 12 December 1785, Hanover), was by marriage Duchess of Mecklenburg-Strelitz.\n\nCharlotte was a daughter of Prince George William of Hesse-Darmstadt (1722-1782) from his marriage to Countess Maria Louise Albertine of Leiningen-Falkenburg-Dagsburg (1729-1818), daughter of Count Christian Karl Reinhard of Leiningen-Dachsburg-Falkenburg-Heidesheim.\n\nThe princess was first engaged with the hereditary prince Peter Frederick William of Oldenburg, but the engagement was dissolved again as a result of the onset of Peter's mental illness.\n\nCharlotte married Charles of Mecklenburg-Strelitz (who later became the Duke of Mecklenburg-Strelitz), on 28 September 1784 in Darmstadt. He was previously married to Charlotte's older sister Friederike, who had died in childbirth. She thus became stepmother for her sister's five surviving children - her nieces and nephews.\n\nThe couple lived in Hanover, where Charles served as Governor-General for his brother-in-law, King George. Charlotte died after the birth of her only child, a year after their marriage. Charles resigned from his post in Hanover and moved to Charlotte's mother in Darmstadt, who then took care of his children (both Frederike's and Charlotte's).\n\nHer only child from her marriage to Charles was:\n\n"}
{"id": "40900012", "url": "https://en.wikipedia.org/wiki?curid=40900012", "title": "Rana Bokhari", "text": "Rana Bokhari\n\nRana Bokhari (born October 23, 1977) was the leader of the Manitoba Liberal Party from 2013 until 2016 in Manitoba, Canada.\n\nBokhari was born on a farm near Anola, Manitoba. As a student she attended the University of Manitoba where she obtained degrees in criminology and psychology. She then went on to complete a degree in law at Robson Hall, focusing on corporate commercial law. Bokhari was active in the Manitoba Law Students Association, serving as President in 2012.\n\nBokhari moved to Pakistan in 2002, living there with her family until she returned to Winnipeg in 2006. Her childhood home and family chicken farm were lost to a fire in 2012.\n\nAfter long-standing Manitoba Liberal Party leader Jon Gerrard resigned his position, Bokhari was the first person formally to declare her candidacy. She faced two opponents, Bob Axworthy and Dougald Lamont. During the party leadership contest, Bokhari was seen as an outsider. Although two of her relatives had stood as Liberal candidates at the previous provincial election, she had not previously had a profile in the provincial party. Despite this, she was endorsed by the Manitoba Senator Maria Chaput, the leading Liberal candidate from the 2011 elections, Paul Hesse and party Vice-President Robert Young. She won a first ballot victory by one vote, with 431 votes.\n\nThe victory made Rana Bokhari the youngest person ever to lead the Manitoba Liberals and the first Manitoban of South Asian descent to lead a political party in the province.\n\nShe faced internal criticism from party members and former leadership challenger Bob Axworthy, who accused Bokhari of \"purging\" longtime Manitoba Liberal members as she solidified control of the party. Party membership and fundraising struggled under Bokhari.\n\nBokhari committed to making Manitoba the \"hub of something\" in her year end interview with the Winnipeg Free Press. She explained \"I want Manitoba to be the IT capital of this country or the innovation capital of this country.\"\n\nIn 2014 Bokhari endorsed Winnipeg mayoral candidate Brian Bowman in the 2014 Winnipeg Municipal election.\n\nIn the Manitoba general election, 2016 Bokhari finished third in Fort Rouge, behind future Manitoba NDP leader Wab Kinew. On May 7, 2016, Bokhari announced that she would not lead the party into the next election but would remain on as leader until her successor was chosen. She ultimately resigned as leader, effective September 24, 2016, and opened a law practice, Bokhari, Smith and Walker, the same month.\n"}
{"id": "8288415", "url": "https://en.wikipedia.org/wiki?curid=8288415", "title": "Regional differentiation", "text": "Regional differentiation\n\nIn the field of developmental biology, regional differentiation is the process by which different areas are identified in the development of the early embryo. The process by which the cells become specified differs between organisms.\n\nIn terms of developmental commitment, a cell can either be specified or it can be determined. Specification is the first stage in differentiation. A cell that is specified can have its commitment reversed while the determined state is irreversible. There are two main types of specification: autonomous and conditional. A cell specified autonomously will develop into a specific fate based upon cytoplasmic determinants with no regard to the environment the cell is in. A cell specified conditionally will develop into a specific fate based upon other surrounding cells or morphogen gradients. Another type of specification is syncytial specification, characteristic of most insect classes.\n\nSpecification in sea urchins uses both autonomous and conditional mechanisms to determine the anterior/posterior axis. The anterior/posterior axis lies along the animal/vegetal axis set up during cleavage. The micromeres induce the nearby tissue to become endoderm while the animal cells are specified to become ectoderm. The animal cells are not determined because the micromeres can induce the animal cells to also take on mesodermal and endodermal fates. It was observed that β-catenin was present in the nuclei at the vegetal pole of the blastula. Through a series of experiments, one study confirmed the role of β-catenin in the cell-autonomous specification of vegetal cell fates and the micromeres inducing ability. Treatments of LiCl sufficient to vegetalize the embryo resulted in increases in nuclearly localized b-catenin. Reduction of expression of β-catenin in the nucleus correlated with loss of vegetal cell fates. Transplants of micromeres lacking nuclear accumulation of β-catenin were unable to induce a second axis.\n\nFor the molecular mechanism of β-catenin and the micromeres, it was observed that Notch was present uniformly on the apical surface of the early blastula but was lost in the secondary mesenchyme cells (SMCs) during late blastula and enriched in the presumptive endodermal cells in late blastula. Notch is both necessary and sufficient for determination of the SMCs. The micromeres express the ligand for Notch, Delta, on their surface to induce the formation of SMCs.\n\nThe high nuclear levels of b-catenin results from the high accumulation of the disheveled protein at the vegetal pole of the egg. disheveled inactivates GSK-3 and prevents the phosphorylation of β-catenin. This allows β-catenin to escape degradation and enter the nucleus. The only important role of β-catenin is to activate the transcription of the gene Pmar1. This gene represses a repressor to allow micromere genes to be expressed.\n\nThe aboral/oral axis (analogous to the dorsal/ventral axes in other animals) is specified by a nodal homolog. This nodal was localized on the future oral side of the embryo. Experiments confirmed that nodal is both necessary and sufficient to promote development of the oral fate. Nodal also has a role in left/right axis formation.\n\nTunicates have been a popular choice for the study of regional specification because tunicates were the first organism in which autonomous specification was discovered and tunicates are evolutionary related to vertebrates.\n\nEarly observations in tunicates led to the identification of the yellow crescent (also called the myoplasm). This cytoplasm was segregated to future muscle cells and if transplanted could induce the formation of muscle cells. The cytoplasmic determinant macho-1 was isolated as the necessary and sufficient factor for muscle cell formation. Similar to Sea urchins, the accumulation of b-catenin in the nuclei was identified as both necessary and sufficient to induce endoderm.\n\nTwo more cell fates are determined by conditional specification. The endoderm sends a fibroblast growth factor (FGF) signal to specify the notocord and the mesenchyme fates. Anterior cells respond to FGF to become notocord while posterior cells (identified by the presence of macho-1) respond to FGF to become mesenchyme.\n\nThe cytoplasm of the egg not only determines cell fate, but also determines the dorsal/ventral axis. The cytoplasm in the vegetal pole specifies this axis and removing this cytoplasm leads to a loss of axis information. The yellow cytoplasm specifies the anterior/posterior axis. When the yellow cytoplasm moves to the posterior of the egg to become posterior vegetal cytoplasm (PVC), the anterior/posterior axis is specified. Removal of the PVC leads to a loss of the axis while transplantation to the anterior reverses the axis.\n\nIn the two cell stage, the embryo of the nematode \"C. elegans\" exhibits mosaic behavior. There are two cells, the P1 cell and the AB cell. The P1 cell was able make all of its fated cells while the AB cell could only make a portion of the cells it was fated to produce. Thus, The first division gives the autonomous specification of the two cells, but the AB cells require a conditional mechanism to produce all of its fated cells.\n\nThe AB lineage gives rise to neurons, skin, and pharynx. The P1 cell divides into EMS and P2. The EMS cell divides into MS and E. The MS lineage gives rise to pharynx, muscle, and neurons. The E lineage gives rise to intestines. The P2 cell divides into P3 and C founder cells. The C founder cells give rise to muscle, skin, and neurons. The P3 cell divides into P4 and D founder cells. The D founder cells give rise to muscle while the P4 lineage gives rise to the germ line.\n\n\n\n\n\n\n\n\nThe anterior/posterior patterning of \"Drosophila\" come from three maternal groups of genes. The anterior group patterns the head and thoracic segments. The posterior group patterns the abdominal segments and the terminal group patterns the anterior and posterior terminal regions called the terminalia (the acron in the anterior and the telson in the posterior).\n\nThe anterior group genes include bicoid. Bicoid functions as a graded morphogen transcription factor that localizes to the nucleus. The head of the embryo forms at the point of highest concentration of bicoid and the anterior pattern depends upon the concentration of bicoid. Bicoid works as a transcriptional activator of the gap genes hunchback (hb), buttonhead (btd), empty spiracles (ems), and orthodentical (otd) while also acting to repress translation of caudal. A different affinity for bicoid in the promoters of the genes it activates allows for the concentration dependent activation. Otd has a low affinity for bicoid, hb has a higher affinity and so will be activated at a lower bicoid concentration. Two other anterior group genes, swallow and exuperantia play a role in localizing bicoid to the anterior. Bicoid is directed to the anterior by its 3' untranslated region (3'UTR). The microtubule cytoskeleton also plays a role in localizing bicoid.\n\nThe posterior group genes include nanos. Similar to bicoid, nanos is localized to the posterior pole as a graded morphogen. The only role of nanos is to repress the maternally transcribed hunchback mRNA in the posterior. Another protein, pumilio, is required for nanos to repress hunchback. Other posterior proteins, oskar (which tethers nanos mRNA), Tudor, vasa, and Valois, localize the germ line determinants and nanos to the posterior.\n\nIn contrast to the anterior and the posterior, the positional information for the terminalia come from the follicle cells of the ovary. The terminalia are specified through the action of the Torso receptor tyrosine kinase. The follicle cells secrete Torso-like into the perivitelline space only at the poles. Torso-like cleaves the pro-peptide Trunk which appears to be the Torso ligand. Trunk activates Torso and causes a signal transduction cascade which represses the transcriptional repressor Groucho which in turn causes the activation of the terminal gap genes tailless and huckebein.\n\nThe patterning from the maternal genes work to influence the expression of the segmentation genes. The segmentation genes are embryonically expressed genes that specify the numbers, size and polarity of the segments. The gap genes are directly influenced by the maternal genes and are expressed in local and overlapping regions along the anterior/posterior axis. These genes are influenced by not only the maternal genes, but also by epistatic interactions between the other gap genes.\n\nThe gap genes work to activate the pair-rule genes. Each pair-rule gene is expressed in seven stripes as a result of the combined effect of the gap genes and interactions between the other pair-rule genes. The pair-rule genes can be divided into two classes: the primary pair-rule genes and the secondary pair-rule genes. The primary pair-rules genes are able to influence the secondary pair-rule genes but not vice versa. The molecular mechanism between the regulation of the primary pair-rule genes was understood through a complex analysis of the regulation of even-skipped. Both positive and negative regulatory interactions by both maternal and gap genes and a unique combination of transcription factors work to express even-skipped in different parts of the embryo. The same gap gene can act positively in one stripe but negatively in another.\n\nThe expression of the pair-rule genes translate into the expression of the segment polarity genes in 14 stripes. The role of the segment polarity genes is to define to boundaries and the polarity of the segments. The means to which the genes accomplish this is believed to involve a wingless and hedgehog graded distribution or cascade of signals initiated by these proteins. Unlike the gap and the pair-rule genes, the segment polarity genes function within cells rather than within the syncytium. Thus, segment polarity genes influence patterning though signaling rather than autonomously. Also, the gap and pair-rule genes are expressed transiently while segment polarity gene expression is maintained throughout development. The continued expression of the segment polarity genes is maintained by a feedback loop involving hedgehog and wingless.\n\nWhile the segmentation genes can specify the number, size, and polarity of segments, homeotic genes can specify the identity of the segment. The homeotic genes are activated by gap genes and pair-rule genes. The Antennapedia complex and the bithorax complex on the third chromosome contain the major homeotic genes required for specifying segmental identity (actually parasegmental identity). These genes are transcription factors and are expressed in overlapping regions that correlate with their position along the chromosome. These transcription factors regulate other transcription factors, cell surface molecules with roles in cell adhesion, and other cell signals. Later during development, homeotic genes are expressed in the nervous system in a similar anterior/posterior pattern. Homeotic genes are maintained throughout development through the modification of the condensation state of their chromatin. Polycomb genes maintain the chromatin in an inactive conformation while trithorax genes maintain chromatin in an active conformation.\n\nAll homeotic genes share a segment of protein with a similar sequence and structure called the homeodomain (the DNA sequence is called the homeobox). This region of the homeotic proteins binds DNA. This domain was found in other developmental regulatory proteins, such as bicoid, as well in other animals including humans. Molecular mapping revealed that the HOX gene cluster has been inherited intact from a common ancestor of flies and mammals which indicates that it is a fundamental developmental regulatory system.\n\nThe maternal protein, Dorsal, functions like a graded morphogen to set the ventral side of the embryo (the name comes from mutations which led to a dorsalized phenotype). \"Dorsal\" is like \"bicoid\" in that it is a nuclear protein; however, unlike \"bicoid,\" \"dorsal\" is uniformly distributed throughout the embryo. The concentration difference arises from differential nuclear transport. The mechanism by which \"dorsa\"l becomes differentially located into the nuclei occurs in three steps.\n\nThe first step happens in the dorsal side of the embryo. The nucleus in the oocyte moves along a microtubule track to one side of the oocyte. This side sends a signal, \"gurken\", to the \"torpedo\" receptors on the follicle cells. The \"torpedo\" receptor is found in all follicle cells; however, the \"gurken\" signal is only found on the anterior dorsal side of the oocyte. The follicle cells change shape and synthetic properties to distinguish the dorsal side from the ventral side. These dorsal follicle cells are unable to produce the pipe protein required for step two.\n\nThe second step is a signal from the ventral follicle cells back to the oocyte. This signal acts after the egg has left the follicle cells so this signal is stored in the perivitelline space. The follicle cells secrete \"windbeutel,\" \"nudel,\" and \"pipe,\" which create a protease-activating complex. Because the dorsal follicle cells do not express \"pipe,\" they are not able to create this complex. Later, the embryo secretes three inactive proteases (\"gastrulation defective,\" \"snake,\" and \"Easter\") and an inactive ligand (\"spätzle\") into the perivitelline space. These proteases are activated by the complex and cleave \"spätzle\" into an active form. This active protein is distributed in a ventral to dorsal gradient. \"Toll\" is a receptor tyrosine kinase for \"spätzle\" and transduces the graded \"spätzle\" signal through the cytoplasm to phosphorylate \"cactus\". Once phosphorylated, \"cactus\" no longer binds to \"dorsal,\" leaving it free to enter the nucleus. The amount of released \"dorsal\" depends on the amount of \"spätzle\" protein present.\n\nThe third step is the regional expression of zygotic genes \"decapentaplegic\" (\"dpp\"), \"zerknüllt\", \"tolloid\", \"twist\", \"snail\", and \"rhomboid\" due to the expression of \"dorsal\" in the nucleus. High levels of \"dorsal\" are required to turn on transcription of \"twist\" and \"snail.\" Low levels of \"dorsal\" can activate the transcription of \"rhomboid.\" \"Dorsal\" represses the transcription of \"zerknüllt,\" \"tolloid,\" and \"dpp.\" The zygotic genes also interact with each other to restrict their domains of expression.\n\nBetween fertilization and the first cleavage in \"Xenopus\" embryos, the cortical cytoplasm of the zygote rotates relative to the central cytoplasm by about 30 degrees to uncover (in some species) a gray crescent in the marginal or middle region of the embryo. The cortical rotation is powered by microtubules motors moving along parallel arrays of cortical microtubules. This gray crescent marks the future dorsal side of the embryo. Blocking this rotation prevents formation of the dorsal/ventral axis. By the late blastula stage, the \"Xenopus\" embryos have a clear dorsal/ventral axis.\n\nIn the early gastrula, most of the tissue in the embryo is not determined. The one exception is the anterior portion of the dorsal blastopore lip. When this tissue was transplanted to another part of the embryo, it developed as it normally would. In addition, this tissue was able to induce the formation of another dorsal/ventral axis. Hans Spemann named this region the organizer and the induction of the dorsal axis the primary induction.\n\nThe organizer is induced from a dorsal vegetal region called the Nieuwkoop center. There are many different developmental potentials throughout the blastula stage embryos. The vegetal cap can give rise to only endodermal cell types while the animal cap can give rise to only ectodermal cell types. The marginal zone, however, can give rise to most structures in the embryo including mesoderm. A series of experiments by Pieter Nieuwkoop showed that if the marginal zone is removed and the animal and vegetal caps placed next to each other, the mesoderm comes from the animal cap and the dorsal tissues are always adjacent to the dorsal vegetal cells. Thus, this dorsal vegetal region, named the Nieuwkoop center, was able to induce the formation of the organizer.\n\nTwinning assays identified Wnt proteins as molecules from the Nieuwkoop center that could specify the dorsal/ventral axis. In twinning assays, molecules are injected into the ventral blastomere of a four-cell stage embryo. If the molecules specifies the dorsal axis, dorsal structures will be formed on the ventral side. Wnt proteins were not necessary to specify the axis, but examination of other proteins in the Wnt pathway led to the discovery that β-catenin was. β-catenin is present in the nuclei on the dorsal side but not on the ventral side. β-catenin levels are regulated by GSK-3. When active, GSK-3 phosphorylates free β-catenin, which is then targeted for degradation. There are two possible molecules that might regulate GSK-3: GBP (GSK-3 Binding Protein) and Dishevelled. The current model is that these act together to inhibit GSK-3 activity. Dishevelled is able to induce a secondary axis when overexpressed and is present at higher levels on the dorsal side after cortical rotation (Symmetry Breaking and Cortical Rotation). Depletion of Dishevelled, however, has no effect. GBP has an effect both when depleted and overexpressed. Recent evidence, however, showed that Xwnt11, a Wnt molecule expressed in \"Xenopus\", was both sufficient and necessary for dorsal axis formation.\n\nMesoderm formation comes from two signals: one for the ventral portion and one for the dorsal portion. Animal cap assays were used to determine the molecular signals from the vegetal cap that are able to induce the animal cap to form mesoderm. In an animal cap assay, molecules of interest are either applied in medium that the cap is grown in or injected as mRNA in an early embryo. These experiments identified a group of molecules, the transforming growth factor-β (TGF-β) family. With dominant negative forms of TGF-β, early experiments were only able to identify the family of molecules involved not the specific member. Recent experiments have identified the \"Xenopus\" nodal-related proteins (Xnr-1, Xnr-2, and Xnr-4) as the mesoderm-inducing signals. Inhibitors of these ligands prevents mesoderm formation and these proteins show a graded distribution along the dorsal/ventral axis.\n\nVegetally localized mRNA, VegT and possibly Vg1, are involved in inducing the endoderm. It is hypothesized that VegT also activates the Xnr-1,2,4 proteins. VegT acts as a transcription factor to activate genes specifying endodermal fate while Vg1 acts as a paracrine factor.\n\nβ-catenin in the nucleus activates two transcription factors: siamois and twin. β-catenin also acts synergistically with VegT to produce high levels of Xnr-1,2,4. Siamois will act synergistically with Xnr-1,2,4 to activate a high level of the transcription factors such as goosecoid in the organizer. Areas in the embryo with lower levels of Xnr-1,2,4 will express ventral or lateral mesoderm. Nuclear β-catenin works synergistically with the mesodermal cell fate signal to create the signaling activity of the Nieuwkoop center to induce the formation of the organizer in the dorsal mesoderm.\n\nThere are two classes of genes that are responsible for the organizer's activity: transcription factors and secreted proteins. Goosecoid (which has a homology between bicoid and gooseberry) is the first known gene to be expressed in the organizer and is both sufficient and necessary to specify a secondary axis.\n\nThe organizer induces ventral mesoderm to become lateral mesoderm, induces the ectoderm to form neural tissue and induces dorsal structures in the endoderm. The mechanism behind these inductions is an inhibition of the bone morphogenetic protein 4 signaling pathway that ventralizes the embryo. In the absence of these signals, ectoderm reverts to its default state of neural tissue. Four of the secreted molecules from the organizer, chordin, noggin, follistatin and Xenopus nodal-related-3 (Xnr-3), directly interact with BMP-4 and block its ability to bind to its receptor. Thus, these molecules create a gradient of BMP-4 along the dorsal/ventral axis of the mesoderm.\n\nBMP-4 mainly acts in trunk and tail region of the embryo while a different set of signals work in the head region. Xwnt-8 is expressed throughout the ventral and lateral mesoderm. The endomesoderm (can give rise to either endoderm or mesoderm) at the leading edge of the archenteron (future anterior) secrete three factors Cerberus, Dickkopf, and Frzb. While Cerberus and Frzb bind directly to Xwnt-8 to prevent it from binding to its receptor, Cerberus is also capable of binding to BMP-4 and Xnr1. Furthermore, Dickkopf binds to LRP-5, a transmembrane protein important for the signalling pathway of Xwnt-8, leading to endocytosis of LRP-5 and eventually to an inhibition of the Xwnt-8 pathway.\n\nThe anterior/posterior patterning of the embryo occurs sometime before or during gastrulation. The first cells to involute have anterior inducing activity while the last cells have posterior inducing activity. The anterior inducing ability comes from the Xwnt-8 antagonizing signals Cereberus, Dickkopf and Frzb discussed above. Anterior head development also requires the function of IGFs (insulin-like growth factors) expressed in the dorsal midline and the anterior neural tube. It is believed that IGFs function by activating a signal transduction cascade that interferes and inhibits both Wnt signaling and BMP signaling. In the posterior, two candidates for posteriorizing signals include eFGF, a fibroblast growth factor homologue, and retinoic acid.\n\nThe basis for axis formation in zebrafish parallels what is known in amphibians. The embryonic shield has the same function as the dorsal lip of the blastopore and acts as the organizer. When transplanted, it is able to organize a secondary axis and removing it prevents the formation of dorsal structures. β-catenin also has a role similar to its role in amphibians. It accumulates in the nucleus only on the dorsal side; ventral β-catenin induces a secondary axis. It activates the expression of Squint (a Nodal related signaling protein aka ndr1) and Bozozok (a homeodomain transcription factor similar to Siamois) which act together to activate goosecoid in the embryonic shield.\n\nAs in Xenopus, mesoderm induction involves two signals: one from the vegetal pole to induce ventral mesoderm and one from the Nieuwkoop center equivalent dorsal vegetal cells to induce dorsal mesoderm.\n\nThe signals from the organizer also parallel to those from amphibians. Noggin and chordin homologue Chordino, binds to a BMP family member, BMP2B, to block it from ventralizing the embryo. Dickkopf binds to a Wnt homolog Wnt8 to block it from ventralizing and posteriorizing the embryo.\n\nThere is a third pathway regulated by β-catenin in fish. β-catenin activates the transcription factor stat3. Stat3 coordinates cell movements during gastrulation and contributes to establishing planar polarity.\n\nThe dorsal/ventral axis is defined in chick embryos by the orientation of the cells with respect to the yolk. Ventral is down with respect to the yolk while animal is up. This axis is defined by the creation of a pH difference \"inside\" and \"outside\" of the blastoderm between the subgerminal space and the albumin on the outside. The subgerminal space has a pH of 6.5 while the albumin on the outside has a pH of 9.5.\n\nThe anterior/posterior axis is defined during the initial tilting of the embryo when the eggshell is being desposited. The egg is constantly being rotated in a consistent direction and there is a partial stratification of the yolk; the lighter yolk components will be near one end of the blastoderm and will become the future posterior. The molecular basis of the posterior is not known, however, the accumulation of cells eventually results in the posterior marginal zone (PMZ).\n\nThe PMZ is the equivalent of the Nieuwkoop center is that its role is to induce Hensen's node. Transplantation of the PMZ results in induction of a primitive streak, however, PMZ does not contribute to the streak itself. Similar to the Nieuwkoop center, the PMZ expresses both Vg1 and nuclear localized β-catenin.\n\nThe Hensen's node is equivalent to the organizer. Transplantation of Hensen's node results in the formation of a secondary axis. Hensen's node is the site where gastrulation begins and it becomes the dorsal mesoderm. Hensen's node is formed from the induction of PMZ on the anterior part of the PMZ called Koller's sickle. When the primitive streak forms, these cells expand out to become Hensen's node. These cells express goosecoid consistent with their role as the organizer.\n\nThe function of the organizer in chick embryos is similar to that of amphibians and fish, however, there are some differences. Similar to the amphibians and fish, the organizer does secrete Chordin, Noggin and Nodal proteins that antagonize BMP signaling and dorsalize the embryo. Neural induction, however, does not rely entirely on inhibiting the BMP signaling. Overexpression of BMP antagonists is not enough induce formation of neurons nor overexpressing BMP block formation of neurons. While the whole story is unknown for neural induction, FGFs seem to play a role in mesoderm and neural induction. The anterior/posterior patterning of the embryo requires signals like cereberus from the hyboplast and the spatial regulation of retinoic acid accumulation to activate the 3' Hox genes in the posterior neuroectoderm (hindbrain and spinal cord).\n\nThe earliest specification in mouse embryos occurs between trophoblast and inner cell mass cells in the outer polar cells and the inner apolar cells respectively. These two groups become specified at the eight-cell stage during compaction, but do not become determined until they reach the 64-cell stage. If an apolar cell is transplanted to the outside during the 8-32 cell stage, that cell will develop as a trophoblast cell.\n\nThe anterior/posterior axis in the mouse embryo is specified by two signaling centers. In the mouse embryo, the egg forms a cylinder with the epiblast forming a cup at the distal end of that cylinder. The epiblast is surrounded by the visceral endoderm, the equivalent of the hypoblast of humans and chicks. Signals for the anterior/posterior axis come from primitive knot. The other important site is the anterior visceral endoderm (AVE). The AVE lies anterior to the node's most anterior position and lies just under the epiblast in the region that will become occupied by migrating endomesoderm to form head mesoderm and foregut endoderm. The AVE interacts with the node to specify the most anterior structures. Thus, the node is able to form a normal trunk, but requires signals from the AVE to form a head.\n\nThe discovery of the homeobox in \"Drosophila\" flies and its conservation in other animals has led to advancements in understanding the anterior/posterior patterning. Most of the Hox genes in mammals show an expression pattern that parallels the homeotic genes in flies. In mammals, there are four copies of the Hox genes. Each set of Hox genes are paralogous to the others (Hox1a is a paralogue of Hox1b, etc.) These paralogs show overlapping expression patterns and could act redundantly. However, double mutations in paralogous genes can also act synergistically indicating that the genes must work together for function.\n\n"}
{"id": "26861", "url": "https://en.wikipedia.org/wiki?curid=26861", "title": "Shamanism", "text": "Shamanism\n\nShamanism is a practice that involves a practitioner reaching altered states of consciousness in order to perceive and interact with what they believe to be a spirit world and channel these transcendental energies into this world.\n\nA shaman ( , or ) is someone who is regarded as having access to, and influence in, the world of benevolent and malevolent spirits, who typically enters into a trance state during a ritual, and practices divination and healing. The word \"shaman\" probably originates from the Tungusic Evenki language of North Asia. According to ethnolinguist Juha Janhunen, \"the word is attested in all of the Tungusic idioms\" such as Negidal, Lamut, Udehe/Orochi, Nanai, Ilcha, Orok, Manchu and Ulcha, and \"nothing seems to contradict the assumption that the meaning 'shaman' also derives from Proto-Tungusic\" and may have roots that extend back in time at least two millennia. The term was introduced to the west after Russian forces conquered the shamanistic Khanate of Kazan in 1552.\n\nThe term \"shamanism\" was first applied by Western anthropologists as outside observers of the ancient religion of the Turks and Mongols, as well as those of the neighbouring Tungusic and Samoyedic-speaking peoples. Upon observing more religious traditions across the world, some Western anthropologists began to also use the term in a very broad sense. The term was used to describe unrelated magico-religious practices found within the ethnic religions of other parts of Asia, Africa, Australasia and even completely unrelated parts of the Americas, as they believed these practices to be similar to one another.\n\nMircea Eliade writes, \"A first definition of this complex phenomenon, and perhaps the least hazardous, will be: shamanism = 'technique of religious ecstasy'.\" Shamanism encompasses the premise that shamans are intermediaries or messengers between the human world and the spirit worlds. Shamans are said to treat ailments/illness by mending the soul. Alleviating traumas affecting the soul/spirit restores the physical body of the individual to balance and wholeness. The shaman also enters supernatural realms or dimensions to obtain solutions to problems afflicting the community. Shamans may visit other worlds/dimensions to bring guidance to misguided souls and to ameliorate illnesses of the human soul caused by foreign elements. The shaman operates primarily within the spiritual world, which in turn affects the human world. The restoration of balance results in the elimination of the ailment.\n\nBeliefs and practices that have been categorised this way as \"shamanic\" have attracted the interest of scholars from a wide variety of disciplines, including anthropologists, archaeologists, historians, religious studies scholars, philosophers and psychologists. Hundreds of books and academic papers on the subject have been produced, with a peer-reviewed academic journal being devoted to the study of shamanism. In the 20th century, many Westerners involved in the counter-cultural movement have created modern magico-religious practices influenced by their ideas of indigenous religions from across the world, creating what has been termed neoshamanism or the neoshamanic movement. It has affected the development of many neopagan practices, as well as faced a backlash and accusations of cultural appropriation, exploitation and misrepresentation when outside observers have tried to represent cultures they do not belong to.\n\nThe word \"shaman\" probably originates from the Evenki word \"šamán\", most likely from the southwestern dialect spoken by the Sym Evenki peoples. The Tungusic term was subsequently adopted by Russians interacting with the indigenous peoples in Siberia. It is found in the memoirs of the exiled Russian churchman Avvakum.\n\nThe word was brought to Western Europe in the late 17th century by the Dutch traveler Nicolaes Witsen, who reported his stay and journeys among the Tungusic and Samoyedic-speaking indigenous peoples of Siberia in his book \"Noord en Oost Tataryen\" (1692). Adam Brand, a merchant from Lübeck, published in 1698 his account of a Russian embassy to China; a translation of his book, published the same year, introduced the word \"shaman\" to English speakers.\n\nThe etymology of the Evenki word is sometimes connected to a Tungus root \"ša-\" \"to know\". This has been questioned on linguistic grounds: \"The possibility cannot be completely rejected, but neither should it be accepted without reservation since the assumed derivational relationship is phonologically irregular (note especially the vowel quantities).\" Other scholars assert that the word comes directly from the Manchu language, and as such would be the only commonly used English word that is a loan from this language.\n\nHowever, Mircea Eliade noted that the Sanskrit word \"śramaṇa,\" designating a wandering monastic or holy figure, has spread to many Central Asian languages along with Buddhism and could be the ultimate origin of the Tungusic word. This proposal has been thoroughly critiqued since 1917. Ethnolinguist Juha Janhunen regards it as an \"anachronism\" and an \"impossibility\" that is nothing more than a \"far-fetched etymology.\"\n\n21st-century anthropologist and archeologist Silvia Tomaskova argues that by the mid-1600s, many Europeans applied the Arabic term \"shaitan\" (meaning \"devil\") to the non-Christian practices and beliefs of indigenous peoples beyond the Ural Mountains. She suggests that \"shaman\" may have entered the various Tungus dialects as a corruption of this term, and then been told to Christian missionaries, explorers, soldiers and colonial administrators with whom the people had increasing contact for centuries. Ethnolinguists did not develop as a discipline nor achieve contact with these communities until the late 19th century, and may have mistakenly \"read backward\" in time for the origin of this word.\n\nA (female shaman) is sometimes called a ', which is not an actual indigenous term but simply \"shaman\" plus the Russian suffix ' (for feminine nouns).\n\nThere is no single agreed-upon definition for the word \"shamanism\" among anthropologists. The English historian Ronald Hutton noted that by the dawn of the 21st century, there were four separate definitions of the term which appeared to be in use. The first of these uses the term to refer to \"anybody who contacts a spirit world while in an altered state of consciousness.\" The second definition limits the term to refer to those who contact a spirit world while in an altered state of consciousness at the behest of others. The third definition attempts to distinguish shamans from other magico-religious specialists who are believed to contact spirits, such as \"mediums\", \"witch doctors\", \"spiritual healers\" or \"prophets,\" by claiming that shamans undertake some particular technique not used by the others. Problematically, scholars advocating the third view have failed to agree on what the defining technique should be. The fourth definition identified by Hutton uses \"shamanism\" to refer to the indigenous religions of Siberia and neighboring parts of Asia. According to the Golomt Center for Shamanic Studies, a Mongolian organisation of shamans, the Evenk word \"shaman\" would more accurately be translated as \"priest\".\n\nShamans may be called through dreams or signs. However, shamanic powers may be inherited. In traditional societies shamanic training varies in length, but generally takes years.\n\nTurner and colleagues mention a phenomenon called shamanistic initiatory crisis, a rite of passage for shamans-to-be, commonly involving physical illness and/or psychological crisis. The significant role of initiatory illnesses in the calling of a shaman can be found in the detailed case history of Chuonnasuan, who was the last master shaman among the Tungus peoples in Northeast China.\n\nThe wounded healer is an archetype for a shamanic trial and journey. This process is important to the young shaman. They undergo a type of sickness that pushes them to the brink of death. This happens for two reasons:\n\nShamans claim to gain knowledge and the power to heal by entering into the spiritual world or dimension. Most shamans have dreams or visions that convey certain messages. The shaman may have or acquire many spirit guides, who often guide and direct the shaman in their travels in the spirit world. These spirit guides are always present within the shaman, although others encounter them only when the shaman is in a trance. The spirit guide energizes the shaman, enabling them to enter the spiritual dimension. The shaman heals within the spiritual dimension by returning 'lost' parts of the human soul from wherever they have gone. The shaman also cleanses excess negative energies, which confuse or pollute the soul.\n\nShamans act as mediators in their culture. The shaman communicates with the spirits on behalf of the community, including the spirits of the deceased. The shaman communicates with both living and dead to alleviate unrest, unsettled issues, and to deliver gifts to the spirits.\n\nAmong the Selkups, the sea duck is a spirit animal. Ducks fly in the air and dive in the water. Thus ducks are believed to belong to both the upper world and the world below. Among other Siberian peoples, these characteristics are attributed to water fowl in general. The upper world is the afterlife primarily associated with deceased humans and is believed to be accessed by soul journeying through a portal in the sky. The lower world or \"world below\" is the afterlife primarily associated with animals and is believed to be accessed by soul journeying through a portal in the earth. In shamanic cultures many animals are regarded as spirit animals.\n\nShamans perform a variety of functions depending upon their respective cultures; healing, leading a sacrifice, preserving the tradition by storytelling and songs, fortune-telling, and acting as a psychopomp (\"guide of souls\"). A single shaman may fulfill several of these functions.\n\nThe functions of a shaman may include either guiding to their proper abode the souls of the dead (which may be guided either one-at-a-time or in a cumulative group, depending on culture), and/or curing (healing) of ailments. The ailments may be either purely physical afflictions—such as disease, which may be cured by gifting, flattering, threatening, or wrestling the disease-spirit (sometimes trying all these, sequentially), and which may be completed by displaying a supposedly extracted token of the disease-spirit (displaying this, even if \"fraudulent\", is supposed to impress the disease-spirit that it has been, or is in the process of being, defeated, so that it will retreat and stay out of the patient's body), or else mental (including psychosomatic) afflictions—such as persistent terror (on account of a frightening experience), which may be likewise cured by similar methods. In most languages a different term other than the one translated \"shaman\" is usually applied to a religious official leading sacrificial rites (\"priest\"), or to a raconteur (\"sage\") of traditional lore; there may be more of an overlap in functions (with that of a shaman), however, in the case of an interpreter of omens or of dreams.\n\nThere are distinct types of shaman who perform more specialized functions. For example, among the Nani people, a distinct kind of shaman acts as a psychopomp. Other specialized shamans may be distinguished according to the type of spirits, or realms of the spirit world, with which the shaman most commonly interacts. These roles vary among the Nenets, Enets, and Selkup shaman.\n\nThe assistant of an Oroqen shaman (called \"jardalanin\", or \"second spirit\") knows many things about the associated beliefs. He or she accompanies the rituals and interprets the behavior of the shaman. Despite these functions, the jardalanin is \"not\" a shaman. For this interpretative assistant, it would be unwelcome to fall into trance.\n\nAmong the Tucano people, a sophisticated system exists for environmental resources management and for avoiding resource depletion through overhunting. This system is conceptualized mythologically and symbolically by the belief that breaking hunting restrictions may cause illness. As the primary teacher of tribal symbolism, the shaman may have a leading role in this ecological management, actively restricting hunting and fishing. The shaman is able to \"release\" game animals, or their souls, from their hidden abodes. The Piaroa people have ecological concerns related to shamanism. Among the Inuit, shamans fetch the souls of game from remote places, or soul travel to ask for game from mythological beings like the Sea Woman.\n\nThe way shamans get sustenance and take part in everyday life varies across cultures. In many Inuit groups, they provide services for the community and get a \"due payment\" (cultures), believe the payment is given to the helping spirits but these goods are only \"welcome addenda.\" They are not enough to enable shamanizing as a full-time activity. Shamans live like any other member of the group, as a hunter or housewife. Due to the popularity of ayahuasca tourism in South America, there are practitioners in areas frequented by backpackers who make a living from leading ceremonies.\n\nThere are many variations of shamanism throughout the world, but several common beliefs are shared by all forms of shamanism. Common beliefs identified by Eliade (1972) are the following:\n\n\nShamanism is based on the premise that the visible world is pervaded by invisible forces or spirits which affect the lives of the living. Although the causes of disease lie in the spiritual realm, inspired by malicious spirits, both spiritual and physical methods are used to heal. Commonly, a shaman \"enters the body\" of the patient to confront the spiritual infirmity and heals by banishing the infectious spirit.\n\nMany shamans have expert knowledge of medicinal plants native to their area, and an herbal treatment is often prescribed. In many places shamans learn directly from the plants, harnessing their effects and healing properties, after obtaining permission from the indwelling or patron spirits. In the Peruvian Amazon Basin, shamans and \"curanderos\" use medicine songs called \"icaros\" to evoke spirits. Before a spirit can be summoned it must teach the shaman its song. The use of totemic items such as rocks with special powers and an animating spirit is common.\n\nSuch practices are presumably very ancient. Plato wrote in his \"Phaedrus\" that the \"first prophecies were the words of an oak\", and that those who lived at that time found it rewarding enough to \"listen to an oak or a stone, so long as it was telling the truth\".\n\nBelief in witchcraft and sorcery, known as \"brujería\" in Latin America, exists in many societies. Other societies assert all shamans have the power to both cure and kill. Those with shamanic knowledge usually enjoy great power and prestige in the community, but they may also be regarded suspiciously or fearfully as potentially harmful to others.\n\nBy engaging in their work, a shaman is exposed to significant personal risk, from the spirit world, from enemy shamans, or from the means employed to alter the shaman's state of consciousness. Shamanic plant materials can be toxic or fatal if misused. Spells are commonly used to protect against these dangers, and the use of more dangerous plants is often very highly ritualized.\n\nThe variety of functions described above may seem like distinct tasks, but they may be united by underlying soul and spirit concepts.\n\n\n\n\n\n\nGenerally, the shaman traverses the axis mundi and enters the spirit world by effecting a transition of consciousness, entering into an ecstatic trance, either autohypnotically or through the use of entheogens. The methods employed are diverse, and are often used together.\n\nAn entheogen (\"generating the divine within\") is a psychoactive substance used in a religious, shamanic, or spiritual context. Entheogens have been used in a ritualized context for thousands of years; their religious significance is well established in anthropological and modern evidences. Examples of traditional entheogens include: peyote, \npsilocybin and Amanita muscaria (fly agaric) mushrooms, \nuncured tobacco, \ncannabis, \nayahuasca, \n\"Salvia divinorum\", \niboga,\nand \nMexican morning glory.\n\nSome shamans observe dietary or customary restrictions particular to their tradition. These restrictions are more than just cultural. For example, the diet followed by shamans and apprentices prior to participating in an ayahuasca ceremony includes foods rich in tryptophan (a biosynthetic precursor to serotonin) as well as avoiding foods rich in tyramine, which could induce hypertensive crisis if ingested with MAOIs such as are found in ayahuasca brews as well as abstinence from alcohol or sex.\n\nJust like shamanism itself, music and songs related to it in various cultures are diverse, far from being alike. In several instances, songs related to shamanism are intended to imitate natural sounds, via onomatopoeia.\n\nSound mimesis in various cultures may serve other functions not necessarily related to shamanism: practical goals as luring game in the hunt; or entertainment (Inuit throat singing).\n\n\nShamans may have various kinds of paraphernalia in different cultures.\n\n\nA debated etymology of the word \"shaman\" is \"one who knows\", implying, among other things, that the shaman is an expert in keeping together the multiple codes of the society, and that to be effective, shamans must maintain a comprehensive view in their mind which gives them certainty of knowledge. According to this view, the shaman uses (and the audience understands) multiple codes, expressing meanings in many ways: verbally, musically, artistically, and in dance. Meanings may be manifested in objects such as amulets. If the shaman knows the culture of his or her community well, and acts accordingly, their audience will know the used symbols and meanings and therefore trust the shamanic worker.\n\nThere are also semiotic, theoretical approaches to shamanism, and examples of \"mutually opposing symbols\" in academic studies of Siberian lore, distinguishing a \"white\" shaman who contacts sky spirits for good aims by day, from a \"black\" shaman who contacts evil spirits for bad aims by night. (Series of such opposing symbols referred to a world-view behind them. Analogously to the way grammar arranges words to express meanings and convey a world, also this formed a cognitive map). Shaman's lore is rooted in the folklore of the community, which provides a \"mythological mental map\". Juha Pentikäinen uses the concept \"grammar of mind\".\n\nArmin Geertz coined and introduced the hermeneutics, or \"ethnohermeneutics\", interpretation. Hoppál extended the term to include not only the interpretation of oral and written texts, but that of \"visual texts as well (including motions, gestures and more complex ritual, and ceremonies performed for instance by shamans)\". Revealing the animistic views in shamanism, but also their relevance to the contemporary world, where ecological problems have validated paradigms of balance and protection.\n\nDavid Lewis-Williams explains the origins of shamanic practice, and some of its precise forms, through aspects of human consciousness evinced in cave art and LSD experiments alike.\n\nGerardo Reichel-Dolmatoff relates these concepts to developments in the ways that modern science (systems theory, ecology, new approaches in anthropology and archeology) treats causality in a less linear fashion. He also suggests a cooperation of modern science and indigenous lore.\n\nShamanic practices may originate as early as the Paleolithic, predating all organized religions, and certainly as early as the Neolithic period. The earliest known undisputed burial of a shaman (and by extension the earliest undisputed evidence of shamans and shamanic practices) dates back to the early Upper Paleolithic era (c. 30,000 BP) in what is now the Czech Republic.\n\nSanskrit scholar and comparative mythologist Michael Witzel proposes that all of the world's mythologies, and also the concepts and practices of shamans, can be traced to the migrations of two prehistoric populations: the \"Gondwana\" type (of circa 65,000 years ago) and the \"Laurasian\" type (of circa 40,000 years ago).\n\nEarly anthropological studies theorize that shamanism developed as a magic practice to ensure a successful hunt or gathering of food. Evidence in caves and drawings on walls support indications that shamanism started during the Paleolithic era. One such picture featured a half-animal, with the face and legs of a man, with antlers and a tail of a stag.\n\nIn November 2008, researchers from the Hebrew University of Jerusalem announced the discovery of a 12,000-year-old site in Israel that is perceived as one of the earliest known shaman burials. The elderly woman had been arranged on her side, with her legs apart and folded inward at the knee. Ten large stones were placed on the head, pelvis and arms. Among her unusual grave goods were 50 complete tortoise shells, a human foot, and certain body parts from animals such as a cow tail and eagle wings. Other animal remains came from a boar, leopard, and two martens. \"It seems that the woman … was perceived as being in a close relationship with these animal spirits\", researchers noted. The grave was one of at least 28 graves at the site, located in a cave in lower Galilee and belonging to the Natufian culture, but is said to be unlike any other among the Epipaleolithic Natufians or in the Paleolithic period.\n\nShamanism is believed to be declining around the world, possibly due to other organised religious influences, like Christianity, that want people who practice shamanism to convert to their own system and doctrine. Another reason is western views of shamanism as 'primitive', 'superstitious', backward and outdated. Whalers who frequently interact with Inuit tribes are one source of this decline in that region.\n\nIn many areas, former shamans ceased to fulfill the functions in the community they used to, as they felt mocked by their own community, or regarded their own past as deprecated and are unwilling to talk about it to an ethnographer.\n\nMoreover, besides personal communications of former shamans, folklore texts may narrate directly about a deterioration process. For example, a Buryat epic text details the wonderful deeds of the ancient \"first shaman\" Kara-Gürgän: he could even compete with God, create life, steal back the soul of the sick from God without his consent. A subsequent text laments that shamans of older times were stronger, possessing capabilities like omnividence, fortune-telling even for decades in the future, moving as fast as a bullet.\n\nIn most affected areas, shamanic practices ceased to exist, with authentic shamans dying and their personal experiences dying with them. The loss of memories is not always lessened by the fact the shaman is not always the only person in a community who knows the beliefs and motives related to the local shaman-hood (laics know myths as well, among Barasana, even though less; there are former shaman apprentices unable to complete the learning among Greenlandic Inuit peoples, moreover, even laics can have trance-like experiences among the Inuit; the assistant of a shaman can be extremely knowledgeable among Dagara). Although the shaman is often believed and trusted precisely because s/he \"accommodates\" to the \"grammar\" of the beliefs of the community, several parts of the knowledge related to the local shamanhood consist of personal experiences of the shaman (illness), or root in his/her family life (the interpretation of the symbolics of his/her drum), thus, those are lost with his/her death. Besides that, in many cultures, the entire traditional belief system has become endangered (often together with a partial or total language shift), the other people of the community remembering the associated beliefs and practices (or the language at all) grew old or died, many folklore memories (songs, texts) were forgotten – which may threaten even such peoples who could preserve their isolation until the middle of the 20th century, like the Nganasan.\n\nSome areas could enjoy a prolonged resistance due to their remoteness.\n\nAfter exemplifying the general decline even in the most remote areas, it should be noted that there are revitalization or tradition-preserving efforts as a response. Besides collecting the memories, there are also tradition-preserving and even revitalization efforts, led by authentic former shamans (for example among Sakha people and Tuvans). However, according to Richard L. Allen, research & policy analyst for the Cherokee Nation, they are overwhelmed with fraudulent shamans (\"plastic medicine people\"). \"One may assume that anyone claiming to be a Cherokee 'shaman, spiritual healer, or pipe-carrier', is equivalent to a modern day medicine show and snake-oil vendor.\" One indicator of a plastic shaman might be someone who discusses \"Native American spirituality\" but does not mention any specific Native American tribe. The \"New Age Frauds and Plastic Shamans\" website discusses potentially plastic shamans.\n\nBesides tradition-preserving efforts, there are also neoshamanistic movements, these may differ from many traditional shamanistic practice and beliefs in several points. Admittedly, several traditional beliefs systems indeed have ecological considerations (for example, many Inuit peoples), and among Tukano people, the shaman indeed has direct resource-protecting roles, see details in section Ecological aspect.\n\nToday, shamanism survives primarily among indigenous peoples. Shamanic practices continue today in the tundras, jungles, deserts, and other rural areas, and even in cities, towns, suburbs, and shantytowns all over the world. This is especially true for Africa and South America, where \"mestizo shamanism\" is widespread.\n\nShamanism is part of the Vietnamese religion of Đạo Mẫu. In Vietnam, this ritual practice is called Lên đồng or also known as \"hầu bóng\", or \"hầu đồng\", sessions involve a number of artistic elements, such as music, singing, dance and the use of costumes. \n\nThe Hmong people, as an ancient people of China with a 5,000-year history, continue to maintain and practice its form of shamanism known as Ua Neeb in mainland Asia. At the end of the Vietnam War, some 300,000 Hmong have been settled across the globe. They have continued to practice Ua Neeb in various countries in North and South America, Europe and Australia. In the U.S., the Hmong shaman practitioner is known as \"Txiv Neeb\" has been licensed by many hospitals in California as being part of the medical health team to treat patients in hospital. This revival of Ua Neeb in the West has been brought great success and has been hailed in the media as \"doctor for the disease, shaman for the soul\".\n\nBeing a Hmong shaman represents a true vocation, chosen by the shaman God, Sivyis.\nThe shaman's main job is to bring harmony to the individual, their family, and their community within their environment by performing various rituals (usually through trance).\n\nAnimal sacrifice has been part of the Hmong shamanic practice for the past 5,000 years. Contrary to the belief of many Westerners, the Hmong practice of using animals in shamanic practice is performed with great respect. After the Vietnam War, over 200,000 Hmong were resettled in the United States and shamanism is still part of the Hmong culture. Due the colliding of culture and the law, as Professor Alison Dundes Renteln, a political science professor at the University of Southern California and author of \"The Cultural Defense\", a book that examines the influence of such cases on U.S. courts, once said, \"We say that as a society we welcome diversity, and in fact that we embrace it ... In practice, it's not that easy\".\n\nThe Hmong believe that all things on Earth have a soul (or multiple souls), and those souls are treated as equal and can be considered interchangeable. When a person is sick due to his soul being lost, or captured by wild spirit, it is necessary to ask for and receive permission of that animal, whether it is a chicken, pig, dog, goat or any other animals required, to use its soul for an exchange with the afflicted person's soul for a period of 12 months. At the end of that period, during the Hmong New Year, the shaman would perform a special ritual to release the soul of that animal and send it off to the world beyond. As part of his service to mankind, the animal soul is sent off to be reincarnated into a higher form of animal, or even to become a member of a god's family (ua Fuab Tais Ntuj tus tub, tus ntxhais) to live a life of luxury, free of the suffering as an animal. Hence, being asked to perform this duty (what is known in the West as \"animal sacrifice\") is one of the greatest honors for that animal, to be able to serve mankind. The Hmong of southeast Guizhou will cover the rooster with a piece of red cloth and then hold it up to worship and sacrifice to the Heaven and the Earth before the Sacred cockfight. In a 2010 trial of a Sheboygan Wisconsin Hmong who was charged with staging a cockfight, it was stated that the roosters were \"kept for both food and religious purposes\", and the case was followed by an acquittal.\n\nIn addition to the spiritual dimension, Hmong shaman attempt to treat many physical illnesses through use of the text of sacred words (khawv koob).\n\nThroughout the villages and towns of Indonesia, local healers known as dukun practice diverse activities from massage, bonesetting, midwivery, herbal medicine, spirit mediumship and divination.\n\nShamanism is part of the indigenous Ainu religion and Japanese religion of Shinto, although Shinto is distinct in that it is shamanism for an agricultural society. Since the early middle-ages Shinto has been influenced by and syncretized with Buddhism and other elements of continental East Asian culture. The book \"Occult Japan: Shinto, Shamanism and the Way of the Gods\" by Percival Lowell delves further into researching Japanese shamanism or Shintoism. The book \"Japan Through the Looking Glass: Shaman to Shinto\" uncovers the extraordinary aspects of Japanese beliefs.\n\nShamanism is still practiced in North and South Korea. In the south, shaman women are known as \"mudangs\", while male shamans are referred to as \"baksoo mudangs\".\n\nA person can become a shaman through hereditary title or through natural ability. Shamans are consulted in contemporary society for financial and marital decisions.\n\nShamanism were also practiced among the Malay community in Malay Peninsula and indigenous people in Sabah and Sarawak. People who practice shamanism in the country are generally called as \"bomoh\" or \"pawang\" in the Peninsula. In Sabah, the Bobohizan is the main shaman among the Kadazan-Dusun indigenous community.\n\nMongolian classics, such as \"The Secret History of the Mongols\", provide details about male and female shamans serving as exorcists, healers, rainmakers, oneiromancers, soothsayers, and officials. Shamanic practices continue in present-day Mongolian culture.\n\nThe spiritual hierarchy in clan-based Mongolian society was complex. The highest group consisted of 99 \"tngri\" (55 of them benevolent or \"white\" and 44 terrifying or \"black\"), 77 \"natigai\" or \"earth-mothers\", besides others. The \"tngri\" were called upon only by leaders and great shamans and were common to all the clans. After these, three groups of ancestral spirits dominated. The \"Lord-Spirits\" were the souls of clan leaders to whom any member of a clan could appeal for physical or spiritual help. The \"Protector-Spirits\" included the souls of great shamans (\"ĵigari\") and shamanesses (\"abĵiya\"). The \"Guardian-Spirits\" were made up of the souls of smaller shamans (\"böge\") and shamanesses (\"idugan\") and were associated with a specific locality (including mountains, rivers, etc.) in the clan's territory.\n\nIn the 1990s, a form of Mongolian neo-shamanism was created which has given a more modern approach to shamanism. Among the Buryat Mongols, who live in Mongolia and Russia, the proliferation of shamans since 1990 is a core aspect of a larger struggle for the Buryats to reestablish their historical and genetic roots, as has been documented extensively by Ippei Shimamura, an anthropologist at the University of Shiga Prefecture in Japan. Some Mongolian shamans are now making a business out of their profession and even have offices in the larger towns. At these businesses, a shaman generally heads the organization and performs services such as healing, fortunetelling, and solving all kinds of problems. Although the initial enthusiasm for the revival of Mongol shamanism in the post-communist/post-1990 era led to an openness to all interested visitors, the situation has changed among those Mongols seeking to protect the essential ethnic or national basis of their practices. In recent years many associations of Mongol shamans have become wary of Western \"core\" or \"neo\" or \"New Age\" shamans and have restricted access to only to Mongols and Western scholars. One such event, organized by Jargalsaichan, the head of the Corporate Union of Mongolian Shamans, was the 21 June 2017 Ulaan Tergel (summer solstice) celebration held near midnight on the steppes about 20 km outside Ulaanbaatar. Although a private event, two Western psychologist scholars of shamanism, Richard Noll and Leonard George were allowed to observe, photograph and post video of the event to YouTube.\n\nShamans were highly respected members of the community in the ancient animistic religions of the Philippines. They were generally known as \"babaylan\" or \"baylan\". In most Filipino ethnic groups, the shamans were almost always women. The few men who gain shaman status were usually \"asog\" or \"bayok\", men who dressed as women and lived as women. They usually acquire their role either by inheriting it from an older shaman or after surviving a serious illness or a bout of insanity. Regardless of the method, full-fledged shamans are those who have acquired spirit familiars who serve as their guides into the spirit world.\n\nThe main role of shamans were as spirit mediums. Through the use of their familiars and various rituals, they allow their bodies to be possessed by spirits (\"anito\"), thus facilitating communication between the spirit world and the material world. There were different ranks and specializations of shamans among different Filipino ethnic groups. Some specialized in healing, others in prophecy, others in creating charms and spells, and so on. The most powerful were usually believed to be sorcerers capable of controlling elemental spirits.\n\nShamanistic practices in the Philippines were largely abandoned when the islands were converted to Christianity and Islam. Though there are still traces of it among modern folk healers and in isolated tribes.\n\nSiberia is regarded as the \"locus classicus\" of shamanism. The area is inhabited by many different ethnic groups, and many of its peoples observe shamanistic practices, even in modern times. Many classical ethnographic sources of \"shamanism\" were recorded among Siberian peoples.\n\nManchu Shamanism is one of very few Shamanist traditions which held official status into the modern era, by becoming one of the imperial cults of the Qing dynasty of China (alongside Buddhism, Taoism and traditional Heaven worship). The Palace of Earthly Tranquility, one of the principal halls of the Forbidden City in Beijing, was partly dedicated to Shamanistic rituals. The ritual set-up is still preserved \"in situ\" today.\n\nAmong the Siberian Chukchis peoples, a shaman is interpreted as someone who is possessed by a spirit, who demands that someone assume the shamanic role for their people. Among the Buryat, there is a ritual known as \"shanar\" whereby a candidate is consecrated as shaman by another, already-established shaman.\n\nAmong several Samoyedic peoples, shamanism was a living tradition also in modern times, especially at groups living in isolation, until recent times (Nganasans). The last notable Nganasan shaman's seances could be recorded on film in the 1970s.\n\nWhen the People's Republic of China was formed in 1949 and the border with Russian Siberia was formally sealed, many nomadic Tungus groups (including the Evenki) that practiced shamanism were confined in Manchuria and Inner Mongolia. The last shaman of the Oroqen, Chuonnasuan (Meng Jinfu), died in October 2000.\n\nIn many other cases, shamanism was in decline even at the beginning of the 20th century, for instance, among the Roma.\n\nGeographical factors heavily influence the character and development of the religion, myths, rituals and epics of Central Asia. While in other parts of the world, religious rituals are primarily used to promote agricultural prosperity, here they were used to ensure success in hunting and breeding livestock. Animals are one of the most important elements of indigenous religion in Central Asia because of the role they play in the survival of the nomadic civilizations of the steppes as well as sedentary populations living on land not conducive to agriculture. Shamans wore animal skins and feathers and underwent transformations into animals during spiritual journeys. In addition, animals served as humans' guides, rescuers, ancestors, totems and sacrificial victims. As a religion of nature, shamanism throughout Central Asia held particular reverence for the relations between sky, earth and water and believed in the mystical importance of trees and mountains. Shamanism in Central Asia also places a strong emphasis on the opposition between summer and winter, corresponding to the huge differences in temperature common in the region. The harsh conditions and poverty caused by the extreme temperatures drove Central Asian nomads throughout history to pursue militaristic goals against their sedentary neighbors. This military background can be seen in the reverence for horses and warriors within many indigenous religions.\n\nCentral Asian shamans served as sacred intermediaries between the human and spirit world. In this role they took on tasks such as healing, divination, appealing to ancestors, manipulating the elements, leading lost souls and officiating public religious rituals. The shamanic séance served as a public display of the shaman's journey to the spirit world and usually involved intense trances, drumming, dancing, chanting, elaborate costumes, miraculous displays of physical strength, and audience involvement. The goal of these séances ranged from recovering the lost soul of a sick patient and divining the future to controlling the weather and finding a lost person or thing. The use of sleight-of-hand tricks, ventriloquism, and hypnosis were common in these rituals but did not explain the more impressive feats and actual cures accomplished by shamans.\n\nShamans perform in a \"state of ecstasy\" deliberately induced by an effort of will. Reaching this altered state of consciousness required great mental exertion, concentration and strict self-discipline. Mental and physical preparation included long periods of silent meditation, fasting, and smoking. In this state, skilled shamans employ capabilities that the human organism cannot accomplish in the ordinary state. Shamans in ecstasy displayed unusual physical strength, the ability to withstand extreme temperatures, the bearing of stabbing and cutting without pain, and the heightened receptivity of the sense organs. Shamans made use of intoxicating substances and hallucinogens, especially mukhomor mushrooms and alcohol, as a means of hastening the attainment of ecstasy.\n\nThe use of purification by fire is an important element of the shamanic tradition dating back as early as the 6th century. People and things connected with the dead had to be purified by passing between fires. These purifications were complex exorcisms while others simply involved the act of literally walking between two fires while being blessed by the shaman. Shamans in literature and practice were also responsible for using special stones to manipulate weather. Rituals are performed with these stones to attract rain or repel snow, cold or wind. This \"rain-stone\" was used for many occasions including bringing an end to drought as well as producing hailstorms as a means of warfare.\nDespite distinctions between various types of shamans and specific traditions, there is a uniformity throughout the region manifested in the personal beliefs, objectives, rituals, symbols and the appearance of shamans.\n\nThe shamanic ceremony is both a religious ceremony and an artistic performance. The fundamental purpose of the dramatic displays seen during shamanic ceremonies is not to draw attention or to create a spectacle for the audience as many Westerners have come to believe, but to lead the tribe in a solemn ritualistic process.\n\nIn general, all performances consist of four elements: dance, music, poetry and dramatic or mimetic action. The use of these elements serves the purpose of outwardly expressing his mystical communion with nature and the spirits for the rest of the tribe. The true shaman can make the journey to the spirit world at any time and any place, but shamanic ceremonies provide a way for the rest of the tribe to share in this religious experience. The shaman changes his voice mimetically to represent different persons, gods, and animals while his music and dance change to show his progress in the spirit world and his different spiritual interactions. Many shamans practice ventriloquism and make use of their ability to accurately imitate the sounds of animals, nature, humans and other noises in order to provide the audience with the ambiance of the journey. Elaborate dances and recitations of songs and poetry are used to make the shamans spiritual adventures into a matter of living reality to his audience.\n\nThe shaman's attire varies throughout the region but his chief accessories are his coat, cap, and tambourine or drum. The transformation into an animal is an important aspect of the journey into the spirit world undertaken during shamanic rituals so the coat is often decorated with birds feathers and representations of animals, coloured handkerchiefs, bells and metal ornaments. The cap is usually made from the skin of a bird with the feathers and sometimes head, still attached.\n\nThe drum or tambourine is the essential means of communicating with spirits and enabling the shaman to reach altered states of consciousness on his journey. The drum, representing the universe in epitome, is often divided into equal halves to represent the earth and lower realms. Symbols and natural objects are added to the drum representing natural forces and heavenly bodies.\n\nIn Soviet Central Asia, the Soviet government persecuted and denounced shamans as practitioners of fraudulent medicine and perpetuators of outdated religious beliefs in the new age of science and logic. The radical transformations occurring after the October Socialist Revolution led to a sharp decrease in the activity of shamans. Shamans represented an important component in the traditional culture of Central Asians and because of their important role in society, Soviet organizations and campaigns targeted shamans in their attempt to eradicate traditional influences in the lives of the indigenous peoples. Along with persecution under the tsarist and Soviet regimes, the spread of Christianity and Islam had a role in the disintegration of native faith throughout central Asia. Poverty, political instability and foreign influence are also detrimental to a religion that requires publicity and patronage to flourish.\nBy the 1980s most shamans were discredited in the eyes of their people by Soviet officials and physicians.\n\n\"Jhakri\" is the common name used for shamans in Sikkim, India and Nepal. They exist in the Limbu, Sunuwar, Rai, Sherpa, Kami, Tamang, Gurung and Lepcha communities. They are inflluenced by Hinduism, Tibetan Buddhism, Mun and Bön rites.\n\nShamanism is still widely practiced in the Ryukyu Islands (Okinawa, Japan), where shamans are known as 'Noro' (all women) and 'Yuta'. 'Noro' generally administer public or communal ceremonies while 'Yuta' focus on civil and private matters. Shamanism is also practiced in a few rural areas in Japan proper. It is commonly believed that the Shinto religion is the result of the transformation of a shamanistic tradition into a religion.\nForms of practice vary somewhat in the several Ryukyu islands, so that there is, for example, a distinct Miyako shamanism.\n\nShamanism practices seem to have been preserved in the Catholic religious traditions of aborigines in Taiwan.\n\nIn Vietnam, shamans conduct rituals in many of the religious traditions that co-mingle in the majority and minority populations. In their rituals, music, dance, special garments and offerings are part of the performance that surround the spirit journey.\n\nSome of the prehistoric peoples who once lived in Siberia have dispersed and migrated into other regions, bringing aspects of their cultures with them. For example, many Uralic peoples live now outside Siberia, however the original location of the Proto-Uralic peoples (and its extent) is debated. Combined phytogeographical and linguistic considerations (distribution of various tree species and the presence of their names in various Uralic languages) suggest that this area was north of Central Ural Mountains and on lower and middle parts of Ob River. The ancestors of Hungarian people or Magyars have wandered from their ancestral proto-Uralic area to the Pannonian Basin. Shamanism has played an important role in Turko-Mongol mythology: Tengriism - the major ancient belief among Xiongnu, Mongol and Turkic peoples, Magyars and Bulgars - incorporates elements of shamanism. Shamanism is no more a living practice among Hungarians, but remnants have been reserved as fragments of folklore, in folktales, customs.\n\nSome historians of the Late Middle Ages and Early Modern period have argued that traces of shamanistic traditions can be seen in the popular folk belief of this period. Most prominent among these was the Italian Carlo Ginzburg, who claimed shamanistic elements in the \"benandanti\" custom of 16th century Italy, the Hungarian Éva Pócs, who identified them in the \"táltos\" tradition of Hungary, and the Frenchman Claude Lecouteux, who has argued that Medieval traditions regarding the soul are based on earlier shamanic ideas. Ginzburg in particular has argued that some of these traditions influenced the conception of witchcraft in Christendom, in particular ideas regarding the witches' sabbath, leading to the events of the witch trials in the Early Modern period. Some of these Italian traditions survived into the 20th and early 21st centuries, allowing Italian-American sociologist Sabina Magliocco to make a brief study of them (2009).\n\nEskimo groups inhabit a huge area stretching from Eastern Siberia through Alaska and Northern Canada (including Labrador Peninsula) to Greenland. Shamanistic practice and beliefs have been recorded at several parts of this vast area crosscutting continental borders.\nWhen speaking of \"shamanism\" in various Eskimo groups, we must remember that (as mentioned above) the term \"shamanism\" can cover certain characteristics of \"various\" different cultures. Mediation is regarded often as an important aspect of shamanism in general. Also in most Eskimo groups, the role of mediator is known well: the person filling it in is actually believed to be able to contact the beings who populate the belief system. Term \"shaman\" is used in several English-language publications also in relation to Eskimos. Also the \"alignalghi\" () of the Asian Eskimos is translated as \"shaman\" in the Russian and English literature.\n\nThe belief system assumes specific links between the living people, the souls of hunted animals, and those of dead people. The soul concepts of several groups are specific examples of soul dualism (showing variability in details in the various cultures).\n\nUnlike the majority of shamanisms the careers of most Eskimo shamans lack the motivation of \"force\": becoming a shaman is usually a result of deliberate consideration, not a necessity forced by the spirits.\n\nAnother possible concern: do the belief systems of various Eskimo groups have such common features at all, that would justify any mentioning them together? There was no political structure above the groups, their languages were relative, but differed more or less, often forming language continuums.\n\nThere are similarities in the cultures of the Eskimo groups together with diversity, far from homogeneity.\n\nThe Russian linguist Menovshikov (Меновщиков), an expert of Siberian Yupik and Sireniki Eskimo languages (while admitting that he is not a specialist in ethnology) mentions, that the shamanistic seances of those Siberian Yupik and Sireniki groups he has seen have many similarities to those of Greenland Inuit groups described by Fridtjof Nansen, although a large distance separates Siberia and Greenland. There may be certain similarities also in Asiatic groups with North American ones. Also the usage of a specific shaman's language is documented among several Eskimo groups, used mostly for talking to spirits. Also the Ungazighmiit (belonging to Siberian Yupiks) had a special allegoric usage of some expressions.\n\nThe local cultures showed great diversity. The myths concerning the role of shaman had several variants, and also the name of their protagonists varied from culture to culture. For example, a mythological figure, usually referred to in the literature by the collective term Sea Woman, has factually many local names: Nerrivik \"meat dish\" among Polar Inuit, Nuliayuk \"lubricous\" among Netsilingmiut, Sedna \"the nether one\" among Baffin Land Inuit. Also the soul conceptions, e.g. the details of the soul dualism showed great variability, ranging from guardianship to a kind of reincarnation. Conceptions of spirits or other beings had also many variants (see e.g. the tupilaq concept).\n\nNative American and First Nations cultures have diverse religious beliefs and there was never one universal Native American religion or spiritual system. Although many Native American cultures have traditional healers, ritualists, singers, mystics, lore-keepers and Medicine people, none of them ever used, or use, the term \"shaman\" to describe these religious leaders. Rather, like other indigenous cultures the world over, their spiritual functionaries are described by words in their own languages, and in many cases are not taught to outsiders.\n\nMany of these indigenous religions have been grossly misrepresented by outside observers and anthropologists, even to the extent of superficial or seriously mistaken anthropological accounts being taken as more authentic than the accounts of actual members of the cultures and religions in question. Often these accounts suffer from \"Noble Savage\"-type romanticism and racism. Some contribute to the fallacy that Native American cultures and religions are something that only existed in the past, and which can be mined for data despite the opinions of Native communities.\n\nNot all Indigenous communities have roles for specific individuals who mediate with the spirit world on behalf of the community. Among those that do have this sort of religious structure, spiritual methods and beliefs may have some commonalities, though many of these commonalities are due to some nations being closely related, from the same region, or through post-Colonial governmental policies leading to the combining of formerly independent nations on reservations. This can sometimes lead to the impression that there is more unity among belief systems than there was in antiquity.\n\nWith the arrival of European settlers and colonial administration, the practice of Native American traditional beliefs was discouraged and Christianity was imposed upon the indigenous people. In most communities, the traditions were not completely eradicated, but rather went underground, and were practiced secretly until the prohibitive laws were repealed.\n\nUp until and during the last hundred years, thousands of Native American and First Nations children from many different communities were sent into the Canadian Indian residential school system, and Indian boarding schools in an effort to destroy tribal languages, cultures and beliefs. The Trail of Tears, in the US, forced Native Americans to relocate from their traditional homes. Canadian laws enacted in 1982, and henceforth, have attempted to reverse previous attempts at extinguishing Native culture.\n\n\nIn the Peruvian Amazon basin and north coastal regions of the country, the healers are known as curanderos. \"Ayahuasqueros\" are Peruvians who specialize in the use of ayahuasca. \"Ayahuasqueros\" have become popular among Western spiritual seekers, who claim that the \"ayauasqueros\" and their ayahuasca brews have cured them of everything from depression to addiction to cancer.\n\nIn addition to \"curanderos\" use of ayahuasca and their ritualized ingestion of mescaline-bearing San Pedro cactuses (\"Trichocereus pachanoi\") for the divination and diagnosis of sorcery, north-coastal shamans are famous throughout the region for their intricately complex and symbolically dense healing altars called mesas (tables). Sharon (1993) has argued that the mesas symbolize the dualistic ideology underpinning the practice and experience of north-coastal shamanism. For Sharon, the mesas are the, \"physical embodiment of the supernatural opposition between benevolent and malevolent energies\" (Dean 1998: 61).\n\nIn several tribes living in the Amazon rainforest, the spiritual leaders also act as managers of scarce ecological resources The rich symbolism in Tukano culture has been documented in field works even in the last decades of the 20th century.\n\nThe \"yaskomo\" of the Waiwai is believed to be able to perform a soul flight. The soul flight can serve several functions:\nThus, a yaskomo is believed to be able to reach sky, earth, and water.\n\nAmong the Mapuche people of Chile, \"Machi\" is usually a woman who serves the community by performing ceremonies to cure diseases, ward off evil, influence the weather and harvest, and by practicing other forms of healing such as herbalism.\n\nFor the Aymara people of South America the Yatiri is a healer who heals the body and the soul, they serve the community and do the rituals for Pachamama.\n\nPart of the healing power attributed to shamanic practices depends of the use of plant alkaloids taken during the therapeutic sessions .\n\nAlthough Fuegians (the indigenous peoples of Tierra del Fuego) were all hunter-gatherers, they did not share a common culture. The material culture was not homogenous, either: the big island and the archipelago made two different adaptations possible. Some of the cultures were coast-dwelling, others were land-oriented.\n\nBoth Selk'nam and Yámana had persons filling in shaman-like roles.\nThe Selk'nams believed their s to have supernatural capabilities, e.g. to control weather. The figure of appeared in myths, too. The Yámana corresponds to the Selknam .\n\nOn the island of Papua New Guinea, indigenous tribes believe that illness and calamity are caused by dark spirits, or \"masalai\", which cling to a person's body and poison them. Shamans are summoned in order to purge the unwholesome spirits from a person. Shamans also perform rainmaking ceremonies and can allegedly improve a hunter's ability to catch animals.\n\nIn Australia various aboriginal groups refer to their shamans as \"clever men\" and \"clever women\" also as \"kadji\". These aboriginal shamans use \"maban\" or \"mabain\", the material that is believed to give them their purported magical powers. Besides healing, contact with spiritual beings, involvement in initiation and other secret ceremonies, they are also enforcers of tribal laws, keepers of special knowledge and may \"hex\" to death one who breaks a social taboo by singing a song only known to the \"clever men\".\n\nIn Mali, Dogon sorcerers (both male and female) communicate with a spirit named Amma, who advises them on healing and divination practices.\n\nThe classical meaning of shaman as a person who, after recovering from a mental illness (or insanity) takes up the professional calling of socially recognized religious practitioner, is exemplified among the Sisala (of northern Gold Coast) : \"the fairies \"seized\" him and made him insane for several months. Eventually, though, he learned to control their power, which he now uses to divine.\"\n\nThe term \"sangoma\", as employed in Zulu and congeneric languages, is effectively equivalent to shaman. Sangomas are highly revered and respected in their society, where illness is thought to be caused by witchcraft, pollution (contact with impure objects or occurrences), bad spirits, or the ancestors themselves, either malevolently, or through neglect if they are not respected, or to show an individual her calling to become a sangoma (\"thwasa\"). For harmony between the living and the dead, vital for a trouble-free life, the ancestors must be shown respect through ritual and animal sacrifice.\n\nThe term \"inyanga\" also employed by the Nguni cultures is equivalent to 'herbalist' as used by the Zulu people and a variation used by the Karanga, among whom remedies (locally known as muti) for ailments are discovered by the inyanga being informed in a dream, of the herb able to effect the cure and also of where that herb is to be found. The majority of the herbal knowledge base is passed down from one \"inyanga\" to the next, often within a particular family circle in any one village.\n\nShamanism is known among the Nuba of Kordofan in Sudan.\n\nThere is an endeavor in some contemporary occult and esoteric circles to reinvent shamanism in a modern form, often drawing from core shamanism—a set of beliefs and practices synthesized by Michael Harner—centered on the use of ritual drumming and dance, and Harner's interpretations of various indigenous religions. Harner has faced criticism for taking pieces of diverse religions out of their cultural contexts and synthesising a set of universal shamanic techniques. Some neoshamans focus on the ritual use of entheogens, and also embrace the philosophies of chaos magic while others (such as Jan Fries) have created their own forms of shamanism.\n\nEuropean-based neoshamanic traditions are focused upon the researched or imagined traditions of ancient Europe, where many mystical practices and belief systems were suppressed by the Christian church. Some of these practitioners express a desire to practice a system that is based upon their own ancestral traditions. Some anthropologists and practitioners have discussed the impact of such neoshamanism as \"giving extra pay\" (Harvey, 1997 and elsewhere) to indigenous American traditions, particularly as many pagan or heathen shamanic practitioners do not call themselves shamans, but instead use specific names derived from the European traditions—they work within such as \"völva\" or \"seidkona\" (seid-woman) of the sagas (see Blain 2002, Wallis 2003).\n\nMany spiritual seekers travel to Peru to work with \"ayahuasqueros\", shamans who engage in the ritual use of ayahuasca, a psychedelic tea which has been documented to cure everything from depression to addiction. When taking ayahuasca, participants frequently report meeting spirits, and receiving divine revelations. Shamanistic techniques have also been used in New Age therapies which use enactment and association with other realities as an intervention.\n\nThe anthropologist Alice Kehoe criticizes the term \"shaman\" in her book \"Shamans and Religion: An Anthropological Exploration in Critical Thinking\". Part of this criticism involves the notion of cultural appropriation. This includes criticism of New Age and modern Western forms of shamanism, which, according to Kehoe, misrepresent or dilute indigenous practices. Alice Kehoe also believes that the term reinforces racist ideas such as the Noble Savage.\n\nKehoe is highly critical of Mircea Eliade's work on shamanism as an invention synthesized from various sources unsupported by more direct research. To Kehoe, citing that ritualistic practices (most notably drumming, trance, chanting, entheogens and hallucinogens, spirit communication and healing) as being definitive of shamanism is poor practice. Such citations ignore the fact that those practices exist outside of what is defined as shamanism and play similar roles even in non-shamanic cultures (such as the role of chanting in Judeo-Christian and Islamic rituals) and that in their expression are unique to each culture that uses them. Such practices cannot be generalized easily, accurately, or usefully into a global religion of shamanism. Because of this, Kehoe is also highly critical of the hypothesis that shamanism is an ancient, unchanged, and surviving religion from the Paleolithic period.\n\nAnthropologist Mihály Hoppál also discusses whether the term \"shamanism\" is appropriate. He notes that for many readers, \"-ism\" implies a particular dogma, like Buddhism or Judaism. He recommends using the term \"shamanhood\" or \"shamanship\" (a term used in old Russian and German ethnographic reports at the beginning of the 20th century) for stressing the diversity and the specific features of the discussed cultures. He believes that this places more stress on the local variations and emphasizes that shamanism is not a religion of sacred dogmas, but linked to the everyday life in a practical way. Following similar thoughts, he also conjectures a contemporary paradigm shift. Piers Vitebsky also mentions that, despite really astonishing similarities, there is no unity in shamanism. The various, fragmented shamanistic practices and beliefs coexist with other beliefs everywhere. There is no record of pure shamanistic societies (although, as for the past, their existence is not impossible). Norwegian social anthropologist Hakan Rydving has likewise argued for the abandonment of the terms \"shaman\" and \"shamanism\" as \"scientific illusions.\"\n\nDulam Bumochir has affirmed the above critiques of \"shamanism\" as a Western construct created for comparative purposes and, in an extensive article, has documented the role of Mongols themselves, particularly \"the partnership of scholars and shamans in the reconstruction of shamanism\" in post-1990/post-communist Mongolia. This process has also been documented by Swiss anthropologist Judith Hangartner in her landmark study of Darhad shamans in Mongolia. Historian Karena Kollmar-Polenz argues that the social construction and reification of shamanism as a religious \"other\" actually began with the 18th century writings of Tibetan Buddhist monks in Mongolia and later \"probably influenced the formation of European discourse on Shamanism\".\n\n\n"}
{"id": "6390798", "url": "https://en.wikipedia.org/wiki?curid=6390798", "title": "Synthetic vaccine", "text": "Synthetic vaccine\n\nA synthetic vaccine is a vaccine consisting mainly of synthetic peptides, carbohydrates, or antigens. They are usually considered to be safer than vaccines from bacterial cultures. Creating vaccines synthetically has the ability to increase the speed of production. This is especially important in the event of a pandemic.\n\nThe world's first synthetic vaccine was created in 1982 from diphtheria toxin by Louis Chedid (scientist) from the Pasteur Institute and Michael Sela from the Weizmann Institute.\n\nIn 1986, Manuel Elkin Patarroyo created the SPf66, the first version of a synthetic vaccine for Malaria.\n\nDuring the H1N1 outbreak in 2009, vaccines only became available in large quantities after the peak of human infections. This was a learning experience for vaccination companies. Novartis Vaccine and Diagnostics, among other companies, developed a synthetic approach that very rapidly generates vaccine viruses from sequence data in order to be able to administer vaccinations early in the pandemic outbreak. Philip Dormatizer, the leader of viral vaccine research at Novartis, says they have \"developed a way of chemically synthesizing virus genomes and growing them in tissue culture cells\".\n\nPhase I data of UB-311, a synthetic peptide vaccine targeting amyloid beta, showed that the drug was able to generate antibodies to specific amyloid beta oligomers and fibrils with no decrease in antibody levels in patients of advanced age. Results from the Phase II trial are expected in the second half of 2018.\n\n"}
{"id": "29097249", "url": "https://en.wikipedia.org/wiki?curid=29097249", "title": "Torture (journal)", "text": "Torture (journal)\n\nTorture: Journal on Rehabilitation of Torture Victims and Prevention of Torture is a peer-reviewed medical journal on rehabilitation of torture victims and prevention of torture, published triannually by the International Rehabilitation Council for Torture Victims\n\nThe journal is abstracted and indexed in MEDLINE/PubMed. It was established in 1991 as \"Torture: Quarterly Journal on Rehabilitation of Torture Victims and Prevention of Torture\" and obtained its current title in 2004.\n"}
{"id": "24498121", "url": "https://en.wikipedia.org/wiki?curid=24498121", "title": "Van Ingen &amp; Van Ingen", "text": "Van Ingen &amp; Van Ingen\n\nVan Ingen & Van Ingen, simply Van Ingen, or Van Ingen of Mysore (1900–1999) were Indian taxidermists located in Mysore, South India, best known for their tiger and leopard taxidermy trophy mounts. \"A History of Taxidermy. Art, science and bad taste\" (Morris, 2006) states that Van Ingen factory processed more than 43,000 tiger and leopard trophies in less than 90 years of operation. Van Ingen & Van Ingen taxidermy today are still found throughout the world in the form of head mounts, full mounts, flat animal rugs, and rug mounts with heads attached. \n\nThe Van Ingen & Van Ingen firm was established by Eugene Van Ingen in the 1890s. His sons later ran the business until it closed in 1999.\n\nVan Ingen & Van Ingen served the highest in international nobility as well as the Maharajas of India, preserving their \"shikar\" hunting trophies in the most lifelike poses and in the utmost beauty, with attention to detail like no other in their time of operation.\n\nVan Ingen & Van Ingen's work was synonymous with quality and fine workmanship, constructing moulds, mannikins, glass eyes, tongues, teeth and even whiskers for jobs of all different sizes of big cat skins and hunting trophies that customers would bring to them. The \"snarling\" open mouth expression of finished big cat mounts was one of the Van Ingen's trademark qualities, a feature rigorously studied and made possible only by special head moulds which had specific built grooves on the nose area. \n\nGlass eyes were imported from Germany, hand painted individually by a factory workman each pair painted specifically for each individual taxidermy mount. Van Ingen constructed mannikins and moulds of all sizes meaning they could produce mounts of consistent quality for a variety of poses from head mounts to full mount life size pieces.\n\nIn its heyday, Van Ingen & Van Ingen was one of the biggest taxidermy businesses in the world. Factory records reveal that Van Ingen & Van Ingen would process over 400 Tigers per year from the 1930s till the late 1960s limited to not only tigers and leopards, but also bears, lions, other species of cat, ungulates and even African game. Film stars, viceroys and senior military men were numbered among their customers, but at least a third of the taxidermy was done for the Indian nobility. The firm employed over 150 workers time to support the high workload, with jobs from cleaning, skinning, salting, pickling, mounting, carpentry, finishing, decorating and offloading. Work began to decline in the late 1960s, following the banning of hunting in India.\n\nThe firm remained lightly active until 1999 when it closed.\n\nIn 2004, Pat Morris travelled to Mysore to document what would remain left of the taxidermy firm meeting the last survivor of business management Joubert Van Ingen. Morris would go on to author and publish the book \"Van Ingen & Van Ingen - Artists in Taxidermy\" in 2006 which outlines the quality, complexity and history of what once was one of the world's largest taxidermy firms. The book also contains actual photocopies of the factory workbook records of the Van Ingen work flow.\n\nThe Van Ingen & Van Ingen book, \"Van Ingen & Van Ingen, Artists in Taxidermy, Mysore\" (Morris, 2006) is considered the main source for information of the firm with studies of original factory records that reveal the abundance of wild leopards and tigers once found in the wild.\n\nOne of the three brothers De Wet Van Ingen (now deceased), still holds the record for the largest Mahseer ever caught on a rod. A cast of the original fish caught was donated to the Regional Museum of Natural History (RMNH), Siddarthanagar, Mysore by Joubert. RMNH also houses a sizable collection of taxidermy mounts which are displayed all round the year.\n\nToday, Van Ingen taxidermy mounts are found in private collections and museums throughout the world. Some can be found in auction houses throughout Britain at times finding fetching high prices.\n\nToday there is little to no information regarding possibly one of the greatest taxidermy firms in the world, apart from P.A. Morris' studies. The Van Ingen factory in Mysore, India lies derelict overgrown by the local jungle. The last member of the Van Ingens family Edwin Joubert Van Ingen (born 27 July 1912) died on 12 Mar 2013 in his Mysore residence. He was 101 years old.\n\nA 160 million-year-old fossil of a sauropod, and stuffed animals by Van Ingen & Van Ingen, were part of the museum collection that was destroyed in the April 2016 fire at the National Museum of Natural History, New Delhi.\n\n\n"}
{"id": "2127153", "url": "https://en.wikipedia.org/wiki?curid=2127153", "title": "Van Wyck Brooks", "text": "Van Wyck Brooks\n\nVan Wyck Brooks (February 16, 1886 in Plainfield, New Jersey – May 2, 1963 in Bridgewater, Connecticut) was an American literary critic, biographer, and historian.\n\nBrooks graduated from Harvard University in 1908. As a student he published his first book, a collection of poetry called \"Verses by Two Undergraduates\", co-written with his friend John Hall Wheelock.\n\nBrooks' best-known work is a series of studies entitled \"Makers and Finders: A History of the Writer in America, 1800-1915\" (1952), which chronicled the development of American literature during the long 19th century. Brooks embroidered elaborate biographical detail into anecdotal prose. For \"The Flowering of New England, 1815-1865\" (1936) he won the second National Book Award for Non-Fiction from the American Book Sellers Association and the 1937 Pulitzer Prize for History. The book was also included in Life Magazine's list of the 100 outstanding books of 1924-1944.\n\nBrooks was a long-time resident of Bridgewater, Connecticut, which built a town library wing in his name. Although a decade-long fund-raising effort was abandoned in 1972, a hermit in Los Angeles, Charles E. Piggott, with no connection to Bridgewater surprised the town by leaving money for the library in his will. With $210,000 raised, the library addition went up in 1980.\n\nAmong his works, the book \"The Ordeal of Mark Twain\" (1920) analyzes the literary progression of Samuel L. Clemens and attributes shortcomings to Clemens' mother and wife. In 1925 he published a translation from French of the 1920 biography of Henry Thoreau by Leon Bazalgette, entitled \"Henry Thoreau, Bachelor of Nature\".\n\nIn 1944, Brooks was on the cover of \"Time Magazine\".\n\n\nA historic district known for its old Victorian and Second French Empire style buildings in Plainfield, the town of his birth, is named after him.\n\n\n\"Doctor of Letters\":\n\n\"Doctor of Humane Letters\":\n\n"}
{"id": "9765894", "url": "https://en.wikipedia.org/wiki?curid=9765894", "title": "Westmoreland County coal strike of 1910–11", "text": "Westmoreland County coal strike of 1910–11\n\nThe Westmoreland County coal strike of 1910–1911, or the Westmoreland coal miners' strike, was a strike by coal miners represented by the United Mine Workers of America. The strike is also known as the Slovak Strike because about 70 percent of the miners were Slovak immigrants. It began in Westmoreland County, Pennsylvania, on March 9, 1910, and ended on July 1, 1911. At its height, the strike encompassed 65 mines and 15,000 coal miners. Sixteen people were killed during the strike, nearly all of them striking miners or members of their families. The strike ended in defeat for the union.\n\nThe Irwin gas coal basin is an area in Westmoreland County, Pennsylvania. It encompasses the townships of North Huntingdon, Penn, Sewickley, Salem, South Huntingdon, Hempfield and Irwin, and the boroughs of Murrysville, Export and Delmont. The coal mined in the district was unsuitable for use as coke. However, it was ideal for gasification and conversion into coal gas.\n\nSeven companies dominated coal mining in the Irwin Basin in 1910. In 1854, the Westmoreland Coal Company was formed to begin mining coal in the region. In 1905, it bought a controlling interest in Penn Gas Coal, a company established in 1861 to gasify coal. Penn Gas Coal, in turn, had obtained a one-third ownership in the Manor Gas Coal Company. Through these purchases, Westmoreland Coal had a near-monopoly on the gas coal market, and was the largest bituminous coal company in Pennsylvania. In 1892, Robert Jamison and his sons founded the Jamison Coal and Coke Company (originally the Jamison Coal Company). In 1886, the Berwind family and Judge Allison White founded the Berwind-White Coal Mining Co. In 1902, a number of smaller coal gas companies in and around Greensburg, Pennsylvania, merged to form the Keystone Coal and Coke Company. In 1905, Latrobe-Connellsville Coal and Coke Company was formed when Marcus W. Saxman merged three of his wholly owned or controlled coal companies.\n\nThese companies were very paternalistic. Company towns (colloquially referred to as \"coal patches\") were established, company stores founded and workers often paid in company scrip.\n\nCoal miners increasingly agitated for improved wages and working conditions after 1900. Miners demanded an eight-hour day and wages equal to those paid in the nearby Pittsburgh coal basin. Since miners were paid by the ton, workers also wanted to standardize the size of coal wagons to ensure they were paid fairly. Miners also sought to be paid for mining \"slack\" (very fine coal), and for \"dead work\" (laying of track, shoring up tunnels, pumping out water, and removing slate and clay).\n\nWestmoreland Coal, Penn Gas Coal and Keystone Coal and Coke strongly resisted the miners' demands and any attempt at unionization. Companies used the Coal and Iron Police to physically intimidate and sometimes beat pro-union miners, workers were fired, and coal companies evicted families from the \"coal patches\" whenever miners struck.\n\nThe situation came to a head in 1910. The coal companies reduced wages by 16 percent, paying only 58 cents per ton-and-a-half of coal mined. The breaking point came when Keystone Coal and Coke announced that miners would have to begin using new safety lights and new forms of explosives—and pay for these items themselves.\n\nMiners' unions had tried to organize Westmoreland County coal mines since 1883, but had little success. In February 1910, however, the lower wage rates and new expenses led miners at Keystone Coal and Coke to meet and discuss their grievances among themselves. The miners decided to invite the United Mine Workers of America (UMWA) to form a union.\n\nOn March 7, 1910, Van Bittner, a UMWA vice president, arrived in Westmoreland County and formed a local union. Four hundred miners signed up and paid dues. Keystone Coke and Coal immediately fired 100 miners for attending the union organizing meeting. The Keystone miners walked off the job, and the strike swiftly spread throughout the Irwin Basin.\n\nUnion recognition became the biggest issue in the strike. The workers felt that if they could win recognition of the union, their other demands would come easily.\n\nWhen the miners struck on March 9, the coal companies evicted thousands of families from their company-owned homes. UMWA spent $25,000 purchasing tents and constructing shanties, and set up 25 tent cities to accommodate the homeless. Near the town of Export, more than 100 tents went up, making it the largest tent city during the strike.\n\nEthnic tension threatened to divide the nascent union. Slovakians comprised 70 percent of the striking miners, but the strike committee was led by native-born miners of English, German and Irish descent. UMWA organizers Bittner and Frank Hayes worked hard to overcome these divisions, however. Multi-lingual organizers were employed, each ethnic group elected its own representatives, and parades and rallies featured musicians and speakers from all groups.\n\nPublic backing for the strike was high. Westmoreland County had a long history of support for unions. Local religious leaders signed petitions in favor of the union, testified before the United States Congress on behalf of workers, and called on the governor and state legislature to force the coal companies to submit to arbitration.\n\nUMWA support for the strike, however, was not nearly as strong. International union president Thomas Lewis had not condoned the strike, and criticized efforts by leaders in surrounding UMWA Districts to drum up increased support for the strikers. But in March 1910, a special meeting of the UMWA international executive board voted to support the strike, forcing Lewis to grudgingly offer the union's resources. Eventually, the union gave more than $1 million in relief payments to the strikers. Lewis, however, continued to work to undermine the union's support for the strike. He backed an insurgent faction in District 6 to unseat leaders who supported the strike. The act led to internecine warfare in the union and charges that Lewis and his candidates were in league with mine owners.\n\nTo end the strike and break the union, the coal companies began importing thousands of Eastern European immigrants to work the mines. Coal company representatives on the East Coast promised immigrants a job and housing, and paid for them and their families to move to Pennsylvania. The flow of strikebreakers was small at first, but by the fall it was nearly a flood. The number of new immigrant workers was so large that the Penn Gas Coal company constructed 30 two-story houses in Hahntown to house its replacement workers, leading local residents to refer to the area as \"Scab Hill\".\n\nManagement often took advantage of the strikebreakers, however. Company recruiters were ordered not to tell potential workers that they would be employed as strikebreakers. The coal companies sought out recent immigrants who did not speak English (or who spoke or understood it poorly), and then used this handicap against the strikebreakers. If workers tried to quit, the Coal and Iron Police prevented them from leaving and told them that they had to work off the cost of their transportation before resigning. When strikebreakers still tried to leave, the police beat them and forced them back to work. In some cases, fences were built around strikebreaker housing to intimidate the workers into staying. The abuse of strikebreakers was so severe that the U.S. House of Representatives Committee on Labor held hearings on whether the coal companies had illegally forced people into peonage.\n\nEmployers also turned to the courts for assistance. In April 1910, Keystone Coal and Coke sought a restraining order to prevent striking miners from approaching company property on the grounds that the number of strikers and the loud noises they made intimidated company employees. Although the local sheriff testified that the strikers had committed no acts of violence, the state district court issued a sweeping injunction which essentially barred the union from use of public roads:\nThe vague terms of the injunction led law enforcement officials to arrest miners as much as a half mile from Keystone grounds. Other coal companies quickly asked for similar injunctions which \"made marching, assembling or traversing public roads illegal\".\n\nThe coal companies moved aggressively to exploit the law in other ways as well. The Coal and Iron Police patrolled company property and denied admittance to union members and supporters. Union members were often arrested for using public roads which traversed company property. Small towns and villages, often encircled by coal company land, became isolated and embattled. In Herminie, all citizens were required to obtain a pass from the local mine manager before leaving the village. Union members were denied the use of post offices or the ability to enter local courthouses, because these facilities were often on coal company property. Nearly 1,000 miners were ultimately arrested for trespass or disorderly conduct. Simply walking home in a group from a union meeting on a public highway could earn a contempt citation and a $50 fine.\n\nIn 1911, seven coal companies in Westmoreland County and Allegheny County sued the leaders of the strike. The coal companies claimed they had suffered economic losses as high as $500,000 due to the strike and strike-related property damage. Twenty-eight officers in nearby District 5 and 17 strike leaders in Westmoreland County were arrested on charges of conspiracy, intimidation, violence and general lawlessness. Local labor unions helped the 45 men post bond of $300 each, and instituted a special per capita assessment to form a legal defense fund. But the public outcry was so extraordinary that the coal companies dropped the suits.\n\nEmployers also used force to intimidate striking miners. At their disposal were the Coal and Iron Police, local law enforcement personnel, and the Pennsylvania State Police.\n\n\nDespite this, sheriff's deputies instigated and participated in three particularly violent and deadly incidents:\nProblems with the deputies were so severe that in November 1910 the Westmoreland County sheriff stopped securing them for the coal companies. The companies responded by seeking deputies from local police forces instead.\n\nIn January 1911, the Westmoreland County sheriff began deputizing striking miners as deputy sheriffs (although they served without pay). In May 1911, four sheriff's deputies were cited for contempt of court for venturing too close to coal company property. The sheriff said that the men had done so in their official capacity as deputies, but the local court fined them anyway. The Westmoreland County sheriff became so frustrated with the injunction that he refused to permit his deputies to patrol marches on public highways.\n\nThe Pennsylvania State Police (PSP) proved to be the most violent group during the strike. The PSP had been founded in 1905 to discourage the use of private police forces in workers' strikes and to provide law enforcement when local police or sheriffs were unable or unwilling to enforce the law. But rather than enforce the law, the PSP proved the group most willing to break it. One trooper described how the State Police dealt with strikers: \"We ride in, scoop them up and beat hell out of them.\"\n\nThe number of unprovoked violent acts committed by the PSP was extremely high and frequent. James Maurer, a socialist member of the Pennsylvania General Assembly from Reading, conducted a survey asking for information on State Police actions during the strike. Maurer's survey found that violence significantly increased after the arrival of the State Police, and that almost all acts of violence were committed by state troopers without provocation. Mauer was so outraged by the results of his survey that he introduced a bill to abolish the state police. Hundreds of citizens later testified before state and federal commissions that mounted State Police routinely charged onto town sidewalks or into crowds, trampling and severely injuring men, women and children (whether strikers or not). Severe beatings with fists and clubs were common, with troopers breaking into and ransacking homes without warrants, beating citizens and striking miners alike. Local police officials claimed State Police routinely beat people on the street for no reason, and resisted local police attempts to stop them. State Police troopers shot up towns \"in true Western style\", and fired indiscriminately into crowds or into tent cities (killing and wounding sleeping women and children). Sexual assault (including rape) was disturbingly common, and at least one hotel manager accused troopers of promoting prostitution.\n\nState Police were also involved in a number of serious violent incidents, several of which resulted in the deaths of unarmed strikers:\n\nDuring the strike, six striking miners, nine wives of striking miners, and one bystander were killed, and thousands of strikers and members of their families severely beaten or wounded.\n\nBy mid-1911, the strike had taken its toll on the coal companies. At least $500,000 had been spent on security, and coal production had dropped by 45 percent. The larger companies, however, used their financial reserves and income from non-mining operations (such as rental properties, company stores and even breweries) to withstand the economic pressure exerted by the miners. But all companies benefited from a significant slump in the demand for coal in 1910 and 1911, which leveled the playing field vis-a-vis their competitors.\n\nBut the miners were worse off than the employers. The winter of 1910–11 was particularly cold, and the miners and their families suffered tremendously. The union built numerous shacks and shanties, and moved miners' families out of tents and into the shacks for better protection from the elements. But not enough shelter could be erected, and 400 families spent the entire winter in tents. Hunger and disease were also beginning to become widespread among strikers' families.\n\nIn early 1911, the UMWA's support for the strikers appeared strong. In January 1911, Lewis lost the presidency of UMWA to John P. White. White fully backed the strike, and the UMWA convention reaffirmed the union's support for the miners.\n\nBut just six months later, the UMWA called a halt to the strike. The union had disbursed more than $1 million in strike relief funds, but it was no longer financially able to keep the strike going. On July 1, 1911, the UMWA executive board voted to end to the strike. Although most miners returned to work, about 400 were blacklisted and forced to seek employment outside Pennsylvania.\n\nThe Westmoreland County coal strike was the setting for one of the more colorful incidents in the life of Mary Harris Jones, better known as \"Mother Jones\". Even though she was 73 years of age, Mother Jones agreed to travel to Westmoreland County to support the United Mine Workers in their strike.\n\nA number of miners' wives had been arrested in the summer of 1910 for harassing strikebreakers and company security personnel.\n\nJones encouraged the women to bring their babies and small children with them when they were sentenced by the court in Greensburg. The presiding judge sentenced the women to pay a $30 fine or serve 30 days in jail. Unable to pay, the women were jailed. As there was no one else to care for the children, the judge was forced to jail the children along with their mothers.\n\nWhile the women were being processed for imprisonment, Jones instructed them: \"You sing the whole night long. You can spell one another if you get tired and hoarse. Sleep all day and sing all night and don't stop for anyone. Say you're singing to the babies. I will bring the little ones milk and fruit. Just you all sing and sing.\"\n\nUnfortunately, the jail was next door to the sheriff's home, as well as several hotels, lodging houses, and other homes. The sound of women singing all through the night kept most of the townspeople awake. After five days of sleeplessness, the townspeople angrily demanded that the judge order the women's release. He did so.\n\nThe incident has become known as \"the women who sang their way out of jail\".\n\n\n\n"}
