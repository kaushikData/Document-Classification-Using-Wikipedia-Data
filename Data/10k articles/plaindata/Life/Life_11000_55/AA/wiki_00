{"id": "11685766", "url": "https://en.wikipedia.org/wiki?curid=11685766", "title": "Absadi", "text": "Absadi\n\nAbba Absadi (died 1381) is a saint of the Eritrean Orthodox Tewahedo Church. He was a disciple of Ewostatewos, and his best-known disciple is Abba Filipos. He founded the monastery of Debre Mariam in 1374, which is located in modern-day Eritrea. He was captured by the soldiers and tortured on the wheel, then he was thrown on the stove. He endured all the tortures patiently and then was beheaded.\n\nAbsadi's feast day is September 28 (Meskerem 18 in the Ethiopian Ecclesiastical calendar).\n\n\n"}
{"id": "4001399", "url": "https://en.wikipedia.org/wiki?curid=4001399", "title": "Abu Abdallah al-Shi'i", "text": "Abu Abdallah al-Shi'i\n\nAbu Abdallah al-Husayn ibn Ahmad ibn Zakariyya al-Shi'i (, \"Abū ʿAbd Allāh ash-Shi'ī\"; died 28 February 911) was a \"Da'i\" for the Isma'ilis in Yemen and North Africa, mainly active among the Kutama Berbers, whose teachings and conquest of Ifriqiya gave rise to the Fatimid Caliphate.\n\nHe was born in Kufa in Iraq (or Sanaa, according to some accounts) and was active in the administration of the Abbasid Caliphate, before he began to associate with Ismaili teachers. At first he proselytised under the guidance of Ibn Hawshab in Yemen and Mecca. \n\nDuring a pilgrimage to Mecca in 279 A.H./892 CE, he met some Kutama Berbers that boasted of their independence and autonomy from the Aghlabids. Abu 'Abdullah sensed a chance and decided to follow their invitation to the Maghrib, where he arrived in 280/893. After successfully preaching the Ismaili doctrine among the Kutama Sanhajas (known today as Kabyles), he was able to form a powerful army consisting of Berber peasants. He began conquering the cities of Ifriqiya up to the point where he finally took over ar-Raqqada, the palace city of the Aghlabids near Kairuan, in 909. \n\nAll this had been done by him to prepare for the appearance of Abdullah al-Mahdi Billah, the \"imam\"-caliph of the Fatimids. Al-Mahdi was rescued from a prison in Sijilmasa (present-day Morocco) and proclaimed as caliph, ruling from the former residence of the Aghlabids. \n\nAl-Shi'i had hoped that al-Mahdi would be a spiritual leader, and leave the administration of secular affairs to him, but he was soon disappointed. After disclosing the plot against al-Mahdi by the Kutama Berber commander Ghazwiyya, who then assassinated Abu abdallah on February 911.\n\n\n"}
{"id": "1347261", "url": "https://en.wikipedia.org/wiki?curid=1347261", "title": "Al-Qaria", "text": "Al-Qaria\n\nSūrat al-Qāriʻah () is the 101st chapter (sura) of the Quran with 11 verses. This chapter takes its name from its first word \"\"qariah\", referring to the Quranic view of the end time and eschatology. \"Qariah\"\" has been translated to calamity, striking, catastrophe, clatterer, etc. According to Ibn Kathir, a traditional exegete, \"Al-Qariah\" is one of the names of the Day of Judgement, like Al-Haaqqa, At-Tammah, As-Sakhkhah and others. After a picturesque depiction of judgement day in first 5 ayaat, next 4 ayat describe that Allah's Court will be established and the people will be called upon to account for their deeds. The people whose good deeds will be heavier, will be blessed with bliss and happiness, and the people whose good deeds will be lighter, will be cast into the burning fire of hell. The last 2 ayaat describe \"Háwíyah\" in similar emphatic way as \"Al-Qariah\" was emphasized in the beginning.\n\nJalaluddin Al-Suyuti co-author of the classical Sunni tafsīr known as Tafsir al-Jalalayn suggests that some of the sūrahs have been named using incipits (i.e. the first few words of the surah). Hamiduddin Farahi a celebrated Islamic scholar of Indian subcontinent is known for his groundbreaking work on the concept of Nazm, or Coherence, in the Quran. He writes that Some sūrahs have been given names after some conspicuous words used in them. The Surah takes its name from its first word al-qariah. This is not only a name but also the title of its subject matter, for the Surah is devoted to Resurrection -Abul A'la Maududi.\n\n\"Al-Qāriʻah\" is a Meccan surah. Meccan suras are chronologically earlier surahs that were revealed to Muhammad at Mecca before the hijrah to Medina in 622 CE. They are typically shorter, with relatively short \"ayat\", and mostly come near the end of the Qur'an’s 114 sūwar. Most of the surahs containing muqattaʿat are Meccan. Theodor Nöldeke and William Muir alike assign this surah a place among the earliest revelations of the Qurán -George Sale. In accordance with the western exegesis mentioned, the Muslim tafsirs also exert that the contents of this surah show that this is one of the earliest Surahs to be revealed at Makkah.\n\nThe surahs of the Qur'an are not haphazardly compiled as is generally thought. They have been arranged in a specific order by the Almighty, and like the arrangement of the verses within a surah, the arrangement of the surahs within the Qur'an is very apt and meaningful with relation to the topic they discuss. In a nutshell, as per this arrangement, the Qur'an is divided in seven distinct groups and the surahs within each group occur in pairs. This pairing of the surahs is on the basis of the topics discussed, and each member of a pair has a complimentary relation with one another. Some surahs are an exception to this scheme like Surah Fatihah, which is like an introduction to the whole Qur'an. Some other surahs have come as an appendix or as a conclusion of a group. The idea of textual relation between the verses of a chapter has been discussed under various titles such as \"nazm\" and \"munasabah\" in non-English literature and \"coherence\", \"text relations\", \"intertextuality\", and \"unity\" in English literature. Hamiduddin Farahi, an Islamic scholar of the Indian subcontinent, is known for his work on the concept of nazm, or coherence, in the Quran. Fakhruddin al-Razi (died 1209 CE), Zarkashi (died 1392) and several other classical as well as contemporary Quranic scholars have contributed to the studies.\n\nThis surah belongs to the last(7th) group of surahs which starts from Surah Al-Mulk (67) and runs till the end of the Quran. The theme of the seventh group is to warn the leadership of the Quraysh of the consequences of the Hereafter, to communicate the truth to them to the extent that they are left with no excuse to deny it, and, as a result, to warn them of a severe punishment, and to give glad tidings to Muhammad of the dominance of his religion in the Arabian peninsula. Briefly, this can be stated as delivering warning and glad tidings.\n\nRhetorically Al-Qariah has 2 similarities with Al-Haaqqa(69). Firstly the opening of the surah resembles Al-Haaqqa(69) which opens with the wordings \n69:1 الْحَاقَّةُ \n69:2 مَا الْحَاقَّةُ\n69:3 وَمَا أَدْرَاكَ مَا الْحَاقَّةُ\n\nnotice that Al-Qaria opens in exactly same style\n101:1 الْقَارِعَةُ \n101:2 مَا الْقَارِعَةُ\n101:3 وَوَمَا أَدْرَاكَ مَا الْقَارِعَةُ\n\nSecondly, word \"Al-Qaria\" appears as a total of 5 times in Quran and out of which thrice it is mentioned in this surah while once it appears in Al-Haaqqa as well.\n\nAl-Qariah form a pair with next surah At-Takathur in regards to their subject-matter. The first surah warns its addressees of the situation that will arise on the Day of Judgement, while the second, with reference to this situation warns them of their attitude of indifference -Javed Ahmed Ghamdi. Regarding its message, this surah forms a group of four similar surahs along with two previous and one next surah which depicts judgement day with picturesque description and concludes the topic of every person's deeds being weighed and thus resulting in either heaven or hell allotted to the according person. -Dr.Israr Ahmed. \n\nThe theme of this surah is resurrection and the hereafter; a scene explaining the day of judgement. At the outset, the people have been aroused and alarmed, saying: \"The Great Disaster! What is the Great Disaster? And what do you know what the Great Disaster is?\" Thus, after preparing the listeners for the news of the dreadful calamity, Resurrection has been depicted before them in two sentences, saying that on that Day people will be running about in confusion and bewilderment just like so many scattered moths around a light, and the mountains uprooted, will their cohesion and will fly about like carded wool. Then, it has been said that when Allah's Court is established in the Hereafter and the people are called upon to account for their deeds. The people whose good deeds are found to be heavier than their evil deeds, will be blessed with bliss and happiness, and the people whose good deeds are found to be lighter than their evil deeds, will be cast into the deep pit full of burning fire. Sale divides the contents of the surah in three principal subjects <br>\nAyat 1-5: The day of judgment a day of striking.<br> \nAyat 6-9: The good and bad shall be judged according to their works.<br> \nAyat 10,11: Háwíyah described.<br>\n"}
{"id": "36471858", "url": "https://en.wikipedia.org/wiki?curid=36471858", "title": "Badger culling in the United Kingdom", "text": "Badger culling in the United Kingdom\n\nBadger culling in the United Kingdom is permitted under licence, within a set area and timescale, as a way to reduce badger numbers in the hope of controlling the spread of bovine tuberculosis (bTB).\n\nHumans can catch bTB, but public health control measures, including milk pasteurisation and the BCG vaccine, mean it is not a significant risk to human health. The disease affects cattle and other farm animals (including pigs, goats, deer, sheep, alpacas and llamas), and some species of wildlife including badgers, deer and a few domestic pets. Geographically, bTB has spread from isolated pockets in the late 1980s to cover large areas of the west and south-west of England and Wales in the 2010s. Some people believe this correlates with the lack of badger control.\n\nIn October 2013, culling in England was controversially trialled in two pilot areas in west Gloucestershire and west Somerset. The main aim of these trials was to assess the humaneness of culling using \"free shooting\" (previous methods trapped the badgers in cages before shooting them). The trials were repeated in 2014 and 2015, and expanded to a larger area in 2016 and 2017. As of July 2017, there is no UK-wide policy of badger culling.\nEuropean badgers (\"Meles meles\") are not an endangered species, but they are among the most legally-protected wild animals in the UK, being shielded under the Protection of Badgers Act 1992, the Wildlife and Countryside Act 1981, and the Convention on the Conservation of European Wildlife and Natural Habitats.\n\nPrior to the 2012/13 badger cull, the government's Department for Environment, Food and Rural Affairs (Defra) stated that badger control was needed because \"...we still need to tackle TB in order to support high standards of animal health and welfare, to promote sustainable beef and dairy sectors, to meet EU legal and trade requirements and to reduce the cost and burden on farmers and taxpayers.\" This report listed the following reasons for bTB control:-\n\n\nHumans can become infected by the \"Mycobacterium bovis\" bacterium, which causes the disease \"bovine TB\" (bTB). Between 1994 and 2011, there were 570 human cases of bovine TB in humans. Most of these cases are thought to be in people aged 45 or over, who could have been infected before milk pasteurisation became common in the UK.\n\nOne route of transmission to humans is drinking infected, non-pasteurised milk (pasteurisation kills the bacterium). European badgers can become infected with bTB and transmit the disease to cattle, thereby posing a risk to the human food chain. Culling is a method used in parts of the UK to reduce the number of badgers and thereby reduce the incidence and spread of bTB that might infect humans.\n\nOnce an animal has contracted bTB, the disease can be spread through the sett via the exhalations or excretions of infected individuals. Modern cattle housing, which has good ventilation, makes this process relatively less effective, but in older-style cattle housing or in badger setts, the disease can spread more rapidly. Badgers range widely at night, potentially spreading bTB over long distances. Badgers mark their territory with urine, which can contain a high proportion of bTB bacteria. According to the RSPCA, the infection rate among badgers is 4–6%.\n\nIn 2014, bTB was mostly concentrated in the south-west of England. It is thought to have re-emerged because of the 2001 foot and mouth disease outbreak which led to thousands of cattle being slaughtered and farmers all over the UK having to buy new stock. There appears to have been undiscovered bTB in some of these replacement animals.\n\nAction on eradicating bTB is a devolved issue. Defra works with the Devolved Administrations in Wales, Scotland and Northern Ireland for coherent and joined-up policies for the UK as a whole. The Chief Veterinary Officers and lead TB policy officials from each country meet on a monthly basis to discuss bTB issues through the UK bTB Liaison Group.\n\nThe government had already paid substantial compensation to farmers because of the foot and mouth outbreak in 2001 followed by the bluetongue outbreak in 2007, against the background of EC Directives 77/391 and 78/52 on eradication of tuberculosis, brucellosis or enzootic bovine leucosis. In the 2001 foot and mouth outbreak, a total of £1.4 billion in compensation was paid. The Cattle Compensation (England) Order 2006 (SI2006/168) was overturned when the High Court decided the Order was unlawful; in the test case, farmers had been receiving compensation payments of around £1,000 on animals valued at over £3,000, but in extreme cases the discrepancy between animal value and compensation paid was over one thousand percent. This case was itself overturned on appeal in 2009.\n\nSome farmers' organisations and Defra are in favour of a policy of badger culling because of the mounting costs of the disease to farmers; cattle testing positive for a bTB test must be slaughtered and the farmer paid compensation. Furthermore, these organisations feel that alternatives to culling are not cost-effective.\n\nIn 2005, attempts to eradicate bTB in the UK cost £90 million.\n\nIn 2009/10, controlling bTB cost the taxpayer £63 million in England with an additional £8.9 million spent on research.\n\nIn 2010/11, nearly 25,000 cattle were slaughtered in England alone, and the cost to the taxpayer of disease control was £91 million; 90% of this amount was accounted for by Government-funded cattle testing and compensation payments to farmers for slaughtered animals. During 2010, 10.8% of herds in England were under restrictions, whilst in the West and South-West, this figure was more than double the average at 22.8%. In a Defra report in 2011, it was stated that the number of new bTB incidents in England rose in 2010, compared to 2009, and suggested the disease situation was not improving. It was concluded \"...the cost to the taxpayer is huge – it is set to exceed £1 billion over the next ten years in England alone.\"\n\nThere are also considerable costs for farmers, including losses incurred as a result of movement restrictions, having to buy replacement animals, and supporting the required programme of bTB testing (animals must be tested routinely, a repeat test is required if the first is positive, and a pre-movement test is needed if a herd has infection) in a herd. It is more difficult to quantify the costs to the industry but they must run into tens of millions of pounds a year.\n\nThe average cost of a bTB breakdown in a cattle herd in England is approximately £30,000. About £20,000 of this is paid by the Government, primarily as compensation for animals compulsorily slaughtered and costs of testing. This leaves approximately £10,000 needing to be paid by farmers as a result of their consequential losses (loss of earnings e.g. milk sales of culled cows), on-farm costs of testing, and disruption to business through movement restrictions.\n\nThe risk of humans contracting bTB from milk is extremely low if certain precautions are taken, and scientists have argued that badger culling is unnecessary. The low risk is accepted by Defra who wrote in a report published in 2011: \"The risk to public health is very low these days, largely thanks to milk pasteurisation and the TB surveillance and control programme in cattle\".\n\nAnimal welfare groups such as the Badger Trust and the Royal Society for the Prevention of Cruelty to Animals (RSPCA) are opposed to what they feel is random slaughter of badgers — which have special legal protection in the UK — in return for what they describe as a relatively small impact on bTB.\nCattle and badgers are not the only carriers of bTB. The disease can infect and be transmitted by domestic animals such as cats and dogs, wildlife such as deer and farm livestock such as horses and goats. Although the frequency of infection from other mammals is generally much less than in cattle and badgers other species of wildlife have been shown as a possible carriers of bTB. In some areas of South-West England, deer, especially fallow deer due to their gregarious behaviour, have been implicated as a possible maintenance host for transmission of bTB. It has been argued that in some localised areas, the risk of transmission to cattle from fallow deer is greater than it is from badgers. \"M. bovis\" was shown to be hosted and transmitted to humans by cats in March 2014 when Public Health England announced two people in England developed bTB infections after contact with a domestic cat. The two human cases were linked to nine cases of bTB infection in cats in Berkshire and Hampshire during 2013. These are the first documented cases of cat-to-human TB transmission.\n\nResearch reported in 2016 indicates that bTB is not transmitted by direct contact between badgers and cattle, but through contaminated pasture and dung. This has important implications for farm practices such as the spreading of slurry. Using a GPS collar small enough to be worn by badgers, the researchers tracked more than 400 cattle when they were in the territories of 100 badgers. In 65,000 observations only once did a badger get within 10 metres of a cow – the badgers preferred to be 50 m away. Experts were quoted as saying expansion of the cull “flies in the face of scientific evidence” and that the cull is a “monstrous” waste of time and money.\n\nUnder the Berne Convention on the Conservation of European Wildlife and Natural Habitats, the culling of badgers is only permitted as part of a bTB reduction strategy if there is no satisfactory alternative.\n\nThere is widespread public support for an alternative to culling. In October 2012, MPs voted 147 in favour of a motion to stop the 2012/2013 badger cull and 28 against. The debate had been prompted by a petition on the government's e-petition website, which at the time had exceeded 150,000 signatories, and which had by June 2013 gathered around a quarter of a million signatories. By the time it closed on 7 September 2013 there were 303,929 signatures breaking the record for the largest number of people ever to sign a government e-petition.\n\nIn July 2008, Hilary Benn, the then Secretary of State for Environment, Food and Rural Affairs, made a statement which highlighted actions other than culling, including allocating funding of £20m to the development of an effective TB injectable vaccine for cattle and badgers, and an oral badger vaccine.\n\nIn March 2010, Defra licensed a vaccine for badgers, called the Badger BCG. The vaccine is only effective on animals that do not already have the disease and it can only be delivered by injection. It is available on prescription, subject to a licence to trap badgers from Natural England, but only where injections are carried out by trained vaccinators. Defra funded a programme of vaccinations in 2010/11, and other organisations that have funded smaller vaccination programmes include the National Trust in Devon, the Gloucestershire Wildlife Trust, and a joint project by the National Farmers' Union and the Badger Trust.\n\nHowever, in England, the Government views badger vaccination as a necessary part of a package of measures for controlling bTB, because it estimates the cost of vaccination to be around £2,250 per square kilometre per annum, and notes that most landowners and farmers have little interest in paying this cost themselves.\n\nIn Wales, badger vaccination is carried out in preference to culling. Whilst a field trial into the vaccination of badgers is under way in the Republic of Ireland, as yet, neither culling nor vaccination is carried out in Northern Ireland, although the Northern Ireland Assembly has carried out a review into bTB that recently recommended an immediate investigation into the viability of culling and/or vaccination. In autumn 2009, Scotland was declared officially tuberculosis-free under EU rules, so there are no proposals to cull badgers there.\n\nAlthough vaccinating cattle is a recognised method of avoiding killing wildlife but reducing the prevalence, incidence and spread of bTB in the cattle population and could also reduce the severity of a herd infection regardless of whether infection is introduced by wildlife or cattle it has three problems.\n\n\nAs of 2011, Defra have invested around £18 million in the development of cattle vaccines and associated diagnostic tools.\n\nAll transmissible livestock diseases can be mitigated by generic good husbandry practices. BTB risks can be reduced by carefully balanced diets for the cattle, careful sourcing of replacement stock, maintaining correct stocking densities and keeping sheds clean and well ventilated.\n\nMany badgers in Europe were gassed during the 1960s and 1970s to control rabies.\n\nThe organism that causes bTB, \"Mycobacterium bovis\", was discovered in 1882, but it took until 1960 for compulsory tests for the disease to be brought in, previously testing was voluntary. Herds that were attested TB free were tested annually and received a premium of 1d per gallon for their milk. Those not tested were able to carry on trading without testing. A programme of test-and-slaughter began and was successful. Until the 1980s, badger culling in the UK was undertaken in the form of gassing. By 1960 it was thought that bTB might have been eradicated in the UK, until 1971 when a new population of tuberculous badgers was located in Gloucestershire. Subsequent experiments showed that bTB can be spread from badgers to cattle, and some farmers tried to cull badgers on their land. Wildlife protection groups lobbied Parliament which responded by passing the Badgers Act 1973, making it an offence to attempt to kill, take, injure badgers or interfere with their setts without a licence. These laws are now contained in the Protection of Badgers Act 1992.\n\nIn 1997, an independent scientific body issued the Krebs Report. This concluded there was a lack of evidence about whether badger culling would help control the spread of bTB and proposed a series of trials.\n\nThe government then ordered an independently run series of trials, known as the Randomised Badger Culling Trials (RBCT). These trials, in which 11,000 badgers in selected areas were cage-trapped and killed, were conducted from 1998 to 2005, although they were briefly suspended due to the outbreak of foot-and-mouth in 2001. The incidence of bTB in and around 10 large (100 km) areas in which annual badger culling occurred was compared with the incidence in and around 10 matched areas with no such culling.\n\nIn 2003, as a result of initial findings from the RBCT, the reactive component of the culling where badgers were culled in and around farms where bTB was present in cattle, was suspended. This was because the RBCT recorded a 27% increase in bTB outbreaks in these areas of the trial compared to areas in which no culling took place. The advisory group of the trials concluded that reactive culling could not be used to control bTB.\n\nIn December 2005, a preliminary analysis of the RBCT data showed that proactive culling, in which most badgers in a particular area were culled, reduced the incidence of bTB by 19% within the cull area, however, it increased by 29% within 2 km outside the cull area. The report therefore warned of a \"perturbation effect\" in which culling leads to changes in badger behaviour thereby increasing infections within the badger colonies and the migration of infected badgers to previously uninfected areas. Whilst culling produced a decreased badger population locally, it disrupted the badgers’ territorial system, causing any surviving badgers to range more widely, which itself led to a substantial increase in the incidence of the disease, and its wider dispersal. It also reported that a culling policy \"would incur costs that were between four and five times higher than the economic benefits gained\" and \"if the predicted detrimental effects in the surrounding areas are included, the overall benefits achieved would fall to approximately one-fortieth of the costs incurred\". In summary, the report argued that it would be more cost-effective to improve cattle control measures, with zoning and supervision of herds, than it would be to cull badgers.\n\nIn 2007, the final results of the trials, conducted by the Independent Scientific Group on Cattle TB, were submitted to David Miliband, the then Secretary of State for Environment, Food and Rural Affairs. The report stated that \"badger culling can make no meaningful contribution to cattle TB control in Britain. Indeed, some policies under consideration are likely to make matters worse rather than better\". According to the report:\n\nIn October 2007, after considering the report and consulting other advisors, the then government's Chief Scientific Advisor, Professor Sir David King produced a report of his own which concluded that culling could indeed make a useful contribution to controlling bTB. This was criticised by scientists, most notably in the editorial of \"Nature\", which implied King was being influenced by politics.\n\nIn July 2008, Hilary Benn, the then Secretary of State for Environment, Food and Rural Affairs, refused to authorise a badger cull because of the practicalities and cost of a cull and the scale and length of time required to implement it, with no guarantee of success and the potential for making the disease worse. Benn went on to highlight other measures that would be taken, including allocating £20m to the development of an effective injectable TB vaccine for both cattle and badgers, and an oral badger vaccine.\n\nIn 2010, a scientific report was published in which bTB incidence in cattle was monitored in and around RBCT areas after culling ended. The report showed that the benefits inside culled areas decreased over time and were no longer detectable three years after culling ceased. In areas adjoining those which culled, a trend indicated beneficial effects immediately after the end of culling were insignificant, and had disappeared 18 months after the cull ceased. The report also stated that the financial costs of culling an idealized 150 km area would exceed the savings achieved through reduced bTB by factors of 2 to 3.5. The report concluded \"These results, combined with evaluation of alternative culling methods, suggest that badger culling is unlikely to contribute effectively to the control of cattle TB in Britain.\"\n\nIn November 2008, The Bovine TB Eradication Group for England was set up. This Group included Defra officials, members from the veterinary profession and farming industry representatives. Based on research published up to February 2010, the Group concluded that the benefits of the cull were not sustained beyond the culling and that it was ineffective method of controlling bTB in Britain. They said:\n\nAfter the 2010 general election, the new Welsh Environment Minister, John Griffiths, ordered a review of the scientific evidence in favour of and against a cull. The incoming Defra Secretary of State, Caroline Spelman, began her Bovine TB Eradication Programme for England, which she described as \"a science-led cull of badgers in the worst-affected areas\". The Badger Trust put it differently, saying \"badgers are to be used as target practice\". Shadow Environment Secretary Mary Creagh said it was prompted by \"short-term political calculation\".\n\nThe Badger Trust brought court action against the government. On 12 July 2012, their case was dismissed in the High Court; the Trust appealed unsuccessfully. Meanwhile, the Humane Society International pursued a parallel case through the European Courts which was also unsuccessful. Rural Economy and Land Use Programme fellow Angela Cassidy has identified one of the major forces underlying the opposition to badger culls as originating in the historically positive fictional depictions of badgers in British literature. Cassidy further noted that modern negative depictions have recently seen a resurgence.\n\nIn August 2015 it was announced culling would be rolled out in Dorset with a target of 615 to 835 badgers being culled there, while also being continued in Gloucestershire and Somerset. Licences were granted to allow six weeks of continuous culling in the three counties until 31 January. In December 2015, Defra released documents confirming the badger cull had \"met government targets\" with 756 animals culled in Dorset, 432 in Gloucestershire and 279 in Somerset.\n\nIn 2009, the Welsh Assembly authorised a non-selective badger cull in the Tuberculosis Eradication (Wales) Order 2009; the Badger Trust sought a judicial review of the decision, but their application was declined. The Badger Trust appealed in \"Badger Trust v Welsh Ministers\" [2010] EWCA Civ 807; the Court of Appeal ruled that the 2009 Order should be quashed. The Welsh Assembly replaced proposals for a cull in 2011 with a five-year vaccination programme following a review of the science.\n\nAs an attempt to reduce the economic costs of live cage-trapping followed by shooting used in the Randomised Badger Culling Trial, the post-2010 culls in England also allowed for the first time, \"free shooting\", i.e. shooting free-roaming badgers with firearms. Licences to cull badgers under the Protection of Badgers Act 1992 are available from Natural England, who require applicants to show that they have the skills, training and resources to cull in an efficient, humane and effective way, and to provide a Badger Control Plan. This meant that farmers were allowed to shoot the badgers themselves, or to employ suitably qualified persons to do this. The actual killing of the badgers was funded by the farmers, whereas the monitoring and data analysis was funded by Defra.\n\nA Defra statement published in October 2012, stated that \"The aim of this monitoring is to test the assumption that controlled shooting is a humane culling technique.\" The statement makes no indication that the cull would assess the effectiveness of reducing bTB in the trial areas.\n\nA Badger Trust statement indicated the 2012/13 badger cull had three specific aims:\n\nAgain, the statement makes no indication that the cull would assess the effectiveness of reducing bTB in the trial areas.\n\nPermission to allow free shooting for the first time during the cull of 2012/13 raised several concerns. \n\nIn 2014, the policing costs in Gloucestershire were £1.7 million over the seven-week period (£1,800 per badger) and in Somerset, the cost of policing amounted to £739,000 for the period.\n\nOn 19 July 2011, Caroline Spelman, the then Secretary of State for Environment, Food and Rural Affairs, announced the Government response to the consultation. It was proposed that a cull would be conducted within the framework of the new \"Bovine TB Eradication Programme for England\". In view of concerns in response to the initial consultation, a further consultation would determine whether a cull could be effectively enforced and monitored by Natural England under the Protection of Badgers Act 1992. The cull would initially be piloted in two areas, before being extended to other parts of the country.\n\nIn December 2011, the Government announced that it intended to go forward with trial badger culls in two 150 km areas. These would take place over a 6-week period with the aim of reducing the badger population by 70% in each area. Farmers and land-owners would be licensed to control badgers by shooting and would bear the costs of any culls. The Government was to bear the costs of licensing and monitoring the culls.\nThe Government would monitor:\n\n\nIn March 2012, the Government appointed members to an Independent Panel of Experts (IPE) to oversee the monitoring and evaluation of the pilot areas and report back to Government. The panel’s role was to evaluate the effectiveness, humaneness and safety of the controlled shooting method, not the effectiveness of badger culling to control TB in cattle.\n\nThe cull was to begin in 2012 led by Defra. However, the Secretary of State for Environment, Owen Paterson, announced in a statement to Parliament on 23 October 2012 that a cull would be postponed until 2013 with a wide range of reasons given.\n\nOn 27 August 2013, a full culling programme began in two pilot areas, one mainly in West Somerset and the other mainly in West Gloucestershire with a part in Southeast Herefordshire, at an estimated cost of £7 million per trial area. Up to 5,094 badgers were to be shot. There were closed seasons during the cull, designed to prevent distress to animals or their dependent offspring.\n\nShooters failed to kill the target of 70% of badgers in both trial areas during the initial 6-week cull. During this time, 850 badgers were killed in Somerset and 708 in Gloucestershire. Of the badgers culled in Gloucestershire, 543 were killed through free shooting whilst 165 were cage-trapped and shot. In Somerset, 360 badgers were killed by free shooting and 490 by being cage-trapped then shot.\n\nBecause the target of 70% badgers to be culled had not been achieved, the cull period was extended. During the 3-week extension in Somerset, an extra 90 badgers were culled, taking the total across the whole cull period to 940, representing a 65% reduction in the estimated badger population. During the 5 weeks and 3 days extension in Gloucestershire, 213 further badgers were culled, giving an overall total of 921, representing a reduction of just under 40% in the estimated badger population.\nDefra and Natural England were unwilling to divulge what data would be collected and the methods of collection during the pilot culls. However, in a decision under the Freedom of information in the United Kingdom act dated 6 August 2013, the Information Commissioner’s Office found that Defra was wrong to apply the Environmental Information Regulations in defence of its refusal to disclose information about the pilot cull methods. Defra originally intended to sample 240 badgers killed during the pilot culls but confirmed only 120 badgers targeted were to be collected for examination of humaneness and that half of these badgers would be shot while caged. Therefore, only 1.1% of badgers killed by free shooting were tested for humaneness of shooting. No badgers were to be tested for bTB.\n\nDetails of the ongoing pilot culls were not released whilst they were being conducted and Defra declined to divulge how the success of the trials would be measured. As a result, scientists, the RSPCA and other animal charities called for greater transparency over the pilot badger culls. Environment Secretary, Owen Paterson, confirmed that the purpose of the pilot culls was to assess whether farmer-led culls deploying controlled shooting of badgers is suitable to be rolled-out to up to 40 new areas over the next four years. Farming minister, David Heath, admitted in correspondence with Lord Krebs that the cull would \"not be able to statistically determine either the effectiveness (in terms of badgers removed) or humaneness of controlled shooting\". Lord Krebs, who led the Randomised Badger Culling Trial in the 1990s, said the two pilots \"will not yield any useful information\".\n\nIn explaining why the culling had missed the target, Environment Secretary Owen Paterson famously commented that \"the badgers moved the goalposts.\"\n\nLeaks reported by the BBC in February 2014 indicated that the Expert Panel found that less than half of all badgers were killed in both trial areas. It was also revealed that between 6.8% and 18% of badgers took more than five minutes to die the standard originally set was that this should be less than 5%. \n\nIt has been suggested that as culling was not selective, as many as six out of seven badgers killed could have been perfectly healthy and bTB free.\n\nScientific experts agree that culling where there are \"hard boundaries\" to the cull zones, on a large and long-term scale, could yield modest benefits. If there are 'soft boundaries' allowing badgers to escape, then it will also make things worse for farmers bordering on the cull areas due to infected badgers dispersing: the so-called \"perturbation\" effect.\n\nThe Food and Environment Research Agency (FERA) concluded \"the form and duration of badger social perturbation is still poorly understood and significant changes to our assumption may alter the order of preference [of the proposed options].\"\nThe Defra-commissioned FERA Report states: \"Our modelling has shown that while the differences between the outcomes of strategies using culling and/or vaccinating badgers are quite modest (~15–40 CHBs prevented over 10 years), their risk profile is markedly different. Culling results in the known hazard of perturbation, leading to increased CHBs [Cattle Herd Breakdowns] in the periphery of the culling area. Culling also risks being ineffective or making the disease situation worse, if it is conducted partially (because of low compliance) or ineffectually (because of disruption or poor co-ordination) or it is stopped early (because of licensing issues). Vaccination carries no comparable risks or hazards.\"\n\nThe UK government claims that a sustained cull, conducted over a wide area in a co-ordinated and efficient manner, over a period of nine years, might achieve a 9–16% reduction in disease incidence. However, many scientists and a coalition of animal-welfare and conservation groups including the RSPCA, the Wildlife Trusts and the RSPB, argue that a cull could risk local extermination of all badgers, and that a badger cull will not in any way solve the problem of bovine tuberculosis in cattle. The British Veterinary Association say that data collected from research in other countries, suggests that the control of the disease in farms has only been successfully carried out by dealing with both cattle and wild reservoirs of infection. However, in the introduction to the Final Report on the RBCT, the Chair of the Independent Scientific Group, John Bourne, states: \"Scientific findings indicate that the rising incidence of disease can be reversed, and geographical spread contained, by the rigid application of cattle-based control measures alone\" (2007, Bovine TB: The Scientific Evidence. Final Report of the Independent Scientific Group on Cattle TB,3-289). In practice it is very difficult to quantify the contribution any wildlife reservoir has to the spread of bovine tuberculosis, since culling is usually carried out alongside cattle control measures (using \"all the tools in the tool box\" approach):\n\n\"From Australian experience, Government has learnt that elimination of a wildlife host (feral Water Buffalo) needs to be followed by a long and extensive programme of cattle testing, slaughter, movement control and public awareness campaigns before bTB is eventually eradicated. And from New Zealand experience, population reduction of the wildlife host (possums) does not by itself reliably control bTB in cattle. In both Australia and New Zealand, Government was dealing with feral reservoirs of bTB rather than indigenous wildlife species, as is the case with the badger in this country\" Wilsmore, A.J. and Taylor, N. M. (2005).\n\nJohn Bourne has also argued that the planned cull is likely only to increase the incidence of bovine tuberculosis, and that there should instead be much greater emphasis on cattle farming controls. He claims that \"the cattle controls in operation at the moment are totally ineffective\", partly because the tuberculin test used in cattle is not accurate, causing tests in herds to often show negative results even while still harbouring the disease. Referring to the group's final report, he further argues that whilst cattle can get tuberculosis from badgers, the true problem is the other way around: \"Badger infections are following, not leading, TB infections in cattle\". Overall, he says, the cull will only do more harm than good, because, \"you just chase the badgers around, which makes TB worse\".\n\nIt is unclear what has been spent so far on planning and preparing for each pilot cull and who exactly is paying for what, i.e. what taxpayers are paying for and what the farming industry is paying for. Costings of the culls have not factored in socio-economic costs, such as tourism and any potential boycotts of dairy products from the cull zones. Others opposed to the cull argue that for economic reasons the government have chosen the most inhumane approach to disease eradication. Tony Dean, Chairperson of the Gloucestershire Badger Group, warns that some badgers will not be killed outright: \"You have got to be a good marksman to kill a badger outright, with one shot... Many of the badgers will be badly injured. They will go back underground after being shot, probably badly maimed. They will die a long lingering death underground from lead poisoning etc. We are going to have a lot of cubs left underground where their mothers have been shot above ground.\" He also suggests that domestic pets will be at risk in the cull areas, as some farmers will mistake black and white cats and dogs for badgers.\n\nMany cull opponents cite vaccination of badgers and cattle as a better alternative to culling. In Wales, where a policy of vaccination in 2013 was into its second year, Stephen James, who is the National Farmers Union Cymru's spokesperson on the matter, argues that the economics of badger culling are \"ridiculous\" saying the cost per badger was £620. \"That's a very expensive way of trying to control this disease when we know full well, from experience from other countries, that there are cheaper ways of doing it...if you vaccinate in the clean areas, around the edges of the endemic areas, then there's a better chance of it working.\"\n\nThe Badger Trust national charity, believes that vaccination will also be more likely to help eradicate the disease. Referring to further studies by Animal Health and Veterinary Laboratories Agency (AHVLA) and the Food and Environment Research Agency (FERA),the group claims that vaccination reduces the risk of unvaccinated badger cubs testing tuberculosis positive, because \"by the time cubs emerge and are available for vaccination they might have already been exposed [and are therefore resistant] to TB\". Steve Clark, a director of the group, has separately said that \"vaccination also reduces the bacilli that is excreted by infected badgers. It doesn't cure them, but it reduces the possibility of any further infection...in the region of a 75% level of protection. The life span of a badger is about five years. So if you continue the vaccination project for five years, then the majority of animals that were there at the beginning will have died out and that vaccination programme is leading towards a clean and healthy badger population.\"\n\nAccording to Dr Robbie McDonald, Head of Wildlife and Emerging Diseases at FERA (the lead wildlife scientist for Defra and responsible for research on badgers) the benefit of culling a population is outweighed by the detrimental effect on neighbouring populations of badgers. He is reported as saying that a huge number of badgers would have to be killed to make a difference and while it is cheap and easy to exterminate animals in the early days of a cull it gets harder and more expensive as time goes on.\n\nOn 3 April 2014, Owen Paterson decided to continue the culling trials in 2014, in the same areas of Gloucestershire and Somerset as the 2012/13 cull. On 20 May 2014, the Badger Trust applied for a judicial review of this policy in the High Court, claiming that Mr Paterson unlawfully failed to put into place an independent expert panel to oversee the process.\n\nIn response to a Freedom of Information Act request submitted by the Humane Society International (HSI) UK, Defra said that for nearly a year, it had been conducting initial investigations into carbon monoxide gas dispersal in badger sett-like structures. No live badgers have been gassed. HSI expressed concerns about the extent to which gassing causes animal suffering.\n\nIn September 2014, a second year of badger culling began in Gloucestershire and Somerset as during 2013/2014. It had previously been stated that the cull was to be extended to a further 10 areas.\n\nThe Badger Trust claimed at the High Court that this cull would take place without independent monitoring, however, Defra has denied this saying experts from Natural England and the Animal Health Veterinary Laboratory Agency will be monitoring the cull.\n\nIn June 2015, the National Trust, one of the largest landowners in the UK, stated it would not be allowing badger cullers onto their land until the results of all 4 years of pilot trials were known.\n\nThe 2014/15 cull targets had been lowered to 316 badgers in Somerset and 615 in Gloucestershire. Overall, the aim was for a reduction of 70% in badger populations over the successive culls. This was to be achieved with an emphasis on trapping badgers in cages and shooting them at dawn, rather than \"free shooting\".\n\nAs in the 2013/14 cull, hundreds of protesters entered the culling areas to disrupt the badgers causing them to remain down their setts and avoiding being trapped and/or shot, or to look for injured badgers. On 9 September 2014, two saboteurs in Gloucestershire found a badger trapped in a cage with cullers nearby. The police were called and the saboteurs pointed out that under government guidelines, trapped badgers should be released if there was a risk of interference from a third party. The sabateur organisation, \"Stop the Cull\" said police \"did the right thing\" and freed the badger. Gloucestershire police confirmed the standoff, which it said was resolved peacefully – adding the decision to release the badger was made by a contractor working for the cull operator.\n\nDr Brian May, guitarist with the rock band Queen is a critic of badger culling in the UK. He has called for the 2014/15 cull to be cancelled. \"It's almost beyond belief that the government is blundering ahead with a second year of inept and barbaric badger killing,\" he said.\n\nOrganisations involved in protesting the cull include:\n\n\nIn the 2013/2014 cull, police from forces including Sussex, Warwickshire, Cornwall and the Metropolitan Police were brought in to help with policing, however, the police have said that in the 2014/2015 cull, there will be a focus on more community policing with local officers on patrol. \"It will be very focussed on Gloucestershire officers dealing will local issues.\"\n\n\n"}
{"id": "301361", "url": "https://en.wikipedia.org/wiki?curid=301361", "title": "Bai Chongxi", "text": "Bai Chongxi\n\nBai Chongxi (18 March 1893 – 1 December 1966; ; , Xiao'erjing: ) was a Chinese general in the National Revolutionary Army of the Republic of China (ROC) and a prominent Chinese Nationalist leader. He was of Hui ethnicity and of the Muslim faith. From the mid-1920s to 1949, Bai and his close ally Li Zongren ruled Guangxi province as regional warlords with their own troops and considerable political autonomy. His relationship with Chiang Kai-shek was at various times antagonistic and cooperative. He and Li Zongren supported the anti-Chiang warlord alliance in the Central Plains War in 1930, then supported Chiang in the Second Sino-Japanese War and the Chinese Civil War. Bai was the first defense minister of the Republic of China from 1946-48. After losing to the Communists in 1949, he fled to Taiwan, where he died in 1966.\n\nBai was born in Guilin, Guangxi, and given the courtesy name Jiansheng (). He was a descendant of a Persian merchant of the name Baiderluden, whose descendants adopted the Chinese surname Bai. His Muslim name was Omar Bai Chongxi.\n\nHe was the second of three sons. His family was said to have come from Sichuan. At the age of 14 he attended the Guangxi Military Cadre Training School in Guilin, a modern-style school run by Cai E to modernize Guangxi's military. Bai and classmates Huang Shaohong and Li Zongren would become the three leading figures of Guangxi's military. For a time Bai withdrew from the military school at the request of his family and studied at the civilian Guangxi Schools of Law and Political Science.\n\nWith the outbreak of the Xinhai Revolution in 1911, under the leadership of Huang Shaoxiong, Bai joined a Students Dare to Die corps. After entering the Nanjing Enlistment Corps he transferred from the Corps to the Second Military Preparatory School at Wuchang. He graduated from the school in 1914, then underwent pre-cadet training for six months before attending the third class of Baoding Military Academy in June 1915. He became a 1st Guangxi Division probationary officer upon returning to Guangxi.\n\nBai rose to fame during the warlord era by allying with Huang Shaohong (a fellow deputy commander of the Model Battalion of the Guangxi First Division) and Li Tsung-jen as supporters of Kuomintang leader Sun Yat-sen. This alliance, called the New Guangxi Clique, proceeded to move against Guangxi warlord Lu Rongting in 1924. The coalition's efforts brought Guangxi Province under ROC jurisdiction, and Pai and Li represented a new generation of Guangxi leaders.\n\nThe Nationalist chief of staff (acting) was Bai. The 13th Army had him as the commander. The Nationalist Northern Punitive Expedition was participated in by Bai.\n\nDuring the Northern Expedition (1926–28) Bai was the Chief of Staff of the National Revolutionary Army and credited with many victories over the northern warlords, often using speed, maneuver and surprise to defeat larger enemy forces. He led the Eastern Route Army that conquered Hangzhou and Shanghai in 1927. As garrison commander of Shanghai, he also took part in the purge of Communist elements of the National Revolutionary Army on April 4, 1927, and of the labor unions in Shanghai. Bai also commanded the forward units that first entered Beijing and was credited with being the senior commander on site to complete the Northern Expedition. For many of his battlefield exploits during the Northern expedition, he was given the laudatory nickname Xiao Zhuge, literally \"little Zhuge Liang,\" of the Three Kingdoms fame.\nBai was the commander of Kuomintang forces in the Shanghai massacre of 1927, where he directed the KMT purge of Communists in the party.\n\nIn 1928, during the Northern Expedition, Bai led Kuomintang forces in the defeat and destruction of Fengtian Clique Gen. Zhang Zongchang, capturing 20,000 of his 50,000 troops and almost capturing Zhang himself, who escaped to Manchuria.\n\nBai personally had around 2,000 Muslims under his control during his stay in Beijing in 1928 after the Northern Expedition was completed; it was reported by TIME magazine that they \"swaggered riotously\" in the aftermath In June 1928 in Beijing, Bai Chongxi announced that the forces of the Kuomintang would seize control of Manchuria and the enemies of the Kuomintang would \"scatter like dead leaves before the rising wind\".\n\nBai was out of money and bankrupt in December 1928. He planned to lead 60,000 troops from east China to Xinjiang province and construct a railroad as a barrier against Russian encroachment in Xinjiang. His plan was perceived by some to be against Feng Yuxiang. The Military Council refused to authorize him leaving Peiping to go to Hankow.\n\nAt the end of the Northern Expedition, Chiang Kai-shek began to agitate to get rid of the Guangxi forces. At one time in 1929 Bai had to escape to Vietnam to avoid harm. Hubei and Guangxi were subjected to the Hankou subcouncil of Li Zongren and Bai Chongxi. Li and Bai's Hankou and Canton self-ruling governments were terminated by Chiang. Hankou was captured by Chiang during the dispute between the Guangxi faction and Nanjing. From 1930-36 Bai was instrumental in the Reconstruction of Guangxi, which became a \"model\" province with a progressive administration. Guangxi supplied over 900,000 soldiers to the war effort against Japan.\n\nDuring the Chinese Civil War Bai fought against the Communists. In the Long March he allowed the Communists to slip through Guangxi.\n\nGoverning his province aptly and capably were two of the things Bai was renowned for in China.\n\nProminent Muslims like Gen. Ma Liang), Ma Fuxiang and Bai Chongxi met in 1931 in Nanjing to discuss intercommunal tolerance between Hui and Han.\n\nThe 4th Army Groups chief of staff was Bai Chongxi.\n\nAn anti-Japanese war was called for by Bai Chongxi, Li Zongren and Chen Jitang in 1936. The mance posed by Japan was seen by Bai chongxi and Li Zongren.\n\nFormal hostilities broke out on 7 July 1937 between China and Japan with the Marco Polo Bridge Incident outside Beijing. On 4 August 1937 Bai rejoined the Central Government at the invitation of Chiang Kai-shek. During the Second Sino-Japanese War (1937–45), he was the Deputy Chief of the General Staff responsible for operations and training. He was the key strategist who convinced Chiang to adopt a \"Total War\" strategy in which China would trade space for time, adopt guerrilla tactics behind enemy lines and disrupt enemy supply lines at every opportunity. When the better armed and trained Japanese troops advanced, the Chinese would adopt a scorched earth campaign in the enemy's path to deny them local supply. Bai was also involved in many key campaigns including the first major victory at the Battle of Tai'erzhuang in Shandong Province in the spring of 1938 when he teamed up with Gen. Li Zongren to defeat a superior enemy. China managed to check and delay the Japanese advance for several months. Subsequently, Bai was appointed Commander of the Field Executive Office of the Military Council in Guilin, with responsibility for the 3rd, 4th, 7th and 9th War Zones. In that capacity he oversaw the successful defense of Changsha, capital of Hunan Province. Between 1939-42 the Japanese attacked Changsha three times and were repelled each time. Bai also directed the Battle of South Guangxi and Battle of Kunlun Pass to retake South Guangxi. The 64th Army and 46th Army were requested to be outfitted by Bai via Gen. Lindsey.\n\nBai's Guangxi soldiers were praised as a \"crack\"(as in elite) army during the war against Japan, and he was known to be an able general who could lead the Chinese resistance should Chiang Kai-shek be assassinated. The majority of Chinese presumed that Chiang Kai-shek, as leader of China, tapped Bai to inherit his position. Bai Chongxi led the competent Guangxi Army against the Japanese.\n\nIn refusing to obey commands from Chiang if he assumed them to be wrong and flawed, Bai Chongxi was alone among fellow military men.\n\nJihad was declared obligatory and a religious duty for all Chinese Muslims against Japan after 1937 during the Second Sino-Japanese War.\n\nBai also sheltered the Muslim Yuehua publication in Guilin, which printed quotes from the Quran and Hadith justifying the need for Chiang Kai-shek as leader of China.\n\nBai promoted Chinese nationalism and uniting Hui to the Han during the war against Japan.\n\nDuring the war, Bai traveled throughout the Muslim northwestern provinces of China controlled by the Ma Clique and met with Ma Clique generals to defeat Japanese propaganda.\n\nThe Hui Muslim Xidaotang sect pledged allegiance to the Kuomintang after their rise to power and Bai Chongxi acquainted Chiang Kai-shek with the Xidaotang jiaozhu Ma Mingren in 1941 in Chongqing.\n\nBai Chongxi headed the Chinese Islamic National Salvation Federation.\n\nFollowing the surrender of Japan in 1945, the Chinese Civil War resumed in full-fledged fighting. In the spring of 1946 the Chinese Communists were active in Manchuria. A crack People's Liberation Army unit of 100,000 strong under the Communist Gen. Lin Biao occupied a key railroad junction at Siping. Kuomintang forces could not dislodge them after several attempts; Chiang Kai-shek then sent Bai to oversee the operation. After some redeployment, Nationalist forces were able to decisively defeat Lin's forces after a two-day pitched battle. This was to be the first major victory for the Kuomintang in the 1946-49 stage of the civil war before the fall of mainland China to the Chinese Communists.\n\nIn June 1946 Bai was appointed Minister of National Defense. It turned to be a post without power, as Chiang began to bypass Bai on major decisions regarding the Chinese Civil War. Chiang would hold daily briefings in his residence without inviting Bai and began to direct front-line troops personally down to the division level, bypassing the chain of command. The Civil War went poorly for the Kuomintang as Chiang's strategy of holding onto provincial capitals and leaving the countryside to the Communists very quickly caused the downfall of his forces, which had a 4:1 numerical superiority at the beginning of the conflict.\n\nDuring the Ili Rebellion Bai was considered by the government for the post of Governor of Xinjiang. The position later was given to Masud Sabri, a pro-Kuomintang Uyghur leader.\n\nIn April 1948 the first National Assembly in China convened in Nanjing, with thousands of delegates from all over China representing different provinces and ethnic groups. Bai Chongxi, acting as Minister of National Defense, debriefed the Assembly on the military situation, completely ignoring Northern China and Manchuria in his report. Delegates from Manchuria in the assembly responded by yelling out and calling for the death of those responsible for the loss of Manchuria.\n\nIn November 1948 Bai, in command of forces in Hankow, met with Generals Fu Zuoyi, Chang Chih-chung and Chiang Kai-shek in Nanjing about defending Suzhou, the gateway to the Yangzi River valley.\n\nBai told the Central Political Council of the Kuomintang that negotiating with the Communists would only make them more powerful. Governor of Hunan Cheng Qian, and Bai reached a consensus that they should impede the advance of the Communists by negotiating with them.\n\nIn January 1949, with the Communists close to victory, almost everyone in the Nationalist media, political and military command began to demand peace as a slogan and turn against Chiang. Bai Chongxi decided to follow suit with the mainstream current and defied Chiang Kai-shek's orders, refusing to battle Communists near the Huai River and demanding that his soldiers, which were \"lent\", be sent back to him so he could secure his hold n the province of Guangxi and ignore the central government in Nanjing. Bai was the commander of four armies in Central China in the Hankow region. He demanded that the government negotiate with the Communists like the others. Bai was in charge of the defense of the capital, Nanjing. He sent a telegram requesting that Chiang Kai-shek step down as President, amid a storm of requests by other Kuomintang military and political figures for Chiang to step down and allow a peace deal with the Communists.\n\nWhen Communist Gen. Lin Biao mounted an attack on Bai Chongxi's forces in Hankow, they retreated quickly, leaving the \"rice bowl\" of China open for the Communists. Bai retreated to Headquarters at Hengyang via a railroad from Hankow to Canton. The railroad then provided access to Guilin where his home was. In August at Hengyang, Bai Chongxi reorganized his troops. In October, as the Canton fell to the Communists, who were almost in complete control of China, Bai Chongxi still commanded 200,000 of his elite troops, making a return to Guangxi for a final stand after covering for Canton.\n\nThe riots following the February 28 Incident of 28 February 1947 that broke out in Taiwan due to poor governance by the central government appointed officials and the garrison forces caused many casualties of both native Taiwanese and mainland residents. Bai was sent as Chiang Kai-shek's personal representative on a fact finding mission and to help pacify the populace. After a two-week tour, including interviews with various segments of the Taiwan population, Bai made sweeping recommendations, including replacement of the governor, and prosecution of his chief of secret police. He also granted amnesty to student violators of peace on the condition that their parents take custody and guarantee subsequent proper behavior. For his forthright actions, native Taiwanese held him in high regard.\n\nBai had another falling out with Chiang when he supported General Li Zongren, his fellow Guangxi comrade-in-arms, for the vice presidency in the 1948 general election when Li won against Chiang's hand picked candidate, Sun Fo. Chiang then removed Bai from the Defense Minister post and assigned him the responsibility for Central and South China. Bai's forces were the last ones to leave the mainland for Hainan Island and eventually to Taiwan.\n\nHe served Chief of the General Staff since 1927 until his retirement in 1949. After he came to Taiwan, he was the appointed vice director of the strategic advisory commission in the presidential office. He also continued to serve in the Central Executive Committee of the Kuomintang. He reorganized the party from 1950-1952.\n\nAfter the Communist victory, some of Bai Chongxi's Guangxi troops fled to French Indochina where they were detained. Others went to Hainan in retreat.\n\nIn 1951, Bai Chongxi made a speech to the entire Muslim world calling for a war against the Soviet Union, claiming that the \"imperialist ogre\" leader Joseph Stalin was engineering World War III, and Bai also called upon Muslims to avoid the Indian leader Jawaharlal Nehru, accusing him of being blind to Soviet imperialism.\n\nHe and Chiang never reconciled and he lived in semi-retirement until he died of coronary thrombosis on 1 December 1966 at the age of 73. Bai was then given a military funeral by the government, with a Kuomintang Blue Sky with a White Sun flag over his coffin. Bai was buried in the Muslim section of the Liuzhangli (六張犁) Cemetery in Taipei, Taiwan.\n\nAs a Muslim, he was Chairman of the Chinese Islamic National Salvation Federation, and then the Chinese Muslim Association. Bai Chongxi was a board member of the All-China Inter-religious Association, representing Islam, the other members of the board were a Catholic Bishop, Methodist Bishop, and the Buddhist Abbot Taixu.\n\nBai sent his son Pai Hsien-yung to Catholic schools in Hong Kong.\n\nDuring the Northern Expedition, in 1926 in Guangxi, Bai Chongxi led his troops in destroying Buddhist temples and smashing idols, turning the temples into schools and Kuomintang party headquarters. It was reported that almost all of Buddhist monasteries in Guangxi were destroyed by Bai in this manner. The monks were removed. Bai led a wave of anti-foreignism in Guangxi, attacking American, European, and other foreigners and missionaries, and generally making the province unsafe for foreigners. Westerners fled from the province, and some Chinese Christians were also attacked as imperialist agents.\n\nThe three goals of his movement were anti-foreignism, anti-imperialism, and anti-religion. Bai led the anti-religious movement, against superstition. Huang Shaoxiong, also a Kuomintang member of the New Guangxi Clique, supported Bai's campaign, and Huang was a non-Muslim, the anti religious campaign was agreed upon by all Guangxi Kuomintang members, so it may have not had anything to do with Bai's beliefs.\n\nAs a Kuomintang member, Bai and the other Guangxi clique members allowed the Communists to continue attacking foreigners and idols, since they shared the goal of expelling the foreign powers from China, but they stopped Communists from initiating social change.\n\nBritish diplomats reported that he also drank wine and ate pork.\n\nBai Chongxi was interested in Xinjiang, a predominately Muslim province. He wanted to resettle disbanded Chinese soldiers there to prevent it from being seized by the Soviet Union. Bai personally wanted to lead an expedition to seize back Xinjiang to bring it under Chinese control, in the style that Zuo Zongtang led during the Dungan revolt. Bai's partner in the Guangxi clique Huang Shaohong planned an invasion of Xinjiang. During the Kumul Rebellion Chiang Kai-shek was ready to send Huang Shaohong and his expeditionary force which he assembled to assist Muslim General Ma Zhongying against Sheng Shicai, but when Chiang heard about the Soviet Invasion of Xinjiang, he decided to withdraw to avoid an international incident if his troops directly engaged the Soviets, leaving Ma alone with not reinforcements to fight the Red Army. Huang was suspicious of this, suspecting that Chiang feared that the Guangxi clique was take control of Xinjiang rather than Chiang's Nanjing regime.\n\nBai's reputation as a military strategist was well known. Evans Carlson, a United States Marine Corps colonel, noted that Bai \"was considered by many to be the keenest of Chinese military men.\" Edgar Snow went even further, calling him \"one of the most intelligent and efficient commanders boasted by any army in the world.\"\n\nBai is the father of Kenneth Hsien-yung Pai, Chinese author and playwright now living in the United States.\nBai and his wife had ten children, three girls and seven boys. Their names are Patsy, Diana, Daniel, Richard, Alfred, Amy, David, Kenneth, Robert and Charlie. He married his wife Ma P'ei-chang in 1925.\n\nOf his ten children, three are still living, scattered across America and Taiwan. Taipei Mayor Hau Lung-pin announced in March 2013 that Bai's tomb will form the basis for a Muslim cultural area and Taiwan historical park.\n\n\n"}
{"id": "2445958", "url": "https://en.wikipedia.org/wiki?curid=2445958", "title": "Carl McCunn", "text": "Carl McCunn\n\nCarl McCunn (1946 – December 18, 1981) was an American wildlife photographer who became stranded in the Alaskan wilderness and eventually committed suicide when he ran out of supplies.\n\nMcCunn was born in Germany, when his father Donovan McCunn was in the United States Army, and was raised in San Antonio, Texas. He graduated from high school in 1964 and enlisted in the U.S. Navy shortly after dropping out of community college. McCunn served in the Navy for four years and was discharged in 1969. He briefly lived in Seattle, Washington before settling in Anchorage, Alaska in 1970.\n\nMcCunn had lived five months on the Brooks Range in 1976. In March 1981, he paid a bush pilot to land him at a remote lake approximately 225 miles northeast of Fairbanks, near the Coleen River, in the Alaskan wilderness, on the southern margin of the Brooks Range. McCunn intended to photograph wildlife for about five months. On this trip, he flew in with 500 rolls of film, 1,400 pounds of provisions, two rifles, and a shotgun. Not believing he would need them, he prematurely disposed of boxes of shotgun shells in the river near his camp. Although McCunn thought he had arranged for the pilot to return for him in August, he had apparently never confirmed this. In early August, when the expected plane had not arrived, he wrote in his diary, \"I think I should have used more foresight about arranging my departure. I'll soon find out.\"\n\nBy mid-August, it became obvious to McCunn that the bush pilot was not going to return for him. At this point he attempted to make his provisions last longer by shooting local game. He shot ducks, muskrats, and tried drying the meat of a caribou he observed die in the lake. At this point, McCunn's diary indicated his hope that his family or friends would send someone to look for him after he failed to return was gone. McCunn had sent three maps with his campsite marked to some friends and his father, but was not clear about his exact itinerary. Although his father knew he would be in the area, he did not know when McCunn planned on returning. McCunn had also told his father not to be concerned if he did not return at the end of the summer, as he might stay later in the season if things went well.\n\nAn Alaska State Trooper flew over the lake in late August and observed McCunn's campsite. The pilot did not sense McCunn was in distress, since he waved a red bag very casually and, on his third pass of the campsite, he saw McCunn casually walking back to his tent. The State Trooper later testified he saw no reason to surmise McCunn needed any assistance. McCunn later wrote in his diary: \"I recall raising my right hand, shoulder high and shaking my fist on the plane's second pass. It was a little cheer like when your team scored a touchdown or something. Turns out that's the signal for 'ALL O.K. DO NOT WAIT!' Man, I can't believe it!\"\n\nA state trooper, who spoke with McCunn before his trip and helped him mark his campsite on a map, stated that McCunn was aware of a hunting cabin located five miles from his campsite. It is unclear why he did not use it when the weather began getting colder. Eventually snow began falling, and the lake froze. Game became increasingly scarce, and McCunn set snares for rabbits, but the traps were frequently raided by wolves and foxes. By November, McCunn had run out of food. He considered trying to walk to Fort Yukon, approximately 75 miles away, but was unable to make the trek due to snow and his weakened condition. By November 26 he wrote of having dizzy spells and almost constant chills.\n\nSometime soon afterward, McCunn decided to commit suicide. He used all his remaining fuel supplies to create a warm fire. He wrote, “Dear God in Heaven, please forgive me my weakness and my sins. Please look over my family.” He wrote a letter to his father instructing him how to develop his film. He also requested that all his personal belongings be given to his father by whoever found him. McCunn even suggested that the person who found him take his rifle and shotgun for their trouble. He then pinned his Alaska driver's license to the note and shot himself with his rifle. Just before his suicide he wrote in his diary: \"They say it doesn't hurt.\"\n\nBy January, McCunn's friends became concerned enough to request the authorities begin a search for him. On February 2, 1982, a ski-equipped plane carrying several State Troopers landed at the lake to check McCunn's campsite. They found his tent zipped shut and, upon cutting it open, discovered his corpse, emaciated and frozen, along with his 100-page diary.\n\n"}
{"id": "174609", "url": "https://en.wikipedia.org/wiki?curid=174609", "title": "Chicxulub crater", "text": "Chicxulub crater\n\nThe Chicxulub crater (; ) is an impact crater buried underneath the Yucatán Peninsula in Mexico. Its center is located near the town of Chicxulub, after which the crater is named. It was formed by a large asteroid or comet about in diameter, the Chicxulub impactor, striking the Earth. The date of the impact coincides precisely with the Cretaceous–Paleogene boundary (K–Pg boundary), slightly less than 66 million years ago, and a widely accepted theory is that worldwide climate disruption from the event was the cause of the Cretaceous–Paleogene extinction event, a mass extinction in which 75% of plant and animal species on Earth became extinct, including all non-avian dinosaurs.\n\nThe crater is estimated to be in diameter and in depth, well into the continental crust of the region of about depth. It is the second largest confirmed impact structure on Earth and the only one whose peak ring is intact and directly accessible for scientific research.\n\nThe crater was discovered by Antonio Camargo and Glen Penfield, geophysicists who had been looking for petroleum in the Yucatán during the late 1970s. Penfield was initially unable to obtain evidence that the geological feature was a crater and gave up his search. Later, through contact with Alan Hildebrand in 1990, Penfield obtained samples that suggested it was an impact feature. Evidence for the impact origin of the crater includes shocked quartz, a gravity anomaly, and tektites in surrounding areas.\n\nIn 2016, a scientific drilling project drilled deep into the peak ring of the impact crater, hundreds of meters below the current sea floor, to obtain rock core samples from the impact itself. The discoveries were widely seen as confirming current theories related to both the crater impact and its effects.\n\nIn 1978, geophysicists Glen Penfield and Antonio Camargo were working for the Mexican state-owned oil company Petróleos Mexicanos, or Pemex, as part of an airborne magnetic survey of the Gulf of Mexico north of the Yucatán peninsula. Penfield's job was to use geophysical data to scout possible locations for oil drilling. In the data, Penfield found a huge underwater arc with \"extraordinary symmetry\" in a ring across. He then obtained a gravity map of the Yucatán made in the 1960s. A decade earlier, the same map suggested an impact feature to contractor Robert Baltosser, but he was forbidden to publicize his conclusion by Pemex corporate policy of the time. Penfield found another arc on the peninsula itself, the ends of which pointed northward. Comparing the two maps, he found the separate arcs formed a circle, wide, centered near the Yucatán village Chicxulub; he felt certain the shape had been created by a cataclysmic event in geologic history.\n\nPemex disallowed release of specific data but let Penfield and company official Antonio Camargo present their results at the 1981 Society of Exploration Geophysicists conference. That year's conference was underattended and their report attracted scant attention. Coincidentally, many experts in impact craters and the K–Pg boundary were attending a separate conference on Earth impacts. Although Penfield had plenty of geophysical data sets, he had no rock cores or other physical evidence of an impact.\n\nHe knew Pemex had drilled exploratory wells in the region. In 1951, one bored into what was described as a thick layer of andesite about down. This layer could have resulted from the intense heat and pressure of an Earth impact, but at the time of the borings it was dismissed as a lava dome—a feature uncharacteristic of the region's geology. Penfield tried to secure site samples, but was told such samples had been lost or destroyed. When attempts at returning to the drill sites and looking for rocks proved fruitless, Penfield abandoned his search, published his findings and returned to his Pemex work.\nAt the same time, in 1980, geologist Walter Alvarez and his father, Nobel Prize-winning scientist Luis Walter Alvarez, put forth his hypothesis that a large extraterrestrial body had struck Earth. In 1981, unaware of Penfield's discovery, University of Arizona graduate student Alan R. Hildebrand and faculty adviser William V. Boynton published a draft Earth-impact theory and sought a candidate crater. Their evidence included greenish-brown clay with surplus iridium containing shocked quartz grains and small weathered glass beads that looked to be tektites. Thick, jumbled deposits of coarse rock fragments were also present, thought to have been scoured from one place and deposited elsewhere by a megatsunami resulting from an Earth impact. Such deposits occur in many locations but seem concentrated in the Caribbean basin at the K–Pg boundary. So when Haitian professor Florentine Morás discovered what he thought to be evidence of an ancient volcano on Haiti, Hildebrand suggested it could be a telltale feature of a nearby impact. Tests on samples retrieved from the K–Pg boundary revealed more tektite glass, formed only in the heat of asteroid impacts and high-yield nuclear detonations.\n\nIn 1990, \"Houston Chronicle\" reporter Carlos Byars told Hildebrand of Penfield's earlier discovery of a possible impact crater. Hildebrand contacted Penfield in April 1990 and the pair soon secured two drill samples from the Pemex wells, stored in New Orleans. Hildebrand's team tested the samples, which clearly showed shock-metamorphic materials.\n\nA team of California researchers including Kevin Pope, Adriana Ocampo, and Charles Duller, surveying regional satellite images in 1996, found a cenote (sinkhole) ring centered on Chicxulub that matched the one Penfield saw earlier; the cenotes were thought to be caused by subsidence of bolide-weakened lithostratigraphy around the impact crater wall. More recent evidence suggests the actual crater is wide, and the 180 km ring is in fact an inner wall of it.\n\nResearchers at the University of Glasgow dated tektite samples from the impact as 66,038,000 ± 11,000 years old.\n\nThe Chicxulub impactor had an estimated diameter of , and delivered an estimated energy of 10 billion Hiroshima A-bombs (about formula_1joules, or 100,000 EJ). By contrast, the most powerful man-made explosive device ever detonated, the Tsar Bomba, had an energy of only 210 petajoules (formula_2 joules, the yield of 50 megatons of TNT). The object dug a hole wide and deep, leaving a crater mainly under the sea and covered by of sediment by the 21st century.\n\nThe impact would have caused a megatsunami over tall that would have reached all the way to what are now Texas and Florida. The height of the tsunami was limited by the relatively shallow sea in the area of the impact; in deep ocean it would have been tall. A cloud of super-heated dust, ash and steam would have spread from the crater as the impactor burrowed underground in less than a second. Excavated material along with pieces of the impactor, ejected out of the atmosphere by the blast, would have been heated to incandescence upon re-entry, broiling the Earth's surface and possibly igniting wildfires; meanwhile, colossal shock waves would have triggered global earthquakes and volcanic eruptions. Fossil evidence for an instantaneous die-off of diverse animals was found in a soil layer only thick in New Jersey some away from the impact site, indicating that death and burial under debris occurred suddenly and quickly over wide distances on land.\n\nThe emission of dust and particles could have covered the entire surface of the Earth for several years, possibly a decade, creating a harsh environment for living things. The shock production of carbon dioxide caused by the destruction of carbonate rocks would have led to a sudden greenhouse effect. Over a decade or longer, sunlight would have been blocked from reaching the surface of the Earth by the dust particles in the atmosphere, cooling the surface dramatically. Photosynthesis by plants would also have been interrupted, affecting the entire food chain. A model of the event developed by Lomax et al. (2001) suggests that net primary productivity (NPP) rates may have increased to higher than pre-impact levels over the long term because of the high carbon dioxide concentrations.\n\nIn February 2008, a team of researchers led by Sean Gulick at the University of Texas at Austin's Jackson School of Geosciences used seismic images of the crater to determine that the impactor landed in deeper water than was previously assumed. They argued that this would have resulted in increased sulfate aerosols in the atmosphere. According to the press release, that \"could have made the impact deadlier in two ways: by altering climate (sulfate aerosols in the upper atmosphere can have a cooling effect) and by generating acid rain (water vapor can help to flush the lower atmosphere of sulfate aerosols, causing acid rain).\" This was borne out by the results of a drilling project in 2016 which found that sulfate-containing rocks found in the area were not found in the peak ring (the rocks found were from deep within the earth's crust instead), the interpretation being that they had been vaporized by the impact and dispersed into the atmosphere.\n\nA long-term local effect of the impact was the creation of the Yucatán sedimentary basin which \"ultimately produced favorable conditions for human settlement in a region where surface water is scarce.\"\n\nIn their 1991 paper, Hildebrand, Penfield, and company described the geology and composition of the impact feature. The rocks above the impact feature are layers of marl and limestone reaching to a depth of almost . These rocks date back as far as the Paleocene. Below these layers lie more than of andesite glass and breccia. These andesitic igneous rocks were only found within the supposed impact feature, as is shocked quartz. The K–Pg boundary inside the feature is depressed to compared with the normal depth of about measured away from the impact feature. Along the edge of the crater are clusters of cenotes or sinkholes, which suggest that there was a water basin inside the feature during the Neogene period, after the impact. The groundwater of such a basin would have dissolved the limestone and created the caves and cenotes beneath the surface. The paper also noted that the crater seemed to be a good candidate source for the tektites reported at Haiti.\n\nIn September 2007, a report published in \"Nature\" proposed an origin for the asteroid that created the Chicxulub crater. The authors, William F. Bottke, David Vokrouhlický, and David Nesvorný, argued that a collision in the asteroid belt 160 million years ago resulted in the Baptistina family of asteroids, the largest surviving member of which is 298 Baptistina. They proposed that the \"Chicxulub asteroid\" was also a member of this group. The connection between Chicxulub and Baptistina is supported by the large amount of carbonaceous material present in microscopic fragments of the impactor, suggesting the impactor was a member of a rare class of asteroids called carbonaceous chondrites, like Baptistina. According to Bottke, the Chicxulub impactor was a fragment of a much larger parent body about across, with the other impacting body being around in diameter. In 2011, new data from the Wide-field Infrared Survey Explorer revised the date of the collision which created the Baptistina family to about 80 million years ago. This makes an asteroid from this family highly improbable to be the asteroid that created the Chicxulub crater, as typically the process of resonance and collision of an asteroid takes many tens of millions of years. In 2010, another hypothesis was offered which implicated the newly discovered asteroid P/2010 A2, a member of the Flora family of asteroids, as a possible remnant cohort of the K/Pg impactor.\n\nThe Chicxulub Crater lends support to the theory postulated by the late physicist Luis Alvarez and his son, geologist Walter Alvarez, that the extinction of numerous animal and plant groups, including non-avian dinosaurs, may have resulted from a bolide impact (the Cretaceous–Paleogene extinction event). Luis and Walter Alvarez, at the time both faculty members at the University of California, Berkeley, postulated that this enormous extinction event, which was roughly contemporaneous with the postulated date of formation for the Chicxulub crater, could have been caused by just such a large impact. The age of the rocks marked by the impact shows that this impact structure dates from roughly 66 million years ago, the end of the Cretaceous period, and the start of the Paleogene period. It coincides with the K–Pg boundary, the geological boundary between the Cretaceous and Paleogene. The impact associated with the crater is thus implicated in the Cretaceous–Paleogene extinction event, including the worldwide extinction of non-avian dinosaurs. This conclusion has been the source of controversy. In March 2010, forty-one experts from many countries reviewed the available evidence: 20 years' worth of data spanning a variety of fields. They concluded that the impact at Chicxulub triggered the mass extinctions at the K–Pg boundary. In 2013 a study compared isotopes in impact glass from the Chicxulub impact with the same isotopes in ash from the boundary where the extinction event occurred in the fossil record; the study concluded that the impact glasses were dated at 66.038 ± 0.049 Ma, and the deposits immediately above the discontinuity in the geological and fossil record was dated to 66.019 ± 0.021 Ma, the two dates being within 19,000 years of each other, or almost exactly the same within experimental error. The theory is now widely accepted by the scientific community. Some critics, including paleontologist Robert Bakker, argue that such an impact would have killed frogs as well as dinosaurs, yet the frogs survived the extinction event. Gerta Keller of Princeton University argues that recent core samples from Chicxulub prove the impact occurred about 300,000 years \"before\" the mass extinction, and thus could not have been the causal factor. However, this conclusion is unsupported by radioactive dating and sedimentology.\n\nThe main evidence of such an impact, besides the crater itself, is contained in a thin layer of clay present in the K–Pg boundary across the world. In the late 1970s, the Alvarezes and colleagues reported that it contained an abnormally high concentration of iridium. Iridium levels in this layer reached 6 parts per billion by weight or more compared to 0.4 for the Earth's crust as a whole; in comparison, meteorites can contain around 470 parts per billion of this element. It was hypothesized that the iridium was spread into the atmosphere when the impactor was vaporized and settled across the Earth's surface amongst other material thrown up by the impact, producing the layer of iridium-enriched clay. Similarly, an iridium anomaly in core samples from the Pacific Ocean suggested the Eltanin impact of about 2.5 million years ago.\n\nIn recent years, several other craters of around the same age as Chicxulub have been discovered, all between latitudes 20°N and 70°N. Examples include the disputed Silverpit crater in the North Sea and the Boltysh crater in Ukraine. Both are much smaller than Chicxulub, but are likely to have been caused by objects many tens of meters across striking the Earth. This has led to the hypothesis that the Chicxulub impact may have been only one of several impacts that happened nearly at the same time. Another possible crater thought to have been formed at the same time is the larger Shiva crater, though the structure's status as an impact crater is contested.\n\nThe collision of Comet Shoemaker–Levy 9 with Jupiter in 1994 demonstrated that gravitational interactions can fragment a comet, giving rise to many impacts over a period of a few days if the comet should collide with a planet. Comets undergo gravitational interactions with the gas giants, and similar disruptions and collisions are very likely to have occurred in the past. This scenario may have occurred on Earth at the end of the Cretaceous, though Shiva and the Chicxulub craters might have been formed 300,000 years apart.\n\nIn late 2006, Ken MacLeod, a geology professor from the University of Missouri, completed an analysis of sediment below the ocean's surface, bolstering the single-impact theory. MacLeod conducted his analysis approximately from the Chicxulub crater to control for possible changes in soil composition at the impact site, while still close enough to be affected by the impact. The analysis revealed there was only one layer of impact debris in the sediment, which indicated there was only one impact. Multiple-impact proponents such as Gerta Keller regard the results as \"rather hyper-inflated\" and do not agree with the conclusion of MacLeod's analysis, arguing that there might only be gaps of hours to days between impacts in a multiple-impact scenario (cf. Shoemaker-Levy 9) which would not leave a detectable gap in deposits.\n\nChicxulub is the only known Earth crater with a remaining impact peak ring, but it is under of sediment. During April and May 2016, a joint IODP-ICDP Mission Specific Platform Expedition no. 364 obtained the first offshore core samples from the peak ring, the central zone of the crater. During Expedition 364, DES drillers on the \"L/B Myrtle\" collected core samples to enable ECORD Science Party members to study how the peak ring formed and calculate the total impact energy.\n\nTheir target depth was below the bottom of the ocean, but they reached an acceptable 1,335 m. Sample preparation and analysis are being performed at Bremen, Germany.\n\nIt was announced in November 2016 that pink granite, usually found deep in the Earth's crust, had been found in drilling samples. It suggests the impact was so great it shocked and melted rocks found deep in the crust, causing them to shoot up before falling back down to produce the peak rings. The granite samples were also found to be lighter and weaker than normal granite, a result of the shock and extreme conditions of the impact. The findings confirmed that the rock comprising the peak ring had originated deep in the earth, and was ejected to the surface. It had been subjected to immense pressures and forces and had been melted by heat and shocked by pressure from its usual state into its present form in just minutes; the fact that the peak ring was made of granite was also significant, since granite is not a rock found in sea-floor deposits, originating much deeper in the earth, and had been ejected to the surface by the immense pressures of impact. Gypsum, a sulfate-containing rock that \"is\" usually present in the shallow seabed of the region, had been almost entirely removed and likely vaporized to enter the atmosphere, an event immediately followed by a megatsunami sufficient to lay down the largest-known layered bed of sand, around 100 m deep and separated by grain size, directly above the peak ring. These types of sand deposits are caused by extreme water movement, where the larger and heavier sand grains settle first, followed by lighter and smaller grains.\n\nTaken together, analyses indicate that the impactor was large enough to create a 120-mile peak ring, to melt, shock and eject granite from many miles within the earth, to create colossal water movements, and to eject an immense quantity of vaporized rock and sulfates into the atmosphere, where they would have persisted over years to decades. This global dispersal of dust and sulfates would have led to a sudden and catastrophic effect on the climate worldwide, large temperature drops, and devastated the food chain. The researchers stated that the impact generated an environmental calamity that extinguished life, but it also induced a vast subsurface hydrothermal system that became an oasis for the recovery of life.\n\nA program on British television described that the drilling revealed, from top down: thick Cenozoic limestone; a graded sediment deposit from one tsunami, over 100 m thick; the impact melted basement granite from the Earth's midcrust and shocked quartz. The peak ring itself did not contain the calcium sulphate that the rocks in the area around contain, leading the program makers to conclude that all the calcium sulphate in the crater area had been vaporized into the atmosphere and had become a dense sulphur dioxide veil stopping the sunlight. As additional clues of the resulting megatsunami represented in a New Jersey quarry, a dense marine bone bed was found on the Cretaceous–Paleogene boundary containing a mixture of dead sea animals with little or no damage from scavengers or predators. Also related to this tsunami was a dense dinosaur bone bed on the Cretaceous–Paleogene boundary found in Patagonia.\n\n\n\n"}
{"id": "3083894", "url": "https://en.wikipedia.org/wiki?curid=3083894", "title": "Contractualism", "text": "Contractualism\n\nContractualism is a term in philosophy that refers either to a family of political theories in the social contract tradition (when used in this sense, the term is synonymous with contractarianism), or to the ethical theory developed in recent years by T. M. Scanlon, especially in his book \"What We Owe to Each Other\".\n\nSocial contract theorists from the history of political thought include Hugo Grotius (1625), Thomas Hobbes (1651), Samuel Pufendorf (1673), John Locke (1689), Jean-Jacques Rousseau (1762), and Immanuel Kant (1797); more recently, John Rawls (1971), David Gauthier (1986) and Philip Pettit (1997).\n\n"}
{"id": "40409788", "url": "https://en.wikipedia.org/wiki?curid=40409788", "title": "Convolutional neural network", "text": "Convolutional neural network\n\nIn deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep, feed-forward artificial neural networks, most commonly applied to analyzing visual imagery.\n\nCNNs use a variation of multilayer perceptrons designed to require minimal preprocessing. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.\n\nConvolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\n\nCNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns the filters that in traditional algorithms were hand-engineered. This independence from prior knowledge and human effort in feature design is a major advantage.\n\nThey have applications in image and video recognition, recommender systems, image classification, medical image analysis, and natural language processing.\n\nA CNN consists of an input and an output layer, as well as multiple hidden layers. The hidden layers of a CNN typically consist of convolutional layers, pooling layers, fully connected layers and normalization layers.\n\nDescription of the process as a convolution in neural networks is by convention. Mathematically it is a cross-correlation rather than a convolution (although cross-correlation is a related operation). This only has significance for the indices in the matrix, and thus which weights are placed at which index.\n\nConvolutional layers apply a convolution operation to the input, passing the result to the next layer. The convolution emulates the response of an individual neuron to visual stimuli.\n\nEach convolutional neuron processes data only for its receptive field. Although fully connected feedforward neural networks can be used to learn features as well as classify data, it is not practical to apply this architecture to images. A very high number of neurons would be necessary, even in a shallow (opposite of deep) architecture, due to the very large input sizes associated with images, where each pixel is a relevant variable. For instance, a fully connected layer for a (small) image of size 100 x 100 has 10000 weights for \"each\" neuron in the second layer. The convolution operation brings a solution to this problem as it reduces the number of free parameters, allowing the network to be deeper with fewer parameters. For instance, regardless of image size, tiling regions of size 5 x 5, each with the same shared weights, requires only 25 learnable parameters. In this way, it resolves the vanishing or exploding gradients problem in training traditional multi-layer neural networks with many layers by using backpropagation.\n\nConvolutional networks may include local or global pooling layers, which combine the outputs of neuron clusters at one layer into a single neuron in the next layer. For example, \"max pooling\" uses the maximum value from each of a cluster of neurons at the prior layer. Another example is \"average pooling\", which uses the average value from each of a cluster of neurons at the prior layer.\n\nFully connected layers connect every neuron in one layer to every neuron in another layer. It is in principle the same as the traditional multi-layer perceptron neural network (MLP).\n\nIn neural networks, each neuron receives input from some number of locations in the previous layer. In a fully connected layer, each neuron receives input from \"every\" element of the previous layer. In a convolutional layer, neurons receive input from only a restricted subarea of the previous layer. Typically the subarea is of a square shape (e.g., size 5 by 5). The input area of a neuron is called its \"receptive field\". So, in a fully connected layer, the receptive field is the entire previous layer. In a convolutional layer, the receptive area is smaller than the entire previous layer.\n\nEach neuron in a neural network computes an output value by applying some function to the input values coming from the receptive field in the previous layer. The function that is applied to the input values is specified by a vector of weights and a bias (typically real numbers). Learning in a neural network progresses by making incremental adjustments to the biases and weights. The vector of weights and the bias are called a \"filter\" and represents some feature of the input (e.g., a particular shape). A distinguishing feature of CNNs is that many neurons share the same filter. This reduces memory footprint because a single bias and a single vector of weights is used across all receptive fields sharing that filter, rather than each receptive field having its own bias and vector of weights.\n\nCNN design follows vision processing in living organisms.\n\nWork by Hubel and Wiesel in the 1950s and 1960s showed that cat and monkey visual cortexes contain neurons that individually respond to small regions of the visual field. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field. Neighboring cells have similar and overlapping receptive fields. Receptive field size and location varies systematically across the cortex to form a complete map of visual space. The cortex in each hemisphere represents the contralateral visual field.\n\nTheir 1968 paper identified two basic visual cell types in the brain:\n\n\nThe \"neocognitron\" was introduced in 1980. The neocognitron does not require units located at multiple network positions to have the same trainable weights. This idea appears in 1986 in the book version of the original back-propagation paper. Neocognitrons were developed in 1988 for temporal signals. Their design was improved in 1998, generalized in 2003 and simplified in the same year.\n\nThe time delay neural network (TDNN) was the first convolutional network.\n\nTDNNs are fixed-size convolutional networks that share weights along the temporal dimension They allow speech signals to be processed time-invariantly, analogous to the translation invariance offered by CNNs. They were introduced in the early 1980s. The tiling of neuron outputs can cover timed stages.\n\nA system to recognize hand-written ZIP Code numbers involved convolutions in which the kernel coefficients had been laboriously hand designed.\n\nYann LeCun et al. (1989) used back-propagation to learn the convolution kernel coefficients directly from images of hand-written numbers. Learning was thus fully automatic, performed better than manual coefficient design, and was suited to a broader range of image recognition problems and image types.\n\nLeNet-5, a pioneering 7-level convolutional network by LeCun et al. in 1998, that classifies digits, was applied by several banks to recognize hand-written numbers on checks () digitized in 32x32 pixel images. The ability to process higher resolution images requires larger and more layers of convolutional neural networks, so this technique is constrained by the availability of computing resources.\n\nSimilarly, a shift invariant neural network was proposed for image character recognition in 1988. The architecture and training algorithm were modified in 1991 and applied for medical image processing and automatic detection of breast cancer in mammograms.\n\nA different convolution-based design was proposed in 1988 for application to decomposition of one-dimensional electromyography convolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.\n\nThe feed-forward architecture of convolutional neural networks was extended in the neural abstraction pyramid by lateral and feedback connections. The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities. In contrast to previous models, image-like outputs at the highest resolution were generated.\n\nFollowing the 2005 paper that established the value of GPGPU for machine learning, several publications described more efficient ways to train convolutional neural networks using GPUs. In 2011, they were refined and implemented on a GPU, with impressive results. In 2012, Ciresan et al. significantly improved on the best performance in the literature for multiple image databases, including the MNIST database, the NORB database, the HWDB1.0 dataset (Chinese characters) and the CIFAR10 dataset (dataset of 60000 32x32 labeled RGB images).\n\nTraditional multilayer perceptron (MLP) models were successfully used for image recognition. However, due to the full connectivity between nodes they suffer from the curse of dimensionality, and thus do not scale well to higher resolution images. A 1000×1000 pixel image with RGB color channels has 3 million dimensions, which is too high to feasibly process efficiently at scale with full connectivity.\n\nFor example, in CIFAR-10, images are only of size 32×32×3 (32 wide, 32 high, 3 color channels), so a single fully connected neuron in a first hidden layer of a regular neural network would have 32*32*3 = 3,072 weights. A 200×200 image, however, would lead to neurons that have 200*200*3 = 120,000 weights.\n\nAlso, such network architecture does not take into account the spatial structure of data, treating input pixels which are far apart in the same way as pixels that are close together. This ignores locality of reference in image data, both computationally and semantically. Thus, full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by spatially local input patterns.\n\nConvolutional neural networks are biologically inspired variants of multilayer perceptrons that are designed to emulate the behavior of a visual cortex. These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images. As opposed to MLPs, CNNs have the following distinguishing features:\n\nTogether, these properties allow CNNs to achieve better generalization on vision problems. Weight sharing dramatically reduces the number of free parameters learned, thus lowering the memory requirements for running the network and allowing the training of larger, more powerful networks.\n\nA CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume (e.g. holding the class scores) through a differentiable function. A few distinct types of layers are commonly used. These are further discussed below.\n\nThe convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input and producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.\n\nStacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input and shares parameters with neurons in the same activation map.\n\nWhen dealing with high-dimensional inputs such as images, it is impractical to connect neurons to all neurons in the previous volume because such a network architecture does not take the spatial structure of the data into account. Convolutional networks exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.\n\nThe extent of this connectivity is a hyperparameter called the receptive field of the neuron. The connections are local in space (along width and height), but always extend along the entire depth of the input volume. Such an architecture ensures that the learnt filters produce the strongest response to a spatially local input pattern.\n\nThree hyperparameters control the size of the output volume of the convolutional layer: the depth, stride and zero-padding.\n\n\nThe spatial size of the output volume can be computed as a function of the input volume size formula_3, the kernel field size of the convolutional layer neurons formula_4, the stride with which they are applied formula_5, and the amount of zero padding formula_6 used on the border. The formula for calculating how many neurons \"fit\" in a given volume is given by\n\nformula_7 \n\nIf this number is not an integer, then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a symmetric way. In general, setting zero padding to be formula_8 when the stride is formula_9 ensures that the input volume and output volume will have the same size spatially. However, it's not always completely necessary to use all of the neurons of the previous layer. For example, a neural network designer may decide to use just a portion of padding.\n\nA parameter sharing scheme is used in convolutional layers to control the number of free parameters. It relies on one reasonable assumption: if a patch feature is useful to compute at some spatial position, then it should also be useful to compute at other positions. In other words, denoting a single 2-dimensional slice of depth as a depth slice, we constrain the neurons in each depth slice to use the same weights and bias.\n\nSince all neurons in a single depth slice share the same parameters, the forward pass in each depth slice of the convolutional layer can be computed as a convolution of the neuron's weights with the input volume. Therefore, it is common to refer to the sets of weights as a filter (or a kernel), which is convolved with the input. The result of this convolution is an activation map, and the set of activation maps for each different filter are stacked together along the depth dimension to produce the output volume. Parameter sharing contributes to the translation invariance of the CNN architecture.\n\nSometimes, the parameter sharing assumption may not make sense. This is especially the case when the input images to a CNN have some specific centered structure; for which we expect completely different features to be learned on different spatial locations. One practical example is when the inputs are faces that have been centered in the image: we might expect different eye-specific or hair-specific features to be learned in different parts of the image. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a \"locally connected layer\".\n\nAnother important concept of CNNs is pooling, which is a form of non-linear down-sampling. There are several non-linear functions to implement pooling among which \"max pooling\" is the most common. It partitions the input image into a set of non-overlapping rectangles and, for each such sub-region, outputs the maximum. \n\nIntuitively, the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting. It is common to periodically insert a pooling layer between successive convolutional layers in a CNN architecture. The pooling operation provides another form of translation invariance.\n\nThe pooling layer operates independently on every depth slice of the input and resizes it spatially. The most common form is a pooling layer with filters of size 2×2 applied with a stride of 2 downsamples at every depth slice in the input by 2 along both width and height, discarding 75% of the activations. In this case, every max operation is over 4 numbers. The depth dimension remains unchanged.\n\nIn addition to max pooling, pooling units can use other functions, such as average pooling or ℓ-norm pooling. Average pooling was often used historically but has recently fallen out of favor compared to max pooling, which performs better in practice.\n\nDue to the aggressive reduction in the size of the representation, there is a recent trend towards using smaller filters or discarding pooling layers altogether.\n\"Region of Interest\" pooling (also known as RoI pooling) is a variant of max pooling, in which output size is fixed and input rectangle is a parameter.\n\nPooling is an important component of convolutional neural networks for object detection based on Fast R-CNN architecture.\n\nReLU is the abbreviation of rectified linear unit, which applies the non-saturating activation function formula_10. Effectively, it removes negative values from an activation map by setting them to zero. It increases the nonlinear properties of the decision function and of the overall network without affecting the receptive fields of the convolution layer.\n\nOther functions are also used to increase nonlinearity, for example the saturating hyperbolic tangent formula_11, formula_12, and the sigmoid function formula_13. ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to generalization accuracy.\n\nFinally, after several convolutional and max pooling layers, the high-level reasoning in the neural network is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular (non-convolutional) artificial neural networks. Their activations can thus be computed as an affine transformation, with matrix multiplication followed by a bias offset (vector addition of a learned or fixed bias term).\n\nThe \"loss layer\" specifies how training penalizes the deviation between the predicted (output) and true labels and is normally the final layer of a neural network. Various loss functions appropriate for different tasks may be used. \n\nSoftmax loss is used for predicting a single class of \"K\" mutually exclusive classes. Sigmoid cross-entropy loss is used for predicting \"K\" independent probability values in formula_14. Euclidean loss is used for regressing to real-valued labels formula_15.\n\nCNNs use more hyperparameters than a standard multilayer perceptron (MLP). While the usual rules for learning rates and regularization constants still apply, the following should be kept in mind when optimizing.\n\nSince feature map size decreases with depth, layers near the input layer will tend to have fewer filters while higher layers can have more. To equalize computation at each layer, the product of feature values \"v\" with pixel position is kept roughly constant across layers. Preserving more information about the input would require keeping the total number of activations (number of feature maps times number of pixel positions) non-decreasing from one layer to the next.\n\nThe number of feature maps directly controls the capacity and depends on the number of available examples and task complexity.\n\nCommon filter shapes found in the literature vary greatly, and are usually chosen based on the dataset.\n\nThe challenge is, thus, to find the right level of granularity so as to create abstractions at the proper scale, given a particular dataset, and without overfitting.\n\nTypical values are 2×2. Very large input volumes may warrant 4×4 pooling in the lower layers. However, choosing larger shapes will dramatically reduce the dimension of the signal, and may result in excess information loss. Often, non-overlapping pooling windows perform best.\n\nRegularization is a process of introducing additional information to solve an ill-posed problem or to prevent overfitting. CNNs use various types of regularization.\n\nBecause a fully connected layer occupies most of the parameters, it is prone to overfitting. One method to reduce overfitting is dropout. At each training stage, individual nodes are either \"dropped out\" of the net with probability formula_16 or kept with probability formula_17, so that a reduced network is left; incoming and outgoing edges to a dropped-out node are also removed. Only the reduced network is trained on the data in that stage. The removed nodes are then reinserted into the network with their original weights.\n\nIn the training stages, the probability that a hidden node will be dropped is usually 0.5; for input nodes, this should be much lower, intuitively because information is directly lost when input nodes are ignored.\n\nAt testing time after training has finished, we would ideally like to find a sample average of all possible formula_18 dropped-out networks; unfortunately this is unfeasible for large values of formula_19. However, we can find an approximation by using the full network with each node's output weighted by a factor of formula_17, so the expected value of the output of any node is the same as in the training stages. This is the biggest contribution of the dropout method: although it effectively generates formula_18 neural nets, and as such allows for model combination, at test time only a single network needs to be tested.\n\nBy avoiding training all nodes on all training data, dropout decreases overfitting. The method also significantly improves training speed. This makes model combination practical, even for deep neural nets. The technique seems to reduce node interactions, leading them to learn more robust features that better generalize to new data.\n\nDropConnect is the generalization of dropout in which each connection, rather than each output unit, can be dropped with probability formula_16. Each unit thus receives input from a random subset of units in the previous layer.\n\nDropConnect is similar to dropout as it introduces dynamic sparsity within the model, but differs in that the sparsity is on the weights, rather than the output vectors of a layer. In other words, the fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage.\n\nA major drawback to Dropout is that it does not have the same benefits for convolutional layers, where the neurons are not fully connected.\n\nIn stochastic pooling, the conventional deterministic pooling operations are replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region. The approach is hyperparameter free and can be combined with other regularization approaches, such as dropout and data augmentation.\n\nAn alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations. This is similar to explicit elastic deformations of the input images, which delivers excellent MNIST performance. Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.\n\nSince the degree of model overfitting is determined by both its power and the amount of training it receives, providing a convolutional network with more training examples can reduce overfitting. Since these networks are usually trained with all available data, one approach is to either generate new data from scratch (if possible) or perturb existing data to create new ones. For example, input images could be asymmetrically cropped by a few percent to create new examples with the same label as the original.\n\nOne of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur. It comes with the disadvantage that the learning process is halted.\n\nAnother simple way to prevent overfitting is to limit the number of parameters, typically by limiting the number of hidden units in each layer or limiting network depth. For convolutional networks, the filter size also affects the number of parameters. Limiting the number of parameters restricts the predictive power of the network directly, reducing the complexity of the function that it can perform on the data, and thus limits the amount of overfitting. This is equivalent to a \"zero norm\".\n\nA simple form of added regularizer is weight decay, which simply adds an additional error, proportional to the sum of weights (L1 norm) or squared magnitude (L2 norm) of the weight vector, to the error at each node. The level of acceptable model complexity can be reduced by increasing the proportionality constant, thus increasing the penalty for large weight vectors.\n\nL2 regularization is the most common form of regularization. It can be implemented by penalizing the squared magnitude of all parameters directly in the objective. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. Due to multiplicative interactions between weights and inputs this has the useful property of encouraging the network to use all of its inputs a little rather than some of its inputs a lot.\n\nL1 regularization is another common form. It is possible to combine L1 with L2 regularization (this is called Elastic net regularization). The L1 regularization leads the weight vectors to become sparse during optimization. In other words, neurons with L1 regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the noisy inputs.\n\nAnother form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint. In practice, this corresponds to performing the parameter update as normal, and then enforcing the constraint by clamping the weight vector formula_23 of every neuron to satisfy formula_24. Typical values of formula_25 are order of 3–4. Some papers report improvements when using this form of regularization.\n\nPooling loses the precise spatial relationships between high-level parts (such as nose and mouth in a face image). These relationships are needed for identity recognition. Overlapping the pools so that each feature occurs in multiple pools, helps retain the information. Translation alone cannot extrapolate the understanding of geometric relationships to a radically new viewpoint, such as a different orientation or scale. On the other hand, people are very good at extrapolating; after seeing a new shape once they can recognize it from a different viewpoint.\n\nCurrently, the common way to deal with this problem is to train the network on transformed data in different orientations, scales, lighting, etc. so that the network can cope with these variations. This is computationally intensive for large data-sets. The alternative is to use a hierarchy of coordinate frames and to use a group of neurons to represent a conjunction of the shape of the feature and its pose relative to the retina. The pose relative to retina is the relationship between the coordinate frame of the retina and the intrinsic features' coordinate frame.\n\nThus, one way of representing something is to embed the coordinate frame within it. Once this is done, large features can be recognized by using the consistency of the poses of their parts (e.g. nose and mouth poses make a consistent prediction of the pose of the whole face). Using this approach ensures that the higher level entity (e.g. face) is present when the lower level (e.g. nose and mouth) agree on its prediction of the pose. The vectors of neuronal activity that represent pose (\"pose vectors\") allow spatial transformations modeled as linear operations that make it easier for the network to learn the hierarchy of visual entities and generalize across viewpoints. This is similar to the way the human visual system imposes coordinate frames in order to represent shapes.\n\nCNNs are often used in image recognition systems. In 2012 an error rate of 0.23 percent on the MNIST database was reported. Another paper on using CNN for image classification reported that the learning process was \"surprisingly fast\"; in the same paper, the best published results as of 2011 were achieved in the MNIST database and the NORB database. Subsequently, a similar CNN called \nAlexNet won the ImageNet Large Scale Visual Recognition Challenge 2012.\n\nWhen applied to facial recognition, CNNs achieved a large decrease in error rate. Another paper reported a 97.6 percent recognition rate on \"5,600 still images of more than 10 subjects\". CNNs were used to assess video quality in an objective way after manual training; the resulting system had a very low root mean square error.\n\nThe ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes. In the ILSVRC 2014, a large-scale visual recognition challenge, almost every highly ranked team used CNN as their basic framework. The winner GoogLeNet (the foundation of DeepDream) increased the mean average precision of object detection to 0.439329, and reduced classification error to 0.06656, the best result to date. Its network applied more than 30 layers. That performance of convolutional neural networks on the ImageNet tests was close to that of humans. The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters, an increasingly common phenomenon with modern digital cameras. By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained categories such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this.\n\nIn 2015 a many-layered CNN demonstrated the ability to spot faces from a wide range of angles, including upside down, even when partially occluded, with competitive performance. The network was trained on a database of 200,000 images that included faces at various angles and orientations and a further 20 million images without faces. They used batches of 128 images over 50,000 iterations.\n\nCompared to image data domains, there is relatively little work on applying CNNs to video classification. Video is more complex than images since it has another (temporal) dimension. However, some extensions of CNNs into the video domain have been explored. One approach is to treat space and time as equivalent dimensions of the input and perform convolutions in both time and space. Another way is to fuse the features of two convolutional neural networks, one for the spatial and one for the temporal stream. LSTM units are typically incorporated after the CNN to account for inter-frame or inter-clip dependencies. Unsupervised learning schemes for training spatio-temporal features have been introduced, based on Convolutional Gated Restricted Boltzmann Machines and Independent Subspace Analysis.\n\nCNNs have also explored natural language processing. CNN models are effective for various NLP problems and achieved excellent results in semantic parsing, search query retrieval, sentence modeling, classification, prediction and other traditional NLP tasks.\n\nCNNs have been used in drug discovery. Predicting the interaction between molecules and biological proteins can identify potential treatments. In 2015, Atomwise introduced AtomNet, the first deep learning neural network for structure-based rational drug design. The system trains directly on 3-dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller, spatially proximate features into larger, complex structures, AtomNet discovers chemical features, such as aromaticity, sp3 carbons and hydrogen bonding. Subsequently, AtomNet was used to predict novel candidate biomolecules for multiple disease targets, most notably treatments for the Ebola virus and multiple sclerosis.\n\nCNNs can be naturally tailored to analyze a sufficiently large collection of time series representing one week long human physical activity streams augmented by the rich clinical data (including the death register, as provided by, e.g., the NHANES study). A simple CNN was combined with Cox-Gompertz proportional hazards model and used to produce a proof-of-concept example of digital biomarkers of aging in the form of all-causes-mortality predictor.\n\nCNNs have been used in the game of checkers. From 1999 to 2001, Fogel and Chellapilla published papers showing how a convolutional neural network could learn to play checkers using co-evolution. The learning process did not use prior human professional games, but rather focused on a minimal set of information contained in the checkerboard: the location and type of pieces, and . Ultimately, the program (Blondie24) was tested on 165 games against players and ranked in the highest 0.4%. It also earned a win against the program Chinook at its \"expert\" level of play.\n\nCNNs have been used in computer Go. In December 2014, Clark and Storkey published a paper showing that a CNN trained by supervised learning from a database of human professional games could outperform GNU Go and win some games against Monte Carlo tree search Fuego 1.1 in a fraction of the time it took Fuego to play. Later it was announced that a large 12-layer convolutional neural network had correctly predicted the professional move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GNU Go in 97% of games, and matched the performance of the Monte Carlo tree search program Fuego simulating ten thousand playouts (about a million positions) per move.\n\nA couple of CNNs for choosing moves to try (\"policy network\") and evaluating positions (\"value network\") driving MCTS were used by AlphaGo, the first to beat the best human player at the time.\n\nFor many applications, little training data is available. Convolutional neural networks usually require a large amount of training data in order to avoid overfitting. A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the in-domain data to fine-tune the network weights. This allows convolutional networks to be successfully applied to problems with small training sets.\n\nEnd-to-end training and prediction are common practice in computer vision. However, human interpretable explanations are required for critical systems such as a self-driving cars. \"Black-box models will not suffice\". With recent advances in visual salience, spatial and temporal attention, the most critical spatial regions/temporal instants could be visualized to justify the CNN predictions.\n\nA deep Q-network (DQN) is a type of deep learning model that combines a deep CNN with Q-learning, a form of reinforcement learning. Unlike earlier reinforcement learning agents, DQNs can learn directly from high-dimensional sensory inputs.\n\nPreliminary results were presented in 2014, with an accompanying paper in February 2015. The research described an application to Atari 2600 gaming. Other deep reinforcement learning models preceded it.\n\nConvolutional deep belief networks (CDBN) have structure very similar to convolutional neural networks and are trained similarly to deep belief networks. Therefore, they exploit the 2D structure of images, like CNNs do, and make use of pre-training like deep belief networks. They provide a generic structure that can be used in many image and signal processing tasks. Benchmark results on standard image datasets like CIFAR have been obtained using CDBNs.\n\n\n\nConvolutional neural networks are mentioned in the 2017 novel \"Infinity Born.\"\n\n\n"}
{"id": "1299607", "url": "https://en.wikipedia.org/wiki?curid=1299607", "title": "Cycle of abuse", "text": "Cycle of abuse\n\nThe cycle of abuse is a social cycle theory developed in 1979 by Lenore E. Walker to explain patterns of behavior in an abusive relationship.\n\nLenore E. Walker interviewed 1,500 women who had been subject to domestic violence and found that there was a similar pattern of abuse, called the \"cycle of abuse\". Initially, Walker proposed that the cycle of abuse described the controlling patriarchal behavior of men who felt entitled to abuse their wives to maintain control over them. Her terms \"the battering cycle\" and \"battered woman syndrome\" has since been largely eclipsed by \"cycle of abuse\" and \"battered person syndrome\", respectively, for many reasons: to maintain objectivity; because the cycle of abuse doesn't always lead to physical abuse; because symptoms of the syndrome have been observed in men and women, and are not confined to marriage and dating. Similarly, Dutton (1994) writes, \"The prevalence of violence in homosexual relationships, which also appear to go through abuse cycles is hard to explain in terms of men dominating women.\"\n\nThe cycle of abuse concept is widely used in domestic violence programs, particularly in the United States. Critics have argued the theory is flawed as it does not apply as universally as Walker suggested, does not accurately or completely describe all abusive relationships, and may emphasize ideological presumptions rather than empirical data.\n\nThe cycle usually goes in the following order, and will repeat until the conflict is stopped, usually by the survivor entirely abandoning the relationship or some form of intervention. The cycle can occur hundreds of times in an abusive relationship, the total cycle taking anywhere from a few hours, to a year or more to complete. However, the length of the cycle usually diminishes over time so that the \"reconciliation\" and \"calm\" stages may disappear, violence becomes more intense and the cycles become more frequent.\n\nStress builds from the pressures of daily life, like conflict over children, marital issues, misunderstandings, or other family conflicts. It also builds as the result of illness, legal or financial problems, unemployment, or catastrophic events, like floods, rape or war. During this period, the abuser feels ignored, threatened, annoyed or wronged. The feeling lasts on average several minutes to hours, it may last as much as several months.\n\nTo prevent violence, the victim may try to reduce the tension by becoming compliant and nurturing. Or, to get the abuse over with, prepare for the violence or lessen the degree of injury, the victim may provoke the batterer. \"However, at no time is the batterer justified in engaging in violent or abusive behavior,\" said Scott Allen Johnson, author of \"Physical Abusers and Sexual Offenders\".\n\nCharacterized by outbursts of violent, abusive incidents which may be preceded by verbal abuse and include psychological abuse. During this stage the abuser attempts to dominate their partner (survivor) with the use of domestic violence.\n\nIn intimate partner violence, children are negatively affected by having witnessed the violence and the partner's relationship degrades as well. The release of energy reduces the tension, and the abuser may feel or express that the victim \"had it coming\" to them.\n\nThe perpetrator may begin to feel remorse, guilty feelings, or fear that their partner will leave or call the police. The victim feels pain, fear, humiliation, disrespect, confusion, and may mistakenly feel responsible.\n\nCharacterized by affection, apology, or, alternatively, ignoring the incident, this phase marks an apparent end of violence, with assurances that it will never happen again, or that the abuser will do their best to change. During this stage the abuser may feel or claim to feel overwhelming remorse and sadness. Some abusers walk away from the situation with little comment, but most will eventually shower the survivor with love and affection. The abuser may use self-harm or threats of suicide to gain sympathy and/or prevent the survivor from leaving the relationship. Abusers are frequently so convincing, and survivors so eager for the relationship to improve, that survivors (who are often worn down and confused by longstanding abuse) stay in the relationship.\n\nDuring this phase (which is often considered an element of the honeymoon/reconciliation phase), the relationship is relatively calm and peaceable. During this period the abuser may agree to engage in counseling, ask for forgiveness, and create a normal atmosphere. In intimate partner relationships, the perpetrator may buy presents or the couple may engage in passionate sex. Over time, the batterer's apologies and requests for forgiveness become less sincere and are generally stated to prevent separation or intervention. However, interpersonal difficulties will inevitably arise, leading again to the tension building phase. The effect of the continual cycle may include loss of love, contempt, distress, and/or physical disability. Intimate partners may separate, divorce or, at the extreme, someone may be killed.\n\nWalker's cycle of abuse theory was regarded as a revolutionary and important concept in the study of abuse and interpersonal violence, which is a useful model, but may be simplistic. For instance, Scott Allen Johnson developed a 14-stage cycle that broke down the tension-building, acting-out and calm stages further. For instance, there are six stages in the \"escalation\" or tension building stage, which includes triggers, the victim feeling victimized, angry and depressed, isolation and revenge planning. These lead up to the assault by acting out the revenge plan, self-destructive behavior, victim grooming and the actual physical and/or sexual assault. This is followed by a sense of relief, fear of consequences, distraction, and rationalization of abuse.\n\nDonald Dutton and Susan Golant agree that Walker's cycle of abuse accurately describes all cyclically abusive relationships they studied. Nonetheless, they also note that her initial research was based almost entirely on anecdotal data from a rather small set of women who were in violent relationships. Walker herself wrote, \"These women were not randomly selected and they cannot be considered a legitimate data base from which to make specific generalizations.\"\n\n\n"}
{"id": "45474514", "url": "https://en.wikipedia.org/wiki?curid=45474514", "title": "Death of Adele Biton", "text": "Death of Adele Biton\n\nThe death of Adele Biton occurred on 17 February 2015 as a consequence of a March 14, 2013 Palestinian stone-throwing attack caused the civilian vehicle in which the infant Adele was riding to crash.\n\nOn the 14 March 2013, Adele, with her mother Adva and two sisters, Avigail and Naama, were in a car driving on Route 5 between the Israeli settlement of Yakir and Tel Aviv, where the family had visited a grandmother. The Biton family were driving on Route 5 towards Tel Aviv. Palestinians were throwing stones at vehicles on the road at the time. They were targeted by rock-throwers, and the car spun out of control and smashed into a truck which was parked on the side of the road, having stopped for similar reasons. The first health aide to arrive on the scene was a Palestinian volunteer paramedic, Muawiya Qabha, an Arab-Muslim volunteer paramedic, who gave immediate assistance. Soon afterwards he was joined by an Israeli doctor who happened to be driving by, who examined Adele and pronounced her clinically dead. Qabha, convinced he could save her life, continued to work on her, and after a considerable time, the girl began to respond. The child had suffered severe head injuries as a result of the crash and was hospitalized at the Rabin Medical Center's Schneider Children's Medical Center for emergency surgery. She remained semi-comatose for two months, and was released to return to the family home.\n\nAdele never recovered from her injuries. According to the \"New York Times\", Adele, \"Biton, became a potent national symbol of the dangers that stones can cause\". According to \"New York Times\" reporter Jodi Rudoren, Adele was \"among the victims who become somewhat iconic... Many, many articles were written about her.\"\n\nBiton is remembered as one of a long series of people injured and killed as a result of Palestinian rock-throwing at passing vehicles. Others who have suffered the same fate include Esther Ohana, a 20-year-old girl who was driving to her wedding rehearsal when she was murdered, eleven-year-old Chava Wechsberg, and Asher Palmer, a young father murdered along with his eleven-month-old son.According to historian Rafael Medoff, 14 people have been killed by Palestinian stone throwing, including 3 Arabs mistaken for Jews by the rock throwers.\n\n5 Palestinian teenagers, Muhammad Mahdi Suleiman,Tamer Ayyad Ahmad Souf, Ammar Abd al-Nayif Souf, Ali Yassin Ali Shamlawi and Muhammad Jumaa Muhammad Kleib, from Kfar Haras were arrested for throwing the rocks that caused the crash. They were charged with having thrown stones on that road that day. 20 drivers driving on that route during the day later filed insurance claims for damages to their vehicles, but no eyewitnesses, according to Ma'an News Agency, were forthcoming, and no police station received complaints at the time. All five eventually confessed but retracted their statements in court, stating that their admissions had been extracted after repeated abuse under interrogation. In December 2015, all 5 were sentenced to 15 years in prison and fined $7,700.\n"}
{"id": "38723257", "url": "https://en.wikipedia.org/wiki?curid=38723257", "title": "Death of Hugo Chávez", "text": "Death of Hugo Chávez\n\nHugo Chávez, the 62nd President of Venezuela, died on 5 March 2013 at the age of 58. His death triggered a presidential election which was constitutionally required to be called within 30 days. Nicolás Maduro served as interim president following Chávez's death until 14 April, because the Vice President did not want to take charge of the country as Chávez had nominated Nicolas Maduro as a successor.\n\nChávez was first elected as president in 1998 and was re-elected in 2000, 2006 and finally in 2012. However, Chávez was unable to be sworn in for a fourth term after the 2012 election due to his illness.\n\nChávez was diagnosed with cancer following the discovery of a mass in his pelvic region in June 2011. He traveled to Havana, Cuba where he underwent a surgical operation to remove a malignant cancerous tissue mass 'about the size of a baseball' from his waist. He underwent a second surgical operation in Venezuela one month later. Over the next 12 months, he followed a cycle of chemotherapy. The type of cancer Chávez was diagnosed with was never made public which fueled speculation over his condition (with speculations from being prostate cancer to colon cancer among others). Following the presidential election in October 2012 (where he was re-elected to a fourth term), he went to Cuba for more treatment and then returned to Venezuela and stayed at a Caracas army hospital for one week until his death. Successive announcements of his return and updates of his health were criticised by the country's opposition that the population were unaware of his health and location. The fact that the cancer had metastasised was not made public during the campaign, and strongly denied by Government officers. After the first lung infection (pneumonia) in the last stages of his life, Chávez was intubated nearing the end of December. His breathing worsened until his death was announced at 16:25 VET (20:55 UTC) on 5 March 2013, almost two years after he was first diagnosed.\n\nVice-president Nicolás Maduro announced Chávez's death on a mandatory television \"cadena\" (a decree forcing all broadcasters to relay State television content). In an emotional eulogy Maduro said: \"Let there be no weakness, no violence. Let there be no hate. In our hearts there should only be one feeling: Love.\" Maduro indicated that Chávez had died \"after battling a tough illness for nearly two years.\" He added that police and troops would be deployed across the country 'to guarantee the peace.' The head of the presidential guard said Chávez died of a massive heart attack after great suffering and had inaudibly mouthed his desire to live. In an interview to the Associated Press he said that Chávez could not speak but he said it with his lips ... \"I don't want to die. Please don't let me die\". The BBC reported isolated incidents of violence following the announcement of Chávez's death. Although pro-Chavez supporters attacked and burned tents of students who had camped demanding more official information about Chávez's health, there were no reported injuries. Vice-President Maduro indicated he had \"no doubt\" of foul play by \"the historical enemies of our fatherland\" behind Chávez's illness and death. Defence Minister Diego Morelo Bellavia said that the \"Bolivarian\" armed forces would be loyal to the vice president and National Assembly and urged supporters and opposition to remain calm.\n\nAfter defecting from Venezuela, former bodyguard for Chávez, Leamsy Salazar, stated that he died in December 2012, months before his date was officially announced.\n\nIn July 2018, former Attorney General Luisa Ortega Díaz also said that Chávez had actually died in December 2012 and the announcement of his death was delayed for political reasons. In an interview cited by Venezuelan daily \"El Nacional\", the former Chávez supporter said that the Venezuelan president died on 28 December, but his closest allies decided to delay the announcement and never submitted the death certificate to the Office of the Attorney General.\n\nThe supposed delay in announcing Chávez's death raised concerns that laws signed in his name during that period were forged for political purposes.\n\nThousands of people flooded the streets of the capital Caracas. Many cried and hugged in public shows of emotion. Women were weeping at Miraflores Palace. With a mixture of joy and sadness Chávez supporters shared their impressions after him a last farewell: \"That man emanates a force forward and his face says my people.\". People left work for the day upon hearing the news, shops and offices shut and cars and buses filled the streets.\n\nOpposition leader and opponent in the 2012 election, Henrique Capriles, called on the government to \"act in strict accordance with its constitutional duties.\" He also added his condolences to Chávez's family saying \"we were adversaries, but never enemies\". Acting President Nicolás Maduro said he believed Chávez was assassinated by Venezuela's \"historical enemies\" (widely assumed to mean the United States), and that a \"scientific commission\" would investigate this possibility. The US State Department denied any American involvement, calling the claim \"absurd\".\n\nOn the first anniversary of Chavez's death, tens of thousands of his supporters marched through cities across Venezuela. This was coupled with the 2014 Venezuelan protests featuring pro and anti-government demonstrations.\n\nUN Secretary-General Ban Ki-moon's office issued a statement expressing condolences.\n\nReactions within the Americas by citizens occurred outside Venezuela's embassies in Honduras, El Salvador, Chile and Ecuador. Spanish citizens expressed their support and solidarity to the people of Venezuela, by concentrating on Wednesday afternoon in the vicinity of the Plaza Puerta del Sol in Madrid (capital), to express in slogans that \"Chávez's legacy will remain far beyond of his death.\"\n\nOAS Secretary General José Miguel Insulza ordered the body's flags to be flown at half-mast and the convening of a special meeting of the Permanent Council in memory of Chávez.\n\nAfter announcing Hugo Chávez's death, Bolivian president Evo Morales broke down and cried on national television while paying tribute to Chávez; Morales then decreed seven days of mourning in Bolivia after Chávez's death. Brazilian president Dilma Rousseff, who had cancelled a scheduled trip to Argentina to meet President Kirchner, led a minute of silence in Brasília. Rousseff decreed three days of mourning. Rousseff's predecessor, Luiz Inácio Lula da Silva, also expressed grief. Salvadorean president Mauricio Funes and Chilean president Sebastián Piñera both praised Chávez's strong character, and the Chilean government declared three days of national mourning for Chávez.\n\nThe Cuban Council of State decreed two days of official mourning, from 6 am on 6 March to midnight 7 March, and a third day of national mourning on 8 March. The presidents of Dominican Republic, Haiti, Uruguay and Ecuador all decreed three days of mourning for Chávez.\n\nNicaraguan president Daniel Ortega declared seven days of mourning.\nColombian president Juan Manuel Santos, Mexican president Enrique Peña Nieto lamented the death of Chávez; The Mexican Ministry of Foreign Affairs issued a press release expressing condolences and \"our feeling of fraternity\". Colombia ordered its 15 consulates in Venezuela temporarily closed to observe the days of mourning. Guyanan president Donald Ramotar, Guatemalan president Otto Pérez Molina, and the President of Suriname Desi Bouterse regretted losing a \"friend\". The Government of Suriname declared Friday a day of national mourning. Ramotar and Honduran president Porfirio Lobo praised Chavez for his contribution to regional integration; the National Congress of Honduras addressed a minute of silence.\n\nTrinidad and Tobago and Jamaica said that special arrangements would be made for an official tribute to Chávez. Uruguay announced that President José Mujica was in Argentina for a summit when Chávez died, but that he would fly to Caracas with Argentine President Cristina Kirchner to attend the funeral. Argentina declared three days of mourning Suriname declared Friday a day of mourning.\n\nCanadian prime minister Stephen Harper offered his condolences; former Prime Minister Jean Chrétien eulogised in a televised interview.\n\nSuggestions of American foul play, implying that Chávez had been poisoned or somehow infected with cancer (arguing a plot reminiscent to the Yasser Arafat death controversy and the attempts against Fidel Castro), were vehemently denied by the U.S. Department of State as \"absurd\".\n\nIn Miami, some Venezuelans joyfully celebrated Chavez's death, and were cautiously optimistic of new elections for Chávez's successor; an estimated 189,219 Venezuelans live in the United States, most of whom are anti-Chavez. United States President Barack Obama reaffirmed the support of the US for the Venezuelan people and its interest in developing a constructive relationship with the Venezuelan government. Former president Jimmy Carter complimented Chávez's commitment to improving the lives of Venezuelans. According to a statement posted at the Carter Center website, Carter and his wife Rosalynn \"came to know a man who expressed a vision to bring profound changes to his country to benefit especially those people who had felt neglected and marginalized.\"\n\nNkosazana Dlamini-Zuma, who chairs the African Union Commission, conveyed her condolence to the family, government and people of Venezuela. The organisation observed a minute of silence at the A.U. headquarters on 8 March during the celebration of the International Women's Day.\n\nAlgerian president Abdelaziz Bouteflika, Gambian president Yahya Jammeh, Mauritanian president Mohamed Ould Abdelaziz, Sahrawi Republic president Mohamed Abdelaziz, South African president Jacob Zuma, Sudanese president Omar al-Bashir, Tanzanian president Jakaya Kikwete, all expressed their sorrow and offered their \"deepest condolences\". Gambia's president Yahya Jammeh proclaimed two national prayer days at mosques and churches for Chavez, on 8 and 10 March 2013. The Sahrawi government declared a day of national mourning.\n\nAfghanistan president Hamid Karzai, President of Armenia Serzh Sargsyan, Azerbaijani president Ilham Aliyev, Chinese president Hu Jintao and Communist Party of China general secretary Xi Jinping, deputy director-general of the Taiwanese Foreign Ministry Calvin Ho, Indian prime minister Manmohan Singh issued statements of \"heartfelt condolences\".\n\nPakistan president Asif Ali Zardari and Prime Minister Raja Pervaiz Ashraf, President of the Palestinian National Authority Mahmoud Abbas, Turkmenistan president Gurbanguly Berdymukhamedov Vietnamese leaders – including Party general secretary Nguyễn Phú Trọng, Prime Minister Nguyễn Tấn Dũng, and National Assembly chairman Nguyễn Sinh Hùng – also expressed condolences; some lauded Chavez's achievements. Memorial services were scheduled to be held in Ramallah and other cities in the West Bank and senior Palestinian officials paid their respects at the Venezuelan Embassy in Ramallah. In Gaza City streets were decorated with Venezuelan flags and posters of Chavez. Hamas, the \"de facto\" government of the Gaza Strip, lauded Chávez as a \"great leader\"; The Syrian Arab News Agency paid homage to Chávez for taking \"an honourable stance regarding the conspiracy against Syria\". Iran declared a day of national mourning.\n\nIn the European Union, European Council President Herman Van Rompuy and European Commission President José Manuel Barroso said that they had received the news of Chávez's death with \"sadness.\" French president François Hollande and British foreign secretary William Hague were \"saddened\". Irish president Michael D. Higgins sent condolences, Sinn Féin leader Gerry Adams also paid tribute. Italian president Giorgio Napolitano (\"painful\") The Spanish government extended its condolences, as did Portuguese president Aníbal Cavaco Silva sent condolences, whilst Swedish PM Fredrik Reinfeldt stated that Chávez \"undeniably affected his country and the entire region\" and hoped for greater democracy and respect for human rights in Venezuela; Foreign minister Carl Bildt criticized his policies, saying that Chávez had \"plunder[ed] the oil wealth of [his] country\".\n\nPresident of Russia Vladimir Putin and prime minister Dmitry Medvedev expressed their \"sincere condolences\" Russia would send a delegation consisting of Rosneft president Igor Sechin, Trade and Industry minister Denis Manturov, Rostec CEO Sergey Chemezov, Federation Council speaker Valentina Matviyenko and foreign minister Sergei Lavrov. Serbian president Tomislav Nikolić and prime minister Ivica Dačić sent condolences and lamented the loss of \"a friend\". Serbian cabinet also announced that he had been posthumously honoured with the Order of the Republic of Serbia Belarus declared three days of mourning\n\nIn the Vatican, a condolence letter was read during a meeting of Cardinals prior to the Papal Conclave.\n\nAustralian Foreign Minister Bob Carr and New Zealand Prime Minister John Key expressed condolences \"to the Chavez family and the people of Venezuela\". However, Key, who was on a diplomatic trip to Mexico, Colombia, Chile and Brazil, did not attend the funeral although meetings had been postponed due to Latin American leaders attending, and was criticized by ex-Greens MP Keith Locke, Toby Manhire and others.\n\nForeign minister Elías Jaua decreed seven days of mourning for Chávez. Chávez's body was taken to the Military Academy in Caracas on 6 March 2013, accompanied by large numbers of supporters who joined the procession at the military parade grounds (the Heroes Avenue) and was left lying in state for the public to visit for three days. The state funeral was held in Caracas on 8 March 2013. Acting President Nicolás Maduro originally stated that Chávez's body would be embalmed and permanently displayed after the state funeral in a transparent sarcophagus at a military museum in the former site of the Military Academy in La Planicie Barracks at the 23 de Enero district west of the city proper. However, due to difficulties in finding an expert and the uncertainties of plastination in which the weather plays a substantial part, Maduro announced that the body would not be embalmed in time.\nPresident Maduro extended national mourning from 4 to 11 days to coincide with the transportation of the body to the military museum (now Museum of the Revolution) at La Planicie Barracks, which was renamed Mountain Barracks as it was, not by accident, the place which the then Army LtCol Chavez captured and used as a command centre in the brief coup of 1992, and where he uttered his famous words \"Por ahora\" (For now) to the press.\n\nHis body was interred with full military honors on 15 March 2016, in a televised service, three years after his death.\n\nFor the final arrangements a funeral service was arranged, with the casket leaving the Military Academy grounds in Fort Tiuna on 17 March 2013 under full military honours including references to Ltn. Cnl. Chavez's home battalion (the Apure Braves 414th Armored Battalion) with the marching song \"Patria Querida\" (Fatherland Beloved) played in slow time, a 21-gun salute, and a Military Aviation (formerly Venezuelan Air Force) flyover by Sukhoi Su-30 fighters in a missing man formation. Government party militias in their light motorcycles followed the motorcade (itself surrounded by Army mounted guards) with a large following of (mostly poor) citizens, with final arrival honors paid upon arrival at the Mountain Barracks. Bolivian President Evo Morales, President Maduro (then interim) and Chavez's brother Adan and daughter Maria Gabiela each gave speeches before the flag folding and dedication ceremony. The national flag covering the casket was handed to Elena Frías de Chávez, the late President's mother, on behalf of the armed forces and the nation.\n\nArgentinian president Cristina Kirchner was amongst the first heads of state to arrive in Venezuela on Tuesday 5 March. She visited the chapel at the military hospital to pay her final respects on Thursday before returning home, citing health reasons. Brazilian president Dilma Rousseff attended a wake on Thursday at the military academy before returning to Brazil on Friday morning. Former President Lula da Silva accompanied President Rousseff and departed before the funeral service.\n\nFormer Canadian prime minister Jean Chrétien and his wife Aline attended the funeral, along with former Colombian senator Piedad Córdoba, former Honduran president Manuel Zelaya, and former Paraguayan president Fernando Lugo.\n\nOther attendees included Former US congressman William Delahunt, President of Russian Rosneft oil company Igor Sechin and CEO of Rostec Sergei Chemezov; Nikolay Lukashenko, son of the Belarus president; Alexis Tsipras, the leader of SYRIZA in Greece (later Prime Minister of Greece); from Spain were Cayo Lara and Willy Meyer Pleite (MEP). American civil rights activist Jesse Jackson and actor Sean Penn also attended.\n\nHonour guards were provided by the cadets of the component service academies of the Venezuelan Bolivarian Military University and by personnel of the Presidential Honor Guard Brigade, among others. The Simón Bolívar Symphony Orchestra provided musical accompaniment during the state funeral services.\n\nEchoing strong national sentiment the Government elevated a proposal to the National Assembly (Parliament) for a statute amendment that would allow placing the late president's body near that of Simón Bolívar (the Liberator and father of the country) in the National Pantheon of Venezuela, a secular building housing the remains and/or cenotaphs to independence war heroes and former presidents. The statute (still unamended) requires that a number of years pass before any such moves. Chávez's remains were placed instead at a mausoleum (built in 99 days) at the now Revolution Museum (formerly Army Museum) at the Mountain Barracks (former site of the Military Academy in La Planicie Barracks). The mausoleum to Hugo Chávez consists of a granite sarcophagus atop a flat architectural composition of four leaves entitled \"Flower of the Four Elements\" by modernist architect 'Fruto' (Jose Fructoso) Vivas (1928–) (national Architecture Price and designer of the Venezuelan Pavilion at Hanover in 2000) and has a permanent ceremonial 4-man honour guard provided by the Presidential Honor Guard Brigade, which is changed every hour. A 19th century cannon is fired every afternoon from the Fort marking the time of his death by a National Militia gun crew. Both ceremonies are open to the public.\n\nThe BBC quoted analysts as saying Chávez' death could alter the balance against the so-called \"pink tide\" in favour of centrist governments. It also suggested a possible economic impact due Venezuelan oil sales at below market prices to some neighbouring countries, especially in the Caribbean. \"Americas Quarterly\" editor Christopher Sabatini suggested that the \"Chávez myth\" would outlive his achievements. Prior to his death, Venezuela's recognition of Abkhazia and South Ossetia were also highlighted as dependent on Chávez.\n\n"}
{"id": "24502483", "url": "https://en.wikipedia.org/wiki?curid=24502483", "title": "Dugu ceremony", "text": "Dugu ceremony\n\nThe Dugu is an ancient extended funerary ceremony (in Belize it is also known as the 9 nights ceremony) practiced by the Garifuna people. The Garifuna is a small-to-medium-sized Central American ethnic group that has inhabited many Central American countries such as Belize and Honduras since the 17th century. Their roots come from both the Caribbean and African coasts. The story goes that slaves being brought over to the Americas crashed into St. Vincent. The indigenous Caribbean Indians and Africans soon formed a community and ethnic group called the Garifuna. They were identified as the \"Black Caribs\" to differentiate them from the native Caribbean population.\n\nThe \"Dugu\" is a type of funeral ceremony that brings the community and families together. It is a festival that aims to bring deceased ancestors of the Garifuna to the present and lasts between two days to as much as two weeks. The ceremony seeks to cure ill persons that have become sick because they have displeased the \"gubida\" (spirits). Families and friends gather around drums and sing, calling the \"gubida\" to the ceremony. This ceremony is headed by the \"Buyai\" (shaman). The Buyai is responsible for organizing and ordering all parts of the ceremony including food, clothes worn, sacrifices, and its length. Once the Buyai believes the spirits of the ancestors are present, the sick person is given food and rum. The rest of the food and alcohol is sacrificed and the person is predicted to be cured.\n\nThe \"Dugu\" ritual has recently become more common. In the 1850s and 1860s the \"Dugu\" was little practiced due to fear the government (appointed by the British) would ban the ritual altogether. Now, however, the \"Dugu ji\" is practiced in many countries throughout Central America, but mainly in Belize. There are many reasons for the increase, one of which is to help unify the Garifuna people and also become politically visible as an ethnic group.\n\nPalacio, I. Myrtle (2011 (June)). \"Adügürahani: A Walk Through Garifuna Spiritualism\". Glessima Research and Services, Belize.\nJenkins, Carol L. (1983 (Aug.)). \"Ritual and Resource Flow: The Garifuna 'Dugu'\". American Ethnologist. Vol 10.3 pp. 429–442. Retrieved 2009-09-20.\n\nSletto, Jacqueline Wiora. (1991(Jan-Feb)). \"Ancestral Ties that Bind. (The Garifuna, Central American Ethnic Group)\". Americas (English Edition). Vol 43.n1 pp. 20–28. Retrieved 2009-09-18.\n"}
{"id": "10805540", "url": "https://en.wikipedia.org/wiki?curid=10805540", "title": "Dunk (elephant)", "text": "Dunk (elephant)\n\nDunk (c. 1861 – March 30, 1917), a tuskless, male Asian Elephant possibly from Ceylon, was the first elephant to reside at the National Zoo in Washington, D.C. He was given to the National Zoo on April 30, 1891 by James E. Cooper, owner and manager of the Adam Forepaugh Circus.\n\nWhen Dunk first arrived at the National Zoo, he had no shelter and was tied to a tree with his companion Gold Dust to prevent him from wandering. Once a day, both elephants were walked to Rock Creek to swim. A temporary structure, known as the Octagonal House, was eventually built for the elephants. Construction on a permanent, brick elephant house, designed by Hornblower & Marshall, began in September 1902 and was completed in January 1903.\n\nDunk was ill throughout the winter of 1917. On March 30, 1917, after Dunk broke his shoulder in a fall, keeper William Blackburne euthanized him by shooting.\n\nDespite a famous ill-temper, Dunk was popular with the children of Washington, D.C. To commemorate his memory, they raised money for a plaque, which remains in the elephant house at the National Zoo today.\n\n"}
{"id": "40801331", "url": "https://en.wikipedia.org/wiki?curid=40801331", "title": "Estate Orpen v Estate Atkinson", "text": "Estate Orpen v Estate Atkinson\n\nIn Estate Orpen v Estate Atkinson, an important case in the South African law of succession, the testators, the Atkinsons, massed their estates in a joint will. They had one child, a daughter. According to the stipulations of the will, the massed estate would, upon the death of Mr. Atkinson, should he die first, be handed over to the executors of the estate, who would act as trustees; a trust was thus created.\n\nFrom the moment of death of the testator, Mrs. Atkinson, also a testator, and the daughter would receive the income of the trust in equal parts as beneficiaries. Should one of them have died, the survivor would receive the whole of the trust income for the rest of her life. Should the daughter have died, the whole trust (the \"corpus\") would go to her children in equal shares, subject to the usufruct of Mrs. Atkinson should she still be alive.\n\nThe will also stipulated that if the daughter should, upon death, have no children, twenty per cent of the trust capital (corpus) would go to such person as the daughter might designate in her will. She therefore obtained a power of appointment in her parents’ will with regard to twenty per cent of the corpus of the trust. The destination of the other eighty per cent was arranged for in the parents' will.\n\nOn 5 March 1963, while her father was still alive, the daughter (Mrs. Orpen) made a will in which, with reference to her power of appointment, she bequeathed the twenty per cent trust capital to her husband, Mr. Orpen. She thus exercised her power of appointment in favour of her spouse. Mrs. Orpen died on 23 March 1963 without children. Her father, Mr. Atkinson, the creator of the power of appointment, died on 9 November 1963. Mr. Orpen died on 23 December 1964.\n\nThe legal question was whether the exercise of Mrs. Orpen’s power of appointment in favour of Mr. Orpen, in terms of her father’s will, was valid, and whether her spouse’s deceased estate had obtained vested rights with regard to the twenty per cent trust capital that she bequeathed to him, regardless of the fact that she died before her father. Her father was therefore still alive when her will, in which she exercised her power of appointment, came into operation.\n\nThe Court held that Mr. Orpen’s estate had no right to twenty per cent of the trust capital. Mrs. Orpen obtained her \"power\" from her father; she could not exercise it unless she survived her father. Because he was still alive when she died, she could not exercise rights left to her in his will. She could only validly exercise her rights if she survived him.\n\n\n"}
{"id": "42716948", "url": "https://en.wikipedia.org/wiki?curid=42716948", "title": "Final maturation induction", "text": "Final maturation induction\n\nInduction of final maturation of oocytes is a procedure that is usually performed as part of controlled ovarian hyperstimulation to render the oocytes fully developed and thereby resulting in optimal pregnancy chances. It is basically a replacement for the luteinizing hormone (LH) surge whose effects include final maturation in natural menstrual cycles.\n\nThe main medications used for induction of final maturation are human chorionic gonadotropin (hCG) and GnRH agonist. In fresh (rather than frozen) autologous cycles of \"in vitro\" fertilization, final oocyte maturation triggering with GnRH agonist instead of hCG decreases the risk of ovarian hyperstimulation syndrome but decreases live birth rate. In cycles followed by oocyte donation, use of GnRH agonists instead of hCG decreases the risk of ovarian hyperstimulation syndrome with no evidence of a difference in live birth rate.\n\nInduction of final maturation also initiates the mechanisms that eventually result in ovulation, and thereby makes the oocytes destined to undergo ovulation unless artificial oocyte retrieval is performed first. Therefore, induction of final maturation is also called triggering oocyte release from the ovary, and the administration of pharmaceutical drugs to induce final maturation is colloquially called giving a \"trigger shot\", even if the plan is to perform artificial oocyte retrieval before ovulation.\n\nAdministration of a drug to trigger oocyte release without oocyte retrieval results in a predictable time of ovulation, with the interval from drug administration to ovulation depending on the type of drug. This avails for sexual intercourse or intrauterine insemination (IUI) to conviently be scheduled at ovulation, the most likely time to achieve pregnancy.\n\nIn cycles stimulated with clomifene for intended conception by sexual intercourse, however, triggering oocyte release has been shown to decrease pregnancy chances compared to frequent monitoring with LH surge tests. Therefore, in such cases, triggering oocyte release is best reserved for women who require IUI and in whom LH monitoring proves difficult or unreliable. It may also be used when LH monitoring hasn't shown an LH surge by cycle day 18 (where cycle day 1 is the first day of the preseding menstruation) and there is an ovarian follicle of over 20 mm in size.\n\nIn \"in vitro\" fertilization (IVF), induction of final maturation avails for egg retrieval when the eggs are fully mature.\n\nIn IVF, final maturation induction is preceded by controlled ovarian hyperstimulation. It is suggested that there should be a size of ovarian follicles of at least 15 mm, and serum estradiol level of 0.49 nmol/L before commencing final maturation induction. There are better prospects at a follicle size of 18 mm and serum estradiol level of 0.91 nmol/L.\n\nMedications used for final maturation and/or release of oocytes include:\n\nFinal maturation induction using GnRH agonist results in a substantial decrease in the risk of ovarian hyperstimulation syndrome (OHSS). A Cochrane review estimated that using GnRH agonist instead of hCG in IVF decreases the risk of mild, moderate or severe OHSS with an odds ratio of approximately 0.15. The review estimated that, for a woman with a 5% risk of mild, moderate or severe OHSS with the use of HCG, the risk of OHSS with the use of a GnRH agonist would be between 0 and 2%.\n\nHowever, using GnRH agonist has a lower live birth rate than when using hCG in autologous oocyte transfers (rather than ones using oocyte donation). A Cochrane review of autologous oocyte transfers estimated that GnRH agonist, compared to hCG, gives an odds ratio of pregnancy of approximately 0.47. It estimated that, for a woman with a 31% chance of achieving live birth with the use of hCG, the chance of a live birth with the use of an GnRH agonist would be between 12% and 24%. Likewise, using GnRH agonist instead of hCG was associated with a lower ongoing pregnancy rate (pregnancy beyond 12 weeks) than was seen with HCG (odds ratio 0.70) and a higher rate of early (less than 12 weeks) miscarriage (odds ratio 1.74). However, a higher pregnancy rate when using hCG is only found in those receiving luteal support without luteinizing hormone activity (such as progesterone or progestin).\n\nFinal maturation induction using a GnRH agonist is recommended in women with cancer undergoing fertility preservation, because ovarian hyperstimulation syndrome is associated with an increased risk of arterial thrombotic events such as stroke, myocardial infarction and peripheral arterial embolism, and this risk can add to an already increased risk caused by the cancer.\n\nUsing hCG versus GnRH agonist has no effect on the risk of multiple pregnancy. Also, no difference has been found between the regimens regarding live birth rate or ongoing pregnancy rate when the controlled ovarian hyperstimulation was followed by oocyte donation.\n"}
{"id": "371703", "url": "https://en.wikipedia.org/wiki?curid=371703", "title": "Fitness proportionate selection", "text": "Fitness proportionate selection\n\nFitness proportionate selection, also known as roulette wheel selection, is a genetic operator used in genetic algorithms for selecting potentially useful solutions for recombination.\n\nIn fitness proportionate selection, as in all selection methods, the fitness function assigns a fitness to possible solutions or chromosomes. This fitness level is used to associate a probability of selection with each individual chromosome. If formula_1 is the fitness of individual formula_2 in the population, its probability of being selected is \nwhere formula_4 is the number of individuals in the population.\n\nThis could be imagined similar to a Roulette wheel in a casino. Usually a proportion of the wheel is assigned to each of the possible selections based on their fitness value. This could be achieved by dividing the fitness of a selection by the total fitness of all the selections, thereby normalizing them to 1. Then a random selection is made similar to how the roulette wheel is rotated.\n\nWhile candidate solutions with a higher fitness will be less likely to be eliminated, there is still a chance that they may be eliminated because their probability of selection is less than 1 (or 100%). Contrast this with a less sophisticated selection algorithm, such as truncation selection, which will eliminate a fixed percentage of the weakest candidates. With fitness proportionate selection there is a chance some weaker solutions may survive the selection process. This is because even though the probability that the weaker solutions will survive is low, it is not zero which means it is still possible they will survive; this is an advantage, because there is a chance that even weak solutions may have some features or characteristics which could prove useful following the recombination process.\n\nThe analogy to a roulette wheel can be envisaged by imagining a roulette wheel in which each candidate solution represents a pocket on the wheel; the size of the pockets are proportionate to the probability of selection of the solution. Selecting N chromosomes from the population is equivalent to playing N games on the roulette wheel, as each candidate is drawn independently.\n\nOther selection techniques, such as stochastic universal sampling or tournament selection, are often used in practice. This is because they have less stochastic noise, or are fast, easy to implement and have a constant selection pressure [Blickle, 1996].\n\nThe naive implementation is carried out by first generating the cumulative probability distribution (CDF) over the list of individuals using a probability proportional to the fitness of the individual. A uniform random number from the range [0,1) is chosen and the inverse of the CDF for that number gives an individual. This corresponds to the roulette ball falling in the bin of an individual with a probability proportional to its width. The \"bin\" corresponding to the inverse of the uniform random number can be found most quickly by using a binary search over the elements of the CDF. It takes in the O(log n) time to choose an individual. A faster alternative that generates individuals in O(1) time will be to use the alias method.\n\nRecently, a very simple algorithm was introduced that is based on \"stochastic acceptance\". The algorithm randomly selects an individual (say formula_2) and accepts the selection with probability formula_6, where formula_7 is the maximum fitness in the population. Certain analysis indicates that the stochastic acceptance version has a considerably better performance than versions based on linear or binary search, especially in applications where fitness values might change during the run. While the behavior of this algorithm is typically fast, some fitness distributions (such as exponential distributions) may require formula_8 iterations in the worst case. This algorithm also requires more random numbers than binary search.\n\nFor example, if you have a population with fitnesses [1, 2, 3, 4], then the sum is (1 + 2 + 3 + 4 = 10). Therefore, you would want the probabilities or chances to be [1/10, 2/10, 3/10, 4/10] or [0.1, 0.2, 0.3, 0.4]. If you were to visually normalize this between 0.0 and 1.0, it would be grouped like below with [red = 1/10, green = 2/10, blue = 3/10, black = 4/10]:\n\nUsing the above example numbers, this is how to determine the probabilities:\n\nThe last index should always be 1.0 or close to it. Then this is how to randomly select an individual:\n\n\n"}
{"id": "57043156", "url": "https://en.wikipedia.org/wiki?curid=57043156", "title": "Funerary Helmets", "text": "Funerary Helmets\n\nFunerary Helmets, Mortuary Helms or Mort Helms were the major element of a suit of armour that was most often placed above or near the carved memorial effigy of the knights or members of the nobility concerned in a tradition that ran from at least the 14th through to the 17th century, particularly when the person concerned had gained a reputation in life as a warrior. These helmets were often brightly painted or otherwise ornamented with floral designs, etc. Largely located within rural churches and other religious buildings the practice was especially common in the south-west English counties and Cornwall with only a few examples known from Scotland. \n\nSome merchants sought the right to this honour and this was granted in the late 16th century, thereby recognising that the person concerned had lived an honorable, chivalric life. This privilege resulted in a greatly increased demand for helms with the reuse and redecoration of old examples and the manufacture of new ones.\n\nIn the 17th century it became more common for armour to accompany the funeral procession to the church rather than being permanently left on display at the funerary monument.\n\nThe tradition was not restricted to the United Kingdom and was found elsewhere in Europe.\n\nIt was common for funerary helmets to be richly decorated especially with floral designs that were painted in bright colours. The appropriate coats of arms might be added and in addition to reduce corrosion the inside of the helmet was often painted. Crests may have been added in some instances as with that of Sir Robert Montgomerie as recorded below.\n\nIt is likely that a number of funerary helmets have been lost or replaced due to their value as collectible items sought after by antiquarians, etc. Funerary helms might be only ornamental, but more frequently they were actual armour worn by the person during their life, either in battle or at jousts. A variety of helmets were used as shown below, such as the Armet, Bascinet, Great helm, etc.\nKing Henry V (d. 1422), Westminster Abbey. Set up over the dead king’s monument until the 20th century was his funerary helmet, a finely decorated jousting helm, now kept in the abbey museum.\n\nEdward the Black Prince or Edward of Woodstock (15 June 1330 – 8 June 1376), eldest son of Edward III, King of England. Dating from 1376 his funerary helmet is to be found above his funerary monument in Canterbury Cathedral. \n\nSir Robert Montgomerie, Skelmorlie Aisle, Largs. An engraving of the 1636 'Montgomery Monument' by McGibbon and Ross in 1886 shows a funerary helm projecting from the southern wall however it shows some differences in appearance from the helm that today sits on the tomb itself. The helm that exists today looks similar to one photographed by the Ministry of Works in 1954. In 1915 an engraving by Robert Bryden does not show a helmet above the south door or on the monument. The surviving helmet could not have been worn as the visor is fixed and holes on the top suggest either a means of attachment or that a crest had once been present.\n\nSir Thomas Long, St James's Church, Draycot Cerne, Wiltshire. This helmet is of the armet type and was originally part of a collection that until 2009 hung above his grave site, a 'rich gothique altar monument'. His gauntlets were also displayed and both are now kept in the Wiltshire Museum in Devizes. Sir Thomas (1451-1508) had fought in the army of Henry VII against the rebel Perkin Warbeck and received his knighthood at the marriage of Arthur, Prince of Wales.\n\nSir Hugh Hastings (d. 1347), St. Mary's Church, Elsing, Norfolk, England. One of the early examples of a doubly pivoted visor on a bascinet is located at the funerary monument Sir Hugh.\n\nJames Cunninghame, 7th Earl of Glencairn, the Glencairn Aisle, St Maurs-Glencairn church, Kilmaurs, East Ayrshire. Here a helmet has been carved from stone on this 1600 funerary monument and lies next to the effigy of the earl whilst a carved open bible sits next to his wife's effigy.\n\n"}
{"id": "23443467", "url": "https://en.wikipedia.org/wiki?curid=23443467", "title": "Happiness at work", "text": "Happiness at work\n\nDespite a large body of positive psychological research into the relationship between happiness and productivity, happiness at work has traditionally been seen as a potential by-product of positive outcomes at work, rather than a pathway to business success. During the past two decades, maintaining a level of happiness at work has become more significant and relevant due to the intensification of work caused by economic uncertainty and increase in competition. Nowadays, happiness is viewed by a growing number of scholars and senior executives as one of the major sources of positive outcomes in the workplace. In fact, companies with higher than average employee happiness exhibit better financial performance and customer satisfaction. It is thus beneficial for companies to create and maintain positive work environments and leadership that will contribute to the happiness of their employees.\n\nHappiness is not fundamentally rooted in obtaining sensual pleasures and money, but those factors can influence the well-being of an individual at the workplace. However, extensive research has revealed that freedom and autonomy at a workplace have the most effect on the employee's level of happiness, and other important factors are gaining knowledge and the ability to influence the self's working hours.\n\nRyan and Deci offer a definition for happiness in two views: happiness as being hedonic, accompanied with enjoyable feelings and desirable judgements, and happiness as being eudemonic, which involves doing virtuous, moral and meaningful things. Watson et al. claims that the most important approach to explain an individual's experience is in a hedonic tone, which is concerned with the subject's pleasant feelings, satisfying judgments, self-validation and self-actualization. However, some psychologists argue that hedonic happiness is unstable over a long period of time, especially in the absence of eudaimonic well-being. Thus, in order for one to live a happy life one must be concerned with doing virtuous, moral and meaningful things while utilising personal talents and skills.\n\nOrganisational culture represents the internal work environment created for operating an organisation. It can also represent how employees are treated by their bosses and peers. An effective organisation should have a culture that takes into account employee's happiness and encourages employee satisfaction. Although each individual has unique talents and personal preferences, the behaviors and beliefs of the people in the same organizations show common properties. This, to some extent, helps organisations to create their own cultural properties.\n\nJarow concludes that an employee feels satisfied not through comparisons with other peers, but through his/her own happiness and awareness of being in harmony with their colleagues. He uses a term called \"carrier\" to represent lack of happiness, life in constant tension and never-ending struggle for status.\n\nThere are many reasons that can contribute to happiness at work. However, when individuals are asked with regards to why they work, money is one of the most common answers as it provides people with sustenance, security and privilege. To a large extent, people work to live, and the pecuniary aspect of the work is what sustains the living. Locke, Feren, McCaleb Shaw and Denny argued that no other incentive or motivational technique comes even close to money with respect to its instrumental value.\n\nThe income-happiness relationship in life can also be applied in organisational psychology. Some studies have found positively significant relationships between salary level and job satisfaction. Some have suggested that income and happiness at work are positively correlated, and the relationship is stronger for individuals with extrinsic value orientations.\n\nHowever, others don't believe that salary, in itself, is a very strong factor in job satisfaction. Hundreds of studies and scores of systematic reviews of incentive studies consistently document the ineffectiveness of external rewards. The question regarding this subject has been recently studied by a group of people, including Judge and his colleagues. Their research shows that the intrinsic relationship between job and salary is complex. In their research, they analysed the combined impact of many existing studies to produce a much larger and statistically powerful analysis. By looking at 86 previous studies, they concluded that while is true to say that money is a driver of employee's happiness, the produced effect is transitory. Judge and his colleagues have reminded us that money may not necessarily make employees happy.\n\nJob security is an important factor to determine whether employees feel happiness at work. Different types of jobs have different levels of job security: in some situations, a position is expected to be offered for a long time, whereas in other jobs an employee may be forced to resign his/ her job. The expectation of the job availability has been related with the job-related well-being and a higher level of job security corresponds to a higher level of job satisfaction alongside a higher level of well-being.\n\nThe option for moving or shifting to alternative roles motivates the employee's participation in the workplace meaning if an employee can see the future potential for a promotion, motivation levels will increase. By contrast, if an organisation does not provide any potential for higher status position in the future, the employee's effectiveness in work will decrease. In addition, the employee may consider whether or not the position would be offered to them in the future. On the other hand, not all of the opportunities for transferring into another activity are aimed to obtain the upward movement. In some cases, they are aimed to prevent the skills obsolescence, provides more future career possibility, as well as directly increasing the skill development.\n\nJob autonomy may be defined as the condition of being self-governing or free from excessive external control in the workplace environment. The German philosopher Immanuel Kant believed that autonomy is important to human beings because it is the foundation of human dignity and the source of all morality. Among the models of human growth and development that are centred on autonomy, the most theoretically sophisticated approach has been developed around the concepts of self-regulation and intrinsic motivation. Self-determination theory proposes that 'higher behavioural effectiveness, greater volitional persistence, enhanced subjective well-being, and better assimilation of the individual within his or her social group' result when individuals act from motivations that emanate from the inner self (intrinsic motivation) rather than from sources of external regulation. For self-determination theorists, it is the experience of an external locus of causation (or the belief that one's actions are controlled by external forces) that undermines the most powerful source of natural motivation and that (when chronic) also can lead to stultification, weak self-esteem, anxiety and depression, and alienation. Thus, health and well-being as well as effective performance in social settings are closely related to the experience of autonomy. Hackman and Oldham developed the Job Characteristics Model, a framework that focused attention on autonomy and four other key factors involved in designing enriched work. Work designed to be complex and challenging (characterized by high levels of autonomy, skill variety, identity, significance, and feedback) was theorized to promote high intrinsic motivation, job satisfaction, and overall work performance. Two decades of research in this tradition have shown that job scope or complexity, an additive combination of autonomy and the four other job characteristics: (a) is correlated significantly with more objective ratings of job characteristics; (b) may be reduced to a primary factor consisting of autonomy and skill variety; and (c) has substantial effects on affective and behavioural reactions to work, mostly indirectly through critical psychological states such as experienced responsibility for the outcomes of the work. It is possible to infer from this line of research that the experience of autonomy at work has positive consequences ranging from higher job performance to job satisfaction and enhanced general well-being, which are both related to the concept of happiness at work.\n\nWork- life balance is a state of equilibrium, characterised by a high level of satisfaction, functionality, and effectiveness while successfully performing several tasks simultaneously. The non-work activity is not limited to family life only but also to various occupations and activities of which one's life is composed. Scholars and popular press articles have started promoting the importance of maintaining a work-life balance beginning in the early 1970s and have been increasing ever since. Studies suggest that there is a clear connection between the increase in work related stress to the constant advancements in digital and telecommunications technology. The existence of cell phones and other internet based devices enables access to work related issues in non- working periods, thus, adding more hours and work load. A decrease in the time allocated to non- work related activities and working nonstandard shifts has been proven to have significant negative effects on family and personal life. The immediate effect is a decrease in general well- being as the individual is unable to properly allocate the appropriate amount of time necessary to maintain a balance between the two spheres. Therefore, extensive research has been done on properly managing time as a main strategy of managing stress. It is estimated by the American Psychological Association that the national cost of stress for the US economy is approximately US$500 billion annually.\n\nSome of the physiological effects of stress include cognitive problems (forgetfulness, lack of creativity, inefficient decision making), emotional reactions (mood swings, irritability, depression, lack of motivation), behavioural issues (withdrawal from relationships and social situations, neglecting responsibilities, abuse of drugs and alcohol) and physical symptoms (tiredness, aches and pain, loss of libido).\n\nThe condition in which work performance is negatively affected by a high level of stress is termed 'burnout', in which the employee experiences a significant reduction in motivation. According to Vroom's Expectancy Theory, when the outcomes of work performance are offset by the negative impacts on the individual's general well being, or, are not valued enough by the employee, levels of motivation are low. Time management, prioritising certain tasks and actions according to one's values and beliefs are amongst the suggested course of action for managing stress and maintaining a healthy work- life balance. Psychologists have suggested that when workers have control over their work schedule, they are more capable of balancing work and non- work related activities. The difficulty of distinguishing and balancing between those spheres was defined by sociologist Arlie Russell Hochschild as Time Bind. The reality of constant increase in competition and economic uncertainty frequently forces the employee to compromise the balance for the sake of financial and job security. Therefore, work/ life balance policies are created by many businesses and are largely implemented and dealt by line managers and supervisors, rather than at the organizational level as the employee's well being can be more carefully observed and monitored.\n\nAccording to Maslow's hierarchy of needs, feeling a sense of belonging to groups is a significant motivation for human beings. Co-workers are an important social group and relationships with them can be a source of pleasure. Three Need theory also suggests that people have a Need for affiliation. Also, person-job fit, the matching between personal abilities and job demand, has important effects on job satisfaction.\n\nHerzberg's Two-Factor theory indicates that co-workers relationship belongs to hygiene needs, which are related to environmental elements. When environmental elements are met, satisfaction will be achieved. Employees tend to be happier and more hardworking when they are in good working environment, for instance, being happy to work in a good working relationship.\n\nGroup relationship is important and has effects on employees' absenteeism and turnover rate. Cohesive groups increase job satisfactions. Mann and Baumgartel state that the sense of group belongingness, group pride, group solidarity or group spirit relates inversely to the absenteeism rate. Among the target groups, group with high cohesiveness tend to have low absenteeism rate while group with low cohesiveness tend to have higher absenteeism rate.\n\nSeashore investigated 228 work groups in a heavy-machinery-manufacturing company. His findings suggest that Group cohesiveness helps employees solve their work-related pressure. Seashore define cohesiveness as '1) members perceive themselves to be a part of a group 2) members prefer to remain in the group rather than to leave, and 3) perceive their group to be better than other groups with respect to the way the men get along together, the way they help each other out, and the way they stick together'. Among the target group, the less cohesive the group, the more likely its employees are to feel nervous and jumpy.\n\nDifferent communication ways in groups contribute to different employees satisfaction. For example, the chain structure results in low satisfaction while the circle structure results in high satisfaction.\n\nIn relations to the work place, successful leadership will structure and develop relationships amongst employees and consequently, employees will empower each other.\n\nKurt Lewin argued that there are 3 main styles of leaderships:\n\nManagement plays an important role in an employee's job satisfaction and happiness. Good leadership can empower employees to work better towards reaching the organisation's goals. For example, if a leader is considerate, the employees will tend to develop a positive attitude towards management and thus, work more effectively.\n\nFeelings, including happiness, are often hidden by employees and should be identified for effective communication in the workplace. Ineffective communication at work is not uncommon, as leaders tend to focus on their own matters and give less attention to employees at a lower rank. Employees, on the other hand, tend to be reluctant to talk about their own problem and assume leaders can figure out the problem. As a result, both leaders and employees can cause repetitive misunderstandings.\n\nResearch shows that employees who are happiest at work are considered to be the most efficient and display the highest levels of performance. For instance, the iOpener Institute found that a happy worker is a high-performing one. The happiest employees only take one-tenth the sick leave of their least happy colleagues as they are in better physical and psychological health than their colleagues. Furthermore, happier employees display a higher level of loyalty, as they tend to stay for far longer periods in their organizations. Happiness at work is the feeling that employee really enjoy what they do and they are proud of themselves, they enjoy people being around, thus they have better performance.\n\nEmployees' behaviour can be influenced by happiness or unhappiness. People would like to participate in work when they feel happiness, or in the converse, absenteeism might occur. Absenteeism can be defined as the lack of physical presence at a given place and time determined by an individual's work schedule.\n\nAlthough employee absenteeism is usually associated with the job-related well-being or simply whether the employee feels happiness during the work, other factors are also important. Firstly, the health constraints such as being ill would force the employee absence from the work. Secondly, social and families pressure can also influence the employee's decision to participate in the work.\n\nEmployee turnover can be considered as another result derived from employee happiness. In particular, it is more likely that individual employees are able to deal with stress and passive feelings when they are in good mood. As people spend a considerable amount of time in the workplace, factors such as employee relationship, organizational culture and job performance can have a significant impact on work happiness. What is more, Avey and his colleagues use a concept called psychological capital to link employee satisfaction with work related outcomes, especially turnover intention and actual turnover. However, their findings were limited due to some reasons. For example, they omitted an important factor, which was emotional stability. Additionally, other researchers have pointed out that the relationship between work happiness and turnover intention is generally low, even if a dissatisfied employee is more likely to quit his/her job than the satisfied one. Therefore, whether or not employee happiness can be linked with employee's turnover intention is still a moot point.\n\nAlthough there are a few surveys used to measure the happiness or well-being level of people in different countries such as the World Happiness Report, the Happy Planet Index and the OECD Better Life Index, there are no surveys that measure happiness in the specific context of the workplace. There are, however, surveys created to assess the job satisfaction level of employees. Even though job satisfaction is a different concept, it is positively correlated to happiness and subjective well-being. The main job satisfaction scales are: The Job Satisfaction Survey (JSS), The Job Descriptive Index (JDI) and The Minnesota Satisfaction Questionnaire (MSQ). The Job Satisfaction Survey (JSS) assesses nine facets of job satisfaction, as well as overall satisfaction. The facets include pay and pay raises, promotion opportunities, relationship with the immediate supervisor, fringe benefits, rewards given for good performance, rules and procedures, relationship with coworkers, type of work performed and communication within the organization. The scale contains thirty-six items and uses a summated rating scale format. The JSS can provide ten scores. Each of the nine subscales produce a separate score and the total of all items produces a total score. The Job Descriptive Index (JDI) scale assesses five facets which are work, pay, promotion, supervision and coworkers. The entire scale contains seventy-two items with either nine or eighteen items per subscale. Each item is an evaluative adjective or short phrase that is descriptive of the job. The individual has to respond \"yes\", \"uncertain\" or \"no\" for each item. The Minnesota Satisfaction Questionnaire (MSQ) has two versions, a one hundred item long version and a twenty item short form. It covers twenty facets including activity, independence, variety, social status, supervision (human relations), supervision (technical), moral values, security, social service, authority, ability utilization, company policies and practices, compensation, advancement, responsibility, creativity, working conditions, coworkers, recognition and achievement. The long form contains five items per facet, while the short one contains only one.\n\nUniversity of Kent research show that career satisfaction stems from living near work, access to the outdoors, mindfulness, flow, non open plan offices, absence of many tight deadlines or long hours, small organisations or self-employment, variety, friends at work, working on a product or service from start to finish, focus, financial freedom, autonomy, positive feedback, helping others, purpose/goals, learning new skill and challenges.\n\nDoctor, dentist, armed forces, teacher, leisure/tourism and journalist are the 6 happiest graduate jobs while social worker, civil servant, estate agent, secretary and administrator at the 5 least happy. According to one study Clergy, CEO's, Agriculturist, Company Secretaries, Regulatory professional, Health managers, Medical Professionals, Farmers and Accommodation managers are the happiest jobs in that order in another study. .\n\nOn the other hand, social workers, nurses, social workers medical doctors, and psychiatrists abuse substances and incur mental ill-health at among the highest rates of any occupation. For instance, the psychiatrist burnout rate is 40%.\n\n\n"}
{"id": "738376", "url": "https://en.wikipedia.org/wiki?curid=738376", "title": "Idris I of Morocco", "text": "Idris I of Morocco\n\nIdris I (), also known as \"Idris ibn Abdillah\", was the founder of the Idrisid dynasty in part of northern Morocco in alliance with the Berber tribe of Awraba. He ruled from 788 to 791. He is credited with founding the dynasty that established Moroccan statehood and is regarded as the \"founder of Morocco\". He was the great-great-great-grandson of the Islamic Prophet Muhammad.\n\nIdris was the great-grandchild of Hasan, who was the son of Fatimah and grandson of the Islamic prophet, Muhammad. His brothers Muhammad al-Nafs al-Zakiyya and Ibrahim had been killed by the Abbasids during an abortive rebellion, and Idris himself escaped after the defeat of another Alid uprising at the Battle of Fakhkh in 786 and took refuge in the western Maghreb (nowadays Morocco). There he established the Arabian Idrisid dynasty.\nIn 789 arrived in Walīla, the site of the Roman Volubilis where he founded the town of Moulay Idriss near the hill of Zerhoun surrounding the native Berber tribes. It was then occupied by the Berber tribe of the Awraba, under Ishaq ibn Mohammed. He married Kenza, daughter of Ishaq ben Mohammed the king of the tribe, fathering a son, Idris II. This event is considered a consolidation and the birth of the Idrisid dynasty, the fourth Muslim State in Morocco after Nekor (710 - 1019), Barghawata (744 - 1058), and Midrar (757 - 976).\n\nIdris I conquered large parts of northern Morocco, his son Idris II made Fez the capital city of the Idrisid dynasty. In 789 AD, he captured Tlemcen (modern day Algeria) which became part of the kingdom. This succession of events prompted vengeance from the Abbasid caliph Harun al-Rashid, who sent emissaries to kill him. Idris I was poisoned and died in 791. His son, Idris II, was brought up by the Awraba, and left Walīla for Fes in 808. Idris is buried in Moulay Idriss.\n\n\n\n"}
{"id": "15474", "url": "https://en.wikipedia.org/wiki?curid=15474", "title": "Infanticide", "text": "Infanticide\n\nInfanticide (or infant homicide) is the intentional killing of infants.\n\nParental infanticide researchers have found that mothers are far more likely than fathers to be the perpetrators of neonaticide and slightly more likely to commit infanticide in general.\n\nAnthropologist Laila Williamson notes that \"Infanticide has been practiced on every continent and by people on every level of cultural complexity, from hunter gatherers to high civilizations, including our own ancestors. Rather than being an exception, then, it has been the rule.\"\n\nIn many past societies, certain forms of infanticide were considered permissible. \n\nThe practice of infanticide has taken many forms over time. Child sacrifice to supernatural figures or forces, such as that believed to have been practiced in ancient Carthage, may be only the most notorious example in the ancient world. \n\nA frequent method of infanticide in ancient Europe and Asia was simply to abandon the infant, leaving it to die by exposure (i.e. hypothermia, hunger, thirst, or animal attack).\n\nIn at least one island in Oceania, infanticide was carried out until the 20th century by suffocating the infant, while in pre-Columbian Mesoamerica and in the Inca Empire it was carried out by sacrifice (see below).\n\nMany Neolithic groups routinely resorted to infanticide in order to control their numbers so that their lands could support them. Joseph Birdsell believed that infanticide rates in prehistoric times were between 15% and 50% of the total number of births, while Laila Williamson estimated a lower rate ranging from 15% to 20%. Both anthropologists believed that these high rates of infanticide persisted until the development of agriculture during the Neolithic Revolution. Comparative anthropologists have calculated that 50% of female newborn babies were killed by their parents during the Paleolithic era. From the infants hominid skulls (e.g. Taung child skull) that had been traumatized, has been proposed cannibalism by Raymond A. Dart. The children were not necessarily actively killed, but neglect and intentional malnourishment may also have occurred, as proposed by Vicente Lull as an explanation for an apparent surplus of men and the below average height of women in prehistoric Menorca.\n\nArchaeologists have uncovered physical evidence of child sacrifice at several locations. Some of the best attested examples are the diverse rites which were part of the religious practices in Mesoamerica and the Inca Empire.\n\nThree thousand bones of young children, with evidence of sacrificial rituals, have been found in Sardinia. Pelasgians offered a sacrifice of every tenth child during difficult times. Syrians sacrificed children to Jupiter and Juno. Many remains of children have been found in Gezer excavations with signs of sacrifice. Child skeletons with the marks of sacrifice have been found also in Egypt dating 950–720 BCE. In Carthage \"[child] sacrifice in the ancient world reached its infamous zenith\". Besides the Carthaginians, other Phoenicians, and the Canaanites, Moabites and Sepharvites offered their first-born as a sacrifice to their gods.\n\nIn Egyptian households, at all social levels, children of both sexes were valued and there is no evidence of infanticide. The religion of the Ancient Egyptians forbade infanticide and during the Greco-Roman period they rescued abandoned babies from manure heaps, a common method of infanticide by Greeks or Romans, and were allowed to either adopt them as foundlings or raise them as slaves, often giving them names such as \"copro -\" to memorialise their rescue. Strabo considered it a peculiarity of the Egyptians that every child must be reared. Diodorus indicates infanticide was a punishable offence. Egypt was heavily dependent on the annual flooding of the Nile to irrigate the land and in years of low inundation severe famine could occur with breakdowns in social order resulting, notably between 930–1070 AD and 1180–1350 AD. Instances of cannibalism are recorded during these periods but it is unknown if this happened during the pharaonic era of Ancient Egypt. Beatrix Midant-Reynes describes human sacrifice as having occurred at Abydos in the early dynastic period (c. 3150–2850 BCE), while Jan Assmann asserts there is no clear evidence of human sacrifice ever happening in Ancient Egypt.\n\nAccording to Shelby Brown, Carthaginians, descendants of the Phoenicians, sacrificed infants to their gods. Charred bones of hundreds of infants have been found in Carthaginian archaeological sites. One such area harbored as many as 20,000 burial urns. Skeptics suggest that the bodies of children found in Carthaginian and Phoenician cemeteries were merely the cremated remains of children that died naturally.\n\nPlutarch (c. 46–120 AD) mentions the practice, as do Tertullian, Orosius, Diodorus Siculus and Philo. The Hebrew Bible also mentions what appears to be child sacrifice practiced at a place called the Tophet (from the Hebrew \"taph\" or \"toph\", to burn) by the Canaanites. Writing in the 3rd century BCE, Kleitarchos, one of the historians of Alexander the Great, described that the infants rolled into the flaming pit. Diodorus Siculus wrote that babies were roasted to death inside the burning pit of the god Baal Hamon, a bronze statue.\n\nThe historical Greeks considered the practice of adult and child sacrifice barbarous, however, the exposure of newborns was widely practiced in ancient Greece, it was even advocated by Aristotle in the case of congenital deformity — \"As to the exposure of children, let there be a law that no deformed child shall live.” In Greece the decision to expose a child was typically the father's, although in Sparta the decision was made by a group of elders. Exposure was the preferred method of disposal, as that act in itself was not considered to be murder; moreover, the exposed child technically had a chance of being rescued by the gods or any passersby. This very situation was a recurring motif in Greek mythology.\nTo notify the neighbors of a birth of a child, a woolen strip was hung over the front door to indicate a female baby and an olive branch to indicate a boy had been born. Families did not always keep their new child. After a woman had a baby, she would show it to her husband. If the husband accepted it, it would live, but if he refused it, it would die. Babies would often be rejected if they were illegitimate, unhealthy or deformed, the wrong sex, or too great a burden on the family. These babies would not be directly killed, but put in a clay pot or jar and deserted outside the front door or on the roadway. In ancient Greek religion, this practice took the responsibility away from the parents because the child would die of natural causes, for example hunger, asphyxiation or exposure to the elements.\n\nThe practice was prevalent in ancient Rome, as well. Philo was the first philosopher to speak out against it. A letter from a Roman citizen to his sister, or a pregnant wife from her husband, dating from 1 BC, demonstrates the casual nature with which infanticide was often viewed:\n\nIn some periods of Roman history it was traditional for a newborn to be brought to the \"pater familias\", the family patriarch, who would then decide whether the child was to be kept and raised, or left to die by exposure. The Twelve Tables of Roman law obliged him to put to death a child that was visibly deformed. The concurrent practices of slavery and infanticide contributed to the \"background noise\" of the crises during the Republic.\n\nInfanticide became a capital offense in Roman law in 374 AD, but offenders were rarely if ever prosecuted.\n\nAccording to mythology, Romulus and Remus, twin infant sons of the war god Mars, survived near-infanticide after being tossed into the Tiber River. According to the myth, they were raised by wolves, and later founded the city of Rome.\n\nJudaism prohibits infanticide, and has for some time, dating back to at least early Common Era. Roman historians wrote about the ideas and customs of other peoples, which often diverged from their own. Tacitus recorded that the Jews \"regard it as a crime to kill any late-born children\". Josephus, whose works give an important insight into 1st-century Judaism, wrote that God \"forbids women to cause abortion of what is begotten, or to destroy it afterward\".\n\nIn his book \"Germania\", Tacitus wrote that the ancient Germanic tribes enforced a similar prohibition. He found such mores remarkable and commented: \"[The Germani] hold it shameful to kill any unwanted child.\" Modern scholarship differs. John Boswell believed that in ancient Germanic tribes unwanted children were exposed, usually in the forest. \"It was the custom of the [Teutonic] pagans, that if they wanted to kill a son or daughter, they would be killed before they had been given any food.\" Usually children born out of wedlock were disposed that way.\n\nIn his highly influential \"Pre-historic Times\", John Lubbock described burnt bones indicating the practice of child sacrifice in pagan Britain.\n\nThe last canto, \"Marjatan poika\" (Son of Marjatta), of Finnish national epic Kalevala describes an assumed infanticide. Väinämöinen orders the infant bastard son of Marjatta to be drowned in marsh.\n\nThe Íslendingabók, a main source for the early history of Iceland, recounts that on the Conversion of Iceland to Christianity in 1000 it was provided – in order to make the transition more palatable to Pagans – that \"the old laws allowing exposure of newborn children will remain in force\".\nHowever, this provision – like other concessions made at the time to the Pagans – was abolished some years later.\n\nChristianity rejects infanticide. The \"Teachings of the Apostles\" or \"Didache\" said \"thou shalt not kill a child by abortion, neither shalt thou slay it when born\". The \"Epistle of Barnabas\" stated an identical command, both thus conflating abortion and infanticide. Apologists Tertullian, Athenagoras, Minucius Felix, Justin Martyr and Lactantius also maintained that exposing a baby to death was a wicked act. In 318 AD, Constantine I considered infanticide a crime, and in 374 AD, Valentinian I mandated the rearing of all children (exposing babies, especially girls, was still common). The Council of Constantinople declared that infanticide was homicide, and in 589 AD, the Third Council of Toledo took measures against the custom of killing their own children.\n\nWhereas theologians and clerics preached sparing their lives, newborn abandonment continued as registered in both the literature record and in legal documents. According to William L. Langer, exposure in the Middle Ages \"was practiced on gigantic scale with absolute impunity, noticed by writers with most frigid indifference\". At the end of the 12th century, notes Richard Trexler, Roman women threw their newborns into the Tiber river in daylight.\n\nHowever, it also conjectured that the notion of \"rampant\" infanticide is a myth pushed by modern historians inferring from lack of particular records, and \"there is absolutely no evidence to support such carnage.\"\n\nUnlike other European regions, in the Middle Ages the German mother had the right to expose the newborn. In Gotland, Sweden, children were also sacrificed.\n\nIn the High Middle Ages, abandoning unwanted children finally eclipsed infanticide. Unwanted children were left at the door of church or abbey, and the clergy was assumed to take care of their upbringing. This practice also gave rise to the first orphanages.\n\nHowever, very high sex ratios were common in even late medieval Europe, which may indicate sex-selective infanticide.\n\nSome Muslim sources allege that pre-Islamic Arabian society practiced infanticide as a form of \"post-partum birth control\". The word \"waʾd\" was used to describe the practice. These sources state that infanticide was practiced either out of destitution (thus practiced on males and females alike), or as \"disappointment and fear of social disgrace felt by a father upon the birth of a daughter\".\n\nSome authors believe that there is little evidence that infanticide was prevalent in pre-Islamic Arabia or early Muslim history, except for the case of the Tamim tribe, who practiced it during severe famine according to Islamic sources. Others state that \"female infanticide was common all over Arabia during this period of time\" (pre-Islamic Arabia), especially by burying alive a female newborn. A tablet discovered in Yemen, forbidding the people of a certain town from engaging in the practice, is the only written reference to infanticide within the peninsula in pre-Islamic times.\n\nInfanticide is explicitly prohibited by the Qur'an. \"And do not kill your children for fear of poverty; We give them sustenance and yourselves too; surely to kill them is a great wrong.\"\nTogether with polytheism and homicide, infanticide is regarded as a grave sin (see and ). Infanticide is also implicitly denounced in the story of Pharaoh's slaughter of the male children of Israelites (see ; ; ; ; ;).\n\nInfanticide may have been practiced as human sacrifice, as part of the pagan cult of Perun. Ibn Fadlan describes sacrificial practices at the time of his trip to Kiev Rus (present day Ukraine) in 921–922, and describes an incident of a woman voluntarily sacrificing her life as part of a funeral rite for a prominent leader, but makes no mention of infanticide. The Primary Chronicle, one of the most important literary sources before the 12th century, indicates that human sacrifice to idols may have been introduced by Vladimir the Great in 980. The same Vladimir the Great formally converted Kiev Rus into Christianity just 8 years later, but pagan cults continued to be practiced clandestinely in remote areas as late as the 13th century.\n\nIn Kamchatka, babies were killed and thrown to the dogs. American explorer George Kennan noted that among the Koryaks, a Mongoloid people of north-eastern Siberia, infanticide was still common in the nineteenth century. One of a pair of twins was always sacrificed.\n\nThe Svans killed newborn females by filling their mouths with hot ashes.\n\nInfanticide (as a crime) gained both popular and bureaucratic significance in Victorian Britain. By the mid 19th century, in the context of criminal lunacy and the insanity defence, killing one's own child(ren) attracted ferocious debate, as the role of women in society was defined by motherhood, and it was thought that any woman who murdered her own child was by definition insane and could not be held responsible for her actions. Several cases were subsequently highlighted during the Royal Commission on Capital Punishment (1864-66), as a particular felony where an effective avoidance of the death penalty had informally begun.\n\nThe New Poor Law Act of 1834 ended parish relief for unmarried mothers and allowed fathers of illegitimate children to avoid paying for \"child support\". Unmarried mothers then received little assistance and the poor were left with the option either entering the workhouse, prostitution, infanticide or abortion. By the middle of the century infanticide was common for social reasons, such as illegitimacy, and the introduction of child life insurance additionally encouraged some women to kill their children for gain. Examples are Mary Ann Cotton, who murdered many of her 15 children as well as 3 husbands, Margaret Waters, the 'Brixton Baby Farmer', a professional baby-farmer who was found guilty of infanticide in 1870, Jessie King hanged in 1889, Amelia Dyer, the 'Angel Maker', who murdered over 400 babies in her care, and Ada Chard-Williams, a baby farmer who was later hanged at Newgate prison.\n\nThe Times reported that 67 infants were murdered in London in 1861 and 150 more recorded as \"found dead\", many of which were found on the streets. Another 250 were suffocated, half of them not recorded as accidental deaths. The report noted that \"infancy in London has to creep into life in the midst of foes.\"\n\nRecording a birth as a still-birth was also another way of concealing infanticide because still-births did not need to be registered until 1926 and they did not need to be buried in public cemeteries. In 1895 the Sun (London) published an article \"Massacre of the Innocents\" highlighting the dangers of baby-farming, in the recording of stillbirths and quoting Braxton-Hicks, the London Coroner, on lying-in houses: \"I have not the slightest doubt that a large amount of crime is covered by the expression `still-birth’. There are a large number of cases of what are called newly-born children, which are found all over England, more especially in London and large towns, abandoned in streets, rivers, on commons, and so on.\" He continued \"a great deal of that crime is due to what are called lying-in houses, which are not registered, or under the supervision of that sort, where the people who act as midwives constantly, as soon as the child is born, either drop it into a pail of water or smother it with a damp cloth. It is a very common thing, also, to find that they bash their heads on the floor and break their skulls.\"\n\nThe last British woman to be executed for infanticide of her own child was Rebecca Smith, who was hanged in Wiltshire in 1849.\n\nThe Infant Life Protection Act of 1897 required local authorities to be notified within 48 hours of changes in custody or the death of children under seven years. Under the Children’s Act of 1908 \"no infant could be kept in a home that was so unfit and so overcrowded as to endanger its health, and no infant could be kept by an unfit nurse who threatened, by neglect or abuse, its proper care and maintenance.\"\n\nShort of execution, the harshest penalties were imposed on practitioners of infanticide by the legal codes of the Qin dynasty and Han dynasty of ancient China.\n\nMarco Polo, the explorer, saw newborns exposed in Manzi. China's society practiced sex selective infanticide. Philosopher Han Fei Tzu, a member of the ruling aristocracy of the 3rd century BC, who developed a school of law, wrote: \"As to children, a father and mother when they produce a boy congratulate one another, but when they produce a girl they put it to death.\" Among the Hakka people, and in Yunnan, Anhui, Sichuan, Jiangxi and Fujian a method of killing the baby was to put her into a bucket of cold water, which was called \"baby water\".\n\nInfanticide was known in China as early as the 3rd century BC, and, by the time of the Song dynasty (960–1279 AD), it was widespread in some provinces. Buddhist belief in transmigration allowed poor residents of the country to kill their newborn children if they felt unable to care for them, hoping that they would be reborn in better circumstances. Furthermore, some Chinese did not consider newborn children fully \"human\", and saw \"life\" beginning at some point after the sixth month after birth.\n\nContemporary writers from the Song dynasty note that, in Hubei and Fujian provinces, residents would only keep three sons and two daughters (among poor farmers, two sons and one daughter), and kill all babies beyond that number at birth. Initially the sex of the child was only one factor to consider. By the time of the Ming Dynasty, however (1368–1644), male infanticide was becoming increasingly uncommon. The prevalence of female infanticide remained high much longer. The magnitude of this practice is subject to some dispute; however, one commonly quoted estimate is that, by late Qing, between one fifth and one quarter of all newborn girls, across the entire social spectrum, were victims of infanticide. If one includes excess mortality among female children under 10 (ascribed to gender-differential neglect), the share of victims rises to one third.\n\nScottish Physician John Dudgeon, who worked in Beijing, China, during the Qing Dynasty said that in China, \"Infanticide does not prevail to the extent so generally believed among us, and in the north it does not exist at all.\"\nGender-selected abortion, abandonment, and infanticide are illegal in present-day China. Nevertheless, the US State Department, and the human rights organization Amnesty International have all declared that China's family planning programs, called the one child policy, contribute to infanticide. The sex gap between males and females aged 0–19 years old was estimated to be 25 million in 2010 by the United Nations Population Fund.\n\nSince feudal Japan the common slang for infanticide was \"mabiki\" (間引き) which means to pull plants from an overcrowded garden. A typical method in Japan was smothering through wet paper on the baby's mouth and nose. It became common as a method of population control. Farmers would often kill their second or third sons. Daughters were usually spared, as they could be married off, sold off as servants or prostitutes, or sent off to become geishas. Mabiki persisted in the 19th century and early 20th century. To bear twins was perceived as barbarous and unlucky and efforts were made to hide or kill one or both twins.\n\nFemale infanticide of newborn girls was systematic in feudatory Rajputs in South Asia for illegitimate female children during the Middle Ages. According to Firishta, as soon as the illegitimate female child was born she was held \"in one hand, and a knife in the other, that any person who wanted a wife might take her now, otherwise she was immediately put to death\". The practice of female infanticide was also common among the Kutch, Kehtri, Nagar, Bengal, Miazed, Kalowries in India inhabitants, and also among the Sindh in British India.\n\nIt was not uncommon that parents threw a child to the sharks in the Ganges River as a sacrificial offering. The British colonists were unable to outlaw the custom until the beginnings of the 19th century.\n\nAccording to social activists, female infanticide has remained a problem in India into the 21st century, with both NGOs and the government conducting awareness campaigns to combat it.\nIn India female infanticide is more common than the killing of male offspring, due to sex-selective infanticide. In China for example, the sex gap between males and females aged 0–19 years old was estimated to be 25 million in 2010 by the United Nations Population Fund.\n\nIn some African societies some neonates were killed because of beliefs in evil omens or because they were considered unlucky. Twins were usually put to death in Arebo; as well as by the Nama people of South West Africa; in the Lake Victoria Nyanza region; by the Tswana in Portuguese East Africa; in some parts of Igboland, Nigeria twins were sometimes abandoned in a forest at birth (as depicted in \"Things Fall Apart\"), oftentimes one twin was killed or hidden by midwives of wealthier mothers; and by the !Kung people of the Kalahari Desert. The Kikuyu, Kenya's most populous ethnic group, practiced ritual killing of twins.\n\nInfanticide is rooted in the old traditions and beliefs prevailing all over the country. A survey conducted by Disability Rights International found that 45% women interviewed by them in Kenya were pressured to kill their children born with disabilities. The pressure being much higher in the rural areas, with every second mother being forced out of three.\n\nLiterature suggests infanticide may have occurred reasonably commonly among Indigenous Australians, in all areas of Australia prior to European settlement. Infanticide may have continued to occur quite often up until the 1960s. An 1866 issue of \"The Australian News for Home Readers\" informed readers that \"the crime of infanticide is so prevalent amongst the natives that it is rare to see an infant\".\n\nAuthor Susanna de Vries in 2007 told a newspaper that her accounts of Aboriginal violence, including infanticide, were censored by publishers in the 1980s and 1990s. She told reporters that the censorship \"stemmed from guilt over the stolen children question\". Keith Windschuttle weighed in on the conversation, saying this type of censorship started in the 1970s. In the same article Louis Nowra suggested that infanticide in customary Aboriginal law may have been because it was difficult to keep an abundant number of Aboriginal children alive; there were life-and-death decisions modern-day Australians no longer have to face.\n\nAccording to William D. Rubinstein, \"Nineteenth-century European observers of Aboriginal life in South Australia and Victoria reported that about 30% of Aboriginal infants were killed at birth.\"\n\nJames Dawson wrote a passage about infanticide among Indigenous people in the western district of Victoria, which stated that \"Twins are as common among them as among Europeans; but as food is occasionally very scarce, and a large family troublesome to move about, it is lawful and customary to destroy the weakest twin child, irrespective of sex.\nIt is usual also to destroy those which are malformed.\"\n\nHe also wrote \"When a woman has children too rapidly for the convenience and necessities of the parents, she makes up her mind to let one be killed, and consults with her husband which it is to be. As the strength of a tribe depends more on males than females, the girls are generally sacrificed.\nThe child is put to death and buried, or burned without ceremony; not, however, by its father or mother, but by relatives. No one wears mourning for it.\nSickly children are never killed on account of their bad health, and are allowed to die naturally.\"\n\nIn 1937, a reverend in the Kimberley offered a \"baby bonus\" to Aboriginal families as a deterrent against infanticide and to increase the birthrate of the local Indigenous population.\n\nA Canberran journalist in 1927 wrote of the \"cheapness of life\" to the Aboriginal people local to the Canberra area 100 years before. \"If drought or bush fires had devastated the country and curtailed food supplies, babies got short shift. Ailing babies, too would not be kept\" he wrote.\n\nA bishop wrote in 1928 that it was common for Aboriginal Australians to restrict the size of their tribal groups, including by infanticide, so that the food resources of the tribal area may be sufficient for them.\n\nAnnette Hamilton, a professor of anthropology at Macquarie University who carried out research in the Aboriginal community of Maningrida in Arnhem Land during the 1960s wrote that prior to that time part-European babies born to Aboriginal mothers had not been allowed to live, and that 'mixed-unions are frowned on by men and women alike as a matter of principle'.\n\nThere is no agreement about the actual estimates of the frequency of newborn female infanticide in the Inuit population. Carmel Schrire mentions diverse studies ranging from 15–50% to 80%.\n\nPolar Inuit (Inughuit) killed the child by throwing him or her into the sea. There is even a legend in Inuit mythology, \"The Unwanted Child\", where a mother throws her child into the fjord.\n\nThe Yukon and the Mahlemuit tribes of Alaska exposed the female newborns by first stuffing their mouths with grass before leaving them to die. In Arctic Canada the Inuit exposed their babies on the ice and left them to die.\n\nFemale Inuit infanticide disappeared in the 1930s and 1940s after contact with the Western cultures from the South.\n\nThe \"Handbook of North American Indians\" reports infanticide among the Dene Natives and those of the Mackenzie Mountains.\n\nIn the Eastern Shoshone there was a scarcity of Indian women as a result of female infanticide. For the Maidu Native Americans twins were so dangerous that they not only killed them, but the mother as well. In the region known today as southern Texas, the Mariame Indians practiced infanticide of females on a large scale. Wives had to be obtained from neighboring groups.\n\nBernal Díaz recounted that, after landing on the Veracruz coast, they came across a temple dedicated to Tezcatlipoca. \"That day they had sacrificed two boys, cutting open their chests and offering their blood and hearts to that accursed idol\". In \"The Conquest of New Spain\" Díaz describes more child sacrifices in the towns before the Spaniards reached the large Aztec city Tenochtitlan.\n\nAlthough academic data of infanticides among the indigenous people in South America is not as abundant as that of North America, the estimates seem to be similar.\n\nThe Tapirapé indigenous people of Brazil allowed no more than three children per woman, and no more than two of the same sex. If the rule was broken infanticide was practiced. The Bororo killed all the newborns that did not appear healthy enough. Infanticide is also documented in the case of the Korubo people in the Amazon.\n\nThe Yanomami men killed children while raiding enemy villages. Helena Valero, a Brazilian woman kidnapped by Yanomami warriors in the 1930s, witnessed a Karawetari raid on her tribe:\n\nWhile \"qhapaq hucha\" was practiced in the Peruvian large cities, child sacrifice in the pre-Columbian tribes of the region is less documented. However, even today studies on the Aymara Indians reveal high incidences of mortality among the newborn, especially female deaths, suggesting infanticide. The Abipones, a small tribe of Guaycuruan stock, of about 5,000 by the end of the 18th century in Paraguay, practiced systematic infanticide; with never more than two children being reared in one family. The Machigenga killed their disabled children. Infanticide among the Chaco in Paraguay was estimated as high as 50% of all newborns in that tribe, who were usually buried. The infanticidal custom had such roots among the Ayoreo in Bolivia and Paraguay that it persisted until the late 20th century.\n\nInfanticide has become less common in the Western world. The frequency has been estimated to be 1 in approximately 3000 to 5000 children of all ages and 2.1 per 100,000 newborns per year. It is thought that infanticide today continues at a much higher rate in areas of extremely high poverty and overpopulation, such as parts of China and India. Female infants, then and even now, are particularly vulnerable, a factor in sex-selective infanticide. Recent estimates suggest that over 100 million girls and women are 'missing' in Asia.\n\nIn spite of the fact that it is illegal, in Benin, West Africa, parents secretly continue with infanticidal customs.\n\nAccording to \"The Hidden Gulag\" published by the Committee for Human Rights in North Korea, the People's Republic of China returns all illegal immigrants from North Korea which usually imprisons them in a short term facility. Women who are suspected of being impregnated by Chinese fathers are subjected to forced abortions; babies born alive are killed, sometimes by exposure or being buried alive.\n\nThere have been some accusations that infanticide occurs in the People's Republic of China due to the one-child policy. In the 1990s, a certain stretch of the Yangtze River was known to be a common site of infanticide by drowning, until government projects made access to it more difficult. Recent studies suggest that over 40 million girls and women are 'missing' in China (Klasen and Wink 2003).\n\nThe practice has continued in some rural areas of India. Infanticide is illegal in India.\n\nAccording to a recent report by the United Nations Children's Fund (UNICEF) up to 50 million girls and women are missing in India's population as a result of systematic sex discrimination and sex selective abortions.\n\nKillings of newborn babies have been on the rise in Pakistan, corresponding to an increase in poverty across the country. More than 1,000 infants, mostly girls, were killed or abandoned to die in Pakistan in 2009 according to a Pakistani charity organization.\n\nThe Edhi Foundation found 1,210 dead babies in 2010. Many more are abandoned and left at the doorsteps of mosques. As a result, Edhi centers feature signs \"Do not murder, lay them here.\" Though female infanticide is punishable by life in prison, such crimes are rarely prosecuted.\n\nIn November 2008 it was reported that in Agibu and Amosa villages of Gimi region of Eastern Highlands province of Papua New Guinea where tribal fighting in the region of Gimi has been going on since 1986 (many of the clashes arising over claims of sorcery) women had agreed that if they stopped producing males, allowing only female babies to survive, their tribe's stock of boys would go down and there would be no men in the future to fight. They agreed to have all newborn male babies killed. It is not known how many male babies were killed by being smothered, but it had reportedly happened to all males over a 10-year period and probably was still happening.\n\nIn England and Wales there were typically 30 to 50 homicides per million children less than 1 year old between 1982 and 1996. The younger the infant, the higher the risk. The rate for children 1 to 5 years was around 10 per million children. The homicide rate of infants less than 1 year is significantly higher than for the general population. \n\nIn English law infanticide is established as a distinct offence by the Infanticide Acts. Defined as the killing of a child under 12 months of age by their mother, the effect of the Acts are to establish a partial defence to charges of murder.\n\nIn 1983, the United States ranked eleventh for infants under 1 year killed, and fourth for those killed from 1 through 14 years (the latter case not necessarily involving filicide). In the U.S. over six hundred children were killed by their parents in 1983.\n\nIn the United States the infanticide rate during the first hour of life outside the womb dropped from 1.41 per 100,000 during 1963 to 1972 to 0.44 per 100,000 for 1974 to 1983; the rates during the first month after birth also declined, whereas those for older infants rose during this time. The legalization of abortion, which was completed in 1973, was the most important factor in the decline in neonatal mortality during the period from 1964 to 1977, according to a study by economists associated with the National Bureau of Economic Research.\n\nIn Canada 114 cases of infanticide by a parent were reported during 1964–1968. There is ongoing debate in the Canadian legal and political fields about whether section 237 of the Criminal Code, which creates the specific offence and partial defence of infanticide in Canadian law, should be amended or abolished altogether.\n\nFrom 2013 to March 2018, 28 infanticides cases done by 22 mothers and three stepmothers were reported in Spain. The most famous case was the murder of Bernardo González Parra in 1910 perpetrated by Francisco Leona Romero, Julio Hernández Rodríguez, Francisco Ortega el Moruno and Agustina Rodríguez.\n\nIn a 2012 article in the \"Journal of Medical Ethics\", a philosopher and a bioethicist jointly proposed that infanticide be legalized, calling it \"after-birth abortion\", and claiming that both \"the fetus and the newborn are potential persons\". Many replies were published to this article.\n\nEuthanasia applied to children that are gravely ill or that suffer from significant birth defects is legal in the Netherlands under rigidly controlled conditions, but controversial. Some critics have compared child euthanasia to infanticide.\n\nThere are various reasons for infanticide. Neonaticide typically has different patterns and causes than for killing of older infants. Traditional neonaticide is often related to economic necessity - inability to provide for the infant.\n\nIn the United Kingdom and the United States, older infants are typically killed for reasons related to child abuse, domestic violence or mental illness. For infants older than one day, younger infants are more at risk, and boys are more at risk than girls. Risk factors for the parent include: Family history of violence, violence in current relationship, history of abuse or neglect of children, and personality disorder and/or depression.\n\nIn the late seventeenth and early eighteenth centuries, \"loopholes\" were invented by those who wanted to avoid the damnation that was promised by most Christian doctrine as a penalty of suicide. One famous example of someone who wished to end their life but avoid the eternity in hell was Christina Johansdotter (died 1740). She was a Swedish murderer who killed a child in Stockholm with the sole purpose of being executed. She is an example of those who seek suicide through execution by committing a murder. It was a common act, frequently targeting young children or infants as they were believed to be free from sin, thus going straight to heaven.\n\nIn 1888, Lieut. F. Elton reported that Ugi beach people in the Solomon Islands killed their infants at birth by burying them, and women were also said to practice abortion. They reported that it was too much trouble to raise a child, and instead preferred to buy one from the bush people.\n\nMany historians believe the reason to be primarily economic, with more children born than the family is prepared to support. In societies that are patrilineal and patrilocal, the family may choose to allow more sons to live and kill some daughters, as the former will support their birth family until they die, whereas the latter will leave economically and geographically to join their husband's family, possibly only after the payment of a burdensome dowry price. Thus the decision to bring up a boy is more economically rewarding to the parents. However, this does not explain why infanticide would occur equally among rich and poor, nor why it would be as frequent during decadent periods of the Roman Empire as during earlier, less affluent, periods.\n\nBefore the appearance of effective contraception, infanticide was a common occurrence in ancient brothels. Unlike usual infanticide - where historically girls have been more likely to be killed - prostitutes in certain areas preferred to kill their male offspring.\n\nInstances of infanticide in Britain in 18th and 19th centuries is often attributed to the economic position of the women, with juries committing “pious perjury” in many subsequent murder cases. The knowledge of the difficulties faced in the 18th century by those women who attempted to keep their children can be seen as reason for juries to show compassion. If the woman chose to keep the child, society was not set up to ease the pressure placed upon the woman, legally, socially or economically.\n\nIn mid-18th century Britain there was assistance available for women who were not able to raise their children. The Foundling Hospital opened in 1756 and was able to take in some of the illegitimate children. However, the conditions within the hospital caused Parliament to withdraw funding and the governors to live off of their own incomes. This resulted in a stringent entrance policy, with the committee requiring that the hospital:\n\nOnce a mother had admitted her child to the hospital, the hospital did all it could to ensure that the parent and child were not re-united.\n\nMacFarlane argues in \"Illegitimacy and Illegitimates in Britain\" (1980) that English society greatly concerned itself with the burden that a bastard child places upon its communities and had gone to some lengths to ensure that the father of the child is identified in order to maintain its well-being. Assistance could be gained through maintenance payments from the father, however, this was capped \"at a miserable 2 s and 6 d a week\". If the father fell behind with the payments he could only be asked \"to pay a maximum of 13 weeks arrears\".\n\nDespite the accusations of some that women were getting a free hand-out there is evidence that many women were far from receiving adequate assistance from their parish. \"Within Leeds in 1822 ... relief was limited to 1 s per week\". Sheffield required women to enter the workhouse, whereas Halifax gave no relief to the women who required it. The prospect of entering the workhouse was certainly something to be avoided. Lionel Rose quotes Dr Joseph Rogers in \"Massacre of the Innocents ...\" (1986). Rogers, who was employed by a London workhouse in 1856 stated that conditions in the nursery were ‘wretchedly damp and miserable ... [and] ... overcrowded with young mothers and their infants’.\n\nThe loss of social standing for a servant girl was a particular problem in respect of producing a bastard child as they relied upon a good character reference in order to maintain their job and more importantly, to get a new or better job. In a large number of trials for the crime of infanticide, it is the servant girl that stood accused. The disadvantage of being a servant girl is that they had to live to the social standards of their superiors or risk dismissal and no references. Whereas within other professions, such as in the factory, the relationship between employer and employee was much more anonymous and the mother would be better able to make other provisions, such as employing a minder. The result of the lack of basic social care in Britain in the 18th and 19th century is the numerous accounts in court records of women, particularly servant girls, standing trial for the murder of their child.\n\nThere may have been no specific offence of infanticide in England before about 1623 because infanticide was a matter for the by ecclesiastical courts, possibly because infant mortality from natural causes was high (about 15% or one in six).\n\nThereafter the accusation of the suppression of bastard children by lewd mothers was a crime incurring the presumption of guilt.\n\nThe Infanticide Acts are several laws. That of 1922 made the killing of an infant child by its mother during the early months of life as a lesser crime than murder. The acts of 1938 and 1939 abolished the earlier act, but introduced the idea that postpartum depression was legally to be regarded as a form of diminished responsibility.\n\nMarvin Harris estimated that among Paleolithic hunters 23–50% of newborn children were killed. He argued that the goal was to preserve the 0.001% population growth of that time. He also wrote that female infanticide may be a form of population control. Population control is achieved not only by limiting the number of potential mothers; increased fighting among men for access to relatively scarce wives would also lead to a decline in population. For example, on the Melanesian island of Tikopia infanticide was used to keep a stable population in line with its resource base. Research by Marvin Harris and William Divale supports this argument, it has been cited as an example of environmental determinism.\n\nEvolutionary psychology has proposed several theories for different forms of infanticide. Infanticide by stepfathers, as well as child abuse in general by stepfathers, has been explained by spending resources on not genetically related children reducing reproductive success (See the Cinderella effect and Infanticide (zoology)). Infanticide is one of the few forms of violence more often done by women than men. Cross-cultural research has found that this is more likely to occur when the child has deformities or illnesses as well as when there are lacking resources due to factors such as poverty, other children requiring resources, and no male support. Such a child may have a low chance of reproductive success in which case it would decrease the mother's inclusive fitness, in particular since women generally have a greater parental investment than men, to spend resources on the child.\n\nA minority of academics subscribe to an alternate school of thought, considering the practice as \"early infanticidal childrearing\". They attribute parental infanticidal wishes to massive projection or displacement of the parents' unconscious onto the child, because of intergenerational, ancestral abuse by their own parents. Clearly, an infanticidal parent may have multiple motivations, conflicts, emotions, and thoughts about their baby and their relationship with their baby, which are often colored both by their individual psychology, current relational context and attachment history, and, perhaps most saliently, their psychopathology (See also Psychiatric section below) Almeida, Merminod, and Schechter suggest that parents with fantasies, projections, and delusions involving infanticide need to be taken seriously and assessed carefully, whenever possible, by an interdisciplinary team that includes infant mental health specialists or mental health practitioners who have experience in working with parents, children, and families.\n\nIn addition to debates over the morality of infanticide itself, there is some debate over the effects of infanticide on surviving children, and the effects of childrearing in societies that also sanction infanticide. Some argue that the practice of infanticide in any widespread form causes enormous psychological damage in children. Conversely, studying societies that practice infanticide Géza Róheim reported that even infanticidal mothers in New Guinea, who ate a child, did not affect the personality development of the surviving children; that \"these are good mothers who eat their own children\". Harris and Divale's work on the relationship between female infanticide and warfare suggests that there are, however, extensive negative effects.\n\nPostpartum psychosis is also a causative factor of infanticide. Stuart S. Asch, MD, a Professor of Psychiatry at Cornell University established the connections between some cases of infanticide and post-partum depression. The books, \"From Cradle to Grave\", and \"The Death of Innocents\", describe selected cases of maternal infanticide and the investigative research of Professor Asch working in concert with the New York City Medical Examiner's Office.\nStanley Hopwood wrote that childbirth and lactation entail severe stress on the female sex, and that under certain circumstances attempts at infanticide and suicide are common. A study published in the \"American Journal of Psychiatry\" revealed that 44% of filicidal fathers had a diagnosis of psychosis. In addition to postpartum psychosis, dissociative psychopathology and sociopathy have also been found to be associated with neonaticide in some cases\n\nIn addition, severe postpartum depression can lead to infanticide.\n\nSex selection may be one of the contributing factors of infanticide. In the absence of sex-selective abortion, sex-selective infanticide can be deduced from very skewed birth statistics. The biologically normal sex ratio for humans at birth is approximately 105 males per 100 females; normal ratios hardly ranging beyond 102–108. When a society has an infant male to female ratio which is significantly higher or lower than the biological norm, and biased data can be ruled out, sex selection can usually be inferred.\n\nIn New South Wales, infanticide is defined in Section 22A(1) of the Crimes Act 1900 (NSW) as follows:\n\nBecause Infanticide is punishable as manslaughter, as per s24, the maximum penalty for this offence is therefore 25 years imprisonment.\n\nInfanticide is illegal in India, but rarely enforced in the rural parts of India. \n\nIn Canada, a mother commits infanticide, a lesser offence than homicide, if she killed her child while \"not fully recovered from the effects of giving birth to the child and by reason thereof or of the effect of lactation consequent on the birth of the child her mind is then disturbed\".\n\nIn England and Wales, the Infanticide Act 1938 describes the offence of infanticide as one which would otherwise amount to murder (by his/her mother) if the victim was older than 12 months and the mother was not suffering from an imbalance of mind due to the effects of childbirth or lactation. Where a mother who has killed such an infant has been charged with murder rather than infanticide s.1(3) of the Act confirms that a jury has the power to find alternative verdicts of Manslaughter in English law or guilty but insane.\n\nArticle 200 of the Penal Code of Romania stipulates that the killing of a newborn during the first 24 hours, by the mother who is in a state of mental distress, shall be punished with imprisonment of one to five years. The previous Romanian Penal Code also defined infanticide (\"pruncucidere\") as a distinct criminal offence, providing for a punishment of two to seven years imprisonment, recognizing the fact that a mother's judgment may be impaired immediately after birth, but did not define the term \"infant\", and this had led to debates regarding the precise moment when infanticide becomes homicide. This issue was resolved by the new Penal Code, which came into force in 2014.\n\nIn 2009, Texas state representative Jessica Farrar proposed legislation that would define infanticide as a distinct and lesser crime than homicide. Under the terms of the proposed legislation, if jurors concluded that a mother's \"judgment was impaired as a result of the effects of giving birth or the effects of lactation following the birth\", they would be allowed to convict her of the crime of infanticide, rather than murder. The maximum penalty for infanticide would be two years in prison. Farrar's introduction of this bill prompted liberal bioethics scholar Jacob M. Appel to call her \"the bravest politician in America\".\n\nSince infanticide, especially neonaticide, is often a response to an unwanted birth, preventing unwanted pregnancies through improved sex education and increased contraceptive access are advocated as ways of preventing infanticide. Increased use of contraceptives and access to safe legal abortions have greatly reduced neonaticide in many developed nations. Some say that where abortion is illegal, as in Pakistan, infanticide would decline if safer legal abortions were available.\n\nScreening for psychiatric disorders or risk factors, and providing treatment or assistance to those at risk may help prevent infanticide. However, in developed world significant proportions of neonaticides that are detected occur in young women who deny their pregnancy, and avoid outside contacts, so they may have limited contact with health care services.\n\nIn some areas baby hatches or \"safe surrender sites\", safe places for a mother to anonymously leave an infant, are offered, in part to reduce the rate of infanticide. In other places, like the United States, safe-haven laws allow mothers to anonymously give infants to designated officials; they are frequently located at hospitals and police and fire stations. Typically such babies are put up for adoption, or cared for in orphanages.\n\nGranting women employment raises their status and autonomy. Having a gainful employment can raise the perceived worth of females. This can lead to an increase in the number of women getting an education and a decrease in the number of female infanticide. As a result, the infant mortality rate will decrease and economic development will increase.\n\nAlthough human infanticide has been widely studied, the practice has been observed in many other species of the animal kingdom since it was first seriously studied by . These include from microscopic rotifers and insects, to fish, amphibians, birds and mammals, including primates such as chacma baboons. Infanticide can be practiced by both males and females.\n\nAccording to studies carried out by Kyoto University in non-human primates, including certain types of gorillas and chimpanzees, several conditions favor the tendency to infanticide in some species (to be performed only by males), among them are: Nocturnal live, the absence of nest construction, the marked sexual dimorphism in which the male is much larger than the female, the mating in a specific season and the high period of lactation without resumption of the estrus state in the female.\n\n"}
{"id": "10387244", "url": "https://en.wikipedia.org/wiki?curid=10387244", "title": "Isaac W. Sprague", "text": "Isaac W. Sprague\n\nIsaac W. Sprague (May 21, 1841 - January 5, 1887) was an entertainer and sideshow performer, billed as the living human skeleton.\n\nHe was born on May 21, 1841, in East Bridgewater, Massachusetts.\n\nAlthough normal for most of his childhood, Sprague began irreversibly losing weight at age 12 after feeling ill after swimming. The weight loss continued throughout his life despite having a healthy appetite. His condition has been described by historians as extreme progressive muscular atrophy. This ultimately led to his death.\n\nIsaac bounced around from job to job during early adulthood. He worked as both a cobbler for his father and a grocer. However, his illness kept him from continuing down either of those career paths. His parents died and Sprague could not work enough to support himself, so he was left unemployed. Until 1865, which is when he was offered a job at a circus sideshow, becoming \"the Living Skeleton\" or \"the Original Thin Man\".\n\nThe next year P. T. Barnum hired Sprague to work at his (newly reopened) American Museum. Barnum paid Sprague $80 a week for his services. Sprague remembered the moment Barnum offered him the job; Barnum said, \"Mr. Barnum stood very near me, and I overheard him say to his agent, 'Pretty lean man, where did you scare him up?'\" \n\nBarnum's Museum burned down in 1868 and Sprague managed to escape with his life. At this point, Sprague took time off to marry his wife, Tamar Moore. They had three sons who lived healthy, normal lives.\n\nSprague made attempts to stay away from the sideshow, but he could not escape financial distress. It is rumored that in addition to be financially responsible for his wife and their three sons, Sprague had a gambling problem. His condition also kept him from finding real work anywhere other than Barnum's. So he continued to tour off and on throughout the country.\n\nBy the age of 44, he was 5 feet and 6 inches tall with a weight of only 43 pounds. Sprague's condition required him to constantly be taking in nutrients. His health was in such a poor state that he often carried milk in a flask around his neck. He would sip this from time to time to keep himself up and conscious.\n\nHe died on January 5, 1887, in poverty, of asphyxia in Chicago, Illinois.\n\nSprague was the first of many more living Skeletons acts to come. In a result of forced promotion and work pressure, it was not uncommon for the Living Skeleton act to marry the Fat Lady act.\n\nHe married Miss Tamar Moore shortly after 1868 and the couple had three strong, healthy, robust sons. Sprague found happiness in his family. He described his new found joy, \"Life, that had at times seemed so little worth preserving, now seemed more precious.\" \n\n"}
{"id": "28867477", "url": "https://en.wikipedia.org/wiki?curid=28867477", "title": "James Baldwin-Webb", "text": "James Baldwin-Webb\n\nColonel James Baldwin-Webb TD (born 1894 – died 18 September 1940) was a British Army officer, businessman, and Conservative Party politician who served in the House of Commons as a Member of Parliament (MP) for The Wrekin from 1931 to his death in 1940.\n\nHe was the only son of James Bertram Webb and his wife Elizabeth Anne Webb (née Baldwin), of Wylde Green, Sutton Coldfield, Warwickshire. He was educated privately.\n\nAfter leaving school, Baldwin-Webb worked in his maternal grandmother's family firm of Messrs Baldwin's(Birmingham) Ltd, then a firm of hardware merchants. He then joined the local staff of Lloyds Bank in Birmingham, where he passed all major banking examinations, but left the company when he joined the army at the outbreak of World War I in August 1914.\n\nAfter the war, he returned to Baldwin's and worked as a representative, later becoming Managing Director. He was credited with guiding the firm in the 1920s to diversify into a major builders' merchants.\n\nHe later became a member of two City of London livery companies, the Worshipful Company of Coachmakers and Coach Harness Makers and of Pattenmakers.\n\nAt the outbreak of World War I, Baldwin-Webb enlisted in a Territorial Army (TA) unit, the 46th North Midland Divisional Train of the Royal Army Service Corps (RASC), becoming a commissioned officer in a few weeks.\n\nFrom 1915 he served on the Western Front, took part in the Battle of the Somme attached to an artillery trench mortar battery, and later served on the staff of the Third and Fourth Armies of the British Expeditionary Force. As a result of his service in France, he was created a Chevalier of the Ordre du Mérite Agricole by the French Government in 1919.\n\nAfter the war he continued to serve, part-time, with the Train and rose to lieutenant-colonel in its command, from 1925 to 1931. He was promoted full colonel in February 1932, and awarded the TD in 1934. In 1939 he was appointed Honorary Colonel of the 4th Anti-Aircraft Division R.A.S.C.\n\nBaldwin-Webb was elected a member of Birmingham City Council in 1925 and served until his death, at one point chairing its Highways Committee.\n\nHe was elected as MP for The Wrekin at the General Election of October 1931, taking it from a Labour Member, Edith Picton-Turbervill, and held it at the 1935 General Election.\n\nIt was a time of depression and at his maiden speech in the House of Commons, he moved a motion to urge the National Government of Ramsay MacDonald to help create employment by a progressive policy of carrying out public works where there was greatest need. He also gained concessions on unemployment insurance for workers in the sugar beet industry, one of the constituency's main seasonal employers. He was described by an unnamed source as \"the best commercial traveller the Wrekin division has ever had\" for his mainly successful efforts to gain orders for local industries.\n\nHe also became well known for organising what became known as the \"Baldwin-Webb trips\" to London and seaside towns for the pleasure of constituents and to advertise the Wrekin area's industries. They attracted between 5,000 and 7,000 day trippers a year.\n\nHe was also appointed as a Deputy Lieutenant of Staffordshire in 1932.\n\nAlthough Baldwin-Webb did not see active service after the outbreak of World War II, continuing to appear in Parliament, he later became honorary secretary of the British Volunteer Ambulance Corps (originally called the Anglo-French Ambulance Corps). It was on a voyage to Canada to fund-raise for the Corps that he lost his life, as he was drowned when the SS \"City of Benares\" was torpedoed and sunk in the North Atlantic by a German submarine. Witnesses recalled that Baldwin-Webb helped women passengers out of the ship onto lifeboats, and tried to persuade the wife of fellow passenger Rudolf Olden to leave but she preferred to stay with her invalid husband. (German Nazi propagandists later claimed that he and Olden were sailing on a British government mission to persuade the then-neutral United States to enter the war.) He was last seen alive \"standing by the Captain as the ship went down\". He was unmarried.\n\nHe is commemorated in the House of Commons chamber by a heraldic shield.\n\nA road, Baldwin-Webb Avenue, is named after him in the Donnington district of Telford in Shropshire.\n\n"}
{"id": "33881926", "url": "https://en.wikipedia.org/wiki?curid=33881926", "title": "Jar burial", "text": "Jar burial\n\nJar burials are human burials where the corpse is placed into a large earthenware and then is interred. Jar-burials are a repeated pattern at a site or within an archaeological culture. When an anomalous burial is found in which a corpse or cremated remains have been interred, it is not considered a \"jar burial\".\n\nJar burial can be traced to various regions across the globe. It is noted to have been practiced as early as BCE 900, and as recent as CE 15-17th centuries Particular areas of studies on jar burial excavations include India, Indonesia, Lebanon, Palestine,Taiwan, Japan, Cambodia, Iran, Syria, Sumatra, Egypt, Malaysia, the Philippines, Taiwan, Thailand, Vanuatu, and Vietnam. These differing locations call for different methods, accoutrements, and rationales behind the jar burial practices. Cultural practices ranged from primary versus secondary burial, burial offerings (bronze/iron tools, weapons and bronze/silver/gold ornaments, wood, stone, clay, glass, and paste) in/around burials, and hierarchical structures represented in the location/method of the placement of jars.\n\nAmong many cultures, a period of waiting occurs between the first burial and a second burial that often coincides with the duration of decomposition. The origin of this practice is considered to be the different concept of death held by these cultures. In such societies, death is held to involve a slow change, a passage from the visible society of the living to the invisible one of the dead. During the period of decomposition, the corpse is sometimes treated as if it were alive, provided with food and drink and surrounded by company. Some groups on the island of Borneo, for example, attach mystical importance to the disintegration of the body, sometimes collecting and carefully disposing of the liquids produced by decomposition.\n\nAs previously stated, jar burial culture was employed by peoples who chose this practice for primary or secondary burial. Primary burial refers to the acts performed on the body immediately after death. In some cases of Jar Burial, primary burial with this technique was a lot more difficult to carry out. In Cretan societies, the dead body would be bound tightly to fit into the desired jar. This was believed to be originally intended for infants and small children, but it evolved into larger categories of adults. Adults, however required much larger jars, deeper graves, and more man-power to In Egyptian societies, the body also could be sat upright, and then the jar would be forced on top of the body. Egyptians also would place the body into the jar themselves, rather than pushing the jar downwards, but this would create a need for a lid. Lids are not specific pieces of pottery, they have been found to be as simple as a rock or another jar. The preference of how it the body was placed did not have any certain significance.\n\nSecondary burials are different acts performed on body that has already been buried. The allotted time between primary and secondary burials varies between cultures, however an emphasis is placed on waiting until the body has decomposed, and whatever technique is carried out as \"secondary\", is dealing with only defleshed bones. With jar burials, the defleshed bones were cleaned and subsequently put in a jar.\n\nTypes of jars and additional components vary from location to culture. Different shapes of jars can indicate the prestige or societal level of the deceased, or it can be a commonplace jar. Funerary offerings are sometimes placed in or around the jars, thus revealing more information about the value different peoples have for certain items.\n\nPithoi were typical storage jars, and were commonly used for burials, and they employ vertical round to oval handles (29). Carvings on jars have also been found, sometimes depicting local divine beings of the time. This is thought to assist in the passing of that individual to a realm beyond life. The carvings on jars are not standardized, meaning there is no particular pattern of a certain carving on multiple jars, but most carvings have been observed in Egypt\n\nSome jars are specifically manufactured for jar burials, due to the varying size of bodies and grave sites available to different cultures.\n\nMany jar burial sites have also been accompanied by more than just the skeletons and jars. Beads, swords, mirrors, and other animal bones have been found in and around jars. In the Cardamom Mountains, a large amount of beads have been found in jars. These are most likely offerings to the deceased, in the same way that tombs have gifts in them. However the presence of these beads and other offerings give great insight into the lifestyle of the people. By studying the materials and methods the beads were made of, researchers have been able to link various cultures together based on their likely trade operations—the way they obtained exotically different beads than what was typical to their own culture.\n\n\n"}
{"id": "11801835", "url": "https://en.wikipedia.org/wiki?curid=11801835", "title": "Kin recognition", "text": "Kin recognition\n\nKin recognition, also called kin detection, is an organism's ability to distinguish between close genetic kin and non-kin. In evolutionary biology and psychology, such an ability is presumed to have evolved for inbreeding avoidance.\n\nAn additional adaptive function sometimes posited for kin recognition is a role in kin selection. There is debate over this, since in strict theoretical terms kin recognition is not necessary for kin selection or the cooperation associated with it. Rather, social behaviour can emerge by kin selection in the demographic conditions of 'viscous populations' with organisms interacting in their natal context, without active kin discrimination, since social participants by default typically share recent common origin. Since kin selection theory emerged, much research has been produced investigating the possible role of kin recognition mechanisms in mediating altruism. Taken as a whole, this research suggests that active powers of recognition play a negligible role in mediating social cooperation relative to less elaborate cue-based and context-based mechanisms, such as familiarity, imprinting and phenotype matching.\n\nBecause cue-based 'recognition' predominates in social mammals, outcomes are non-deterministic in relation to actual genetic kinship, instead outcomes simply reliably correlate with genetic kinship in an organism's typical conditions. A well-known human example of an inbreeding avoidance mechanism is the Westermarck effect, in which unrelated individuals who happen to spend their childhood in the same household find each other sexually unattractive. Similarly, due to the cue-based mechanisms that mediate social bonding and cooperation, unrelated individuals who grow up together in this way are also likely to demonstrate strong social and emotional ties, and enduring altruism.\n\nThe English evolutionary biologist W. D. Hamilton's theory of inclusive fitness, and the related theory of kin selection, were formalized in the 1960s and 1970s to explain the evolution of social behaviours. Hamilton's early papers, as well as giving a mathematical account of the selection pressure, discussed possible implications and behavioural manifestations. Hamilton considered potential roles of cue-based mechanisms mediating altruism versus 'positive powers' of kin discrimination:\n\nThese two possibilities, altruism mediated via 'passive situation' or via 'sophisticated discrimination', stimulated a generation of researchers to look for evidence of any 'sophisticated' kin discrimination. However, Hamilton later (1987) developed his thinking to consider that \"an innate kin recognition adaptation\" was unlikely to play a role in mediating altruistic behaviours:\n\nThe implication that the inclusive fitness criterion can be met by mediating mechanisms of cooperative behaviour that are context and location-based has been clarified by recent work by West \"et al.\":\n\nFor a recent review of the debates around kin recognition and their role in the wider debates about how to interpret inclusive fitness theory, including its compatibility with ethnographic data on human kinship, see Holland (2012).\n\nLeading inclusive fitness theorists such as Grafen have argued that the whole research program around kin recognition is somewhat misguided:\n\nOthers have cast similar doubts over the enterprise:\n\nKin recognition is a behavioral adaptation noted in many species but proximate level mechanisms are not well documented. Recent studies have shown that kin recognition can result from a multitude of sensory input. Jill Mateo notes that there are three components are prominent in kin recognition. First, \"production of unique phenotypic cues or labels\". Second, \"perception of these labels and the degree of correspondence of these labels with a 'recognition template'\", and finally the recognition of the phenotypes should lead to \"action taken by the animal as a function of the perceived similarity between its template and an encountered phenotype\".\n\nThe three components allow for several possible mechanisms of kin recognition. Sensory information gathered from visual, olfactory and auditory stimuli are the most prevalent. The belding ground squirrel kin produce similar odors in comparison to non-kin. Mateo notes that the squirrels spent longer investigating non-kin scents suggesting recognition of kin odor. It's also noted that belding's ground squirrels produce at least two scents arising from dorsal and oral secretions, giving two opportunities for kin recognition. Auditory distinctions have been noted among avian species. Long-tailed tits (\"Aegithalos caudatus\") are capable of discriminating kin and non-kin based on contact calls. Distinguishing calls are often learned from adults during the nestling period. Studies suggest that the bald-faced hornet, \"Dolichovespula maculata\", can recognize nest mates by their cuticular hydrocarbon profile, which produces a distinct smell.\n\nKin recognition in some species may also be mediated by immunogenetic similarity of the major histocompatibility complex (MHC). For a discussion of the interaction of these social and biological kin recognition factors see Lieberman, Tooby, and Cosmides (2007). Some have suggested that, as applied to humans, this nature-nurture interactionist perspective allows a synthesis between theories and evidence of social bonding and cooperation across the fields of evolutionary biology, psychology (attachment theory) and cultural anthropology (nurture kinship).\n\nKin recognition is an adaptive behavior observed in living beings to prevent inbreeding, and increase fitness of populations, individuals and genes. Kin recognition is the key to successful reciprocal altruism, a behavior that increases reproductive success of both organisms involved. Reciprocal altruism as a product of kin recognition has been observed and studied in many animals, and more recently, plants. Due to the nature of plant reproduction and growth, plants are more likely than animals to live in close proximity to family members, and therefore stand to gain more from the ability to differentiate kin from strangers.\n\nIn recent years, botanists have been conducting studies to determine which plant species can recognize kin, and discover the responses of plants to neighboring kin. Murphy and Dudley (2009) shows that \"Impatiens pallida\" has the ability to recognize individuals closely related to them and those not related to them. The physiological response to this recognition is increasingly interesting. \"I. pallida\" responds to kin by increasing branchiness and stem elongation, to prevent shading relatives, and responds to strangers by increasing leaf to root allocation, as a form of competition.\n\nSimilarly, Bhatt et al. (2010) show that \"Cakile edentula\", the American sea rocket, has the ability to allocate more energy to root growth, and competition, in response to growing next to a stranger, and allocates less energy to root growth when planted next to a sibling. This reduces competition between siblings and increases fitness of relatives growing next to each other, while still allowing competition between non-relative plants.\n\nLittle is known about the mechanisms involved in kin recognition. They most likely vary between species as well as within species. A study by Bierdrzycki et al. (2010) shows that root secretions are necessary for \"Arabidopsis thaliana\" to recognize kin vs. strangers, but not necessary to recognize self vs. non-self roots. This study was performed using secretion inhibitors, which disabled the mechanism responsible for kin recognition in this species, and showed similar growth patterns to Bhatt et al., (2010) and Murphy and Dudley (2009) in control groups. The most interesting result of this study was that inhibiting root secretions did not reduce the ability of \"Arabidopsis\" to recognize their own roots, which implicates a separate mechanism for self/non-self recognition than that for kin/stranger recognition.\n\nWhile this mechanism in the roots responds to exudates and involves competition over resources like nitrogen and phosphorus, another mechanism has been recently proposed, which involves competition over light, in which kin recognition takes place in leaves. In their 2014 study, Crepy and Casal conducted multiple experiments on different accessions of \"A. thaliana\". These experiments showed that \"Arabidopsis\" accessions have distinct R:FR and blue light signatures, and that these signatures can be detected by photoreceptors, which allows the plant to recognize its neighbor as a relative or non-relative. Not much is known about the pathway that \"Arabidopsis\" uses to associate these light patterns with kin, however, researchers ascertained that photoreceptors phyB, cry 1, cry 2, phot1, and phot2 are involved in the process by performing a series of experiments with knock-out mutants. Researchers also concluded that the auxin-synthesis gene TAA1 is involved in the process, downstream of the photoreceptors, by performing a similar experiments using Sav3 knock-out mutants. This mechanism leads to altered leaf direction to prevent shading of related neighbors and to reduce competition for sunlight.\n\nWhen mice inbreed with close relatives in their natural habitat, there is a significant detrimental effect on progeny survival. Since inbreeding is detrimental, it tends to be avoided. In the house mouse, the major urinary protein (MUP) gene cluster provides a highly polymorphic scent signal of genetic identity that appears to underlie kin recognition and inbreeding avoidance. Thus there are fewer matings between mice sharing MUP haplotypes than would be expected if there were random mating. Another mechanism for avoiding inbreeding is evident when a female house mouse mates with multiple males. In such a case, there appears to be egg-driven sperm selection against sperm from related males.\n\nIn toads, male advertisement vocalizations may serve as cues by which females recognize their kin and thus avoid inbreeding.\n\nIn dioecious plants, the stigma may receive pollen from several different potential donors. As multiple pollen tubes from the different donors grow through the stigma to reach the ovary, the receiving maternal plant may carry out pollen selection favoring pollen from less related donor plants. Thus, kin recognition at the level of the pollen tube apparently leads to post-pollination selection to avoid inbreeding depression. Also, seeds may be aborted selectively depending on donor–recipient relatedness.\n\n"}
{"id": "21451766", "url": "https://en.wikipedia.org/wiki?curid=21451766", "title": "Lipid bilayer mechanics", "text": "Lipid bilayer mechanics\n\nLipid bilayer mechanics is the study of the physical material properties of lipid bilayers, classifying bilayer behavior with stress and strain rather than biochemical interactions. Local point deformations such as membrane protein interactions are typically modelled with the complex theory of biological liquid crystals but the mechanical properties of a homogeneous bilayer are often characterized in terms of only three mechanical elastic moduli: the area expansion modulus K, a bending modulus K and an edge energy formula_1. For fluid bilayers the shear modulus is by definition zero, as the free rearrangement of molecules within plane means that the structure will not support shear stresses. These mechanical properties affect several membrane-mediated biological processes. In particular, the values of K and K affect the ability of proteins and small molecules to insert into the bilayer. Bilayer mechanical properties have also been shown to alter the function of mechanically activated ion channels.\n\nSince lipid bilayers are essentially a two dimensional structure, K is typically defined only within the plane. Intuitively, one might expect that this modulus would vary linearly with bilayer thickness as it would for a thin plate of isotropic material. In fact this is not the case and K is only weakly dependent on bilayer thickness. The reason for this is that the lipids in a fluid bilayer rearrange easily so, unlike a bulk material where the resistance to expansion comes from intermolecular bonds, the resistance to expansion in a bilayer is a result of the extra hydrophobic area exposed to water upon pulling the lipids apart. \nBased on this understanding, a good first approximation of K for a monolayer is 2γ, where gamma is the surface tension of the water-lipid interface. Typically gamma is in the range of 20-50mJ/m. To calculate K for a bilayer it is necessary to multiply the monolayer value by two, since a bilayer is composed of two monolayer leaflets. Based on this calculation, the estimate of K for a lipid bilayer should be 80-200 mN/m (note: N/m is equivalent to J/m). It is not surprising given this understanding of the forces involved that studies have shown that K varies strongly with solution conditions but only weakly with tail length and unsaturation.\n\nThe compression modulus is difficult to measure experimentally because of the thin, fragile nature of bilayers and the consequently low forces involved. One method utilized has been to study how vesicles swell in response to osmotic stress. This method is, however, indirect and measurements can be perturbed by polydispersity in vesicle size. A more direct method of measuring K is the pipette aspiration method, in which a single giant unilamellar vesicle (GUV) is held and stretched with a micropipette. More recently, atomic force microscopy (AFM) has been used to probe the mechanical properties of suspended bilayer membranes, but this method is still under development.\n\nOne concern with all of these methods is that, since the bilayer is such a flexible structure, there exist considerable thermal fluctuations in the membrane at many length scales down to sub-microscopic. Thus, forces initially applied to an unstressed membrane are not actually changing the lipid packing but are rather “smoothing out” these undulations, resulting in erroneous values for mechanical properties. This can be a significant source of error. Without the thermal correction typical values for Ka are 100-150 mN/m and with the thermal correction this would change to 220-270 mN/m.\n\nBending modulus is defined as the energy required to deform a membrane from its natural curvature to some other curvature. For an ideal bilayer the intrinsic curvature is zero, so this expression is somewhat simplified. The bending modulus, compression modulus and bilayer thickness are related by formula_2 such that if two of these parameters are known the other can be calculated. This relationship derives from the fact that to bend the inner face must be compressed and the outer face must be stretched. The thicker the membrane, the more each face must deform to accommodate a given curvature (see bending moment). Many of the values for K in literature have actually been calculated from experimentally measured values of K and t. This relation holds only for small deformations, but this is generally a good approximation as most lipid bilayers can support only a few percent strain before rupturing.\n\nOnly certain classes of lipids can form bilayers. Two factors primarily govern whether a lipid will form a bilayer or not: solubility and shape. For a self assembled structure such as a bilayer to form, the lipid should have a low solubility in water, which can also be described as a low critical micelle concentration (CMC). Above the CMC, molecules will aggregate and form larger structures such as bilayers, micelles or inverted micelles.\n\nThe primary factor governing which structure a given lipid forms is its shape (i.e.- its intrinsic curvature). Intrinsic curvature is defined by the ratio of the diameter of the head group to that of the tail group. For two-tailed PC lipids, this ratio is nearly one so the intrinsic curvature is nearly zero. Other headgroups such as PS and PE are smaller and the resulting diacyl (two-tailed) lipids thus have a negative intrinsic curvature. Lysolipids tend to have positive spontaneous curvature because they have one rather than two alkyl chains in the tail region. If a particular lipid has too large a deviation from zero intrinsic curvature it will not form a bilayer.\n\nEdge energy is the energy per unit length of a free edge contacting water. This can be thought of as the work needed to create a hole in the bilayer of unit length L. The origin of this energy is the fact that creating such an interface exposes some of the lipid tails to water, which is unfavorable. formula_1 is also an important parameter in biological phenomena as it regulates the self-healing properties of the bilayer following electroporation or mechanical perforation of the cell membrane. Unfortunately, this property is both difficult to measure experimentally and to calculate. One of the major difficulties in calculation is that the structural properties of this edge are not known. The simplest model would be no change in bilayer orientation, such that the full length of the tail is exposed. This is a high energy conformation and, to stabilize this edge, it is likely that some of the lipids rearrange their head groups to point out in a curved boundary. The extent to which this occurs is currently unknown and there is some evidence that both hydrophobic (tails straight) and hydrophilic (heads curved around) pores can coexist.\n"}
{"id": "35981509", "url": "https://en.wikipedia.org/wiki?curid=35981509", "title": "List of American police officers killed in the line of duty", "text": "List of American police officers killed in the line of duty\n\nThis is a list of American police officers killed in the line of duty. Summaries of the overall casualty figures, by year, are also provided.\n\nAccording to the FBI, which publishes the data in the Uniform Crime Reports, from 1980–2014, an average of 64 law enforcement officers were feloniously killed per year. Those killed in accidents in the line of duty are not included in that number.\n\n161 law enforcement officers were killed in 2010. The average from 1990-2010 was 164 per year.\n\nThe FBI reported that in 2011, \"69 law enforcement officers from around the nation were killed in the line of duty, while another 53 officers died in accidents while performing their duties.\" (released November 19, 2012) NBC News reported 165 dead.\n\nFor 2012, the FBI records 49 deaths in the line of duty. The FBI Fund counted 49 federal, state and local officers to have been killed in 2012.\n\nThe \"Officer Down Memorial Page\" reports 126 deaths in the line of duty. The National Law Enforcement Officers Memorial Fund counted 102 federal, state and local officers to have been killed in 2012. \nThe official count from the FBI is that 27 law enforcement officers were 'feloniously' killed in the line of duty in 2013 (the lowest in a 35-year period 1980-2014), and an additional 49 died in accidents (total: 76).\n\nThe \"Officer Down Memorial Page\" reports 155 deaths in the line of duty. The National Law Enforcement Officers Memorial Fund counted 126 federal, state, local, tribal and territorial officers killed. The preliminary count from the FBI is that 51 law enforcement officers were 'feloniously' killed in the line of duty in 2014, and an additional 44 died in accidents (total: 95).\n\nThe \"Officer Down Memorial Page\" reports 160 deaths in the line of duty. The National Law Enforcement Officers Memorial Fund counted 124 federal, state, local, tribal and territorial officers killed. 42 officers were shot and killed and 52 officers were killed in traffic-related incidents.\n\nThe \"Officer Down Memorial Page\" reports 159 deaths in the line of duty. The National Law Enforcement Officers Memorial Fund counted 135 federal, state, local, tribal and territorial officers killed. 64 officers were shot and killed and 21 were ambushed.\n\nThe \"Officer Down Memorial Page\" reports 133 deaths in the line of duty. The National Law Enforcement Officers Memorial Fund counted 128 federal, state, local, tribal and territorial officers killed. Fatalities decreased more than 10 percent with traffic-related fatalities the leading cause this year. Firearms-related fatalities were the second-leading cause of officer deaths, with 44 officers shot and killed in 2017. This represents a 33 percent decrease from the 66 officers killed in firearm-related incidents during 2016.\n\nThe \"Officer Down Memorial Page\" reports 108 deaths in the line of duty as of September 2018. The National Law Enforcement Officers Memorial Fund count for federal, state, local, tribal and territorial officers killed has not yet been released.\n\n\n Officer Paul Scuillo || Pittsburgh Police Department (Pittsburgh, Pennsylvania) || April 9, 2009 || Gunfire\n\n\n\n\n\n\n"}
{"id": "37932460", "url": "https://en.wikipedia.org/wiki?curid=37932460", "title": "List of countries by guns and homicide", "text": "List of countries by guns and homicide\n\nCreated by combining: Number of guns per capita by country and List of countries by intentional homicide rate.\n"}
{"id": "14480409", "url": "https://en.wikipedia.org/wiki?curid=14480409", "title": "List of fictional cyborgs", "text": "List of fictional cyborgs\n\nThis list is for fictional cyborgs.\n\n\n\nCybermen Doctor Who The Tenth Planet episode October 291966\n\n\n\n\n\n\n(1958)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "9015068", "url": "https://en.wikipedia.org/wiki?curid=9015068", "title": "Lupus of Friuli", "text": "Lupus of Friuli\n\nLupus was the Duke of Friuli from between 660 and 663 to his death around 666.\n\nImmediately after he succeeded to Friuli, Lupus invaded Grado with a body of cavalry and plundered the city, then proceeding to Aquileia, where he stole the treasures of the Patriarchate.\n\nWhen King Grimoald went south to rescue his son Romuald and the Duchy of Benevento from the invasion of the Byzantine Emperor Constans II, he put Lupus in charge of Pavia. Lupus played the tyrant during Grimoald's absence, believing that the king would not return, thus was forced to flee to Cividale, seat of Friuli, and enter into rebellion when the king did come north again. Grimoald promptly asked the Khagan of the Avars to attack Friuli in order to prevent a civil war in Italy. Fighting lasted for four days at Flovius, during which Lupus held his own for three, taking much booty and slaughtering many men, before his own losses and the arrival of Avar reinforcements forced his army to retreat. He himself was killed in battle.\n\nLupus' son Arnefrit claimed Friuli on his father's death, but was unseated by Grimoald. Lupus' daughter Theuderada (or Theodorada) married the aforementioned Romuald. She acted as regent of Benevento for their son Gisulf.\n\n"}
{"id": "19312", "url": "https://en.wikipedia.org/wiki?curid=19312", "title": "Meme", "text": "Meme\n\nA meme ( ) is an idea, behavior, or style that spreads from person to person within a culture—often with the aim of conveying a particular phenomenon, theme, or meaning represented by the meme. A meme acts as a unit for carrying cultural ideas, symbols, or practices, that can be transmitted from one mind to another through writing, speech, gestures, rituals, or other imitable phenomena with a mimicked theme. Supporters of the concept regard memes as cultural analogues to genes in that they self-replicate, mutate, and respond to selective pressures.\n\nProponents theorize that memes are a viral phenomenon that may evolve by natural selection in a manner analogous to that of biological evolution. Memes do this through the processes of variation, mutation, competition, and inheritance, each of which influences a meme's reproductive success. Memes spread through the behavior that they generate in their hosts. Memes that propagate less prolifically may become extinct, while others may survive, spread, and (for better or for worse) mutate. Memes that replicate most effectively enjoy more success, and some may replicate effectively even when they prove to be detrimental to the welfare of their hosts.\n\nA field of study called memetics arose in the 1990s to explore the concepts and transmission of memes in terms of an evolutionary model. Criticism from a variety of fronts has challenged the notion that academic study can examine memes empirically. However, developments in neuroimaging may make empirical study possible. Some commentators in the social sciences question the idea that one can meaningfully categorize culture in terms of discrete units, and are especially critical of the biological nature of the theory's underpinnings. Others have argued that this use of the term is the result of a misunderstanding of the original proposal.\n\nThe word \"meme\" is a neologism coined by Richard Dawkins. It originated from Dawkins' 1976 book \"The Selfish Gene\". Dawkins's own position is somewhat ambiguous: he welcomed N. K. Humphrey's suggestion that \"memes should be considered as living structures, not just metaphorically\" and proposed to regard memes as \"physically residing in the brain\". Later, he argued that his original intentions, presumably before his approval of Humphrey's opinion, had been simpler.\n\nThe word \"meme\" is a shortening (modeled on \"gene\") of \"mimeme\" (from Ancient Greek \"mīmēma\", \"imitated thing\", from \"mimeisthai\", \"to imitate\", from \"mimos\", \"mime\") coined by British evolutionary biologist Richard Dawkins in \"The Selfish Gene\" (1976) as a concept for discussion of evolutionary principles in explaining the spread of ideas and cultural phenomena. Examples of memes given in the book included melodies, catchphrases, fashion, and the technology of building arches. Kenneth Pike coined the related terms emic and etic, generalizing the linguistic idea of phoneme, morpheme, grapheme, lexeme, and tagmeme (as set out by Leonard Bloomfield), characterizing them as insider view and outside view of behaviour and extending the concept into a tagmemic theory of human behaviour (culminating in \"Language in Relation to a Unified Theory of the Structure of Human Behaviour\", 1954).\n\nThe word \"meme\" originated with Richard Dawkins' 1976 book \"The Selfish Gene\". Dawkins cites as inspiration the work of geneticist L. L. Cavalli-Sforza, anthropologist F. T. Cloak and ethologist J. M. Cullen. Dawkins wrote that evolution depended not on the particular chemical basis of genetics, but only on the existence of a self-replicating unit of transmission—in the case of biological evolution, the gene. For Dawkins, the meme exemplified another self-replicating unit with potential significance in explaining human behavior and cultural evolution. Although Dawkins invented the term 'meme' and developed meme theory, the possibility that ideas were subject to the same pressures of evolution as were biological attributes was discussed in Darwin's time. T. H. Huxley claimed that 'The struggle for existence holds as much in the intellectual as in the physical world. A theory is a species of thinking, and its right to exist is coextensive with its power of resisting extinction by its rivals.'\nDawkins used the term to refer to any cultural entity that an observer might consider a replicator. He hypothesized that one could view many cultural entities as replicators, and pointed to melodies, fashions and learned skills as examples. Memes generally replicate through exposure to humans, who have evolved as efficient copiers of information and behavior. Because humans do not always copy memes perfectly, and because they may refine, combine or otherwise modify them with other memes to create new memes, they can change over time. Dawkins likened the process by which memes survive and change through the evolution of culture to the natural selection of genes in biological evolution.\n\nDawkins defined the \"meme\" as a unit of cultural transmission, or a unit of imitation and replication, but later definitions would vary. The lack of a consistent, rigorous, and precise understanding of what typically makes up one unit of cultural transmission remains a problem in debates about memetics. In contrast, the concept of genetics gained concrete evidence with the discovery of the biological functions of DNA. Meme transmission requires a physical medium, such as photons, sound waves, touch, taste, or smell because memes can be transmitted only through the senses.\n\nDawkins noted that in a society with culture a person need not have descendants to remain influential in the actions of individuals thousands of years after their death:\n\nBut if you contribute to the world's culture, if you have a good idea...it may live on, intact, long after your genes have dissolved in the common pool. Socrates may or may not have a gene or two alive in the world today, as G.C. Williams has remarked, but who cares? The meme-complexes of Socrates, Leonardo, Copernicus and Marconi are still going strong.\n\nAlthough Dawkins invented the term \"meme\", he has not claimed that the idea was entirely novel, and there have been other expressions for similar ideas in the past. In 1904, Richard Semon published \"Die Mneme\" (which appeared in English in 1924 as \"The Mneme\"). The term \"mneme\" was also used in Maurice Maeterlinck's \"The Life of the White Ant\" (1926), with some parallels to Dawkins's concept.\n\nMemes, analogously to genes, vary in their aptitude to replicate; successful memes remain and spread, whereas unfit ones stall and are forgotten. Thus memes that prove more effective at replicating and surviving are selected in the meme pool.\n\nMemes first need retention. The longer a meme stays in its hosts, the higher its chances of propagation are. When a host uses a meme, the meme's life is extended. The reuse of the neural space hosting a certain meme's copy to host different memes is the greatest threat to that meme's copy.\n\nA meme which increases the longevity of its hosts will generally survive longer. On the contrary, a meme which shortens the longevity of its hosts will tend to disappear faster. However, as hosts are mortal, retention is not sufficient to perpetuate a meme in the long term; memes also need transmission.\n\nLife-forms can transmit information both vertically (from parent to child, via replication of genes) and horizontally (through viruses and other means).\nMemes can replicate vertically or horizontally within a single biological generation. They may also lie dormant for long periods of time.\n\nMemes reproduce by copying from a nervous system to another one, either by communication or imitation. Imitation often involves the copying of an observed behavior of another individual. Communication may be direct or indirect, where memes transmit from one individual to another through a copy recorded in an inanimate source, such as a book or a musical score. Adam McNamara has suggested that memes can be thereby classified as either internal or external memes (i-memes or e-memes).\n\nSome commentators have likened the transmission of memes to the spread of contagions. Social contagions such as fads, hysteria, copycat crime, and copycat suicide exemplify memes seen as the contagious imitation of ideas. Observers distinguish the contagious imitation of memes from instinctively contagious phenomena such as yawning and laughing, which they consider innate (rather than socially learned) behaviors.\n\nAaron Lynch described seven general patterns of meme transmission, or \"thought contagion\":\n\n\nDawkins initially defined \"meme\" as a noun that \"conveys the idea of a unit of cultural transmission, or a unit of \"imitation\"\". John S. Wilkins retained the notion of meme as a kernel of cultural imitation while emphasizing the meme's evolutionary aspect, defining the meme as \"the least unit of sociocultural information relative to a selection process that has favorable or unfavorable selection bias that exceeds its endogenous tendency to change\". The meme as a unit provides a convenient means of discussing \"a piece of thought copied from person to person\", regardless of whether that thought contains others inside it, or forms part of a larger meme. A meme could consist of a single word, or a meme could consist of the entire speech in which that word first occurred. This forms an analogy to the idea of a gene as a single unit of self-replicating information found on the self-replicating chromosome.\n\nWhile the identification of memes as \"units\" conveys their nature to replicate as discrete, indivisible entities, it does not imply that thoughts somehow become quantized or that \"atomic\" ideas exist that cannot be dissected into smaller pieces. A meme has no given size. Susan Blackmore writes that melodies from Beethoven's symphonies are commonly used to illustrate the difficulty involved in delimiting memes as discrete units. She notes that while the first four notes of Beethoven's Fifth Symphony () form a meme widely replicated as an independent unit, one can regard the entire symphony as a single meme as well.\n\nThe inability to pin an idea or cultural feature to quantifiable key units is widely acknowledged as a problem for memetics. It has been argued however that the traces of memetic processing can be quantified utilizing neuroimaging techniques which measure changes in the connectivity profiles between brain regions.\" Blackmore meets such criticism by stating that memes compare with genes in this respect: that while a gene has no particular size, nor can we ascribe every phenotypic feature directly to a particular gene, it has value because it encapsulates that key unit of inherited expression subject to evolutionary pressures. To illustrate, she notes evolution selects for the gene for features such as eye color; it does not select for the individual nucleotide in a strand of DNA. Memes play a comparable role in understanding the evolution of imitated behaviors.\n\nThe 1981 book \"Genes, Mind, and Culture: The Coevolutionary Process\" by Charles J. Lumsden and E. O. Wilson proposed the theory that genes and culture co-evolve, and that the fundamental biological units of culture must correspond to neuronal networks that function as nodes of semantic memory. They coined their own word, \"culturgen\", which did not catch on. Coauthor Wilson later acknowledged the term \"meme\" as the best label for the fundamental unit of cultural inheritance in his 1998 book \"\", which elaborates upon the fundamental role of memes in unifying the natural and social sciences.\n\nDawkins noted the three conditions that must exist for evolution to occur:\nDawkins emphasizes that the process of evolution naturally occurs whenever these conditions co-exist, and that evolution does not apply only to organic elements such as genes. He regards memes as also having the properties necessary for evolution, and thus sees meme evolution as not simply analogous to genetic evolution, but as a real phenomenon subject to the laws of natural selection. Dawkins noted that as various ideas pass from one generation to the next, they may either enhance or detract from the survival of the people who obtain those ideas, or influence the survival of the ideas themselves. For example, a certain culture may develop unique designs and methods of tool-making that give it a competitive advantage over another culture. Each tool-design thus acts somewhat similarly to a biological gene in that some populations have it and others do not, and the meme's function directly affects the presence of the design in future generations. In keeping with the thesis that in evolution one can regard organisms simply as suitable \"hosts\" for reproducing genes, Dawkins argues that one can view people as \"hosts\" for replicating memes. Consequently, a successful meme may or may not need to provide any benefit to its host.\n\nUnlike genetic evolution, memetic evolution can show both Darwinian and Lamarckian traits. Cultural memes will have the characteristic of Lamarckian inheritance when a host aspires to replicate the given meme through inference rather than by exactly copying it. Take for example the case of the transmission of a simple skill such as hammering a nail, a skill that a learner imitates from watching a demonstration without necessarily imitating every discrete movement modeled by the teacher in the demonstration, stroke for stroke. Susan Blackmore distinguishes the difference between the two modes of inheritance in the evolution of memes, characterizing the Darwinian mode as \"copying the instructions\" and the Lamarckian as \"copying the product.\"\n\nClusters of memes, or \"memeplexes\" (also known as \"meme complexes\" or as \"memecomplexes\"), such as cultural or political doctrines and systems, may also play a part in the acceptance of new memes. Memeplexes comprise groups of memes that replicate together and coadapt. Memes that fit within a successful memeplex may gain acceptance by \"piggybacking\" on the success of the memeplex.\nAs an example, John D. Gottsch discusses the transmission, mutation and selection of religious memeplexes and the theistic memes contained. Theistic memes discussed include the \"prohibition of aberrant sexual practices such as incest, adultery, homosexuality, bestiality, castration, and religious prostitution\", which may have increased vertical transmission of the parent religious memeplex. Similar memes are thereby included in the majority of religious memeplexes, and harden over time; they become an \"inviolable canon\" or set of dogmas, eventually finding their way into secular law. This could also be referred to as the propagation of a taboo.\n\nThe discipline of memetics, which dates from the mid-1980s, provides an approach to evolutionary models of cultural information transfer based on the concept of the meme. Memeticists have proposed that just as memes function analogously to genes, memetics functions analogously to genetics. Memetics attempts to apply conventional scientific methods (such as those used in population genetics and epidemiology) to explain existing patterns and transmission of cultural ideas.\n\nPrincipal criticisms of memetics include the claim that memetics ignores established advances in other fields of cultural study, such as sociology, cultural anthropology, cognitive psychology, and social psychology. Questions remain whether or not the meme concept counts as a validly disprovable scientific theory. This view regards memetics as a theory in its infancy: a protoscience to proponents, or a pseudoscience to some detractors.\n\nAn objection to the study of the evolution of memes in genetic terms (although not to the existence of memes) involves a perceived gap in the gene/meme analogy: the cumulative evolution of genes depends on biological selection-pressures neither too great nor too small in relation to mutation-rates. There seems no reason to think that the same balance will exist in the selection pressures on memes.\n\nLuis Benitez-Bribiesca M.D., a critic of memetics, calls the theory a \"pseudoscientific dogma\" and \"a dangerous idea that poses a threat to the serious study of consciousness and cultural evolution\". As a factual criticism, Benitez-Bribiesca points to the lack of a \"code script\" for memes (analogous to the DNA of genes), and to the excessive instability of the meme mutation mechanism (that of an idea going from one brain to another), which would lead to a low replication accuracy and a high mutation rate, rendering the evolutionary process chaotic.\n\nBritish political philosopher John Gray has characterized Dawkins' memetic theory of religion as \"nonsense\" and \"not even a theory... the latest in a succession of ill-judged Darwinian metaphors\", comparable to Intelligent Design in its value as a science.\n\nAnother critique comes from semiotic theorists such as Deacon and Kull. This view regards the concept of \"meme\" as a primitivized concept of \"sign\". The meme is thus described in memetics as a sign lacking a triadic nature. Semioticians can regard a meme as a \"degenerate\" sign, which includes only its ability of being copied. Accordingly, in the broadest sense, the objects of copying are memes, whereas the objects of translation and interpretation are signs.\n\nFracchia and Lewontin regard memetics as reductionist and inadequate. Evolutionary biologist Ernst Mayr disapproved of Dawkins' gene-based view and usage of the term \"meme\", asserting it to be an \"unnecessary synonym\" for \"concept\", reasoning that concepts are not restricted to an individual or a generation, may persist for long periods of time, and may evolve.\n\nOpinions differ as to how best to apply the concept of memes within a \"proper\" disciplinary framework. One view sees memes as providing a useful philosophical perspective with which to examine cultural evolution. Proponents of this view (such as Susan Blackmore and Daniel Dennett) argue that considering cultural developments from a meme's-eye view—\"as if\" memes themselves respond to pressure to maximise their own replication and survival—can lead to useful insights and yield valuable predictions into how culture develops over time. Others such as Bruce Edmonds and Robert Aunger have focused on the need to provide an empirical grounding for memetics to become a useful and respected scientific discipline.\n\nA third approach, described by Joseph Poulshock, as \"radical memetics\" seeks to place memes at the centre of a materialistic theory of mind and of personal identity.\n\nProminent researchers in evolutionary psychology and anthropology, including Scott Atran, Dan Sperber, Pascal Boyer, John Tooby and others, argue the possibility of incompatibility between modularity of mind and memetics. In their view, minds structure certain communicable aspects of the ideas produced, and these communicable aspects generally trigger or elicit ideas in other minds through inference (to relatively rich structures generated from often low-fidelity input) and not high-fidelity replication or imitation. Atran discusses communication involving religious beliefs as a case in point. In one set of experiments he asked religious people to write down on a piece of paper the meanings of the Ten Commandments. Despite the subjects' own expectations of consensus, interpretations of the commandments showed wide ranges of variation, with little evidence of consensus. In another experiment, subjects with autism and subjects without autism interpreted ideological and religious sayings (for example, \"Let a thousand flowers bloom\" or \"To everything there is a season\"). People with autism showed a significant tendency to closely paraphrase and repeat content from the original statement (for example: \"Don't cut flowers before they bloom\"). Controls tended to infer a wider range of cultural meanings with little replicated content (for example: \"Go with the flow\" or \"Everyone should have equal opportunity\"). Only the subjects with autism—who lack the degree of inferential capacity normally associated with aspects of theory of mind—came close to functioning as \"meme machines\".\n\nIn his book \"The Robot's Rebellion\", Stanovich uses the memes and memeplex concepts to describe a program of cognitive reform that he refers to as a \"rebellion\". Specifically, Stanovich argues that the use of memes as a descriptor for cultural units is beneficial because it serves to emphasize transmission and acquisition properties that parallel the study of epidemiology. These properties make salient the sometimes parasitic nature of acquired memes, and as a result individuals should be motivated to reflectively acquire memes using what he calls a \"Neurathian bootstrap\" process.\n\nAlthough social scientists such as Max Weber sought to understand and explain religion in terms of a cultural attribute, Richard Dawkins called for a re-analysis of religion in terms of the evolution of self-replicating ideas \"apart from\" any resulting biological advantages they might bestow.\nHe argued that the role of key replicator in cultural evolution belongs not to genes, but to memes replicating thought from person to person by means of imitation. These replicators respond to selective pressures that may or may not affect biological reproduction or survival.\n\nIn her book \"The Meme Machine\", Susan Blackmore regards religions as particularly tenacious memes. Many of the features common to the most widely practiced religions provide built-in advantages in an evolutionary context, she writes. For example, religions that preach of the value of faith over evidence from everyday experience or reason inoculate societies against many of the most basic tools people commonly use to evaluate their ideas. By linking altruism with religious affiliation, religious memes can proliferate more quickly because people perceive that they can reap societal as well as personal rewards. The longevity of religious memes improves with their documentation in revered religious texts.\n\nAaron Lynch attributed the robustness of religious memes in human culture to the fact that such memes incorporate multiple modes of meme transmission. Religious memes pass down the generations from parent to child and across a single generation through the meme-exchange of proselytism. Most people will hold the religion taught them by their parents throughout their life. Many religions feature adversarial elements, punishing apostasy, for instance, or demonizing infidels. In \"Thought Contagion\" Lynch identifies the memes of transmission in Christianity as especially powerful in scope. Believers view the conversion of non-believers both as a religious duty and as an act of altruism. The promise of heaven to believers and threat of hell to non-believers provide a strong incentive for members to retain their belief. Lynch asserts that belief in the Crucifixion of Jesus in Christianity amplifies each of its other replication advantages through the indebtedness believers have to their Savior for sacrifice on the cross. The image of the crucifixion recurs in religious sacraments, and the proliferation of symbols of the cross in homes and churches potently reinforces the wide array of Christian memes.\n\nAlthough religious memes have proliferated in human cultures, the modern scientific community has been relatively resistant to religious belief. Robertson (2007) reasoned that if evolution is accelerated in conditions of propagative difficulty, then we would expect to encounter variations of religious memes, established in general populations, addressed to scientific communities. Using a memetic approach, Robertson deconstructed two attempts to privilege religiously held spirituality in scientific discourse. Advantages of a memetic approach as compared to more traditional \"modernization\" and \"supply side\" theses in understanding the evolution and propagation of religion were explored.\n\nIn \"Cultural Software: A Theory of Ideology\", Jack Balkin argued that memetic processes can explain many of the most familiar features of ideological thought. His theory of \"cultural software\" maintained that memes form narratives, social networks, metaphoric and metonymic models, and a variety of different mental structures. Balkin maintains that the same structures used to generate ideas about free speech or free markets also serve to generate racistic beliefs. To Balkin, whether memes become harmful or maladaptive depends on the environmental context in which they exist rather than in any special source or manner to their origination. Balkin describes racist beliefs as \"fantasy\" memes that become harmful or unjust \"ideologies\" when diverse peoples come together, as through trade or competition.\n\nIn \"A Theory of Architecture\", Nikos Salingaros speaks of memes as \"freely propagating clusters of information\" which can be beneficial or harmful. He contrasts memes to patterns and true knowledge, characterizing memes as \"greatly simplified versions of patterns\" and as \"unreasoned matching to some visual or mnemonic prototype\". Taking reference to Dawkins, Salingaros emphasizes that they can be transmitted due to their own communicative properties, that \"the simpler they are, the faster they can proliferate\", and that the most successful memes \"come with a great psychological appeal\".\n\nArchitectural memes, according to Salingaros, can have destructive power. \"Images portrayed in architectural magazines representing buildings that could not possibly accommodate everyday uses become fixed in our memory, so we reproduce them unconsciously.\" He lists various architectural memes that circulated since the 1920s and which, in his view, have led to contemporary architecture becoming quite decoupled from human needs. They lack connection and meaning, thereby preventing \"the creation of true connections necessary to our understanding of the world\". He sees them as no different from antipatterns in software design—as solutions that are false but are re-utilized nonetheless.\n\nAn \"Internet meme\" is a concept that spreads rapidly from person to person via the Internet, largely through Internet-based E-mailing, blogs, forums, imageboards like 4chan, social networking sites like Facebook, Instagram, or Twitter, instant messaging, social news sites or thread sites like Reddit, and video hosting services like YouTube and Twitch.\n\nIn 2013, Richard Dawkins characterized an Internet meme as one deliberately altered by human creativity, distinguished from Dawkins's original idea involving mutation by random change and a form of Darwinian selection.\n\nOne technique of meme mapping represents the evolution and transmission of a meme across time and space. Such a meme map uses a figure-8 diagram (an analemma) to map the gestation (in the lower loop), birth (at the choke point), and development (in the upper loop) of the selected meme. Such meme maps are nonscalar, with time mapped onto the y-axis and space onto the x-axis transect. One can read the temporal progression of the mapped meme from south to north on such a meme map. Paull has published a worked example using the \"organics meme\" (as in organic agriculture).\n\n\n"}
{"id": "5287537", "url": "https://en.wikipedia.org/wiki?curid=5287537", "title": "Micajah Autry", "text": "Micajah Autry\n\nMicajah Autry (1793March 6, 1836) was an American merchant, poet and lawyer who died in the Texas Revolution at the Battle of the Alamo.\n\nAutry was born, 1793 of a Quaker family, in Sampson County, North Carolina, to Theophilus and Elizabeth (Crumpler) Autry. Between the ages of 17 and 18, he volunteered for military service against the British in the War of 1812. He marched to Wilmington, North Carolina, as a member of a volunteer militia company and later joined the United States Army at Charleston, South Carolina. He remained in Charleston in the company of Captain Long until the Treaty of Ghent was signed in 1815.\nAfter the war, bad health forced Autry to quit farming and become a teacher. Then in 1823, he moved to Haysboro in Davidson County, Tennessee, and studied law. At the end of that year, he married a widow, Martha Wyche Putney Wilkinson. They had two children of their own who survived to adulthood; and they raised Martha's daughter from her first marriage. In 1828, Autry was admitted to the bar in Nashville. He practiced law in Jackson, Tennessee, between 1831 and 1835, in a partnership with Andrew L. Martin. Autry and Martin later started an unsuccessful mercantile business in Nashville.\n\nDuring a subsequent business trip to New York City and Philadelphia, he heard of the opportunities in Texas. In 1835 he left his family and slaves in the care of Samuel Smith, his stepdaughter's husband, and set out for Texas by steamboat from Nashville.\n\nFrom Natchitoches, Louisiana, on December 13 he wrote: \"About 20 men from Tennessee formed our squad... [T]he war [in Texas] is still going on favorably to the Texans, but it is thought that Santa Anna will make a descent with his whole force in the Spring, but there will be soldiers enough of the real grit in Texas by that time to overrun all of Mexico... We have between 400 and 500 miles to foot it to the seat of government, for we cannot get horses, but we have sworn allegiance to each other and will get along somehow.\"\n\nHe was in Nacogdoches, Texas, on January 13, 1836, where he enlisted in the Volunteer Auxiliary Corps of Texas. His letter to his wife written on that date indicated that he had set out for Washington-on-the-Brazos with David Crockett and others under the command of Capt. William B. Harrison. He arrived in San Antonio de Bexar with this company on February 9 and joined the Alamo garrison under the command of Lt. Col. William Barrett Travis.\n\nAfter a siege lasting 13 days, Autry was killed with the rest of the Alamo garrison after the Mexican army stormed it on March 6, 1836. Among some of his possessions now housed at the Alamo in San Antonio, Texas, is an eagle approximately 3 feet high which he carved. They also have a collection of his letters and poetry written to his beloved wife.\n\n\n\n"}
{"id": "50889806", "url": "https://en.wikipedia.org/wiki?curid=50889806", "title": "Murder of Ellie Butler", "text": "Murder of Ellie Butler\n\nEllie Butler (30 December 2006 – 28 October 2013) was a British girl who was murdered by her father, Ben Butler, on 28 October 2013, at his home in Sutton, London. In February 2007, he was arrested after Ellie Butler was taken to a hospital with head and retinal injuries. Ellie then lived with her maternal grandparents until late 2012, when a judge, Justice Mary Hogg, ordered she be returned to her parents.\n\nOn 21 June 2016, Ben Butler was found guilty of murder at the Old Bailey in London, and sentenced to a minimum of 23 years in prison. His partner and Ellie's mother, Jennie Gray, was jailed for 42 months in connection with the case, after admitting perverting the course of justice, and both were found guilty of child cruelty.\n\nIn the wake of Ellie's death and before the trial of Ben Butler and Jennie Gray, Sutton Safeguarding Children Board (SCCB) conducted a Serious Case Review into Ellie Butler's death. Beyond furnishing the Serious Case Review with necessary court orders, Hogg and other members of the judiciary refused to cooperate with it.\n\nThe report of the Serious Case Review was published on 21 June 2016, immediately after Ben Butler's conviction.. Launching the Report, Christine Davies, the Chair of SCCB, said:\n"}
{"id": "33573831", "url": "https://en.wikipedia.org/wiki?curid=33573831", "title": "Murder of Girly Chew Hossencofft", "text": "Murder of Girly Chew Hossencofft\n\nGirly Chew Hossencofft (August 27, 1963 – September 1999) was a Malaysian-born woman who disappeared on September 9, 1999 in Albuquerque, New Mexico. The investigation into the murder of Girly Chew revealed a conspiracy theory involving reptilian queens, UFOs and reports of cannibalism. Girly Chew's husband Diazien Hossencofft and his girlfriend Linda Henning were convicted of her murder. Girly's body has never been found.\n\nGirly Chew was born on August 27, 1963 in Malaysia. During a visit to the United States in the early 1990s, she met Diazien Hossencofft at SeaWorld. In 1993, Girly and Diazien married. They resided in Albuquerque, New Mexico where Girly was employed as a bank teller. In January 1999, Girly moved out of the couple's home and filed for divorce after a domestic violence incident where Diazien had threatened to kill her. She confided in her co-workers that she was afraid of her husband after she found out he was not a doctor and was using a fake name.\n\nDiazien Hossencofft was born Armand Chavez in Houston, Texas on March 5, 1965. He falsely claimed that he was a thoracic surgeon with degrees from the University of Tokyo and Cornell Medical College. In reality, he was a con artist who had doctored his transcripts and was expelled from medical school. Following his expulsion, he changed his name to Diazien Hossencofft and married Girly Chew. Diazien continued to trick people into believing he was a geneticist who claimed to have leukemia; he sold fake cancer treatments to clients, who would pay thousands of dollars for anti-aging injections. In 1996, he fathered a son with a Japanese woman living in Canada. In 1999, while still married to his wife Girly, he was engaged to three different women, including Linda Henning.\n\nLinda Henning was born on October 10, 1953 in Hollywood, California. After high school, she worked as a fashion model, and later became a successful fashion designer. In 1999, Linda met Diazien, and she quickly broke up with her fiance and became engaged to Diazien. Linda and Diazien shared an interest in government conspiracy theories and UFOs.\n\nOn the morning of September 10, 1999, Girly Chew Hossencofft failed to show up for work. Her co-workers immediately became concerned about Girly's welfare and reported her missing that day. Diazien Hossencofft was the prime suspect in the investigation, but he had left for Charleston, South Carolina that very day. Investigators then focused their attention on Girly Chew's apartment and Diazien Hossencofft's girlfriend, Linda Henning. Inside Girly's apartment, the investigators noticed the smell of bleach. Using luminol, they found considerable blood evidence.\n\nFollowing the search of Girly Chew's apartment, police questioned Henning, who appeared as a personal reference of Diazien. In her interview, she claimed that she believed that Diazien was an accomplished doctor and that she had no knowledge of Girly Chew Hossencofft's disappearance. She later stated to an investigative grand jury that she did not even know Diazien's missing wife, but police were able to prove that she was lying. Investigators showed that Linda had banked at the branch where Girly worked, and that Girly had been Linda's teller on at least one occasion. Linda Henning was charged with perjury for lying to the grand jury in October 1999.\n\nIn Henning's home, investigators recovered a ninja sword in her attic, which was purchased on the morning of Girly's murder. Days after Girly Chew's disappearance, her clothing was found on a tarpaulin in Belen, New Mexico. Along with Girly's clothing, investigators discovered a piece of duct tape with Linda Henning's hair attached. She and Diazien Hossencofft were indicted and charged with murder.\n\nIn January 2002, in an effort to avoid the death penalty, Diazien Hossencofft pleaded guilty to the murder of his wife. In exchange for his plea bargain, he was sentenced to life in prison plus 61 years to be served in Wyoming State Penitentiary.\n\nLinda Henning's murder trial began in September 2002, more than three years after Girly Chew Hossencofft's disappearance. The trial was later televised on CourtTV. She was the first woman in New Mexico history to face capital punishment. Linda's friends believed that she had been brainwashed and drugged by Diazien. Onlookers noted Linda's strange actions as forensic investigators testified for the prosecution.\n\nDuring the trial, Linda Henning's attorneys Gary Mitchell and Monica Baca called Diazien Hossencofft to testify in Linda's defense. On the stand, he proclaimed that he had masterminded the murder of his wife and that Linda Henning was completely innocent. He claimed that a man named Bill Miller was Girly Chew Hossencofft's true killer, and not Linda Henning as the prosecutors had theorized. Bill Miller had been charged in the investigation, but only with five counts of tampering with evidence. Regarding Linda's blood found in Girly's apartment, Diazien had claimed that he planted her blood there. Even though Diazien testified that he planted Linda's blood in an effort to confuse investigators, Linda's attorney believed that Diazien meant to frame Linda for the crime.\n\nOn October 25, 2002, Linda Henning was found guilty of first degree murder. She was also convicted of kidnapping, conspiracy to kidnap, tampering with evidence, and four counts of perjury. Due to the special circumstances of felony murder and kidnapping, Linda faced the death penalty.\n\nLinda Henning's sentencing was held on April 18, 2003. Before her sentencing date, prosecutor Paul Spiers wrote in his presentence investigation report that Linda Henning \"had made statements that she had actually consumed the flesh of Girly Chew Hossencofft and that, as a consequence, her remains and body would never be recovered by authorities.\" Despite the allegation, Linda was not given a death sentence. Instead, she was sentenced to 73 years in prison.\n\nFor his role in the crime, Bill Miller received one year of probation.\n\nIn 2010, Linda's perjury convictions were overturned by the New Mexico Supreme Court, however all of her other convictions and her sentence were affirmed.\n\nThe story of Girly Chew Hossencofft's murder has been televised on Crime Stories, \"Court TV\", \"American Justice\", \"The Investigators\", \"Snapped\", \"Monstresses\", \"Sins and Secrets\" and \"I'd Kill For You\".\n\nAlbuquerque television journalist Mark Horner wrote a book about the murder of Girly Chew Hossencofft, entitled \"September Sacrifice\".\n"}
{"id": "47414698", "url": "https://en.wikipedia.org/wiki?curid=47414698", "title": "Murder of Moll McCarthy", "text": "Murder of Moll McCarthy\n\nMary McCarthy, known as Moll Carthy (1902–20/21 November 1940), was a smallholder, prostitute, and murder victim from Marlhill, near New Inn, County Tipperary in Ireland. Henry \"Harry\" Gleeson (1903–23 April 1941) from Holycross, County Tipperary, was convicted of her murder and executed, but granted a posthumous pardon in 2015.\n\nMary McCarthy or Carthy, known as Moll, was an unmarried mother who had seven children by at least six different fathers between 1921 and 1940. She lived in a rundown cottage on a two-acre plot beside a farm belonging to John Ceasar, from whose well she drew water. She lived by bartering sexual favours for produce and services. Her scandalous lifestyle attracted opprobrium and the cottage's thatched roof was destroyed by arson in 1926. Local judge Seán Troy refused two applications to have her children taken into an orphanage, persuaded that she was a good mother.\n\nHarry Gleeson was Ceasar's nephew by marriage and worked the farm for him. On 21 November 1940, Gleeson reported finding McCarthy's body, with two gunshot wounds to the face, in the \"Dug-Out Field\" of his uncle's farm. The Garda Síochána arrested Gleeson on 30 November, claiming he was the father of McCarthy's youngest child, who had recently died in infancy, and that he feared his uncle would disinherit him if he found this out. Gleeson denied any \"immoral association\" with McCarthy or \"hand, act or part\" in her murder. He was tried at the Central Criminal Court in Dublin, found guilty on 27 February 1941, and sentenced to death. Appeals to the Fianna Fáil government for clemency were rejected, and he was hanged by Thomas Pierrepoint in Mountjoy Prison and buried in the prison yard.\n\nSeán MacBride was junior counsel to James Nolan-Whelan in defending Gleeson, and later claimed his opposition to the death penalty was prompted by his certainty that Gleeson was innocent. \"The Farcical Trial of Harry Gleeson\", privately published by Gleeson's friend Bill O'Connor in the 1980s, maintained that Gleeson was framed. The book spurred historian and lawyer Marcus Bourke to write \"Murder at Marlhill\", published in 1993, which offered evidence of Gleeson's innocence. Cathal O'Shannon presented a documentary on RTÉ in 1995 based on Bourke's book. The Justice for Harry Gleeson Group was established locally to gather evidence and campaign, and it later contacted the Irish Innocence Project, the Innocence Network's Irish affiliate at Griffith College Dublin. In 2013 the Irish Innocence Project sent its file to the Department of Justice and Equality. Minister Alan Shatter sent it to Máire Whelan, the Attorney General, who got senior counsel Shane Murphy to review it. Deficiencies in the case were noted:\n\nMurphy reported that the conviction was based on \"unconvincing circumstantial evidence\" and recommended a pardon. On 1 April 2015, Shatter's successor as minister, Frances Fitzgerald, announced that the government would direct the President of Ireland to exercise his right to pardon under Article 13.6 of the Constitution of Ireland. President Michael D. Higgins formally signed the pardon order on 19 December 2015. This was presented to Gleeson's family at a ceremony on 13 January 2016. Some family members complained that the document used \"Harry\" rather than \"Henry\" as Gleeson's forename.\n\nKieran Fagan believed Marcus Bourke chose not to name the murderer in his 1993 book. Fagan in 2015 published \"The Framing of Harry Gleeson\", which claimed McCarthy was murdered by local Irish Republican Army (IRA) members suspecting that she was an informant for the local Garda sergeant, Anthony Delaney. Fagan suggests Seán MacBride's past as IRA Chief of Staff prevented him following up this angle. Other possible culprits mentioned by Brendan Ó Cathaoir in 2001 were the Gardaí or the father of the seventh child. Fagan's book caused controversy by naming the alleged fathers of McCarthy's children, many of them married. Of those, he alleges that one was involved in the murder and others knew that Gleeson was innocent, but were content to have the scandal of their relationship to the victim kept hidden.\n\n\"We Are Seven\", a 1955 novel based on McCarthy's life, was written by Una Troy, daughter of the judge Seán Troy who had kept McCarthy's children with her. A 1958 film adaptation, \"She Didn't Say No\", was banned by the Irish Film Censor for immorality. Carlo Gébler's 2011 novel \"The Dead Eight\" is based on the murder case.\n\n\n"}
{"id": "21460807", "url": "https://en.wikipedia.org/wiki?curid=21460807", "title": "Norman Brown (motorcyclist)", "text": "Norman Brown (motorcyclist)\n\nNorman Brown, Jr. (1960 – 31 July 1983) was a Northern Irish professional motorcycle road racer.\n\nBrown was born in Newry, County Down, Northern Ireland where his father, Norman Brown, Sr. ran a public house, \"The Star Bar\" or \"Brown's Bar\", overlooking the Clanrye River and Newry Town Hall. An alumnus of Newry High School, Brown, Jr. won the 1982 \"Classic race\" in the Isle of Man TT. In 1983, he raised the TT lap record to 116.19 mph in the Senior Classic event for machines up to 1000cc. Brown also won the 350cc class at the 1983 North West 200 race in Northern Ireland.\n\nBrown was killed during the 1983 British Grand Prix at Silverstone on 31 July 1983. When it began to rain he slowed, apparently due to mechanical problems. With greatly reduced speed he continued the lap to reach the pits. After exiting the Stowe he held to the inside line and was passed by multiple riders before being hit by Swiss rider Peter Huber, whose view was obscured by the riders in front of him. The race was not stopped until multiple riders decided to enter the pits voluntarily. Both riders died as a consequence of their serious injuries.\n"}
{"id": "21632295", "url": "https://en.wikipedia.org/wiki?curid=21632295", "title": "Phreatoicidea", "text": "Phreatoicidea\n\nPhreatoicidea is a suborder of isopod crustaceans. Extant species are confined to freshwater environments in South Africa, India, and Oceania. This seemingly Gondwana-derived distribution belies the fact that the group once had a cosmopolitan distribution; fossils which can be assigned to the Phreatoicidea are the oldest isopod fossils, and are found throughout the world. In the intervening 325 million years, phreatoicideans have changed little, and are thus considered living fossils.\n\nThe first Australian phreatoicidean was described by Charles Chilton in 1891. Two families are represented in Australia: Amphisopodidae in the interior of Australia, and in the west, and Phreatoicidae in New South Wales, Victoria and Tasmania.\n\n"}
{"id": "49516442", "url": "https://en.wikipedia.org/wiki?curid=49516442", "title": "Phylogenetic inertia", "text": "Phylogenetic inertia\n\nPhylogenetic inertia or phylogenetic constraint refers to the limitations on the future evolutionary pathways that have been imposed by previous adaptations.\n\nCharles Darwin first recognized this phenomenon, though the term was later coined by Huber in 1939. Darwin explained the idea of phylogenetic inertia based on his observations; he spoke about it when explaining the \"Law of Conditions of Existence\". Darwin also suggested that, after speciation, the organisms do not start over from scratch, but have characteristics that are built upon already existing ones that were inherited from their ancestors; and these characteristics likely limit the amount of evolution seen in that new taxa. This is the main concept of phylogenetic inertia.\n\nRichard Dawkins also explained these constraints by likening natural selection to a river in his 1982 book \"The Extended Phenotype\".\n\n\nBirds are the only speciose group of vertebrates that are exclusively oviparous, or egg laying. It has been suggested that birds are phylogenetically constrained, as being derived from reptiles, and likely have not overcome this constraint or diverged far enough away to develop viviparity, or live birth.\n\n\n\nThere have been several studies that have been able to effectively test for phylogenetic inertia when looking into shared traits; predominantly with a comparative methods approach. Some have used comparative methods and found evidence for certain traits attributed to adaptation, and some to phylogeny; there were also numerous traits that could be attributed to both. Another study developed a new method of comparative examination that showed to be a powerful predictor of phylogenetic inertia in a variety of situations. It was called Phylogenetic Eigenvector Regression (PVR), which runs principal component analyses between species on a pairwise phylogenetic distance matrix. In another, different study, the authors described methods for measuring phylogenetic inertia, looked at effectiveness of various comparative methods, and found that different methods can reveal different aspects of drivers. Autoregression and PVR showed good results with morphological traits.\n"}
{"id": "19919849", "url": "https://en.wikipedia.org/wiki?curid=19919849", "title": "Precambrian rabbit", "text": "Precambrian rabbit\n\n\"Precambrian rabbits\" or \"fossil rabbits in the Precambrian\" are reported to have been among responses given by the biologist J.B.S. Haldane when asked what evidence could destroy his confidence in the theory of evolution and the field of study. The answers became popular imagery in debates about evolution and the scientific field of evolutionary biology in the 1990s. Many of Haldane's statements about his scientific research were popularized in his lifetime.\n\nSome accounts use this response to rebut claims that the theory of evolution is not falsifiable by any empirical evidence. This followed an assertion by philosopher, Karl Popper, who had proposed that \"falsifiability\" is an essential feature of a scientific theory. Popper also expressed doubts about the scientific status of evolutionary theory, although he later concluded that the field of study was genuinely scientific.\n\nRabbits are mammals. From the perspective of the philosophy of science, it is doubtful whether the genuine discovery of mammalian fossils in Precambrian rocks would overthrow the theory of evolution instantly, though if authentic, such a discovery would indicate serious errors in modern understanding about the evolutionary process. Mammals are a class of animals whose emergence in the geologic timescale is dated to much later than any found in Precambrian strata. Geological records indicate that although the first true mammals appeared in the Triassic period, modern mammalian orders appeared in the Palaeocene and Eocene epochs of the Palaeogene period. Hundreds of millions of years separate this period from the Precambrian.\n\nSeveral authors have written that J.B.S. Haldane (1892–1964) said that the discovery of a fossil rabbit in Precambrian rocks would be enough to destroy his belief in evolution. However these references date from the 1990s or later. In 1996 Michael J. Benton cited the 1993 edition of Mark Ridley's book \"Evolution\", Richard Dawkins wrote in 2005 that Haldane was responding to a challenge by a \"Popperian zealot\". In 2004 Richa Arora wrote that the story was told by John Maynard Smith (1920–2004) in a television programme. John Maynard Smith attributed the phrase to Haldane in a conversation with Paul Harvey in the early 1970s.\n\nThe philosopher Karl Popper held that any scientific proposition must be falsifiable, in other words it must at least be possible to imagine some reproducible experiment or observation whose outcome would disprove the hypothesis. Initially he thought that Charles Darwin's theory of natural selection (often summarized as \"the survival of the fittest\") was untestable in this sense, and therefore \"almost tautological.\" Popper later changed his view, concluding that the theory of natural selection is falsifiable and that Darwin's own example of the peacock's tail had disproved one extreme variation of it, that \"all\" evolution is driven by natural selection. Although in 1978 Popper wrote that his earlier objection had been specifically to the theory of natural selection, in lectures and articles from 1949 to 1974 he had stated that \"Darwinism\" or \"Darwin's theory of evolution\" was a \"metaphysical research programme\" because it was not falsifiable. In fact he continued to express dissatisfaction with contemporary statements of the theory of evolution which focused on population genetics, the study of the relative frequencies of alleles (different forms of the same gene). Unfortunately some of the adjustments he proposed resembled Lamarckianism or saltationism, evolutionary theories that were and still are considered obsolete, and evolutionary biologists therefore disregarded his criticisms. In 1981 Popper complained that he had been misinterpreted as saying that \"historical sciences\" such as paleontology or the history of evolution of life on Earth were not genuine sciences, when in fact he believed they could make falsifiable predictions.\n\nFurther confusion arose in 1980–1981, when there was a long debate in the pages of \"Nature\" about the scientific status of the theory of evolution. Specifically, the argument was on the factors influencing and nature of the unit of selection in the genome, with one side positing natural selection, and the other, neutral mutation. Neither of the parties seriously doubted that the theory was both scientific and, according to current scientific knowledge, true. Some participants objected to statements that appeared to present the theory of evolution as an absolute dogma, however, rather than as a hypothesis that so far has performed very well, and both sides quoted Popper in support of their positions. Evolution critics such as Phillip E. Johnson took this as an opportunity to declare that the theory of evolution was unscientific.\n\nEvolutionary biologist Richard Dawkins said that the discovery of fossil mammals in Precambrian rocks would \"completely blow evolution out of the water.\" Philosopher Peter Godfrey-Smith doubted that a single set of anachronistic fossils, however, even rabbits in the Precambrian, would disprove the theory of evolution outright. The first question raised by the assertion of such a discovery would be whether the alleged \"Precambrian rabbits\" really were fossilized rabbits. Alternative interpretations might include incorrect identification of the \"fossils\", incorrect dating of the rocks, and a hoax such as the Piltdown Man was shown to be. Even if the \"Precambrian rabbits\" turned out to be genuine, they would not instantly refute the theory of evolution, because that theory is a large package of ideas, including: that life on Earth has evolved over billions of years; that this evolution is driven by certain mechanisms; and that these mechanisms have produced a specific \"family tree\" that defines the relationships among species and the order in which they appeared. Hence, \"Precambrian rabbits\" would prove that there were one or more serious errors somewhere in this package, and the next task would be to identify those errors.\n\nBenton pointed out that, in the short term, scientists often have to accept the existence of competing hypotheses, each of which explains large parts—but not all—of the observed relevant data.\n\nGenuine fossils of earliest rabbits are from the Eocene Epoch, about 56 to 33.9 million years ago. Members of the genus \"Gomphos\" are established to be the phylogenetic root of lagomorph rabbits and hares. To date, the oldest \"Gomphos\" is \"G. elkema\" discovered in 2008 from Gujarat, India. The fossil is dated to 53 million years old.\n\n"}
{"id": "14665309", "url": "https://en.wikipedia.org/wiki?curid=14665309", "title": "Princess Marie of Waldeck and Pyrmont", "text": "Princess Marie of Waldeck and Pyrmont\n\nPrincess Marie of Waldeck and Pyrmont (Georgine Henriette Marie; 23 May 1857 – 30 April 1882) was the third daughter of George Victor, Prince of Waldeck and Pyrmont and his wife, Princess Helena of Nassau, younger half-sister of Adolphe, Grand Duke of Luxembourg.\n\nMarie was born in Arolsen, then part of the German Principality of Waldeck and Pyrmont. Her younger brother, Friedrich, was the last reigning prince of Waldeck and Pyrmont. Two of her younger sisters, Emma and Helena, married William III of the Netherlands and Prince Leopold, Duke of Albany (youngest son of Queen Victoria), respectively.\n\nOn 15 February 1877 at Arolsen, Marie married, Prince William of Württemberg (later King William II of Württemberg).\n\nThey had three children:\n\n\nMarie died on 30 April 1882 in Stuttgart, from complications resulting from the birth of her third child. William married again in 1886 to Charlotte of Schaumburg-Lippe.\n\n\n"}
{"id": "1540117", "url": "https://en.wikipedia.org/wiki?curid=1540117", "title": "Russian cosmism", "text": "Russian cosmism\n\nRussian cosmism is a philosophical and cultural movement that emerged in Russia in the turn of the 19th and 20th centuries.\n\nCosmism entailed a broad theory of natural philosophy, combining elements of religion and ethics with a history and philosophy of the origin, evolution, and future existence of the cosmos and humankind. It combined elements from both Eastern and Western philosophic traditions as well as from the Russian Orthodox Church.\n\nCosmism was one of the influences on Proletkult, and after the October Revolution, the term came to be applied to \"...the poetry of such writers as Mikhail Gerasimov and Vladimir Kirillov...: emotional paeans to physical labor, machines, and the collective of industrial workers ... organized around the image of the universal 'Proletarian', who strides forth from the earth to conquer planets and stars.\" This form of cosmism, along with the writings of Nikolai Fyodorov, was a strong influence on Andrei Platonov.\n\nMany ideas of the Russian cosmists were later developed by those in the transhumanist movement. Victor Skumin argues that the Culture of Health will play an important role in the creation of a human spiritual society into the Solar System.\n\nAmong the major representatives of Russian cosmism was Nikolai Fyodorovich Fyodorov (1828–1903), an advocate of radical life extension by means of scientific methods, human immortality, and resurrection of dead people.\n\nIn 1881, Russian revolutionary and rocket pioneer Nikolai Kibalchich proposed an idea of pulsed rocket propulsion by combustion of explosives, which was an early precursor for Project Orion.\n\nKonstantin Tsiolkovsky (1857–1935) was among the pioneers of theoretical space exploration and cosmonautics. In 1903, he published \"Изслѣдованіе міровыхъ пространствъ реактивными приборами\" (\"The Exploration of Cosmic Space by Means of Reactive Devices [Rockets]\"), the first serious scientific work on space travel. Tsiolkovsky believed that colonizing space would lead to the perfection of the human race, with immortality and a carefree existence. He also developed ideas of the \"animated atom\" (panpsychism), as well as \"radiant mankind\".\n\nOther cosmists included Vladimir Vernadsky (1863–1945), who developed the notion of noosphere, and Alexander Chizhevsky (1897–1964), pioneer of \"heliobiology\" (study of the sun’s effect on biology). A minor planet, 3113 Chizhevskij, discovered by Soviet astronomer Nikolai Stepanovich Chernykh in 1978, is named after him.\n\n\n"}
{"id": "15235331", "url": "https://en.wikipedia.org/wiki?curid=15235331", "title": "Saensak Muangsurin", "text": "Saensak Muangsurin\n\nSaensak Muangsurin (13 August 1950 – 16 April 2009) was a retired professional boxer from Phetchabun, Thailand. He was a former WBC light welterweight champion, who set a world record by winning a world title in his 3rd professional fight. He is also Thai world's heaviest boxing champion to date.\n\nSaensak started fighting from Muay Thai and fought in several Muay Thai matches held in Japan prior to winning the world title. In the beginning, he used the name \"Saensaep Petchcharoen\" and \"Saepsuang Petchcharoen\" in his neighborhood.\n\nLater, he became a famous Muay Thai fighter, he has faced many top Muay Thai fighters such as Pud Lorleg, Vicharnnoi Porntawee, Putpadnoi Warrawut, Kunpol Sakornpitak, Wisan Graigreangyuk, Kongdej Lookbangplasroy, Sirimongkol Looksiripat, and he won the junior welterweight title by knockout Sorrasak Sor Lukbookalo just the first round in 1971.\n\nIn addition, he was also an amateur boxer at the 7th Southeast Asian Peninsular Games in Singapore in 1973. He makes statistics every time he wins by RSC until won the gold medal.\n\nSaensak made his formal professional boxing debut on November 16, 1974, with a first-round knockout win. He won his second fight in February 1975 by technical knockout in round 7, and challenged Perico Fernandez for the WBC light welterweight title in his third professional fight. He defeated Fernandez by technical knockout in the 8th round on July 15, 1975, to set a world record for taking the shortest time to win the world title; it had been less than a year since he made his debut in 1974.\n\nSaensak lost his world title in his second defense against Miguel Velasquez after being disqualified in the 5th round, but quickly regained it four months later on October 29, 1976, by knocking out Velázquez in two rounds. He successfully defended the WBC belt 7 times (8 total including his defense prior to the disqualification against Velázquez), most notably against former WBC lightweight champion Guts Ishimatsu, whom he knocked out in six rounds.\n\nHe was knocked out by Sang Hyun Kim in the 13th round to lose his world title on December 30, 1978. He fell into relative obscurity from then on, losing both of his fights in 1979, one of which was a third-round knockout loss to Thomas Hearns. His last professional fight was for the OPBF welterweight title, which he lost by decision over 12 rounds. His record was 14–6–0 (11 KOs).\n\nIn 2014 Vasyl Lomachenko equaled the record of winning a world title in his third bout. Saensak still has the record for the fastest time though, having taken 11 days less than the Ukrainian.\n\nDuring the glory period he is a celebrity like a superstar. He married a popular actress in that era Prim Prapaporn. The couple have one son, he named his son Kriangsak \"King\" Mansri, just like the name of the prime minister at the time Gen. Kriangsak Chamanan.\n\nThe end of boxing, he was injured, especially the right eye. When he retired his right eye is blind. His wife divorced him. And his savings of up to 10 million baht was exhausted. Ever since his life is hard living. He has a monthly courtesy from WBC and other authorities in Thailand. But it was not enough for the cost.\n\nSaensak was admitted to Rajvithi Hospital on April 12, 2009 for liver failure and intestinal blockage. Surgery failed to improve his condition, which was complicated by Saensak being afflicted by various ailments. On April 16, Saensak died while under observation in an intensive care unit.\n\n"}
{"id": "366863", "url": "https://en.wikipedia.org/wiki?curid=366863", "title": "Shangri-La", "text": "Shangri-La\n\nShangri-La is a fictional place described in the 1933 novel \"Lost Horizon\" by British author James Hilton. Hilton describes Shangri-La as a mystical, harmonious valley, gently guided from a lamasery, enclosed in the western end of the Kunlun Mountains. Shangri-La has become synonymous with any earthly paradise, particularly a mythical Himalayan utopia – a permanently happy land, isolated from the world. In the novel, the people who live at Shangri-La are almost immortal, living hundreds of years beyond the normal lifespan and only very slowly aging in appearance. The name also evokes the imagery of the exoticism of the Orient.\n\nIn the ancient Tibetan scriptures, the existence of seven such places is mentioned as \"Nghe-Beyul Khembalung\". Khembalung is one of several \"beyuls\" (hidden lands similar to Shangri-La) believed to have been created by Padmasambhava in the 9th century as idyllic, sacred places of refuge for Buddhists during times of strife (Reinhard, 1978).\n\nThe phrase \"Shangri-La\" most probably comes from the Tibetan ',\"Shang\" – a district of Ü-Tsang, north of Tashilhunpo\" + ', pronounced \"ri\", \"Mountain\" = \"Shang Mountain\" + \"\", Mountain Pass, which suggests that the area is accessed to, or is named by, \"Shang Mountain Pass\".\n\nWhile the name Shangri-La is of relatively recent origin, the concept previously existed.\n\nAcademic scholars have debunked the myth of Shangri-La and argued that this has less to do with an unexplored place and is more connected to a fantasy of the Western world.\n\nIn China, the poet Tao Yuanming of the Jin Dynasty (265–420 CE) described a kind of Shangri-La in his work \"The Tale of the Peach Blossom Spring\" (). The story goes that there was a fisherman from Wuling, who came across a beautiful peach grove, and he discovered happy and content people who lived completely cut off from the troubles in the outside world since the Qin Dynasty (221–207 BCE).\n\nShambhala is a core concept in Tibetan Buddhism that describes a realm of harmony between man and nature that is also connected with the Kalachakra or \"wheel of time\". The Shambhala ideal is described in detail in the Shambhala Sutra, a historical text written by the Sixth Panchen Lama (1737–1780) which describes some of the Shambhala locations as being in Ngari, the western prefecture of Tibet.\n\nFolklore from the Altai Mountains describe Mount Belukha as a gateway to Shambhala. The Kun Lun Mountains (崑崙山) offer another possible place for valleys like the Shangri-La, since Hilton specifically described the “Kuen-Lun” mountains as its likely location in the book, however, Hilton is not known to have visited or studied the area. Parts of the Kun Lun lie within Ngari, mentioned in the Shambhala Sutra.\n\nIn a \"New York Times\" interview in 1936, Hilton states that he used \"Tibetan material\" from the British Museum, particularly the travelogue of two French priests, Evariste Regis Huc and Joseph Gabet, to provide the Tibetan cultural and Buddhist spiritual inspiration for Shangri-La. Huc and Gabet travelled a roundtrip between Beijing and Lhasa in 1844–1846 on a route more than north of Yunnan. Their famous travelogue, first published in French in 1850, went through many editions in many languages. A popular \"condensed translation\" was published in England in 1928, at the time that Hilton would have been gathering inspiration for – or perhaps writing – \"Lost Horizon\".\n\nToday various places, such as parts of southern Kham in northwestern Yunnan province, including the tourist destinations of Lijiang and Zhongdian, claim the title. In modern China, Zhongdian county was renamed Xiānggélǐlā (香格里拉, Shangri-La in Chinese) in 2001, to attract tourists.\n\nHilton visited the Hunza Valley in northern Pakistan, close to the Chinese border, a few years before \"Lost Horizon\" was published; hence it is a popularly believed inspiration for Hilton's physical description of Shangri-La. Being an isolated green valley surrounded by mountains, enclosed on the western end of the Himalayas, it closely matches the description in the novel; also, in an ironic reversal on the story, due to increased exposure to ultraviolet radiation, inhabitants of the high-altitude parts of the valley appear to age quickly. However, because the Hunza Valley does not have Tibetan culture and lacks Buddhist religion, it could not have been the inspiration for the cultural context for Hilton's story.\n\nPlaces like Sichuan and Tibet also claim the real Shangri-La was in its territory. In 2001, Tibet Autonomous Region put forward a proposal that the three regions optimise all Shangri-La tourism resources and promote them as one. After failed attempts to establish a China Shangri-la Ecological Tourism Zone in 2002 and 2003, government representatives of Sichuan and Yunnan provinces and Tibet Autonomous Region signed a declaration of co-operation in 2004. Also in 2001, Zhongdian County in northwestern Yunnan officially renamed itself Shangri-La County.\n\nAmerican explorers Ted Vaill and Peter Klika visited the Muli area of southern Sichuan Province in 1999, and claimed that the Muli monastery in this remote region was the model for James Hilton's Shangri-La, which they thought Hilton learned about from articles on this area in several \"National Geographic\" magazine articles in the late 1920s and early 1930s written by Austrian-American explorer Joseph Rock. Vaill completed a film based on their research, \"Finding Shangri-La\", which debuted at the Cannes Film Festival in 2007. However, Michael McRae unearthed an obscure James Hilton interview from a \"New York Times\" gossip column where he reveals his cultural inspiration for Shangri-La and, if it is any place, it is more than 250 km north of Muli on the route travelled by Huc and Gabet.\n\nBetween 2002–2004 a series of expeditions were led by author and film maker Laurence Brahm in western China which determined that the Shangri-La mythical location in Hilton's book \"Lost Horizon\" was based on references to northern Yunnan Province from articles published by National Geographic's first resident explorer Joseph Rock.\n\nOn 2 December 2010, OPB televised one of Martin Yan's \"Hidden China\" episodes, \"Life in Shangri-La\", in which Yan said that \"Shangri-La\" is the actual name of a real town in the hilly and mountainous region in northwestern Yunnan Province, frequented by both Han and Tibetan locals. Martin Yan visited arts and craft shops, local farmers as they harvest crops, and sampled their cuisine.\n\nTelevision presenter and historian Michael Wood, in the \"Shangri-La\" episode of the BBC documentary series \"In Search of Myths and Heroes\", suggests that the legendary Shangri-La is the abandoned city of Tsaparang in upper Satluj valley, and that its two great temples were once home to the kings of Guge in modern Tibet.\nThe Travel Channel recently aired an episode of Expedition Unknown that followed host Josh Gates to Nepal and its surrounding areas in search of Shangri-La. His findings are not necessarily proof that Shangri-La is or was real. However, the sky caves that are found do represent some interesting facts.\n\nThere are a number of cultural usages of the Shangri-La idea that have developed since 1933 in the wake of the novel and the film made from it.\n\nIn 2006 the International Astronomical Union gave the equatorial, dark, low-lying area of Saturn's moon Titan the name Shangri-La.\n\n\n\nShangri-La as part of the plot\n\nEiichi Ikegami wrote a novel titled \"Shangri-La\" (2005); an anime adaptation of the novel was released in 2008.\n\n\nLed Zeppelin's \"Kashmir\" contains the following lyrics: \"Like Shangri-La beneath the summer moon / I will return again / As the dust that floats finds you / We're movin' through Kashmir.\"\n\n\"Shangri-La\" is a song written by Ray Davies of The Kinks. The song appeared on the 1969 concept album, \"Arthur (Or the Decline and Fall of the British Empire)\". The song's inspiration can be traced back to when the band visited the Davies brothers' sister, Rose, and her family in Australia, the \"designed community\" that the family lived in serving as the initial lyrical inspiration.\n\nShangri-La also appears in the Oasis song \"Idler's Dream\", B-side to \"The Hindu Times\". The lyrics appear as: \n\"And as I close my eyes,\nAnd the sky turns red\nI realise just what you are.\nYou're an idler's dream,\nand you're singing Shangri-la\nShangri-la\nShangri-la\nShangri-la.\"\n\n\"Going to Shangri-La\" is a song from Atlanta Rhythm Section\n\n“This is Shangri-La” is a song on the album \"Apple\" by Mother Love Bone. \n\n\"Shangri-La\" is a track on Billy Idol's 1993 album \"Cyberpunk\".\n\n\"Helsinki–Shangri-La\" is a 2010 single of Finnish rapper Paleface.\n\n\"Shangri-La\" is the final track on the album \"A New World Record\" by ELO.\n\nElectro-Acoustic Harpist and multi-instrumentalist, Gary Edward Drum, released his composition: \"ENTERING SHANGRI-LA\" on his 2013 album: \"The Utopia Within\".\nOn 15 May 2017, Korean boyband VIXX released their song \"Shangri-La\" together with their 4th mini album, which has the same name.\n\nThe AC/DC song \"Sin City\" on the 1978 \"Powerage\" album, Shangri-la is mentioned with the lyrics \"Lamborghini's, caviar\nDry martini's, Shangrila\"\n\nShangri-La is mentioned in the song “Dr. Feelgood” by Mötley Crüe, from the album of the same name. Shangri-La is included in the lyric “He’ll tell you he’s the king of these Barrio streets, movin’ up to Shangri-La”.\n\nStevie Nicks’ solo album \"Trouble in Shangri-La\" was released on May 1, 2001. Cover art features an oriental setting showing Nicks with her back to the camera looking out over an ocean.\n\nEnglish rock band Arctic Monkeys mentioned Shangri-La in the song \"Suck It and See\", from their fourth studio album, released on 6 June 2011 by Domino Recording Company. The lyrics appear as: \n\"Blue moon girls from once upon a Shangri-La\nHow I often wonder where you are\nYou have got that face that just says\n\"Baby, I was made to break your heart\", oh-oh-oh\"\n\nShangri-La is often used in a similar context to \"Garden of Eden,\" to represent a paradise hidden from modern man. It is sometimes used as an analogy for a lifelong quest or something elusive that is much sought. For a man who spends his life obsessively looking for a cure to a disease, such a cure could be said to be that man's \"Shangri-La.\" It also might be used to represent perfection that is sought by man in the form of love, happiness, or Utopian ideals. It may be used in this context alongside other mythical and famous examples of somewhat similar metaphors such as El Dorado, The Fountain of Youth, and The Holy Grail.\n\n\n"}
{"id": "14032644", "url": "https://en.wikipedia.org/wiki?curid=14032644", "title": "Steve Aoki", "text": "Steve Aoki\n\nSteven Hiroyuki Aoki (; born November 30, 1977) is an American electro house musician, record producer, DJ, and music executive. In 2012, Pollstar designated Aoki as the highest grossing dance artist in North America from tours. He has collaborated with artists such as will.i.am, Afrojack, LMFAO, Linkin Park, Iggy Azalea, Lil Jon, Laidback Luke, BTS, Louis Tomlinson, Rise Against, Vini Vici and Fall Out Boy and is known for his remixes of artists such as Kid Cudi. Aoki has released several \"Billboard\"-charting studio albums as well, notably \"Wonderland\", which was nominated for Grammy Award for Best Dance/Electronica Album in 2013. He is the founder of the Steve Aoki Charitable Fund, which raises money for global humanitarian relief organizations.\n\nSteven Hiroyuki Aoki was born in Miami, Florida, and grew up in Newport Beach, California. He graduated from Newport Harbor High School in 1995, where he was a player on the varsity badminton team. He is of Japanese descent, the third child of Rocky Aoki and Chizuru Kobayashi. His father was a former wrestler who also founded the restaurant chain Benihana. He has two older siblings, sister Kana (who is sometimes called by her middle name \"Grace\"), and brother Kevin (owner of Doraku Sushi restaurant). His half-sister is model and actress Devon Aoki.\n\nAoki attended the University of California, Santa Barbara and graduated with two B.A. degrees, one in feminist studies and the other in sociology. In college, he produced do-it-yourself records and ran underground concerts out of his Biko room in the Santa Barbara Student Housing Cooperative, which was located in Isla Vista, a section of residential land adjacent to UCSB. As a concert venue, the apartment became known as \"The Pickle Patch\". Aoki was also involved in student activism at UCSB, being the founder of a Revolutionary Anti-Imperialist League chapter on campus. By his early 20s, Aoki had built his own record label, which he named Dim Mak – a reference to his childhood hero, Bruce Lee.\n\nAoki founded his own label, Dim Mak Records, in 1996. The label has released music by other electro house artists such as MSTRKRFT, The Bloody Beetroots, Felix Cartal, and Mustard Pimp, as well as Bloc Party, The Rakes, The Kills, Klaxons, Infected Mushroom, Scanners, Whitey, and Mystery Jets. Aoki teamed up with Blake Miller of the LA-based band Moving Units to produce remixes. The duo of Miller and Aoki work under the moniker Weird Science. Aoki has also been in numerous bands, including This Machine Kills, which released an album on Ebullition Records, Esperanza, and The Fire Next Time.\n\nIn May 2006, Aoki became a board member for MC5 bassist Michael Davis' Music Is Revolution Foundation, a non-profit organization that provides music education support within public schools. Aoki's debut mix album, \"Pillowface and His Airplane Chronicles\" was released in January 2008. He had an \"Essential Mix\" that aired on BBC Radio 1 on August 2, 2008, and again on October 27, 2012. Aoki has collaborated with fellow producers and thus far has released singles with The Bloody Beetroots, Armand Van Helden of Duck Sauce, Afrojack, Laidback Luke, Tai, Chris Lake, Angger Dimas, Sidney Samson, and Tiësto. In his interviews, Twitter feed or from his YouTube channel he has shown teasers or has discussed doing future collaborations with Diplo, Knife Party, Datsik, Chris Lake, and more.\n\nAoki has remixed many artists and bands, including The Jackson 5, Drake, Kanye West, Eminem, Lil Wayne, Mike Posner, Girls Generation, All American Rejects, Refused, The Killers, Bassnectar, Lenny Kravitz, Bloc Party, Snoop Dogg, Robin Thicke, S.P.A., Kid Cudi, Fërnando Oviedo, Chester French, BTS and Peaches. He remixed the track \"When The Wind Blows\" that features on the UK edition of The All-American Rejects 2008 album \"When The World Comes Down\". On November 10, 2009, he released a remix for Drake's song \"Forever\". The song features Drake, Kanye West, Lil Wayne, and Eminem. The track made it to the top of Hype Machine's chart in December 2009.\n\nThrough relentless touring he gained huge support from colleges. He is widely known for his acrobatic crowd surfing stunts, throwing cake at fans, spraying champagne bottles, and riding rafts on the dance floor. Performing an average of 250 shows a year, he has recently started touring with production via bus tours, like the spring 2012 Deadmeat Tour, when he headlined more than 55 cities in 60 dates across the United States and Canada. Many of the artists Aoki collaborates with make appearances on tour with him. He has played lesser-traveled regions – in 2009 he played a show in Beijing, China, with Diplo at a night organised by promoters Split Works. In July 2012, Aoki was added to the Pollstar Top 100 North American Tours in their 2012 Mid Year Report. The list designated Aoki as the highest grossing dance artist in North America for the first half of the year.\n\nIn March 2010 Aoki released \"I'm in the House\", a collaboration with Zuper Blahq—alter-ego of The Black Eyed Peas singer will.i.am. The song charted at No. 29 in the UK Singles Chart in its first week of release, and later entered the UK Dance Chart and the UK Indie Chart, peaking within the top five in each chart. The song was featured on an Episode of MTV's \"Jersey Shore\", as well as in the feature film \"Piranha\" and the trailer for \"Think Like A Man\". Producer-songwriter Lucas Secon confirmed in a May 2010 interview with HitQuarters that he and Rivers Cuomo had recently worked with Aoki on a single.\n\nAoki's first solo album, \"Wonderland,\" was released January 2012 and features guest vocalists and musicians LMFAO, Kid Cudi, Kay, Travis Barker, will.i.am aka Zuper Blahq, Wynter Gordon, Rivers Cuomo, Lil Jon, Chiddy Bang, Lovefoxxx of CSS, Big John Duncan (former guitarist of the punk band The Exploited), and others. A remix album was released shortly after. On December 11, 2012, Aoki released his first EP, \"It's the End of the World As We Know It\", which includes three songs. Aoki was nominated for Grammy Award for Best Dance/Electronica Album for \"Wonderland\" at the 2013 55th Annual Grammy Awards.\n\nOn October 11, 2013, Aoki collaborated with Linkin Park on the song \"A Light That Never Comes\" that was included on the remix album, \"Recharged,\" 18 days later. Several remixes of the song were added on the January 2014 digital download EP \"A Light That Never Comes (Remixes)\". \"A Light That Never Comes\" was used in films such as \"Expendables 3\". Aoki finished in 6th place in the 2013 America's Best DJ competition-a vote and promotion to find out the country's most popular DJ conducted by \"DJ Times\" magazine and Pioneer DJ.\n\nFrom 2011 to 2014 he had a number of other tracks included in television shows, commercials, and film. This included \"I'm In the House\", used in the music festival documentary \"Electric Daisy Carnival\" in 2011, which in 2014 was used in a trailer for the comedy \"Think Like A Man Too\" as well. In 2012 his track \"Beat Down\", featuring Australian rapper Iggy Azalea, was used in a promo for the reality show \"Bad Girls All-Star Battle\". From 2013 to 2014 his track \"Boneless\" was used in a number of commercials, with companies including Scion, Budweiser, and Sol Republic. His track \"Get Me Outta Here\" was used in a Scion commercial in 2014 as well, while \"Free the Madness\" was used in a 2014 Bud Light commercial. His track \"Flight\" in 2014 was used in a commercial for Sol Republic. Aoki's song \"Back To Earth\", featuring Fall Out Boy, was used in the 2014 film \"\", while his collaborative single \"Freak\" with Diplo and Deorro, featuring Steve Bays, was used in the 2014 film \"22 Jump Street\".\n\nThe first part of Aoki's two-part album, \"Neon Future I\", was released on September 30, 2014, and reached No. 1 on Dance/Electronic Albums in the United States. The second album, \"Neon Future II\", features artists such as Snoop Lion and Rivers Cuomo. In the United States it peaked at No. 32 on the \"Billboard\" 200, No. 1 on Dance/Electronic Albums, and No. 4 on the Independent Albums chart. In Belgium, it reached No. 68 on the Ultratop 200 Albums chart.\n\nIn May 2015, it was announced that Relativity Productions had acquired the rights to distribute the documentary \"I'll Sleep When I'm Dead\" in the United States. Filmed during the making of his \"Neon Future\" double album, the film is focused on Aoki and delves into his family history, lifestyle, music, and his business. It is co-produced by Matthew Weaver and David Gelb, who together had previously worked on the 2011 documentary \"Jiro Dreams Of Sushi\". Among the executive producers are Ryan Kavanaugh and Tucker Tooley.\n\nAs with the first in the series, Aoki released a number of promo singles leading up to the release of \"Neon Future II\". The second of those singles, \"Darker Than Blood\", came out on April 14, 2015, and features vocals from Linkin Park. According to Aoki, the song had been a work in progress since 2012. Mike Shinoda rewrote Aoki's original lyrics to make them darker, because Shinoda thought Aoki's original lyrics were \"too happy\". \"Neon Future II\" was released on May 12, 2015, through Dim Mak. Among other artists, the second \"Neon Future\" featured Snoop Lion and Rivers Cuomo. It peaked at No. 2 on the US Dance/Electronic Albums chart, among other placements in the United States. In Belgium it reached No. 93 on the Ultratop 200 Albums chart.\n\nThe 2015 science fiction thriller film \"The Hive\" features tracks from the album \"Neon Future\" by Steve Aoki,' who created the soundtrack and also served as an executive producer. Aoki is also the central character in the documentary \"I'll Sleep When I'm Dead\".\n\nAoki's fourth studio album, \"Steve Aoki Presents Kolony\", was released on July 21, 2017. It features the songs \"Night Call\" featuring Migos and Lil Yachty, \"Lit\" with Gucci Mane, \"Been Balling\" with Lil Uzi Vert and the lead single \"Without You\" with DVBBS featuring 2 Chainz which was released in April and debuted at Aoki's Ultra Music Festival 2017 set in Miami. In November 2017, it was confirmed that Aoki would be producing a remix of Korean group BTS’s song \"Mic Drop\" featuring rapper Desiigner, which was released on November 24. That day, Aoki also released a collaboration with Fifth Harmony's Lauren Jauregui, titled \"All Night\".\n\nIn February 2018, Aoki announced the release of his five-track EP titled \"5OKI\", the follow up to his 2016 EP \"4OKI\". The EP would feature him collaborating with other producers to produce a \"cross-genre\" track collective. \"I’m really putting an emphasis on EDM and I’m putting an emphasis on cross-genre collaboration. For EDM itself I’m making a big statement of re-claiming it as something [that’s] really important to me – kinda like giving back to my community,\" stated Aoki prior to the EP's release. The tracks were released at a weekly interval over five weeks from 23 March to 20 April, with \"Mayhem\" featuring Quintino releasing on 23 March 2018, followed by \"Pika Pika\" with Loopers, \"It's Time\" with Laidback Luke, \"Anthem\" with Hardwell, and concluding with \"Moshi Moshi\" with Vini Vici.\n\nOn May 18, 2018, Aoki released new single \"Pretender\" featuring AJR and rapper Lil Yachty. In June 2018, Aoki remixed Rita Ora's hit single \"Girls\" featuring Charli XCX, Bebe Rexha and Cardi B. Later that month, alongside Italian DJ Marnik, they released their version of \"Bella Ciao\", which garnered controversy. The new dance music version of the track was deemed inappropriate and insulting by many. On July 20, 2018, Aoki released new single \"Lie To Me\" featuring singer-songwriter Ira Wroldsen.\n\nOn August 6, 2018, in an interview, he announced the release of new album \"Neon Future III\". It will include collaborations with Ira Wroldsen, Nicki Minaj, Maluma, Blink-182, and BTS.\n\nOn October 25, 2018, Aoki released \"Waste It On Me\" which features BTS members, RM and Jungkook. The single, which was also included in Aoki's album, \"Neon Future III\", marked Aoki and BTS' third collaboration as well as BTS' first all-English single.\n\nAoki has made a number of appearances in the media, notably in video games, television, and music videos. He was featured in the video games \"NBA 2K8\" and \"NBA 2K9\" as a special celebrity player, even though he admits to being terrible at basketball. He makes cameos in the videos for Cobra Starship's 2007 single \"Send My Love to the Dancefloor, I'll See You in Hell (Hey Mister DJ)\" and The Sounds' single \"Tony the Beat\". Aoki made a cameo appearance in rapper Kid Cudi's video \"Just What I Am\". On July 1, 2016, it was announced that Aoki would make an appearance as both a musical contributor and non-playable character in the video game \"Dragon Ball Xenoverse 2\".\n\nIn January 2012, Steve Aoki released new tracks on \"Turntable.fm\" in conjunction with SOL REPUBLIC Headphones, making him the first established artist to fully orchestrate a listening session using the platform. Aoki appeared in an episode of The CW's new superhero series \"Arrow\" on March 20, 2013, at 8 pm EST. He was playing himself, spinning at the grand opening of Oliver Queen's fictional nightclub. He also appeared in an anti-fur ad for PETA, an organization he says he's supported since he was 14 years old. Aoki appeared on \"Never Mind the Buzzcocks\" in December 2014. He currently resides in Henderson, Nevada.\n\nAoki has won and been nominated for a number of industry awards, both in annual competitions and in magazine rankings. In 2007, he was named Best Party Rocker DJ by \"BPM Magazine\", Best DJ of the Year by \"Paper Magazine\", and Best Set of the Season at the Ibiza Awards. Several years later, in 2012, he was named #15 in the Top 100 DJs in \"DJ Magazine\", and was named America's #2 Best DJ. Also in 2012, he won an EDM Effect Woodie Award by MTVu, and the following year he was nominated for his first Grammy.\n\nAoki finished in 6th place in the 2013 America's Best DJ competition conducted by \"DJ Times\" magazine, and finished in 8th place in 2013 & 2016 and 10th place in 2014, 2015 And 2017 for \"DJ Mag\"'s Top 100 DJs competition. In 2014, Aoki was awarded two Guinness World Records, one for the \"longest crowd cheer\", and also for the \"most amount of glow sticks for thirty seconds.\" Aoki performed at the 2015 Ultra Music Festival in Miami Beach on May 21. He also earned the Guinness record for \"most traveled musician in one year\", with 161 shows in 41 countries in 2014.\n\nSince early in his career Aoki has been involved with various charities, and EDM.com named him No. 1 on their list of the eleven most charitable EDM producers. He is the founder of the Steve Aoki Charitable Fund, which raises money for global humanitarian relief organizations and medical research. Among the organization's fundraising methods are Aoki's touring events, \"memorabilia auctions\", and collaborations with other artists. In early 2015 he was named as Global Ambassador for the Best Buddies program, which is a non-profit devoted to young people with developmental and intellectual disabilities. Also around that time MTV Latin America awarded Aoki the Chiuku Award for humanitarian work. He was presented with the award at the International Dance Music Awards.\n\n\n\n\n"}
{"id": "23838524", "url": "https://en.wikipedia.org/wiki?curid=23838524", "title": "Synthetic Organism Designer", "text": "Synthetic Organism Designer\n\nSynthetic Organism Designer is a piece of software created by Craig Venter's team for designing species.\n"}
{"id": "40792793", "url": "https://en.wikipedia.org/wiki?curid=40792793", "title": "Systems of social stratification", "text": "Systems of social stratification\n\nDetailed anthropological and sociological studies have been made about customs of patrilineal inheritance, where only male children can inherit. Some cultures also employ matrilineal succession, where property can only pass along the female line, most commonly going to the sister's sons of the decedent; but also, in some societies, from the mother to her daughters. Some ancient societies and most modern states employ egalitarian inheritance, without discrimination based on gender and/or birth order.\n\nThe system of patrilineal primogeniture traditionally prevalent among most southern Bantu tribes is explained in detail by Isabel Moodley: \"Due to the polygynous nature of the customary marriage, African customary law distinguishes between \"family rank\" and \"house rank\". ... Family rank refers to the status of family members within the family group. In customary law, males held a higher rank than their female counterparts. A person's rank was ultimately determined by the principle of primogeniture. On the basis of that principle, oldest sons always had a higher rank than younger brothers and all sisters. That meant that females were always subjected to the authority of males and males alone were allowed to become family heads. In the extended family group however, the rank of a child was determined by the rank of their father within his family of origin. So, for example, if the father was the first born son in his family group that would mean that his children would hold a higher rank than any of the other children born of his siblings. ... House rank simply refers to the hierarchy of the various houses that constitute a family group. In a polygynous marriage, each marriage creates a separate family or household with the husband as the common spouse to all the families. Each household or separate family has a particular rank. ... Amongst the indigenous African peoples, the wife married first is known as the \"main wife\" or the \"great wife\". The rank of the children born in a specific household is thus solely dependent upon the rank of their mother's house or house rank. In other words, the rank of the children born to the main or great wife (irrespective of age) will be higher than the rank of all the other children born to the ancillary wives. That means that the house rank of the main or great wife and her children will be higher than that of the other spouses and their children in the other houses.\" Although she says that this system prevailed among most African peoples, not only the southern Bantu, this is doubtful.\n\nThis social structure prevalent among the southern Bantu even informed their religious beliefs The expansion of southern Bantu peoples, such as for example the Xhosa, is attributed to the fission of younger sons.\n\nPatrilineal primogeniture prevailed among the Xhosa (\"each eldest son, upon the death of his father, inherits all the property appertaining to his mother's house\"), the Pondo, the Tswana, the Ndebele, the Swazi, the Zulus, the Sotho, the Tsonga, the Venda and most other southern Bantu peoples; among them in general the first son was conceived of as superior to his siblings. As Hoernlé states, \"Among the children a strict hierarchy prevails, based on the seniority which serves as a fundamental principle of behaviour in Bantu society. The elder brother always takes precedence between brothers, and so, too, between sisters the privilege of age is maintained. Between brothers and sisters the sex differentiation often dominates the behaviour. Sisterhood and brotherhood most often overrule age differences, and there is a prescribed type of behaviour for a brother towards his sister and vice versa. Outside this intimate circle of the immediate family, the same principles of kinship and seniority hold sway. The father forms one of a close-knit group with his brothers. The latter are everywhere grouped under a kinship term which we may translate \"father\"; and these \"fathers\" are distinguished as \"great\" or \"little\" fathers, according as they are older or younger than the child's own father\". Van Warmelo writes, \"Bantu social structure knows no equals, as with whole sibs, so with individuals. The first-born of the same parents is always superior to those born after him, and this superiority is extended to his descendants, with varying consistency.\"\n\nIsaac Schapera writes about the Southern Bantu in general in \"The Bantu Speaking Tribes of South Africa\": \"Polygyny is practised; but, except in the case of Chiefs and other prominent or wealthy men, not to any marked extent. Among the Shangana-Tonga, Venda, and Tswana the first wife married is normally the great wife, the rest ranking as minor wives in order of marriage. The Nguni, however, also give special rank to a second wife (the \"right-hand wife\"), and in some cases (e.g. Natal tribes) to a third wife (the \"left-hand wife\"). Any other wives are attached in a subordinate capacity to one or other of these principal houses. The Southern and Northern Sotho have adopted a somewhat similar system of domestic organization. The great wife takes the lead in all domestic affairs and, as already mentioned, her eldest son is heir to the general household property and to the status of his father.\" He writes specifically about the Tswana: \"When a married man dies, leaving a wife and children of both sexes, his eldest son becomes the principal heir even if there is an older daughter. If this son has been formally disowned by his father, he cannot after the latter's death claim the estate. The rightful heir will be the oldest of the remaining sons. If the principal heir is dead, his eldest son will succeed to his rights, taking precedence over his father's younger brothers, along the lines already described in regard to the rules of succession.\" \"The estate of a polygamist is similarly divided. The eldest son in each house inherits all livestock assigned to that house. The eldest son of the great house further inherits such property as has not been assigned to any house\". The only land that the Tswana use for agriculture are some fields that are assigned to each wife. Regarding their rules of inheritance, \"The general rule, in practice, seems to be that the fields are inherited by those children who have not yet obtained any of their own, the youngest child having the first claim. If provision has already been made for all the children, the eldest son inherits all the fields, but can, and usually does, distribute some of them among his younger brothers and sisters\". \"(There are) three separate classes, nobles, commoners, ... and immigrants, ... Within each class there are further distinctions. Among nobles, the more closely a man is related to the chief, the higher does he rank. ... Among commoners ... the head of any group is senior to all his dependents, among whom his own relatives are of higher status than the others.\" \"The children of paternal uncles are differentiated according to the relative status of their father. ... If senior to one's father by birth, they are entitled to obedience and respect; if junior, their services can be freely commanded. The saying that a man's elder brother is his chief, and his younger brother his subject, summarises adequately the accepted relation. ...\" \"Seniority is determined firstly by priority of birth. An\neldest son is always senior to the second, who in turn is senior to the third son and so on.\"\n\nSimon Roberts and Michael Palmer made a description of the Kgatla society, a sub-group of the Tswana people, in their book \"Dispute Processes: ADR and the Primary Forms of Decision-Making\", where they notice the conical (or pyramidal, as they say) shape of Tswana societies: \"The link between the chief and the senior man in each ward is ideally a genealogical one, for the office of chief should devolve from father to eldest son, while the younger sons of each ruler go off to form their own wards, assuming administrative control of these new subdivisions of the main group. The Kgatla believe that their society was founded by Kgafela in the late seventeenth or early eighteenth century, and most of the forty-eight wards in the central village of Mochuli today are headed by men claiming descent from younger brothers of chiefs descended from Kgafela. ... ward heads are senior members of the junior branches of the chief's lineage. This system of administration is reflected at ground level in the residential organization of the main village. At the centre is a group of homesteads occupied by men of the chief's immediate agnatic segment, and ranged around this are forty seven other groups of homesteads, each presided over by a ward head. ... Within each ward ... the majority of the members again claim to be related in the male line to the headman. ... All the males claiming descent from a common grandfather tend to be grouped together, and within such a sub-group a minimal unit is made up of an adult married male, occupying a homestead with his wife (or wives) and children. ... Thus if the group is looked from the bottom up there is first the married male heading his own household, then the group consisting of his closest male agnates, then an aggregate of such groups forming a ward, and lastly the wards together forming the total society. ... Kgatla society can thus be seen as an ever growing and deepening pyramid, the base of which is extended as more males are born and rear their own families; while in its simplest form the political and administrative organization is imposed on the lineage system like a cloak.\"\n\nThe Zulus also practiced patrilineal primogeniture, allowing only minimal grants of land to younger sons. D.H. Reader writes in \"Zulu Tribe in Transition: The Makhanya of southern Natal\": \"Within a given descent group, dominant or not in the sub-ward, the senior agnate will sometimes make known to his sons before he dies the land which he wishes them to have when they marry. If he has done so, it is the duty of the eldest son of the Great House (the general heir) to see that the others receive their allotted land when they marry after their father's death. Like the chief on a smaller scale, he holds the land in trust for them. ... In general, the chief will support a father during his lifetime in the matter of land apportionment, provided an adequate grant of land has been made to the eldest son and a minimal grant to any other sons. These grants naturally depend on the amount of land which the father has available, if any. If there is sufficient land, a minimal grant consists of a garden of at least half an acre, a big field of about two acres, and space to build upon; for under the present conditions of subsistence a man cannot live on less.\" In cases of polygamy, \"The eldest son of the indlunkulu, to the exclusion of all others, succeeds to the property and status of the kraal head. Should he be dead, his eldest son will succeed. Failing such eldest son and all male lineal descendants through him, the second son of the indlunkulu succeeds and failing him his male lineal descendants in due order of seniority. Failing a third and all other sons of the indlunkulu and all male lineal descendants there, the succession will devolve upon the eldest son of the house first affiliated to the indlunkulu. Failing all heirs of this house the succession devolves upon the next affiliated house and so an according to the order of affiliation. Failing an heir in the indlunkulu or affiliated houses recourse will be had to the chief house on the Qadi side (second chief wife in a kraal, failing which, to the affiliate houses in order of their affiliation to the qadi house. Only in the event of a failure in all these houses will the succession devolve upon the eldest son of the chief khohlwa (wife of the left hand side or second in the order of marriage) in succession\" (Krige, 1950: 180). The eldest son of each wife inherited the property assigned to his mother's house. According to Comaroff, \"a man's eldest son normally succeeds him as head of his household and to any political office that he may have held, and also inherits the great bulk of his cattle and such other property. The younger sons are likewise given a few cattle each. The widow and daughters received no cattle at all\" (Comaroff, 1953:42 ). Livestock was so important among the southern Bantu that a Zulu would sometimes compare the structure of his homestead with the body of a cow. Cook claims that a Zulu informant \"drew with his finger an incomplete oval in the sand, which stood for the trunk of a cow. Above, at the neck, he indicated the place of the homestead head. At breast height he indicated with his finger the uyise wabantu. At shoulder height, on the right side, he placed the heir, and on the right flank the junior right hand son. The left hand and junior left hand sons were indicated on the left shoulder and flank. According to them the homestead thus presents itself, structurally, like a cow.\" (1940: 69; cf. Cook 1931: 26)\n\nOm Mntanga says about the Xhosa: \"According to Xhosa traditional custom, when a man dies his eldest son usually inherits his social position as household head. He also inherits land rights, cattle and material possessions\". Monica Hunter says about the Pondo: \"From childhood there is a distinction between younger and elder brother. A younger brother is ordered about by his senior. After the death of the father the eldest brother, the heir, takes the place of the father, being responsible for the maintenance of the property and, if possible, of his younger brothers. They should give him their earnings, as they should their father. An elder brother is referred to as umkhuluwe, a younger as umninawe\". It is said about the Venda:\"\"Traditionally, all land is communal, under the trusteeship of the chief. However, every man has indisputable rights to the land he occupies and uses. His sons are entitled to the use of his land but may also ask the local headman to allocate fresh portions of land. Movable property—livestock, household utensils, and the proceeds of agriculture and trade—passes to the oldest son or, in the case of a polygynous marriage, the oldest son of the senior wife. This son becomes the undisputed head of the family unless he has disgraced himself in the eyes of the family, in which case the son next in line is appointed by the deceased's oldest sister with the consent of his brothers.\" Among the Tsonga: \"Women do not inherit. The eldest son of the principal wife inherits the bulk of kraal\nproperty such as cattle and ploughs. No two siblings have the same status\". It is said about the Ndebele of Zimbabwe: \"A husband will allocate land and livestock to his wives; the eldest son of the first wife is the principal heir and inherits this property\". Among the Swazi, says Hilda Kuper in \"The Swazi: A South African Kingdom\": \"The eldest son of each house is the heir to the property belonging to that house, and the heir to the general estate is the eldest son of the principal wife of the deceased. Often she is not pointed out as such until after her husband's death. the heir to the general estate of course is also special heir to the estate of his mother's house. These special estates become the general estates inherited by the next generation of heirs.\" Phakama Shili writes in \"Social Inequalities: Inheritance Under Swazi Customary Law\": \"under Swazi customary law women are not considered to inherit the estates of their late husbands and fathers. In terms of Swazi customary law there is only one heir who succeeds to the whole estate of the deceased and such person is chosen by\nlusendvo. Where the deceased headman had one wife, his eldest son, in the absence of factors which may disqualify him becomes heir. This therefore means that his siblings will not inherit but only benefit from the estate through their brother. This preference of the eldest son over his siblings and mother goes against the dictates of the Constitution which provides for equal treatment and non-discrimination of women. If the deceased dies having married to two or more wives, the lusendvo will choose the principal wife and the oldest son of that wife or house will become the main heir\".\n\nCustoms of male primogeniture also prevailed among the Sotho. Among the Sotho, \"The heir under custom is the first male person born of that family. He takes over the administration of the estate upon death of the head of the family. This is provided for under Article 11 of the Laws of Lerotholi. The heir under custom should inherit (assuming use of the land after death of his father) the land together with obligations attached to that land.\" Adam Kuper says about all the Sotho peoples: \"The basic principle is that siblings of the same sex are regarded as similar, but are ranked; while siblings of opposite sex are different and equal. ... A polygynist's first wife is normally the senior wife, and her eldest son is generally the heir.\"\n\nPrecedence within clans and tribes based on patrilineal primogeniture was also common among the Khoi and the Damara.\n\nThe Hausa didn't have the conical clan as their system of social organization (in Africa, this system predominated mostly among southern African peoples), but had a complex system of hereditary social stratification as well. The following excerpt is from Frank A. Salamone's \"The Hausa of Nigeria\":\n\n\"The Hausa tend to rank all specialties in a hierarchical and hereditary system. Inheritance is by primogeniture. The Hausa prize wealth and use it to form patronage links. However, wealth also brings with it the burden of great responsibilities. The patron-client relationship binds all Hausa men to some extent. The Maguzawa are organized into small villages of exogamous patrilineal kin. Conversely, Muslim Hausa local organization is somewhat more complex. The compound, his wife or wives, and their children is the smallest social unit. Other family members, clients, and their families may also inhabit the compound. Therefore, patrilocal extended families or joint fraternal families often inhabit a compound. The mai-gida, or male head of the family, rules the compound. The compound forms a joint agricultural unit. Occupational specialties, however, are at the discretion of the individual. As Muslims, each Hausa male may have four wives and as many concubines as he can support. ... In conformity with the Muslim Hausa principle of hierarchy, wives are ranked in the order of their marriages. The Hausa prefer cousin marriage on either side, although patrilateral parallel cousin marriage in the Fulani style has greater prestige than any other form of marriage. ... The Hausa pride themselves on being a \"civilized\" people with strong urban roots. They display a genius for organization. Their wards have a village organization, which is under the leadership of the village head. Formerly, there would be a titled official in the capital who held clusters of villages in fief. The emir would be the overall ruler of the particular state, which consisted of a number of clusters of villages. British rule which was consolidated about the beginning of the Twentieth century changed the system in a number of ways, providing greater power to emirs and local Muslim officials.\"\nEleanor C. Swanson and Robert O. Lagace write:\n\n\"Muslim Hausa social organization is characterized by a complex system of stratification, based on occupation, wealth, birth, and patron-client ties. Occupational specialties are ranked and tend to be hereditary, to the extent that the first son is expected to follow his father's occupation. Wealth gives its possessor a certain amount of prestige and power, especially in forming ties of patronage. One's status is also determined by the status of one's family. Finally, all Hausa men are caught up in a network of patron-client ties that permeates the society. Patron-client ties are used as means of access to favors and power\".\n\nM.G. Smith also discussed thoroughly the Hausa system of social status in his work \"The Hausa system of social status.\" In that article it is explained that wives are ranked according to their order of marriage: the first-married wife is the uwar gida or highest-ranking wife; she is most respected and has greatest authority over other wives. The lowest-ranking wife is the last-married wife or amariya and is the least respected wife and the one with least authority.\n\nKent M. Elbow described the socioeconomic system of Hausa farm villages extensively in 1994. He wrote about the Gandu:\n\n\"Gandu refers to the set of relations that collectively define the basic production unit in traditional Hausaland. Most often these relations express themselves among the members of the gida, the basic household unit of rural Hausaland. The gida corresponds roughly to the common understanding of the extended family. Thus the nucleus of a gandu is an extended family, but accounts such as the classic Baba of Karo (M. Smith 1954) make it clear that the nineteenth century gandu also included slaves and descendants of slaves. Sutter's (1982) review of the literature points out that some writers stress the gandu's importance as a hedge against famine and food insecurity, while other writers emphasize its role as a defense against the slave-raiding parties prevalent during the pre-colonial era—and especially menacing in the nineteenth century under the Sokoto caliphate. Ega (1980) suggests that the traditional gandu probably consisted mostly of slaves, but stresses that the gandu was a work unit in which the owner and the slaves had mutual obligations. The owner had the right to a certain number of hours of labor from his slaves each day, and in return he was expected to provide them with land and the time to cultivate it. The slaves had full rights over the product of their \"private\" plots. It is thought that the elaborate and detailed mutual rights and duties between the gandu head and his younger brothers and sons—such as those enumerated by Hill (1970)—have evolved from the traditional mutual duties characteristic of master/slave relationships in the nineteenth century. For example, in most gandu arrangements the father assumes the responsibility of paying the taxes charged to his sons and may even be obligated to pay his sons' brideprice\".\n\n\"The gandu system dictates that holdings are inherited in their entirety by the eldest son who will assume the role as gandu head\", also wrote Kent M. Elbow. He argued that the gandu system had been on the decline for many years, and most scholars agree with this opinion. However, Poly Hill, researching a Hausa village in 1973, found that eldest sons or elder sons were still favored over younger sons in matters of land inheritance at that time. This greater transfer of property occurred during the father's lifetime:\n\n\"But although many of the sons of rich farmers may be badly situated following their father's death, there are some who will be exceptionally well placed. As under systems of primogeniture, it may be that one son (or perhaps two or more) is effectively the father's heir and successor, while his brothers are not. This is not because of any blatant inequality in the division of physical property at the time of his father's death, but because a man's eldest son (or elder sons) may have had special opportunities ... of establishing a secure position in life, while under his father\".\n\nEric J. Arnould described the social organization of Hausa farm villages as follows in \"Marketing and Social Reproduction in Zinder, Niger Republic\":\n\n\"Each hausa farm village was built up around a core family group (dengi) composed of agnatic kinfolk. The fundamental unit of residence, production, distribution, transmission, and reproduction was the gida. At a mature stage of the domestic cycle the gida was a patrilocal multiple family household of at least two generations depth and comprising the conjugal family units (iyali) of the household head (mai gida) and his married sons and their children. Some wealthier gida contained farm slaves. The gida was essentially a family farming unit (FFU) distinguished from other FFU by usufructory rights of tenure to dune (jigawa) and marsh (fadama) lands, control of its own granary, and disposition of the labor power of its active members. The household hhead (mai gida) partitioned the household land into gandu (collective) and gamana (individual) parcels. Men worked together on the gandu five days a week. The mai gida held the fruits of gandu production in trust and was obliged to feed, clothe, and pay taxes and ceremonial expenses of his household from the gandu produce during the agricultural season. With the help of the extended agnatic kin group the mai gida ensured that his sons and daughters would marry. Individual and junior iyali fed themselves during the dry season from the fruits of the gandu produce during the agricultural season. With the help of the exntended agnatic kin group the mai gida ensured tha his sons and daughters would marry. Individuals and junior iyali fed themselves during the dry season from the fruits of the gamana and, in addition, used gamana produce to participate in ceremonial events and exchanges (baptisms, marriages, funerals). Gandu produce could never be sold; gamana produce could be, but the bulk of production took place on gandu plots. On the death of the mai gida the inheriting sons did not immediately divide the land and slaves but continued to work together, the eldest brother assuming the role of mai gida. At this stage of the developmental cycle the gida became a frereche. As the families of the brothers grew, they divided the patrimony. Usually junior brothers were compelled to clear new bush lands\".\n\nThe British thought that the Hausa Law of Primogeniture was bad because it encouraged usury and mortgage.\n\nA system of ranking and patrilineal primogeniture similar to that of many southern African peoples seems to have traditionally prevailed among the Nilotic peoples of South Sudan with regards to land (the eldest son of the first wife was the heir of his father's land, residential and arable, and the land of each house was inherited by the heir of that house, i.e., the eldest son of the head wife in the house). Thus a similar lineage system prevailed among some Nilotic peoples like the Lugbara or the Dinka.\n\nHowever, it should be kept in mind that the system of social organization characteristic of most East African peoples was the segmentary lineage organization as described by Evans Pritchard's famous work on the Nuer.\n\nSahlins considered the conical clan typical of some central African Bantu lineage organizations. He didn't elaborate further on this point. According to him, \"Called conical clan by Kirchoff, at one time ramage by Firth and status lineage by Goldman, the Polynesian ranked lineage is the same in principle as the so-called obok system widely distributed in Central Asia, and it is at least analogous to the Scottish clan, the Chinese clan, certain Central African Bantu lineage systems, the house-groups of Northwest Coast Indians, perhaps even the \"tribes\" of the Israelites\". Éric de Dampierre found this type of social organization to be prevalent among the Azande. He discussed this in his work \"Sons aînés, sons cadets: les sanza d'Ebézagui\", where he explained that among the Azande elder sons and their lines of descent were ranked higher than younger sons and their lines of descent. Male primogeniture, a typical feature of a social structure of this type, also prevailed among many Cameroonian peoples (such as for example the Masa), eastern and northern Congo peoples (such as the Ngala), and the Gbaya and the Mossi, all this according to the Ethnographic Atlas. However, in Angola, Gabon and most of the rest of Congo, lateral rather than lineal succession was the rule, and most Chadian peoples commonly divided land and livestock equally between all sons.\n\nPatrilineal primogeniture also prevailed among the Songye and the Buduma, according to the Ethnographic Atlas.\n\nIn traditional Austronesian societies (roughly those of modern-day Malaysia, Indonesia, Philippines, East Timor, Brunei, Madagascar and Oceania), seniority of birth and of descent generally determined rank, often leading to the fission of those lowest in rank (younger sons from younger branches), a fact often cited by anthropologists as the cause of Austronesian expansion throughout Southeast Asia, Oceania and even the Indian Ocean -Madagascar, Mauritius-. Other terms have also been used to describe this type of social organization, such as \"status lineage\" (Goldman) \"apical demotion\" (Fox) or \"ramage\" (Firth). Sahlins also created the concept of the \"Big Man\", a type of man in Melanesian societies who becomes a leader not due to his fraternal birth order as in Polynesian societies, but to his ability and charisma. Melanesian societies could either be dominated by the conical clan as Polynesian societies or by an egalitarian system of social organization as most Papuan societies (though even some Papuan societies were characterized by a predominance of patrilineal primogeniture, like for example the society of Goodenough island). In Micronesia, the system was matrilineal and brothers succeeded each other in order of seniority; when the line of brothers was extinguished, the eldest son of the eldest sister succeeded, and so on in each successive generation.\n\nThe social system of Polynesians was similar to that of the southern Bantu. As Sahlins writes, \"The mode of succession is primogeniture; the eldest son succeeds to the position of his father. ... Not only is he differentiated from his younger brothers, but so also is every brother differentiated from every other, in accordance with their respective order of birth and the consequent prospects of succeeding to the position of their father. ... The seniority principle in the family is a microcosm of the ramified social system. ... As a consequence of seniority, the descendants of an older brother rank higher than the descendants of a younger brother. ... Every individual within this group of descendants of a common ancestor holds a differing status, one precisely in proportion to his distance from the senior line of descent in the group. ... People descendent from remote collaterals of the common ancestor are lower in rank than those descendent from a more immediate relative of the chiefly line. People with the lowest status are those who have descended from younger brothers through younger brothers ad infinitum. The process of primogenitural succession and its consequent implication of seniority result in a ranking structure which encompasses the entire society. ... In every ramified society one can recognise groups of statuses or status levels which are functionally significant in terms of differential socio-economic prerogatives. These different levels are normally present in all the larger ramages.\" These principles of seniority of descent structured and organized traditional Maori society, for example. Bernard Willard Aginsky and Te Rangi Hiroa write in \"Interacting forces in the Maori family\":\n\n\"Primogeniture is well established as the method of passing wealth, honor, titles, and other prerogatives from generation to generation. The Maori desire to have their first-born be male. The desire is especially acute in chiefly families. If the first-born is a male, he is considered an especially \"big man\" and the people rejoice because \"a chief is born.\" If a\ndaughter is born first, it is a case of \"bad luck,\" but it does not affect the right of the first-born male to primogeniture. He succeeds to his father's position in the normal course of events. But the sister is senior and all her descendants will, in each generation, be senior to her brother's descendants. The family and the people do not like this to happen. The man and his sons and daughters have to pay more deference to her and her sons and daughters than otherwise, because she is \"senior.\" Thus a man would have to pay respect to a female when the desire was for the established pattern which was the opposite. The same holds true for families not of chiefly blood. ... This came about in the Maori culture due to the fact that the elder brother takes precedence over his siblings on the basis of precedence of birth which carried with it many prerogatives. There are times when a particularly brilliant younger male is placed in the position of the \"first-born\" by the father due to his superior abilities. This depends upon the first-born not being at all outstanding, in fact, being of decidedly inferior quality. Although this occurs, it is not the pattern for the younger males of a fraternity to try to compete for the position. In the vast majority of cases, the eldest male is recognized as being the male who will succeed and does succeed to the father's position. ... The most important distinction which was made between all individuals was whether they were junior or senior to each other. This was determined by tracing their lineage back to the time when they both had the same male ancestor. The children of this ancestor became the real point at which the\ndistinction began. If \"my\" ancestor was a younger brother or sister of ((your\" ancestor, then \"I\" would be of the junior lineage and ((you\" would be of the senior lineage. The male lineages were the important ones in the society, but at the same time the female lineages had to be reckoned with. ... The first-born, being of the highest rank and power, caused the people to want a male to be the first-born. The Maori are patrilocal and patrilineal and if a female was the first-born, in the vast majority of cases she took that prestige to her husband's tribe when she married. She automatically passed it on to his children. In this way, the female was taking away from the tribe what rightfully belonged to them and was giving it to another tribe which was a potential enemy. Thus the children of a female became the members of another group. In many cases hard feelings, antagonisms and even war sprang up between these two groups. Then these children, the male children of your own females, became enemies in policy and oftentimes in fact. ... The Maori have evaded that possibility to some extent by tracing their main genealogy through the first-born males only. Thus, theoretically, there is only one line in each family which is counted, first-born males of the first-born males. This is the sociological tree of the Maori, not the biological tree. The biological tree would be represented by a triangle with the man at the apex and extended to his descendants, and by an inverted triangle viewed by a man looking at his ancestors. There would be no genealogical line, except when a relationship was established between two individuals of different generations. The line would exclude from consideration all the other individuals in the biological tree. But every time a relationship was established between two individuals of different generations, a new line would be drawn for the sake of convenience. Thus if your great-grandmother through your father (father's mother's mother) had been married to your great-grandfather through your mother (mother's mother's father), your biological tree would have fewer branches than the perfect biological tree and fewer lines could be drawn. ... Brothers call each other by terms designating \"born before me, takes precedence over me, comes before me, etc.,\" or the converse \"born after me\" etc.' The oldest male calls all the males in his fraternity by one term, and the youngest calls all the male members of his fraternity by another term. Thus, taken from the standpoint of every member of a fraternity speaking of every other member, they are all equated (as are their cousins, both cross and parallel). A child of any one of these individuals will follow his father's identifications and call all these men by one term, although he is cognizant of the paternity of his father ... The importance of the senior and junior lines and of the degree of relationship played a large part in the Maori social and political life. For example, if one tribe was visiting another, the old man who was the specialist on genealogies, and incidentally was an honored man for this accomplishment, would recite the genealogies. He would start at the very beginning when the first boat-load landed at that spot, over twenty generations before, and finally come to the split where two brothers became separated by having gone on different expeditions, or something of that nature. These two tribes are now the descendants of the two brothers. They are relatives and all of the members of the two tribes know their relationships to one another. The senior group, by establishing itself as such, is then in the position to command respect and a certain amount of deference from the junior group. But this was really a ceremonial usage of the genealogy and while the two groups were together it had its place ... When a marriage between two groups, or of a chiefly man in a group came about, or the death of an important individual, other groups visited them. Then the recounting of genealogies began and relationships would be established. Thus they would know whether to treat a man with respect or whether to expect a man to treat them with respect, as well as the individual treatments due to brother-sister relationship and so on. When two tribes came together they started their recounting of the genealogies from the original settler and came down perhaps five, ten or fifteen generations when a split occurred and a younger male left the main group to settle somewhere else. At this point the old man would say \"and so and so, the younger, went away. I leave him to you.\" Then he would go on showing how his line, and particularly he, was the direct descendant of the original settler. In this way he would establish his seniority and prestige. The other group would thus be placed in the position of being the junior lineage and therefore of less importance and prestige. A member of the visiting group would recognize the genealogy and pick up where the old man had \"given him his ancestor.\" He would continue the line down and show that he and his people were the relatives of the other group in the junior lineage and therefore of less importance and prestige in that locality. In his own locality, the visitor might have prestige by right of conquest or from intermarriage. A member of the visiting group would recognize the genealogy and pick up where the old man had \"given him his ancestor.\" He would continue the line down and show that he and his people were the relatives of the other group. In this way he, at the same time, acknowledges that his tribe is the junior group in that particular lineage and in that district. The genealogical status, which is of course the biological tree, excluding the branches for the most part, was established and memorized. This was of the utmost importance in the tribe, especially for the chiefs. This was a mark of rank, prestige and honor.\"\n\nRichard F. Salisbury described a sort of conical-like clan structure similar to the Polynesian one, although of a much less developed nature, in New Guinea.\n\nThe ramage or conical prevailed in early China, during the Longshan culture period and the period of the Three Dynasties (Xia, Shang and Zhou dynasties).\n\nRobert E. Murowchick wrote the following about the Longshan culture in \"China: Ancient Culture, Modern Land\": \"a kinship system in which people live in lineages; the status of members within the lineages, and of the different lineages themselves are dependent upon their proximity to the main line of descent from founding ancestor to current lineage head, probably through male primogeniture (as suggested by all texts relating to early China). Apparently the Longshan people were organized, according to early historical records, as ancient Chinese people were, into segmentary lineages, and their political status, both within lineages and between them, was predetermined in a hierarchical fashion. This kind of kinship groups is sometimes referred to as the conical clan, and is often prevalent among societies that tend to branch off and send the branch segments to colonize new territories, where they establish new settlements and new polities\".\n\nC. C. Lamberg-Karlovsky wrote the following about the period of the Three Dynasties (Xia, Shang and Zhou) in \"Archaeological Thought in America\": \"The Chinese state of the Three Dynasties, which did possess both law and military force, was, nevertheless, built upon a hierarchical system of segmentary lineages, where the distance away from the main line of patrilineal descent determined political status and the share of political power. Members of these lineages inhabited the walled towns, which constituted stratified networks ruled by the state government. the king sat at the top of the conical clan and, at the same time, at the top of the hierarchical state\".\n\nBruce G. Trigger wrote the following about the Shang dynasty in \"Understanding Early Civilizations: A Comparative Study\": \"Family life in Shang China was structured by patrilineal descent. Each corporate descent group (zu) inhabited a single community, and its male members worked a tract of land or practised a particular craft. Among the upper classes, two or more generations of a family belonging to a corporate descent group lived, under the authority of its senior male member, in a house composed of living rooms, shrines, reception halls, and work areas arranged around a series of open courts. Commoners appear to have lived in smaller, possibly nuclear family houses, but married sons remained subject to the authority of their fathers and uncles. Each corporate descent group traced its origin to a single male ancestor who was venerated by all his male descendants. Within the descent group patrilineal descent lines were hierarchically organized, with descent from elder brothers invariably ranking higher than descent from younger brothers. The oldest member of the senior line (da zong) was the group's leader and the sole person who could perform rituals honouring the group's deceased founder and chief guardian spirit. When a group had expanded until it contained over one hundred nuclear families (this was estimated to take seven generations), it split into two and the junior branch moved off to establish a new group. It is generally assumed that already in Shang times all the patrilineal descent groups that could trace themselves back to a common ancestor shared a surname and constituted an exogamous clan (xing). Clans took the form of large ramages, which meant that their various descent lines (zu, shi) were ranked in terms of their genealogical proximity to the clan's founder. ... Most lower-class Shang Chinese were monogamous. To ensure the birth of sons, who would perpetuate their lineage, upper-class men frequently acquired secondary wives. ... The male heir of a man's position was normally the eldest son of his first chief wife\".\n\nHe wrote the following about the specific case of the inheritance of political power: \"Strong emphasis was placed at all levels of Shang society on the ranking of descent lines within clans and on birth order among siblings of the same sex. Power and authority passed from a man to his eldest son or from older to younger brothers within a specific descent line. Supreme power was vested in the senior line of the Zi clan. Males who were closely related to reigning or previous kings held important court offices or administered territories. Regional offices tended to remain hereditary in the senior male line of their occupants. As the state expanded, new territories were established where younger sons of officials might be installed. Thus officials of higher genealogical status tended to hold land closer to the centre of the state and participated in the functioning of the court while others lived farther away. As lineages expanded, it was increasingly difficult to find positions for younger sons that would allow them to maintain an upper-class lifestyle. Territories were also assigned to leaders of clans that supported the Zi, while some conquered rulers were allowed to govern all or part of their former territories as Shang vassals. These officials were permitted to marry female members of the royal clan, and some of the most important of them married women of the royal lineage. The Shang upper class thus became a network of officials related directly or indirectly to the king. Officials who governed administrative territories bore the titles hou (archer lord?), bo (patriarch?), and tian or dian (field lord). While these positions normally were hereditary, successors, at least at the higher levels, had to be confirmed by the king, who could also promote or remove individuals from their offices. Officials who headed junior branches of a clan remained ritually and socially subordinate to the leaders of the senior branches from which they had split off, even when they lived far apart\".\n\nDuring the time of the Zhou dynasty, patrilineal primogeniture (the tsung-fa system) was also the norm, as Li Hwei explains in \"The ramage system in China and Polynesia\". He wrote: \"All the essential features of the Polynesian ramage -the principle of fission and dispersion, the succession by primogeniture, the differentiation of rank through the operation of seniority, the localization of the ramage groups,- are present in Chou Tsung-fa system in ancient China. Both of these systems involve patrilineal inheritance and the prevalence of adoption, but involve no exogamy. Both of them are reflected in the system of ancestral temples. ... the Tsung-fa system in the Chou dynasty in ancient China is essentially similar to the ramage system among the modern Polynesians\". Li Hwei also points out that the ramage system of the Paiwan (an aboriginal Taiwanese tribe) was based on a rule of absolute primogeniture (the eldest child inherits regardless of sex), not on a rule of patrilineal primogeniture (eldest son inherits) as in China and Polynesia.\n\nThe tsung-fa system, also called \"extensive stratified patrilineage\", was defined as follows by the anthropologist Chang Kuang-chih: \"The tsung-fa system of Chou is characterized by the fact that the eldest son of each generation formed the main line of descent and political authority, whereas the younger brothers were moved out to establish new lineages of lesser authority. The farther removed, the lesser the political authority\". According to Tao (1934: 17-31), \"the Tsung-fa or descent line system has the following characteristics: patrilineal descent, patrilineal succession, patriarchate, sib-exogamy, and primogeniture\".\n\nK.E. Brashier writes in his book \"Ancestral Memory in Early China\" about the tsung-fa system of patrilineal primogeniture: \"The greater lineage, if it has survived, is the direct succession from father to eldest son and is not defined via the collateral shifts of the lesser lineages. In discussions that demarcate between trunk and collateral lines, the former is called a zong and the latter a zu, whereas the whole lineage is dubbed the shi. ... On one hand every son who is not the eldest and hence not heir to the lineage territory has the potential of becoming a progenitor and fostering a new trunk lineage (Ideally he would strike out to cultivate new lineage territory). ... According to the Zou commentary, the son of heaven divided land among his feudal lords, his feudal lords divided land among their dependent families and so forth down the pecking order to the officers who had their dependent kin and the commoners who \"each had his apportioned relations and all had their graded precedence\"\"\n\nPatricia Ebrey defines the descent-line system as follows: \"A great line (ta-tsung) is the line of eldest sons continuing indefinitely from a founding ancestor. A lesser line is the line of eldest sons going back no more than five generations. Great lines and lesser lines continually spin off new lesser lines, founded by younger sons\".\n\nStrong traits of the tsung-fa system of patrilineal primogeniture survived in the lineage organizations of north China until the communist era. Myron L. Cohen writes in \"Kinship, Contract, Community, And State: Anthropological Perspectives On China\": \"The north China data reveal a dimension of agnatic kinship previously not seen as significant in lineage organization. In what I call the fixed genealogical mode of agnatic kinship patrilineal ties are figured on the basis of the relative seniority of descent lines, so that the unity of the lineage as a whole is based upon a ritual focus on the senior descent line traced back to the founding ancestor, his eldest son, and the succession of eldest sons. ... lineages can be subdivided into branches based upon the nonequivalence of lines of descent. A branch tracing its origin from the eldest son of the founding ancestor is seen to be in a relationship of ritual superiority to those branches deriving from the younger brothers. Members of different branches are thus related to each other not only in terms of common descent, but also on the basis of permanent horizontal ties between senior and junior descent lines\".\n\nThis type of unlineal descent-group later became the model of the Korean family through the influence of Neo-Confucianism, as Zhu Xi and others advocated its re-establishment in China.\n\nIn South Asia, the Aryans were also organized in a system of ranked patrilines where senior patrilines were superior to junior patrilines:\n\n\"The bifurcation in clan status increased, with status differences between lines descending\nfrom an older and younger son, with specially higher status given to those who demonstrated\nleadership qualities--the ability to lead cattle, raids, to protect the clan, to establish new\nsettlements, and to manage alliances with other clans. The rajanya families were characterized as chariot-riders and warriors, while the vish were sedentary folk, producers of pastoral and\nagricultural items. They were the lesser status, junior lineages in clans and as such they had the obligation to give some of their product to the rajanyas and to priests and bards. They were to give the oblations--sacrificial items--which the priests offered at ritual ceremonies which the rajanya organized. The priests, which came to be known as brahmins, legitimized the superior status and authority of the rajanya at these rituals. (Brahmin is often also spelled Brahman.) They invest the chiefs with attributes of the deities.\"\n\nThe Paite had a similar system, strongly based on primogeniture and patrilineality and reinforced by a characteristic system of name-giving:\n\n\"Position of a child in a family determines who will be its name-giver. The first son of the second son receives his name from his father's eldest brother or father's father. Any first born son of younger sons receives his name from paternal side to emphasize patrilineality and seniority of the child concerned. The first sons of the younger brothers also get names from paternal kinsmen while the first daughter gets her name from her maternal kinsmen. As in the case of the third child of the eldest brother the tanupi gets a chance to give name to the third child of the younger brother. Death of the first child or the second child in childhood reverts the process. ... The rule of giving names to the children of more brothers cannot follow the same procedure in precision. Importance is given to the first son of the eldest son in which case the male line is strictly adhered to. The eldest son of the eldest son or eldest brother is the link between the generation of his father and his own children. He is also the lineage leader. Formerly he was known as tuulpi, e.g. ritual leader of the lineage. This line of descent is the main line in conical clan system of the paite. So long as it continues to exist this senior descent line is regarded as innpi (principal house) by the younger brothers or the cadet lines. The name-giving system of the Paite serves as an infallible record of pedigree. Depth of generation is acertainable through the name giving system as every grandfather transmits the last word of his name to his eldest grandson born to his eldest son. By correlating the names of grandsons and grandfathers one can determine whether a particular son is the eldest son of the eldest son or they are the younger ones. So a son of a younger brother cannot easily claim seniority over the son of the eldest brother and his descendants. The eldest son of the eldest brother has muniments to defend his seniority in the derivation of his name. When a child is born in a family the villagers say, \"So and so gives birth to a child\". What is the sex of the infant? What is its position in the family? asks someone. \"It is the third child and the first female child in the family\" comes the answer. \"Well! If it is so, she will get her name from the female tanupi\" concludes the other. Since patriliny and primogeniture are so much emphasized in Paite society the younger brothers and sisters of the ascending generations are not remembered in the next few generations. But the names of the eldest sons or brothers in each generation are more or less well remembered in subsequent generations as the name-giving system reveals it.\"\n\nA conical clan system also prevailed among the Nagas. In the beginning it vas based on a principle of male ultimogeniture, being very similar to Kachin gumsa; however, when all available land had been divided between communities in a given neighbourhood, male primogeniture became the dominant principle.\n\nOwen Lattimore wrote that the Mongols have a clan structure comprising ruling and subordinate clans, and that the elite clans are themselves internally divided into junior and elder lineages. Karl Kaser attributes the inexistence of different terms to designate an elder and a younger brother in European languages to the high prevalence of ultimogeniture among the European peasantry. Although male primogeniture came to be almost universal in the European aristocracy, peasants practiced both male primogeniture and ultimogeniture, and thus there was no overall preeminence of elder over younger brothers or vice versa. He says that among peoples of Inner Asian origin, by contrast, seniority between sons was emphasized, and thus there were separate terms to designate elder and younger brothers in their languages. Indeed, the Mongol kinship, for example, is according to Lévi-Strauss one of a type where sons must be carefully distinguished according to seniority, because of the complexity of the right of inheritance, which contemplates not only seniority of birth but also of patriline. The anthropologist Herbert Harold Vreeland, who visited three Mongol communities in 1920, published a highly detailed book with the results of his field study, \"Mongol community and kinship structure\", now publicly available. In this book he explained the ranking system prevalent in traditional Mongol communities.\n\nHe said about the Khalka Mongols: \"The family was based on monogamous marriage. Polygyny occurred, but was very rare and countenanced only for reason of sterility in the first wife. ... Custom required that at least one of the man's sons should remain always with the parents to care for them in their old age and to inherit the core of the family's property; but other sons were generally given separate shares and their economic independence, plus the movable nature of the property itself, made it possible for them to leave their father's camp. ... The terms abaga and aca are used to express not only ascendant-descendant generational ranking, but also the relative seniority of two collateral lines. Where successive generations descend patrilineally from two brothers, the line from the elder brother is the senior line, and the line from the younger brother is the junior line. All successive generations in the senior line are senior to corresponding generations in the junior line, and are known collectively as the abagiin üye (\"uncle\" generations); reciprocally, all generations in the junior line are known as the aciin üye (\"nephew\" generations). Hence, persons in corresponding generations in two collateral lines refer to each other reciprocally as abaga aha/egci and aca hüu/hüuhen. Under these circumstances, relative age terms are not employed. That is, Ego cannot say abaga düu for an abaga cousin younger than himself, nor aca aha for an aca cousin older than himself. The reason for this is clear: the Khalka system distinguishes between paternal cousins solely on the basis of the relative seniority of the two brothers who head the collateral lines, and makes these distinctions by using generation terms (abaga, aca) instead of relative age terms (aha, düü). The relative age of two cousins is not considered in the reckoning. ... The terms üyeeld, hayaald, etc. are combined with the terms abaga and aca so that collateral kinsmen may be distinguished not only according to whether they are in ascendant or descendant generations, or of senior or junior rank, with respect to the speaker. [..] Where equality of age and generation tended to minimize reserve, seniority ranking tended to increase it - i.e. in the presence of one's age and generation equals, one was more reserved if they were of senior rank than if they were of equal rank. ... Younger siblings addressed elder siblings as aha or egci, and were in turn addressed by their personal names. If there were several elder siblings of same sex, the younger sibling generally addressed only the eldest as aha or egci, and the others by abgailana terms. ... Ordinarily, younger siblings did not call elder siblings by their personal names. ... An elder brother could punish a younger brother by striking him, and the younger brother was expected not to strike back if he was not of age. When he came of age, he could strike back with impunity. However, a family was criticized by outsiders if two brothers had a long-standing feud, and quarrels between siblings were considered worse than those between spouses. ... An elder brother couuld ask a younger brother to perform certain services for him - e.g. saddle his horse - but younger brothers did not expect the service to be reciprocated. ... When an elder brother assumed trusteeship of the family after the father's death, he did not merit from his brothers all the respect shown to the father by his sons. In such cases, younger brothers often fought with elder brothers over shares allotted to them at the time the property was finally divided; this is one of the reasons why fathers liked to divide property before their death\".\n\nAbout the Chahar Mongols he wrote: \"The family was based on monogamous marriage. Polygyny occurred, but was very rare and countenanced only for reason of sterility in the first wife. ... With respect to the authority structure of the family, there appears to have been little difference between the Mongol families of Taibas Pasture and those of the Narobanchin territory ... The father, or the eldest brother, was nominal head of the house by virtue of age seniority; he controlled the capital wealth of the family, supervised the work of junior male members, and in general disciplined the males, although he had the right to discipline daughters as well, short of striking. ... The Chahar kinship terminology system presented here appears to be basically the same as the system presented for the Khalkas ... Younger siblings addressed their elder siblings with abgailana terms. Where there were several elder siblings of same sex, qualifying terms of all sorts were added to distinguish them. Elder siblings addressed younger siblings by their personal names, or, in an affectionate or joking way, as düügei. A younger sibling never addressed an elder sibling by name. ... A group of relatives, all of whom shared independently and in common a single unit of family property, was known as örehe. The senior male, who had authority over this group, managed the family property and made any necessary division of property. Family property was normally transferred to sons by a combination of both division and inheritance. When there was only one son, there was usually no division, the son remaining with his parents and inheriting the estate from them when they came enfeebled or died. Where there were several sons, the father usually divided the property during his own lifetime, giving a separate share to each son except to the son who was chosen to inherit his parent's residual share. Traditionally, this was the youngest son; in practice, it was usually the son who had take care of his parents in their old age. ... Sons to whom property was divided did not necessarily get equal shares and the father retained for himself and his heir a share larger than any of those given to other sons. Marriage appears to have been a factor determining when sons received their shares, but the data here are not clear. ... If the property was not divided among two or more sons before the father's death, the eldest son became trustee, or the mother became trustee until the eldest son reached maturity. When younger brothers reached the point where they were entitled to separate shares, the elder brother made the division\".\n\nAmong the Dagor Mongols, however, things were somewhat different: \"As suggested by the sleeping and eating arrangements, the senior man and woman in the house were accorded special privileges. These included sleeping and eating in the position of honor, being served first, receiving the choice tidbits, the right to be greeted first by persons entering the room, and other courtesies of respect and deference. Seniority depended entirely on relative age and generation. While the father and the mother were alive, they were the senior couple. Where several married brothers continued to live together after the parents' death, the eldest brother and his wife moved automatically to the position of seniority\". However, \"Seniority status in the family affected only the allocation of respect and certain privileges in intra-familial courtesies and behavior, and was not directly related to the allocation of authority. The authority structure of the extended family was based partly on considerations of relative age and generation, but the senior man and woman of the house were not automatically the most authoritative people in the family, since considerations of a more practical nature entered in. ... Younger siblings addressed their elder siblings as akaa and ekee, and were in turn addressed by their personal names, or as dew. Younger siblings never addressed elder siblings by their personal names. Brothers were rarely on terms of easy friendship with each other; they were reserved and did not joke. An elder brother could punish a younger brother physically. Although brothers might loan each other their clothes, they did not undress in each other's presence. Brothers were, on the other hand, considerably less reserved with their sisters, and could joke with them. This relationship continued throughout life. After marriage a woman felt closer to her brothers than to her sisters, because her brothers remained together in the old family home, and represented her family and ultimate authority. ... A married son or brother was always entitled to a share of the property if he desired to set up house for himself. If two or more sons left they were given equal shares\".\n\nA strict fraternal hierarchy prevailed among Mongols, and slave (\"bogol\") is equated with the category of a younger brother in The Secret History. In another passage Ogodei, though being the Great Khan, still asks for the permission of his elder brother Chagatai to invade Cathay, and Tolui sacrifices himself for his elder brother Ogodei. In the Yuan shi it is told that Nayan, weeping and beating his head to the floor, refused to accept a princely title because he had an elder brother, Qurumchi, whom he thought ought to inherit it in spite of his lower ability; in the end Qurumchi inherited the title, but he consulted with Nayan in all affairs. Mongol literature is full of events of this kind. Models of opposition between the egalitarianism of Arab societies and the hierarchical tribalism of Turco-Mongol peoples have been developed by many anthropologists, such as Cuisenier, Beck, Barfield, and Lindholm. The conical clan of Inner Asian peoples is explained in detail by Lawrence Krader in his monumental work, \"Social Organization of the Mongol-Turkic Pastoral Nomads.\" He wrote there: \"Nevertheless, this uniform kinship structure was divided into unequal estates, the nobility and the commoners. Both were estates related by descent from the clan founder; but in practice they were divided by differences in birth, wealth, accident migrations, wars. Descent lines were not equal; the line of the firstborn was more highly placed than any other, having the right of seniority… Leadership was a status that was not assigned by rote-it had to be achieved, and achievement was based on social recognition of leadership qualities.\" Sevʹi͡an Izrailevich Vaĭnshteĭn also remarks the existence of a strong fraternal hierarchy among Inner Asian (Siberian and central Asian) peoples.\n\nAmong Mongols, the marking of livestock reflected this system of social stratification. E. Landais wrote in \"The marking of livestock in traditional pastoral societies\": \"The system is based on a series of related marks that are derived from a primary mark designating the clan, which is then combined with other marks some of which are called complementary marks. These cannot be used as primary marks. The complementary marks have both syntactical and semantic properties. For instance, the 'throne' mark indicates that the owner descends from the eldest branch of his lineage, since this line, in the primogeniture system, is the one that inherits the images of the spirits of the ancestors that sit on the throne. Some of these marks, such as the 'thumb' and 'tail', the 'horn' and 'foot', the 'sun' and 'moon', are associated by pairs, or in any case suggest the existence of another mark of greater or lesser value, as applicable. An additional mark located on the right of the main mark denotes primogeniture as opposed to a left-hand position. An inverted mark along the horizontal or sagittal plane of symmetry indicates a socially inferior rank to that indicated by the primary mark.\n\nThe princes (who descend from Genghis Khan through the paternal line) mark their horses on the right-hand-side, whereas common people mark them on the left. Brothers by the same father differentiate their marks by adding a sign (rather than subtracting one which might bring bad luck to the herd) and alter them as little as possible (they might simply move them to a different position)\".\n\nDouglas R. White and Ulla C. Johansen, in a study about Turkish nomads, denied the idea that the conical clan was the type of social organization prevalent in this group, but nevertheless found evidence that earlier-born sons (first sons when there were only two sons, and first and second sons when there were more than two) took on more leadership positions and had significantly more wives and children than their younger brothers. Bates also tries to qualify the characterization of the social organization of the steppe pastoral nomads as a \"conical clan\", saying, just like Johansen about Turkish nomads, that among the Yörük nomads he studied social practices gave an advantage to elder brothers over younger ones, but this didn't mean that ranking was automatic, fixed; it was rather achieved:\n\n\"is not merely a linguistic phenomenon; it has considerable importance in interpersonal relations among siblings. What is relevant here with respect to segmentation is that the eldest of the brothers is held to be senior to all younger, irrespective of wealth, in situations of formal etiquette; he serves as spokesman when brothers act in concert. After the father's death he is obliged, more than the father in his lifetime, to provide for his single brothers, and to assist them in time of trouble . . . marriage takes place in order of birth, which again sets the order of household fissioning to form new ones as younger sons marry and bring their brides into the tent. This, of course, gives older brothers in any generation an earlier start in the production of progeny to further their name. . . . However, just as the point of segmentation does not depend entirely on genealogical depth, neither does the relative seniority of brothers escape the impact of political and residential fact in determining which of several will provide the name under which the group passes.\"\n\nOther anthropologists such as Khazanov, Lindner, Fletcher and Sneath have also rejected the theory that the conical clan was the social structure typical of the Asian steppe, arguing, contrarily to other authors, that strict succession rules based on primogeniture didn't exist in these societies. Osman Aziz Basan, in his analysis of Oguz society, found this social structure to be the dominant one, but nuanced by the importance of other factors such as \"merit\", as in the case of Turkish and Yorük nomads. Bacon wrote: \"seniority both of generation and of line were factors in selecting a chiefly successor, but ability was also of importance\" (1958:58).\n\nSome studies have found that Arab practices of endogamous marriage also benefitted elder sons and their lines of descent over younger sons and their lines of descent, thus contradicting the idea that in Arab societies, unlike in those of Inner Asia, fraternal birth order played no role at all in family relationships.\n\nIt was customary in the Ottoman Empire to let the sons of a king fight amongst themselves for the kingdom. It was almost always the eldest son, however, who succeeded in gaining the throne for himself, such as in the cases of Bayezid II, Mehmet III or Murad III. Halil Inalcik is of the opinion that among Inner Asian peoples there was no rule of succession, but notes that the first Ottoman sultans were all eldest sons and finds parallels between this tendency to make the eldest son the next king and the steppe customs of making the eldest son of the eldest line sovereign, giving the eldest son the largest share of the inheritance and the most important part of the realm, and ranking the tents in order of importance from the father's to the eldest son's and then to the eldest brother's sons; according to him, these customs were particularly common among the Kazakhs. Other scholars have also considered Kazakh society an especially good example of the Inner Asian conical clan, although others consider Mongol society the paradigm of this type of society in the Asian steppe. Buryats, for example, validated land ownership at clan gatherings where \"each component segment of the group was spatially arranged from right to left in order of genealogical seniority\" (Humphrey 1979:250). Uzbek traditional society has been analyzed under the same light. The development of conical clan structures has been linked to an increase in warfare and military expansionism in Central Asia.\n\nIn Iran, male primogeniture was the rule within the Qashqai confederacy. Within this confederacy there were three levels of leadership, and both Khan and headmen appropriated taxes and labor from members of their groups, though only the lineages of the Khans and Ilkhanis (paramount chieftains) constituted an aristocracy (Beck 1986: 193–195, 233). Thus the Qashqa'i confederacy can be considered to have been a true chiefdom confederacy. It is the contention of Lois Beck that this confederacy was a product of the interaction of nomads with the economy and institutions of the Persian state over the last 300 years (Ibid.)\n\nAs can be seen from the former examples, societies based on lineage hierarchy are particularly common in central, east and southeast Asia. Lineage hierarchy was present even in the stem-family systems of Korea, Vietnam and Japan. In Korea, the main house, that of the eldest son, was called the \"big house\" or superordinate descent group (taejong), while the houses of younger sons were called \"small houses\" or subordinate descent groups (sojong). It was through the stem family of the eldest son that the main line of descent was traced from generation to generation. Patrilineal primogeniture became prevalent during the time of the Choson dynasty. Even modern businesses are passed down according to male primogeniture in most cases. Discussing patterns of adoption in Korean families, Roger L. and Dawnhee Yim Janelli write in \"Ancestor Worship and Korean Society\":\n\n\"When adoption involves the transfer of a son between households headed by brothers, the relative seniority of the brothers usually determines whether an eldest or junior son is selected as the adoptee. younger brothers give their eldest sons to eldest brothers, but eldest brothers give one of their younger sons to younger brothers. This rule, which is common throughout Korea, was violated only twice. In both cases, eldest brothers were given to younger sons. The nonreciprocal transfer of eldest sons to eldest brothers reflects the special status accorded to a primogeniture descendant (chongso: eldest son, eldest son's eldest son, etc.) by those who belong to junior descent lines. Just as an elder brother has a higher status than his younger siblings, so his own eldest son retains some of that status over the younger brothers's sons. Giving eldest sons to senior descent lines, therefore, preserves the relative statuses of siblings based on birthright. One who had enjoyed superior status as an eldest brother before adoption enjoys it as a primogeniture descendant after adoption. Occasional violations of this adoption rule wreak havoc on the relative seniority of descent lines. Violations occur because Korean adoption practices also attempt to preserve the respective property rights of descendants. Since an eldest brother inherits more property, he is usually wealthier than his younger siblings. If he dies without descendants, his younger brother would inherit his larger share of property from their parents and in turn pass it on to his own eldest son. That eldest son, by becoming the adoptive heir of the elder brother, therefore inherits essentially the same property he would have without the adoption\".\n\nIn Korea, chiefdom confederacies where male primogeniture was the rule were a fact of early Korean history since the first millennium BC. The first may have been Old Joseon (also Kochosŏn, Gojoseon), said to be a confederacy of three tribes (Lee et al. 2005: 53).3 'The Hwanug tribe formed an aggregation with adjacent tribes or villages and then subjugated other aggregations…' (ibid.: 54). 'Old Joseon was basically a confederation and could not be easily ruled from the center' (ibid.: 64). Old Joseon's counterpart in South Korea was Jin (also Chin), also described as a loose confederacy. These confederacies ultimately broke apart into their constituent units (geosuguk), which then reformed into new confederacies: Puyŏ (also Buyeo), Koguryŏ (also Goguryeo), Ye, the Three Han (Samhan), and Gaya. These chiefdom confederacies were eclipsed by the consolidation of three of these polities into the states of Goguryeo, Baekje and Silla in the first century CE. However even these polities did not really develop centralized systems of territorial administration until the fourth century AD (Lee et al. 2005: 179).\n\nIn Japan, too, the main house, that of the eldest son, was called \"honke\", while the houses of younger sons were called \"bunke\". Younger houses were theoretically subordinate to the eldest house. There was a peculiar family type, the dozoku, which consistently reproduced this hierarchical arrangement. Edward Norbeck found survivals of this family type even as late as during the 1950s in Tohoku, in northeastern Japan. According to the author,\n\n\"The branch household stood in a social position much inferior to its founding household, and was expected to give aid to the founding household whenever it was needed. Many customs gave expression to the hierarchical relationship of the two households. Main households had obligations to their branches of providing economic support, but the greater obligation was undoubtedly upward, from bunke to honke. One of the standardized conventions of social interaction between the two was a formal exchange of greetings, congratulations, and small gifts at New Year's, the Buddhist Bon festival of midsummer, and at other ceremonial occasions. These exchanges were always initiated by the junior households, whose heads came at these occasions to call at the homes of the seniors.\"\n\nHowever, as the author also explains, not even in this region had the dozoku ever been popular, since establishing a branch family was generally difficult. Most \"branch\" families that had been established during the years immediately prior to his study had been established without the aid of the main house and functioned more or less independently from the latter.\n\nLineage hierarchy was also present in the Vietnamese family. Mark W. McLeod and Thi Dieu Nguyen write in \"Culture and Customs of Vietnam\":\n\n\"In pre-colonial times, the Viet were defined first and foremost by their families, which were fundamentally patrilineal and patriarchal in character. The \"clan\" (toc), which included a number of families related to each other through a common male ancestor (thuy to), formed the basis of society. Each clan was identified by a specific lineage name (ho) or surname, of which there are approximately 300, the most common being \"Nguyen\", followed by \"Tran\", \"Pham\", and \"Le.\" To the clan leader (truong toc) -the eldest male in the oldest branch directly descended from the founding ancestor- fell a number of duties: for instance, keeping and preserving the genealogical register (gia pha), which records the names, births, and deaths of members. Well kept registers would list the land or other properties used for the maintenance of the ancestral cult. The truong toc, who resided in the ancestral home and presided over the family council, was the one to whom related families or members within each familial unit would turn to resolve disputes; he made decisions related to lineage matters; and he served as the protector of widows and minors as well as the moral anchor for all within the clan. Within this larger body of the toc, there was the family (gia dinh): traditionally multigenerational (grandparents, parents, and children, uncles and aunts, and sometimes great-grandparents); it revolved around its central figure, the family head (gia truong) who could be the grandfather or the father (bo or thay). All owed obedience to him. The family head ruled over all family members in all matters, including property rights, education, marriage and profession, and he spoke on their behalf in dealings with the outside world. He had the power to reward or to chastise; to him were incumbent the duties of protection, of feeding, and of education, both morally and academically, vis-a-vis everyone in the family\".\n\nTheresa Phuong-Thao Pham writes in \"Family, Change and Mobility in a North Vietnamese Family\":\n\n\"The powerful lineage is known as the 'senior families' (ho dan anh) and the less powerful families are considered the 'junior families' (ho dan em). The patrilineage organization plays a role in the establishment of the villages and the development of the cultivated areas of North Vietnam (Nguyen 1993). The first group of people who left their native villages to establish new villages on new land acquisition was often composed of members of the same patrilineages. In a highly stratified society, the small families in the same patrilineage had different socio-economic positions, which can translate intocomplications for the kinship system. Traditional family record (gia pha) consists of the head of the lineage (toc truong), the heads of the branches (chi truong), a system of rituals composed of ancestor worship and the family temple, and economic means such as the family paddy fields (ruong ho) to support this worship. The family temple resembles clan system, in which members all the strands or chi of the family would pay homage on the death anniversaries of the toc truong (the head of the lineage). The redistribution of land by the Communist party since 1954 has greatly altered the family system of worship. The family temple no longer exists, but the celebration of the death anniversaries of ancestors still continues on a much smaller scale consisting of family members up to three generations. The celebration usually takes place at the eldest son's house with all immediate family members present on the death anniversary of the elder family member. The family members, usually the women, would place the food on the altar and offer the food to the deceased person before serving the food to the family members present at the meal. Family members often wear colorful headbands following the death of a family elder for up to three years\".\n\nTherefore, the conical clan of the Asian steppe, Austronesian societies and southern Bantu societies was based on a rule of primogeniture. E.R. Leach observes that a different system prevailed among the Kachin. The Kachin gave most of the land to the youngest son (patrilineal ultimogeniture) and most of the moveable property to the eldest son (patrilineal primogeniture). According to Leach, \"the kachin gumsa situation is that both the eldest and the youngest son are privileged in relation to their other brothers. The eldest brother is ideally a warrior who goes out with a group of followers drawn from his father's relatives and supporters and carves for himself a new domain; the youngest brother stays at home and inherits the ritual function of guardian of the shrine and, in the case of a chief, of the madai nat.\" Lineage rank was also determined by patrilineal ultimogeniture: \"The ritual status of the youngest son chief and his descendants is deemed to be higher than that of the eldest son chief and his descendants\", while middle sons and their descendants are ranked even below eldest sons and their descendants. In case of death or inability of the youngest son, the eldest son inherits the land as well, in preference to a middle son. According to the same author, this principle of ultimogeniture-primogeniture is reversed in Assam and the North Triangle; among the Kachin population of these regions, the eldest son inherits the house and lands of the father and the youngest son inherits the moveable property. The opposite gumlao situation is that of a more democratic and flexible system and emerges when chiefs and/or aristocrats are led to repudiate Kachin social rules, especially patrilineal ultimogeniture, partly due to the influence of the Shan, who do not employ this mode of inheritance. Shan succession rules, \"though somewhat vague, appear to favour primogeniture -at least in theory. Thus although, from certain aspects, the gumsa system can be regarded as modelled after a Shan pattern, the gumsa chief whose status and power begins to approach that of a Shan saohpa is led to repudiate principles which are fundamental to the gumsa system\". The Kachin stand in diametrical opposition to Austronesian societies with regards to rules of land and chieftainship succession, as shown by Leach, the great expert on Kachin society, who uses a comparison with Batak society to illustrate his point.\n\nThe Indigenous peoples of the Pacific Northwest Coast were socially stratified. Bruce Elliott Johansen wrote in \"The Encyclopedia of Native American Legal Tradition\":\n\n\"The Northwest Coast culture stretched from the Alaska Panhandle to the northwest coast of present day California. Members of Northwest Coast nations built large, substantial houses for extended families from massive beams taken from the tall timber of the coast. ... Rank and status permeated nearly every facet of their lives, even dictating what portion of a house a given person occupied. The class system was hereditary as well. The class structure was fixed in time, handed down in temporal lockstep by the rules of primogeniture, the passage of rights and property to the firstborn son. Northwest Coast peoples recognized three classes that seemed as imperishable as the red cedar from which they constructed their lodges: nobility, commoners, and slaves. The nobility comprised chiefs and their closest relatives; the eldest son was the family head. He, his family, and a few associates lived in the rear right-hand corner of the house, abutted by people of lower status. These people were said to be \"under the arm\" of the chief. The next highest-ranking chief, usually a younger brother of the head chief, invariably occupied the rear left-hand corner of the house, with his family. He, too, had a number of people \"under the arm\". the other two corners were occupied by lesser chiefs' families. The space between the corners, along the walls, was used by commoners' families and a few very junior-ranking nobility. They were called \"tenants\", while the nobility in the corners reserved the right to ownership of the house. ... Slaves had no designated lodgings or rights; they were captured in raids on other peoples along the coast and were sometimes traded for other slaves or goods. A noble in one village could be captured and sols into slavery in another. the captive's relatives might then mount a counter-raid to free him. A person also could fall into slavery because of accumulated unpaid debts\".\n\nRaymond J. DeMallie and Alfonso Ortiz wrote in \"North American Indian Anthropology: Essays on Society and Culture\": \"Among some Coast Salish, particularly those on Vancouver Island and the Straits Salish, the kinship system contained a potential basis for primogeniture. For example, separate terms for the oldest child existed in some societies. Also, the term for younger sibling was used as synonymous for members of junior lines (i.e., the children of siblings younger than the parents). This pattern was reflected to some extent in behavior. Barnett (1955:250-51), speaking about the Coast Salish of British Columbia, says that the oldest son would inherit the name (presumably the most distinguished name belonging to the family). Summing up the emphasis on primogeniture, Barnett states:\n\n\"Rank depended, not alone upon birth in a certain family, but also upon the order of birth within it. Within any given family, the possession of valuable items and resources of wealth and of ceremonial preprogatives was the important criterion of status. As a rule, this correlated paripassu with order of birth, for in general all rights were inherited. A fifth son in an aristocratic family therefore ranked far below the first, and his first cousin far below him (1955:247)\".\n\nNote that the \"resources of wealth\" included the title to lands such as fishing sites and ownership of such food-getting devices such as sturgeon nets. The oldest son was expected to share lands belonging to the family with other members, but he was in control of those lands and directed their use. Where family masks, dances, and other privileges were concerned, he decided when and under what circumstances they could be used\".\n\nWilliam C. Sturtevant wrote about the Nootka in \"Handbook of North American Indians: Northwest Xoast\":\n\n\"Kinship and hereditary rank were fundamental in the organization of Nootkan society. Kinship terminology is lineal in parents' generation and Hawaiian in ego's generation, consistent with ambilineal descent and the option to shift residence. The generations are consistently distinguished, and within ego's generation, senior and junior lines are distinguished. Parents' older and younger siblings' children are called by the terms used for own older and younger siblings, and the distinction continues in subsequent generations, so that an old man might call a boy 'older brother' if the boy's grandparent was the older sibling of his own grandparent. This usage is consistent with the importance of primogeniture. Brother and sister treated one another with reserve, especially while unmarried. Those called brother and sister could not marry, even if remote cousins, but if kinship was so remote that links could not be traced it was possible \"to marry one's own\", usually to get back hereditary rights that had left a descent line. Parent-child relations were close, and grandparent-grandchild especially close, as children often stayed with grandparents. Aunts and uncles were like parents, and one helped oneself to their things without asking. With parents-in-law there was great familiarity. Step-father and step-daughter kept their distance. Descent was ambilateral and kinship traced in any line allowed an individual to claim membership in more than one local group. Residence with a given group activated membership in it as a kinsman, and while there the individual gave it his loyalty and participated in its activities. Although residence was mainly patrilocal, in the long run there was no set rule. People were constantly moving between groups. Rank was closely linked with kinship, positions, such as chief, being inherited by primogeniture. A chief (the native term, hawii, also means 'wealthy upper class') was simply the highest-ranking member of a kin group of whatever level. Rank was founded on inherited rights called tupa'ti, thought of as property, which governed the ownership and use of practically everything of value. Tupa'ti, depending on their nature, could be inherited by an eldest son, shared by several children, held by an eldest daughter until her marriage and then transferred to her brother, or given to a son-in-law as common alternatives. There was a sense of patrimony of rights in a local group to be kept as intact as possible as it passed down through successive chiefs. The inheritance of tupa'ti tended to be through males. Over generations a number of descent lines developed in a group in a ranked relationship made explicit at feasts and potlatches in the order of seating, serving, and gift receiving. Rank was also constantly embodied in the place occupied in the big house. The top chief and house owner occupied the right rear (right for one facing the entrance), the next in rank, a brother or other close kinsman, the left rear. In between might be the head's married sons. Left and right front corners belonged to the third and fourth ranked. Middle sides could be for fifth and sixth ranked. Such interior locations were hereditarily owned. By the entrance were the slaves, mostly war captives, who were significant as trade objects, protective attendants, and even sacrificial victims. Commoners (were either those living with a chief, often quite close relatives, or less definitely associated transients along the sides. They always belonged to some chief who addressed them as kin. Even secondary chiefs were mascim (commoner) to a head chief. Although rank was graded continuously, an upper stratum could be distinguished consisting of indisputable chiefs with potlacht seats and titles to resource sites plus closely associated supporters, generally immediate relatives. Chiefs were the nuclei of Nootkan society; they owned practically everything and ideally did not work but directed followers. A chief and his family wore richer dress, abalone and dentallum ornaments, sea otter or fur-trimmed robes, and decorated rain hats and owned powerful symbols. For the use of resource sites the chief collected a tribute in kind, of no fixed amount, with which he could give a feast. However, big sea or land mammals belomged to the hunter who gave a feast with his catch. A chief's sons and younger brothers were subsidiary chiefs, war chiefs, and speakers, but the eldest son nominally took the top position while still a youth to ensure succession, the father continuing to actually run affairs. Some younger brothers of chiefs became independent chiefs through conquest of other groups. Other avenues to chiefship were potlatching or marriage to a woman of high rank. A chief and his more distantly related commoners were interdependent, the maintenance of his high standing resting on the support of the commoners, who in return had their children named ceremonially, were assisted in marriages, often lent privileges for social use and even granted minor rights. The chief of a group was regarded as a father looking after his children, authoritarian but beneficent\".\n\nIrving Goldman thought that the Indigenous peoples of the Pacific Northwest Coast could be related to the Polynesians. He wrote:\n\n\"For reasons that remain to be discovered, the Indian tribes of this area [NW Coast] share formal principles of rank, lineage, and kinship with Pacific islanders. The Kwakiutl, especially, seem very close to what I have designated as the \"traditional\" Polynesian society. They share with Polynesians a status system of graded hereditary ranking of individuals and of lineages; a social class system of chiefs (\"nobles\"), commoners, and slaves; concepts of primogeniture and seniority of descent lines; a concept of abstract supernatural powers as special attributes of chiefs; and a lineage system that leans toward patriliny, but acknowledges the maternal lines as well. Finally, Kwakiutl and eastern Polynesians, especially, associate ambiguity of lineage membership with \"Hawaiian\" type kinship, a fully classificatory system that does not distinguish between maternal and paternal sides, or between siblings and cousins\".\n\nRanking by matrilineal primogeniture (the nephews of a man by an elder sister rank higher than his nephews by a younger sister) prevailed among the Natchez.\n\nThe conical clan was also the form of social organization among many peoples in Pre-Columbian America, like the Aztecs (calpulli), the Inka (in fact this anthropological concept was created by Kirchoff to describe the form of Inka social organization, the ayllu; see also Isabel Yaya's description of the Inca ayllu in her work \"The Two Faces of Inca History: Dualism in the Narratives and Cosmology of Ancient Cuzco\") or the lowland tribes of Central and South America described by Kalervo Oberg.\n\nThomas Allan Abercrombie discusses the ayllu extensively as it exists today among the Aymara people in \"THE POLITICS OF SACRIFICE: AN AYMARA COSMOLOGY IN ACTION\": \"The ranking of ayllus is (and was?) performed in an idiom derived from what is ... a central and divisive cleavage in the nature of the domestic group, birth order among siblings, who are contrasted not only by age but by their differing rights to leadership roles, fiesta-cargo offices, and property. ... Patrilines are not mere aggregates of patronym possessing men and their families, juxtaposed only because of rights in land. Rather, they are structured, internally hierarchical social units, in which collective action is both enabled by, and enables the creation of, formally recognized positions of authority.`... Within the \"patristem family\" -a group of brothers who have constructed houses around the patio of their father—authority is vested in the father until his death. Afterwards, however, it is the eldest brother, the jiliri or jiliri jilata, who is regarded as becoming the kamachiri. This works out at the level of the sibling group, but what about the group of patristem units, some with nearest linking ancestors beyond the reach of memory? There exists a notion of an informal collective body of jiliris within the hamlet and patriline which can act as a sole council of elders. On close inspection, however, it turns out that these jiliris are neither equal in status nor necessarily eldest brothers within their own patri-stem sibling groups! In fact, jiliri status outside the patristem unit (and this unit begins to fragment after the death of the father of the sibling group) depends on the combination of appropriate \"leaderly\" personal qualities and the individual's status in the \"elder brother and herder-making\" system of public ritual careers. Moreover, greatest authority, that accompanied by the power to impose sanctions by force, is said to reside in a body of officials known as the jach'a íilírís. the \"great eldest brothers,\" that is, in ayllu level authorities also known as alcaldes, alguaciles, and íaías. It is almost certain that the name for this last office (the highest ranking of the three), is derived from the root jila, from which both jilata (\"brother\") and jiliri (\"eldest\" or \"first [born]\") are derived. The patrilineal hamlet as well as ayllu authority is also designated by terms related to herding roles. First, he is compared to the lead animal of the herd, the llantiru (from Sp.delantero, \"one who goes before\"). Secondly, he is known as the patriline's or ayllu's awatiri (herder), in which capacity the group which recognizes his authority becomes his rama (herd)... Upon his death, the sullk'iri may inherit the house and herd, but it is to the eldest son, not the youngest, that the status of kamachiri falls. And his comnmand extends into serious matters such as the allocation of lands and pastures within the sibling group, control over fallowing cycles, decisions about the opening of new fields (which may lead to warfare with neighboring groups), and the timing/itinerary of collective caravan expeditions to the valleys. In addition, it is the kamachiri who controls important ritual matters (related to herd fertility) which take place at the very altars he does not inherit. ... Like the llama llantiru, the role of eldest brother and the authorities who are called iilírí encode a principle of reproduction. First, as authority at the level of hamnlet, patriline, ayllu, and moiety, the jiliri conjoins the particular domestic groups of a hamlet ando patriline, the patrilines of the ayllu, and the ayllus of a moiety, by standing to all in an equivalent transitive relationship. The sullk'iri, on the other hand, reaps the rewards of inheritance, but is thereby irrevocably identified with the continuity of a particular household-that of his father—rather than with its reproduction. Like the llama-llantiru, the jiliri-llantíru owes his dominant position to control over herds, but here we refer to both animal and human ones. Unlike the youngest brother in the sibling group, who remains essentially a social extension of the father and a permanent dependant, the eldest brother receives the father's \"command\" (kamachiri), though he is exiled from his father's house and (to a degree) disinherited from his herd. His authority is, in fact, closely connected to his outward-directedness. The eldest brother could be said to be autonomous and self-generating-by establíshing his own house and herd, he is the embodiment not of the continuity of a house and herd (like the sullk'iri), but of the principle of reproduction of the very unit he is excluded from. As such, within and outside the patrigroup the jiliri also embodies the fertility (that is, the expansion) and generativity of the patriline. Like the llama llantiru, the jiliri-llantiru is associated with the conjunction of disparate herds in a new, unified herd. The jiliri's actual leadership role within the sibling group and patronymic hamlet amplifies these associations. The jiliri's \"command\" extends from the role of arbiter in intra-sibling group disputes, to that of leader of the conjoined brothers in disputes with other sibling groups within the hamlet or patriline. In addition, it is the jiliri who, stereotypically, decides when and where to go on annual trading trips, and conjoins multiple herds to make up the large caravan needed for a successful trip. it is men who are (or are becoming) jiliris who are the most likely to be able to establish a conjoint herd, garner sufficient labor, and otherwise mount a successful trade expedition. Such expeditions are crucially important source of foodstuffs, and are refracted within the collective ritual sphere in an inverse type of caravan trade (carrying foodstuffs to the ayllu-and moiety level \"ladder\" of the town for the fiesta, and returning empty-handed to the hamlet) through which the status of jach'ajiliri is achieved. But it is not only in his capacity to circulate foodstuffs that the stature of the jiliri is achieved, but in an attendant control over the circulation of the generative substances blood (wila) and fat (as a kind of solidified muju) among the human and animal, and the earthly and otherworldly realms. The point is not that only jiliris establish independent, conjoint households and herds, but that the opposed attributes of youngest and eldest brothers make them appropriate vehicles for representing two opposed facets of the household and herd: the fírst (typified by the youngest brother in dependant filial roles) is its continuity per se, as a particular unit; the second (typified by the eldest brother in independent founding-pater role) the general model or generative principIe of the household and herd as a type of social arrangement produced by, and reproducing, the patriline. Once he has begun his career, or continued an inherited one, the sponsor-jiliri joins the ranks of patriline-hamlet \"fathers\" and \"elder brothers\", and with it takes on, at the inter-domestic group level, what was, in the domestic group, the leadership roles of elder brother and father. This role is, of course, a function of the sponsor's \"outward directedness\", expressed in his ritual duties but represented as well in the terms of the asymmetric relations among exogamous patrilines within the ayllu. Patriline jiliris, like jilaqatas, are made, not born. But they are made in the image of the \"self made man\" of K'ulta society, the eldest sons, who must build their households themselves through the control they achieve of herds and alliances. Marriage is but the fírst step towards becoming a collective elder brother, herd-leader, and herder of men. The asymmetrical nature of marriage alliances, however, does not make a man into a herder of men, but a subordinate member of the herds of his wife's brother and wife's father, and he will remain thus subordinated until he turns the relation on its head by becoming a herder of his own sisters' and daughters' husbands. Accomplishing this involves withholding one's children's inheritance and \"seniority\" as long as possible, just as it requires establishing oneself in the status of superior among equals among one's own sibling group\".\n\nIn the Amazonia the conical clan survived the conquest and could be researched in situ by anthropologists. Michael J. Heckenberger writes about the xinguanos in \"The Enigma of the Great Cities: Body and State in Amazonia\":\n\n\"Hierarchical social relationships are described in terms of the degree of respect or \"shame\", ihuse (to be in a state of deference or \"shame\" [ihuse-ndagu] to a social superior), that one individual has for another. ... Children and their spouses are ihuse-ndagu to their parents and parents-inlaw, wives are to their husbands, younger siblings are to elder siblings, and, most notably in the present context, commoners are to the primary chiefs. This relationship is metaphorically represented in chiefly discourses where community members are called \"my children\", \"my sons\", or simply \"children ... Structurally hierarchy is based on primogeniture within an otherwise cognatic kinship system, whereby the higher ranking individuals derive status form their relative position in the chiefly hierarchy. More or less similar structural patterns, variably referred to as status lineages, conical clans, or house societies, have been identified for a wide range of moderately stratified societies. It is typically the case in these other hierarchical societies that the temporal extension of birth order ranking is branching, what Firth (1936) called ramification, whereby chiefly lines (e.g., the oldest sons of oldest sons) become separated from subordinate lines (the youngest sons of youngest sons). Such a structure of hierarchically organized kin groups simultaneously divides society into upper strata (chiefs) and lower strata (non chiefs) while incorporating both in a unified structure\".\n\nThe Tukanoan \"are patrilineal and exogamous: individuals belong to their father's group and speak his language but must marry partners from other groups who speak other languages. Externally, groups are equal but different; internally each is made up of a number of named clans ranked in a hierarchy. The ancestors of these clans were the sons of the Anaconda-ancestor and their birth order, the order of emergence from their father's body, determines their position: higher ranking clans are collectively \"elder brothers to those below. Clan rank is correlated with status and prestige and loosely correlated with residence: higher ranking clans tend to live in favoured downstream locations with lower ranking clans often living upstream or in headwater areas. Clan rank also has ritual correlates: top ranking clans, the \"head of the Anaconda\", are \"chiefs\" or \"headmen\" who control the group's dance ornaments and Yuruparí and sponsor major rituals; middle ranking clans are specialist dancers and chanters; below them come shamans; and at the bottom are servant clans, the \"tail of the Anaconda\", who are sometimes identified with the semi-nomadic \"Makú\" (A pejorative term with connotations of 'servant, slave, uncivilised, etc.\" ) who live in the interfluvial zones. This hierarchy of specialised roles and ritual prerogatives is most evident during collective rituals where genealogies are recited and where relations of rank and respect are emphasised. In a more subtle way, it is also reflected in everyday life. The inhabitants of a maloca are typically a group of closely related men, the children of the same father or of two or more brothers, who live together with their wives and children. When a woman marries, she leaves her natal maloca and goes to live with her husband. In symbolic terms, the maloca replicates the world in miniature and the maloca community is a both a replication and a future precursor of the ideal clan organisation described above. Here the father of the maloca community would be the Anaconda-ancestor of the whole group and his sons the ancestors of its component clans. In real life too, the eldest son and senior brother is typically the maloca headman and quite often his younger brothers are dancers, chanters or shamans, sometimes in appropriate order of birth\".\n\nStephen Hugh-Jones writes about the Tukanoan in \"Clear Descent or Ambiguous Houses ? A Re-Examination of Tukanoan Social Organisation\": \"Horizontal affinal exchanges between different groups have their complement in the vertical or hierarchical ordering of agnatic relations within each one. Each group, descended from an anaconda ancestor, is divided into a number of clans or sibs ranked according to the birth order of their founding ancestors, the anaconda's sons. Members of a given sib refer to other sibs as their elder or younger brothers. In theory, each sib should live in a single communal long-house or maloca; in practice the residence group typically consists of a sib-segment or minimal lineage, a group of brothers living with their parents and their in-married wives. The maloca community is the minimal exogamic unit and residence is virilocal: on marriage, wives move in whilst sisters move out. Tukanoan life is river oriented; in theory, and to some extent in practice, sib rank is reflected in spatial organisation. Senior sibs live downstream relative to junior sibs who live towards the headwaters. ... The headman and owner of the house is normally the eldest brother. He is treated with a certain amount of deference and has his compartment on the right hand side furthest to the rear; the compartments of married younger brothers are further towards the front whilst both unmarried youths and guests sleep near the front door. Each family represents a potential household and, in the end, tensions between them (typically over food, sex and authority) lead to the break-up of the group. ... Groups are divided into one or more sets of sibs internally ranked as elder/ younger brother as if the component sibs were a group of male siblings, the sons of the anaconda father. Sets of sibs, ideally numbering five (as in the primal house), claim specialised roles as their ritual prerogatives: the top sib are chiefs followed by chanter-dancers, warriors, shamans and servants in that order; in any given area, not all these roles are necessarily represented by extant sibs. Thought this caste-like division is expressed at sib level during ritual, in daily practice it operates only at an individual level. Male children should be given a name appropriate to their birth order and linked with the ritual role which they should adopt in adult life. In practice, the eldest brother is indeed usually the maloca headman and his younger siblings may also specialise as dancers, chanters and shamans according to seniority\"\n\nJean Elizabeth Jackson wrote the following about the Tukanoan people in \"The Fish People: Linguistic Exogamy and Tukanoan Identity in Northwest Amazonia\": \"Vaupés sibs (clans) are named, ranked, exogamous, localized patrilineal descent groups. ... Sibs are named, and these names often refer to plant or animals. Sib names can also refer to sib ancestors and their immediate descendants; this is also true for the personal names owned by each sib. These personal names are given to infants in a prescribed order. The eldest son of the headman ideally is the first-born male of his generation and receives the first name on the list. This sib-supplied name fosters growth, for it associates the newborn child with a nurturing group of agnatic kinsmen. The infant becomes more human upon receiving a name, for it is an explicit affirmation of membership in the sib, entitling it to the power and nurturance available from the ancestors. ... The sibs in a given language group are ranked. The order of ranking is explained as corresponding to the order in which a group of brothers, the ancestors of the various sibs, emerged from the rocks at a particular rapids site. ... The ranking of sibs is continued today with the use of elder-younger sibling terms between members of different sibs. However, in some language groups the difference in rank between certain pair of sibs is so great that generational divisions are brought into play. This results in an unusual and initially surprising usage of cognatic terminology. A person who belongs to a considerably higher ranked sib than another will address the other as \"uncle\" or \"grandfather\". This seemingly incongruous state of affairs is explained by Tukanoans as follows: The first ancestors of all the sibs of one language group were brothers to one another. The eldest brother emerged from the rocks at the rapids first, and the youngest last. However, there were many brothers in the beginning, and obviously there were many years between the birth of the eldest and the youngest brother. By the time the youngest brother emerged at the rapids, the eldest was very old, and had great-grandchildren. Thus, although the eldest and youngest brothers called each other \"brother\"; because many years had passed between their births the younger brothers were addressing as \"grandchild\" those individuals in the eldest brother's sib who were close to them in age. This is why, today, when people of about the same age are heard using grandparent and grandchild terms to each other, it is the one who says \"grandfather\" and who is called \"grandson\" who is of higher rank. Sib rank is signaled in other ways as well. One method of indicating a sib's ver low rank is to impugn its origins with the claim that it is a \"new\" member of the language group, \"who were our servants, who had to be taught how to build houses and speak our language. Then, taking pity on them, we adopted them as our youngest-brother sib.\"\n\nRobin M. Wright writes about the Baniwa in \"Umawali. Hohodene myths of the Anaconda, father of the fish: \"Baniwa society is some six exogamous phratries, each consisting of 4-5 patrilineal sibs ranked according to the order of emergence of mythical ancestral brothers. Like their Tukanoan neighbors, sibs were once categorized (the system has suffered numerous changes due to a situation of permanent contact) according to a system of ritual roles as ciefs (enawinai), shamans, warriors, dancers, and servants (makuperi). ... The core of local communities is the male sibling group and, as on the phratric end sib level, male sibling ties form the basis of a system of hierarchical rank according to relative age. Traditionally, the agnatic sibling group of a community constituted the most important level of decision-making. Leadership is often exercised by the eldest brother of the local group. Oral histories indicate that warfare was an important dynamic in socio-political relations with Tukanoan and Maku peoples of the Uaupés, and that war chiefs frequently organized communities of younger-brother warrior sibs to conduct campaigns for the purposes of undertaking vengeance and capturing women and children. Warfare also has a fundamental importance in mythology\".\n\nThe Gê-speaking peoples of the Amazonia were also organized in conical clan similar to those described above.\n\nSome isolated lowland tribes of Central and South America have also preserved the conical clan as their form of social organization. Such is the case of the Koji people of Colombia.\n\nIn the South Cone, ranking by patrilineal primogeniture prevailed among the Mapuche.\n\nC. Scott Littleton has suggested that ranking by patrilineal ultimogeniture could have prevailed in Proto-Indo-European society. He wrote the following in \"The New Comparative Mythology: An Anthropological Assessment of the Theories of George Dumezil\":\n\"Gerschel published, in 1956, a most interesting, albeit exploratory, paper. Entitled \"Sur un schème trifonctionnel dans une famille de légendes germaniques\", the paper is concerned with the possible existence of a tripartite scheme in a series of German and Swiss legends wherein a man or a woman performs some service for the \"little people\" (fairies, elves, etc.) and, in return, receives three gifts (e.g., a ring, a sword, and a loaf of bread) which are to be passed on to the three sons. So long as these three items are preserved, the three branches of the family will prosper. These gifts, of course, are seen by Gerschel as symbolic of the three functions, and the prosperity of the three sons so endowed varies accordingly: the eldest son receives a gift symbolizing the third function (e.g., a loaf of bread; cf. the third function identification of Lipoxaïs, eldest son of the Scythian Targitaos) and becomes a successful farmer and the father of many children; the second son receives a gift symbolic of the second function (e.g., a sword) and becomes a successful warrior; the youngest son receives a gift symbolic of the first function (e.g., a ring or a cup) and becomes a priest, an abbot, or the governor of a province. Should these objects be lost or destroyed, then the three branches of the family will cease to prosper in their respective ways. Often the first and second sons lose their talismans, while the youngest, who holds the gift symbolizing sovereignty, is able to preserve his by sequestering it in an abbey and thus continues to prosper. Gerschel concludes that these modern (fifteenth-to eighteenth century) South German and Swiss legends, many of which are tied to existing families in the area and are used to explain the differing fortunes of various branches thereof, \"sont susceptibles de récéler une matière d' origine indo-européenne: la légende est ici héritière du mythe\" (1956, p. 92). This interpretation, if correct, is, in my opinion, of the highest significance; it implies that the tripartite ideology has persisted far beyond the phase in which epics were composed, that it trascended the era of classical historical interpretation, and that, despite well over a thousand years of Christianity, it still forms a part of the European world view (at least in Bavaria and some Swiss cantons). As I see it, even if these legends are but isolated examples, Gerschel's work, coupled with that of Dumézil, opens up some most interesting avenues of research, ones that have perhaps some important theoretical implications as far as the relationships among language, society, and ideology are concerned. Another matter that this article brings into focus is the extent to which Proto I-E society was characterized by ultimogeniture. I have alluded above to Lipoxaïs, who, as the eldest son, received the lowest rank; conversely, his youngest brother Kolaxaïs became sovereign. In these German and Swiss legends, the same thing happens. Elsewhere the evidence is not clear-cut, but hints of ultimogeniture can be found throughout ancient I-E literature. One such example can be seen in the kinship in heaven theme mentioned previously in my discussion of Wikander's work; here again, the youngest son inherits the sovereign position (cf. the positions of Zeus, Feridun, Tesub, etc., relative to their respective siblings). That this was indeed the Proto I-E pattern is still an open question, but I feel that a good case for it can be made on the basis of the evidence presented above\".\n\nIt is possible that even the Proto-Germanic word for \"king\" (kuningaz) derived initially from the word for \"youngest son\" (see Rígsþula).\n\nOn the other hand, Gilman's concept of \"Germanic societies\", characterized by \"1) the autonomy of households (which are the basic units of production); 2) the coalition of households that makes up the community, which takes the form of tribal assemblies with authority in matters of war, religion, and legal disputes; and 3) hereditary leadership of the assembly's military and judicial activities\" is opposite to the conical clan model. Gilman included in his category of \"Germanic societies\" some societies from East Africa and the Near East, unrelated to Germanic peoples from an ethnic or linguistic point of view but similar in their form of social organization (this concept originated from studies of the early forms of social organization in La Mancha, Spain). This form of social organization has also been called \"segmentary lineage model\", and prevailed mostly among Semitic peoples, such as Arabs or ancient Israelites, but also among Iranian societies, Slavic societies, Tai societies and some societies from East Africa such as the Nuer, whom Evans-Pritchard studied extensively. Pashtun society is nowadays the largest society of this kind. In this model of social organization, every member of a society claims descent from a common ancestor, but all lines of descent are considered equal, not ranked.\n"}
{"id": "48804819", "url": "https://en.wikipedia.org/wiki?curid=48804819", "title": "The Keeping Hours", "text": "The Keeping Hours\n\nThe Keeping Hours is a 2017 American supernatural horror drama film directed by Karen Moncrieff and written by Rebecca Sonnenshine. The film stars Lee Pace, Carrie Coon and Sander Thomas. The film released on July 24, 2018, via video on demand and DVD on August 7, 2018 by Universal Pictures.\nTen years after the death of their son, a divorced couple is suddenly reunited by supernatural events that offer them a chance at forgiveness.\n\nThe movie opens with a couple preparing for a wedding at their home. Mark and Elizabeth already have a son, Jacob. After eight years they make the relationship official, exchange wedding vows, and enjoy a day long reception with family and friends. Time flashes to the future with the couple divorced after the son was killed in an automobile accident. The father was driving and the mother thinks she failed to secure the boy's seat belt. Each blame the other parent and yet themselves for the tragic death.\n\nMark is an attorney busy working at a large law firm. Elizabeth has remarried, wrote a book and lives in an expensive home with her step-daughters. Mark is bothered with tenants who abandoned the rented former marital home. Marks inspects the home where lights flicker and he hears strange noises. He hears footsteps and he finds Jacob's toys in the attic. He sees Jacob and passes out. After time and adjustment, Mark accepts Jacob's ghost as real. After Jacob asks Dad about Mommy. Mark brings Elizabeth to the home. She sees her son and thinks Mark has played some cruel trick on her. She learns to accept reality and is happy the boy is back in their lives. Neither parent can touch the boy.\n\nMark quits his job to make time to be with Jacob. Elizabeth visits the house each day. Jacob tells his parents he wants things back to normal including the couple back together loving one another. They all do things to make up for lost opportunities. Mom reads bedtime stories and Dad plays games. Jacob wants that real train set that he never got. The couple become close again. They learn that Jacob can leave the house so they go to the beach and build sand castles and watch a beautiful sunset.\n\nJacob tells Dad that he pushed the red button that released the seat belt. Jacob caused his own death and Dad should not feel guilty and he should forgive Mom. Elizabeth has been having nose bleeds and passed out after claiming to see her deceased mother. After an emergency room visit, Elizabeth tells Mark she stopped her depression medicine and the fainting was isolated and nothing to worry about. When Dad gets home, Jacob has his train set up and fully running. Jacob tells Dad that Mom has to take a long train ride with him. Mark confronts Elizabeth and she tells him she has terminal cancer. Mark tells her that Jacob told him that he unlatched the seat belt and she was not at fault. Later, Jacob comes to his Mom's hospital room and she hugs him and they both disappear into a white light.\n\n\nOn October 14, 2015, it was announced that Karen Moncrieff would direct a supernatural romance horror film scripted by Rebecca Sonnenshine, about two parents whose life together ends when their son dies in a car accident. Lee Pace and Carrie Coon were cast in the film to play the parents, while Jason Blum would produce the film through his Blumhouse Productions.\n\nPrincipal photography on the film began on December 1, 2015 in Los Angeles, which ended on January 22, 2016.\n\n"}
{"id": "9374964", "url": "https://en.wikipedia.org/wiki?curid=9374964", "title": "Tom Bruce (rugby league)", "text": "Tom Bruce (rugby league)\n\nThomas Fraser Bruce (1885–1917) was a pioneer Australian rugby league footballer in the New South Wales Rugby League competition and an Australian Imperial Forces (AIF) officer who fell in World War I at the Battle of Passchendale.\n\nBorn in Braidwood, New South Wales to parents Robert and Margaret Bruce, the family relocated to Sydney. His mother later lived in the Sydney suburb of Kensington.\nA halfback, Bruce played in nineteen matches for the Eastern Suburbs club in the years 1909-1912 alongside Dally Messenger. He was the 28th player for the Eastern Suburbs club. He is listed in the Easts playing squad from 1909 through till 1913, although Leslie Cody kept him out of the half-back spot in East's first premiership winning side in 1911. By 1912 the champion representative half-back Pony Halloway had joined the Tricolours and Bruce saw little first grade football in 1912 and none in 1913.\n\nBruce was a thirty-two-year-old married tram conductor with two adopted children living in Yurong St, near Hyde Park, Sydney when he enlisted in the AIF in March 1916. He was at that point active in the Home Service and had contributed as a camp-cook. Enlisted to the Australian 36th Infantry Battalion he rose from private to corporal with three months, and to sergeant six months later. He was wounded in action in Belgium at the Battle of Messines in June 1917 and rejoined his unit in August 1917 at which point he was promoted to 2nd lieutenant, less than eighteen months after enlistment . He was killed early in the first day of the First Battle of Passchendaele in Belgium on 12 October 1917 after establishing a forward command post. He was one of fifteen officers of the 36th Bttn killed at 1st Passchendaele.\n\nHe was survived by his children William and Mary and his wife May Maud Bruce. He has no known grave but is commemorated on panel 25 of the Menin Gate memorial.\n\nUnarguably perplexing is the military record at the AIF Project of a Thomas John Bruce born in 1898 whose father was the same Thomas Fraser Bruce of 28 Yurong St, Hyde Park. The private TJ Bruce served in a different unit to his father and survived the war. This would have made the older Thomas fourteen years of age when his son Thomas John was born. Perhaps one, or both Thomas Bruce was lying about his age at enlistment.\n\n"}
