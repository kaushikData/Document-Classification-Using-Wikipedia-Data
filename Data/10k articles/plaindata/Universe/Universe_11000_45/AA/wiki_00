{"id": "529953", "url": "https://en.wikipedia.org/wiki?curid=529953", "title": "Ablation", "text": "Ablation\n\nAblation is removal of material from the surface of an object by vaporization, chipping, or other erosive processes. Examples of ablative materials are described below, and include spacecraft material for ascent and atmospheric reentry, ice and snow in glaciology, biological tissues in medicine and passive fire protection materials.\n\nBiological ablation is the removal of a biological structure or functionality.\n\nGenetic ablation is another term for gene silencing, in which gene expression is abolished through the alteration or deletion of genetic sequence information. In cell ablation, individual cells in a population or culture are destroyed or removed. Both can be used as experimental tools, as in loss-of-function experiments.\n\nIn glaciology and meteorology, ablation—the opposite of accumulation—refers to all processes that remove snow, ice, or water from a glacier or snowfield. Ablation refers to the melting of snow or ice that runs off the glacier, evaporation, sublimation, calving, or erosive removal of snow by wind. Air temperature is typically the dominant control of ablation, with precipitation exercising secondary control. In a temperate climate during ablation season, ablation rates typically average around 2 mm/h. Where solar radiation is the dominant cause of snow ablation (e.g., if air temperatures are low under clear skies), characteristic ablation textures such as suncups and penitentes may develop on the snow surface.\n\nAblation can refer either to the processes removing ice and snow or to the quantity of ice and snow removed.\n\nDebris-covered glaciers have also been shown to greatly impact the ablation process. There is a thin debris layer that can be located on the top of glaciers that intensifies the ablation process below the ice. The debris-covered parts of a glacier that is experiencing ablation are sectioned into three categories which include ice cliffs, ponds, and debris. These three sections allow scientists to measure the heat digested by the debris-covered area and is calculated. The calculations are dependent on the area and net absorbed heat amounts in regards to the entire debris-covered zones. These types of calculations are done to various glaciers to understand and analyze future patterns of melting.\n\nMoraine (glacial debris) is moved by natural processes that allow for down-slope movement of materials on the glacier body. It is noted that if the slope of a glacier is too high then the debris will continue to move along the glacier to a further location. The sizes and locations of glaciers vary around the world, so depending on the climate and physical geography the varieties of debris can differ. The size and magnitude of the debris is dependent on the area of glacier and can vary from dust-size fragments to blocks as large as a house.\n\nThere has been many experiments done to demonstrate the effect of debris on the surface of glaciers. Yoshiyuki Fujii, a professor at the National Institute of Polar Research designed an experiment that showed ablation rate was accelerated under a thin debris layer and was retarded under a thick one as compared with that of a natural snow surface. This science is significant due to the importance of long-term availability of water resources and assess glacier response to climate change. Natural resource availability is a major drive behind research conducted in regards to the ablation process and overall study of glaciers.\n\nLaser ablation is greatly affected by the nature of the material and its ability to absorb energy, therefore the wavelength of the ablation laser should have a minimum absorption depth. While these lasers can average a low power, they can offer peak intensity and fluence given by:\n\nwhile the peak power is\n\nSurface ablation of the cornea for several types of eye refractive surgery is now common, using an excimer laser system (LASIK and LASEK). Since the cornea does not grow back, laser is used to remodel the cornea refractive properties to correct refraction errors, such as astigmatism, myopia, and hyperopia. Laser ablation is also used to remove part of the uterine wall in women with menstruation and adenomyosis problems in a process called endometrial ablation.\n\nRecently, researchers have demonstrated a successful technique for ablating subsurface tumors with minimal thermal damage to surrounding healthy tissue, by using a focused laser beam from an ultra-short pulse diode laser source.\n\nAntifouling paints and other related coatings are routinely used to prevent the buildup of microorganisms and other animals, such as barnacles for the bottom hull surfaces of recreational, commercial and military sea vessels. Ablative paints are often utilized for this purpose to prevent the dilution or deactivation of the antifouling agent. Over time, the paint will slowly decompose in the water, exposing fresh antifouling compounds on the surface. Engineering the antifouling agents and the ablation rate can produce long-lived protection from the deleterious effects of biofouling.\n\nIn medicine, ablation is the same as removal of a part of biological tissue, usually by surgery. Surface ablation of the skin (dermabrasion, also called resurfacing because it induces regeneration) can be carried out by chemicals (chemoablation), by lasers (laser ablation), by freezing (cryoablation), or by electricity (fulguration). Its purpose is to remove skin spots, aged skin, wrinkles, thus rejuvenating it. Surface ablation is also employed in otolaryngology for several kinds of surgery, such as for snoring. Ablation therapy using radio frequency waves on the heart is used to cure a variety of cardiac arrhythmiae such as supraventricular tachycardia, Wolff–Parkinson–White syndrome (WPW), ventricular tachycardia, and more recently as management of atrial fibrillation. The term is often used in the context of laser ablation, a process in which a laser dissolves a material's molecular bonds. For a laser to ablate tissues, the power density or fluence must be high, otherwise thermocoagulation occurs, which is simply thermal vaporization of the tissues.\n\nRotoablation is a type of arterial cleansing that consists of inserting a tiny, diamond-tipped, drill-like device into the affected artery to remove fatty deposits or plaque. The procedure is used in the treatment of coronary heart disease to restore blood flow.\n\nRadiofrequency ablation (RFA) is a method of removing aberrant tissue from within the body via minimally invasive procedures.\n\nMicrowave ablation (MWA) is similar to RFA but at higher frequencies of electromagnetic radiation.\n\nBone marrow ablation is a process whereby the human bone marrow cells are eliminated in preparation for a bone marrow transplant. This is performed using high-intensity chemotherapy and total body irradiation. As such, it has nothing to do with the vaporization techniques described in the rest of this article.\n\nAblation of brain tissue is used for treating certain neurological disorders, particularly Parkinson's disease, and sometimes for psychiatric disorders as well.\n\nRecently, some researchers reported successful results with genetic ablation. In particular, genetic ablation is potentially a much more efficient method of removing unwanted cells, such as tumor cells, because large numbers of animals lacking specific cells could be generated. Genetically ablated lines can be maintained for a prolonged period of time and shared within the research community. Researchers at Columbia University report of reconstituted caspases combined from \"C. elegans\" and humans, which maintain a high degree of target specificity. The genetic ablation techniques described could prove useful in battling cancer.\n\nFirestopping and fireproofing products can be ablative in nature. This can mean endothermic materials, or merely materials that are sacrificial and become \"spent\" over time while exposed to fire, such as silicone firestop products.\nGiven sufficient time under fire or heat conditions, these products char away, crumble, and disappear. The idea is to put enough of this material in the way of the fire that a level of fire-resistance rating can be maintained, as demonstrated in a fire test. Ablative materials usually have a large concentration of organic matter that is reduced by fire to ashes. In the case of silicone, organic rubber surrounds very finely divided silica dust (up to 380 m² of combined surface area of all the dust particles per gram of this dust). When the organic rubber is exposed to fire, it burns to ash and leaves behind the silica dust with which the product started.\n\nIn spacecraft design, ablation is used to both cool and protect mechanical parts and/or payloads that would otherwise be damaged by extremely high temperatures. Two principal applications are heat shields for spacecraft entering a planetary atmosphere from space and cooling of rocket engine nozzles. Examples include the Apollo Command Module that protected astronauts from the heat of atmospheric reentry and the Kestrel second stage rocket engine designed for exclusive use in an environment of space vacuum since no heat convection is possible.\n\nIn a basic sense, ablative material is designed to slowly burn away in a controlled manner, so that heat can be carried away from the spacecraft by the gases generated by the ablative process while the remaining solid material insulates the craft from superheated gases. There is an entire branch of spaceflight research involving the search for new fireproofing materials to achieve the best ablative performance; this function is critical to protect the spacecraft occupants and payload from otherwise excessive heat loading. The same technology is used in some passive fire protection applications, in some cases by the same vendors, who offer different versions of these fireproofing products, some for aerospace and some for structural fire protection.\n\n\n"}
{"id": "4499573", "url": "https://en.wikipedia.org/wiki?curid=4499573", "title": "Adduct", "text": "Adduct\n\nAn adduct (from the Latin \"adductus\", \"drawn toward\" alternatively, a contraction of \"addition product\") is a product of a direct addition of two or more distinct molecules, resulting in a single reaction product containing all atoms of all components. The resultant is considered a distinct molecular species. Examples include the addition of sodium bisulfite to an aldehyde to give a sulfonate. It can just be considered as a single product resulting from direct addition of different molecules and constitutes all the reactant molecules' atoms.\n\nAdducts often form between Lewis acids and Lewis bases. A good example is the formation of adducts between the Lewis acid borane and the oxygen atom in the Lewis bases, tetrahydrofuran (THF): BH·O(CH) or diethyl ether: BH·O(CHCH).\nCompounds or mixtures that cannot form an adduct because of steric hindrance are called frustrated Lewis pairs.\n\nAdducts are not necessarily molecular in nature. A good example from solid-state chemistry is the adducts of ethylene or carbon monoxide of CuAlCl. The latter is a solid with an extended lattice structure. Upon formation of the adduct, a new extended phase is formed in which the gas molecules are incorporated (inserted) as ligands of the copper atoms within the structure. This reaction can also be considered a reaction between a base and a Lewis acid with the copper atom in the electron-receiving role and the pi electrons of the gas molecule in the electron-donating role.\n\nAn adduct ion is formed from a precursor ion and contains all of the constituent atoms of that ion as well as additional atoms or molecules. Adduct ions are often formed in a mass spectrometer ion source.\n\n"}
{"id": "30440813", "url": "https://en.wikipedia.org/wiki?curid=30440813", "title": "Airport Carbon Accreditation", "text": "Airport Carbon Accreditation\n\n\"Airport Carbon Accreditation\" is a global carbon management programme for airports that independently assesses and recognises airports’ efforts to manage and reduce their CO emissions. There are 4 different levels of accreditation: Mapping, Reduction, Optimisation and Neutrality;\n\nThe programme was launched by European airports' trade body ACI EUROPE at their Annual Congress in June 2009. It is independently administered by WSP, an international consultancy firm. The programme provides airports with a common framework for active carbon management with measurable goal-posts. Individual airport carbon footprints are independently verified in accordance with ISO 14064 (Greenhouse Gas Accounting) on the basis of supporting evidence. Claims regarding airports' carbon management processes are also independently verified by a group of 117 independent verifiers, based in 36 countries.\n\n• The 'Mapping' level of \"Airport Carbon Accreditation\" (Level 1) requires carbon footprint measurement.\n\n• The 'Reduction' level of \"Airport Carbon Accreditation\" (Level 2) requires carbon management and progress towards a reduced carbon footprint.\n\n• The 'Optimisation' level of \"Airport Carbon Accreditation\" (Level 3) requires third party engagement in carbon footprint reduction. Third parties include airlines and various service providers, for example, independent ground handlers, catering companies, air traffic control and others working on the airport site. It also involves engagement on surface access modes (road, rail) with authorities and users.\n\n• The 'Neutrality' level of \"Airport Carbon Accreditation\" (Level 3+) requires neutralising remaining direct carbon emissions by offsetting. The first airport to ever achieve carbon neutrality was the Stockholm-Arlanda Airport in Sweden.\n\nThe initiative is a direct consequence of the resolution on Climate Change adopted in June 2008 by the ACI EUROPE annual assembly, and has been endorsed by both the European Civil Aviation Conference and EUROCONTROL. The administration of \"Airport Carbon Accreditation\" is overseen by an independent Advisory Board, members of which include representatives of the United Nations Framework Convention for Climate Change (UNFCCC), United Nations Environment Programme (UNEP), European Civil Aviation Conference (ECAC), the European Commission, EUROCONTROL, Federal Aviation Administration (FAA) and Manchester Metropolitan University. On 30 November 2011 it was announced that the International Civil Aviation Organization (ICAO) was also formally supporting the programme, and taking a seat on the independent advisory board.\n\nIn addition to European Commission participation on the Advisory Board, the then European Commission Vice President responsible for Transport Siim Kallas has strongly supported the scheme, participating in the presentation of accreditation certificates at several European Airports, including Charles de Gaulle, Orly, Brussels and Budapest Airports. He has also stated that he believes the initiative \"is playing a crucial role in helping move European aviation onto a more sustainable footing\".\n\nThe programme has expanded beyond Europe on 30 November 2011, having been formally extended to the Asia-Pacific region at ACI Airport Exchange conference in Abu Dhabi, organised by ACI ASIA-PACIFIC. The first airport to become accredited within this region was Abu Dhabi International Airport which achieved 'Mapping' level. Since then, 38 airports from the region joined the community of accredited airports. \nThe programme was further extended with the African region of ACI joining the community in June 2013. The launch of \"Airport Carbon Accreditation\" in Africa was coupled with the official certification of the first African airport to the programme, Enfidha-Hammamet International Airport in Tunisia, which was certified at the 'Mapping' level. \nIn June 2014, at ACI EUROPE’s Annual Congress in Frankfurt the \"Airport Carbon Accreditation\" programme celebrated two important milestones in its story: its 5th anniversary together with crossing the threshold of 100 airports participating in the programme.\n\nShortly thereafter, in fall 2014, the programme became global, with its official launch in North America, followed by its introduction in the region of Latin America and the Caribbean. Having already achieved significant results in 5 continents, the launch of \"Airport Carbon Accreditation\" in this region, in partnership with ACI Latin America & the Caribbean, marked the decisive moment when the programme became the global standard for carbon management at airports.\n\nIn 2015, a new interactive website – www.airportco2.org – was launched at the end of Year 6 of \"Airport Carbon Accreditation\" – the year of the global expansion of the programme. This microsite was created to promote the programme in more accessible language and to communicate the annual results achieved by participating airports. It continues to present key figures from the programme, both globally and per region, in a more visual and engaging way.\n\nThe COP21 Conference in Paris in December 2015 was an important milestone for the \"Airport Carbon Accreditation\" programme. On the occasion of its presentation at the Conference, the European airport industry committed to increasing the number of carbon neutral airports to 50 by 2030. Following the announcement of this commitment, ACI EUROPE and the carbon standard \"Airport Carbon Accreditation\" signed a partnership with the United Nations Framework Convention on Climate Change (UNFCCC), at a special side event. The partnership agreement committed ACI to supporting the UNFCCC’s ‘Climate Neutral Now’ campaign, while the UNFCCC would support airport climate action at airports, with a particular focus on carbon management by airports through \"Airport Carbon Accreditation\". The organisations agreed also to develop a common work programme and communications plan promoting carbon neutrality at airports.\n\nIn June 2017, at ACI EUROPE's 27th Annual Congress, European airports made a new pledge, doubling the one made during COP21. They committed to 100 carbon neutral airports by 2030. Over 20 airport operator companies signed the new commitment, among which: Groupe ADP, AENA, Aeroporto di Bologna, Aeroport Brest Bretagne, Aeroports de la Côte d'Azur, Bristol Airport, Brussels Airport, Finavia, Heathrow Airport, London City Airport, Geneva Airport, Munich Airport, Aeroporto Internazionale di Napoli, Aeroport Quimper Bretagne, Schiphol Group and Zurich Airport.\n\nThe \"Airport Carbon Accreditation\" programme has gathered a number of notable climate-action awards. In 2013, the programme reached Top 3 in the World You Like competition, a contest in which businesses, NGOs and local authorities can participate by showcasing their climate-friendly solutions, run by the European Commission's Directorate-General for Climate Action. The \"Airport Carbon Accreditation\" programme was chosen out of 269 low carbon projects in Europe – and the only transport project in the Top 3. It was recognised as an efficient and innovative climate solution that is making a real difference in helping airports address their CO emissions. \nIn May 2014, the airport industry’s efforts to address its carbon emissions received the Highly Commended prize at the annual global International Transport Forum (ITF) Awards issued by the Organisation for Economic Cooperation and Development (OECD). The voluntary climate change initiative \"Airport Carbon Accreditation\" was named as one of two runners-up for the ITF’s Transport Achievement Award.\n\nOnly a month later, in June 2015, the animation “Life is about Movement”, created to highlight the essence of the programme, was awarded the Gold Totem prize in the “Businesses & Eco-Performances” category at the 4th Deauville Green Awards 2015.\n\nIn 2016, \"Airport Carbon Accreditation\" was featured in the first ever European Aviation Environmental Report, published by the European Commission, in very positive terms as one of the innovative initiatives of the airport industry to tackle environmental challenges.\n\nAs of 2017, 192 airports across the world are certified at one of the 4 levels of Airport Carbon Accreditation. These airports handle 2.7 billion passengers a year, 38.4% of global air passenger traffic. 35 airports are carbon neutral – the latest to reach this level was Helsinki Airport. There are now 28 carbon neutral airports in Europe, 5 in Asia, 1 in North America and 1 in Africa.\n\nIn Europe, there are now 116 airports participating in the programme, 51 of which are at the top 2 levels of the programme. Helsinki Airport was the latest airports to reach carbon neutrality in the region. The other recent movers within the programme are Düsseldorf and Naples airports – each of which successfully make the jump from Level 2 Reduction, to Level 3 Optimisation. Madeira, Marseille and Porto Santo airports have moved up to Level 2 Reduction while Switzerland’s Bern Airport became the latest newcomer in Europe, entering the programme at Level 1 Mapping.\n\nThere are now 38 airports certified in Asia-Pacific with recent entrants including Gold Coast Airport and Hobart International (both in Australia) as well as Muscat International Airport and Nadi International Airport (Fiji) – which have all started their journey to active carbon management, becoming accredited at Level 1 Mapping. Mumbai International Airport and Bangalore International Airport are the latest airports to become carbon neutral in the region.\n\nRecent months have seen several new airports come on board, nearly doubling the participation on the African continent. Cape Town International, King Shaka International (Durban), Port Elizabeth International and O.R. Tambo International (Johannesburg) – 4 airports in South Africa have all successfully entered the programme at Level 1 Mapping. This brings the total number of African airports in the programme up to 9.\n\nAnother key development was the successful upgrade of Felix Houphouet Boigny International Airport (Abidjan) to Level 3+ Carbon Neutrality. This is the first African airport to ever scale this high in the Airport Carbon Accreditation scheme.\n\nIt’s been two and a half years since the programme was launched in North America, and 23 airports have become certified in this region. The latest entry was made by Van Nuys Airport. In all, the 23 certified airports in the North America region currently account for 32.6% of air passenger traffic in North America.\n\nThere are currently 6 certified airports in the region of Latin American and Caribbean. The latest entrants are Guayaquil Airport in Ecuador and El Dorado Airport in Columbia. 4 of them at Level 1 Mapping, and the other 2 actively reducing their emissions, certified at Level 2 Reduction.\n\nAirport emissions have been reduced by 55,633 tonnes of CO in Year 1 of the programme and 55,501 tonnes in Year 2, and 77,782 tonnes in Year 3 as a result. Year 4 of the programme had a CO reduction of 110,003 tonnes - enough to power 45,949 households for a year.\n\nIf 31,894 cars were removed from the roads for one year, it would enable a reduction close to the one achieved by \"Airport Carbon Accreditation\"’s participants in Year 5.\n\nFrom July 2014 to June 2015, the programme has allowed a reduction comparable to the annual CO sequestered by 1,496 acres of forest. We could have powered almost twice as many households as compared to the year 4 result in the sixth consecutive year of the programme. Following years are bound to beat these figures, with a number of accredited airports at high levels rising.\n\n"}
{"id": "166017", "url": "https://en.wikipedia.org/wiki?curid=166017", "title": "Avocado", "text": "Avocado\n\nThe avocado (\"Persea americana\") is a tree, long thought to have originated in South Central Mexico, classified as a member of the flowering plant family Lauraceae. The fruit of the plant, also called an avocado (or avocado pear or alligator pear), is botanically a large berry containing a single large seed.\n\nAvocados are commercially valuable and are cultivated in tropical and Mediterranean climates throughout the world. They have a green-skinned, fleshy body that may be pear-shaped, egg-shaped, or spherical. Commercially, they ripen after harvesting. Avocado trees are partially self-pollinating and are often propagated through grafting to maintain a predictable quality and quantity of the fruit.\n\n\"Persea americana\", or the avocado, possibly originated in the Tehuacan Valley in the state of Puebla, Mexico, although fossil evidence suggests similar species were much more widespread millions of years ago. However, there is evidence for three possible separate domestications of the avocado, resulting in the currently recognized Mexican (\"aoacatl\"), Guatemalan (\"quilaoacatl\"), and West Indian (\"tlacacolaocatl\") landraces. The Mexican and Guatemalan landraces originated in the highlands of those countries, while the West Indian landrace is a lowland variety that ranges from Guatemala, Costa Rica, Colombia, Ecuador to Peru, achieving a wide range through human agency before the arrival of the Europeans. The three separate landraces were most likely to have already intermingled in pre-Columbian America and were described in the Florentine Codex.\n\nThe earliest residents were living in temporary camps in an ancient wetland eating avocados, chilies, mollusks, sharks, birds, and sea lions. The oldest discovery of an avocado pit comes from Coxcatlan Cave, dating from around 9,000 to 10,000 years ago. Other caves in the Tehuacan Valley from around the same time period also show early evidence for the presence of avocado. There is evidence for avocado use at Norte Chico civilization sites in Peru by at least 3,200 years ago and at Caballo Muerto in Peru from around 3,800 to 4,500 years ago.\nThe native, undomesticated variety is known as a \"criollo\", and is small, with dark black skin, and contains a large seed. It probably coevolved with extinct megafauna. The avocado tree also has a long history of cultivation in Central and South America, likely beginning as early as 5,000 BC. A water jar shaped like an avocado, dating to AD 900, was discovered in the pre-Incan city of Chan Chan.\n\nThe earliest known written account of the avocado in Europe is that of Martín Fernández de Enciso (\"circa\" 1470–1528) in 1519 in his book, \"Suma De Geographia Que Trata De Todas Las Partidas Y Provincias Del Mundo.\" The first detailed account that unequivocally describes the avocado was given by Gonzalo Fernández de Oviedo y Valdés in his work in 1526. The first written record in English of the use of the word 'avocado' was by Hans Sloane, who coined the term in 1669, in a 1696 index of Jamaican plants. The plant was introduced to Spain in 1601, Indonesia around 1750, Mauritius in 1780, Brazil in 1809, the United States mainland in 1825, South Africa and Australia in the late 19th century, and Israel in 1908. In the United States, the avocado was introduced to Florida and Hawaii in 1833 and in California in 1856.\n\nBefore 1915, the avocado was commonly referred to in California as \"ahuacate\" and in Florida as \"alligator pear\". In 1915, the California Avocado Association introduced the then-innovative term \"avocado\" to refer to the plant.\n\nThe word \"avocado\" comes from the Spanish \"aguacate\", which in turn comes from the Nahuatl word \"āhuacatl\" , which goes back to the proto-Aztecan \"*pa:wa\" which also meant \"avocado\". Sometimes the Nahuatl word was used with the meaning \"testicle\", probably because of the likeness between the fruit and the body part.\n\nThe modern English name comes from an English rendering of the Spanish \"aguacate\" as \"avogato\". The earliest known written use in English is attested from 1697 as \"avogato pear\", a term which was later corrupted as \"alligator pear\". Because the word \"avogato\" sounded like \"advocate\", several languages reinterpreted it to have that meaning. French uses \"avocat\", which also means \"lawyer\", and \"advocate\"-forms of the word appear in several Germanic languages, such as the (now obsolete) German \"Advogato-Birne\", the old Danish \"advokat-pære\" (today it is called \"avocado\") and the Dutch \"advocaatpeer\".\n\nIn other Central American and Caribbean Spanish-speaking countries, it is known by the Mexican name, while South American Spanish-speaking countries use a Quechua-derived word, \"palta\". In Portuguese, it is \"abacate\". The fruit is sometimes called an avocado pear or alligator pear (due to its shape and the rough green skin of some cultivars). The Nahuatl \"ahuacatl\" can be compounded with other words, as in \"ahuacamolli\", meaning avocado soup or sauce, from which the Spanish word \"guacamole\" derives.\n\nIn the United Kingdom, the term \"avocado pear\" is still sometimes misused as applied when avocados first became commonly available in the 1960s.\n\nOriginating as a diminutive in Australian English, a clipped form, \"avo\", has since become a common colloquialism in South Africa and the United Kingdom.\n\nIt is known as \"butter fruit\" in parts of India and goes by the name \"bơ\" [ɓɘː] in Vietnamese, which is the same word that is used for butter. In eastern China, it is known as \"è lí\" (\"alligator pear\") or \"niú yóu guǒ\" (\"butter fruit\"). In Taiwan, it is known as \"luò lí\" or \"cheese pear\".\n\nThe tree grows to , with alternately arranged leaves long. The flowers are inconspicuous, greenish-yellow, wide. The pear-shaped fruit is long, weighs between , and has a large central seed, long.\n\nBotanically, the avocado fruit is a single-seeded berry, due to the imperceptible endocarp covering the seed, rather than a drupe.\n\nThe subtropical species needs a climate without frost and with little wind. High winds reduce the humidity, dehydrate the flowers, and affect pollination. When even a mild frost occurs, premature fruit drop may occur, although the 'Hass' cultivar can tolerate temperatures down to −1 °C. Several cold-hardy varieties are planted in the region of Gainesville, Florida, which survive temperatures as low as with only minor leaf damage. The trees also need well-aerated soils, ideally more than 1 m deep. Yield is reduced when the irrigation water is highly saline. These soil and climate conditions are available in southern and eastern Spain, Morocco, the Levant, South Africa, Venezuela, Colombia, Peru, parts of central and northern Chile, Vietnam, Indonesia, parts of southern India, Sri Lanka, Australia, New Zealand, the Philippines, Malaysia, Central America, the Caribbean, Mexico, southern California, Arizona, Puerto Rico, Texas, Florida, Hawaii, Ecuador, and Rwanda. Each region has different cultivars.\n\nCommercial orchards produce an average of seven tonnes per hectare each year, with some orchards achieving 20 tonnes per hectare. Biennial bearing can be a problem, with heavy crops in one year being followed by poor yields the next.\n\nLike the banana, the avocado is a climacteric fruit, which matures on the tree, but ripens off the tree. Avocados used in commerce are picked hard and green and kept in coolers at until they reach their final destination. Avocados must be mature to ripen properly. Avocados that fall off the tree ripen on the ground. Generally, the fruit is picked once it reaches maturity; Mexican growers pick 'Hass' avocados when they have more than 23% dry matter, and other producing countries have similar standards. Once picked, avocados ripen in one to two weeks (depending on the cultivar) at room temperature (faster if stored with other fruits such as apples or bananas, because of the influence of ethylene gas). Some supermarkets sell ripened avocados which have been treated with synthetic ethylene to hasten ripening. The use of an ethylene gas \"ripening room\", which is now an industry standard, was pioneered in the 1980s by farmer Gil Henry of Escondido, California, in response to footage from a hidden supermarket camera which showed shoppers repeatedly squeezing hard, unripe avocados, putting them \"back in the bin,\" and moving on without making a purchase. In some cases, avocados can be left on the tree for several months, which is an advantage to commercial growers who seek the greatest return for their crop, but if the fruit remains unpicked for too long, it falls to the ground.\n\nThe species is only partially able to self-pollinate because of dichogamy in its flowering. This limitation, added to the long juvenile period, makes the species difficult to breed. Most cultivars are propagated by grafting, having originated from random seedling plants or minor mutations derived from cultivars. Modern breeding programs tend to use isolation plots where the chances of cross-pollination are reduced. That is the case for programs at the University of California, Riverside, as well as the Volcani Centre and the Instituto de Investigaciones Agropecuarias in Chile.\n\nThe avocado is unusual in that the timing of the male and female flower phases differs among cultivars. The two flowering types are A and B. A-cultivar flowers open as female on the morning of the first day and close in late morning or early afternoon. Then they open as male in the afternoon of the second day. B varieties open as female on the afternoon of the first day, close in late afternoon and reopen as male the following morning.\n\nCertain cultivars, such as the 'Hass', have a tendency to bear well only in alternate years. After a season with a low yield, due to factors such as cold (which the avocado does not tolerate well), the trees tend to produce abundantly the next season. In addition, due to environmental circumstances during some years, seedless avocados may appear on the trees. Known in the avocado industry as \"cukes\", they are usually discarded commercially due to their small size.\n\nAvocados can be propagated by seed, taking roughly four to six years to bear fruit, although in some cases seedlings can take 10 years to come into bearing. The offspring is unlikely to be identical to the parent cultivar in fruit quality. Prime quality varieties are therefore propagated by grafting to rootstocks that are propagated by seed (seedling rootstocks) or by layering (clonal rootstocks). After about a year of growing in a greenhouse, the young rootstocks are ready to be grafted. Terminal and lateral grafting is normally used. The scion cultivar grows for another 6–12 months before the tree is ready to be sold. Clonal rootstocks are selected for tolerance of specific soil and disease conditions, such as poor soil aeration or resistance to the soil-borne disease (root rot) caused by \"Phytophthora\".\n\nCommercial avocado production is limited to a small fraction of the vast genetic diversity in the species. Conservation of this genetic diversity has relied largely on field collection, as avocado seeds often do not survive storage in seed banks. This is problematic, as field preservation of living cultivars is expensive, and habitat loss threatens wild cultivars. More recently, an alternate method of conservation has been developed based on cryopreservation of avocado somatic embryos with reliable methods for somatic embryogenesis and reconstitution into living trees.\n\nIndoors, an avocado tree is usually grown from the pit of an avocado fruit. This is often done by removing the pit from a ripe, unrefrigerated avocado fruit. The pit is then stabbed with three or four toothpicks, about one-third of the way up from the flat end. The pit is placed in a jar or vase containing tepid water. It should split in four to six weeks and yield roots and a sprout. If there is no change by this time, the avocado pit is discarded. Once the stem has grown a few inches, it is placed in a pot with soil. It should be watered every few days. Avocados have been known to grow large, so owners must be ready to re-pot the plant several times.\n\nAvocado trees are vulnerable to bacterial, viral, fungal, and nutritional diseases (excesses and deficiencies of key minerals). Disease can affect all parts of the plant, causing spotting, rotting, cankers, pitting, and discoloration.\n\nMexico is by far the world's largest avocado growing country, producing several times more than the second largest producer. In 2013, the total area dedicated to avocado production was 168,155 hectares (415,520 acres), and the harvest was 1.47 million tonnes. The states that produce the most are México, Morelos, Nayarit, Puebla, and Michoacan, accounting for 86% of the total. In Michoacán, the cultivation is complicated by the existence of drug cartels that extort protection fees from cultivators. They are reported to exact 2000 Mexican pesos per hectare from avocado farmers and 1 to 3 pesos/kg of harvested fruit.\n\nThe avocado was introduced from Mexico to California in the 19th century, and has become a successful cash crop. About – some 95% of United States avocado production – is located in Southern California, with 60% in San Diego County. Fallbrook, California, claims the title of \"Avocado Capital of the World\" (also claimed by the town of Uruapan in Mexico), and both Fallbrook and Carpinteria, California, host annual avocado festivals. Avocado is the official fruit of the State of California.\n\nHass avocado production in Peru encompasses thousands of hectares in central and western Peru. Peru has now become the largest supplier of avocados imported to the European Union and, more recently, has begun to export avocados in significant quantities to North America.\n\nPeru's location near the equator and along the Pacific Ocean creates consistently mild temperatures year round. The soil is rich and sandy and the towering Andes mountains provide a constant flow of pure water for irrigation. Naturally sheltered as it is from heavy rain or freezing temperatures, Peru is an almost perfect climate for the cultivation of avocados.\n\nHass avocados from Peru are seasonally available to consumers from May through September and are promoted under the auspices of the Peruvian Avocado Commission, headquartered in Washington, D.C.\n\n\n\n\n\nOther avocado cultivars include 'Spinks'. Historically attested varieties (which may or may not survive among horticulturists) include the 'Challenge', 'Dickinson', 'Kist', 'Queen', 'Rey', 'Royal', 'Sharpless', and 'Taft'.\n\nA stoneless avocado, marketed as a \"cocktail avocado,\" which does not contain a pit, is available on a limited basis. They are five to eight centimetres long; the whole fruit may be eaten, including the skin. It is produced from an unpollinated blossom in which the seed does not develop. Seedless avocados regularly appear on trees. Known in the avocado industry as \"cukes\", they are usually discarded commercially due to their small size.\n\nIn 2016, world production of avocados was 5.6 million tonnes, led by Mexico alone with 34% (1.89 million tonnes) of the total (table). Other major producers were Dominican Republic, Peru, Colombia, and Indonesia, together producing 30% of the world total (table).\n\nAfter the North American Free Trade Agreement (NAFTA) went into effect in 1994, Mexico tried exporting avocados to the US. The US government resisted, claiming the trade would introduce Tephritidae fruit flies that would destroy California's crops. The Mexican government responded by inviting USDA inspectors to Mexico, but the US government declined, claiming fruit fly inspection was not feasible. The Mexican government then proposed to sell avocados only to the northeastern US in the winter (fruit flies cannot withstand extreme cold). The US government balked, but gave in when the Mexican government started erecting barriers to US corn.\n\nImports from Mexico in the 2005–2006 season exceeded .\n\nIn 2009, Peru joined Chile and Mexico as an exporter of avocados to the US.\n\nIn the US, avocados are grown in California and Florida, where land, labor, and water are expensive. Avocado trees require frequent, deep watering to bear optimally, particularly in spring, summer, and fall. Due to increased Southern California water costs, they are now costly to grow. California produces 90% of the United States' avocados.\n\nAs of 2013, Mexico leads international exports, with other significant production in California, New Zealand, Peru, and South Africa.\n\nThe fruit of horticultural cultivars has a markedly higher fat content than most other fruit, mostly monounsaturated fat, and as such serves as an important staple in the diet of consumers who have limited access to other fatty foods (high-fat meats and fish, dairy products). Having a high smoke point, avocado oil is expensive compared to common salad and cooking oils, and mostly used for salads or dips.\n\nA ripe avocado yields to gentle pressure when held in the palm of the hand and squeezed. The flesh is prone to enzymatic browning, quickly turning brown after exposure to air. To prevent this, lime or lemon juice can be added to avocados after peeling.\n\nThe fruit is not sweet, but distinctly and subtly flavored, with smooth texture. It is used in both savory and sweet dishes, though in many countries not for both. The avocado is popular in vegetarian cuisine as a substitute for meats in sandwiches and salads because of its high fat content.\n\nGenerally, avocado is served raw, though some cultivars, including the common 'Hass', can be cooked for a short time without becoming bitter. The flesh of some avocados may be rendered inedible by heat. Prolonged cooking induces this chemical reaction in all cultivars.\n\nIt is used as the base for the Mexican dip known as guacamole, as well as a spread on corn tortillas or toast, served with spices.\n\nIn the Philippines, Brazil, Indonesia, Vietnam, and southern India (especially the coastal Kerala, Tamil Nadu and Karnataka region), avocados are frequently used for milkshakes and occasionally added to ice cream and other desserts. In Brazil, Vietnam, the Philippines and Indonesia, a dessert drink is made with sugar, milk or water, and pureed avocado. Chocolate syrup is sometimes added. In Morocco, a similar chilled avocado and milk drink is sweetened with confectioner's sugar and flavored with a touch of orange flower water.\n\nIn Ethiopia, avocados are made into juice by mixing them with sugar and milk or water, usually served with Vimto and a slice of lemon. It is also common to serve layered multiple fruit juices in a glass (locally called \"Spris\") made of avocados, mangoes, bananas, guavas, and papayas. Avocados are also used to make salads.\n\nAvocados in savory dishes, often seen as exotic, are a relative novelty in Portuguese-speaking countries, such as Brazil, where the traditional preparation is mashed with sugar and lime, and eaten as a dessert or snack. This contrasts with Spanish-speaking countries such as Chile, Mexico, or Argentina, where the opposite is true and sweet preparations are rare.\n\nIn Australia and New Zealand, it is commonly served in sandwiches, sushi, on toast, or with chicken. In Ghana, it is often eaten alone in sliced bread as a sandwich. In Sri Lanka, well-ripened flesh, thoroughly mashed with sugar and milk, or treacle (a syrup made from the nectar of a particular palm flower) is a popular dessert. In Haiti, it is often consumed with cassava or regular bread for breakfast.\n\nIn Mexico and Central America, avocados are served mixed with white rice, in soups, salads, or on the side of chicken and meat. In Peru, they are consumed with \"tequeños\" as mayonnaise, served as a side dish with \"parrillas\", used in salads and sandwiches, or as a whole dish when filled with tuna, shrimp, or chicken. In Chile, it is used as a puree-like sauce with chicken, hamburgers, and hot dogs; and in slices for celery or lettuce salads. The Chilean version of Caesar salad contains large slices of mature avocado. In Kenya and Nigeria, the avocado is often eaten as a fruit eaten alone or mixed with other fruits in a fruit salad, or as part of a vegetable salad.\n\nAvocado is a primary ingredient in avocado soup. Avocado slices are frequently added to hamburgers, \"tortas\", hot dogs, and \"carne asada\". Avocado can be combined with eggs (in scrambled eggs, tortillas, or omelettes), and is a key ingredient in California rolls and other \"makizushi\" (\"maki\", or rolled sushi).\n\nIn the United Kingdom, the avocado became available during the 1960s when introduced by Sainsbury's under the name 'avocado pear'.\n\nIn addition to the fruit, the leaves of Mexican avocados (\"Persea americana\" var. \"drymifolia\") are used in some cuisines as a spice, with a flavor somewhat reminiscent of anise. They are sold both dried and fresh, toasted before use, and either crumbled or used whole, commonly in bean dishes. Leaves of \"P. americana\", Guatemalan variety, are toxic to goats, sheep, and horses.\n\nA typical serving of avocado (100 g) is moderate to rich in several B vitamins and vitamin K, with good content of vitamin C, vitamin E and potassium (right table, USDA nutrient data). Avocados also contain phytosterols and carotenoids, such as lutein and zeaxanthin.\n\nAvocados have diverse fats. For a typical avocado:\n\nAlthough costly to produce, nutrient-rich avocado oil has diverse uses for salads or cooking and in cosmetics and soap products.\n\nThe avocado tree can be grown domestically and used as a (decorative) houseplant. The pit germinates in normal soil conditions or partially submerged in a small glass (or container) of water. In the latter method, the pit sprouts in four to six weeks, at which time it is planted in standard houseplant potting soil. The plant normally grows large enough to be prunable; it does not bear fruit unless it has ample sunlight. Home gardeners can graft a branch from a fruit-bearing plant to speed maturity, which typically takes four to six years to bear fruit.\n\nSome people have allergic reactions to avocado. There are two main forms of allergy: those with a tree-pollen allergy develop local symptoms in the mouth and throat shortly after eating avocado; the second, known as latex-fruit syndrome, is related to latex allergy and symptoms include generalised urticaria, abdominal pain, and vomiting and can sometimes be life-threatening.\n\nAvocado leaves, bark, skin, or pit are documented to be harmful to animals; cats, dogs, cattle, goats, rabbits, rats, guinea pigs, birds, fish, and horses can be severely harmed or even killed when they consume them. The avocado fruit is poisonous to some birds, and the American Society for the Prevention of Cruelty to Animals (ASPCA) lists it as toxic to horses.\n\nAvocado leaves contain a toxic fatty acid derivative, persin, which in sufficient quantity can cause colic in horses and without veterinary treatment, death. The symptoms include gastrointestinal irritation, vomiting, diarrhea, respiratory distress, congestion, fluid accumulation around the tissues of the heart, and even death. Birds also seem to be particularly sensitive to this toxic compound. A line of premium dog and cat food, AvoDerm, uses oils and meal made from avocado meat as main ingredients. The manufacturer says the avocado's leaves and pit are the source of toxicity, and only in the Guatemalan variety of avocados, and the fruit is often eaten by orchard dogs as well as wildlife such as bears and coyotes.\n\nIn 1982, evolutionary biologist Daniel H. Janzen concluded that the avocado is an example of an 'evolutionary anachronism', a fruit adapted for ecological relationship with now-extinct large mammals (such as giant ground sloths or gomphotheres). Most large fleshy fruits serve the function of seed dispersal, accomplished by their consumption by large animals. There are some reasons to think that the fruit, with its mildly toxic pit, may have coevolved with Pleistocene megafauna to be swallowed whole and excreted in their dung, ready to sprout. No extant native animal is large enough to effectively disperse avocado seeds in this fashion.\n\n"}
{"id": "38940", "url": "https://en.wikipedia.org/wiki?curid=38940", "title": "Banana", "text": "Banana\n\nA banana is an edible fruit – botanically a berry – produced by several kinds of large herbaceous flowering plants in the genus \"Musa\". In some countries, bananas used for cooking may be called \"plantains\", distinguishing them from dessert bananas. The fruit is variable in size, color, and firmness, but is usually elongated and curved, with soft flesh rich in starch covered with a rind, which may be green, yellow, red, purple, or brown when ripe. The fruits grow in clusters hanging from the top of the plant. Almost all modern edible seedless (parthenocarp) bananas come from two wild species – \"Musa acuminata\" and \"Musa balbisiana\". The scientific names of most cultivated bananas are \"Musa acuminata\", \"Musa balbisiana\", and \"Musa\" × \"paradisiaca\" for the hybrid \"Musa acuminata\" × \"M. balbisiana\", depending on their genomic constitution. The old scientific name \"Musa sapientum\" is no longer used.\n\n\"Musa\" species are native to tropical Indomalaya and Australia, and are likely to have been first domesticated in Papua New Guinea. They are grown in 135 countries, primarily for their fruit, and to a lesser extent to make fiber, banana wine, and banana beer and as ornamental plants. The world's largest producers of bananas in 2016 were India and China, which together accounted for 28% of total production.\n\nWorldwide, there is no sharp distinction between \"bananas\" and \"plantains\". Especially in the Americas and Europe, \"banana\" usually refers to soft, sweet, dessert bananas, particularly those of the Cavendish group, which are the main exports from banana-growing countries. By contrast, \"Musa\" cultivars with firmer, starchier fruit are called \"plantains\". In other regions, such as Southeast Asia, many more kinds of banana are grown and eaten, so the binary distinction is not useful and is not made in local languages.\n\nThe term \"banana\" is also used as the common name for the plants that produce the fruit. This can extend to other members of the genus \"Musa\", such as the scarlet banana (\"Musa coccinea\"), the pink banana (\"Musa velutina\"), and the Fe'i bananas. It can also refer to members of the genus \"Ensete\", such as the snow banana (\"Ensete glaucum\") and the economically important false banana (\"Ensete ventricosum\"). Both genera are in the banana family, Musaceae.\n\nThe banana plant is the largest herbaceous flowering plant. All the above-ground parts of a banana plant grow from a structure usually called a \"corm\". Plants are normally tall and fairly sturdy, and are often mistaken for trees, but what appears to be a trunk is actually a \"false stem\" or pseudostem. Bananas grow in a wide variety of soils, as long as the soil is at least 60 cm deep, has good drainage and is not compacted. The leaves of banana plants are composed of a \"stalk\" (petiole) and a blade (lamina). The base of the petiole widens to form a sheath; the tightly packed sheaths make up the pseudostem, which is all that supports the plant. The edges of the sheath meet when it is first produced, making it tubular. As new growth occurs in the centre of the pseudostem the edges are forced apart. Cultivated banana plants vary in height depending on the variety and growing conditions. Most are around tall, with a range from 'Dwarf Cavendish' plants at around to 'Gros Michel' at or more. Leaves are spirally arranged and may grow long and wide. They are easily torn by the wind, resulting in the familiar frond look.\n\nWhen a banana plant is mature, the corm stops producing new leaves and begins to form a flower spike or inflorescence. A stem develops which grows up inside the pseudostem, carrying the immature inflorescence until eventually it emerges at the top. Each pseudostem normally produces a single inflorescence, also known as the \"banana heart\". (More are sometimes produced; an exceptional plant in the Philippines produced five.) After fruiting, the pseudostem dies, but offshoots will normally have developed from the base, so that the plant as a whole is perennial. In the plantation system of cultivation, only one of the offshoots will be allowed to develop in order to maintain spacing. The inflorescence contains many bracts (sometimes incorrectly referred to as petals) between rows of flowers. The female flowers (which can develop into fruit) appear in rows further up the stem (closer to the leaves) from the rows of male flowers. The ovary is inferior, meaning that the tiny petals and other flower parts appear at the tip of the ovary.\n\nThe banana fruits develop from the banana heart, in a large hanging cluster, made up of tiers (called \"hands\"), with up to 20 fruit to a tier. The hanging cluster is known as a bunch, comprising 3–20 tiers, or commercially as a \"banana stem\", and can weigh . Individual banana fruits (commonly known as a banana or \"finger\") average , of which approximately 75% is water and 25% dry matter (nutrient table, lower right).\n\nThe fruit has been described as a \"leathery berry\". There is a protective outer layer (a peel or skin) with numerous long, thin strings (the phloem bundles), which run lengthwise between the skin and the edible inner portion. The inner part of the common yellow dessert variety can be split lengthwise into three sections that correspond to the inner portions of the three carpels by manually deforming the unopened fruit. In cultivated varieties, the seeds are diminished nearly to non-existence; their remnants are tiny black specks in the interior of the fruit.\n\nBananas are naturally slightly radioactive, more so than most other fruits, because of their potassium content and the small amounts of the isotope potassium-40 found in naturally occurring potassium. The banana equivalent dose of radiation is sometimes used in nuclear communication to compare radiation levels and exposures.\n\nThe word banana is thought to be of West African origin, possibly from the Wolof word \"banaana\", and passed into English via Spanish or Portuguese.\n\nThe genus \"Musa\" was created by Carl Linnaeus in 1753. The name may be derived from Antonius Musa, physician to the Emperor Augustus, or Linnaeus may have adapted the Arabic word for banana, \"mauz\". The old biological name \"Musa sapientum\" = \"Muse of the wise\" arose because of homophony in Latin with the classical Muses.\n\n\"Musa\" is in the family Musaceae. The APG III system assigns Musaceae to the order Zingiberales, part of the commelinid clade of the monocotyledonous flowering plants. Some 70 species of \"Musa\" were recognized by the World Checklist of Selected Plant Families ; several produce edible fruit, while others are cultivated as ornamentals.\n\nThe classification of cultivated bananas has long been a problematic issue for taxonomists. Linnaeus originally placed bananas into two species based only on their uses as food: \"Musa sapientum\" for dessert bananas and \"Musa paradisiaca\" for plantains. More species names were added, but this approach proved to be inadequate for the number of cultivars in the primary center of diversity of the genus, Southeast Asia. Many of these cultivars were given names that were later discovered to be synonyms.\n\nIn a series of papers published from 1947 onwards, Ernest Cheesman showed that Linnaeus's \"Musa sapientum\" and \"Musa paradisiaca\" were cultivars and descendants of two wild seed-producing species, \"Musa acuminata\" and \"Musa balbisiana\", both first described by Luigi Aloysius Colla. Cheesman recommended the abolition of Linnaeus's species in favor of reclassifying bananas according to three morphologically distinct groups of cultivars – those primarily exhibiting the botanical characteristics of \"Musa balbisiana\", those primarily exhibiting the botanical characteristics of \"Musa acuminata\", and those with characteristics of both. Researchers Norman Simmonds and Ken Shepherd proposed a genome-based nomenclature system in 1955. This system eliminated almost all the difficulties and inconsistencies of the earlier classification of bananas based on assigning scientific names to cultivated varieties. Despite this, the original names are still recognized by some authorities today, leading to confusion.\n\nThe accepted scientific names for most groups of cultivated bananas are Musa acuminata and Musa balbisiana for the ancestral species, and Musa\" × \"paradisiaca for the hybrid \"M. acuminata\" × \"M. balbisiana\".\n\nSynonyms of \"M.\" × \"paradisica\" include\n\nGenerally, modern classifications of banana cultivars follow Simmonds and Shepherd's system. Cultivars are placed in groups based on the number of chromosomes they have and which species they are derived from. Thus the Latundan banana is placed in the AAB Group, showing that it is a triploid derived from both \"M. acuminata\" (A) and \"M. balbisiana\" (B). For a list of the cultivars classified under this system, \"see\" \"List of banana cultivars\".\n\nIn 2012, a team of scientists announced they had achieved a draft sequence of the genome of \"Musa acuminata\".\n\nIn regions such as North America and Europe, \"Musa\" fruits offered for sale can be divided into \"bananas\" and \"plantains\", based on their intended use as food. Thus the banana producer and distributor Chiquita produces publicity material for the American market which says that \"a plantain is not a banana\". The stated differences are that plantains are more starchy and less sweet; they are eaten cooked rather than raw; they have thicker skin, which may be green, yellow or black; and they can be used at any stage of ripeness. Linnaeus made the same distinction between plantains and bananas when first naming two \"species\" of \"Musa\". Members of the \"plantain subgroup\" of banana cultivars, most important as food in West Africa and Latin America, correspond to the Chiquita description, having long pointed fruit. They are described by Ploetz et al. as \"true\" plantains, distinct from other cooking bananas. The cooking bananas of East Africa belong to a different group, the East African Highland bananas, so would not qualify as \"true\" plantains on this definition.\n\nAn alternative approach divides bananas into dessert bananas and cooking bananas, with plantains being one of the subgroups of cooking bananas. Triploid cultivars derived solely from \"M. acuminata\" are examples of \"dessert bananas\", whereas triploid cultivars derived from the hybrid between \"M. acuminata\" and \"M. balbinosa\" (in particular the plantain subgroup of the AAB Group) are \"plantains\". Small farmers in Colombia grow a much wider range of cultivars than large commercial plantations. A study of these cultivars showed that they could be placed into at least three groups based on their characteristics: dessert bananas, non-plantain cooking bananas, and plantains, although there were overlaps between dessert and cooking bananas.\n\nIn Southeast Asia – the center of diversity for bananas, both wild and cultivated – the distinction between \"bananas\" and \"plantains\" does not work, according to Valmayor et al. Many bananas are used both raw and cooked. There are starchy cooking bananas which are smaller than those eaten raw. The range of colors, sizes and shapes is far wider than in those grown or sold in Africa, Europe or the Americas. Southeast Asian languages do not make the distinction between \"bananas\" and \"plantains\" that is made in English (and Spanish). Thus both Cavendish cultivars, the classic yellow dessert bananas, and Saba cultivars, used mainly for cooking, are called \"pisang\" in Malaysia and Indonesia, \"kluai\" in Thailand and \"chuoi\" in Vietnam. Fe'i bananas, grown and eaten in the islands of the Pacific, are derived from entirely different wild species than traditional bananas and plantains. Most Fe'i bananas are cooked, but Karat bananas, which are short and squat with bright red skins, very different from the usual yellow dessert bananas, are eaten raw.\n\nIn summary, in commerce in Europe and the Americas (although not in small-scale cultivation), it is possible to distinguish between \"bananas\", which are eaten raw, and \"plantains\", which are cooked. In other regions of the world, particularly India, Southeast Asia and the islands of the Pacific, there are many more kinds of banana and the two-fold distinction is not useful and not made in local languages. Plantains are one of many kinds of cooking bananas, which are not always distinct from dessert bananas.\n\nFarmers in Southeast Asia and Papua New Guinea first domesticated bananas. Recent archaeological and palaeoenvironmental evidence at Kuk Swamp in the Western Highlands Province of Papua New Guinea suggests that banana cultivation there goes back to at least 5000 BCE, and possibly to 8000 BCE. It is likely that other species were later and independently domesticated elsewhere in Southeast Asia. Southeast Asia is the region of primary diversity of the banana. Areas of secondary diversity are found in Africa, indicating a long history of banana cultivation in the region.\nPhytolith discoveries in Cameroon dating to the first millennium BCE triggered an as yet unresolved debate about the date of first cultivation in Africa. There is linguistic evidence that bananas were known in Madagascar around that time. The earliest prior evidence indicates that cultivation dates to no earlier than late 6th century CE. It is likely, however, that bananas were brought at least to Madagascar if not to the East African coast during the phase of Malagasy colonization of the island from South East Asia c. 400 CE.\n\nThe banana may also have been present in isolated locations elsewhere in the Middle East on the eve of Islam. The spread of Islam was followed by far-reaching diffusion. There are numerous references to it in Islamic texts (such as poems and hadiths) beginning in the 9th century. By the 10th century the banana appears in texts from Palestine and Egypt. From there it diffused into North Africa and Muslim Iberia. During the medieval ages, bananas from Granada were considered among the best in the Arab world. In 650, Islamic conquerors brought the banana to Palestine. Today, banana consumption increases significantly in Islamic countries during Ramadan, the month of daylight fasting.\n\nBananas were certainly grown in the Christian Kingdom of Cyprus by the late medieval period. Writing in 1458, the Italian traveller and writer wrote favourably of the extensive farm produce of the estates at Episkopi, near modern-day Limassol, including the region's banana plantations.\n\nBananas were introduced to the Americas by Portuguese sailors who brought the fruits from West Africa in the 16th century.\n\nMany wild banana species as well as cultivars exist in extraordinary diversity in India, China, and Southeast Asia.\n\nIn the 15th and 16th centuries, Portuguese colonists started banana plantations in the Atlantic Islands, Brazil, and western Africa. North Americans began consuming bananas on a small scale at very high prices shortly after the Civil War, though it was only in the 1880s that the food became more widespread. As late as the Victorian Era, bananas were not widely known in Europe, although they were available. Jules Verne introduces bananas to his readers with detailed descriptions in \"Around the World in Eighty Days\" (1872).\n\nThe earliest modern plantations originated in Jamaica and the related Western Caribbean Zone, including most of Central America. It involved the combination of modern transportation networks of steamships and railroads with the development of refrigeration that allowed more time between harvesting and ripening. North American shippers like Lorenzo Dow Baker and Andrew Preston, the founders of the Boston Fruit Company started this process in the 1870s, but railroad builders like Minor C. Keith also participated, eventually culminating in the multi-national giant corporations like today's Chiquita Brands International and Dole. These companies were monopolistic, vertically integrated (meaning they controlled growing, processing, shipping and marketing) and usually used political manipulation to build enclave economies (economies that were internally self-sufficient, virtually tax exempt, and export-oriented that contribute very little to the host economy). Their political maneuvers, which gave rise to the term Banana republic for states like Honduras and Guatemala, included working with local elites and their rivalries to influence politics or playing the international interests of the United States, especially during the Cold War, to keep the political climate favorable to their interests.\n\nThe vast majority of the world's bananas today are cultivated for family consumption or for sale on local markets. India is the world leader in this sort of production, but many other Asian and African countries where climate and soil conditions allow cultivation also host large populations of banana growers who sell at least some of their crop.\n\nPeasant sector banana growers produce for the world market in the Caribbean, however. The Windward Islands are notable for the growing, largely of Cavendish bananas, for an international market, generally in Europe but also in North America. In the Caribbean, and especially in Dominica where this sort of cultivation is widespread, holdings are in the 1–2 acre range. In many cases the farmer earns additional money from other crops, from engaging in labor outside the farm, and from a share of the earnings of relatives living overseas.\n\nBanana crops are vulnerable to destruction by high winds, such as tropical storms or cyclones.\n\nAll widely cultivated bananas today descend from the two wild bananas \"Musa acuminata\" and \"Musa balbisiana\". While the original wild bananas contained large seeds, diploid or polyploid cultivars (some being hybrids) with tiny seeds are preferred for human raw fruit consumption. These are propagated asexually from offshoots. The plant is allowed to produce two shoots at a time; a larger one for immediate fruiting and a smaller \"sucker\" or \"follower\" to produce fruit in 6–8 months.\n\nAs a non-seasonal crop, bananas are available fresh year-round.\n\nIn global commerce in 2009, by far the most important cultivars belonged to the triploid AAA group of \"Musa acuminata\", commonly referred to as Cavendish group bananas. They accounted for the majority of banana exports, despite only coming into existence in 1836. The cultivars Dwarf Cavendish and Grand Nain (Chiquita Banana) gained popularity in the 1950s after the previous mass-produced cultivar, Gros Michel (also an AAA group cultivar), became commercially unviable due to Panama disease, caused by the fungus \"Fusarium oxysporum\" which attacks the roots of the banana plant. Cavendish cultivars are resistant to the Panama Disease, but in 2013 there were fears that the Black Sigatoka fungus would in turn make Cavendish bananas unviable.\n\nEven though it is no longer viable for large scale cultivation, Gros Michel is not extinct and is still grown in areas where Panama disease is not found. Likewise, Dwarf Cavendish and Grand Nain are in no danger of extinction, but they may leave supermarket shelves if disease makes it impossible to supply the global market. It is unclear if any existing cultivar can replace Cavendish bananas, so various hybridisation and genetic engineering programs are attempting to create a disease-resistant, mass-market banana. One such strain that has emerged is the Taiwanese Cavendish, also known as the Formosana.\n\nExport bananas are picked green, and ripen in special rooms upon arrival in the destination country. These rooms are air-tight and filled with ethylene gas to induce ripening. The vivid yellow color consumers normally associate with supermarket bananas is, in fact, caused by the artificial ripening process. Flavor and texture are also affected by ripening temperature. Bananas are refrigerated to between during transport. At lower temperatures, ripening permanently stalls, and the bananas turn gray as cell walls break down. The skin of ripe bananas quickly blackens in the environment of a domestic refrigerator, although the fruit inside remains unaffected.\nBananas can be ordered by the retailer \"ungassed\" (\"i.e.\" not treated with ethylene), and may show up at the supermarket fully green. (green bananas) that have not been gassed will never fully ripen before becoming rotten. Instead of fresh eating, these bananas can be used for cooking, as seen in Jamaican cuisine.\n\nA 2008 study reported that ripe bananas fluoresce when exposed to ultraviolet light. This property is attributed to the degradation of chlorophyll leading to the accumulation of a fluorescent product in the skin of the fruit. The chlorophyll breakdown product is stabilized by a propionate ester group. Banana-plant leaves also fluoresce in the same way. Green bananas do not fluoresce. The study suggested that this allows animals which can see light in the ultraviolet spectrum (tetrachromats and pentachromats) to more easily detect ripened bananas.\nBananas must be transported over long distances from the tropics to world markets. To obtain maximum shelf life, harvest comes before the fruit is mature. The fruit requires careful handling, rapid transport to ports, cooling, and refrigerated shipping. The goal is to prevent the bananas from producing their natural ripening agent, ethylene. This technology allows storage and transport for 3–4 weeks at . On arrival, bananas are held at about and treated with a low concentration of ethylene. After a few days, the fruit begins to ripen and is distributed for final sale. Ripe bananas can be held for a few days at home. If bananas are too green, they can be put in a brown paper bag with an apple or tomato overnight to speed up the ripening process.\n\nCarbon dioxide (which bananas produce) and ethylene absorbents extend fruit life even at high temperatures. This effect can be exploited by packing banana in a polyethylene bag and including an ethylene absorbent, e.g., potassium permanganate, on an inert carrier. The bag is then sealed with a band or string. This treatment has been shown to more than double lifespans up to 3–4 weeks without the need for refrigeration.\n\nIn 2016, world production of bananas and plantains was 148 million tonnes, led by India and China with a combined total (only for bananas) of 28% of global production (table). Other major producers were the Philippines, Ecuador, Indonesia, and Brazil, together accounting for 20% of the world total of bananas and plantains (table).\n\nAs reported for 2013, total world exports were 20 million tonnes of bananas and 859,000 tonnes of plantains. Ecuador and the Philippines were the leading exporters with 5.4 and 3.3 million tonnes, respectively, and the Dominican Republic was the leading exporter of plantains with 210,350 tonnes.\n\nBananas and plantains constitute a major staple food crop for millions of people in developing countries. In most tropical countries, green (unripe) bananas used for cooking represent the main cultivars. Most producers are small-scale farmers either for home consumption or local markets. Because bananas and plantains produce fruit year-round, they provide a valuable food source during the \"hunger season\" (when the food from one annual/semi-annual harvest has been consumed, and the next is still to come). Bananas and plantains are important for global food security.\n\nWhile in no danger of outright extinction, the most common edible banana cultivar Cavendish (extremely popular in Europe and the Americas) could become unviable for large-scale cultivation in the next 10–20 years. Its predecessor 'Gros Michel', discovered in the 1820s, suffered this fate. Like almost all bananas, Cavendish lacks genetic diversity, which makes it vulnerable to diseases, threatening both commercial cultivation and small-scale subsistence farming. Some commentators remarked that those variants which could replace what much of the world considers a \"typical banana\" are so different that most people would not consider them the same fruit, and blame the decline of the banana on monogenetic cultivation driven by short-term commercial motives.\n\nPanama disease is caused by a fusarium soil fungus (Race 1), which enters the plants through the roots and travels with water into the trunk and leaves, producing gels and gums that cut off the flow of water and nutrients, causing the plant to wilt, and exposing the rest of the plant to lethal amounts of sunlight. Prior to 1960, almost all commercial banana production centered on \"Gros Michel\", which was highly susceptible. Cavendish was chosen as the replacement for Gros Michel because, among resistant cultivars, it produces the highest quality fruit. However, more care is required for shipping the Cavendish, and its quality compared to Gros Michel is debated.\n\nAccording to current sources, a deadly form of Panama disease is infecting Cavendish. All plants are genetically identical, which prevents evolution of disease resistance. Researchers are examining hundreds of wild varieties for resistance.\n\nTropical race 4 (TR4), a reinvigorated strain of Panama disease, was first discovered in 1993. This virulent form of fusarium wilt has wiped out Cavendish in several southeast Asian countries and has recently spread to Australia, India and Mozambique. It has yet to reach the Americas; however, the soil-based fungi can easily be carried on boots, clothing, or tools. This is how TR4 travels and will be its most likely route into Latin America. Cavendish is highly susceptible to TR4, and over time Cavendish will almost certainly be eliminated from commercial production by this disease. The only known defense to TR4 is genetic resistance. This is conferred either by RGA2, a gene isolated from a TR4-resistant diploid banana, or by the nematode-derived Ced9.\n\nBlack sigatoka is a fungal leaf spot disease first observed in Fiji in 1963 or 1964. Black Sigatoka (also known as black leaf streak) has spread to banana plantations throughout the tropics from infected banana leaves that were used as packing material. It affects all main cultivars of bananas and plantains (including the Cavendish cultivars), impeding photosynthesis by blackening parts of the leaves, eventually killing the entire leaf. Starved for energy, fruit production falls by 50% or more, and the bananas that do grow ripen prematurely, making them unsuitable for export. The fungus has shown ever-increasing resistance to treatment, with the current expense for treating exceeding $1,000 per year. In addition to the expense, there is the question of how long intensive spraying can be environmentally justified.\n\nBanana bunchy top virus (BBTV) is a plant virus of the genus \"Babuvirus\", family \"Nanonviridae\" affecting \"Musa spp.\" (including banana, abaca, plantain and ornamental bananas) and \"Ensete spp.\" in the family \"Musaceae\". Banana Bunchy Top Disease (BBTD) symptoms include dark green streaks of variable length in leaf veins, midribs and petioles. Leaves become short and stunted as the disease progresses, becoming 'bunched' at the apex of the plant. Infected plants may produce no fruit or the bunch may not emerge from the pseudostem.\n\nBanana bacterial wilt (BBW) is a bacterial disease caused by \"Xanthomonas campestris\" pv. \"musacearum\". After being originally identified on a close relative of bananas, \"Ensete ventricosum\", in Ethiopia in the 1960s, BBW occurred in Uganda in 2001 affecting all banana cultivars. Since then BBW has been diagnosed in Central and East Africa including the banana growing regions of Rwanda, the Democratic Republic of the Congo, Tanzania, Kenya, Burundi, and Uganda.\n\nGiven the narrow range of genetic diversity present in bananas and the many threats via biotic (pests and diseases) and abiotic (such as drought) stress, conservation of the full spectrum of banana genetic resources is ongoing. Banana germplasm is conserved in many national and regional gene banks, and at the world's largest banana collection, the International \"Musa\" Germplasm Transit Centre (ITC), managed by Bioversity International and hosted at KU Leuven in Belgium. \"Musa\" cultivars are usually seedless, and options for their long-term conservation are constrained by the vegetative nature of the plant's reproductive system. Consequently, they are conserved by three main methods: \"in vivo\" (planted in field collections), \"in vitro\" (as plantlets in test tubes within a controlled environment), and by cryopreservation (meristems conserved in liquid nitrogen at -196 °C). Genes from wild banana species are conserved as DNA and as cryopreserved pollen and banana seeds from wild species are also conserved, although less commonly, as they are difficult to regenerate. In addition, bananas and their crop wild relatives are conserved \"in situ\" (in wild natural habitats where they evolved and continue to do so). Diversity is also conserved in farmers' fields where continuous cultivation, adaptation and improvement of cultivars is often carried out by small-scale farmers growing traditional local cultivars (including home gardens).\n\nRaw bananas (not including the peel) are 75% water, 23% carbohydrates, 1% protein, and contain negligible fat. A 100-gram serving supplies 89 Calories, 31% of the US recommended Daily Value of vitamin B, and moderate amounts of vitamin C, manganese and dietary fiber (see table).\n\n\n\nBananas are a staple starch for many tropical populations. Depending upon cultivar and ripeness, the flesh can vary in taste from starchy to sweet, and texture from firm to mushy. Both the skin and inner part can be eaten raw or cooked. The primary component of the aroma of fresh bananas is isoamyl acetate (also known as \"banana oil\"), which, along with several other compounds such as butyl acetate and isobutyl acetate, is a significant contributor to banana flavor.\n\nDuring the ripening process, bananas produce the gas ethylene, which acts as a plant hormone and indirectly affects the flavor. Among other things, ethylene stimulates the formation of amylase, an enzyme that breaks down starch into sugar, influencing the taste of bananas. The greener, less ripe bananas contain higher levels of starch and, consequently, have a \"starchier\" taste. On the other hand, yellow bananas taste sweeter due to higher sugar concentrations. Furthermore, ethylene signals the production of pectinase, an enzyme which breaks down the pectin between the cells of the banana, causing the banana to soften as it ripens.\n\nBananas are eaten deep fried, baked in their skin in a split bamboo, or steamed in glutinous rice wrapped in a banana leaf. Bananas can be made into jam. Banana pancakes are popular amongst backpackers and other travelers in South Asia and Southeast Asia. This has elicited the expression \"Banana Pancake Trail\" for those places in Asia that cater to this group of travelers. Banana chips are a snack produced from sliced dehydrated or fried banana or plantain, which have a dark brown color and an intense banana taste. Dried bananas are also ground to make banana flour. Extracting juice is difficult, because when a banana is compressed, it simply turns to pulp. Bananas feature prominently in Philippine cuisine, being part of traditional dishes and desserts like \"maruya\", \"turón\", and \"halo-halo\" or \"saba con yelo\". Most of these dishes use the Saba or Cardaba banana cultivar. Bananas are also commonly used in cuisine in the South-Indian state of Kerala, where they are steamed (\"puzhungiyathu\"), made into curries, fried into chips, (\"upperi\") or fried in batter (\"pazhampori\"). Pisang goreng, bananas fried with batter similar to the Filipino \"maruya\" or Kerala \"pazhampori\", is a popular dessert in Malaysia, Singapore, and Indonesia. A similar dish is known in the United Kingdom and United States as banana fritters.\n\nPlantains are used in various stews and curries or cooked, baked or mashed in much the same way as potatoes, such as the pazham pachadi dish prepared in Kerala.\n\nBanana hearts are used as a vegetable in South Asian and Southeast Asian cuisine, either raw or steamed with dips or cooked in soups, curries and fried foods. The flavor resembles that of artichoke. As with artichokes, both the fleshy part of the bracts and the heart are edible.\n\nBanana leaves are large, flexible, and waterproof. They are often used as ecologically friendly disposable food containers or as \"plates\" in South Asia and several Southeast Asian countries. In Indonesian cuisine, banana leaf is employed in cooking methods like pepes and botok; banana leaf packages containing food ingredients and spices are cooked in steam or in boiled water, or are grilled on charcoal. When used so for steaming or grilling, the banana leaves protect the food ingredients from burning and add a subtle sweet flavor. In South India, it is customary to serve traditional food on a banana leaf. In Tamil Nadu (India), dried banana leaves are used as to pack food and to make cups to hold liquid food items.\n\nThe tender core of the banana plant's trunk is also used in South Asian and Southeast Asian cuisine, and notably in the Burmese dish mohinga.\n\nBanana fiber harvested from the pseudostems and leaves of the plant has been used for textiles in Asia since at least the 13th century. Both fruit-bearing and fibrous varieties of the banana plant have been used. In the Japanese system Kijōka-bashōfu, leaves and shoots are cut from the plant periodically to ensure softness. Harvested shoots are first boiled in lye to prepare fibers for yarn-making. These banana shoots produce fibers of varying degrees of softness, yielding yarns and textiles with differing qualities for specific uses. For example, the outermost fibers of the shoots are the coarsest, and are suitable for tablecloths, while the softest innermost fibers are desirable for kimono and kamishimo. This traditional Japanese cloth-making process requires many steps, all performed by hand.\n\nIn India, a banana fiber separator machine has been developed, which takes the agricultural waste of local banana harvests and extracts strands of the fiber.\n\nBanana fiber is used in the production of banana paper. Banana paper is made from two different parts: the bark of the banana plant, mainly used for artistic purposes, or from the fibers of the stem and non-usable fruits. The paper is either hand-made or by industrial process.\n\n\n\nIn all the important festivals and occasions of Hindus, the serving of bananas plays a prominent part.\n\nIn Thailand, it is believed that a certain type of banana plants may be inhabited by a spirit, Nang Tani, a type of ghost related to trees and similar plants that manifests itself as a young woman. Often people tie a length of colored satin cloth around the pseudostem of the banana plants.\n\nIn Malay folklore, the ghost known as Pontianak is associated with banana plants (\"pokok pisang\"), and its spirit is said to reside in them during the day.\n\nThere is a long racist history of describing people of African descent as being more like monkeys than humans, and due to the assumption in popular culture that monkeys like bananas, bananas have been used in symbolic acts of hate speech. In April 2014, during a match at Villarreal's stadium, El Madrigal, Dani Alves was targeted by Villareal supporter David Campaya Lleo, who threw a banana at him. Alves picked up the banana, peeled it and took a bite, and the meme went viral on social media in support of him. Racist taunts are an ongoing problem in football. Bananas were hung from nooses around the campus of American University in May 2017 after the student body elected its first black woman student government president.\n\nThe Unicode standard includes the emoji character .\n\n\n\n\n\n"}
{"id": "30874007", "url": "https://en.wikipedia.org/wiki?curid=30874007", "title": "Brake-specific fuel consumption", "text": "Brake-specific fuel consumption\n\nBrake-specific fuel consumption (BSFC) is a measure of the fuel efficiency of any prime mover that burns fuel and produces rotational, or shaft power. It is typically used for comparing the efficiency of internal combustion engines with a shaft output.\n\nIt is the rate of fuel consumption divided by the power produced. It may also be thought of as power-specific fuel consumption, for this reason. BSFC allows the fuel efficiency of different engines to be directly compared.\n\nTo calculate BSFC, use the formula\n\nwhere:\n\nThe above values of \"r\", formula_5, and formula_6 may be readily measured by instrumentation with an engine mounted in a test stand and a load applied to the running engine. The resulting units of BSFC are grams per joule (g/J)\n\nCommonly BSFC is expressed in units of grams per kilowatt-hour (g/(kW⋅h)). The conversion factor is as follows:\n\nThe conversion between metric and imperial units is:\n\nTo calculate the actual efficiency of an engine requires the energy density of the fuel being used.\n\nDifferent fuels have different energy densities defined by the fuel's heating value. The lower heating value (LHV) is used for internal-combustion-engine-efficiency calculations because the heat at temperatures below cannot be put to use.\n\nSome examples of lower heating values for vehicle fuels are:\n\nThus a diesel engine's efficiency = 1/(BSFC × 0.0119531) and a gasoline engine's efficiency = 1/(BSFC × 0.0122225)\n\nAny engine will have different BSFC values at different speeds and loads. For example, a reciprocating engine achieves maximum efficiency when the intake air is unthrottled and the engine is running near its peak torque. The efficiency often reported for a particular engine, however, is not its maximum efficiency but a fuel economy cycle statistical average. For example, the cycle average value of BSFC for a gasoline engine is 322 g/(kW⋅h), translating to an efficiency of 25% (1/(322 × 0.0122225) = 0.2540). Actual efficiency can be lower or higher than the engine’s average due to varying operating conditions. In the case of a production gasoline engine, the most efficient BSFC is approximately 225 g/(kW⋅h), which is equivalent to a thermodynamic efficiency of 36%.\n\nAn iso-BSFC map (fuel island plot) of a diesel engine is shown. The sweet spot at 206 BSFC has 40.6% efficiency. The x-axis is rpm; y-axis is BMEP in bar (bmep is proportional to torque)\n\nBSFC numbers change a lot for different engine designs, and compression ratio and power rating. Engines of different classes like diesels and gasoline engines will have very different BSFC numbers, ranging from less than 200 g/(kW⋅h) (diesel at low speed and high torque) to more than 1,000 g/(kW⋅h) (turboprop at low power level).\n\nThe following table takes values as an example for the specific fuel consumption of several types of engines. For specific engines values can and often do differ from the table values shown below. Energy efficiency is based on a lower heating value of 42.7 MJ/kg (3600/42.7round1 g/(kW⋅h)) for diesel fuel and jet fuel, 43.9 MJ/kg (3600/43.9round1 g/(kW⋅h)) for gasoline.\n\nTurboprop efficiency is only good at high power; SFC increases dramatically for approach at low power (30% P) and especially at idle (7% P) :\n\n\n\n\n"}
{"id": "3679268", "url": "https://en.wikipedia.org/wiki?curid=3679268", "title": "Carbon capture and storage", "text": "Carbon capture and storage\n\nCarbon capture and storage (CCS) (or carbon capture and sequestration or carbon control and sequestration) is the process of capturing waste carbon dioxide () from large point sources, such as fossil fuel power plants, transporting it to a storage site, and depositing it where it will not enter the atmosphere, normally an underground geological formation. The aim is to prevent the release of large quantities of into the atmosphere (from fossil fuel use in power generation and other industries). It is a potential means of mitigating the contribution of fossil fuel emissions to global warming and ocean acidification. Although has been injected into geological formations for several decades for various purposes, including enhanced oil recovery, the long term storage of is a relatively new concept. The first commercial example was the Weyburn-Midale Carbon Dioxide Project in 2000. Another example is SaskPower's Boundary Dam. 'CCS' can also be used to describe the scrubbing of from ambient air as a climate engineering technique.\n\nAn integrated pilot-scale CCS power plant was to begin operating in September 2008 in the eastern German power plant Schwarze Pumpe run by utility Vattenfall, to test the technological feasibility and economic efficiency. CCS applied to a modern conventional power plant could reduce emissions to the atmosphere by approximately 80–90% compared to a plant without CCS. The IPCC estimates that the economic potential of CCS could be between 10% and 55% of the total carbon mitigation effort until year 2100.\n\nCarbon dioxide can be captured out of air or fossil fuel power plant flue gas using adsorption (or carbon scrubbing), membrane gas separation, or adsorption technologies. Amines are the leading carbon scrubbing technology.\nCapturing and compressing may increase the energy needs of a coal-fired CCS plant by 25–40%. These and other system costs are estimated to increase the cost per watt-hour energy produced by 21–91% for fossil fuel power plants. Applying the technology to existing plants would be more expensive, especially if they are far from a sequestration site. A 2005 industry report suggests that with successful research, development and deployment (RD&D), sequestered coal-based electricity generation in 2025 may cost less than unsequestered coal-based electricity generation today.\n\nStorage of the is envisaged either in deep geological formations, or in the form of mineral carbonates. Deep ocean storage is not currently considered feasible due to the associated effect of ocean acidification. Geological formations are currently considered the most promising sequestration sites. The National Energy Technology Laboratory (NETL) reported that North America has enough storage capacity for more than 900 years worth of carbon dioxide at current production rates. A general problem is that long term predictions about submarine or underground storage security are very difficult and uncertain, and there is still the risk that might leak into the atmosphere.\n\nCapturing is most effective at point sources, such as large fossil fuel or biomass energy facilities, industries with major emissions, natural gas processing, synthetic fuel plants and fossil fuel-based hydrogen production plants. Extracting from air is also possible, although the far lower concentration of in air compared to combustion sources presents significant engineering challenges.\n\nOrganisms that produce ethanol by fermentation generate cool, essentially pure that can be pumped underground. Fermentation produces slightly less than ethanol by weight.\n\nFlue gas from the combustion of coal in oxygen has a large concentration of CO2, about 10-15% whereas natural gas power plant flue gas is about 5–10% . Therefore, it is more energy and cost efficient to capture CO2 from coal-fired power plants.\nImpurities in streams, like sulfurs and water, could have a significant effect on their phase behaviour and could pose a significant threat of increased corrosion of pipeline and well materials. In instances where impurities exist, especially with air capture, a scrubbing separation process would be needed to initially clean the flue gas. According to the Wallula Energy Resource Center in Washington state, by gasifying coal, it is possible to capture approximately 65% of carbon dioxide embedded in it and sequester it in a solid form.\n\nBroadly, three different configurations of technologies for capture exist: post-combustion, pre-combustion, and oxyfuel combustion:\n\n\nCarbon dioxide can be separated out of air or flue gas with absorption, adsorption, or membrane gas separation technologies. Absorption, or carbon scrubbing, with amines is currently the dominant capture technology. Membrane and adsorption technologies are still in the developmental research stages, initiating primary pilot plants in the near future. Metal-Organic Frameworks (MOFs) are a novel class of materials that offer promise for carbon capture using adsorption technologies.\n\nCarbon dioxide adsorbs to a MOF through physisorption or chemisorption based on the porosity and selectivity of the MOF leaving behind a Greenhouse gas poor gas stream that is more environmentally friendly. The carbon dioxide is then stripped off the MOF using temperature swing adsorption (TSA) or pressure swing adsorption (PSA) so the MOF can be reused. Adsorbents and absorbents require regeneration steps where the is removed from the sorbent or solution that collected it out of the flue gas in order for the sorbent or solution to be reused. Monoethanolamine (MEA) solutions, the leading amine for capturing , have a heat capacity between 3-4 J/g K since they are mostly water. Higher heat capacities add to the energy penalty in the solvent regeneration step. Thus, to optimize a MOF for carbon capture, low heat capacities and heats of adsorption are desired. Additionally, high working capacity and high selectivity are desirable in order to capture as much as possible from the flue gas. However, there is an energy trade off with selectivity and energy expenditure. As the amount of captured increases, the energy, and therefore cost, required to regenerate increases. A large drawback of using MOFs for CCS is the limitations imposed by their chemical and thermal stability. Current research is looking to optimize MOF properties for CCS, but it has proven difficult to find these optimizations that also result in a stable MOF. Metal reservoirs are also a limiting factor to the potential success of MOFs.\n\nCapture is attributed to about two thirds of the total cost of CCS, making it limit the wide-scale deployment of CCS technologies. To optimize a capture process would significantly increase the feasibility of CCS since the transport and storage steps of CCS are rather mature technologies.\n\nAn alternate method under development is chemical looping combustion (CLC). Chemical looping uses a metal oxide as a solid oxygen carrier. Metal oxide particles react with a solid, liquid or gaseous fuel in a fluidized bed combustor, producing solid metal particles and a mixture of carbon dioxide and water vapor. The water vapor is condensed, leaving pure carbon dioxide, which can then be sequestered. The solid metal particles are circulated to another fluidized bed where they react with air, producing heat and regenerating metal oxide particles that are recirculated to the fluidized bed combustor. A variant of chemical looping is calcium looping, which uses the alternating carbonation and then calcination of a calcium oxide based carrier as a means of capturing .\n\nDirect air capture refers to the process of removing directly from the ambient air (as opposed to from point sources). Combining direct air capture with carbon storage could act as a carbon dioxide removal technology and as such would constitute a form of climate engineering if deployed at large scale.\n\nA few engineering proposals have been made for such direct air capture, but work in this area is still in its infancy. A pilot plant has operated in British Columbia, Canada since 2015. An economic study of this plant in 2018 estimated the cost at US$94-$232 per tonne of atmospheric CO2 removed. This estimate has decreased compared to a 2011 study that estimated that direct air capture would cost $600 per tonne.\n\nAmong the specific chemical processes that are being explored, three stand out: causticization with alkali and alkali-earth hydroxides, carbonation,\nand organic−inorganic hybrid sorbents consisting of amines supported in porous adsorbents.\n\nGiven that in the atmosphere is highly diluted compared to point-source capture, capture costs are estimated to be higher. Once costs and incentives for climate change mitigation rise higher later this century, however, they might become attractive for dealing with emissions from diffuse sources such as automobiles and aircraft. Global Research Technologies demonstrated a pre-prototype of air capture technology in 2007.\n\nAfter capture, the would have to be transported to suitable storage sites. This would most likely be done by pipeline, which is generally the cheapest form of transport for large volume of CO2. In 2008, there were approximately 5,800 km of pipelines in the United States, used to transport to oil production fields where it is then injected into older fields to extract oil. The injection of to produce oil is generally called \"enhanced oil recovery\". In addition, there are several pilot programs in various stages to test the long-term storage of in non-oil producing geologic formations.\n\nAccording to the Congressional Research Service, \"There are important unanswered questions about pipeline network requirements, economic regulation, utility cost recovery, regulatory classification of itself, and pipeline safety. Furthermore, because pipelines for enhanced oil recovery are already in use today, policy decisions affecting pipelines take on an urgency that is unrecognized by many. Federal classification of as both a commodity (by the Bureau of Land Management) and as a pollutant (by the Environmental Protection Agency) could potentially create an immediate conflict which may need to be addressed not only for the sake of future CCS implementation, but also to ensure consistency of future CCS with pipeline operations today.\"\n\nShips could also be utilized for transport where pipelines are not feasible. These methods are currently used for transporting for other applications.\n\nVarious forms have been conceived for permanent storage of . These forms include gaseous storage in various deep geological formations (including saline formations and exhausted gas fields), and solid storage by reaction of with metal oxides to produce stable carbonates.\n\nAlso known as \"geo-sequestration\", this method involves injecting carbon dioxide, generally in supercritical form, directly into underground geological formations. Oil fields, gas fields, saline formations, unmineable coal seams, and saline-filled basalt formations have been suggested as storage sites. Various physical (e.g., highly impermeable caprock) and geochemical trapping mechanisms would prevent the from escaping to the surface.\n\nUnmineable coal seams can be used to store because the molecules attach to the surface of coal. The technical feasibility, however, depends on the permeability of the coal bed. In the process of absorption the coal releases previously absorbed methane, and the methane can be recovered (enhanced coal bed methane recovery). The sale of the methane can be used to offset a portion of the cost of the storage. Burning the resultant methane, however, would negate some of the benefit of sequestering the original .\n\nSaline formations contain highly mineralized brines, and have so far been considered of no benefit to humans. Saline aquifers have been used for storage of chemical waste in a few cases. The main advantage of saline aquifers is their large potential storage volume and their common occurrence. The major disadvantage of saline aquifers is that relatively little is known about them, especially compared to oil fields. To keep the cost of storage acceptable, the geophysical exploration may be limited, resulting in larger uncertainty about the aquifer structure. Unlike storage in oil fields or coal beds, no side product will offset the storage cost. Leakage of back into the atmosphere may be a problem in saline aquifer storage. Current research shows, however, that \"trapping mechanisms\" such as structural trapping, residual trapping, solubility trapping and mineral trapping could immobilize the underground and reduce the risk of leakage.\nAn alternative to geochemical injection would instead be to physically store carbon dioxide in containers with a bacteria that could degrade the carbon dioxide. It would ultimately be ideal to exploit the carbon dioxide metabolizing bacterium \"Clostridium thermocellum\" in such theoretical CO2 storage containers. Using this bacteria would prevent overpressurization of such theoretical carbon dioxide storage containers. \n\nEnhanced oil recovery (EOR) is a generic term for techniques used to increase the amount of crude oil that can be extracted from an oil field. In carbon capture and sequestration enhanced oil recovery (CCS EOR), carbon dioxide is injected into an oil field to recover oil that is often never recovered using more traditional methods.\n\nCrude oil development and production in U.S. oil reservoirs can include up to three distinct phases: primary, secondary, and tertiary (or enhanced) recovery. During primary recovery only about 10 percent of a reservoir's original oil in place is typically produced. Secondary recovery techniques extend a field's productive life generally by injecting water or gas to displace oil and drive it to a production wellbore, resulting in the recovery of 20 to 40 percent of the original oil in place. However, with much of the easy-to-produce oil already recovered from U.S. oil fields, producers have attempted several tertiary, or enhanced oil recovery, techniques that offer prospects for ultimately producing 30 to 60 percent, or more, of the reservoir's original oil in place.\n\nAn example of a project that will use CCS EOR is the Kemper Project in Mississippi. Due to the Kemper Project's close proximity to oil fields, the carbon dioxide byproduct from producing electricity will be transported to the neighboring oil fields for enhanced oil recovery.\n\nHeld in 1992, the results from this climate convention are the most widely agreed upon for addressing the problem of climate change and the use of sinks of greenhouse gases. Ocean storage of has been pointed out a viable option of mitigating the levels of carbon dioxide in the atmosphere. However, the convention also states that there should be precautionary measures taken to mitigate any detriments to the environment. Therefore, with this convention, ocean storage may prove to be a way to store carbon dioxide efficiently, especially in places where it is cost effective such as Norway.\n\nTaken place in 1972 with more than 70 members, the result of the London Convention is that it prohibits all ocean dumping without the direct approval of a national authority. In 1991, an addendum also prohibited the dumping of all radioactive and industrial waste, making it unclear and debated to today whether or not carbon dioxide falls under industrial waste. The London Convention also applies to sea-faring vessels such as ships, planes, and offshore drilling platforms. If these types of vessels want to dump carbon dioxide into the ocean, they must get permission from their respective national authority.\n\nThe 1996 Protocol to the London Convention went even further by prohibiting carbon dioxide storage that comes from sea-based storage. In 1997, the Joint Group of Experts on the Scientific Aspects of Marine environmental Protection stated that until there was 2/3 majority vote, any dumping of carbon dioxide from ships was in direct violation of the London Convention.\n\nAlso occurring in 1992, this convention was set up to protect the North East Atlantic Ocean. The convention was more certain in its results from the meeting. The first is that it prohibited carbon dioxide from going to a storage site through a petroleum platform and also prohibited transport by ship. It did however, allow transport of carbon dioxide through a pipeline from land to a site that did not require the use of a platform used for gas exploration.\n\nIn the past, it was suggested that could be stored in the oceans, but this would only exacerbate ocean acidification and has been made illegal under specific regulations. Ocean storage is no longer considered feasible.\n\nIn this process, is exothermically reacted with available metal oxides, which in turn produces stable carbonates (e.g. calcite, magnesite). This process occurs naturally over many years and is responsible for a great amount of surface limestone. The idea of using olivine has been promoted by the geochemist Prof. Schuiling. The reaction rate can be made faster, for example, with a catalyst or by reacting at higher temperatures and/or pressures, or by pre-treatment of the minerals, although this method can require additional energy. The IPCC estimates that a power plant equipped with CCS using mineral storage will need 60–180% more energy than a power plant without CCS.\n\nThe economics of mineral carbonation at scale are now being tested in a world-first pilot plant project based in Newcastle, Australia. New techniques for mineral activation and reaction have been developed the GreenMag Group and the University of Newcastle and funded by the New South Wales and Australian Governments to be operational by 2013.\n\nIn 2009 it was reported that scientists had mapped of rock formations in the U.S. that could be used to store 500 years' worth of U.S. carbon dioxide emissions. A study on mineral sequestration in the US states:\nCarbon sequestration by reacting naturally occurring Mg and Ca containing minerals with to form carbonates has many unique advantages. Most notabl[e] is the fact that carbonates have a lower energy state than , which is why mineral carbonation is thermodynamically favorable and occurs naturally (e.g., the weathering of rock over geologic time periods). Secondly, the raw materials such as magnesium based minerals are abundant. Finally, the produced carbonates are unarguably stable and thus re-release of into the atmosphere is not an issue. However, conventional carbonation pathways are slow under ambient temperatures and pressures. The significant challenge being addressed by this effort is to identify an industrially and environmentally viable carbonation route that will allow mineral sequestration to be implemented with acceptable economics.\n\nThe following table lists principal metal oxides of Earth's Crust. Theoretically, up to 22% of this mineral mass is able to form carbonates.\n\nUltramafic mine tailings are a readily available source of fine-grained metal oxides that can act as artificial carbon sinks to reduce net greenhouse gas emissions in the mining industry. Accelerating passive sequestration via mineral carbonation may be achieved through microbial processes that enhance mineral dissolution and carbonate precipitation.\n\nThe energy requirements of sequestration processes may be significant. In one paper, sequestration consumed 25 percent of the plant's rated 600-megawatt output capacity.\n\nA major concern with CCS is whether leakage of stored will compromise CCS as a climate change mitigation option. For well-selected, designed and managed geological storage sites, IPCC estimates that risks are comparable to those associated with current hydrocarbon activity. However, this finding is contested due to a lack of experience in such long term storage. could be trapped for millions of years, and although some leakage occurs upwards through the soil, well selected storage sites are likely to retain over 99% of the injected over 1000 years. Leakage through the injection pipe is a greater risk.\n\nAlthough the injection pipe is usually protected with non-return valves to prevent release on a power outage, there is still a risk that the pipe itself could tear and leak due to the pressure. The Berkel en Rodenrijs incident in December 2008 was an example, where a modest release of from a pipeline under a bridge resulted in the deaths of some ducks sheltering there. In order to measure accidental carbon releases more accurately and decrease the risk of fatalities through this type of leakage, the implementation of alert meters around the project perimeter has been proposed. Malfunction of a carbon dioxide industrial fire suppression system in a large warehouse released and 14 citizens collapsed on the nearby public road. A release of from a salt mine killed a person at distance of 300 meters.\n\nIn 1986 a large leakage of naturally sequestered rose from Lake Nyos in Cameroon and asphyxiated 1,700 people. While the carbon had been sequestered naturally, some point to the event as evidence for the potentially catastrophic effects of sequestering carbon artificially. The Lake Nyos disaster resulted from a volcanic event, which very suddenly released as much as a cubic kilometre of gas from a pool of naturally occurring under the lake in a deep narrow valley. The location of this pool of is not a place where man can inject or store , and this pool was not known about nor monitored until after the occurrence of the natural disaster.\n\nFor ocean storage, the retention of would depend on the depth. The IPCC estimates 30–85% of the sequestered carbon dioxide would be retained after 500 years for depths 1000–3000 m. Mineral storage is not regarded as having any risks of leakage. The IPCC recommends that limits be set to the amount of leakage that can take place. This might rule out deep ocean storage as an option.\n\nAt the conditions of the deeper oceans, (about 400 bar or 40 MPa, 280 K) water–(l) mixing is \"very\" low (where carbonate formation/acidification is the rate limiting step), but the formation of water- hydrates, a kind of solid water cage that surrounds the , is favorable.\n\nTo further investigate the safety of sequestration, Norway's Sleipner gas field can be studied, as it is the oldest plant that stores on an industrial scale. According to an environmental assessment of the gas field which was conducted after ten years of operation, the author affirmed that geosequestration of was the most definite form of permanent \"geological\" storage of :\nAvailable geological information shows absence of major tectonic events after the deposition of the Utsira formation [saline reservoir]. This implies that the geological environment is tectonically stable and a site suitable for carbon dioxide storage. The solubility trapping [is] the most permanent and secure form of geological storage.\n\nIn March 2009 StatoilHydro issued a study showing the slow spread of in the formation after more than 10 years operation.\n\nPhase I of the Weyburn-Midale Carbon Dioxide Project in Weyburn, Saskatchewan, Canada has determined that the likelihood of stored release is less than one percent in 5,000 years. A January 2011 report, however, claimed evidence of leakage in land above that project. This report was strongly refuted by the IEAGHG Weyburn-Midale Monitoring and Storage Project, which issued an eight-page analysis of the study, claiming that it showed no evidence of leakage from the reservoir.\n\nThe liability of potential leak(s) is one of the largest barriers to large-scale CCS. To assess and reduce such liability, the leakage of stored gasses, particularly carbon dioxide, into the atmosphere may be detected via atmospheric gas monitoring, and can be quantified directly via the eddy covariance flux measurements,\n\nIn order to detect carbon dioxide leaks and the effectiveness of geological sequestration sites, different monitoring techniques can be employed to verify that the sequestered carbon stays trapped below the surface in the intended reservoir. Leakage due to injection at improper locations or conditions could result in carbon dioxide being released back into the atmosphere. It is important to be able to detect leaks with enough warning to put a stop to it, and to be able to quantify the amount of carbon that has leaked for purposes such as cap and trade policies, evaluation of environmental impact of leaked carbon, as well as accounting for the total loss and cost of the process. To quantify the amount of carbon dioxide released, should a leak occur, or to closely watch stored , there are several monitoring methods that can be done at both the surface and subsurface levels.\n\nIn subsurface monitoring, there are direct and indirect methods to determine the amount of in the reservoir. A direct method would be drilling deep enough to collect a fluid sample. This drilling can be difficult and expensive due to the physical properties of the rock. It also only provides data at a specific location. Indirect methods would be to send sound or electromagnetic waves down to the reservoir where it is then reflected back up to be interpreted. This approach is also expensive but it provides data over a much larger region; it does however lack precision. Both direct and indirect monitoring can be done intermittently or continuously.\n\nSeismic monitoring is a type of indirect subsurface monitoring. It is done by creating vibrational waves either at the surface using a vibroseis truck, or inside a well using spinning eccentric mass. These vibrational waves then propagate through the geological layers and reflect back creating patterns that are read and interpreted by seismometers. It can identify migration pathways of the plume. Two examples of monitoring geological sequestration sites using seismic monitoring are the Sleipner sequestration project and the Frio Injection test. Although this method can confirm the presence of in a given region, it cannot determine the specifics of the environment or concentration of .\n\nEddy covariance is a surface monitoring technique that measures the flux of from the ground's surface. It involves measuring concentrations as well as vertical wind velocities using an anemometer. This provides a measure of the total vertical flux of CO2. Eddy covariance towers could potentially detect leaks, however, the natural carbon cycle, such as photosynthesis and the respiration of plants, would have to be accounted for and a baseline cycle would have to be developed for the location of monitoring. An example of Eddy covariance techniques used to monitor carbon sequestration sites is the Shallow Release test. Another similar approach is utilizing accumulation chambers. These chambers are sealed to the ground with an inlet and outlet flow stream connected to a gas analyzer. This also measures the vertical flux of . The disadvantage of accumulation chambers is its inability to monitor a large region which is necessary in detecting leaks over the entire sequestration site.\n\nInSAR monitoring is another type of surface monitoring. It involves a satellite sending signals down to the Earth's surface where it is reflected back to the satellite's receiver. From this, the satellite is able to measure the distance to that point. In CCS, the injection of in deep sublayers of geological sites creates high pressures. These high pressured, fluid filled layers affect those above and below it resulting in a change of the surface landscape. In areas of stored , the ground's surface often rises due to the high pressures originating in the deep subsurface layers. These changes in elevation of the Earth's surface corresponds to a change in the distance from the inSAR satellite which is then detectable and measurable.\n\nCarbon capture and use may offer a response to the global challenge of significantly reducing greenhouse gas emissions from major stationary (industrial) emitters in the near to medium term. Given that it does not result in geological storage of carbon dioxide, it represents a different technological category from CCS. Technologies under development, such as Bio CCS Algal Synthesis, utilises pre-smokestack (such as from a coal-fired power station) as a useful feedstock input to the production of oil-rich algae in solar membranes to produce oil for plastics and transport fuel (including aviation fuel), and nutritious stock-feed for farm animal production. The and other captured greenhouse gases are injected into the membranes containing waste water and select strains of algae causing, together with sunlight or UV light, an oil rich biomass that doubles in mass every 24 hours.\n\nThe Bio CCS Algal Synthesis process is based on earth science photosynthesis: the technology is entirely retrofittable and collocated with the emitter, and the capital outlays may offer a return upon investment due to the high value commodities produced (oil for plastics, fuel and feed).\n\nBio CCS Algal Synthesis test facilities were being trialed at Australia's three largest coal-fired power stations (Tarong, Queensland; Eraring, NSW; Loy Yang, Victoria) using piped pre-emission smokestack (and other greenhouse gases) as feedstock to grow oil-rich algal biomass in enclosed membranes for the production of plastics, transport fuel and nutritious animal feed.\n\nAnother potentially useful way of dealing with industrial sources of is to convert it into hydrocarbons where it can be stored or reused as fuel or to make plastics. There are a number of projects investigating this possibility.\n\nCarbon dioxide scrubbing variants exist based on potassium carbonate which can be used to create liquid fuels, though this process requires a great deal of energy input. Although the creation of fuel from atmospheric does not result in carbon dioxide removal as carbon dioxide is re-released when the fuel is burned. Therefore, synfuels do not represent a climate engineering technique. Nevertheless, they are potentially useful as net-zero-carbon fuel.\n\nOther uses are the production of stable carbonates from silicates (e.g. olivine produces magnesium carbonate). These processes are still under research and development.\n\nA proven process to produce a hydrocarbon is to make methanol. Methanol is easily synthesized from and H. Based on this fact the idea of a methanol economy was born.\n\nAt the department of Industrial Chemistry and Engineering of Materials at the University of Messina, Italy, there is a project to develop a system which works like a fuel-cell in reverse, whereby a catalyst is used that enables sunlight to split water into hydrogen ions and oxygen gas. The ions cross a membrane where they react with the to create hydrocarbons.\n\nIf is heated to 2400 °C, it splits into carbon monoxide (CO) and oxygen. The Fischer-Tropsch process can then be used to convert the CO into hydrocarbons. The required temperature can be achieved by using a chamber containing a mirror to focus sunlight on the gas. Rival teams are developing such chambers, at Solarec and at Sandia National Laboratories, both based in New Mexico. According to Sandia these chambers could provide enough fuel to power 100% of domestic vehicles using 5800 km; unlike biofuels this would not take fertile land away from crops but would be land that is not being used for anything else. James May, the British TV presenter, visited a demonstration plant in a programme in his Big Ideas series.\n\nAs of September 2012, the Global CCS Institute identified 75 large-scale integrated projects in its 2012 Global Status of CCS report which is a net increase of one project since its 2011 Global Status of CCS report. 16 of these projects are in operation or in construction capturing around 36 million tonnes of per annum. For more information see Integrated CCS Projects on the Global CCS Institute's website. For information on EU projects see Zero Emissions Platform website. The eight large-scale integrated CCS projects currently in operation are:\n\nIn Salah is a fully operational onshore gas field with injection. is separated from produced gas and reinjected in the producing hydrocarbon reservoir zones. Since 2004, about 1 Mt/a of has been captured during natural gas extraction and injected into the Krechba geologic formation at a depth of 1,800m. The Krechba formation is expected to store 17Mt over the life of the project.\n\nInjection suspended in 2011 due to concerns about the integrity of the seal.\n\nSleipner is a fully operational offshore gas field with injection initiated in 1996. is separated from produced gas and reinjected in the Utsira saline aquifer (800–1000 m below ocean floor) above the hydrocarbon reservoir zones. This aquifer extends much further north from the Sleipner facility at its southern extreme. The large size of the reservoir accounts for why 600 billion tonnes of are expected to be stored, long after the Sleipner natural gas project has ended.\n\nSnøhvit is a fully operational offshore gas field with injection. The LNG plant is located onshore. is necessarily separated to produce liquefied natural gas (LNG) and then is injected in a saline aquifer below the hydrocarbon reservoir zones offshore at a rate of 700,000 t/a into the Tubåen sandstone formation 2,600 m under the seabed for storage. This formation was closed April 2011, and injection started in the Stø-formation where produced gas is taken. Produced is increasing, therefore separation capacity may limit production before end 2015 when a new formation will be drilled for -injection only. (Teknisk Ukeblad nr. 30, 2013, tu.no)\n\nWeyburn-Midale is a coal gasification operation that produces synthetic natural gas and various petrochemicals from coal. This project captures about 2.8 Mt/a of from its coal gasification plant located in North Dakota, US, transported by pipeline 320 km across the Canada–US border and injects it into depleting oil fields in Saskatchewan where it is used for enhanced oil recovery (EOR).\n\nAround 7 million tonnes per annum of carbon dioxide are recovered from ExxonMobil's Shute Creek gas processing plant in Wyoming, and transported by pipeline to various oil fields for enhanced oil recovery. This project has been operational since 1986.\n\nThe Enid Fertilizer plant sends 675,000 tonnes of to be used for EOR. The pipeline and wells are operated separately by Anadarko Petroleum.\n\n from Mitchell, Gray Ranch, Puckett, and Turrell gas processing plants is transported via the Val Verde and CRC pipelines for EOR (incl. Sharon Ridge EOR field).\n\nOccidental Petroleum, along with Sandridge Energy, is operating a West Texas hydrocarbon gas processing plant and related pipeline infrastructure that provides for use in EOR. With a total capture capacity of 8.5 Mt/a expected in 2012, the Century plant would be the largest single industrial source capture facility in North America.\n\nResearchers at the Center for Applied Energy Research of the University of Kentucky are currently developing the algae-mediated conversion of coal-fired power plant flue gas to drop-in hydrocarbon fuels. Through their work, these researchers have proven that the carbon dioxide within flue gas from coal-fired power plants can be captured using algae, which can be subsequently harvested and utilized, e.g. as a feedstock for the production of drop-in hydrocarbon fuels.\n\nThe Petra Nova project is a billion dollar endeavour taken upon by NRG Energy and JP Nippon to retrofit their jointly owned W.A Parish coal-fired power plant with post-combustion carbon capture. The plant, which is located in Thompsons, Texas (just outside of Houston), entered commercial service in 1977, and carbon capture began operation on January 10, 2017. The plant generates 240 MW and 90% of the CO2 (or 1.4 million tonnes) is captured per year. The carbon dioxide captured (99% purity) from the power plant is compressed and piped about 82 miles to West Ranch Oil Field, Texas, where it will be used for enhanced oil recovery. The field has a capacity of 60 million barrels of oil and is expected to increase oil production by a factor of 506. This project is expected to run for at least another 20 years.\n\nThe federal government in the 2008 and 2009 budgets has invested approximately $1.4 billion in Carbon Capture and Storage development.\n\nAlberta has committed $170 million in 2013/2014 – and a total of $1.3 billion over 15 years – to fund two large-scale CCS projects that will help reduce emissions from tar sands refining. In 2010 a grant agreement was signed with the Alberta Carbon Trunk Line. The second is the Quest Project. The Quest project uses amine absorption to capture from the Scotford Steam Methane Reformer units. Approximately 1.2 Mtonne per year is captured and transported through 64 km of onshore pipeline into a saline aquifer in the Cambrian Basal Sands.\n\nQuest Carbon Capture and Storage Project captures and stores underground one million tonnes of CO2 emissions per year. The capture unit is located at the Scotford Upgrader in Alberta, Canada, where hydrogen is produced to upgrade bitumen from oil sands into synthetic crude oil.\n\nThe objective of the Weyburn-Midale Carbon Dioxide Project is to increase oil production and extend the oil field's lifetime through Enhanced Oil Recovery (EOR) by injecting the captured CO2 from the Dakota Gasification Company's Great Plains Synfuels Plant in North Dakota and SaskPower's coal-fired Boundary Dam Power Station in Saskatchewan, Canada into the Weyburn oilfields.\n\nSpectra Energy's Fort Nelson Project is proposed but still needs to secure funding. The total project cost is estimated to be US$12.5 million. The source of will be from the Fort Nelson Natural Gas Processing Plant and will be transported 15 km via an onshore pipeline to middle Devonian carbonate rock that is between 6500 and 7000 feet deep. The process will capture 2.2 Megatonne per year using an amine process in its pre-combustion capture. Injections and MVA Operations have already occurred (2014) and is projected to startup in 2018.\n\nLed by the provincially owned utility, SaskPower, one of the world's first and largest full production carbon capture facilities is operating at the coal fired Boundary Dam Power Station. With an initial investment of $1.5 to $1.6 billion. Of the 90% of CO2 emissions captured, about a half of this will be sold and permanently sequestered in enhanced oil recovery. The remainder is released into the atmosphere during capturing, and processing in the oil field. The project started in May 2011 and became operational in October 2014. The post-combustion full flue gas capture process was to capture 1 million tonnes of a year. Since opening serious design issues were found in the carbon capture system, resulting in maintenance problems that led to operating only 40% of the time. In 2016 the contracts to sell CO2 were renegotiated to reflect the reduced sales.\n\nThe Alberta Saline Aquifer Project (ASAP), Husky Upgrader and Ethanol Plant pilot, Heartland Area Redwater Project (HARP), Wabamun Area Sequestration Project(WASP), and Aquistore.\n\nAnother Canadian initiative is the Integrated Network (IN), a group of industry participants providing a framework for carbon capture and storage development in Canada.\nOther Canadian organizations related to CCS include CCS 101, Carbon Management Canada, IPAC , and the Canadian Clean Power Coalition.\n\nIn the Netherlands, a 68-megawatt oxyfuel plant (\"Zero Emission Power Plant\") was being planned to be operational in 2009. This project was later canceled.\n\nROAD (Rotterdam Capture and Storage Demonstration project) is a joint project by E.ON Benelux and Electrabel Nederland / GDF SUEZ Group. Every year, starting in 2015 ROAD will capture around 1.1 million tonnes of at the new power plant on the Maasvlakte. This will be stored in depleted gas reservoirs under the North Sea. Pending financial approval, the plant hopes to be operational sometime after 2019. But due to uncertainty of the continuance of coal-fired power plant in the Netherlands, the ROAD project is cancelled\n\nDeveloped in the Netherlands, an electrocatalysis by a copper complex helps reduce carbon dioxide to oxalic acid.\n\nIn Norway, the Technology Centre (TCM) at Mongstad began construction in 2009, and completed in 2012. It includes two capture technology plants (one advanced amine and one chilled ammonia), both capturing fluegas from two sources. This includes a gas-fired power plant and refinery cracker fluegas (similar to coal-fired power plant fluegas).\n\nIn addition to this, the Mongstad site was also planned to have a full-scale CCS demonstration plant. The project was delayed to 2014, 2018, and then indefinitely. The project cost rose to US$985 million.\nThen in October 2011, Aker Solutions' wrote off its investment in Aker Clean Carbon, declaring the carbon sequestration market to be \"dead\".\n\nOn 1 October 2013 Norway asked Gassnova not to sign any contracts for Carbon capture and storage outside Mongstad.\n\nIn 2015 Norway was reviewing feasibility studies and hoping to have a full-scale carbon capture demonstration project by 2020.\n\nIn Belchatów, Poland,<ref name=\"https://www.ccsnetwork.eu\"></ref> a lignite-fired energy plant of more than 858 MW is planned to be in operation in 2013.\n\nIn November 2008, the DOE awarded a $66.9 million eight-year grant to a research partnership headed by Montana State University to demonstrate that underground geologic formations \"can store huge volumes of carbon dioxide economically, safely and permanently\". Researchers under the Big Sky Regional Carbon Sequestration Project plan to inject up to one million tonnes of into sandstone beneath southwestern Wyoming.\n\nIn the United States, four different synthetic fuel projects are moving forward, which have publicly announced plans to incorporate carbon capture and storage:\n\n\nIn October 2009, the U.S. Department of Energy awarded grants to twelve Industrial Carbon Capture and Storage (ICCS) projects to conduct a Phase 1 feasibility study. The DOE plans to select 3 to 4 of those projects to proceed into Phase 2, design and construction, with operational startup to occur by 2015. Battelle Memorial Institute, Pacific Northwest Division, Boise, Inc., and Fluor Corporation are studying a CCS system for capture and storage of emissions associated with the pulp and paper production industry. The site of the study is the Boise White Paper L.L.C. paper mill located near the township of Wallula in Southeastern Washington State. The plant generates approximately 1.2 MMT of annually from a set of three recovery boilers that are mainly fired with black liquor, a recycled byproduct formed during the pulping of wood for paper-making. Fluor Corporation will design a customized version of their Econamine Plus carbon capture technology. The Fluor system also will be designed to remove residual quantities of remnant air pollutants from stack gases as part of the capture process. Battelle is leading preparation of an Environmental Information Volume (EIV) for the entire project, including geologic storage of the captured in deep flood basalt formations that exist in the greater region. The EIV will describe the necessary site characterization work, sequestration system infrastructure, and monitoring program to support permanent sequestration of the captured at the plant.\n\nIn addition to individual carbon capture and sequestration projects, there are a number of U.S. programs designed to research, develop, and deploy CCS technologies on a broad scale. These include the National Energy Technology Laboratory's (NETL) Carbon Sequestration Program, regional carbon sequestration partnerships and the Carbon Sequestration Leadership Forum (CSLF).\n\nIn October 2007, the Bureau of Economic Geology at the University of Texas at Austin received a 10-year, $38 million subcontract to conduct the first intensively monitored long-term project in the United States studying the feasibility of injecting a large volume of for underground storage. The project is a research program of the Southeast Regional Carbon Sequestration Partnership (SECARB), funded by the National Energy Technology Laboratory of the U.S. Department of Energy (DOE).\n\nThe SECARB partnership will demonstrate injection rate and storage capacity in the Tuscaloosa-Woodbine geologic system that stretches from Texas to Florida. The region has the potential to store more than 200 billion tons of from major point sources in the region, equal to about 33 years of overall U.S. emissions at present rates. Beginning in fall 2007, the project will inject at the rate of one million tons per year, for up to 1.5 years, into brine up to 10,000 feet (3,000 m) below the land surface near the Cranfield oil field, which lays about east of Natchez, Mississippi. Experimental equipment will measure the ability of the subsurface to accept and retain .\n\nThe $1.4 billion FutureGen power generation and carbon sequestration demonstration project, announced in 2003 by President George W. Bush, was cancelled in 2015, due to delays and inability to raise required private funding.\n\nThe Kemper Project, is a natural gas-fired power plant under construction in Kemper County, Mississippi, which was originally planned as a coal-fired plant. Mississippi Power, a subsidiary of Southern Company, began construction of the plant in 2010. The project was considered central to President Obama's Climate Plan. Had it become operational as a coal plant, the Kemper Project would have been a first-of-its-kind electricity plant to employ gasification and carbon capture technologies at this scale. The emission target was to reduce CO2 to the same level an equivalent natural gas plant would produce. However, in June 2017 the proponents - Southern Company and Mississippi Power - announced that they would only burn natural gas at the plant at this time.\n\nThe plant experienced project management problems. Construction was delayed and the scheduled opening was pushed back over two years, at a cost of $6.6 billion—three times original cost estimate. According to a Sierra Club analysis, Kemper is the most expensive power plant ever built for the watts of electricity it will generate.\n\nThe Texas Clean Energy Project (TCEP) is a \"NowGen\" Integrated Gasification Combined Cycle (IGCC) facility that will incorporate carbon capture, utilization and storage (CCUS) technology in a first-of-its-kind commercial clean coal power plant. This project is expected to be operational in 2018. It will be the first US-based power plant to combine both IGCC and capture 90% of its emissions.\n\nExamples of carbon sequestration at an existing US coal plant can be found at utility company Luminant's pilot version at its Big Brown Steam Electric Station in Fairfield, Texas. This system is converting carbon from smokestacks into baking soda. Skyonic plans to circumvent storage problems of liquid by storing baking soda in mines, landfills, to be sold as industrial or food grade baking soda, Green Fuel Technologies is piloting and implementing algae based carbon capture, circumventing storage issues by then converting algae into fuel or feed, though this may lead to re-release of the carbon.\n\nThe government of the United Kingdom launched a first tender process for a CCS demonstration project in 2007. The project were to use post-combustion technology on coal-fired power generation at 300–400 megawatts or equivalent. The project aimed to be operational by 2014. The Government announced in June 2008 that four companies had pre-qualified for the competition: BP Alternative Energy International Limited, EON UK Plc, Peel Power Limited and Scottish Power Generation Limited. BP subsequently withdrew from the competition, claiming it could not find a power generator partner, and RWE npower sought a judicial review of the process after it did not qualify. This first CCS tender was cancelled in late 2011 when government could not reach agreement with the ScottishPower/Shell/National Grid consortium on terms and cost, for the project based on retrofitting the existing Longannet coal-fired power station in Scotland.\n\nA second tender process was launched by government in 2012 as part of DECC's CCS Commercialisation Programme and two bidders, namely the Shell Peterhead gas-fired power station CCS project and the White Rose CCS project based upon a new oxy-fuel coal-fired unit at Drax power station were selected in 2013 to proceed to a funded front-end engineering and design phase. This second tender was cancelled in November 2015 following a government spending review at the time of the Chancellor's Autumn Statement.\n\nDoosan Babcock has modified their Clean Combustion Test Facility (CCTF) in Renfrew, Scotland to create the largest Oxyfuel test facility currently in the world. Oxyfuel firing on pulverized coal with recycled flue gas demonstrates the operation of a full scale 40 MW burner for use in coal-fired boilers. Sponsors of the project include the UK Department for Business Enterprise and Regulatory Reform (BERR,) as well as a group of industrial sponsors and university partners comprising Scottish and Southern Energy (Prime Sponsor), E.ON UK PLC, Drax Power Limited, ScottishPower, EDF Energy, Dong Energy Generation, Air Products Plc (Sponsors), and Imperial College and University of Nottingham (University Partners).\n\nIn 2009 UK firm 2Co Energy was awarded planning permission for a £5bn power station and carbon-capture-and-storage project at Hatfield, near Doncaster and £164m of EU funding. Technology company Samsung agreed to take a 15% stake in the project. It is planned to construct a pipeline from Stainforth, near Hatfield in South Yorkshire to Barmston in the East Riding of Yorkshire. would then be stored in natural porous rock beneath the North Sea. National Grid believes the project has the potential to reduce emissions from power stations across Yorkshire and the Humber by up to 90% and both the proposed White Rose CCS project at Drax Power Station in North Yorkshire and the proposed Don Valley Power Project at Hatfield could benefit from the scheme.\n\nIn the Northeast of England, The Northeast of England Process Industry Cluster (NEPIC) of commodity chemical manufacturers are amongst the largest single point producers of carbon dioxide in the United Kingdom and they have created within NEPIC the Process Industry Carbon Capture and Storage Initiative (PICCSI) to study the possibility of a carbon capture and storage (CCS) solution being provided for the chemical and steel manufacturing industry on Teesside, as well as for any carbon based energy production. This CCS technology option is being considered as a result of climate change regulations and the carbon taxation that could become a prohibitive cost for such energy intensive industries.\n\nThe Crown Estate is responsible for storage rights on the UK continental shelf and it has facilitated work on offshore carbon dioxide storage technical and commercial issues.\n\nIn Beijing, as of 2009, one major power plant is capturing and re-selling a small fraction of its emissions. Technologies like CCS result in uncertainties that also need to be monitored. Interval fuzzy stochastic programming(IFSP) is used to deal with the multiple uncertainties that may arise in the research of CCS technology.Currently an IFSP for CCS is used in planning CCS in Bayingolin. The results reveal that CCs technology can help lower carbon dioxide emissions in a long term scale.\n\nThe German industrial area of Schwarze Pumpe, about south of the city of Spremberg, is home to the world's first demonstration CCS coal plant, the Schwarze Pumpe power station. The mini pilot plant is run by an Alstom-built oxy-fuel boiler and is also equipped with a flue gas cleaning facility to remove fly ash and sulphur dioxide. The Swedish company Vattenfall AB invested some €70 million in the two-year project, which began operation September 9, 2008. The power plant, which is rated at 30 megawatts, is a pilot project to serve as a prototype for future full-scale power plants. 240 tonnes a day of are being trucked where it will be injected into an empty gas field. Germany's BUND group called it a \"fig leaf\". For each tonne of coal burned, 3.6 tonnes of carbon dioxide is produced. The CCS program at Schwarze Pumpe ended in 2014 due to inviable costs and energy use.\n\nGerman utility RWE operates a pilot-scale scrubber at the lignite-fired Niederaußem power station built in cooperation with BASF (supplier of detergent) and Linde engineering.\n\nIn Jänschwalde, Germany, a plan is in the works for an Oxyfuel boiler, rated at 650 thermal MW (around 250 electric MW), which is about 20 times more than Vattenfall's 30 MW pilot plant under construction, and compares to today's largest Oxyfuel test rigs of 0.5 MW. Post-combustion capture technology will also be demonstrated at Jänschwalde.\n\nThe Federal Resources and Energy Minister Martin Ferguson opened the first geosequestration project in the southern hemisphere in April 2008. The demonstration plant is near Nirranda South in South Western Victoria. () The plant is owned by CO2CRC Limited. CO2CRC is a non profit research collaboration supported by government and industry. The project has stored and monitored over 80,000 tonnes of carbon dioxide-rich gas which was extracted from a natural gas reservoir via a well, compressed and piped 2.25 km to a new well. There the gas has been injected into a depleted natural gas reservoir approximately two kilometers below the surface. The project has moved to a second stage and is investigating carbon dioxide trapping in a saline aquifer 1500 meters below the surface. The Otway Project is a research and demonstration project, focused on comprehensive monitoring and verification.\n\nThis plant does not propose to capture from coal-fired power generation, though two CO2CRC demonstration projects at a Victorian power station and research gasifier are demonstrating solvent, membrane, and adsorbent capture technologies from coal combustion. Currently, only small-scale projects are storing stripped from the products of combustion of coal burnt for electricity generation at coal-fired power stations. Work currently being carried out by the GreenMag Group and the University of Newcastle and funded by the New South Wales and Australian Governments and industry intends to have a working mineral carbonation pilot plant in operation by 2013.\n\nThe Gorgon Carbon Dioxide Injection Project is part of the Gorgon Project, the world's largest natural gas project. The Gorgon Project, located on Barrow Island in Western Australia, includes a liquefied natural gas (LNG) plant, a domestic gas plant, and a Carbon Dioxide Injection Project.\n\nThe initial carbon dioxide injections were planned to take place by the end of 2017. Once launched, the Gorgon Carbon Dioxide Injection Project will be the world's largest injection plant, with an ability to store up to 4 million tons of per year – approximately 120 million tons over the project's lifetime, and 40 percent of total Gorgon Project emissions.\n\nThe project started extracting gas in February 2017, but carbon capture and storage is now not expected to begin until the first half of 2019, requiring a further five million tonnes of to be released, because:\n\nTerraforming the planet Venus by removing CO from the atmosphere was first scholarly proposed by the astronomer Carl Sagan in 1961, although fictional treatments, such as \"The Big Rain\" of The Psychotechnic League by novelist Poul Anderson, preceded it. Adjustments to the existing environment of Venus to support human life would require at least three major changes to the planet's atmosphere: Reducing Venus's surface temperature of , eliminating most of the planet's dense carbon dioxide and sulfur dioxide atmosphere via removal or conversion to some other form, and the addition of breathable oxygen to the atmosphere. These three changes are closely interrelated, because Venus's extreme temperature is due to the high pressure of its dense atmosphere, and the greenhouse effect.\n\nCritics say large-scale CCS deployment is unproven and decades away from being commercialized. They say that it is risky and expensive and that a better option is renewable energy. Some environmental groups point out that CCS technology leaves behind dangerous waste material that has to be stored, just like nuclear power stations.\n\nAnother limitation of CCS is its energy penalty - the reduction in overall plant efficiency due to the carbon capturing process. It has been estimated that about 60% of the energy penalty originates from the capture process itself, 30% comes from compression of , while the remaining 10% comes from electricity requirements for necessary pumps and fans. CCS technology is expected to use between 10 and 40 percent of the energy produced by a power station.\n\nWide-scale adoption of CCS may erase efficiency gains in coal power plants of the last 50 years, and increase resource consumption by one third. Even taking the fuel penalty into account, however, overall levels of abatement would remain high at approximately 80–90%, compared to a plant without CCS. It is possible for CCS, when combined with biomass, to result in net negative emissions. Though, all of the currently (as of Feb 2011) operational BECCS (Bio-energy with carbon capture and storage) plants operate on point emissions other than power stations, such as biofuel refineries.\n\nThe use of CCS can reduce emissions from the stacks of coal power plants by 85–90% or more, but it has no effect on emissions due to the mining and transport of coal. It will actually \"increase such emissions and of air pollutants per unit of net delivered power and will increase all ecological, land-use, air-pollution, and water-pollution impacts from coal mining, transport, and processing, because the CCS system requires 25% more energy, thus 25% more coal combustion, than does a system without CCS\".\n\nAnother concern regards the permanence of storage schemes. Opponents to CCS claim that safe and permanent storage of cannot be guaranteed and that even very low leakage rates could undermine any climate mitigation effect. In 1986 a large leakage of naturally sequestered rose from Lake Nyos in Cameroon and asphyxiated 1,700 people. While the carbon had been sequestered naturally, some point to the event as evidence for the potentially catastrophic effects of sequestering carbon artificially.\n\nOn one hand, Greenpeace claims that CCS could lead to a doubling of coal plant costs. It is also claimed by opponents to CCS that money spent on CCS will divert investments away from other solutions to climate change. On the other hand, CCS is pointed out as economically attractive in comparison to other forms of low carbon electricity generation and seen by the IPCC and others as a critical component for meeting mitigation targets such as 450 ppm and 350 ppm.\n\nAlthough the processes involved in CCS have been demonstrated in other industrial applications, no commercial scale projects which integrate these processes exist; the costs therefore are somewhat uncertain. Some recent credible estimates indicate that the cost of capturing and storing carbon dioxide is US$60 per ton, corresponding to an increase in electricity prices of about US 6c per kWh (based on typical coal-fired power plant emissions of per kWh). This would double the typical US industrial electricity price (now at around 6c per kWh) and increase the typical retail residential electricity price by about 50% (assuming 100% of power is from coal, which may not necessarily be the case, as this varies from state to state). Similar (approximate) price increases would likely be expected in coal dependent countries such as Australia, because the capture technology and chemistry, as well as the transport and injection costs from such power plants would not, in an overall sense, vary significantly from country to country.\n\nThe reasons that CCS is expected to cause such power price increases are several. Firstly, the increased energy requirements of capturing and compressing significantly raises the operating costs of CCS-equipped power plants. In addition, there are added investment and capital costs. The process would increase the fuel requirement of a plant with CCS by about 25% for a coal-fired plant, and about 15% for a gas-fired plant. The cost of this extra fuel, as well as storage and other system costs, are estimated to increase the costs of energy from a power plant with CCS by 30–60%, depending on the specific circumstances. Pre-commercial CCS demonstration projects are likely to be more expensive than mature CCS technology; the total additional costs of an early large-scale CCS demonstration project are estimated to be €0.5-1.1 billion per project over the project lifetime. Other applications are possible. In the belief that use of sequestered carbon could be harnessed to offset the cost of capture and storage, Walker Architects published the first gas CAES application, proposing the use of sequestered for Energy Storage on October 24, 2008. To date the feasibility of such potential offsets to the cost have not been examined.\n\nThe cost of CCS depends on the cost of capture and storage, which varies according to the method used. Geological storage in saline formations or depleted oil or gas fields typically cost US$0.50–8.00 per tonne of injected, plus an additional US$0.10–0.30 for monitoring costs. When storage is combined with enhanced oil recovery to extract extra oil from an oil field, however, the storage could yield net benefits of US$10–16 per tonne of injected (based on 2003 oil prices). This would likely negate some of the effect of the carbon capture when the oil was burnt as fuel. Even taking this into account, as the table above shows, the benefits do not outweigh the extra costs of capture.\n\nCost of electricity generated by different sources including those incorporating CCS technologies can be found in cost of electricity by source.\nIf capture was part of a fuel cycle then the would have value rather than be a cost. The proposed Solar Fuel or methane cycle proposed by the Fraunhofer Society amongst others is an example. This \"solar fuel\" cycle uses the excess electrical renewable energy to create hydrogen via electrolysis of water. The hydrogen is then combined with to create synthetic natural gas SNG and stored in the gas network. See the latest Cost Report on the Cost of Capture produced by the Zero Emissions Platform\n\nGovernments around the world have provided a range of different types of funding support to CCS demonstration projects, including tax credits, allocations and grants. The funding is associated with both a desire to accelerate innovation activities for CCS as a low-carbon technology and the need for economic stimulus activities. As of 2011, approximately US$23.5bn has been made available to support large-scale CCS demonstration projects around the world.\n\nOne way to finance future CCS projects could be through the Clean Development Mechanism of the Kyoto Protocol. At COP16 in 2010, The Subsidiary Body for Scientific and Technological Advice, at its thirty-third session, issued a draft document recommending the inclusion of Carbon dioxide capture and storage in geological formations in Clean Development Mechanism project activities. At COP17 in Durban, a final agreement was reached enabling CCS projects to receive support through the Clean Development Mechanism.\n\nThe theoretical merit of CCS systems is the reduction of emissions by up to 90%, depending on plant type. Generally, environmental effects from use of CCS arise during power production, capture, transport, and storage. Issues relating to storage are discussed in those sections.\n\nAdditional energy is required for capture, and this means that substantially more fuel has to be used to produce the same amount of power, depending on the plant type. For new super-critical pulverized coal (PC) plants using current technology, the extra energy requirements range from 24 to 40%, while for natural gas combined cycle (NGCC) plants the range is 11–22% and for coal-based gasification combined cycle (IGCC) systems it is 14–25% [IPCC, 2005]. Obviously, fuel use and environmental problems arising from mining and extraction of coal or gas increase accordingly. Plants equipped with flue-gas desulfurization (FGD) systems for sulfur dioxide control require proportionally greater amounts of limestone, and systems equipped with selective catalytic reduction systems for nitrogen oxides produced during combustion require proportionally greater amounts of ammonia.\n\nIPCC has provided estimates of air emissions from various CCS plant designs (see table below). While is drastically reduced though never completely captured, emissions of air pollutants increase significantly, generally due to the energy penalty of capture. Hence, the use of CCS entails a reduction in air quality. Type and amount of air pollutants still depends on technology. is captured with alkaline solvents catching the acidic at low temperatures in the absorber and releasing at higher temperatures in a desorber. Chilled Ammonia CCS Plants have inevitable ammonia emissions to air. \"Functionalized Ammonia\" emit less ammonia, but amines may form secondary amines and these will emit volatile nitrosamines by a side reaction with nitrogendioxide, which is present in any flue gas even after DeNOx. Nevertheless, there are advanced amines in testing with little to no vapor pressure to avoid these amine- and consecutive nitrosamine emissions. Nevertheless, all the capture plants amines have in common, that practically 100% of remaining sulfur dioxide from the plant is washed out of the flue gas, the same applies to dust/ash.\n\n\n"}
{"id": "337070", "url": "https://en.wikipedia.org/wiki?curid=337070", "title": "Charles Greeley Abbot", "text": "Charles Greeley Abbot\n\nCharles Greeley Abbot (May 31, 1872 – December 17, 1973) was an American astrophysicist and the fifth secretary of the Smithsonian Institution, serving from 1928 until 1944. Abbot went from being director of the Smithsonian Astrophysical Observatory, to becoming Assistant Secretary, and then Secretary of the Smithsonian Institution over the course of his career. As an astrophysicist, he researched the solar constant, research that led him to invent the solar cooker, solar boiler, solar still, and other patented solar energy inventions.\n\nCharles Greeley Abbot was born in Wilton, New Hampshire. His parents were farmers and he was the youngest of four children. As a youth he built and invented numerous things, such as a forge to fix tools, a water wheel to power a saw, and a bicycle. He dropped out of school when he was 13 to become a carpenter. Two years later he went back to high school. He attended Phillips Andover Academy. \nWhen a friend of his went to Boston to take the entrance exam to get into the Massachusetts Institute of Technology, Abbot went for the chance to visit Boston. However, upon arrival, he was uncomfortable visiting Boston alone and chose to take the exam instead. He passed and his family gathered the funds to send him to MIT for one year. He started out studying chemical engineering, but eventually moved on to physics.\n\nHe would graduate in 1894 with a Master of Science in physics. Abbot would meet Samuel P. Langley on MIT campus when Langley visited seeking an assistant. In 1895, he would start working as an aid at the Smithsonian Astrophysical Observatory.\n\nWhile at the Smithsonian Astrophysical Observatory (SAO), Abbot would work under Samuel P. Langley. Langley would go on to change his focus from solar radiation to aeronautics, with Abbot taking over solar radiation research. Abbot would participate in many expeditions. In 1900 he, along with Langley, would travel to Wadesboro, North Carolina to observe a solar eclipse, followed by another eclipse expedition to Sumatra in 1901. During his expedition experiences he would also travel to Algeria, Egypt, South Africa, Australia, and other countries, often in partnership with the National Geographic Society. Abbot would become acting director of SAO in 1906 and in 1907, Abbot became the Director of the Smithsonian Astrophysical Observatory, following the death of Samuel P. Langley. While Langley was still Director, he had visited Mount Whitney, and decided it would be a great place for an observatory. Abbot secured funding for the observatory and it was built in 1909. As Director, a position he would hold until his retirement, Abbot would open the Radiation Biology Laboratory in 1929, to study radiation effects on plants, and other organisms. This helped to develop the first wave of biophysics researchers in the United States.\n\nAbbot would become the Assistant Secretary at the Smithsonian Institution in 1918, upon the death of Frederick W. True. In his role as Assistant Secretary he would oversee the Smithsonian Institution Libraries, the International Exchange Service, and the SAO. He also co-created the \"Smithsonian Scientific Series\" books, which helped raise funds for the Smithsonian.\n\nTen years later, on January 10, 1928, he became the fifth Secretary of the Smithsonian after the death of Charles Doolittle Walcott. Abbot would also maintain his position as Director of the Astrophysical Observatory. In 1927, Walcott had finalized the Smithsonian's strategic plan, which Abbot took on responsibility for upon his election as Secretary. The Smithsonian began a capital campaign in 1929, coinciding with the start of the Great Depression. During this tenure, Abbot oversaw the Smithsonian's participation in Works Progress Administration projects, including the Federal Art Project. Projects included new buildings and artwork at the National Zoo, and the start of the Smithsonian's first media project, a radio show called \"The World is Yours\". The program would be ceased in 1942 due to World War II. In the 1930s an expansion was approved for the National Museum of Natural History building, which would not begin until the 1960s. The Institute for Social Anthropology was also transferred to the Smithsonian during this time. While Secretary, Abbot would fail to acquire the National Gallery of Art for the Smithsonian. Abbot's role in the United States National Museum was also minimal, and was under the primary care of Assistant Secretary Alexander Wetmore.\n\nHe was the first Smithsonian Secretary to retire, ending his tenure on July 1, 1944. Following retirement, he was awarded Secretary Emeritus status and proceeded to continue his research work. The first Smithsonian holiday party would be held during his tenure. At the party, Abbot sang and played the cello for the partygoers. While in Washington, he was a deacon at the First Congregational Church. He also played tennis frequently at the former tennis courts at the Smithsonian Castle.\n\nOn May 31, 1955, the Smithsonian held a birthday party for Abbot, marking his 83rd birthday and his 60th year of association with the Smithsonian. The event was held at the Smithsonian Castle and a bronze bust of Abbot, by Alicia Neatherly, was presented, and donated to the National Gallery of Art. Charles Greeley Abbot died, at age 101 in Maryland, on December 17, 1973. The American Solar Energy Society has an award named in Abbot's honor, which is awarded for contributions to solar energy research.\n\nThe Abbot crater on the Moon has been named after him.\n\nAbbot began his astrophysics research focusing on solar radiation before proceeding to chart cyclic patterns found in solar variations. With this research he hoped to track solar constant in order to make weather pattern predictions. He believed that the sun was a variable star which effected the weather on Earth, which was criticized by many contemporaries. In 1953, he discovered a connection between solar variations and planetary climate. This discovery allowed general climate patterns to be predicted 50 years in advance. He did field work at the Smithsonian Institution Shelter, which was built during his tenure as director at SAO, Lick Observatory, and Mount Wilson Observatory. At Lick, he worked with W.W. Campbell. To fight critics, Abbot would utilize balloons with pyrheliometers installed on them for measurements. He was the first scientist in America to do so, with the balloons reaching upwards of 25 kilometers. One balloon returned data that allowed Abbot to determine the solar constant at the highest point of the Earth's atmosphere. Later in his research career, he turned his focus on solar energy use.\n\nAn instrumentalist, he invented the solar cooker, which was first built at Mount Wilson Observatory, the solar boiler, and held fifteen other patents related to solar energy. For his research and contributions to the sciences, Abbot was awarded a Henry Draper Medal in 1910 and a Rumford Medal in 1916.\n\n\n\n"}
{"id": "873136", "url": "https://en.wikipedia.org/wiki?curid=873136", "title": "Chrysler Sebring", "text": "Chrysler Sebring\n\nThe Chrysler Sebring ( ) is a line of mid-size luxury automobiles that was sold from 1995 through 2010 by Chrysler. Three generations of convertibles, two generations of sedans, and two generations of coupes were produced. Although the coupe shared the same name and some styling cues, it was mechanically unrelated to the other Sebring models.\n\nThe Sebring line was introduced in 1995 with the Chrysler Sebring coupe. It was the replacement for the Chrysler LeBaron coupe. In 1996 the convertible was introduced, replacing its LeBaron counterpart as well. For 2001, both body styles were redesigned and a sedan version was offered, replacing the Chrysler Cirrus. The coupe was discontinued after 2005 with no replacement model planned.\n\nThe redesigned sedan was introduced for 2007, and a convertible the following year. New options included all-wheel drive on sedans and a hardtop for the convertible. All Sebring models were replaced by the Chrysler 200 for the 2011 model year.\n\nThe Chrysler Sebring was introduced as a coupe for 1995, and as a convertible in 1996, both models replacing the Chrysler LeBaron convertible and coupe. The convertible was built off the Chrysler JA platform also used for the Cirrus sedan, while the coupe was based on the Mitsubishi Eclipse. The Chrysler Sebring was named after Sebring, Florida, the site of the renowned endurance car race called the \"12 Hours of Sebring\". The name was first used by Chrysler Corporation's Plymouth division trim line of the Satellite mid-size coupe of the 1970s.\n\nThe 1995 through 2000 Chrysler Sebring coupe was the successor to the Chrysler LeBaron coupe.\n\nThe first generation Sebring coupe was introduced in April 1995, several months after the related Dodge Avenger. Despite its similarities to the Avenger, the Chrysler's suspension was tuned slightly on the softer side compared to Dodge's stiff suspension. Although the Sebring did not really offer true \"off-the-line\" muscle, it did handle well over long, curvy roads, offering minimal body roll. LXi models further benefited from rear sway bars, a slightly different tuned fully independent suspension, along with 17-inch wheels wrapped with Goodyear Eagle performance tires. Recorded slalom speeds proved to be impressive for a car of its class, and were a result of Sebring's 4-wheel double wishbone suspension and variable speed rack and pinion steering; both of which were key contributors to the car's road manners.\n\nThe coupe version of the Sebring had seating for five and was considered to be one of the larger, more roomy coupes on the market. Trunk capacity was similar to that of many mid-size cars, capable of handling more than one set of golf clubs. At the time of its introduction, the Sebring sported a crosshair grille, reminiscent of the original Chrysler 300 letter series. The grille was non-functional, with the lower half under the bumper used for air flow intake in a \"bottom breather\" function.\n\nAlthough said to be built on a stretched Eagle Talon platform (which is not entirely untrue), it is more accurate to say that their platform was based on the four-door Mitsubishi Galant platform. However, these cars do share a great deal with their Talon sibling, including much of their dash and instrument panel along with select suspension and steering components.\n\nThe Sebring underwent a minor facelift for 1997. Its grille was replaced with a slightly larger black grid. The facelift also made the Sebring the first car to use Chrysler's \"wings\" logo. The 1997 restyle also saw the addition of ribbed lower body cladding and new wheel styles.\n\nFeatures offered on Sebring coupes included 4-wheel disc brakes with ABS, adaptive automatic transmissions and fully independent suspensions, along with a host of power operated features. Sebring also offered variable speed rack and pinion steering, 17 inch aluminum wheels with GoodYear Eagle tires, 4-wheel double wishbone suspension, one-touch power windows, one-touch moonroof, electrochromic mirror with compass, power accessory delay ignition (which allowed occupants to operate power window switches when ignition is turned off), and Homelink universal transmitter, among other options.\n\nSebring coupe received a 5-star frontal safety rating, the highest rating possible.\n\nFirst generation bodystyle coupes continued to be sold past the 2000 model year to select export models\n\nTrim levels:\n\nThe Sebring convertible was launched in 1996 alongside the Sebring coupe, replacing the LeBaron convertible. The convertible didn't share any sheetmetal with the coupe and was instead based on the Chrysler Cirrus sedan. Consequently, both the Cirrus and Sebring convertible were sold in Europe as the Stratus. All Stratus convertibles were sourced from Mexico. The Chrysler Stratus convertible was actually available in Mexico, but the sedan version was not. The Sebring convertible was sold alongside with the Chrysler Stratus convertible in Mexico. In Mexico, a rare turbocharged 2.4 L DOHC I4 engine was optional.\n\nTrim levels:\n\nThe Sebring name was then used on three different cars for 2001: the coupe was based on the Mitsubishi Eclipse, while the sedan and convertible were Chrysler JR platform successors to the Chrysler Cirrus. The 2004 Chrysler Sebring had received minor tweaks to its front-end: a redesigned grille, re-worked headlights, and a Chrysler winged emblem placed in the center on the rear deck; furthermore, after the 2004 Chrysler Sebring sedan had seen a mild cycle refresh, the company discontinued the Chrysler Sebring coupe after model year 2005. And outside of the United States, and Canada, over into Mexico, the Sebring was sold as the Chrysler Cirrus. Exclusive for the Cirrus was the availability of Chrysler's turbocharged 2.4 L DOHC engine. The Cirrus available as a sedan, and convertible body-styles. Models with this engine are identified with a \"High Output\" badge on the back of the vehicle. Also unique to the Cirrus was the number of trim levels; the sedan was offered in two while the convertible was only offered in one. All were equipped with an automatic transmission.\n\nThe Insurance Institute for Highway Safety gives the 2001–2006 Sebring an \"Acceptable\" overall rating in frontal crash tests. In the side impact test, a \"Poor\" overall rating was given to models without side airbags. The IIHS did not test the Sebring with side airbags since Chrysler declined another test.\n\nFor 2001, the Sebring Convertible was redesigned. It now closely resembled the sedan, though it still differed greatly from it and the coupe. The front fascia and most of the interior were the only features that these cars had in common. Many interior and exterior components were carried over from the first-generation car, though the body shell underneath is significantly different. The Sebring received minor styling revisions (mostly the appearance of the nose) for the 2004 model year.\n\nA redesigned Sebring Coupe was introduced for the 2001 model year, based on the third generation Mitsubishi Eclipse. Like the previous generation, the coupe shared very little in common with the sedan or the convertible, other than the name and a few exterior styling cues to help market all three vehicles together as one model.\n\nThe Sebring Coupe received a minor facelift for 2003, and was discontinued after the 2005 model-year-year. The redesigned 2008 Chrysler Sebring convertible was considered the replacement for the Sebring coupe.\n\nChrysler also manufactured export versions of the 2001-2006 Sebring sedan and convertible for the mainland European market. Front and rear lights are to European standards, different from the USA & Canada in that turn-signal indicators are orange, with additional side-turn repeaters on the front fenders. The rear bumper has a larger recess for the longer European-size license plates, and two rear fog-lamps are fitted; one on each side of the license plate. The LHD headlamps incorporate Euro-type H4 bulbs, together with three-way up and down beam-level adjustment via a dash-mounted switch to the left of the steering wheel. Emissions controls are to the EURO 3 standard; later versions are compliant with EURO 4. Engine ranges offered were the 2.0 L DOHC 16V inline 4-cylinder (later replaced by the 2.4L unit in some countries), and the 2.7 L DOHC 24V 6-cylinder unit. The 2.0 and 2.4L engines are available with the 5-speed manual or four-speed 41TE auto transmission (depending on country); the six-cylinder engine is automatic only.\n\nThe Canadian-market 240 km/h-160 mph speedometer (with km/h predominant) is fitted to the European models. Odometer and tripmeter are in kilometres. As the 2001-2006 Sebring sedan and convertible were made in left-hand drive only, they were not sold in the UK and Ireland. Chrysler UK did however, import 50 convertibles with the 2.7L engine in 2001/2002, and these were sold though selected dealers. Being non-standard in Chrysler's UK range at the time though, no more were imported.\n\nTrim levels offered in Europe were LE (equivalent to North American market LX) and LX (equivalent to North American market LXi). From 2004, \"Touring\" and \"Limited\" versions started to replace the LE and LX designations respectively.\n\nLack of a diesel engine and right-hand drive availability prevented this Sebring from being a true pan-European model unlike other Chryslers such as the PT Cruiser and Voyager. In addition, the model was dropped from Chrysler's lineup in some countries, notably France, before production ended in 2006. In France, the three domestic car-makers PSA-Peugeot, Citroen and Renault dominate the new car market, which meant very low sales of the Sebring there. As a result, the sedan was only imported by Chrysler France in 2001 and 2002. The 2003 and facelifted 2004–2006 year models were not. The convertible was only sold until 2004. The 2005 and 2006 models were likewise not imported.\n\nDespite not being available in the UK and Ireland, some Sebring convertibles have been bought in from the U.S. as grey-imports. Some Euro-spec models have also been privately imported, mostly from Germany. The European versions are easier to re-register in the UK as they have EU-type approval. The dual km/h-mph speedo-display and twin rear foglights mean only headlamp beam-aim adjustment for left-hand traffic is necessary. The sedan is much rarer in the UK though; a few EU models have been imported, but most are likely to be North American 'grey-imports'.\n\n\nNote: Additional packages could be added to various standard trim levels.\n\nIn 2006, the license, tooling and assembly line for the second-generation Chrysler Sebring/Dodge Stratus sedan was sold to Russian firm GAZ for about US$151 million (€ 124 million). After some minor modifications the vehicle was renamed the Volga Siber. It went into production in March 2008 at the Gorky Automobile Plant in Nizhny Novgorod, Russia. However, due to the Great Recession sales were not as expected and production ended in 2010 after 9,000 examples were built.\n\nThe Sebring was replaced with a new model based on the JS platform for the 2007 model year. The third-generation Sebring was assembled in Sterling Heights, Michigan, containing over 82% of parts sourced in North America.\n\nBecause no 2007 convertible was offered, the 2006 Sebring convertible was left to fill the void, remaining in showrooms and on the company's website until the 2008 model's release.\n\nThe third-generation Sebring borrowed many styling cues from the 2003 Chrysler Airflite concept. It also has several Chrysler-signature styling cues, several of which were borrowed from the Chrysler Crossfire. The Sebring sedan and convertible were also sold in right-hand drive through Chrysler's UK and Ireland dealer network.\n\nChrysler offered three engines for the 2007 Sebring; the GEMA I4, the EER V6, and the EGF V6. The 3.5 L V6 is coupled to Chrysler's first ever six-speed automatic transmission, which employs Autostick technology, and the 2.7 L V6 is capable of running on cleaner-burning E85. Export vehicles will be offered with a 2.0 L turbocharged PDTDI (pumpe düse) diesel made by Volkswagen and the 2.0 L GEMA engine. The 3.5 L V6 sedan is available with all-wheel drive as an extra cost option for 2008 only.\n\nTrim levels:\n\nIn 2008, the optional \"MyGIG Multimedia Infotainment System\" became available. In addition, the Limited got the 2.4-litre four-cylinder engine and was priced at the same level as the 2008 Touring model. Also for 2009, the Sebring got rear badge placements modified slightly. For model year 2010, the hood was redesigned, eliminating the longitudinal grooves.\n\nThe IIHS gave the 2010 Models a G for good in the frontal crash test, the side impact test, and the roof strength test, giving the 2010 Sebring a \"Top Safety Pick\".\n\nFor the 2008 model year, the Sebring convertible was redesigned with hood strakes recalling the Chrysler Crossfire. The new convertible body style debuted at the 2007 Los Angeles International Auto Show as an early-2008 model. It was the bestselling four-place open-top cars in the United States, trailing only the Ford Mustang convertible.\n\nThe new convertible offered both a retractable hardtop and soft tops, with the Sebring's roofs manufactured by Karmann. A vinyl top came on the base LX model, a cloth roof on the Touring and Limited models with the option of a retractable metal hardtop. The convertible top retracts into the trunk with a power tonneau cover and a luggage protector for the top. The top can also be retracted with the remote keyless entry, meaning the top can be stowed without being inside the car or starting the engine.\n\nThe LX model included a new 2.4 L I4 engine, the Touring version came with a retuned version of the 2.7 L V6, while the Limited featured a new 3.5 L V6. Unlike the Sebring sedan, the convertible was not available in all-wheel drive.\n\nProduction of the Chrysler Sebring sedan for the China market began in 2007 at the Beijing-Benz DaimlerChrysler Automotive Co. (BBDC) in Beijing. BBDC is a joint venture between the Beijing Automotive Industry Holding and Chrysler.\n\nProduction of the Sebring leveraged assembly capacity for the new BBDC plant which also built the Chrysler 300C, the Mercedes-Benz E-Class and Mitsubishi Outlander.\nFour-cylinder World Engines for the Sebring were built at the Global Engine Manufacturing Alliance (GEMA) plant in Dundee, Michigan for export to China. GEMA began as a joint venture of Chrysler, Mitsubishi, and Hyundai. Since 2009, GEMA is wholly owned by Chrysler.\n\nChrysler introduced this generation Sebring to Europe (including right-hand drive markets) as their first competitor in the D-segment. It received a generally unfavorable reception from European motoring journalists.\n\n\nThe Chrysler Sebring was extensively refreshed in 2010, but was rebadged as the Chrysler 200. The JS platform and bodyshell had been retained, but there were extensive cosmetic and powertrain changes to the vehicle. The name change helped distance the vehicle from the Sebring's reputation for quality issues and fleet pervasiveness.\n\n"}
{"id": "1634911", "url": "https://en.wikipedia.org/wiki?curid=1634911", "title": "Colocasia esculenta", "text": "Colocasia esculenta\n\nColocasia esculenta is a tropical plant grown primarily for its edible corms, the root vegetables most commonly known as taro (). It is the most widely cultivated species of several plants in the Araceae family which are used as vegetables for their corms, leaves, and petioles. Taro corms are a food staple in African, Oceanic and South Asian cultures, and taro is believed to have been one of the earliest cultivated plants.\n\nThis plant and its root is generally called taro, but it has different names in different countries like for instance eddoe, or . The plant is called \"tales\" in Java, \"taro\" in Tahiti, \"ndalo\" in Fiji, \"talo\" in Samoa, \"colcas\" () in Arabic, \"kolokasi\" or \"kolokas\" in Cyprus, \"kalo\" in Hawaii and \"amateke\" in Rwanda. Taro is often referred to as \"elephant ears\" when grown as an ornamental plant.\n\nLinnaeus originally described two species, \"Colocasia esculenta\" and \"Colocasia antiquorum\" but many later botanists consider them both to be members of a single, very variable species, the correct name for which is \"Colocasia esculenta\". The specific epithet, \"\", means \"edible\" in Latin.\n\nTaro is related to \"Xanthosoma\" and \"Caladium\", plants commonly grown ornamentally, and like them it is sometimes loosely called elephant ear. Similar taro varieties include giant taro (\"Alocasia macrorrhizos\"), swamp taro (\"Cyrtosperma merkusii\"), and arrowleaf elephant's ear (\"Xanthosoma sagittifolium\").\n\n\"Colocasia esculenta\" is a perennial, tropical plant primarily grown as a root vegetable for its edible, starchy corm. The plant has rhizomes of different shapes and sizes. Leaves are up to and sprout from the rhizome. They are dark green above and light green beneath. They are triangular-ovate, sub-rounded and mucronate at the apex, with the tip of the basal lobes rounded or sub-rounded. The petiole is high. The path can be up to long. The spadix is about three fifths as long as the spathe, with flowering parts up to in diameter. The female portion is at the fertile ovaries intermixed with sterile white ones. Neuters grow above the females, and are rhomboid or irregular orium lobed, with six or eight cells. The appendage is shorter than the male portion.\n\n\"Colocasia esculenta\" is thought to be native to Southern India and Southeast Asia, but is widely naturalised. \"Colocasia\" is thought to have originated in the Indomalaya ecozone, perhaps in East India, Nepal, and Bangladesh. It spread by cultivation eastward into Southeast Asia, East Asia and the Pacific Islands; westward to Egypt and the eastern Mediterranean Basin; and then southward and westward from there into East Africa and West Africa, where it spread to the Caribbean and Americas. \n\nTaro was probably first native to the lowland wetlands of Malaysia, where it is called \"taloes\".\n\nIn Australia, \"Colocasia esculenta\" var. \"aquatilis\" is native to the Kimberley region of Western Australia; variety \"esculenta\" is naturalised in Western Australia, the Northern Territory, Queensland and New South Wales.\n\nIn Turkey, \"Colocasia esculenta\" is locally known as \"gölevez\" and mainly grown on the Mediterranean coast, such as the Alanya and Anamur districts of Antalya.\n\nIn the southeastern US, this plant is recognized as an invasive species. Many populations can be commonly found growing near drain ditches and bayous in Houston, Texas.\n\nTaro is believed to have been one of the earliest cultivated plants. Estimates are that taro was in cultivation in wet tropical India before 5000 BC, presumably coming from Malaysia, and from India further transported westward to ancient Egypt, where it was described by Greek and Roman historians as an important crop.\n\nAt around 3.3 million metric tons per year, Nigeria is the largest producer of taro in the world.\n\nTaro can be grown in paddy fields where water is abundant or in upland situations where water is supplied by rainfall or supplemental irrigation. Taro is one of the few crops (along with rice and lotus) that can be grown under flooded conditions. This is due to air spaces in the petiole, which permit underwater gaseous exchange with the atmosphere. For a maximum dissolved oxygen supply, the water should be cool and flowing. Warm, stagnant water causes basal rotting. For maximum yields, the water level should be controlled so that the base of the plant is always under water.\n\nFlooded cultivation has some advantages over dry-land cultivation: higher yields (about double), out-of-season production (which may result in higher prices), and weed control (which flooding facilitates). On the other hand, in flooded production systems taro requires a longer maturation period, investment in infrastructure, and higher operational costs, and monoculture is likely.\n\nLike most root crops, taro and eddoes do well in deep, moist or even swampy soils where the annual rainfall exceeds . Eddoes are more resistant to drought and cold. The crop attains maturity within six to twelve months after planting in dry-land cultivation and after twelve to fifteen months in wetland cultivation. The crop is harvested when the plant height decreases and the leaves turn yellow. These signals are usually less distinct in flooded taro cultivation.\n\nHarvesting is usually done by hand tools, even in mechanized production systems. First, the soil around the corm is loosened, and then, the corm is pulled up by grabbing the base of the petioles. The global average yield is 6.2 tonnes/hectare but varies according to the region. In Asia, average yields reach 12.6 tonnes/hectare.\n\nIt is a food staple in African, Oceanic and South Asian cultures.\nPeople usually consume its edible corm and leaves. The corms, which have a light purple color due to phenolic pigments, are roasted, baked or boiled. The natural sugars give a sweet, nutty flavor. The starch is easily digestible, and since the grains are fine and small it is often used for baby food. Young taro leaves and stems can be eaten after boiling twice to remove the acrid flavor. The leaves are a good source of vitamins A and C and contain more protein than the corms.\n\nIn its raw form, the plant is toxic due to the presence of calcium oxalate, and the presence of needle-shaped raphides in the plant cells. However, the toxin can be minimized and the tuber rendered palatable by cooking, or by steeping in cold water overnight.\n\nCorms of the small, round variety are peeled and boiled, then sold either frozen, bagged in its own liquids, or canned.\n\nTaro is the pre-eminent crop of the Cook Islands and surpasses all other crops in terms of land area devoted to production. The prominence of the crop there has led it to be a staple of the population′s diet. Taro is grown across the country, but the method of cultivation depends on the nature of the island it is grown on. Taro also plays an important role in the country's export trade. The root is eaten boiled, as is standard across Polynesia. Taro leaves are also eaten as a delicacy, cooked with coconut milk, onion, and meat or fish.\n\nTaro (\"dalo\" in Fijian) has been a staple of the Fijian diet for centuries, and its cultural importance is celebrated on Taro Day. Its growth as an export crop began in 1993 when taro leaf blight decimated the taro industry in neighboring Samoa. Fiji filled the void and was soon supplying taro internationally. Almost 80% of Fiji's exported taro comes from the island of Taveuni where the taro beetle species \"Papuana uninodis\" is absent. The Fijian taro industry on the main islands of Viti Levu and Vanua Levu faces constant damage from the beetles. The Fiji Ministry of Agriculture and the Land Resources Division of the Secretariat of the Pacific Community (SPC) are researching pest control and instigating quarantine restrictions to prevent the spread of the pest. Taveuni now exports pest damage-free crops.\n\n\"Kalo\" is the Hawaiian name for the Taro plant. The local crop plays an important role in Hawaiian culture, mythology, and cuisine. Kalo is a traditional staple of the native cuisine of Hawaii. Some of the uses for taro include poi, table taro (steamed and served like a potato), taro chips, and luau leaf (to make laulau)). In Hawaii, kalo is farmed under either dryland or wetland conditions. Taro farming in the Hawaiian Islands is challenging because of the difficulties of accessing fresh water. Kalo is usually grown in \"pond fields\" known as \"loʻi\". Typical dryland or \"upland\" varieties (varieties grown in watered but not flooded fields) in Hawaii are \"lehua maoli\" and \"bun long\", the latter widely known as \"Chinese taro\". \"Bun long\" is used for making taro chips. \"Dasheen\" (also called \"eddo\") is another dryland variety of \"C. esculenta\" grown for its edible corms or as an ornamental plant. A contemporary Hawaiian diet consists of many tuberous plants, particularly sweet potato and kalo.\n\nThe Hawaii Agricultural Statistics Service determined the 10-year median production of kalo in Hawaii to be about 6.1 million pounds (2,800 t). However, 2003 taro production in Hawaii was only 5 million pounds (2,300 t), an all-time low since record-keeping began in 1946. The previous low of 1997 was 5.5 million pounds (2,500 t). Despite generally growing demand, production was even lower in 2005—only 4 million pounds, with \"kalo\" for processing into \"poi\" accounting for 97.5%. Urbanization is one cause driving down harvests from the high of 14.1 million pounds (6,400 t) in 1948, but more recently, the decline has resulted from pests and diseases. A non-native apple snail (\"Pomacea canaliculata\") is a major culprit along with a plant rot disease traced to a newly identified species of fungus in the genus \"Phytophthora\" that now affects kalo crops throughout Hawaii. Although pesticides could control both problems to some extent, pesticide use in the \"loʻi\" is banned because of the opportunity for chemicals to migrate quickly into streams, and then eventually the sea.\n\n\nImportant aspects of Hawaiian culture revolve around \"kalo\" cultivation and consumption. For example, the newer name for a traditional Hawaiian feast (luau) comes from the \"kalo\". Young \"kalo\" tops baked with coconut milk and chicken meat or octopus arms are frequently served at \"luaus\".\n\nBy ancient Hawaiian custom, fighting is not allowed when a bowl of \"poi\" is \"open\". Similarly, it is also considered disrespectful to fight in front of an elder and one should not raise their voice, speak angrily, or make rude comments/gestures.\n\n\nA \"loʻi\" is a patch of wetland dedicated to growing \"kalo\" (taro). Hawaiians have traditionally used water irrigation systems to produce kalo. Wetland fields produce ten to fifteen times more kalo per acre than dry fields. Wetland-grown kalo need a constant flow of water, and to get this water, fields are usually positioned between the \"mauka\" (mountains) and \"makai\" (sea). A \"lo'i\" specifically denotes wetland kalo growing, not dry land.\n\nThe \"loʻi\" is part of an \"ahupuaʻa\", a division of land from the mountain to the sea. Ahupuaʻa means \"pig altar,\" and was named for stone altars with pig head carvings that marked the boundaries of each Hawaiian land division. Ideally, an ahupuaʻa has all the necessities within its borders. From the mountains, materials such as wood are provided for thatching roofs and twining rope. The uplands produce crops like sugar cane and sweet potatoes, while the lowlands provide taro and fish. This system typically satisfies the large populations in each \"ahupuaʻa\".\n\nWhen kalo was brought to Hawaiʻi, there were about 300 varieties (about 100 remain). The kalo plant takes seven months to grow until harvest, so \"lo`i\" fields are used in rotation and the soil can be replenished while the \"loʻi\" in use has sufficient water. The stems are typically replanted in the \"lo`i\" for future kalo harvests. Once harvested, kalo is incorporated into many foods. The leaves are used to make laulau, from the corm poi or \"paʻiʻai\".\n\n\nOne mythological version of Hawaiian ancestry cites the taro plant as an ancestor to Hawaiians. Legend joins the two siblings of high and divine rank: Papahānaumoku (\"Papa from whom lands are born\", or Earth mother) and Wākea (Sky father). Together they create the islands of Hawaii and a beautiful woman, Hoʻohokukalani (The Heavenly one who made the stars).\n\nThe story of kalo begins when Wakea and Papa conceived their daughter, Hoʻohokukalani. Daughter and father then conceived a child together named Hāloanakalaukapalili (Long stalk trembling), but it was stillborn. After the father and daughter buried the child near their house, a kalo plant grew over the grave:\n\nThe second child born of Wakea and Hoʻohokukalani was named Hāloa after his older brother. The kalo of the earth was the sustenance for the young brother and became the principal food for successive generations. Now, as man continues to work the wetlands for this sacred crop, he remembers Haloanaka, the ancestor that nourishes him. The Hawaiian world for family, \"\", is derived from \"ʻohā\", the shoot which grows from the kalo corm. The reason being: as young shoots grow from the corm of the kalo plant, so people, too, grow from their family.\n\nThe Taro corm is a traditional staple crop for large parts of Papua New Guinea, with a domestic trade extending its consumption to areas where it is not traditionally grown. Taro from some regions has developed particularly good reputations with (for instance) Lae taro being highly prized.\n\nAmong the Urapmin people of Papua New Guinea, taro (known in Urap as \"ima\") is the main source of sustenance along with the sweet potato (Urap: \"wan\"). In fact, the word for \"food\" in Urap is a compound of these two words.\n\nConsidered the staple starch of traditional Polynesian cuisine, taro is both a common and prestigious food item that was first introduced to the Polynesian islands by prehistoric seafarers of Southeast Asian derivation. The tuber itself is prepared in various ways, including baking, steaming in earth ovens (\"umu\" or \"imu\"), boiling, and frying. The famous Hawaiian staple poi is made by mashing steamed taro roots with water. Taro also features in traditional desserts such as Samoan \"fa'ausi\", which consists of grated, cooked taro mixed with coconut milk and brown sugar. The leaves of the taro plant also feature prominently in Polynesian cooking, especially as edible wrappings for dishes such as Hawaiian \"laulau\", Fijian and Samoan \"palusami\" (wrapped around onions and coconut milk), and Tongan \"lupulu\" (wrapped corned beef). Ceremonial presentations on occasion of chiefly rites or communal events (weddings, funerals, etc.) traditionally included the ritual presentation of raw and cooked taro roots/plants.\n\nThe Hawaiian \"laulau\" traditionally contains pork, fish, and \"lu'au\" (cooked taro leaf). The wrapping is inedible \"ti\" leaves (Hawaiian: \"lau ki\"). Cooked taro leaf has the consistency of cooked spinach and is therefore unsuitable for use as a wrapping.\n\nIn Samoa, the baby talo leaves and coconut milk are wrapped into parcels and cooked, along with other food, in an earth oven . The parcels are called \"palusami\" or \"lu'au\". The resulting taste is smoky, sweet, savory and has a unique creamy texture. The root is also baked (\"Talo tao\") in the \"umu\" or boiled with coconut cream (\"Faálifu Talo\"). It has a slightly bland and starchy flavor. It is sometimes called the Polynesian potato.\n\n\"Lū\" is lea faka-Tonga for the edible leaves of the talo/taro plant, as well as the traditional dish made using them. This meal is still prepared for special occasions and especially on \"Sāpate\" (Sunday). The dish consists of chopped meat and onions with coconut milk wrapped in a number of \"lū talo\"/taro leaves. This is then wrapped traditionally in a \"lū siaine\"/banana leaf (nowadays, aluminum foil is often used) and put in the \"ʻumu\" to cook. It has a number of named varieties, dependent on the filling:\n\n\nTaro (), is commonly used as a main course as steamed taro with or without sugar, as a substitute for other cereals, in Chinese cuisine in a variety of styles and provinces steamed, boiled or stir-fried as a main dish and as a flavor-enhancing ingredient. In Northern China, it is often boiled or steamed then peeled and eaten with or without sugar much like a potato. It is commonly braised with pork or beef. It is used in the dim sum cuisine of southern China to make a small plated dish called taro dumpling as well as a pan-fried dish called taro cake. It can also be shredded into long strips which are woven together to form a seafood birdsnest.\n\nTaro cake is a delicacy traditionally eaten during Chinese New Year celebrations. As a dessert, it can be mashed into a purée or used as a flavoring in \"tong sui\", bubble tea, ice cream, and other desserts such as Sweet Taro Pie. McDonald's sells taro-flavored pies in China.\n\nTaro is mashed in the dessert known as taro purée.\n\nA similar plant in Japan is called . The \"child\" and \"grandchild\" corms (cormels, cormlets) which bud from the parent \"satoimo\", are called and , respectively, or more generally . \"Satoimo\" has been propagated in Southeast Asia since the late Jōmon period. It was a regional staple before rice became predominant. The tuber, \"satoimo\", is often prepared through simmering in fish stock (\"dashi\") and soy sauce. The stalk, , can also be prepared a number of ways, depending on the variety.\n\nIn Korea, taro is called \"toran\" (: \"earth egg\"), and the corm is stewed and the leaf stem is stir-fried. Taro roots can be used for medicinal purposes, particularly for treating insect bites. It is made into the Korean traditional soup \"toranguk\" (토란국). Taro stems are often used as an ingredient in yukgaejang (육개장).\n\nIn the Philippines taro is usually called \"gabi\", \"abi\" or \"avi\" and is widely available throughout the archipelago. Its adaptability to marshland and swamps make it one of the most common vegetables in the Philippines. The leaves, stems, and corms are all consumed and form part of the local cuisine. A popular recipe for taro is \"laing\"; the dish's main ingredients are taro leaves (at times including stems) cooked in coconut milk, and salted with fermented shrimp or fish \"bagoong\". It is sometimes heavily spiced with red hot chilies called \"siling labuyo\". Another dish in which taro is commonly used is the Philippine national stew, \"sinigang\", although radish can be used if taro is not available. This stew is made with pork and beef, shrimp, or fish, a souring agent (tamarind fruit, \"kamias\", etc.) with the addition of peeled and diced corms as thickener. The corm is also prepared as a basic ingredient for \"ginataan\", a coconut milk and taro dessert.\n\nIn Taiwan, taro— \"yùtóu\" () in Mandarin, and \"ō͘-á\" () in Taiwanese—is well-adapted to Taiwanese climate and can grow almost anywhere with minimal maintenance. Before the Taiwan Miracle made rice affordable to everyone, taro was one of the main staples in Taiwan. Nowadays taro is used more often in desserts. supermarket varieties range from about the size and shape of a brussels sprout to longer, larger varieties the size of a football. Taro chips are often used as a potato-chip-like snack. Compared to potato chips, taro chips are harder and have a nuttier flavor. Another popular traditional Taiwanese snack is taro ball, served on ice or deep-fried.\n\nIn Thai cuisine, taro (\"pheuak\") is used in a variety of ways depending on the region. Boiled taro is readily available in the market packaged in small cellophane bags, already peeled and diced, and eaten as a snack. Pieces of boiled taro with coconut milk are a traditional Thai dessert. Raw taro is also often sliced and deep fried and sold in bags as chips (เผือกทอด). As in other Asian countries, taro is a popular flavor for ice cream in Thailand.\n\nIn Vietnam, there is a large variety of taro plants. One is called \"khoai môn,\" which is used as a filling in spring rolls, cakes, puddings and sweet soup desserts, smoothies and other desserts. Taro is used in the Tết dessert \"chè khoai môn\", which is sticky rice pudding with taro roots. The stems are also used in soups such as \"canh chua\". One is called \"khoai sọ\", which is smaller in size and more delicious than \"Khoai môn\", and of course, more expensive than \"khoai môn\". Another common taro plant grows roots in shallow waters and grows stems and leaves above the surface of the water. This taro plant has saponin-like substances that cause a hot, itchy feeling in the mouth and throat. Northern farmers used to plant them to cook the stems and leaves to feed their hogs. They re-grew quickly from their roots. After cooking, the saponin in the soup of taro stems and leaves is reduced to a level the hogs can eat. Today this practice is no longer popular in Vietnam agriculture. These taro plants are commonly called \"khoai ngứa\", which literally means \"itchy potato\".\n\nIn Bangladesh taro is a very popular vegetable known as \"kochu\" (কচু) or \"mukhi\" (মুখি). Within the Sylheti dialect of the Bangla language, it is called \"mukhi\". It is usually cooked with small prawns or the ilish fish into a curry, but some dishes are cooked with dried fish. Its green leaves, \"kochu pata\" (কচু পাতা), and stem, \"kochu\" (কচু), are also eaten as a favorite dish and usually ground to a paste or finely chopped to make \"shak\" — but it must be boiled well beforehand. Taro stolons or stems, \"kochur loti\" (কচুর লতি), are also favored by Bangladeshis and cooked with shrimp, dried fish or the head of the ilish fish. Taro is available, either fresh or frozen, in the UK and US in most Asian stores and supermarkets specialising in Bangladeshi or South Asian food. Also, another variety called \"maan kochu\" is consumed and is a rich source of vitamins and nutrients. \"Maan Kochu\" is made into a paste and fried to prepare a delicious food known as \"Kochu Bata\".\n\nIn India, taro or eddoe is a common dish served in many ways. It is called \"Arvi\" in Urdu/Hindi in Central and North India, which is often mispronounced as \"Arbi\". It is called कचु(\"kachu\") in Sanskrit.\n\nIn Mizoram, it is called \"bäl\"; the leaves, stalks and tubers are eaten as \"dawl bai\". The leaves and stalks are often traditionally preserved to be eaten in dry season as \"dawl rëp bai\".\n\nIn Assam, a north-eastern state of India, taro is known as \"kosu\" (কচু). Various parts of different types of such plants are eaten by making different dishes. The leaf buds called \"Kosu loti\" (কচু লতি) are cooked with sour dried fruits called \"Thekera\" (থেকেৰা) or sometimes with Tamarind or Elephant apple alone or with a small amount of pulses and sometimes, fish. Similar dishes are prepared from the long root-like structures called \"Kosu thuri\". A fried dish with sour objects is also made from its flower (\"Kosu kala\"). Soupy dishes are made from solid roots which are sometimes also boiled and eaten sometimes with salt as snacks or home-made fast food.\n\nIn Manipur, another north-eastern Indian state, taro is known as \"pan\". The kuki tribes called it \"bal\". Boiled \"bal\" is a snack at lunch along with chutney or hot chili-flakes besides being cooked as a main dish along with smoked or dried meat, beans, and mustard leaves. They also sun dry the leaves and keep them for future use as broth and hodge-podge. It is widely available and is eaten in many forms, either baked, boiled, or cooked into a curry with Hilsa fish or with fermented soybeans called \"Hawai-zaar\". The leaves are also used in a special traditional dish called \"utti\", cooked with peas.\n\nIn Himachal Pradesh, a northern state in India, the tarp root is known as \"ghandyali\", and the plant is known as \"Kachalu\" in Kangra & Mandi district. The dish called \"patrodu\" is made using taro leaves rolled with corn/gram flour and boiled in water. Another dish, \"pujji\" is made with mashed leaves and the trunk of the plant and \"ghandyali\" or taro roots are prepared as a separate dish. Also in the capital Shimla, a pancake-style dish, called \"patra\" or \"patid\", is made using gram flour.\n\nA tall-growing variety of taro is extensively used on the western coast of India to make \"patrode\", \"patrade\", or \"patrada\", literally a \"leaf-pancake\". In the Dakshin Kannada district in the state of Karnataka, it is used as a morning breakfast dish, either made like fritters or steamed. In the state of Maharashtra, the leaves, called \"alu che paana\", are de-veined, rolled with a paste of gram flour, tamarind paste, red chili powder, turmeric, coriander, asafoetida, and salt, and then steamed. These can be eaten whole or cut into pieces, or shallow fried and eaten as a snack known as \"alu chi wadi\". \"Alu chya panan chi patal bhaji\" a lentil and colocasia leaves curry, is also popular. In Goan cuisine as well as the Konkani cuisine Taro leaves are very popular.\n\nIn the Indian states of Gujarat and Maharashtra, the leaves of the plant are used to make \"patra\" a dish with gram flour, tamarind and other spices.\n\nSindhis call it \"kachaloo\"; they fry it, compress it, and re-fry it to make a dish called \"tuk\" which complements Sindhi curry.\n\nIn Kerala, a state in southern India, taro corms are known as ചേമ്പ് കിഴങ്ങ് \"chembu-kizhangu\". Taro is used as a staple food, as a side dish, or as an ingredient in various side dishes like \"sambar\". As a staple food, it is steamed and eaten with a spicy chutney of green chilies, tamarind, and shallots. The leaves and stems of certain varieties of taro are used as a vegetable in Kerala.\n\nIn other Indian states, Tamil Nadu and Andhra Pradesh, taro corms are known as \"sivapan-kizhangu\" (\"seppankilangu\" or \"cheppankilangu\"), \"chamagadda\", or in coastal Andhra districts as \"chaama dumpa\" in Telugu. It can be cooked in many ways, such as deep-fried in oil for a side item with rice, or cooked in a tangy tamarind sauce with spices, onion, and tomato.\n\nIn the East Indian state of West Bengal, taro roots are thinly sliced and fried to make chips called \"kochu bhaja\". The stem is used to cook a very tasty \"Kochur saag\" with fried hilsha fish head or boiled chhola (chickpea), often eaten as a starter with hot rice. The roots are also made into a paste with spices and eaten with rice. The most popular dish is a spicy curry made with prawn and taro roots.\n\nIn the Mithilanchal region of Bihar, taro root is known as अडुआ and its leaves are called अड़िकंच के पात. A curry of taro leaves is made with mustard paste and आमिल (sun-dried mango pulp used for a sour taste in daal, curry and sour gravy).\n\nIn the eastern Indian state of Odisha, taro root is known as \"saru\". Dishes made of taro include \"saru besara\" (taro in mustard and garlic paste). It is also an indispensable ingredient in preparing the heart of Odia cuisine, the \"dalma\", where vegetables are cooked with dal. Sliced taro roots, deep fried in oil and mixed with red chili powder and salt, are known as \"saru chips\".\n\nIn the north Indian state of Uttarakhand and neighboring Nepal, taro is considered a healthy food cooked in a variety of ways. The delicate\"Gaderi\" taro of Kumaun, especially from the Lobanj region is much sought after. Most commonly it is boiled in tamarind water until tender, then it is diced into cubes which are stir-fried in mustard oil with methi (fenugreek) leaves. Boiling it in salty water in iron cooking pots until it becomes like porridge, is another technique. The young leaves called \"gaaba\", are steamed, then sun-dried and stored for later use. For another use, the taro leaves and stems are used raw as an ingredient for pickles. Crushed leaves and stems are mixed with de-husked urad dal – black lentils and then dried as small balls called \"badi\". The stems may also be sun-dried and stored for later use. On one special day, women worship \"saptarshi\" (\"seven sages\") and eat only rice with taro leaf vegetable.\n\n\"Ala\" was widely grown in the southern atolls of Addu Atoll, Fuvahmulah, Huvadhu Atoll, and Laamu Atoll and is considered a staple even after rice was introduced. \"Ala\" and \"olhu ala\" are still widely eaten all over the Maldives, cooked or steamed with salt to taste, and eaten with grated coconut along with chili paste and fish soup. It is also prepared as a curry. The roots are sliced and fried to make chips and are also used to prepare varieties of sweets.\n\nTaro is grown in the Terai and the hilly regions of Nepal. The root (corm) of taro is known as \"pindalu\" (पिँडालु) and petioles with leaves are known as \"karkalo\" (कर्कलो) and also as \"Gava\" (गाभा). Almost all parts are eaten in different dishes. Boiled corm of Taro is commonly served with salt, spices, and chilies. Taro is a popular dish in the hilly region. Chopped leaves and petioles are mixed with \"Urad\" bean flour to make dried balls called \"maseura\" (मस्यौरा). Large taro leaves are used as an alternative to an umbrella when unexpected rain occurs. Popular attachment to taro since ancient times is reflected in popular culture, such as in songs and textbooks. \"Jivan hamro karkala ko pani jastai ho\" (जिवन हाम्रो कर्कलाको पानी जस्तै हो) means, \"Our life is as vulnerable as water stuck in the leaf of taro\".\n\nTaro is cultivated and eaten by the Tharu people in the Inner Terai as well. Roots are mixed with dried fish and turmeric, then dried in cakes called \"sidhara\" which are curried with radish, chili, garlic and other spices to accompany rice. The Tharu prepare the leaves in a fried vegetable side-dish that also shows up in Maithili cuisine.\n\nIn Pakistan, taro or \"eddoe\" or \"arvi\" is a very common dish served with or without gravy; a popular dish is \"arvi gosht\", which includes beef, lamb or mutton. The leaves are rolled along with gram flour batter and then fried or steamed to make a dish called \"Pakora\", which is finished by tempering with red chilies and carrom (ajwain) seeds. Taro or \"arvi\" is also cooked with chopped spinach. The dish called \"Arvi Palak\" is the second most renowned dish made of Taro.\n\nMany varieties are recorded in Sri Lanka, several being edible, others being toxic to humans and therefore not cultivated. Edible varieties (\"kiri ala\", \"kolakana ala\", \"gahala\", and \"sevel ala\") are cultivated for their corms and leaves. Sri Lankans eat corms after boiling them or making them into a curry with coconut milk. The leaves of only one variety, \"kolakana ala,\" are eaten.\n\nTaro was consumed by the early Romans in much the same way the potato is today. They called this root vegetable \"colocasia\". The Roman cookbook \"Apicius\" mentions several methods for preparing taro, including boiling, preparing with sauces, and cooking with meat or fowl. After the fall of the Roman Empire, the use of taro dwindled in Europe. This was largely due to the decline of trade and commerce with Egypt, previously controlled by Rome. It is important to note when the Spanish and Portuguese sailed to the new world, they brought taro along with them. Recently there has been renewed interest in exotic foods and consumption is increasing.\n\nIn Cyprus, taro has been in use since the time of the Roman Empire. Today it is known as \"kolokas\" in Turkish or \"kolokasi\" (κολοκάσι) in Greek, which comes from the Ancient Greek name κολοκάσιον (\"kolokasion\") for lotus root. It is usually sauteed with celery and onion with pork or chicken, in a tomato sauce – a vegetarian version is also available. The cormlets are called \"poulles\" (sing. \"poulla\"), and they are prepared by first being sauteed, followed by decaramelising the vessel with dry red wine and coriander seeds, and finally served with freshly squeezed lemon.\n\nIn Egypt, taro is known as \"qolqas\" (, ). The corms are larger than what would be found in North American supermarkets. After being peeled completely, it is cooked in one of two ways. It is cut into small cubes and cooked in broth with fresh coriander and chard and served as an accompaniment to meat stew, or it may be sliced and cooked with minced meat and tomato sauce.\n\nIn the army, the \"black dish\" ( \"al-ṭabkha al-sawda\") is a combination of eggplants and unpeeled taro halves.\n\nIn Greece, taro grows on Icaria. Icarians credit taro for saving them from famine during World War II. They boil it until tender and serve it as a salad.\n\nIn Lebanon, taro is known as \"kilkass\" and is grown mainly along the Mediterranean coast. The leaves and stems are not consumed in Lebanon and the variety grown produces round to slightly oblong tubers that vary in size from a tennis ball to a small cantaloupe. \"Kilkass\" is a very popular winter dish in Lebanon and is prepared in two ways: \"kilkass\" with lentils is a stew flavored with crushed garlic and lemon juice and \"’il’as\" (Lebanese pronunciation of ) \"bi-tahini\". Another common method of preparing taro is to boil, peel then slice it into thick slices, before frying and marinating in edible \"red\" sumac.\nIn northern Lebanon, it is known as a potato with the name \"borshoushi\" (\"el-orse borshushi\"). It is also prepared as part of a lentil soup with crushed garlic and lemon juice. Also in the north, it is known by the name \"bouzmet\", mainly around Menieh, where it is first peeled, and left to dry in the sun for a couple of days. After that, it is stir-fried in lots of vegetable oil in a casserole until golden brown, then a large amount of wedged, melted onions are added, in addition to water, chickpeas and some seasoning. These are all left to simmer for a few hours, and the result is a stew-like dish. It is considered a hard-to-make delicacy, not only because of the tedious preparation but the consistency and flavour that the taro must reach. The smaller variety of taro is more popular in the north due to its tenderness.\nIn the Azores taro is known as \"inhame\" or \"inhame-coco\" and is commonly steamed with potatoes, vegetables and meats or fish. It is also consumed as a dessert after first being steamed and peeled, then fried in vegetable oil or lard, and finally sprinkled with sugar. Taro grows in the fertile land of the Azores, as well as in creeks that are fed by mineral springs. Through migration to other countries, the \"inhame\" is found in the Azorean diaspora.\n\nTaro root is consumed in the south of Spain. Taro has remained popular in the Canary Islands. In the Canary Islands it is known as \"ñame\" and is often used in thick vegetable stews, like \"potaje de berros\" (cress potage). Taro is called \"ñame\" (which normally designates yams) in Canarian Spanish and is a common crop in the Autonomous Community of the Canary Islands (Canary Islands, Spain).\n\nTaro () is grown in the south coast of Turkey, especially in Mersin, Bozyazı, Anamur and Antalya. It is boiled in a tomato sauce or cooked with meat, beans and chickpeas. It is often used as a substitute for potato.\n\nIn Kenya, Uganda and Tanzania, taro is commonly known as \"arrow root\", \"ggobe\", or \"nduma\" and \"madhumbe\" in some local Bantu languages. It is usually boiled and eaten with tea or other beverages, or as the main starch of a meal. It is also cultivated in Malawi, Mozambique, and Zimbabwe.\n\nIt is known as \"amadumbe\" (plural) or \"idumbe\" (singular) in the Zulu language of Southern Africa.\n\nTaro is consumed as a staple crop in West Africa, particularly in Ghana, Nigeria and Cameroon. It is called \"cocoyam\" in Nigeria, Ghana and Anglophone Cameroon, \"macabo\" in Francophone Cameroon, and \"ede\" in Igbo language. \"Cocoyam\" is often boiled, fried, or roasted and eaten with a sauce. In Ghana, it substitutes for plantain in making \"fufu\" when plantains are out of season. It is also cut into small pieces to make a soupy baby food and appetizer called \"mpotompoto\". It is also common in Ghana to find \"cocoyam chips\" (deep-fried slices, about thick). \"Cocoyam\" leaves, locally called \"kontomire\" in Ghana, are a popular vegetable for local sauces such as palaver sauce and egusi/agushi stew. It is also commonly consumed in Guinea and parts of Senegal, as a leaf sauce or as a vegetable side, and is referred to as \"jaabere\" in the local Pulaar dialect.\n\nIn Lusophone countries, \"inhame\" (pronounced , or , literally \"yam\") and \"cará\" are the common names for various plants with edible parts of the genera \"Alocasia\", \"Colocasia\" (family Araceae) and \"Dioscorea\" (family Dioscoreaceae), and its respective starchy edible parts, generally tubers, with the exception of \"Dioscorea bulbifera\", called \"cará-moela\" (pronounced , literally, \"gizzard yam\"), in Brazil and never deemed to be an \"inhame\". Definitions of what constitutes an \"inhame\" and a \"cará\" vary regionally, but the common understanding in Brazil is that \"carás\" are potato-like in shape, while \"inhames\" are more oblong.\n\nIn the \"broad\" lower class Brazilian Portuguese of the hotter and drier Northeastern region, both \"inhames\" and \"carás\" are called \"batata\" (literally, \"potato\"). For differentiation, potatoes are called \"batata-inglesa\" (literally, \"English potato\"), a name used in other regions and sociolects to differentiate it from the \"batata-doce\", \"sweet potato\", ironic names since both were first cultivated by the indigenous peoples of South America, their native continent, and only later introduced in Europe by the colonizers.\n\nTaros are often prepared like potatoes, eaten boiled, stewed or mashed, generally with salt and sometimes garlic as a condiment, as part of a meal (most often lunch or dinner).\n\nIn Costa Rica, Nicaragua and Panama, taro is eaten in soups, as a replacement for potatoes, and as chips. It is known locally as \"malanga\" (also \"malanga coco\") in Costa Rica, \"quiquizque\" in Nicaragua, and as \"otoe\" in Panama.\n\nIn Haiti, it is usually called \"malanga\", or \"taro\". The corm is grated into a paste and deep-fried to make a fritter called \"Acra\". \"Acra\" is a very popular street food in Haiti.\n\nIn Jamaica, taro is known as \"coco\", \"cocoyam\" and \"dasheen\". Corms with flesh which is white throughout are referred to as \"minty-coco\". The leaves are also used to make callaloo.\n\nIn Suriname it is called \"tayer\", \"taya\", \"pomtayer\" or \"pongtaya\". The taro root is called \"aroei\" by the native Indians and is commonly known as \"Chinese \"tayer\"\". The variety known as \"eddoe\" is also called Chinese \"tayer\". It is a popular cultivar among the maroon population in the interior, also because it is not adversely affected by high water levels. The \"dasheen\" variety, commonly planted in swamps, is rare, although appreciated for its taste. The closely related \"Xanthosoma\" species is the base for the popular Surinamese dish, pom.\n\nIn Trinidad and Tobago, it is called \"dasheen\". The leaves of the taro plant are used to make the Trinidadian variant of the Caribbean dish known as callaloo (which is made with okra, \"dasheen\"/taro leaves, coconut milk or creme and aromatic herbs) and it is also prepared similarly to steamed spinach. The root of the taro plant is often served boiled, accompanied by stewed fish or meat, curried, often with peas and eaten with roti, or in soups.\n\nIn American Chinatowns, people often use taro in Chinese cuisine, though it is not as popular as in Asian and Pacific nations. Since the late 20th century, taro chips have been available in many supermarkets and natural food stores. In the 1920s, \"dasheen\", as it was known, was highly touted by the Secretary of the Florida Department of Agriculture as a valuable crop for growth in muck fields. Fellsmere, Florida, near the east coast, was a farming area deemed perfect for growing \"dasheen\". It was used in place of potatoes and dried to make flour. \"Dasheen\" flour was said to make excellent pancakes when mixed with wheat flour.\n\nIn Venezuela, taro is called \"ocumo chino\" or \"chino\" and used in soups and \"sancochos\". Soups contain large chunks of several kinds of tubers, including \"ocumo chino\", especially in the eastern part of the country, where West Indian influence is present. It is also used to accompany meats in \"parrillas\" (barbecue) or fried cured fish where yuca is not available. \"Ocumo\" is an indigenous name; \"chino\" means \"Chinese\", an adjective for produce that is considered exotic. \"Ocumo\" without the Chinese denomination is a tuber from the same family, but without taro's inside purplish color. \"Ocumo\" is the Venezuelan name for malanga, so \"ocumo chino\" means \"Chinese malanga\". Taro is always prepared boiled. No porridge form is known in the local cuisine.\n\nTaro is called \"dasheen\", in contrast to the smaller variety of corms called \"eddo\", or \"tanya\" in the English speaking countries of the West Indies, and is cultivated and consumed as a staple crop in the region. There are differences among the roots mentioned above: taro or \"dasheen\" is mostly blue when cooked, \"tanya\" is white and very dry, and \"eddoes\" are small and very slimy.\n\nIn the Spanish speaking countries of the Spanish West Indies taro is called \"ñame\", the Portuguese variant of which (\"inhame\") is used in former Portuguese colonies where taro is still cultivated, including the Azores and Brazil. In Puerto Rico and Cuba, and the Dominican Republic it is sometimes called \"malanga\" or \"yautia\". In some countries, such as Trinidad and Tobago, Saint Vincent and the Grenadines, and Dominica, the leaves and stem of the \"dasheen\", or taro, are most often cooked and pureed into a thick liquid called callaloo, which is served as a side dish similar to creamed spinach. \"Callaloo\" is sometimes prepared with crab legs, coconut milk, pumpkin, and okra. It is usually served alongside rice or made into a soup along with various other roots.\n\nIt is also sold as an ornamental aquatic plant.\n\nIt is also used for anthocyanin study experiments especially with reference to abaxial and adaxial anthocyanic concentration.\n\n\n001. 8 p. http://www.ctahr.hawaii.edu/oc/freepubs/pdf/SA-1.pdf.\n\n"}
{"id": "46707774", "url": "https://en.wikipedia.org/wiki?curid=46707774", "title": "Dark globular cluster", "text": "Dark globular cluster\n\nDark globular cluster is a proposed type of globular star clusters that has an unusually high mass for the number of stars within it. Proposed in 2015 on the basis of observational data, dark globular clusters are believed to be populated by objects with significant dark matter components, such as central massive black holes.\n\nThe observational data for dark globular clusters comes from the Very Large Telescope (VLT) in Chile which observed the vicinity of the galaxy Centaurus A. Many of the globular clusters inside that galaxy are brighter and more massive than those orbiting the Milky Way and a sample of 125 globular clusters around Centaurus A was studied using the VLT's FLAMES instrument. While globular clusters are normally considered to be almost devoid of dark matter, the study of the dynamical properties of sampled clusters suggested the presence of exotically concentrated dark matter. The study was published in \"The Astrophysical Journal\"(link). The existence of dark globular clusters would suggest that their formation and evolution are markedly different from other globular clusters in Centaurus A and the Local Group.\n"}
{"id": "32752933", "url": "https://en.wikipedia.org/wiki?curid=32752933", "title": "Du Noüy–Padday method", "text": "Du Noüy–Padday method\n\nThe Du Noüy–Padday method is a minimized version of the Du Noüy ring method replacing the large platinum ring with a thin rod that is used to measure equilibrium surface tension or dynamic surface tension at an air–liquid interface. In this method, the rod is oriented perpendicular to the interface, and the force exerted on it is measured. Based on the work of Padday, this method finds wide use in the preparation and monitoring of Langmuir–Blodgett films, ink & coating development, pharmaceutical screening, and academic research.\n\nThe Du Noüy Padday rod consists of a rod usually on the order of a few millimeters square making a small ring. The rod is often made from a composite metal material that may be roughened to ensure complete wetting at the interface. The rod is cleaned with water, alcohol and a flame or with strong acid to ensure complete removal of surfactants. The rod is attached to a scale or balance via a thin metal hook. The Padday method uses the maximum pull force method, i.e. the maximum force due to the surface tension is recorded as the probe is first immersed ca. one mm into the solution and then slowly withdrawn from the interface. The main forces acting on a probe are the buoyancy (due to the volume of liquid displaced by the probe) and the mass of the meniscus adhering to the probe. This is an old, reliable, and well-documented technique.\n\nAn important advantage of the maximum pull force technique is that the receding contact angle on the probe is effectively zero. The maximum pull force is obtained when the buoyancy force reaches its minimum,\n\nThe surface tension measurement used in the Padday devices based on the Du Noüy ring/maximum pull force method is explained further here:\n\nThe force acting on the probe can be divided into two components: \nThe latter is in equilibrium with the surface tension force, i.e.\n\nwhere\n\nThus, the force measured by the balance is given by\n\nwhere\n\nAt the point of detachment the volume of the probe immersed in the solution vanishes, and thus, also the buoyancy term. This is observed as a maximum in the force curve, which relates to the surface tension through\n\nThe above derivation holds for ideal conditions. Non-idealities, e.g. from defect probe shape, are partly compensated in the calibration routine using a solution with known surface tension.\n\nUnlike a Du Noüy ring, no correction factors are required when calculating surface tensions. Due to its small size the rod can be used in high throughput instruments that use a 96-well plate to determine the surface tension. The small diameter of the rod allows its use in a small volume of liquid with 50 formula_9l samples being used in some devices.\n\nIn addition, the rod also allows use for the Wilhelmy method because the rod is not completely removed during measurements. For this the dynamic surface tension can be used for accurate determination of surface kinetics on a wide range of timescales.\n\nThe Padday technique also offers low operator variance and does not need an anti-vibration table. This advantage over other devices allows the Padday devices to be used in the field easily. The rod when made of composite material is also less likely to bend and therefore cheaper than the more costly platinum rod offered in the Du Noüy method.\n\nIn a typical experiment, the rod is lowered using a manual or automatic device to the surface being analyzed until a meniscus is formed, and then raised so that the bottom edge of the rod lies on the plane of the undisturbed surface. One disadvantage of this technique is that it can not bury the rod into the surface to measure interfacial tension between two liquids.\n\nThe practical uses of an instrument that uses a single probe are that it allows for the developing of a high throughput device. A high throughput surface tension device can be used for formulation in real time for understanding the penetration of drugs in the blood–brain barrier (BBB), understanding the solubility of drugs, development of a screen to test a drugs toxicity, determining the physicochemical properties of oxidized phospholipids, and development of new surfactant/polymers.\n\nThe physicochemical profiling of poorly soluble drug candidates performed using a HTS surface tension device. Allowed prediction of penetration through the blood–brain barrier.\n\nA correlation with drug-lipid-complexes were correlated with high-throughput surface tension device to predict phospholipidosis in particular cationic drugs.\n\nDrug solubility has previously been done by the shaker method. A 96-well high throughput device has allowed development of a new method to test drugs.\n\nThe physicochemical properties of oxidized lipids were characterized using a high throughput device. Since these oxidized lipids are expensive and only available in small quantities a surface tension device requiring only a small amount of volume is better.\n\nThe surface tension profiles of the branched copolymers solutions were\nperformed using a HTS surface tensiometer as a function polymer concentration to produce pH-triggered aggregation emulsion droplets.\n\n"}
{"id": "11290724", "url": "https://en.wikipedia.org/wiki?curid=11290724", "title": "Ecoheatcool", "text": "Ecoheatcool\n\nLaunched at the beginning of 2005 with support from the Intelligent Energy Europe programme. the ECOHEATCOOL project carried out by Euroheat & Power, in cooperation with 13 partners across Europe was concluded at the end of December 2006. \n\nThe project assessed the heating and cooling markets, looked for possibilities for more district heating and district cooling in Europe, provided recommendations for policy makers and developed a tool for assessing the efficiency of district heating and cooling systems. The project showed that district heating and cooling grids make it possible to optimally use and combine a large spectrum of \"free\" energy inputs: surplus heat from electricity production based on conventional or renewable fuels, from waste incineration and/or from industrial processes as well as different forms of renewable heat (i.e. geothermal, heat/cold from deep-sea or lake water).\n\nThe Ecoheatcool project became a reference for district heating and cooling sector, its findings being used in the arguments provided to European Union and national policy makers. It enabled the development of a vision, quantification of the benefits which the district heating and cooling sector can bring to achieving the EU policy objectives: energy efficiency, environmental protection, security of supply, use of renewable energy sources, avoided investments in peak electricity capacities, and evaluation of the costs.\n\n"}
{"id": "53885851", "url": "https://en.wikipedia.org/wiki?curid=53885851", "title": "Energy Regulatory Authority (Albania)", "text": "Energy Regulatory Authority (Albania)\n\nThe Energy Regulatory Authority (ERE) () is an independent public entity tasked to ensure a sustainable and secure electricity supply for the Albanian consumer by establishing an operational and competitive electricity market, taking into account the consumer's interest.\n\nERE organizes hearings with stakeholders from the three energy operators KESH, OST, and OSHEE to discuss price increases and tariff changes for energy production.\n\n"}
{"id": "5260053", "url": "https://en.wikipedia.org/wiki?curid=5260053", "title": "Energy supply", "text": "Energy supply\n\nEnergy supply is the delivery of fuels or transformed fuels to point of consumption. It potentially encompasses the extraction, transmission, generation, distribution and storage of fuels. It is also sometimes called energy flow.\n\nThis supply of energy can be disrupted by several factors, including imposition of higher energy prices due to action by OPEC or other cartel, war, political disputes, economic disputes, or physical damage to the energy infrastructure due to terrorism. The security of the energy supply is a major concern of national security and energy law.\n\nSome sources refer to \"energy supply\" when actually referring to the oil reserves or other potential sources of energy.\n\nNew York Statutes includes a statutory code called \"Energy Law\". Article 21 of this code is called \"Energy Supply and Production\", but rather than a comprehensive code, only consists of one section dealing with renewable energy.\n\n\n\n\n"}
{"id": "39606469", "url": "https://en.wikipedia.org/wiki?curid=39606469", "title": "Eric Martinot", "text": "Eric Martinot\n\nEric Martinot is senior research director with the Institute for Sustainable Energy Policies in Tokyo, Japan, specialising in renewable energy commercialization. He is author of the 2013 REN21 \"Renewables Global Futures Report\", and former lead author of the REN21 \"Renewables Global Status Report\" (2005–2010), an annual compilation of progress with renewable energy worldwide.\n\nFrom 2005 to 2008 Martinot lived in Beijing, where he was senior visiting scholar at Tsinghua University and researched China's approach to renewable energy use. From 2000 to 2003, he was senior energy analyst with the World Bank (Washington DC) where he managed renewable energy projects for developing countries.\n\nEric Martinot has written 70 publications on sustainable energy. He has M.A. and Ph.D. degrees in Energy and Resources from the University of California at Berkeley (1991 and 1995) and a B.S. in Electrical Engineering from MIT (1984).\n\n\n"}
{"id": "50131354", "url": "https://en.wikipedia.org/wiki?curid=50131354", "title": "Exxon donor solvent process", "text": "Exxon donor solvent process\n\nExxon donor solvent process (EDS) is a coal liquefaction process developed by Exxon Research and Engineering Company, starting in 1966. The process converts solid coal directly to liquid synthetic fuels which could be used as a substitute for petroleum products. The process does not involve an intermediate step of coal gasification. Exxon operated a pilot plant in Texas from 1980 until 1982.\n\nExxon started to develop this process in 1966 and the development process continued until 1976. By 1975, the process was used in 1/2-tons per day pilot plant. In 1977, preparations to build the demonstration-scale 250-tons per day plant in Baytown, Texas. The plant was opened in April 1980. The plant was built by Carter Oil, an affiliate of Exxon Corporation later renamed Exxon Coal, U.S.A. The plant was financed by the United States Department of Energy and by the private investors Carter Oil, Electric Power Research Institute, Japan Coal Liquefaction Development Company, Phillips Coal Company, ARCO Coal Company, Ruhrkohle and Agip. The plant was closed and dismantled in 1982. Originally Exxon planned to open its first commercial scale plant in 1997; however, this plan was abandoned.\n\nThe Exxon donor solvent process is a non-catalytic processing of solvent-slurried coal in a high-pressure liquefaction reactor. Coal is cleaned, crushed and fed to the slurry dryer, where water is removed. The dry crushed coal is slurried with the hydrogen donor recycle solvent. The coal slurry is treated with hydrogen and heated in a liquefaction slurry furnace. The liquefaction occurs at and . The process produces gas and liquids. After separation of gas from liquids and remaining solids, the gas is cooled to separate vaporized naptha, and scrubbed to remove ammonia, hydrogen gas, and carbon monoxide. The remaining gas is treated with hydrogen, and reused in the liquefaction reactor. Liquids, remaining solids, and condensate from the process gas are treated in fractionators for separating naptha, a spent solvent, and vacuum gas oil. Naptha is processed into different hydrocarbon products while spent solvent hydrogenated before reusing in the slurry drier.\n\nBy this process from of dry, high volatile coal can be produced more than of a synthetic fuel. Initially, the process was focused to be used for bituminous coals but it was tested also for lower grade coals, such as lignite. Pilot testings show that lignite was harder to process than bituminous coals and it resulted a lower oil yield.\n"}
{"id": "29837448", "url": "https://en.wikipedia.org/wiki?curid=29837448", "title": "Fluid dynamic gauge", "text": "Fluid dynamic gauge\n\nA fluid dynamic gauge (FDG) is a measurement technique used to study the behaviour of soft deposit layers in a liquid environment. It employs fluid mechanics to determine the thickness of the layer, and can also be used to obtain a measure of its strength. It was inspired by the technique of pneumatic gauging, which relies on a flow of air rather than the process liquid. Fluid dynamic gauging can be conducted as an in-line measuring technique, but is more commonly used as a research tool. \n\nThe technique was originally developed to measure the buildup or removal of the fouling layers commonly encountered in the process industry (such as in the heat treatment of dairy products). More recently, it has been applied to study cake buildup on porous membrane surfaces. Scanning versions can determine the topology of a solid/soft-solid surface immersed in a liquid environment, in an analogous manner to an atomic force microscope, but exploiting the principles of fluid mechanics.\n\nKey features of the technique are that it can study soft deposit layers without touching them, relies on relatively simple operating principles, can be used in a completely opaque liquid, and does not rely on knowledge of the fluid or deposit properties.\n\n"}
{"id": "31948705", "url": "https://en.wikipedia.org/wiki?curid=31948705", "title": "Frances Beinecke", "text": "Frances Beinecke\n\nFrances Beinecke is the former president of the Natural Resources Defense Council, the nonprofit conservation group, serving since 2006.\n\nShe was appointed by President Barack Obama to the National Commission on the BP Deepwater Horizon Oil Spill and Offshore Drilling. She currently serves on the boards of the World Resources Institute, the Energy Future Coalition, the Nicholas Institute for Environmental Policy Solutions, and Conservation International's Center for Environmental Leadership in Business. She previously served on the boards of the Wilderness Society, the China-U.S. Center for Sustainable Development, and the New York League of Conservation Voters.\n\nBeinecke received a bachelor's degree from Yale College and a master's degree from the Yale School of Forestry and Environmental Studies.\n\nIn 2007, Beinecke was awarded The National Audubon Society's prestigious Rachel Carson Award, a premier award honoring distinguished American women environmentalists.\n\nShe is the daughter of William Sperry Beinecke.\n\n\n"}
{"id": "11756585", "url": "https://en.wikipedia.org/wiki?curid=11756585", "title": "GEO-2000", "text": "GEO-2000\n\nGEO-2000 is the United Nations Environment Programme (UNEP) Global Environment Outlook 2000.\n\nThe UNEP launched the Global Environment Outlook in 1995 to assess environmental issues and to have them published. The first report was published in 1999.\n\nAs well as some of the more well known issues the report identified new threats such as:\n\n"}
{"id": "20234988", "url": "https://en.wikipedia.org/wiki?curid=20234988", "title": "Generation on the Wind", "text": "Generation on the Wind\n\nGeneration on the Wind is a 1979 documentary film produced by David Vassar and Andrew Finley. The film is a character study centered on a rag tag group of young artists, mechanics and environmental activists who successfully built the largest electrical generating windmill in the world. The documentary required two years of shooting to finish the film. It was nominated for an Academy Award for Best Documentary Feature.\n"}
{"id": "52671902", "url": "https://en.wikipedia.org/wiki?curid=52671902", "title": "Havar (alloy)", "text": "Havar (alloy)\n\nHavar, or UNS R30005, is an alloy of cobalt, possessing very high mechanical strength. It can be heat-treated. It is highly resistant to corrosion and is non-magnetic. It is biocompatible. It has high fatigue resistance. It is a precipitation hardening superalloy.\n\nHavar is composed of 42.0% (41-44%) of cobalt, 19.5% (19-21%) of chromium, 12.7% (12-14%) of nickel, 2.7% (2.3-3.3%) of tungsten, 2.2% (2-2.8%) of molybdenum, 1.6% (1.35-1.8%) of manganese, 0.2% (0.17-0.23%) of carbon, 0.02-0.08% of beryllium, and balance of iron. Its melting point is about 1480 °C. It will retain three quarters of its room temperature strengths up to 510 °C. Its density is 8.3 g/cm. Its thermal conductivity is 13.0 W/m·K. Its tensile strength is 960-970 MPa and its modulus of elasticity is 200-210 GPa. It can be joined by welding (GMAW and resistance welding, soldering and brazing.\n\nHavar foils of various thickness are used as diaphragms for pressure sensing in process control equipment, biocompatible medical implants, as particle beam windows in nuclear physics, and various other high temperature applications.\n\nHavar foils are frequently used as window material for high-energy proton beams used in production of fluorine-18 from oxygen-18 enriched water.\n\nHavar was originally developed in the late 1940s by Hamilton Watch Company as an alloy for the mainsprings used in watches, and named Dynavar. Later it was used as sensing diaphragms and other uses, under its current name Havar. Its corrosion resistance allows use in stress corrosion resistant springs and diaphragms in oilfield equipment handling sour crude oil. Havar outperforms 316L stainless steel in resistance to pitting corrosion and crevice corrosion in medical implant environment. In cold-rolled and aged form, its yield and tensile strength are higher than of other cobalt-based implant alloys.\n\nIn Green death, the Havar alloy does not corrode at all at room temperature, starts corroding rapidly (15 mm/year) at 70 °C, and reaches rate of 56 mm/year at boiling point.\n\nHavar is difficult to machine, as it undergoes rapid work hardening under the cutting tool. The tool should be as sharp as possible and the machine should be rigid, with minimal backlash. Higher power is required than to machine ordinary steels of similar hardness.\n"}
{"id": "13751399", "url": "https://en.wikipedia.org/wiki?curid=13751399", "title": "Hermann Scheer", "text": "Hermann Scheer\n\nHermann Scheer (29 April 1944 – 14 October 2010) was a Social Democrat member of the German Bundestag (parliament), President of Eurosolar (European Association for Renewable Energy) and General Chairman of the World Council for Renewable Energy. In 1999, Scheer was awarded the Right Livelihood Award for his \"indefatigable work for the promotion of solar energy worldwide\".\n\nScheer believed that the continuation of current patterns of energy supply and use would be environmentally, socially, economically, and politically damaging, with renewable energy being the only realistic alternative. Scheer had concluded that it is technically and environmentally feasible to harness enough solar radiation to achieve a total replacement of the foclear (fossil/nuclear) energy system by a global renewable energy economy. The main obstacle to such a change is seen to be political, not technical or economic. In 1999 he was one of the initiators of the German feed-in tariffs that were the major source of the rise of renewable energies in Germany during the following years.\n\nScheer was born in Wehrheim, and became a member of the Social Democratic Party of Germany in 1965 during his military service as an officer in the Bundeswehr. He majored in economics and law and was active in student politics at the University of Heidelberg. 1979 he graduated from the Free University of Berlin as a doctor of political science. He worked as postgrade scientist at Universität Stuttgart and as a scientist (1976 till 1980) at Forschungszentrum Karlsruhe (a large nuclear and basic research center). Scheer was member of the German Modern pentathlon national team in his youth. He became a member of the Bundestag in 1980, representing Baden-Württemberg; in 1993, he also became a member of the federal steering committee (\"Bundesvorstand\") of the Social Democratic Party. Scheer had a solid track record as an anti-establishment figure within his own party. He however never gained a direct majority based mandate in any political election and never held any executive post in government.\n\nIn the preelection shadow cabinet of Andrea Ypsilanti, candidate for prime minister of Hesse in 2008, Scheer was pegged unsuccessfully as minister for development, environment and economics. The final list long after the election mentioned him as secretary of a downsized ministry of economics Scheer announced ambitious energy policy plans, which failed to gain applause with his own party and possible coalition partners. Leading SPD figures as Jürgen Walter and Wolfgang Clement, a former Ministerpräsident which later left the party were rather critical. Scheer however believed Ypsilanti's strategies would result in a big triumph of his party at the federal elections 2009. However Ypsilanti's post election 'read my lips' attempt to partner with ex-communist Linkspartei and the Greens led to a complete failure.\n\nHis book Energy Autonomy was instrumental in the making of the film Die 4. Revolution – Energy Autonomy. Scheer advocated for the municipal ownership of utility companies, and was a supporter of the Campaign for the Establishment of a United Nations Parliamentary Assembly, an organisation which campaigns for democratic reformation of the United Nations. \n\nHe suddenly died in a hospital in Berlin from heart failure after an unspecified short and severe illness. His wife (since 1970), Irm Pontenagel, managed the solar lobby association Eurosolar for decades. His daughter Nina Scheer managed an eco management consulting company and is herself a member of the Bundestag. After his sudden death, SPD politician Rita Schwarzelühr-Sutter took his mandate via the German list system.\n\n\n\n"}
{"id": "2511800", "url": "https://en.wikipedia.org/wiki?curid=2511800", "title": "Hippolyte Pixii", "text": "Hippolyte Pixii\n\nHippolyte Pixii (1808–1835) was an instrument maker from Paris, France. In 1832 he built an early form of alternating current electrical generator, based on the principle of electromagnetic induction discovered by Michael Faraday. Pixii's device was a spinning magnet, operated by a hand crank, where the north and south poles passed over a coil with an iron core. A current pulse was experienced each time a pole passed over the coil. He also found that the current direction changed when the north pole passed over the coil after the south pole. Later, acting on a suggestion by André-Marie Ampère, other results were obtained by introducing a commutator which produced a pulsating direct current. At that time direct current was preferable to alternating current. Although Pixii did not fully understand electromagnetic induction, his device led to more sophisticated devices being constructed.\n\n"}
{"id": "49651549", "url": "https://en.wikipedia.org/wiki?curid=49651549", "title": "Ibiden", "text": "Ibiden\n\nIbiden was founded as an electrical power generation company in 1912. In the following decades the company diversified its operations and products, from power generation to electric furnace products (between 1917 and 1919), building materials (in 1960), printed circuit board (in 1972) and ceramic fibers (in 1974).\n\nToday electronic components and ceramics are the company's main products, with customers including Apple Inc., Intel and Groupe PSA (PSA Peugeot Citroën).\n\n"}
{"id": "1410429", "url": "https://en.wikipedia.org/wiki?curid=1410429", "title": "International POPs Elimination Network", "text": "International POPs Elimination Network\n\nThe International POPs Elimination Network (IPEN) is a global network of NGOs dedicated to the common aim of eliminating persistent organic pollutants.\n\nIPEN is composed of public interest non-governmental organizations who support a common platform for the global elimination of POPs. The Participating Organizations (POs) of IPEN are those NGOs which have endorsed the POPs Elimination Platform and/or the Stockholm Declaration. Because the network is primarily engaged in facilitating information exchange and in supporting activities of its constituents, and because the purpose of the network does not include developing network-wide-policy statements, strategies, or action plans, a formal decision-making process for the network can be simple, flexible, and largely administrative in nature. (IPEN 2005)\n\nThe International POPs Elimination Network (IPEN) is a global network of more than 600 public interest non-governmental organizations working together for the elimination of persistent organic pollutants, on an expedited yet socially equitable basis. This mission includes achieving a world in which all chemicals are produced and used in ways that eliminate significant adverse effects on human health and the environment, and where persistent organic pollutants (POPs) and chemicals of equivalent concern no longer pollute our local and global environments, and no longer contaminate our communities, our food, our bodies, or the bodies of our children and future generations.\n\n\n"}
{"id": "37839", "url": "https://en.wikipedia.org/wiki?curid=37839", "title": "Ion thruster", "text": "Ion thruster\n\nAn ion thruster or ion drive is a form of electric propulsion used for spacecraft propulsion. It creates thrust by accelerating positive ions with electricity. The term refers strictly to gridded electrostatic ion thrusters, and is often incorrectly loosely applied to all electric propulsion systems including electromagnetic plasma thrusters.\n\nAn ion thruster ionizes a neutral gas by extracting some electrons out of atoms, creating a cloud of positive ions. These thrusters rely mainly on electrostatics as ions are accelerated by the Coulomb force along an electric field. Temporarily stored electrons are finally reinjected by a \"neutralizer\" in the cloud of ions after it has passed through the electrostatic grid, so the gas becomes neutral again and can freely disperse in space without any further electrical interaction with the thruster. Electromagnetic thrusters on the contrary use the Lorentz force to accelerate all species (free electrons as well as positive and negative ions) in the same direction whatever their electric charge, and are specifically referred as plasma propulsion engines, where the electric field is not in the direction of the acceleration.\n\nIon thrusters in operational use have an input power need of 1–7 kW, exhaust velocity 20–50 km/s, thrust 25–250 millinewtons and efficiency 65–80% though experimental versions have achieved 100kW, 5N.\n\nThe Deep Space 1 spacecraft, powered by an ion thruster, changed velocity by 4.3 km/s while consuming less than 74 kilograms of xenon. The \"Dawn\" spacecraft broke the record, with a velocity change of  km/s.\n\nApplications include control of the orientation and position of orbiting satellites (some satellites have dozens of low-power ion thrusters) and use as a main propulsion engine for low-mass robotic space vehicles (such as \"Deep Space 1\" and \"Dawn\").\n\nIon thrust engines are practical only in the vacuum of space and cannot take vehicles through the atmosphere because ion engines do not work in the presence of ions outside the engine. Additionally, the engine's minuscule thrust cannot overcome any significant air resistance. Spacecraft rely on conventional chemical rockets to initially reach orbit.\n\nThe first person to mention the idea publicly was Konstantin Tsiolkovsky in 1911. However, the first document to consider electric propulsion is Robert H. Goddard's handwritten notebook in an entry dated September 6, 1906. The first experiments with ion thrusters were carried out by Goddard at Clark University from 1916–1917. The technique was recommended for near-vacuum conditions at high altitude, but thrust was demonstrated with ionized air streams at atmospheric pressure. The idea appeared again in Hermann Oberth's \"Wege zur Raumschiffahrt” (Ways to Spaceflight), published in 1923, where he explained his thoughts on the mass savings of electric propulsion, predicted its use in spacecraft propulsion and attitude control, and advocated electrostatic acceleration of charged gasses.\n\nA working ion thruster was built by Harold R. Kaufman in 1959 at the NASA Glenn Research Center facilities. It was similar to a gridded electrostatic ion thruster and used mercury for propellant. Suborbital tests were conducted during the 1960s and in 1964, the engine was sent into a suborbital flight aboard the Space Electric Rocket Test 1 (SERT 1). It successfully operated for the planned 31 minutes before falling to Earth. This test was followed by an orbital test, SERT-2, in 1970.\n\nAn alternate form of electric propulsion, the Hall effect thruster, was studied independently in the U.S. and the Soviet Union in the 1950s and 1960s. Hall effect thrusters operated on Soviet satellites from 1972 until the late 1990s, mainly used for satellite stabilization in North-South and in East-West directions. Some 100–200 engines completed missions on Soviet and Russian satellites. Soviet thruster design was introduced to the West in 1992 after a team of electric propulsion specialists, under the support of the Ballistic Missile Defense Organization, visited Soviet laboratories.\n\nIon thrusters use beams of ions (electrically charged atoms or molecules) to create thrust in accordance with momentum conservation. The method of accelerating the ions varies, but all designs take advantage of the charge/mass ratio of the ions. This ratio means that relatively small potential differences can create high exhaust velocities. This reduces the amount of reaction mass or propellant required, but increases the amount of specific power required compared to chemical rockets. Ion thrusters are therefore able to achieve high specific impulses. The drawback of the low thrust is low acceleration because the mass of the electric power unit directly correlates with the amount of power. This low thrust makes ion thrusters unsuited for launching spacecraft into orbit, but effective for in-space propulsion.\n\nIon thrusters are categorized as either electrostatic or electromagnetic. The main difference is the method for accelerating the ions.\n\nPower supplies for ion thrusters are usually electric solar panels, but at sufficiently large distances from the Sun, nuclear power is used. In each case, the power supply mass is proportional to the peak power that can be supplied, and both provide, for this application, almost no limit to the energy.\n\nElectric thrusters tend to produce low thrust, which results in low acceleration. Defining formula_1, the standard gravitational acceleration of Earth, and noting that formula_2, this can be analyzed. A NSTAR thruster producing a thrust force of 92 mN will accelerate a satellite with a mass of 1Mg by 0.092N / 1000 kg = 9.2 m/s (or 9.38 g). However, this acceleration can be sustained for months or years at a time, in contrast to the very short burns of chemical rockets.\n\nWhere\n\nThe ion thruster is not the most promising type of electrically powered spacecraft propulsion, but it is the most successful in practice to date. An ion drive would require two days to accelerate a car to highway speed. The technical characteristics, especially thrust, are considerably inferior to the prototypes described in literature, technical capabilities are limited by the space charge created by ions. This limits the thrust density (force per cross-sectional area of the engine). Ion thrusters create small thrust levels (the thrust of Deep Space 1 is approximately equal to the weight of one sheet of paper) compared to conventional chemical rockets, but achieve high specific impulse, or propellant mass efficiency, by accelerating the exhaust to high speed. The power imparted to the exhaust increases with the square of exhaust velocity while thrust increase is linear. Conversely, chemical rockets provide high thrust, but are limited in total impulse by the small amount of energy that can be stored chemically in the propellants. Given the practical weight of suitable power sources, the acceleration from an ion thruster is frequently less than one thousandth of standard gravity. However, since they operate as electric (or electrostatic) motors, they convert a greater fraction of input power into kinetic exhaust power. Chemical rockets operate as heat engines, and Carnot's theorem limits the exhaust velocity.\n\nGridded electrostatic ion thrusters commonly utilize xenon gas. The gaseous propellant begins with no charge; it is ionized by bombarding it with energetic electrons, as the energy transferred ejects valence electrons from the propellant gas's atoms. These electrons can be provided by a hot cathode filament and accelerated through the potential difference towards an anode. Alternatively, the electrons can be accelerated by an oscillating induced electric field created by an alternating electromagnet, which results in a self-sustaining discharge without a cathode (radio frequency ion thruster).\n\nThe positively charged ions are extracted by a system consisting of 2 or 3 multi-aperture grids. After entering the grid system near the plasma sheath, the ions are accelerated by the potential difference between the first grid and second grid (called the screen grid and the accelerator grid, respectively) to the final ion energy of (typically) 1–2 keV, which generates thrust.\n\nIon thrusters emit a beam of positively charged xenon ions. To keep the spacecraft from accumulating a charge, another cathode is placed near the engine to emit electrons into the ion beam, leaving the propellant electrically neutral. This prevents the beam of ions from being attracted (and returning) to the spacecraft, which would cancel the thrust.\n\nGridded electrostatic ion thruster research (past/present):\n\nHall effect thrusters accelerate ions by means of an electric potential between a cylindrical anode and a negatively charged plasma that forms the cathode. The bulk of the propellant (typically xenon) is introduced near the anode, where it ionizes and flows toward the cathode; ions accelerate towards and through it, picking up electrons as they leave to neutralize the beam and leave the thruster at high velocity.\n\nThe anode is at one end of a cylindrical tube. In the center is a spike that is wound to produce a radial magnetic field between it and the surrounding tube. The ions are largely unaffected by the magnetic field, since they are too massive. However, the electrons produced near the end of the spike to create the cathode are trapped by the magnetic field and held in place by their attraction to the anode. Some of the electrons spiral down towards the anode, circulating around the spike in a Hall current. When they reach the anode they impact the uncharged propellant and cause it to be ionized, before finally reaching the anode and closing the circuit.\n\nField-emission electric propulsion (FEEP) thrusters use either caesium or indium as the propellant. The design comprises a small propellant reservoir that stores the liquid metal, a narrow tube or a system of parallel plates that the liquid flows through and an accelerator (a ring or an elongated aperture in a metallic plate) about a millimeter past the tube end. Caesium and indium are used due to their high atomic weights, low ionization potentials and low melting points. Once the liquid metal reaches the end of the tube, an electric field applied between the emitter and the accelerator causes the liquid surface to deform into a series of protruding cusps, or \"Taylor cones\". At a sufficiently high applied voltage, positive ions are extracted from the tips of the cones. The electric field created by the emitter and the accelerator then accelerates the ions. An external source of electrons neutralizes the positively charged ion stream to prevent charging of the spacecraft.\n\nPulsed inductive thrusters (PIT) use pulses instead of continuous thrust and have the ability to run on power levels on the order of megawatts (MW). PITs consist of a large coil encircling a cone shaped tube that emits the propellant gas. Ammonia is the gas commonly used. For each pulse, a large charge builds up in a group of capacitors behind the coil and is then released. This creates a current that moves circularly in the direction of jθ. The current then creates a magnetic field in the outward radial direction (Br), which then creates a current in the gas that has just been released in the opposite direction of the original current. This opposite current ionizes the ammonia. The positively charged ions are accelerated away from the engine due to the electric field jθ crossing the magnetic field Br, due to the Lorentz Force.\n\nMagnetoplasmadynamic (MPD) thrusters and lithium Lorentz force accelerator (LiLFA) thrusters use roughly the same idea. The LiLFA thruster builds off of the MPD thruster. Hydrogen, argon, ammonia and nitrogen can be used as propellant. In a certain configuration, the ambient gas in low Earth orbit (LEO) can be used as a propellant. The gas enters the main chamber where it is ionized into plasma by the electric field between the anode and the cathode. This plasma then conducts electricity between the anode and the cathode, closing the circuit. This new current creates a magnetic field around the cathode, which crosses with the electric field, thereby accelerating the plasma due to the Lorentz force.\n\nThe LiLFA thruster uses the same general idea as the MPD thruster, with two main differences. First, the LiLFA uses lithium vapor, which can be stored as a solid. The other difference is that the single cathode is replaced by multiple, smaller cathode rods packed into a hollow cathode tube. MPD cathodes are easily corroded due to constant contact with the plasma. In the LiLFA thruster the lithium vapor is injected into the hollow cathode and is not ionized to its plasma form/corrode the cathode rods until it exits the tube. The plasma is then accelerated using the same Lorentz Force.\n\nIn 2013, Russian company the Chemical Automatics Design Bureau successfully conducted a bench test of their MPD engine for long-distance space travel.\n\nElectrodeless plasma thrusters have two unique features: the removal of the anode and cathode electrodes and the ability to throttle the engine. The removal of the electrodes eliminates erosion, which limits lifetime on other ion engines. Neutral gas is first ionized by electromagnetic waves and then transferred to another chamber where it is accelerated by an oscillating electric and magnetic field, also known as the ponderomotive force. This separation of the ionization and acceleration stages allows throttling of propellant flow, which then changes the thrust magnitude and specific impulse values.\n\nA helicon double layer thruster is a type of plasma thruster that ejects high velocity ionized gas to provide thrust. In this design, gas is injected into a tubular chamber (the \"source tube\") with one open end. Radio frequency AC power (at 13.56 MHz in the prototype design) is coupled into a specially shaped antenna wrapped around the chamber. The electromagnetic wave emitted by the antenna causes the gas to break down and form a plasma. The antenna then excites a helicon wave in the plasma, which further heats it. The device has a roughly constant magnetic field in the source tube (supplied by solenoids in the prototype), but the magnetic field diverges and rapidly decreases in magnitude away from the source region and might be thought of as a kind of magnetic nozzle. In operation, a sharp boundary separates the high density plasma inside the source region and the low density plasma in the exhaust, which is associated with a sharp change in electrical potential. Plasma properties change rapidly across this boundary, which is known as a \"current-free electric double layer\". The electrical potential is much higher inside the source region than in the exhaust and this serves both to confine most of the electrons and to accelerate the ions away from the source region. Enough electrons escape the source region to ensure that the plasma in the exhaust is neutral overall.\n\nVASIMR, or Variable Specific Impulse Magnetoplasma Rocket, works by using radio waves to ionize a propellant into a plasma and then a magnetic field to accelerate the plasma out of the back of the rocket engine to generate thrust. The VASIMR is currently being developed by the private company Ad Astra Rocket Company, headquartered in Houston, TX with of help from Canada-based Nautel, producing the 200 kW RF generators for ionizing propellant. Some of the components and \"plasma shoots\" experiments are tested in a laboratory settled in Liberia, Costa Rica. This project is led by former NASA astronaut Dr. Franklin Chang-Díaz (CRC-USA). An 200 kW VASIMR test engine was in discussion to be fitted in the exterior of the International Space Station, as part of the plan to test the VASIMR in space - however plans for this test onboard ISS were canceled in 2015 by NASA, with a free flying VASIMR test being discussed by Ad Astra instead. An envisioned 200 megawatt engine could reduce the duration of flight from Earth to Jupiter or Saturn from six years to fourteen months, and Mars from 6 months to 39 days.\n\nUnder a research grant from the NASA Lewis Research Center during the 1980s and 1990s, Martin C. Hawley and Jes Asmussen led a team of engineers in developing a Microwave Electrothermal Thruster (MET).\n\nIn the discharge chamber, microwave (MW) energy flows into the center containing a high level of ions (I), causing neutral species in the gaseous propellant to ionize. Excited species flow out (FES) through the low ion region (II) to a neutral region (III) where the ions complete their recombination, replaced with the flow of neutral species (FNS) towards the center. Meanwhile, energy is lost to the chamber walls through heat conduction and convection (HCC), along with radiation (Rad). The remaining energy absorbed into the gaseous propellant is converted into thrust.\n\nIon thrusters' low thrust requires continuous operation for a long time to achieve the necessary change in velocity (delta-v) for a particular mission. Ion thrusters are designed to provide continuous operation for intervals of weeks to years.\n\nThe lifetime of electrostatic ion thrusters is limited by several processes. In electrostatic gridded designs, charge-exchange ions produced by the beam ions with the neutral gas flow can be accelerated towards the negatively biased accelerator grid and cause grid erosion. End-of-life is reached when either the grid structure fails or the holes in the grid become large enough that ion extraction is substantially affected; e.g., by the occurrence of electron backstreaming. Grid erosion cannot be avoided and is the major lifetime-limiting factor. Thorough grid design and material selection enable lifetimes of 20,000 hours or more.\n\nA test of the NASA Solar Technology Application Readiness (NSTAR) electrostatic ion thruster resulted in 30,472 hours (roughly 3.5 years) of continuous thrust at maximum power. Post-test examination indicated the engine was not approaching failure.\n\nThe NASA Evolutionary Xenon Thruster (NEXT) project operated continuously for more than 48,000 hours. The test was conducted in a high vacuum test chamber. Over the course of the 5 1/2 + year test, the engine consumed approximately 870 kilograms of xenon propellant. The total impulse generated would require over 10,000 kilograms of conventional rocket propellant for a similar application.\n\nThe Advanced Electric Propulsion System (AEPS) is expected to accumulate about 5,000 hr and the design aims to achieve a flight model that offers a half-life of at least 23,000 hours and a full life of about 50,000 hours. \nHall thrusters suffer from strong erosion of the ceramic discharge chamber by impact of energetic ions: a test reported in 2010 showed erosion of around 1 mm per hundred hours of operation, though this is inconsistent with observed on-orbit lifetimes of a few thousand hours.\n\nIonization energy represents a large percentage of the energy needed to run ion drives. The ideal propellant is thus easy to ionize and has a high mass/ionization energy ratio. In addition, the propellant should not erode the thruster to any great degree to permit long life; and should not contaminate the vehicle.\n\nMany current designs use xenon gas, as it is easy to ionize, has a reasonably high atomic number, is inert and causes low erosion. However, xenon is globally in short supply and expensive.\n\nOlder designs used mercury, but this is toxic and expensive, tended to contaminate the vehicle with the metal and was difficult to feed accurately. A modern commercial prototype may be using mercury successfully.\n\nOther propellants, such as bismuth and iodine, show promise, particularly for gridless designs, such as Hall effect thrusters.\n\nVASIMR design (and other plasma-based engines) are theoretically able to use practically any material for propellant. However, in current tests the most practical propellant is argon, which is relatively abundant and inexpensive.\n\nThe CubeSat Ambipolar Thruster (CAT) used on the Mars Array of Ionospheric Research Satellites Using the CubeSat Ambipolar Thruster (MARS-CAT) mission proposes to use solid iodine as the propellant to minimize storage volume.\n\nIon thruster efficiency is the kinetic energy of the exhaust jet emitted per second divided by the electrical power into the device.\n\nOverall system energy efficiency is determined by the propulsive efficiency, which depends on vehicle speed and exhaust speed. Some thrusters can vary exhaust speed in operation, but all can be designed with different exhaust speeds. At the lower end of specific impulse, \"I\", the overall efficiency drops, because ionization takes up a larger percentage energy and at the high end propulsive efficiency is reduced.\n\nOptimal efficiencies and exhaust velocities for any given mission can be calculated to give minimum overall cost.\n\nIon thrusters have many in-space propulsion applications. The best applications make use of the long mission interval when significant thrust is not needed. Examples of this include orbit transfers, attitude adjustments, drag compensation for low Earth orbits, fine adjustments for scientific missions and cargo transport between propellant depots, e.g., for chemical fuels. Ion thrusters can also be used for interplanetary and deep-space missions where acceleration rates are not crucial. Continuous thrust over a long interval can reach high velocities while consuming far less fuel than traditional chemical rockets.\n\nAmong electric thrusters, ion thrusters have received the most serious commercial and academic consideration. Ion thrusters are seen as the best solution for these missions, as they require high change in velocity but do not require rapid acceleration.\n\nIon propulsion systems were first demonstrated in space by the NASA Lewis (now Glenn Research Center) missions \"Space Electric Rocket Test\" (SERT) I and II. SERT-1 was launched July 20, 1964, and successfully proved that the technology operated as predicted in space. These were electrostatic ion thrusters using mercury and cesium as the reaction mass. SERT-II, launched on February 3, 1970, verified the operation of two mercury ion engines for thousands of running hours.\n\nIon thrusters are routinely used for station-keeping on commercial and military communication satellites in geosynchronous orbit. The Soviet Union pioneered this field, using Stationary Plasma Thruster (SPT) thrusters on satellites starting in the early 1970s.\n\nTwo geostationary satellites (ESA's Artemis in 2001–03 and the US military's AEHF-1 in 2010–12) used the ion thruster to change orbit after the chemical-propellant engine failed. Boeing began using ion thrusters for station-keeping in 1997 and planned in 2013–14 to offer a variant on their 702 platform, with no chemical engine and ion thrusters for orbit raising; this permits a significantly lower launch mass for a given satellite capability. AEHF-2 used a chemical engine to raise perigee to 10,150 miles and proceeded to geosynchronous orbit using electric propulsion.\n\nESA's Gravity Field and Steady-State Ocean Circulation Explorer (GOCE) was launched on March 16, 2009. It used ion propulsion throughout its twenty-month mission to combat the air-drag it experienced in its low orbit (altitude of 255 kilometres) before intentionally deorbiting on November 11, 2013.\n\nNASA developed the NSTAR ion engine for use in interplanetary science missions beginning in the late-1990s. It was space-tested in the highly successful space probe \"Deep Space 1\", launched in 1998. This was the first use of electric propulsion as the interplanetary propulsion system on a science mission. Based on the NASA design criteria, Hughes Research Labs, developed the Xenon Ion Propulsion System (XIPS) for performing station keeping on geosynchronous satellites. Hughes (EDD) manufactured the NSTAR thruster used on the spacecraft.\n\nThe Japanese space agency's \"Hayabusa\" launched in 2003 and successfully rendezvoused with the asteroid 25143 Itokawa and remained in close proximity for months to collect samples and information. It was powered by four xenon ion engines. Its xenon ions were generated by microwave electron cyclotron resonance and an erosion-resistant carbon/carbon-composite material for its acceleration grid. Although the ion engines on \"Hayabusa\" had technical difficulties, in-flight reconfiguration allowed one of the four engines to be repaired and allowed the mission to successfully return to Earth.\n\nThe European Space Agency's satellite \"SMART-1\" launched in 2003 using a Snecma PPS-1350-G Hall thruster to get from GTO to lunar orbit. This satellite completed its mission on September 3, 2006, in a controlled collision on the Moon's surface, after a trajectory deviation so scientists could see the 3 meter crater the impact created on the visible side of the Moon.\n\n\"Dawn\" launched on September 27, 2007, to explore the asteroid Vesta and the dwarf planet Ceres. It used three \"Deep Space 1\" heritage xenon ion thrusters (firing one at a time). \"Dawn\" ion drive is capable of accelerating from 0 to in 4 days of continuous firing. The mission ended on November 1, 2018, when the spacecraft ran out of propellant.\n\nLISA Pathfinder is an ESA spacecraft launched in 2015. It does not use ion thrusters as its primary propulsion system, but uses both colloid thrusters and FEEP for precise attitude control — the low thrusts of these propulsion devices make it possible to move the spacecraft incremental distances accurately. It is a test for the possible LISA mission. The mission ended on December 30, 2017.\n\nESA's BepiColombo mission was launched to Mercury on October 20, 2018. It uses ion thrusters in combination with swing-bys to get to Mercury, where a chemical rocket will complete orbit insertion.\n\nThe Lunar Orbital Platform-Gateway is proposed to have a module called 'Power and Propulsion Element' (PPE) that will be used to generate electricity for the space station and its ion thruster. It is targeting launch on a commercial vehicle in 2022. It will probably use the 50 kW Advanced Electric Propulsion System (AEPS) under development at NASA Glenn Research Center and Aerojet Rocketdyne.\n\n, a future launch of an Ad Astra VF-200 VASIMR electromagnetic thruster was under consideration for testing on the International Space Station. However, in 2015 NASA ended plans for flying the VF-200 to the ISS. A NASA spokesperson stated that the ISS \"was not an ideal demonstration platform for the desired performance level of the engines\". Ad Astra stated that tests of a VASIMR thruster on the ISS would remain an option after a future in-space demonstration.\n\nThe VF-200 would have been a flight version of the VX-200. Since the available power from the ISS is less than 200 kW, the ISS VASIMR would have included a trickle-charged battery system allowing for 15 min pulses of thrust. The ISS orbits at a relatively low altitude and experiences fairly high levels of atmospheric drag, requiring periodic altitude boosts - a high efficiency engine (high specific impulse) for station-keeping would be valuable, theoretically VASIMR reboosting could cut fuel cost from the current $210 million annually to one-twentieth. VASIMR could in theory use as little as 300 kg of argon gas for ISS station-keeping instead of 7.5 tonnes of chemical fuel - the high exhaust velocity (high specific impulse) would achieve the same acceleration with a smaller amount of propellant, compared to chemical propulsion with its lower exhaust velocity needing more fuel. Hydrogen is generated by the ISS as a by-product and is vented into space.\n\nNASA previously worked on a 50 kW ion hall thruster for ISS, but work was stopped in 2005.\n\nThe MARS-CAT (Mars Array of ionospheric Research Satellites using the CubeSat Ambipolar Thruster) mission is a two 6U CubeSat concept mission to study Mars' ionosphere. The mission would investigate its plasma and magnetic structure, including transient plasma structures, magnetic field structure, magnetic activity and correlation with solar wind drivers. The CAT thruster is now called the RF thruster and manufactured by Phase Four.\n\nGeoffrey A. Landis proposed to use a space laser source and ion thruster to propel an interstellar probe.\n\nThe idea of an ion engine first appeared in Donald W Horner's \"By Aeroplane to the Sun: Being the Adventures of a Daring Aviator and his Friends\" (1910).\n\nIon propulsion is the main thrust source of the spaceship \"Kosmokrator\" in the Eastern German/Polish science fiction movie \"Der Schweigende Stern\" (1960). Minute 28:10.\n\nIn the 1968 episode of \"\", \"Spock's Brain\", Scotty is repeatedly impressed by a civilization's use of ion power.\n\n\"Star Wars\" films and literature refer to twin ion engines (TIE) starfighters.\n\nIon thrusters appear as the primary form of propulsion in vacuum for the spacecraft in the game \"Space Engineers\".\n\n\n"}
{"id": "48441167", "url": "https://en.wikipedia.org/wiki?curid=48441167", "title": "Kijiya", "text": "Kijiya\n\nAlternative names used to refer to \"kijiya\" include: , , , , , .\n"}
{"id": "35014501", "url": "https://en.wikipedia.org/wiki?curid=35014501", "title": "Le Fleuve Niger se meurt", "text": "Le Fleuve Niger se meurt\n\nLe Fleuve Niger se meurt is a 2006 documentary film.\n\nThis short documentary film tells the story of Alfari, who lives on the bank of the Niger, a river which is slowly running dry due to climate change. Alfari had to give up fishing to become a gardener, fighting against the hippopotamus that devastate his plantations.\n\n"}
{"id": "158011", "url": "https://en.wikipedia.org/wiki?curid=158011", "title": "Lipid bilayer", "text": "Lipid bilayer\n\nThe lipid bilayer (or phospholipid bilayer) is a thin polar membrane made of two layers of lipid molecules. These membranes are flat sheets that form a continuous barrier around all cells. The cell membranes of almost all organisms and many viruses are made of a lipid bilayer, as are the nuclear membrane surrounding the cell nucleus, and other membranes surrounding sub-cellular structures. The lipid bilayer is the barrier that keeps ions, proteins and other molecules where they are needed and prevents them from diffusing into areas where they should not be. Lipid bilayers are ideally suited to this role, even though they are only a few nanometers in width, they are impermeable to most water-soluble (hydrophilic) molecules. Bilayers are particularly impermeable to ions, which allows cells to regulate salt concentrations and pH by transporting ions across their membranes using proteins called ion pumps.\n\nBiological bilayers are usually composed of amphiphilic phospholipids that have a hydrophilic phosphate head and a hydrophobic tail consisting of two fatty acid chains. Phospholipids with certain head groups can alter the surface chemistry of a bilayer and can, for example, serve as signals as well as \"anchors\" for other molecules in the membranes of cells. Just like the heads, the tails of lipids can also affect membrane properties, for instance by determining the phase of the bilayer. The bilayer can adopt a solid gel phase state at lower temperatures but undergo phase transition to a fluid state at higher temperatures, and the chemical properties of the lipids' tails influence at which temperature this happens. The packing of lipids within the bilayer also affects its mechanical properties, including its resistance to stretching and bending. Many of these properties have been studied with the use of artificial \"model\" bilayers produced in a lab. Vesicles made by model bilayers have also been used clinically to deliver drugs.\n\nBiological membranes typically include several types of molecules other than phospholipids. A particularly important example in animal cells is cholesterol, which helps strengthen the bilayer and decrease its permeability. Cholesterol also helps regulate the activity of certain integral membrane proteins. Integral membrane proteins function when incorporated into a lipid bilayer, and they are held tightly to lipid bilayer with the help of an annular lipid shell. Because bilayers define the boundaries of the cell and its compartments, these membrane proteins are involved in many intra- and inter-cellular signaling processes. Certain kinds of membrane proteins are involved in the process of fusing two bilayers together. This fusion allows the joining of two distinct structures as in the fertilization of an egg by sperm or the entry of a virus into a cell. Because lipid bilayers are quite fragile and invisible in a traditional microscope, they are a challenge to study. Experiments on bilayers often require advanced techniques like electron microscopy and atomic force microscopy.\n\nWhen phospholipids are exposed to water, they self-assemble into a two-layered sheet with the hydrophobic tails pointing toward the center of the sheet. This arrangement results in two “leaflets” that are each a single molecular layer. The center of this bilayer contains almost no water and excludes molecules like sugars or salts that dissolve in water. The assembly process is driven by interactions between hydrophobic molecules (also called the hydrophobic effect). An increase in interactions between hydrophobic molecules (causing clustering of hydrophobic regions) allows water molecules to bond more freely with each other, increasing the entropy of the system. This complex process includes non-covalent interactions such as van der Waals forces, electrostatic and hydrogen bonds.\nThe lipid bilayer is very thin compared to its lateral dimensions. If a typical mammalian cell (diameter ~10 micrometers) were magnified to the size of a watermelon (~1 ft/30 cm), the lipid bilayer making up the plasma membrane would be about as thick as a piece of office paper. Despite being only a few nanometers thick, the bilayer is composed of several distinct chemical regions across its cross-section. These regions and their interactions with the surrounding water have been characterized over the past several decades with x-ray reflectometry, neutron scattering and nuclear magnetic resonance techniques.\n\nThe first region on either side of the bilayer is the hydrophilic headgroup. This portion of the membrane is completely hydrated and is typically around 0.8-0.9 nm thick. In phospholipid bilayers the phosphate group is located within this hydrated region, approximately 0.5 nm outside the hydrophobic core. In some cases, the hydrated region can extend much further, for instance in lipids with a large protein or long sugar chain grafted to the head. One common example of such a modification in nature is the lipopolysaccharide coat on a bacterial outer membrane, which helps retain a water layer around the bacterium to prevent dehydration.\n\nNext to the hydrated region is an intermediate region that is only partially hydrated. This boundary layer is approximately 0.3 nm thick. Within this short distance, the water concentration drops from 2M on the headgroup side to nearly zero on the tail (core) side. The hydrophobic core of the bilayer is typically 3-4 nm thick, but this value varies with chain length and chemistry. Core thickness also varies significantly with temperature, in particular near a phase transition.\n\nIn many naturally occurring bilayers, the compositions of the inner and outer membrane leaflets are different. In human red blood cells, the inner (cytoplasmic) leaflet is composed mostly of phosphatidylethanolamine, phosphatidylserine and phosphatidylinositol and its phosphorylated derivatives. By contrast, the outer (extracellular) leaflet is based on phosphatidylcholine, sphingomyelin and a variety of glycolipids, In some cases, this asymmetry is based on where the lipids are made in the cell and reflects their initial orientation. The biological functions of lipid asymmetry are imperfectly understood, although it is clear that it is used in several different situations. For example, when a cell undergoes apoptosis, the phosphatidylserine — normally localised to the cytoplasmic leaflet — is transferred to the outer surface: There, it is recognised by a macrophage that then actively scavenges the dying cell.\n\nLipid asymmetry arises, at least in part, from the fact that most phospholipids are synthesised and initially inserted into the inner monolayer: those that constitute the outer monolayer are then transported from the inner monolayer by a class of enzymes called flippases. Other lipids, such as sphingomyelin, appear to be synthesised at the external leaflet. Flippases are members of a larger family of lipid transport molecules that also includes floppases, which transfer lipids in the opposite direction, and scramblases, which randomize lipid distribution across lipid bilayers (as in apoptotic cells). In any case, once lipid asymmetry is established, it does not normally dissipate quickly because spontaneous flip-flop of lipids between leaflets is extremely slow.\n\nIt is possible to mimic this asymmetry in the laboratory in model bilayer systems. Certain types of very small artificial vesicle will automatically make themselves slightly asymmetric, although the mechanism by which this asymmetry is generated is very different from that in cells. By utilizing two different monolayers in Langmuir-Blodgett deposition or a combination of Langmuir-Blodgett and vesicle rupture deposition it is also possible to synthesize an asymmetric planar bilayer. This asymmetry may be lost over time as lipids in supported bilayers can be prone to flip-flop.\n\nAt a given temperature a lipid bilayer can exist in either a liquid or a gel (solid) phase. All lipids have a characteristic temperature at which they transition (melt) from the gel to liquid phase. In both phases the lipid molecules are prevented from flip-flopping across the bilayer, but in liquid phase bilayers a given lipid will exchange locations with its neighbor millions of times a second. This random walk exchange allows lipid to diffuse and thus wander across the surface of the membrane. Unlike liquid phase bilayers, the lipids in a gel phase bilayer have less mobility.\n\nThe phase behavior of lipid bilayers is determined largely by the strength of the attractive Van der Waals interactions between adjacent lipid molecules. Longer-tailed lipids have more area over which to interact, increasing the strength of this interaction and, as a consequence, decreasing the lipid mobility. Thus, at a given temperature, a short-tailed lipid will be more fluid than an otherwise identical long-tailed lipid. Transition temperature can also be affected by the degree of unsaturation of the lipid tails. An unsaturated double bond can produce a kink in the alkane chain, disrupting the lipid packing. This disruption creates extra free space within the bilayer that allows additional flexibility in the adjacent chains. An example of this effect can be noted in everyday life as butter, which has a large percentage saturated fats, is solid at room temperature while vegetable oil, which is mostly unsaturated, is liquid.\n\nMost natural membranes are a complex mixture of different lipid molecules. If some of the components are liquid at a given temperature while others are in the gel phase, the two phases can coexist in spatially separated regions, rather like an iceberg floating in the ocean. This phase separation plays a critical role in biochemical phenomena because membrane components such as proteins can partition into one or the other phase and thus be locally concentrated or activated. One particularly important component of many mixed phase systems is cholesterol, which modulates bilayer permeability, mechanical strength, and biochemical interactions.\n\nWhile lipid tails primarily modulate bilayer phase behavior, it is the headgroup that determines the bilayer surface chemistry. Most natural bilayers are composed primarily of phospholipids, but sphingolipids and sterols such as cholesterol are also important components. Of the phospholipids, the most common headgroup is phosphatidylcholine (PC), accounting for about half the phospholipids in most mammalian cells. PC is a zwitterionic headgroup, as it has a negative charge on the phosphate group and a positive charge on the amine but, because these local charges balance, no net charge.\n\nOther headgroups are also present to varying degrees and can include phosphatidylserine (PS) phosphatidylethanolamine (PE) and phosphatidylglycerol (PG). These alternate headgroups often confer specific biological functionality that is highly context-dependent. For instance, PS presence on the extracellular membrane face of erythrocytes is a marker of cell apoptosis, whereas PS in growth plate vesicles is necessary for the nucleation of hydroxyapatite crystals and subsequent bone mineralization. Unlike PC, some of the other headgroups carry a net charge, which can alter the electrostatic interactions of small molecules with the bilayer.\n\nThe primary role of the lipid bilayer in biology is to separate aqueous compartments from their surroundings. Without some form of barrier delineating “self” from “non-self,” it is difficult to even define the concept of an organism or of life. This barrier takes the form of a lipid bilayer in all known life forms except for a few species of archaea that utilize a specially adapted lipid monolayer. It has even been proposed that the very first form of life may have been a simple lipid vesicle with virtually its sole biosynthetic capability being the production of more phospholipids. The partitioning ability of the lipid bilayer is based on the fact that hydrophilic molecules cannot easily cross the hydrophobic bilayer core, as discussed in Transport across the bilayer below. The nucleus, mitochondria and chloroplasts have two lipid bilayers, while other sub-cellular structures are surrounded by a single lipid bilayer (such as the plasma membrane, endoplasmic reticula, Golgi apparatus and lysosomes). See Organelle.\n\nProkaryotes have only one lipid bilayer- the cell membrane (also known as the plasma membrane). Many prokaryotes also have a cell wall, but the cell wall is composed of proteins or long chain carbohydrates, not lipids. In contrast, eukaryotes have a range of organelles including the nucleus, mitochondria, lysosomes and endoplasmic reticulum. All of these sub-cellular compartments are surrounded by one or more lipid bilayers and, together, typically comprise the majority of the bilayer area present in the cell. In liver hepatocytes for example, the plasma membrane accounts for only two percent of the total bilayer area of the cell, whereas the endoplasmic reticulum contains more than fifty percent and the mitochondria a further thirty percent.\n\nProbably the most familiar form of cellular signaling is synaptic transmission, whereby a nerve impulse that has reached the end of one neuron is conveyed to an adjacent neuron via the release of neurotransmitters. This transmission is made possible by the action of synaptic vesicles loaded with the neurotransmitters to be released. These vesicles fuse with the cell membrane at the pre-synaptic terminal and release its contents to the exterior of the cell. The contents then diffuse across the synapse to the post-synaptic terminal.\n\nLipid bilayers are also involved in signal transduction through their role as the home of integral membrane proteins. This is an extremely broad and important class of biomolecule. It is estimated that up to a third of the human proteome may be membrane proteins. Some of these proteins are linked to the exterior of the cell membrane. An example of this is the CD59 protein, which identifies cells as “self” and thus inhibits their destruction by the immune system. The HIV virus evades the immune system in part by grafting these proteins from the host membrane onto its own surface. Alternatively, some membrane proteins penetrate all the way through the bilayer and serve to relay individual signal events from the outside to the inside of the cell. The most common class of this type of protein is the G protein-coupled receptor (GPCR). GPCRs are responsible for much of the cell’s ability to sense its surroundings and, because of this important role, approximately 40% of all modern drugs are targeted at GPCRs.\n\nIn addition to protein- and solution-mediated processes, it is also possible for lipid bilayers to participate directly in signaling. A classic example of this is phosphatidylserine-triggered phagocytosis. Normally, phosphatidylserine is asymmetrically distributed in the cell membrane and is present only on the interior side. During programmed cell death a protein called a scramblase equilibrates this distribution, displaying phosphatidylserine on the extracellular bilayer face. The presence of phosphatidylserine then triggers phagocytosis to remove the dead or dying cell.\n\nThe lipid bilayer is a very difficult structure to study because it is so thin and fragile. In spite of these limitations dozens of techniques have been developed over the last seventy years to allow investigations of its structure and function.\n\nElectrical measurements are a straightforward way to characterize an important function of a bilayer: its ability to segregate and prevent the flow of ions in solution. By applying a voltage across the bilayer and measuring the resulting current, the resistance of the bilayer is determined. This resistance is typically quite high (10 Ohm-cm or more) since the hydrophobic core is impermeable to charged species. The presence of even a few nanometer-scale holes results in a dramatic increase in current. The sensitivity of this system is such that even the activity of single ion channels can be resolved.\n\nElectrical measurements do not provide an actual picture like imaging with a microscope can. Lipid bilayers cannot be seen in a traditional microscope because they are too thin. In order to see bilayers, researchers often use fluorescence microscopy. A sample is excited with one wavelength of light and observed in a different wavelength, so that only fluorescent molecules with a matching excitation and emission profile will be seen. Natural lipid bilayers are not fluorescent, so a dye is used that attaches to the desired molecules in the bilayer. Resolution is usually limited to a few hundred nanometers, much smaller than a typical cell but much larger than the thickness of a lipid bilayer.\n\nElectron microscopy offers a higher resolution image. In an electron microscope, a beam of focused electrons interacts with the sample rather than a beam of light as in traditional microscopy. In conjunction with rapid freezing techniques, electron microscopy has also been used to study the mechanisms of inter- and intracellular transport, for instance in demonstrating that exocytotic vesicles are the means of chemical release at synapses.\n\nP-NMR(nuclear magnetic resonance) spectroscopy is widely used for studies of phospholipid bilayers and biological membranes in native conditions. The analysis of P-NMR spectra of lipids could provide a wide range of information about lipid bilayer packing, phase transitions (gel phase, physiological liquid crystal phase, ripple phases, non bilayer phases), lipid head group orientation/dynamics, and elastic properties of pure lipid bilayer and as a result of binding of proteins and other biomolecules.\n\nA new method to study lipid bilayers is Atomic force microscopy (AFM). Rather than using a beam of light or particles, a very small sharpened tip scans the surface by making physical contact with the bilayer and moving across it, like a record player needle. AFM is a promising technique because it has the potential to image with nanometer resolution at room temperature and even under water or physiological buffer, conditions necessary for natural bilayer behavior. Utilizing this capability, AFM has been used to examine dynamic bilayer behavior including the formation of transmembrane pores (holes) and phase transitions in supported bilayers. Another advantage is that AFM does not require fluorescent or isotopic labeling of the lipids, since the probe tip interacts mechanically with the bilayer surface. Because of this, the same scan can image both lipids and associated proteins, sometimes even with single-molecule resolution. AFM can also probe the mechanical nature of lipid bilayers.\n\nLipid bilayers exhibit high levels of birefringence where the refractive index in the plane of the bilayer differs from that perpendicular by as much as 0.1 refractive index units. This has been used to characterise the degree of order and disruption in bilayers using dual polarisation interferometry to understand mechanisms of protein interaction.\n\nLipid bilayers are complicated molecular systems with many degrees of freedom. Thus atomistic simulation of membrane and in particular ab initio calculations of its properties is difficult and computationally expensive. Quantum chemical calculations has recently been successfully performed to estimate dipole and quadrupole moments of lipid membranes.\n\nMost polar molecules have low solubility in the hydrocarbon core of a lipid bilayer and, as a consequence, have low permeability coefficients across the bilayer. This effect is particularly pronounced for charged species, which have even lower permeability coefficients than neutral polar molecules. Anions typically have a higher rate of diffusion through bilayers than cations. Compared to ions, water molecules actually have a relatively large permeability through the bilayer, as evidenced by osmotic swelling. When a cell or vesicle with a high interior salt concentration is placed in a solution with a low salt concentration it will swell and eventually burst. Such a result would not be observed unless water was able to pass through the bilayer with relative ease. The anomalously large permeability of water through bilayers is still not completely understood and continues to be the subject of active debate. Small uncharged apolar molecules diffuse through lipid bilayers many orders of magnitude faster than ions or water. This applies both to fats and organic solvents like chloroform and ether. Regardless of their polar character larger molecules diffuse more slowly across lipid bilayers than small molecules.\n\nTwo special classes of protein deal with the ionic gradients found across cellular and sub-cellular membranes in nature- ion channels and ion pumps. Both pumps and channels are integral membrane proteins that pass through the bilayer, but their roles are quite different. Ion pumps are the proteins that build and maintain the chemical gradients by utilizing an external energy source to move ions against the concentration gradient to an area of higher chemical potential. The energy source can be ATP, as is the case for the Na-K ATPase. Alternatively, the energy source can be another chemical gradient already in place, as in the Ca/Na antiporter. It is through the action of ion pumps that cells are able to regulate pH via the pumping of protons.\n\nIn contrast to ion pumps, ion channels do not build chemical gradients but rather dissipate them in order to perform work or send a signal. Probably the most familiar and best studied example is the voltage-gated Na channel, which allows conduction of an action potential along neurons. All ion pumps have some sort of trigger or “gating” mechanism. In the previous example it was electrical bias, but other channels can be activated by binding a molecular agonist or through a conformational change in another nearby protein.\n\nSome molecules or particles are too large or too hydrophilic to pass through a lipid bilayer. Other molecules could pass through the bilayer but must be transported rapidly in such large numbers that channel-type transport is impractical. In both cases, these types of cargo can be moved across the cell membrane through fusion or budding of vesicles. When a vesicle is produced inside the cell and fuses with the plasma membrane to release its contents into the extracellular space, this process is known as exocytosis. In the reverse process, a region of the cell membrane will dimple inwards and eventually pinch off, enclosing a portion of the extracellular fluid to transport it into the cell. Endocytosis and exocytosis rely on very different molecular machinery to function, but the two processes are intimately linked and could not work without each other. The primary mechanism of this interdependence is the sheer volume of lipid material involved. In a typical cell, an area of bilayer equivalent to the entire plasma membrane will travel through the endocytosis/exocytosis cycle in about half an hour. If these two processes were not balancing each other, the cell would either balloon outward to an unmanageable size or completely deplete its plasma membrane within a matter of minutes.\n\nExocytosis in prokaryotes: Membrane vesicular exocytosis, popularly known as membrane vesicle trafficking, a Nobel prize-winning (year, 2013) process, is traditionally regarded as a prerogative of eukaryotic cells. This \"myth\" was however broken with the revelation that nanovesicles, popularly known as bacterial outer membrane vesicles, released by gram-negative microbes, translocate bacterial signal molecules to host or target cells to carry out multiple processes in favour of the secreting microbe e.g., in \"host cell invasion\" and microbe-environment interactions, in general.\n\nElectroporation is the rapid increase in bilayer permeability induced by the application of a large artificial electric field across the membrane. Experimentally, electroporation is used to introduce hydrophilic molecules into cells. It is a particularly useful technique for large highly charged molecules such as DNA, which would never passively diffuse across the hydrophobic bilayer core. Because of this, electroporation is one of the key methods of transfection as well as bacterial transformation. It has even been proposed that electroporation resulting from lightning strikes could be a mechanism of natural horizontal gene transfer.\n\nThis increase in permeability primarily affects transport of ions and other hydrated species, indicating that the mechanism is the creation of nm-scale water-filled holes in the membrane. Although electroporation and dielectric breakdown both result from application of an electric field, the mechanisms involved are fundamentally different. In dielectric breakdown the barrier material is ionized, creating a conductive pathway. The material alteration is thus chemical in nature. In contrast, during electroporation the lipid molecules are not chemically altered but simply shift position, opening up a pore that acts as the conductive pathway through the bilayer as it is filled with water.\n\nLipid bilayers are large enough structures to have some of the mechanical properties of liquids or solids. The area compression modulus K, bending modulus K, and edge energy formula_1, can be used to describe them. Solid lipid bilayers also have a shear modulus, but like any liquid, the shear modulus is zero for fluid bilayers. These mechanical properties affect how the membrane functions. K and K affect the ability of proteins and small molecules to insert into the bilayer, and bilayer mechanical properties have been shown to alter the function of mechanically activated ion channels. Bilayer mechanical properties also govern what types of stress a cell can withstand without tearing. Although lipid bilayers can easily bend, most cannot stretch more than a few percent before rupturing.\n\nAs discussed in the Structure and organization section, the hydrophobic attraction of lipid tails in water is the primary force holding lipid bilayers together. Thus, the elastic modulus of the bilayer is primarily determined by how much extra area is exposed to water when the lipid molecules are stretched apart. It is not surprising given this understanding of the forces involved that studies have shown that K varies strongly with osmotic pressure but only weakly with tail length and unsaturation. Because the forces involved are so small, it is difficult to experimentally determine K. Most techniques require sophisticated microscopy and very sensitive measurement equipment.\n\nIn contrast to K, which is a measure of how much energy is needed to stretch the bilayer, K is a measure of how much energy is needed to bend or flex the bilayer. Formally, bending modulus is defined as the energy required to deform a membrane from its intrinsic curvature to some other curvature. Intrinsic curvature is defined by the ratio of the diameter of the head group to that of the tail group. For two-tailed PC lipids, this ratio is nearly one so the intrinsic curvature is nearly zero. If a particular lipid has too large a deviation from zero intrinsic curvature it will not form a bilayer and will instead form other phases such as micelles or inverted micelles. Addition of \"small hydrophilic molecules\" like \"sucrose\" into mixed lipid \"lamellar liposomes\" made from galactolipid-rich thylakoid membranes destabilises bilayers into micellar phase. Typically, K is not measured experimentally but rather is calculated from measurements of K and bilayer thickness, since the three parameters are related.\n\nformula_1 is a measure of how much energy it takes to expose a bilayer edge to water by tearing the bilayer or creating a hole in it. The origin of this energy is the fact that creating such an interface exposes some of the lipid tails to water, but the exact orientation of these border lipids is unknown. There is some evidence that both hydrophobic (tails straight) and hydrophilic (heads curved around) pores can coexist.\n\nFusion is the process by which two lipid bilayers merge, resulting in one connected structure. If this fusion proceeds completely through both leaflets of both bilayers, a water-filled bridge is formed and the solutions contained by the bilayers can mix. Alternatively, if only one leaflet from each bilayer is involved in the fusion process, the bilayers are said to be hemifused. Fusion is involved in many cellular processes, in particular in eukaryotes, since the eukaryotic cell is extensively sub-divided by lipid bilayer membranes. Exocytosis, fertilization of an egg by sperm and transport of waste products to the lysozome are a few of the many eukaryotic processes that rely on some form of fusion. Even the entry of pathogens can be governed by fusion, as many bilayer-coated viruses have dedicated fusion proteins to gain entry into the host cell.\n\nThere are four fundamental steps in the fusion process. First, the involved membranes must aggregate, approaching each other to within several nanometers. Second, the two bilayers must come into very close contact (within a few angstroms). To achieve this close contact, the two surfaces must become at least partially dehydrated, as the bound surface water normally present causes bilayers to strongly repel. The presence of ions, in particular divalent cations like magnesium and calcium, strongly affects this step. One of the critical roles of calcium in the body is regulating membrane fusion. Third, a destabilization must form at one point between the two bilayers, locally distorting their structures. The exact nature of this distortion is not known. One theory is that a highly curved \"stalk\" must form between the two bilayers. Proponents of this theory believe that it explains why phosphatidylethanolamine, a highly curved lipid, promotes fusion. Finally, in the last step of fusion, this point defect grows and the components of the two bilayers mix and diffuse away from the site of contact.\n\nThe situation is further complicated when considering fusion \"in vivo\" since biological fusion is almost always regulated by the action of membrane-associated proteins. The first of these proteins to be studied were the viral fusion proteins, which allow an enveloped virus to insert its genetic material into the host cell (enveloped viruses are those surrounded by a lipid bilayer; some others have only a protein coat). Eukaryotic cells also use fusion proteins, the best-studied of which are the SNAREs. SNARE proteins are used to direct all vesicular intracellular trafficking. Despite years of study, much is still unknown about the function of this protein class. In fact, there is still an active debate regarding whether SNAREs are linked to early docking or participate later in the fusion process by facilitating hemifusion.\n\nIn studies of molecular and cellular biology it is often desirable to artificially induce fusion. The addition of polyethylene glycol (PEG) causes fusion without significant aggregation or biochemical disruption. This procedure is now used extensively, for example by fusing B-cells with myeloma cells. The resulting “hybridoma” from this combination expresses a desired antibody as determined by the B-cell involved, but is immortalized due to the melanoma component. Fusion can also be artificially induced through electroporation in a process known as electrofusion. It is believed that this phenomenon results from the energetically active edges formed during electroporation, which can act as the local defect point to nucleate stalk growth between two bilayers.\n\nLipid bilayers can be created artificially in the lab to allow researchers to perform experiments that cannot be done with natural bilayers. They can also be used in the field of Synthetic Biology, to define the boundaries of artificial cells. These synthetic systems are called model lipid bilayers. There are many different types of model bilayers, each having experimental advantages and disadvantages. They can be made with either synthetic or natural lipids. Among the most common model systems are:\n\n\nTo date, the most successful commercial application of lipid bilayers has been the use of liposomes for drug delivery, especially for cancer treatment. (Note- the term “liposome” is in essence synonymous with “vesicle” except that vesicle is a general term for the structure whereas liposome refers to only artificial not natural vesicles) The basic idea of liposomal drug delivery is that the drug is encapsulated in solution inside the liposome then injected into the patient. These drug-loaded liposomes travel through the system until they bind at the target site and rupture, releasing the drug. In theory, liposomes should make an ideal drug delivery system since they can isolate nearly any hydrophilic drug, can be grafted with molecules to target specific tissues and can be relatively non-toxic since the body possesses biochemical pathways for degrading lipids.\n\nThe first generation of drug delivery liposomes had a simple lipid composition and suffered from several limitations. Circulation in the bloodstream was extremely limited due to both renal clearing and phagocytosis. Refinement of the lipid composition to tune fluidity, surface charge density, and surface hydration resulted in vesicles that adsorb fewer proteins from serum and thus are less readily recognized by the immune system. The most significant advance in this area was the grafting of polyethylene glycol (PEG) onto the liposome surface to produce “stealth” vesicles, which circulate over long times without immune or renal clearing.\n\nThe first stealth liposomes were passively targeted at tumor tissues. Because tumors induce rapid and uncontrolled angiogenesis they are especially “leaky” and allow liposomes to exit the bloodstream at a much higher rate than normal tissue would. More recently work has been undertaken to graft antibodies or other molecular markers onto the liposome surface in the hope of actively binding them to a specific cell or tissue type. Some examples of this approach are already in clinical trials.\n\nAnother potential application of lipid bilayers is the field of biosensors. Since the lipid bilayer is the barrier between the interior and exterior of the cell, it is also the site of extensive signal transduction. Researchers over the years have tried to harness this potential to develop a bilayer-based device for clinical diagnosis or bioterrorism detection. Progress has been slow in this area and, although a few companies have developed automated lipid-based detection systems, they are still targeted at the research community. These include Biacore (now GE Healthcare Life Sciences), which offers a disposable chip for utilizing lipid bilayers in studies of binding kinetics and Nanion Inc., which has developed an automated patch clamping system. Other, more exotic applications are also being pursued such as the use of lipid bilayer membrane pores for DNA sequencing by Oxford Nanolabs. To date, this technology has not proven commercially viable.\n\nA supported lipid bilayer (SLB) as described above has achieved commercial success as a screening technique to measure the permeability of drugs. This parallel artificial membrane permeability assay PAMPA technique measures the permeability across specifically formulated lipid cocktail(s) found to be highly correlated with Caco-2 cultures, the gastrointestinal tract, blood–brain barrier and skin.\n\nBy the early twentieth century scientists had come to believe that cells are surrounded by a thin oil-like barrier, but the structural nature of this membrane was not known. Two experiments in 1925 laid the groundwork to fill in this gap. By measuring the capacitance of erythrocyte solutions, Hugo Fricke determined that the cell membrane was 3.3 nm thick.\n\nAlthough the results of this experiment were accurate, Fricke misinterpreted the data to mean that the cell membrane is a single molecular layer. Prof. Dr. Evert Gorter (1881–1954) and F. Grendel of Leiden University approached the problem from a different perspective, spreading the erythrocyte lipids as a monolayer on a Langmuir-Blodgett trough. When they compared the area of the monolayer to the surface area of the cells, they found a ratio of two to one. Later analyses showed several errors and incorrect assumptions with this experiment but, serendipitously, these errors canceled out and from this flawed data Gorter and Grendel drew the correct conclusion- that the cell membrane is a lipid bilayer.\n\nThis theory was confirmed through the use of electron microscopy in the late 1950s. Although he did not publish the first electron microscopy study of lipid bilayers J. David Robertson was the first to assert that the two dark electron-dense bands were the headgroups and associated proteins of two apposed lipid monolayers. In this body of work, Robertson put forward the concept of the “unit membrane.” This was the first time the bilayer structure had been universally assigned to all cell membranes as well as organelle membranes.\n\nAround the same time, the development of model membranes confirmed that the lipid bilayer is a stable structure that can exist independent of proteins. By “painting” a solution of lipid in organic solvent across an aperture, Mueller and Rudin were able to create an artificial bilayer and determine that this exhibited lateral fluidity, high electrical resistance and self-healing in response to puncture, all of which are properties of a natural cell membrane. A few years later, Alec Bangham showed that bilayers, in the form of lipid vesicles, could also be formed simply by exposing a dried lipid sample to water. This was an important advance, since it demonstrated that lipid bilayers form spontaneously via self assembly and do not require a patterned support structure.\n\nIn 1977, a totally synthetic bilayer membrane was prepared by Kunitake and Okahata, from a single organic compound, didodecyldimethylammonium bromide. It clearly shows that the bilayer membrane was assembled by the van der Waals interaction.\n\n\n"}
{"id": "30870496", "url": "https://en.wikipedia.org/wiki?curid=30870496", "title": "Lloyd in Space", "text": "Lloyd in Space\n\nLloyd in Space is an American animated television series, created by Joe Ansolabehere and Paul Germain (previous creators of \"Recess\"), and premiered in 2001 on ABC-TV on Saturday mornings. The pilot was written by Ansolabehere, Germain and Mark Drop. The characters were designed by Eric Keyes. Reruns have aired on \"Toon Disney\" until 2006, when it was replaced by \"The Emperor's New School\".\n\nLiving far in the future, shortly after the end of World War IX, Lloyd Nebulon is a green-skinned alien (of the Verdigrean race) with pointy ears and a single antenna sticking from his head. Lloyd lives in the Intrepidville Space Station along with his telekinetic and telepathic little sister Francine and his mother, Commander Norah Li Nebulon, the Head of Intrepidville. Lloyd's friends are Eddie R. Horton (a red-haired teenage human), Kurt Blobberts (an enormous purple blob with a single eyeball and simple intelligence, of a species known as the Blobullons), and Douglas McNoggin (a giant brain with limbs and a face, of a species known as the Cerebellians).\n\n\"Lloyd in Space\" was first introduced in early 2001 during Disney's One Saturday Morning on ABC. The show received higher ratings than initially expected, prompting Disney to quickly order additional episodes (some of which would air in the second season).\n\n\"Lloyd in Space\" finished production in 2003, after the \"One Saturday Morning\" block was removed. The final episodes aired in February 2004.\n\n\n\n\n\n\n"}
{"id": "227709", "url": "https://en.wikipedia.org/wiki?curid=227709", "title": "Meniscus (liquid)", "text": "Meniscus (liquid)\n\nThe meniscus (plural: \"menisci\", from the Greek for \"crescent\") is the curve in the upper surface of a liquid close to the surface of the container or another object, caused by surface tension. It can be either concave or convex, depending on the liquid and the surface.\n\nA concave meniscus occurs when the particles of the liquid are more strongly attracted to the container (adhesion) than to each other (cohesion), causing the liquid to climb the walls of the container. This occurs between water and glass. Water-based fluids like sap, honey, and milk also have a concave meniscus in glass or other wettable containers.\n\nConversely, a convex meniscus occurs when the particles in the liquid have a stronger attraction to each other than to the material of the container. Convex menisci occur, for example, between mercury and glass in barometers and thermometers.\n\nThe formation of menisci is commonly used in surface science to measure contact angles and surface tension. In a contact angle measurement, the shape of the menisci is measured with a balance or optically with a digital camera. In a surface tension measurement, the measurement probe has a contact angle of zero and the surface tension can be obtained by measuring the mass of the menisci. This is typically done with a Wilhelmy plate.\n\nWhen reading a depth scale on the side of an instrument filled with liquid, such as a water level device, the meniscus must be taken into account in order to obtain an accurate measurement. Depth must be measured with the meniscus at eye level (to eliminate parallax error) and at the center of the meniscus, i.e. the top of a convex meniscus or the bottom of a concave meniscus.\n\nManufacturers of glassware and other tools calibrate their measurement marks to account for the meniscus. This means that any instrument is calibrated for a specific liquid, usually water.\n\nMenisci are a manifestation of capillary action, by which surface adhesion pulls a liquid up to form a concave meniscus or internal cohesion pulls the liquid down to form a convex meniscus. This phenomenon is important in transpirational pull in plants. When a tube of a narrow bore, often called a capillary tube, is dipped into a liquid and the liquid wets the tube (with zero contact angle), the liquid surface inside the tube forms a concave meniscus, which is a virtually spherical surface having the same radius, \"r\", as the inside of the tube. The tube experiences a downward force of magnitude 2πrσ, where σ is the surface tension of the liquid.\n"}
{"id": "56072420", "url": "https://en.wikipedia.org/wiki?curid=56072420", "title": "Mineral bonded wood wool board", "text": "Mineral bonded wood wool board\n\nMineral bonded wood wool boards (WW boards) are building boards made of wood wool fibres, water and the binding agents cement, caustic magnesia and gypsum. Mineral bound wood wool boards are used in a wide range of applications, e.g., thermal insulation, acoustic insulation, indoor decoration, etc.\n\nHistorical brand names include Ceban, Erulit, Fibrolith, Frankotekt, Hapec, Hapri, Heraklith, Hincolith, Holwolith, Klimalit, Lenzolite, Lignolith, Lossius and Saalith. Because of the term \"wool\", laypersons sometimes mistake wood wool boards with \"wood fibre insulating boards\", a different insulation material that does not contain mineral bindings.\n\nIn German speaking areas, because of their surface also known as \"sauerkraut plates\".\n\nWood wool boards were standardised in 1938 according to DIN 1101 and are therefore among the oldest insulation materials made of renewable raw materials. This standard was replaced by European Standard EN 13168 in January 2002.\n\nWood wool boards and wood-wool layers in composite boards are generally manufactured using coniferous wood species, mainly spruce and pine. The wood logs are processed to make wood fibres of various widths, generally between 1mm and 3mm. After drying the wood, it is planed into long fibres in a wood wool machine. The fibres are then mixed with the binding agent (caustic magnesite or cement) in a water solution, in a mixer. Wood wool boards which are bound with magnesite are easily distinguishable by their beige colour. Boards which are bound with grey cement have a greyish colour. White cement is used to maintain the natural colour of the wood. The combination of wood wool fibres and binding agent is automatically fed into a moulding line to be shaped according to the required board dimensions (length, width and thickness). After pre-compaction, the endless row of moulds filled with the mixture is separated into individual moulds with a saw. The moulds are stacked on top of each other, pressed again and weighted so that they are perfectly flush with each other. After hardening of the binder (usually between 24 and 48 hours) the moulds are removed, the semi-finished boards are dried and cut to raw size. The products are then taken to the maturation stock where they will remain for a period that depends on type of binder and thickness. The boards can be subject to further processing in the finishing department, e.g. in case a special edge profile or board shape is needed. The whole production process is carried out in such way that the product meets the requirements set in EN 13168.\n\nWood wool boards are rigid and very strong. Their thermal conductivity is higher than other insulation material between 0.070 and 0.100 W/mK compared with mineral wool insulation materials to approximately 0.040 W/mK. But their specific thermal capacity and therefore summer heat insulation is higher than other materials, e.g. when installed in lofts’ pitched roofs, wood wool boards offer better properties than basic dry wall systems in terms of summer heat insulation. Wood wool boards can be made to offer a high degree of sound insulation (e.g. if they are plastered) or sound absorption performance (e.g. non-plastered boards) and a good moisture-regulating capacity thanks to their open structure. In the harmonized Euroclass system of reaction to fire performance of building products, wood wool boards can be classified as A2-s1,d0 according to EN 13501-1 Fire classification of construction products and building elements; Part 1: Classification using data from reaction to fire tests.\n\nIn combination with other insulation materials (e.g mineral wool), the resistance against fire can reach up to two hundred forty minutes depending on the product’s thickness and setup.\n\nWood wool composite boards (WW-C boards) are a two- or three-layer combination of wood wool boards and various insulation materials (mineral fibre boards, EPS boards, XPS boards, etc…) The thickness of the wood wool layer in a composite board is at least 5 mm. Due to the higher insulation effect of the mineral or synthetic insulation layer, composite boards provide a higher level of thermal insulation relative to single wood wool boards.\n\n"}
{"id": "6263612", "url": "https://en.wikipedia.org/wiki?curid=6263612", "title": "Naturgy", "text": "Naturgy\n\nNaturgy Energy Group S.A., formerly Gas Natural Fenosa (), is a Spanish natural gas and electrical energy utilities company, which operates primarily in Spain. The company's administrative headquarters are in Barcelona, while its registered office is in Madrid.\n\nIt also has operations in other countries, including: Italy, France, Germany, The Netherlands, Belgium, Mexico, Colombia, Argentina, Puerto Rico, Moldova, and Morocco.\n\nThe corporation's main interests are: the distribution of natural gas in Spain, Italy, and Latin America; the generation and commercialisation of electricity in the liberalised Spanish market (1997-2009); and the management of natural gas infrastructure and shipping transport.\n\nGas Natural has approximately 10,000,000 energy clients worldwide. It has around 6,700 employees, of which approximately 50% work within Spain.\n\nThe group's largest shareholders include the Spanish \"La Caixa\" bank and Repsol global energy company. \n\n\"Gas Natural\" acquired utility company \"Unión Fenosa\" for around €16.8 billion in 2009.\n\nIn June 2018, the general shareholders meeting of Gas Natural approved the change of name of the company, baptized Naturgy Energy Group.\n\nThe company's administrative headquarters complex, Gas Natural Building or \"Mare Nostrum Tower\", is located in the La Barceloneta neighbourhood of the Ciutat Vella district in Barcelona. Its registered office is being moved to Madrid.\n\nThe skyscraper was designed in the High-tech architectural style by the EMBT Architects firm of architects Enric Miralles and Benedetta Tagliabue, and was completed in 2005.\n\n"}
{"id": "30960266", "url": "https://en.wikipedia.org/wiki?curid=30960266", "title": "Nirmal toys and craft", "text": "Nirmal toys and craft\n\nNirmal toys are traditional Indian wooden toys made in the town of Nirmal in the Adilabad district in the newly formed state of Telangana in India.\n\nNirmal Art, encompassing a 400-year-old tradition of making soft wood toys and paintings, occupies a place of pride in the world of handicrafts. The finely carved figures and dainty paintings are still being used to decorate drawing rooms in thousands of homes across the country. Nirmal district in Telangana was once famous as a production centre of as diverse things as cannons and toys. While the foundry supplied heavy artillery to the army of the Nizam of Hyderabad, the Naqqash craftsmen and artists brought out exquisite wooden toys and duco paintings under the name of Nirmal Art.\nThe foundry was closed soon after Hyderabad's accession but the art form has survived many ups and downs, the most impacting being the loss of its patron, the Nizam. Elegant toys and paintings continue to be produced by the Naqqash artisans at this town located just 4 km off the new four lane National Highway No. 7 about 220 km from Hyderabad.\nThough no records pertaining to their origins exist now, it is believed the Naqqash families were brought here from Rajasthan in the 17th century by Neema Naik (or Nimma Naidu according to another version), the local chieftain after whom the town itself is named. Many changes have since been incorporated in their art form obviously to suit the taste of the patrons of the time.\n\nInitially, the Naqqash, or Jingar artisans, had produced only toys from the locally available variety of softwood called poniki or white sander. They made wooden furniture during the last Nizam's rule.\nNow, they are carved from local softwood and painted with Duco paints. \nThe Jingars have discontinued making the fine Kishti (tray), Khanchibba chowki (settee) or the Palang (cot) owing to the change in customs. “These articles were used as dowry gifts in marriages and were ordered mostly by the Muslim nobility during the time of the Nizam\".\nGanjifa playing cards are also traditionally made in Nirmal, but as of February 2011, only one elderly artisan was still making them. The artists shifted from natural dyes to duco paints. Due to use of the duco colours, the Nirmal paintings acquire a typical shine. The toys are also painted in enamel colours giving them the sheen they are known for.\n\n"}
{"id": "69937", "url": "https://en.wikipedia.org/wiki?curid=69937", "title": "Nuclear pulse propulsion", "text": "Nuclear pulse propulsion\n\nNuclear pulse propulsion or external pulsed plasma propulsion, is a hypothetical method of spacecraft propulsion that uses nuclear explosions for thrust. It was first developed as Project \"Orion\" by DARPA, after a suggestion by Stanislaw Ulam in 1947. Newer designs using inertial confinement fusion have been the baseline for most post-\"Orion\" designs, including Project \"Daedalus\" and Project \"Longshot\".\n\nProject Orion was the first serious attempt to design a nuclear pulse rocket. The design effort was carried out at General Atomics in the late 1950s and early 1960s. The idea of \"Orion\" was to react small directional nuclear explosives utilizing a variant of the Teller-Ulam two-stage bomb design against a large steel pusher plate attached to the spacecraft with shock absorbers. Efficient directional explosives maximized the momentum transfer, leading to specific impulses in the range of 6,000 seconds, or about thirteen times that of the Space Shuttle Main Engine. With refinements a theoretical maximum of 100,000 seconds (1 MN·s/kg) might be possible. Thrusts were in the millions of tons, allowing spacecraft larger than 8 × 10 tons to be built with 1958 materials.\n\nThe reference design was to be constructed of steel using submarine-style construction with a crew of more than 200 and a vehicle takeoff weight of several thousand tons.\nThis low-tech single-stage reference design would reach Mars and back in four weeks from the Earth's surface (compared to 12 months for NASA's current chemically powered reference mission). The same craft could visit Saturn's moons in a seven-month mission (compared to chemically powered missions of about nine years).\n\nA number of engineering problems were found and solved over the course of the project, notably related to crew shielding and pusher-plate lifetime. The system appeared to be entirely workable when the project was shut down in 1965, the main reason being given that the Partial Test Ban Treaty made it illegal (however, before the treaty, the US and Soviet Union had already detonated at least nine nuclear bombs, including thermonuclear bombs, in space, i.e., at altitudes over 100 km: see high altitude nuclear explosions). There were also ethical issues with launching such a vehicle within the Earth's magnetosphere: calculations using the now disputed linear no-threshold model of radiation damage showed that the fallout from each takeoff would kill between 1 and 10 people. In a threshold model, such extremely low levels of thinly distributed radiation would have no associated ill-effects, while under hormesis models, such tiny doses would be negligibly beneficial. With the possible use of less efficient clean nuclear bombs for achieving orbit and then more efficient higher yield dirty bombs for travel would bring down the amount of fallout caused from an Earth-based launch by a significant factor.\n\nOne useful mission for this near-term technology would be to deflect an asteroid that could collide with the Earth, depicted dramatically in the 1998 film \"Deep Impact\", even though it was a comet in that particular film. The extremely high performance would permit even a late launch to succeed, and the vehicle could effectively transfer a large amount of kinetic energy to the asteroid by simple impact, and in the event of an imminent asteroid impact a few predicted deaths from fallout would probably not be considered prohibitive. Also, an automated mission would eliminate the most problematic issues of the design: the shock absorbers.\n\nOrion is one of very few interstellar space drives that could theoretically be constructed with available technology, as discussed in a 1968 paper, \"Interstellar Transport\" by Freeman Dyson.\n\nProject Daedalus was a study conducted between 1973 and 1978 by the British Interplanetary Society (BIS) to design a plausible interstellar unmanned spacecraft that could reach a nearby star within one human scientist's working lifetime or about 50 years. A dozen scientists and engineers led by Alan Bond worked on the project. At the time fusion research appeared to be making great strides, and in particular, inertial confinement fusion (ICF) appeared to be adaptable as a rocket engine.\n\nICF uses small pellets of fusion fuel, typically lithium deuteride (LiH) with a small deuterium/tritium trigger at the center. The pellets are thrown into a reaction chamber where they are hit on all sides by lasers or another form of beamed energy. The heat generated by the beams explosively compresses the pellet, to the point where fusion takes place. The result is a hot plasma, and a very small \"explosion\" compared to the minimum size bomb that would be required to instead create the necessary amount of fission.\n\nFor Daedalus, this process was run within a large electromagnet which formed the rocket engine. After the reaction, ignited by electron beams in this case, the magnet funnelled the hot gas to the rear for thrust. Some of the energy was diverted to run the ship's systems and engine. In order to make the system safe and energy efficient, Daedalus was to be powered by a helium-3 fuel that would have had to be collected from Jupiter.\n\nThe \"Medusa\" design is a type of nuclear pulse propulsion which has more in common with solar sails than with conventional rockets. It was envisioned by Johndale Solem in the 1990s and published in the \"Journal of the British Interplanetary Society\" (JBIS).\n\nA \"Medusa\" spacecraft would deploy a large “spinnaker” sail ahead of it, attached by separate independent cables, and then launch nuclear explosives forward to detonate between itself and its sail. The sail would be accelerated by the plasma and photonic impulse, running out the tethers as when a fish flees the fisherman, and generating electricity at the “reel”. The spacecraft would then use some of the generated electricity to reel itself up towards the sail, constantly smoothly accelerating as it goes.\n\nIn the original design, multiple tethers connected to multiple motor generators. The advantage over the single tether is to increase the distance between the explosion and the tethers, thus reducing damage to the tethers.\n\nFor heavy payloads, performance could be improved by taking advantage of lunar materials, for example, wrapping the explosive with lunar rock or water, likely stored previously at a stable Earth-Moon Lagrange point to be subsequently acquired by the \"Medusa\" spacecraft.\n\n\"Medusa\" performs better than the classical Orion design because its sail intercepts more of the explosive impulse, its shock-absorber stroke is much longer, and all its major structures are in tension and hence can be quite lightweight. \"Medusa\"-type ships would be capable of a specific impulse between 50,000 and 100,000 seconds (500 to 1000 kN·s/kg).\n\n\"Medusa\" is widely known to the public in the BBC documentary film \"To Mars By A-Bomb: The Secret History of Project Orion\". A short film shows an artist’s conception of how the \"Medusa\" spacecraft works “by throwing bombs into a sail that's ahead of it!”\n\nProject Longshot was a NASA-sponsored research project carried out in conjunction with the US Naval Academy in the late 1980s. \"Longshot\" was in some ways a development of the basic Daedalus concept, in that it used magnetically funneled ICF as a rocket. The key difference was that they felt that the reaction could not power both the rocket and the systems, and instead included a 300 kW conventional nuclear reactor for running the ship. The added weight of the reactor reduced performance somewhat, but even using LiD fuel it would be able to reach Alpha Centauri, the closest solar system to our own, in 100 years (approx. velocity of 13,411 km/s, at a distance of 4.5 light years - equivalent to 4.5% of light speed).\n\nIn the mid-1990s research at the Pennsylvania State University led to the concept of using antimatter to catalyze nuclear reactions. In short, antiprotons would react inside the nucleus of uranium, causing a release of energy that breaks the nucleus apart as in conventional nuclear reactions. Even a small number of such reactions can start the chain reaction that would otherwise require a much larger volume of fuel to sustain. Whereas the \"normal\" critical mass for plutonium is about 11.8 kilograms (for a sphere at standard density), with antimatter catalyzed reactions this could be well under one gram.\n\nSeveral rocket designs using this reaction were proposed, some which would use all-fission reactions for interplanetary missions, and others using fission-fusion (effectively a very small version of Orion's bombs) for interstellar missions.\n\nNASA funded MSNW LLC and the University of Washington in 2011 to study and develop a fusion rocket through the NASA Innovative Advanced Concepts NIAC Program.\n\nThe rocket uses a form of magneto-inertial fusion to produce a direct thrust fusion rocket. Powerful magnetic fields cause large metal rings (likely made of lithium, where a set for one pulse has a total mass of 365 grams) to collapse around the deuterium-tritium plasma, compressing it to a fusion state. Energy from these fusion reactions heats and ionizes the shell of metal formed by the crushed rings. The hot, ionized metal is shot out of a magnetic rocket nozzle at a high speed (up to 30 km/s). Repeating this process roughly every minute would propel the spacecraft. The fusion reaction is not self-sustaining and requires electrical energy to induce fusion. With electrical requirements estimated to be between 100 kW to 1,000 kW (300 kW average), spacecraft designs incorporate solar panels to produce the electrical energy needed for the fusion engine. \nThis approach uses Foil Liner Compression to create a fusion reaction of the proper energy scale to be used for space propulsion. The proof of concept experiment in Redmond, Washington, will use aluminum liners for compression. However, the actual rocket design will run with lithium liners.\n\nThe performance characteristics of the engine are highly dependent on the Fusion energy gain factor achieved by the reactor. Gains are expected to be between a factor of 20 and 200, with an estimated average of 40. With higher fusions gains comes higher exhaust velocity, higher specific impulse and lower electrical power requirements. The table below summarizes different performance characteristics for a theoretical 90-day Mars transfer at gains of 20, 40 and 200.\n\n, MSNW has demonstrated subcomponents of the systems: heating deuterium plasma up to fusion temperatures and have concentrated the magnetic fields needed to create fusion. They plan to put the two technologies together for a test before the end of 2013.\n\nThey will later be scaled up in power and plan to add the necessary fusion fuel (deuterium) by the end (Sept 2014) of the NIAC Study.\n\n"}
{"id": "15424786", "url": "https://en.wikipedia.org/wiki?curid=15424786", "title": "Odorizer", "text": "Odorizer\n\nAn odorizer is a device that adds an odorant to a gas. The most common type is one that adds a mercaptan liquid into natural gas distribution systems so that leaks can be readily detected. Other types have been used for carbon dioxide fire extinguishers.\n\nNatural gas odorizers run the gamut from a simple wick in a container to computerized equipment, which controls the amount of odorant based on flow rate, tracks the amount of odorant in inventory, and alarms when odorant is not being injected into the gas stream.\n\nOdorants used for natural gas vary from country to country, depending on gas distribution regulations. Some odorants contain sulfur, which is oxidized to sulfur dioxide when the gas is burned. \n\nSulfur containing odorants include:\nNon-sulfur containing odorants include:\n\nWick type odorizers can be very small, odorizing the gas for as few as one gas customer to much larger ones that can odorize the gas for a small town (10,000 MCF). They use a wick which is very similar to those used in a kerosene lantern. The odorant is drawn up the wick from the container and into the gas stream.\n\nAbsorption bypass odorizers take a portion of the gas stream, the amount being dependent on the flow of gas in the line, and run it through a tank containing liquid odorant. The gas is passed over the top of the liquid. Variations exist where wicks are utilized to increase odorant vaporization.\n\nFor very high volume systems (and for some smaller volume systems), liquid injection odorizers are being manufactured. These odorizers work by the addition of small amounts of liquid odorant to the moving gas. A pump that can be controlled to give the range of addition rates necessary is a very important aspect of this type of odorizer. Computer control to monitor flow rates and vary injection rate is a significant part of the more modern versions of this. Previous versions worked off a variety of schemes to control the odorization level.\n\nThe Peerless odorizer was the first example of this type of odorizer. The Peerless natural-gas odorizer was recognized as a Mechanical Engineering Landmark by the American Society of Mechanical Engineers in 1992. This odorizer was said to have been developed in response to the New London School explosion that occurred in March 1937. It was first shipped in July 1937, the Peerless odorizer overcame two of the major problems of previous devices:\n\n\nOdorizers are used in carbon dioxide fire extinguisher systems, the odorizer assembly injects wintergreen oil into the carbon dioxide stream when the agent is discharged. Approximately 50 cc of wintergreen oil contained within a frangible glass cartridge is mounted within a protective housing attached to the discharge piping in such a manner as to rupture the glass container when the carbon dioxide manifold is pressurized during discharge, atomizing the oil and dispersing it. The strong wintergreen scent effectively notifies the occupants of the presence of carbon dioxide gas after carbon dioxide has been discharged into the hazard.\n\nSimilar systems are used in mines, where ampoules of ethanethiol are broken in front of ventilation fans to warn of gas in the mines.\n\n"}
{"id": "2920705", "url": "https://en.wikipedia.org/wiki?curid=2920705", "title": "Peg wooden doll", "text": "Peg wooden doll\n\nPeg wooden dolls, also known as Dutch dolls, are a type of wooden doll from the Netherlands and Germany. They originated as simple lathe-turned dolls from the Val Gardena in the Alps. These dolls were sold undressed. Children would then make their clothing from scraps of fabric.\n\nOther similarly constructed wooden dolls, using a jointing technique where the arms and/or legs are attached to the body with pegs, are some of the oldest surviving dolls, and were made worldwide. Sometimes a peg wooden doll's arms or legs are locked together by the jointing system, so if one arm is moved the other will move. An advanced form of peg joints is where the body pegs are \"split\" and attached separately allowing independent movement.\n\n\"Tuck comb dolls\" are a special style of peg wooden doll, named for their carved hair comb. The head and body are turned as one piece. The hair is usually painted with curled fringes and with a painted comb. Early tuck comb dolls had elongated, graceful proportions, nicely carved details, painted slippers, and sometimes with wood pendant earrings. Some dressed as merchants were called \"pedlar dolls\".\n\nFlorence Kate Upton illustrated a children's book entitled \"The Adventures of Two Dutch Dolls and a Golliwogg\".\n\nThe Museum Gherdëina has a collection of Dutch dolls of different sizes.\n\n"}
{"id": "43826458", "url": "https://en.wikipedia.org/wiki?curid=43826458", "title": "Penguin Island Conservation Park", "text": "Penguin Island Conservation Park\n\nPenguin Island Conservation Park (formerly Penguin Island National Parks Reserve) is a protected area occupying Penguin Island and part of Cape Martin on the mainland in Rivoli Bay on the south east coast of South Australia about south of Beachport. \n\nThe land on Penguin Island became subject to protection after the decommissioning of the Penguin Island Lighthouse in 1960 due to recognition by the South Australian government of ‘the importance of Penguin Island as a seabird haven’. Initially, the island was resumed under the \"Crown Lands Act 1929-57\" and then it was declared as a Closed Area under the \"Animals and Birds Protection Act 1919-1953\". In 1961, the island was established as a wildlife reserve. On 9 November 1967, the entire island was proclaimed under the \"National Parks Act 1966\" as \"Penguin Island National Parks Reserve\". Land associated with Cape Martin was added to the protected area in 1970 and 1976 respectively. \n\nThe conservation park is classified as an IUCN Category IA protected area.\n\n"}
{"id": "20465089", "url": "https://en.wikipedia.org/wiki?curid=20465089", "title": "Pine–cypress forest", "text": "Pine–cypress forest\n\nPine–cypress forest is a type of mixed conifer woodland in which at least one species of pine and one species of cypress are present. Such forests are noted in several parts of North America including Florida and California. \n\nCalifornia occurrences of pine–cypress forest are typically along Pacific coastal headlands. Understory species in these California pine–cypress forests include salal and western poison oak.\n\nMany of the Florida occurrences of pine–cypress forest are in swampy areas such as the Everglades.\n\n"}
{"id": "29285", "url": "https://en.wikipedia.org/wiki?curid=29285", "title": "Semtex", "text": "Semtex\n\nSemtex is a general-purpose plastic explosive containing RDX and PETN. It is used in commercial blasting, demolition, and in certain military applications. \n\nSemtex was developed and manufactured in Czechoslovakia, originally under the name B 1 and then under \"Semtex\" designation since 1964, labeled as \"SEMTEX 1A\", since 1967 as \"SEMTEX H\" and since 1987 as \"SEMTEX 10\".\n\nOriginally developed for Czechoslovak military use and export, Semtex eventually became popular with paramilitary groups and rebels or terrorists because prior to second millennia it was extremely difficult to detect, as in the case of Pan Am Flight 103.\n\nThe composition of the two most common variants differ according to their use. The 1A (or 10) variant is used for blasting, and is based mostly on crystalline PETN. The version 1AP and 2P are formed as hexagonal booster charges; a special assembly of PETN and wax inside the charge assures high reliability for detonating cord or detonator. The H (or SE) variant is intended for explosion hardening.\n\nSemtex was invented in the late 1950s by Stanislav Brebera and Radim Fukátko, chemists at VCHZ Synthesia, Czechoslovakia (now Czech Republic). The explosive is named after Semtín, a suburb of Pardubice where the mixture was first manufactured starting in 1964. The plant was later renamed to become Explosia a.s., a subsidiary of Synthesia.\n\nSemtex was very similar to other plastic explosives, especially C-4, in being highly malleable; but it is usable over a greater temperature range than other plastic explosives, since it stays plastic between −40 and +60 °C. It is also waterproof. There are visual differences between Semtex and other plastic explosives, too: while C-4 is off-white in colour, Semtex is red or brick-orange.\n\nThe new explosive was widely exported, notably to the government of North Vietnam, which received 14 tons during the Vietnam War. However, the main consumer was Libya; about 700 tons of Semtex were exported to Libya between 1975 and 1981 by Omnipol. It has also been used by Islamic militants in the Middle East and by the Provisional Irish Republican Army (IRA) and the Irish National Liberation Army in Northern Ireland.\n\nExports fell after the name became closely associated with terrorist attacks. Export of Semtex was progressively tightened and since 2002 all of Explosia's sales have been controlled by a government ministry. , only approximately 10 tons of Semtex were produced annually, almost all for domestic use. On December 21, 1988, 12 ounces (340g) of Semtex brought down a Boeing 747 over Lockerbie, Scotland killing all 259 aboard the aircraft and many on the ground, some bodies were never recovered.\n\nAlso in response to international agreements, Semtex has a detection taggant added to produce a distinctive vapor signature to aid detection. First, ethylene glycol dinitrate was used, later switched to 2,3-dimethyl-2,3-dinitrobutane (3,4-dinitrohexane, DMDNB) or \"p\"-mononitrotoluene, which is used currently. According to the manufacturer, the taggant agent was voluntarily being added by 1991, years before the protocol signed became compulsory. Batches of Semtex made before 1990, however, are untagged, though it is not known whether there are still major stocks of such old batches of Semtex. According to the manufacturer, even this untagged Semtex can now be detected. The shelf life of Semtex was reduced from ten years before the 1990s to five years now. Explosia states that there is no compulsory tagging allowing reliable post-detonation detection of a certain plastic explosive (such as incorporating a unique metallic code into the mass of the explosive), so Semtex is not tagged in this way.\n\nOn 25 May 1997, Bohumil Šole, a scientist often said to have been involved with inventing Semtex, strapped the explosive to his body and committed suicide in the Priessnitz spa of Jeseník. Šole, 63, was being treated there for depression. Twenty other people were hurt in the explosion, while six were seriously injured. According to the manufacturer, Explosia, he was not a member of the team that developed the explosive.\n\n"}
{"id": "5202512", "url": "https://en.wikipedia.org/wiki?curid=5202512", "title": "Stobie pole", "text": "Stobie pole\n\nA Stobie pole is a power line pole made of two steel joists held apart by a slab of concrete. It was invented by Adelaide Electric Supply Company engineer James Cyril Stobie (1895–1953). Stobie used materials easily at hand due to the shortage of suitably long, strong, straight and termite-resistant timber in South Australia.\n\nIn July 1924 the patent application for the pole design was submitted in both English and French, and accepted in November 1925. Stobie described his invention as\n\"an improved pole adopted to be used for very many purposes, but particularly for carrying electric cables, telegraph wires... [it] consists of two flanged beams of iron or steel, preferably rolled steel joist of 'H' or of channel sections, placed one beside the other with their flanges inward and preferably at a very slight angle one with the other and held together by means of tie bolts, the space between them being filled with cement concrete.\" \n\nA second patent was granted to Stobie and Frederick William Herbert Weadon in 1946. With John Ragless Brookman they formed The Stobie Pole Syndicate for the purpose of patenting the design and then selling the patent or manufacturing rights. The Hume Pipe Company became their first agents and, while there were numerous international enquiries, South Australia has largely remained the only place where they are widely used.\n\nStobie poles are reasonably common in Broken Hill, as well as the Darwin CBD and a few thousand are installed across Tasmania. A few also exist in isolated settlements in the Goldfields-Esperance region of Western Australia such as Eucla and Rawlinna.\n\nThe first poles were erected in South Terrace, Adelaide in 1924, and were then used extensively in building the electricity transmission and distribution infrastructure throughout the state. The Stobie pole was central to the speedy expansion of Adelaide Electricity Supply Company's supply. It was cheap and simple to produce, had a uniform appearance, saved an enormous amount of timber from being cut down, had a long life expectancy and, at the time, was seen as more environmentally sensitive. SA Power Networks review alternative pole designs available on the market and has yet to find one with the benefits offered by the Stobie pole.\n\nThe poles carry supply voltages from 240 to 275,000 volts and come in various sizes from 9 to 26 metres in length, though studies indicate heights to 36 metres are feasible. The expected service life of a Stobie pole is predicted to be in excess of 80 years. It is now commonly regarded as a South Australian icon. SA Power Networks manufactures Stobie poles at a plant in Angle Park, South Australia.\n\nIts modern construction is a composite of two steel beams connected intermittently by bolts to manage compressive buckling, with the gap between the beams filled with concrete. The bolts transfer the shear, with an equal number of bolts above and below ground. The poles are tapered from ground level to the top and the toe. This construction uses the tensile properties of the steel, giving the poles excellent properties in bending. Stobie pole strength in the strong direction may be up to 4.5 times the weak direction strength. Small holes through the concrete enable easy attachment of modular cross-arms, insulators and other hardware. The poles are fireproof, rotproof, and termiteproof. Stobie poles are widely regarded in Australia to be dangerous to vehicles, with collisions sometimes \"almost cutting the vehicle in half.\" \n\nStobie pole designs are carefully calculated to ensure the installation uses a suitably sized pole. Factors such as physical mass (static load) of transformers, cross beams, voltage regulators, protection devices, conductors (including tension), etc. are carefully considered, however the wind loading (dynamic load) of this equipment must also be calculated. In some cases the wind loading factors far exceed the static load values.\n\nAttempts have been made to beautify their appearance through Stobie pole gardens and Stobie pole art projects. Renowned artist Clifton Pugh painted Adam and Eve in the Garden of Eden on a Stobie pole in 1984, but was subsequently asked to \"cover up\" the genitals on his painting.\n\nOver the years, a number of Adelaide primary and high schools have also painted murals on Stobie poles located outside the schools.\n\nThe Oppenheimer pole was a galvanized steel pole made in three telescopic sections for easy transport during the construction of the Australian Overland Telegraph Line in 1872.\n"}
{"id": "1754403", "url": "https://en.wikipedia.org/wiki?curid=1754403", "title": "Strip farming", "text": "Strip farming\n\nStrip cropping is a method of farming which involves cultivating a field partitioned into long, narrow strips which are alternated in a crop rotation system. It is used when a slope is too steep or when there is no alternative method of preventing soil erosion. The most common crop choices for strip cropping are closely sown crops such as hay, wheat, or other forages which are alternated with strips of row crops, such as corn, soybeans, cotton, or sugar beets. The forages serve primarily as cover crops. In certain systems, strips in particularly eroded areas are used to grow permanent protective vegetation; in most systems, however, all strips are alternated on an annual basis.\n\nWidths of strips are determined by a number of factors, with the two most important being the average wind velocity in a specific site and the features of the slope, particularly the gradient. Each strip typically ranges from 25 feet (7.6 m) to 75 feet (23 m) in width, but certain conditions may necessitate widths outside of this range. A minimum width of 50 feet (15 m) is ideal for the use of most farm equipment.\n\nThe growing of a cultivated crop (as corn) in strips alternating with strips of a sod-forming crop (as hay) arranged to follow an approximate contour of the land and minimize erosion.\n\nStrip cropping helps to stop soil erosion by creating natural dams for water, helping to preserve the strength of the soil. Certain layers of plants will absorb minerals and water from the soil more effectively than others. When water reaches the weaker soil that lacks the minerals needed to make it stronger, it normally washes it away. When strips of soil are strong enough to slow down water from moving through them, the weaker soil can't wash away like it normally would. Because of this, farmland stays fertile much longer.\n\nThe term strip cropping also refers to a method of dry farming sometimes used in areas including parts of the Great Plains of the United States and the Prairies of Canada. To accumulate moisture in these dry areas, cropland is periodically left fallow. Typically, the fallow and planted areas are organized in parallel long, narrow strips that are oriented normal to the prevailing winds, in order to minimize the erosion of soil from the bare fields. \nStrip farming helps to prevent mass erosion by having the roots of crops hold on to the soil to prevent it from being washed away.\n\nIntercropping is the practice of growing two or more crops in the same field. In strip intercropping, the field is still divided into strips, but the strips are narrower and contiguous. This helps facilitate modern farm machinery as well as allowing adjoining plants to benefit from synergistic growth effects.\n\nContour stripcropping involves employing a crop rotation system down a slope in order to minimize runoff and rain velocity. It is used mainly on gentle slope gradients. The width of protective strips is often higher than that of the row crop strips so that they may effectively intercept runoff.\n"}
{"id": "49759287", "url": "https://en.wikipedia.org/wiki?curid=49759287", "title": "Suki Kinari Hydropower Project", "text": "Suki Kinari Hydropower Project\n\nSK Hydro also known as Suki Kinari HPP, is an under construction, run-of-the-river hydropower project located on the Kunhar river in the Kaghan valley of Mansehra District Khyber Pakhtunkhwa, which has an installed generation capacity of 870 MW. The project is one of Pakistan's largest private-sector power development project, and is being constructed as part of the China–Pakistan Economic Corridor's \"Early Harvest\" projects, although the government of Khyber Pakhtunkhwa disputes this, arguing that financing for the project predates the announcement of CPEC.\n\nThe project was first envisaged in 1960, and feasibility studies have been carried out by German GTZ, Quebec based Montreal Engineering and recent detailed design and engineering study was performed by Mott Macdonald of UK.\n\nThe Private Power and Infrastructure Board of Pakistan identified a number of sites in the country that were deemed attractive for their hydropower potential. In March, 2005, PPIB publicly advertised seven hydro power sites for implementation in the private sector pursuant to the Policy for Power Generation Projects 2002.\n\nSK Hydro Consortium, having the requisite technical and financial strength, submitted its bid for the Suki Kinari Hydropower project. The consortium was prequalified, and a Letter of Interest (LOI) for conducting feasibility study of the project was issued to SK Hydro on 15 November 2005. The government of the province of Khyber Pakhtunkhwa, Pakistan, announced on August 24, 2016 that it has signed an agreement with SK Hydro Private Ltd. and Industrial and Commercial Bank of China to develop and construct the dam.\n\nThe dam will be constructed as a 54.5 meter high and 336 meter wide concrete gravity dam with 2 gated spillways. Four 218 MW turbines are to be installed as part of the project, and will generate approximately 870 MW of electricity in total.\n\nConstruction of the dam will result in the formation of a 3.1 kilometer long reservoir with a capacity of 9 million cubic meters of water. It will not cause large scale displacement of populations as no villages or towns will be inundated by the resulting dam's reservoir, although a four kilometer section of the Kaghan-Naran highway will have to be diverted as a result of construction works and the resulting reservoir.\n\nAccompanying transmission lines will be constructed by Pakistan's National Transmission and Dispatch Company, and is not considered complementary to the project, but is to be constructed separately from the dam itself.\n\nExpected completion date for the dam is 2023.\n\nThe project is being built on a \"Build, Own, Operate and Transfer\" basis in accordance with Government of Pakistan's Policy for Power Generation Projects 2002. The dam is being developed by Pakistan's SK Hydro group and China's Gezhouba Group. In April 2015, an agreement for 75% of financing costs was signed by the developers and the Exim Bank of China and Industrial and Commercial Bank of China. The project achieved financial close on January 9, 2017.\n\nThe projected cost for the project was initially projected to be $1.314 billion, but as a result of devaluation of the Pakistani Rupee, the cost is now estimated to be $1.8 billion.\n\nThe Government of Pakistan has agreed to purchase electricity from SK Hydro at a cost of 8.8415 US cents per kilowatt hour for the 30 years.\n"}
{"id": "65937", "url": "https://en.wikipedia.org/wiki?curid=65937", "title": "Tael", "text": "Tael\n\nTael (; ) or tahil can refer to any one of several weight measures of the Far East. Most commonly, it refers to the Chinese tael, a part of the Chinese system of weights and currency.\n\nIn Taiwan, Hong Kong, and Southeast Asia it is equivalent to 10 mace () or catty, albeit with slightly different metric equivalents in these two places. These Chinese units of measurement are usually used in Chinese herbal medicine stores as well as gold and silver exchange.\n\nThe English word \"tael\" comes through Portuguese from the Malay word , meaning \"weight\". Early English forms of the name such as \"tay\" or \"taes\" derive from the Portuguese plural of tael, .\n\nTahil ( in Singaporean English) is used in Malay \"and\" English today when referring to the weight in Malaysia, Singapore, and Brunei where it is still used in some contexts especially related to the significant Overseas Chinese population.\n\nIn Chinese, tael is written (simplified Chinese: ) and has the Mandarin Chinese pronunciation in . In Chinese and Vietnamese, the phrase \"half a catty, eight taels\" (; Vietnamese:), meaning two different presentations of the same thing (similar to the English phrase \"Six of one and half-a-dozen of the other\"), is still often used today.\n\nIn China, there were many different weighting standards of tael depending on the region or type of trade. In general the silver tael weighed around . The most common government measure was the \"Kuping\" () tael, weighing . A common commercial weight, the \"Caoping\" () tael weighed of marginally less pure silver.\n\nAs in China, Japan used the as both a unit of weight and, by extension, a currency.\n\nTraditional Chinese silver sycees and other currencies of fine metals were not denominated or made by a central mint and their value was determined by their weight in taels. They were made by individual silversmiths for local exchange, and as such the shape and amount of extra detail on each ingot were highly variable; square and oval shapes were common but \"boat\", flower, tortoise and others are known. The local tael also took precedence over any central measure, so the Canton tael weighed 37.5 grams, the Convention or Shanghai tael was 33.9 g (1.09 ozt), and the \"Haiguan\" () tael . The conversion rates between various common taels were well known. The tael was still used in Qing dynasty coinage as the basis of the silver currency and sycee remained in use until the end of the dynasty in 1911. Common weights were 50, 10, 5 and one tael.\n\nModern studies suggest that, on purchasing power parity basis, one tael of silver was worth about 4130 RMB (modern Chinese yuan) in the early Tang Dynasty, 2065 RMB in the late Tang Dynasty, and 660.8 RMB in the mid Ming Dynasty. Today the price of silver is about 元154RMB/tael.\n\nThe Thai equivalent of the tael is known as the \"tamlueng\", a term derived from Khmer. It was used as a unit of currency equal to four baht, and as a unit of weight is now standardised at 60 grams.\n\nThe tael is still in use as a weight measurement in a number of countries though usually only in limited contexts.\n\nChina's standardised \"market tael\" () of 31.25 g was modified by the People's Republic of China in 1959. The new market tael was 50 g or catty (500 g) to make it compatible with metric measures. (see Chinese unit for details.) In Shanghai, silver is still traded in taels.\n\nSome foodstuffs in China are sold in units also called \"taels\", but which do not necessarily weigh one tael. For cooked rice, the weight of the tael is approximated using special tael-sized ladles. Other items sold in taels include the shengjian mantou and the xiaolongbao, both small buns commonly found in Shanghai. In these cases, one tael is traditionally four and eight buns respectively.\n\nThe tael is a legal weight measure in Hong Kong, and is still in active use. In Hong Kong, one tael is 37.799364167 g, and in ordinance 22 of 1884 is oz. avoir. Similar to Hong Kong, in Singapore, one tael is defined as ounce and is approximated as 37.7994 g\n\nThe Taiwan tael is 37.5 g and is still used in some contexts. The Taiwan tael is derived from the tael or of the Japanese system (equal to 10 \"momme\") which was 37.5 g. Although the catty (equal to 16 taels) is still frequently used in Taiwan, the tael is only used for precious metals and medicines.\n\nIn French Indochina, the colonial administration standardised the tael \"()\" as 100 g, which is commonly used at food markets where many items typically weigh in the 100–900 g range. However, a different tael (called , , or ) unit of 37.5 g is used for domestic transactions in gold. Real estate prices are often quoted in taels of gold rather than the local currency over concerns over monetary inflation.\n\n\n"}
{"id": "57659452", "url": "https://en.wikipedia.org/wiki?curid=57659452", "title": "The Big Gusher", "text": "The Big Gusher\n\nThe Big Gusher is a 1951 American adventure film directed by Lew Landers and starring Wayne Morris, Preston Foster and Dorothy Patrick. A pair oil prospectors on a drunken spree but an apparently worthless piece of land from a conman, then attempt to find if there may really be oil there.\n\n\n"}
{"id": "37806307", "url": "https://en.wikipedia.org/wiki?curid=37806307", "title": "Timber Framers Guild", "text": "Timber Framers Guild\n\nThe Timber Framers Guild (the Guild) is a non-profit, international, membership organization established in 1984 in the United States to improve the quality and education of people practicing the centuries-old art of Timber framing buildings with timbers joined with primarily wooden joints. Today the stated goals of the Guild are to provide \"... national and regional conferences, sponsoring projects and workshops, and publishing a monthly newsletter, Scantlings, and a quarterly journal, Timber Framing \" The Guild is not like medieval guilds in that the emphasis is on education rather than control of this traditional trade. Similar organizations are the Carpenters Fellowship in the U. K., Compagnons du Tour de France in France, and in Germany (a German language site). The Guild is not directly associated with the United Brotherhood of Carpenters and Joiners of America. Originally the Guild was named the Timber Framers Guild of North America but the \"North America\" was dropped in recognition of the Guild's international presence.\n\nMembership in the Guild does not necessarily reflect competency but an interest in learning and/or teaching. Membership is not required to practice timber framing. Most members build new timber frames, but many members restore, rehabilitate, preserve and/or study historic timber framed buildings. The philosophies vary widely with some members being innovative and designing buildings of the future, some use computer-controlled machinery to cut frames, some work only with traditional hand-powered tools. Some members use metal connectors rather than traditional wooden joinery.\n\n\nThe TTRAG group produced survey guidelines for recording historic timber framed buildings.\n\n\nThe TFEC has developed a Standard for the Design of Timber Framed Structures as a \"...supplement to provisions of the National Design Specification for\nWood Construction...\" to assist engineers in this design specialty.\n\nThe Guild holds an eastern conference, western conference and TTRAG conference annually. Regional meetings, workshops and projects occur irregularly. For a list of past projects since 1988 see here.\n\nThe Guild has created a training program for apprentices to learn the art and science of traditional timber framing from mentors called journeyworkers. \"Successful apprentices receive a nationally recognized credential registered by the United States Department of Labor under our program number NO152090893. This program uses a formal curriculum which is still under development as of 2012.\n\nThe Guild publishes a newsletter for members, a respected journal Timber Framing, and books on the specialized topics of traditional timber framing. The Guild also lists other relevant books, software and a Glossary of timber framing terms. An important record of historic timber frame joints found in the U.S.A. is \"Historic American Timber Joinery: A Graphic Guide\" which was partially funded by a grant from National Park Service and the National Center for Preservation Technology and Training and thus are available for free download. This guide is expanding as new types of joints are found and recorded.\n\nAn online, public forum is managed for anyone to search for past discussions or ask questions.\n\n\n"}
{"id": "32850452", "url": "https://en.wikipedia.org/wiki?curid=32850452", "title": "Variable shunt reactor", "text": "Variable shunt reactor\n\nVariable Shunt Reactors are used in high voltage energy transmission systems to stabilize the voltage during load variations. A traditional shunt reactor has a fixed rating and is either connected to the power line all the time or switched in and out depending on the load. Recently Variable Shunt Reactors (VSR) have been developed and introduced on the market. The rating of a VSR can be changed in steps, The maximum regulation range typically is a factor of two, e.g. from 100-200 Mvar. The regulation speed is normally in the order seconds per step and around a minute from max to min rating. VSRs are today available for voltages up to 550 kV. The largest three-phase VSRs in operation have a rating of 120-200 Mvar at 420 kV and single-phase variable shunt reactors banks rated 200-285 Mvar at 420 kV have been installed in Italy.\n\nThe variability brings several benefits compared to a traditional fixed shunt reactors. The VSR can continuously compensate reactive power as the load varies and thereby securing voltage stability. Other important benefits are:\n\nVSRs are considered as technically advanced products and are mainly supplied by larger global manufacturers such as ABB and Siemens.\n\n"}
{"id": "49054091", "url": "https://en.wikipedia.org/wiki?curid=49054091", "title": "Westerly wind burst", "text": "Westerly wind burst\n\nA westerly wind burst is a phenomenon commonly associated with El Niño events whereby the typical east-to-west trade winds across the equatorial Pacific shift to west-to-east. A westerly wind burst is defined by Harrison and Vecchi (1997) as sustained winds of over a period of 5–20 days. However, no concrete definition has been determined, with Tziperman and Yu (2007) defining them as having winds of and lasting \"at least a few days\". On average, three of these events take place each year, but are significantly more common during El Niño years. They have been linked to various mesoscale phenomena, including tropical cyclones, mid-latitude cold surges, and the Madden–Julian oscillation. Their connection with Kelvin waves also indicate a connection with the onset of El Niño events, with every major occurrence since the 1950s featuring a westerly wind burst upon their onset.\n\nRecent studies, including Yu et al. (2003), have indicated some correlation between westerly wind bursts and the El Niño–Southern Oscillation (ENSO). These events occur more frequently when the equatorial Pacific warm pool is extended by ENSO events. A significant relationship exists between the frequency of westerly wind bursts and the central equatorial Pacific sea surface temperatures, with events commonly taking place when temperatures were present. The wind bursts also traveled along with the warm pool, propagating west to east.\n\nA westerly wind burst event can often result in the formation of twin tropical cyclones in the Pacific, with events occurring once per year on average. These events spur counter-clockwise rotation in the Northern Hemisphere and clockwise rotation in the Southern Hemisphere—a key component of low pressure systems. For example, during July 2015 Typhoon Chan-hom and Tropical Cyclone Raquel developed simultaneously over the Northwestern and Southwestern Pacific, respectively, in conjunction with a westerly wind burst. This was also the only known instance of twin cyclones during July and attributed to the record strength of the 2014–16 El Niño event. Another unusually strong wind burst led to the atypical formations of Tropical Depression Nine-C and Tropical Storm Pali in late December 2015 and early January 2016, respectively. Similarly, the formation of twin cyclones along the equatorial Pacific can spur the formation of a westerly wind burst and enhance El Niño events. In May 2002, a strong westerly wind burst moved from west to east across the Indian Ocean, producing two separate sets of twin cyclones. It first led to the development of Cyclone Kesiny in the south-west Indian Ocean and a storm that struck Oman, and later spawned a deep depression that struck Myanmar and Tropical Storm Errol to the southwest of Indonesia.\n"}
