{"id": "50628066", "url": "https://en.wikipedia.org/wiki?curid=50628066", "title": "Aditya (boat)", "text": "Aditya (boat)\n\nAditya, India's first solar ferry, is a solar-powered ferry operating between Vaikkom and Thavanakkadavu in the Indian state of Kerala. The boat was inaugurated by Kerala Chief Minister Sri. Pinarayi Vijayan and Central Cabinet Minister for Power, Renewable Energy, Sri. Piyush Goyal on 12 January 2017. It is India's first solar-powered ferry and the largest solar-powered boat in India. The vessel was designed and built by NavAlt Solar and Electric Boats in Kochi, India. NavAlt is a joint venture firm between Navgathi Marine Design and Constructions, Alternative Energies (France) and EVE Systems (France).\n\nThe boat is operating since launch on 12 January 2017 between Vaikkom and Thavanakkadavu.\n\nThe first150 days operation data shows that even rainy days during monsoon did not affect the schedule of the boat.\n\nThe first 60 days operation data of ADITYA yielded the following results\n\nThe boat was launched on 9 November 2016. After that multiple sets of tests and trials were conducted to verify the operational characteristics and safety standards of the boat.\n\nThe 20-metre-long and 7-metre-wide boat is covered by of solar panels rated at 20 kW, which in turn connect to two electric motors of 20 kW, one in each hull. There are 700 kg of lithium-ion batteries in the ship's two hulls with a total capacity of 50 kWh. The catamaran hull and its shape allow it to reach speeds of up to 7.5 knots. This was verified by Indian Register of Shipping surveyor, Kerala Port surveyor and technical committee. The hull was designed based on extensive experience of Navgathi and AltEn and extensive computational fluid dynamics (CFD) was done to determine its hydrodynamics. The boat is designed to be used as a passenger ferry to operate between Vaikom and Thavanakadavu.\n\nThe normal operating speed is 5.5 knots (10 km/h) to achieve a 15-minute travel time between Vaikom and Thavanakkadavu, a distance of 2.5 km on water. For achieving this speed, the power needed is about 16 kW. During manoeuvring, when leaving the jetty or approaching it, about 22 kW of power are needed. Hence, on an average about 20 kW power is needed. The total running time, neglecting the time in jetty for embarkation and disembarkation of passengers, is 5.5 hours on a sunny day (depending on client needs).\n\nAlthough the maximum power needed is a total of 22 kW during manoeuvring and 16 kW under cruise, more than double the power, a total of 40 kW, is provided in two motors of 20 kW each. The two systems on either side of the boat (in each demi-Hull) are electrically independent to ensure redundancy in case of system failure in one. Even if one system fails the power is available to safely cruise to shore with other. Also, unlike diesel engines, since efficiency does not drop with load, the electric motors can normally operate at 50% load and in emergencies at 100%.\n\nFor higher safety standards and reliability, the vessel is built under Indian Register of Shipping rules for inland vessels and operating conditions of the Vaikom – Thavanakkadavu route. The boat construction is complete and was tested by Technical committee, Indian Register of Shipping surveyor and Kerala Port surveyor on 16 November 2016, near in backwaters at Aroor. The boat is registered in Kodungallur Port under Kerala Ports.\n\nThe boat is remotely monitored and trouble shooting can also be done remotely. All the operating parameters of the boat are recorded and transmitted to the NavAlt Solar and Electric Boats server from where the technical experts can monitor the boat. The upgrades and settings in the software can also be performed remotely as if a computer is plugged on the boat. This makes the boat even more safe.\n\nThe project cost was US$370,000.\n\nThe boat satisfies the Indian Register of Shipping's safety requirement of being able to maintain cruise speed with one set of propulsion shut down.\n\nThe total energy needed to operate the ferry for 5.5 hours is 110 kWh (20 kW is average power). 1 kW solar panels produce 4 kWh of energy per day, factoring the system efficiency and standard sun of the location of 5.72 (average throughout the year). Hence the energy from solar panels is 80 kWh. The gap in energy is provided by lithium battery that can provide up to 40 kWh (80% discharge) from a total capacity of 50 kWh. The lithium batteries are fully charged in the morning because of overnight grid charging.\n\nA trip between the two boat points takes 15 minutes and it needs energy of 5 kWh. Hence a total of 22 trips can be made daily transporting 1,650 people daily, or 580,000 people every year without burning fuel.\n\nTrips on average sunny day: 7:00 AM to 7:00 PM (running hours 5.5 hours)\n\nThe below table describes the 22 trips in each column, and for each trip the start time and end time. It also list the break time at the end of each trip. In non-peak hours this is about 15 minutes, in peak time it is 10 minutes and around noon it is two hours. The energy from sun is cumulative at the end of the period and for an average sunny day it is about 72 kWh from 18 kW panels (the rest is for auxiliary systems and charges a different battery bank). The battery state of charge (SOC) is shown at the beginning of trip and end of trip. At the end of the day, the battery has about 20% charge left. The energy use can be further optimised by adding one more trip (5 kWh usage) so that end of day battery SOC can be 10%.\nOn a bright sunny day, the no. of trips can be increased by taking trips during 11:55 to 14:05 break. About four more trips can be made in this period.\n\nOn a cloudy day, the no. of trips is reduced and the break time is increased. If it is very cloudy in the break time, then shore charging can be done. This is a 32A charger and charges at 7 kW. Hence in the three hour break, it can charge battery by 21 kWh.\n\nCompared to a conventional boat powered by diesel with same functional features and safety standards which costs 231,000 US$, the solar ferry costs 370,000 US$. An efficient conventional boat consumes 120 litres per day (12 litres per hour), or 3,500 litres per month and 42,000 litres per year of diesel. This amounts to 39,000 US$ for diesel (@ 0.93 US$/litre) and total operating costs including lube oil and other maintenance costs amounts to 44,600 US$ per year.\n\nThe operating cost of solar ferry is 40 units of electricity or 6.2 US$ per day which amounts to 185 US$ per month and 2,150 US$ per year.\n\nThe pay-back period is under three years.\n\nThe Government of India under the leadership of Prime Minister, Sri. Narendra Modi is very supportive of the project and the Ministry of New and Renewable Energy has also agreed to sponsor the project considering that this is a first of its kind in India. The benefit of sponsorship would mean that Kerala State Water Transport Department would get the boat at almost free of cost. In this scenario the boat is cheaper than conventional boat and they would start saving money from day one.\n\n\n"}
{"id": "551061", "url": "https://en.wikipedia.org/wiki?curid=551061", "title": "Allotropes of carbon", "text": "Allotropes of carbon\n\nCarbon is capable of forming many allotropes due to its valency. Well-known forms of carbon include diamond and graphite. In recent decades many more allotropes are forms of carbon have been discovered and researched including ball shapes such as buckminsterfullerene and sheets such as graphene. Larger scale structures of carbon include nanotubes, nanobuds and nanoribbons. Other unusual forms of carbon exist at very high temperatures or extreme pressures. Around 500 hypothetical 3-periodic allotropes of carbon are known at the present time according to SACADA\ndatabase.\n\nDiamond is a well known allotrope of carbon. The hardness and high dispersion of light of diamond make it useful for both industrial applications and jewelry. Diamond is the hardest known natural mineral. This makes it an excellent abrasive and makes it hold polish and luster extremely well. No known naturally occurring substance can cut (or even scratch) a diamond, except another diamond.\n\nThe market for industrial-grade diamonds operates much differently from its gem-grade counterpart. Industrial diamonds are valued mostly for their hardness and heat conductivity, making many of the gemological characteristics of diamond, including clarity and color, mostly irrelevant. This helps explain why 80% of mined diamonds (equal to about 100 million carats or 20 tonnes annually) are unsuitable for use as gemstones and known as \"bort\", are destined for industrial use. In addition to mined diamonds, synthetic diamonds found industrial applications almost immediately after their invention in the 1950s; another 400 million carats (80 tonnes) of synthetic diamonds are produced annually for industrial use, which is nearly four times the mass of natural diamonds mined over the same period.\n\nThe dominant industrial use of diamond is in cutting, drilling (drill bits), grinding (diamond edged cutters), and polishing. Most uses of diamonds in these technologies do not require large diamonds; in fact, most diamonds that are not gem-quality can find an industrial use. Diamonds are embedded in drill tips or saw blades, or ground into a powder for use in grinding and polishing applications (due to its extraordinary hardness). Specialized applications include use in laboratories as containment for high pressure experiments (see diamond anvil), high-performance bearings, and limited use in specialized windows.\n\nWith the continuing advances being made in the production of synthetic diamond, future applications are beginning to become feasible. Garnering much excitement is the possible use of diamond as a semiconductor suitable to build microchips from, or the use of diamond as a heat sink in electronics. Significant research efforts in Japan, Europe, and the United States are under way to capitalize on the potential offered by diamond's unique material properties, combined with increased quality and quantity of supply starting to become available from synthetic diamond manufacturers.\n\nEach carbon atom in a diamond is covalently bonded to four other carbons in a tetrahedron. These tetrahedrons together form a 3-dimensional network of six-membered carbon rings (similar to cyclohexane), in the chair conformation, allowing for zero bond angle strain. This stable network of covalent bonds and hexagonal rings is the reason that diamond is so strong. Although graphite is the most stable allotrope of carbon under standard laboratory conditions (273 or 298 K, 1 atm), a recent computational study indicated that under idealized conditions (\"T\" = 0, \"p\" = 0), diamond is the most stable allotrope by 1.1 kJ/mol compared to graphite.\n\nGraphite, named by Abraham Gottlob Werner in 1789, from the Greek γράφειν (\"graphein\", \"to draw/write\", for its use in pencils) is one of the most common allotropes of carbon. Unlike diamond, graphite is an electrical conductor. Thus, it can be used in, for instance, electrical arc lamp electrodes. Likewise, under standard conditions, graphite is the most stable form of carbon. Therefore, it is used in thermochemistry as the standard state for defining the heat of formation of carbon compounds.\n\nGraphite conducts electricity, due to delocalization of the pi bond electrons above and below the planes of the carbon atoms. These electrons are free to move, so are able to conduct electricity. However, the electricity is only conducted along the plane of the layers. In diamond, all four outer electrons of each carbon atom are 'localised' between the atoms in covalent bonding. The movement of electrons is restricted and diamond does not conduct an electric current. In graphite, each carbon atom uses only 3 of its 4 outer energy level electrons in covalently bonding to three other carbon atoms in a plane. Each carbon atom contributes one electron to a delocalised system of electrons that is also a part of the chemical bonding. The delocalised electrons are free to move throughout the plane. For this reason, graphite conducts electricity along the planes of carbon atoms, but does not conduct in a direction at right angles to the plane.\n\nGraphite powder is used as a dry lubricant. Although it might be thought that this industrially important property is due entirely to the loose interlamellar coupling between sheets in the structure, in fact in a vacuum environment (such as in technologies for use in space), graphite was found to be a very poor lubricant. This fact led to the discovery that graphite's lubricity is due to adsorbed air and water between the layers, unlike other layered dry lubricants such as molybdenum disulfide. Recent studies suggest that an effect called superlubricity can also account for this effect.\n\nWhen a large number of crystallographic defects bind these planes together, graphite loses its lubrication properties and becomes what is known as pyrolytic carbon, a useful material in blood-contacting implants such as prosthetic heart valves.\n\nGraphite is the most stable allotrope of carbon. Contrary to popular belief, high-purity graphite does not readily burn, even at elevated temperatures. For this reason, it is used in nuclear reactors and for high-temperature crucibles for melting metals. At very high temperatures and pressures (roughly 2000 °C and 5 GPa), it can be transformed into diamond.\n\nNatural and crystalline graphites are not often used in pure form as structural materials due to their shear-planes, brittleness and inconsistent mechanical properties.\n\nIn its pure glassy (isotropic) synthetic forms, pyrolytic graphite and carbon fiber graphite are extremely strong, heat-resistant (to 3000 °C) materials, used in reentry shields for missile nosecones, solid rocket engines, high temperature reactors, brake shoes and electric motor brushes.\n\nIntumescent or expandable graphites are used in fire seals, fitted around the perimeter of a fire door. During a fire the graphite intumesces (expands and chars) to resist fire penetration and prevent the spread of fumes. A typical start expansion temperature (SET) is between 150 and 300 °C.\n\nDensity: graphite's specific gravity is 2.3, which makes it lighter than diamonds.\n\nChemical activity: it is slightly more reactive than diamond. This is because the reactants are able to penetrate between the hexagonal layers of carbon atoms in graphite. It is unaffected by ordinary solvents, dilute acids, or fused alkalis. However, chromic acid oxidises it to carbon dioxide.\n\nA single layer of graphite is called graphene and has extraordinary electrical, thermal, and physical properties. It can be produced by epitaxy on an insulating or conducting substrate or by mechanical exfoliation (repeated peeling) from graphite. Its applications may include replacing silicon in high-performance electronic devices. With two layers stacked, bilayer graphene results with different properties.\n\nGraphenylene is a single layer carbon material with biphenylene-like subunits as basis in its hexagonal lattice structure. It is also known as biphenylene-carbon.\n\nAA'-graphite is an allotrope of carbon similar to graphite, but where the layers are positioned differently to each other as compared to the order in graphite.\n\nAmorphous carbon is the name used for carbon that does not have any crystalline structure. As with all glassy materials, some short-range order can be observed, but there is no long-range pattern of atomic positions. While entirely amorphous carbon can be produced, most amorphous carbon actually contains microscopic crystals of graphite-like, or even diamond-like carbon.\n\nCoal and soot or carbon black are informally called amorphous carbon. However, they are products of pyrolysis (the process of decomposing a substance by the action of heat), which does not produce true amorphous carbon under normal conditions.\n\nThe \"buckminsterfullerenes\", or usually just \"fullerenes\" or \"buckyballs\" for short, were discovered in 1985 by a team of scientists from Rice University and the University of Sussex, three of whom were awarded the 1996 Nobel Prize in Chemistry. They are named for the resemblance to the geodesic structures devised by Richard Buckminster \"Bucky\" Fuller. Fullerenes are positively curved molecules of varying sizes composed entirely of carbon, which take the form of a hollow sphere, ellipsoid, or tube.\n\nAs of the early twenty-first century, the chemical and physical properties of fullerenes are still under heavy study, in both pure and applied research labs. In April 2003, fullerenes were under study for potential medicinal use — binding specific antibiotics to the structure to target resistant bacteria and even target certain cancer cells such as melanoma.\n\nCarbon nanotubes, also called buckytubes, are cylindrical carbon molecules with novel properties that make them potentially useful in a wide variety of applications (e.g., nano-electronics, optics, materials applications, etc.). They exhibit extraordinary strength, unique electrical properties, and are efficient conductors of heat. Inorganic nanotubes have also been synthesized.\nA nanotube is a member of the fullerene structural family, which also includes buckyballs. Whereas buckyballs are spherical in shape, a nanotube is cylindrical, with at least one end typically capped with a hemisphere of the buckyball structure. Their name is derived from their size, since the diameter of a nanotube is on the order of a few nanometers (approximately 50,000 times smaller than the width of a human hair), while they can be up to several centimeters in length. There are two main types of nanotubes: single-walled nanotubes (SWNTs) and multi-walled nanotubes (MWNTs).\n\nCarbon nanobuds are a newly discovered allotrope of carbon in which fullerene like \"buds\" are covalently attached to the outer sidewalls of the carbon nanotubes. This hybrid material has useful properties of both fullerenes and carbon nanotubes. For instance, they have been found to be exceptionally good field emitters.\n\nSchwarzites are negatively curved carbon molecules. (A negatively curved object bends inwards like a saddle rather than bending outwards like a sphere.)\n\nThe team that first created schwarzites did not recognize them as such. Instead they were called zeolite-templated carbons (ZTCs). The name derives from their origin inside the pores of zeolites, crystalline silicon dioxide minerals. Another team recognized them as schwarzites and refined the original synthesis technique. A vapor of carbon-containing molecules is injected into the zeolite, where the carbon gathers on the pores' inner walls. It forms a 2D sheet that pulls inwards, creating the negative curve. Dissolving the zeolite leaves the carbon.\n\nGlassy carbon or vitreous carbon is a class of non-graphitizing carbon widely used as an electrode material in electrochemistry, as well as for high-temperature crucibles and as a component of some prosthetic devices.\n\nIt was first produced by Bernard Redfern in the mid-1950s at the laboratories of The Carborundum Company, Manchester, UK. He had set out to develop a polymer matrix to mirror a diamond structure and discovered a resole (phenolic) resin that would, with special preparation, set without a catalyst. Using this resin the first glassy carbon was produced.\n\nThe preparation of glassy carbon involves subjecting the organic precursors to a series of heat treatments at temperatures up to 3000 °C. Unlike many non-graphitizing carbons, they are impermeable to gases and are chemically extremely inert, especially those prepared at very high temperatures. It has been demonstrated that the rates of oxidation of certain glassy carbons in oxygen, carbon dioxide or water vapour are lower than those of any other carbon. They are also highly resistant to attack by acids. Thus, while normal graphite is reduced to a powder by a mixture of concentrated sulfuric and nitric acids at room temperature, glassy carbon is unaffected by such treatment, even after several months.\n\nUnder certain conditions, carbon can be found in its atomic form. It is formed by passing large electric currents through carbon under very low pressures. It is extremely unstable, but it is an intermittent product used in the creation of carbenes.\n\nDiatomic carbon can also be found under certain conditions. It is often detected via spectroscopy in extraterrestrial bodies, including comets and certain stars.\n\nCarbon nanofoam is the fifth known allotrope of carbon, discovered in 1997 by Andrei V. Rode and co-workers at the Australian National University in Canberra. It consists of a low-density cluster-assembly of carbon atoms strung together in a loose three-dimensional web.\n\nEach cluster is about 6 nanometers wide and consists of about 4000 carbon atoms linked in graphite-like sheets that are given negative curvature by the inclusion of heptagons among the regular hexagonal pattern. This is the opposite of what happens in the case of buckminsterfullerenes, in which carbon sheets are given positive curvature by the inclusion of pentagons.\n\nThe large-scale structure of carbon nanofoam is similar to that of an aerogel, but with 1% of the density of previously produced carbon aerogels – only a few times the density of air at sea level. Unlike carbon aerogels, carbon nanofoam is a poor electrical conductor.\n\nCarbide-derived carbon (CDC) is a family of carbon materials with different surface geometries and carbon ordering that are produced via selective removal of metals from metal carbide precursors, such as TiC, SiC, TiAlC, MoC, etc. This synthesis is accomplished using chlorine treatment, hydrothermal synthesis, or high-temperature selective metal desorption under vacuum. Depending on the synthesis method, carbide precursor, and reaction parameters, multiple carbon allotropes can be achieved, including endohedral particles composed of predominantly amorphous carbon, carbon nanotubes, epitaxial graphene, nanocrystalline diamond, onion-like carbon, and graphitic ribbons, barrels, and horns. These structures exhibit high porosity and specific surface areas, with highly tunable pore diameters, making them promising materials for supercapacitor-based energy storage, water filtration and capacitive desalinization, catalyst support, and cytokine removal.\n\nLonsdaleite is a hexagonal allotrope of the carbon allotrope diamond, believed to form from graphite present in meteorites upon their impact to Earth. The great heat and stress of the impact transforms the graphite into diamond, but retains graphite's hexagonal crystal lattice. Hexagonal diamond has also been synthesized in the laboratory, by compressing and heating graphite either in a static press or using explosives. It can also be produced by the thermal decomposition of a polymer, poly(hydridocarbyne), at atmospheric pressure, under inert gas atmosphere (e.g. argon, nitrogen), starting at temperature .\n\nA one-dimensional carbon polymer with the structure -(C:::C)-.\n\n\n\n\nThe system of carbon allotropes spans an astounding range of extremes, considering that they are all merely structural formations of the same element.\n\nBetween diamond and graphite:\n\nDespite the hardness of diamonds, the chemical bonds that hold the carbon atoms in diamonds together are actually weaker than those that hold together graphite. The difference is that in diamond, the bonds form an inflexible three-dimensional lattice. In graphite, the atoms are tightly bonded into sheets, but the sheets can slide easily over each other, making graphite soft.\n\n\n"}
{"id": "35145642", "url": "https://en.wikipedia.org/wiki?curid=35145642", "title": "Andy Manson (luthier)", "text": "Andy Manson (luthier)\n\nAndy Manson is a custom guitar maker (luthier). For almost five decades Manson has been hand crafting guitars, mandolins and multi-necked instruments. Over the years Manson has achieved a reputation as one of England's finest luthiers and one of the world's finest makers of flat-top acoustic guitars, and his influence can be seen in many other makers' work including Hugh's and Brook Guitars and other small makers such as Adrian Lucas, Elysian Acoustics and Gary Nava.\n\nManson studied at the London College of Furniture, where he completed a new course for stringed instrument makers. Such a course did not exist in England at the time and Manson was encouraged by the college to create his own course on becoming a luthier. He built his first instrument in 1967. Manson started a workshop in 1969 in Sussex, UK.\n\nIn the early 1980s, Manson was joined by his brother Hugh Manson, who focused on building electric guitars and basses. The two of them moved workshop to Devon, England in 1985.\n\nAndy Petherick and Simon Smidmore, former associates of Andy Manson's, went on to found Brook Guitars, where they produce some of his regular designs under licence.\n\nIn 1974, Manson created a now iconic instrument for John Paul Jones of Led Zeppelin. The instrument featured three necks: six and 12 string guitar and mandolin. The instrument was used extensively during Led Zeppelin's acoustics sets throughout the mid to late 70's. The story of the creation of this guitar can be found in Manson's book \"Talking Wood\". Jones has continued using Manson through the years.\n\nIn 1994, Manson was commissioned to make a triple-neck guitar for Jimmy Page. It was used during the performances.\n\n"}
{"id": "13776683", "url": "https://en.wikipedia.org/wiki?curid=13776683", "title": "CALPHAD", "text": "CALPHAD\n\nCALPHAD stands for \"CALculation of PHAse Diagrams\", a methodology which has been introduced in the previous century by Larry Kaufman. An equilibrium phase diagram is usually a diagram with axes for temperature and composition of a chemical system. It shows the regions where substances or solutions (i.e. phases) are stable and regions where two or more of them coexist. Phase diagrams are a very powerful tool for predicting the state of a system under different conditions and were initially a graphical method to rationalize experimental information on states of equilibrium. In complex systems, computational methods such as CALPHAD are employed to model thermodynamic properties for each phase and simulate multicomponent phase behavior. The CALPHAD approach is based on the fact that a phase diagram is a manifestation of the equilibrium thermodynamic properties of the system, which are the sum of the properties of the individual phases. It is thus possible to calculate a phase diagram by first assessing the thermodynamic properties of all the phases in a system.\n\nWith the CALPHAD method one collects all experimental information on phase equilibria in a system and all thermodynamic information obtained from thermochemical and thermophysical studies. The thermodynamic properties of each phase are then described with a mathematical model containing adjustable parameters. The parameters are evaluated by optimizing the fit of the model to all the information, also involving coexisting phases. It is then possible to recalculate the phase diagram as well as the thermodynamic properties of all the phases. The philosophy of the CALPHAD method is to obtain a consistent description of the phase diagram and the thermodynamic properties so to reliably predict the set of stable phases and their thermodynamic properties in regions without experimental information and for metastable states during simulations of phase transformations. \n\nThere are two crucial factors for the success of the CALPHAD method. The first factor is to find realistic as well as convenient mathematical models for the Gibbs energy for each phase. The Gibbs energy is used because most experimental data have been determined at known temperature and pressure and any other thermodynamic quantities can be calculated from it. It is not possible to obtain an exact description of the behavior of the Gibbs energy of a multi-component system with analytical expressions. It is thus necessary to identify the main features and base the mathematical models on them. The discrepancy between model and reality is finally represented by a power series expansion in temperature, pressure and constitution of the phase. The adjustable parameters of these model descriptions are refined to reproduce the experimental data. The strength of the CALPHAD method is that the descriptions of the constituent sub-systems can be combined to describe a multi-component system. \n\nThe second crucial factor is the availability of computer software for calculating equilibria and various kinds of diagrams and databases with the stored assessed information. As there are at present many different kinds of models used for different kinds of phases there are several thermodynamic databases available, either free or commercially, for different materials like steels, super-alloys, semiconductor materials, aqueous solutions, slags, etc. There are also several different kinds of software available using different kinds of algorithms for computing the equilibrium. It is an advantage if the software allows the equilibrium to be calculated using many different types of conditions for the system, not only the temperature, pressure and overall composition because in many cases the equilibrium may be determined at constant volume or at a given chemical potential of an element or a given composition of a particular phase.\n\nCALPHAD had a slow start in the 60s but sophisticated thermodynamic data bank systems started to appear in the 80s and today there are several commercial products on the market, e.g. FactSage, MTDATA, PANDAT, MatCalc, JMatPro, and Thermo-Calc as well as the free implementation OpenCalphad . They are used in research and industrial development (e.g., QuesTek Innovations' PrecipiCalc software and \"Materials by Design\" Technology), where they save large amounts of time and resources by reducing the experimental work and by making thermodynamic predictions available for multi-component systems that would be practically unattainable without this approach. There is a journal with this name where recent scientific achievements are published but scientific papers describing the use of the CALPHAD methods are published also in many other journals.\n\n\n"}
{"id": "2737450", "url": "https://en.wikipedia.org/wiki?curid=2737450", "title": "COVRA", "text": "COVRA\n\nCOVRA (Centrale Organisatie Voor Radioactief Afval) is the Dutch nuclear waste processing and storage company in Vlissingen, which stores the waste produced in the Borssele nuclear power plant after it is reprocessed by Areva NC in La Hague, Manche, Normandy, France. Until the Dutch government decides what to do with the waste, it will stay at COVRA. COVRA currently has a license to operate for one hundred years.\n\nThe director is Jan Boelen.\n"}
{"id": "1145987", "url": "https://en.wikipedia.org/wiki?curid=1145987", "title": "Cascade converter", "text": "Cascade converter\n\nA cascade converter is a type of motor-generator which was patented in 1902 by J. L. la Cour and O. S. Bragstad.\n\nIt consists of an induction motor driving a dynamo through a shaft. In addition, the rotor of the induction motor is electrically connected to the armature of the dynamo.\n\nWhen the machine is running, half the power is transmitted mechanically through the shaft while the other half is transmitted electrically. \n\nThe advantage of this arrangement is that the machine can be smaller than a conventional motor-generator of the same power.\n\nThe British manufacturing rights for the cascade converter were held by Bruce Peebles & Co. Ltd. of Edinburgh.\n\n\n"}
{"id": "18005315", "url": "https://en.wikipedia.org/wiki?curid=18005315", "title": "Central African Regional Program for the Environment", "text": "Central African Regional Program for the Environment\n\nCARPE the Central African Regional Program for the Environment is a United States Agency for International Development (USAID) initiative aimed at promoting sustainable natural resource management in the Congo Basin. It aims at protecting the forest in countries such as Gabon, Cameroon and the Republic of the Congo providing critical habitat for biodiversity conservation. CARPE works to reduce the rate of forest degradation and loss of biodiversity by supporting other groups and working together towards an increased local, national, and regional framework for natural resource management.\nSince 1997, CARPE has worked in protected areas such as the Minkébé National Park in north-east Gabon and has worked together with agencies such as the WWF and provided funding along with the European Union, UNESCO, the Netherlands Development Cooperation and the French Global Environment Facility (FFEM).\n"}
{"id": "27858906", "url": "https://en.wikipedia.org/wiki?curid=27858906", "title": "Coaling tower", "text": "Coaling tower\n\nA coaling tower, coal stage or coaling station is a facility used to load coal as fuel into railway steam locomotives. Coaling towers were often sited at motive power depots or locomotive maintenance shops.\n\nCoaling towers were constructed of wood, steel-reinforced concrete, or steel. In almost all cases coaling stations used a gravity fed method, with one or more large storage bunkers for the coal elevated on columns above the railway tracks, from which the coal could be released to slide down a chute into the waiting locomotive's coal storage area. The method of lifting the bulk coal into the storage bin varied. The coal usually was dropped from a hopper car into a pit below tracks adjacent to the tower. From the pit a conveyor-type system used a chain of motor-driven buckets to raise the coal to the top of the tower where it would be dumped into the storage bin; a skip-hoist system lifted a single large bin for the same purpose. Some facilities lifted entire railway coal trucks or wagons. Sanding pipes were often mounted on coaling towers to allow simultaneous replenishment of a locomotive's sand box.\n\nAs railroads transitioned from the use of steam locomotives to the use of diesel locomotives in the 1950s the need for coaling towers ended. Many reinforced concrete towers remain in place if they do not interfere with operations due to the high cost of demolition incurred with these massive structures.\n\nThe sortable tables below list existing steam locomotive coaling towers, coal stages, coal docks, coal chutes, and automatic loaders with the following information when known:\n\n"}
{"id": "16878758", "url": "https://en.wikipedia.org/wiki?curid=16878758", "title": "Copolyester", "text": "Copolyester\n\nCopolyester forms when modifications are made to polyesters, which are combinations of diacids and diols. For example, by introducing other diacids, such as isophthalic acid (IPA), or other diols, such as cyclohexane dimethanol (CHDM) to the polyester polyethylene terephthalate (PET), the material becomes a copolyester due to its comonomer content.\n\nCopolyesters retain their strength, clarity, and other mechanical properties even when exposed to a variety of chemicals that typically affect other materials, such as polycarbonates. This, plus their versatility and flexibility, allows manufacturers to use them effectively in the design of both high-volume, low-cost parts as well as critical, more expensive component parts.\n\nCopolyesters offer versatility to meet a wide variety of applications.\nCopolyester resins have proved to be effective in packaging applications, due to their toughness, versatility and chemical resistance. They are also frequently used in the manufacture and packaging of consumer goods and materials. Markets that rely on copolyesters include medical packaging, home appliances, consumer goods (pens, toys, sporting goods, etc.), and cosmetics, among others.\n\nTable of Common Copolyester and Components \nThe main global manufacturers and suppliers of Copolyester resins are as follows (The brand names are in parenthesis):\n\n"}
{"id": "16796643", "url": "https://en.wikipedia.org/wiki?curid=16796643", "title": "Domain (mathematical analysis)", "text": "Domain (mathematical analysis)\n\nIn mathematical analysis, a domain is any connected open subset of a finite-dimensional vector space. This is a different concept than the domain of a function, though it is often used for that purpose, for example in partial differential equations and Sobolev spaces.\n\nVarious degrees of smoothness of the boundary of the domain are required for various properties of functions defined on the domain to hold, such as integral theorems (Green's theorem, Stokes theorem), properties of Sobolev spaces, and to define measures on the boundary and spaces of traces (generalized functions defined on the boundary). Commonly considered types of domains are domains with continuous boundary, Lipschitz boundary, \"C\" boundary, and so forth.\n\nA Bounded domain is a domain which is a bounded set, while an Exterior or external domain is the interior of the complement of a bounded domain.\n\nIn complex analysis, a complex domain (or simply domain) is any connected open subset of the complex plane ℂ. For example, the entire complex plane is a domain, as is the open unit disk, the open upper half-plane, and so forth. Often, a complex domain serves as the domain of definition for a holomorphic function.\n\nIn the study of several complex variables, the definition of a domain is extended to include any connected open subset of ℂ\"\".\n\nAccording to Hans Hahn, the concept of a domain as an open connected set was introduced by Constantin Carathéodory in his famous book . Hahn also remarks that the word \"\"Gebiet\" (\"Domain\"\") was occasionally previously used as a synonym of open set.\n\nHowever, the term \"domain\" was occasionally used to identify closely related but slightly different concepts. For example, in his influential monographs on elliptic partial differential equations, Carlo Miranda uses the term \"region\" to identify an open connected set, and reserves the term \"domain\" to identify an internally connected, perfect set, each point of which is an accumulation point of interior points, following his former master Mauro Picone: according to this convention, if a set is a region then its closure is a domain.\n\n\n"}
{"id": "13750931", "url": "https://en.wikipedia.org/wiki?curid=13750931", "title": "Energy Autonomy", "text": "Energy Autonomy\n\nEnergy Autonomy: The Economic, Social & Technological Case for Renewable Energy is a 2006 book written by Hermann Scheer. It was first published on December 1, 2006 through Routledge and discusses the topic of renewable energy.\n\nIn the book Scheer discusses that for the past two hundred years industrial civilization has relied predominantly upon fossil fuels, which are abundant and cheap but also have adverse social and environmental effects. Scheer argues that it would be more beneficial if they transition to renewable energy and distributed, decentralized energy generation, as this is a model that has already been proven to be successful. Much progress with renewable energy commercialization has already been made in Europe where the renewable energy industry is a multi-billion Euro industry with high growth rates.\n\nCritical reception has been mostly positive. The \"Doctors for the Environment Australia\" gave the book a favorable review, commenting that \"\"Energy Autonomy\" is engagingly written, well referenced, with informative tables and a good index.\" \"Ecological Economics\" also reviewed the book and wrote \"Although some may find it a bit dry, heavy with policy, this book, by the director of EUROSOLAR, the European Association for Renewable Energy, gets right to the heart of the energy policy puzzle, wrestling with questions that are often skirted.\"\n\n\n\n<br>\n"}
{"id": "11276754", "url": "https://en.wikipedia.org/wiki?curid=11276754", "title": "Enrico Fermi Nuclear Power Plant (Italy)", "text": "Enrico Fermi Nuclear Power Plant (Italy)\n\nEnrico Fermi Nuclear Power Plant was a nuclear power plant at Trino (often referred to as ‘Trino Vercellese’, meaning ‘Trino in the Province of Vercelli’), in north-west Italy.\n\nConsisting of one 260 megawatt pressurized water reactor (PWR) from the vendor Westinghouse Electric Corporation, it operated from 1964 until 1990. Trino was in 1964 the third ever commercially operated PWR worldwide, and it had the second highest megawatt-capacity of them. It was closed down following the Italian nuclear power referendum, 1987.\n\nThe experimental enrichment plant, EUREX, near the power plant, was closed down in 1984.\n\n"}
{"id": "2213159", "url": "https://en.wikipedia.org/wiki?curid=2213159", "title": "European Ecological Federation", "text": "European Ecological Federation\n\nThe European Ecological Foundation (EEF) is a European organisation with the objective \"to promote cooperation within the science of ecology in Europe\".\n\nIts members are:\n\n\nPresidents include:\n\n\n"}
{"id": "23650053", "url": "https://en.wikipedia.org/wiki?curid=23650053", "title": "Gold chalcogenides", "text": "Gold chalcogenides\n\nGold chalcogenides are compounds formed between gold and one of the chalcogens, elements from group 16 of the periodic table: oxygen, sulfur, selenium, or tellurium.\n\n\nNatural gold tellurides, like calaverite and krennerite (AuTe), petzite ( AgAuTe), and sylvanite (AgAuTe), are minor ores of gold (and tellurium). See telluride minerals for more information on individual naturally occurring tellurides.\n\n"}
{"id": "30013379", "url": "https://en.wikipedia.org/wiki?curid=30013379", "title": "Harrison Ngau Laing", "text": "Harrison Ngau Laing\n\nHarrison Ngau Laing is a Malaysian environmentalist and politician, a member of the Kayan tribe. He was awarded the Goldman Environmental Prize in 1990 for his work to prevent deforestation of the Sarawak region. He was a member of the Malaysian Parliament from 1990 to 1995.\n\nHarrison Ngau was born in 1959 at his home village in Long Keseh, which is located near the Baram River in the northen region of Sarawak. In 1976, a logging company named WTK (short form for the company's founder, Wong Tuong Kwang) went to his village. Harrison was a 17 year old boy who just had just completed second last year of his secondary school at Marudi. He went back to his village for a Christmas holiday when a large meeting convened in his longhouse. The villagers only realised that WTK company had just been granted a concession behind their longhouse when the company turned up with bulldozers, heavy machinaries, and chainsaws in front of them. The villagers initially mooted the idea of stopping the loggers, however when company workers sent them some free biscuits and Coke, the villagers accepted the food and the resistance died down. It was later turned out that two villagers in the longhouse own shares in another logging company who owned the concession. They sold to concession to WTK and made a handsome profit. Since Harrison was the only one who know how write, he offered himself to write letters to the company. WTK later agreed to pay a compensation of RM 2 (US$ 0.60) for every tonne of timber taken from their area.\n\nHarrison then went on to work in a hotel in Miri, an ice factory, and with Shell oil company. In 1980, he started Sarawak branch of Sahabat Alam Malaysia (SAM), an environmental and human rights organisation in Malaysia. He went to Marudi rented a office for his organisation. In November 1980, he was married to 17 year old Uding, another Kayan from a nearby village. They raised four children and continue to campaigned against logging companies in Baram region. The first protest was at the Apoh river against the Samling logging company. The Kayans from three longhouses went to threatened the company's employees. The company then agreed to pay compensation to the three longhouses. Harrison's organisation was primarily involved in advising the indigenous people in exercising their land rights. In the mid 1980s, the Penan people started turn up to his office when they themselves were also affected by logging.\n\nThe biggest protest came in March 1987 when 4,700 indigenous people from 26 Penan villages and six longhouses turned up simultaneously to prevent loggers from reaching upper Baram and Limbang region. Around 200 bulldozers and 1,600 timber workers were held up for several months. After a few months, the blockade was forcefully dismantled by the police. On 27 October 1987, Operation Lalang was started by the then Malaysian prime minister, Mahathir Mohamad. Harrison was arrested under Internal Secruity Act. Harrison was flown to Miri and spent a night at a cell there before he was transported to Kuching through an off-road vehicle. He was held for 60 days and nights but no charge was brought against him. Harrison was released in December 1987. Harrison's arrest brought attention to environmental campaigners and human rights activists worldwide. They wrote letters to protest the Malaysian government actions. One year later, SAM received \"Right Livelihood Award\" for Harrison's work in Sarawak.\n\nHarrison received Goldman Environmental Prize in 1990. He later used the prize money to fund his campaign against Barisan Nasional (BN) during 1990 Malaysian general election. He defeated the deputy minister of Public Works, Luhat Wan and became the member of parliament for Baram constituency. However, in the 1995 Malaysian general election, he was defeated by another BN candidate Jacob Dungau Sagan.\n"}
{"id": "1784528", "url": "https://en.wikipedia.org/wiki?curid=1784528", "title": "Ice IX", "text": "Ice IX\n\nIce IX is a form of solid water stable at temperatures below 140 K and pressures between 200 and 400 MPa. It has a tetragonal crystal lattice and a density of 1.16 g/cm³, 26% higher than ordinary ice. It is formed by cooling ice III from 208 K to 165 K (rapidly—to avoid forming ice II). Its structure is identical to ice III other than being hydrogen-ordered.\n\nOrdinary water ice is known as ice I in the Bridgman nomenclature. Different types of ice, from ice II to ice XVI, have been created in the laboratory at different temperatures and pressures.\n\n\n\n"}
{"id": "49809733", "url": "https://en.wikipedia.org/wiki?curid=49809733", "title": "Institute of Wood Science", "text": "Institute of Wood Science\n\nThe Institute of Wood Science was a British organisation that researched wood.\n\nIt was established in 1955. It is a research institute for the wood industry in the UK.\n\nThe Institute of Wood Science is now known as the Wood Technology Society, part of the Institute of Materials, Minerals and Mining.\n\nIt was situated in Hughenden Valley in Hughenden, north of High Wycombe west of the A4128, home of the British furniture industry. The site is also the headquarters of the Timber Research and Development Association, or TRADA. The site is also known as Trada Technology. It is not a government organisation.\n\nTRADA is owned by Exova BM TRADA.\n\nIt researches wood products. Its journal is the International Wood Products Journal.\n\nIt is the UK's examining body for the UK timber trade. It organises training at its site and at The Horse Trust nearby.\n\n\n"}
{"id": "26096136", "url": "https://en.wikipedia.org/wiki?curid=26096136", "title": "Johari-Goldstein relaxation", "text": "Johari-Goldstein relaxation\n\nJohari-Goldstein relaxation, also known as the JG β-relaxation, is a universal property of glasses and certain other disordered materials. \nInitially posited in 1969 by Martin Goldstein, its existence was proved experimentally by Gyan P. Johari and Martin Goldstein in 1970 by experiments on glasses made from rigid molecules.\nThe relaxation, a peak in mechanical or dielectric loss at a particular frequency, had previously been attributed to a type of molecular flexibility. The fact that such a loss peak shows up in glasses of rigid molecules lacking this flexibility demonstrated its universal character.\nThe JG relaxation is regarded as the precursor of the α-relaxation, i.e., its occurrence facilitates viscous flow, and it must occur before the latter can occur. Accordingly, the narrow ε″ peak observed at GHz frequencies in the spectra of polar liquids at high temperatures is associated with processes similar to the JG relaxation that is observed at lower temperatures. As the liquid is cooled, the ε″ peak at GHz frequency broadens and shifts to lower frequencies. A new peak\nin ε″ emerges from the low frequency side of this peak once some value of higher density and viscosity are reached. The relaxation time at which it emerges is typically 0.1 to 1 μs. As the liquid is further\ncooled, this peak broadens and grows in strength at the expense of the original peak and rapidly moves to very low frequencies at T < Tg from above. This is the α-relaxation peak. Its relaxation rate changes more rapidly on cooling than the rate of JG relaxation and the motions that produce it become kinetically frozen at Tg while the motions due to the JG relaxation persist. In the glassy state, its mechanism is seen to be thermally activated hindered reorientation, the same as that in a low viscosity liquid at high temperatures. The discovery was made by Johari and Goldstein in the period 1970-1976 and these observations have now been confirmed by a number of authors on many types of systems. The relative amplitudes of the JG process and the α processes in terms of dielectric strength have also been given in some cases.\nIt is known that viscosity and density of a liquid also increase as a liquid polymerizes at a fixed T and macromolecular structure grows in the liquid as covalent bonds replace weaker Van der Waals interactions. More recently, it has been shown by dielectric measurements that during polymerization, the α-relaxation process emerges from the JG relaxation at a fixed T as monomeric liquids polymerize under isothermal conditions, i.e., the viscosity of the liquid increases irreversibly until it becomes a glass isothermally. As polymerization progresses, the ε″ peak observed in the GHz frequency\nrange for the monomeric liquid begins to decrease in strength while its position does not change significantly. A new ε″ peak that corresponds to the α-relaxation evolves on the low frequency side,\nincreases in strength, and shifts to lower frequency as the viscosity increases. As polymerization occurs, the decrease in Δε for the high frequency relaxation with time has the same form as the decrease in Δε_JG as structural relaxation occurs during isothermal annealing.\n\n\n J. K. Vij and G.Power, Physical ageing and the Johari–Goldstein relaxation in molecular glasses, Journal of Non-Crystalline Solids 357 (2011) 783–792.\n\n"}
{"id": "429609", "url": "https://en.wikipedia.org/wiki?curid=429609", "title": "John Frederic Daniell", "text": "John Frederic Daniell\n\nJohn Frederic Daniell FRS (12 March 1790 – 13 March 1845) was an English chemist and physicist.\n\nDaniell was born in London. In 1831 he became the first professor of chemistry at the newly founded King's College London; and in 1835 he was appointed to the equivalent post at the East India Company's Military Seminary at Addiscombe, Surrey. His name is best known for his invention of the Daniell cell, an element of an electric battery much better than voltaic cells. He also invented the dew-point hygrometer known by his name, and a register pyrometer; and in 1830 he erected in the hall of the Royal Society a water-barometer, with which he carried out a large number of observations. A process devised by him for the manufacture of illuminating gas from turpentine and resin was in use in New York City for a time.\n\nIn 1842 he was awarded an honorary Doctorate of Civil Law by the University of Oxford.\n\nDaniell's publications included \"Meteorological Essays\" (1823), an \"Essay on Artificial Climate considered in its Applications to Horticulture\" (1824), which showed the necessity of a humid atmosphere in hothouses devoted to tropical plants, and an \"Introduction to the Study of Chemical Philosophy\" (1839).\n\nIn 1840 he was invited to deliver the Royal Institution Christmas Lecture on \"The First Principles of Franklinic Electricity\".\n\nDaniell died suddenly of apoplexy in London in March 1845, while attending a meeting of the council of the Royal Society, of which he had become a fellow in 1813 and Foreign Secretary in 1839.\n\nThe lunar crater Daniell is named in his honour.\n\n\n"}
{"id": "12175442", "url": "https://en.wikipedia.org/wiki?curid=12175442", "title": "Jōyō (nuclear reactor)", "text": "Jōyō (nuclear reactor)\n\nIt was made with the purpose of doing tests on and advancing the development of that type of reactor, as an irradiation test facility for construction materials. It also does tests with the nuclear fuel as well as activation experiments.\n\nThe reactor has gone through 3 different core changes.\n\nThe current core provides the neutron flux of 4×10 cms for E>0.1 MeV.\n\nAfter an incident in 2007, the reactor is suspended for repairing, recovery works were planned to be completed in 2014.\n\nFollowing the closure of the unsuccessful follow-on fast breeder reactor Monju in 2016, a decision was made to continue research at Jōyō.\n\n\n"}
{"id": "64204", "url": "https://en.wikipedia.org/wiki?curid=64204", "title": "Kinetic theory of gases", "text": "Kinetic theory of gases\n\nThe kinetic theory of gases describes a gas as a large number of submicroscopic particles (atoms or molecules), all of which are in constant, rapid, random motion. The randomness arises from the particles' many collisions with each other and with the walls of the container.\n\nKinetic theory of gases explains the macroscopic properties of gases, such as pressure, temperature, viscosity, thermal conductivity, and volume, by considering their molecular composition and motion. The theory posits that gas pressure results from particles' collisions with the walls of a container at different velocities.\n\nKinetic molecular theory defines temperature in its own way, in contrast with the thermodynamic definition.\n\nUnder an optical microscope, the molecules making up a liquid are too small to be visible. However, the jittery motion of pollen grains or dust particles in liquid are visible. Known as Brownian motion, the motion of the pollen or dust results from their collisions with the liquid's molecules.\n\nIn approximately 50 BCE, the Roman philosopher Lucretius proposed that apparently static macroscopic bodies were composed on a small scale of rapidly moving atoms all bouncing off each other. This Epicurean atomistic point of view was rarely considered in the subsequent centuries, when Aristotlean ideas were dominant.\n\nIn 1738 Daniel Bernoulli published \"Hydrodynamica\", which laid the basis for the kinetic theory of gases. In this work, Bernoulli posited the argument, still used to this day, that gases consist of great numbers of molecules moving in all directions, that their impact on a surface causes the gas pressure that we feel, and that what we experience as heat is simply the kinetic energy of their motion. The theory was not immediately accepted, in part because conservation of energy had not yet been established, and it was not obvious to physicists how the collisions between molecules could be perfectly elastic.\n\nOther pioneers of the kinetic theory (which were neglected by their contemporaries) were Mikhail Lomonosov (1747), Georges-Louis Le Sage (ca. 1780, published 1818), John Herapath (1816) and John James Waterston (1843), which connected their research with the development of mechanical explanations of gravitation. In 1856 August Krönig (probably after reading a paper of Waterston) created a simple gas-kinetic model, which only considered the translational motion of the particles.\n\nIn 1857 Rudolf Clausius, according to his own words independently of Krönig, developed a similar, but much more sophisticated version of the theory which included translational and contrary to Krönig also rotational and vibrational molecular motions. In this same work he introduced the concept of mean free path of a particle.\nIn 1871, Ludwig Boltzmann generalized Maxwell's achievement and formulated the Maxwell–Boltzmann distribution. Also the logarithmic connection between entropy and probability was first stated by him.\n\nIn the beginning of the twentieth century, however, atoms were considered by many physicists to be purely hypothetical constructs, rather than real objects. An important turning point was Albert Einstein's (1905) and Marian Smoluchowski's (1906)\npapers on Brownian motion, which succeeded in making certain accurate quantitative predictions based on the kinetic theory.\n\nThe theory for ideal gases makes the following assumptions:\n\n\n\n\nMore modern developments relax these assumptions and are based on the Boltzmann equation. These can accurately describe the properties of dense gases, because they include the volume of the molecules. The necessary assumptions are the absence of quantum effects, molecular chaos and small gradients in bulk properties. Expansions to higher orders in the density are known as virial expansions.\n\nAn important book on kinetic theory is that by Chapman and Cowling. An important approach to the subject is called Chapman–Enskog theory. There have been many modern developments and there is an alternative approach developed by Grad based on moment expansions.\nIn the other limit, for extremely rarefied gases, the gradients in bulk properties are not small compared to the mean free paths. This is known as the Knudsen regime and expansions can be performed in the Knudsen number.\n\nIn kinetic model of gases, the pressure is equal to the force exerted by the atoms hitting and rebounding from a unit area of the gas container surface. Consider a gas of \"N\" molecules, each of mass \"m\", enclosed in a cube of volume \"V\" = \"L\". When a gas molecule collides with the wall of the container perpendicular to the \"x\" axis and bounces off in the opposite direction with the same speed (an elastic collision), the change in momentum is given by:\n\nwhere \"p\" is the momentum, \"i\" and \"f\" indicate initial and final momentum (before and after collision), \"x\" indicates that only the \"x\" direction is being considered, and \"v\" is the speed of the particle (which is the same before and after the collision).\n\nThe particle impacts one specific side wall once every\n\nwhere \"L\" is the distance between opposite walls.\n\nThe force due to this particle is\n\nThe total force on the wall is\n\nwhere the bar denotes an average over the \"N\" particles.\n\nSince the motion of the particles is random and there is no bias applied in any direction, the average squared speed in each direction is identical:\n\nBy Pythagorean theorem in three dimensions the total squared speed \"v\" is given by\n\nTherefore:\n\nand the force can be written as:\n\nThis force is exerted on an area \"L\". Therefore, the pressure of the gas is\n\nwhere \"V\" = \"L\" is the volume of the box.\n\nIn terms of the kinetic energy of the gas \"K\":\n\nThis is a first non-trivial result of the kinetic theory because it relates pressure, a macroscopic property, to the (translational) kinetic energy of the molecules formula_12, which is a microscopic property.\n\nRewriting the above result for the pressure as formula_13, \nwe may combine it with the ideal gas law\n\nwhere formula_14 is the Boltzmann constant and formula_15 the\nabsolute temperature defined by the ideal gas law, to obtain\n\nwhich leads to simplified expression of the average kinetic energy per molecule,\n\nThe kinetic energy of the system is N times that of a molecule, namely formula_18.\nThen the temperature formula_15 takes the form\n\nwhich becomes\nEq.()\nis one important result of the kinetic\ntheory:\n\"The average molecular kinetic energy is proportional to the ideal gas law's absolute temperature\".\nFrom Eq.() and\nEq.(),\nwe have\n\nThus, the product of pressure and\nvolume per mole is proportional to the average\n(translational) molecular kinetic energy.\n\nEq.() and Eq.()\nare called the \"classical results\",\nwhich could also be derived from statistical mechanics;\nfor more details, see:\n\nSince there are\nformula_20\ndegrees of freedom in a monatomic-gas system with\nformula_21\nparticles,\nthe kinetic energy per degree of freedom per molecule is\n\nIn the kinetic energy per degree of freedom,\nthe constant of proportionality of temperature\nis 1/2 times Boltzmann constant or R/2 per mole. In addition to this, the temperature will decrease when the pressure drops to a certain point.\nThis result is related\nto the equipartition theorem.\n\nAs noted in the article on heat capacity, diatomic\ngases should have 7 degrees of freedom, but the lighter diatomic gases act\nas if they have only 5. Monatomic gases have 3 degrees of freedom.\n\nThus the kinetic energy per kelvin (monatomic ideal gas) is 3 [R/2] = 3R/2:\n\nAt standard temperature (273.15 K), we get:\n\nOne can calculate the number of atomic or molecular collisions with a wall of a container per unit area per unit time.\n\nAssuming an ideal gas, a derivation results in an equation for total number of collisions per unit time per area:\n\nThis quantity is also known as the \"impingement rate\" in vacuum physics.\n\nFrom the kinetic energy formula it can be shown that\n\nwhere \"v\" is in m/s, \"T\" is in kelvins, and \"m\" is the mass of one molecule of gas. The most probable (or mode) speed formula_26 is 81.6% of the rms speed formula_27, and the mean (arithmetic mean, or average) speed formula_28 is 92.1% of the rms speed (isotropic distribution of speeds).\n\nSee: \n\nThe kinetic theory of gases deals not only with gases in thermodynamic equilibrium, but also very importantly with gases not in thermodynamic equilibrium. This means considering what are known as \"transport properties\", such a viscosity and thermal conductivity.\n\nIn books on elementary kinetic \ntheory\none can find results for dilute gas modeling that has widespread use. \nDerivation of the kinetic model for shear viscosity usually starts by considering a Couette flow where two parallel plates are separated by a gas layer. The upper plate is moving at a constant velocity to the right due to a force F. The lower plate is stationary, and an equal and opposite force must therefore be acting on it to keep it at rest. The molecules in the gas layer have a forward velocity component formula_29 which increase uniformly with distance formula_30 above the lower plate. The non-equilibrium flow is superimposed on a Maxwell-Boltzmann equilibrium distribution of molecular motions.\n\nLet formula_31 be the collision cross section of one molecule colliding with another. The number density formula_32 is defined as the number of molecules per (extensive) volume formula_33. The collision cross section per volume or collision cross section density is formula_34, and it is related to the mean free path formula_35 by \n\nformula_36\n\nNotice that the unit of the collision cross section per volume formula_34 is reciprocal of length. The mean free path is the average distance traveled by a molecule, or a number of molecules per volume, before they make their first collision.\n\nLet formula_38 be the forward velocity of the gas at an imaginary horizontal surface inside the gas layer. On the average, a molecule that crosses the surface makes its last collision before crossing at a distance equal to two-thirds of the mean free path (i.e. formula_39) away from the surface. At this distance above and below the surface, the forward momentum of the molecule is respectively\n\nformula_40\n\nwhere m is the molecular mass. The molecular flux formula_41 includes all molecules arriving at one side of an element of the surface within the gas layer. The incoming molecules are coming from all directions at the one side of the surface and with all speeds. This molecular flux (i.e. the number flux) is related to the average molecular speed formula_42 by\n\nformula_43\n\nNotice that the forward velocity gradient formula_44 can be considered to be constant over a distance of mean free path. Next we multiply by the total flux to get the change of momentum per unit time and per unit area, that is carried by the molecules crossing from either above or below the surface area. This gives the equation\n\nformula_45\n\nThe net rate of momentum per unit area that is transported across the imaginary surface is thus\n\nformula_46\n\nThe defining equation for the (shear) viscosity formula_47 of the gas is\n\nformula_48\n\nCombining the above kinetic equation with defining equation for (shear) viscosity by formula_49 gives the equation for shear viscosity, which is usually denoted formula_50 when it is a dilute gas:\n\nformula_51\n\nCombining this equation with the equation for mean free path gives\n\nformula_52\n\nFrom statistical thermodynamics for gases we have equations relating average molecular speed to most likely speed and further to temperature. These statistical results gives the average (equilibrium) molecular speed as\n\nformula_53\n\nwhere formula_54 is the most probable speed, formula_55 is the Boltzmann constant. We note that\n\nformula_56\n\nand insert the velocity in the viscosity equation above. This gives the well known equation for shear viscosity for dilute gases:\n\nformula_57\n\nand formula_58 is the molar mass. The equation above presupposes that the gas density is low (i.e. the pressure is low). This implies that the kinetic translational energy dominates over rotational and vibrational molecule energies. The viscosity equation further presupposes that there is only one type of gas molecules, and that the gas molecules are perfect elastic and hard core particles of spherical shape. This assumption of elastic, hard core spherical molecules, like billiard balls, implies that the collision cross section of one molecule can be estimated by\n\nformula_59\n\nThe radius formula_60 is called collision cross section radius or kinetic radius, and the diameter formula_61 is called collision cross section diameter or kinetic diameter of a molecule in a monomolecular gas. There are no simple general relation between the collision cross section and the hard core size of the (fairly spherical) molecule. The relation depends on shape of the potential energy of the molecule. For a real spherical molecule (i.e. a noble gas atom or a reasonably spherical molecule) the interaction potential is more like the Lennard-Jones potential or Morse potential which have a negative part that attracts the other molecule from distances longer than the hard core radius. The radius for zero Lennard-Jones potential is then appropriate to use as estimate for the kinetic radius.\n\nLocal nomenclature list:\n\n\n\n\n\n\n\n"}
{"id": "57073573", "url": "https://en.wikipedia.org/wiki?curid=57073573", "title": "Korea District Heating Corporation", "text": "Korea District Heating Corporation\n\nThe Korea District Heating Corporation (KDHC; ) is a South Korean district heating company with its main office in Seongnam, South Korea. It was established as a statutory corporation in 1985 \"for the purpose of dealing effectively with the United Nations Framework Convention on Climate Change by promoting energy conservation and improving living standards through the efficient use of district heating\". It supplied district heating services to 1.3 million South Korean households as of 2015.\n"}
{"id": "51098118", "url": "https://en.wikipedia.org/wiki?curid=51098118", "title": "List of Japanese gardens in the United States", "text": "List of Japanese gardens in the United States\n\nThis list of Japanese gardens in the United States contains gardens, museums, institutions and other organizations which features gardens designed and created in traditional Japanese style that are open to the public.\n\n"}
{"id": "19111468", "url": "https://en.wikipedia.org/wiki?curid=19111468", "title": "MV Iron Baron (1985)", "text": "MV Iron Baron (1985)\n\nMV \"Iron Baron\" (formerly MV \"Ocean Express\" and MV \"Irrawaddy\") was a 37,557 dwt bulk carrier built in 1985. It was chartered by BHP Shipping in 1990.\n\nOn 10 July 1995 it was nearing the end of a voyage transporting 24,000 tonnes of manganese ore from Groote Eylandt via Port Kembla to the port of Launceston in northern Tasmania, Australia. Weather conditions at the time were north-westerly 37–46 km/h (20–25 knot) winds and two-metre seas. It grounded on Hebe Reef as it approached the mouth of the Tamar River and began leaking bunker fuel oil. The crew was safely evacuated.\n\nOn 16 July the \"Iron Baron\" was refloated and moved to an offshore anchorage. Underwater inspections confirmed that it had incurred major structural damage and was continuing to deteriorate. With further bad weather predicted, it was decided by BHP to dump the ship. It was towed to an approved disposal site 85 km east of Flinders Island where it sank on 30 July.\n\nAn estimated 325 tonnes of heavy bunker fuel oil was spilled from the vessel in the course of its grounding, refloating and towing to the disposal ground.\n\nSeveral beaches and islands in north-eastern Tasmania were affected and a major clean-up and wildlife rescue effort was undertaken. Little penguins were especially badly affected with 1894 oiled birds collected for treatment and rehabilitation. An estimated 2000–6000 were killed at Ninth Island alone. In 2001, penguin fatalities were estimated at between 10,000 and 20,000 birds. In 2005, a 10-year post-mortem reflection on the incident revised the figure upwards, estimating penguin fatalities at 25,000.\n\n"}
{"id": "27268344", "url": "https://en.wikipedia.org/wiki?curid=27268344", "title": "Maximum ramp weight", "text": "Maximum ramp weight\n\nThe maximum ramp weight (MRW) (also known as the maximum taxi weight (MTW)) is the maximum weight authorised for manoeuvring (taxiing or towing) an aircraft on the ground as limited by aircraft strength and airworthiness requirements. It includes the weight of taxi and run-up fuel for the engines and the auxiliary power unit (APU).\n\nIt is greater than the maximum takeoff weight due to the fuel that will be burned during the taxi and runup operations.\n\nThe difference between the maximum taxi/ramp weight and the maximum take-off weight (\"maximum taxi fuel allowance\") depends on the size of the aircraft, the number of engines, APU operation, and engines/APU fuel consumption, and is typically assumed for 10 to 15 minutes allowance of taxi and run-up operations.\n\n\n"}
{"id": "21162207", "url": "https://en.wikipedia.org/wiki?curid=21162207", "title": "Mott criterion", "text": "Mott criterion\n\nThe Mott criterion describes the critical point of the metal–insulator transition. The criterion is\n\nformula_1\n\nwhere formula_2 is the electron density of the material and formula_3 the effective bohr radius. \nThe constant formula_4, according to various estimates, is 2.0, 2.78,4.0, or 4.2.\n\nIf the criterion is satisfied (i.e. if the density of electrons is sufficiently high) the material becomes conductive (metal) and otherwise it will be an insulator.\n\n"}
{"id": "1693865", "url": "https://en.wikipedia.org/wiki?curid=1693865", "title": "Nose cone design", "text": "Nose cone design\n\nGiven the problem of the aerodynamic design of the nose cone section of any vehicle or body meant to travel through a compressible fluid medium (such as a rocket or aircraft, missile or bullet), an important problem is the determination of the nose cone geometrical shape for optimum performance. For many applications, such a task requires the definition of a solid of revolution shape that experiences minimal resistance to rapid motion through such a fluid medium, which consists of elastic particles.\n\nIn all of the following nose cone shape equations, is the overall length of the nose cone and is the radius of the base of the nose cone. is the radius at any point , as varies from , at the tip of the nose cone, to . The equations define the two-dimensional profile of the nose shape. The full body of revolution of the nose cone is formed by rotating the profile around the centerline . While the equations describe the 'perfect' shape, practical nose cones are often blunted or truncated for manufacturing or aerodynamic reasons.\n\nA very common nose-cone shape is a simple cone. This shape is often chosen for its ease of manufacture. More optimal, streamlined shapes (described below) are often much more difficult to create. The sides of a conic profile are straight lines, so the diameter equation is simply:\n\nCones are sometimes defined by their half angle, :\n\nIn practical applications, a conical nose is often blunted by capping it with a segment of a sphere. The tangency point where the sphere meets the cone can be found from:\nwhere is the radius of the spherical nose cap.\n\nThe center of the spherical nose cap, , can be found from:\n\nAnd the apex point, can be found from: \n\nA bi-conic nose cone shape is simply a cone with length stacked on top of a frustum of a cone (commonly known as a \"conical transition section\" shape) with length , where the base of the upper cone is equal in radius to the top radius of the smaller frustum with base radius .\n\nHalf angles:\n\nNext to a simple cone, the tangent ogive shape is the most familiar in hobby rocketry. The profile of this shape is formed by a segment of a circle such that the rocket body is tangent to the curve of the nose cone at its base, and the base is on the radius of the circle. The popularity of this shape is largely due to the ease of constructing its profile, as it is simply a circular section.\n\nThe radius of the circle that forms the ogive is called the \"ogive radius\", , and it is related to the length and base radius of the nose cone as expressed by the formula:\nThe radius at any point , as varies from to is:\n\nThe nose cone length, , must be less than or equal to . If they are equal, then the shape is a hemisphere.\n\nA tangent ogive nose is often blunted by capping it with a segment of a sphere. The tangency point where the sphere meets the tangent ogive can be found from:\nwhere is the radius and is the center of the spherical nose cap.\n\nFinally, the apex point can be found from:\n\nThe profile of this shape is also formed by a segment of a circle, but the base of the shape is not on the radius of the circle defined by the ogive radius. The rocket body will not be tangent to the curve of the nose at its base. The ogive radius is not determined by and (as it is for a tangent ogive), but rather is one of the factors to be chosen to define the nose shape. If the chosen ogive radius of a secant ogive is greater than the ogive radius of a tangent ogive with the same and , then the resulting secant ogive appears as a tangent ogive with a portion of the base truncated.\n\nThen the radius at any point as varies from to is:\n\nIf the chosen is less than the tangent ogive and greater than half the length of the nose cone, then the result will be a secant ogive that bulges out to a maximum diameter that is greater than the base diameter. The classic example of this shape is the nose cone of the Honest John.\n\nThe profile of this shape is one-half of an ellipse, with the major axis being the centerline and the minor axis being the base of the nose cone. A rotation of a full ellipse about its major axis is called a prolate spheroid, so an elliptical nose shape would properly be known as a prolate hemispheroid. This shape is popular in subsonic flight (such as model rocketry) due to the blunt nose and tangent base. This is not a shape normally found in professional rocketry, which almost always flies at much higher velocities where other designs are more suitable. If equals , this is a hemisphere.\n\nThis nose shape is not the blunt shape that is envisioned when people commonly refer to a \"parabolic\" nose cone. The parabolic series nose shape is generated by rotating a segment of a parabola around a line parallel to its latus rectum. This construction is similar to that of the tangent ogive, except that a parabola is the defining shape rather than a circle. Just as it does on an ogive, this construction produces a nose shape with a sharp tip. For the blunt shape typically associated with a parabolic nose, see power series below. (The parabolic shape is also often confused with the elliptical shape.)\n\nFor formula_26 : formula_27\n\nFor the case of the full parabola () the shape is tangent to the body at its base, and the base is on the axis of the parabola. Values of less than result in a slimmer shape, whose appearance is similar to that of the secant ogive. The shape is no longer tangent at the base, and the base is parallel to, but offset from, the axis of the parabola.\n\nThe \"power series\" includes the shape commonly referred to as a 'parabolic' nose cone, but the shape correctly known as a parabolic nose cone is a member of the parabolic series (described above). The power series shape is characterized by its (usually) blunt tip, and by the fact that its base is not tangent to the body tube. There is always a discontinuity at the joint between nose cone and body that looks distinctly non-aerodynamic. The shape can be modified at the base to smooth out this discontinuity. Both a flat-faced cylinder and a cone are shapes that are members of the power series.\n\nThe power series nose shape is generated by rotating the curve about the -axis for values of less than . The factor controls the bluntness of the shape. For values of above about , the tip is fairly sharp. As decreases towards zero, the power series nose shape becomes increasingly blunt.\n\nCommon values of include:\nUnlike all of the nose cone shapes above, the Haack series shapes are not constructed from geometric figures. The shapes are instead mathematically derived for the purpose of minimizing drag; see also Sears–Haack body. While the series is a continuous set of shapes determined by the value of in the equations below, two values of have particular significance: when , the notation signifies minimum drag for the given length and diameter, and when , indicates minimum drag for a given length and volume. The Haack series nose cones are not perfectly tangent to the body at their base except for the case where . However, the discontinuity is usually so slight as to be imperceptible. For , Haack nose cones bulge to a maximum diameter greater than the base diameter. Haack nose tips do not come to a sharp point, but are slightly rounded.\n\nSpecial values of (as described above) include:\nThe Haack series giving minimum drag for the given length and diameter, the LD-Haack where , is commonly called the \"Von Kármán\" or \"Von Kármán ogive\".\n\nFor aircraft and rockets, below Mach .8, the nose pressure drag is essentially zero for all shapes. The major significant factor is friction drag, which is largely dependent upon the wetted area, the surface smoothness of that area, and the presence of any discontinuities in the shape. For example, in strictly subsonic rockets a short, blunt, smooth elliptical shape is usually best. In the transonic region and beyond, where the pressure drag increases dramatically, the effect of nose shape on drag becomes highly significant. The factors influencing the pressure drag are the general shape of the nose cone, its fineness ratio, and its bluffness ratio.\n\nMany references on nose cone design contain empirical data comparing the drag characteristics of various nose shapes in different flight regimes. The chart shown here seems to be the most comprehensive and useful compilation of data for the flight regime of greatest interest. This chart generally agrees with more detailed, but less comprehensive data found in other references (most notably the USAF Datcom).\n\nIn many nose cone designs, the greatest concern is flight performance in the transonic region from 0.8 to 1.2 Mach. Although data are not available for many shapes in the transonic region, the table clearly suggests that either the Von Kármán shape, or power series shape with , would be preferable to the popular conical or ogive shapes, for this purpose.\n\nThis observation goes against the often-repeated conventional wisdom that a conical nose is optimum for 'Mach-breaking'. Fighter aircraft are probably good examples of nose shapes optimized for the transonic region, although their nose shapes are often distorted by other considerations of avionics and inlets. For example, an F-16 Fighting Falcon nose appears to be a very close match to a Von Kármán shape.\n\nThe ratio of the length of a nose cone compared to its base diameter is known as the \"fineness ratio\". This is sometimes also called the \"aspect ratio\", though that term is usually applied to wings and fins. Fineness ratio is often applied to the entire vehicle, considering the overall length and diameter. The length/diameter relation is also often called the \"caliber\" of a nose cone.\n\nAt supersonic speeds, the fineness ratio has a significant effect on nose cone wave drag, particularly at low ratios; but there is very little additional gain for ratios increasing beyond 5:1. As the fineness ratio increases, the wetted area, and thus the skin friction component of drag, is also going to increase. Therefore, the minimum drag fineness ratio is ultimately going to be a trade-off between the decreasing wave drag and increasing friction drag.\n\n"}
{"id": "147242", "url": "https://en.wikipedia.org/wiki?curid=147242", "title": "Octane rating", "text": "Octane rating\n\nAn octane rating, or octane number, is a standard measure of the performance of an engine or aviation fuel. The higher the octane number, the more compression the fuel can withstand before detonating (igniting). In broad terms, fuels with a higher octane rating are used in high performance gasoline engines that require higher compression ratios. In contrast, fuels with lower octane numbers (but higher cetane numbers) are ideal for diesel engines, because diesel engines (also referred to as compression-ignition engines) do not compress the fuel, but rather compress only air and then inject fuel into the air which was heated by compression. Gasoline engines rely on ignition of air and fuel compressed together as a mixture, which is ignited at the end of the compression stroke using spark plugs. Therefore, high compressibility of the fuel matters mainly for gasoline engines. Use of gasoline with lower octane numbers may lead to the problem of engine knocking.\n\nIn a normal spark-ignition engine, the air-fuel mixture is heated because of being compressed and is then triggered to burn rapidly by the spark plug. During the combustion process, if the unburnt portion of the fuel in the combustion chamber is heated (or compressed) too much, pockets of unburnt fuel may self-ignite (detonate) before the main flame front reaches them. Shockwaves produced by detonation can cause much higher pressures than engine components are designed for, and can cause a \"knocking\" or \"pinging\" sound. Knocking can cause major engine damage if severe.\n\nThe most typically used engine management systems found in automobiles today have a knock sensor that monitors if knock is being produced by the fuel being used. In modern computer-controlled engines, the ignition timing will be automatically altered by the engine management system to reduce the knock to an acceptable level.\n\nOctanes are a family of hydrocarbons that are typical components of gasoline. They are colorless liquids that boil around 125 °C (260 °F). One member of the octane family, isooctane, is used as a reference standard to benchmark the tendency of gasoline or LPG fuels to resist self-ignition.\n\nThe octane rating of gasoline is measured in a test engine and is defined by comparison with the mixture of 2,2,4-trimethylpentane (iso-octane) and heptane that would have the same anti-knocking capacity as the fuel under test: the percentage, by volume, of 2,2,4-trimethylpentane in that mixture is the octane number of the fuel. For example, gasoline with the same knocking characteristics as a mixture of 90% iso-octane and 10% heptane would have an octane rating of 90. A rating of 90 does not mean that the gasoline contains just iso-octane and heptane in these proportions but that it has the same detonation resistance properties (generally, gasoline sold for common use never consists solely of iso-octane and heptane; it is a mixture of many hydrocarbons and often other additives). Because some fuels are more knock-resistant than pure iso-octane, the definition has been extended to allow for octane numbers greater than 100.\n\nOctane ratings are not indicators of the energy content of fuels. (See Effects below and Heat of combustion). They are only a measure of the fuel's tendency to burn in a controlled manner, rather than exploding in an uncontrolled manner. Where the octane number is raised by blending in ethanol, energy content per volume is reduced. Ethanol BTUs can be compared with gasoline BTUs in heat of combustion tables.\n\nIt is possible for a fuel to have a Research Octane Number (RON) more than 100, because iso-octane is not the most knock-resistant substance available. Racing fuels, avgas, LPG and alcohol fuels such as methanol may have octane ratings of 110 or significantly higher. Typical \"octane booster\" gasoline additives include MTBE, ETBE, isooctane and toluene. Lead in the form of tetraethyllead was once a common additive, but its use for fuels for road vehicles has been progressively phased-out worldwide, beginning in the 1970s.\n\nThe most common type of octane rating worldwide is the Research Octane Number (RON). RON is determined by running the fuel in a test engine with a variable compression ratio under controlled conditions, and comparing the results with those for mixtures of iso-octane and n-heptane.\n\nAnother type of octane rating, called Motor Octane Number (MON), is determined at 900 rpm engine speed instead of the 600 rpm for RON. MON testing uses a similar test engine to that used in RON testing, but with a preheated fuel mixture, higher engine speed, and variable ignition timing to further stress the fuel's knock resistance. Depending on the composition of the fuel, the MON of a modern pump gasoline will be about 8 to 12 octane lower than the RON, but there is no direct link between RON and MON. Pump gasoline specifications typically require both a minimum RON and a minimum MON.\n\nIn most countries in Europe (also in Australia and New Zealand) the \"headline\" octane rating shown on the pump is the RON, but in Canada, the United States, Brazil, and some other countries, the headline number is the average of the RON and the MON, called the Anti-Knock Index (AKI), and often written on pumps as (R+M)/2. It may also sometimes be called the Posted Octane Number (PON).\n\nBecause of the 8 to 12 octane number difference between RON and MON noted above, the AKI shown in Canada and the United States is 4 to 6 octane numbers lower than elsewhere in the world for the same fuel. This difference between RON and MON is known as the fuel's Sensitivity, and is not typically published for those countries that use the Anti-Knock Index labelling system.\n\nSee the table in the following section for a comparison.\n\nAnother type of octane rating, called Observed Road Octane Number (RdON), is derived from testing gasolines in real world multi-cylinder engines, normally at wide open throttle. It was developed in the 1920s and is still reliable today. The original testing was done in cars on the road but as technology developed the testing was moved to chassis dynamometers with environmental controls to improve consistency.\n\nThe evaluation of the octane number by the two laboratory methods requires a standard engine, and the test procedure can be both expensive and time-consuming. The standard engine required for the test may not always be available, especially in out-of-the-way places or in small or mobile laboratories. These and other considerations led to the search for a rapid method for the evaluation of the anti-knock quality of gasoline. Such methods include FTIR, near infrared on-line analyzers (ASTM D-2885) and others. Deriving an equation that can be used for calculating the octane quality would also serve the same purpose with added advantages. The term Octane Index is often used to refer to the calculated octane quality in contradistinction to the (measured) research or motor octane numbers. The octane index can be of great service in the blending of gasoline. Motor gasoline, as marketed, is usually a blend of several types of refinery grades that are derived from different processes such as straight-run gasoline, reformate, cracked gasoline etc. These different grades are considered as one group when blending to meet final product specifications. Most refiners produce and market more than one grade of motor gasoline, differing principally in their anti-knock quality. The ability to predict the octane quality of the blends prior to blending is essential, something for which the calculated octane index is specially suited.\n\nAviation gasolines used in piston aircraft engines common in general aviation have a slightly different method of measuring the octane of the fuel. Similar to an AKI, it has two different ratings, although it is referred to only by the lower of the two. One is referred to as the \"aviation lean\" rating and is the same as the MON of the fuel up to 100. The second is the \"aviation rich\" rating and corresponds to the octane rating of a test engine under forced induction operation common in high-performance and military piston aircraft. This utilizes a supercharger, and uses a significantly richer fuel/air ratio for improved detonation resistance. \n\nThe most commonly used current fuel, 100LL, has an aviation lean rating of 100 octane, and an aviation rich rating of 130.\n\nThe RON/MON values of n-heptane and iso-octane are exactly 0 and 100, respectively, by the definition of octane rating. The following table lists octane ratings for various other fuels.\n\nHigher octane ratings correlate to higher activation energies: the amount of applied energy required to initiate combustion. Since higher octane fuels have higher activation energy requirements, it is less likely that a given compression will cause uncontrolled ignition, otherwise known as autoignition or detonation.\n\nBecause octane is a measured and/or calculated rating of the fuel's ability to resist autoignition, the higher the octane of the fuel, the harder that fuel is to ignite and the more heat is required to ignite it. The result is that a hotter ignition spark is required for ignition. Creating a hotter spark requires more energy from the ignition system, which in turn increases the parasitic electrical load on the engine. The spark also must begin earlier in order to generate sufficient heat at the proper time for precise ignition. As octane, ignition spark energy, and the need for precise timing increase, the engine becomes more difficult to \"tune\" and keep \"in tune\". The resulting sub-optimal spark energy and timing can cause major engine problems, from a simple \"miss\" to uncontrolled detonation and catastrophic engine failure.\n\nThe other rarely-discussed reality with high-octane fuels associated with \"high performance\" is that as octane increases, the specific gravity and energy content of the fuel per unit of weight are reduced. The net result is that to make a given amount of power, more high-octane fuel must be burned in the engine. Lighter and \"thinner\" fuel also has a lower specific heat, so the practice of running an engine \"rich\" to use excess fuel to aid in cooling requires richer and richer mixtures as octane increases.\n\nHigher-octane, lower-energy-dense \"thinner\" fuels often contain alcohol compounds incompatible with the stock fuel system components, which also makes them hygroscopic. They also evaporate away much more easily than heavier, lower-octane fuel which leads to more accumulated contaminants in the fuel system. Its typically the and the compounds in the fuel that have the most detrimental effects on the engine fuel system components, as such acids corrode many metals used in gasoline fuel systems. \n\nDuring the compression stroke of an internal combustion engine, the temperature of the air-fuel mix rises as it is compressed, in accordance with the ideal gas law. Higher compression ratios necessarily add parasitic load to the engine, and are only necessary if the engine is being specifically designed to run on high-octane fuel. Aircraft engines run at relatively low speeds and are \"undersquare\". They run best on lower-octane, slower-burning fuels that require less heat and a lower compression ratio for optimum vaporization and uniform fuel-air mixing, with the ignition spark coming as late as possible in order to extend the production of cylinder pressure and torque as far down the power stroke as possible. The main reason for using high-octane fuel in air-cooled engines is that it is more easily vaporized in a cold carburetor and engine and absorbs less intake air heat which greatly reduces the tendency for carburetor icing to occur. \n\nWith their reduced densities and weight per volume of fuel, the other obvious benefit is that an aircraft with any given volume of fuel in the tanks is automatically lighter. And since many airplanes are flown only occasionally and may sit unused for weeks or months, the lighter fuels tend to evaporate away and leave behind fewer deposits such as \"varnish\". Aircraft also typically have dual \"redundant\" ignition systems which are nearly impossible to tune and time to produce identical ignition timing so using a lighter fuel that's less prone to autoignition is a wise \"insurance policy\". For the same reasons, those lighter fuels which are better solvents are much less likely to cause any \"varnish\" or other fouling on the \"backup\" spark plugs. \n\nBecause of the high cost of unleaded, high-octane avgas, and the tendency of piston-engine aircraft to be recreational vehicles and the potential for fuel loss via evaporation/theft/leaks, most general aviation pilots attempt to save money by tuning their fuel-air mixtures and ignition timing to run \"lean of peak\". \n\nThat practice can be fine for \"cruising\" straight and level and in smooth air, but in case of the need to rapidly add power (sudden climb, headwind, etc), the additional \"insurance policy\" of excess octane in avgas helps prevent dangerously lean fuel-air mixtures from rapidly melting and physically \"burning\" the aluminum pistons in an air-cooled aircraft engine. With only fuel, lubricating oil and airflow to cool the engine and a \"lean of peak\" mixture with no \"excess\" fuel for cooling, the engine is only a few seconds of dangerously lean mixtures, autoignition and detonation away from catastrophic failure.\n\nThe selection of octane ratings available at the pump can vary greatly from region to region.\n\n"}
{"id": "4207510", "url": "https://en.wikipedia.org/wiki?curid=4207510", "title": "Oil", "text": "Oil\n\nAn oil is any nonpolar chemical substance that is a viscous liquid at ambient temperatures and is both hydrophobic (does not mix with water, literally \"water fearing\") and lipophilic (mixes with other oils, literally \"fat loving\"). Oils have a high carbon and hydrogen content and are usually flammable and surface active.\n\nThe general definition of oil includes classes of chemical compounds that may be otherwise unrelated in structure, properties, and uses. Oils may be animal, vegetable, or petrochemical in origin, and may be volatile or non-volatile. They are used for food (e.g., olive oil), fuel (e.g., heating oil), medical purposes (e.g., mineral oil), lubrication (e.g. motor oil), and the manufacture of many types of paints, plastics, and other materials. Specially prepared oils are used in some religious ceremonies and rituals as purifying agents.\n\nFirst attested in English 1176, the word \"oil\" comes from Old French \"oile\", from Latin \"oleum\", which in turn comes from the Greek (\"elaion\"), \"olive oil, oil\" and that from (\"elaia\"), \"olive tree\", \"olive fruit\". The earliest attested forms of the word are the Mycenaean Greek , \"e-ra-wo\" and , \"e-rai-wo\", written in the Linear B syllabic script.\n\nOrganic oils are produced in remarkable diversity by plants, animals, and other organisms through natural metabolic processes. \"Lipid\" is the scientific term for the fatty acids, steroids and similar chemicals often found in the oils produced by living things, while oil refers to an overall mixture of chemicals. Organic oils may also contain chemicals other than lipids, including proteins, waxes (class of compounds with oil-like properties that are solid at common temperatures) and alkaloids.\n\nLipids can be classified by the way that they are made by an organism, their chemical structure and their limited solubility in water compared to oils. They have a high carbon and hydrogen content and are considerably lacking in oxygen compared to other organic compounds and minerals; they tend to be relatively nonpolar molecules, but may include both polar and nonpolar regions as in the case of phospholipids and steroids.\n\nCrude oil, or petroleum, and its refined components, collectively termed \"petrochemicals\", are crucial resources in the modern economy. Crude oil originates from ancient fossilized organic materials, such as zooplankton and algae, which geochemical processes convert into oil. The name \"mineral oil\" is a misnomer, in that minerals are not the source of the oil—ancient plants and animals are. Mineral oil is organic. However, it is classified as \"mineral oil\" instead of as \"organic oil\" because its organic origin is remote (and was unknown at the time of its discovery), and because it is obtained in the vicinity of rocks, underground traps, and sands. \"Mineral oil\" also refers to several specific distillates of crude oil.\n\nSeveral edible vegetable and animal oils, and also fats, are used for various purposes in cooking and food preparation. In particular, many foods are fried in oil much hotter than boiling water. Oils are also used for flavoring and for modifying the texture of foods (e.g. Stir Fry). Cooking oils are derived either from animal fat, as butter, lard and other types, or plant oils from the olive, maize, sunflower and many other species.\n\nOils are applied to hair to give it a lustrous look, to prevent tangles and roughness and to stabilize the hair to promote growth. See hair conditioner.\n\nOil has been used throughout history as a religious medium. It is often considered a spiritually purifying agent and is used for anointing purposes. As a particular example, holy anointing oil has been an important ritual liquid for Judaism and Christianity.\n\nColor pigments are easily suspended in oil, making it suitable as a supporting medium for paints. The oldest known extant oil paintings date from 650 AD.\n\nOils are used as coolants in oil cooling, for instance in electric transformers. Heat transfer oils are used both as coolants (see oil cooling), for heating (e.g. in oil heaters) and in other applications of heat transfer.\n\nGiven that they are non-polar, oils do not easily adhere to other substances. This makes them useful as lubricants for various engineering purposes. Mineral oils are more commonly used as machine lubricants than biological oils are. Whale oil is preferred for lubricating clocks, because it does not evaporate, leaving dust, although its use was banned in the USA in 1980.\n\nIt is a long-running myth that spermaceti from whales has still been used in NASA projects such as the Hubble Telescope and the Voyager probe because of its extremely low freezing temperature. Spermaceti is not actually an oil, but a mixture mostly of wax esters, and there is no evidence that NASA has used whale oil.\n\nSome oils burn in liquid or aerosol form, generating light, and heat which can be used directly or converted into other forms of energy such as electricity or mechanical work. To obtain many fuel oils, crude oil is pumped from the ground and is shipped via oil tanker or a pipeline to an oil refinery. There, it is converted from crude oil to diesel fuel (petrodiesel), ethane (and other short-chain alkanes), fuel oils (heaviest of commercial fuels, used in ships/furnaces), gasoline (petrol), jet fuel, kerosene, benzene (historically), and liquefied petroleum gas. A 42-gallon barrel (U.S.) of crude oil produces approximately 10 gallons of diesel, 4 gallons of jet fuel, 19 gallons of gasoline, 7 gallons of other products, 3 gallons split between heavy fuel oil and liquified petroleum gases, and 2 gallons of heating oil. The total production of a barrel of crude into various products results in an increase to 45 gallons. Not all oils used as fuels are mineral oils, see biodiesel and vegetable oil fuel.\n\nIn the 18th and 19th centuries, whale oil was commonly used for lamps, which was replaced with natural gas and then electricity.\n\nCrude oil can be refined into a wide variety of component hydrocarbons. \"Petrochemicals\" are the refined components of crude oil and the chemical products made from them. They are used as detergents, fertilizers, medicines, paints, plastics, synthetic fibers, and synthetic rubber.\n\nOrganic oils are another important chemical feedstock, especially in green chemistry.\n\n\n"}
{"id": "3088802", "url": "https://en.wikipedia.org/wiki?curid=3088802", "title": "Oil Shockwave", "text": "Oil Shockwave\n\nThe Oil Shockwave event was a policy wargaming scenario created by the joint effort of several energy policy think tanks, the National Commission on Energy Policy and Securing America's Future Energy. It outlined a series of hypothetical international events taking place in December 2005, all related to world supply and demand of petroleum. Participants in the scenario role-played Presidential Cabinet officials, who were asked to discuss and respond to the events. The hypothetical events included civil unrest in OPEC country Nigeria, and coordinated terrorist attacks on ports in Saudi Arabia and Alaska. In the original simulation, the participants had all previously held jobs closely related to their roles in the exercise.\n\nJason Grumet, from the \"National Commission on Energy Policy\", said that the message of the simulation was that, \"very modest disruptions in oil supply, whether they're here at home or abroad can have truly devastating impacts on our nations economy and our overall security.\"\n\nThe original event was performed June 23, 2005, and was a simulation of December 2005, six months in the future. The first scenario involved civil unrest in Nigeria, a member of the Organization of Petroleum Exporting Countries, resulting in oil companies and the US government evacuating their personnel from the country. In the simulation, this led to decrease in oil supply and the price spikes causing a variety of negative effects on the United States economy. \n\nMore events followed as the scenario progressed, including a very cold winter in the Northern hemisphere, terrorist attacks on Saudi Arabian and Alaskan oil ports, and Al-Qaeda cells hijacking oil tankers and crashing them into the docking facilities at the ports (which might effectively shut down such port for weeks, if not months).\n\nThe scenarios were set up with pre-produced scripted news clips. Participants were also given briefing memos with background information related to their specific cabinet positions. The participants discussed and prepared policy recommendations for an unseen Chief Executive after each part of the scenario.\n\nThe original event was a one-time exercise and used participants that held positions that were identical or closely related to their positions in the simulation. Participants included former administrator of the Environmental Protection Agency Carol Browner, former Director of Central Intelligence Robert Gates, former Marine Corps Commendant and member of the Joint Chiefs of Staff General P.X. Kelley USMC (Ret.), and former National Economic Advisor to the President, Gene Sperling.\n\n"}
{"id": "48230267", "url": "https://en.wikipedia.org/wiki?curid=48230267", "title": "Oriented structural straw board", "text": "Oriented structural straw board\n\nOriented structural straw board (OSSB) is an engineered board that is made by splitting straw and formed by adding formaldehyde-free adhesives and then hot compressing layers of straw in specific orientations. Research and development for OSSB panels began in the mid 1980s and was spearheaded by The Alberta Research Council, Canada (today AITF) which identified the straw strand manufacturing technology using formaldehyde-free (p-MDI) adhesives.\n\nOSSB can replace wood oriented strand board (OSB) and particle board in structural and non-structural applications, such as interior and exterior walls for house construction, furniture and interior decoration.\n\nOSSB panel manufacturing starts with careful selection of straw fibres, which are then cut, cleaned, split and dried. Splitting straws allows resin to coat what would otherwise be the inside of a hollow straw. Producing split straw of sufficient length was the key technical innovation making OSSBs possible. OSSB is thus sometimes referred to as oriented split straw board. Formaldehyde free resin is added to the straw and the fibres are oriented for strength and appearance, and shaped into a mat through directional mat forming. The mat is then pressed between heated belts, water is vaporized, transferring heat into the straw. The heat cures the adhesive and causes a series of physical and chemical changes to the pressurized raw materials, which harden the final product.\n\nOne producer of OSSB on a commercial scale is Novofibre Panel Board Holding China, Ltd., located in Yangling, Shaanxi province in China. Currently, their factory has a yearly capacity.\n\nOSSB panels have high structural strength, load bearing and stability in both directions, as well as superior workability and excellent nail holding properties on all sides. Water permeability treated OSSB panels are more water resistant than treated traditional wood panel boards because they have no internal gaps or voids. OSSB panels are also highly earthquake resistant.\nThe resin used to manufacture OSSB is p-MDI, which does not emit volatile organic compounds (VOCs) and is formaldehyde-free. The raw material can be treated by various borate compounds, which are toxic to termites, beetles, molds, and fungi, but not to mammals in applied doses.\n\nOSSB boards are available in thicknesses varying from in different densities.\nNovofibre Panel Board Holding China, Ltd., manufactures 3 standard products:\n\n"}
{"id": "36030443", "url": "https://en.wikipedia.org/wiki?curid=36030443", "title": "Outline of nuclear power", "text": "Outline of nuclear power\n\nThe following outline is provided as an overview of and topical guide to nuclear power:\n\nNuclear power – the use of sustained nuclear fission to generate heat and electricity. Nuclear power plants provide about 6% of the world's energy and 13–14% of the world's electricity, with the U.S., France, and Japan together accounting for about 50% of nuclear generated electricity.\n\nNuclear power can be described as all of the following:\n\n\n\nNuclear material\n\n\n\n\nHistory of nuclear power\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNuclear power groups\n\n\n\n\n"}
{"id": "26653222", "url": "https://en.wikipedia.org/wiki?curid=26653222", "title": "Parasporal body", "text": "Parasporal body\n\nParasporal body is a crystalline protein that forms around a spore in some bacteria that acts as a toxin precursor when digested.\n\nFor example, \"Bacillus thuringiensis\" and \"Bacillus sphaericus\" form a solid protein crystal, the parasporal body, next to their endospores during spore formation. The \"B. thuringiensis\" parasporal body contains protein toxins that kill over 100 species of moths by dissolving in the alkaline gut of caterpillars and destroying the epithelium. The solubilized toxin proteins are cleaved by mid-gut proteases to smaller toxic polypeptides that attack the gut epithelial cells. The alkaline gut contents escape into the blood, causing paralysis and death. One of these toxins has been shown to form pores in the plasma membrane of the target insect's cells. These channels allow monovalent cations such as potassium to pass through. \n\n\"B. thuringiensis\" toxin genes have been engineered to make a variety of pest-resistant, genetically modified plants. The \"B. sphaericus\" parasporal body contains proteins toxic for mosquito larvae and may be useful in controlling the mosquitoes that carry the malaria parasite \"Plasmodium\".\n\n"}
{"id": "13893984", "url": "https://en.wikipedia.org/wiki?curid=13893984", "title": "Psychrometric constant", "text": "Psychrometric constant\n\nThe psychrometric constant formula_1 relates the partial pressure of water in air to the air temperature. This lets one interpolate actual vapor pressure from paired dry and wet thermometer bulb temperature readings.\n\nBoth formula_7 and formula_8 are constants.<br>\nSince atmospheric pressure, P, depends upon altitude, so does formula_9.<br>\nAt higher altitude water evaporates and boils at lower temperature.\n\nAlthough formula_10 is constant, varied air composition results in varied formula_11.\n\nThus on average, at a given location or altitude, the psychrometric constant is approximately constant. Still, it is worth remembering that weather impacts both atmospheric pressure and composition.\n\nSaturated vapor pressure, formula_12<br>\nActual vapor pressure, formula_13\n"}
{"id": "41447716", "url": "https://en.wikipedia.org/wiki?curid=41447716", "title": "Renewable energy in Luxembourg", "text": "Renewable energy in Luxembourg\n\nRenewable energy in Luxembourg comes from hydro power, wind, biomass and solar power.\n\nPolicy that supports renewable energy development in Luxembourg is the 1993 Framework Law (amended in 2005), in which there are special tariffs given to different type of renewable energy used and subsidies available for private companies that invest in renewable energy technology.\n\nIn 2005, renewable energy contributed to the 24.8% electricity generation in the country, which comprises pump storage (19.0%), hydro (2.3%), biomass (1.8%), wind (1.3%) and solar (0.4%).\n\n"}
{"id": "51872207", "url": "https://en.wikipedia.org/wiki?curid=51872207", "title": "Robin Hood Energy", "text": "Robin Hood Energy\n\nRobin Hood Energy is a Not for Profit Energy Company launched in September 2015 by Nottingham City Council as a competitor to the Big Six Energy Suppliers (UK). The company operates as both an energy generator and supplier. Nottingham City Council wholly own the company making it the first local authority energy company in the UK. Prior none had existed since the UK energy system was nationalised in 1948 under the Electricity Act 1947 and subsequently privatised in 1990 under the Electricity Act 1989.\n\nThe aim of the organisation is provide low cost energy to all households and address fuel poverty. It provides special tariffs to residents within the boundaries of the Nottingham City Council and provides a socially orientated pricing structure to the entirety of the UK.\n\nThe company operates Not for Profit by keeping overheads as low as possible, does not pay bonuses to staff and none of the organisation's directors are paid. This makes the company rare within the UK energy market as a Not For Profit company.\n\nThe company generates electricity from the city’s incinerator, solar panels and waste food plants while also buying in gas and electricity from the UK electricity and gas markets. The mixture of energy generated and bought from markets to be sold to consumers has not been revealed at this time. Robin Hood Energy will publish its first Fuel Mix Disclosure in the summer of 2017.\n\nRobin Hood Energy partnered with Leeds City Council to establish as of September 2016 White Rose Energy, an iniative to provide affordble energy to residents in Leeds and Yorkshire.\n\nRobin Hood Energy was announced on March 10, 2017 as the new supply partner for Not For Profit energy provider and registered Social Enterprise Ebico. This began a transition of Ebico customers who opted in to be transferred to the new Ebico Zero Tariffs provided by Robin Hood Energy. In the decision to opt for a relationship with Robin Hood Energy Ebico stated \"we wanted to ensure our supply partner shared the same values as us; something Robin Hood Energy does in its mission to provide its customers with low-cost energy.\" \n\nThe decision by Ebico to end its partnership with its former supply partner SSE plc was due to SSE deciding to close Ebico's EquiGas/EquiPower tariffs to new sales.\n\nThe partnership was welcomed by a number of prominent politicians including Jesse Norman MP - Minister for Energy and Industry, Dr. Alan Whitehead MP - Shadow Minister for Energy and Climate Change and Callum McCaig MP - SNP Spokesperson on Energy.\n\n"}
{"id": "14696791", "url": "https://en.wikipedia.org/wiki?curid=14696791", "title": "Rote Jahne Solar Park", "text": "Rote Jahne Solar Park\n\nThe Rote Jahne Solar Park in Saxony, Germany, has a total output capacity of 6 megawatts peak (MWp). Built at a former military airfield, it has 90,000 First Solar thin-film modules covering approximately 6.7 hectares, and produces approximately 5.7 million kilowatt-hours (kW·h) of solar electricity every year. The project cost around Euro 21 million or US $28 million.\n\n"}
{"id": "31573088", "url": "https://en.wikipedia.org/wiki?curid=31573088", "title": "Silvology", "text": "Silvology\n\nSilvology (Latin, silva or sylva, \"forests and woods\"; and , \"-logia\", \"\"science of\" or \"study of\"\") is the biological science of studying forests and woods, incorporating the understanding of natural forest ecosystems, and the effects and development of silvicultural practices. The term compliments silviculture, which deals with the art and practice of forest management.\n\nSilvology is seen as a single science for forestry and was first used by Roeloff Oldeman. It integrates the study of forests and forest ecology, dealing with single tree autecology and natural forest ecology.\n\n\n\n\n"}
{"id": "14694019", "url": "https://en.wikipedia.org/wiki?curid=14694019", "title": "Sisante Wind Farm", "text": "Sisante Wind Farm\n\nSisante Wind Farm is a 196 megawatt wind power station located in Sisante, province of Cuenca, Spain.\n\n"}
{"id": "8250382", "url": "https://en.wikipedia.org/wiki?curid=8250382", "title": "Sludge (film)", "text": "Sludge (film)\n\nSludge is a 2005 documentary film by Appalshop filmmaker Robert Salyer chronicling the Martin County Sludge Spill that was an accident that occurred after midnight on October 11, 2000 when a coal sludge impoundment in Martin County, Kentucky, broke through an underground mine below, propelling 306 million gallons of sludge down two tributaries of the Tug Fork River. The movie documents the continuing story of the Martin County disaster, the resulting federal investigation, and the looming threat of coal sludge ponds throughout the coalfield region.\n\nIn the United States today, coal is the largest single source of fuel for energy production. Annually, the country mines over a billion tons of coal. Coal waste is a consequence of this consumption; the Mine Safety and Health Administration has estimated that there are over 235 sludge ponds throughout the region with the potential to break into an underground mine, as the Martin County pond did in 2000.\n\n\n"}
{"id": "20236523", "url": "https://en.wikipedia.org/wiki?curid=20236523", "title": "Sponge iron reaction", "text": "Sponge iron reaction\n\nThe sponge iron reaction (SIR) is a chemical process based on redox cycling of an iron-based contact mass, the first cycle is a conversion step between iron metal (Fe) and wuestite (FeO), the second cycle is a conversion step between wuestite (FeO) and magnetite (FeO). In application, the SIT is used in the reformer sponge iron cycle (RESC) in combination with a steam reforming unit.\n\nThe process has two modes, a reduction mode and an oxidation mode.\n\n + ↔ 3 + \n\nThe reformer sponge iron cycle is a two step cycle to produce hydrogen from hydrocarbon fuels based SIR and steam.\n\nIn the first step the hydrocarbon fuel is reformed to syngas in the reformer which is then used to reduce the iron oxide (magnetite—FeO) to iron (wüstite—FeO), in the second step steam is utilized to re-oxidise the iron into magnetite and hydrogen. The iron oxide pellets are placed in a pelletbed and have a service life of several thousand redox cycles.\n\n\n"}
{"id": "49446859", "url": "https://en.wikipedia.org/wiki?curid=49446859", "title": "Union of the European Lubricants' Industry", "text": "Union of the European Lubricants' Industry\n\nThe Union of the European Lubricants' Industry (UEIL) is a Brussels-based trade association representing lubricants' companies at European level.\n"}
{"id": "947310", "url": "https://en.wikipedia.org/wiki?curid=947310", "title": "United States Department of Energy national laboratories", "text": "United States Department of Energy national laboratories\n\nThe United States Department of Energy National Laboratories and Technology Centers are a system of facilities and laboratories overseen by the United States Department of Energy (DOE) for the purpose of advancing science and technology to fulfill the DOE mission. Sixteen of the seventeen DOE national laboratories are federally funded research and development centers administered, managed, operated and staffed by private-sector organizations under management and operating (M&O) contract with DOE.\n\nThe system of centralized national laboratories grew out of the massive scientific endeavors of World War II, in which new technologies such as radar, the computer, the proximity fuze, and the atomic bomb proved decisive for the Allied victory. Though the United States government had begun seriously investing in scientific research for national security since World War I, it was only in late 1930s and 1940s that monumental amounts of resources were committed or coordinated to wartime scientific problems, under the auspices first of the National Defense Research Committee, and later the Office of Scientific Research and Development, organized and administered by the MIT engineer Vannevar Bush.\n\nDuring the second world war, centralized sites such as the Radiation Laboratory at MIT and Ernest O. Lawrence's laboratory at the University of California, Berkeley allowed for a large number of expert scientists to collaborate towards defined goals as never before, and with virtually unlimited government resources at their disposal.\n\nIn the course of the war, the Allied nuclear effort, the Manhattan Project, created several secret sites for the purpose of bomb research and material development, including a laboratory in the mountains of New Mexico directed by Robert Oppenheimer (Los Alamos), and sites at Hanford, Washington and Oak Ridge, Tennessee. Hanford and Oak Ridge were administered by private companies, and Los Alamos was administered by a public university (the University of California). Additional success was had at the University of Chicago in reactor research, leading to the creation of Argonne National Laboratory outside Chicago, and at other academic institutions spread across the country.\n\nAfter the war and its scientific successes, the newly created Atomic Energy Commission took over the future of the wartime laboratories, extending their lives indefinitely (they were originally thought of as temporary creations). Funding and infrastructure were secured to sponsor other \"national laboratories\" for both classified and basic research, especially in physics, with each national laboratory centered around one or many expensive machines (such as particle accelerators or nuclear reactors). \n\nMost national laboratories maintained staffs of local researchers as well as allowing for visiting researchers to use their equipment, though priority to local or visiting researchers often varied from lab to lab. With their centralization of resources (both monetary and intellectual), the national labs serve as an exemplar for Big Science.\n\nElements of both competition and cooperation were encouraged in the laboratories. Often two laboratories with similar missions were created (such as Lawrence Livermore which was designed to compete with Los Alamos) with the hope that competition over funding would create a culture of high quality work. Laboratories which did not have overlapping missions would cooperate with each other (for example, Lawrence Livermore would cooperate with the Lawrence Berkeley Laboratory, which itself was often in competition with Brookhaven National Laboratory). The idea of regional laboratories to work with local universities for nuclear development originated with Arthur Compton and Charles Allen Thomas, though Leslie Groves later claimed the idea as his own. \n\nThe national laboratory system, administered first by the Atomic Energy Commission, then the Energy Research and Development Administration, and currently the Department of Energy, is one of the largest (if not the largest) scientific research systems in the world. The DOE provides more than 40% of the total national funding for physics, chemistry, materials science, and other areas of the physical sciences. Many are locally managed by private companies, while others are managed by academic universities, and as a system they form one of the overarching and far-reaching components in what is known as the \"iron triangle\" of military, academia, and industry.\n\nThe United States Department of Energy currently operates seventeen national laboratories:\n\n<nowiki>*</nowiki> GOCO (Government-owned, Contractor-operated)\n<nowiki>**</nowiki> GOGO (Government-owned, Government-operated)\n\n\n\n\n"}
{"id": "32313", "url": "https://en.wikipedia.org/wiki?curid=32313", "title": "Unobtainium", "text": "Unobtainium\n\nIn fiction, engineering, and thought experiments, unobtainium is any fictional, extremely rare, costly, or impossible material, or (less commonly) device needed to fulfill a given design for a given application. The properties of any particular unobtainium depend on the intended use. For example, a pulley made of unobtainium might be massless and frictionless; however, if used in a nuclear rocket, unobtainium might be light, strong at high temperatures, and resistant to radiation damage. The concept of unobtainium is often applied flippantly or humorously. For instance, unobtainium is described as being stronger than steel, and lighter than helium.\n\nThe word \"unobtainium\" derives humorously from \"unobtainable\" with the suffix \"-ium\", the conventional designation for a chemical element. It pre-dates the similar-sounding IUPAC systematic element names, such as ununennium. An alternative spelling, unobtanium is sometimes used (for example, for the crypto-currency Unobtanium), based on the spelling of metals such as titanium.\n\nSince the late 1950s, aerospace engineers have used the term \"unobtainium\" when referring to unusual or costly materials, or when theoretically considering a material perfect for their needs in all respects, except that it does not exist. By the 1990s, the term was in wide use, even in formal engineering papers such as \"Towards unobtainium <nowiki>[</nowiki>new composite materials for space applications<nowiki>]</nowiki>.\"\nThe word \"unobtainium\" may well have been coined in the aerospace industry to refer to materials capable of withstanding the extreme temperatures expected in re-entry. Aerospace engineers are frequently tempted to design aircraft which require parts with strength or resilience beyond that of currently available materials.\n\nLater, \"unobtainium\" became an engineering term for practical materials that really exist, but are difficult to get. For example, during the development of the SR-71 Blackbird spy plane, Lockheed engineers at the \"Skunk Works\" under Clarence \"Kelly\" Johnson used \"unobtainium\" as a dysphemism for \"titanium.\" Titanium allowed a higher strength-to-weight ratio at the high temperatures the Blackbird would reach, but the Soviet Union controlled its supply and was trying to deprive the US armed forces of this resource.\n\nIn the 1970s, driver and engineer Mark Donohue claimed unobtainium was used in the construction of Penske race cars.\n\nBy 2010, the term had diffused beyond engineering, and now can appear in the headlines of mainstream newspapers, especially to describe the commercially useful rare earth elements (particularly terbium, erbium, dysprosium, yttrium, and neodymium). These are essential to the performance of consumer electronics and green technology, but the projected demand for them so outstrips their current supply that they are called \"unobtainiums\" within the ore industry and by commentators on the US Congressional hearings into the \"supply security\" of rare-earths.\n\n\"Unobtainium\" has come to be used as a synonym for \"unobtainable\" among people who are neither science fiction fans nor engineers to denote an object that actually exists, but which is very hard to obtain either because of high price (sometimes referred to as \"unaffordium\") or limited availability. It usually refers to a very high-end and desirable product; for instance, in the mountain biking community, \"These titanium hubs are unobtainium, man!\" Old-car enthusiasts use \"unobtainium\" to describe parts that are vanishingly rare or no longer available.\n\nIn maintaining old equipment, \"unobtainium\" refers to replacement parts that are no longer made, such as parts for reel-to-reel audio-tape recorders or rare vacuum tubes that cost more than the equipment they are fitted to (especially true of certain vacuum tubes, such as the 1L6, used almost exclusively in American battery-powered shortwave radios or the WD-11 used in certain early 1920s radios). Similarly, parts for classic & vintage Ferraris are made by a company actually named Unobtainium Supply Co.\n\nThere have been repeated attempts to attribute the name to a real material. Because of the long-standing usage of the term \"unobtainium\" within the space elevator research community to describe a material with the necessary characteristics, LiftPort Group President Michael Laine has advocated assigning the term as the generic name for cables woven of carbon nanotube fibers, which seem to satisfy the requirements for this application. Since he claimed that sufficiently long nanotube cables will be prohibitively expensive to develop without inexpensive access to microgravity, these cables would still be close enough to unobtainable to meet the definition. However, this usage does not seem to have become widespread. The eyewear and fashion wear company Oakley, Inc. also frequently denotes the material used for many of their eyeglass nosepieces and earpieces, which has the unusual property of increasing tackiness and thus grip when wet, as unobtanium.\n\nFrequent Sunday night/Monday morning host of \"Coast to Coast AM\" George Knapp usually opens his show mentioning unobtainium. As a play on the word, \"Obtainium\" is an album by Skeleton Key, released in 2002 by Ipecac Recordings.\n\n\"Unobtainium\" can refer to any substance needed to build some device critical to the plot of a science fiction story but which does not exist in the universe as we know it. A hull material that gets stronger by absorbing and converting heat and pressure into energy in the film \"The Core\" (2003) was nicknamed \"unobtainium\", but the concept under different names can be seen in the anti-gravity material cavorite from H. G. Wells' 1901 novel \"The First Men in the Moon\", as well as the super-strong material scrith from Larry Niven's novel \"Ringworld\", which requires a tensile strength (i.e. chemical bonds) on the order of the force binding an atomic nucleus.\n\nThe term was used in James Cameron's 2009 movie \"Avatar\", as a substance that was named (in the film's dialog) \"unobtanium\" (note the slightly different spelling). In the film, it was mined on the fictional moon Pandora and was a room-temperature superconductor.\n\n\"Unobtainium\" can also refer to any rare but desirable material used to motivate a conflict over its possession, making it a MacGuffin (it appears in the story as something to obtain, not something that is significantly used).\n\n\"Unobtainium\" can be used in a disparaging context (e.g., \"That idea is silly; you'd need unobtainium wires to hold the planet up!\") or a hypothetical one (\"If one were to build an unobtainium shell around a black hole's event horizon, what would happen to the material piling up on it?\").\n\nThe term handwavium (suggesting handwaving) is another term for this hypothetical material, as are buzzwordium, impossibrium, hardtofindium, and less commonly, phlebotinum.\n\nThe term eludium (also spelled with variants such as illudium) has been used to describe a material which has \"eluded\" attempts to develop it. This was mentioned in several Looney Tunes cartoons, where Marvin the Martian tried (unsuccessfully) to use his \"Eludium Q-36 Explosive Space Modulator\" to blow up the Earth.\n\nAnother largely synonymous term is wishalloy, although the sense is often subtly different in that a wishalloy usually does not exist at all, whereas unobtainium may merely be unavailable.\n\nA similar conceptual material in alchemy is the philosopher's stone, a mythical substance with the ability to turn lead into gold, or bestow immortality and youth. While the search to find such a substance was not successful, it did lead to discovery of a new element: phosphorus.\n\nAnother closely related term is quantonium (a portmanteau of quantum and plutonium), the rare element that serves as the MacGuffin in the film Monsters vs Aliens.\n\n\n"}
{"id": "2593019", "url": "https://en.wikipedia.org/wiki?curid=2593019", "title": "Uranyl nitrate", "text": "Uranyl nitrate\n\nUranyl nitrate (UO(NO)) is a water soluble yellow uranium salt. The yellow-green crystals of dioxouranium nitrate hexahydrate are triboluminescent.\n\nUranyl nitrate can be prepared by reaction of uranium salts with nitric acid. It is soluble in water, ethanol, acetone, and ether, but not in benzene, toluene, or chloroform.\n\nDuring the first half of the 19th century, many photosensitive metal salts had been identified as candidates for photographic processes, among them uranyl nitrate. The prints thus produced were alternately referred to as uranium prints, urbanities, or more commonly uranotypes.\nThe first uranium printing processes were invented by a Scotsman, J. Charles Burnett, between 1855 and 1857, and used this compound as the sensitive salt. Burnett, authored an 1858 article comparing \"Printing by the Salts of the Uranic and Ferric Oxides\"\nThe basis for the process lies in the ability of the uranyl ion to pick up two electrons and reduce to the lower oxidation state of uranium(IV) under ultraviolet light.\nUranotypes can vary from print to print from a more neutral, brown russet to strong Bartolozzi red, with a very long tone grade. Surviving prints are slightly radioactive, a property which serves as a means of non-destructively identifying them.\nSeveral other more elaborate photographic processes employing the compound sprang up and vanished throughout the second half of the century with names like Wothlytype, Mercuro-Uranotype and the Auro-Uranium process. Uranium papers were manufactured commercially at least until the end of the 19th century, vanishing in the face of the superior sensitivity and practical advantages of the silver halides. Nevertheless, between the 1930s through the 1950s Kodak Books still described a uranium toner (Kodak T-9) using uranium nitrate hexahydrate. Some alternative process photographers including artists Blake Ferris and Robert Schramm continue to make uranotype prints today.\n\nAlong with uranyl acetate it is used as a negative stain for viruses in electron microscopy; in tissue samples it stabilizes nucleic acids and cell membranes.\n\nUranyl nitrate was used to fuel Aqueous Homogeneous Reactors in the 1950s as an alternative to the more corrosive uranyl sulfate. However, research focus was on heterogeneous reactor designs and the experiments were abandoned.\n\nUranyl nitrate is important for nuclear reprocessing; it is the compound of uranium that results from dissolving the decladded spent nuclear fuel rods or yellowcake in nitric acid, for further separation and preparation of uranium hexafluoride for isotope separation for preparing of enriched uranium.\n\nUranyl nitrate is an oxidizing and highly toxic compound. When ingested, it causes severe renal insufficiency and acute tubular necrosis and is a lymphocyte mitogen. Target organs include the kidneys, liver, lungs and brain. It also represents a severe fire and explosion risk when heated or subjected to shock in contact with oxidizable substances.\n\n"}
{"id": "7299399", "url": "https://en.wikipedia.org/wiki?curid=7299399", "title": "Waste Implementation Programme", "text": "Waste Implementation Programme\n\nThe Waste Implementation Programme (WIP) is the UK Government's response to the package of strategic measures recommended by the Strategy Unit \"Waste Not, Want Not\" report published in 2002. The WIP is the route map of the Department for Environment, Food and Rural Affairs, aimed at delivering the action required to meet the UK's legally binding targets under Article Five of the EU Landfill Directive related to reducing levels of biodegradable waste that are landfilled.\n\nThe UK's targets are:\n\n\n"}
{"id": "13351034", "url": "https://en.wikipedia.org/wiki?curid=13351034", "title": "Werner Kuhn", "text": "Werner Kuhn\n\nWerner Kuhn (February 6, 1899 – August 27, 1963) was a Swiss physical chemist who developed the first model of the viscosity of polymer solutions using statistical mechanics. He is known for being the first to apply Boltzmann's entropy formula:\n\nto the modeling of rubber molecules, i.e. the \"rubber band entropy model\", molecules which he imagined as chains of \"N\" independently oriented links of length \"b\" with an end-to-end distance of \"r\". This model, which resulted in the derivation of the thermal equation of state of rubber, has since been extrapolated to the entropic modeling of proteins and other conformational polymer chained molecules attached to a surface.\n\nKuhn received a degree in chemical engineering at the Eidgenössische Technische Hochschule (ETH, Federal Institute of Technology), in Zürich, and later a doctorate (1923) in physical chemistry. He was appointed professor of physical chemistry at the University of Kiel (1936–39) and then returned to Switzerland as director of the Physico-Chemical Institute of the University of Basel (1939–63), where he also served as rector (1955–56). \n\nIn a 1951 lecture along with his student V.B. Hargitay, he was the first to hypothesize the countercurrent multiplier mechanism in the mammalian kidney, later to be discovered in many other similar biological systems.\n\nKuhn length\n\n"}
{"id": "644459", "url": "https://en.wikipedia.org/wiki?curid=644459", "title": "WindShare", "text": "WindShare\n\nWindShare is a for-profit wind power co-operative that was officially launched in February 2002 in Toronto, Ontario, Canada. It was created by the non-profit Toronto Renewable Energy Co-operative (TREC) which was incorporated in 1998. TREC continues to exist as a separate non-profit entity.\n\nWindShare's ExPlace wind turbine was erected on December 18, 2002, on the grounds of Exhibition Place, in Toronto. It was the first wind turbine installed in a major North American urban city centre. and the first community-owned wind power project in Ontario.\n\nThe tall ExPlace wind turbine is co-owned by the \"WindShare\" co-operative and Toronto Hydro, and annually adds an average of 1000 MWh of electricity to the city's main power grid.\n\nWindShare and its parent, the Toronto Renewable Energy Cooperative (TREC), have plans for more wind turbines. As of March, 2010 these plans are called \"The Lakewind Project.\" (See below)\n\n\n\nLakewind Power Co-operative Inc. is a sustainable energy development entity consisting of two Ontario co-operatives: Countryside Energy Co-operative, and TREC-Windshare 2 Co-operative.\n\nThe Ontario Power Authority's Feed-In Tariff (FIT) program is now in place as the most generous renewable energy support program in North America (See Green Energy Act 2009, and Ontario Power Authority \"Standard Offer Program\" (SOP) for Wind Energy Projects ). TREC is moving ahead with ambitious generation development plans. Building on the experience from the WindShare co-operative's Exhibition Place wind turbine project, TREC has submitted a FIT contract application for a 20-megawatt (MW) wind farm project called Lakewind. TREC has incorporated Lakewind Power Co-operative Inc., a for-profit co-operative of Ontarians that will develop and own the project near the village of Bervie, just east of Kincardine, Ontario. The Lakewind project will be the largest co-operatively owned, wind power project in Canada and pending a successful FIT application, is expected to be generating power in the spring of 2012.\n\nIf awarded a FIT contract, WindShare hoped to be looking for investors by the summer of 2010.\n\nOntario introduced a feed-in tariff in 2006, and revised it in 2009, which in a draft proposal increases from 42¢/kWh to 80.2¢/kWh for micro-scale (≤10 kW) grid-tied photovoltaic projects. Ontario's FIT program also includes a tariff schedule for larger projects up to and including 10MW solar farms at a reduced rate. (See Ontario Power Authority \"Standard Offer Program\" (SOP) for Wind Energy Projects \nand Ontario Power Authority Feed-in Tariff program for renewable energy)\n\n\n"}
