{"id": "47622643", "url": "https://en.wikipedia.org/wiki?curid=47622643", "title": "9-Hydroxyoctadecadienoic acid", "text": "9-Hydroxyoctadecadienoic acid\n\n9-Hydroxyoctadecadienoic acid (9-hydroxy-10(\"E\"),12(\"Z\")-octadecadienoic acid or 9-HODE) has been used in the literature to designate either or both of two stereoisomer metabolites of the essential fatty acid, linoleic acid: 9(\"S\")-hydroxy-10(\"E\"),12(\"Z\")-octadecadienoic acid (9(\"S\")-HODE) and 9(\"R\")-hydroxy-10(\"E\"),12(\"Z\")-octadecadienoic acid (9(\"R\")-HODE); these two metabolites differ in having their hydroxy residues in the \"S\" or \"R\" configurations, respectively. The accompanying figure gives the structure for 9(\"S\")-HETE. Two other 9-hydroxy linoleic acid derivatives occur in nature, the 10\"E\",12\"E\" isomers of 9(\"S\")-HODE and 9\"(R\")-HODE viz., 9(\"S\")-hydroxy-10\"E\",12\"E\"-octadecadienoic acid (9(\"S\")-\"EE\"-HODE) and 9(\"R\")-hydroxy-10\"E\",12\"E\"-octadecadienoic acid (13(\"R\")-\"EE\"-HODE); these two derivatives have their double bond at carbon 12 in the \"E\" or trans configuration as opposed to the \"Z\" or cis configuration. The four 9-HODE isomers, particularly under conditions of oxidative stress, may form together in cells and tissues; they have overlapping but not identical biological activities and significances. Because many studies have not distinguished between the \"S\" and \"R\" stereoisomers and, particularly in identifying tissue levels, the two \"EE\" isomers, 9-HODE is used here when the isomer studied is unclear.\n\nA similar set of 13-Hydroxyoctadecadienoic acid (13-HODE) metabolites (13(S)-HODE), 13(R)-HODE, 13(S)-EE-HODE), and 13(R)-EE-HODE) also occurs naturally and, again particularly under conditions of oxidative stress, may form concurrently with 9-HODEs; these 13-HODEs also have overlapping and complementary but not identical activities with the 9-HODEs. Some recent studies measuring HODE levels in tissue have lumped the four 9-HODEs and four 13-HODEs together to report only on total HODEs (tHODEs): tHODEs have been proposed to be markers for certain human disease. Other recent studies have lumped together the 9-(\"S\"), 9(\"R\"), 13 (\"S\")-, and 13(\"R\")-HODE along with the two ketone metabolites of these HODEs, 9-oxoODE (9-oxo-10(\"E\"),12(\"Z\")-octadecadienoic acid) and 13-oxoODE, reporting only on total OXLAMs (oxidized linoleic acid metabolites); the OXLAMs have been implicated in working together to signal for pain perception.\n\nThe enzymes cyclooxygenase 1 (COX-1) and cyclooxygenase 2 (COX-2), which are best known for metabolizing arachidonic acid to prostaglandins, are also able to metabolize linoleic acid predominantly to 9(\"R\")-hydroperoxy-10(\"E\"),12(\"Z\")-octadecadienoic acid (i.e. 9(\"R\")-HpODE)-HODE) and lesser amounts of 9(\"S\")-hydroperoxy-10(\"E\"),12(\"Z\")-octadecadienoic acid (i.e. 9(\"S\")-HpODE); in cells and tissues, the two hydroperoxy metabolites are rapidly reduce to 9(\"R\")-HODE and 9(\"S\")-HODE, respectively. COX-2 exhibits a greater preference for linoleic acid than does Cox-1 and is therefore credited with producing most of these products in cells expressing both COX enzymes. The COXs also metabolize linoleic acid to 13(\"S\")-hydroperoxy-octadecadionoic acid (13(\"S\")-HpODE and lesser amounts of 13(\"R\")-hydroperoxy-octadecadienoic acid (13(\"R\")-HpODE, which are then rapidly reduced to 13(\"S\")-HODE) and 13(\"R\")-HODE; the two enzymes therefore metabolize linoleic acid predominantly to the \"R\" stereoisomer of 9-HODE and (\"S\") stereoisomer of 13-HODE with the 13-HODE products predominating over the 9-HODE products.\n\nCytochrome P450 microsomal enzymes metabolize linoleic acid to a mixture of 9(\"S\")-HpODE and 9(\"R\")-HpODE which are subsequently reduced to their corresponding hydroxy products; these reactions produce racemic mixtures in which the \"R\" stereoisomer predominates, for instance by a \"R\"/\"S\" ratio of 80%/20% in human liver microsomes. In cells and tissues, the cytochrome enzymes concurrently metabolize linoleic acid to 13(\"S\")-HpODE and 13(\"R\")-HpODE which are reduced to 13(\"S\")-HODE and 13(\"R\")-HODE in an \"R\"/\"S\" ratio similar to than of the 9-HODES, i.e. 80%/20%.\n\nOxidative stress in cells and tissues produces Free radical-induced and singlet oxygen-induced oxidations of linoleic acid to generate the various racemic mixtures of 9-HpODE and 9-HODE in non-enzymatic reactions that produce, or are suspected but not proven to produce, approximately equal amounts of their \"S\" and \"R\" stereoisomers. These oxidations are credited with being the major contributors to 9-HODE and 13-HODE isomer production in tissues undergoing oxidative stress such as occurs in any tissue suffering inadequate blood flow, inflammation, or other serious insult, in liver steatohepatitis, in the atheroma plaques of cardiovascular disease, in nerve tissues of neurodegenerative diseases, and in the various tissues compromised by diabetes (see oxidative stress). Free radical oxidation of linoleic acid produces racemic mixtures of 9-HODE and 9-EE-HODE; singlet oxygen attack on linoleic acid produces (presumably) racemic mixtures of 9-HODE, 10-hydroxy-8\"E\",12\"Z\"-octadecadienoic acid, and 12-hydroxy-9\"Z\"-13-\"E\"-octadecadienoic acid. Since free radical-induced and singlet oxygen-induced oxidations of linoleic acid produce a similar set of 13-HODE metabolites (see 13-Hydroxyoctadecadienoic acid), since both free radicals and singlet oxygen attack not only free linoleic acid but also linoleic acid bound to phospholipids, glycerides, cholesterol, and other lipids, and since free radical and singlet oxygen reactions may occur together, oxygen-stressed tissues often contain an array of free and lipid-bound 9-HODE and 13-HODE products. For example, laboratory studies find that 9-HODE and 9-EE-HODE (along with their 13-HODE counterparts) are found in the phospholipid and cholesterol components of low density lipoproteins that have been oxidized by human monocytes; the reaction appears due to the in situ free radical- and/or superoxide-induced oxidation of the lipoproteins.\n\nThe murine homolog of human 15(\"S\")-lipoxygenase-2 (ALOX15B), 8(\"S\")-lipoxygenase, while preferring arachidonic acid over linoleic acid, metabolizes linoleic acid predominantly to (9(\"S\")-HpODE, which in tissues and cells is rapidly reduced to 9(\"S\")-HODE. However, ALOX15B, similar to human 15-lipoxygenase-1 (ALOX15), metabolizes linoleic acid to 13(\"S\")-HODE but not to 9(\"S\")-HODEs.\n\nLike most unsaturated fatty acids, the 9-HODEs formed in cells are incorporated into cellular phospholipids principally at the sn-2 position of the phospholipid (see Phospholipase A2); since, however, the linoleic acid bound to cellular phospholipids is susceptible to non-enzymatic peroxidation and free radical attack, the 9-HODEs in cellular phospholipids may also derive more directly from in situ oxidation. 9-HODE esterified to the sn-2 position of phosphatidylserine is subject to be released as free 9-HODE by the action of cytosolic (see phospholipase A2 section on cPLA2) and therefore may serve as a storage pool that is mobilized by cell stimulation.\n\n9-HODE may be further metabolized to 9-oxo-10(\"E\"),12(\"Z\")-octadecadienoic acid (9-oxoODE or 9-oxo-ODE), possibly by the same hydroxy fatty acid dehydrogenase which metabolizes other hydroxy fatty acids, such as 13-HODE, to their oxo derivatives.\n\n9-HODE, 9-oxoODE, and 9-EE-HODE (along with their 13-HODE counterparts) directly activate peroxisome proliferator-activated receptor gamma (PPARγ). This activation appears responsible for the ability of 13-HODE (and 9-HODE) to induce the transcription of PPARγ-inducible genes in human monocytes as well as to stimulate the maturation of these cells to macrophages. 13(\"S\")-HODE (and 9(\"S\")-HODE) also stimulate the activation of peroxisome proliferator-activated receptor beta (PPARβ) in a model cell system; 13-HODE (and 9-HODE) are also proposed to contribute to the ability of oxidized low-density lipoprotein (LDL) to activate PPARβl: LDL containing phospholipid-bound 13-HODE (and 9-HODE) is taken up by the cell and then acted on by phospholipases to release the HODEs which in turn directly activate PPARβl.\n\n13(\"S\")-HODE, 13(\"R\")-HODE and 13-oxoODE, along with their 9-HODE counterparts, also act on cells through TRPV1. TRPV1 is the transient receptor potential cation channel subfamily V member 1 receptor (also termed capsaicin receptor or vanilloid receptor 1). These 6 HODEs, dubbed, oxidized linoleic acid metabolites (OXLAMs), individually but also and possibly to a greater extent when acting together, stimulate TRPV1-dependent responses in rodent neurons, rodent and human bronchial epithelial cells, and in model cells made to express rodent or human TRPV1. This stimulation appears due to a direct interaction of these agents on TRPV1 although reports disagree on the potencies of the (OXLAMs) with, for example, the most potent OXLAM, 9(\"S\")-HODE, requiring at least 10 micromoles/liter or a more physiological concentration of 10 nanomoles/liter to activate TRPV1 in rodent neurons. The OXLAM-TRPV1 interaction is credited with mediating pain sensation in rodents (see below).\n\n9(\"S\")-HODE and with progressively lesser potencies 9(\"S\")-HpODE, a racemic mixture of 9-HODE, 13(\"S\")-HpODE, and 13(\"S\")-HODE directly activate human (but not mouse) GPR132 (i.e. G protein coupled receptor 132 or G2A) in Chinese hamster ovary cells made to express these receptors; 9(\"S\")-HODE was also a more potent stimulator of human G2A than a series of mono-hydroxy arachidonic acid metabolites. GPR132 was initially described as a pH sensing receptor; the role(s) of 9-HODEs as well as other linoleic and arachidonic acid metabolites in activating GPR132 under the physiological and pathological conditions in which it is implicated to be involved(see (see GPR132 for a listing of these conditions) have not yet been determined. This determination, as it might apply to humans, is made difficult by the inability of these HODEs to activate rodent GPR132 and therefore to be analyzed in rodent models.\n\nVarious measurements of tissue and blood levels of reactive oxygen species have been used as markers of diseases in which these species are generated and may contribute to tissue injury and systemic disturbances; examples of such diseases include a wide range of neurological, cardiovascular, infectious, autoimmune, and genetic diseases (see oxidative stress). HODEs measurements have been evaluated as markers for many of these oxygen stress-related diseases. These measurements commonly use saponification methods to release HODEs bound by acylation to other molecules; they therefore measure not only free HODEs but also HODEs acylated to phospholipids, glycerides, cholesterol, and other lipids.\n\nStudies find that 1) 9(\"S\")-HODE (and 13(\"S\")-HODE) levels are elevated in the plasma of older patients with early-stage cataracts compared to non-cataract subjects; 2) 9-HODE (and 13-HODE) are increased in the low density lipoproteins of patients with rheumatoid arthritis compared to healthy subjects as well as in the destructive but not normal bone tissue of the rheumatoid arthritic patients; 3) total HODEs (includes 9-HODE and 13-HODE stereoisomers) are higher in the plasma and liver of patients with hepatitis C and hepatitis B chronic viral infections as well as in the plasma and red blood cells of patients with Alzheimer's disease compared to healthy subjects; 4) 9-HODE and 9-oxoODE (as well as 13-HODE and 13-oxo-ODE) levels were elevated in the serum and/or pancreatic secretions of patients with pancreatitis compared to control subjects; 5) levels of the hydroperoxy precursors to 9-HODE and 13-HODE are elevated in the plasma and/or red blood cells of patients with Alzheimer's disease, atherosclerosis, diabetes, diabetic nephritis, non-alcoholic steatohepatitis, and alcoholic steatohepatitis compared to healthy subjects. These studies suggest that high levels of the HODEs may be useful to indicate the presence and progression of the cited diseases. Since, however, the absolute values of HODEs found in different studies vary greatly, since HODE levels vary with dietary linoleic acid intake, since HODEs may form during the processing of tissues, and since abnormal HODE levels are not linked to a specific disease, the use of these metabolites as markers has not attained clinical usefulness. HODE markers may find usefulness as markers of specific disease, type of disease, and/or progression of disease when combined with other disease markers.\n\nSome of the studies cited above have suggested that 9-HODEs, 13-HODEs, their hydroperoxy counterparts, and/or their oxo counterparts contribute mechanistically to these oxidative stress-related diseases. That is, the free radical oxidation of linoleic acid makes these products which then proceed to contribute to the tissue injury, DNA damage, and/or systemic dysfunctions that characterize the diseases. Furthermore, certain of these HODE-related products may serve as signals to activate pathways that combat the reactive oxygen species and in this and other ways the oxidative stress. It remains unclear whether or not the HODEs and their counterparts promote, dampen, or merely reflect oxidative stress-related diseases.\n\n9(\"S\")-HODE, 9(\"R\")-HODE, and 9-oxoODE, along with the other OXLAMs, appear to act through the TRPV1 receptor (see above section on Direct actions) mediate the perception of acute and chronic pain induced by heat, UV light, and inflammation in the skin of rodents. These studies propose that the OXLAM-TRPV1 circuit (with 9(\"S\")-HODE being the most potent TRPV1-activating OXLAM) similarly contributes to the perception of in humans.\n\n9-HODEs, 13-HODEs, and low density lipoprotein which has been oxidized so that it contains HODEs stimulate the expression of interleukin 1β mRNA in and its extracellular release from human peripheral blood monocyte-derived macrophages; interleukin 1β is implicated in the proliferation of smooth muscle cells that occurs in atherosclerosis and contributes to blood vessel narrowing.\n"}
{"id": "39136", "url": "https://en.wikipedia.org/wiki?curid=39136", "title": "Accelerating expansion of the universe", "text": "Accelerating expansion of the universe\n\nThe accelerating expansion of the universe is the observation that the expansion of the universe is such that the velocity at which a distant galaxy is receding from the observer is continuously increasing with time.\n\nThe accelerated expansion was discovered in 1998, by two independent projects, the Supernova Cosmology Project and the High-Z Supernova Search Team, which both used distant type Ia supernovae to measure the acceleration. The idea was that as type 1a supernovae have almost the same intrinsic brightness (a standard candle), and since objects that are further away appear dimmer, we can use the observed brightness of these supernovae to measure the distance to them. The distance can then be compared to the supernovae's cosmological redshift, which measures how much the universe has expanded since the supernova occurred. The unexpected result was that objects in the universe are moving away from another at an accelerated rate. Cosmologists at the time expected that recession velocity would always be decelerating to the gravitational attraction of the matter in the universe. Three members of these two groups have subsequently been awarded Nobel Prizes for their discovery. Confirmatory evidence has been found in baryon acoustic oscillations, and in analyses of the clustering of galaxies.\n\nThe accelerated expansion of the universe is thought to have begun since the universe entered its dark-energy-dominated era roughly 5 billion years ago.\nWithin the framework of general relativity, an accelerated expansion can be accounted for by a positive value of the cosmological constant , equivalent to the presence of a positive vacuum energy, dubbed \"dark energy\". While there are alternative possible explanations, the description assuming dark energy (positive ) is used in the current standard model of cosmology, which also includes cold dark matter (CDM) and is known as the Lambda-CDM model.\n\nIn the decades since the detection of cosmic microwave background (CMB) in 1965, the Big Bang model has become the most accepted model explaining the evolution of our universe. The Friedmann equation defines how the energy in the universe drives its expansion.\n\nwhere the pressure is defined by the cosmological model chosen. (see explanatory models below)\n\nPhysicists at one time were so assured of the deceleration of the universe's expansion that they introduced a so-called deceleration parameter . Current observations point towards this deceleration parameter being negative.\n\nAccording to the theory of cosmic inflation, the very early universe underwent a period of very rapid, quasi-exponential expansion. While the time-scale for this period of expansion was far shorter than that of the current expansion, this was a period of accelerated expansion with some similarities to the current epoch.\n\nThe definition of \"accelerating expansion\" is that the second time derivative of the cosmic scale factor, formula_2, is positive, which implies that the deceleration parameter is negative. However, note this does not imply that the Hubble parameter is increasing with time. Since the Hubble parameter is defined as formula_3, it follows from the definitions that the derivative of the Hubble parameter is given by \n\nso the Hubble parameter is decreasing with time unless formula_5. Observations prefer formula_6, which implies that formula_2 is positive but formula_8 is negative. Essentially, this implies that the cosmic recession velocity of any one particular galaxy is increasing with time, but its velocity/distance ratio is still decreasing; thus different galaxies expanding across a sphere of fixed radius cross the sphere more slowly at later times.\n\nIt is seen from above that the case of \"zero acceleration/deceleration\" corresponds to formula_9 is a linear function of formula_10, formula_11, formula_12, and formula_13.\n\nTo learn about the rate of expansion of the universe we look at the magnitude-redshift relationship of astronomical objects using standard candles, or their distance-redshift relationship using standard rulers. We can also look at the growth of large-scale structure, and find that the observed values of the cosmological parameters are best described by models which include an accelerating expansion.\n\nThe first evidence for acceleration came from the observation of Type Ia supernovae, which are exploding white dwarfs that have exceeded their stability limit. Because they all have similar masses, their intrinsic luminosity is standardizable. Repeated imaging of selected areas of the sky is used to discover the supernovae, then follow-up observations give their peak brightness, which is converted into a quantity known as luminosity distance (see distance measures in cosmology for details). Spectral lines of their light can be used to determine their redshift.\n\nFor supernovae at redshift less than around 0.1, or light travel time less than 10 percent of the age of the universe, this gives a nearly linear distance–redshift relation due to Hubble's law. At larger distances, since the expansion rate of the universe has changed over time, the distance-redshift relation deviates from linearity, and this deviation depends on how the expansion rate has changed over time. The full calculation requires computer integration of the Friedmann equation, but a simple derivation can be given as follows: the redshift directly gives the cosmic scale factor at the time the supernova exploded.\n\nSo a supernova with a measured redshift implies the universe was  =  of its present size when the supernova exploded. In the standard accelerated expansion scenario the rate of expansion still decreases, but does so more slowly than the non-accelerated case. This means that in the accelerated case, the past rate of expansion is slower than it would be in the non-accelerated case. Thus in a universe with accelerated expansion, it takes a longer time to expand from two thirds its present size, compared to a non-accelerating universe with the same present-day value of the Hubble constant. This results in a larger light-travel time, larger distance and fainter supernovae, which corresponds to the actual observations. Adam Riess \"et al.\" found that \"the distances of the high-redshift SNe Ia were, on average, 10% to 15% farther than expected in a low mass density universe without a cosmological constant\". This means that the measured high-redshift distances were too large, compared to nearby ones, for a decelerating universe.\n\nIn the early universe before recombination and decoupling took place, photons and matter existed in a primordial plasma. Points of higher density in the photon-baryon plasma would contract, being compressed by gravity until the pressure became too large and they expanded again. This contraction and expansion created vibrations in the plasma analogous to sound waves. Since dark matter only interacts gravitationally it stayed at the centre of the sound wave, the origin of the original overdensity. When decoupling occurred, approximately 380,000 years after the Big Bang, photons separated from matter and were able to stream freely through the universe, creating the cosmic microwave background as we know it. This left shells of baryonic matter at a fixed radius from the overdensities of dark matter, a distance known as the sound horizon. As time passed and the universe expanded, it was at these anisotropies of matter density where galaxies started to form. So by looking at the distances at which galaxies at different redshifts tend to cluster, it is possible to determine a standard angular diameter distance and use that to compare to the distances predicted by different cosmological models.\n\nPeaks have been found in the correlation function (the probability that two galaxies will be a certain distance apart) at , indicating that this is the size of the sound horizon today, and by comparing this to the sound horizon at the time of decoupling (using the CMB), we can confirm the accelerated expansion of the universe.\n\nMeasuring the mass functions of galaxy clusters, which describe the number density of the clusters above a threshold mass, also provides evidence for dark energy . By comparing these mass functions at high and low redshifts to those predicted by different cosmological models, values for and are obtained which confirm a low matter density and a non zero amount of dark energy.\n\nGiven a cosmological model with certain values of the cosmological density parameters, it is possible to integrate the Friedmann equations and derive the age of the universe.\n\nBy comparing this to actual measured values of the cosmological parameters, we can confirm the validity of a model which is accelerating now, and had a slower expansion in the past.\n\nRecent discoveries of gravitational waves through LIGO and VIRGO not only confirmed Einstein's predictions but also opened a new window into the universe. These gravitational waves can work as sort of standard sirens to measure the expansion rate of the universe. Abbot et al. 2017 measured the Hubble constant value to be approximately 70 kilometres per second per megaparsec. The amplitudes of the strain 'h' is dependent on the masses of the objects causing waves, distances from observation point and gravitational waves detection frequencies. The associated distance measures are dependent on the cosmological parameters like the Hubble Constant for nearby objects and will be dependent on other cosmological parameters like the dark energy density, matter density, etc. for distant sources.\n\nThe most important property of dark energy is that it has negative pressure (repulsive action) which is distributed relatively homogeneously in space.\n\nwhere is the speed of light and is the energy density. Different theories of dark energy suggest different values of , with for cosmic acceleration (this leads to a positive value of in the acceleration equation above).\n\nThe simplest explanation for dark energy is that it is a cosmological constant or vacuum energy; in this case . This leads to the Lambda-CDM model, which has generally been known as the Standard Model of Cosmology from 2003 through the present, since it is the simplest model in good agreement with a variety of recent observations. Riess \"et al.\" found that their results from supernovae observations favoured expanding models with positive cosmological constant () and a current accelerated expansion ().\n\nCurrent observations allow the possibility of a cosmological model containing a dark energy component with equation of state . This phantom energy density would become infinite in finite time, causing such a huge gravitational repulsion that the universe would lose all structure and end in a Big Rip. For example, for and  =70 km·s·Mpc, the time remaining before the universe ends in this Big Rip is 22 billion years.\n\nThere are many alternative explanations for the accelerating universe. Some examples are quintessence, a proposed form of dark energy with a non-constant state equation, whose density decreases with time. Dark fluid is an alternative explanation for accelerating expansion which attempts to unite dark matter and dark energy into a single framework. Alternatively, some authors have argued that the accelerated expansion of the universe could be due to a repulsive gravitational interaction of antimatter or a deviation of the gravitational laws from general relativity. The measurement of the speed of gravity with the gravitational wave event GW170817 ruled out many modified gravity theories as alternative explanation to dark energy.\n\nAnother type of model, the backreaction conjecture, was proposed by cosmologist Syksy Räsänen: the rate of expansion is not homogenous, but we are in a region where expansion is faster than the background. Inhomogeneities in the early universe cause the formation of walls and bubbles, where the inside of a bubble has less matter than on average. According to general relativity, space is less curved than on the walls, and thus appears to have more volume and a higher expansion rate. In the denser regions, the expansion is slowed by a higher gravitational attraction. Therefore, the inward collapse of the denser regions looks the same as an accelerating expansion of the bubbles, leading us to conclude that the universe is undergoing an accelerated expansion. The benefit is that it does not require any new physics such as dark energy. Räsänen does not consider the model likely, but without any falsification, it must remain a possibility. It would require rather large density fluctuations (20%) to work.\n\nA final possibility is that dark energy is an illusion caused by some bias in measurements. For example, if we are located in an emptier-than-average region of space, the observed cosmic expansion rate could be mistaken for a variation in time, or acceleration. A different approach uses a cosmological extension of the equivalence principle to show how space might appear to be expanding more rapidly in the voids surrounding our local cluster. While weak, such effects considered cumulatively over billions of years could become significant, creating the illusion of cosmic acceleration, and making it appear as if we live in a Hubble bubble. Yet other possibilities are that the accelerated expansion of the universe is an illusion caused by the relative motion of us to the rest of the universe, or that the supernovae sample size used wasn't large enough.\n\nAs the universe expands, the density of radiation and ordinary dark matter declines more quickly than the density of dark energy (see equation of state) and, eventually, dark energy dominates. Specifically, when the scale of the universe doubles, the density of matter is reduced by a factor of 8, but the density of dark energy is nearly unchanged (it is exactly constant if the dark energy is a cosmological constant).\n\nIn models where dark energy is a cosmological constant, the universe will expand exponentially with time in the far future, coming closer and closer to a de Sitter spacetime. This will eventually lead to all evidence for the Big Bang disappearing, as the cosmic microwave background is redshifted to lower intensities and longer wavelengths. Eventually its frequency will be low enough that it will be absorbed by the interstellar medium, and so be screened from any observer within the galaxy. This will occur when the universe is less than 50 times its current age, leading to the end of cosmology as we know it as the distant universe turns dark.\n\nA constantly expanding universe with non-zero cosmological constant has mass density decreasing over time, to an undetermined point when zero matter density is reached. All matter (electrons, protons and neutrons) would ionize and disintegrate, with objects dissipating away.\n\nAlternatives for the ultimate fate of the universe include the Big Rip mentioned above, a Big Bounce, Big Freeze or Big Crunch.\n"}
{"id": "2855101", "url": "https://en.wikipedia.org/wiki?curid=2855101", "title": "Age class structure", "text": "Age class structure\n\nAge class structure in fisheries and wildlife management is a part of population assessment. Age class structures can be used to model many populations include trees and fish. This method can be used to predict the occurrence of forest fires within a forest population. Age can be determined by counting growth rings in fish scales, otoliths, cross-sections of fin spines for species with thick spines such as triggerfish, or teeth for a few species. Each method has its merits and drawbacks. Fish scales are easiest to obtain, but may be unreliable if scales have fallen off the fish and new ones grown in their places. Fin spines may be unreliable for the same reason, and most fish do not have spines of sufficient thickness for clear rings to be visible. Otoliths will have stayed with the fish throughout its life history, but obtaining them requires killing the fish. Also, otoliths often require more preparation before ageing can occur.\n\nAn example of using age class structure to learn about a population is a regular bell curve for the population of 1-5 year-old fish with a very low population for the 3-year-olds. An age class structure with gaps in population size like the one described earlier implies a bad spawning year 3 years ago in that species.\n\nOften fish in younger age class structures have very low numbers because they were small enough to slip through the sampling nets, and may in fact have a very healthy population.\n\n"}
{"id": "30091533", "url": "https://en.wikipedia.org/wiki?curid=30091533", "title": "Alpha Wind Casimcea Wind Farm", "text": "Alpha Wind Casimcea Wind Farm\n\nThe Wind Farm Casimcea is an under construction wind power project in Tulcea County, Romania. It will consist of an individual wind farm with 77 individual wind turbines with a nominal output of around 2,3-3  MW which will deliver up to 688 000 000 kWh of power, enough to power over 445,000 homes, with a capital investment required of approximately €300 million.\n"}
{"id": "1047047", "url": "https://en.wikipedia.org/wiki?curid=1047047", "title": "American Nuclear Society", "text": "American Nuclear Society\n\nThe American Nuclear Society (ANS) is an international, not-for-profit 501(c)(3) scientific and educational organization with a membership of approximately 11,000 scientists, engineers, educators, students, and other associate members. Approximately 900 members live outside the United States in 45 countries. There are 51 U.S. and nine non-U.S. local sections, 24 nuclear plant branches and 34 student sections. ANS members represent more than 1,750 corporations, educational institutions, and government agencies.\n\nThe ANS is a member of the International Nuclear Societies Council (INSC).\n\nThe society was founded on December 11, 1954. ANS has been a leader in the development of nuclear consensus standards since 1958. The main objective of ANS is to promote the advancement of science and engineering relating to the atomic nucleus. Other purposes are to integrate the many nuclear science and technology disciplines, encourage research, establish scholarships, disseminate information through publications and journals, inform the public about nuclear-related activities, hold meetings devoted to scientific and technical papers, and cooperate with government agencies, educational institutions, and other organizations having similar purposes. In 1955 Walter Zinn was elected as the first president of the ANS.\n\nANS is made up of 19 Professional Divisions, two work groups (WG) and one technical group (TG). The technical group is Young Members Group (YMG) and is for ANS members under age 36. YMG provides young professionals with opportunities to expand their technical knowledge and network with recognized authorities and the nuclear industry. It also nominates young professionals for awards and leadership opportunities. The ANS Young Members Group lends its support to the Nuclear Energy Institute trade association - sponsored the North American Young Generation in Nuclear 501(c)(6) on outreach projects.\n\nThe 19 professional divisions and groups are as follows: \n\nThe Society publishes the magazines \"Nuclear News\" and \"Radwaste Solutions\" and three technical journals: \"Nuclear Science and Engineering\", \"Nuclear Technology\" and \"Fusion Science and Technology.\" The ANS holds an annual meeting in June and a winter meeting in November, with participants from around the world. Through its professional divisions and local sections, ANS conducts separate topical meetings, covering specific subjects in-depth.\n\nTo be eligible for professional membership a person must be engaged in activities in one or more of the fields of nuclear science and engineering or allied fields and shall meet at least one of the following requirements:\n\nTo be eligible for student membership, a person must be regularly enrolled and pursuing an approved scientific or engineering curriculum in a school having, or eligible to have, a Student Section of the Society, or in the Naval Nuclear Power School, or in a similar institution approved by the Board of Directors.\n\nANS believes that a well-recognized honors and awards program is a key attribute of any highly respected technical/professional society. Currently with more than 35 prestigious awards, the American Nuclear Society has a vigorous program to honor outstanding achievement and meritorious service in the various fields served by our Society. With these honors and awards programs, ANS recognizes the accomplishments of nuclear science and technology professionals.\n\nANS helps students complete their post-high school education and prepare for careers in nuclear science and technology (NS&T). Among the programs available is the long list of ANS Scholarships for those looking for funding opportunities.\nMore than 20 scholarships named after pioneers and leaders in NS&T and other general scholarships are awarded each year to students with outstanding academic credentials. Special scholarships are available to students who have significant economic needs in order to pursue degrees in NS&T. In addition to the scholarships for students entering their sophomore year and higher in college, ANS also provides scholarships to incoming freshmen.\n\n"}
{"id": "40054744", "url": "https://en.wikipedia.org/wiki?curid=40054744", "title": "Auxiliary line", "text": "Auxiliary line\n\nAn auxiliary line (or helping line) is an extra line needed to complete a proof in plane geometry. Other common auxiliary constructs in elementary plane synthetic geometry are the helping circles.\n\nAs an example, a proof of the theorem on the sum of angles of a triangle can be done by adding a straight line parallel to one of the triangle sides (passing through the opposite vertex).\n\nAlthough the adding of auxiliary constructs can often make a problem obvious, it's not at all obvious to discover the helpful construct among all the possibilities, and for this reason many prefer to use more systematic methods for the solution of geometric problems (such as the coordinate method, which requires much less ingenuity).\n\n"}
{"id": "1501218", "url": "https://en.wikipedia.org/wiki?curid=1501218", "title": "Baratol", "text": "Baratol\n\nBaratol is an explosive made of a mixture of TNT and barium nitrate, with a small quantity (about 1%) of paraffin wax used as a phlegmatizing agent. TNT typically makes up 25% to 33% of the mixture. Because of the high density of barium nitrate, Baratol has a density of at least 2.5 Mg/m.\n\nBaratol, which has a detonation velocity of only about 4,900 metres per second, was used as the slow-detonating explosive in the explosive lenses of some early atomic bombs, with Composition B often used as the fast-detonating component. Atomic bombs detonated at Trinity in 1945, the Soviet Joe 1 in 1949, and in India in 1972 all used Baratol and Composition B.\n\nBaratol was also used in the Mills bomb, a British hand grenade.\n"}
{"id": "2994458", "url": "https://en.wikipedia.org/wiki?curid=2994458", "title": "Blade pitch", "text": "Blade pitch\n\nBlade pitch or simply pitch refers to turning the angle of attack of the blades of a propeller or helicopter rotor into or out of the wind to control the production or absorption of power. Wind turbines use this to adjust the rotation speed and the generated power. A propeller of a ship uses this effect to control the ship's speed without changing the rotation of the shaft and to increase the efficiency of streaming fluids.\n\nIn aircraft, blade pitch is usually described as \"coarse\" for a greater horizontal blade angle, and \"fine\" for a more vertical blade angle. For an aircraft that is stationary the angle of pitch of each blade of a propeller fitted to that aircraft equates to the angle of attack.\n\nBlade pitch is normally described in units of distance/rotation assuming no slip.\n\nBlade pitch acts much like the gearing of the final drive of a car. Low pitch yields good low speed acceleration (and climb rate in an aircraft) while high pitch optimizes high speed performance and economy.\n\nA propeller blade's \"lift\", or its thrust, depends on the angle of attack combined with its speed. Because the velocity of a propeller blade varies from the hub to the tip, it is of twisted form in order for the thrust to remain approximately constant along the length of the blade; this is called washout. This is typical of all but the crudest propellers.\n\nIt is quite common in aircraft for the propeller to be designed to vary pitch in flight, to give optimum thrust over the maximum amount of the aircraft's speed range, from takeoff and climb to cruise.\n\nIn helicopters the pitch control changes the angle of attack of the rotor blades and thus the vertical acceleration or climb rate of the vehicle. This control is also called \"collective\" as distinct from the \"cyclic\" control for lateral movement. The collective blade setting is mostly achieved through vertical movement of the swashplate.\n\nFeathering the blades of a propeller means to increase their angle of pitch by turning the blades to be parallel to the airflow. This minimizes drag from a stopped propeller following an engine failure in flight.\n\nBlade pitch control is a feature of nearly all large modern horizontal-axis wind turbines. While operating, a wind turbine's control system adjusts the blade pitch to keep the rotor speed within operating limits as the wind speed changes. Feathering the blades stops the rotor during emergency shutdowns, or whenever the wind speed exceeds the maximum rated speed. During construction and maintenance of wind turbines, the blades are usually feathered to reduce unwanted rotational torque in the event of wind gusts.\n\nIn boating, blade pitch is measured in the number of inches of forward propulsion through the water for one complete revolution of the propeller. For example, a propeller with a 12\" pitch when rotated once, will propel the vessel 12\" ahead. Note that this is the theoretical maximum distance; in reality, due to \"slip\" between the propeller and the water, the actual distance propelled will invariably be less.\n\nSome composite propellers have interchangeable blades, which enables the blade pitch to be adjusted. Changing the blade pitch in different elevations can be very beneficial to a boater. Typically, using a lower pitch will provide better acceleration and a higher pitch enables better top end speed.\n\nIn rowing, blade pitch is the inclination of the blade towards the stern of the boat during the drive phase of the rowing stroke. Without correct blade pitch, a blade would have a tendency to dive too deep, or pop out of the water and/or cause difficulties with balancing on the recovery phase of the rowing stroke.\n"}
{"id": "11252801", "url": "https://en.wikipedia.org/wiki?curid=11252801", "title": "Blood Hill wind farm", "text": "Blood Hill wind farm\n\nBlood Hill is a wind farm near Hemsby in Norfolk, England. It is the smallest windfarm owned by E.ON; taking up 3 hectares. It has a nameplate capacity of 2.25MW which is enough to power 1000 homes at peak. There are 10 Vestas V27-225 kW turbines which are 30 metres tall and stand on top of Blood Hill. They are visible from the villages of Hemsby and Winterton-on-Sea. Blood Hill began operating in December 1992 and was one of the first windfarms in the United Kingdom.\n\nIn 2000 a much larger 65m 1.5MW Ecotricity turbine was built adjacent to the site.\n\nIn 2015 a repowering of the site saw the original 10 turbines replaced with 2 two Turbowind T400 wind turbines.\n\n"}
{"id": "183390", "url": "https://en.wikipedia.org/wiki?curid=183390", "title": "Carbon audit regime", "text": "Carbon audit regime\n\nA carbon audit regime is a means of accounting for quantifiable greenhouse gas control efforts. It establishes that the claimed reductions in emissions or enhancements of carbon sinks, has actually occurred and is stable.\n\nThe UK is the only nation in the world that presently has such a regime.\n\n"}
{"id": "2856125", "url": "https://en.wikipedia.org/wiki?curid=2856125", "title": "Coal Exchange", "text": "Coal Exchange\n\nThe Coal Exchange (also known as the Exchange Building) is a historical building in Cardiff, Wales.\n\nIt was built in 1888 as the Coal and Shipping Exchange to be used as a market floor and office building for trading in coal in Cardiff, then a hub of the global coal trade. It is situated in Mount Stuart Square in Butetown, and was for many years the hub of the city's prosperous shipping industry. \n\nIt later became a music venue, with offices remaining in use in the West Wing, before being closed indefinitely in 2013 due to building safety issues. Following a series of proposals to demolish the building, Cardiff Council purchased the Coal Exchange. In 2016 the property was sold to Liverpool based hospitality company Signature Living, which began a programme of restoration and conversion of the building into a hotel. \n\nThe first phase of this renovation was completed with the opening of the first thirty rooms in April 2017, with further rooms added as renovations continued. As of August 2018, renovations were still ongoing to the rear areas of the building, over 90 rooms had been completed, and the hotel restaurant had opened.\n\nBefore the Coal Exchange was built in Mount Stuart Square, the area was a residential square with a central garden. It was taken over by commerce as the city grew in prosperity. Built to provide a dedicated location for merchants and traders to sell coal, it followed construction of buildings of a similar function in London, Liverpool and Manchester. Prior to its construction, coal merchants used to chalk up the changing prices of coal on slates outside their offices or struck deals in the local public houses. It was built and opened in stages, the central trading hall and east block completed first. The trading hall was a large central space around which suites of offices were located. The London and Provincial Banking Company occupied the majority of the north side.\n\nAs Cardiff became the biggest coal port in the world, the building was constructed between 1884 and 1888 by Edwin Seward as a base from which to conduct trade negotiations regarding the coal mines of the South Wales Valleys – most of which was shipped to Cardiff for distribution.\n\nThe building played an important role in the industrial Cardiff of the 19th century. Paired Corinthian columns, an oak balcony, and rich wood panelling adorn the trading hall, which was reconstructed by Edwin Seward in 1911.\n\nFollowing its opening, coal owners, ship owners and their agents met daily on the floor of the trading hall where agreements were made by word of mouth and telephone. During the peak trading hour of midday to one o'clock, the floor might have as many as 200 men gesticulating and shouting. It was estimated that up to 10,000 people would pass in and out of the building each day. At one time the price of the world's coal was determined here. It was at the Coal Exchange that the first ever £1,000,000 deal was agreed in 1904. The building interior was lavishly refurbished in 1912 by Edwin Seward, and reopened as the ‘New Exchange Building’. In 1915, an extension was added to the southern section, connected to the trading hall.\n\nCardiff's reliance on coal made the Bute Docks highly vulnerable to any downturn in the demand for it. With the end of the war the docks went into further decline. The Coal exchange closed in 1958 and coal exports came to an end in 1964. The southern extension was demolished in the 1970s. The building became Grade II* listed in 1975.\n\nIn 1979 the Coal Exchange was earmarked as a future home of the proposed Welsh Assembly and a heavily reinforced underground carpark was constructed (also envisaged to act as a nuclear shelter) but the plan for devolution was rejected by the Welsh people in a referendum. In 1983 the building was considered as a headquarters for the Welsh language television station, S4C, though this also failed to take off. The Exchange Hall was used with great regularity during this period as a filming location for various parts of the entertainment industry, for example the BBC drama \"Bevan\".\n\nIn 1988 the building was re-acquired and subsequently completely refurbished in 2001 to turn it into a major venue. The venue hosted acts such as the Arctic Monkeys, Manic Street Preachers, Ocean Colour Scene, Stereophonics, Van Morrison and Biffy Clyro.\n\nThe Coal Exchange closed on 7 August 2013 as a result of building safety issues. With the subsequent liquidation of the company which owned it in 2014, ownership of the Coal Exchange passed to the Crown Estate. It then became the subject of efforts to preserve the historic fabric of the building by the not-for-profit organisation Save the Coal Exchange Limited. In February 2015, Welsh Government Economy Minister Edwina Hart commissioned a feasibility study into future re-use of the building. In May 2015 it was confirmed that the exchange would be used for filming of the remake of \"The Crow\". In 2016, filmmaker Nick Broomfield visited the building as part of his documentary \"Going Going Gone\", which investigated the deterioration and heritage of the Coal Exchange. \n\nIn 2016 it was announced that the building was to be fully refurbished as a hotel by private company Signature Living, with a museum detailing the history of the building and of the Cardiff Docks. The proposal received some opposition, including from the Victorian Society and MP Stephen Doughty. Cardiff council granted planning permission in July 2016. In June 2017, the BBC broadcast a documentary entitled \"Saving The Coal Exchange\", which looked at the development of the building into a hotel. As part of the phased restoration programme, rooms were opened as works were completed. The first 30 rooms of the hotel opened in May 2017. This was followed by a further 30 rooms in both June and September 2017, bringing the total to 90. In total 200 bedrooms are expected on completion, along with restaurants, bars and spa facilities. The restoration retained the original structure, including a number of original features including a memorial dedicated to World War I and the grand hall, previously the trading floor.\n\nThe building is constructed largely in limestone, in the French Renaissance style. The exterior is made of pale Corsham stone on three sides, with yellow brick on the western elevation. The roof is slate, topped with multiple chimneys mainly in yellow brick. Its style was derived from French Renaissance models. The main entrance front faces south. The building is made up of three storeys and basement, plus attic storeys in the central pedimented 'frontispiece', with a hipped pavilion roof. The entrance is guarded by a pair of fluted Corinthian columns, and topped by a floral relief in a triangular pediment surmounted by Royal Arms. On the north east corner, steps lead up to a projecting porch which housed Barclays Bank, resident here since building opened.\n\nThe interior retains an entrance hall with a Jacobethan style moulded plaster ceiling, panelled walls, and woodblock and inlay floor. At the rear are two lions on high plinths supporting clock faces showing times of Cardiff high tides. The central Coal and Shipping Hall dominates the building, surrounded by galleried tiers, in Jacobethan style dark wood. A false ceiling has reduced the height to 2 storeys, hiding a centrally glazed roof.\n\nCoal Exchange is served by Cardiff Bay railway station and Cardiff Bus service 7, 8, 35, and Baycar.\n\n\n"}
{"id": "67458", "url": "https://en.wikipedia.org/wiki?curid=67458", "title": "Coalbed methane extraction", "text": "Coalbed methane extraction\n\nCoalbed methane extraction (CBM extraction) is a method for extracting methane from a coal deposit.\n\nMethane adsorbed into a solid coal matrix (coal macerals) will be released if the coal seam is depressurised. Methane may be extracted by drilling wells into the coal seam. The goal is to decrease the water pressure by pumping water from the well. The decrease in pressure allows methane to desorb from the coal and flow as a gas up the well to the surface. Methane is then compressed and piped to market.\n\nThe objective is to avoid putting methane into the water line, but allow it to flow up the backside of the well (casing) to the compressor station. If the water level is pumped too low during dewatering, methane may travel up the tubing into the water line causing the well to become \"gassy\". Although methane may be recovered in a water-gas separator at the surface, pumping water and gas is inefficient and can cause pump wear and breakdown.\n\nTens of thousands of methane wells have been drilled, and extensive support facilities such as roads, pipelines, and compressors have been installed for CBM extraction in the Powder River Basin of northeast Wyoming and southeast Montana and now in India at West Bengal- Ranigunj, Panagarh etc. Seven percent of the natural gas (methane) currently produced in the United States comes from CBM extraction. Methane from coalbed reservoirs can be recovered economically, but disposal of water is an environmental concern.\n\nThere are also sites in Central Scotland at Letham Moss.\nMost gas in coal is stored on the internal surfaces of organic matter. Because of its large internal surface area, coal stores 6 to 7 times more gas than the equivalent rock volume of a conventional gas reservoir. Gas content generally increases with coal rank, with depth of burial of the coal bed, and with reservoir pressure. Fractures, or cleats, within coal beds are usually filled with water. Deeper coal beds contain less water, but that water is more saline. Removing water from the coal bed reduces pressure and releases methane. Large amounts of water, sometimes saline brine, are produced from coalbed methane wells. The greatest water volumes are produced during the early stages of production. Environmentally acceptable disposal of brine is a major cost factor for economic methane production. Fresh water may be discharged on the surface, but brine is usually injected into rock at a depth where the salinity of the injected brine is less than connate fluids of the host rock. Evaporation of water for recovery of potentially salable solid residues might be feasible in regions having high evaporation rates.\n\nCoal bed gas content measurements are commonly used in mine safety as well as coal bed methane resource assessment and recovery applications. Gas content determination techniques generally fall into two categories: (1) direct methods which actually measure the volume of methane released from a coal sample sealed into a desorption canister and (2) indirect methods based on empirical correlations, or laboratory derived sorption isotherm methane storage capacity data. Laboratory sorption isotherms provide information about the storage capacity of a coal sampleif these are measured under geological realistic pressure and temperature conditions. Thus, the maximum gas content which can be expected for methane recovery can be assessed from such laboratory isotherm measurements.\n\nThe total gas content by the indirect methods is based on the empirical formula given by Meinser and Kim. The quantity of gas is determined by Meisner and Kim formula with using the moisture content, volatile content, volume of methane adsorbed on wet coal, fixed carbon, thickness of coal and temperature.\nMeinser (1984) observed that the amount of methane gas (VCH4) is related to volatile matter (daf).\n\nV = −325.6 × log (V.M/37.8)\n\nEstimation of \"in situ\" gas content of the coal will be evaluated by using Kim's (Kim 1977) equation \n\nV = (100 −M − A) /100 × [ Vw /Vd ] [K(P) - (b × T)]\nWhere,\nV = Volume of methane gas adsorbed (cc/g) \nM = Moisture content (%) \nA = Ash content (%).\nVw/Vd = 1/(0.25 ×M + 1)\nVw = Volume of gas adsorbed on wet coal (cc/g) \nVd = Volume of gas adsorbed on dry coal (cc/g)\nThe values of K and N depend on the rank of the coal and can be expressed in terms of ratio of fixed carbon (FC) to Volatile matter(VM)\nK = 0.8 (F.C /V.M) + 5.6\nWhere\nF.C = Fixed carbon (%)\nVM = Volatile matter (%)\nN = Composition of coal (for most bituminous coals, N = (0.39 - 0.013 × K)\nb =Adsorption constant due to temperature change (cc/g/◦C).\nT = Geothermal Gradient × (h/ 100) + To\nT = Temperature at given depth\nTo = Ground temperature\nh = Depth (m)\n\nEstimation of methane content in coal seams by Karol curve\n\nIn the absence measured methane content of coal beds, and production data from coal bed methane wells, gas content can be estimated using the Eddy curve. Eddy and others constructed a series of curves estimating maximum producible methane content of coal bed as a function of depth and rank.\nThe estimation of methane content of a coal bed is determined from the Eddy curve by locating the average depth of each coal seam on the depth axis. A normal line is extended upward from the depth axis (feet) to intersect the specific coal rank curves. A line from the point on the curve is extended normal to the lost and desorbed gas axis(cm/gm). The intersection of the line and the axis is the estimated methane content of the coal seam.\n\nAsh is an important indicator of clastic input, derived from marine or fluvial deposition of clay, silt, and sand during peat development. Outcrop ash content appears to be less than ash content of subsurface samples. Lower ash contents of outcrop samples may be due to coal deposits being up dip and further away from a marine influence than samples down-dip.\n\n"}
{"id": "7864782", "url": "https://en.wikipedia.org/wiki?curid=7864782", "title": "Congruent melting", "text": "Congruent melting\n\nCongruent melting occurs during melting of a compound when the composition of the liquid that forms is the same as the composition of the solid. It can be contrasted with incongruent melting. This generally happens in two-component systems. To take a general case, let A and B be the two components and AB a stable solid compound formed by their chemical combination. If we draw a phase diagram for the system, we notice that there are three solid phases, namely A, B and compound AB. Accordingly, there will be three fusion or freezing point curves AC, BE and CDE for the three solid phases. In the phase diagram, we can notice that the top point D of the phase diagram is the congruent melting point of the compound AB because the solid and liquid phases now have the same composition. Evidently, at this temperature, the two-component system has become a one-component system because both solid and liquid phases contains only the compound AB.\n\nThis happens for inter-metallic compounds.\nFor example, MgSi\n\n"}
{"id": "25102817", "url": "https://en.wikipedia.org/wiki?curid=25102817", "title": "Dauletabad–Sarakhs–Khangiran pipeline", "text": "Dauletabad–Sarakhs–Khangiran pipeline\n\nThe Dauletabad–Sarakhs–Khangiran pipeline (also known as Dauletabad–Salyp Yar pipeline) is a natural gas pipeline from the Dauletabad gas field in Turkmenistan to Khangiran in Iran, where it is connected with the Iran Gas Trunkline system. It is significant as it allows the diversification of Turkmenistan's gas export routes, doubling the nation's export of gas to Iran. For Iran, the pipeline allows the country to deal with gas shortages in its northern regions, and to improve its reputation as a trade partner in the Caspian region. Gas began pumping on 3 January 2010, and the pipeline was inaugurated in a ceremony in Turkmenistan on 6 January 2010.\n\nThe decision to build the pipeline was made in July 2009. The pipeline was completed in October 2009, and was inaugurated on 6 January 2010, by presidents Mahmoud Ahmadinejad and Gurbanguly Berdimuhamedow at a ceremony held at the border village of Salyp Yar, Serakhs in Ahal Province, Turkmenistan. At the inauguration, Ahmadinejad said, \"These two are not just economic projects, but are indications of the two nations' profound bonds and interest as well as the two countries' fair relations in the region ... This pipeline will be a good stimulus for energy co-operation between Turkmenistan and Iran, as well as for delivery of Turkmen gas to the Persian Gulf and the world market.\" The ceremony was also attended by Taner Yıldız, the minister of energy and natural resources of Turkey, and Ahmed Mohammed Ali Al-Madani, president of the Islamic Development Bank.\n\nThe total length of the pipeline is . The pipeline starts at the Dauletabad gas field where it branches off from the Dovletabad–Deryalyk pipeline (Central Asia – Center gas pipeline system). It runs to Sarakhs, where it crosses the Iran–Turkmenistan border. From there, the long section transports gas to the Shahid Hasheminejad (Khangiran) Gas Refinery in Khangiran, Khorasan Province. Later the pipeline will be extended to Sangbast area.\n\nThe pipeline has an initial capacity of 6 billion cubic meters (bcm) of natural gas per year, which later will be increased up to 12 bcm. Combined with the other, smaller, Turkmenistan–Iran pipeline, the Korpezhe–Kurt Kui pipeline, Turkmenistan will have the capacity to transport up to 20 bcm of gas. The pipeline has a diameter of . Construction costs for the pipeline totaled US$180 million.\n\n"}
{"id": "24431363", "url": "https://en.wikipedia.org/wiki?curid=24431363", "title": "Davyum", "text": "Davyum\n\nDavyum was the proposed name for a chemical element found by chemist Serge Kern in 1877. It was shown that the material was a mixture of iridium and rhodium. In 1950 it was proposed that the new metal might also have contained rhenium, which had not been discovered in Kern's time.\n"}
{"id": "191061", "url": "https://en.wikipedia.org/wiki?curid=191061", "title": "Dawn", "text": "Dawn\n\nDawn, from an Old English verb \"dagian\": \"to become day\", is the time that marks the beginning of twilight before sunrise. It is recognized by the appearance of indirect sunlight being scattered in the atmosphere, when the centre of the Sun's disc reaches 18° below the horizon. This dawn twilight period will last until sunrise (when the Sun's upper limb breaks the horizon), as the diffused light becomes direct sunlight.\n\nDawn begins with the first sight of lightness in the morning, and continues until the sun breaks the horizon. This morning twilight \"before sunrise\", is divided into three categories depending on the amount of sunlight that is present in the sky, which is determined by the angular distance of the centre of the Sun (degrees below the horizon) in the morning. The categories are named: \"astronomical\", \"nautical\", and \"civil\" dawn.\n\nAstronomical twilight begins when the sky is no longer completely dark after astronomical dawn. This occurs when the Sun is 18 degrees below the horizon in the morning. At this point a very small portion of the sun's rays illuminate the sky and the fainter stars begin to disappear. Astronomical dawn is often indistinguishable from night, especially in areas with light pollution. Astronomical dawn marks the beginning of astronomical twilight, which lasts until nautical dawn.\n\nNautical twilight begins when there is enough illumination for sailors to distinguish the horizon at sea but the sky is too dark to perform outdoor activities (except with artificial light). Formally, nautical twilight begins when the Sun is 12 degrees below the horizon in the morning. The sky becomes light enough to clearly distinguish it from land and water. Nautical dawn marks the start of nautical twilight, which lasts until civil dawn.\n\nCivil twilight begins when there is enough light for most objects to be distinguishable, so that some outdoor activities, but not all, can commence. Formally, civil dawn occurs when the Sun is 6 degrees below the horizon in the morning.\n\nIf the sky is clear, it is blue colored, and if there is some cloud or haze, there can be bronze, orange and yellow colours. Some bright stars and planets such as Venus and Jupiter are visible to the naked eye at civil dawn. This moment marks the start of civil twilight, which lasts until sunrise.\n\nThe duration of the twilight period (e.g. between astronomical dawn and sunrise) varies greatly depending on the observer's latitude: from a little over 70 minutes at the Equator, to many hours in the polar regions.\n\nThe period of twilight is shortest at the Equator, where the equinox Sun rises due east and sets due west, at a right angle to the horizon. Each stage of twilight (civil, nautical, and astronomical) lasts only 24 minutes. From anywhere on Earth, the twilight period is shortest around the equinoxes and longest on the solstices.\n\nDaytime becomes longer as the summer solstice approaches, while nighttime gets longer as the winter solstice approaches. This can have a potential impact on the times and durations of dawn and dusk. This effect is more pronounced closer to the poles, where the Sun rises at the vernal equinox and sets at the autumn equinox, with a long period of twilight, lasting for a few weeks.\n\nThe polar circle (at 66°34′ north or south) is defined as the lowest latitude at which the Sun does not set at the summer solstice. Therefore, the angular radius of the polar circle is equal to the angle between Earth's equatorial plane and the ecliptic plane. This period of time with no sunset lengthens closer to the pole.\n\nNear the summer solstice, latitudes higher than 54°34′ get no darker than nautical twilight; the \"darkness of the night\" varies greatly at these latitudes.\n\nAt latitudes higher than about 60°34, summer nights get no darker than civil twilight. This period of \"bright nights\" is longer at higher latitudes.\n\nAround the summer solstice, Glasgow, Scotland at 55°51′ N, and Copenhagen, Denmark at 55°40′ N, get a few hours of \"night feeling\". Oslo, Norway at 59°56′ N, and Stockholm, Sweden at 59°19′ N, seem very bright when the Sun is below the horizon. When the sun gets 9.0 to 9.5 degrees below the horizon (at summer solstice this is at latitudes 57°30′–57°00′), the zenith gets dark even on cloud-free nights (if there is no full moon), and even the brightest stars are clearly visible in a large majority of the sky.\n\nMany Indo-European mythologies have a dawn goddess, separate from the male Solar deity, her name deriving from PIE \"*hausos-\", derivations of which include Greek Eos, Roman Aurora and Indian Ushas. Also related is Lithuanian Aušrinė, and possibly a Germanic \"*Austrōn-\" (whence the term \"Easter\"). In Sioux mythology, Anpao is an entity with two faces.\n\nThe Hindu dawn deity Ushas is female, whereas Surya, the Sun, and Aruṇa, the Sun's charioteer, are male. Ushas is one of the most prominent Rigvedic deities. The time of dawn is also referred to as the Brahmamuhurtham (Brahma is god of creation and muhurtham is a Hindu unit of time), and is considered an ideal time to perform spiritual activities, including meditation and yoga. In some parts of India, both Usha and Pratyusha (dusk) are worshiped along with the Sun during the festival of Chhath.\n\nPrime is the fixed time of prayer of the traditional Divine Office (Canonical Hours) in Christian liturgy, said at the first hour of daylight.\n\nIn Islam, astronomical dawn (Arabic \"fajr\") is the time of the first prayer of the day, and the beginning of the daily fast during Ramadan.\n\nIn Judaism, the question of how to calculate dawn (Hebrew Alos/ HaShachar, or Alos/) is posed by the Talmud, as it has many ramifications for Jewish law (such as the possible start time for certain daytime commandments, like prayer). The simple reading of the Talmud is that dawn takes place 72 minutes before sunrise. Others, including the Vilna Gaon, have the understanding that the Talmud's timeframe for dawn was referring specifically to an equinox day in Mesopotamia, and is therefore teaching that dawn should be calculated daily as commencing when the sun is 16.1 degrees below the horizon. The longstanding practice among most Sephardic Jews is to follow the first opinion, while many Ashkenazi Jews follow the latter view.\n\n\n\n"}
{"id": "6729444", "url": "https://en.wikipedia.org/wiki?curid=6729444", "title": "Ecologic Association Green Osijek", "text": "Ecologic Association Green Osijek\n\nThe Ecologic Association Green Osijek () was founded in 1995 in Osijek, Croatia.\n\nIts main activities are environmental protection, schools in nature, ecotourism and preserving the cultural and natural heritage of Slavonia and Baranja region. The main project of Green Osijek is development of Eco centre Zlatna Greda near the Nature park Kopački rit. In Eco centre Zlatna Greda, the association is organising schools in nature, hiking through wetlands and forests, boat rides on the Danube, birdwatching, making of traditional meals in the open fire under the gazebo.\n\n"}
{"id": "159472", "url": "https://en.wikipedia.org/wiki?curid=159472", "title": "Flight", "text": "Flight\n\nFlight is the process by which an object moves through an atmosphere (or beyond it, as in the case of spaceflight) without contact with the surface. This can be achieved by generating aerodynamic lift associated with propulsive thrust, aerostatically using buoyancy, or by ballistic movement.\n\nMany things can fly, from natural aviators such as birds, bats, and insects, to human inventions like aircraft, including airplanes, helicopters, balloons, and rockets which may carry spacecraft.\n\nThe engineering aspects of flight are the purview of aerospace engineering which is subdivided into aeronautics, the study of vehicles that travel through the air, and astronautics, the study of vehicles that travel through space, and in ballistics, the study of the flight of projectiles.\n\nHumans have managed to construct lighter than air vehicles that raise off the ground and fly, due to their buoyancy in air.\n\nAn aerostat is a system that remains aloft primarily through the use of buoyancy to give an aircraft the same overall density as air. Aerostats include free balloons, airships, and moored balloons. An aerostat's main structural component is its envelope, a lightweight skin that encloses a volume of lifting gas to provide buoyancy, to which other components are attached.\n\nAerostats are so named because they use \"aerostatic\" lift, a buoyant force that does not require lateral movement through the surrounding air mass to effect a lifting force. By contrast, aerodynes primarily use aerodynamic lift, which requires the lateral movement of at least some part of the aircraft through the surrounding air mass.\n\nSome things that fly do not generate propulsive thrust through the air, for example, the flying squirrel. This is termed gliding. Some other things can exploit rising air to climb such as raptors (when gliding) and man-made sailplane gliders. This is termed soaring. However most other birds and all powered aircraft need a source of propulsion to climb. This is termed powered flight.\n\nThe only groups of living things that use powered flight are birds, insects, and bats, while many groups have evolved gliding. The extinct Pterosaurs, an order of reptiles contemporaneous with the dinosaurs, were also very successful flying animals. Each of these groups' wings evolved independently. The wings of the flying vertebrate groups are all based on the forelimbs, but differ significantly in structure; those of insects are hypothesized to be highly modified versions of structures that form gills in most other groups of arthropods.\n\nBats are the only mammals capable of sustaining level flight (see \"bat flight\"). However, there are several gliding mammals which are able to glide from tree to tree using fleshy membranes between their limbs; some can travel hundreds of meters in this way with very little loss in height. Flying frogs use greatly enlarged webbed feet for a similar purpose, and there are flying lizards which fold out their mobile ribs into a pair of flat gliding surfaces. \"Flying\" snakes also use mobile ribs to flatten their body into an aerodynamic shape, with a back and forth motion much the same as they use on the ground.\n\nFlying fish can glide using enlarged wing-like fins, and have been observed soaring for hundreds of meters. It is thought that this ability was chosen by natural selection because it was an effective means of escape from underwater predators. The longest recorded flight of a flying fish was 45 seconds.\n\nMost birds fly (\"see bird flight\"), with some exceptions. The largest birds, the ostrich and the emu, are earthbound, as were the now-extinct dodos and the Phorusrhacids, which were the dominant predators of South America in the Cenozoic era. The non-flying penguins have wings adapted for use under water and use the same wing movements for swimming that most other birds use for flight. Most small flightless birds are native to small islands, and lead a lifestyle where flight would offer little advantage.\n\nAmong living animals that fly, the wandering albatross has the greatest wingspan, up to ; the great bustard has the greatest weight, topping at .\n\nMost species of insects can fly as adults. Insect flight makes use of either of two basic aerodynamic models: creating a leading edge vortex, found in most insects, and using clap and fling, found in very small insects such as thrips.\n\nMechanical flight is the use of a machine to fly. These machines include aircraft such as airplanes, gliders, helicopters, autogyros, airships, balloons, ornithopters as well as spacecraft. Gliders are capable of unpowered flight. Another form of mechanical flight is para-sailing where a parachute-like object is pulled by a boat. In an airplane, lift is created by the wings; the shape of the wings of the airplane are designed specially for the type of flight desired. There are different types of wings: tempered, semi-tempered, sweptback, rectangular and elliptical. An aircraft wing is sometimes called an airfoil, which is a device that creates lift when air flows across it.\n\nSupersonic flight is flight faster than the speed of sound. Supersonic flight is associated with the formation of shock waves that form a sonic boom that can be heard from the ground, and is frequently startling. This shockwave takes quite a lot of energy to create and this makes supersonic flight generally less efficient than subsonic flight at about 85% of the speed of sound.\n\nHypersonic flight is very high speed flight where the heat generated by the compression of the air due to the motion through the air causes chemical changes to the air. Hypersonic flight is achieved by reentering spacecraft such as the Space Shuttle and Soyuz.\nSome things generate little or no lift and move only or mostly under the action of momentum, gravity, air drag and in some cases thrust. This is termed \"ballistic flight\". Examples include balls, arrows, bullets, fireworks etc.\n\nEssentially an extreme form of ballistic flight, spaceflight is the use of space technology to achieve the flight of spacecraft into and through outer space. Examples include ballistic missiles, orbital spaceflight etc.\n\nSpaceflight is used in space exploration, and also in commercial activities like space tourism and satellite telecommunications. Additional non-commercial uses of spaceflight include space observatories, reconnaissance satellites and other earth observation satellites.\n\nA spaceflight typically begins with a rocket launch, which provides the initial thrust to overcome the force of gravity and propels the spacecraft from the surface of the Earth. Once in space, the motion of a spacecraft—both when unpropelled and when under propulsion—is covered by the area of study called astrodynamics. Some spacecraft remain in space indefinitely, some disintegrate during atmospheric reentry, and others reach a planetary or lunar surface for landing or impact.\n\nMany human cultures have built devices that fly, from the earliest projectiles such as stones and spears, the\nboomerang in Australia, the hot air Kongming lantern, and kites.\n\nGeorge Cayley studied flight scientifically in the first half of the 19th century, and in the second half of the 19th century Otto Lilienthal made over 200 gliding flights and was also one of the first to understand flight scientifically. His work was replicated and extended by the Wright brothers who made gliding flights and finally the first controlled and extended, manned powered flights.\n\nSpaceflight, particularly human spaceflight became a reality in the 20th century following theoretical and practical breakthroughs by Konstantin Tsiolkovsky and Robert H. Goddard. The first orbital spaceflight was in 1957, and Yuri Gagarin was carried aboard the first manned orbital spaceflight in 1961.\n\nThere are different approaches to flight. If an object has a lower density than air, then it is buoyant and is able to float in the air without expending energy. A heavier than air craft, known as an aerodyne, includes flighted animals and insects, fixed-wing aircraft and rotorcraft. Because the craft is heavier than air, it must generate lift to overcome its weight. The wind resistance caused by the craft moving through the air is called drag and is overcome by propulsive thrust except in the case of gliding.\n\nSome vehicles also use thrust for flight, for example rockets and Harrier Jump Jets.\n\nFinally, momentum dominates the flight of ballistic flying objects.\n\nForces relevant to flight are\n\nThese forces must be balanced for stable flight to occur.\n\nA fixed-wing aircraft generates forward thrust when air is pushed in the direction opposite to flight. This can be done in several ways including by the spinning blades of a propeller, or a rotating fan pushing air out from the back of a jet engine, or by ejecting hot gases from a rocket engine. The forward thrust is proportional to the mass of the airstream multiplied by the difference in velocity of the airstream. Reverse thrust can be generated to aid braking after landing by reversing the pitch of variable-pitch propeller blades, or using a thrust reverser on a jet engine. Rotary wing aircraft and thrust vectoring V/STOL aircraft use engine thrust to support the weight of the aircraft, and vector sum of this thrust fore and aft to control forward speed.\n\nIn the context of an air flow relative to a flying body, the lift force is the component of the aerodynamic force that is perpendicular to the flow direction. Aerodynamic lift results when the wing causes the surrounding air to be deflected - the air then causes a force on the wing in the opposite direction, in accordance with Newton's third law of motion.\n\nLift is commonly associated with the wing of an aircraft, although lift is also generated by rotors on rotorcraft (which are effectively rotating wings, performing the same function without requiring that the aircraft move forward through the air). While common meanings of the word \"lift\" suggest that lift opposes gravity, aerodynamic lift can be in any direction. When an aircraft is cruising for example, lift does oppose gravity, but lift occurs at an angle when climbing, descending or banking. On high-speed cars, the lift force is directed downwards (called \"down-force\") to keep the car stable on the road.\n\nLift can also occur in a different way if the air is not still, especially if there is an updraft due to heat (\"thermals\") or wind blowing along sloping terrain or other meteorological conditions. This form of lift permits soaring and is particularly important for gliding. It is used by birds and gliders to stay in the air for long periods with little effort.\n\nFor a solid object moving through a fluid, the drag is the component of the net aerodynamic or hydrodynamic force acting opposite to the direction of the movement. Therefore, drag opposes the motion of the object, and in a powered vehicle it must be overcome by thrust. The process which creates lift also causes some drag.\n\nAerodynamic lift is created by the motion of an aerodynamic object (wing) through the air, which due to its shape and angle deflects the air. For sustained straight and level flight, lift must be equal and opposite to weight. In general, long narrow wings are able deflect a large amount of air at a slow speed, whereas smaller wings need a higher forward speed to deflect an equivalent amount of air and thus generate an equivalent amount of lift. Large cargo aircraft tend to use longer wings with higher angles of attack, whereas supersonic aircraft tend to have short wings and rely heavily on high forward speed to generate lift.\n\nHowever, this lift (deflection) process inevitably causes a retarding force called drag. Because lift and drag are both aerodynamic forces, the ratio of lift to drag is an indication of the aerodynamic efficiency of the airplane. The lift to drag ratio is the L/D ratio, pronounced \"L over D ratio.\" An airplane has a high L/D ratio if it produces a large amount of lift or a small amount of drag. The lift/drag ratio is determined by dividing the lift coefficient by the drag coefficient, CL/CD. \n\nThe lift coefficient Cl is equal to the lift L divided by the (density r times half the velocity V squared times the wing area A). [Cl = L / (A * .5 * r * V^2)] The lift coefficient is also affected by the compressibility of the air, which is much greater at higher speeds, so velocity V is not a linear function. Compressibility is also affected by the shape of the aircraft surfaces.\nThe drag coefficient Cd is equal to the drag D divided by the (density r times half the velocity V squared times the reference area A). [Cd = D / (A * .5 * r * V^2)] \nLift-to-drag ratios for practical aircraft vary from about 4:1 for vehicles and birds with relatively short wings, up to 60:1 or more for vehicles with very long wings, such as gliders. A greater angle of attack relative to the forward movement also increases the extent of deflection, and thus generates extra lift. However a greater angle of attack also generates extra drag. \n\nLift/drag ratio also determines the glide ratio and gliding range. Since the glide ratio is based only on the relationship of the aerodynamics forces acting on the aircraft, aircraft weight will not affect it. The only effect weight has is to vary the time that the aircraft will glide for – a heavier aircraft gliding at a higher airspeed will arrive at the same touchdown point in a shorter time. \n\nAir pressure acting up against an object in air is greater than the pressure above pushing down. The buoyancy, in both cases, is equal to the weight of fluid displaced - Archimedes' principle holds for air just as it does for water.\n\nA cubic meter of air at ordinary atmospheric pressure and room temperature has a mass of about 1.2 kilograms, so its weight is about 12 newtons. Therefore, any 1-cubic-meter object in air is buoyed up with a force of 12 newtons. If the mass of the 1-cubic-meter object is greater than 1.2 kilograms (so that its weight is greater than 12 newtons), it falls to the ground when released. If an object of this size has a mass less than 1.2 kilograms, it rises in the air. Any object that has a mass that is less than the mass of an equal volume of air will rise in air - in other words, any object less dense than air will rise.\n\nThrust-to-weight ratio is, as its name suggests, the ratio of instantaneous thrust to weight (where weight means weight at the Earth's standard acceleration formula_1). It is a dimensionless parameter characteristic of rockets and other jet engines and of vehicles propelled by such engines (typically space launch vehicles and jet aircraft).\n\nIf the thrust-to-weight ratio is greater than the local gravity strength (expressed in \"g\"s), then flight can occur without any forward motion or any aerodynamic lift being required.\n\nIf the thrust-to-weight ratio times the lift-to-drag ratio is greater than local gravity then takeoff using aerodynamic lift is possible.\n\nFlight dynamics is the science of air and space vehicle orientation and control in three dimensions. The three critical flight dynamics parameters are the angles of rotation in three dimensions about the vehicle's center of mass, known as \"pitch\", \"roll\" and \"yaw\" (See Tait-Bryan rotations for an explanation).\n\nThe control of these dimensions can involve a horizontal stabilizer (i.e. \"a tail\"), ailerons and other movable aerodynamic devices which control angular stability i.e. flight attitude (which in turn affects altitude, heading). Wings are often angled slightly upwards- they have \"positive dihedral angle\" which gives inherent roll stabilization.\n\nTo create thrust so as to be able to gain height, and to push through the air to overcome the drag associated with lift all takes energy. Different objects and creatures capable of flight vary in the efficiency of their muscles, motors and how well this translates into forward thrust.\n\nPropulsive efficiency determines how much energy vehicles generate from a unit of fuel.\n\nThe range that powered flight articles can achieve is ultimately limited by their drag, as well as how much energy they can store on board and how efficiently they can turn that energy into propulsion.\n\nFor powered aircraft the useful energy is determined by their fuel fraction- what percentage of the takeoff weight is fuel, as well as the specific energy of the fuel used.\n\nAll animals and devices capable of sustained flight need relatively high power-to-weight ratios to be able to generate enough lift and/or thrust to achieve take off.\n\nVehicles that can fly can have different ways to takeoff and land. Conventional aircraft accelerate along the ground until sufficient lift is generated for takeoff, and reverse the process for landing. Some aircraft can take off at low speed; this is called a short takeoff. Some aircraft such as helicopters and Harrier jump jets can take off and land vertically. Rockets also usually take off and land vertically, but some designs can land horizontally.\n\nNavigation is the systems necessary to calculate current position (e.g. compass, GPS, LORAN, star tracker, inertial measurement unit, and altimeter).\n\nIn aircraft, successful air navigation involves piloting an aircraft from place to place without getting lost, breaking the laws applying to aircraft, or endangering the safety of those on board or on the ground.\n\nThe techniques used for navigation in the air will depend on whether the aircraft is flying under the visual flight rules (VFR) or the instrument flight rules (IFR). In the latter case, the pilot will navigate exclusively using instruments and radio navigation aids such as beacons, or as directed under radar control by air traffic control. In the VFR case, a pilot will largely navigate using dead reckoning combined with visual observations (known as pilotage), with reference to appropriate maps. This may be supplemented using radio navigation aids.\n\nA guidance system is a device or group of devices used in the navigation of a ship, aircraft, missile, rocket, satellite, or other moving object. Typically, guidance is responsible for the calculation of the vector (i.e., direction, velocity) toward an objective.\n\nA conventional fixed-wing aircraft flight control system consists of flight control surfaces, the respective cockpit controls, connecting linkages, and the necessary operating mechanisms to control an aircraft's direction in flight. Aircraft engine controls are also considered as flight controls as they change speed.\n\nIn the case of aircraft, air traffic is controlled by air traffic control systems.\n\nCollision avoidance is the process of controlling spacecraft to try to prevent collisions.\n\nAir safety is a term encompassing the theory, investigation and categorization of flight failures, and the prevention of such failures through regulation, education and training. It can also be applied in the context of campaigns that inform the public as to the safety of air travel.\n\n\n\n\n"}
{"id": "40702807", "url": "https://en.wikipedia.org/wiki?curid=40702807", "title": "Fragmentos de Paixão", "text": "Fragmentos de Paixão\n\nFragmentos de Paixão is a 2013 Brazilian documentary film directed by Iara Cardoso.\n\nThe film was produced by INPE (National Institute for Space Research), and it's about the frequency of lightning in Brazil.\n\n"}
{"id": "2224692", "url": "https://en.wikipedia.org/wiki?curid=2224692", "title": "Gasoline gallon equivalent", "text": "Gasoline gallon equivalent\n\nGasoline gallon equivalent (GGE) or gasoline-equivalent gallon (GEG) is the amount of alternative fuel it takes to equal the energy content of one liquid gallon of gasoline. GGE allows consumers to compare the energy content of competing fuels against a commonly known fuel—gasoline. GGE also compares gasoline to fuels sold as a gas (natural gas, propane, hydrogen) and electricity.\n\nIn 1994, the US National Institute of Standards and Technology (NIST) defined \"gasoline gallon equivalent (GGE) means 5.660 pounds of natural gas.\" Compressed natural gas (CNG), for example, is a gas rather than a liquid. It can be measured by its volume in standard cubic feet (ft³) (volume at atmospheric conditions), by its weight in pounds (lb) or by its energy content in joules (J) or British thermal units (BTU) or kilowatt-hours (kW·h). It is difficult to compare the cost of gasoline with other fuels if they are sold in different units. GGE solves this. One GGE of CNG and one GGE of electricity have exactly the same energy content as one gallon of gasoline. CNG sold at filling stations in the US is priced in dollars per GGE.\n\nUsing GGE to compare fuels for use in an internal combustion engine is only the first part of the equation whose bottom line is useful work. In the context of GGE, a real world kind of \"useful work\" is miles per gallon (MPG) as advertised by motor vehicle manufacturers.\n\nSubstituting one fuel for another in a given engine may start and may do useful work. However getting optimum efficiency from each fuel–engine combination requires adjusting the mix of air and fuel. This can be a manual adjustment using tools and test instruments or done automatically in computer-controlled fuel injected and multi-fuel vehicles. Fine tuning of the optimum fuel–air mix may be facilitated by using a supercharger or turbocharger.\n\nIn battery or electric vehicles, calculating efficiency of useful work begins with the charge–discharge rate of the battery pack, generally 80% to 90%. Next is the conversion of potential energy (BTU) of the charge to distance traveled under power. See table below translating retail electricity costs for a GGE in BTU.\n\nNote that throughout this article, 'gallon' refers to the US gallon of approximately 3.8 litres, as opposed to the imperial gallon of approximately 4.5 litres\n\nRates per kWh for residential electricity in the USA range from $0.0728 (Idaho) to $0.166 (Alaska), \n$0.22 (San Diego Tier 1, while Tier 2 is $.40) and $0.2783 (Hawaii).\n\nOne GGE of natural gas is 126.67 cubic feet (3.587 m) at standard conditions. This volume of natural gas has the same energy content as one US gallon of gasoline (based on lower heating values: 900 BTU/cu ft of natural gas and 115,000 BTU/gal of gasoline).\n\nOne GGE of CNG pressurized at is 0.77 cubic foot (21.8 liters or 5.75 Gallons). This volume of CNG at 2,400 psi has the same energy content as one US gallon of gasoline (based on lower heating values: 148,144 BTU/cu ft of CNG and 115,000 BTU/gal of gasoline. Using Boyle's law, the equivalent GGE at is 0.51 cubic foot (14.4 L or 3.82 actual US gal).\n\nThe National Conference of Weights & Measurements (NCWM) has developed a standard unit of measurement for compressed natural gas, defined in the NIST Handbook 44 Appendix D as follows:\n\"1 Gasoline [US] gallon equivalent (GGE) means 2.567 kg (5.660 lb) of natural gas.\"\n\nWhen consumers refuel their CNG vehicles in the USA, the CNG is usually measured and sold in GGE units. This is fairly helpful as a comparison to gallons of gasoline.\n\n1.5 gallons of ethanol has the same energy content as 1.0 gallon of gasoline.\n\nThe energy content of 1.0 US gallon of ethanol is 76,100 BTU, compared to 114,100 BTU for gasoline. (see chart above)\n\nA flex-fuel vehicle will experience about 76% of the fuel mileage MPG when using E85 (85% ethanol) products as compared to 100% gasoline. Simple calculations of the BTU values of the ethanol and the gasoline indicate the reduced heat values available to the internal combustion engine. Pure ethanol provides 2/3 of the heat value available in pure gasoline.\n\nIn the most common calculation, that is, the BTU value of pure gasoline vs gasoline with 10% ethanol, the latter has just over 96% BTU value of pure gasoline. Gasoline BTU varies relating to the Reid vapor pressure (causing easier vaporization in winter blends containing ethanol(ethanol is difficult to start a vehicle on when it is cold out) and anti-knock additives. Such additives offer a reduction in BTU value.\n\nA concept closely related to the BTU or kWh potential of a given fuel is engine efficiency, often called thermal efficiency in the case of internal combustion engines.\n\nGenerally speaking, an electrical motor is far more efficient than an internal combustion engine at converting potential energy into work - turning the wheels that may move a car down the road, as there is minimal waste heat coming off the motor parts, and zero heat cast off by the coolant radiator and out of the exhaust.\n\nA diesel cycle engine can be as much as 40% to 50% efficient at converting fuel into work, where a typical automotive gasoline engine's efficiency is about 25% to 30%.\n\nThe efficiency of converting a unit of fuel to rotation of the driving wheels includes many points of friction loss and heat loss through the exhaust or cooling system. Friction inside the engine happens along the cylinder walls, crankshaft rod bearings and main bearings, camshaft bearings, drive chains or gears, plus other miscellaneous and minor bearing surfaces. An electric motor has internal friction only at the main axle bearings. Friction outside the motor/engine includes loads from the generator / alternator, power steering pump, A/C compressor, transmission, transfer case (if four-wheel-drive), differential(s) and universal joints, plus rolling resistance of the pneumatic tires.\n\nThe MPG of a given vehicle starts with the thermal efficiency of the fuel and engine, less all of the above elements of friction.\n\nThe MPGe metric was introduced in November 2010 by EPA in the Monroney label of the Nissan Leaf electric car and the Chevrolet Volt plug-in hybrid. The ratings are based on EPA's formula, in which 33.7 kilowatt hours of electricity is equivalent to one gallon of gasoline, and the energy consumption of each vehicle during simulating varying driving conditions. All new cars and light-duty trucks sold in the U.S. are required to have this label showing the EPA's estimate of fuel economy of the vehicle.\n\n"}
{"id": "12240", "url": "https://en.wikipedia.org/wiki?curid=12240", "title": "Gold", "text": "Gold\n\nGold is a chemical element with symbol Au (from ) and atomic number 79, making it one of the higher atomic number elements that occur naturally. In its purest form, it is a bright, slightly reddish yellow, dense, soft, malleable, and ductile metal. Chemically, gold is a transition metal and a group 11 element. It is one of the least reactive chemical elements and is solid under standard conditions. Gold often occurs in free elemental (native) form, as nuggets or grains, in rocks, in veins, and in alluvial deposits. It occurs in a solid solution series with the native element silver (as electrum) and also naturally alloyed with copper and palladium. Less commonly, it occurs in minerals as gold compounds, often with tellurium (gold tellurides).\n\nGold is resistant to most acids, though it does dissolve in aqua regia, a mixture of nitric acid and hydrochloric acid, which forms a soluble tetrachloroaurate anion. Gold is insoluble in nitric acid, which dissolves silver and base metals, a property that has long been used to refine gold and to confirm the presence of gold in metallic objects, giving rise to the term \"acid test\". Gold also dissolves in alkaline solutions of cyanide, which are used in mining and electroplating. Gold dissolves in mercury, forming amalgam alloys, but this is not a chemical reaction.\n\nA relatively rare element, gold is a precious metal that has been used for coinage, jewelry, and other arts throughout recorded history. In the past, a gold standard was often implemented as a monetary policy, but gold coins ceased to be minted as a circulating currency in the 1930s, and the world gold standard was abandoned for a fiat currency system after 1971.\n\nA total of 186,700 tonnes of gold exists above ground, . The world consumption of new gold produced is about 50% in jewelry, 40% in investments, and 10% in industry. Gold's high malleability, ductility, resistance to corrosion and most other chemical reactions, and conductivity of electricity have led to its continued use in corrosion resistant electrical connectors in all types of computerized devices (its chief industrial use). Gold is also used in infrared shielding, colored-glass production, gold leafing, and tooth restoration. Certain gold salts are still used as anti-inflammatories in medicine. , the world's largest gold producer by far was China with 450 tonnes per year.\n\nGold is the most malleable of all metals; a single gram can be beaten into a sheet of 1 square meter, and an avoirdupois ounce into 300 square feet. Gold leaf can be beaten thin enough to become semi-transparent. The transmitted light appears greenish blue, because gold strongly reflects yellow and red. Such semi-transparent sheets also strongly reflect infrared light, making them useful as infrared (radiant heat) shields in visors of heat-resistant suits, and in sun-visors for spacesuits. Gold is a good conductor of heat and electricity.\n\nGold has a density of 19.3 g/cm, almost identical to that of tungsten at 19.25 g/cm; as such, tungsten has been used in counterfeiting of gold bars, such as by plating a tungsten bar with gold, or taking an existing gold bar, drilling holes, and replacing the removed gold with tungsten rods. By comparison, the density of lead is 11.34 g/cm, and that of the densest element, osmium, is .\n\nWhereas most metals are gray or silvery white, gold is slightly reddish-yellow. This color is determined by the frequency of plasma oscillations among the metal's valence electrons, in the ultraviolet range for most metals but in the visible range for gold due to relativistic effects affecting the orbitals around gold atoms. Similar effects impart a golden hue to metallic caesium.\n\nCommon colored gold alloys include the distinctive eighteen-karat rose gold created by the addition of copper. Alloys containing palladium or nickel are also important in commercial jewelry as these produce white gold alloys. Fourteen-karat gold-copper alloy is nearly identical in color to certain bronze alloys, and both may be used to produce police and other badges. White gold alloys can be made with palladium or nickel. Fourteen- and eighteen-karat gold alloys with silver alone appear greenish-yellow and are referred to as green gold. Blue gold can be made by alloying with iron, and purple gold can be made by alloying with aluminium. Less commonly, addition of manganese, aluminium, indium and other elements can produce more unusual colors of gold for various applications.\n\nColloidal gold, used by electron-microscopists, is red if the particles are small; larger particles of colloidal gold are blue.\n\nGold has only one stable isotope, , which is also its only naturally occurring isotope, so gold is both a mononuclidic and monoisotopic element. Thirty-six radioisotopes have been synthesized, ranging in atomic mass from 169 to 205. The most stable of these is with a half-life of 186.1 days. The least stable is , which decays by proton emission with a half-life of 30 µs. Most of gold's radioisotopes with atomic masses below 197 decay by some combination of proton emission, α decay, and β decay. The exceptions are , which decays by electron capture, and , which decays most often by electron capture (93%) with a minor β decay path (7%). All of gold's radioisotopes with atomic masses above 197 decay by β decay.\n\nAt least 32 nuclear isomers have also been characterized, ranging in atomic mass from 170 to 200. Within that range, only , , , , and do not have isomers. Gold's most stable isomer is with a half-life of 2.27 days. Gold's least stable isomer is with a half-life of only 7 ns. has three decay paths: β decay, isomeric transition, and alpha decay. No other isomer or isotope of gold has three decay paths.\n\nThe production of gold from a more common element, such as lead, has long been a subject of human inquiry, and the ancient and medieval discipline of alchemy often focused on it; however, the transmutation of the chemical elements did not become possible until the understanding of nuclear physics in the 20th century. The first synthesis of gold was conducted by Japanese physicist Hantaro Nagaoka, who synthesized gold from mercury in 1924 by neutron bombardment. An American team, working without knowledge of Nagaoka's prior study, conducted the same experiment in 1941, achieving the same result and showing that the isotopes of gold produced by it were all radioactive.\n\nGold can currently be manufactured in a nuclear reactor by irradiation either of platinum or mercury.\n\nOnly the mercury isotope Hg, which occurs with a frequency of 0.15% in natural mercury, can be converted to gold by neutron capture, and following electron capture-decay into Au with slow neutrons. Other mercury isotopes are converted when irradiated with slow neutrons into one another, or formed mercury isotopes which beta decay into thallium.\n\nUsing fast neutrons, the mercury isotope Hg, which composes 9.97% of natural mercury, can be converted by splitting off a neutron and becoming Hg, which then disintegrates to stable gold. This reaction, however, possesses a smaller activation cross-section and is feasible only with un-moderated reactors.\n\nIt is also possible to eject several neutrons with very high energy into the other mercury isotopes in order to form Hg. However, such high-energy neutrons can be produced only by particle accelerators.\n\nAlthough gold is the most noble of the noble metals, it still forms many diverse compounds. The oxidation state of gold in its compounds ranges from −1 to +5, but Au(I) and Au(III) dominate its chemistry. Au(I), referred to as the aurous ion, is the most common oxidation state with soft ligands such as thioethers, thiolates, and tertiary phosphines. Au(I) compounds are typically linear. A good example is Au(CN), which is the soluble form of gold encountered in mining. The binary gold halides, such as AuCl, form zigzag polymeric chains, again featuring linear coordination at Au. Most drugs based on gold are Au(I) derivatives.\n\nAu(III) (auric) is a common oxidation state, and is illustrated by gold(III) chloride, AuCl. The gold atom centers in Au(III) complexes, like other d compounds, are typically square planar, with chemical bonds that have both covalent and ionic character.\n\nGold does not react with oxygen at any temperature and, up to 100 °C, is resistant to attack from ozone.\n\nSome free halogens react with gold. Gold is strongly attacked by fluorine at dull-red heat to form gold(III) fluoride. Powdered gold reacts with chlorine at 180 °C to form AuCl. Gold reacts with bromine at 140 °C to form gold(III) bromide, but reacts only very slowly with iodine to form the monoiodide.\n\nGold does not react with sulfur directly, but gold(III) sulfide can be made by passing hydrogen sulfide through a dilute solution of gold(III) chloride or chlorauric acid.\n\nGold readily dissolves in mercury at room temperature to form an amalgam, and forms alloys with many other metals at higher temperatures. These alloys can be produced to modify the hardness and other metallurgical properties, to control melting point or to create exotic colors.\n\nGold is unaffected by most acids. It does not react with hydrofluoric, hydrochloric, hydrobromic, hydriodic, sulfuric, or nitric acid. It does react with selenic acid, and is dissolved by aqua regia, a 1:3 mixture of nitric acid and hydrochloric acid. Nitric acid oxidizes the metal to +3 ions, but only in minute amounts, typically undetectable in the pure acid because of the chemical equilibrium of the reaction. However, the ions are removed from the equilibrium by hydrochloric acid, forming AuCl ions, or chloroauric acid, thereby enabling further oxidation.\n\nGold is similarly unaffected by most bases. It does not react with aqueous, solid, or molten sodium or potassium hydroxide. It does however, react with sodium or potassium cyanide under alkaline conditions when oxygen is present to form soluble complexes.\n\nCommon oxidation states of gold include +1 (gold(I) or aurous compounds) and +3 (gold(III) or auric compounds). Gold ions in solution are readily reduced and precipitated as metal by adding any other metal as the reducing agent. The added metal is oxidized and dissolves, allowing the gold to be displaced from solution and be recovered as a solid precipitate.\n\nLess common oxidation states of gold include −1, +2, and +5.\n\nThe −1 oxidation state occurs in aurides, compounds containing the Au anion. Caesium auride (CsAu), for example, crystallizes in the caesium chloride motif; rubidium, potassium, and tetramethylammonium aurides are also known. Gold has the highest electron affinity of any metal, at 222.8 kJ/mol, making Au a stable species.\n\nGold(II) compounds are usually diamagnetic with Au–Au bonds such as [Au(CH)P(CH)]Cl. The evaporation of a solution of in concentrated produces red crystals of gold(II) sulfate, Au(SO). Originally thought to be a mixed-valence compound, it has been shown to contain cations, analogous to the better-known mercury(I) ion, . A gold(II) complex, the tetraxenonogold(II) cation, which contains xenon as a ligand, occurs in [AuXe](SbF).\n\nGold pentafluoride, along with its derivative anion, , and its difluorine complex, gold heptafluoride, is the sole example of gold(V), the highest verified oxidation state.\n\nSome gold compounds exhibit \"aurophilic bonding\", which describes the tendency of gold ions to interact at distances that are too long to be a conventional Au–Au bond but shorter than van der Waals bonding. The interaction is estimated to be comparable in strength to that of a hydrogen bond.\n\nWell-defined cluster compounds are numerous. In such cases, gold has a fractional oxidation state. A representative example is the octahedral species {Au(P(CH))}. Gold chalcogenides, such as gold sulfide, feature equal amounts of Au(I) and Au(III).\n\nMedicinal applications of gold and its complexes have a long history dating back thousands of years. Several gold complexes have been applied to treat rheumatoid arthritis, the most frequently used are: aurothiomalate, aurothioglucose, and auranofin. Both gold(I) and gold(III) compounds have been have been investigated as possible anti-cancer drugs. For gold(III) complexes, reduction to gold(0/I) under physiological conditions has to be considered. Stable complexes can be generated using different types of bi-, tri-, and tetradentate ligand systems and their high efficacy has been demonstrated in vitro and in vivo.\n\nIn 2017, an international group of scientists, including José María González Jiménez and Ramón y Cajalan, in cooperation with the University of Granada and other universities, while researching the origins of gold, historically established that it \"came to the Earth's surface from the deepest regions of our planet,\" Earth's mantle, evidenced by their findings at Deseado Massif in the Argentinian Patagonia.\n\nGold is thought to have been produced in supernova nucleosynthesis, and from the collision of neutron stars, and to have been present in the dust from which the Solar System formed. Because the Earth was molten when it was formed, almost all of the gold present in the early Earth probably sank into the planetary core. Therefore, most of the gold that is in the Earth's crust and mantle is thought to have been delivered to Earth later, by asteroid impacts during the Late Heavy Bombardment, about 4 billion years ago.\n\nTraditionally, gold is thought to have formed by the r-process (rapid neutron capture) in supernova nucleosynthesis, but more recently it has been suggested that gold and other elements heavier than iron may also be produced in quantity by the r-process in the collision of neutron stars. In both cases, satellite spectrometers only indirectly detected the resulting gold: \"we have no spectroscopic evidence that [such] elements have truly been produced,\" wrote author Stephan Rosswog. However, in August 2017, the signatures of heavy elements, including gold, were observed by gravitational wave detectors and other electromagnetic observatories in the GW170817 neutron star merger event. Current astrophysical models suggest that single neutron star merger event generated between 3 and 13 Earth masses of gold.\n\nThe asteroid that formed Vredefort crater 2.020 billion years ago is often credited with seeding the Witwatersrand basin in South Africa with the richest gold deposits on earth. However, the gold-bearing Witwatersrand rocks were laid down between 700 and 950 million years before the Vredefort impact. These gold-bearing rocks had furthermore been covered by a thick layer of Ventersdorp lavas and the Transvaal Supergroup of rocks before the meteor struck. What the Vredefort impact achieved, however, was to distort the Witwatersrand basin in such a way that the gold-bearing rocks were brought to the present erosion surface in Johannesburg, on the Witwatersrand, just inside the rim of the original 300 km diameter crater caused by the meteor strike. The discovery of the deposit in 1886 launched the Witwatersrand Gold Rush. Some 22% of all the gold that is ascertained to exist today on Earth has been extracted from these Witwatersrand rocks.\n\nOn Earth, gold is found in ores in rock formed from the Precambrian time onward. It most often occurs as a native metal, typically in a metal solid solution with silver (i.e. as a gold silver alloy). Such alloys usually have a silver content of 8–10%. Electrum is elemental gold with more than 20% silver. Electrum's color runs from golden-silvery to silvery, dependent upon the silver content. The more silver, the lower the specific gravity.\n\nNative gold occurs as very small to microscopic particles embedded in rock, often together with quartz or sulfide minerals such as \"Fool's Gold\", which is a pyrite. These are called lode deposits. The metal in a native state is also found in the form of free flakes, grains or larger nuggets that have been eroded from rocks and end up in alluvial deposits called placer deposits. Such free gold is always richer at the surface of gold-bearing veins owing to the oxidation of accompanying minerals followed by weathering, and washing of the dust into streams and rivers, where it collects and can be welded by water action to form nuggets.\n\nGold sometimes occurs combined with tellurium as the minerals calaverite, krennerite, nagyagite, petzite and sylvanite (see telluride minerals), and as the rare bismuthide maldonite (AuBi) and antimonide aurostibite (AuSb). Gold also occurs in rare alloys with copper, lead, and mercury: the minerals auricupride (CuAu), novodneprite (AuPb) and weishanite ((Au, Ag)Hg).\n\nRecent research suggests that microbes can sometimes play an important role in forming gold deposits, transporting and precipitating gold to form grains and nuggets that collect in alluvial deposits.\n\nAnother recent study has claimed water in faults vaporizes during an earthquake, depositing gold. When an earthquake strikes, it moves along a fault. Water often lubricates faults, filling in fractures and jogs. About 6 miles (10 kilometers) below the surface, under incredible temperatures and pressures, the water carries high concentrations of carbon dioxide, silica, and gold. During an earthquake, the fault jog suddenly opens wider. The water inside the void instantly vaporizes, flashing to steam and forcing silica, which forms the mineral quartz, and gold out of the fluids and onto nearby surfaces.\n\nThe world's oceans contain gold. Measured concentrations of gold in the Atlantic and Northeast Pacific are 50–150 femtomol/L or 10–30 parts per quadrillion (about 10–30 g/km). In general, gold concentrations for south Atlantic and central Pacific samples are the same (~50 femtomol/L) but less certain. Mediterranean deep waters contain slightly higher concentrations of gold (100–150 femtomol/L) attributed to wind-blown dust and/or rivers. At 10 parts per quadrillion the Earth's oceans would hold 15,000 tonnes of gold. These figures are three orders of magnitude less than reported in the literature prior to 1988, indicating contamination problems with the earlier data.\n\nA number of people have claimed to be able to economically recover gold from sea water, but they were either mistaken or acted in an intentional deception. Prescott Jernegan ran a gold-from-seawater swindle in the United States in the 1890s, as did an English fraudster in the early 1900s. Fritz Haber did research on the extraction of gold from sea water in an effort to help pay Germany's reparations following World War I. Based on the published values of 2 to 64 ppb of gold in seawater a commercially successful extraction seemed possible. After analysis of 4,000 water samples yielding an average of 0.004 ppb it became clear that extraction would not be possible and he stopped the project.\n\nAs of 1990, gold artifacts found at the Nahal Qana cave cemetery of the 4th millennium BC were the earliest from the Levant. Gold artifacts in the Balkans also appear from the 4th millennium BC, such as those found in the Varna Necropolis near Lake Varna in Bulgaria, thought by one source (La Niece 2009) to be the earliest \"well-dated\" find of gold artifacts. Gold artifacts such as the golden hats and the Nebra disk appeared in Central Europe from the 2nd millennium BC Bronze Age.\n\nThe oldest known map of a gold mine was drawn in the 19th Dynasty of Ancient Egypt (1320–1200 BC), whereas the first written reference to gold was recorded in the 12th Dynasty around 1900 BC. Egyptian hieroglyphs from as early as 2600 BC describe gold, which King Tushratta of the Mitanni claimed was \"more plentiful than dirt\" in Egypt. Egypt and especially Nubia had the resources to make them major gold-producing areas for much of history. One of the earliest known maps, known as the Turin Papyrus Map, shows the plan of a gold mine in Nubia together with indications of the local geology. The primitive working methods are described by both Strabo and Diodorus Siculus, and included fire-setting. Large mines were also present across the Red Sea in what is now Saudi Arabia.\nGold is mentioned in the Amarna letters numbered 19 and 26 from around the 14th century BC.\n\nGold is mentioned frequently in the Old Testament, starting with Genesis 2:11 (at Havilah), the story of The Golden Calf and many parts of the temple including the Menorah and the golden altar. In the New Testament, it is included with the gifts of the magi in the first chapters of Matthew. The Book of Revelation 21:21 describes the city of New Jerusalem as having streets \"made of pure gold, clear as crystal\". Exploitation of gold in the south-east corner of the Black Sea is said to date from the time of Midas, and this gold was important in the establishment of what is probably the world's earliest coinage in Lydia around 610 BC. The legend of the golden fleece dating from eighth century BCE may refer to the use of fleeces to trap gold dust from placer deposits in the ancient world. From the 6th or 5th century BC, the Chu (state) circulated the Ying Yuan, one kind of square gold coin.\n\nIn Roman metallurgy, new methods for extracting gold on a large scale were developed by introducing hydraulic mining methods, especially in Hispania from 25 BC onwards and in Dacia from 106 AD onwards. One of their largest mines was at Las Medulas in León, where seven long aqueducts enabled them to sluice most of a large alluvial deposit. The mines at Roşia Montană in Transylvania were also very large, and until very recently, still mined by opencast methods. They also exploited smaller deposits in Britain, such as placer and hard-rock deposits at Dolaucothi. The various methods they used are well described by Pliny the Elder in his encyclopedia \"Naturalis Historia\" written towards the end of the first century AD.\n\nDuring Mansa Musa's (ruler of the Mali Empire from 1312 to 1337) hajj to Mecca in 1324, he passed through Cairo in July 1324, and was reportedly accompanied by a camel train that included thousands of people and nearly a hundred camels where he gave away so much gold that it depressed the price in Egypt for over a decade, causing high inflation. A contemporary Arab historian remarked:\n\nThe European exploration of the Americas was fueled in no small part by reports of the gold ornaments displayed in great profusion by Native American peoples, especially in Mesoamerica, Peru, Ecuador and Colombia. The Aztecs regarded gold as the product of the gods, calling it literally \"god excrement\" (\"teocuitlatl\" in Nahuatl), and after Moctezuma II was killed, most of this gold was shipped to Spain. However, for the indigenous peoples of North America gold was considered useless and they saw much greater value in other minerals which were directly related to their utility, such as obsidian, flint, and slate. Rumors of cities filled with gold fueled legends of El Dorado.\n\nGold played a role in western culture, as a cause for desire and of corruption, as told in children's fables such as Rumpelstiltskin—where Rumpelstiltskin turns hay into gold for the peasant's daughter in return for her child when she becomes a princess—and the stealing of the hen that lays golden eggs in Jack and the Beanstalk.\n\nThe top prize at the Olympic Games and many other sports competitions is the gold medal.\n\n75% of the presently accounted for gold has been extracted since 1910. It has been estimated that the currently known amount of gold internationally would form a single cube 20 m (66 ft) on a side (equivalent to 8,000 m).\n\nOne main goal of the alchemists was to produce gold from other substances, such as lead — presumably by the interaction with a mythical substance called the philosopher's stone. Although they never succeeded in this attempt, the alchemists did promote an interest in systematically finding out what can be done with substances, and this laid the foundation for today's chemistry. Their symbol for gold was the circle with a point at its center (☉), which was also the astrological symbol and the ancient Chinese character for the Sun.\n\nGolden treasures have been rumored to be found at various locations, following tragedies such as the Jewish temple treasures in the Vatican, following the temple's destruction in 70 AD, a gold stash on the \"Titanic\", the Nazi gold train – following World War II.\n\nThe Dome of the Rock is covered with an ultra-thin golden glassier. The Sikh Golden temple, the Harmandir Sahib, is a building covered with gold. Similarly the Wat Phra Kaew emerald Buddhist temple (wat) in Thailand has ornamental gold-leafed statues and roofs. Some European king and queen's crowns were made of gold, and gold was used for the bridal crown since antiquity. An ancient Talmudic text circa 100 AD describes Rachel, wife of Rabbi Akiva, receiving a \"Jerusalem of Gold\" (diadem). A Greek burial crown made of gold was found in a grave circa 370 BC.\n\n\"Gold\" is cognate with similar words in many Germanic languages, deriving via Proto-Germanic *\"gulþą\" from Proto-Indo-European *\"ǵʰelh₃-\" (\"to shine, to gleam; to be yellow or green\").\n\nThe symbol \"Au\" is from the , the Latin word for \"gold\". The Proto-Indo-European ancestor of \"aurum\" was \"*h₂é-h₂us-o-\", meaning \"glow\". This word is derived from the same root (Proto-Indo-European \"*h₂u̯es-\" \"to dawn\") as \"*h₂éu̯sōs\", the ancestor of the Latin word Aurora, \"dawn\". This etymological relationship is presumably behind the frequent claim in scientific publications that \"aurum\" meant \"shining dawn\".\n\nOutside chemistry, gold is mentioned in a variety of expressions, most often associated with intrinsic worth. Great human achievements are frequently rewarded with gold, in the form of gold medals, gold trophies and other decorations. Winners of athletic events and other graded competitions are usually awarded a gold medal. Many awards such as the Nobel Prize are made from gold as well. Other award statues and prizes are depicted in gold or are gold plated (such as the Academy Awards, the Golden Globe Awards, the Emmy Awards, the Palme d'Or, and the British Academy Film Awards).\n\nAristotle in his ethics used gold symbolism when referring to what is now known as the golden mean. Similarly, gold is associated with perfect or divine principles, such as in the case of the golden ratio and the golden rule.\n\nGold is further associated with the wisdom of aging and fruition. The fiftieth wedding anniversary is golden. A person's most valued or most successful latter years are sometimes considered \"golden years\". The height of a civilization is referred to as a golden age.\n\nIn some forms of Christianity and Judaism, gold has been associated both with holiness and evil. In the Book of Exodus, the Golden Calf is a symbol of idolatry, while in the Book of Genesis, Abraham was said to be rich in gold and silver, and Moses was instructed to cover the Mercy Seat of the Ark of the Covenant with pure gold. In Byzantine iconography the halos of Christ, Mary and the Christian saints are often golden.\n\nAccording to Christopher Columbus, those who had something of gold were in possession of something of great value on Earth and a substance to even help souls to paradise.\n\nWedding rings have been made of gold. It is long lasting and unaffected by the passage of time and may aid in the ring symbolism of eternal vows before God and the perfection the marriage signifies. In Orthodox Christian wedding ceremonies, the wedded couple is adorned with a golden crown (though some opt for wreaths, instead) during the ceremony, an amalgamation of symbolic rites.\n\nThe World Gold Council states that as of the end of 2017, \"there were 187,200 tonnes of stocks in existence above ground\". This can be represented by a cube with an edge length of about 21 meters. At $1,349 per troy ounce, 187,200 metric tonnes of gold would have a value of $8.9 trillion.\n\n, the world's largest gold producer by far was China with 455 tonnes. The second-largest producer, Australia, mined 270 tonnes in the same year, followed by Russia with 250 tonnes.\n\nSince the 1880s, South Africa has been the source of a large proportion of the world's gold supply, and about 50% of the gold presently accounted is from South Africa. Production in 1970 accounted for 79% of the world supply, about 1,480 tonnes. In 2007 China (with 276 tonnes) overtook South Africa as the world's largest gold producer, the first time since 1905 that South Africa has not been the largest.\n\n, China was the world's leading gold-mining country, followed in order by Australia, Russia, the United States, Canada, and Peru. South Africa, which had dominated world gold production for most of the 20th century, had declined to sixth place. Other major producers are the Ghana, Burkina Faso, Mali, Indonesia and Uzbekistan.\nIn South America, the controversial project Pascua Lama aims at exploitation of rich fields in the high mountains of Atacama Desert, at the border between Chile and Argentina.\n\nToday about one-quarter of the world gold output is estimated to originate from artisanal or small scale mining.\n\nThe city of Johannesburg located in South Africa was founded as a result of the Witwatersrand Gold Rush which resulted in the discovery of some of the largest natural gold deposits in recorded history. The gold fields are confined to the northern and north-western edges of the Witwatersrand basin, which is a 5–7 km thick layer of archean rocks located, in most places, deep under the Free State, Gauteng and surrounding provinces. These Witwatersrand rocks are exposed at the surface on the Witwatersrand, in and around Johannesburg, but also in isolated patches to the south-east and south-west of Johannesburg, as well as in an arc around the Vredefort Dome which lies close to the center of the Witwatersrand basin. From these surface exposures the basin dips extensively, requiring some of the mining to occur at depths of nearly 4000 m, making them, especially the Savuka and TauTona mines to the south-west of Johannesburg, the deepest mines on earth. The gold is found only in six areas where archean rivers from the north and north-west formed extensive pebbly Braided river deltas before draining into the \"Witwatersrand sea\" where the rest of the Witwatersrand sediments were deposited.\n\nThe Second Boer War of 1899–1901 between the British Empire and the Afrikaner Boers was at least partly over the rights of miners and possession of the gold wealth in South Africa.\n\nDuring the 19th century, gold rushes occurred whenever large gold deposits were discovered. The first documented discovery of gold in the United States was at the Reed Gold Mine near Georgeville, North Carolina in 1803. The first major gold strike in the United States occurred in a small north Georgia town called Dahlonega. Further gold rushes occurred in California, Colorado, the Black Hills, Otago in New Zealand, Australia, Witwatersrand in South Africa, and the Klondike in Canada.\n\nGold extraction is most economical in large, easily mined deposits. Ore grades as little as 0.5 parts per million (ppm) can be economical. Typical ore grades in open-pit mines are 1–5 ppm; ore grades in underground or hard rock mines are usually at least 3 ppm. Because ore grades of 30 ppm are usually needed before gold is visible to the naked eye, in most gold mines the gold is invisible.\n\nThe average gold mining and extraction costs were about $317 per troy ounce in 2007, but these can vary widely depending on mining type and ore quality; global mine production amounted to 2,471.1 tonnes.\n\nAfter initial production, gold is often subsequently refined industrially by the Wohlwill process which is based on electrolysis or by the Miller process, that is chlorination in the melt. The Wohlwill process results in higher purity, but is more complex and is only applied in small-scale installations. Other methods of assaying and purifying smaller amounts of gold include parting and inquartation as well as cupellation, or refining methods based on the dissolution of gold in aqua regia.\n\nThe consumption of gold produced in the world is about 50% in jewelry, 40% in investments, and 10% in industry.\n\nAccording to World Gold Council, China is the world's largest single consumer of gold in 2013 and toppled India for the first time with Chinese consumption increasing by 32 percent in a year, while that of India only rose by 13 percent and world consumption rose by 21 percent. Unlike India where gold is mainly used for jewelry, China uses gold for manufacturing and retail.\n\nGold production is associated with contribution to hazardous pollution.\n\nLow-grade gold ore may contain less than one ppm gold metal; such ore is ground and mixed with sodium cyanide to dissolve the gold. Cyanide is a highly poisonous chemical, which can kill living creatures when exposed in minute quantities. Many cyanide spills from gold mines have occurred in both developed and developing countries which killed aquatic life in long stretches of affected rivers. Environmentalists consider these events major environmental disasters. Thirty tons of used ore is dumped as waste for producing one troy ounce of gold. Gold ore dumps are the source of many heavy elements such as cadmium, lead, zinc, copper, arsenic, selenium and mercury. When sulfide-bearing minerals in these ore dumps are exposed to air and water, the sulfide transforms into sulfuric acid which in turn dissolves these heavy metals facilitating their passage into surface water and ground water. This process is called acid mine drainage. These gold ore dumps are long term, highly hazardous wastes second only to nuclear waste dumps.\n\nIt was once common to use mercury to recover gold from ore, but today the use of mercury is largely limited to small-scale individual miners. Minute quantities of mercury compounds can reach water bodies, causing heavy metal contamination. Mercury can then enter into the human food chain in the form of methylmercury. Mercury poisoning in humans causes incurable brain function damage and severe retardation.\n\nGold extraction is also a highly energy intensive industry, extracting ore from deep mines and grinding the large quantity of ore for further chemical extraction requires nearly 25 kWh of electricity per gram of gold produced.\n\nGold has been widely used throughout the world as money, for efficient indirect exchange (versus barter), and to store wealth in hoards. For exchange purposes, mints produce standardized gold bullion coins, bars and other units of fixed weight and purity.\n\nThe first known coins containing gold were struck in Lydia, Asia Minor, around 600 BC. The \"talent\" coin of gold in use during the periods of Grecian history both before and during the time of the life of Homer weighed between 8.42 and 8.75 grams. From an earlier preference in using silver, European economies re-established the minting of gold as coinage during the thirteenth and fourteenth centuries.\n\nBills (that mature into gold coin) and gold certificates (convertible into gold coin at the issuing bank) added to the circulating stock of gold standard money in most 19th century industrial economies.\nIn preparation for World War I the warring nations moved to fractional gold standards, inflating their currencies to finance the war effort.\nPost-war, the victorious countries, most notably Britain, gradually restored gold-convertibility, but international flows of gold via bills of exchange remained embargoed; international shipments were made exclusively for bilateral trades or to pay war reparations.\n\nAfter World War II gold was replaced by a system of nominally convertible currencies related by fixed exchange rates following the Bretton Woods system. Gold standards and the direct convertibility of currencies to gold have been abandoned by world governments, led in 1971 by the United States' refusal to redeem its dollars in gold. Fiat currency now fills most monetary roles. Switzerland was the last country to tie its currency to gold; it backed 40% of its value until the Swiss joined the International Monetary Fund in 1999.\n\nCentral banks continue to keep a portion of their liquid reserves as gold in some form, and metals exchanges such as the London Bullion Market Association still clear transactions denominated in gold, including future delivery contracts.\nToday, gold mining output is declining.\nWith the sharp growth of economies in the 20th century, and increasing foreign exchange, the world's gold reserves and their trading market have become a small fraction of all markets and fixed exchange rates of currencies to gold have been replaced by floating prices for gold and gold future contract.\nThough the gold stock grows by only 1 or 2% per year, very little metal is irretrievably consumed. Inventory above ground would satisfy many decades of industrial and even artisan uses at current prices.\n\nThe gold proportion (fineness) of alloys is measured by karat (k). Pure gold (commercially termed \"fine\" gold) is designated as 24 karat, abbreviated 24k. English gold coins intended for circulation from 1526 into the 1930s were typically a standard 22k alloy called crown gold, for hardness (American gold coins for circulation after 1837 contain an alloy of 0.900 fine gold, or 21.6 kt).\n\nAlthough the prices of some platinum group metals can be much higher, gold has long been considered the most desirable of precious metals, and its value has been used as the standard for many currencies. Gold has been used as a symbol for purity, value, royalty, and particularly roles that combine these properties. Gold as a sign of wealth and prestige was ridiculed by Thomas More in his treatise \"Utopia\". On that imaginary island, gold is so abundant that it is used to make chains for slaves, tableware, and lavatory seats. When ambassadors from other countries arrive, dressed in ostentatious gold jewels and badges, the Utopians mistake them for menial servants, paying homage instead to the most modestly dressed of their party.\n\nThe ISO 4217 currency code of gold is XAU. Many holders of gold store it in form of bullion coins or bars as a hedge against inflation or other economic disruptions, though its efficacy as such has been questioned; historically, it has not proven itself reliable as a hedging instrument.. Modern bullion coins for investment or collector purposes do not require good mechanical wear properties; they are typically fine gold at 24k, although the American Gold Eagle and the British gold sovereign continue to be minted in 22k (0.92) metal in historical tradition, and the South African Krugerrand, first released in 1967, is also 22k (0.92).\n\nThe \"special issue\" Canadian Gold Maple Leaf coin contains the highest purity gold of any bullion coin, at 99.999% or 0.99999, while the \"popular issue\" Canadian Gold Maple Leaf coin has a purity of 99.99%. In 2006, the United States Mint began producing the American Buffalo gold bullion coin with a purity of 99.99%. The Australian Gold Kangaroos were first coined in 1986 as the Australian Gold Nugget but changed the reverse design in 1989. Other modern coins include the Austrian Vienna Philharmonic bullion coin and the Chinese Gold Panda.\n\n, gold is valued at around $42 per gram ($1,300 per troy ounce).\n\nLike other precious metals, gold is measured by troy weight and by grams. The proportion of gold in the alloy is measured by \"karat\" (k), with 24 karat (24k) being pure gold, and lower karat numbers proportionally less. The purity of a gold bar or coin can also be expressed as a decimal figure ranging from 0 to 1, known as the millesimal fineness, such as 0.995 being nearly pure.\n\nThe price of gold is determined through trading in the gold and derivatives markets, but a procedure known as the Gold Fixing in London, originating in September 1919, provides a daily benchmark price to the industry. The afternoon fixing was introduced in 1968 to provide a price when US markets are open.\n\nHistorically gold coinage was widely used as currency; when paper money was introduced, it typically was a receipt redeemable for gold coin or bullion. In a monetary system known as the gold standard, a certain weight of gold was given the name of a unit of currency. For a long period, the United States government set the value of the US dollar so that one troy ounce was equal to $20.67 ($0.665 per gram), but in 1934 the dollar was devalued to $35.00 per troy ounce ($0.889/g). By 1961, it was becoming hard to maintain this price, and a pool of US and European banks agreed to manipulate the market to prevent further currency devaluation against increased gold demand.\n\nOn March 17, 1968, economic circumstances caused the collapse of the gold pool, and a two-tiered pricing scheme was established whereby gold was still used to settle international accounts at the old $35.00 per troy ounce ($1.13/g) but the price of gold on the private market was allowed to fluctuate; this two-tiered pricing system was abandoned in 1975 when the price of gold was left to find its free-market level. Central banks still hold historical gold reserves as a store of value although the level has generally been declining. The largest gold depository in the world is that of the U.S. Federal Reserve Bank in New York, which holds about 3% of the gold known to exist and accounted for today, as does the similarly laden U.S. Bullion Depository at Fort Knox.\nIn 2005 the World Gold Council estimated total global gold supply to be 3,859 tonnes and demand to be 3,754 tonnes, giving a surplus of 105 tonnes.\n\nAfter the August 15, 1971 Nixon shock, the price began to greatly increase, and between 1968 and 2000 the price of gold ranged widely, from a high of $850 per troy ounce ($27.33/g) on January 21, 1980, to a low of $252.90 per troy ounce ($8.13/g) on June 21, 1999 (London Gold Fixing). Prices increased rapidly from 2001, but the 1980 high was not exceeded until January 3, 2008, when a new maximum of $865.35 per troy ounce was set. Another record price was set on March 17, 2008, at $1023.50 per troy ounce ($32.91/g).\n\nIn late 2009, gold markets experienced renewed momentum upwards due to increased demand and a weakening US dollar. On December 2, 2009, gold reached a new high closing at $1,217.23. Gold further rallied hitting new highs in May 2010 after the European Union debt crisis prompted further purchase of gold as a safe asset. On March 1, 2011, gold hit a new all-time high of $1432.57, based on investor concerns regarding ongoing unrest in North Africa as well as in the Middle East.\n\nFrom April 2001 to August 2011, spot gold prices more than quintupled in value against the US dollar, hitting a new all-time high of $1,913.50 on August 23, 2011, prompting speculation that the long secular bear market had ended and a bull market had returned. However, the price then began a slow decline towards $1200 per troy ounce in late 2014 and 2015.\n\nBecause of the softness of pure (24k) gold, it is usually alloyed with base metals for use in jewelry, altering its hardness and ductility, melting point, color and other properties. Alloys with lower karat rating, typically 22k, 18k, 14k or 10k, contain higher percentages of copper or other base metals or silver or palladium in the alloy. Nickel is toxic, and its release from nickel white gold is controlled by legislation in Europe. Palladium-gold alloys are more expensive than those using nickel. High-karat white gold alloys are more resistant to corrosion than are either pure silver or sterling silver. The Japanese craft of Mokume-gane exploits the color contrasts between laminated colored gold alloys to produce decorative wood-grain effects.\n\nBy 2014, the gold jewelry industry was escalating despite a dip in gold prices. Demand in the first quarter of 2014 pushed turnover to $23.7 billion according to a World Gold Council report.\n\nGold solder is used for joining the components of gold jewelry by high-temperature hard soldering or brazing. If the work is to be of hallmarking quality, the gold solder alloy must match the fineness (purity) of the work, and alloy formulas are manufactured to color-match yellow and white gold. Gold solder is usually made in at least three melting-point ranges referred to as Easy, Medium and Hard. By using the hard, high-melting point solder first, followed by solders with progressively lower melting points, goldsmiths can assemble complex items with several separate soldered joints. Gold can also be made into thread and used in embroidery.\n\nOnly 10% of the world consumption of new gold produced goes to industry, but by far the most important industrial use for new gold is in fabrication of corrosion-free electrical connectors in computers and other electrical devices. For example, according to the World Gold Council, a typical cell phone may contain 50 mg of gold, worth about 50 cents. But since nearly one billion cell phones are produced each year, a gold value of 50 cents in each phone adds to $500 million in gold from just this application.\n\nThough gold is attacked by free chlorine, its good conductivity and general resistance to oxidation and corrosion in other environments (including resistance to non-chlorinated acids) has led to its widespread industrial use in the electronic era as a thin-layer coating on electrical connectors, thereby ensuring good connection. For example, gold is used in the connectors of the more expensive electronics cables, such as audio, video and USB cables. The benefit of using gold over other connector metals such as tin in these applications has been debated; gold connectors are often criticized by audio-visual experts as unnecessary for most consumers and seen as simply a marketing ploy. However, the use of gold in other applications in electronic sliding contacts in highly humid or corrosive atmospheres, and in use for contacts with a very high failure cost (certain computers, communications equipment, spacecraft, jet aircraft engines) remains very common.\n\nBesides sliding electrical contacts, gold is also used in electrical contacts because of its resistance to corrosion, electrical conductivity, ductility and lack of toxicity. Switch contacts are generally subjected to more intense corrosion stress than are sliding contacts. Fine gold wires are used to connect semiconductor devices to their packages through a process known as wire bonding.\n\nThe concentration of free electrons in gold metal is 5.91×10 cm. Gold is highly conductive to electricity, and has been used for electrical wiring in some high-energy applications (only silver and copper are more conductive per volume, but gold has the advantage of corrosion resistance). For example, gold electrical wires were used during some of the Manhattan Project's atomic experiments, but large high-current silver wires were used in the calutron isotope separator magnets in the project.\n\nIt is estimated that 16% of the world's gold and 22% of the world's silver is contained in electronic technology in Japan.\n\nMetallic and gold compounds have long been used for medicinal purposes. Gold, usually as the metal, is perhaps the most anciently administered medicine (apparently by shamanic practitioners) and known to Dioscorides. In medieval times, gold was often seen as beneficial for the health, in the belief that something so rare and beautiful could not be anything but healthy. Even some modern esotericists and forms of alternative medicine assign metallic gold a healing power.\n\nIn the 19th century gold had a reputation as a \"nervine\", a therapy for nervous disorders. Depression, epilepsy, migraine, and glandular problems such as amenorrhea and impotence were treated, and most notably alcoholism (Keeley, 1897).\n\nThe apparent paradox of the actual toxicology of the substance suggests the possibility of serious gaps in the understanding of the action of gold in physiology. Only salts and radioisotopes of gold are of pharmacological value, since elemental (metallic) gold is inert to all chemicals it encounters inside the body (i.e., ingested gold cannot be attacked by stomach acid). Some gold salts do have anti-inflammatory properties and at present two are still used as pharmaceuticals in the treatment of arthritis and other similar conditions in the US (sodium aurothiomalate and auranofin). These drugs have been explored as a means to help to reduce the pain and swelling of rheumatoid arthritis, and also (historically) against tuberculosis and some parasites.\n\nGold alloys are used in restorative dentistry, especially in tooth restorations, such as crowns and permanent bridges. The gold alloys' slight malleability facilitates the creation of a superior molar mating surface with other teeth and produces results that are generally more satisfactory than those produced by the creation of porcelain crowns. The use of gold crowns in more prominent teeth such as incisors is favored in some cultures and discouraged in others.\n\nColloidal gold preparations (suspensions of gold nanoparticles) in water are intensely red-colored, and can be made with tightly controlled particle sizes up to a few tens of nanometers across by reduction of gold chloride with citrate or ascorbate ions. Colloidal gold is used in research applications in medicine, biology and materials science. The technique of immunogold labeling exploits the ability of the gold particles to adsorb protein molecules onto their surfaces. Colloidal gold particles coated with specific antibodies can be used as probes for the presence and position of antigens on the surfaces of cells. In ultrathin sections of tissues viewed by electron microscopy, the immunogold labels appear as extremely dense round spots at the position of the antigen.\n\nGold, or alloys of gold and palladium, are applied as conductive coating to biological specimens and other non-conducting materials such as plastics and glass to be viewed in a scanning electron microscope. The coating, which is usually applied by sputtering with an argon plasma, has a triple role in this application. Gold's very high electrical conductivity drains electrical charge to earth, and its very high density provides stopping power for electrons in the electron beam, helping to limit the depth to which the electron beam penetrates the specimen. This improves definition of the position and topography of the specimen surface and increases the spatial resolution of the image. Gold also produces a high output of secondary electrons when irradiated by an electron beam, and these low-energy electrons are the most commonly used signal source used in the scanning electron microscope.\n\nThe isotope gold-198 (half-life 2.7 days) is used, in nuclear medicine, in some cancer treatments and for treating other diseases.\n\n\n\nPure metallic (elemental) gold is non-toxic and non-irritating when ingested and is sometimes used as a food decoration in the form of gold leaf. Metallic gold is also a component of the alcoholic drinks Goldschläger, Gold Strike, and Goldwasser. Metallic gold is approved as a food additive in the EU (E175 in the Codex Alimentarius). Although the gold ion is toxic, the acceptance of metallic gold as a food additive is due to its relative chemical inertness, and resistance to being corroded or transformed into soluble salts (gold compounds) by any known chemical process which would be encountered in the human body.\n\nSoluble compounds (gold salts) such as gold chloride are toxic to the liver and kidneys. Common cyanide salts of gold such as potassium gold cyanide, used in gold electroplating, are toxic by virtue of both their cyanide and gold content. There are rare cases of lethal gold poisoning from potassium gold cyanide. Gold toxicity can be ameliorated with chelation therapy with an agent such as dimercaprol.\n\nGold metal was voted Allergen of the Year in 2001 by the American Contact Dermatitis Society, gold contact allergies affect mostly women. Despite this, gold is a relatively non-potent contact allergen, in comparison with metals like nickel.\n\nA sample of the fungus \"Aspergillus niger\" was found growing from gold mining solution; and was found to contain cyano metal complexes; such as gold, silver, copper iron and zinc. The fungus also plays a role in the solubilization of heavy metal sulfides.\n\n"}
{"id": "189424", "url": "https://en.wikipedia.org/wiki?curid=189424", "title": "Hot dark matter", "text": "Hot dark matter\n\nHot dark matter (HDM) is a theoretical form of dark matter which consists of particles that travel with ultrarelativistic velocities.\n\nDark matter is a form of matter that neither emits nor absorbs light. Within physics, this behavior is characterized by dark matter not interacting with electromagnetic radiation, hence making it \"dark\" and rendering it undetectable via conventional instruments in physics. Data from galaxy rotation curves indicate that approximately 80% of the mass of a galaxy cannot be seen, forcing researchers to innovate ways that \"indirectly\" detect it through dark matter's effects on gravitational fluctuations. There exists no consensus in the theoretical physics community as to whether dark matter is divisible into various 'types', but there exists evidence for differentiating dark matter into \"hot\" (HDM) and \"cold\" (CDM) types–some even suggesting a middle-ground of \"warm\" dark matter (WDM). The terminology is not meant to invoke any association with temperature, but instead refer to the \"size\" of the purported dark matter particles (WIMPs). In turn, the size of the particles determines the velocities at which they travel at in an inverse relationship: HDM travels faster than CDM because the HDM particles are theorized to be of lower mass.\n\nIn terms of its application, the distribution of Hot dark matter could also help explain how clusters and superclusters of galaxies formed after the Big Bang. Theorists claim that there exist two classes of dark matter: 1) those that \"congregate around individual members of a cluster of visible galaxies\" and 2) those that encompass \"the clusters as a whole.\" Because Cold dark matter possesses a lower velocity, it could be the source of \"smaller, galaxy-sized lumps,\" as shown in the image. Hot dark matter, then, should correspond to the formation of larger mass aggregates that surround whole galaxy clusters. However, data from the cosmic microwave background radiation, as measured by the COBE satellite, is highly uniform, and such high-velocity Hot dark matter particles cannot form clumps as small as galaxies beginning from such a smooth initial state, highlighting a discrepancy in what dark matter theory and the actual data are saying. Theoretically, in order to explain relatively small-scale structures in the observable Universe, it is necessary to invoke Cold dark matter or WDM. In other words, Hot dark matter being the sole substance in explaining cosmic galaxy formation is no longer viable, placing Hot dark matter under the larger umbrella of mixed dark matter (MDM) theory.\n\nAn example of a hot dark matter particle is the neutrino. Neutrinos have very small masses, and do not take part in two of the four fundamental forces, the electromagnetic interaction and the strong interaction. They interact by the weak interaction, and gravity, but due to the feeble strength of these forces, they are difficult to detect. A number of projects, such as the Super-Kamiokande neutrino observatory, in Gifu, Japan are currently studying these neutrinos.\n\n\n"}
{"id": "11748592", "url": "https://en.wikipedia.org/wiki?curid=11748592", "title": "Idle reduction", "text": "Idle reduction\n\nIdle reduction describes technologies and practices that minimize the amount of time drivers idle their engines. Avoiding idling time has a multitude of benefits including: savings in fuel and maintenance costs, extending vehicle life, and reducing damaging emissions. An idling engine consumes only enough power to keep itself and its accessories running, therefore, producing no usable power to the drive train.\n\nFor cargo ships, the need to run the ship's engines for power in port is eliminated by techniques collectively described as cold ironing. \n\nIdle reduction equipment is aimed at reducing the amount of energy wasted by idling trucks, rail locomotives or automobiles. When a vehicle's engine is not being used to move the vehicle, it can be shut off entirely — thereby conserving fuel and reducing emissions— while other functions like accessories and lighting are powered by an electrical source other than the vehicle's alternator. Each year, long-duration idling of truck and locomotive engines emits 11 million tons of carbon dioxide, 200,000 tons of oxides of nitrogen, and 5,000 tons of particulate matter into the air.\n\nThere are other technologies that can reduce the use of fuel to heat or cool the cab when the vehicle is traditionally idling overnight. These can be battery or fuel powered but in either case, use less fuel, do no harm to the vehicle's engine, and reduce or eliminate emissions. Other vehicles, including police, military, service trucks, news vans, fire trucks, ambulances, and hydraulic bucket trucks can be equipped with mobile power idle reduction systems, similar to a rechargeable battery. The systems are usually installed in the trunk and can provide up to 10 hours of additional power for equipment operation without engine engagement. When used by law enforcement and the military, idle reduction technology increases mission capability by extending operational time and providing increased situational awareness and safety.\n\nIdle reduction is a rapidly growing trend in US federal, state, local and fleet policy. Idling contributes significantly to the transportation sector’s portion of yearly greenhouse gas emissions. The US Department of Energy is putting forth a huge effort through the Energy Efficiency and Renewable Energy Program to increase public awareness about decreasing petroleum use; idle-reduction being one of the methods. The Alternative Fuels and Advanced Vehicles Data Center is a reliable resource for information regarding idle-reduction methods such as fuel-operated heaters, auxiliary power units and truck stop electrification.\n\nIn the public sector, idling is common. Police officers, public works employees, fire fighters, and EMTs who operate city fleet vehicles run them at idle to perform their duties which require them to operate equipment. The emissions generated from these tasks by cities all over the U.S. contribute to the fact that each year U.S. passenger cars, light trucks, medium-duty trucks, and heavy-duty vehicles consume more than 6 billion gallons of diesel fuel and gasoline — without even moving. As fuel prices continue to rise, a major challenge in fleet management is how to keep service vehicles on the road to serve the public while staying within budget. \n\nIdle reduction is particularly significant for vehicles in heavy traffic and trucks at the estimated 5,000 truck stops in the US. Many hybrid electric vehicles employ idle reduction to achieve better fuel economy in traffic. America's fleet of around 500,000 long-haul trucks consumes over a billion gallons (3.8×10 l; 830 million imp gal) of diesel fuel per year. The trucking industry has analyzed the impact of idling on engines, both in terms of maintenance and engine wear costs. Long-duration idling causes more oil and oil filter deterioration and increases the need for more oil and filter changes. Similarly, the longer the idling time, the sooner the engine itself will need to be rebuilt. The trucking industry estimates that long duration idling costs the truck owner $1.13 per day, based on the need for more frequent oil changes and sooner overhaul costs. Services such as AireDock, IdleAire and Shorepower provide power at truck stops to resting truckers who would otherwise need to continue idling during mandatory breaks. Because the United States Department of Transportation mandates that truckers rest for 10 hours after driving for 11 hours, truckers might park at truck stops for several hours. Often they idle their engines during this rest time to provide their sleeper compartments with air conditioning or heating or to run electrical appliances such as refrigerators or televisions. \n\nThe problem of anti-idling is most commonly associated with heavy duty diesel engines because they are the biggest contributors when idling. As an example of the need for idling an engine, school bus drivers on a cold morning may go out to their bus and turn it on to warm up the engine in order to provide direct heat to the cabin when they return to their bus to start their morning routes, which brings up two of the main reasons for idling, driver mentality and the need for passenger comfort. This idling period can be considered excessive, though excessive idling is defined and regulated differently in different parts of the country.\n\nPolicies at the federal level are more focused towards research and development of technologies, economic incentives, and education. The Department of Energy (DOE) is sponsoring several corporate companies in the R&D of new anti-idling technologies with the hope that this technology will be installed and incorporated in the assembly line or possibly at the dealer as an option. The Environmental Protection Agency (EPA) also has many ways to promote idle reduction. The EPA established the SmartWay Transport Partnership that provides information about available anti-idling technologies, possible strategies for idle reduction, and resources for obtaining financing on anti-idling projects. The program also serves as an EnergyStar-like program with a label available to companies that commit “to improve the environmental performance of their freight delivery operations.” The EPA has a national campaign called the Clean School Bus Campaign which works to reduce diesel fuel consumption in school buses across the nation. Several regions were awarded millions of dollars through grant projects including idle-reduction pilot projects.\n\nVarious states and localities have passed laws pertaining to idling. Some of the laws are more strict and stringent than others. Thirty-one states currently have some sort of existing regulations pertaining to anti-idling. Of these states, California has the most codes and regulations. The California Air Resources Board has enacted numerous laws that regulate idling in the state. For example, in Virginia, the excessive idling threshold is ten minutes, though, in many west coast states such as Hawaii and California, where there is a larger presence of greener policies in relation to fuel consumption, the thresholds are drastically smaller and may even have no idling tolerance at all. According to Hawaii Administrative Rules §11-60.1-34, no idling is permitted “while the motor vehicle is stationary at a loading zone, parking or servicing area, route terminal, or other off street areas” with a couple of exceptions. “Each year, long-duration idling of truck and locomotive engines consumes over of diesel fuel and emits 11 million tons of carbon dioxide, 200,000 tons of oxides of nitrogen, and 5,000 tons of particulate matter into the air.” \n\nAt the local level, there are many municipalities that have enacted anti-idling regulations. New York is an example of states making their idling policies more strict. In early 2009, New York Mayor Michael Bloomberg signed legislation that reduced the amount of time non-emergency vehicles could idle when they are located near schools. The new legislation reduced the allowed idling time from three minutes to one minute. In addition, the new law authorized the Department of Parks and Recreation and the Department of Sanitation to enforce the new idling laws. Previously, only the police department and the Department of Environmental Protection had this authority. Civilians are also allowed to report violations under the new law. In 2017, the City of Palo Alto began considering a proposal to stop drivers from running engines when parked.\n\nTruckers argue for the need for idling to keep their cabins comfortable overnight at truck stops. Further complaints have come from the lack of concurrence among state and local idling laws. This disparity in laws requires truckers travelling across the country to be aware of the local idling laws in every place they visit. Even consistency between state and local laws has been a concern. Some truckers have expressed concern that some idling laws could prevent them from complying with other laws, For example, laws requiring truckers to get a certain amount of uninterrupted rest might be interfered with by anti-idling laws. The transportation blog uShip.com, Ship Happens states that “[anti-idling] laws fail to consider the truckers well-being and place drivers at risk of debilitating fines for noncompliance.” These fines could run as high as $25,000 in Connecticut for idling for more than three minutes.\n\nUnnecessary vehicle idling is an offence against the Road Traffic (Vehicle Emissions) (Fixed Penalty) (England) Regulations (Statutory Instrument 2002 No. 1808). It is unclear whether Scotland, Wales and Northern Ireland have similar regulations.\n\nThe regulations apply in zones designated as Air quality management areas by local authorities.\nThe Department for Environment, Food and Rural Affairs has published a list of local authorities with air quality management areas.\n\nIn Europe, vehicle increasingly include a Start-stop system to prevent idling. \n\nHong Kong introduced an anti-idling bill in 2010.\n\nThere are a variety of reasons that bus drivers idle their engines. The majority of engine idling occurs in the morning, when drivers are warming up the engines and the passenger compartments. Part of the problem with excessive idling, other than the immense amount of fuel it uses, is driver mentality coming from lack of knowledge about the fuel consumption of an idling engine. Typically, a bus driver will turn on the bus when they wake up, then proceed to get ready for the day, creating a period of excessive idling of up to half an hour. The objective of fuel-operated heaters is to eliminate this specific need for idling, which in turn reduces fuel consumption and costs. This technology works by using the coolant system to warm the engine, and the “thermal energy gained is then distributed through the vehicle's own heat exchanger as forced hot air. This [process] heats the interior of the vehicle via existing air vents. The engine is [also] warmed up with the residual heat in the cooling water”. In general, coolant heaters burns eight times less fuel that an idling engine would, simultaneously emitting 1/20th of the emissions and directing heat significantly faster to the passenger compartment. Coolant heaters are also much more efficient than an engine. For example, according to the manufacturer, the Webasto TSL-17 is upwards of 82% efficient, whereas a diesel engine has no more than half that efficiency.\n\nAuxiliary power units (APUs) are commonly used on semi-trucks to provide electric power to the cabin at times when the cabin or cargo need to be heated or cooled while the vehicle is not in motion for an extended period of time. This period of time is usually overnight, when the truck driver has parked at a truck stop for some rest. Instead of having to keep the engine idling all night just to maintain the temperature in the cabin, the APU can turn on and provide power. Most commonly, the APU will have its own cooling system, heating system, generator, and air conditioning compressor. Sometimes the APU will be integrated into those components of the semi itself. APUs are also commonly used in police cruisers as an alternative to idling. Since a significant amount of time is spent in the cruiser while stationary, idling becomes a major source of cost to police fleets, though, most police fleets have idling policies. The drawback of APUs on police cruisers is that they are normally kept in the trunk where they take up valuable space.\n\nFederal safety regulations developed by the Federal Motor Carrier Safety Administration, require that truckers must rest ten hours for every eleven hours of consecutive driving. As a result, drivers spend extended periods of time resting and sleeping inside the cabs of their trucks. To maintain comfort and amenities, most long haul truck drivers idle their engines for close to ten hours per day to power their heating systems and air conditioners, generate electricity for on-board appliances, charge their vehicle’s batteries, and to warm their engines in colder weather. Given that trucks typically consume 0.8 gallons (3.03 L) of diesel fuel per hour of idling, between 900 and 1,400 gallons (3406 to 5300 L) of fuel are consumed each year per truck, resulting in significant greenhouse gas emissions. Truck-stop electrification (TSE) and auxiliary power unit technologies provide long-haul truckers with the ability to heat, cool, and power additional auxiliary devices at truck stops without requiring them to idle their engines.\n\nThe United States Department of Transportation estimates there are approximately 5,000 truck stops on the U.S. highway system that provide overnight parking, restrooms, showers, stores, restaurants and fueling stations. The United States Department of Energy maintains a website that lists current TSE sites throughout the United States. As of October 2013, the website records 115 TSE stations throughout the country.\n\nTruck stop electrification allows a trucker to “plug-in” to power their on and off-board electrical needs. There are two types of truck stop electrification, on-board and off-board systems. On board TSE solutions allow trucker’s the ability to recharge their batteries at truck stops via standard 120 Volt electrical outlets. Truckers can then utilize the truck’s batteries to power appliances and provide heating and cooling to the truck cab. Typically, on-board TSE solutions require some vehicle modification. Off-board TSE solutions do not typically require any vehicle modifications, as they provide heating and air conditioning services via an overhead unit and hose that connects to the truck’s window. In addition to heating and cooling, these connections can also offer standard electrical outlets, internet access, movies and satellite programming. Normally, private companies provide and regulate either system and can charge an hourly rate for services, typically around $1.00-$2.00 an hour. Both of these options can generate revenue for truck stop operators, and decrease operating expenses for truckers relative to the cost of diesel fuel. The cost of electricity to provide overnight power to trucks can save up to $3,240 of fuel that would normally be consumed by idling per parking space. Truck stop electrification can allow truck drivers to abide local idling regulations and reduce noise to neighboring establishments.\n\nThe cost of implementing a single TSE site can vary greatly, depending on the type of technology that is employed. Installation costs for technology that provides external power to operate equipment on board a truck range from $4,500 to $8,500 per space, whereas the costs to provide a window based power unit (i.e. an off board apparatus) range from $10,000 to $20,000 per space. Costs for an individual truck operator to install an on-board system capable of utilizing shore power from a TSE space can cost up to $2,000.\n\n\n"}
{"id": "6074570", "url": "https://en.wikipedia.org/wiki?curid=6074570", "title": "International Association of Oil &amp; Gas Producers", "text": "International Association of Oil &amp; Gas Producers\n\nThe International Association of Oil & Gas Producers (IOGP) is the petroleum industry's global forum in which members identify and share best practices to achieve improvements in health, safety, the environment, security, social responsibility, engineering and operations.\n\nThe association was formed in London in 1974 to develop effective communications between the upstream industry and the network of international regulators. Originally called the E&P Forum (for \"oil and gas exploration and production\"), in 1999 the name International Association of Oil & Gas Producers (IOGP) was adopted. Most of the world’s leading publicly traded, private and state-owned oil & gas companies, oil & gas associations and major upstream service companies are members. IOGP members produce 40% of the world’s oil and gas.\n\nIOGP also represent the interests of the upstream industry before international regulators and legislators in UN bodies such as the International Maritime Organization and the Commission for Sustainable Development. IOGP also works with the World Bank and with the International Organization for Standardization (ISO). It is also accredited to a range of regional bodies that include OSPAR, the Helsinki Commission and the Barcelona Convention, and provides a conduit for advocacy and debate between the upstream industry and the European Union (EU). This involves regular contact with the European Commission and the European Parliament.\n\nEvery year, IOGP collects and publishes data on upstream operations worldwide, both onshore and offshore, from participating member companies and their contractor employees. The reports are free and publicly available.\nThe data covers:\n\nOccupational safety:\nSince 1985, when IOGP started reporting annual trends in upstream safety data, there have been considerable improvements in industry performance.\nToday, it is the industry’s largest database of safety performance, covering participating member company employees and their contractors onshore and offshore, worldwide.\nFatal incidents are analysed by incident category, activity and associated causal factors, and incident descriptions are provided for fatal incidents and high potential events.\n\nEnvironmental performance:\nIOGP has collected and published environmental data from its participating member companies on an annual basis since 2001. The objectives of this programme are to allow member companies to compare their performance with other companies in the sector; and increase transparency of industry operations.\nThe reports aggregate information at both global and regional levels, expressed within six environmental indicator categories:\n\nProcess safety events:\nProcess safety is a disciplined framework for managing the integrity of operating systems and processes that handle hazardous substances. It relies on good design principles, engineering and operating and maintenance practices.\nThe process safety events (PSE) data are based on the numbers of Tier 1 and Tier 2 process safety events reported by participating IOGP member companies, separately for:\nThe data are normalized against work hours associated with drilling and production activities to provide PSE rates.\n\nHealth management:\nIOGP (with IPIECA) has developed two tools to assess health leading performance indicators within individual companies. These enable performance comparison between different parts of a company and between participating companies.\nThe annual health leading performance indicators report illustrates the results submitted by participating companies for both tools and includes actual anonymous results for the year by company, trends over time and the potential benefits to health management in the industry.\nLand transport safety\nIn April 2005, IOGP published Report No. 365, Land transportation safety recommended practice, a guideline designed to be applicable to all land transportation activities in the upstream oil and gas industry, including operators, contractors and subcontractors.\nIOGP collects data on motor vehicle crashes and information submitted by participating member companies are published from 2008 onwards. Data are broken down by region and crash category. Data are further grouped to indicate the number of crashes that resulted in a rollover. This includes:\n\nIn 2018, IOGP published its Global Production Report. It is based on the latest \"BP Statistical Review of World Energy\" and establishes an \"IOGP\" \"Production Indicator©\" (PI) – the level at which a region is able to meet its own oil or gas demand – for seven regions across the world. A PI higher than 100% means the region produces more than it needs to meet its own requirements and so can export.\n\nThe main conclusion of the report is that demand growth and the annual depletion rate of 6% of existing fields are driving the need for investment to gain additional volumes. Such investment will depend on regional and local policies that encourage responsible resource development.\n\nIn 2005, IOGP absorbed the European Petroleum Survey Group or EPSG (1986–2005) into its structure. EPSG was a scientific organization with ties to the European petroleum industry consisting of specialists working in applied geodesy, surveying, and cartography related to oil exploration. EPSG compiled and disseminated the EPSG Geodetic Parameter Set, a widely used database of Earth ellipsoids, geodetic datums, geographic and projected coordinate systems, units of measurement, etc.\n\nThe award, in association with the biennial SPE HSSE-SR International Conference, recognizes the achievements of an individual with fewer than 10 years of professional E&P experience, who demonstrates professional accomplishments and evidence of outstanding talent, dedication and leadership in at least one aspect of health, safety, security, the environment and/or social responsibility.\n\n2018 winner: Marcin Nazaruk, BP. Finalists: Mohammed A. Al-Ghazal, Saudi Aramco; Jessica Guzzetta-King, Genesis; Cedric Michel, Total; Natasha Sihota, Chevron; Josh R Townsend, BP.\n\nExtracts of their presentations can be viewed at IOGP's OYPA webpage.\n\n2016 winner: Muriel Barnier, Schlumberger. \nFinalists: Yu Chen, CNOOC; Bev Coleman, Chevron; Omar De Leon, ExxonMobil; and Emma Thomson, BP.\n\n"}
{"id": "13825072", "url": "https://en.wikipedia.org/wiki?curid=13825072", "title": "Keel effect", "text": "Keel effect\n\nIn aeronautics, the keel effect (also known as the pendulum effect or pendulum stability) is the result of the sideforce-generating surfaces being above (or below) the center of mass (which coincides with the center of gravity) in \"any\" aircraft. Along with dihedral, sweepback, and weight distribution, keel effect is one of the four main design considerations in aircraft lateral stability.\n\nExamples of sideforce-generating surfaces are the vertical stabilizer, rudder, and parts of the fuselage. When an aircraft is in a sideslip, these surfaces generate sidewards lift forces. If the surface is above or below the center of gravity, the sidewards lift forces generate a rolling moment. This \"rolling moment caused by sideslip\" is \"dihedral effect\". Keel effect is the contribution of these side forces to rolling moment (as sideslip increases), i.e. keel effect is the contribution of the side forces to dihedral effect. Sideforce producing surfaces \"above\" the center of gravity will \"increase\" dihedral effect, while sideforce producing surfaces below the center of gravity will decrease dihedral effect.\n\nIncreased dihedral effect (helped or hindered by keel effect) results in a greater tendency for the aircraft to return to level flight when the aircraft is put into a bank. Or, reduces the tendency to diverge to a greater bank angle when the aircraft starts wings-level.\n\nKeel effect is also called \"Pendulum Effect\" because a lower center of gravity increases the effect of sideways forces (above the center of gravity) in producing a rolling moment. This is because the \"moment arm is longer\", \"not\" because of gravitational forces. A low center of gravity is like a pendulum (which has a \"very\" low center of gravity).\n\nThe effect is an important consideration in seaplane design, where pontoon floats generate strong sideforces with a long moment arm.\n\n"}
{"id": "15616713", "url": "https://en.wikipedia.org/wiki?curid=15616713", "title": "Kline sphere characterization", "text": "Kline sphere characterization\n\nIn mathematics, a Kline sphere characterization, named after John Robert Kline, is a topological characterization of a two-dimensional sphere in terms of what sort of subset separates it. Its proof was one of the first notable accomplishments of R. H. Bing; Bing gave an alternate proof using brick partitioning in his paper \"Complementary domains of continuous curves\" \n\nA simple closed curve in a two-dimensional sphere (for instance, its equator) separates the sphere into two pieces upon removal. If one removes a pair of points from a sphere, however, the remainder is connected. Kline's sphere characterization states that the converse is true: If a nondegenerate locally connected metric continuum is separated by any simple closed curve but by no pair of points, then it is a two-dimensional sphere.\n\n"}
{"id": "46309037", "url": "https://en.wikipedia.org/wiki?curid=46309037", "title": "LIGNA", "text": "LIGNA\n\nThe LIGNA (\"ligna\" lat. = the woods), previously known as Ligna Plus (Ligna+) is an industrial trade fair for the woodworking industry. It takes place in uneven years on the Hanover fairground. It is run by Deutsche Messe AG and the Fachverband Holzbearbeitungsmaschinen section of VDMA e.V.\n\nUntil 1975, the Ligna was part of the yearly Hannover Messe. Due to space constraints, it was decided to establish the woodworking section as a separate fair. Since then, the Ligna fair takes place biannually.\n\nThere are exhibitions of machines and tools from the following sections:\n\n\n\n\n\n\n\n\n"}
{"id": "3994444", "url": "https://en.wikipedia.org/wiki?curid=3994444", "title": "Lie-Nielsen Toolworks", "text": "Lie-Nielsen Toolworks\n\nLie-Nielsen Toolworks, Inc. is a family-owned business, established in 1981 and based in Warren, Maine. It manufactures a range of high quality hand tools, primarily for woodworking, based on traditional designs. It is best known for its hand planes. Thomas Lie-Nielsen is the founder and CEO of Lie-Nielsen Toolworks.\n\nIn the late 1970s, Thomas Lie-Nielsen (pronounced \"Lee-Neelsen\") worked for Garry Chin's company, Garrett Wade. In 1981, Garrett Wade's supplier of an adapted Stanley #95 edge trimming block plane, Ken Wisner, was ready to leave the business, so Lie-Nielsen acquired the tooling, plans and components necessary for producing the #95.\n\nLie-Nielsen moved from New York to a farm in West Rockport, Maine, and began production of the plane in a tiny back-yard shed. The first of the new planes was delivered to Chinn in the autumn of 1981.\n\nA few years later, Lie-Nielsen moved into a workshop on the farm, and started production on his second plane, the skew-angle block plane. In 1988, as business grew, Lie-Nielsen bought an building in the town of Warren, Maine, which the company still occupies. In the mid-1990s, Lie-Nielsen moved the entire production to a facility.\n\nToday, the Lie-Nielsen Toolworks products compete with mass-produced tools from companies such as Stanley and Record, with sales in the order of 20,000 tools a year. The acquisition of the Independence Tool Co. in 1998 added hand saws to the product line, which has further expanded over the years to include over 50 different models of planes, in addition to spokeshaves, socket chisels, screwdrivers, marking and measuring devices and workbench hardware.\n\nLie-Nielsen uses manganese bronze and ductile iron castings, and cryogenically treated A-2 steel.\n\nManganese bronze, a very hard, strong alloy, is the material of choice for Lie-Nielsen tools because it is heavier than iron, doesn't rust, and won't crack if dropped. Where the use of bronze would result in excessive weight in a tool, ductile iron is used instead.\n\nLie-Nielsen products are expensive when compared to the mass-produced items from the likes of Stanley and Record, but these higher prices are often defended by comparing them with the prices paid 100 years ago for such things as Norris infill planes, which could cost up to \"a couple of weeks' wages\".\n"}
{"id": "31518594", "url": "https://en.wikipedia.org/wiki?curid=31518594", "title": "Matrixx Initiatives, Inc. v. Siracusano", "text": "Matrixx Initiatives, Inc. v. Siracusano\n\nMatrixx Initiatives, Inc. v. Siracusano, 563 U.S. 27 (2011), is a decision by the Supreme Court of the United States regarding whether a plaintiff can state a claim for securities fraud under §10(b) of the Securities Exchange Act of 1934, as amended, 15 U.S.C. §78j(b), and Securities and Exchange Commission Rule 10b-5, 17 CFR §240.10b-5 (2010), based on a pharmaceutical company's failure to disclose reports of adverse events associated with a product if the reports do not find statistically significant evidence that the adverse effects may be caused by the use of the product. In a 9–0 opinion delivered by Justice Sonia Sotomayor, the Court affirmed the Court of Appeals for the Ninth Circuit's ruling that the respondents, plaintiffs in a securities fraud class action against Matrixx Initiatives, Inc., and three Matrixx executives, had stated a claim under §10(b) and Rule 10b-5.\n\n\nPetitioner Matrixx Initiatives, Inc., is a pharmaceutical company that sells cold remedy products through its wholly owned subsidiary Zicam, LLC. One of Zicam's main products is Zicam Cold Remedy (Zicam), which is produced in the form of a nasal spray or gel containing the active ingredient zinc gluconate. On April 27, 2004, respondents brought a class action suit against petitioners, alleging that petitioners violated §10(b) of the Securities Exchange Act and SEC Rule 10b-5 by failing to disclose reports that Zicam could cause anosmia, or loss of the sense of smell. Petitioners filed a motion to dismiss respondents' complaint for failure to state a claim. The District Court for the District of Arizona granted the motion without prejudice, reasoning that the allegation of user complaints were neither material nor statistically significant, and that respondents failed to allege scienter. Respondents appealed to the Court of Appeals for the Ninth Circuit, which issued a decision on October 28, 2009, to reverse and remand the judgement of the District Court. On March 23, 2010, petitioners filed their petition for a writ of certiorari to the Ninth Circuit with the United States Supreme Court.\n\nOn March 22, 2011, Justice Sotomayor delivered the 9–0 opinion that held \"[r]espondents have stated a claim under §10(b) and Rule 10b-5\", affirming 585 F.3d 1167.\n\nAn article by Carl Bialik appearing in the Wall Street Journal on April 2, 2011, reported:\nIn [the] opinion, the justices said companies can't only rely on statistical significance when deciding what they need to disclose to investors.\n\nAmen, say several statisticians who have long argued that the concept of statistical significance has unjustly overtaken other barometers used to determine which experimental results are valid and warrant public distribution. \"Statistical significance doesn't tell you everything about the truth of the hypothesis you're exploring,\" says Steven Goodman, an epidemiologist and biostatistician at the Johns Hopkins Bloomberg School of Public Health. \nErik Olson, a partner at the Morrison & Foerster law firm in San Francisco which filed an amicus brief on behalf of BayBio, said that the court's ruling risks leaving companies without a clear guideline for deciding when they need to disclose adverse events. Olson, Stephen Thau, and Stefan Szpajda wrote a press release stating:\nLife sciences companies and other public companies can learn at least two lessons from the decision. First and foremost, be careful what you say. As the Court emphasized, the securities laws focus on false or misleading speech. \"[C]ompanies can control what they have to disclose under these provisions by controlling what they say to the market.\" (Slip Op. at 16). Rash or categorical comments are far more likely to form the basis for a lawsuit than measured, careful statements about the facts.\n\nSecond, life sciences companies should consult carefully with lawyers regarding specific disclosures and policies and practices for disclosing adverse events.\n\n"}
{"id": "539354", "url": "https://en.wikipedia.org/wiki?curid=539354", "title": "Mirror matter", "text": "Mirror matter\n\nIn physics, mirror matter, also called shadow matter or Alice matter, is a hypothetical counterpart to ordinary matter.\n\nModern physics deals with three basic types of spatial symmetry: reflection, rotation, and translation. The known elementary particles respect rotation and translation symmetry but do not respect mirror reflection symmetry (also called P-symmetry or parity). Of the four fundamental interactions—electromagnetism, the strong interaction, the weak interaction, and gravity—only the weak interaction breaks parity.\n\nParity violation in weak interactions was first postulated by Tsung Dao Lee and Chen Ning Yang in 1956 as a solution to the τ-θ puzzle. They suggested a number of experiments to test if the weak interaction is invariant under parity. These experiments were performed half a year later and they confirmed that the weak interactions of the known particles violate parity.\n\nHowever, parity symmetry can be restored as a fundamental symmetry of nature if the particle content is enlarged so that every particle has a mirror partner. The theory in its modern form was described in 1991, although the basic idea dates back further. Mirror particles interact amongst themselves in the same way as ordinary particles, except where ordinary particles have left-handed interactions, mirror particles have right-handed interactions. In this way, it turns out that mirror reflection symmetry can exist as an exact symmetry of nature, provided that a \"mirror\" particle exists for every ordinary particle. Parity can also be spontaneously broken depending on the Higgs potential. While in the case of unbroken parity symmetry the masses of particles are the same as their mirror partners, in case of broken parity symmetry the mirror partners are lighter or heavier.\n\nMirror matter, if it exists, would need to interact weakly with ordinary matter. This is because the forces between mirror particles are mediated by mirror bosons. With the exception of the graviton, none of the known bosons can be identical to their mirror partners. The only way mirror matter can interact with ordinary matter via forces other than gravity is via kinetic mixing of mirror bosons with ordinary bosons or via the exchange of Holdom particles. These interactions can only be very weak. Mirror particles have therefore been suggested as candidates for the inferred dark matter in the universe.\n\nIn another context, mirror matter has been proposed to give rise to an effective Higgs mechanism responsible for the electroweak symmetry breaking. In such a scenario, mirror fermions have masses on the order of 1 TeV since they interact with an additional interaction, while some of the mirror bosons are identical to the ordinary gauge bosons. In order to emphasize the distinction of this model from the ones above, these mirror particles are usually called katoptrons.\n\nMirror matter could have been diluted to unobservably low densities during the inflation epoch. Sheldon Glashow has shown that if at some high energy scale particles exist which interact strongly with both ordinary and mirror particles, radiative corrections will lead to a mixing between photons and mirror photons. This mixing has the effect of giving mirror electric charges a very small ordinary electric charge. Another effect of photon–mirror photon mixing is that it induces oscillations between positronium and mirror positronium. Positronium could then turn into mirror positronium and then decay into mirror photons.\n\nThe mixing between photons and mirror photons could be present in tree level Feynman diagrams or arise as a consequence of quantum corrections due to the presence of particles that carry both ordinary and mirror charges. In the latter case, the quantum corrections have to vanish at the one and two loop level Feynman diagrams, otherwise the predicted value of the kinetic mixing parameter would be larger than experimentally allowed.\n\nAn experiment to measure this effect is currently being planned.\n\nIf mirror matter does exist in large abundances in the universe and if it interacts with ordinary matter via photon-mirror photon mixing, then this could be detected in dark matter direct detection experiments such as DAMA/NaI and its successor DAMA/LIBRA. In fact, it is one of the few dark matter candidates which can explain the positive DAMA/NaI dark matter signal whilst still being consistent with the null results of other dark matter experiments.\n\nMirror matter may also be detected in electromagnetic field penetration experiments and there would also be consequences for planetary science and astrophysics.\n\nMirror matter could also be responsible for the GZK puzzle. Topological defects in the mirror sector could produce mirror neutrinos which can oscillate to ordinary neutrinos. Another possible way to evade the GZK bound is via neutron–mirror neutron oscillations.\n\nIf mirror matter is present in the universe with sufficient abundance then its gravitational effects can be detected. Because mirror matter is analogous to ordinary matter, it is then to be expected that a fraction of the mirror matter exists in the form of mirror galaxies, mirror stars, mirror planets etc. These objects can be detected using gravitational microlensing. One would also expect that some fraction of stars have mirror objects as their companion. In such cases one should be able to detect periodic Doppler shifts in the spectrum of the star. There are some hints that such effects may already have been observed.\n\nReference Blinnikov S.I.(1982) should be Blinnikov S.I., Khlopov M.Yu.(1982)\nReference Blinnikov S.I.(1983) should be Blinnikov S.I., Khlopov M.Yu.(1983)\n\n"}
{"id": "42946944", "url": "https://en.wikipedia.org/wiki?curid=42946944", "title": "Mother Country: Britain, the Welfare State, and Nuclear Pollution", "text": "Mother Country: Britain, the Welfare State, and Nuclear Pollution\n\nMother Country: Britain, the Welfare State, and Nuclear Pollution (1989) is a work of nonfiction by Marilynne Robinson that tells the story of Sellafield, a government nuclear reprocessing plant located on the coast of the Irish Sea. The book shows how the closest village to Sellafield suffers from death and disease due to decades of waste and radiation from the plant. \"Mother Country\" was a National Book Award finalist for Nonfiction in 1989. While on sabbatical in England, Robinson's interest in the environmental ramifications of the plant began when she discovered a newspaper article detailing its hazards.\n"}
{"id": "17519440", "url": "https://en.wikipedia.org/wiki?curid=17519440", "title": "Native Wind", "text": "Native Wind\n\nNative Wind (NAWIG) was formed to protect the environment and promote the welfare of Native Americans by facilitating the development of wind power and other renewable energy resources on tribal lands. Directors of Native Wind include representatives of the Intertribal Council On Utility Policy, Native Energy, ICLEI, Honor the Earth and American Spirit Productions. \n\nTwo wind facilities have previously been built through Native Wind -- a 750kW turbine at the Rosebud Indian Reservation and another at the Fort Berthold Indian Reservation in North Dakota. \n\nThe Indian tribes of the North and South Dakota and Nebraska are presently collaborating on a project to develop the large wind resources of the northern Great Plains. Eight separate tribes are moving ahead with plans to develop the first large-scale Native owned and operated wind farms in the United States.\n\n\n"}
{"id": "5190009", "url": "https://en.wikipedia.org/wiki?curid=5190009", "title": "North West Water", "text": "North West Water\n\nThe North West Water Authority took over the following statutory water undertakings:\n"}
{"id": "47269172", "url": "https://en.wikipedia.org/wiki?curid=47269172", "title": "Odeillo solar furnace", "text": "Odeillo solar furnace\n\nThe Odeillo solar furnace is the world's largest solar furnace. It is situated in Font-Romeu-Odeillo-Via, in the department of Pyrénées-Orientales, in south of France. It is high and wide, and includes 63 heliostats. It was built between 1962 and 1968, and started operating in 1970, and has a power of one megawatt.\n\nIt serves as a science research site studying materials at very high temperatures.\n\nIt is situated in Font-Romeu-Odeillo-Via, in the department of Pyrénées-Orientales, region of Languedoc-Roussillon, in south of France. The site was chosen because:\n\nThe solar power plant of Themis and the Mont-Louis Solar Furnace are situated nearby.\n\nThe principle used is the concentration of rays by reflecting mirrors (9,600 of them). The solar rays are picked up by a first set of steerable mirrors located on the slope, and then sent to a second series of mirrors (the \"concentrators\"), placed in a parabola and eventually converging on a circular target, 40 cm in diameter, on top of the central tower. \n\nEquivalent to concentrating the energy of \"10,000 suns\", the solar furnace produces a peak power of 3200 Kw.\n\n\nThe research areas are also extended to the aviation and aerospace industries. Experiments can be conducted there in conditions of high chemical purity.\nThe \"high temperature materials division\" use the furnace to evaluate radome survival during MIRV warhead earth re-entry along with investigating other material properties under the \"high energy thermal radiation environment\" frequently produced by \"nuclear devices\".\n\nIn 1946 French chemist Felix Trombe and his team achieved in Meudon their first experience of using a DCA mirror. They demonstrated the ability to reach high temperatures very quickly, and in a very pure environment, using highly concentrated sunlight. Their aim was to melt ore and extract highly pure materials for making new and improved refractories.\n\nTo achieve this objective and test the various possibilities, a first solar furnace was built at Mont-Louis in 1949. Some years later, on the model of the Mont-Louis furnace and using the results obtained there, a solar furnace of almost industrial size was built at Odeillo. Work on the construction of the Great Solar Oven of Odeillo lasted from 1962 to 1968, and it was commissioned in 1970.\n\nBeing strong supporters of solar power, following the first oil shock of 1973, researchers at the Odeillo solar furnace made further progress in the conversion of solar energy into electricity.\n\nSince 1990, there has been an information center on the site which is open to the public, and is independent of the CNRS laboratory.\n\nDesigned for young and old, Héliodyssée allows you to discover, in an entertaining way, solar energy and its derivatives (other forms of renewable energy, and its uses in the home) and the work of researchers from CNRS on energy, environmental, materials for space, and materials of the future.\n\n"}
{"id": "20054020", "url": "https://en.wikipedia.org/wiki?curid=20054020", "title": "PML Flightlink", "text": "PML Flightlink\n\nPML Flightlink were a Hampshire based firm specialising in the design and manufacture of \"pancake\" (flat) electric motors. The company operated for over 30 years in a number of markets including defense, aerospace, mobility, motion control, processing and printing. In 2006, they demonstrated an in-wheel electric motor for cars called the Hi-Pa Drive at the British Motor Show in London, using a Mini dubbed the \"Mini QED\" as a demonstration object. Two other car manufacturers have also presented concept cars using this technology: Volvo in its Volvo ReCharge, and Ford with a Ford F150 pick-up prototype presented at the 2008 SEMA Show in Las Vegas.\n\nOn 28 November 2008 by UK court order PML was put into administration (insolvency handling in the UK similar to Chapter 11).\nAfter the court case, PML was split in two in 2009: Protean Electric continue to develop automotive in-wheel motor applications of the Hi-Pa Drive; and Printed Motor Works design and manufacture Printed Armature/Pancake electric motors, joysticks and drive systems.\n"}
{"id": "23591472", "url": "https://en.wikipedia.org/wiki?curid=23591472", "title": "RECS International", "text": "RECS International\n\nRECS International was founded in Brussels in 2002 and is a non-profit-making European association of market players trading in renewable energy certificates. Its members are renewable energy producers, traders, suppliers and brokers, mostly in Europe (but also in South Africa, US and Canada), who either wish to have a voluntary account for trading RECS certificates with their national issuing body and/or wish to influence policy at governmental and regulatory level concerning certificate trading. RECS International represents market players in discussions with national and international government, and facilitates events and activities.\n\nRECS International works in cooperation with the Association of Issuing Bodies.\n"}
{"id": "39019161", "url": "https://en.wikipedia.org/wiki?curid=39019161", "title": "Radical sustainability", "text": "Radical sustainability\n\nRadical sustainability recognizes that a system is not sustainable if any part of it is unsustainable. An economy cannot be sustained if the underlying social structure is unsustainable. A social structure cannot be sustained if the environment it depends upon is unsustainable. Vice versa we find that in our modern day the environment cannot be sustained unless proper economical and social practices are in place.\n\nThe radical sustainable philosophy addressed problems of sustainability through a bottom-up approach - a form of \"grass roots\" sustainability.\n\nRadical sustainability advocates and supports autonomous development, indigenous movements, women's rights, social justice and green practices.\n\nThere are widespread examples of radical sustainability including open source ecology, rainwater harvesting (e.g. the projects by Brad Lancaster) and the Bushmen who live a life where social and environmental aspects are completely intertwined.\n\n"}
{"id": "42601453", "url": "https://en.wikipedia.org/wiki?curid=42601453", "title": "Rafea: Solar Mama", "text": "Rafea: Solar Mama\n\nRafea: Solar Mama is a documentary that depicts the trials and tribulations faced by Rafea, an illiterate Jordanian Bedouin as she follows her aspirations of lighting up her village by harnessing the power of solar energy by enrolling in the Barefoot College solar program in India. The story takes the viewer through Rafea's and her neighbour's physical and emotional journey before she triumphs. The true story was directed by Mona Eldaief and Jehane Noujaim as part of the Why Poverty project\n\n\n\n\n"}
{"id": "52820644", "url": "https://en.wikipedia.org/wiki?curid=52820644", "title": "Rothberger space", "text": "Rothberger space\n\nIn mathematics, a Rothberger space is a topological space that satisfies a certain a basic selection principle. A Rothberger space is a space in which for every sequence of open covers formula_1 of the space there are sets formula_2 such that the family formula_3 covers the space.\n\nIn 1938, Fritz Rothberger introduced his property known as formula_4.\n\nFor subsets of the real line, the Rothberger property can be characterized using continuous functions into the Baire space formula_5. A subset formula_6 of formula_5 is guessable if there is a function formula_8 such that the sets formula_9 are infinite for all functions formula_10. A subset of the real line is Rothberger iff every continuous image of that space into the Baire space is guessable. In particular, every subset of the real line of cardinality less than formula_11 is Rothberger.\n\nLet formula_12 be a topological space. The Rothberger game formula_13 played on formula_12 is a game with two players Alice and Bob.\n\n1st round: Alice chooses an open cover formula_15 of formula_12. Bob chooses a set formula_17.\n\n2nd round: Alice chooses an open cover formula_18 of formula_12. Bob chooses a finite set formula_20.\n\netc.\n\nIf the family formula_3 is a cover of the space formula_12, then Bob wins the game formula_13. Otherwise, Alice wins.\n\nA player has a winning strategy if he knows how to play in order to win the game formula_13 (formally, a winning strategy is a function).\n\n"}
{"id": "168632", "url": "https://en.wikipedia.org/wiki?curid=168632", "title": "Siemens", "text": "Siemens\n\nSiemens AG ( ) is a German conglomerate company headquartered in Berlin and Munich and the largest industrial manufacturing company in Europe with branch offices abroad.\n\nThe principal divisions of the company are \"Industry\", \"Energy\", \"Healthcare\" (Siemens Healthineers), and \"Infrastructure & Cities\", which represent the main activities of the company. The company is a prominent maker of medical diagnostics equipment and its medical health-care division, which generates about 12 percent of the company's total sales, is its second-most profitable unit, after the industrial automation division. The company is a component of the Euro Stoxx 50 stock market index. Siemens and its subsidiaries employ approximately 372,000 people worldwide and reported global revenue of around €83 billion in 2017 according to its earnings release.\n\nSiemens & Halske was founded by Werner von Siemens and Johann Georg Halske on 12 October 1847. Based on the telegraph, their invention used a needle to point to the sequence of letters, instead of using Morse code. The company, then called \"Telegraphen-Bauanstalt von Siemens & Halske\", opened its first workshop on 12 October.\n\nIn 1848, the company built the first long-distance telegraph line in Europe; 500 km from Berlin to Frankfurt am Main. In 1850, the founder's younger brother, Carl Wilhelm Siemens, later Sir William Siemens, started to represent the company in London. The London agency became a branch office in 1858. In the 1850s, the company was involved in building long distance telegraph networks in Russia. In 1855, a company branch headed by another brother, Carl Heinrich von Siemens, opened in St Petersburg, Russia. In 1867, Siemens completed the monumental Indo-European telegraph line stretching over 11,000 km from London to Calcutta.\nIn 1867, Werner von Siemens described a dynamo without permanent magnets. A similar system was also independently invented by Charles Wheatstone, but Siemens became the first company to build such devices. In 1881, a Siemens AC Alternator driven by a watermill was used to power the world's first electric street lighting in the town of Godalming, United Kingdom. The company continued to grow and diversified into electric trains and light bulbs. In 1887, it opened its first office in Japan. In 1890, the founder retired and left running the company to his brother Carl and sons Arnold and Wilhelm.\n\nSiemens & Halske (S & H) was incorporated in 1897, and then merged parts of its activities with Schuckert & Co., Nuremberg in 1903 to become Siemens-Schuckert. In 1907, Siemens (Siemens & Halske and Siemens-Schuckert) had 34,324 employees and was the seventh-largest company in the German empire by number of employees. (see List of German companies by employees in 1907)\n\nIn 1919, S & H and two other companies jointly formed the Osram lightbulb company.\n\nDuring the 1920s and 1930s, S & H started to manufacture radios, television sets, and electron microscopes.\n\nIn 1932, (Erlangen), Phönix AG (Rudolstadt) and Siemens-Reiniger-Veifa mbH (Berlin) merged to form the Siemens-Reiniger-Werke AG (SRW), the third of the so-called parent companies that merged in 1966 to form the present-day Siemens AG.\n\nIn the 1920s, Siemens constructed the Ardnacrusha Hydro Power station on the River Shannon in the then Irish Free State, and it was a world first for its design. The company is remembered for its desire to raise the wages of its under-paid workers only to be overruled by the Cumann na nGaedheal government.\n\nSiemens (at the time: Siemens-Schuckert) exploited the forced labour of deported people in extermination camps. The company owned a plant in Auschwitz concentration camp.\n\nDuring the final years of World War II, numerous plants and factories in Berlin and other major cities were destroyed by Allied air raids. To prevent further losses, manufacturing was therefore moved to alternative places and regions not affected by the air war. The goal was to secure continued production of important war-related and everyday goods. According to records, Siemens was operating almost 400 alternative or relocated manufacturing plants at the end of 1944 and in early 1945.\n\nIn 1972, Siemens sued German satirist F.C. Delius for his satirical history of the company, \"Unsere Siemenswelt\", and it was determined much of the book contained false claims although the trial itself publicized Siemens' history in Nazi Germany. The company supplied electrical parts to Nazi concentration camps and death camps. The factories had poor working conditions, where malnutrition and death were common. Also, the scholarship has shown that the camp factories were created, run, and supplied by the SS, in conjunction with company officials, sometimes high-level officials.\n\nSiemens businessman and Nazi Party member John Rabe is, however, credited with saving many Chinese lives during the infamous Nanking Massacre. He later toured Germany lecturing on the atrocities committed by Japanese forces in Nanking.\n\nIn the 1950s, and from their new base in Bavaria, S&H started to manufacture computers, semiconductor devices, washing machines, and pacemakers. In 1966, Siemens & Halske (S&H, founded in 1847), Siemens-Schuckertwerke (SSW, founded in 1903) and Siemens-Reiniger-Werke (SRW, founded in 1932) merged to form Siemens AG. In 1969, Siemens formed Kraftwerk Union with AEG by pooling their nuclear power businesses.\n\nThe company's first digital telephone exchange was produced in 1980. In 1988, Siemens and GEC acquired the UK defence and technology company Plessey. Plessey's holdings were split, and Siemens took over the avionics, radar and traffic control businesses—as Siemens Plessey.\n\nIn 1985, Siemens bought Allis-Chalmers' interest in the partnership company Siemens-Allis (formed 1978) which supplied electrical control equipment. It was incorporated into Siemens' Energy and Automation division.\n\nIn 1987, Siemens reintegrated Kraftwerk Union, the unit overseeing nuclear power business.\n\nIn 1991, Siemens acquired Nixdorf Computer AG and renamed it Siemens Nixdorf Informationssysteme AG, in order to produce personal computers.\n\nIn October 1991, Siemens acquired the Industrial Systems Division of Texas Instruments, Inc, based in Johnson City, Tennessee. This division was organized as Siemens Industrial Automation, Inc., and was later absorbed by Siemens Energy and Automation, Inc.\n\nIn 1992, Siemens bought out IBM's half of ROLM (Siemens had bought into ROLM five years earlier), thus creating SiemensROLM Communications; eventually dropping ROLM from the name later in the 1990s.\n\nIn 1993-1994, Siemens C651 electric trains for Singapore's Mass Rapid Transit (MRT) system were built in Austria.\n\nIn 1997, Siemens agreed to sell the defence arm of Siemens Plessey to British Aerospace (BAe) and a German aerospace company, DaimlerChrysler Aerospace. BAe and DASA acquired the British and German divisions of the operation respectively.\n\nIn October 1997, Siemens Financial Services (SFS) was founded to act as competence center for financing issues and as a manager of financial risks within Siemens.\n\nIn 1998, Siemens acquired Westinghouse Power Generation for more than $1.5 billion from the CBS Corporation and moving Siemens from third to second in the world power generation market.\n\nIn 1999, Siemens' semiconductor operations were spun off into a new company called Infineon Technologies. In the same year, Siemens Nixdorf Informationssysteme AG became part of Fujitsu Siemens Computers AG, with its retail banking technology group becoming Wincor Nixdorf.\n\nIn 2000, Shared Medical Systems Corporation was acquired by the Siemens' Medical Engineering Group, eventually becoming part of Siemens Medical Solutions.\n\nAlso in 2000, Atecs-Mannesman was acquired by Siemens, The sale was finalised in April 2001 with 50% of the shares acquired, acquisition, \"Mannesmann VDO AG\" merged into Siemens Automotive forming Siemens VDO Automotive AG, \"Atecs Mannesmann Dematic Systems\" merged into Siemens Production and Logistics forming Siemens Dematic AG, \"Mannesmann Demag Delaval\" merged into the Power Generation division of Siemens AG. Other parts of the company were acquired by Robert Bosch GmbH at the same time. Also, Moore Products Co. of Spring House, PA USA was acquired by Siemens Energy & Automation, Inc.\n\nIn 2001, Chemtech Group of Brazil was incorporated into the Siemens Group; it provides industrial process optimisation, consultancy and other engineering services.\n\nAlso in 2001, Siemens formed joint venture Framatome with Areva SA of France by merging much of the companies' nuclear businesses.\n\nIn 2002, Siemens sold some of its business activities to Kohlberg Kravis Roberts & Co. L.P. (KKR), with its metering business included in the sale package.\n\nIn 2003, Siemens acquired the flow division of Danfoss and incorporated it into the Automation and Drives division. Also in 2003 Siemens acquired IndX software (realtime data organisation and presentation). The same year in an unrelated development Siemens reopened its office in Kabul. Also in 2003 agreed to buy Alstom Industrial Turbines; a manufacturer of small, medium and industrial gas turbines for €1.1 billion.\nOn 11 February 2003, Siemens planned to shorten phones' shelf life by bringing out annual Xelibri lines, with new devices launched as spring -summer and autumn-winter collections. On 6 March 2003, the company opened an office in San Jose. On 7 March 2003, the company announced that it planned to gain 10 per cent of the mainland China market for handsets. On 18 March 2003, the company unveiled the latest in its series of Xelibri fashion phones.\n\nIn 2004, the wind energy company Bonus Energy in Brande, Denmark was acquired, forming Siemens Wind Power division. Also in 2004 Siemens invested in Dasan Networks (South Korea, broadband network equipment) acquiring ~40% of the shares, Nokia Siemens disinvested itself of the shares in 2008. The same year Siemens acquired Photo-Scan (UK, CCTV systems), US Filter Corporation (water and Waste Water Treatment Technologies/ Solutions, acquired from Veolia), Hunstville Electronics Corporation (automobile electronics, acquired from Chrysler), and Chantry Networks (WLAN equipment).\n\nIn 2005, Siemens sold the Siemens mobile manufacturing business to BenQ, forming the BenQ-Siemens division. Also in 2005 Siemens acquired Flender Holding GmbH (Bocholt, Germany, gears/industrial drives), Bewator AB (building security systems), Wheelabrator Air Pollution Control, Inc. (Industrial and power station dust control systems), AN Windenergie GmbH. (Wind energy), Power Technologies Inc. (Schenectady, USA, energy industry software and training), CTI Molecular Imaging (Positron emission tomography and molecular imaging systems), Myrio (IPTV systems), Shaw Power Technologies International Ltd (UK/USA, electrical engineering consulting, acquired from Shaw Group), and Transmitton (Ashby de la Zouch UK, rail and other industry control and asset management).\n\nIn 2005 Germany opened investigations into Siemens business practices worldwide, prompted by requests from prosecutors in Italy, Liechtenstein and Switzerland; US investigators joined in 2006 and the US investigators addressed violations only since 2001, when Siemens started selling shares in a US stock exchange. The investigators found that bribing officials to win contracts was standard operating procedure. Over that time period the company paid around $1.3 billion in bribes in many countries and kept separate books to hide them.\n\nFines were anticipated to be as high as $5 billion as the investigation unfolded. Settlement negotiations took place through most of 2008 and when they were announced in December they were far less, driven in part by Siemens' cooperation, in part by the imminent change in US administrations (the Obama administration was about to take over from the Bush administration), and in part by the dependence of the US military on Siemens as a contractor.\n\nThe company paid a total of about $1.6 billion, around $800 million in each of the US and Germany. This was the largest bribery fine in history, at the time. The money paid to Germany included a $270 million fine paid the year before (related to bribes in Nigeria). The US payment included $450 million in fines and penalties and a forfeiture of $350 million in profits. The company was also obligated to spend $1 billion on setting up and funding new internal compliance regimens. Siemens pleaded guilty to violating accounting provisions of the Foreign Corrupt Practices Act; the parent company did not plead guilty to paying bribes (although its Bangladesh and Venezuela subsidiaries did); such a guilty plea would have barred Siemens from contracting for the US government. As the scandal had started breaking, Siemens had fired its chairman and CEO Heinrich von Pierer, and had hired its first non-German CEO. Peter Löscher; it also had appointed a US lawyer, Peter Solmssen as an independent director to its board, in charge of compliance, and had accepted oversight of Theo Waigel, a former German finance minister, as a \"compliance monitor\". The compliance overhaul eventually entailed hiring around 500 full-time compliance personnel worldwide. Siemens also enacted a series of new anti-corruption compliance policies, including a new anti-corruption handbook, web-based tools for due diligence and compliance, a confidential communications channel for employees to report irregular business practices, and a corporate disciplinary committee to impose appropriate disciplinary measures for substantiated misconduct.\n\nThe culture of bribery was old in Siemens, and led to the 1914 scandal in Japan over bribes paid by both Siemens and Vickers to Japanese naval authorities to win shipbuilding contracts.\n\nThe culture of bribery had further had grown up inside Siemens after World War II as Siemens attempted to rebuild its business by competing in the developing world, where bribery is common. Until 1999 in Germany, bribes were a tax-deductible business expense, and there were no penalties for bribing foreign officials. In 1999 the OECD Anti-Bribery Convention came into effect, to which Germany was a party, and Siemens started to use off-shore accounts and other means of hiding its bribery.\n\nAs the investigation opened a midlevel executive in the telecommunications unit, Reinhard Slekaczek, was identified as a key player; Slekaczek quit Siemens in 2005 after the company required him to sign a document saying he had followed law and company policy, and turned state's evidence and led investigators to documents he had saved and to other documents. He had controlled an annual global bribery budget of $40 to $50 million. The usual method of bribery was to pay a local insider as a \"contractor\" who would in turn pass money to government officials; as part of the settlement Siemens disclosed that it had 2,700 such contractors worldwide. Bribes were generally around 5% of a contract's value but in very corrupt countries they could be as high as 40%. It paid the highest bribes in China, Russia, Argentina, Israel and Venezuela.\n\nExamples of bribery the investigation found included:\n\nThe investigation led directly to several prosecutions while it was unfolding, and led to settlements with other governments and prosecution of Siemens employees and bribe recipients in various countries.\n\nIn May 2007 a German court convicted two former executives of paying about €6 million in bribes from 1999 to 2002 to help Siemens win natural gas turbine supply contracts with Enel, an Italian energy company. The contracts were valued at about €450 million. Siemens was fined €38 million.\n\nIn July 2009, Siemens settled allegations of fraud by a Russian affiliate in a World Bank-funded mass transit project in Moscow by agreeing to not bid on World Bank projects for two years, not allowing the Russian affiliate to do any World Bank funded work for four years, and setting up a $100 million fund at the World Bank to fund anti-corruption activities over 15 years, over which the World Bank had veto and audit rights; this fund became the \"“Siemens Integrity Initiative”. The first payments were made out of the funds in 2010 in a tranche of $40 million. A second set of projects was funded in 2014 totaling $30 million.\n\nSiemens paid N7 billion to the Nigerian government in 2010.\n\nIn 2012, the Greek government settled the Greek bribery scandal for 330 million euros. The trial of the persons accused of involvement in the scandal began on 24 February 2017. A total of 64 individuals are accused, both Greek and German nationals. The central figure of the scandal however, ex-Siemens chief executive in Greece Michael Christoforakos, against whom European arrest warrants are pending will likely be absent, as Germany refuses his extradition to this day. Initially arrested in Germany in 2009, the accusations against him by German courts have been dropped, and he since lives free in this country. Greece has been demanding his extradition since 2009, and considers him a fugitive from justice.\n\nIn 2014 a former Siemens executive Andres Truppel pleaded guilty to funneling nearly $100 million in bribes to Argentine government officials to win the ID card project for Siemens.\n\nIn 2014 Israeli prosecutors decreed that Siemens should pay US$42.7 million penalty and appoint an external inspector to supervise its business in Israel in exchange for state prosecutors dropping charges of securities fraud. According to the indictment, \"Siemens systematically paid bribes to Israel Electric Corporation executives so they would utilize their positions in order to favor and advance the interests of Siemens\".\n\nIn 2006, Siemens announced the purchase of Bayer Diagnostics, which was incorporated into the Medical Solutions Diagnostics division on 1 January 2007, also in 2006 Siemens acquired Controlotron (New York) (ultrasonic flow meters) Also in 2006 Siemens acquired Diagnostic Products Corp., Kadon Electro Mechanical Services Ltd. (now TurboCare Canada Ltd.), Kühnle, Kopp, & Kausch AG, Opto Control, and VistaScape Security Systems\n\nIn January 2007, Siemens was fined €396 million by the European Commission for price fixing in EU electricity markets through a cartel involving 11 companies, including ABB, Alstom, Fuji Electric, Hitachi Japan, AE Power Systems, Mitsubishi Electric Corp, Schneider, Areva, Toshiba and VA Tech. According to the Commission, \"between 1988 and 2004, the companies rigged bids for procurement contracts, fixed prices, allocated projects to each other, shared markets and exchanged commercially important and confidential information.\" Siemens was given the highest fine of €396 million, more than half of the total, for its alleged leadership role in the activity.\nIn March 2007, a Siemens board member was temporarily arrested and accused of illegally financing a business-friendly labour association which competes against the union IG Metall. He has been released on bail. Offices of the labour union and of Siemens have been searched. Siemens denies any wrongdoing. In April the Fixed Networks, Mobile Networks and Carrier Services divisions of Siemens merged with Nokia's Network Business Group in a 50/50 joint venture, creating a fixed and mobile network company called Nokia Siemens Networks. Nokia delayed the merger due to bribery investigations against Siemens. In October 2007, a court in Munich found that the company had bribed public officials in Libya, Russia, and Nigeria in return for the awarding of contracts; four former Nigerian Ministers of Communications were among those named as recipients of the payments. The company admitted to having paid the bribes and agreed to pay a fine of 201 million euros. In December 2007, the Nigerian government cancelled a contract with Siemens due to the bribery findings.\n\nAlso in 2007, Siemens acquired Vai Ingdesi Automation (Argentina, Industrial Automation), UGS Corp., Dade Behring, Sidelco (Quebec, Canada), S/D Engineers Inc., and Gesellschaft für Systemforschung und Dienstleistungen im Gesundheitswesen mbH (GSD) (Germany).\n\nIn July 2008, Siemens AG announced a joint venture of the Enterprise Communications business with the Gores Group, renamed Unify in 2013. The Gores Group holding a majority interest of 51% stake, with Siemens AG holding a minority interest of 49%.\n\nIn August 2008, Siemens Project Ventures invested $15 million in the Arava Power Company. In a press release published that month, Peter Löscher, President and CEO of Siemens AG said: “This investment is another consequential step in further strengthening our green and sustainable technologies”. Siemens now holds a 40% stake in the company.\nIn January 2009, Siemens announced to sell its 34% stake in Framatome, complaining limited managerial influence. In March, it announced to form an alliance with Rosatom of Russia to engage in nuclear-power activities.\n\nIn April 2009, Fujitsu Siemens Computers became Fujitsu Technology Solutions as a result of Fujitsu buying out Siemens' share of the company.\n\nIn June 2009 news broke that Nokia Siemens had supplied telecommunications equipment to the Iranian telecom company that included the ability to intercept and monitor telecommunications, a facility known as \"lawful intercept\". The equipment was believed to have been used in the suppression of the 2009 Iranian election protests, leading to criticism of the company, including by the European Parliament. Nokia-Siemens later divested its call monitoring business, and reduced its activities in Iran.\n\nIn October 2009, Siemens signed a $418 million contract to buy Solel Solar Systems an Israeli company in the solar thermal power business.\n\nIn December 2010, Siemens agreed to sell its IT Solutions and Services subsidiary for €850 million to Atos. As part of the deal, Siemens agreed to take a 15% stake in the enlarged Atos, to be held for a minimum of five years. In addition, Siemens concluded a seven-year outsourcing contract worth around €5.5 billion, under which Atos will provide managed services and systems integration to Siemens.\n\nIn March 2011, it was decided to list Osram on the stock market in the autumn, but CEO Peter Löscher said Siemens intended to retain a long-term interest in the company, which was already independent from the technological and managerial viewpoints.\n\nIn September 2011, Siemens, which had been responsible for constructing all 17 of Germany's existing nuclear power plants, announced that it would exit the nuclear sector following the Fukushima disaster and the subsequent changes to German energy policy. Chief executive Peter Löscher has supported the German government's planned \"Energiewende\", its transition to renewable energy technologies, calling it a \"project of the century\" and saying Berlin's target of reaching 35% renewable energy sources by 2020 was feasible.\n\nIn November 2012, Siemens acquired the Rail division of Invensys for £1.7 billion. In the same month, Siemens made the announcement of acquiring a privately held company, LMS International NV.\n\nIn August 2013, Nokia acquired 100% of the company Nokia Siemens Networks, with a buy-out of Siemens AG, ending Siemens role in telecommunication.\n\nIn August 2013, Siemens won a $966.8 million order for power plant components from oil firm Saudi Aramco, the largest bid it has ever received from the Saudi company.\n\nIn 2014, Siemens plans to build a $264 million facility for making offshore wind turbines in Paull, England, as Britain's wind power rapidly expands. Siemens chose the Hull area on the east coast of England because it is close to other large offshore projects planned in coming years. The new plant is expected to begin producing turbine rotor blades in 2016. The plant and the associated service center, in Green Port Hull nearby, will employ about 1,000 workers. The facilities will serve the UK market, where the electricity that major power producers generate from wind grew by about 38 percent in 2013, representing about 6 percent of total electricity, according to government figures. There are also plans to increase Britain's wind-generating capacity at least threefold by 2020, to 14 gigawatts.\n\nIn May 2014, Rolls-Royce agreed to sell its gas turbine and compressor energy business to Siemens for £1 billion.\n\nIn June 2014, Siemens and Mitsubishi Heavy Industries announced their formation of joint ventures to bid for Alstom's troubled energy and transportation businesses (in locomotives, steam turbines, and aircraft engines). A rival bid by General Electric (GE) has been criticized by French government sources, who consider Alstom's operations as a \"vital national interest\" at a moment when the French unemployment level stands above 10% and some voters are turning towards the far-right.\n\nIn 2015, Siemens acquired U.S. oilfield equipment maker Dresser-Rand Group Inc for $7.6 billion.\n\nIn November 2016, Siemens announced the acquisition of EDA company Mentor Graphics for $4.5 billion.\n\nIn December 2017, Siemens announced the acquisition of medical technology company Fast Track Diagnostics for an undisclosed amount.\n\nIn August 2018, Siemens announced the acquisition of rapid application development company Mendix for €0.6 billion in cash.\n\nSiemens offers a wide range of electrical engineering- and electronics-related products and services. Its products can be broadly divided into the following categories: buildings-related products; drives, automation and industrial plant-related products; energy-related products; lighting; medical products; and transportation and logistics-related products.\n\nSiemens buildings-related products include building-automation equipment and systems; building-operations equipment and systems; building fire-safety equipment and systems; building-security equipment and systems; and low-voltage switchgear including circuit protection and distribution products.\n\nSiemens drives, automation and industrial plant-related products include motors and drives for conveyor belts; pumps and compressors; heavy duty motors and drives for rolling steel mills; compressors for oil and gas pipelines; mechanical components including gears for wind turbines and cement mills; automation equipment and systems and controls for production machinery and machine tools; and industrial plant for water processing and raw material processing.\n\nSiemens energy-related products include gas and steam turbines; generators; compressors; on- and offshore wind turbines; high-voltage transmission products; power transformers; high-voltage switching products and systems; alternating and direct current transmission systems; medium-voltage components and systems; and power automation products.\n\nSiemens is a player in the renewable energy industry, the company provides a comprehensive portfolio of products, solutions, and services to help build and operate microgrids of any size. Siemens provide generation and distribution of electrical energy as well as monitoring and controlling of microgrids. By using primarily renewable energy, microgrids reduce carbon-dioxide emissions, which is often required by government regulations. That makes Siemens especially attractive for campuses, utilities, and islands. Ventotene Island in Italy demonstrates the benefits of a microgrid in terms of sustainability. The Italian energy utility Enel Produzione SPA had a clear goal for the island of Ventotene: a stable power supply system that would operate more sustainably, economically, and reliably. And Siemens had the complete solution: The SIESTORAGE storage system, optimally combined with the Microgrid Controller. This approach included the integration of renewable energy sources to reduce the supply of diesel and to create greater sustainability. An additional goal was to perfectly coordinate all existing and new power components and, even more important, to respond quickly and reliably to grid fluctuations, ultimately guaranteeing a stable network.\n\nSiemens OSRAM subsidiary produces lighting products including incandescent, halogen, compact fluorescent, fluorescent, high-intensity discharge and Xenon lamps; opto-electronic semiconductor light sources such as light emitting diodes (LEDs), organic LEDs, high power laser diodes, LED systems and LED luminaires; electronic equipment including electronic ballasts; lighting control and management systems; and related precision components.\n\nSiemens medical products include clinical information technology systems; hearing instruments; in-vitro diagnostics equipment; imaging equipment including angiography, computed tomography, fluoroscopy, magnetic resonance, mammography, molecular imaging ultrasound, and x-ray equipment; and radiation oncology and particle therapy equipment. , Siemens finalized the sale of its hearing-aid (hearing instruments) business to Sivantos.\n\nSiemens transportation and logistics-related products include equipment and systems for rail transportation including rail vehicles for mass transit, regional and long-distance transportation, locomotives, equipment and systems for rail electrification, central control systems, interlockings, and automated train controls; equipment and systems for road traffic including traffic detection, information and guidance; equipment and systems for airport logistics including cargo tracking and baggage handling; and equipment and systems for postal automation including letter parcel sorting.\n\nSiemens also completed a world record in 2012 for the most electricity generated by bicycles in an hour. Generating 4,630 watts in an hour in Melbourne, Australia, on December 11, 2012\nSiemens is incorporated in Germany and has its corporate headquarters in Munich. It has operations in around 190 countries and approximately 285 production and manufacturing facilities. Siemens had around 360,000 employees as of 30 September 2011.\n\nElectrification, automation and digitalization are the long-term growth fields of Siemens. In order to take full advantage of the market potential in these fields, Siemens businesses are bundled into nine divisions and healthcare as a separately managed business.\n\n\nIn 2011, Siemens invested a total of €3.925 billion in research and development, equivalent to 5.3% of revenues. As of 30 September 2011, Siemens had approximately 11,800 Germany-based employees engaged in research and development and approximately\n16,000 in the rest of the world, of whom the majority were based in either Austria, China, Croatia, Denmark, France, India, Japan, Mexico, The Netherlands, Russia, Slovakia, Sweden, Switzerland, the United Kingdom or the United States. As of 30 September 2011, Siemens held approximately 53,300 patents worldwide.\nSiemens' current joint ventures include:\n\n\nFor the fiscal year 2017, Siemens reported earnings of EUR€6.046 billion, with an annual revenue of EUR€83.049 billion, an increase of 4.3% over the previous fiscal cycle. Siemen's shares traded at over US$58 per share, and its market capitalization was valued at US$95.3 billion in November 2018.\nThe company has issued 881,000,000 shares of common stock. The largest single shareholder continues to be the founding shareholder, the Siemens family, with a stake of 6.9%. 62% are held by institutional asset managers, the largest being two divisions of the world's largest asset manager BlackRock. 83.97% of the shares are considered public float, however including such strategic investors as the State of Qatar (DIC Company Ltd.) with 3.04%, the Government Pension Fund of Norway with 2.5% and Siemens AG itself with 3.04%. 19% are held by private investors, 13% by investors that are considered unidentifiable. 26% are owned by German investors, 21% by US investors, followed by the UK (11%), France (8%), Switzerland (8%) and a number of others (26%).\n\nChairmen of the Siemens-Schuckertwerke Managing Board (1903 to 1966)\n\nChairmen of the Siemens & Halske / Siemens-Schuckertwerke Supervisory Board (1918 to 1966)\nChairmen of the Siemens AG Managing Board (1966 to present)\nChairmen of the Siemens AG Supervisory Board (1966 to present)\n\nManaging Board (present day)\n\n\n\n"}
{"id": "1426421", "url": "https://en.wikipedia.org/wiki?curid=1426421", "title": "Society of Wood Engravers", "text": "Society of Wood Engravers\n\nThe Society of Wood Engravers was founded in 1920 by the artists Noel Rooke and Robert Gibbings, who were the driving force behind the society, and Edward Gordon Craig, E.M.O'R. Dickey, Eric Gill, Philip Hagreen, Sydney Lee, John Nash, Lucien Pissarro, and Gwen Raverat. The aim of the society has been to promote original white line wood engravings, designed and engraved by the artist, as opposed to the wood engravings of the nineteenth century, where skilled craftsmen engraved the design of the artist. The impetus behind this new philosophy was Rooke. \n\nThe Society went into abeyance during the 1960s, but was revived in 1984 by Hilary Paynter. It publishes a bulletin called \"Multiples\".\n\nThe Annual Exhibition of the Society tours the UK. In November and December 2017, the 80th Annual Exhibition is being held in Petworth, West Sussex.\n\nNotable former Members include:\n\n\n"}
{"id": "19521418", "url": "https://en.wikipedia.org/wiki?curid=19521418", "title": "Solar Power International", "text": "Solar Power International\n\nSolar Power International is a solar power conference, in 2008 was touted as the largest solar power conference in North America. The conference was previously called Solar Power Conference and Expo, and was created in 2004 when the Solar Electric Power Association (SEPA) and the Solar Energy Industries Association (SEIA) joined together to organize an annual event to bring together companies and professionals from all parts of the solar industry. The conference consists of two main elements: an exhibition hall where companies have booths to promote their products and services; and conference sessions where panels of solar industry experts share ideas and success stories.\nSolar Power International 2010 was held at the Los Angeles Convention Center\nOctober 12–14. The 2013 Conference was held on Oct 21-24 in Chicago, Ill at McCormick Place Convention Center and the 2014 Conference will be held on Oct 20-23 at the Las Vegas Convention Center in Las Vegas, Nevada\n\nSolar Power International is attended by professionals in the solar industry who are builders, project developers, installers, distributors, engineering firms, investors and financiers, service providers, law firms, equipment manufacturers, and manufacturers of tools for equipment manufacturing. Representatives from utilities also attend the conference as well as Government representatives, policymakers, and the press.\n\nMembers of the Solar Energy Industries Association and the Solar Electric Power Association receive discounts on registration.\n\nThe majority of attendees of Solar Power International come from the United States, however there are a large number of attendees from major solar markets such as China, Japan, and Germany.\nThe conference sessions at Solar Power International are traditionally separated by topic into different tracks. Typical tracks are technical, marketing & sales, market conditions, finance, and politics. There are generally over 70 sessions over the four-day conference. \n\nStart-Up Alley, located on the Expo floor, is a dedicated area specifically designed to promote up-and-coming ideas and companies in the solar industry. It was added to the conference features in 2013. \n\n"}
{"id": "23957935", "url": "https://en.wikipedia.org/wiki?curid=23957935", "title": "Soterml", "text": "Soterml\n\nSoTerML (Soil and Terrain Markup Language) is a XML-based markup language for storing and exchanging soil and terrain related data. SoTerML development is being done within The e-SoTer Platform. GEOSS plans a global Earth Observation System and, within this framework, the e-SOTER project addresses the felt need for a global soil and terrain database.\nThe Centre for Geospatial Science (Currently Nottingham Gepospatial Institute) at the University of Nottingham has initiated the development since January 2009. Further development and maintenance is currently handled in National Soil Resources Institurte (NSRI) at Cranfield University, UK. The role of CGS is within the development of the e-SOTER dissemination platform, which is based on INSPIRE principles. The SoTerML development included:\n\n1. Development of a data dictionary for nomenclatures and various data sources (data and metadata).\n\n2. Development of an exchange format/procedures from the World Reference Base 2006. \n\n"}
{"id": "47410081", "url": "https://en.wikipedia.org/wiki?curid=47410081", "title": "Steam spring", "text": "Steam spring\n\nSteam springs or steam suspension are a form of suspension used for some early steam locomotives designed and built by George Stephenson. They were only briefly used and may have been used for fewer than ten locomotives.\n\nEarly railways used cast-iron fishbelly rails. These were brittle and prone to cracking under shock loads. The new steam locomotives of the 1820s were much heavier than the horse-drawn wagons of earlier plateways. Locomotives of this period also used vertical cylinders set within the boiler. The vertical forces of the moving pistons further gave rise to hammer blow, which increased the load on the rails.\n\nA further reason for suspension was to improve the frictional contact between the wheels and rail. This relied upon maintaining a good contact, thus requiring good suspension of the wheels over the uneven track. The ability of an 'adhesion-hauled' locomotive to draw a train was much questioned at this time, as it was thought that the friction between a smooth iron wheel and the rail would be inadequate. Some designers, such as Blenkinsop with his \"Salamanca\" thought that a system of geared teeth would be necessary. Stephenson believed that, provided a good contact could be maintained between wheel and rail, frictional adhesion alone would be adequate. \n\nAt the time of these early locomotives there was not yet a way of forging an adequate steel spring to carry the weight of a locomotive. High quality steel had been available since Huntsman's crucible process, but it was still so expensive as to be regarded as 'a semi-precious metal'. It would be another forty years before Bessemer's converter made cheap bulk steel available. A similar problem affected safety valves, causing them to rely on dead weights or Hackworth's bulky stack of leaf springs, rather than the ubiquitous steel coil spring that would appear later.\n\nStephenson's 'steam suspension' provided each wheel with its own 'steam spring'. Vertical cylinders were set into the base of the boiler, above each axle and offset in pairs to the sides. The chassis or frames of Stephenson's locomotives provided little structural strength, most of which came from the shell of the boiler. Inside each cylinder a piston carried the load of the axle and pressed upwards against steam pressure within the boiler. A piston of only a few inches in diameter was sufficient to balance the locomotive's weight. The axlebox bearings could slide vertically within hornblocks attached to the wooden frame beneath the boiler.\n\nPiston seals were a perennial problem at this time. Those for large stationary engines, working at low pressures, were sealed by a variety of methods including leather cup washers, pools of standing water and even a poultice of cow dung. As working pressures increased, which had been an essential part of turning the stationary steam engine into the mobile steam locomotive, demands on the piston seal increased further. Pistons were now mostly sealed by having oakum rope wrapped around them in a groove, often smeared with tallow. Keeping the rope seal moist, thus swollen, was recognised as an important factor in achieving a good seal. As the steam spring cylinders were in the lower part of the boiler, below the water line, it was expected that they would seal well. Despite this, they continued to give trouble with leakage and were eventually removed and replaced with iron or steel leaf springs. Wood in 1831 illustrates one of the Killingworth locomotives, now fitted with metal leaf springs and also coupling rods.\n\nGeorge Stephenson's first locomotive was the \"Blücher\" of 1814. This was a four-wheeled locomotive with the wheels coupled by spur gears. It suffered from poor traction on the relatively new technology of edge rails with flanged wheels, put down to the problem of maintaining a good contact with them. It was the first of a batch of early Stephenson locomotives known as the 'Killingworth Colliery locomotives'. Stephenson's next design was a development of this, still with four wheels, but now using a chain drive to couple them together. This was his first locomotive to use steam springs.\n\nStephenson had gained a reputation as a builder of locomotives and was approached to build the first locomotive for use in Scotland, on the Kilmarnock and Troon Railway. \"The Duke\" was larger, with six wheels, and used the same chain drive and steam springs as the Killingworth locomotives. As this locomotive was to be built for an outside customer, Stephenson could no longer use the workshop facilities at Killingworth and so it was built at his friend William Losh's Walker Iron Works in Newcastle. Improvements of this locomotive were detailed in a patent, jointly filed with Losh, on 30 September 1816.\n\n\"The Duke\" was probably completed in 1817 and ran at Kilmarnock, but seems to have continued the problems of rail breakage. It was sold to the Earl of Elgin in October 1824 for his railway in Fife, but being too heavy for the rails was used as a stationary pumping engine in a quarry at Charlestown, and from 1830 at a colliery near Dunfermline; its subsequent fate is unrecorded. \n\nMost Scottish depictions of \"The Duke\" are inaccurate, being based on the Killingworth locomotives or even Stephenson's \"Rocket\", but in 1914 a commemorative silver model was made for the centenary and this alone seems accurate, showing the six wheels and the cylinders of the steam springs.\n\nFive locomotives were built for Hetton Colliery between 1820 and 1822, four of which were named: \"Hettton\", \"Dart\", \"Tallyho\" and \"Star\". These were of similar design to \"The Duke\", but four-wheeled with 3' 9\" wheels. They were built with steam springs, later removed owing to problems with steam leakage.\n\nIn 1852, \"Lyon\" was built as a replica of these early Hetton locomotives.\n\nLater locomotives abandoned the steam springs. For \"Locomotion\" on the Stockton and Darlington Railway in 1825 there was no springing provided. Although there were no springs, side-to-side compensation was provided to keep good contact between rails and wheels. One of the axles was carried in a 'cannon box' bearing that was pivoted centrally and could tilt from side to side. Although not giving a stable ride for the locomotive, it did allow the wheels to follow uneven track. The presence of this cannon box between the wheels also prevented the previous use of the central drive chain and so Stephenson adopted the now ubiquitous coupling rods for his first time. Reducing the travel of the suspension, compared to that with steam springs, also made the provision of free-running coupling rods easier, as it avoided the change in effective wheelbase when one axle moved relative to the other.\n\nThe unsprung ride broke the original eight-spoked cast-iron wheels and so these were replaced by Hackworth with his distinctive two piece cast-iron disc wheels, trued by wooden wedges between the concentric parts. Rail breakage had been reduced by this time with the use of stronger rails. These new malleable wrought iron rails had been the source of a rift between Stephenson and Losh, as Losh had originally expected to supply cast-iron rails from his ironworks, which Stephenson had briefly been a partner in. Stephenson though chose to use an improved iron rail from John Birkinshaw's Bedlington Ironworks instead.\n"}
{"id": "212490", "url": "https://en.wikipedia.org/wiki?curid=212490", "title": "Subatomic particle", "text": "Subatomic particle\n\nIn the physical sciences, subatomic particles are particles much smaller than atoms. The two types of subatomic particles are: elementary particles, which according to current theories are not made of other particles; and \"composite\" particles. Particle physics and nuclear physics study these particles and how they interact.\nThe idea of a particle underwent serious rethinking when experiments showed that light could behave like a stream of particles (called photons) as well as exhibiting wave-like properties. This led to the new concept of wave–particle duality to reflect that quantum-scale \"particles\" behave like both particles and waves (they are sometimes described as wavicles to reflect this). Another new concept, the uncertainty principle, states that some of their properties taken together, such as their simultaneous position and momentum, cannot be measured exactly. In more recent times, wave–particle duality has been shown to apply not only to photons but to increasingly massive particles as well.\n\nInteractions of particles in the framework of quantum field theory are understood as creation and annihilation of \"quanta\" of corresponding fundamental interactions. This blends particle physics with field theory.\n\nAny subatomic particle, like any particle in the three-dimensional space that obeys the laws of quantum mechanics, can be either a boson (with integer spin) or a fermion (with odd half-integer spin).\n\nThe elementary particles of the Standard Model include:\nVarious extensions of the Standard Model predict the existence of an elementary graviton particle and many other elementary particles.\n\nComposite subatomic particles (such as protons or atomic nuclei) are bound states of two or more elementary particles. For example, a proton is made of two up quarks and one down quark, while the atomic nucleus of helium-4 is composed of two protons and two neutrons. The neutron is made of two down quarks and one up quark. Composite particles include all hadrons: these include baryons (such as protons and neutrons) and mesons (such as pions and kaons).\n\nIn special relativity, the energy of a particle at rest equals its mass times the speed of light squared, \"E\" = \"mc\". That is, mass can be expressed in terms of energy and vice versa. If a particle has a frame of reference in which it lies at rest, then it has a positive rest mass and is referred to as \"massive\".\n\nAll composite particles are massive. Baryons (meaning \"heavy\") tend to have greater mass than mesons (meaning \"intermediate\"), which in turn tend to be heavier than leptons (meaning \"lightweight\"), but the heaviest lepton (the tau particle) is heavier than the two lightest flavours of baryons (nucleons). It is also certain that any particle with an electric charge is massive.\n\nAll massless particles (particles whose invariant mass is zero) are elementary. These include the photon and gluon, although the latter cannot be isolated.\n\nThrough the work of Albert Einstein, Satyendra Nath Bose, Louis de Broglie, and many others, current scientific theory holds that \"all\" particles also have a wave nature. This has been verified not only for elementary particles but also for compound particles like atoms and even molecules. In fact, according to traditional formulations of non-relativistic quantum mechanics, wave–particle duality applies to all objects, even macroscopic ones; although the wave properties of macroscopic objects cannot be detected due to their small wavelengths.\n\nInteractions between particles have been scrutinized for many centuries, and a few simple laws underpin how particles behave in collisions and interactions. The most fundamental of these are the laws of conservation of energy and conservation of momentum, which let us make calculations of particle interactions on scales of magnitude that range from stars to quarks. These are the prerequisite basics of Newtonian mechanics, a series of statements and equations in \"Philosophiae Naturalis Principia Mathematica\", originally published in 1687.\n\nThe negatively charged electron has a mass equal to of that of a hydrogen atom. The remainder of the hydrogen atom's mass comes from the positively charged proton. The atomic number of an element is the number of protons in its nucleus. Neutrons are neutral particles having a mass slightly greater than that of the proton. Different isotopes of the same element contain the same number of protons but differing numbers of neutrons. The mass number of an isotope is the total number of nucleons (neutrons and protons collectively).\n\nChemistry concerns itself with how electron sharing binds atoms into structures such as crystals and molecules. Nuclear physics deals with how protons and neutrons arrange themselves in nuclei. The study of subatomic particles, atoms and molecules, and their structure and interactions, requires quantum mechanics. Analyzing processes that change the numbers and types of particles requires quantum field theory. The study of subatomic particles \"per se\" is called particle physics. The term \"high-energy physics\" is nearly synonymous to \"particle physics\" since creation of particles requires high energies: it occurs only as a result of cosmic rays, or in particle accelerators. Particle phenomenology systematizes the knowledge about subatomic particles obtained from these experiments.\n\nThe term \"\"subatomic\" particle\" is largely a retronym of the 1960s, used to distinguish a large number of baryons and mesons (which comprise hadrons) from particles that are now thought to be truly elementary. Before that hadrons were usually classified as \"elementary\" because their composition was unknown.\n\nA list of important discoveries follows:\n\n\n\n"}
{"id": "15736133", "url": "https://en.wikipedia.org/wiki?curid=15736133", "title": "Tata OneCAT", "text": "Tata OneCAT\n\nTata OneCAT (Compressed Air Technology) was advertised as an upcoming compressed air car in 2008. India's Tata Motors was said to be collaborating with Air engine developer Guy Nègre of MDI to produce the vehicle.\n\nThe vehicle contains air tanks that can be filled in four hours by plugging the car into a standard electrical plug. MDI also plans to design a gas station compressor, which would fill the tanks in three minutes.\n\nThe OneCAT is a five-seat vehicle with a 200 litre trunk. There is no reliable data on range and top speed for this prototype available.\n\nAs of August 2009 there was no mentioning of the prototype or planned production of the TATA OneCAT on the TATA or MDI homepages. In December 2009 Tata's vice president of engineering systems confirmed that the limited range and low engine temperatures were causing difficulties. \nMeanwhile, all links, articles and archives relative to MDI have disappeared from Tata's website.\n\nIn February, 2012 Tata released information that their compressed-air vehicle would debut in August, 2012.\n\nIn February 2017, news report about the TaTa 'AirPod'.\n\n"}
{"id": "37462383", "url": "https://en.wikipedia.org/wiki?curid=37462383", "title": "The White Lady (Ireland)", "text": "The White Lady (Ireland)\n\nThe White Lady is an unusual standing stone, said to resemble a figure, located near the small fishing village of Dunmore East,in County Waterford, Ireland.\n\nThe standing stone is situated in open farmland overlooking the sea, between the small coves of Rathmoylan and Ballymacaw.\n\nIt is believed that the name \"White Lady\" is due to the standing stone having been whitewashed, or possibly painted white, at some point, although no traces of this remain. The purpose of the stone is not fully understood, it may have been erected as a marker to guide local fishermen, or it could have been an ancient symbolic or religious monument.\n\n"}
{"id": "13232579", "url": "https://en.wikipedia.org/wiki?curid=13232579", "title": "Toyota iQ", "text": "Toyota iQ\n\nThe Toyota iQ is a transverse engined, front-wheel-drive city car that was manufactured by Toyota and marketed in a single generation for Japan (2008–2016), Europe (2008–2015), and North America (2012–2015) where it was marketed as the Scion iQ. A rebadged variant was marketed in Europe as the Aston Martin Cygnet (2009–2013).\n\nDesigned at the Toyota European Design and Development studio in Nice, France, the iQ is noted for its specialized engineering to maximize passenger space, while minimizing exterior length. The design accommodates three passengers—and provisionally a fourth, under very tight conditions.\n\nFollowing a concept presented at the 2007 Frankfurt Auto Show, the production iQ debuted at the March 2008 Geneva Motor Show. Japanese sales began in November 2008 and European sales in January 2009.\n\nIn 2008, the iQ was named the Japanese Car of the Year. The name \"iQ\", an initialism of the term intelligence quotient, recalls a competitor, the Smart Fortwo. The letters \"iQ\" also stand for \"individuality\", \"innovation\", \"quality\", a hint at its \"cubic form\" and also a \"cue\" for owners to embrace new types of vehicles and lifestyles.\n\nThe iQ reached the end of production in December 2015, and it was discontinued in Japan on 4 April 2016.\n\nThe IQ design emphasizes low fuel consumption, maneuverability, environmental friendliness, and maximized interior space. Six specific design factors contribute to IQ's minimal overhangs, forward windscreen location, maximized cabin space and overall compactness:\n\nThe iQ features a transmissions differential housing located ahead of, rather than behind, the engine; a starter motor incorporated in the engine's flywheel, a high-mounted steering rack and a compact, high-located air conditioning unit behind the dashboard central area. The arrangement allows the front passenger to sit forward of the driver, giving increased rear passenger legroom. A shallow under-floor fuel tank reduces rear overhang.\n\nBecause of its overall width and engine displacement, the iQ is classified in its home market as a supermini, though its length complies with \"kei car\" dimensional regulations.\n\nProduction of the Scion iQ EV (Toyota eQ in Japan) was to be limited to 100 units for special fleet use in Japan and carsharing demonstration projects in the U.S. Deliveries of the all-electric version with a range of began in the U.S. in March 2013.\n\nThe two seat version was only sold in Japan.\n\nThe 1.0L engine is similar to the engine in Toyota Aygo. The iQ achieves by European standards.\n\nUK models include only petrol engines.\n\nEarly Japan models include only 1.0L three-cylinder engine. 1.33L engine option was added beginning in 2009.\n\nThe car is capable of fitting 1.6L four-cylinder engine.\n\nModels with the 1.33L engine include start and stop system, however, only with the manual transmission.\n\nJapan models include only CVT transmission.\n\nThe iQ includes nine airbags, dual frontal airbags, front seat-mounted side torso airbags, side curtain airbags, front passenger seat cushion airbag, a driver's knee airbag and a newly developed rear curtain airbag to protect backseat passengers' heads from rear-end collisions. Vehicle Stability Control, traction control, anti-lock brakes, brake assist, and electronic brakeforce distribution come standard.\n\nIn 2013, the UK's Vehicle and Operator Services Agency voted the Toyota iQ as top three-year-old car most likely to pass its first Ministry of Transport road worthiness test.\n\nThe Toyota FT-EV concept was unveiled at the January 2009 North American International Auto Show.\n\nIt is a battery electric concept vehicle with an estimated capacity of . Toyota plans to launch the production version of FT-EV in 2012.\n\nA slightly modified version was shown as the FT-EV II at the October 2009 Tokyo Motor Show.\n\nThis is a family of Toyota iQ custom body kits in Japanese market.\n\nMODELLISTA MAXI includes custom front bumper, side skirt, rear bumper. MODELLISTA MIXTURE includes custom B-pillar shadow, mirror cover, back window panel, side door trim. MODELLISTA MIXTURE side make set only includes custom mirror cover and side door trim.\n\nThis is a limited (100 units) version for Japanese market. It included a I4 engine, 6-speed manual transmission, stiffer sport suspension that lowers its ride height by , rear disk brakes, RAYS 16x5.5-in aluminium wheels with 175/60R16 tires, enhanced brakes, stiffening brace, tachometer, aluminium pedals, rear spoiler, GRMN emblem and a sport exhaust system.\n\nThe GAZOO Racing package adds a front bumper spoiler, side mudguards, rear bumper spoiler centre muffler, Toyota front fog lamps, original decal, front sport seat covers.\n\nThe vehicle was unveiled at the January 2009 Tokyo Auto Salon.\n\nThe GAZOO Racing cars were sold through Toyota's Netz dealer channel. It has MSRP of ¥1,972,000 (¥1,878,095+tax).\n\nThese are show cars that demonstrate possibilities for customers to personalise their cars.\n\niQ for Sports reflects modern urban chic through a purpose-made body kit emphasizing the iQ's broad stance, powerful geometry and clean sweeping lines.\n\niQ Collection focuses on interior customisation.\n\nThe vehicles were unveiled at the 2009 Frankfurt Motor Show.\n\nThe Scion iQ Concept car was built by Five Axis (California, USA) based on the Toyota iQ and displayed in April 2009 at the New York Auto Show. Based on the production Toyota iQ, the concept was equipped with a and 1.3-liter, DOHC Inline-4 engine, 18-inch wheels and widened wheel arches, with eleven airbags.\n\nThe production Scion iQ debuted at the 2010 New York Auto Show and was marketed for model years 2012 to 2015.\n\nToyota sold 15,695 units of the Scion iQ—248 in 2011, 8,879 in 2012, 4,046 in 2013, 2,040 in 2014, and 482 in 2015.\n\nThe GRMN iQ Racing Concept was based on Toyota iQ \"GAZOO Racing tuned by MN\" car sold in 2009, but was equipped with a supercharger and roll cage.\n\nThe vehicle was unveiled at the 2011 Tokyo Auto Salon.\n\nIt is a limited (100 units) version of Toyota iQ for Japanese market, based on the Toyota iQ 130G MT. It included the supercharger found in the GRMN iQ Racing Concept car.\n\nThe prototype vehicle was unveiled at the 2012 Tokyo Auto Salon.\n\nA prototype of the Toyota eQ (Scion iQ EV in the US) was exhibited at the 2011 Geneva Motor Show. The Scion iQ EV is the successor to the FT-EV II as an electric vehicle based on the Toyota iQ chassis. Toyota produced three generations of FT-EV concept cars, and the iQ EV is a production version of those concepts, incorporating the technological and design strengths of all three models. The exterior of the production version is based on the FT-EV III concept shown at the 2011 Tokyo Motor Show.\n\nThe U.S. launch of the Scion iQ EV was announced for 2012, and according to Toyota, for the initial roll-out the iQ EV would not be available to individual consumers, instead the carmaker decided to focus on fleet customers and car sharing programs. The iQ EV was scheduled to be produced at Toyota's Takaoka Plant in Toyota City beginning in August 2012 and the initial production was planned to be limited to 600 units, with 400 staying in Japan, 100 units destined to the U.S. and the other 100 for Europe. In September 2012 Toyota announced that due to customers' concerns about range and charging time, the production of the Scion iQ (Toyota eQ in Japan) will be limited to 100 units for special fleet use in Japan and the U.S. only, of which, 90 will be placed in American carsharing demonstration projects. The iQ EV will be priced in the Japanese market at (~). The iQ EV/eQ was scheduled to be released in both countries in December 2012.\n\nThe first 30 units were delivered in the U.S. to the University of California, Irvine in March 2013 for use in its Zero Emission Vehicle-Network Enabled Transport (ZEV-NET) carsharing fleet. Since 2002 the ZEV-NET program has been serving the transport needs of the Irvine community with all-electric vehicles for the critical last mile of commutes from the Irvine train station to the UC campus and local business offices. In September 2013, another 30 units were allocated to City Carshare to operate Dash, a three-year pilot carsharing program in Hacienda Business Park, in Pleasanton, California.\n\nDesigned as a city commuting vehicle, the iQ EV has a lower battery capacity that also translates into a shorter charging time, allowing the car to be fully recharged in approximately three hours, and using fast charging, the battery can be recharged up to 80% capacity in only 15 minutes. The iQ EV has a 150 cell 12 kWh 277.5 V lithium-ion battery pack that delivers a NEDC-certified range of , and rated in the U.S. Based on further development of Toyota's Hybrid Synergy Drive technology, the iQ EV's fully electric powertrain comprises an air-cooled, 47 kW electric motor/generator, the 12 kWh battery pack, a 3 kW water-cooled battery charger, an inverter, a DC/DC converter and a motor speed reduction mechanism. Maximum torque of is delivered to the front wheels, giving the iQ EV 0–100 km/h (62 mph) acceleration of 14.0 seconds and a maximum speed of . Like other Toyota full hybrid vehicles, the iQ EV is equipped with a regenerative braking system.\n\nThe iQ EV has a minimum turning radius of just and with a length of , making the iQ EV longer than a standard iQ. The electric car shares the iQ overall width of , height of and wheelbase of . High tensile sheet steel has been extensively used in the body shell construction to minimize the additional weight caused by the lithium-ion battery pack, and as a result, the iQ EV weighs just more than a standard 1.3L CVT iQ.\n\nThe U. S. Environmental Protection Agency rated the 2013 iQ EV with a combined fuel economy of 121 miles per gallon gasoline equivalent (MPG-e) () with an energy consumption of 28 kW-hrs/100 miles. The city rating is 138 MPG-e () with an energy consumption of 24 kW-hrs/100 miles and 105 MPG-e () with an energy consumption of 32 kW-hrs/100 miles for highway driving.\n, these ratings allow the 2013 iQ EV to be the second most fuel efficient EPA-certified vehicle of all fuel types considered in all years behind the BMW i3. The iQ EV was ranked first in DOE-EPA's 2013 Annual Fuel Economy Guide.\n\nThe Aston Martin Cygnet is a rebadged variant of the Toyota/Scion iQ marketed by Aston Martin beginning with model year 2011—enabling Aston Martin to comply with the 2012 European Union-imposed fleet average emissions regulations.\n\nThe Cygnet was initially only marketed in the UK. Sales commenced in January 2011 and the market coverage was expanded to cover other European countries the following year. Sales were not restricted, but demand from existing Aston Martin owners for Cygnet was expected to take priority initially. Aston Martin CEO Ulrich Bez announced shipping expectations of about 4000 per year at a price of about £30,000 – about three times as much as the iQ. Bez claimed that the Cygnet demonstrated the company's \"commitment to innovation and integrity\", whilst respecting the need to \"satisfy demands of emissions and space\".\n\nThe Cygnet featured revisions to the exterior and interior but shared other specifications with the iQ, having a 1.3L inline-four engine,<ref name=\"astonmartin.com/cars\"></ref> it produced 110 g of /km and fuel consumption of .\n\nIn September 2013, after just over two years of production, Aston Martin announced that it would stop production of their Cygnet city car. The Cygnet has been the second shortest running production car in the history of Aston Martin after the 2012 Aston Martin Virage, which was only produced for a year. The Cygnet was cancelled due to disastrously low sales, with the car reaching only 150 units in the UK (approximately 300 in total) rather than its annual target of 4000.\n\nIn June 2018 Aston Martin announced a one-off 4.7-litre V8 edition for a customer. It uses the engine, transmission, suspension, brakes and wheels from the Aston Martin Vantage S. New subframes and wheel arches where made to combined the body and mechanicals.\n\n\n\n \n"}
{"id": "29758999", "url": "https://en.wikipedia.org/wiki?curid=29758999", "title": "Unbroken: A World War II Story of Survival, Resilience, and Redemption", "text": "Unbroken: A World War II Story of Survival, Resilience, and Redemption\n\nUnbroken: A World War II Story of Survival, Resilience, and Redemption is a 2010 non-fiction book by Laura Hillenbrand, author of the best-selling book \"\" (2001). \"Unbroken\" is a biography of World War II hero Louis Zamperini, a former Olympic track star who survived a plane crash in the Pacific theater, spent 47 days drifting on a raft, and then survived more than two and a half years as a prisoner of war in three brutal Japanese prisoner-of-war camps.\n\n\"Unbroken\" has spent more than four years on \"The New York Times\" best seller list, 14 weeks at number one, it is the 5th longest-running nonfiction best seller of all time.\n\nA feature film based on the book was adapted by Universal Pictures and Legendary Pictures. Angelina Jolie directed this film while the Coen brothers, Richard LaGravenese, and William Nicholson wrote the screenplay. Jack O'Connell portrays Louis Zamperini and the film had its general release on Christmas, 2014.\n"}
{"id": "8652769", "url": "https://en.wikipedia.org/wiki?curid=8652769", "title": "Undecylenic acid", "text": "Undecylenic acid\n\nUndecylenic acid is an organic compound with the formula CH=CH(CH)COH. It is an unsaturated fatty acid. It is a colorless oil. Undecylenic acid is mainly used for the production of Nylon-11 and in the treatment of fungal infections of the skin, but it is also a precursor in the manufacture of many pharmaceuticals, personal hygiene products, cosmetics, and perfumes. Salts and esters of undecylenic acid are known as undecylenates.\n\nUndecylenic acid is prepared by pyrolysis of ricinoleic acid, which is derived from castor oil. Specifically, the methyl ester of ricinoleic acid is cracked to yield both undecylenic acid and heptanal. The process is conducted at 500–600 °C in the presence of steam. The methyl ester is then hydrolyzed.\n\nUndecylenic acid is converted to 11-aminoundecanoic acid on an industrial scale. This aminocarboxylic acid is the precursor to Nylon-11.\n\nUndecylenic acid is reduced to undecylene aldehyde, which is valued in perfumery. The acid is first converted to the acid chloride, which allows selective reduction.\n\nUndecylenic acid is an active ingredient in medications for skin infections, and to relieve itching, burning, and irritation associated with skin problems. For example, it is used against fungal skin infections, such as athlete's foot, ringworm, tinea cruris, or other generalized infections by \"Candida albicans\". When used for tinea cruris, it can result in extreme burning. In some case studies of tinae versicolor, pain and burning result from fungicide application. In a review of placebo-controlled trials, undecenoic acid was deemed efficacious, alongside prescription azoles (e.g., clotrimazole) and allylamines (e.g., terbinafine). Undecylenic acid is also a precursor to antidandruff shampoos and antimicrobial powders.\n\nIn terms of the mechanism underlying its antifungal effects against \"Candida albicans\", undecylenic acid inhibits morphogenesis. In a study on denture liners, undecylenic acid in the liners was found to inhibit conversion of yeast to the hyphal form (which are associated with active infection), via inhibition of fatty acid biosynthesis. The mechanism of action and effectiveness in fatty acid-type antifungals is dependent on the number of carbon atoms in the chain, with efficacy increasing with the number of atoms in the chain.\n\nUndecylenic acid is approved by the U.S. FDA for topical route and is listed in the Code of Federal Regulations.\n\nUndecylenic acid has been used as a linking molecule, because it is a bifunctional compound. Specifically it is an α,ω- (terminally functionalized) bifunctional agent. For instance, the title compound has been used to prepare silicon-based biosensors, linking silicon transducer surfaces to the terminal double bond of undecylenic acid (forming an Si-C bond), leaving the carboxylic acid groups available for conjugation of biomolecules (e.g., proteins).\n"}
