{"id": "51276448", "url": "https://en.wikipedia.org/wiki?curid=51276448", "title": "2008 June Hong Kong Rainstorm", "text": "2008 June Hong Kong Rainstorm\n\n2008 June Hong Kong Rainstorm was a rainstorm in Hong Kong on 7 June 2008, that caused flooding and landslides. It resulted in 2 deaths and 16 injuries. The Hong Kong Observatory recorded 145.5mm of precipitation at its headquarters from 08:00 to 09:00, setting the highest 1-hour precipitation record. 307.1mm of precipitation was recorded during the whole day.\n\nAn active trough had been affecting the South China coast since May 29th, 2008. Around dawn on June 7th, rainfall arrived in Hong Kong. The rainfall mainly focused on Lantau Island, Kowloon and Hong Kong Island. The peak of the precipitation was from 08:00 to 09:00 in the morning. The Hong Kong Observatory recorded 145.5mm of precipitation, a record high, at its headquarters. Precipitation at Tung Chung for the entire day even surpassed 400mm. Former Chief Executive Donald Tsang, described it as \"once in a century\". The Civil Engineering and Development Department of Hong Kong estimated it as a \"once in 1100 years\" occurrence.\n\nAn Amber Rainstorm signal was issued at 05:15, and escalated to Red at 05:55. 112mm and 101mm of rain were recorded at the Eastern and Southern Districts respectively. 86mm was recorded at Sai Kung District. The Hong Kong Observatory eventually issued a Black Rainstorm Signal at 06:40 and it was sustained for 4 hours and 20 minutes. Red replaced Black at 11:00 and was then replaced by Amber at 11:30. All signals were cancelled at 13:30. \nA Landslide Warning was maintained from 01:00 June 7th till 12:00 June 8th.\n\nA retaining wall at Old Coffee Bay, Castle Peak Road, Tuen Mun fell and collapsed on a store with two residents. The two residents killed were cousins visiting from mainland China. Their bodies were not unearthed until 18:30 in the evening by firefighters despite efforts of nearby residents and firefighters.\n\nA section of Hung Hom Road collapsed at 13:00 on June 8th due to heavy rainfall the day before, causing detours.\n\n1.5m flood was observed at Sheung Wan, as well as seawater back-flow. Village houses in Pokfulam were flooded, as were many roads, including Tai Hang Road, Pokfulam Road, Water Street and Hill Road, Wong Nai Chung Road, Tin Lok Lane and Wong Chuk Hang Road. A landslide was seen at Kennedy Town. 13 slopes were pronounced at high risk of landslide after the rainstorm.\n\nNorth Lantau Highway experienced the most severe flood ever. Major landslip occurred in Tung Chung, blocking all lanes of the highway. Ground commute between Tung Chung, airport and downtown was completely halted, except for train service.\n\n- 326 landslips and 539 floods were reported\n- 410 flights were delayed, 14 were canceled on June 7th\n- Hong Kong Wetland Park and Disneyland Resort were temporarily closed in the morning\n- Ngong Ping 360 service was halted \n- All banks and judiciary organisations closed for the day\n- The central allocation of primary school was delayed \n- Many hiking trails were closed, detoured or permanently blocked, especially on Lantau Island\n\nChinese version of the same incident:\n2008年6月香港暴雨\n"}
{"id": "45642610", "url": "https://en.wikipedia.org/wiki?curid=45642610", "title": "Artists Against Fracking", "text": "Artists Against Fracking\n\nArtists Against Fracking is an association of artists initiated by Yoko Ono and her son, Sean Lennon, also including Mark Ruffalo, Robert de Niro, Lady Gaga, Paul McCartney, and Deepak Chopra. \n\nAs of August 2012, 180 artists were part of the group, which opposes natural gas drilling in the Marcellus shale. \n\nIn March 2013, the Independent Oil & Gas Association of New York filed a complaint with the New York Lobbying Board claiming the group had violated lobbying regulations, following an Associated Press news story suggesting that they should formally register as a lobbying group and had not done so. As of late 2014, hydraulic fracking is prohibited in New York state.\n\n \n"}
{"id": "17573670", "url": "https://en.wikipedia.org/wiki?curid=17573670", "title": "Axon Automotive", "text": "Axon Automotive\n\nAxon Automotive is a British car manufacturer and car components manufacturer based in Northampton, Northamptonshire. The company is focused on design and material technologies.\n\nAxon unveiled its hatchback on 23 May 2008 at the \"Sexy Green Car Show\" at the Eden Project. The new car, which was expected to be on sale in 2010, has a claimed CO emission rate of less than 80 g/km.\n\n"}
{"id": "2524938", "url": "https://en.wikipedia.org/wiki?curid=2524938", "title": "Beryllium nitride", "text": "Beryllium nitride\n\nBeryllium nitride, BeN, is a nitride of beryllium. It can be prepared from the elements at high temperature (1100–1500 °C), unlike Beryllium azide or BeN, it decomposes in vacuum into beryllium and nitrogen. It is readily hydrolysed forming beryllium hydroxide and ammonia. It has two polymorphic forms cubic α-BeN with a defect anti-fluorite structure, and hexagonal β-BeN. It reacts with silicon nitride, SiN in a stream of ammonia at 1800–1900 °C to form BeSiN.\n\nBeryllium nitride is prepared by heating beryllium metal powder with dry nitrogen in an oxygen-free atmosphere in temperatures between 700 and 1400 °C.\n\nIt is used in refractory ceramics as well as in nuclear reactors and to produce radioactive carbon-14 for tracer applications.\n\nBeryllium nitride reacts with mineral acids producing ammonia and the corresponding salts of the acids:\n\nIn strong alkali solutions, a beryllate forms, with evolution of ammonia:\n\nBoth the acid and alkali reactions are brisk and vigorous. Reaction with water, however, is very slow:\n\nReactions with oxidizing agents are likely to be violent. It is oxidized when heated at 600 °C in air.\n"}
{"id": "496124", "url": "https://en.wikipedia.org/wiki?curid=496124", "title": "BirdWatch Ireland", "text": "BirdWatch Ireland\n\nBirdWatch Ireland (BWI) is a voluntary conservation organisation devoted to the conservation and protection of wild birds and their habitats in Ireland. It was formerly known as the Irish Wildbird Conservancy (IWC). Irish Wildbird Conservancy was founded in 1968, among others by Major Robert (Robin) Ruttledge, an Irish ornithologist who became its first president. \n\nBWI has over 15,000 active members and supporters, and a network of 30 branches actively promoting the importance of birds and habitats, and general conservation issues. It publishes the annual journal \"Irish Birds\" and the quarterly magazine \"Wings\". It manages a number of nature reserves including Little Skellig.\n\nBirdWatch Ireland is a member of the Irish Environmental Network, the Sustainable Water Network (SWAN), Environmental (Ecological) NGOs Core Funding Ltd (EENGO), Working and Educating for Biodiversity (WEB) and the Irish Uplands Forum (IUF). They also work closely with the Irish National Biodiversity Data Centre in providing wildlife monitoring data. \n\nBirdTrack is an online citizen science website, operated by the British Trust for Ornithology (BTO) on behalf of a partnership of the BTO, the RSPB, BirdWatch Ireland, the Scottish Ornithologists' Club and the Welsh Ornithological Society ().\n\nThe Garden Bird Survey (GBS) is one of BirdWatch Ireland's most popular volunteer surveys which receives over 1,000 submissions annually when it takes place between December and February.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "1433627", "url": "https://en.wikipedia.org/wiki?curid=1433627", "title": "British timber trade", "text": "British timber trade\n\nThe British timber trade was importation of timber from the Baltic, and later North America, by the British. During the Middle Ages and Stuart period, Great Britain had large domestic supplies of timber, especially valuable were the famous British oaks. This timber formed the backbone of many industries such as shipbuilding but not iron smelting which used charcoal derived from the wood of various trees.\n\nFrom before the industrial revolution period the price of timber in England had been increasing as domestic quantities became more difficult to obtain. Many industries thus were forced to change to substitutes. As the industrial revolution progressed coal replaced timber for use as fuel, while brick replaced timber for use in construction.\n\nIt would be many decades, however, before iron could be used to replace timber in shipbuilding. By the eighteenth century England had not exhausted its supply of suitable domestic hardwood timber but – like the Netherlands – it imported softwood supplies. While every nation has trees and wood, ship timber is a far more limited product. The ideal woods were oak, Scots pine – but not spruce, and other large trees. Especially difficult to find were trees suitable to be masts, a crucial requirement for any sailing ship, and one that often had to be replaced after storms or wear. As suitable trees take decades to grow, in densely populated nations like England any given square metre of land could, usually, be far more valuably employed by producing foodstuffs rather than timber.\n\nTimber was thus only a viable industry in sparsely populated lands such as Scandinavia, those in the Baltic Sea area, and in North America. The Baltic countries, and especially Norway, had other benefits including superior sawmills, and often lower transport prices than distant overland travel. The British shipping industry, by the late seventeenth century, increasingly used imports of Baltic timber.\n\nThe importation of timber from the Baltic had two notable defects in the mind of British statesmen. The first was one of economics. The British had a large trade deficit with the entire Baltic region. Great Britain required a large number of essential resources from the Baltic, but did not have enough goods to export to the Baltic to make up for these purchases. Thus the shortfall had to be made up in bullion exports. This imbalance caused great displeasure among the mercantilist economists of the day. Further compounding the problem was that unlike other areas where the British had a trade deficit, such as India, the Baltic trade could not be justified on the grounds that Great Britain gained in the end from re-export to the continent, Baltic goods were overwhelmingly used in Britain. Most during the later half of the seventeenth century regarded the Baltic trade as a regrettable, but necessary expenditure for the defence of the land. Some consolation was, however, provided to the mercantilists by the employment of the timber in the merchant fleet that would later assist in bringing bullion into the land. Also of concern was the foreign domination of the Baltic timber trade. This problem was only partially solved by the inclusion of timber in the Navigation Acts of 1651 and 1660. While the acts successfully excluded the Dutch from Britain's trade with the Baltic, it still allowed the Baltic countries the right to import their own timber. It was mostly the Danes, Swedes, and Germans who replaced the Dutch in this trade as British merchants did not see it as profitable enough. This was because the Baltic trade was a difficult one to profit from as one load of British manufactured goods could buy seventy loads of timber, most ships entering the Baltic were thus empty, a great inefficiency. Most British merchants could employ their ships in more profitable colonial and manufactured goods trades, an option that the Baltic merchants did not have.\n\nThese commercial problems of Baltic timber imports were compounded by a military and strategic problem. The dependency on Baltic timber was paramount in the minds of British statesmen in the late seventeenth century mostly because of the strategic dangers. There were no trades as militarily important as the Baltic lumber trade, but there were also few more fragile. Besides the trade coming from Norway, the timber ships had to come through the Sound – the narrow straits separating Denmark from Sweden- a passage easily blocked by enemy navies, especially the Dutch who were geographically well placed to impede trade through the North Sea, as could, to a lesser extent, the French. Also threatening was the rise of Sweden who by 1690 was at the height of its brief period of being a global power. Sweden also was a strong trade protectionist and had imposed high duties of British imports. Sweden's empire was also expanding having seized Livonia as well as Pomerania, both important sources of timber. Thus beginning with the Anglo-Dutch wars of the later seventeenth century British statesmen and merchants began to look for some alternative to these imports.\n\nDespite commercial clamouring for regulation of the Baltic timber trade, Josiah Child, for instance, thought the trade should be limited to only British vessels, no actions were taken until 1704 when British security was threatened. The great threat to Britain's security occurred during the War of the Spanish Succession, what some have termed the first global conflict. Only then did the British parliament attempt to break Britain's dependence upon Baltic timber. The only viable alternative to the Baltic areas was North America, New England especially had vast amounts of suitable timber. The great disadvantages were a lack of infrastructure in the colonies and much higher transport costs to British markets. Beginning in 1704 a number of initiatives were launched to try to encourage the use of colonial timber over that from the Baltic. These encouragements included bounties from North American producers, and rules forbidding the export of colonial timber to anywhere other than England. These efforts were quite unsuccessful, however, and both the navy and the merchant fleets remained dependent upon Baltic timber. Baltic timber still remained about a third the price of timber from North America. After the War of the Spanish succession ended the threat to British timber supplies receded, and despite the continuation of strong mercantilist pressure to increase the protectionism this was not done for the next century.this increased the opportunities for jobs in British North America (B.N.A).\n\nOver the entire eighteenth century Britain's naval supremacy in the North Sea area was never questioned. However, Britain's commercial position remained unfavourable. With only occasional exceptions Britain was still in constant trade deficit with the entire Baltic region. Despite this condition being viewed as harmful by the economists of the day no action of any significance was taken to try to prevent it. While the laws of Queen Anne's era remained in place, these were well known to be totally ineffective in curbing the dependence on the Baltic. During this period more economic disadvantages of the trade also developed. The American colonies still could exported little timber to England, only great masts could justify the cost of the long transatlantic journey. Thus New England, rather than producing timber and naval stores for the motherland was instead building its own ships that were cheaper and often of superior quality to those produced in Britain. This further violated important tenets of mercantilism and the old colonial system which considered manufacturing in the colonies to be counter Britain interests. Parliament, however, failed to be swayed by shipwrights, merchants or colonial timber producers who were hoping for an end to Baltic competition. It would again take pressure from the navy to introduce mercantilist policies.\n\nThe next attempt to break Britain's dependence on the Baltic once again occurred during a great Europe wide conflict that had significant naval elements. The Napoleonic Wars reopened Britain's fears of the Baltic timber trade being severed. Denmark and the straits, like all of continental Europe, were at the mercy of Napoleon's army and many of the rest of the timber ports within the Baltic were threatened by Napoleon's Continental system. The government thus made a more concerted attempt than ever before to break Britain's dependence upon Baltic timber. Throughout the period commencing in 1795 tariffs on foreign timber imports steadily rose. Eventually in 1807 a 275% levy was placed upon all Baltic timber imports to Britain. This levy succeeded in making Canadian timber more cost effective than that from the Baltic. Canadian timber exports to Britain more than tripled from 27,000 loads in 1807 to 90,000 loads in 1809. The sheer bulk of timber and its many requirements soon led the transatlantic timber trade to become Britain's largest employing a quarter of Britain's merchant tonnage. The previous large Baltic trade almost vanished with European wood being used only for luxury items.\n\nAfter peace had returned to Britain the timber tariffs did not have long to survive. While at first they were continued, and even strengthened, by 1820 timber became one of the first areas for free trade theory to be applied. In part this was caused by the continued existence of powerful merchants who wanted to see the old Baltic trade restored. The trading interests with the colonies were even stronger, however. The much longer voyage from British North America to Britain meant far more ships and seamen had to be employed. The longer route not only meant more business, but it also was a more profitable route for British merchants, especially since foreigners were still excluded by the Navigation Acts. Military sources, however, disliked Canadian timber. The longer voyage lowered its quality and it was far more susceptible to the dry rot that was one of the navy's more implacable foes. A frigate made of colonial wood tended to have only half the life span of a Baltic ship.\n\nBecause of timber's great importance, in 1820 a committee of the House of Lords was formed to review the state of the timber trade. Led by Lord Lansdowne the committee strongly supported the reduction of the duties. This has been viewed as one of the first successes of free trade ideology in Britain. The duties were not eliminated, but they were brought to a level that left Baltic wood competitive with that from Canada. These reductions were a rare example of \"laissez-faire\" in an era still almost totally committed to mercantilism. The post-war era also saw a great unwillingness to enforce the duties that were in place. Rampant smuggling of timber into and out of Norway was mostly ignored, as were the illegal exports of bullion to fund the trade. In 1824 the duties were further lowered when Britain began to sign reciprocity treaties with other powers. Out of the first ten bilateral trade treaties signed, seven of them were with Baltic nations covering all the major timber exporters except for Russia. These quick reversals of Baltic trade policy in an era before free trade was paramount can almost certainly be attributed to the navy's unwillingness to become reliant on Canadian timber now that trade with the Baltic had been unquestionably secured.\n\nIn seeking the exploit of further timber resources was one of the reasons of the First and the Second Anglo-Burmese War (1824–1826 and 1852, respectively). Burma had to cede Assam, Manipur, Rakhine (Arakan) and Tanintharyi (Tenessarim) and later the remaining coastal provinces: Ayeyarwady, Yangon and Bago. During the following years timber was harvested introducing new techniques. The British cut the bark off the trees and left them to dry before felling them roughly four years later with the use of elephants. Dry wood was easier to fell and floated in water and therefore the river Irrawady was used for transporting the wood to the saw mills near Rangoon.\n\nOther sources were the wood from Australia which included Jarrah and Karri wood. Some streets in London are still paved with Karri wood from the southern parts of Western Australia. But Jarrah wood is more resistant to water and therefore more valuable then Karri in the constructions of ships.\n\n"}
{"id": "47271988", "url": "https://en.wikipedia.org/wiki?curid=47271988", "title": "Burning Gold (1936 film)", "text": "Burning Gold (1936 film)\n\nBurning Gold is a 1936 American drama film directed by Sam Newfield and starring William Boyd, Judith Allen and Lloyd Ingraham. It is a modern-day western about a World War I veteran who becomes a wildcat prospector for oil and enjoys a major strike.\n\nThe film's sets were designed by art director Lewis J. Rachmil. It was made as a B movie by the Poverty Row company Winchester Productions and was distributed by Republic Pictures in the US and British Lion in the United Kingdom. \n\nFamed in his Western role of Hopalong Cassidy, Bill Boyd appeared in three 1936 films of non Western genre for Winchester Productions, all produced by George A. Hirliman, directed by Sam Newfield, and released by Republic Pictures. The other films were Federal Agent and Go-Get-'Em, Haines.\n\n\n"}
{"id": "7656652", "url": "https://en.wikipedia.org/wiki?curid=7656652", "title": "Calculated Ignition Index", "text": "Calculated Ignition Index\n\nThe Calculated Ignition Index (CII) is an index of the ignition quality of residual fuel oil.\n\nThe running of all internal combustion engines is dependent on the ignition quality of the fuel. For spark-ignition engines the fuel has an octane rating. For diesel engines it depends on the type of fuel, for distillate fuels the cetane numbers are used. Cetane numbers are tested using a special test engine and the existing engine was not made for residual fuels. For residual fuel oil two other empirical indexes are used CII and Calculated Carbon Aromaticity Index (CCAI). Both CII and CCAI are calculated from the density and kinematic viscosity of the fuel.\n\nFormula for CII:\n\nWhere:\nD = density at 15°C (kg/m³)\nV = viscosity (cST)\nT = viscosity temperature (°C)\n\nCII was designed to give out numbers in the same order as the cetane index for distillate fuels.\n"}
{"id": "4249191", "url": "https://en.wikipedia.org/wiki?curid=4249191", "title": "Cefn Croes Wind Farm", "text": "Cefn Croes Wind Farm\n\nCefn Croes is a wind farm in Ceredigion, Wales. It is located in the Cambrian Mountains on Cefn Croes mountain, 573m (1,880 ft) south of the A44 road between Aberystwyth and Llangurig, in west Wales. The construction of the wind farm commenced in February 2004, and was completed in the spring of 2005 when the 39 wind turbines started producing electricity. The maximum installed nameplate capacity is 58.5 MW.\n"}
{"id": "12568222", "url": "https://en.wikipedia.org/wiki?curid=12568222", "title": "Continental shelf of Russia", "text": "Continental shelf of Russia\n\nThe continental shelf of Russia (also called the Russian continental shelf or the Arctic shelf in the Arctic region) is a continental shelf adjacent to Russia. Geologically, the extent of the shelf is defined as the entirety of the continental shelves adjacent to Russia's coast. In international law, however, the United Nations Convention on the Law of the Sea more narrowly defines the extent of the shelf as the seabed and subsoil of the submarine areas over which a state exercises sovereign rights. \n\nThe Siberian Shelf in the Arctic Ocean is the largest (and least explored) of the Russian shelves, a region of strategic importance because of its oil and natural gas reserves. Other parts of the Russian shelf are typically named after the corresponding seas: Barents Shelf (Barents Sea Shelf), Chukchi Shelf (Chukchi Sea Shelf), etc. With the exception of internal Russian seas, these geological shelves are shared with other countries which share the corresponding seas. For example, the Chukchi Shelf is shared between Russia and the United States according to the 1990 USA-USSR maritime boundary.\n\nOn 20 December 2001, Russia made an official submission into the UN Commission on the Limits of the Continental Shelf in accordance with the United Nations Convention on the Law of the Sea (article 76, paragraph 8). In the document it is proposed to establish new outer limits of the continental shelf of Russia beyond the previous 200 nautical mile zone (370 km), but within the Russian Arctic sector. The territory claimed by Russia in the submission is a large portion of the Arctic within Russia's sector and extending to the North Pole. One of the arguments was a statement that eastern portion of the Lomonosov Ridge, an underwater mountain ridge extending across the polar basin, and the Mendeleev Ridge are extensions of the Eurasian continent. In 2002, the UN Commission requested that Russia submit additional scientific evidence in support of its claim.\n\nAdditional research for the Russian claim was planned over 2007–2008 as part of the Russian program for the International Polar Year. The program investigated the structure and evolution of the Earth's crust in the Arctic regions neighbouring Eurasia, such as the regions of Mendeleev Ridge, Alpha Ridge, and Lomonosov Ridge, to discover whether they were linked with the Siberian shelf. Major means of research during the expedition were the \"Akademik Fedorov\" research ship, the \"Russia\" nuclear icebreaker with two helicopters and geological probe devices, and Il-18 aircraft with gravimetric devices.\n\nIn June 2007, a group of 50 Russian scientists returned from a six-week expedition on the \"Russia\" with the news that the Lomonosov Ridge was linked to Russian Federation territory, supporting Russia's claim over the oil-and-gas rich triangle. The territory contained 10 billion tonnes of gas and oil deposits, the scientists said. Russian President Vladimir Putin then used this information to restate the 2001 Russian claim.\n\nOn 2 August 2007, Russian explorers in a submersible planted the national flag on the seabed below the North Pole in symbolic support of the 2001 claim. A mechanical arm dropped a specially made rust-proof titanium flag onto the Arctic seabed at a depth of .\n\nIn response to Russia's planting the national flag on the seabed at the North Pole, Canadian Foreign Minister Peter MacKay said, \"This isn't the 15th century. You can't go around the world and just plant flags and say 'We're claiming this territory'\". In response to these words the Foreign Minister of the Russian Federation Sergey Lavrov stated: \"I was amazed by my Canadian counterpart's statement that we are planting flags around. We’re not throwing flags around. We just do what other discoverers did. The purpose of the expedition is not to stake whatever rights of Russia, but to prove that our shelf extends to the North Pole\".\n\nIn mid-September 2007, Russia's Natural Resources Ministry issued a statement:\nOn August 4, 2015, Russia submitted additional data in support of its bid, containing new arguments based on \"ample scientific data collected in years of Arctic research\", for territories in the Arctic to the United Nations. Through this bid, Russia is claiming 1.2 million square kilometers (over 463,000 square miles) of Arctic sea shelf extending more than 350 nautical miles (about 650 kilometers) from the shore.\n\nOn February 09, 2016, Russia formally submitted to the United Nations a revised application with substantiated evidence of shelf claims to the Arctic Ocean seabed, including an area under the North Pole. \n\nThe evidential base of this application includes geology and geophysics evidence from nine Russian scientific expeditions. They were launched by Ministry of natural resources and environmental protection in cooperation with the Ministry of Defence and Russian Academy of Sciences. It is important to note that the expeditions were performed by scientific icebreakers and submarines. Moreover a geological office has conducted acquisitions of bathymetric multibeam sounder, integrated seismic exploration, airborne geophysical measurements and geological sampling of the main Amerasian and Eurasian basins’ structures. During the work researchers used a unique technology, specially designed for difficult ice conditions. The icebreaking research vessel \"Akademik Fedorov\" was refitted specifically for seismic operations in ice thickness up to three meters. \n\nThe justification of Russian claim is confirmed by the continuity of the sedimentary magnitude, elements of basal complex, as well as the overall continuity and consistency of the deep layers of the earth's crust and the absence of strike-slip transverse faults at the junction of the Lomonosov Ridge and the Eurasian continent. \n\nAll collected data show the continental character of the Lomonosov Ridge, the Mendeleev-Alfa High, the Chukotka Plateau, as well as the continuous extension of these elements from the shallow Eurasian shelf. \n\nOn August, 09, 2016, all of this evidence were presented in New York at the 41st session of the UN Commission on the Limits of the Continental Shelf (CLCS).\n\n"}
{"id": "26866107", "url": "https://en.wikipedia.org/wiki?curid=26866107", "title": "Corona ring", "text": "Corona ring\n\nA corona ring, also called an anti-corona ring, is a toroid of conductive material, usually metal, which is attached to a terminal or other irregular hardware piece of high voltage equipment. The role of the corona ring is to distribute the electric field gradient and lower its maximum values below the corona threshold, either preventing corona discharge entirely or transferring its destructive effects from the valuable hardware to the expendable ring. Corona rings are used on very high voltage power transmission insulators and switchgear, and on scientific research apparatus that generates high voltages. A very similar related device, the grading ring is used around insulators.\n\nCorona discharge is a leakage of electric current into the air adjacent to high voltage conductors. It is sometimes visible as a dim blue glow in the air next to sharp points on high voltage equipment. The high electric field ionizes the air, making it conductive, allowing current to leak from the conductor into the air in the form of ions. In electric power transmission lines and equipment, corona results in an economically significant waste of power and may deteriorate the hardware from where it originates. In devices such as electrostatic generators, Marx generators, and television sets, the current load caused by corona leakage can reduce the voltage produced by the device, causing it to malfunction. Coronas also produce noxious and corrosive ozone gas, which can cause aging and embrittlement of nearby structures such as insulators, and create a health hazard for workers and local residents. For these reasons corona discharge is considered undesirable in most electrical equipment.\n\nCorona discharges only occur when the electric field (potential gradient) at the surface of conductors exceeds a critical value, the dielectric strength or \"disruptive potential gradient\" of air. It is roughly 30 kilovolts per centimeter, but varies with atmospheric pressure, so corona is more of a problem at high altitudes. The electric field at a conductor is greatest where the curvature is sharpest, and therefore corona discharge occurs first at sharp points, corners and edges. The terminals on very high voltage equipment are frequently designed with large diameter rounded shapes such as balls and toruses called \"corona caps\", to suppress corona formation. However, some parts of high voltage circuits require hardware with exposed sharp edges or corners, such as the attachment points where wires or bus bars are connected to insulators. Corona rings are installed at these points to prevent corona formation. \n\nThe corona ring is electrically connected to the high voltage conductor, encircling the points where corona would form. Since the ring is at the same potential as the conductor, the presence of the ring reduces the potential gradient at the surface of the conductor greatly, below the disruptive potential gradient, so corona does not form on the metal points.\n\nA very similar related device, called a grading ring, is also used on high-voltage equipment. Grading rings are similar to corona rings, but they encircle insulators rather than conductors. Although they may also serve to suppress corona, their main purpose is to reduce the potential gradient along the insulator, preventing premature electrical breakdown. \n\nThe potential gradient (electric field) across an insulator is not uniform, but is highest at the end next to the high voltage electrode. If subjected to a high enough voltage, the insulator will break down and become conductive at that end first. Once a section of insulator at the end has electrically broken down and become conductive, the full voltage is applied across the remaining length, so the breakdown will quickly progress from the high voltage end to the other, and a flashover arc will start. Therefore, insulators can stand significantly higher voltages if the potential gradient at the high voltage end is reduced. \n\nThe grading ring surrounds the end of the insulator next to the high voltage conductor. It reduces the gradient at the end, resulting in a more even voltage gradient along the insulator, allowing a shorter, cheaper insulator to be used for a given voltage. Grading rings also reduce aging and deterioration of the insulator that can occur at the high voltage end due to the high electric field there.\n\nIn very high voltage apparatus like Marx generators and particle accelerator tubes, insulating columns often have many metal grading rings spaced evenly along their length. These are linked by a voltage divider chain of high value resistors so there is an equal voltage drop from each ring to the next. This divides the potential difference evenly along the length of the column so there are no high field spots, resulting in the least stress on the insulators.\n\nCorona rings are used on extremely high voltage apparatus like Van de Graaff generators, Cockcroft–Walton generators, and particle accelerators, as well as electric power transmission insulators, bushings and switchgear. Manufacturers suggest a corona ring on the line end of the insulator for transmission lines above 230 kV and on both ends for potentials above 500 kV. Corona rings prolong the lifetime of insulator surfaces by suppressing the effects of corona discharge.\n\nCorona rings may also be installed on the insulators of antennas of high-power radio transmitters. However, they increase the capacitance of the insulators.\n\n\n"}
{"id": "7794", "url": "https://en.wikipedia.org/wiki?curid=7794", "title": "Crystallography", "text": "Crystallography\n\nCrystallography is the experimental science of determining the arrangement of atoms in crystalline solids (see crystal structure). The word \"crystallography\" derives from the Greek words \"crystallon\" \"cold drop, frozen drop\", with its meaning extending to all solids with some degree of transparency, and \"graphein\" \"to write\". In July 2012, the United Nations recognised the importance of the science of crystallography by proclaiming that 2014 would be the International Year of Crystallography. X-ray crystallography is used to determine the structure of large biomolecules such as proteins. \nBefore the development of X-ray diffraction crystallography (see below), the study of crystals was based on physical measurements of their geometry. This involved measuring the angles of crystal faces relative to each other and to theoretical reference axes (crystallographic axes), and establishing the symmetry of the crystal in question. This physical measurement is carried out using a goniometer. The position in 3D space of each crystal face is plotted on a stereographic net such as a Wulff net or Lambert net. The pole to each face is plotted on the net. Each point is labelled with its Miller index. The final plot allows the symmetry of the crystal to be established.\n\nCrystallographic methods now depend on analysis of the diffraction patterns of a sample targeted by a beam of some type. X-rays are most commonly used; other beams used include electrons or neutrons. This is facilitated by the wave properties of the particles. Crystallographers often explicitly state the type of beam used, as in the terms \"X-ray crystallography, neutron diffraction\" and \"electron diffraction\". These three types of radiation interact with the specimen in different ways. \nBecause of these different forms of interaction, the three types of radiation are suitable for different crystallographic studies.\n\nAn image of a small object is made using a lens to focus the beam, similar to a lens in a microscope. However, the wavelength of visible light (about 4000 to 7000 ångström) is three orders of magnitude longer than the length of typical atomic bonds and atoms themselves (about 1 to 2 Å). Therefore, obtaining information about the spatial arrangement of atoms requires the use of radiation with shorter wavelengths, such as X-ray or neutron beams. Employing shorter wavelengths implied abandoning microscopy and true imaging, however, because there exists no material from which a lens capable of focusing this type of radiation can be created. Scientists have had some success focusing X-rays with microscopic Fresnel zone plates made from gold, and by critical-angle reflection inside long tapered capillaries. Diffracted X-ray or neutron beams cannot be focused to produce images, so the sample structure must be reconstructed from the diffraction pattern. Sharp features in the diffraction pattern arise from periodic, repeating structure in the sample, which are often very strong due to coherent reflection of many photons from many regularly spaced instances of similar structure, while non-periodic components of the structure result in diffuse (and usually weak) diffraction features - areas with a higher density and repetition of atom order tend to reflect more light toward one point in space when compared to those areas with fewer atoms and less repetition.\n\nBecause of their highly ordered and repetitive structure, crystals give diffraction patterns of sharp Bragg reflection spots, and are ideal for analyzing the structure of solids.\n\n\nSome materials that have been analyzed crystallographically, such as proteins, do not occur naturally as crystals. Typically, such molecules are placed in solution and allowed to slowly crystallize through vapor diffusion. A drop of solution containing the molecule, buffer, and precipitants is sealed in a container with a reservoir containing a hygroscopic solution. Water in the drop diffuses to the reservoir, slowly increasing the concentration and allowing a crystal to form. If the concentration were to rise more quickly, the molecule would simply precipitate out of solution, resulting in disorderly granules rather than an orderly and hence usable crystal.\n\nOnce a crystal is obtained, data can be collected using a beam of radiation. Although many universities that engage in crystallographic research have their own X-ray producing equipment, synchrotrons are often used as X-ray sources, because of the purer and more complete patterns such sources can generate. Synchrotron sources also have a much higher intensity of X-ray beams, so data collection takes a fraction of the time normally necessary at weaker sources. Complementary neutron crystallography techniques are used to identify the positions of hydrogen atoms, since X-rays only interact very weakly with light elements such as hydrogen.\n\nProducing an image from a diffraction pattern requires sophisticated mathematics and often an iterative process of modelling and refinement. In this process, the mathematically predicted diffraction patterns of an hypothesized or \"model\" structure are compared to the actual pattern generated by the crystalline sample. Ideally, researchers make several initial guesses, which through refinement all converge on the same answer. Models are refined until their predicted patterns match to as great a degree as can be achieved without radical revision of the model. This is a painstaking process, made much easier today by computers.\n\nThe mathematical methods for the analysis of diffraction data only apply to \"patterns,\" which in turn result only when waves diffract from orderly arrays. Hence crystallography applies for the most part only to crystals, or to molecules which can be coaxed to crystallize for the sake of measurement. In spite of this, a certain amount of molecular information can be deduced from patterns that are generated by fibers and powders, which while not as perfect as a solid crystal, may exhibit a degree of order. This level of order can be sufficient to deduce the structure of simple molecules, or to determine the coarse features of more complicated molecules. For example, the double-helical structure of DNA was deduced from an X-ray diffraction pattern that had been generated by a fibrous sample.\n\nCrystallography is used by materials scientists to characterize different materials. In single crystals, the effects of the crystalline arrangement of atoms is often easy to see macroscopically, because the natural shapes of crystals reflect the atomic structure. In addition, physical properties are often controlled by crystalline defects. The understanding of crystal structures is an important prerequisite for understanding crystallographic defects. Mostly, materials do not occur as a single crystal, but in poly-crystalline form (i.e., as an aggregate of small crystals with different orientations). Because of this, the powder diffraction method, which takes diffraction patterns of polycrystalline samples with a large number of crystals, plays an important role in structural determination.\n\nOther physical properties are also linked to crystallography. For example, the minerals in clay form small, flat, platelike structures. Clay can be easily deformed because the platelike particles can slip along each other in the plane of the plates, yet remain strongly connected in the direction perpendicular to the plates. Such mechanisms can be studied by crystallographic texture measurements.\n\nIn another example, iron transforms from a body-centered cubic (bcc) structure to a face-centered cubic (fcc) structure called austenite when it is heated. The fcc structure is a close-packed structure unlike the bcc structure; thus the volume of the iron decreases when this transformation occurs.\n\nCrystallography is useful in phase identification. When manufacturing or using a material, it is generally desirable to know what compounds and what phases are present in the material, as their composition, structure and proportions will influence the material's properties. Each phase has a characteristic arrangement of atoms. X-ray or neutron diffraction can be used to identify which patterns are present in the material, and thus which compounds are present. Crystallography covers the enumeration of the symmetry patterns which can be formed by atoms in a crystal and for this reason is related to group theory and geometry.\n\nX-ray crystallography is the primary method for determining the molecular conformations of biological macromolecules, particularly protein and nucleic acids such as DNA and RNA. In fact, the double-helical structure of DNA was deduced from crystallographic data. The first crystal structure of a macromolecule was solved in 1958, a three-dimensional model of the myoglobin molecule obtained by X-ray analysis. The Protein Data Bank (PDB) is a freely accessible repository for the structures of proteins and other biological macromolecules. Computer programs such as RasMol or Pymol can be used to visualize biological molecular structures.\nNeutron crystallography is often used to help refine structures obtained by X-ray methods or to solve a specific bond; the methods are often viewed as complementary, as X-rays are sensitive to electron positions and scatter most strongly off heavy atoms, while neutrons are sensitive to nucleus positions and scatter strongly even off many light isotopes, including hydrogen and deuterium.\nElectron crystallography has been used to determine some protein structures, most notably membrane proteins and viral capsids.\n\nThe \"International Tables for Crystallography\" is an eight book series that outlines the standard notations for formatting, describing and testing crystals. The series contains books that covers analysis methods and the mathematical procedures for determining organic structure though x-ray crystallography, electron diffraction, and neutron diffraction. The International tables are focused on procedures, techniques and descriptions and does not list the physical properties of individual crystals themselves. Each book is about 1000 pages and the titles of the books are:\n\n"}
{"id": "3782852", "url": "https://en.wikipedia.org/wiki?curid=3782852", "title": "Dipalmitoylphosphatidylcholine", "text": "Dipalmitoylphosphatidylcholine\n\nDipalmitoylphosphatidylcholine (DPPtdCho) is a phospholipid (and a lecithin) consisting of two palmitic acids attached of a phosphatidylcholine head-group and is the major constituent of many pulmonary surfactants. It is zwitterionic by virtue of having a negative charge on the phosphate group and a positive charge on the quaternary ammonium group.\n\nIt is thought that a lysophosphatidylcholine (lysoPC) acyltransferase may play a critical role in its synthesis. The identity of this acyltransferase has not yet been confirmed. Dipalmitoylphosphatidylcholine is an exception to the rule of thumb that biological phospholipids are synthesized with a saturated fat at the R1 position and an unsaturated fat at the R2 position.\n\nIt is also used for research purposes in studying liposomes, lipid bilayers, and model biological membranes and in the formation of reconstituted HDL (rHDL) particles.\n"}
{"id": "33860728", "url": "https://en.wikipedia.org/wiki?curid=33860728", "title": "Energy Act 2004", "text": "Energy Act 2004\n\nThe Energy Act 2004 (c 20) is an Act of the Parliament of the United Kingdom.\n\nThe following orders have been made under this section:\n\n"}
{"id": "5127584", "url": "https://en.wikipedia.org/wiki?curid=5127584", "title": "Estropipate", "text": "Estropipate\n\nEstropipate, also known as piperazine estrone sulfate and sold under the brand names Harmogen, Improvera, Ogen, Ortho-Est, and Sulestrex among others, is an estrogen medication which is used mainly in menopausal hormone therapy in the treatment of menopausal symptoms. It is a salt of estrone sulfate and piperazine, and is transformed into estrone and estradiol in the body. It is taken by mouth.\n\nEstropipate is used to:\n\n\nEstropipate is a prodrug of estrone and estradiol. Hence, it is an estrogen, or an agonist of the estrogen receptors.\n\nEstropipate has been found to act as an inhibitor of SLCO1B1 (OATP1B1) (IC = 70 nM).\n\nEstropipate is hydrolyzed into estrone in the body. Estrone can then be transformed into estradiol by 17β-hydroxysteroid dehydrogenase.\n\nEstropipate was introduced for medical use by Abbott in 1968. It was approved by the in the United States in 1991.\n\n\"Estropipate\" is the generic name of the drug and its , , and .\n\nEstropipate is or has been marketed under the brand names Genoral, Harmogen, Improvera, Ogen, Ortho-Est, and Sulestrex among others.\n\nEstropipate appears to remain available only in the United States. In the past, estropipate has also been marketed in Canada, the United Kingdom, Ireland, Switzerland, Australia, South Africa, Mexico, and Indonesia.\n"}
{"id": "152969", "url": "https://en.wikipedia.org/wiki?curid=152969", "title": "Eutectic system", "text": "Eutectic system\n\nA eutectic system ( ) from the Greek \"ευ\" (eu = easy) and \"τήξις\" (teksis = melting) is a homogeneous mixture of substances that melts or solidifies at a single temperature that is lower than the melting point of either of the constituents.\n\nThe separate atomic or chemical species form a joint super-lattice, by striking a unique atomic percentage ratio between the components – as each pure component has its own distinct bulk lattice arrangement. It is only in this atomic or molecular ratio that the eutectic system melts as a whole, at a specific temperature (the eutectic temperature). The super-lattice releases at once all its components into a liquid mixture. The eutectic temperature is the lowest possible melting temperature over all of the mixing ratios for the involved component species.\n\nUpon heating any other mixture ratio, and reaching the eutectic temperature – see the adjacent phase diagram – one component's lattice will melt first, while the temperature of the mixture has to further increase for (all) the other component lattice(s) to melt. Conversely, as a non-eutectic mixture cools down, each mixture's component will solidify (form its lattice) at a distinct temperature, until all material is solid.\n\nThe coordinates defining a \"eutectic point\" on a phase diagram are the \"eutectic percentage ratio\" (on the atomic/molecular ratio axis of the diagram) and the \"eutectic temperature\" (on the temperature axis of the diagram).\n\nNot all binary alloys have eutectic points because the valence electrons of the component species are not always compatible, in any mixing ratio, to form a new type of joint crystal lattice. For example, in the silver-gold system the melt temperature (liquidus) and freeze temperature (solidus) \"meet at the pure element endpoints of the atomic ratio axis while slightly separating in the mixture region of this axis\".\n\nThe term was coined in 1884 by British physicist and chemist Frederick Guthrie (1833–1886).\n\nThe eutectic reaction is defined as follows:\n\nThis type of reaction is an invariant reaction, because it is in thermal equilibrium; another way to define this is the change in Gibbs free energy equals zero. Tangibly, this means the liquid and two solid solutions all coexist at the same time and are in chemical equilibrium. There is also a thermal arrest for the duration of the change of phase during which the temperature of the system does not change.\n\nThe resulting solid macrostructure from a eutectic reaction depends on a few factors. The most important factor is how the two solid solutions nucleate and grow. The most common structure is a lamellar structure, but other possible structures include rodlike, globular, and acicular.\n\nCompositions of eutectic systems that are not at the eutectic composition can be classified as \"hypoeutectic\" or \"hypereutectic\". Hypoeutectic compositions are those with a smaller percent composition of species β and a greater composition of species α than the eutectic composition (E) while hypereutectic solutions are characterized as those with a higher composition of species β and a lower composition of species α than the eutectic composition. As the temperature of a non-eutectic composition is lowered the liquid mixture will precipitate one component of the mixture before the other. In a hypereutectic solution, there will be a proeutectoid phase of species β whereas a hypoeutectic solution will have a proeutectic α phase.\n\nEutectic alloys have two or more materials and have a eutectic composition. When a non-eutectic alloy solidifies, its components solidify at different temperatures, exhibiting a plastic melting range. Conversely, when a well-mixed, eutectic alloy melts, it does so at a single, sharp temperature. The various phase transformations that occur during the solidification of a particular alloy composition can be understood by drawing a vertical line from the liquid phase to the solid phase on the phase diagram for that alloy.\n\nSome uses include:\n\n\nWhen the solution above the transformation point is solid, rather than liquid, an analogous eutectoid transformation can occur. For instance, in the iron-carbon system, the austenite phase can undergo a eutectoid transformation to produce ferrite and cementite, often in lamellar structures such as pearlite and bainite. This eutectoid point occurs at and about 0.76% carbon.\n\nA \"peritectoid\" transformation is a type of isothermal reversible reaction that has two solid phases reacting with each other upon cooling of a binary, ternary, ..., formula_2ary alloy to create a completely different and single solid phase. The reaction plays a key role in the order and decomposition of quasicrystalline phases in several alloy types.\n\nPeritectic transformations are also similar to eutectic reactions. Here, a liquid and solid phase of fixed proportions react at a fixed temperature to yield a single solid phase. Since the solid product forms at the interface between the two reactants, it can form a diffusion barrier and generally causes such reactions to proceed much more slowly than eutectic or eutectoid transformations. Because of this, when a peritectic composition solidifies it does not show the lamellar structure that is found with eutectic solidification.\n\nSuch a transformation exists in the iron-carbon system, as seen near the upper-left corner of the figure. It resembles an inverted eutectic, with the δ phase combining with the liquid to produce pure austenite at and 0.17% carbon.\nAt the peritectic decomposition temperature the compound, rather than melting, decomposes into another solid compound and a liquid. The proportion of each is determined by the lever rule. In the Al-Au phase diagram, for example, it can be seen that only two of the phases melt congruently, AuAl and AuAl , while the rest peritectically decompose.\n\nThe composition and temperature of a eutectic can be calculated from enthalpy and entropy of fusion of each components.\n\nThe Gibbs free energy, G, depends\non its own differential\n\nformula_3\n\nThus, the G/T derivative at constant pressure is calculated by\nthe following equation\n\nformula_4\n\nThe chemical potential formula_5 is calculated if we assume the activity is equal to the\nconcentration.\n\nformula_6\n\nAt the equilibrium, formula_7, thus formula_8 is obtained by:\n\nformula_9\n\nUsing and integrating gives\n\nformula_10\n\nThe integration constant K may be determined for a pure\ncomponent with a melting temperature formula_11 and an enthalpy of\nfusion formula_12 Eq.\n\nformula_13\n\nWe obtain a relation that determines\nthe molar fraction as a function of the temperature for each\ncomponent.\n\nformula_14\n\nThe mixture of n components is described by the system\n\nformula_15\nformula_15\n\nthat can be solved by\n\nformula_17\n\n\n"}
{"id": "55015985", "url": "https://en.wikipedia.org/wiki?curid=55015985", "title": "Five Canyons Open Space", "text": "Five Canyons Open Space\n\nFive Canyons Open Space (FCOS) is located in Castro Valley, in Alameda County, California. Five Canyons is a multi-agency collaboration between East Bay Regional Parks District (EBRPD), Alameda County Public Works, Hayward Area Recreation and Parks District (HARD), and several homeowners associations. EBRPD is the lead agency for this open space. FCOS opened in 1998, consists of and of trails and has almost no amenities. The main visitors are hikers, bicyclists, equestrians and dog walkers. Restrooms and drinking water are available at HARD's nearby Five Canyons Park. \n\nFCOS is open daily from 8:00 AM until dusk. There are no fees for parking or for dogs. There are no wheelchair-accessible facilities, no restrooms, no drinking water, no picnic facilities, and no reservable campgrounds.\n\nThe Bay Area Ridge Trail connects FCOS to Cull Canyon Regional Recreation Area to the north and Don Castro Regional Recreational Area to the west. At some future time, the trail will also connect to Garin Regional Park, Dry Creek Regional Park and Mission Peak Regional Preserve.\n"}
{"id": "1100220", "url": "https://en.wikipedia.org/wiki?curid=1100220", "title": "Four-minute warning", "text": "Four-minute warning\n\nThe four-minute warning was a public alert system conceived by the British Government during the Cold War and operated between 1953 and 1992. The name derived from the approximate length of time from the point at which a Soviet nuclear missile attack against the United Kingdom could be confirmed and the impact of those missiles on their targets. The population was to be notified by means of air raid sirens, television and radio, and urged to seek cover immediately. In practice, the warning would have been more likely three minutes or less.\n\nThe warning would be initiated by the detection of inbound missiles and aircraft targeted at the United Kingdom. Early in the Cold War, Jodrell Bank was used to detect and track incoming missiles, while continuing to be used for astronomical research.\n\nThroughout the Cold War, there was a conflict between the Royal Air Force and the Home Office about who was in charge of the warning system. This was not for any practical or technical reason, but more to do with who would be blamed if a false alarm were given or if an attack occurred without warning (which could have been as little as thirty seconds from launch to impact on a target). By the 1980s, the warning was to be given on the orders of a Warning Officer from the Home Office's Warning and Monitoring Organization stationed at RAF High Wycombe.\n\nFrom the early 1960s, initial detection of attack would be provided primarily by the RAF BMEWS station at Fylingdales in North Yorkshire. There, powerful radars would track the inbound missiles and allow confirmation of targets. In later years the first indication of any imminent attack would be expected to come from infrared detectors aboard the United States Defense Support Program (DSP) satellites. BMEWS would still play an important role in tracking and confirming the destination of any launches.\n\nThe British government was not the main beneficiary of BMEWS, given that it would only receive what Solly Zuckerman described in 1960 as \"no more than 5 minutes warning time\" of an attack. The United States was the United Kingdom's most important military and technological partner, and its Strategic Air Command would have thirty minutes warning from the Fylingdales station.\n\nIt was the responsibility of the United Kingdom Warning and Monitoring Organisation (UKWMO) at the United Kingdom Regional Air Operations Centre (UK RAOC) located at Headquarters Bomber Command, renamed \"Strike Command Operations Centre\" in 1968, at High Wycombe to alert the nation to an imminent air attack. Once an alert was initiated the national and local television and radio networks would break into transmissions and broadcast a warning (the warning message would originate from an emergency studio in BBC Broadcasting House in London). Simultaneously the national air raid siren system would be brought into service. A system, which used the same frequency on normal telephone lines as the peacetime speaking clock, was employed for this whereby a key switch activation alerted 250 national Carrier Control Points or CCPs present in police stations across the country. In turn the CCPs would, via a signal carried along ordinary phone lines, cause 7,000 powered sirens to start up. In rural areas, around 11,000 hand powered sirens would be operated by postmasters, rural police officers, or Royal Observer Corps personnel (even parish priests, publicans, magistrates, subpostmasters or private citizens could be involved in some remote rural areas).\n\nLinked into the system were the twenty-five Royal Observer Corps (ROC) group controls, also with direct links to the carrier control points. In the event of subsequent radioactive fallout, local fallout warnings could be generated from the group controls on a very localised basis over the same carrier wave system.\n\nThe national warning system saw many changes over the years. During the 1960s and 1970s, much of the local authority civil defence planning in the United Kingdom became outdated, although the WB400/WB600 warning system was maintained and kept serviceable along with updating of ROC instrumentation and communications. The system's main problem was that many of the telephone lines it needed had to be manually switched in times of pre-war tension by Post Office telephone engineers. The links were not hardened against the effects of EMP. In the late 1970s and early 1980s heightened fears and tensions led to a resumption of contingency planning and the upgrading of many systems. The outdated WB400/WB600 systems were replaced with brand new WB1400 equipment, communications links were made permanent and hardened against EMP disruption.\n\nThe national siren system originating from World War II had a secondary role of \"general warning\", particularly for imminent flooding. Following the end of the Cold War, a telephone-based system was thought to be more appropriate for national warnings and less expensive to maintain. Additionally the Government retains an ability to break into television and radio broadcasts for the purpose of alerting the general public and has legal power to take over editorial control of the BBC during a national emergency under the BBC Charter and the Broadcasting Act 1980.\n\nThe national siren system was largely dismantled during the 1990s. The British Government cited the increasing use of double-glazed windows (which make sirens harder to hear) and the reduced likelihood of air attack as reasons to eliminate the system in most parts of the country. Some coastal and river areas have retained and regularly test the sirens as part of the flood warning defences. Since 1952, Broadmoor Hospital has employed a network of 14 sirens to warn of escaped patients; this is tested every Monday at 10 am. The hospital sirens are scheduled for removal during 2018 except for one located in the hospital grounds. Carstairs Hospital also retains its sirens, which are tested monthly. In some towns sirens were once used to summon part-time firemen until the introduction of radio pagers during the 1970s – these 'stand alone' sirens operated independently of the warning network.\n\nThe following is a script that would have been broadcast in the event of an attack, available from the BBC. It was recorded by Peter Donaldson, chief continuity announcer for BBC Radio 4:\n\nThe Cold War and the fear of nuclear attack permeated pop culture up until the 1990s. Examples include the song \"Four Minute Warning\" by the British punk band Chaos UK (EP \"Burning Britain\", 1982), the poem \"Your Attention Please\" by Peter Porter, a solo song by Take That singer, Mark Owen, and \"Four Minutes\" by Roger Waters (of Pink Floyd fame) on his 1987 solo album \"Radio K.A.O.S.\". John Paul Jones has a song entitled \"4-Minute Warning\" on the 1988 Brian Eno album \"Music for Films III\". The first single of the UK rap crew Gunshot, from 1990, was entitled \"Battle Creek Brawl (4 Minute Warning)\". A Radiohead track from the 2007 Bonus Disc album \"In Rainbows\" Disk 2 is titled \"4 Minute Warning\".\n\nThe four-minute warning was a central plot and narrative device in dramas (both on stage and screen) and novels, often being the motor force of plays, films, novels and cartoon strips. The BBC drama \"Threads\", about how society decays after a nuclear holocaust, focuses on an attack on Sheffield. \"The War Game\" also portrays the four-minute warning, pointing out the warning period could be even less. The narrator, Michael Aspel, says it could even be two minutes between issuing the warning and impact on a target. The film adaptation of Raymond Briggs's satirical and blackly comic cartoon strip, \"When the Wind Blows\", has the warning message as part of the script, which triggers arguing between Jim and Hilda Bloggs. Although this is not Peter Donaldson's pre-recorded warning (which was not available on grounds of national security and for copyright reasons), this was a fictional announcement written on grounds of artistic licence. It was read by Robin Houston, a voiceover artist who was known in London as a newsreader for Thames Television (who played the role of newsreader in the film).\n\nThe adult humour comic \"Viz\" ran a photo strip in its issue 107 called \"Four Minutes to Fall in Love\", where a boyfriend and girlfriend cram a whole relationship into the four minutes before a nuclear attack. The four-minute warning had become the inspiration for many jokes and sketches in comedy programmes in Britain, in the same way that the Emergency Broadcast System had in the United States (see nuclear weapons in popular culture). In one episode of \"Only Fools and Horses\", \"The Russians Are Coming,\" Delboy and Rodney Trotter sell fallout shelter kits and have an attack drill. Driving towards their shelter, they are stopped by the police for speeding and asked: \"You just heard the four-minute warning?\" After being sent on their way, Rodney points out: \"We died forty-five seconds ago.\" Around the same time, a sketch on the BBC Scotland programme \"Naked Video\" had a mock announcement warning of an attack with a punchline of \"...except for viewers in Scotland.\"\n\n\n"}
{"id": "42311009", "url": "https://en.wikipedia.org/wiki?curid=42311009", "title": "Golen Gol Hydropower Project", "text": "Golen Gol Hydropower Project\n\nGolen Gol Hydropower Plant (GGHPP) is a hydroelectric power plant located on Golen Gol River - a major left tributary of Mastuj River in Chitral District of Khyber Pakhtunkhwa province of Pakistan. The dam is located approximately 25 km from Chitral city, and 365 km from provincial capital of Peshawar. Construction of Golen Gol project began in 2011, and was completed in January 2018.\n\nGolen Gol Hydropower Project is a run-of-the-river project designed for the generation of 108 MW consisting of three vertical Pelton wheel turbine units in one phase with average energy output of 436 Gwh. Golen Gol Hydropower Project is a part of least-cost energy generation plan, being executed by WAPDA to harness the indigenous hydropower resources of the country. WAPDA awarded the contract to SAMBU-SARCO joint venture comprising a Korean and a Pakistani firm. Sambu, an independent power provider (IPP), won the project in the last quarter of 2010 and construction work started in Jan 2011\n\nSambu has already successfully completed Pakistan's first IPP hydropower plant, 84MW New Bong Escape Hydropower Project, which is commercially operational since March 2013. Korean company has also been awarded a contract to construct Pakistan's third IPP hydropower plant, 100MW Gulpur Hydropower Project on BOOT (Build, Own, Operate, Transfer) basis Joint Venture with other Korean firm and execution of work is in progress.\n\nThe Saudi Fund for Development is the major source of funding for the 108-MW Golen Gol hydropower project being developed by Pakistan's WAPDA. The Golen Gol project is also being funded by the Kuwait Fund for Arab Economic Development (KFD) and Organization of the Petroleum Exporting Countries (OPEC). Saudi Fund, Kuwait Fund and Opec Fund are providing $107 million for the construction of GGHPP.\n\nThe Electro-Mechanical works of the Golen Gol Project were awarded to Andritz Hydro,the world leader and renowned supplier of hydro power equipment and services. The Project is based on the state of the art, water to wire concept developed by Andritz Hydro for the supply, installation and commissioning of the hydro power plants. Andritz hydro completed the similar projects namely Allai Khwar and Duber Khwar in North of Pakistan within the record lowest time period and thus providing timely and precious power supply to the country and considerable early revenue generation to WAPDA.\n\nOn its completion, Golen Gol Hydropower project will generate about 436 Mega Units (GWH) of inexpensive electricity annually to earn revenue of about Rs 1 billion. Being an environment friendly hydropower project, it will help reduce dependence on expensive thermal power, thereby saving foreign exchange amounting to $34 million (equivalent to Rs 3 billion) to the country. According to estimation, Golen Gol hydropower project will add about Rs 9 billion per annum to the national economy through socio-economic uplift in the country caused by the project.\n\nConstruction of Golen Gol Hydropower Plant was commenced in June 2009 and the project is expected to be completed in October 2017. The total cost of the project is about PKR 16 billion. Golen Gol Hydropower Project is part of the least-cost energy generation plan of the Government of Pakistan. It is being executed by Wapda on priority basis to harness indigenous hydropower resources to improve the ratio of hydel electricity in the national grid and help provide relief to the consumers.\n\nType: Concrete Diversion Weir<br>\nDiversion Weir Length: 60 m.<br>\nDiversion Weir Height: 12 m.<br>\nDesign Discharge: 30 Cusecs<br>\nHeadrace Tunnel Length: 3800m long, 3.7m in diameter <br>\nGated Flushing Section Width: 19.72m<br>\nSand Trap: 83.7m<br>\nHeadrace Channel: 102m<br>\nVertical and pressure shaft: 970m long, 2.5m dia<br>\nSurge Chambers: 42m high, 15m dia<br>\nInstalled Capacity: 108 MW<br>\nAverage Annual Energy Production: 436 GWh\n\nThe Intake weir will be about 1 km upstream of Babuka village. From the intake there will be a headrace channel leading to the tunnel, which will discharge the flow into the surge chamber and a combination of vertical and horizontal pressure shafts from where water flows to the surface powerhouse which is located on the left bank of Mastuj River, just downstream from the confluence of the Golen Gol and the Mastuj River.\n\n"}
{"id": "12247112", "url": "https://en.wikipedia.org/wiki?curid=12247112", "title": "Growth and yield modelling", "text": "Growth and yield modelling\n\nGrowth and yield modelling is a branch of financial management. This method of modelling is also known as the Gordon constant growth model. In this method the cost of equity share capital by determining the sum of yield percentage and growth percentage.\n\n"}
{"id": "29182417", "url": "https://en.wikipedia.org/wiki?curid=29182417", "title": "Guam Power Authority", "text": "Guam Power Authority\n\nThe Guam Power Authority (GPA, ) is an agency of the Government of Guam and Guam's electricity provider. Its headquarters are in Fadian, Mangilao, Guam|\n\n"}
{"id": "31178002", "url": "https://en.wikipedia.org/wiki?curid=31178002", "title": "Heavy fermion superconductor", "text": "Heavy fermion superconductor\n\nHeavy fermion superconductors are a type of unconventional superconductor.\n\nThe first heavy fermion superconductor, CeCuSi, was discovered by Frank Steglich in 1978.\n\nSince then over 30 heavy fermion superconductors were found (in materials based on Ce, U), with a critical temperature up to 2.3 K (in CeCoIn).\n\nHeavy Fermions are intermetallic compounds, containing rare earth or actinide elements. The f-electrons of these atoms hybridize with the normal conduction electrons leading to quasiparticles with an enhanced mass.\n\nFrom specific heat measurements (ΔC/C(T) one knows that the Cooper pairs in the superconducting state are also formed by the heavy quasiparticles.\nIn contrast to normal superconductors it cannot be described by BCS-Theory. Due to the large effective mass, the \nFermi velocity is reduced and comparable to the inverse Debye frequency. This leads to the failing of the picture of electrons polarizing the lattice as an attractive force.\n\nSome heavy fermion superconductors are candidate materials for the Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) phase. In particular there has been evidence that CeCoIn close to the critical field is in an FFLO state.\n"}
{"id": "14564979", "url": "https://en.wikipedia.org/wiki?curid=14564979", "title": "Hypersonic flight", "text": "Hypersonic flight\n\nHypersonic flight is flight through the atmosphere below about 90km at speeds above Mach 5, a speed where dissociation of air begins to become significant and high heat loads exist.\n\nThe first manufactured object to achieve hypersonic flight was the two-stage Bumper rocket, consisting of a WAC Corporal second stage set on top of a V-2 first stage. On February 1949, at White Sands, the rocket reached a speed of 5,150 miles per hour, or approximately Mach 6.7. The vehicle, however, burned on atmospheric re-entry, and only charred remnants were found. In April 1961, Russian Major Yuri Gagarin became the first human to travel at hypersonic speed, during the world's first piloted orbital flight. Soon after, in May 1961, Alan Shepard became the first American and second person to achieve hypersonic flight when his capsule reentered the atmosphere at a speed above Mach 5 at the end of his suborbital flight over the Atlantic Ocean. \n\nIn November, 1961, Air Force Major Robert White flew the X-15 research airplane at speeds over Mach 6.\nAccording to Air Force Chief Scientist, Dr. Greg Zacharias, the US anticipates having hypersonic weapons by the 2020s, hypersonic drones by the 2030s and recoverable hypersonic drone aircraft by the 2040s.\n\nRand Corporation (28 September 2017) estimates there is less than a decade to prevent Hypersonic Missile proliferation. \n\n\"See: Prompt Global Strike\"\n\n\n\n\n\n\n\n\n"}
{"id": "27005859", "url": "https://en.wikipedia.org/wiki?curid=27005859", "title": "Jiroft Dam", "text": "Jiroft Dam\n\nJiroft Dam is a hydroelectric dam in Iran with an installed electricity generating capability of 85 MWh situated in Kerman Province.\nThe fifth concrete dam built in the country, it was begun in 1975 and completed in 1992 (6 Daymah 1370 in Persian calendar). It is located on Halil River (Halilrood) 40 km upstream of Jiroft (North-East of the city) in the narrow valley of Narab.\nIts reservoir capacity is around 410 million cubic metres up to the normal level (1185 metres above sea level). The maximum height of the dam is 134 m and the crest length is 277 m. The dam in its first water year of operation (1992) survived an extraordinary flood (1 February 1993) with the peak discharge of 5035 cubic metres per second. The flood had a return period of 800 to 1000 years. The heavy rains of this year caused the dam was filled of water much sooner than the planned water storing duration. The spillways and other hydrodynamic outlets of the dam can manage to discharge up to 6500 cubic meters per seconds (the design flood with return period of 10000 years).\nThe reservoir is planned to irrigate 14200 hectares of the downstream lands.\n\n"}
{"id": "17875046", "url": "https://en.wikipedia.org/wiki?curid=17875046", "title": "John Hance", "text": "John Hance\n\nJohn Hance (1840 – January 8, 1919) is thought to be the first non-Native American resident of the Grand Canyon, US. He opened the first tourist trail in the canyon in the late nineteenth century. He started giving tours of the canyon after his attempts at mining asbestos failed, largely due to the expense of removing the asbestos from the canyon. \"Captain\" John Hance was said to be one of the Grand Canyon's most colorful characters, and it had been declared by one early visitor that \"To see the canyon only and not to see Captain John Hance, is to miss half the show.\" Hance delighted in telling canyon stories to visitors, favoring the whopper of a tale over mere facts. With a straight face, Hance told travelers how he had dug the canyon himself, piling the excavated earth down near Flagstaff (a dirt pile now known as the San Francisco Peaks). Despite such questionable claims, Hance left a lasting legacy at the Grand Canyon, dying in 1919, the year the Grand Canyon became a National Park. Hance was the first person buried in what would become the Grand Canyon Pioneer Cemetery.\n"}
{"id": "37952929", "url": "https://en.wikipedia.org/wiki?curid=37952929", "title": "List of cobblestone streets", "text": "List of cobblestone streets\n\nA cobbled street or cobblestone road, is a street or road paved with cobblestones.\nThere are many historic streets that are cobbled. In the United States, several of these are recognized in the National Register of Historic Places.\n\nThe following is a list of streets and roads which are famed or notable for being paved with cobbles (natural stone), setts (cut stone), artificial pavers (i.e. concrete or brick), or similar masonry works (natural, cut, or artificial).\n\n"}
{"id": "28685848", "url": "https://en.wikipedia.org/wiki?curid=28685848", "title": "Lucainena de las Torres Photovoltaic Power Station", "text": "Lucainena de las Torres Photovoltaic Power Station\n\nThe Lucainena de las Torres Photovoltaic Power Station () is a photovoltaic power station in Lucainena de las Torres, Almería in Spain. It consists of different units. Lucainena de las Torres 1 has a total capacity of 7.4 MWp and its annual output is about 11.42 GWh. It was commissioned in July 2008. Lucainena de las Torres 2 has a total capacity of 7.9 MWpand its annual output is about 12.236 GWh. It was commissioned in July 2008.\n\n"}
{"id": "51086269", "url": "https://en.wikipedia.org/wiki?curid=51086269", "title": "Marine thruster", "text": "Marine thruster\n\nA marine thruster is a device for producing directed hydrodynamic thrust on a marine vehicle. The thrust direction may be fixed or steerable.\nExamples of marine thrusters include screw propellers, Voith-Schneider propellers, waterjets, ducted propellers, tunnel bow thrusters and stern thrusters, azimuth thrusters, rim-driven thrusters, ROV and submersible drive units.\nMarine thrusters may be used for propulsion, maneuvering and steering, attitude control and dynamic positioning.\n"}
{"id": "29384258", "url": "https://en.wikipedia.org/wiki?curid=29384258", "title": "Microcrystalline cellulose", "text": "Microcrystalline cellulose\n\nMicrocrystalline cellulose (MCC) is a term for refined wood pulp and is used as a texturizer, an anti-caking agent, a fat substitute, an emulsifier, an extender, and a bulking agent in food production. The most common form is used in vitamin supplements or tablets. It is also used in plaque assays for counting viruses, as an alternative to carboxymethylcellulose.\n\nA naturally occurring polymer, it is composed of glucose units connected by a 1-4 beta glycosidic bond. These linear cellulose chains are bundled together as microfibril spiralled together in the walls of plant cell. \n\nEach microfibril exhibits a high degree of three-dimensional internal bonding resulting in a crystalline structure that is insoluble in water and resistant to reagents. There are, however, relatively weak segments of the microfibril with weaker internal bonding. These are called amorphous regions; some argue that they are more accurately called dislocations, because of the single-phase structure of microfibrils. The crystalline region is isolated to produce microcrystalline cellulose.\n\nApproved within the European Union as a thickener, stabilizer or emulsifiers microcrystalline cellulose was granted the E number E460(i) with basic cellulose given the number E460.\n\nMCC has use in cosmetics as an abrasive, absorbent, anti-caking agent, aqueous viscosity increasing agent, binder, bulking agent, emulsion stabilizer, slip modifier, and texturizer, which can be found in various hair and skin care products as well as makeup.\n\nThe MCC is a valuable additive in pharmaceutical, food, cosmetic and other industries. Different properties of MCC are measured to qualify its suitability to such utilization, namely particle size, density, compressibility index, angle of repose, powder porosity, hydration swelling capacity, moisture sorption capacity, moisture content, crystallinity index, crystallite size, and mechanical properties such as hardness and tensile strength.\n\nMCC is pure partially depolymerized cellulose synthesized from α-cellulose precursor. The MCC can be synthesized by different processes such as reactive extrusion, enzyme mediated, steam explosion and acid hydrolysis. The later process can be done using mineral acids such as HSO, HCl and HBr as well as ionic liquids. The role of these reagents is to destroy the amorphous regions leaving the crystalline domains. \n\nThe degree of polymerization is typically less than 400. The MCC particles with size lower than 5 µm must not be more than 10%. \n\nThermogravimetric analysis (TGA) and differential thermal analysis (DTA) or differential scanning calorimetry (DSC) are also important to predict the thermal behavior of the MCC upon heat stresses.\n\nAt least one case of an allergic reaction to microcrystalline cellulose has been documented.\n"}
{"id": "43236799", "url": "https://en.wikipedia.org/wiki?curid=43236799", "title": "Oil (film)", "text": "Oil (film)\n\nOil is a 2009 documentary film directed by Massimiliano Mazzotta. It explores the Italian energy provider Saras S.p.A., operating in the area of oil refining and the production of electricity, located in the island of Sardinia, near Cagliari and the impact of oil development on the land and lives of the local population.\n\n\n"}
{"id": "681218", "url": "https://en.wikipedia.org/wiki?curid=681218", "title": "Omega-6 fatty acid", "text": "Omega-6 fatty acid\n\nOmega-6 fatty acids (also referred to as ω-6 fatty acids or \"n\"-6 fatty acids) are a family of polyunsaturated fatty acids that have in common a final carbon-carbon double bond in the \"n\"-6 position, that is, the sixth bond, counting from the methyl end. Members of the family can have pro-inflammatory or anti-inflammatory effects. \n\nThe biological effects of the omega-6 fatty acids are largely produced during and after physical activity for the purpose of promoting growth and during the inflammatory cascade to halt cell damage and promote cell repair by their conversion to omega-6 eicosanoids that bind to diverse receptors found in every tissue of the body.\n\nLinoleic acid (18:2, \"n\"−6), the shortest-chained omega-6 fatty acid, is one of many essential fatty acids and is categorized as an essential fatty acid because the human body cannot synthesize it. Mammalian cells lack the enzyme omega-3 desaturase and therefore cannot convert omega-6 fatty acids to omega-3 fatty acids. Closely related omega-3 and omega-6 fatty acids act as competing substrates for the same enzymes. This outlines the importance of the proportion of omega-3 to omega-6 fatty acids in a diet.\n\nOmega-6 fatty acids are precursors to endocannabinoids, lipoxins, and specific eicosanoids.\n\nMedical research on humans found a correlation (though correlation does not imply causation) between the high intake of omega-6 fatty acids from vegetable oils and disease in humans. However, biochemistry research has concluded that air pollution, heavy metals, smoking, passive smoking, lipopolysaccharides, lipid peroxidation products (found mainly in vegetable oils, roasted nuts and roasted oily seeds) and other exogenous toxins initiate the inflammatory response in the cells which leads to the expression of the COX-2 enzyme and subsequently to the temporary production of inflammatory \"promoting\" prostaglandins from arachidonic acid for the purpose of alerting the immune system of the cell damage and eventually to the production of anti-inflammatory molecules (e.g. lipoxins & prostacyclin) during the resolution phase of inflammation, after the cell damage has been repaired.\"\n\nThe conversion of cell membrane arachidonic acid (20:4n-6) to omega-6 prostaglandin and omega-6 leukotriene eicosanoids during the inflammatory cascade provides many targets for pharmaceutical drugs to impede the inflammatory process in atherosclerosis, asthma, arthritis, vascular disease, thrombosis, immune-inflammatory processes, and tumor proliferation. Competitive interactions with the omega-3 fatty acids affect the relative storage, mobilization, conversion and action of the omega-3 and omega-6 eicosanoid precursors (see Essential fatty acid interactions).\n\nSome medical research suggests that excessive levels of omega-6 fatty acids from seed oils relative to certain omega-3 fatty acids may increase the probability of a number of diseases.\n\nModern Western diets typically have ratios of omega-6 to omega-3 in excess of 10, some as high as 30; the average ratio of omega-6 to omega-3 in the Western diet is 15–16.7. Humans are thought to have evolved with a diet of a 1-to-1 ratio of omega-6 to omega-3 and the optimal ratio is thought to be 4 or lower, although some sources suggest ratios as low as 1. A ratio of 2–3 omega-6 to omega-3 helped reduce inflammation in patients with rheumatoid arthritis. A ratio of 5 had a beneficial effect on patients with asthma but a ratio of 10 had a negative effect. A ratio of 2.5 reduced rectal cell proliferation in patients with colorectal cancer, whereas a ratio of 4 had no effect.\n\nExcess omega-6 fatty acids from vegetable oils interfere with the health benefits of omega-3 fats, in part because they compete for the same rate-limiting enzymes. A high proportion of omega-6 to omega-3 fat in the diet shifts the physiological state in the tissues toward the pathogenesis of many diseases: prothrombotic, proinflammatory and proconstrictive.\n\nChronic excessive production of omega-6 eicosanoids is correlated with arthritis, inflammation, and cancer. Many of the medications used to treat and manage these conditions work by blocking the effects of the COX-2 enzyme. Many steps in formation and action of omega-6 prostaglandins from omega-6 arachidonic acid proceed more vigorously than the corresponding competitive steps in formation and action of omega-3 hormones from omega-3 eicosapentaenoic acid. The COX-1 and COX-2 inhibitor medications, used to treat inflammation and pain, work by preventing the COX enzymes from turning arachidonic acid into inflammatory compounds. (See Cyclooxygenase for more information.) The LOX inhibitor medications often used to treat asthma work by preventing the LOX enzyme from converting arachidonic acid into the leukotrienes. Many of the anti-mania medications used to treat bipolar disorder work by targeting the arachidonic acid cascade in the brain.\n\nA high consumption of oxidized polyunsaturated fatty acids (PUFAs), which are found in most types of vegetable oil, may increase the likelihood that postmenopausal women will develop breast cancer. Similar effect was observed on prostate cancer, but the study was performed on mice. Another \"analysis suggested an inverse association between total polyunsaturated fatty acids and breast cancer risk, but individual polyunsaturated fatty acids behaved differently [from each other]. [...] a 20:2 derivative of linoleic acid [...] was inversely associated with the risk of breast cancer\".\n\nIndustry-sponsored studies have suggested that omega-6 fatty acids should be consumed in a 1:1 ratio to omega-3, though it has been observed that the diet of many individuals today is at a ratio of about 16:1, mainly from vegetable oils. Omega-6 and omega-3 are essential fatty acids that are metabolized by some of the same enzymes, and therefore an imbalanced ratio can affect how the other is metabolized. In a study performed by Ponnampalam, it was noticed that feeding systems had a great effect on nutrient content on the meat sold to consumers. Cynthia Doyle conducted an experiment to observe the fatty acid content of beef raised through grass feeding versus grain feeding; she concluded that grass fed animals contain an overall omega-6:omega-3 ratio that is preferred by nutritionists. In today's modern agriculture, the main focus is on production quantity, which has decreased the omega-3 content, and increased the omega-6 content, due to simple changes such as grain-feeding cattle. In grain-feeding cattle, this is a way to increase their weight and prepare them for slaughter much quicker compared to grass-feeding. This modern way of feeding animals may be one of many indications as to why the omega-6:omega-3 ratio has increased.\n\nThe melting point of the fatty acids increase as the number of carbons in the chain increases.\n\nAdding more controversy to the omega-6 fat issue is that the dietary requirement for linoleic acid has been questioned, because of a significant methodology error proposed by University of Toronto scientist Stephen Cunnane. Cunnane proposed that the seminal research used to determine the dietary requirement for linoleic acid was based on feeding animals linoleic acid-deficient diets, which were simultaneously deficient in omega-3 fats. The omega-3 deficiency was not taken into account. The omega-6 oils added back systematically to correct the deficiency also contained trace amounts of omega-3 fats. Therefore, the researchers were inadvertently correcting the omega-3 deficiency as well. Ultimately, it took more oil to correct both deficiencies. According to Cunnane, this error overestimates linoleic acid requirements by 5 to 15 times.\n\nFour major food oils (palm, soybean, rapeseed, and sunflower) provide more than 100 million metric tons annually, providing more than 32 million metric tons of omega-6 linoleic acid and 4 million metric tons of omega-3 alpha-linolenic acid.\n\nDietary sources of omega-6 fatty acids include:\n\n\n"}
{"id": "694751", "url": "https://en.wikipedia.org/wiki?curid=694751", "title": "Optimum sustainable yield", "text": "Optimum sustainable yield\n\nIn population ecology and economics, optimum sustainable yield is the level of effort (LOE) that maximizes the difference between total revenue and total cost. Or, where marginal revenue equals marginal cost. This level of effort maximizes the economic profit, or rent, of the resource being utilized. It usually corresponds to an effort level lower than that of maximum sustainable yield.\n\nIn environmental science, optimum sustainable yield is the largest economical yield of a renewable resource achievable over a long time period without decreasing the ability of the population or its environment to support the continuation of this level of yield, and enables an ecosystem to have a high aesthetic value. This concept is widely used specifically in the management of fisheries, where surplus fish are removed so the population stays at its carrying capacity. This allows the most fish to be harvested while still maintaining maximum population growth.\n\n"}
{"id": "58296445", "url": "https://en.wikipedia.org/wiki?curid=58296445", "title": "Piezoelectric microelectromechanical systems", "text": "Piezoelectric microelectromechanical systems\n\nA piezoelectric microelectromechanical system (piezoMEMS) is a miniature or microscopic device that uses piezoelectricity to generate motion and carry out its tasks. It is a microelectromechanical system that takes advantage of an electrical potential that appears under mechanical stress. PiezoMEMS can be found in a variety of applications, such as switches, inkjet printer heads, sensors, micropumps, and energy harvesters.\n\nInterest in piezoMEMS technology began around the early 1990s as scientists explored alternatives to electrostatic actuation in radio frequency (RF) microelectromechanical systems (MEMS). For RF MEMS, electrostatic actuation specialized high voltage charge pump circuits due to small electrode gap spacing and large driving voltages. In contrast, piezoelectric actuation allowed for high sensitivity as well as low voltage and power consumption as low as a few millivolts. It also had the ability to close large vertical gaps while still allowing for low microsecond operating speeds. Lead zirconate titanate (PZT), in particular, offered the most promise as a piezoelectric material because of its high piezoelectric coefficient, tunable dielectric constant, and electromechanical coupling coefficient. PiezoMEMS have been applied to various different technologies from switches to sensors, and further research have led to the creation of piezoelectric thin films, which aided in the realization of highly integrated piezoMEMS devices.\n\nThe first reported piezoelectrically actuated RF MEMS switch was developed by scientists at the LG Electronics Institute of Technology in Seoul, South Korea in 2005. The researchers designed and actualized a RF MEMS switch with a piezoelectric cantilever actuator that had an operation voltage of 2.5 volts.\n\nIn 2017, researchers from the U.S. Army Research Laboratory (ARL) evaluated the radiation effects in the piezoelectric response of PZT thin films for the first time. They determined that PZT exhibited a degree of radiation hardness that could be further extended by using conductive oxide electrodes instead of traditional platinum electrodes. Gamma radiation tests have also shown that actuated devices such as switches, resonators, and inertial devices could benefit from the radiation tolerance of PZT, suggesting the possibility that actuators and sensors can be integrated into platforms evaluating nuclear material and reduce human exposure to radiation.\n\nThis experiment was part of a decades-long research investment effort at ARL to improve the use of PZT thin film technology for piezoMEMS. Other piezoMEMS-related work included developing a piezoelectric microphone based on PZT thin films, creating new integrated surface micromachining processes for RF MEMS to incorporate thin film PZT actuators, providing the first experimental demonstration of monolithically integrated piezoMEMS RF switches with contour mode filters, and demonstrating the feasibility of vibrational energy harvesting using thin film PZT MEMS. In their work, researchers from ARL have also increased the overall electromechanical response of PZT thin films by 15-30% by incorporating iridium oxide electrode materials.\n\nThere exists three primary approaches to realizing PiezoMEMS devices:\n\n\nPiezoMEMS use two principal crystal structures, the wurtzite and perovskite structures.\n\nPiezoMEMS still face many difficulties that impede its ability to be successfully commercialized. For instance, the success of depositing uniform films of piezoelectrics still depend heavily on the use of appropriate layers of proper nucleation and film growth. As a result, extensive device-specific development efforts are needed to create a proper sensor structure. In addition, researchers continue to search for ways to reduce and control the material and sensor drift and aging characteristics of thin film piezoelectric materials. Deposition techniques to create thin films with properties approaching those of bulk materials remain in development and in need of improvement. Furthermore, the chemistry and etching characteristics of most piezoelectric materials remain very slow.\n"}
{"id": "23324", "url": "https://en.wikipedia.org/wiki?curid=23324", "title": "Platinum", "text": "Platinum\n\nPlatinum is a chemical element with symbol Pt and atomic number 78. It is a dense, malleable, ductile, highly unreactive, precious, silverish-white transition metal. Its name is derived from the Spanish term \"platino\", meaning \"little silver\".\n\nPlatinum is a member of the platinum group of elements and group 10 of the periodic table of elements. It has six naturally occurring isotopes. It is one of the rarer elements in Earth's crust, with an average abundance of approximately 5 μg/kg. It occurs in some nickel and copper ores along with some native deposits, mostly in South Africa, which accounts for 80% of the world production. Because of its scarcity in Earth's crust, only a few hundred tonnes are produced annually, and given its important uses, it is highly valuable and is a major precious metal commodity.\n\nPlatinum is one of the least reactive metals. It has remarkable resistance to corrosion, even at high temperatures, and is therefore considered a noble metal. Consequently, platinum is often found chemically uncombined as native platinum. Because it occurs naturally in the alluvial sands of various rivers, it was first used by pre-Columbian South American natives to produce artifacts. It was referenced in European writings as early as 16th century, but it was not until Antonio de Ulloa published a report on a new metal of Colombian origin in 1748 that it began to be investigated by scientists.\n\nPlatinum is used in catalytic converters, laboratory equipment, electrical contacts and electrodes, platinum resistance thermometers, dentistry equipment, and jewelry. Being a heavy metal, it leads to health problems upon exposure to its salts; but due to its corrosion resistance, metallic platinum has not been linked to adverse health effects. Compounds containing platinum, such as cisplatin, oxaliplatin and carboplatin, are applied in chemotherapy against certain types of cancer.\n\nAs of 2018, the value of platinum is $833.00 per ounce.\n\nPure platinum is a lustrous, ductile, and malleable, silver-white metal. Platinum is more ductile than gold, silver or copper, thus being the most ductile of pure metals, but it is less malleable than gold. The metal has excellent resistance to corrosion, is stable at high temperatures and has stable electrical properties. Platinum does oxidize, forming PtO, at 500 °C; this oxide can be easily removed thermally. It reacts vigorously with fluorine at to form platinum tetrafluoride. It is also attacked by chlorine, bromine, iodine, and sulfur. Platinum is insoluble in hydrochloric and nitric acid, but dissolves in hot \"aqua regia\" (A mixture of nitric and hydrochloric acids), to form chloroplatinic acid, HPtCl.\n\nIts physical characteristics and chemical stability make it useful for industrial applications. Its resistance to wear and tarnish is well suited to use in fine jewellery.\n\nThe most common oxidation states of platinum are +2 and +4. The +1 and +3 oxidation states are less common, and are often stabilized by metal bonding in bimetallic (or polymetallic) species. As is expected, tetracoordinate platinum(II) compounds tend to adopt 16-electron square planar geometries. Although elemental platinum is generally unreactive, it dissolves in hot aqua regia to give aqueous chloroplatinic acid (HPtCl):\n\nAs a soft acid, platinum has a great affinity for sulfur, such as on dimethyl sulfoxide (DMSO); numerous DMSO complexes have been reported and care should be taken in the choice of reaction solvent.\n\nIn 2007, Gerhard Ertl won the Nobel Prize in Chemistry for determining the detailed molecular mechanisms of the catalytic oxidation of carbon monoxide over platinum (catalytic converter).\n\nPlatinum has six naturally occurring isotopes: Pt, Pt, Pt, Pt, Pt, and Pt. The most abundant of these is Pt, comprising 33.83% of all platinum. It is the only stable isotope with a non-zero spin; with a spin of /, Pt satellite peaks are often observed in H and P NMR spectroscopy (i.e., Pt-phosphine and Pt-alkyl complexes). Pt is the least abundant at only 0.01%. Of the naturally occurring isotopes, only Pt is unstable, though it decays with a half-life of 6.5 years, causing an activity of 15 Bq/kg of natural platinum. Pt can undergo alpha decay, but its decay has never been observed (the half-life is known to be longer than 3.2 years); therefore, it is considered stable. Platinum also has 31 synthetic isotopes ranging in atomic mass from 166 to 202, making the total number of known isotopes 37. The least stable of these is Pt, with a half-life of 300 µs, whereas the most stable is Pt with a half-life of 50 years. Most platinum isotopes decay by some combination of beta decay and alpha decay. Pt, Pt, and Pt decay primarily by electron capture. Pt and Pt are predicted to have energetically favorable double beta decay paths.\n\nPlatinum is an extremely rare metal, occurring at a concentration of only 0.005 ppm in Earth's crust. It is sometimes mistaken for silver. Platinum is often found chemically uncombined as native platinum and as alloy with the other platinum-group metals and iron mostly. Most often the native platinum is found in secondary deposits in alluvial deposits. The alluvial deposits used by pre-Columbian people in the Chocó Department, Colombia are still a source for platinum-group metals. Another large alluvial deposit is in the Ural Mountains, Russia, and it is still mined.\n\nIn nickel and copper deposits, platinum-group metals occur as sulfides (e.g. (Pt,Pd)S), tellurides (e.g. PtBiTe), antimonides (PdSb), and arsenides (e.g. PtAs), and as end alloys with nickel or copper. Platinum arsenide, sperrylite (PtAs), is a major source of platinum associated with nickel ores in the Sudbury Basin deposit in Ontario, Canada. At Platinum, Alaska, about was mined between 1927 and 1975. The mine ceased operations in 1990. The rare sulfide mineral cooperite, (Pt,Pd,Ni)S, contains platinum along with palladium and nickel. Cooperite occurs in the Merensky Reef within the Bushveld complex, Gauteng, South Africa.\n\nIn 1865, chromites were identified in the Bushveld region of South Africa, followed by the discovery of platinum in 1906. In 1924, the geologist Hans Merensky discovered a large supply of platinum in the Bushveld Igneous Complex in South Africa. The specific layer he found, named the Merensky Reef, contains around 75% of the world's known platinum. The large copper–nickel deposits near Norilsk in Russia, and the Sudbury Basin, Canada, are the two other large deposits. In the Sudbury Basin, the huge quantities of nickel ore processed make up for the fact platinum is present as only 0.5 ppm in the ore. Smaller reserves can be found in the United States, for example in the Absaroka Range in Montana. In 2010, South Africa was the top producer of platinum, with an almost 77% share, followed by Russia at 13%; world production in 2010 was .\n\nLarge platinum deposits are present in the state of Tamil Nadu, India.\n\nPlatinum exists in higher abundances on the Moon and in meteorites. Correspondingly, platinum is found in slightly higher abundances at sites of bolide impact on Earth that are associated with resulting post-impact volcanism, and can be mined economically; the Sudbury Basin is one such example.\n\nHexachloroplatinic acid mentioned above is probably the most important platinum compound, as it serves as the precursor for many other platinum compounds. By itself, it has various applications in photography, zinc etchings, indelible ink, plating, mirrors, porcelain coloring, and as a catalyst.\n\nTreatment of hexachloroplatinic acid with an ammonium salt, such as ammonium chloride, gives ammonium hexachloroplatinate, which is relatively insoluble in ammonium solutions. Heating this ammonium salt in the presence of hydrogen reduces it to elemental platinum. Potassium hexachloroplatinate is similarly insoluble, and hexachloroplatinic acid has been used in the determination of potassium ions by gravimetry.\n\nWhen hexachloroplatinic acid is heated, it decomposes through platinum(IV) chloride and platinum(II) chloride to elemental platinum, although the reactions do not occur stepwise:\n\nAll three reactions are reversible. Platinum(II) and platinum(IV) bromides are known as well. Platinum hexafluoride is a strong oxidizer capable of oxidizing oxygen.\n\nPlatinum(IV) oxide, PtO, also known as 'Adams' catalyst', is a black powder that is soluble in potassium hydroxide (KOH) solutions and concentrated acids. PtO and the less common PtO both decompose upon heating. Platinum(II,IV) oxide, PtO, is formed in the following reaction:\n\nUnlike palladium acetate, platinum(II) acetate is not commercially available. Where a base is desired, the halides have been used in conjunction with sodium acetate. The use of platinum(II) acetylacetonate has also been reported.\n\nSeveral barium platinides have been synthesized in which platinum exhibits negative oxidation states ranging from −1 to −2. These include BaPt, , and . Caesium platinide, , a dark-red transparent crystalline compound has been shown to contain Pt anions. Platinum also exhibits negative oxidation states at surfaces reduced electrochemically. The negative oxidation states exhibited by platinum are unusual for metallic elements, and they are attributed to the relativistic stabilization of the 6s orbitals.\n\nZeise's salt, containing an ethylene ligand, was one of the first organometallic compounds discovered. Dichloro(cycloocta-1,5-diene)platinum(II) is a commercially available olefin complex, which contains easily displaceable cod ligands (\"cod\" being an abbreviation of 1,5-cyclooctadiene). The cod complex and the halides are convenient starting points to platinum chemistry.\n\nCisplatin, or \"cis\"-diamminedichloroplatinum(II) is the first of a series of square planar platinum(II)-containing chemotherapy drugs. Others include carboplatin and oxaliplatin. These compounds are capable of crosslinking DNA, and kill cells by similar pathways to alkylating chemotherapeutic agents. (Side effects of cisplatin include nausea and vomiting, hair loss, tinnitus, hearing loss, and nephrotoxicity.)\n\nArchaeologists have discovered traces of platinum in the gold used in ancient Egyptian burials as early as 1200 BC. However, the extent of early Egyptians' knowledge of the metal is unclear. It is quite possible they did not recognize there was platinum in their gold.\n\nThe metal was used by pre-Columbian Americans near modern-day Esmeraldas, Ecuador to produce artifacts of a white gold-platinum alloy. Archeologists usually associate the tradition of platinum-working in South America with the La Tolita Culture (circa 600 BC - AD 200), but precise dates and location is difficult, as most platinum artifacts from the area were bought secondhand through the antiquities trade rather than by direct archeological excavation. To work the metal, they employed a relatively sophisticated system of powder metallurgy. The platinum used in such objects was not the pure element, but rather a naturally occurring mixture of the platinum group metals, with small amounts of palladium, rhodium, and iridium.\n\nThe first European reference to platinum appears in 1557 in the writings of the Italian humanist Julius Caesar Scaliger as a description of an unknown noble metal found between Darién and Mexico, \"which no fire nor any Spanish artifice has yet been able to liquefy\". From their first encounters with platinum, the Spanish generally saw the metal as a kind of impurity in gold, and it was treated as such. It was often simply thrown away, and there was an official decree forbidding the adulteration of gold with platinum impurities.\n\nIn 1735, Antonio de Ulloa and Don Jorge Juan y Santacilia saw Native Americans mining platinum while the Spaniards were travelling through Colombia and Peru for eight years. Ulloa and Juan found mines with the whitish metal nuggets and took them home to Spain. Antonio de Ulloa returned to Spain and established the first mineralogy lab in Spain and was the first to systematically study platinum, which was in 1748. His historical account of the expedition included a description of platinum as being neither separable nor calcinable. Ulloa also anticipated the discovery of platinum mines. After publishing the report in 1748, Ulloa did not continue to investigate the new metal. In 1758, he was sent to superintend mercury mining operations in Huancavelica.\n\nIn 1741, Charles Wood, a British metallurgist, found various samples of Colombian platinum in Jamaica, which he sent to William Brownrigg for further investigation.\n\nIn 1750, after studying the platinum sent to him by Wood, Brownrigg presented a detailed account of the metal to the Royal Society, stating that he had seen no mention of it in any previous accounts of known minerals. Brownrigg also made note of platinum's extremely high melting point and refractoriness toward borax. Other chemists across Europe soon began studying platinum, including Andreas Sigismund Marggraf, Torbern Bergman, Jöns Jakob Berzelius, William Lewis, and Pierre Macquer. In 1752, Henrik Scheffer published a detailed scientific description of the metal, which he referred to as \"white gold\", including an account of how he succeeded in fusing platinum ore with the aid of arsenic. Scheffer described platinum as being less pliable than gold, but with similar resistance to corrosion.\n\nCarl von Sickingen researched platinum extensively in 1772. He succeeded in making malleable platinum by alloying it with gold, dissolving the alloy in hot \"aqua regia\", precipitating the platinum with ammonium chloride, igniting the ammonium chloroplatinate, and hammering the resulting finely divided platinum to make it cohere. Franz Karl Achard made the first platinum crucible in 1784. He worked with the platinum by fusing it with arsenic, then later volatilizing the arsenic.\n\nBecause the other platinum-family members were not discovered yet (platinum was the first in the list), Scheffer and Sickingen made the false assumption that due to its hardness—which is slightly more than for pure iron—platinum would be a relatively non-pliable material, even brittle at times, when in fact its ductility and malleability are close to that of gold. Their assumptions could not be avoided because the platinum they experimented with was highly contaminated with minute amounts of platinum-family elements such as osmium and iridium, amongst others, which embrittled the platinum alloy. Alloying this impure platinum residue called \"plyoxen\" with gold was the only solution at the time to obtain a pliable compound, but nowadays, very pure platinum is available and extremely long wires can be drawn from pure platinum, very easily, due to its crystalline structure, which is similar to that of many soft metals.\n\nIn 1786, Charles III of Spain provided a library and laboratory to Pierre-François Chabaneau to aid in his research of platinum. Chabaneau succeeded in removing various impurities from the ore, including gold, mercury, lead, copper, and iron. This led him to believe he was working with a single metal, but in truth the ore still contained the yet-undiscovered platinum-group metals. This led to inconsistent results in his experiments. At times, the platinum seemed malleable, but when it was alloyed with iridium, it would be much more brittle. Sometimes the metal was entirely incombustible, but when alloyed with osmium, it would volatilize. After several months, Chabaneau succeeded in producing 23 kilograms of pure, malleable platinum by hammering and compressing the sponge form while white-hot. Chabeneau realized the infusibility of platinum would lend value to objects made of it, and so started a business with Joaquín Cabezas producing platinum ingots and utensils. This started what is known as the \"platinum age\" in Spain.\n\nPlatinum, along with the rest of the platinum-group metals, is obtained commercially as a by-product from nickel and copper mining and processing. During electrorefining of copper, noble metals such as silver, gold and the platinum-group metals as well as selenium and tellurium settle to the bottom of the cell as \"anode mud\", which forms the starting point for the extraction of the platinum-group metals.\n\nIf pure platinum is found in placer deposits or other ores, it is isolated from them by various methods of subtracting impurities. Because platinum is significantly denser than many of its impurities, the lighter impurities can be removed by simply floating them away in a liquid. Platinum is paramagnetic, whereas nickel and iron are both ferromagnetic. These two impurities are thus removed by running an electromagnet over the mixture. Because platinum has a higher melting point than most other substances, many impurities can be burned or melted away without melting the platinum. Finally, platinum is resistant to hydrochloric and sulfuric acids, whereas other substances are readily attacked by them. Metal impurities can be removed by stirring the mixture in either of the two acids and recovering the remaining platinum.\n\nOne suitable method for purification for the raw platinum, which contains platinum, gold, and the other platinum-group metals, is to process it with \"aqua regia\", in which palladium, gold and platinum are dissolved, whereas osmium, iridium, ruthenium and rhodium stay unreacted. The gold is precipitated by the addition of iron(II) chloride and after filtering off the gold, the platinum is precipitated as ammonium chloroplatinate by the addition of ammonium chloride. Ammonium chloroplatinate can be converted to platinum by heating. Unprecipitated hexachloroplatinate(IV) may be reduced with elemental zinc, and a similar method is suitable for small scale recovery of platinum from laboratory residues. Mining and refining platinum has environmental impacts.\n\nOf the 218 tonnes of platinum sold in 2014, 98 tonnes were used for vehicle emissions control devices (45%), 74.7 tonnes for jewelry (34%), 20.0 tonnes for chemical production and petroleum refining (9.2%), and 5.85 tonnes for electrical applications such as hard disk drives (2.7%). The remaining 28.9 tonnes went to various other minor applications, such as medicine and biomedicine, glassmaking equipment, investment, electrodes, anticancer drugs, oxygen sensors, spark plugs and turbine engines.\n\nThe most common use of platinum is as a catalyst in chemical reactions, often as platinum black. It has been employed as a catalyst since the early 19th century, when platinum powder was used to catalyze the ignition of hydrogen. Its most important application is in automobiles as a catalytic converter, which allows the complete combustion of low concentrations of unburned hydrocarbons from the exhaust into carbon dioxide and water vapor. Platinum is also used in the petroleum industry as a catalyst in a number of separate processes, but especially in catalytic reforming of straight-run naphthas into higher-octane gasoline that becomes rich in aromatic compounds. PtO, also known as Adams' catalyst, is used as a hydrogenation catalyst, specifically for vegetable oils. Platinum also strongly catalyzes the decomposition of hydrogen peroxide into water and oxygen and it is used in fuel cells as a catalyst for the reduction of oxygen.\n\nFrom 1889 to 1960, the meter was defined as the length of a platinum-iridium (90:10) alloy bar, known as the International Prototype Meter bar. The previous bar was made of platinum in 1799. Until 2018, the International Prototype Kilogram remained defined by a cylinder of the same platinum-iridium alloy made in 1879.\n\nThe standard hydrogen electrode also uses a platinized platinum electrode due to its corrosion resistance, and other attributes.\n\nPlatinum is a precious metal commodity; its bullion has the ISO currency code of XPT. Coins, bars, and ingots are traded or collected. Platinum finds use in jewellery, usually as a 90–95% alloy, due to its inertness. It is used for this purpose for its prestige and inherent bullion value. Jewellery trade publications advise jewellers to present minute surface scratches (which they term patina) as a desirable feature in attempt to enhance value of platinum products.\n\nIn watchmaking, Vacheron Constantin, Patek Philippe, Rolex, Breitling, and other companies use platinum for producing their limited edition watch series. Watchmakers appreciate the unique properties of platinum, as it neither tarnishes nor wears out (the latter quality relative to gold).\n\nThe price of platinum, like other industrial commodities, is more volatile than that of gold. In 2008, the price of platinum dropped from $2,252 to $774 per oz, a loss of nearly 2/3 of its value. By contrast, the price of gold dropped from ~$1,000 to ~$700/oz during the same time frame, a loss of only 1/3 of its value.\n\nDuring periods of sustained economic stability and growth, the price of platinum tends to be as much as twice the price of gold, whereas during periods of economic uncertainty, the price of platinum tends to decrease due to reduced industrial demand, falling below the price of gold. Gold prices are more stable in slow economic times, as gold is considered a safe haven. Although gold is used in industrial applications, its demand is not so driven by industrial uses. In the 18th century, platinum's rarity made King Louis XV of France declare it the only metal fit for a king.\n\nIn the laboratory, platinum wire is used for electrodes; platinum pans and supports are used in thermogravimetric analysis because of the stringent requirements of chemical inertness upon heating to high temperatures (~1000 °C). Platinum is used as an alloying agent for various metal products, including fine wires, noncorrosive laboratory containers, medical instruments, dental prostheses, electrical contacts, and thermocouples. Platinum-cobalt, an alloy of roughly three parts platinum and one part cobalt, is used to make relatively strong permanent magnets. Platinum-based anodes are used in ships, pipelines, and steel piers.\n\nPlatinum's rarity as a metal has caused advertisers to associate it with exclusivity and wealth. \"Platinum\" debit and credit cards have greater privileges than \"gold\" cards. \"Platinum awards\" are the second highest possible, ranking above \"gold\", \"silver\" and \"bronze\", but below diamond. For example, in the United States, a musical album that has sold more than 1 million copies will be credited as \"platinum\", whereas an album that has sold more than 10 million copies will be certified as \"diamond\". Some products, such as blenders and vehicles, with a silvery-white color are identified as \"platinum\". Platinum is considered a precious metal, although its use is not as common as the use of gold or silver. The frame of the Crown of Queen Elizabeth The Queen Mother, manufactured for her coronation as Consort of King George VI, is made of platinum. It was the first British crown to be made of this particular metal.\n\nAccording to the Centers for Disease Control and Prevention, short-term exposure to platinum salts may cause irritation of the eyes, nose, and throat, and long-term exposure may cause both respiratory and skin allergies. The current OSHA standard is 2 micrograms per cubic meter of air averaged over an 8-hour work shift. The National Institute for Occupational Safety and Health has set a recommended exposure limit (REL) for platinum as 1 mg/m over an 8-hour workday.\n\nPlatinum-based antineoplastic agents are used in chemotherapy, and show good activity against some tumors.\n\nAs platinum is a catalyst in the manufacture of the silicone rubber and gel components of several types of medical implants (breast implants, joint replacement prosthetics, artificial lumbar discs, vascular access ports, etc.), the possibility that platinum could enter the body and cause adverse effects has merited study. The Food and Drug Administration and other institutions have reviewed the issue and found no evidence to suggest toxicity in vivo.\n\n\n"}
{"id": "9775196", "url": "https://en.wikipedia.org/wiki?curid=9775196", "title": "Polyresin", "text": "Polyresin\n\nPolyresin is a resin compound generally used for statues, figurines, bobbleheads and decorative furniture. It is a sturdy material that can be intricately molded, allowing a great level of detail with consistent texture.\n\nAdditives can be incorporated into the compound to enhance the material's strength, reduce its weight, add heat stability, decorative effects, and so on. Polyresin is also compatible with a large range of different finishes, including paint and metallic finishes, which is why many decorative pieces are made from this material.\n\nOne form of polyresin often used is Alabastrite. It is a stone-based material, easy to sculpt, takes paint well, and has a similar appearance to porcelain and pottery.\n\n"}
{"id": "1549715", "url": "https://en.wikipedia.org/wiki?curid=1549715", "title": "Polysulfide", "text": "Polysulfide\n\nPolysulfides are a class of chemical compounds containing chains of sulfur atoms. There are two main classes of polysulfides: anions and organic polysulfides. Anions have the general formula . These anions are the conjugate bases of the hydrogen polysulfides HS. Organic polysulfides generally have the formulae RSR, where R = alkyl or aryl.\n\nThe alkali metal polysulfides arise by treatment of a solution of sulfide, e.g. sodium sulfide, with elemental sulfur:\n\nIn some cases, these anions have been obtained as organic salts, which are soluble in organic solvents.\n\nThe energy released in the reaction of sodium and elemental sulfur is the basis of battery technology. The sodium–sulfur battery and the lithium–sulfur battery require high temperatures to maintain liquid polysulfide and Na-conductive membranes that are unreactive toward sodium, sulfur, and sodium sulfide.\nPolysulfides are ligands in coordination chemistry. Examples of transition metal polysulfido complexes include (CH)TiS, [Ni(S)], and [Pt(S)]. Main group elements also form polysulfides.\n\nIn commerce, the term \"polysulfide\" usually refers to a class of polymers with alternating chains of several sulfur atoms and hydrocarbons. They have the formula RS. In this formula \"x\" indicates the number of sulfur atoms (or \"rank\"). Polysulfide polymers can be synthesized by condensation polymerization reactions between organic dihalides and alkali metal salts of polysulfide anions:\n\nDihalides used in this condensation polymerization are dichloroalkanes (such as 1,2-dichloroethane, bis-(2-chloroethyl)formal (ClCHCHOCHOCHCHCl), and 1,3-dichloropropane). The polymers are called thiokols. In some cases, polysulfide polymers can be formed by ring-opening polymerization reactions.\n\nPolysulfide polymers are also prepared by the addition of polysulfanes to alkenes. An idealized equation is:\nIn reality, homogeneous samples of HS are difficult to prepare.\n\nPolysulfide polymers are insoluble in water, oils, and many other organic solvents. Because of their solvent resistance, these materials find use as sealants to fill the joints in pavement, automotive window glass, and aircraft structures.\n\nPolymers containing one or two sulfur atoms separated by hydrocarbon sequences are usually not classified polysulfides, e.g. poly(\"p\"-phenylene) sulfide (CHS).\n\nMany commercial elastomers contain polysulfides as crosslinks. These crosslinks interconnect neighboring polymer chains, thereby conferring rigidity. The degree of rigidity is related to the number of crosslinks. Elastomers therefore have a characteristic ability to \"snap back\" to their original shape after being stretched or compressed. Because of this memory for their original cured shape, elastomers are commonly referred to as rubbers. The process of crosslinking the polymer chains in these polymers with sulfur is called vulcanization. The sulfur chains attach themselves to the \"allylic\" carbon atoms, which are adjacent to C=C linkages. Vulcanization is a step in the processing of several classes of rubbers, including polychloroprene (Neoprene), styrene-butadiene, and polyisoprene, which is chemically similar to natural rubber. Charles Goodyear's discovery of vulcanization, involving the heating of polyisoprene with sulfur, was revolutionary because it converted a sticky and almost useless material into an elastomer which could be fabricated into useful products.\n\nIn addition to water and ammonia, the clouds in the atmospheres of the gas giant planets contain ammonium sulfides. The reddish-brownish clouds are attributed to polysulfides, arising from the exposure of the ammonium sulfides to light.\n\nPolysulfides, as sulfides, can induce stress corrosion cracking in carbon steel and stainless steel.\n"}
{"id": "3471089", "url": "https://en.wikipedia.org/wiki?curid=3471089", "title": "Recrystallization (metallurgy)", "text": "Recrystallization (metallurgy)\n\nRecrystallization is a process by which deformed grains are replaced by a new set of defect-free grains that nucleate and grow until the original grains have been entirely consumed. Recrystallization is usually accompanied by a reduction in the strength and hardness of a material and a simultaneous increase in the ductility. Thus, the process may be introduced as a deliberate step in metals processing or may be an undesirable byproduct of another processing step. The most important industrial uses are softening of metals previously hardened or rendered brittle by cold work, and control of the grain structure in the final product.\n\nRecrystallization is defined as the process in which grains of a crystal structure come in a new structure or new crystal shape.\n\nA precise definition of recrystallization is difficult to state as the process is strongly related to several other processes, most notably recovery and grain growth. In some cases it is difficult to precisely define the point at which one process begins and another ends. Doherty \"et al.\" (1997) defined recrystallization as:\n\"... the formation of a new grain structure in a deformed material by the formation and migration of high angle grain boundaries driven by the stored energy of deformation. High angle boundaries are those with greater than a 10-15° misorientation\"\n\nThus the process can be differentiated from recovery (where high angle grain boundaries do not migrate) and grain growth (where the driving force is only due to the reduction in boundary area).\nRecrystallization may occur during or after deformation (during cooling or a subsequent heat treatment, for example). The former is termed \"dynamic\" while the latter is termed \"static\". In addition, recrystallization may occur in a discontinuous manner, where distinct new grains form and grow, or a continuous manner, where the microstructure gradually evolves into a recrystallised microstructure. The different mechanisms by which recrystallization and recovery occur are complex and in many cases remain controversial. The following description is primarily applicable to static discontinuous recrystallization, which is the most classical variety and probably the most understood. Additional mechanisms include (geometric) dynamic recrystallization and strain induced boundary migration.\n\n\"Secondary recrystallization\" occurs when a certain very small number of {110}<001> (Goss) grains grow selectively, about one in 106 primary grains, at the expense of many other primary recrystallized grains. The mechanism of secondary recrystallization is a small and uniform primary grain size, achieved through the inhibition of normal grain growth by fine precipitates called inhibitors. Goss grains are named in honor of Norman P. Goss, the inventor of grain-oriented electrical steel circa 1934.\n\nThere are several, largely empirical laws of recrystallization:\n\nDuring plastic deformation the work performed is the integral of the stress and strain in the plastic deformation regime. Although the majority of this work is converted to heat, some fraction (~1–5%) is retained in the material as defects — particularly dislocations. The rearrangement or elimination of these dislocations will reduce the internal energy of the system and so there is a thermodynamic driving force for such processes. At moderate to high temperatures, particularly in materials with a high stacking fault energy such as aluminium and nickel, recovery occurs readily and free dislocations will readily rearrange themselves into subgrains surrounded by low-angle grain boundaries.\nThe driving force is the difference in energy between the deformed and recrystallized state Δ\"E\" which can be determined by the dislocation density or the subgrain size and boundary energy (Doherty, 2005):\n\nwhere \"ρ\" is the dislocation density, \"G\" is the shear modulus, \"b\" is the Burgers vector of the dislocations, \"γ\" is the subgrain boundary energy and \"d\" is the subgrain size.\n\nHistorically it was assumed that the nucleation rate of new recrystallized grains would be determined by the thermal fluctuation model successfully used for solidification and precipitation phenomena. In this theory it is assumed that as a result of the natural movement of atoms (which increases with temperature) small nuclei would spontaneously arise in the matrix. The formation of these nuclei would be associated with an energy requirement due to the formation of a new interface and an energy liberation due to the formation of a new volume of lower energy material. If the nuclei were larger than some critical radius then it would be thermodynamically stable and could start to grow. \nThe main problem with this theory is that the stored energy due to dislocations is very low (0.1-1 Jm) while the energy of a grain boundary is quite high (~0.5Jm). Calculations based on these values found that the observed nucleation rate was greater than the calculated one by some impossibly large factor (~10).\n\nAs a result, the alternate theory proposed by Cahn in 1949 is now universally accepted. The recrystallized grains do not nucleate in the classical fashion but rather grow from pre-existing sub-grains and cells. The 'incubation time' is then a period of recovery where sub-grains with low-angle boundaries (<1-2°) begin to accumulate dislocations and become increasingly misoriented with respect to their neighbors. The increase in misorientation increases the mobility of the boundary and so the rate of growth of the sub-grain increases. If one sub-grain in a local area happens to have an advantage over its neighbors (such as locally high dislocation densities, a greater size or favorable orientation) then this sub-grain will be able to grow more rapidly than its competitors. As it grows its boundary becomes increasingly misoriented with respect to the surrounding material until it can be recognized as an entirely new strain-free grain.\n\nRecrystallization kinetics are commonly observed to follow the profile shown. There is an initial 'nucleation period' \"t\" where the nuclei form, and then begin to grow at a constant rate consuming the deformed matrix. Although the process does not strictly follow classical nucleation theory it is often found that such mathematical descriptions provide at least a close approximation. For an array of spherical grains the mean radius \"R\" at a time \"t\" is (Humphreys and Hatherly 2004):\n\nwhere \"t\" is the nucleation time and \"G\" is the growth rate dR/dt. If \"N\" nuclei form in the time increment \"dt\" and the grains are assumed to be spherical then the volume fraction will be:\n\nThis equation is valid in the early stages of recrystallization when \"f«1\" and the growing grains are not impinging on each other. Once the grains come into contact the rate of growth slows and is related to the fraction of untransformed material (1-f) by the Johnson-Mehl equation:\n\nWhile this equation provides a better description of the process it still assumes that the grains are spherical, the nucleation and growth rates are constant, the nuclei are randomly distributed and the nucleation time t is small. In practice few of these are actually valid and alternate models need to be used.\n\nIt is generally acknowledged that any useful model must not only account for the initial condition of the material but also the constantly changing relationship between the growing grains, the deformed matrix and any second phases or other microstructural factors. The situation is further complicated in dynamic systems where deformation and recrystallization occur simultaneously. As a result, it has generally proven impossible to produce an accurate predictive model for industrial processes without resorting to extensive empirical testing. Since this may require the use of industrial equipment that has not actually been built there are clear difficulties with this approach.\n\nThe annealing temperature has a dramatic influence on the rate of recrystallization which is reflected in the above equations. However, for a given temperature there are several additional factors that will influence the rate.\n\nThe rate of recrystallization is heavily influenced by the amount of deformation and, to a lesser extent, the manner in which it is applied. Heavily deformed materials will recrystallize more rapidly than those deformed to a lesser extent. Indeed, below a certain deformation recrystallization may never occur. Deformation at higher temperatures will allow concurrent recovery and so such materials will recrystallize more slowly than those deformed at room temperature e.g. contrast hot and cold rolling. In certain cases deformation may be unusually homogeneous or occur only on specific crystallographic planes. The absence of orientation gradients and other heterogeneities may prevent the formation of viable nuclei. Experiments in the 1970s found that molybdenum deformed to a true strain of 0.3, recrystallized most rapidly when tensioned and at decreasing rates for wire drawing, rolling and compression (Barto & Ebert 1971).\n\nThe orientation of a grain and how the orientation changes during deformation influence the accumulation of stored energy and hence the rate of recrystallization. The mobility of the grain boundaries is influenced by their orientation and so some crystallographic textures will result in faster growth than others.\n\nSolute atoms, both deliberate additions and impurities, have a profound influence on the recrystallization kinetics. Even minor concentrations may have a substantial influence e.g. 0.004% Fe increases the recrystallization temperature by around 100 °C (Humphreys and Hatherly 2004). It is currently unknown whether this effect is primarily due to the retardation of nucleation or the reduction in the mobility of grain boundaries i.e. growth.\n\nMany alloys of industrial significance have some volume fraction of second phase particles, either as a result of impurities or from deliberate alloying additions. Depending on their size and distribution such particles may act to either encourage or retard recrystallization.\n\nRecrystallization is prevented or significantly slowed by a dispersion of small, closely spaced particles due to Zener pinning on both low- and high-angle grain boundaries. This pressure directly opposes the driving force arising from the dislocation density and will influence both the nucleation and growth kinetics. The effect can be rationalized with respect to the \"particle dispersion level\" formula_5 where formula_6 is the volume fraction of the second phase and r is the radius. At low formula_7 the grain size is determined by the number of nuclei, and so initially may be very small. However the grains are unstable with respect to grain growth and so will grow during annealing until the particles exert sufficient pinning pressure to halt them. At moderate formula_7 the grain size is still determined by the number of nuclei but now the grains are stable with respect to normal growth (while abnormal growth is still possible). At high formula_5 the unrecrystallized deformed structure is stable and recrystallization is suppressed.\n\nThe deformation fields around large (over 1 μm) non-deformable particles are characterised by high dislocation densities and large orientation gradients and so are ideal sites for the development of recrystallization nuclei. This phenomenon, called particle stimulated nucleation (PSN), is notable as it provides one of the few ways to control recrystallization by controlling the particle distribution.\n\nThe size and misorientation of the deformed zone is related to the particle size and so there is a minimum particle size required to initiate nucleation. Increasing the extent of deformation will reduce the minimum particle size, leading to a PSN regime in size-deformation space.\nIf the efficiency of PSN is one (i.e. each particle stimulates one nuclei), then the final grain size will be simply determined by the number of particles. Occasionally the efficiency can be greater than one if multiple nuclei form at each particle but this is uncommon. The efficiency will be less than one if the particles are close to the critical size and large fractions of small particles will actually prevent recrystallization rather than initiating it (see above).\n\nThe recrystallization behavior of materials containing a wide distribution of particle sizes can be difficult to predict. This is compounded in alloys where the particles are thermally-unstable and may grow or dissolve with time. The situation is more simple in bimodal alloys which have two distinct particle populations. An example is Al-Si alloys where it has been shown that even in the presence of very large (<5 μm) particles the recrystallization behavior is dominated by the small particles (Chan & Humphreys 1984). In such cases the resulting microstructure tends to resemble one from an alloy with only small particles.\n\n\n"}
{"id": "24376808", "url": "https://en.wikipedia.org/wiki?curid=24376808", "title": "Rubblization", "text": "Rubblization\n\nRubblization is a construction and engineering technique that involves saving time and transportation costs by reducing existing concrete into rubble at its current location rather than hauling it to another location. Rubblization has two primary applications: creating a base for new roadways and decommissioning nuclear power plants.\n\nIn road construction, a worn-out Portland cement concrete can be rubblized and then overlaid with a new surface, usually asphalt concrete. Specialized equipment breaks up the old roadway into small pieces to make a base for new pavement. This saves the expense of transporting the old pavement to a disposal site, and purchasing/transporting new base materials for the replacement paving. The result is a smoother pavement surface than would be obtained if a layer of asphalt were to be applied to the unbroken concrete surface. The technique has been used on roads since the late 1990s, and is also being used for concrete airport runways.\n\nThe rubblizing process provides many benefits versus other methods of road rehabilitation, such as crack and seat or removal and replacement of a concrete surface including: rubblizing a concrete surface is 52% less expensive than remove and replacing concrete; rubblizing reduces road reconstruction time, from days of lane closures to hours, providing large savings to contractors and reduced impact on travelling public; and rubblization is an environmentally friendly \"green\" process.,\n\nIn nuclear energy regulation, \"Rubblization\" refers to a method for decommissioning a nuclear power plant. As with other decommissioning techniques, all equipment from buildings is removed and the surfaces are decontaminated. The difference with rubblization is that above-grade structures, including the concrete containment building, are demolished into rubble and buried in the structure's foundation below ground. The site surface is then covered, regraded, and landscaped for unrestricted use. This saves the expense of removing and transporting the building pieces to a different site.\n\n"}
{"id": "46906913", "url": "https://en.wikipedia.org/wiki?curid=46906913", "title": "Sadun Boro", "text": "Sadun Boro\n\nSadun Boro (1928 – June 5, 2015) was the first Turkish amateur sailor to circumnavigate the globe by sailing.\n\nSadun Boro was born in Istanbul, Turkey in 1928. He spent his childhood at Caddebostan neighnorhood of Kadıköy, Istanbul, on the coast of Sea of Marmara. He changed his rowing boat with a sailboat as soon as he became a high school student. \n\nHe finished Galatasaray High School in 1948, and went to the United Kingdom to study textile engineering at University of Manchester Institute of Science and Technology. \n\nIn 1952, Boro made his first ocean voyage from British Islands to the Caribbean Islands on the -long sailboat \"Ling\" together with an Englishman. The story of his travel that lasted six months was published in serial format in the Turkish daily \"Cumhuriyet\", and was compiled in his book titled \"Bir Hayalin Peşinde\" (literally: In Pursuit of a Dream) later in 2004.\n\nHis -long sloop was laid down at the workshop of Athar Beşpınar in Salacak neidhborhood of Üsküdar, Istanbul in 1963, and named \"Kısmet\" (Turkish for \"Fortune\"). The sail, he manufactured in the textile plant, he was working at Çukurova, southern Turkey.\n\nBoro began his westabout (east to west) voyage to circumnavigate the globe on August 22, 1965, accompanied by his German-born wife Oda Boro. He set sail from Istanbul, passed Strait of Gibraltar crossing Mediterranean Sea and reached Canary Islands, where they took a housecat aboard and named it \"Miço\" (Turkish for \"shipmate\"). Crossing the Atlantic Ocean, he arrived in Barbados and Caribbean Islands. Passing through the Panama Canal, he sailed crossing Pacific Ocean to Galápagos Islands, Marquesas Islands, Tuamotu Archipelago, Tahiti, Society Islands, Tonga Islands, Fiji Islands, New Hebrides and New Guinea. His route went then through Torres Strait to Timor, Indonesia and Singapore. Crossing the Bay of Bengal, he was in Ceylon (today: Sri Lanka). He sailed then on Arabian Sea and Red Sea and then was carried by a truck from Eilat to Haifa. In Mediterranean Sea again, his last stop before completing his globe circumnavigation was Israel. \n\nOn June 15, 1968, after 1,028 days of an ocean voyage, he arrived in Istanbul, where he was welcomed by his mother, and cheered as a national hero. Becoming the first ever Turkish global circumnavigator, he paved the way for global circumnavigation of Turkish sailors.\n\nThe memories about his voyage around the world were published as newspaper serialization in the daily \"Hürriyet\" at that time, and were written down later in his popular book \"Pupa Yelken\" (Turkish for \"Full Sail\").\n\nErected in front of the Kalamış Marina's main entrance in Kadıköy, Istanbul, a monument featuring Sadun Boro at boat's wheel of his sloop and his wife Oda standing next, both sailing on the globe commemorates his achievement.\n\nBetween 1977–79, Sadun Boro sailed with his wife and then-eight-year old daughter Deniz to the Caribbean and the East Coast of the United States. After 1980, he settled down in Bodrum and Gökova, known for its idyllic coasts full of forests and turquoise sea. \n\nHe devoted himself to the protection of nature at the Turkish Riviera, in particular in Gökova, Göcek and Fethiye. Boro aimed to instil love for nature and sea to young people with his articles published in newspapers and journals. As a lover of Gökova, he had a mermaid statue erected with an inscription atop a rock in the middle of Okluk Bay. The inscription reads Boro's words as \"This mermaid has traveled many seas and horizons to find the heaven that she dreamed of. She traveled continents, islands and bays, until she reached Gökova.\" His latest book, titled \"Vira Demir\" (Turkish for \"Haul Up the Anchor\"), is a guide for sailors.\n\nBoro donated his sloop \"Kısmet\", he sailed 46-year long about with, to the Rahmi M. Koç Museum, a museum in Istanbul dedicated to the history of transport, industry and communications, which was founded by the wealthy businessman Rahmi Koç, who also circumnavigated the globe between 2004-06.\n\nSadun Boro lived in Okluk Bay, Gökova on board his catamaran named \"Son Bahar\" (Turkish for \"Autumn\" or \"Last Spring\").\n\nSadun Boro was diagnosed with bladder cancer a couple of years ago. He was first treated in Marmaris, where he lived, and then transferred to the American Hospital in Istanbul. However, he was airlifted by helicopter back to Muğla on May 14, 2015 as he wished to spend his rest of life on board of his sailboat.\n\nAt 9:15 hours local time on June 5, 2015, he died at age 87 in the intensive care unit of a hospital at Marmaris, where he was taken into three days before. His last will was to be buried under the pine, to which his sailboat is secured mooring at İngilizlimanı (literally: English Harbor) in Gökova. For its realization, a cabinet decision is necessary. He was interred in Karacasöğüt Cemetery in Marmaris following a memorial tour in the bays of the Turkish Riviera he admired on board of his catamaran \"Son Bahar\" accompanied by many boats and vessels of the Turkish Coast Guard and a frigate of the Turkish Navy.\n\nHe was survived by his wife Oda and his daughter Deniz (Turkish for \"Sea\").\n\n\nTurkish sailors circumnavigated the globe following Sadun Boro, listed chronologically:\n"}
{"id": "31679460", "url": "https://en.wikipedia.org/wiki?curid=31679460", "title": "Sinking (behavior)", "text": "Sinking (behavior)\n\nSinking of champagne is the act of pouring out champagne in the sink. Sinking probably started in Sweden as \"a reaction to the ban on spraying champagne in many bars\" and the sinking is usually done by a person ordering two bottles of champagne and asking the bartender to pour out (sink) one of them. The term \"sinking\" is a translation of the Swedish \"vaskning\", derived from \"vask\", which means \"sink\".\n\nIn 2007 and 2010 respectively, bars in the Swedish cities of Båstad and Visby, popular party destinations for the wealthy youth, banned the spraying of champagne. The ban referred to champagne spraying possibly violating the law’s requirement on servers of alcohol to maintain good order. The ban caused some people to sink the champagne instead, while others chose to buy more expensive champagne.\n\nAccording to Marie Söderqvist, CEO of the analysis company United Minds and author of the book \"Status – vägen till lycka\" (Eng. \"Status – the road to happiness\"), sinking is not just a protest against the ban on spraying champagne: \"One gives the finger to everything – bans, global justice, saving the planet and equality.\"\n\nSinking has been the subject of articles by national newspapers like \"Aftonbladet\" and \"Dagens Nyheter,\" but it is unclear how much sinking actually occurs. In a survey among barkeepers in Båstad, Stockholm, and Visby, one of them said they get \"approximately one serious sinking request per night,\" while others claimed sinking was a myth.\n\nSinking has also been the theme of a music video by \"Kakan och Julia\" featured on Swedish Public Television.\n\nVariants of the phenomenon have reportedly taken place, such as \"hamburger dumping\" (purchasing a large number of hamburgers at a fast food restaurant, and throwing all but one into the trash). \n\n"}
{"id": "7095838", "url": "https://en.wikipedia.org/wiki?curid=7095838", "title": "Steelyard balance", "text": "Steelyard balance\n\nA steelyard balance, steelyard, or stilyard is a straight-beam balance with arms of unequal length. It incorporates a counterweight which slides along the longer arm to counterbalance the load and indicate its weight. A steelyard is also known as a Roman steelyard or Roman balance.\n\nThe steelyard comprises a balance beam which is suspended from a Lever/pivot or fulcrum which is very close to one end of the beam. The two parts of the beam which flank the pivot are the arms. The arm from which the object to be weighed (the load) is hung is short and is located close to the pivot point. The other arm is longer, is graduated and incorporates a counterweight which can be moved along the arm until the two arms are balanced about the pivot, at which time the weight of the load is indicated by the position of the counterweight.\n\nThe steelyard exemplifies the law of the lever, wherein, when balanced, the weight of the object being weighed, multiplied by the length of the short balance arm to which it is attached, is equal to the weight of the counterweight multiplied by the distance of the counterweight from the pivot.\n\nAccording to Mark Sky of Harvard University, the steelyard was in use among Greek craftsmen of the 5th and 4th centuries BC, even before Archimedes demonstrated the law of the lever theoretically. The Latin name \"statera\" comes from the Ancient Greek \"στατήρ\" (\"statḗr\"). Roman and Chinese steelyards were independently invented around 200 BC. Steelyards dating from AD 100 to 400 have been unearthed in Great Britain. Steelyards and their components have also been excavated from shipwrecks of the Byzantine period in the Mediterranean and the Red Sea, such as the 7th-century wreck at Yassi Ada, Turkey, and the mid-first millennium shipwreck at Black Assarca Island, Eritrea. The \"Oxford English Dictionary\" suggests that the name \"steelyard\" is derived from\" steel\" combined with \"yard\", influenced by a \"misunderstood\" allusion to the Steelyard, the main trading base of the Hanseatic League in London in the 14th century.\n\nLarge steelyard balances (known as cart balances), both public and private, were a common feature in agricultural areas in England from the eighteenth century forward. An example of a public cart steelyard remains at Soham, Cambridgeshire and another is to be seen at Woodbridge, Suffolk.\n\nSteelyards of different sizes have been used to weigh loads ranging from ounces to tons. A small steelyard could be a foot or less in length and thus conveniently used as a portable device that merchants and traders could use to weigh small ounce-sized items of merchandise. In other cases a steelyard could be several feet long and used to weigh sacks of flour and other commodities. Even larger steelyards were three stories tall and used to weigh fully laden horse-drawn carts.\n\nA Scandinavian steelyard is a variant which consists of a bar with a fixed weight attached to one end, a movable pivot point and an attachment point for the object to be weighed at the other end. Once the object to be weighed is attached to its end of the bar, the pivot point, which is frequently a loop at the end of a cord or chain, is moved until the bar is balanced. The bar can be calibrated so that the object's weight can be read off directly from the position of the pivot. This type is known in Sweden, Denmark and Norway.\n\n"}
{"id": "16731190", "url": "https://en.wikipedia.org/wiki?curid=16731190", "title": "The Great Resistance", "text": "The Great Resistance\n\nThe Great Resistance (French: \"Au pays des colons\") is a 2007 documentary by Quebec film director Denys Desjardins. This length feature is produced by the National Film Board of Canada (NFB).\n\nIn the 1930s, in the throes of the Great Depression, the government of Quebec relocated more than 80,000 citizens to found a new settlement in the virgin forests of Quebec’s Abitibi region. After enduring backbreaking work to clear the land, however, many left, seeking a better life in the city or as labourers for the large corporations that had come to exploit the North’s valuable resources. The Lalancette family, however, have persisted in forging their future on the land from one generation to the next, earning their keep from farming, and defying the constraints of globalization and the mining and forestry companies that control the area. Revisiting the heritage of Quebec filmmakers who documented Abitibi, following in the footsteps of Pierre Perrault, among others, this documentary traces a defining chapter of Quebec history and raises fundamental questions about regional development.\n\n\n"}
{"id": "319506", "url": "https://en.wikipedia.org/wiki?curid=319506", "title": "Transient-voltage-suppression diode", "text": "Transient-voltage-suppression diode\n\nA transient-voltage-suppression (TVS) diode, also transil or thyrector, is an electronic component used to protect electronics from voltage spikes induced on connected wires.\n\nThe device operates by shunting excess current when the induced voltage exceeds the avalanche breakdown potential. It is a clamping device, suppressing all overvoltages above its breakdown voltage. It automatically resets when the overvoltage goes away, but absorbs much more of the transient energy internally than a similarly rated crowbar device.\n\nA transient-voltage-suppression diode may be either unidirectional or bidirectional. A unidirectional device operates as a rectifier in the forward direction like any other avalanche diode, but is made and tested to handle very large peak currents.\n\nA bidirectional transient-voltage-suppression diode can be represented by two mutually opposing avalanche diodes in series with one another and connected in parallel with the circuit to be protected. While this representation is schematically accurate, physically the devices are now manufactured as a single component.\n\nA transient-voltage-suppression diode can respond to over-voltages faster than other common over-voltage protection components such as varistors or gas discharge tubes (GDT). The actual clamping occurs in roughly one picosecond, but in a practical circuit the inductance of the wires leading to the device imposes a higher limit. This makes transient-voltage-suppression diodes useful for protection against very fast and often damaging voltage transients. These fast over-voltage transients are present on all distribution networks and can be caused by either internal or external events, such as lightning or motor arcing.\n\nTransient voltage suppressors will fail if they are subjected to voltages or conditions beyond those that the particular product was designed to accommodate. There are three key modes in which the TVS will fail: short, open, and degraded device.\n\nTVS diodes are sometimes referred to as transorbs, from the Vishay trademark \"TransZorb\".\nA TVS diode is characterized by:\n\n\n\n"}
{"id": "39882593", "url": "https://en.wikipedia.org/wiki?curid=39882593", "title": "Unacceptable Levels", "text": "Unacceptable Levels\n\nUnacceptable Levels is a 2013 documentary film about the widespread use of artificial chemicals and their effects on the natural environment and human health. It was directed and written by Edward Brown.\n\nThe film features Ralph Nader, Devra Lee Davis, Stacy Malkan, Ken Cook, Christopher Gavigan, Alan Greene, John Warner, Andy Igrejas, Joan Blades, William Hirzy, Richard Clapp, Tyrone Hayes, Jeffrey Hollender, and Randy Hayes.\n\nThe film is touring the United States in the summer of 2013, with screenings scheduled for San Francisco on July 11, Chicago on July 24, and Austin, Texas, on August 24.\n\n"}
{"id": "3888193", "url": "https://en.wikipedia.org/wiki?curid=3888193", "title": "Waman Bapuji Metre", "text": "Waman Bapuji Metre\n\nWaman Bapuji Metre (14 February 1906 – 21 November 1970), sometimes referred to in the Indian oil industry as Dada (meaning \"Elder brother Metre\" in the Bengali and Marathi languages), was an Indian petroleum geologist. For his \"significant contribution to the growth of the oil industry in the country\", he was awarded India's third-highest civilian award, the Padma Bhushan, in 1968.\n\n"}
{"id": "7320236", "url": "https://en.wikipedia.org/wiki?curid=7320236", "title": "Waste collection authority", "text": "Waste collection authority\n\nA waste collection authority (WCA) is a local authority in the UK charged with the collection of municipal waste. There are 376 WCAs in England and Wales who are responsible for collecting waste from nearly 22 million homes and some businesses. The WCA passes on the waste to the waste disposal authority that is tasked with the ultimate treatment and disposal of that waste. In England WCAs are the district councils and unitary authorities.\n"}
{"id": "17476820", "url": "https://en.wikipedia.org/wiki?curid=17476820", "title": "Wenche Kjølås", "text": "Wenche Kjølås\n\nWenche Kjølås (born 20 December 1962) is a Norwegian businessperson.\n\nShe hails from Stranda, and is educated as a master in economics and business administration from the Norwegian School of Economics. From 1986 to 1992 she worked in Touche Ross. She then became financial manager in Hakon Gruppen from 1993 to 1995 and financial director in Kavli Holding from 1995. She was also managing director in Kavli from 1997 to 1999\n\nFrom 2006 she was the chief financial officer of Grieg Logistics, and in 2009 she became managing director of Grieg Maturitas. This is the mother company in Grieg Gruppen, and Kjølås is also a board member of the daughter companies Grieg Group Resources (chair), Grieg Seafood, Grieg Property, Grieg Logistics and Grieg Gaarden.\n\nIn 1996–1997 Kjølås was a member of the governmental Norges Eksportråd. In 2006 she was noted as being among the most sought-after female board members in Norwegian enterprise, with six memberships on boards of directors. Kjølås chairs the board of Flytoget since 2013, and has been a member of the board of Cermaq (2003–2009), Selvaag Bolig (2011–2013), DOF ASA, Petroleum Geo-Services, Kavli and Q–meieriene.\n"}
{"id": "25188014", "url": "https://en.wikipedia.org/wiki?curid=25188014", "title": "Wood-free paper", "text": "Wood-free paper\n\nWood-free paper is paper created exclusively from chemical pulp rather than mechanical pulp. Chemical pulp is normally made from pulpwood, but is not considered wood as most of the lignin is removed and separated from the cellulose fibers during processing, whereas mechanical pulp retains most of its wood components and can therefore still be described as wood. Wood-free paper is not as susceptible to yellowing as paper containing mechanical pulp.\n\n"}
{"id": "53954", "url": "https://en.wikipedia.org/wiki?curid=53954", "title": "Work function", "text": "Work function\n\nIn solid-state physics, the work function (sometimes spelled workfunction) is the minimum thermodynamic work (i.e. energy) needed to remove an electron from a solid to a point in the vacuum immediately outside the solid surface. Here \"immediately\" means that the final electron position is far from the surface on the atomic scale, but still too close to the solid to be influenced by ambient electric fields in the vacuum.\nThe work function is not a characteristic of a bulk material, but rather a property of the surface of the material (depending on crystal face and contamination).\n\nThe work function for a given surface is defined by the difference\nwhere is the charge of an electron, is the electrostatic potential in the vacuum nearby the surface, and is the Fermi level (electrochemical potential of electrons) inside the material. The term is the energy of an electron at rest in the vacuum nearby the surface.\n\nIn practice, one directly controls by the voltage applied to the material through electrodes, and the work function is generally a fixed characteristic of the surface material. Consequently, this means that when a voltage is applied to a material, the electrostatic potential produced in the vacuum will be somewhat lower than the applied voltage, the difference depending on the work function of the material surface. Rearranging the above equation, one has\nwhere is the voltage of the material (as measured by a voltmeter, through an attached electrode), relative to an electrical ground that is defined as having zero Fermi level. The fact that depends on material surface means that the space between two dissimilar conductors will have a built-in electric field, when those conductors are in total equilibrium with each other (electrically shorted to each other, and with equal temperatures). An example of this situation is depicted in the adjacent figure. As described in the next section, these built-in vacuum electric fields can have important consequences in some cases.\n\n\nCertain physical phenomena are highly sensitive to the value of the work function.\nThe observed data from these effects can be fitted to simplified theoretical models, allowing one to extract a value of the work function.\nThese phenomenologically extracted work functions may be slightly different from the thermodynamic definition given above.\nFor inhomogeneous surfaces, the work function varies from place to place, and different methods will yield different values of the typical \"work function\" as they average or select differently among the microscopic work functions.\n\nMany techniques have been developed based on different physical effects to measure the electronic work function of a sample. One may distinguish between two groups of experimental methods for work function measurements: absolute and relative.\n\n\nThe work function is important in the theory of thermionic emission, where thermal fluctuations provide enough energy to \"evaporate\" electrons out of a hot material (called the 'emitter') into the vacuum. If these electrons are absorbed by another, cooler material (called the \"collector\") then a measurable electric current will be observed. Thermionic emission can be used to measure the work function of both the hot emitter and cold collector. Generally, these measurements involve fitting to Richardson's law, and so they must be carried out in a low temperature and low current regime where space charge effects are absent.\n\nIn order to move from the hot emitter to the vacuum, an electron's energy must exceed the emitter Fermi level by an amount\ndetermined simply by the thermionic work function of the emitter.\nIf an electric field is applied towards the surface of the emitter, then all of the escaping electrons will be accelerated away from the emitter and absorbed into whichever material is applying the electric field.\nAccording to Richardson's law the emitted current density (per unit area of emitter), \"J\" (A/m), is related to the absolute temperature \"T\" of the emitter by the equation:\nwhere \"k\" is the Boltzmann constant and the proportionality constant \"A\" is the Richardson's constant of the emitter.\nIn this case, the dependence of \"J\" on \"T\" can be fitted to yield \"W\".\n\nThe same setup can be used to instead measure the work function in the collector, simply by adjusting the applied voltage.\nIf an electric field is applied \"away from\" the emitter instead, then most of the electrons coming from the emitter will simply be reflected back to the emitter. Only the highest energy electrons will have enough energy to reach the collector, and the height of the potential barrier in this case depends on the collector's work function, rather than the emitter's.\n\nThe current is still governed by Richardson's law. However, in this case the barrier height does not depend on \"W\". The barrier height now depends on the work function of the collector, as well as any additional applied voltages:\nwhere \"W\" is the collector's thermionic work function, \"ΔV\" is the applied collector–emitter voltage, and \"ΔV\" is the Seebeck voltage in the hot emitter (the influence of \"ΔV\" is often omitted, as it is a small contribution of order 10 mV).\nThe resulting current density \"J\" through the collector (per unit of collector area) is again given by Richardson's Law, except now\nwhere \"A\" is a Richardson-type constant that depends on the collector material but may also depend on the emitter material, and the diode geometry.\nIn this case, the dependence of \"J\" on \"T\", or on \"ΔV\", can be fitted to yield \"W\".\n\nThis retarding potential method is one of the simplest and oldest methods of measuring work functions, and is advantageous since the measured material (collector) is not required to survive high temperatures.\n\nThe photoelectric work function is the minimum photon energy required to liberate an electron from a substance, in the photoelectric effect.\nIf the photon's energy is greater than the substance's work function, photoelectric emission occurs and the electron is liberated from the surface.\nSimilar to the thermionic case described above, the liberated electrons can be extracted into a collector and produce a detectable current, if an electric field is applied into the surface of the emitter.\nExcess photon energy results in a liberated electron with non-zero kinetic energy.\nIt is expected that the minimum photon energy formula_7 required to liberate an electron (and generate a current) is \nwhere \"W\" is the work function of the emitter.\n\nPhotoelectric measurements require a great deal of care, as an incorrectly designed experimental geometry can result in an erroneous measurement of work function. This may be responsible for the large variation in work function values in scientific literature.\nMoreover, the minimum energy can be misleading in materials where there are no actual electron states at the Fermi level that are available for excitation. For example, in a semiconductor the minimum photon energy would actually correspond to the valence band edge rather than work function.\n\nOf course, the photoelectric effect may be used in the retarding mode, as with the thermionic apparatus described above. In the retarding case, the dark collector's work function is measured instead.\n\nThe Kelvin probe technique relies on the detection of an electric field (gradient in \"ϕ\") between a sample material and probe material.\nThe electric field can be varied by the voltage \"ΔV\" that is applied to the probe relative to the sample.\nIf the voltage is chosen such that the electric field is eliminated (the flat vacuum condition), then\nSince the experimenter controls and knows \"ΔV\", then finding the flat vacuum condition gives directly the work function difference between the two materials.\nThe only question is, how to detect the flat vacuum condition?\nTypically, the electric field is detected by varying the distance between the sample and probe. When the distance is changed but \"ΔV\" is held constant, a current will flow due to the change in capacitance. This current is proportional to the vacuum electric field, and so when the electric field is neutralized no current will flow.\n\nAlthough the Kelvin probe technique only measures a work function difference, it is possible to obtain an absolute work function by first calibrating the probe against a reference material (with known work function) and then using the same probe to measure a desired sample.\nThe Kelvin probe technique can be used to obtain work function maps of a surface with extremely high spatial resolution, by using a sharp tip for the probe (see Kelvin probe force microscope).\n\nBelow is a table of work function values for various elements.\nNote that the work function depends on the configurations of atoms at the surface of the material. For example, on polycrystalline silver the work function is 4.26 eV, but on silver crystals it varies for different crystal faces as (100) face: 4.64 eV, (110) face: 4.52 eV, (111) face: 4.74 eV. Ranges for typical surfaces are shown in the table below.\n\nDue to the complications described in the modelling section below, it is difficult to theoretically predict the work function with accuracy. Various trends have, however, been identified. The work function tends to be smaller for metals with an open lattice, and larger for metals in which the atoms are closely packed. It is somewhat higher on dense crystal faces than open crystal faces, also depending on surface reconstructions for the given crystal face.\n\nThe work function is not simply dependent on the \"internal vacuum level\" inside the material (i.e., its average electrostatic potential), because of the formation of an atomic-scale electric double layer at the surface. This surface electric dipole gives a jump in the electrostatic potential between the material and the vacuum.\n\nA variety of factors are responsible for the surface electric dipole. Even with a completely clean surface, the electrons can spread slightly into the vacuum, leaving behind a slightly positively charged layer of material. This primarily occurs in metals, where the bound electrons do not encounter a hard wall potential at the surface but rather a gradual ramping potential due to image charge attraction. The amount of surface dipole depends on the detailed layout of the atoms at the surface of the material, leading to the variation in work function for different crystal faces.\n\nIn a semiconductor, the work function is sensitive to the doping level at the surface of the semiconductor. Since the doping near the surface can also be controlled by electric fields, the work function of a semiconductor is also sensitive to the electric field in the vacuum.\n\nThe reason for the dependence is that, typically, the vacuum level and the conduction band edge retain a fixed spacing independent of doping. This spacing is called the electron affinity (note that this has a different meaning than the electron affinity of chemistry); in silicon for example the electron affinity is 4.05 eV. If the electron affinity \"E\" and the surface's band-referenced Fermi level \"E\"-\"E\" are known, then the work function is given by\nwhere \"E\" is taken at the surface.\n\nFrom this one might expect that by doping the bulk of the semiconductor, the work function can be tuned. In reality, however, the energies of the bands near the surface are often pinned to the Fermi level, due to the influence of surface states. If there is a large density of surface states, then the work function of the semiconductor will show a very weak dependence on doping or electric field.\n\nTheoretical modeling of the work function is difficult, as an accurate model requires a careful treatment of both electronic many body effects and surface chemistry; both of these topics are already complex in their own right.\n\nOne of the earliest successful models for metal work function trends was the jellium model, which allowed for oscillations in electronic density nearby the abrupt surface (these are similar to Friedel oscillations) as well as the tail of electron density extending outside the surface. This model showed why the density of conduction electrons (as represented by the Wigner-Seitz radius \"r\") is an important parameter in determining work function.\n\nThe jellium model is only a partial explanation, as its predictions still show significant deviation from real work functions. More recent models have focussed on including more accurate forms of electron exchange and correlation effects, as well as including the crystal face dependence (this requires the inclusion of the actual atomic lattice, something that is neglected in the jellium model).\n\nThe electron behavior in metals varies with temperature and is largely reflected by the electron work function. A recent theoretical model for predicting the temperature dependence of the electron work function, developed by Reza Rahemi et. al. explains the underlying mechanism and predicts this temperature dependence for various crystal structures via calculable and measurable parameters.\n\n\nFor a quick reference to values of work function of the elements:\n\n\"*Some of the work functions listed on these sites do not agree!*\"\n"}
