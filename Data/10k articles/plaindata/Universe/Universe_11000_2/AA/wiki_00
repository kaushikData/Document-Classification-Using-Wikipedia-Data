{"id": "41700450", "url": "https://en.wikipedia.org/wiki?curid=41700450", "title": "2010 ExxonMobil oil spill", "text": "2010 ExxonMobil oil spill\n\nOn May 1st, 2010, a ruptured ExxonMobil pipeline in the state of Akwa Ibom, Nigeria, spilled more than a million gallons into the delta. The spill had occurred at an Exxon platform some 20-25 miles (32-40 km) offshore which feeds the Qua Iboe oil export terminal. Exxon Mobil declared force majeure on Qua Iboe oil shipments due to the pipeline damage. The leakage in the Qua Iboe oil field discharged about 232 barrels of crude into the Atlantic Ocean contaminating the waters and coastal settlements in the predominantly fishing communities along Akwa Ibom and Cross River.\n\nMany locals in the region attest to environmental damage that allegedly developed as a result of the leak. Past oil spills in the delta's creeks have been left to fester for decades, polluting the air, soil, and water of impoverished communities. Nigeria sees its future output growth largely in offshore fields and does not want spills there to compound its environmental woes. Checks by Sahara Reporters revealed that the fishermen reportedly hauled in fish killed in the ExxonMobil’s oil spill in a location about 20 kilometers from the shoreline and supplied the bad fish to unsuspecting members of the public. The Nigerian Environmental Rights Action group issued a demand for N51 billion ($100 Million) from ExxonMobil in Nigeria for their failure to compensate fishermen within the coastal areas who suffered devastating losses due to the oil company’s exploration activities and major oil spills. Thick balls of tar have also been sighted washed upon the shoreline as well as oil slicks. The spill has only exacerbated the already growing problem of pollution in the Delta. The Nigerian government estimates there were over 7,000 spills, large and small, between 1970 and 2000, according to the BBC. That is approximately 300 spills a year, and some spills have been leaking for years. Vast swathes of the Delta have been seen covered with tar and stagnant lakes of crude due to oil spills of the past.\n\nExxonMobil of Nigeria was cited for the reported use of dispersants near the coast to contain the oil spill. These dispersants were considered a violation of environmental standards in the oil industry. Rev. Samuel Ayadi, Akwa Ibom State Chapter Chairman of Artisan Fishermen Association of Nigeria (ARFAN), said that ExxonMobil was in the habit of using dangerous chemical dispersants which are scientifically proven to be toxic to human and aquatic life to clean up oil spills whenever they occur. He also noted that dispersants were even more dangerous than crude oil because it breaks down the crude oil and sinks it to the sea bed where it kills fish eggs and fingerlings thereby wiping out generations of fish stock and other sea food and marine creatures that make up the food chain. \n\nFollowing the May 1 spill, protests by women and youth in the local areas disrupted oil production at Mobil facilities for two days, with reports of soldiers beating protestors, including one woman who suffered a broken leg. Those protests led to a May 20 meeting with stakeholders from the Akwa Ibom State Government, Mobil, and core host communities. Among the topics raised was “the issue of the oil company playing one community against another.”\n\n\nResearch for this Wikipedia entry was conducted as a part of a Science of Oil Spills course (EN.530.119.13) offered in the Department of Mechanical Engineering at Johns Hopkins University.\n"}
{"id": "36588783", "url": "https://en.wikipedia.org/wiki?curid=36588783", "title": "2012 India blackouts", "text": "2012 India blackouts\n\nTwo severe power blackouts affected most of northern and eastern India on 30 and 31 July 2012. The 30 July 2012 blackout affected over 300 million people and was briefly the largest power outage in history by number of people affected, beating the January 2001 blackout in Northern India (230 million affected). The blackout on 31 July is the largest power outage in history. The outage affected more than 620 million people, about 9% of the world population, or half of India's population, spread across 22 states in Northern, Eastern, and Northeast India. An estimated 32 gigawatts of generating capacity was taken offline. An article in \"The Wall Street Journal\" stated that of the affected population, 320 million initially had power, while the rest lacked direct access. Electric service was restored in the affected locations between 31 July and 1 August 2012.\n\nIndia is the world's third largest producer and consumer of electricity after the United States and China; however, the electrical infrastructure is generally considered unreliable. The northern electrical grid had previously collapsed in 2001. An estimated 27% of energy generated is lost in transmission or stolen, while peak supply falls short of demand by an average of 9%. The nation suffers from frequent power outages that last as long as 10 hours. Further, about 25% of the population, about 300 million people, have no electricity at all. Efforts are underway to reduce transmission and distribution losses and increase production.\n\nIn the summer of 2012, leading up to the failure, extreme heat had caused power use to reach record levels in New Delhi. Due to the late arrival of monsoons, agricultural areas in Punjab and Haryana drew increased power from the grid for running pumps irrigating paddy fields. The late monsoon also meant that hydropower plants were generating less than their usual production.\n\nAt 02:35 IST (21:05 UTC on 29 July), circuit breakers on the 400 kV Bina-Gwalior line tripped. As this line fed into the Agra-Bareilly transmission section, breakers at the station also tripped, and power failures cascaded through the grid. All major power stations were shut down in the affected states, causing an estimated shortage of 32 GW. Officials described the failure as \"the worst in a decade\".\n\nOn the day of the collapse, Power Minister Sushilkumar Shinde stated that the exact cause of the failure was unknown, but that at the time of the failure, electricity use was \"above normal\". He speculated that some states had attempted to draw more power than permitted due to the higher consumption. Spokesperson for PowerGrid Corporation of India Limited (PGCIL) and the Northern Regional Load Dispatch Centre (NRLDC) stated that Uttar Pradesh, Punjab and Haryana were the states responsible for the overdraw. PGCIL's chairman also stated that electrical service was restored \"at a record time\".\n\nA senior director for an Indian power company described the outage as \"a fairly large breakdown that exposed major technical faults in India's grid system. Something went terribly wrong which caused the backup safety systems to fail.\"\n\nMore than 300 million people, about 25% of India's population, were without power. Railways and some airports were shut down until 08:00. The busiest airport in South Asia, Delhi Airport, continued functioning because it switched to back-up power in 15 seconds. The outage caused \"chaos\" for Monday morning rush hour, as passenger trains were shut down and traffic signals were non-operational. Trains stalled for three to five hours. Several hospitals reported interruptions in health services, while others relied on back-up generators. Water treatment plants were shut down for several hours, and millions were unable to draw water from wells powered by electric pumps.\n\nThe Associated Chambers of Commerce and Industry of India (ASSOCHAM) stated that the blackout had \"severely impacted\" businesses, leaving many unable to operate. Oil refineries in Panipat, Mathura and Bathinda continued operating because they have their own captive power stations within the refineries and do not depend on the grid.\n\nIt took 15 hours to restore 80% of service.\n\nThe system failed again at 13:02 IST (07:32 UTC), due to a relay problem near the Taj Mahal. As a result, power stations across the affected parts of India again went offline. NTPC Ltd. stopped 38% of its generation capacity. Over 600 million people (nearly half of India's population), in 22 out of 28 states in India, were without power.\n\nMore than 300 intercity passenger trains and commuter lines were shut down as a result of the power outage. The worst affected zones in the wake of the power grid's collapse were Northern, North Central, East Central, and East Coast railway zones, with parts of Eastern, South Eastern and West Central railway zones. The Delhi Metro suspended service on all six lines, and had to evacuate passengers from trains that stopped mid-journey, helped by the Delhi Disaster Management Authority.\n\nAbout 200 miners were trapped underground in eastern India due to lifts failing, but officials later said they had all been rescued.\n\nThe National Disaster Management Authority (NDMA), not normally mandated to investigate blackouts, began to do so because of the threat to basic infrastructure facilities like railways, metro rail system, lifts in multi-storey buildings, and movement of vehicular traffic.\n\nThe following states were affected by the grid failure:\n\nThe following regions were not directly affected by the power outage:\n\nAs of 2 August, Uttar Pradesh was being supplied about 7 GW power, while the demand was between 9 and 9.7 GW.\n\nBefore the grid collapse, the private sector spent $29 billion to build their own independent power stations in order to provide reliable power to their factories. The five biggest consumers of electricity in India have private off-grid supplies. Indian companies have 35 GW of private off-grid generation capacity and plan to add another 33 GW to their off-grid capacity.\n\nSome villages that were not connected to the grid were not affected, such as Meerwada, Madhya Pradesh which had a 14 kW solar power station built by a United States-based firm for $125,000.\n\nOn the day of the collapse, Power Minister Sushilkumar Shinde ordered a three-member panel to determine the reason for the failure and report on it in fifteen days. In response to criticism, he observed that India was not alone in suffering major power outages, as blackouts had also occurred in the United States and Brazil within the previous few years.\n\n\"The Washington Post\" described the failure as adding urgency to Indian Prime Minister Dr. Manmohan Singh's plan for a US$400 billion overhaul of India's power grid. His plan calls for a further 76 gigawatts of generation by 2017, produced in part by nuclear power.\n\nRajiv Kumar, secretary general of the Federation of Indian Chambers of Commerce and Industry (FICCI) said, \"One of the major reasons for the collapse of the power grid is the major gap between demand and supply. There is an urgent need to reform the power sector and bring about infrastructural improvements to meet the new challenges of the growing economy.\"\n\nOn 1 August 2012, newly appointed Power Minister Veerappa Moily stated, \"First thing is to stabilize the grid and it has to sustain. For that we will work out a proper strategy.\" He declined to blame specific states, saying, \"I don't want to start with the blame game.\"\n\nTeam Anna, the supporters of anti-corruption activist Anna Hazare, charged that this grid failure was a conspiracy to suppress the indefinite fast movement started on 25 July 2012 for the Jan Lokpal Bill and targeting Sharad Pawar.\n\nSome technology sources and United States Agency for International Development (USAID) proposed that another widespread outage could be prevented by integrated network of microgrids and distributed generation connected seamlessly with the main grid via a superior smart grid technology, which includes automated fault detection, islanding and self-healing of the network.\n\nThe three-member investigation committee consisted of S. C. Srivastava, A. Velayutham and A. S. Bakshi, and issued its report on 16 August 2012. It concluded that four factors were responsible for the two days of blackout:\n\nThe committee also offered a number of recommendations to prevent further failures, including an audit of the protection systems.\n\n\n"}
{"id": "12948410", "url": "https://en.wikipedia.org/wiki?curid=12948410", "title": "Abell 520", "text": "Abell 520\n\nThe Abell 520 galaxy cluster possesses an unusual substructure resulting from a major merger. It has been popularly nicknamed The Train Wreck Cluster, due to its chaotic structure, and is classified as a Bautz-Morgan type III cluster. It is at a co-moving radial distance of and subtends 25 arcminutes on the sky. Analysis of the motions of 293 galaxies in the cluster field suggested that Abell 520 was a cluster forming at the crossing of three filaments of the large scale structure\n\nThe surprising substructure of Abell 520 was reported in 2007 from a weak gravitational lensing study based on Canada-France-Hawaii-Telescope (CFHT) imaging data. It was surprising because the study found the \"dark core\" with a significant amount of mass in the region, where there is no concentration of bright cluster galaxies. No conventional understanding of dark matter can explain this peculiar concentration of dark matter. One interesting interpretation is that the substructure may arise from non-gravitational interaction of dark matter.\n\nHowever, in the year 2012 two international teams of astronomers published conflicting results on Abell 520. While one study based on the Wide Field Planetary Camera 2 (WFPC2) on Hubble Space Telescope (HST) confirmed the previous claim of the dark core in Abell 520, the other study based on the Advanced Camera for Surveys (ACS) did not support the claim.\n\nIn 2014, a study of the ACS images by the original team claims to again have found evidence of a dark core, but is in a different location from the first two studies. A subsequent analysis by an independent third team of the gravitational shear catalogs of the two competing ACS analyses indicates marginal evidence for the core in both data sets and the authors \"do not consider A520 as posing a significant challenge to the collisionless dark matter scenario.\"\n\n\n"}
{"id": "32853388", "url": "https://en.wikipedia.org/wiki?curid=32853388", "title": "Arc suppression", "text": "Arc suppression\n\nArc suppression is the reduction of sparks formed when current-carrying contacts are separated. The spark is a luminous discharge of highly energized electrons and ions, and is an electric arc.\n\nThere are several possible areas of use of arc suppression methods, among them metal film deposition and sputtering, arc flash protection, electrostatic processes where electrical arcs are not desired (such as powder painting, air purification, PVDF film poling) and contact current arc suppression. In industrial, military and consumer electronic design, the latter method generally applies to devices such as electromechanical power switches, relays and contactors. In this context, arc suppression is contact protection.\n\nEvery time an electrical power device (for example: heaters, lamps, motors, transformers or similar power loads) turns on or off, its switch, relay or contactor transitions either from a closed to an open state (break arc) or from an open to a closed state (make arc & bounce arc), under load, an electrical arc occurs between the two contact points (electrodes) of the switch. The break arc is typically more energetic and thus more destructive.\n\nThe temperature of the resulting electric arc is very high (tens of thousands of degrees), causing the metal on the contact surfaces to melt, pool and migrate with the current. The high temperature of the arc cracks the surrounding gas molecules creating ozone, carbon monoxide, and other compounds. The arc energy slowly destroys the contact metal, causing some material to escape into the air as fine particulate matter. This very activity causes the material in the contacts to degrade quickly, resulting in device failure.\n\nArc suppression is an area of interest in engineering because of the destructive effects of the electrical arc to electromechanical power switches, relays and contactors’ points of contact.\n\nThe efficacy of an arc suppression solution for contact protection can be assessed, by comparing the arc intensity with the help of the following methods:\n\n\nCommon devices used to prevent arcs are capacitors, snubbers, diodes, Zener diodes, varistors, and transient voltage suppressors. Contact arc suppression solutions that are considered more effective:\n\nArc suppression techniques can produce a number of benefits: \n\n\n"}
{"id": "25349404", "url": "https://en.wikipedia.org/wiki?curid=25349404", "title": "Bartlett street lamp", "text": "Bartlett street lamp\n\nThe Bartlett street lamp was an economical type of lighting first patented and manufactured by J. W. Bartlett at 569 Broadway in Manhattan in New York City, in 1872. Bartlett claimed his street lamps cost less than a quarter of the $25 \"The New York Times\" had reported a competitor claimed they cost. The \"Times\" responded that the New York City Parks Department said that they actually paid more than that for each lamp, including the post and frame, that they used in parks, streets, and elsewhere. The city of Troy, New York used the lamps beginning in 1872 to replace older models when they wore out.\n\nAccording to Bartlett, a portion of the economy of the Bartlett street lamp was derived from the iron frames used in their construction. Other efficient qualities included a greater thickness of glass and less need for repair. Unless an object collided with a Bartlett street lamp with sufficient force, it would likely glance off of it. Likewise, drops of rain did not affect them after they were lighted. The \"Times\" disputed those contentions, saying the lamps were frequently cracked or broken. Lamplighters preferred them because they were easy to light and clean. Bartlett Street Lamps diffused light nicely, according to an advertisement.\n\nJ.W. Bartlett presented a claim for $1,796 against the Department of Public Parks of New York City, in February 1872. \nBy mid-1878 Bartlett introduced several devices which enabled lamplighting via electricity which he produced from an office at 950 Broadway. There were three inventions which each related to the other. One was an electric gas cock and lighter, which was controlled by the hand and which could be adjusted upon any gas fixture. The second was an automatic gas cock and lighter used in street lights and buildings. The third was an electric signal. As an experiment the lamps around Madison Square were fitted with automatic lighters. Each could be lighted or extinguished in a short time by placing a finger on the button of a battery at the office at 950 Broadway. Also the battery could be connected to a clock and the lights extinguished in just a moment.\n\nThe \"Railroad, Telegraph and Steamship Builders' Directory\" of 1888 lists a Bartlett Street Lamp Co., at 35 Howard Street in New York. It also mentions Bartlett Street Lamp Mfg. Co., at 42 College Place in New York.\n"}
{"id": "41788329", "url": "https://en.wikipedia.org/wiki?curid=41788329", "title": "Beduhe Dam", "text": "Beduhe Dam\n\nThe Beduhe Dam is a concrete-face rock-fill dam currently under construction near Kani Mase in Dohuk Province, Iraq. The foundation stone for the dam was laid on 18 February 2010.\n\n"}
{"id": "22950413", "url": "https://en.wikipedia.org/wiki?curid=22950413", "title": "Blue Gold: World Water Wars", "text": "Blue Gold: World Water Wars\n\nBlue Gold: World Water Wars is a 2008 documentary film directed, co-produced, and co-written by Sam Bozzo, based on the book \"Blue Gold: The Fight to Stop the Corporate Theft of the World’s Water\" by Maude Barlow and Tony Clarke.\n\nIt was produced by Mark Achbar and Si Litvinoff and was narrated by Malcolm McDowell. The film was first screened on October 9, 2008, at the Vancouver International Film Festival.\n\n\"Blue Gold: World Water Wars\" examines environmental and political implications of the planet's dwindling water supply, and posits that wars in the future will be fought over water. The film also highlights some success stories of water activists around the world.\n\n\n\n"}
{"id": "5138094", "url": "https://en.wikipedia.org/wiki?curid=5138094", "title": "Bunter (geology)", "text": "Bunter (geology)\n\nBunter Pebble Beds are sandstone deposits containing rounded pebbles. They can be found in Warwickshire, Cheshire, Staffordshire, Nottinghamshire, Yorkshire, Devon and Dorset in England. They are thought to be alluvial deposits and, judging from the rounding of the mainly quartzite pebbles, to have resulted from prolonged transportation in a large and turbulent river, resulting in powerful abrasion. The deposits in the English Midlands are thought to have been transported in this way northwards from Brittany, France. This supposed river has been called the \"Budleighensis\", after the Devon village of Budleigh Salterton, a site where such deposits were discovered. The depositions took place in the lower Triassic period. Some newer conglomerates, e.g. near Ryton in Warwickshire, are thought to have arisen during the Ice Age by reworking and southward transportation of older deposits by ice flows.\n\nThe pebbles, also called cobbles, which can be used as gravel, as ballast or as cobblestones, are mainly milky-white quartzite but can vary in colour and composition, including some that are hard, reddish-coloured sandstone. The sandstone in which these pebbles are deposited can be used for building or as an aggregate for cement or concrete.\n\nThe name \"Bunter\" derives from the German term \"Buntsandstein\", \"bunt\" meaning \"variegated\" or \"colourful\", referring to the colour of the sandstone deposit, which varies from reddish to greenish. This sandstone is widespread across central Europe, notably in the Black Forest and Odenwald region of Germany, as well as the Vosges Mountains in northeastern France.\n\nThe sandstone can be hard enough for building, yet easy enough to \"work\", resulting in bridges, castles, cathedrals and churches constructed of reddish sandstone, throughout the relevant areas of Europe (e.g. Germany, Luxembourg, Switzerland, Alsace in France, Denmark, Poland). The land under which these beds lie is generally very well drained, creating heathlike conditions. Because of the drainage, the soil tends to be of low fertility. A notable area in Britain that has these characteristics is Cannock Chase, a designated Area of Outstanding Natural Beauty (AONB).\n\nThe long shingle tombolo of Chesil Beach in Dorset and the raised beach of Portland, Dorset are partly composed of Bunter pebbles. As yet, no fully satisfactory and universally accepted geological explanation has been formulated to explain their precise origin and mode of transport, as each proposed theory has its difficulties.\n"}
{"id": "30808450", "url": "https://en.wikipedia.org/wiki?curid=30808450", "title": "Cartridge heater", "text": "Cartridge heater\n\nA cartridge heater is a tube-shaped, heavy-duty, industrial Joule heating element used in the process heating industry, usually custom manufactured to a specific watt density, based on its intended application. Compact designs are capable of reaching a watt density of up to 50W/cm².\n\nCartridge heaters are found useful in many applications, such as:\n\n\nConstruction of a cartridge heater may be divided in 7 main parts:\n\nThe heating coil is the actual resistance which is where the electrical load occurs. The most common type of metal alloy used for this purpose is a nickel-chromium mixture, also known as nichrome. The nichrome wire is wound around a ceramic core, and the number of spirals per inch vary according to the requested watt density. Potential from an alternating current source, which can either be 2 phase or 3 phase, flows through the coiled nichrome wire, heating up the wire, which in turn, heats the cartridge heater sheath.\n\nInsulation is used to prevent the nichrome coil contacting the sheath, an event that would ground the resistance and could produce a catastrophic short-circuit, resulting in a melted sheath and a major equipment failure. Damage can be mitigated by installing a ground fault interrupting circuit. To prevent the coil from touching the sheath, the coil is inserted into the sheath, and immediately filled with magnesium oxide (MgO). To ensure the MgO fills the empty space between the sheath and the coil, the cartridge heater is filled under vibration.\n\nThe sheath is the part of the cartridge heater which makes contact with the material or substance to be heated. Several metal alloys are used, depending on the type of application, such as highly acidic or corrosive environments. The most common types of sheaths are 304 stainless steel, 316 stainless steel, and incoloy 800. Incoloy has the highest temperature rating, and is considered a superalloy.\n\nAfter the cartridge heater has been filled with MgO, a seal is applied to the open end of the cartridge heater (where the nichrome coil was introduced). This prevents the coil and the MgO from coming out, as well as preventing contaminants such as plastic debris, air, or moisture from entering the heater.\n\nSince cartridge heaters are installed in a wide variety of machines, manufacturers must design the heaters to meet certain clearances. [dead link] The cartridge heaters might be terminated with the leads coming out straight, or in a right angle. Also, manufacturers must be careful that the leads are not exposed to temperatures higher than the maximum rating for the lead wire. In order to prevent lead wire damage from temperature, movement or contamination, the lead wire can be protected with a metal conduit, braided metal or silicone sleeves.\n\nDepending on the clearance and the design of the machine where the cartridge heater will be inserted, the type of wire used will vary. Fiberglass is the commonly used for cartridge heaters and other high-temperature applications, such as automotive wiring harnesses and industrial equipment. Other variants used are silicone impregnated fiberglass and silicone rubber.\n\nhttp://www.gimido.com/\n\n"}
{"id": "79533", "url": "https://en.wikipedia.org/wiki?curid=79533", "title": "Centaur (rocket stage)", "text": "Centaur (rocket stage)\n\nCentaur has been designed to be the upper stage of space launch vehicles and is used on the Atlas V. Centaur was the world's first high-energy upper stage, burning liquid hydrogen (LH2) and liquid oxygen (LOX). Centaur has enabled the launch of some of NASA's most important scientific missions during its 50-year history.\n\nCentaur was the brainchild of Convair employees Karel Bossart (the man behind the SM-65 Atlas, an intercontinental ballistic missile (ICBM)), and Krafft Arnold Ehricke. Their design was essentially a smaller version of the Atlas, adopting its use of lightweight \"stainless steel balloon\" tanks whose structural rigidity was provided solely by the pressure of the propellants within. To keep the tanks from collapsing before the propellant was loaded, they were either kept in \"stretch\" or pressurized with nitrogen gas.\n\nExisting Centaur stages are powered by one (Single Engine Centaur variant) or two (Double Engine Centaur variant) RL10 rocket engines. The upcoming Centaur V will be powered by four RL10 engines.\n\nIn 1956, Krafft Arnold Ehricke of Convair began studying an LH2 upper stage rocket. The ensuing project began in 1958 as a joint venture among Convair, the Advanced Research Projects Agency (ARPA), and the U.S. Air Force. In 1959, NASA assumed ARPA's role. \n\nThe Centaur was originally designed for use with the Atlas launch vehicle family, which shared its balloon structure. Known in early planning as the \"high-energy upper stage\", its eventual name was proposed by Ehricke, who was directing its development for General Dynamics. In recognition of the mythological half-man-half-horse Centaur, the horse portion represented the \"workhorse\" Atlas as the \"brawn\" of the launch vehicle, while the man represented the \"brain\" of the combination in the Centaur.\n\nCentaur was considered essential for both launching the Surveyor probes and proving the viability of LH2 as a high energy fuel. Both were important to the Apollo program. The Surveyor probes were tasked with studying the lunar regolith and confirming the feasibility of crewed landings. LH2 had been selected as the ideal propellant for the Saturn I, IB, and V upper stages.\n\nInitial Atlas-Centaur launches used developmental versions, labeled Centaur-A through -C. The first launch on May 8, 1962, ended in an explosion 54 seconds after launch when insulation panels on the Centaur failed and caused the LH2 tank to rupture. After extensive redesigns, the next test on November 26, 1963, was successful.\n\nOn May 30, 1966, an Atlas-Centaur boosted the first Surveyor lander towards the Moon. The soft landing of \"Surveyor 1\" in the Ocean of Storms was NASA's first landing on any extraterrestrial body. \n\nBy the end of 1989, the Centaur-D had been used as the upper stage for 63 Atlas rocket launches, 55 of which were successful.\n\nThe Centaur stage was mated with the far more powerful Titan III booster in 1974, producing the Titan IIIE or Titan III-Centaur, with more than triple the payload capacity of Atlas-Centaur. This version of Centaur featured improved thermal insulation, allowing it to coast for five hours in orbit, up from the Atlas-Centaur's 30 minute maximum.\n\nThe first launch of Titan-Centaur in February 1974 was unsuccessful, with Centaur's engines failing to ignite after separation from the Titan booster. Without power, the Centaur was ordered to self-destruct by a range safety command. The original plan was to carry a simulated mockup of the $1 billion Viking probe to be launched the following year. The \"Space Plasma High Voltage Experiment (SPHINX)\", which would have studied the interaction between spacecraft and high energy plasma, was instead added as a secondary payload and was destroyed. It was eventually determined that Centaur's engines had ingested an incorrectly installed clip from the oxygen tank.\n\nThe next Titan-Centaur flew in December 1974 and carried the joint West German-American \"Helios 1\" probe to study the sun at close range. The West Germans were concerned that NASA was using the Helios launch as a second test flight of Titan/Centaur in preparation for the upcoming Viking missions. This concern gained believability when the Helios launch used an unnecessary two-burn profile, presumably a rehearsal for the Viking launch that needed the two burns. Centaur completed a further two burns after separation, proving the stage's in-space multi-restart capability.\n\nIn 1975, Titan-Centaur launched the \"Viking 1\" and \"Viking 2\" spacecraft to Mars. The original plan was to launch them on Saturn V rockets as the Vikings were the most massive interplanetary missions to date, with each including an orbiter and a lander. These missions were highly successful, with the \"Viking 1\" lander operating until 1982, and were the only NASA missions to study Mars until the \"Mars Global Surveyor\" was launched in 1996.\n\nThese launches were followed by the 1976 launch of \"Helios 2\", another West German-U.S. solar probe that flew closer to the Sun than \"Helios 1\". \"Helios 2\" still holds the record for the highest speed of any spacecraft, with a heliocentric velocity of at its closest approach to the Sun.\n\nThe Titan-Centaur's next two launches were the \"Voyager 1\" and \"Voyager 2\" spacecraft. \"Voyager 1\" visited Jupiter and Saturn. \"Voyager 2\" completed the \"Grand Tour\" of the outer planets by visiting Jupiter, Saturn, Uranus, and Neptune. A once-in-175-years alignment of those planets allowed gravitational assists to boost the probe from one planet to the next. \"Voyager 2\" was launched on August 20, 1977, followed 16 days later by \"Voyager 1\". \"Voyager 2\" is still the only spacecraft to have visited Uranus and Neptune. \"Voyager 1\" is the first spacecraft to have entered interstellar space. While the Titan-Centaur that launched \"Voyager 2\" performed flawlessly, the Titan booster used to launch \"Voyager 1\" had a hardware problem that caused a premature shutdown. The Centaur stage detected and successfully compensated for this problem, although Centaur ended its burn with less than 4 seconds of fuel remaining. This was the final launch of the Titan IIIE-Centaur.\n\nWith the introduction of the Space Shuttle, NASA and the Air Force needed an upper stage to boost shuttle payloads out of low Earth orbit. The Centaur-G was developed for this purpose, with both \"Challenger\" and \"Discovery\" being modified to carry the stage. To enable its installation in shuttle payload bays, the diameter of the Centaur-G's hydrogen tank was increased to . The diameter of its oxygen tank, however, remained at . During its first mission on May 16, 1986, a Centaur-G was to have boosted the \"Galileo\" probe towards Jupiter. Just six days later, another Centaur-G would have boosted the \"Ulysses\" probe towards Jupiter where it eventually - with an IUS - used the planet's gravity to reach a highly inclined solar orbit to observe the Sun's polar regions. A shortened version of the Centaur-G was planned to be used on shuttles carrying payloads for the U.S. Department of Defense and for boosting the \"Magellan\" probe to Venus.\n\nDuring the development of the shuttle in the 1970s, NASA debated whether to use a solid-fueled Inertial Upper Stage (IUS) instead of a Centaur. An IUS was much lighter and safer than a Centaur. NASA was concerned, however, that the rough starting and extremely fast acceleration of a solid rocket motor could damage payloads. Unlike a Centaur, an IUS could not be turned off once ignited. In addition, an IUS would have a lower thrust than a Centaur, which meant that a shuttle would have to carry less complex payloads. However, the presence of several tons of volatile liquid hydrogen and oxygen on a shuttle was concerning, especially because no Centaur had been designed as a human-rated vehicle and lacked the safety features of both a shuttle and a Saturn upper stage. NASA was especially worried about a shuttle having to make an emergency landing with a fully fueled Centaur in its payload bay. The Centaur's weight would exceed the design capacity of the shuttle's landing gear, and there was no safe and reliable method for dumping the Centaur's fuel before the shuttle landed. In its favor, the Centaur had an excellent reliability record in recent years. As of April 1981, when the first shuttle flight occurred, a Centaur had failed to operate only twice in the 35 launches during the previous decade. Still, several astronauts were wary about flying a shuttle with a Centaur in its payload bay, and a few flat-out refused to do it. Ultimately, NASA decided that shuttles could carry Centaurs. Their superior performance and smoother engine starts versus an IUS were too important to disregard. Additionally, the Air Force needed a Centaur's extra power to launch its satellites during classified military shuttle missions. Another important factor was that the Titan-Centaur launch vehicle was the only alternative for planetary missions. The problem was that the Air Force controlled those vehicles, and two decades of those entities sharing a launch vehicle had proven that bad blood always resulted.\n\nA Centaur, when carried in the shuttle payload bay, needs a complex airborne support system, known as the Centaur Integrated Support System (CISS). The CISS controls Centaur pressurization in flight and enables Centaur's cryogenic propellants to be dumped overboard quickly in the event of an abort. Shuttle-Centaur flights would have needed the shuttle's main engines to run at 109 percent instead of the typical 104 percent, and the Shuttle would have had to orbit at its lowest possible altitude.\n\nAfter the \"Challenger\" accident, and just months before the Shuttle-Centaur was scheduled to fly, NASA concluded that it was far too risky to fly the Centaur on the Shuttle. \"Galileo\", \"Ulysses\", and \"Magellan\" were boosted by the much less powerful solid-fueled IUS, with \"Galileo\" needing multiple gravitational assists from Venus and Earth to reach Jupiter.\n\nTermination of the Shuttle-Centaur program spurred the Air Force to create the Titan IV. In the 401A/B versions, the Centaur-T was used as its final stage. The diameter of its hydrogen tank was . This vehicle was capable of launching the same payloads as the Shuttle-Centaur combination. In the Titan 401A version, a Centaur-T was launched nine times between 1994 and 1998. Titan-Centaur launched the \"Cassini-Huygens\" probe to Saturn in 1997 on the debut flight of the Titan 401B, which launched an additional six times, with one failure. The last flight of the Titan IV/Centaur was in 2003\n\nBoth versions of Atlas III used Centaur variants. Atlas IIIA used the Centaur II upper stage, developed for the Atlas II series. Atlas IIIB used a new version, Common Centaur.\n\nThe Atlas V rocket currently uses the Common Centaur variant. In 2014, on the NROL-35 mission, Atlas V's Common Centaur first flew in a reengined configuration with an RL10-C-1 replacing its previous RL10-A-4-2. This engine is meant to be common between Centaur and the Delta Cryogenic Second Stage to reduce costs. RL10-A-4-2 will continue to be used on some future flights. Atlas V launches using the Dual Engine Centaur configuration must use RL10-A-4-2 because the new engine is too wide to accommodate two side-by-side. To date, all Atlas V launches have used the Single Engine Centaur variant, however CST-100 Starliner and Dream Chaser missions will require the dual engine variant, because it allows a \"flatter\" trajectory which is safer for aborts.\n\nAs on Titan-Centaur, Atlas V 500 launches encapsulate the upper stage inside the payload fairing, to reduce aerodynamic loads. Atlas V 400 flights carry the fairing on top of Centaur, exposing it to the air.\n\nThe new Vulcan launch vehicle currently being developed by United Launch Alliance will initially fly with an upgraded variant of the Common Centaur stage flown on Atlas V known as Centaur V, before later upgrading to the new \"Advanced Cryogenic Evolved Stage\", which will include the Integrated Vehicle Fluids technology to allow long on-orbit life of the upper stage measured in weeks rather than hours.\nWhen the new ULA successor to the Atlas V was initially announced in 2015, it was slated to initially use a Centaur upper stage, but no mention was made at that time about an upgrade to a newer version.\n\nCentaur uses so-called \"balloon tanks\", made of stainless steel so thin they cannot support their own weight without pressurization. This tank design, with walls as thin as , allowed for an extremely high ratio of fuel to dry mass, maximizing the stage's performance. It uses a common double-bulkhead to separate the LOX and LH2 tanks. The two stainless steel skins are separated by a 0.25 inch (6.4 mm) layer of fiberglass honeycomb. The extreme cold of the LH2 on one side creates a vacuum within the fiberglass layer, decreasing the bulkhead's thermal conductivity, and thus reducing heat transfer from the relatively warm LOX to the super cold LH2.\n\nAttitude control and ullage are provided by means of hydrazine monopropellant thrusters located around the stage. There are two 2-thruster pods and four 4-thruster pods, sixteen in total, fed from a pair of bladder tanks carrying 340 pounds of hydrazine. Tank pressurization, as well as some engine functions, use helium gas. The main propulsion system consists of one or two RL10 engines. These engines can be restarted multiple times, given sufficient power, helium, and ullage propellant, allowing Centaur to perform complex orbital insertions and deorbit burns.\n\nCommon Centaur, on Atlas V, can accommodate secondary payloads using its Aft Bulkhead Carrier, a mounting fixture on the rear end of the stage, near the engine.\n\nCentaur-D was the first Centaur version to enter operational service.\n\nCentaur II was initially developed for use on the Atlas II series of rockets. It was also used on the Atlas IIIA.\n\nIn late 2017, ULA decided to bring elements of the ACES upper stage forward and begin work on Centaur V. This upper stage would be expanded to the same -diameter of Vulcan core, using a cluster of four LH2/LOX engines (BE-3U or RL-10), but not include the Integrated Vehicle Fluids (IVF) feature expected with ACES.\nBringing critical items from ACES to Centaur V, at this time, is expected to increase the lift capacity of the first generation Vulcan, so it can carry planned national security payloads. Centaur V would permit ULA to retire both the Atlas V and Delta IV rocket families on a faster schedule.\n\nBy March 2018, ULA had begun to publicly refer to the new Vulcan first stage with the Centaur V second stage as the \"Vulcan Centaur\".\n\nIn May 2018 United Launch Alliance (ULA) announced that Aerojet Rocketdyne RL10 upper stage engine was selected for ULA’s next-generation Vulcan Centaur rocket following a competitive procurement process.\n\n, derivatives of the Centaur-3, with one RL-10A4-2 engine, continue to be used as the upper stage of the Atlas V EELV rocket. There is an option to fly the Atlas V with a two engined Centaur, which is planned to be used for manned launches with the CST-100 Starliner and Dream Chaser.\n\nUnited Launch Alliance (ULA) had been working on an upper stage design concept that would bring the Delta and Centaur stages together into a single new cryogenic second stage design, called the Advanced Common Evolved Stage, was originally intended as a lower-cost, more-capable and more-flexible upper stage that would supplement, and perhaps replace, the existing ULA (Lockheed Martin legacy) Centaur and the ULA (Boeing legacy) Delta Cryogenic Second Stage (DCSS) upper stage vehicles. ACES design conceptualization has been underway at ULA for many years, and leverages design features of both the Centaur and Delta Cryogenic Second Stage (DCSS) upper stages. With the decision to discontinue both the Delta IV and Atlas V lines by the 2020s, ULA also abandoned work on replacing their upper stages. ACES will continue to be developed, and will be deployed on Vulcan.\n\nAlthough Centaur has a long and successful history in planetary exploration, it has had its share of problems, especially early on:\n\nPerformance levels for a planned Evolved Centaur based Phase 1 vehicles envelope all Atlas V capabilities. In certain circumstances a single Atlas booster vehicle with five solids and with an evolved Centaur upper-stage can replace a three-booster core Atlas V-Heavy (HLV). This has obvious reliability and cost benefits. Phase 2 vehicles open the door to a vastly higher performance capability. Up to 80 metric tons can be lifted to low earth orbit on a Phase 2 HLV vehicle — a substantial fraction of a Saturn V or SLS vehicle. This performance level, mandated only by NASA crewed exploration missions, can be achieved using hardware identical to that used for traditional commercial and USG missions thus allowing development and support costs to be diluted by rate.\n\nStudies have been conducted showing the extensibility of the basic Centaur and Evolved Centaur designs to long duration space flight for exploration purposes and even for use as a Lunar Lander. Complementing these basic performance capabilities is the ability to rate the vehicle for crewed operation. Extensive work has been conducted showing that achieving this \"man-rating\" is straightforward and does not mandate wholesale design changes to the Centaur vehicle.\n\nBy 2006, Lockheed Martin Space Systems had described the ability to use existing Centaur hardware, with little modification, as a test bed for in-space cryogenic fluid management techniques. Most Centaurs launched on Atlas have excess propellants, ranging from hundreds to thousands of pounds, which could be used for \"rideshare\" experiments flown as secondary payloads conducted after separation of the primary spacecraft.\n\nIn October 2009, the Air Force and United Launch Alliance (ULA) performed an experimental on-orbit demonstration on a modified Centaur upper stage on the DMSP-18 launch to improve \"understanding of propellant settling and slosh, pressure control, RL10 chilldown and RL10 two-phase shutdown operations. \"The light weight of DMSP-18 allowed of remaining LO and LH propellant, 28% of Centaur’s capacity,\" for the on-orbit demonstrations. The post-spacecraft mission extension ran 2.4 hours before executing the deorbit burn. The initial mission demonstration in 2009 was preparatory to the more-advanced cryogenic fluid management experiments planned for the Centaur-based CRYOTE technology development program in 2012–2014 and to a higher-TRL design for the Advanced Common Evolved Stage Centaur successor.\n\nSource: Atlas V551 Specifications.\n"}
{"id": "37097881", "url": "https://en.wikipedia.org/wiki?curid=37097881", "title": "Chandrapur–Padghe HVDC transmission system", "text": "Chandrapur–Padghe HVDC transmission system\n\nThe Chandrapur–Padghe HVDC transmission system is an HVDC connection between Chandrapur and Padghe (near Mumbai) in the state of Maharashtra in India, which was put into service in 1999.\n\nIt connects the coal-fired Chandrapur Super Thermal Power Station to the major load centre of Mumbai. The project has a long bipolar overhead line. The transmission voltage is ±500 kV and the maximum transmission power is 1,500 megawatts. The scheme uses thyristor valves, arranged in a single twelve pulse bridge per pole. The project was built by ABB and BHEL, and is owned by Maharashtra State Electricity Board (MSEB).\n\nThe eastern (Chandrapur) converter station is located from the Chandrapur back to back HVDC station. The close proximity of the two converter stations meant that the control systems needed to be carefully coordinated, a task made more challenging by the fact that the two stations were built by different manufacturers. To address this problem a series of joint simulation studies, involving the control equipment from both converter stations connected to a common simulator, was performed.\n\n\n"}
{"id": "22482833", "url": "https://en.wikipedia.org/wiki?curid=22482833", "title": "Clouds of Smoke", "text": "Clouds of Smoke\n\nClouds of Smoke is a documentary directed and produced by Fatmir Terziu. It explores the recent phenomenon of global warming and asks several environmental questions. It mainly focuses on the environmental damage caused by Albania, especially its biggest industrial city, Elbasan. The documentary started as a collaboration with Department for Environment, Food and Rural Affairs (DEFRA), and it was created for the purpose of educating students at London South Bank University. It was chosen to be shown at Curzon, London, the first documentary directed by an Albanian director to be selected.\n\nFatmir Terziu's blog article \"Making \"Clouds of Smoke\"\"\n"}
{"id": "3949010", "url": "https://en.wikipedia.org/wiki?curid=3949010", "title": "Cyclic compound", "text": "Cyclic compound\n\nA cyclic compound (\"ring compound\") is a term for a compound in the field of chemistry in which one or more series of atoms in the compound is connected to form a ring. Rings may vary in size from three to many atoms, and include examples where all the atoms are carbon (i.e., are carbocycles), none of the atoms are carbon (inorganic cyclic compounds), or where both carbon and non-carbon atoms are present (heterocyclic compounds). Depending on the ring size, the bond order of the individual links between ring atoms, and their arrangements within the rings, carbocyclic and heterocyclic compounds may be aromatic or non-aromatic, in the latter case, they may vary from being fully saturated to having varying numbers of multiple bonds between the ring atoms. Because of the tremendous diversity allowed, in combination, by the valences of common atoms and their ability to form rings, the number of possible cyclic structures, even of small size (e.g., <17 total atoms) numbers in the many billions. \n\nAdding to their complexity and number, closing of atoms into rings may lock particular atoms with distinct substitution (by functional groups) such that stereochemistry and chirality of the compound results, including some manifestations that are unique to rings (e.g., configurational isomers). As well, depending on ring size, the three-dimensional shapes of particular cyclic structures—typically rings of 5-atoms and larger—can vary and interconvert such that conformational isomerism is displayed. Indeed, the development of this important chemical concept arose, historically, in reference to cyclic compounds. Finally, cyclic compounds, because of the unique shapes, reactivities, properties, and bioactivities that they engender, are the largest majority of all molecules involved in the biochemistry, structure, and function of living organisms, and in the man-made molecules (e.g., drugs, herbicides, etc.).\n\nA \"cyclic compound or ring compound\" is a compound at least some of whose atoms are connected to form a ring. Rings vary in size from 3 to many tens or even hundreds of atoms. Examples of ring compounds readily include cases where:\n\nCommon atoms can (as a result of their valences) form varying numbers of bonds, and many common atoms readily form rings. In addition, depending on the ring size, the bond order of the individual links between ring atoms, and their arrangements within the rings, cyclic compounds may be aromatic or non-aromatic; in the case of non-aromatic cyclic compounds, they may vary from being fully saturated to having varying numbers of multiple bonds. As a consequence of the constitutional variability that is thermodynamically possible in cyclic structures, the number of possible cyclic structures, even of small size (e.g., <17 atoms) numbers in the many billions.\n\nMoreover, the closing of atoms into rings may lock particular functional group–substituted atoms into place, resulting in stereochemistry and chirality being associated with the compound, including some manifestations that are unique to rings (e.g., configurational isomers); As well, depending on ring size, the three-dimensional shapes of particular cyclic structures—typically rings of 5-atoms and larger—can vary and interconvert such that conformational isomerism is displayed.\n\nIUPAC nomenclature has extensive rules to cover the naming of cyclic structures, both as core structures, and as substituents appended to alicyclic structures. The term macrocycle is used when a ring-containing compound has a ring of 8 or more atoms. The term polycyclic is used when more than one ring appears in a single molecule. Naphthalene is formally a polycyclic, but is more specifically named as a bicyclic compound. Several examples of macrocyclic and polycyclic structures are given in the final gallery below.\nThe atoms that are part of the ring structure are called annular atoms.\n\nThe vast majority of cyclic compounds are organic, and of these, a significant and conceptually important portion are composed of rings made only of carbon atoms (i.e., they are carbocycles).\n\nInorganic atoms form cyclic compounds as well. Examples include sulfur, silicon (e.g., in silanes), phosphorus (e.g., in phosphanes and phosphoric acid variants), and boron (e.g., in triboric acid). When carbon in benzene is \"replaced\" by other elements, e.g., as in borabenzene, silabenzene, germanabenzene, stannabenzene, and phosphorine, aromaticity is retained, and so aromatic inorganic cyclic compounds are known and well-characterized.\n\nCyclic compounds that have both carbon and non-carbon atoms present are termed (heterocyclic compounds); alternatively the name can refer to inorganic cyclic compounds, such as siloxanes and borazines, that have more than one type of atom in their rings. Hantzsch–Widman nomenclature is recommended by the IUPAC for naming heterocycles, but many common names remain in regular use.\n\nCyclic compounds may or may not exhibit aromaticity; benzene is an example of an aromatic cyclic compound, while cyclohexane is non-aromatic. In organic chemistry, the term aromaticity is used to describe a cyclic (ring-shaped), planar (flat) molecule that exhibits unusual stability as compared to other geometric or connective arrangements of the same set of atoms. As a result of their stability, it is very difficult to cause aromatic molecules to break apart and to react with other substances. Organic compounds that are not aromatic are classified as aliphatic compounds—they might be cyclic, but only aromatic rings have especial stability (low reactivity).\n\nSince one of the most commonly encountered aromatic systems of compounds in organic chemistry is based on derivatives of the prototypical aromatic compound benzene (an aromatic hydrocarbon common in petroleum and its distillates), the word “aromatic” is occasionally used to refer informally to benzene derivatives, and this is how it was first defined. Nevertheless, many non-benzene aromatic compounds exist. In living organisms, for example, the most common aromatic rings are the double-ringed bases in RNA and DNA. A functional group or other substituent that is aromatic is called an aryl group.\n\nThe earliest use of the term “aromatic” was in an article by August Wilhelm Hofmann in 1855.[1] Hofmann used the term for a class of benzene compounds, many of which do have odors (aromas), unlike pure saturated hydrocarbons. Today, there is no general relationship between aromaticity as a chemical property and the olfactory properties of such compounds (how they smell), although in 1855, before the structure of benzene or organic compounds was understood, chemists like Hofmann were beginning to understand that odiferous molecules from plants, such as terpenes, had chemical properties we recognize today are similar to unsaturated petroleum hydrocarbons like benzene.\n\nIn terms of the electronic nature of the molecule, aromaticity describes a conjugated system often made of alternating single and double bonds in a ring. This configuration allows for the electrons in the molecule’s pi system to be delocalized around the ring, increasing the molecule's stability. The molecule cannot be represented by one structure, but rather a resonance hybrid of different structures, such as with the two resonance structures of benzene. These molecules cannot be found in either one of these representations, with the longer single bonds in one location and the shorter double bond in another (See Theory below). Rather, the molecule exhibits bond lengths in between those of single and double bonds. This commonly seen model of aromatic rings, namely the idea that benzene was formed from a six-membered carbon ring with alternating single and double bonds (cyclohexatriene), was developed by August Kekulé (see History section below). The model for benzene consists of two resonance forms, which corresponds to the double and single bonds superimposing to produce six one-and-a-half bonds. Benzene is a more stable molecule than would be expected without accounting for charge delocalization.\n\nThe following are examples of simple and aromatic carbocycles, inorganic cyclic compounds, and heterocycles:\n\nThe closing of atoms into rings may lock particular atoms with distinct substitution by functional groups such that the result is stereochemistry and chirality of the compound, including some manifestations that are unique to rings (e.g., configurational isomers).\n\nDepending on ring size, the three-dimensional shapes of particular cyclic structures—typically rings of 5-atoms and larger—can vary and interconvert such that conformational isomerism is displayed. Indeed, the development of this important chemical concept arose, historically, in reference to cyclic compounds. For instance, cyclohexanes—six membered carbocycles with no double bonds, to which various substituents might be attached, see image—display an equilibrium between two conformations, the \"chair\" and the \"boat,\" as shown in the image.\n\nThe chair conformation is the favored configuration, because in this conformation, the steric strain, eclipsing strain, and angle strain that are otherwise possible are minimized. Which of the \"possible\" chair conformations predominate in cyclohexanes bearing one or more substituents depends on the substiuents, and where they are located on the ring; generally, \"bulky\" substituents—those groups with large \"volumes,\" or groups that are otherwise repulsive in their interactions—prefer to occupy an equatorial location. An example of interactions within a molecule that would lead to steric strain, leading to a shift in equilibrium from boat to chair, is the interaction between the two methyl groups in \"cis\"-1,4-dimethylcyclohexane. In this molecule, the two methyl groups are in opposing positions of the ring (1,4-), and their \"cis\" stereochemistry projects both of these groups toward the same side of the ring. Hence, if forced into the higher energy boat form, these methyl groups are in steric contact, repel one another, and drive the equilibrium toward the chair conformation.\n\nThe term macrocycle is used for compounds having a rings of 8 or more atoms. Macrocycles may be fully carbocyclic, heterocyclic but having limited heteroatoms (e.g., in lactones and lactams), or be rich in heteroatoms and displaying significant symmetry (e.g., in the case of chelating macrocycles). Macrocycles can access a number of stable conformations, with preference to reside in conformations that minimize transannular nonbonded interactions within the ring (e.g., with the chair and chair-boat being more stable than the boat-boat conformation for cyclooctane, because of the interactions depicted by the arcs shown). Medium rings (8-11 atoms) are the most strained, with between 9-13 (kcal/mol) strain energy, and analysis of factors important in the conformations of larger macrocycles can be modeled using medium ring conformations. Conformational analysis of odd-membered rings suggests they tend to reside in less symmetrical forms with smaller energy differences between stable conformations.\n\nBecause of the unique shapes, reactivities, properties, and bioactivities that they engender, cyclic compounds are the largest majority of all molecules involved in the biochemistry, structure, and function of living organisms, and in the man-made molecules (e.g., drugs, herbicides, etc.) through which man attempts to exert control over nature and biological systems.\n\nThe following are examples of cyclic compounds exhibiting more complex ring systems and stereochemical features:\nThere are a variety of specialized reactions whose use is solely the formation of rings, and these will be discussed below. In addition to those, there are a wide variety of \"general\" organic reactions that historically have been crucial in the development, first, of understanding the concepts of ring chemistry, and second, of reliable procedures for preparing ring structures in high yield, and with defined orientation of ring substituents (i.e., defined stereochemistry). These general reactions include:\n\nIn organic chemistry, a variety of synthetic procures are particularly useful in closing carbocyclic and other rings; these are termed \"ring-closing reactions\". Examples include:\n\nA variety of further synthetic procedures are particularly useful in opening carbocyclic and other rings, generally which contain a double bound or other functional group \"handle\" to facilitate chemistry; these are termed \"ring-opening reactions\". Examples include:\n\n\n\n"}
{"id": "18111385", "url": "https://en.wikipedia.org/wiki?curid=18111385", "title": "Dihydrogen cation", "text": "Dihydrogen cation\n\nThe hydrogen molecular ion, dihydrogen cation, or , is the simplest molecular ion. It is composed of two positively charged protons and one negatively charged electron, and can be formed from ionization of a neutral hydrogen molecule. It is of great historical and theoretical interest because, having only one electron, the electronic Schrödinger equation for the system (in the clamped-nuclei approximation) can be solved in a relatively straightforward way due to the lack of electron–electron repulsion (electron correlation). The analytical solutions for the electronic energy eigenvalues are a \"generalization\" of the Lambert W function which can be obtained using a computer algebra system within an experimental mathematics approach. Consequently, it is included as an example in most quantum chemistry textbooks.\n\nThe first successful quantum mechanical treatment of was published by the Danish physicist Øyvind Burrau in 1927, just one year after the publication of wave mechanics by Erwin Schrödinger. Earlier attempts using the old quantum theory had been published in 1922 by Karel Niessen and Wolfgang Pauli, and in 1925 by Harold Urey. In 1928, Linus Pauling published a review putting together the work of Burrau with the work of Walter Heitler and Fritz London on the hydrogen molecule.\n\nBonding in can be described as a covalent one-electron bond, which has a formal bond order of one half.\n\nThe ion is commonly formed in molecular clouds in space, and is important in the chemistry of the interstellar medium.\n\nThe electronic Schrödinger wave equation for the hydrogen molecular ion with two fixed nuclear centers, labeled \"A\" and \"B\", and one electron can be written as\nwhere \"V\" is the electron-nuclear Coulomb potential energy function:\nand \"E\" is the (electronic) energy of a given quantum mechanical state (eigenstate), with the electronic state function \"ψ\" = \"ψ\"(r) depending on the spatial coordinates of the electron. An additive term , which is constant for fixed internuclear distance \"R\", has been omitted from the potential \"V\", since it merely shifts the eigenvalue. The distances between the electron and the nuclei are denoted \"r\" and \"r\". In atomic units (\"ħ\" = \"m\" = \"e\" = 4\"ε\" = 1) the wave equation is\nWe choose the midpoint between the nuclei as the origin of coordinates. It follows from general symmetry principles that the wave functions can be characterized by their symmetry behavior with respect to the point group inversion operation i (r ↦ −r). There are wave functions \"ψ\"(r), which are \"symmetric\" with respect to i, and there are wave functions \"ψ\"(r), which are \"antisymmetric\" under this symmetry operation:\nThe suffixes g and u are from the German \"gerade\" and \"ungerade\") occurring here denote the symmetry behavior under the point group inversion operation i. Their use is standard practice for the designation of electronic states of diatomic molecules, whereas for atomic states the terms \"even\" and \"odd\" are used.\nThe ground state (the lowest state) of is denoted XΣ or 1sσ and it is gerade. There is also the first excited state AΣ (2pσ), which is ungerade. \n\nAsymptotically, the (total) eigenenergies \"E\" for these two lowest lying states have the same asymptotic expansion in inverse powers of the inter-nuclear distance \"R\":\nThe actual difference between these two energies is called the exchange energy splitting and is given by:\nwhich exponentially vanishes as the inter-nuclear distance \"R\" gets greater. The lead term was first obtained by the Holstein–Herring method. Similarly, asymptotic expansions in powers of have been obtained to high order by Cizek \"et al.\" for the lowest ten discrete states of the hydrogen molecular ion (clamped nuclei case). For general diatomic and polyatomic molecular systems, the exchange energy is thus very elusive to calculate at large internuclear distances but is nonetheless needed for long-range interactions including studies related to magnetism and charge exchange effects. These are of particular importance in stellar and atmospheric physics.\n\nThe energies for the lowest discrete states are shown in the graph above. These can be obtained to within arbitrary accuracy using computer algebra from the generalized Lambert W function (see eq. (3) in that site and the reference of Scott, Aubert-Frécon, and Grotendorst) but were obtained initially by numerical means to within double precision by the most precise program available, namely ODKIL. The red solid lines are Σ states. The green dashed lines are Σ states. The blue dashed line is a Π state and the pink dotted line is a Π state. Note that although the generalized Lambert W function eigenvalue solutions supersede these asymptotic expansions, in practice, they are most useful near the bond length. These solutions are possible because the partial differential equation of the wave equation here separates into two coupled ordinary differential equations using prolate spheroidal coordinates.\n\nThe complete Hamiltonian of (as for all centrosymmetric molecules) does not commute with the point group inversion operation i because of the effect of the nuclear hyperfine Hamiltonian. The nuclear hyperfine Hamiltonian can mix the rotational levels of g and u electronic states (called ortho-para mixing) and give\nrise to ortho-para transitions\n\nThe dihydrogen ion is formed in nature by the interaction of cosmic rays and the hydrogen molecule. An electron is knocked off leaving the cation behind.\nCosmic ray particles have enough energy to ionize many molecules before coming to a stop.\n\nIn nature the ion is destroyed by reacting with other hydrogen molecules:\n\nThe ionization energy of the hydrogen molecule is 15.603 eV. The dissociation energy of the ion is 1.8 eV. High speed electrons also cause ionization of hydrogen molecules with a peak cross section around 50 eV. The peak cross section for ionization for high speed protons is with a cross section of . A cosmic ray proton at lower energy can also strip an electron off a neutral hydrogen molecule to form a neutral hydrogen atom and the dihydrogen cation, (p + H → H + ) with a peak cross section at around of .\n\nAn artificial plasma discharge cell can also produce the ion.\n\n"}
{"id": "2850670", "url": "https://en.wikipedia.org/wiki?curid=2850670", "title": "Dowel", "text": "Dowel\n\nA dowel is a cylindrical rod, usually made from wood, plastic, or metal. In its original manufactured form, a dowel is called a \"dowel rod\". Dowel rods are often cut into short lengths called \"dowel pins\". Dowels are commonly used as structural reinforcements in cabinet making and in numerous other applications, including:\n\nThe traditional tool for making dowels is a \"dowel plate\", an iron\n(or better, hardened tool steel) plate with a hole having the size of the desired dowel. To make a dowel, a piece of wood is split or whittled to a size slightly bigger than desired and then driven through the hole in the dowel plate. The sharp edges of the hole shear off the excess wood.\n\nA second approach to cutting dowels is to rotate a piece of oversized stock past a fixed knife, or alternatively, to rotate the knife around the stock. Machines based on this principle emerged in the 19th century. Frequently, these are small bench-mounted tools.\n\nFor modest manufacturing volumes, wood dowels are typically manufactured on industrial dowel machines based on the same principles as the rotary cutters described above. Such machines may employ interchangeable cutting heads of varying diameters, thus enabling the machines to be quickly changed to manufacture different dowel diameters.\nTypically, the mechanism is open-ended, with material guides at the machine's entry and exit to enable fabrication of continuous dowel rod of unlimited length. Since the 19th century, some of these dowel machines have had power feed mechanisms to move the stock past the cutting mechanism.\n\nHigh-volume dowel manufacturing is done on a wood shaper, which simultaneously forms multiple dowels from a single piece of rectangular stock (i.e., wood). These machines employ two wide, rotating cutting heads, one above the stock and one below it. The heads have nearly identical cutting profiles so that each will form an array of adjoined, side-by-side \"half dowels\". The heads are aligned to each other and one head is shaped to make deeper cuts along the dowel edges so as to part the stock into individual dowel rods, resulting in a group of dowel rods emerging in parallel at the machine's output.\n\nThe wooden dowel rod used in woodworking applications is commonly cut into dowel pins, which are used to reinforce joints and support shelves and other components in cabinet making. Some woodworkers make their own dowel pins, while others purchase dowel pins precut to the required length and diameter.\n\nWhen dowels are glued into blind holes, a very common case in dowel-based joinery, there must be a path for air and excess glue to escape when the dowel is pressed into place. If no provision is made to relieve the hydraulic pressure of air and glue, hammering the dowel home or clamping the joint can split the wood. An old solution to this problem is to plane a flat on the side of the dowel; some sources suggest planing the flat on the rough stock before the final shaping of the round dowel. Some dowel plates solve the problem by cutting a groove in the side of the dowel as it is forced through; this is done by a \"groove screw\", a pointed screw intruding from the side into the dowel cutting opening. Some dowel pins are Fluted with multiple parallel grooves along their length to serve the same purpose.\n\nWhen two pieces of wood are to be joined by dowels embedded in blind holes, there are numerous methods for aligning the holes. For example, pieces of shot may be placed between the wood pieces to produce indentations when the pieces are clamped together; after the clamp is released, the indentations indicate the center points for drilling. \"Dowel centers\" are simple and inexpensive tools for aligning opposing blind holes. Various commercial systems, such as Dowelmax, have been devised to solve this problem.\n\nAlternative joinery methods may be used in place of conventional dowel pins, such as Miller dowels, biscuit joiners, spline joints, and proprietary tools such as the Domino jointer.\n\nThe word \"dowel\" was used in Middle English; it appears in Wycliffe's Bible translation (circa 1382-1395) in a list of the parts of a wheel: \"...and the spokis, and dowlis of tho wheelis...\" Cognates with other Germanic languages suggest that the word is much older (\"deuvel\" in Dutch, \"Dübel\" in German).\n\nWooden dowels have been used in manufacturing and woodworking for many centuries. One of the earliest documented uses of wooden dowels was in Japanese shrines in AD 690, which were constructed using only wood, wooden dowels and pegs, and interlocking joints. Around AD 1000, Leif Erikson sailed across the North Atlantic in a ship that was largely constructed of overlapping planks held together by wooden dowels and iron nails. The wooden dowels did not rust and thus were more reliable than iron for long expeditions.\n\nDowel pins are often used as precise locating devices in machinery. Steel dowel pins are machined to tight tolerances, as are the corresponding holes, which are typically reamed. A dowel pin may have a smaller diameter than its hole so that it freely slips in, or a larger diameter so that it must be pressed into its hole (an interference fit).\n\nWhen designing mechanical components, mechanical engineers typically use dowel holes as reference points to control positioning variations and attain repeatable assembly quality. If no dowels are used for alignment (e.g., components are mated by bolts only), there can be significant variation, or \"play\", in component alignment.\n\nTypical drilling and milling operations, as well as manufacturing practices for bolt threads, introduce mechanical play proportional to the size of the fasteners. For example, bolts up to in diameter typically have play on the order of . When dowels are used in addition to bolts, however, the tighter dimensional tolerances of dowels and their mating holes—typically —result in significantly less play, on the order of . Manufacturing costs are inversely proportional to mechanical tolerances and, as a result, engineers must balance the need for mechanical precision against cost as well as other factors such as manufacturability and serviceability.\n\nThere are a variety of specifications, military, ISO, DIN, ASME that pins may be made to. And size can even vary by dowel pin material. Metric dowel pins are often found in two size. In DIN 6325 standard the dowel pins are slightly larger than the nominal value. For example a 3 mm dowel pin will range from 3.002 to 3.008. In the ISO 2338 standard the dowel pins are slightly smaller - 3mm nominal range is 2.986 to 3.000. The terminology (e.g. \"oversized\", \"standard\") is not entirely consistent across suppliers. In inch pins \"oversized\" refers to pins that are more significantly oversized for worn out dowel pin holes. The most common inch sized pins are slightly oversized, and \"undersized\" versions are also available. \n\nIn automobiles, dowels are used when precise mating alignment is required, such as in differential gear casings, engines, and transmissions.\n\nBolts in a bolted joint often have an important function as a dowel, resisting shear forces. For this reason, many bolts have a plain unthreaded section to their shank. This gives a closer fit to the hole and also avoids some problems with fretting wear when a screw thread bears against an unthreaded component.\n\nA cross dowel is a cylindrically shaped metal nut (i.e., a metal dowel) that is used to join two pieces of wood. Like other metal nuts, it has an inside threaded hole, although the hole is unusual in that it passes through the sides of the dowel. One or both ends of the dowel are slotted, with the slots oriented parallel to the threaded hole through which the bolt will pass.\n\nIn a cross dowel application, the two pieces of wood are aligned and a bolt hole is drilled through one piece of wood and into the other. A dowel hole is drilled laterally across the bolt hole and the cross dowel is inserted into it. A screwdriver is inserted into the slot at the end of the cross dowel and the dowel is rotated so that its threaded hole aligns with the bolt hole. The bolt is then inserted into the bolt hole and screwed into the cross dowel until the wood pieces are held tightly together.\n\n"}
{"id": "20895994", "url": "https://en.wikipedia.org/wiki?curid=20895994", "title": "Dynamic voltage restoration", "text": "Dynamic voltage restoration\n\nDynamic voltage restoration (DVR) is a method of overcoming voltage sags that occur in electrical power distribution. These are a problem because spikes consume power and sags reduce efficiency of some devices. DVR saves energy through voltage injections that can affect the phase and wave-shape of the power being supplied.\n\nDevices used for DVR include static var devices, which are series compensation devices that use voltage source converters (VSC). The first such system in North America was installed in 1996 - a 12.47 kV system located in Anderson, South Carolina.\n\nThe basic principle of dynamic voltage restoration is to inject a voltage of the magnitude and frequency necessary to restore the load side voltage to the desired amplitude and waveform, even when the source voltage is unbalanced or distorted. Generally, devices for dynamic voltage restoration employ gate turn off thyristors, (GTO) solid state power electronic switches in a pulse-width modulated (PWM) inverter structure. The DVR can generate or absorb independently controllable real and reactive power at the load side. In other words, the DVR is a solid state DC to AC switching power converter that injects a set of three phase AC output voltages in series and synchronicity with the distribution and transmission line voltages.\n\nThe source of the injected voltage is the commutation process for reactive power demand and an energy source for the real power demand. The energy source may vary according to the design and manufacturer of the DVR, but DC capacitors and batteries drawn from the line through a rectifier are frequently used. The energy source is typically connected to the DVR through its DC input terminal.\n\nThe amplitude and phase angle of the injected voltages are variable, thereby allowing control of the real and reactive power exchange between the dynamic voltage restorer and the distribution system. As mentioned, the reactive power exchange between the DVR and the distribution system is internally generated by the DVR without AC passive reactive components.\n\nDVRs use a technically similar approach as low voltage ride-through (LVRT) capability systems in wind turbine generators use. The dynamic response characteristics, particularly for line supplied DVRs, are similar to those in LVRT-mitigated turbines. Conduction losses in both kinds of devices are often minimized by using integrated gate-commutated thyristor (IGCT) technology in the inverters.\n\nPractically, DVR systems can to inject up to 50% of nominal voltage, but only for a short time (up to 0.1 seconds). However, most voltage sags are much less than 50 percent, so this is not typically an issue.\n\nDVRs can also mitigate the damaging effects of voltage swells, voltage unbalance and other waveform distortions.\n\nDVRs may provide good solutions for end-users subject to unwanted power quality disturbances. However, they are generally not used in systems that are subject to prolonged reactive power deficiencies (resulting in low voltage conditions) and in systems that are vulnerable to voltage collapse. Because DVRs will maintain appropriate supply voltage, in such systems where incipient voltage conditions are present they actually make collapses more difficult to prevent and can even lead to cascading interruptions.\n\nTherefore, when applying DVRs, it is vital to consider the nature of the load whose voltage supply is being secured, as well as the transmission system which must tolerate the change in voltage-response of the load. It may be necessary to provide local fast reactive supply sources in order to protect the system, including the DVR, from voltage collapse and cascading interruptions.\n\nThe SSSC’s counterpart is the Dynamic Voltage Regulator (DVR). Although both are utilized for series voltage sag compensation, their operating principles differ from each other. The static synchronous series compensator injects a balance voltage in series with the transmission line. On the other hand, the DVR compensates the unbalance in supply voltage of different phases. Also, DVRs are usually installed on a critical feeder supplying the active power through DC energy storage and the required reactive power is generated internally without any means of DC storage.\n\n\n"}
{"id": "4310539", "url": "https://en.wikipedia.org/wiki?curid=4310539", "title": "Elaidic acid", "text": "Elaidic acid\n\nElaidic acid is the organic compound with the formula CH(CH)CHCH(CH)COH. Classified as an unsaturated trans fatty acid, it is a colorless oily solid. This compound has attracted attention because it is a major trans fat found in hydrogenated vegetable oils, and trans fats are implicated in heart disease.\n\nIt is the trans isomer of oleic acid. The name of the elaidinization reaction comes from elaidic acid. \n\nElaidic acid occurs naturally in small amounts in caprine and bovine milk (very roughly 0.1% of the fatty acids) and in some meats. It also comprises 2.50% of the fats from the fruit of the durian species \"Durio graveolens\".\n\nElaidic acid increases plasma cholesterylester transfer protein (CETP) activity which lowers HDL cholesterol.\n\n"}
{"id": "14777567", "url": "https://en.wikipedia.org/wiki?curid=14777567", "title": "Ethenone", "text": "Ethenone\n\nEthenone is the formal name for ketene, an organic compound with formula CHO or HC=C=O. It is the simplest member of the ketene class. It is a tautomer of ethynol.\n\nEthenone is a highly reactive gas (at standard conditions) and has a sharp irritating odour. It is only reasonably stable at low temperatures (-80 °C). It must therefore always be prepared for each use and processed immediately, otherwise a dimerization to diketene occurs or it reacts to polymers that are difficult to handle. The polymer content formed during the preparation is reduced, for example, by adding sulfur dioxide to the ketene gas. Because of its cumulative double bonds, ethenone is highly reactive and reacts in an addition reaction H-acidic compounds to the corresponding acetic acid derivatives. It does for example react with water to acetic acid or with primary or secondary amines to the corresponding acetamides.\n\nEthenone is highly poisonous; its toxicity is about eight times that of phosgene.\n\nEthenone tends to spontaneously polymerize. Contact with hydrogen peroxide leads to an explosive reaction. It can form an explosive mixture with air.\n\nIt is soluble in acetone, ethanol, ethyl ether, aromatic solvents and halocarbons.\n\nEthenone can be prepared by dehydration of acetic acid or by the pyrolysis of acetone. For example, when passing acetone vapors through heated pipes or electrically heated metal (like copper) wires at 500-600 °C in the presence of little carbon disulfide (CS), ethenone is formed in 95% yield in addition to some methane. In industrial chemistry, ketone pyrolysis has largely been replaced by the dehydration of acetic acid (Schmidlin-Bergman-Wilsmore reaction).\n\nEthenone has been observed to occur in space, in comets or in gas as part of the interstellar medium.\n\nEthenone is used to make acetic anhydride from acetic acid. Generally it is used for the acetylation of chemical compounds.\n\nEthenone reacts with methanal in the presence of catalysts such as Lewis acids (AlCl, ZnCl oder BF) to give β-propiolactone. The technically most significant use of ethenone is the synthesis of sorbic acid by reaction with 2-butenal (crotonaldehyde) in toluene at about 50 °C in the presence of zinc salts of long-chain carboxylic acids. This produces a polyester of 3-hydroxy-4-hexenoic acid, which is thermally or hydrolytically depolymerized to sorbic acid.\n\nEthenone is very reactive, tending to react with nucleophiles to form an acetyl group. For example, it reacts with water to form acetic acid; with acetic acid to form acetic anhydride; with ammonia and amines to form ethanamides; and with dry hydrogen halides to form acetyl halides.\n\nThe formation of acetic acid likely occurs by an initial formation of 1,1-dihydroxyethene, which then tautomerizes to give the final product.\n\nEthenone will also react with itself via [2 + 2] photocycloadditions to form cyclic dimers known as diketenes. For this reason, it should not be stored for long periods.\n\nExposure to concentrated levels causes humans to experience irritation of body parts such as the eye, nose, throat and lungs. Extended toxicity testing on mice, rats, guinea pigs and rabbits showed that ten-minute exposures to concentrations of freshly generated ethenone as low as 0.2 mg/liter (116 ppm) may produce a high percentage of deaths in small animals. These findings put ethenone in the same order of toxicity as phosgene (0.2–20 mg/liter) and hydrogen cyanide (0.2-0.5 mg/liter). Death is from pulmonary edema and is entirely similar to, but much more rapid than is the case with phosgene poisoning.\n\nOccupational exposure limits are set at 0.5 ppm (0.9 mg/m) over an eight-hour time-weighted average. \nAn IDLH limit is set at 5 ppm, as this is the lowest concentration productive of a clinically relevant physiologic response in humans.\n\n"}
{"id": "9543045", "url": "https://en.wikipedia.org/wiki?curid=9543045", "title": "Flood mitigation", "text": "Flood mitigation\n\nIn environmental engineering, the flood mitigation involves the management and control of flood water movement, such as redirecting flood run-off through the use of floodwalls and flood gates, rather than trying to prevent floods altogether. It also involves the management of people, through measures such as evacuation and dry/wet proofing properties. The prevention and mitigation of flooding can be studied on three levels: on individual properties, small communities, and whole towns or cities. The costs of protection rise as more people and property are protected. The FEMA, for example, estimates that for every $1.00 spent on mitigation, $4.00 is saved.\n\nProperty owners may fit their home to stop water entering by blocking doors and air vents, waterproofing important areas and sandbagging the edges of the building.\n\nWhen more homes, shops and infrastructure are threatened by the effects of flooding, then the benefits of greater protection are worth the additional cost. Temporary flood defenses can be constructed relatively quickly in certain locations and provide protection from rising flood waters. Rivers running through large urban developments are often controlled and channeled. Water rising above a canal's full capacity may cause flooding to spread to other waterways and areas of the community, which causes damage. Defenses (both long-term and short-term) can be constructed to minimize damage, which involves raising the edge of the water with levees, embankments or walls. The high population and value of infrastructure at risk often justifies the high cost of mitigation in larger urban areas.\n\nThe most effective way of reducing the risk to people and property is through the production of flood risk maps. Most countries have produced maps which show areas prone to flooding based on flood data. In the UK, the Environment Agency has produced maps which show areas at risk. The map to the right shows a flood map for the City of York, including the floodplain for a 1 in 100 year flood (dark blue), the predicted floodplain for a 1 in 1000 year flood (light blue) and low-lying areas in need of flood defence (purple).\nThe most sustainable way of reducing risk is to prevent further development in flood-prone areas and old waterways. It is important for at-risk communities to develop a comprehensive Floodplain Management plan. Communities that participate in the National Flood Insurance Program must agree to regulate development in flood-prone areas.\n\n\n"}
{"id": "8122151", "url": "https://en.wikipedia.org/wiki?curid=8122151", "title": "Great Appalachian Storm of 1950", "text": "Great Appalachian Storm of 1950\n\nThe Great Appalachian Storm of November 1950 was a large extratropical cyclone which moved through the Eastern United States, causing significant winds, heavy rains east of the Appalachians, and blizzard conditions along the western slopes of the mountain chain. Hurricane-force winds, peaking at in Concord, New Hampshire and in the New England highlands, disrupted power to 1,000,000 customers during the event. In all, the storm impacted 22 states, killing 353, injuring over 160, and creating US$66.7 million in damage (1950 dollars). At the time, U.S. insurance companies paid more money out to their policy holders for damage resulting from this cyclone than for any other previous storm or hurricane. The cyclone is also one of only twenty-six storms to rank as a Category 5 on the Regional Snowfall Index.\n\nThe preceding atmospheric state was one of La Niña conditions, the cold phase of ENSO, which favors a storm track from the Ohio and Tennessee Valleys into the Appalachians. The cyclone initially formed in southeast North Carolina near a cold front on the morning of November 24 as the main cyclone over the Great Lakes weakened. Rapid development ensued as the surface center began to migrate back into a closed 500 hPa (14.75 inHg)-level (around 6,000 m/20,000 ft above sea level) cyclone, and the cyclone bombed while moving north through Washington D.C. the next morning. The former occluded front to its northwest became a warm front which moved back to the west around the strengthening, and now dominant, southern low pressure center. By the evening of November 25, the cyclone retrograded, or moved northwestward, into Ohio due to a blocking ridge up across eastern Canada. It was at this time that the pressure gradient was its most intense across southern New England and eastern New York. A wide area of +4 standard deviation 850mb winds occurred. The cyclone moved west over Lake Erie to the north of the upper cyclone before looping over Ohio as the low-level and mid-level cyclone centers coupled. Significant convection within its comma head led to the development of a warm seclusion, or a pocket of low level warm air, near its center which aided in further development due to the increased lapse rates a warmer low level environment affords under a cold low. After the system became stacked with height, the storm slowly spun down as it drifted north and northeast into eastern Canada over the succeeding few days.\n\nThis extratropical cyclone rapidly deepened as it moved up the eastern side of the Appalachians during November 24 and November 25 and continued into November 27. Coastal flooding was seen along the U.S. coastline from New Jersey northward.\n\nIn Alabama, all-time record lows for November were set at Birmingham , Mobile , and Montgomery . Across Florida, all-time record lows for November were set at Apalachicola (24˚F), Pensacola (22˚F), and Jacksonville (23˚F). Within Georgia, all-time record lows for November were set at Atlanta (3˚F), Columbus (10˚F), Augusta (11˚F), and Savannah (15˚F).\n\nAn all-time record low for November was set at Louisville (-1˚f).\n\nConcord recorded a wind gust of during the height of the storm. Winds at Mount Washington reached .\n\nSustained winds of 50-60 mph (80–100 km/h) with gusts to were recorded at Albany, New York. A wind gust of was recorded in New York City. Extensive damage was caused by the wind across New York, including massive tree fall and power outages. Coastal flooding breached dikes at LaGuardia Airport, flooding the runways. Flooding extended to New York City's Office of Emergency Management on the Lower East Side, in Manhattan.\n\nExtensive wind damage with tidal flooding along the coast. On the coast structures and railroad tracks washed away. Plows were needed to remove sand from coastal roads. Roofs torn off on the coast and at the University of Connecticut. The tide at New London was 7.58ft MLLW third highest in the last 100 years. Hartford had sustained winds of 70MPH the highest ever on record, 100 MPH gusts also the highest on record were recorded on 3 separate occasions. The 62 MPH sustained wind recorded at Bridgeport is the 4th highest on record. Other gusts 88MPH at Bridgeport and 77MPH at New Haven.\n\nA wind gust of 108 mph (173.8 km/h), the strongest ever recorded in New Jersey, occurred in Newark.\n\nAll-time record lows for November were set at Asheville and Wilmington .\n\nOn the storm's west side, nearly a foot of snow fell on Dayton, Ohio, which combined with the wind and cold temperatures, became their worst blizzard on record. Nearly the entire state was blanketed with of snow, with 20-30 inches (50–75 cm) being measured in eastern sections of Ohio. The highest report was from Steubenville. Snow drifts were up to deep. Winds exceeded with gusts as high as . Bulldozers were used to clear roads. Despite the high winds and snow, the annual football game between the University of Michigan and Ohio State University went on as scheduled in Columbus and was nicknamed the Snow Bowl. When the snow melted during the first four days of December, river flooding occurred in Cincinnati.\n\nDuring the height of the storm, record to near-record flooding occurred along the eastern side of the Appalachians across eastern and central sections of the state. The Schuylkill at Fairmont Dam reached its highest stage since 1902. In Pittsburgh, of snow accumulated from this cyclone. Tanks were used to clear the resultant snow. When a warm spell visited the region during the first four days of December, river flooding struck Pittsburgh.\n\nAll-time record lows for November were set at Charleston (17˚F) and Greenville (11˚F).\n\nAll-time record lows for November were set at Chattanooga (4˚F), Knoxville (5˚F), Memphis (9˚F), and Nashville (-1˚F).\n\nParkersburg recorded 34.4 inches (87.3 cm) of snowfall during the passage of this low, which exceeded its snowiest November on record by over . Pickens reported the highest amount from anywhere within the cyclone, with measured. November 1950 became West Virginia's snowiest month on record. This remarkably heavy snow led to 160 deaths.\n\nThis system was a major snowstorm for the area, with in Toronto on November 24. This set a record for single-day snowfall in November.\n\nThis cyclone was used as a test case for some of the first attempts at numerical modeling of the atmosphere, and is still used as a case study to run recent versions of forecast models. These studies helped create what is now known as the National Centers for Environmental Prediction.\n\nStorms during the time frames November 8–10, 1913, October 22–25, 1923, and November 19–22, 1952 were considered analogous to this cyclone. Despite their similarities, there are some differences. For example, the 1913 event was much more destructive to Great Lakes shipping, while the 1950 storm caused greater snowfall amounts.\n\n\n"}
{"id": "20611913", "url": "https://en.wikipedia.org/wiki?curid=20611913", "title": "Hai-Fu Power Station", "text": "Hai-Fu Power Station\n\nThe Hai-Fu Power Station () is a combined cycle power station located in Taoyuan City, Taiwan. The station is located north east of Taoyuan International Airport. The power station runs on natural gas and consists of two KA24-2 turbines. The turnkey project was awarded in 1996 to ABB. The customer is EverPower IPP Co. Ltd. with its head office in Taichung.\n\n"}
{"id": "55305587", "url": "https://en.wikipedia.org/wiki?curid=55305587", "title": "Intersolar", "text": "Intersolar\n\nIntersolar is a trade fair in the solar energy industry. \n\nThe exhibition and conference series focuses on the areas of photovoltaics, PV production technology, energy storage and solar thermal energy. It launched in 1991.\nThe trade fairs and conferences take place in Munich, San Francisco, Mumbai, Beijing and São Paulo.\n\n"}
{"id": "38088325", "url": "https://en.wikipedia.org/wiki?curid=38088325", "title": "Kulluk", "text": "Kulluk\n\nKulluk was an ice-strengthened drill barge that was used for oil exploration in the Arctic waters. She was constructed by Mitsui Engineering & Shipbuilding in Japan in 1983 and operated in the Canadian Arctic until 1993 when she was mothballed for over a decade. In 2005, she was purchased and extensively refurbished by Royal Dutch Shell for the drilling operations off the northern coast of Alaska.\n\nOn 31 December 2012, \"Kulluk\" drifted aground after the towing line to the icebreaking anchor-handling tug \"Aiviq\" parted in heavy weather. While the rig was recovered, the repairs were not deemed feasible and Shell decided to scrap the unit in 2014.\n\nFrom 1983 to 1993, the rig was operated by Gulf Canada Resources in the Canadian Arctic.\nShe was mothballed in 1993, and in 2005 she was acquired by Royal Dutch Shell and underwent intensive refurbishment. In January 2006, Shell awarded a contract to manage and operate \"Kulluk\" to Frontier Drilling (now part of Noble Corporation). In 2007, there was an industrial accident on board \"Kulluk\" while she was undergoing refurbishment, causing the death of a man.\n\nOn 31 December 2012, \"Kulluk\" drifted aground off Sitkalidak Island in the Gulf of Alaska. Up until October the rig had been working in the Beaufort Sea, off the Alaska North Slope. She was being towed to her winter home in Seattle when she encountered a storm, and the incident occurred. The US Coast Guard evacuated her 18-man crew on 29 December. On New Year's Eve, tug crews were ordered by the US Coast Guard to cut the rig loose, leading to her grounding.\n\n\"Kulluk\"'s movement south for the winter was at least in part motivated by an effort to avoid State of Alaska property taxes on oil and gas extraction equipment.\n\nThe tax in question is a state property tax of 20 mills (or 2 percent) \"on property used or committed by contract or other agreement for use for the pipeline transportation of gas or unrefined oil or for the production of gas or unrefined oil at its full and true value as of January 1 of the assessment year.\" The tax liability for the rig is estimated at between 6 and 7 million dollars, based on the value of the rig; however Shell may seek a filing extension to try to pay a lower tax rate given that the rig was grounded, potentially reducing her value, as of January 1.\n\n\"Kulluk\" was carrying of ultra-low-sulfur diesel fuel, of aviation fuel and of lubricants. So far the Coast Guard has reported no sign of a hull breach or fuel spill.\n\nOn January 6, 2013, \"Kulluk\" was floated from the rocks. Satisfied the vessel was seaworthy, she was towed to shelter in nearby Kodiak Island's Kiliuda Bay. After further assessment of damage, \"Kulluk\" was towed to Captains Bay, Unalaska, where she was loaded on the heavy lift ship \"Xiang Rui Kou\" and departed for Singapore for repair and updates around 26 March 2013. Until February 2014, she remained at Keppel FELS Pioneer Yard shipyard in Singapore.\n\nOn 31 October 2013, a Shell representative hinted that \"Kulluk\" may not be brought back into operation. On 27 February 2014, \"Kulluk\" was again loaded on \"Xiang Rui Kou\" which carried the mobile drilling unit to a Chinese scrapyard.\n\n\"Kulluk\" was ice-reinforced with thick, reinforced steel, and a double-sided funnel-shape hull with flared sides enabling her to operate in Arctic waters as moving ice was deflected downwards and was broken into pieces. The vessel was moored with a twelve-point anchor system. Her rated water depth for operations was . Her drilling depth was .\n\n\"Kulluk\" originally had no propulsion and had to be towed to location. In 2006, Shell contracted Aker Arctic to evaluate the feasibility of adding a thruster-aided propulsion to the drilling barge. In 2007, \"Kulluk\" was fitted with two 62-tonne, ThrustMaster hydraulic overboard azimuth thrusters, the largest ever supplied by the company, to provide the platform an ability to move between drill sites and improve her operability in ice. However, before the system had been installed completely, the project was already delayed and subsequently halted due to regulatory and operational changes. In 2011, it was decided to remove the thrusters while \"Kulluk\" was on the shipyard and sell them, turning \"Kulluk\" into an unpropelled drilling barge again.\n\n"}
{"id": "21210511", "url": "https://en.wikipedia.org/wiki?curid=21210511", "title": "Lalamilo Wells", "text": "Lalamilo Wells\n\nLalamilo Wells is a wind farm on the island of Hawaii. It is located within the \"ahupuaa\" (ancient land division) called Lalamilo, between the coastal area known as Puako, Hawaii, and the inland towns of Waimea and Waikoloa Village, Hawaii. It was commissioned in 1985 with 39 17.5 kW Jacobs wind turbines and 81 20 kW Jacobs wind turbines, yielding a total capacity of 2.3 MW.\n\nStarting in January 2006, the electric utility operating the wind farm, Hawaiian Electric Company (HELCO), operated a demonstration model of a grid-stabilizing unit, known as an Electronic Shock Absorber (ESA). This unit was designed to increase the stability of the island's grid, which has a relatively high penetration of wind energy, which is subject to rapid fluctuations. However, the unit was damaged in an earthquake in October 2006.\n\nBy 2010 the turbines were antiquated; only two-thirds were still in operation. The farm was decommissioned that year in anticipation of replacing the turbines with more efficient modern models.\n\nLalamilo Wind Company was awarded the contract to repower and operate the wind farm. They plan to install five Vestas V47/660 kW turbines that together would have a generating capacity of 3.3 MW. Commercial operation is intended to begin in late 2015 or early 2016.\n"}
{"id": "52148921", "url": "https://en.wikipedia.org/wiki?curid=52148921", "title": "Leifheit", "text": "Leifheit\n\nLeifheit AG is a German manufacturing company that makes kitchen equipment.\nIt was founded in 1959 by Günter Leifheit (13 December 1920 - 2 July 2009) with his wife Ingeborg, as Günter Leifheit KG. He sold the company in 1973. In 2006 he received the Order of Merit of Rhineland-Palatinate.\n\nThe company was listed on the Deutsche Börse in 1984. It forms part of the SDAX. \n\nIt is headquartered in Nassau, Rhineland-Palatinate. \n\nIt makes kitchen equipment under the name Soehnle.\n\n"}
{"id": "15237300", "url": "https://en.wikipedia.org/wiki?curid=15237300", "title": "Libby, Montana (film)", "text": "Libby, Montana (film)\n\nLibby, Montana is a 2004 documentary film about the biggest case of community-wide exposure to a toxic substance in U.S. history. The film details the story of the iconic, mountainside town of Libby, Montana and the hundreds of residents who have been exposed to asbestos, raising questions of the role of corporate power in American politics.\n\n\"Libby, Montana\" was directed, produced, and edited by Drury Gunn Carr and Doug Hawes-Davis and was aired as part of PBS's Point of View series in 2007.\n\n\n"}
{"id": "2679205", "url": "https://en.wikipedia.org/wiki?curid=2679205", "title": "Long-fiber-reinforced thermoplastic", "text": "Long-fiber-reinforced thermoplastic\n\nLong-fiber-reinforced thermoplastic (LFRTs) is a type of easily mouldable thermoplastic used to create a variety of components used primarily in the automotive industry. LFRTs are one of the fastest growing categories in thermoplastic technologies. Leading this expansion is one of the oldest forms, glass mat thermoplastic (GMT) and two of the segment’s newest: precompounded (pelletized) LFRTs (long-fiber-reinforced thermoplastics), also known as LFTs, and inline compounded (ILC) or direct LFTs (D-LFTs).\n\nLFRTs differ from the composite structures used in the aerospace industry for components such as aircraft parts. The fibers in LFRTs are relatively short (6.35 mm/0.25 in. or greater) compared to the fibres contained in composite aircraft components. High performance composites usually contain fibers as long as the component itself (6 metres or longer).\n\nTheir structural properties and low cost per part have enabled LFRTs to replace metal parts in the automotive industry. In addition, some new organic fibers can even be recyclable. With the independence of choosing the reinforcement from a wide range of fibers and the matrix from a wide range of thermoplastics polymer in the LFRTs, its property can be changed according to customer needs. LFRTs have become an increasingly valuable and popular part of building envelope components such as windows and doors.\n\nLFRT components or semi-finished products are made by compression or injection molding. Fibers are contained in the polymer matrix, often in the form of a granulate raw material.\nLong Fiber Reinforced Thermoplastic Compounds are typically 10-12 mm in length. Fiber is unidirectional along the length of the 12 mm pellet.\n\n"}
{"id": "9093853", "url": "https://en.wikipedia.org/wiki?curid=9093853", "title": "Loudoun County Sanitation Authority", "text": "Loudoun County Sanitation Authority\n\nIn May 1959, the Loudoun County Board of Supervisors created Loudoun County Sanitation Authority (LCSA) by a resolution, through the Water and Waste Authorities Act, for the sole purpose of providing water and wastewater service to residents of the unincorporated areas of the county. rebranded and moved from Leesburg to Ashburn in April 2008. It now does business as Loudoun Water.\n\nLoudoun Water is a political subdivision of the state, similar to a town or a county government. All income is received either as user fees from customers or availability fees from developers. User fees pay for operating expenses. Availability fees pay for capital improvements. Loudoun Water receives no tax revenues.\n\nLoudoun Water's nine-member Board governs how it operates and generally meets every second Thursday of the month. These meetings are open to the public. Each member of the Board is appointed at-large by the Loudoun County Board of Supervisors and serves a four-year term. These terms are staggered, so that every year, two members are re-appointed and every fourth year, three members are re-appointed. The Authority's Board appoints a General Manager who is responsible for the daily management of Loudoun Water.\n\nLoudoun Water purchases its water from Fairfax Water (Fairfax County Water Authority) and Loudoun Water's Goose Creek Water Treatment Facility. A small percentage of Loudoun Water's customers are part of Community Systems. Customers within these systems have community wells and / or small communal wastewater systems. Wastewater in the Central Service Area is sent to the Broad Run Water Reclamation Facility, owned and operated by Loudoun Water, or conveyed to the Blue Plains Advanced Wastewater Treatment Plant operated by the District of Columbia Water and Sewer Authority.\n\nLoudoun Water created an indoor education center and outdoor interpretive area called The Aquiary (ā•kwee•air•ee). The Aquiary is like a water museum, full of interactive exhibits and interpretive trails that tell the story of drinking water treatment and delivery; source water protection; water conservation and water reclamation. The Aquiary was named by one of the citizen members of the advisory group that advised Loudoun Water on the content and appearance of the space. It is a made-up word that rhymes with aviary, and means “a place for Loudoun water learning and appreciation.” Brainstorming for the space and the trail system began in 2003 when Loudoun Water first decided to build a campus in Ashburn, next to its Operations and Maintenance facility. Loudoun Water worked with consultants and a citizen advisory group, comprising a diverse array of Loudoun Water customer volunteers, to develop the exhibits and the space.\n\nLoudoun Water has intended the Aquiary to serve as a learning and teaching tool for Loudoun County Public Schools, and consulted with teachers and the school administration to ensure its effectiveness as a field trip destination. \n\nThe Aquiary is a National Wildlife Federation certified national wildlife habitat.\n\n"}
{"id": "19145781", "url": "https://en.wikipedia.org/wiki?curid=19145781", "title": "Maren (energy management system)", "text": "Maren (energy management system)\n\nMaren is a marine energy management system used to minimize fuel usage, thereby reducing vessel operator's fuel cost and the harmful emissions. Maren is developed by Marorka in Iceland. Maren 2 was released in Q3 in 2005 and launched at the Icelandic Fisheries Exhibition that year. Maren 2 was awarded the best new product at the exhibition.\n\nMaren monitors the various energy systems onboard different types of vessels. It puts operating en environmental parameters in an energy management context. Maren uses simulation and optimization to deliver suggestions on how to improve the operation of the vessel to minimize fuel usage.\n\n"}
{"id": "31341243", "url": "https://en.wikipedia.org/wiki?curid=31341243", "title": "Ministry of Energy of Georgia", "text": "Ministry of Energy of Georgia\n\nThe Ministry of Energy of Georgia (, \"sakartvelos energetikis saministro\") was a governmental agency within the Cabinet of Georgia in charge of regulating the activities in the energy sector of Georgia from 1991 to 2017.\n\nThe ministry is headed by minister appointed by the President of Georgia. Five deputy ministers report directly to the minister. Main functions of the ministry are increasing capabilities for maximum exploitation of the available energy resources in the country and diversification of energy supply imported from other countries; improving and modernizing electricity supply by enhancing the hydropower capacity of Georgia; renovation of existing and construction of new power stations and natural gas transportation infrastructure; development of alternative energy sources; improvements of infrastructure for making the country a reliable transit point for regional energy projects, etc.\n\nDue to improvements in recent years, Georgia has become a major exporter of electricity in the region, exporting 1.3 billion KWh in 2010. Hydropower stations of Georgia produce 80-85% of the electricity utilized within the country, the remaining 15-20% is produced by thermal power stations. According to the authorities, so far Georgia has been exploiting only 18% of its hydro resource potential.\n\n\n"}
{"id": "10543014", "url": "https://en.wikipedia.org/wiki?curid=10543014", "title": "Molecular property", "text": "Molecular property\n\nMolecular properties include the chemical properties, physical properties, and structural properties of molecules, including drugs. Molecular properties typically do not include pharmacological or biological properties of a chemical compound.\n\n"}
{"id": "2836053", "url": "https://en.wikipedia.org/wiki?curid=2836053", "title": "Natural uranium", "text": "Natural uranium\n\nNatural uranium (NU, U) refers to uranium with the same isotopic ratio as found in nature. It contains 0.711% uranium-235, 99.284% uranium-238, and a trace of uranium-234 by weight (0.0055%). Approximately 2.2% of its radioactivity comes from uranium-235, 48.6% from uranium-238, and 49.2% from uranium-234.\n\nNatural uranium can be used to fuel both low- and high-power nuclear reactors. Historically, graphite-moderated reactors and heavy water-moderated reactors have been fueled with natural uranium in the pure metal (U) or uranium dioxide (UO) ceramic forms. However, experimental fuelings with uranium trioxide (UO) and triuranium octaoxide, (UO) have shown promise.\n\nThe 0.72% uranium-235 is not sufficient to produce a self-sustaining critical chain reaction in light water reactors or nuclear weapons; these applications must use enriched uranium. Nuclear weapons take a concentration of 90% uranium-235, and light water reactors require a concentration of roughly 3% uranium-235. Unenriched natural uranium is appropriate fuel for a heavy-water reactor, like a CANDU reactor.\n\nIn rare occasions, earlier in geologic history when uranium-235 was more abundant, uranium ore was found to have naturally engaged in fission, forming natural nuclear fission reactors. Uranium-235 decays at a faster rate (half-life of 700 million years) compared to uranium-238, which decays extremely slowly (half-life of 4.5 billion years). Therefore, a billion years ago, there was more than double the uranium-235 compared to now.\n\nDuring the Manhattan Project, the name Tuballoy was used to refer to natural uranium in the refined condition; this term is still in occasional use. Uranium was also called codenamed \"X-Metal\" during World War II. Similarly, enriched uranium was referred to as Oralloy (Oak Ridge alloy), and depleted uranium was referred to as Depletalloy (depleted alloy).\n\n\n"}
{"id": "31913893", "url": "https://en.wikipedia.org/wiki?curid=31913893", "title": "Occasional-shrimp goby", "text": "Occasional-shrimp goby\n\nDrombus bontii is a species of goby native to the Indian Ocean from the Bazaruto Archipelago of Mozambique through to the tropical waters of the western Pacific Ocean. This species can reach a length of TL. The status of this species is questionable, with Maurice Kottelat considering it to be a junior synonym of \"Drombus triangularis\".\n"}
{"id": "43098972", "url": "https://en.wikipedia.org/wiki?curid=43098972", "title": "Orkjärv Nature Reserve", "text": "Orkjärv Nature Reserve\n\nOrkjärv Nature Reserve is a nature reserve situated in northern Estonia, in Harju County. It was established in 2005.\n\nNature reserve was established to protect Orkjärve Bog and Aude and Viisu mires.\n"}
{"id": "13537250", "url": "https://en.wikipedia.org/wiki?curid=13537250", "title": "PAS 2010", "text": "PAS 2010\n\nPAS 2010 is a Publicly Available Specification published by the British Standards Institution. It is particularly relevant to land use and spatial planning in terrestrial, coastal and freshwater environments, but its principles can also be applied to planning in the marine environment. It shows where and how competent authorities can have regards to seek to further biodiversity conversation in the exercise of their planning functions – as required under statutory obligations.\n\n\n"}
{"id": "57873748", "url": "https://en.wikipedia.org/wiki?curid=57873748", "title": "Paper car wheel", "text": "Paper car wheel\n\nPaper car wheels were composite wheels of railway carriages, made from a wrought iron or steel rim bolted to an iron hub with an interlayer of laminated paper. The center was made of compressed paper held between two plate-iron disks. Their ability to damp rail/wheel noise resulted in a quiet and smooth ride for the passengers of North American Pullman dining and sleeping cars.\n\nPaper car wheels were invented by the locomotive engineer Richard N. Allen (1827–1890), who set up a company with his brother-in-law in 1867, producing paper from straw. They damped vibrations much better than conventional cast-iron railway wheels, which transmitted all imperfections of the track into the car above it, making train rides noisy and uncomfortable. Paper wheels were especially used in Pullman dining and sleeping cars, although they were occasionally criticised for causing derailments. In 1915 the Interstate Commerce Commission, which regulated U.S. railroads, declared paper car wheels to be unsafe, and they went out of use on railroad passenger cars in the United States.\n\nThe construction process involved the bonding of 200 circular sheets of paper, as follows. Sets of three circular sheets were bonded into a \"sandwich\" using a flour-based glue. Additional \"sandwiches\" were then constructed and placed atop one another to make a high stack. This stack was placed in a 650-ton hydraulic press for three hours. The circular compound disks were then dried and cured for six to eight weeks, leaving no moisture in them. After curing, the compound disks were turned in a lathe to the appropriate size, and 24 or more bolt holes were drilled in them. These compound disks formed the center of each wheel, to which was added a cast-iron hub and steel rim bolted to thick protective metal plates on either side of the paper center. With the bolts tightened, the paper center became a \"solid, dense, compressed, composite structure\" which could support the weight of the carriages.\n\nThe Allen Paper Car Wheel Works was initially based on East North Street in Morris, Illinois, while its general office was on 239 Broadway, New York. The company's principal customer was the Pullman Palace Car Company in Chicago which, after testing and optimising the wheel, had placed their first order for 100 wheels in 1871. Subsequently, the main plant was established at South Bay in Hudson, New York, in 1873, and eventually relocated onto the site of Pullman's Chicago works.\n\nBy 1881, the Allen Paper Car Wheel Co. operated workshops in New York and Chicago, but maintained its processing plant in Morris. Each workshop employed approximately 80 men and produced more than 24 wheels a day. Thus the company produced and sold thousands of wheels each year. In 1886 the company announced it had 60,000 wheels in service. In 1893 it had sold 115,000. The Allen Paper Car Wheel Works operated until 1890, when they were transferred to John N. Bunnell and changed their name to the American Straw Board Co. Subsequently, the business and plant were leased, sold and restructured, and operated for the next two decades under different names, including the Morris Box Board Co. In October 1915, the company was restructured and incorporated as the Morris Paper Mills. By the 1920s, the paper mill was one of the largest employers in Morris, producing cardboard boxes of various shapes, sizes, and colors that were shipped throughout the US.\n\nThe company John Brown & Co in Sheffield, England, came to an agreement with the inventor on the manufacture of paper wheels in Europe. It installed the necessary machines by October 1875, so that production was expected to start in due course.\n\nAs proposed by the Master Machine Builder Finckbein in Saarbrücken-St. Johann and the Master Craftsman Caesar of the Reichseisenbahn, the oilboard and lacquerware factory of Gebrüder Adt in Forbach produced a paper pulp suitable for railway car wheels after various tests. With the permission of the Royal Railway Administration in Frankfurt a. M., wheelsets with paper discs were manufactured in the main railway workshop in Saarbrücken and in the railway car wheels factory of the van der Zypen brothers in Deutz and then put into use. Such wheelsets with paper pulp discs were in regular service on wagons for a long time. They held perfectly and showed a very smooth running while driving without making any annoying noises.\n\nThe wheels used in Saarbrücken were constructed in the manner of wooden Mansell wheels, with the wheel tire being placed on the paper disc and the hub in it by means of strong hydraulic pressure, while the tires of the American paper wheels were provided with an inner attachment against which the paper disc was pressed and to which it was connected by bolts. Practice has shown that tires with such an inner approach, apparently due to the uneven mass distribution, cracked from the inside to the outside, so that the advantage of reinforcing the tires was lost and an opposite result was achieved. The tire in conventional Mansell wheels with wooden discs could slip on the wooden disc when the tire was warmed up during braking. In the wheels designed in Saarbrücken, four iron dowels were therefore inserted on each side between the tire and the Mansell ring, which prevented the wheel tires from turning during braking.\n\n"}
{"id": "4810180", "url": "https://en.wikipedia.org/wiki?curid=4810180", "title": "Picarin", "text": "Picarin\n\nPicarin is a plastic used to make optics such as lenses for terahertz radiation (THz radiation). Picarin is useful for this purpose because it is highly transparent in both the THz and visible spectral ranges. The refractive index of Picarin is almost the same for THz (\"n\"=1.52) and visible light (\"n\"=1.52). It is very strong mechanically, and withstands optical polishing.\n\nUnpolished Picarin Lenses offer the best performance at 2-7 THz spectral range. Unfortunately, unpolished surfaces scatter visible and near-IR light.\n\nA version which can be polished is sold as Tsurupica.\n"}
{"id": "16058789", "url": "https://en.wikipedia.org/wiki?curid=16058789", "title": "Rue Saint-Paul (Montreal)", "text": "Rue Saint-Paul (Montreal)\n\nRue Saint-Paul (\"Saint Paul Street\") is a street in the Old Montreal historic area of Montreal, Quebec.\n\nThe street was laid out by François Dollier de Casson, along the route of a path that had bordered a former fort. Saint Paul is Montreal's oldest street and for many years served as its main thoroughfare. Paved in 1672, it was named after Paul de Chomedey de Maisonneuve, founder of Montreal, who built a home for himself on it in 1650.\n\nThe street is home to such landmarks as the Bonsecours Market and Notre-Dame-de-Bon-Secours Chapel. Much of Saint Paul is still paved with cobblestones. Plans to pedestrianize the street in 2008 were dropped by the City of Montreal after complaints from merchants.\n\n"}
{"id": "53175530", "url": "https://en.wikipedia.org/wiki?curid=53175530", "title": "Sadad Ibrahim Al Husseini", "text": "Sadad Ibrahim Al Husseini\n\nDr. Sadad Ibrahim Al Husseini is a leading Saudi oil and gas industry expert. He is most widely known for his achievements during his tenure at Saudi Aramco as the Senior and Executive Vice President for Exploration and Producing, and his current work on supply side risk; referred to by the New York Times as “one of the most respected and accomplished oilmen in the world”.\n\nHe is credited with launching the field modernization and state of art reservoir management and development of Saudi Arabia’s giant oil fields, the upgrading of the company’s drilling, environmental, and upstream safety standards, the discovery and development of its Paleozoic oil and gas reservoirs, the discovery of its Red Sea oil and condensate fields, the initiation of its upstream advanced degree and specialists professional programs, and the development of its leading edge reservoir modelling and simulation capabilities at its purpose built Exploration and Petroleum Engineering Center,EXPEC. In 1988 he launched Aramco’s mothballing program for 3.5 million barrels of oil production capacity and in 1990, as a result of the Iraqi invasion of Kuwait, he led the Aramco team that re-activated the mothballed capacity thereby increasing Kingdom’s oil production from 5 million bd to 8.5 million bd within six months. In 1994 he launched the intensified non-associated Saudi gas exploration program which increased the Kingdom’s non-associated gas reserves by 30 Tcf within 4 years.\n\nIn 1996,Al Husseini was called upon by HM King Abdullah ibn Abdul Aziz to provide advisory support to the Kingdom’s leadership for the purpose of expanding its economy through a broader exploitation of its proven gas reserves. This culminated in the Kingdom’s Natural Gas Initiative in 1999 which invited international oil companies to participate in the development of the Kingdom’s non-associated gas reservoirs and the expansion of its power generation, desalination and petrochemical sectors. Following on his retirement from Saudi Aramco in 2004, Dr.Al Husseini co-founded and is president of Husseini Energy Company, a highly specialized oil and gas consulting firm based in Bahrain and Saudi Arabia.\n\nIn July 30, 2018, Al Hussenini said, “Rather than allowing these hostile maneuvers to go unnoticed in the eyes of the world, the Saudi (energy) minister has placed Iran’s subversions of the whole global economy under the spotlight for everyone to see,” “The capture of the port of Hodeidah will go a long way towards putting an end to these disruptions\".\n\nDr Sadad Al Husseini was born in Damascus in 1946 to Col. Ibrahim Abdulrahman Al Husseini and Myassar BachImam. His father was a leading Syrian nationalist and member of the Syrian military and political leadership until 1957. Al Husseini attended primary and secondary education at Notre Dame International School in Rome, Italy between 1955 and 1964. He and his family moved to Saudi Arabia in 1961 when King Faisal bin Abdul Aziz invited Col. Ibrahim Al Husseini to advise the Saudi Arabian Council of Ministers on national security matters and to support Prince Abdullah bin Abdul Aziz Al Saud as his special advisor in the establishment of the modern Saudi Arabian National Guard.\n\nOn February 8, 2011 The Guardian newspaper published US cables from Saudi Arabia that were obtained by WikiLeaks. The cables were based on a conversation attributed to Dr Sadad Al Husseini in 2007 claiming Dr Husseini thought Aramco’s reserves were overstated by as much as 300 billion barrels. The story gained traction in the press and caused tremendous damage to Dr Husseini’s reputation within the Kingdom. Dr Sadad Al Husseini maintained that the US cable gravely misrepresented his opinion and that the report was full of errors and rooky mistakes including quoting resource figures as reserve figures.Subsequently, Dr Sadad Al Husseini’s firm published a press release on February 9, 2011 in response to the significant errors in the cable and clarified Dr Sadad’s position on Saudi Arabia’s reserves and production capabilities.\n\n"}
{"id": "1639361", "url": "https://en.wikipedia.org/wiki?curid=1639361", "title": "Shock stall", "text": "Shock stall\n\nA shock stall is a stall created when the airflow over an aircraft's wings is disturbed by shock waves formed when flying at or above the aircraft's drag divergence Mach number.\n\nA stall is the decrease in Lift to a value below the Weight, and the associated increase in Drag upon the separation of the boundary layer (in this case behind the shock wave).\n"}
{"id": "19991258", "url": "https://en.wikipedia.org/wiki?curid=19991258", "title": "Sociology of space", "text": "Sociology of space\n\nThe sociology of space is a sub-discipline of sociology that mostly borrows from theories developed within the discipline of geography, including the sub fields of human geography, economic geography, and feminist geography. The \"sociology\" of space examines the social and material constitution of spaces. It is concerned with understanding the social practices, institutional forces, and material complexity of how humans and spaces interact. The sociology of space is an inter-disciplinary area of study, drawing on various theoretical traditions including Marxism, postcolonialism, and Science and Technology Studies, and overlaps and encompasses theorists with various academic disciplines such as geography and architecture. Edward T. Hall developed the study of Proxemics which concentrates on the empirical analysis of space in psychology. \n\nSpace is one of the most important concepts within the disciplines of social science as it is fundamental to our understanding of geography. The term \"space\" has been defined variously by scholars:\n\nIn general terms, the Oxford English Dictionary defines space in two ways;\n\n1. A continuous extension viewed with or without reference to the existence of objects within it. \n2. The interval between points or objects viewed as having one, two or three dimensions.\n\nHowever, the human geographers’ interest is in the objects within the space and their relative position, which involves the description, explanation and prediction of the distribution of phenomena. Thus, the relationships between objects in space is the central of the study.\n\nMichel Foucault defines space as;\n“The space in which we live, which draws us out of ourselves, in which the erosion of our lives, our time and our history occurs, the space that claws and gnaws at us, is also, in itself, a heterogeneous space…..we live inside a set of relations.\n\nNigel Thrift also defines space as;\n\"The outcome of a series of highly problematic temporary settlements that divide and connect things up into different kinds of collectives which are slowly provided with the meaning which render them durable and sustainable.\" \n\nIn short, \"space\" is the social space in which we live and create relationships with other people, societies and surroundings. Space is an outcome of the hard and continuous work of building up and maintaining collectives by bringing different things into alignments. All kinds of different spaces can and therefore do exist which may or may not relate to each other. Thus, through space, we can understand more about social action.\n\nGeorg Simmel has been seen as the classical sociologist who was most important to this field. Simmel wrote on \"the sociology of space\" in his 1908 book \"Sociology: Investigations on the Forms of Sociation\". His concerns included the process of metropolitanisation and the separation of leisure spaces in modern economic societies.\n\nThe category of space long played a subordinate role in sociological theory formation. Only in the late 1980s did it come to be realised that certain changes in society cannot be adequately explained without taking greater account of the spatial components of life. This shift in perspective is referred to as the topological turn. The space concept directs attention to organisational forms of juxtaposition. The focus is on differences between places and their mutual influence. This applies equally for the micro-spaces of everyday life and the macro-spaces at the nation-state or global levels.\n\nThe theoretical basis for the growing interest of the social sciences in space was set primarily by English and French-speaking sociologists, philosophers, and human geographers. Of particular importance is Michel Foucault’s essay on “Of Other Spaces”, in which the author proclaims the “age of space”, and Henri Lefebvre’s seminal work “La production de l’espace”. The latter provided the grounding for Marxist spatial theory on which David Harvey, Manuel Castells, Edward Soja, and others have built. Marxist theories of space, which are predicated on a structural, i.e., capitalist or global determinants of spaces and the growing homogenization of space, are confronted by action theoretical conceptions, which stress the importance of the corporeal placing and the perception of spaces as albeit habitually predetermined but subjective constructions. One example is the theory of space of the German sociologist Martina Löw. Approaches deriving from the post-colonialism discourse have attracted greater attention in recent years. Also in contrast to (neo)Marxist concepts of space, British geographer Doreen Massey and German sociologist Helmuth Berking, for instance, emphasise the heterogeneity of local contexts and the place-relatedness of our knowledge about the world.\n\nMartina Löw developed the idea of a \"relational\" model of space, which focuses on the “orderings” of living entities and social goods, and examines how space is constituted in processes of perception, recall, or ideation to manifest itself as societal structure. From a social theory point of view, it follows on from the theory of structuration proposed by Anthony Giddens, whose concept of the “duality of structure” Löw extends sociological terms into a “duality of space.” The basic idea is that individuals act as social agents (and constitute spaces in the process), but that their action depends on economic, legal, social, cultural, and, finally, spatial structures. Spaces are hence the outcome of action. At the same time, spaces structure action, that is to say spaces can both constrain and enable action.\n\nWith respect to the constitution of space, Löw distinguishes analytically between two, generally mutually determining factors: “spacing” and “synthesis.” Spacing refers to the act of placing or the state of being placed of social goods and people in places. According to Löw, however, an ordering created through placings is only effectively constituted as space where the elements that compose it are actively interlinked by people – in processes of perception, ideation, or recall. Löw calls this synthesis. This concept has been empirically tested in studies such as those by Lars Meier (who examined the constitution of space in the everyday life of financial managers in London and Singapore), Cedric Janowicz (who carried out an ethnographical-space sociological study of food supply in the Ghanaian city of Accra), and Silke Streets (who looked at processes of space constitution in the creative industries in Leipzig).\n\nThe most important proponent of Marxist spatial theory was Henri Lefebvre. He proposed \"social space\" to be where the relations of production are reproduced and that dialectical contradictions were spatial rather than temporal. Lefèbvre sees the societal production of space as a dialectical interaction between three factors. Space is constituted:\n\n\nIn Lefebvre’s view of the 1970s, this spatial production resulted in a space of non-reflexive everydayness marked by alienation, dominating through mathematical-abstract concepts of space, and reproduced in spatial practice. Lefebvre sees a line of flight from alienated spatiality in the spaces of representation – in notions of non-alienated, mythical, pre-modern, or artistic visions of space.\n\nMarxist spatial theory was given decisive new impetus by David Harvey, in particular, who was interested in the effects of the transition from Fordism to “flexible accumulation” on the experience of space and time. He shows how various innovations at the economic and technological levels have breached the crisis-prone inflexibility of the Fordist system, thus increasing the turnover rate of capital. This causes a general acceleration of economic cycles. According to Harvey, the result is “time-space compression.” While the feeling for the long term, for the future, for continuity is lost, the relationship between proximity and distance becomes more and more difficult to determine.\n\nTheories of space that are inspired by the post-colonialism discourse focus on the heterogeneity of spaces. According to Doreen Massey, calling a country in Africa a “developing country” is not appropriate, since this expression implies that spatial difference is temporal difference (Massey 1999b). This logic treats such a country not as different but merely as an early version of countries in the “developed” world, a view she condemns as \"Eurocentrism.\" In this vein, Helmuth Berking criticises theories that postulate the increasing homogenisation of the world through globalisation as “globocentrism.” He confronts this with the distinctiveness and importance of local knowledge resources for the production of (different and specific) places. He claims that local contexts form a sort of framework or filter through which global processes and globally circulating images and symbols are appropriated, thus attaining meaning. For instance, the film character Conan the Barbarian is a different figure in radical rightwing circles in Germany than in the black ghettoes of the Chicago Southside, just as McDonald’s means something different in Moscow than in Paris.\n\nHenri Lefebvre (see also Edward Soja) says that (social) space is a (social) product, or a complex social construction (based on values, and the social production of meanings) which affects spatial practices and perceptions. He explains space embraces a multitude of intersection in his great book, “Production of Space”. That means that we need to consider how the various modes of spatial production relate to each other.\n\nHe argues that there are three aspects to our spatial existence, which exist in a kind of triad:\n\n1. First Space\n\"The spatial practice of a society secretes that society's space; it propounds and presupposes it, in a dialectical interaction; it produces it slowly and surely as it masters and appropriates it.\"\n\n2. Second Space\n\"Conceptualized space, the space of scientists, planners, urbanists, technocratic subdividers and social engineers, as of a certain type of artist with a scientific bent -- all of whom identify what is lived and what is perceived with what is conceived.\"\n\n3. Third Space\n\"Space as directly lived through its associated images and symbols.\"\n\nEven though there are many disciplines in the study of Human Geography, the most well-known approach is “The third space” formulated by Edward Soja. In unitary theory, there are three approaches; first space, second space and third space. First space is physical space, and spaces are measurable and mappable. The second space is a mental or conceived space which comes from our thinking and ideas. However, the third space is a social space/lived space which is a social product that is a space created by society under oppression or marginalization that want to reclaim the space of inequality and make it into something else. Soja argues that our old ways to thinking about space (first and second space theories) can no longer accommodate the way the world works because he believed that spaces may not be contained within one social category, they may include different aspects of many categories or developed within the boundaries of a number of category. For instance, two different cultures combine together and emerge as a third culture. This third hybrid space displaces the original values that constitute it and set up new values and perspectives that is different from the first two spaces. Thus, the third space theory can explain some of the complexity of poverty, social exclusion and social inclusion, gender and race issues.\n\nIn the work of geographer and critical theorist Nigel Thrift, he wrote a rational view of space in which, rather than seeing space being viewed as a container within which the world proceeds, space should be seen as a co-product of these proceedings. He explained about four constructed space in modern human geography. \nThere are four different kinds of space according to how modern geography thinks about space. They are 1. Empirical Construction of Space, 2. Unblocking space, 3. Image space and 4. Place Space.\n\nFirst Space is the empirical construction of space. Empirical space refers to the process whereby the mundane fabric of daily life is constructed. These simple things like, cars, houses, mobiles, computers and roads are very simple but they are great achievements of our daily life and they play very important role in making up who we are today. For example, today’s technology such as GPS did not suddenly come into existence; in fact, it is laid down in the 18th century and developed throughout time. The first space is real and tangible, and it is also known as physical space.\nSecond space is the unblocking space. This type of space refers to the process whereby routine pathways of interaction as set up around which boundaries are often drawn. The routine may include the movement of office workers, the interaction of drunk teenagers, and the flow of goods, money, people, and information. Unlike the old time in geography when people accepted a space as blocked boundary (Example: A capitalist space, neoliberal space or city space), we began to realize that there is no such thing like boundaries in space. The space of the world is flowing and transforming continuously that it is very difficult to describe in a fixed way. The second space is ideology/conceptual and it is also known as mental space. For example, the second space will explain the behaviors of people from different social class and the social segregation among rich and poor people. \nThird space is the image space that refers to the process whereby the images has produced new kind of space. The images may be in different form and shape; ranging from painting to photograph, from portrait to post card, and from religious theme to entertainment. Nowadays, we are highly influenced by images in many ways and these certain images can tell us new social and cultures values, or something new about how we see the world. Images, symbols and sign do have some kind of spatial expression. \nFourth space is the place that refers to the process whereby spaces are ordered in ways that open up affective and other embodied potentials. Place space has more meaning than a place, and it can represent as different type of space. This fourth type of space tries to understand that place is a vital actor in bringing up people's lives in certain ways and place will let us to understand all kind of things which are hidden form us..\n\nAndrew Herod mentioned that scale, within human geography, is typically seen in one of the two ways: either as a real material thing which actually exists and is the result of political struggle and/or social process, or as a way of framing our understanding of the world. People’s lives across the globe have been re-scaling by contemporary economic, political, cultural and social processes, such as globalization, in complex ways. As a result, we have seen the creation of supra-national political bodies such as the European Union, the devolution of political power from the nation-state to regional political bodies. We have also experienced the increasing homogenization and ‘Americanization’ through the process of globalization while the locals’ tendencies (or counter force)among people who defend traditional ways of life increase around the world .The process of re-scaling people‘s lives and the relationship between the two extremes of our scaled lives- the ‘global’ and the ‘local’ were brought into question.\n\nUntil the 1980s, theorizing the concept of ‘scale’ itself was taken for granted although physical and human geographers looked at issues from ‘regional scale’ or‘national scale’. The questions such as whether scale is simply a mental device categorizing and ordering the world or whether scales really exists as material social products, particularly, were debated among materialists and idealists. Some geographers draw upon Immanuel Kant’s idealist philosophy that scales were handy conceptual mechanism for ordering the world while others, by drawing upon Marxist ideas of materialism, argue that scales really exist in the world and they were the real social products. For those idealists based on Kantian‘s inspiration, the ‘global’ is defined by the geologically given limits of the earth and the ‘local’ is defined as a spatial resolution useful for comprehending the process and practices. For materialists, the ‘national’ scale is a scale that had to be actively created through economic and political processes but not a scale existed in a logical hierarchy between global and the regional.\n\nThe notion of ‘becoming’ and the focus on the politics of producing scales have been central to materialist arguments concerning the global scale. It is important to recognize that social actors may have to work just as hard to become ‘local’as they have to work to become ‘global’. People paid attention to how transnational corporations have ‘gone global’, how institutions of governance have‘become’ supra-national and how labour unions have sought to ‘globalize’ their operations to match those of an increasingly ‘globalized’ city.\n\nFor the scale ‘global’ and ‘local’, Kevin Cox mentioned that moving from the local to the global scale ‘is not a movement from one discrete arena to another’ but a process of developing networks of associations that allow actors to shift between various spaces of engagement. According to his view, ‘scale’ is seen as a process rather than as a fixed entity and, in other words, the global and the local are not static ’arenas’within which social life plays out but are constantly made by social actions.For example, a political organization might attempt to go ‘global’ to engage with actors or opportunities outside of its own space; likewise, a transnational corporation may attempt to ‘go local’ through tailoring its products and operations in different places.\n\nGibson-Graham (2002) has identified at least six ways in which the relationship between the local and the global is often viewed.\n\n1. The global and the local are seen as interpretive frames for analyzing situations\n\n2. Drawing on Dirlik, Gibson-Graham suggests that in such a representation, the global is ‘something more than the national or regional ..anything other than the local’. Meaning that, the global and the local each derive meaning from what they are not.\n\n3. According to French social theorist Bruno Latour, the local and the global ‘offer different points of view on networks that are by nature neither local nor global, but are more or less long and more or less connected. Also, in Latour’s view, it is impossible to distinguish where the local ends and the global begins.\n\n4. The concept ‘The global is local’ was proposed by Gibson-Graham. For instance, multinational firms are actually ‘multi local‘ rather than ‘global’.\n\n5. The local is global. In this view, the local is an entry point to the world of global flows which encircle the planet.\n\n6. The global and the local are actually the processes rather than the locations. All spaces are the hybrids of global and local; so they are ‘glocal.’\n\nThere are some western thoughts that greater size and extensiveness imply domination and superior power, such that the local is often represented as ‘small and relatively powerless, defined and confined by the global’. So, the global is a force and the local is its field of play. However, the local can serve as a powerful scale of political organization; the global is not a scale just controlled by capital – those who challenge capital can also organize globally( Herod, A). There has been the concept ‘Think globally and act locally’ viewed by neoliberals.\n\nFor representing how the world is scaled, there are five different and popular metaphors: they are the ladder, concentric circles, Matryoshka nesting dolls, earthworm burrows and tree roots. First, in using such a metaphor of hierarchical ladder, the global as the highest rung on the ladder is seen to be above the local and all other scales. Second, the use of concentric metaphor leaves us with a particular way of conceptualizing the scalar relationship between places. In this second metaphor, the local is seen as a relatively small circle, with the regional as a larger circle encompassing it, while the national and the global scales are still larger circles encompassing the local and the regional. For the hierarchy of Russian Matryoshka nesting dolls, the global can contain other scales but this does not work the other way round; for instance, the local cannot contain the global. For the fourth metaphor concerning with thinking on scale, what French social theorist Bruno Latour argued is that a world of places is ‘networked’ together. Such the metaphor leaves us with an image of scale in which the global and the local are connected together and not totally separated from each other. For the tree roots metaphor similar with the earthworm burrow metaphor, as the earthworm burrows or tree roots penetrating different strata of the soil, it is difficult to determine exactly where one scale ends and another begins. When thinking about the use of metaphor, it should be aware that the choice of metaphor over another is not made on the basis of which is empirically a ‘more accurate’representation of something but, on the basis of how someone is attempting to understand a particular phenomenon.\n\nSuch an appreciation of metaphors is important because it suggests that how we talk about scale impacts upon the ways in which we engage socially and politically with our scaled world and that may impact on how we conduct our social, economic and political praxis and so make landscapes ( Herod,A )\n\n\n"}
{"id": "2435087", "url": "https://en.wikipedia.org/wiki?curid=2435087", "title": "The Rock (Michigan State University)", "text": "The Rock (Michigan State University)\n\nThe Rock is a boulder on the campus of Michigan State University. Once popular as a trysting site, today it serves as a billboard for campus groups and events. \n\nThe Rock was unearthed in 1873 near what is now the corner of Grand River Avenue (M-43) and Michigan Avenue in East Lansing, Michigan. It was donated to the (Michigan) State Agricultural College by the class of 1873. The college placed the rock in the \"Sacred Space\" near the modern day Beaumont Tower, where the stone became a common hangout for young couples and became known as the \"Engagement Rock\". By the late 20th Century, the rock had become better known for protest slogans than engagement photos. In 1985, it was moved to its current location, east of Farm Lane, on the north bank of the Red Cedar River. Today, the innumerable layers of paint obliterate the original inscription: \"Class '73\".\n\nThe Rock can be painted on by anyone, and is used for anything from birthday wishes and marriage proposals to political statements. The Rock is also a hot spot for rival universities to paint. As a result, during football and basketball season MSU students often camp next to the Rock to protect it.\n\nOne of the most poignant moments in the history of the Rock occurred on the evening of September 11, 2001. Within hours of the September 11, 2001 attacks, virtually every activist group on campus, along with the university administration, had organized an impromtpu candlelight vigil at the floodplain next to the Rock. The Rock was painted green and white with the words \"MSU students in remembrance and reflection\" on the front, and an American flag on the back. Several thousand students attended. In a break from normal rock-painting etiquette, the university asked all campus groups to abstain from repainting the Rock for one week.\nOn Wednesday, April 9, 2014, at 9:00 pm, hundreds gathered at the rock to hold a vigil for Lacey Holsworth, dubbed \"Princess Lacey\", a young 8-year-old girl, with terminal cancer, who befriended the MSU Basketball team and whose story was a source of inspiration nationwide. The rock was painted white, with \"MSU Loves Princess Lacey\" on the front, and \"Love Like Lacey\" on the base. Students then proceeded to sign the rock with a black sharpie, leaving their own personal messages to Lacey, who had passed that morning. \nThroughout Thursday, dozens of students an hour stopped at the rock, adding their names, leaving flowers, and paying their respects. A movement, highlighted by an article in the Detroit News, sought to ban all future painting of the rock, and to preserve it as a permanent memorial to Lacey. But by April 21, 2014, four days after her memorial, it was repainted with the message \"Congratulations graduates, be a hero to someone\"\n\n"}
{"id": "3431556", "url": "https://en.wikipedia.org/wiki?curid=3431556", "title": "Turbosteamer", "text": "Turbosteamer\n\nA turbosteamer is a term used by BMW to describe a combined cycle engine. Waste heat energy from the internal combustion engine would be used to generate steam (see Waste Heat Recovery Unit) for a steam engine which would create supplemental power for the vehicle. The turbosteamer device is affixed to the exhaust and cooling system. It salvages the heat wasted in the exhaust and radiator (as much as 80% of heat energy) and uses a steam piston or turbine to relay that power to the crankshaft. The steam circuit produces and of torque at peak (for a 1.8 Straight-4 engine), yielding an estimated 15% gain in fuel efficiency. Unlike gasoline-electric hybrids, these gains increase at higher, steadier speeds.\n\nBMW has been the pioneer of this concept as early as 2000 under the direction of Dr. Raymond Freymann, and while they were designing this system to fit to most current BMW models, the technology didn't reach production.\n\n\n\n"}
{"id": "7958430", "url": "https://en.wikipedia.org/wiki?curid=7958430", "title": "Turkish Airlines Flight 5904", "text": "Turkish Airlines Flight 5904\n\nTurkish Airlines Flight 5904 was a Boeing 737-400 on an international repositioning flight from Adana Şakirpaşa Airport in Adana, Turkey to King Abdulaziz International Airport in Jeddah, Saudi Arabia which crashed on 7 April 1999 in the vicinity of Ceyhan, Adana Province in southern Turkey some eight minutes after takeoff. The flight was on its way to Saudi Arabia to pick up pilgrims from Jeddah and as such took off without any passengers on board. All six crew members however were killed in the crash.\n\nThe aircraft operating Flight 5904 was a 1995-built Boeing 737-400, registered as TC-JEP and named \"Trakya\". Owned by ILFC, – an American aircraft lessor – it was equipped with two CFM International CFM56 engines and had accumulated around 11.600 flight hours in 6.360 flight cycles up until the time of the crash.\n\nThe preceding flight from King Abdulaziz International Airport in Jeddah, Saudi Arabia had transferred 150 pilgrims returning from Hajj back to Adana Şakirpaşa Airport, where it landed without any problems at around 23:45 EET (20:45 UTC). Remaining on the ground for around one hour for refueling, Flight 5904 took off with a new crew – two pilots and four flight attendants – and with around 10 to 15 tons of fuel at 00:36 EET in order to pick up more pilgrims from Jeddah.\n\nBefore takeoff, upon request by the crew, the air traffic controller at Incirlik Air Base relayed the weather report and told the crew that the entire aerodrome was completely covered by thunderstorms and that the thunderstorms were moving from the south towards the north.\n\nAround eight minutes into the flight, at 00:44 EET, at an altitude of around and without any sign of inconvenience, the aircraft started to plunge nose-down into the ground and crashed into a field some east-northeast of the airport near Hamdilli village in the vicinity of Ceyhan in Adana Province. The force of the impact created of deep and large hole. The horizontal stabilizer of the aircraft was discovered some away from the main wreckage which was spread over an area of around . All six occupants were instantly killed.\n\nAfter the aircraft vanished from radar without any prenotice, air traffic controllers at Adana Airport and at Incirlik Air Base immediately notified the Gendarmerie and the police to initiate search and rescue efforts. At around that time, a large explosion was reported near Hamdili village around east of Ceyhan in Adana Province.\n\nThe investigation into the accident was carried out by Turkey's Directorate General of Civil Aviation (DGCA). The cockpit voice recorder revealed that while the crew was struggling to regain control of the aircraft, at least some of the four flight attendants were inside the cockpit panicking and screaming. The copilot was heard telling the captain \"aman ağabey, gittik, gidiyoruz, bas..\" (which roughly translates into \"Oh brother, we've gone, we're going, push...\").\n\nThe final report concluded that:\n"}
{"id": "6324034", "url": "https://en.wikipedia.org/wiki?curid=6324034", "title": "Uglies", "text": "Uglies\n\nUglies is a 2005 science fiction novel by Scott Westerfeld. It is set in a future post scarcity dystopian world in which everyone is considered an \"ugly\", but then turned \"Pretty\" by extreme cosmetic surgery when they reach the age 16. It tells the story of teenager Tally Youngblood who rebels against society's enforced conformity, after her newfound friends Shay and David show her the downsides to becoming a \"Pretty\".\n\nWritten for young adults, \"Uglies\" deals with themes of change, both emotional and physical. The book is the first installment in what was originally a trilogy, the \"Uglies\" series, which also includes the books \"Pretties\", \"Specials\", and \"Extras\". In 2018, four new installments within the Uglies Universe were announced, to be titled the Imposters Series.\n\nThree hundred years in the future, the government provides for everything, including plastic surgery operations. Everyone on their sixteenth birthday receives the “pretty” operation which transforms them into the society's standard of beautiful. After the operation, new Pretties cross the river that divides the city and lead a new life with no responsibilities or obligations. There are two other operations available, one to transform Pretties into “Middle-Pretties” (adults with a job), and another to transform Middle-Pretties into \"Crumblies\".\n\nFormer cities have decayed after bacteria infected the world's petroleum, making it unstable. The old society, so dependent on oil, fell apart when cars and oil fields exploded and food could no longer be transported. People who lived before this catastrophe are called \"Rusties.\"\n\nTally Youngblood is almost sixteen. Like every other Ugly, she awaits the operation with great anticipation. Her best friend, Peris, has already had the operation and, motivated by her desire to see him, Tally sneaks across the river to New Pretty Town. There she meets Shay, another Ugly. They become friends and Shay teaches Tally how to ride a hoverboard. Shay also mentions rebelling against the operation. At first, Tally ignores the idea, but is forced to deal with it when Shay runs away a few days before their shared sixteenth birthday, leaving behind cryptic directions to her destination, a “renegade settlement” called the Smoke, where city runaways go to escape the operation.\n\nOn the day of Tally’s operation, she is taken to Special Circumstances, a division that is likened to “gremlins” and, “[blamed] when anything weird happens.\" Dr. Cable, a woman who is described as “a cruel pretty”, is the head of Special Circumstances. She gives Tally an ultimatum to either help locate Shay and the Smoke, or never become a pretty. Tally cooperates and Dr. Cable gives her a hoverboard and all the needed supplies to survive in the wild, along with a heart locket that contains a tracking device. Once activated, it will show the location of the Smoke to Special Circumstances. Following Shay's clues, Tally sets off to find her friend.\n\nWhen Tally arrives at the Smoke, she finds Shay, her friend David and an entire community of runaway Uglies. She is reluctant to activate the pendant and it eventually becomes clear that David is in love with her. David takes her to meet his parents, Maddy and Az, who are the original runaways from the city. They explain how the operation does more than “cosmetic nipping and tucking.” It also causes lesions in the brain to make the people placid, or “pretty-minded.” Horrified, Tally decides to keep the Smoke secret and throws the locket into a fire. However, the flames' heat causes the tracker to activate, giving away the Smoke’s location.\n\nThe following morning, Special Circumstances arrives at the camp and Tally makes an effort to escape. She does not succeed and is caught and taken to a rabbit pen, where other caught Smokies are kept, tied up. Eye scans are taken of all the captured Smokies, identifying from which city they fled. Tally is then taken to Dr. Cable, who explains how they found the Smoke. Dr. Cable thinks Tally purposefully activated the pendant. After being ordered to retrieve the pendant, Tally escapes on a hoverboard. After a long and stressful chase, she manages to hide in a cave where they cannot track her heat signature. There she finds David also hiding and together, they begin to plan a rescue.\n\nTally and David go back to his house, where they find evidence that Special Circumstances took Maddy and Az. David leads Tally to a secret stash of survival equipment where they find everything they need, and load them onto the four hoverboards stashed there. As Tally and David travel back to the city to free their friends, they fall in love. Arriving at the Special Circumstances complex, they discover that Shay has already been “turned” and is now a Pretty. After meeting Dr. Cable, David knocks her out and takes her work tablet, which contains all the necessary information to reverse the brain lesions created by the Pretty operation. Tally and David then free all the Smokies held in the complex. As they escape the complex, Maddy tells David that his father, Az, is dead.\n\nOnce everyone is safe, Maddy begins working on a cure using Dr. Cable’s tablet. She then offers it to Shay, who refuses, not wanting to become a “vegetable.” Since Tally feels responsible for her betrayal, she decides to become a Pretty and take the cure as a “willing subject”. To convince David to let her go back to the city, she tells him about her involvement with Special Circumstances and searching for the Smoke to betray them. While David is absorbing what Tally admitted, Maddy advises Tally to go back with Shay before she changes her mind. Once there, Tally announces to a Middle Pretty, “I’m Tally Youngblood. Make me pretty,” the final phrase of the novel.\n\n\n\n\n\nAccording to critics, Uglies contains themes of identity, particularly regarding teenagers. Phillip Gough said the government of Tally’s city, which controls what happens within the operation, “removes responsibility for identity, ” creating sameness and uniformity. By placing heavy emphasis on the role of individualism, the novel shows the importance of teen’s self-concept. Because identity is formed by “displacement,” and all citizens are carefully sheltered, there is no chance for them to branch out into independence. “Physical identity is determined by committees,\" noted Gough in his essay discussing Westerfeld’s novel. Due to the lack of choice, all “markers of physical identity” are destroyed by their government.\n\nKristi N. Scott and M. Heather Dragoo note that another recurring theme in the “image-obsessed society,” is beauty, and its recurring relationship with individuality. Gough agreed, commenting that “when everyone is equal, beauty loses its meaning”. Beauty went hand in hand with identity: Uglies were taught to think of their bodies and faces as “temporary”, something that would be replaced later with cosmetic surgery. A strong line is drawn to connect features with personality, and one critic stated that the characters develop “ugly” and “pretty” personalities with each stage of their operations.\n\nA “utopia resting on ruthless suppression of individual freedom” was Amanda Craig of The Times’s description of Tally’s city. Many critics identified the trend of a controlling government in the novel. People in the protagonist’s world are “programmed and designed by the Pretty committee, ” with no say-so in their operation, and identity is placed firmly “in the hands of the state”. Dragoo and Scott point out how segregated the city is, with Pretties, Uglies, Middlies, and Crumblies neatly divided into different sections. Many reviewers have commented on the way in which the city manipulates its inhabitants, including the supposedly rebellious uglies, who are nothing more than “docile bodies”. Bedies, the dystopian society depicted by Westerfeld includes a particularly common trope in the genre: the duality of spaces, the metropolis representing the totalitarian civilization and nature as a field for freedom.\n\nVarious critics also found a theme of humanity within Uglies. Phillip Gough noted that Pretties and Specials (those who worked for Special Circumstances) are “posthuman” because of their operations. Others, including Scott and Dragoo, argued against this, claiming “the human body provides an artistic and political canvas for intentional manipulation,\" and that this physical transformation can be an “outlet for humanity”. The novel Uglies seems to take no definite stance on it, though clearer points are shown in Pretties and Specials, the following books in the trilogy.\n\nWhen asked how he came up with the idea of \"Uglies,\" Westerfeld said, \"the inspiration came from a friend whose dentist asked him to consider getting cosmetic surgery.\" He is the son of a computer programmer for Univac, which meant he grew up familiar with the cutting edge of 1960s technology. Amanda Craig said that \"it is his prescient perception of how such inventions will lead to absolute loss of privacy which has elicited as much fan-mail as the issue of how looks dominate our lives.\" \n\nThe book shares many themes with the 1964 \"The Twilight Zone\" episode \"Number 12 Looks Just Like You\". The author of the books noted that he saw the episode in his childhood but had forgotten the details.\n\nIn the dedication page for Uglies, Westerfeld says: “This novel was shaped by a series of e-mail exchanges between myself and Ted Chiang about his story “Liking What You See: A Documentary.” His input on the manuscript was also invaluable.” In another interview, Westerfeld says that this documentary is about a new technology that enables an individual to turn off their ability to see beauty so they can focus on the deeper and more important parts of another individual. In a 2012 interview on Bookyurt, Westerfeld explained that his point in writing the book was not to make a big commentary on the issues with beauty, but to make people aware of the culture of retouching that is developing in the world and to be aware of our own ideas about beauty and our need to think for ourselves.\n\nThe novel has received mostly positive reviews. The Baroque Body praised the novel as having “creative slang, unique technical gadgets, and defining characteristics of personhood.” Cory Doctorow complimented its “perfect parables of adolescent life,” and stated that it is “fine science fiction for youth.\" Jennifer Mattson claimed it to be “ingenious. ” Reed Business Information praised the “convincing plot” and noted that it is “highly readable.”\n\nHowever, \"Publishers Weekly\" commented that Tally was a “rather passive protagonist,” and the United Kingdom Times complained that “Tally herself is a bit too vague as a character.” Critic Jennifer Mattson noted that the brisk pace of the novel as being “bad for convincing relationships.”\n\nThe novel sparked discussion over the use of plastic surgery to improve one's looks. The author said he has “received many letters from girls who have decided against having surgery since reading Uglies,” while others, sparked by Uglies, have started to ponder the ethics of changing your body’s appearance. Westerfeld has theorized that “having extreme cosmetic surgery will be like buying a $1,000 Gucci bag, an indication that you are a member of the privileged class.\" Critics echo his opinion. However, Westerfeld has also stated he “wouldn’t hesitate [to use plastic surgery] if he had a kid with port-wine stain. We have all been altering our appearances ever since clothing was invented.” Other critics have stated that while altering one's appearance with plastic surgery can be ethically debatable, the benefits of it to people who have need for it are tremendous.\n\nThere is also some moderate debate sparked by Uglies over the issue of monitoring people. The state has started to track teens through their cell phones and on occasion through dental implants. Westerfeld feels that this will “result in a total loss of privacy,” however, others feel that this technology is necessary to properly supervise people.\n\n20th Century Fox and producer John Davis (\"Eragon\") bought the film rights to the novel in 2006. The movie was originally supposed to be released in 2011, according to the Internet Movie Database, but the release date was pushed back.\n\nThe movie \"Uglies\" was once again in the works as of July 3, 2013.\n\nStill no news has followed as of May 18, 2018.\n\nSteven Cummings illustrated Uglies in a manga-style graphic novel written by Westerfeld and Devin K. Grayson called Shay's Story which tells the story from Shay's perspective. It was published in a black-and-white 5¾ x 8¼ inches format by Del Rey Manga in 2012.\n\nThe novel \"Uglies\" was first published in 2006, and re-released in 2011 with a new cover. It is the first part of a trilogy, with sequels \"Pretties\", and \"Specials\", and another book \"Extras\". The trilogy featured on the New York Times bestseller list for a significant amount of time. There has also been an audio recording made of the book (sad) (published in 2006), available on both CD and cassette.\n\n"}
{"id": "22087494", "url": "https://en.wikipedia.org/wiki?curid=22087494", "title": "Vergnet", "text": "Vergnet\n\nVergnet is a French wind turbine manufacturer headquartered in Orléans. The company also produces water pumps installed in Africa. \n\nVergnet wind turbines are small to midsize (the newest model is rated for 1MW) designed for operation in tropical countries: Caribbean, Africa, parts of Asia and South America. They are robust, designed to resist hurricanes (by parking the turbine close to the ground), and easy to assemble on site with self erecting components (no tall crane required) from factory-made kits.\n\nIn 2008, Vergnet got a large contract for 120 1MW turbines in Ethiopia. . \n\n"}
{"id": "2122027", "url": "https://en.wikipedia.org/wiki?curid=2122027", "title": "Yousef Al Omeir", "text": "Yousef Al Omeir\n\nYousef bin Omeir bin Yousef Al Muhairi is the chairman and CEO of the Abu Dhabi National Oil Company (ADNOC). Born in 1958 he is considered one of the doyens of the UAE Oil Industry and is very closely connected to the Royal Family of Abu Dhabi and Al Tayer family.\n\nHE Yousef Bin Omeir comes from one of the wealthiest families of Abu Dhabi. His family has extensive business interests in the country. Their businesses include licenses awarded to them to import choice goods into the country, real estate, construction, petroleum services and supply, military equipment supply and is also a large player in the service sector. Omeir Travels & Omeir Holidays are the biggest travel agency in the Emirate of Abu Dhabi and Omeir Automobiles is the sole importer of Peugeot cars into the UAE. The family also has huge stakes in many businesses in the Emirates. It is widely said that before the discovery of oil made the Royal Family stupendously rich, the Al Omeirs were the richest family in the entire country.\n\nAl Omeir served as the country's Oil Minister for several years before taking more domestic responsibilities as the chairman of ADNOC. Al Omeir also sits on the UAE's Supreme Petroleum Council, a powerful body that is responsible for the vast oil reserves of the country and the Emirate of Abu Dhabi.\n"}
