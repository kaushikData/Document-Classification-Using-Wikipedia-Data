{"id": "46630621", "url": "https://en.wikipedia.org/wiki?curid=46630621", "title": "Assyrian lion weights", "text": "Assyrian lion weights\n\nThe Assyrian lion weights are a group of bronze Mesopotamian weights from the 8th century BCE, with bilingual inscriptions in both cuneiform and Phoenician characters. The lion weights were discovered at Nimrud in the late 1840s and are now in the British Museum.\n\nThe weights date from the 8th century BCE and they have bilingual inscriptions in both cuneiform and Phoenician characters. The Phoenician inscriptions are epigraphically from the same period as the Mesha Stele. They are one of the most important groups of artifacts evidencing the \"Aramaic\" form of the Phoenician script. At the time of their discovery, they were the oldest Phoenician-style inscription that had been discovered.\n\nThe set form a regular series diminishing in size from 30 cm to 2 cm in length. The larger weights have handles cast on to the bodies, and the smaller have rings attached to them. The group of weights also included stone weights in the shape of ducks. The weights represent the earliest known uncontested example of the Aramaic numeral system. Eight of the lions are represented with the only known inscriptions from the short reign of Shalmaneser V. Other similar lion weights were excavated at the Iranian site of Susa in 1901 by the French archaeologist Jacques de Morgan and are now in the Louvre in Paris.\n\nThere are two known systems of weights and measures from the ancient Middle East. One system was based on a weight called the mina which could be broken down into sixty smaller weights called shekels. These lion weights, however, come from a different system which was based on the \"heavy mina\" which weighed about a kilogram. This system was still being used in the Persian period and is thought to have been used for weighing metals.\n\nThe weights were discovered by Austen Henry Layard in his earliest excavations at Nimrud (1845–51). A pair of lamassu were found at a gateway, one of which had fallen against the other and had broken into several pieces. After lifting the statue, Layard's team discovered under it sixteen lion weights. The artefacts were first deciphered by Edwin Norris, who confirmed that they had originally been used as weights.\n\n\n"}
{"id": "2460089", "url": "https://en.wikipedia.org/wiki?curid=2460089", "title": "Australian Nuclear Science and Technology Organisation", "text": "Australian Nuclear Science and Technology Organisation\n\nThe Australian Nuclear Science and Technology Organisation (ANSTO) is a statutory body of the Australian government, formed in 1987 to replace the Australian Atomic Energy Commission. Its head office and main facilities are in southern outskirts of Sydney at Lucas Heights, in the Sutherland Shire.\n\nThe Australian Nuclear Science & Technology Organisation (ANSTO) is Australia's national nuclear organisation and the centre of Australian nuclear expertise. The Australian Nuclear Science and Technology Organisation Act 1987 (Cth) prescribes its general purpose. The purpose is translated into action through corporate drivers of vision, mission and strategic goals.\n\n\nANSTO is governed by a Board of Directors chaired by former CEO of BAE Systems Saudi Arabia, James \"Jim\" McDowell. Erica Smyth from uranium exploration company Toro Energy is the Deputy Chair. The CEO, Dr Adrian \"Adi\" Paterson, manages the organisation.\n\nANSTO operates five research facilities: \n\n\nMajor research instruments include:\n\nANSTO also manufactures radiopharmaceuticals and performs commercial work such as silicon doping by nuclear transmutation.\n\nANSTO currently has two nuclear reactors onsite: HIFAR and the new OPAL from the Argentine company INVAP. HIFAR was permanently shut down on 30 January 2007. OPAL became operational in November 2006 and was officially opened 20 April 2007.\n\nIn 2017, ANTSO announced the creation of a NiMo-SiC alloy for use in molten salt reactors.\n\n\n"}
{"id": "27228351", "url": "https://en.wikipedia.org/wiki?curid=27228351", "title": "Axion Dark Matter Experiment", "text": "Axion Dark Matter Experiment\n\nThe Axion Dark Matter Experiment (ADMX, also written as \"Axion Dark Matter eXperiment\" in the project's documentation) uses a resonant microwave cavity within a large superconducting magnet to search for cold dark matter axions in the local galactic dark matter halo. Unusually for a dark matter detector, it is not located deep underground. Sited at the Center for Experimental Nuclear Physics and Astrophysics (CENPA) at the University of Washington, ADMX is a large collaborative effort with researchers from universities and laboratories around the world.\n\nThe axion is a hypothetical elementary particle originally postulated to solve the strong CP problem. The axion is also an extremely attractive dark matter candidate. The axion is the puzzle piece allowing these two mysteries to fit naturally into our understanding of the universe.\n\nThe axion was originally postulated to exist as part of the solution to the \"strong CP problem\". This problem arose from the observation that the strong force holding nuclei together and the weak force making nuclei decay differ in the amount of CP violation in their interactions. Weak interaction was expected to feed into the strong interactions (QCD), yielding appreciable QCD CP violation, but no such violation has been observed to very high accuracy. One solution to this Strong CP Problem ends up introducing a new particle called the axion. If the axion is very light, it interacts so weakly that it would be nearly impossible to detect but would be an ideal dark matter candidate. The ADMX experiment aims to detect this extraordinarily weakly coupled particle.\n\nAlthough dark matter can't be seen directly, its gravitational interactions with familiar matter leave unmistakable evidence for its existence. The universe we see today simply wouldn't look the way it does without dark matter. Approximately five times more abundant than ordinary matter, the nature of dark matter remains one of the biggest mysteries in physics today. In addition to solving the strong CP problem, the axion could provide an answer to the question \"what is dark matter made of?\" The axion is a neutral particle that is extraordinarily weakly interacting and could be produced in the right amount to constitute dark matter. If the dark matter accounting for the bulk of all matter in our universe is axions, ADMX is one of only few experiments able to detect it.\n\nPierre Sikivie invented the axion haloscope in 1983. After smaller scale experiments at the University of Florida demonstrated the practicality of the axion haloscope, ADMX was constructed at Lawrence Livermore National Laboratory in 1995. In 2010 ADMX moved to the Center for Experimental Physics and Astrophysics (CENPA) at the University of Washington. Led by Dr. Leslie Rosenberg, ADMX is undergoing an upgrade that will allow it to be sensitive to a broad range of plausible dark-matter axion masses and couplings.\n\nThe experiment (written as \"eXperiment\" in the project's documentation) is designed to detect the very weak conversion of dark matter axions into microwave photons in the presence of a strong magnetic field. Axion conversion into photons is stimulated by an apparatus consisting of an 8 tesla magnet and a cryogenically cooled high-Q tunable microwave cavity. When the cavity's resonant frequency is tuned to the axion mass, the interaction between nearby axions in the Milky Way halo and ADMX's magnetic field is enhanced. This results in the deposit of a very tiny amount of power (less than a yoctowatt) into the cavity.\n\nAn extraordinarily sensitive microwave receiver allows the very weak axion signal to be extracted from the noise. The experiment receiver features quantum-limited noise performance delivered by an exotic Superconducting QUantum Interference Device (SQUID) amplifier and lower temperatures from a He refrigerator. ADMX is the first experiment sensitive to realistic dark-matter axion masses and couplings and the improved detector allows an even more sensitive search.\n\nThe microwave cavity within the magnet bore is at the heart of ADMX. It is a circular cylinder, 1 meter long and 0.5 meter diameter. ADMX searches for axions by slowly scanning the cavity resonant frequency by adjusting positions of two tuning rods within the cavity. A signal appears when the cavity resonant frequency matches the axion mass.\n\nThe expected signal from axion decay is so small that the entire experiment is cooled to well below 4.2 kelvin with a liquid helium refrigerator to minimize thermal noise. The electric field within the cavity is sampled by a tiny antenna connected to an ultra-low-noise microwave receiver.\n\nThe ultra-low noise microwave receiver makes the experiment possible. The dominant background is thermal noise arising from the cavity and the receiver electronics. Signals from the cavity are amplified by an exotic cryogenic Superconducting QUantum Interference Device (SQUID) amplifier followed by ultralow noise cryogenic HFET amplifiers. The receiver then downconverts microwave cavity frequencies to a lower frequency that can be easily digitized and saved. The receiver chain is sensitive to powers smaller than 0.01 yoctowatts; this is the world's lowest-noise microwave receiver in a production environment.\n\nADMX has already eliminated one of the two axion benchmark models from 1.9 μeV to 3.53 μeV, assuming axions saturate the Milky Way's halo. ADMX hopes to exclude or discover 2 μeV to 20 μeV dark matter axions within the next 10 years. ADMX is undergoing an upgrade to the \"Definitive Experiment\"; this is sensitive to a very broad range of plausible dark-matter axion masses and couplings. Greater sensitivity will be possible with the upgrade to SQUID amplifiers and the addition of a dilution refrigerator.\n\nSeveral years ago, the ADMX amplifier noise temperature was around 2 K. Recently the amplifiers were replaced by SQUID amplifiers, which greatly lowered the noise (to less than 100 mK) and vastly improved sensitivity. ADMX has demonstrated that the SQUID amplifier allows for quantum-limited-power sensitivity. More recently, ADMX has acquired Josephson Parametric Amplifiers which allow quantum noise limited searches at higher frequencies.\n\nThe addition of a dilution refrigerator is the main focus of the ADMX upgrade program. The dilution refrigerator allows cooling the apparatus down to 100 mK or less, reducing the noise to 0.15 K, which makes data taking 400 times faster. This makes it the \"Definitive Experiment\".\n\nThe Haloscope at Yale Sensitive to Axion CDM, or HAYSTAC (formerly known as ADMX-High Frequency), hosted at Yale University, is using a Josephson Parametric Amplifier, 9 T magnet, and microwave cavity with radius of 5 cm and height 25 cm to search masses 19–24 µeV.\n\n"}
{"id": "57413006", "url": "https://en.wikipedia.org/wiki?curid=57413006", "title": "Baird Brothers Fine Hardwoods", "text": "Baird Brothers Fine Hardwoods\n\nBaird Brothers Fine Hardwoods is a privately held manufacturer and retailer of interior hardwood products. It has been family owned and operated since 1960. The company is headquartered in Canfield, Ohio.\n\nBaird Brothers manufactures and retails interior hardwood products. The company produces products as simple as dimensional lumber and hardwood flooring, to custom doors, mouldings, and other products.\n\nBaird Brothers Fine Hardwoods, also known by its incorporated name, Baird Brothers Sawmill, was founded in 1960.\n\nPresident Paul Baird, the last surviving founder, but the company still remains a family owned and operated business. Now into their second generation, the family business is conducted by Scott Baird, Mark Baird, Matt Baird, Lori Baird, Terry Baird, and Tim Baird.\n\nCurrently the company operates all of its business through its headquarters in Canfield, Ohio, doing most of its business through online and phone sales. Baird Brothers has an annual festival named the \"Red White & True Fall Festival\". The company has evolved from a small operation to a nationwide corporation housing their finished product in warehouses spanning more than 200 yards.\n"}
{"id": "2739214", "url": "https://en.wikipedia.org/wiki?curid=2739214", "title": "Balance spring", "text": "Balance spring\n\nA balance spring, or hairspring, is a spring attached to the balance wheel in mechanical timepieces. It causes the balance wheel to oscillate with a resonant frequency when the timepiece is running, which controls the speed at which the wheels of the timepiece turn, and thus the rate of movement of the hands. A regulator lever is often fitted, which can be used to alter the free length of the spring and thereby adjust the rate of the timepiece.\n\nThe balance spring is a fine spiral or helical torsion spring used in mechanical watches, alarm clocks, kitchen timers, marine chronometers, and other timekeeping mechanisms to control the rate of oscillation of the balance wheel. The balance spring is an essential adjunct to the balance wheel, causing it to oscillate back and forth. The balance spring and balance wheel together form a harmonic oscillator, which oscillates with a precise period or \"beat\" resisting external disturbances, and is responsible for timekeeping accuracy.\n\nThe addition of the balance spring to the balance wheel around 1657 by Robert Hooke and Christiaan Huygens greatly increased the accuracy of portable timepieces, transforming early pocketwatches from expensive novelties to useful timekeepers. Improvements to the balance spring are responsible for further large increases in accuracy since that time. Modern balance springs are made of special low temperature coefficient alloys like nivarox to reduce the effects of temperature changes on the rate, and carefully shaped to minimize the effect of changes in drive force as the mainspring runs down. Before the 1980s, balance wheels and balance springs were used in virtually every portable timekeeping device, but in recent decades electronic quartz timekeeping technology has replaced mechanical clockwork, and the major remaining use of balance springs is in mechanical watches.\n\nThere is some dispute as to whether it was invented around 1660 by British physicist Robert Hooke or Dutch scientist Christiaan Huygens, with the likelihood being that Hooke first had the idea, but Huygens built the first functioning watch that used a balance spring. Before that time, balance wheels or foliots without springs were used in clocks and watches, but they were very sensitive to fluctuations in the driving force, causing the timepiece to slow down as the mainspring unwound. The introduction of the balance spring effected an enormous increase in the accuracy of pocketwatches, from perhaps several hours per day to 10 minutes per day, making them useful timekeepers for the first time. The first balance springs had only a few turns.\n\nA few early watches had a Barrow regulator, which used a worm drive, but the first widely used regulator was invented by Thomas Tompion around 1680. In the Tompion regulator the curb pins were mounted on a semicircular toothed rack, which was adjusted by fitting a key to a cog and turning it. The modern regulator, a lever pivoted concentrically with the balance wheel, was patented by Joseph Bosley in 1755, but it didn't replace the Tompion regulator until the early 19th century.\n\nIn order to adjust the rate, the balance spring usually has a \"regulator\". The regulator is a moveable lever mounted on the balance cock or bridge, pivoted coaxially with the balance. A narrow slot is formed on one end of the regulator by two downward projecting pins, called curb pins, or by a curb pin and a pin with a heavier section called a boot. The end of the outer turn of the balance spring is fixed in a stud which is secured to the balance cock. The outer turn of the spring then passes through the regulator slot. The portion of the spring between the stud and the slot is held stationary, so the position of the slot controls the free length of the spring. Moving the regulator slides the slot along the outer turn of the spring, changing its effective length. Moving the slot away from the stud shortens the spring, making it stiffer, increasing the balance's oscillation rate, and making the timepiece gain time.\n\nThe regulator interferes slightly with the motion of the spring, causing inaccuracy, so precision timepieces like marine chronometers and some high end watches are \"free sprung\", meaning they don't have a regulator. Instead, their rate is adjusted by timing screws on the balance wheel.\n\nThere are two principal types of Balance Spring Regulator.\n\nThere is also a \"Hog's Hair\" or \"Pig's Bristle\" regulator, in which stiff fibres are positioned at the extremities of the Balance's arc, and bring it to a gentle halt before throwing it back. The Watch is accelerated by shortening the arc. This is not a Balance Spring Regulator, being used in the earliest Watches before the Balance Spring was invented.\n\nThere is also a Barrow Regulator, but this is really the earlier of the two principal methods of giving the Mainspring \"set-up tension\"; that required to keep the Fusee chain in tension but not enough to actually drive the Watch. Verge Watches can be regulated by adjusting the set-up tension, but if any of the previously described Regulators is present then this is not usually done.\n\nA number of materials have been used for balance springs. Early on, steel was used, but without any hardening or tempering process applied; as a result, these springs would gradually weaken and the watch would start losing time. Some watchmakers, for example John Arnold, used gold, which avoids the problem of corrosion but retains the problem of gradual weakening. Hardened and tempered steel was first used by John Harrison and subsequently remained the material of choice until the 20th century.\n\nIn 1833, E. J. Dent (maker of the Great Clock of the Houses of Parliament) experimented with a glass balance spring. This was much less affected by heat than steel, reducing the compensation required, and also didn't rust. Other trials with glass springs revealed that they were difficult and expensive to make, and they suffered from a widespread perception of fragility, which persisted until the time of fibreglass and fibre-optic materials.\n\nThe modulus of elasticity of materials is dependent on temperature. For most materials, this temperature coefficient is large enough that variations in temperature significantly affect the timekeeping of a balance wheel and balance spring. The earliest makers of watches with balance springs, such as Robert Hooke and Christiaan Huygens, observed this effect without finding a solution to it.\n\nJohn Harrison, in the course of his development of the marine chronometer, solved the problem by a \"compensation curb\" – essentially a bimetallic thermometer which adjusted the effective length of the balance spring as a function of temperature. While this scheme worked well enough to allow Harrison to meet the standards set by the Longitude Act, it was not widely adopted.\n\nAround 1765, Pierre Le Roy (son of Julien Le Roy) invented the compensation balance, which became the standard approach for temperature compensation in watches and chronometers. In this approach, the shape of the balance is altered, or adjusting weights are moved on the spokes or rim of the balance, by a temperature-sensitive mechanism. This changes the moment of inertia of the balance wheel, and the change is adjusted such that it compensates for the change in modulus of elasticity of the balance spring. The compensating balance design of Thomas Earnshaw, which consists simply of a balance wheel with bimetallic rim, became the standard solution for temperature compensation.\n\nWhile the compensating balance was effective as a way to compensate for the effect of temperature on the balance spring, it could not provide a complete solution. The basic design suffers from \"middle temperature error\": if the compensation is adjusted to be exact at extremes of temperature, then it will be slightly off at temperatures between those extremes. Various \"auxiliary compensation\" mechanisms were designed to avoid this, but they all suffer from being complex and hard to adjust.\n\nAround 1900, a fundamentally different solution was created by Charles Édouard Guillaume, inventor of elinvar. This is a nickel-steel alloy with the property that the modulus of elasticity is essentially unaffected by temperature. A watch fitted with an elinvar balance spring requires either no temperature compensation at all, or very little. This simplifies the mechanism, and it also means that middle temperature error is eliminated as well, or at a minimum is drastically reduced.\n\nA balance spring obeys Hooke's Law: the restoring torque is proportional to the angular displacement. When this property is exactly satisfied, the balance spring is said to be \"isochronous\", and the period of oscillation is independent of the amplitude of oscillation. This is an essential property for accurate timekeeping, because no mechanical drive train can provide absolutely constant driving force. This is particularly true in watches and portable clocks which are powered by a mainspring, which provides a diminishing drive force as it unwinds. Another cause of varying driving force is friction, which varies as the lubricating oil ages.\n\nEarly watchmakers empirically found approaches to make their balance springs isochronous. For example, John Arnold in 1776 patented a helical (cylindrical) form of the balance spring, in which the ends of the spring were coiled inwards. In 1861 M. Phillips published a theoretical treatment of the problem. He demonstrated that a balance spring whose center of gravity coincides with the axis of the balance wheel is isochronous.\n\nIn general practice, the most common method of achieving isochronism is through the use of the Breguet overcoil, which places part of the outermost turn of the hairspring in a different plane from the rest of the spring. This allows the hairspring to \"breathe\" more evenly and symmetrically. Two types of overcoils are found - the gradual overcoil and the Z-Bend. The gradual overcoil is obtained by imposing two gradual twists to the hairspring, forming the rise to the second plane over half the circumference. The Z-bend does this by imposing two kinks of complementary 45 degree angles, accomplishing a rise to the second plane in about three spring section heights. The second method is done for aesthetic reasons and is much more difficult to perform. Due to the difficulty with forming an overcoil, modern watches often use a slightly less effective \"dogleg\", which uses a series of sharp bends (in plane) to place part of the outermost coil out of the way of the rest of the spring.\n\nThe balance spring and the balance wheel (which is usually referred to as simply \"the balance\") form a harmonic oscillator. The balance spring provides a restoring couple that limits and reverses the motion of the balance so it oscillates back and forth. The motion of the balance is approximately simple harmonic motion, i.e., a sinusoidal motion of constant period. Its resonant period makes it resistant to changes from perturbing forces, which is what makes it a good timekeeping device. The stiffness of the spring, its spring coefficient, formula_1 in N*m/radian, along with the balance wheel's moment of inertia, formula_2 in kg*m, determines the wheel's oscillation period formula_3 in seconds:\nThis period controls the rate of the timepiece.\n\n"}
{"id": "46351363", "url": "https://en.wikipedia.org/wiki?curid=46351363", "title": "Before Vanishing", "text": "Before Vanishing\n\nBefore Vanishing is a French language Syrian documentary film directed by Joude Gorani.<ref name=\"DoermannMaryland/UMIACS2005\"></ref>\n\nThe director of the film sets out for a journey from the beginning to the end of the Barada river and discovers a number of facts like unplanned urbanization and pollution.\n\nThe documentary is directed by Joude Gorani as her graduation project.\n"}
{"id": "9774491", "url": "https://en.wikipedia.org/wiki?curid=9774491", "title": "Biomass heating system", "text": "Biomass heating system\n\nBiomass heating systems generate heat from biomass.<br>\nThe systems fall under the categories of:\n\nThe use of biomass in heating systems is beneficial because it uses agricultural, forest, urban and industrial residues and waste to produce heat and electricity with less effect on the environment than fossil fuels. This type of energy production has a limited long-term effect on the environment because the carbon in biomass is part of the natural carbon cycle; while the carbon in fossil fuels is not, and permanently adds carbon to the environment when burned for fuel (carbon footprint). Historically, before the use of fossil fuels in significant quantities, biomass in the form of wood fuel provided most of humanity's heating.\n\nOn a large scale, the use of biomass removes agricultural land from food production, reduces the carbon sequestration capacity of forests, and extracts nutrients from the soil. Combustion of biomass creates air pollutants and adds significant quantities of carbon to the atmosphere that may not be returned to the soil for many decades.\n\nUsing biomass as a fuel produces air pollution in the form of carbon monoxide, NOx (nitrogen oxides), VOCs (volatile organic compounds), particulates and other pollutants, in some cases at levels above those from traditional fuel sources such as coal or natural gas. Black carbon – a pollutant created by incomplete combustion of fossil fuels, biofuels, and biomass – is possibly the second largest contributor to global warming. In 2009 a Swedish study of the giant brown haze that periodically covers large areas in South Asia determined that it had been principally produced by biomass burning, and to a lesser extent by fossil-fuel burning. Researchers measured a significant concentration of C, which is associated with recent plant life rather than with fossil fuels.\n\nOn combustion, the carbon from biomass is released into the atmosphere as carbon dioxide (CO). The amount of carbon stored in dry wood is approximately 50% by weight. When from agricultural sources, plant matter used as a fuel can be replaced by planting for new growth. When the biomass is from forests, the time to recapture the carbon stored is generally longer, and the carbon storage capacity of the forest may be reduced overall if destructive forestry techniques are employed.\n\nThe biomass-is-carbon-neutral proposal put forward in the early 1990s has been superseded by more recent science that recognizes that mature, intact forests sequester carbon more effectively than cut-over areas. When a tree’s carbon is released into the atmosphere in a single pulse, it contributes to climate change much more than woodland timber rotting slowly over decades. Current studies indicate that \"even after 50 years the forest has not recovered to its initial carbon storage\" and \"the optimal strategy is likely to be protection of the standing forest\".\n\nThe oil price increases since 2003 and consequent price increases for natural gas and coal have increased the value of biomass for heat generation. Forest renderings, agricultural waste, and crops grown specifically for energy production become competitive as the prices of energy dense fossil fuels rise. Efforts to develop this potential may have the effect of regenerating mismanaged croplands and be a cog in the wheel of a decentralized, multi-dimensional renewable energy industry. Efforts to promote and advance these methods became common throughout the European Union through the 2000s. In other areas of the world, inefficient and polluting means to generate heat from biomass coupled with poor forest practices have significantly added to environmental degradation.\n\nBuffer tanks store the hot water the biomass appliance generates and circulates it around the heating system. Sometimes referred to as 'thermal stores', they are crucial for the efficient operation of all biomass boilers where the system loading fluctuates rapidly, or the volume of water in the complete hydraulic system is relatively small. Using a suitably sized buffer vessel prevents rapid cycling of the boiler when the loading is below the minimum boiler output. Rapid cycling of the boiler causes a large increase in harmful emissions such as Carbon monoxide, dust, and NOx, greatly reduces boiler efficiency and increases electrical consumption of the unit. In addition, service and maintenance requirements will be increased as parts are stressed by rapid heating and cooling cycles. Although most boilers claim to be able to turn down to 30% of nominal output, in the real world this is often not achievable due to differences in the fuel from the 'ideal' or test fuel. A suitably sized buffer tank should therefore be considered where the loading of the boiler drops below 50% of the nominal output – in other words unless the biomass component is purely base load, the system should include a buffer tank. In any case where the secondary system does not contain sufficient water for safe removal of residual heat from the biomass boiler irrespective of the loading conditions, the system must include a suitably sized buffer tank. The residual heat from a biomass unit varies greatly depending on the boiler design and the thermal mass of the combustion chamber. Light weight, fast response boilers require only 10L/kW, while industrial wet wood units with very high thermal mass require 40L/kW.\n\nThe use of Biomass in heating systems has a use in many different types of buildings, and all have different uses. There are four main types of heating systems that use biomass to heat a boiler. The types are Fully Automated, Semi-Automated, Pellet-Fired, and Combined Heat and Power.\n\nIn fully automated systems chipped or ground up waste wood is brought to the site by delivery trucks and dropped into a holding tank. A system of conveyors then transports the wood from the holding tank to the boiler at a certain managed rate. This rate is managed by computer controls and a laser that measures the load of fuel the conveyor is bringing in. The system automatically goes on and off to maintain the pressure and temperature within the boiler. Fully automated systems offer a great deal of ease in their operation because they only require the operator of the system to control the computer, and not the transport of wood while offering comprehensive and cost effective solutions to complex industrial challenges.\n\nSemi-automated or \"Surge Bin\" systems are very similar to fully automated systems except they require more manpower to keep operational. They have smaller holding tanks, and a much simpler conveyor systems which will require personnel to maintain the systems operation. The reasoning for the changes from the fully automated system is the efficiency of the system. The heat created by the combustor can be used to directly heat the air or it can be used to heat water in a boiler system which acts as the medium by which the heat is delivered. Wood fire fueled boilers are most efficient when they are running at their highest capacity, and the heat required most days of the year will not be the peak heat requirement for the year. Considering that the system will only need to run at a high capacity a few days of the year, it is made to meet the requirements for the majority of the year to maintain its high efficiency.\n\nThe third main type of biomass heating systems are pellet-fired systems. Pellets are a processed form of wood, which make them more expensive. Although they are more expensive, they are much more condensed and uniform, and therefore are more efficient. Further, it is relatively easy to automatically feed pellets to boilers. In these systems, the pellets are stored in a grain-type storage silo, and gravity is used to move them to the boiler. The storage requirements are much smaller for pellet-fired systems because of their condensed nature, which also helps cut down costs. these systems are used for a wide variety of facilities, but they are most efficient and cost effective for places where space for storage and conveyor systems is limited, and where the pellets are made fairly close to the facility.\n\nOne subcategory of pellet systems are boilers or burners capable of burning pellet with higher ash rate (paper pellets, hay pellets, straw pellets). One of this kind is PETROJET pellet burner with rotating cylindrical burning chamber.\nIn terms of efficiencies advanced pellet boilers can exceed other forms of biomass because of the more stable fuel charataristics. Advanced pellet boilers can even work in condensing mode and cool down combustion gases to 30-40 °C, instead of 120 °C before sent into the flue.\n\nCombined heat and power systems are very useful systems in which wood waste, such as wood chips, is used to generate power, and heat is created as a byproduct of the power generation system. They have a very high cost because of the high pressure operation. Because of this high pressure operation, the need for a highly trained operator is mandatory, and will raise the cost of operation. Another drawback is that while they produce electricity they will produce heat, and if producing heat is not desirable for certain parts of the year, the addition of a cooling tower is necessary, and will also raise the cost.\n\nThere are certain situations where CHP is a good option. Wood product manufacturers would use a combined heat and power system because they have a large supply of waste wood, and a need for both heat and power. Other places where these systems would be optimal are hospitals and prisons, which need energy, and heat for hot water. These systems are sized so that they will produce enough heat to match the average heat load so that no additional heat is needed, and a cooling tower is not needed.\n\n\n"}
{"id": "40333285", "url": "https://en.wikipedia.org/wiki?curid=40333285", "title": "Cis-2-Decenoic acid", "text": "Cis-2-Decenoic acid\n\n\"cis\"-2-Decenoic acid is a fatty acid made by \"Pseudomonas aeruginosa\". It could be used to fight again Biofilm implied in infectious diseases, that are present in more than 60% of Hospital-acquired infection.\n"}
{"id": "23234121", "url": "https://en.wikipedia.org/wiki?curid=23234121", "title": "Constructible set (topology)", "text": "Constructible set (topology)\n\nIn topology, a constructible set in a topological space is a finite union of locally closed sets. (A set is locally closed if it is the intersection of an open set and closed set, or equivalently, if it is open in its closure.) Constructible sets form a Boolean algebra (i.e., it is closed under finite union and complementation.) In fact, the constructible sets are precisely the Boolean algebra generated by open sets and closed sets; hence, the name \"constructible\". The notion appears in classical algebraic geometry.\n\nChevalley's theorem (EGA IV, 1.8.4.) states: Let formula_1 be a morphism of finite presentation of schemes. Then the image of any constructible set under \"f\" is constructible. In particular, the image of a variety need not be a variety, but is (under the assumptions) always a constructible set. For example, the map formula_2 that sends formula_3 to formula_4 has image the set formula_5, which is not a variety, but is constructible.\n\nIn any (not necessarily Noetherian) topological space, every constructible set contains a dense open subset of its closure.\n\nWarning: In EGA III, Def.9.1.2, constructible sets are defined using only \"retrocompact\" opens. That is, the family of constructible sets of a topological space is defined as the smallest family closed under finite intersection and complement and containing all \"retrocompact\" open subsets.\n\nSo for example, the origin formula_6 in the infinite affine space formula_7 is \"not\" constructible.\n\nIn any locally noetherian topological space, \"all\" subsets are retrocompact (EGA III, 9.1), so the two definitions are the same in this setting.\n\n"}
{"id": "1951419", "url": "https://en.wikipedia.org/wiki?curid=1951419", "title": "Critical point (thermodynamics)", "text": "Critical point (thermodynamics)\n\nIn thermodynamics, a critical point (or critical state) is the end point of a phase equilibrium curve. The most prominent example is the liquid-vapor critical point, the end point of the pressure-temperature curve that designates conditions under which a liquid and its vapor can coexist. At higher temperatures, the gas cannot be liquefied by pressure alone. At the critical point, defined by a \"critical temperature\" \"T\" and a \"critical pressure\" \"p\", phase boundaries vanish. Other examples include the liquid–liquid critical points in mixtures.\n\nFor simplicity and clarity, the generic notion of \"critical point\" is best introduced by discussing a specific example, the liquid-vapor critical point. This was the first critical point to be discovered, and it is still the best known and most studied one.\n\nThe figure to the right shows the schematic PT diagram of a \"pure substance\" (as opposed to mixtures, which have additional state variables and richer phase diagrams, discussed below). The commonly known phases \"solid\", \"liquid\" and \"vapor\" are separated by phase boundaries, i.e. pressure-temperature combinations where two phases can coexist. At the triple point, all three phases can coexist. However, the liquid-vapor boundary terminates in an endpoint at some \"critical temperature\" \"T\" and \"critical pressure\" \"p\". This is the \"critical point\".\n\nIn water, the critical point occurs at around 647 K (374 °C or 705 °F) and 22.064 MPa (3200 psia or 218 atm).\n\nIn the \"vicinity\" of the critical point, the physical properties of the liquid and the vapor change dramatically, with both phases becoming ever more similar. For instance, liquid water under normal conditions is nearly incompressible, has a low thermal expansion coefficient, has a high dielectric constant, and is an excellent solvent for electrolytes. Near the critical point, all these properties change into the exact opposite: water becomes compressible, expandable, a poor dielectric, a bad solvent for electrolytes, and prefers to mix with nonpolar gases and organic molecules.\n\n\"At\" the critical point, only one phase exists. The heat of vaporization is zero. There is a stationary inflection point in the constant-temperature line (\"critical isotherm\") on a PV diagram. This means that at the critical point:\n\n\"Above\" the critical point there exists a state of matter that is continuously connected with (can be transformed without phase transition into) both the liquid and the gaseous state. It is called supercritical fluid. The common textbook knowledge that all distinction between liquid and vapor disappears beyond the critical point has been challenged by Fisher and Widom who identified a p,T-line that separates states with different asymptotic statistical properties (Fisher-Widom line).\n\nThe existence of a critical point was first discovered by Charles Cagniard de la Tour in 1822 and named by Dmitri Mendeleev in 1860 and Thomas Andrews in 1869. Cagniard showed that CO could be liquefied at 31 °C at a pressure of 73 atm, but not at a slightly higher temperature, even under pressures as high as 3,000 atm.\n\nSolving the above condition formula_3 for the van der Waals equation, one can compute the critical point as \nHowever, the van der Waals equation, based on a mean field theory, does not hold near the critical point. In particular, it predicts wrong scaling laws.\n\nTo analyse properties of fluids near the critical point, reduced state variables are sometimes defined relative to the critical properties\n\nThe principle of corresponding states indicates that substances at equal reduced pressures and temperatures have equal reduced volumes. This relationship is approximately true for many substances, but becomes increasingly inaccurate for large values of \"p\".\n\nFor some gases, there is an additional correction factor, called \"Newton's correction\", added to the critical temperature and critical pressure calculated in this manner. These are empirically derived values and vary with the pressure range of interest.\n\nThe liquid–liquid critical point of a solution, which occurs at the \"critical solution temperature\", occurs at the limit of the two-phase region of the phase diagram. In other words, it is the point at which an infinitesimal change in some thermodynamic variable (such as temperature or pressure) will lead to separation of the mixture into two distinct liquid phases, as shown in the polymer–solvent phase diagram to the right. Two types of liquid–liquid critical points are the upper critical solution temperature (UCST), which is the hottest point at which cooling will induce phase separation, and the lower critical solution temperature (LCST), which is the coldest point at which heating will induce phase separation.\n\nFrom a theoretical standpoint, the liquid–liquid critical point represents the temperature-concentration extremum of the spinodal curve (as can be seen in the figure to the right). Thus, the liquid–liquid critical point in a two-component system must satisfy two conditions: the condition of the spinodal curve (the \"second\" derivative of the free energy with respect to concentration must equal zero), and the extremum condition (the \"third\" derivative of the free energy with respect to concentration must also equal zero or the derivative of the spinodal temperature with respect to concentration must equal zero).\n\n"}
{"id": "56883685", "url": "https://en.wikipedia.org/wiki?curid=56883685", "title": "DIGI Group", "text": "DIGI Group\n\nDIGI (Teraoka/DIGI Group) is a global corporation with offices in Japan, Europe and North America. Founded in 1934, it supplies weighing and packaging equipment for trade, industries, and logistics. Its products are widely used in the manufacturing, retail, and consumer fields. The company occupies 30% of the Russian market of weighing scales.\n\nAlthough the company dates back to 1934, its activity dates back to 1910, when industrialist Teraoka Toyonaru created the Japan Calculation Machinery Manufacturing Co, which was focused on innovative technologies and supporting inventions. It produced precision instruments for industries and consumers. At the time of its inception, Teraoka had already developed weight scales capable of functioning under different temperature environments, which had been patented in Japan, the United States, the United Kingdom, Germany and France. Establishing itself firmly in its market, Teraoka Takeharu, son of Toyonaru, started the Teraoka Research Center (Teraoka Seiko Co., Ltd.), which would eventually form part of Teraoka/DIGI Group. The corporation presently operates five R&D centres and five production sites across Europe and Asia, as well as its own line of strain gauges.\n\n\n\n\n"}
{"id": "54200847", "url": "https://en.wikipedia.org/wiki?curid=54200847", "title": "Dislocation avalanches", "text": "Dislocation avalanches\n\nDislocation avalanches are rapid discreet events during plastic deformation, in which defects are reorganized collectively. This intermittent flow behavior has been observed in microcrystals, whereas macroscopic plasticity appears as a smooth process. Intermittent plastic flow has been observed in several different systems. In AlMg Alloys, interaction between solute and dislocations can cause sudden jump during dynamic strain aging. In metallic glass, it can be observed via shear banding with stress localization; and single crystal plasticity, it shows up as slip burst. However, analysis of the events with orders-magnitude difference in sizes with different crystallographic structure reveals power-law scaling between the number of events and their magnitude, or scale-free flow. \n\nThis microscopic instability of plasticity can have profound consequences on mechanical behavior of microcrystals. The increased relative size of the fluctuations makes it difficult to control the plastic forming process. Moreover, at small specimen sizes the yield stress is not well defined by the 0.2% plastic strain criterion anymore, since this value varies specimen by specimen.\n\nSimilar intermittent effects has been studied in many completely different systems, including intermittency of energy dissipation in magnetism(Barkhausen effect), superconductivity, earthquakes, and friction.\n\nMacroscopic plasticity are well-described by continuum model. Dislocations motions are characterized by an average velocity\nwhich is known as Orowan's equation. However, this approach completely fails to account for well-known intermittent deformation phenomena such as the spatial localization of dislocation flow into “slip bands” (also known as Lüders band) and the temporal fluctuations in stress-strain curves (the Portevin–Le Chatelier effect first reported in the 1920s).\n\nAlthough evidence of intermittent flow behavior is long known and studied, it is not until past two decades that a quantitative understanding of the phenomenon is developed with help of novel experimental techniques. \nAcoustic emission (AE) is used to record the crackling noise from deforming crystals. The amplitudes of the acoustic signals can be related to the area swept by the fast-moving dislocations and hence to the energy dissipated during deformation events. The result shows that cracking noise is not smooth, with no specific energy scale. Effect of grain structure for “supercritical” flow has been studied in polycrystalline ice. \nRecent developments in small scale mechanical testing, with sub-nm resolution in displacement and sub-μN resolution in force, now allow to directly study discrete events in stress and strain. Currently, the most prominent method is a miniaturized compression experiment, where a nanoindenter equipped with a flat indentation tip is used. Equipped with in-situ techniques in combination with Transmission electron microscopy (TEM), Scanning electron microscopy (SEM), and micro-diffraction methods, this nanomechanical testing method can give us rich detail in nanoscale plasticity instabilities in real time. \n\nOne potential concern in nanomechanical measurement is: how fast can the system respond? Can indentation tip remain contact with the sample and track the deformation? Since dislocation velocity is strongly effected by stress, velocity can be many orders different in different systems. Also, multiscale nature of dislocation avalanche event gives dislocation velocity a large range. For example, single dislocations have been shown to move at speeds of ∼10 ms in pure Cu, but dislocation groups moved with ∼10 ms in Cu-0.5%Al. The opposite is found for iron, where dislocation groups are found to move six orders of magnitude faster in a FeSi-alloy than individual dislocations in pure iron.\n\nTo resolve this issue, Sparks et al. has designed an experiment to measure first fracture of Si beam and compare with theoretical prediction to determine the respond speed of the system. In addition to regular compression experiments, in-situ electrical contact resistance measurements (ECR) were performed. During these in-situ tests, a constant voltage was applied during the deformation experiment to record current evolution during intermittent plastic flow. Result shows that indentation tip remains contact with the sample throughout experiments, which proves the respond speed is fast enough. \nAvalanche strain distributions have the general form\nwhere C is a normalization constant, t is a scaling exponent, and s is the characteristic strain of the largest avalanches.\n\nDislocation dynamic simulation has shown that formula_3 is close to 1.5, which is in good agreement with mean-field theory prediction. Simulation results also revealed the scale free nature of dislocation avalanches and concluded that deformation of crystals having highly mobile dislocations exhibits the attributes of a self-organized critical (SOC) process.\nIn FCC crystal, scaled velocity shows a main peak in distribution with relatively smooth curve, which is expected from theory except for some disagreement at low velocity. However, in BCC crystal, distribution of scaled velocity is broader and much more dispersed. The result also shows that scaled velocity in BCC is a lot slower than FCC, which is not predicted by mean field theory. A possible explanation this discrepancy is based on different moving speed of edge and screw dislocations in two type of crystals. In FCC crystals, two parts of dislocation move at same velocity, resulting in smooth averaged avalanches profile; whereas in BCC crystals, edge components move fast and escape rapidly, while screw parts propagate slowly, which drag the overall velocity. Based on this explanation, we will also expect a direction dependence of avalanche events in HCP crystals, which currently lack in experimental data.\n"}
{"id": "10663427", "url": "https://en.wikipedia.org/wiki?curid=10663427", "title": "Dry Creek Pioneer Regional Park", "text": "Dry Creek Pioneer Regional Park\n\nDry Creek Pioneer Regional Park is a regional park located in Union City, California, sharing a contiguous border with sister park Garin Regional Park. It is part of the East Bay Regional Parks system.\n\n"}
{"id": "38103101", "url": "https://en.wikipedia.org/wiki?curid=38103101", "title": "Earth pyramids of Platten", "text": "Earth pyramids of Platten\n\nThe earth pyramids of Platten (German: \"Erdpyramiden von Platten\" or \"Erdpyramiden bei Oberwielenbach\"; ) are earth pyramids located in Platten in the municipality of Percha, near Bruneck in South Tyrol, Italy.\n\nThe erosion area is located at an altitude of 1550 to 1750 meters. What is so impressive about the pyramids of Platten is their wildness which reminds at the same time also of their fragility.\n\nThe pyramids of Platten belong to the most beautiful natural monuments of South Tyrol such as the earth pyramids of Ritten and part of the earth pyramids of South Tyrol.\n\nThey were described in a scientific manner for the first time by Karl Meusburger in 1914 .\n\nFollowing a cloudburst, a few centuries ago, there came a landslide which cut off the roads connecting the villages in the surroundings of Aschbach.\n\nIn 1882, again after a heavy cloudburst, a new fault was formed. Following eluviations and erosions these earth\npyramids are constantly changing; that is due to the succession of severe cold spells in winter and hot summers which have the effect of continually forming new ones.\n\nFrom the main road we deter at Percha/Percia and drive less than 6 km up into Oberwielenbach and beyond it a bit more to the big parking place. That road continues to the hamlet of Platten, but before reaching it, another narrow mountain road deters left, heading towards the Gönner Alm (alpine pasture). On the crossroads there's the inscription that this mountain road leads also towards the pyramids, but it is closed for public traffic (2017). So, it's best to start the walk up to the pyramids before, on the big parking place, 1430 m, or eventually later, from Platten.\n\nFrom the big parking place, 1430 m, a good, marked path goes up into the woods. First it ascends a bit, then does a lot of crossing the slopes towards the right. When we reach out of the woods, hitting the before mentioned mountain road, we follow the road only to the big left turn. From there we go into the forest again and in a few minutes we reach the big ravine with the pyramids. Some 30 minutes till here.\n\nTo return, it is best to use the approach route, even if we descend along the ravine to the lower lookout point. From there a path goes further down, but it descends more than needed and makes the return a bit longer.\n\n"}
{"id": "3211810", "url": "https://en.wikipedia.org/wiki?curid=3211810", "title": "Electrical Trades Union of Australia", "text": "Electrical Trades Union of Australia\n\nThe Electrical Trades Union of Australia (ETU) is a trade union in Australia which has a history stretching back over 100 years. In its modern form the ETU is a division of the Communications, Electrical and Plumbing Union (CEPU), although it is possibly the most well known of the three divisions. At a state registered level, the union often exists as a separately registered union as for example it does in Queensland.\n\nOn 24 December 1919 Electrical Trades Union of Australia federally re-registered under the Commonwealth Conciliation and Arbitration Act 1904 as an association of employees. This date is now taken as the official registration date of the Federal Union.\n\nWhilst being a part of the CEPU the union has carved out for itself a unique identity. It is well known for its militant attitude. Its members have long memories and openly berated Peter Beattie for giving former Queensland premier Joh Bjelke-Petersen a state funeral. The Bjelke-Petersen government had sacked ETU members working at SEQEB in 1985 during a bitter dispute over the privatization of work normally done by SEQEB employees. Like other trade unions of the left in Australia it has adopted the Eureka Flag as one of its logos.\n\nIn the lead-up to the 2010 federal election, the Victorian ETU withdrew its support for the Labor Party, citing Labor's refusal to scrap laws restricting union action on building sites. However, since then it has rejoined in the Australian Capital Territory and Victoria. Traditionally the ETU has sided with the Labor Left or equivalent faction in the state branches of the ALP with the notable exception of the ACT, where it aligns with the Centre Coalition (Labor Right) faction. It enjoys a close relationship there with the Shop, Distributive and Allied Employees Association (SDA) and the Australian Workers Union (AWU). Despite reaffiliating with Victorian Labor, in the leadup to the 2018 Victorian Election the ETU donated $50,000 towards a competing party, the Victorian Socialists.\n\n"}
{"id": "3825804", "url": "https://en.wikipedia.org/wiki?curid=3825804", "title": "Endgame: The Blueprint for Victory in the War on Terror", "text": "Endgame: The Blueprint for Victory in the War on Terror\n\nEndgame: The Blueprint for Victory in the War on Terror (, 2004) is a book by Lt.General Thomas McInerney, US Air Force, and Major General Paul E. Vallely, US Army, with forward remarks by CIA Director James Woolsey. It describes a super secret weapon system that is intended to neutralize nuclear weapons.\n\n\" I call upon the scientific community in our country, those who gave us nuclear weapons, to turn their talents now to the cause of mankind and world peace, to give us the means of rendering those weapons impotent and obsolete.\"\n\n--President Ronald Reagan, Address to the Nation, March 23, 1983 \n\nThe book states:\n\nIn 1981, when president Ronald Reagan and CIA director William J. Casey agreed and signed onto the SDI (Strategic Defense Initiative) — a missile defense shield against incoming nuclear warheads — they gave the green light for the secret development of the BHB weapon for deterrence purposes and peaceful use only. Although we have only limited information, it appears that Iran’s rapidly developing nuclear capabilities could be neutralized and rendered obsolete, as could the capabilities of other rogue countries.\"'\n\n"}
{"id": "2234049", "url": "https://en.wikipedia.org/wiki?curid=2234049", "title": "Enercell", "text": "Enercell\n\nEnercell is a battery brand that was sold exclusively by RadioShack at retail stores and online. \n\nIn a \"battery of the month club\" promotion introduced in the 1960s and abandoned in the early 1990s, RadioShack clients were issued a free wallet-sized cardboard card which entitled the bearer to one free battery a month when presented in RadioShack stores. The free Enercells were individual AA, C or D cells or 9V rectangular transistor radio batteries. Like the free tube testing offered in-store in the early 1970s, this small loss leader drew foot traffic.\n\nThere were two editions of a \"Enercell Battery Guidebook\", published in 1985 and 1990. The selector guide was later moved online. While the \"battery of the month\" card program ended in the 1990s, the Enercell name remained in use as RadioShack's store brand of dry cells and transistor radio batteries.\n\nRadioShack for several years sold batteries branded \"Enercell Plus\" that were marketed as \"Premium Alkaline\" batteries.\n\n"}
{"id": "43097069", "url": "https://en.wikipedia.org/wiki?curid=43097069", "title": "Energy4All", "text": "Energy4All\n\nEnergy4All facilitates the creation and development of wind turbine cooperatives in the United Kingdom, based on the experienced gained in the creation of the UK's first wind co-op, Baywind Energy Co-operative. It has gone on to raise at least £6million on behalf of the co-operatives, through community share offerings.\n\nWhilst not technically a co-operative itself, the organisation has helped create at least ten wind co-ops, including Westmill Wind Farm Co-operative and Boyndie Wind Farm Co-operative, who, along with Baywind, own Energy4All.\n\nOne of the co-operatives it has created, Energy Prospects Co-operative, specialises in taking early stage wind co-operatives through the development and planning application stages to the point where a community share offer, managed by Energy4All, can be launched to fund the project.\n\nThey won an Ashden Award in 2012.\n\n\n"}
{"id": "24940941", "url": "https://en.wikipedia.org/wiki?curid=24940941", "title": "Girardinus falcatus", "text": "Girardinus falcatus\n\nGirardinus falcatus is a species of Cuban tropical fish. The common name of the species is yellow belly. The fish is pale gold and has a bright blue iris. Males are smaller than females and constantly mate.\n"}
{"id": "21499557", "url": "https://en.wikipedia.org/wiki?curid=21499557", "title": "Guy Chichester", "text": "Guy Chichester\n\nGuy Chichester (February 11, 1935 – February 8, 2009) was a founding member of the Clamshell Alliance, an anti-nuclear group that led protests against Seabrook Station Nuclear Power Plant in the 1970s, which led to a broader environmental movement. Though the Seabrook power plant was eventually built, a planned second reactor at the site was cancelled. Several acts of protest at Seabrook, including one large demonstration that resulted in nearly 1,500 arrests, contributed to a turn public opinion against nuclear power in the USA in the 1970s. Then Governor Meldrim Thomson, a vocal supporter of the Seabrook plant, was defeated for re-election in 1978, in large part because of voter dissatisfaction over the rising cost of plant construction. \nA few years before the Seabrook protests, Chichester helped rally opposition to a plan by Aristotle Onassis to build an oil refinery on Great Bay in Durham, New Hampshire. He helped establish the national Green Party. Chichester was also a local organizer for George McGovern's 1972 presidential campaign. \n\nChichester was born and raised on Long Island, New York. He was a carpenter by trade. \n\n"}
{"id": "31161972", "url": "https://en.wikipedia.org/wiki?curid=31161972", "title": "IEC 61400", "text": "IEC 61400\n\nIEC 61400 is an International Standard published by the International Electrotechnical Commission regarding wind turbines.\n\nThe 61400 is a set of design requirements made to ensure that wind turbines are appropriately engineered against damage from hazards within the planned lifetime. The standard concerns most aspects of the turbine life from site conditions before construction, to turbine components being tested, assembled and operated.\n\nWind turbines are capital intensive, and are usually purchased before they are being erected and commissioned.\n\nSome of these standards provide technical conditions verifiable by an independent, third party, and as such are necessary in order to make business agreements so wind turbines can be financed and erected.\n\nIEC started standardizing international certification on the subject in 1995, and the first standard appeared in 2001.\n\nThe common set of standards sometimes replace the various national standards, forming a basis for global certification.\n\nSmall wind turbines are defined as being of up to 200 m swept area and a somewhat simplified IEC 61400-2 standard addresses these. It is also possible to use the IEC 61400-1 standard for turbines of less than 200 m swept area.\n\nThe standards for loads and noise are used in the development of prototypes at the Østerild Wind Turbine Test Field.\n\nIn the U.S., standards are intended to be compatible with IEC standards, and some parts of 61400 are required documentation.\n\nThe U.S. National Renewable Energy Laboratory participates in IEC standards development work, and tests equipment according to these standards. For U.S. offshore turbines however, more standards are needed, and the most important are :\nIn Canada, the previous national standards were outdated and impeded the wind industry, and they were updated and harmonized with 61400 by the Canadian Standards Association with several modifications.\n\nAn update for IEC 61400 is scheduled for 2016.\n\nFor small wind turbines the global industry has been working towards harmonisation of certification requirements with a \"test once, certify everywhere\" objective. Considerable co-operation has been taking place between UK, USA, and more recently Japan, Denmark and other countries so that the IEC 61400-2 standard as interpreted within e.g. the MCS certification scheme (of UK origin) is interoperable with the USA (for example where it corresponds to an AWEA small wind turbine standard) and other countries.\n\nWind turbines are designed for specific conditions. During the construction and design phase assumptions are made about the wind climate that the wind turbines will be exposed to. Turbine wind class is just one of the factors needing consideration during the complex process of planning a wind power plant. Wind classes determine which turbine is suitable for the normal wind conditions of a particular site. Turbine classes are determined by three parameters - the average wind speed, extreme 50-year gust, and turbulence.\n\nTurbulence intensity quantifies how much the wind varies typically within 10 minutes. Because the fatigue loads of a number of major components in a wind turbine are mainly caused by turbulence, the knowledge of how turbulent a site is of crucial importance. Normally the wind speed increases with increasing height. In flat terrain the wind speed increases logarithmically with height. In complex terrain the wind profile is not a simple increase and additionally a separation of the flow might occur, leading to heavily increased turbulence.\n\nThe extreme wind speeds are based on the 3 second average wind speed. Turbulence is measured at 15 m/s wind speed. This is the definition in IEC 61400-1 edition 2.\n\nFor U.S. waters however, several hurricanes have already exceeded wind class Ia with speeds above the 70 m/s (156 mph), and efforts are being made to provide suitable standards.\n\n\n\n"}
{"id": "3879492", "url": "https://en.wikipedia.org/wiki?curid=3879492", "title": "Idiotarod", "text": "Idiotarod\n\nThe Idiotarod is a shopping cart race in which teams of five \"idiots\" tie themselves to a (sometimes modified) grocery store shopping cart and run through the streets of a major metropolitan area. The race usually features people in costumes and themed floats. The races are fun competitions where sabotage, costume, and presentation are rewarded. Sabotage, such as tripping competitors, throwing marbles or large obstacles in their paths, and the spreading of misinformation such as false route information, is common.\n\nThe Idiotarod is named after the Iditarod, a 1,000 mile dog-sledding race in Alaska.\n\nIdiotarods take place in Ann Arbor, Asheville, Austin, Boston, Chicago, Cincinnati, Dallas, Denver, Iowa City, New York City, Phoenix, Portland, Salt Lake City, Seattle, St. Louis, Toronto, Los Angeles, Vancouver and Washington, D.C. though the original race was founded in San Francisco in 1994 as the \"Urban Iditarod\".\n\nThe Portland Urban Iditarod, which began in March 2001, runs through a course over four miles through downtown Portland, Oregon. This race occurs on the first Saturday of March, the same date as the actual Alaskan Iditarod. Racers wear \"absurd\" costumes, including Spanish bullfighters and diaper-wearing astronauts, and make stops at pubs and bars along the way. There are no winners or losers in the Portland event, but other cities offer a \"Best in Show\" prize.\n\nChicago's Urban Iditarod or Chiditarod, has been held annually on the first Saturday in March since 2006. Historically the race has occurred in and around the Chicago neighborhood of West Town. Much like other Urban Iditarods, a Chiditarod team includes 5 participants: 4 dawgs and a musher. Teams are required to use a regular shopping cart and are not allowed to modify the cart's original caster wheels. Beyond this limitation, teams are encouraged to take artistic liberties with their carts and participants often decorate their carts in highly creative ways and dress in costume to match their team's theme. Like a traditional race, teams compete to finish the course in as little time as possible, while making designated stops at checkpoints along the course. Participating teams are allowed and even encouraged to sabotage each other in order to gain advantage but most teams engage in sabotage merely for bragging rights. In the spirit of radical inclusion, the Chiditarod organizers hand out a number of awards in a variety of categories giving participants the freedom to compete in the fields they are best suited for.\n\nThe landmark of the Chiditarod is the event's charitable aspect. Billing itself as \"Probably the world's largest mobile food drive,\" the Chiditarod plays an important role in helping raise foods for Chicago's food depositories. Teams are asked to donate a minimum amount of high protein, non perishable food items. Another notable innovation is the organization's approach to self-policing. In an effort to keep all participants safe throughout the course, the Chiditarod deploys bike marshals who act as roaming course deputies: resolving disputes between teams, mitigating destructive sabotage, safeguarding participant conduct and lending a helping hand whenever necessary.\n\nIn 2014, the Iditarod Trail Sled Dog Race sent a cease-and-desist order to Idiotarod NYC, asserting that the name \"Idiotarod\" infringed its trademark in \"Iditarod.\" Idiotarod NYC characterized the letter as \"frivolous threats of legal action\", but renamed the event to \"Idiotarodorama NYC (aka 'The Desistarod')\".\n\n\n"}
{"id": "33992121", "url": "https://en.wikipedia.org/wiki?curid=33992121", "title": "Inertial response", "text": "Inertial response\n\nInertial Response is a property of large synchronous generators, which contain large synchronous rotating masses, and which acts to overcome the immediate imbalance between power supply and demand for electric power systems, typically the electrical grid. Due to the ever existing power imbalance between mechanical power supply and electric power demand the rotational frequency of the rotating masses in all sychronous generators in the grid either speed up (excess power supply) or slow down (excess power demand). This enables the grid operator to rebalance the system in order to stop the speed change, resulting in a relatively small variation in AC frequency ideally within the allowable frequency range of that system. i.e. A 50 Hz system may allow a ±0.5 Hz deviation in the frequency of the AC voltage\nThe grid frequency is the combined result of the detailed motions of all individual synchronous rotors in the grid, which are modeled by a general equation of motion called the Swing Equation.\n\nWhen the grid frequency is too high or too low, active power flow through the high-voltage direct current link will be ramped down or up. In turn, the wind generation will increase or decrease the blade angles to reduce or increase the captured wind power through pitch control.\n"}
{"id": "659414", "url": "https://en.wikipedia.org/wiki?curid=659414", "title": "Information-theoretic death", "text": "Information-theoretic death\n\nInformation-theoretic death is the scrambling of information within a brain to such an extent that recovery of the original person becomes theoretically impossible.\n\nInformation-theoretic death is an attempt to define death in a way that is permanent and independent of any future medical advances, no matter how distant or improbable that may be.\n\nBecause detailed reading or restoration of information-storing brain structures is well beyond current technology, it is generally not of practical importance in \"mainstream medicine\", though it is of great importance in cryonics, where consideration of future technology is important.\n\nRalph Merkle defined information-theoretic death as follows:\nSo defined, information-theoretic death has been called \"the ultimate definition of irreversible death\", and \"absolutely irreversible death\" in which \"destruction of the brain has occurred to such an extreme that any information it may have ever held is irrevocably lost for all eternity\".\n\nInformation-theoretic death has propagated into some mainstream bioethical, biophilosophical and religious discussions of death, and was mentioned in a 2007 \"Newsweek\" article on advances in treating cardiac arrest.\n"}
{"id": "31873414", "url": "https://en.wikipedia.org/wiki?curid=31873414", "title": "Isabella Psalter", "text": "Isabella Psalter\n\nThe Isabella Psalter (BSB Cod.gall. 16), also called the Psalter of Queen Isabella or the Psalter of Isabella of England, is a 14th-century volume containing the Book of Psalms, named for Isabella of France, who is herself depicted in it; it was likely a gift upon her betrothal or marriage. The illuminated manuscript is also notable for its bestiary.\n\nThe psalter was produced ca. 1303-1308. Like its \"closest relation,\" the Tickhill Psalter, it shows a French influence and is similar in content and style to the Queen Mary Psalter and the Ormesby Psalter. Like the Queen Mary and Tickhill psalters, and like the Egerton Gospel and the Holkham Picture Bible, some of its captions and illustrations can be traced to the 12th-century \"Historia scholastica\"; all these 14th-century manuscripts may have \"a thirteenth-century Parisian antecedent, reflected in the Tours Genesis window\" (in reference to a window in the clerestory of the Tours Cathedral). It is currently held in the Bavarian State Library, Munich.\n\nAccording to Donald Drew Egbert, the illuminators belong to the same group that illuminated the Tickhill Psalter. Art historian Ellen Beer, however, states that while there are similarities, Egbert is too quick to identify the illuminators (whom he connects to four other manuscripts as well). According to Beer, two of the illuminators responsible for the Psalter of St. Louis can be recognized in the Isabella Psalter.\n\nThe psalter measures and consists of 131 parchment pages. The first section is a calendar, with two illuminations per page, followed by a section with illuminations of scenes from the Old Testament and a complete bestiary, which (as in the Queen Mary Psalter) are executed as marginalia.\n\n\n"}
{"id": "35886071", "url": "https://en.wikipedia.org/wiki?curid=35886071", "title": "Isolation condensor", "text": "Isolation condensor\n\nIsolation condenser, isolation condensor (IC or “iso. condenser” or” isolation condenser system”) is, in a reactor core isolation cooling system (“RCIC”); one of the emergency reactor safety systems in some nuclear plants (boiling water reactor safety systems).\n\nIt is a passive system for cooling of some reactors (BWR/2, BWR/3 ..., and the (E)SBWR series) in nuclear production, located above containment in a pool of water open to atmosphere.\n\nIn operation, decay heat boils steam, which is drawn into the heat exchanger and condensed; then it falls by weight of gravity back into the reactor. This process keeps the cooling water in the reactor, making it unnecessary to use powered feedwater pumps. The water in the open pool slowly boils off, venting clean steam to the atmosphere. This makes it unnecessary to run mechanical systems to remove heat. Periodically, the pool must be refilled, a simple task for a fire truck. The (E)SBWR reactors provide three days' supply of water in the pool. Some older reactors also have IC systems, including Fukushima Dai-ichi reactor 1, however their water pools may not be as large.\n\nUnder normal conditions, the IC system is not activated, but the top of the IC condenser is connected to the reactor's steam lines through an open valve. Steam enters the IC condenser and condenses until it is filled with water. When the IC system is activated, a valve at the bottom of the IC condenser is opened which connects to a lower area on the reactor. The water falls to the reactor via gravity, allowing the condenser to fill with steam, which then condenses. This cycle runs continuously until the bottom valve is closed.\n\nIn case of electricity failure, the valves close automatically, and operators have to open them manually, which can be difficult in case of accident has already released radioactive steam inside the building.\n\nDuring the accident Fukushima nuclear plant in 2011, the operators did not open the valve manually, and emergency system had been activated too late and could not work for long. Operators did not know if they should've left the valves open or not when the tanks of two condensers were emptied of their water cooling.\n\n\n"}
{"id": "46560320", "url": "https://en.wikipedia.org/wiki?curid=46560320", "title": "Joint Organisations Data Initiative", "text": "Joint Organisations Data Initiative\n\nThe Joint Organisations Data Initiative (JODI) is an international collaboration to improve the availability and reliability of data on petroleum and natural gas. First named the \"Joint Oil Data Exercise\", the collaboration was launched in April 2001 with six international organisations: Asia-Pacific Economic Cooperation (APEC), Statistical Office of the European Communities (Eurostat), International Energy Agency (IEA), (OLADE), Organization of the Petroleum Exporting Countries (OPEC), and United Nations Statistics Division (UNSD). In 2005, the effort was renamed JODI, joined by the International Energy Forum (IEF), and covered more than 90% of the global oil market. The Gas Exporting Countries Forum (GECF) joined as an eighth partner in 2014, enabling JODI also to cover nearly 90% of the global market for natural gas.\n"}
{"id": "4990146", "url": "https://en.wikipedia.org/wiki?curid=4990146", "title": "Lahore Electric Supply Company", "text": "Lahore Electric Supply Company\n\nLahore Electric Supply Company (LESCO) is an electric distribution company which supplies electricity to Lahore, Punjab, Pakistan.\n\n"}
{"id": "15296588", "url": "https://en.wikipedia.org/wiki?curid=15296588", "title": "Linear molecular geometry", "text": "Linear molecular geometry\n\nIn chemistry, the linear molecular geometry describes the geometry around a central atom bonded to two other atoms (or \"ligands\") placed at a bond-angle of 180°. Linear organic molecules, such as acetylene (HC≡CH), are often described by invoking sp orbital hybridization for their carbon centers.\n\nAccording to the VSEPR model, linear geometry occurs at central atoms with two bonded atoms and zero or three lone pairs (AX or AXE) in the AXE notation. Neutral AX molecules with linear geometry include beryllium fluoride (F−Be−F) with two single bonds, carbon dioxide (O=C=O) with two double bonds, hydrogen cyanide (H−C≡N) with one single and one triple bond. The most important linear molecule with more than three atoms is acetylene (H−C≡C−H), in which each of its carbon atoms is considered to be a central atom with a single bond to one hydrogen and a triple bond to the other carbon atom. Linear anions include azide () and thiocyanate (SCN), and a linear cation is the nitronium ion ().\n\nLinear geometry also occurs in AXE molecules, such as xenon difluoride (XeF) and the triiodide ion () with one iodide bonded to the two others. As described by the VSEPR model, the five valence electron pairs on the central atom form a trigonal bipyramid in which the three lone pairs occupy the less crowded equatorial positions and the two bonded atoms occupy the two axial positions at the opposite ends of an axis, forming a linear molecule.\n\n\n"}
{"id": "1038887", "url": "https://en.wikipedia.org/wiki?curid=1038887", "title": "Natural gas vehicle", "text": "Natural gas vehicle\n\nA natural gas vehicle (NGV) is an alternative fuel vehicle that uses compressed natural gas (CNG) or liquefied natural gas (LNG). Natural gas vehicles should not be confused with vehicles powered by LPG (mainly propane), which is a fuel with a fundamentally different composition.\n\nIn a natural gas powered vehicle, energy is released by combustion of essentially Methane gas (CH4) fuel with Oxygen (O2) from the air to CO2 and water vapor (H2O) in an internal combustion engine. Methane is the cleanest burning hydrocarbon and many contaminants present in natural gas are removed at source.\n\nSafe, convenient and cost effective gas storage and fuelling is more of a challenge compared to petrol and diesel vehicles since the natural gas is pressurized and/or - in the case of LNG - the tank needs to be kept cold. This makes LNG unsuited for vehicles that are not in frequent use. The lower energy density of gases compared to liquid fuels is mitigated to a great extent by high compression or gas liquefaction, but requires a trade-off in terms of size/complexity/weight of the storage container, range of the vehicle between refueling stops, and time to refuel.\n\nAlthough similar storage technologies may be used for and similar compromises would apply to a hydrogen vehicle as part of a proposed new hydrogen economy, methane as a gaseous fuel is safer than hydrogen due to its lower flammability, low corrosivity and better leak tightness due to larger molecular weight/ size, resulting in lower price hardware solutions based on proven technology and conversions. A key advantage of using natural gas is the existence, in principle, of most of the infrastructure and the supply chain, which is non-interchangeable with hydrogen. Methane today mostly comes from non-renewable sources but can be supplied or produced from renewable sources, offering net carbon neutral mobility. In many markets, especially the Americas, natural gas may trade at a discount to other fossil fuel products such as petrol, diesel or coal, or indeed be a less valuable by-product associated with their production that has to be disposed. Many countries also provide tax incentives for natural gas powered vehicles due to the environmental benefits to society. Lower operating costs and government incentives to reduce pollution from heavy vehicles in urban areas have driven the adoption of NGV for commercial and public uses, i.e. trucks and buses.\n\nMany factors hold back NGV popularization for individual mobility applications, i.e. private vehicles, including: relatively price and environmentally insensitive but convenience seeking private individuals; good profits and taxes extractable from small batch sales of value-added, branded petrol and diesel fuels via established trade channels and oil refiners; resistance and safety concerns to increasing gas inventories in urban areas; dual-use of utility distribution networks originally built for home gas supply and allocation of network expansion costs; reluctance, effort and costs associated with switching; prestige and nostalgia associated with petroleum vehicles; fear of redundancy and disruption. A particular challenge may be the fact that refiners are currently set up to produce a certain fuels mix from crude oil. Aviation fuel is likely to remain the fuel of choice for aircraft due to their weight sensitivity for the foreseeable future.\n\nWorldwide, there were 24.452 million NGVs by 2016, led by China (5.0 million), Iran (4.00 million), India (3.045 million), Pakistan (3.0 million), Argentina (2.295 million), Brazil (1.781 million), and Italy (1.001 million). The Asia-Pacific region leads the world with 6.8 million vehicles, followed by Latin America with 4.2 million. In Latin America, almost 90% of NGVs have bi-fuel engines, allowing these vehicles to run on either gasoline or CNG. In Pakistan, almost every vehicle converted to (or manufactured for) alternative fuel use typically retains the capability of running on gasoline.\n\nAs of 2016, the U.S. had a fleet of 160,000 NG vehicles, including 3,176 LNG vehicles. Other countries where natural gas-powered buses are popular include India, Australia, Argentina, Germany, and Greece. In OECD countries, there are around 500,000 CNG vehicles. Pakistan's market share of NGVs was 61.1% in 2010, follow by Armenia with more than 77% (2014), and Bolivia with 20%. The number of NGV refueling stations has also increased, to 18,202 worldwide as of 2010, up 10.2% from the previous year.\n\nExisting gasoline-powered vehicles may be converted to run on CNG or LNG, and can be dedicated (running only on natural gas) or bi-fuel (running on either gasoline or natural gas). Diesel engines for heavy trucks and busses can also be converted and can be dedicated with the addition of new heads containing spark ignition systems, or can be run on a blend of diesel and natural gas, with the primary fuel being natural gas and a small amount of diesel fuel being used as an ignition source. It is also possible to generate energy in a small gas turbine and couple the gas engine or turbine with a small electric battery to create a hybrid electric motor driven vehicle. An increasing number of vehicles worldwide are being manufactured to run on CNG by major carmakers. Until recently, the Honda Civic GX was the only NGV commercially available in the US market. More recently, Ford, General Motors and Ram Trucks have bi-fuel offerings in their vehicle lineup. In 2006, the Brazilian subsidiary of FIAT introduced the Fiat Siena Tetra fuel, a four-fuel car that can run on natural gas (CNG).\n\nNGV filling stations can be located anywhere that natural gas lines exist. Compressors (CNG) or liquifaction plants (LNG) are usually built on large scale but with CNG small home refueling stations are possible. A company called FuelMaker pioneered such a system called Phill Home Refueling Appliance (known as \"Phill\"), which they developed in partnership with Honda for the American GX model. Phill is now manufactured and sold by BRC FuelMaker, a division of Fuel Systems Solutions, Inc.\n\nCNG may be generated and used for bulk storage and pipeline transport of renewable energy and also be mixed with biomethane, itself derived from biogas from landfills or anaerobic digestion. This would allow the use of CNG for mobility without increasing the concentration of carbon in the atmosphere. It would also allow continued use of CNG vehicles currently powered by non-renewable fossil fuels that do not become obsolete when stricter CO2 emissions regulations are mandated to combat global warming.\n\nDespite its advantages, the use of natural gas vehicles faces several limitations, including fuel storage and infrastructure available for delivery and distribution at fueling stations. CNG must be stored in high pressure cylinders (3000psi to 3600psi operation pressure), and LNG must be stored in cryogenic cylinders (-260F to -200F). These cylinders take up more space than gasoline or diesel tanks that can be molded in intricate shapes to store more fuel and use less on-vehicle space. CNG tanks are usually located in the vehicle's trunk or pickup bed, reducing the space available for other cargo. This problem can be solved by installing the tanks under the body of the vehicle, or on the roof (typical for busses), leaving cargo areas free. As with other alternative fuels, other barriers for widespread use of NGVs are natural gas distribution to and at fueling stations as well as the low number of CNG and LNG stations.\n\nCNG-powered vehicles are considered to be safer than gasoline-powered vehicles.\n\nExisting gasoline-powered vehicles may be converted to run on CNG or LNG, and can be dedicated (running only on natural gas) or bi-fuel (running on either gasoline or natural gas). However, an increasing number of vehicles worldwide are being manufactured to run on CNG. Until recently, the now-discontinued Honda Civic GX was the only NGV commercially available in the US market. More recently, Ford, General Motors and Ram Trucks have bi-fuel offerings in their vehicle lineup. Ford's approach is to offer a bi-fuel prep kit as a factory option, and then have the customer choose an authorized partner to install the natural gas equipment. Choosing GM's bi-fuel option sends the HD pickups with the 6.0L gasoline engine to IMPCO in Indiana to upfit the vehicle to run on CNG. Ram currently is the only pickup truck manufacturer with a truly CNG factory-installed bi-fuel system available in the U.S. market.\n\nOutside the U.S. GM do Brasil introduced the MultiPower engine in 2004, which was capable of using CNG, alcohol and gasoline (E20-E25 blend) as fuel, and it was used in the Chevrolet Astra 2.0 model 2005, aimed at the taxi market. In 2006, the Brazilian subsidiary of FIAT introduced the Fiat Siena Tetra fuel, a four-fuel car developed under Magneti Marelli of Fiat Brazil. This automobile can run on natural gas (CNG); 100% ethanol (E100); E20 to E25 gasoline blend, Brazil's mandatory gasoline; and pure gasoline, though no longer available in Brazil it is used in neighboring countries.\n\nIn 2015, Honda announced its decision to phase out the commercialization of natural-gas powered vehicles to focus on the development of a new generation of electrified vehicles such as hybrids, plug-in electric cars and hydrogen-powered fuel cell vehicles. Since 2008, Honda sold about 16,000 natural-gas vehicles, mainly to taxi and commercial fleets.\n\nThough LNG and CNG are both considered NGVs, the technologies are vastly different. Refueling equipment, fuel cost, pumps, tanks, hazards, capital costs are all different.\n\nOne thing they share is that due to engines made for gasoline, computer controlled valves to control fuel mixtures are required for both of them, often being proprietary and specific to the manufacturer. The on-engine technology for fuel metering is the same for LNG and CNG.\n\nCNG, or compressed natural gas, is stored at high pressure, . The required tank is more massive and costly than a conventional fuel tank. Commercial on-demand refueling stations are more expensive to operate than LNG stations because of the energy required for compression, the compressor requires 100 times more electrical power, however, slow-fill (many hours) can be cost-effective with LNG stations [missing citation - the initial liquefaction of natural gas by cooling requires more energy than gas compression]. Time to fill a CNG tank varies greatly depending on the station. Home refuelers typically fill at about 0.4 GGE/hr. \"Fast-fill\" stations may be able to refill a 10 GGE tank in 5–10 minutes. Also, because of the lower energy density, the range on CNG is limited by comparison to LNG. Gas composition and throughput allowing, it should be feasible to connect commercial CNG fueling stations to city gas networks, or enable home fueling of CNG vehicles directly using a gas compressor. Similar to a car battery, the CNG tank of a car could double as a home energy storage device and the compressor could be powered at times when there is excess/ free renewable electrical energy.\n\nLNG, or liquified natural gas, is natural gas that has been cooled to a point that it is a cryogenic liquid. In its liquid state, it is still more than 2 times as dense as CNG. LNG is usually dispensed from bulk storage tanks at LNG fuel stations at rates exceeding 20 DGE/min. Sometimes LNG is made locally from utility pipe. Because of its cryogenic nature, it is stored in specially designed insulated tanks. Generally speaking, these tanks operate at fairly low pressures (about 70-150 psi) when compared to CNG. A vaporizer is mounted in the fuel system that turns the LNG into a gas (which may simply be considered low pressure CNG). When comparing building a commercial LNG station with a CNG station, utility infrastructure, capital cost, and electricity heavily favor LNG over CNG. There are existing LCNG stations (both CNG and LNG), where fuel is stored as LNG, then vaporized to CNG on-demand. LCNG stations require less capital cost than fast-fill CNG stations alone, but more than LNG stations.\n\nLNG – and especially CNG – tends to corrode and wear the parts of an engine less rapidly than gasoline. Thus it is quite common to find diesel-engine NGVs with high mileages (over 500,000 miles). CNG also emits 20-29% less CO2 than diesel and gasoline. Emissions are cleaner, with lower emissions of carbon and lower particulate emissions per equivalent distance traveled. There is generally less wasted fuel. However, cost (monetary, environmental, pre-existing infrastructure) of distribution, compression, cooling must be taken into account.\n\nAutogas, also known as LPG, has different chemical composition, but still a petroleum based gas, has a number of inherent advantages and disadvantages, as well as noninherent ones. The inherent advantage of autogas over CNG is that it requires far less compression (20% of CNG cost), is denser as it is a liquid at room temperature, and thus requires far cheaper tanks (consumer) and fuel compressors (provider) than CNG. As compared to LNG, it requires no chilling (and thus less energy), or problems associated with extreme cold such as frostbite. Like NGV, it also has advantages over gasoline and diesel in cleaner emissions, along with less wear on engines over gasoline. The major drawback of LPG is its safety. The fuel is volatile and the fumes are heavier than air, which causes them to collect in a low spot in the event of a leak, making it far more hazardous to use and more care is needed in handling. Besides this, LPG (40% from Crude Oil refining) is more expensive than Natural Gas.\n\nIn places like the US, Thailand, and India, there are five to ten times more stations thus making the fuel more accessible than NGV stations. Other countries like Poland, South Korea, and Turkey, LPG stations and autos are widespread while NGVs are not. In addition, in some countries such as Thailand, the retail LPG fuel is considerably cheaper in cost.\n\nThough ANG (adsorbed natural gas) has not yet been used in either providing stations nor consumer storage tanks, its low compression (500psi vs 3600 psi) has the potential to drive down costs of NGV infrastructure and vehicle tanks.\n\nLNG is being evaluated and tested for over-the-road trucking, off-road, marine, and railroad applications. There are known problems with the fuel tanks and delivery of gas to the engine.\n\nChina has been a leader in the use of LNG vehicles with over 100,000 LNG powered vehicles on the road as of 2014.\n\nIn the United States, there were 69 public truck LNG fuel centres as of February 2015. The 2013 National Trucker's Directory lists approximately 7,000 truckstops, thus approximately 1% of US truckstops have LNG available.\n\nIn 2013, Dillon Transport announced they were putting 25 LNG large trucks into service in Dallas Texas. They are refueling at a public LNG fuel center. The same year Raven Transportation announced they were buying 36 LNG large trucks to be fueled by Clean Energy Fuels locations and Lowe's finished converting one of its dedicated fleets to LNG fueled trucks.\n\nUPS had over 1200 LNG fueled trucks on the roads in February 2015. UPS has 16,000 tractor trucks in its fleet, and 60 of the new for 2014 large trucks will be placed in service in the Houston, Texas area, where UPS is building its own private LNG fuel center to avoid the lines at retail fuel centers. In Amarillo, Texas and Oklahoma City, Oklahoma, UPS is using public fuel centers.\n\nClean Energy Fuels has opened several public LNG Fuel Lanes along I-10 and claims that as of June 2014 LNG fueled trucks can use the route from Los Angeles, California to Houston, Texas by refueling exclusively at Clean Energy Fuels public facilities. In 2014 Shell and Travel Centers of America opened the first of a planned network of U.S. truck stop LNG stations in Ontario, California. Per the alternative fuel fuelling centre tracking site there are 10 LNG capable public fuel stations in the greater Los Angeles area, making it the single most penetrated metro market. As of February 2015, Blu LNG has at least 23 operational LNG capable fuel centers across 8 states, and Clean Energy had 39 operational public LNG facilities.\n\nAs can be seen at the alternative fuel fueling center tracking site, as of early 2015 there is void of LNG fuel centers, public and private, from Illinois to the Rockies. A Noble Energy LNG production plant in northern Colorado was planned to go online in 1st quarter 2015 and to have a capacity of 100,000 gallons of LNG per day for on-road, off-road, and drilling operations.\n\nAs of 2014, LNG fuel and NGV's had not achieved much usage in Europe.\n\nAmerican Gas & Technology pioneered use of onsite liquefaction using van sized station to access Natural Gas from utility pipe and clean, liquefy, store and dispense it. Their stations make 300-5,000 gallons of LNG per day.\n\nIn internal combustion engines the volume of the cylinders is a common measure of the power of an engine. Thus a 2000cc engine would typically be more powerful than an 1800cc engine, but that assumes a similar air-fuel mixture is used.\n\nIf, via a turbocharger as an example, the 1800cc engine were using an air-fuel mixture that was significantly more energy dense, then it might be able to produce more power than a 2000cc engine burning a less energy dense air-fuel mixture. However, turbochargers are both complex and expensive. Thus it becomes clear for high-horsepower/high-torque engines a fuel that can inherently be used to create a more energy dense air-fuel mixture is preferred because a smaller and simpler engine can be used to produce the same power.\n\nWith traditional gasoline and diesel engines the energy density of the air-fuel mixture is limited because the liquid fuels do not mix well in the cylinder. Further, gasoline and diesel auto-ignite at temperatures and pressures relevant to engine design. An important part of traditional engine design is designing the cylinders, compression ratios, and fuel injectors such that pre-ignition is avoided, but at the same time as much fuel as possible can be injected, become well mixed, and still have time to complete the combustion process during the power stroke.\n\nNatural gas does not auto-ignite at pressures and temperatures relevant to traditional gasoline and diesel engine design, thus providing more flexibility in the design of a natural gas engine. Methane, the main component of natural gas, has an autoignition temperature of 580C/1076F, whereas gasoline and diesel autoignite at approximately 250C and 210C respectively.\n\nWith a compressed natural gas (CNG) engine, the mixing of the fuel and the air is more effective since gases typically mix well in a short period of time, but at typical CNG compression pressures the fuel itself is less energy dense than gasoline or diesel thus the end result is a lower energy dense air-fuel mixture. Thus for the same cylinder displacement engine, a non turbocharged CNG powered engine is typically less powerful than a similarly sized gasoline or diesel engine. For that reason, turbochargers are popular on European CNG cars. Despite that limitation, the 12 liter Cummins Westport ISX12G engine is an example of a CNG capable engine designed to pull tractor/trailer loads up to 80,000 lbs showing CNG can be used in most if not all on-road truck applications. The original ISX G engines incorporated a turbocharger to enhance the air-fuel energy density.\n\nLNG offers a unique advantage over CNG for more demanding high-horsepower applications by eliminating the need for a turbocharger. Because LNG boils at approximately -160C, using a simple heat exchanger a small amount of LNG can be converted to its gaseous form at extremely high pressure with the use of little or no mechanical energy. A properly designed high-horsepower engine can leverage this extremely high pressure energy dense gaseous fuel source to create a higher energy density air-fuel mixture than can be efficiently created with a CNG powered engine. The end result when compared to CNG engines is more overall efficiency in high-horsepower engine applications when high-pressure direct injection technology is used. The Westport HDMI2 fuel system is an example of a high-pressure direct injection technology that does not require a turbocharger if teamed with appropriate LNG heat exchanger technology. The Volvo Trucks 13-liter LNG engine is another example of a LNG engine leveraging advanced high pressure technology.\n\nWestport recommends CNG for engines 7 liters or smaller and LNG with direct injection for engines between 20 and 150 liters. For engines between 7 and 20 liters either option is recommended. See slide 13 from their NGV BRUXELLES – INDUSTRY INNOVATION SESSION presentation\n\nHigh horsepower engines in the oil drilling, mining, locomotive, and marine fields have been or are being developed. Paul Blomerous has written a paper concluding as much as 40 million tonnes per annum of LNG (approximately 26.1 billion gallons/year or 71 million gallons/day) could be required just to meet the global needs of the high-horsepower engines by 2025 to 2030.\n\nAs of the end of 1st quarter 2015 Prometheus Energy Group Inc claims to have delivered over 100 million gallons of LNG within the previous 4 years into the industrial market, and is continuing to add new customers.\n\nThe is the world's first LNG powered container ship. LNG carriers are sometimes powered by the boil-off of LNG from their storage tanks, although Diesel powered LNG carriers are also common to minimize loss of cargo and enable more versatile refueling.\n\nSome airplanes use LNG to power their turbofans. Aircraft are particularly sensitive to weight and much of the weight of an aircraft goes into fuel carriage to allow the range. The low energy density of natural gas even in liquid form compared to conventional fuels give it a distinct disadvantage for flight applications.\n\nThe primary component of natural gas is methane (CH), the shortest and lightest hydrocarbon molecule. It may also contain heavier gaseous hydrocarbons such as ethane (CH), propane (CH) and butane (CH), as well as other gases, in varying amounts. Hydrogen sulfide (HS) is a common contaminant, which must be removed prior to most uses.\n\nCombustion of one cubic meter yields 38 MJ (10.6 kWh). Natural gas has the highest energy/carbon ratio of any fossil fuel, and thus produces less carbon dioxide per unit of energy.\n\nThe major difficulty in the use of natural gas is transportation. Natural gas pipelines are economical and common on land and across medium-length stretches of water (like Langeled, Interconnector and Trans-Mediterranean Pipeline), but are impractical across large oceans. Liquefied natural gas (LNG) tanker ships, railway tankers, and tank trucks are also used.\n\nCNG is typically stored in steel or composite containers at high pressure (3000 to 4000 psi, or 205 to 275 bar). These containers are not typically temperature controlled, but are allowed to stay at local ambient temperature. There are many standards for CNG cylinders, the most popular one is ISO 11439. For North America the standard is ANSI NGV-2.\n\nLNG storage pressures are typically around 50-150 psi, or 3 to 10 bar. At atmospheric pressure, LNG is at a temperature of -260 °F (-162 °C), however, in a vehicle tank under pressure the temperature is slightly higher (see saturated fluid). Storage temperatures may vary due to varying composition and storage pressure. LNG is far denser than even the highly compressed state of CNG. As a consequence of the low temperatures, vacuum insulated storage tanks typically made of stainless steel are used to hold LNG.\n\nCNG can be stored at lower pressure in a form known as an ANG (Adsorbed Natural Gas) tank at 35 bar (500 psi, the pressure of gas in natural gas pipelines) in various sponge like materials, such as activated carbon and metal-organic frameworks (MOFs). The fuel is stored at similar or greater energy density than CNG. This means that vehicles can be refuelled from the natural gas network without extra gas compression, the fuel tanks can be slimmed down and made of lighter, less strong materials.\n\nConversion kits for gasoline or diesel to LNG/CNG are available in many countries, along with the labor to install them. However, the range of prices and quality of conversion vary enormously.\n\nRecently, regulations involving certification of installations in USA have been loosened to include certified private companies, those same kit installations for CNG have fallen to the $6,000+ range (depending on type of vehicle).\n\nNatural gas vehicles are popular in regions or countries where natural gas is abundant and where the government chooses to price CNG lower than gasoline. The use of natural gas began in the Po River Valley of Italy in the 1930s, followed by New Zealand in the 1980s, though its use has declined there. At the peak of New Zealand's natural gas use, 10% of the nation's cars were converted, around 110,000 vehicles. In the United States CNG powered buses are the favorite choice of several public transit agencies, with a fleet of more than 114,000 vehicles, mostly buses. India, Australia, Argentina, and Germany also have widespread use of natural gas-powered buses in their public transportation fleets.\n\nGermany hit the milestone of 900 CNG filling stations nationwide in December 2011. Gibgas, an independent consumer group, estimates that 21% of all CNG filling stations in the country offer a natural gas/biomethane mix to varying ratios, and 38 stations offer pure biomethane.\n\nGreece uses natural gas buses for public transport in Athens.\nAlso the Public Gas Company (DEPA) has a network of 11 stations (as of 2017), under brand \"Fisikon\", and plans more stations in next 5 years.\n\nBus Éireann Introduced the first NGV on 17 July 2012. It will operate on the 216 city centre to Mount Oval, Rochestown, route until mid-August on a trial being undertaken in partnership with Ervia. The Eco-city bus is made by MAN.\n\nNatural gas traction is quite popular in Italy, due to the existence of a capillar distribution network for industrial use since the late 50s and a traditionally high retail price for petrol. As of April 2012 there were about 1173 filling stations, mainly located in the northern regions, while the fleet reached 730,000 CNG vehicles at the end of 2010.\n\nUkraine's first compressed natural gas refueling station (CNGS) was commissioned in 1937. Today, there is a well-developed CNGS network across the country. Many buses were converted to run on CNG during the 1990s, primarily for economic reasons. The retrofitted cylinders are often visible atop the vehicle's roof and/or underneath the body. Despite their age, these buses remain in service and continue to provide reliable public transport combined with the environmental benefits of CNG.\n\nCNG buses are beginning to be used in the UK, e.g. by Reading Buses.\n\nWith the recent increase in natural gas production due to widespread use of fracking technology, many countries, including the United States and Canada, now can be self-sufficient. Canada is a substantial net exporter of natural gas, though the United States still has a net import of natural gas. Natural gas prices have decreased dramatically in the past few years and are likely to decrease further as additional production comes on line. However, the EIA predicts that natural gas prices will start increasing in a few years as the most profitable natural gas reserves are used up. Natural gas prices have decreased from $13 per mmbtu (USD) in 2008 to $3 per mmbtu (USD) in 2012. It is likely therefore that natural gas-powered vehicles will be increasingly cheaper to run relative to gasoline-powered vehicles. The issue is how to finance the purchase and installation of conversion kits. Some support may be available through the Department of Energy. Private initiatives which essentially lease the conversion equipment in exchange for slightly higher natural gas refueling can be self-financing and offer considerable advantages to liquidity strapped consumers.\n\nNatural Gas has been used as a motor fuel in Canada for over 20 years. With assistance from federal and provincial research programs, demonstration projects, and NGV market deployment programs during the 1980s and 1990s, the population of light-duty NGVs grew to over 35,000 by the early 1990s. This assistance resulted in a significant adoption of natural gas transit buses as well. The NGV market started to decline after 1995, eventually reaching today's vehicle population of about 12,000.\n\nThis figure includes 150 urban transit buses, 45 school buses, 9,450 light-duty cars and trucks, and 2,400 forklifts and ice-resurfacers. The total fuel use in all NGV markets in Canada was 1.9 petajoules (PJs) in 2007 (or 54.6 million litres of gasoline litres equivalent), down from 2.6 PJs in 1997. Public CNG refuelling stations have declined in quantity from \n134 in 1997 to 72 today. There are 22 in British Columbia, 12 in Alberta, 10 in Saskatchewan, 27 in \nOntario, and 1 in Québec. There are only 12 private fleet stations.\n\nAs of December 2009, the U.S. had a fleet of 114,270 compressed natural gas (CNG) vehicles, 147,030 vehicles running on liquefied petroleum gas (LPG), and 3,176 vehicles running on liquefied natural gas (LNG). The NGV fleet is made up mostly of transit buses but there are also some government fleet cars and vans, as well as increasing number of corporate trucks replacing diesel versions, most notably Waste Management, Inc and UPS trucks. As of 12-Dec-2013 Waste Management has a fleet of 2000 CNG Collection trucks; as of 12-Dec-2013 UPS has 2700 alternative fuel vehicles. As of February 2011, there were 873 CNG refueling sites, 2,589 LPG sites, and 40 LNG sites, led by California with 215 CNG refueling stations in operation, 228 LPG sites and 32 LNG sites. The number of refueling stations includes both public and private sites, and not all are available to the public. As of December 2010, the U.S. ranked 6th in the world in terms of number of NGV stations. Currently there are 160,000 NGVs operating in the country.\n\nThe natural gas vehicle market is limited to fleet vehicles and other public use vehicles like minibuses in larger cities. However the state-owned bus company RTP Of Mexico City has purchased 30 Hyundai Super Aero City CNG-Propelled buses to integrate with the existing fleet as well as to introduce new routes within the city.\n\nCNG vehicles are common in South America, with a 35% share of the worldwide NGV fleet, where these vehicles are mainly used as taxicabs in main cities of Argentina and Brazil. Normally, standard gasoline vehicles are retrofitted in specialized shops, which involve installing the gas cylinder in the trunk and the CNG injection system and electronics.\n\nAs of 2009 Argentina had 1,807,186 NGV's with 1,851 refueling stations across the nation, or 15% of all vehicles; and Brazil had 1,632,101 vehicles and 1,704 refueling stations, with a higher concentration in the cities of Rio de Janeiro and São Paulo.\n\nColombia had an NGV fleet of 300,000 vehicles, and 460 refueling stations as of 2009. Bolivia has increased its fleet from 10,000 in 2003 to 121,908 units in 2009, with 128 refueling stations.\n\nPeru had 81,024 NGVs and 94 fueling stations as 2009. In Peru, several factory-built CNVs have the tanks installed under the body of the vehicle, leaving the trunk free. Among the models built with this feature are the Fiat Multipla, the new Fiat Panda, the Volkswagen Touran Ecofuel, the Volkswagen Caddy Ecofuel, and the Chevy Taxi. Right now, Peru has 224,035 NGVs.\n\nOther countries with significant NGV fleets are Venezuela (226,100) as of 2017 and Chile (15,000) as of 2017.\n\nGM do Brasil introduced the MultiPower engine in August 2004 which was capable of using CNG, alcohol and gasoline as fuel. The GM engine has electronic fuel injection that automatically adjusts to any acceptable fuel configuration. This motor was used in the Chevrolet Astra and was aimed at the taxi market.\n\nIn 2006 the Brazilian subsidiary of Fiat introduced the Fiat Siena Tetra fuel, a four-fuel car developed under Magneti Marelli of Fiat Brazil. This automobile can run on 100% ethanol (E100), E20 to E25 blend (Brazil's normal ethanol gasoline blend), pure gasoline (not available in Brazil), and natural gas, and switches from the gasoline-ethanol blend to CNG automatically, depending on the power required by road conditions.\n\nSince 2003 and with the commercial success of flex cars in Brazil, another existing option is to retrofit an ethanol flexible-fuel vehicle to add a natural gas tank and the corresponding injection system. Some taxicabs in São Paulo and Rio de Janeiro, Brazil, run on this option, allowing the user to choose among three fuels (E25, E100 and CNG) according to current market prices at the pump. Vehicles with this adaptation are known in Brazil as tri-fuel cars.\n\nPakistan was the country with the second largest fleet of NGV with a total of 2.85 million by the end of 2011. Most of the public transportation fleet has been converted to CNG. Also, in Pakistan and India, there have been on-going (last several years now) series of CNG fuel shortages which periodically waxes and wanes, getting the fuel into a tank can be a major problem. In July 2011, petrol usage shot up 15% from the month before due to shortages. Pakistan also has reported that over 2,000 people have died in 2011 from CNG cylinder blasts, because of low quality of cylinders there. In 2012, the Pakistani government took the decision to gradually phase out CNG sector altogether beginning by banning any new conversions to CNG and banning the manufacturing of new NGV's. In addition the government plans to close down all refueling stations in the next 3 years.\n\nIn 1993, CNG had become available in Delhi, India's capital, though LPG is what really took off due to its inherently far lower capital costs. Compressed Natural Gas is a domestic energy produced in Western parts of India. In India, most CNG vehicles are dual fueled, which means they can run both on CNG and gasoline. This makes it very convenient and users can drive long distances without worrying about availability of natural gas (as long as gasoline is available). As of December 2010 India had 1,080,000 NGVs and 560 fueling stations, many of the older ones being LPG rather than CNG. In addition, it is thought that more illegally converted LPG autos than legal ones ply the streets in India, some estimates are as high as 15 million \"autos\" (running the gamut of everything from LPG motored pedal bicycles to CNG buses)\n\nIn 1995, a lawyer filed a case with the Supreme Court of India under the Public Interest Litigation rule, which is part of the Constitution of India and enables any citizen to address directly the Supreme Court. The lawyer's case was about the health risks caused by air pollution emitted from road vehicles. The Supreme Court decided that cars put into circulation after 1995 would have to run on unleaded fuel. By 1998, India was converted to 100% of unleaded fuel after the government ruled that diesel cars in India were restricted to 10,000 ppm after 1995. At the beginning of 2005, 10,300 CNG busses, 55,000 CNG three-wheelers taxis, 5,000 CNG minibuses, 10,000 CNG taxis and 10,000 CNG cars run on India's roads (1982-2008 Product-Life Institute, Geneva). The Delhi Transport Corporation currently operates the world's largest fleet of CNG buses for public transport. Currently India stands 3rd with 3.045 million NGVs.\n\nBy the end of 2015, Iran had the world's largest fleet of NGV at 3.5 million vehicles. The share of compressed natural gas in the national fuel basket is more than 23%. CNG consumption by Iran's transportation sector is around 20 million cubic meters per day. There are 2,335 CNG stations. The growth of NGV market in Iran has in large part been due to Iranian government intervention to decrease the society's dependence on gasoline. This governmental plan was implemented to reduce the effect of sanctions on Iran and make the nation's domestic market less dependent on imported gasoline. Iran has been manufacturing its own NGV's through local manufacturing using dedicated CNG engines which use gasoline only as a back up fuel. Also by 2012, Iranian manufacturers had the capacity to build 1.5 million CNG cylinders per year and therefore Iranian government has banned their imports to support the local manufacturers. In addition CNG in Iran costs the least compared to the rest of the world. In 2012, the Iranian government announced a plan to replace the traditional CNG cylinders with Adsorbed Natural Gas (ANG) cylinders.\n\nThailand has for over a 15 years run autogas taxi cabs in Bangkok, though autos and buses had erroneously labelled NGV stickers on them, when in fact, were LPG fuelled.\n\nIn view of a generous supply of natural gas but relying on imported oil, the Thailand government heavily promoted alternative fuels like LPG, natural gas and ethanol to replace gasoline beginning around 2003, yet NGV was very slow to take off due to cheaper LPG fuel, a pre-existing LPG fleet, and very low conversion cost of local LPG conversion shops as compared to factory installed CNG or conversion. A significant effort was taken when the state-controlled oil company PTT PCL built a network of natural gas refueling stations. The cost of subsidy was estimated at US$150 million in 2008.\n\nAs price of oil climbed rapidly, it was estimated more than 40,000 new cars and trucks powered by natural-gas were purchased in six months in 2008, including many buses. That year, about half of the taxi fleet in Bangkok used LPG, and were prodded to convert to CNG, with little success. Since 2008, there has been a government arm-twisting to switch from LPG to CNG, with a rollout of CNG stations near Bangkok around 2007 and then upcountry in 2010, at times replacing LPG stations. Operators of used vehicles have balked at the massive conversion cost (up to quadruple that of LPG in Thailand), especially given Thailand's strong ultra-competitive domestic LPG conversion industry, as well as retail CNG fuel cost (one and a half times). Thailand had some 700,000 LPG fueled vehicles, and 300,000 CNG fueled, with 1,000 LPG stations and 600 CNG as of 2011. Demand has increased 26% over 2011 for CNG in Thailand. As of the end of 2012, Thailand has 1,014,000 LPG fueled vehicles, and consumed 606,000 tonnes in 2012 of LPG, while 483 stations serve up some 380,000 CNG vehicles., showing that LPG conversion continues to enjoy heavy favor over NGVs despite massive government push for CNG. CNG vehicles are more likely to be bought factory installed while LPG is likely to be an aftermarket conversion. LNG vehicles in Thailand are almost non-existent except for lorries.\n\nIn Malaysia, the use of compressed natural gas was originally introduced for taxicabs and airport limousines during the late-1990s, when new taxis were launched with NGV engines while taxicab operators were encouraged to send in existing taxis for full engine conversions, reducing their costs of operation. Any vehicle converted to use CNG is labelled with white rhombus \"NGV\" (Natural Gas Vehicle) tags, lending to the common use of \"NGV\" when referring to road vehicles with CNG engine. The practice of using CNG remained largely confined to taxicabs predominantly in the Klang Valley and Penang due to a lack of interest. No incentives were offered for those besides taxicab owners to use CNG engines, while government subsidies on petrol and diesel made conventional road vehicles cheaper to use in the eyes of the consumers. Petronas, Malaysia's state-owned oil company, also monopolises the provision of CNG to road users. , Petronas only operates about 150 CNG refueling stations, most of which are concentrated in the Klang Valley. At the same time, another 50 was expected by the end of 2008.\n\nAs fuel subsidies were gradually removed in Malaysia starting June 5, 2008, the subsequent 41% price hike on petrol and diesel led to a 500% increase in the number of new CNG tanks installed. National car maker Proton considered fitting its Waja, Saga and Persona models with CNG kits from Prins Autogassystemen by the end of 2008, while a local distributor of locally assembled Hyundai cars offers new models with CNG kits. Conversion centres, which also benefited from the rush for lower running costs, also perform partial conversions to existing road vehicles, allowing them to run on both petrol or diesel and CNG with a cost varying between RM3,500 to RM5,000 for passenger cars.\n\nThere were about 400 CNG-fueled vehicles in Singapore in mid-2007, of which about 110 are taxis operated by Smart Automobile. By February 2008, the number has risen 520 CNG vehicles, of which about half are taxis. All vehicles had to refuel at the sole CNG station operated by Sembcorp Gas and located on Jurong Island until the opening of the first publicly accessible CNG station at Mandai in 2008, operated by Smart Automobile. The company plans to build another four stations by 2011, by which time the company projects to operate 3,000 to 4,000 CNG taxis, and with 10,000 CNG public and commercial vehicles of other types on Singapore's roads. Sembcorp Gas opened its second CNG station a week after the Mandai station at Jalan Buroh.\n\nCNG is almost unheard of as a transport fuel before 2010 in the archipelago except in Jakarta, where a very relatively minor number of vehicles, most notably Transjakarta buses, use the fuel. However, since 2010 there has been a government emphasis to push usage of CNG not only for vehicle fuel, but also for domestic consumption over wood burning (which can produce deadly methanol) and kerosene.\n\nChina had 450,000 NGV's and 870 refueling stations as of 2009. China in 2012 has 1 million NGVs on the roads, 3 million forecast for 2015, with over 2000 stations (both CNG and LPG), with plans for 12,000 by 2020. Currently China leads the World with 5 million NGVs China also has lot of vehicles running of Petrol blended with Methanol as M15 and M85.\n\nFor the purpose of improving air quality in the metropolitan area of Seoul, CNG buses were first introduced in July, 1997. By 2014, all Seoul buses were operating on CNG. Hyundai motor developed a CNG hybrid bus with 34.5% more-fuel efficiency and 30% lower pollution compared to CNG buses. As a result, Seoul city government plans to change to CNG hybrid buses for 2,235 low-bed disabled-friendly CNG bus in Seoul.\n\nCNG buses are operation in other major South Korean cities like Busan, Daegu, Daejeon, Gwangju and Incheon.\n\nA new category of motorcar racing unites teams which compete with cars powered by natural gas, to demonstrate the effectiveness of natural gas as an alternative fuel. ECOMOTORI (magazine) Racing Team The magazine's team participates in the FIA Alternative Energies Cup and the talian . In 2012, the team, led by Nicola Ventura, competes with a Fiat 500 Abarth, modified to run on natural gas with a Cavagna/Bigas fuel conversion kit and thus renamed \"500 EcoAbarth\". The driver is Massimo Liverani while in the role of navigator, alternate Valeria Strada, Alessandro Talmelli and Fulvio Ciervo. On October 14, 2012, at the end of the 7th Ecorally San Marino-Vatican with 3 wins and a second place (out of 4 races), the Team also won the Italian CSAI Alternative Energy Pilots and Navigators titles. On 28 October 2012, after having raced in 7 European countries, collecting 3 wins, 2 second places and additional points, the team won the FIA Alternative Energies Drivers and Constructors world titles. For the first time ever, a car powered by methane won an FIA world title. In 2013, the team raced in the FIA Alternative Energies Cup and Championships. The \"500 EcoAbarth\" of Ecomotori.net dominated the season, winning 5 of 5 titles. Thanks to the work of the team, the Abarth once again won a constructors' title since its last win 46 years ago.\n\n\n"}
{"id": "3290070", "url": "https://en.wikipedia.org/wiki?curid=3290070", "title": "Penrose criterion", "text": "Penrose criterion\n\nThe Penrose criterion in Plasma Physics is a criterion for kinetic stability of a plasma with a given velocity-space distribution function. This criterion can be used to determine that all so-called \"single-humped\" distributions (those with a single maximum), are kinetically stable.\n"}
{"id": "24620684", "url": "https://en.wikipedia.org/wiki?curid=24620684", "title": "Plug-in electric vehicles in the United States", "text": "Plug-in electric vehicles in the United States\n\nThe adoption of plug-in electric vehicles in the United States is actively supported by the American federal government, and several state and local governments. , cumulative sales in the U.S. totaled one million highway legal plug-in electric vehicles since the market launch of the Tesla Roadster in 2008. , the American stock represented about 25% of the global plug-in car stock, and the U.S. had the world's third largest stock of plug-in passenger cars after China and Europe. \n\nThe U.S. market share of plug-in electric passenger cars increased from 0.14% in 2011 to 0.62% in 2013. The plug-in segment reached a market share of 0.75% in 2014 and fell to 0.66% in 2015. Then climbed to 0.90% in 2016, and achieved a record market share of 1.13% in 2017. California is the largest plug-in car regional market in the country, with over 490,000 plug-in electric vehicles registered through October 2018, representing almost half of plug-in sales in the American market. The other nine states that follow California's Zero Emission Vehicle (ZEV) regulations accounted for another 10% of cumulative plug-in car sales in the U.S.\n\n, there were 41 highway legal plug-in cars available in the American market from over a dozen car manufacturers, plus several models of electric motorcycles, utility vans and neighborhood electric vehicles (NEVs). , the Chevrolet Volt plug-in hybrid is the all-time best selling plug-in electric car with 148,556 units (both generations), followed by the Tesla Model S all-electric car with about 138,000, and the Nissan Leaf with 126,747. The Model S has been the best selling plug-in car in the U.S. for three consecutive years, from 2015 to 2017. , the United States had 12,203 charging stations across the country, led by California with 2,976 stations (24.4%). In terms of public charging points, there were 30,669 public outlets available across the country by the end of January 2016, again led by California with 9,086 charging points (29.6%).\n\nThe Energy Improvement and Extension Act of 2008 granted tax credits for new qualified plug-in electric vehicles. The American Recovery and Reinvestment Act of 2009 (ARRA) also authorized federal tax credits for converted plug-ins. The federal tax credit for new plug-in electric vehicles (PEVs) is worth between and depending on battery capacity. , a total of 37 states and Washington, D.C. have established incentives and tax or fee exemptions for BEVs and PHEVs, or utility-rate breaks, and other non-monetary incentives such as free parking and high-occupancy vehicle lane access. The U.S. government also has pledged in federal grants to support the development of next-generation electric cars and batteries, and million for the installation of electric vehicle charging infrastructure in 16 different metropolitan areas around the country.\n\nIn his 2011 State of the Union address, President Barack Obama set the goal for the U.S. to become the first country to have one million electric vehicles on the road by 2015. Due to a initial slow rate of plug-in car sales, the goal was achieved only in September 2018. The Governor of California, Jerry Brown, issued an executive order in March 2012 that established the goal of getting 1.5 million zero-emission vehicles (ZEVs) on California roads by 2025. In September 2014, the Charge Ahead California Initiative set the additional goal to have at least one million zero-emission vehicles and near-zero-emission vehicles in California by January 1, 2023.\n\nIn his 2011 State of the Union address, President Barack Obama set the goal for the U.S. to become the first country to have one million electric vehicles on the road by 2015. This goal was established based on forecasts made by the U.S. Department of Energy (DoE), using production capacity of PEV models announced to enter the U.S. market through 2015. The DoE estimated a cumulative production of 1,222,200 PEVS by 2015, and was based on manufacturer announcements and media reports accounting production goals for the Fisker Karma, Fisker Nina, Ford Transit Connect, Ford Focus Electric, Chevrolet Volt, Nissan Leaf, Smith Newton, Tesla Roadster, Tesla Model S and Th!nk City.\n\nConsidering that actual PEV sales were lower than initially expected, as of early 2013, several industry observers have concluded that this goal was unattainable. According to a July 2012 study by Pike Research, cumulative sales will reach the one million goal set by the Obama Administration only in 2018. Other analysts agree that the goal could be achieved in 2018. With only about 400,000 plug-in electric cars sold in the United States by the end of December 2015, Secretary of Energy, Ernest Moniz, said in January 2016 that the one million goal may not be reached until 2020. According to the Secretary purchases have fallen well below President Barack Obama's goal due to low gasoline prices, which had a negative impact on sales. Also improvements in battery technology are required as lowering battery costs is \"absolutely critical\" to boost electric vehicle sales. U.S. cumulative plug-in sales since 2008 achieved the 500,000 unit milestone in August 2016, and Obama's goal was achieved only in September 2018.\n\nPresident Barack Obama pledged billion in federal grants to support the development of next-generation electric vehicles and batteries. $1.5 billion in grants to U.S. based manufacturers to produce highly efficient batteries and their components; up to $500 million in grants to U.S. based manufacturers to produce other components needed for electric vehicles, such as electric motors and other components; and up to $400 million to demonstrate and evaluate plug-in hybrids and other electric infrastructure concepts—like truck stop charging station, electric rail, and training for technicians to build and repair electric vehicles (greencollar jobs).\n\nIn March 2009, as part of the American Recovery and Reinvestment Act, the U.S. Department of Energy announced the release of two competitive solicitations for up to $2 billion in federal funding for competitively awarded cost-shared agreements for manufacturing of advanced batteries and related drive components as well as up to $400 million for transportation electrification demonstration and deployment projects. This initiative aimed to help meet President Barack Obama's goal of putting one million plug-in electric vehicles on the road by 2015.\n\nIn 2008, San Francisco Mayor Gavin Newsom, San Jose Mayor Chuck Reed and Oakland Mayor Ron Dellums announced a nine-step policy plan for transforming the Bay Area into the \"Electric Vehicle (EV) Capital of the U.S.\". Other local and state governments have also expressed interest in electric cars.\n\nA 2013 study published in the journal \"Energy Policy\" explored the relative benefits of a vehicle-charging network and plug-in hybrid vehicles with larger batteries. Across the battery-capacity and charging-infrastructure scenarios examined, the lowest-cost solution is for more drivers to switch to traditional hybrid electrics or low-capacity plug-in hybrid electric vehicles (PHEVs). Installing charging infrastructure would provide lower gasoline savings per dollar spent than paying for increased PHEV battery capacity. In addition, the study determined that current federal subsidies are \"not aligned with the goal of decreased gasoline consumption in a consistent and efficient manner.\"\n\nFirst the Energy Improvement and Extension Act of 2008, and later the American Clean Energy and Security Act of 2009 (ACES) granted tax credits for new qualified plug-in electric drive motor vehicles. The American Recovery and Reinvestment Act of 2009 (ARRA) also authorized federal tax credits for converted plug-ins, though the credit is lower than for new plug-in electric vehicle (PEV).\n\nAs defined by the 2009 ACES Act, a PEV is a vehicle which draws propulsion energy from a traction battery with at least 5 kwh of capacity and uses an offboard source of energy to recharge such battery. The tax credit for new plug-in electric vehicles is worth plus for each kilowatt-hour of battery capacity over 5 kwh, and the portion of the credit determined by battery capacity cannot exceed . Therefore, the total amount of the credit, between and , will vary depending on the capacity of the battery (4 to 16 kWh) used to power the vehicles.\n\nThe qualified plug-in electric vehicle credit phases out for a plug-in manufacturer over the one-year period beginning with the second calendar quarter after the calendar quarter in which at least 200,000 qualifying plug-in vehicles from that manufacturer have been sold for use in the U.S. Cumulative sales started counting sales after December 31, 2009. After reaching the cap, qualifying PEVs for one quarter still earn the full credit, the second quarter after that quarter plug-in vehicles are eligible for 50% of the credit for six months, then 25% of the credit for another six months and finally the credit is phased out. Both the Nissan Leaf electric vehicle and the Chevrolet Volt plug-in hybrid, launched in December 2010, are eligible for the maximum $7,500 tax credit. The Toyota Prius Plug-in Hybrid, released in January 2012, is eligible for a tax credit due to its smaller battery capacity of 5.2 kWh. All Tesla cars and the Chevrolet Bolts and BMW i3 BEV are eligible for the tax credit.\n\nA 2016 study conducted by researchers from the University of California, Davis found that the federal tax credit was the reason behind more than 30% of the plug-in electric sales. The impact of the federal tax incentive is higher among owners of the Nissan Leaf, with up to 49% of sales attributable to the federal incentive. The study, based on an stated preference survey of more than 2,882 plug in vehicle owners in 11 states, also found that the federal tax credit shifts buyers from internal combustion engine vehicles to plug-in vehicles and advances the purchase timing of new vehicles by a year or more.\n\nIn July 2018, Tesla Inc. was the first plug-in manufacturer to pass 200,000 sales and the full tax credit will be available until the end 2018, with the phase out beginning in January 2019. , General Motors combined sales of plug-in electric vehicles in the U.S. totaled 196,986 units and are expected to pass 200,000 early in 2019. Thereafter, the applicable tax credit reduces gradually until it is completely phase out beginning on January 1, 2020. In order of cumulative sales, , Nissan has delivered 125,747 units, Ford 110,583, Toyota 90,699 and the BMW Group 77,366 plug-in electric cars.\n\n, a total of 37 states and Washington, D.C. have established incentives and tax or fee exemptions for BEVs and PHEVs, or utility-rate breaks, and other non-monetary incentives such as free parking and high-occupancy vehicle lane access regardless of the number of occupants. In California, for example, the Clean Vehicle Rebate Project (CVRP) was established to promote the production and use of zero-emission vehicles (ZEVs). Eligible vehicles include only new Air Resources Board-certified or approved zero-emission or plug-in hybrid electric vehicles. Among the eligible vehicles are neighborhood electric vehicles, battery electric, plug-in hybrid electric, and fuel cell vehicles including cars, trucks, medium- and heavy-duty commercial vehicles, and zero-emission motorcycles. Vehicles must be purchased or leased on or after March 15, 2010. Rebates initially of up to per light-duty vehicle, and later lowered to up to , are available for individuals and business owners who purchase or lease new eligible vehicles. Certain zero-emission commercial vehicles are also eligible for rebates up to . California's zero-emission (ZEV) regulations are anticipated to result in 1.5 million electric vehicles on the road by 2025 ( i.e., 15% sales of total states in 2025), moreover, the California's mixed incentives means to reach 40% of electric vehicle sales in the entire U.S. \nAll electric vehicle purchases made in any of the 50 states are eligible for the $7,500 federal tax credit. Local governments may offer additional rebates.\n\nThe following table summarizes some of the state incentives:\nSeveral separate initiatives have been pursued unsuccessfully at the federal level since 2011 to transform the tax credit into an instant cash rebate. The objective of these initiatives is to make new qualifying plug-in electric cars more accessible to buyers by making the incentive more effective. The rebate would be available at the point of sale allowing consumers to avoid a wait of up to a year to apply the tax credit against income tax returns.\n\nIn March 2014, the Obama Administration included a provision in the FY 2015 Budget to increase the maximum tax credit for plug-in electric vehicles and other advanced vehicles to , over the current . However, the new maximum tax credit would not apply to luxury vehicles with a sales price of over , such as the Tesla Model S and the Cadillac ELR, which would be capped at . According to the Treasury Department, the proposal intends to transform the existing tax credit into a rebate available at the point of sale that will be claimable by dealers and passed along to the consumers. The proposal also seeks to remove the 200,000 vehicle cap per manufacturer after which the credit phases out over a year. Instead, the incentives would begin to phase out starting in 2019 for all manufacturers, and the credit would be completely phased out by 2022, and fall to 75% of the current credit starting in 2019. Despite President Barack Obama's unsuccessful attempts to raise the tax credit to in his previous three annual budgets, the proposal was included again in the FY 2016 Budget.\n\nIn November 2017, House Republicans proposed scrapping the $7,500 tax credit as part of a sweeping tax overhaul.\n\nUntil 2010 there was a federal tax credit equal to 50% of the cost to buy and install a home-based charging station with a maximum credit of for each station. Businesses qualified for tax credits up to for larger installations. These credits expired on December 31, 2010, but were extended through 2013 with a reduced tax credit equal to 30% with a maximum credit of up to for each station for individuals and up to for commercial buyers. In 2016, the Obama administration and several stake holders announced $4.5 billion in loan guarantees for public charge stations, along with other iniatives.\n\nOn March 7, 2012, President Barack Obama launched the EV Everywhere Challenge as part of the U.S. Department of Energy’s Clean Energy Grand Challenges, which seeks to solve some of the U.S. biggest energy challenges and make clean energy technologies affordable and accessible to the vast majority of American households and businesses. The EV Everywhere Challenge has the goal of advancing electric vehicle technologies to have the country, by 2022, to produce a five-passenger electric vehicle that would provide both a payback time of less than five years and the ability to be recharged quickly enough to provide enough range for the typical American driver.\n\nIn January 2013 the Department of Energy (DoE) published the \"EV Everywhere Grand Challenge Blueprint,\" which set the technical targets of the PEV program to fall into four areas: battery research and development; electric drive system research and development; vehicle lightweighting; and advanced climate control technologies. The DoE set several specific goals, established in consultation with stakeholders through a series of workshops held during the second half of 2012. The key goals to be met over the next five years to make plug-in electric vehicles competitive with conventional fossil fuel vehicles are:\n\nAchieving these goals in the next five years will result in an automotive propulsion battery with five-times the present range capacity, costing one-fifth present lithium-ion batteries. The DoE aim is to level the purchase plus operating (fuel) cost of an all-electric vehicle with a range with the costs of an internal combustion engine (ICE) vehicle of similar size. The DoE expects than even before the latter goals are met, the 5-year cost of ownership of most plug-in hybrid electric vehicles and of all-electric vehicles with shorter ranges, such as , will be comparable to the same cost of ICE vehicles of similar size.\nIn order to achieve these goals, the DoE is providing up to million over the next five years to fund the new Joint Center for Energy Storage Research (JCESR), a research center led by the Argonne National Laboratory in Chicago. JCESR is a consortium of five DOE national labs, five universities, and four private-sector enterprises, and it is being likened to the Manhattan Project of battery technology.\n\nAn initial progress report for the initiative was released in January 2014. Four key successes of the first year of the initiative were reported: \n\nIn January 2013, during the Washington Auto Show, Secretary of Energy Steven Chu announced an initiative to expand the EV Everywhere program with the “Workplace Charging Challenge.” This initiative is a plan to install more electric vehicle charging stations in workplace parking lots. There are 21 founding partners and ambassadors for the program, including Ford, Chrysler, General Motors, Nissan, Tesla Motors, 3M, Google, Verizon, Duke Energy, General Electric, San Diego Gas & Electric, Siemens, Plug In America, and the Rocky Mountain Institute. The initiative's target is to increase the number of U.S. employers offering workplace charging by tenfold in the next five years. Initially, the DoE will not provide funding for this initiative.\n\nThe U.S. Army announced in 2009 that it will lease 4,000 Neighborhood Electric Vehicles (NEVs) within three years. The Army plans to use NEVs at its bases for transporting people around the base, as well as for security patrols and maintenance and delivery services. The Army accepted its first six NEVs at Virginia's Fort Myer in March 2009 and will lease a total of 600 NEVs through the rest of the year, followed by the leasing of 1,600 NEVs for each of the following two years. With a full eight-hour recharge, the NEVs can travel at a top speed of .\n\nU.S. Air Force officials announced, in August 2011, a plan to establish Los Angeles Air Force Base, California, as the first federal facility to replace 100% of its general purpose fleet with plug-in electric vehicles. As part of the program, all Air Force-owned and -leased general purpose fleet vehicles on the base will be replaced with PEVs. There are approximately 40 eligible vehicles, ranging from passenger sedans to two-ton trucks and shuttle buses. The replacement PEVs include all-electric, plug-in hybrids, and extended-range electric vehicles. The initiative would not include force protection, tactical and emergency response vehicles. The program is also subject to environmental review. Electrification of Los Angeles AFB's general purpose fleet is the first step in a Department of Defense effort to establish strategies for large-scale integration of PEVs.\n\nBy May 2013, it was announced that, as part of a test program created in January 2013, 500 plug-in electric vehicles with vehicle-to-ground (V2G) technology would be in use at six military bases, purchased using an investment of $20 million. If the program succeeds, there will be 3,000 V2G vehicles in 30 bases.\n\nDue to the low noise typical of electric vehicles at low speeds, the National Highway Traffic Safety Administration ruled that all hybrids and EVs must emit artificial noise when idling, accelerating to or going in reverse by September 2019.\n\nThe Chevrolet Volt and other hybrid and plug-in cars have included a noise generator when operating at low speeds to alert pedestrians to the car's presence since their inception.\n\nAs a signatory party to the 2015 Paris Climate Agreement, the United States government committed to reduce its greenhouse gas emissions, among others, from the transportation sector. Already in 2015, the Federal government had set targets to reduce its own carbon footprint 30% by 2025, and acquire 20% of all new passenger vehicles as zero emission (all-electric of fuel cell) or plug-in hybrid by 2020, and 50% by 2025. These goals are part of the U.S. nationally determined contributions (NDCs) to achieve the worldwide emissions reduction goal set by the Paris Agreement.\n\nBuilding on the first-ever U.S.-China Electric Vehicle Forum in September 2009, US and China unveiled the U.S.-China Electric Vehicles Initiative, which will include developing joint standards, building demonstration projects in more than a dozen cities, creating technical roadmaps, and carrying out public education projects. Both nations said they share an interest in accelerating the deployment of electric vehicles in order to reduce oil dependence, cut greenhouse gas emissions, and promote economic growth.\n\nThe following table shows the U.S. Environmental Protection Agency (EPA) official ratings for fuel economy (miles per gallon gasoline equivalent) and EPA's estimated out-of-pocket fuel costs for all plug-in electric passenger vehicles rated by EPA in the United States since 2010 up to December 2016.\n\nElectric cars, as well as plug-in hybrids operating in all-electric mode, emit no harmful tailpipe pollutants from the onboard source of power, such as particulates (soot), volatile organic compounds, hydrocarbons, carbon monoxide, ozone, lead, and various oxides of nitrogen. The clean air benefit is usually local because, depending on the source of the electricity used to recharge the batteries, air pollutant emissions are shifted to the location of the generation plants. In a similar manner, plug-in electric vehicles operating in all-electric mode do not emit greenhouse gases from the onboard source of power, but from the point of view of a well-to-wheel assessment, the extent of the benefit also depends on the fuel and technology used for electricity generation. From the perspective of a full life cycle analysis, the electricity used to recharge the batteries must be generated from renewable or clean sources such as wind, solar, hydroelectric, or nuclear power for PEVs to have almost none or zero well-to-wheel emissions.\n\nThe following table compares tailpipe and upstream emissions estimated by the U.S. Environmental Protection Agency for all series production model year 2014 plug-in electric vehicles available in the U.S. market. Total emissions include the emissions associated with the production and distribution of electricity used to charge the vehicle, and for plug-in hybrid electric vehicles, it also includes emissions associated with tailpipe emissions produced from the internal combustion engine. These figures were published by the EPA in October 2014 in its annual report \"\"Light-Duty Automotive Technology, Carbon Dioxide Emissions, and Fuel Economy Trends\".\" All emissions are estimated considering average real world city and highway operation based on the EPA 5-cycle label methodology, using a weighted 55% city and 45% highway driving.\n\nFor purposes of an accurate estimation of emissions, the analysis took into consideration the differences in operation between plug-in hybrids. Some, like the Chevrolet Volt, can operate in all-electric mode without using gasoline, and others operate in a blended mode like the Toyota Prius PHV, which uses both energy stored in the battery and energy from the gasoline tank to propel the vehicle, but that can deliver substantial all-electric driving in blended mode. In addition, since the all-electric range of plug-in hybrids depends on the size of the battery pack, the analysis introduced a utility factor as a projection of the share of miles that will be driven using electricity by an average driver, for both, electric only and blended EV modes. Since all-electric cars do not produce tailpipe emissions, the utility factor applies only to plug-in hybrids. The following table shows the overall fuel economy expressed in terms of miles per gallon gasoline equivalent (mpg-e) and the utility factor for the ten MY2014 plug-in hybrids available in the U.S. market, and EPA's best estimate of the tailpipe emissions produced by these PHEVs.\n\nIn order to account for the upstream emissions associated with the production and distribution of electricity, and since electricity production in the United States varies significantly from region to region, the EPA considered three scenarios/ranges with the low end scenario corresponding to the California powerplant emissions factor, the middle of the range represented by the national average powerplant emissions factor, and the upper end of the range corresponding to the powerplant emissions factor for the Rocky Mountains. The EPA estimates that the electricity GHG emission factors for various regions of the country vary from 346 g /kWh in California to 986 g /kWh in the Rockies, with a national average of 648 g /kWh.\n\nThe Union of Concerned Scientists (UCS) published a study in 2012 that assessed average greenhouse gas emissions in the U.S. resulting from charging plug-in car batteries from the perspective of the full life-cycle (well-to-wheel analysis) and according to fuel and technology used to generate electric power by region. The study used the Nissan Leaf all-electric car to establish the analysis baseline, and electric-utility emissions are based on EPA's 2009 estimates. The UCS study expressed the results in terms of miles per gallon instead of the conventional unit of grams of greenhouse gases or carbon dioxide equivalent emissions per year in order to make the results more friendly for consumers. The study found that in areas where electricity is generated from natural gas, nuclear, hydroelectric or renewable sources, the potential of plug-in electric cars to reduce greenhouse emissions is significant. On the other hand, in regions where a high proportion of power is generated from coal, hybrid electric cars produce less -e equivalent emissions than plug-in electric cars, and the best fuel efficient gasoline-powered subcompact car produces slightly less emissions than a PEV. In the worst-case scenario, the study estimated that for a region where all energy is generated from coal, a plug-in electric car would emit greenhouse gas emissions equivalent to a gasoline car rated at a combined city/highway driving fuel economy of . In contrast, in a region that is completely reliant on natural gas, the PEV would be equivalent to a gasoline-powered car rated at .\n\nThe study concluded that for 45% of the U.S. population, a plug-in electric car will generate lower equivalent emissions than a gasoline-powered car capable of combined , such as the Toyota Prius and the Prius c. The study also found that for 37% of the population, the electric car emissions will fall in the range of a gasoline-powered car rated at a combined fuel economy of , such as the Honda Civic Hybrid and the Lexus CT200h. Only 18% of the population lives in areas where the power-supply is more dependent on burning carbon, and the greenhouse gas emissions will be equivalent to a car rated at a combined fuel economy of , such as the Chevrolet Cruze and Ford Focus. The study found that there are no regions in the U.S. where plug-in electric cars will have higher greenhouse gas emissions than the average new compact gasoline engine automobile, and the area with the dirtiest power supply produces emissions equivalent to a gasoline-powered car rated at .\n\nThe following table shows a representative sample of cities within each of the three categories of emissions intensity used in the UCS study, showing the corresponding miles per gallon equivalent for each city as compared to the greenhouse gas emissions of a gasoline-powered car:\nIn September 2014 the UCS published an updated analysis of its 2012 report. The 2014 analysis found that 60% of Americans, up from 45% in 2009, live in regions where an all-electric car produce fewer equivalent emissions per mile than the most efficient hybrid. The UCS study found several reasons for the improvement. First, electric utilities have adopted cleaner sources of electricity to their mix between the two analysis. The 2014 study used electric-utility emissions based on EPA's 2010 estimates, but since coal use nationwide is down by about 5% from 2010 to 2014, actual efficiency in 2014 is expected to be better than estimated in the UCS study. Second, electric vehicles have become more efficient, as the average model year 2013 all-electric vehicle used 0.325 kWh/mile, representing a 5% improvement over 2011 models. The Nissan Leaf, used as the reference model for the baseline of the 2012 study, was upgraded in model year 2013 to achieve a rating of 0.30 kWh/mile, a 12% improvement over the 2011 model year model rating of 0.34 kWh/mile. Also, some new models are cleaner than the average, such as the BMW i3, which is rated at 0.27 kWh by the EPA. An i3 charged with power from the Midwest grid would be as clean as a gasoline-powered car with about , up from for the average electric car in the 2012 study. In states with a cleaner mix generation, the gains were larger. The average all-electric car in California went up to equivalent from in the 2012 study. States with dirtier generation that rely heavily on coal still lag, such as Colorado, where the average BEV only achieves the same emissions as a gasoline-powered car. The author of the 2014 analysis noted that the benefits are not distributed evenly across the U.S. because electric car adoptions is concentrated in the states with cleaner power.\n\nIn November 2015 the Union of Concerned Scientists published a new report comparing two battery electric vehicles (BEVs) with similar gasoline vehicles by examining their global warming emissions over their full life-cycle, cradle-to-grave analysis. The two BEVs modeled, midsize and full-size, are based on the two most popular BEV models sold in the United States in 2015, the Nissan Leaf and the Tesla Model S. The study found that all-electric cars representative of those sold today, on average produce less than half the global warming emissions of comparable gasoline-powered vehicles, despite taken into account the higher emissions associated with BEV manufacturing. Considering the regions where the two most popular electric cars are being sold, excess manufacturing emissions are offset within 6 to 16 months of average driving. The study also concluded that driving an average EV results in lower global warming emissions than driving a gasoline car that gets in regions covering two-thirds of the U.S. population, up from 45% in 2009. Based on where EVs are being sold in the United States in 2015, the average EV produces global warming emissions equal to a gasoline vehicle with a fuel economy rating. The authors identified two main reason for the fact that EV-related emissions have become even lower in many parts of the country since the first study was conducted in 2012. Electricity generation has been getting cleaner, as coal-fired generation has declined while lower-carbon alternatives have increased. In addition, electric cars are becoming more efficient. For example, the Nissan Leaf and the Chevrolet Volt, have undergone improvements to increase their efficiencies compared to the original models launched in 2010, and other even more efficient BEV models, such as the most lightweight and efficient BMW i3, have entered the market.\n\nOne criticism to the UCS analysis and several other that have analyze the benefits of PEVs is that these analysis were made using average emissions rates across regions instead of marginal generation at different times of the day. The former approach does not take into account the generation mix within interconnected electricity markets and shifting load profiles throughout the day. An analysis by three economist affiliated with the National Bureau of Economic Research (NBER), published in November 2014, developed a methodology to estimate marginal emissions of electricity demand that vary by location and time of day across the United States. The study used emissions and consumption data for 2007 through 2009, and used the specifications for the Chevrolet Volt (all-electric range of ). The analysis found that marginal emission rates are more than three times as large in the Upper Midwest compared to the Western U.S., and within regions, rates for some hours of the day are more than twice those for others. Applying the results of the marginal analysis to plug-in electric vehicles, the NBER researchers found that the emissions of charging PEVs vary by region and hours of the day. In some regions, such as the Western U.S. and Texas, emissions per mile from driving PEVs are less than those from driving a hybrid car. However, in other regions, such as the Upper Midwest, charging during the recommended hours of midnight to 4 a.m. implies that PEVs generate more emissions per mile than the average car currently on the road. The results show a fundamental tension between electricity load management and environmental goals as the hours when electricity is the least expensive to produce tend to be the hours with the greatest emissions. This occurs because coal-fired units, which have higher emission rates, are most commonly used to meet base-level and\noff-peak electricity demand; while natural gas units, which have relatively low emissions rates, are often brought online to meet peak demand. This pattern of fuel shifting explains why emission rates tend to be higher at night and lower during periods of peak demand in the morning and evening.\n\nIn February 2014, the Automotive Science Group (ASG) published the result of a study conducted to assess the life-cycle of over 1,300 automobiles across nine categories sold in North America. The study found that among advanced automotive technologies, the Nissan Leaf holds the smallest life-cycle environmental footprint of any model year 2014 automobile available in the North American market with minimum four-person occupancy. The study concluded that the increased environmental impacts of manufacturing the battery electric technology is more than offset with increased environmental performance during operational life. For the assessment, the study used the average electricity mix of the U.S. grid in 2014. In the 2014 mid-size cars category, the Leaf also ranked as the best all-around performance, best environmental and best social performance. The Ford Focus Electric, within the 2014 compact cars category, ranked as the best all-around performance, best environmental and best social performance. The Tesla Model S ranked as the best environmental performance in the 2014 full-size cars category.\n\n, the United States had 12,203 charging stations across the country, up from 5,678 in March 2013. California led with 2,976 stations, followed by Texas with 686, and Florida with 626. In terms of public charging points, there were 30,669 public outlets available across the country by the end of January 2016, led by California with 9,086 charging points (29.6%), followed by Texas with 1,679 (13.8%), and Florida and Washington state with 1,435 each (11.8%). There were 592 CHAdeMO quick charging stations across the country by April 2014.\n\nCar2Go made San Diego the only North American city with an all-electric carsharing fleet when it launched service in 2011. , the carsharing service has 40,000 members and 400 all-electric Smart EDs in operation. However, due to lack of enough charging infrastructure Car2Go decided to replace all of its all-electric car fleet with gasoline-powered cars starting on 1 May 2016. When the carsharing service started Car2Go expected 1,000 charging stations to be deployed around the city, but only 400 were in place by early 2016. As a result, an average of 20% of the carsharing fleet is unavailable at any given time because the cars are either being charged or because they don’t have enough electricity in them to be driven. Also, many of the company’s San Diego members say they often worry their Car2Go will run out of charge before they finish their trip.\n\nResearchers from the Indiana University School of Public and Environmental Affairs developed an index that identifies and ranks the municipal plug-in electric vehicle readiness (\"PEV readiness\"). The evaluation ranked the U.S. 25 largest cities by population along with five other large cities that have been included in other major PEV studies. The rankings also included the largest cities in states that joined California zero-emissions vehicle goal. A total of 36 major U.S. cities were included in the study. The evaluation found that Portland, Oregon ranks at the top of the list of major American cities that are the most ready to accommodate plug-in electric vehicles.\n\nReadiness is the degree to which adoption of electric vehicles is supported, as reflected in the presence of various types of policy instruments, infrastructure development, municipal investments in PEV technology, and participation in relevant stakeholder coalitions. The study also compares cities within states that participate in the Zero Emission Vehicle program, with those that do not, with the objective to understand whether participation in that program has a meaningful impact on PEV readiness.\n\nIn order to accelerate the adoption of plug-in electric vehicles (PEV), many municipalities, along with their parent states, offer a variety of benefits to owners and operators of PEVs to make PEV adoption easier and more affordable. All six cities in the top of the ranking offer purchase incentives for PEVs and charging equipment. Four of the six offer time-of-use electricity rates, which makes overnight charging more affordable. The top-ranking cities also score well in categories such as public charging station density, special parking privileges, access to high occupancy vehicle (HOV) lanes, and streamlined processes for installing charging equipment. Those services and incentives are largely absent from the bottom six cities.\n\nThe following is the full ranking of the 36 U.S. cities in 25 states included in the evaluation of PEV readiness:\n\nCumulative sales of highway legal plug-in electric cars in the U.S. since 2008, when the Tesla Roadster was introduced, achieved the one million unit milestone in September 2018. , the American stock represented about 25% of the global plug-in car stock, down from about 40% in 2014. Sales in the American market are led by California with over 365,000 plug-in electric vehicles sold up until 2017. California accounted for approximately 48% of cumulative plug-in sales in the American market from 2011 to June 2016. The other nine states that follow California's Zero Emission Vehicle (ZEV) regulations accounted for another 10% of cumulative plug-in car sales in the U.S. during the same period.\n\n, the United States had the world's largest stock of light-duty plug-in electric vehicles, and led annual plug-in car sales in calendar year 2014. By May 2016, the European stock of light-duty had surpassed the U.S. and became the world's largest regional market. By the end of September 2016, the Chinese stock of plug-in passenger cars reached the level of the American plug-in stock. In November 2016, China’s cumulative total plug-in passenger vehicles sales had surpassed those of Europe, allowing China to become the market with the world's largest stock of light-duty plug-in electric vehicles, with about 600,000 plug-in passenger cars. As a result, since November 2016 the U.S. has world's third largest stock of plug-in passenger cars. China also surpassed the U.S. and Europe in terms of annual sales of light-duty plug-in electric vehicles, both in calendar years 2015 and 2016. IHS Automotive predicted that due to the more aggressive support of the Chinese government toward the adoption of plug-in electric vehicles, China will reach 1 million annual plug-in car sales in 2019, four years before the United States.\n\nNational sales increased from 17,800 units delivered in 2011 to 53,200 during 2012, and reached 97,100 in 2013, up 83% from the previous year. During 2014 plug-in electric car sales totaled 123,347 units, up 27.0% from 2013, and fell to 114,248 units in 2015, down 7.4% from 2014. A total of 157,181 plug-in cars were sold in 2016, up 37.6% from 2015, and rose to 194,479 in 2017, up 23.7% from 2016. The market share of plug-in electric passenger cars increased from 0.14% of new car sales in 2011 to 0.37% in 2012, 0.62% in 2013, and reached 0.75% of new car sales during 2014. As plug-in car sales slowed down during the 2015, the segment's market share fell to 0.66% of new car sales, with the all-electric segment flat at 0.41%, while plug-in hybrids declined to 0.25% from 0.34% in 2014. The plug-in market share increased to increased to 0.90% in 2016, and achieved the 1% market share mark for the first time in 2017, with 1.13% of the country's total annual new car sales.\n\nThe highest-ever monthly market share for plug-in electric vehicles was achieved in December 2017 with 1.58% of new car sales. The previous record was achieved in September 2017. Monthly sales of plug-in cars in the American market passed the 1% mark for the first time in September 2016 (1.12%). December 2017 is also the best monthly plug-in sales volume on record ever, with 25,149 units delivered. The previous record was set in December 2016 with 23,288 units delivered. Records are usually set in the month of December because of the additional consumers seeking to quickly gain back the federal tax credit of up to on purchases.\n\n, the Chevrolet Volt plug-in hybrid continued to rank as the all-time best selling plug-in electric car with 148,556 units of both generations, followed by the Tesla Model S all-electric car with about 138,000, and the Nissan Leaf with 126,747. The Leaf passed the Chevrolet Volt as the all-time top selling plug-in in March 2015, but the Volt became once again the best selling plug-in car in the American market in March 2016. In July 2016, the Volt became the first plug-in vehicle in the American market to achieve the 100,000 unit sales milestone. Leaf sales achieved the 100,000 unit milestone in October 2016, becoming the first all-electric vehicle in the country to pass that mark. The Model S achieved the mark of 100,000 sales in the U.S. in June 2017, launched in June 2012, the Model S hit this milestone quicker than both the Volt and the Leaf.\n\nDuring 2013 sales were led by the Chevrolet Volt with 23,094 units, followed by the Nissan Leaf with 22,610 cars, and the Tesla Model S with about 18,000 units. In 2013 the Model S was the top selling car in the American full-size luxury sedan category, ahead of the Mercedes-Benz S-Class (13,303), the top selling car in the category in 2012, and also surpassing the BMW 7 Series (10,932), Lexus LS (10,727), Audi A8 (6,300) and Porsche Panamera (5,421). During the first quarter of 2014, plug-in car sales captured a 3.0% market share of the luxury vehicle segment, of which, the Model S represented 94% of the plug-in sales. In 2014 the Leaf took the lead, with 30,200 units sold, with the Volt ranking second with 18,805, followed by the Model S with 16,689 units. The Tesla Model S, with 25,202 units delivered, was the top selling plug-in car in 2015, followed by the Nissan Leaf with 17,269 units, the Volt with 15,393, and the BMW i3 with 11,024. For a second year on a row, the Model S was the top selling plug-in car with about 29,156 units sold in 2016, followed by the Volt with 24,739, Model X with about 18,028, Ford Fusion Energi with 15,938, and the Nissan Leaf with 14,006. The top five best-selling models in the U.S. accounted for about 65% of total plug-in cars in 2016. Sales in 2017 were led by the Tesla Model S with about 26,500 units, the top selling plug-in car for the third year running, followed by the Chevrolet Bolt (23,297), Tesla Model X (~21,700), Toyota Prius Prime (20,936), and the Chevrolet Volt (20,349), together accounting for 58% of total sales in 2017.\n\nDuring 2011, all-electric cars (10,064 units) oversold plug-in hybrids (7,671 units), but increased Volt sales, together with the introduction of the Prius PHV and the Ford C-Max, allowed plug-in hybrids to take the lead over pure electric cars during 2012, with 38,584 PHEVs sold versus 14,251 BEVs. Sales of pure electric cars (about 47,600 units) in 2013 were almost even with plug-in hybrids (about 49,000 units), due to large sales of the Tesla Model S and Nissan Leaf during 2013. , cumulative sales of plug-in electric vehicles in the U.S. since December 2010 were led by plug-in hybrids, with 150,946 units sold representing 52.7% of all plug-in car sales, while 135,444 all-electric cars (47.3%) had been delivered to retail customers. During 2015, the all-electric segment grew much faster, with a total of 72,303 all-electric cars sold, up 6.6% year-on-year, while plug-in hybrid were down 22.4% year-on-year, with 42,959 units sold. These results reversed the trend, and , a total of 206,508 all-electric cars and 193,904 plug-in hybrids have been sold since 2010, with all-electrics now representing 51.6% of cumulative sales. The lead of battery electric cars continued in 2016, with 84,246 all-electrics sold, up 18.4% from 2015, representing 53.6% of the plug-in segment 2016 sales, while sales of plug-in hybrids totaled 72,935 unis, up 69.1% from 2015. , the distribution of cumulative sales since 2010 between these two technologies is 52.8% all-electrics and 47.2% plug-in hybrids.\n\nSales of series production plug-in cars during its first two years in the U.S. market were lower than the initial expectations. Cumulative plug-in electric car sales since 2008 reached the 250,000 units in August 2014, 500,000 in August 2016, and the one million goal was achieved in September 2018.\n\nAccording to the U.S. Department of Energy, combined sales of plug-in hybrids and battery electric cars are climbing more rapidly and outselling by more than double sales of hybrid-electric vehicles over their respective 24 month introductory periods, as shown in the graph at the right. A more detailed analysis by the Office of Energy Efficiency and Renewable Energy over the same two-year introductory periods found that except for the initial months in the market, monthly sales of the Volt and the Leaf have been higher than the Prius HEV, and the Prius PHEV has outsold the regular Prius during its 8 months in the market. Over the first 24 months from introduction, the Prius HEV achieved monthly sales of over 1,700 in month 18, the Leaf achieved about 1,700 units in month 7, the Prius PHEV achieved nearly 1,900 sales in month 8, and the Volt achieved more than 2,900 sales in month 23. A 2016 analysis by the Consumer Federation of America (CFA) found that 5 years after its introduction, sales of plug-in electric cars in the U.S. continued to outsell conventional hybrids. The analysis considered sales between January 2011 and December 2015.\n\nAn analysis by Scientific American found a similar trend at the international level when considering the global top selling PEVs over a 36-month introductory period. Monthly sales of the Volt, Prius PHV and Leaf are performing better than the conventional Prius during their respective introductory periods, with the exception of the Mitsubishi i-MiEV, which has been outsold most of the time by the Prius HEV over their 36-month introductory periods.\n\nAccording to Pike Research, global sales of plug-ins will surpass 1 million per year in 2017, after 7 years in the market and almost half the time it took hybrid electric vehicles to reach that sales threshold. As fuel economy standards in the U.S. have become more stringent and push automakers towards hybridization or full electrification, Bloomberg New Energy Finance forecast that 30% of new passenger vehicles in the United States will be plug-in hybrids or full battery electrics by 2030.\n\nThe U.S. Energy Information Administration (EIA) in its 2017 Annual Energy Outlook 2017 projected that all-electric vehicles sales in the United States will increase from less than 1% in 2016 to 6% in 2040 of total light-duty vehicles sold in the country, and plug-in hybrid electric vehicle sales will increase from less than 1% to 4% over the same period. According to the EIA projected sales of light-duty battery electric, plug-in hybrid electric, and hydrogen fuel cell vehicles will reach 1.5 million in 2025, about 9% of projected total sales of light-duty vehicles.\n\nAccording to Edmunds.com, leasing of plug-in cars instead of purchasing is dominant in the American market, with leasing accounting for 51% of all new all-electric cars and 73% of plug-in hybrids, compared with just 32% of gasoline-powered cars.\n\n, the market of used plug-in electric cars is concentrated in California, the state with the biggest pool of used plug-in vehicles, especially all-electrics, followed by Colorado, Florida, Georgia, New York, Oregon and Texas. With the exception of used Teslas, all models depreciate more rapidly than conventionally powered cars and trucks. For all-electric cars depreciation varies between 60% to 75% in three years. In contrast, most conventionally powered vehicles in the same period depreciate between 45% to 50% . The Tesla Model S is more like conventional cars, with three-year depreciation of about 40%. And plug-in hybrids depreciate less than all-electric cars but still depreciate faster than conventionally powered cars.\n\nResearchers from the University of California, Davis conducted a study to identify the factors influencing the decision to adopt high-end battery electric vehicles (BEV), such as the Tesla Model S, as these vehicles are remarkably different from mainstream BEVs. Based on a questionnaire responded by 539 high-end adopters and in-depth interviews with 33 adopters, the 2016 study found that \"environmental, performance, and technological motivations are reasons for adoption; the new technology brings a new segment of buyers into the market; and financial purchase incentives are not important in the consumer’s decision to adopt a high-end BEV.\"\n\n\nFive states had more than two plug-in vehicles registered per 1,000 people in 2015, of which, three are located in the West Coast. California had the highest concentration with 4.68 PEVs per 1,000 people. Hawaii ranked second (2.94) followed by Washington (2.32), Georgia (2.20), and Oregon (2.04). Mississippi (0.09), Louisiana (0.14), North Dakota (0.15), Arkansas (0.15), and Wyoming (0.16) had the lowest concentration of plug-in cars.\n\nAmong the Eastern states, Georgia is the only one with over two PEVs per 1,000 people, likely the result of the generous state incentives that were offered until mid-2015. Other Eastern states with high concentration of plug-ins are Vermont (1.67), Michigan (0.99), Maryland (0.98), Connecticut (0.96), and also the District of Columbia (1.01). Among other regions, Colorado had the highest concentration with 1.09 PEVs per 1,000 people, followed by Arizona (0.93).\n\n, the U.S. average concentration was 1.51 plug-in cars registered per 1,000 people, while California's concentration had increased to 5.83 registrations per 1,000 people. Only Norway exceeds California's plug-in concentration per capita, by 3.69 times, but California narrowly outpaces the Netherlands (5.63), the world's second largest PEV market after Norway in terms of the plug-in segment market share of new car sales.\n\n\nDuring 2013 the top selling all-electric car markets at the state level in terms of their market share of new light-vehicle registrations were Washington (1.4%), California (1.28%) and Hawaii (1.21%), while the U.S. average was 0.32%. During the first half of 2014 the leading states were Georgia (1.6%), California (1.41%) and Washington (1.13%), and the national average remained at 0.32%. In the 12 months between April 2013 and March 2014, the top selling pure electric car metropolitan markets in terms of market share were San Francisco-Oakland-San Jose (3.33%), Atlanta (2.15%), Seattle-Tacoma (1.83%), Honolulu (1.71%), and Monterey-Salinas (1.51%).\n\nThe following table summarizes the ten states and metropolitan areas leading all-electric car adoption in terms of their market share of new light-vehicle registrations or sales.\n\nA total of 52% of American plug-in electric car registrations from January to May 2013 were concentrated in five metropolitan areas: San Francisco (19.5%), Los Angeles (15.4%), Seattle (8.0%), New York (4.6%) and Atlanta (4.4%). From January to July 2013, the three cities with the highest all-electric car registrations were all located in California, Atherton and Los Altos in the Silicon Valley, followed by Santa Monica, located in Los Angeles County.\n\nGovernor Jerry Brown issued an executive order in March 2012 that established the goal of getting 1.5 million zero-emission vehicles (ZEVs) in California by 2025. In January 2018, Governor Brown set a new goal of getting a total of 5 million zero-emission vehicles in California by 2030.\n\nCalifornia is the largest American car market with about 10% of all new car sales in the country. , cumulative sales of plug-in cars totaled 491,000 units, making California the leading plug-in market in the country. The state accounted for approximately 48% of cumulative plug-in sales in the American market from 2011 to June 2016, and also accounted for about 50% of nationwide all-electric car sales and 47% of total plug-in hybrid sales. Plug-in electric cars represented about 0.5% of the passenger fleet on the Californian roads by September 2015.\n\nUntil December 2014 California not only had more plug-in electric vehicles than any other American state but also more than any other country in the world. In 2015 only two countries, Norway (22.4%) and the Netherlands (9.7%), achieved a higher plug-in market share than California. By November 2016, with about 250,000 plug-in cars sold in the state since 2010, China was the only country market that exceeds California in terms of cumulative plug-in electric car sales. In 2015, California's plug-in car market share was 4.7 times higher than the U.S. market, and registrations of plug-in electric cars in the state in 2015 represented 54.5% of total plug-in car sales in the U.S. that year. California's plug-in car market share was 3.5% of new car sales in 2016, while the U.S. take-rate was 0.90%. In 2017, the state's market share reached nearly 5%, while the national share was 1.1%. \n\nCalifornia has been a leader in the promotion of plug-in electric vehicles as the state has in place several financial and non-financial incentives. In addition to the existing federal tax credit, PEVs are eligible for a purchase rebate of up to through the Clean Vehicle Rebate Project (CVRP). Also, battery electric vehicles and initially, the first 40,000 applicants that purchase or lease a plug-in hybrid meeting California’s Enhanced Advanced Technology Partial Zero Emission Vehicle (Enhanced AT PZEV), are entitled to a clean air sticker that allows the vehicle to be operated by a single occupant in California's carpool or high-occupancy vehicle lanes (HOV). The white access sticker is reserved for zero-emissions vehicles, while plug-in hybrids use the green sticker. , the limits for plug-in hybrids and experation dates have been extended several timeas, and both the white and green stickers have the same expiration date, January 1, 2019.\n\nIn March 2016 California added income-based caps to its rebate system. Buyers with incomes less than 300% of the Federal poverty level will get up to for a plug-in hybrid, for an all-electric car, and for a hydrogen fuel-cell car and the rebate scales down until Californian buyers with incomes over are no longer are eligible for incentives on hybrids or electric cars, however can get . As of March 2016, the Center for Sustainable Energy has issued more than $291 million in the CVRP for over 137,200 vehicles since 2010.\nThe income-base caps went into effect on 1 November 2016. Residents will not be eligible for rebates if their gross annual income exceeds for single tax filers, for head of household filers and for joint filers. These limits do not apply to the purchase of fuel cell electric vehicles, which represent less than 1% of rebate applications.\n\nGeorgia ranked second in the U.S. after California in terms of total plug-in electric vehicles on the road by mid-2014 . During the first half of 2014 Georgia ranked as the top selling all-electric car market in the U.S. at the state level with a 1.6% share of new light-vehicle registrations, ahead of California (1.41%), and up from 0.94% during 2013. , there were about 12,000 electric vehicles registered in the state, of which, about 80% are registered in metro Atlanta’s five core counties. In the 12 months between April 2013 and March 2014, metro Atlanta was the second top selling all-electric car metropolitan market in the U.S., with a market share of 2.15% of total new light-vehicle sales in the state, 5.6 times the national average share of 0.38%. Savannah ranks second in the state after Atlanta, with a market share of 0.13% of total new light-vehicle sales.\n\nBetween August 2013 and May 2014, Atlanta was the top U.S. metropolitan market for the Nissan Leaf for eight out of the ten months, and until July 2013, Atlanta was the third largest Leaf market behind San Francisco and Los Angeles. Leaf sales are favored by Georgia's law, which caps sales of electric vehicles sold direct by a manufacturer to 150, setting a restrictive limit to Tesla Model S sales, and the law excluded plug-in hybrids for eligibility to the state's tax credit.\n\nThe State of Georgia considers alternative fuel vehicles (AFVs) those that run solely on alternative fuel and do not run on regular gasoline. AFVs includes vehicles that operate using battery electricity, propane, natural gas, and hydrogen fuel cell. As incentives to accelerate all-electric vehicle adoption, in addition to the existing federal tax credit, Georgia offers an income tax credit of 20% of the vehicle cost up to for the purchase or leasing of a zero emission vehicle (ZEV). Plug-in hybrids are not eligible for this incentive because sometimes they are powered by electricity from their on-board combustion engine. There is also a 10% tax credit up to for the purchase and installation of qualified electric vehicle charger. This tax credit applies only to non-retail business enterprises and chargers installed at homes do not qualify.\nAn income tax credit for the purchase of a new commercial medium-duty or heavy-duty AFVs started on July 1, 2015. Medium-duty hybrid electric vehicles also qualify. Eligible medium-duty AFVs with a gross vehicle weight rating (GVWR) between qualify for a credit of up to , while heavy-duty AFVs with a GVWR over qualify for a credit of up to . The credit is capped at per taxpayer. Qualified AFVs must be purchased before June 30, 2017, remain registered in Georgia for at least five years, and accumulate at least 75% of their annual mileage in Georgia. Up to in total credits will be available each fiscal year.\n\nThe definition of alternate fuel vehicle for the purposes of an AFV License Plate in Georgia is different from the one for tax credit purposes. The Official Code of Georgia Annotated defines an AFV as a vehicle that has been certified by the EPA in accordance with the Federal Clean Air Act, therefore, both all-electric vehicles and plug-in hybrids are eligible for Georgia's AFV license plate. All vehicles displaying a GA alternative fuel license plate are allowed to use high occupancy vehicle lanes (HOV) regardless of number of passengers. Alternative fuel vehicles displaying the proper alternative fuel license plat may obtain a Peach Pass electronic tag that grants them toll-free access to all Peach Pass controlled high-occupancy toll lanes (HOT) lanes.\n\nGeorgia Power, the primary utility in Atlanta, offers a time-of-use electric vehicle plan designed for plug-in charging. , the plan has about 1,500 customers statewide. For a monthly fee of , the utility lowers the overnight rate to 1.3 cents per Kilowatt hour (kWh) while raising the peak rate, from 2-7 p.m. from June through September, to 20.3 cents per kWh. There is also a shoulder rate of 6.2 cents per Kwh in between those times. The average U.S. rate is 11.88 cents per kWh.\n\n, Georgia had 238 charging stations with 548 public outlets available across the state. Of these, about 120 public charging stations are located in metro Atlanta, with only about half of these located inside the city limits of Atlanta. Considering the rapid growth of electric cars in the city, there is a shortage of charging infrastructure relative to supply of electric vehicles.\n\nThe city of Atlanta is considering legislation to attend the needs of electric car owners and others who want to provide electric vehicle charging at their business, multifamily dwelling or private home. The measure aims to remove a major barrier to owning an electric vehicle by encouraging office and residential landlords to install electric vehicle chargers and reserved parking. Under the proposal, each electric vehicle charging station would be counted as one parking space, and the minimum parking requirement for developers and builders would be reduced by one space for each charging station provided, allowing up to a 10% reduction in minimum parking requirements. The city also wants to simplify the process required to obtain a permit to install electric vehicle chargers and make the spaces more identifiable.\n\nHawaii has a high potential for mass adoption of plug-in electric vehicles due to the limited driving range imposed by the island geographies, and its high fuel costs, with gasoline prices, , ranging between and a gallon. The number of registered plug-in electric vehicles increased from 581 units in 2011, to 967 in 2012, and reached 1,551 units in June 2013. , a total of 2,821 plug-in highway legal plug-in electric cars have been registered in Hawaii.\n\nIn terms of EV adoption, Hawaii ranked in 2013 as the state with the third highest all-electric car market share with 1.21% of new car sales, and during the first half of 2014 ranked fourth with a 1.04% market share. Accounting for sales of pure electric cars between April 2013 and March 2014, the Honolulu metropolitan area ranks as the fourth top selling BEV metro market in the United States, with 1.71% of new car sales.\n\nIn January 2011 the state implemented a purchase rebate of up to available for both the purchase of a plug-in electric car purchase and a charging station, but limited to for the vehicle. The rebate ended in May 2012 as high consumer demand depleted the fund. More than 450 rebates were issued totaling about . Several efforts to add more funds were unsuccessful.\n\n, there were 2,282 all-electric cars registered in Maryland. Sales of the Nissan Leaf and Tesla Model S account for about 70% of the electrics registered in the state. As part of the incentives to promote electric vehicle adoption, drivers of approved plug-in electric vehicles can use Maryland's high occupancy vehicle (HOV) lanes at all times, even if they are traveling solo. This incentive is in effect until September 30, 2017.\n\nPlug-in electric vehicles purchased new and titled for the first time between July 1, 2014, and July 1, 2017, are eligible for a credit up to , calculated as per kWh of battery capacity. Buyers of PEVs may apply for a tax credit against the imposed excise tax. The credit is returned to the taxpayer in the form of a check from the state. The tax credit is limited to one vehicle per individual and 10 vehicles per business. A qualified vehicle must meet the following criteria:\n\n\nThe state also offers a rebate for buying and installation of wall connectorsfor individuals, for business, or state or local governments, and for retail service station dealers. Between July 1, 2014, and June 30, 2016, rebate amounts are equal to the previous amounts, up to 50% of the costs of acquiring and installing qualified chargers.\n\nThe stock of plug-in electric vehicles in New York climbed from 1,000 units in early 2012, to over 10,000 plug-in vehicles by mid-September 2,014. The state of New York set the goal to deploy up to 3,000 EV charging stations in public and workplace locations across the state by 2018. , there are about 1,000 charging stations.\n\nPlug-in electric vehicles and hybrid electric vehicles with a combined fuel economy rating of at least and that also meet the California Air Resources Board SULEV emissions standard, are eligible for the Clean Pass Program. Eligible vehicles which display the Clean Pass vehicle sticker are allowed to use the Long Island Expressway HOV lanes, regardless of the number of occupants. Drivers of qualified vehicles may also receive a 10% discount on established E-ZPass accounts with proof of registration. In New York state there are no purchase incentives.\n\n, there were about 3,500 plug-in electric vehicles registered in Oregon. In 2013 the state was the fifth top selling all-electric car market in the U.S. at the state level with a 0.89% market share of new light-vehicle registrations, more than twice the national average share of 0.32%. During the first half of 2014 Oregon BEV share fell to 0.67% but continued to rank in the fifth place among the top selling states.\n\nIn the 12 months between April 2013 and March 2014, two metropolitan areas in Oregon ranked among the top ten selling all-electric car metropolitan markets in the U.S. Portland ranked eighth with a 1.25% market share of total new light-vehicle sales, ahead of Los Angeles metropolitan area, and Eugene ranked in number 10 with a market share of 0.86%. The national average share during this period was 0.38%.\n\nA tax credit for the purchase of a new all-electric vehicle is no longer available. There is a tax credit up to to cover 25% of the cost of purchasing and installing an electric vehicle charger station, and 35% for business owners. Beginning January 1, 2015, business owners that purchase two or more all-electric vehicles may be eligible for a tax credit of 35% of eligible costs for the incremental cost of purchasing the vehicles. This incentive ends on December 31, 2018.\n\nElectric Avenue is a joint research and development initiative of Portland State University (PSU), Portland General Electric (PGE), and the City of Portland. The Electric Avenue was launched in August 2011 to learn about the interaction and performance of charging stations and a variety of electric vehicles. The initiative also aimed to understand the charging preferences and travel patterns of electric vehicle visitors. The charging infrastructure includes quick chargers and both Level 1 and Level 2 charging stations powered by 100% renewable energy from PGE, and offers charging at standard city parking rates. The site comprises eight on street parking spaces with seven available charging stations located along an entire block. The Electric Avenue is located in the south end of downtown Portland, at the PSU’s campus adjacent to Portland’s Sixth Avenue Transit Mall where light rail trains, electric street cars, buses, cars, bikes, and pedestrians share a well-integrated personal and public transit corridor.\n\nTexas is the second largest light-duty vehicle market in the U.S. after California, with over 20 million passenger and light truck vehicles registered at the end of 2013. , there were about 5,000 plug-in electric vehicles registered in the state. Accounting for sales of new all-electric vehicles between April 2013 and March 2014, the top three selling metropolitan markets in Texas in terms of market share of total new light-vehicle sales were the Austin metropolitan area with 0.47%, followed by Dallas-Ft. Worth with 0.21% and Houston area with 0.15%. The national average share for the period was 0.38%, with Austin ranking in 15th place, and together with metro Atlanta, the only two cities in the top 15 that are not located on the West Coast.\n\nIn November 2013 the Texas Commission on Environmental Quality approved a rebate program to provide financial incentives up to for the purchase or lease of new eligible vehicles powered by compressed natural gas (CNG), liquefied petroleum gas (LPG), or plug-in electric drive with battery capacity larger than 4 kWh. The rebate amount for leasing depends on the lease term, only 4-year lease terms are eligible for the full , just like new car purchases. Total funding for the program is , and the maximum number of vehicles allowed is 2,000 units for each plug-in electric drive and natural gas/propane vehicles for the length of the program. Only purchases made on or after May 13, 2014 are eligible to apply for a rebate, and the program ends June 26, 2015 or until funding ends. , there were remaining in the rebate fund.\n\nAmong plug-in cars sold nationwide, the Tesla Model S is not eligible for the rebate because only new PEVs purchased or leased from a dealer or leasing company licensed to operate in Texas may qualify. Tesla Motors is not authorized to sell its vehicles in the state due to its direct-sales business model. But customers can buy directly from the company's website like in any other state.\n\nDespite the low penetration of plug-in electric vehicles in the state, the Texas River Cities Plug-In Electric Vehicle Initiative (TRC) is one of the most comprehensive plans for electric vehicles and their infrastructure aimed to increase the long-term success of PEV adoption. The TRC initiative encompasses two major metropolitan areas in and around Austin and San Antonio. Austin Energy, one of the project partners, had deployed 239 utility-operated publicly accessible charging stations in the TRC region by 2012. The utility company is the recipient of the U.S. Department of Energy funding for this initiative. The TRC region is projected to have 4,259 PEVs in 2015 and 17,336 in 2020.\n\nThis demonstration project is run by the Pecan Street Inc., a University of Texas based research consortium of research and industry partners focused on developing and testing advanced technology, business model, and customer behavior surrounding energy management systems. The project is supported by a smart grid demonstration grant from the U.S. Department of Energy and more than in matching funds from the project partners. The demonstration project began in 2010 and is taken place with volunteer residents at the Mueller neighborhood, a planned green community in Austin. The Pecan Street hosts an electric vehicle research program and provides incentives to participants with rebates of and to lease or purchase a PEV that is in addition to the federal tax credits. Through the research program, Pecan Street is studying grid load and monitoring home energy use through management equipment. As a result of the incentive program, Mueller has more plug-in electric vehicles per capita than any other U.S. neighborhood.\n\nGeneral Motors is a sponsor of the Pecan Street demonstration and is supporting the project to learn the charging patterns of plug-in electric car owners, and to study how a residential fleet of electric vehicles might strain the electric grid if all owners try to charge them at the same, which is what the preliminary monitoring found when the plug-in cars return home in the evening. , the community had nearly 60 Chevrolet Volt owners alone thanks to GM's commitment to match the federal government's rebate incentive, which halves the purchase price of the Volt.\n\nThe state set a goal to have 50,000 electric or other clean vehicles on the road by 2020. , there were 30,701 battery-powered and plug-in electric cars registered in Washington. The Seattle metropolitan area concentrated 76% of the state PEV registrations, with 18,154 plug-ins in King County (59%), where the city of Seattle is located, 3,153 in Snohomish County (10.3%), and 2,040 in Pierce County (6.6%). Outside the metro area, Clark County has the largest number of PEV registrations with 1,467 units (4.8%).\n\nWashington was the top selling all-electric car market in the U.S. at the state level in 2013 with a 1.40% market share of new light-vehicle registrations, ahead of California (1.28%). Washington PEV share in 2013 was more than four times the national average share of 0.32%. In the 12 months between April 2013 and March 2014, Seattle-Tacoma metro ranked as the third top selling all-electric car metropolitan market with a 1.83% market share of total new light-vehicle sales, only behind San Francisco-Oakland-San Jose (3.33%) and Atlanta (2.15%).\n\nNew passenger cars, light-duty trucks, and medium-duty passenger vehicles that operate exclusively on electricity, hydrogen, natural gas, or propane are exempt from state motor vehicle sales and use taxes. Qualified vehicles must also meet the California motor vehicle emissions standards, and comply with the rules of the Washington Department of Ecology. The initial sales tax exemption expired on July 1, 2015. The sales tax exemption was renewed on July 1, 2015, for four years, but the incentive was limited to new plug-in cars that cost less than . The approved cap excludes what legislators considered as luxury cars such as Tesla Motors and BMW i electric models. The same legislations that extended the incentives through 2019, raised the annual registration renewal fee for plug-in car owners from to . That annual fee is designed to make electric vehicle drivers contribute toward highway maintenance in lieu of the gas taxes PEVs do not pay.\n\nIn April 2016 governor Jay Inslee signed legislation to provide up to about off the purchase or lease of a new car all-electric vehicle, or a plug-in hybrid with at least of all-electric range – such as the Chevrolet Volt and the BMW i3 REx. The new law also raises the previous purchase price cap to , which will allow buyers of the Chevrolet Bolt EV, the next generation Nissan Leaf, and the Tesla Model 3 – all with of electric range – to be eligible for the incentive. The new law goes into effect on July 1, 2016. Under the updatede scheme, the sales tax exemption applies to the first of the selling price of a qualifying new plug-in electric car, which translates into a tax savings between to for plug-in car buyers depending on where the dealer is located within the state, as the sales tax vary by county. The tax exemption could expire before July 2019 if sales of electric vehicles accelerate because legislators established that the tax break should end the month after 7,500 qualifying vehicles are sold in the state. The state Department of Licensing was directed to start a tally beginning with PEV registrations since July 15, 2015. , the state sales tax is 6.5%, and increases up to 9.8% depending on the county rate.\n\nPuget Sound Energy (PSE) provides a rebate to the first 5,000 qualified customers for the purchase and installation of Level 2 electric vehicle charging station (EVSE). Eligible applicants must be PSE residential electric schedule 7 customers, must be the registered owner of an electric vehicle, and must install the charging station within a specified timeframe. PSE expects the rebate program to remain available until November 1, 2016, depending on available funds.\n\n, there were 41 highway legal plug-in cars available in the American market for retail sales, 16 all-electric cars and 25 plug-in hybrids. , sales were concentrated to a few models, with only seven selling more than 1,000 units sold in December 2016, and the top 5 best selling plug-in cars accounting for about 65% of total 2016 sales. Car manufacturers are offering plug-in electric cars in the U.S. for retail customers under 19 brands or marques: Audi, BMW, Cadillac, Chevrolet, Chrysler, Fiat, Ford, Honda, Hyundai, Kia, Mercedes-Benz, Mitsubishi, Nissan, Porsche, Smart, Tesla, Toyota, Volkswagen, and Volvo.\n\n, only the Chevrolet Volt, Nissan Leaf, Tesla's Model S and Model X, BMW i3, Mitsubishi i, Porsche Panamera S E-Hybrid, Cadillac ELR, and Ford’s C-Max and Fusion Energi plug-in hybrids were available nationwide. Several models, such as the Toyota RAV4, Fiat 500e, Honda Fit EV, and Chevrolet Spark EV, are compliance cars sold in limited markets, mainly California, available in order to raise an automaker’s fleet average fuel economy to satisfy regulator requirements. , out of the 14 plug-in hybrid models available in the American market, nine were upscale models affordable only for high income customers, namely the BMW X5 xDrive, Audi A3 e-tron, Porsche Cayenne and Panamera S E-Hybrids, Volvo XC90 T8, Mercedes S500, BMW i8, 3 Series iPerformance, and the Cadillac ELR, all priced above . Among all-electric cars, the BMW i3, Tesla Model S and Model X are also in the upscale category.\n\nThe following table presents key features and cumulative sales of highway-capable plug-in electric cars launched in the American market since 2008 through December 2016.\n\nWith the exception of Tesla Motors, almost all new cars in the United States are sold through dealerships, so they play a crucial role in the sales of electric vehicles, and negative attitudes can hinder early adoption of plug-in electric vehicles. Dealers decide which cars they want to stock, and a salesperson can have a big impact on how someone feels about a prospective purchase. Sales people have ample knowledge of internal combustion cars while they do not have time to learn about a technology that represents a fraction of overall sales. As with any new technology, and in the particular case of advanced technology vehicles, retailers are central to ensuring that buyers, especially those switching to a new technology, have the information and support they need to gain the full benefits of adopting this new technology. A 2016 study indicated that 60% of Americans were not aware of electric cars.\n\nThere are several reasons for the reluctance of some dealers to sell plug-in electric vehicles. PEVs do not offer car dealers the same profits as gasoline-powered car. Plug-in electric vehicles take more time to sell because of the explaining required, which hurts overall sales and sales people commissions. Electric vehicles also may require less maintenance, resulting in loss of service revenue, and thus undermining the biggest source of dealer profits, their service departments. According to the National Automobile Dealers Association (NADS), dealers on average make three times as much profit from service as they do from new car sales. However, a NADS spokesman said there was not sufficient data to prove that electric cars would require less maintenance. According to the New York Times, BMW and Nissan are among the companies whose dealers tend to be more enthusiastic and informed, but only about 10% of dealers are knowledgeable on the new technology.\n\nA study conducted at the Institute of Transportation Studies (ITS), at the University of California, Davis (UC Davis) published in 2014 found that many car dealers are less than enthusiastic about plug-in vehicles. ITS conducted 43 interviews with six automakers and 20 new car dealers selling plug-in vehicles in California’s major metro markets. The study also analyzed national and state-level J.D. Power 2013 Sales Satisfaction Index (SSI) study data on customer satisfaction with new car dealerships and Tesla retail stores. The researchers found that buyers of plug-in electric vehicles were significantly less satisfied and rated the dealer purchase experience much lower than buyers of non-premium conventional cars, while Tesla Motors earned industry-high scores. According to the findings, plug-in buyers expect more from dealers than conventional buyers, including product knowledge and support that extends beyond traditional offerings.\n\nIn 2014 \"Consumer Reports\" published results from a survey conducted with 19 secret shoppers that went to 85 dealerships in four states, making anonymous visits between December 2013 and March 2014. The secret shoppers asked a number of specific questions about cars to test the salespeople’s knowledge about electric cars. The consumer magazine decided to conduct the survey after several consumers who wanted to buy a plug-in car reported to the organization that some dealerships were steering them toward gasoline-powered models. The survey found that not all sales people seemed enthusiastic about making PEV sales; a few outright discouraged it, and even one dealer was reluctant to even show a plug-in model despite having one in stock. And many sales people seemed not to have a good understanding of electric-car tax breaks and other incentives or of charging needs and costs. \"Consumer Reports\" also found that when it came to answering basic questions, sales people at Chevrolet, Ford, and Nissan dealerships tended to be better informed than those at Honda and Toyota. The survey found that most of the Toyota dealerships visited recommended against buying a Prius Plug-in and suggested buying a standard Prius hybrid instead. Overall, the secret shoppers reported that only 13 dealers “discouraged sale of EV,” with seven of them being in New York. However, at 35 of the 85 dealerships visited, the secret shoppers said sales people recommended buying a gasoline-powered car instead.\n\nThe ITS-Davis study also found that a small but influential minority of dealers have introduced new approaches to better meet the needs of plug-in customers. Examples include marketing carpool lane stickers, enrolling buyers in charging networks, and preparing incentive paperwork for customers. Some dealers assign seasoned sales people as plug-in experts, many of whom drive plug-ins themselves to learn and be familiar with the technology and relate the cars' benefits to potential buyers. The study concluded also that carmakers could do much more to support dealers selling PEVs.\n\nAccording to a 2011 study by Pike Research, annual sales of plug-in electric vehicles in the U.S. were predicted to reach 360,000 vehicles by 2017. The study projected that the highest sales between 2011 and 2017 would take place in California, New York and Florida. In 2012, and as sales have fallen short of projections, Pike Research projected that annual sales of plug-in electric vehicles in the U.S. will reach 400,073 units in 2020, with California as the state with the highest PEV sales over the remainder of this decade, with nearly 25% of all PEVs sold in the United States between 2012 and 2020. In terms of market share, California will be followed by New York, Florida, Texas, and Washington, but Hawaii is expected by 2020 to have the highest penetration rate of PEVs as a percentage of all light duty vehicle sales. California is predicted to have four of the top ten metropolitan areas for PEV sales: Los Angeles–Long Beach, San Francisco Bay Area, Silicon Valley, and Greater Sacramento. Pike Research forecasts that cumulative sales of PEVs in the largest 102 American cities will reach more than 1.8 million from 2012 through 2020, with a share of more than 25% of all annual sales concentrated in the top five metropolitan areas for PEV sales: New York, Los Angeles, San Francisco, Seattle, and Portland.\n\nIn a separate analysis published in September 2013, Navigant Research forecasts that PEVs will represent a 2.4% market share of total new vehicle sales in the United States in 2022. Navigant also predicted that Hawaii will have the highest concentration of plug-in electric vehicle sales in the U.S., with 10.1% of total Hawaiian new light-duty vehicle sales in 2022; followed by Northern California with 9.7%, California as a whole will be 6.0%, and Oregon with 5.8%. Hawaii has a high potential for mass adoption of plug-in electric vehicles due to the limited driving range imposed by the islands size and its high fuel costs. In an updated report published in April 2014 Navigant forecasts that the United States will remain the largest national market for light-duty plug-in electric vehicles during the next 10 years, with the PEV segment growing at a compound annual growth rate of 16.3% between 2014 and 2023, predicting that annual PEV sales in the U.S. will exceed 514,000 in 2023.\n\nAccording to forecasts made by Pike Research in January 2013, the United States was expected to continue to be the largest market for PEVs in 2020, but the European market was anticipated to have a higher market penetration (4.0% market share) due to its higher gasoline prices and supportive government policies, while Japan was expected to become the largest market for hybrid electric vehicles. A similar trend was predicted by Navigant Research in a geographical forecast published in April 2014. Navigant predicted that by 2023 the fleet of light duty plug-in electric vehicles in use in Oslo is expected to represent 10.7% of the city's total registered light-duty fleet, 7.7% in Amsterdam, and 2.5% in Paris. Navigant also predicts that by 2020 annual PEV sales in the Greater Tokyo Area will surpass Los Angeles, currently the city with the largest PEV market. The PEV fleet in Tokyo is expected to reach a market penetration of 2.3% of the city's light-duty stock in 2023, and become the world's largest PEV city market with a PEV stock of around 260,000 in 2023, while Los Angeles is expected to have a stock of over 250,000 PEVs.\n\nThe chart and table are based on Department of Energy tables. (Table V1 and the Historical Data.) Figures for electric vehicles do not include privately owned vehicles, but do include Low-Speed Vehicles (LSVs), defined as \"four-wheeled motor vehicles whose top speed is ... ... to be used in residential areas, planned communities, industrial sites, and other areas with low density traffic, and low-speed zones.\"\nLSVs, more commonly known as neighborhood electric vehicles (NEVs), were defined in 1998 by the National Highway Traffic Safety Administration's \"Federal Motor Vehicle Safety Standard No. 500\", which required safety features such as windshields and seat belts, but not doors or side walls.\n\nSince 1998 Global Electric Motorcars (GEM), the market leader in North America, has sold more than 50,000 GEM battery-electric vehicles worldwide .\n\nThis is a list of all highway-capable plug-in electric vehicles available for retail customers in the U.S. for sale or leasing since the early 1990s.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe following is a list of plug-in hybrids with market launch scheduled up to 2020.\n\n\n\n"}
{"id": "34177870", "url": "https://en.wikipedia.org/wiki?curid=34177870", "title": "Pure shear", "text": "Pure shear\n\nIn mechanics and geology, pure shear is a three-dimensional homogeneous flattening of a body. It is an example of irrotational strain in which body is elongated in one direction while being shortened perpendicularly. For soft materials, such as rubber, a strain state of pure shear is often used for characterizing hyperelastic and fracture mechanical behaviour. Pure shear is differentiated from simple shear in that pure shear involves no rigid body rotation. \n\nIf formula_1 is the stretch ratio applied to the material, then the deformation gradient in pure shear can be expressed as\n\nThe linear elastic stress-strain law for the case of pure shear is:\n\n"}
{"id": "8147472", "url": "https://en.wikipedia.org/wiki?curid=8147472", "title": "Reactor protection system", "text": "Reactor protection system\n\nA reactor protection system (RPS) is a set of nuclear safety components in a nuclear power plant designed to safely shut down the reactor and prevent the release of radioactive materials. The system can \"trip\" automatically (initiating a scram), or it can be tripped by the operators. Trips occurs when the parameters meet or exceed the limit setpoint. A trip of the RPS results in full insertion (by gravity in pressurized water reactors or high-speed injection in boiling water reactors) of all control rods and shutdown of the reactor.\n\nSome of the measured parameters for US pressurized water plants would include:\n\n\nEach parameter is measured by independent channels such that actuation of any two channels would result in an automatic SCRAM or reactor shutdown. The system also allows manual actuation by the operator.\n\n"}
{"id": "54813", "url": "https://en.wikipedia.org/wiki?curid=54813", "title": "Shellac", "text": "Shellac\n\nShellac is a resin secreted by the female lac bug, on trees in the forests of India and Thailand. It is processed and sold as dry flakes (pictured) and dissolved in alcohol to make liquid shellac, which is used as a brush-on colorant, food glaze and wood finish. Shellac functions as a tough natural primer, sanding sealant, tannin-blocker, odour-blocker, stain, and high-gloss varnish. Shellac was once used in electrical applications as it possesses good insulation qualities and it seals out moisture. Phonograph and 78 rpm gramophone records were made of it until they were replaced by vinyl long-playing records from the 1950s onwards.\n\nFrom the time it replaced oil and wax finishes in the 19th century, shellac was one of the dominant wood finishes in the western world until it was largely replaced by nitrocellulose lacquer in the 1920s and 1930s.\n\n\"Shellac\" comes from \"shell\" and \"lac\", a calque of French \"laque en écailles\", \"lac in thin pieces\", later \"gomme-laque\", \"gum lac\". Most European languages (except Romance ones and Greek) have borrowed the word for the substance from English or from the German equivalent \"Schellack\".\n\nShellac is scraped from the bark of the trees where the female lac bug, \"Kerria lacca\" (order Hemiptera, family Kerriidae, also known as \"Laccifer lacca\"), secretes it to form a tunnel-like tube as it traverses the branches of the tree. Though these tunnels are sometimes referred to as \"cocoons\", they are not cocoons in the entomological sense. This insect is in the same superfamily as the insect from which cochineal is obtained. The insects suck the sap of the tree and excrete \"sticklac\" almost constantly. The least coloured shellac is produced when the insects feed on the kusum tree (\"Schleichera\").\n\nThe number of lac bugs required to produce of shellac has variously been estimated as , , or . The root word lakh is a unit in Indian numbering system for and presumably refers to the huge numbers of insects that swarm on host trees, up to 150 per square inch.\n\nThe raw shellac, which contains bark shavings and lac bugs removed during scraping, is placed in canvas tubes (much like long socks) and heated over a fire. This causes the shellac to liquefy, and it seeps out of the canvas, leaving the bark and bugs behind. The thick, sticky shellac is then dried into a flat sheet and broken into flakes, or dried into \"buttons\" (pucks/cakes), then bagged and sold. The end-user then crushes it into a fine powder and mixes it with ethyl alcohol before use, to dissolve the flakes and make liquid shellac.\n\nLiquid shellac has a limited shelf life (about 1 year), so is sold in dry form for dissolution before use. Liquid shellac sold in hardware stores is often marked with the production (mixing) date, so the consumer can know whether the shellac inside is still good. Some manufacturers (e.g., Zinsser) have ceased labeling shellac with the production date, but the production date may be discernible from the production lot code. Alternatively, old shellac may be tested to see if it is still usable: a few drops on glass should quickly dry to a hard surface. Shellac that remains tacky for a long time is no longer usable. Storage life depends on peak temperature, so refrigeration extends shelf life.\n\nThe thickness (concentration) of shellac is measured by the unit \"pound cut\", referring to the amount (in pounds) of shellac flakes dissolved in a gallon of denatured alcohol. For example: a 1-lb. cut of shellac is the strength obtained by dissolving one pound of shellac flakes in a gallon of alcohol. Most pre-mixed commercial preparations come at a 3-lb. cut. Multiple thin layers of shellac produce a significantly better end result than a few thick layers. Thick layers of shellac do not adhere to the substrate or to each other well, and thus can peel off with relative ease; in addition, thick shellac will obscure fine details in carved designs in wood and other substrates.\n\nShellac naturally dries to a high-gloss sheen. For applications where a flatter (less shiny) sheen is desired, products containing amorphous silica, such as \"Shellac Flat\", may be added to the dissolved shellac.\n\nShellac naturally contains a small amount of wax (3%–5% by volume), which comes from the lac bug. In some preparations, this wax is removed (the resulting product being called \"dewaxed shellac\"). This is done for applications where the shellac will be coated with something else (such as paint or varnish), so the topcoat will adhere. Waxy (non-dewaxed) shellac appears milky in liquid form, but dries clear.\n\nShellac comes in many warm colours, ranging from a very light blonde (\"platina\") to a very dark brown (\"garnet\"), with many varieties of brown, yellow, orange and red in between. The colour is influenced by the sap of the tree the lac bug is living on and by the time of harvest. Historically, the most commonly sold shellac is called \"orange shellac\", and was used extensively as a combination stain and protectant for wood panelling and cabinetry in the 20th century.\n\nShellac was once very common anywhere paints or varnishes were sold (such as hardware stores). However, cheaper and more abrasion- and chemical-resistant finishes, such as polyurethane, have almost completely replaced it in decorative residential wood finishing such as hardwood floors, wooden wainscoting plank panelling, and kitchen cabinets. These alternative products, however, must be applied over a stain if the user wants the wood to be coloured; clear or blonde shellac may be applied over a stain without affecting the colour of the finished piece, as a protective topcoat. \"Wax over shellac\" (an application of buffed-on paste wax over several coats of shellac) is often regarded as a beautiful, if fragile, finish for hardwood floors. Luthiers still use shellac to \"French polish\" fine acoustic stringed instruments, but it has been replaced by synthetic plastic lacquers and varnishes in many workshops, especially high-volume production environments.\n\nShellac is a natural bioadhesive polymer and is chemically similar to synthetic polymers, and thus can be considered a natural form of plastic. It can be turned into a moulding compound when mixed with wood flour and moulded under heat and pressure methods, so it can also be classified as thermoplastic.\n\nShellac scratches more easily than most lacquers and varnishes, and application is more labour-intensive, which is why it has been replaced by plastic in most areas. But damaged shellac can easily be touched up with another coat of shellac (unlike polyurethane) because the new coat merges with and bonds to the existing coat(s). Shellac is much softer than Urushi lacquer, for instance, which is far superior with regard to both chemical and mechanical resistance.\n\nShellac is soluble in alkaline solutions such as ammonia, sodium borate, sodium carbonate, and sodium hydroxide, and also in various organic solvents. When dissolved in de-natured alcohol or ethanol, shellac yields a coating of good durability and hardness.\n\nUpon mild hydrolysis shellac gives a complex mix of aliphatic and alicyclic hydroxy acids and their polymers that varies in exact composition depending upon the source of the shellac and the season of collection. The major component of the aliphatic component is aleuritic acid, whereas the main alicyclic component is shellolic acid.\n\nShellac is UV-resistant, and does not darken as it ages (though the wood under it may do so, as in the case of pine).\n\nThe earliest written evidence of shellac goes back years, but shellac is known to have been used earlier. According to the Mahabharata, an entire palace was built out of dried shellac.\n\nShellac was in rare use as a dyestuff for as long as there was a trade with the East Indies. Merrifield cites 1220 for the introduction of shellac as an artist's pigment in Spain. Lapis lazuli, an ultramarine pigment from Afghanistan, was already being imported long before this.\n\nThe use of overall paint or varnish decoration on large pieces of furniture was first popularised in Venice (then later throughout Italy). There are a number of 13th-century references to painted or varnished cassone, often dowry cassone that were made deliberately impressive as part of dynastic marriages. The definition of varnish is not always clear, but it seems to have been a spirit varnish based on gum benjamin or mastic, both traded around the Mediterranean. At some time, shellac began to be used as well. An article from the \"Journal of the American Institute of Conservation\" describes the use of infrared spectroscopy to identify a shellac coating on a 16th-century cassone. This is also the period in history where \"varnisher\" was identified as a distinct trade, separate from both carpenter and artist.\n\nAnother use for shellac is sealing wax. Woods's \"The Nature and Treatment of Wax and Shellac Seals\" discusses the various formulations, and the period when shellac started to be added to the previous beeswax recipes.\n\nThe \"period of widespread introduction\" would seem to be around 1550 to 1650, when the substance moves from being a rarity on highly decorated pieces to being described in the standard texts of the day.\n\nIn the early- and mid-twentieth century, orange shellac was used as a one-product finish (combination stain and varnish-like topcoat) on decorative wood panelling used on walls and ceilings in homes, particularly in the US. In the American South, use of knotty pine plank panelling covered with orange shellac was once as common in new construction as drywall is today. It was also often used on kitchen cabinets and hardwood floors, prior to the advent of polyurethane.\n\nUntil the advent of vinyl, most gramophone records were pressed from shellac compounds. From 1921 to 1928, tons of shellac were used to create 260 million records for Europe. In the 1930s, it was estimated that half of all shellac was used for gramophone records. Use of shellac for records was common until the 1950s and continued into the 1970s in some non-Western countries.\n\nUntil recent advances in technology, shellac (French polish) was the only glue used in the making of ballet dancers' pointe shoes, to stiffen the box (toe area) to support the dancer en pointe. Many manufacturers of pointe shoes still use the traditional techniques, and many dancers use shellac to revive a softening pair of shoes.\n\nShellac was historically used as a protective coating on paintings.\n\nSheets of Braille were coated with shellac to help protect them from wear due to being read by hand.\n\nShellac was used from the mid-nineteenth century to produce small moulded goods such as picture frames, boxes, toilet articles, jewelry, inkwells and even dentures. Advances in plastics have rendered shellac obsolete as a moulding compound.\n\nShellac (both orange and white varieties) was used both in the field and laboratory to glue and stabilise dinosaur bones until about the mid-1960s. While effective at the time, the long-term negative effects of shellac (being organic in nature) on dinosaur bones and other fossils is debated, and shellac is very rarely used by professional conservators and fossil preparators today.\n\nShellac was once used for fixing inductor, motor, generator and transformer windings, where it was applied directly to single-layer windings in an alcohol solution. For multi-layer windings, the whole coil was submerged in shellac solution, then drained and placed in a warm place to allow the alcohol to evaporate. The shellac then locks the wire turns in place, provides extra insulation and prevents movement and vibration, reducing buzz and hum. In motors and generators it also helps transfer force generated by magnetic attraction and repulsion from the windings to the rotor or armature. In more recent times, synthetic resins, such as glyptol, (Glyptal), have been substituted for the shellac. Some applications use shellac mixed with other natural or synthetic resins, such as pine resin or phenol-formaldehyde resin, of which Bakelite is the best known, for electrical use. Mixed with other resins, barium sulfate, calcium carbonate, zinc sulfide, aluminium oxide and/or cuprous carbonate (malachite), shellac forms a component of heat-cured capping cement used to fasten the caps or bases to the bulbs of electric lamps.\n\nIt is the central element of the traditional \"French polish\" method of finishing furniture, fine string instruments, and pianos.\n\nShellac, edible, is used as a glazing agent on pills (see excipient) and sweets, in the form of \"pharmaceutical glaze\" (or, \"confectioner's glaze\"). Because of its acidic properties (resisting stomach acids), shellac-coated pills may be used for a timed enteric or colonic release. Shellac is used as a 'wax' coating on citrus fruit to prolong its shelf/storage life. It is also used to replace the natural wax of the apple, which is removed during the cleaning process. When used for this purpose, it has the food additive E number E904.\n\nShellac coating applied with either a standard or modified Huon-Stuehrer nozzle, can be economically micro-sprayed onto various smooth sweets, such as chocolate coated peanuts. Irregularities on the surface of the product being sprayed typically result in the formation of unsightly aggregates (\"lac-aggs\") which precludes the use of this technique on foods such as walnuts or raisins (however, chocolate-coated raisins being smooth surfaced, are able to be sprayed successfully using a modified Huon-Stuehrer nozzle).\n\nBecause it is compatible with most other finishes, shellac is also used as a barrier or primer coat on wood to prevent the bleeding of resin or pigments into the final finish, or to prevent wood stain from blotching.\n\nShellac is an odour and stain blocker and so is often used as the base of \"solves all problems\" primers. Although its durability against abrasives and many common solvents is not very good, shellac provides an excellent barrier against water vapour penetration. Shellac-based primers are an effective sealant to control odours associated with fire damage.\n\nShellac has traditionally been used as a dye for cotton and, especially, silk cloth in Thailand, particularly in the north-eastern region. It yields a range of warm colours from pale yellow through to dark orange-reds and dark ochre. Naturally dyed silk cloth, including that using shellac, is widely available in the rural northeast, especially in Ban Khwao District, Chaiyaphum province. The Thai name for the insect and the substance is \"khrang\" (Thai: ครั่ง).\n\nShellac is used:\n\n"}
{"id": "12693013", "url": "https://en.wikipedia.org/wiki?curid=12693013", "title": "Smoke composition", "text": "Smoke composition\n\nA smoke composition is a pyrotechnic composition designed primarily to generate smoke. Smoke compositions are used as obscurants or for generation of signaling smokes. Some are used as a payload of smoke bombs and smoke grenades.\n\nSmoke compositions used as obscurants generate large amount of thick, usually white, smoke. The most common smoke composition for pyrotechnic generation of smoke screens is the zinc chloride smoke mixture (HC).\n\nZinc chloride smoke is grey-white and consists of tiny particles of zinc chloride. The most common mixture for generating these is the zinc chloride smoke mixture (HC), consisting of hexachloroethane, grained aluminium and zinc oxide. The smoke consists of zinc chloride, zinc oxychlorides, and hydrochloric acid, which absorb the moisture in the air. The smoke also contains traces of organic chlorinated compounds, phosgene, carbon monoxide, and chlorine.\n\nIts toxicity is caused mainly by the content of strongly acidic hydrochloric acid, but also due to thermal effects of reaction of zinc chloride with water. These effects cause lesions of the mucous membranes of the upper airways. Damage of the lower airways can manifest itself later as well, due to fine particles of zinc chloride and traces of phosgene. In high concentrations the smoke can be very dangerous when inhaled. Symptoms include dyspnea, retrosternal pain, hoarseness, stridor, lachrymation, cough, expectoration, and in some cases haemoptysis. Delayed pulmonary edema, cyanosis or bronchopneumonia may develop. The smoke and the spent canisters contain suspected carcinogens.\n\nThe prognosis for the casualties depends on the degree of the pulmonary damage. All exposed individuals should be kept under observation for 8 hours. Most affected individuals recover within several days, with some symptoms persisting for up to 1-2 weeks. Severe cases can suffer of reduced pulmonary function for some months, the worst cases developing marked dyspnea and cyanosis leading to death.\n\nRespirators are required for people coming into contact with the zinc chloride smoke.\n\nWhite phosphorus is a popular base for smoke production. It is used in artillery shells, bombs, and grenades.\n\nA colored smoke composition can be used for signalling. These are usually based on a low-temperature burning pyrotechnic composition, mixed with a dye that gets vaporized and creates large, colored smoke particles. The composition is often based on an oxidizer (e.g. potassium chlorate, potassium nitrate, or potassium perchlorate), a fuel (e.g. lactose), an optional coolant (e.g. sodium bicarbonate), and one or more dyes.\n\nSmoke with a suitable composition can be used as a fire suppression agent. A pyrotechnic composition similar to black powder, composed of 15% charcoal and 85% potassium nitrate, generates thick smoke composed of particles of mainly potassium carbonate, which has fire extinguishing properties. Two-kilograms smoke grenades, thrown into burning rooms through plate-glass windows, have been used by some European firefighters.\n\nSmoke compositions can be used also for creating aerosol of other materials than dyes. Generally the same type of pyrotechnic composition as for colored smokes is used, with the dye being replaced by the desired chemical. The devices usually have the form of smoke bombs.\n\nThe best known such application of smoke compositions is in riot control, for dispersion of lachrymatory agents. The agent used is most often CS gas, with less used alternatives CR gas, CN gas and Adamsite.\n\nIn agriculture, smoke compositions are used to disperse insecticides and fungicides. Some agents used in this manner are permethrin, cypermethrin, chlorpyrifos, imazalil, etc., and some fumigation agents.\n\nSmoke compositions can be also used for weather modification, namely cloud seeding, to provide cloud condensation nuclei for the moisture to precipitate. \n"}
{"id": "35543910", "url": "https://en.wikipedia.org/wiki?curid=35543910", "title": "Solarpark Eiche", "text": "Solarpark Eiche\n\nSolarpark Eiche is a 26.5-megawatt (MW) photovoltaic power station located in Ahrensfelde‐Eiche, Germany, near the capital Berlin, and covers an area of .\n\n"}
{"id": "37725767", "url": "https://en.wikipedia.org/wiki?curid=37725767", "title": "Tablet of Akaptaḫa", "text": "Tablet of Akaptaḫa\n\nThe tablet of Akaptaḫa, or Agaptaḫa, is an ancient Mesopotamian private commemorative inscription on stone of the donation of a 10 field (about 200 acres) by Kassite king Kaštiliašu IV (ca. 1232 BC – 1225 BC) to a fugitive leatherworker from Assyrian-occupied Ḫanigalbat in grateful recognition of his services provisioning the Babylonian army with bridles (\"pagumu\", a loanword from Hurrian or perhaps Kassite) .\n\nThe Mitanni kingdom of Ḫanigalbat, here given the Babylonian pronunciation \"Ḫaligalbatû\", had been annexed under the preceding reign of Adad-nārārī I (1307–1275 BC) or Salmānu-ašarēdu I (1274–1245 BC) and Akaptaḫa (a Hurrian name) seems to have been one of the political refugees (\"munnabittu\", refugee, displaced persion, foreigner) who consequently sought asylum in the Kassite kingdom. He made his home in Padan (var. Padnu), one of the eastern provinces somewhere (Jebel Hamrin, according to Jensen) in the upper Diyala region which had been claimed by the Kassites since the time of Agum II.\n\nThe object was recovered during the French excavations at Susa at the end of the 19th century, where it had been taken as war booty during one of the Elamite invasions following the overthrow of Kaštiliašu IV by Tukulti-Ninurta I, those of Kidin-Hutran III (ca. 1224 BC and 1217 BC), Shutruk-Nakhunte (ca. 1158 BC) and Kutir-Nahhunte II (1155 BC). \n\nThe tablet describes itself using the same term applied generally to kudurrus as a \"narû\", \"stele\", and falls into the same tradition of entitlement monuments, excepting the absence of religious iconography and the format of the granting and cursing formulae. The text invokes \"the gods of the king\", presumably the Kassite deities Šuqamuna and Šumalia. The inscription uses an informal mix of monumental and cursive cuneiform, precedes the royal name with a masculine ( or ) rather than the divine () or () determinative and spells his name with \"-ti-li-\" in place of the more usual \"–til-\", suggesting its provincial origin or perhaps its lack of authenticity.\n\nThe name Akaptaḫa appears on four accounts of salaries or ration lists from Nippur as the father of Ninurta-ašarēdu, dated to the sixteenth year of an unnamed king probably Nazi-Maruttaš (1291 BC), the father of Izkur-Šuqamuna, in the twentieth year of an unnamed king, that of Arunayû the twenty-first year of Kurigalzu II and as \"-Akaptaḫa\" on an inventory of gardening implements from Nazi-Maruttaš’ second year but these incidents are probably for someone else as they appear too early.\n"}
{"id": "4624037", "url": "https://en.wikipedia.org/wiki?curid=4624037", "title": "Throughfall", "text": "Throughfall\n\nIn Hydrology, throughfall is the process which describes how wet leaves shed excess water onto the ground surface. These drops have erosive power because they are larger than rain drops, however, if they travel a shorter distance their erosive power is reduced. In the case of a high canopy, higher than what is required for the drops to reach terminal velocity, about , the erosive power is increased.\n\nRates of throughfall are higher in areas of forest where the leaves are broad-leaved. This is because the flat leaves allow water to collect. Drip-tips also facilitate throughfall. Rates of throughfall are lower in coniferous forests as conifers can only hold individual droplets of water on their needles.\n\n"}
{"id": "25540633", "url": "https://en.wikipedia.org/wiki?curid=25540633", "title": "Toenailing", "text": "Toenailing\n\nToenailing or skew-nailing is a popular technique that carpenters use regularly to fix two timbers together by slanted application. The fasteners (nails or screws), used in pairs, are driven in on opposing angles. This locks the timbers together, to create a stable framework, e.g. in stud walls (partitions) or roof framing. The angled nailing makes later dismantling difficult or destructive. One of the most common places to toenail a framing member is where a rafter meets the top plate of a wall at the birdsmouth. Alternatives to toenailing include the use of hurricane ties, joist hangers, and other engineered steel connectors that permit nails to be attached perpendicular to a member's surface.\n\nWhen toenailing, nails can be driven from the inside or outside of the joint, depending on access available to use the hammer. Skew nailing is also a technique used by other woodworkers, for example a drawer or box can be glued and skew-nailed with finer nails or panel pins. Skew nailing will fasten the joint, while the glue sets, avoiding the use of clamps. A variation of toenailing is to use screws for the same purpose, which might be called toenailing or \"toe-screwing\".\n\n"}
{"id": "49002764", "url": "https://en.wikipedia.org/wiki?curid=49002764", "title": "Tornadoes of 1969", "text": "Tornadoes of 1969\n\nThis page documents the tornadoes and tornado outbreaks of 1969, primarily in the United States. Most tornadoes form in the U.S., although some events may take place internationally. Tornado statistics for older years like this often appear significantly lower than modern years due to fewer reports or confirmed tornadoes.\n"}
{"id": "45561", "url": "https://en.wikipedia.org/wiki?curid=45561", "title": "United States Secretary of Energy", "text": "United States Secretary of Energy\n\nThe United States Secretary of Energy is the head of the United States Department of Energy, a member of the Cabinet of the United States, and fifteenth in the presidential line of succession. The position was formed on October 1, 1977 with the creation of the Department of Energy when President Jimmy Carter signed the Department of Energy Organization Act. Originally the post focused on energy production and regulation. The emphasis soon shifted to developing technology for better and more efficient energy sources as well as energy education. After the end of the Cold War, the department's attention also turned toward radioactive waste disposal and maintenance of environmental quality. The current Secretary of Energy is Rick Perry\n\nFormer Secretary of Defense James Schlesinger was the first Secretary of Energy, who was a Republican nominated to the post by Democratic President Jimmy Carter, the only time a president has appointed someone of another party to the post. Schlesinger is also the only secretary to be dismissed from the post. Hazel O'Leary, Bill Clinton's first Secretary of Energy, was the first female and African-American holder. The first Hispanic to serve as Energy Secretary was Clinton's second, Federico Peña. Spencer Abraham became the first Arab American to hold the position on January 20, 2001, serving under the administration of George W. Bush. Steven Chu became the first Asian American to hold the position on January 20, 2009, serving under the administration of Barack Obama. He is also the longest-serving Secretary of Energy and the first individual to join the Cabinet having received a Nobel Prize.\n\n (6)\n (8)\n\nAs of , there are nine living former Secretaries of Energy, the oldest being Charles Duncan Jr. (served 1979–1981, born 1926). The most recent Secretary of Energy to die was Samuel Bodman (served 2005-2009, born 1938) on September 7, 2018. \n"}
{"id": "4002131", "url": "https://en.wikipedia.org/wiki?curid=4002131", "title": "Uranyl peroxide", "text": "Uranyl peroxide\n\nUranyl peroxide or uranium peroxide hydrate (UO·nHO) is a pale-yellow, soluble peroxide of uranium. It is found to be present at one stage of the enriched uranium fuel cycle and in yellowcake prepared via the \"in situ\" leaching and resin ion exchange system. This compound, also expressed as:\nUO·(HO)·(HO), is very similar to uranium trioxide hydrate UO·nHO. The dissolution behaviour of both compounds are very sensitive to the hydration state (n can vary between 0 and 4). One main characteristic of uranium peroxide is that it consists of small needles with an average AMAD of about 1.1 µm.\n\nThe uranyl minerals studtite, UO·4HO, and metastudtite, UO·2HO, are the only minerals discovered to date found to contain peroxide.\n\n"}
{"id": "3997849", "url": "https://en.wikipedia.org/wiki?curid=3997849", "title": "Uranyl sulfate", "text": "Uranyl sulfate\n\nUranyl sulfate (UOSO), a sulfate of uranium, is an odorless lemon-yellow sand-like solid in its pure crystalline form. It is prepared by dissolving UO in HSO.\n\nIt has found use as a negative stain in microscopy and tracer in biology. The Aqueous Homogeneous Reactor experiment, constructed in 1951, circulated a fuel composed of 565 grams of U-235 enriched to 14.7% in the form of uranyl sulfate.\n\nThe acid process of milling uranium ores involves precipitating uranyl sulfate from the pregnant leaching solution to produce the semi-refined product referred to as yellowcake.\n\nRadioactivity was discovered using potassium uranyl sulfate, KUO(SO).\n"}
{"id": "2415493", "url": "https://en.wikipedia.org/wiki?curid=2415493", "title": "Vanadium redox battery", "text": "Vanadium redox battery\n\nThe vanadium redox battery (VRB), also known as the vanadium flow battery (VFB) or vanadium redox flow battery (VRFB), is a type of rechargeable flow battery that employs vanadium ions in different oxidation states to store chemical potential energy. The vanadium redox battery exploits the ability of vanadium to exist in solution in four different oxidation states, and uses this property to make a battery that has just one electroactive element instead of two. For several reasons, including their relative bulkiness, most vanadium batteries are currently used for grid energy storage, i.e., attached to power plants or electrical grids.\n\nThe possibility of creating a vanadium flow battery was explored variously by Pissoort in the 1930s, NASA researchers in the 1970s, and Pellegri and Spaziante in the 1970s, but none of them were successful in demonstrating the technology. The first successful demonstration of the all-vanadium redox flow battery which employed vanadium in a solution of sulfuric acid in each half was by Maria Skyllas-Kazacos at the University of New South Wales in the 1980s. Her design used sulfuric acid electrolytes, and was patented by the University of New South Wales in Australia in 1986.\n\nThe main advantages of the vanadium redox battery are that it can offer almost unlimited energy capacity simply by using larger electrolyte storage tanks; it can be left completely discharged for long periods with no ill effects; if the electrolytes are accidentally mixed, the battery suffers no permanent damage; a single state of charge between the two electrolytes avoids the capacity degradation due to a single cell in non-flow batteries; the electrolyte is aqueous and inherently safe and non-flammable,; and the generation 3 formulation using a mixed acid solution developed by the Pacific Northwest National Laboratory operates over a wider temperature range allowing for passive cooling.\n\nThe main disadvantages with vanadium redox technology are a relatively poor energy-to-volume ratio in comparison with standard storage batteries (although the Generation 3 formulation has doubled the energy density of the system), and the aqueous electrolyte makes the battery heavy and therefore only useful for stationary applications.\n\nNumerous companies and organizations involved in funding and developing vanadium redox batteries include Vionx (formerly Premium Power), UniEnergy Technologies and Ashlawn Energy in the United States; Renewable Energy Dynamics Technology in Ireland; Gildemeister AG (formerly Cellstrom GmbH in Austria, energy division now defunct) in Germany; Cellennium in Thailand Rongke Power; Prudent Energy in China; Sumitomo in Japan; H2, Inc. in South Korea; redT in Britain., Australian Vanadium in Australia, and the now defunct Imergy (formerly Deeya). Lately, also several smaller size vanadium redox flow batteries were brought to market (for residential applications) mainly from StorEn Technologies (USA), Schmid Group, VoltStorage and Volterion (all three from Germany), VisBlue (Denmark) or Pinflow energy storage (Czechia).\n\nA vanadium redox battery consists of an assembly of power cells in which the two electrolytes are separated by a proton exchange membrane. The electrodes in a VRB cell are carbon based; the most common types being carbon felt, carbon paper, carbon cloth, and graphite felt. Recently, carbon nanotube based electrodes have gained marked interest from the scientific community. Both electrolytes are vanadium-based, the electrolyte in the positive half-cells contains VO and VO ions, the electrolyte in the negative half-cells, V and V ions. The electrolytes may be prepared by any of several processes, including electrolytically dissolving vanadium pentoxide (VO) in sulfuric acid (HSO). The solution remains strongly acidic in use.\n\nIn vanadium flow batteries, both half-cells are additionally connected to storage tanks and pumps so that very large volumes of the electrolytes can be circulated through the cell. This circulation of liquid electrolytes is somewhat cumbersome and does restrict the use of vanadium flow batteries in mobile applications, effectively confining them to large fixed installations.\n\nWhen the vanadium battery is being charged, the VO ions in the positive half-cell are converted to VO ions when electrons are removed from the positive terminal of the battery. Similarly in the negative half-cell, electrons are introduced converting the V ions into V. During discharge this process is reversed and results in a typical open-circuit voltage of 1.41 V at 25 °C.\n\nOther useful properties of vanadium flow batteries are their very fast response to changing loads and their extremely large overload capacities. Studies by the University of New South Wales have shown that they can achieve a response time of under half a millisecond for a 100% load change, and allowed overloads of as much as 400% for 10 seconds. The response time is mostly limited by the electrical equipment. Sulfuric acid-based vanadium batteries only work between about 10 and 40 °C. Below that temperature range, the ion-infused sulfuric acid crystallizes. Round trip efficiency in practical applications is around 65–75 %.\n\nSecond generation vanadium redox batteries (vanadium/bromine) may approximately double the energy density and increase the temperature range in which the battery can operate.\n\nDespite the traditional pumping requirements, nanoFlowcell AG has developed a proprietary system of energy storage for electric vehicle applications showcased through a number of Quant vehicle prototypes, using rapid replacement of electrolyte to refuel the battery.\n\nCurrent production vanadium redox batteries achieve a specific energy of about 20 Wh/kg (72 kJ/kg) of electrolyte. \nMore recent research at UNSW indicates that the use of precipitation inhibitors can increase the density to about 35 Wh/kg (126 kJ/kg), with even higher densities made possible by controlling the electrolyte temperature. This specific energy is quite low compared to other rechargeable battery types (e.g., lead–acid, 30–40 Wh/kg (108–144 kJ/kg); and lithium ion, 80–200 Wh/kg (288–720 kJ/kg)).\n\nA number of research groups worldwide have reported capacity loss in VRFBs over prolonged periods of use. While several causes have been considered, the influence of electrode microstructure on cell electrochemistry within the electrode is poorly known. Electrolytic wetting of carbon electrodes in VRFBs is important for overcoming sources of degradation and applying appropriate operational procedures. Recently, it appears that electrolytic wetting behaviour within the electrode may be influenced by local concentration effects as well as capillary action. Rapid wetting or permeation may also leave behind undissolved gases which could cause electrode degradation.\n\nThe extremely large capacities possible from vanadium redox batteries make them well suited to use in large power storage applications such as helping to average out the production of highly variable generation sources such as wind or solar power, helping generators cope with large surges in demand or leveling out supply/demand at a transmission constrained region.\n\nThe limited self-discharge characteristics of vanadium redox batteries make them useful in applications where the batteries must be stored for long periods of time with little maintenance while maintaining a ready state. This has led to their adoption in some military electronics, such as the sensor components of the GATOR mine system. Their ability to fully cycle and stay at 0% state of charge makes them suitable for solar + storage applications where the battery must start each day empty and fill up depending upon the load and weather. Lithium ion batteries, for example, are typically damaged when they are allowed to discharge below 20% state of charge, so they typically only operate between about 20% and 100%, meaning they are only using 80% of their nameplate capacity.\n\nTheir extremely rapid response times also make them superbly well suited to uninterruptible power supply (UPS) type applications, where they can be used to replace lead–acid batteries and even diesel generators. Also the fast response time makes them well-suited for frequency regulation. Economically neither the UPS or frequency regulation applications of the battery are currently sustainable alone, but rather the battery is able to layer these applications with other uses to capitalize on various sources of revenue. Also, these capabilities make vanadium redox batteries an effective \"all-in-one\" solution for microgrids that depend on reliable operations, frequency regulation and have a need for load shifting (from either high renewable penetration, a highly variable load or desire to optimize generator efficiency through time-shifting dispatch).\n\nA 200 MW, 800 MWh (4 hours) vanadium redox battery is under construction in China; it is expected to be completed by 2018.\n\n\n\n"}
{"id": "799521", "url": "https://en.wikipedia.org/wiki?curid=799521", "title": "Voltage multiplier", "text": "Voltage multiplier\n\nA voltage multiplier is an electrical circuit that converts AC electrical power from a lower voltage to a higher DC voltage, typically using a network of capacitors and diodes.\n\nVoltage multipliers can be used to generate a few volts for electronic appliances, to millions of volts for purposes such as high-energy physics experiments and lightning safety testing. The most common type of voltage multiplier is the half-wave series multiplier, also called the Villard cascade (but actually invented by Heinrich Greinacher).\n\nAssuming that the peak voltage of the AC source is +U, and that the C values are sufficiently high to allow, when charged, that a current flows with no significant change in voltage, then the (simplified) working of the cascade is as follows:\n\n\nIn reality more cycles are required for C to reach the full voltage. Each additional stage of two diodes and two capacitors increases the output voltage by twice the peak AC supply voltage.\n\nA \"voltage doubler\" uses two stages to approximately double the DC voltage that would have been obtained from a single-stage rectifier. An example of a voltage doubler is found in the input stage of switch mode power supplies containing a SPDT switch to select either 120 V or 240 V supply. In the 120 V position the input is typically configured as a full-wave voltage doubler by opening one AC connection point of a bridge rectifier, and connecting the input to the junction of two series-connected filter capacitors. For 240 V operation, the switch configures the system as a full-wave bridge, re-connecting the capacitor center-tap wire to the open AC terminal of a bridge rectifier system. This allows 120 or 240 V operation with the addition of a simple SPDT switch.\n\nA \"voltage tripler\" is a three-stage voltage multiplier. A tripler is a popular type of voltage multiplier. The output voltage of a tripler is in practice below three times the peak input voltage due to their high impedance, caused in part by the fact that as each capacitor in the chain supplies power to the next, it partially discharges, losing voltage doing so.\n\nTriplers were commonly used in color television receivers to provide the high voltage for the cathode ray tube (CRT, picture tube). \n\nTriplers are still used in high voltage supplies such as copiers, laser printers, bug zappers and electroshock weapons.\n\nWhile the multiplier can be used to produce thousands of volts of output, the individual components do not need to be rated to withstand the entire voltage range. Each component only needs to be concerned with the relative voltage differences directly across its own terminals and of the components immediately adjacent to it.\n\nTypically a voltage multiplier will be physically arranged like a ladder, so that the progressively increasing voltage potential is not given the opportunity to arc across to the much lower potential sections of the circuit.\n\nNote that some safety margin is needed across the relative range of voltage differences in the multiplier, so that the ladder can survive the shorted failure of at least one diode or capacitor component. Otherwise a single-point shorting failure could successively over-voltage and destroy each next component in the multiplier, potentially destroying the entire multiplier chain.\n\n\nAn even number of diode-capacitor cells is used in any column so that the cascade ends on a smoothing cell. If it were odd and ended on a clamping cell the ripple voltage would be very large. Larger capacitors in the connecting column also reduce ripple but at the expense of charging time and increased diode current.\n\nThe Dickson charge pump, or Dickson multiplier, is a modification of the Greinacher/Cockcroft–Walton multiplier. Unlike that circuit, however, the Dickson multiplier takes a DC supply as its input so is a form of DC-to-DC converter. Also, unlike Greinacher/Cockcroft–Walton which is used on high-voltage applications, the Dickson multiplier is intended for low-voltage purposes. In addition to the DC input, the circuit requires a feed of two clock pulse trains with an amplitude swinging between the DC supply rails. These pulse trains are in antiphase.\n\nTo describe the ideal operation of the circuit, number the diodes D1, D2 etc. from left to right and the capacitors C1, C2 etc. When the clock formula_1 is low, D1 will charge C1 to \"V\". When formula_1 goes high the top plate of C1 is pushed up to 2\"V\". D1 is then turned off and D2 turned on and C2 begins to charge to 2\"V\". On the next clock cycle formula_1 again goes low and now formula_4 goes high pushing the top plate of C2 to 3\"V\". D2 switches off and D3 switches on, charging C3 to 3\"V\" and so on with charge passing up the chain, hence the name charge pump. The final diode-capacitor cell in the cascade is connected to ground rather than a clock phase and hence is not a multiplier; it is a peak detector which merely provides smoothing.\n\nThere are a number of factors which reduce the output from the ideal case of \"nV\". One of these is the threshold voltage, \"V\" of the switching device, that is, the voltage required to turn it on. The output will be reduced by at least \"nV\" due to the volt drops across the switches. Schottky diodes are commonly used in Dickson multipliers for their low forward voltage drop, amongst other reasons. Another difficulty is that there are parasitic capacitances to ground at each node. These parasitic capacitances act as voltage dividers with the circuit's storage capacitors reducing the output voltage still further. Up to a point, a higher clock frequency is beneficial: the ripple is reduced and the high frequency makes the remaining ripple easier to filter. Also the size of capacitors needed is reduced since less charge needs to be stored per cycle. However, losses through stray capacitance increase with increasing clock frequency and a practical limit is around a few hundred kilohertz.\n\nDickson multipliers are frequently found in integrated circuits (ICs) where they are used to increase a low-voltage battery supply to the voltage needed by the IC. It is advantageous to the IC designer and manufacturer to be able to use the same technology and the same basic device throughout the IC. For this reason, in the popular CMOS technology ICs the transistor which forms the basic building block of circuits is the MOSFET. Consequently, the diodes in the Dickson multiplier are often replaced with MOSFETs wired to behave as diodes.\n\nThe diode-wired MOSFET version of the Dickson multiplier does not work very well at very low voltages because of the large drain-source volt drops of the MOSFETs. Frequently, a more complex circuit is used to overcome this problem. One solution is to connect in parallel with the switching MOSFET another MOSFET biased into its linear region. This second MOSFET has a lower drain-source voltage than the switching MOSFET would have on its own (because the switching MOSFET is driven hard on) and consequently the output voltage is increased. The gate of the linear biased MOSFET is connected to the output of the next stage so that it is turned off while the next stage is charging from the previous stage's capacitor. That is, the linear-biased transistor is turned off at the same time as the switching transistor.\n\nAn ideal 4-stage Dickson multiplier (5× multiplier) with an input of would have an output of . However, a diode-wired MOSFET 4-stage multiplier might only have an output of . Adding parallel MOSFETs in the linear region improves this to around . More complex circuits still can achieve an output much closer to the ideal case.\n\nMany other variations and improvements to the basic Dickson circuit exist. Some attempt to reduce the switching threshold voltage such as the Mandal-Sarpeshkar multiplier or the Wu multiplier. Other circuits cancel out the threshold voltage: the Umeda multiplier does it with an externally provided voltage and the Nakamoto multiplier does it with internally generated voltage. The Bergeret multiplier concentrates on maximising power efficiency.\n\nIn CMOS integrated circuits clock signals are readily available, or else easily generated. This is not always the case in RF integrated circuits, but often a source of RF power will be available. The standard Dickson multiplier circuit can be modified to meet this requirement by simply grounding the normal input and one of the clock inputs. RF power is injected into the other clock input, which then becomes the circuit input. The RF signal is effectively the clock as well as the source of power. However, since the clock is injected only into every other node the circuit only achieves a stage of multiplication for every second diode-capacitor cell. The other diode-capacitor cells are merely acting as peak detectors and smoothing the ripple without increasing the multiplication.\n\nA voltage multiplier may be formed of a cascade of voltage doublers of the cross-coupled switched capacitor type. This type of circuit is typically used instead of a Dickson multiplier when the source voltage is or less. Dickson multipliers have increasingly poor power conversion efficiency as the input voltage drops because the voltage drop across the diode-wired transistors becomes much more significant compared to the output voltage. Since the transistors in the cross-coupled circuit are not diode-wired the volt-drop problem is not so serious.\n\nThe circuit works by alternately switching the output of each stage between a voltage doubler driven by formula_1 and one driven by formula_4. This behaviour leads to another advantage over the Dickson multiplier: reduced ripple voltage at double the frequency. The increase in ripple frequency is advantageous because it is easier to remove by filtering. Each stage (in an ideal circuit) raises the output voltage by the peak clock voltage. Assuming that this is the same level as the DC input voltage then an \"n\" stage multiplier will (ideally) output \"nV\". The chief cause of losses in the cross-coupled circuit is parasitic capacitance rather than switching threshold voltage. The losses occur because some of the energy has to go into charging up the parasitic capacitances on each cycle.\n\nThe high-voltage supplies for CRTs often use voltage multipliers with the final-stage smoothing capacitor formed by the interior and exterior aquadag coatings on the CRT itself.\n\nA common type of voltage multiplier used in high-energy physics is the Cockcroft–Walton generator (which was designed by John Douglas Cockcroft and Ernest Thomas Sinton Walton for a particle accelerator for use in research that won them the Nobel Prize in Physics in 1951).\n\n\n\n"}
{"id": "191803", "url": "https://en.wikipedia.org/wiki?curid=191803", "title": "Wilhelm Eduard Weber", "text": "Wilhelm Eduard Weber\n\nWilhelm Eduard Weber (; ; 24 October 1804 – 23 June 1891) was a German physicist and, together with Carl Friedrich Gauss, inventor of the first electromagnetic telegraph.\n\nWeber was born in Wittenberg, where his father, Michael Weber, was professor of theology. Wilhelm was the second of three brothers, all of whom were distinguished by an aptitude for science. After the dissolution of the University of Wittenberg his father was transferred to Halle in 1815. Wilhelm had received his first lessons from his father, but was now sent to the Orphan Asylum and Grammar School at Halle. After that he entered the University, and devoted himself to natural philosophy. He distinguished himself so much in his classes, and by original work, that after taking his degree of Doctor and becoming a \"Privatdozent\" he was appointed Professor Extraordinary of natural philosophy at Halle.\nIn 1831, on the recommendation of Carl Friedrich Gauss, he was hired by the University of Göttingen as professor of physics, at the age of twenty-seven. His lectures were interesting, instructive, and suggestive. Weber thought that, in order to thoroughly understand physics and apply it to daily life, mere lectures, though illustrated by experiments, were insufficient, and he encouraged his students to experiment themselves, free of charge, in the college laboratory. As a student of twenty years he, with his brother, Ernst Heinrich Weber, Professor of Anatomy at Leipzig, had written a book on the \"Wave Theory and Fluidity,\" which brought its authors a considerable reputation. Acoustics was a favourite science of his, and he published numerous papers upon it in \"Poggendorffs Annalen,\" Schweigger's \"Jahrbücher für Chemie und Physik,\" and the musical journal \"Carcilia.\" The 'mechanism of walking in mankind' was another study, undertaken in conjunction with his younger brother, Eduard Weber. These important investigations were published between the years 1825 and 1838. Gauss and Weber constructed the first electromagnetic telegraph in 1833, which connected the observatory with the institute for physics in Göttingen.\n\nIn December 1837, the Hannovarian government dismissed Weber, one of the Göttingen Seven, from his post at the university for political reasons. Weber then travelled for a time, visiting England, among other countries, and became professor of physics in Leipzig from 1843 to 1849, when he was reinstated at Göttingen. One of his most important works, co-authored with Carl Friedrich Gauss and Carl Wolfgang Benjamin Goldschmidt, was \"Atlas des Erdmagnetismus: nach den Elementen der Theorie entworfen\" (\"Atlas of Geomagnetism: Designed according to the elements of the theory\"), a series of magnetic maps, and it was chiefly through his efforts that magnetic observatories were instituted. He studied magnetism with Gauss, and during 1864 published his \"Electrodynamic Proportional Measures\" containing a system of absolute measurements for electric currents, which forms the basis of those in use. Weber died in Göttingen, where he is buried in the same cemetery as Max Planck and Max Born.\nHe was elected a foreign member of the Royal Swedish Academy of Sciences in 1855.\n\nIn 1856 with Rudolf Kohlrausch (1809–1858) he demonstrated that the ratio of electrostatic to electromagnetic units produced a number that matched the value of the then known speed of light. This finding led to Maxwell's conjecture that light is an electromagnetic wave. This also led to Weber's development of his theory of electrodynamics. Also, the first usage of the letter \"c\" to denote the speed of light was in an 1856 paper by Kohlrausch and Weber.\n\nThe SI unit of magnetic flux, the weber (symbol: Wb) is named after him.\n\n\n\n"}
