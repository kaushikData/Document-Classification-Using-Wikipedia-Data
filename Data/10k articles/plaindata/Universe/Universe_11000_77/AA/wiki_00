{"id": "8971550", "url": "https://en.wikipedia.org/wiki?curid=8971550", "title": "Alpha-Eleostearic acid", "text": "Alpha-Eleostearic acid\n\nα-Eleostearic acid or (9\"Z\",11\"E\",13\"E\")-octadeca-9,11,13-trienoic acid, is an organic compound, a conjugated fatty acid and one of the isomers of octadecatrienoic acid. It is often called simply eleostearic acid although there is also a β-eleostearic acid (the all-\"trans\" or (9\"E\",11\"E\",13\"E\") isomer). Its high degree of unsaturation gives tung oil its properties as a drying oil.\n\nIn their pioneering work on essential fatty acids, Burr, Burr and Miller compared the nutritional properties of α-eleostearic acid (ELA) to that of its isomer alpha-linolenic acid (ALA). ALA relieved essential fatty acid deficiency; ELA did not.\n\nIn rats, α-eleostearic acid is converted to a conjugated linoleic acid. The compound has been found to induce programmed cell death of fat cells, and of HL60 leukemia cells in vitro at a concentration of 20 μM. Diets containing 0.01% bitter gourd seed oil (0.006% as α-eleostearic acid) were found to prevent azoxymethane-induced colon carcinogenesis in rats.\n\nα-Eleostearic acid is found in the oils extracted from seeds. Tung oil has 82% α-Eleostearic acid. Bitter gourd seed oil has 60% α-Eleostearic acid.\n\nEleo- is from Greek ἔλαιον, means olive.\n\n"}
{"id": "23889357", "url": "https://en.wikipedia.org/wiki?curid=23889357", "title": "Biocidal natural building material", "text": "Biocidal natural building material\n\nA biocidal natural building material is a natural building material which has biocidal properties. The biocidal properties of biocidal natural building materials are inherent to the material, rather than being supplemented afterwards. This makes that the material is long lasting and inexpensive, as no additional processing needs to be done.\n\n\n"}
{"id": "43327", "url": "https://en.wikipedia.org/wiki?curid=43327", "title": "Borel set", "text": "Borel set\n\nIn mathematics, a Borel set is any set in a topological space that can be formed from open sets (or, equivalently, from closed sets) through the operations of countable union, countable intersection, and relative complement. Borel sets are named after Émile Borel.\n\nFor a topological space \"X\", the collection of all Borel sets on \"X\" forms a σ-algebra, known as the Borel algebra or Borel σ-algebra. The Borel algebra on \"X\" is the smallest σ-algebra containing all open sets (or, equivalently, all closed sets).\n\nBorel sets are important in measure theory, since any measure defined on the open sets of a space, or on the closed sets of a space, must also be defined on all Borel sets of that space. Any measure defined on the Borel sets is called a Borel measure. Borel sets and the associated Borel hierarchy also play a fundamental role in descriptive set theory.\n\nIn some contexts, Borel sets are defined to be generated by the compact sets of the topological space, rather than the open sets. The two definitions are equivalent for many well-behaved spaces, including all Hausdorff σ-compact spaces, but can be different in more pathological spaces.\n\nIn the case \"X\" is a metric space, the Borel algebra in the first sense may be described \"generatively\" as follows.\n\nFor a collection \"T\" of subsets of \"X\" (that is, for any subset of the power set P(\"X\") of \"X\"), let\n\nNow define by transfinite induction a sequence \"G\", where \"m\" is an ordinal number, in the following manner:\n\nThe claim is that the Borel algebra is \"G\", where ω is the first uncountable ordinal number. That is, the Borel algebra can be \"generated\" from the class of open sets by iterating the operation\n\nto the first uncountable ordinal.\n\nTo prove this claim, note that any open set in a metric space is the union of an increasing sequence of closed sets. In particular, complementation of sets maps \"G\" into itself for any limit ordinal \"m\"; moreover if \"m\" is an uncountable limit ordinal, \"G\" is closed under countable unions.\n\nNote that for each Borel set \"B\", there is some countable ordinal α such that \"B\" can be obtained by iterating the operation over α. However, as \"B\" varies over all Borel sets, α will vary over all the countable ordinals, and thus the first ordinal at which all the Borel sets are obtained is ω, the first uncountable ordinal.\n\nAn important example, especially in the theory of probability, is the Borel algebra on the set of real numbers. It is the algebra on which the Borel measure is defined. Given a real random variable defined on a probability space, its probability distribution is by definition also a measure on the Borel algebra.\n\nThe Borel algebra on the reals is the smallest σ-algebra on R which contains all the intervals.\n\nIn the construction by transfinite induction, it can be shown that, in each step, the number of sets is, at most, the cardinality of the continuum. So, the total number of Borel sets is less than or equal to\n\nIn fact, the cardinality of the collection of Borel sets is equal to that of the continuum (compare to the number of Lebesgue measurable sets that exist, which is strictly larger and equal to formula_9).\n\nLet \"X\" be a topological space. The Borel space associated to \"X\" is the pair (\"X\",\"B\"), where \"B\" is the σ-algebra of Borel sets of \"X\".\n\nMackey defined a Borel space somewhat differently, writing that it is \"a set together with a distinguished σ-field of subsets called its Borel sets.\" However, modern usage is to call the distinguished sub-algebra \"measurable sets\" and such spaces \"measurable spaces\". The reason for this distinction is that the Borel sets are the σ-algebra generated by \"open\" sets (of a topological space), whereas Mackey's definition refers to a set equipped with an \"arbitrary\" σ-algebra. There exist measurable spaces that are not Borel spaces, for any choice of topology on the underlying space.\n\nMeasurable spaces form a category in which the morphisms are measurable functions between measurable spaces. A function formula_10 is measurable if it pulls back measurable sets, i.e., for all measurable sets \"B\" in \"Y\", formula_11 is a measurable set in \"X\".\n\nTheorem. Let \"X\" be a Polish space, that is, a topological space such that there is a metric \"d\" on \"X\" which defines the topology of \"X\" and which makes \"X\" a complete separable metric space. Then \"X\" as a Borel space is isomorphic to one of\n(This result is reminiscent of Maharam's theorem.)\n\nConsidered as Borel spaces, the real line R, the union of R with a countable set, and R are isomorphic.\n\nA standard Borel space is the Borel space associated to a Polish space. A standard Borel space is characterized up to isomorphism by its cardinality, and any uncountable standard Borel space has the cardinality of the continuum.\n\nFor subsets of Polish spaces, Borel sets can be characterized as those sets which are the ranges of continuous injective maps defined on Polish spaces. Note however, that the range of a continuous noninjective map may fail to be Borel. See analytic set.\n\nEvery probability measure on a standard Borel space turns it into a standard probability space.\n\nAn example of a subset of the reals which is non-Borel, due to Lusin (see Sect. 62, pages 76–78), is described below. In contrast, an example of a non-measurable set cannot be exhibited, though its existence can be proved.\n\nEvery irrational number has a unique representation by an infinite continued fraction\n\nwhere formula_13 is some integer and all the other numbers formula_14 are \"positive\" integers. Let formula_15 be the set of all irrational numbers that correspond to sequences formula_16 with the following property: there exists an infinite subsequence formula_17 such that each element is a divisor of the next element. This set formula_15 is not Borel. In fact, it is analytic, and complete in the class of analytic sets. For more details see descriptive set theory and the book by Kechris, especially Exercise (27.2) on page 209, Definition (22.9) on page 169, and Exercise (3.4)(ii) on page 14.\n\nAnother non-Borel set is an inverse image formula_19 of an infinite parity function formula_20. However, this is a proof of existence (via the axiom of choice), not an explicit example.\n\nAccording to P. Halmos, a subset of a locally compact Hausdorff topological space is called a \"Borel set\" if it belongs to the smallest σ–ring containing all compact sets.\n\nNorberg and Vervaat redefine the Borel algebra of a topological space formula_21 as the formula_22–algebra generated by its open subsets and its compact saturated subsets. This definition is well-suited for applications in the case where formula_21 is not Hausdorff. It coincides with the usual definition if formula_21 is second countable or if every compact saturated subset is closed (which is the case in particular if formula_21 is Hausdorff).\n\n\n\n"}
{"id": "30762119", "url": "https://en.wikipedia.org/wiki?curid=30762119", "title": "Clever Bins", "text": "Clever Bins\n\nClever Bins Limited was UK company that provided solar-powered street litter bin that displayed digital outdoor advertising.\n\nThe 'Clever Bins' came with A2 sized display panels that were lit up by directional LED beams. The panels came with military standard Riot shielding. Some models of the bin could broadcast messages to nearby mobile devices.\n\nThe bins used solar power that, even in cloudy conditions, could charge the units for up to 7 hours of illumination. The level of illumination was regulated depending on the power available.\n\nIn August 2009, Sachiti failed to find an investor on the BBCs TV show Dragons' Den.\n\nClever Bins was partnered with Keep Britain Tidy in July 2010. on a study for which Keep Britain tidy will release the results later in 2011.\n\nClever Bins had a trial with the London Borough of Hammersmith & Fulham.\n\nClever Bins could also be found outside near London's tube stations, Lakeside Shopping Centre, Manchester, Birmingham City, Tower Bridge London, and locations in Singapore,Hong Hong, Maldives and Italy.\n"}
{"id": "470625", "url": "https://en.wikipedia.org/wiki?curid=470625", "title": "Constantin Carathéodory", "text": "Constantin Carathéodory\n\nConstantin Carathéodory (Greek: Κωνσταντίνος Καραθεοδωρή \"Konstantinos Karatheodori\"; 13 September 1873 – 2 February 1950) was a Greek mathematician who spent most of his professional career in Germany. He made significant contributions to the theory of functions of a real variable, the calculus of variations, and measure theory. His work also includes important results in conformal representations and in the theory of boundary correspondence. In 1909, Carathéodory pioneered the \"Axiomatic Formulation of Thermodynamics\" along a purely geometrical approach.\n\nConstantin Carathéodory was born in Berlin to Greek parents and grew up in Brussels. His father Stephanos, a lawyer, served as the Ottoman ambassador to Belgium, St. Petersburg and Berlin. His mother, Despina, née Petrokokkinos, was from the island of Chios. The Carathéodory family, originally from Bosnochori or Vyssa, was well established and respected in Constantinople, and its members held many important governmental positions.\n\nThe Carathéodory family spent 1874–75 in Constantinople (now Istanbul), where Constantin's paternal grandfather lived, while his father Stephanos was on leave. Then in 1875 they went to Brussels when Stephanos was appointed there as Ottoman Ambassador. In Brussels, Constantin's younger sister Julia was born. The year 1879 was a tragic one for the family since Constantin's paternal grandfather died in that year, but much more tragically, Constantin's mother Despina died of pneumonia in Cannes. Constantin's maternal grandmother took on the task of bringing up Constantin and Julia in his father's home in Belgium. They employed a German maid who taught the children to speak German. Constantin was already bilingual in French and Greek by this time.\n\nConstantin began his formal schooling at a private school in Vanderstock in 1881. He left after two years and then spent time with his father on a visit to Berlin, and also spent the winters of 1883–84 and 1884–85 on the Italian Riviera. Back in Brussels in 1885 he attended a grammar school for a year where he first began to become interested in mathematics. In 1886, he entered the high school Athénée Royal d'Ixelles and studied there until his graduation in 1891. Twice during his time at this school Constantin won a prize as the best mathematics student in Belgium.\n\nAt this stage Carathéodory began training as a military engineer. He attended the École Militaire de Belgique from October 1891 to May 1895 and he also studied at the École d'Application from 1893 to 1896. In 1897 a war broke out between Ottoman Empire and Greece. This put Carathéodory in a difficult position since he sided with the Greeks, yet his father served the government of the Ottoman Empire. Since he was a trained engineer he was offered a job in the British colonial service. This job took him to Egypt where he worked on the construction of the Assiut dam until April 1900. During periods when construction work had to stop due to floods, he studied mathematics from some textbooks he had with him, such as Jordan's \"Cours d'Analyse\" and Salmon's text on the analytic geometry of conic sections. He also visited the Cheops pyramid and made measurements which he wrote up and published in 1901. He also published a book on Egypt in the same year which contained a wealth of information on the history and geography of the country. \n\nCarathéodory studied engineering in Belgium at the Royal Military Academy, where he was considered a charismatic and brilliant student.\n\n1900 Studies at University of Berlin.\n1902 Completed graduation at University of Göttingen (1904 Ph.D, 1905 Habilitation)\n1908 Dozent at Bonn\n1909 Ordinary Professor at Hannover Technical High School.\n1910 Ordinary Professor at Breslau Technical High School.\n1913 Professor following Klein at University of Göttingen.\n1919 Professor at University of Berlin\n1919 Elected to Prussian Academy of Science.\n1920 University Dean at Ionian University of Smyrna (later, University of the Aegean).\n1922 Professor at University of Athens.\n1922 Professor at Athens Polytechnic.\n1924 Professor following Lindemann at University of Munich.\n1938 Retirement from Professorship. Continued working from Bavarian Academy of Science\n\nCarathéodory had about 20 doctoral students among these being Hans Rademacher, known for his work on analysis and number theory, and Paul Finsler known for his creation of Finsler space.\n\nCarathéodory's contacts in Germany were many and included such famous names as: Minkowski, Hilbert, Klein, Einstein, Schwarz, Fejér. During the difficult period of World War II his close associates at the Bavarian Academy of Sciences were Perron and Tietze.\n\nWhile in Germany Carathéodory retained numerous links with the Greek academic world about which detailed information may be found in Georgiadou's book. He was directly involved with the reorganization of Greek universities. An especially close friend and colleague in Athens was Nicolaos Kritikos who had attended his lectures at Gŏttingen, later going with him to Smyrna, then becoming professor at Athens Polytechnic. Kritikos and Carathéodory helped the Greek topologist Christos Papakyriakopoulos take a doctorate in topology at Athens University in 1943 under very difficult circumstances. While teaching in Athens University Carathéodory had as undergraduate student Evangelos Stamatis who subsequently achieved considerable distinction as a scholar of ancient Greek mathematical classics.\n\nIn his doctoral dissertation Carathéodory originated his method based on the use of the Hamilton–Jacobi equation to construct a field of extremals. The ideas are closely related to light propagation in optics. The method became known as \"the royal road to the calculus of variations\". More recently the same idea has been taken into the theory of optimal control. The method can also be extended to multiple integrals.\n\nHe proved an existence theorem for the solution to ordinary differential equations under mild regularity conditions.\n\nHe is credited with the Carathéodory extension theorem which is fundamental to modern set theory. Later Carathéodory extended the theory from sets to Boolean algebras.\n\nHe greatly extended the theory of conformal transformation proving his theorem about the extension of conformal mapping to the boundary of Jordan domains. In studying boundary correspondence he originated the theory of prime ends.\n\nIn 1909, Carathéodory published a pioneering work \"Investigations on the Foundations of Thermodynamics\" in which he formulated the Laws of Thermodynamics axiomatically. It has been said that he was using only mechanical concepts and the theory of Pfaff's differential forms. But in reality he also relied heavily on the concept of an adiabatic process. The physical meaning of the term adiabatic rests on the concepts of heat and temperature. Thus, in Bailyn's survey of thermodynamics, Carathéodory's approach is called \"mechanical\", as distinct from \"thermodynamic\". Carathéodory's \"first axiomatically rigid foundation of thermodynamics\" was acclaimed by Max Born but criticized by Max Planck.\n\nIn his theory he simplified the basic concepts, for instance \"heat\" is not an essential concept but a derived one. He formulated the axiomatic principle of irreversibility in thermodynamics stating that inaccessibility of states is related to the existence of entropy, where temperature is the integration function. The Second Law of Thermodynamics was expressed via the following axiom: \"In the neighbourhood of any initial state, there are states which cannot be approached arbitrarily close through adiabatic changes of state.\" In this connexion he coined the term adiabatic accessibility.\n\nCarathéodory's work in optics is closely related to his method in the calculus of variations. In 1926 he gave a strict and general proof that no system of lenses and mirrors can avoid aberration, except for the trivial case of plane mirrors.\nIn his later work he gave the theory of the Schmidt telescope.\n\nDuring the 2nd World War Carathéodory edited two volumes of Euler's Complete Works dealing with the Calculus of Variations which were submitted for publication in 1946.\n\nHe is credited with the authorship of the Carathéodory conjecture claiming that a closed convex surface admits at least two umbilic points. As of 2007, this conjecture remained unproven despite having attracted a large amount of research.\n\nAt the time, Athens was the only major educational centre in the wider area and had limited capacity to sufficiently satisfy the growing educational need of the eastern part of the Aegean Sea and the Balkans. Constantin Carathéodory, who was a Professor at the University of Berlin at the time, proposed the establishment of a new University - the difficulties regarding the establishment of a Greek university in Constantinople led him to consider three other cities: Thessaloniki, Chios and Smyrna.\n\nAt the invitation of the Greek Prime Minister Eleftherios Venizelos he submitted a plan on 20 October 1919 for the creation of a new University at Smyrna in Asia Minor, to be named Ionian University of Smyrna. In 1920 Carathéodory was appointed Dean of the University and took a major part in establishing the institution, touring Europe to buy books and equipment. The university however never actually admitted students due to the War in Asia Minor which ended in the Great Fire of Smyrna. Carathéodory managed to save books from the library and was only rescued at the last moment by a journalist who took him by rowing boat to the battleship Naxos which was standing by. Carathéodory brought to Athens some of the university library and stayed in Athens, teaching at the university and technical school until 1924.\n\nIn 1924 Carathéodory was appointed professor of mathematics at the University of Munich, and held this position until retirement in 1938. He later worked from the Bavarian Academy of Sciences until his death in 1950.\n\nThe new Greek University in the broader area of the Southeast Mediterranean region, as originally envisioned by Carathéodory, finally materialised with the establishment of the Aristotle University of Thessaloniki in 1925.\n\nCarathéodory excelled at languages, much like many members of his family did. Greek and French were his first languages, and he mastered German with such perfection, that his writings composed in the German language are stylistic masterworks. Carathéodory also spoke and wrote English, Italian, Turkish, and the ancient languages without any effort. Such an impressive linguistic arsenal enabled him to communicate and exchange ideas directly with other mathematicians during his numerous travels, and greatly extend his fields of knowledge.\n\nMuch more than that, Carathéodory was a treasured conversation partner for his fellow professors in the Munich Department of Philosophy. The well-respected, German philologist, professor of ancient languages Kurt von Fritz praised Carathéodory, saying that from him one could learn an endless amount about the old and new Greece, the old Greek language, and Hellenic mathematics. Fritz had numerous philosophical discussions with Carathéodory.\n\nThe Greek language was spoken exclusively in Carathéodory's house – his son Stephanos and daughter Despina went to a German high school, but they obtained daily additional instruction in Greek language and culture from a Greek priest. At home, they were not allowed to speak any other language.\n\nIn 2002, in recognition of his achievements, the University of Munich named one of the largest lecture rooms in the mathematical institute the Constantin-Carathéodory Lecture Hall.\nKnown correspondence Carathéodory–Einstein can be seen as facsimile in Einstein Archives Online (11 items). Three letters concern mathematics and these are printed in vol.8 of Einstein's Collected Works (Princeton Univ. Press 1987) now freely available online.\n\nIn the town of Nea Vyssa, where Caratheodory's family came from, there is the unique Caratheodory's family museum. The museum is located in the central square of the town nearby the church and there are many personal items of Constantin as well as letters that he had exchanged with A. Einstein, for more information visit the original website of the club http://www.s-karatheodoris.gr. On the other hand, the Greek authorities intended for a long time to create a museum honoring Karatheodoris in Komotini, a major town of the northeastern Greek region, which is more than 200 km far away for the town of Nea Vyssa where his family came from. On 21 March 2009, the museum \"Karatheodoris\" (Καραθεοδωρής) opened its gates to the public, in Komotini.\n\nThe coordinator of the Museum, Athanasios Lipordezis (Αθανάσιος Λιπορδέζης), noted that the museum gave home to original manuscripts of the mathematician of about 10,000 pages including correspondence of Carathéodory with the German mathematician Arthur Rozenthal for the algebraization of measure. Also visitors can view at the showcases the books \"\" Gesammelte Mathematische Schriften Band 1,2,3,4 \", \"Mass und Ihre Algebraiserung\", \" Reelle Functionen Band 1\", \" Zahlen/Punktionen Funktionen \"\" and many more. Handwritten letters of C.Carathéodory to Albert Einstein, Hellmuth Kneser and photographs of the Carathéodory family are on display.\n\nThe effort to furnish the museum with more exhibits is continuous.\n\nA complete list of Carathéodory's journal article publications can be found in his \"Collected Works\"(\"Ges. Math. Schr.\"). Notable publications are:\n\n\n\n\n\n\n\n\n"}
{"id": "5066836", "url": "https://en.wikipedia.org/wiki?curid=5066836", "title": "Coordinated flight", "text": "Coordinated flight\n\nIn aviation, coordinated flight of an aircraft is flight without sideslip. \n\nWhen an aircraft is flying with zero sideslip a turn and bank indicator installed on the aircraft’s instrument panel usually shows the ball in the center of the spirit level. The occupants perceive no lateral acceleration of the aircraft and their weight to be acting straight downward into their seats. \n\nParticular care to maintain coordinated flight is required by the pilot when entering and leaving turns.\n\nCoordinated flight is usually preferred over uncoordinated flight for the following reasons:\n\nAirplanes and helicopters are usually equipped with a turn and bank indicator to provide their pilots with a continuous display of the lateral balance of their aircraft so the pilots can ensure coordinated flight.\n\nGlider pilots attach a piece of coloured string to the outside of the canopy to sense the sideslip angle and assist in maintaining coordinated flight.\n\nAn airplane has three axes of rotation: \n\nCoordinated flight requires the pilot to use pitch, roll and yaw control simultaneously. See also flight dynamics.\n\nIf the pilot were to use only the rudder to initiate a turn in the air, the airplane would tend to \"skid\" to the outside of the turn. \n\nIf the pilot were to use only the ailerons to initiate a turn in the air, the airplane would tend to \"slip\" toward the lower wing.\n\nIf the pilot were to fail to use the elevator to increase the angle of attack throughout the turn, the airplane would also tend to \"slip\" toward the lower wing.\n\nHowever, if the pilot makes appropriate use of the rudder, ailerons and elevator to enter and leave the turn such that sideslip and lateral acceleration are zero the airplane will be in coordinated flight. \n\nAdverse yaw\n\n"}
{"id": "54113277", "url": "https://en.wikipedia.org/wiki?curid=54113277", "title": "David Gaines (environmentalist)", "text": "David Gaines (environmentalist)\n\nDavid Allen Gaines (December 30, 1947–January 11, 1988) was an American environmentalist and the founder of the Mono Lake Committee.  His main goal in accomplishing a lawsuit was to work with the opposition (Los Angeles Department of Water and Power) instead of demonizing the organization, this ultimately got them ahead. He and his wife, Sally Gaines, began the committee in 1978. They required help from students at Stanford University, UC Davis, UC Santa Cruz, and Earlham College. From the information he collected he co-wrote a chapter in the book \"California Riparian Systems\". This got scientist engaged to help. As a collaborative team, The Mono Lake Committee took a stand against LADWP.\n\nHe died on January 11, 1988 in a car accident caused by a wind storm. Sally and his kids, Vireo and Sage, survived the accident.\n"}
{"id": "2045197", "url": "https://en.wikipedia.org/wiki?curid=2045197", "title": "Dempster Brothers", "text": "Dempster Brothers\n\nDempster Brothers, Inc. of Knoxville, Tennessee, was an industrial firm that made waste handling vehicles including the Dempster Dumpmaster and Dempster Dinosaur. The firm was originally established by George Roby Dempster with his brothers Thomas and John Dempster.\n\nThe Dempster Dumpmaster, introduced in the 1950s, was the first commercially successful, front-loading garbage truck in the United States. The product uses the \"Dempster-Dumpster\" system of mechanically emptying standardized metal containers, which had been patented by the company in 1937. It had arms at the front that picked up a dumpster and lifted it over the cab to tip it into the hopper. A rearward-traveling compacting panel compressed the garbage stored in the truck, and was also used to push it out through a door at the back when it was being emptied.\n\n\n"}
{"id": "45398316", "url": "https://en.wikipedia.org/wiki?curid=45398316", "title": "Energy Technology (journal)", "text": "Energy Technology (journal)\n\nEnergy Technology is a monthly peer-reviewed scientific journal covering applied energy research. It was established in 2013 and is published by Wiley-VCH.\n\nThe journal is abstracted and indexed in:\nAccording to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 2.789.\n"}
{"id": "28602665", "url": "https://en.wikipedia.org/wiki?curid=28602665", "title": "Ensted Power Station", "text": "Ensted Power Station\n\nThe Ensted Power Station (also known as the Aabenraa Power Station) () is a thermal power plant in Aabenraa, Denmark. The power station is fueled by coal, straw and woodchips. It is operated by DONG Energy.\n\nThe power station has two units, which went in service in 1969 and 1977. The older unit, which was in 1997 transformed in a combined gas- and steam-turbine plant, has a total height from with its chimney on the roof. The chimney of the other unit is tall. Coal is delivered to the power station by ship. The harbour of the power plant is with a depth of the deepest of Denmark.\n\n"}
{"id": "26056187", "url": "https://en.wikipedia.org/wiki?curid=26056187", "title": "Environmental Media Association", "text": "Environmental Media Association\n\nThe Environmental Media Association (EMA) is a non-profit organization which was founded in 1989 by Cindy and Alan Horn and Lyn and Norman Lear. EMA works with the entertainment industry to encourage green production and raise the public's environmental awareness. The group provides a \"Green Seal\" to productions which reduce their environmental footprint. The first movie to have the EMA Green Seal in its credits was The Incredible Hulk, which made specific efforts during its 2007 filming to cut carbon emissions and waste created during production. There are also various TV episodes, such as the \"Futurama\" episode \"The Problem with Popplers\", and various movies have been awarded the Environmental Media Award, which is awarded to the best television show or film with an environmental message.\n\nEMA also hosts the annual Environmental Media Awards, an awards ceremony which celebrates the entertainment industry’s environmental efforts.\n\n"}
{"id": "34288509", "url": "https://en.wikipedia.org/wiki?curid=34288509", "title": "Exotic Tropic Timber Enterprises", "text": "Exotic Tropic Timber Enterprises\n\nThe Exotic Tropic Timber Enterprises (ETTE) was formed by Fernando Robleda as a logging company in Liberia in February 1997. It later supplied arms to Charles Taylor for his \"Operation No Living Thing\" in January 1998, in return for concessions, or a license, to harvest the Cavalla Reforestation and Research Plantation in Liberia. The supply of arms was in addition to cash payments made directly to Taylor. \n\nThe company had received a license in May 1997 but this was revoked when Taylor came to power. The Ukrainian-Israeli Leonid Minin traveled with Robleda to Liberia to meet with Taylor in September 1998 to set up the deal. Minin became chairman of the board of ETTE on 10 December four days before the company was granted the license.\n\nThe UN Security Council listed ETTE as one of three timber companies involved in supplying arms to Charles Taylor, the others being Forum Liberia and the Indonesian-owned Oriental Timber company.\n"}
{"id": "351931", "url": "https://en.wikipedia.org/wiki?curid=351931", "title": "Explosive train", "text": "Explosive train\n\nA triggering sequence, also called an explosive train, is a sequence of events that culminates in the detonation of explosives. For safety reasons, most widely used high explosives are difficult to detonate. A primary explosive of higher sensitivity is used to trigger a uniform and predictable detonation of the main body of the explosive. Although the primary explosive itself is generally a more sensitive and expensive compound, it is only used in small quantities and in relatively safely packaged forms. By design there are low explosives and high explosives made such that the low explosives are highly sensitive (i.e. their 'Figure of Insensitivity' is low) and high explosives are comparatively insensitive. This not only affords inherent safety to the usage of explosives during handling and transport, but also necessitates an explosive triggering sequence or explosive train. The explosive triggering sequence or the explosive train essentially consists of an 'initiator', an 'intermediary' and the 'high explosive'. \n\nFor example, a match will not cause plastic explosive to explode, but it will light a fuse coupled with a blasting cap which will detonate a primary explosive that will shock a secondary high explosive and cause it to detonate. In this way, even very insensitive explosives may be used; the primary detonates a \"booster\" charge that then detonates the main charge. Triggering sequences are used in the mining industry for the detonation of ANFO and other cheap, bulk, and insensitive explosives that can not be fired by only a blasting cap or similar item.\n\nAn example of a low-explosive train is a rifle cartridge, which consists of \n\nHigh-explosives trains can be either two-step (e.g., detonator and dynamite) or three-step (e.g., detonator, booster of primary explosive, and main charge of secondary explosive).\n\nA high explosive train includes three primary high explosive components which are used to initiate explosives:\n\nDetonators are often made from tetryl and fulminates.\n\nIn an explosive train there are two secondary high explosive components:\n\nExamples of bursting charges are\n\n\nExamples of main charges are\n\nIn some cases, the main charge is so insensitive that using typical primary materials becomes impractical due to large amount required. Thus, an explosive booster is used to deliver sufficient shockwave to the main charge.\n\nThe most significant tertiary material in widespread use is ANFO.\n"}
{"id": "1212189", "url": "https://en.wikipedia.org/wiki?curid=1212189", "title": "Ford C-Max", "text": "Ford C-Max\n\nThe Ford C-Max (stylized as Ford C-MAX and previously called the Ford Focus C-Max) is a compact multi-purpose vehicle (MPV) produced by the Ford Motor Company since 2003. The Ford Grand C-Max has a larger wheelbase.\n\nFord introduced the C-Max in the United States as its first hybrid-only line of vehicles, which includes the C-Max Hybrid, released in September 2012, and the C-Max Energi plug-in hybrid, launched in October 2012. Although the C-Max was initially available only in Europe, the first generation was partially available in New Zealand. With the introduction of the new large MPVs S-Max and Galaxy, the C-Max is now the mid-sized multi-purpose vehicle in Ford's lineup, above the B-Max. \nC-Max Mk I was the first product to use the Ford C1 platform, also used by the Ford Focus Mk II and the compact MPV Premacy/Mazda5. Its internal code name is C214.\n\nIt seats five passengers and has a large amount of cargo space, which can be increased by folding the rear seats flat. Some models feature diagonally sliding outer rear seats. It also shares the control blade independent rear suspension from the Focus.\n\nThe available four-cylinder engines are the same as the Focus.\n1.6 L Duratec was the basic engine for C-Max, 1.6 L Ti-VCT Duratec was also available.\n1.8/2.0 L Duratec HE are the rest of available petrol engines\n1.6/2.0 L Duratorq Ford/PSA made diesels were available along with Ford's 1.8 L Endura engine which is upgraded and named Duratorq\n\n<nowiki>*Overboost</nowiki>\n\nTransmissions mated with engines are Ford IB5 (1.6/1.8 Duratec), Ford Durashift (2.0 Duratorq), MTX-75 (2.0 Duratec / 1.6-1.8 Duratorq) manual and Ford Powershift double-clutch transmission available with 2.0 Duratorq. The 4F27E mated with the 2.0 Duratec engine. A CVT automatic was also available\n\nIn December 2006, the facelifted version of the C-Max was revealed at the 2006 Bologna Motor Show and went on sale in late spring 2007. The pre-facelift version of the car (2003–2007) was called the Ford Focus C-Max. The name change to C-Max is attributable to Ford's MPV strategy of creating a 'Max' branded line of MPVs, starting with the Ford S-Max, launched in 2006.\n\nThe facelift brought the car in line with Ford's 'Kinetic Design' design language, evidenced through its twin trapezoidal grilles, large wheel arches and angular headlights. However, as the car does not have a bodyshell originally designed for 'Kinetic Design,' Ford officially states that the car contains only 'elements' of the design language.\n\nAlongside the third generation Ford Focus Mk III, the second generation C-Max (C344) is built on Ford's new Global C platform. The appearance is inspired by the Iosis Max concept, shown at the 2009 Geneva Motor Show. In addition, Ford added a long wheelbase, seven-seat minivan variant of the C-Max, the Ford Grand C-Max\n\nThe vehicle was unveiled at the 2009 Frankfurt Motor Show. Early European models include 5 seats, and 7-seat models entered the market at the end of 2010 (except Russia, where there is only the 7-seat model). At the 2011 North American International Auto Show, Ford announced a 7-seat C-MAX for the North American market. However, this model was cancelled prior to launch.\n\nFord unveiled the Ford C-Max Energi plug-in hybrid and the C-Max Hybrid at the 2011 North American International Auto Show. Like the conventional C-Max, the C-Max Energi and Hybrid are five-seat only. They replace the Ford Escape Hybrid and Mercury Mariner Hybrid since Ford discontinued the Mercury brand after the 2011 model year and the Escape Hybrid after the 2012 year model. The C-Max is Ford's first hybrid-only line of vehicles. Both the plug-in and hybrid version designs are based on the European gasoline- and diesel-powered versions.\n\nThe C-Max Hybrid was released in the United States in September 2012 as a 2013 model year, followed by the release of the plug-in Energi version by mid October 2012.\n\nProduction of the C-Max Energi in the United States ended in September 2017, while Hybrid production ended in 2018.\n\nThe new Mk III platform is the first in its class to support Torque Vectoring Control (TVC).\n\nThe redesigned C-Max features flat folding third row seats, a hands free power lift gate, rear view camera, park assist, and panoramic sunroof. HD Radio, Sirius XM, Sync, dual-zone climate control system, and navigation system come as standard or as available options on the different trim lines.\n\nThe aerodynamics (drag coefficient, \"c\") of the car has been improved, being 0,30 for the 5 seater and 0,32 for the Grand C-Max.\n\nLike the previous C-Max, the new C-Max also comes with a range of petrol and diesel four-cylinder engines which are shared with the Focus:\n<nowiki>*Overboost</nowiki>\n\nTransmissions mated with engines are Ford IB5 (1.6 Duratec Ti-VCT), B6 (1.6 EcoBoost/1.6 Duratorq), Durashift MMT6 (2.0 Duratorq) manual and Ford Powershift double-clutch transmission available with the 2.0 Duratorq engine.\n\nThe Ford C-MAX was facelifted in 2015 and the 1.6 ecoboost changed from 1.6 ECOBOOST 125 PS to the 1.0 ECOBOOST 125PS along with the 1.6 TDCI 115PS DUROTORQ changing to the 1.5 TDCI 120 PS DUROTORQ Single Over head cam unit.\n\nFord developed the C-Max Hybrid with the aim to become \"America’s most affordable hybrid utility vehicle.\" The gasoline-electric hybrid model base pricing starts at , including destination and delivery.\n\nThe front-wheel drive hybrid has a 2-liter four-cylinder Atkinson cycle engine mated to an electric motor and a 1.4 kWh lithium-ion battery for total power output of 188 hp (140 kW). The top speed in all-electric mode of and the car's top speed in hybrid mode is .\n\nThe hybrid has a maximum cargo volume of with rear seats folded flat, and in the cargo area behind the rear seats, providing more room than the regular Prius liftback, but less cargo room than the Prius v, which provides with the rear seats folded.\n\nThe Hybrid is offered in two trims:\n\nThe SE features eco-friendly cloth seating surfaces, Ford SYNC system with A/M-F/M stereo with single-disc CD/MP3 player, USB and auxiliary input jacks, six speakers, a multi-informational gauge cluster and color display screen, keyless entry, alloy wheels, and split-folding rear bench seat, plus a security alarm.\n\nThe SEL adds leather seating surfaces, MyFord Touch with AM/FM HD Radio stereo with single-disc CD/MP3 player and USB and auxiliary input jacks, a Sony premium surround sound system, SIRIUS Satellite Radio, power dual front seats, keyless access, push-button start system, and other luxury features. For the 2017 model year, the SEL trim level on both the C-Max Hybrid and Energi will be renamed to the Titanium trim level and also all the 2017 Ford C-Max Hybrids and plug-in Energis are expected to have restyled headlights and taillights.\n\nThe Energi Plug-In Hybrid is only available in SEL trim. But for the 2017 model year the C-Max Energi is also available on the SE trim level.\n\nFord's design aimed for the C-Max Hybrid to deliver better fuel economy than the Toyota Prius v. Ford had reduced its estimated fuel economy twice, once in 2013 and again in 2014, with the second revision placing fuel economy below the Prius V. The US Environmental Protection Agency (EPA) initially rated the hybrid model at with the same rating for combined/city/highway cycles. These ratings allowed the C-Max Hybrid to improve the fuel economy of the Toyota Prius v by 3 mpg on the city cycle, by 7 mpg on the highway cycle and by 5 mpg combined. However, after criticism and lawsuits about worse-than-expected real-world fuel economy, in August 2013 Ford voluntarily lowered the EPA ratings and issued customer rebates. The revised fuel economy ratings were reduced to for city driving, for combined and for highway. The revised rating for the updated 2013 C-Max Hybrid is still better than the combined rating for the Toyota Prius v. A second downward revision was made during June 2014.\n\nFord boosted the on-road fuel efficiency of its three 2013 model year hybrids through changes in the cars' vehicle control software in an effort to improve customer satisfaction. The upgrade was offered free of charge to existing owners of these hybrids. Some of the changes include: \n\nA total of 969 units were sold during September 2012, allowing the C-Max Hybrid to rank as the ninth-best selling hybrid car in the United States that month. During October, its first full month in the market, 3,182 units were sold, outselling the Prius v by more than 400 units, which had ranked as the fourth most sold hybrid in the previous months. Sales of the C-Max Hybrid also led Ford to achieve its best October hybrid sales month ever with a total of 4,612 sales, up 142% over October 2011. Ford reported that 25% of C-Max Hybrid sales took place in California, with Los Angeles and San Francisco as the top selling regional markets. A total of 10,935 C-Max Hybrids were sold during 2012, and a total of 28,056 units in 2013. After Ford cut the car's EPA fuel economy rating by 4 miles (6.4 kilometers) per gallon to 43 mpg in the middle of 2012, the car experienced its three worst sales months since it debuted in the U.S. Since its inception, a total of 72,330 units have been sold in the United States through December 2015.\n\nIn December 2012, Motor Trend reported that Consumer Reports and Green Car Reports have found that the 2013 Ford C-Max Hybrid and 2013 Ford Fusion Hybrid, which share the same powertrain, do not deliver their triple EPA ratings in real-world use. After running both vehicles through Consumer Reports real-world tests, the magazine found that C-Max hybrid achieved a combined fuel economy average of , with and for city and highway. Green Car Reports found that the C-Max delivered over of mixed freeway and urban driving, and over mostly at freeway speeds.\n\nConsumer Reports concluded that the overall fuel economy for the C-Max Hybrid is off by 10 mpg, representing a deviation of about 20%. The consumer magazine said that their overall fuel economy results are usually close to the EPA's combined-mpg estimate, and among current models tested, more than 80% fall within 2 mpg margin. The largest discrepancy the magazine has previously found was 7 and 6 mpg for the Toyota Prius C and the Prius hatchback, respectively. Ford responded in a statement, saying that, \"\"Early C-MAX Hybrid and Fusion Hybrid customers praise the vehicles and report a range of fuel economy figures, including some reports above 47 mpg. This reinforces the fact that driving styles, driving conditions, and other factors can cause mileage to vary\".\"\n\nA few days later the Environmental Protection Agency(EPA) said it would review claims that two new Ford hybrid vehicles were not delivering the advertised 47 mpg. Linc Wehrly, Director of Light-duty Vehicle Center Compliance Division at EPA's National Vehicle and Fuel Emissions Laboratory in Ann Arbor, Michigan commented that hybrids had far more variability in miles per gallon than conventional vehicles. All vehicles are run through the same EPA fuel-efficiency test but the test is not administered by the EPA; instead the automakers conduct the test and EPA often conducts reviews. Most vehicles's real-world gas mileage is less than the EPA sticker number, and can often be 20% less than depending on speed, temperature and other factors. The EPA explained that with hybrids the gap was much wider, as high as 30%.\n\nThe problem lay with EPA's rules that allowed automakers to group similar vehicles and apply the same ratings, which Ford did with the Fusion hybrid and C-Max hybrids.\n\nFord Motor Co. officials said the real-world fuel-efficiency in the C-Max Hybrid depended on driving style and other factors, and t rt he company did not expect the car's fuel efficiency numbers to change, as they followed EPA's test guidelines. Ford said they we re working closely with the EPA to determine if changes were needed for the industry relative to hybrid vehicle testing. They explained that several factors could affect hybrid fuel economy more than that of regular gasoline engines, including speed (as the difference between 75 mph and 65 mph could produce a 7-mpg difference in fuel economy); outside temperature (the difference between 40 °F and 70 °F could result in a 5 mpg difference); and vehicle break-in (a 5 mpg difference could occur from the difference 0 miles to 6,0 miles).\n\nDue to the criticism and lawsuits, in July 2013 Ford announced it would boost the on-road fuel efficiency of the C-Max and its other two 2013 hybrids through changes in the vehicle control software, in an effort to improve customer satisfaction. In August 2013, the carmaker voluntarily reduced the official EPA ratings in August 2013. They also announced they would issue rebates to some 32,000 C-Max owners who would be notified by mail. The payment would be to U.S. customers who purchased C-Maxes, and to customers who had leased them.\n\nAfter the Ford announcement, the EPA stated that it will update the test procedures used to assign fuel economy ratings to cars \"\"to ensure that the requirements keep pace with industry trends and innovations in advanced high-efficiency vehicles\".\" Ford used the Fusion Hybrid test to generate the fuel economy label for the C-Max Hybrid following EPA's rules. These, which date to the 1970s, specify that automakers can use the same fuel economy numbers for similar-size vehicles equipped with the same engines and transmissions. The EPA requires automakers to test the fuel economy of the biggest-selling model in a specific category. In its midsize hybrid class, Ford tested the Fusion sedan version because it was the top seller, and Ford was allowed to apply the achieved with the Fusion Hybrid in combined, city and highway driving to the C-Max hybrid. Ford has no plans to change the fuel economy ratings on the 2013 Fusion hybrid.\n\nThe C-Max Energi plug-in hybrid starts at including the destination fee. According to its battery size, the plug-in car qualifies for a federal tax credit of , and it is eligible for additional incentives at the state and local level, such as California's rebate.\n\nThe Plug-in Energi Hybrid family is currently either in or will soon be facing a class action suit due to the massive wear out rate on the battery storage capacity. https://www.girardgibbs.com/ford-mpg/\n\nThis is similar to the issues that affected early Nissan Leaf class action. https://www.greencarreports.com/news/1099200_nissan-leaf-battery-capacity-lawsuit-court-approves-settlement\n\nThe reason why they are similar is that similar language was used in the initial battery warranty by Nissan as is currently used by Ford.. that battery capacity loss is not warrantied whatsoever. In fact, this was not found to be acceptable for Nissan and a 20% limit was imposed, so only a matter of time before Ford is called to pay to repair, replace or otherwise make whole the many C-Max and Fusion Energi customers (the two cars shared the Energi battery system) who have massively reduced electric range. What is typically seen is that in hot areas the ability to hold charge goes from \"new\" of about 5.8 kwh to less than 4.0 kwh, over a 30% drop in electric range, and in some instances that happens in 30,000 miles or less.\n\nThe C-Max Energi was designed with total 188 hp (140 kW) in hybrid mode delivered by a 2.0-liter Atkinson cycle four-cylinder gasoline engine plus an electric motor powered by a 7.6 kWh lithium-ion battery pack, which is smaller and lighter than nickel metal hydride batteries used in previous Ford generation hybrids. The electric drivetrain can produce a peak power of 68 kW, limited by the size of the electric motor and the power delivery capability of the battery pack, and delivers a total system power of 195 hp (150 kW) in charge-depleting mode (EV mode). The C-Max Energi is capable of reaching a top electric-only speed of , exceeding the Toyota Prius Plug-in Hybrid by more than . The top speed in hybrid mode is .\n\nThe C-Max Energi uses a regenerative braking system capable of capturing and reusing more than 95% of the braking energy normally lost during the braking process. The charging time for the C-Max Energi is 7 hours with a 120 volt charger, and 2.5 hours with a 240 volt charger. The charge port has a LED light ring like the Ford Focus Electric and is located on the driver’s side and near the front of the car. The light ring illuminates to indicate charge status. The battery is covered by an eight years or component warranty.\n\nFord equipped the C-Max Energi with a button mounted in the center stack that enables drivers to choose an electric-only driving mode, and allows the driver to switch vehicle operation between three modes: electric-only driving without gasoline engine power (\"EV Now\" setting); normal hybrid mode where the powertrain blends electric and gasoline engine power as appropriate (\"EV Auto\" setting); or a battery-saving mode that reserves the battery power for later use (\"EV Later\" setting). Like the Ford Fusion Hybrid, the C-Max Energi comes with a SmartGauge with EcoGuide that provides in-vehicle customizable displays, including instantaneous fuel economy readings and coaching functions to help drivers understand and optimize their fuel efficiency. The plug-in hybrid also features ECO Cruise which saves energy by relaxing acceleration compared to standard cruise control.\n\nFord designed the C-Max Energi plug-in hybrid to deliver better miles per gallon equivalent (MPG-e) in all-electric mode than the Toyota Prius Plug-in Hybrid. Initially, the EPA rated the Energi combined city/highway fuel economy in all-electric mode at 100 MPG-e (). Later, due to complaints from owners not achieving the sticker fuel economy, and following a technical review, the official EPA rating in EV mode was downgraded to 88 MPG-e (). In a similar way, initially the EPA rating in hybrid-gasoline mode was , but it was later downgraded to . EPA's rating for combined EV/hybrid operation is 51 MPG-e (4.6 L gasoline equivalent/100 km), which allows the C-Max Energi to rank in sixth place, together with the Fusion Energi, among the top ten EPA-Rated Fuel Sippers since 1984.\n\nThe C-Max Energi has an all-electric range of , for a total EPA certified range of , which in 2012 surpassed both the generation 1 Chevrolet Volt (), and the Prius Plug-in Hybrid ().\n\nFord released the C-Max Energi in the U.S. market by mid October 2012, and during that month 144 units were delivered to U.S. retail customers, and ended with 2,374 units delivered in 2012. The C-Max Energi ranked as the fifth top selling plug-in electric car in the U.S. during 2013, and climbed to number fourth in 2014. Over 35,700 units have been sold in North America and Europe through December 2016, with 33,509 units delivered in the U.S. through December 2016, 967 units in Canada through December 2016, and 1,229 in the Netherlands in 2015.\n\nFord Motor Company announced the C-MAX Solar Energi concept, a solar PV-powered vehicle to run electrically without depending on the electric grid for fuel. The C-MAX Solar Energi Concept was unveiled at the 2014 International CES in Las Vegas. This is a collaborative project of Ford, SunPower Corp. and the Georgia Institute of Technology.\n\nIn Europe, the C-Max is designed with lower VOC and allergens, along with several other Ford vehicles.\n\nFor the North American market, the C-Max Hybrid was assembled alongside the 2012 Focus and Ford Focus Electric at Ford's Wayne plant in Michigan. The C-Max Energi was also assembled in Michigan. Since 2015 all European versions are built in the Saarlouis Body & Assembly, Germany.\n\n\n"}
{"id": "39773863", "url": "https://en.wikipedia.org/wiki?curid=39773863", "title": "Forward curve", "text": "Forward curve\n\nThe forward curve is a function graph in finance that defines the prices at which a contract for future delivery or payment can be concluded today. For example, a futures contract forward curve is prices being plotted as a function of the amount of time between now and the expiry date of the futures contract (with the spot price being the price at time zero). The forward curve represents a term structure of prices.\n\nA forward interest rate is a type of interest rate that is specified for a loan that will occur at a specified future date. As with current interest rates, forward interest rates include a term structure which shows the different forward rates offered to loans of different maturities. According to the unbiased expectations hypothesis, forward interest rates predict spot interest rates at the time the loan is actually made, but many analysts dispute whether this is true, as it ignore durational risk.\n\nThis figure is part of the lending & credit industry and is related as well to the \"expectations theory\" which states that forward interest rates can be used as forecasts for future interest rates. Investors expecting higher short-term interest rates are more likely to buy bonds maturing in the short term. If they were to park money into a long term debt they might not be able to make as much interest.\n\nFinance analysts can refer to a graph of forward interest rate values over different time periods, the forward curve, to evaluate the time value of money.\n\nA Price forward curves (short \"PFC\") reflects specialties of the commodity market such as:\nIn order to fairly value and manage the profitability of energy products it is thus necessary to capture these seasonal price dynamics in a forward curve term-structure.\n\nThe contract duration of a futures contract is limited by definition and investors have to change their contract during the contract term. Price forward curves help to determine when to do that, two scenarios are possible:\n\nAn hourly price forward curve (HPFC) is the construction of a forward curve at a resolution exceeding that known to the market and is as such able to capture the seasonalities of the electricity spot prices. The construction of an HPFC can be based on the combination of two approaches. A statistical approach examines how spot prices have moved in the past. A fundamental model suggests that the price is set purely by supply and demand (respectively, fuel prices on the merit order curve, and load).\n\nIt is difficult to specify exactly what makes a good HPFC, it should (1) be arbitrage-free for products traded on an exchange, (2) reflect the seasonality of spot prices, and (3) handle renewable energies correctly\n\n"}
{"id": "5641551", "url": "https://en.wikipedia.org/wiki?curid=5641551", "title": "Front of Store Recycling", "text": "Front of Store Recycling\n\nFront of Store Recycling is a project exploring the viability of different front of store recycling (FOSR) and reverse vending machines in England. It was funded by WRAP.\n\n\n"}
{"id": "67405", "url": "https://en.wikipedia.org/wiki?curid=67405", "title": "Great Red Spot", "text": "Great Red Spot\n\nThe Great Red Spot is a persistent high-pressure region in the atmosphere of Jupiter, producing an anticyclonic storm 22° south of the planet's equator. It has been continuously observed for 188 years, since 1830. Earlier observations from 1665 to 1713 are believed to be of the same storm; if this is correct, it has existed for at least ((2018 - 1665)/10 round 0) * 10 years.\nSuch storms are not uncommon within the turbulent atmospheres of gas giants.\n\nThe Great Red Spot may have existed since before 1665, but the present spot was first seen only after 1830 and well-studied only after a prominent apparition in 1879. The storm people had seen in the 1600s may have been a different storm than the one we see today. A long gap separates its period of current study after 1830 from its seventeenth-century discovery; whether the original spot dissipated and reformed, whether it faded, or even if the observational record was simply poor, are all unknown.\n\nFor example, its first sighting is often credited to Robert Hooke, who described a spot on the planet in May 1664; however, it is likely that Hooke's spot was in another belt altogether (the North Equatorial Belt, versus the current Great Red Spot's location in the South Equatorial Belt). Much more convincing is Giovanni Cassini's description of a \"permanent spot\" the following year. With fluctuations in visibility, Cassini's spot was observed from 1665 to 1713; however, the 118-year observational gap makes the identity of the two spots inconclusive, and the older spot's shorter observational history and slower motion than the modern spot make their identity unlikely.\n\nA minor mystery concerns a Jovian spot depicted in a 1711 canvas by Donato Creti, which is exhibited in the Vatican. Part of a series of panels in which different (magnified) heavenly bodies serve as backdrops for various Italian scenes, and all overseen by the astronomer Eustachio Manfredi for accuracy, Creti's painting is the first known to depict the Great Red Spot as red. No Jovian feature was explicitly described in writing as red before the late 1800s.\nOn February 25, 1979, when the \"Voyager 1\" spacecraft was 9.2 million kilometres (5.7 million miles) from Jupiter it transmitted the first detailed image of the Great Red Spot back to Earth. Cloud details as small as 160 kilometres (100 miles) across were visible. The colorful, wavy cloud pattern seen to the left (west) of the Red Spot is a region of extraordinarily complex and variable wave motion.\n\nAt the start of 2004, the Great Red Spot had approximately half the longitudinal extent it had a century ago, when it reached a size of 40,000 kilometres. At the present rate of reduction it would become circular by 2040. It is not known how long the spot will last, or whether the change is a result of normal fluctuations.\n\nA smaller spot, designated Oval BA, formed recently (March 2000) from the merger of three white ovals, has turned reddish in color. Astronomers have named it the \"Little Red Spot\" or \"Red, Jr.\" As of June 5, 2006, the Great Red Spot and Oval BA appeared to be approaching convergence. The storms pass each other about every two years but the passings of 2002 and 2004 were of little significance. Amy Simon-Miller, of the Goddard Space Flight Center, predicted the storms would have their closest passing on July 4, 2006. She worked with Imke de Pater and Phil Marcus of UC Berkeley, and a team of professional astronomers since April 2006 to study the storms using the Hubble Space Telescope; on July 20, the two storms were photographed passing each other by the Gemini Observatory without converging. In May 2008 a third storm turned red.\n\nThe Great Red Spot should not be confused with the \"Great Dark Spot\", a feature observed near the northern pole of Jupiter in 2000 with the \"Cassini–Huygens\" spacecraft. Note that a feature in the atmosphere of Neptune was also called the \"Great Dark Spot\". The latter feature was imaged by \"Voyager 2\" in 1989, and may have been an atmospheric hole rather than a storm and it was no longer present as of 1994 (although a similar spot had appeared farther to the north).\n\nNASA's Juno Spacecraft flew over the Great Red Spot on July 11, 2017, taking several images of the Spot from about above the surface.\n\nThe oval object rotates counter-clockwise, with a period of about six Earth days or fourteen Jovian days. Measuring 10,159 miles (16,350 kilometers) in width (as of April 3, 2017) Jupiter's Great Red Spot is 1.3 times as wide as Earth. The cloud-tops of this storm are about eight kilometres above the surrounding cloud-tops.\n\nInfrared data have long indicated that the Great Red Spot is colder (and thus, higher in altitude) than most of the other clouds on the planet. However, recent infrared measurements of the upper atmosphere show far more heat above the Great Red Spot than the rest of the planet; \"acoustic waves\" rising from the storm have been proposed as an explanation for Jupiter's temperature.\n\nCareful tracking of atmospheric features revealed the spot's counter-clockwise circulation as far back as 1966, observations dramatically confirmed by the first time-lapse movies from the \"Voyager\" fly-bys. The spot is confined by a modest eastward jet stream to its south and a very strong westward one to its north. Though winds around the edge of the spot peak at ~120 metres per second (432 kilometres per hour), currents inside it seem stagnant, with little inflow or outflow. The rotation period of the spot has decreased with time, perhaps as a direct result of its steady reduction in size.\nThe Great Red Spot's latitude has been stable for the duration of good observational records, typically varying by about a degree. Its longitude, however, is subject to constant variation.\nBecause Jupiter does not rotate uniformly at all latitudes, astronomers have defined\nthree different systems for defining the longitude. System II is used for latitudes of more than 10°, and was originally based on the average rotational period of the Great Red Spot of 9h 55m 42s. Despite this, however, the spot has \"lapped\" the planet in System II at least 10 times since the early nineteenth century. Its drift rate has changed dramatically over the years and has been linked to the brightness of the South Equatorial Belt, and the presence or absence of a South Tropical Disturbance.\nIt is not known exactly what causes the Great Red Spot's reddish color. Theories supported by laboratory experiments suppose that the color may be caused by complex organic molecules, red phosphorus, or a compound containing sulphur, but a consensus has yet to be reached.\n\nThe Great Red Spot varies greatly in hue, from almost brick-red to pale salmon, or even white. In fact, the spot occasionally \"disappears\", becoming evident only through the Red Spot Hollow, which is its in the South Equatorial Belt (SEB). Its visibility is apparently coupled to the SEB; when the belt is bright white, the spot tends to be dark, and when it is dark, the spot is usually light. These periods when the spot is dark or light occur at irregular intervals; as of 1997, during the preceding 50 years, the spot was darkest in the periods 1961–1966, 1968–1975, 1989–1990, and 1992–1993.\n\nThere is no definitive theory as to what causes the formation or color of the Great Red Spot. Laboratory studies are examining the effects that cosmic rays or UV Light from the Sun have on the chemical composition of the clouds of Jupiter. One question is whether the Sun's radiation reacts with ammonium hydrosulfide in the planet's outer atmosphere to create the deep red color. Research has shown that the storm produces extreme amounts of heat because it simultaneously generates gravity waves and acoustic waves. When these turbulent energy waves collide above the red spot, they create extremely high temperatures in the planet's upper atmosphere. The effect is described as being like \"crashing [..] ocean waves on a beach\". The reason the storm has continued to exist for centuries is that there is no planetary surface to provide friction (only a liquid core of hydrogen); circulating gas eddies persist for a very long time in the atmosphere because there is nothing to oppose their angular momentum.\n\n\n\n"}
{"id": "30865894", "url": "https://en.wikipedia.org/wiki?curid=30865894", "title": "Halo Array", "text": "Halo Array\n\nThe Halo Array is a group of fictional megastructures and superweapons in the \"Halo\" science fiction franchise, consisting of ring-shaped worlds known as Halos and a control station called the Ark. They are referred to as \"Installations\" by their AI monitors, and were created by an ancient race known as the Forerunners. The series' alien antagonists, the Covenant, refer to the Halos as the \"Sacred Rings\", believing them to form part of a greater religious prophecy known as \"The Great Journey\". According to \"Halo\"s fiction, the Forerunners built the Halo Array to contain and study the Flood, an infectious alien parasite. The rings act together as a weapon of last resort; when fired, they kill any sentient life capable of falling prey to the Flood, starving the parasite of its food. The installations are at the crux of the plot progression for the \"Halo\" series.\n\nEach Halo features their own wildlife and weather. The constructs resemble Iain M. Banks' Orbital concept in shape and design. The structure that \"Halo: Combat Evolved\" takes place on was initially to be a hollowed-out planet, but was changed to its ring design later in development; a staff member provided \"Halo\" as the name for both the ring and the video game after names such as \"Red Shift\" were suggested.\n\nThe term \"megastructure\" refers to artificial structures where one of three dimensions is or larger. The first use of a ring-shaped megastructure in fiction was Larry Niven's novel \"Ringworld\" (1970). Niven described his design as an intermediate step between Dyson spheres and planets - a ring with a radius of more than and a width of ; these are dimensions far exceeding the ringworlds found in the \"Halo\" series, which feature radii of The Halos are closer in proportion to a Bishop Ring, an actual proposed space habitat first explained by Forrest Bishop, though the proportions of the Halos do not exactly match up with Bishop's idea or more accurately the bigger Orbital. As seen in the games, Halo installations feature a metallic exterior, with the interior of the ring filled with an atmosphere, water, plant life, and animal life. What appear to be docking ports and windows dot the exterior surface, suggesting that a fraction of the ring structure itself is hollow and used for maintenance, living, and power generation.\n\nBefore the title for game developer Bungie's next project was announced and development of the game that would become \"Halo\" was in its early stages, the megastructure that \"Halo: Combat Evolved\" took place on was a massive, hollowed-out planet called \"Solipsis\". The planet became a Dyson Sphere, and then a Dyson Ring. Some Bungie staffers felt the change to a ringworld was \"ripping off Larry Niven\", according to Bungie artist Paul Russel. Bungie employee Frank O'Connor wrote in a post on Bungie that \"the specific accusation that we swiped the idea of a ring-shaped planet wholesale is not accurate\", explaining that Bungie used a ringworld because \"it's cool and therefore the type of thing a Forerunner civilization would build.\"\n\nAt the time, the game was known as \"Blam!\", but Bungie had always expected to replace the working title with something better. \"Blam!\" was used after studio co-founder Jason Jones could not bring himself to tell his mother their next project was dubbed \"Monkey Nuts\". Titles such as \"The Crystal Palace\", \"Hard Vacuum\", \"Star Maker\", \"Star Shield\", and \"The Santa Machine\" were suggested. Russel suggested calling it \"Project: Halo\" because of the ring. Despite concerns that the title seemed too religious or lacked action, the name stuck. In turn, \"Halo\" became the ring's name as well.\n\n\"Combat Evolved\"s Halo was intended to be populated with large animal life, collectively known as Fauna. The Fauna included \"pseudo-dinosaurs\" and mammals, as well as a Chocobo-like creature—the \"Blind Wolf\"—that players could ride. The animals were removed for technical and conceptual reasons; there were difficulties in getting herd and behavior action to work, and under pressure to complete the game's more central aspects, the animals were dropped. Bungie also felt that the desolate ring heightened the sense of Halo's mystery, and made the appearance of the parasitic Flood more terrifying and unexpected.\n\nPhysicist Kevin Grazier posited in a 2006 essay the composition and problems associated with a Halo installation. The complete Halos seen in \"Halo: Combat Evolved\" and \"Halo 2\" orbit gas giants similar to Jupiter, though much larger; the bodies exhibit characteristics of both a jovian planet and a small star. In each system, there are five points where a body of negligible mass would remain stationary to the two much larger bodies in the system, the gas giant and its moon. These areas, known as Lagrange points, are classified by stability; while bodies at 60° angles to the gas giant would remain in the same location relative to the other objects in the system, the other three Lagrange points are meta-stable, having the tendency to be unstable in one direction. As the Halos are located at point , the installations must actively correct its orbit. The apparent gravity of the Halo installations is close to Earth normal. A Halo would have to spin with a tangental speed of per second to match Earth's gravity, translating to 19.25 rotations in a day.\n\nAside from its unstable position, Halos would have to contend with thousands of meteor and micrometeor impacts which would destabilize or destroy the ring; there is no evidence in the games that the installations project an energy shield to prevent this occurrence. Because of the magnetic environment around the gas giant, a Halo would be exposed to high levels of radiation. Earth is protected from such radiation by charged particles created by the planet's magnetic field. Grazier posits that huge conductive cables could run the circumference of a Halo; when an electric current was run through these cables, a protective magnetic environment could be created to sustain life.\n\nIn the games, spectroscopic analysis of the ring's composition proved \"inconclusive\", implying that the Halos are constructed of an unknown material (unobtainium). Were a Halo to be constructed using conventional materials a light steel alloy would be most feasible. Assuming that the ring structure is 50% empty space, a 5000 km ring composed of steel alloy at an average density of per would result in a total mass of 1.7x10 kg. The amount of material required to build such a ring would be akin to the total material available in the asteroid belt.\n\nInstallation 03, also referred to as Gamma Halo, appears in \"Halo 4\". It is monitored by 049 Abject Testament and is located in the Khaphrae system, orbiting a damaged planet. Whilst no gameplay takes place on the installation, an extremely dense asteroid field surrounding the installation is the site of the UNSC scientific research base \"Ivanoff\". It is here that UNSC scientists are conducting experiments on the Forerunner artifact called the Composer, which has the ability to convert biological forms, specifically humans, into AIs. After the game's antagonist, the Didact, activates the device, the UNSC base is left uninhabited. In \"Halo: Escalation\", a series of comics which follows many events after \"Halo 4\", establishes that 049 Abject Testament has long disappeared from the ring, leading a monitor to arrive at the Installation, just to be ambushed by a still living Didact, using the Installation to use the Composer.\n\nInstallation 04, also referred to as Alpha Halo, appears in \"\". The majority of gameplay takes place in areas on this installation, and its exploration drives the story. The ring was managed by an artificial intelligence known as 343 Guilty Spark, and is located in the Soell system, dominated by a gas giant known as Threshold. Halo orbits Threshold's only satellite, an extremely large moon known as Basis. A group of humans aboard the ship \"Pillar of Autumn\" crash-land on the ring after being pursued by the alien Covenant. The ring holds religious significance to the aliens, while the humans believe it is a weapon that could turn the tide of the war against the Covenant in their favor. In reality, the ring is home to a virulent parasite called the Flood, which is accidentally released by the Covenant and threatens to infest the galaxy. The human soldier Master Chief eventually detonates the \"Pillar of Autumn\"s reactors in order to destabilize the ring and cause it to break up, preventing the spread of the Flood and the activation of the Halo network, which would kill all sentient life as a fail-safe to starve the Flood. The Ark was alerted to its destruction and proceeded to create another ring, which, too, was destroyed by Master Chief. During the game's events, Guilty Spark alludes to a previous firing of the network, which Bungie's director of cinematics Joseph Staten said occurred around 100,000 years previous to the events of the game in the year 2552. After Installation 04 was destroyed, a shard of the ring was sent through slipspace to orbit a red giant. The supernova-like detonation of the \"Pillar of Autumn\" creates a new element on the ring shard which is fatal to humans. Appearing in \"Halo: Nightfall\", the shard is visited by a team of ONI operatives and colonial militia following a terrorist attack with the new element. With only a limited time before the shard's sunrise kills them, the team struggles to destroy the deposits and capture the smugglers mining it. Only two of the team manage to escape while Colonel Randall Aiken, a former Spartan supersoldier, sacrifices himself to destroy the deposits with a nuclear weapon.\n\nDuring the events of \"Halo 2\", the Covenant and humans discover a second ringworld, Installation 05, or Delta Halo. It was monitored by 2401 Penitent Tangent, who completely ignored Flood warnings and was captured by their leader, the Gravemind. The Covenant leadership wants to activate the installation, believing it is the key to their salvation. At the same time, the Flood, led by an intelligence known as the Gravemind, lay siege to the Covenant's city-ship, \"High Charity\". After 343 Guilty Spark informs Halo's true purpose to the Arbiter, a Covenant holy warrior, of the danger that the Halos truly represent, a group of humans and Covenant Elites prevent the firing of the ring. The unexpected shutdown activates a fail-safe protocol, priming the remaining Halo installations for remote activation from a location known as The Ark.\nIn \"Halo 4\", it is revealed that the UNSC has created an oversight base on the Installation (or around it), as they did with Installation 03.\n\nThe Ark, also referred to as Installation 00, is located outside the Milky Way galaxy and serves as the construction and control station for the Halo weapon system. It does not share the ringworld geometry of the other installations. During \"Halo 3\", the Covenant discover a portal on Earth that leads to the Ark and are pursued by the humans and a breakaway faction of Covenant opposed to activating the rings. Gravemind, having hijacked \"High Charity\", crash-lands on the installation. The remote firing of the rings is halted by Master Chief and the Arbiter. In order to end the threat of the Flood, Master Chief decides to activate Installation 08 under construction in The Ark, the replacement for the Halo that he destroyed in \"Halo: Combat Evolved\". Unknown to everyone but 343 Guilty Spark, a premature firing would destroy the installation; the monitor attempted to defend 'his' ring but was destroyed by Master Chief, who proceeded to fire the weapon. The firing tears apart the incomplete Halo and severely damages The Ark as Master Chief, Cortana, and the Arbiter try to escape through the Portal, which closes as they enter, leaving Master Chief and Cortana drifting in space while the Arbiter returns to Earth successfully. The Ark appears in other \"Halo\" novels and the video game \"Halo Wars 2\".\n\nA replacement for Installation 04 that is constructed by the Ark upon the original's destruction in \"Halo: Combat Evolved\". Identical to the original ring, the replacement is mostly complete when the Ark is found a few months after the destruction of Installation 04, but is unfinished enough that parts of its superstructure are visible. Cortana describes it as \"so new, unfinished.\" After the death of the Prophet of Truth, the new ring rises from the Ark's Foundry in front of the Master Chief and the Arbiter who realize that the ring, disconnected from the rest of the network and safely outside the Milky Way galaxy, can be fired to destroy the local infestation on the Ark without harming anything else. After rescuing Cortana from \"High Charity\", the Master Chief and Sergeant Johnson attempt to fire the ring, angering 343 Guilty Spark who knows that doing so will destroy the installation in its present state and heavily damage the Ark. Spark kills Johnson, but is destroyed by the Master Chief before Cortana fires the installation. The Master Chief and the Arbiter manage to escape aboard the \"Forward Unto Dawn\", but the ring's firing causes the Portal to close, severing the ship in half and stranding the Master Chief in space. Firing Installation 08 ends the Flood infestation upon the Ark and destroys the Gravemind and itself. However, in \"Halo Wars 2: Awakening the Nightmare\", Flood infection forms are revealed to have survived in the ruins of \"High Charity\" and are accidentally unleashed again by the Banished before the Flood are contained once more.\n\nIn \"Halo Wars 2\", a second replacement for Installation 04 is found nearly complete on the Ark by the crew of the UNSC \"Spirit of Fire\". With no way back to human space, the crew decides to launch the replacement ring with a distress beacon aboard to Installation 04's original position, thereby signaling for help. A conflict with the Banished occurs on the installation, but Professor Ellen Anders, after disarming the ring's superweapon, is able to take control of the installation's gravity anchors and launch part of its landmass into space, killing the Banished forces. The ring and Anders enter slipspace, but are pulled out prematurely by a construct known as a Guardian.\n\n\n"}
{"id": "14283", "url": "https://en.wikipedia.org/wiki?curid=14283", "title": "Heavy water", "text": "Heavy water\n\nHeavy water (deuterium oxide, ', ') is a form of water that contains a larger than normal amount of the hydrogen isotope deuterium ( or D, also known as \"heavy hydrogen\"), rather than the common hydrogen-1 isotope ( or H, also called protium) that makes up most of the hydrogen in normal water. The presence of deuterium gives the chemical different nuclear properties, and the increase of mass gives it different physical and chemical properties compared to normal \"light water\".\n\nDeuterium is a hydrogen isotope with a nucleus containing a neutron and a proton; the nucleus of a protium (normal hydrogen) atom consists of just a proton. The additional neutron makes a deuterium atom roughly twice as heavy as a protium atom.\n\nA molecule of heavy water has two deuterium atoms in place of the two protium atoms of ordinary \"light\" water. The weight of a heavy water molecule, however, is not substantially different from that of a normal water molecule, because about 89% of the molecular weight of water comes from the single oxygen atom rather than the two hydrogen atoms. The colloquial term \"heavy water\" refers to a highly enriched water mixture that contains mostly deuterium oxide , but also some hydrogen-deuterium oxide (HDO) and a smaller number of ordinary hydrogen oxide molecules. For instance, the heavy water used in CANDU reactors is 99.75% enriched by hydrogen atom-fraction—meaning that 99.75% of the hydrogen atoms are of the heavy type. For comparison, ordinary water (the \"ordinary water\" used for a deuterium standard) contains only about 156 deuterium atoms per million hydrogen atoms, meaning that 0.0156% of the hydrogen atoms are of the heavy type.\n\nHeavy water is not radioactive. In its pure form, it has a density about 11% greater than water, but is otherwise physically and chemically similar. Nevertheless, the various differences in deuterium-containing water (especially affecting the biological properties) are larger than in any other commonly occurring isotope-substituted compound because deuterium is unique among heavy stable isotopes in being twice as heavy as the lightest isotope. This difference increases the strength of water's hydrogen-oxygen bonds, and this in turn is enough to cause differences that are important to some biochemical reactions. The human body naturally contains deuterium equivalent to about five grams of heavy water, which is harmless. When a large fraction of water (> 50%) in higher organisms is replaced by heavy water, the result is cell dysfunction and death.\n\nHeavy water was first produced in 1932, a few months after the discovery of deuterium. With the discovery of nuclear fission in late 1938, and the need for a neutron moderator that captured few neutrons, heavy water became a component of early nuclear energy research. Since then, heavy water has been an essential component in some types of reactors, both those that generate power and those designed to produce isotopes for nuclear weapons. These heavy water reactors have the advantage of being able to run on natural uranium without using graphite moderators that pose radiological and dust explosion hazards in the decommissioning phase. Most modern reactors use enriched uranium with ordinary water as the moderator.\n\nSemiheavy water, HDO, exists whenever there is water with light hydrogen (protium, ) and deuterium (D or ) in the mix. This is because hydrogen atoms (hydrogen-1 and deuterium) are rapidly exchanged between water molecules. Water containing 50% H and 50% D in its hydrogen actually contains about 50% HDO and 25% each of and , in dynamic equilibrium.\nIn normal water, about 1 molecule in 3,200 is HDO (one hydrogen in 6,400 is in the form of D), and heavy water molecules () only occur in a proportion of about 1 molecule in 41 million (i.e. one in 6,400). Thus semiheavy water molecules are far more common than \"pure\" (homoisotopic) heavy water molecules.\n\nWater enriched in the heavier oxygen isotopes and is also commercially available, e.g., for use as a non-radioactive isotopic tracer. It is \"heavy water\" as it is denser than normal water ( is approximately as dense as , is about halfway between and )—but is rarely called heavy water, since it does not contain the deuterium that gives DO its unusual nuclear and biological properties. It is more expensive than DO due to the more difficult separation of O and O. HO is also used for production of fluorine-18 for radiopharmaceuticals and radiotracers and for positron emission tomography.\n\nTritiated water contains tritium (H) in place of protium (H) or deuterium (H), and therefore it is radioactive.\n\nThe physical properties of water and heavy water differ in several respects. Heavy water is less dissociated than light water at given temperature, and the true concentration of D ions is less than ions would be for a light water sample at the same temperature. The same is true of OD vs. ions. For heavy water Kw DO (25.0 °C) = 1.35 × 10, and [D] must equal [OD] for neutral water. Thus pKw DO = p[OD] + p[D] = 7.44 + 7.44 = 14.87 (25.0 °C), and the p[D] of neutral heavy water at 25.0 °C is 7.44.\n\nThe pD of heavy water is generally measured using pH electrodes giving a pH (apparent) value, or pHa, and at various temperatures a true acidic pD can be estimated from the directly pH meter measured pHa, such that pD+ = pHa (apparent reading from pH meter) + 0.41. The electrode correction for alkaline conditions is 0.456 for heavy water. The alkaline correction is then pD+ = pH(apparent reading from pH meter) + 0.456. These corrections are slightly different from the differences in p[D+] and p[OD-] of 0.44 from the corresponding ones in heavy water.\n\nHeavy water is 10.6% denser than ordinary water, and heavy water's physically different properties can be seen without equipment if a frozen sample is dropped into normal water, as it will sink. If the water is ice-cold the higher melting temperature of heavy ice can also be observed: it melts at 3.7 °C, and thus does not melt in ice-cold normal water.\n\nAn early experiment reported not the \"slightest difference\" in taste between ordinary and heavy water. However, rats given a choice between distilled normal water and heavy water were able to avoid the heavy water based on smell, and it may have a different taste.\n\nNo physical properties are listed for \"pure\" semi-heavy water, because it is unstable as a bulk liquid. In the liquid state, a few water molecules are always in an ionised state, which means the hydrogen atoms can exchange among different oxygen atoms. Semi-heavy water could, in theory, be created via a chemical method, but it would rapidly transform into a dynamic mixture of 25% light water, 25% heavy water, and 50% semi-heavy water. However, if it were made in the gas phase and directly deposited into a solid, semi heavy water in the form of ice could be stable. This is due to collisions between water vapour molecules being almost completely negligible in the gas phase at standard temperatures, and once crystallized, collisions between the molecules cease altogether due to the rigid lattice structure of solid ice.\n\nHarold Urey discovered the isotope deuterium in 1931 and was later able to concentrate it in water. Urey's mentor Gilbert Newton Lewis isolated the first sample of pure heavy water by electrolysis in 1933. George de Hevesy and Erich Hofer used heavy water in 1934 in one of the first biological tracer experiments, to estimate the rate of turnover of water in the human body. The history of large-quantity production and use of heavy water in early nuclear experiments is given below.\nEmilian Bratu and Otto Redlich studied the autodissociation of heavy water in 1934.\n\nDifferent isotopes of chemical elements have slightly different chemical behaviors, but for most elements the differences are far too small to use, or even detect. For hydrogen, however, this is not true. The larger chemical isotope-effects seen between protium (light hydrogen) versus deuterium and tritium manifest because bond energies in chemistry are determined in quantum mechanics by equations in which the quantity of reduced mass of the nucleus and electrons appears. This quantity is altered in heavy-hydrogen compounds (of which deuterium oxide is the most common) more than for heavy-isotope substitution in other chemical elements. This isotope effect of heavy hydrogen is magnified further in biological systems, which are very sensitive to small changes in the solvent properties of water.\n\nHeavy water is the only known chemical substance that affects the period of circadian oscillations, consistently increasing the length of each cycle. The effect is seen in unicellular organisms, green plants, isopods, insects, birds, mice, and hamsters. The mechanism is unknown.\n\nTo perform their tasks, enzymes rely on their finely tuned networks of hydrogen bonds, both in the active center with their substrates, and outside the active center, to stabilize their tertiary structures. As a hydrogen bond with deuterium is slightly stronger than one involving ordinary hydrogen, in a highly deuterated environment, some normal reactions in cells are disrupted.\n\nParticularly hard-hit by heavy water are the delicate assemblies of mitotic spindle formation necessary for cell division in eukaryotes. Plants stop growing and seeds do not germinate when given only heavy water, because heavy water stops eukaryotic cell division. The deuterium cell is larger and is a modification of the direction of division. The cell membrane also changes, and it reacts first to the impact of heavy water. In 1972 it was demonstrated that an increase in the percentage content of deuterium in water reduces plant growth. Research conducted on the growth of prokaryote microorganisms in artificial conditions of a heavy hydrogen environment showed that in this environment, all the hydrogen atoms of water could be replaced with deuterium. Experiments showed that bacteria can live in 98% heavy water. However, all concentrations over 50% of deuterium in the water molecules were found to kill plants.\n\nExperiments in mice, rats, and dogs have shown that a degree of 25% deuteration causes (sometimes irreversible) sterility, because neither gametes nor zygotes can develop. High concentrations of heavy water (90%) rapidly kill fish, tadpoles, flatworms, and \"Drosophila\". Mammals (for example, rats) given heavy water to drink die after a week, at a time when their body water approaches about 50% deuteration. The mode of death appears to be the same as that in cytotoxic poisoning (such as chemotherapy) or in acute radiation syndrome (though deuterium is not radioactive), and is due to deuterium's action in generally inhibiting cell division. It is more toxic to malignant cells than normal cells but the concentrations needed are too high for regular use. As in chemotherapy, deuterium-poisoned mammals die of a failure of bone marrow (bleeding and infection) and intestinal-barrier functions (diarrhea and fluid loss).\n\nDespite the problems of plants and animals in living with too much deuterium, prokaryotic organisms such as bacteria, which do not have the mitotic problems induced by deuterium, may be grown and propagated in fully deuterated conditions, resulting in replacement of all hydrogen atoms in the bacterial proteins and DNA with the deuterium isotope.\n\nFull replacement with heavy atom isotopes can be accomplished in higher organisms with other non-radioactive heavy isotopes (such as carbon-13, nitrogen-15, and oxygen-18), but this cannot be done for the stable heavy isotope of hydrogen. This is a consequence of the relative difference in nuclear mass between the isotopes of hydrogen that is the greatest in all elements. This isotopic effect alters physical properties of heavy water to a greater extent than other isotopes, and consequently induces toxicity at high concentration due to slowing down of essential biochemical reactions.\n\nDeuterium oxide is used to enhance boron neutron capture therapy, but this effect does not rely on the biological effects of deuterium per se, but instead on deuterium's ability to moderate (slow) neutrons without capturing them.\n\nBecause it would take a very large amount of heavy water to replace 25% to 50% of a human being's body water (water being in turn 50–75% of body weight) with heavy water, accidental or intentional poisoning with heavy water is unlikely to the point of practical disregard. Poisoning would require that the victim ingest large amounts of heavy water without significant normal water intake for many days to produce any noticeable toxic effects.\n\nOral doses of heavy water in the range of several grams, as well as heavy oxygen O, are routinely used in human metabolic experiments. See doubly labeled water testing. Since one in about every 6,400 hydrogen atoms is deuterium, a 50 kg human containing 32 kg of body water would normally contain enough deuterium (about 1.1 g) to make 5.5 g of pure heavy water, so roughly this dose is required to double the amount of deuterium in the body.\n\nA loss of blood pressure may partially explain the reported incidence of dizziness upon ingestion of heavy water. However, it is more likely that this symptom can be attributed to altered vestibular function.\n\nAlthough many people associate heavy water primarily with its use in nuclear reactors, pure heavy water is not radioactive. Commercial-grade heavy water is slightly radioactive due to the presence of minute traces of natural tritium, but the same is true of ordinary water. Heavy water that has been used as a coolant in nuclear power plants contains substantially more tritium as a result of neutron bombardment of the deuterium in the heavy water (tritium is a health risk when ingested in large quantities).\n\nIn 1990, a disgruntled employee at the Point Lepreau Nuclear Generating Station in Canada obtained a sample (estimated as about a \"half cup\") of heavy water from the primary heat transport loop of the nuclear reactor, and loaded it into a cafeteria drink dispenser. Eight employees drank some of the contaminated water. The incident was discovered when employees began leaving bioassay urine samples with elevated tritium levels. The quantity of heavy water involved was far below levels that could induce heavy water toxicity, but several employees received elevated radiation doses from tritium and neutron-activated chemicals in the water. This was not an incident of heavy water poisoning, but rather radiation poisoning from other isotopes in the heavy water. Some news services were not careful to distinguish these points, and some of the public were left with the impression that heavy water is normally radioactive and more severely toxic than it is. Even if pure heavy water had been used in the water cooler indefinitely, it is not likely the incident would have been detected or caused harm, since no employee would be expected to get much more than 25% of their daily drinking water from such a source.\n\nOn Earth, deuterated water, HDO, occurs naturally in normal water at a proportion of about 1 molecule in 3,200. This means that 1 in 6,400 hydrogen atoms is deuterium, which is 1 part in 3,200 by weight (hydrogen weight). The HDO may be separated from normal water by distillation or electrolysis and also by various chemical exchange processes, all of which exploit a kinetic isotope effect. With the partial enrichment also occurring in natural bodies of water under particular evaporation conditions. (For more information about the isotopic distribution of deuterium in water, see Vienna Standard Mean Ocean Water.) \nIn theory, deuterium for heavy water could be created in a nuclear reactor, but separation from ordinary water is the cheapest bulk production process.\n\nThe difference in mass between the two hydrogen isotopes translates into a difference in the zero-point energy and thus into a slight difference in the speed of the reaction. Once HDO becomes a significant fraction of the water, heavy water becomes more prevalent as water molecules trade hydrogen atoms very frequently. Production of pure heavy water by distillation or electrolysis requires a large cascade of stills or electrolysis chambers and consumes large amounts of power, so the chemical methods are generally preferred.\n\nThe most cost-effective process for producing heavy water is the dual temperature exchange sulfide process (known as the Girdler sulfide process) developed in parallel by Karl-Hermann Geib and Jerome S. Spevack in 1943.\n\nAn alternative process, patented by Graham M. Keyser, uses lasers to selectively dissociate deuterated hydrofluorocarbons to form deuterium fluoride, which can then be separated by physical means. Although the energy consumption for this process is much less than for the Girdler sulfide process, this method is currently uneconomical due to the expense of procuring the necessary hydrofluorocarbons.\n\nAs noted, modern commercial heavy water is almost universally referred to, and sold as, deuterium oxide. It is most often sold in various grades of purity, from 98% enrichment to 99.75–99.98% deuterium enrichment (nuclear reactor grade) and occasionally even higher isotopic purity.\n\nArgentina is the main producer of heavy water, using an ammonia/hydrogen exchange based plant supplied by Switzerland's Sulzer company. It is also a major exporter to Canada, Germany, the US and other countries. The heavy water production facility located in Arroyito is the world's largest heavy water production facility. Argentina produces of heavy water per year using, not HS bithermal method, but \"monothermal ammonia-hydrogen isotopic exchange\".\n\nIn October 1939, Soviet physicists Yakov Borisovich Zel'dovich and Yulii Borisovich Khariton concluded that heavy water and carbon were the only feasible moderators for a natural uranium reactor, and in August 1940, along with Georgy Flyorov, submitted a plan to the Russian Academy of Sciences calculating that 15 tons of heavy water were needed for a reactor. With the Soviet Union having no uranium mines at the time, young Academy workers were sent to Leningrad photographic shops to buy uranium nitrate, but the entire heavy water project was halted in 1941 when German forces invaded during Operation Barbarossa.\n\nBy 1943, Soviet scientists had discovered that all scientific literature relating to heavy water had disappeared from the West, which Flyorov in a letter warned Soviet leader Joseph Stalin about, and at which time there was only 2–3 kg of heavy water in the entire country. In late 1943, the Soviet purchasing commission in the U.S. obtained 1 kg of heavy water and a further 100 kg in February 1945, and upon World War II ending, the NKVD took over the project.\n\nIn October 1946, as part of the Russian Alsos, the NKVD deported to the Soviet Union from Germany the German scientists who had worked on heavy water production during the war, including Karl-Hermann Geib, the inventor of the Girdler sulfide process. These German scientists worked under the supervision of German physical chemist Max Volmer at the Institute of Physical Chemistry in Moscow with the plant they constructed producing large quantities of heavy water by 1948.\n\nDuring the Manhattan Project the United States constructed three heavy water production plants as part of the P-9 Project at Morgantown Ordnance Works, near Morgantown, West Virginia; at the Wabash River Ordnance Works, near Dana and Newport, Indiana; and at the Alabama Ordnance Works, near Childersburg and Sylacauga, Alabama. Heavy water was also acquired from the Cominco plant in Trail, British Columbia, Canada. The Chicago Pile-3 experimental reactor used heavy water as a moderator and went critical in 1944. The three domestic production plants were shut down in 1945 after producing around 20 metric tons of product (around 20,000 litres). The Wabash plant was reopened and began resumption of heavy water production in 1952.\n\nIn 1953, the United States began using heavy water in plutonium production reactors at the Savannah River Site. The first of the five heavy water reactors came online in 1953, and the last was placed in cold shutdown in 1996. The SRS reactors were heavy water reactors so that they could produce both plutonium and tritium for the US nuclear weapons program.\n\nThe U.S. developed the Girdler sulfide chemical exchange production process—which was first demonstrated on a large scale at the Dana, Indiana plant in 1945 and at the Savannah River Plant, South Carolina in 1952. DuPont operated the SRP for the USDOE until 1 April 1989, when Westinghouse took it over.\n\nIndia is one of the world's largest producers of heavy water through its Heavy Water Board and also exports to countries like Republic of Korea and the US. Development of heavy water process in India happened in three phases: The first phase (late 1950s to mid-1980s) was a period of technology development, the second phase was of deployment of technology and process stabilisation (mid-1980s to early 1990s) and third phase saw consolidation and a shift towards improvement in production and energy conservation.\n\nIn the 1930s, it was suspected by the United States and Soviet Union that Austrian chemist Fritz Johann Hansgirg built a pilot plant for the Empire of Japan in Japanese ruled northern Korea to produce heavy water by using a new process he had invented.\n\nIn 1934, Norsk Hydro built the first commercial heavy water plant at Vemork, Tinn, with a capacity of 12 tonnes per year. From 1940 and throughout World War II, the plant was under German control and the Allies decided to destroy the plant and its heavy water to inhibit German development of nuclear weapons. In late 1942, a planned raid by British airborne troops failed, both gliders crashing. The raiders were killed in the crash or subsequently executed by the Germans. On the night of 27 February 1943 Operation Gunnerside succeeded. Norwegian commandos and local resistance managed to demolish small, but key parts of the electrolytic cells, dumping the accumulated heavy water down the factory drains.\n\nOn 16 November 1943, the Allied air forces dropped more than 400 bombs on the site. The Allied air raid prompted the Nazi government to move all available heavy water to Germany for safekeeping. On 20 February 1944, a Norwegian partisan sank the ferry M/F \"Hydro\" carrying heavy water across Lake Tinn, at the cost of 14 Norwegian civilian lives, and most of the heavy water was presumably lost. A few of the barrels were only half full, and therefore could float, and may have been salvaged and transported to Germany.\n\nRecent investigation of production records at Norsk Hydro and analysis of an intact barrel that was salvaged in 2004 revealed that although the barrels in this shipment contained water of pH 14—indicative of the alkaline electrolytic refinement process—they did not contain high concentrations of DO. Despite the apparent size of the shipment, the total quantity of pure heavy water was quite small, most barrels only containing 0.5–1% pure heavy water. The Germans would have needed a total of about 5 tons of heavy water to get a nuclear reactor running. The manifest clearly indicated that there was only half a ton of heavy water being transported to Germany. \"Hydro\" was carrying far too little heavy water for one reactor, let alone the 10 or more tons needed to make enough plutonium for a nuclear weapon.\n\nIsrael admitted running the Dimona reactor with Norwegian heavy water sold to it in 1959. Through re-export using Romania and Germany, India probably also used Norwegian heavy water.\n\nAs part of its contribution to the Manhattan Project, Canada built and operated a 6-tonnes-per-year electrolytic heavy water plant at Trail, British Columbia, which started operation in 1943.\n\nThe Atomic Energy of Canada Limited (AECL) design of power reactor requires large quantities of heavy water to act as a neutron moderator and coolant. AECL ordered two heavy water plants, which were built and operated in Atlantic Canada at Glace Bay, Nova Scotia (by Deuterium of Canada Limited) and Port Hawkesbury, Nova Scotia (by General Electric Canada). These plants proved to have significant design, construction and production problems. Consequently, AECL built the Bruce Heavy Water Plant (), which it later sold to Ontario Hydro, to ensure a reliable supply of heavy water for future power plants. The two Nova Scotia plants were shut down in 1985 when their production proved unnecessary.\n\nThe Bruce Heavy Water Plant (BHWP) in Ontario was the world's largest heavy water production plant with a capacity of 1600 tonnes per year at its peak (800 tonnes per year per full plant, two fully operational plants at its peak). It used the Girdler sulfide process to produce heavy water, and required 340,000 tonnes of feed water to produce one tonne of heavy water. It was part of a complex that included eight CANDU reactors, which provided heat and power for the heavy water plant. The site was located at Douglas Point/Bruce Nuclear Generating Station near Tiverton, Ontario on Lake Huron where it had access to the waters of the Great Lakes.\n\nAECL issued the construction contract in 1969 for the first BHWP unit (BHWP A). Commissioning of BHWP A was done by Ontario Hydro from 1971 through 1973, with the plant entering service on June 28, 1973 and design production capacity being achieved in April 1974. Due to the success of BHWP A and the large amount of heavy water that would be required for the large numbers of upcoming planned CANDU nuclear power plant construction projects, Ontario Hydro commissioned three additional heavy water production plants for the Bruce site (BHWP B, C, and D). BHWP B was placed into service in 1979. These first two plants were significantly more efficient than planned, and the number of CANDU construction projects ended up being significantly lower than originally planned, which led to the cancellation of construction on BHWP C & D. In 1984 BHWP A was shut down. By 1993 Ontario Hydro had produced enough heavy water to meet all of its anticipated domestic needs (which were lower than expected due to improved efficiency in the use and recycling of heavy water), so they shut down and demolished half of the capacity of BHWP B. The remaining capacity continued to operate in order to fulfill demand for heavy water exports until it was permanently shut down in 1997, after which the plant was gradually dismantled and the site cleared.\n\nAECL is currently researching other more efficient and environmentally benign processes for creating heavy water. This is essential for the future of the CANDU reactors since heavy water represents about 15–20% of the total capital cost of each CANDU plant.\n\nSince 1996 a plant for production of heavy water was being constructed at Khondab near Arak. On 26 August 2006, Iranian President Ahmadinejad inaugurated the expansion of the country's heavy-water plant. Iran has indicated that the heavy-water production facility will operate in tandem with a 40 MW research reactor that had a scheduled completion date in 2009.\n\nIran produced deuterated solvents in early 2011 for the first time.\n\nThe core of the IR-40 is supposed to be re-designed based on the nuclear agreement in July 2015.\n\nIran is permitted to store only of heavy water. Iran exports excess production after exceeding their allotment making Iran the world's third largest exporter of heavy water.\n\nThe 50 MW heavy water and natural uranium research reactor at Khushab, in Punjab province, is a central element of Pakistan's program for production of plutonium, deuterium and tritium for advanced compact warheads (i.e. thermonuclear weapons). Pakistan succeeded in acquiring a tritium purification and storage plant and deuterium and tritium precursor materials from two German firms.\n\nRomania produces heavy water at the Drobeta Girdler sulfide plant for domestic and export purposes.\n\nFrance operated a small plant during the 1950s and 1960s.\n\nHeavy water exists in elevated concentration in the hypolimnion of Lake Tanganyika in East Africa. It is likely that similar elevated concentrations exist in lakes with similar limnology, but this is only 4% enrichment (24 vs 28) and surface waters are usually enriched in by evaporation to even greater extend by faster evaporation. \n\nDeuterium oxide is used in nuclear magnetic resonance spectroscopy when using water as solvent if the nuclide of interest is hydrogen. This is because the signal from light-water (HO) solvent molecules interfere with observing the signal from the molecule of interest dissolved in it. Deuterium has a different magnetic moment and therefore does not contribute to the H-NMR signal at the hydrogen-1 resonance frequency.\n\nFor some experiments, it may be desirable to identify the labile hydrogens on a compound, that is hydrogens that can easily exchange away as H ions on some positions in a molecule. With addition of DO, sometimes referred to as a \"DO shake\", labile hydrogens exchange away and are substituted by deuterium (H) atoms. These positions in the molecule then do not appear in the H-NMR spectrum.\n\nDeuterium oxide is often used as the source of deuterium for preparing specifically labelled isotopologues of organic compounds. For example, C-H bonds adjacent to ketonic carbonyl groups can be replaced by C-D bonds, using acid or base catalysis. Trimethylsulfoxonium iodide, made from dimethyl sulfoxide and methyl iodide can be recrystallized from deuterium oxide, and then dissociated to regenerate methyl iodide and dimethyl sulfoxide, both deuterium labelled. In cases where specific double labelling by deuterium and tritium is contemplated, the researcher must be aware that deuterium oxide, depending upon age and origin, can contain some tritium.\n\nDeuterium oxide is often used instead of water when collecting FTIR spectra of proteins in solution. HO creates a strong band that overlaps with the amide I region of proteins. The band from DO is shifted away from the amide I region.\n\nHeavy water is used in certain types of nuclear reactors, where it acts as a neutron moderator to slow down neutrons so that they are more likely to react with the fissile uranium-235 than with uranium-238, which captures neutrons without fissioning.\nThe CANDU reactor uses this design. Light water also acts as a moderator, but because light water absorbs more neutrons than heavy water, reactors using light water for a reactor moderator must use enriched uranium rather than natural uranium, otherwise criticality is impossible. A significant fraction of outdated power reactors, such as the RBMK reactors in the USSR, were constructed using normal water for cooling but graphite as a moderator. However, the danger of graphite in power reactors (graphite fires in part led to the Chernobyl disaster) has led to the discontinuation of graphite in standard reactor designs.\n\nBecause they do not require uranium enrichment, heavy water reactors are more of a concern in regards to nuclear proliferation. The breeding and extraction of plutonium can be a relatively rapid and cheap route to building a nuclear weapon, as chemical separation of plutonium from fuel is easier than isotopic separation of U-235 from natural uranium.\nAmong current and past nuclear weapons states, Israel, India, and North Korea first used plutonium from heavy water moderated reactors burning natural uranium, while China, South Africa and Pakistan first built weapons using highly enriched uranium.\n\nIn the U.S., however, the first experimental atomic reactor (1942), as well as the Manhattan Project Hanford production reactors that produced the plutonium for the Trinity test and Fat Man bombs, all used pure carbon (graphite) neutron moderators combined with normal water cooling pipes. They functioned with neither enriched uranium nor heavy water. Russian and British plutonium production also used graphite-moderated reactors.\n\nThere is no evidence that civilian heavy water power reactors—such as the CANDU or Atucha designs—have been used to produce military fissile materials. In nations that do not already possess nuclear weapons, nuclear material at these facilities is under IAEA safeguards to discourage any diversion.\n\nDue to its potential for use in nuclear weapons programs, the possession or import/export of large industrial quantities of heavy water are subject to government control in several countries. Suppliers of heavy water and heavy water production technology typically apply IAEA (International Atomic Energy Agency) administered safeguards and material accounting to heavy water. (In Australia, the \"Nuclear Non-Proliferation (Safeguards) Act 1987\".) In the U.S. and Canada, non-industrial quantities of heavy water (i.e., in the gram to kg range) are routinely available without special license through chemical supply dealers and commercial companies such as the world's former major producer Ontario Hydro.\n\nThe Sudbury Neutrino Observatory (SNO) in Sudbury, Ontario uses 1,000 tonnes of heavy water on loan from Atomic Energy of Canada Limited. The neutrino detector is underground in a mine, to shield it from muons produced by cosmic rays. SNO was built to answer the question of whether or not electron-type neutrinos produced by fusion in the Sun (the only type the Sun should be producing directly, according to theory) might be able to turn into other types of neutrinos on the way to Earth. SNO detects the Cherenkov radiation in the water from high-energy electrons produced from electron-type neutrinos as they undergo charged current (CC) interactions with neutrons in deuterium, turning them into protons and electrons (however, only the electrons are fast enough to produce Cherenkov radiation for detection). SNO also detects neutrino↔electron scattering (ES) events, where the neutrino transfers energy to the electron, which then proceeds to generate Cherenkov radiation distinguishable from that produced by CC events. The first of these two reactions is produced only by electron-type neutrinos, while the second can be caused by all of the neutrino flavors. The use of deuterium is critical to the SNO function, because all three \"flavours\" (types) of neutrinos may be detected in a third type of reaction as well, neutrino-disintegration, in which a neutrino of any type (electron, muon, or tau) scatters from a deuterium nucleus (deuteron), transferring enough energy to break up the loosely bound deuteron into a free neutron and proton via a neutral current (NC) interaction. This event is detected when the free neutron is absorbed by Cl present from NaCl deliberately dissolved in the heavy water, causing emission of characteristic capture gamma rays. Thus, in this experiment, heavy water not only provides the transparent medium necessary to produce and visualize Cherenkov radiation, but it also provides deuterium to detect exotic mu type (μ) and tau (τ) neutrinos, as well as a non-absorbent moderator medium to preserve free neutrons from this reaction, until they can be absorbed by an easily detected neutron-activated isotope.\n\nHeavy water is employed as part of a mixture with HO for a common and safe test of mean metabolic rate in humans and animals undergoing their normal activities.\n\nTritium is the active substance in self-powered lighting and controlled nuclear fusion, its other uses including autoradiography and radioactive labeling. It is also used in nuclear weapon design for boosted fission weapons and initiators. Some tritium is created in heavy water moderated reactors when deuterium captures a neutron. This reaction has a small cross-section (probability of a single neutron-capture event) and produces only small amounts of tritium, although enough to justify cleaning tritium from the moderator every few years to reduce the environmental risk of tritium escape.\n\nProducing a lot of tritium in this way would require reactors with very high neutron fluxes, or with a very high proportion of heavy water to nuclear fuel and very low neutron absorption by other reactor material. The tritium would then have to be recovered by isotope separation from a much larger quantity of deuterium, unlike production from lithium-6 (the present method), where only chemical separation is needed.\n\nDeuterium's absorption cross section for thermal neutrons is 0.52 millibarns (5.2 × 10 m; 1 barn = 10 m), while those of oxygen-16 and oxygen-17 are 0.19 and 0.24 millibarns, respectively. O makes up 0.038% of natural oxygen, making the overall cross section 0.28 millibarns. Therefore, in DO with natural oxygen, 21% of neutron captures are on oxygen, rising higher as O builds up from neutron capture on O. Also, O may emit an alpha particle on neutron capture, producing radioactive carbon-14.\n\n\n"}
{"id": "14459375", "url": "https://en.wikipedia.org/wiki?curid=14459375", "title": "Heffa Schücking", "text": "Heffa Schücking\n\nHeffa Schücking is a German environmentalist. She was awarded the Goldman Environmental Prize in 1994, for her works to protect the rainforests.\n\nToday, she mainly works for the NGO urgewald on campaigns to prevent banks and the financial industry from making harmful investments such as cluster ammunition, coal mining or the nuclear industry.\n"}
{"id": "50941168", "url": "https://en.wikipedia.org/wiki?curid=50941168", "title": "How to Let Go of the World and Love All the Things Climate Can't Change", "text": "How to Let Go of the World and Love All the Things Climate Can't Change\n\nHow to Let Go of the World (And Love All the Things Climate Can't Change) is a 2016 environmental documentary by Josh Fox that premiered at the 2016 Sundance Film Festival.\n\n"}
{"id": "47492430", "url": "https://en.wikipedia.org/wiki?curid=47492430", "title": "Ion reactor", "text": "Ion reactor\n\nIon Reactor, is an invention by a British scientist.\n\nIn 2011, Dr Christopher Strevens (an inventor from London) began posting a website with instructions of how to build his \"fusion reactor\", which he says: \"Creates helium from hydrogen. It also captures the power given off during the reaction as electrical power.\" He also posted several videos to YouTube showing his prototype in operation, and showing the different color of gas from before versus after; as well as showing spectral analysis that indicates that the hydrogen that he puts into the system has transmuted to helium—a nuclear phenomenon.\n\nHe said: \"I found that when I increased the exciter power to 800 Watts, the output rose to 2,000 Watts [2.5-times overunity], and when I isolated the reactor from the exciter, this power remained. The spark gap regulator became active, keeping the power at this level. I only allowed this for a short time before reconnecting the exciter and turning the power down and the reaction ceased.\"\n\nBecause of the experiment being dangerous it would require a special paramagnetic ceramic bottle glazed inside to contain hydrogen ions and use the magnetic field of the coils and induction of ion fields to make a magnetic bottle to confine the ion reactions.\n\nA brief description of the device, being a hydrogen tube wrapped with high voltage coils and a sort of energizing coil being similar to a high voltage tesla coil for the ionizer. The device having been made in a clear glass tube in early experiments uses induction to ionize the gases and the field made by ionized gases to energize ion tube coils.\n\nThe effect is similar to pyroelectric fusion but instead of pyroelectric crystals stripping the electrons from hydrogen atoms it is a high voltage induced electromagnetic field of coils and electrostatic induction of the ionized gas.\n\nhttps://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19660030642.pdf\n\n"}
{"id": "3838963", "url": "https://en.wikipedia.org/wiki?curid=3838963", "title": "John Sealy Townsend", "text": "John Sealy Townsend\n\nSir John Sealy Edward Townsend, FRS (7 June 1868 – 16 February 1957) was an Irish mathematical physicist who conducted various studies concerning the electrical conduction of gases (concerning the kinetics of electrons and ions) and directly measured the electrical charge. He was a Wykeham Professor of physics at Oxford University.\n\nThe phenomenon of the electron avalanche was discovered by him, and is known as the Townsend discharge.\n\nJohn Townsend was born in Galway, County Galway, Ireland, son of Edward Townsend, a Professor of Civil Engineering at Queen's College, Galway and Judith Townsend. In 1885, he entered Trinity College Dublin, was elected a Scholar of the College in 1888, and came top of the class in mathematics with a BA in 1890. He became a Clerk Maxwell Scholar and entered Trinity College, Cambridge, where he became a research student at the same time as Ernest Rutherford. At the Cavendish laboratory, he studied under J. J. Thomson. He developed the \"Townsend's collision theory\". Townsend supplied important work to the electrical conductivity of gases (\"Townsend discharge\" circa 1897). This work determined the elementary electrical charge with the droplet method. This method was improved later by Robert Andrews Millikan.\n\nIn 1900, Townsend became a Wykeham Professor of Physics at Oxford. In 1901, he discovered the ionization of molecules by ion impact and the dependence of the mean free path on electrons (in gases) of the energy (and his independent studies concerning the collisions between atoms and low-energy electrons in the 1920s would later be called the Ramsauer–Townsend effect). On 11 June 1903, he was elected to Fellow of the Royal Society (FRS). He was awarded the Hughes Medal in 1914. During World War I, he researched, at Woolwich, wireless methods for the Royal Naval Air Service.\n\nTownsend was a laboratory demonstrator when Brebis Bleaney was an undergraduate. Bleaney recounts an occasion when Townsend gathered together all the demonstrators and proceeded to refute both quantum mechanics and relativity.\n\nBetween the two world wars, Townsend led an effective small group of researchers, often Rhodes scholars, of whom some became distinguished physicists. However, by the 1930s he had become less effective. He was seen as a boring lecturer, a dogmatic supervisor, and out of touch with the wider world of physics. As the 1930s went on, no German refugees sought refuge in his laboratory, while Lindemann, Dr Lee's professor of Physics, gained eight refugee physicists, some of whom gave his department an international reputation in the world of low temperature physics. In the late 1930s, the University decided to build a new Clarendon Laboratory Building and looked closely at the relations between Oxford's two physics laboratories. There was a suggestion to convert the Wykeham chair into one for theoretical physics. In 1941, Townsend's career came to an unhappy end. He had refused to support the war effort by teaching service-men, and the university appointed a visitorial board. This found Townsend guilty of misconduct and advised him that he would be dismissed unless he agreed to resign. Townsend, knighted in January 1941, resigned in September, subject to confidentiality.\nJohn Townsend spent his retirement in Oxford, where he died in 1957 in the Acland Nursing Home.\n\nTownsend married May Georgina, also from County Galway, and they had two sons. His wife took an interest in politics, became a city councillor, and was twice Mayor of Oxford.\n\n\n\n"}
{"id": "26174474", "url": "https://en.wikipedia.org/wiki?curid=26174474", "title": "Kawagoe Power Station", "text": "Kawagoe Power Station\n\n"}
{"id": "125487", "url": "https://en.wikipedia.org/wiki?curid=125487", "title": "List of culinary herbs and spices", "text": "List of culinary herbs and spices\n\nThis is a list of culinary herbs and spices. Specifically these are food or drink additives of mostly botanical origin used in nutritionally insignificant quantities for flavoring or coloring.\n\nThis list does not contain fictional plants such as aglaophotis, or recreational drugs such as tobacco.\n\nThis list is not for plants used primarily for herbal teas, nor for purely medicinal plant products, such as valerian.\n\n\n\n\n\n\" (Ancient Roman cuisine, Ancient Greek cuisine)\n\n\n"}
{"id": "26891004", "url": "https://en.wikipedia.org/wiki?curid=26891004", "title": "Matador (toy)", "text": "Matador (toy)\n\nMatador is a wooden toy set. The bricks are held together using special wooden sticks.\n\nThe blocks are precision cut to a single size and shape and are held together with sticks, which assists in the stability of larger constructions. The standard distance between brick holes is 20mm. The blocks are not varnished or treated.\n\nThe set has been invented by the Austrian engineer Johann Korbuly.\n\n"}
{"id": "1380151", "url": "https://en.wikipedia.org/wiki?curid=1380151", "title": "Mount Waialeale", "text": "Mount Waialeale\n\nMount Waialeale is a shield volcano and the second highest point on the island of Kauai in the Hawaiian Islands. Its name literally means \"rippling water\" or \"overflowing water\" \n\nThe mountain, at an elevation of , averages more than of rain a year since 1912, with a record in 1982; its summit is one of the rainiest spots on earth. However, recent reports mention that over the period 1978–2007 the wettest spot in Hawaii is Big Bog on Maui ( per year).\n\nThe summit of Waialeale features a tropical rainforest climate (Köppen \"Af\"), with substantial rainfall throughout the course of the year. quotes per year figure as being the 1912–45 average, an average that quite possibly will have changed since then, while The National Climatic Data Center quotes this figure as a 30-year average. The Weather Network and \"The Guinness Book of Weather Records\" quotes rain per year, while quotes as the average annual rainfall at Mount Waialeale and claims falls here. Similarly, The Weather Network and the \"Guinness Book of Weather Records\" quote 335 days with rain here while suggests that rain falls on 360 days per year.\n\nThe local tourist industry of Kauai has promoted it as the wettest spot, although the 38-year average at Mawsynram, Meghalaya, India is higher at . Both Mawsynram and Cherrapunji in Meghalaya are recognized by the \"Guinness Book of World Records\" as having higher average rainfall. Mawsynram's rainfall is concentrated in the monsoon season, while the rain at Waiʻaleʻale is more evenly distributed through the year.\n\nSeveral factors give the summit of Waialeale more potential to create precipitation than the rest of the island chain:\n\nThe great rainfall in the area produces the Alakai Wilderness Preserve, a large boggy area that is home to many rare plants. The ground is so wet that although trails exist, access by foot to the Waiʻaleʻale area is extremely difficult.\n\nA number of rare local plant species are named for this mountain, including \"Astelia waialealae\", \"Melicope waialealae\", and the endemic \"Dubautia waialealae\".\n\n\n"}
{"id": "25565997", "url": "https://en.wikipedia.org/wiki?curid=25565997", "title": "Nuns' Island gas station", "text": "Nuns' Island gas station\n\nThe Nun's Island gas station was a modernist-style filling station designed by Ludwig Mies van der Rohe in 1969, one of four buildings by Mies in Nuns' Island, an island in the city of Montreal. It is no longer a working gas station after being converted to a community centre.\n\nIt was the first gas station on the island, and the first designed by Mies, who had worked in collaboration with local architect Paul H. Lapointe on the project. The station was commissioned by Imperial Oil.\n\nThe borough of Verdun transformed the building into a community arts centre, La Station. Eric Gauthier was the lead architect on the project, which saw the two glass pavilions rebuilt to their original 3,000- and sizes.\n\nLa Station is a community centre for teens and people over 50 years of age. The two main buildings are called the \"salle blanche\" (English: white room) and \"salle noire\" (English: black room), after their floor colours. The original glass-enclosed attendant's booth serves as a display case of Mies' and the building's history, with the former fuel dispensers marked by ventilation shafts. The centre uses geothermal energy.\n\n\n"}
{"id": "37587003", "url": "https://en.wikipedia.org/wiki?curid=37587003", "title": "On the Line (2011 film)", "text": "On the Line (2011 film)\n\nOn the Line is a 2011 Canadian documentary by Frank Wolf that investigates the risks and consequences associated with the proposed Enbridge Northern Gateway Pipelines project. The film is set in the context of a 2,400 km biking, hiking, rafting and kayaking journey that two friends embark on from the Alberta oil sands to the British Columbia coast. As the pair travel the proposed pipeline route, they encounter a broad cross-section of people who voice their perspective on the issues associated with the project. It won the 'Spirit of Action Prize' at the 2012 Santa Cruz Film Festival and was chosen for the VIFF Selects section at the 2011 Vancouver International Film Festival. It airs on CBC's documentary (TV channel) in Canada multiple times through 2015. The film features music by Peirson Ross, Terry Jacks, Chilliwack, Kola Collective, Phontaine,Tessa Amy, and Eric Stanger.\n"}
{"id": "11049146", "url": "https://en.wikipedia.org/wiki?curid=11049146", "title": "Outdoor heating", "text": "Outdoor heating\n\nOutdoor heating allows people to stay in substantially unenclosed spaces, when it would otherwise be too cold to do so. To this end, various outdoor heating appliances are available, including gas patio heaters, quartz or ceramic electric lamps, and wood burning chimenea and fire pits.\n\nIn an outdoor environment, convection would quickly carry away heat in the form of hot air, so all these methods emit various amounts of their total output as radiant heat. Radiant heat is emitted from the appliance, and is absorbed by objects and people, raising their temperature.\n"}
{"id": "1321031", "url": "https://en.wikipedia.org/wiki?curid=1321031", "title": "Photoelectrolysis", "text": "Photoelectrolysis\n\nPhotoelectrolysis, also known as water splitting, occurs in a photoelectrochemical cell when light is used as the energy source for the electrolysis of water, producing dihydrogen which can be used as a fuel. This process is one route to a \"hydrogen economy\", in which hydrogen fuel is produced efficiently and inexpensively from natural sources without using fossil fuels. In contrast, steam reforming usually or always uses a fossil fuel to obtain hydrogen. Photoelectrolysis is sometimes known colloquially as the \"hydrogen holy grail\" for its potential to yield a viable alternative to petroleum as a source of energy; such an energy source would supposedly come without the sociopolitically undesirable effects of extracting and using petroleum.\n\nSome researchers have practiced photoelectrolysis by means of a nanoscale process. Nanoscale photoelectrolysis of water could someday reach greater efficiency than that of \"traditional\" photoelectrolysis. Semiconductors with bandgaps smaller than 1.7 eV would ostensibly be required for efficient nanoscale photoelectrolysis using light from the Sun.\n\nDevices based on hydrogenase have also been investigated.\n\n"}
{"id": "11042043", "url": "https://en.wikipedia.org/wiki?curid=11042043", "title": "Plakohypaphorine", "text": "Plakohypaphorine\n\nPlakohypaphorines are halogenated indolic non-proteinogenic amino acids named for their similarity to hypaphorine (\"N,N,N\"-trimethyltryptophan), First reported in the Caribbean sponge \"Plakortis simplex\" in 2003, plakohypaphorines A-C were the first iodine-containing indoles to be discovered in nature. Plakohypaphorines D-F, also found in \"P. simplex\", were reported in 2004 by a group including the researchers who discovered the original plakohypaphorines.\n\n"}
{"id": "701107", "url": "https://en.wikipedia.org/wiki?curid=701107", "title": "Planck energy", "text": "Planck energy\n\nIn physics, Planck energy, denoted by , is the unit of energy in the system of natural units known as Planck units.\n\nwhere is the speed of light in a vacuum, is the reduced Planck's constant, and is the gravitational constant.\n\nSubstituting values for the various components in this definition gives the approximate equivalent value of this unit in terms of other units of energy:\n\nAn equivalent definition is:\n\nwhere is the Planck time.\n\nAlso:\n\nwhere is the Planck mass.\n\nThe ultra-high-energy cosmic ray observed in 1991 had a measured energy of about 50 joules, equivalent to about 2.5×10 . Most Planck units are fantastically small and thus are unrelated to \"macroscopic\" phenomena (or fantastically large, as in the case of Planck temperature and Planck acceleration). Energy of 1 , on the other hand, is definitely macroscopic, approximately equaling the energy stored in an automobile gas tank (57.2 L of gasoline at 34.2 MJ/L of chemical energy).\n\nPlanck units are designed to normalize the physical constants , and to 1. Hence given Planck units, the mass-energy equivalence simplifies to , so that the Planck energy and mass are numerically identical. In the equations of general relativity, is often multiplied by 4π. Hence writings in particle physics and physical cosmology often normalize to 1. This normalization results in the reduced Planck energy, defined as:\n\n"}
{"id": "35987585", "url": "https://en.wikipedia.org/wiki?curid=35987585", "title": "Prigi Arisandi", "text": "Prigi Arisandi\n\nPrigi Arisandi (born 1976) is an Indonesian biologist and environmentalist. He graduated in biology from the Airlangga University. He was awarded the Goldman Environmental Prize in 2011, for his efforts on reducing industrial pollution of the Surabaya River.\n"}
{"id": "43360036", "url": "https://en.wikipedia.org/wiki?curid=43360036", "title": "Regional Snowfall Index", "text": "Regional Snowfall Index\n\nThe regional snowfall index (RSI) is a system used by the NOAA to assess the societal impact of winter storms in the six easternmost regions of the United States. The system is a replacement for the Northeast Snowfall Impact Scale (NESIS) system which the National Climatic Data Center (NCDC) began using in 2005. The NCDC has retroactively assigned RSI values to over 500 historical storms since 1900.\n\nThe index makes use of population and regional differences to assess the impact of snowfall. For example, areas which receive very little snowfall on average may be more adversely affected than other regions, and so the index will grant storms in those regions higher severity.\n\nIn each region, four \"thresholds\" are set based on climatological records:\nFor example, in the Northeast, a typical location will get 16 inches of snow about once every 10 years and 20 inches about once every 25, so the thresholds are 2.5, 10, 20, and 30 inches.\n\nFor each threshold and each region, a baseline area and population are determined; for a given storm, the area that exceeds a particular threshold will be normalized by the baseline value. For example, for a storm in the northeast, the area receiving at least 4 inches of snow is divided by 149,228 square miles, and the population affected is divided by 51,553,600 (using 2010 census data). This gives eight different numbers representing how widespread the storm is compared to notable snow storms in that region. The baseline area and population represent the average area and population for large storms, so that each of these eight different measures will average 1 among storms considered notable (for the calibration sample). The RSI is simply the total of these eight numbers.\n\n\n"}
{"id": "31232659", "url": "https://en.wikipedia.org/wiki?curid=31232659", "title": "Reifendrehen", "text": "Reifendrehen\n\nReifendrehen is a unique type of toy manufacture using wood turning techniques that was developed in the Ore Mountains in the vicinity of the town of Seiffen and continues there to the present day. The process produces small animals and other figures or even little wooden houses in outline, that are used as toys or to decorate Christmas pyramids or Nativity scenes. The animals and figures (\"Reifentiere\" and \"Reifenfiguren\") so produced are an inherent part of Ore Mountain folk art.\n\nIn the process known as \"Reifendrehen\" (literally \"tyre turning\") a suitable piece of wood, as far as possible free of splits, is worked on a special wood lathe to produce a wooden ring with a diameter of about 30 to 50 centimetres, the cross-section of which forms the outline of the desired figure. Small slices are then sawn off the ring. These are used as the raw material from which the finished figures are made by carving and painting.\n\nThe technique of \"Reifendrehen\", which demands great experience and skill, emerged around 1800. It enabled, during the 19th century, the efficient mass production of wooden figures, because it was faster and cheaper than pure woodcarving by hand. Today part of the exhibition at the Ore Mountain Toy Museum in Seiffen is dedicated to the craft of the turners - the \"Reifendreher\" - who make these toys. In addition, there are several visitor workshops in the region around Seiffen.\n\n\n\n"}
{"id": "17618723", "url": "https://en.wikipedia.org/wiki?curid=17618723", "title": "Renewable energy in developing countries", "text": "Renewable energy in developing countries\n\nRenewable energy technology has sometimes been seen as a costly luxury item by critics, and affordable only in the affluent developed world. This erroneous view has persisted for many years, but 2015 was the first year when investment in non-hydro renewables, was higher in developing countries, with $156 billion invested, mainly in China, India, and Brazil.\n\nMost developing countries have abundant renewable energy resources, including solar energy, wind power, geothermal energy, and biomass, as well as the ability to manufacture the relatively labor-intensive systems that harness these. By developing such energy sources developing countries can reduce their dependence on oil and natural gas, creating energy portfolios that are less vulnerable to price rises. In many circumstances, these investments can be less expensive than fossil fuel energy systems.\n\nIn isolated rural areas, electricity grid extensions are often not economical. Off‐grid renewable technologies provide a sustainable and cost‐effective alternative to the diesel generators that would be otherwise be deployed in such areas. Renewable technologies can also help to displace other unsustainable energy sources such as kerosene lamps and traditional biomass.\n\nKenya is the world leader in the number of solar power systems installed per capita (but not the number of watts added). More than 30,000 small solar panels, each producing 12 to 30 watts, are sold in Kenya annually. Kenya was the first African country to use geothermal power, and still has the largest installed capacity of geothermal power in Africa at 200 MW, with a potential of up to 10 GW.\n\nIn 2009, about 1.4 billion of people in the world lived without electricity, and 2.7 billion relied on wood, charcoal, and dung for home energy requirements. This lack of access to modern energy technology limits income generation, blunts efforts to escape poverty, affects people's health, and contributes to global deforestation and climate change. Small-scale renewable energy technologies and distributed energy options, such as onsite solar power and improved cookstoves, offer rural households\nmodern energy services.\n\nRenewable energy can be particularly suitable for developing countries. In rural and remote areas, transmission and distribution of energy generated from fossil fuels can be difficult and expensive. Producing renewable energy locally can offer a viable alternative.\n\nRenewable energy doesn't always have to come from a developing country. The Developing Areas Study Group session is a group of speakers from all over the energy businesses discusses the potential ideas to get developing countries the renewable energy that they need. Papers written by W. Morgan, R. Moss and P. Richard discuss the opportunities of renewable resources that lie within the developing country as well. Morgan and Richard claim firewood and agriculture could play a great role in an alternative energy solution in developing countries, while Richards claims that efficient use of agriculture could lead to renewable energy. Morgan also points out that green plants could play a great role in producing synthetic fuel alcohol, which would not only impact the developing country but the world as a whole in providing an alternative fuel source.\n\nInterest in renewable energies has increased in recent years due to environmental concern about global warming and air pollution, reduced costs of the technologies themselves, and improved efficiency and reliability. In recent years, supportive programs from governments, businesses, nonprofit organizations, and community cooperatives have expanded access to these off-grid technologies and the energy services they provide. Program planners should select “low-hanging fruit” first, aiming for maximum access to modern energy services with the least effort.\n\nCollectively, developing countries have more than half of global renewable power capacity. China and India are rapidly expanding markets for renewable energy. Brazil produces most of the world’s sugar-derived ethanol and has been adding new biomass and wind power plants. Many renewable markets are growing at rapid rates in countries such as Argentina, Costa Rica, Egypt, Indonesia, Kenya, Tanzania, Thailand, Tunisia, and Uruguay.\n\nIn isolated rural areas, electricity grid extensions are often not economical. Off‐grid renewable technologies provide a sustainable and cost‐effective alternative to the diesel generators that would be otherwise be deployed in such areas. Renewable technologies can also help to displace other unsustainable energy sources such as kerosene lamps and traditional biomass.\n\nTechnology advances are opening up a huge new market for solar power: the approximately 1.3 billion people around the world who don't have access to grid electricity. Even though they are typically very poor, these people have to pay far more for lighting than people in rich countries because they use inefficient kerosene lamps. Solar power costs half as much as lighting with kerosene. An estimated 3 million households get power from small solar PV systems. Kenya is the world leader in the number of solar power systems installed per capita. More than 30,000 very small solar panels, each producing 12 to 30 watts, are sold in Kenya annually.\n\nMicro-hydro systems configured into village-scale or county-scale mini-grids serve many areas. More than 30 million rural households get lighting and cooking from biogas made in household-scale systems. These stoves are being manufactured in factories and workshops worldwide, and more than 160 million households now use them.\n\nRenewable energy projects in many developing countries have demonstrated that renewable energy can directly contribute to poverty alleviation by providing the energy needed for creating businesses and employment. Renewable energy technologies can also make indirect contributions to alleviating poverty by providing energy for cooking, space heating, and lighting.\n\nRenewable energy can also contribute to education, by providing electricity to schools. Renewable energy for cooking and heating can reduce the time that children spend out of school collecting fuel.\n\n2.4 billion people use only traditional biomass, such as wood, residues and dung, for cooking and heating. The constant use of these types of energy sources exposes them to indoor particulate and carbon monoxide concentrations many times higher than World Health Organization (WHO) standards. \"Traditional stoves using dung and charcoal emit large amounts of carbon monoxide and other noxious gases. Women and children suffer most, because they are exposed for the longest periods of time. Acute respiratory illnesses affect as much as 6% of the world population. The WHO estimates that 2.5 million women and young children in developing countries die prematurely each year from breathing the fumes from indoor biomass stoves\".\nRenewable energy can improve this situation by reducing exposure to indoor pollutants.\n\nFurthermore, renewable can also provide energy to refrigerate medicine and sterilize medical equipment in rural areas where the access to electricity is difficult. It can also provide power to supply the fresh water and sewerage services needed to reduce the spread of infectious diseases.\n\nMore developing countries are implementing the public policies needed for the widespread development of renewable energy technologies and markets, which have traditionally been dominated by Europe, Japan, and North America. The exceptions include countries like Brazil, which has built the world’s leading biofuels industry, China, India, which are leaders in developing decentralized renewable sources such as small hydro, small wind, biogas, and solar water heating.\nHowever, policies like feed-in tariff are applied. Besides, with the Kyoto Protocol, the program called the Clean Development Mechanism (CDM) that allows for industrialized nations to invest in projects that reduce emissions in developing countries as an alternative to more expensive emission reductions in their own countries.\n\nDeveloping-country Governments need to steer resources mobilized for large-scale investments into new production sectors and new technologies. Some argue that policies should base on active industrial policies, combining large scale investments and active policy interventions. There is a need of subsidizing these type of energy services to make them affordable to the major part of the population.\n\n The Philippine government sees the growth of the renewable energy sector essential for national energy security. The Philippines' fossil fuel sector is unsustainable, being dependent on the import of nonrenewable fuel, including petroleum, but has significant potential in the renewable energy sector. Based on a report of an Australian consulting firm, International Energy Consultants, the Philippines has the highest electricity rate in Asia, followed by Japan. Transmitting power and transporting fuel throughout the Philippine archipelago is problematic due to very high cost.\n\nThe Philippines could be considered a world leader in renewable energy, with its 30 percent of its power generation being powered by the renewable energy sector. the Philippines is the world's second largest generator of geothermal energy and was the first Southeast Asian nation to invest in large-scale solar and wind technologies.\n\nPromotion and support of renewable energy in the country was intensified with the passing of the Renewable Energy Act of 2008 which made a feed-in-tariff and a renewable portfolio standard. The Philippines aims to triple renewable energy supply by 2030.\n\nRecently the government has concluded agreements with private developers for extensive projects in Oriental Mindoro with an eventual output of 48 MW, with plans for even larger development in the future.\n\nDespite government efforts, some investors have criticized the government's lack of firmness in its feed-in-tariff policy, and the solar industry accused the government for hampering its progress in the country.\n\nOn February 3, 2011, Algeria launched the National Development Programme for new and renewable energy and energy efficiency. The program, which spans the period from 2011 to 2013, aims to produce 22,000 MW of electricity from solar and wind power which 10,000 MW for export.\n\nIn Kenya, the Ministry of Energy and Petroleum is in charge of renewable energy policies. In March 2008, the country adopted the feed-in tariff policy. In January 2010, the policy was revised to urge private sectors to invest in electricity generation from renewable sources.\n\nKenya was the first African country to use geothermal power, and still has the largest installed capacity of geothermal power in Africa at 200 MW, with a potential of up to 10 GW. The only other country in Africa utilising geothermal power is Ethiopia.\n\nKenya is the world leader in the number of solar power systems installed per capita (but not the number of watts added). More than 30,000 small solar panels, each producing 12 to 30 watts, are sold in Kenya annually. For an investment of as little as $100 for the panel and wiring, the PV system can be used to charge a car battery, which can then provide power to run a fluorescent lamp or a small television for a few hours a day. More Kenyans are turning to solar power every year rather than making connections to the country’s electric grid. This is due to the high connectivity costs and the fact that there is an abundance of solar power in Kenya.\n\nRenewable energy accounted for more than 85.4% of the domestically produced electricity used in Brazil, according to preliminary data from the 2009 National Energy Balance, conducted by the Energy Research Corporation (EPE). After the oil shocks of the 1970s, Brazil started focusing on developing alternative sources of energy, mainly sugarcane ethanol. Its large sugarcane farms helped. In 1985, 91% of cars produced that year ran on sugarcane ethanol. The success of flexible-fuel vehicles, introduced in 2003, together with the mandatory E25 blend throughout the country, have allowed ethanol fuel consumption in the country to achieve a 50% market share of the gasoline-powered fleet by February 2008.\n\nRenewable Energy in Costa Rica accounts for over 90% of the total output of the nation's energy. The country is the world leader in renewable use with massive investment in windmill technologies. The government aim is to make the country the world's first carbon neutral country.\nIn March 2015 the whole country was running over 75 straight days on 100% renewable energy.\n\n"}
{"id": "14519111", "url": "https://en.wikipedia.org/wiki?curid=14519111", "title": "Rodolfo Montiel Flores", "text": "Rodolfo Montiel Flores\n\nRodolfo Montiel Flores is a campesino, a subsistence farmer, from the Guerrero village El Mameyal, Mexico.\n\nHe was awarded the Goldman Environmental Prize in 2000 for organizing campesinos to protest against rampant logging in their district.\n"}
{"id": "53425137", "url": "https://en.wikipedia.org/wiki?curid=53425137", "title": "Rønland Offshore Wind Farm", "text": "Rønland Offshore Wind Farm\n\nRønland Offshore Wind Farm is a nearshore wind farm in the westmost part of Limfjorden, Denmark. It was commissioned in 2003 and consists of four 2 MW Vestas wind turbines and four 2.3 MW ones from Bonus/Siemens.\n\n"}
{"id": "5411318", "url": "https://en.wikipedia.org/wiki?curid=5411318", "title": "Sendust", "text": "Sendust\n\nSendust is a magnetic metal powder that was invented by Hakaru Masumoto at Tohoku Imperial University in Sendai, Japan, about 1936 as an alternative to permalloy in inductor applications for telephone networks. Sendust composition is typically 85% iron, 9% silicon and 6% aluminum. The powder is sintered into cores to manufacture inductors. Sendust cores have high magnetic permeability (up to 140 000), low loss, low coercivity (5 A/m) good temperature stability and saturation flux density up to 1 T.\n\nDue to its chemical composition and crystallographic structure Sendust exhibits simultaneously zero magnetostriction and zero magnetocrystalline anisotropy constant K.\n\nSendust is harder than permalloy, and is thus useful in abrasive wear applications such as magnetic recording heads. \n\n\n"}
{"id": "8703587", "url": "https://en.wikipedia.org/wiki?curid=8703587", "title": "Silvan Dam", "text": "Silvan Dam\n\nSilvan Dam is an embankment concrete-face rock-fill currently under construction on the Batman River in the district of Silvan, Diyarbakır Province in southeastern Turkey. It is part of the Southeastern Anatolia Project and located upstream of the Batman Dam. Construction began on 26 July 2011 and is expected to be complete in 2017. The purpose of the dam is hydroelectric power production and irrigation. It is designed to irrigate an area of . The power station will have an installed capacity of 160 MW.\n\nIn 2014, the dam, as well as other in southeast Turkey such as the Ilisu Dam, became a prime target of Kurdistan Workers' Party (PKK) militants after peace talks collapsed with the government. Attacks on the dam, supporting structures and workers are part of the PKK's efforts to stop construction. Construction of the dam was suspended temporarily late in the year.\n\nThe dam is expected to be completed in 2019.\n"}
{"id": "32161246", "url": "https://en.wikipedia.org/wiki?curid=32161246", "title": "Solar cable", "text": "Solar cable\n\nA solar cable is the interconnection cable used in photovoltaic power generation. Solar cables interconnect solar panels and other electrical components of a photovoltaic system. Solar cables are designed to be UV resistant and weather resistant. They can be used within a large temperature range and are generally laid outside.\n\nOne common factor for most of the photovoltaic power systems is outdoor use, characterized by high temperatures and high UV radiation. Single-core cables with a maximum permissible DC voltage of 1.8 kV Umax. The phase to ground DC voltage rating must be Uo1.5kVDC and a temperature range from -40 °C to +90 °C ambient, 120 °C on the conductor for 25 year service life against thermal ageing. Ambient temperature and conductor temperature is derived from the Arrhenius law for ageing of polymers - ageing of polymers doubles for every 10 °C rise.\n\nDC string cables must be class II double insulated to protect against short circuits and ground faults.\n\nA three-core AC cable is used for connection to the grid if a single-phase inverter is used, and a five-core cable is used for three-phase feed-in.\n\nReferred to as the Main DC, larger power collector cables are used to interconnect from the Generator box also referred to as the DC combiner to the central inverter. IEC 62548 states that these cables must be shielded when over 50m in length.\nCentral inverters are large frequency converters and unshielded cables would cause EMC issues throughout the whole solar farm which can behave like a capacitor.\n\nThe cable's insulation must be able to withstand thermal and mechanical loads. As a consequence, plastics which have been cross-linked are increasingly used today. The insulation and jacket materials are extremely resistant to weathering, UV-radiation and abrasion . Additionally, it is salt water resistant and resistant to acids and alkaline solutions. It is suitable for fixed installation as well as for moving applications without tensile load. It is especially designed for outdoor use, which means direct sun radiation and air humidity, but due to the halogen free flame retardant cross-linked jacket material the cable can also be installed in dry and humid conditions indoors.\n\nIndividual modules are connected using cables to form the PV generator (usually employing MC4 connectors. The module cables are connected into a string (i.e. using a MC4 Y connectors) which leads into the generator junction box, and a main DC cable connects the generator junction box to the inverter. The inverter output can connect to the grid using AC cables.\n\nIn order to eliminate the risk of ground faults and short circuits, the positive and negative cables, each with double insulation, are laid separately.\n\nThe cross-section of the cables should be proportioned such that losses incurred in nominal operation do not exceed 1%. String cables usually have a cross-section of 4 to 10 mm².\n\n\n 3. EN50618 http://shop.bsigroup.com/ProductDetail/?pid=000000000030320864\n\n4. In the U.K. DC string cable installation must observe the recommendations of the IET Code of Practice. Connectors used must be from the same manufacturer. https://www.bre.co.uk/filelibrary/nsc/Documents%20Library/Presentations/The-IET-solar-PV-code-of-practice-what-this-means-for-you.pdf\n\n"}
{"id": "19550641", "url": "https://en.wikipedia.org/wiki?curid=19550641", "title": "Solar hot water in New Zealand", "text": "Solar hot water in New Zealand\n\nSolar hot water in New Zealand is increasingly used on both new and existing buildings.\n\nSolar thermal technologies had a sizable initial uptake in the pioneering days of the 1970s. By 2001 more than 40GWhr was produced from solar hot water technologies, equating to 0.1% of the total electricity consumption in New Zealand.\nIn 2006 the government announced an investment of $15.5 million over the first three and a half years of a five-year Solar Water Heating program to increase the number of solar hot water heating installations. As of 2006 there were about 35,000 solar hot water installations on domestic and commercial buildings.\n\nThere are now eleven manufacturers and importers in the industry with most of the collector system being locally made.\n\nThe main barrier for the installation of solar hot water systems is the initial capital investment. Other barriers are the conservatism of the building industry, lack of influence on increasing the sale price of houses, conflicting interest between housing investors and home-owners, and a lack of adequate information about solar hot water heating.\n\n\n"}
{"id": "5929448", "url": "https://en.wikipedia.org/wiki?curid=5929448", "title": "SuperGrid", "text": "SuperGrid\n\nIn lossless power transmission, a supergrid with hydrogen is an idea for combining very long distance electric power transmission with liquid hydrogen distribution, to achieve superconductivity in the power lines. The hydrogen is both a distributed fuel and a cryogenic coolant for the power lines, rendering them superconducting. The concept's advocates describe it as being in a \"visionary\" stage, for which no new scientific breakthrough is required but which requires major technological innovations before it could progress to a practical system. A system for the United States is projected to require \"several decades\" before it could be fully implemented.\n\nOne proposed design for a superconducting cable includes a superconducting bipolar DC line operating at ±50 kV, and 50 kA, transmitting about 2.5 GW for several hundred kilometers at zero resistance and nearly no line loss. High-voltage direct current (HVDC) lines have the capability of transmitting similar wattages, for example a 5 gigawatt HVDC system is being constructed along the southern provinces of China without the use of superconducting cables.\n\nIn the United States, a Continental SuperGrid 4,000 kilometers long might carry 40,000 to 80,000 MW in a tunnel shared with long distance high speed maglev trains, which at low pressure could allow cross continental journeys of one hour. The liquid hydrogen pipeline would both store and deliver hydrogen.\n\n1.5% of the energy transmitted on the British AC Supergrid is lost (transformer, heating and capacitive losses), of which a little under two-thirds, or 1% on the British supergrid, represents \"DC\", resistive, heating type losses. With the use of superconductors, the capacitive and transformer losses, in the unlikely event the transmission lines were still overhead, AC lines, would remain the same. Overhead lines do not lend themselves at all well physically to the incorporation of cryogenic hydrogen piping, due to the likely weight of the transmission medium and the considerable brittleness of supercooled materials. It would probably be necessary for a supercooled hydrogen-carrying transmission line to be subterranean, and this in turn means that for such a cable, if it were of any distance (e.g. over 60 km), the power would have to be converted to DC and transmitted as such, since otherwise the capacitive losses would be too high. The power electronic losses in the AC/DC converter substations to convert the AC power at either end of the cryogenic cable to and from DC, if the transmission line(s) itself were DC, would also remain exactly the same as they would have been without the use of a superconducting transmission line - but the DC type resistive losses in the transmission lines would be rendered even smaller than at present.\n\nEven before comprehensive continental and (in the case of the proposed European Super Grid) intercontinental backbones of electrical transmission may be realized, such cables could be used to efficiently interconnect regional power grids of conventional design.\n\n\n"}
{"id": "37037695", "url": "https://en.wikipedia.org/wiki?curid=37037695", "title": "Tetradecylthioacetic acid", "text": "Tetradecylthioacetic acid\n\nTetradecylthioacetic acid (TTA) is a synthetic fatty acid used as a nutritional supplement.\n\nTTA acts as a peroxisome proliferator-activated receptor alpha (PPARα) agonist and increases mitochondrial fatty acid oxidation \"in vitro\". In rodent studies, TTA has been reported to have other activities such as reducing inflammation and preventing high fat diet induced adiposity and insulin resistance.\n\nIn human clinical study, there have been mixed observations in preliminary studies. One Phase I study showed no significant changes in the blood lipids or free fatty acids and another showed that TTA attenuates dyslipidemia in patients with type 2 diabetes mellitus.\n"}
{"id": "19061350", "url": "https://en.wikipedia.org/wiki?curid=19061350", "title": "The Salisbury Museum", "text": "The Salisbury Museum\n\nThe Salisbury Museum (previously The Salisbury and South Wiltshire Museum) is a museum in Salisbury, Wiltshire, England. It houses one of the best collections relating to Stonehenge and local archaeology.\n\nThe museum is housed in The King's House, a Grade I listed building, where King James I of England was entertained in 1610 and 1613. Set in the surroundings of the Cathedral Close, the museum faces the west front of Salisbury Cathedral. Previously based at No 40-42, St Ann Street, where it had been founded in 1860 by Dr Richard Fowler, FRS, it transferred to its current location in the 1970s.\n\nThe original three-storey building with mullioned and transomed windows, ornate plaster ceilings and a fine oak-balustraded staircase, houses the main temporary exhibition gallery, with the ceramics gallery above. The arms of James I's eldest son, Henry Frederick, Prince of Wales, can be seen in a window in the Wedgwood gallery upstairs.\n\nThe Director of the museum is Adrian Green.\nSummer exhibitions since 2011 have featured artists who share a close connection with the locality.\n\n\nOn 10 September 2012, a meteorite, possibly the biggest to have ever fallen on the British Isles, went on display at the museum. For at least 80 years it sat near the front door of Lake House at Wilsford-cum-Lake near Salisbury. When the house was sold, the stone was confirmed as a meteorite by the Natural History Museum where it remained in storage for many years. Professor Colin Pillinger, known for his work on the Beagle 2 Mars spacecraft, had been studying a smaller meteorite from the Danebury Hill Fort in Hampshire and felt that there could be a connection between the two. The meteorite from Lake House was retrieved from storage and although the two objects were found to be unrelated, Professor Pillinger continued with his study of the larger meteorite.\n\nThe meteorite landed on earth some 30,000 years ago and was apparently preserved by the frozen conditions during the last ice age. In normal circumstances the meteorite would have disintegrated, but the cold and ice helped preserve it. Thousands of years later, in the Stone or Bronze Age, it is thought that the meteorite was built into a burial mound close to Lake House. The local chalk environment would again have helped to preserve it. The meteorite may have been unearthed in the 19th century by Edward Duke, a previous owner of Lake House who was an antiquarian who excavated burial mounds nearby and had his own private museum. Photographic evidence shows it on the doorstep of Lake House at the time the property was owned by the brewer Joseph Lovibond, Mayor of Salisbury in 1878–79 and 1890–91.\n\nIn November 2011 the Museum displayed the Wardour Hoard of over 100 copper alloy objects, over 2,700 years old, from the late Bronze Age and early Iron Age. It was found near Wardour by a metal detectorist, and consists of tools such as axe heads, chisels, sickles and gouges, as well as spearheads, daggers, knives, swords and scabbard fittings. It was the most important hoard to have been found in Wiltshire since the discovery of the Salisbury Hoard in the 1980s.\n\nIn around 2014, the museum acquired the Wylye Hoard.\n\nIn June 2012, the Heritage Lottery Fund (HLF) awarded Salisbury Museum a grant of £1,794,600 towards the development of a new Archaeology of Wessex gallery. The new gallery opened in the summer of 2014 and is of international importance, telling the story of Salisbury and the surrounding area from prehistoric times to the Norman Conquest, and showing why Salisbury has a unique place in history. The museum's collections include some of the most important archaeological finds in Britain, including artefacts from the Stonehenge World Heritage Site, the Pitt Rivers Wessex Collection and the Amesbury Archer.\n\nA £350,000 grant from the National Heritage Memorial Fund was awarded in August 2013, to help save the personal archive of Rex Whistler. The Salisbury Museum hopes to purchase the archive, which contains over 1,000 items and is the only substantial collection of material relating to the artist.\n\nThe Museum has an art collection of over 4,000 paintings, prints and drawings, representing local personalities, topographical scenes, special events and everyday life, or created by local artists of note. An outstanding Costume Collection includes clothes relating to the people in and around Salisbury over the past 250 years, including wedding dresses, uniforms, formal wear and lace samples produced by Downton Lace. The Museum also has an outstanding collection of ceramics. Local Verwood and Wiltshire Brown ware is represented alongside the celebrated Wedgwood, Bow and Chelsea potteries.\n\n\n"}
{"id": "40235696", "url": "https://en.wikipedia.org/wiki?curid=40235696", "title": "Watermark (film)", "text": "Watermark (film)\n\nWatermark is a 2013 Canadian documentary film by Jennifer Baichwal and Edward Burtynsky. It concerns the history and use of water. Burtynsky was previously the subject of Baichwal's 2006 documentary, \"Manufactured Landscapes\". The film features water use practices around the world, including multiple scenes in China and the United States, as well as segments shot in eight other countries. In China, the film chronicles the building of the Xiluodu Dam and flooding of its reservoir.\n\nThe film was recorded in various international locations using ultra high definition equipment, including a prototype RED Epic that was hand assembled.\n\nThe film won the Rogers Best Canadian Film Award at the 2013 Toronto Film Critics Association Awards, over \"The Dirties\" and \"Gabrielle\" and was named Best Feature Length Documentary at the 2014 Canadian Screen Awards.\n\n"}
{"id": "14709204", "url": "https://en.wikipedia.org/wiki?curid=14709204", "title": "William States Lee III Nuclear Generating Station", "text": "William States Lee III Nuclear Generating Station\n\nThe William States Lee III Nuclear Station was a planned two-unit nuclear power plant in Cherokee County, South Carolina. Duke Energy filed the Combined Construction and Operating License (COL) application for the plant on December 13, 2007 to the NRC. On December 19, 2016, the NRC issued two Combined Licenses authorizing Duke to build and operate two AP1000 reactors at the site.\n\nIn August 2017, Duke decided to seek permission from the North Carolina Utility Commission to cancel the project due to the bankruptcy of Westinghouse and \"other market activity\", although they will retain the option of restarting the project at some point in the future if circumstances change.\n\nThe plant was named for William States Lee III (1929–1996), former chief executive officer (CEO) of Duke Energy (1982–94). \nThis site would have been be adjacent to the Cherokee Nuclear Power Plant site, which was also never completed and abandoned in the early 1980s, then later used by James Cameron as a film set for the 1989 movie \"The Abyss\".\n\nIn December 2007, Duke Power announced that it would spend $160 million in 2008 on the plant and that total costs could range 5–6 billion dollars. In November 2008, Duke estimated the overnight cost of the plant at $11 billion.\n\nDuke submitted the Lee application to the NRC on Dec. 12, 2007. The NRC's Advisory Committee on Reactor Safeguards independently reviewed aspects of the application that concern safety, as well as the staff's final safety evaluation report. The committee provided the results of its review to the Commission on Dec. 14, 2015. The NRC completed its environmental review and issued the final impact statement for the proposed William States Lee reactors in December 2013.\n\nThe Commission authorized the agency's Office of New Reactors to issue the licenses, having found the staff's review of Duke's application adequate to make the necessary regulatory safety and environmental findings. The licenses were issued Dec. 19. The licenses contain conditions, including:\n\nThe William States Lee III Nuclear Generating Station was planned to consist of two AP1000 reactors.\n\n"}
