{"id": "42163402", "url": "https://en.wikipedia.org/wiki?curid=42163402", "title": "Airsynergy", "text": "Airsynergy\n\nAirsynergy is a privately owned renewable energy product development and licensing company, which was founded in 2008 by Jim Smyth, Andrew Smyth, Gerard Smyth, Peter Smyth, David Smyth and Adrian Kelly. Airsynergy produces cleantech products which generate an affordable, secure and reliable power supply. The company is based in Granard, county Longford, Ireland, with other offices based in Dublin, Ireland.\n\nTotal Energy Solution (TES)\n\nAirsynergy’s TES is a small-scale wind turbine which has been built to maximise power production. The TES is a two-in-one turbine which contains not only a standard rotor and blades, but also a multi-bladed duct augmenter. This augmenter concentrates and amplifies air from the inside out, increasing the speed of the wind flowing past the two-bladed rotor system. This means that the system can cut in at significantly lower wind speeds compared to conventional wind turbines, and provide double the power production (AEP) of similarly rated turbines.\n\nThe TES has the ability to generate €4,000 plus worth of electricity per year, and offers fixed power prices for up to 30 years.\n\nRenewable Power Unit (RPU)\n\nAirsynergy’s RPU is a hybrid wind and solar powered streetlight which contains both a solar panel and a small, duct augmented wind turbine, which together generate enough energy to provide street lighting. The duct augmented turbine is able to accelerate the surrounding air, increasing the total blade revolutions per minute.\n\nThe RPU is the most powerful hybrid solution on the market – as it provides approximately 1200kWh annual energy production at 5 m/s. This solution also contains a turbine which can ‘cut in’ sooner and increase the power output when there are low wind speeds – a critical feature which ensures reliable and powerful lighting. The energy produced from the RPU can also be used to provide power for CCTV security cameras, Wi-Fi at bus stops, phone-charging and other micro-power needs.\n\nonesynergy, founded in 2008, is the sister company of Airsynergy, and it is a company which invents, designs and builds Heating, Ventilation and Air Conditioning products (HVAC). These HVAC products are ideal components for a variety of commercial, industrial and agricultural buildings as well as residential properties.\n\nPAVEL\n\nPAVEL is onesynergy’s aerodynamic air extraction unit which halves the total energy consumption of a building, cutting both carbon emissions and energy bills. This extraction unit contains patented technology which means that it can achieve optimum air flow efficiency via the gradual deceleration of air and its gentle diffusion into the air at low velocity.\n\nThe PAVEL has already received third party verification for its performance. Moore Environmental, an independent commissioning and validation engineering company, have certified the PAVEL’s volume flow rate against power. The PAVEL unit offers approximately 55 per cent power savings in comparison to a standard extraction unit or exhaust cowl.\n\nAris Renewables Energy, LLC\n\nIn 2013, Airsynergy entered into an exclusive license agreement in the United States with New York-based Aris Renewables Energy, LLC. Airsynergy has granted Aris a royalty bearing patent license (up to 100 kW) to develop, manufacture and sell wind turbines and wind powered street-lights utilising Airsynergy’s patented enhancement technologies. The license covers the United States and the Caribbean. Aris is also acting as an agent for Airsynergy to secure other licensees in South America.\n\nFairhaven H&V Services\n\nFairhaven H&V Services are a stockist and distributor of ventilation and air movement products, supplying to the construction and industrial trade sectors.[2]\n\nWoodleigh Ventilation\n\nWoodleigh Ventilation is a supplier of ventilation, air conditioning and heating products to the HVAC industry.[3]\n\n"}
{"id": "44366653", "url": "https://en.wikipedia.org/wiki?curid=44366653", "title": "Ariston Thermo", "text": "Ariston Thermo\n\nAriston Thermo SpA is an Italian corporation that produces heating systems and related products, marketed mainly under the Ariston, Chaffoteaux, Elco, Racold, Atag, NTI, HTP, Cuenod, Ecoflam and Thermowatt brands.\n\nIn 1930, Aristide Merloni founded Industrie Merloni in the Marches and began producing scales. The production of electric water heaters dates back to 1960, with the appearance of the Ariston brand, which would propel the Group to leader status in this sector in Italy with the dawn of the 1970s.\n\nFollowing the success of Ariston heaters, in the 1980s the company decided to enter the space heating sector and started manufacturing boilers.\n\nDuring the 1990s the company opened its first branches in Eastern Europe and Asia. In the same years Ariston Thermo acquired Racold, India's largest water heaters' manufacturer, and opened its first wholly owned plant in China.\n\nThe early 21st century saw the acquisition in 2001 of several historical companies and brands in the heating and burner sectors, namely: Chaffoteaux, Elco, Cuenod and Rendamax.\n\nOver the two-year period 2004–2005, new plants were inaugurated in Hanoi and St Petersburg, while the acquisition of Ecoflam was completed, the latter among Italy's leading companies for heating systems; in 2008, after the acquisition of Termogamma SA, specialised in the production of heat pumps, the company opened its European centre of excellence for solar heating systems in Italy, in Serra de' Conti.\nIn 2009, the company (until then part of MTS Group) changed its name to Ariston Thermo.\nAriston Thermo acquired in 2011 Cipag SA and Domotec AG, leaders in Switzerland for the production, distribution and maintenance of water heating systems.\n\n2013 saw the acquisition of DhE, an Italian company specialised in heating elements for commercial and industrial applications, and the set up of a joint venture for the production and commercialisation in Uzbekistan of domestic heating systems.\n\nIn 2014, the company entered the South African market directly through the acquisition of Heat Tech Geysers, the country's second player for water heaters, and inaugurated an electric water heater factory in Vietnam.\nIn the same year it also strengthened its presence in mature markets with the acquisition of ATAG Heating, a Dutch high-end brand in the heating industry.\n\nIn April 2015, signed the acquisition of Gastech-Energi A/S, a leading company in the field of domestic and industrial heating in Denmark, announced during the inauguration in Russia of a new logistics center of approximately 10,000 m² in the production site of Vsevolozhsk, nearby St. Petersburg.\n\nIn September 2016, Ariston Thermo announced the acquisition of the majority stake in NY Thermal Inc., a company based in Saint John (Canada), operating in the domestic and commercial NTI branded condensing boilers in Canada and the United States.\n\nDuring 2017 the Group completed two further acquisitions, one in the United States of America, where in August Ariston Thermo acquired HTP, a leading company in this market for thermal comfort solutions, and the other in Israel in October acquiring ATMOR Group, a leading company in the technology of electric instantaneous water heaters.\n\nAlso in 2017 two Ariston products - the instant electric water heater Aures Luxury Round and the brand new Lydos Hybrid, the first Class A hybrid electric water heater - were won the GOOD DESIGN ™ awards in the \"Bath & Accessories\" and \"Building materials\" categories”. The 2017 Ariston’s victories follow the one archived in 2016 with the state-of-the-art gas boiler Alteas, awarded due to its innovative silhouette and its fine materials, impeccable details and user-friendliness\n\nIn 2016, Ariston Thermo sold 7 million products in over 150 countries worldwide, amounting to a turnover of 1.43 billion Euro.\n\nIt employs 6,900 people working in 59 companies, with 8 representative offices in 36 countries.\n\n\n"}
{"id": "809005", "url": "https://en.wikipedia.org/wiki?curid=809005", "title": "Balloon (aeronautics)", "text": "Balloon (aeronautics)\n\nIn aeronautics, a balloon is an unpowered aerostat, which remains aloft or floats due to its buoyancy. A balloon may be free, moving with the wind, or tethered to a fixed point. It is distinct from an airship, which is a powered aerostat that can propel itself through the air in a controlled manner.\n\nMany balloons have a basket, gondola, or capsule suspended beneath the main envelope for carrying people or equipment (including cameras and telescopes, and flight-control mechanisms).\n\nA balloon is conceptually the simplest of all flying machines. The balloon is a fabric envelope filled with a gas that is lighter than the surrounding atmosphere. As the entire balloon is less dense than its surroundings, it rises, taking along with it a basket, attached underneath, which carries passengers or payload. Although a balloon has no propulsion system, a degree of directional control is possible through making the balloon rise or sink in altitude to find favorable wind directions.\n\nThere are three main types of balloon:\n\nBoth the hot air, or Montgolfière, balloon and the gas balloon are still in common use. Montgolfière balloons are relatively inexpensive, as they do not require high-grade materials for their envelopes, and they are popular for balloonist sport activity.\n\nThe first balloon which carried passengers used hot air to obtain buoyancy and was built by the brothers Josef and Etienne Montgolfier in Annonay, France in 1783: the first passenger flight was 19 September 1783, carrying a sheep, a duck, and a rooster.\n\nThe first tethered manned balloon flight was by a larger Montgolfier balloon, probably on 15 October 1783. The first free balloon flight was by the same Montgolfier balloon on 21 November 1783.\n\nWhen heated, air expands, so a given volume of space contains less air. This makes it lighter and, if its lifting power is greater than the weight of the balloon containing it, it will lift the balloon upwards. A hot air balloon can only stay up while it has fuel for its burner, to keep the air hot enough.\n\nThe Montgolfiers' early hot air balloons used a solid-fuel brazier which proved less practical than the hydrogen balloons that had followed almost immediately, and hot air ballooning soon died out.\n\nIn the 1950s, the convenience and low cost of bottled gas burners led to a revival of hot air ballooning for sport and leisure.\n\nThe height or altitude of a hot air balloon is controlled by turning the burner up or down as needed, unlike a gas balloon where ballast weights are often carried so that they can be dropped if the balloon gets too low, and in order to land some lifting gas must be vented through a valve.\n\nA man-carrying balloon using the light gas hydrogen for buoyancy was made by Professor Jacques Charles and flown less than a month after the Montgolfier flight, on 1 December 1783. Gas balloons have greater lift for a given volume, so they do not need to be so large, and they can also stay up for much longer than hot air, so gas balloons dominated ballooning for the next 200 years. In the 19th century, it was common to use town gas to fill balloons; this was not as light as pure hydrogen gas, having about half the lifting power, but it was much cheaper and readily available.\nLight gas balloons are predominant in scientific applications, as they are capable of reaching much higher altitudes for much longer periods of time. They are generally filled with helium. Although hydrogen has more lifting power, it is explosive in an atmosphere rich in oxygen. With a few exceptions, scientific balloon missions are unmanned.\n\nThere are two types of light-gas balloons: zero-pressure and superpressure. Zero-pressure balloons are the traditional form of light-gas balloon. They are partially inflated with the light gas before launch, with the gas pressure the same both inside and outside the balloon. As the zero-pressure balloon rises, its gas expands to maintain the zero pressure difference, and the balloon's envelope swells.\n\nAt night, the gas in a zero-pressure balloon cools and contracts, causing the balloon to sink. A zero-pressure balloon can only maintain altitude by releasing gas when it goes too high, where the expanding gas can threaten to rupture the envelope, or releasing ballast when it sinks too low. Loss of gas and ballast limits the endurance of zero-pressure balloons to a few days.\n\nA superpressure balloon, in contrast, has a tough and inelastic envelope that is filled with light gas to pressure higher than that of the external atmosphere, and then sealed. The superpressure balloon cannot change size greatly, and so maintains a generally constant volume. The superpressure balloon maintains an altitude of constant density in the atmosphere, and can maintain flight until gas leakage gradually brings it down.\n\nSuperpressure balloons offer flight endurance of months, rather than days. In fact, in typical operation an Earth-based superpressure balloon mission is ended by a command from ground control to open the envelope, rather than by natural leakage of gas.\n\nHigh-altitude balloons are used as high flying vessels to carry scientific instruments (like weather balloons), or reach near-space altitudes to take footage or photos of the earth. These balloons can fly over 100,000 feet (30.5 km) into the air, and are designed to burst at a set altitude where the parachute will deploy to safely carry the payload back to earth.\n\nCluster ballooning uses many smaller gas-filled balloons for flight (see An Introduction to Cluster Ballooning).\n\nEarly hot air balloons could not stay up for very long because they used a lot of fuel, while early hydrogen balloons were difficult to take higher or lower as desired because the aeronaut could only vent the gas or drop off ballast a limited number of times. Pilâtre de Rozier realised that for a long-distance flight such as crossing the English Channel, the aeronaut would need to make use of the differing wind directions at different altitudes. It would be essential therefore to have good control of altitude while still able to stay up for a long time. He developed a combination balloon having two gas bags, the Rozier balloon. The upper one held hydrogen and provided most of the steady lift. The lower one held hot air and could be quickly heated or cooled to provide the varying lift for good altitude control.\n\nIn 1785 Pilâtre de Rozier took off in an attempt to fly across the Channel, but shortly into the flight the hydrogen gas bag caught fire and de Rozier did not survive the ensuing accident. This earned de Rozier the title \"The First to Fly and the First to Die\".\n\nIt wasn't until the 1980s that technology was developed to allow safe operation of the Rozier type, for example by using non-flammable helium as the lifting gas, and several designs have successfully undertaken long-distance flights.\n\nAs an alternative to free flight, a balloon may be tethered to allow reliable take off and landing at the same location. Some of the earliest balloon flights were tethered for safety, and since then balloons have been tethered for many purposes, including military observation and aerial barrage, meteorological and commercial uses.\n\nThe natural spherical shape of a balloon is unstable in high winds. Tethered balloons for use in windy conditions are often stabilised by aerodynamic shaping and connecting to the tether by a halter arrangement. These are called kite balloons.\n\nA kite balloon is distinct from a kytoon, which obtains a portion of its lift aerodynamically.\n\nUnmanned hot air balloons are popular in Chinese history. Zhuge Liang of the Shu Han kingdom, in the Three Kingdoms era (220–280 AD) used airborne lanterns for military signaling. These lanterns are known as Kongming lanterns (孔明灯). Mongolian army studied Kongming lanterns from Chinese and used it in Battle of Legnica during Mongol invasion of Poland. This is the first time balloon was known by western world.\nIn 1709 the Portuguese cleric Bartolomeu de Gusmão made a balloon filled with heated air rise inside a room in Lisbon. He is also claimed to have built a balloon named \"\" (\"Big bird\") and attempted to lift himself from Saint George Castle in Lisbon, landing about one kilometre away. This claim is not generally recognized by aviation historians outside the Portuguese speaking community, in particular the FAI.\n\nFollowing Henry Cavendish's 1766 work on hydrogen, Joseph Black proposed that a balloon filled with hydrogen would be able to rise in the air.\n\nThe first recorded manned flight was made in a hot air balloon built by the Montgolfier brothers on 21 November 1783. The flight started in Paris and reached a height of 500 feet or so. The pilots, Jean-François Pilâtre de Rozier and François Laurent d'Arlandes, covered about 5½ miles in 25 minutes.\n\nOn 1 December 1783, Professor Jacques Charles and the Robert brothers made the first gas balloon flight, also from Paris. Their hydrogen-filled balloon flew to almost 2,000 feet (600 m), stayed aloft for over 2 hours and covered a distance of 27 miles (43 km), landing in the small town of Nesles-la-Vallée.\n\nThe first Italian balloon ascent was made by Count Paolo Andreani and two other passengers in a balloon designed and constructed by the three Gerli brothers, on 25 February 1784. A public demonstration occurred in Brugherio a few days later, on 13 March 1784, when the vehicle flew to a height of 1,537 metres (5,043 ft) and a distance of 8 kilometres (5.0 mi). On 28 March Andreani received a standing ovation at La Scala, and later a medal from Joseph II, Holy Roman Emperor.\n\nDe Rozier, together with Joseph Proust, took part in a further flight on 23 June 1784, in a modified version of the Montgolfiers' first balloon christened La Marie-Antoinette after the Queen. They took off in front of the King of France and King Gustav III of Sweden. The balloon flew north at an altitude of approximately 3,000 metres, above the clouds, travelling 52 km in 45 minutes before cold and turbulence forced them to descend past Luzarches, between Coye et Orry-la-Ville, near the Chantilly forest.\n\nThe first balloon ascent in Britain was made by James Tytler on 25 August 1784 at Edinburgh, Scotland, in a hot air balloon.\n\nThe first aircraft disaster occurred in May 1785 when the town of Tullamore, County Offaly, Ireland was seriously damaged when the crash of a balloon resulted in a fire that burned down about 100 houses, making the town home to the world's first aviation disaster. To this day, the town shield depicts a phoenix rising from the ashes.\n\nJean-Pierre Blanchard went on to make the first manned flight of a balloon in America on 9 January 1793, after touring Europe to set the record for the first balloon flight in countries including the Austrian Netherlands, Germany, the Netherlands and Poland. His hydrogen filled balloon took off from a prison yard in Philadelphia, Pennsylvania. The flight reached 5,800 feet (1,770 m) and landed in Gloucester County, New Jersey. President George Washington was among the guests observing the takeoff.\n\nOn 29 September 1804, Abraham Hopman became the first Dutchman to make a successful balloon flight in the Netherlands.\n\nGas balloons became the most common type from the 1790s until the 1960s. The French military observation balloon \"L'Intrépide\" of 1795 is the oldest preserved aircraft in Europe; it is on display in the \"Heeresgeschichtliches Museum\" in Vienna. Jules Verne wrote a short, non-fiction story, published in 1852, about being stranded aboard a hydrogen balloon.\n\nThe earliest successful balloon flight recorded in Australia was by William Dean in 1858. His balloon was gas-filled and travelled 30 km with two people aboard. On 5 January, 1870, T. Gale, made an ascent from the Domain in Sydney. His balloon was 17 metres in length by 31 metres in circumference and his ascent, with him seated on the netting, took him about a mile before he landed in Glebe.\n\nHenri Giffard also developed a tethered balloon for passengers in 1878 in the Tuileries Garden in Paris. The first tethered balloon in modern times was made in France at Chantilly Castle in 1994 by Aerophile SA.\n\nThe first military use of a balloon was at the Battle of Fleurus in 1794, when \"L'Entreprenant\" was used by the French Aerostatic Corps to watch the movements of the enemy. On 2 April 1794, an aeronauts corps was created in the French army; however, given the logistical problems linked with the production of hydrogen on the battlefield (it required constructing ovens and pouring water on white-hot iron), the corps was disbanded in 1799.\n\nThe first major use of balloons in the military occurred during the American Civil War with the Union Army Balloon Corps established in 1861.\n\nDuring the Paraguayan War (1864–70), observation balloons were used by the Brazilian Army.\n\nBalloons were used by the British Royal Engineers in 1885 for reconnaissance and observation purposes during the Bechuanaland Expedition and the Sudan Expedition. Although experiments in Britain had been conducted as early as 1863, a School of Ballooning was not established at Chatham, Medway, Kent until 1888. During the Anglo-Boer War (1899–1902), use was made of observation balloons. A balloon was kept inflated for 22 days and marched 165 miles into the Transvaal with the British forces.\n\nHydrogen-filled balloons were widely used during World War I (1914–1918) to detect enemy troop movements and to direct artillery fire. Observers phoned their reports to officers on the ground who then relayed the information to those who needed it. Balloons were frequently targets of opposing aircraft. Planes assigned to attack enemy balloons were often equipped with incendiary bullets, for the purpose of igniting the hydrogen.\n\nThe Aeronaut Badge was established by the United States Army in World War I to denote service members who were qualified balloon pilots. Observation balloons were retained well after the Great War, being used in the Russo-Finnish Wars, the Winter War of 1939–40, and the Continuation War of 1941–45.\n\nDuring World War II the Japanese launched thousands of hydrogen \"fire balloons\" against the United States and Canada. In Operation Outward the British used balloons to carry incendiaries to Nazi Germany. During 2018, Incendiary balloons and kites were launched from Gaza at Israel, burning some 12,000 dunams (3,000 acres) in Israel.\n\nLarge helium balloons are used by the South Korean government and private activists advocating freedom in North Korea. They float hundreds of kilometers across the border carrying news from the outside world, illegal radios, foreign currency and gifts of personal hygiene supplies. A North Korean military official has described it as \"psychological warfare\" and threatened to attack South Korea if their release continued.\n\nEd Yost redesigned the hot air balloon in the late 1950s using rip-stop nylon fabrics and high-powered propane burners to create the modern hot air balloon. His first flight of such a balloon, lasting 25 minutes and covering 3 miles (5 km), occurred on 22 October 1960 in Bruning, Nebraska. Yost's improved design for hot air balloons triggered the modern sport balloon movement. Today, hot air balloons are much more common than gas balloons.\n\nIn the late 1970s the British hot air balloonist Julian Nott constructed a hot air balloon using technologies he believed would have been available to the Nazca culture of Peru some 1500 to 2000 years earlier, and demonstrated that it could fly. and again in 2003, Nott has speculated that the Nazca might have used it as a tool for designing the famous Nazca ground figures and lines. Nott also pioneered the use of hybrid energy, where solar power is a significant heat source, and in 1981 he crossed the English Channel.\n\nIn 2012, the Red Bull Stratos balloon took Felix Baumgartner to 128,100 ft. for a freefall jump from the stratosphere.\n\nTethered gas balloons have been installed as amusement rides in Paris since 1999, in Berlin since 2000, in Disneyland Paris since 2005, in the San Diego Wild Animal Park since 2005, in Walt Disney World in Orlando since 2009, and the DHL Balloon in Singapore in 2006. Modern tethered gas balloons are made by Aerophile SAS.\n\nHot air balloons used in sport flying are sometimes made in special designs to advertise a company or product, such as the Chubb fire extinguisher illustrated.\n\nA balloon in space uses internal gas pressure only to maintain its shape.\n\nThe Echo satellite was a balloon satellite launched into Earth orbit in 1960 and used for passive relay of radio communication. PAGEOS was launched in 1966 for worldwide satellite triangulation, allowing for greater precision in the calculation of different locations on the planet's surface.\n\nIn 1984, the Soviet space probes Vega 1 and Vega 2 released two balloons with scientific experiments in the atmosphere of Venus. They transmitted signals for two days to Earth.\n\nOn 19 October 1910, Alan Hawley and Augustus Post landed in the wilderness of Quebec, Canada after traveling for 48 hours and 1887.6 kilometers (1,173 mi) from St. Louis during the Gordon Bennett International Balloon Race, setting a distance record that held for more than 20 years. It took the men a week to hike out of the woods, during which time search parties had been mobilized and many had taken the pair for dead.\n\nOn 13 December 1913 through 17 December 1913 Hugo Kaulen stayed aloft for 87 hours. His record lasted until 1976.\nOn 27 May 1931, Auguste Piccard and Paul Kipfer became the first to reach the stratosphere in a balloon.\n\nBen Abruzzo was the first man to cross the Pacific Ocean in a hot air balloon.\n\nOn 31 August 1933, Alexander Dahl took the first picture of the Earth's curvature in an open hydrogen gas balloon.\n\nThe helium-filled \"Explorer II\" balloon, piloted by US Army Air Corps officers Capt. Orvil A. Anderson, Maj. William E. Kepner and Capt. Albert W. Stevens, reached a new record height of 22,066 m (72,395 ft) on 11 November 1935. This followed the same crew's previous near-fatal plunge in July 1934 in a predecessor craft, \"Explorer\", after its canopy ruptured just 190 m (624 ft) short (it transpired) of the then-current altitude record of 22,000 m (72,178 ft) set by the Soviet balloon \"Osoaviakhim-1\".\n\nIn 1976, Ed Yost set 13 aviation world’s records for distance traveled and amount of time aloft in his attempt to cross the Atlantic Ocean —solo— by balloon (3.938 km, 107:37 h).\n\nThe current absolute altitude record for manned balloon flight was set at 34,668 m (113,739 ft) on 4 May 1961 by Malcolm Ross and Victor Prather in the Strato-Lab V balloon payload launched from the deck of the USS \"Antietam\" in the Gulf of Mexico.\n\nThe previous record altitude for a manned balloon was set at 38,960.5 m (127,823 ft) by Felix Baumgartner in the Red Bull Stratos balloon launched from Roswell, New Mexico on Sunday, 14 Oct 2012.\n\nThe current record altitude for a manned balloon was set at 41,419.0 m (135,889.108 ft) by Alan Eustace on 24 October 2014.\n\nOn 1 March 1999 Bertrand Piccard and Brian Jones set off in the balloon Breitling Orbiter 3 from Château d'Oex in Switzerland on the first non-stop balloon circumnavigation around the globe. They landed in Egypt after a 40,814 km (25,361 mi) flight lasting 19 days, 21 hours and 55 minutes.\nThe altitude record for an unmanned balloon is 53.0 kilometres (173,882 ft), reached with a volume of 60,000 cubic metres. The balloon was launched by JAXA on 25 May 2002 from Iwate Prefecture, Japan. This is the greatest height ever obtained by an atmospheric vehicle. Only rockets, rocket planes, and ballistic projectiles have flown higher.\n\nIn 2015, the two pilots Leonid Tiukhtyaev and Troy Bradley arrived safely in Baja California, Mexico after a journey of 10,711 km. The two men, originally from Russia and the United States of America respectively, started in Japan and flew with a helium balloon over the Pacific. In 160 hours, the balloon named \"Two Eagles\" arrived in Mexico, which is new distance and duration records for straight gas balloons.\n\n\n\n"}
{"id": "3395805", "url": "https://en.wikipedia.org/wiki?curid=3395805", "title": "Blackmail (1939 film)", "text": "Blackmail (1939 film)\n\nBlackmail is a 1939 crime drama film starring Edward G. Robinson and was directed by H. C. Potter.\n\nJohn Ingram is a very successful oil-field firefighter and a family man. All is going so well, he's even bought his own oil well in hope of striking it rich. His greatest fears are realized, however, when a man, William Ramey, from his secret past sees Ingram in a newsreel and shows up looking for a job.\n\nRamey attempts to blackmail Ingram, who had run from a chain gang years ago and started a new life under an assumed name. After a shady deal is made, Ingram is tricked and Ramey turns him into authorities, who return him to a chain gang. Ramey subsequently becomes a very rich man.\n\nWhen Ingram finds out about the success of the man who betrayed him, he plans a daring escape in an attempt to return home and get revenge.\n\n"}
{"id": "32812103", "url": "https://en.wikipedia.org/wiki?curid=32812103", "title": "Bratsberg Hydroelectric Power Station", "text": "Bratsberg Hydroelectric Power Station\n\nBratsberg Power Station (\"Bratsberg kraftverk\") is a hydroelectric power station located in Trondheim in Sør-Trøndelag County, Norway, owned by Statkraft. It operates at an installed capacity of , with an average annual production of 650 GWh. The power plant is fed from the Selbusjøen reservoir, connected with a 12 km long tunnel, offering a gross head of 147 m. The power plant has two Francis turbines.\n"}
{"id": "25508508", "url": "https://en.wikipedia.org/wiki?curid=25508508", "title": "Building Safer Communities. Risk Governance, Spatial Planning and Responses to Natural Hazards", "text": "Building Safer Communities. Risk Governance, Spatial Planning and Responses to Natural Hazards\n\nBuilding Safer Communities. Risk Governance, Spatial Planning and Responses to Natural Hazards is a 2009 book edited by Urbano Fra Paleo, published by IOS Press.\n\nThis textbook examines the central principles of enhanced risk governance, whose implementation might help to mitigate the increasing losses caused by natural hazards. It promotes the adoption of proactive, preventive approaches in public policies, particularly through land use planning, by influencing on the occupation of hazard-prone areas.\nIt serves both as a comprehensive introduction to the formulation and implementation at the strategic level of policies that address risk, and as an advancement in the integration of current practices, including emergency management, environmental management, community development and spatial planning. \nThe authors study and construe solutions that review integrated strategies of the various levels of government considering:\n\nUrbano Fra Paleo is a geographer, and an Associate Professor of Human Geography at the University of Santiago de Compostela, Spain.\n\n"}
{"id": "15007761", "url": "https://en.wikipedia.org/wiki?curid=15007761", "title": "Canna Agriculture Group", "text": "Canna Agriculture Group\n\nThe Canna Agriculture Group contains all of the varieties of Canna used in agriculture. Canna achira and Canna edulis (Latin: eatable) are generic terms used in South America to describe the cannas that have been selectively bred for agricultural purposes, normally derived from C. \"discolor\". It is grown especially for its edible rootstock from which starch is obtained, but the leaves and young seed are also edible, and achira was once a staple foodcrop in Peru and Ecuador.\n\nThere are some named agricultural varieties, and published comparative studies have involved:\n\nMany more traditional varieties exist worldwide, they have all involved human selection and so are classified as agricultural cultivars. Folk lore states that \"Canna edulis\" Ker-Gawl. is the variety grown for food in South America, but there is no scientific evidence to substantiate the name as a separate species. It is probable that this is simply a synonym of C. \"discolor\", which is grown for agricultural purposes throughout South America and Asia. \n\nIn the Andes, the rhizome can be harvested within 6 months from planting out and the yields range from 13 - 85 tonnes per hectare, with 22 - 50 tonnes being average, though larger yields are obtained after 8 – 10 months. In Queensland, Australia they are able to obtain a yield of 5-10 tons of C. 'Queensland Arrowroot' tubers per acre.\n\nMost cultivated forms do not produce fertile seed. There are also sterile triploid forms, these contain a significantly higher proportion of starch, though their cropping potential is not known.\n\nThe rhizomes and leaves are good fodder for cattle and pigs and it is grown for this purpose in Tropical Africa and Hawaii, where it is harvested 4–8 months after planting. The foliage of Agricultural Canna is also used for its silage making properties, which are superior to those of corn.\n\nCanna is still grown for human consumption in the Andes and also in Vietnam and southern China, where the starch is used to make cellophane noodles.\n\nRootstock - actually a rhizome, this can be eaten either raw or cooked. It is the source of \"canna starch\" which is used as a substitute for arrowroot. The starch is obtained by rasping the rhizome to a pulp, then washing and straining to get rid of the fibres. This starch is very digestible. The very young rhizomes can also be eaten cooked, they are sweet but fibrous. The rhizome can be very large, sometimes as long as a person's forearm. In Peru the rhizomes are baked for up to 12 hours by which time they become a white, translucent, fibrous and somewhat mucilaginous mass with a sweetish taste. The starch is in very large grains, about three times the size of potato starch grains, and can be seen with the naked eye. This starch is easily separated from the fibre of the rhizome.\n\nYoung shoots - these can be cooked and eaten as a green vegetable and are quite nutritious, containing at least 10% protein.\n\n\n\n"}
{"id": "9176384", "url": "https://en.wikipedia.org/wiki?curid=9176384", "title": "Cathode bias", "text": "Cathode bias\n\nIn electronics, cathode bias (also known as self-bias, or automatic bias) is a technique used with vacuum tubes to make the direct current (dc) cathode voltage positive in relation to the negative side of the plate voltage supply by an amount equal to the magnitude of the desired grid bias voltage.\n\nThe most common cathode bias implementation passes the cathode current through a resistor connected between the cathode and the negative side of the plate voltage supply. The cathode current through this resistor causes the desired voltage drop across the resistor and places the cathode at a positive dc voltage equal in magnitude to the negative grid bias voltage required. The grid circuit puts the grid at zero volts dc relative to negative side of the plate voltage supply, causing the grid voltage to be negative with respect to the cathode by the required amount. Directly heated cathode circuits connect the cathode bias resistor to the center tap of the filament transformer secondary or to the center tap of a low resistance connected across the filament.\n\nTo find the correct resistor value, first the tube operating point is determined. The plate current, the grid voltage relative to the cathode and the screen current (if applicable) are noted for the operating point. The cathode bias resistor value is found by dividing the absolute value of the operating point grid voltage by the operating point cathode current (plate current plus screen current). The power dissipated by the cathode bias resistor is the product of the square of the cathode current and the resistance in ohms.\n\nAny signal frequency effect of the cathode resistor may be minimized by providing a suitable capacitor in parallel with the resistor. In general, the capacitor value is selected such that the time constant of the capacitor and bias resistor is an order of magnitude greater than the period of the lowest frequency to be amplified. The capacitor makes the gain of the stage, at the signal frequencies, essentially the same as if the cathode was connected directly to the circuit return.\n\nIn some designs, the degenerative (negative) feedback caused by the cathode resistor may be desirable. In this case, all or a portion of the cathode resistance is not bypassed by a capacitor.\n\nIn class A push-pull circuits a pair of tubes driven by identical signals 180 degrees out of phase may share a common unbypassed cathode resistor. Degeneration will not occur because, if the grid voltage versus plate current characteristics of the two tubes are matched, the current through the cathode resistor will not vary during the 360 degrees of the signal cycle.\n\n\nCathode bias, as a solution, is often the alternative to using fixed bias. Robert Tomer, in his 1960 book about vacuum tubes, which mainly concerned itself with strategies for improving tube lifespan, condemned fixed bias designs in favor of cathode bias. He said that fixed bias, unlike cathode bias, does not provide a margin for error that protects the system from inevitable differences between vacuum tubes nor does it protect against run-away conditions caused by tube or circuit malfunctions. He also asserted that most tube specialists consider fixed bias operation to be dangerous. Despite this stance, fixed bias is commonly used in tube amplifiers today. Tomer identified the trend toward fixed bias designs in 1960 but was not certain about the reasons for it.\n\n\n"}
{"id": "36680", "url": "https://en.wikipedia.org/wiki?curid=36680", "title": "Combinatorial chemistry", "text": "Combinatorial chemistry\n\nCombinatorial chemistry comprises chemical synthetic methods that make it possible to prepare a large number (tens to thousands or even millions) of compounds in a single process. These compound libraries can be made as mixtures, sets of individual compounds or chemical structures generated by computer software. Combinatorial chemistry can be used for the synthesis of small molecules and for peptides.\n\nStrategies that allow identification of useful components of the libraries are also part of combinatorial chemistry. The methods used in combinatorial chemistry are applied outside chemistry, too.\n\nSynthesis of molecules in a combinatorial fashion can quickly lead to large numbers of molecules. For example, a molecule with three points of diversity (\"R\", \"R\", and \"R\") can generate formula_1 possible structures, where formula_2, formula_3, and formula_4 are the numbers of different substituents utilized. \n\nThe basic principle of combinatorial chemistry is to prepare libraries of very large number of compounds then identify the useful components of the libraries.\n\nAlthough combinatorial chemistry has only really been taken up by industry since the 1990s, its roots can be seen as far back as the 1960s when a researcher at Rockefeller University, Bruce Merrifield, started investigating the solid-phase synthesis of peptides.\n\nIn its modern form, combinatorial chemistry has probably had its biggest impact in the pharmaceutical industry. Researchers attempting to optimize the activity profile of a compound create a 'library' of many different but related compounds. Advances in robotics have led to an industrial approach to combinatorial synthesis, enabling companies to routinely produce over 100,000 new and unique compounds per year.\n\nIn order to handle the vast number of structural possibilities, researchers often create a 'virtual library', a computational enumeration of all possible structures of a given pharmacophore with all available reactants. Such a library can consist of thousands to millions of 'virtual' compounds. The researcher will select a subset of the 'virtual library' for actual synthesis, based upon various calculations and criteria (see ADME, computational chemistry, and QSAR).\n\nThe combinatorial \"split-mix synthesis\" is based on the solid phase synthesis developed by Merrifield. If a combinatorial peptide library is synthesized using 20 amino acids (or other kinds of building blocks) the bead form solid support is divided into 20 equal portions. This is followed by coupling a different amino acid to each portion. The third step is mixing of all portions. These three steps comprise a cycle. Elongation of the peptide chains can be realized by simply repeating the steps of the cycle.\nThe procedure is illustrated by the synthesis of a dipeptide library using the same three amino acids as building blocks in both cycles. Each component of this library contains two amino acids arranged in different orders. The amino acids used in couplings are represented by yellow, blue and red circles in the figure. Divergent arrows show dividing solid support resin (green circles) into equal portions, vertical arrows mean coupling and convergent arrows represent mixing and homogenizing the portions of the support.\n\nThe figure shows that in the two synthetic cycles 9 dipeptides are formed. In a third and fourth cycles 27 tripeptides and 81 tetrapeptides would form, respectively.\n\nThe \"split-mix synthesis\" has several outstanding features:\n\n\nIn 1990 three groups described methods for preparing peptide libraries by biological methods and one year later Fodor et al. published a remarkable method for synthesis of peptide arrays on small glass slides.\n\nA \"parallel synthesis\" method was developed by Mario Geysen and his colleagues for preparation of peptide arrays. They synthesized 96 peptides on plastic rods (pins) coated at their ends with the solid support. The pins were immersed into the solution of reagents placed in the wells of a microtiter plate. The method is widely applied particularly by using automatic parallel synthesizers. Although the parallel method is much slower than the real combinatorial one, its advantage is that it is exactly known which peptide or other compound forms on each pin.\n\nFurther procedures were developed to combine the advantages of both split-mix and the parallel synthesis. In the method described by two groups the solid support was enclosed into permeable plastic capsules together with a radiofrequency tag that carried the code of the compound to be formed in the capsule. The procedure was carried out similar to the split-mix method. In the split step, however, the capsules were distributed among the reaction vessels according to the codes read from the radiofrequency tags of the capsules.\nA different method for the same purpose was developed by Furka et al. is named \"string synthesis\". In this method the capsules carried no code. They are stringed like the pearls in a necklace and placed into the reaction vessels in stringed form. The identity of the capsules, as well as their contents, are stored by their position occupied on the strings. After each coupling step the capsules are redistributed among new strings according to definite rules.\n\nIn the drug discovery process, the synthesis and biological evaluation of small molecules of interest has typically been a long and laborious process. Combinatorial chemistry has emerged in recent decades as an approach to quickly and efficiently synthesize large numbers of potential\nsmall molecule drug candidates. In a typical synthesis, only a single target molecule is produced at the end of a synthetic scheme, with each step in a synthesis producing only a single product. In a combinatorial synthesis, when using only single starting material, it is possible to synthesize a large library of molecules using identical reaction conditions that can then be screened for their biological activity. This pool of products is then split into three equal portions containing each of the three products, and then each of the three individual pools is then reacted with another unit of reagent B, C, or D, producing 9 unique compounds from the previous 3. This process is then repeated until the desired number of building blocks is added, generating many compounds. When synthesizing a library of compounds by a multi-step synthesis, efficient reaction methods must be employed, and if traditional purification methods are used after each reaction step, yields and efficiency will suffer.\n\nSolid-phase synthesis offers potential solutions to obviate the need for typical quenching and purification steps often used in synthetic chemistry. In general, a starting molecule is adhered to a solid support (typically an insoluble polymer), then additional reactions are performed, and the final product is purified and then cleaved from the solid support. Since the molecules of interest are attached to a solid support, it is possible to reduce the purification after each reaction to a single filtration/wash step, eliminating the need for tedious liquid-liquid extraction and solvent evaporation steps that most synthetic chemistry involves. Furthermore, by using heterogeneous reactants, excess reagents can be used to drive sluggish reactions to completion, which can further improve yields. Excess reagents can simply be washed away without the need for additional purification steps such as chromatography.\n\nOver the years, a variety of methods have been developed to refine the use of solid-phase organic synthesis in combinatorial chemistry, including efforts to increase the ease of synthesis and purification, as well as non-traditional methods to characterize intermediate products. Although\nthe majority of the examples described here will employ heterogeneous reaction media in every reaction step, Booth and Hodges provide an early example of using solid-supported reagents only during the purification step of traditional solution-phase syntheses. In their view,\nsolution-phase chemistry offers the advantages of avoiding attachment and cleavage reactions necessary to anchor and remove molecules to resins as well as eliminating the need to recreate solid-phase analogues of established solution-phase reactions.\n\nThe single purification step at the end of a synthesis allows one or more impurities to be removed, assuming the chemical structure of the offending impurity is known. While the use of solid-supported reagents greatly simplifies the synthesis of compounds, many combinatorial syntheses require multiple steps, each of which still requires some form of purification. Armstrong, et al. describe a one-pot method for generating combinatorial libraries, called multiple-component condensations (MCCs). In this scheme, three or more reagents react such that each reagent is incorporated into the final product in a single step, eliminating the need for a multi-step synthesis that involves many purification steps. In MCCs, there is no deconvolution required to determine which compounds are biologically-active because each synthesis in an array has only a single product, thus the identity of the compound should be unequivocally known.\n\nIn another array synthesis, Still generated a large library of oligopeptides by split synthesis. The drawback to making many thousands of compounds is that it is difficult to determine the structure of the formed compounds. Their solution is to use molecular tags, where a tiny amount (1 pmol/bead) of a dye is attached to the beads, and the identity of a certain bead can be determined by analyzing which tags are present on the bead. Despite how easy attaching tags makes identification of receptors, it would be quite impossible to individually screen each compound for its receptor binding ability, so a dye was attached to each receptor, such that only those receptors that bind to their substrate produce a color change.\n\nWhen many reactions need to be run in an array (such as the 96 reactions described in one of Armstrong's MCC arrays), some of the more tedious aspects of synthesis can be automated to improve efficiency. DeWitt and Czarnik detail a method called the \"DIVERSOMER method,\" in which many miniaturized versions of chemical reactions are all run simultaneously. This method uses a device that automates the resin loading and wash cycles, as well as the reaction cycle monitoring and purification, and demonstrate the feasibility of their method and apparatus by using it to synthesize a variety of molecule classes, such as hydantoins and benzodiazepines, running 40 individual reactions in most cases.\n\nOftentimes, it is not possible to use expensive equipment, and Schwabacher, et al. describe a simple method of combining parallel synthesis of library members and evaluation of entire libraries of compounds. In their method, a thread that is partitioned into different regions is wrapped around a cylinder, where a different reagent is then coupled to each region which bears only a single species. The thread is then re-divided and wrapped around a cylinder of a different size, and this process is then repeated. The beauty of this method is that the identity of each product can be known simply by its location along the thread, and the corresponding biological activity is identified by Fourier transformation of fluorescence signals.\n\nIn most of the syntheses described here, it is necessary to attach and remove the starting reagent to/from a solid support. This can lead to generation of a hydroxyl group, which can potentially affect the biological activity of a target compound. Ellman uses solid phase supports in a multi-step synthesis scheme to obtain 192 individual 1,4-benzodiazepine derivatives, which are well-known therapeutic agents. To eliminate the possibility of potential hydroxyl group interference, a novel method using silyl-aryl chemistry is used to link the molecules to the solid support which cleaves from the support and leaves no trace of the linker.\n\nWhen anchoring a molecule to a solid support, intermediates cannot be isolated from one another without cleaving the molecule from the resin. Since many of the traditional characterization techniques used to track reaction progress and confirm product structure are solution-based,\ndifferent techniques must be used. Gel-phase 13 C NMR spectroscopy, MALDI mass spectrometry, and IR spectroscopy have been used to confirm structure and monitor the progress of solid-phase reactions. Gordon et al., describe several case studies that utilize imines and peptidyl phosphonates to generate combinatorial libraries of small molecules. To generate the imine library, an amino acid tethered to a resin is reacted in the present of an aldehyde. The authors demonstrate the use of fast 13 C gel phase NMR spectroscopy and magic angle spinning 1 H NMR spectroscopy to monitor the progress of reactions and showed that most imines could be formed in as little as 10 minutes at room temperature when trimethyl orthoformate was used as the solvent. The formed imines were then derivatized to generate 4-thiazolidinones, B-lactams, and pyrrolidines.\n\nThe use of solid-phase supports greatly simplifies the synthesis of large combinatorial libraries of compounds. This is done by anchoring a starting material to a solid support and then running subsequent reactions until a sufficiently large library is built, after which the products are cleaved from the support. The use of solid-phase purification has also been demonstrated for use in solution-phase synthesis schemes in conjunction with standard liquid-liquid extraction purification techniques.\n\nThe synthesized molecules of a combinatorial library are 'cleaved' from the solid support and mixed into solution. In such solution, millions of different compounds may be found. When this synthetic method was developed, it first seemed impossible to identify the molecules, and to find molecules with useful properties. Strategies of purification, identification, and screening were developed, however, to solve the problem. All these strategies are based on synthesis and testing of partial libraries.\n\nThe earliest strategy, the \"Iteration method\" is described in the above-mentioned document of Furka notarized in 1982. Identification of the sequence of the active peptide involves removal of samples after each coupling step of the synthesis before mixing. These samples are used in the step-by-step identification by testing and coupling starting at the N-terminus.\n\nThe \"Positional scanning\" method is based on synthesis and testing of a series of sub-libraries in which a certain sequence position in all components is occupied by the same amino acid.\n\n\"Omission libraries\" in which a certain amino acid is missing from all peptides of the mixture as well as \"amino acid tester libraries\" that contain those peptides that are missing from the omission libraries can also be used in the deconvolution process.\n\nIf the peptides are not cleaved from the solid support we deal with a mixture of beads, each bead containing a single peptide. Smith and his colleagues showed earlier that peptides could be tested in tethered form, too. This approach was also used in screening peptide libraries. The tethered peptide library was tested with a dissolved target protein. The beads to which the protein was attached were picked out, removed the protein from the bead then the tethered peptide was identified by sequencing.\n\nA somewhat different approach was followed by Taylor and Morken. They used infrared thermography to identify catalysts in non-peptide tethered libraries. When the beads were immersed into a solution of a substrate. the catalyst containing beads were glowing because of the heat evolved in them and could be picked out.\n\nThe components of combinatorial libraries can also be tested one by one after cleaving them from the individual beads.\n\nIf we deal with a non-peptide organic libraries library it is not as simple to determine of the identity of the content of a bead as in the case of a peptide one. In order to circumvent this difficulty methods were developed to attach to the beads, in parallel with the synthesis of the library, molecules that encode the identity of the compound formed in the bead. The attached molecules may form peptide or nucleotide sequences or a binary code.\n\nMaterials science has applied the techniques of combinatorial chemistry to the discovery of new materials. This work was pioneered by P.G. Schultz et al. in the mid nineties in the context of luminescent materials obtained by co-deposition of elements on a silicon substrate. His work was preceded by J. J. Hanak in 1970 but the computer and robotics tools were not available for the method to spread at the time. Work has been continued by several academic groups as well as companies with large research and development programs (Symyx Technologies, GE, Dow Chemical etc.). The technique has been used extensively for catalysis, coatings, electronics, and many other fields. The application of appropriate informatics tools is critical to handle, administer, and store the vast volumes of data produced. New types of Design of experiments methods have also been developed to efficiently address the large experimental spaces that can be tackled using combinatorial methods.\n\nEven though combinatorial chemistry has been an essential part of early drug discovery for more than two decades, so far only one de novo combinatorial chemistry-synthesized chemical has been approved for clinical use by FDA (sorafenib, a multikinase inhibitor indicated for advanced renal cancer). The analysis of poor success rate of the approach has been suggested to connect with the rather limited chemical space covered by products of combinatorial chemistry. When comparing the properties of compounds in combinatorial chemistry libraries to those of approved drugs and natural products, Feher and Schmidt noted that combinatorial chemistry libraries suffer particularly from the lack of chirality, as well as structure rigidity, both of which are widely regarded as drug-like properties. Even though natural product drug discovery has not probably been the most fashionable trend in pharmaceutical industry in recent times, a large proportion of new chemical entities still are nature-derived compounds, and thus, it has been suggested that effectiveness of combinatorial chemistry could be improved by enhancing the chemical diversity of screening libraries. As chirality and rigidity are the two most important features distinguishing approved drugs and natural products from compounds in combinatorial chemistry libraries, these are the two issues emphasized in so-called diversity oriented libraries, i.e. compound collections that aim at coverage of the chemical space, instead of just huge numbers of compounds.\n\nIn the 8th edition of the International Patent Classification (IPC), which entered into force on January 1, 2006, a special subclass has been created for patent applications and patents related to inventions in the domain of combinatorial chemistry: \"C40B\".\n\n\n"}
{"id": "16507553", "url": "https://en.wikipedia.org/wiki?curid=16507553", "title": "Core damage frequency", "text": "Core damage frequency\n\nCore damage frequency (CDF) is a term used in probabilistic risk assessment (PRA) that indicates the likelihood of an accident that would cause severe damage to a nuclear fuel in nuclear reactor core. Core (severe) damage accidents are considered extremely serious because severe damage to the fuel in the core prevents adequate heat removal or even safe shutdown, which can lead to a nuclear meltdown. Some sources on CDF consider core (severe) damage and core meltdown to be the same thing, and different methods of measurement are used between industries and nations, so the primary value of the CDF number is in managing the risk of core accidents within a system and not necessarily to provide large-scale statistics.\n\nAn assessment of permanent or temporary changes in a nuclear power plant is performed to evaluate if such changes are within risk criteria. For example, the probability of core (severe) damage may increase while replacing a component, but the probability would be even \"higher\" if that component were to fail because it wasn't replaced. Risk measures, such as core damage frequency and large early release frequency (LERF), determine the risk criteria for such changes.\n\nThis risk analysis allows decision making of any changes within a nuclear power plant in accordance with legislation, safety margins and performance strategies.\n\nA 2003 study commissioned by the European Commission remarked that \"core damage frequencies of 5 × 10 [per reactor-year] are a common result\" or in other words, one core damage incident in 20,000 reactor years. A 2008 study performed by the Electric Power Research Institute, the estimated core damage frequency for the United States nuclear industry is estimated at once in 50,000 reactor years, or 2 × 10.\n\nAssuming there are 500 reactors in use in the world, the above CDF estimates mean that, statistically, one core damage incident would be expected to occur somewhere in the world every 40 years for the 2003 European Commission estimated average accident rate or every 100 years for the 2008 Electric Power Research Institute estimated average accident rate.\n\nAccording to a 2011 report by the National Resources Defense Council, about 14,400 reactor years of commercial power operation have been accrued worldwide for 582 reactors. Of these 582 reactors, 11 have suffered from serious core damage. This historical data results in a 1954 to 2011 era average accident rate of 1 in every 1,309 reactor years (7.6 × 10 per reactor year CDF). In five of these accidents, the damage was light enough that the reactor was repaired and restarted.\n\nDuring the 2011 earthquake and resultant 15+ meter tsunami on the east coast of Japan, the Fukushima I nuclear power plant suffered core damages at three of its six reactors after the emergency core cooling systems failed due to the extreme beyond design basis conditions. That is, the Fukushima plants did not consider a tsuanmi above 3.1 meters in their original design. These reactors were General Electric BWR-3 and BWR-4 reactors inside Mark I containment designs, which is common in the United States. However, all of these types of plants have varying designs due to regulations, individual utility preferences, and construction location. In 1995, Sandia National Laboratories estimated that the individual BWR-3 and BWR-4 reactors in the United States have a core damage frequency between 10 and 10.\n\n\n"}
{"id": "4159599", "url": "https://en.wikipedia.org/wiki?curid=4159599", "title": "Corvette leaf spring", "text": "Corvette leaf spring\n\nCorvette leaf spring commonly refers to a type of independent suspension that utilizes a fiber-reinforced plastic (FRP) mono-leaf spring instead of more conventional coil springs. It is named after the Chevrolet Corvette, the American sports car for which it was originally developed and first utilized. A notable characteristic of this suspension configuration is the mounting of the mono-leaf spring such that it can serve as both ride spring and anti-roll spring. In contrast to many applications of leaf springs in automotive suspension designs, this type does not use the spring as a locating link. While this suspension type is most notably associated with several generations of the Chevrolet Corvette the design has been used in other production General Motors cars, as well as vehicles from Volvo Cars and Mercedes-Benz. Fiat produced cars with a similar configuration, using a multi-leaf steel spring in place of the FRP mono-leaf spring.\n\nThe leaf-spring suspension configuration is independent, because the movement of one wheel is not determined by the position of the other. Control arms are utilized to define the motion of the wheel as the suspension is compressed. The usual coil springs are replaced with a single FRP spring, which spans the width of the car. As in independent suspension systems using coil springs, and unlike the common leaf-spring supported Hotchkiss rear axle, the suspension kinematics are defined only by the control arms.\n\nAs in a coil-spring suspension design, the FRP mono-leaf spring supports the weight of the vehicle. However, the FRP leaf springs differ from steel coils and traditional steel multi-leaf springs in a number of significant ways. The FRP plastic springs have 4.3–5.5 times the strain energy storage per weight, compared to steel. This results in a lighter spring for a given application. The single FRP mono-leaf front spring used on the fourth-generation Corvette is 33 percent of the weight of an equivalent set of coil springs. Comparing FRP to conventional steel leaf springs in similar applications, the weight saved is even greater. The third-generation Corvette offered an optional FRP mono-leaf spring as an alternative to the standard multi-leaf steel spring, the steel spring being replaced by a FRP spring. Volvo claims a weight savings of by using a FRP spring in the rear suspension of its second-generation XC90, compared to designs using coil springs. In addition to the reduction in vehicle weight, the weight of the spring is partly unsprung mass.\n\nThe relative sliding movement of the leaves of a multi-leaf steel spring results in stiction-based hysteresis with respect to spring compression. This stiction reduces suspension compliance and can compromise both ride quality and handling. Lacking individual leaves, the mono-leaf spring avoids stiction.\n\nFRP springs are advertised as having exceptional cycle life and corrosion resistance. A GM test comparing the third-generation Corvette springs found that failure of the multi-leaf steel springs was likely after 200,000 full-travel cycles. The replacement FRP leaf spring showed no loss of performance after two million full cycles.\n\nPackaging is cited as both an advantage and disadvantage of the transverse FRP leaf spring, as compared to coil springs, depending on the application. The FRP spring is typically set low in the suspension, resulting in a low center of gravity. It also allows manufacturers to avoid tall spring mounts, thus resulting in a flatter load floor about the suspension. James Schefter reports that, as used on the C5 and later Corvettes, the use of OEM coilover damper springs would have forced the chassis engineers to either vertically raise the shock towers or move them inward. In the rear this would have reduced trunk space. In the front this would have interfered with engine packaging. The use of the leaf spring allowed the spring to be placed under the chassis, out of the way, while keeping the diameter of the shock-absorber assembly to that of just the damper, rather than damper and spring. However, in other applications, such as race car designs, the need to span the width of the vehicle resulted in significant design limitations. Coil and torsion springs present better packaging options for racing applications. FRP springs also have limited availability and selection as compared to coil springs. Higher cost has also been cited as a disadvantage, when comparing FRP springs to coil springs on production road cars.\n\nA notable advantage of the FRP transverse leaf springs—when supported with widely spaced, pivotable mounts—is the ability to supplement or replace the anti-roll bar. Typically springs that provide a sufficient ride rate need a supplemental spring (the anti-roll bar) to increase the suspension roll rate. The coupling of the two sides of the transverse leaf spring across the vehicle results in an anti-roll bar like behavior. Corvette engineers have cited this property as enabling the use of a lighter anti-roll bar, and even eliminating the rear anti-roll bar on some versions of the seventh generation Corvette.\n\nWhen either wheel is deflected upward, the center span of the spring (the portion between the pivotable mounts) deflects downward. If both wheels deflect upward at the same time (for example, when hitting a bump in the road) the center section bends uniformly between the pivot mounts. In a roll, only one wheel is deflected upwards, which tends to form the center of the spring into an S-shaped curve. The result is that the wheel rate of one side of the suspension depends on the displacement of the other side. The extent to which the spring acts as an anti-roll bar depends on the distance between the pivot mounts and their rigidity.\n\nA simplified flat, rectangular spring illustrates this principle. Deflecting the right side of the spring results in the left side rising. By comparison, a rigid central mount (2nd and 3rd generation Corvettes and other cars) shows no movement on one side when the other is deflected.\n\nA number of manufacturers have produced vehicles or concepts utilizing independent front or rear suspensions supported by transverse leaf springs that have an anti-roll effect.\n\nSeveral automotive companies have filed patents for suspension designs using a transverse composite leaf-spring supported in a fashion similar to that of the Corvette.\n\n"}
{"id": "1191172", "url": "https://en.wikipedia.org/wiki?curid=1191172", "title": "Dangling bond", "text": "Dangling bond\n\nIn chemistry, a dangling bond is an unsatisfied valence on an immobilized atom. An atom with a dangling bond is also referred to as an immobilized free radical or an immobilized radical, a reference to its structural and chemical similarity to a free radical.\n\nIn order to gain enough electrons to fill their valence shells (see also octet rule), many atoms will form covalent bonds with other atoms. In the simplest case, that of a single bond, two atoms each contribute one unpaired electron, and the resulting pair of electrons is shared between them. Atoms which possess too few bonding partners to satisfy their valences and which possess unpaired electrons are termed \"free radicals\"; so, often, are molecules containing such atoms. When a free radical exists in an immobilized environment (for example, a solid), it is referred to as an \"immobilized free radical\" or a \"dangling bond\".\n\nBoth free and immobilized radicals display very different chemical characteristics from atoms and molecules containing only complete bonds. Generally, they are extremely reactive. Immobilized free radicals, like their mobile counterparts, are highly unstable, but they gain some kinetic stability because of limited mobility and steric hindrance. While free radicals are usually short lived, immobilized free radicals often exhibit a longer lifetime because of this reduction in reactivity.\n\nSome allotropes of silicon, such as amorphous silicon, display a high concentration of dangling bonds. Besides being of fundamental interest, these dangling bonds are important in modern semiconductor device operation. Hydrogen introduced to the silicon during the synthesis process is well known to replace dangling bonds, as are other elements such as oxygen.\n\nIn computational chemistry, a dangling bond generally represents an error in structure creation, in which an atom is inadvertently drawn with too few bonding partners, or a bond is mistakenly drawn with an atom at only one end.\n\n"}
{"id": "4887057", "url": "https://en.wikipedia.org/wiki?curid=4887057", "title": "Debye frequency", "text": "Debye frequency\n\nThe Debye frequency (Symbol: formula_1 or formula_2) is a parameter in the Debye model. It refers to a cut-off angular frequency for waves a harmonic chain of masses, used to describe the movement of ions in a crystal lattice and more specifically, to correctly predict the heat capacity in such crystals to be constant for high temperatures (Dulong-Petit law). The term was first introduced by Peter Debye in 1912.\n\nThroughout this whole article periodic boundary conditions are assumed.\n\nAssuming the dispersion relation is\n\nwith formula_4 the speed of sound in the crystal; and k the wave vector, the value of the Debye frequency is as follows:\n\nFor a one dimensional monatomic chain the Debye frequency is equal to\n\nwith formula_6 the distance between two neighbouring atoms in the chain when the system is in its ground state (in this case that means that none of the atoms are moving with respect to each other); formula_7 the total amount of atoms in the chain; and formula_8 the size (volume) of the system (length of the chain); and formula_9 is the linear number density. Where the following relation holds: formula_10.\n\nFor a two dimensional monatomic square lattice the Debye frequency is equal to\n\nwhere formula_6 and formula_13 are the same as before; formula_14 is the size (area) of the surface; and formula_15 the surface number density.\n\nFor a three dimensional monatomic primitive cubic crystal, the Debye frequency is equal to\n\nwhere formula_6 and formula_13 are the same as before; formula_19 the size of the system; and formula_20 the volume number density.\n\nThe speed of sound in the crystal could depend on (among others) the mass of the atoms, the strength of their interaction, the pressure on the system, and/or the polarization of the wave (longitudinal or transverse), but in the following we will first assume the speed of sound to be the same for any polarization (this assumption however does not render far-reaching implications).\n\nThe assumed dispersion relation is easily proven wrong for a one-dimensional chain of masses, but in Debye’s model this didn’t prove to be problematic.\n\nThe Debye temperature formula_21, another parameter in Debye model, is related to the Debye frequency by the relationformula_22where formula_23 is the reduced Planck constant and formula_24is the Boltzmann constant.\n\nIn Debye’s derivation of the heat capacity he sums over all possible modes of the system. That is: including different directions and polarizations. He assumed the total amount of modes per polarization to be formula_25 (with formula_7 the amount of masses in the system), or in mathematical language\n\nwhere the formula_28 on both sides is because of the three polarizations, so the sum runs over all modes for one specific polarization. Debye made this assumption because he knew from classical mechanics that the amount of modes per polarization in a chain of masses should always be equal to the amount of masses in the chain.\n\nThe left hand side is now to be made explicit to show how it depends on the Debye frequency (here simply introduced as a cut-off frequency, that is: higher frequencies than the Debye frequency can’t exist), so that an expression for it could be found.\n\nFirst of all, by assuming formula_8 to be very large (formula_8»1, with formula_8 the size of the system in any of the three directions) the smallest wave vector in any direction could be approximated by: formula_32, with formula_33. Smaller wave vectors can't exist because of the periodic boundary conditions. Thus the summation would become 4\n\nwhere formula_35; formula_36 is the size of the system; and the integral is (as the summation) over all possible modes, which is assumed to be an finite region (bounded by the cut-off frequency).\n\nThe triple integral could be rewritten as a single integral over all possible values of the absolute value of formula_37 (see: Jacobian for spherical coordinates). The result is\n\nwith formula_39 the absolute value of the wave vector corresponding with the Debye frequency, so formula_40.\n\nSince we know the dispersion relation to be formula_41, this can be written as an integral over all possible formula_42\n\nAfter solving the integral it is again equated to formula_44 to find\n\nConclusion:\n\nThe same derivation could be done for a one dimensional chain of atoms. The amount of modes remains unchanged, because there are still three polarizations. So\n\nThe rest of the derivation is analogous to the previous, so again the left hand side is rewritten\n\nIn the last step the multiplication by two is because formula_49 runs negative, but formula_42 doesn’t.\n\nWe continue\n\nConclusion:\n\nThe same derivation could be done for a two dimensional crystal. Again, the amount of modes remains unchanged, because there are still three polarizations. The derivation is analogous to the previous two. We start with the same equation,\n\nAnd then the left hand side is rewritten and equated to formula_25\n\nwhere formula_56 is the size of the system.\n\nConclusion\n\nAs mentioned in the introduction: in general, longitudinal waves have a different wave velocity than transverse waves. For clarity they were first assumed to be equal, but now we drop that assumption.\n\nThe dispersion relation becomes formula_58, where formula_59, which correspond to the three polarizations. The cut-off frequency (Debye frequency) however does not depend on formula_60. And we can write the total amount of modes as formula_61, which is again equal to formula_44. Here the summation over the modes is (although not explicitly stated) dependent on formula_60.\n\nOnce again the summation over the modes is rewritten\n\nThe result is\n\nThus the Debye frequency is found\n\nOr by assuming the two transverse polarizations to be the same (to have the same phase speed and frequency)\n\nOne can check this relation is equivalent to the one found earlier (when polarization didn't make a difference) by setting formula_68.\n\nThe same derivation can be done for a two dimensional crystal to find (the derivation is analogous to previous derivations)\n\nOr by assuming the two transverse polarizations are equal (although for two dimensions it would be more logical if all polarizations would be different):\n\nAgain, one can check this relation is equivalent to the one found earlier by setting formula_68.\n\nThe same derivation can be done for a three dimensional crystal to find (the derivation is analogous to previous derivations)\n\nOr by assuming the two transverse polarizations are equal (although for three dimensions it would be more logical when all polarizations would be the same):\n\nAgain, one can check this relation is equivalent to the one found earlier by setting formula_68.\n\nThis problem could be made more insightful by making it more complex. Instead of using the dispersion relation formula_75, the correct dispersion relation is now going to be assumed. From classical mechanics it is known that for an equidistant chain of masses which interact harmonically with each other the dispersion relation reads as follows\n\nformula_76.\n\nAfter plotting this relation, it is clear that Debye’s estimation of the cut-off wavelength was right after all. Because for every wavenumber bigger than formula_77 (that is: formula_9 is smaller than formula_79) a wavenumber that is smaller than formula_80 could be found with the same angular frequency. This means the resulting physical manifestation for the mode with the larger wavenumber is indistinguishable from the one with the smaller wavenumber. This is possible because of the fact that the system consists of discretized points, as is demonstrated in the gif. Dividing the dispersion relation by formula_49 and inserting formula_80 for formula_49, we find the speed of a wave with formula_84 to be\n\nformula_85.\n\nBy simply inserting formula_86 in the original dispersion relation we find\n\nformula_87.\n\nCombining these results the same result is once again found\n\nformula_88.\n\nHowever, for diatomic chains (and more complex chains) the associated cut-off frequency (and wavelength) is not very accurate, since the cut-off wavelength is twice as big and the dispersion relation exists of two branches (for a diatomic chain). It is also not certain from this whether for more dimensional systems the cut-off frequency was accurately predicted by Debye.\n\nFor a one dimensional chain this result could also be reproduced using theory on aliasing. The Nyquist-Shannon sampling theorem is used in the following derivation; the main difference being that in the following derivation the discretization is not in time, but in space. If we use the correct dispersion relation from last paragraph, it will be clear in another insightful way why the cut-off frequency has the value previously (twice) derived. So again,\n\nformula_76\n\nis assumed.\n\nThis derivation is completely equivalent to the previous one, that is: the same assumptions are made to retrieve the result. It is not more or less accurate, it is just a different approach.\n\nTo determine where the cut-off frequency should be, it is useful to first determine where the cut-off of the wavelength should be. From the dispersion relation we know that for formula_90 every mode is repeated, so the cut-off wavelength would be at formula_91. From this and the periodic boundary conditions you can immediately see that the total amount of modes per polarization would be formula_7. As seen in the gif of the previous paragraph this is because every wave with a wavelength shorter than formula_93 could be replaced by a wave with a wavelength longer than formula_94 to regain the same physical result.\n\nHowever, the dispersion relation from previous paragraph (the correct one) isn't even necessary in reasoning as to why the cut-off should be at formula_95. Because, as is depicted, only waves with a longer wavelength than formula_94 could render the same physical result as another one. So this is another way to correctly predict the cut-off wavelength without using the correct dispersion relation (or even knowledge from classical mechanics as Debye did). However, using the wrong dispersion relation which Debye assumed, waves with a smaller wavelength would have a higher frequency, but the relative movement of the masses would be the same, so this doesn't render new modes.\n\nThis results again in formula_97, rendering\n\nformula_88.\n\nAlso here it doesn't matter which dispersion relation is used (the correct one or the one Debye used), the same cut-off frequency would be found.\n\nUnfortunately, the same method could not be used (as easily) for a two- or three-dimensional crystal, because diagonal waves would have a larger cut-off wavelength, which are also difficult to predict.\n\n"}
{"id": "35987669", "url": "https://en.wikipedia.org/wiki?curid=35987669", "title": "Dmitry Lisitsyn", "text": "Dmitry Lisitsyn\n\nDmitry Lisitsyn is a Russian environmentalist. He was awarded the Goldman Environmental Prize in 2011, for his efforts on protection of the ecosystems of the island of Sakhalin.\n"}
{"id": "54507206", "url": "https://en.wikipedia.org/wiki?curid=54507206", "title": "Dual photon", "text": "Dual photon\n\nIn theoretical physics, the dual photon is a hypothetical elementary particle that is a dual of the photon under electric-magnetic duality which is predicted by some theoretical models and some results of M-theory in eleven dimensions.\n\nIt has been shown that including magnetic monopole in Maxwell's equations introduces a singularity. The only way to avoid the singularity is including a second four-vector potential, called dual photon, in addition to the usual four-vector potential, photon. Additionally, it was found that the standard Lagrangian of electromagnetism is not dual symmetric that causes dual-asymmetric problems of the energy–momentum, spin and orbital angular-momentum tensors. To resolve this issue, a dual-symmetric Lagrangian of electromagnetism has been proposed, which has a self-consistent separation of the spin and orbital degrees of freedom. The Poincaré symmetries imply that the dual electromagnetism naturally makes self-consistent conservation laws.\n\nThe free electromagnetic field is described by a covariant antisymmetric tensor formula_1 of rank 2 by\n\nwhere formula_3 is the electromagnetic potential.\n\nThe dual electromagnetic field formula_4 is defined as\n\nwhere formula_6 denotes the Hodge dual, and formula_7 is the Levi-Civita tensor\n\nFor both the electromagnetic field and its dual field, we have\n\nThen, for a given gauge field formula_3, the dual configuration formula_11 is defined as \n\nwhere formula_11 the field potential of the dual photon, and non-locally linked to the original field potential formula_3.\n\nA p-form generalization of Maxwell's theory of electromagnetism is described by a gauge invariant 2-form formula_16 defined as\n\nwhich satisfies the equation of motion\n\nwhere formula_6 is the Hodge dual.\n\nThis implies the following action in the spacetime manifold formula_20:\n\nwhere formula_22 is the dual of the gauge invariant 2-form formula_16 for the electromagnetic field.\n\nThe dark photon is a spin-1 boson associated with a U(1) gauge field, which could be massless and behaves like electromagnetism. But, it could be unstable and massive, quickly decays into electron-positron pairs, and interact with electrons.\n\nThe dark photon was first suggested in 2008 by Lotty Ackerman, Matthew R. Buckley, Sean M. Carroll, and Marc Kamionkowski to explain the 'g–2 anomaly' in experiment E821 at Brookhaven National Laboratory. Nevertheless, it was ruled out in some experiments such as the PHENIX detector at the Relativistic Heavy Ion Collider at Brookhaven.\n\nIn 2015, the Hungarian Academy of Sciences's Institute for Nuclear Research in Debrecen, Hungary, suggested the existence of a new, light spin-1 boson, 34 times heavier than the electron that decays into a pair of electron and positron with a combined energy of 17 MeV. In 2016, it was proposed that it is a X-boson with a mass of 16.7 MeV that explains m-2 muon anomaly.\n"}
{"id": "54052265", "url": "https://en.wikipedia.org/wiki?curid=54052265", "title": "El Dabaa Nuclear Power Plant", "text": "El Dabaa Nuclear Power Plant\n\nEl Dabaa Nuclear Power Plant is the first nuclear power plant planned for Egypt and will be located at El Dabaa, Matrouh Governorate, Egypt, which is about 130 Kilometers northwest of Cairo. The plant will have four VVER-1200 reactors, making Egypt the only country in the region to have a Generation III+ reactor.\n\nOn November 19, 2015 Egypt and Russia signed an initial agreement, under which Russia will build and finance Egypt’s\nfirst nuclear power plant. In November 2017 preliminary contracts for the construction of four VVER-1200 units were signed in the presence of Egyptian President Abdel Fattah el-Sisi and Russian President Vladimir Putin.\n\nThe project will cost US$28.75 billion of which Russia will finance 85% as a state loan of US$25 billion and Egypt will provide the remaining 15% in the form of installments. The Russian loan has a repayment period of 13 years, with an annual interest rate of 3%.\n\n"}
{"id": "2272790", "url": "https://en.wikipedia.org/wiki?curid=2272790", "title": "Equivalent series inductance", "text": "Equivalent series inductance\n\nEquivalent series inductance (ESL) is an effective inductance that is used to describe the inductive part of the impedance of certain electrical components.\n\nThe theoretical treatment of devices such as capacitors and resistors tends to assume they are \"ideal\" or \"perfect\" devices, contributing only capacitance or resistance to the circuit. However, all physical devices are connected to a circuit through conductive leads and paths, which contain inherent, usually unwanted, inductance. This means that physical components contain some inductance in addition to their other properties.\n\nAn easy way to deal with these inherent inductances in circuit analysis is by using a lumped element model to express each physical component as a combination of an ideal component and a small inductor in series, the inductor having a value equal to the inductance present in the non-ideal, physical device.\n\nIdeally, the impedance of a capacitor falls with increasing frequency at 20 dB/decade. However, due partly to the inductive properties of the connections, and partly to non-ideal characteristics of the capacitor material, real capacitors also have inductive properties whose impedance \"rises\" with frequency at 20 dB/decade. At the \"resonance frequency\" the sum of both is minimal, above it the parasitic series inductance of the capacitor dominates.\n\n"}
{"id": "737876", "url": "https://en.wikipedia.org/wiki?curid=737876", "title": "Fiat Palio", "text": "Fiat Palio\n\nThe Fiat Palio is a supermini car which was produced by the Italian manufacturer Fiat since 1996 until 2017. It is a world car, developed by Fiat Automóveis and aimed at developing countries. It has been produced in various countries worldwide, and its platform was also used in the Siena sedan, the Palio Weekend station wagon, the Palio Adventure crossover and the Strada light pick-up truck.\n\nThe Palio badge originated on the Mark II Fiat 127, of 1977, where it was a trim designation rather than an actual model. The 127 Palio featured alloy wheels, a more luxurious interior, and a metallic paint finish as found on the 127 Sport. The Palio designation was also used on other Fiat models throughout the 1980s and 1990s in various markets.\n\nLaunched in 1996 in Brazil, as part of Fiat's \"Project 178\", the Palio was Fiat's first attempt to build a world car, the same basic design being produced in numerous nations around the globe. Four principal models were produced: hatchback, sedan, pickup, and station wagon, with different versions being built for different markets. The powerplants, both diesel and petrol, also varied from region to region depending on local production capability, legislation, and market requirements.\n\nThe basic chassis was a development of the European Fiat Uno but little remained unchanged. The entire structure was significantly stronger to be suitable on the rougher roads found in some of the markets for which it was intended. The suspension layout, as on the Uno, consisted of MacPherson struts at the front and a torsion beam at the rear, even though the Weekend (station wagon) version had the fully independent trailing arms rear end from the Fiat Punto instead. The body was a completely new design by the I.DE.A Institute of Turin, which also designed the new interior. Some engines were also coming from other Fiat models, such as the Punto and the Bravo.\n\nProduction began in 1996 in Brazil and was followed later that year by a plant in Argentina. In 1997, production started in Venezuela, Poland for the European market, and Morocco (at the Somaca plant) whilst Turkey started building the same car in 1998. In India, assembly was at Pune in the new Fiat-Tata Motors factory and in South Africa by Nissan together the pickup version called Fiat Strada. Production in India and South Africa began in 1999, in Egypt in 2001, and in China in 2002. The Palio Weekend station wagon was launched in 1996 in Brazil and later in Europe. The station wagon is the version most commonly sold in Europe.\n\nIn 2001, the model had its first facelift. The new design was made by the Italian automobile designer Giorgetto Giugiaro. This facelift included new front and rear fasciae and a brand new interior. Also, new engines came for the Palio: the Fire 16-valve 1.0-L and 1.2-L and the Sporting, a 1.6-L 16-valve engine with 120 hp made in Turkey. The 2001 Palio was the first Fiat to be made in China, by Nanjing Automobile. In some markets, this generation included a Speedgear semiautomatic option. The Palio 2001 facelift is the ultimate version sold in Italy. In 2001, Fiat introduced for the South American market the crossover version, called Palio Adventure and based on the Palio Weekend. In Europe, the Palio Weekend was succeeded in 2003 by the Fiat Idea MPV.\n\nIn November 2001, the Chinese Fiat Palio debuted, with either the 1.2-L or the 1.5-L. The Siena sedan was added in November 2002, followed by the Palio Weekend in June 2003. The Palio Weekend were not available with the smaller engine. A 1.6-L 72kW weekend was planned but never been sold.\n\nA Fiat Albea, the sedan version of the Palio, was tested in Russia according to the Euro NCAP latest standard (offset frontal crash at 64 km/h). The Albea scored 8,5 points in the frontal test, equivalent to three stars. The tested vehicle was equipped with standard driver airbag and regular seatbelts.\n\nThe Fiat Perla, the Chinese version of the Albea, was tested in China by China-NCAP in three different tests: 100% front crash test with a wall (similar to the U.S. National Highway Traffic Safety Administration test), a 40% offset test (similar to Euro NCAP), and a side crash test. The Perla scored 8.06 points in the 100% frontal crash test, equivalent to three stars; 12.02 pts in the 40% offset crash test, equivalent to four stars, and 10,96 pts in the side crash test, equivalent to three stars; with an average result of 31 points and three stars. The tested vehicle was equipped with standard driver and passenger airbags and regular seatbelts.\n\nThe third revision was released in 2004, designed again by Giorgetto Giugiaro. It is basically a facelift from the previous models. The 2004 Palio was the first Brazilian model in the B-segment available with four airbags (two front airbags and two side airbags), parking assistance, and light and rain sensor. In Europe, the new model featured a redesigned front fascia and interior with rear fascia similar to Palio 2001 version. It has also a sport version called the Palio 1.8R' which has a new version of the General Motors 1.8-L X18XE Powertrain engine rated at 115 hp (ethanol) and 112 hp (gasoline), lowered suspension, new 14-inch alloy wheels, new seats, and other sporting features. The third generation of the Palio had huge sales numbers, even getting higher sales in some months than the VW Golf, the Brazilian best-selling car for over 24 years. It is currently sold as the Palio Fire Economy as a cheaper alternative to its posterior facelift, with alterations derived from the Uno Mille Fire Economy model. The top model is still Weekend Adventure version; it is equipped with a 1.8-L Powertrain Flex fuel engine with 112 hp (petrol/gasoline) and 114 hp (ethanol) at 5500 rpm, all-terrain Pirelli Citynet tires, and a higher/reinforced suspension kit but still with 4x2 drive.\n\nFiat India is manufacturing the 2004 Palio, with 2001-version interiors, at the Ranjangaon plant along with the Grande Punto and Linea. After entering into a partnership with Tata Motors, the Palio has been relaunched as the Palio Stile, with the 1.1-L Fire, 1.6-L Torque, and 1.3-L Multijet engines. Sales have been low at hardly 200 units per month.\n\nThe last Palio facelift was launched in 2007, in Natal, Brazil. The design of the body was inspired by the new version of the Grande Punto, which was launched in Brazil in the first quarter of 2008.\n\nThis fourth facelift included new front, rear, and side designs, but it kept the original chassis from the 1996 model, being marketed as the New Palio. It also has a minor change in the instrument panel with differences between the two variants sold.\n\nThe trims for this new Palio are ELX with the 1.0- or the 1.4-L Fire engines, both flex (ethanol and petrol) and the \"sporty\" version 1.8R with the current revision of the 1.8-L 8-valve engine from GM, also flexible. The new Torque engines were added to the Palio after the launch of the Grande Punto. The Palio Adventure introduced the new limited slip differential and new suspension for off road with front-wheel drive.\n\nIn 2015 the station-wagon variant has been renamed as \"Fiat Weekend\", dropping the Palio name.\n\nAn all-new generation of Palio was revealed in October 2011, at the annual Fiat dealers' meeting in Mykonos, Greece. The official launch, however, took place on 4 November 2011, in Brazil. It is the first total remodeling since launch in 1996. The project, code named 326, was anticipated by the success of the new Fiat Uno in Brazil. One of the new versions will be the Sporting, a trim level known for the sporty versions of the Siena, Uno, Idea, Bravo, and Strada. In late 2017, the Fiat Palio assembly line stopped in Argentina, due to Fiat plans to start assembling the new Fiat Cronos, the saloon version of Fiat Argo, as well as a basic version of Argo without UConnect multimedia system, making the Palio officially discontinued worldwide after 21 years.\n\nFiat is joining utility companies Cemig and Itaipu to develop new electric vehicles for Brazil, with an initial batch of Fiat Palio cars scheduled to start testing later 2007.\n\nSeveral competition and homologated versions of the Palio have been produced, such as the A6 class rally car, multiple Brazilian and South American champion of the A6 class with Brazilian Luis Tedesco as driver, and the Turkish Fiat Rally Team-created Palio Super 1600 Abarth rally car, with a 215-hp 1.6-L 16-valve engine and a six-speed sequential transmission. Turkey also boasts an N2 Palio.\n\nThe first generation design of Fiat Palio, that suffered very few structural changes from 1997, has been rated as highly unsafe by Latin NCAP in 2010, scoring only one star for adult occupants and two stars for children. Its air bag-equipped version scored three stars, although it is a vast minority in the sales mix. This changed with the Brazilian law requiring dual front airbags from 2014 on.\n\n"}
{"id": "56528765", "url": "https://en.wikipedia.org/wiki?curid=56528765", "title": "Fluoroanion", "text": "Fluoroanion\n\nA fluoroanion is an anion that contains an element and fluorine atoms. They are also known as complex fluorides. They can occur in salts, or in solution, but not as pure acids. They often contain elements in higher oxidation states. They mostly can be considered as fluorometalates which are a subclass of halometalates.\n\nThe following is a list of fluoroanions in atomic number order.\n"}
{"id": "49520524", "url": "https://en.wikipedia.org/wiki?curid=49520524", "title": "Ground reinforcement", "text": "Ground reinforcement\n\nGround reinforcement is a reinforcing element placed on a flat surface in order to increase accessibility for vehicles and ensure proper rainwater drainage in addition to protection The reinforcing element, usually in the form of grids, is used beneath grass, asphalt, concrete in roads, parking lots, driveways and paths.\n\nThe materials used for ground reinforcement include iron, plywood and recycled plastic. Recycled plastic possesses the desirable properties of water resistance and recycling opportunities, in addition to the sustainability.\n\nIron plates, being heavy, are generally installed using a crane while plywood and plastic reinforcements are placed by hand.\n"}
{"id": "11113090", "url": "https://en.wikipedia.org/wiki?curid=11113090", "title": "HTR-10", "text": "HTR-10\n\nHTR-10 is a 10 MWt prototype pebble bed reactor at Tsinghua University in China. Construction began in 1995, achieving its first criticality in December 2000, and was operated in full power condition in January 2003.\n\nTwo HTR-PM units, scaled up versions of the HTR with 250-MWt capacity, are under construction at the Shidao Bay Nuclear Power Plant near the city of Rongcheng in Shandong Province.\n\nHTR-10 is modeled after the German HTR-MODUL. Like the HTR-MODUL, HTR-10 is claimed to be fundamentally safer, potentially cheaper and more efficient than other nuclear reactor designs. Outlet temperature ranges between , which allows these reactors to generate hydrogen as a byproduct efficiently, thus supplying inexpensive and non-polluting fuel for fuel cell powered vehicles.\n\nHTR-10 is a pebble-bed reactor HTGR utilizing spherical fuel elements with ceramic coated fuel particles. \nThe reactor core has a diameter of 1.8 m, a mean height of 1.97 m and\nthe volume of 5.0 m³, and is surrounded by graphite reflectors. \nThe core is composed of 27,000 fuel elements. The fuel elements use low enriched uranium with a design mean burn\nup of 80,000 MWd/t. The pressure of the primary helium coolant circuit is 3.0 Mpa.\n\n\n"}
{"id": "265112", "url": "https://en.wikipedia.org/wiki?curid=265112", "title": "Improvised explosive device", "text": "Improvised explosive device\n\nAn improvised explosive device (IED) is a bomb constructed and deployed in ways other than in conventional military action. It may be constructed of conventional military explosives, such as an artillery shell, attached to a detonating mechanism. IEDs are commonly used as roadside bombs.\n\nIEDs are generally seen in heavy terrorist actions or in asymmetric unconventional warfare by insurgent guerrillas or commando forces in a theatre of operations. In the second Iraq War, IEDs were used extensively against US-led invasion forces and by the end of 2007 they had become responsible for approximately 63% of coalition deaths in Iraq. They are also used in Afghanistan by insurgent groups, and have caused over 66% of coalition casualties in the 2001–present Afghanistan War.\n\nIEDs were also used extensively by cadres of the rebel Tamil Tiger (LTTE) organisation against military targets in Sri Lanka.\n\nAn IED is a bomb fabricated in an improvised manner incorporating destructive, lethal, noxious, pyrotechnic, or incendiary chemicals and designed to destroy or incapacitate personnel or vehicles. In some cases, IEDs are used to distract, disrupt, or delay an opposing force, facilitating another type of attack. IEDs may incorporate military or commercially sourced explosives, and often combine both types, or they may otherwise be made with homemade explosives (HME). An HME lab refers to a Homemade Explosive Lab, or the physical location where the devices are crafted.\n\nAn IED has five components: a switch (activator), an initiator (fuse), container (body), charge (explosive), and a power source (battery). An IED designed for use against armoured targets such as personnel carriers or tanks will be designed for armour penetration, by using a shaped charge that creates an explosively formed penetrator. IEDs are extremely diverse in design and may contain many types of initiators, detonators, penetrators, and explosive loads.\n\nAntipersonnel IEDs typically also contain fragmentation-generating objects such as nails, ball bearings or even small rocks to cause wounds at greater distances than blast pressure alone could. In the conflicts of the 21st century, anti-personnel improvised explosive devices (IED) have partially replaced conventional or military landmines as the source of injury to dismounted (pedestrian) soldiers and civilians. These injuries were recently reported in BMJ Open to be far worse with IEDs than with landmines resulting in multiple limb amputations and lower body mutilation. This combination of injuries has been given the name \"Dismounted Complex Blast Injury\" and is thought to be the worst survivable injury ever seen in war.\n\nIEDs are triggered by various methods, including remote control, infrared or magnetic triggers, pressure-sensitive bars or trip wires (victim-operated). In some cases, multiple IEDs are wired together in a daisy chain to attack a convoy of vehicles spread out along a roadway.\n\nIEDs made by inexperienced designers or with substandard materials may fail to detonate, and in some cases, they actually detonate on either the maker or the placer of the device. Some groups, however, have been known to produce sophisticated devices constructed with components scavenged from conventional munitions and standard consumer electronics components, such as mobile phones, consumer-grade two-way radios, washing machine timers, pagers, or garage door openers. The sophistication of an IED depends on the training of the designer and the tools and materials available.\n\nIEDs may use artillery shells or conventional high-explosive charges as their explosive load as well as homemade explosives. However, the threat exists that toxic chemical, biological, or radioactive (dirty bomb) material may be added to a device, thereby creating other life-threatening effects beyond the shrapnel, concussive blasts and fire normally associated with bombs. Chlorine liquid has been added to IEDs in Iraq, producing clouds of chlorine gas.\n\nA vehicle-borne IED, or VBIED, is a military term for a car bomb or truck bomb but can be any type of transportation such as a bicycle, motorcycle, donkey (), etc. They are typically employed by insurgents in particular ISIS, and can carry a relatively large payload. They can also be detonated from a remote location. VBIEDs can create additional shrapnel through the destruction of the vehicle itself and use vehicle fuel as an incendiary weapon. The act of a person's being in this vehicle and detonating it is known as an SVBIED suicide.\n\nOf increasing popularity among insurgent forces in Iraq is the house-borne IED, or HBIED from the common military practice of clearing houses; insurgents rig an entire house to detonate and collapse shortly after a clearing squad has entered.\n\nIn addition to known posttraumatic stress disorder (PTSD) risk factors experienced by both civilians and military personnel in combat areas; in early 2018, it was reported by \"60 Minutes\" that neuropathology specialist Dr. Daniel \"Dan\" Perl had conducted research on brain tissue exposed to traumatic brain injury (TBI), discovering a cause-and-effect relationship between IED blast waves and PTSD. Dr. Perl was recruited to the faculty of the Uniformed Services University of the Health Sciences as a Professor of Pathology and to establish the Center for Neuroscience and Regenerative Medicine mandated by Congress in 2008.\n\nThe fougasse was improvised for centuries, eventually inspiring factory-made land mines. Ernst Jünger mentions in his war memoir the systematic use of IEDs and booby traps to cover the retreat of German troops at the Somme region during the First World War. Another early example of coordinated large-scale use of IEDs was the Belarusian Rail War launched by Belarusian guerrillas against the Germans during World War II. Both command-detonated and delayed-fuse IEDs were used to derail thousands of German trains during 1943–1944.\n\nStarting six months before the invasion of Afghanistan by the USSR on 27 December 1979, the Afghan Mujahideen were supplied by the CIA, among others, with large quantities of military supplies. Among those supplies were many types of anti-tank mines. The insurgents often removed the explosives from several foreign anti-tank mines, and combined the explosives in tin cooking-oil cans for a more powerful blast. By combining the explosives from several mines and placing them in tin cans, the insurgents made them more powerful, but sometimes also easier to detect by Soviet sappers using mine detectors. After an IED was detonated, the insurgents often used direct-fire weapons such as machine guns and rocket-propelled grenades to continue the attack.\n\nAfghan insurgents operating far from the border with Pakistan did not have a ready supply of foreign anti-tank mines. They preferred to make IEDs from Soviet unexploded ordnance. The devices were rarely triggered by pressure fuses. They were almost always remotely detonated. Since the 2001 invasion of Afghanistan, the Taliban and its supporters have used IEDs against NATO and Afghan military and civilian vehicles. This has become the most common method of attack against NATO forces, with IED attacks increasing consistently year on year.\n\nAccording to a report by the Homeland Security Market Research in the US, the number of IEDs used in Afghanistan had increased by 400 percent since 2007 and the number of troops killed by them by 400 percent, and those wounded by 700 percent. It has been reported that IEDs are the number one cause of death among NATO troops in Afghanistan.\n\nA brigade commander said that sniffer dogs are the most reliable way of detecting IEDs. However, statistical evidence gathered by the US Army Maneuver Support Center at Fort Leonard Wood, MO shows that the dogs are not the most effective means of detecting IEDs. The U.S. Army's 10th Mountain Division was the first unit to introduce explosive detection dogs in southern Afghanistan. In less than two years the dogs discovered 15 tons of illegal munitions, IED's, and weapons.\n\nIn July 2012 it was reported that \"sticky bombs\", magnetically adhesive IED's that were prevalent in the Iraq War, showed up in Afghanistan.\n\nISAF troops stationed in Afghanistan and other IED prone areas of operation would commonly \"BIP\" (blow in place) IED's and other explosives that were considered too dangerous to defuse.\n\nIEDs are being used by insurgents against government forces during the insurgency in Egypt (2013-present) and the Sinai insurgency.\n\nIEDs are increasingly being used by Maoists in India.\n\nOn 13 July 2011, three IEDs were used by the Insurgency in Jammu and Kashmir to carry out a coordinated attack on the city of Mumbai, killing 19 people and injuring 130 more.\n\nOn 21 February 2013, two IEDs were used to carry out bombings in the Indian city of Hyderabad. The bombs exploded in Dilsukhnagar, a crowded shopping area of the city, within 150 metres of each other.\n\nOn 17 April 2013, two kilos of explosives used in Bangalore bomb blast at Malleshwaram area, leaving 16 injured and no fatalities. Intelligence sources have said the bomb was an Improvised Explosive Device or IED.\n\nOn 21 May 2014, Indinthakarai village supporters of the Kudankulam Nuclear Power Plant were targeted by opponents using over half a dozen crude \"country-made bombs\". It was further reported that there had been at least four similar bombings in Tamil Nadu during the preceding year.\n\nOn 28 December 2014, a minor explosion took place near the Coconut Grove restaurant at Church Street in Bangalore on Sunday around 8:30 pm. One woman was killed and another injured in the blast.\n\nDuring the 2016 Pathankot attack, several casualties came from IEDs.\n\nIn the 2003–2011 Iraq War, IEDs have been used extensively against Coalition forces and by the end of 2007 they have been responsible for at least 64% of Coalition deaths in Iraq.\n\nBeginning in July 2003, the Iraqi insurgency used IEDs to target invading coalition vehicles. According to the Washington Post, 64% of U.S. deaths in Iraq occurred due to IEDs. A French study showed that in Iraq, from March 2003 to November 2006, on a global deaths in the US-led invading coalition soldiers, were caused by IEDs, i.e. 41%. That is to say more than in the \"normal fights\" (1027 dead, 34%). Insurgents now use the bombs to target not only invading coalition vehicles but Iraqi police as well.\n\nCommon locations for placing these bombs on the ground include animal carcasses, soft drink cans, and boxes. Typically they explode underneath or to the side of the vehicle to cause the maximum amount of damage; however, as vehicle armour was improved on military vehicles, insurgents began placing IEDs in elevated positions such as on road signs, utility poles, or trees, in order to hit less protected areas.\n\nIEDs in Iraq may be made with artillery or mortar shells or with varying amounts of bulk or homemade explosives. Early during the Iraq war, the bulk explosives were often obtained from stored munitions bunkers to include stripping landmines of their explosives.\n\nDespite the increased armor, IEDs are killing military personnel and civilians with greater frequency. May 2007 was the deadliest month for IED attacks thus far, with a reported 89 of the 129 invading coalition casualties coming from an IED attack. According to the Pentagon, 250,000 tons (out of 650,000 tons total) of Iraqi heavy ordnance were looted, providing a large supply of ammunition for the insurgents.\n\nIn October 2005, the UK government charged that Iran was supplying insurgents with the technological know-how to make shaped charge IEDs. Both Iranian and Iraqi government officials denied the allegations.\n\nDuring the Iraqi Civil War (2014–present), ISIL has made extensive use of suicide VBIEDs, often driven by children, elderly and disabled.\n\nThroughout The Troubles, the Provisional IRA made extensive use of IEDs in their 1969–97 campaign. They used barrack buster mortars and remote controlled IEDs. Members of the IRA developed and counter-developed devices and tactics. IRA bombs became highly sophisticated, featuring anti-handling devices such as a mercury tilt switch or microswitches. These devices would detonate the bomb if it was moved in any way. Typically, the safety-arming device used was a clockwork Memopark timer, which armed the bomb up to 60 minutes after it was placed by completing an electrical circuit supplying power to the anti-handling device. Depending on the particular design (e.g., boobytrapped briefcase or car bomb) an independent electrical circuit supplied power to a conventional timer set for the intended time delay, e.g. 40 minutes. However, some electronic delays developed by IRA technicians could be set to accurately detonate a bomb weeks after it was hidden, which is what happened in the Brighton hotel bomb attack of 1984. Initially, bombs were detonated either by timer or by simple command wire. Later, bombs could be detonated by radio control. Initially, simple servos from radio-controlled aircraft were used to close the electrical circuit and supply power to the detonator. After the British developed jammers, IRA technicians introduced devices that required a sequence of pulsed radio codes to arm and detonate them. These were harder to jam.\n\nRoadside bombs were extensively used by the IRA. Typically, a roadside bomb was placed in a drain or culvert along a rural road and detonated by remote control when British security forces vehicles were passing. As a result of the use of these bombs, the British military stopped transport by road in areas such as South Armagh, and used helicopter transport instead to avoid the danger.\n\nMost IEDs used commercial or homemade explosives, although the use of Semtex-H smuggled in from Libya in the 1980s was also common from the mid-1980s onward. Bomb Disposal teams from 321 EOD manned by Ammunition Technicians were deployed in those areas to deal with the IED threat. The IRA also used secondary devices to catch British reinforcements sent in after an initial blast as occurred in the Warrenpoint Ambush. Between 1970 and 2005, the IRA detonated 19,000 improvised explosive devices (IEDs) in the Northern Ireland and Britain, an average of one every 17 hours for three and a half decades, arguably making it \"the biggest terrorist bombing campaign in history\".\n\nIn the early 1970s, at the height of the IRA campaign, the British Army unit tasked with rendering safe IEDs, 321 EOD, sustained significant casualties while engaged in bomb disposal operations. This mortality rate was far higher than other high risk occupations such as deep sea diving, and a careful review was made of how men were selected for EOD operations. The review recommended bringing in psychometric testing of soldiers to ensure those chosen had the correct mental preparation for high risk bomb disposal duties.\n\nThe IRA came up with ever more sophisticated designs and deployments of IEDs. Booby Trap or Victim Operated IEDs (VOIEDs), became commonplace. The IRA engaged in an ongoing battle to gain the upper hand in electronic warfare with remote controlled devices. The rapid changes in development led 321 EOD to employ specialists from DERA (now Dstl, an agency of the MOD), the Royal Signals, and Military Intelligence. This approach by the British army to fighting the IRA in Northern Ireland led to the development and use of most of the modern weapons, equipment and techniques now used by EOD Operators throughout the rest of the world today.\n\nThe bomb disposal operations were led by Ammunition Technicians and Ammunition Technical Officers from 321 EOD, and were trained at the Felix Centre at the Army School of Ammunition.\n\nThe Lebanese National Resistance Front, the Popular Front for the Liberation of Palestine, other resistance groups in Lebanon, and later Hezbollah, made extensive use of IEDs to resist Israeli forces after Israel's invasion of Lebanon in 1982. Israel withdrew from Beirut, Northern Lebanon, and Mount Lebanon in 1985, whilst maintaining its occupation of Southern Lebanon. Hezbollah frequently used IEDs to attack Israeli military forces in this area up until the Israeli withdrawal, and the liberation of Lebanon in May 2000.\n\nOne such bomb killed Israeli Brigadier General Erez Gerstein on February 28, 1999, the highest-ranking Israeli to die in Lebanon since Yekutiel Adam's death in 1982.\n\nAlso in the 2006 War in Lebanon, a Merkava Mark II tank was hit by a pre-positioned Hezbollah IED, killing all 4 IDF servicemen on board, the first of two IEDs to damage a Merkava tank.\n\nHomemade IEDs are used extensively during the post-civil war violence in Libya, mostly in the city of Benghazi against police stations, cars or foreign embassies.\n\nIEDs were also widely used in the 10-years long civil war of the Maoists in Nepal, ranging from those bought from illicit groups in India and China, to self-made devices. Typically used devices were pressure cooker bombs, socket bombs, pipe bombs, bucket bombs, etc. The devices were used more for the act of terrorizing the urban population rather than for fatal causes, placed in front of governmental offices, street corners or road sides. Mainly, the home-made IEDs were responsible for destruction of majority of structures targeted by the Maoists and assisted greatly in spreading terror among the public.\n\nBoko Haram are using IEDs during their insurgency.\n\nTaliban and other insurgent groups use IEDs against police, military, security forces, and civilian targets.\n\nIEDs have also been popular in Chechnya, where Russian forces were engaged in fighting with rebel elements. While no concrete statistics are available on this matter, bombs have accounted for many Russian deaths in both the First Chechen War (1994–1996) and the Second (1999–2009).\n\nAl Shabaab is using IEDs during the Somali Civil War.\n\nDuring the Syrian Civil War, militant insurgents were using IEDs to attack buses, cars, trucks, tanks and military convoys. Additionally, the Syrian Air Force has used barrel bombs to attack targets in cities and other areas. Such barrel bombs consist of barrels filled with high explosives, oil, and shrapnel, and are dropped from helicopters.\n\nISIS is using VBIEDs also in Syria, including during 2017 Aleppo suicide car bombing.\n\nIn the 1995 Oklahoma City bombing, Timothy McVeigh and Terry Nichols built an IED with ammonium nitrate fertilizer, nitromethane, and stolen commercial explosives in a rental truck, with sandbags used to concentrate the explosive force in the desired direction. McVeigh detonated it next to the Alfred P. Murrah Federal Building, killing 168 people, 19 of whom were children.\n\nIn August 28, 2003, Marjorie Diehl-Armstrong, and three people plotted to make Brian Wells wear a fake collar bomb and rob a bank. What Wells did not know was that the plot was for him to wear a real bomb. When he met with the conspirators and was armed with the device, Wells stated that the bomb looked real and Diehl-Armstrong responded telling him it was. Wells tried to escape, but was recaptured by his accomplices. He was forced to go to the bank, where he demanded money, receiving only $8,702. Wells was arrestd by the police outside the bank and handcuffed, Wells said that he had a bomb on him, about 30 minutes later, 3 minutes before the bomb squad arrived Brian Wells was pronounced dead, from the explosive device he carried.\n\nIn January 2011, a shaped pipe bomb was discovered and defused at a Martin Luther King Jr. memorial march in Spokane, Washington. The FBI said that the bomb was specifically designed to cause maximum harm as the explosive device was, according to the \"Los Angeles Times\", packed with fishing weights covered in rat poison, and may have been racially motivated. No one was injured during the event.\n\nOn April 15, 2013, as the annual Boston Marathon race was concluding, two bombs were detonated seconds apart close to the finish line. Initial FBI response indicated suspicion of IED pressure cooker bombs.\n\nOn September 17–19, 2016, several explosions occurred in Manhattan and New Jersey. The sources of the explosions were all found to be IEDs of various types, such as pressure cooker bombs and pipe bombs.\n\nMany IED-related arrests are made each year in circumstances where the plot was foiled before the device was deployed, or the device exploded but no one was injured.\n\nIEDs are in use in the ongoing War in Donbass and have also been used there for assassinations.\n\nIEDs were used during the Vietnam War by the Viet Cong against land- and river-borne vehicles as well as personnel. They were commonly constructed using materials from unexploded American ordnance. Thirty-three percent of U.S. casualties in Vietnam and twenty-eight percent of deaths were officially attributed to mines; these figures include losses caused by both IEDs and commercially manufactured mines.\n\nThe \"Grenade in a Can\" was a simple and effective booby trap. A hand grenade with the safety pin removed and safety lever compressed was placed into a container such as a tin can, with a length of string or tripwire attached to the grenade. The can was fixed in place and the string was stretched across a path or doorway opening and firmly tied down. In alternative fashion, the string could be attached to the moving portion of a door or gate. When the grenade was pulled out of the can by a person or vehicle placing tension on the string, the spring-loaded safety lever would release and the grenade would explode.\n\nThe \"rubber band grenade\" was another booby trap. To make this device, a Viet Cong guerrilla would wrap a strong rubber band around the spring-loaded safety lever of a hand grenade and remove the pin. The grenade was then hidden in a hut. American and South Vietnamese soldiers would burn huts regularly to prevent them from being inhabited again, or to expose foxholes and tunnel entrances, which were frequently concealed within these structures. When a hut with the booby trap was torched, the rubber band on the grenade would melt, releasing the safety lever and blowing up the hut. This would often wound the soldiers with burning bamboo and metal fragments. This booby trap was also used to destroy vehicles when the modified grenade was placed in the fuel tank. The rubber band would be eaten away by the chemical action of the fuel, releasing the safety lever and detonating the grenade.\n\nAnother variant was the \"Mason jar grenade.\" The safety pin of hand grenades would be pulled and the grenades would be placed in glass Ball Mason jars, which would hold back the safety lever. The safety lever would release upon the shattering of the jar and the grenade would detonate. This particular variant was popular with helicopter warfare, and were used as improvised anti-personnel cluster bombs during air raids. They were easy to dump out of the flight door over a target, and the thick Ball Mason glass was resistant to premature shattering. They could also be partially filled with gasoline or jellied gasoline, Napalm, to add to their destructive nature.\n\nHouthis are using IEDs against Saudi-led coalition and Hadi's forces during Yemeni Civil War (2015–present), Saudi-led intervention in Yemen and Conflict in Najran, Jizan and Asir.\n\nAl-Qaeda in the Arabian Peninsula and ISIL in Yemen are also known to use IEDs.\n\nThe \"Dictionary of Military and Associated Terms\" (JCS Pub 1-02) includes two definitions for improvised devices: improvised explosive devices (IED) and improvised nuclear device (IND). These definitions address the \"Nuclear\" and \"Explosive\" in \"CBRNe\". That leaves chemical, biological and radiological undefined. Four definitions have been created to build on the structure of the JCS definition. Terms have been created to standardize the language of first responders and members of the military and to correlate the operational picture.\n\nA device placed or fabricated in an improvised manner incorporating destructive, lethal, noxious, pyrotechnic, or incendiary chemicals and designed to destroy, incapacitate, harass, or distract. It may incorporate military stores, but is normally devised from non-military components.\n\nIEDs have been deployed in the form of explosively formed projectiles (EFP), a special type of shaped charge that is effective at long standoffs from the target (50 meters or more), however they are not accurate at long distances. This is because of how they are produced. The large \"slug\" projected from the explosion has no stabilization because it has no tail fins and it does not spin like a bullet from a rifle. Without this stabilization the trajectory can not be accurately determined beyond 50 meters. An EFP is essentially a cylindrical shaped charge with a machined concave metal disc (often copper) in front, pointed inward. The force of the shaped charge turns the disc into a high velocity slug, capable of penetrating the armor of most vehicles in Iraq.\n\nDirectionally focused charges (also known as directionally focused fragmentary charges depending on the construction) are very similar to EFPs, with the main difference being that the top plate is usually flat and not concave. It also is not made with machined copper but much cheaper cast or cut metal. When made for fragmentation, the contents of the charge is usually nuts, bolts, ball bearings and other similar shrapnel products and explosive. If it only consists of the flat metal plate, it is known as a platter charge, serving a similar role as an EFP with reduced effect but easier construction.\n\nA device incorporating the toxic attributes of chemical materials designed to result in the dispersal of these toxic chemical materials for the purpose of creating a primary patho-physiological toxic effect (morbidity and mortality), or secondary psychological effect (causing fear and behavior modification) on a larger population. Such devices may be fabricated in a completely improvised manner or may be an improvised modification to an existing weapon.\n\nA device incorporating biological materials designed to result in the dispersal of vector borne biological material for the purpose of creating a primary patho-physiological toxic effect (morbidity and mortality), or secondary psychological effect (causing fear and behavior modification) on a larger population. Such devices are fabricated in a completely improvised manner.\n\nA device making use of exothermic chemical reactions designed to result in the rapid spread of fire for the purpose of creating a primary patho-physiological effect (morbidity and mortality), or secondary psychological effect (causing fear and behavior modification) on a larger population or it may be used with the intent of gaining a tactical advantage. Such devices may be fabricated in a completely improvised manner or may be an improvised modification to an existing weapon. A common type of this is the Molotov cocktail.\n\nA speculative device incorporating radioactive materials designed to result in the dispersal of radioactive material for the purpose of area denial and economic damage, and/or for the purpose of creating a primary patho-physiological toxic effect (morbidity and mortality), or secondary psychological effect (causing fear and behavior modification) on a larger population. Such devices may be fabricated in a completely improvised manner or may be an improvised modification to an existing nuclear weapon. Also called a Radiological Dispersion Device (RDD) or \"dirty bomb\".\n\nImprovised nuclear device of most likely gun-type or implosion-type.\n\nNanotechnology can theoretically be used to develop miniaturised laser-triggered pure fusion weapon that will be easier to produce than conventional nuclear weapons and could be used in terrorist attacks.\n\nA vehicle may be laden with explosives, set to explode by remote control or by a passenger/driver, commonly known as a car bomb or vehicle-borne IED (VBIED, pronounced \"vee-bid\"). On occasion the driver of the car bomb may have been coerced into delivery of the vehicle under duress, a situation known as a proxy bomb. Distinguishing features are low-riding vehicles with excessive weight, vehicles with only one passenger, and ones where the interior of the vehicles look as if they have been stripped down and built back up. Car bombs can carry thousands of pounds of explosives and may be augmented with shrapnel to increase fragmentation. The U.S. State Department has published a guide on car bomb awareness.\n\nISIS has used truck bombs with devastating effects.\n\nBoats laden with explosives can be used against ships and areas connected to water. An early example of this type was the Japanese Shinyo suicide boats during World War II. The boats were laden with explosives and attempted to ram Allied ships, sometimes successfully, having sunk or severely damaged several American ships by war's end. Suicide bombers used a boat-borne IED to attack the USS Cole, US and UK troops have also been killed by boat-borne IEDs in Iraq.\n\nMonkeys and war pigs were used as incendiaries around 1000 AD. More famously the \"anti-tank dog\" and \"bat bomb\" were developed during World War II. In recent times, a two-year-old child and seven other people were killed by explosives strapped to a horse in the town of Chita in Colombia The carcasses of certain animals were also used to conceal explosive devices by the Iraqi insurgency.\n\nIEDs strapped to the necks of farmers have been used on at least three occasions by guerrillas in Colombia, as a way of extortion. American pizza delivery man Brian Douglas Wells was killed in 2003 by an explosive fastened to his neck, purportedly under duress from the maker of the bomb. In 2011 a schoolgirl in Sydney, Australia had a suspected collar bomb attached to her by an attacker in her home. The device was removed by police after a ten-hour operation and proved to be a hoax.\n\nSuicide bombing usually refers to an individual wearing explosives and detonating them in order to kill others including themselves, a technique pioneered by LTTE (Tamil Tigers). The bomber will conceal explosives on and around their person, commonly using a vest (or possibly a prosthetic) and will use a timer or some other trigger to detonate the explosives. The logic behind such attacks is the belief that an IED delivered by a human has a greater chance of achieving success than any other method of attack. In addition, there is the psychological impact of fighters prepared to deliberately sacrifice themselves for their cause.\n\nIn May 2012 American counter-terrorism officials leaked their acquisition of documents describing the preparation and use of surgically implanted improvised explosive devices.\nThe devices were designed to evade detection.\nThe devices were described as containing no metal, so they could not be detected by X-rays.\n\nSecurity officials referred to bombs being surgically implanted into suicide bombers' \"love handles\".\n\nAccording to the \"Daily Mirror\" UK security officials at MI-6 asserted that female bombers could travel undetected carrying the explosive chemicals in otherwise standard breast implants. The bomber would blow up the implanted explosives by injecting a chemical trigger.\n\nRobots can be used to carry explosives. First such documented case was during the aftermath of 2016 shooting of Dallas police officers when a bomb disposal robot was used to deliver explosives to kill Micah Xavier Johnson, who was hiding in a place unaccesible to police snipers.\n\nISIS\nand Al-Nusra have used bombs detonated in tunnels dug under targets.\n\nIn 2008, rocket-propelled IEDs, dubbed \"Improvised Rocket Assisted Munitions\", \"Improvised Rocket Assisted Mortars\" and \"(IRAM)\" by the military, came to be employed in numbers against U.S. forces in Iraq. They have been described as propane tanks packed with explosives and powered by 107 mm rockets. They are similar to some Provisional IRA barrack buster mortars.\nNew types of IRAMs including Volcano IRAM and Elephant Rockets, are used during Syrian Civil War.\n\nImprovised mortar has been used by many insurgent groups including during civil war in Syria and Boko Haram insurgency. IRA used improvised mortars called barrack busters.\n\nImprovised artillery including \"hell cannons\" are used by rebel forces during Syrian Civil War.\n\nCommand-wire improvised, explosive devices (CWIED) use an electrical firing cable that affords the user complete control over the device right up until the moment of initiation.\n\nThe trigger for a radio-controlled improvised explosive device (RCIED) is controlled by radio link. The device is constructed so that the receiver is connected to an electrical firing circuit and the transmitter operated by the perpetrator at a distance. A signal from the transmitter causes the receiver to trigger a firing pulse that operates the switch. Usually the switch fires an initiator; however, the output may also be used to remotely arm an explosive circuit. Often the transmitter and receiver operate on a matched coding system that prevents the RCIED from being initiated by spurious radio frequency signals or jamming. An RCIED can be triggered from any number of different mechanisms including car alarms, wireless door bells, cell phones, pagers and encrypted GMRS radios.\n\nA radio-controlled IED (RCIED) incorporating a mobile phone that is modified and connected to an electrical firing circuit. Mobile phones operate in the UHF band in line of sight with base transceiver station (BTS) antennae sites. In the common scenario, receipt of a paging signal by phone is sufficient to initiate the IED firing circuit.\n\nVictim-operated improvised explosive devices (VOIED), also known as booby traps, are designed to function upon contact with a victim. VOIED switches are often well hidden from the victim or disguised as innocuous everyday objects. They are operated by means of movement. Switching methods include tripwire, pressure mats, spring-loaded release, push, pull or tilt. Common forms of VOIED include the under-vehicle IED (UVIED), improvised landmines, and mail bombs.\n\nThe British accused Iran and Hezbollah of teaching Iraqi fighters to use infrared light beams to trigger IEDs. As the occupation forces became more sophisticated in interrupting radio signals around their convoys, the insurgents adapted their triggering methods. In some cases, when a more advanced method was disrupted, the insurgents regressed to using uninterruptible means, such as hard wires from the IED to detonator; however, this method is much harder to effectively conceal. It later emerged however, that these \"advanced\" IEDs were actually old IRA technology. The infrared beam method was perfected by the IRA in the early '90s after it acquired the technology from a botched undercover British Army operation. Many of the IEDs being used against the invading coalition forces in Iraq were originally developed by the British Army who unintentionally passed the information on to the IRA. The IRA taught their techniques to the Palestine Liberation Organisation and the knowledge spread to Iraq.\n\nCounter-IED efforts are done primarily by military, law enforcement, diplomatic, financial, and intelligence communities and involve a comprehensive approach to countering the threat networks that employ IEDs, not just efforts to defeat the devices themselves.\n\nBecause the components of these devices are being used in a manner not intended by their manufacturer, and because the method of producing the explosion is limited only by the science and imagination of the perpetrator, it is not possible to follow a step-by-step guide to detect and disarm a device that an individual has only recently developed. As such, explosive ordnance disposal (IEDD) operators must be able to fall back on their extensive knowledge of the first principles of explosives and ammunition, to try and deduce what the perpetrator has done, and only then to render it safe and dispose of or exploit the device. Beyond this, as the stakes increase and IEDs are emplaced not only to achieve the direct effect, but to deliberately target IEDD operators and cordon personnel, the IEDD operator needs to have a deep understanding of tactics to ensure he is neither setting up any of his team or the cordon troops for an attack, nor walking into one himself. The presence of chemical, biological, radiological, or nuclear (CBRN) material in an IED requires additional precautions. As with other missions, the EOD operator provides the area commander with an assessment of the situation and of support needed to complete the mission.\n\nMilitary and law enforcement personnel from around the world have developed a number of render-safe procedures (RSPs) to deal with IEDs. RSPs may be developed as a result of direct experience with devices or by applied research designed to counter the threat. The supposed effectiveness of IED jamming systems, including vehicle- and personally-mounted systems, has caused IED technology to essentially regress to command-wire detonation methods. These are physical connections between the detonator and explosive device and cannot be jammed. However, these types of IEDs are more difficult to emplace quickly, and are more readily detected.\n\nMilitary forces and law enforcement from India, Canada, United Kingdom, Israel, Spain, and the United States are at the forefront of counter-IED efforts, as all have direct experience in dealing with IEDs used against them in conflict or terrorist attacks. From the research and development side, programs such as the new Canadian Unmanned Systems Challenge will bring student groups together to invent an unmanned device to both locate IEDs and pinpoint the insurgents.\n\n"}
{"id": "23468400", "url": "https://en.wikipedia.org/wiki?curid=23468400", "title": "Kestrel Trust", "text": "Kestrel Trust\n\nFounded in 1970, the Kestrel Land Trust is a land conservation organization based in Amherst which works to conserve farmland, forests, fields and rivers from development in the Pioneer Valley of Western Massachusetts. Like most land trusts, the Kestrel Land Trust depends on private donors to leverage state money. By working with landowners, town conservation commissions, state agencies, and other land trusts Kestrel has conserved thousands of acres in the region they serve.\n\nIn the Spring of 2011, Kestrel merged with the Valley Land Fund, another land trust based in Northampton, Massachusetts. As part of the merger, Kestrel expanded its service area range from nine to nineteen towns in order to include those areas served by Valley Land Fund.\n\nThe Kestrel Land Trust annually hosts a 5K run and 2 Mile walk in late October to fundraise for land conservation. Racers begin on the Hadley Commons area and then run a fast, flat course through historic Hadley farmland before ending once again on the Commons. Prizes donated by local businesses are given to the overall male and female winners, as well as the winners of each age group. \n\nIn 2011, the event was expanded to include a farmer's market and festival following the race. Approximately 10 local farmers and artisans set up booths and sold their goods, while local Irish-music band Banish Misfortune played. Additionally, the US Fish and Wildlife Service presented their family-friendly Watershed on Wheels educational exhibit and Tom Ricardi showed rehabilitated birds. Over 500 people ran or shopped at the 2011 5K for Farmland and Farmer's Market Festival.\n\nOn December 23, 2011, Massachusetts Energy and Environmental Affairs(EEA) Secretary Richard K. Sullivan Jr. announced that 3,486 acres owned by W.D. Cowls, Inc. would be protected through a conservation restriction. This land conservation deal, arranged by the Kestrel Land Trust with partners Department of Fish and Game (DFG), Franklin Land Trust, and W.D. Cowls, Inc. is the largest land protection deal done in Massachusetts since the 1920s and the largest conservation restriction ever done in the state. This Conservation Restriction will guarantee public access for recreation, conserve wildlife habitat, and promote sustainable forestry.\n\n(1) http://www.kestreltrust.org\n\n(2) http://www.amherstarea.com/business/index.cfm/fa/showBusiness/CompanyID/828.cfm\n\n(3)http://www.farmland.org/news/pressreleases/110507nrMass.asp\n"}
{"id": "1666770", "url": "https://en.wikipedia.org/wiki?curid=1666770", "title": "Kii Channel HVDC system", "text": "Kii Channel HVDC system\n\nWith a rated power of 1400MW, the Kii Channel HVDC system in Japan is, as of 2012, the highest-capacity high-voltage direct current (HVDC) submarine power cable system in the world to use a single bipole. The cross channel system between England and France has a larger total capacity, but uses two bipoles rated at 1000MW each.\n\nThe Kii Channel HVDC system connects the Anan static inverter plant, located south of Tachibana Power Plant, at on the Japanese Home Island of Shikoku, with the inverter plant at Kihoku ( coordinates: ) on the largest of the Home Islands, Honshu.\n\nThe first stage of this project went in service in the year 2000 with a bipolar voltage of 250 kilovolts (kV) and rated to carry 1400 megawatts (MW). A second-stage upgrade to 500kV has been planned from the outset and the HV cable, DC switchgear and DC reactor are already rated for the higher voltage, but as of 2012 the upgrade has not been put into effect.\n\nThe project contained several \"firsts\" when it was originally built, including:\n\nThe first 50 kilometers of the transmission line run north from the Anan inverter station as an undersea cable. At Yura ( coordinates: ) there is a switching station, and from there the HVDC line runs for another 50 km as an overhead power line.\n\n"}
{"id": "7030890", "url": "https://en.wikipedia.org/wiki?curid=7030890", "title": "Lietuvos Dujos", "text": "Lietuvos Dujos\n\nAB Lietuvos dujos was a natural gas company in Lithuania. It was established in 1961 as an integrated gas company for import, transmission, distribution and sales of natural gas. After privatization in 1990s, its major shareholders became Gazprom and E.ON Ruhrgas. In 2013, its transmission business was spin-off into a separate company Amber Grid. In 2014, Gazprom and E.ON sold their stakes to the state-owned energy company Lietuvos Energija. On 1 January 2016, Lietuvos Dujos was merged into Energijos Skirstymo Operatorius.\n"}
{"id": "57133205", "url": "https://en.wikipedia.org/wiki?curid=57133205", "title": "Maharashtra Forest Department", "text": "Maharashtra Forest Department\n\nThe Maharashtra Forest Department is a department of the Indian state of Maharashtra responsible for forestry and wildlife management.\n\nThe headquarters of Maharashtra Forest Department is in Nagpur. There are 11 territorial forest circles in Amravati, Aurangabad, Chandrapur, Dhule, Gadchiroli, Kolhapur, Nagpur, Nashik, Pune, Thane and Yavatmal. The three wildlife circles are Wildlife Borivali, Wildlife Nagpur and Wildlife Nashik.\n\nForestry management in the state requires that special attention be paid to the rights of tribal people.\n\n"}
{"id": "25851099", "url": "https://en.wikipedia.org/wiki?curid=25851099", "title": "March 18–20, 1956 nor'easter", "text": "March 18–20, 1956 nor'easter\n\nThe March 18–20, 1956 nor'easter was a significant winter storm in the United States that affected the Mid-Atlantic States and southern New England. The storm ranked as Category 1, or \"notable\", on the Northeast Snowfall Impact Scale. A high-pressure area north of New York State, developing in the wake of another system on March 15–16, provided cold air for the snowfall. It was among a series of snowstorms to affect the region during the month.\n\nThe initial low pressure center moved southeastward into the Ohio Valley as a weak cyclone between March and March 17. As it approached the U.S. East Coast, a secondary low formed over Virginia on March 18 and gradually intensified. The primary storm dissipated shortly thereafter, and the new low emerged over the western Atlantic Ocean as it drifted northeastward. It intensified to reach a minimum barometric pressure of 1000 millibars before moving out of the region.\n\nPrecipitation began late on March 18 and ended across southern New England late the next day. Areas of northern New Jersey, southern New York, Connecticut, and Massachusetts received snowfall totals exceeding . According to local newspaper reports, the storm\nwas poorly forecast and caught travelers off-guard. The storm was not widespread, but it dropped heavy snowfall throughout densely populated areas. It had a severe and deadly impact, killing approximately 162 people. In Connecticut, it was considered the worst March blizzard of the century, having left drifts of snow high.\n\n\n"}
{"id": "36059636", "url": "https://en.wikipedia.org/wiki?curid=36059636", "title": "Neutron trail", "text": "Neutron trail\n\nThe Neutron Trail is an open cultural dialogue into our shared nuclear legacy intended to raise awareness and stimulate strategic thinking around nuclear power and nuclear disarmament. Neutron Trail deals with paradoxical human dilemmas, such as the world’s need for large outputs of energy amid ongoing and often charged discussions regarding sustainability, and pervasive public fears surrounding nuclear energy. Through visiting the people and places most impacted by society’s nuclear legacy, transmedia projects, public lectures and workshops, the Neutron Trail works to engage people from all walks of life in an ongoing exploration and evaluation of existing perceptions — true and untrue — about nuclear energy and weapons.\n\nEnrico Fermi built the first nuclear reactor (Chicago Pile-1) in an abandoned squash court at the University of Chicago. He ran the historic experiment for 28 minutes. In April 2009 artist Matthew Day Jackson invited Olivia to participate in a ceremonial game of squash. Jackson and the younger Fermi’s game tied “the physics of a squash ball to the physics of the first nuclear reactor”; was filmed in Los Alamos, New Mexico and displayed in a 28–minute video loop at the M.I.T. List Visual Arts Center and the Contemporary Arts Museum Houston. \nJackson also filmed Olivia’s visit to Trinity in Southern New Mexico, location of the first atomic bomb test on July 16, 1945.\n\nOn September 29, 2011, for the 110th anniversary of Enrico Fermi’s birth, she visited her grandfather's former lab at Via Panisperna in Rome, where Enrico conducted his Nobel Prize–winning research. It is now the site of Centro Fermi: Enrico Fermi Historical Museum of Physics.\n\nIn October 2011 Olivia visited CERN in Geneva, Switzerland. She toured various key experimental areas including the CERN Control Centre, ATLAS, the SM18 magnet test facility, and ISOLDE; met with Nobel Prize-winning physicist and former director of CERN Carlo Rubbia; and joined in a discussion with CERN’s ConCERNed for Humanity Club founders and guests.\n\nHer visit to Richland, WA in 2012 drew the interest of scientists, students and environmental activists who came to her talk and workshops. She travelled to Hiroshima and Nagasaki in November 2014 extending her dialogue project to speaking with atomic bomb survivors including Toshiko Tanaka and artist who promotes peace.\n\nFermi has given Neutron Trail talks in the US, Canada and Europe. On Jan 19, 2012, she gave a talk sponsored by the United Nations Association in Canada titled “Positioning Change and Global Nuclear Disarmament.” She presented personal stories of activists, images and timelines of individuals championing the nuclear disarmament movement.\n\nA TEDx Transmedia Talk in Rome on September 30, 2011 entitled “Becoming the Inspiration We Seek – The Alchemy of Opposites.” is about the power of embracing contradictions, especially those inherent in our nuclear legacy, such as the thrill of discovery commingled with the pride and shame of the Hiroshima and Nagasaki bombings. It includes a photograph of her grandfather Enrico Fermi, with physicist Edward Teller, holding an image of the Hiroshima bomb cloud.\n\nOn March 21, 2011, BBC World Radio contacted Fermi to give an interview regarding the crisis — then taking place — at the Fukushima 1 Nuclear Power Plant in Japan. During the five-minute interview, she spoke about her position on nuclear energy and the Neutron Trail.\nOn April 15, 2011, Olivia was the keynote speaker for the Society of Italian Researchers and Professionals of Western Canada’s inaugural meeting. This Neutron Trail talk was about her grandparents’ lives with personal anecdotes and archival images. During the question and answer period, she offered her opinions on the Fukushima Daiichi disaster: “Today we need nuclear power, and the challenge is to make it safe.”\n\n"}
{"id": "11569971", "url": "https://en.wikipedia.org/wiki?curid=11569971", "title": "OWEZ", "text": "OWEZ\n\nWindpark Egmond aan Zee (OWEZ) is the first large scale offshore wind farm built off the Dutch North Sea coast. It consists of 36 Vestas V90-3MW wind turbines, each with nameplate capacity of 3 MW. In total the farm has a capacity of 108 MW. Together these are scaled to provide energy for a maximum of 100,000 households.\n\nThe wind farm is located to off the coasts of Egmond aan Zee and is visible from the shore. Size of the farm is a projected . It was built by a consortium of Ballast Nedam and wind turbine manufacturers Vestas.\n\n\n"}
{"id": "20954851", "url": "https://en.wikipedia.org/wiki?curid=20954851", "title": "Oreichthys", "text": "Oreichthys\n\nOreichthys is a genus of tropical barbs found in Thailand, India, Bangladesh, Myanmar (Burma), northern Malay Peninsula, and the Mekong basin in Laos. They are found in ditches, ponds, streams (both highland and lowland) and canals. The genus \"Oreichthys\" (Smith 1933) was originally established to receive little fish collected in a small brook on Kao Sabap, an extensive mountain range near Chantaban, Thailand.\n\nThere are currently 7 recognized species in this genus:\n\nAll \"Oreichthys\", with the exception of \"O. crenuchoides\", possess a triangular-looking body, with the face being pointed. In \"O. crenuchoides\", the body and face are more rounded. The last simple dorsal ray is flexible and smooth. Scale count is 23 in the lengthwise series and 7 in the transverse series. The tube-bearing scales of the lateral line are restricted to the first 6 or 7 scales anteriorly. The head is marked by numerous fine rows of pores, mostly in parallel groups on the snout, cheeks, interorbital space, and operuclar bones. Barbels are absent.\n\nThailand, India, Bangladesh, Myanmar (Burma), northern Malay Peninsula, and the Mekong basin in Laos.\n\n\"Oreichthys\" are found in ditches, ponds, streams (both highland and lowland) and canals.\n\nAll \"Oreichthys\" species are easily maintained in aquaria. They are generally peaceful towards conspecifics and tankmates, even where the other fish may be smaller than they are. They appear to prefer cooler water temperatures, with 76 °F appearing to be the short-term upper limit unless auxiliary aeration is provided. They will feed on flake food, micro-pellets, frozen bloodworms, frozen mysis shrimp, and gelatin diet. All in all they are not fussy feeders, and adapt readily to captivity.\npH should range from neutral to slightly alkaline with moderate water hardness.\n"}
{"id": "16671520", "url": "https://en.wikipedia.org/wiki?curid=16671520", "title": "Orthobaric density", "text": "Orthobaric density\n\nThe orthobaric density of a compound is the density of coexisting phases (liquid, gas, or solid) at a given temperature. \n\nFor any temperature below the critical point, the density of the gas will be less than that of the liquid. At the critical point, the density of the liquid and gas phases are identical and the compound becomes a supercritical fluid.\n"}
{"id": "6925700", "url": "https://en.wikipedia.org/wiki?curid=6925700", "title": "Pinolenic acid", "text": "Pinolenic acid\n\nPinolenic acid (often misspelled as pinoleic acid) is a fatty acid contained in Siberian Pine nuts, Korean Pine nuts and the seeds of other pines (Pinus species). The highest percentage of pinolenic acid is found in Siberian pine nuts and the oil produced from them.\n\nPinolenic acid is formally designated as \"all-cis-5,9,12-18:3\". Some sources also use the term columbinic acid for this substance. But \"columbinic acid\" sometimes designates an E-Z isomer (\"trans\",\"cis\",\"cis\"\n\"delta\"-5,9,12/18:3) in the biologic literature.\n\nPinolenic acid is an isomer of gamma-linolenic acid (GLA). GLA is an ω-6 essential fatty acid (EFA) but pinolenic acid is not. However, like the EFAs, it forms biologically active metabolites in the presence of cyclooxygenase or lipoxygenase. These metabolites can partially relieve some of the symptoms of EFA deficiency.\n\nRecent research has shown its potential use in weight loss by curbing appetite.\nPinolenic acid causes the triggering of two hunger suppressants—cholecystokinin and glucagon-like peptide-1 (GLP-1).\nPinolenic acid may have LDL-lowering properties by enhancing hepatic LDL uptake.\nIt is sometimes used as a pesticide.\n"}
{"id": "56927398", "url": "https://en.wikipedia.org/wiki?curid=56927398", "title": "PreussenElektra (nuclear energy company)", "text": "PreussenElektra (nuclear energy company)\n\nPreussenElektra GmbH (former name: E.ON Kernkraft GmbH) is a subsidiary of the German utility E.ON. It is responsible for operation and decommissioning of the E.ON's nuclear assets.\n\nAfter creation of E.ON in 2000, E.ON Kernkraft was created based on the nuclear assets of PreussenElektra AG and Bayernwerk AG. In July 2016, E.ON Kernkraft was renamed PreussenElektra GmbH.\n\nPreussenElektra GmbH operates the Brokdorf, Grohnde, and Isar 2 nuclear power plants. It is decommissioning Isar 1 and Unterweser nuclear power plants. It also holds minority stakes in the RWE-operated Gundremmingen and Emsland nuclear power plants. According to the assets swap deal between E.ON and RWE, RWE will acquire these minority stakes.\n"}
{"id": "1125762", "url": "https://en.wikipedia.org/wiki?curid=1125762", "title": "Pyrography", "text": "Pyrography\n\nPyrography or pyrogravure is the art of decorating wood or other materials with burn marks resulting from the controlled application of a heated object such as a poker. It is also known as pokerwork or wood burning.\n\nThe term means \"writing with fire\", from the Greek \"pur\" (fire) and \"graphos\" (writing). It can be practiced using specialized modern pyrography tools, or using a metal implement heated in a fire, or even sunlight concentrated with a magnifying lens. \"Pyrography dates from the 17th century and reached its highest standard in the 19th century. In its crude form it is pokerwork.\" \n\nA large range of tones and shades can be achieved. Varying the type of tip used, the temperature, or the way the iron is applied to the material all create different effects. After the design is burned in, wooden objects are often coloured. Light-coloured hardwoods such as sycamore, basswood, beech and birch are most commonly used, as their fine grain is not obtrusive. However, other woods, such as maple, pine or oak, are also used. Pyrography is also applied to leather items, using the same hot-iron technique. Leather lends itself to bold designs, and also allows very subtle shading to be achieved. Specialist vegetable-tanned leather must be used for pyrography (as modern tanning methods leave chemicals in the leather which are toxic when burned), typically in light colours for good contrast.\n\nPyrography is also popular among gourd crafters and artists, where designs are burned onto the exterior of a dried hard-shell gourd.\n\nThe process has been practiced by a number of cultures including the Egyptians and some African tribes since the dawn of recorded history. Pyrographer Robert Boyer hypothesises that the art form dates back to prehistory, when early humans created designs using the charred remains of their fires. It was known in China from the time of the Han dynasty, where it was known as \"Fire Needle Embroidery\". During the Victorian era, the invention of pyrography machines sparked a widespread interest in the craft, and it was at this time that the term \"pyrography\" was coined (previously the name \"pokerwork\" had been most widely used) In the late 19th century, a Melbourne architect by the name of Alfred Smart discovered that water-based paint could be applied hot to wood by pumping benzoline fumes through a heated hollow platinum pencil. This improved the pokerwork process by allowing the addition of tinting and shading that were previously impossible. In the early 20th century, the development of the electric pyrographic hot wire wood etching machine further automated the pokerwork process, and Art Nouveau pyrographic gloveboxes and other works were popular in that era. Pyrography is a traditional folk art in many parts of Europe, including Romania, Poland, Hungary, and Flanders, as well as Argentina and other areas in South America.\n\nTraditional pyrography can be performed using any heated metal implement. Modern pyrography machines exist, and can be divided into three main categories.\n\nSolid-point burners are similar in design to a soldering iron. They have a solid brass tip which is heated by an electrical element, and operate at a fixed temperature.\n\nWire-nib burners have variable temperature controls. The writing nib is heated by an electric current passing directly through it. Some models have interchangeable nibs to allow for different effects.\n\nLaser cutters can be set to scorch the material instead of cutting all the way through it. Many laser cutters provide software facilities to import image files and transfer them onto a sheet of wood. Some laser systems are sufficiently sensitive to perform pyrography on thin card or even paper.\n\nWoods differ in hardness, grain, figure, texture, color, and other physical characteristics.\nHardness: All woods can be classified into hard or soft. Usually softwoods are from coniferous (needle-leaved) trees. You may be aware of a little bit of resin oozing and also, a slight turpentine smell when you burn on softwood. \n\nHardwoods are from broad-leaved trees. These hardwood trees can be classified into two distinct growing seasons each year (hot and cold season or a wet and dry season) such as:\n\nSoftwood will burn faster than a hardwood does. It does not require as hot a pen to burn as do the hardwoods. \n\nGrain: Grain is the direction of the fibrous elements of the wood cells. This is important to sand with the grain. Also the grain can cause deviation from its intended path with use of woodturning pen unless you apply more pressure and burn slower on the grain.\n\nFigure: This is the natural design, or pattern, that you can see on the cut surface of the wood. The figure present on the wood should always be taken into consideration when you are planning your woodburned design. \n\nTexture: There is a texture on the surface of that wood that feels either coarse of fine, even or uneven. \n\nAs a beginning woodburner, avoid using very fine or intricate designs on uneven, coarse-textured wood. Softwoods are more apt to be fine or moderately coarse-textured. With some textures it may mean that you will have to compensate when burning it – going slower on the harder summerwood, faster and with a lighter touch on the softer springwood to create an even burn overall.\n\nColor: Woodburning should be mainly used to enhance the natural beauty of a wooden project, so do not always hide a beautiful figure, grain, luster, or color if it is present.\n\nThe main hazard to be wary of is the extremely fine wood dust when sanding the wood or in some cases the pitch/sap or resin that emits harmful fumes when burning. All wood dust is hazardous & can cause respiratory problems if you do not wear a mask, some more than others & should be avoided. You should always wear a quality dust mask/respirator while power carving, and use a good dust collection system to avoid a lifetime injury to your lungs. These recommendations really are not just for power carving or sanding, but they should be used for burning as well. Remember:\nPrepared Wood, Medium Density Fibreboard (MDF), man made boards and plywood should never really ever be burned on for several reasons. Prepared wood usually has been chemically treated and burning on it will release toxins into the air. MDF is made out of toxic materials and may cause cancer and other health issues. Man-made boards and such also have layers of glue that releases toxins that may not cause immediate harm but impact one later on in life.\n\n"}
{"id": "25600", "url": "https://en.wikipedia.org/wiki?curid=25600", "title": "Ruthenium", "text": "Ruthenium\n\nRuthenium is a chemical element with symbol Ru and atomic number 44. It is a rare transition metal belonging to the platinum group of the periodic table. Like the other metals of the platinum group, ruthenium is inert to most other chemicals. Russian-born scientist of Baltic-German ancestry Karl Ernst Claus discovered the element in 1844 at Kazan State University and named it after the Latin name of his homeland, \"Ruthenia\". Ruthenium is usually found as a minor component of platinum ores; the annual production has risen from about 19 tonnes in 2009 to some 35.5 tonnes in 2017. Most ruthenium produced is used in wear-resistant electrical contacts and thick-film resistors. A minor application for ruthenium is in platinum alloys and as a chemistry catalyst. A new application of ruthenium is as the capping layer for extreme ultraviolet photomasks. Ruthenium is generally found in ores with the other platinum group metals in the Ural Mountains and in North and South America. Small but commercially important quantities are also found in pentlandite extracted from Sudbury, Ontario and in pyroxenite deposits in South Africa.\n\nA polyvalent hard white metal. Ruthenium is a member of the platinum group and is in group 8 of the periodic table:\n\nWhereas all other group 8 elements have 2 electrons in the outermost shell, in ruthenium, the outermost shell has only one electron (the final electron is in a lower shell). This anomaly is observed in the neighboring metals niobium (41), molybdenum (42), and rhodium (45).\n\nRuthenium has four crystal modifications and does not tarnish unless subject to high temperatures. Ruthenium dissolves in fused alkalis to give ruthenates (), is not attacked by acids (even aqua regia) but is attacked by halogens at high temperatures. Indeed, ruthenium is most readily attacked by oxidizing agents. Small amounts of ruthenium can increase the hardness of platinum and palladium. The corrosion resistance of titanium is increased markedly by the addition of a small amount of ruthenium. The metal can be plated by electroplating and by thermal decomposition. A ruthenium-molybdenum alloy is known to be superconductive at temperatures below 10.6 K. Ruthenium is the last of the 4d transition metals that can assume the group oxidation state +8, and even then it is less stable there than the heavier congener osmium: this is the first group from the left of the table where the second and third-row transition metals display notable differences in chemical behavior. Like iron but unlike osmium, ruthenium can form aqueous cations in its lower oxidation states of +2 and +3.\n\nRuthenium is the first in a downward trend in the melting and boiling points and atomization enthalpy in the 4d transition metals after the maximum seen at molybdenum, because the 4d subshell is more than half full and the electrons are contributing less to metallic bonding. (Technetium, the previous element, has an exceptionally low value that is off the trend due to its half-filled [Kr]4d5s configuration, though the small amount of energy needed to excite it to a [Kr]4d5s configuration indicates that it is not as far off the trend in the 4d series as manganese in the 3d transition series.) Unlike the lighter congener iron, ruthenium is paramagnetic at room temperature, as iron also is above its Curie point.\n\nThe reduction potentials in acidic aqueous solution for some common ruthenium ions are shown below:\n\nNaturally occurring ruthenium is composed of seven stable isotopes. Additionally, 34 radioactive isotopes have been discovered. Of these radioisotopes, the most stable are Ru with a half-life of 373.59 days, Ru with a half-life of 39.26 days and Ru with a half-life of 2.9 days.\n\nFifteen other radioisotopes have been characterized with atomic weights ranging from 89.93 u (Ru) to 114.928 u (Ru). Most of these have half-lives that are less than five minutes except Ru (half-life: 1.643 hours) and Ru (half-life: 4.44 hours).\n\nThe primary decay mode before the most abundant isotope, Ru, is electron capture and the primary mode after is beta emission. The primary decay product before Ru is technetium and the primary decay product after is rhodium.\n\nAs the 74th most abundant element in Earth's crust, ruthenium is relatively rare, found in about 100 parts per trillion. This element is generally found in ores with the other platinum group metals in the Ural Mountains and in North and South America. Small but commercially important quantities are also found in pentlandite extracted from Sudbury, Ontario, Canada, and in pyroxenite deposits in South Africa. The native form of ruthenium is a very rare mineral (Ir replaces part of Ru in its structure).\n\nRoughly 12 tonnes of ruthenium are mined each year with world reserves estimated at 5,000 tonnes. The composition of the mined platinum group metal (PGM) mixtures varies widely, depending on the geochemical formation. For example, the PGMs mined in South Africa contain on average 11% ruthenium while the PGMs mined in the former USSR contain only 2% (1992). Ruthenium, osmium, and iridium are considered the minor platinum group metals.\n\nRuthenium, like the other platinum group metals, is obtained commercially as a by-product from nickel, and copper, and platinum metals ore processing. During electrorefining of copper and nickel, noble metals such as silver, gold, and the platinum group metals precipitate as \"anode mud\", the feedstock for the extraction. The metals are converted to ionized solutes by any of several methods, depending on the composition of the feedstock. One representative method is fusion with sodium peroxide followed by dissolution in aqua regia, and solution in a mixture of chlorine with hydrochloric acid. Osmium, ruthenium, rhodium, and iridium are insoluble in aqua regia and readily precipitate, leaving the other metals in solution. Rhodium is separated from the residue by treatment with molten sodium bisulfate. The insoluble residue, containing Ru, Os, and Ir is treated with sodium oxide, in which Ir is insoluble, producing dissolved Ru and Os salts. After oxidation to the volatile oxides, is separated from by precipitation of (NH)RuCl with ammonium chloride or by distillation or extraction with organic solvents of the volatile osmium tetroxide. Hydrogen is used to reduce ammonium ruthenium chloride yielding a powder. The product is reduced using hydrogen, yielding the metal as a powder or sponge metal that can be treated with powder metallurgy techniques or argon-arc welding.\n\nThe oxidation states of ruthenium range from 0 to +8, and −2. The properties of ruthenium and osmium compounds are often similar. The +2, +3, and +4 states are the most common. The most prevalent precursor is ruthenium trichloride, a red solid that is poorly defined chemically but versatile synthetically.\n\nRuthenium can be oxidized to ruthenium(IV) oxide (RuO, oxidation state +4) which can in turn be oxidized by sodium metaperiodate to the volatile yellow tetrahedral ruthenium tetroxide, RuO, an aggressive, strong oxidizing agent with structure and properties analogous to osmium tetroxide. Like osmium tetroxide, ruthenium tetroxide is a potent fixative and stain for electron microscopy of organic materials, and is mostly used to reveal the structure of polymer samples. Dipotassium ruthenate (KRuO, +6), and potassium perruthenate (KRuO, +7) are also known. Unlike osmium tetroxide, ruthenium tetroxide is less stable and is strong enough as an oxidising agent to oxidise dilute hydrochloric acid and organic solvents like ethanol at room temperature, and is easily reduced to ruthenate () in aqueous alkaline solutions; it decomposes to form the dioxide above 100 °C. Unlike iron but like osmium, ruthenium does not form oxides in its lower +2 and +3 oxidation states. Ruthenium forms dichalcogenides only when reacted directly with the chalcogens, which are diamagnetic semiconductors crystallizing in the pyrite structure and thus must contain ruthenium(II).\n\nLike iron, ruthenium does not readily form oxoanions, and prefers to achieve high coordination numbers with hydroxide ions instead. Ruthenium tetroxide is reduced by cold dilute potassium hydroxide to form black potassium perruthenate, KRuO, with ruthenium in the +7 oxidation state. Potassium perruthenate can also be produced by oxidising potassium ruthenate, KRuO, with chlorine gas. The perruthenate ion is unstable and is reduced by water to form the orange ruthenate. Potassium ruthenate may be synthesized by reacting ruthenium metal with potassium hydroxide and potassium nitrate.\n\nSome mixed oxides are also known, such as MRuO, NaRuO, NaRuO, and MLnRuO.\n\nThe highest known ruthenium halide is the hexafluoride, a dark brown solid that melts at 54 °C. It hydrolyzes violently upon contact with water and easily disproportionates to form a mixture of lower ruthenium fluorides, releasing fluorine gas. Ruthenium pentafluoride is a tetrameric dark green solid that is also readily hydrolyzed, melting at 86.5 °C. The yellow ruthenium tetrafluoride is probably also polymeric and can be formed by reducing the pentafluoride with iodine. Among the binary compounds of ruthenium, these high oxidation states are known only in the oxides and fluorides.\n\nRuthenium trichloride is a well-known compound, existing in a black α-form and a dark brown β-form: the trihydrate is red. Of the known trihalides, trifluoride is dark brown and decomposes above 650 °C, tetrabromide is dark-brown and decomposes above 400 °C, and triiodide is black. Of the dihalides, difluoride is not known, dichloride is brown, dibromide is black, and diiodide is blue. The only known oxyhalide is the pale green ruthenium(VI) oxyfluoride, RuOF.\n\nRuthenium forms a variety of coordination complexes. Examples are the many pentammine derivatives [Ru(NH)L] that often exist for both Ru(II) and Ru(III). Derivatives of bipyridine and terpyridine are numerous, best known being the luminescent tris(bipyridine)ruthenium(II) chloride.\n\nRuthenium forms a wide range compounds with carbon-ruthenium bonds. Grubbs' catalyst is used for alkene metathesis. Ruthenocene is analogous to ferrocene structurally, but exhibits distinctive redox properties. The colorless liquid ruthenium pentacarbonyl converts in the absence of CO pressure to the dark red solid triruthenium dodecacarbonyl. Ruthenium trichloride reacts with carbon monoxide to give many derivatives including RuHCl(CO)(PPh) and Ru(CO)(PPh) (Roper's complex). Heating solutions of ruthenium trichloride in alcohols with triphenylphosphine gives tris(triphenylphosphine)ruthenium dichloride (RuCl(PPh)), which converts to the hydride complex chlorohydridotris(triphenylphosphine)ruthenium(II) (RuHCl(PPh)).\n\nThough naturally occurring platinum alloys containing all six platinum-group metals were used for a long time by pre-Columbian Americans and known as a material to European chemists from the mid-16th century, not until the mid-18th century was platinum identified as a pure element. That natural platinum contained palladium, rhodium, osmium and iridium was discovered in the first decade of the 19th century. Platinum in alluvial sands of Russian rivers gave access to raw material for use in plates and medals and for the minting of ruble coins, starting in 1828. Residues from platinum production for coinage were available in the Russian Empire, and therefore most of the research on them was done in Eastern Europe.\n\nIt is possible that the Polish chemist Jędrzej Śniadecki isolated element 44 (which he called \"vestium\" after the asteroid Vesta discovered shortly before) from South American platinum ores in 1807. He published an announcement of his discovery in 1808. His work was never confirmed, however, and he later withdrew his claim of discovery.\n\nJöns Berzelius and Gottfried Osann nearly discovered ruthenium in 1827. They examined residues that were left after dissolving crude platinum from the Ural Mountains in aqua regia. Berzelius did not find any unusual metals, but Osann thought he found three new metals, which he called pluranium, ruthenium, and polinium. This discrepancy led to a long-standing controversy between Berzelius and Osann about the composition of the residues. As Osann was not able to repeat his isolation of ruthenium, he eventually relinquished his claims. The name \"ruthenium\" was chosen by Osann because the analysed samples stemmed from the Ural Mountains in Russia. The name itself derives from Ruthenia, the Latin word for Rus', a historical area that included present-day Ukraine, Belarus, western Russia, and parts of Slovakia and Poland.\n\nIn 1844, Karl Ernst Claus, a Russian scientist of Baltic German descent, showed that the compounds prepared by Gottfried Osann contained small amounts of ruthenium, which Claus had discovered the same year. Claus isolated ruthenium from the platinum residues of rouble production while he was working in Kazan University, Kazan, the same way its heavier congener osmium had been discovered four decades earlier. Claus showed that ruthenium oxide contained a new metal and obtained 6 grams of ruthenium from the part of crude platinum that is insoluble in aqua regia. Choosing the name for the new element, Claus stated: \"I named the new body, in honour of my Motherland, ruthenium. I had every right to call it by this name because Mr. Osann relinquished his ruthenium and the word does not yet exist in chemistry.\"\n\nBecause it hardens platinum and palladium alloys, ruthenium is used in electrical contacts, where a thin film is sufficient to achieve the desired durability. With similar properties and lower cost than rhodium, electric contacts are a major use of ruthenium. The plate is applied to the base by electroplating or sputtering.\n\nRuthenium dioxide with lead and bismuth ruthenates are used in thick-film chip resistors. These two electronic applications account for 50% of the ruthenium consumption.\n\nRuthenium is seldom alloyed with metals outside the platinum group, where small quantities improve some properties. The added corrosion resistance in titanium alloys led to the development of a special alloy with 0.1% ruthenium. Ruthenium is also used in some advanced high-temperature single-crystal superalloys, with applications that include the turbines in jet engines. Several nickel based superalloy compositions are described, such as EPM-102 (with 3% Ru), TMS-162 (with 6% Ru), TMS-138, and TMS-174, the latter two containing 6% rhenium. Fountain pen nibs are frequently tipped with ruthenium alloy. From 1944 onward, the famous Parker 51 fountain pen was fitted with the \"RU\" nib, a 14K gold nib tipped with 96.2% ruthenium and 3.8% iridium.\n\nRuthenium is a component of mixed-metal oxide (MMO) anodes used for cathodic protection of underground and submerged structures, and for electrolytic cells for such processes as generating chlorine from salt water. The fluorescence of some ruthenium complexes is quenched by oxygen, finding use in optode sensors for oxygen. Ruthenium red, [(NH)Ru-O-Ru(NH)-O-Ru(NH)], is a biological stain used to stain polyanionic molecules such as pectin and nucleic acids for light microscopy and electron microscopy. The beta-decaying isotope 106 of ruthenium is used in radiotherapy of eye tumors, mainly malignant melanomas of the uvea. Ruthenium-centered complexes are being researched for possible anticancer properties. Compared with platinum complexes, those of ruthenium show greater resistance to hydrolysis and more selective action on tumors.\n\nRuthenium tetroxide exposes latent fingerprints by reacting on contact with fatty oils or fats with sebaceous contaminants and producing brown/black ruthenium dioxide pigment.\n\nMany ruthenium-containing compounds exhibit useful catalytic properties. The catalysts are conveniently divided into those that are soluble in the reaction medium, homogeneous catalysts, and those that are not, which are called heterogeneous catalysts.\n\nSolutions containing ruthenium trichloride are highly active for olefin metathesis. Such catalysts are used commercially for the production of polynorbornene for example. Well defined ruthenium carbene and alkylidene complexes show comparable reactivity and provide mechanistic insights into the industrial processes. The Grubbs' catalysts for example have been employed in the preparation of drugs and advanced materials.\n\nRuthenium complexes are highly active catalyst for transfer hydrogenations (sometimes referred to as \"borrowing hydrogen\" reactions). This process is employed for the enantioselective hydrogenation of ketones, aldehydes, and imines. This reaction exploits using chiral ruthenium complexes introduced by Ryoji Noyori. For example, (cymene)Ru(S,S-TsDPEN) catalyzes the hydrogenation of benzil into (\"R,R\")-hydrobenzoin. In this reaction, formate and water/alcohol serve as the source of H:\n\nA Nobel Prize in Chemistry was awarded in 2001 to Ryōji Noyori for contributions to the field of asymmetric hydrogenation.\n\nIn 2012, Masaaki Kitano (and 9 co-authors), working with an organic ruthenium catalyst, demonstrated \"Ammonia Synthesis Using a Stable Electride as an Electron Donor and Reversible Hydrogen Store\". Small-scale, intermittent production of ammonia, for local agricultural use, may be a viable substitute for electrical grid attachment as a sink for power generated by wind turbines in isolated rural installations.\n\nRuthenium-promoted cobalt catalysts are used in Fischer-Tropsch synthesis.\n\nSome ruthenium complexes absorb light throughout the visible spectrum and are being actively researched for solar energy technologies. For example, Ruthenium-based compounds have been used for light absorption in dye-sensitized solar cells, a promising new low-cost solar cell system.\n\nMany ruthenium-based oxides show very unusual properties, such as a quantum critical point behavior, exotic superconductivity (in its strontium ruthenate form), and high-temperature ferromagnetism.\n\n"}
{"id": "47326403", "url": "https://en.wikipedia.org/wiki?curid=47326403", "title": "Rwamagana Solar Power Station", "text": "Rwamagana Solar Power Station\n\nRwamagana Solar Power Station is a 8.5MW solar power plant in Rwanda, the fourth-largest economy in the East African Community.\n\nThe power station is located on leased land, at the campus of \"Agahozo Shalom Youth Village\", in Rwamagana District, Eastern Rwanda, approximately , by road, southeast of Kigali, the capital and largest city in the country. The coordinates of the power station are:2°01'34.0\"S, 30°22'38.0\"E (Latitude:-2.026111; Longitude:30.377222).\n\nIn July 2013, the government of Rwanda contracted with GigaWatt Global, a Dutch firm, to develop an 8.5 Megawatt solar power plant in Rwamagana District, Eastern Province, for a contract price of US$23 million (RwF:15 billion). GigaWatt Global would finance, build, own and operate the facility for 25 years, with the power produced sold to Rwanda Energy, the national electricity utility.\n\nIn February 2014, GigaWatt Global was able to reach financial closure, allowing construction to begin. Interconnection to the national electricity grid was achieved in July 2014, and by September 2014, the power plant was producing at maximum capacity. The power station consists of 28,360 individual photovoltaic panels spread out on a field. The final construction price, including the cost to access the national grid came to US$23.7 million. Funding came from multiple sources, including (a) Netherlands Development Finance Company (b) Emerging Africa Infrastructure Fund and (c) Norfund. The United States Overseas Private Investment Corporation and Finland's Energy and Environment Partnership provided grants.\n\n"}
{"id": "55792755", "url": "https://en.wikipedia.org/wiki?curid=55792755", "title": "Schlechtenberg Solarpark", "text": "Schlechtenberg Solarpark\n\nThe Schlechtenberg Solarpark consists of 33,000 solar panels by Hanwha SolarOne, has a length of 1.2 kilometers and a with of 100 meters. Inaugurated in September 2013, it was the largest photovoltaic power station in the Allgäu.\n\n"}
{"id": "40145449", "url": "https://en.wikipedia.org/wiki?curid=40145449", "title": "Shellite (explosive)", "text": "Shellite (explosive)\n\nShellite (known as Tridite in US service) is an explosive mixture of picric acid and dinitrophenol or picric acid and hexanitrodiphenylamine in a ratio of 70/30. It was typically used as a filling in Royal Navy armour-piercing shells during the early part of the 20th century.\n\nShellite originated after World War I as a development of lyddite (picric acid). During the war, lyddite-filled, armour-piercing shells had been found to be shock-sensitive, with a tendency to prematurely detonate upon impact rather than after penetrating the target's armour plate. Shellite was less sensitive, and also had the advantage of a low melting point, that allowed it to be easily melted and poured into shell casings during manufacture. The first trials of shellite took place in 1921, when the British monitor experimentally fired different types of 15 inch shell at , point-blank range against the surrendered German ship SMS Baden.\n\nDuring World War II, Shellite continued to be used in naval shells. It was used in the British Disney bomb, a type of concrete-piercing bomb.\n\nShellite-filled munitions may still be encountered in the wrecks of sunken warships. They are considered hazardous as, over time, picric acid will react to form crystals of metal picrates, such as iron picrate. These crystals are extremely shock sensitive and it is recommended that wrecks that contain shellite munitions not be disturbed in any way. The hazard may reduce when the shells become corroded enough to admit seawater as these materials are water-soluble.\n\n\n"}
{"id": "42713229", "url": "https://en.wikipedia.org/wiki?curid=42713229", "title": "Standard wind tunnel models", "text": "Standard wind tunnel models\n\nStandard wind tunnel models, also known as reference models, calibration models () or test check-standards are objects of relatively simple and precisely defined shapes, having known aerodynamic characteristics, that are tested in wind tunnels. Standard models are used in order to verify, by comparison of wind tunnel test results with previously published results, the complete measurement chain in a wind tunnel, including wind tunnel structure, quality of the airstream, model positioning, transducers and force balances, data acquisition system and data reduction software.\n\nMore specifically, standard wind tunnel models are used for:\n\n\nBesides, results from wind tunnel tests of standard models are used as test cases for verification of computational-fluid-dynamics (CFD) computer codes.\n\nIn most wind tunnels, standard models are tested during the commissioning and calibration of the facility. \nThis sometimes has an unfortunate effect that the test results are not as good as they can be,\nbecause the wind tunnel and its measurement system have not yet been optimally tuned at the time of the test. \nHowever, some laboratories\nhave adopted the practice of periodical testing of a standard model\nevery couple of years in order to provide a continued confidence in the \nreliability of measurements in their wind tunnels \n\nStandard wind tunnel models are usually (but not always) intended for one of the basic wind tunnel\nmeasurement types, such as the measurement of forces and moments with force balances or measurements of pressure distribution. Results of wind tunnel tests of these models are generally published in the form of nondimensional aerodynamic coefficients (thus being made independent of model size) and made\navailable to the wind-tunnel community, often in review reports containing inter-facility comparisons of data, discussing observed scatter of results, different testing conditions, production differences between models etc.\n\nAs the majority of wind tunnel tests is related to aeronautics, most\nstandard wind tunnel models resemble simplified forms of wings, airplanes or missiles. \nSuch are, for static tests: NACA 0012 and CLARK Y\n(2D wing-segment models with typical airfoils), AGARD-B / AGARD-C \n(generic delta-wing-airplane shapes), \nONERA-M (a generic transport-airplane shape), HB-2 (Hypervelocity ballistic model 2, a shape similar to a reentry-body). For dynamic tests, the often-used standard models are: SDM (Standard dynamic model, a generic fighter-like airplane shape somewhat similar to F-16)), \nBFM (Basic finner model, a generic conical-cylindrical missile with four fins at the rear end) and MBFM (Modified basic finner model). A number of other standard models exists as well.\n\nWith the increased use of wind tunnels in the testing of road vehicles, several standard\nmodels of generic car shapes were defined., such as the \nAhmed body\n, MIRA reference car\n, etc.\n\nSome wind tunnel laboratories perform periodical checkouts using internally defined standard models\nthat are selected from the repository of models previously tested in the facility\n\nGeometry of a standard wind tunnel model is defined relative to some easily identified\nparameter (), e.g. body diameter or wing chord. The geometry is published by the institution proposing the model. Beside the model itself, a standard model support, such as a sting, to be used with the model, is usually defined. An actual model is built to a size suitable for the size of a specific wind tunnel test section, in particular taking care that the frontal blockage of the model (the ratio of the model cross-section area to wind tunnel test section area) is kept well below 1% (except for wall-interference research where the models may be larger).\n\nIn order to eliminate the effects of production differences between models in inter-facility comparisons, sometimes the same physical standard model is tested in several wind tunnels \n\nWind tunnel\n\nAGARD-B wind tunnel model\n\n"}
{"id": "38634089", "url": "https://en.wikipedia.org/wiki?curid=38634089", "title": "Switch (2012 film)", "text": "Switch (2012 film)\n\nSwitch is a documentary film on global energy directed by Harry Lynch, produced and distributed by Arcos Films, and featuring Scott W. Tinker, a geologist and energy researcher who runs the Bureau of Economic Geology, a 200-person research unit of The University of Texas at Austin. and is a professor at the Jackson School of Geosciences.\n\nThe film is part of a larger energy education and efficiency project, which also includes the Switch Energy Project website, with additional video content and educational programs. The website includes interviews with some of the world's leading energy policy analysts. Interviews including Ernie Moniz, former Under Secretary of Energy, Steven E. Koonin, Deputy Executive Director of the International Energy Agency, Richard Jones and physicist Richard A. Muller. \n\nThe film aims to be a nonpartisan, scientifically based exploration of the energy transition from the traditional energies of coal and oil to future energies. It has been accepted by many environmental groups, government agencies, fossil and renewable energy companies and academic institutions. \n\n\"Switch\" premiered at the 2012 Environmental Film Festival in Washington DC to positive reviews, then played at 12 other international festivals, most of them environmentally focused, and at 6 international geology conferences, before opening in theaters in New York in September 2012.\n\n\"Switch\" begins in Norway, where Dr. Tinker explores an electricity system built on renewable hydropower. There, he asks the central question of the film: what will the energy transition look like for the rest of us. Over the next 90 minutes, he travels the world to find out. His first step is to calculate how much energy the average person uses in a year, including all the energy embodied in the food and products we consume, the roads and public buildings we share. He uses that figure to measure and compare each energy type he visits.\n\nTinker starts with the big conventional energies, coal and oil, trying to determine their futures. Can coal be clean? Will we keep using it? Will oil price keep rising? Will we run out of it? He then examines the energies that may replace them. For oil, those are biofuels, natural gas and electricity. For coal, they are geothermal, solar, wind, natural gas and nuclear. \n\nWith each type, he visits some of the world’s leading facilities, talks to top experts in the Department of Energy, universities and within each industry, and gives a concise and objective analysis of each resource’s major pros and cons. The expertise of the interviewees and the access to restricted energy sites is unparalleled in other energy films.\n\nAfter his journey, he assembles his findings to map out the likely energy future. While coal and oil will continue to play a large role especially in developing countries, a global transition to where their alternatives become dominant will happen in about 50 years. Renewables see by far the largest growth rate, while natural gas makes up the largest portion of the replacement, with nuclear approximately equal in share to renewables.\n\nTinker ends by emphasizing that energy efficiency, including personal energy conservation, will play a vital and growing role in a successful energy future: “The most important thing is to change the way we think about energy, so we can change the way we use it.” \n\n\"\"Switch\" is refreshingly free of hot air. It’s almost shocking in the way it sidesteps the kind of issue advocacy made commonplace by filmmakers Michael Moore, Davis Guggenheim and the like. Lynch’s film tries (and largely succeeds) in taking a scrupulously neutral tack between extremes.\" - \"The Washington Post\" \n\n\"Sidestepping the usual eco-docu strategy, \"Switch\" takes a far less hysterical route. Lynch’s method gives a rational evaluation of where the world is heading. It’s considerably more honest, and manages to be quite effective. Tech credits are tops, particularly the seamless editing and the often beautiful photography.” - \"Variety\"\n\n\"Tinker comes across as affable, reasonable, and unfailingly curious. His interview \nsubjects are technicians, business executives, scientists, government officials. It insures a tone of dispassionate seriousness and good will.\" - \"Boston Globe\"\n\n\"Tinker takes us along for this beautifully shot ride, excellent in its details, and mixes a kind of gee-whiz wonderment at the way energy is produced with pithy, on-the-mark observations about the realities of those sources. He foresees the increasing use of renewables, natural gas and nuclear power in the US. But he also offers a sobering forecast of why we’re unlikely to shake coal and oil for a long time.\" - \"Austin American-Statesman\"\n\n\"There's no one solution to solving the energy crisis, but that's where Switch provides a valuable resource. In addition to the film, the Switch Energy Project also provides a deep video archive of the many interviews Dr. Tinker captured and used throughout the film.\" - \"TreeHugger\" \n\nAs of 2013, \"Switch\" is currently screening at university campuses as part of an energy awareness and efficiency program sponsored by the Geological Society of America. \n\nThe website mentions an upcoming primary education program being co-developed with the American Geosciences Institute.\n\n"}
{"id": "33811335", "url": "https://en.wikipedia.org/wiki?curid=33811335", "title": "Syngnathus dawsoni", "text": "Syngnathus dawsoni\n\nSyngnathus dawsoni is a species of the pipefishes. It occurs in the entral, western Atlantic in the Caribbean Sea from Puerto Rico to St. Lucia and has been recorded only from the east of the Mona Passage. It is a marine tropical demersal fish. It is ovoviviparous, te male carries the fertilized eggs n a brood pouch located under his tail. It has been captured at around in shallow, inshore water but its habits and ecology are unknown. The specific name honours Charles Eric Dawson who collected the type material and who recognised this species as different from the other Atlantic members of the family Syngnathidae.\n"}
{"id": "43348114", "url": "https://en.wikipedia.org/wiki?curid=43348114", "title": "The City Dark", "text": "The City Dark\n\nThe City Dark is a documentary film by filmmaker Ian Cheney about light pollution. It won the Best Score/Music Award at the 2011 SXSW Film Festival and was nominated for at the 34th News & Documentary Emmy Awards.\n\n"}
{"id": "3877354", "url": "https://en.wikipedia.org/wiki?curid=3877354", "title": "Thermal airship", "text": "Thermal airship\n\nA thermal airship is an airship that generates buoyancy by heating air in a large chamber or envelope. The lower density of interior hot air compared to cool ambient air causes an upward force on the envelope. This is very similar to a hot air balloon, with the notable exception that an airship has a powered means of propulsion, whilst a hot air balloon relies on winds for navigation. An airship that uses steam would also qualify as a thermal airship.\n\nOther types of airships use a gas that is lighter than air at ambient temperature, such as helium, as a lifting gas.\n\nSome airship designs that use a lighter-than-air lifting gas heat a portion of the gas, which is usually maintained in enclosed cells to gain additional lift. Heating the lifting gas causes expansion of the gas in order to further lower the density of the lifting gas, which results in greater lift.\n\nThermal airships have the advantage of being much less expensive than helium-based airships. They are also routinely deflated after each flight and can be readily packed for storage and/or transport, making them blimps rather than rigid airships.\n\nHot air craft produce much less uplift per unit volume than helium- or hydrogen-filled craft (about 30% depending on air conditions). This necessitates lighter construction, with fewer controls and hence more difficulty in maneuvering. This leads to:\n\nIn recent years, the steering of these ships has improved somewhat. The most successful approach has been to use higher pressure in the tail fin structures than in the rest of the envelope, or to use an internal structure (see below).\n\nThe first public flight of a hot air airship was made by Don Cameron (UK) in a Cameron D-96 at the Icicle Meet in January 1973. The aircraft reportedly took 3 years to develop.\n\nMost thermal airships are non-rigid. Some are pressurized. In some cases, the pressurized air is taken from a duct located behind the propeller. In other cases, the pressurized air comes from a separate fan.\n\nIn 2006, a new type of envelope employing a tensile membrane structure was developed by Skyacht Aircraft. This design uses an unpressurized envelope and an internal structure that uses ribs made of aluminium to keep the envelope in shape. When not in use, the structure folds up in a manner similar to an umbrella. The structure also permits the mounting of a steerable engine/propeller on the tail of the aircraft. The tail-mounted propeller provides for vectored thrust steering, allowing tight turns.\n\nLike hot air balloons, thermal airships are first inflated partially with cold (ambient temperature) air. Once the envelopes are sufficiently full, a propane burner is ignited and the inflation is completed using heated air.\n\n\n"}
{"id": "2474597", "url": "https://en.wikipedia.org/wiki?curid=2474597", "title": "Tropical upper tropospheric trough", "text": "Tropical upper tropospheric trough\n\nA tropical upper tropospheric trough (TUTT), also known as the mid-oceanic trough,or commonly called as Western Hemisphere or \"upper cold low\" is a trough situated in upper-level (at about 200 hPa) tropics. Its formation is usually caused by the intrusion of energy and wind from the mid-latitudes into the tropics. It can also develop from the inverted trough adjacent to an upper level anticyclone. TUTTs are different from mid-latitude troughs in the sense that they are maintained by subsidence warming near the tropopause which balances radiational cooling. When strong, they can present a significant vertical wind shear to the tropics and subdue tropical cyclogenesis. When upper cold lows break off from their base, they tend to retrograde and force the development, or enhance, surface troughs and tropical waves to their east. Under special circumstances, they can induce thunderstorm activity and lead to the formation of tropical cyclones.\n\nThe TUTT is elongated from east-northeast to west-southwest across oceans of the Northern Hemisphere, and west-northwest to east-southeast across oceans of the Southern Hemisphere. In the South Pacific, it stretches from near the equator at the 175th meridian west to the east-southeast near 30N 105W, offshore the western South American coast. In the South Atlantic, the TUTT extends from near the equator at the 75th meridian west east-southeast to 30N 15W, offshore the western coast of southern Africa. In the North Atlantic, the TUTT is oriented from 35N 30W (south of the Azores) to 22N 95W (the southern Gulf of Mexico). In the North Pacific, it stretches from 35N 145W (offshore western North America) to 22N 135E, offshore the northeast coast of the Philippines.\n\nTUTTs sometimes brings a large amount of vertical wind shear over tropical disturbances in the deep tropics and cyclones and thus hinder their development. However, there are cases that TUTTs assist the genesis and intensification of tropical cyclones by providing additional forced ascent near the storm center and an efficient outflow channel in the upper troposphere. This is most likely near its most westward and equatorward periphery.\n\nUnder specific circumstances, upper cold lows can break off from the base of the TUTT. These upper tropospheric cyclonic vortices usually move slowly from east-northeast to west-southwest, and generally do not extend below 20,000 feet in altitude. A weak inverted wave in the easterlies is generally found underneath them, and they may also be associated with broad areas of high-level clouds. Downward development results in an increase of cumulus clouds and the appearance of a surface vortex. In rare cases, they become warm-core, resulting in the vortex becoming a tropical cyclone. Upper cyclones and upper troughs which trail tropical cyclones can cause additional outflow channels and aid in their intensification process. Developing tropical disturbances can help create or deepen upper troughs or upper lows in their wake due to the outflow jet emanating from the developing tropical disturbance/cyclone.\n\n"}
{"id": "5351436", "url": "https://en.wikipedia.org/wiki?curid=5351436", "title": "Turbulence kinetic energy", "text": "Turbulence kinetic energy\n\nIn fluid dynamics, turbulence kinetic energy (TKE) is the mean kinetic energy per unit mass associated with eddies in turbulent flow. Physically, the turbulence kinetic energy is characterised by measured root-mean-square (RMS) velocity fluctuations.\n\nIn Reynolds-averaged Navier Stokes equations, the turbulence kinetic energy can be calculated based on the closure method, i.e. a turbulence model. Generally, the TKE can be quantified by the mean of the turbulence normal stresses:\n\nTKE can be produced by fluid shear, friction or buoyancy, or through external forcing at low-frequency eddy scales(integral scale). Turbulence kinetic energy is then transferred down the turbulence energy cascade, and is dissipated by viscous forces at the Kolmogorov scale. This process of production, transport and dissipation can be expressed as:\n\nwhere:\n\n\nAssuming density and viscosity both constant, the full form of the TKE equation is:\n\nBy examining these phenomena, the turbulence kinetic energy budget for a particular flow can be found.\n\nIn computational fluid dynamics (CFD), it is impossible to numerically simulate turbulence without discretizing the flow-field as far as the Kolmogorov microscales, which is called direct numerical simulation (DNS). Because DNS simulations are exorbitantly expensive due to memory, computational and storage overheads, turbulence models are used to simulate the effects of turbulence. A variety of models are used, but generally TKE is a fundamental flow property which must be calculated in order for fluid turbulence to be modelled.\n\nReynolds-averaged Navier–Stokes (RANS) simulations use the Boussinesq eddy viscosity hypothesis to calculate the Reynolds stress that results from the averaging procedure:\n\nwhere\n\nThe exact method of resolving TKE depends upon the turbulence model used; \"–\" (k–epsilon) models assume isotropy of turbulence whereby the normal stresses are equal:\n\nThis assumption makes modelling of turbulence quantities ( and ) simpler, but will not be accurate in scenarios where anisotropic behaviour of turbulence stresses dominates, and the implications of this in the production of turbulence also leads to over-prediction since the production depends on the mean rate of strain, and not the difference between the normal stresses (as they are, by assumption, equal).\n\nReynolds-stress models (RSM) use a different method to close the Reynolds stresses, whereby the normal stresses are not assumed isotropic, so the issue with TKE production is avoided.\n\nAccurate prescription of TKE as initial conditions in CFD simulations are important to accurately predict flows, especially in high Reynolds-number simulations. A smooth duct example is given below.\n\nwhere is the initial turbulence intensity [%] given below, and is the initial velocity magnitude;\n\nHere is the turbulence or eddy length scale, given below, and is a – model parameter whose value is typically given as 0.09;\n\nThe turbulent length scale can be \"estimated\" as\n\nwith a characteristic length. For internal flows this may take the value of the inlet duct (or pipe) width (or diameter) or the hydraulic diameter.\n\n"}
{"id": "12232494", "url": "https://en.wikipedia.org/wiki?curid=12232494", "title": "Undergrounding", "text": "Undergrounding\n\nUndergrounding is the replacement of overhead cables providing electrical power or telecommunications, with underground cables. This is typically performed for fire prevention and to make the power lines less susceptible to outages during high wind thunderstorms or heavy snow or ice storms. An added benefit of undergrounding is the aesthetic quality of the landscape without the powerlines. Undergrounding can increase the initial costs of electric power transmission and distribution but may decrease operational costs over the lifetime of the cables.\n\nThe first uses of undergrounding had a basis in the detonation of mining explosives and undersea telegraph cables. Power cables were used in Russia to detonate mining explosives in 1812, and to carry telegraph signals across the English Channel in 1850. \n\nWith the spread of early electrical power systems, undergrounding began to increase as well. Thomas Edison used underground DC “street pipes” in his early distribution networks; they were insulated first with jute in 1880, before progressing to rubber insulation in 1882. \n\nSubsequent developments occurred in both insulation and fabrication techniques: \n\n\nThe aerial cables that carry high-voltage electricity and are supported by large pylons are generally considered an unattractive feature of the countryside. Underground cables can transmit power across densely populated areas or areas where land is costly or environmentally or aesthetically sensitive. Underground and underwater crossings may be a practical alternative for crossing rivers.\n\n\n\nThe advantages can in some cases outweigh the disadvantages of the higher investment cost, and more expensive maintenance and management.\n\nMost electrical power in Japan is still provided by aerial cables. In Tokyo's 23 wards, according to Japan's Construction and Transport Ministry, just 7.3 percent of cables were laid underground as of March 2008\n\nThe UK regulator Office of Gas and Electricity Markets (OFGEM) permits transmission companies to recoup the cost of some undergrounding in their prices to consumers. The undergrounding must be in National Parks or designated Areas of Outstanding Natural Beauty (AONB) to qualify. The most visually intrusive overhead cables of the core transmission network are excluded from the scheme. Some undergrounding projects are funded by the proceeds of national lottery.\n\nAll low and medium voltage electrical power (<50 kV) in the Netherlands is now supplied underground.\n\nIn Germany, 73% of the medium voltage cables are underground and 87% of low voltage cables are underground. The high fraction of underground cables contributes to the very high grid reliability (SAIDI < 20). . In comparison, the SAIDI value (minutes without electricity per year) in the Netherlands is about 30, and in the UK it is about 70.\n\nIn the United States, the California Public Utilities Commission (CPUC) Rule 20 permits the undergrounding of electrical power cables under certain situations. Rule 20A projects are paid for by all customers of the utility companies. Rule 20B projects are partially funded this way and cover the cost of an equivalent overhead system. Rule 20C projects enable property owners to fund the undergrounding.\n\nA compromise between undergrounding and using overhead lines is installing air cables. Aerial cables are insulated cables spun between poles and used for power transmission or telecommunication services. An advantage of aerial cables is that their insulation removes the danger of electric shock (unless the cables are damaged). Another advantage is that they forgo the costs—particularly high in rocky areas—of burying. The disadvantages of aerial cables are that they have the same aesthetic issues as standard overhead lines and that they can be affected by storms. However if the insulation is not destroyed during pylon failure or when hit by a tree, there is no interruption of service. Electrical hazards are minimised and re-hanging the cables may be possible without power interruption.\n\n\n"}
{"id": "2055144", "url": "https://en.wikipedia.org/wiki?curid=2055144", "title": "Upgrader", "text": "Upgrader\n\nAn upgrader is a facility that upgrades bitumen (extra heavy oil) into synthetic crude oil. Upgrader plants are typically located close to oil sands production, for example, the Athabasca oil sands in Alberta, Canada or the Orinoco tar sands in Venezuela.\n\nUpgrading means using fractional distillation and/or chemical treatment to convert bitumen so it can be handled by oil refineries. At a minimum, this means reducing its viscosity so that it can be pumped through pipelines (bitumen is 1000x more viscous than light crude oil). However this process often also includes separating out heavy fractions and reducing sulfur, nitrogen and metals like nickel and vanadium.\n\nUpgrading may involve multiple processes:\n\n\nResearch into using biotechnology to perform some of these processes at lower temperatures and cost is ongoing.\n\n\n"}
{"id": "5470239", "url": "https://en.wikipedia.org/wiki?curid=5470239", "title": "Xylophagy", "text": "Xylophagy\n\nXylophagy is a term used in ecology to describe the habits of an herbivorous animal whose diet consists primarily (often solely) of wood. The word derives from Greek \"ξυλοφάγος\" (\"xulophagos\") \"eating wood\", from \"ξύλον\" (\"xulon\") \"wood\" and \"φαγεῖν\" (\"phagein\") \"to eat\", an ancient Greek name for a kind of a worm-eating bird. Animals feeding only on dead wood are called sapro-xylophagous or saproxylic.\n\nMost such animals are arthropods, primarily insects of various kinds, in which the behavior is quite common, and found in many different orders. It is not uncommon for insects to specialize to various degrees; in some cases, they limit themselves to certain plant groups (a taxonomic specialization), and in others, it is the physical characteristics of the wood itself (e.g., state of decay, hardness, whether the wood is alive or dead, or the choice of heartwood versus sapwood versus bark).\n\nMany xylophagous insects have symbiotic protozoa and/or bacteria in their digestive system which assist in the breakdown of cellulose; others (e.g., the termite family Termitidae) possess their own cellulase. Others, especially among the groups feeding on decaying wood, apparently derive much of their nutrition from the digestion of various fungi that are growing amidst the wood fibers. Such insects often carry the spores of the fungi in special structures on their bodies (called \"mycangia\"), and infect the host tree themselves when they are laying their eggs.\n\n"}
{"id": "4541988", "url": "https://en.wikipedia.org/wiki?curid=4541988", "title": "ZEUS-HLONS (HMMWV Laser Ordnance Neutralization System)", "text": "ZEUS-HLONS (HMMWV Laser Ordnance Neutralization System)\n\nThe HLONS (HMMWV Laser Ordnance Neutralization System), commonly known as ZEUS, is a solid-state laser weapon which is used by the U.S. military in order to neutralize surface land mines and unexploded ordnance. The ZEUS-HLONS system was a co-operative effort between Sparta Inc and NAVEODTECHDIV (Naval Explosive Ordnance Disposal Technology Division) to demonstrate that a moderate-power commercial solid state laser (SSL) and beam control system could be integrated onto a Humvee (HMMWV) and used to clear surface mines, improvised explosive devices (IEDs), or unexploded ordnance from supply routes and minefields.\n\nZEUS uses a 10 kW solid-state heat capacity (SSHC) laser beam to heat target ordnance to the point of causing the explosive filler to ignite and start to burn. Therefore, it does not depend on the type of fusing the specific ordnance uses. The resulting neutralization causes a low-level explosion that minimizes collateral damage.\n\nIt has demonstrated the capability to engage targets from 25 to 300 meters away, as long as they are in line of sight. The Zeus system can be fired up to 2,000 times a day.\n\nThe ZEUS-HLONS system offers a roll-on roll-off capability that is C-17 and C-130 transportable. It is also helicopter sling certified.\n\nThe two main people behind the project are Gerald Wilson (Directed Energy division of the U.S. Army Space and Missile Defense Command (SMDC)) and Owen Hofer (U.S. engineering firm SPARTA), which designed and built the system.\n\nPrior to the ZEUS-HLONS system, Explosive Ordnance Disposal (EOD) personnel would have to approach such munitions (either manually, or by robotic platform), place an explosive charge near it, and then detonate the charge to destroy the munitions - something they still have to do until laser neutralizing systems are commonplace. Using ZEUS is cheaper (a few cents per laser shot) and safer than the traditional method.\n\nLasers were theoretically evaluated for use in causing detonations of explosives in 1986 and laboratory demonstrations were done in 1987 with a 30 kW CO laser.\n\nBy 1991 demonstrations were done on landmines using a 0.3 kW laser and 0.8 kW CO laser.\n\nThe concept of laser neutralization of ordnance was demonstrated in 1994 with the design, development and live field testing of the Mobile Ordnance Disrupter System (MODS). MODS used an M113A2 armored personnel carrier that supported an 1100 watt arc lamp-pumped laser system. The program was funded by the U.S. Air Force at Eglin Air Force Base (Florida). This was then moved to fitting the system into a Humvee.\n\nZEUS is therefore the 2nd generation of this concept. Its development started in 1996 and was still undergoing upgrades and military demonstrations at the High Energy Laser Systems Test Facility (HELSTF) at White Sands Missile Range, New Mexico, in 2002 when it was requested to be deployed to Afghanistan (in December 2002 by General John M. Keane, Vice Chief of Staff of the Army 1999-2003).\n\nIn early 2004 the system was upgraded to a 1-kilowatt laser and then by late 2004 to a 2-kilowatt Yb:glass fibre-laser that is diode-pumped and operates in quasi-CW mode. This significantly reduced the overall system weight (removing about 2,000 pounds) and provided increased output beam power, which equates to extended range.\n\nIn January 2005, at the IQPC's Directed Energy Weapons conference in London, Gerald Wilson said the system takes between 5 seconds and 4 minutes (typically 30 seconds) to destroy a mine, resulting in a clearance rate of up to 25 explosives per hour when equipped with a 0.5 kW laser.\n\nOver its test and deployment history, ZEUS has eliminated more than 1,600 ordnance items of 40 different types with more than a 98% success rate.\n\nIn March 2003, ZEUS was deployed to Afghanistan for 6 months to demonstrate its counter-mine capabilities in a combat environment (Operation Enduring Freedom). It was used at Bagram Air Base and neutralized more than 200 munitions (including 51 in one 100 minute period) of 10 different types. At the time, the ZEUS-HLONS system was a 1/2 kilowatt laser.\n\nOn March 16, 2005, ZEUS was deployed to Iraq to assist in explosive ordnance disposal activities there as part of a three-vehicle convoy protection concept. The Zeus laser was tested and used in Iraq along MSR Tampa by a team of EOD soldiers from the 319th Ord Co (EOD), Tacoma, Washington in February and March 2005. The HLONS(Zeus) was added into the Hunter/Killer Project in an attempt to integrate EOD and Engineer resources. The project illustrated the shortcomings of the system with Counter IED (C-IED) operations. Chief among the limitations of the system was the inability to penetrate concealment materials to heat the explosives inside the ordnance, and the tendency of non EOD personnel to utilize the HLONS on all ordnance even if doing so created a more dangerous situation.\n\nIt is currently being used in Iraq by the U.S. military, in the first battlefield use of any laser weapon.\n\n\n"}
