{"id": "5527689", "url": "https://en.wikipedia.org/wiki?curid=5527689", "title": "2006 Auckland Blackout", "text": "2006 Auckland Blackout\n\nThe 2006 Auckland Blackout refers to the massive electrical blackout in Auckland, the largest city in New Zealand, on 12 June 2006. It started at 8:30 am local time, with most areas of Auckland regaining power by 2:45 pm local time. It affected some 230,000 customers and at least 700,000 people in and around the city.\n\nPower went off at around 08:30 am local time on 12 June 2006 over half of Auckland in New Zealand. Most of southern and central Auckland, including the central business district, were without power.\n\nThe cause of the blackout was traced back to the Otahuhu sub-station, the city's main transmission switching station. A corroded shackle connecting the Otahuhu to Penrose 220 kV line's earth wire had dislodged in winds, letting the earth wire fall across the 220 kV line and the 110 kV busbar below it, tripping both the line and three sections of the busbar, disconnecting lines to Mount Roskill, Penrose and Pakuranga. The trip also disconnected Otahuhu B and Southdown power stations from the national grid. The trip left only one line, the now-dismantled Arapuni to Pakuranga 110 kV line, supplying Pakuranga, Penrose, and the central city. Eight seconds after the failure, this line tripped from overloading, leaving Penrose, Pakuranga, and central city substations without power, as well as parts of Otahuhu and Mount Roskill substations.\n\nInvestigation of this incident found that maintenance of the electricity transmission system was not adequate and that this substation had major and minor design deficiencies.\n\nDue to the power outage, many public services and business operations were disrupted:\n\nSince the central business district was without power from the morning rush hours, business operations and traffic were disrupted severely. Many businesses sent their staff home.\n\nPower was restored to the central business district of Auckland at 12:40 local time, 12 June 2006. It was estimated that all affected areas would have their power restored by 16:30 local time. At approximately 14:45, power was restored to most of Auckland, except Penrose, Glen Innes, East Tamaki, and Otahuhu.\n\nThe incident at Otahuhu in June 2006 had a major influence on subsequent decisions about the development of the grid. \n\nOn 11 December 2006, the Electricity Commission (NZ) received an application from Transpower for the establishment of a new 220 kV gas insulated switchgear (GIS) facility at Otahuhu, adjacent to but geographically separate from the existing outdoor 220 kV switchyard. This project was described as the Otahuhu substation diversity project, and included transferring approximately half of the circuits from the existing switchyard to the new GIS switchyard, to improve network resilience. The project was approved in August 2007.\n\nFurther steps have been taken to increase security of supply to Auckland, by reducing the dependence on Otahuhu. These include the diversity provided as part of the North Island Grid Upgrade Project by connecting the new Whakamaru to Brownhill Road transmission line to Pakuranga substation, rather than directly to Otahuhu. A second major project, the North Auckland and Northland grid upgrade project provides underground 220 kV cables from Pakuranga to Penrose, and from Penrose to Albany on the North Shore, via Hobson Street in the Auckland CBD. A 220 kV- capable overhead transmission line between Pakuranga and Otahuhu has also been upgraded from 110 kV to 220 kV.\n\n\n \n"}
{"id": "33500986", "url": "https://en.wikipedia.org/wiki?curid=33500986", "title": "American Standard Safety System", "text": "American Standard Safety System\n\nThe American Standard Safety System, or ASSS, is a connection system for gas cylinders with a volume exceeding 25 cubic feet. The connections differ in thread type and size, right and left handed threading, internal and external threading, and nipple-seat design. This variability reduces the risk of errors such as administering the wrong gas to a patient, or utilizing equipment calibrated for one gas with another. However, as there are only 26 connections for the 62 gases and mixtures recognized by the CGA, connections are not unique.\n\nConnection specifications will be listed in cylinder catalogs as a list of abbreviations and numbers, such as that for O, CGA-540 0.903-14NGO-RH-Ext. This means that the Compressed Gas Association has classified this connection as number 540, the thread bore is 0.903 inches, with 14 threads per inch. The connection is right-handed (RH) and must be turned clock-wise to tighten. The threading is external, so the connections of the cylinder and the attached equipment must be fixed together using a nipple, which is signified by NGO. A nipple is a bolt which fits together two male connections. Internal (Int) threading allows for equipment to be screwed directly onto the cylinder outlet.\n\n"}
{"id": "39806131", "url": "https://en.wikipedia.org/wiki?curid=39806131", "title": "Barakah nuclear power plant", "text": "Barakah nuclear power plant\n\nThe Barakah nuclear power plant is the United Arab Emirates's first nuclear power station. It is still under construction, and four APR-1400 nuclear reactors are planned to start operation successively between 2018 and 2020. The site is on UAE's Persian Gulf coastline between the sea and the E11 highway, about 50 km west of Ruwais.\n\nIn December 2009, Emirates Nuclear Energy Corporation (ENEC) awarded a coalition led by Korea Electric Power Corporation (KEPCO) a $20 billion bid to build the first nuclear power plant in the UAE. Barakah was chosen as the site to build four APR-1400 nuclear reactors successively, with the first scheduled to start supplying electricity in 2017.\n\nThe plant's ground-breaking ceremony was held on 14 March 2011, including\nKorean President Lee Myung-bak.\nConstruction of the first unit was begun in the afternoon of 18 July 2012, ahead of its scheduled date in late 2012. This happened despite delays being mooted in the wake of the Fukushima Daiichi nuclear disaster. In May 2013 construction started on the second unit, which is expected to take five years. The first safety-related concrete was poured for Unit 3 in September 2014. Unit 4 started construction in September 2015. \n\nIn 2011 Bloomberg reported that following detailed finance agreements, the build cost was put at $30 billion: $10 billion equity, $10 billion export-credit agency debt, and $10 billion from bank and sovereign debt. South Korea may earn a further $20 billion from operation, maintenance and fuel supply contracts. A later Bloomberg report indicates the price as $25 billion. \n\nIn 2014 the Barakah 1 reactor vessel was delivered onsite and site preparation works for Barakah 3 and 4 started. Meanwhile, the concrete-and-steel reactor containment building for Barakah 1 was completed in January 2015.\n\nIn March 2015 ENEC applied to FANR for operating licences for Units 1 and 2. The schedule is still for operation of Unit 1 starting in 2017, with the remaining units following annually, so Unit 4 is set to reach commercial operations in 2020.\n\nIn September 2015 first concrete was poured for Unit 4. More than 18,000 staff were then working on the construction of all 4 units.\n\nIn December 2017 the rebel Houthis group claimed to have fired a cruise missile in the direction of the Barakah plant, but the Emirati authorities said that no missiles had actually reached the UAE.\n\nAs of March 22nd the project's total cost was refined to $24.4 billion to complete. Startup of Unit 1 has been delayed to late 2018 to complete operator training in accordance with international standards. \n\nAs of April 11th, 2018:\n\n\nOverall construction completion rate for the entire plant is at 87%.\n\n\n"}
{"id": "6494011", "url": "https://en.wikipedia.org/wiki?curid=6494011", "title": "Blown oil", "text": "Blown oil\n\nA blown oil is a drying oil which has been modified through an oxidative process.\n\nOils are \"blown\" through partial oxidation of the oil at elevated temperatures. A typical blowing process involves heating the oil to and passing air through the liquid. The modification causes the formation of C-O-C and C-C cross links, and hydroxyl and carboxyl functional groups.\n\nBlown oils are chemically different from oils modified only by heating, which are known as stand oils.\n\nSome common types of oils that can be blown include linseed oil, rapeseed oil, castor oil and soybean oil.\n"}
{"id": "232345", "url": "https://en.wikipedia.org/wiki?curid=232345", "title": "Butyric acid", "text": "Butyric acid\n\nButyric acid (from , meaning \"butter\"), also known under the systematic name butanoic acid, is a carboxylic acid with the structural formula CHCHCH-COOH. Salts and esters of butyric acid are known as butyrates or butanoates. Butyric acid is found in animal fat and plant oils, bovine milk, breast milk, butter, parmesan cheese, and as a product of anaerobic fermentation (including in the colon and as body odor). Butyric acid has a taste somewhat like butter and an unpleasant odor. Mammals with good scent detection abilities, such as dogs, can detect it at 10 parts per billion, whereas humans can only detect it in concentrations above 10 parts per million. In food manufacturing, it is used as a flavoring agent.\n\nButyric acid is a biologically active compound in humans. Butyric acid is one of two primary endogenous agonists of human hydroxycarboxylic acid receptor 2 (HCA), a G protein-coupled receptor.\n\nButyric acid is a fatty acid occurring in the form of esters in animal fats. The triglyceride of butyric acid makes up 3–4% of butter. When butter goes rancid, butyric acid is liberated from the glyceride by hydrolysis, leading to the unpleasant odor. It is one of the fatty acid subgroup called short-chain fatty acids. Butyric acid is a medium-strong acid that reacts with bases and affects many metals.\n\nThe acid is an oily, colorless liquid that is easily soluble in water, ethanol, and ether, and can be separated from an aqueous phase by saturation with salts such as calcium chloride. It is oxidized to carbon dioxide and acetic acid using potassium dichromate and sulfuric acid, while alkaline potassium permanganate oxidizes it to carbon dioxide. The calcium salt, Ca(CHO)·HO, is less soluble in hot water than in cold. Butyric acid has a structural isomer called isobutyric acid (2-methylpropanoic acid).\n\nPersonal protective equipment such as rubber or PVC gloves, protective eye goggles, and chemical-resistant clothing and shoes are used to minimize risks when handling butyric acid.\n\nInhalation of butyric acid may result in soreness of throat, coughing, a burning sensation, and laboured breathing. Ingestion of the acid may result in abdominal pain, shock, and collapse. Physical exposure to the acid may result in pain, blistering and skin burns, while exposure to the eyes may result in pain, severe deep burns and loss of vision.\n\nButyric acid was first observed in impure form in 1814 by the French chemist Michel Eugène Chevreul. By 1818, he had purified it sufficiently to characterize it. However, Chevreul did not publish his early research on butyric acid; instead, he deposited his findings in manuscript form with the secretary of the Academy of Sciences in Paris, France. Henri Braconnot, a French chemist, was also researching the composition of butter and was publishing his findings, and this led to disputes about priority. As early as 1815, Chevreul claimed that he had found the substance responsible for the smell of butter. By 1817, he published some of his findings regarding the properties of butyric acid and named it. However, it was not until 1823 that he presented the properties of butyric acid in detail. The name of butyric acid comes from the Latin word for butter, \"butyrum\" (or \"buturum\"), the substance in which butyric acid was first found.\n\nIndustrially, butyric acid is prepared by fermentation of sugar or starch, made more efficient by use of \"Clostridium tyrobutyricum\" in a process called catalytic upgrading. Salts and esters of the acid are called butyrates or butanoates. \n\nButyric acid or fermentation butyric acid is also present as the octyl ester (octyl butyrate) in parsnip (\"Pastinaca sativa\") and in the fruit of the ginko tree.\n\nButyric acid is used in the preparation of various butyrate esters. Low-molecular-weight esters of butyric acid, such as methyl butyrate, have mostly pleasant aromas or tastes. As a consequence, they are used as food and perfume additives. It is an approved food flavoring in the EU FLAVIS database (number 08.005).\n\nDue to its powerful odor, it has also been used as a fishing bait additive. Many of the commercially available flavors used in carp (\"Cyprinus carpio\") baits use butyric acid as their ester base; however, it is not clear whether fish are attracted by the butyric acid itself or the substances added to it. Butyric acid was, however, one of the few organic acids shown to be palatable for both tench and bitterling. The substance has also been used as a stink bomb by Sea Shepherd Conservation Society to disrupt Japanese whaling crews.\n\nButyric acid, along with acetic acid, can be reacted with cellulose to produce the organic ester cellulose acetate butyrate (CAB), which is used in a wide variety of tools, parts, and coatings, and is more resistant to degradation than cellulose acetate. However, CAB can degrade with exposure to heat and moisture, releasing butyric acid.\n\nButyrate is produced as end-product of a fermentation process solely performed by obligate anaerobic bacteria. Fermented Kombucha \"tea\" includes butyric acid as a result of the fermentation. This fermentation pathway was discovered by Louis Pasteur in 1861. Examples of butyrate-producing species of bacteria:\n\n\nThe pathway starts with the glycolytic cleavage of glucose to two molecules of pyruvate, as happens in most organisms. Pyruvate is then oxidized into acetyl coenzyme A using a unique mechanism that involves an enzyme system called . Two molecules of carbon dioxide (CO) and two molecules of elemental hydrogen (H) are formed as waste products from the cell. Then,\n\nATP is produced, as can be seen, in the last step of the fermentation. Three molecules of ATP are produced for each glucose molecule, a relatively high yield. The balanced equation for this fermentation is\n\nSeveral species form acetone and \"n\"-butanol in an alternative pathway, which starts as butyrate fermentation. Some of these species are:\n\nThese bacteria begin with butyrate fermentation, as described above, but, when the pH drops below 5, they switch into butanol and acetone production to prevent further lowering of the pH. Two molecules of butanol are formed for each molecule of acetone.\n\nThe change in the pathway occurs after acetoacetyl CoA formation. This intermediate then takes two possible pathways:\n\nHighly-fermentable fiber residues, such as those from resistant starch, oat bran, pectin, and guar are transformed by colonic bacteria into short-chain fatty acids (SCFA) including butyrate, producing more SCFA than less fermentable fibers such as celluloses. One study found that resistant starch consistently produces more butyrate than other types of dietary fiber. The production of SCFA from fibers in ruminant animals such as cattle is responsible for the butyrate content of milk and butter.\n\nFructans are another source of prebiotic soluble dietary fibers which can be digested to produce butyrate. They are often found in the soluble fibers of foods which are high in sulfur, such as the allium and cruciferous vegetables. Sources of fructans include wheat (although some wheat strains such as spelt contain lower amounts), rye, barley, onion, garlic, Jerusalem and globe artichoke, asparagus, beetroot, chicory, dandelion leaves, leek, radicchio, the white part of spring onion, broccoli, brussels sprouts, cabbage, fennel and prebiotics, such as fructooligosaccharides (FOS), oligofructose, and inulin.\n\nButyric acid is one of two primary endogenous agonists of human hydroxycarboxylic acid receptor 2 (HCA, aka GPR109A), a G protein-coupled receptor (GPCR),\n\nLike other short-chain fatty acids (SCFAs), butyrate is an agonist at the free fatty acid receptors FFAR2 and FFAR3, which function as nutrient sensors that facilitate the homeostatic control of energy balance; however, among the group of SCFAs, only butyrate is as an agonist of HCA. Butyric acid is metabolized by mitochondria, particularly in colonocytes and by the liver, to generate adenosine triphosphate (ATP) during fatty acid metabolism. Butyric acid is also an HDAC inhibitor (specifically, HDAC1, HDAC2, HDAC3, and HDAC8), a drug that inhibits the function of histone deacetylase enzymes, thereby favoring an acetylated state of histones in cells. Histone acetylation loosens the structure of chromatin by reducing the electrostatic attraction between histones and DNA. In general, it is thought that transcription factors will be unable to access regions where histones are tightly associated with DNA (i.e., non-acetylated, e.g., heterochromatin). Therefore, butyric acid is thought to enhance the transcriptional activity at promoters, which are typically silenced or downregulated due to histone deacetylase activity.\n\nButyrate that is produced in the colon through microbial fermentation of dietary fiber is primarily absorbed and metabolized by colonocytes and the liver for the generation of ATP during energy metabolism; however, some butyrate is absorbed in the distal colon, which is not connected to the portal vein, thereby allowing for the systemic distribution of butyrate to multiple organ systems through the circulatory system. Butyrate that has reached systemic circulation can readily cross the blood-brain barrier via monocarboxylate transporters (i.e., certain members of the SLC16A group of transporters). Other transporters that mediate the passage of butyrate across lipid membranes include SLC5A8 (SMCT1), SLC27A1 (FATP1), and SLC27A4 (FATP4).\n\nButyric acid is metabolized by various human XM-ligases (ACSM1, ACSM2B, ASCM3, ACSM4, ACSM5, and ACSM6), also known as butyrate–CoA ligase. The metabolite produced by this reaction is butyryl–CoA, and is produced as follows:\nAs a short-chain fatty acid, butyrate is metabolized by mitochondria as an energy (i.e., adenosine triphosphate or ATP) source through fatty acid metabolism.\n\nIn humans, the butyrate prodrug tributyrin is metabolized by triacylglycerol lipase into dibutyrin and butyrate through the reaction:\n\nButyrate has numerous effects on energy homeostasis and related diseases (diabetes and obesity), inflammation, and immune function (e.g., it has pronounced antimicrobial and anticarcinogenic effects) in humans. These effects occur through its metabolism by mitochondria to generate during fatty acid metabolism or through one or more of its histone-modifying enzyme targets (i.e., the class I histone deacetylases) and G-protein coupled receptor targets (i.e., FFAR2, FFAR3, and HCA).\n\nButyrate's effects on the immune system are mediated through the inhibition of class I histone deacetylases and activation of its G-protein coupled receptor targets: HCA (GPR109A), FFAR2 (GPR43), and FFAR3 (GPR41). Among the short-chain fatty acids, butyrate is the most potent promoter of intestinal regulatory T cells \"in vitro\" and the only one among the group that is an HCA ligand. It has been shown to be a critical mediator of the colonic inflammatory response. It possesses both preventive and therapeutic potential to counteract inflammation-mediated ulcerative colitis and colorectal cancer.\n\nButyrate has established antimicrobial properties in humans that are mediated through the antimicrobial peptide LL-37, which it induces via HDAC inhibition on histone H3. In vitro, butyrate increases gene expression of FOXP3 (the transcription regulator for ) and promotes colonic regulatory T cells (Tregs) through the inhibition of class I histone deacetylases; through these actions, it increases the expression of interleukin 10, an anti-inflammatory cytokine. Butyrate also suppresses colonic inflammation by inhibiting the IFN-γ–STAT1 signaling pathways, which is mediated partially through histone deacetylase inhibition. While transient IFN-γ signaling is generally associated with normal host immune response, chronic IFN-γ signaling is often associated with chronic inflammation. It has been shown that butyrate inhibits activity of HDAC1 that is bound to the Fas gene promoter in T cells, resulting in hyperacetylation of the Fas promoter and up-regulation of Fas receptor on the T-cell surface.\n\nSimilar to other HCA agonists studied, butyrate also produces marked anti-inflammatory effects in a variety of tissues, including the brain, gastrointestinal tract, skin, and vascular tissue. Butyrate binding at FFAR3 induces neuropeptide Y release and promotes the functional homeostasis of colonic mucosa and the enteric immune system.\n\nButyric acid is an important energy (ATP) source for cells lining the mammalian colon (colonocytes). Without butyric acid for energy, colon cells undergo upregulated autophagy (i.e., self-digestion).\n\nButyrate produces different effects in healthy and cancerous cells; this is known as the \"butyrate paradox\". In particular, butyrate inhibits colonic tumor cells and promotes healthy colonic epithelial cells. The signaling mechanism is not well understood. The production of volatile fatty acids such as butyrate from fermentable fibers may contribute to the role of dietary fiber in colon cancer. Short-chain fatty acids, which include butyric acid, are produced by beneficial colonic bacteria (probiotics) that feed on, or ferment prebiotics, which are plant products that contain dietary fiber. These short-chain fatty acids benefit the colonocytes by increasing energy production and cell proliferation, and may protect against colon cancer.\n\nConversely, some researchers have sought to eliminate butyrate and consider it a potential cancer driver. Studies in mice indicate it drives transformation of MSH2-deficient colon epithelial cells.\n\nA review on the relationship between the microbiome and diabetes asserted that butyrate can induce \"profound immunometabolic effects\" in animal models and humans with type 2 diabetes, although there is no such use in clinical practice and further research is needed.\n\nButyric acid is an inhibitor that is selective for class I HDACs in humans. HDACs are histone-modifying enzymes that can cause histone deacetylation and repression of gene expression. HDACs are important regulators of synaptic formation, synaptic plasticity, and long-term memory formation. Several HDACs (specifically, class I HDACs) are known to be involved in mediating the development of an addiction. Butyric acid and other HDAC inhibitors have been used in preclinical research to assess the transcriptional, neural, and behavioral effects of HDAC inhibition in animals addicted to drugs.\n\n"}
{"id": "11635906", "url": "https://en.wikipedia.org/wiki?curid=11635906", "title": "Choker setter", "text": "Choker setter\n\nA choker setter or choke setter is a logger who attaches cables to logs for retrieval by skidders or skylines. The work process involves the choker setter wrapping a special cable end (choker) around a log and then moving clear so the yarding engineer (e.g. skidder operator) can pull the log to a central area. In clearcutting, fallers will typically cut down all the trees and limb and buck them into logs before the choke setters and others arrive to remove the logs.\n\nOld chokers were made of metal. New chokers are safer, quicker and thus more productive. They are also radio controlled.\n\n\n\n"}
{"id": "46469202", "url": "https://en.wikipedia.org/wiki?curid=46469202", "title": "Chornobyl.3828", "text": "Chornobyl.3828\n\nChornobyl.3828 or Chernobyl.3828 is a 2011 Ukrainian documentary film about the Chernobyl disaster. Directed by Sergei Zabolotnyy, it is dedicated to the \"liquidators\" who were involved in cleaning the most dangerous areas of the plant roof, the \"M\" zone. The film is named for the 3,828 people who worked in this area.\n\nTwenty-five years have passed since Valeriy Starodumov worked as a dosimeter scout in September 1986. Valeriy worked at the epicenter of the explosion, the reactor's operation area, which was the most radioactive part of the site. The protagonist, a direct participant in the operation, went to the roof himself and brought people there after a failed attempt to clear the area with robots. At the government level, it was decided to assign soldiers and cadets of military schools to the task of cleaning the roofs. Unique pictures of the events of 1986 are widely used in the film. \"Chernobyl.3828\" is dedicated to people who saved the world from the radioactive contamination at the cost of their health and life.\n\nThe film director Sergei Zabolotnyy commented, \"We all know what happened on April 26, 1986 but we know next to nothing about the events of the summer and autumn of 1986. \"Chernobyl.3828\" is just one of many stories you need to know and remember.\"\n\n\n"}
{"id": "23637218", "url": "https://en.wikipedia.org/wiki?curid=23637218", "title": "Church Rock uranium mill spill", "text": "Church Rock uranium mill spill\n\nThe Church Rock uranium mill spill occurred in the US state of New Mexico on July 16, 1979, when United Nuclear Corporation's Church Rock uranium mill tailings disposal pond breached its dam. Over 1,000 tons of solid radioactive mill waste and 93 million gallons of acidic, radioactive tailings solution flowed into the Puerco River, and contaminants traveled downstream to Navajo County, Arizona and onto the Navajo Nation. The mill was located on privately owned land approximately 17 miles north of Gallup, New Mexico, and bordered to the north and southwest by Navajo Nation Tribal Trust lands. Local residents, who were mostly Navajos, used the Puerco River for irrigation and livestock and were not immediately aware of the toxic danger.\n\nThe accident is frequently described as having released more radioactivity than the Three Mile Island accident that occurred four months earlier and was the largest release of radioactive material in U.S. history. The spill contaminated groundwater and rendered the Puerco unusable by local residents. The governor of New Mexico refused the Navajo Nation's request that the site be declared a federal disaster area, limiting aid to affected residents. The event received less media coverage than that of Three Mile Island, likely because it occurred in a lightly populated, rural area. Some scholars suggest there were elements of class and racism to the neglect as well, since it affected primarily poor Native Americans.\n\nIn 2003 the Churchrock Chapter of the Navajo Nation began the Church Rock Uranium Monitoring Project to assess environmental impacts of abandoned uranium mines; it found significant radiation from both natural and mining sources in the area. The EPA National Priorities List currently includes the Church Rock tailings storage site, where \"groundwater migration is not under control.\"\n\nAt around 5:30 am on July 16, 1979, a 20-foot breach formed in the south cell of United Nuclear Corporation's Church Rock uranium mill tailings disposal pond, and 1,100 tons of solid radioactive mill waste and approximately of acidic, radioactive tailings solution flowed into Pipeline Arroyo, a tributary of the Puerco River. Though the uranium mill only bordered the Navajo Nation, the tailings spilled onto the Navajo Nation as they flowed down the Puerco River.\n\nThe tailings solution had a pH of 1.2 and a gross alpha particle activity of per liter, and contained radioactive uranium, thorium, radium, polonium, metals including cadmium, aluminium, magnesium, manganese, molybdenum, nickel, selenium, sodium, vanadium, zinc, iron, lead, and high concentrations of sulfates. The contaminated water from the Church Rock spill traveled downstream, through Gallup, New Mexico, and reached as far as Navajo County, Arizona. The flood backed up sewers, affected nearby aquifers, and left stagnating, contaminated pools on the riverside.\n\nAt 6:00 am, a United Nuclear Corporation employee noticed the breach and suspended further discharge of tailings solution to the holding pond. By 8:00, a temporary dike had stopped the flow of residual tailings solution.\n\nThe Indian Health Service and the Environmental Improvement Division of New Mexico warned local residents over the radio and with signs not to drink from, water livestock at, or enter the Puerco River, but many Navajos in the area didn't speak English or couldn't read and were unaware of the dangers of radiation. United Nuclear Corporation employees were dispatched to warn Navajo-speaking residents downstream in accordance with a state contingency plan, but not until a few days after the spill. The Navajo Nation asked the governor of New Mexico to request disaster assistance from the US government and have the site declared a disaster area, but he refused, limiting disaster relief assistance to the Navajo Nation.\n\nThe New Mexico Environmental Improvement Division said the spill's \"short-term and long-term impacts on people and the environment were quite limited.\" United Nuclear denied claims that the spill caused livestock deaths. The company said in a statement issued by an attorney, \"We just don't know of any substance to those claims. Some people aren't going to be satisfied no matter how thoroughly you show it.\"\n\nUnder the \"agreement state\" legislative framework of the Uranium Mill Tailings Radiation Control Act, the Nuclear Regulatory Commission left New Mexico to handle the dam failure until October 12, 1979, when it was notified that the state would permit the uranium mill to resume operation that week. The NRC then suspended United Nuclear's operating license until it could be determined that the embankment was stable. After fewer than four months of downtime following the dam failure, the mill resumed operations on . This further contaminated the groundwater and resulted in the mill site's placement on the EPA's National Priorities List in 1983. United Nuclear made a $525,000 out-of-court settlement with the Navajo Nation a year after the spill.\n\nIn terms of the amount of radioactivity released, the accident was larger in magnitude than the Three Mile Island accident of the same year. The spill has been called \"the largest radioactive accident in U.S. history,\" but the Nuclear Regulatory Commission has said that this is \"an overstatement,\" and that \"there have been a number of other events that have been more significant in terms of radiological impact. The event was more significant from an environmental perspective than from a human one.\"\n\nThe dam formed the southern wall of one of the mill's three holding ponds, which were used to evaporate tailings solution until the remaining solid waste could be buried. During its operation from 1967 to 1982, the mill produced 3.5 million tons of tailings at the rate of 4,000 tons a day. The 35-foot-high embankment was constructed on a deposit of collapsible clayey, silty sand a hundred feet deep. United Nuclear used a new design, recommended by the Nuclear Regulatory Commission, that used earth rather than tailings themselves as building material. The holding pond was not lined, in violation of standards in the Uranium Mill Tailings Radiation Control Act of 1978 that required that holding ponds be impermeable. This lack of lining allowed tailings solution to seep into the ground, weakening the foundation of the dam and contaminating the groundwater.\n\nHorizontal and vertical cracks formed along the southern part of the embankment, allowing the acidic tailings solution to penetrate and weaken the embankment. A sand beach was constructed to protect the face of the embankment from the tailings solution, but it was not properly maintained. Prior to the collapse, the level of the tailings solution in the holding pond had risen two feet higher than the dam's designed limit, and the sand beach no longer provided the dam protection. The United States Army Corps of Engineers concluded in its report to Governor Bruce King of New Mexico that the principal cause of failure was differential settlement of the foundation beneath the dam wall, and the report commissioned by the Nuclear Regulatory Commission corroborated this conclusion. Critical variations in tailings pond operation practice from approved procedures contributed further to the dam failure. United Nuclear's Chief Operating Officer, J. David Hann, blamed the failure of dam on the pointed shape of the bedrock beneath the embankment, which he said acted as a fulcrum and weakened the dam.\n\nCracks were first noted in the dam wall by independent consultants in December 1977 and were sealed with bentonite and kerosene slurry in February 1978. United Nuclear was notified of the cracking, but, aside from the initial seal, took little or no preventative action. United Nuclear did not make regular inspections of the dam despite strong recommendations by independent consultants that it do so. Further cracking was noted in October 1978. Neither the facility owner nor the State Engineer were formally notified of the episodes of cracking prior to the dam breach, though Arizona representative Morris K. Udall testified before Congress that at least three federal and state agencies had \"ample opportunity\" to predict that the dam's failure was likely. At the same Congressional hearing, the United States Army Corps of Engineers testified that United Nuclear ignored warnings from the Corps that the dam was structurally unsound.\n\nBoth New Mexico and Arizona were governed under the Uranium Mill Tailings Radiation Control Act as \"agreement states,\" meaning that they, not the Nuclear Regulatory Commission, were responsible for ensuring compliance with NRC standards. However, the states lacked the equipment and personnel to properly oversee tailings disposal sites statewide, and the ambiguity and drafting errors present in the act left them confused about how much regulatory power they had.\n\nShortly after the breach, below the dam radioactivity levels of river water were 7000 times that of the allowable level of drinking water. United Nuclear initially claimed that only one curie of radioactivity had been released in the spill, but that figure was later revised upward by the New Mexico Environmental Improvement Division. In all, of radioactivity were released.\n\nPrior to the spill, local residents used the riverside for recreation and herb-gathering, and children often waded in the Puerco River. Residents who waded in the river after the spill went to the hospital complaining of burning feet and were misdiagnosed with heat stroke. Burns acquired by some of those who came into contact with the contaminated water developed serious infections and required amputations. Herds of sheep and cattle died after drinking the contaminated water, and children played in pools of contaminated water. The spill contaminated shallow aquifers near the river that residents drank and used to water livestock. 1,700 people lost access to clean water after the spill. United Nuclear Corporation distributed 600 gallon-jugs of clean water, but the affected area required more than 30,000 gallons of water daily. The three community wells serving Church Rock had already been closed, one because of high radium levels and the other two for high levels of iron and bacteria. The Indian Health Service advised the tribe to repair five shallow wells along the Puerco River and said that the wells \"are not expected to show any contamination, if at all, for several years.\" The Navajo Nation spent $100,000 on clean water, and in 1981, the New Mexico and federal governments stopped providing water, which they had delivered by truck since the spill.\n\nAn epidemiological study conducted by the NMEID in 1989 concluded that \"the health risk to the public from eating exposed cattle is minimal, unless large amounts of this tissue, especially liver and kidney, are ingested.\" An Indian Health Service study found significantly higher levels of radionuclides in Church Rock cattle compared to livestock from non-mining areas. The study's authors advised that contamination would not pose a risk as long as residents did not depend on livestock for food over long periods of time, but local Navajos did. A few Navajo children were sent to Los Alamos to be checked for radiation exposure, but no long-term monitoring was undertaken, prompting a local writer to comment that the IHS spent more effort studying livestock than the people affected. No ongoing epidemiological studies have been done at Church Rock. Studies have shown since the 1950s that the Navajo have had significantly higher rates for some cancers than the national average, associated with contamination from the uranium mines and the exposure of workers to radiation.\n\nUnited Nuclear dispatched small crews with shovels and 55-gallon drums to begin cleanup, but expanded the workforce after complaints from local residents and pressure from the state. The crews removed three inches of sediment from the river bed, retrieving about of waste materials over the course of three months, but this amount was estimated as only 1% of the solid waste spilled. Groundwater remained contaminated by the spilled tailings solution, and rain transported leftover pollutants downstream into Arizona. New Mexico ordered United Nuclear to monitor pools left behind by the spill along the Puerco River, but United Nuclear only measured uranium levels, ignoring the presence of Th and Ra. The pools contained high levels of sulfuric acid and remained for more than a month after the spill, despite cleanup efforts by the New Mexico Environmental Improvement Division. The NMEID ordered United Nuclear to control tailings seepage from the mill in 1979, and the company implemented a limited seepage collective program in 1981.\n\nThe Navajo Nation appealed to the governor to request that the president declare the site a federal disaster area, but he refused, reducing the aid available to local residents. United Nuclear continued operation of the uranium mill until 1982, when it closed because of the declining uranium market.\n\nUnited Nuclear neutralized the acidity of the tailings with ammonia and lime from 1979 to 1982. In 1983, the site was entered on the National Priorities List of the Environmental Protection Agency's Superfund investigations and cleanup efforts, as radionuclides and chemical constituents were found to be contaminating local groundwater. The EPA conducted a remedial investigation from 1984 to 1987, and in the NRC approved United Nuclear's closure and reclamation plan in 1988.\n\nIn 1994 the EPA extended its efforts with a study of all known uranium mines on the Navajo Nation.\n\nThe EPA and United Nuclear removed of radium-contaminated soil surrounding five buildings, some residential, in 2007. The soil was moved to an off-site disposal facility.\n\nIn 2003 the Churchrock Chapter of the Navajo Nation began the Church Rock Uranium Monitoring Project to assess environmental impacts of abandoned uranium mines, and build capacity to conduct community-based research with policy implications. Its May 2007 report found significant radiation remaining in the area, from both natural and mining sources.\n\nIn 2008, the US Congress authorized a five-year plan for cleanup of contaminated uranium sites on the Navajo reservation. The non-profit Groundswell Educational Films is hosting online videos of the cleanup effort.\n\n\n"}
{"id": "6153352", "url": "https://en.wikipedia.org/wiki?curid=6153352", "title": "Cloud suck", "text": "Cloud suck\n\nCloud suck is a phenomenon commonly known in paragliding, hang gliding, and sailplane flying where pilots experience significant lift due to a thermal under the base of cumulus clouds, especially towering cumulus and cumulonimbus. The vertical extent of a cumulus cloud is a good indicator of the strength of lift beneath it, and the potential for cloud suck.\nCloud suck most commonly occurs in low pressure weather and in humid conditions.\n\nCloud suck is typically associated with an increase in thermal updraft velocity near cloud base. As a parcel of air lifted in a thermal rises, it also cools, and water vapour will eventually condense to form a cloud if the parcel rises above the lifted condensation level. As the water vapour condenses, it releases its latent heat of vaporization, thereby increasing the buoyancy of the parcel.\nThe updraft is amplified by this latent heat release. Although the process that causes this amplification happens above cloud base height, the effect is often noticeable as much as 300 m (1,000 feet) below cloud base. In fact, it is this effect \"below\" cloud base, not the effect \"within\" the cloud, that is generally referred to by pilots as cloud suck. The telltale signs for a pilot climbing in the thermal under a \"sucking\" cloud are (1) lift strengthening, (2) lift getting smoother, and (3) widening of the thermal.\n\nParaglider pilots have reported being unable to descend in strong cloud suck, even after bringing their canopies into deep spiral, which would normally result in a rapid vertical descent. Cloud suck is especially dangerous for paraglider pilots, whose maximum speed is less than 30 knots, because storm clouds (Cumulonimbus) can expand and develop rapidly over a large area with accompanying large areas of strong lift.\n\nOn 14 February 2007 while practising for a paragliding contest in Australia, Polish-born\nGerman team pilot Ewa Wiśnierska-Cieślewicz was sucked into a cumulonimbus cloud, climbing at up to 20 m per second (4,000 feet per minute)\nto an altitude of 9,946 m (32,600 feet). She lost consciousness due to hypoxia, but regained consciousness after 30 minutes to an hour, and landed still covered in ice after a three and a half hour flight. \n\nChinese paraglider pilot He Zhongpin died after he was sucked into the same storm system and struck by lightning at 5900 m (19,000 feet). His body was found the next day from his last known position prior to entering the cloud.\n\nIn 2014 Italian paraglider Paolo Antoniazzi, 66 years old retired Army general, died after being sucked into a thunderstorm.\n\nCompared with hang-gliders and paragliders, sailplanes have much higher top speeds (often over 250 km/h), and can more easily escape powerful cumulonimbus clouds by flying away quickly or by using very effective air brakes. A sailplane also has the added benefit of the pilot being able to put the sailplane into a spin to descend rapidly without over speeding. \nCloud suck is also a concern for powered aircraft but is usually not a lethal hazard, except in extreme weather situations. The USS \"Shenandoah\", the first rigid airship built in the United States, and the first in the world to be inflated with helium, was lost in a cloud suck accident associated with a squall line. At about 6:00 AM on 3 September 1925, near Ava in northern Noble County, Ohio, the \"Shenandoah\" was suddenly caught in a violent updraft while at an altitude of 2,100 feet, rising at the rate of a meter per second. At about 6,200 feet the ascent was checked, but the ship began to descend. When halfway to the ground it was hit by another updraft and began to rise rapidly at an even faster rate. Ultimately the keel snapped, and the ship broke up while still more than a mile above the ground. \"Shenandoah\"<nowiki>'</nowiki>s commanding officer and 13 other officers and men were killed. Twenty-nine members of the crew survived the break-up, although some received serious injuries.\n\n\n"}
{"id": "6515277", "url": "https://en.wikipedia.org/wiki?curid=6515277", "title": "Coastal warning display tower", "text": "Coastal warning display tower\n\nA coastal warning display tower, also known as a storm warning tower, is a type of signal station in the form of skeletal towers designed to provide warnings of hazardous wind conditions in coastal areas. The towers were developed in 1898 on the orders of President William McKinley. Through a system of flags, the towers can indicate not only wind-related warnings, but also major aspects of the local daily weather forecast.\n\nA single red pennant was shown from the top of the tower as a small craft advisory; for a gale warning, two such pennants were used. Two square flags, red with a black square at center, indicate an approaching hurricane or winds >73 MPH. One such flag warns of storm-force winds or an approaching tropical storm.\n\nThree lights, two red and one white, carry the signal at night. Red over white indicates a small craft advisory, white over red indicates a gale warning, red over red indicates a storm warning. All three lights together, red-white-red, warns of a hurricane or other hurricane-force wind event.\n\nOther flags can be used to indicate the direction of winds during a tropical storm or storm warning, to indicate the temperature change relative to the previous day, to warn of an approaching cold front, and to show the forecast coverage of precipitation (widespread fair weather, scattered precipitation, or widespread precipitation).\n\nThe system of towers is widely considered unnecessary today due to the prevalence of NOAA Weather Radio All Hazards, and few original towers survive. However, the system of using flags to indicate warnings related to strong winds in coastal areas remains in use by the U.S. Coast Guard, using ordinary flagpoles in lieu of the larger, more expensive, and more complex towers. At least one complete CWD tower, with all of its original equipment, remains in full operation in the city of Manteo, North Carolina.\n\n\n\n"}
{"id": "35598183", "url": "https://en.wikipedia.org/wiki?curid=35598183", "title": "Curbans Solar Park", "text": "Curbans Solar Park\n\nCurbans Solar Park is a 33 MW solar farm near Curbans, in France. It has 145,000 Yingli PV panels, and is located at an altitude of 1000 m.\n\n\n"}
{"id": "12603887", "url": "https://en.wikipedia.org/wiki?curid=12603887", "title": "Danelectro Amp-in-case", "text": "Danelectro Amp-in-case\n\nThe Danelectro Amp-In-Case, properly known as Solid-body Electric Guitar with \"All-in-one\" Amplifier-Case or Silvertone 1448/1449/1451/1452/1457 is a line of guitar sets introduced from 1962 to 1968. It was sold for US $67.95 (equivalent to approximately $ in today's funds), sometimes including a 45 rpm how-to-play record, as part of Sears Silvertone. It was later reissued in 2008 in modified form as the \"Dano '63\" without the amp-in-case. The Dano '63 was also available as a baritone guitar and a long- and short-scale bass guitar.\n\nThe amplifier is built into the top-half of the hard-shell guitar case. The first one, the 1448 series, was a simple 3-watt amplifier with 2 tubes plus 1 tube rectifier, 5-inch speaker, and gain control. In 1963, the 1449 series (later renamed 1457) was released, with a 5-watt amplifier with 3 tubes (and 1 tube rectifier) amplifier, with 8-inch speakers, gain, tone, tremolo (speed and strength), 2 inputs, and one foot-switch. The front end of the case has its top half covered in cloth for the speaker. In 1966, the amp-in-case comes with both the non-tremolo version 1451 (modified from 1448) and tremolo version 1452 (modified from 1449). Electronically they are identical, but the speakers are moved to the opposite lid.\n\nThe case is approx 37x15x3 inches. When the guitar is stored inside the case, with the speaker cloth facing upward, the guitar neck would sit on the left side of the amplifier.\n\nWhen first introduced in 1962, the 3/4-sized guitar had a double cutaway semi-hollow body in a shape similar to the well known Fender Stratocaster. The body was composed of a poplar center block and frame with Masonite top and back. It came with a single lipstick pickup at the \"middle\" position, controlled by a volume and tone knob. The poplar neck was fitted with a Brazilian rosewood fingerboard, and only had 18 frets. The neck connected to the body with three bolts.\n\nBy Fall of 1963, there was a two pickup model available. The new model 1449 was the same as its predecessor, but equipped with 2 lipstick pickups and a 21 fret neck. Eventually the semi-hollow guitar models were replaced with solid-body design similar to Danelectro's Dane line.\n\nThe guitar, minus the amp-in-case, was reissued by Evets Corporation for 2008 as the Dano '63. It is not an exact copy, but updated with modern materials and construction methods.\n\nSpecifications:\n\nThe Dano '63 was also available as a long- and short-scale bass and a baritone guitar.\n\nThe Amp-in-case amplifier has been redesigned and reissued in an amp head form by Fritz Brothers Guitars in Mendocino County, California. This new take on the original amp does not include the speaker, but can be run into a separate speaker cabinet, or through a larger PA system instead. It is primarily marketed to fit in a typical American hardshell Stratocaster style guitar case, but it can be custom built to fit other cases.\n\nThe Dano '63 Baritone was reviewed by several guitar magazines, and was well received. Guitar Player praised its clarity and tone and Guitarist magazine awarded it as a \"Guitarist Choice.\" In the May 2008 issue of Guitarist magazine, both of the Dano '63 basses were favorably reviewed, with the long scale being chosen as a \"Guitarist Choice.\"\nA bassist and a music journalist from Poland, Adam Pawlowski, noticed that the unmodified Dano '63 Baritone equipped with Ernie Ball 2837 strings' set is nothing else than the famous Danelectro's six-string bass tuned E-E, one octave below the guitar. That's because of its 29-5/8\" scale.\n\nFamous musicians such as Mick Jagger (of the Rolling Stones), Beck, Cat Power, Daniel Rossen of Grizzly Bear, Jeremy Earl of Woods (band) and Dexter Romweber (of the Flat Duo Jets), have made use of the Amp-in-case model live on stage, and Dave Grohl and Sammy Hagar both owned one as children.\n\n"}
{"id": "21397023", "url": "https://en.wikipedia.org/wiki?curid=21397023", "title": "Diderik Schnitler", "text": "Diderik Schnitler\n\nDiderik Børsting Schnitler (born 23 October 1946) is a Norwegian businessperson.\n\nHe hails from Stabekk, and in his younger days he was the treasurer and an active tennis player for Stabekk TK. He graduated from the Norwegian Institute of Technology with a Bachelor of Science degree in 1970. He was hired as an engineer in Jarlsø Støperi in 1974, and was chief executive from 1976 to 1983. He was the chief executive officer of Kaldnes from 1983 to 1986 and EB Anker Sønnak from 1986 to 1989. In the 1980s he was a board member of Larvik Jernstøperi, Vestfold Jernlager, EB Consultants and Scanmar and chair of Sandefjord Airport.\n\nHe was elected leader of the Federation of Norwegian Manufacturing Industries in 1989. He left that position already in October 1989. After the Norwegian parliamentary election, 1989, Syse's Cabinet assumed office, and Schnitler was appointed State Secretary in the Ministry of Industry. He belonged to the Conservative Party. He lost that job in 1990 when Syse's Cabinet fell, but immediately became president of Kværner Shipbuilding and vice president of the Kværner Group. He also served as president of the Confederation of Norwegian Enterprise from 1994 to 1996. From 1998 to 2000 he was the CEO of Saga Petroleum; he stepped down to become a professional board member. His period with Saga was disastrous for the company, after a series of unfavorable financial dispositions, and the company ceased to exist and was acquired by Norsk Hydro.\n\nSince 2002 he has chaired the board of the global shipping company Wilh. Wilhelmsen. In 2009 he became chair of Stabæk Holding.\n\nHe is a fellow of the Norwegian Academy of Technological Sciences.\n"}
{"id": "54641229", "url": "https://en.wikipedia.org/wiki?curid=54641229", "title": "EnPowered", "text": "EnPowered\n\nEnPowered is a Canadian energy management organization, established in 2015. The company groups together consumers and businesses to get a lower group-buying rate for energy and control their energy usage as well as costs.\n\nIt was founded by Tomas Van Stee in 2015 in Toronto, before moving to the Velocity Incubator at the University of Waterloo.\n\nIn the summer of 2016, EnPowered began working with consumers in Ontario in an open-beta.\n\nThe company introduced the group-buying system, where customers that use at least 50 percent of their electricity during the day are placed in one group. The group then turns into a larger volume with more customers added, allowing them to pay less.\nAccording to the company, users are mandated to sign up with their local hydro account number.\n"}
{"id": "3021822", "url": "https://en.wikipedia.org/wiki?curid=3021822", "title": "Fareham red brick", "text": "Fareham red brick\n\nFareham red brick is a famous red-tinged clay brick, from Fareham, Hampshire. Notable buildings constructed of these distinctive bricks include London's Royal Albert Hall and Knowle Hospital - previously known as Hampshire County Lunatic Asylum.\n"}
{"id": "3337860", "url": "https://en.wikipedia.org/wiki?curid=3337860", "title": "Formic acid fuel cell", "text": "Formic acid fuel cell\n\nFormic acid fuel cells (direct formic acid fuel cells or DFAFCs) are a subcategory of proton exchange membrane fuel cells where the fuel, formic acid, is not reformed, but fed directly to the fuel cell. Their applications include small, portable electronics such as phones and laptop computers as well as larger fixed power applications and vehicles.\n\nSimilar to methanol, formic acid is a small organic molecule fed directly into the fuel cell, removing the need for complicated catalytic reforming. Storage of formic acid is much easier and safer than that of hydrogen because it does not need to be done at high pressures and (or) low temperatures, as formic acid is a non-flammable liquid at standard temperature and pressure. Formic acid does not cross over the polymer membrane, so its efficiency can be higher than that of methanol. \n\nDFAFCs convert formic acid and oxygen into carbon dioxide and water to produce energy. Formic acid oxidation occurs at the anode on a catalyst layer. Carbon dioxide is formed and protons (H) are passed through the polymer membrane to react with oxygen on a catalyst layer located at the cathode. Electrons are passed through an external circuit from anode to cathode to provide power to an external device.\n\nDuring previous investigations, researchers dismissed formic acid as a practical fuel because of the high overpotential shown by experiments: this meant the reaction appeared to be too difficult to be practical. However, in 2005 - 2006, other researchers (in particular Richard Masel's group at the University of Illinois at Urbana-Champaign) found that the reason for the low performance was the usage of platinum as a catalyst, as it is common in most other types of fuel cells: using palladium instead, they claim to have obtained better performance than equivalent direct methanol fuel cells. As of April 2006, Tekion held the exclusive license to DFAFC fuel cell technology using PEM membranes and formic-acid fuel from the University of Illinois at Urbana-Champaign, and with an investment from Motorola, was partnering with BASF to design and manufacture power packs by late 2007, but development appears to have stalled, and almost all information was removed from Tekion's web site before April 24, 2010.\n\nNeah Power Systems, Inc. and Silent Falcon UAS Technologies will work together to integrate formic acid reformer fuel cell technology into the Silent Falcon's unmanned aerial system (UAS), aka \"drone\".\n\nIn 2018, work was published addressing the issue of requiring a high overpotential by way of golden single-atom-site platinum catalysts.\n"}
{"id": "2511921", "url": "https://en.wikipedia.org/wiki?curid=2511921", "title": "Formula Lightning", "text": "Formula Lightning\n\nFormula Lightning was an electric type of single-seat open-wheel formula racing. Rather unknown to the public, it was held for Colleges of Engineering student teams who built and designed these vehicles which were able to reach speeds up to and competed on both oval and road course type race tracks.\n\nEach participant in the Formula Lightning series purchased an identical rolling chassis, then designed and built the electric drive system for their vehicle. There were no changes allowed in the chassis design without majority approval of the Formula Lightning Owners Association. This ensured student teams could concentrate on the electric drive without the necessity of designing specialized mechanical chassis components.\n\nThese vehicles raced first in 1994 at the Grand Prix of Cleveland CART race and since then have participated in venues across the country. The final official series race was held in October 2004 at Mid-Ohio Sports Car Course.\n\nThe Ohio State University was the leading series champion.\n"}
{"id": "47489368", "url": "https://en.wikipedia.org/wiki?curid=47489368", "title": "GARN (company)", "text": "GARN (company)\n\nGARN is an American alternative energy company and manufacturer of smokeless wood-burning furnaces with integrated hydronic thermal storage.\n\nGARN pioneered wood gasification in conjunction with thermal storage in 1984, after GARN founder Martin Lunde developed the technology under a contract with the U.S. Department of Energy in the late 1970s, along with researchers Richard Snyder and James Buesing. Lunde was awarded patents in wood-fired hydronic storage in the early 1980s. \nIn April 2015, the GARN WHS-2000 was the first ever hydronic wood heater to pass the EPA's Phase II \"white tag\" certification using cord wood as fuel. \n\n"}
{"id": "23793839", "url": "https://en.wikipedia.org/wiki?curid=23793839", "title": "Global Earthquake Model", "text": "Global Earthquake Model\n\nThe Global Earthquake Model (GEM) is a public–private partnership initiated in 2006 by the Global Science Forum of the OECD to develop global, open-source risk assessment software and tools. With committed backing from academia, governments and industry, GEM contributes to achieving profound, lasting reductions in earthquake risk worldwide by following the priorities of the Hyogo Framework for Action. From 2009 to 2013 GEM is constructing its first working global earthquake model and will provide an authoritative standard for calculating and communicating earthquake risk worldwide.\n\nSince March 2009, GEM is a legal entity in the form of a non-profit foundation based in Pavia, Italy. The GEM Secretariat is hosted at the European Centre for Training and Research in Earthquake Engineering (EUCENTRE). The current secretary general is John Schneider.\n\nBetween 2000 and 2010 over half a million people died due to earthquakes and tsunamis, most of these in the developing world, where risks increase due to rapid population growth and urbanization. However, in many earthquake-prone regions no risk models exist, and even where models do exist, they are inaccessible. Better risk-awareness can reduce the toll that earthquakes take by leading to better construction, improved emergency response, and greater access to insurance.\n\nGEM will provide a basis for comparing earthquake risks across regions and across borders, and thereby take the necessary first step towards increased awareness and actions that reduce earthquake risk. GEM tools will be usable at the community, national and international level for uniform earthquake risk-evaluation and as a defensible basis for risk-mitigation plans. GEM results will be disseminated all over the world. GEM will build technical capacity and carry out awareness-raising activities.\n\nThe GEM scientific framework serves as the underlying basis for constructing the global earthquake model, and is organised in three principal integrated modules: seismic hazard, seismic risk and socio-economic impact.\n\n\nIt will take five years to build the first working global earthquake model – including corresponding tools, software and datasets. The work started in 2009 and will be finished at the end of 2013. Construction occurs in various stages that are partly overlapping in time. The pilot project GEM1 (January 2009 – March 2010) generates GEM’s first products and initial model building infrastructure, Global components will establish a common set of definitions, strategies, standards, quality criteria and formats for the compilation of databases that serve as an input to the global earthquake model. They are addressed by international consortia that respond to calls for proposals on hazard, risk and socio-economic impact. Global components will provide preliminary data on a global scale, but on a local scale, regional and national programmes will provide more detailed and reliable data. One Global component was the Global GMPEs project that proposed a set of ground motion prediction equations for use when calculating seismic hazard. Regional Programmes are projects with targeted funding taking place in various regions of the world; currently in the Middle East and Europe programs have already been completed. The data produced on a regional and national scale will be carefully quality-controlled and integrated into the global models. The actual development of the model will occur using a common, web-based platform for dynamic sharing of tools and resources, in order to create software and online tools as end-products. The global earthquake model will be tested and evaluated before its official release; the testing procedure will involve the establishment of scientific experiments that are reproducible, transparent, and set up within a controlled environment.\n\nGEM is however more than the creation and release of this first version of the model. GEM strives for continuous improvement of the model and will ensure that results are disseminated, technology is transferred through training and workshops and that awareness raising activities are deployed in order to contribute to risk reduction worldwide.\n\n\n"}
{"id": "9190950", "url": "https://en.wikipedia.org/wiki?curid=9190950", "title": "Global Environmental Citizen Award", "text": "Global Environmental Citizen Award\n\nThe Global Environmental Citizen Award is an environmental award created by the Harvard Medical School Center for Health and the Global Environment and bestowed annually upon an individual working to restore and protect the global environment.\n\nIn 2003, Primatologist Jane Goodall received Harvard’s annual Global Environmental Citizen Award. Goodall founded a program called “Take Care,” aimed at creating microcredit banks and educating conservation methods to inhabitants near the forest and national park. \n\nIn 2004, the award was given to Journalist Bill Moyers who has created discussion around the relation between the environment and various political trends, such as the discourse between environmental policy and religious right. Moyers’s acceptance made a connection between the rising Christian fundamentalism movement and environmental policies of the post-Columbine era.\n\nAl Gore, the 45th Vice President of the United States was the 2005 award recipient. Al Gore has long voiced his interests in the role of technology in environmental issues—from biomedical and genetic engineering to the socio-ecological effects of greenhouse gases.\n\nIn 2007, Charles, Prince of Wales was presented with the Global Environmental Citizen Award for his work towards preserving the environment. In 1990, Charles prince started Duchy Originals, a company dedicated in providing small farmers new markets to sell their goods and delivering high-quality organic goods through more sustainable production methods. Since then, Duchy Originals has rapidly grown to profit more than £1 million annually, becoming one of the most well-known and prosperous natural brands in the United Kingdom. For decades, the prince has voiced concerns about the dangerous risks of genetically modified foods, advocated for research into chemical farming and its effects on human health, launched numerous development projects in rural communities, and fostered corporate responsibility toward the environment. The prince has actively called for the improvement of energy efficiency and reduction of toxic discharge. In his award speech, the prince addressed the role of the British government in recognizing climate change as an upmost global priority.\n\nIn 2008, Kofi Annan and Alice Waters received the Award for their contributions to sustainable living and agricultural production. Kofi Annan has led the Millennium Ecosystem Assessment as Secretary-General of the United Nations, served as the President of the Global Humanitarian Forum and now serves as Chair of the Alliance for Africa’s Green Revolution. Alice Waters, founder of Chez Panisse Foundation, has established an organic classroom, The Edible Schoolyard in Berkeley, California, providing a space for students of all ages to tend land, harvest their crops and prepare food fresh from the garden. As a chef, Waters has long advocated for sustainably produced local goods and empowerment of youth through educational food programs.\n\nSource: Harvard College\n\n"}
{"id": "4193327", "url": "https://en.wikipedia.org/wiki?curid=4193327", "title": "HELRAM", "text": "HELRAM\n\nThe Northrop Grumman High Energy Laser for Rockets, Artillery and Mortars (HELRAM) system is a ground-based directed energy weapon intended to be used mainly against short-range ballistic targets.\n\nIt is supposed to be able to shoot down mortar bombs, rocket-propelled mortar bombs, artillery shells and artillery rockets by pointing a high-energy laser beam at them, thereby causing them to explode in the air.\n\nNorthrop Grumman unveiled the HELRAM concept in October 2004, saying that it \"could be available within 18 months of a contract\".\n\nIts technology is based on that of the THEL system.\n\n\n"}
{"id": "20898670", "url": "https://en.wikipedia.org/wiki?curid=20898670", "title": "Henri Deutsch de la Meurthe", "text": "Henri Deutsch de la Meurthe\n\nHenri Deutsch de la Meurthe (1846, Paris – 1919), born Salomon Henry Deutsch, was a successful French petroleum businessman (known as the \"Oil King of Europe\") and an avid supporter of early aviation. He sponsored a number of prizes to encourage the development of aviation technologies, including the Grand Prix d'Aviation and the Deutsch de la Meurthe prize.\n\nThe Deutsch de la Meurthe was a French family known for its wealth and patronage in technology and philanthropy, having helped develop the industrial oils industry in France. In 1845 Alexander Deutsch founded a company for the processing and marketing of vegetable oils in La Villette, then an independent commune of Paris. With the discovery of petroleum oil in Pennsylvania in 1859, Deutsch began to study and develop the use of petroleum oils in France. In 1877 Deutsch brought his two sons, Henri and Emile, into the family business, which bought a refinery in Rouen in 1881 and another in St. Loubès in Gironde in 1883. In 1889, in association with the Rothschild brothers, oil refining began in Spain. At this time Alexander added the \"de la Meurthe\" to the family name.\nHenri recognized that the future of petroleum sales depended on the development of small internal-combustion engines, and so he promoted automobile development (he presented French President Marie François Sadi Carnot with an automobile) and also became interested in aviation. Together with Ernest Archdeacon he founded the \"Aéro-Club de France\" to promote the new technologies. In order to do this, he used some of his wealth to create a number of monetary prizes as incentives for aviators to achieve certain aviation milestones.\n\nIn 1906 Deutsch entered into a partnership with Wilbur Wright and Hart Berg to establish a company in France to supply a Wright aircraft to the French government. Deutsch financed the venture by buying the only block of shares to be sold in France, and used his influence with the French government. The effort fell through, however.\n\nHe supported Lazare Weiller, who bought the patents of the Wright brothers and organized demonstration flights piloted by Wilbur Wright in Le Mans which began on 8 August 1908. Deutsch de la Meurthe also invested in aircraft builders Société Astra (1909) and Nieuport (1911), and commissioned the construction of aircraft, including the Blériot XXIV \"Limousine and the Voisin 'Aero-Yacht'.\n\nAt the end of May 1909, Henri Deutsch de la Meurthe offered the University of Paris a sum of 500,000 francs and an annual pension of 15,000 francs for the creation and maintenance of the \"Institute Aérotechnique\" at Saint-Cyr-l'École, which would continue the theoretical research and development of air transport aircraft. It was later integrated into the Conservatoire National des Arts et Métiers.\n\nAlthough an enthusiastic promoter of heavier-than air flight, De la Meurthe did not make his first flight in an airplane until May 1911, when he was taken for a flight in a Blériot monoplane piloted by Alfred Leblanc.\nOn 21 May 1911, Deutsch was injured and French Minister of War Maurice Berteaux was killed when a Train monoplane crashed at the beginning of the 1911 Paris to Madrid air race.\n\nHenri Deutsch de la Meurthe was made Commander of the Legion of Honor on November 20, 1912.\n\nIn April 1900, Henri offered the Deutsch de la Meurthe prize, also simply known as the Deutsch prize, of 100,000 francs to the first machine capable of flying a round trip from the Parc Saint Cloud to the Eiffel Tower in Paris and back in less than thirty minutes. The winner of the prize needed to maintain an average ground speed of at least to cover the round trip distance of in the allotted time. The prize was to be available from May 1, 1900 to October 1, 1903.\n\nTo win the prize, Alberto Santos-Dumont decided to build the Santos-Dumont No. 5, a larger airship than his earlier craft. On August 8, 1901 during one of his attempts, the dirigible began to lose hydrogen gas. It started to descend and was unable to clear the roof of the Trocadero Hotel. Santos-Dumont was left hanging in a basket from the side of the hotel. With the help of the Paris fire brigade he climbed to the roof without injury.\n\nOn October 19, 1901, after several attempts and trials, Santos-Dumont launched his \"Number 6\" airship at 2:30 pm. After only nine minutes of flight, Santos-Dumont had rounded the Eiffel Tower, but then suffered an engine failure. To restart the engine, he had to climb back over the gondola rail without a safety harness. The attempt was successful, and he crossed the finish line in 29 minutes 30 seconds. However, there was a short delay before his mooring line was secured, and at first the adjudicating committee refused him the prize, despite de la Meurthe, who was present, declaring himself satisfied. This caused a public outcry from the crowds watching the flight, as well as comment in the press. However a face-saving compromise was reached, and Santos-Dumont was awarded the prize. In a charitable gesture, he gave half the prize to his crew and then donated the other half to the poor of Paris.\n\nIn 1904, Deutsch de la Meurthe in collaboration with Ernest Archdeacon created the \"Grand Prix d'Aviation\" (also known as the \"Deutsch-Archdeacon Prize\"), a prize of 50,000 francs for the first person to fly a circular 1-kilometer course in a heavier-than-air craft. It was won on January 13, 1908 by Henry Farman flying a Voisin biplane at Issy-les-Moulineaux in a time of 1 minute 28 seconds, then a distance and speed record since the flights of the Wright Brothers had not been officially witnessed.\n\nThis speed race was held intermittently from 1912-1936, with 20,000 francs offered first by Deutsch, later by the Aéro-Club de France.\n\nPlace des États-Unis\n"}
{"id": "43421", "url": "https://en.wikipedia.org/wiki?curid=43421", "title": "Henry David Thoreau", "text": "Henry David Thoreau\n\nHenry David Thoreau (see name pronunciation; July 12, 1817 – May 6, 1862) was an American essayist, poet, philosopher, abolitionist, naturalist, tax resister, development critic, surveyor, and historian. A leading transcendentalist, Thoreau is best known for his book \"Walden\", a reflection upon simple living in natural surroundings, and his essay \"Civil Disobedience\" (originally published as \"Resistance to Civil Government\"), an argument for disobedience to an unjust state.\n\nThoreau's books, articles, essays, journals, and poetry amount to more than 20 volumes. Among his lasting contributions are his writings on natural history and philosophy, in which he anticipated the methods and findings of ecology and environmental history, two sources of modern-day environmentalism. His literary style interweaves close observation of nature, personal experience, pointed rhetoric, symbolic meanings, and historical lore, while displaying a poetic sensibility, philosophical austerity, and Yankee attention to practical detail. He was also deeply interested in the idea of survival in the face of hostile elements, historical change, and natural decay; at the same time he advocated abandoning waste and illusion in order to discover life's true essential needs.\n\nHe was a lifelong abolitionist, delivering lectures that attacked the Fugitive Slave Law while praising the writings of Wendell Phillips and defending the abolitionist John Brown. Thoreau's philosophy of civil disobedience later influenced the political thoughts and actions of such notable figures as Leo Tolstoy, Mahatma Gandhi, and Martin Luther King Jr.\n\nThoreau is sometimes referred to as an anarchist. Though \"Civil Disobedience\" seems to call for improving rather than abolishing government—\"I ask for, not at once no government, but \"at once\" a better government\"—the direction of this improvement contrarily points toward anarchism: \"'That government is best which governs not at all;' and when men are prepared for it, that will be the kind of government which they will have.\"\n\nAmos Bronson Alcott and Thoreau's aunt each wrote that \"Thoreau\" is pronounced like the word \"thorough\" ( —in General American, but more precisely —in 19th-century New England). Edward Waldo Emerson wrote that the name should be pronounced \"Thó-row\", with the \"h\" sounded and stress on the first syllable. Among modern-day American speakers, it is perhaps more commonly pronounced —with stress on the second syllable.\n\nThoreau had a distinctive appearance, with a nose that he called his \"most prominent feature\". Of his appearance and disposition, Ellery Channing wrote:\n\nHis face, once seen, could not be forgotten. The features were quite marked: the nose aquiline or very Roman, like one of the portraits of Caesar (more like a beak, as was said); large overhanging brows above the deepest set blue eyes that could be seen, in certain lights, and in others gray,—eyes expressive of all shades of feeling, but never weak or near-sighted; the forehead not unusually broad or high, full of concentrated energy and purpose; the mouth with prominent lips, pursed up with meaning and thought when silent, and giving out when open with the most varied and unusual instructive sayings.\n\nHenry David Thoreau was born David Henry Thoreau in Concord, Massachusetts, into the \"modest New England family\" of John Thoreau, a pencil maker, and Cynthia Dunbar. His paternal grandfather had been born on the UK crown dependency island of Jersey. His maternal grandfather, Asa Dunbar, led Harvard's 1766 student \"Butter Rebellion\", the first recorded student protest in the American colonies. David Henry was named after his recently deceased paternal uncle, David Thoreau. He began to call himself Henry David after he finished college; he never petitioned to make a legal name change. He had two older siblings, Helen and John Jr., and a younger sister, Sophia. Thoreau's birthplace still exists on Virginia Road in Concord. The house has been restored by the Thoreau Farm Trust, a nonprofit organization, and is now open to the public.\n\nHe studied at Harvard College between 1833 and 1837. He lived in Hollis Hall and took courses in rhetoric, classics, philosophy, mathematics, and science. He was a member of the Institute of 1770 (now the Hasty Pudding Club). According to legend, Thoreau refused to pay the five-dollar fee (approximately ) for a Harvard diploma. In fact, the master's degree he declined to purchase had no academic merit: Harvard College offered it to graduates \"who proved their physical worth by being alive three years after graduating, and their saving, earning, or inheriting quality or condition by having Five Dollars to give the college.\" He commented, \"Let every sheep keep its own skin\", a reference to the tradition of using sheepskin vellum for diplomas.\n\nThe traditional professions open to college graduates—law, the church, business, medicine—did not interest Thoreau, so in 1835 he took a leave of absence from Harvard, during which he taught school in Canton, Massachusetts. After he graduated in 1837, he joined the faculty of the Concord public school, but he resigned after a few weeks rather than administer corporal punishment. He and his brother John then opened the Concord Academy, a grammar school in Concord, in 1838. They introduced several progressive concepts, including nature walks and visits to local shops and businesses. The school closed when John became fatally ill from tetanus in 1842 after cutting himself while shaving. He died in Henry's arms.\n\nUpon graduation Thoreau returned home to Concord, where he met Ralph Waldo Emerson through a mutual friend. Emerson, who was 14 years his senior, took a paternal and at times patron-like interest in Thoreau, advising the young man and introducing him to a circle of local writers and thinkers, including Ellery Channing, Margaret Fuller, Bronson Alcott, and Nathaniel Hawthorne and his son Julian Hawthorne, who was a boy at the time.\n\nEmerson urged Thoreau to contribute essays and poems to a quarterly periodical, \"The Dial\", and lobbied the editor, Margaret Fuller, to publish those writings. Thoreau's first essay published in \"The Dial\" was \"Aulus Persius Flaccus,\" an essay on the Roman playwright, in July 1840. It consisted of revised passages from his journal, which he had begun keeping at Emerson's suggestion. The first journal entry, on October 22, 1837, reads, \"'What are you doing now?' he asked. 'Do you keep a journal?' So I make my first entry to-day.\"\n\nThoreau was a philosopher of nature and its relation to the human condition. In his early years he followed Transcendentalism, a loose and eclectic idealist philosophy advocated by Emerson, Fuller, and Alcott. They held that an ideal spiritual state transcends, or goes beyond, the physical and empirical, and that one achieves that insight via personal intuition rather than religious doctrine. In their view, Nature is the outward sign of inward spirit, expressing the \"radical correspondence of visible things and human thoughts\", as Emerson wrote in \"Nature\" (1836).\n\nOn April 18, 1841, Thoreau moved into the Emerson house. There, from 1841 to 1844, he served as the children's tutor; he was also an editorial assistant, repairman and gardener. For a few months in 1843, he moved to the home of William Emerson on Staten Island, and tutored the family's sons while seeking contacts among literary men and journalists in the city who might help publish his writings, including his future literary representative Horace Greeley.\n\nThoreau returned to Concord and worked in his family's pencil factory, which he would continue to do alongside his writing and other work for most of his adult life. He rediscovered the process of making good pencils with inferior graphite by using clay as the binder. This invention allowed profitable use of a graphite source found in New Hampshire that had been purchased in 1821 by Thoreau's brother-in-law, Charles Dunbar. The process of mixing graphite and clay, known as the Conté process, had been first patented by Nicolas-Jacques Conté in 1795. The company's other source of graphite had been Tantiusques, a mine operated by Native Americans in Sturbridge, Massachusetts. Later, Thoreau converted the pencil factory to produce plumbago, a name for graphite at the time, which was used in the electrotyping process.\n\nOnce back in Concord, Thoreau went through a restless period. In April 1844 he and his friend Edward Hoar accidentally set a fire that consumed of Walden Woods.\n\nThoreau felt a need to concentrate and work more on his writing. In March 1845, Ellery Channing told Thoreau, \"Go out upon that, build yourself a hut, & there begin the grand process of devouring yourself alive. I see no other alternative, no other hope for you.\" Two months later, Thoreau embarked on a two-year experiment in simple living on July 4, 1845, when he moved to a small house he had built on land owned by Emerson in a second-growth forest around the shores of Walden Pond. The house was in \"a pretty pasture and woodlot\" of that Emerson had bought, from his family home.\nOn July 24 or July 25, 1846, Thoreau ran into the local tax collector, Sam Staples, who asked him to pay six years of delinquent poll taxes. Thoreau refused because of his opposition to the Mexican–American War and slavery, and he spent a night in jail because of this refusal. The next day Thoreau was freed when someone, likely to have been his aunt, paid the tax, against his wishes. The experience had a strong impact on Thoreau. In January and February 1848, he delivered lectures on \"The Rights and Duties of the Individual in relation to Government\", explaining his tax resistance at the Concord Lyceum. Bronson Alcott attended the lecture, writing in his journal on January 26:\n\nThoreau revised the lecture into an essay titled \"Resistance to Civil Government\" (also known as \"Civil Disobedience\"). It was published by Elizabeth Peabody in the \"Aesthetic Papers\" in May 1849. Thoreau had taken up a version of Percy Shelley's principle in the political poem \"The Mask of Anarchy\" (1819), which begins with the powerful images of the unjust forms of authority of his time and then imagines the stirrings of a radically new form of social action.\n\nAt Walden Pond, Thoreau completed a first draft of \"A Week on the Concord and Merrimack Rivers\", an elegy to his brother John, describing their trip to the White Mountains in 1839. Thoreau did not find a publisher for the book and instead printed 1,000 copies at his own expense; fewer than 300 were sold. He self-published the book on the advice of Emerson, using Emerson's publisher, Munroe, who did little to publicize the book.\n\nIn August 1846, Thoreau briefly left Walden to make a trip to Mount Katahdin in Maine, a journey later recorded in \"Ktaadn\", the first part of \"The Maine Woods\".\n\nThoreau left Walden Pond on September 6, 1847. At Emerson's request, he immediately moved back to the Emerson house to help Emerson's wife, Lidian, manage the household while her husband was on an extended trip to Europe. Over several years, as he worked to pay off his debts, he continuously revised the manuscript of what he eventually published as \"Walden, or Life in the Woods\" in 1854, recounting the two years, two months, and two days he had spent at Walden Pond. The book compresses that time into a single calendar year, using the passage of the four seasons to symbolize human development. Part memoir and part spiritual quest, \"Walden\" at first won few admirers, but later critics have regarded it as a classic American work that explores natural simplicity, harmony, and beauty as models for just social and cultural conditions.\n\nThe American poet Robert Frost wrote of Thoreau, \"In one book ... he surpasses everything we have had in America.\"\n\nThe American author John Updike said of the book, \"A century and a half after its publication, Walden has become such a totem of the back-to-nature, preservationist, anti-business, civil-disobedience mindset, and Thoreau so vivid a protester, so perfect a crank and hermit saint, that the book risks being as revered and unread as the Bible.\"\n\nThoreau moved out of Emerson's house in July 1848 and stayed at a house on nearby Belknap Street. In 1850, he and his family moved into a house at 255 Main Street, where he lived until his death.\n\nIn the summer of 1850, Thoreau and Channing journeyed from Boston to Montreal and Quebec City. These would be Thoreau's only travels outside the United States. It is as a result of this trip that he developed lectures that eventually became \"A Yankee in Canada\". He jested that all he got from this adventure \"was a cold.\" In fact, this proved an opportunity to contrast American civic spirit and democratic values with a colony apparently ruled by illegitimate religious and military power. Whereas his own country had had its revolution, in Canada history had failed to turn.\n\nIn 1851, Thoreau became increasingly fascinated with natural history and narratives of travel and expedition. He read avidly on botany and often wrote observations on this topic into his journal. He admired William Bartram and Charles Darwin's \"Voyage of the Beagle\". He kept detailed observations on Concord's nature lore, recording everything from how the fruit ripened over time to the fluctuating depths of Walden Pond and the days certain birds migrated. The point of this task was to \"anticipate\" the seasons of nature, in his word.\n\nHe became a land surveyor and continued to write increasingly detailed observations on the natural history of the town, covering an area of , in his journal, a two-million-word document he kept for 24 years. He also kept a series of notebooks, and these observations became the source of his late writings on natural history, such as \"Autumnal Tints\", \"The Succession of Trees\", and \"Wild Apples\", an essay lamenting the destruction of indigenous wild apple species.\n\nUntil the 1970s, literary critics dismissed Thoreau's late pursuits as amateur science and philosophy. With the rise of environmental history and ecocriticism as academic disciplines, several new readings of Thoreau began to emerge, showing him to have been both a philosopher and an analyst of ecological patterns in fields and woodlots. For instance, his late essay \"The Succession of Forest Trees\" shows that he used experimentation and analysis to explain how forests regenerate after fire or human destruction, through the dispersal of seeds by winds or animals.\nHe traveled to Canada East once, Cape Cod four times, and Maine three times; these landscapes inspired his \"excursion\" books, \"A Yankee in Canada\", \"Cape Cod\", and \"The Maine Woods\", in which travel itineraries frame his thoughts about geography, history and philosophy. Other travels took him southwest to Philadelphia and New York City in 1854 and west across the Great Lakes region in 1861, when he visited Niagara Falls, Detroit, Chicago, Milwaukee, St. Paul and Mackinac Island. He was provincial in his own travels, but he read widely about travel in other lands. He devoured all the first-hand travel accounts available in his day, at a time when the last unmapped regions of the earth were being explored. He read Magellan and James Cook; the arctic explorers John Franklin, Alexander Mackenzie and William Parry; David Livingstone and Richard Francis Burton on Africa; Lewis and Clark; and hundreds of lesser-known works by explorers and literate travelers. Astonishing amounts of reading fed his endless curiosity about the peoples, cultures, religions and natural history of the world and left its traces as commentaries in his voluminous journals. He processed everything he read, in the local laboratory of his Concord experience. Among his famous aphorisms is his advice to \"live at home like a traveler.\"\n\nAfter John Brown's raid on Harpers Ferry, many prominent voices in the abolitionist movement distanced themselves from Brown or damned him with faint praise. Thoreau was disgusted by this, and he composed a key speech, \"A Plea for Captain John Brown\", which was uncompromising in its defense of Brown and his actions. Thoreau's speech proved persuasive: the abolitionist movement began to accept Brown as a martyr, and by the time of the American Civil War entire armies of the North were literally singing Brown's praises. As a biographer of Brown put it, \"If, as Alfred Kazin suggests, without John Brown there would have been no Civil War, we would add that without the Concord Transcendentalists, John Brown would have had little cultural impact.\"\nThoreau contracted tuberculosis in 1835 and suffered from it sporadically afterwards. In 1860, following a late-night excursion to count the rings of tree stumps during a rainstorm, he became ill with bronchitis. His health declined, with brief periods of remission, and he eventually became bedridden. Recognizing the terminal nature of his disease, Thoreau spent his last years revising and editing his unpublished works, particularly \"The Maine Woods\" and \"Excursions\", and petitioning publishers to print revised editions of \"A Week\" and \"Walden\". He wrote letters and journal entries until he became too weak to continue. His friends were alarmed at his diminished appearance and were fascinated by his tranquil acceptance of death. When his aunt Louisa asked him in his last weeks if he had made his peace with God, Thoreau responded, \"I did not know we had ever quarreled.\"\nAware he was dying, Thoreau's last words were \"Now comes good sailing\", followed by two lone words, \"moose\" and \"Indian\". He died on May 6, 1862, at age 44. Amos Bronson Alcott planned the service and read selections from Thoreau's works, and Channing presented a hymn. Emerson wrote the eulogy spoken at the funeral. Thoreau was buried in the Dunbar family plot; his remains and those of members of his immediate family were eventually moved to Sleepy Hollow Cemetery () in Concord, Massachusetts.\n\nThoreau's friend William Ellery Channing published his first biography, \"Thoreau the Poet-Naturalist\", in 1873. Channing and another friend, Harrison Blake, edited some poems, essays, and journal entries for posthumous publication in the 1890s. Thoreau's journals, which he often mined for his published works but which remained largely unpublished at his death, were first published in 1906 and helped to build his modern reputation. A new, expanded edition of the journals is under way, published by Princeton University Press. Today, Thoreau is regarded as one of the foremost American writers, both for the modern clarity of his prose style and the prescience of his views on nature and politics. His memory is honored by the international Thoreau Society and his legacy honored by the Thoreau Institute at Walden Woods, established in 1998 in Lincoln, Massachusetts.\n\nThoreau was an early advocate of recreational hiking and canoeing, of conserving natural resources on private land, and of preserving wilderness as public land. He was himself a highly skilled canoeist; Nathaniel Hawthorne, after a ride with him, noted that \"Mr. Thoreau managed the boat so perfectly, either with two paddles or with one, that it seemed instinct with his own will, and to require no physical effort to guide it.\" \n\nHe was not a strict vegetarian, though he said he preferred that diet and advocated it as a means of self-improvement. He wrote in \"Walden\", \"The practical objection to animal food in my case was its uncleanness; and besides, when I had caught and cleaned and cooked and eaten my fish, they seemed not to have fed me essentially. It was insignificant and unnecessary, and cost more than it came to. A little bread or a few potatoes would have done as well, with less trouble and filth.\"\nThoreau neither rejected civilization nor fully embraced wilderness. Instead he sought a middle ground, the pastoral realm that integrates nature and culture. His philosophy required that he be a didactic arbitrator between the wilderness he based so much on and the spreading mass of humanity in North America. He decried the latter endlessly but felt that a teacher needs to be close to those who needed to hear what he wanted to tell them. The wildness he enjoyed was the nearby swamp or forest, and he preferred \"partially cultivated country.\" His idea of being \"far in the recesses of the wilderness\" of Maine was to \"travel the logger's path and the Indian trail\", but he also hiked on pristine land. In the essay \"Henry David Thoreau, Philosopher\" Roderick Nash wrote, \"Thoreau left Concord in 1846 for the first of three trips to northern Maine. His expectations were high because he hoped to find genuine, primeval America. But contact with real wilderness in Maine affected him far differently than had the idea of wilderness in Concord. Instead of coming out of the woods with a deepened appreciation of the wilds, Thoreau felt a greater respect for civilization and realized the necessity of balance.\"\nOf alcohol, Thoreau wrote, \"I would fain keep sober always. ... I believe that water is the only drink for a wise man; wine is not so noble a liquor. ... Of all ebriosity, who does not prefer to be intoxicated by the air he breathes?\"\n\nThoreau never married and was childless. He strove to portray himself as an ascetic puritan. However, his sexuality has long been the subject of speculation, including by his contemporaries. Critics have called him heterosexual, homosexual, or asexual. There is no evidence to suggest he had physical relations with anyone, man or woman. Some scholars have suggested that homoerotic sentiments run through his writings and concluded that he was homosexual. The elegy \"Sympathy\" was inspired by the eleven-year-old Edmund Sewell, with whom he hiked for five days in 1839. One scholar has suggested that he wrote the poem to Edmund because he could not bring himself to write it to Edmund's sister, and another that Thoreau's \"emotional experiences with women are memorialized under a camouflage of masculine pronouns\", but other scholars dismiss this. It has been argued that the long paean in \"Walden\" to the French-Canadian woodchopper Alek Therien, which includes allusions to Achilles and Patroclus, is an expression of conflicted desire. In some of Thoreau's writing there is the sense of a secret self. In 1840 he writes in his journal: \"My friend is the apology for my life. In him are the spaces which my orbit traverses\". Thoreau was strongly influenced by the moral reformers of his time, and this may have instilled anxiety and guilt over sexual desire.\n\nThoreau was fervently against slavery and actively supported the abolitionist movement. He participated in the Underground Railroad, delivered lectures that attacked the Fugitive Slave Law, and in opposition to the popular opinion of the time, supported radical abolitionist militia leader John Brown and his party. Two weeks after the ill-fated raid on Harpers Ferry and in the weeks leading up to Brown's execution, Thoreau regularly delivered a speech to the citizens of Concord, Massachusetts, in which he compared the American government to Pontius Pilate and likened Brown's execution to the crucifixion of Jesus Christ:\n\nIn \"The Last Days of John Brown\", Thoreau described the words and deeds of John Brown as noble and an example of heroism. In addition, he lamented the newspaper editors who dismissed Brown and his scheme as \"crazy\".\n\nThoreau was a proponent of limited government and individualism. Although he was hopeful that mankind could potentially have, through self-betterment, the kind of government which \"governs not at all\", he distanced himself from contemporary \"no-government men\" (anarchists), writing: \"I ask for, not at once no government, but at once a better government.\"\n\nThoreau deemed the evolution from absolute monarchy to limited monarchy to democracy as \"a progress toward true respect for the individual\" and theorized about further improvements \"towards recognizing and organizing the rights of man.\" Echoing this belief, he went on to write: \"There will never be a really free and enlightened State until the State comes to recognize the individual as a higher and independent power, from which all its power and authority are derived, and treats him accordingly.\"\n\nIt is on this basis that Thoreau could so strongly inveigh against British and Catholic power in \"A Yankee in Canada\". Despotic authority had crushed the people's sense of ingenuity and enterprise; the Canadian \"habitants\" had been reduced, in his view, to a perpetual childlike state. Ignoring the recent Rebellions, he argued that there would be no revolution in the St. Lawrence River valley.\n\nAlthough Thoreau believed resistance to unjustly exercised authority could be both violent (exemplified in his support for John Brown) and nonviolent (his own example of tax resistance displayed in \"Resistance to Civil Government\"), he regarded pacifist nonresistance as temptation to passivity, writing: \"Let not our Peace be proclaimed by the rust on our swords, or our inability to draw them from their scabbards; but let her at least have so much work on her hands as to keep those swords bright and sharp.\" Furthermore, in a formal lyceum debate in 1841, he debated the subject \"Is it ever proper to offer forcible resistance?\", arguing the affirmative.\n\nLikewise, his condemnation of the Mexican–American War did not stem from pacifism, but rather because he considered Mexico \"unjustly overrun and conquered by a foreign army\" as a means to expand the slave territory.\n\nThoreau was ambivalent towards industrialization and capitalism. On one hand he regarded commerce as \"unexpectedly confident and serene, adventurous, and unwearied\" and expressed admiration for its associated cosmopolitanism, writing:\n\nOn the other hand, he wrote disparagingly of the factory system:\n\nThoreau also favored bioregionalism, the protection of animals and wild areas, free trade, and taxation for schools and highways. He disapproved of the subjugation of Native Americans, slavery, technological utopianism, consumerism, philistinism, mass entertainment, and frivolous applications of technology.\n\nThoreau was influenced by Indian spiritual thought. In \"Walden\", there are many overt references to the sacred texts of India. For example, in the first chapter (\"Economy\"), he writes: \"How much more admirable the Bhagvat-Geeta than all the ruins of the East!\" \"American Philosophy: An Encyclopedia\" classes him as one of several figures who \"took a more pantheist or pandeist approach by rejecting views of God as separate from the world\", also a characteristic of Hinduism.\n\nFurthermore, in \"The Pond in Winter\", he equates Walden Pond with the sacred Ganges river, writing:\n\nThoreau was aware his Ganges imagery could have been factual. He wrote about ice harvesting at Walden Pond. And he knew that New England's ice merchants were shipping ice to foreign ports, including Calcutta.\n\nAdditionally, Thoreau followed various Hindu customs, including following a diet of rice (\"It was fit that I should live on rice, mainly, who loved so well the philosophy of India.\"), flute playing (reminiscent of the favorite musical pastime of Krishna), and yoga.\n\nIn an 1849 letter to his friend H.G.O. Blake, he wrote about yoga and its meaning to him:\n\nThoreau read contemporary works in the new science of biology, including the works of Alexander von Humboldt, Charles Darwin, and Asa Gray (Charles Darwin's staunchest American ally). Thoreau was deeply influenced by Humboldt, especially his work Kosmos.\n\nIn 1859, Thoreau purchased and read Darwin's \"On the Origin of Species\". Unlike many natural historians at the time, including Louis Agassiz who publicly opposed Darwinism in favor of a static view of nature, Thoreau was immediately enthusiastic about the theory of evolution by natural selection and endorsed it, stating:\n\nThoreau's political writings had little impact during his lifetime, as \"his contemporaries did not see him as a theorist or as a radical,\" viewing him instead as a naturalist. They either dismissed or ignored his political essays, including \"Civil Disobedience\". The only two complete books (as opposed to essays) published in his lifetime, \"Walden\" and \"A Week on the Concord and Merrimack Rivers\" (1849), both dealt with nature, in which he loved to wander.\" His obituary was lumped in with others rather than as a separate article in an 1862 yearbook. Nevertheless, Thoreau's writings went on to influence many public figures. Political leaders and reformers like Mohandas Gandhi, U.S. President John F. Kennedy, American civil rights activist Martin Luther King Jr., U.S. Supreme Court Justice William O. Douglas, and Russian author Leo Tolstoy all spoke of being strongly affected by Thoreau's work, particularly \"Civil Disobedience\", as did \"right-wing theorist Frank Chodorov [who] devoted an entire issue of his monthly, \"Analysis\", to an appreciation of Thoreau.\"\n\nThoreau also influenced many artists and authors including Edward Abbey, Willa Cather, Marcel Proust, William Butler Yeats, Sinclair Lewis, Ernest Hemingway, Upton Sinclair, E. B. White, Lewis Mumford, Frank Lloyd Wright, Alexander Posey, and Gustav Stickley. Thoreau also influenced naturalists like John Burroughs, John Muir, E. O. Wilson, Edwin Way Teale, Joseph Wood Krutch, B. F. Skinner, David Brower, and Loren Eiseley, whom \"Publishers Weekly\" called \"the modern Thoreau\". English writer Henry Stephens Salt wrote a biography of Thoreau in 1890, which popularized Thoreau's ideas in Britain: George Bernard Shaw, Edward Carpenter, and Robert Blatchford were among those who became Thoreau enthusiasts as a result of Salt's advocacy. Mohandas Gandhi first read \"Walden\" in 1906 while working as a civil rights activist in Johannesburg, South Africa. He first read \"Civil Disobedience\" \"while he sat in a South African prison for the crime of nonviolently protesting discrimination against the Indian population in the Transvaal. The essay galvanized Gandhi, who wrote and published a synopsis of Thoreau's argument, calling its 'incisive logic ... unanswerable' and referring to Thoreau as 'one of the greatest and most moral men America has produced'.\" He told American reporter Webb Miller, \"[Thoreau's] ideas influenced me greatly. I adopted some of them and recommended the study of Thoreau to all of my friends who were helping me in the cause of Indian Independence. Why I actually took the name of my movement from Thoreau's essay 'On the Duty of Civil Disobedience', written about 80 years ago.\"\n\nMartin Luther King, Jr. noted in his autobiography that his first encounter with the idea of nonviolent resistance was reading \"On Civil Disobedience\" in 1944 while attending Morehouse College. He wrote in his autobiography that it was,\n\nHere, in this courageous New Englander's refusal to pay his taxes and his choice of jail rather than support a war that would spread slavery's territory into Mexico, I made my first contact with the theory of nonviolent resistance. Fascinated by the idea of refusing to cooperate with an evil system, I was so deeply moved that I reread the work several times. I became convinced that noncooperation with evil is as much a moral obligation as is cooperation with good. No other person has been more eloquent and passionate in getting this idea across than Henry David Thoreau. As a result of his writings and personal witness, we are the heirs of a legacy of creative protest. The teachings of Thoreau came alive in our civil rights movement; indeed, they are more alive than ever before. Whether expressed in a sit-in at lunch counters, a freedom ride into Mississippi, a peaceful protest in Albany, Georgia, a bus boycott in Montgomery, Alabama, these are outgrowths of Thoreau's insistence that evil must be resisted and that no moral man can patiently adjust to injustice.\n\nAmerican psychologist B. F. Skinner wrote that he carried a copy of Thoreau's \"Walden\" with him in his youth. and, in 1945, wrote \"Walden Two\", a fictional utopia about 1,000 members of a community living together inspired by the life of Thoreau. Thoreau and his fellow Transcendentalists from Concord were a major inspiration of the composer Charles Ives. The 4th movement of the Concord Sonata for piano (with a part for flute, Thoreau's instrument) is a character picture and he also set Thoreau's words.\n\nActor Ron Thompson did a dramatic portrayal of Henry David Thoreau on the 1976 NBC television series \"The Rebels\".\n\nThoreau's ideas have impacted and resonated with various strains in the anarchist movement, with Emma Goldman referring to him as \"the greatest American anarchist\". Green anarchism and anarcho-primitivism in particular have both derived inspiration and ecological points-of-view from the writings of Thoreau. John Zerzan included Thoreau's text \"Excursions\" (1863) in his edited compilation of works in the anarcho-primitivist tradition titled \"Against civilization: Readings and reflections\". Additionally, Murray Rothbard, the founder of anarcho-capitalism, has opined that Thoreau was one of the \"great intellectual heroes\" of his movement. Thoreau was also an important influence on late-19th-century anarchist naturism. Globally, Thoreau's concepts also held importance within individualist anarchist circles in Spain, France, and Portugal.\n\nFor the 200th anniversary of his birth, publishers released several new editions of his work: a recreation of \"Walden\" 1902 edition with illustrations, a picture book with excerpts from \"Walden\", and an annotated collection of Thoreau's essays on slavery. The United States Postal Service issued a commemorative stamp honoring Thoreau on May 23, 2017 in Concord, MA.\n\nAlthough his writings would receive widespread acclaim, Thoreau's ideas were not universally applauded. Scottish author Robert Louis Stevenson judged Thoreau's endorsement of living alone and apart from modern society in natural simplicity to be a mark of \"unmanly\" effeminacy and \"womanish solitude\", while deeming him a self-indulgent \"skulker\".\n\nNathaniel Hawthorne had mixed feelings about Thoreau. He noted that \"He is a keen and delicate observer of nature—a genuine observer—which, I suspect, is almost as rare a character as even an original poet; and Nature, in return for his love, seems to adopt him as her especial child, and shows him secrets which few others are allowed to witness.\" On the other hand, he also wrote that Thoreau \"repudiated all regular modes of getting a living, and seems inclined to lead a sort of Indian life among civilized men\".\n\nIn a similar vein, poet John Greenleaf Whittier detested what he deemed to be the \"wicked\" and \"heathenish\" message of \"Walden\", claiming that Thoreau wanted man to \"lower himself to the level of a woodchuck and walk on four legs\".\n\nIn response to such criticisms, English novelist George Eliot, writing for the \"Westminster Review\", characterized such critics as uninspired and narrow-minded:\nThoreau himself also responded to the criticism in a paragraph of his work \"Walden\" by illustrating the irrelevance of their inquiries:\n\nRecent criticism has accused Thoreau of hypocrisy, misanthropy, and being sanctimonious, based on his writings in \"Walden\", although this criticism has been perceived as highly selective.\n\n\n\n\n"}
{"id": "20917863", "url": "https://en.wikipedia.org/wiki?curid=20917863", "title": "Lessivage", "text": "Lessivage\n\nLessivage is a kind of leaching from clay particles being carried down in suspension. \nThe process can lead to the breakdown of peds (the particles that give the soil its characteristic structure).\n\n"}
{"id": "3675092", "url": "https://en.wikipedia.org/wiki?curid=3675092", "title": "List of omega-3 fatty acids", "text": "List of omega-3 fatty acids\n\nOmega-3 fatty acids, also called ω−3 fatty acids or \"n\"−3 fatty acids, are polyunsaturated fatty acids (PUFAs). Omega−3 fatty acids are important for normal metabolism.\n\nMammals are unable to synthesize omega−3 fatty acids, but can obtain the shorter-chain omega−3 fatty acid ALA (18 carbons and 3 double bonds) through diet and use it to form the more important long-chain omega−3 fatty acids, EPA (20 carbons and 5 double bonds) and then from EPA, the most crucial, DHA (22 carbons and 6 double bonds).\n\n"}
{"id": "1213271", "url": "https://en.wikipedia.org/wiki?curid=1213271", "title": "Micronization", "text": "Micronization\n\nMicronization is the process of reducing the average diameter of a solid material's particles. Traditional techniques for micronization focus on mechanical means, such as milling and grinding. Modern techniques make use of the properties of supercritical fluids and manipulate the principles of solubility.\n\nThe term micronization usually refers to the reduction of average particle diameters to the micrometer range, but can also describe further reduction to the nanometer scale. Common applications include the production of active chemical ingredients, foodstuff ingredients, and pharmaceuticals. These chemicals need to be micronized to increase efficacy.\n\nTraditional micronization techniques are based on friction to reduce particle size. Such methods include milling, bashing and grinding. A typical industrial mill is composed of a cylindrical metallic drum that usually contains steel spheres. As the drum rotates the spheres inside collide with the particles of the solid, thus crushing them towards smaller diameters. In the case of grinding, the solid particles are formed when the grinding units of the device rub against each other while particles of the solid are trapped in between.\n\nMethods like crushing and cutting are also used for reducing particle diameter, but produce more rough particles compared to the two previous techniques (and are therefore the early stages of the micronization process). Crushing employs hammer-like tools to break the solid into smaller particles by means of impact. Cutting uses sharp blades to cut the rough solid pieces into smaller ones.\n\nModern methods use supercritical fluids in the micronization process. These methods use supercritical fluids to induce a state of supersaturation, which leads to precipitation of individual particles. The most widely applied techniques of this category include the RESS process (Rapid Expansion of Supercritical Solutions), the SAS method (Supercritical Anti-Solvent) and the PGSS method (Particles from Gas Saturated Solutions). These modern techniques allow for greater tuneability of the process. Parameters like relative pressure and temperature, solute concentration, and antisolvent to solvent ratio are varied to adjust the output to the producer's needs. The supercritical fluid methods result in finer control over particle diameters, distribution of particle size and consistency of morphology. Because of the relatively low pressure involved, many supercritical fluid methods can incorporate thermolabile materials. Modern techniques involve renewable, nonflammable and nontoxic chemicals.\n\nIn the case of RESS, the supercritical fluid is used to dissolve the solid material under high pressure and temperature, thus forming a homogeneous supercritical phase. Thereafter, the mixture is expanded through a nozzle to form the smaller particles. Immediately upon exiting the nozzle, rapid expansion occurs, lowering the pressure. The pressure will drop below supercritical pressure, causing the supercritical fluid - usually carbon dioxide - to return to the gas state. This phase change severely decreases the solubility of the mixture and results in precipitation of particles. The less time it takes the solution to expand and the solute to precipitate, the narrower the particle size distribution will be. Faster precipitation times also tend to result in smaller particle diameters.\n\nIn the SAS method, the solid material is dissolved in an organic solvent. The supercritical fluid is then added as an antisolvent, which decreases the solubility of the system. As a result, particles of small diameter are formed. There are various submethods to SAS which differ in the method of introduction of the supercritical fluid into the organic solution.\n\nIn the PGSS method the solid material is melted and the supercritical fluid is dissolved in it. However, in this case the solution is forced to expand through a nozzle, and in this way nanoparticles are formed. The PGSS method has the advantage that because of the supercritical fluid, the melting point of the solid material is reduced. Therefore, the solid melts at a lower temperature than the normal melting temperature at ambient pressure.\n\nPharmaceuticals and foodstuff ingredients are the main industries in which micronization is utilized. Particles with reduced diameters have higher dissolution rates, which increases efficacy. Progesterone, for example, can be micronized by making very tiny crystals of the progesterone. Micronized progesterone is manufactured in a laboratory from plants. It is available for use as HRT, infertility treatment, treat progesterone deficiency treatment, including dysfunctional uterine bleeding in premenopausal women. Compounding pharmacies can supply micronized progesterone in sublingual tablets, oil caps, or transdermal creams. Creatine is among the other drugs that are micronized.\n\n"}
{"id": "1049637", "url": "https://en.wikipedia.org/wiki?curid=1049637", "title": "Molten carbonate fuel cell", "text": "Molten carbonate fuel cell\n\nMolten-carbonate fuel cells (MCFCs) are high-temperature fuel cells that operate at temperatures of 600 °C and above.\n\nMolten carbonate fuel cells (MCFCs) are currently being developed for natural gas, biogas (produced as a result of anaerobic digestion or biomass gasification), and coal-based power plants for electrical utility, industrial, and military applications. MCFCs are high-temperature fuel cells that use an electrolyte composed of a molten carbonate salt mixture suspended in a porous, chemically inert ceramic matrix of beta-alumina solid electrolyte (BASE). Since they operate at extremely high temperatures of 650 °C (roughly 1,200 °F) and above, non-precious metals can be used as catalysts at the anode and cathode, reducing costs.\n\nImproved efficiency is another reason MCFCs offer significant cost reductions over phosphoric acid fuel cells (PAFCs). Molten carbonate fuel cells can reach efficiencies approaching 60%, considerably higher than the 37–42% efficiencies of a phosphoric acid fuel cell plant. When the waste heat is captured and used, overall fuel efficiencies can be as high as 85%.\n\nUnlike alkaline, phosphoric acid, and polymer electrolyte membrane fuel cells, MCFCs don't require an external reformer to convert more energy-dense fuels to hydrogen. Due to the high temperatures at which MCFCs operate, these fuels are converted to hydrogen within the fuel cell itself by a process called internal reforming, which also reduces cost.\n\nMolten carbonate fuel cells are not prone to poisoning by carbon monoxide or carbon dioxide — they can even use carbon oxides as fuel — making them more attractive for fueling with gases made from coal. Because they are more resistant to impurities than other fuel cell types, scientists believe that they could even be capable of internal reforming of coal, assuming they can be made resistant to impurities such as sulfur and particulates that result from converting coal, a dirtier fossil fuel source than many others, into hydrogen. Alternatively, because MCFCs require CO be delivered to the cathode along with the oxidizer, they can be used to electrochemically separate carbon dioxide from the flue gas of other fossil fuel power plants for sequestration.\n\nThe primary disadvantage of current MCFC technology is durability. The high temperatures at which these cells operate and the corrosive electrolyte used accelerate component breakdown and corrosion, decreasing cell life. Scientists are currently exploring corrosion-resistant materials for components as well as fuel cell designs that increase cell life without decreasing performance.\n\nMolten carbonate FCs are a recently developed type of fuel cell that targets small and large energy distribution/generation systems since their power production is in the 0.3-3 MW range. The operating pressure is between 1-8 atm while the temperatures are between 600-700 C. Due to the production of CO during reforming of the fossil fuel (methane, natural gas), MCFCs are not a completely green technology, but are promising due to their reliability and efficiency (sufficient heat for co-generation with electricity). Current MCFC efficiencies range from 60-70%.\n\nInternal Reformer:\n\nformula_1\n\nAnode:\n\nformula_2\n\nCathode:\n\nformula_3\n\nCell:\n\nformula_4\n\nNernst Equation:\n\nformula_5\n\nDue to the high operating temperatures of MCFC’s, the materials need to be very carefully selected to survive the conditions present within the cell. The following sections cover the various materials present in the fuel cell and recent developments in research.\n\nThe anode material typically consists of a porous (3-6 μm, 45-70% material porosity) Ni based alloy. Ni is alloyed with either Chromium or Aluminum in the 2-10% range. These alloying elements allow for formation of LiCrO/LiAlO at the grain boundaries, which increases the materials' creep resistance and prevents sintering of the anode at the high operating temperatures of the fuel cell. Recent research has looked at using nano Ni and other Ni alloys to increase the performance and decrease the operating temperature of the fuel cell. A reduction in operating temperature would extend the lifetime of the fuel cell (i.e. decrease corrosion rate) and allow for use of cheaper component materials. At the same time, a decrease in temperature would decrease ionic conductivity of the electrolyte and thus, the anode materials need to compensate for this performance decline (e.g. by increasing power density). Other researchers have looked into enhancing creep resistance by using a NiAl alloy anode to reduce mass transport of Ni in the anode when in operation.\n\nOn the other side of the cell, the cathode material is composed of a porous Ni that is converted to a lithiated nickel oxide (lithium is intercalated within the NiO crystal structure). The pore size within the cathode is in the range of 7-15 μm with 60-70% of the material being porous. The primary issue with the cathode material is dissolution of NiO since it reacts with CO when the cathode is in contact with the carbonate electrolyte. This dissolution leads to precipitation of Ni metal in the electrolyte and since it is electrically conductive, the fuel cell can get short circuited. Therefore, current studies have looked into the addition of MgO to the NiO cathode to limit this dissolution. Magnesium oxide serves to reduce the solubility of Ni in the cathode and decreases precipitation in the electrolyte. Alternatively, replacement of the conventional cathode material with a LiFeO2-LiCoO2-NiO alloy has shown promising performance results and almost completely avoids the problem of Ni dissolution of the cathode.\n\nMCFC’s use a liquid electrolyte (molten carbonate) which consists of a sodium(Na) and potassium(K) carbonate. This electrolyte is supported by a ceramic (LiAlO) matrix to contain the liquid between the electrodes. The high temperatures of the fuel cell is required to produce sufficient ionic conductivity of oxygen through this electrolyte. Common MCFC electrolytes contain 62% LiCO and 38% KCO. A greater fraction of Li carbonate is used due to its higher ionic conductivity but is limited to 62% due to its lower gas solubility and ionic diffusivity of oxygen. In addition, LiCO is a very corrosive electrolyte and this ratio of carbonates provides the lowest corrosion rate. Due to these issues, recent studies have delved into replacing the potassium carbonate with a sodium carbonate. A Li/Na electrolyte has shown to have better performance (higher conductivity) and improves the stability of the cathode when compared to a Li/K electrolyte (Li/K is more basic). In addition, scientists have also looked into modifying the matrix of the electrolyte to prevent issues such as phase changes (γ-LiAlO to α-LiAlO) in the material during cell operation. The phase change accompanies a volume decrease in the electrolyte which leads to lower ionic conductivity. Through various studies, it has been found that an alumina doped α-LiAlO matrix would improve the phase stability while maintaining the fuel cell's performance.\n\nThe German company MTU Friedrichshafen presented an MCFC at the Hannover Fair in 2006. The unit weighs 2 tonnes and can produce 240 kW of electric power from various gaseous fuels, including biogas. If fueled by fuels that contain carbon such as natural gas, the exhaust will contain CO but will be reduced by up to 50% compared to diesel engines running on marine bunker fuel. The exhaust temperature is 400 °C, hot enough to be used for many industrial processes. Another possibility is to make more electric power via a steam turbine. Depending on feed gas type, the electric efficiency is between 12% and 19%. A steam turbine can increase the efficiency by up to 24%. The unit can be used for cogeneration.\n\n\n\n"}
{"id": "23169958", "url": "https://en.wikipedia.org/wiki?curid=23169958", "title": "Mont-Louis Solar Furnace", "text": "Mont-Louis Solar Furnace\n\nThe Mont-Louis Solar Furnace is an experimental solar furnace - a solar thermal energy facility that was built in 1949. It was the first facility of its kind in the world, and was a precursor of the Odeillo Solar Furnace. It provides a thermal power of 50 kW.\n\nThe French chemist Félix Trombe and his team made an initial demonstration of a mirror of DCA in Meudon in 1946 to show the possibility of reaching high temperatures very quickly using highly concentrated sunlight. The goal was to melt ore and extract very pure substances to make new and more effective refractory materials.\n\nIn order to do further experiments, the first solar furnace was built in Mont-Louis in the Pyrénées-Orientales in 1949.\n\nThe Mont-Louis Solar Furnace is engaged in a process of technology transfer to the countries of the south; the city of Safi in Morocco is participating in this process. The aim is to install in villages, solar ovens that will cook pots, plates for eating bread, building materials, and melt any metal to make pots or tools.\n\nThe centre gives demonstrations of its work. A guide takes visitors to the heart of the facility to explain the operation and use of the solar furnace. Applications of simple scientific and educational experiments complement the visit, for example: the concentration of the solar rays to produce temperatures between 2000 °C and 3500 °C, the ignition of wood, melting of metal, and ceramic cooking. The visit concludes with an overview of technologies that use solar energy: solar thermal, solar forge, solar cells, solar cookers.\n\n"}
{"id": "4074700", "url": "https://en.wikipedia.org/wiki?curid=4074700", "title": "NACA airfoil", "text": "NACA airfoil\n\nThe NACA airfoils are airfoil shapes for aircraft wings developed by the National Advisory Committee for Aeronautics (NACA). The shape of the NACA airfoils is described using a series of digits following the word \"NACA\". The parameters in the numerical code can be entered into equations to precisely generate the cross-section of the airfoil and calculate its properties.\n\nThe NACA four-digit wing sections define the profile by:\n\n\nFor example, the NACA 2412 airfoil has a maximum camber of 2% located 40% (0.4 chords) from the leading edge with a maximum thickness of 12% of the chord.\n\nThe NACA 0015 airfoil is symmetrical, the 00 indicating that it has no camber. The 15 indicates that the airfoil has a 15% thickness to chord length ratio: it is 15% as thick as it is long.\n\nThe formula for the shape of a NACA 00xx foil, with \"x\" being replaced by the percentage of thickness to chord, is:\n\nwhere:\n\nNote that in this equation, at (\"x\"/\"c\") = 1 (the trailing edge of the airfoil), the thickness is not quite zero. If a zero-thickness trailing edge is required, for example for computational work, one of the coefficients should be modified such that they sum to zero. Modifying the last coefficient (i.e. to −0.1036) will result in the smallest change to the overall shape of the airfoil. The leading edge approximates a cylinder with a radius of:\n\nNow the coordinates formula_4 of the upper airfoil surface, and formula_5 of the lower airfoil surface are:\n\nSymmetrical 4-digit series airfoils by default have maximum thickness at 30% of the chord from the leading edge.\n\nThe simplest asymmetric foils are the NACA 4-digit series foils, which use the same formula as that used to generate the 00xx symmetric foils, but with the line of mean camber bent. The formula used to calculate the mean camber line is:\n\nwhere:\n\nFor this cambered airfoil, because the thickness needs to be applied perpendicular to the camber line, the coordinates formula_4 and formula_5, of respectively the upper and lower airfoil surface, become:\n\nwhere\n\nThe NACA five-digit series describes more complex airfoil shapes. Its format is: LPSTT, where:\nFor example, the NACA 23112 profile describes an airfoil with design lift coefficient of 0.3 (0.15*2), the point of maximum camber located at 15% chord (5*3), reflex camber (1), and maximum thickness of 12% of chord length (12).\n\nThe camber-line is defined in two sections:\n\nwhere the chordwise location formula_14 and the ordinate formula_15 have been normalized by the chord. The constant formula_16 is chosen so that the maximum camber occurs at formula_17; for example, for the 230 camber-line, formula_18 and formula_19. Finally, constant formula_20 is determined to give the desired lift coefficient. For a 230 camber-line profile (the first 3 numbers in the 5 digit series), formula_21 is used.\n\n3 digit camber lines provide a very far forward location for the maximum camber.\n\nThe camber line is defined as:\n\nThe following table presents the various camber line profile coefficients: \n\nCamber lines such as 231 makes the negative trailing edge camber of the 230 series profile to be positively cambered. This results in a theoretical pitching moment of 0.\n\nfrom formula_23\n\nformula_24\n\nfrom formula_25\n\nformula_26\n\nThe following table presents the various camber line profile coefficients: \nFour- and five-digit series airfoils can be modified with a two-digit code preceded by a hyphen in the following sequence:\n\n\nFor example, the NACA 1234-05 is a NACA 1234 airfoil with a sharp leading edge and maximum thickness 50% of the chord (0.5 chords) from the leading edge.\n\nIn addition, for a more precise description of the airfoil all numbers can be presented as decimals.\n\nA new approach to airfoil design pioneered in the 1930s in which the airfoil shape was mathematically derived from the desired lift characteristics. Prior to this, airfoil shapes were first created and then had their characteristics measured in a wind tunnel. The 1-series airfoils are described by five digits in the following sequence:\nFor example, the NACA 16-123 airfoil has minimum pressure 60% of the chord back with a lift coefficient of 0.1 and maximum thickness of 23% of the chord.\n\nAn improvement over 1-series airfoils with emphasis on maximizing laminar flow. The airfoil is described using six digits in the following sequence:\n\n\nFor example, the NACA 61-315 a=0.5 has the area of minimum pressure 10% of the chord back, maintains low drag 0.2 above and below the lift coefficient of 0.3, has a maximum thickness of 15% of the chord, and maintains laminar flow over 50% of the chord.\n\nFurther advancement in maximizing laminar flow achieved by separately identifying the low pressure zones on upper and lower surfaces of the airfoil. The airfoil is described by seven digits in the following sequence:\n\n\nFor example, the NACA 712A315 has the area of minimum pressure 10% of the chord back on the upper surface and 20% of the chord back on the lower surface, uses the standard \"A\" profile, has a lift coefficient of 0.3, and has a maximum thickness of 15% of the chord.\n\nSupercritical airfoils designed to independently maximize airflow above and below the wing. The numbering is identical to the 7-series airfoils except that the sequence begins with an \"8\" to identify the series.\n\n\n\n"}
{"id": "20946368", "url": "https://en.wikipedia.org/wiki?curid=20946368", "title": "Native Vegetation Management Framework", "text": "Native Vegetation Management Framework\n\nThe \"Native Vegetation Management: A Framework for action 2002\" is a Victorian strategy which aims to protect, enhance and revegetate Victoria's native vegetation. The Framework’s main goal is to \"achieve a reversal, across the entire landscape of the long-term decline in the extent and quality of native vegetation, leading to a net gain.\" . The framework is notable for the inclusion of offsets, which allow authorised land clearing, providing there is a net gain in biodiversity, and for the fact that a monetary value is being placed on biodiversity. The \"habitat hectare\" has been defined as the trading currency of the framework, and provides a reliable and repeatable measurement of the quality of the native vegetation when correctly administered by an experienced assessor. The trading in \"habitat hectares\" is a form of biodiversity banking, which occurs in the private market responding to the supply and demand of the available remnant vegetation.\n\nThe act is administered by the Victorian Department of Sustainability and Environment (DSE).\n\n\n"}
{"id": "21175", "url": "https://en.wikipedia.org/wiki?curid=21175", "title": "Nitrogen", "text": "Nitrogen\n\nNitrogen is a chemical element with symbol N and atomic number 7. It was first discovered and isolated by Scottish physician Daniel Rutherford in 1772. Although Carl Wilhelm Scheele and Henry Cavendish had independently done so at about the same time, Rutherford is generally accorded the credit because his work was published first. The name \"nitrogène\" was suggested by French chemist Jean-Antoine-Claude Chaptal in 1790, when it was found that nitrogen was present in nitric acid and nitrates. Antoine Lavoisier suggested instead the name azote, from the Greek άζωτικός \"no life\", as it is an asphyxiant gas; this name is instead used in many languages, such as French, Russian, and Turkish, and appears in the English names of some nitrogen compounds such as hydrazine, azides and azo compounds.\n\nNitrogen is the lightest member of group 15 of the periodic table, often called the pnictogens. The name comes from the Greek πνίγειν \"to choke\", directly referencing nitrogen's asphyxiating properties. It is a common element in the universe, estimated at about seventh in total abundance in the Milky Way and the Solar System. At standard temperature and pressure, two atoms of the element bind to form dinitrogen, a colourless and odorless diatomic gas with the formula N. Dinitrogen forms about 78% of Earth's atmosphere, making it the most abundant uncombined element. Nitrogen occurs in all organisms, primarily in amino acids (and thus proteins), in the nucleic acids (DNA and RNA) and in the energy transfer molecule adenosine triphosphate. The human body contains about 3% nitrogen by mass, the fourth most abundant element in the body after oxygen, carbon, and hydrogen. The nitrogen cycle describes movement of the element from the air, into the biosphere and organic compounds, then back into the atmosphere.\n\nMany industrially important compounds, such as ammonia, nitric acid, organic nitrates (propellants and explosives), and cyanides, contain nitrogen. The extremely strong triple bond in elemental nitrogen (N≡N), the second strongest bond in any diatomic molecule after carbon monoxide (CO), dominates nitrogen chemistry. This causes difficulty for both organisms and industry in converting N into useful compounds, but at the same time means that burning, exploding, or decomposing nitrogen compounds to form nitrogen gas releases large amounts of often useful energy. Synthetically produced ammonia and nitrates are key industrial fertilisers, and fertiliser nitrates are key pollutants in the eutrophication of water systems.\n\nApart from its use in fertilisers and energy-stores, nitrogen is a constituent of organic compounds as diverse as Kevlar used in high-strength fabric and cyanoacrylate used in superglue. Nitrogen is a constituent of every major pharmacological drug class, including antibiotics. Many drugs are mimics or prodrugs of natural nitrogen-containing signal molecules: for example, the organic nitrates nitroglycerin and nitroprusside control blood pressure by metabolizing into nitric oxide. Many notable nitrogen-containing drugs, such as the natural caffeine and morphine or the synthetic amphetamines, act on receptors of animal neurotransmitters.\n\nNitrogen compounds have a very long history, ammonium chloride having been known to Herodotus. They were well known by the Middle Ages. Alchemists knew nitric acid as \"aqua fortis\" (strong water), as well as other nitrogen compounds such as ammonium salts and nitrate salts. The mixture of nitric and hydrochloric acids was known as \"aqua regia\" (royal water), celebrated for its ability to dissolve gold, the king of metals.\n\nThe discovery of nitrogen is attributed to the Scottish physician Daniel Rutherford in 1772, who called it \"noxious air\". Though he did not recognise it as an entirely different chemical substance, he clearly distinguished it from Joseph Black's \"fixed air\", or carbon dioxide. The fact that there was a component of air that does not support combustion was clear to Rutherford, although he was not aware that it was an element. Nitrogen was also studied at about the same time by Carl Wilhelm Scheele, Henry Cavendish, and Joseph Priestley, who referred to it as \"burnt air\" or \"phlogisticated air\". Nitrogen gas was inert enough that Antoine Lavoisier referred to it as \"mephitic air\" or \"azote\", from the Greek word (azotikos), \"no life\". In an atmosphere of pure nitrogen, animals died and flames were extinguished. Though Lavoisier's name was not accepted in English, since it was pointed out that almost all gases (indeed, with the sole exception of oxygen) are mephitic, it is used in many languages (French, Italian, Portuguese, Polish, Russian, Albanian, Turkish, etc.; the German \"Stickstoff\" similarly refers to the same characteristic, viz. \"sticken\" \"to choke or suffocate\") and still remains in English in the common names of many nitrogen compounds, such as hydrazine and compounds of the azide ion. Finally, it led to the name \"pnictogens\" for the group headed by nitrogen, from the Greek πνίγειν \"to choke\".\n\nThe English word nitrogen (1794) entered the language from the French \"nitrogène\", coined in 1790 by French chemist Jean-Antoine Chaptal (1756–1832), from the French \"nitre\" (potassium nitrate, also called saltpeter) and the French suffix \"-gène\", \"producing\", from the Greek -γενής (-genes, \"begotten\"). Chaptal's meaning was that nitrogen is the essential part of nitric acid, which in turn was produced from niter. In earlier times, niter had been confused with Egyptian \"natron\" (sodium carbonate) – called νίτρον (nitron) in Greek – which, despite the name, contained no nitrate.\n\nThe earliest military, industrial, and agricultural applications of nitrogen compounds used saltpeter (sodium nitrate or potassium nitrate), most notably in gunpowder, and later as fertiliser. In 1910, Lord Rayleigh discovered that an electrical discharge in nitrogen gas produced \"active nitrogen\", a monatomic allotrope of nitrogen. The \"whirling cloud of brilliant yellow light\" produced by his apparatus reacted with mercury to produce explosive mercury nitride.\n\nFor a long time, sources of nitrogen compounds were limited. Natural sources originated either from biology or deposits of nitrates produced by atmospheric reactions. Nitrogen fixation by industrial processes like the Frank–Caro process (1895–1899) and Haber–Bosch process (1908–1913) eased this shortage of nitrogen compounds, to the extent that half of global food production (see Applications) now relies on synthetic nitrogen fertilisers. At the same time, use of the Ostwald process (1902) to produce nitrates from industrial nitrogen fixation allowed the large-scale industrial production of nitrates as feedstock in the manufacture of explosives in the World Wars of the 20th century.\n\nA nitrogen atom has seven electrons. In the ground state, they are arranged in the electron configuration 1s2s2p2p2p. It therefore has five valence electrons in the 2s and 2p orbitals, three of which (the p-electrons) are unpaired. It has one of the highest electronegativities among the elements (3.04 on the Pauling scale), exceeded only by chlorine (3.16), oxygen (3.44), and fluorine (3.98). Following periodic trends, its single-bond covalent radius of 71 pm is smaller than those of boron (84 pm) and carbon (76 pm), while it is larger than those of oxygen (66 pm) and fluorine (57 pm). The nitride anion, N, is much larger at 146 pm, similar to that of the oxide (O: 140 pm) and fluoride (F: 133 pm) anions. The first three ionisation energies of nitrogen are 1.402, 2.856, and 4.577 MJ·mol, and the sum of the fourth and fifth is 16.920 MJ·mol. Due to these very high figures, nitrogen has no simple cationic chemistry.\n\nThe lack of radial nodes in the 2p subshell is directly responsible for many of the anomalous properties of the first row of the p-block, especially in nitrogen, oxygen, and fluorine. The 2p subshell is very small and has a very similar radius to the 2s shell, facilitating orbital hybridisation. It also results in very large electrostatic forces of attraction between the nucleus and the valence electrons in the 2s and 2p shells, resulting in very high electronegativities. Hypervalency is almost unknown in the 2p elements for the same reason, because the high electronegativity makes it difficult for a small nitrogen atom to be a central atom in an electron-rich three-center four-electron bond since it would tend to attract the electrons strongly to itself. Thus, despite nitrogen's position at the head of group 15 in the periodic table, its chemistry shows huge differences from that of its heavier congeners phosphorus, arsenic, antimony, and bismuth.\n\nNitrogen may be usefully compared to its horizontal neighbours carbon and oxygen as well as its vertical neighbours in the pnictogen column (phosphorus, arsenic, antimony, and bismuth). Although each period 2 element from lithium to nitrogen shows some similarities to the period 3 element in the next group from magnesium to sulfur (known as the diagonal relationships), their degree drops off quite abruptly past the boron–silicon pair, so that the similarities of nitrogen to sulfur are mostly limited to sulfur nitride ring compounds when both elements are the only ones present. Nitrogen resembles oxygen far more than it does carbon with its high electronegativity and concomitant capability for hydrogen bonding and the ability to form coordination complexes by donating its lone pairs of electrons. It does not share carbon's proclivity for catenation, with the longest chain of nitrogen yet discovered being composed of only eight nitrogen atoms (PhN=N–N(Ph)–N=N–N(Ph)–N=NPh). One property nitrogen does share with both its horizontal neighbours is its preferentially forming multiple bonds, typically with carbon, nitrogen, or oxygen atoms, through p–p interactions; thus, for example, nitrogen occurs as diatomic molecules and thus has very much lower melting (−210 °C) and boiling points (−196 °C) than the rest of its group, as the N molecules are only held together by weak van der Waals interactions and there are very few electrons available to create significant instantaneous dipoles. This is not possible for its vertical neighbours; thus, the nitrogen oxides, nitrites, nitrates, nitro-, nitroso-, azo-, and diazo-compounds, azides, cyanates, thiocyanates, and imino-derivatives find no echo with phosphorus, arsenic, antimony, or bismuth. By the same token, however, the complexity of the phosphorus oxoacids finds no echo with nitrogen.\n\nNitrogen has two stable isotopes: N and N. The first is much more common, making up 99.634% of natural nitrogen, and the second (which is slightly heavier) makes up the remaining 0.366%. This leads to an atomic weight of around 14.007 u. Both of these stable isotopes are produced in the CNO cycle in stars, but N is more common as its neutron capture is the rate-limiting step. N is one of the five stable odd–odd nuclides (a nuclide having an odd number of protons and neutrons); the other four are H, Li, B, and Ta.\n\nThe relative abundance of N and N is practically constant in the atmosphere but can vary elsewhere, due to natural isotopic fractionation from biological redox reactions and the evaporation of natural ammonia or nitric acid. Biologically mediated reactions (e.g., assimilation, nitrification, and denitrification) strongly control nitrogen dynamics in the soil. These reactions typically result in N enrichment of the substrate and depletion of the product.\n\nThe heavy isotope N was first discovered by S. M. Naudé in 1929, soon after heavy isotopes of the neighbouring elements oxygen and carbon were discovered. It presents one of the lowest thermal neutron capture cross-sections of all isotopes. It is frequently used in nuclear magnetic resonance (NMR) spectroscopy to determine the structures of nitrogen-containing molecules, due to its fractional nuclear spin of one-half, which offers advantages for NMR such as narrower line width. N, though also theoretically usable, has an integer nuclear spin of one and thus has a quadrupole moment that leads to wider and less useful spectra. N NMR nevertheless has complications not encountered in the more H and C NMR spectroscopy. The low natural abundance of N (0.36%) significantly reduces sensitivity, a problem which is only exacerbated by its low gyromagnetic ratio, (only 10.14% that of H). As a result, the signal-to-noise ratio for H is about 300 times as much as that for N at the same magnetic field strength. This may be somewhat alleviated by isotopic enrichment of N by chemical exchange or fractional distillation. N-enriched compounds have the advantage that under standard conditions, they do not undergo chemical exchange of their nitrogen atoms with atmospheric nitrogen, unlike compounds with labelled hydrogen, carbon, and oxygen isotopes that must be kept away from the atmosphere. The N:N ratio is commonly used in stable isotope analysis in the fields of geochemistry, hydrology, paleoclimatology and paleoceanography, where it is called \"δ\"N.\n\nOf the ten other isotopes produced synthetically, ranging from N to N, N has a half-life of ten minutes and the remaining isotopes have half-lives on the order of seconds (N and N) or even milliseconds. No other nitrogen isotopes are possible as they would fall outside the nuclear drip lines, leaking out a proton or neutron. Given the half-life difference, N is the most important nitrogen radioisotope, being relatively long-lived enough to use in positron emission tomography (PET), although its half-life is still short and thus it must be produced at the venue of the PET, for example in a cyclotron via proton bombardment of O producing N and an alpha particle.\n\nThe radioisotope N is the dominant radionuclide in the coolant of pressurised water reactors or boiling water reactors during normal operation, and thus it is a sensitive and immediate indicator of leaks from the primary coolant system to the secondary steam cycle, and is the primary means of detection for such leaks. It is produced from O (in water) via an (n,p) reaction in which the O atom captures a neutron and expels a proton. It has a short half-life of about 7.1 s, but during its decay back to O produces high-energy gamma radiation (5 to 7 MeV). Because of this, access to the primary coolant piping in a pressurised water reactor must be restricted during reactor power operation.\n\nAtomic nitrogen, also known as active nitrogen, is highly reactive, being a triradical with three unpaired electrons. Free nitrogen atoms easily react with most elements to form nitrides, and even when two free nitrogen atoms collide to produce an excited N molecule, they may release so much energy on collision with even such stable molecules as carbon dioxide and water to cause homolytic fission into radicals such as CO and O or OH and H. Atomic nitrogen is prepared by passing an electric discharge through nitrogen gas at 0.1–2 mmHg, which produces atomic nitrogen along with a peach-yellow emission that fades slowly as an afterglow for several minutes even after the discharge terminates.\n\nGiven the great reactivity of atomic nitrogen, elemental nitrogen usually occurs as molecular N, dinitrogen. This molecule is a colourless, odourless, and tasteless diamagnetic gas at standard conditions: it melts at −210 °C and boils at −196 °C. Dinitrogen is mostly unreactive at room temperature, but it will nevertheless react with lithium metal and some transition metal complexes. This is due to its bonding, which is unique among the diatomic elements at standard conditions in that it has an N≡N triple bond. Triple bonds have short bond lengths (in this case, 109.76 pm) and high dissociation energies (in this case, 945.41 kJ/mol), and are thus very strong, explaining dinitrogen's chemical inertness.\n\nThere are some theoretical indications that other nitrogen oligomers and polymers may be possible. If they could be synthesised, they may have potential applications as materials with a very high energy density, that could be used as powerful propellants or explosives. This is because they should all decompose to dinitrogen, whose N≡N triple bond (bond energy 946 kJ⋅mol) is much stronger than those of the N=N double bond (418 kJ⋅mol) or the N–N single bond (160 kJ⋅mol): indeed, the triple bond has more than thrice the energy of the single bond. (The opposite is true for the heavier pnictogens, which prefer polyatomic allotropes.) A great disadvantage is that most neutral polynitrogens are not expected to have a large barrier towards decomposition, and that the few exceptions would be even more challenging to synthesise than the long-sought but still unknown tetrahedrane. This stands in contrast to the well-characterised cationic and anionic polynitrogens azide (), pentazenium (), and pentazolide (cyclic aromatic ). Under extremely high pressures (1.1 million atm) and high temperatures (2000 K), as produced in a diamond anvil cell, nitrogen polymerises into the single-bonded cubic gauche crystal structure. This structure is similar to that of diamond, and both have extremely strong covalent bonds, resulting in its nickname \"nitrogen diamond\".\nAt atmospheric pressure, molecular nitrogen condenses (liquefies) at 77 K (−195.79 °C) and freezes at 63 K (−210.01 °C) into the beta hexagonal close-packed crystal allotropic form. Below 35.4 K (−237.6 °C) nitrogen assumes the cubic crystal allotropic form (called the alpha phase). Liquid nitrogen, a colourless fluid resembling water in appearance, but with 80.8% of the density (the density of liquid nitrogen at its boiling point is 0.808 g/mL), is a common cryogen. Solid nitrogen has many crystalline modifications. It forms a significant dynamic surface coverage on Pluto and outer moons of the Solar System such as Triton. Even at the low temperatures of solid nitrogen it is fairly volatile and can sublime to form an atmosphere, or condense back into nitrogen frost. It is very weak and flows in the form of glaciers and on Triton geysers of nitrogen gas come from the polar ice cap region.\n\nThe first example of a dinitrogen complex to be discovered was [Ru(NH)(N)] (see figure at right), and soon many other such complexes were discovered. These complexes, in which a nitrogen molecule donates at least one lone pair of electrons to a central metal cation, illustrate how N might bind to the metal(s) in nitrogenase and the catalyst for the Haber process: these processes involving dinitrogen activation are vitally important in biology and in the production of fertilisers.\n\nDinitrogen is able to coordinate to metals in five different ways. The more well-characterised ways are the end-on M←N≡N (\"η\") and M←N≡N→M (\"μ\", bis-\"η\"), in which the lone pairs on the nitrogen atoms are donated to the metal cation. The less well-characterised ways involve dinitrogen donating electron pairs from the triple bond, either as a bridging ligand to two metal cations (\"μ\", bis-\"η\") or to just one (\"η\"). The fifth and unique method involves triple-coordination as a bridging ligand, donating all three electron pairs from the triple bond (\"μ\"-N). A few complexes feature multiple N ligands and some feature N bonded in multiple ways. Since N is isoelectronic with carbon monoxide (CO) and acetylene (CH), the bonding in dinitrogen complexes is closely allied to that in carbonyl compounds, although N is a weaker \"σ\"-donor and \"π\"-acceptor than CO. Theoretical studies show that \"σ\" donation is a more important factor allowing the formation of the M–N bond than \"π\" back-donation, which mostly only weakens the N–N bond, and end-on (\"η\") donation is more readily accomplished than side-on (\"η\") donation.\n\nToday, dinitrogen complexes are known for almost all the transition metals, accounting for several hundred compounds. They are normally prepared by three methods:\nOccasionally the N≡N bond may be formed directly within a metal complex, for example by directly reacting coordinated ammonia (NH) with nitrous acid (HNO), but this is not generally applicable. Most dinitrogen complexes have colours within the range white-yellow-orange-red-brown; a few exceptions are known, such as the blue [{Ti(\"η\"-CH)}-(N)].\n\nNitrogen bonds to almost all the elements in the periodic table except the first three noble gases, helium, neon, and argon, and some of the very short-lived elements after bismuth, creating an immense variety of binary compounds with varying properties and applications. Many binary compounds are known: with the exception of the nitrogen hydrides, oxides, and fluorides, these are typically called nitrides. Many stoichiometric phases are usually present for most elements (e.g. MnN, MnN, MnN, MnN, MnN, and MnN for 9.2 < \"x\" < 25.3). They may be classified as \"salt-like\" (mostly ionic), covalent, \"diamond-like\", and metallic (or interstitial), although this classification has limitations generally stemming from the continuity of bonding types instead of the discrete and separate types that it implies. They are normally prepared by directly reacting a metal with nitrogen or ammonia (sometimes after heating), or by thermal decomposition of metal amides:\nMany variants on these processes are possible.The most ionic of these nitrides are those of the alkali metals and alkaline earth metals, LiN (Na, K, Rb, and Cs do not form stable nitrides for steric reasons) and MN (M = Be, Mg, Ca, Sr, Ba). These can formally be thought of as salts of the N anion, although charge separation is not actually complete even for these highly electropositive elements. However, the alkali metal azides NaN and KN, featuring the linear anion, are well-known, as are Sr(N) and Ba(N). Azides of the B-subgroup metals (those in groups 11 through 16) are much less ionic, have more complicated structures, and detonate readily when shocked.\nMany covalent binary nitrides are known. Examples include cyanogen ((CN)), triphosphorus pentanitride (PN), disulfur dinitride (SN), and tetrasulfur tetranitride (SN). The essentially covalent silicon nitride (SiN) and germanium nitride (GeN) are also known: silicon nitride in particular would make a promising ceramic if not for the difficulty of working with and sintering it. In particular, the group 13 nitrides, most of which are promising semiconductors, are isoelectronic with graphite, diamond, and silicon carbide and have similar structures: their bonding changes from covalent to partially ionic to metallic as the group is descended. In particular, since the B–N unit is isoelectronic to C–C, and carbon is essentially intermediate in size between boron and nitrogen, much of organic chemistry finds an echo in boron–nitrogen chemistry, such as in borazine (\"inorganic benzene\"). Nevertheless, the analogy is not exact due to the ease of nucleophilic attack at boron due to its deficiency in electrons, which is not possible in a wholly carbon-containing ring.\n\nThe largest category of nitrides are the interstitial nitrides of formulae MN, MN, and MN (although variable composition is perfectly possible), where the small nitrogen atoms are positioned in the gaps in a metallic cubic or hexagonal close-packed lattice. They are opaque, very hard, and chemically inert, melting only at very high temperatures (generally over 2500 °C). They have a metallic lustre and conduct electricity as do metals. They hydrolyse only very slowly to give ammonia or nitrogen.\n\nThe nitride anion (N) is the strongest \"π\" donor known amongst ligands (the second-strongest is O). Nitrido complexes are generally made by thermal decomposition of azides or by deprotonating ammonia, and they usually involve a terminal {≡N} group. The linear azide anion (), being isoelectronic with nitrous oxide, carbon dioxide, and cyanate, forms many coordination complexes. Further catenation is rare, although (isoelectronic with carbonate and nitrate) is known.\n\nIndustrially, ammonia (NH) is the most important compound of nitrogen and is prepared in larger amounts than any other compound, because it contributes significantly to the nutritional needs of terrestrial organisms by serving as a precursor to food and fertilisers. It is a colourless alkaline gas with a characteristic pungent smell. The presence of hydrogen bonding has very significant effects on ammonia, conferring on it its high melting (−78 °C) and boiling (−33 °C) points. As a liquid, it is a very good solvent with a high heat of vaporisation (enabling it to be used in vacuum flasks), that also has a low viscosity and electrical conductivity and high dielectric constant, and is less dense than water. However, the hydrogen bonding in NH is weaker than that in HO due to the lower electronegativity of nitrogen compared to oxygen and the presence of only one lone pair in NH rather than two in HO. It is a weak base in aqueous solution (p\"K\" 4.74); its conjugate acid is ammonium, . It can also act as an extremely weak acid, losing a proton to produce the amide anion, . It thus undergoes self-dissociation, similar to water, to produce ammonium and amide. Ammonia burns in air or oxygen, though not readily, to produce nitrogen gas; it burns in fluorine with a greenish-yellow flame to give nitrogen trifluoride. Reactions with the other nonmetals are very complex and tend to lead to a mixture of products. Ammonia reacts on heating with metals to give nitrides.\n\nMany other binary nitrogen hydrides are known, but the most important are hydrazine (NH) and hydrogen azide (HN). Although it is not a nitrogen hydride, hydroxylamine (NHOH) is similar in properties and structure to ammonia and hydrazine as well. Hydrazine is a fuming, colourless liquid that smells similarly to ammonia. Its physical properties are very similar to those of water (melting point 2.0 °C, boiling point 113.5 °C, density 1.00 g/cm). Despite it being an endothermic compound, it is kinetically stable. It burns quickly and completely in air very exothermically to give nitrogen and water vapour. It is a very useful and versatile reducing agent and is a weaker base than ammonia. It is also commonly used as a rocket fuel.\n\nHydrazine is generally made by reaction of ammonia with alkaline sodium hypochlorite in the presence of gelatin or glue:\n(The attacks by hydroxide and ammonia may be reversed, thus passing through the intermediate NHCl instead.) The reason for adding gelatin is that it removes metal ions such as Cu that catalyses the destruction of hydrazine by reaction with chloramine (NHCl) to produce ammonium chloride and nitrogen.\n\nHydrogen azide (HN) was first produced in 1890 by the oxidation of aqueous hydrazine by nitrous acid. It is very explosive and even dilute solutions can be dangerous. It has a disagreeable and irritating smell and is a potentially lethal (but not cumulative) poison. It may be considered the conjugate acid of the azide anion, and is similarly analogous to the hydrohalic acids.\n\nAll four simple nitrogen trihalides are known. A few mixed halides and hydrohalides are known, but are mostly unstable and uninteresting: examples include NClF, NClF, NBrF, NFH, NClH, and NClH.\n\nFive nitrogen fluorides are known. Nitrogen trifluoride (NF, first prepared in 1928) is a colourless and odourless gas that is thermodynamically stable, and most readily produced by the electrolysis of molten ammonium fluoride dissolved in anhydrous hydrogen fluoride. Like carbon tetrafluoride, it is not at all reactive and is stable in water or dilute aqueous acids or alkalis. Only when heated does it act as a fluorinating agent, and it reacts with copper, arsenic, antimony, and bismuth on contact at high temperatures to give tetrafluorohydrazine (NF). The cations and are also known (the latter from reacting tetrafluorohydrazine with strong fluoride-acceptors such as arsenic pentafluoride), as is ONF, which has aroused interest due to the short N–O distance implying partial double bonding and the highly polar and long N–F bond. Tetrafluorohydrazine, unlike hydrazine itself, can dissociate at room temperature and above to give the radical NF•. Fluorine azide (FN) is very explosive and thermally unstable. Dinitrogen difluoride (NF) exists as thermally interconvertible \"cis\" and \"trans\" isomers, and was first found as a product of the thermal decomposition of FN.\n\nNitrogen trichloride (NCl) is a dense, volatile, and explosive liquid whose physical properties are similar to those of carbon tetrachloride, although one difference is that NCl is easily hydrolysed by water while CCl is not. It was first synthesised in 1811 by Pierre Louis Dulong, who lost three fingers and an eye to its explosive tendencies. As a dilute gas it is less dangerous and is thus used industrially to bleach and sterilise flour. Nitrogen tribromide (NBr), first prepared in 1975, is a deep red, temperature-sensitive, volatile solid that is explosive even at −100 °C. Nitrogen triiodide (NI) is still more unstable and was only prepared in 1990. Its adduct with ammonia, which was known earlier, is very shock-sensitive: it can be set off by the touch of a feather, shifting air currents, or even alpha particles. For this reason, small amounts of nitrogen triiodide are sometimes synthesised as a demonstration to high school chemistry students or as an act of \"chemical magic\". Chlorine azide (ClN) and bromine azide (BrN) are extremely sensitive and explosive.\n\nTwo series of nitrogen oxohalides are known: the nitrosyl halides (XNO) and the nitryl halides (XNO). The first are very reactive gases that can be made by directly halogenating nitrous oxide. Nitrosyl fluoride (NOF) is colourless and a vigorous fluorinating agent. Nitrosyl chloride (NOCl) behaves in much the same way and has often been used as an ionising solvent. Nitrosyl bromide (NOBr) is red. The reactions of the nitryl halides are mostly similar: nitryl fluoride (FNO) and nitryl chloride (ClNO) are likewise reactive gases and vigorous halogenating agents.\n\nNitrogen forms nine molecular oxides, some of which were the first gases to be identified: NO (nitrous oxide), NO (nitric oxide), NO (dinitrogen trioxide), NO (nitrogen dioxide), NO (dinitrogen tetroxide), NO (dinitrogen pentoxide), NO (nitrosylazide), and N(NO) (trinitramide). All are thermally unstable towards decomposition to their elements. One other possible oxide that has not yet been synthesised is oxatetrazole (NO), an aromatic ring.\n\nNitrous oxide (NO), better known as laughing gas, is made by thermal decomposition of molten ammonium nitrate at 250 °C. This is a redox reaction and thus nitric oxide and nitrogen are also produced as byproducts. It is mostly used as a propellant and aerating agent for sprayed canned whipped cream, and was formerly commonly used as an anaesthetic. Despite appearances, it cannot be considered to be the anhydride of hyponitrous acid (HNO) because that acid is not produced by the dissolution of nitrous oxide in water. It is rather unreactive (not reacting with the halogens, the alkali metals, or ozone at room temperature, although reactivity increases upon heating) and has the unsymmetrical structure N–N–O (N≡NO↔N=N=O): above 600 °C it dissociates by breaking the weaker N–O bond.\n\nNitric oxide (NO) is the simplest stable molecule with an odd number of electrons. In mammals, including humans, it is an important cellular signaling molecule involved in many physiological and pathological processes. It is formed by catalytic oxidation of ammonia. It is a colourless paramagnetic gas that, being thermodynamically unstable, decomposes to nitrogen and oxygen gas at 1100–1200 °C. Its bonding is similar to that in nitrogen, but one extra electron is added to a \"π\"* antibonding orbital and thus the bond order has been reduced to approximately 2.5; hence dimerisation to O=N–N=O is unfavourable except below the boiling point (where the \"cis\" isomer is more stable) because it does not actually increase the total bond order and because the unpaired electron is delocalised across the NO molecule, granting it stability. There is also evidence for the asymmetric red dimer O=N–O=N when nitric oxide is condensed with polar molecules. It reacts with oxygen to give brown nitrogen dioxide and with halogens to give nitrosyl halides. It also reacts with transition metal compounds to give nitrosyl complexes, most of which are deeply coloured.\n\nBlue dinitrogen trioxide (NO) is only available as a solid because it rapidly dissociates above its melting point to give nitric oxide, nitrogen dioxide (NO), and dinitrogen tetroxide (NO). The latter two compounds are somewhat difficult to study individually because of the equilibrium between them. although sometimes dinitrogen tetroxide can react by heterolytic fission to nitrosonium and nitrate in a medium with high dielectric constant. Nitrogen dioxide is an acrid, corrosive brown gas. Both compounds may be easily prepared by decomposing a dry metal nitrate. Both react with water to form nitric acid. Dinitrogen tetroxide is very useful for the preparation of anhydrous metal nitrates and nitrato complexes, and it became the storable oxidiser of choice for many rockets in both the United States and USSR by the late 1950s. This is because it is a hypergolic propellant in combination with a hydrazine-based rocket fuel and can be easily stored since it is liquid at room temperature.\n\nThe thermally unstable and very reactive dinitrogen pentoxide (NO) is the anhydride of nitric acid, and can be made from it by dehydration with phosphorus pentoxide. It is of interest for the preparation of explosives. It is a deliquescent, colourless crystalline solid that is sensitive to light. In the solid state it is ionic with structure [NO][NO]; as a gas and in solution it is molecular ON–O–NO. Hydration to nitric acid comes readily, as does analogous reaction with hydrogen peroxide giving peroxonitric acid (HOONO). It is a violent oxidising agent. Gaseous dinitrogen pentoxide decomposes as follows:\n\nMany nitrogen oxoacids are known, though most of them are unstable as pure compounds and are known only as aqueous solution or as salts. Hyponitrous acid (HNO) is a weak diprotic acid with the structure HON=NOH (p\"K\" 6.9, p\"K\" 11.6). Acidic solutions are quite stable but above pH 4 base-catalysed decomposition occurs via [HONNO] to nitrous oxide and the hydroxide anion. Hyponitrites (involving the anion) are stable to reducing agents and more commonly act as reducing agents themselves. They are an intermediate step in the oxidation of ammonia to nitrite, which occurs in the nitrogen cycle. Hyponitrite can act as a bridging or chelating bidentate ligand.\n\nNitrous acid (HNO) is not known as a pure compound, but is a common component in gaseous equilibria and is an important aqueous reagent: its aqueous solutions may be made from acidifying cool aqueous nitrite (, bent) solutions, although already at room temperature disproportionation to nitrate and nitric oxide is significant. It is a weak acid with p\"K\" 3.35 at 18 °C. They may be titrimetrically analysed by their oxidation to nitrate by permanganate. They are readily reduced to nitrous oxide and nitric oxide by sulfur dioxide, to hyponitrous acid with tin(II), and to ammonia with hydrogen sulfide. Salts of hydrazinium react with nitrous acid to produce azides which further react to give nitrous oxide and nitrogen. Sodium nitrite is mildly toxic in concentrations above 100 mg/kg, but small amounts are often used to cure meat and as a preservative to avoid bacterial spoilage. It is also used to synthesise hydroxylamine and to diazotise primary aromatic amines as follows:\n\nNitrite is also a common ligand that can coordinate in five ways. The most common are nitro (bonded from the nitrogen) and nitrito (bonded from an oxygen). Nitro-nitrito isomerism is common, where the nitrito form is usually less stable.\nNitric acid (HNO) is by far the most important and the most stable of the nitrogen oxoacids. It is one of the three most used acids (the other two being sulfuric acid and hydrochloric acid) and was first discovered by the alchemists in the 13th century. It is made by catalytic oxidation of ammonia to nitric oxide, which is oxidised to nitrogen dioxide, and then dissolved in water to give concentrated nitric acid. In the United States of America, over seven million tonnes of nitric acid are produced every year, most of which is used for nitrate production for fertilisers and explosives, among other uses. Anhydrous nitric acid may be made by distilling concentrated nitric acid with phosphorus pentoxide at low pressure in glass apparatus in the dark. It can only be made in the solid state, because upon melting it spontaneously decomposes to nitrogen dioxide, and liquid nitric acid undergoes self-ionisation to a larger extent than any other covalent liquid as follows:\nTwo hydrates, HNO·HO and HNO·3HO, are known that can be crystallised. It is a strong acid and concentrated solutions are strong oxidising agents, though gold, platinum, rhodium, and iridium are immune to attack. A 3:1 mixture of concentrated hydrochloric acid and nitric acid, called \"aqua regia\", is still stronger and successfully dissolves gold and platinum, because free chlorine and nitrosyl chloride are formed and chloride anions can form strong complexes. In concentrated sulfuric acid, nitric acid is protonated to form nitronium, which can act as an electrophile for aromatic nitration:\nThe thermal stabilities of nitrates (involving the trigonal planar anion) depends on the basicity of the metal, and so do the products of decomposition (thermolysis), which can vary between the nitrite (for example, sodium), the oxide (potassium and lead), or even the metal itself (silver) depending on their relative stabilities. Nitrate is also a common ligand with many modes of coordination.\n\nFinally, although orthonitric acid (HNO), which would be analogous to orthophosphoric acid, does not exist, the tetrahedral orthonitrate anion is known in its sodium and potassium salts:\nThese white crystalline salts are very sensitive to water vapour and carbon dioxide in the air:\nDespite its limited chemistry, the orthonitrate anion is interesting from a structural point of view due to its regular tetrahedral shape and the short N–O bond lengths, implying significant polar character to the bonding.\n\nNitrogen is one of the most important elements in organic chemistry. Many organic functional groups involve a carbon–nitrogen bond, such as amides (RCONR), amines (RN), imines (RC(=NR)R), imides (RCO)NR, azides (RN), azo compounds (RNR), cyanates and isocyanates (ROCN or RCNO), nitrates (RONO), nitriles and isonitriles (RCN or RNC), nitrites (RONO), nitro compounds (RNO), nitroso compounds (RNO), oximes (RCR=NOH), and pyridine derivatives. C–N bonds are strongly polarised towards nitrogen. In these compounds, nitrogen is usually trivalent (though it can be tetravalent in quaternary ammonium salts, RN), with a lone pair that can confer basicity on the compound by being coordinated to a proton. This may be offset by other factors: for example, amides are not basic because the lone pair is delocalised into a double bond (though they may act as acids at very low pH, being protonated at the oxygen), and pyrrole is not acidic because the lone pair is delocalised as part of an aromatic ring. The amount of nitrogen in a chemical substance can be determined by the Kjeldahl method. In particular, nitrogen is an essential component of nucleic acids, amino acids and thus proteins, and the energy-carrying molecule adenosine triphosphate and is thus vital to all life on Earth.\n\nNitrogen is the most common pure element in the earth, making up 78.1% of the entire volume of the atmosphere. Despite this, it is not very abundant in Earth's crust, making up only 19 parts per million of this, on par with niobium, gallium, and lithium. The only important nitrogen minerals are nitre (potassium nitrate, saltpetre) and sodanitre (sodium nitrate, Chilean saltpetre). However, these have not been an important source of nitrates since the 1920s, when the industrial synthesis of ammonia and nitric acid became common.\n\nNitrogen compounds constantly interchange between the atmosphere and living organisms. Nitrogen must first be processed, or \"fixed\", into a plant-usable form, usually ammonia. Some nitrogen fixation is done by lightning strikes producing the nitrogen oxides, but most is done by diazotrophic bacteria through enzymes known as nitrogenases (although today industrial nitrogen fixation to ammonia is also significant). When the ammonia is taken up by plants, it is used to synthesise proteins. These plants are then digested by animals who use the nitrogen compounds to synthesise their own proteins and excrete nitrogen–bearing waste. Finally, these organisms die and decompose, undergoing bacterial and environmental oxidation and denitrification, returning free dinitrogen to the atmosphere. Industrial nitrogen fixation by the Haber process is mostly used as fertiliser, although excess nitrogen–bearing waste, when leached, leads to eutrophication of freshwater and the creation of marine dead zones, as nitrogen-driven bacterial growth depletes water oxygen to the point that all higher organisms die. Furthermore, nitrous oxide, which is produced during denitrification, attacks the atmospheric ozone layer.\n\nMany saltwater fish manufacture large amounts of trimethylamine oxide to protect them from the high osmotic effects of their environment; conversion of this compound to dimethylamine is responsible for the early odour in unfresh saltwater fish. In animals, free radical nitric oxide (derived from an amino acid), serves as an important regulatory molecule for circulation.\n\nNitric oxide's rapid reaction with water in animals results in production of its metabolite nitrite. Animal metabolism of nitrogen in proteins, in general, results in excretion of urea, while animal metabolism of nucleic acids results in excretion of urea and uric acid. The characteristic odour of animal flesh decay is caused by the creation of long-chain, nitrogen-containing amines, such as putrescine and cadaverine, which are breakdown products of the amino acids ornithine and lysine, respectively, in decaying proteins.\n\nNitrogen gas is an industrial gas produced by the fractional distillation of liquid air, or by mechanical means using gaseous air (pressurised reverse osmosis membrane or pressure swing adsorption). Nitrogen gas generators using membranes or pressure swing adsorption (PSA) are typically more cost and energy efficient than bulk delivered nitrogen. Commercial nitrogen is often a byproduct of air-processing for industrial concentration of oxygen for steelmaking and other purposes. When supplied compressed in cylinders it is often called OFN (oxygen-free nitrogen). Commercial-grade nitrogen already contains at most 20 ppm oxygen, and specially purified grades containing at most 2 ppm oxygen and 10 ppm argon are also available.\n\nIn a chemical laboratory, it is prepared by treating an aqueous solution of ammonium chloride with sodium nitrite.\n\nSmall amounts of the impurities NO and HNO are also formed in this reaction. The impurities can be removed by passing the gas through aqueous sulfuric acid containing potassium dichromate. Very pure nitrogen can be prepared by the thermal decomposition of barium azide or sodium azide.\n\nThe applications of nitrogen compounds are naturally extremely widely varied due to the huge size of this class: hence, only applications of pure nitrogen itself will be considered here. Two-thirds of nitrogen produced by industry is sold as the gas and the remaining one-third as the liquid. The gas is mostly used as an inert atmosphere whenever the oxygen in the air would pose a fire, explosion, or oxidising hazard. Some examples include:\n\nNitrogen is commonly used during sample preparation in chemical analysis. It is used to concentrate and reduce the volume of liquid samples. Directing a pressurised stream of nitrogen gas perpendicular to the surface of the liquid causes the solvent to evaporate while leaving the solute(s) and un-evaporated solvent behind.\n\nNitrogen can be used as a replacement, or in combination with, carbon dioxide to pressurise kegs of some beers, particularly stouts and British ales, due to the smaller bubbles it produces, which makes the dispensed beer smoother and headier. A pressure-sensitive nitrogen capsule known commonly as a \"widget\" allows nitrogen-charged beers to be packaged in cans and bottles. Nitrogen tanks are also replacing carbon dioxide as the main power source for paintball guns. Nitrogen must be kept at higher pressure than CO, making N tanks heavier and more expensive. Nitrogen gas has become the inert gas of choice for inert gas asphyxiation, and is under consideration as a replacement for lethal injection in Oklahoma. Nitrogen gas, formed from the decomposition of sodium azide, is used for the inflation of airbags.\n\nLiquid nitrogen is a cryogenic liquid. When insulated in proper containers such as Dewar flasks, it can be transported without much evaporative loss.\nLike dry ice, the main use of liquid nitrogen is as a refrigerant. Among other things, it is used in the cryopreservation of blood, reproductive cells (sperm and egg), and other biological samples and materials. It is used in the clinical setting in cryotherapy to remove cysts and warts on the skin. It is used in cold traps for certain laboratory equipment and to cool infrared detectors or X-ray detectors. It has also been used to cool central processing units and other devices in computers that are overclocked, and that produce more heat than during normal operation. Other uses include freeze-grinding and machining materials that are soft or rubbery at room temperature, shrink-fitting and assembling engineering components, and more generally to attain very low temperatures whenever necessary (around −200 °C). Because of its low cost, liquid nitrogen is also often used when such low temperatures are not strictly necessary, such as refrigeration of food, freeze-branding livestock, freezing pipes to halt flow when valves are not present, and consolidating unstable soil by freezing whenever excavation is going on underneath.\n\nAlthough nitrogen is non-toxic, when released into an enclosed space it can displace oxygen, and therefore presents an asphyxiation hazard. This may happen with few warning symptoms, since the human carotid body is a relatively poor and slow low-oxygen (hypoxia) sensing system. An example occurred shortly before the launch of the first Space Shuttle mission in 1981, when two technicians died from asphyxiation after they walked into a space located in the Shuttle's Mobile Launcher Platform that was pressurised with pure nitrogen as a precaution against fire.\n\nWhen inhaled at high partial pressures (more than about 4 bar, encountered at depths below about 30 m in scuba diving), nitrogen is an anesthetic agent, causing nitrogen narcosis, a temporary state of mental impairment similar to nitrous oxide intoxication.\n\nNitrogen dissolves in the blood and body fats. Rapid decompression (as when divers ascend too quickly or astronauts decompress too quickly from cabin pressure to spacesuit pressure) can lead to a potentially fatal condition called decompression sickness (formerly known as caisson sickness or \"the bends\"), when nitrogen bubbles form in the bloodstream, nerves, joints, and other sensitive or vital areas. Bubbles from other \"inert\" gases (gases other than carbon dioxide and oxygen) cause the same effects, so replacement of nitrogen in breathing gases may prevent nitrogen narcosis, but does not prevent decompression sickness.\n\nAs a cryogenic liquid, liquid nitrogen can be dangerous by causing cold burns on contact, although the Leidenfrost effect provides protection for very short exposure (about one second). Ingestion of liquid nitrogen can cause severe internal damage. For example, in 2012, a young woman in England had to have her stomach removed after ingesting a cocktail made with liquid nitrogen.\n\nBecause the liquid-to-gas expansion ratio of nitrogen is 1:694 at 20 °C, a tremendous amount of force can be generated if liquid nitrogen is rapidly vaporised in an enclosed space. In an incident on January 12, 2006 at Texas A&M University, the pressure-relief devices of a tank of liquid nitrogen were malfunctioning and later sealed. As a result of the subsequent pressure buildup, the tank failed catastrophically. The force of the explosion was sufficient to propel the tank through the ceiling immediately above it, shatter a reinforced concrete beam immediately below it, and blow the walls of the laboratory 0.1–0.2 m off their foundations.\n\nLiquid nitrogen readily evaporates to form gaseous nitrogen, and hence the precautions associated with gaseous nitrogen also apply to liquid nitrogen. For example, oxygen sensors are sometimes used as a safety precaution when working with liquid nitrogen to alert workers of gas spills into a confined space.\n\nVessels containing liquid nitrogen can condense oxygen from air. The liquid in such a vessel becomes increasingly enriched in oxygen (boiling point −183 °C, higher than that of nitrogen) as the nitrogen evaporates, and can cause violent oxidation of organic material.\n\n\n"}
{"id": "14787239", "url": "https://en.wikipedia.org/wiki?curid=14787239", "title": "Nuclear exclusion clause", "text": "Nuclear exclusion clause\n\nThe nuclear exclusion clause is a clause which excludes damage caused by nuclear and radiation accidents from regular insurance policies of, for example, home owners. \n\nAs operators of nuclear power plants often have limited third-party liability, in the case of a nuclear accident it is possible that private property damage would be covered neither by the operator of the nuclear power plant nor by the property owners' insurance.\n\nThere is no nuclear exclusion clause in health insurance policies. \n\n"}
{"id": "14668841", "url": "https://en.wikipedia.org/wiki?curid=14668841", "title": "Oil megaprojects (2017)", "text": "Oil megaprojects (2017)\n\nThis page summarizes projects that propose to bring more than of new liquid fuel capacity to market with the first production of fuel beginning in 2017. This is part of the Wikipedia summary of Oil Megaprojects. \n"}
{"id": "12212114", "url": "https://en.wikipedia.org/wiki?curid=12212114", "title": "On-board scale", "text": "On-board scale\n\nFor many types of trucks, knowing the loaded weight is important for operating safely and maximising payload whilst avoiding fines for overloading. There are two ways that a driver can determine the approximate loaded weight — either by driving to an in-ground scale, or using on-board scales. On-board scales use either load cell technology or pressure readings from air suspension to calculate the weight on the vehicle axles. Operating the truck at its optimal payload ensures that the owner minimises his running costs whilst maximising his profit.\n\nThe convenience of being able to weigh at the loading site is a key factor in the popularity of on-board scales. This ability eliminates the costs associated with using an in-ground scale, such as lost hours of service, scale fees, and driver wages.\n\nThere are essentially four types of on-board scales currently in use:\n\nLoad-cell scales are based on electronic load cell transducers, and can be mechanical or strain-gauge. There is a wide variety of scale types that can be built with load cell technology. Typically load cells are used in payload scales for vehicles with spring suspension.\n\nAir-suspension PSI gauges are used on commercial trucks and semi-trailers where accurate weights are not as critical.\n\nLoad scales for air-ride applications that show on-the-ground weight in pounds (LBS) or kilograms (KG) instead of standard PSI. These non-electric gauges are analog (dial-face) with versions that can calibrate for accuracy.\n\nElectronic scales with PSI sensors measure temperature and pressure changes in a vehicle’s air suspension. It relays this data to a receiver hardwired into the cab, or wirelessly to a handheld unit, which interprets the data and displays an approximate axle weight or gross vehicle weight.\n"}
{"id": "1286008", "url": "https://en.wikipedia.org/wiki?curid=1286008", "title": "Overhead line crossing", "text": "Overhead line crossing\n\nAn overhead line crossing is the crossing of an obstacle—such as a traffic route, a river, a valley or a strait—by an overhead power line. The style of crossing depends on the local conditions and regulations at the time the power line is constructed. Overhead line crossings can sometimes require extensive construction and can also have operational issues. In such cases, those in charge of construction should consider whether a crossing of the obstacle would be better accomplished by an underground or submarine cable.\n\nOverhead line crossings of roads, railway lines, and small- and medium-sized watercourses do not normally require special construction. However, in the first years of overhead line building a scaffold under the line was required, when a railway line or a road was crossed. Later in Germany and some other countries on each end of a powerline crossing of a state-operated railway a dead-end tower was required, which can still be seen on some old power lines. For overhead line crossings of motorways the pylons must be rebuilt before they wear out, because these demand additional maintenance. If local conditions are appropriate, an overhead line can be implemented by way of a valley bridge. For example, the Koersch valley bridge near Esslingen, Germany carries the 110 kV, three-phase line of the EnBW AG with 2 circuits. Because of the danger of short circuits from falling objects, undercrossings are typically avoided.\n\nThere is frequently an anchor pylon on each side of the border, particularly if the lines on either side of the border are operated by different companies. This setup reduces maintenance work, which would otherwise require direct coordination of workers on both sides of the border, and avoids possible authority problems associated with border crossings as much as possible.\n\nAt crossings of overhead lines by other overhead lines, the two lines must be kept at the necessary safety distances between the lines and the ground. As a rule, the line with the lower voltage passes under the line with higher voltage. Construction workers try to plan these crossings in such a way that their construction is as economical as possible. This is usually done by leaving unchanged the line that is crossed, if possible. Undercrossings of existing lines are often constructed in proximity to the line's pylons, since this can often be accomplished without raising the existing pylons and while keeping the necessary safety distances between the ground and the other line.\n\nIn the course of undercrossings the pylon picture is frequently changed, and because of its small height it is preferable to create an arrangement with conductors in one level. Sometimes at such crossings there can be problems because of the maximum pylon height allowed for flight safety reasons. If it is not possible at a given location for the pylons of the upper line to be built at a necessary height, the line running below it will be rebuilt on smaller pylons or replaced with an underground cable.\n\nA unique undercrossing of two powerlines can be found north of Kincardine at Scotland at 56°5'17\"N 3°43'11\"W. Here crosses the powerline Kincardine-Tealing two other lines. One of the two circuits of Kincardine-Tealing powerline crosses these lines on two small pylons and the other circuit via an underground cable.\n\nThere are some crossings between two overhead powerlines, which are unique, either as both lines are of special type or the unique way of implementation\n\nOverhead lines should cross the route of an aerial tramway only above it, if at all.\n\nThe necessary protection distances from overhead lines to the ropes of an aerial tramway are subject to regulations concerning the construction of aerial tramways and overhead lines. In the case of an undercrossing of an aerial tramway, the maximum safety distances between the overhead line and the floor of the aerial tramway cab must be followed absolutely.\n\nIn principle, over- and undercrossings of aerial tramways are completely regulated. However, frequently at the range of the crossing section, special precautionary measures are taken. Thus, at overhead line crossings at which the overhead line runs above the rope of the aerial tramway, two catch ropes are occasionally installed to prevent the conductor from falling off the rope of the tramway in case a pylon or insulator were to break. Alternatively, auxiliary cross-bars can be installed on the pylons of the overhead line under the conductors, which prevent the conductor cables from falling in case of an insulator failure on the aerial tramway. Occasionally, the span field of the line over the aerial ropeway can be scaffolded with a rigid construction along its whole length, or at least for the span which crosses the aerial tramway.\n\nAt crossings at which the aerial tramway runs above the power line, the line is frequently installed on special masts in the crossing range, which scaffold the line in the area of the aerial tramway crossing. Such a measure is not necessary according to power line regulations, but it is often done because, in case of aerial tramway failure, it is possible to rescue people from the tram without switching off the overhead line. Such constructions may be seen at 110 kV power line crossings of the Penkenbahn at Mayrhofen, the Patscherkofelbahn at Innsbruck and south of Zermatt.\n\nOverhead line crossings of broad rivers and of straits, if the terrain on both sides is relatively even, frequently consist of four pylons: two particularly substantial anchor pylons for bracing the conductors of the crossing section, and two tall carrying masts to keep the line high over the water. These pylons have broader cross-bars and greater distances between the cross-bars than the other pylons of the line, in order to prevent the conductor cables from striking against each other during strong winds. In contrast to normal pylons, the two carrying masts at both ends of the crossing are frequently equipped with flight safety lamps, and have stairways for easy access to the top.\n\nOverhead line crossings of rivers and straits with spans of over 2 km are frequently prohibitively expensive to build and operate; because of the danger of wind-induced oscillatory movements of the conductor cables, it is necessary either to install very large leader distances or to mount insulators between the conductors in the area of the span. Bundle conductors, which are used for almost all extra-high voltage lines, are more susceptible to oscillations from wind forces than single conductors. Therefore, single conductors must be used for the crossing section, which means the crossing section of the power line determines the maximum transmittable power.\n\nFurther, one cannot build pylons arbitrarily high at either end of the crossing section, and there is a usually a considerable minimum height because of ships crossing under the line, so there is often a high mechanical tension in the conductors at long spans. This tension requires conductors made largely of steel, which have a worse electrical conductivity than the common overhead line conductors consisting of copper, Aldrey or aluminum-encased steel, and also limits the amount of transmittable electrical power. For this reason, for crossings with a span width of more than approximately 2 km, those in charge of construction should consider laying an underwater cable as the more practicable solution.\n\nAlternatively, it might be possible to erect one or more pylons in the water to be crossed. Such crossings can be seen occasionally in North America. They are, however, only used when it is more economical and practical to do so than to lay a cable underwater, such as when the water is not very deep and no large passage heights are needed for vessels. Also, such construction can be very problematic as far as getting legal permission to build, because pylons standing in the water are likely to be considered dangerous obstacles for ships, especially in foggy conditions.\n\nIn some cases on bridges small crossing a wider waterway pylons or crossbars for the conductors can be mounted. Such a solution, which may lead to safety problems at bridge maintenance, was for example realized at the Danish Storstrøm Bridge.\n\nIt is quite likely that overhead line crossings of broad waters can be replaced with underwater cables. The overhead line crossing the Strait of Messina — which, with a span of 3646 meters, was one of the longest overhead line crossings in the world, with 200-meter pylons among the highest in the world — was replaced by a submarine cable, because of its small maximum transmittable electrical power.\n\nOverhead line crossings of valleys consist of two anchor pylons, one at either end of the valley. If the topography of the valley is suitable, these do not need to be very high. In very wide valleys, it is better to use a pylon for each phase in order to achieve sufficient distance between the conductors. In these cases there is frequently a further anchor pylon behind the crossing, used in order to realize the angle change of the conductor cables behind these. The problems associated with large spans also exist in these cases, but these can be easily and economically ameliorated, if the topography does not require high crossing pylons, by using a separate pylon for each conductor.\n\nA \"crossing pylon\" is used for crossing over a body of water or a valley. Due to the long span, crossing pylons across rivers and sea straits are frequently taller than standard pylons. They may have marking lamps, and unlike standard pylons, often have stairways for easy access to the top. In many cases, their height makes them ideal for carrying radio antennas and transmitting equipment.\n\nCrossing pylons for valleys, depending on the local topography, are not necessarily tall, but the distance between the conducting cables must be sufficient to prevent high winds knocking the conductors into one another; these pylons have wide crossbars to prevent this. For very long spans each phase has a separate pylon, particularly if the pylons are short.\n\nSpecial crossing pylons are often used where aerial tramways cross power lines. These pylons are designed with integral scaffolding so that the tramway cars can be reached without touching a live power line. This enables passengers to be rescued from the tramway if it fails without cutting the power from the power line. Such installations can be found, for example, south of Zermatt, Switzerland; at the Patscherkofelbahn near Innsbruck, Austria; and at the Penkenbahn in Mayrhofen, Austria.\n\n\nThis article draws heavily on the in the German-language Wikipedia.\n"}
{"id": "994887", "url": "https://en.wikipedia.org/wiki?curid=994887", "title": "Petroleum industry", "text": "Petroleum industry\n\nThe petroleum industry, also known as the oil industry or the oil patch, includes the global processes of exploration, extraction, refining, transporting (often by oil tankers and pipelines), and marketing of petroleum products. The largest volume products of the industry are fuel oil and gasoline (petrol). Petroleum (oil) is also the raw material for many chemical products, including pharmaceuticals, solvents, fertilizers, pesticides, synthetic fragrances, and plastics. The extreme monetary value of oil and its products has led to it being known as \"black gold\". The industry is usually divided into three major components: upstream, midstream, and downstream. \n\nPetroleum is vital to many industries, and is necessary for the maintenance of industrial civilization in its current configuration, making it a critical concern for many nations. Oil accounts for a large percentage of the world’s energy consumption, ranging from a low of 32% for Europe and Asia, to a high of 53% for the Middle East.\n\nOther geographic regions' consumption patterns are as follows: South and Central America (44%), Africa (41%), and North America (40%). The world consumes 30 billion barrels (4.8 km³) of oil per year, with developed nations being the largest consumers. The United States consumed 25% of the oil produced in 2007. The production, distribution, refining, and retailing of petroleum taken as a whole represents the world's largest industry in terms of dollar value.\n\nGovernments such as the United States government provide a heavy public subsidy to petroleum companies, with major tax breaks at virtually every stage of oil exploration and extraction, including the costs of oil field leases and drilling equipment.\n\nIn recent years, enhanced oil recovery techniques — most notably multi-stage drilling and hydraulic fracturing, together commonly known as \"fracking\" — have moved to the forefront of the industry as this new technology plays a crucial and controversial role in new methods of oil extraction.\n\nPetroleum is a naturally occurring liquid found in rock formations. It consists of a complex mixture of hydrocarbons of various molecular weights, plus other organic compounds. It is generally accepted that oil is formed mostly from the carbon rich remains of ancient plankton after exposure to heat and pressure in Earth's crust over hundreds of millions of years. Over time, the decayed residue was covered by layers of mud and silt, sinking further down into Earth’s crust and preserved there between hot and pressured layers, gradually transforming into oil reservoirs.\n\nPetroleum in an unrefined state has been utilized by humans for over 5000 years. Oil in general has been used since early human history to keep fires ablaze and in warfare.\n\nIts importance to the world economy however, evolved slowly, with whale oil being used for lighting in the 19th century and wood and coal used for heating and cooking well into the 20th century. Even though the Industrial Revolution generated an increasing need for energy, this was initially met mainly by coal, and from other sources including whale oil. However, when it was discovered that kerosene could be extracted from crude oil and used as a lighting and heating fuel, the demand for petroleum increased greatly, and by the early twentieth century had become the most valuable commodity traded on world markets.\n\nImperial Russia produced 3,500 tons of oil in 1825 and doubled its output by mid-century. After oil drilling began in what is now Azerbaijan in 1846 in Baku, two large pipelines were built in the Russian Empire: the 833 km long pipeline to transport oil from the Caspian to the Black Sea port of Batum (Baku-Batum pipeline), completed in 1906, and the 162 km long pipeline to carry oil from Chechnya to the Caspian. Batum is renamed to Batumi in 1936.\n\nAt the turn of the 20th century, Imperial Russia's output of oil, almost entirely from the Apsheron Peninsula, accounted for half of the world's production and dominated international markets. Nearly 200 small refineries operated in the suburbs of Baku by 1884. As a side effect of these early developments, the Apsheron Peninsula emerged as the world's \"oldest legacy of oil pollution and environmental negligence.\" In 1846, Baku (Bibi-Heybat settlement) the first ever well drilled with percussion tools to a depth of 21 meters for oil exploration. In 1878, Ludvig Nobel and his Branobel company \"revolutionized oil transport\" by commissioning the first oil tanker and launching it on the Caspian Sea.\n\nSamuel Kier established America's first oil refinery in Pittsburgh on Seventh avenue near Grant Street, in 1853. One of the first modern oil refineries were built by Ignacy Łukasiewicz near Jasło (then in the dependent Kingdom of Galicia and Lodomeria in Central European Galicia), Poland in 1854–56. These were initially small, as demand for refined fuel was limited. The refined products were used in artificial asphalt, machine oil and lubricants, in addition to Łukasiewicz's kerosene lamp. As kerosene lamps gained popularity, the refining industry grew in the area.\n\nThe first commercial oil well in Canada became operational in 1858 at Oil Springs, Ontario (then Canada West). Businessman James Miller Williams dug several wells between 1855 and 1858 before discovering a rich reserve of oil four metres below ground. Williams extracted 1.5 million litres of crude oil by 1860, refining much of it into kerosene lamp oil. Some historians challenge Canada’s claim to North America’s first oil field, arguing that Pennsylvania’s famous Drake Well was the continent’s first. But there is evidence to support Williams, not least of which is that the Drake well did not come into production until August 28, 1859. The controversial point might be that Williams found oil above bedrock while Edwin Drake’s well located oil within a bedrock reservoir. The discovery at Oil Springs touched off an oil boom which brought hundreds of speculators and workers to the area. Canada's first gusher (flowing well) erupted on January 16, 1862, when local oil man John Shaw struck oil at 158 feet (48 m). For a week the oil gushed unchecked at levels reported as high as 3,000 barrels per day.\n\nThe first modern oil drilling in the United States began in West Virginia and Pennsylvania in the 1850s. Edwin Drake's 1859 well near Titusville, Pennsylvania, is typically considered the first true modern oil well, and touched off a major boom. In the first quarter of the 20th century, the United States overtook Russia as the world's largest oil producer. By the 1920s, oil fields had been established in many countries including Canada, Poland, Sweden, Ukraine, the United States, Peru and Venezuela.\n\nThe first successful oil tanker, the \"Zoroaster\", was built in 1878 in Sweden, designed by Ludvig Nobel. It operated from Baku to Astrakhan. A number of new tanker designs were developed in the 1880s.\n\nIn the early 1930s the Texas Company developed the first mobile steel barges for drilling in the brackish coastal areas of the Gulf of Mexico. In 1937 Pure Oil Company (now part of Chevron Corporation) and its partner Superior Oil Company (now part of ExxonMobil Corporation) used a fixed platform to develop a field in of water, one mile (1.6 km) offshore of Calcasieu Parish, Louisiana. In early 1947 Superior Oil erected a drilling/production oil platform in of water some 18 miles off Vermilion Parish, Louisiana. It was Kerr-McGee Oil Industries (now Anadarko Petroleum Corporation), as operator for partners Phillips Petroleum (ConocoPhillips) and Stanolind Oil & Gas (BP), that completed its historic Ship Shoal Block 32 well in November 1947, months before Superior actually drilled a discovery from their Vermilion platform farther offshore. In any case, that made Kerr-McGee's Gulf of Mexico well, Kermac No. 16, the first oil discovery drilled out of sight of land. Forty-four Gulf of Mexico exploratory wells discovered 11 oil and natural gas fields by the end of 1949.\nDuring World War II (1939-1945) - control of oil supply from Baku and Middle East played a huge role in the events of the war and the ultimate victory of the allies. Cutting off the oil supply considerably weakened Japan in the latter part of the war.\nAfter World War II ended, the countries of the Middle East took the lead in oil production from the United States. Important developments since World War II include deep-water drilling, the introduction of the Drillship, and the growth of a global shipping network for petroleum relying upon oil tankers and pipelines. In 1949, first offshore oil drilling at Oil Rocks (Neft Dashlari) in the Caspian Sea off Azerbaijan eventually resulted in a city built on pylons. In the 1960s and 1970s, multi-governmental organizations of oil–producing nations OPEC and OAPEC played a major role in setting petroleum prices and policy. Oil spills and their cleanup have become an issue of increasing political, environmental, and economic importance.\n\nWith the advent of hydraulic fracturing and other horizontal drilling techniques, shale play has seen an enormous uptick in production. Areas such as the Permian Basin and Eagle-Ford shales are now huge hotbeds of production for the largest oil corporations in the country.\n\nThe American Petroleum Institute divides the petroleum industry into five sectors:\n\nOil companies used to be classified by sales as \"supermajors\" (BP, Chevron, ExxonMobil, ConocoPhillips, Shell, Eni and Total S.A.), \"\"majors\",\" and \"\"independents\" or \"jobbers\".\" In recent years however, National Oil Companies (NOC, as opposed to IOC, International Oil Companies) have come to control the rights over the largest oil reserves; by this measure the top ten companies all are NOC. The following table shows the ten largest national oil companies ranked by reserves and by production in 2012.\n\nMost upstream work in the oil field or on an oil well is contracted out to drilling contractors and oil field service companies.\n\nAside from the NOCs which dominate the Upstream sector, there are many international companies that have a market share. For example:\n\nMidstream operations are sometimes classified within the downstream sector, but these operations compose a separate and discrete sector of the petroleum industry. Midstream operations and processes include the following:\n\nWhile some upstream companies carry out certain midstream operations, the midstream sector is dominated by a number of companies that specialize in these services. Midstream companies include:\n\nSome petroleum industry operations have been responsible for water pollution through by-products of refining and oil spills. Though hydraulic fracturing has significantly increased natural gas extraction, there is some belief and evidence to support that consumable water has seen increased in methane contamination due to this gas extraction. Leaks from underground tanks and abandoned refineries may also contaminate groundwater in surrounding areas. Hydrocarbons that comprise refined petroleum are resistant to biodegradation and have been found to remain present in contaminated soils for years. To hasten this process, bioremediation of petroleum hydrocarbon pollutants is often employed by means of aerobic degradation. More recently, other bioremediative methods have been explored such as phytoremediation and thermal remediation. \n\nThe industry is the largest industrial source of emissions of volatile organic compounds (VOCs), a group of chemicals that contribute to the formation of ground-level ozone (smog). The combustion of fossil fuels produces greenhouse gases and other air pollutants as by-products. Pollutants include nitrogen oxides, sulphur dioxide, volatile organic compounds and heavy metals.\n\nResearchers have discovered that the petrochemical industry can produce ground-level ozone pollution at higher amounts in winter than in summer..\n\nThe greenhouse gases due to fossil fuels drive global warming. Already in 1959, at a symposium organised by the American Petroleum Institute for the centennial of the American oil industry, the physicist Edward Teller warned then of the danger of global climate change. Edward Teller explained that carbon dioxide \"in the atmosphere causes a greenhouse effect\" and that burning more fossil fuels could \"melt the icecap and submerge New York\".\n\nThe Intergovernmental Panel on Climate Change, founded by the United Nations in 1988, concludes that human-sourced greenhouse gases are responsible for most of the observed temperature increase since the middle of the twentieth century.\n\nAs a result of climate change concerns, many alternative energy enthusiasts have began using other methods of energy such as solar and wind, among others. This recent view has some petroleum enthusiasts skeptic about the true future of the industry. \n\nAs petroleum is a non-renewable natural resource the industry is faced with an inevitable eventual depletion of the world's oil supply. The BP Statistical Review of World Energy 2007 listed the reserve/production ratio for proven resources worldwide. This study indicated a ratio of proven reserves to production in the Middle East at 79.5 years, Latin America at 41.2 years and North America at 12 years. A misguided interpretation of the ratio has led to many false predictions of imminent world oil shortages since the early years of the oil industry in the 1800s. This has been especially true in the United States, where the ratio of proved reserves-to-production has been between 8 years and 17 years since 1920. Many have mistakenly interpreted the result as the number of years before the oil supply is exhausted. Such analyses do not take into account future reserves growth.\n\nThe Hubbert peak theory, which introduced the concept of peak oil, questions the sustainability of oil production. It suggests that after a peak in oil production rates, a period of oil depletion will ensue. Since virtually all economic sectors rely heavily on petroleum, peak oil could lead to a partial or complete failure of markets.\n\nAccording to market research by IBISWorld, biofuels (primarily ethanol, but also biodiesel) will continue to supplement petroleum. However output levels are low, and these fuels will not displace local oil production. More than 90% of the ethanol used in the US is blended with gasoline to produce a 10% ethanol mix, lifting the oxygen content of the fuel.\n\n\n"}
{"id": "21269385", "url": "https://en.wikipedia.org/wiki?curid=21269385", "title": "Philippine Airlines Flight 158", "text": "Philippine Airlines Flight 158\n\nPhilippine Airlines Flight PR158 was a Philippine Airlines flight from Mactan-Cebu International Airport to Manila International Airport in Manila which crashed on 12 September 1969. The aircraft, a BAC One-Eleven, struck a mango tree on the hill in suburban Kula-ike, Antipolo City, east of its destination while on a VOR approach to runway 24.\nOf the 42 passengers and five crewmembers on board, only one passenger and one flight attendant survived, both of whom were hospitalized with burns.\n\nMateo Ranillo was the pilot, father of actor Mat Ranillo III.\nLT.Col. Felix del Roario was co-pilot, he hailed from Taytay Rizal, a town just below the hills west of Antipolo.\n\nThe aircraft crashed due to turbulent high winds, and heavy rainstorm, with poor visibility at night. At the time, it was the worst accident involving a BAC One-Eleven. It was surpassed by EAS Airlines Flight 4226, which crashed on May 4, 2002 with 149 fatalities.\n\n"}
{"id": "7936939", "url": "https://en.wikipedia.org/wiki?curid=7936939", "title": "Potential density", "text": "Potential density\n\nThe potential density of a fluid parcel at pressure formula_1 is the density that the parcel would acquire if adiabatically brought to a reference pressure formula_2, often 1 bar (100 kPa). Whereas density changes with changing pressure, potential density of a fluid parcel is conserved as the pressure experienced by the parcel changes (provided no mixing with other parcels or net heat flux occurs). The concept is used in oceanography and (to a lesser extent) atmospheric science. \n\nPotential density is a dynamically important property: for static stability potential density must decrease upward. If it doesn't, a fluid parcel displaced upward finds itself lighter than its neighbors, and continues to move upward; similarly, a fluid parcel displaced downward would be heavier than its neighbors. This is true even if the density of the fluid decreases upward. In stable conditions (potential density decreasing upward) motion along surfaces of constant potential density (isopycnals) is energetically favored over flow across these surfaces (diapycnal flow), so most of the motion within a 3-D geophysical fluid takes place along these 2-D surfaces. \n\nIn oceanography, the symbol formula_3 is used to denote \"potential density\", with the reference pressure formula_4 taken to be the pressure at the ocean surface. The corresponding \"potential density anomaly\" is denoted by formula_5 kg/m. Because the compressibility of seawater varies with salinity and temperature, the reference pressure must chosen to be near the actual pressure to keep the definition of potential density dynamically meaningful. Reference pressures are often chosen as a whole multiple of 100 bar; for water near a pressure of 400 bar (40 MPa), say, the reference pressure 400 bar would be used, and the potential density anomaly symbol would be written formula_6.\nSurfaces of constant potential density (relative to and in the vicinity of a given reference pressure) are used in the analyses of ocean data and to construct models of ocean currents. Neutral density surfaces, defined using another variable called neutral density (formula_7), can be considered the continuous analog of these potential density surfaces.\n\nPotential density adjusts for the effect of compression in two ways:\n\nA parcel's density may be calculated from an equation of state:\nwhere formula_9 is temperature, formula_1 is pressure, and formula_11 are other tracers that affect density (e.g. salinity of seawater). The potential density would then be calculated as:\nwhere formula_13 is the potential temperature of the fluid parcel for the same reference pressure formula_4.\n\nPotential energy\n"}
{"id": "24387025", "url": "https://en.wikipedia.org/wiki?curid=24387025", "title": "Pullapart", "text": "Pullapart\n\nPullApart is a UK-based, independent packaging recycling classification system. Applied at the kerbside, it combines environmental and consumer packaging surveys to provide customers with a measurement of the ease with which specific types of packaging may be recycled locally. The process was invented by Michael Butler of Dawlish in 2005, and is operated for free.\n\nAs PullApart is applied to existing local authority-installed recycling bin refuse collection systems, its scoring scheme is dependent on individual local authorities’ own packaging disassembly practices. Sample packaging is disassembled, according to the Local Authority’s process, rearranged and its components graded for ease of recycling. The raw information from this exercise is also made available to the public.\n\nA final, consumer-oriented \"PAC\" (PullApart Code) score is achieved by measuring what proportion of a product's components is recyclable from the kerbside. The PAC score is represented by 13 stages of ‘traffic light’ grading.\n\nPullApart’s stated aims are to encourage, manufactures, retailers, food and agricultural producers to give greater weight to the ease of disposal and recycling in their packaging designs. Weighting the consumers point of view equally to that of packaging manufactures, retailers and recyclers, in the handling of domestic waste products for kerbside collections. To provide consumers with information enabling product choice (ethical consumerism), that's easy, local and totally kerbside recyclable. Furnishing an unambiguous tool, that measures the differences between those mentioned above, assisting in the optimisation of products for the goal of near Zero waste.\n\nAccording to PullApart’s current Teignbridge (2011) survey of over 2000 products, 2.84% are ideally suited for kerbside recycling and a further 29.32% are good, whilst the rest fail. The sample area, Teignbridge, and therefore Teignbridge District Council, has a current recycling rate of 57% (2008/2009), (by weight). Quoting from their periodical, “Teignbridge Life” explaining to local people how PullApart works: “The online packaging recycling guide features a free search function which classifies ordinary consumer products, like cereal boxes, with a 'PullApart' rating. The rating breaks the product down into its components, explaining which parts can be recycled in Teignbridge.”\n\nPullApart is considered to be of “Environmental Best Practice” by The Green Organisation.\n\nWorldwide there are broader packaging scoring systems that address the full environmental impact of packaging. Recycling being one factor, other vital considerations include the use of recycled materials in the package, avoidance of toxic substances, minimization of packaging, effects on atmosphere (greenhouse gas, VOC, etc.), use of renewable resources, etc. Efforts involve methodologies such as life cycle assessment to inventory the all environmental impacts and factors.\nThere are many Sustainability metrics and indices, some specifically for packaging.\n\n\n"}
{"id": "21376140", "url": "https://en.wikipedia.org/wiki?curid=21376140", "title": "Reusable shopping bag", "text": "Reusable shopping bag\n\nA reusable shopping bag, sometimes called bag-for-life in the UK, is a type of shopping bag which can be reused many times. It is an alternative to single-use paper or plastic bags. It is often made from fabric such as canvas, natural fibres such as Jute, woven synthetic fibers, or a thick plastic that is more durable than disposable plastic bags, allowing multiple use.\n\nReusable shopping bags are a kind of carrier bag, which are available for sale in supermarkets and apparel shops. Some reusable bags have been found to contain high amounts of lead. Reusable bags require more energy to produce than common plastic shopping bags. one reusable bag requires the same amount of energy as an estimated 28 traditional plastic shopping bags or eight paper bags. \"If used once per week, four or five reusable bags will replace 520 plastic bags a year\", according to Nick Sterling, research director at Natural Capitalism Solutions. A study commissioned by the United Kingdom Environment Agency in 2005 found that the average cotton bag is used only 51 times before being thrown away. In some cases, reusable bags need to be used over 100 times before they are better for the environment than single-use plastic bags.\n\nFirst introduced in the US in 1977, plastic shopping bags for bagging groceries at stores flourished in the 1980s and 1990s, replacing paper bags. In 1990s, governments in some countries started to impose taxes on distribution of disposable plastic bags or to regulate the use of them. Some supermarkets have encouraged shoppers to stop using disposable plastic bags, by for example offering inexpensive reusable shopping bags or providing information on plastic bags environmental damage. The physical shape of reusable shopping bags is often different than was typical before the prevalence of plastic bags. The apparel industry promotes reusable shopping bags as sustainable fashion.\n\nMany supermarkets encourage the use of reusable shopping bags to increase sales and profit margins. Most non woven bags cost $0.10-0.25 to produce but are sold for $0.99-$3.00. As stores receive diminishing returns due to saturated markets, there are concerns that prices will drop and they will become the new single-use bag. Some major supermarket chains have string or calico bags available for sale. They are sold with announcement of environmental issues in many cases. The ones sold in supermarkets often have designs related to nature, such as prints of trees or that of the earth, in order to emphasize environmental issues. One startup company out of Duluth, Minnesota, embroiders their bags with their local Aerial Lift Bridge on it. Some supermarkets have rewards programs for customers who bring own shopping bags. When the customers collect a certain amount of points, they can usually get discount coupons or gifts, which motivate customers to reduce plastic bag use. Some retailers such as Whole Foods Market and Target offer a cash discount for bringing in reusable bags.\n\nSince 1999, 6.25 billion reusable bags were imported into the United States for resale and give-aways under Harmonized Tariff Code (HTC) 4202923031 as reported by the United States International Trade Commission.\n\nMost U.S. grocery store customers do not bring their own bags, and many reusable bags go unused by customers, according to a 2008 article in the \"Wall Street Journal\".\n\nIn 2009, Walmart Stores proposed turning three California stores into reusable bag only stores. Concurrently, Walmart was prepared to introduce a $0.15 reusable bag. On 23 October 2009, Walmart abandoned plans to remove carrier bags and introduced the new lower-cost bags. In contrast to previous bags sold at $0.99 and $0.50, these lower cost bags may reduce price incentive to reuse these heavier-duty bags.\n\nReusable shopping bags are offered in most British supermarkets. These are sold for a nominal sum, usually 10 pence, and are replaced for free. The bags are more durable than standard bags, meaning that they can be reused many times over.\n\nThe main purpose of this is to ensure that packaging waste legislation was met and to encourage the bags to be recycled (which usually earns the retailer a small amount of money per bag), and unlike with 5p carrier bags there is a (small) financial incentive to bring the bags back for recycling, lessening the environmental impact.\n\nIn contrast to most spartan carrier bags, bags for life tend to be colourful and sometimes show some aspect of the supermarket's advertising. Some supermarkets maintain the same design for years at a time, whereas some, like Waitrose, rotate the designs to tie in with either the season or the most recent advertising campaign.\n\nWaitrose was the first British Supermarket to launch Bag For Life in association with British Polythene Industries. It was the brainchild of Gini Ekstein, from British Polythene industries. Gini Ekstein with Paul Oustedal and Nick Jones, of Waitrose, launched Bag For Life in 1998. It was the first closed-loop recycling initiative; returned and broken bags are made into black benches places outside Waitrose stores. The initial marketing messages designed by Gini Ekstein, British Polythene Industries and Beth Chiles, of Message Marketing, are still in use today. As of April 2008, Marks and Spencer are giving their \"bags for life\" free to every customer, as their normal plastic bags will have to be paid for from May 6. This will be a small sum of 5 pence a carrier. The bags are given to the customer every time they shop, so they will have plenty when the switchover in May comes live. Later on, Sainsbury's and other supermarkets introduced the \"bag for life\". As of 2016, the UK Government introduced a tax on all carrier bags, which means that every consumer pays 5p for any carrier bag from any store.\n\nReusable plastic bags do however have a very simple end of life disposal route. Most reusable plastic carrier bags are made from LDPE 4 (Low Density Poly-Ethylene) which is the easiest form of plastic to recycle currently in the UK (August 2018). These types of plastic carrier bag (along with 'single use' plastic carrier bags) can be recycled with many local council kerbside collections in the UK. \n\nThe increasing use of jute and juco bags (a mix of cotton and jute) has provided a natural alternative to single-use plastic bags and reusable plastic bags. These are found in many of the major supermarkets, and over 50 million have been sold in the UK alone. These bags have a 3-4 year lifespan and so are often seen as the ecological option. \nJute bags have become a crossover product from an alternative to plastics to a fashion/shopper accessory. Jute bags will last for about 4 years – if used correctly will replace over 600 single bags. At end of life, they can be used as planters for growing garden vegetables.\n\nIn Ireland, they were introduced in March 2002, when the Plastic Bag Environmental Levy was brought in to reduce the massive amount of disposable bags being used annually. Bags costing 70 euro cents or more are exempt from the levy.\n\nIntroduced in the 90s, these bags are known as green bags in Australia due to their relative environmental friendliness and usual (though far from universal) green color. Green Bags and similar reusable shopping bags are commonly distributed at the point of sale by supermarkets and other retail outlets. They are intended to be reused repeatedly to replace the use of hundreds of High-density polyethylene (HDPE) plastic bags. Most green bags are made of 100% Non-woven Polypropylene (NWPP) which is recyclable but not biodegradable. Some companies claim to be making NWPP bags from recycled material, however with current manufacturing techniques this is not possible. All NWPP bags are made from virgin material. Similar bags are made of jute, canvas, calico or hemp but are not discussed here. A typical base insert is 200 mm × 300 mm and weighs 30 g. It is generally made of a stiff plastic.\n\nMost reusable bag shoppers do not wash their bags once they return home, and the bags may be leading to food poisoning, according to Dr. Richard Summerbell, research director at Toronto-based Sporometrics and former chief of medical mycology for the Ontario Ministry of Health. Because of their repeated exposure to raw meats and vegetables, there is an increased risk of foodborne illness. A 2008 study of bags, sponsored by the Environmental and Plastics Industry Council of Canada, found mold and bacterial levels in one reusable bag to be 300% greater than the levels that would be considered safe in drinking water.\nThe study does not differentiate between non-hemp bags and hemp bags, which have natural antimildew and antimicrobial properties.\n\nA 2010 joint University of Arizona and Limo Loma University study (sponsored by the American Chemistry Council, a trade group that advocates on behalf of disposable plastic bag manufacturers) they found that \"Reusable grocery bags can be a breeding ground for dangerous foodborne bacteria and pose a serious risk to public health\". The study found that 97% of users did not wash them and that greater than 50% of the 84 bags contained coliform (a bacterium found in fecal material), while \"E. coli\" was found in 12% of the bags. The study made the following recommendations:\n\nThe study further showed that machine or hand washing even without the presence of bleach was effective in reducing coliform and other bacteria in the bags to levels below detection.\n\nA \"Consumer Reports\" article criticized the 2010 study, calling into question the small sample size of bags examined in the study and the questionable danger of the type and amount of bacteria found. Michael Hansen, senior staff scientist at Consumers Union, stated \"A person eating an average bag of salad greens gets more exposure to these bacteria than if they had licked the insides of the dirtiest bag from this study\". But Hansen notes that there are some reminders to take away from the study. It’s easy to spread bacteria from meat, fish, or poultry to other foods – in your kitchen or in your grocery bags. So he does think it’s wise to carry those items in disposable bags. Reusable bags are fine for most everything else, but it’s a good idea to wash them occasionally.\n\nIn September 2010, \"Wegmans Food Markets Inc., owner of a chain of East Coast supermarkets, announced it would replace reusable shopping bags after a consumer group found the sacks had high levels of lead.\" Bloomberg News also stated that the high levels were related to two specific designs, totaling more than 725,000 bags.\n\nAfter a report in the \"Tampa Tribune\" in November 2010 that elevated levels of lead were found in similar reusable bags, the Food and Drug Administration opened an investigation responding to calls by U.S. environmental and consumer groups, as well as U.S. Senator Charles Schumer, to investigate the reusable bags commonly distributed by grocery stores and large retail chains. Winn-Dixie recalled their bags after they were directly cited in the investigation.\n\nIn December 2010, Canadian-based athletic retailer Lululemon Athletica recalled complimentary reusable bags distributed since November 2009 because \"environmental concerns were raised over the proper disposal of reusable bags due to lead content.\" Sears' Canadian stores announced a recall on reusable bags because of similar findings on January 6, 2011. On January 12, 2011, The Center for Environmental Health announced Disney-themed bags from U.S. grocery chain Safeway have been found to contain levels of lead 15 to 17 times the current federal limit of 300ppm. Safeway recalled bags that had been identified as containing high levels of lead in late January 2011.\n\nIn January 2011, \"USA Today\" ran an article based on a report from the Center for Consumer Freedom, a front group for the \"hospitality industries\", that bags sold in the U.S. by Bloom, Giant, Giant Eagle, Safeway, Walgreens, and other grocery chains and retailers contained levels of lead in excess of 100 parts per million, the maximum amount allowed under law in many U.S. states. They have not produced their testing methods and data, and many organizations feel this was an attempt to discredit the use of reusable bags. Bloom stopped distributing the bags due to toxicity levels prior to the study, but did not recall the bags.\n\nOther concerns have been raised about the safety of reusable bags due to infrequent washing and the presence of bacteria.\n\nIn May 2012, Oregon Public Health published a study in the \"Journal of Infectious Diseases\", traced an outbreak of the dangerous norovirus to a reusable grocery bag that members of a Beaverton girls' soccer team passed around when they shared cookies.\n\nSome governments have encouraged or required the use of reusable shopping bags through the regulation of plastic bags with bans, recycling mandates, taxes or fees. The legislation to discourage plastic bag use has been passed in parts of Hong Kong, Ireland, South Africa, the United States, Canada, and Taiwan.\n\nIn 2002, the Australian federal government studied the use of throwaway plastic bags and threatened to outlaw them if retailers did not voluntarily discourage their use. In 2003, the government negotiated with the Australian Retailers Association a voluntary progressive reduction of plastic bag use which led to a number of initiatives, including the widespread distribution and promotion of Green Bags.\n\nFrom 1 October 2011, the Welsh government began enforcing a minimum tax of 5p on single use carrier bags.\n\nIn 2012, San Luis Obispo County, CA outlawed disposable plastic bags and began requiring shoppers to bring their own bags or pay a 10 cent per bag fee for paper bags. In 2009, the District of Columbia began requiring a 5¢ fee for each disposable bag. In 2012, Portland, Oregon began mandated programs to eliminate disposable checkout bags.\n\nIn 2015, the Canadian province of Quebec voted in a program to ban disposable bags, but the program must be adopted by each municipality. Toronto had tried a similar program, but was eliminated after a short time.\n\nBecause of the encouragement of reusable shopping bags by governments and supermarkets, reusable shopping bags have become one of the new fashion trends. The apparel industry also contributed to making it popular to have fashionable reusable shopping bags instead of disposable plastic bags. In 2007, British designer Anya Hindmarch's $15 \"I'm Not A Plastic Bag\" (an unbleached cotton bag) sold out in one day, and fetched $800 on the Internet. The brand Envirosax started out producing reusable shopping bags, but have expanded their lines with more color and pattern options, in addition to licensing properties like Sesame Street.\n\nEnvironmental concerns, Ostalgie (nostalgia for East Germany), and a general fashion for retro style have led to the resurgence, in all parts of Germany, of what was once considered the frumpy \"Omas Einkaufsnetz\" (Grandma's shopping net). The DDR Museum in Berlin has a collection of \"Einskaufsnetz\", and the bags are now often sold as \"DDR kult Klassiker\" (East German cult classics).\n\nIn terms of consumer behaviour, use of reusable bags is positively correlated with organic purchases and with self-indulgent purchases such as ice cream or cookies.\n\n"}
{"id": "8684198", "url": "https://en.wikipedia.org/wiki?curid=8684198", "title": "Ricinoleic acid", "text": "Ricinoleic acid\n\nRicinoleic acid, formally called 12-hydroxy-9-\"cis\"-octadecenoic acid is a fatty acid. It is an unsaturated omega-9 fatty acid and a hydroxy acid. It is a major component of the seed oil obtained from mature Castor plant (\"Ricinus communis\" L., Euphorbiaceae) seeds or in sclerotium of ergot (\"Claviceps purpurea\" Tul., Clavicipitaceae). About 90% of the fatty acid content in castor oil is the triglyceride formed from ricinoleic acid.\n\nRicinoleic acid is manufactured for industries by saponification or fractional distillation of hydrolyzed castor oil. The zinc salt is used in personal care products, such as deodorants.\n\nThe first attempts to prepare ricinoleic acid were made by Friedrich Krafft in 1888.\n\nRicinoleic acid exerts analgesic and anti-inflammatory effects.\n\nRicinoleic acid specifically activates the EP3 prostanoid receptor for prostaglandin E2.\n\nRicinoleic acid acts as a specific algicide for the control of cyanobacteria (formerly called blue-green algae).\n\n"}
{"id": "4489400", "url": "https://en.wikipedia.org/wiki?curid=4489400", "title": "Rivne Nuclear Power Plant", "text": "Rivne Nuclear Power Plant\n\nThe Rivne Nuclear Power Plant (), also called Rovno is a nuclear power plant in Varash, Rivne Oblast, Ukraine.\n\nIt has four reactors:\nIn 2018 unit 3, after modernisation, received a life-extension licence extending its operation by 20 years until 2037. \n\n\n"}
{"id": "173186", "url": "https://en.wikipedia.org/wiki?curid=173186", "title": "Roll-to-roll processing", "text": "Roll-to-roll processing\n\nIn the field of electronic devices, Roll-to-roll processing, also known as web processing, reel-to-reel processing or R2R, is the process of creating electronic devices on a roll of flexible plastic or metal foil. In other fields predating this use, it can refer to any process of applying coatings, printing, or performing other processes starting with a roll of a flexible material and re-reeling after the process to create an output roll. These processes, and others such as sheeting, can be grouped together under the general term converting. When the rolls of material have been coated, laminated or printed they can be subsequently slit to their finished size on a slitter rewinder.\n\nLarge circuits made with thin-film transistors and other devices can be patterned onto these large substrates, which can be up to a few metres wide and 50 km long. Some of the devices can be patterned directly, much like an inkjet printer deposits ink. For most semiconductors, however, the devices must be patterned using photolithography techniques.\n\nRoll-to-roll processing of large-area electronic devices reduces manufacturing cost. Most notable would be solar cells, which are still prohibitively expensive for most markets due to the high cost per unit area of traditional bulk (mono- or polycrystalline) silicon manufacturing. Other applications could arise which take advantage of the flexible nature of the substrates, such as electronics embedded into clothing, large-area flexible displays, and roll-up portable displays.\n\nA crucial issue for a roll-to-roll thin-film cell production system is the deposition rate of the microcrystalline layer, and this can be tackled using four approaches:\n\n"}
{"id": "13757191", "url": "https://en.wikipedia.org/wiki?curid=13757191", "title": "Sedimentation potential", "text": "Sedimentation potential\n\nSedimentation potential occurs when dispersed particles move under the influence of either gravity or centrifugation in a medium. This motion disrupts the equilibrium symmetry of the particle's double layer. While the particle moves, the ions in the electric double layer lag behind due to the liquid flow. This causes a slight displacement between the surface charge and the electric charge of the diffuse layer. As a result, the moving particle creates a dipole moment. The sum of all of the dipoles generates an electric field which is called \"sedimentation potential\". It can be measured with an open electrical circuit, which is also called sedimentation current.\n\nThere are detailed descriptions of this effect in many books on colloid and interface science.\n\nElectrokinetic phenomena are a family of several different effects that occur in heterogeneous fluids or in porous bodies filled with fluid. The sum of these phenomena deals with the effect on a particle from some outside resulting in a net electrokinetic effect.\n\nThe common source of all these effects stems from the interfacial 'double layer' of charges. Particles influenced by an external force generate tangential motion of a fluid with respect to an adjacent charged surface. This force may consist of electric, pressure gradient, concentration gradient, gravity. In addition, the moving phase might be either the continuous fluid or dispersed phase.\n\nSedimentation potential is the field of electrokinetic phenomena dealing with the generation of an electric field by sedimenting colloid particles.\n\nThis phenomenon was first discovered by Dorn in 1879. He observed that a vertical electric field had developed in a suspension of glass beads in water, as the beads were settling. This was the origin of sedimentation potential, which is often referred to as the Dorn effect.\n\nSmoluchowski built the first models to calculate the potential in the early 1900s. Booth created a general theory on sedimentation potential in 1954 based on Overbeek's 1943 theory on electrophoresis. In 1980, Stigter extended Booth's model to allow for higher surface potentials. Ohshima created a model based on O'Brien and White 's 1978 model used to analyze the sedimentation velocity of a single charged sphere and the sedimentation potential of a dilute suspension.\n\nAs a charged particle moves through a gravitational force or centrifugation, an electric potential is induced. While the particle moves, ions in the electric double layer lag behind creating a net dipole moment behind due to liquid flow. The sum of all dipoles on the particle is what causes sedimentation potential. Sedimentation potential has the opposite effect compared to electrophoresis where an electric field is applied to the system. Ionic conductivity is often referred to when dealing with sedimentation potential.\n\nThe following relation provides a measure of the sedimentation potential due to the settling of charged spheres. First discovered by Smoluchowski in 1903 and 1921. This relationship only holds true for non-overlapping electric double layers and for dilute suspensions. In 1954, Booth proved that this idea held true for Pyrex glass powder settling in a KCl solution. From this relation, the sedimentation potential, E, is independent of the particle radius and that E → 0, Φ → 0 (a single particle).\n\nSmoluchowski's sedimentation potential is defined where ε is the permitivity of free space, D the dimensionless dielectric constant, ξ the zeta potential, g the acceleration due to gravity, Φ the particle volume fraction, ρ the particle density, ρ the medium density, λ the specific volume conductivity, and η the viscosity.\n\nSmoluchowski developed the equation under five assumptions:\n\nWhere \"D\" is the diffusion coefficient of the \"ith\" solute species, and \"n\" is the number concentration of electrolyte solution.\nAn improved design cell was developed to determine sedimentation potential, specific conductivity, volume fraction of the solids as well as pH. Two pairs of electrodes are used in this set up, one to measure potential difference and the other for resistance. A flip switch is utilized to avoid polarization of the resistance electrodes and buildup of charge by alternating the current. The pH of the system could be monitored and the electrolyte was drawn into the tube using a vacuum pump.\n\nOhshima's model was developed in 1984 and was originally used to analyze the sedimentation velocity of a single charged sphere and the sedimentation potential of a dilute suspension. The model provided below holds true for dilute suspensions of low zeta potential, \"i.e. e\"ζ/κT ≤2\n\nSedimentation potential is measured by attaching electrodes to a glass column filled with the dispersion of interest. A voltmeter is attached to measure the potential generated from the suspension. To account for different geometries of the electrode, the column is typically rotated 180 degrees while measuring the potential. This difference in potential through rotation by 180 degrees is twice the sedimentation potential. The zeta potential can be determined through measurement by sedimentation potential, as the concentration, conductivity of the suspension, density of the particle, and potential difference are known. By rotating the column 180 degrees, drift and geometry differences of the column can be ignored.\n\nWhen dealing with the case of concentrated systems, the zeta potential can be determined through measurement of the sedimentation potential formula_5, from the potential difference relative to the distance between the electrodes. The other parameters represent the following: formula_6 the viscosity of the medium; formula_7 the bulk conductivity; formula_8 the relative permittivity of the medium; formula_9 the permittivity of free space; formula_10 the density of the particle; formula_11 the density of the medium; formula_12 is the acceleration due to gravity; and σ is the electrical conductivity of the bulk electrolyte solution.\n\nAn improved design cell was developed to determine sedimentation potential, specific conductivity, volume fraction of the solids as well as pH. Two pairs of electrodes are used in this set up, one to measure potential difference and the other for resistance. A flip switch is utilized to avoid polarization of the resistance electrodes and buildup of charge by alternating the current. The pH of the system could be monitored and the electrolyte was drawn into the tube using a vacuum pump.\n\nSedimentation field flow fractionation (SFFF) is a non-destructive separation technique which can be used for both separation, and collecting fractions. Some applications of SFFF include characterization of particle size of latex materials for adhesives, coatings and paints, colloidal silica for binders, coatings and compounding agents, titanium oxide pigments for paints, paper and textiles, emulsion for soft drinks, and biological materials like viruses and liposomes.\n\nSome main aspects of SFFF include: it provides high-resolution possibilities for size distribution measurements with high precision, the resolution is dependent on experimental conditions, the typical analysis time is 1 to 2 hours, and it is a non-destructive technique which offers the possibility of collecting fraction.\n\nAs sedimentation field flow fractionation (SFFF) is one of field flow fractionation separation techniques, it is appropriate for fractionation and characterization of particulate materials and soluble samples in the colloid size range. Differences in interaction between a centrifugal force field and particles with different masses or sizes lead to the separation. An exponential distribution of particles of a certain size or weight is results due to the Brownian motion. Some of the assumptions to develop the theoretical equations include that there is no interaction between individual particles and equilibrium can occur anywhere in separation channels.\n\nVarious combinations of the driving force and moving phase determine various electrokinetic effects. Following \"Fundamentals of Interface and Colloid Science\" by Lyklema (1995), the complete family of electrokinetic phenomena includes:\n\n"}
{"id": "1159186", "url": "https://en.wikipedia.org/wiki?curid=1159186", "title": "Seed crystal", "text": "Seed crystal\n\nA seed crystal is a small piece of single crystal or polycrystal material from which a large crystal of typically the same material is to be grown in a laboratory. Used to replicate material, the use of seed crystal to promote growth avoids the otherwise slow randomness of natural crystal growth and allows manufacture on a scale suitable for industry. \n\nThe large crystal can be grown by dipping the seed into a supersaturated solution, into molten material that is then cooled, or by growth on the seed face by passing vapor of the material to be grown over it.\n\nThe theory behind this effect is thought to derive from the physical intermolecular interaction that occurs between compounds in a supersaturated solution (or possibly vapor). In solution, liberated (soluble) molecules (solute) are free to move about in random flow. This random flow permits for the possibility of two or more molecular compounds to interact. This interaction can potentiate intermolecular forces between the separate molecules and form a basis for a crystal lattice. The placement of a seed crystal into solution allows the recrystallization process to expedite by eliminating the need for random molecular collision or interaction. By introducing an already pre-formed basis of the target crystal to act upon, the intermolecular interactions are formed much more easily or readily, than relying on random flow. Often, this phase transition from solute in a solution to a crystal lattice will be referred to as nucleation. Seeding is therefore said to decrease the necessary amount of time needed for nucleation to occur in a recrystallization process.\n\nOne example where a seed crystal is used to grow large boules or ingots of a single crystal is the semiconductor industry where methods such as the Czochralski process or Bridgman technique are employed.\n\n"}
{"id": "9670295", "url": "https://en.wikipedia.org/wiki?curid=9670295", "title": "Self-discharge", "text": "Self-discharge\n\nSelf-discharge is a phenomenon in batteries in which internal chemical reactions reduce the stored charge of the battery without any connection between the electrodes. Self-discharge decreases the shelf life of batteries and causes them to initially have less than a full charge when actually put to use.\n\nHow fast self-discharge in a battery occurs is dependent on the type of battery, state of charge, charging current, ambient temperature and other factors. Primary batteries, which aren't designed for recharging between manufacturing and use, use battery chemistry with much lower self-discharge rates than rechargeable batteries, since they must have an economically practical shelf life.\n\nSelf-discharge is a chemical reaction, just as closed-circuit discharge is, and tends to occur more quickly at higher temperatures. Storing batteries at lower temperatures thus reduces the rate of self-discharge and preserves the initial energy stored in the battery. Self-discharge is also thought to be reduced as a passivation layer develops on the electrodes over time.\n\n\n"}
{"id": "56930739", "url": "https://en.wikipedia.org/wiki?curid=56930739", "title": "Solaristor", "text": "Solaristor\n\nA solaristor (from SOLAR cell transISTOR) is a compact two terminal self-powered phototransistor. The two-in-one transistor plus solar cell achieves the high-low current modulation by a memresistive effect in the flow of photogenerated carriers. The term was coined by Dr Amador Perez-Tomas working in collaboration with other ICN2 researchers in 2018 when they demonstrated the concept in a ferroelectric-oxide/organic bulk heterojunction solar cell.\n\nIn a basic Solaristor embodiment, the self-powered transistor effect is achieved by the integration of a light absorber layer (a material that absorbs photon energy) in series with a functional semiconductor transport layer, which internal conductivity or contact resistance can be modified externally. \n\nIn general, the light absorber is a semiconductor p-n junction that:\n\nAdditionally, in thin-film solar cells, buffer electron and hole semiconductor transport layers are introduced at the respective metal electrodes to avoid electron-hole recombination and to remove the metal/absorber Schottky barrier.\n\nA Solaristor effect is achieved by modifying the internal field properties or the overall conductivity of the solar cell. \nFerroelectric Solaristors. One possibility is the use of ferroelectric semiconductors as transport layers. A ferroelectric layer can be seen as a semiconductor with switchable surface charge polarity. Because of this tuneable dipole effect, ferroelectrics bend their electronic band structure and offsets with respect to adjacent metals and/or semiconductors when switching the ferroelectric polarization so that the overall conductivity can be tuned orders of magnitude.\n\nConventional photodiodes or photodetectors do not switch as a phototransistor does when biased through its third terminal (gate). An additional advantage of a Solaristor is, therefore, the potential reduction of the standard phototransistor’s area and interconnection complexity. By using Solaristors, it would be possible in theory to replace the in-plane three-electrode architecture by a vertical, two-electrode photodiode-like architecture in systems like photo-sensors, cameras or displays.\n"}
{"id": "37691100", "url": "https://en.wikipedia.org/wiki?curid=37691100", "title": "Solbus Solcity 12 LNG", "text": "Solbus Solcity 12 LNG\n\nThe Solbus Solcity 12 LNG is a fully low-floor single-decker bus manufactured by Solbus SA in Poland. The bus is the first to be powered by liquid natural gas in Mainland Europe. Fueling the bus takes 3–5 minutes.\n\nThe first LNG Solcity's were produced in 2010; the model was perfected at the end of 2011. In 2012, the bus was exhibited in the Hannower IAA motor show.\n"}
{"id": "1533815", "url": "https://en.wikipedia.org/wiki?curid=1533815", "title": "Ultra-low-sulfur diesel", "text": "Ultra-low-sulfur diesel\n\nUltra-low-sulfur diesel (ULSD) is diesel fuel with substantially lowered sulfur content. Since 2006, almost all of the petroleum-based diesel fuel available in Europe and North America has been of a ULSD type.\n\nThe move to lower sulfur content allows for the application of advanced emissions control technologies that substantially lower the harmful emissions from diesel combustion. Testing by engine manufacturers and regulatory bodies have found the use of emissions control devices in conjunction with ULSD can reduce the exhaust output of ozone precursors and particulate matter to near-zero levels.\n\nIn 1993 the European Union began mandating the reduction of diesel sulfur content and implementing modern ULSD specifications in 1999. The United States started phasing in ULSD requirements for highway vehicles in 2006, with implementation for off-highway applications, such as locomotive and marine fuel, beginning in 2007.\n\nSulfur is not a lubricant in and of itself, but it can combine with the nickel content in many metal alloys to form a low melting point eutectic alloy that can increase lubricity. The process used to reduce the sulfur also reduces the fuel's lubricating properties. Lubricity is a measure of the fuel's ability to lubricate and protect the various parts of the engine's fuel injection system from wear. The processing required to reduce sulfur to 15 ppm also removes naturally occurring lubricity agents in diesel fuel. To manage this change ASTM International (formerly the American Society for Testing and Materials) adopted the lubricity specification defined in ASTM D975 for all diesel fuels and this standard went into effect January 1, 2005. The D975 standard defines two ULSD standards, Grade No. 2-D S15 (regular ULSD) and Grade No. 1-D S15 (a higher volatility fuel with a lower gelling temperature than regular ULSD).\n\nThe refining process that removes the sulfur also reduces the aromatic content and density of the fuel, resulting in a minor decrease in the energy content, by about 1%. This decrease in energy content may result in slightly reduced peak power and fuel economy.\n\nThe transition to ULSD is not without substantial costs. The US government has estimated that pump prices for diesel fuel will increase between $.05 and $.25 per gallon as a result of the transition. And, according to the American Petroleum Institute, the domestic refining industry has invested over $8 billion to comply with the new regulations.\n\nULSD will run in any engine designed for the ASTM D975 diesel fuels.\n\nHowever, it is known to cause some seals to shrink, and may cause fuel pump failures in Volkswagen TDI engines used in 2006 to pre-2009 models. TDI engines from 2009 and on are designed to use ULSD exclusively; biodiesel blends are reported to prevent that failure.\n\nSome filling stations in Kenya started offering 50 ppm diesel as of December 2010. As of 2018, Kenya has not fully implemented emission control systems. It needs to work extra hard to regulate the emission systems on highway diesel engines which a factor to air pollution.\n\nAs of June 2012, 50 ppm diesel is now standard across all filling stations, in a bid to reduce pollution.\n\nMorocco has started to introduce 50 ppm diesel to filling stations as of 2009.\n\nSince 2011, the 10 ppm diesel has been available in some filling stations. \nA generalization to all filling stations with the 10 ppm diesel is available since December 2015.\n\n50 ppm was first legislated by the South African Department of Minerals and Energy in early 2006, and has been widely available since then.\n\nSouth Africa's Clean Fuels 2 standard, expected to begin in 2017, will reduce the allowable sulfur content to 10 ppm. Sasol has already launched 10 ppm diesel at selected filling stations as of 2013.\n\nChina has limited sulfur in diesel fuel to 150 ppm (which is equivalent to the Euro III standard). The limits of 10 ppm (Which is equivalent to the Euro V standard), only applied for certain cities such as Beijing.\n\nFrom 2014 to 2017, China will limit sulfur in diesel fuel to 50ppm. After 2017, the sulfur content in diesel fuel will be limited to 10ppm.\n\nIn July 2000, Hong Kong became the first city in Asia to introduce ULSD, with sulfur content of 50 parts per million (ppm). In addition, new petrol private cars were asked to meet Euro III standards from 2001.\n\nSince the introduction of the law, all fuel station started supplying ULSD since August 2000.\n\nSulfur content of regular diesel fuel was lowered from 500 ppm to 350 ppm on 1 January 2001.\n\nAs part of the ULSD package, Hong Kong government lowered the tax for ULSD from HK$2.89 to $2.00 per litre in June 1998. The temporary concession was extended to 31 March 2000, then to 31 December 2000.\n\nOn 19 June 2000, under \"Report of the Subcommittee on resolution under section 4(2) of the Dutiable Commodities Ordinance (Cap. 109)\", ULSD fuel tax was lowered to HK$1.11 per litre between 7 July 2000 and 31 December 2000, then increased to $2 in 2001, then $2.89 per litre on 1 January 2002. This resolution was passed on 27 June 2000.\n\nUnder \"LC Paper No. LS 37/00-01\", which passed on 20 December 2000, the $1.11 per litre tax rate was extended to 30 June 2001.\n\nUnder \"LC Paper No. LS 115/00-01\", which passed on 20 June 2001, the $1.11 per litre tax rate was extended to 31 March 2002, then the tax would be raised to $2.89 per litre afterwards.\n\nUnder \"LC Paper No. LS 67/01-02\", which passed on 13 March 2002, the $1.11 per litre tax rate was extended to 31 March 2003.\n\nUnder \"LC Paper No. LS 76/02-03\", which passed on 19 March 2003, the $1.11 per litre tax rate was extended to 31 March 2004.\n\nUnder \"LC Paper No. LS 59/03-04\", which passed on 24 March 2004, the $1.11 per litre tax rate was extended to 31 December 2004.\n\nCastle Peak Power Station was designed to burn heavy fuel oil for boiler startup, flame stabilisation and occasionally as a secondary fuel. Since the early 2010s, all boilers were converted to burn ULSD to cut down sulfur dioxide emission. On the other hand, Black Point Power Station and Penny's Bay Power Station were designed to burn ULSD as a secondary and primary fuel respectively. So all power stations under CLP Power burn ULSD instead of higher sulfur alternatives now.\n\nDelhi first introduced 50 ppm sulfur diesel on 1 April 2010 as a step aimed at curbing vehicular pollution in the capital. This was done in 12 other cities at the same time. The sulfur content in the diesel being used was 350 ppm.\n\nThere are two types of diesel available in India from year 2010. Bharat Stage IV (equivalent to Euro IV) specification having Sulfur level below 50 ppm is available all over the country.\n\nThe National Environment Agency (NEA) defines ultra low sulfur diesel (ULSD) as diesel fuel with less than 50ppm, or 0.005 per cent, by July 2017 the limit will be 10 ppm\n\nOn June 16, 2005, NEA announced that the use of ULSD would be mandatory beginning December 1, 2005. The regulation also offered tax incentives for Euro IV diesel taxis, buses and commercial vehicles between June 1, 2004 and September 3, 2006, pending a mandatory conversion to Euro IV-compliant vehicles in 2007.\n\nBeginning on 1 July 2007, Taiwan has limited sulfur in diesel fuel to 10 ppm.\n\nIn the European Union, the “Euro IV” standard has applied since 2005, which specifies a maximum of 50 ppm of sulfur in diesel fuel for most highway vehicles; ultra-low-sulfur diesel with a maximum of 10 ppm of sulfur must “be available” from 2005 and was widely available as of 2008. In 2009, the Euro V fuel standard came into effect which reduced maximum sulfur to 10 ppm. In 2009, diesel fuel for most non-highway applications is also expected to conform to the Euro V standard for fuel. Various exceptions exist for certain uses and applications, most of which are being phased out over a period of several years. In particular, the so-called EU accession countries (primarily in Eastern Europe), have been granted certain temporary exemptions to allow for transition.\n\nCertain EU countries may apply higher standards or require faster transition. For example, Germany implemented a tax incentive of per litre of \"sulfur free\" fuel (both gasoline and diesel) containing less than 10 ppm beginning in January 2003 and average sulfur content was estimated in 2006 to be 3-5 ppm. Similar measures have been enacted in most of the Nordic countries, Benelux, Ireland and the United Kingdom to encourage early adoption of the 50 ppm and 10 ppm fuel standards.\n\nSince 1990, diesel fuel with a sulfur content of 50 ppm (0.005%) has been available on the Swedish market. From the year 1992, production started of a diesel fuel with 2 to 5 ppm of sulfur and a maximum of 5% by volume aromatics. There are certain tax incentives for using this fuel and from about year 2000, this low aromatic, low sulfur fuel has achieved 98-99% penetration of the Swedish diesel fuel market. Now RME (rapeseed methyl ester, also known as FAME (Fatty Acid Methyl Ester)) is a biofuel additive.\n\nSince 2003, a \"zero\" sulfur with very low aromatic content (less than 1% by volume) diesel fuel has been made available on the Swedish market under the name \"EcoPar\". It is used wherever the working environment is highly polluted, an example being where diesel trucks are used in confined spaces such as in harbours, inside storage houses, during construction of road and rail tunnels & in vehicles that are predominantly run in city centres.\n\nAs of 2008, most accession countries are expected to have made the transition to diesel fuel with 10 ppm sulfur or less. Slightly different times for transition have applied to each of the countries, but most have been required to reduce the maximum sulfur content to less than 50 ppm since 2005. Certain exemptions are expected for certain industries and applications, which will also be phased out over time. Compared to other EU countries, ULSD may be less widely available.\n\nIn Serbia, an EU candidate country, all diesel fuel has been of the ultra-low-sulfur (\"evrodizel\") type since August 2013. Before that, there were two types of diesel fuel: \"D2\" with 500 ppm sulfur or more, and low-sulfur \"evrodizel\".\n\nUnder \"Sulphur in Diesel Fuel Regulations\" (SOR/2002-254), the sulfur content of diesel fuel produced or imported was reduced to 15 ppm after 31 May 2006. This was followed by the reduction of sulfur in diesel fuel sold for use in on-road vehicles after 31 August 2006. For the designated Northern Supply Area, the deadline for reducing the sulfur content of diesel fuel for use in on-road vehicles was 31 August 2007.\n\nAn amendment titled \"Regulations Amending the Sulphur in Diesel Fuel Regulations\" (SOR/2005-305) added following deadlines:\n\n\nAn amendment titled \"Regulations Amending the Sulphur in Diesel Fuel Regulations\" (SOR/SOR/2006-163) allowed diesel with sulfur content up to 22 ppm to be sold for onroad vehicles between 1 September 2006 and 15 October 2006, then 15 ppm after that date. This amendment facilitated the introduction of 15 ppm sulfur diesel fuel for on-road use in 2006, by lengthening the period between the dates that the production/import limit and the sales limit come into effect. It provided additional time to fully turn over the higher-sulfur diesel fuel inventory for on-road use in the distribution system. The requirements of the Regulations were aligned, in level and timing, with those of the U.S. EPA.\n\nMexico began introduction of ULSD throughout the country in 2006. \n\nUltra-low-sulfur diesel fuel was proposed by EPA as a new standard for the sulfur content in on-road diesel fuel sold in the United States since October 15, 2006, except for rural Alaska which transferred in 2010. California has required it since September 1, 2006. This new regulation applies to all diesel fuel, diesel fuel additives and distillate fuels blended with diesel for on-road use, such as kerosene, however, it does not yet apply to railroad locomotives, marine, or off-road uses. Since December 1, 2010, all highway diesel fuel have been ULSD. Non-road diesel engine fuel was required to move to 500 ppm sulfur in 2007, and further to ULSD in 2010. Railroad locomotive and marine diesel fuel also moved to 500 ppm sulfur in 2007, and will change to ULSD in 2012. There are exemptions for small refiners of non-road, locomotive and marine diesel fuel that allow for 500 ppm diesel to remain in the system until 2014. After December 1, 2014 all highway, non-road, locomotive and marine diesel fuel produced and imported will be ULSD.\n\nThe EPA mandated the use of ULSD fuel in model year 2007 and newer highway diesel fuel engines equipped with advanced emission control systems that require the new fuel. These advanced emission control technologies will be required for marine diesel engines in 2014 and for locomotives in 2015.\n\nThe allowable sulfur content for ULSD (15 ppm) is much lower than the previous U.S. on-highway standard for low sulfur diesel (LSD, 500 ppm) which allows advanced emission control systems to be fitted that would otherwise be damaged and or rendered ineffective by these compounds. These systems can greatly reduce emissions of oxides of nitrogen and particulate matter.\n\nBecause this grade of fuel is comparable to European grades, European engines will no longer have to be redesigned to cope with higher sulfur content in the U.S. These engines may use advanced emissions control systems which would otherwise be damaged by sulfur. Thus the ULSD standard is increasing the availability of diesel-fueled passenger cars in the U.S. In Europe, diesel-engined automobiles have been much more popular with buyers than has been the case in the U.S.\n\nAdditionally, the EPA is assisting manufacturers with the transition to tougher emissions regulations by loosening them for model year 2007 to 2010 light-duty diesel engines. As a result, Honda, Nissan, Subaru, Toyota, and others are expecting to begin producing diesel vehicles for the U.S. market to join those from Mercedes-Benz, Audi, Volkswagen, and BMW.\n\nAccording to EPA estimates, with the implementation of the new fuel standards for diesel, nitrogen oxide emissions will be reduced by 2.6 million tons each year and soot or particulate matter will be reduced by 110,000 tons a year.\n\nOn June 1, 2006, U.S. refiners were required to produce 80% of their annual output as ULSD (15 ppm), and petroleum marketers and retailers were required to label diesel fuel, diesel fuel additives and kerosone pumps with EPA-authorized language disclosing fuel type and sulfur content. Other requirements effective June 1, 2006, including EPA-authorized language on Product Transfer Documents and sulfur-content testing standards, are designed to prevent misfueling, contamination by higher-sulfur fuels and liability issues. The EPA deadline for industry compliance to a 15 ppm sulfur content was originally set for July 15, 2006 for distribution terminals, and by September 1, 2006 for retail. But on November 8, 2005, the deadline was extended by 1.5 months to September 1, 2006 for terminals and October 15, 2006 for retail. In California, the extension was not granted and followed the original schedule. As of December, 2006, the ULSD standard has been in effect according to the amended schedule, and compliance at retail locations was reported to be in place.\n\nSource:\n\nArgentina has three grades of diesel fuel, as follows:\n\nGrade 1, also known as AGRODIESEL or GASOIL AGRO, is intended mainly for agricultural equipment. Sale of Grade 1 diesel is optional at retail outlets.\nGrade 2, also known as GASOIL COMUN (common diesel fuel), is intended for the bulk of diesel fuelled vehicles. Grade 2 diesel fuel is available with 2 different sulfur levels depending on the population density of the location where it is retailed.\nGrade 3 diesel fuel, also known as GASOIL ULTRA, is the highest quality diesel fuel and is supposed to be available starting February 1, 2006. Sale of Grade 3 diesel at retail outlets is optional until 2008.\nAt the time the regulation was published, the sulfur limits amounted to 3000 ppm for Grade 1, 1500/2500 ppm (depending on the area) for Grade 2, and 500 ppm for Grade 3. Sulfur limit reductions occur in 2008, 2009, 2011, and 2016. After the last reduction, in June 2016, the sulfur limits become 1000 ppm, 30 ppm, and 10 ppm for the three respective grades.\n\nLaw 26.093 requires 5% biodiesel to be blended with diesel fuel starting January 1, 2010.\n\nSince January 2012, Brazilian service stations started offering two types of Diesel, 50 ppm and 500 ppm on most areas and 1800 ppm in remote areas. Since January 2013 The 10 ppm or EURO V Diesel replaced the 50 ppm Diesel, which is now widely used and can be found in the majority of service stations, and the 1800 ppm was discontinued. All vehicles produced or sold in Brazil since January 2012 must be able to use only 50 ppm or lower sulfur Diesel.\nAlso, all Diesel available for purchase in Brazil contains 5% of Biodiesel.\n\nChile requires <15-ppm in Santiago, for diesel since 2011, and the rest of the country requires <50-ppm.\n\nSince January 1, 2013, Colombia's diesel has <50 PPM for public and private transport.\n\nUruguay is expected to impose a 50-ppm ULSD limit by 2009. 70% of the fuel used in Uruguay is diesel.\n\nAustralia has had a limit of 10 ppm since 1 January 2009. The limit had been 50ppm.\n\nNew Zealand has had a limit of 10 ppm since 1 January 2009. Prior to that, the limit was 50 ppm.\n\nAs of 2002, much of the former Soviet Union still applied limits on sulfur in diesel fuel substantially higher than in Western Europe. Maximum levels of 2,000 and 5,000 ppm were applied for different uses. In Russia, lower maximum levels of 350 ppm and 500 ppm sulfur in automotive fuel were enforced in certain areas, particularly in regions. Euro IV and Euro V fuel with a concentration of 50 ppm or less was available at certain fueling stations, at least in part to comply with emissions control equipment on foreign-manufactured cars and trucks, number of which is increased every year, especially in big cities, such as Moscow and Saint Petersburg. According to the technical regulation, selling a fuel with sulfur content over 50 ppm was allowed until 31 December 2011. Euro IV diesel may in particular be available at fueling stations selling to long-distance truck fleets servicing import and export flows between Russia and the EU.\n\n\n"}
