{"id": "15885309", "url": "https://en.wikipedia.org/wiki?curid=15885309", "title": "1871 St. Louis tornado", "text": "1871 St. Louis tornado\n\nThe 1871 St. Louis tornado was an F3 tornado that touched down in St. Louis, Missouri on Wednesday, March 8, 1871, at 3:00pm. It traveled east-northeast at , cutting a swath up to wide and long into East St. Louis, Illinois. The tornado was on the ground for 3 minutes. Thirty homes were destroyed and 30 severely damaged. Six railroad depots were destroyed with eight deaths in them. One death occurred on a bridge. Overall, 9 people were killed, 60 injured, and $1,500,000 damage occurred. It is one of four tornadoes (1896, 1927, 1959) that have ripped through the central business district of St. Louis. \n\n"}
{"id": "26664939", "url": "https://en.wikipedia.org/wiki?curid=26664939", "title": "2010 China drought and dust storms", "text": "2010 China drought and dust storms\n\nThe 2010 China drought and dust storms were a series of severe droughts during the spring of 2010 that affected Yunnan, Guizhou, Guangxi, Sichuan, Shanxi, Henan, Shaanxi, Chongqing, Hebei and Gansu in the People's Republic of China as well as parts of Southeast Asia including Vietnam and Thailand, and dust storms in March and April that affected much of East Asia. The drought has been referred to as the worst in a century in southwestern China.\n\nPrior to the drought in Yunnan and Guizhou, the China Meteorological Administration recorded temperatures averaging 2 °C warmer than normal over six months and half the average precipitation for the past year across the region, both unprecedented since at least the 1950s. The effects of El Niño are believed to be contributing to the drought, which may be exacerbated by global warming, as some areas in Yunnan have recorded record high temperatures during the winter since record-keeping began in 1950. Some areas in the drought-affected regions have seen no rainfall since before October. Spring dust storms are common in China, but have become more severe in recent years due to desertification, deforestation, drought, urban sprawl and overgrazing. Countries downstream from Yunnan are also affected by drought conditions upriver, and some places including much of Vietnam have seen very little precipitation since the previous September.\n\nA severe drought in 2009 also affected much of Northern China and Northeastern China, resulting in agricultural losses of up to 50%.\n\nBy March 22, 2010, about 51 million people faced water shortages in a number of provinces. Commodities including sugar cane, flowers, tea, fruit, potatoes, rapeseed, medicinal ingredients, tobacco, wheat, rubber and coffee have been severely affected with output reduced by as much as 50%. Authorities began to fear unrest due to soaring food prices and sent more than 10,000 armed police to the affected regions to ensure stability and help with water supplies. More than 20 million people are left without adequate drinking water in Yunnan, Guangxi, Guizhou, Sichuan and Chongqing, and many wells in Yunnan have gone dry. The three wells in the village of Xiazha in Guangxi Autonomous Region were reported to have gone completely dry for the first time since 1517, in addition to three reservoirs in the area going dry. Economic damage to agriculture and failed electricity generation from hydroelectric dams from the drought was estimated to be at least 24 billion Chinese yuan ($3.5 billion USD). Around 3,600 rivers and brooks in Guizhou have run dry, while 916,000 ha of crops were affected by drought in the province and one million farmers have left to find work in other provinces. The drought affected over 28 million farmers, and a grain shortage has affected 8 million people. The Chinese government has transferred 1.7 million tonnes of grain to the region to reduce potential inflation. About 4.348 million ha of cropland were affected by the drought in Southwestern China and 942,000 ha would yield no harvest by late March, according to China's State Commission of Disaster Relief. In late March, the government began cloud seeding in Guizhou using silver iodide to produce rain. By April 10, the drought had eased in Chongqing due to heavy rain, but it had affected over 18 million livestock and 8.13 million ha of land. In parts of Yunnan Province inhabited by the Dai people, officials cancelled or shortened the Songkran water dousing festival due to the water shortage, including in Dehong Dai and Jingpo Autonomous Prefecture and Xishuangbanna Dai Autonomous Prefecture. By early June, the drought had affected close to 5 million hectares of land.\n\nThe drought may also affect water levels at the headwaters of the Chang Jiang, Mekong and Salween Rivers. Some experts believe that hydropower production may be contributing to the water shortage from the drought. Countries downstream of the Mekong, including Thailand, suggested that the building of dams on the river such as at Lancang may be worsening the effects of drought on the river's water levels, which were at their lowest in 20 years. Fisheries along the Mekong in Thailand have halted, and 7.9 million people in the country are affected by the drought. 3,674 small dams within the river basin have dried up.\n\nThe drought in Vietnam was described as the country's worst in a century. The Red River near Hanoi was by early March at a level of , the lowest on record, and rice plantations have been severely affected. Timber fires have been sparked in several regions. The Mekong Delta experienced its lowest water levels in nearly 20 years, threatening to produce saltwater intrusion in dry areas. Some parts of Vietnam are forecast to possibly receive no rain until August. A power shortage of up to one billion kilowatt-hours could also hit the country as less water is available for hydroelectricity.\n\nThe El Niño conditions of the winter prior to the drought has raised concerns that the rice crop in Vietnam, Thailand and the Philippines may be significantly reduced by the summer.\n\nThe lack of precipitation caused land subsidence at Kunming Wujiaba International Airport in Yunnan.\n\nAbout 5,000 villagers in Yunnan Province have left their homes from the drought for streams near Himalayan foothills, and many residents in Guangxi who are able to leave have also left. However, officials have denied reports of drought refugees leaving their villages. The source of the Pearl River's headwaters was cut off, and its outflow was severely reduced. Water rationing was put into practice in some rural regions.\n\nShortages of drinking water also affected parts of Inner Mongolia, including a water shortage for over 250,000 residents of Chifeng. Reservoirs in the city held 73.7% less water than they did one year prior and water volume had reduced by 77.4% in major rivers in the area by mid-April.\n\nThe drought has affected non-ferrous metal production in Guangxi, including of electrolytic zinc, with companies in Nandan County cutting production by 30%.\n\nChinese Premier Wen Jiabao visited southwestern China three times during the drought, including a three-day tour in mid-March in Yunnan, including Luliang County, which had seen no rainfall since August, to promote water conservation, and another visit in early April 2010 to several Miao and Buyei Autonomous Prefectures in Guizhou, some of the worst-hit places where farming has been made impossible.\n\nMost provinces in South China affected by the drought were hit by a series of floods beginning in mid-May that ended most of the drought but also destroyed large areas of farmland.\n\nStrong dust storms from the Gobi Desert in Mongolia hit Xinjiang Autonomous Region, Inner Mongolia, Shaanxi, Shanxi, Hebei, Beijing, Hong Kong, Taiwan, South Korea, North Korea and Japan by March 22, before being carried across the Pacific Ocean by the jet stream, with some dust reaching the West Coast of the United States. The dust storm in late March spiralled around a strong low pressure system. Many areas recorded an extremely rare level 5 \"hazardous\" rating for air quality. Many flights in Beijing were also delayed or cancelled. Air pollution readings in Hong Kong reached a record high, reaching at least 15 times the recommended maximum levels by the World Health Organization. Taiwan also reported a new record for worst sandstorm conditions.\n\nA strong sandstorm tore through Turpan in Xinjiang on April 23, sparking fires that killed two people and forcing a shutdown of rail and road traffic for six hours.\n\nOxfam Hong Kong provided water in Yunnan. A major fundraiser was also held that raised 280 million yuan. Many celebrities took part including Wang Feng (汪峰), Elva Hsiao, Andy Lau, He Jie, Jackie Chan, Ye bei (叶蓓), Yan Wei-wen (阎维文), Zhou Xiao-ou (周晓欧), Bibi Zhou, and Yang-zi (杨紫). The Hong Kong government also approved a HK$1.4 million grant.\n\nMany donations of bottled water have also arrived in Guizhou and other parts of southwestern China from around the country.\n\nIn mid-June 2010, a large algal bloom, consisting of \"enteromorpha\" algae, developed off the coast of Shandong, in the Yellow Sea. Causes of the algal outbreak include marine pollution from sewage and agricultural run-off, in addition to run-off from fish farms, worsened by eutrophication following the drought, subsequent flooding and heat wave, as well as high sea surface temperatures in the area. The bloom continues to expand, and preparations have been made for a flotilla of vessels to ward off the bloom, covering an area of , the largest bloom since 2008. The patch of algae since expanded offshore Jiangsu Province, and is pushing toward the city of Qingdao. The Chinese State Oceanic Administration has warned that the algae could threaten marine life and local tourism, and other scientists have stated that the bloom could decompose on beaches and release toxic gases if not cleaned up. Close to 4,000 tonnes a day of algae is being removed from the bloom, to be sent off and used as animal feed or fertilizer. Green and red tides have become more common in China in recent years. The green tides from the current algal blooms can also result in dead zones from localized ocean anoxia. Large blooms of jellyfish, including giant Nomura's jellyfish have also appeared off Shandong and around the coasts of Japan within the past decade, as a result of the same type of pollution in dead zones.\n\n\n"}
{"id": "39481006", "url": "https://en.wikipedia.org/wiki?curid=39481006", "title": "2013 Pakistan gas bus explosion", "text": "2013 Pakistan gas bus explosion\n\n2013 Pakistan gas bus explosion occurred on 25 May 2013 after a gas cylinder exploded in a school minivan heading towards Gujrat in Pakistan. The blast killed at least 17 people, including 16 children and a bus driver and another 7 children were wounded. The children were aged between 6 and 12.\n\nThe fire was reportedly caused by a spark when the driver of the dual-fuel bus switched from gas to petrol. Officer Ijaz Ahmad said a short-circuit next to a leaking petrol tank started the blaze. Police had earlier blamed an exploding natural gas cylinder.\n"}
{"id": "27616733", "url": "https://en.wikipedia.org/wiki?curid=27616733", "title": "Advanced composite materials (engineering)", "text": "Advanced composite materials (engineering)\n\nAdvanced composite materials (ACMs) are also known as advanced polymer matrix composites. These are generally characterized or determined by unusually high strength fibres with unusually high stiffness, or modulus of elasticity characteristics, compared to other materials, while bound together by weaker matrices. These are termed advanced composite materials (ACM) in comparison to the composite materials commonly in use such as reinforced concrete, or even concrete itself. The high strength fibers are also low density while occupying a large fraction of the volume\n\nAdvanced composites exhibit desirable physical and chemical properties that include light weight coupled with high stiffness (elasticity), and strength along the direction of the reinforcing fiber, dimensional stability, temperature and chemical resistance, flex performance, and relatively easy processing. Advanced composites are replacing metal components in many uses, particularly in the aerospace industry.\n\nComposites are classified according to their matrix phase. These classifications are polymer matrix composites (PMCs), ceramic matrix composites (CMCs), and metal matrix composites (MMCs). Also, materials within these categories are often called \"advanced\" if they combine the properties of high (axial, longitudinal) strength values and high (axial, longitudinal) stiffness values, with low weight, corrosion resistance, and in some cases special electrical properties.\n\nAdvanced composite materials have broad, proven applications, in the aircraft, aerospace, and sports equipment sectors. Even more specifically ACMs are very attractive for aircraft and aerospace structural parts. ACMs have been developing for NASA's \"Advanced Space Transportation Program\", armor protection for \"Army aviation\" and the \"Federal Aviation Administration\" of the USA, and high-temperature shafting for the \"Comanche helicopter\". Additionally, ACMs have a decades long history in military and government aerospace industries. However, much of the technology is new and not presented formally in secondary or undergraduate education, and the technology of advanced composites manufacture is continually evolving.\n\nManufacturing ACMs is a multibillion-dollar industry worldwide. Composite products range from skateboards to components of the space shuttle. The industry can be generally divided into two basic segments, industrial composites and advanced composites. Several of the composites manufacturing processes are common to both segments. The two basic segments are described below.\n\nThe industrial composites industry has been in place for over 40 years in the U.S. This large industry utilizes various resin systems including polyester, epoxy, and other specialty resins. These materials, along with a catalyst or curing agent and some type of fiber reinforcement (typically glass fibers) are used in the production of a wide spectrum of industrial components and consumer goods: boats, piping, auto bodies, and a variety of other parts and components.\n\nThe Advanced polymer matrix composites industry, or Advanced composite materials industry, is characterized by the use of expensive, high-performance resin systems and high-strength, high-stiffness fiber reinforcement. The aerospace industry, including military and commercial aircraft of all types, is the major customer for advanced composites. These materials have also been adopted for use by the sporting goods suppliers who sell high-performance equipment to the golf, tennis, fishing, and archery markets; as well as in the swimming pool industry with Composite wall structures.\n\nWhile aerospace is the predominant market for advanced composites today, the industrial and automotive markets will increasingly see the use of advanced composites toward the year 2000(Its now 2017 this is out of date). At present, both manual and automated processes are employed in making advanced-composite parts. As automated processes become more predominant, the costs of advanced composites are expected to decline to the point at which these materials will be used widely in electronic, machinery, and surface transportation equipment.\n\nSuppliers of advanced composite materials tend to be larger companies capable of doing the research and development necessary to provide the high-performance resin systems used in this segment of the industry. End-users also tend to be large, and many are in the aircraft and aerospace businesses.\n\nTo achieve your desired characteristics like good strength, wear resistance, good impact resistance, rigidity, toughness, good weather resistance etc. you may follow these guidelines.\n\n\"Align the fibers with the load's direction.\"\n\n\"Avoid shear loading.\"\n\n\"Combine several components into an integral structure.\"\n\n\"Use light core material covered with strong composite layer.\"\n\n\"Avoid high temperatures.\"\n\n\"Involve manufacturing considerations early in the design.\"\n\nAdvanced composite systems are divided into two basic types based on the chemical characteristics of the matrix, the two most common are thermosets and thermoplastics. Thermosets are by far the predominant type in use today. Thermosets are subdivided into several resin systems including epoxies, phenolics, polyurethanes, and polyimides. Of these, epoxy systems currently dominate the advanced composite industry.\n\nThermoset resins require addition of a curing agent or hardener and impregnation onto a reinforcing material, followed by a curing step to produce a cured or finished part. Once cured, the part cannot be changed or reformed, except for finishing. Some of the more common thermosets include epoxy, polyurethanes, phenolic and amino resins, bismaleimides (BMI, polyimides), polyamides.\n\nOf these, epoxies are the most commonly used in the industry. Epoxy resins have been in use in U.S. industry for over 40 years. Epoxy compounds are also referred to as glycidyl compounds. The epoxy molecule can also be expanded or cross-linked with other molecules to form a wide variety of resin products, each with distinct performance characteristics. These resins range from low-viscosity liquids to high-molecular weight solids. Typically they are high-viscosity liquids.\n\nThe second of the essential ingredients of an advanced composite system is the curing agent or hardener. These compounds are very important because they control the reaction rate and determine the performance characteristics of the finished part. Since these compounds act as catalysts for the reaction, they must contain active sites on their molecules. Some of the most commonly used curing agents in the advanced composite industry are the aromatic amines. Two of the most common are methylene-dianiline (MDA) and sulfonyldianiline (DDS).\n\nSeveral other types of curing agents are also used in the advanced composite industry. These include aliphatic and cycloaliphatic amines, polyaminoamides, amides, and anhydrides. Again, the choice of curing agent depends on the cure and performance characteristics desired for the finished part. Polyurethanes are another group of resins used in advanced composite processes. These compounds are formed by reacting the polyol component with an isocyanate compound, typically toluene diisocyanate (TDI); methylene diisocyanate (MDI) and hexamethylene diisocyanate (HDI) are also widely used. Phenolic and amino resins are another group of PMC resins. The bismaleimides and polyamides are relative newcomers to the advanced composite industry and have not been studied to the extent of the other resins.\n\nThermoplastics currently represent a relatively small part of the ACM industry. They are typically supplied as nonreactive solids (no chemical reaction occurs during processing) and require only heat and pressure to form the finished part. Unlike the thermosets, the thermoplastics can usually be reheated and reformed into another shape, if desired.\n\nFiber reinforcement materials are added to the resin system increase the tensile strength and stiffness of the finished part. The selection of reinforcement material is based on the properties desired in the finished product. These materials do not react with the resin but are a distinct and integral part of the advanced composite system.\n\nThe three basic types of fiber reinforcement materials in use in the advanced composite industry are\n\n\nFibers used in advanced composite manufacture come in various forms, including tows, yarns, rovings, chopped strands, and woven fabric \nmats. Each of these has its own special application. When prepreg materials are used in parts manufacture, woven fabric or mats are required. In processes such as filament wet winding or pultrusion, yarns and rovings are used.\n\nPrepregs are resin-impregnated cloth, mat, or filaments in flat form that can be stored for later use. The resin is often partially cured to a tack-free state called \"B-staging.\" Catalysts, inhibitors, flame retardants, and other additives may be included to obtain specific end-use properties and improve processing, storage, and handling characteristics.\n\nDespite their strength and low weight, composites have not been a miracle solution for aircraft structures. Composites are typically difficult to inspect for flaws. Some of them absorb moisture. Most importantly, they can be prohibitively expensive, primarily because they are labor-intensive and often require complex and expensive fabrication machines. Aluminium, by contrast, is easy and inexpensive to manufacture and repair, for example in a minor collision an aluminium component can often be hammered back into its original shape, whereas a crunched fiberglass component will likely have to be completely replaced.\n\nAluminium has a relatively high fracture toughness, allowing it to undergo large amounts of plastic deformation before failure. Composites, on the other hand, are less damage tolerant and undergo much less plastic deformation before failure. An airplane made entirely from aluminium can be repaired almost anywhere. This is not the case for composite materials, particularly as they use different and more exotic materials. Because of this, composites will probably always be used more in military aircraft, which are constantly being maintained, than in commercial aircraft, which have to require less maintenance. Aluminium still remains a remarkably useful material for aircraft structures and metallurgists have worked hard to develop better aluminium alloys, for example aluminium-lithium alloys.\n\n\n"}
{"id": "15250506", "url": "https://en.wikipedia.org/wiki?curid=15250506", "title": "Allotropes of plutonium", "text": "Allotropes of plutonium\n\nPlutonium occurs in a variety of allotropes, even at ambient pressure. These allotropes differ widely in crystal structure and density; the α and δ allotropes differ in density by more than 25% at constant pressure.\n\nPlutonium normally has six allotropes and forms a seventh (zeta, ζ) under high temperature and a limited pressure range. These allotropes have very similar energy levels but significantly varying densities and crystal structures. This makes plutonium very sensitive to changes in temperature, pressure, or chemistry, and allows for dramatic volume changes following phase transitions. Unlike most materials, plutonium \"increases\" in density when it melts, by 2.5%, but the liquid metal exhibits a linear decrease in density with temperature. Densities of the different allotropes vary from 16.00 g/cm to 19.86 g/cm.\n\nThe presence of these many allotropes makes machining plutonium very difficult, as it changes state very readily. For example, the α phase exists at room temperature in unalloyed plutonium. It has machining characteristics similar to cast iron but changes to the β phase (\"beta phase\") at slightly higher temperatures. The reasons for the complicated phase diagram are not entirely understood; recent research has focused on constructing accurate computer models of the phase transitions. The α phase has a low-symmetry monoclinic structure, hence its poor conductivity, brittleness, strength and compressibility.\n\nPlutonium in the δ phase (\"delta phase\") normally exists in the 310 °C to 452 °C range but is stable at room temperature when alloyed with a small percentage of gallium, aluminium, or cerium, enhancing workability and allowing it to be welded in weapons applications. The delta phase has more typical metallic character, and is roughly as strong and malleable as aluminium. In fission weapons, the explosive shock waves used to compress a plutonium core will also cause a transition from the usual delta phase plutonium to the denser alpha phase, significantly helping to achieve supercriticality. The plutonium-gallium alloy is the most common δ-stabilized alloy.\n\nGallium, aluminium, americium, scandium and cerium can stabilize the δ phase of plutonium for room temperature. Silicon, indium, zinc and zirconium allow formation of metastable δ state when rapidly cooled. High amount of hafnium, holmium and thallium also allows retaining some of the δ phase at room temperature. Neptunium is the only element that can stabilize the α phase at higher temperatures. Titanium, hafnium and zirconium stabilize the β phase at room temperature when rapidly cooled.\n"}
{"id": "17232430", "url": "https://en.wikipedia.org/wiki?curid=17232430", "title": "Aluminized cloth", "text": "Aluminized cloth\n\nAluminized cloth is a material designed to reflect thermal radiation. Applications include fire proximity suits, emergency space blankets, protection in molten metal handling, and insulation for building and containers.\n\nAluminium powder was added to aircraft dope which was then used to give a shiny finish to fabric-covered aircraft, so protecting them from sunlight. The Hindenburg airship was treated in this way and it has been suggested that the aluminium powder made the skin more combustible and so caused or contributed to the Hindenburg disaster. This theory is controversial and experiments have been conducted to test the hypothesis.\n\n"}
{"id": "50037064", "url": "https://en.wikipedia.org/wiki?curid=50037064", "title": "Amorphous silicon", "text": "Amorphous silicon\n\nAmorphous silicon (a-Si) is the non-crystalline form of silicon used for solar cells and thin-film transistors in LCDs.\n\nUsed as semiconductor material for a-Si solar cells, or thin-film silicon solar cells, it is deposited in thin films onto a variety of flexible substrates, such as glass, metal and plastic. Amorphous silicon cells generally feature low efficiency, but are one of the most environmentally friendly photovoltaic technologies, since they do not use any toxic heavy metals such as cadmium or lead.\n\nAs a second-generation thin-film solar cell technology, amorphous silicon was once expected to become a major contributor in the fast-growing worldwide photovoltaic market, but has since lost its significance due to strong competition from conventional crystalline silicon cells and other thin-film technologies such as CdTe and CIGS.\n\nAmorphous silicon differs from other allotropic variations, such as monocrystalline silicon—a single crystal, and polycrystalline silicon, that consists of small grains, also known as crystallites.\nSilicon is a fourfold coordinated atom that is normally tetrahedrally bonded to four neighboring silicon atoms. In crystalline silicon (c-Si) this tetrahedral structure continues over a large range, thus forming a well-ordered crystal lattice.\n\nIn amorphous silicon this long range order is not present. Rather, the atoms form a continuous random network. Moreover, not all the atoms within amorphous silicon are fourfold coordinated. Due to the disordered nature of the material some atoms have a dangling bond. Physically, these dangling bonds represent defects in the continuous random network and may cause anomalous electrical behavior.\n\nThe material can be passivated by hydrogen, which bonds to the dangling bonds and can reduce the dangling bond density by several orders of magnitude. Hydrogenated amorphous silicon (a-Si:H) has a sufficiently low amount of defects to be used within devices such as solar photovoltaic cells, particularly in the protocrystalline growth regime. However, hydrogenation is associated with light-induced degradation of the material, termed the Staebler–Wronski effect.\n\nAmorphous alloys of silicon and carbon (amorphous silicon carbide, also hydrogenated, a-SiC:H) are an interesting variant. Introduction of carbon atoms adds extra degrees of freedom for control of the properties of the material. The film could also be made transparent to visible light.\n\nIncreasing the concentration of carbon in the alloy widens the electronic gap between conduction and valence bands (also called \"optical gap\" and bandgap). This can potentially increase the light efficiency of solar cells made with amorphous silicon carbide layers. On the other hand, the electronic properties as a semiconductor (mainly electron mobility), are adversely affected by the increasing content of carbon in the alloy, due to the increased disorder in the atomic network.\n\nSeveral studies are found in the scientific literature, mainly investigating the effects of deposition parameters on electronic quality, but practical applications of amorphous silicon carbide in commercial devices are still lacking.\n\nThe density of amorphous Si has been calculated as 4.90×10 atom/cm (2.285 g/cm) at 300 K. This was done using thin (5 micron) strips of amorphous silicon. This density is 1.8±0.1% less dense than crystalline Si at 300 K. Silicon is one of the few elements that expands upon cooling and has a lower density as a solid than as a liquid.\n\nUnhydrogenated a-Si has a very high defect density which leads to undesirable semiconductor properties such as poor photoconductivity and prevents doping which is critical to engineering semiconductor properties. By introducing hydrogen during the fabrication of amorphous silicon, photoconductivity is significantly improved and doping is made possible. Hydrogenated amorphous silicon, a-Si:H, was first fabricated in 1969 by Chittick, Alexander and Sterling by deposition using a silane gas (SiH4) precursor. The resulting material showed a lower defect density and increased conductivity due to impurities. Interest in a-Si:H came when (in 1975), LeComber and Spear discovered the ability for substitutional doping of a-Si:H using phosphine (n-type) or diborane (p-type). The role of hydrogen in reducing defects was verified by Paul's group at Harvard who found a hydrogen concentration of about 10 atomic % through IR vibration, which for Si-H bonds has a frequency of about 2000 cm. Starting in the 1970s, a-Si:H was developed in solar cells by RCA by which steadily climbed in efficiency to about 13.6% in 2015.\n\nWhile a-Si suffers from lower electronic performance compared to c-Si, it is much more flexible in its applications. For example, a-Si layers can be made thinner than c-Si, which may produce savings on silicon material cost.\n\nOne further advantage is that a-Si can be deposited at very low temperatures, e.g., as low as 75 degrees Celsius. This allows deposition on not only glass, but plastic as well, making it a candidate for a roll-to-roll processing technique. Once deposited, a-Si can be doped in a fashion similar to c-Si, to form p-type or n-type layers and ultimately to form electronic devices.\n\nAnother advantage is that a-Si can be deposited over large areas by PECVD. The design of the PECVD system has great impact on the production cost of such panel, therefore most equipment suppliers put their focus on the design of PECVD for higher throughput, that leads to lower manufacturing cost particularly when the silane is recycled.\n\nArrays of small (under 1 mm by 1 mm) a-Si photodiodes on glass are used as visible-light image sensors in some flat panel detectors for fluoroscopy and radiography.\n\nAmorphous silicon (a-Si) has been used as a photovoltaic solar cell material for devices which require very little power, such as pocket calculators, because their lower performance compared to conventional crystalline silicon (c-Si) solar cells is more than offset by their simplified and lower cost of deposition onto a substrate. The first solar-powered calculators were already available in the late 1970s, such as the Royal \"Solar 1\", Sharp \"EL-8026\", and Teal \"Photon\".\n\nMore recently, improvements in a-Si construction techniques have made them more attractive for large-area solar cell use as well. Here their lower inherent efficiency is made up, at least partially, by their thinness – higher efficiencies can be reached by stacking several thin-film cells on top of each other, each one tuned to work well at a specific frequency of light. This approach is not applicable to c-Si cells, which are thick as a result of its indirect band-gap and are therefore largely opaque, blocking light from reaching other layers in a stack.\n\nThe source of the low efficiency of amorphous silicon photovoltaics is due largely to the low hole mobility of the material. This low hole mobility has been attributed to many physical aspects of the material, including the presence of dangling bonds (silicon with 3 bonds), floating bonds (silicon with 5 bonds), as well as bond reconfigurations. While much work has been done to control these sources of low mobility, evidence suggests that the multitude of interacting defects may lead to the mobility being inherently limited, as reducing one type of defect leads to formation others.\n\nThe main advantage of a-Si in large scale production is not efficiency, but cost. a-Si cells use only a fraction of the silicon needed for typical c-Si cells, and the cost of the silicon has historically been a significant contributor to cell cost. However, the higher costs of manufacture due to the multi-layer construction have, to date, made a-Si unattractive except in roles where their thinness or flexibility are an advantage.\n\nTypically, amorphous silicon thin-film cells use a p-i-n structure. The placement of the p-type layer on top is also due to the lower hole mobility, allowing the holes to traverse a shorter average distance for collection to the top contact. Typical panel structure includes front side glass, TCO, thin-film silicon, back contact, polyvinyl butyral (PVB) and back side glass. Uni-Solar, a division of Energy Conversion Devices produced a version of flexible backings, used in roll-on roofing products. However, the world's largest manufacturer of amorphous silicon photovoltaics had to file for bankruptcy in 2012, as it could not compete with the rapidly declining prices of conventional solar panels.\n\nMicrocrystalline silicon (also called nanocrystalline silicon) is amorphous silicon, but also contains small crystals. It absorbs a broader spectrum of light and is flexible. Micromorphous silicon module technology combines two different types of silicon, amorphous and microcrystalline silicon, in a top and a bottom photovoltaic cell. Sharp produces cells using this system in order to more efficiently capture blue light, increasing the efficiency of the cells during the time where there is no direct sunlight falling on them. Protocrystalline silicon is often used to optimize the open circuit voltage of a-Si photovoltaics.\n\nXunlight Corporation, which has received over $40 million of institutional investments, has completed the installation of its first 25 MW wide-web, roll-to-roll photovoltaic manufacturing equipment for the production of thin-film silicon PV modules. Anwell Technologies has also completed the installation of its first 40 MW a-Si thin film solar panel manufacturing facility in Henan with its in-house designed multi-substrate-multi-chamber PECVD equipment.\n\nPhotovoltaic thermal hybrid solar collectors (PVT), are systems that convert solar radiation into electrical energy and thermal energy. These systems combine a solar cell, which converts electromagnetic radiation (photons) into electricity, with a solar thermal collector, which captures the remaining energy and removes waste heat from the solar PV module. Solar cells suffer from a drop in efficiency with the rise in temperature due to increased resistance. Most such systems can be engineered to carry heat away from the solar cells thereby cooling the cells and thus improving their efficiency by lowering resistance. Although this is an effective method, it causes the thermal component to under-perform compared to a solar thermal collector. Recent research showed that a-Si:H PV with low temperature coefficients allow the PVT to be operated at high temperatures, creating a more symbiotic PVT system and improving performance of the a-Si:H PV by about 10%.\n\nAmorphous silicon has become the material of choice for the active layer in thin-film transistors (TFTs), which are most widely used in large-area electronics applications, mainly for liquid-crystal displays (LCDs).\n\nThin-film-transistor liquid-crystal display (TFT-LCD) show a similar circuit layout process to that of semiconductor products. However, rather than fabricating the transistors from silicon, that is formed into a crystalline silicon wafer, they are made from a thin film of amorphous silicon that is deposited on a glass panel. The silicon layer for TFT-LCDs is typically deposited using the PECVD process. Transistors take up only a small fraction of the area of each pixel and the rest of the silicon film is etched away to allow light to easily pass through it.\n\nPolycrystalline silicon is sometimes used in displays requiring higher TFT performance. Examples include small high-resolution displays such as those found in projectors or viewfinders. Amorphous silicon-based TFTs are by far the most common, due to their lower production cost, whereas polycrystalline silicon TFTs are more costly and much more difficult to produce.\n\n"}
{"id": "6589624", "url": "https://en.wikipedia.org/wiki?curid=6589624", "title": "Anaerobic clarigester", "text": "Anaerobic clarigester\n\nThe anaerobic clarigester is a form of anaerobic digester. It is regarded as being the ancestor of the upflow anaerobic sludge blanket digestion (UASB) anaerobic digester. A clarigester treats dilute biodegradable feedstocks and separates out solid and hydraulic (liquid) retention times. A diagram comparing the UASB, anaerobic clarigester and anaerobic contact processes can be found here.\n\n"}
{"id": "37591807", "url": "https://en.wikipedia.org/wiki?curid=37591807", "title": "Borealis (film)", "text": "Borealis (film)\n\nBorealis is a 2008 documentary film by Frank Wolf that follows two friends on a 3,100 km canoe adventure through the northern Boreal forest of Manitoba and Ontario. The film looks at the industrial threats to the pristine, vast wilderness north of the 51st parallel from the perspective of those who live in the region. The film is notable for its quirky and humorous tone in spite of the subject matter. It won the Grand Prize as well as Prize for Best Canadian Film at the 2009 Vancouver International Mountain Film Festival and was one of the Top Ten Most Popular Canadian Films at the 2008 Vancouver International Film Festival. It aired multiple times on CBC's documentary in Canada in 2009-10.\n\nFrank Wolf (born in 1970) is an award-winning, Canadian filmmaker, adventurer, writer and environmentalist. Wolf's creative works specialize in adventure and environmental documentary film. His handful of films include Wild Ones, The Hand of Franklin, Kitturiaq, On the Line, Mammalian, and Borealis, all of which broadcast on CBC's documentary channel in Canada. Wolf, acts as starring role and director in his films, using a humorous approach in order to make the environmentalist and adventurer documentaries appealing to a broader audience.\n\n•2008 Vancouver International Film Festival Official Selection: runner-up for NFB audience award, best documentary\n\n•2009 Vancouver International Mountain Film Festival Official Selection: winner of Grand Prize for best overall film, winner of prize for best Canadian film\n\n•2009 Beloit International Film Festival Official Selection\n\n•2009 Powell River Film Festival Official Selection\n\n•2009 Reel Paddling Film Festival Official Selection\n\n•2009 New Zealand Mountain Film Festival Official Selection\n\n\"The challenge of making this film was almost as severe as the challenge of the journey it depicts. The makers showed great imagination to get around the limitations of a zero budget, livening up the narrative with interviews, jokes, sight gags, even dance! It gently raised important issues along the way, allowing these issues to arise quite naturally out of the journey itself.\" -VIMFF Jury Statement for Grand Prize winner 'Borealis'\n\n\"An appealing ground-level spin on environmental issues\" - The Vancouver Province\n\n"}
{"id": "5651008", "url": "https://en.wikipedia.org/wiki?curid=5651008", "title": "Bristow Helicopters Flight 56C", "text": "Bristow Helicopters Flight 56C\n\nBristow Helicopters Flight 56C was a helicopter flight that flew between Aberdeen and the Brae Alpha oil rig in the North Sea. On 19 January 1995 the AS 332L Super Puma helicopter operating the route, registered G-TIGK and named \"Cullen\", was struck by lightning. The flight was carrying 16 oil workers from Aberdeen to an oil platform at the Brae oilfield. All people on board survived.\n\nThe commander of the flight was Cedric Roberts (44). He had been with Bristow Helicopters Ltd since 1974. He was a very experienced pilot with more than 9,600 hours of flying time under his belt. The first officer was Lionel Sole (39). Sole had been with Bristow Helicopters Ltd since 1990. He had more than 3,100 hours of flying time to his credit.\n\nEn route, the helicopter ran into poor weather and was then struck by lightning. This caused severe damage to the tail rotor. Though the helicopter managed to limp for a few more minutes, the tail rotor eventually failed completely and the pilot was forced to perform an emergency autorotation onto the rough seas. Emergency floaters on the helicopter allowed the passengers and crew to be evacuated onto a life raft. Despite the high waves and bad weather, all the people on board the flight were rescued by the ship \"Grampian Freedom\".\n\nThe lightning strike was an isolated one in the storm, and may have been induced by the helicopter flying through the cloud. The accident investigation also revealed potential troubles with the composite material with brass strip design of the rotors which made the rotorblades prone to explosion and damage from lightning strikes.\n\nThe events of Flight 56C were featured in \"Helicopter Down\", a Season 3 (2005) episode of the Canadian TV series \"Mayday\" (called \"Air Emergency\" and \"Air Disasters\" in the U.S. and \"Air Crash Investigation\" in the UK and elsewhere around the world).\n\n\n"}
{"id": "11276977", "url": "https://en.wikipedia.org/wiki?curid=11276977", "title": "Caorso Nuclear Power Plant", "text": "Caorso Nuclear Power Plant\n\nCaorso Nuclear Power Plant was a nuclear power plant at Caorso in Italy. It featured a single Boiling Water Reactor, a BWR 4 with a Mark II-Containment from General Electric, with an electrical net output of 860 MW, used low-enriched uranium as fuel, was moderated and cooled by normal light water.\n\nIt operated from 1981 until 1990, when it was closed following the referendum of November 1987. It was by far the most modern and in terms of capacity biggest nuclear power plant to go online in Italy.\n\n"}
{"id": "1777481", "url": "https://en.wikipedia.org/wiki?curid=1777481", "title": "Clapboard (architecture)", "text": "Clapboard (architecture)\n\nClapboard or clabbard, also called bevel siding, lap siding, and weatherboard, with regional variation in the definition of these terms, is wooden siding of a building in the form of horizontal boards, often overlapping.\n\n\"Clapboard\" in modern (American English) usage is a word for long, thin boards used to cover walls and (formerly) roofs of buildings. Also historically called \"clawboards\" and \"cloboards\".\n\nAn older meaning of clapboard is small, split pieces of oak imported from Germany for use as barrel staves, and the name is a partial translation of Middle Dutch \"klapholt\" and related to German \"Klappholz\".\n\nClapboards were originally riven radially producing triangular or \"feather-edged\" sections, attached thin side up and overlapped thick over thin to shed water.\n\nLater, the boards were radially sawn in a type of sawmill called a \"clapboard mill\", producing \"vertical-grain\" clapboards. The more commonly used boards in New England are vertical-grain boards. Depending on the diameter of the log, cuts are made from 4½\" to 6½\" deep along the full length of the log. Each time the log turns for the next cut, it is rotated ⅝\" until it has turned 360°. This gives the radially sawn clapboard its taper and true vertical grain.\n\n\"Flat-grain\" clapboards are cut tangent to the annual growth rings of the tree. As this technique was common in most parts of the British Isles, it was carried by immigrants to their colonies in the Americas and in Australia and New Zealand. Flat-sawn wood cups more and does not hold paint as well as radially sawn wood.\n\n\"Chamferboards\" are an Australian form of weatherboarding using tongue-and-groove joints to link the boards together to give a flatter external appearance than regular angled weatherboards.\n\nSome modern clapboards are made up of shorter pieces of wood \"finger jointed\" together with an adhesive.\n\nIn North America clapboards were historically made of split oak, pine and spruce. Modern clapboards are available in red cedar and pine.\n\nIn some areas, clapboards were traditionally left as raw wood, relying upon good air circulation and the use of 'semi-hardwoods' to keep the boards from rotting. These boards eventually go grey as the tannins are washed out from the wood. More recently clapboard has been tarred or painted—traditionally black or white due to locally occurring minerals or pigments. In modern clapboard these colors remain popular, but with a hugely wider variety due to chemical pigments and stains.\n\nClapboard houses may be found in most parts of the British Isles, and the style may be part of all types of traditional building, from cottages to windmills, shops to workshops, as well as many others.\n\nIn New Zealand, clapboard housing dominates buildings before 1960. Clapboard, with a corrugated iron roof, was found to be a cost-effective building style. After the big earthquakes of 1855 and 1931, wooden buildings were perceived as being less vulnerable to damage. Clapboard is always referred to as 'weatherboard' in New Zealand.\n\nNewer, cheaper designs often imitate the form of clapboard construction as \"siding\" made of vinyl (uPVC), aluminum, fiber cement, or other man-made materials.\n\n\n"}
{"id": "452955", "url": "https://en.wikipedia.org/wiki?curid=452955", "title": "Cornerstone", "text": "Cornerstone\n\nThe cornerstone (or foundation stone or setting stone) is the first stone set in the construction of a masonry foundation, important since all other stones will be set in reference to this stone, thus determining the position of the entire structure.\n\nOver time a cornerstone became a ceremonial masonry stone, or replica, set in a prominent location on the outside of a building, with an inscription on the stone indicating the construction dates of the building and the names of architect, builder, and other significant individuals. The rite of laying a cornerstone is an important cultural component of eastern architecture and metaphorically in sacred architecture generally.\n\nSome cornerstones include time capsules from, or engravings commemorating, the time a particular building was built.\n\nOften, the ceremony involved the placing of offerings of grain, wine and oil on or under the stone. These were symbolic of the produce and the people of the land and the means of their subsistence. This in turn derived from the practice in still more ancient times of making an animal or human sacrifice that was laid in the foundations.\n\nFrazer (2006: p. 106-107) in \"The Golden Bough\" charts the various propitiary sacrifices and effigy substitution such as the shadow, states that:\n\nNowhere, perhaps, does the equivalence of the shadow to the life or soul come out more clearly than in some customs practised to this day in South-eastern Europe. In modern Greece, when the foundation of a new building is being laid, it is the custom to kill a cock, a ram, or a lamb, and to let its blood flow on the foundation-stone, under which the animal is afterwards buried. The object of the sacrifice is to give strength and stability to the building. But sometimes, instead of killing an animal, the builder entices a man to the foundation-stone, secretly measures his body, or a part of it, or his shadow, and buries the measure under the foundation-stone; or he lays the foundation-stone upon the man's shadow. It is believed that the man will die within the year. The Roumanians of Transylvania think that he whose shadow is thus immured will die within forty days; so persons passing by a building which is in course of erection may hear a warning cry, Beware lest they take thy shadow! Not long ago there were still shadow-traders whose business it was to provide architects with the shadows necessary for securing their walls. In these cases the measure of the shadow is looked on as equivalent to the shadow itself, and to bury it is to bury the life or soul of the man, who, deprived of it, must die. Thus the custom is a substitute for the old practice of immuring a living person in the walls, or crushing him under the foundation-stone of a new building, in order to give strength and durability to the structure, or more definitely in order that the angry ghost may haunt the place and guard it against the intrusion of enemies.\nAncient Japan legends talk about Hitobashira (人柱, \"human pillar\"), in which maidens were buried alive at the base or near some constructions as a prayer to ensure the buildings against disasters or enemy attacks.\n\nNormally, a VIP of the organization, or a local celebrity or community leader, will be invited to conduct the ceremony of figuratively beginning the foundations of the building, with the person's name and official position and the date usually being recorded on the stone. This person is usually asked to place their hand on the stone or otherwise signify its laying.\n\nOften still, and certainly until the 1970s, most ceremonies involved the use of a specially manufactured and engraved trowel that had a formal use in laying mortar under the stone. Similarly, a special hammer was often used to ceremonially tap the stone into place.\n\nThe foundation stone often has a cavity into which is placed a time capsule containing newspapers of the day or week of the ceremony plus other artifacts that are typical of the period of the construction: coins of the year may also be immured in the cavity or time capsule.\n\nFreemasons sometimes perform the public cornerstone laying ceremony for notable buildings. This ceremony was described by The Cork Examiner of 13 January 1865 as follows: \n...The Deputy Provincial Grand Master of Munster, applying the golden square and level to the stone said ; \" My Lord Bishop, the stone has been proved and found to be 'fair work and square work' and fit to be laid as the foundation stone of this Holy Temple\".' After this, Bishop Gregg spread cement over the stone with a trowel specially made for the occasion by John Hawkesworth, a silversmith and a jeweller. He then gave the stone three knocks with a mallet and declared the stone to be 'duly and truly laid'. The Deputy Provincial Grand Master of Munster poured offerings of corn, oil and wine over the stone after Bishop Gregg had declared it to be 'duly and truly laid'. The Provincial Grand Chaplain of the Masonic Order in Munster then read out the following prayer: 'May the Great Architect of the universe enable us as successfully to carry out and finish this work. May He protect the workmen from danger and accident, and long preserve the structure from decay; and may He grant us all our needed supply, the corn of nourishment, the wine of refreshment, and the oil of joy, Amen. So mote it be.' The choir and congregation then sang the Hundredth Psalm. \n\nIn Freemasonry, which grew from the practice of stonemasons, the initiate (Entered Apprentice) is placed in the north-east corner of the Lodge as a figurative foundation stone. This is intended to signify the unity of the North associated with darkness and the East associated with light.\n\nA cornerstone (Greek: Άκρογωνιεîς, Latin: Primarii Lapidis) will sometimes be referred to as a \"foundation-stone\", and is symbolic of Christ, whom the Apostle Paul referred to as the \"head of the corner\" and is the \"Chief Cornerstone of the Church\" (). A chief or head cornerstone is placed above two walls to maintain them together and avoid the building to fall apart. Many of the more ancient churches will place relics of the saints, especially martyrs, in the foundation stone.\n\nAccording to the pre-Vatican II rite of the Roman Catholic Church: Before the construction of a new church begins, the foundations of the building are clearly marked out and a wooden cross is set up to indicate where the altar will stand. Once preparations have been made, the bishop—or a priest delegated by him for that purpose—will bless holy water and with it sprinkle first the cross that was erected and then the foundation stone itself. Upon the stone he is directed to engrave crosses on each side with a knife, and then pronounce the following prayer: \"Bless, O Lord, this creature of stone (\"creaturam istam lapidis\") and grant by the invocation of Thy holy name that all who with a pure mind shall lend aid to the building of this church may obtain soundness of body and the healing of their souls. Through Christ Our Lord, Amen.\"\n\nAfter this, the Litany of the Saints is said, followed by an antiphon and Psalm 126 ( in the Hebrew numbering), which appropriately begins with the verse, \"Unless the Lord build the house, they labour in vain that build it\". Then the stone is lowered into its place with another prayer and again sprinkled with holy water. More antiphons and psalms follow, while the bishop sprinkles the foundations, dividing them into three sections and ending each with a special prayer. Finally, \"Veni Creator Spiritus\" is sung, and two short prayers. Then the bishop, if he deems it opportune, sits down and exhorts the people to contribute to the construction, appointments and maintenance of the new church, after which he dismisses them with his blessing and the proclamation of an indulgence.\n\nIn the Eastern Orthodox Church the blessing of the bishop must be obtained before construction on a new church may commence, and any clergyman who ventures to do so without a blessing can be deposed. The \"Rite of the Foundation of a Church\" (i.e., the laying of the cornerstone) will differ slightly depending on whether the church is to be constructed of wood or of stone. Even when a church is built of wood, the cornerstone must in fact be made of stone.\n\nThe cornerstone is a solid stone cube upon which a cross has been carved. Below the cross, the following words are inscribed:\n\nIn the Name of the Father, and of the Son, and of the Holy Spirit, this church is founded, in honour and memory of (\"here the name of the patron saint of the new church is inserted\"); in the rule of (\"here the name of the ruler is inserted\"); in the episcopacy of (\"here the name of the bishop is inserted\"); in the Year of the World _____ (Anno Mundi), and from the Birth in the flesh of God the Word _____ (Anno Domini).\n\nIn the top of the stone a cross-shaped space is hollowed out into which relics may be placed. Relics are not required, but they are normally placed in the cornerstone. If no relics are inserted in the stone, the inscription may be omitted, but not the cross.\n\nAfter the foundations for the new church have been dug and all preparations finished, the bishop (or his deputy) with the other clergy vest and form a crucession to the building site. The service begins with a moleben and the blessing of holy water. Then a cross is erected in the place where the Holy Table (altar) will stand, and the cornerstone is consecrated and set in place.\n\n"}
{"id": "4055229", "url": "https://en.wikipedia.org/wiki?curid=4055229", "title": "Dhruva reactor", "text": "Dhruva reactor\n\nThe Dhruva reactor is India's largest nuclear research reactor. Located in the Mumbai (Bombay) suburb of Trombay at the Bhabha Atomic Research Centre (BARC), it is India's primary generator of weapons-grade plutonium-bearing spent fuel for its nuclear weapons program. Originally named the R-5, this pool-type reactor first went critical on 8 August 1985 after 10 years of construction. However, the unit did not attain full power until 1988. The reactor experienced at least one serious accident when 4MT (four metric tons) of heavy water overflowed from the reactor core in 1985 following vibration problems.\n\nDesigned as a larger version of the CIRUS reactor, Dhruva was an Indian designed project built to provide an independent source of weapons-grade plutonium free from safeguards. The Dhruva project cost 950 million rupees. The reactor uses heavy water (deuterium) as a moderator and coolant. Aluminum clad fuel rods containing natural uranium are used to obtain a maximum power output of 100MW. According to conservative estimates, the reactor produces an average of 16–26 kg of weapons-grade plutonium per year in its spent fuel, while former Indian Atomic Energy Commission (AEC) Chairman P.K. Iyengar said the unit could produce up to 30 kg of weapons-grade plutonium each year.\n\nDhruva, in Indian mythology, is a prince blessed to eternal existence and glory as the Pole Star (Dhruva Nakshatra in Sanskrit) by Lord Vishnu. It can also mean simply the Pole Star or 'ultimate' in Sanskrit.\n\n"}
{"id": "8951334", "url": "https://en.wikipedia.org/wiki?curid=8951334", "title": "Diver's pump", "text": "Diver's pump\n\nA diver's pump is a manually operated low pressure air compressor used to provide divers in standard diving dress with air while they are underwater.\n\nRotary pumps are driven by a crankshaft that is rotated by handles on two flywheels attached to the ends of the shaft on each side of the pump. Rotary pumps were built with one, two or three cylinders, and are operated by a team of two men. Pistons attached to the crankshaft draw in air through the inlet valves and then pump it through the outlet valves to an air hose which delivers the air to the helmet of the diver. Cylinders, valves and outlet fittings for air are generally made from brass for corrosion resistance in the marine environment. Rotary operated pumps were manufactured with single or double action.\n\nFlow of air through the helmet could be controlled by manually adjusting the back-pressure on the helmet exhaust valve, usually on the lower right side of the bonnet, and by manually adjusting the inlet supply valve on the airline, usually fastened to the front lower left of the corselet. Flow rate would also be affected by the surface delivery system and depth. Manual pumps would be operated at the speed necessary for sufficient air supply, which could be judged by delivery pressure and feedback from the diver. Many manual pumps had delivery pressure gauges calibrated in units of water depth - feet or metres of water column - which would provide the supervisor with a reasonable indication of diver depth. If the diver needed more air, the operators would have to crank faster.\n\nLever pumps have one or two cylinders, which are operated by rocking a beam with handles attached to its ends which is pivoted at the centre for a two cylinder pump, and at the end for a single cylinder pump. Vertical lever pumps with bell-crank operation were also made, usually for shallow water work. The piston rods are connected to the beam near the pivot. Upward movement of the pistons pulls the air into the cylinders through the inlet valves, and then downward movement pumps the air through the hose to the helmet of the diver in a single action pump. Cylinders, valves and outlet for air are usually made from brass for reliability.\n\nThe pump may be mounted in a cabinet for protection during transport and storage, and may be fitted with one or more pressure gauges.\n\n\n"}
{"id": "33766737", "url": "https://en.wikipedia.org/wiki?curid=33766737", "title": "Electric Power Systems Research", "text": "Electric Power Systems Research\n\nElectric Power Systems Research is a peer-reviewed scientific journal covering research on new applications of transmission, generation, distribution and uses of electric power. Its current editor-in-chief is Carlo Alberto Nucci. According to the \"Journal Citation Reports\", the journal has a 2010 impact factor of 1.396.\n"}
{"id": "497684", "url": "https://en.wikipedia.org/wiki?curid=497684", "title": "Equivalent series resistance", "text": "Equivalent series resistance\n\nPractical capacitors and inductors as used in electric circuits are not ideal components with only capacitance or inductance. However, they can be treated, to a very good degree of approximation, as being ideal capacitors and inductors in series with a resistance; this resistance is defined as the equivalent series resistance (ESR). If not otherwise specified, the ESR is always an AC resistance measured at specified frequencies, 100 kHz for switched-mode power supply components, 120 Hz for linear power-supply components, and at the self-resonant frequency for general-application components. Audio components may report \"Q factor\", incorporating ESR among other things, at 1000 Hz.\n\nElectrical circuit theory deals with ideal resistors, capacitors and inductors, each assumed to contribute only resistance, capacitance or inductance to the circuit. However, all components have a non-zero value of each of these parameters. In particular, all physical devices are constructed of materials with finite electrical resistance, so that physical components have some resistance in addition to their other properties. The physical origins of ESR depend on the device in question.\nOne way to deal with these inherent resistances in circuit analysis is to use a lumped element model to express each physical component as a combination of an ideal component and a small resistor in series, the ESR. The ESR can be measured and included in a component's datasheet. To some extent it can be calculated from the device properties.\n\nQ factor, which is related to ESR and is sometimes a more convenient parameter than ESR to use in calculations of high-frequency non-ideal performance of real inductors, is quoted in inductor data sheets.\n\nCapacitors, inductors, and resistors are usually designed to minimise other parameters. In many cases this can be done to a sufficient extent that \"parasitic\" capacitance and inductance of a resistor, for example, are so small as not to affect circuit operation. However, under some circumstances parasitics become important and even dominant.\n\nPure capacitors and inductors do not dissipate energy; any component which dissipates energy must be treated in a equivalent circuit model incorporating one or more resistors. Actual passive two-terminal components can be represented by some network of lumped and distributed ideal inductors, capacitors, and resistors, in the sense that the real component behaves as the network does. Some of the components of the equivalent circuit can vary with conditions, e.g., frequency and temperature.\n\nIf driven by a periodic sinewave (alternating current) the component will be characterised by its complex impedance \"Z\"(ω) = \"R\" + \"j\" \"X\"(ω); the impedance can involve several minor resistances, inductances and capacitances in addition to the main property. These small deviations from the ideal behavior of the device can become significant under certain conditions, typically high frequency, where the reactance of small capacitances and inductances can become a significant element of circuit operation. Models of lesser or greater complexity can be used, depending upon the accuracy required. For many purposes a simple model with an inductance or capacitance in series with an ESR is good enough.\n\nThese models, however simple or complex, can be inserted into a circuit to calculate performance. Computer tools are available for complex circuits; e.g., the SPICE program and its variants.\n\nAn inductor consists of a conducting insulated wire coil usually wound around a ferromagnetic core. Inductors have resistance inherent in the metal conductor, quoted as DCR in datasheets. This metallic resistance is small for small inductance values (typically below 1 Ω). The DC wire resistance is an important parameter in transformer and general inductor design because it contributes to the impedance of the component, and current flowing through that resistance is dissipated as waste heat and lost from the circuit. It can be modeled as a resistor in series with the inductor, often leading to the DC resistance being referred to as the ESR. Though this is not precisely correct usage, the unimportant elements of ESR are often neglected in circuit discussion, since it is rare that all elements of ESR are significant to a particular application.\n\nAn inductor using a core to increase inductance will have losses such as hysteresis and eddy current in the core. At high frequencies there are also losses in the windings due to proximity and skin effects. These are in addition to wire resistance, and lead to a higher ESR.\n\nIn a non-electrolytic capacitor and electrolytic capacitors with solid electrolyte the metallic resistance of the leads and electrodes and losses in the dielectric cause the ESR. Typically quoted values of ESR for ceramic capacitors are between 0.01 and 0.1 ohms. ESR of non-electrolytic capacitors tends to be fairly stable over time; for most purposes real non-electrolytic capacitors can be treated as ideal components.\n\nAluminium and tantalum electrolytic capacitors with non solid electrolyte have much higher ESR values, up to several ohms; electrolytics of higher capacitance have lower ESR. ESR decreases with frequency up to the capacitor's self-resonant frequency. A very serious problem, particularly with aluminium electrolytics, is that ESR increases over time with use; ESR can increase enough to cause circuit malfunction and even component damage, although measured capacitance may remain within tolerance. While this happens with normal aging, high temperatures and large ripple current exacerbate the problem. In a circuit with significant ripple current, an increase in ESR will increase heat dissipation, thus accelerating aging.\n\nElectrolytic capacitors rated for high-temperature operation and of higher quality than basic consumer-grade parts are less susceptible to become prematurely unusable due to ESR increase. A cheap electrolytic capacitor may be rated for a life of less than 1000 hours at 85°C. (A year is 8760 hours.) Higher-grade parts are typically rated at a few thousand hours at maximum rated temperature, as can be seen from manufacturers' datasheets. If ESR is critical, specification of a part with higher temperature rating, \"low ESR\" or larger capacitance than is otherwise required may be advantageous. There is no standard for \"low ESR\" capacitor rating.\n\nPolymer capacitors usually have lower ESR than wet-electrolytic of same value, and stable under varying temperature. Therefore, polymer capacitors can handle higher ripple current. From about 2007 it became common for better-quality computer motherboards to use only polymer capacitors where wet electrolytics had been used previously.\n\nThe ESR of capacitors larger than about 1 μF is easily measured in-circuit with an ESR meter.\n\n\n"}
{"id": "16812637", "url": "https://en.wikipedia.org/wiki?curid=16812637", "title": "European windstorm", "text": "European windstorm\n\nEuropean windstorms are the strongest extratropical cyclones which occur across the continent of Europe. They form as cyclonic windstorms associated with areas of low atmospheric pressure. They are most common in the autumn and winter months. On average, the month when most windstorms form is January. The seasonal average is 4.6 windstorms. Deep low pressure areas are relatively common over the North Atlantic, sometimes starting as nor'easters off the New England coast, and frequently track across the North Atlantic Ocean towards western Europe, past the north coast of Great Britain and Ireland and into the Norwegian Sea. However, when they track further south, they can affect almost any country in Europe. Commonly affected countries include the United Kingdom, Ireland, the Netherlands, Norway, the Faroe Islands and Iceland, but any country in Central Europe, Northern Europe and especially Western Europe is occasionally struck by such a storm system.\n\nThe strong wind phenomena intrinsic to European windstorms, that give rise to \"damage footprints\" at the surface, can be placed into three categories, namely the \"warm jet\", the \"cold jet\", and the \"sting jet\". These phenomena vary in terms of physical mechanisms, atmospheric structure, spatial extent, duration, severity level, predictability, and location relative to cyclone and fronts.\n\nOn average, these storms cause economic damage of around €1.9 billion per year, and insurance losses of €1.4 billion per year (1990–1998). They rank as the second highest cause of global natural catastrophe insurance loss (after U.S. hurricanes).\n\nUp to the second half of the 19th century, European windstorms were named after the person who spotted them. Usually, they would be named either by the year, the date, the Saint's day of their occurrence or any other way that made them commonly known.\n\nHowever, a storm may still be named differently in different countries. For instance, the Norwegian weather service also names independently notable storms that affect Norway, which can result in multiple names being used in different countries they affect, such as:\n\n\nAn alternative Scottish naming system arose in 2011 via social media/Twitter which resulted in the humorous naming of Hurricane Bawbag and Hurricane Fannybaws. Such usage of the term Hurricane is not without precedent, as the 1968 Scotland storm was referred to as \"Hurricane Low Q\".\n\nThe UK Met Office and Irish forecasting service Met Éireann held discussions about developing a common naming system for Atlantic storms. In 2015 a pilot project by the two forecasters was launched as \"Name our storms\" which sought public participation in naming large-scale cyclonic windstorms affecting the UK and/or Ireland over the winter of 2015/16. The UK/Ireland storm naming system began its first operational season in 2017/2018. An independent forecaster, the European Windstorm Centre, also has its own naming list, although this is not an official list.\n\nDuring 1954, Karla Wege, a student at the Free University of Berlin's meteorological institute suggested that names should be assigned to all areas of low and high pressure that influenced the weather of Central Europe. The university subsequently started to name every area of high or low pressure within its weather forecasts, from a list of 260 male and 260 female names submitted by its students. The female names were assigned to areas of low pressure while male names were assigned to areas of high pressure. The names were subsequently exclusively used by Berlin's media until February 1990, after which the German media started to commonly use the names, however, they were not officially approved by the German Meteorological Service Deutscher Wetterdienst. The DWD subsequently banned the usage of the names by their offices during July 1991, after complaints had poured in about the naming system. However, the order was leaked to the German press agency, Deutsche Presse-Agentur, who ran it as its lead weather story. Germany's ZDF television channel subsequently ran a phone in poll on 17 July 1991 and claimed that 72% of the 40,000 responses favored keeping the names. This made the DWD pause and think about the naming system and these days the DWD accept the naming system and request that it is maintained.\n\nDuring 1998 a debate started about if it was discrimination to name areas of high pressure with male names and the areas of low pressure with female names. The issue was subsequently resolved by alternating male and female names each year. In November 2002 the \"Adopt-a-Vortex\" scheme began, which allows members of the public or companies to buy naming rights for a letter chosen by the buyer that are then assigned alphabetically to high and low pressure areas in Europe during each year. The naming comes with the slim chance that the system will be notable. The money raised by this is used by the meteorology department to maintain weather observations at the Free University.\n\nSeveral European languages use cognates of the word \"huracán\" (\"ouragan\", \"uragano\", \"orkan\", \"huragan\", \"orkaan\", \"ураган\", which may or may not be differentiated from tropical hurricanes in these languages) to indicate particularly strong cyclonic winds occurring in Europe. The term hurricane as applied to these storms is not in reference to the structurally different tropical cyclone of the same name, but to the \"hurricane strength\" of the wind on the Beaufort scale (winds ≥ 118 km/h or ≥ 73 mph).\n\nIn English, use of term \"hurricane\" to refer to European windstorms is mostly discouraged, as these storms do not display the structure of tropical storms. Likewise the use of the French term \"ouragan\" is similarly discouraged as \"hurricane\" is in English, as it is typically reserved for tropical storms only. European windstorms in Latin Europe are generally referred to by derivatives of \"tempestas\" (\"tempest\", \"tempête\", \"tempestado\", \"tempesta\"), meaning storm, weather, or season, from the Latin \"tempus\", meaning time.\n\nGlobally storms of this type forming between 30° and 60° latitude are known as \"extratropical cyclones\". The name \"European windstorm\" reflects that these storms in Europe are primarily notable for their strong winds and associated damage, which can span several nations on the continent. The strongest cyclones are called \"windstorms\" within academia and the insurance industry. The name \"European windstorm\" has not been adopted by the UK Met Office in broadcasts (though it is used in their academic research), the media or by the general public, and appears to have gained currency in academic and insurance circles as a linguistic and terminologically neutral name for the phenomena.\n\nIn contrast to some other European nations there is a lack of a widely accepted name for these storms in English. The Met Office and UK media generally refer to these storms as \"severe gales\". The current definition of severe gales (which warrants the issue of a weather warning) are repeated gusts of or more over inland areas. European windstorms are also described in forecasts variously as \"winter storms\", \"winter lows\", \"autumnal lows\", \"Atlantic lows\" and \"cyclonic systems\". They are also sometimes referred to as \"bullseye isobars\" and \"dartboard lows\" in reference to their appearance on weather charts. A Royal Society exhibition has used the name \"European cyclones\", with \"North-Atlantic cyclone\" and \"North-Atlantic windstorms\" also being used. Though with the advent of the \"Name our Storms\" project, they are generally known as storms.\n\nThe state of the North Atlantic Oscillation relates strongly to the frequency, intensity, and tracks of European windstorms. An enhanced number of storms have been noted over the North Atlantic/European region during positive NAO phases (compared to negative NAO phases) and is due to larger areas of suitable growth conditions. The occurrence of extreme North Atlantic cyclones is aligned with the NAO state during the cyclones' development phase. The strongest storms are embedded within, and form in large scale atmospheric flow. It should be kept in mind that, on the other hand, the cyclones themselves play a major role in steering the NAO phase. Aggregate European windstorm losses show a strong dependence on NAO, with losses increasing/decreasing 10-15% at all return periods.\n\nTemporal clustering of windstorm events has also been noted, with 8 consecutive storms hitting Europe during the winter of 1989/90. Lothar and Martin in 1999 were separated only by 36 hours. Kyrill in 2007 following only four days after Hanno, and 2008 with Johanna, Kirsten and Emma. In 2011, Xaver (Berit) moved across Northern Europe and just a day later another storm, named Yoda, hit the same area. In December the same year, Friedhelm, Hergen, Joachim and Oliver/Patrick (Cato/Dagmar) struck northern Europe.\n\nInsurance losses from windstorms are the second greatest source of loss for any natural peril after Atlantic hurricanes in the United States. Windstorm losses exceed those caused by flooding in Europe. For instance one windstorm, Kyrill in 2007, exceeded the losses of the 2007 United Kingdom floods. \nOn average, some 200,000 buildings are damaged by high winds in the UK every year. \nEuropean windstorms wipe out electrical generation capacity across large areas, making supplementation from abroad difficult (windturbines shut down to avoid damage and nuclear capacity may shut if cooling water is contaminated or flooding of the power plant occurs). Transmission capabilities can also be severely limited if power lines are brought down by snow, ice or high winds. In the wake of Cyclone Gudrun in 2005 Denmark and Latvia had difficulty importing electricity, and Sweden lost 25% of its total power capacity as the Ringhals Nuclear Power Plant and Barsebäck nuclear power plant nuclear plants were shut down.\n\nDuring the Boxing Day Storm of 1998 the reactors at Hunterston B nuclear power station were shut down when power was lost, possibly due to arcing at pylons caused by salt spray from the sea. When the grid connection was restored, the generators that had powered the station during the blackout were shut down and left on \"manual start\", so when the power failed again the station was powered by batteries for a short time of around 30 minutes, until the diesel generators were started manually. During this period the reactors were left without forced cooling, in a similar fashion to the Fukushima Daiichi nuclear disaster, but the event at Hunterston was rated as International Nuclear Event Scale 2.\n\nA year later in 1999 during the Lothar storm Flooding at the Blayais Nuclear Power Plant resulted in a \"level 2\" event on the International Nuclear Event Scale. Cyclone Lothar and Martin in 1999 left 3.4 million customers in France without electricity, and forced EdF to acquire all the available portable power generators in Europe, with some even being brought in from Canada. These storms brought a fourth of France's high-tension transmission lines down and 300 high-voltage transmission pylons were toppled. It was one of the greatest energy disruptions ever experienced by a modern developed country.\n\nFollowing the Great Storm of 1987 the High Voltage Cross-Channel Link between the UK and France was interrupted, and the storm caused a domino-effect of power outages throughout the Southeast of England. Conversely windstorms can produce too much wind power. Cyclone Xynthia hit Europe in 2010, generating 19000 megawatts of electricity from Germany's 21000 wind turbines. The electricity produced was too much for consumers to use, and prices on the European Energy Exchange in Leipzig plummeted, which resulted in the grid operators having to pay over 18 euros per megawatt-hour to offload it, costing around half a million euros in total.\n\nDisruption of the gas supply during Cyclone Dagmar in 2011 left Royal Dutch Shell's Ormen Lange gas processing plant in Norway inoperable after its electricity was cut off by the storm. This left gas supplies in the United Kingdom vulnerable as this facility can supply up to 20 percent of the United Kingdom's needs via the Langeled pipeline. However, the disruption came at a time of low demand. The same storm also saw the Leningrad Nuclear Power Plant also affected, as algae and mud stirred up by the storm were sucked into the cooling system, resulting in one of the generators being shut down. A similar situation was reported in the wake of Storm Angus in 2016 (though not linked specifically to the storm) when reactor 1 at Torness Nuclear Power Station in Scotland was taken offline after a sea water intake tripped due to excess seaweed around the inlet. Also following Storm Angus the UK's National Grid launched an investigation into whether a ship's anchor damaged four of the eight cables of the Cross Channel high voltage interconnector, which would leave it only able to operate at half of its capacity until February 2017.\n\n\n\n\n\n"}
{"id": "30177094", "url": "https://en.wikipedia.org/wiki?curid=30177094", "title": "F-1 (nuclear reactor)", "text": "F-1 (nuclear reactor)\n\nThe F-1 is a research reactor operated by the Kurchatov Institute in Moscow, Russia. When started on December 25, 1946, it became the first nuclear reactor in Europe to achieve a self-sustaining nuclear chain reaction. It was still in operation in the beginning of the 2010s, with a power level of 24 kW, making it, at that time, the world's oldest operating reactor. In November 2016 it was in permanent shutdown state.\n\n\n"}
{"id": "25701723", "url": "https://en.wikipedia.org/wiki?curid=25701723", "title": "February 1995 nor'easter", "text": "February 1995 nor'easter\n\nThe February 1995 Northeast United States snowstorm was a significant nor'easter that impacted the Mid-Atlantic and New England regions of the United States around the beginning of the month. It was the only major nor'easter of the 1994–1995 winter. \n\nThe initial low pressure area tracked eastward from the southern Great Plains on February 2. Gradually intensifying, it was situated over eastern Kentucky by 0000 UTC on February 4. As the system entered West Virginia, a secondary low began to develop over South Carolina. The new low quickly deepened, and absorbed the primary low over West Virginia into its expanding and strengthening circulation. It continued to rapidly mature as it moved northward from eastern Maryland, and it hugged the coast as it moved northeastward towards southern New England. \n\nThe cyclone reached a strength of 980 millibars while located south of Long Island. It crossed eastern New England and reached its peak intensity, with a minimum barometric pressure of 962 mb, over eastern Maine. Prior to the nor'easter, an area of high pressure drifted southeastward from north of the Great Lakes, producing sufficient cold air to support snow throughout the Northeast. However, as the storm intensified, precipitation near the coast, including the major cities of Philadelphia, New York, and Boston, changed to rain. Due to the lack of a strong anticyclone at the surface, winds in association with the system were minimal until after the storm abated. Behind the nor'easter, high winds, sufficient to bring down trees and powerlines, occurred.\n\nSnow from the nor'easter was heavy and widespread. Areas that picked up or more include Pennsylvania, New York, New Jersey, Connecticut, Massachusetts, Vermont, New Hampshire and Maine. Scattered reports of were received in upstate New York and northern Vermont. At Burlington, Vermont, of snow fell, beating the daily record of set in 1988. Overall, the event ranks as a category 2 on the Northeast Snowfall Impact Scale.\n\nIn Pennsylvania, the heaviest snow fell in Bucks County. Throughout the state, the number of traffic accidents was minimized due to the storm's arrival on a weekend. Three died of cardiac arrest after shoveling snow, and more than 100 people were hospitalized for chest pain. Several dozen more were injured after slipping and falling on ice, and 53 residents sustained snowblower-related injuries. At least 18 people were injured in nearby New Jersey, where the maximum snow accumulation was reported to be in Princeton. Along the coast, minor to moderate coastal flooding occurred, along with some beach erosion. Some areas lost power for several hours as fallen tree branches downed power lines. The cyclone also produced heavy snow and coastal flooding in New York.\n\n"}
{"id": "3048095", "url": "https://en.wikipedia.org/wiki?curid=3048095", "title": "Fern Canyon", "text": "Fern Canyon\n\nFern Canyon is a canyon in the Prairie Creek Redwoods State Park in Humboldt County, California, western United States. The park is managed in cooperation with other nearby redwoods state parks and Redwood National Park. It is named for the ferns growing on the 50-foot high walls, through which runs Home Creek. Fern Canyon is recognized as a World Heritage site and an International Biosphere Reserve. \n\nFern Canyon was donated to the State to add 2,125 acres to Prairie Creek State Park.\n\nFern Canyon has California native ferns covering the sheer walls, giving a primeval habitat quality.\nSome species include:\n\nA hiking trail follows the canyon and creek. The start of Fern Canyon Trail is reached at the bottom of the canyon by hiking a quarter mile north up California Coastal Trail from Fern Canyon Day Use Area, which is north of Gold Bluffs Beach Campground. The trail loop is 0.5 miles, one end of the trail connecting to the James Irvine Trail.\n\nThe prehistoric ambience led to the canyon being used as a filming location for \"\", BBC's \"Walking with Dinosaurs\" and IMAX's Dinosaurs Alive!.\n\n"}
{"id": "47829992", "url": "https://en.wikipedia.org/wiki?curid=47829992", "title": "Flux loop", "text": "Flux loop\n\nA flux loop is a loop of wire placed inside a plasma at a right angle. Changes in the field create a current in the loop, which may be interpreted to measure the properties of the plasma. Flux loops are key diagnostics in fusion power research.\n\nA flux loop is a loop of wire. The magnetic field passes through the wire loop. As the field varied inside the loop, it generated a voltage, driving a current. This was measured and from the signal the magnetic flux was measured. The voltage induced is determined by:\n\nTypically, you need to integrate the signal over a period of time to get the magnetic field at that instant (not just the change in magnetic fields). This is normally done by adding a integrator circuit which will passively integrate the electrical signal.\n\nThe flux loop is common on tokamaks, magnetic mirrors, Field-reversed configurations, the Levitated dipole experiment and the polywell. In tokamaks a set of loops is used, and these are spaced slightly off-center and non-concentrically. Placing the loops intentionally asymmetrically allows the users to find the magnetic field density at different points inside the tokamak. The distance between the loops was determined by shafranov, and is sometime called the \"shafranov distance\".\n"}
{"id": "9529842", "url": "https://en.wikipedia.org/wiki?curid=9529842", "title": "Global Energy Network Institute", "text": "Global Energy Network Institute\n\nThe Global Energy Network Institute (GENI) is a research and education organization founded by Peter Meisen in 1986 and registered as a 501(c)(3) non-profit organization in 1991. GENI's focus is on the interconnection of electric power transmission networks between nations and continents, emphasizing tapping abundant renewable energy resources, and utilizing the efficiencies of seasonal, time of day, and load differences around the world.\n\nGENI's goal is to educate world leaders and policy makers on the benefits of this global strategy. The concept of an interconnected global grid linked to renewable resources was first suggested by Buckminster Fuller in the World Game simulation in the 1970s. Fuller concluded that this strategy is the highest priority of the World Game simulation, (see page 206 of Fuller's book \"Critical Path\" (1981, ).\n\nGENI has organized international workshops on international electricity transmission grids and coordinated workshops on renewable energy generation, the latter hosted by the IEEE Power Engineering Society.\n\nGENI is one of the original members of American Council on Renewable Energy and has been a regular presence at the World Energy Congress, held internationally every 3 years.\n\nGENI has stated that one reason technologies to accelerate the use of renewable energy and to avert climate change were not making headway in the marketplace has been the lack of ways for investors to track and easily invest in these technologies. Because of this, in 2004, GENI partnered with KLD, who creates socially conscious investing stock indexes in the US, to create the KLD Global Climate 100 stock index. The index became available for investment in Japan in 2005 and in the U.S. on April 24, 2007.\n\nGENI's research includes information about national electricity power grids; location and availability of renewable energy resources; international integrated energy models; current national energy usage (by fuel type) and global issues that are addressed by the GENI concept, such as international relations, human security, peace and disarmament, the environment, conflict and development, and global health.\n\nNumerous articles have been published on and about the organization, the concept, and its personnel in the following publications. Some are in academic and professional publications:\n\nA.A. Bolonkin and R.B. Cathcart, \"Antarctica: a southern hemisphere wind power station?\", INT. J. GLOBAL ENVIRONMENTAL ISSUES 8: 262-273 (2008). [They propose windpower base of 450 GW output connected to the Global Energy Electric Grid via undersea HVDC cable.]\n\nSome are in general one:\n\n\nThe Global Energy Network Institute (or GENI) is a research and education organization founded in 1986. It was officially registered as a 501(c)(3) non-profit Corporation in 1991.\n\n\n"}
{"id": "898390", "url": "https://en.wikipedia.org/wiki?curid=898390", "title": "Helge Lund", "text": "Helge Lund\n\nHelge Lund (born 16 October 1962) is a Norwegian businessman, a director of Schlumberger since June 2016, and the former chief executive officer (CEO) of BG Group, Statoil and Aker Kværner..\n\nOn 26 April 2018, it was announced by BP that he would join the board on the 1 September 2018 and succeed Carl-Henric Svanberg as chairman with effect from 1 January 2019.\n\nLund graduated in business management at the Norwegian School of Economics in Bergen. He also has a Master of Business Administration (MBA) from the INSEAD business school in France. \n\nHe started his career as a management consultant for McKinsey & Company and as political adviser for the Conservative Party in the Norwegian parliament Stortinget, before starting work for Hafslund Nycomed in 1993. In 1997-8 he was vice president in Nycomed Pharma before starting work in Aker RGI in 1999 as vice president before becoming CEO for Aker Kværner in 2002. After Olav Fjell withdrew as CEO of Statoil in 2004, Lund took over and was retained after Statoil merged with the oil & gas division of Norsk Hydro in 2007 to create StatoilHydro.\n\nOn 15 October 2014, Lund resigned as CEO for Statoil with immediate effect, to join the management team of the UK's BG Group as CEO from 9 February 2015. \n\nOn 1 December 2014, in response to pressure from shareholders, BG Group reduced a £12 million share award golden hello for Lund to between £4.7 million to £10.6 million, depending on the company's future performance. His basic salary will be £1.5 million, but with bonuses, total compensation could reach £14 million per annum.\n\nFollowing the takeover of BG Group by Royal Dutch Shell, Lund was out of a job, but did receive a total of £5.5 million for his 11 months work, and £9.7 million in shares in February 2016, as a result of the takeover.\n\nIn June 2016, Lund was appointed to the board of directors of Schlumberger.\n\nHe is married to Else-Cathrine Lund.\n"}
{"id": "45302840", "url": "https://en.wikipedia.org/wiki?curid=45302840", "title": "Howard's Rock", "text": "Howard's Rock\n\nHoward's Rock is a large piece of white flint that is displayed in Clemson University's Memorial Stadium. The rock is the center of a longstanding tradition where players touch it before running down the hill in the east end zone at each home football game.\n\nThe rock was brought to football coach Frank Howard in the early 1960s as a gift from Samuel C. Jones. Jones found the rock while driving through Death Valley, California and gave it to Howard as a reference to \"Death Valley,\" the name Howard used to refer to Memorial Stadium. The coach used the rock as a doorstop until 1966. He was cleaning out his office when he told Gene Willimon, a Clemson booster, \"Take this rock and throw it over the fence or out in the ditch...Do something with it, but get it out of my office.\" It was Willimon who had the rock placed on a pedestal in the east end zone, where it remains today.\n\nThe rock made its first appearance on September 24, 1966: Clemson was losing to Virginia by 18 points with seventeen minutes left in the game. The Tigers made up the deficit and won the game 40-35. The next season was when the tradition of rubbing the rock upon entering the stadium began. Howard reportedly said to his players, \"If you're going to give me 110 percent, you can rub that rock. If you're not, keep your filthy hands off of it.\"\n\nThe Tigers have continued this tradition since 1967, except for two-and-a-half seasons between 1970 and 1972. This was due to new head coach Hootie Ingram's changing the team's entrance to the west end zone after Frank Howard's retirement. During those seasons, Clemson held a bad record at home of 6-9. Before the South Carolina rivalry game in 1972, the team voted to enter via the east end zone and run down the hill. They later won the game 7-6.\n\nOn June 2, 2013 Howard's Rock was vandalized. The case the Rock was held in was broken into and a large portion of the rock was broken off. \nThree men have been arrested in this ongoing investigation; ESPN reported that “the charges being pressed on him are felony malicious injury to animals or personal property valued at more than $2,000 but less than $10,000 and misdemeanor trespassing.\" The charges were subsequently upgraded. The damage to the rock was re-evaluated to more than 10,000 dollars. Clemson University police later stated that the surveillance video from the outside of Memorial Stadium shows that three people got out of the truck used in the act. Two more people have been arrested and released on a bond of 7,500 dollars.\n\nMicah Rogers was accused vandalizing and stealing a portion of Howard's Rock in Memorial Stadium. A jury found Rogers guilty of malicious damage, but they found him not guilty of grand larceny. The judge gave Rogers the maximum sentence of 30 days in jail or a $1,000 fine for the malicious damage charge; however, the sentence was suspended, meaning Rogers does not have to serve the jail time, so long as he pays a $750 fine and completes 25 days of supervised community service.\n\nTwo other men later pleaded guilty to attempting to cover up the vandalism of Howard's Rock that took place in June 2013. Michael J. Rogers, 49, and Alden J. Gainey, 20, pleaded guilty to the misdemeanor charge of giving false Information to police for their involvement in attempting to cover up vandalism of Howard’s Rock at Clemson University. Micah Rogers, Michael Rogers' son, was previously convicted of malicious injury to property in the case. Michael Rogers had a meeting June 20, 2013 at his home in North Carolina with Micah Rogers, Gainey, and Xavia Wynn to discuss video surveillance of Micah’s truck and the three boys in the vicinity of Howard's Rock the night the vandalism occurred.\n"}
{"id": "14369", "url": "https://en.wikipedia.org/wiki?curid=14369", "title": "Humphry Davy", "text": "Humphry Davy\n\nSir Humphry Davy, 1st Baronet (17 December 177829 May 1829) was a Cornish chemist and inventor, who is best remembered today for isolating, using electricity, a series of elements for the first time: potassium and sodium in 1807 and calcium, strontium, barium, magnesium and boron the following year, as well as discovering the elemental nature of chlorine and iodine. He also studied the forces involved in these separations, inventing the new field of electrochemistry. In 1799 Davy experimented with nitrous oxide and became astonished that it made him laugh, so he nicknamed it \"laughing gas\", and wrote about its potential anaesthetic properties in relieving pain during surgery.\n\nBerzelius called Davy's 1806 Bakerian Lecture \"On Some Chemical Agencies of Electricity\" \"one of the best memoirs which has ever enriched the theory of chemistry.\"\nDavy was a baronet, President of the Royal Society (PRS), Member of the Royal Irish Academy (MRIA), and Fellow of the Geological Society (FGS). He also invented the Davy lamp and a very early form of incandescent light bulb.\n\nHe joked that his assistant Michael Faraday was his greatest discovery.\n\nDavy was born in Penzance, Cornwall in England on 17 December 1778. Davy's brother, John Davy, writes that the society of their hometown was characterised by \"an almost unbounded credulity respecting the supernatural and monstrous ... Amongst the middle and higher classes, there was little taste for literature, and still less for science ... Hunting, shooting, wrestling, cockfighting, generally ending in drunkenness, were what they most delighted in\". At the age of six, Davy was sent to the grammar school at Penzance. Three years later, his family moved to Varfell, near Ludgvan, and subsequently, in term-time Davy boarded with John Tonkin, his godfather and later his guardian. On leaving Penzance grammar school in 1793, Tonkin paid for Davy to attend Truro Grammar School in 1793 to finish his education under the Rev Dr Cardew, who, in a letter to Davies Gilbert, said dryly: \"I could not discern the faculties by which he was afterwards so much distinguished.\" Yet, Davy entertained his school friends with writing poetry, Valentines, and telling stories from One Thousand and One Nights. Reflecting on his school days, in a letter to his mother, Davy wrote: \"Learning naturally is a true pleasure; how unfortunate then it is that in most schools it is made a pain.\" Davy said: \"I consider it fortunate I was left much to myself as a child, and put upon no particular plan of study ... What I am I made myself.\" Davy's brother praises his \"native vigour\": \"there belonged, however, to his mind, it cannot be doubted, the genuine quality of genius, or of that power of intellect which exalts its possessor above the crowd.\"\n\nAfter Davy's father died in 1794, Tonkin apprenticed him to John Bingham Borlase, a surgeon with a practice in Penzance. Davy's indenture is dated 10 February 1795. In the apothecary's dispensary, Davy became a chemist, and conducted his earliest chemical experiments in a garret in Tonkin's house. Davy's friends said: \"This boy Humphry is incorrigible. He will blow us all into the air.\" His elder sister complained of the ravages made on her dresses by corrosive substances. Davy was taught French by a refugee priest, and in 1797 read Lavoisier's \"Traité élémentaire de chimie\": much of his future work can be seen as reacting against Lavoisier's work and the dominance of French chemists.\n\nAs a poet, over one hundred and sixty manuscript poems were written by Davy, the majority of which are found in his personal notebooks. Most of his written poems were not published, and he chose instead to share a few of them with his friends. Eight of his known poems were published. His poems reflected his views on both his career and also his pereception of certain aspects of human life. He wrote on human endeavours and aspects of life like death, metaphysics, geology, natural theology and chemistry.\n\nJohn Ayrton Paris remarked that poetry written by the young Davy \"bear the stamp of lofty genius\". Davy's first preserved poem entitled \"The Sons of Genius\" is dated 1795 and marked by the usual immaturity of youth. Other poems written in the following years, especially \"On the Mount's Bay\" and \"St Michael's Mount\", are descriptive verses, showing sensibility but no true poetic imagination. Three of Davy's paintings from around 1796 have been donated to the Penlee House museum at Penzance. One is of the view from above Gulval showing the church, Mount's Bay and the Mount, while the other two depict Loch Lomond in Scotland.\n\nWhile writing verses at the age of 17 in honour of his first love, he was eagerly discussing the question of the materiality of heat with his Quaker friend and mentor Robert Dunkin. Dunkin remarked: 'I tell thee what, Humphry, thou art the most quibbling hand at a dispute I ever met with in my life.' One winter day he took Davy to the Larigan River, To show him that rubbing two plates of ice together developed sufficient energy by motion, to melt them, and that after the motion was suspended, the pieces were united by regelation. It was a crude form of analogous experiment exhibited by Davy in the lecture-room of the Royal Institution that elicited considerable attention. As professor at the Royal Institution, Davy repeated many of the ingenious experiments he learned from his friend and mentor, Robert Dunkin.\n\nEven though he initially started writing his poems albeit haphazardly, as a reflection of his views on his career, and on life generally, most of his final poems concentrated more on immortality and death. This was after he started experiencing failing health and a decline both in health and career.\n\nDavies Giddy met Davy in Penzance carelessly swinging on the half-gate of Dr Borlase's house, and interested by his talk invited him to his house at Tredrea and offered him the use of his library. This led to an introduction to Dr Edwards, who lived at Hayle Copper House. Edwards was a lecturer in chemistry in the school of St. Bartholomew's Hospital. He permitted Davy to use his laboratory and possibly directed his attention to the floodgates of the port of Hayle, which were rapidly decaying as a result of the contact between copper and iron under the influence of seawater. Galvanic corrosion was not understood at that time, but the phenomenon prepared Davy's mind for subsequent experiments on ship's copper sheathing. Gregory Watt, son of James Watt, visited Penzance for his health's sake, and while lodging at the Davy's house became a friend and gave him instructions in chemistry. Davy was acquainted with the Wedgwood family, who spent a winter at Penzance.\n\nThomas Beddoes and John Hailstone were engaged in a geological controversy on the rival merits of the Plutonian and Neptunist hypotheses. They travelled together to examine the Cornish coast accompanied by Davies Gilbert and made Davy's acquaintance. Beddoes, who had established at Bristol a 'Pneumatic Institution,' needed an assistant to superintend the laboratory. Gilbert recommended Davy, and in 1798 Gregory Watt showed Beddoes the \"Young man's Researches on Heat and Light\", which were subsequently published by him in the first volume of \"West-Country Contributions\". After prolonged negotiations, mainly by Gilbert, Mrs Davy and Borlase consented to Davy's departure, but Tonkin wished him to remain in his native town as a surgeon, and altered his will when he found that Davy insisted on going to Dr Beddoes.\n\nIn 1802, Humphry Davy had what was then, the most powerful electrical battery in the world at the Royal Institution. With it, Davy created the first incandescent light by passing electric current through a thin strip of platinum, chosen because the metal had an extremely high melting point. It was neither sufficiently bright nor long lasting enough to be of practical use, but demonstrated the principle. By 1806 he was able to demonstrate a much more powerful form of electric lighting to the Royal Society in London. It was an early form of arc light which produced its illumination from an electric arc created between two charcoal rods.\n\nOn 2 October 1798, Davy joined the Pneumatic Institution at Bristol. It had been established to investigate the medical powers of factitious airs and gases (gases produced experimentally or artificially), and Davy was to superintend the various experiments. The arrangement agreed between Dr Beddoes and Davy was generous, and enabled Davy to give up all claims on his paternal property in favour of his mother. He did not intend to abandon the medical profession and was determined to study and graduate at Edinburgh, but he soon began to fill parts of the institution with voltaic batteries. While living in Bristol, Davy met the Earl of Durham, who was a resident in the institution for his health, and became close friends with Gregory Watt, James Watt, Samuel Taylor Coleridge and Robert Southey, all of whom became regular users of nitrous oxide (laughing gas), to which Davy became addicted. The gas was first synthesized in 1772 by the natural philosopher and chemist Joseph Priestley, who called it \"phlogisticated nitrous air\" (see phlogiston). Priestley described his discovery in the book \"Experiments and Observations on Different Kinds of Air (1775)\", in which he described how to produce the preparation of \"nitrous air diminished\", by heating iron filings dampened with nitric acid.\n\nJames Watt built a portable gas chamber to facilitate Davy's experiments with the inhalation of nitrous oxide. At one point the gas was combined with wine to judge its efficacy as a cure for hangover (his laboratory notebook indicated success). The gas was popular among Davy's friends and acquaintances, and he noted that it might be useful for performing surgical operations. Anesthetics were not regularly used in medicine or dentistry until decades after Davy's death.\n\nDavy threw himself energetically into the work of the laboratory and formed a long romantic friendship with Mrs Anna Beddoes, the novelist Maria Edgeworth's sister, who acted as his guide on walks and other fine sights of the locality. The critic Maurice Hindle was the first to reveal that Davy and Anna had written poems for each other. Wahida Amin has transcribed and discussed a number of poems written between 1803 and 1808 to \"Anna\" and one to her infant child. In December 1799 Davy visited London for the first time and extended his circle of friends. Davy features in the diary of William Godwin, with their first meeting recorded for 4 December 1799.\n\nIn the gas experiments Davy ran considerable risks. His respiration of nitric oxide which may have combined with air in the mouth to form nitric acid (HNO), severely injured the mucous membrane, and in Davy's attempt to inhale four quarts of \"pure hydrocarbonate\" gas in an experiment with carbon monoxide he \"seemed sinking into annihilation.\" On being removed into the open air, Davy faintly articulated, \"I do not think I shall die,\" but some hours elapsed before the painful symptoms ceased. Davy was able to take his own pulse as he staggered out of the laboratory and into the garden, and he described it in his notes as \"threadlike and beating with excessive quickness\".\n\nIn this year the first volume of the \"West-Country Collections\" was issued. Half consisted of Davy's essays \"On Heat, Light, and the Combinations of Light\", \"On Phos-oxygen and its Combinations\", and on the \"Theory of Respiration\". On 22 February 1799 Davy, wrote to Davies Gilbert, \"I am now as much convinced of the non-existence of caloric as I am of the existence of light.\" In another letter to Gilbert, on 10 April, Davy informs him: \"I made a discovery yesterday which proves how necessary it is to repeat experiments. The gaseous oxide of azote (the laughing gas) is perfectly respirable when pure. It is never deleterious but when it contains nitrous gas. I have found a mode of making it pure.\" He said that he breathed sixteen quarts of it for nearly seven minutes, and that it \"absolutely intoxicated me.\" \nDavy became increasingly well known in 1799 due to his experiments with the physiological action of some gases, including laughing gas (nitrous oxide). In addition to himself, his enthusiastic experimental subjects included his poet friends Robert Southey and Samuel Taylor Coleridge.\n\nDuring 1799, Beddoes and Davy published \"Contributions to physical and medical knowledge, principally from the west of England\" and \"Essays on heat, light, and the combinations of light, with a new theory of respiration. On the generation of oxygen gas, and the causes of the colors of organic beings.\" Their experimental work was poor, and the publications were harshly criticized. In after years Davy regretted he had ever published these immature hypotheses, which he subsequently designated \"the dreams of misemployed genius which the light of experiment and observation has never conducted to truth.\"\n\nThese criticisms, however, led Davy to refine and improve his experimental techniques, spending his later time at the institution increasingly in experimentation.\nIn 1800, Davy informed Gilbert that he had been \"repeating the galvanic experiments with success\" in the intervals of the experiments on the gases, which \"almost incessantly occupied him from January to April.\" In 1800, Davy published his \"Researches, Chemical and Philosophical, chiefly concerning Nitrous Oxide and its Respiration\", and received a more positive response.\n\nWilliam Wordsworth and Samuel Taylor Coleridge moved to the Lake District in 1800, and asked Davy to deal with the Bristol publishers of the Lyrical Ballads, Biggs & Cottle. Coleridge asked Davy to proofread the second edition of the Lyrical Ballads, the first to contain Wordsworth's Preface in a letter dated 16 July 1800: \"Will you be so kind as just to look over the sheets of the lyrical Ballads\". Wordsworth subsequently wrote to Davy on 29 July 1800, sending him the first manuscript sheet of poems and asking him specifically to correct: \"any thing you find amiss in the punctuation a business at which I am ashamed to say I am no adept\". Wordsworth was ill in the autumn of 1800 and slow in sending poems for the second edition; the volume appeared on 26 January 1801 even though it was dated 1800. While it is impossible to know whether Davy was at fault, this edition of the Lyrical Ballads contained many errors, including the poem \"Michael\" being left incomplete. In a personal notebook marked on the front cover \"Clifton 1800 From August to Novr\", Davy wrote his own Lyrical Ballad: \"As I was walking up the street\". Wordsworth features in Davy's poem as the recorder of ordinary lives in the line: \"By poet Wordsworths Rymes\" [sic].\n\nIn 1799, Count Rumford had proposed the establishment in London of an 'Institution for Diffusing Knowledge', i.e. the Royal Institution. The house in Albemarle Street was bought in April 1799. Rumford became secretary to the institution, and Dr Thomas Garnett was the first lecturer.\nIn February 1801 Davy was interviewed by the committee of the Royal Institution, comprising Joseph Banks, Benjamin Thompson (who had been appointed Count Rumford) and Henry Cavendish. Davy wrote to Davies Gilbert on 8 March 1801 about the offers made by Banks and Thompson, a possible move to London and the promise of funding for his work in galvanism. He also mentioned that he might not be collaborating further with Beddoes on therapeutic gases. The next day Davy left Bristol to take up his new post at the Royal Institution, it having been resolved 'that Humphry Davy be engaged in the service of the Royal Institution in the capacity of assistant lecturer in chemistry, director of the chemical laboratory, and assistant editor of the journals of the institution, and that he be allowed to occupy a room in the house, and be furnished with coals and candles, and that he be paid a salary of 100l. per annum.'\n\nOn 25 April 1801, Davy gave his first lecture on the relatively new subject of 'Galvanism'. He and his friend Coleridge had had many conversations about the nature of human knowledge and progress, and Davy's lectures gave his audience a vision of human civilisation brought forward by scientific discovery. \"It [science] has bestowed on him powers which may almost be called creative; which have enabled him to modify and change the beings surrounding him, and by his experiments to interrogate nature with power, not simply as a scholar, passive and seeking only to understand her operations, but rather as a master, active with his own instruments.\" The first lecture garnered rave reviews, and by the June lecture Davy wrote to John King that his last lecture had attendance of nearly 500 people. \"There was Respiration, Nitrous Oxide, and unbounded Applause. Amen!\"\nDavy revelled in his public status.\n\nDavy's lectures included spectacular and sometimes dangerous chemical demonstrations along with scientific information, and were presented with considerable showmanship by the young and handsome man. \nDavy also included both poetic and religious commentary in his lectures, emphasizing that God's design was revealed by chemical investigations. Religious commentary was in part an attempt to appeal to women in his audiences. Davy, like many of his enlightenment contemporaries, supported female education and women's involvement in scientific pursuits, even proposing that women be admitted to evening events at the Royal Society.\nDavy acquired a large female following around London. In a satirical cartoon by Gillray, nearly half of the attendees pictured are female. His support of women caused Davy to be subjected to considerable gossip and innuendo, and to be criticized as unmanly.\n\nWhen Davy's lecture series on Galvanism ended, he progressed to a new series on Agricultural Chemistry, and his popularity continued to skyrocket. By June 1802, after just over a year at the Institution and at the age of 23, Davy was nominated to full lecturer at the Royal Institution of Great Britain. Garnett quietly resigned, citing health reasons.\n\nIn November 1804 Davy became a Fellow of the Royal Society, over which he would later preside. He was one of the founding members of the Geological Society in 1807 and was elected a foreign member of the Royal Swedish Academy of Sciences in 1810 and a Foreign Honorary Member of the American Academy of Arts and Sciences in 1822.\n\nDavy was a pioneer in the field of electrolysis using the voltaic pile to split common compounds and thus prepare many new elements. He went on to electrolyse molten salts and discovered several new metals, including sodium and potassium, highly reactive elements known as the alkali metals. Davy discovered potassium in 1807, deriving it from caustic potash (KOH). Before the 19th century, no distinction had been made between potassium and sodium. Potassium was the first metal that was isolated by electrolysis. Davy isolated sodium in the same year by passing an electric current through molten sodium hydroxide.\n\nDuring the first half of 1808, Davy conducted a series of further electrolysis experiments on alkaline earths including lime, magnesia, strontites and barytes. At the beginning of June, Davy received a letter from the Swedish chemist Berzelius claiming that he, in conjunction with Dr. Pontin, had successfully obtained amalgams of calcium and barium by electrolysing lime and barytes using a mercury cathode. Davy managed to successfully repeat these experiments almost immediately and expanded Berzelius' method to strontites and magnesia. He noted that while these amalgams oxidated in only a few minutes when exposed to air they could be preserved for lengthy periods of time when submerged in naphtha before becoming covered with a white crust.\nOn 30 June 1808 Davy reported to the Royal Society that he had successfully isolated four new metals which he named barium, calcium, strontium and magnium (later changed to magnesium) which were subsequently published in the \"Philosophical Transactions\". Although Davy conceded magnium was an \"undoubtedly objectionable\" name he argued the more appropriate name magnesium was already being applied to metallic manganese and wished to avoid creating an equivocal term.\nThe observations gathered from these experiments also led to Davy isolating boron in 1809.\n\nChlorine was discovered in 1774 by Swedish chemist Carl Wilhelm Scheele, who called it \"dephlogisticated marine acid\" (see phlogiston theory) and mistakenly thought it contained oxygen. Davy showed that the acid of Scheele's substance, called at the time oxymuriatic acid, contained no oxygen. This discovery overturned Lavoisier's definition of acids as compounds of oxygen. In 1810, chlorine was given its current name by Humphry Davy, who insisted that chlorine was in fact an element. The name chlorine, chosen by Davy for \"one of [the substance's] obvious and characteristic properties - its colour\", comes from the Greek χλωρος (chlōros), meaning green-yellow.\n\nDavy seriously injured himself in a laboratory accident with nitrogen trichloride. French chemist Pierre Louis Dulong had first prepared this compound in 1811, and had lost two fingers and an eye in two separate explosions with it. In a letter to John Children, on 16 November 1812, Davy wrote: \"It must be used with great caution. It is not safe to experiment upon a globule larger than a pin's head. I have been severely wounded by a piece scarcely bigger. My sight, however, I am informed, will not be injured\". Davy's accident induced him to hire Michael Faraday as a co-worker, particularly for assistance with handwriting and record keeping. He had recovered from his injuries by April 1813.\n\nIn 1812, Davy was knighted and gave up his lecturing position at the Royal Institution. He was given the title of Honorary Professor of Chemistry. He gave a farewell lecture to the Institution, and married a wealthy widow, Jane Apreece. (While Davy was generally acknowledged as being faithful to his wife, their relationship was stormy, and in later years he travelled to continental Europe alone.)\n\nDavy then published his \"Elements of Chemical Philosophy, part 1, volume 1\", though other parts of this title were never completed. He made notes for a second edition, but it was never required. \nIn October 1813, he and his wife, accompanied by Michael Faraday as his scientific assistant (also treated as a valet), travelled to France to collect the second edition of the \"prix du Galvanisme,\" a medal that Napoleon Bonaparte had awarded Davy for his electro-chemical work. Faraday noted that 'Tis indeed a strange venture at this time, to trust ourselves in a foreign and hostile country, where so little regard is had to protestations of honour, that the slightest suspicion would be sufficient to separate us for ever from England, and perhaps from life'. Davy's party sailed from Plymouth to Morlaix by cartel, where they were searched.\n\nUpon reaching Paris, Davy was a guest of honour at a meeting of the First Class of the Institut de France and met with André-Marie Ampère and other French chemists.\n\nWhile in Paris, Davy attended lectures at the Ecole Polytechnique, including those by Joseph Louis Gay-Lussac on a mysterious substance isolated by Bernard Courtois. Davy wrote a paper for the Royal Society on the element, which is now called iodine. This led to a dispute between Davy and Gay-Lussac on who had the priority on the research.\n\nDavy's party did not meet Napoleon in person, but they did visit the Empress Joséphine de Beauharnais at the Château de Malmaison. The party left Paris in December 1813, travelling south to Italy. They sojourned in Florence, where using the burning glass of the Grand Duke of Tuscany in a series of experiments conducted with Faraday's assistance, Davy succeeded in using the sun's rays to ignite diamond, proving it is composed of pure carbon.\n\nDavy's party continued to Rome, where he undertook experiments on iodine and chlorine and on the colours used in ancient paintings. This was the first chemical research on the pigments used by artists.\n\nHe also visited Naples and Mount Vesuvius, where he collected samples of crystals. By June 1814, they were in Milan, where they met Alessandro Volta, and then continued north to Geneva. They returned to Italy via Munich and Innsbruck, and when their plans to travel to Greece and Istanbul were abandoned after Napoleon's escape from Elba, they returned to England.\n\nAfter the Battle of Waterloo, Davy wrote to Lord Liverpool urging that the French be treated with severity:\n\nAfter his return to England in 1815, Davy began experimenting with lamps that could be used safely in coal mines. The Revd Dr Robert Gray of Bishopwearmouth in Sunderland, founder of the Society for Preventing Accidents in Coalmines, had written to Davy suggesting that he might use his 'extensive stores of chemical knowledge' to address the issue of mining explosions caused by firedamp, or methane mixed with oxygen, which was often ignited by the open flames of the lamps then used by miners. Incidents such as the Felling mine disaster of 1812 near Newcastle, in which 92 men were killed, not only caused great loss of life among miners but also meant that their widows and children had to be supported by the public purse. The Revd Gray and a fellow clergyman also working in a north-east mining area, the Revd John Hodgson of Jarrow, were keen that action should be taken to improve underground lighting and especially the lamps used by miners.\n\nDavy conceived of using an iron gauze to enclose a lamp's flame, and so prevent the methane burning inside the lamp from passing out to the general atmosphere. Although the idea of the safety lamp had already been demonstrated by William Reid Clanny and by the then unknown (but later very famous) engineer George Stephenson, Davy's use of wire gauze to prevent the spread of flame was used by many other inventors in their later designs. George Stephenson's lamp was very popular in the north-east coalfields, and used the same principle of preventing the flame reaching the general atmosphere, but by different means. Unfortunately, although the new design of gauze lamp initially did seem to offer protection, it gave much less light, and quickly deteriorated in the wet conditions of most pits. Rusting of the gauze quickly made the lamp unsafe, and the number of deaths from firedamp explosions rose yet further.\n\nThere was some discussion as to whether Davy had discovered the principles behind his lamp without the help of the work of Smithson Tennant, but it was generally agreed that the work of both men had been independent. Davy refused to patent the lamp, and its invention led to his being awarded the Rumford medal in 1816.\n\nIn 1815 Davy suggested that acids were substances that contained replaceable hydrogen ions;– hydrogen that could be partly or totally replaced by reactive metals which are placed above hydrogen in the reactivity series. When acids reacted with metals they formed salts and hydrogen gas. Bases were substances that reacted with acids to form salts and water. These definitions worked well for most of the nineteenth century.\n\nHumphry Davy experimented on fragments of the Herculaneum papyri before his departure to Naples in 1818. His early experiments showed hope of success. In his report to the Royal Society Davy writes that: \n'When a fragment of a brown MS. in which the layers were strongly adhered, was placed in an atmosphere of chlorine, there was an immediate action, the papyrus smoked and became yellow, and the letters appeared much more distinct; and by the application of heat the layers separated from each other, giving fumes of muriatic acid.'\n\nThe success of the early trials prompted Davy to travel to Naples to conduct further research on the Herculaneum papyri. Accompanied by his wife, they set off on 26 May 1818 to stay in Flanders where Davy was invited to by the coal miners. They then traveled to Carniola (now Slovenia) which proved to become 'his favourite Alpine retreat' before finally arriving in Italy. In Italy, they befriended Lord Byron in Rome and then went on to travel to Naples.\n\nInitial experiments were again promising and his work resulted in 'partially unrolling 23 MSS., from which fragments of writing were obtained' but after returning to Naples on 1 December 1819 from a summer in the Alps, Davy complained that 'the Italians at the museum [were] no longer helpful but obstructive'. Davy decided to renounce further work on the papyri because 'the labour, in itself difficult and unpleasant, been made more so, by the conduct of the persons at the head of this department in the Museum'.\n\nFrom 1761 onwards, copper plating had been fitted to the undersides of Royal Navy ships, to protect the wood from attack by shipworms. However, the copper bottoms were gradually corroded by exposure to the salt water. Between 1820 and 1825, Davy, assisted by Michael Faraday, attempted to protect the copper by electrochemical means. He attached sacrificial pieces of zinc or iron to the copper, which provided cathodic protection to the host metal. It was discovered, however, that protected copper became foul quickly, i.e. pieces of weed and/or marine creatures became attached to the hull, which had a detrimental effect on the handling of the ship. The Navy Board approached Davy in 1822, asking for help. Davy conducted a number of tests in Portsmouth Dockyard, which led to the Navy Board adopting the use of Davy's \"protectors\". By 1824, it had become apparent that fouling of the copper bottoms was still occurring on the majority of protected ships. By the end of 1825, the Admiralty ordered the Navy Board to cease fitting the protectors to sea-going ships, and to remove those that had already been fitted. Davy's scheme was seen as a public failure, despite the fact that, as Frank A. J. L. James comments, \"The somewhat ironical problem ... was not that they were unsuccessful. They did after all preserve the copper as Davy said they would. The problem was that the protectors, on most ships, had a chemical side effect which provided nutrients for weeds, barnacles etc. thus fouling the ships\".\n\nElections took place on St Andrew's Day and Davy was elected on 30 November 1820. Although he was unopposed, other candidates had received initial backing. These candidates embodied the factional difficulties that beset Davy's presidency and which eventually defeated him.\n\nThe Society was in transition from a club for gentlemen interested in natural philosophy, connected with the political and social elite, to an academy representing increasingly specialised sciences. The previous president, Joseph Banks, had held the post for over 40 years and had presided autocratically over what David Philip Miller calls the \"Banksian Learned Empire\", in which natural history was prominent.\n\nBanks had groomed the engineer, author and politician Davies Gilbert to succeed him and preserve the status quo, but Gilbert declined to stand. Fellows who thought royal patronage was important proposed Prince Leopold of Saxe-Coburg (later Leopold I of Belgium), who also withdrew, as did the Whig Edward St Maur, 11th Duke of Somerset. Davy was the outstanding scientist but some fellows did not approve of his popularising work at the Royal Institution.\n\nThe strongest alternative had been William Hyde Wollaston, who was supported by the \"Cambridge Network\" of outstanding mathematicians such as Charles Babbage and John Herschel, who tried to block Davy. They were aware that Davy supported some modernisation, but thought that he would not sufficiently encourage aspiring young mathematicians, astronomers and geologists, who were beginning to form specialist societies. Davy was only 41, and reformers were fearful of another long presidency.\n\nIn his early years Davy was optimistic about reconciling the reformers and the Banksians. In his first speech as president he declared, \"I trust that, with these new societies, we shall always preserve the most amicable relations ... I am sure there is no desire in [the Royal Society] to exert anything like patriarchal authority in relation to these institutions\".\n\nDavy spent much time juggling the factions but, as his reputation declined in the light of failures such as his research into copper-bottomed ships, he lost popularity and authority. This was compounded by a number of political errors. In 1825 his promotion of the new Zoological Society, of which he was a founding fellow, courted the landed gentry and alienated expert zoologists. He offended the mathematicians and reformers by failing to ensure that Babbage received one of the new Royal Medals (a project of his) or the vacant secretaryship of the Society in 1826. In November 1826 the mathematician Edward Ryan recorded that: \"The Society, every member almost ... are in the greatest rage at the President's proceedings and nothing is now talked of but removing him.\"\n\nIn the event he was again re-elected unopposed, but he was now visibly unwell. In January 1827 he set off to Italy for reasons of his health. It did not improve and, as the 1827 election loomed, it was clear that he would not stand again. He was succeeded by Davies Gilbert.\n\nIn January 1819, Davy was awarded a baronetcy. Although Sir Francis Bacon (also later made a peer) and Sir Isaac Newton had already been knighted, this was, at the time, the first such honour ever conferred on a man of science in Britain. This was followed a year later with the Presidency of the Royal Society.\n\nDavy's laboratory assistant, Michael Faraday, went on to enhance Davy's work and would become the more famous and influential scientist. Davy is supposed to have even claimed Faraday as his greatest discovery. Davy later accused Faraday of plagiarism, however, causing Faraday (the first Fullerian Professor of Chemistry) to cease all research in electromagnetism until his mentor's death.\n\nOf a sanguine, somewhat irritable temperament, Davy displayed characteristic enthusiasm and energy in all his pursuits. As is shown by his verses and sometimes by his prose, his mind was highly imaginative; the poet Coleridge declared that if he \"had not been the first chemist, he would have been the first poet of his age\", and Southey said that \"he had all the elements of a poet; he only wanted the art.\" In spite of his ungainly exterior and peculiar manner, his happy gifts of exposition and illustration won him extraordinary popularity as a lecturer, his experiments were ingenious and rapidly performed, and Coleridge went to hear him \"to increase his stock of metaphors.\" The dominating ambition of his life was to achieve fame; occasional petty jealousy did not diminish his concern for the \"cause of humanity\", to use a phrase often employed by him in connection with his invention of the miners' lamp. Careless about etiquette, his frankness sometimes exposed him to annoyances he might have avoided by the exercise of tact.\n\nAccording to one of Davy's biographers, June Z. Fullmer, he was a deist.\nHe spent the last months of his life writing \"Consolations in Travel\", an immensely popular, somewhat freeform compendium of poetry, thoughts on science and philosophy. Published posthumously, the work became a staple of both scientific and family libraries for several decades afterward. Davy spent the winter in Rome, hunting in the Campagna on his fiftieth birthday. But on 20 February 1829 he had another stroke. After spending many months attempting to recuperate, Davy died in a hotel room in Geneva, Switzerland, on 29 May 1829.\n\nHe had wished to be buried where he died, but had also wanted the burial delayed in case he was only comatose. He refused to allow a post-mortem for similar reasons. But the laws of Geneva did not allow any delay and he was given a public funeral on the following Monday, in the Plainpalais Cemetery, outside the city walls.\n\n\n\n\nSee Fullmer's work for a full list of Davy's articles.\n\nHumphry Davy's books are as follows:\nDavy also contributed articles on chemistry to \"Rees's Cyclopædia\", but the topics are not known.\n\nHis collected works were published in 1839–1840:\n\n\n"}
{"id": "7751608", "url": "https://en.wikipedia.org/wiki?curid=7751608", "title": "Inertial wave", "text": "Inertial wave\n\nInertial waves, also known as inertial oscillations, are a type of mechanical wave possible in rotating fluids. Unlike surface gravity waves commonly seen at the beach or in the bathtub, inertial waves flow through the interior of the fluid, not at the surface. Like any other kind of wave, an inertial wave is caused by a restoring force and characterized by its wavelength and frequency. Because the restoring force for inertial waves is the Coriolis force, their wavelengths and frequencies are related in a peculiar way. Inertial waves are transverse. Most commonly they are observed in atmospheres, oceans, lakes, and laboratory experiments. Rossby waves, geostrophic currents, and geostrophic winds are examples of inertial waves. Inertial waves are also likely to exist in the molten core of the rotating Earth.\n\nInertial waves are restored to equilibrium by the Coriolis force, a result of rotation. To be precise, the Coriolis force arises (along with the centrifugal force) in a rotating frame to account for the fact that such a frame is always accelerating. Inertial waves, therefore, cannot exist without rotation. More complicated than tension on a string, the Coriolis force acts at a 90° angle to the direction of motion, and its strength depends on the rotation rate of the fluid. These two properties lead to the peculiar characteristics of inertial waves.\n\nInertial waves are possible only when a fluid is rotating, and exist in the bulk of the fluid, not at its surface. Like light waves, inertial waves are transverse, which means that their vibrations occur perpendicular to the direction of wave travel. One peculiar geometrical characteristic of inertial waves is that their phase velocity, which describes the movement of the \"crests\" and \"troughs\" of the wave, is \"perpendicular\" to their group velocity, which is a measure of the propagation of energy.\n\nWhereas a sound wave or an electromagnetic wave of any frequency is possible, inertial waves can exist only over the range of frequencies from zero to twice the rotation rate of the fluid. Moreover, the frequency of the wave is determined by its direction of travel. Waves traveling perpendicular to the axis of rotation have zero frequency and are sometimes called the geostrophic modes. Waves traveling parallel to the axis have maximum frequency (twice the rotation rate), and waves at intermediate angles have intermediate frequencies. In free space, an inertial wave can exist at \"any\" frequency between 0 and twice the rotation rate. A closed container, however, can impose restrictions on the possible frequencies of inertial waves, as it can for any kind of wave. Inertial waves in a closed container are often called inertial modes. In a sphere, for example, the inertial modes are forced to take on discrete frequencies, leaving gaps where no modes can exist.\n\nAny kind of fluid can support inertial waves: water, oil, liquid metals, air, and other gases. Inertial waves are observed most commonly in planetary atmospheres (Rossby waves, geostrophic winds) and in oceans and lakes (geostrophic currents), where they are responsible for much of the mixing that takes place. Inertial waves affected by the slope of the ocean floor are often called Rossby waves. Inertial waves can be observed in laboratory experiments or in industrial flows where a fluid is rotating. Inertial waves are also likely to exist in the liquid outer core of the Earth, and at least one group has claimed evidence of them. Similarly, inertial waves are likely in rotating astronomical flows like accretion disks, planetary rings, and galaxies.\n\nFluid flow is governed by the Navier-Stokes equation for momentum. The flow velocity formula_1 of a fluid with viscosity formula_2 under pressure formula_3 and rotating at rate formula_4 changes over time formula_5 according to\n\nThe first term on the right accounts for pressure, the second accounts for viscous diffusion and the third (last) term on the right side of the momentum equation (above) is the Coriolis term.\n\nTo be precise, formula_1 is the flow velocity as observed in the rotating frame of reference. Since a rotating frame of reference is accelerating (i.e. non-inertial frame), two additional (pseudo) forces (as mentioned above) emerge as a result of this coordinate transformation: the centrifugal force and the Coriolis force. In the equation above, the centrifugal force is included as a part of the generalized pressure formula_3, that is, formula_3 is related to the usual pressure formula_10, depending on the distance from the rotation axis formula_11, by\n\nIn the case where the rotation rate is large, the Coriolis force and the centrifugal force become large compared to the other terms. Being small in comparison, diffusion and the \"convective derivative\" (second term on the left) can be left out. Taking a curl of both sides and applying a few vector identities, the result is\n\nOne class of solutions to this equation are waves that satisfy two conditions. First, if formula_14 is the wave vector,\n\nthat is, the waves must be transverse, as mentioned above. Second, solutions are required to have a frequency formula_16 that satisfies the dispersion relation\n\nwhere formula_18 is the angle between the axis of rotation and the direction of the wave. These particular solutions are known as inertial waves.\n\nThe dispersion relation looks much like the Coriolis term in the momentum equation—notice the rotation rate and the factor of two. It immediately implies the range of possible frequencies for inertial waves, as well as the dependence of their frequency on their direction.\n\n"}
{"id": "6756784", "url": "https://en.wikipedia.org/wiki?curid=6756784", "title": "Kennedy Grove Regional Recreation Area", "text": "Kennedy Grove Regional Recreation Area\n\nKennedy Grove Regional Recreation Area,(KGRRA), also known simply as Kennedy Grove, is located in West Contra Costa County, California at the base of San Pablo Dam. The nearest city is El Sobrante, California. Created in 1967, it contains a three-mile hiking trail with an elevation of . The Grove features many large eucalyptus trees, picnic areas, volleyball nets, playgrounds, and horseshoe pits. Bird watching is popular here because hawks are almost always spotted. Some hikers have reported seeing golden and bald eagles around the reservoir. There is no camping allowed. Parking is $5 with an extra $2 fee for a dog. Dogs have to be on the leash around the lawn but they are allowed off the leash in remote parts of the park. The park is open from 8 a.m. to dusk.\n\nBefore this park became a protected area, it was home to wheat fields, the site of Ranchos and railroad stations for a railroad that ran from Oakland to Orinda through Berkeley and Richmond via El Sobrante. It was originally part of the 17,754-acre Rancho San Pablo. Francisco Castro acquired the rancho in 1823, and the grove later became the Clancy Ranch. By 1886 the railroad had scheduled stops from the California and Nevada railroad at Laurel Glen and Frenchman's Curve. The picnic areas around the park are named after some of the former railroad stops. The eucalyptus trees were planted in 1910. This park was named in honor of President John F. Kennedy and opened on October 22, 1967. It is now owned/operated by the East Bay Regional Park District(EBRPD).\nThere are several trails located within the recreation area ranging from very easy to somewhat difficult. All trails lead out from the eucalyptus grove located near the base of the San Pablo Dam, adjacent to the parking area. Several trails will guide visitors through changing landscapes of native Oak chaparrals and fern laden Bay laurel woodlands. A segment of the Bay Area Ridge Trail begins at Kennedy Grove and runs along the western shore of San Pablo Reservoir. Eventually the trail crosses San Pablo Dam Road and then climbs up the San Pablo Ridge. *NOTE* An EBMUD permit is required for this hike.\n\nSeen from the Kennedy Grove area is the San Pablo Reservoir where fishing is popular. The reservoir has trout and catfish and is recognized as the one of the finest fisheries in the East Bay. However a fishing license and EBMUD fishing permit is required. You can see flocks of ducks, shorebirds, geese, and white pelicans from the trails. Sometimes deer, bobcats, foxes and coyotes can be sighted. There are also species like quail, dove, and wild turkeys. Some birds of prey that are known to take the skies above Kennedy Grove are eagles, owls, hawks, and ospreys.\n\nThe area surrounding San Pablo Dam is fairly temperate. The East Bay is warmer than the Peninsula. Summer temperatures tend to vary from 60-100 degrees. Fog is very common. Rainfall occurs mostly during the months of October through March. The temperatures can dip below 32 degrees in the winter.\n\nPopular activities include hiking, day camps, bird watching, walking around the lawn asphalt path and special events such as cross-country meets. The eucalyptus grove is frequently used as a desirable setting for company picnics, family reunions and other group events.\n\nFern Cottage is an indoor/outdoor facility designed for a capacity of 60 guests (seated) or 120 guests {standing). L-shaped, it has a kitchen and two separate rooms, with an enclosed private backyard and two decks.\n\nKennedy Grove's main entrance is off of San Pablo Dam Road in El Sobrante. The park is open year round, starting at 8:00 AM daily. Closing time depends on the month: November - February, 4:30 PM, March, 6:00 PM; April, 7:00 PM; May - August, 8:00 PM; September, 7:00 PM; October, 6:00 PM. Parking fees are charged on weekends and holidays from April 1 to October 31 and are $5.00 per car, $4.00 per trailered vehicle and $25.00 per bus. Visitors may bring dogs, and there is a dog fee of $2.00 each. \n"}
{"id": "51476697", "url": "https://en.wikipedia.org/wiki?curid=51476697", "title": "Kikonge Hydroelectric Power Station", "text": "Kikonge Hydroelectric Power Station\n\nKikonge Hydroelectric Power Station is a proposed hydroelectric dam in Tanzania.\n\nThe power station and the associated dam and water reservoir would be located in the Kikonge area in the Ruvuma Region in south-western Tanzania. This is approximately , by road, north-west of Songea, the regional headquarters. This is about , by road, south-west of Dodoma, Tanzania's capital.\n\nIn August 2016, the government of Tanzania secured partial funding from the African Development Bank for a pre-feasibility study for a dam across River Ruhuhu, with a reservoir of and capable of generating of electricity. As part of the development, a high voltage transmission line, an irrigation scheme, and an agro-business development are also planned. The pre-feasibility study is expected to last 22 months and the power station, if developed, is expected online in 2025.\n\n\n"}
{"id": "476416", "url": "https://en.wikipedia.org/wiki?curid=476416", "title": "Lichtenberg figure", "text": "Lichtenberg figure\n\nLichtenberg figures (German \"Lichtenberg-Figuren\"), or \"Lichtenberg dust figures\", are branching electric discharges that sometimes appear on the surface or in the interior of insulating materials. Lichtenberg figures are often associated with the progressive deterioration of high voltage components and equipment. The study of planar Lichtenberg figures along insulating surfaces and 3D electrical trees within insulating materials often provides engineers with valuable insights for improving the long-term reliability of high voltage equipment. Lichtenberg figures are now known to occur on or within solids, liquids, and gases during electrical breakdown.\n\nLichtenberg figures are named after the German physicist Georg Christoph Lichtenberg, who originally discovered and studied them. When they were first discovered, it was thought that their characteristic shapes might help to reveal the nature of positive and negative electric \"fluids\". In 1777, Lichtenberg built a large electrophorus to generate high voltage static electricity through induction. After discharging a high voltage point to the surface of an insulator, he recorded the resulting radial patterns by sprinkling various powdered materials onto the surface. By then pressing blank sheets of paper onto these patterns, Lichtenberg was able to transfer and record these images, thereby discovering the basic principle of modern xerography.\n\nThis discovery was also the forerunner of the modern day science of plasma physics. Although Lichtenberg only studied two-dimensional (2D) figures, modern high voltage researchers study 2D and 3D figures (electrical trees) on, and within, insulating materials. Lichtenberg figures are now known to be examples of fractals.\n\nTwo-dimensional (2D) Lichtenberg figures can be produced by placing a sharp-pointed needle perpendicular to the surface of a non-conducting plate, such as of resin, ebonite, or glass. The point is positioned very near or contacting the plate. A source of high voltage, such as a Leyden jar (a type of capacitor) or a static electricity generator, is applied to the needle, typically through a spark gap. This creates a sudden, small electrical discharge along the surface of the plate. This deposits stranded areas of charge onto the surface of the plate. These electrified areas are then tested by sprinkling a mixture of powdered flowers of sulfur and red lead (PbO or lead tetroxide) onto the plate.\n\nDuring handling, powdered sulfur tends to acquire a slight negative charge, while red lead tends to acquire a slight positive charge. The negatively electrified sulfur is attracted to the positively electrified areas of the plate, while the positively electrified red lead is attracted to the negatively electrified areas. In addition to the distribution of colors thereby produced, there is also a marked difference in the form of the figure, according to the polarity of the electrical charge that was applied to the plate. If the charge areas were positive, a widely extending patch is seen on the plate, consisting of a dense nucleus, from which branches radiate in all directions. Negatively charged areas are considerably smaller and have a sharp circular or fan-like boundary entirely devoid of branches. Heinrich Rudolf Hertz employed Lichtenberg dust figures in his seminal work proving Maxwell's electromagnetic wave theories.\nIf the plate receives a mixture of positive and negative charges as, for example, from an induction coil, a mixed figure results, consisting of a large red central nucleus, corresponding to the negative charge, surrounded by yellow rays, corresponding to the positive charge. The difference between positive and negative figures seems to depend on the presence of air; for the difference tends to disappear when the experiment is conducted in vacuum. Peter T. Riess (a 19th-century researcher) theorized that the negative electrification of the plate was caused by the friction of the water vapour, etc., driven along the surface by the explosion which accompanies the disruptive discharge at the point. This electrification would favor the spread of a positive, but hinder that of a negative discharge.\n\nIt is now known that electrical charges are transferred to the insulator's surface through small spark discharges that occur along the boundary between the gas and insulator surface. Once transferred to the insulator, these excess charges become temporarily stranded. The shapes of the resulting charge distributions reflect the shape of the spark discharges which, in turn, depend on the high voltage polarity and pressure of the gas. Using a higher applied voltage will generate larger diameter and more branched figures. It is now known that positive Lichtenberg figures have longer, branching structures because long sparks within air can more easily form and propagate from positively charged high voltage terminals. This property has been used to measure the transient voltage polarity and magnitude of lightning surges on electrical power lines.\n\nAnother type of 2D Lichtenberg figure can be created when an insulating surface becomes contaminated with semiconducting material. When a high voltage is applied across the surface, leakage currents may cause localized heating and progressive degradation and charring of the underlying material. Over time, branching, tree-like carbonized patterns are formed upon the surface of the insulator called electrical trees. This degradation process is called \"tracking\". If the conductive paths ultimately bridge the insulating space, the result is catastrophic failure of the insulating material. Some artists purposely apply salt water to the surface of wood or cardboard and then apply a high voltage across the surface to generate complex carbonized 2D Lichtenberg figures on the surface.\n\nThe branching, self-similar patterns observed in Lichtenberg figures exhibit fractal properties. Lichtenberg figures often develop during the dielectric breakdown of solids, liquids, and even gases. Their appearance and growth appear to be related to a process called diffusion-limited aggregation (DLA). A useful macroscopic model that combines an electric field with DLA was developed by Niemeyer, Pietronero, and Weismann in 1984, and is known as the dielectric breakdown model (DBM).\n\nAlthough the electrical breakdown mechanisms of air and PMMA plastic are considerably different, the branching discharges turn out to be related. So, it should not be surprising that the branching forms taken by natural lightning also have fractal characteristics.\n\nLichtenberg figures may also appear on the skin of lightning strike victims. These are reddish, fernlike patterns that may persist for hours or days. They are also a useful indicator for medical examiners when determining the cause of death. Lichtenberg figures appearing on people are sometimes called lightning flowers, and they are thought to be caused by the rupture of capillaries under the skin due to the passage of the lightning current or the shock wave from the lightning discharge as it flashes over the skin.\n\nA lightning strike can also create a large Lichtenberg figure in grass surrounding the point struck. These are sometimes found on golf courses or in grassy meadows. Branching root-shaped \"fulgurite\" mineral deposits may also be created as sand and soil is fused into glassy tubes by the intense heat of the current.\n\nElectrical treeing often occurs in high-voltage equipment prior to causing complete breakdown. Following these Lichtenberg figures within the insulation during post-accident investigation of an insulation failure can be useful in finding the cause of breakdown. An experienced high-voltage engineer can see from the direction and the shape of trees and their branches where the primary cause of the breakdown was situated and possibly find the initial cause. Broken-down transformers, high-voltage cables, bushings and other equipment can usefully be investigated in this manner. The insulation is unrolled (in the case of paper insulation) or sliced in thin slices (in the case of solid insulating materials). The results are then sketched or photographed to create a record of the breakdown process.\n\nModern Lichtenberg figures can also be created within solid insulating materials, such as acrylic (polymethyl methacrylate or PMMA) or glass by injecting them with a beam of high speed electrons from a linear electron beam accelerator (or Linac, a type of particle accelerator). Inside the Linac, electrons are focused and accelerated to form a beam of high speed particles. Electrons emerging from the accelerator have energies up to 25MeV and are moving at an appreciable fraction (95 - 99+ percent) of the speed of light (relativistic velocities).\n\nIf the electron beam is aimed towards a thick acrylic specimen, the electrons easily penetrate the surface of the acrylic, rapidly decelerating as they collide with molecules inside the plastic, finally coming to rest deep inside the specimen. Since acrylic is an excellent electrical insulator, these electrons become temporarily trapped within the specimen, forming a plane of excess negative charge. Under continued irradiation, the amount of trapped charge builds, until the effective voltage inside the specimen reaches millions of volts. Once the electrical stress exceeds the dielectric strength of the plastic, some portions suddenly become conductive in a process called dielectric breakdown.\n\nDuring breakdown, branching tree or fern-like conductive channels rapidly form and propagate through the plastic, allowing the trapped charge to suddenly rush out in a miniature lightning-like flash and bang. Breakdown of a charged specimen may also be manually triggered by poking the plastic with a pointed conductive object to create a point of excessive voltage stress. During the discharge, the powerful electric sparks leave thousands of branching chains of fractures behind - creating a permanent Lichtenberg figure inside the specimen. Although the internal charge within the specimen is negative, the discharge is initiated from the positively charged exterior surfaces of the specimen, so that the resulting discharge creates a positive Lichtenberg figure. These objects are sometimes called electron trees, beam trees, or lightning trees.\n\nAs the electrons rapidly decelerate inside the acrylic, they also generate powerful X-rays. Residual electrons and X-rays darken the acrylic by introducing defects (color centers) in a process called solarization. Solarization initially turns acrylic specimens a lime green color which then changes to an amber color after the specimen has been discharged. The color usually fades over time, and gentle heating, combined with oxygen, accelerates the fading process.\n\nLichtenberg figures can also be produced on wood. The types of wood and grain patterns affect the shape of the Lichtenberg Figure produced.\n\n"}
{"id": "7377445", "url": "https://en.wikipedia.org/wiki?curid=7377445", "title": "List of saturated fatty acids", "text": "List of saturated fatty acids\n\n"}
{"id": "58698681", "url": "https://en.wikipedia.org/wiki?curid=58698681", "title": "Medway Community Forest", "text": "Medway Community Forest\n\nMedway Community Forest Coop Ltd. is a community forest pilot project in southwestern Nova Scotia. Covering 15,000 hectares of land, it is the first community-owned forest on crown land in Canada east of Quebec.\n\nIt borders the Kejimkujik National Park and the Tobeatic Wilderness Area..\n\nThe provincial government bought private lands in southwestern Nova Scotia belonging to Resolute Forest Products in 2012. At the same time, community forestry in Nova Scotia quickly picked up steam after a discussion paper was published by Dalhousie University. In 2013, the government launched two calls for proposals of a community project pilot and Medway Community Forest was accepted. After some negotiations, the agreement was signed in January 2015.\n\nThe community forest commissioned a report in 2017 for the establishment of a carbon offset program in a cap and trade system\n\n"}
{"id": "45113596", "url": "https://en.wikipedia.org/wiki?curid=45113596", "title": "Monsoon (2014 film)", "text": "Monsoon (2014 film)\n\nMonsoon is a 2014 Canadian documentary film by Sturla Gunnarsson about the monsoon weather system in India.\n\nThe film was shot in India in the extra-high-definition 4K format with Red Epic cameras.\n\nThe film was included in the list of \"Canada's Top Ten\" feature films of 2014, selected by a panel of filmmakers and industry professionals organized by TIFF. Subsequently the film finished first in the audience balloting, of the features in \"Canada's Top Ten\".\n\nThe film will reportedly begin its theatrical run in Toronto on February 27, 2015; meanwhile Gunnarsson was quoted as being in discussions with an American distributor, following \"Monsoon\"'s United States premiere at the 2015 Palm Springs International Film Festival.\n\n"}
{"id": "36573870", "url": "https://en.wikipedia.org/wiki?curid=36573870", "title": "Multinet Gas", "text": "Multinet Gas\n\nMultinet Gas is an Australian energy company and one of three Victorian natural gas distribution networks.\n\nMultinet Gas distributes natural gas to more than 690,000 customers throughout Melbourne's inner eastern suburbs and outer Eastern Suburbs, the Yarra Ranges, and South Gippsland. The network comprises 175km of licensed Transmission Pipelines, 9,959km of distribution mains (operating at pressures between 7kPa and 515 kPa), and 258 regulator stations.\n\nThe Multinet Gas area has over 200km of low pressure (7 kpa) gas mains, some of which are cast iron mains that date back to the 1880s. These older cast iron mains are subject to water ingress during wet weather and as such, are the common cause of supply reliability issues. Multinet Gas' mains Replacement Program is aimed at replacing low-pressure gas distribution mains in the network and is targeting to replace all low-pressure mains by 2033. Upgraded low-pressure mains are typically replaced with high-pressure polyethylene gas mains by inserting the new ductile polyethylene pipe into the existing cast iron main. This method minimizes damage to property and offers additional protection to the polyethylene mains.\n\nGas networks were first built in Melbourne by the Metropolitan Gas Company some time before the 1880's. In 1951 the Metropolitan Gas Company was taken over by the government-owned monopoly supplier, the Gas and Fuel Corporation of Victoria (G&FC). G&FC owned the Melbourne gas network area from 1951 until the privatization in 1997. \n\nThe company is owned by the DUET Group, which was purchased in 2017, by Cheung Kong Infrastructure (CKI) for A$7.4 billion. CKI controls other energy networks in Australia, including United Energy, an electricity distributor in Melbourne's eastern and south-eastern suburbs and the Mornington Peninsula; CitiPower in Melbourne; Powercor in western Melbourne and western Victoria; and Envestra, which distributes gas through Victoria, Queensland and South Australia. After the acquisition, CKI controls three out of five electricity distributors and two out of three gas distributors in Victoria. As of 2018, Multinet Gas is operated as a part of Australian Gas Infrastructure Group (AGIG) in conjunction with the other CKI owned Australian gas distribution Networks. \n"}
{"id": "35137148", "url": "https://en.wikipedia.org/wiki?curid=35137148", "title": "Parc Cynog", "text": "Parc Cynog\n\nParc Cynog is a wind farm operated by Nuon Renewables in Wales.\n\nParc Cynog Windfarm was built in 2001. The Windfarm currently consists of 11 turbines.\n\nThere were originally five turbines on site which are Micon M1800-750/48 turbines built in 2001, by 2009, a further six turbines were installed by Enercon Wind Energy, the technology used was Enercon E48.\n\nThe windfarm is owned by Vattenfall.\n"}
{"id": "38487739", "url": "https://en.wikipedia.org/wiki?curid=38487739", "title": "Plug-in electric vehicles in the United Kingdom", "text": "Plug-in electric vehicles in the United Kingdom\n\nThe adoption of plug-in electric vehicles in the United Kingdom is actively supported by the British government through the plug-in car and van grants schemes and other incentives. More than 137,000 light-duty plug-in electric vehicles had been registered in the UK as of December 2017. , the British plug-in fleet was the fourth largest in Europe. The stock of plug-ins includes about 5,100 plug-in commercial vans. These figures include a significant number of registered plug-in electric cars and vans which were not eligible for the grant schemes. The UK ranked in 2016 as the second best-selling European market after Norway, with almost 37,000 plug-in cars registered.\n\nThere was a surge of plug-in car sales in Britain during 2014 and the following years: total registrations were 3,586 in 2013, but 36,907 plug-in electric cars were registered in 2016, 1.37% of total UK new car registrations. Plug-in car sales in March 2017 achieved the best monthly plug-in registration volume on record ever with over 8,000 units, and registrations during the first quarter of 2017 achieved a record 1.47% market share of new car sales during this quarter.\n\nThe Mitsubishi Outlander P-HEV is the all-time top selling plug-in car in the UK with 26,600 units registered through December 2016, accounting for about 50% of all plug-in hybrid sold in the UK since 2010. The Nissan Leaf ranks second and it is also the all-time top selling all-electric car with 15,000 units sold by September 2016. Ranking third is the BMW i3 with 4,457 units, followed by the Renault Zoe with 4,339 units, both, registered at the end of June 2016.\n\nThe Plug-in Car Grant (PICG) programme started on 1 January 2011 and is available across the UK. The programme initially reduced the up-front cost of eligible cars by providing a 25% grant towards the cost of new plug-in cars capped at . The programme was extended in February 2012 to include plug-in vans. Van buyers can receive 20% - up to - off the cost of a plug-in van. As plug-in car sales surged during 2014 and 2015, the PICG was extended until March 2018. The maximum grant was reduced to , and the amount granted varies according to emission levels. The eligible ultra-low emission vehicles (ULEVs) must meet criteria in one of three categories depending on emission levels ( emissions bands between 50 and 75g/km) and zero-emission-capable mileage (minimum of ). Hydrogen fuel cell cars are now eligible for the grant. A price cap is in place for the extension for Category 2 and 3 models with a list price of more than , which are no longer eligible for the grant. , a total of 127,509 eligible cars have been registered since the launch of the Plug-in Car Grant in 2011, and, , the number of claims made through the Plug-in Van Grant scheme totaled 2,938 units since the launch of the programme in 2012. The Plug-In Van Grant scheme was extended in October 2016 to make electric trucks above 3.5 tonnes eligible for grants of up to , the UK had 11,837 public charging points at 4,237 locations, of which 2,173 were rapid charging points at 695 locations.\n\nSpeaking at the G8 summit in 2008, British Prime Minister Gordon Brown announced plans for Britain to be at the forefront of a \"green car revolution\". Mr Brown suggested that by 2020 all new cars sold in Britain could be electric or hybrid vehicles producing less than . In preparation for the introduction of mass-produced electric vehicles to Britain's roads, trials of electric cars took place from 2009, with further trials in cities across the UK from 2010. Local councils were invited to submit bids to become Britain's first \"green cities\". One example is Glasgow, where a Scottish consortium has been awarded more than to run a pilot electric car scheme from 2009 to 2011.\n\nLondon mayor Boris Johnson also announced plans in April 2009 to deliver 25,000 electric car-charging places across the capital by 2015, in order to make London the \"electric car capital of Europe\". His target is to get 100,000 electric vehicles on to London's streets. Mr Johnson has also pledged to convert at least 1,000 Greater London Authority fleet vehicles to electric by 2015. Transport for London also announced that all new taxis must be zero emissions capable by 2018. , there were about 3,000 plug-in electric vehicles in London, 3% of the mayor's goal, up from 1,700 electric cars in January 2009. The city also has only 1,408 charging points in operation, of which, only 57% were used in the first quarter of 2014. , Greater London postcode areas contain 8,000 electric vehicles according to the Driver and Vehicle Licensing Agency (DVLA).\n\nNissan's Sunderland plant — the largest car factory in the UK — was granted a grant from the British government and up to from the European Investment Bank. Production of the Nissan Leaf at the Sunderland plant began in March 2013. The plant has the capacity to produce 60,000 lithium-ion batteries and 50,000 Leafs a year. The UK produced Leaf are sold only in Europe has an improved driving range, lower price and a more European design. The price of the 2013 Leaf produced in Sunderland is lower than the model built in Japan, and Nissan is offering a battery leasing option for the three trims produced at Sunderland, which further reduced the purchase price by .\n\n, the UK government had pledged to support the deployment of plug-in vehicles in the five years between March 2010 and March 2015. However, , only had been spent and an additional of had been committed for projects up to March 2015, of which, were allocated for research and development; on infrastructure such as public charging points; and in consumer purchase incentives (Plug-in Car Grant). , the UK has around 5,000 public charging points, of which, only 200 are quick chargers. By April 2014 the UK was the leader in quick charging deployment in Europe, with 211 CHAdeMO charging stations available across the country.\n\nAs a result of lower than initially expected electric and plug-in hybrid vehicle sales, in January 2014 the UK government launched the \"Go Ultra Low\" national campaign in partnership with five of the largest manufacturers of plug-in electric vehicles, BMW, Nissan, Renault, Toyota and Vauxhall. The campaign has a cost of and its objective is to promote the benefits of electric and plug-in hybrid cars to buyers. The Government classifies any car emitting less than 75g/km of CO as ultra-low emission. The British government also announced its commitment to invest to install more rapid charge-points to make motorway journeys by electric car feasible. According to Nicholas Clegg, Deputy Prime Minister, “Our clear objective is to move the car fleet in this country to ultra low-emission vehicles by 2040 and to put money and policy money behind it.\"\n\nIn July 2014 Baroness Kramer, Minister of State for Transport, announced that all of the government’s fleets will be supplied with funding to introduce electric vehicles. The \"Ultra Low Emission Vehicle Readiness Project\", funded with , is the first step towards making all government vehicles electrically powered. Central government fleets will benefit first, with plans to bring in over 150 plug-in cars and vans. The Government Car Service, which presently has 85 vehicles used by ministers, will be the initial target with electric cars expected to be in operation by the third quarter 2014. A second phase is scheduled next to provide funds for the public sector in general to purchase more electric vehicles. Beneficiary agencies includes the National Health Service, councils and police forces.\n\nIn January 2009, transport secretary Geoff Hoon said the British government would make (~) available for consumer incentives to bring electric cars to market in the UK. The plug-in grant scheme was first announced in January 2009 by the Labour Government. The coalition government, led by David Cameron, took office in May 2010 and confirmed their support of the grant on 28 July 2010. This confirmed that £43 million would be available for the first 15 months of the scheme, with the 2011 Spending Review confirming funding for the programme for the lifetime of the Parliament of around £300 million (~).\n\nTwo subsidy programs were implemented, the Plug-in Car Grant, from January 2011, and the Plug-In Van Grant, from February 2012. Both offer buyers of eligible vehicles a purchase subsidy discounted at the point of purchase. , the number of eligible registered plug-in electric cars that have benefited with the subsidy totaled 127,509 units since the launch of the programme in 2011. , the number of claims made through the Plug-in Van Grant scheme totaled 2,938 units since the launch of the programme in 2012. , there were 1,467 electric cars and vans registered which were not eligible for the Plug-in Grant scheme.\n\nThe Plug-in Car Grant programme started on 1 January 2011 and is available across the UK The programme reduces the up-front cost of eligible cars by providing a 25% grant towards the cost of new plug-in cars capped at (). From 1 April 2015, the purchase price cap was raised to cover up to 35% discount of the vehicle’s recommended retail price, up to the already existing £5,000 limit. This change means electric cars priced under , such as the Renault Zoe, are able to take advantage of most or all of the £5,000 discount. Both private and business fleet buyers are eligible for this grant which is received at the point of purchase.\n\nThe subsidy programme is managed in a similar way to the grant made as part of the 2009 Car Scrappage Scheme, allowing consumers to buy an eligible car discounted at the point of purchase with the subsidy claimed back by the manufacturer afterwards. The government announced in April 2014 that funding for the full grant of up to will remain in place until either 50,000 grants have been issued or 2017, whichever is first. Nevertheless, as forecasts estimated that the scheme would reached its 50,000 limit around November 2015, the government announced in August 2015 that the Plug-in Car Grant should continue until at least February 2016 for all plug-in cars with emissions of 75 g/km of under. The Government also announced that a minimum of (~) has been made available to continue the Plug-in Car Grant.\n\nVehicles eligible for the subsidy must meet the following criteria:\n\nIn February 2015 the government announced that to take account of rapidly developing technology, and the growing range of ultra-low emission vehicles (ULEVs) on the British market, the criteria for the plug-in car grant was updated and from April 2015, eligible ULEVs must meet criteria in one of the following categories depending on emission levels and zero-emission-capable mileage, with a technology neutral approach, which means that hydrogen fuel cell cars are also eligible for the grant:\n\n, the following 31 cars available in the British market are eligible for the grant according to their category:\n\nBMW i3, BYD e6, Citroen C-Zero, Ford Focus Electric, Hyundai Ioniq Electric, Kia Soul EV, Mahindra e2o, Mercedes-Benz B-Class Electric Drive, Nissan e-NV200 5- and 7-seater Combi, Nissan Leaf, Peugeot iOn, Renault Fluence Z.E., Renault Zoe, Smart Fortwo electric drive, Tesla Model S, Toyota Mirai, Volkswagen e-Golf, and Volkswagen e-Up!.\n\nAudi A3 e-tron (MY 2016 only), BMW 225xe, BMW 330e, Kia Optima PHEV, Mercedes-Benz C350 e, Mitsubishi Outlander P-HEV (except GX3h 4Work), Toyota Prius Plug-in Hybrid, Volkswagen Golf GTE, Volkswagen Passat GTE, Volvo V60 Plug-in Hybrid (D5 and D6 Twin Engine), and Volvo XC90 T8 Twin Engine Momentum.\n\nCategory 2 or 3 vehicles with a recommended retail price over £60,000 aren’t eligible for a grant. This includes: BMW i8 (category 2), Mercedes-Benz S500 Plug-in Hybrid (category 3), and Porsche Panamera S E-Hybrid (category 3).\n\nThe Tesla Roadster was not included in the government's list of eligible vehicles for the plug-in electric car grant. Tesla Motors stated that the company applied for the scheme, but did not complete its application.\n\nIn December 2015, the Department for Transport (DfT) announced that Plug-in car grant was extended until the end of March 2018 to encourage more than 100,000 UK motorists to buy cleaner vehicles. A total funding of (~) will be available for the extension. The criteria for the Plug-in Car Grant was updated and the maximum grant drops from (~) to (~). For the extension, the amount of the grant is linked in directly with the Office for Low Emission Vehicles three vehicle categories issued in April 2015. The eligible ultra-low emission vehicles (ULEVs) must meet criteria in one of three categories depending on emission levels ( emissions bands between 50 and 75g/km) and zero-emission-capable mileage with a minimum all-electric range of . Hydrogen fuel cell cars are also eligible for the grant. The updated scheme went into effect on 1 March 2016.\n\nA price cap is in place, with all Category 1 plug-in vehicles eligible for the full grant no matter what their purchase price, while Category 2 and 3 models with a list price of more than (~) are no longer eligible for the grant. Vehicles with a zero-emission range of at least (category 1), including hydrogen fuel cell vehicles, get a full (~), but plug-in hybrids (categories 2 and 3) costing under (~) receive (~). Under the extended scheme, some plug-in hybrid sports car are no longer eligible for the grant, such as the BMW i8 because of its (~) purchase price tag. The grant scheme will come under review when a cumulative total of 40,000 Category 1 claims, and 45,000 Category 2 and 3 combined sales have been made. Both these totals will include cars sold before March 2016.\n\nIn addition to the extension of the Plug-in Grant, the government also announced it will continue the \"Electric Vehicle Homecharge Scheme.\" Starting in March 2016 owners of ultra-low emission vehicles who install a dedicated charge point at their home, covering roughly half the average cost, get (~) towards the cost of installing the charging point, rather than the previous (~) maximum.\n\nThe Plug-In Car Grant was extended to include vans since February 2012. Van buyers can receive 20% - up to (~ ) - off the cost of a plug-in van. To be eligible for the scheme, vans have to meet performance criteria to ensure safety, range, and ultra-low tailpipe emissions. Consumers, both business and private can receive the discount at the point of purchase. The Plug-In Van Grant scheme was extended in October 2016 to make electric trucks above 3.5 tonnes eligible for grants of up to , when businesses switch their large trucks to an electric vehicle. Also in October 2016, the government announced their commitment for an additional to the scheme so that all vans and trucks meeting the eligibility requirements can benefit from the grant scheme. The extension of the Plug-In Van grant means that N2 vans (3.5 – 12 tonnes gross weight) and N3 vans (over 12 tonnes gross weight) are now eligible.\n\nThe eligibility criteria for vans with a gross weight of 3.5 tonnes or less (N1 van) are:\n\nor extra evidence of battery performance to show reasonable performance after 3 years of use\n\n, the number of claims made through the Plug-in Van Grant scheme totaled 2,938 units since the launch of the programme in 2012, up from 1,906 made by the end of December 2015. the following nine vans are eligible for the grant: BD Otomotive eTraffic, BD Otomotiv eDucato, Citroën Berlingo, Mercedes-Benz Vito E-Cell, Mitsubishi Outlander GX3h 4Work, Nissan e-NV200, Peugeot ePartner, Renault Kangoo Z.E., and Smith Electric Edison.\n\nOn 19 November 2009, Andrew Adonis, the Secretary of State for Transport, announced a scheme called \"Plugged-in-Places\", making available £30 million to be shared between three and six cities to investigate further the viability of providing power supply for electric vehicles, and encouraging local government and business to participate and bid for funds.\n\nThe Government is supporting the ‘Plugged-In Places’ programme to install vehicle recharging points across the UK. The scheme offers match-funding to consortia of businesses and public sector partners to support the installation of electric vehicle recharging infrastructure in lead places across the UK. There are eight Plugged-In Places: East of England; Greater Manchester; London; Midlands; Milton Keynes; North East; Northern Ireland; and Scotland. The Government also published an Infrastructure Strategy in June 2011.\n\nAll-electric vehicles (BEVs) and eligible plug-in hybrid electric vehicles (PHEVs) qualify for a 100% discount from the London congestion charge. A plug-in electric drive vehicle qualifies if the vehicle is registered with the Driver and Vehicle Licensing Agency (DVLA) and has a fuel type of 'electric', or alternatively, if the vehicle is a 'plug-in hybrid' and is on the Government's list of PHEVs eligible for the OLEV grant. , approved PHEVs include all extended-range cars such as the BMW i3 REx, and plug-in hybrids that emit 75g/km or less of and that meet the Euro 5 standard for air quality, such as the Audi A3 Sportback e-tron, BMW i8, Mitsubishi Outlander P-HEV (passenger and van variants), Toyota Prius Plug-in Hybrid, and Volkswagen Golf GTE.\n\nThe original Greener Vehicle Discount was substituted by the Ultra Low Emission Discount (ULED) scheme that went into effect on 1 July 2013. The ULED introduced more stringent emission standards that limited the free access to the congestion charge zone to any car or van that emits 75g/km or less of CO and meets the Euro 5 emission standards for air quality. there are no internal combustion-only vehicles that meet this criteria. The measure is designed to limit the growing number of diesel vehicles on London's roads. Mayor Boris Johnson approved the new scheme in April 2013, after taking into account a number of comments received during the 12-week public consultation that took place. About 20,000 owners of vehicles registered for the Greener Vehicle Discount by June 2013 were granted a three-year sunset period (until 24 June 2016) before they have to pay the full congestion charge.\n\nField testing with 100 Smart EDs began in London in 2007. On 30 April 2009, the Electric Car Corporation put on sale the Citroën C1 ev'ie, an adapted Citroën C1 intended for city driving. On that date, it had a list price of £16,850 ($24,989 US).\n\nA demonstration trial with the Mini E took place between December 2009 and March 2011 with 40 Mini E cars leased to private users for a two consecutive six-month field trial periods. In addition, one Mini E was delivered to the Government car pool in Downing Street to be tested by ministers in an urban environment on their official business around London. The UK trial was a partnership between BMW Group UK, Scottish and Southern Energy, the South East England Development Agency (SEEDA), Oxford City Council and Oxfordshire County Council. Data collection and research was conducted by Oxford Brookes University’s Sustainable Vehicle Engineering Centre throughout the UK project. Funding support was provided by the Technology Strategy Board and the Department for Transport (DFT) as part of the () UK-wide program involving trials of 340 ultra-low carbon vehicles from several carmakers. The selected test area is roughly a triangle contained within the M40 motorway between the M25 motorway and Oxford, the A34 south to the M3 motorway, and the M3 back to the M25.\n\nThe 40 Mini E electric cars were kept in use after the trial was completed in March 2011, participating in activities to promote awareness and understanding of electric vehicles. These cars were part of the BMW Group UK’s official vehicle fleet of 4,000 low-emission luxury vehicles deployed for the London 2012 Olympic Games. The fleet also included 160 BMW ActiveE electric cars.\n, the UK had 11,837 public charging points at 4,237 locations, of which 2,173 were rapid charging points at 695 locations. According to UK's National Chargepoint Registry, there are over 25 network operators (charge point owners, branded networks, such as POLAR and charge point controllers, such as Chargemaster) at a national and regional basis. , the regions with most of the infrastructure are London (16%), South East (15.6%), Scotland (15.1%), South West (9.1%), and North East (8.7%).\n\nThe UK also has nine regional operators: Source London, Source East, Source West, ChargePlace Scotland, Energise (for the South-East), Plugged-In Midlands, Greater Manchester EV, ChargerNet (for Bournemouth, Dorset and Poole) and eCar (for Northern Ireland).\n\nMany companies, local and regional authorise also provide charging to employees and members of the public. Purchasers of electric vehicles also receive a subsidy of up to £500 towards the installation of a charger at their home (which covers nearly all purchase and installation costs).\n\nMore than 137,000 light-duty plug-in electric vehicles have been registered in the UK up until December 2017, including about 5,100 plug-in commercial vans. These figures includes a significant number of registered plug-in electric cars and vans which were not eligible for the grant schemes. Before the market launch of highway-capable mass production plug-in electric cars in 2010, a total of 1,096 electric vehicles were registered in the country between 2006 and December 2010. , the UK had the fourth largest European stock of light-duty plug-in vehicles after Norway, the Netherlands and France, and with 36,907 plug-in passenger cars registered in 2016, ranked as the second best selling European plug-in market after Norway.\n\nElectric car sales grew from 138 units in 2010 to 1,082 units during 2011. Before 2011, the G-Wiz quadricycle was top selling EV for several years. During 2012, a total of 2,254 plug-in electric cars were registered in the UK, of which, 1,262 were pure electrics, and sales were led by the Nissan Leaf with 699 units, followed by the Toyota Prius Plug-in Hybrid with 470 units, and the Vauxhall Ampera with 455 units sold in 2012. In addition, 279 Renault Kangoo Z.E. electric vans and 252 Renault Twizy electric quadricycles were sold through September 2012. Vehicles eligible for the Plug-in Car Grant accounted for 0.1% of total new car sales in 2012, with pure electric cars representing only 0.06%.\n\nDuring 2013, a total of 3,586 plug-in electric cars were registered, up 59.0% from 2012. Of these, 2,512 were pure electric cars, up 99.0% from 2012, and 1,072 plug-in hybrids, up 8.1% from 2012. Plug-in car sales represented a 0.16% market share of the 2.26 million new cars sold in the UK in 2013. The top selling plug-in electric car during 2013 was the Nissan Leaf, with 1,812 units sold, and the Prius PHV ended 2013 as the top selling plug-in hybrid with 509 units sold, up 8.5% from 2012.\n\nThe British market experienced a rapid growth of plug-in car sales during 2014, driven by the introduction of new models such as the BMW i3, Tesla Model S, Mitsubishi Outlander P-HEV, Renault Zoe, and Volkswagen e-Up!. The number of plug-in cars available in the market climbed from 9 models in 2011 to 18 in 2013, and to 29 models by the end of 2014. Registrations during 2014 totaled 14,518 plug-in electric cars and consisted of 6,697 pure electrics and 7,821 plug-in hybrids. Total registrations in 2014 were up 305% from 2013, with all-electric cars growing 167% while plug-in hybrid registrations were up 628% from a year earlier. The plug-in electric car segment captured a 0.59% market share of new car sales in 2014, over three times and a half the market share of 2013 (0.16%). In November 2014, with 646 all-electric cars and 1,225 plug-in hybrids registered, the segment's market share passed 1% of monthly new car sales for the first time in the UK. Again in January 2015, the segment's market share was over 1% of new car sales with 1,715 plug-in electric cars registered that month.\n\nNissan Leaf sales in September 2014 achieved a record of 851 units, up from 332 units the same month in 2013, representing not only the best monthly sales ever in the UK, but also the largest volume of Nissan Leafs ever sold in one month in a European country. The previous European record was achieved by Norway in March 2013 with 703 Leafs sold in that month. Sales of recently introduced BMW i3 and i8 models exceeded 1,600 units during 2014. The Outlander P-HEV was among the new models with a significant effect in the market, released in April 2014, it captured a 35.8% market share of total plug-in sales during the first half of 2014. The Mitsubishi plug-in hybrid became the top selling plug-in electric vehicle in July 2014 and captured 43% of all applications to the Plug-in Car Grants scheme that month.\n\nThe Outlander P-HEV ended 2014 as the top selling plug-in electric car in the UK that year with 5,370 units sold. Sales of the Nissan Leaf also experienced significant growth in 2014, with 4,051 units sold, up 124% from the 1,812 units sold in 2013, and ranked as the top selling all-electric car in 2014. , the Leaf continued ranking as the top selling plug-in electric car in the UK ever with cumulative sales of 7,197 units since its introduction in March 2011. Over 24,500 light-duty plug-in electric cars were registered in the country at the end of December 2014.\n\nThe surge in demand for plug-in cars continued during 2015, to the extent that 2014's ultra-low emission vehicle (ULEV) sales figure was passed in June 2015. Plug-in electric car registrations in the UK totaled 28,188 units in 2015, consisting of 9,934 pure electric cars and 18,254 plug-in hybrids. Total registrations in 2015 were up 94.0% from 2014, with all-electric cars growing 48.3% year-on-year, while plug-in hybrid registrations were up 133.0% year-on-year. Since 2011, about 54,000 plug-in electric vehicles have been registered in the UK up until December 2015, including plug-in hybrids and all-electric cars, and about 2,900 commercial vans. This figure includes a significant number of registered plug-in electric cars and vans which were not eligible for the grant schemes.\n\nThe plug-in electric car segment raised its market share of new car sales in 2015 to almost 1.1%, up from 0.59% in 2014. With almost 3,100 plug-in cars sold during December 2015, the plug-in segment reached a record of 1.7% of new car sales in the UK, the highest ever. According to the British Vehicle Rental and Leasing Association (BVRLA), the market share of all new leased cars reached 4% in 2015, while a record 4.7% of all new leased cars registered during the last quarter of 2015 was a plug-in.\n\nSales of the Mitsubishi Outlander P-HEV in the British market reached the 10,000 unit milestone in March 2015, allowing the plug-in hybrid to overtake the Leaf as the all-time top selling plug-in electric vehicle in the UK. Sales of the Nissan Leaf sales passed the 10,000 unit milestone in June 2015. The top selling models in 2015 were the Outlander P-HEV with 11,681 units registered, up 118% from 2014, followed by the Leaf with 5,236 units (up 29%), and the BMW i3 with 2,213 units (up 59%).\n\n, cumulative sales of the Outlander P-HEV, the top selling plug-in car in the UK ever, totaled 17,045 units registered, and cumulative sales of the Nissan Leaf, the top selling all-electric car ever, totaled 12,433 units registered. Combined sales of the Outlander PHEV and the Nissan Leaf represent more than 50% of the British stock of plug-in electric cars sold since 2011.\n\nPlug-in car sales in March 2016 achieved the best monthly plug-in sales volume on record ever, with 7,144 grant eligible cars registered, exceeding the previous high of 6,104 units, recorded in March 2015. The plug-in market share during this month reached 1.37% of total UK new car registrations, continuing the trend for the fifth month running of sales equal of or exceeding the 1.3% market share threshold. The surge in March sales was expected as a result of the changes in the Plug-in Car Grant scheme, which now provides a stronger incentive for pure electrics over plug-in hybrids, as the grant amount available for purchase of both types of powertrain was reduced, but the grant for plug-in hybrids was cut by half.\n\nDuring the first quarter of 2016 Outlander P-HEV sales totaled 3,906 units, representing 52.3% of all plug-in hybrid registered in the UK during the quarter. By early April 2016, two years since launch, there were 21,053 Outlander P-HEVs in the UK's roads, and the plug-in SUV sales represent 36.2% of the 58,186 eligible cars registered since the grant scheme was introduced in January 2011. The sustained demand for plug-in cars over the previous 12 months through March 2016, has allowed the UK to become a leading market in the European Union for electric vehicles, ranking as the second biggest market after the Netherlands in terms of total plug-in car registrations, with 28,715 new units representing 20% of the European Union’s collective plug-in sales.\n\nRegistrations during the first six months of 2016 recorded the highest-volume half-year ever for plug-in electric car registrations. A total of 19,252 plug-in electric cars were registered in the UK between January and June 2016. During the first half of 2016, the Mitsubishi Outlander PHEV was the top selling plug-in car in the UK with 5,738 units registered. The Nissan Leaf remained the top selling pure-electric car with 2,336 registrations.\n\nA total of 36,907 plug-in electric vehicles were registered in 2016, of which, 35,447 cars were eligible for the Plug-in Car Grant. Registrations consisted of 10,264 all-electric cars, up 3.3% from 2015, and 26,643 plug-in hybrids, up 41.9% from the previous year. Sales of plug-in hybrids oversold pure electric cars, with the latter more than doubling sales of battery electric models. The plug-in car segment's market share reached 1.37% of new car sales in 2016. While overall new car registrations year-to-date increased 2.3% from the same period in 2015, total plug-in car registrations in 2016 increased 28.6% from a year earlier. The Outlander P-HEV continued to lead sales of the plug-in electric segment in 2016 with 9,486 units delivered. The Leaf remained as the top selling all-electric car with 4,463 units registered. The other best selling models were the Mercedes-Benz C 350 e (4,934), BMW 330e (3,499), and the BMW i3 (2,450).\n\nBy mid-October 2016, sales of the Outlander P-HEV passed the 25,000 unit mark, accounting for about 50% of all plug-in hybrid sold in the UK since 2010. , the Outlander plug-in hybrid continued ranking as the all-time top selling plug-in electric car in the UK, with 26,600 units sold since its inception. Cumulative sales of the Nissan Leaf, the second all-time best selling plug-in car and top selling all-electric car ever, passed the 15,000 unit mark in September 2016. Ranking third is the BMW i3, with almost 6,000 units sold since its inception in late 2013 through October 2016.\n\nRegistration of plug-in cars totaled 8,087 units in March 2017, surpassing the previous sales record achieved in March 2016 (7,534). In addition to the normal annual sales peak caused by the plate change, consumers rushed to complete purchases to avoid the new vehicle excise duty (VED) rates that came into force from 1 April for petrol-powered vehicles priced more than £40,000, including all plug-in hybrid models. The plug-in electric car segment reached a market share of 1.44% of new car sales in March 2017. Registrations during the first quarter of 2017 totaled 12,071 plug-in cars, consisting of 4,634 all-electric cars and 7,437 plug-in hybrids, achieving a record market share of 1.47% for that quarter.\n\nThe following table presents annual registrations of plug-in electric cars and vans by model between 2010 and 2013, and total registrations (cumulative) by model at the end of December 2014, and at the end of June 2016.\n\nA study by Element Energy commissioned by BP and published in September 2013, concluded that the use of advanced biofuels in the UK, and particularly E20 cellulosic ethanol, is a more cost-effective way of reducing emissions than using plug-in electric vehicles (PEVs) in the timeframe to 2030. The study also found that the use of higher blends of biofuels is complementary to hybrid electric vehicles (HEVs) and plug-in hybrids (PHEVs). Battery electric vehicles (BEVs) can deliver strong CO savings with a decarbonised electric grid, but are expected to have significantly higher costs than internal combustion engine vehicles and hybrid cars to 2030, as the latter are expected to be the most popular models by 2030. According to the study, blending biofuels in fuels is a cheaper way to reduce \nemissions than using BEVs in the timeframe to 2030, as an E20 blend in a HEV can achieve a 10% emission savings compared to an HEV running on E5, for an annual fuel cost premium of £13 compared to an annual cost of £195 for an all-electric car. The study also concluded that advanced biofuels address emissions of both new and existing vehicles, thus reducing emissions earlier than new powertrains and abating the risk of relying solely on longer term deployment of new technology.\n\n\n"}
{"id": "1268823", "url": "https://en.wikipedia.org/wiki?curid=1268823", "title": "Real gas", "text": "Real gas\n\nReal gases are non-hypothetical gases whose molecules occupy space and have interactions; consequently, they adhere to gas laws.\nTo understand the behaviour of real gases, the following must be taken into account:\n\n\nFor most applications, such a detailed analysis is unnecessary, and the ideal gas approximation can be used with reasonable accuracy. On the other hand, real-gas models have to be used near the condensation point of gases, near critical points, at very high pressures, to explain the Joule–Thomson effect and in other less usual cases. The deviation from ideality can be described by the compressibility factor Z.\n\nReal gases are often modeled by taking into account their molar weight and molar volume\n\nor alternatively:\n\nWhere \"p\" is the pressure, \"T\" is the temperature, \"R\" the ideal gas constant, and \"V\" the molar volume. \"a\" and \"b\" are parameters that are determined empirically for each gas, but are sometimes estimated from their critical temperature (\"T\") and critical pressure (\"p\") using these relations:\n\nWith the reduced properties formula_4 the equation can be written in the \"reduced form\":\n\nThe Redlich–Kwong equation is another two-parameter equation that is used to model real gases. It is almost always more accurate than the van der Waals equation, and often more accurate than some equations with more than two parameters. The equation is\n\nor alternatively:\n\nwhere \"a\" and \"b\" two empirical parameters that are not the same parameters as in the van der Waals equation. These parameters can be determined:\n\nUsing formula_9 the equation of state can be written in the \"reduced form\":\n\nThe Berthelot equation (named after D. Berthelot) is very rarely used,\n\nbut the modified version is somewhat more accurate\n\nThis model (named after C. Dieterici) fell out of usage in recent years\n\nwith parameters a, b, and\n\nThe Clausius equation (named after Rudolf Clausius) is a very simple three-parameter equation used to model gases.\n\nor alternatively:\n\nwhere\n\nwhere \"V\" is critical volume.\n\nThe Virial equation derives from a perturbative treatment of statistical mechanics.\n\nor alternatively\n\nwhere \"A\", \"B\", \"C\", \"A\"′, \"B\"′, and \"C\"′ are temperature dependent constants.\n\nPeng–Robinson equation of state (named after D.-Y. Peng and D. B. Robinson) has the interesting property being useful in modeling some liquids as well as real gases.\n\nThe Wohl equation (named after A. Wohl) is formulated in terms of critical values, making it useful when real gas constants are not available, but it cannot be used for high densities, as for example the critical isotherm shows a drastic \"decrease\" of pressure when the volume is contracted beyond the critical volume.\n\nor:\n\nor, alternatively:\n\nwhere\n\nAnd with the reduced properties formula_9 one can write the first equation in the \"reduced form\":\n\nThis equation is based on five experimentally determined constants. It is expressed as\n\nwhere\n\nThis equation is known to be reasonably accurate for densities up to about 0.8 \"ρ\", where \"ρ\" is the density of the substance at its critical point. The constants appearing in the above equation are available in the following table when \"p\" is in kPa, \"v\" is in formula_34, \"T\" is in K and \"R\" = 8.314formula_35\n\nThe BWR equation, sometimes referred to as the BWRS equation,\n\nwhere \"d\" is the molar density and where \"a\", \"b\", \"c\", \"A\", \"B\", \"C\", \"α\", and \"γ\" are empirical constants. Note that the \"γ\" constant is a derivative of constant \"α\" and therefore almost identical to 1.\n\nThe expansion work of the real gas is different than that of the ideal gas by the quantity formula_37.\n\n\n\n"}
{"id": "11593538", "url": "https://en.wikipedia.org/wiki?curid=11593538", "title": "Severe weather", "text": "Severe weather\n\nSevere weather refers to any dangerous meteorological phenomena with the potential to cause damage, serious social disruption, or loss of human life. Types of severe weather phenomena vary, depending on the latitude, altitude, topography, and atmospheric conditions. High winds, hail, excessive precipitation, and wildfires are forms and effects of severe weather, as are thunderstorms, downbursts, tornadoes, waterspouts, tropical cyclones, and extratropical cyclones. Regional and seasonal severe weather phenomena include blizzards (snowstorms), ice storms, and duststorms.\n\nMeteorologists generally define severe weather as any aspect of the weather that poses risks to life, property or requires the intervention of authorities. A narrower definition of \"severe weather\" is any weather phenomena relating to severe thunderstorms.\n\nAccording to the World Meteorological Organization (WMO), severe weather can be categorized into two groups: general severe weather and localized severe weather. Nor'easters, European wind storms, and the phenomena that accompany them form over wide geographic areas. These occurrences are classified as \"general severe weather\". Downbursts and tornadoes are more localized and therefore have a more limited geographic effect. These forms of weather are classified as \"localized severe weather\". The term \"severe weather\" is technically not the same phenomenon as extreme weather. Extreme weather describes unusual weather events that are at the extremes of the historical distribution for a given area.\n\nOrganized severe weather occurs from the same conditions that generate ordinary thunderstorms: atmospheric moisture, lift (often from thermals), and instability. A wide variety of conditions cause severe weather. Several factors can convert thunderstorms into severe weather. For example, a pool of cold air aloft may aid in the development of large hail from an otherwise innocuous appearing thunderstorm. However, the most severe hail and tornadoes are produced by supercell thunderstorms, and the worst downbursts and derechos (straight-line winds) are produced by bow echoes. Both of these types of storms tend to form in environments high in wind shear.\n\nFloods, hurricanes, tornadoes, and thunderstorms are considered to be the most destructive weather-related [develop models to predict the most frequent and possible locations. This information is used to notify affected areas and save lives.\n\nSevere thunderstorms can be assessed in three different categories. These are \"approaching severe\", \"severe\", and \"significantly severe\".\n\nApproaching severe is defined as hail between diameter or winds between 50 and 58 M.P.H. (50 knots, 80–93 km/h). In the United States, such storms will usually warrant a Significant Weather Alert.\n\nSevere is defined as hail diameter, winds , or an F1 tornado.\n\nSignificant severe is defined as hail in diameter or larger, winds 75 M.P.H. (65 knots, 120 km/h) or more, or a tornado of strength EF2 or stronger. \n\nBoth \"severe\" and \"significant severe\" events warrant a severe thunderstorm warning from the United States National Weather Service (excludes flash floods), the Environment Canada, the Australian Bureau of Meteorology, or the Meteorological Service of New Zealand if the event occurs in those countries. If a tornado is occurring (a tornado has been seen by spotters) or is imminent (Doppler weather radar has observed strong rotation in a storm, indicating an incipient tornado), the severe thunderstorm warning will be superseded by a \"tornado warning\" in the United States and Canada.\n\nA severe weather outbreak is typically considered to be when ten or more tornadoes, some of which will likely be long-tracked and violent, and \"many\" large hail or damaging wind reports occur within one or more consecutive days. Severity is also dependent on the size of the geographic area affected, whether it covers hundreds or thousands of square kilometers.\n\nHigh winds are known to cause damage, depending upon their strength.\nWind speeds as low as may lead to power outages when tree branches fall and disrupt power lines. Some species of trees are more vulnerable to winds. Trees with shallow roots are more prone to uproot, and brittle trees such as eucalyptus, sea hibiscus, and avocado are more prone to branch damage.\n\nWind gusts may cause poorly designed suspension bridges to sway. When wind gusts harmonize with the frequency of the swaying bridge, the bridge may fail as occurred with the Tacoma Narrows Bridge in 1940.\n\nHurricane-force winds, caused by individual thunderstorms, thunderstorm complexes, derechos, tornadoes, extratropical cyclones, or tropical cyclones can destroy mobile homes and structurally damage buildings with foundations. Winds of this strength due to downslope winds off terrain have been known to shatter windows and sandblast paint from cars.\n\nOnce winds exceed within strong tropical cyclones and tornadoes, homes completely collapse, and significant damage is done to larger buildings. Total destruction to man-made structures occurs when winds reach . The Saffir–Simpson scale for cyclones and Enhanced Fujita scale (TORRO scale in Europe) for tornados were developed to help estimate wind speed from the damage they cause.\n\n \n\nA dangerous rotating column of air in contact with both the surface of the earth and the base of a cumulonimbus cloud (thundercloud) or a cumulus cloud, in rare cases. Tornadoes come in many sizes but typically form a visible condensation funnel whose narrowest end reaches the earth and surrounded by a cloud of debris and dust.\n\nTornadoes' wind speeds generally average between and . They are approximately across and travel a few miles (kilometers) before dissipating. Some attain wind speeds in excess of , may stretch more than two miles (3.2 km) across, and maintain contact with the ground for dozens of miles (more than 100 km).\n\nTornadoes, despite being one of the most destructive weather phenomena, are generally short-lived. A long-lived tornado generally lasts no more than an hour, but some have been known to last for 2 hours or longer (for example, the Tri-State Tornado). Due to their relatively short duration, less information is known about the development and formation of tornadoes.\nDownbursts are created within thunderstorms by significantly rain-cooled air, which, upon reaching ground level, spreads out in all directions and produce strong winds. Unlike winds in a tornado, winds in a downburst are not rotational but are directed outwards from the point where they strike land or water. \"Dry downbursts\" are associated with thunderstorms with very little precipitation, while wet downbursts are generated by thunderstorms with large amounts of rainfall. Microbursts are very small downbursts with winds that extend up to 2.5 miles (4 km) from their source, while macrobursts are large-scale downbursts with winds that extend in excess of 2.5 miles (4 km). The heat burst is created by vertical currents on the backside of old outflow boundaries and squall lines where rainfall is lacking. Heat bursts generate significantly higher temperatures due to the lack of rain-cooled air in their formation. Derechos are longer, usually stronger, forms of downburst winds characterized by straight-lined windstorms.\n\nDownbursts create vertical wind shear or microbursts, which are dangerous to aviation. These convective downbursts can produce damaging winds, lasting 5 to 30 minutes, with wind speeds as high as , and cause tornado-like damage on the ground. Downbursts also occur much more frequently than tornadoes, with ten downburst damage reports for every one tornado.\n\nA squall line is an elongated line of severe thunderstorms that can form along or ahead of a cold front. The squall line typically contains heavy precipitation, hail, frequent lightning, strong straight line winds, and possibly tornadoes or waterspouts. Severe weather in the form of strong straight-line winds can be expected in areas where the squall line forms a bow echo, in the farthest portion of the bow. Tornadoes can be found along waves within a line echo wave pattern (LEWP) where mesoscale low-pressure areas are present. Intense bow echoes responsible for widespread, extensive wind damage are called derechos, and move quickly over large territories. A wake low or a mesoscale low-pressure area forms behind the rain shield (a high pressure system under the rain canopy) of a mature squall line and is sometimes associated with a heat burst.\n\nSquall lines often cause severe straight-line wind damage, and most non-tornadic wind damage is caused from squall lines. Although the primary danger from squall lines is straight-line winds, some squall lines also contain weak tornadoes.\n\nVery high winds can be caused by mature tropical cyclones (called \"hurricanes\" in the United States and Canada and \"typhoons\" in eastern Asia). A tropical cyclone's heavy surf created by such winds may cause harm to marine life either close to or upon the surface of the water, such as coral reefs. Coastal regions may receive significant damage from a tropical cyclone while inland regions are relatively safe from the strong winds, due to their rapid dissipation over land. However, severe flooding can occur even far inland because of high amounts of rain from tropical cyclones and their remnants.\n\nWaterspouts are generally defined as tornadoes or non-supercell tornadoes that develop over bodies of water.\n\nWaterspouts typically do not do much damage because they occur over open water, but they are capable of traveling over land. Vegetation, weakly constructed buildings, and other infrastructure may be damaged or destroyed by waterspouts. Waterspouts do not generally last long over terrestrial environments as the friction produced easily dissipates the winds. Strong horizontal winds disturbe the vortex, causing waterspouts to dissipate, While not generally as dangerous as \"classic\" tornadoes, waterspouts can overturn boats, and they can cause severe damage to larger ships.\n\nSevere local windstorms in Europe that develop from winds off the North Atlantic. These windstorms are commonly associated with the destructive extratropical cyclones and their low pressure frontal systems. European windstorms occur mainly in the seasons of autumn and winter.\n\nA synoptic-scale extratropical storm along the East Coast of the United States and Atlantic Canada is called a Nor'easter. They are so named because their winds come from the northeast, especially in the coastal areas of the Northeastern United States and Atlantic Canada. More specifically, it describes a low-pressure area whose center of rotation is just off the East Coast and whose leading winds in the left forward quadrant rotate onto land from the northeast. Nor'easters may cause coastal flooding, coastal erosion, and hurricane-force winds. \n\nAn unusual form of windstorm that is characterized by the existence of large quantities of sand and dust particles carried by the wind. Dust storms frequently develop during periods of droughts, or over arid and semi-arid regions. \n\nDust storms have numerous hazards and are capable of causing deaths. Visibility may be reduced dramatically, so risks of vehicle and aircraft crashes are possible. Additionally, the particulates may reduce oxygen intake by the lungs, potentially resulting in suffocation. Damage can also be inflicted upon the eyes due to abrasion.\n\nDust storms can many issues for agricultural industries as well. Soil erosion is one of the most common hazards and decreases arable lands. Dust and sand particles can cause severe weathering of buildings and rock formations. Nearby bodies of water may be polluted by settling dust and sand, killing aquatic organisms. Decrease in exposure to sunlight can affect plant growth, as well as decrease in infrared radiation may cause decreased temperatures.\n\nThe most common cause of wildfires varies throughout the world. In the United States, Canada, and Northwest China, lightning is the major source of ignition. In other parts of the world, human involvement is a major contributor. For instance, in Mexico, Central America, South America, Africa, Southeast Asia, Fiji, and New Zealand, wildfires can be attributed to human activities such as animal husbandry, agriculture, and land-conversion burning. Human carelessness is a major cause of wildfires in China and in the Mediterranean Basin. In Australia, the source of wildfires can be traced to both lightning strikes and human activities such as machinery sparks and cast-away cigarette butts.\" Wildfires have a rapid \"forward rate of spread\" (FROS) when burning through dense, uninterrupted fuels. They can move as fast as in forests and in grasslands. Wildfires can advance tangential to the main front to form a \"flanking\" front, or burn in the opposite direction of the main front by \"backing\".\n\nWildfires may also spread by \"jumping\" or \"spotting\" as winds and vertical convection columns carry \"firebrands\" (hot wood embers) and other burning materials through the air over roads, rivers, and other barriers that may otherwise act as firebreaks. Torching and fires in tree canopies encourage spotting, and dry ground fuels that surround a wildfire are especially vulnerable to ignition from firebrands. Spotting can create \"spot fires\" as hot embers and firebrands ignite fuels downwind from the fire. In Australian bushfires, spot fires are known to occur as far as from the fire front. Since the mid-1980s, earlier snowmelt and associated warming has also been associated with an increase in length and severity of the wildfire season in the Western United States.\n\nAny form of thunderstorm that produces precipitating hailstones is known as a hailstorm. Hailstorms are generally capable of developing in any geographic area where thunderclouds (cumulonimbus) are present, although they are most frequent in tropical and monsoon regions. The updrafts and downdrafts within cumulonimbus clouds cause water molecules to freeze and solidify, creating hailstones and other forms of solid precipitation. Due to their larger density, these hailstones become heavy enough to overcome the density of the cloud and fall towards the ground. The downdrafts in cumulonimbus clouds can also cause increases in the speed of the falling hailstones. The term \"hailstorm\" is usually used to describe the existence of significant quantities or size of hailstones.\n\nHailstones can cause serious damage, notably to automobiles, aircraft, skylights, glass-roofed structures, livestock, and crops. Rarely, massive hailstones have been known to cause concussions or fatal head trauma. Hailstorms have been the cause of costly and deadly events throughout history. One of the earliest recorded incidents occurred around the 12th century in Wellesbourne, Britain. The largest hailstone in terms of maximum circumference and length ever recorded in the United States fell in 2003 in Aurora, Nebraska, USA. The hailstone had a diameter of 7 inches (18 cm) and a circumference of 18.75 inches (47.6 cm).\n\nHeavy rainfall can lead to a number of hazards, most of which are floods or hazards resulting from floods. Flooding is the inundation of areas that are not normally under water. It is typically divided into three classes: River flooding, which relates to rivers rising outside their normals banks; flash flooding, which is the process where a landscape, often in urban and arid environments, is subjected to rapid floods; and coastal flooding, which can be caused by strong winds from tropical or non-tropical cyclones. Meteorologically, excessive rains occur within a plume of air with high amounts of moisture (also known as an atmospheric river) which is directed around an upper level cold-core low or a tropical cyclone. Flash flooding can frequently occur in slow-moving thunderstorms and are usually caused by the heavy liquid precipitation that accompanies it. Flash floods are most common in dense populated urban environments, where less plants and bodies of water are presented to absorb and contain the extra water. Flash flooding can be hazardous to small infrastructure, such as bridges, and weakly constructed buildings. Plants and crops in agricultural areas can be destroyed and devastated by the force of raging water. Automobiles parked within experiencing areas can also be displaced. Soil erosion can occur as well, exposing risks of landslide phenomena. Like all forms of flooding phenomenon, flash flooding can also spread and produce waterborne and insect-borne diseases cause by microorganisms. Flash flooding can be caused by extensive rainfall released by tropical cyclones of any strength or the sudden thawing effect of ice dams.\n\nSeasonal wind shifts lead to long-lasting wet seasons which produce the bulk of annual precipitation in areas such as Southeast Asia, Australia, Western Africa, eastern South America, Mexico, and the Philippines. Widespread flooding occurs if rainfall is excessive, which can lead to landslides and mudflows in mountainous areas. Floods cause rivers to exceed their capacity with nearby buildings becoming submerged. Flooding may be exacerbated if there are fires during the previous dry season. This may cause soils which are sandy or composed of loam to become hydrophobic and repel water.\n\nGovernment organizations help their residents deal with wet-season floods though floodplain mapping and information on erosion control. Mapping is conducted to help determine areas that may be more prone to flooding. Erosion control instructions are provided through outreach over the telephone or the internet.\n\nFlood waters that occur during monsoon seasons can often host numerous protozoa, bacterial, and viral microorganisms. Mosquitoes and flies will lay their eggs within the contaminated bodies of water. These disease agents may cause infections of foodborne and waterborne diseases. Diseases associated with exposure to flood waters include malaria, cholera, typhoid, hepatitis A, and the common cold. Possible trenchfoot infections may also occur when personnel are exposed for extended periods of time within flooded areas.\n\nA tropical cyclone is a storm system characterized by a low-pressure center and numerous thunderstorms that produce strong winds and flooding rain. A tropical cyclone feeds on heat released when moist air rises, resulting in condensation of water vapor contained in the moist air. Tropical cyclones may produce torrential rain, high waves, and damaging storm surge. Heavy rains produce significant inland flooding. Storm surges may produce extensive coastal flooding up to from the coastline.\nAlthough cyclones take an enormous toll in lives and personal property, they are also important factors in the precipitation regimes of areas they affect. They bring much-needed precipitation to otherwise dry regions. Areas in their path can receive a year's worth of rainfall from a tropical cyclone passage. Tropical cyclones can also relieve drought conditions. They also carry heat and energy away from the tropics and transport it toward temperate latitudes, which makes them an important part of the global atmospheric circulation mechanism. As a result, tropical cyclones help to maintain equilibrium in the Earth's troposphere.\n\nWhen extratropical cyclones deposit heavy, wet snow with a snow-water equivalent (SWE) ratio of between 6:1 and 12:1 and a weight in excess of 10 pounds per square foot (~50 kg/m) piles onto trees or electricity lines, significant damage may occur on a scale usually associated with strong tropical cyclones. An avalanche can occur with a sudden thermal or mechanical impact on snow that has accumulated on a mountain, which causes the snow to rush downhill suddenly. Preceding an avalanche is a phenomenon known as an avalanche wind caused by the approaching avalanche itself, which adds to its destructive potential. Large amounts of snow which accumulate on top of man-made structures can lead to structural failure. During snowmelt, acidic precipitation which previously fell in the snow pack is released and harms marine life.\nLake-effect snow is produced in the winter in the shape of one or more elongated bands. This occurs when cold winds move across long expanses of warmer lake water, providing energy and picking up water vapor which freezes and is deposited on the lee shores. For more information on this effect see the main article.\nConditions within blizzards often include large quantities of blowing snow and strong winds which may significantly reduce visibility. Reduced viability of personnel on foot may result in extended exposure to the blizzard and increase the chance of becoming lost. The strong winds associated with blizzards create wind chill that can result in frostbites and hypothermia. The strong winds present in blizzards are capable of damaging plants and may cause power outages, frozen pipes, and cut off fuel lines.\n\nThe precipitation pattern of Nor'easters is similar to other mature extratropical storms. Nor'easters can cause heavy rain or snow, either within their comma-head precipitation pattern or along their trailing cold or stationary front. Nor'easters can occur at any time of the year but are mostly known for their presence in the winter season. Severe European windstorms are often characterized by heavy precipitation as well.\n\nIce storms are also known as a \"Silver storm\", referring to the color of the freezing precipitation. Ice storms are caused by liquid precipitation which freezes upon cold surfaces and leads to the gradual development of a thickening layer of ice.\nThe accumulations of ice during the storm can be extremely destructive. Trees and vegetation can be destroyed and in turn may bring down power lines, causing the loss of heat and communication lines. Roofs of buildings and automobiles may be severely damaged. Gas pipes can become frozen or even damaged causing gas leaks. Avalanches may develop due to the extra weight of the ice present. Visibility can be reduced dramatically. The aftermath of an ice storm may result in severe flooding due to sudden thawing, with large quantities of displaced water, especially near lakes, rivers, and bodies of water.\n\nAnother form of severe weather is drought, which is a prolonged period of persistently dry weather (that is, absence of precipitation). Although droughts do not develop or progress as quickly as other forms of severe weather, their effects can be just as deadly; in fact, droughts are classified and measured based upon these effects. Droughts have a variety of severe effects; they can cause crops to fail, and they can severely deplete water resources, sometimes interfering with human life. A drought in the 1930s known as the Dust Bowl affected 50 million acres of farmland in the central United States. In economic terms, they can cost many billions of dollars: a drought in the United States in 1988 caused over $40 billion in losses, exceeding the economic totals of Hurricane Andrew, the Great Flood of 1993, and the 1989 Loma Prieta earthquake. In addition to the other severe effects, the dry conditions caused by droughts also significantly increase the risk of wildfires.\n\nAlthough official definitions vary, a heat wave is generally defined as a prolonged period with excessive heat. Although heat waves do not cause as much economic damage as other types of severe weather, they are extremely dangerous to humans and animals: according to the United States National Weather Service, the average total number of heat-related fatalities each year is higher than the combined total fatalities for floods, tornadoes, lightning strikes, and hurricanes. In Australia, heat waves cause more fatalities than any other type of severe weather. As in droughts, plants can also be severely affected by heat waves (which are often accompanied by dry conditions) can cause plants to lose their moisture and die. Heat waves are often more severe when combined with high humidity.\n"}
{"id": "40364759", "url": "https://en.wikipedia.org/wiki?curid=40364759", "title": "Smart Grid Interoperability Panel", "text": "Smart Grid Interoperability Panel\n\nSmart Grid Interoperability Panel or SGIP is an organization that defines requirements for a smarter electric grid by driving interoperability, the use of standard, and collaborating across organizations to address gaps and issue hindering the deployment of smart grid technologies.\n\nSGIP facilitates and runs different working groups to address key topical areas such as the architecture group, the grid management group, the cybersecurity group, the distributed resources and generation group, and the testing and certification group.\n\nSGIP 1.0 was established in December 2009 as a new stakeholder forum to provide technical support to the Commerce Department’s National Institute of Standards and Technology (NIST) with the assistance from Knoxville and EnerNex Corp, under a contact enabled by the American Recovery and Reinvestment Act.\n\nSGIP 2.0 was established as a public-private organization which transitioned into a non-profit public-private partnership organization in 2013.\n\nThe prime functions of SGIP is reported to be-\nSGIP 1.0’s initial focus was to define the industry standards for 20 categories, representing every domain in the power industry and these categories include:\n\nWhen SGIP 1.0 transitioned to SGIP 2.0, LLC, the focus remained for interoperability and addressing gaps in standards and also focused on Distributed Energy Resources, EnergyIoT, Cybersecurity and Orange Button.\n\nIn 2013, SGIP was the recipient of PMI Distinguished Project Award.\n\nIn November 2014, Sharon Allan was appointed as the president and CEO of SGIP.\n\nIn October 2015, SGIP partnered with Industrial Internet Consortium in order to develop technologies and testbeds to accelerate IoT adoption in the energy sector.\n\nIn November 2015, SGIP was the recipient of the Smart Grid Interoperability Standards Cooperative Agreement Program federal funding opportunity from NIST, during which, SGIP was reported to receive $2.1 million during the performance period from January 1, 2016, to December 2018.\n\nIn March 2016, SGIP announced that the Open Field Message Bus (OpenFMB) was ratified as a standard through a NAESB Retail Market Quadrant member vote. OpenFMB is said to be SGIP’s EnergyIoT initiative, bringing the IoT and advanced interoperability to the power grid.\n\nIn April 2016, the organization received $615,426 from US Department of Energy, which was used for reducing non-hardware soft-costs associated with solar projects.\n\nIn February 2017, SGIP merged with Smart Electric Power Alliance(SEPA) under SEPA brand and organizational umbrella.\n\n\n"}
{"id": "7320446", "url": "https://en.wikipedia.org/wiki?curid=7320446", "title": "Soil gradation", "text": "Soil gradation\n\nSoil gradation is a classification of a coarse-grained soil that ranks the soil based on the different particle sizes contained in the soil. Soil gradation is an important aspect of soil mechanics and geotechnical engineering because it is an indicator of other engineering properties such as compressibility, shear strength, and hydraulic conductivity. In a design, the gradation of the in situ or on site soil often controls the design and ground water drainage of the site. A poorly graded soil will have better drainage than a well graded soil.\n\nSoil is graded as either well graded or poorly graded.\n\nSoil gradation is determined by analyzing the results of a sieve analysis\n\nThe process for grading a soil is in accordance with either the Unified Soil Classification System or the AASHTO Soil Classification System. Gradation of a soil is determined by reading the grain size distribution curve produced from the results of laboratory tests on the soil. Gradation of a soil can also be determined by calculating the coefficient of uniformity, C, and the coefficient of curvature, C, of the soil and comparing the calculated values with published gradation limits.\n\nSoil gradation is a classification of the particle size distribution of a soil. Coarse-grained soils, mainly gravels or sands, are graded as either well graded or poorly graded. Poorly graded soils are further divided into uniformly-graded or gap-graded soils. Fine-grained soils, mainly silts and clays, are classified according to their Atterberg limits.\n\nA \"well graded\" soil is a soil that contains particles of a wide range of sizes and has a good representation of all sizes from the No. 4 to No. 200 sieves. A well graded gravel is classified as GW while a well graded sand is classified as SW.\n\nA \"poorly graded\" soil is a soil that does not have a good representation of all sizes of particles from the No. 4 to No. 200 sieve. A poorly graded gravel is classified as GP while a poorly graded sand is classified as SP. Poorly graded soils are more susceptible to soil liquefaction than well graded soils.\n\nA \"gap-graded\" soil is a soil that has an excess or deficiency of certain particle sizes or a soil that has at least one particle size missing. An example of a gap-graded soil is one in which sand of the No. 10 and No. 40 sizes are missing, and all the other sizes are present.\n\nThe process of grading a soil is in accordance with either the Unified Soil Classification System or the AASHTO Soil Classification System. The steps in grading a soil are data collection, calculating coefficients of uniformity and curvature, and grading the soil based on the grading criteria given in the used soil classification system.\n\nSoil gradation is determined by analyzing the results of a sieve analysis or a hydrometer analysis. \n\nIn a sieve analysis, a coarse-grained soil sample is shaken through a series of woven-wire square-mesh sieves. Each sieve has successively smaller openings so particles larger than the size of each sieve are retained on the sieve. The percentage of each soil size is measured by weighing the amount retained on each sieve and comparing the weight to the total weight of the sample. The results of a sieve analysis are plotted as a grain size distribution curve, which is then analyzed to determine the soil gradation of the particular soil.\n\nIn a hydrometer analysis, a fine-grained soil sample is left to settle in a viscous fluid. This method is used based on Stoke's Law which relates terminal velocity of fall of a particle in a viscous fluid to the grain diameter and density of the grain in suspension.Grain diameter is calculated from a known distance and time of the fall of the particle. This is used to classify fine-grained soils.\n\nCalculating the coefficients of uniformity and curvature requires grain diameters. The grain diameter can be found for each percent of the soil passing a particular sieve. This means that if 40% of the sample is retained on the No. 200 sieve then there is 60% passing the No. 200 sieve.\n\nThe \"coefficient of uniformity\", C is a crude shape parameter and is calculated using the following equation:\n\nformula_1\n\nwhere D is the grain diameter at 60% passing, and D is the grain diameter at 10% passing\n\nThe \"coefficient of curvature\", C is a shape parameter and is calculated using the following equation:\n\nformula_2\n\nwhere D is the grain diameter at 60% passing, D is the grain diameter at 30% passing, and D is the grain diameter at 10% passing\n\nOnce the coefficient of uniformity and the coefficient of curvature have been calculated, they must be compared to published gradation criteria.\n\nThe following criteria are in accordance with the Unified Soil Classification System:\n\nFor a gravel to be classified as well graded, the following criteria must be met:\n\nC > 4 & 1 < C < 3\n\nIf both of these criteria are not met, the gravel is classified as poorly graded or GP. If both of these criteria are met, the gravel is classified as well graded or GW.\n\nFor a sand to be classified as well graded, the following criteria must be met:\n\nC ≥ 6 & 1 < C < 3\n\nIf both of these criteria are not met, the sand is classified as poorly graded or SP. If both of these criteria are met, the sand is classified as well graded or SW.\n\nSoil gradation is very important to geotechnical engineering. It is an indicator of other engineering properties such as compressibility, shear strength, and hydraulic conductivity. \n\nIn a design, the gradation of the in situ or on site soil often controls the design and ground water drainage of the site. A poorly graded soil will have better drainage than a well graded soil because there are more void spaces in a poorly graded soil.\n\nWhen a fill material is being selected for a project such as a highway embankment or earthen dam, the soil gradation is considered. A well graded soil is able to be compacted more than a poorly graded soil. These types of projects may also have gradation requirements that must be met before the soil to be used is accepted. \n\nWhen options for ground remediation techniques are being selected, the soil gradation is a controlling factor.\n"}
{"id": "51852423", "url": "https://en.wikipedia.org/wiki?curid=51852423", "title": "Solid acid fuel cell", "text": "Solid acid fuel cell\n\nSolid acid fuel cells (SAFCs) are a class of fuel cells characterized by the use of a solid acid material as the electrolyte. Similar to proton exchange membrane fuel cells and solid oxide fuel cells, they extract electricity from the electrochemical conversion of hydrogen- and oxygen-containing gases, leaving only water as a byproduct. Current SAFC systems use hydrogen gas obtained from a range of different fuels, such as industrial-grade propane and diesel. They operate at mid-range temperatures, from 200 to 300 °C.\n\nSolid acids are chemical intermediates between salts and acids, such as CsHSO. Solid acids of interest for fuel cell applications are those whose chemistry is based on oxyanion groups (SO, PO, SeO, AsO) linked together by hydrogen bonds and charge-balanced by large cation species (Cs, Rb, NH, K).\n\nAt low temperatures, solid acids have an ordered molecular structure like most salts. At warmer temperatures (between 140 and 150 degrees Celsius for CsHSO), some solid acids undergo a phase transition to become highly disordered \"superprotonic\" structures, which increases conductivity by several orders of magnitude. When used in fuel cells, this high conductivity allows for efficiencies of up to 50% on various fuels.\n\nThe first proof-of-concept SAFCs were developed in 2000 using cesium hydrogen sulfate (CsHSO). However, fuel cells using acid sulfates as an electrolyte result in byproducts that severely degrade the fuel cell anode, which leads to diminished power output after only modest usage.\n\nCurrent SAFC systems use cesium dihydrogen phosphate (CsHPO) and have demonstrated lifetimes in the thousands of hours. When undergoing a superprotonic phase transition, CsHPO experiences an increase in conductivity by four orders of magnitude. In 2005, it was shown that CsHPO could stably undergo the superprotonic phase transition in a humid atmosphere at an \"intermediate\" temperature of 250 °C, making it an ideal solid acid electrolyte to use in a fuel cell. A humid environment in a fuel cell is necessary to prevent certain solid acids (such as CsHPO) from dehydration and dissociation into a salt and water vapor.\n\nHydrogen gas is channeled to the anode, where it is split into protons and electrons. Protons travel through the solid acid electrolyte to reach the Cathode, while electrons travel to the cathode through an external circuit, generating electricity. At the cathode, protons and electrons recombine along with oxygen to produce water that is then removed from the system.\n\nAnode: H → 2H + 2e\n\nCathode: ½O + 2H + 2e → HO\n\nOverall: H + ½O → HO\n\nThe operation of SAFCs at mid-range temperatures allows them to utilize materials that would otherwise be damaged at high temperatures, such as standard metal components and flexible polymers. These temperatures also make SAFCs tolerant to impurities in their hydrogen source of fuel, such as carbon monoxide or sulfur components. For example, SAFCs can utilize hydrogen gas extracted from propane, natural gas, diesel, and other hydrocarbons.\n\nIn 2005, SAFCs were fabricated with thin electrolyte membranes of 25 micrometer thickness, resulting in an eightfold increase in peak power densities compared to earlier models. Thin electrolyte membranes are necessary to minimize the voltage lost due to internal resistance within the membrane.\n\nAccording to Suryaprakash et al. 2014, the ideal solid acid fuel cell anode is a \"porous electrolyte nanostructure uniformly covered with a platinum thin film.\" This group used a method called spray drying to fabricate SAFCs, depositing CsHPO solid acid electrolyte nanoparticles and creating porous, 3-dimensional interconnected nanostructures of the solid acid fuel cell electrolyte material CsHPO.\n\nBecause of their moderate temperature requirements and compatibility with several types of fuel, SAFCs can be utilized in remote locations where other types of fuel cells would be impractical. In particular, SAFC systems for remote oil and gas applications have been deployed to electrify wellheads and eliminate the use of pneumatic components, which vent methane and other potent greenhouse gases straight into the atmosphere. A smaller, portable SAFC system is in development for military applications that will run on standard logistic fuels, like marine diesel and JP8.\n\nIn 2014, a toilet that chemically transforms waste into water and fertilizer was developed using a combination of solar power and SAFCs.\n"}
{"id": "25511545", "url": "https://en.wikipedia.org/wiki?curid=25511545", "title": "Teton–Yellowstone tornado", "text": "Teton–Yellowstone tornado\n\nThe Teton–Yellowstone tornado was a rare high-altitude tornado which occurred on July 21, 1987 in the U.S. State of Wyoming. Rated at F4 on the Fujita scale, it was the strongest tornado ever recorded in the state. It was also the only recorded F4 tornado in Wyoming history. The tornado cut through a long, wide swath of the Teton Wilderness and Yellowstone National Park, and even crossed the Continental Divide. The damage occurred at elevations ranging from , making it the highest altitude violent tornado recorded in the United States. No human fatalities or injuries were recorded, but up to 1,000,000 trees were uprooted by the storm. The F4 rating was based on the severity of the tree damage in the worst affected areas. Huge swaths of trees were flattened, and many were stripped of leaves and limbs, with the trunks debarked. Topsoil was picked up and spattered against the bare trunks. Fujita noted that the tree damage was only comparable to that he had seen associated with some of the tornadoes from the 1974 Super Outbreak, as well as the April 1977 Birmingham tornado. Most of the damaged forest later burned in the Yellowstone fires of 1988.\n"}
{"id": "6217058", "url": "https://en.wikipedia.org/wiki?curid=6217058", "title": "Tetrafluorohydrazine", "text": "Tetrafluorohydrazine\n\nTetrafluorohydrazine or dinitrogen tetrafluoride, , is a colourless, reactive inorganic gas. It is a fluorinated analog of hydrazine. It is a highly hazardous chemical that explodes in the presence of organic materials.\n\nTetrafluorohydrazine is manufactured from nitrogen trifluoride using an iron catalyst or iron(II) fluoride. It is used in some chemical syntheses, as a precursor or a catalyst.\n\nTetrafluorohydrazine was considered for use as a high-energy liquid oxidizer in some never-flown rocket fuel formulas in 1959.\n"}
{"id": "23092691", "url": "https://en.wikipedia.org/wiki?curid=23092691", "title": "Textile-reinforced concrete", "text": "Textile-reinforced concrete\n\nTextile-reinforced concrete is a type of reinforced concrete in which the usual steel reinforcing bars are replaced by textile materials. Instead of using a metal cage inside the concrete, this technique uses a fabric cage inside the same.\n\nMaterials with high tensile strengths with negligible elongation properties are reinforced with woven or nonwoven fabrics. The fibres used for making the fabric are of high tenacity like Jute, Glass Fibre, Kevlar, Polypropylene, Polyamides (Nylon) etc. The weaving of the fabric is done either in a coil fashion or in a layer fashion. Molten materials, ceramic clays, plastics or cement concrete are deposited on the base fabric in such a way that the inner fabric is completely wrapped with the concrete or plastic.\n\nAs a result of this sort of structure the resultant concrete becomes flexible from the inner side along with high strength provided by the outer materials. Various nonwoven structures also get priority to form the base structure. Special types of weaving machines are used to form spiral fabrics and layer fabrics are generally nonwoven.\n\nUses of textile reinforced materials, concretes are extensively increasing in modern days in combination with materials science and textile technology. Bridges, Pillars and Road Guards are prepared by kevlar or jute reinforced concretes to withstand vibrations, sudden jerks and torsion (mechanics).\nThe use of reinforced concrete construction in the modern world stems from the extensive\navailability of its ingredients – reinforcing steel as well as concrete. Reinforced concrete fits\nnearly into every form, is extremely versatile and is therefore widely used in the construction\nof buildings, bridges, etc. The major disadvantage of RC is that its steel reinforcement is prone\nto corrosion. Concrete is highly alkaline and forms a passive layer on steel, protecting it\nagainst corrosion. Substances penetrating the concrete from outside (carbonisation) lowers\nthe alkalinity over time (depassivation), making the steel reinforcement lose its protection\nthus resulting in corrosion. This leads to spalling of the concrete, reducing the permanency of\nthe structure as a whole and leading to structural failure in extreme cases.\n\n"}
{"id": "36888097", "url": "https://en.wikipedia.org/wiki?curid=36888097", "title": "The Open Solar Outdoors Test Field", "text": "The Open Solar Outdoors Test Field\n\nThe Open Solar Outdoors Test Field (OSOTF) is a project organized under open source principles, which is a fully grid-connected test system that continuously monitors the output of many solar photovoltaic modules and correlates their performance to a long list of highly accurate meteorological readings.\n\nAs the solar photovoltaic industry grows there is an increased demand for high-quality research in solar systems design and optimization in realistic (and sometimes extreme) outdoor environments such as in Canada. To answer this need, a partnership has formed the Open Solar Outdoors Test Field (OSOTF). The OSOTF was originally developed with a strong partnership between the Queen's Applied Sustainability Research Group run by Joshua M. Pearce at Queen’s University (now at Michigan Tech) and the Sustainable Energy Applied Research Centre (SEARC) at St. Lawrence College headed by Adegboyega Babasola.\nThis collaboration has grown rapidly to include multiple industry partners and the OSOTF has been redesigned to provide critical data and research for the team.\n\nThe OSOTF is a fully grid-connected test system, which continuously monitors the output of over 100 photovoltaic modules and correlates their performance to a long list of highly accurate meteorological readings. The teamwork has resulted in one of the largest systems in the world for this detailed level of analysis, and can provide valuable information on the actual performance of photovoltaic modules in real-world conditions. Unlike many other projects, the OSOTF is organized under open source principles.\n\n\"All data and analysis when completed will be made freely available to the entire photovoltaic community and the general public.\"\n\nThe first project for the OSOTF quantifies the losses due to snowfall of a solar photovoltaic system, generalizes these losses to any location with weather data and recommends best practices for system design in snowy climates. This work was accomplished by creating a synthetic day using empirical data from the OSOTF. This application of the OSOTF has been covered extensively in the media.\n\nThis system has been made possible by the Natural Sciences and Engineering Research Council of Canada and contributions and collaborations from:\n\nThe development of this test facility is a testament to the commitment of the photovoltaic industry to continuous innovation, and the researchers hope that it will be a valuable tool for ensuring the development of a sustainable power system worldwide.\n\nThe SEARC Open Solar Outdoors Test Field consists of two discreet test beds, the largest of which is located on the roof of the new Wind Turbine and Trades building at St.Lawrence College and which has room for 60 commercial PV panels, which are divided between eight angles of 5.10,15,20,30,40,50 and 60 degrees. Live video for the test field is openly available online. Full data access available here.\n\nThe second test field is located on a flat rooftop at St.Lawrence College and consists of two commercial flat roof ballasted systems. Live video of this test field is also available online\n\nIn addition the Queen's Innovation Park Test Site which was developed as part of a preliminary study on the effects of snow on photovoltaic performance funded by Sustainable Energy Technologies. It consists of 16 panels mounted at angles from 0 to 70 degrees, with two each at increments of 10 degrees. By monitoring panel output, solar influx, snow fall and meteorological factors a loss due to snowfall can be determined for a general system at a variety of angles. In addition, thermal panel measurements lead to a better understanding of snow shedding mechanisms. A series of analysis algorithms have been developed which allow for constant data mining to determine factors such as snow coverage ratio using image analysis, performance ratio, and estimated losses/gains due to snowfall. A detailed description of the sensors and measurements used in the study can be seen below.\n\nThe Open Solar Outdoors Test Field is designed to be a state-of-the-art outdoors test facility which makes this site one of the premier PV test beds in North America.The capabilities of this test bed are shown in the following table.\n\n"}
{"id": "50044949", "url": "https://en.wikipedia.org/wiki?curid=50044949", "title": "Twilly Cannon", "text": "Twilly Cannon\n\nHoward Charles Cannon III (September 23, 1955 – March 29, 2016), known as Twilly Cannon, was an American environmental and social justice activist.\n\nCannon was born in Newark, New Jersey to Barbara and Howard Cannon Jr. and grew up in Point Pleasant Beach. He attended Christian Brothers Academy in Lincroft and Evergreen State University. In 1995, he and Mike Roselle founded the Ruckus Society, a nonprofit organization that sponsors skill-sharing and non-violent direct action training, strategy and consultation for activists and organizers from frontline and impacted communities working on social justice, human rights, migrant rights, workers rights and environmental justice.\n\nHe died in Brielle, New Jersey, aged 60.\n"}
{"id": "22267922", "url": "https://en.wikipedia.org/wiki?curid=22267922", "title": "Wiardunek", "text": "Wiardunek\n\nThe Wiardunek (also referred to as wiardunk, czwartak or ferton; , ) was a Mediaeval Central European unit of mass most widely used in Poland and Germany. Wiardunek was also used as a unit of account, and as a such as commodity money.\n\nAs a unit of mass 1 wiardunek (ca. 49 g) was equivalent to 1/4 of grzywna. Two ounces made up one wiardunek, and in turn each ounce consisted of two lots. \n\nAs a unit of currency, the wiardunek was introduced probably around 14th century, first in Bohemia and then in other Central European states. This usage followed the same scheme as for other commodities, that is 1 wiardunek of pure silver was equivalent to 1/4 of grzywna, which in turn was composed of 64 groschen. This usage was true regardless of changes in overall weight of grzywna, which was the basic unit of mass in this system.\n\n"}
{"id": "508291", "url": "https://en.wikipedia.org/wiki?curid=508291", "title": "Wok racing", "text": "Wok racing\n\nWok racing has been developed by the German TV host and entertainer Stefan Raab: Modified woks are used to make timed runs down an Olympic bobsled track. There are competitions for one-person-woksleds and four-person-woksleds, the latter using four woks per sled.\n\nWok racing was inspired by a bet in the German TV show \"Wetten, dass..?\". In November 2003, the \"First official Wok World Championship\" was broadcast from Winterberg. The immediate success led to the second world championship in Innsbruck on March 4, 2004. Participants are mostly b-list celebrities like musical artists, actors, and TV hosts, but there are also known athletes that have ongoing professional careers in winter sports, like three-time Olympic luge champion Georg Hackl and the Jamaican Bobsled Team.\nThe third championship took place again in Winterberg on March 5, 2005. In contrast to the previous championships, there were two runs in which all contesters participated. The times of both runs were added. As a further innovation a qualifying round was created in which the participants had to jump from a trickski-jump with woks to determine the starting order. Further the sport event was professionalized.\n\nThe typical racing woks are the ordinary round-bottomed Chinese pans, usually directly imported from China. The only modifications are that the bottom is reinforced with an epoxy filling and the edges of the wok are coated with polyurethane foam to avoid injuries. Four-person woksleds consist of two pairs of woks, each of them is held together by a rounded frame. The two pairs are connected by a coupling. Due to the rather risky nature of the sport the participants wear heavy protective gear, usually similar to ice hockey equipment. To further reduce friction and the risk of injuries, the athletes wear ladles under their feet.\n\nTo improve performance, the undersides of the woks are often heated with a blowlamp before the race.\n\nPublic wok Racing is only practiced once a year: The \"World Wok Racing Championships\" (German: Wok-WM, , lit. Wok Worldcup) are aired as special edition of Raab's show \"TV total\" on the German television channel ProSieben. The network used to declare these broadcasts as sporting events. Under German law that allowed the network to treat the massive corporate sponsorship of the event as incidental advertising which didn't count against Germany's strict rules regarding time limits for TV commercials. After a Berlin court ruling in 2009, however, the shows have to be labeled as an infomercial, since – unlike a regular sporting event – the races are explicitly staged for the TV broadcast, and there is strong evidence that the profits of the event sponsorship directly benefit the network.\n\n\n\n"}
{"id": "37284349", "url": "https://en.wikipedia.org/wiki?curid=37284349", "title": "World Bank office, Chennai", "text": "World Bank office, Chennai\n\nThe World Bank, Chennai is the extension of the World Bank headquartered in Washington, DC. The World Bank Chennai office offers corporate financial, accounting, administrative and IT services for the Bank's offices in around 150 countries. The Chennai office handles several value-added operations of the bank that were earlier handled only in its Washington, DC office.\n\nThe Chennai office started its business operation as a primary processing work, including payroll processing, in August 2001 with 80 staff. On 15 March 2002, the chief minister of Tamil Nadu, J. Jayalalithaa, inaugurated a new 26,000 sq ft office in Raheja Towers in Anna Salai, where the bank started functioning in a full-fledged manner to process all of the bank's accounting functions and its global payrolls, with about 90 personnel. The same year, the staff strength increased to about 180. In 2003, the bank decided to move the analytical work in bond valuation to the Chennai office, whereby the bank moved the work outside its headquarters in Washington, DC for the first time in its history. The size of the bank's commercial bonds portfolio is estimated at US$100 billion. On 22 September 2006, the bank moved to a leased premises in Taramani, which was inaugurated by the then chief minister of Tamil Nadu, M. Karunanidhi. In 2009, the bank decided to purchase the land it took on lease, in order to set up a permanent back office in Chennai. By 2012, the staff strength grew to 500.\n\nThe staff growth of the Chennai office is as follows:\nThe World Bank Chennai office building is located in Taramani on a 3.5-acre campus off the IT corridor and has 120,000 sq feet built-up area with a capacity to house about 450 staff members. The building is certified as a LEED Silver building. The Taramani office, measuring 128,000 sq ft area, is the largest bank-owned building outside its headquarters in Washington, DC.\n\nMost of the administrative expense and trust fund transactions for the Bank, which range between US$1 billion and US$2 billion a year, are processed in the Chennai office. When the bank commenced its Chennai operations, it was primarily restricted to processing. An analysis component was added later.\n\n\n"}
{"id": "39982426", "url": "https://en.wikipedia.org/wiki?curid=39982426", "title": "ZubaBox", "text": "ZubaBox\n\nA ZubaBox is a solar-powered internet café developed by Computer Aid International. It is constructed from used shipping containers and consists of a Pentium 4 PC (3 GHz+, 3GB RAM, 80GB+ HDD), 11 sets of peripherals (keyboards, mice, monitors), 2 desktop virtualisation cards, a ventilation fan for the server, low-power lights and an advanced power inverter. The solar panels used are poly-crystalline and the cell batteries are of Advanced Glass Mat type. It is named after the Nyanja word \"Zuba\", which means \"Sun\".\n\nThe first ever ZubaBox was deployed in a mission hospital in the village of Macha, Zambia and is used by the Johns Hopkins Malaria Research Institute. It is located 70 km from the nearest paved road and supports a mesh network with a radius of 1.5 km. The ZubaBox in Macha has a rota system which enables students to use it in the mornings, teachers and nurses to use it for professional training in the afternoon and is then open to adults to use thereafter.\n\nSince then, there have been around 10 ZubaBoxes deployed in countries such as Nigeria, Zambia, Zimbabwe and Kenya.\n\n"}
