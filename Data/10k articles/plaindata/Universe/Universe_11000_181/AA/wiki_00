{"id": "2514612", "url": "https://en.wikipedia.org/wiki?curid=2514612", "title": "A Cow at My Table", "text": "A Cow at My Table\n\nA Cow at My Table is a 1998 documentary film examining Western attitudes towards farm animals and meat.\n\nIt covers the conflict between animal rights advocates and the meat industry, and their respective attempts to influence consumers. It was directed, shot, and edited by Jennifer Abbott, who spent five years travelling across Canada, the United States, Australia and New Zealand to interview representatives on all sides. The film intercuts these interviews with images of farm animals and industrial farming operations. It explores what is sometimes popularly called factory farming.\n\nThe filming of \"A Cow at My Table\" drew early criticism from the Canadian meat industry, with both the Ontario Chicken Marketing Board and the Dairy Farmers of Ontario publishing articles warning of Abbott's actions.\n\nMusic for the film was performed by Oh Susanna.\n\n"}
{"id": "23106631", "url": "https://en.wikipedia.org/wiki?curid=23106631", "title": "Alexander Selligue", "text": "Alexander Selligue\n\nAlexander François Selligue (1784-1845) was a French engineer. In 1832, he together with David Blum patented an application of shale oil for direct illumination. In 1838, he patented \"the employment of mineral oils for lighting\". His process of distilling bituminous shales (oil shale) was first described in the \"Journal des Connaissances Usuelles\" in 1834. This process for the oil shale retorting was first used in Autun, France, in 1838. This is considered the start of the modern oil shale industry.\n"}
{"id": "25306212", "url": "https://en.wikipedia.org/wiki?curid=25306212", "title": "AmaZulu Game Reserve", "text": "AmaZulu Game Reserve\n\nAmaZulu Game Reserve, is located in the KwaZulu-Natal, province of South Africa and has an area of about 10.000 hectares.\n\nWildlife species include lion, African bush elephant, cheetah, South-central black rhinoceros, South African giraffe, warthog and hyena, as well as 15 different antelope species, hippopotamus and crocodile.\n\n\n"}
{"id": "1372", "url": "https://en.wikipedia.org/wiki?curid=1372", "title": "Amber", "text": "Amber\n\nAmber is fossilized tree resin, which has been appreciated for its color and natural beauty since Neolithic times. Much valued from antiquity to the present as a gemstone, amber is made into a variety of decorative objects. Amber is used in jewelry. It has also been used as a healing agent in folk medicine.\n\nThere are five classes of amber, defined on the basis of their chemical constituents. Because it originates as a soft, sticky tree resin, amber sometimes contains animal and plant material as inclusions. Amber occurring in coal seams is also called resinite, and the term ambrite is applied to that found specifically within New Zealand coal seams.\n\nThe English word \"amber\" derives from Arabic (cognate with Middle Persian \"ambar\") via Middle Latin \"ambar\" and Middle French \"ambre\". The word was adopted in Middle English in the 14th century as referring to what is now known as \"ambergris\" (\"ambre gris\" or \"grey amber\"), a solid waxy substance derived from the sperm whale. \nIn the Romance languages, the sense of the word had come to be extended to Baltic amber (fossil resin) from as early as the late 13th century. At first called white or yellow amber (\"ambre jaune\"), this meaning was adopted in English by the early 15th century. As the use of ambergris waned, this became the main sense of the word.\n\nThe two substances (\"yellow amber\" and \"grey amber\") conceivably became associated or confused because they both were found washed up on beaches. Ambergris is less dense than water and floats, whereas amber is too dense to float, though less dense than stone. \nThe classical names for amber, Latin \"electrum\" and Ancient Greek (\"ēlektron\"), are connected to a term ἠλέκτωρ (\"ēlektōr\") meaning \"beaming Sun\". According to myth, when Phaëton son of Helios (the Sun) was killed, his mourning sisters became poplar trees, and their tears became \"elektron\", amber. The word \"elektron\" gave rise to the words \"electric, electricity\", and their relatives because of amber's ability to bear a static electricity charge.\n\nTheophrastus discussed amber in the 4th century BC, as did Pytheas (c. 330 BC), whose work \"On the Ocean\" is lost, but was referenced by Pliny the Elder (23 to 79 AD), according to whose \"The Natural History\" (in what is also the earliest known mention of the name \"Germania\"):\nPytheas says that the Gutones, a people of Germany, inhabit the shores of an estuary of the Ocean called Mentonomon, their territory extending a distance of six thousand stadia; that, at one day's sail from this territory, is the Isle of Abalus, upon the shores of which, amber is thrown up by the waves in spring, it being an excretion of the sea in a concrete form; as, also, that the inhabitants use this amber by way of fuel, and sell it to their neighbors, the Teutones.\nEarlier Pliny says that Pytheas refers to a large island - three days' sail from the Scythian coast and called Balcia by Xenophon of Lampsacus (author of a fanciful travel book in Greek) - as \"Basilia\" - a name generally equated with \"Abalus\". Given the presence of amber, the island could have been Heligoland, Zealand, the shores of Bay of Gdansk, the Sambia Peninsula or the Curonian Lagoon, which were historically the richest sources of amber in northern Europe.\nIt is assumed that there were well-established trade routes for amber connecting the Baltic with the Mediterranean (known as the \"Amber Road\"). Pliny states explicitly that the Germans exported amber to Pannonia, from where the Veneti distributed it onwards.\n\nThe ancient Italic peoples of southern Italy used to work amber; the National Archaeological Museum of Siritide (Museo Archeologico Nazionale della Siritide) at Policoro in the province of Matera (Basilicata) displays important surviving examples.\nAmber used in antiquity as at Mycenae and in the prehistory of the Mediterranean comes from deposits of Sicily.\n\nPliny also cites the opinion of Nicias ( 470–413 BC), according to whom amberis a liquid produced by the rays of the sun; and that these rays, at the moment of the sun's setting, striking with the greatest force upon the surface of the soil, leave upon it an unctuous sweat, which is carried off by the tides of the Ocean, and thrown up upon the shores of Germany. Besides the fanciful explanations according to which amber is \"produced by the Sun\", Pliny cites opinions that are well aware of its origin in tree resin, citing the native Latin name of \"succinum\" (\"sūcinum\", from \"sucus\" \"juice\"). He writes:\nAmber is produced from a marrow discharged by trees belonging to the pine genus, like gum from the cherry, and resin from the ordinary pine. It is a liquid at first, which issues forth in considerable quantities, and is gradually hardened [...] Our forefathers, too, were of opinion that it is the juice of a tree, and for this reason gave it the name of \"succinum\" and one great proof that it is the produce of a tree of the pine genus, is the fact that it emits a pine-like smell when rubbed, and that it burns, when ignited, with the odour and appearance of torch-pine wood.\nHe also states that amber is also found in Egypt and in India, and he even refers to the electrostatic properties of amber, by saying that \"in Syria the women make the whorls of their spindles of this substance, and give it the name of \"harpax\" [from ἁρπάζω, \"to drag\"] from the circumstance that it attracts leaves towards it, chaff, and the light fringe of tissues\".\n\nPliny says that the German name of amber was \"glæsum\", \"for which reason the Romans, when Germanicus Caesar commanded the fleet in those parts, gave to one of these islands the name of Glæsaria, which by the barbarians was known as Austeravia\". This is confirmed by the recorded Old High German word \"glas\" and by the Old English word \"glær\" for \"amber\" (compare \"glass\").\nIn Middle Low German, amber was known as \"berne-, barn-, börnstēn\" (with etymological roots related to \"burn\" and to \"stone\"). The Low German term became dominant also in High German by the 18th century, thus modern German \"Bernstein\" besides Dutch \"barnsteen\".\n\nIn the Baltic languages, the Lithuanian term for amber is \"gintaras\" and the Latvian \"dzintars\". These words, and the Slavic \"jantar\" and Hungarian \"gyanta\" ('resin'), are thought to originate from Phoenician \"jainitar\" (\"sea-resin\").\n\nEarly in the nineteenth century, the first reports of amber found in North America came from discoveries in New Jersey along Crosswicks Creek near Trenton, at Camden, and near Woodbury.\n\nAmber is heterogeneous in composition, but consists of several resinous bodies more or less soluble in alcohol, ether and chloroform, associated with an insoluble bituminous substance. Amber is a macromolecule by free radical polymerization of several precursors in the labdane family, e.g. communic acid, cummunol, and biformene. These labdanes are diterpenes (CH) and trienes, equipping the organic skeleton with three alkene groups for polymerization. As amber matures over the years, more polymerization takes place as well as isomerization reactions, crosslinking and cyclization.\n\nHeated above , amber decomposes, yielding an oil of amber, and leaves a black residue which is known as \"amber colophony\", or \"amber pitch\"; when dissolved in oil of turpentine or in linseed oil this forms \"amber varnish\" or \"amber lac\".\n\nMolecular polymerization, resulting from high pressures and temperatures produced by overlying sediment, transforms the resin first into copal. Sustained heat and pressure drives off terpenes and results in the formation of amber.\n\nFor this to happen, the resin must be resistant to decay. Many trees produce resin, but in the majority of cases this deposit is broken down by physical and biological processes. Exposure to sunlight, rain, microorganisms (such as bacteria and fungi), and extreme temperatures tends to disintegrate the resin. For the resin to survive long enough to become amber, it must be resistant to such forces or be produced under conditions that exclude them.\n\nFossil resins from Europe fall into two categories, the famous Baltic ambers and another that resembles the \"Agathis\" group. Fossil resins from the Americas and Africa are closely related to the modern genus \"Hymenaea\", while Baltic ambers are thought to be fossil resins from Sciadopityaceae family plants that used to live in north Europe.\n\nThe abnormal development of resin in living trees (\"succinosis\") can result in the formation of amber. Impurities are quite often present, especially when the resin dropped onto the ground, so the material may be useless except for varnish-making. Such impure amber is called \"firniss\".\n\nSuch inclusion of other substances can cause amber to have an unexpected color. Pyrites may give a bluish color. \"Bony amber\" owes its cloudy opacity to numerous tiny bubbles inside the resin. However, so-called \"black amber\" is really only a kind of jet.\n\nIn darkly clouded and even opaque amber, inclusions can be imaged using high-energy, high-contrast, high-resolution X-rays.\n\nAmber is globally distributed, mainly in rocks of Cretaceous age or younger.\nHistorically, the Samland coast west of Königsberg in Prussia was the world's leading source of amber. The first mentions of amber deposits here date back to the 12th century. About 90% of the world's extractable amber is still located in that area, which became the Kaliningrad Oblast of Russia in 1946.\n\nPieces of amber torn from the seafloor are cast up by the waves, and collected by hand, dredging, or diving. Elsewhere, amber is mined, both in open works and underground galleries. Then nodules of \"blue earth\" have to be removed and an opaque crust must be cleaned off, which can be done in revolving barrels containing sand and water. Erosion removes this crust from sea-worn amber.\nCaribbean amber, especially Dominican blue amber, is mined through bell pitting, which is dangerous due to the risk of tunnel collapse.\n\nThe Vienna amber factories, which use pale amber to manufacture pipes and other smoking tools, turn it on a lathe and polish it with whitening and water or with rotten stone and oil. The final luster is given by friction with flannel.\n\nWhen gradually heated in an oil-bath, amber becomes soft and flexible. Two pieces of amber may be united by smearing the surfaces with linseed oil, heating them, and then pressing them together while hot. Cloudy amber may be clarified in an oil-bath, as the oil fills the numerous pores to which the turbidity is due. \n\nSmall fragments, formerly thrown away or used only for varnish, are now used on a large scale in the formation of \"ambroid\" or \"pressed amber\". The pieces are carefully heated with exclusion of air and then compressed into a uniform mass by intense hydraulic pressure, the softened amber being forced through holes in a metal plate. The product is extensively used for the production of cheap jewelry and articles for smoking. This pressed amber yields brilliant interference colors in polarized light.\n\nAmber has often been imitated by other resins like copal and kauri gum, as well as by celluloid and even glass. Baltic amber is sometimes colored artificially, but also called \"true amber\".\n\nAmber occurs in a range of different colors. As well as the usual yellow-orange-brown that is associated with the color \"amber\", amber itself can range from a whitish color through a pale lemon yellow, to brown and almost black. Other uncommon colors include red amber (sometimes known as \"cherry amber\"), green amber, and even blue amber, which is rare and highly sought after.\n\nYellow amber is a hard fossil resin from evergreen trees, and despite the name it can be translucent, yellow, orange, or brown colored. Known to the Iranians by the Pahlavi compound word kah-ruba (from kah \"straw\" plus rubay \"attract, snatch\", referring to its electrical properties), which entered Arabic as kahraba' or kahraba (which later became the Arabic word for electricity, كهرباء \"kahrabā<nowiki>'</nowiki>\"), it too was called amber in Europe (Old French and Middle English ambre). Found along the southern shore of the Baltic Sea, yellow amber reached the Middle East and western Europe via trade. Its coastal acquisition may have been one reason yellow amber came to be designated by the same term as ambergris. Moreover, like ambergris, the resin could be burned as an incense. The resin's most popular use was, however, for ornamentation—easily cut and polished, it could be transformed into beautiful jewelry.\nMuch of the most highly prized amber is transparent, in contrast to the very common cloudy amber and opaque amber. Opaque amber contains numerous minute bubbles. This kind of amber is known as \"bony amber\".\n\nAlthough all Dominican amber is fluorescent, the rarest Dominican amber is blue amber. It turns blue in natural sunlight and any other partially or wholly ultraviolet light source. In long-wave UV light it has a very strong reflection, almost white. Only about is found per year, which makes it valuable and expensive.\n\nSometimes amber retains the form of drops and stalactites, just as it exuded from the ducts and receptacles of the injured trees. It is thought that, in addition to exuding onto the surface of the tree, amber resin also originally flowed into hollow cavities or cracks within trees, thereby leading to the development of large lumps of amber of irregular form.\n\nAmber can be classified into several forms. Most fundamentally, there are two types of plant resin with the potential for fossilization. Terpenoids, produced by conifers and angiosperms, consist of ring structures formed of isoprene (CH) units. Phenolic resins are today only produced by angiosperms, and tend to serve functional uses. The extinct medullosans produced a third type of resin, which is often found as amber within their veins. The composition of resins is highly variable; each species produces a unique blend of chemicals which can be identified by the use of pyrolysis–gas chromatography–mass spectrometry. The overall chemical and structural composition is used to divide ambers into five classes. There is also a separate classification of amber gemstones, according to the way of production.\n\nThis class is by far the most abundant. It comprises labdatriene carboxylic acids such as communic or ozic acids. It is further split into three sub-classes. Classes Ia and Ib utilize regular labdanoid diterpenes (e.g. communic acid, communol, biformenes), while Ic uses \"enantio\" labdanoids (ozic acid, ozol, \"enantio\" biformenes).\n\nClass Ia includes \"Succinite\" (= 'normal' Baltic amber) and \"Glessite\". They have a communic acid base, and they also include much succinic acid.\n\nBaltic amber yields on dry distillation succinic acid, the proportion varying from about 3% to 8%, and being greatest in the pale opaque or \"bony\" varieties. The aromatic and irritating fumes emitted by burning amber are mainly due to this acid. Baltic amber is distinguished by its yield of succinic acid, hence the name \"succinite\". Succinite has a hardness between 2 and 3, which is rather greater than that of many other fossil resins. Its specific gravity varies from 1.05 to 1.10. It can be distinguished from other ambers via IR spectroscopy due to a specific carbonyl absorption peak. IR spectroscopy can detect the relative age of an amber sample. Succinic acid may not be an original component of amber, but rather a degradation product of abietic acid.\n\nLike class Ia ambers, these are based on communic acid; however, they lack succinic acid.\n\nThis class is mainly based on \"enantio\"-labdatrienonic acids, such as ozic and zanzibaric acids. Its most familiar representative is Dominican amber.\n\nDominican amber differentiates itself from Baltic amber by being mostly transparent and often containing a higher number of fossil inclusions. This has enabled the detailed reconstruction of the ecosystem of a long-vanished tropical forest. Resin from the extinct species \"Hymenaea protera\" is the source of Dominican amber and probably of most amber found in the tropics. It is not \"succinite\" but \"retinite\".\n\nThese ambers are formed from resins with a sesquiterpenoid base, such as cadinene.\n\nThese ambers are polystyrenes.\n\nClass IV is something of a wastebasket; its ambers are not polymerized, but mainly consist of cedrene-based sesquiterpenoids.\n\nClass V resins are considered to be produced by a pine or pine relative. They comprise a mixture of diterpinoid resins and \"n\"-alkyl compounds. Their main variety is \"Highgate copalite\".\n\nThe oldest amber recovered dates to the Upper Carboniferous period (). Its chemical composition makes it difficult to match the amber to its producers – it is most similar to the resins produced by flowering plants; however, there are no flowering plant fossils known from before the Cretaceous, and they were not common until the Late Cretaceous. Amber becomes abundant long after the Carboniferous, in the Early Cretaceous, , when it is found in association with insects. The oldest amber with arthropod inclusions comes from the Levant, from Lebanon and Jordan. This amber, roughly 125–135 million years old, is considered of high scientific value, providing evidence of some of the oldest sampled ecosystems.\n\nIn Lebanon, more than 450 outcrops of Lower Cretaceous amber were discovered by Dany Azar, a Lebanese paleontologist and entomologist. Among these outcrops, 20 have yielded biological inclusions comprising the oldest representatives of several recent families of terrestrial arthropods. Even older, Jurassic amber has been found recently in Lebanon as well. Many remarkable insects and spiders were recently discovered in the amber of Jordan including the oldest zorapterans, clerid beetles, umenocoleid roaches, and achiliid planthoppers.\n\nBaltic amber or succinite (historically documented as Prussian amber) is found as irregular nodules in marine glauconitic sand, known as \"blue earth\", occurring in the Lower Oligocene strata of Sambia in Prussia (in historical sources also referred to as \"Glaesaria\"). After 1945, this territory around Königsberg was turned into Kaliningrad Oblast, Russia, where amber is now systematically mined.\n\nIt appears, however, to have been partly derived from older Eocene deposits and it occurs also as a derivative phase in later formations, such as glacial drift. Relics of an abundant flora occur as inclusions trapped within the amber while the resin was yet fresh, suggesting relations with the flora of Eastern Asia and the southern part of North America. Heinrich Göppert named the common amber-yielding pine of the Baltic forests \"Pinites succiniter\", but as the wood does not seem to differ from that of the existing genus it has been also called \"Pinus succinifera\". It is improbable, however, that the production of amber was limited to a single species; and indeed a large number of conifers belonging to different genera are represented in the amber-flora.\n\nAmber is a unique preservational mode, preserving otherwise unfossilizable parts of organisms; as such it is helpful in the reconstruction of ecosystems as well as organisms; the chemical composition of the resin, however, is of limited utility in reconstructing the phylogenetic affinity of the resin producer.\n\nAmber sometimes contains animals or plant matter that became caught in the resin as it was secreted. Insects, spiders and even their webs, annelids, frogs, crustaceans, bacteria and amoebae, marine microfossils, wood, flowers and fruit, hair, feathers and other small organisms have been recovered in Cretaceous ambers (deposited c. ). The oldest amber to bear fossils (mites) is from the Carnian (Triassic, ) of north-eastern Italy.\n\nThe preservation of prehistoric organisms in amber forms a key plot point in Michael Crichton's 1990 novel \"Jurassic Park\" and the 1993 movie adaptation by Steven Spielberg. In the story, scientists are able to extract the preserved blood of dinosaurs from prehistoric mosquitoes trapped in amber, from which they genetically clone living dinosaurs. Scientifically this is as yet impossible, since no amber with fossilized mosquitoes has ever yielded preserved blood. Amber is, however, conducive to preserving DNA, since it dehydrates and thus stabilizes organisms trapped inside. One projection in 1999 estimated that DNA trapped in amber could last up to 100 million years, far beyond most estimates of around 1 million years in the most ideal conditions, although a later 2013 study was unable to extract DNA from insects trapped in much more recent Holocene copal.\n\nAmber has been used since prehistory (Solutrean) in the manufacture of jewelry and ornaments, and also in folk medicine.\n\nAmber has been used as jewelry since the Stone Age, from 13,000 years ago. Amber ornaments have been found in Mycenaean tombs and elsewhere across Europe. To this day it is used in the manufacture of smoking and glassblowing mouthpieces. Amber's place in culture and tradition lends it a tourism value; Palanga Amber Museum is dedicated to the fossilized resin.\n\nAmber has long been used in folk medicine for its purported healing properties. Amber and extracts were used from the time of Hippocrates in ancient Greece for a wide variety of treatments through the Middle Ages and up until the early twentieth century.\n\nIn ancient China, it was customary to burn amber during large festivities. If amber is heated under the right conditions, oil of amber is produced, and in past times this was combined carefully with nitric acid to create \"artificial musk\" – a resin with a peculiar musky odor. Although when burned, amber does give off a characteristic \"pinewood\" fragrance, modern products, such as perfume, do not normally use actual amber due to the fact that fossilized amber produces very little scent. In perfumery, scents referred to as “amber” are often created and patented\nto emulate the opulent golden warmth of the fossil.\n\nThe modern name for amber is thought to come from the Arabic word, ambar, meaning ambergris. Ambergris is the waxy aromatic substance created in the intestines of sperm whales and was used in making perfumes both in ancient times as well as modern.\n\nThe scent of amber was originally derived from emulating the scent of ambergris and/or the plant resin labdanum, but due to the endangered species status of the sperm whale the scent of amber is now largely derived from labdanum. The term “amber” is loosely used to describe a scent that is warm, musky, rich and honey-like, and also somewhat earthy. It can be synthetically created or derived from natural resins. When derived from natural resins it is most often created out of labdanum. Benzoin is usually part of the recipe. Vanilla and cloves are sometimes used to enhance the aroma.\n\n\"Amber\" perfumes may be created using combinations of labdanum, benzoin resin, copal (itself a type of tree resin used in incense manufacture), vanilla, Dammara resin and/or synthetic materials.\n\nYoung resins, these are used as imitations: \n\nPlastics, these are used as imitations: \n\n\n\n"}
{"id": "6654736", "url": "https://en.wikipedia.org/wiki?curid=6654736", "title": "Anaerobic contact process", "text": "Anaerobic contact process\n\nThe anaerobic contact process is a type of anaerobic digester. Here a set of reactors are created in series, often with recycling. This recycled material is pumped up into the bottom of the first reactor, an upflow reactor. The upflow anaerobic process is a large reactor which allows the waste to flow up from the bottom and separates the waste into 3 zones. At the very top is the biogas zone where the gas is collected. Bacteria digest waste in the lowest portion of the upflow reactor; the bioreactor zone. In between these two stages is the clarifier zone where which exports the stabilised waste.\n\nA diagram of an anaerobic contact process can be found here.\n\n"}
{"id": "52535373", "url": "https://en.wikipedia.org/wiki?curid=52535373", "title": "Avfall Sverige", "text": "Avfall Sverige\n\nAvfall Sverige is the Swedish Waste Management recycling association.\n"}
{"id": "2928212", "url": "https://en.wikipedia.org/wiki?curid=2928212", "title": "Bauschinger effect", "text": "Bauschinger effect\n\nWhile more tensile cold working increases the tensile yield strength, the local initial compressive yield strength after tensile cold working is actually reduced. The greater the tensile cold working, the lower the compressive yield strength.\n\nThe Bauschinger effect is normally associated with conditions where the yield strength of a metal decreases when the direction of strain is changed. It is a general phenomenon found in most polycrystalline metals. The basic mechanism for the Bauschinger effect is related to the dislocation structure in the cold worked metal. As deformation occurs, the dislocations will accumulate at barriers and produce dislocation pile-ups and tangles. Based on the cold work structure, two types of mechanisms are generally used to explain the Bauschinger effect.\n\n\nSevere unidirectional cold working results in accumulation of dislocation at barriers to dislocation movement, When stresses are applied in the reverse direction, the dislocations are now aided by the back stresses that were present at the dislocation barriers previously and also because the back stresses at the dislocation barriers in the back are not likely to be strong compared to the previous case. Hence the dislocations glide easily, resulting in lower yield stress for plastic deformation for reversed direction of loading.\n\nMetal forming operations result in situations exposing the metal workpiece to stresses of reversed sign. The Bauschinger effect contributes to work softening of the workpiece, for example in straightening of drawn bars or rolled sheets, where rollers subject the workpiece to alternate bending stresses, thereby reducing the yield strength and enabling greater cold drawability of the workpiece.\n\n"}
{"id": "30729469", "url": "https://en.wikipedia.org/wiki?curid=30729469", "title": "Bian stones", "text": "Bian stones\n\nBian stones are pointed stones that were historically used in traditional Chinese medicine. They are generally considered to be a precursor to acupuncture, utilising heated pointed stones (instead of acupuncture needles) in the treatment of back and neck pain. The stones are made from a variety of materials found along the coastline of Shandong, China.\n\nBian stone therapy is one of humanity's oldest medical practices. The Bian-stone technique refers to the use of stone-based equipment to perform massaging, heating and other operations. The devices are called bian stone tools. Bian-stone includes both the bian-stone technique and the tool. When used in medical institutions for therapeutic purposes, it is referred to as Bian-stone treatment.\n\nBefore acupuncture and moxibustion appeared, ancient Chinese people selected certain kinds of stone and ground it into a therapeutic tool that featured a sharp tip or an edge. Such shapes allowed the stone to be applied to the human body in different ways. The puncturing and pressing methods eventually evolved into acupuncture, while the heated-stone application evolved into moxibustion. A classic book notes that bian-stone treatment originated in the east of China, but moxibustion came from the North, where people had to warm themselves by fire.\n\nKnown by three names - Needle Stone, Arrow-headed Stone, and Bian Stone - these stones were used in primitive society as a special medicinal tool. Excavations of New Stone Age ruins in Asia recovered multiple Bian-stone needles of varying lengths from multiple locations. The recovered stone needles have different ends for different procedures, including blood-letting, qi (energy) regulation, and incising.\n\nThis technique disappeared during the Han Dynasty, due to the introduction and use of iron. The source of the material for making Bian-stone has been identified as Sibin floating stone. Bian stone appliances have since been devised and developed and therapeutic techniques explored.\n\nResearchers have also investigated historical Chinese documents. Bian-stone is the first technique of the five major ancient medical practices of the “Yellow Emperor” (these five are: Bian-stone, Bian-stone tool, moxibustion, medicine, guided by Rocker).\n\nBian stone has been applied in Traditional Chinese Medicine for various soft tissue injuries, especially, cervical spondylosis, acute or chronic lower back pain, as well as skin disorders, such as abscesses or boils, and regulating qi and blood circulation.\n\nTherapy usually begins with a traditional Chinese massage to open up the body's meridians, followed by a series of Bian stone treatments with pre-heated bian stone. This therapy can be coupled with other traditional Chinese medicine therapy, such as acupuncture, or cupping to achieve the optimal effect on cervical vertebra disease.\n"}
{"id": "34526468", "url": "https://en.wikipedia.org/wiki?curid=34526468", "title": "British Woodworking Federation", "text": "British Woodworking Federation\n\nThe British Woodworking Federation is the trade association for the woodworking and joinery manufacturing industry in the UK. It has just around 600 members drawn from manufacturers, distributors and installers of timber doors (including fire doors), windows, conservatories, staircases, all forms of architectural joinery including interior fit out, as well as suppliers to the industry. \n\nNotes\n"}
{"id": "18952002", "url": "https://en.wikipedia.org/wiki?curid=18952002", "title": "Cereus repandus", "text": "Cereus repandus\n\nCereus repandus (syn. Cereus peruvianus), the Peruvian apple cactus, is a large, erect, thorny columnar cactus found in South America as well as the nearby ABC Islands of the Dutch Caribbean. It is also known as giant club cactus, hedge cactus, cadushi (in Wayuunaiki), and kayush.\n\nWith an often tree-like appearance, its cylindrical gray-green to blue stems can reach in height and 10–20 cm in diameter as a self-supporting plant. However, if supported by a scaffold, \"C. repandus\" has grown to a height of at the SDM College of Dental Sciences at Dharwad, Karnataka, India, technically making this the tallest cactus plant in the world, although no cactus under natural conditions exceeds in height in the case of \"C. stenogonus\". The large, cream-colored, nocturnal flowers remain open for only one night. The fruits, known locally as pitaya, \"olala\" (only in some parts of Bolivia) or Peruvian apple, are thornless and vary in skin colour from violet-red to yellow. The edible flesh is white and contains small, edible, crunchy seeds. The flesh sweetens as the fruit opens out fully.\n\n\"Cereus repandus\" is an unresearched, under-utilized cactus, grown mostly as an ornamental plant. As noted above, it has some local culinary importance. The Wayuu from the La Guajira Peninsula of Colombia and Venezuela also use the inner cane-like wood of the plant in wattle and daub construction.\n\n"}
{"id": "1987293", "url": "https://en.wikipedia.org/wiki?curid=1987293", "title": "Contact angle", "text": "Contact angle\n\nThe contact angle is the angle, conventionally measured through the liquid, where a liquid–vapor interface meets a solid surface. It quantifies the wettability of a solid surface by a liquid via the Young equation. A given system of solid, liquid, and vapor at a given temperature and pressure has a unique equilibrium contact angle. However, in practice a dynamic phenomenon of contact angle hysteresis is often observed, ranging from the advancing (maximal) contact angle to the receding (minimal) contact angle . The equilibrium contact is within those values, and can be calculated from them. The equilibrium contact angle reflects the relative strength of the liquid, solid, and vapor molecular interaction.\n\nThe shape of a liquid–vapor interface is determined by the Young–Laplace equation, with the contact angle playing the role of a boundary condition via the Young equation.\n\nThe theoretical description of contact arises from the consideration of a thermodynamic equilibrium between the three phases: the liquid phase (L), the solid phase (S), and the gas or vapor phase (G) (which could be a mixture of ambient atmosphere and an equilibrium concentration of the liquid vapor). (The \"gaseous\" phase could be replaced by another immiscible liquid phase.) If the solid–vapor interfacial energy is denoted by formula_1, the solid–liquid interfacial energy by formula_2, and the liquid–vapor interfacial energy (i.e. the surface tension) by formula_3, then the equilibrium contact angle formula_4 is determined from these quantities by the Young equation:\n\nThe contact angle can also be related to the work of adhesion via the Young–Dupré equation:\nwhere formula_7 is the solid – liquid adhesion energy per unit area when in the medium V.\n\nA given substrate-liquid-vapor combination yields a continuous range of contact angle values in practice. The maximum contact angle is referred to as the advancing contact angle and the minimum contact angle is referred to as the receding contact angle. The advancing and receding contact angles are measured from dynamic experiments where droplets or liquid bridges are in movement . In contrast, the equilibrium contact angle described by the Young-LaPlace equation is measured from a static state. Static measurements yield values in-between the advancing and receding contact angle depending on deposition parameters (e.g. velocity, angle, and drop size) and drop history (e.g. evaporation from time of deposition). Contact angle hysteresis is defined as formula_8although the term is also used to describe the expression formula_9.The static, advancing, or receding contact angle can be used in place of the equilibrium contact angle depending on the application.\n\nThe advancing contact angle can be described as a measure of the liquid-solid cohesion while the receding contact angle is a measure of liquid-solid adhesion. The advancing and receding contact angles can be measured directly using different methods and can also be calculated from other wetting measurements such as force tensiometery (aka Wilhemy-Plate method). \n\nAdvancing and receding contact angles can be measured directly from the same measurement if drops are moved linearly on a surface. For example, a drop of liquid will adopt a given contact angle when static, but when the surface is tilted the drop will initially deform so that the contact area between the drop and surface remains constant. The \"downhill\" side of the drop will adopt a higher contact angle while the \"uphill\" side of the drop will adopt a lower contact angle. As the tilt angle increases the contact angles will continue to change but the contact area between the drop and surface will remain constant. At a given surface tilt angle, the advancing and receding contact angles will be met and the drop will move on the surface. In practice, the measurement can be influenced by shear forces and momentum if the tilt velocity is high. The measurement method can also be challenging in practice for systems with high (>30 degrees) or low (<10 degrees) contact angle hysteresis. \n\nAdvancing and receding contact angle measurements can be carried out by adding and removing liquid from a drop deposited on a surface. If a sufficiently small volume of liquid is added to a drop, the contact line will still be pinned, and the contact angle will increase. Similarly, if a small amount of liquid is removed from a drop, the contact angle will decrease. \n\nThe Young's equation assumes a homogeneous surface and does not account for surface texture or outside forces such as gravity. Real surfaces are not atomically smooth or chemically homogeneous so a drop will assume contact angle hysteresis. The equilibrium contact angle (formula_10) can be calculated from formula_11 and formula_12 as was shown theoretically by Tadmor and confirmed experimentally by Chibowski as,\n\nwhere\n\nOn a surface that is rough or contaminated, there will also be contact angle hysteresis, but now the local equilibrium contact angle (the Young equation is now only locally valid) may vary from place to place on the surface. According to the Young–Dupré equation, this means that the adhesion energy varies locally – thus, the liquid has to overcome local energy barriers in order to wet the surface. One consequence of these barriers is contact angle hysteresis: the extent of wetting, and therefore the observed contact angle (averaged along the contact line), depends on whether the liquid is advancing or receding on the surface.\n\nBecause liquid advances over previously dry surface but recedes from previously wet surface, contact angle hysteresis can also arise if the solid has been altered due to its previous contact with the liquid (e.g., by a chemical reaction, or absorption). Such alterations, if slow, can also produce measurably time-dependent contact angles.\n\nSurface roughness has a strong effect on the contact angle and wettability of a surface. The effect of roughness depends on if the droplet will wet the surface grooves or if air pockets will be left between the droplet and the surface.\n\nIf the surface is wetted homogeneously, the droplet is in Wenzel state. In Wenzel state, adding surface roughness will enhance the wettability caused by the chemistry of the surface. The Wenzel correlation can be written as\nwhere θ is the measured contact angle, θ is the Young contact angle and r is the roughness ratio. The roughness ratio is defined as the ratio between the actual and projected solid surface area.\n\nIf the surface is wetted heterogeneously, the droplet is in Cassie-Baxter state. The most stable contact angle can be connected to the Young contact angle. The contact angles calculated from the Wenzel and Cassie-Baxter equations have been found to be good approximations of the most stable contact angles with real surfaces.\n\nFor liquid moving quickly over a surface, the contact angle can be altered from its value at rest. The advancing contact angle will increase with speed, and the receding contact angle will decrease. The discrepancies between static and dynamic contact angles are closely proportional to the Capillary number, noted formula_16.\n\nOn the basis of interfacial energies, the profile of a surface droplet or a liquid bridge between two surfaces can be described by the Young–Laplace equation . This equation is applicable for three-dimensional axisymmetric conditions and is highly non-linear. This is due to the mean curvature term which includes products of first- and second-order derivatives of the drop shape function formula_17:\n\nSolving this elliptic partial differential equation that governs the shape of a three-dimensional drop, in conjunction with appropriate boundary conditions, is complicated, and an alternate energy minimization approach to this is generally adopted. The shapes of three-dimensional sessile and pendant drops have been successfully predicted using this energy minimisation method.\n\nContact angles are extremely sensitive to contamination; values reproducible to better than a few degrees are generally only obtained under laboratory conditions with purified liquids and very clean solid surfaces. If the liquid molecules are strongly attracted to the solid molecules then the liquid drop will completely spread out on the solid surface, corresponding to a contact angle of 0°. This is often the case for water on bare metallic or ceramic surfaces, although the presence of an oxide layer or contaminants on the solid surface can significantly increase the contact angle. Generally, if the water contact angle is smaller than 90°, the solid surface is considered hydrophilic and if the water contact angle is larger than 90°, the solid surface is considered hydrophobic. Many polymers exhibit hydrophobic surfaces. Highly hydrophobic surfaces made of low surface energy (e.g. fluorinated) materials may have water contact angles as high as ~120°. Some materials with highly rough surfaces may have a water contact angle even greater than 150°, due to the presence of air pockets under the liquid drop. These are called superhydrophobic surfaces.\n\nIf the contact angle is measured through the gas instead of through the liquid, then it should be replaced by 180° minus their given value. Contact angles are equally applicable to the interface of two liquids, though they are more commonly measured in solid products such as non-stick pans and waterproof fabrics.\n\nControl of the wetting contact angle can often be achieved through the deposition or incorporation of various organic and inorganic molecules onto the surface. This is often achieved through the use of specialty silane chemicals which can form a SAM (self-assembled monolayers) layer. With the proper selection of the organic molecules with varying molecular structures and amounts of hydrocarbon and/or perfluoronated terminations, the contact angle of the surface can tune. The deposition of these specialty silanes can be achieved in the gas phase through the use of a specialized vacuum ovens or liquid-phase process. Molecules that can bind more perfluorinated terminations to the surface can results in lowering the surface energy (high water contact angle).\n\nThe sessile drop contact angle is measured by a contact angle goniometer using an optical subsystem to capture the profile of a pure liquid on a solid substrate. The angle formed between the liquid–solid interface and the liquid–vapor interface is the contact angle. Older systems used a microscope optical system with a back light. Current-generation systems employ high resolution cameras and software to capture and analyze the contact angle. Angles measured in such a way are often quite close to advancing contact angles. Equilibrium contact angles can be obtained through the application of well defined vibrations.\n\nMeasuring contact angles for pendant drops is much more complicated than for sessile drops due to the inherent unstable nature of inverted drops. This complexity is further amplified when one attempts to incline the surface. Experimental apparatus to measure pendant drop contact angles on inclined substrates has been developed recently. This method allows for the deposition of multiple microdrops on the underside of a textured substrate, which can be imaged using a high resolution CCD camera. An automated system allows for tilting the substrate and analysing the images for the calculation of advancing and receding contact angles.\n\nThe dynamic sessile drop is similar to the static sessile drop but requires the drop to be modified. A common type of dynamic sessile drop study determines the largest contact angle possible without increasing its solid–liquid interfacial area by adding volume dynamically. This maximum angle is the advancing angle. Volume is removed to produce the smallest possible angle, the receding angle. The difference between the advancing and receding angle is the contact angle hysteresis.\n\nA method for calculating average advancing and receding contact angles on solids of uniform geometry. Both sides of the solid must have the same properties. Wetting force on the solid is measured as the solid is immersed in or withdrawn from a liquid of known surface tension. Also in that case it is possible to measure the equilibrium contact angle by applying a very controlled vibration. That methodology, called VIECA, can be implemented in a quite simple way on every Wilhelmy balance.\n\nDynamic Wilhelmy method applied to single fibers to measure advancing and receding contact angles.\nAn optical variation of the single-fiber Wilhelmy method. Instead of measuring with a balance, the shape of the meniscus on the fiber is directly imaged using a high resolution camera. Automated meniscus shape fitting can then directly measure the static, advancing or receding contact angle on the fiber.\n\nIn case of a porous materials many issues have been raised both about the physical meaning of the calculated pore diameter and the real possibility to use this equation for the calculation of the contact angle of the solid, even if this method is often offered by much software as consolidated. Change of weight as a function of time is measured.\n\n"}
{"id": "511046", "url": "https://en.wikipedia.org/wiki?curid=511046", "title": "Copper(I) oxide", "text": "Copper(I) oxide\n\nCopper(I) oxide or cuprous oxide is the inorganic compound with the formula CuO. It is one of the principal oxides of copper, the other being CuO or cupric oxide. This red-coloured solid is a component of some antifouling paints. The compound can appear either yellow or red, depending on the size of the particles. Copper(I) oxide is found as the reddish mineral cuprite.\n\nCopper(I) oxide may be produced by several methods. Most straightforwardly, it arises via the oxidation of copper metal:\nAdditives such as water and acids affect the rate of this process as well as the further oxidation to copper(II) oxides. It is also produced commercially by reduction of copper(II) solutions with sulfur dioxide. Aqueous cuprous chloride solutions react with base to give the same material. In all cases, the color is highly sensitive to the procedural details.\n\nFormation of copper(I) oxide is the basis of the Fehling's test and Benedict's test for reducing sugars. These sugars reduce an alkaline solution of a copper(II) salt, giving a bright red precipitate of CuO.\n\nIt forms on silver-plated copper parts exposed to moisture when the silver layer is porous or damaged. This kind of corrosion is known as red plague.\n\nLittle evidence exists for cuprous hydroxide, which is expected to rapidly undergo dehydration. A similar situation applies to the hydroxides of gold(I) and silver(I).\n\nThe solid is diamagnetic. In terms of their coordination spheres, copper centres are 2-coordinated and the oxides are tetrahedral. The structure thus resembles in some sense the main polymorphs of SiO, and both structures feature interpenetrated lattices.\n\nCopper(I) oxide dissolves in concentrated ammonia solution to form the colourless complex [Cu(NH)], which is easily oxidized in air to the blue [Cu(NH)(HO)]. It dissolves in hydrochloric acid to give solutions of CuCl. Dilute sulfuric acid and nitric acid produce copper(II) sulfate and copper(II) nitrate, respectively.\n\nCuO degrades to copper(II) oxide in moist air.\n\nCuO crystallizes in a cubic structure with a lattice constant a=4.2696 Å. The Cu atoms arrange in a fcc sublattice, the O atoms in a bcc sublattice. One sublattice is shifted by a quarter of the body diagonal. The space group is formula_1, which includes the point group with full octahedral symmetry.\n\nIn the history of semiconductor physics, CuO is one of the most studied materials, and many experimental observations and semiconductor applications have been demonstrated first in this material:\nThe lowest excitons in CuO are extremely long lived; absorption lineshapes have been demonstrated with neV linewidths, which is the narrowest bulk exciton resonance ever observed. The associated quadrupole polaritons have low group velocity approaching the speed of sound. Thus, light moves almost as slowly as sound in this medium, which results in high polariton densities.\nAnother unusual feature of the ground state excitons is that all primary scattering mechanisms are known quantitatively. CuO was the first substance where an entirely parameter-free model of absorption linewidth broadening by temperature could be established, allowing the corresponding absorption coefficient to be deduced. It can be shown using CuO that the Kramers–Kronig relations do not apply to polaritons.\n\nCuprous oxide is commonly used as a pigment, a fungicide, and an antifouling agent for marine paints. Rectifier diodes based on this material have been used industrially as early as 1924, long before silicon became the standard. Copper(I) oxide is also responsible for the pink color in a positive Benedict's test.\n\n\n"}
{"id": "22145352", "url": "https://en.wikipedia.org/wiki?curid=22145352", "title": "Dó paper", "text": "Dó paper\n\nDó paper ( ; \"bamboo paper\") is a paper made from the bark of the Rhamnoneuron balansae traditionally produced in many villages in Vietnam. It plays an important role in folk art, Dong Ho Painting in particular, because of its durability.\n\nThe production process includes some stages. First, the bark is soaked in limewater for three months. Second, the black outer bark is husked off and ground by mortar and pestle before being blended with a viscous substance made from a plant belonging to Verbenaceae family. This mixture is diluted to form a slurry. A bamboo mold (Vietnamese: liềm xeo) is dipped into the vat of slurry and removed. Paper fibers adhere to the mold in a thin sheet that is then pressed, dried, rolled, and dried again. The final product must be soft, light, and durable.\n\nDue to its durability, this paper found many uses in traditional Vietnam, including the making of books, paintings, and documents.\n"}
{"id": "47500618", "url": "https://en.wikipedia.org/wiki?curid=47500618", "title": "European countries by electricity consumption per person", "text": "European countries by electricity consumption per person\n\nThe map data is for year 2012 from the World Bank. Numbers are in kWh per year.\n\nThe table uses 2012 data from the World Bank. Numbers are in kWh per year.\n\n"}
{"id": "51797088", "url": "https://en.wikipedia.org/wiki?curid=51797088", "title": "Garissa Solar Power Station", "text": "Garissa Solar Power Station\n\nGarissa Power Station is a solar power plant under construction in Kenya.\n\nThe power station is located in Garissa County about , north of the town of Garissa. This is approximately by road, north-east of Nairobi, the country's capital and largest city.\n\nThe solar farm sits on and consist of 200,200 solar panels and is expected to be the largest in East and Central Africa. It is expected to create about 1,000 jobs during the construction period. The power from this power station is enough to power about 625,000 homes.\n\nThe power station is owned and operated by Kenya Rural Electrification Authority, a government agency. The power generated will be sold to Kenya Power and Lighting for integration into the national grid. In February 2018, the Business Daily Africa, reported that the expected commissioning of this power plant had been pushed back to December 2018, following delays. The power purchase agreement, signed in September 2016, calls for Kenya Power to sell electricity from the solar plant at KSh12 (US$0.12) per kilowatt hour, approximately KSh8 cheaper than diesel-generated electricity.\n\nChina Jiangxi, a Chinese construction company was awarded the construction contract at a budgeted cost of KSh13.7 billion ($135.7 million), borrowed from Exim Bank of China. Construction was expected to begin in the fourth quarter of 2016 and was expected to last one year. Due to prolonged negotiations in securing a power purchase agreement from Kenya Power and Lighting, construction of this project was delayed. As of February 2018, commissioning of the power station was expected in December 2018. In August 2018, The EastAfrican reported that the new commissioning date had been brought forward to September 2018.\n\n\n"}
{"id": "23798174", "url": "https://en.wikipedia.org/wiki?curid=23798174", "title": "Green Energy Wind Farm", "text": "Green Energy Wind Farm\n\nThe Green Energy Wind Farm is a proposed wind power project in Tulcea County, Romania. It will have 200 individual wind turbines with a nominal output of around 1 MW which will deliver up to 200 MW of power, enough to power over 79,200 homes, with a capital investment required of approximately US$450 million.\n"}
{"id": "27421290", "url": "https://en.wikipedia.org/wiki?curid=27421290", "title": "Herbert Riehl", "text": "Herbert Riehl\n\nHerbert Riehl (March 30, 1915 – June 1, 1997) was a German-born American meteorologist who is widely regarded as the father of tropical meteorology. He is well known for his work with Joanne Simpson on the importance of hot towers, and their critical role in transport of energy out of the tropics via the Hadley circulation.\n\n\nRiehl wrote the first textbook on tropical meteorology.\n"}
{"id": "29385903", "url": "https://en.wikipedia.org/wiki?curid=29385903", "title": "Hydraulic jumps in rectangular channels", "text": "Hydraulic jumps in rectangular channels\n\nHydraulic jump in a rectangular channel, also known as classical jump, is a natural phenomenon that occurs whenever flow changes from supercritical to subcritical flow. In this transition, the water surface rises abruptly, surface rollers are formed, intense mixing occurs, air is entrained, and often a large amount of energy is dissipated. In other words, a hydraulic jump happens when a higher velocity, \"v\", supercritical flow upstream is met by a subcritical downstream flow with a decreased velocity, \"v\", and sufficient depth. Numeric models created using the standard step method or HEC-RAS are used to track supercritical and subcritical flows to determine where in a specific reach a hydraulic jump will form.\n\nThere are common hydraulic jumps that occur in everyday situations such as during the use of a household sink. There are also man-made hydraulic jumps created by devices like weirs or sluice gates. In general, a hydraulic jump may be used to dissipate energy, to mix chemicals, or to act as an aeration device.\n\nTo produce equations describing the jump, since there is an unknown energy loss, there is a need to apply conservation of momentum. To develop this equation, a general situation in which there may or may not be an energy loss between upstream and downstream, and there may or may not be some obstacle on which there is a drag force P is considered. however, for a simple or classic hydraulic jump the force per unit width(P) equals 0. From there the momentum equation, and the conjugate depths equation can be derived.\n\nThe depth of supercritical flow, y, ‘jumps’ up to its subcritical conjugate depth, y, and the result of this abrupt change in flow conditions is considerable turbulence and Energy Loss, E. Figure 1 shows a schematic of typical jump characteristics where E is the energy of the upstream flow, E is the energy of the downstream flow and L is the length of the hydraulic jump. A series of small surface rollers are formed in a standing wave like the one shown in Figure 1.\nFigure 1. Hydraulic Jump Overall Schematic\n\nHydraulic jumps occur commonly in everyday situations such as during the use of any household sink. The jump can be seen in the form of a circular, stationary wave surrounding the inflow of water. The hydraulic jump occurs at the point where the seemingly still water becomes turbulent. As water hits the sink, it disperses, increasing in depth to a critical radius where the flow (supercritical with low depth, high velocity, and a Froude number greater than 1) must suddenly jump to a greater, subcritical depth (high depth, low velocity, and a Froude number less than 1) that is known to conserve momentum.\n\nFigure 2. Turbulent hydraulic jump can be created in sink (left), viscous hydraulic jump can create advanced shapes (right)\n\nHydraulic jumps may also be manmade; as seen in Figure 2, scientists have been experimenting with the effects of viscosity on the hydraulic jump and have been able to create steady asymmetrical forms. In more practical applications, jumps are created in the environment with specific purposes such as erosion prevention. Erosion in stream beds is often caused by a high velocity water flow which leads to sediment transport. This process can be prevented by decreasing the velocity of the flow into the stream bed with the introduction of a hydraulic jump. Often in these cases, a hydraulic jump is created by devices such as a weir or sluice gate where the turbulent flow enters the stream. The mixture of chemical constituents in a solution is another practical use for hydraulic jumps. Introducing a hydraulic jump rapidly increases the turbulence of the flow, allowing sufficient constituent mixing without the use of any additional mechanisms. The wastewater industry sometimes uses hydraulic jumps as a way to mix solutions, minimizing the need to implement more expensive mechanical mixing systems.\n\nFigure 3. Weir in Riverfront Park, WA (left) and Hydraulic Jump in Coagulation Chamber (right)\n\nStill another use for manmade hydraulic jumps is energy dissipation. One example of an energy dissipating use is a hydraulic jump stilling basin. In these basins, horizontal and sloping aprons are used to dissipate up to 60% of the energy of incoming flow; the basins implement devices such as chute blocks, baffle piers, and dentated ends whose effectiveness in energy dissipation is dependent on the Froude number of the incoming flow. ‘Hydraulic jump stilling basins are not typically suggested for use when dealing with heads greater than 100 meters due to complications caused by turbulences like intermittent cavitation, vibration, uplift, and hydrodynamic loading.’ Other hydraulic structures such as dams and weirs also use these same energy dissipating principles to reduce the incoming force from turbulent flows that tend to scour or erode downstream areas.\n\nFigure 4. Stilling Basin On Oker River in the Harz-Mointains at Opened Scour Outlet (left) and Stilling Basin for Griggs Dam in Columbus, OH (right)\n\nMomentum is defined as the product of mass times velocity, and like velocity, it is a vector. French Scientist and Philosopher of the early 1600s René Descartes first discovered the concept of momentum but got stuck on the amount of motion (speed) which was not being conserved. Christian Huygens, a Dutch Scientist, pointed out that the \"quantity of motion\" did not need to be a positive value; a negative value meant that it was moving in the opposite direction.\n\nThe basic principles behind the momentum function are:\n\nThe following derivation is for the momentum function of a simple momentum conserving hydraulic jump in a rectangular channel with constant width.\n\n\nConjugate depths are the depths (\"y\") upstream and the depth (y) downstream of the hydraulic jump whose momentum functions are equal for a given unit discharge, \"q\". The depth upstream of a hydraulic jump is always supercritical, and the depth downstream of a hydraulic jump is always subcritical. It is important to note that the conjugate depth is different than the alternate depths for flow which are used in energy conservation calculations.\n\n(1) Beginning with momentum function, we equate momentum between locations 1 and 2: \n(2) Rearranging terms by moving the q terms to the left and the 1/2 terms to the right, we get:\n(3) We then multiply to get a common denominator on the left-hand side and factor the right-hand side:\n(4) The (\"y\"−\"y\") term cancels out:\n(5) Divide by \"y\"\n(6) Multiply by \"y\" and expand right-hand side:\n(7) Substitute \"x\" for the quantity \"y\"/\"y\". We have a quadratic equation in x:\n(8) Using the quadratic equation:\n\n(9) Hence, substituting the constant \"y\"/\"y\" back in for \"x\" to get the conjugate depth equation:\n\nGiven: <br>\nFind: <br>\nSolution: <br>\n\nThe M-y Diagram for this example is plotted below. To develop the M-y Diagram, we plot the value of M as a function of depth with M on the x-axis and depth on the y-axis since this is more naturally conducive to visualizing the change in momentum with depth. This example is a very basic hydraulic jump situation where the flow approaches at a supercritical depth, \"y\", and jumps to its subcritical conjugate depth, \"y\", in order to obtain the necessary energy to continue moving down the channel with the given flow rate, \"q\".\n\n<br>\nFigure 6. M-y Diagram\n\nThe M-y Diagram is a graphical representation of the conservation of momentum and can be applied over a hydraulic jump to find the upstream and downstream depths. We can see from the above example that the flow approaches supercritically at a depth of \"y\". There is a jump to the subcritical conjugate depth of \"y\" which is labeled as \"y\" in Figure 6. Figure 6 helps in visualizing how two depths can exist with the same momentum.\n\nThere are a few key locations on the M-y diagram which are labeled in Figure 6 above developed based on the information in Example 1. The first location of interest is the critical point labeled with y and M in Figure 6. The critical point represents the minimum value of the momentum function available for that particular flow per unit width, \"q\". An increase in q would cause the M function to move to the right and slightly up, giving the flow access to more momentum at its critical point. It follows that a decrease in the q value would move the M function down and to the left, decreasing the momentum available to the flow at its critical value. This is shown graphically Figure 7 below.\n\nFigure 7. Effect of increasing q on depth up- and down-stream of hydraulic jump\n\nFrom Figure 7, it can also be seen what effect increasing the flow rate, \"q\", will have on the depth up- and down-stream of the jump. Increasing the incoming flow rate (from q = 10 ft/s to 30 ft/s in Figure 7) will result in an increase in the supercritical approach depth and a decrease in the subcritical depth post-jump. This can be seen in Figure 6 by the decrease in depth from y to y and the increase in depth between y and y. From this analysis of the change in depth due to a change in flow rate, we can also imagine that the energy lost in a jump with a value of q = 10 ft/s would be different from that of a jump with q = 30 ft/s. This is further discussed in Section 5.1.\n\nAlthough momentum is conserved throughout the hydraulic jump, the energy is not. There is an initial loss of energy when the flow jumps from supercritical to subcritical depths. The resulting loss of energy is equal to the change in specific energy across the jump and is given by the equation for ΔE below. The equation below is based on the condition that y and y are conjugate depths.\nWhen looking at the critical points on the M-y diagram and what their locations tell us about the nature of the hydraulic jump, we mentioned that an increase in q would affect the energy lost in the jump. From Figure 7 we see that increasing the flow rate decreases the difference in the upstream and downstream depth of the jump (\"y\" – \"y\"). From this we can infer that if the momentum is held to be constant, there will be a decrease in the energy lost in the jump if the flow rate is increased.\n\nThe efficiency of the jump is determined by the dimensionless parameter E/E which tells us how much of the original energy is remaining after the jump is complete. The equation for the energy efficiency is given below and shows the heavy dependence that the efficiency has on the Froude number of the upstream flow. Example 2 shows a sample calculation for energy loss and efficiency.\n\nGiven:\nFind:\nSolution:\n\nLength of a hydraulic jump is often hard to measure in the field and during laboratory investigations due to the sudden changes in surface turbulence, in addition to the formation of roller and eddies. The length of a hydraulic jump is often an important factor to know when considering the design of structures like settling basins. The equation derived for length is based on experimental data, and relates the length to the upstream Froude number.\n\nGiven:\nFind:\nSolution:\n\nThe height of the hydraulic jump, similar to length, is useful to know when designing waterway structures like settling basins or spillways. The height of the hydraulic jump is simply the difference in flow depths prior to and after the hydraulic jump. The height can be determined using the Froude number and upstream energy.\n\nEquations:\nSubstitute \"y\" equation into jump height equation:\n\nGiven:\nFind:\nSolution:\n\nA hydraulic jump can assume several distinct forms depending on the approach Froude number, Fr. Each of these types has unique flow patterns and flow characteristics, such as the strength and formation of rollers and eddies, that help to determine the amount of energy dissipation that will occur in the jump. The following descriptions of jump types are based on specific ranges of Froude numbers, but it should be noted that these ranges are not precise and that overlap can occur near the endpoints.\n\nFor the case when 1 < Fr < 1.7, y and y are approximately equal and only a very small jump occurs. In this range, the water surface shows slight undulations and because of this, jumps in this range are sometimes known as undular jumps. These surface riffles generally result in very little energy dissipation. As Fr approaches 1.7, a number of small rollers begin to form at the water surface at the jump location, but in general, the downstream water surface remains relatively smooth. Between 1.7 < Fr < 2.5, the velocity remains fairly uniform on either side of the jump and energy loss is low.\n\nAn oscillating jump can occur when 2.5 < Fr < 4.5. During this jump, the jet of water at the entrance of the jump (supercritical) fluctuates from the bottom of the channel to the top of the channel at an irregular period. Turbulence created from this jet can be near the channel bottom at one instant and then suddenly transition to the water surface. This oscillation of the jet causes irregular waves to form, which can propagate for long distances downstream of the jump, potentially causing damage and degradation of the channel banks.\n\nWhen the Froude number falls into this range, the jump forms steadily and at the same location. In a steady jump, turbulence is confined within the jump and the location of the jump is the least susceptible to downstream flow conditions out of the four major types of jumps. Steady jumps are generally well-balanced and the energy dissipation is usually considerable (45-70%).\n\nThere is a large difference in conjugate depths in a strong jump. Strong jumps are characterized by a jump action that is very rough resulting in a high energy dissipation rate. At irregular intervals, slugs of water can be seen rolling down the front of the jump face. These slugs enter the high-velocity, supercritical jet and cause the formation of additional waves in the jump. Energy dissipation in strong jumps can reach up to 85%.\n\nIn general, a hydraulic jump is formed at a location where the upstream and downstream flow depths satisfy the conjugate depth equation. However, there can be conditions in a channel, such as downstream controls, that can alter where the conjugate depths form. Tailwater depth can play a very influential role on where the jump will occur in the channel, and changes in this depth can shift the jump either upstream or downstream. Figure 6 contains three scenarios of tailwater elevations (y): y is equal to the conjugate depth (y) of the upstream flow depth (y), y is less than the conjugate depth (y) of the upstream flow depth (y), and y is greater than the conjugate depth (y) of the upstream flow depth (y). The upstream depth (y) in all three cases is controlled by a sluice gate and remains constant. Its corresponding conjugate depth (y) is shown by the dashed line in each of the scenarios. \n\nIn the first situation (Scenario A), the jump is formed right at the apron, as it would if there was no downstream control. However, in the next scenario (Scenario B), the downstream tailwater depth has some control imposed on it such that it is less than the conjugate to y. In this case, the jump travels downstream and initiates at a point where the upstream flow depth (y’) has risen to the conjugate of the new downstream tailwater depth (y). This rise from y to y’ is caused by frictional resistance in the channel; and velocity decrease, the depth increase. In this image, y’ and y’ represent the conjugate depths of the hydraulic jump where y’ assumes the depth of y. In contrast, in the third setup (Scenario C), there is a downstream control that forces the tailwater elevation to a depth above the original conjugate depth. Here, y is greater than the required depth so the jump is pushed upstream. In this scenario, the sluice gate inhibits the movement of the jump upstream so that the upstream conjugate cannot be attained. This leads to a situation known as a submerged or drowned hydraulic jump. These scenarios demonstrate how influential the role of tailwater is to jump formation and location.\n\nTable 1. Hydraulic Jump Classifications\n\nTo help visualize the relationship of the upstream Froude number and the flow depth downstream of the hydraulic jump, it is helpful to plot y/y versus the upstream Froude Number, Fr. (Figure 8) The value of y/y is a ratio of depths that represent a dimensionless jump height; for example, if y/y = 2, then the jump doubles the depth of flow. As the upstream Froude Number increases (moves toward more supercritical flow), the ratio of the downstream depth to the upstream depth also increases, and the graph verifies the existence of a positive linear relationship between the dimensionless jump height and the upstream Froude Number. This implies that a more supercritical upstream flow, y, will produce a larger downstream depth, y, and thus a larger jump. The relationship given in Figure 8 below was developed for a horizontal, rectangular channel with q = 10 ft/s. This graph is limited by the following due to the nature of a hydraulic jump:\n\nTable 2 shows the calculated values used to develop Figure 8. The values associated with a y = 1.5 ft are not valid for use since they violate the above limits. The cusp of the above limits is reached at the critical depth, y, where all of these values are equal to 1. There will not, however, be a hydraulic jump in the situation where y is equal to y.\n\nTable 2. Values for Depth and Froude Number over Hydraulic Jump<br>\n\n\"q\" = 10 ft, \"g\" = 32.2 ft/s, \"y\" = 1.46 ft, \"y\" values in ft\n\n<br>\nFigure 8. Dimensionless Jump Height vs. Upstream Froude Number (Please note that this diagram is not fully correct. Other factors taken into account are width and water velocity\n\n\"This topic contribution was made in partial fulfillment of the requirements for Virginia Tech, Department of Civil and Environmental Engineering course: CEE 5984 – Open Channel Flow during the Fall 2010 semester.\"\n"}
{"id": "4992149", "url": "https://en.wikipedia.org/wiki?curid=4992149", "title": "Hydrocarbon Oil Duty", "text": "Hydrocarbon Oil Duty\n\nHydrocarbon Oil Duty (also fuel duty and fuel tax) is a fuel tax levied on some fuels used by most road motor vehicles in the United Kingdom; with exceptions for local bus services, some farm and construction vehicles and aviation, which pay reduced or no fuel duty.\n\nThe government revenue from fuel duty was £27.1 billion for the financial year 2014-2015. This is an increase in cash terms in comparison to 2013-2014 but now only represents 1.5% of GDP. This is in contrast to the start of the 2000s when it was 2.3% of GDP. A further £3.9 billion is raised from the VAT on the duty, contributing some 3.5 per cent of total UK tax revenues. The Fuel Price Escalator, which was introduced in 1993 was abandoned after the disruptive fuel tax protests of 2000.\n\nThe Finance Act 1908 introduced a petrol duty in the UK, with the rate being set at 3d (£0.013) per UK gallon, bringing the price of a typical UK gallon to 1s 1½d ().\n\nIt was then abolished by the Finance Act 1919 after several years of steady petrol price rises and replaced by vehicle taxation, and the tax disc based on horsepower, after which the cost of petrol was about 4s () per UK gallon.\n\nIn 1928, following market reductions in the cost of a UK gallon of fuel to about 1s 2½d (), the Government introduced a tax of 4d (£0.017) per UK gallon bringing the cost of a UK gallon of petrol to 1s 6¾d ().\n\nIn the 1993 Budget during the Major ministry, Norman Lamont introduced a 10p rise and also a Fuel Price Escalator whereby the cost of fuel would be increased annually by 3 per cent above inflation in future years; the Petroleum Revenue Tax was reduced in the same budget and later abolished. Kenneth Clarke, the new chancellor, increased the escalator to 5p in November of that year. These increases were introduced at a time of considerable change in government transport policy, and followed major UK road protests, including the M11 link road protest and the protest at Twyford Down. The escalator was increased in 6p per year in 1997 by Gordon Brown, chancellor for the new Blair ministry.\n\nThe escalator was effectively cancelled by the Brown ministry follow severe disruption caused by the fuel tax protests in 2000. Since that time more cautious increases have been applied. A planned 3.02p/litre rise which was confirmed by the 2012 United Kingdom budget to come into effect on 1 August 2012 was later deferred until 1 January 2013 at short notice. The last increase in Fuel duty occurred in 2010. Taxation currently accounts for 75% of the total price of fuel at 99.7ppl.\n\nThe rates since 23 March 2011 have been as follows:\n\nVAT at the current rate is then added to the total price. The taxation percentage of forecourt prices varies according to the price of oil, rising from 55.9% at 65p per litre untaxed to 61.4% at 50p per litre (2012 figures).\n\nThe UK average petrol price as of 11 January 2016 is £1.01 per litre. This is slightly above the European average but is 30p lower than the peak in 2014. With declining oil prices, it has been suggested petrol could fall to 86.9p per litre if oil prices fall to $10 a barrel. Average diesel prices are currently £1.03 per litre. The minimum petrol price available is 99.7p and £1.03 for diesel. The minimum across Europe is 87.9.\n\nNo duty or VAT tax is levied on jet fuel, in accordance with the Convention on International Civil Aviation, although commercial operators do pay Air Passenger Duty.\n\nAvgas, used some smaller planes, was taxed at half the rate of road petrol for all users until October 2008, when the reduced rate was limited to commercial flying. A minority of light planes use standard road petrol and pay tax at the normal rate.\n\nThe Bus Service Operators Grant provides a fuel duty rebate to local bus service operators (but not for express coach which receives no rebate). As of April 2010 the rebate was £0.43 for diesel, £0.2360 for road fuel gas other than natural gas and 100% for biodiesel and bioethanol. Additional rebates are available for increasing fuel efficiency, low carbon emission vehicles and equipping vehicles with Smartcards and GPS tracking equipment.\n\nIn 2001 it was proposed that long-distance scheduled coach services should receive the rebate in return for offering half-price fares to older and disabled passengers.\n\nRegistered construction and farm vehicles 'red diesel' which includes a fuel dye has a significantly reduced tax levy compared to normal road fuel. This can only be used in registered agricultural and construction vehicles including tractors, excavators, cranes and there are heavy fines for misuse.\n\nUK train operators are required pay full duty rates with the exception of biofuels, for which the duty was reduced from 53p to 8p in 2006 and for electrified services.\n\n\n"}
{"id": "36538319", "url": "https://en.wikipedia.org/wiki?curid=36538319", "title": "Interstate Oil and Gas Compact Commission", "text": "Interstate Oil and Gas Compact Commission\n\nThe Interstate Oil and Gas Compact Commission (IOGCC), formerly the Interstate Oil Compact Commission, is a United States organization, representing the governors of 31 member and seven associate states, that works to ensure the nation's oil and natural gas resources are conserved and utilized to their maximum potential while protecting health, safety and the environment. Established in 1935, it is the oldest and largest interstate compact in the nation.\n\nIn the early days of oil exploration, drilling was governed by the \"law of capture\", which states that the owner of land on which a well resides has the right to any oil from that well even if it was drained from the land of his neighbors. This provided an incentive for each land owner to extract the oil as fast as possible. Each state tried to regulate its own oil by such measures as proration, the limiting of production to some fraction of capacity; but then two great oil fields, the Oklahoma City Oil Field and the East Texas Oil Field, were discovered. This, along with the Great Depression, led to much waste and very low prices, with a catastrophic effect on the industry. The problems were large enough that the states recognized the need for cooperation.\n\nThe compact was formed in 1935 as the \"Interstate Compact to Conserve Gas and Oil\". The purpose of the compact was to eliminate the glut of oil and raise prices for consumers. The interstate compact was seen as an alternative to direct federal regulation that would allow oil producing states to retain more control.\n\nWhile the National Guard occupied wells in Oklahoma and Texas in 1931–1932, an Oil States Advisory Committee drafted the Thomas-McKeon Bill, which proposed an interstate oil compact and a Federal Interstate Oil Board to recommend quotas. However, the bill was abandoned after oil industry representatives withdrew their support. From 1933 to 1935, oil was regulated under the National Industrial Recovery Act and the Petroleum Code, which in effect left production control in the hands of industry representatives, with no representation for the states. The Supreme Court found these regulations unconstitutional in 1935, and the idea of an interstate compact was revived. On December 3, 1934, Oklahoma Governor-elect E. W. Marland met with the governors of Kansas and Texas to discuss an interstate compact. This led to the drafting of the Interstate Compact to Conserve Oil and Gas, which was ratified by Congress on August 27, 1935. At first, Congress ratified it for only two years at a time, then four years, and finally the compact was made permanent in 1979.\n\nSome economic historians have described the regulation of oil output under the compact as an example of a price fixing cartel. The production controls of the IOGCC and the Texas Railroad Commission have been cited as precursors to the establishment of OPEC's caps on member state oil production.\n\nThe stated purpose of the compact was \"conserve oil and gas by the prevention of physical waste thereof from any cause\". States that ratified the compact agreed to enact legislation for this purpose. Article VI of the compact constituted \"The Interstate Oil Compact Commission,\" renamed as the Interstate Oil and Gas Compact Commission in 1991, and its duty was to make recommendations for preventing the physical waste of gas and oil.\n\nInitially the commission had six members: Colorado, Illinois, Kansas, New Mexico, Oklahoma and Texas. It now has 31 member states, 7 associate states and 10 international affiliates (including 7 Canadian provinces and territories). The governor of each member state appoints an official representative who can vote on policy recommendations, and any number of associate representatives who can vote in their place if the official representative is not available. The list of members can be found on the IOGCC website. Many representatives are state regulators overseeing gas and drilling, but as of 2010 at least seven were industry executives and lobbyists.\nThe commission meets biannually, but much of its work occurs in small committee meetings throughout the year. To govern operations, it has steering, finance, resolutions and nominating committees. Other committees are Energy Resources, Research and Technology; Environment and Safety; International; Public Lands; Public Outreach; and State Review.\n\nThe IOGCC is governed by the compact and several bylaws. The compact did not provide for any resources to support IOGCC; a later bylaw stipulated that its expenses would be paid \"from voluntary contributions from the member states and other sources of revenue approved by the Commission\". These sources, which include federal grants, have proved to be enough to allow the commission to function. IOGCC uses an Oklahoma government email address and domain but it is not a state, not a federal agency and does not have to register to lobby the federal government. A plethora of information is available but relatively little of it has come directly from the organization itself. IOGCC claims an exemption from the Open Public Records Act and has removed a provision within its by-laws that formerly said its records are open to the public.\n\nTo identify best practices, IOGCC surveys member states and assesses their activities. It catalogues innovative programs and shares the information with states, and it hosts biannual meetings that draw together representatives from the government, the oil industry and environmentalists. IOGCC is an advocate for states' rights, arguing that state regulation is more effective than \"one size fits all\" federal regulation. As well as creating reports, it creates model statutes as a guide for legislation by states.\n\nIssues that IOGCC has worked on include national energy policy, carbon sequestration, environmental stewardship, hydraulic fracturing and produced water.\n\nIn the 1930s and 1940s, the commission functioned as a price fixing cartel. According to the legal scholar Blakely Murphy, the commission operated under the guise resource conservation but primarily existed to protect the interests of oil producers.\n\nA large part of the human contribution to global warming is from the emission of carbon dioxide (CO) as a result of burning fossil fuels. One way to reduce the contribution is to capture the CO before it enters the atmosphere and sequester it by injecting underground in depleted oil and natural gas fields, saline formations and coal beds. Recognizing that the oil and gas industry has a lot of experience with injecting CO into the ground for enhanced oil recovery, the IOGCC launched the \"Geological CO2 Sequestration Task Force\" in 2002 to investigate the issues surrounding sequestration. A two-phase study was funded by the Department of Energy. Phase I concluded that the states had the knowledge and experience to regulate sequestration safely. In phase II, started in 2006, the task force prepared a report that included a model statute for the states with explanations on how to implement it.\n\nThe IOGCC has three awards. The E. W. Marland Award, established in 1994, recognizes an outstanding state legislator. The Warwick Downing Award, established in 2005, recognizes an individual outside state governments who has made an outstanding contribution to the IOGCC. The highest honor, established in 2001, is the Chairman's Stewardship Award for exemplary efforts in environmental stewardship. This award has four categories: Environmental Partnership (for partnerships with industry led by non-industry organizations); Energy Education; Small Company and Large Company.\n"}
{"id": "12569695", "url": "https://en.wikipedia.org/wiki?curid=12569695", "title": "Kahl Nuclear Power Plant", "text": "Kahl Nuclear Power Plant\n\nThe Kahl plant was the first nuclear power plant ever to be built in Germany. It was located in Karlstein am Main and was an (at the time) experimental boiling water reactor. It was built by General Electric and supplied by Siemens. At the end of 2008, the demolition works had been finished.\n\nThe station was the subject of the 1961 short documentary film, \"Kahl\".\n\n"}
{"id": "325181", "url": "https://en.wikipedia.org/wiki?curid=325181", "title": "Keelung", "text": "Keelung\n\nKeelung (Standard Mandarin Pīnyīn: \"Jīlóng\"; Hokkien POJ: \"Ke-lâng\"), officially known as Keelung City, is a major port city situated in the northeastern part of Taiwan. It borders New Taipei with which it forms the Taipei–Keelung metropolitan area, along with Taipei itself. Nicknamed the \"Rainy Port\" for its frequent rain and maritime role, the city is Taiwan's second largest seaport (after Kaohsiung).\n\nAccording to early Chinese accounts, this northern coastal area was originally called \"Pak-kang\" (). By the early 20th century, the city was known to the Western world as Kelung, as well as the variants \"Kiloung\", \"Kilang\" and \"Keelung\". In his 1903 general history of Taiwan, US Consul to Formosa (1898–1904) James W. Davidson related that \"Kelung\" was among the few well-known names, thus warranting no alternate Japanese romanization.\n\nHowever, the Taiwanese people have long called the city \"Kelang\" (). It has been proposed that this name was derived from the local mountain that took the shape of a rooster cage. However, it is more probable that the name was derived from the first inhabitants of the region, as are the names of many other Taiwanese cities. In this case, the Ketagalan people were the first inhabitants, and early Han settlers probably approximated \"Ketagalan\" with \"Ke-lâng\" (Hokkien phonetics).\n\nIn 1875, during the late Qing era, a new official name was given (). In Mandarin, probably the working language of Chinese government at the time, both the old and new names were likely pronounced \"Kīlóng\" (hence \"Keelung\").\n\nUnder Japanese rule (1895–1945), the city was also known to the west by the Japanese romanization Kīrun (also written as \"Kirun\" or \"Kiirun\").\n\nIn Standard Chinese, which became the official language of Taiwan after its handover to the Republic of China, the newer name is read Jīlóng (the shift from initial \"K\" to \"J\" is a recent development in the Beijing dialect, see Old Mandarin). However, the locals continue to call the city Ke-lâng across the changes in government.\n\nKeelung was first inhabited by the Ketagalan, a tribe of Taiwanese aborigine. The Spanish expedition to Formosa in the early 17th century was its first contact with the West; by 1624 the Spanish had built San Salvador de Quelung, a fort in Keelung serving as an outpost of the Manila-based Spanish East Indies. The Spanish ruled it as a part of Spanish Formosa. From 1642 to 1661 and 1663–1668, Keelung was under Dutch control. The Dutch East India Company took over the Spanish Fort San Salvador at Santissima Trinidad. They reduced its size and renamed it Fort Noort-Hollant. The Dutch had three more minor fortifications in Keelung and also a little school and a preacher.\n\nWhen Ming Dynasty loyalist Koxinga successfully attacked the Dutch in southern Taiwan \n(Siege of Fort Zeelandia), the crew of the Keelung forts fled to the Dutch trading post in Japan. The Dutch came back in 1663 and re-occupied and strengthened their earlier forts. However, trade with Qing China through Keelung was not what they hoped it would be and, in 1668, they left after getting harassed by aboriginals.\n\nGiven the strategic and commercial value of Taiwan, there were British suggestions in 1840 and 1841 to seize the island. In September 1841, during the First Opium War, the British transport ship \"Nerbudda\" became shipwrecked near Keelung Harbour due to a typhoon. The brig \"Ann\" also became shipwrecked in March 1842. Most of the crew were Indian lascars. Survivors from both ships were transferred by authorities to the capital Tainan. The Taiwan Qing commanders, Ta-hung-ah and Yao Ying, filed a disingenuous report to the emperor, claiming to have defended against an attack from the Keelung fort. In October 1841, HMS \"Nimrod\" sailed to Keelung to search for the \"Nerbudda\" survivors, but after Captain Joseph Pearse found out that they were sent south for imprisonment, he ordered the bombardment of the harbour and destroyed 27 sets of cannon before returning to Hong Kong. Most of the survivors—over 130 from the \"Nerbudda\" and 54 from the \"Ann\"—were executed in Tainan in August 1842.\n\nIn 1863, the Qing Empire opened up Keelung as a trading port and the city enjoyed rapid development due to the abundant commodities such as placer gold and high quality coal found in the drainage area of Keelung River. In 1875, Taipeh Prefecture was created and included Keelung. In 1878, Keelung was formed into a \"ting\" or sub-prefecture. Around the same time, the name was changed from \"Ke-lang\" () to \"Kilong\" (), which means \"rich and prosperous land\".\n\nDuring the Sino-French War (1884–85), the French attempted an invasion of Taiwan during the Keelung Campaign. Liu Mingchuan, who led the defence of Taiwan, recruited Aboriginals to serve alongside the Chinese soldiers in fighting against the French of Colonel Jacques Duchesne's Formosa Expeditionary Corps. The French were defeated at the Battle of Tamsui and the Qing forces pinned the French down at Keelung in an eight-month-long campaign before the French withdrew.\n\nA systematic city development started during the Japanese Era, after the 1895 Treaty of Shimonoseki, which handed all Taiwan over to Japan. A five-phase construction of Keelung Harbor was initiated, and in by 1916 trade volume had exceeded even those of Tamsui and Kaohsiung Harbors to become one of the major commercial harbors of Taiwan.\n\nKeelung was governed as , Kīrun District, Taihoku Prefecture in 1920 and was upgraded to a city in 1924. The Pacific War broke out in 1941, and Keelung became one of the first targets of Allied bombers and was nearly destroyed as a result.\n\nAfter the withdrawal of the Japanese, Taiwan became part of the Republic of China (ROC) in October 1945, Keelung was established as a provincial city of Taiwan Province. The Keelung City Government worked with the harbor bureau to rebuild the city and the harbor and in 1984, the harbor became the 7th largest container harbor in the world.\n\nKeelung City is located in the northern part of Taiwan Island. It occupies an area of and is separated from its neighboring county by mountains in the east, west and south. The northern part of the city faces the ocean and is a great deep water harbor since early times.\n\nKeelung has a humid subtropical climate (Köppen \"Cfa\") with a yearly rainfall average upwards of . It has long been noted as one of the wettest and gloomiest cities in the world; the effect is related to the Kuroshio Current. Although it is one of the coolest cities of Taiwan, winters are still short and warm, whilst summers are long, relatively dry and hot, temperatures can peek above 26 °C during a warm winter day, while it can dip below 27 °C during a rainy summer day, much like the rest of northern Taiwan. However its location on northern mountain slopes means that due to orographic lift, rainfall is heavier during fall and winter, the latter during which a northeasterly flow prevails. During summer, southwesterly winds dominate and thus there is a slight rain shadow effect. Fog is most serious during winter and spring, when relative humidity levels are also highest.\n\nZhongzheng District is the seat of Keelung City which houses the Keelung City Government and Keelung City Council. The current Mayor of Keelung is Lin Yu-chang of the Democratic Progressive Party.\n\nKeelung has seven (7) districts:\nKeelung City voted one Democratic Progressive Party legislator to be in the Legislative Yuan during the 2016 Republic of China legislative election.\n\nOne of the most popular festivals in Taiwan is the Mid-Summer Ghost Festival. The Keelung Ghost Festival is among the oldest in Taiwan, dating back to 1851 after bitter clashes between rivaling clans, which claimed many lives before mediators stepped in. The Ghost Festival of Keelung City is a reflection of Taiwan's rich cultural history that is very much alive today.\n\nCoal mining peaked in 1968. The city developed quickly and by 1984, the harbor was the 7th largest container harbor in the world.\n\nEducation in Keelung City is governed by the Department of Education of Keelung City Government.\n\nKeelung City houses several universities and colleges, such as the National Taiwan Ocean University, Ching Kuo Institute of Management and Health and Chungyu Institute of Technology.\n\n\nKeelung City houses the only fully oil-fired power plant in Taiwan, the Hsieh-ho Power Plant, which is located in Zhongshan District. The installed capacity of the power plant is 2,000 MW.\n\nBisha Fishing Port.\n\nChung Cheng Park and Heping Island Park.\n\nEmbrace Cultural and Creative Park and Keelung Cultural Center.\n\nNational Museum of Marine Science and Technology.\n\nBaimiweng Fort, Dawulun Fort, Gongzi Liao Fort, Keelung Fort Commander's Official Residence, Pengjia Lighthouse and Uhrshawan Battery.\n\nThe Taiwan Railways Administration stations of Badu Station, Baifu Station, Keelung Station, Nuannuan Station, Qidu Station and Sankeng Station cross Keelung City.\n\nTaiwan's second largest port, the Port of Keelung, is located in the city. The port serves for destinations to Matsu Islands, Xiamen and Okinawa.\n\nKeelung is twinned with:\n\n\n\n"}
{"id": "22836986", "url": "https://en.wikipedia.org/wiki?curid=22836986", "title": "METATOY", "text": "METATOY\n\nA METATOY is a sheet, formed by a two-dimensional array of small, telescopic optical components, that switches the path of transmitted light rays. METATOY is an acronym for \"metamaterial for rays\", representing a number of analogies with metamaterials; METATOYs even satisfy a few definitions of metamaterials, but are certainly not metamaterials in the usual sense. When seen from a distance, the view through each individual telescopic optical component acts as one pixel of the view through the METATOY as a whole. In the simplest case, the individual optical components are all identical; the METATOY then behaves like a homogeneous, but pixellated, window that can have very unusual optical properties (see the picture of the view through a METATOY).\n\nMETATOYs are usually treated within the framework of geometrical optics; the light-ray-direction change performed by a METATOY is described by a mapping of the direction of any incoming light ray onto the corresponding direction of the outgoing ray. The light-ray-direction mappings can be very general. METATOYs can even create pixellated light-ray fields that could not exist in non-pixellated form due to a condition imposed by wave optics.\n\nMuch of the work on METATOYs is currently theoretical, backed up by computer simulations. A small number of experiments have been performed to date; more experimental work is ongoing.\n\nTelescopic optical components that have been used as the unit cell of two-dimensional arrays, and which therefore form homogeneous METATOYs, include a pair of identical lenses (focal length formula_1) that share the same optical axis (perpendicular to the METATOY) and that are separated by formula_2, that is they share one focal plane (a special case of a refracting telescope with angular magnification -1); a pair of non-identical lenses (focal lengths formula_3 and formula_4) that share the same optical axis (again perpendicular to the METATOY) and that are separated by formula_5, that is they again share one focal plane (a generalization of the former case, a refracting telescope with any angular magnification); a pair of non-identical lenses (focal lengths formula_3 and formula_4) that share one focal plane, that is, they share the direction of the optical axis, which is not necessarily perpendicular to the METATOY, and they are separated by formula_5 (a generalization of the former case); a prism; and a Dove prism \n\nExamples of inhomogeneous METATOYs include the moiré magnifier, which is based on deliberately \"mis-aligned\" pairs of confocal microlens arrays; Fresnel lenses, which can be seen as non-homogeneous METATOYs made from prisms;\nand frosted glass, which can be seen as an extreme case of an inhomogeneous, random METATOY made from prisms.\n\nNote that examples of METATOYs as defined above have existed long before analogies with metamaterials were noted and it was recognized that METATOYs can perform wave-optically forbidden ray-direction mappings (in pixellated form).\n\nWave optics describes light at a more fundamental level than geometrical optics. In the ray-optics limit (in which the optical wavelength tends towards zero) of scalar optics (in which light is described as a scalar wave, an approximation that works well for paraxial light with uniform polarization), the light-ray field rformula_9 corresponding to a light wave formula_10 is its phase gradient,\n\nformula_11\n\nwhere formula_12 is the phase of the wave formula_13. But according to vector calculus, the curl of any gradient is zero, that is\n\nformula_14\n\nand therefore\n\nformula_15\n\nThis last equation is a condition, derived from wave optics, on light-ray fields.\n\nUsing the example of ray-rotation sheets, it was shown that METATOYs can create light-ray fields that do not satisfy the above condition on light-ray fields.\n\nMETATOYs are not metamaterials in the standard sense. The acronym \"\"meta\"ma\"t\"erial f\"o\"r ra\"y\"s\" was chosen because of a number of similarities between METATOYs and metamaterials, which are discussed below, along with the differences.\nIn addition, metamaterials provided the inspiration for early METATOYs research, as summarized in the following quote:\n\nMotivated by the desire to build optical elements that have some of the visual properties of metamaterials on an everyday size scale and across the entire visible wavelength spectrum, we recently started to investigate sheets formed by miniaturized optical elements that change the direction of transmitted light rays.\nIn a number of ways, METATOYs are analogous to metamaterials:\n\"structure\": metamaterials are arrays of small (sub-wavelength size) wave-optical components (electro-magnetic circuits resonant with the optical frequency), whereas METATOYs are arrays of small (so that they work well as pixels), telescopic, \"ray-optical components\";\n\"functionality\": both metamaterials and METATOYs can behave like homogeneous materials, in the case of metamaterials a volume of material, in the case of METATOYs a sheet material, in both cases with very unusual optical properties such as negative refraction.\n\nArguably amongst the most startling properties of metamaterials are some that are fundamentally wave-optical, and therefore not reproduced in METATOYs. These include amplification of evanescent waves, which can, in principle, lead to perfect lenses (\"superlenses\") and magnifying superlenses (\"hyperlenses\"); reversal of the phase velocity; reversal of the Doppler shift.\n\nOn the other hand, because they are not bound by wave-optical constraints on light-ray fields, it can be argued that METATOYs can perform light-ray-direction changes that metamaterials could not, unless a METATOY was effectively built out of metamaterials.\n\n\n"}
{"id": "804123", "url": "https://en.wikipedia.org/wiki?curid=804123", "title": "Marble Bar, Western Australia", "text": "Marble Bar, Western Australia\n\nMarble Bar is a town and rock formation in the Pilbara region of north-western Western Australia. It is well known for its extremely hot weather. By mean maximum temperatures it is the second hottest place in Australia, behind only Wyndham, Western Australia.\n\nThe town was officially gazetted in 1893 following the discovery of gold in the area in 1890 by a prospector named Francis Jenkins who is remembered by the name of the town's main street. The name Marble Bar was derived from a nearby jasper bar mistaken for marble and now known as Marble Bar, which runs across the bed of the Coongan River.\n\nIn 1891 the town boasted a population in excess of 5,000 as it experienced a rush on the goldfields.\n\nBy 1895 the town had its Government offices built; these are now National Trust buildings. Cut from local stone, the buildings still stand today.\n\nPossibly the most famous building in the town is the \"Ironclad hotel\" built in the 1890s, constructed of corrugated Iron, and given the name by American miners who were reminded of the Ironclad ships from the United States. In 2006, the Ironclad hotel was listed on the Western Australian register of heritage places.\n\nSeveral large gold nuggets were discovered as a result of the goldrush. The 333 ounce Little Hero nugget, the 413 ounce Bobby Dazzler and the 332 ounce General Gordon nugget were all found in the goldfields around the town.\n\nDuring World War II, United States Army Air Forces and Royal Australian Air Force heavy bombers were based away as the crow flies at Corunna Downs Airfield. Allied airmen from the base attacked Japanese forces as far away as Borneo.\n\nThe Port Hedland to Marble Bar railway opened on 15 July 1911, costing around ₤300,000 to build. Due to low traffic and high financial losses, the railway closed from 31 May 1951. This railway could be seen as a narrow gauge precursor to the network of standard gauge iron-ore railways that have since been created across the Pilbara.\n\nMarble Bar has a hot desert climate (Köppen \"BWh\") with sweltering summers and warm winters. Most of the annual rainfall occurs in the summer. The town set a world record of most consecutive days of or above, during a period of 160 days from 31 October 1923 to 7 April 1924. Although annual temperatures indicate Marble Bar should be within the tropics, with a July (winter) mean of , it does not have the high precipitation requirements for hot-weather climates to sustain tropical vegetation.\n\nDuring December and January, temperatures in excess of are common, and the average maximum temperature exceeds normal human body temperature for six months each year. Marble Bar receives 159.6 clear days annually. Dewpoint in the summers is between . In contrast to most of the year, winters are warm, with days averaging , low humidity and clear skies. Nights from June to August can be chilly, occasionally as low as but frost is unknown. Even in mid winter however, brief bursts of heat can result in the temperature rising to as high as for a few days before dropping back to normal.\n\nRainfall is sparse and erratic, though variability is significantly less extreme than over the coastal Pilbara – the tenth percentile being vis-à-vis only in Onslow. It falls largely between December and March, with occasional rain events from autumn northwest cloudbands up to June. As little as can fall in a year; however, during heavy wet seasons when the monsoon reaches well south into the Pilbara, the rainfall can be significantly more – as much as fell between April 1999 and March 2000, and fell in 1980 owing to several tropical cyclones. The most rain recorded in a month is in March 2007, and the most in one day on 2 March 1941.\nA locality nearby is known as \"North Pole\" (21° 05' S. 119° 22' E.). It is the location of rock formations considered to have evidence that puts the origin of life on earth back to 3,400–3,500 million years ago, due to stromatolites in particular rock sequences. However this is disputed, and it is argued that stromatolites older than 3,200 mya are not the result of living organisms (the definition of stromatolites includes both living and abiotic causes), the small conical structures in the Strelley Pool formation (Warrawoona Group) being formed by evaporation and a dome structure from the North Pole chert (also Warrawoona Group) being formed by soft-sediment deformation.\n\n\n"}
{"id": "5494349", "url": "https://en.wikipedia.org/wiki?curid=5494349", "title": "Meisenheimer complex", "text": "Meisenheimer complex\n\nA Meisenheimer complex or Jackson–Meisenheimer complex in organic chemistry is a 1:1 reaction adduct between an arene carrying electron withdrawing groups and a nucleophile. These complexes are found as reactive intermediates in nucleophilic aromatic substitution but stable and isolated Meisenheimer salts are also known.\n\nThe early development of this type of complex takes place around the turn of the 19th century. In 1886 Janovski observed an intense violet color when he mixed \"meta\"-dinitrobenzene with an alcoholic solution of alkali. In 1895 Lobry de Bruyn investigated a red substance formed in the reaction of trinitrobenzene with potassium hydroxide in methanol. In 1900 Jackson and Gazzolo reacted trinitroanisole with sodium methoxide and proposed a quinoid structure for the reaction product.\n\nIn 1902 Jakob Meisenheimer observed that by acidifying their reaction product, the starting material was recovered.\n\nWith three electron withdrawing groups, the negative charge in the complex is located at one of the nitro groups according to the quinoid model. When less electron poor arenes this charge is delocalized over the entire ring (structure to the right in \"scheme 1\").\n\nIn one study a Meisenheimer arene (4,6-Dinitrobenzofuroxan) was allowed to react with a strongly electron-releasing arene (1,3,5-tris(N-pyrrolidinyl)benzene) forming a zwitterionic Meisenheimer–Wheland complex. The Wheland intermediate is its opposite number and the reactive intermediate in electrophilic aromatic substitution.\n\nThe structure of this complex was confirmed by NMR spectroscopy.\n\nThe Janovski reaction is the reaction of 1,3-dinitrobenzene with an enolizable ketone to the Meisenheimer adduct.\n\nIn the Zimmermann reaction the Janovski adduct is oxidized with excess base to a strongly colored enolate with subsequent reduction of the dinitro compound to the aromatic nitro amine. This reaction is the basis of the Zimmermann test used for the detection of ketosteroids.\n\nThe Jackson-Meisenheimer Complex was named after the American Organic Chemist, Charles Loring Jackson (1847–1935) and the German Organic Chemist, Jakob Meisenheimer (1876–1934).\n\nThe Janovski Reaction was named for the Czech Chemist, Jaroslav Janovski (1850–1907).\n\nThe Zimmermann Reaction was named after the German Chemist, Wilhelm Zimmermann (1910–1982).\n\nLastly, the Wheland Intermediate was named for the American Chemist, George Willard Wheland (1907–1976)\n"}
{"id": "25933913", "url": "https://en.wikipedia.org/wiki?curid=25933913", "title": "Montreal East Refinery (Gulf Oil Canada)", "text": "Montreal East Refinery (Gulf Oil Canada)\n\nThe Montreal East Refinery (Gulf Canada) is a small petrochemical refinery located inside the city of Montréal-Est and inside the Coastal Petrochemical fields. The operator of the refining unit is Coastal Petrochemical (Petrochimie Coastal du Canada).\n\nThe refinery was constructed by British-American Oil Company in the 1930s to process crude oil imported from Texas. It was shut down by B/A’s successor company, Gulf Canada, in 1983. Ultramar Canada purchased the 74,000 b/d capacity facility. refinery from Gulf Canada in 1986 and closed it soon after with the loss of 450 jobs. In June 1986 Montreal-based engineering firm Lavalin Inc. announced it was purchasing the refinery and would re-open it. In 1986 the refinery and its 210 000 m2 site was sold to Kemtec Petrochemicals which converted the plant to produce paraxylene. The plant came on line in 1989 and operated until 1991. That year Kemtec filed for bankruptcy. The site was determined to be heavily contaminated and, facing potentially large clean-up costs, all creditors of the company except the Government of Quebec declined to take over the property. \n\nIn 1994 the refinery was purchased by Coastal Canada Petroleum, Inc., (CCP) a subsidiary of Houston-based Coastal Corporation, for USD $1.2 million. CCP acquired the processing equipment, entered into a long-term lease for the site, and agreed to make payments to an environmental trust fund for remediation of the contaminated site.\n\n"}
{"id": "43706810", "url": "https://en.wikipedia.org/wiki?curid=43706810", "title": "Morris Operation", "text": "Morris Operation\n\nThe Morris Operation in Grundy County, Illinois, United States, is the location of the only de facto high-level radioactive waste storage site in the United States and holds 772 tons of spent nuclear fuel. It is owned by GE Hitachi Nuclear Energy with an address of 7555 East Collins Rd., Morris, IL 60450. The site is located immediately southwest of Dresden Generating Station. Spent nuclear fuel assemblies are stored at this away-from-reactor, Independent Spent Fuel Storage Installation (ISFSI) in a spent fuel storage pool.\n"}
{"id": "8978893", "url": "https://en.wikipedia.org/wiki?curid=8978893", "title": "NERC Tag", "text": "NERC Tag\n\nA NERC Tag, also commonly referred to as an E-Tag, represents a transaction on the North American bulk electricity market scheduled to flow within, between or across electric utility company territories. The NERC Tag is named for the North American Electric Reliability Corporation (NERC), which is the entity that was responsible for the implementation of the first energy tagging processes. NERC Tags were first introduced in 1997, in response to the need to track the increasingly complicated energy transactions which were produced as a result of the beginning of electric deregulation in North America.\n\nThe Federal Energy Regulatory Commission (FERC)'s Energy Policy Act of 1992 was the first major step towards electric deregulation in North America, and was followed by a much more definitive action when FERC issued Orders 888 and 889 in 1996, which laid the groundwork for formalized deregulation of the industry and led to the creation of the network of Open Access Same-Time Information System (OASIS) nodes.\n\nFERC is an independent agency of the U.S. Government and thus its authority extends only over electric utilities operating in the United States. However, NERC members include all of the FERC footprint as well as all of the electric utilities in lower Canada and a Mexican utility company. In the interest of reciprocity and commonality, all NERC members generally cooperate with FERC rules.\n\nThe creation of OASIS nodes allowed for energy to be scheduled across multiple power systems, creating complex strings of single \"point-to-point\" transactions which could be connected end-to-end to literally travel across the continent. This frequently created situations where it was difficult or impossible for transmission system operators to ascertain all of the transactions impacting their local system or take any corrective actions to alleviate situations which could put the power grid at risk of damage or collapse. The NERC Tag was implemented as a result of this new problem introduced by deregulation.\n\nThe earliest NERC Tag application was based on a Microsoft Excel spreadsheet, and was introduced in 1997. The form was usually completed by the power marketers or schedulers, by defining the date and time of the transaction, the physical path of the energy schedule from its point of generation to point of consumption, the financial path (buying/selling chain) of the energy schedule, the hourly energy amounts scheduled to flow, and also the OASIS transmission requests for each power system crossed which thereby documented that permission to cross each power system had been properly obtained.\n\nElements of a NERC Tag included Control Areas (CA), Transmission Providers (TP), Purchasing/Selling Entities (PSE), transmission Points of Receipt (POR) and Points of Delivery (POD), as well as product codes for several transmission and generation priorities.\n\nThe physical path was the most important aspect of the NERC Tag in terms of understanding the impact of a collection of individual transactions after they had been compiled into a single complete transaction. To complete the physical path it was necessary to identify the power system and power plant where the energy was to be generated, any and all power systems that would be utilized to move the energy to its eventual destination, and lastly the power system and location of the delivery point where the energy would be consumed (the \"load\").\n\nWhen a NERC Tag was created in the spreadsheet, the information was then distilled into a small CSV formatted data packet which was disseminated via e-mail to all of the participants listed on the NERC tag. In this way, all participants of a transaction were able to determine which other electric utilities and power marketers were involved in the transaction, and what the roles of the other participants were. More importantly, in the event of a contingency such as a transmission line outage or generation failure, all participants could more easily be notified of the schedule change, and could then all act in cooperation to curtail the scheduled transaction.\n\nThe NERC Tag 1.0 implementation was not capable of collecting schedule flow data in any useful way, but it did serve to familiarize schedulers with the demands of tagging their transactions, a process that would eventually be mandatory. A database of transmission scheduling points maintained by NERC through the Transmission System Information Networks (TSIN) that was originally developed for the OASIS nodes was greatly expanded to include additional information required in the process of creating NERC Tags.\n\nThe spreadsheet-based NERC Tag application saw minor improvements in functionality and scope with small incremental changes which advanced it to NERC Tag 1.3, although there was not much discernible difference to the participants, and until version 1.4 was implemented, any previous version could still be used.\n\nNot long after NERC introduced the NERC Tag spreadsheet and packet emailer, NERC concluded that it did not want involvement in any future software development or maintenance. A NERC Tag specification document, version 1.4, was drafted as the next level in energy tagging, the NERC Tag would subsequently also be known as an E-Tag. Data transfer would now occur directly over an Internet connection instead of via e-mail. This eliminated the cumbersome process required to receive a data packet via email and port it back into the original spreadsheet-based tagging application. This change made the NERC Tag much easier to use in a real-time application. E-Tag 1.4 went into effect in 1999, but was replaced just nine months later with E-Tag 1.5, followed three months later with E-Tag 1.501. The 1.5 and 1.501 Specs corrected the shortcomings experienced with the initial release of the first E-Tag Spec.\n\nAlthough NERC was responsible for the E-Tag Spec, it opened development of the application to run it to the software market. Initially there were numerous E-Tagging software providers, mainly a mix of small start-ups and new applications developed by existing energy industry software developers. The E-Tag 1.5 Spec was written in such a way that the various applications were permitted to have differing graphical user interfaces (GUIs), but functionally \"under the hood\" they were required to be able to interact with each other when transmitting, receiving and processing E-Tags. A new feature introduced with E-Tag 1.4/1.5, made possible by the real-time sharing of E-Tags, was the ability for reliability entities (namely the CA's and TP's) in the E-Tag to electronically approve or deny E-Tags based on various criteria.\n\nThe arrival of real-time tagging also enabled NERC to begin collecting real-time and short-term future data regarding the energy transactions scheduled throughout the North American power grid. The data from approved transactions was ported to the Interchange Distribution Calculator (IDC), where the data could be applied to a virtual study model of the Eastern Interconnection. The IDC went online in 1999.\n\nBuilding on the lessons experienced with E-Tag applications to date, E-Tag 1.6 went into effect in 2000. There were seven variations of E-Tag 1.6, up to E-Tag 1.67 which was in effect until late 2002. Most of the changes in E-Tag 1.6 were of a functional nature and not overly apparent to the users.\n\nUnder E-Tag 1.6, NERC implemented the \"no tag, no flow\" rule, where all energy transactions were to be documented with an E-Tag. Accurate system studies of the Eastern Interconnection in order to determine which schedules should be curtailed would only be possible if every transaction was tagged and therefore included in the IDC calculations. Reliability Coordinators in the Eastern Interconnection could access the IDC online and run flow studies based on various operating scenarios with all of the current energy schedules derived from the E-Tags. When an actual contingency occurred, the Reliability Coordinators could identify the constrained transmission line or corridor within the IDC, and the IDC would then identify which E-Tagged schedules should be curtailed in order to ease the loading on the restricted facilities.\n\nNERC's E-Tag 1.7 Specification completely reworked the E-Tag platform from scratch. Some users said that it was so significant that it might have been more appropriate to have called it \"E-Tag 2.0\". For the first time, Extensible Markup Language (XML) was utilized to format the data transferred between E-Tag applications, finally replacing the base CSV data transfer format based on its ancestral NERC Tag 1.0 spreadsheet/e-mail origins. The TSIN database was expanded to include generation and load points which were matched with PSEs that had rights to schedule them, and also included complex associations that enforced matched sets of PORs and PODs with TPs. E-Tag 1.7 also greatly expanded the time frame flexibility of an E-Tag by allowing extensions and modifications with comprehensive approval processes, layering of multiple OASIS requests for transmission rights, and also fully automated the tag curtailment functions from the IDC so that individual manual tag curtailments were no longer necessary.\n\nShortly after E-Tag 1.7 went online in 2002, the Western Electricity Coordinating Council (WECC) implemented the WECC Unscheduled Flow (USF) Tool, which accomplished a similar automated curtailing capability for the Western Interconnection that the IDC had done for the Eastern Interconnection.\n\nThe number of software choices for E-Tag software dwindled within the first few years to a handful of major players. The number of E-Tag users was strictly limited by the number of entities involved in E-Tagging, and the cost of complying with NERC E-Tag Specifications became prohibitive for any software company that did not already have significant market share or adequate financial backing. The added complexities of E-Tag 1.7 dealt a severe blow to most of the E-Tagging software providers, and within a year of E-Tag 1.7 going online, there was only one dominant E-Tag software provider remaining, which also provided all IDC and WECC USF services, though a few holdouts and customer-developed \"in-house\" E-Tag applications remain.\n\nVersion 1.7.097 of E-Tag was implemented on January 3, 2007.\n\nFive years following the release of E-Tag 1.7, a major update was developed and implemented on December 4, 2007. E-Tag 1.8 cleaned up some long-standing issues not easily addressed with minor revisions to E-Tag 1.7 and brought the E-Tag applications back up to current industry policy standards.\n\nOASIS primarily deals with the purchase and availability of transmission from individual transmission providers with a forward-looking time frame, while E-Tag is focused on real-time scheduling and power flow management across multiple systems. Nonetheless, the FERC-derived OASIS applications and NERC-derived E-Tag applications are somewhat duplicative. FERC's plan for the eventual introduction of OASIS Phase 2 envisions a combined platform to post transmission offerings, allow transmission purchases, and facilitate scheduling and flow management, effectively merging the essential functions of E-Tag and OASIS. However, there has been very little activity to move towards OASIS Phase 2 since the introduction of E-Tag 1.7 in 2002, and the future remains unclear. As both systems have increased in complexity over time, the difficulties in merging the two independently evolved systems have likewise also increased.\n\n"}
{"id": "22764213", "url": "https://en.wikipedia.org/wiki?curid=22764213", "title": "Narec", "text": "Narec\n\nNarec, since 2014 known as the National Renewable Energy Centre, is a part of the Offshore Renewable Energy (ORE) Catapult, a British technology innovation and research centre for offshore wind power, wave energy, tidal energy and low carbon technologies. ORE Catapult's head office is in Glasgow, Scotland. The centre operates multi-purpose offshore renewable energy test and demonstration facilities. It is similar to other centres, such as NREL in the US and National Centre for Renewable Energies (CENER) in Spain. The National Renewable Energy Centre is based in Blyth, Northumberland.\n\nOriginally known as NaREC (New and Renewable Energy Centre), the centre was created in 2002 by One NorthEast, the North East regional development agency, as part of the \"Strategy for Success\" programme. In 2010 the organisation changed its name to Narec (National Renewable Energy Centre). In April 2014, the organisation merged with the Offshore Renewable Energy (ORE) Catapult to focus on the development and cost reduction of offshore wind, wave and tidal energy across the UK.\n\nThe organisation was originally involved in a wide range of technologies, including:\n\nIn 2010, due to UK government cutbacks, Narec closed, sold off or separated parts of the business. Now, Narec itself concentrates on testing blades and drive trains for marine renewables. Spin-off companies include:\n\nNarec Distributed Energy – An organisation which deals with microrenewables, energy efficiency, low carbon transport and citywide energy planning. Narec Distributed Energy is 100% owned by Narec.\n\nSolar Capture Technologies – 8% owned by Narec, and 92% owned by the Swedish firm Absolicon. This organisation is focused on silicon photovoltaic cells.\n\nNarec Capital – A financial organisation run by Narec and Ashberg Limited.\n\nNarec Capital Risk Solutions – Beyond its existence, there is very little information on what this organisation does.\n\nFollowing its merger with ORE Catapult, the National Renewable Energy Centre now focuses on helping to de-risk and accelerate the development and commercialisation of the offshore renewable energy industry in the UK.\n\nThe National Renewable Energy Centre is involved in:\n\nProduct certification, verification and investigations for the next generation offshore wind turbines.\n\n3MW and 15MW facilities that can perform independent performance and reliability assessments of full systems and components.\n\nUKAS accredited laboratories with specialist test and measurement facilities to help develop technologies needed for developing power systems and exploring life extension opportunities for ageing assets.\n\nControlled onshore salt water location for all stages of technology development.\n\nOpen access facility for testing, calibrating and verifying remote sensor technologies\n\nThe Clothier Electrical Testing Laboratory was opened in 1970 by A. Reyrolle & Company. Narec took over the facility in 2004, to use it to test the robustness of electrical infrastructure offshore locations to onshore sites.\n\nAlthough one of the few high voltage testing facilities in the world, the facility was closed by Narec in 2011 due to a lack of government funding. Many parts of the lab were relocated to Narec's main campus in Blyth. The ruins of the original lab are now the property of Siemens.\n\nBuilt in 2004, this £5m facility contains a low voltage electrical laboratory for the testing of connecting renewable energy systems to the transmission and distribution grid. Some of the equipment and staff from the closed Narec Clothier Electrical Testing Laboratory were moved to this facility.\n\nThis is a 27m high tower, for training of offshore wind technicians.\n\nTests marine devices with three modified dry docks.\n\nFacilities that can perform independent performance and reliability assessments of full systems and components.\n\nThe blade testing facilities at National Renewable Energy Centre are designed to test wind turbine blades up to 100m in length. Blades are tested using a Compact Resonant Mass (CRM) system. ORE Catapult is working on a technique of blade testing known as \"Dual Axis\".\n\nORE Catapult is involved in a number of European funded research projects including Tidal EC, Optimus and LIFES50+.\n\nNarec staff have written papers which have appeared in journals and international energy conferences. These are mainly in the subjects of photovoltaics, wind, marine, and electrical infrastructure. A short list of some of these is given below:\n\n"}
{"id": "1681089", "url": "https://en.wikipedia.org/wiki?curid=1681089", "title": "Nuclear-powered aircraft", "text": "Nuclear-powered aircraft\n\nA nuclear-powered aircraft is a concept for an aircraft intended to be powered by nuclear energy. The intention was to produce a jet engine that would heat compressed air with heat from fission, instead of heat from burning fuel. During the Cold War, the United States and Soviet Union researched nuclear-powered bomber aircraft, the greater endurance of which could enhance nuclear deterrence, but neither country created any such operational aircraft.\n\nOne inadequately solved design problem was the need for heavy shielding to protect the crew and those on the ground from acute radiation syndrome; other potential problems included dealing with crashes.\n\nSome unmanned missile designs included nuclear powered supersonic cruise missiles.\n\nHowever, the advent of ICBMs, and nuclear submarines in the 1960s greatly diminished the strategic advantage of such aircraft, and respective projects were cancelled; the inherent danger of the technology has prevented its civilian use.\n\nIn May 1946, the United States Army Air Forces started the Nuclear Energy for the Propulsion of Aircraft (NEPA) project, which conducted studies until the Aircraft Nuclear Propulsion (ANP) program replaced NEPA in 1951. The ANP program included provisions for studying two different types of nuclear-powered jet engines: General Electric's Direct Air Cycle and Pratt & Whitney's Indirect Air Cycle. ANP planned for Convair to modify two B-36s under the MX-1589 project. One of the B-36s, the NB-36H, was to be used for studying shielding requirements for an airborne reactor, while the other was to be the X-6; however, the program was cancelled before the X-6 was completed.\n\nThe first operation of a nuclear aircraft engine occurred on January 31, 1956 using a modified General Electric J47 turbojet engine. The Aircraft Nuclear Propulsion program was terminated by Kennedy after the President's annual budget message to Congress in 1961.\n\nThe Oak Ridge National Laboratory researched and developed nuclear aircraft engines. Two shielded reactors powered two General Electric J87 turbojet engines to nearly full thrust. Two experimental engines complete with reactor system, HTRE 3 and HTRE 1, are at the EBR-1 facility south of the Idaho National Laboratory .\nThe U.S. designed these engines for use in a new, specially-designed nuclear bomber, the WS-125. Although Eisenhower eventually terminated it by cutting NEPA and telling Congress that the program was not urgent, he backed a small program for developing high temperature materials and high performance reactors; that program was terminated early in the Kennedy administration.\n\nIn 1957, the Air Force and the U.S. Atomic Energy Commission contracted with the Lawrence Radiation Laboratory to study the feasibility of applying heat from nuclear reactors to ramjet engines. This research became known as \"Project Pluto\". This program was to provide engines for an unmanned cruise missile, called SLAM, for Supersonic Low Altitude Missile. The program succeeded in producing two test engines, which were operated on the ground. On May 14, 1961, the world's first nuclear ramjet engine, \"Tory-IIA,\" mounted on a railroad car, roared to life for just a few seconds. On July 1, 1964, seven years and six months after it was born, \"Project Pluto\" was cancelled.\n\nThe 1 December 1958 issue of \"Aviation Week\" included an article, \"Soviets Flight Testing Nuclear Bomber\", that claimed that the Soviets had greatly progressed a nuclear aircraft program: \"[a] nuclear-powered bomber is being flight tested in the Soviet Union. Completed about six months ago, this aircraft has been flying in the Moscow area for at least two months. It has been observed both in flight and on the ground by a wide variety of foreign observers from Communist and non-Communist countries.\" Unlike the US designs of the same era, which were purely experimental, the article noted that \"The Soviet aircraft is a prototype of a design to perform a military mission as a continuous airborne alert warning system and missile launching platform.\" Photographs illustrated the article, along with technical diagrams on the proposed layout; these were so widely seen that one company produced a plastic model aircraft based on the diagrams in the article. An editorial on the topic accompanied the article.\n\nConcerns were soon expressed in Washington that \"the Russians were from three to five years ahead of the US in the field of atomic aircraft engines and that they would move even further ahead unless the US pressed forward with its own program\". These concerns caused continued but temporary funding of the US's own program.\n\nThe aircraft in the photographs was later revealed to be the conventional Myasishchev M-50 \"Bounder\", a medium-range strategic bomber that performed like the USAFs B-58 Hustler. The design was considered a failure, never entered service, and was revealed to the public on Soviet Aviation Day in 1963 at Monino, putting the issue to rest.\n\nThe Soviet program of nuclear aircraft development resulted in the experimental Tupolev Tu-119, or the Tu-95LAL (LAL- Летающая Атомная Лаборатория- Flying Nuclear Laboratory) which derived from the Tupolev Tu-95 bomber. It had 4 conventional turboprop engines and an onboard nuclear reactor. The Tu-119 completed 34 research flights, most of which were made with the reactor shut down. The main purpose of the flight phase was examining the effectiveness of the radiation shielding, which was one of the main concerns for the engineers. Massive shielding was needed in order to reduce radiation levels, and the obvious potential of the ICBM made the expensive program superfluous, and around the mid-1960s it was cancelled.\n\nSeveral other projects reached only the design phase.\n\nIn February 2018, Russian President Vladimir Putin claimed that Russia had developed a new, nuclear-powered cruise missile with nuclear warhead that can evade air and missile defenses and hit any point on the globe. According to the statements its first flight test occurred in 2017. It was claimed to feature \"a small-size super-powerful power plant that can be placed inside the hull of a cruise missile and guarantee a range of flight ten times greater than that of other missiles.\" The video showed the missile evading defense systems over the Atlantic, flying over Cape Horn and finally north towards Hawaii. To date there is no publicly available evidence to verify these statements. The Pentagon is aware of a Russian test of a nuclear-powered cruise missile but the system is still under development and had crashed in the Arctic in 2017. A RAND Corporation researcher specializing in Russia said \"My guess is they're not bluffing, that they've flight-tested this thing. But that's incredible.\" According to a CSIS fellow, such a nuclear powered missile \"has an almost unlimited range -- you could have it flying around for long periods of time before you order it to hit something\" Putin's statements and the video showing a concept of the missile in flight suggest that it is not a supersonic ramjet like Project Pluto but a subsonic vehicle with a nuclear-heated turbojet or turbofan engine.\n\nThe new cruise missile will be named Burevestnik (Thunderbird).\n\nLockheed-Martin announced, in 2014, that they were working on developing a small fusion reactor. They described it as being about the size of a jet engine and having the potential to power aircraft, spaceships, and cities. They expected it to be operating before 2024.\n\n\n\n"}
{"id": "44141826", "url": "https://en.wikipedia.org/wiki?curid=44141826", "title": "Nuyts Archipelago Wilderness Protection Area", "text": "Nuyts Archipelago Wilderness Protection Area\n\nNuyts Archipelago Wilderness Protection Area is a protected area located in the Nuyts Archipelago off the west coast of Eyre Peninsula in South Australia within to south-west of Ceduna. The wilderness protection area was proclaimed in August 2011 under the \"Wilderness Protection Act 1992\" in order to protect ‘important island habitat for species such as the stick-nest rat and brush-tailed bettongs (which are part of re-introduction programs) and species such as the carpet python and short-nosed bandicoot’ and habitat for ‘other notable species’ including the Australian sea lion and mutton birds. It was created on land both excised from the Nuyts Archipelago Conservation Park and land on Evans Island previously classed as unalienated Crown land with exception of a portion held by Australian Maritime Safety Authority for ‘lighthouse purposes’. The land excised from the Nuyts Archipelago Conservation Park comprised the following islands: Purdie Islands, Lound Island, Goat Island, Lacy Islands, Lilliput Island, Franklin Islands, Blefuscu Island, Egg Island, Freeling Island, Smooth Island, Dog Island, West Island, St Francis Island, Masillon Island, Fenelon Island and Hart Island. The Wilderness Protection Area is classified as an IUCN Category Ib protected area.\n\n"}
{"id": "45398313", "url": "https://en.wikipedia.org/wiki?curid=45398313", "title": "Odisha Solar Conference", "text": "Odisha Solar Conference\n\nThe Odisha Solar Conference (OSC) is a conference, the gathering of professionals to develop and promote solar power across Odisha. TiE (The Indus Entrepreneur), Bhubaneswar Chapter and Canyon Consultancy together organizes the Odisha Solar Conference every year to promote and create awareness amongst the local investors about the benefits from the solar industry. The conference is held every year in association with Odisha Electricity Regulatory Commission (OERC), Industrial Promotion & Investment Corporation of Odisha Limited (IPICOL), Grid Corporation of Odisha (GRIDCO) and supported by Ministry of New and Renewable Energy.\n\nThe Odisha Solar Conference have completed its three editions in 2012, 2013, and 2014.\n\nThe Organisers of the Odisha Solar Conference 2012 were Canyon Con, SEMI India & TiE Bhubaneswar.\n\nSEMI India was the Knowledge Partner for the Odisha Solar Conference 2012.\n\n\nThe Organisers of the Odisha Solar Conference 2013 were Canyon Consultancy, SEMI India & TiE Bhubaneswar.\n\nSEMI India was the Knowledge Partner for the Odisha Solar Conference 2013.\n\nNational Solar Mission and State Solar Policies <br>\nRenewable Purchase Obligation (RPO) & Renewable Energy Certificate (REC) Mechanism <br>\nBiomass Solar Hybrid Projects\nSolar Termal and Roof Top Solar PV <br>\nMW Scale Solar Roof-top Project in Twin City (Bhubaneswar-Cuttack) <br>\nMolten Salt based 24X7 Solar Thermal Project <br>\nCase Study of MW Scale Roof Top Solar in Gandhinagar <br>\nCase Study of 2.5kWp Roof Top Project in BJB Nagar, Bhubaneswar - Net Meter \nSolar Funding from National Agencies and International Bi-Lateral Agencies <br>\nRemote Area Electrification through Solar <br>\nGreen CSR (Corporate Social Responsibility) – Solar <br>\nCase Study of a Model Solar Village \n\nThe Organisers of the Odisha Solar Conference 2014 were Canyon Consultancy, SEMI India & TiE Bhubaneswar.\n\nSEMI India was the Knowledge Partner for the Odisha Solar Conference 2014.\n\n\n"}
{"id": "3118345", "url": "https://en.wikipedia.org/wiki?curid=3118345", "title": "Personnel halting and stimulation response rifle", "text": "Personnel halting and stimulation response rifle\n\nThe personnel halting and stimulation response rifle (PHASR) is a prototype non-lethal laser dazzler developed by the Air Force Research Laboratory's Directed Energy Directorate, U.S. Department of Defense. Its purpose is to temporarily disorient and blind a target. Blinding laser weapons have been tested in the past, but were banned under the 1995 UN Protocol on Blinding Laser Weapons, which the United States acceded to on 21 January 2009. The PHASR rifle, a low-intensity laser, is not prohibited under this regulation, as the blinding effect is intended to be temporary. It also uses a two-wavelength laser. The PHASR was tested at Kirtland Air Force Base, part of the Air Force Research Laboratory Directed Energy Directorate in New Mexico.\n\nIts name is likely derived from The Phaser in Star Trek\n\n\n"}
{"id": "216167", "url": "https://en.wikipedia.org/wiki?curid=216167", "title": "Raw material", "text": "Raw material\n\nA raw material, also known as a feedstock, unprocessed material, or primary commodity, is a basic material that is used to produce goods, finished products, energy, or intermediate materials which are feedstock for future finished products. As feedstock, the term connotes these materials are bottleneck assets and are highly important with regard to producing other products. An example of this is crude oil, which is a raw material and a feedstock used in the production of industrial chemicals, fuels, plastics, and pharmaceutical goods; lumber is a raw material used to produce a variety of products including all types of furniture.\n\nMetallic raw material production follows the processes such as crushing, roasting, magnetic separation, flotation, and leaching (at the first step), smelting and alloying (at the second step). \n\nThe term \"raw material\" denotes materials in minimally processed or unprocessed in states; e.g., raw latex, crude oil, cotton, coal, raw biomass, iron ore, air, logs, or water i.e. \"...any product of agriculture, forestry, fishing and any other mineral that is in its natural form or which has undergone the transformation required to prepare it for internationally marketing in substantial volumes.\"\n\nPlaces with plentiful raw materials and little economic development often show a phenomenon, known as \"Dutch disease\" or the \"resource curse\", that occurs when the economy of a country is mainly based upon its exports due to its method of governance. An example of this is the Democratic Republic of Congo as it is rich in raw materials; the Second Congo War focused on controlling these raw materials.\n\nRaw materials are also used by non-humans, such as birds using found objects and twigs to create nests.\n\n"}
{"id": "71777", "url": "https://en.wikipedia.org/wiki?curid=71777", "title": "Satyendra Nath Bose", "text": "Satyendra Nath Bose\n\nSatyendra Nath Bose, ( \"Sôtyendronath Bosu\", ; 1 January 1894 – 4 February 1974) was an Indian physicist specialising in theoretical physics. He is best known for his work on quantum mechanics in the early 1920s, providing the foundation for Bose–Einstein statistics and the theory of the Bose–Einstein condensate. A Fellow of the Royal Society, he was awarded India's second highest civilian award, the Padma Vibhushan in 1954 by the Government of India.\n\nThe class of particles that obey Bose–Einstein statistics, bosons, was named after Bose by Paul Dirac.\n\nA self-taught scholar and a polymath, he had a wide range of interests in varied fields including physics, mathematics, chemistry, biology, mineralogy, philosophy, arts, literature, and music. He served on many research and development committees in sovereign India.\n\nBose was born in Calcutta (now Kolkata), the eldest of seven children in a Bengali Kayastha family. He was the only son, with six sisters after him. His ancestral home was in the village Bara Jagulia, in the district of Nadia, in the state of West Bengal. His schooling began at the age of five, near his home. When his family moved to Goabagan, he was admitted into the New Indian School. In the final year of school, he was admitted into the Hindu School. He passed his entrance examination (matriculation) in 1909 and stood fifth in the order of merit. He next joined the intermediate science course at the Presidency College, Calcutta, where his teachers included Jagadish Chandra Bose, Sarada Prasanna Das, and Prafulla Chandra Ray. Naman Sharma and Meghnad Saha, from Dacca (Dhaka), joined the same college two years later. Prasanta Chandra Mahalanobis and Sisir Kumar Mitra were a few years senior to Bose. Bose chose mixed (applied) mathematics for his BSc and passed the examinations standing first in 1913 and again stood first in the MSc mixed mathematics exam in 1915. It is said that his marks in the MSc examination created a new record in the annals of the University of Calcutta, which is yet to be surpassed.\n\nAfter completing his MSc, Bose joined the University of Calcutta as a research scholar in 1916 and started his studies in the theory of relativity. It was an exciting era in the history of scientific progress. Quantum theory had just appeared on the horizon and important results had started pouring in.\n\nHis father, Surendranath Bose, worked in the Engineering Department of the East Indian Railway Company. In 1914, at age 20, Satyendra Nath Bose married Ushabati Ghosh, the 11-year-old daughter of a prominent Calcutta physician. They had nine children, two of whom died in early childhood. When he died in 1974, he left behind his wife, two sons, and five daughters.\n\nAs a polyglot, Bose was well versed in several languages such as Bengali, English, French, German and Sanskrit as well as the poetry of Lord Tennyson, Rabindranath Tagore and Kalidasa. He could play the \"esraj\", an Indian musical instrument similar to a violin. He was actively involved in running night schools that came to be known as the Working Men's Institute.\n\nBose attended Hindu School in Calcutta, and later attended Presidency College, also in Calcutta, earning the highest marks at each institution, while fellow student and future astrophysicist Meghnad Saha came second. He came in contact with teachers such as Jagadish Chandra Bose, Prafulla Chandra Ray and Naman Sharma who provided inspiration to aim high in life. From 1916 to 1921, he was a lecturer in the physics department of the University of Calcutta. Along with Saha, Bose prepared the first book in English based on German and French translations of original papers on Einstein's special and general relativity in 1919. In 1921, he joined as Reader of the department of Physics of the recently founded University of Dhaka (in present-day Bangladesh). Bose set up whole new departments, including laboratories, to teach advanced courses for MSc and BSc honours and taught thermodynamics as well as James Clerk Maxwell's theory of electromagnetism.\n\nSatyendra Nath Bose, along with Saha, presented several papers in theoretical physics and pure mathematics from 1918 onwards. In 1924, while working as a Reader (Professor without a chair) at the Physics Department of the University of Dhaka, Bose wrote a paper deriving Planck's quantum radiation law without any reference to classical physics by using a novel way of counting states with identical particles. This paper was seminal in creating the very important field of quantum statistics. Though not accepted at once for publication, he sent the article directly to Albert Einstein in Germany. Einstein, recognising the importance of the paper, translated it into German himself and submitted it on Bose's behalf to the prestigious \"Zeitschrift für Physik\". As a result of this recognition, Bose was able to work for two years in European X-ray and crystallography laboratories, during which he worked with Louis de Broglie, Marie Curie, and Einstein.\n\nWhile presenting a lecture at the University of Dhaka on the theory of radiation and the ultraviolet catastrophe, Bose intended to show his students that the contemporary theory was inadequate, because it predicted results not in accordance with experimental results.\n\nIn the process of describing this discrepancy, Bose for the first time took the position that the Maxwell–Boltzmann distribution would not be true for microscopic particles, where fluctuations due to Heisenberg's uncertainty principle will be significant. Thus he stressed the probability of finding particles in the phase space, each state having volume , and discarding the distinct position and momentum of the particles.\n\nBose adapted this lecture into a short article called \"Planck's Law and the Hypothesis of Light Quanta\" and sent it to Albert Einstein with the following letter:\nEinstein agreed with him, translated Bose's paper \"Planck's Law and Hypothesis of Light Quanta\" into German, and had it published in \"Zeitschrift für Physik\" under Bose's name, in 1924.\n\nThe reason Bose's interpretation produced accurate results was that since photons are indistinguishable from each other, one cannot treat any two photons having equal energy as being two distinct identifiable photons. By analogy, if in an alternate universe coins were to behave like photons and other bosons, the probability of producing two heads would indeed be one-third (tail-head = head-tail).\n\nBose's interpretation is now called Bose–Einstein statistics. This result derived by Bose laid the foundation of quantum statistics, and especially the revolutionary new philosophical conception of the indistinguishability of particles, as acknowledged by Einstein and Dirac. When Einstein met Bose face-to-face, he asked him whether he had been aware that he had invented a new type of statistics, and he very candidly said that no, he wasn't that familiar with Boltzmann's statistics and didn't realize that he was doing the calculations differently. He was equally candid with anyone who asked.\n\nEinstein also did not at first realize how radical Bose's departure was, and in his first paper after Bose, he was guided, like Bose, by the fact that the new method gave the right answer. But after Einstein's second paper using Bose's method in which Einstein predicted the Bose–Einstein condensate (\"pictured left\"), he started to realize just how radical it was, and he compared it to wave/particle duality, saying that some particles didn't behave exactly like particles. Bose had already submitted his article to the British Journal \"Philosophical Magazine\", which rejected it, before he sent it to Einstein. It is not known why it was rejected.\n\nEinstein adopted the idea and extended it to atoms. This led to the prediction of the existence of phenomena which became known as Bose–Einstein condensate, a dense collection of bosons (which are particles with integer spin, named after Bose), which was demonstrated to exist by experiment in 1995.\n\nAfter his stay in Europe, Bose returned to Dhaka in 1926. He did not have a doctorate, and so ordinarily, under the prevailing regulations, he would not be qualified for the post of Professor he applied for, but Einstein recommended him. He was then made Head of the Department of Physics at Dhaka University. He continued guiding and teaching at Dhaka University.\n\nBose designed equipment himself for an X-ray crystallography laboratory. He set up laboratories and libraries to make the department a center of research in X-ray spectroscopy, X-ray diffraction, magnetic properties of matter, optical spectroscopy, wireless, and unified field theories. He also published an equation of state for real gases with Meghnad Saha. He was also the Dean of the Faculty of Science at Dhaka University until 1945.\n\nWhen the partition of India became imminent (1947), he returned to Calcutta and taught there until 1956. He insisted every student design his own equipment using local materials and local technicians. He was made professor emeritus on his retirement. He then became Vice-Chancellor of Visva-Bharati University in Santiniketan. He returned to the University of Calcutta to continue research in nuclear physics and complete earlier works in organic chemistry. In subsequent years, he worked in applied research such as extraction of helium in hot springs of Bakreshwar.\n\nApart from physics, he did some research in biotechnology and literature (Bengali and English). He made deep studies in chemistry, geology, zoology, anthropology, engineering and other sciences. Being Bengali, he devoted a lot of time to promoting Bengali as a teaching language, translating scientific papers into it, and promoting the development of the region.\nIn 1937, Rabindranath Tagore dedicated his only book on science, \"Visva–Parichay\", to Satyendra Nath Bose. Bose was honoured with title Padma Vibhushan by the Indian Government in 1954. In 1959, he was appointed as the National Professor, the highest honour in the country for a scholar, a position he held for 15 years. In 1986, the S.N. Bose National Centre for Basic Sciences was established by an act of Parliament, Government of India, in Salt Lake, Calcutta.\n\nBose became an adviser to then newly formed Council of Scientific and Industrial Research. He was the President of Indian Physical Society and the National Institute of Science. He was elected General President of the Indian Science Congress. He was the Vice-President and then the President of Indian Statistical Institute. In 1958, he became a Fellow of the Royal Society. He was nominated as member of Rajya Sabha.\n\nPartha Ghose has stated that\n\nS.N. Bose was nominated by K. Banerji (1956), D.S. Kothari (1959), S.N. Bagchi (1962) and A.K. Dutta (1962) for the Nobel Prize in Physics, for his contribution to Bose–Einstein statistics and the unified field theory. For instance, Kedareswar Banerjee, head of the Physics Department, University of Allahabad, in a letter of 12 January 1956 wrote to the Nobel Committee as follows: “(1). He (Bose) made very outstanding contributions to Physics by developing the statistics known after his name as Bose statistics. In recent years this statistics is found to be of profound importance in the classifications of fundamental particles and has contributed immensely in the development of nuclear physics. (2). During the period from 1953 to date he has made a number of highly interesting contributions of far-reaching consequences on the subject of Einstein’s Unitary Field Theory.” Bose's work was evaluated by an expert of the Nobel Committee, Oskar Klein, who did not see his work worthy of a Nobel Prize.\n\nBosons, a class of elementary subatomic particles in particle physics were named after Satyendra Nath Bose to commemorate his contributions to science.\n\nAlthough several Nobel Prizes were awarded for research related to the concepts of the boson, Bose–Einstein statistics and Bose–Einstein condensate, Bose himself was not awarded a Nobel Prize.\n\nIn his book \"The Scientific Edge\", physicist Jayant Narlikar observed: \n\n"}
{"id": "4878884", "url": "https://en.wikipedia.org/wiki?curid=4878884", "title": "Scott-T transformer", "text": "Scott-T transformer\n\nA Scott-T transformer (also called a Scott connection) is a type of circuit used to produce two-phase electric power ( 2 φ, 90 degree phase rotation) from a three-phase ( 3 φ, 120 degree phase rotation) source, or vice versa. The Scott connection evenly distributes a balanced load between the phases of the source. The Scott three-phase transformer was invented by a Westinghouse engineer Charles F. Scott in the late 1890s to bypass Thomas Edison's more expensive rotary converter and thereby permit two-phase generator plants to drive three-phase motors.\n\nAt the time of the invention, two-phase motor loads also existed and the Scott connection allowed connecting them to newer three-phase supplies with the currents equal on the three phases. This was valuable for getting equal voltage drop and thus feasible regulation of the voltage from the electric generator (the phases cannot be varied separately in a three-phase machine). Nikola Tesla's original polyphase power system was based on simple-to-build two-phase four-wire components. However, as transmission distances increased, the more transmission-line efficient three-phase system became more common. (Three phase power can be transmitted with only three wires, where the two-phase power systems required four wires, two per phase.) Both 2 φ and 3 φ components coexisted for a number of years and the Scott-T transformer connection allowed them to be interconnected.\n\nAssuming the desired voltage is the same on the two and three phase sides, the Scott-T transformer connection (shown right) consists of a centre-tapped 1:1 ratio main transformer, T1, and a /2 (≈86.6%) ratio teaser transformer, T2. The centre-tapped side of T1 is connected between two of the phases on the three-phase side. Its centre tap then connects to one end of the lower turn count side of T2, the other end connects to the remaining phase. The other side of the transformers then connect directly to the two pairs of a two-phase four-wire system.\n\nTwo-phase motors draw constant power, just as three-phase motors do, so a balanced two-phase load is converted to a balanced three-phase load. However if a two-phase load is not balanced (more power drawn from one phase than the other), no arrangement of transformers (including the Scott-T transformers) can restore balance: Unbalanced current on the two-phase side causes unbalanced current on the three-phase side. Since the typical two-phase load was a motor, the current in the two phases was presumed inherently equal during the Scott-T development.\n\nIn modern times people have tried to revive the Scott connection as a way to power single-phase electric railways from three-phase Utility supplies. This will not result in balanced current on the three-phase side, as it is unlikely that two different railway sections, each connected as two-phase, will at all times conform to the Scott presumption of being equal. The instantaneous difference in loading on the two sections will be seen as an imbalance in the three-phase supply; there is no way to smooth it out with transformers.\n\nThe Scott-T transformer connection may be also be used in a back-to-back T-to-T arrangement for a three-phase to three-phase connection. This is a cost-saving in the lower-power transformers due to the two-coil T connected to a secondary two-coil T instead of the traditional three-coil primary to three-coil secondary transformer. In this arrangement the X0 neutral tap is part way up on the secondary teaser transformer (see right). The voltage stability of this T-to-T arrangement as compared to the traditional three-coil primary to three-coil secondary transformer is questioned, as the \"per unit\" impedance of the two windings (primary and secondary, respectively) \"are not\" the same in a T-to-T configuration, whereas the three windings (primary and secondary, respectively) \"are\" the same in a three transformer configuration, if the three transformers are identical.\n\nThree-phase to three-phase (also called \"T-connected\") distribution transformers are seeing increasing applications. The primary \"must\" be delta-connected (Δ), but the secondary \"may be\" either delta or “wye”-connected (Y), at the customer's option, with X0 providing the neutral for the “wye” case. Taps for either case are usually provided. The customary maximum capacity of such a distribution transformer is 333 kV A (a third of a megawatt).\n\n"}
{"id": "1905327", "url": "https://en.wikipedia.org/wiki?curid=1905327", "title": "Self-sealing fuel tank", "text": "Self-sealing fuel tank\n\nUsed primarily in aviation, self-sealing is a technology—in wide use since World War II—that prevents fuel tanks or bladders from leaking fuel and igniting after being damaged by enemy fire.\n\nTypical self-sealing tanks have multiple layers of rubber and reinforcing fabric, one of vulcanized rubber, and one of untreated natural rubber, which can absorb fuel, swell, and expand when it comes into contact with the fuel. When a fuel tank is punctured, the fuel seeps into the layers, causing the untreated layer to swell and thus seal the puncture.\n\nGeorge J. Murdock applied for the patent \"War Aeroplane Fuel Tanks\" on February 7, 1917 but was temporarily blocked by an order of the Federal Trade Commission, on February 6, 1918, to keep any discussion or publication of the invention secret. The order was rescinded by the United States Patent Office on September 26, 1918 and Murdock was eventually granted United States Patent 1,386,791 \"Self-Puncture Sealing Covering for Fuel-Containers\" on August 9, 1921. Military aircraft built by the Glenn L. Martin Company used this self-sealing fuel tank.\n\nIn the newer generations of pre-war and early-war aircraft, self-sealing tanks were tanks used to minimize the damage from leaking or burning fuel. A conventional fuel tank, when hit by gunfire, could leak fuel rapidly. This would not only reduce the aircraft's effective range, but was also a significant fire hazard. Damaged fuel tanks could also rupture, destroying the airframe or critically affecting flight characteristics.\n\nIt was realized that, because of weight limitations, it was not practical to simply add armor plate to aircraft fuel tanks; a method of stopping fuel leaking from damaged tanks was necessary.\n\nEarly attempts at protecting fuel tanks consisted of using metal tanks, covered inside or outside by a material that expanded after being pierced. Research revealed that the \"exit\" of the projectile, rather than the entry, was the greater problem, as it often tumbled, thus creating a large exit hole. Among the earliest versions of these types of tanks were those manufactured in the UK at Portsmouth airport by Fireproof Tanks Ltd. These tanks were first installed in the Fairey Battle light bomber with other versions installed in Supermarine Spitfire and Hawker Hurricane fighters and larger aircraft such as the Avro Lancaster heavy bomber. The Henderson Safety Tank company provided crash-proof self-sealing tanks for the Miles Master trainer.\n\nThe Germans were using layers of rubber laid over leather hide with a treated fibre inner surface for the self-sealing tanks on their Junkers Ju 88 bombers early in the war.\nIn the US, Ernst Eger of United States Rubber Company (later Uniroyal) patented a self-sealing fuel tank design in 1941; one of many companies involved in developing this technology during the war. Goodyear chemist James Merrill filed a patent in 1941 (published in 1947) for refining and successfully testing his method for manufacturing self-sealing tanks using a two-layer system of rubber compounds encased in a metal outer shell or the wing lining of the aircraft. In 1942, he received a War Production Board citation from President Roosevelt and the Goodyear tanks were subsequently placed in service in Goodyear-produced Corsair fighters, as well as other aircraft. By 1942 Fireproof Tanks had developed the first flexible fuel bladders as range extender tanks for the Mk IX Spitfire. These tanks were flexible containers, made of a laminated self-sealing material like vulcanized rubber and with as few seams as possible to minimize leak paths.\n\nAs early tests showed that impact could overpressurize a fuel tank, the self-sealing fuel cell is suspended, allowing it to absorb shocks without rupture. U.S. Navy fuel tanks during the war were able to withstand bullets and, on occasion, cannon shells.\n\nNot all fighters were fitted with the relatively new invention. Self-sealing tanks tended to be heavier with lower capacity than non-sealed tanks. Nonetheless, aircraft that were fitted with self-sealing tanks regularly took more punishment than those without, and were able to return to base. Combat experience in the Pacific war showed that the heavily protected American aircraft could sustain far more damage than the lightly armored Japanese designs without self-sealing fuel tanks (for instance, the Mitsubishi A6M Zero).\n\nThe same principles were applied to give self-sealing fuel lines in aircraft (MIL-PRF-7061C).\n\nMost jet fighters and all US military rotary wing aircraft have some type of self-sealing tanks. Military rotary wing fuel tanks have the additional feature of being crashworthy. High altitudes require the tanks to be pressurized, making self-sealing difficult. Newer technologies have brought advances like inert foam-filled tanks to prevent detonation. This foam is an open cell foam that effectively divides the gas space above the remaining fuel into thousands of small spaces, none of which contain sufficient vapour to support combustion. This foam also serves to reduce fuel slosh. Major manufacturers of this technology include Hutchinson, Amfuel (Zodiac) (formerly Firestone), Meggitt (formerly Goodyear), Robertson Fuel Systems, GKN USA, and FPT Industries. FPT is now part of GKN. For military use, tanks are qualified to MIL-DTL-27422 (includes crashworthiness requirements) or MIL-DTL-5578 (non-crashworthy). An aircraft fuel tank sometimes consists of several interconnected fuel cells. The interconnecting hoses are typically also self-sealing.\n\nIn addition to fighter aircraft some military patrol vehicles and armoured VIP limousines feature self-sealing fuel tanks.\nSelf-sealing fuel tanks using military technology are also required in some motorsport categories.\n\n\n"}
{"id": "25098268", "url": "https://en.wikipedia.org/wiki?curid=25098268", "title": "South East Water", "text": "South East Water\n\nSouth East Water is a UK supplier of drinking water to 2.2 million consumers in Kent, Sussex, Surrey, Hampshire and Berkshire and is a private limited company registered in England and Wales with company number 02679874.\n\nEach day the company supplies on average 521 million litres of drinking water from its 83 water treatment works and manages more than 14,500 kilometres (about 9,000 miles) of its water mains. The company's supply area covers 5,657 square kilometres. The company takes water from rivers, reservoirs and underground sources (aquifers) under abstraction licences issued by the Environment Agency.\n\nThe present company came into existence in December 2007 by a merger of Mid Kent Water and an earlier separate company with the name of South East Water, thus uniting two water companies in the South East of England. It is owned jointly by Vantage Infrastructure and the Utilities Trust of Australia (UTA). UTA is managed by H. R. L. Morrison & Co and is not stock exchange listed; it was established in 1994 and is one of Australia’s first infrastructure investment funds, with approximately A$2-billion in funds under management, with investments in Australia, the US, UK and Europe.\n\n"}
{"id": "1323610", "url": "https://en.wikipedia.org/wiki?curid=1323610", "title": "Sustainable yield", "text": "Sustainable yield\n\nThe sustainable yield of natural capital is the ecological yield that can be extracted without reducing the base of capital itself, i.e. the surplus required to maintain ecosystem services at the same or increasing level over time. This yield usually varies over time with the needs of the ecosystem to maintain itself, e.g. a forest that has recently suffered a blight or flooding or fire will require more of its own ecological yield to sustain and re-establish a mature forest. While doing so, the sustainable yield may be much less.\n\nIn forestry terms it is the largest amount of harvest activity that can occur without degrading the productivity of the stock.\n\nThis concept is important in fishery management, in which sustainable yield is defined as the number of fish that can be extracted without reducing the base of fish stock, and the maximum sustainable yield is defined as the amount of fish that can be extracted under given environmental conditions. In fisheries, the basic natural capital or virgin population, must decrease with extraction. At the same time productivity increases. Hence, sustainable yield would be within the range in which the natural capital together with its production are able to provide satisfactory yield. It may be very difficult to quantify sustainable yield, because every dynamic ecological conditions and other factors not related to harvesting induce changes and fluctuations in both, the natural capital and its productivity.\n\nIn the case of groundwater there is a safe yield of water extraction per unit time, beyond which the aquifer risks the state of overdrafting or even depletion.\n\n"}
{"id": "46818814", "url": "https://en.wikipedia.org/wiki?curid=46818814", "title": "Syed Ali Nawab", "text": "Syed Ali Nawab\n\nMajor-General Syed Ali Nawab (Urdu: سید علی نواب;b. 6 October 1925– 22 February 1994) , was an engineering officer in the Pakistan Army Corps of EME, and a mechanical engineer who was known for his classified works in the development of atomic bomb at the Engineering Research Laboratories (ERL) in the 1970s.\n\nHe is associated with his research work in the Engineering Research Laboratories (ERL), mainly working on the operations of the computer numerical control (CNC) machines throughout his career. Earlier in his career, he was posted twice as the military liaison officer at the High Commission of Pakistan in London in the United Kingdom, for the British Army. He is known for using his influence as DG EME by carefully selecting and deputing the EME officers to staff ERL. In addition, known for appointing staff in London and Germany to help ERL import equipment\n\nAmong his colleagues at the Khan Research Laboratories (KRL), he had reputation of being a qualified machinist and a competent engineer who sought quick solutions, and later worked as consultant engineer on electric power production and quality assurance at the Ministry of Defence Production of Government of Pakistan for many years.\n\nSyed Ali Nawab was born in Budaun, Uttar Pradesh in British India, into an Urdu-speaking family on 6 October 1925. He was married to Razia Jaffery, an Army Captain and graduate of King Edward Medical College who belonged to a family from Khyber Pakhtunkhwa. Nawab went to attend Aligarh Muslim University (AMU) after his matriculation in 1941–43. He initially studied physics and graduated with BSc in physics in 1946, before attending the engineering college. In 1948, he graduated with B.S. in electrical engineering and emigrated to Pakistan in 1949. In 1950, he joined the Pakistan Military Academy (PMA) in Kakul, and graduated at the top of his class.\n\nIn 1951, Nawab was commissioned in the Pakistan Army's Corps of Electrical and Mechanical Engineering (PEME) and was one of the few army officers directed by the Pakistani military to attend the Loughborough University where he gained MSc in mechanical engineering in 1954. He was admitted as the \"MIMechE:\" at the Institution of Mechanical Engineers (IMechE) in the United Kingdom.\n\nUpon returning to Pakistan in 1954, Major Nawab was appointed as inspector of vehicle and engineering equipment in the Pakistan Army, having responsible for quality inspection and equipment for the military vehicles. In 1955–56, Major Nawab was later posted in the Army GHQ as a controller of inspection and technical development.\n\nIn 1957–60, Major Nawab was first directed to attend the Royal Military College of Science in Shrivenham in England to study machine design components on the military vehicles, and was then sent to attend the Aberdeen Proving Ground, the United States Army facility, located in Maryland, in the United States. At the Aberdeen Proving Ground in Maryland, Major Nawab attended the Ordnance Officer Career Course, and qualified as an ordnance specialist.\n\nIn 1960–64, Lieutenant-Colonel Nawab was appointed assistant director of the EME director at the Army GHQ. In 1965, Lt-Col. Nawab participated in the second war with India, responsible for managing military ordnance and inspections of the military vehicles.\n\nIn 1965, Colonel Nawab was directed by the Minister of Defence (MoD) to join the staff of the High Commission of Pakistan in London as a military liaison officer for the British Army. Col. Nawab served in this assignment until 1971 when he returned to his country to participate in the third war with India.\n\nAfter the third war with India in 1971, Col. Nawab was posted back at the Corps of Electrical and Mechanical Engineering as an inspector-general for inspection for the military equipment and vehicles at the Army GHQ, later promoted as one-star rank general, Brigadier, in 1972–75.\n\nIn 1975, Nawab was promoted to the rank of two star or Major General as DG Military Vehicles Research and Development Establishment.\n\nSince, Prime Minister Bhutto had placed the nuclear weapons project directly under Mr Ghulam Ishaq Khan's control rather than the Army, Nawab's first appointment as a Major General was in the Ministry of Defense as DG MVRDE in 1975, where he could work directly with the newly appointed Secretary of Defense, Mr Ghulam Ishaq Khan at the Ministry of Defense without arousing suspicion\n\nNawab was transferred to the position of Director General Corps of Electrical and Mechanical Engineering (EME) on May 6, 1976 until 6 December 1976. During this time, then-Defence Secretary Ghulam Ishaq Khan directed Major-General Nawab to supervise the establishing of Engineering Research Laboratories (ERL); and made him responsible for procuring metallurgical equipments, elemental ores, and metalworking that was crucial for scientific and research work at the ERL. General Zia who was recently promoted to COAS on March 1, 1976 was instructed by the Secretary of Defense, Mr. Ghulam Ishaq Khan to transfer Nawab to the post of DG EME in the Army so Nawab could perform these functions and use his British connections to the British Ministry of Defence to import and procure industrial equipments, and the computerized numerical control machines from the United Kingdom that were installed in the ERL.\n\nAt the ERL, Nawab established the machine shop at the ERL, and was noted among the civilian scientists as competent mechanical engineer and able machinist, while working on the machine design components that were crucial for the feasibility of the gas centrifuges, where Nawab designed and built the machine components using the lathe, drill press, bandsaw, and the CNC machines. Major-General Nawab officiated his role towards establishing the engineering branch at the KRL as a senior engineer and researcher while partially completing the engineering staffing composed of EME army officers.\n\nMajor-General Nawab also used his influence as DG EME in carefully selecting and deputing EME officers as to be posted as military liaison officers and staff at the Office of Military Procurement (PALTO) that was used by the ERL at the High Commission of Pakistan in the United Kingdom. All this was done clandestinely, without Dr A.Q. Khan knowing that Nawab was actually DG EME to maintain deniability. Brigadier Islamullah Khan of EME assisted in maintaining the clandestine aspect of this operation and in building ERL. He as well as other EME officers who assisted were recommended and later promoted to the rank of Major General.\n\nIn 1977–78, Major-General Nawab was moved to be appointed as Chairman of Pakistan Ordnance Factories (POF) but remain associated with his work at the ERL. COAS General Zia was instructed by Secretary Defence, Ghulam Ishaq Khan to recommend this transfer. Nawab used his appointment at POFs to make additional personnel allocations to ERL and to procure ores of uranium in the country, and relocating them at a secure location for the expansion of nuclear infrastructure.\n\nIn 1978, during General Zia's military regime, Major-General Nawab was superseded from his rank, as junior officers were promoted to higher ranks. However, Nawab was given an extension of three years to resume his classified works with the KRL.. This was unsurprising since Prime Minister Bhutto and General Tikka Khan had both been jailed; and Nawab's boss Defense Secretary Ghulam Ishaq Khan was moved to the Ministry of Finance. Subsequently, Ghulam Ishaq Khan had to bring Zia up to speed on details of the project and convince Zia to give Nawab the extension.\n\nIn 1981, Major-General Nawab again provided a crucial technical support when he assisted the KRL scientists in redesigning, and eventually machining of the gyrational beds and bearing components of the gas centrifuges with the goal of developing powerful and effective methods of gaseous method that were employed in the Uranium enrichment.\n\nIn 1981, Major-General Nawb was again posted by the Ministry of Defence as the military liaison officer at the High Commission of Pakistan in the United Kingdom, working closely with maintaining Pakistan Army's military relations with British Army. His assignment did not last long, and eventually decided to seek retirement from his military service with the Army in 1983.\n\nAfter his retirement, Nawab found the small engineering consulting firm, the Experts Advisory Cell (EAC), where he worked for the Government of Pakistan as a consultant engineer to advise and monitor state owned enterprises. Later, he became involved in consulting on the electricity manufacturing and electric power production to the Ministry of Industries and Production. He also co-authored a paper while consulting on the industrial nuclear power generation to the Ministry of Finance as he opined: \"Evaluating Public Manufacturing Enterprises: An experimental monitoring system\". In addition, the contributions of Nawab's and his firm, the EAC, to industrialization of Pakistan were recognized by the World Bank and IMF in the 1983 World Development Report.\n\nHe later consulted the Ministry of Defence Production on product safety and quality assurance for many years, until living a quiet live in Karachi in 1990.\n\nOn 22 February 1994, Nawab passed away at his estate in Karachi, and was buried in Military Cemetery in DHA Society in Karachi, Sindh, Pakistan. For many years, Nawab's work and role at the KRL was not known to the public and details of his work was kept well hidden until the memoirs were published by dr. AQ Khan in 2009.\n\nAccording to the various admission, Nawab often used the codename: \"Anis Nawab\", to hide his identity while working on classified works at the ERL, when he reportedly met with journalist Peter Griffin to discuss the issue of industrialization in Pakistan.\n\n\n"}
{"id": "6043761", "url": "https://en.wikipedia.org/wiki?curid=6043761", "title": "Texas Low Emission Diesel standards", "text": "Texas Low Emission Diesel standards\n\nTexas Low Emission Diesel standards (TxLED) are rules regulating the quality of diesel fuels, intended to reduce pollutants (especially NOx). Since October 31, 2005, diesel fuel to be consumed by engines in 110 counties in Eastern Texas must meet these requirements:\n\n\nAlternatively, diesel fuel that complies with the specifications of a California Air Resources Board (CARB) certified alternative diesel formulation that was approved by CARB before January 18, 2005 may be used, as can fuel approved by the Texas Commission on Environmental Quality (TCEQ) that is proven to have emissions equivalent to or less than TxLED compliant fuel.\n"}
{"id": "8974112", "url": "https://en.wikipedia.org/wiki?curid=8974112", "title": "The Hopewell Project", "text": "The Hopewell Project\n\nThe Hopewell Project is a solar-powered residence in North America that generates hydrogen for subsequent reconversion into electricity, meeting all of the home's power needs, including heating and cooling, through renewable solar energy. The solar/hydrogen-powered home is located northwest of Hopewell, New Jersey in East Amwell Township, cost $500,000 and was dedicated on October 20, 2006.\n\nThe Hopewell Project is an organization of private citizens advocating the adoption of renewable energy technologies. The Hopewell Project does not advocate a particular renewable energy technology.\n\nThe Solar-Hydrogen Residence that has been set up and is operating in Hopewell, New Jersey combines photovoltaic solar, electrolyzer, fuel cell, computer software, and other technologies that have been carefully selected to work in concert to make the renewable energy installation 100% reliant on renewable energy sources for the home's energy needs, negating the need for utility delivered non-renewable energy sources.\n\nThe New Jersey project, which opened in October 2006 after four years of planning and building, cost around $500,000, some $225,000 of which was provided by the New Jersey Board of Public Utilities. The project also got equipment and expertise from a number of commercial sponsors including Exide, which donated some $50,000 worth of batteries, and Swagelok, an Ohio company that provided stainless steel piping costing around $28,000. Michael Strizki, the project promoter, contributed about $100,000 of his own money.\n\nIn the summer, the solar panels generate 60% more electricity than the super-insulated house needs. The excess is stored in the form of hydrogen which is used in the winter—when the solar panels can't meet all the domestic demand—to make electricity in the fuel cell.\n\nThe Hopewell Project is currently developing a complete solar-hydrogen-fuel cell turnkey system that could be installed on an average home. The target is to bring the system to market by 2008, for the approximate price of a mid-range automobile (considerably lower than the price for the initial system).\n\n\n"}
{"id": "15357916", "url": "https://en.wikipedia.org/wiki?curid=15357916", "title": "The Phenomenon of Man", "text": "The Phenomenon of Man\n\nThe Phenomenon of Man (\"Le phénomène humain\") is a 1955 book written by the French philosopher, paleontologist and Jesuit priest Pierre Teilhard de Chardin. In this work, Teilhard describes evolution as a process that leads to increasing complexity, culminating in the unification of consciousness.\n\nThe book was finished in the 1930s, but was published posthumously in 1955, and translated into English in 1959. The Roman Catholic Church initially prohibited the publication of some of Teilhard's writings on the grounds that they contradicted orthodoxy.\n\nThe foreword to the book was written by one of the key advocates for natural selection and evolution of the 20th century, and a co-developer of the modern synthesis in biology, Julian Huxley.\n\nTeilhard views evolution as a process that leads to increasing complexity. From the cell to the thinking animal, a process of psychical concentration leads to greater consciousness. The emergence of \"Homo sapiens\" marks the beginning of a new age, as the power acquired by consciousness to turn in upon itself raises mankind to a new sphere. Borrowing Huxley’s expression, Teilhard describes humankind as evolution becoming conscious of itself.\nIn Teilhard's conception of the evolution of the species, a collective identity begins to develop as trade and the transmission of ideas increases. Knowledge accumulates and is transmitted in increasing levels of depth and complexity. This leads to a further augmentation of consciousness and the emergence of a thinking layer that envelops the earth. Teilhard calls the new membrane the “noosphere” (from the Greek “\"nous\"”, meaning mind), a term first coined by Vladimir Vernadsky. The noosphere is the collective consciousness of humanity, the networks of thought and emotion in which all are immersed. \nThe development of science and technology causes an expansion of the human sphere of influence, allowing a person to be simultaneously present in every corner of the world. Teilhard argues that humanity has thus become cosmopolitan, stretching a single organized membrane over the Earth. Teilhard describes the process by which this happens as a \"gigantic psychobiological operation, a sort of mega-synthesis, the “super-arrangement” to which all the thinking elements of the earth find themselves today individually and collectively subject\". The rapid expansion of the noosphere requires a new domain of psychical expansion, which \"is staring us in the face if we would only raise our heads to look at it\".\n\nIn Teilhard’s view, evolution will culminate in the Omega Point, a sort of supreme consciousness. Layers of consciousness will converge in Omega, fusing and consuming them in itself. The concentration of a conscious universe will reassemble in itself all consciousnesses as well as all that we are conscious of. Teilhard emphasizes that each individual facet of consciousness will remain conscious of itself at the end of the process.\n\nIn 1961, the Nobel Prize-winner Peter Medawar, a British immunologist, wrote a scornful review of the book for the journal \"Mind\", calling it \"a bag of tricks\" and saying that the author had shown \"an active willingness to be deceived\": \"the greater part of it, I shall show, is nonsense, tricked out with a variety of metaphysical conceits, and its author can be excused of dishonesty only on the grounds that before deceiving others he has taken great pains to deceive himself\".\n\nThe evolutionary biologist Richard Dawkins called Medawar's review \"devastating\", and \"The Phenomenon of Man\" \"the quintessence of bad poetic science\".\n\nIn the June 1995 issue of \"Wired\", Jennifer Cobb Kreisberg said, \"Teilhard saw the Net coming more than half a century before it arrived\":\nTeilhard imagined a stage of evolution characterized by a complex membrane of information enveloping the globe and fueled by human consciousness. It sounds a little off-the-wall, until you think about the Net, that vast electronic web encircling the Earth, running point to point through a nerve-like constellation of wires.\n\nIn July 2009, during a vespers service in Aosta Cathedral in northern Italy, Pope Benedict XVI, reflecting on the Epistle to the Romans in which \"St. Paul writes that the world itself will one day become a form of living worship\", commented on Teilhard:\nIt's the great vision that later Teilhard de Chardin also had: At the end we will have a true cosmic liturgy, where the cosmos becomes a living host. Let's pray to the Lord that he help us be priests in this sense, to help in the transformation of the world in adoration of God, beginning with ourselves.\n"}
{"id": "16818862", "url": "https://en.wikipedia.org/wiki?curid=16818862", "title": "USAF Stability and Control DATCOM", "text": "USAF Stability and Control DATCOM\n\nThe United States Air Force Stability and Control DATCOM is a collection, correlation, codification, and recording of best knowledge, opinion, and judgment in the area of aerodynamic stability and control prediction methods. It presents substantiated techniques for use (1) early in the design or concept study phase, (2) to evaluate changes resulting from proposed engineering fixes, and (3) as a training on crosstraining aid. It bridges the gap between theory and practice by including a combination of pertinent discussion and proven practical methods. For any given configuration and flight condition, a complete set of stability and control derivatives can be determined without resort to outside information.\n\nA spectrum of methods is presented, ranging from very simple and easily applied techniques to quite accurate and thorough procedures. Comparatively simple methods are presented in complete form, while the more complex methods are often handled by reference to separate treatments. Tables which compare calculated results with test data provide indications of method accuracy. Extensive references to related material are also included.\n\nThe report was compiled from September 1975 to September 1977 by the McDonnell Douglas Corporation in conjunction with the engineers at the Flight Dynamics Laboratory at Wright-Patterson Air Force Base.\n\nFundamentally, the purpose of the DATCOM (Data Compendium), is to provide a systematic summary of methods for estimating basic stability and control derivatives. The DATCOM is organized in such a way that it is self-sufficient. For any given flight condition and configuration the complete set of derivatives can be determined without resort to outside information. The book is intended to be used for preliminary design purposes before the acquisition of test data. The use of reliable test data in lieu of the DATCOM is always recommended. However, there are many cases where the DATCOM can be used to advantage in conjunction with test data.\n\nFor instance, if the lift-curve slope of a wing-body combination is desired, the DATCOM recommends that the lift-curve slopes of the isolated wing and body, respectively, be estimated by methods presented and that appropriate wing-body interference factors (also presented) be applied. If wing-alone test data are available, it is obvious that these test data should be substituted in place of the estimated wing-alone characteristics in determining the lift-curve slope of the combination. Also, if test data are available on a configuration similar to a given configuration, the characteristics of the similar configuration can be corrected to those for the given configuration by judiciously using the DATCOM material.\n\nThe DATCOM Manual is divided into 9 sections:\n\n\nMany textbooks utilized in universities implement the DATCOM method of stability and control. Shortly before compilation of the DATCOM was completed, a computerized version called Digital DATCOM was created. The USAF S&C Digital DATCOM implements the DATCOM methods in an easy to use manner.\n\n"}
{"id": "15007701", "url": "https://en.wikipedia.org/wiki?curid=15007701", "title": "Unit block", "text": "Unit block\n\nA unit block is a type of standardized wooden toy block for children. Known also as standard unit blocks or kindergarten blocks, these building blocks are common in preschools and some kindergarten classrooms in the United States.\n\nA unit block is 5.5 inches long, 2.75 inches wide, and 1.375 inches thick. Larger pieces include the double (11 inches long) and quadruple (22 inches long) sizes. Smaller sizes are made in various fractions of the standard unit.\n\nThe unit block principle was popularized by educator Caroline Pratt in the early 1900s. Pratt based her blocks on a similar but larger-scale block system designed by educator Patty Hill, a follower of Friedrich Fröbel, the originator of kindergarten education. Fröbel's series of 20 age-calibrated educational \"gifts\" had included a set of eight blocks, sized ½ by 1 by 2 inches, or a 1:2:4 ratio, which could be formed into a cube. She founded the City and Country School in 1914 in New York City. In the 1970s, under license from the school, a version of the blocks was sold by a company called Childcraft.\n\nUnit blocks vary in price according to the wood used and the manufacturer. Maple blocks (the original wood put forth by Pratt) are more expensive than birch or beech, which in turn are more expensive than rubberwood.\n\n\n"}
{"id": "10853528", "url": "https://en.wikipedia.org/wiki?curid=10853528", "title": "United States foreign policy in the Middle East", "text": "United States foreign policy in the Middle East\n\nUnited States foreign policy in the Middle East has its roots as early as the Barbary Wars in the first years of the U.S.'s existence, but became much more expansive after World War II. American policy during the Cold War tried to prevent Soviet Union influence by supporting anti-communist regimes and backing Israel against Soviet-sponsored Arab countries. The U.S. also came to replace the United Kingdom as the main security patron of the Persian Gulf states in the 1960s and 1970s, working to ensure a stable flow of Gulf oil. Since the 9/11 attacks of 2001, U.S. policy has included an emphasis on counter-terrorism. The U.S. has diplomatic relations with all countries in the Middle East except for Iran, whose 1979 revolution brought to power a staunchly anti-American regime.\n\nRecent priorities of the U.S. government in the Middle East have included resolving the Arab–Israeli conflict and limiting the spread of weapons of mass destruction among regional states.\n\nThe United States' relationship with the Middle East prior to World War I was limited, although commercial ties existed even in the early 19th century. President Andrew Jackson established formal ties with the Sultan of Muscat and Oman in 1833. (The Sultan saw the U.S. as a potential balance to Britain's overwhelming regional influence.) Commercial relations opened between the U.S. and Persia in 1857, after Britain persuaded the Persian government not to ratify a similar agreement in 1851.\n\nIn comparison to European powers such as Britain and France which had managed to colonize almost all of the Middle East region after defeating the Ottoman Empire in 1918, the United States was \"popular and respected throughout the Middle East\". Indeed, \"Americans were seen as good people, untainted by the selfishness and duplicity associated with the Europeans.\" American missionaries had brought modern medicine and set up educational institutions all over the Middle East. Moreover, the United States had provided the Middle East with highly skilled petroleum engineers. Thus, there were some connections made between the United States and the Middle East before the Second World War. Other examples of cooperations between the U.S. and the Middle East are the Red Line Agreement signed in 1928 and the Anglo-American Petroleum Agreement signed in 1944. Both of these agreements were legally binding and reflected an American interest in control of Middle Eastern energy resources, namely oil, and moreover reflected an American \"security imperative to prevent the (re)emergence of a powerful regional rival\". The Red Line Agreement had been \"part of a network of agreements made in the 1920s to restrict supply of petroleum and ensure that the major [mostly American] companies … could control oil prices on world markets\". The Red Line agreement governed the development of Middle East oil for the next two decades. The Anglo-American Petroleum Agreement of 1944 was based on negotiations between the United States and Britain over the control of Middle Eastern oil. Below is shown what the American President Franklin D. Roosevelt had in mind for to a British Ambassador in 1944:\nPersian oil … is yours. We share the oil of Iraq and Kuwait. As for Saudi Arabian oil, it's ours.\nOn August 8, 1944, the Anglo-American Petroleum Agreement was signed, dividing Middle Eastern oil between the United States and Britain. Consequently, political scholar Fred H. Lawson remarks, that by the mid-1944, U.S. officials had buttressed their country's position on the peninsula by concluding an Anglo-American Petroleum Agreement that protected \"all valid concession contracts and lawfully acquired rights\" belonging to the signatories and established a principle of \"equal opportunity\" in those areas where no concession had yet been assigned. Furthermore, political scholar Irvine Anderson summarises American interests in the Middle East in the late 19th century and the early 20th century noting that, \"the most significant event of the period was the transition of the United States from the position of net exporter to one of net importer of petroleum.\"\n\nBy the end of the Second World War, the United States had come to consider the Middle East region as \"the most strategically important area of the world.\" and \"one of the greatest material prizes in world history,\" argues Noam Chomsky. For that reason, it was not until around the period of World War II that America became directly involved in the Middle East region. At this time the region was going through great social, economic and political changes and as a result, internally the Middle East was in turmoil. Politically, the Middle East was experiencing an upsurge in the popularity of nationalistic politics and an increase in the number of nationalistic political groups across the region, which was causing great trouble for the English and French colonial powers.\n\nHistory scholar Jack Watson explains that \"Europeans could not hold these lands indefinitely in the face of Arab nationalism\". Watson then continues, stating that \"by the end of 1946 Palestine was the last remaining mandate, but it posed a major problem\". In truth, this nationalistic political trend clashed with American interests in the Middle East, which were, as Middle East scholar Louise Fawcett argues, \"about the Soviet Union, access to oil and the project for a Jewish state in Palestine\". Hence, Arabist Ambassador Raymond Hare described the Second World War, as \"the great divide\" in United States' relation with the Middle East, because these three interests would later serve as a backdrop and reasoning for a great deal of American interventions in the Middle East and thus also come to be the cause of several future conflicts between the United States and the Middle East.\n\nIn 1947, the U.S. and the Truman administration, under domestic political pressure, pushed for a solution and resolution on the Arab–Israeli conflict, and in May 1948 the new state of Israel came into existence. This process was not without its fights and loss of lives. Nevertheless, \"the first state to extend diplomatic recognition to Israel was the United States; the Soviet Union and several Western nations quickly followed suit. No Arab state, however, recognized Israel.\"\n\nSyria became an independent republic in 1946, but the March 1949 Syrian coup d'état, led by Army Chief of Staff Husni al-Za'im, ended the initial period of civilian rule. Za'im met at least six times with CIA operatives in the months prior to the coup to discuss his plan to seize power. Za'im requested American funding or personnel, but it is not known whether this assistance was provided. Once in power, Za'im made several key decisions that benefitted the United States. He approved the Trans-Arabian Pipeline (TAPLINE), an American project designed to transport Saudi Arabian oil to Mediterranean ports. Construction of TAPLINE had been delayed due to Syrian intransigence. Za'im also improved relations with two American allies in the region: Israel and Turkey. He signed an armistice with Israel, formally ending the 1948 Arab–Israeli War and he renounced Syrian claims to Hatay Province, a major source of dispute between Syria and Turkey. Za'im also cracked down on local communists. However, Za'im's regime was short-lived. He was overthrown in August, just four and a half months after seizing power.\n\nOpposed to foreign intervention in Iran and a keen nationalist, Mohammed Mosaddeq became the prime minister of Iran in 1951. Thus, when Mosaddeq was elected he chose to nationalize the Iranian oil industry, where previously British holdings had generated great profits for Britain through the Anglo-Iranian Oil Company. Furthermore, prior to the nationalisation of Iranian oil Mosaddeq had also cut all diplomatic ties with Britain. The Shah of Iran, Mohammad Reza Pahlavi was opposed to the nationalisation of Iranian oil as he feared this would result in an oil embargo, which would destroy Iran's economy and thus, the Shah was very concerned with the effect of Mosaddeq's policies on Iran. Equally worried were workers in the Iranian oil industry, when they experienced the economic effect of the sanctions on Iranian oil exports which Mosaddeq's policies had resulted in, and riots were happening across Iran.\n\nThus, Mohammad Reza Pahlavi asked Mosaddeq to resign, as was the Shah's constitutional right, but Mosaddeq refused, which resulted in national uprisings. The Shah, fearing for his personal security, fled the country but nominated General Fazlollah Zahedi as new Prime Minister. Although General Fazlollah Zahedi was a nationalist, he did not agree with the Mosaddeq's lenient attitude towards the communist Tudeh party, which the United States had also become increasingly concerned with, fearing Soviet influence spreading in the Middle East. Therefore, in late 1952, the British government asked the U.S. administration for help with the removal of Mohammed Mosaddeq. President Harry S. Truman thought Mossadeq was a valuable bulwark against Soviet influence. However, Truman left office in January 1953, and the new administration of Dwight Eisenhower shared British concern over Mossadeq. Allen Dulles, the director of the CIA, approved one million dollars on April 4, 1953 to be used \"in any way that would bring about the fall of Mossadegh\" Consequently, after a failed attempt on August 15, \"on August 19, 1953, General Fazlollah Zahedi succeeded [with the help of the United States and Britain] and Mossadegh was overthrown. The CIA covertly funneled five million dollars to General Zahedi's regime on August 21, 1953.\"\n\nThis CIA operation, often referred to as Operation Ajax and led by CIA officer Kermit Roosevelt, Jr., ensured the return of the Shah on August 22, 1953.\n\nToday more than a quarter of the world's oil is shipped through the Suez Canal.\n\nAlthough accepting large sums of military aid from the United States in 1954, by 1956 Egyptian leader Nasser had grown tired of the American influence in the country. The involvement that the U.S. would take in Egyptian business and politics in return for aid, Nasser thought \"smacked of colonialism.\" Indeed, as political scholar B.M. Bleckman argued in 1978, \"Nasser had ambivalent feelings toward the United States. From 1952 to 1954 he was on close terms with U.S. officials and was viewed in Washington as a promising moderate Arab leader. The conclusion of an arms deal with the USSR in 1955, however, had cooled the relationship between Cairo and Washington considerably, and the Dulles-Eisenhower decision to withdraw the offer to finance the Aswan High Dam in mid-1956 was a further blow to the chances of maintaining friendly ties. Eisenhower's stand against the British, French, and Israeli attack on Egypt in October 1956 created a momentary sense of gratitude on the part of Nasser, but the subsequent development of the Eisenhower Doctrine, so clearly aimed at 'containing' Nasserism, undermined what little goodwill existed toward the United States in Cairo.\" \"The Suez Crisis of 1956 marked the demise of British power and its gradual replacement by USA as the dominant power in the Middle East.\" The Eisenhower Doctrine became a manifestation of this process. \"The general objective of the Eisenhower Doctrine, like that of the Truman Doctrine formulated ten years earlier, was the containment of Soviet expansion.\" Furthermore, when the Doctrine was finalised on March 9, 1957, it \"essentially gave the president the latitude to intervene militarily in the Middle East … without having to resort to Congress.\" indeed as, Middle East scholar Irene L. Gerdzier explains \"that with the Eisenhower Doctrine the United States emerged \"as the uncontested Western power … in the Middle East.\"\n\nMeanwhile, in Jordan nationalistic anti-government rioting broke out and the United States decided to send a battalion of marines to Lebanon in case of possibly having to intervene in Jordan later that year. Moreover, attempting to keep the pro-American King Hussein of Jordan in power, the CIA started to make secret payments of millions of dollars a year to King Hussein. In the same year, the U.S. supported allies in Lebanon, Iraq, Turkey and Saudi Arabia and sent fleets to be near Syria as Syria's government had executed nationalistic and pro-Soviet policies the same year. However, 1958 was to become a difficult year in U.S. foreign policy; in 1958 Syria and Egypt were merged into the \"United Arab Republic\", anti-American and anti-government revolts started occurring in Lebanon, causing the Lebanese president Chamoun to ask America for help, and the very pro-American King Feisal the 2nd of Iraq was overthrown by a group of nationalistic military officers. It was quite \"commonly believed that [Nasser] … stirred up the unrest in Lebanon and, perhaps, had helped to plan the Iraqi revolution.\"\n\nIn June 1967 Israel fought with Egypt, Jordan, and Syria in the Six-Day War. As a result of the war, Israel captured the West Bank, Golan Heights, and the Sinai Peninsula. The U.S. supported Israel with weapons and continued to support Israel financially throughout the 1970s. On September 17, 1970, with U.S. and Israeli help, Jordanian troops attacked PLO guerrilla camps, while Jordan's U.S.-supplied air force dropped napalm from above. The U.S. deployed the aircraft carrier \"Independence\" and six destroyers off the coast of Lebanon and readied troops in Turkey to support the assault.\n\nThe American interventions in the years before the Iranian revolution have all proven to be based in part on economic considerations, but more so have been influenced and led by the international Cold War context.\n\nSaudi Arabia and the United States are strategic allies, but relations with the U.S. became strained following September 11 attacks. \n\nIn March 2015, President Barack Obama declared that he had authorized U.S. forces to provide logistical and intelligence support to the Saudis in their military intervention in Yemen, establishing a \"Joint Planning Cell\" with Saudi Arabia. The report by Human Rights Watch stated that US-made bombs were being used in attacks indiscriminately targeting civilians and violating the laws of war.\n\nAfghanistan and Pakistan, though situated in South Asia, are considered part of the Greater Middle East. U.S. intervention in both Afghanistan and Pakistan started with the Carter Administration after the Soviet invasion of Afghanistan.\nThe relations of the U.S. with Afghanistan and Pakistan have been closely tied to the War on terrorism that has happened there. American policy has been instrumental in coordinating the ongoing conflicts in Afghanistan and northwestern Pakistan. In recent times, political situations of both countries have been bracketed under a single theater of operations, denoted by the newly coined American term \"AfPak.\"\n\nOn 15 July 2016, a \"coup d'état\" was attempted in Turkey by a faction within the Turkish Armed Forces against state institutions, including, but not limited to the government and President Recep Tayyip Erdoğan.\n\nThe Turkish government accused the coup leaders of being linked to the Gülen movement, which is designated as a terrorist organization by the Republic of Turkey and led by Fethullah Gülen, a Turkish businessman and cleric who lives in Pennsylvania, United States. Erdoğan accuses Gülen of being behind the coup—a claim that Gülen denies—and accused the United States of harboring him. President Recep Tayyip Erdoğan accused the head of United States Central Command, chief General Joseph Votel of \"siding with coup plotters,\" (after Votel accused the Turkish government of arresting the Pentagon's contacts in Turkey).\n\n\n\n\n\n\n\n\n"}
{"id": "20988440", "url": "https://en.wikipedia.org/wiki?curid=20988440", "title": "Verbund Casimcea Wind Farm", "text": "Verbund Casimcea Wind Farm\n\nThe Verbund Casimcea Wind Farm is an operational wind power project located in Tulcea County, Romania. It consists of 88 individual wind turbines with a nominal output 2.5 MW each which will deliver up to 540 GWh of power, enough to power over 350,000 homes, with a capital investment required of approximately €380 million.\n"}
{"id": "51495660", "url": "https://en.wikipedia.org/wiki?curid=51495660", "title": "XMASS", "text": "XMASS\n\nXMASS is a multipurpose physics experiment in Japan that monitors a large tank of xenon for flashes of light that might be caused by hypothetical dark matter particles. In addition to searching for dark matter, XMASS is also studying neutrinoless double beta decay and solar neutrinos.\n\nIts results have not confirmed the annual variation seen in some earlier experiments.\n\nConstruction started in April 2007. The detector was completed in September 2010. Commissioning run was conducted between October 2010 and June 2012. Since November 2013, the detector has been taking scientific data. The detector is sometimes called XMASS-I, as it is planned to be superseded by an upgrade called XMASS-1.5 (a 5 ton detector) and eventually XMASS-II (24 ton detector).\n\nAs of 2018, the experiment continues.\n\nThe detector is located 1000m underground in the Kamioka Observatory in Japan. It contains about 800 kg of liquid xenon.\n\n"}
{"id": "45119857", "url": "https://en.wikipedia.org/wiki?curid=45119857", "title": "Çanta Wind Farm", "text": "Çanta Wind Farm\n\nÇanta Wind Farm () is a wind power plant consisting of 19 wind turbines with a total installed capacity of 47.5 MW. The wind farm is situated in Çanta town of Silivri district in Istanbul Province, northwestern Turkey. It went in production by end May 2014.\n\nThe wind farm was initially projected by Bora Wind Energy Company in 2011. After Boydak Energy Company took over Bora Co., the construction began in 2012. The farm went in production by end May 2014 with six turbines of each 2.5 MW. By end June the same year, eight more turbines increased the total installed capacity to 35 MW.\n\nThe wind farm is located on a -high hill northwest of Çanta town, just east of the provincial border between Tekirdağ and Istanbul. It is at a distance of to Çorlu, to Silivri and to Istanbul.\n\nMaximum power output of each of the 19 turbines supplied by Nordex in Germany is 2.5 MW, and the total annual energy production is about 151 GWh. The turbines of type N100/2500 have rotor diameter.\n\nAverage annual wind speed at the site is given with .\n\n"}
