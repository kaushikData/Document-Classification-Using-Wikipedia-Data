{"id": "50026453", "url": "https://en.wikipedia.org/wiki?curid=50026453", "title": "1948 Sabena DC-4 Crash", "text": "1948 Sabena DC-4 Crash\n\nThe 1948 Sabena DC-4 Crash was the crash of a Douglas DC-4-1009 of the Belgian airline Sabena, 27 km South of Libenge, Congo (Democratic Republic) on 12 May 1948. It was the deadliest accident for Sabena at the time and the second of three deadly Sabena crashes in 1948. It was also the deadliest in Belgian Congo before the country's independence in 1960, of the 32 people on board 31 were killed, leaving only 1 survivor.\n\nThe DC-4-1009 involved was built in 1946 and bought new from Douglas with serial number 42932 and registration \"OO-CBE\" and was used by the Belgian airline company Sabena from 17 April 1946 until its destruction in 1948. The aircraft was mostly used in Belgian Congo and carried Regent Prince Charles of Belgium back to Belgium on 13 August 1947 after his official visit to Congo.\n\nThe Sabena flight departed from Léopoldville-N'Djili Airport, Congo Democratic Republic en route to Libenge Airport, Congo Democratic Republic with 25 passengers and 7 crew members on board.\n\nWhile above the Congo rainforest, 27 km South of Libenge, at an altitude of 700 feet, the aircraft probably penetrated a very turbulent line of clouds or flew the aircraft into the active centre of a tornado at a low altitude. The aircraft was probably then forced to the ground by a down-ward gust.,\n\nThe aircraft hit the tree-tops and left a trail through the forest until it finally crashed, killing all 7 crew members and 24 of the 25 passengers, the sole survivor was an Egyptian man named Moutafis.\n\nThe wreck was located the following day and the injured sole survivor was rescued. Rescuers searched for more survivors, but it quickly became clear that their efforts were in vain. This crash was the second deadly crash of three involving a Sabena aircraft in 1948, making 1948 the deadliest year in Sabena's history.\n"}
{"id": "23637954", "url": "https://en.wikipedia.org/wiki?curid=23637954", "title": "Activ Business Casimcea Wind Farm", "text": "Activ Business Casimcea Wind Farm\n\nThe Activ Business Casimcea Wind Farm is a proposed wind power project in Casimcea, Tulcea County, Romania. It will have 13 individual wind turbines with a nominal output of around 3.46 MW which will deliver up to 45 MW of power, enough to power over 28,450 homes, with a capital investment required of approximately US$80 million.\n"}
{"id": "17823745", "url": "https://en.wikipedia.org/wiki?curid=17823745", "title": "Arsenobetaine", "text": "Arsenobetaine\n\nArsenobetaine is an organoarsenic compound that is the main source of arsenic found in fish. It is the arsenic analog of trimethylglycine, commonly known as betaine. The biochemistry and its biosynthesis are similar to those of choline and betaine.\n\nArsenobetaine is a common substance in marine biological systems and unlike many other organoarsenic compounds, such as dimethylarsine and trimethylarsine, it is relatively non-toxic.\n\nIt has been known since 1920 that marine fish contain organoarsenic compounds, but it was not until 1977 that the chemical structure of the most predominant compound arsenobetaine was determined.\n"}
{"id": "21902229", "url": "https://en.wikipedia.org/wiki?curid=21902229", "title": "Association of Issuing Bodies", "text": "Association of Issuing Bodies\n\nThe Association of Issuing Bodies - the AIB - promotes the use of a standardised system, based on harmonized environment, structures and procedures in order to ensure the reliable operation of international energy certificate systems. The standardized system is known as EECS - the European Energy Certificate System - and is set out in \"The EECS Rules\" and its supporting documents.\n\nOf the 28 countries of the European Union, 18 are now active members, along with Norway and Switzerland. Since 2001, more than three billion (3,232 million) 1MWh certificates have been issued, of which 2,859 million have already been used (cancelled) to guarantee to consumers the origin of the renewable energy they have purchased. In 2016, more than 531 million certificates were issued, and 387 million of these were cancelled.\n\nThe work of the AIB is of relevance to all electricity customers, as the Guarantee of Origin (the instrument created in the European Directive and standardised through EECS) is a cornerstone of providing reliable disclosure information on the origin of electricity supplied to consumers.\n"}
{"id": "56602", "url": "https://en.wikipedia.org/wiki?curid=56602", "title": "Astana", "text": "Astana\n\nAstana (; Kazakh and ; ; ) is the capital city of Kazakhstan. It is located on the banks of the Ishim River in the north portion of Kazakhstan, within the Akmola Region, though administered separately from the region as a city with special status. The 2017 official estimate reported a population of 1,029,556 within the city limits, making it the second-largest city in Kazakhstan, behind Almaty.\n\nAstana became the capital city of Kazakhstan in 1997, and since then has developed economically into one of the most modernized cities in Central Asia. \n\nModern Astana is a planned city, like Brasília in Brazil, Canberra in Australia, Washington, D.C. in the United States and other planned capitals. After Astana became the capital of Kazakhstan, the city cardinally changed its shape. The master plan of Astana was designed by Japanese architect Kisho Kurokawa. As the seat of the Government of Kazakhstan, Astana is the site of the Parliament House, the Supreme Court, the Ak Orda Presidential Palace and numerous government departments and agencies. It is home to many futuristic buildings, hotels and skyscrapers. Astana also has extensive healthcare, sports and education systems.\n\nFounded in 1830 as a settlement of \"Akmoly\" or \"Akmolinsky prikaz\" (), it served as a defensive fortification for the Siberian Cossacks. In 1832 the settlement was granted a town status and renamed \"Akmolinsk\" (). On 20 March 1961 the city was renamed \"Tselinograd\" () to mark the city's evolution as a cultural and administrative center of the Virgin Lands Campaign. In 1992 it was renamed \"Akmola\", the modified original name meaning \"white grave\". On 10 December 1997 Akmola replaced Almaty as the capital of Kazakhstan. On 6 May 1998 it was renamed \"Astana\", which means \"capital city\" in Kazakh.\n\nThe settlement of \"Akmoly\", also known as \"Akmolinsky prikaz\", was established on the Ishim River in 1830 as the seat of an okrug by a unit of the Siberian Cossacks headed by Fyodor Shubin. The name was possibly given after a local landmark—\"Akmola\" literally means \"a white grave\" in Kazakh—although this theory is not universally accepted. In 1832, the settlement was granted town status and named \"Akmolinsk\". The fairly advantageous position of the town was clear as early as 1863 in an abstract from the Geographic and Statistical Dictionary of the Russian Empire. It describes how picket roads and lines connected this geographic centre to Kargaly in the East, Aktau fort in the South and through Atbasar to Kokchetav in the West. In 1838, at the height of the great national and liberation movement headed by Kenesary Khan, Akmolinsk fortress was burned. After the repression of the liberation movement, the fortress was rebuilt. On 16 July 1863, Akmolinsk was officially declared an uyezd town. During the rapid development of the Russian capitalist market, the huge Saryarka areas were actively exploited by the colonial administration. To draft regulation governing the Kazakh Steppe the Government of the Russian Empire formed Steppe Commission in 1865. On 21 October 1868, Tsar Alexander II signed a draft Regulation on governing Turgay, Ural, Akmolinsk and Semipalatinsk Oblasts. In 1869, Akmolinsk external district and department were cancelled, and Akmolinsk became the centre of the newly established Akmolinsk Oblast. In 1879, Major General Dubelt proposed to build a railway between Tyumen and Akmolinsk to the Ministry of Communications of Russia. In the course of the first 30 years of its existence, the population of Akmola numbered a trifle more than 2,000 people. However, over the next 30 years the city's population increased by three times according to volosts and settlements of the Akmolinsk Oblast. In 1893, Akmolinsk was an uyezd with a 6,428 strong population, 3 churches, 5 schools and colleges and 3 factories.\n\nDuring World War II, Akmolinsk served as a route for the transport of engineering tools and equipment from evacuated plants in the Ukrainian SSR, Byelorussian SSR, and Russian SFSR located in the oblasts of the Kazakh SSR. Local industries were appointed to respond to war needs, assisting the country to provide the battle and home fronts with all materials needed. In the post-war years, Akmolinsk became a beacon of economic revival in the west of the Soviet Union ruined by the war. Additionally, many Russian-Germans were resettled here after being deported under Joseph Stalin's rule.\n\nIn 1954, Northern Kazakh SSR oblasts became a territory of the Virgin Lands Campaign led by Nikita Khrushchev, in order to turn the region into a second grain producer for the Soviet Union.) In December 1960, Central Committee made a resolution to create the Tselinniy Krai, which comprised five regions of the Northern Kazakh SSR oblasts. Akmolinsk Oblast was ceased to exist as a separate administrative entity. Its districts were directly subordinated to the new krai administration, and Akmolinsk became the krai capital, as well as the administrative seat of the new Virgin Lands economic region. On 14 March 1961, Khrushchev proposed to rename the city to name corresponding to its role in the Virgin Lands Campaign. On 20 March 1961, the Supreme Soviet of the Kazakh SSR renamed Akmolinsk to \"Tselinograd\". On 24 April 1961, the region was reconstituted as \"Tselinograd Oblast\". In the 1960s, Tselinograd was completely transformed. In 1963, work on the first three new high-rise housing districts began. In addition, the city received a number of new monumental public buildings, including the Virgin Lands Palace, a Palace of Youth, a House of Soviets, a new airport, and several sports venues. In 1971, the Tselinniy Krai was abolished and Tselinograd became the centre of the oblast.\n\nAfter the dissolution of the Soviet Union and the consequent independence of Kazakhstan, the city's original form was restored in the modified form \"Akmola\". On 6 July 1994, the Supreme Council of Kazakhstan adopted the decree \"On the transfer of the capital of Kazakhstan\". After the capital of Kazakhstan was moved to Akmola on 10 December 1997, the city was consequently renamed Astana in 1998. On 10 June 1998, Astana was presented as the capital internationally. On 16 July 1999, Astana was awarded the medal and title of the City of Peace by UNESCO.\n\nAstana is located in central Kazakhstan on the Ishim River in a very flat, semi-arid steppe region which covers most of the country's territory. It is at 51° 10' north latitude and 71° 26' east longitude. The city encompasses . The elevation of Astana is above sea level. Astana is in a spacious steppe landscape, in the transitional area between the north of Kazakhstan and the extremely thinly settled national centre, because of the Ishim River. The older boroughs lie north of the river, whilst the new boroughs are located south of the Ishim.\n\nThe time offset from the UTC used by Astana is 6 hours after UTC, or . This is also used by most of Kazakhstan and Almaty.\n\nAstana is the second-coldest capital city in the world after Ulaanbaatar, Mongolia, a position formerly held by Canada's capital, Ottawa, until Astana attained capital city status in 1997. Astana has an extreme continental climate with warm summers (featuring occasional brief rain showers) and long, very cold, dry winters. Summer temperatures occasionally reach while is not unusual between mid-December and early March. Typically, the city's river is frozen over between the second week of November and the beginning of April. Astana has a well-deserved reputation among Kazakhs for its frequent high winds, the effects of which are felt particularly strongly on the fast-developing but relatively exposed Left Bank area of the city.\n\nOverall, Astana has a humid continental climate (Köppen climate classification \"Dfb\"), The average annual temperature in Astana is . January is the coldest month with an average temperature of and record lowest is in January 1893's cold wave reaching temperatures down to . July is the hottest month with an average temperature of .\n\nAs of September 2017, the population of Astana was 1,029,556; over double the 2002 population of 493,000.\n\nThe ethnic makeup of the city's population as of September 4, 2014 was:\n\nMany argue that a drive to attract ethnic Kazakhs northward was the key factor in shifting the capital, which was officially put down to lack of space for expansion in the former capital, Almaty, and its location in an earthquake zone. Astana would also be 'closer to the industrial centre of Kazakhstan' than Almaty.\n\nAccording to the 1999 Census, 40.5% of the population was Russian, 5.7% Ukrainian, 3.0% German, 2.6% Tatar, 1.8% Belarusian and 0.8% Polish. But at 41.8%, Kazakhs outnumbered Russians and formed the largest ethnic group, while Ingush and Korean each accounted for 0.6%. Others, mostly Uzbeks, accounted for 3.8%.\n\nIn 1989, Astana had a population of 281,000. The ethnic mix was about 30% Kazakh and 70% Russian, Ukrainian and German.\n\nBy 2007, Astana's population had more than doubled since becoming the capital, to over 600,000, and it topped 1 million in 2017. Migrant workers—legal and illegal—have been attracted from across Kazakhstan and neighbouring states such as Uzbekistan and Kyrgyzstan, and Astana is a magnet for young professionals seeking to build a career. This has changed the city's demographics, bringing more ethnic Kazakhs to a city that formerly had a Slavic majority. Astana's ethnic Kazakh population has risen to some 60%, up from 17% in 1989. According to preliminary figures, Astana had 700,000 inhabitants in late 2007.\n\nIslam is the predominant religion of the city. Other religions practiced in Astana are Christianity (primarily Russian Orthodox, Roman Catholicism, and Protestantism), Judaism, and Buddhism.\n\nThe Palace of Peace and Reconciliation was specially constructed in 2006 to host the Congress of Leaders of World and Traditional Religions. It contains accommodations for different religions: Judaism, Islam, Christianity, Buddhism, Hinduism, Taoism and other faiths. The pyramid-shaped building would express the spirit of Kazakhstan, where cultures, traditions and representatives of various nationalities coexist in peace, harmony and accord.\n\nThe metropolitan area centred upon Astana includes the Arshaly, Shortandy, Tselinograd and (partially) Akkol District districts of Akmola Region. The area contains 1.2 million people.\n\nAstana's economy is based on trade, industrial production, transport, communication and construction. The city's industrial production is mainly focused on producing building materials, foodstuff and mechanical engineering.\n\nThe Astana International Financial Center (AIFC) will open in July 2018 to become a hub for financial services in Central Asia.\n\nAstana is the headquarters of state-owned corporations such as Samruk-Kazyna, Kazakhstan Temir Zholy, KazMunayGas, KazTransOil, Kazatomprom, KEGOC, Kazpost and Kazakhtelecom.\n\nThe shift of the capital has given it a powerful boost to Astana's economic development. The city's high economic growth rate has attracted numerous investors. In the 16 years since Astana became the capital, the volume of investments has increased by almost 30 times, the gross regional product has increased by 90 times, and industrial output has increased by 11 times. The city's Gross Regional Product makes up about 8.5 percent of the republic's Gross domestic product.\n\nThe Astana – New City special economic zone was established in 2001 to help develop industry and increase the attractiveness of the city to investors. The SEZ plans to commission five projects worth 20 billion KZT (around $108 million) in the Industrial Park #1 in 2015. The projects include construction of a plant for production of diesel engines, a fast food complex, temporary storage warehouses and a business centre, a furniture factory, and production of military and civil engineering machinery. The new Astana International Financial Centre is due to launch on 1 January 2018.\n\nAstana's administration is promoting the development of small and medium-sized businesses through the cooperation of the Sovereign Welfare Fund Samruk-Kazyna and National Economic Chamber. Support is provided by a special program of crediting. As a result, the number of small and medium-sized businesses increased by 13.7% to over 96,000 compared to the previous year as of July 1, 2015. In addition, the number of people employed in small and medium-sized business increased by 17.8% to over 234,000 people as of April 1, 2015.\n\nAstana was included in the list of top 21 intelligent communities of the world, according to the report released by the Intelligent Community Forum in October 2016. The rating list includes the cities, regions and communities which use digital instruments for construction of local economy and society.\n\nAstana has become an platform for high-profile diplomatic talks and summits on critical global issues. Astana has hosted multiple rounds of talks between the Assad regime and Syrian opposition. The 12th Ministerial Conference of the World Trade Organization (WTO) is to be held there in 2020. Beginning in 2003, Astana has hosted the Congress on World and Traditional Religions, which is a diverse gathering of religious leaders to discuss religious harmony and ending terrorism and extremism. \n\nAstana is subdivided into three districts. Almaty District was created on 6 May 1998 by presidential decree. The district's territory encompasses an area of with a population of 375,938 people. The district has five villages. Yesil District, which is also called left bank of the city, was created on 5 August 2008 by presidential decree. The district's territory encompasses an area of with a population of 119,929 people. Saryarka District was created on 6 May 1998 by presidential decree. The district's territory encompasses an area of with a population of 339,286 people.\n\nIn April 1998, the Government of Kazakhstan asked architects and urban planners of international renown to participate in a design competition for the new capital. On 6 October 1998, Japanese architect Kisho Kurokawa was awarded the First Prize. Summary of Kurokawa's Proposal, since the 1960s, pleaded for the paradigm shift from the age of the machine principle to the age of life principle. His work is the embodiment of Metabolism and symbiosis, which are the two most important concepts of the age of life principle. Kurokawa's proposal aimed to preserve and redevelop the existing city, and create a new city at the south and the east sides of the Ishim River, enabling the Symbiosis of the History and the Future.\n\nNorth of the railway line, which crosses Astana in an east-west direction, are industrial and poorer residential areas. Between the railway line and the Ishim river is the city centre, where at present intense building activity is occurring. To the west and east are more elevated residential areas with parks and the new area of government administration to the south of the Ishim River. Here many large building projects are under way; for example, the construction of a diplomatic quarter, and a variety of different government buildings. By 2030, these quarters are to be completed. Astana's current chief planner, Vladimir Laptev, wants to build a Berlin in a Eurasian style. He has stated that a purely administrative capital such as Canberra is not one of his goals.\n\nThe city has a variety of sporting teams. The major association football team is the FC Astana of the Kazakhstan Premier League. Founded in 2009, Astana won four league titles, three Kazakhstan Cups and two Kazakhstan Super Cups. Their home ground is the Astana Arena, which is also serves as a home for the Kazakhstan national football team and the FC Bayterek. The FC Bayterek is a member of the Kazakhstan First Division. They were founded in 2012, to develop youth football. The FC Astana-1964 is based in the Kazhymukan Munaitpasov Stadium and plays in the Astana Municipal Football League. The club's most successful years were 2000s, when they won 3 league titles.\n\nAstana is home to several professional ice hockey teams. The Barys Astana, a founding member of the Kontinental Hockey League in 2008 and based in the Barys Arena. The Nomad Astana and HC Astana play in the Kazakhstan Hockey Championship. The Snezhnye Barsy of the Junior Hockey League is a junior team of the Barys Astana. Astana annually hosts the President of the Republic of Kazakhstan's Cup ice hockey tournament.\n\nThe Astana Pro Team, founded in 2007, participates in the UCI World Tour. The team is one of the most successful cycling teams of recent years, winning several grand tours. The BC Astana of the VTB United League and the Kazakhstan Basketball League is the only professional basketball team in Astana. It is the most successful basketball team in Kazakhstan with three Kazakhstan Basketball League titles and four Kazakhstan Basketball Cups. Its home arena is the Saryarka Velodrome, which is mainly used for track cycling events. The Saryarka Velodrome hosted the UCI Track Cycling World Cup stage in 2011. The Astana Presidential Sports Club was founded in 2012, to combine the main sports teams in Astana. The organization is supported by Sovereign Wealth Fund Samruk-Kazyna. The 2011 Asian Winter Games were partly held in the capital. The Alau Ice Palace, hosted the 2015 World Sprint Speed Skating Championships. The President's Cup tennis tournament is annually held at the Daulet National Tennis Centre.\n\nAstana has many universities and junior colleges. academic year, Astana had a total enrollment of 53,561 students in its 14 higher educational institutions, a 10% increase from the prior year. The L.N.Gumilyov Eurasian National University is the biggest university in Astana with 16,558 students and 1,678 academic staff. It was founded as the result of merging the Akmola Civil Engineering Institute and Akmola Pedagogical Institute on 23 May 1996. The oldest university in Astana is the S.Seifullin Kazakh Agro Technical University founded in 1957. Nazarbayev University is an autonomous research university founded in 2010 in partnership with some of the world's top universities. The Kazakh University of Economics, Finance and International Trade is an economic institution in Astana. The Kazakh Humanities and Law Institute is a law university founded by initiative of Ministry of Justice in 1994. The Astana Medical University was the only medical school in Astana until the opening of the School of Medecine at Nazarbayev University in 2014. The Kazakh National University of Arts is the premier music school and has provided Astana with highly qualified professional specialists in the field of Arts.\n\nAstana schools enrolls about 103,000 students across 83 schools, including 71 state schools and 12 private schools. The Miras International School, established 1999, was the first private high school established in Astana. The Haileybury Astana school was established in 2011, as a branch of the Haileybury and Imperial Service College, an independent school in The United Kingdom. The Astana Kazakh-Turkish High Schools are run by the International KATEV foundation. In Astana, there are Kazakh-Turkish High Boarding Schools for gifted boys and girls, separately and the Nurorda International School. Astana hosts two Nazarbayev Intellectual Schools (NIS), including School of Physics and Mathematics and International Baccalaureate world school. The QSI International School of Astana is an international school that provides an American curriculum to its students. The school is a branch of the Quality Schools International that started in the Middle East.\n\nPublic transport in Astana consists of buses and share taxis. Over 720,000 people use public transport daily. There are over 40 bus lines served by more than 1000 vehicles, with over 3000 people working in the public transport sector. Just like buses, share taxis have their own predefined routes and work on a shared basis. There are nine share taxi routes in total. In 2011, Akimat of Astana established a company to implement a series of changes and programmes in the metropolis known as the \"New transport system of Astana\". As the part of these programmes, Bus rapid transit (BRT) lines are expected to start operating in Astana in 2016. Astana Light Metro is a proposed light rail system. Astana also has air taxi service and the modern Astana Bike bicycle-sharing system.\n\nAstana International Airport , located south-east of the city centre, is the main gateway for the city's domestic and international civilian air traffic. It is the second-busiest airport in Kazakhstan, with 2,960,181 passengers passing through it in 2014. The airport hosts 13 airlines operating regular passenger flights inside the country and internationally. Air Astana maintains its second-largest hub at the airport. An expected 50% increase in passenger traffic by 2017 has spurred construction of a new terminal with an area of about .\n\nAstana is located in the centre of the country, serving as a well-positioned transport node for rail and automotive networks.\n\nAstana railway station is the city's main railway station and serves approximately 7,000 people each day. A new railway station, Nurly Zhol was built during the Expo 2017 event with a customer capacity of 12,000. Tulpar Talgo is a daily express train to Almaty. Short-term plans include construction of a new railway station in the industrial district; in the vicinity of CHPP-3 a new terminal will be erected for freight cars.\n\nM-36 Chelyabinsk-Almaty and A-343 Astana-Petropavlovsk highways are routed through the city. The strategic geographical positioning of Astana allows the city to serve as a transport and reload centre for cargoes formed at adjacent stations in the area.\n\nOn 1 July 2010, at the 153rd General Assembly of Bureau International des Expositions held in Paris, representatives from Astana presented the city's bid to host the Specialised Expo 2017. Kazakhs concept for this exhibition relates to the impact of energy and social on the modern world. The theme of the Astana Expo was \"Future Energy\". \n\nExpo 2017 opened to much fanfare on June 10, with heads of state from 17 different nations in attendance. The two-millionth visitor was registered on August 7. It is the first world's fair to be held in Central Asia and its central pavilion, \"Nur Alem\", is the largest spherical building in the world.\n\nMore than 4 million people visited Expo 2017 in Astana, two times more than was expected. Recently it was announced that Expo pavilion will be opened again on 11 November. Entry will be free for all the visitors. The only places that will require additional fees for entry are \"Nur Alem\" and centre of art.\n\nAstana maintains official partnerships with 18 cities. Astana's twin towns and sister cities are:\n\nThe Smart Astana project is an initiative developed by the Astana city administration that incorporates technology-driven solutions in various sectors, like hospitals, schools, the ticket booking system and street lighting. These projects run on an interconnected application, The Smart Astana.\n\n\n"}
{"id": "211762", "url": "https://en.wikipedia.org/wiki?curid=211762", "title": "Burr puzzle", "text": "Burr puzzle\n\nA burr puzzle is an interlocking puzzle consisting of notched sticks, combined to make one three-dimensional, usually symmetrical unit.\nThese puzzles are traditionally made of wood, but versions made of plastic or metal can also be found. Quality burr puzzles are usually precision-made for easy sliding and accurate fitting of the pieces.\nIn recent years the definition of \"burr\" is expanding, as puzzle designers use this name for puzzles not necessarily of stick-based pieces.\n\nThe term \"burr\" is first mentioned in a 1928 book by Edwin Wyatt, but the text implies that it was commonly used before. The term is attributed to the finished shape of many of these puzzles, resembling a seed burr.\nThe origin of burr puzzles is unknown. The first known record appears in a 1698 engraving used as a title page of Chambers's Cyclopaedia. Later records can be found in German catalogs from the late 18th century and early 19th century. There are claims of the burr being a Chinese invention, like other classic puzzles such as the Tangram. In Kerala, India, these wooden problems are called Edakoodam.\n\nThe six-piece burr, also called \"Puzzle Knot\" or \"Chinese Cross\", is the most well-known and presumably the oldest of the burr puzzles. This is actually a family of puzzles, all sharing the same finished shape and basic shape of the pieces. The earliest US patent for a puzzle of this kind dates back to 1917.\n\nFor many years, the six-piece burr was very common and popular, but was considered trite and uninteresting by enthusiasts. Most of the puzzles made and sold were very similar to one another and most of them included a \"key\" piece, an unnotched stick that slides easily out. In the late 1970s, however, the six-piece burr regained the attention of inventors and collectors, thanks largely to a computer analysis conducted by the mathematician Bill Cutler and its publication in Martin Gardner's column on \"Scientific American\".\n\nAll six pieces of the puzzle are square sticks of equal length (at least 3 times their width). When solved, the pieces are arranged in three perpendicular, mutually intersecting pairs. The notches of all sticks are located within the region of intersection, so when the puzzle is assembled they are unseen. All notches can be described as being made by removing cubic units (with an edge length of half the sticks' width), as shown in the figure:\n\nThere are 12 removable cubic units, and different puzzles of this family are made of sticks with different units removed. 4,096 permutations exist for removing the cubic units. Of those, we ignore the ones that cut the stick in two and the ones creating identical pieces, and are left with 837 usable pieces. Theoretically, these pieces can be combined to create over 35 billion possible assemblies, however it is estimated that less than 6 billion of them are actual puzzles, capable of being assembled or taken apart.\n\nA burr puzzle with no internal voids when assembled is called a solid burr. These burrs can be taken apart directly by removing a piece or some pieces in one move. Up until the late 1970s, solid burrs received the most attention and publications referred only to this type. 119,979 solid burrs are possible, using 369 of the usable pieces. To assemble all these puzzles, one would need a set of 485 pieces, as some of the puzzles include identical pieces.\n\nFor aesthetic, but mostly practical reasons, the burr pieces can be divided into two types:\n\n59 of the usable pieces are notchable, including the unnotched stick. Of those, only 25 can be used to create solid burrs. This set, often referred to as \"The 25 notchable pieces\", with the addition of 17 duplicates, can be assembled to create 221 different solid burr puzzles. Some of those puzzles have more than one solution, for a total of 314 solutions. These pieces are very popular, and full sets are manufactured and sold by many companies.\n\nFor all solid burrs, one movement is required to remove the first piece or pieces. However, a holey burr, which has internal voids when assembled, can require more than one move. The number of moves required for removing the first piece is referred to as the \"level\" of the burr. All solid burrs are therefore level 1. The higher the level is, the more difficult the puzzle.\n\nDuring the 1970s and 1980s, attempts were made by experts to find burrs of an ever-higher level. On 1979, the American designer and craftsman Stewart Coffin found a level-3 puzzle. In 1985, Bill Cutler found a level-5 burr and shortly afterwards a level-7 burr was found by the Israeli Philippe Dubois. In 1990, Cutler completed the final part of his analysis and found that the highest possible level using notchable pieces is 5, and 139 of those puzzles exist. The highest level possible for a six-piece burr with more than one solution is 12, meaning 12 moves are required to remove the first piece.\n\nA three-piece burr made from sticks with \"regular\" right-angled notches (as the six-piece burr), cannot be assembled or taken apart. There are, however, some three-piece burrs with different kinds of notches, the best known of them being the one mentioned by Wyatt in his 1928 book, consisting of a rounded piece that is meant to be rotated.\nThe Altekruse puzzle is named after the grantee of its 1890 patent, though the puzzle is of earlier origin. The name \"Altekruse\" is of Austrian-German origin and means \"old-cross\" in German, which led to the presumption that it was a pseudonym, but a man by that name immigrated to America in 1844 with his three brothers to avoid being drafted to the Prussian Army and is presumed to be the one who filed this patent.\n\nA classic Altekruse consists of 12 identical pieces. In order to disassemble it, two halves of the puzzle have to be moved in opposite directions. Using two more of these pieces, the puzzle can be assembled in a different way. By the same principle, other puzzles of this family can be created, with 6, 24, 36 and so forth. Despite their size, those bigger puzzles are not considered very difficult, yet they require patience and dexterity to assemble.\nThe Chuck puzzle was invented and patented by Edward Nelson in 1897. His design was improved and developed by Ron Cook of the British company \"Pentangle Puzzles\" who designed other puzzles of the family.\n\nThe Chuck consists mostly of U-shaped stick pieces of various lengths, and some with an extra notch that are used as key pieces. For creating bigger Chuck puzzles (named Papa-chuck, Grandpapachuck and Great Grandpapachuck, by Cook) one would need to add longer pieces. The Chuck can also be regarded as an extension of a six-piece burr of very simple pieces called Baby-chuck, which is very easy to solve. Chuck pieces of different lengths can also be used to create asymmetric shapes, assembled according to the same principle as the original puzzle.\n\nThe origin of the Pagoda, also called \"Japanese Crystal\" is unknown. It is mentioned in Wyatt's 1928 book. Puzzles of this family can be regarded as an extension of the \"three-piece burr\" (Pagoda of size 1), however they do not require special notches to be assembled or taken apart. Pagoda of size 2 consists of 9 pieces, and bigger versions consist of 19, 33, 51 and so forth. Pagoda of size formula_1 consists of formula_2 pieces.\n\nThough most burr puzzle pieces are made with square notches, some are made with diagonal notches. Diagonal burr pieces are square sticks with V-shaped notches, cut at an angle of 45° off the stick's Face. These puzzles are often called \"Stars\", as it is customary to also cut the sticks' edges at an angle of 45°, for aesthetic reasons, giving the assembled puzzle a Star-like shape.\n\n\n\n"}
{"id": "22786112", "url": "https://en.wikipedia.org/wiki?curid=22786112", "title": "Candy (unit)", "text": "Candy (unit)\n\nThe candy or candee (Marathi: खंडी, \"khaṇḍī\"; Tamil: கண்டி, \"kṇṭi\"; Malayalam: \"kaṇḍi\", \"kaṇṭi\"), also known as the maunee, was a traditional South Asian unit of mass, equal to 20 maunds and roughly equivalent to 500 pounds avoirdupois (227 kilograms). It was most used in southern India, to the south of Akbar's empire, but has been recorded elsewhere in South Asia. In Marathi, the same word was also used for a unit of area of 120 bighas (25 hectares, very approximately), and it is also recorded as a unit of dry volume.\n\nThe candy was generally one of the largest (if not \"the\" largest) unit in a given system of measurement. The name is thought to be derived from the Sanskrit खण्डन (root खुड्) \"khaṇḍ\", \"to divide, break into pieces\", which has also been suggested as the root of the term (sugar-)candy. The word was adopted into several South Asian languages before the compilation of dictionaries, presumably through trade as several Dravidian languages have local synonyms: for example ఖండి \"kaṇḍi\" and పుట్టి \"puṭṭi\" in Telugu.\n\nThe candy was equal to twenty maunds, but the value of the maund was not standardised across South Asia. There were at least three different approximate values for maund in early nineteenth century India, ranging from 11.34 kg to 37.32 kg, and values from outside India varied even wider. Much of our knowledge of the values of South Asian mass units comes from an 1821 study ordered by the British East India Company and subsequently published as \"Kelly's Oriental Metrology\", although the approximate value of 500 pounds for the candy is attested as early as 1618. The earliest European reference to the candy (1563) puts its mass at 522 arráteis (239.6 kg, 528.2 lbs.).\n\nThe three Presidencies of British India had already undertaken a fair degree of standardisation of weights and measures by the time of Kelly's study. In the Madras Presidency, the maund was fixed at 25 lbs. av. (11.340 kg), making the candy equal to 500 lbs. av. (226.796 kg). In the Bombay Presidency, the maund was fixed at 28 lbs. av. (12.701 kg), making the candy exactly equal to 5 hundredweight (560 lbs. av., 254.012 kg). In Bombay itself (present-day Mumbai), a separate value of the candy was recorded for \"grain\", equal to 8 parahs or 358 lbs. 6 oz. 4 dr. (162.563 kg, see also below). In the Bengal Presidency, where the candy was not traditionally used, the maund (or \"mun\") was a much larger unit, 100 troy pounds (37.324 kg, equivalent to a candy of 746.5 kg).\n\nThe effects of this standardisation can also be seen in other territories under direct British control. In Ceylon, the candy (also known as the bahar) was 500 lbs (226.796 kg) as on the Continent. Use of the candy is also recorded in British Burma, where it was the equivalent of 150 viss: its equivalent in Imperial units was measured as 500 lbs. (226.796 kg) in Pegu and 550 lbs. (249.476 kg) in Rangoon.\n\nPerhaps the most striking example is from the princely state of Travancore in southwest India. At the British East India Company trading station of Anjengo, (near modern-day Kadakkavoor), the candy was equal to 35 telong and fixed at 560 lbs. (254.012 kg), as in Bombay. At Colachy (modern-day Kolachal) however, less than 50 miles (80 km) to the south, the candy was measured at only 376 lbs. 1 oz. 2 dr. (170.583 kg).\n\nIn the region of the Central Provinces, the maund was roughly 40 lbs., which is probably about the value it had under the Mughal Empire. The candy was not recorded as being in use as a unit of measurement in this region in 1821. Although not a part of the Central Provinces region, the unusually high value recorded for the candy in Baroda, Gujarat (modern-day Vadodara) – 892 lbs. 1 oz. 4 dr. (404.640 kg) – can be explained by this higher value of the Mughal maund. The candy in Surat, the main port of Gujerat, is also consistently quoted as being much larger than the same unit further south.\n\nThe candy (खंडी, \"khaṇḍī\") is also recorded as a unit of area in Marathi, equal to 120 bighas. It is impossible to accurately convert this to modern units given the huge variability in the different values of the bigha in different locations. In particular, Kelly's 1821 study of South Asian metrology is completely silent on land measures in the Bombay Presidency. Molesworth defines the Marathi bigha (बिघा, \"bighā\") as equal to twenty pandas (पांड, \"pāṇḍa\") or to 400 square kathys (काठी, \"kāṭhī\"), but also notes that it varies in different districts. The same author defines the kathy as \"a land measure,—five cubits and five handbreadths […] also the measuring rod\": other authors are silent on the unit. A cubit is roughly equal to five handbreadths, so the kathy can be taken to be roughly 25 square cubits: that is, 8100 square inches or 6.25 square yards. This would make the bigha roughly 2500 square yards, or half an acre, in agreement with measurements in other areas of India. The candy, therefore, can be taken to be approximately 60 acres or 25 hectares.\n\nThe celebrated Scottish orientalist Sir Henry Yule gives a slightly larger value for the candy as a unit of area (\"approximately 75 acres\"), and describes it as the area of land which will produce one candy of grain. The Telegu unit of the putty (పుట్టి, \"puṭṭi\") is also used in the same way: one putty of land is that area which will produce one putty of rice.\n\nSeveral sources also describe the candy as a unit of dry measure. Again, it is difficult to give an accurate conversion to modern units, as most sources quote conversions to mass units for specific goods, and the few specific conversion factors that exist range from 8 to 25 bushels. More plausible is that one candy of dry measure was the volume that would have been occupied by one candy (in mass) of water, that is about 254 litres (7 bushels) in Bombay (present-day Mumbai).\n\nNot all grain measures in candies should be taken as dry measures. The United Nations Statistical Office reported that the candy was in use in the 20th century:\nBoth of these are obviously related to the candy as a unit of mass.\n\n"}
{"id": "4078380", "url": "https://en.wikipedia.org/wiki?curid=4078380", "title": "Claude Alvares", "text": "Claude Alvares\n\nClaude Alvares is an Indian environmentalist based in Goa, India. He is the editor of the Other India Press publication based in India. The Director of the Goa Foundation, an environmental monitoring action group, Claude Alvares got his PhD from the Technische Hogeschool, Eindhoven, in the Netherlands, in 1976. He lives at Parra, Goa with his wife Padma Sri Norma Alvares, an environmental lawyer and three children, Rahul, Samir and Milind.\n\nHe is a member of the Goa Coastal Zone Management Authority of the Ministry of Environment and Forests (MoEF). He is also a member of the Supreme Court Monitoring Committee (SCMC) on Hazardous Wastes constituted by the Supreme Court of India. He is the author of the article 'The Great Gene Robbery', published in the Illustrated Weekly of India in 1986.\n\nAuthor\n\nEditor\n\n\n"}
{"id": "33876752", "url": "https://en.wikipedia.org/wiki?curid=33876752", "title": "Deploying Renewables 2011", "text": "Deploying Renewables 2011\n\nDeploying Renewables 2011: Best and Future Policy Practice is a 2011 book by the International Energy Agency. The book analyses the recent successes in renewable energy, which now accounts for almost a fifth of all electricity produced worldwide, and addresses how countries can best capitalize on that growth to realise a sustainable energy future. The book says that renewable energy commercialization must be stepped up, especially given the world’s increasing appetite for energy and the need to meet this demand more efficiently and with low-carbon energy sources. Wind power and other renewable energy sources offer great potential to address issues of energy security and sustainability.\n\nThis analysis updates and expands \"Deploying Renewables: Principles for Effective Policies\", published by the IEA in 2008, in light of events and trends in the last five years. It also \"extends the analysis to a wider range of countries beyond the OECD and BRICS countries, focussing on 56 countries representative of each world region\".\n\nRenewable energy commercialisation has been rapid. Growth rates are in line with those required for a sustainable energy future:\n\n• \"The RE electricity sector, for example, has grown by 17.8% over the last five years (2005-09) and currently provides 19.3% of total power generation in the world.\"\n• \"Hydro power is still the major source of renewable electricity (83.8% of RE generation, corresponding to about 16% of total generation in 2009), and the absolute growth in hydro generation over the last five years has been equivalent to that of all the other RE electricity technologies, mainly because of developments in China. Hydro will continue to be an important technology for years to come and must not be excluded from policy considerations.\" \n• \"The other newer RE electricity technologies have also grown rapidly, by an impressive 73.6% between 2005 and 2009, a compound average growth rate (CAGR) of 14.8%. Wind has grown most rapidly in absolute terms and has overtaken bioenergy. Solar PV has grown at a growth rate of 50.2% (CAGR), and installed capacity reached about 40 GW by the end of 2010.\" \n• \"Progress in RE electricity penetration was focused in the OECD and in Brazil, India and China. The OECD was the only region where the deployment of less mature technologies (such as solar PV, offshore wind) reached a significant scale, with capacities in the order of GWs.\" \n• \"Renewable heat grew by 5.9% between 2005 and 2009. Although the use of biomass is still the dominant technology (and includes the use of “traditional” biomass with low efficiency for heating and cooking), growth in solar heating, and to a lesser extent geothermal heating technologies, has been strong, with an overall growth rate of nearly 12% between 2005 and 2009. Growth was particularly driven by rapid increases in solar heating in China.\" \n• \"The production and use of biofuels have been growing rapidly, and in 2009 they provided 53.7 Mtoe, equivalent to some 3% of road transport fuels (or 2% of all transport fuels). The biofuels sector has been growing very rapidly (26% CAGR in 2005-09). Biofuels production and consumption are still concentrated in Brazil, the United States and in the European Union. The main centres for ethanol production and consumption are the United States and Brazil, while Europe produces and consumes mainly biodiesel. The remaining markets in other regions and the rest of the world account for only 6% of total production and for 3.3% of consumption. Trade in biofuels plays a limited, yet increasingly important role.\"\n"}
{"id": "24909382", "url": "https://en.wikipedia.org/wiki?curid=24909382", "title": "EN 206+A1", "text": "EN 206+A1\n\nEN 206+A1 Concrete – Part 1: Specification, performance, production and conformity (formerly EN 206 and EN 206-1) is a European standard elaborated by the CEN/TC 104 \"Concrete and related products\" technical committee which .\n\n\n"}
{"id": "3385027", "url": "https://en.wikipedia.org/wiki?curid=3385027", "title": "Engineers Without Borders (Belgium)", "text": "Engineers Without Borders (Belgium)\n\nIngénieurs sans Frontières - Ingénieurs Assistance Internationale (ISF-IAI, more commonly known as ISF, Belgium) is a Belgian NGO assisting developing areas of the world with their engineering needs and whose fundamental purpose is to adapt technological development to the needs of those living in underprivileged areas.\n\nIt should not be confused with Ingenieurs zonder Grenzen (Dutch for \"Engineers Without Borders\").\n\nFounded on the initiative of a few engineers and with the support of the Associations of Schools for Engineers (FABI), ISF can count on the contribution of several hundred volunteers: engineers with varying qualifications and students willing to put their time and skills at the disposal of development projects.\n\nThanks to many contacts in both professional and associative environment, ISF can seek advice from engineers and technicians on specific problems in every sector of technology. All ISF work is done on a voluntary basis.\n\nISF, looking for collaboration with other Belgian NGOs, has formed the CHAKA group with CODEART and ADG, both Belgian associations. ISF is also a member of the Federation of the French and German speaking NGOs of Belgium (ACODEV) and is approved by the General Directorate for International Cooperation of the Belgian Federal Government (DGCI).\n\nISF is also a member of EWB-International (Engineers Without Borders International Network)\n\n\n"}
{"id": "3907232", "url": "https://en.wikipedia.org/wiki?curid=3907232", "title": "Generation II reactor", "text": "Generation II reactor\n\nA generation II reactor is a design classification for a nuclear reactor, and refers to the class of commercial reactors built up to the end of the 1990s. Prototypical generation II reactors include the PWR, CANDU, BWR, AGR, VVER and RBMK.\n\nThese are contrasted to generation I reactors, which refer to the early prototype of power reactors, such as Shippingport, Magnox/UNGG, AMB, Fermi 1, and Dresden 1. The last commercial Gen I power reactor was located at the Wylfa Nuclear Power Station and ceased operation at the end of 2015. The nomenclature for reactor designs, describing four 'generations', was proposed by the US Department of Energy when it introduced the concept of generation IV reactors.\n\nThe designation \"generation II+ reactor\" is sometimes used for modernized generation II designs built post-2000, such as the Chinese CPR-1000, in competition with more expensive generation III reactor designs. Typically, the modernization includes improved safety systems and a 60-year design life.\n\nGeneration II reactor designs generally had an original design life of 30 or 40 years. This date was set as the period over which loans taken out for the plant would be paid off. However, many generation II reactor are being life-extended to 50 or 60 years, and a second life-extension to 80 years may also be economic in many cases. By 2013 about 75% of still operating U.S. reactors had been granted life extension licenses to 60 years.\n\nFukushima Daiichi's three destroyed reactors are Mark I Boiling water reactors (BWR) designed by General Electric.\nIn 2016, unit 2 at the Watts Bar Nuclear Generating Station came online and is likely to be the last generation II reactor to become operational in the United States.\n\n\n"}
{"id": "31929885", "url": "https://en.wikipedia.org/wiki?curid=31929885", "title": "Gobius senegambiensis", "text": "Gobius senegambiensis\n\nGobius senegambiensis is a species of goby native to the Atlantic Ocean from Morocco to Angola as well as the islands in the Gulf of Guinea where it is found in inshore waters on sandy substrates. This species can reach a length of SL.\n\nThe species is named after where they were described in one location, Senegambia, a region compromising Senegal and the Gambia.\n"}
{"id": "53273402", "url": "https://en.wikipedia.org/wiki?curid=53273402", "title": "Greenhill Ogham Stones", "text": "Greenhill Ogham Stones\n\nGreenhill Ogham Stones (CIIC 57–58) are two ogham stones forming a National Monument located in County Cork, Ireland.\n\nGreenhill Ogham Stones are located 7.4 km (4.6 mi) south-southeast of Mallow.\n\nThe stones were carved in the 5th century AD. Greenhill I is dated to the early 6th century, and Greenhill II to the 5th century (first half, or early second half).\n\nGreenhill I measures 260 × 72 × 35 cm. The inscription is TṚENỤ [MA]QỊ MUCOI QRITTI (of Trén/Trian son of the descendant of Creth? (Crothrige?)')\n\nGreenhill II measures 154 × 46 × 36 cm. The inscription is CATTUBUTTAS Ṃ[AQI] (of Cathub [son of])\n"}
{"id": "22795933", "url": "https://en.wikipedia.org/wiki?curid=22795933", "title": "Hawaii Audubon Society", "text": "Hawaii Audubon Society\n\nThe Hawaii Audubon Society is a birding and bird conservation organisation in the American state of Hawaii. It was founded in 1939 by Charles Dunn, is based in Honolulu and is affiliated with the National Audubon Society. It has over 1,500 members throughout the state and produces a regular newsletter, ‘Elepaio.\n\nThe mission of the Hawaii Audubon Society is to foster community values that result in the protection and restoration of native ecosystems and conservation of natural resources through education, science and advocacy in Hawaii and the Pacific.\n\nOne initiative of the Hawaii Audubon Society is the Pacific Fisheries Coalition, a joint project between the Society and the Hawai`i Fishermen's Foundation, to promote the protection and responsible use of marine resources through education and advocacy in the Pacific region.\n\n\n"}
{"id": "3205338", "url": "https://en.wikipedia.org/wiki?curid=3205338", "title": "Heliospheric current sheet", "text": "Heliospheric current sheet\n\nThe heliospheric current sheet\nis the surface within the Solar System where the polarity of the Sun's magnetic field changes from north to south. This field extends throughout the Sun's equatorial plane in the heliosphere. The shape of the current sheet results from the influence of the Sun's rotating magnetic field on the plasma in the interplanetary medium (solar wind). A small electrical current flows within the sheet, about 10 A/m². The thickness of the current sheet is about 10,000 km near the orbit of the Earth.\n\nThe underlying magnetic field is called the interplanetary magnetic field, and the resulting electric current forms part of the heliospheric current circuit. The heliospheric current sheet is also sometimes called the \"interplanetary current sheet\".\n\nAs the Sun rotates, its magnetic field twists into a Parker spiral, a form of an Archimedean spiral, as it extends through the solar system. This phenomenon is named after Eugene Parker's work: he predicted the solar wind and many of its associated phenomena in the 1950s.\nThe spiral nature of the heliospheric magnetic field had been noted earlier by Hannes Alfvén, based on the structure of comet tails.\n\nThe influence of this spiral-shaped magnetic field on the interplanetary medium (solar wind) creates the largest structure in the Solar System, the heliospheric current sheet.\nParker's spiral magnetic field was divided in two by a current sheet, a mathematical model first developed in the early 1970s by Schatten. It warps into a wavy spiral shape that has been likened to a ballerina's skirt. The waviness of the current sheet is because of the magnetic field dipole axis' tilt angle to the solar rotation axis and variations from an ideal dipole field.\n\nUnlike the familiar shape of the field from a bar magnet, the Sun's extended field is twisted into an arithmetic spiral by the magnetohydrodynamic influence of the solar wind. The solar wind travels outward from the Sun at a uniform rate, but an individual jet of solar wind from a particular feature on the Sun's surface rotates with the solar rotation, making a spiral pattern in space. Unlike the jet from a sprinkler, the solar wind is tied to the magnetic field by MHD effects, so that magnetic field lines are tied to the material in the jet and take on an arithmetic spiral shape.\nThe cause of the ballerina spiral shape has sometimes been called the \"garden sprinkler effect\" or \"garden hose effect\", because it is likened to a lawn sprinkler with nozzle that moves up and down while it spins. The stream of water represents the solar wind.\n\nThe Parker spiral shape of the solar wind changes the shape of the Sun's magnetic field in the outer solar system: beyond about 10-20 astronomical units from the Sun, the magnetic field is nearly toroidal (pointed around the equator of the Sun) rather than poloidal (pointed from the North to the South pole, as in a bar magnet) or radial (pointed outward or inward, as might be expected from the flow of the solar wind if the Sun were not rotating). The spiral shape also greatly amplifies the strength of the solar magnetic field in the outer solar system.\n\nThe Parker spiral may be responsible for the differential solar rotation, in which the Sun's poles rotate more slowly (about a 35-day rotation period) than the equator (about a 27-day rotation period). The solar wind is guided by the Sun's magnetic field and hence largely emanates from the polar regions of the Sun; the induced spiral shape of the field causes a drag torque on the poles due to the magnetic tension force.\n\nDuring solar maximum the entire magnetic field of the sun flips, thus alternating the polarity of the field every solar cycle.\n\nThe heliospheric current sheet rotates along with the Sun with a period of about 25 days, during which time the peaks and troughs of the skirt pass through the Earth's magnetosphere, interacting with it. Near the surface of the Sun, the magnetic field produced by the radial electric current in the sheet is of the order of 5×10 T.\n\nThe magnetic field at the surface of the Sun is about 10 teslas. If the form of the field were a magnetic dipole, the strength would decrease with the cube of the distance, resulting in about 10 teslas at the Earth's orbit. The heliospheric current sheet results in higher order multipole components so that the actual magnetic field at the Earth due to the Sun is 100 times greater.\n\nThe electric current in the heliospheric current sheet has a radial component (directed inward) as well as an azimuthal component, the radial circuit being closed by outward currents aligned with the Sun's magnetic field in the solar polar regions. The radial current in the circuit is on the order of 3×10 amperes. As a comparison with other astrophysical electric currents, the Birkeland currents that supply the Earth's aurora are about a thousand times weaker at a million amperes. The maximum current density in the sheet is on the order of 10 A/m² (10 A/km²).\n\nThe heliospheric current sheet was discovered by John M. Wilcox and Norman F. Ness, who published their finding in 1965. Hannes Alfvén and Per Carlqvist speculate on the existence of a galactic current sheet, a counterpart of the heliospheric current sheet, with an estimated galactic current of 10 to 10 amperes, that might flow in the plane of symmetry of the galaxy.\n\n\n"}
{"id": "6654013", "url": "https://en.wikipedia.org/wiki?curid=6654013", "title": "Hybrid reactor", "text": "Hybrid reactor\n\nA hybrid biological reactor (HBR) was developed which involved the introduction of a new phase of attached-biomass into a regular suspended-growth system (activated sludge process) by addition of carriers to\n\nthe aeration tanks. A novel hybrid biological reactor which contained both suspended and attached-growth biomass was developed by introducing porous materials into a regular activated sludge unit and used for the treatment of domestic wastewater. \n\nA hybrid reactor is an anaerobic digester that combines a UASB reactor with an anaerobic filter. This combination is an advanced form enabling improved solid retention time in the treatment of waste water. This waste water can be built up in the secondary chamber and must be removed daily or an explosion is imminent to occur.\n\n"}
{"id": "46211058", "url": "https://en.wikipedia.org/wiki?curid=46211058", "title": "I-III-VI semiconductors", "text": "I-III-VI semiconductors\n\nI-III-VI semiconductors are solid semiconducting materials that contain three or more chemical elements belonging to groups I, III and VI of the periodic table. They usually involve two metals and one chalcogen. Some of these materials have a direct bandgap, E, of ~ 1.5 eV, which makes them efficient absorbers of sunlight and thus potential solar cell materials. A fourth element is often added to a I-III-VI material to tune the bandgap for maximum solar cell efficiency. A representative example is copper indium gallium selenide (CuInGaSe, E = 1.7–1.0 eV for x = 0–1), which is used in copper indium gallium selenide solar cells.\n\nCuGaO exists in two main polymorphs, α and β. The α form has the delafossite crystal structure and can be prepared by reacting CuO with GaO at high temperatures. The β form has a wurtzite-like crystal structure (space group Pna2); it is metastable, but exhibits a long-term stability at temperatures below 300 °C. It can be obtained by an ion exchange of Na ions in a β-NaGaO precursor with Cu ions in CuCl under vacuum, to avoid the oxidation of Cu to Cu.\n\nUnlike most I-III-VI oxides, which are transparent, electrically insulating solids with a bandgap above 2 eV, β-CuGaO has a direct bandgap of 1.47 eV, which is favorable for solar cell applications. In contrast, β-AgGaO and β-AgAlO have an indirect bandgap. Undoped β-CuGaO is a p-type semiconductor.\n\nSimilarly to CuGaO, α-AgGaO and α-AgAlO have the delafossite crystal structure while the structure of the corresponding β phases is similar to wurtzite (space group Pna2a). β-AgGaO is metastable and can be synthesized by ion exchange with a β-NaGaO precursor. The bandgaps of β-AgGaO and β-AgAlO (2.2 and 2.8 eV respectively) are indirect; they fall into the visible range and can be tuned by alloying with ZnO. For this reason, both materials are hardly suitable for solar cells, but have potential applications in photocatalysis.\n\nContrary to LiGaO, AgGaO can not be alloyed with ZnO by heating their mixture because of the Ag reduction to metallic silver; therefore, magnetron sputtering of AgGaO and ZnO targets is used instead.\n\nPure single crystals of β-LiGaO with a length of several inches can be grown by the Czochralski method. Their cleaved surfaces have lattice constants that match those of ZnO and GaN and are therefore suitable for epitaxial growth of thin films of those materials. β-LiGaO is a potential nonlinear optics material, but its direct bandgap of 5.6 eV is too wide for visible light applications. It can be reduced down to 3.2 eV by alloying β-LiGaO with ZnO. The bandgap tuning is discontinuous because ZnO and β-LiGaO do not mix but form a ZnLiGaO phase when their ratio is between ca. 0.2 and 1.\n\n"}
{"id": "13338003", "url": "https://en.wikipedia.org/wiki?curid=13338003", "title": "Interstitial compound", "text": "Interstitial compound\n\nAn interstitial compound, or interstitial alloy, is a compound that is formed when an atom with a small enough radius sits in an interstitial “hole” in a metal lattice. Examples of small atoms are hydrogen, boron, carbon and nitrogen. The compounds are important industrially and include some transition-metal carbides and nitrides.\n\nThe idea of interstitial compounds was started in the late 1930s and they are often called Hagg phases after Hägg. Transition metals generally crystallise in either the hexagonal close packed or face centered cubic structures, both of which can be considered to be made up of layers of hexagonally close packed atoms. In both of these very similar lattices there are two sorts of interstice, or hole:\n\nIt was suggested by early workers that:\n\nThese were not viewed as compounds, but rather as solutions, of say carbon, in the metal lattice, with a limiting upper “concentration” of the smaller atom that was determined by the number of interstices available.\n\nA more detailed knowledge of the structures of metals, and binary and ternary phases of metals and non metals shows that:\n\nOne example is the solubility of carbon in iron. The form of pure iron stable between 910 °C and 1390 °C, γ-iron, forms a solid solution with carbon termed austenite.\n"}
{"id": "19242924", "url": "https://en.wikipedia.org/wiki?curid=19242924", "title": "Issues relating to biofuels", "text": "Issues relating to biofuels\n\nThere are various social, economic, environmental and technical issues with biofuel production and use, which have been discussed in the popular media and scientific journals. These include: the effect of moderating oil prices, the \"food vs fuel\" debate, poverty reduction potential, carbon emissions levels, sustainable biofuel production, deforestation and soil erosion, loss of biodiversity, effect on water resources, the possible modifications necessary to run the engine on biofuel, as well as energy balance and efficiency. The International Resource Panel, which provides independent scientific assessments and expert advice on a variety of resource-related themes, assessed the issues relating to biofuel use in its first report \"Towards sustainable production and use of resources: Assessing Biofuels\". In it, it outlined the wider and interrelated factors that need to be considered when deciding on the relative merits of pursuing one biofuel over another. It concluded that not all biofuels perform equally in terms of their effect on climate, energy security and ecosystems, and suggested that environmental and social effects need to be assessed throughout the entire life-cycle.\n\nThe International Energy Agency's \"World Energy Outlook 2006\" concludes that rising oil demand, if left unchecked,\nwould accentuate the consuming countries' vulnerability to a severe supply disruption and resulting price shock. The report suggested that biofuels may one day offer a viable alternative, but also that \"the implications of the use of biofuels for global security as well as for economic, environmental, and public health need to be further evaluated\".\n\nAccording to Francisco Blanch, a commodity strategist for Merrill Lynch, crude oil would be trading 15 per cent higher and gasoline would be as much as 25 per cent more expensive, if it were not for biofuels. Gordon Quaiattini, president of the Canadian Renewable Fuels Association, argued that a healthy supply of alternative energy sources will help to combat gasoline price spikes.\n\n\"Food vs fuel\" is the debate regarding the risk of diverting farmland or crops for biofuels production in detriment of the food supply on a global scale. Essentially the debate refers to the possibility that by farmers increasing their production of these crops, often through government subsidy incentives, their time and land is shifted away from other types of non-biofuel crops driving up the price of non-biofuel crops due to the decrease in production. Therefore, it is not only that there is an increase in demand for the food staples, like corn and cassava, that sustain the majority of the world's poor but this also has the potential to increase the price of the remaining crops that these individuals would otherwise need to utilize to supplement their diets. A recent study for the International Centre for Trade and Sustainable Development shows that market-driven expansion of ethanol in the US increased maize prices by 21 percent in 2009, in comparison with what prices would have been had ethanol production been frozen at 2004 levels. A November 2011 study states that biofuels, their production, and their subsidies are leading causes of agricultural price shocks. The counter-argument includes considerations of the type of corn that is utilized in biofuels, often field corn not suitable for human consumption; the portion of the corn that is used in ethanol, the starch portion; and the negative effect higher prices for corn and grains have on government welfare for these products. The \"food vs. fuel\" or \"food or fuel\" debate is internationally controversial, with disagreement about how significant this is, what is causing it, what the effect is, and what can or should be done about it.\n\nResearchers at the Overseas Development Institute have argued that biofuels could help to reduce poverty in the developing world, through increased employment, wider economic growth multipliers and by stabilising oil prices (many developing countries are net importers of oil). However, this potential is described as 'fragile', and is reduced where feedstock production tends to be large scale, or causes pressure on limited agricultural resources: capital investment, land, water, and the net cost of food for the poor.\n\nWith regards to the potential for poverty reduction or exacerbation, biofuels rely on many of the same policy, regulatory or investment shortcomings that impede agriculture as a route to poverty reduction. Since many of these shortcomings require policy improvements at a country level rather than a global one, they argue for a country-by-country analysis of the potential poverty effects of biofuels. This would consider, among other things, land administration systems, market coordination and prioritizing investment in biodiesel, as this 'generates more labour, has lower transportation costs and uses simpler technology'. Also necessary are reductions in the tariffs on biofuel imports regardless of the country of origin, especially due to the increased efficiency of biofuel production in countries such as Brazil.\n\nResponsible policies and economic instruments would help to ensure that biofuel commercialization, including the development of new cellulosic technologies, is sustainable. Responsible commercialization of biofuels represents an opportunity to enhance sustainable economic prospects in Africa, Latin America and impoverished Asia.\n\nLarge-scale deforestation of mature trees (which help remove CO through photosynthesis — much better than sugar cane or most other biofuel feedstock crops do) contributes to soil erosion, un-sustainable global warming atmospheric greenhouse gas levels, loss of habitat, and a reduction of valuable biodiversity (both on land as in oceans). Demand for biofuel has led to clearing land for palm oil plantations. In Indonesia alone, over of forest have been converted to plantations since 1996.\nA portion of the biomass should be retained onsite to support the soil resource. Normally this will be in the form of raw biomass, but processed biomass is also an option. If the exported biomass is used to produce syngas, the process can be used to co-produce biochar, a low-temperature charcoal used as a soil amendment to increase soil organic matter to a degree not practical with less recalcitrant forms of organic carbon. For co-production of biochar to be widely adopted, the soil amendment and carbon sequestration value of co-produced charcoal must exceed its net value as a source of energy.\n\nSome commentators claim that removal of additional cellulosic biomass for biofuel production will further deplete soils.\n\nIncreased use of biofuels puts increasing pressure on water resources in at least two ways: water use for the irrigation of crops used as feedstocks for biodiesel production; and water use in the production of biofuels in refineries, mostly for boiling and cooling.\n\nIn many parts of the world supplemental or full irrigation is needed to grow feedstocks. For example, if in the production of corn (maize) half the water needs of crops are met through irrigation and the other half through rainfall, about 860 liters of water are needed to produce one liter of ethanol. However, in the United States only 5-15% of the water required for corn comes from irrigation while the other 85-95% comes from natural rainfall.\n\nIn the United States, the number of ethanol factories has almost tripled from 50 in 2000 to about 140 in 2008. A further 60 or so are under construction, and many more are planned. Projects are being challenged by residents at courts in Missouri (where water is drawn from the Ozark Aquifer), Iowa, Nebraska, Kansas (all of which draw water from the non-renewable Ogallala Aquifer), central Illinois (where water is drawn from the Mahomet Aquifer) and Minnesota.\n\nFor example, the four ethanol crops: corn, sugarcane, sweet sorghum and pine yield net energy. However, increasing production in order to meet the U.S. Energy Independence and Security Act mandates for renewable fuels by 2022 would take a heavy toll in the states of Florida and Georgia. The sweet sorghum, which performed the best of the four, would increase the amount of freshwater withdrawals from the two states by almost 25%.\n\nFormaldehyde, acetaldehyde and other aldehydes are produced when alcohols are oxidized. When only a 10% mixture of ethanol is added to gasoline (as is common in American E10 gasohol and elsewhere), aldehyde emissions increase 40%. Some study results are conflicting on this fact however, and lowering the sulfur content of biofuel mixes lowers the acetaldehyde levels. Burning biodiesel also emits aldehydes and other potentially hazardous aromatic compounds which are not regulated in emissions laws.\n\nMany aldehydes are toxic to living cells. Formaldehyde irreversibly cross-links protein amino acids, which produces the hard flesh of embalmed bodies. At high concentrations in an enclosed space, formaldehyde can be a significant respiratory irritant causing nose bleeds, respiratory distress, lung disease, and persistent headaches. Acetaldehyde, which is produced in the body by alcohol drinkers and found in the mouths of smokers and those with poor oral hygiene, is carcinogenic and mutagenic.\n\nThe European Union has banned products that contain Formaldehyde, due to its documented carcinogenic characteristics. The U.S. Environmental Protection Agency has labeled Formaldehyde as a probable cause of cancer in humans.\n\nBrazil burns significant amounts of ethanol biofuel. Gas chromatograph studies were performed of ambient air in São Paulo, Brazil, and compared to Osaka, Japan, which does not burn ethanol fuel. Atmospheric Formaldehyde was 160% higher in Brazil, and Acetaldehyde was 260% higher.\n\nDespite its occasional proclamation as a “green” fuel, first-generation biofuels, primarily ethanol, are not without their own GHG emissions. While ethanol does produce fewer overall GHG emissions than gasoline, its production is still an energy intensive process with secondary effects. Gasoline generally produces 8.91 kg CO2 per gallon, compared to 8.02 kg CO2 per gallon for E10 ethanol and 1.34 kg CO2 per gallon for E85 ethanol. Based on a study by Dias de Oliveira et al. (2005), corn-based ethanol requires 65.02 gigajoules (GJ) of energy per hectare (ha) and produces approximately 1236.72 kg per ha of carbon dioxide (CO2), while sugar cane-based ethanol requires 42.43 GJ/ha and produces 2268.26 kg/ha of CO2 under the assumption of non-carbon neutral energy production. These emissions accrue from agricultural production, crop cultivation, and ethanol processing. Once the ethanol is blended with gasoline, it results in carbon-savings of approximately 0.89 kg of CO2 per gallon consumed (U.S. D.O.E., 2011a).\n\nFrom a production standpoint, miscanthus can produce 742 gallons of ethanol per acre of land, which is nearly twice as much as corn (399 gal/acre, assuming average yield of 145 bushels per acre under normal corn-soybean rotation) and nearly three times as much as corn stover (165 gal/acre) and switchgrass (214 gal/acre). Production costs are a big impediment to large-scale implementation of 2nd Generation bio-fuels, and their market demand will depend primarily on their price competitiveness relative to corn ethanol and gasoline. At this time, costs of conversion of cellulosic fuels, at $1.46 per gallon, were roughly twice that of corn-based ethanol, at $0.78 per gallon. Cellulosic biofuels from corn stover and miscanthus were 24% and 29% more expensive than corn ethanol, respectively, and switchgrass biofuel is more than twice as expensive as corn ethanol.\n\nBiofuels and other forms of renewable energy aim to be carbon neutral or even carbon negative. Carbon neutral means that the carbon released during the use of the fuel, e.g. through burning to power transport or generate electricity, is reabsorbed and balanced by the carbon absorbed by new plant growth. These plants are then harvested to make the next batch of fuel. Carbon neutral fuels lead to no net increases in human contributions to atmospheric carbon dioxide levels, reducing the human contributions to global warming. A carbon negative aim is achieved when a portion of the biomass is used for carbon sequestration. Calculating exactly how much greenhouse gas (GHG) is produced in burning biofuels is a complex and inexact process, which depends very much on the method by which the fuel is produced and other assumptions made in the calculation.\n\nThe carbon emissions (carbon footprint) produced by biofuels are calculated using a technique called Life Cycle Analysis (LCA). This uses a \"cradle to grave\" or \"well to wheels\" approach to calculate the total amount of carbon dioxide and other greenhouse gases emitted during biofuel production, from putting seed in the ground to using the fuel in cars and trucks. Many different LCAs have been done for different biofuels, with widely differing results. Several well-to-wheel analysis for biofuels has shown that first generation biofuels can reduce carbon emissions, with savings depending on the feedstock used, and second generation biofuels can produce even higher savings when compared to using fossil fuels. However, those studies did not take into account emissions from nitrogen fixation, or additional carbon emissions due to indirect land use changes. In addition, many LCA studies fail to analyze the effect of substitutes that may come into the market to replace current biomass-based products. In the case of Crude Tall Oil, a raw material used in the production of pine chemicals and now being diverted for use in biofuel, an LCA study found that the global carbon footprint of pine chemicals produced from CTO is 50 percent lower than substitute products used in the same situation offsetting any gains from utilizing a biofuel to replace fossil fuels. Additionally the study showed that fossil fuels are not reduced when CTO is diverted to biofuel use and the substitute products consume disproportionately more energy. This diversion will negatively affect an industry that contributes significantly to the world economy, globally producing more than 3 billion pounds of pine chemicals annually in complex, high technology refineries and providing jobs directly and indirectly for tens of thousands of workers.\n\nA paper published in February 2008 in Sciencexpress by a team led by Searchinger from Princeton University concluded that once considered indirect land use changes effects in the life cycle assessment of biofuels used to substitute gasoline, instead of savings both corn and cellulosic ethanol increased carbon emissions as compared to gasoline by 93 and 50 percent respectively. A second paper published in the same issue of Sciencexpress, by a team led by Fargione from The Nature Conservancy, found that a carbon debt is created when natural lands are cleared and being converted to biofuel production and to crop production when agricultural land is diverted to biofuel production, therefore this carbon debt applies to both direct and indirect land use changes.\n\nThe Searchinger and Fargione studies gained prominent attention in both the popular media and in scientific journals. The methodology, however, drew some criticism, with Wang and Haq from Argonne National Laboratory posted a public letter and send their criticism about the Searchinger paper to Letters to Science. Another criticism by Kline and Dale from Oak Ridge National Laboratory was published in Letters to Science. They argued that Searchinger et al. and Fargione et al. \"...\"do not provide adequate support for their claim that biofuels cause high emissions due to land-use change\". The U.S. biofuel industry also reacted, claiming in a public letter, that the \"\"Searchinger study is clearly a \"worst-case scenario\" analysis...\" and that this study \"relies on a long series of highly subjective assumptions...\"\".\n\nThe modifications necessary to run internal combustion engines on biofuel depend on the type of biofuel used, as well as the type of engine used. For example, gasoline engines can run without any modification at all on biobutanol. Minor modifications are however needed to run on bioethanol or biomethanol. Diesel engines can run on the latter fuels, as well as on vegetable oils (which are cheaper). However, the latter is only possible when the engine has been foreseen with indirect injection. If no indirect injection is present, the engine hence needs to be fitted with this.\n\nA number of environmental NGOs campaign against the production of biofuels as a large-scale alternative to fossil fuels. For example, Friends of the Earth state that \"the current rush to develop agrofuels (or biofuels) on a large scale is ill-conceived and will contribute to an already unsustainable trade whilst not solving the problems of climate change or energy security\". Some mainstream environmental groups support biofuels as a significant step toward slowing or stopping global climate change. However, supportive environmental groups generally hold the view that biofuel production can threaten the environment if it is not done sustainably. This finding has been backed by reports of the UN, the IPCC, and some other smaller environmental and social groups as the EEB and the Bank Sarasin, which generally remain negative about biofuels.\n\nAs a result, governmental and environmental organizations are turning against biofuels made in a non-sustainable way (hereby preferring certain oil sources as jatropha and lignocellulose over palm oil) and are asking for global support for this. Also, besides supporting these more sustainable biofuels, environmental organizations are redirecting to new technologies that do not use internal combustion engines such as hydrogen and compressed air.\n\nSeveral standard-setting and certification initiatives have been set up on the topic of biofuels. The \"Roundtable on Sustainable Biofuels\" is an international initiative which brings together farmers, companies, governments, non-governmental organizations, and scientists who are interested in the sustainability of biofuels production and distribution. During 2008, the Roundtable is developing a series of principles and criteria for sustainable biofuels production through meetings, teleconferences, and online discussions. In a similar vein, the Bonsucro standard has been developed as a metric-based certificate for products and supply chains, as a result of an ongoing multi-stakeholder initiative focussing on the products of sugar cane, including ethanol fuel.\n\nThe increased manufacture of biofuels will require increasing land areas to be used for agriculture. Second and third generation biofuel processes can ease the pressure on land, because they can use waste biomass, and existing (untapped) sources of biomass such as crop residues and potentially even marine algae.\n\nIn some regions of the world, a combination of increasing demand for food, and increasing demand for biofuel, is causing deforestation and threats to biodiversity. The best reported example of this is the expansion of oil palm plantations in Malaysia and Indonesia, where rainforest is being destroyed to establish new oil palm plantations. It is an important fact that 90% of the palm oil produced in Malaysia is used by the food industry; therefore biofuels cannot be held solely responsible for this deforestation. There is a pressing need for sustainable palm oil production for the food and fuel industries; palm oil is used in a wide variety of food products. The \"Roundtable on Sustainable Biofuels\" is working to define criteria, standards and processes to promote sustainably produced biofuels. Palm oil is also used in the manufacture of detergents, and in electricity and heat generation both in Asia and around the world (the UK burns palm oil in coal-fired power stations to generate electricity).\n\nSignificant area is likely to be dedicated to sugar cane in future years as demand for ethanol increases worldwide. The expansion of sugar cane plantations will place pressure on environmentally sensitive native ecosystems including rainforest in South America. In forest ecosystems, these effects themselves will undermine the climate benefits of alternative fuels, in addition to representing a major threat to global biodiversity.\n\nAlthough biofuels are generally considered to improve net carbon output, biodiesel and other fuels do produce local air pollution, including nitrogen oxides, the principal cause of smog.\n\n\n"}
{"id": "10864058", "url": "https://en.wikipedia.org/wiki?curid=10864058", "title": "Keggin structure", "text": "Keggin structure\n\nKeggin structure is the best known structural form for heteropoly acids. It is the structural form of α-Keggin anions, which have a general formula of [XMO], where X is the heteroatom (most commonly are P, Si, or B), M is the addenda atom (most common are molybdenum and tungsten), and O represents oxygen. The structure self-assembles in acidic aqueous solution and is the most stable structure of polyoxometalate catalysts.\n\nThe first α-Keggin anion, ammonium phosphomolybdate ((NH)[PMoO]), was first reported by Berzelius in 1826. In 1892, Blomstrand proposed the structure of phosphomolybdic acid and other poly-acids as a chain or ring configuration. Alfred Werner, using the coordination compounds ideas of Copaux, attempted to explain the structure of silicotungstic acid. He assumed a central group, [SiO] ion, enclosed by four [RWO], where R is a unipositive ion. The [RWO] are linked to the central group by primary valences. Two more RWO groups were linked to the central group by secondary valences. This proposal accounted for the characteristics of most poly-acids, but not all.\n\nIn 1928, Linus Pauling proposed a structure for α-Keggin anions consisting of a tetrahedral central ion, [XO], caged by twelve WO octahedral. In this proposed structure, three of the oxygen on each of the octahedral shared electrons with three neighboring octahedral. As a result, 18 oxygen atoms were used as bridging atoms between the metal atoms. The remaining oxygen atoms bonded to a proton. This structure explained many characteristics that were observed such as basicities of alkali metal salts and the hydrated of some of the salts. However the structure could not explain the structure of dehydrated acids.\n\nJames Fargher Keggin with the use of X-ray diffraction experimentally determined the structure of α-Keggin anions in 1934. The Keggin structure accounts for both the hydrated and dehydrated α-Keggin anions without a need for significant structural change. The Keggin structure is the widely accepted structure for the α-Keggin anions.\n\n +\n\nThe structure is composed of one heteroatom surrounded by four oxygen atoms to form a tetrahedron. The heteroatom is located centrally and caged by 12 octahedral MO-units linked to one another by the neighboring oxygen atoms. There are a total of 24 bridging oxygen atoms that link the 12 addenda atoms. The metal centres in the 12 octahedra are arranged on a sphere almost equidistant from each other, in four MO units, giving the complete structure an overall tetrahedral symmetry. The bond length between atoms varies depending on the heteroatom (X) and the addenda atoms (M). For the 12–phosphotungstic acid, Keggin determined the bond length between the heteroatom and each the four central oxygen atoms to be 1.5 Å. The bond length form the central oxygen to the addenda atoms is 2.43 Å. The bond length between the addenda atoms and each of the bridging oxygen is 1.9 Å. The remaining 12 oxygen atoms that are each double bonded to an addenda atom have a bond length of 1.70 Å. The octahedra are therefore distorted. This structure allows the molecule to hydrate and dehydrate without significant structural changes and the molecule is thermally stable in the solid state for use in vapor phase reactions at high temperatures (400−500 °C).\n\nIncluding the original Keggin structure there are 5 isomers, designated by the prefixes α-, β-, γ-, δ- and ε-. The original Keggin structure is designated α-. These isomers are sometimes termed Baker, Baker-Figgis or rotational isomers, These involve different rotational orientations of the MoO units, which lowers the symmetry of the overall structure.\n\nThe term \"lacunary\" is applied to ions which have a fragment missing, sometimes called defect structures. Examples are the (XMO) and (XMO) formed by the removal from the Keggin structure of sufficient Mo and O atoms to eliminate 1 or 3 adjacent MO octahedra. The Dawson structure, XMO, is made up of two Keggin lacunary fragments with 3 missing octahedra.\nThe cluster cation (AlO(OH)(HO)) has the Keggin structure with a tetrahedral Al atom in the centre of the cluster coordinated to 4 oxygen atoms. The formula can be expressed as (AlOAl(OH)(HO)). This ion is generally called the Al13 ion. A Ga13 analogue is known an unusual ionic compound with an Al13 cation and a Keggin polyoxoanion has been characterised.\n\nDue to the similar aqueous chemistries of aluminum and iron, it has been long thought that an analogous iron polycation should be isolatable from water. Moreover, in 2007, the structure of ferrihydrite was determined and shown to be built of iron Keggin ions. This further captured scientists’ imagination and drive to isolate the iron Keggin ion. In 2015, the iron Keggin ion was isolated from water, but as a polyanion with a −17 charge; and protecting chemistry was required. Iron-bound water is very acidic; so it is difficult to capture the intermediate Keggin ion form without bulky and nonprotic ligands instead of the water that is found in the aluminum Keggin ion. However, more important in this synthesis was the bismuth (Bi) counterions that provided high positive charge to stabilize the high negative charge of the heptadecavalent polyanion.\n\nThe stability of the Keggin structure allows the metals in the anion to be readily reduced. Depending on the solvent, acidity of the solution and the charge on the α-Keggin anion, it can be reversibly reduced in one- or multiple-electron steps. For example, silicotungstate anion can be reduced to 20th state. Some anions such as silicotungstic acid are strong enough as an acid as sulfuric acid and can be used in its place as an acid catalyst.\n\nIn general α-Keggin anions are synthesized in acidic solutions. For example, 12-Phosphotungstic acid is formed by condensing phosphate ion with tungstate ions. The heteropolyacid that is formed has the Keggin structure.\n\nα-Keggin anions have been used as catalyst in the following reactions: hydration, polymerization and oxidation reaction as catalysts. Japanese chemical companies have commercialized the use of the compounds in hydration of propene, oxidation of methacrolein, hydration isobutene, hydration of \"n\"-butene, and polymerization of THF.\n\n12-Phosphotungstic acid, the compound J.F. Keggin used to determine the structure, can be purchased commercially. Other compounds that contain the α-Keggin anion such as silicotungstic acid and phosphomolybdic acid are also commercially available at Aldrich Chemicals, Fisher Chemicals, Alfa Aesar, VWR Chemical, American Elements, etc.\n"}
{"id": "26794949", "url": "https://en.wikipedia.org/wiki?curid=26794949", "title": "Kline–Fogleman airfoil", "text": "Kline–Fogleman airfoil\n\nThe Kline–Fogleman airfoil or KF airfoil is a simple airfoil design with single or multiple steps along the length of the wing. It was originally devised around 50 years ago for paper airplanes.\n\nIn the 21st century the KF airfoil has found renewed interest among hobbyist builders of radio-controlled aircraft, due to its simplicity of construction. But it has not been adopted for full-size aircraft capable of carrying a pilot, passengers, or other substantial payloads.\n\nThe KF airfoil was designed by Richard Kline and Floyd Fogleman.\nIn the early 1960s, Richard Kline wanted to make a paper airplane that could handle strong winds, climb high, level off by itself and then enter a long downwards glide. After many experiments he was able to achieve this goal. He presented the paper airplane to Floyd Fogleman who saw it fly and resist stalling. The two men then filed for a patent on the stepped airfoil.\n\nFurther development resulted in two patents and a family of airfoils known as the KF airfoil and KFm airfoils (for Kline–Fogleman modified). The two patents, US Patent # 3,706,430 and US Patent # 4,046,338, refer to the introduction of a step either on the bottom (KFm1) or on the top of an airfoil (KFm2), or both on top and bottom (KFm4). It can also be used with two steps on the top (KFm3), or two steps on the top and one on the bottom (KFm7).\n\nThe purpose of the step, it is claimed, is to allow some of the displaced air to fall into a pocket behind the step and become part of the airfoil shape as a trapped vortex or vortex attachment. This purportedly prevents separation and maintains airflow over the surface of the airfoil.\n\n\"Time\" published an April 2, 1973 article,\"The Paper-Plane Caper\" about the paper airplane and its Kline–Fogleman airfoil.\n\nAlso in 1973, CBS 60 Minutes did a 15-minute segment on the KF airfoil. It repeated the show again in 1976.\n\nIn 1985, Kline wrote a book entitled \"The Ultimate Paper Airplane\". To publicize the book, he went down to Kill Devil Hills, NC in 1985, to the site where the Wright Brothers first flew where their first manned powered flight went 122 feet. A crew from Good Morning America came along to film the event. The longest flight by Kline with his paper airplane traveled 401 feet, four inches.\n\nIn 1974, a NASA-funded study prompted by Kline and Fogelman's claims and the resulting national coverage found the airfoil to have worse lift-to-drag ratio than a flat plate airfoil in wind tunnel tests.\n\nIn the 1990s, with 20 years of technical progress opening up new possibilities and with the original patents expired, researchers returned to the topic of stepped wings. A 1998 study by Fathi Finaish and Stephen Witherspoon at the University of Missouri tested numerous step configurations in a wind tunnel. While many made wing performance worse, they got promising results with backward-facing steps on the lower surface of the wing – in some cases giving considerable enhancement in lift without much of a drag penalty. However, they concluded that a single configuration could not be best solution at every angle of attack and flight speed. Indeed, \"vastly different configurations may be needed during a single maneuver.\" The idea works, Finaish and Witherspoon concluded, but only with active automated re-configuration of the shape of the step(s) during flight. Further testing has shown that this airfoil is effective in low Reynolds number flow.\n\nA 2008 study by Fabrizio De Gregorio and Giuseppe Fraioli at CIRA and the University of Rome in Italy tried this out. The model aerofoils used in their wind tunnel tests were equipped with numerous small holes through which air could be blown or sucked in an active way.\n\nThey concluded that the trapped vortex formed by a cavity or step could not be held in place without such active control. Just relying passively on wing shape wasn't enough – the vortex would detach possibly giving you worse characteristics than the original unstepped airfoil. But when active controls were used to keep the vortex stably in place they found the results \"really encouraging\".\n\nSuch scientific experimental work seems to have put paid to the idea that the original KF airfoil will find a simple practical application in the world of full-size aircraft. But the basic idea of the stepped wing has mutated, and is now bound up with a new body of research into actively controlling the airflow over a wing's surface with new mechanisms unthinkable 50 years ago.\n\nResearch led by Ranganadhan Voona in 2012 at Missouri University of Science and Technology was to investigate the lift and drag characteristics of a stepped airfoil with backward facing steps; apply active flow control technique to enhance the aerodynamic performance of stepped airfoils and examine the possibility of using such airfoils on Unmanned Aerial Vehicles (UAV’s). A step was introduced at mid-chord, with a depth of 50% of the airfoil thickness at mid-chord position extending till the trailing edge of a NACA 4415 airfoil.\n\nComputational studies were conducted with the use of passive flow control constituting the activation of step and active flow control with the use of air injecting jets placed in the step cavity of the NACA 4415 airfoil with a goal of enhancing the aerodynamic performance. The jet angle and jet momentum coefficient were varied independently to identify the best setting for optimizing the aerodynamic performance of the stepped airfoil. Studies of a scaled wing model with the same airfoil were conducted within a wind tunnel for a range of Reynolds numbers to validate some of the numerical results that were obtained or the cases of base and stepped airfoils. The results that were produced showed that as much as 37% increase in Cl and as much as 12% increase in L/D ratios over conventional airfoil values could be obtained by using stepped airfoils.\n\nThe case study conducted as a part of this research focuses on the UAV RQ-2 Pioneer employed in a stepped airfoil configuration by comparing its aerodynamic characteristics with the conventional NACA 4415 airfoil originally used on this aircraft. The main objective of the case study was to identify and outline a step schedule for the flight envelope of the UAV Pioneer using a stepped airfoil configuration at the same time applying active flow control to obtain enhanced aerodynamic performance over conventional NACA 4415 airfoil originally used and hence improve the flight performance characteristics like Range and Endurance of the aircraft.\n\nPoor lift-to-drag ratio performance in wind tunnel testing has meant that to date the KF airfoil has not been used on any full size aircraft. But the KF airfoil and derivative 'stepped' airfoils have in recent years gained a following in the world of foam constructed radio controlled model aircraft. The low Reynolds numbers allow for the stepped airfoils to produce a significant amount of lift for the drag inured, making them increasingly popular among RC hobbyist.\n\nThe simple KF airfoil shape lends itself well to construction in sheets of various plastic foams, typically expanded polystyrene (EPS) or expanded polypropylene (EPP). The resulting stepped wing can have improved performance and flying characteristics compared to the even simpler 'flat plate' wing used in some radio-controlled models. The Airfoils illustrated in this article are examples of those used in radio control foam models.\n\nThe first man carrying KF airfoil based aircraft was successfully flown in 1986 by Richard Wood in Canada. Top speed was higher and stall was slower. The airfoil was tested on a Vector 600 ultralight.\n\nThe KF airfoil has been applied to the Darrieus wind turbine using a trapped vortex. Experiments have found the KF rotor demonstrates a higher static and dynamic torque with low Reynolds applications and better performance for wind conditions lower than 0.8 m/s. It is seen a potential solution for self-starting in the Darrieus wind turbine.\n\n\n\n"}
{"id": "35014484", "url": "https://en.wikipedia.org/wiki?curid=35014484", "title": "Le Fil vert", "text": "Le Fil vert\n\nLe Fil vert is a 2010 documentary film.\n\nCan cultural heritage and ancient customs help conserve the environment and biodiversity? This is what this documentary shows as it offers us images of typical plants from Morocco.\n\n"}
{"id": "863712", "url": "https://en.wikipedia.org/wiki?curid=863712", "title": "Liquid breathing", "text": "Liquid breathing\n\nLiquid breathing is a form of respiration in which a normally air-breathing organism breathes an oxygen-rich liquid (such as a perfluorocarbon), rather than breathing air.\n\nThis requires certain physical properties such as respiratory gas solubility, density, viscosity, vapor pressure, and lipid solubility which some, but not all, perfluorochemicals (perfluorocarbon) have. Thus, it is critical to choose the appropriate PFC for a specific biomedical application, such as liquid ventilation, drug delivery or blood substitutes. The physical properties of PFC liquids vary substantially; however, the one common property is their high solubility for respiratory gases. In fact, these liquids carry more oxygen and carbon dioxide than blood.\n\nIn theory, liquid breathing could assist in the treatment of patients with severe pulmonary or cardiac trauma, especially in pediatric cases. Liquid breathing has also been proposed for use in deep diving and space travel. Despite some recent advances in liquid ventilation, a standard mode of application has not yet been established.\n\nBecause liquid breathing is still a highly experimental technique, there are several proposed approaches.\n\nAlthough total liquid ventilation (TLV) with completely liquid-filled lungs can be beneficial, the complex liquid-filled tube system required is a disadvantage compared to gas ventilation—the system must incorporate a membrane oxygenator, heater, and pumps to deliver to, and remove from the lungs tidal volume aliquots of conditioned perfluorocarbon (PFC). One research group led by Thomas H. Shaffer has maintained that with the use of microprocessors and new technology, it is possible to maintain better control of respiratory variables such as liquid functional residual capacity and tidal volume during TLV than with gas ventilation. Consequently, the total liquid ventilation necessitates a dedicated liquid ventilator similar to a medical ventilator except that it uses a breatheable liquid. Many prototypes are used for animal experimentation, but experts recommend continued development of a liquid ventilator toward clinical applications.\nSpecific preclinical liquid ventilator (Inolivent) is currently under joint development in Canada and France. The main application of this liquid ventilator is the ultra-fast induction of therapeutic hypothermia after cardiac arrest. This has been demonstrated to be more protective than slower cooling method after experimental cardiac arrest.\n\nIn contrast, partial liquid ventilation (PLV) is a technique in which a PFC is instilled into the lung to a volume approximating functional residual capacity (approximately 40% of total lung capacity). Conventional mechanical ventilation delivers tidal volume breaths on top of it. This mode of liquid ventilation currently seems technologically more feasible than total liquid ventilation, because PLV could utilise technology currently in place in many neonatal intensive-care units (NICU) worldwide.\n\nThe influence of PLV on oxygenation, carbon dioxide removal and lung mechanics has been investigated in several animal studies using different models of lung injury. Clinical applications of PLV have been reported in patients with acute respiratory distress syndrome (ARDS), meconium aspiration syndrome, congenital diaphragmatic hernia and respiratory distress syndrome (RDS) of neonates. In order to correctly and effectively conduct PLV, it is essential to\nIf PFC liquid is not maintained in the lung, PLV can not effectively protect the lung from biophysical forces associated with the gas ventilator.\n\nNew application modes for PFC have been developed.\n\nPartial liquid ventilation (PLV) involves filling the lungs with a fluid. This fluid is perfluorocarbon, also called Liquivent or Perflubron. The liquid has some unique properties. It has a very low surface tension, similar to surfactant, a substance that is produced in the lungs to prevent the alveoli from collapsing and sticking together during exhalation. It also has a high density, oxygen readily diffuses through it, and it may have some anti-inflammatory properties. In PLV, the lungs are filled with the liquid, the patient is then ventilated with a conventional ventilator using a protective lung ventilation strategy. This is called partial liquid ventilation. The hope is that the liquid will help the transport of oxygen to parts of the lung that are flooded and filled with debris, help remove this debris and open up more alveoli improving lung function. The study of PLV involves comparison to protocolized ventilator strategy designed to minimize lung damage.\n\nVaporization of perfluorohexane with two anesthetic vaporizers calibrated for perfluorohexane has been shown to improve gas exchange in oleic acid-induced lung injury in sheep.\n\nPredominantly PFCs with high vapor pressure are suitable for vaporization.\n\nWith aerosolized perfluorooctane, significant improvement of oxygenation and pulmonary\nmechanics was shown in adult sheep with oleic acid-induced lung injury.\n\nIn surfactant-depleted piglets, persistent improvement of gas exchange and lung mechanics was demonstrated with Aerosol-PFC.\nThe aerosol device is of decisive importance for the efficacy of PFC aerosolization, as aerosolization of PF5080 (a less purified FC77) has been shown to be ineffective using a different aerosol device in surfactant-depleted rabbits. Partial liquid ventilation and Aerosol-PFC reduced pulmonary inflammatory response.\n\nGas pressure increases with depth, rising 1 bar () every 10 meters to over 1,000 bar at the bottom of the Mariana Trench. Diving becomes more dangerous as depth increases, and deep diving presents many hazards. All surface-breathing animals are subject to decompression sickness, including aquatic mammals and free-diving humans (see \"taravana\"). Breathing at depth can cause nitrogen narcosis and oxygen toxicity. Holding the breath while ascending after breathing at depth can cause air embolisms, burst lung, and collapsed lung.\n\nSpecial breathing gas mixes such as trimix or heliox ameliorate the risk of decompression illness but do not eliminate it. Heliox further eliminates the risk of nitrogen narcosis but introduces the risk of helium tremors below about . Atmospheric diving suits maintain body and breathing pressure at 1 bar, eliminating most of the hazards of descending, ascending, and breathing at depth. However, the rigid suits are bulky, clumsy, and very expensive.\n\nLiquid breathing offers a third option, promising the mobility available with flexible dive suits and the reduced risks of rigid suits. With liquid in the lungs, the pressure within the diver's lungs could accommodate changes in the pressure of the surrounding water without the huge gas partial pressure exposures required when the lungs are filled with gas. Liquid breathing would not result in the saturation of body tissues with high pressure nitrogen or helium that occurs with the use of non-liquids, thus would reduce or remove the need for slow decompression.\n\nA significant problem, however, arises from the high viscosity of the liquid and the corresponding reduction in its ability to remove CO. All uses of liquid breathing for diving must involve total liquid ventilation (see above). Total liquid ventilation, however, has difficulty moving enough liquid to carry away CO, because no matter how great the total pressure is, the amount of partial CO gas pressure available to dissolve CO into the breathing liquid can never be much more than the pressure at which CO exists in the blood (about 40 mm of mercury (Torr)).\n\nAt these pressures, most fluorocarbon liquids require about 70 mL/kg minute-ventilation volumes of liquid (about 5 L/min for a 70 kg adult) to remove enough CO for normal resting metabolism. This is a great deal of fluid to move, particularly as liquids are more viscous and denser than gases, (for example water is about 850 times the density of air). Any increase in the diver's metabolic activity also increases CO production and the breathing rate, which is already at the limits of realistic flow rates in liquid breathing. It seems unlikely that a person would move 10 liters/min of fluorocarbon liquid without assistance from a mechanical ventilator, so \"free breathing\" may be unlikely. However, it has been suggested that a liquid breathing system could be combined with a CO scrubber connected to the diver's blood supply; a US patent has been filed for such a method.\n\n The most promising area for the use of liquid ventilation is in the field of pediatric medicine. The first medical use of liquid breathing was treatment of premature babies and adults with acute respiratory distress syndrome (ARDS) in the 1990s. Liquid breathing was used in clinical trials after the development by Alliance Pharmaceuticals of the fluorochemical perfluorooctyl bromide, or perflubron for short. Current methods of positive-pressure ventilation can contribute to the development of lung disease in pre-term neonates, leading to diseases such as bronchopulmonary dysplasia. Liquid ventilation removes many of the high pressure gradients responsible for this damage. Furthermore, perfluorocarbons have been demonstrated to reduce lung inflammation, improve ventilation-perfusion mismatch and to provide a novel route for the pulmonary administration of drugs.\n\nIn order to explore drug delivery techniques that would be useful for both partial and total liquid ventilation, more recent studies have focused on PFC drug delivery using a nanocrystal suspension. The first image is a computer model of a PFC liquid (perflubron) combined with gentamicin molecules.\n\nThe second image shows experimental results comparing both plasma and tissue levels of gentamicin after an intratracheal (IT) and intravenous (IV) dose of 5 mg/kg in a newborn lamb during gas ventilation. Note that the plasma levels of the IV dose greatly exceed the levels of the IT dose over the 4 hour study period; whereas, the lung tissue levels of gentamicin when delivered by an intratracheal (IT) suspension, uniformly exceed the intravenous (IV) delivery approach after 4 hours. Thus, the IT approach allows more effective delivery of the drug to the target organ while maintaining a safer level systemically. Both images represent the in-vivo time course over 4 hours. Numerous studies have now demonstrated the effectiveness of PFC liquids as a delivery vehicle to the lungs.\n\nClinical trials with premature infants, children and adults were conducted. Since the safety of the procedure and the effectiveness were apparent from an early stage, the US Food and Drug Administration (FDA) gave the product \"fast track\" status (meaning an accelerated review of the product, designed to get it to the public as quickly as is safely possible) due to its life-saving potential. Clinical trials showed that using perflubron with ordinary ventilators improved outcomes as much as using high frequency oscillating ventilation (HFOV). But because perflubron was not better than HFOV, the FDA did not approve perflubron, and Alliance is no longer pursuing the partial liquid ventilation application. Whether perflubron would improve outcomes when used with HFOV or has fewer long-term consequences than HFOV remains an open question.\n\nIn 1996 Mike Darwin and Steven B. Harris proposed using cold liquid ventilation with perfluorocarbon to quickly lower the body temperature of victims of cardiac arrest and other brain trauma to allow the brain to better recover.\nThe technology came to be called gas/liquid ventilation (GLV), and was shown able to achieve a cooling rate of 0.5 °C per minute in large animals. It has not yet been tried in humans.\n\nMost recently, hypothermic brain protection has been associated with rapid brain cooling. In this regard, a new therapeutic approach is the use of intranasal perfluorochemical spray for preferential brain cooling. The nasopharyngeal (NP) approach is unique for brain cooling due to anatomic proximity to the cerebral circulation and arteries. Based on preclinical studies in adult sheep, it was shown that independent of region, brain cooling was faster during NP-perfluorochemical versus conventional whole body cooling with cooling blankets. To date, there have been four human studies including a completed randomized intra-arrest study (200 patients). Results clearly demonstrated that prehospital intra-arrest transnasal cooling is safe, feasible and is associated with an improvement in cooling time.\n\nLiquid immersion provides a way to reduce the physical stress of G forces. Forces applied to fluids are distributed as omnidirectional pressures. Because liquids cannot be practically compressed, they do not change density under high acceleration such as performed in aerial maneuvers or space travel. A person immersed in liquid of the same density as tissue has acceleration forces distributed around the body, rather than applied at a single point such as a seat or harness straps. This principle is used in a new type of G-suit called the Libelle G-suit, which allows aircraft pilots to remain conscious and functioning at more than 10 G acceleration by surrounding them with water in a rigid suit.\n\nAcceleration protection by liquid immersion is limited by the differential density of body tissues and immersion fluid, limiting the utility of this method to about 15 to 20 G.\nExtending acceleration protection beyond 20 G requires filling the lungs with fluid of density similar to water. An astronaut totally immersed in liquid, with liquid inside all body cavities, will feel little effect from extreme G forces because the forces on a liquid are distributed equally, and in all directions simultaneously. However effects will be felt because of density differences between different body tissues, so an upper acceleration limit still exists.\n\nLiquid breathing for acceleration protection may never be practical because of the difficulty of finding a suitable breathing medium of similar density to water that is compatible with lung tissue. Perfluorocarbon fluids are twice as dense as water, hence unsuitable for this application.\n\n\n\n\n\n"}
{"id": "18327974", "url": "https://en.wikipedia.org/wiki?curid=18327974", "title": "List of Lepidoptera that feed on Buddleja", "text": "List of Lepidoptera that feed on Buddleja\n\nBuddleja (or \"Buddleia\") species are used as food plants by the larvae (caterpillars) of a number of Lepidoptera species, including the following.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "33353007", "url": "https://en.wikipedia.org/wiki?curid=33353007", "title": "List of flash floods", "text": "List of flash floods\n\nThis list of notable flash floods summarizes the most widely reported events.\n\n"}
{"id": "31645223", "url": "https://en.wikipedia.org/wiki?curid=31645223", "title": "List of sandstones", "text": "List of sandstones\n\nThis is a list of types of sandstone that have been or are used economically as natural stone for building and other commercial or artistic purposes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElbe sandstones:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "20429217", "url": "https://en.wikipedia.org/wiki?curid=20429217", "title": "Marine diesel oil", "text": "Marine diesel oil\n\nMarine Diesel Oil (MDO) is a type of fuel oil and is a blend of gasoil and heavy fuel oil, with less gasoil than intermediate fuel oil used in the maritime field. Marine Diesel Oil is also called \"Distillate Marine Diesel\". MDO is widely used by medium speed and medium/high speed marine diesel engines. It is also used in the larger slow speed and medium speed propulsion engine which normally burn residual fuel. Those fuels resulting from a catalytic cracking/visbreaking refinery. Marine diesel oil has been condemned for its nimiety of sulfur, so many countries and organizations established regulations and laws on MDO use. Due to its lower price compared to more refined fuel, MDO is favored particularly by shipping industry. \n\nISO 8217 of the International Standards Organization (ISO) is the primary standard of MDO. \n\nMarine fuels range in viscosity from less than one centistoke (see viscosity) (cSt) to about 700 cSt at 50°C (122°F). (1 cSt = 1 mm2/s.) And higher viscosity grades are preheated during use to bring their viscosity into the range suitable for fuel injection (8 to 27 cSt). But MDO does not need to be preheated before using. According to Chevron, MDO has a sulfur limit varies from 1 to 4.5 percent by mass for different grades and Sulfur Emission Control Areas (SECAs). \n\nMDO is made from a catalytic cracking/visbreaking refinery. The catalytic cracking operation breaks large molecules into small molecules. It happens in high temperature and with appropriate catalyst. \nVisbreaking is a process that turn the bottom product of the vacuum unit, which has extremely high viscosity, into lower viscosity, marketable product. In visbreaking, a relatively mild thermal cracking operation is performed. And the amount of cracking is limited by the overruling requirement to safeguard the heavy fuel stability.\n\nThe market of MDO is much smaller than on-highway diesel. According to the a 2004 U.S. Diesel Fuel Sales statistics from U.S. Department of Energy, Energy Information Administration, Marine shipping only takes 3.7% of total diesel market. On the other hand, On-highway diesel takes up 59.5% of diesel fuel sales. This small sales share of MDO is due to the high proportion of petroleum resid that made it can be used on large marine engines. According to Chevron, petroleum resid, or inorganic salts, in the fuel result in injector tip deposits that prevent the injector from creating the desired fuel spray pattern. But those low-speed, large marine diesel engines are appropriate for using fuel containing large amounts of petroleum resid.\n\nThe International Maritime Organization (IMO) develops regulations for marine shipping. Among those regulations, MARPOL (the International Convention for the Prevention of Pollution from Ships) is the most widely adopted one. MARPOL is the main international convention covering the prevention of operational or accidental pollution of the marine environment by ships. Inside IMO, there is a committee called MEPC(Marine Environment Protection Committee). MEPC has meetings periodically and discuss resolutions to current marine pollution by adding amendments to its official documents.\n"}
{"id": "52035331", "url": "https://en.wikipedia.org/wiki?curid=52035331", "title": "Mene (unit)", "text": "Mene (unit)\n\nThe mĕnē (also mina, Aramaic) () is an ancient Mesopotamian unit of weight for gold or silver and one of the earliest written words for money. The mĕnē, like the shekel, was also a unit of currency. In ancient Greece, it originally equalled 70 drachmae and later was increased to 100 drachmae. The Greek word \"mna\" was borrowed from Semitic; compare Hebrew \"māneh\", Aramaic \"mĕnē\", Syriac \"manyā\", Ugaritic \"mn\", and Akkadian \"manū\".\nHowever, before it was used as currency, a mene was a unit of measurement, equal to 567 grams. One mĕnē of gold would be worth $23,000 USD and one mĕnē of silver would be worth $300 USD at today's metal prices.\n\nIn folk language used by sailors, the word \"mina\" or \"mines\" came to mean \"mines\", indicating mineral resources extracted from the ground.\n\nFrom earliest Sumerian times, a mĕnē was a unit of weight. At first, talents and shekels had not yet been introduced. By the time of Ur-Nammu, the mĕnē had a value of 1/60 talents as well as 60 shekels. The value of the mĕnē is calculated at 1.25 pounds or 0.571 kilograms per mĕnē (18.358 troy ounces).\n\nEvidence from Ugarit indicates that a mĕnē was equivalent to fifty shekels. The prophet Ezekiel refers to a mĕnē ('maneh' in the King James Version) as sixty shekels, in the Book of Ezekiel. Jesus of Nazareth tells the \"parable of the mĕnē\" in Luke 19:11-27.\n\nFrom the Akkadian period, 2 mĕnē was equal to 1 \"sila\" of water (cf. clepsydra, water clock).\nIn early 2016, noted gold investor Roy Sebag began to study and write about the global jewelry market which contributes the majority of the world's annual gold demand (2,000 tonnes) far exceeding demand for gold investment coins. Following extensive travels to India, Asia, and Southeast Asia, Sebag recognized an opportunity in bringing the ancient tradition for jewelry being a store of enduring value and accessible savings to the West.\n\nIn October 2016, Sebag founded Mene Inc. a luxury online jewelry venture along with Diana Widmaier Picasso the granddaughter of Pablo Picasso. Menē (meh-nay) derives its name from the ancient Mesopotamian unit of measurement, the Mene (unit) reflected 567 grams of pure gold and was one of the earliest written words for money. Menē designs, manufactures, and markets timeless 24 karat gold jewelry under the brand name Menē. The company retails its jewelry direct-to-consumer through a transparent and empowering online shopping experience. Through Mene.com, customers can buy, sell, and exchange their jewelry by weight at the prevailing daily price for gold as quoted on the international bullion markets. Menē is currently in closed private beta and will launch to the greater public in the fall of 2017.\n\n\n\nThe ancient Greek goddess Selene was also known by the ancient Greek term for moon \"Mene\". She was the goddess of the moon denoting the calendar or passage of time.\n"}
{"id": "23832262", "url": "https://en.wikipedia.org/wiki?curid=23832262", "title": "Micah Challenge", "text": "Micah Challenge\n\nThe Micah Challenge is an international campaign that encourages Christians to support the Millennium Development Goals. Their aim is to \"encourage our leaders to halve global poverty by 2015.\" \n\nThere are national campaigns in around 40 countries in all areas of the world.\n\nMicah Challenge UK\n"}
{"id": "23149538", "url": "https://en.wikipedia.org/wiki?curid=23149538", "title": "Ministry of Energy and Mines (Peru)", "text": "Ministry of Energy and Mines (Peru)\n\nThe Ministry of Energy and Mines of Peru (Spanish: \"Ministerio de Energía y Minas de Perú\", MINEM), is an entity of the Peruvian government responsible for managing the energy and mining sectors of Peru. Additionally, it is charged with overseeing the equal distribution of energy throughout the country. The current minister is Francisco Ísmodes.\n\n1. To promote the proportional, efficient, and competitive use and development of energy resources in the context of decentralization and regional development, prioritizing private investment, meeting demand, as well as the employment of alternative energy in the process of rural electrification.\n\n2. To promote the development of the mining sub sector, to impulse private investment and legal stability, to encourage the fair exploitation and implementation of clean energy technologies in small-scale mining and in the context of the process of regional decentralization.\n\n3. To promote the protection of the environment, with respect to energy and mining corporations as well as to encourage friendly relations between private entities, consumers, and civil society.\n\n4. To bring about and develop planning for the sector and its institutions, as well as the efficient and effective administration of resources.\n\n\n"}
{"id": "67514", "url": "https://en.wikipedia.org/wiki?curid=67514", "title": "Moscovium", "text": "Moscovium\n\nMoscovium is a synthetic chemical element with symbol Mc and atomic number 115. It was first synthesized in 2003 by a joint team of Russian and American scientists at the Joint Institute for Nuclear Research (JINR) in Dubna, Russia. In December 2015, it was recognized as one of four new elements by the Joint Working Party of international scientific bodies IUPAC and IUPAP. On 28 November 2016, it was officially named after the Moscow oblast, which the JINR is situated in.\n\nMoscovium is an extremely radioactive element: its most stable known isotope, moscovium-290, has a half-life of only 0.8 seconds. In the periodic table, it is a p-block transactinide element. It is a member of the 7th period and is placed in group 15 as the heaviest pnictogen, although it has not been confirmed to behave as a heavier homologue of the pnictogen bismuth. Moscovium is calculated to have some properties similar to its lighter homologues, nitrogen, phosphorus, arsenic, antimony, and bismuth, and to be a post-transition metal, although it should also show several major differences from them. In particular, moscovium should also have significant similarities to thallium, as both have one rather loosely bound electron outside a quasi-closed shell. About 100 atoms of moscovium have been observed to date, all of which have been shown to have mass numbers from 287 to 290.\n\nThe first successful synthesis of moscovium was by a joint team of Russian and American scientists in August 2003 at the Joint Institute for Nuclear Research (JINR) in Dubna, Russia. Headed by Russian nuclear physicist Yuri Oganessian, the team included American scientists of the Lawrence Livermore National Laboratory. The researchers on February 2, 2004, stated in \"Physical Review C\" that they bombarded americium-243 with calcium-48 ions to produce four atoms of moscovium. These atoms decayed by emission of alpha-particles to nihonium in about 100 milliseconds.\n\nThe Dubna–Livermore collaboration strengthened their claim to the discoveries of moscovium and nihonium by conducting chemical experiments on the final decay product Db. None of the nuclides in this decay chain were previously known, so existing experimental data was not available to support their claim. In June 2004 and December 2005, the presence of a dubnium isotope was confirmed by extracting the final decay products, measuring spontaneous fission (SF) activities and using chemical identification techniques to confirm that they behave like a group 5 element (as dubnium is known to be in group 5 of the periodic table). Both the half-life and the decay mode were confirmed for the proposed Db, lending support to the assignment of the parent nucleus to moscovium. However, in 2011, the IUPAC/IUPAP Joint Working Party (JWP) did not recognize the two elements as having been discovered, because current theory could not distinguish the chemical properties of group 4 and group 5 elements with sufficient confidence. Furthermore, the decay properties of all the nuclei in the decay chain of moscovium had not been previously characterized before the Dubna experiments, a situation which the JWP generally considers \"troublesome, but not necessarily exclusive\".\n\nTwo heavier isotopes of moscovium, Mc and Mc, were discovered in 2009–2010 as daughters of the tennessine isotopes Ts and Ts; the isotope Mc was later also synthesized directly and confirmed to have the same properties as found in the tennessine experiments. The JINR also had plans to study lighter isotopes of moscovium in 2017 by replacing the americium-243 target with the lighter isotope americium-241. The Ca+Am reaction producing moscovium is planned to be the first experiment done at the new SHE Factory in 2018 at Dubna to test the systems in preparation for attempts at synthesising elements 119 and 120.\n\nIn 2011, the Joint Working Party of international scientific bodies International Union of Pure and Applied Chemistry (IUPAC) and International Union of Pure and Applied Physics (IUPAP) evaluated the 2004 and 2007 Dubna experiments, and concluded that they did not meet the criteria for discovery. Another evaluation of more recent experiments took place within the next few years, and a claim to the discovery of moscovium was again put forward by Dubna. In August 2013, a team of researchers at Lund University and at the Gesellschaft für Schwerionenforschung (GSI) in Darmstadt, Germany announced they had repeated the 2004 experiment, confirming Dubna's findings. Simultaneously, the 2004 experiment had been repeated at Dubna, now additionally also creating the isotope Mc that could serve as a cross-bombardment for confirming the discovery of the tennessine isotope Ts in 2010. Further confirmation was published by the team at the Lawrence Berkeley National Laboratory in 2015.\n\nIn December 2015, the IUPAC/IUPAP Joint Working Party recognized the element's discovery and assigned the priority to the Dubna-Livermore collaboration of 2009–2010, giving them the right to suggest a permanent name for it. While they did not recognise the experiments synthesising Mc and Mc as persuasive due to the lack of a convincing identification of atomic number via cross-reactions, they recognised the Ts experiments as persuasive because its daughter Mc had been produced independently and found to exhibit the same properties.\n\nA 2016 study from Lund University and the GSI nevertheless cast some doubt on the syntheses of moscovium and tennessine after the IUPAC/IUPAP Joint Working Party recognized these elements as having been discovered in 2009–2010. It found that the decay chains assigned to the isotopes Mc and Mc were probably internally consistent, with the uncertainty due to the probable insensitivity of the measurements to very short and very long nuclide lifetimes, incorrect assignments of other decay chains from the Am+Ca reaction to different moscovium isotopes, or uncertainty in the identification of some of the daughters of these moscovium isotopes. On the other hand, the decay chains assigned to Mc, the isotope instrumental in the official confirmation of the synthesis of moscovium and tennessine, were found not to be internally consistent. Some subsets of these chains were found to be consistent, suggesting however that their true assignment was to Mc, and that their shortness indicated instead new spontaneous fission branches in its daughters Nh and Rg – or, more likely, undetected electron capture branches in these daughters leading to the even–even nuclides Cn and Ds, which have a very low barrier to spontaneous fission. While the Ts decay chains were found to be congruent, the Ts decay chains approved by the JWP were found to probably not be so and require splitting into individual data sets assigned to different tennessine isotopes. It was also found that the set of chains from Ts and Mc were not congruent. The multiplicity of states found when nuclides that are not even–even undergo alpha decay is not unexpected and contributes to the lack of clarity in the cross-reactions. This study criticised the IUPAC/IUPAP JWP report for overlooking subtleties associated with this issue, and noted that the fact that the only argument for the acceptance of the discoveries of moscovium and tennessine was an almost certainly non-existent link was \"problematic\".\n\nOn 8 June 2017, two members of the Dubna team published a journal article answering these criticisms, analysing their data on the nuclides Ts and Mc with widely accepted statistical methods, noted that the 2016 studies indicating non-congruence produced problematic results when applied to radioactive decay: they excluded from the 90% confidence interval both average and extreme decay times, and the decay chains that would be excluded from the 90% confidence interval they chose were more probable to be observed than those that would be included. The 2017 reanalysis concluded that the observed decay chains of Ts and Mc were consistent with the assumption that only one nuclide was present at each step of the chain, although it would be desirable to be able to directly measure the mass number of the originating nucleus of each chain as well as the excitation function of the Am+Ca reaction.\n\nUsing Mendeleev's nomenclature for unnamed and undiscovered elements, moscovium is sometimes known as \"eka-bismuth\". In 1979 IUPAC recommended that the placeholder systematic element name \"ununpentium\" (with the corresponding symbol of \"Uup\") be used until the discovery of the element is confirmed and a permanent name is decided. Although widely used in the chemical community on all levels, from chemistry classrooms to advanced textbooks, the recommendations were mostly ignored among scientists in the field, who called it \"element 115\", with the symbol of \"E115\", \"(115)\" or even simply \"115\".\n\nOn 30 December 2015, discovery of the element was recognized by the International Union of Pure and Applied Chemistry (IUPAC). According to IUPAC recommendations, the discoverer(s) of a new element has the right to suggest a name. A suggested name was \"langevinium\", after Paul Langevin. Later, the Dubna team mentioned the name \"moscovium\" several times as one among many possibilities, referring to the Moscow Oblast where Dubna is located.\n\nIn June 2016, IUPAC endorsed the latter proposal to be formally accepted by the end of the year, which it was on 28 November 2016. The naming made Russia one of two countries with an element named after both itself and its capital. The naming ceremony for moscovium, tennessine, and oganesson was held on 2 March 2017 at the Russian Academy of Sciences in Moscow.\n\nMoscovium is expected to be in the middle of an island of stability centered on copernicium (element 112) and flerovium (element 114): the reasons for the presence of this island, however, are still not well understood. Due to the expected high fission barriers, any nucleus within this island of stability exclusively decays by alpha decay and perhaps some electron capture and beta decay. Although the known isotopes of moscovium do not actually have enough neutrons to be on the island of stability, they can be seen to approach the island as in general, the heavier isotopes are the longer-lived ones.\n\nThe hypothetical isotope Mc is an especially interesting case as it has only one neutron more than the heaviest known moscovium isotope, Mc. It could plausibly be synthesized as the daughter of Ts, which in turn could be made from the reaction . Calculations show that it may have a significant electron capture or positron emission decay mode in addition to alpha decaying and also have a relatively long half-life of several seconds. This would produce Fl, Nh, and finally Cn which is expected to be in the middle of the island of stability and have a half-life of about 1200 years, affording the most likely hope of reaching the middle of the island using current technology. Possible drawbacks are that the cross section of the production reaction of Ts is expected to be low and the decay properties of superheavy nuclei this close to the line of beta stability are largely unexplored.\n\nOther possibilities to synthesize nuclei on the island of stability include quasifission (partial fusion followed by fission) of a massive nucleus. Such nuclei tend to fission, expelling doubly magic or nearly doubly magic fragments such as calcium-40, tin-132, lead-208, or bismuth-209. Recently it has been shown that the multi-nucleon transfer reactions in collisions of actinide nuclei (such as uranium and curium) might be used to synthesize the neutron-rich superheavy nuclei located at the island of stability, although formation of the lighter elements nobelium or seaborgium is more favored. One last possibility to synthesize isotopes near the island is to use controlled nuclear explosions to create a neutron flux high enough to bypass the gaps of instability at Fm and at mass number 275 (atomic numbers 104 to 108), mimicking the r-process in which the actinides were first produced in nature and the gap of instability around radon bypassed. Some such isotopes (especially Cn and Cn) may even have been synthesized in nature, but would have decayed away far too quickly (with half-lives of only thousands of years) and be produced in far too small quantities (about 10 the abundance of lead) to be detectable as primordial nuclides today outside cosmic rays.\n\nIn the periodic table, moscovium is a member of group 15, the pnictogens, below nitrogen, phosphorus, arsenic, antimony, and bismuth. Every previous pnictogen has five electrons in its valence shell, forming a valence electron configuration of nsnp. In moscovium's case, the trend should be continued and the valence electron configuration is predicted to be 7s7p; therefore, moscovium will behave similarly to its lighter congeners in many respects. However, notable differences are likely to arise; a largely contributing effect is the spin–orbit (SO) interaction—the mutual interaction between the electrons' motion and spin. It is especially strong for the superheavy elements, because their electrons move much faster than in lighter atoms, at velocities comparable to the speed of light. In relation to moscovium atoms, it lowers the 7s and the 7p electron energy levels (stabilizing the corresponding electrons), but two of the 7p electron energy levels are stabilized more than the other four. The stabilization of the 7s electrons is called the inert pair effect, and the effect \"tearing\" the 7p subshell into the more stabilized and the less stabilized parts is called subshell splitting. Computation chemists see the split as a change of the second (azimuthal) quantum number \"l\" from 1 to and for the more stabilized and less stabilized parts of the 7p subshell, respectively. For many theoretical purposes, the valence electron configuration may be represented to reflect the 7p subshell split as 7s7p7p. These effects cause moscovium's chemistry to be somewhat different from that of its lighter congeners.\n\nThe valence electrons of moscovium fall into three subshells: 7s (two electrons), 7p (two electrons), and 7p (one electron). The first two of these are relativistically stabilized and hence behave as inert pairs, while the last is relativistically destabilized and can easily participate in chemistry. (The 6d electrons are not destabilized enough to participate chemically, although this may still be possible in the two previous elements nihonium and flerovium.) Thus, the +1 oxidation state should be favored, like Tl, and consistent with this the first ionization potential of moscovium should be around 5.58 eV, continuing the trend towards lower ionization potentials down the pnictogens. Moscovium and nihonium both have one electron outside a quasi-closed shell configuration that can be delocalized in the metallic state: thus they should have similar melting and boiling points (both melting around 400 °C and boiling around 1100 °C) due to the strength of their metallic bonds being similar. Additionally, the predicted ionization potential, ionic radius (1.5 Å for Mc; 1.0 Å for Mc), and polarizability of Mc are expected to be more similar to Tl than its true congener Bi. Moscovium should be a dense metal due to its high atomic weight, with a density around 13.5 g/cm. The electron of the hydrogen-like moscovium atom (oxidized so that it only has one electron, Mc) is expected to move so fast that it has a mass 1.82 times that of a stationary electron, due to relativistic effects. For comparison, the figures for hydrogen-like bismuth and antimony are expected to be 1.25 and 1.077 respectively.\n\nMoscovium is predicted to be the third member of the 7p series of chemical elements and the heaviest member of group 15 in the periodic table, below bismuth. Unlike the two previous 7p elements, moscovium is expected to be a good homologue of its lighter congener, in this case bismuth. In this group, each member is known to portray the group oxidation state of +5 but with differing stability. For nitrogen, the +5 state is mostly a formal explanation of molecules like NO: it is very difficult to have five covalent bonds to nitrogen due to the inability of the small nitrogen atom to accommodate five ligands. The +5 state is well represented for the essentially non-relativistic typical pnictogens phosphorus, arsenic, and antimony. However, for bismuth it becomes rare due to the relativistic stabilization of the 6s orbitals known as the inert pair effect, so that the 6s electrons are reluctant to bond chemically. It is expected that moscovium will have an inert pair effect for both the 7s and the 7p electrons, as the binding energy of the lone 7p electron is noticeably lower than that of the 7p electrons. Nitrogen(I) and bismuth(I) are known but rare and moscovium(I) is likely to show some unique properties, probably behaving more like thallium(I) than bismuth(I). Because of spin-orbit coupling, flerovium may display closed-shell or noble gas-like properties; if this is the case, moscovium will likely be typically monovalent as a result, since the cation Mc will have the same electron configuration as flerovium, perhaps giving moscovium some alkali metal character. However, the Mc cation would behave like its true lighter homolog Bi. The 7s electrons are too stabilized to be able to contribute chemically and hence the +5 state should be impossible and moscovium may be considered to have only three valence electrons. Moscovium would be quite a reactive metal, with a standard reduction potential of −1.5 V for the Mc/Mc couple.\n\nThe chemistry of moscovium in aqueous solution should essentially be that of the Mc and Mc ions. The former should be easily hydrolyzed and not be easily complexed with halides, cyanide, and ammonia. Moscovium(I) hydroxide (McOH), carbonate (McCO), oxalate (McCO), and fluoride (McF) should be soluble in water; the sulfide (McS) should be insoluble; and the chloride (McCl), bromide (McBr), iodide (McI), and thiocyanate (McSCN) should be only slightly soluble, so that adding excess hydrochloric acid would not noticeably affect the solubility of moscovium(I) chloride. Mc should be about as stable as Tl and hence should also be an important part of moscovium chemistry, although its closest homolog among the elements should be its lighter congener Bi. Moscovium(III) fluoride (McF) and thiozonide (McS) should be insoluble in water, similar to the corresponding bismuth compounds, while moscovium(III) chloride (McCl), bromide (McBr), and iodide (McI) should be readily soluble and easily hydrolyzed to form oxyhalides such as McOCl and McOBr, again analogous to bismuth. Both moscovium(I) and moscovium(III) should be common oxidation states and their relative stability should depend greatly on what they are complexed with and the likelihood of hydrolysis.\n\nLike its lighter homologues ammonia, phosphine, arsine, stibine, and bismuthine, moscovine (McH) is expected to have a trigonal pyramidal molecular geometry, with an Mc–H bond length of 195.4 pm and a H–Mc–H bond angle of 91.8° (bismuthine has bond length 181.7 pm and bond angle 91.9°; stibine has bond length 172.3 pm and bond angle 92.0°). In the predicted aromatic pentagonal planar cluster, analogous to pentazolate (), the Mc–Mc bond length is expected to be expanded from the extrapolated value of 156–158 pm to 329 pm due to spin–orbit coupling effects.\n\nUnambiguous determination of the chemical characteristics of moscovium has yet to have been established. In 2011, experiments were conducted to create nihonium, flerovium, and moscovium isotopes in the reactions between calcium-48 projectiles and targets of americium-243 and plutonium-244. However, the targets included lead and bismuth impurities and hence some isotopes of bismuth and polonium were generated in nucleon transfer reactions. This, while an unforeseen complication, could give information that would help in the future chemical investigation of the heavier homologs of bismuth and polonium, which are respectively moscovium and livermorium. The produced nuclides bismuth-213 and polonium-212m were transported as the hydrides BiH and PoH at 850 °C through a quartz wool filter unit held with tantalum, showing that these hydrides were surprisingly thermally stable, although their heavier congeners McH and LvH would be expected to be less thermally stable from simple extrapolation of periodic trends in the p-block. Further calculations on the stability and electronic structure of BiH, McH, PoH, and LvH are needed before chemical investigations take place. However, moscovium and livermorium are expected to be volatile enough as pure elements for them to be chemically investigated in the near future. The moscovium isotopes Mc, Mc, and Mc may be chemically investigated with current methods, although their short half-lives would make this challenging. Moscovium is the heaviest element that has known isotopes that are long-lived enough for chemical experimentation.\n\n"}
{"id": "56407123", "url": "https://en.wikipedia.org/wiki?curid=56407123", "title": "National Oil &amp; Gas Authority", "text": "National Oil &amp; Gas Authority\n\nThe National Oil & Gas Authority or The Ministry of Oil and Gas(); is the governmental body in the Bahrain responsible for developing and implementing the government policy for exploiting the oil and gas resources in Bahrain.\n\n"}
{"id": "58983704", "url": "https://en.wikipedia.org/wiki?curid=58983704", "title": "Neon Museum, Warsaw", "text": "Neon Museum, Warsaw\n\nNeon Museum, also the Museum of Neon () is a museum located in Warsaw's Praga-Południe. The institution documents and protects Polish light advertisements created after World War II. It is the first in Poland and one of the few museums of neon signs in the world.\n\nThe museum is located at ul. Mińska 25, on the premises of Soho Factory. It was established in 2012.\n\nThe history of the museum began in 2005 when Ilona Karwińska saved the \"Berlin\" neon sign from Marszałkowska Street in Warsaw. The collection of the museum features about 100 neon lights from all over Poland\n Most of the neons come from the 1960s and 1970s.\n\nThe nine largest neon signs including \"GŁÓWNA KSIĘGARNIA TECHNICZNA (MAIN TECHNICAL BOOKSTORE)\", \"Jubiler\", \"dworzec kolejowy CHODZIEŻ (CHODZIEŻ railway station)\", \"KINO PRAHA (PRAHA cinema)\" i \"WARSZAWA WSCHODNIA\" are located on different Soho Factory buildings. The museum also looks after some neon signs in Warsaw, including Mermaid on Grójecka Street. \n\nIn 2013, the museum together with RWE organized \"Neon for Warsaw\" competition.\n\n"}
{"id": "2322902", "url": "https://en.wikipedia.org/wiki?curid=2322902", "title": "Nine (purity)", "text": "Nine (purity)\n\nNines are an informal, yet common method of grading the purity of materials.\n\nvery fine precious metals such as platinum, gold and silver. Based on the system of millesimal fineness, a metal is said to be \"one nine\" or \"one nine fine\" if it is 900 fine, or 90% pure. A metal that is 990 fine is then described as \"two nines fine\" and one that is 999 fine is described as \"three nines fine\". Thus, nines are a logarithmic scale of purity for very fine precious metals. Similarly, percentages ending in a 5 have conventional names, traditionally the number of nines, then \"five\", so 999.5 fine (99.95% pure) is \"three nines five\", abbreviated 3N5. \n\nThe nines scale is also sometimes used in describing the purity of bottled gases. The purity of gas is an indication of the amount of other gases it contains. A high purity refers to a low amount of other gases. Gases of higher purity are considered to be of better quality and are usually more expensive.\n\nThe purity of a gas is generally expressed as a grade prefixed with the letter N giving the \"number of nines\" in the percentage or decimal fraction. For gasses, the number of nines is usually written after the letter N, rather than before it. An N2.0 gas is 99% pure, and 1% (by volume) impurities. An N6.0 gas is 99.9999% (six nines) pure, with 1 part per million (1 ppm) impurities.\n\nIntermediate values are formed using the common logarithm. For example, a gas which is 99.97% pure would be described as N3.5, since log(0.03%) = −3.523.\n\nNines are used in a similar manner to describe computer system availability.\n\n"}
{"id": "939466", "url": "https://en.wikipedia.org/wiki?curid=939466", "title": "Orders of magnitude (energy)", "text": "Orders of magnitude (energy)\n\nThis list compares various energies in joules (J), organized by order of magnitude.\n\n"}
{"id": "20989833", "url": "https://en.wikipedia.org/wiki?curid=20989833", "title": "Parallel generation", "text": "Parallel generation\n\nParallel generation refers to the generation of electric power directly by consumers instead of purchasing it from an integrated electric utility company. Generally, it seems that parallel generation of electric power is taken on by institutions, such as hospitals, manufacturers or other large organizations. It may be understood that individuals typically do not have an economic incentive to invest in and organize such specialized services as electric power generation.\n"}
{"id": "9627264", "url": "https://en.wikipedia.org/wiki?curid=9627264", "title": "Pearlescent coating", "text": "Pearlescent coating\n\nPearlescent coatings or pigments possess optical effects that not only serve decorative purposes (such as cosmetics, printed products, industrial coatings, or automotive paints), but also provide important functional roles, such as security printing or optical filters.\n\n"}
{"id": "287301", "url": "https://en.wikipedia.org/wiki?curid=287301", "title": "Photoflash capacitor", "text": "Photoflash capacitor\n\nA photoflash capacitor is an electrolytic capacitor used in flash cameras, professional flashes, and also in solid-state laser power supplies. Their usual purpose is to briefly power a high-voltage flash tube, used to illuminate a photographic subject or optically pump a laser rod. As flash tubes require very high current for a very short time to operate, photoflash capacitors are designed to supply high discharge current pulses without excessive internal heating. \n\nThe principal properties of a capacitor are capacitance, working voltage, equivalent series resistance (ESR), equivalent series inductance (ESL), and working temperature\n\nCompared with electrolytic capacitors usually used for power supply filtering at power frequency, a photoflash capacitor is designed to have lower ESR, ESL, and capacitance manufacturing tolerance, but does not need as high a working temperature.\n\nThe light energy emitted by a flash is supplied by the capacitor, and is proportional to the product of the capacitance and the voltage squared; photoflash capacitors have capacitance in the range 80-160 microfarads (µF) and voltages from 180–330 volts for flash units built into small disposable and compact cameras, increasing for units delivering higher light energy. A typical manufacturer's range includes capacitors operating at 330–380V, with capacitance from 80 to 1,500 µF While normal electrolytic capacitors are often operated at not more than half their nominal voltage due to their high derating, photoflash capacitors are typically operated at their nominal working voltage (labelled as \"WV\" or \"W.V.\" rather than just \"V\"). Photoflash capacitors are not subject to the high temperatures of cased electronic equipment in continuous operation, with nearby components and sometimes the capacitors themselves dissipating heat; they are often rated at a maximum operating temperature rate of typically 55 °C, compared to 85 °C–105 °C or more for capacitors for continuous use in electronic equipment. In most electronic applications an electrolytic capacitor can have a capacitance much larger than its nominal value without detracting from circuit performance; general-purpose electrolytics are often specified to have capacitance between 20% below and 80% above rated value, although tighter tolerances are available. The light energy of a flash is proportional to the capacitance and large variations are not acceptable, typical tolerance is -10+20%.\n\nPhotoflash capacitors are designed to deliver a brief pulse of very high current, and are consequently sometimes used in railgun and coilgun designs.\n"}
{"id": "25405953", "url": "https://en.wikipedia.org/wiki?curid=25405953", "title": "Pseudocapacitor", "text": "Pseudocapacitor\n\nPseudocapacitors store electrical energy faradaically by electron charge transfer between electrode and electrolyte. This is accomplished through electrosorption, reduction-oxidation reactions (redox reactions), and intercalation processes, termed \"pseudocapacitance\".\n\nA pseudocapacitor is part of an electrochemical capacitor, and forms together with an electric double-layer capacitor (EDLC) to create a supercapacitor.\n\nPseudocapacitance and double-layer capacitance add up to a common inseparable capacitance value of a supercapacitor. However, they can be effective with very different parts of the total capacitance value depending on the design of the electrodes. A pseudocapacitance may be higher by a factor of 100 as a double-layer capacitance with the same electrode surface.\n\nA pseudocapacitor has a chemical reaction at the electrode, unlike EDLCs where the electrical charge storage is stored electrostatically with no interaction between the electrode and the ions. Pseudocapacitance is accompanied by an electron charge-transfer between electrolyte and electrode coming from a de-solvated and adsorbed ion. One electron per charge unit is involved. The adsorbed ion has no chemical reaction with the atoms of the electrode (no chemical bonds arise) since only a charge-transfer takes place. An example is a redox reaction where the ion is O and during charging, one electrode hosts a reduction reaction and the other an oxidation reaction. Under discharge the reactions are reversed.\n\nUnlike batteries, in faradaic electron charge-transfer ions simply cling to the atomic structure of an electrode. This faradaic energy storage with only fast redox reactions makes charging and discharging much faster than batteries.\n\nElectrochemical pseudocapacitors use metal oxide or conductive polymer electrodes with a high amount of electrochemical pseudocapacitance. The amount of electric charge stored in a pseudocapacitance is linearly proportional to the applied voltage. The unit of pseudocapacitance is the farad.\n\nBrezesinki et al. showed that mesoporous films of \"α\"-MoO have improved charge storage due to lithium ions inserting into the gaps of \"α\"-MoO. They claim this intercalation pseudocapacitance takes place on the same timescale as redox pseudocapacitance and gives better charge-storage capacity without changing kinetics in mesoporous MoO. This approach is promising for batteries with rapid charging ability, comparable to that of lithium batteries, and are promising for efficient energy materials.\n\nOther groups have used vanadium oxide thin films on carbon nanotubes for pseudocapacitors. Kim et al. electrochemically deposited amorphous VO·HO onto a carbon nanotube film. The three-dimensional structure of the carbon nanotubes substrate facilitates high specific lithium-ion capacitance and shows three times higher capacitance than vanadium oxide deposited on a typical Pt substrate. These studies demonstrate the capability of deposited oxides to effectively store charge in pseudocapacitors.\n\nConducting polymers, such as polypyrrole (PPy) and poly(3,4-ethylenedioxythiophene) (PEDOT), have tunable electronic conductivity and can achieve high doping levels with the proper counterion. A high-performing conducting polymer pseudocapacitor has high cycling stability after undergoing charge/discharge cycles. Successful approaches include embedding the redox polymer in a host phase (e.g. titanium carbide) for stability and depositing a carbonaceous shell onto the conducting polymer electrode. These techniques improve cyclability and stability of the pseudocapacitor device.\n"}
{"id": "2909558", "url": "https://en.wikipedia.org/wiki?curid=2909558", "title": "Rice bran wax", "text": "Rice bran wax\n\nRice bran wax is the vegetable wax extracted from the bran oil of rice (\"Oryza sativa\").\n\nThe main components of rice bran wax are aliphatic acids (wax acids) and higher alcohol esters. The aliphatic acids consist of palmitic acid (C16), behenic acid (C22), lignoceric acid (C24), other higher wax acids. The higher alcohol esters consist mainly of ceryl alcohol (C26) and melissyl alcohol (C30). Rice bran wax also contains constituents such as free fatty acids (palmitic acid), squalene and phospholipids.\n\nRice bran wax is edible and can serve as a substitute for carnauba wax in most applications due to its relatively high melting point. It is used in paper coatings, textiles, explosives, fruit & vegetable coatings, confectionery, pharmaceuticals, candles, moulded novelties, electric insulation, textile and leather sizing, waterproofing, carbon paper, typewriter ribbons, printing inks, lubricants, crayons, adhesives, chewing gum and cosmetics.\n\nIn cosmetics, rice bran wax is used as an emollient, and is the basis material for some exfoliation particles. It has been observed that rice bran wax at concentrations as low as 1 wt% in triglycerides can crystallize to form stable gels.\n\nMelting point = 77 - 86 °C\n\nSaponification value = 75 - 120\n\nIodine number = 11.1 - 17.6\n\nFree fatty acids = 2.1 - 7.3%\n\nPhosphorus = 0.01 - 0.15%\n\nColor: Off-white to moderate orange/brown\n\nOdor: typical fatty, crayola-ish\n\nRice bran wax bleaches and deodorizes readily\n\nINCI name: \"Oryza Sativa (Rice) Bran Wax\".\n"}
{"id": "27117", "url": "https://en.wikipedia.org/wiki?curid=27117", "title": "Selenium", "text": "Selenium\n\nSelenium is a chemical element with symbol Se and atomic number 34. It is a nonmetal (more rarely considered a metalloid) with properties that are intermediate between the elements above and below in the periodic table, sulfur and tellurium, and also has similarities to arsenic. It rarely occurs in its elemental state or as pure ore compounds in the Earth's crust. Selenium (from Ancient Greek (selḗnē) \"Moon\") was discovered in 1817 by Jöns Jacob Berzelius, who noted the similarity of the new element to the previously discovered tellurium (named for the Earth).\n\nSelenium is found in , where it partially replaces the sulfur. Commercially, selenium is produced as a byproduct in the refining of these ores, most often during production. Minerals that are pure selenide or selenate compounds are known but rare. The chief commercial uses for selenium today are glassmaking and pigments. Selenium is a semiconductor and is used in photocells. Applications in electronics, once important, have been mostly replaced with silicon semiconductor devices. Selenium is still used in a few types of DC power surge protectors and one type of fluorescent quantum dot.\n\nSelenium salts are toxic in large amounts, but trace amounts are necessary for cellular function in many organisms, including all animals. Selenium is an ingredient in many multivitamins and other dietary supplements, including infant formula. It is a component of the antioxidant enzymes glutathione peroxidase and thioredoxin reductase (which indirectly reduce certain oxidized molecules in animals and some plants). It is also found in three deiodinase enzymes, which convert one thyroid hormone to another. Selenium requirements in plants differ by species, with some plants requiring relatively large amounts and others apparently requiring none.\n\nSelenium forms several allotropes that interconvert with temperature changes, depending somewhat on the rate of temperature change. When prepared in chemical reactions, selenium is usually an amorphous, brick-red powder. When rapidly melted, it forms the black, vitreous form, usually sold commercially as beads. The structure of black selenium is irregular and complex and consists of polymeric rings with up to 1000 atoms per ring. Black Se is a brittle, lustrous solid that is slightly soluble in CS. Upon heating, it softens at 50 °C and converts to gray selenium at 180 °C; the transformation temperature is reduced by presence of halogens and amines.\n\nThe red α, β, and γ forms are produced from solutions of black selenium by varying the evaporation rate of the solvent (usually CS). They all have relatively low, monoclinic crystal symmetries and contain nearly identical puckered Se rings with different arrangements, as in sulfur. The packing is most dense in the α form. In the Se rings, the Se-Se distance is 233.5 pm and Se-Se-Se angle is 105.7°. Other selenium allotropes may contain Se or Se rings.\n\nThe most stable and dense form of selenium is gray and has a hexagonal crystal lattice consisting of helical polymeric chains, where the Se-Se distance is 237.3 pm and Se-Se-Se angle is 130.1°. The minimum distance between chains is 343.6 pm. Gray Se is formed by mild heating of other allotropes, by slow cooling of molten Se, or by condensing Se vapor just below the melting point. Whereas other Se forms are insulators, gray Se is a semiconductor showing appreciable photoconductivity. Unlike the other allotropes, it is insoluble in CS. It resists oxidation by air and is not attacked by nonoxidizing acids. With strong reducing agents, it forms polyselenides. Selenium does not exhibit the changes in viscosity that sulfur undergoes when gradually heated.\n\nOwing to its use as a photoconductor in flat-panel x-ray detectors (see below), the optical properties of amorphous selenium (α-Se) thin films have been the subject of intense research.\n\nSelenium has seven natural isotopes, including Se, which occurs in minute quantities in uranium ores, as well as 23 other synthetic isotopes.\n\nSelenium compounds commonly exist in the oxidation states −2, +2, +4, and +6.\n\nSelenium forms two oxides: selenium dioxide (SeO) and selenium trioxide (SeO). Selenium dioxide is formed by the reaction of elemental selenium with oxygen:\n\nIt is a polymeric solid that forms monomeric SeO molecules in the gas phase. It dissolves in water to form selenous acid, HSeO. Selenous acid can also be made directly by oxidizing elemental selenium with nitric acid:\n\nUnlike sulfur, which forms a stable trioxide, selenium trioxide is thermodynamically unstable and decomposes to the dioxide above 185 °C:\n\nSelenium trioxide is produced in the laboratory by the reaction of anhydrous potassium selenate (KSeO) and sulfur trioxide (SO).\n\nSalts of selenous acid are called selenites. These include silver selenite (AgSeO) and sodium selenite (NaSeO).\n\nHydrogen sulfide reacts with aqueous selenous acid to produce selenium disulfide:\n\nSelenium disulfide consists of 8-membered rings. It has an approximate composition of SeS, with individual rings varying in composition, such as SeS and SeS. Selenium disulfide has been used in shampoo as an antidandruff agent, an inhibitor in polymer chemistry, a glass dye, and a reducing agent in fireworks.\n\nSelenium trioxide may be synthesized by dehydrating selenic acid, HSeO, which is itself produced by the oxidation of selenium dioxide with hydrogen peroxide:\n\nHot, concentrated selenic acid can react with gold to form gold(III) selenate.\n\nIodides of selenium are not well known. The only stable chloride is selenium monochloride (SeCl), which might be better known as selenium(I) chloride; the corresponding bromide is also known. These species are structurally analogous to the corresponding disulfur dichloride. Selenium dichloride is an important reagent in the preparation of selenium compounds (e.g. the preparation of Se). It is prepared by treating selenium with sulfuryl chloride (SOCl). Selenium reacts with fluorine to form selenium hexafluoride:\n\nIn comparison with its sulfur counterpart (sulfur hexafluoride), selenium hexafluoride (SeF) is more reactive and is a toxic pulmonary irritant.\nSome of the selenium oxyhalides, such as selenium oxyfluoride (SeOF) and selenium oxychloride (SeOCl) have been used as specialty solvents.\n\nAnalogous to the behavior of other chalcogens, selenium forms hydrogen selenide, HSe. It is a strongly odiferous, toxic, and colorless gas. It is more acidic than HS. In solution it ionizes to HSe. The selenide dianion Se forms a variety of compounds, including the minerals from which selenium is obtained commercially. Illustrative selenides include mercury selenide (HgSe), lead selenide (PbSe), zinc selenide (ZnSe), and copper indium gallium diselenide (Cu(Ga,In)Se). These materials are semiconductors. With highly electropositive metals, such as aluminium, these selenides are prone to hydrolysis:\nAlkali metal selenides react with selenium to form polyselenides, , which exist as chains.\n\nTetraselenium tetranitride, SeN, is an explosive orange compound analogous to tetrasulfur tetranitride (SN). It can be synthesized by the reaction of selenium tetrachloride (SeCl) with .\n\nSelenium reacts with cyanides to yield selenocyanates:\n\nSelenium, especially in the II oxidation state, forms stable bonds to carbon, which are structurally analogous to the corresponding organosulfur compounds. Especially common are selenides (RSe, analogues of thioethers), diselenides (RSe, analogues of disulfides), and selenols (RSeH, analogues of thiols). Representatives of selenides, diselenides, and selenols include respectively selenomethionine, diphenyldiselenide, and benzeneselenol. The sulfoxide in sulfur chemistry is represented in selenium chemistry by the selenoxides (formula RSe(O)R), which are intermediates in organic synthesis, as illustrated by the selenoxide elimination reaction. Consistent with trends indicated by the double bond rule, selenoketones, R(C=Se)R, and selenaldehydes, R(C=Se)H, are rarely observed.\n\nSelenium (Greek σελήνη \"selene\" meaning \"Moon\") was discovered in 1817 by Jöns Jakob Berzelius and Johan Gottlieb Gahn. Both chemists owned a chemistry plant near Gripsholm, Sweden, producing sulfuric acid by the lead chamber process. The pyrite from the Falun mine created a red precipitate in the lead chambers which was presumed to be an arsenic compound, so the pyrite's use to make acid was discontinued. Berzelius and Gahn wanted to use the pyrite and they also observed that the red precipitate gave off a smell like horseradish when burned. This smell was not typical of arsenic, but a similar odor was known from tellurium compounds. Hence, Berzelius's first letter to Alexander Marcet stated that this was a tellurium compound. However, the lack of tellurium compounds in the Falun mine minerals eventually led Berzelius to reanalyze the red precipitate, and in 1818 he wrote a second letter to Marcet describing a newly found element similar to sulfur and tellurium. Because of its similarity to tellurium, named for the Earth, Berzelius named the new element after the Moon.\n\nIn 1873, Willoughby Smith found that the electrical resistance of grey selenium was dependent on the ambient light. This led to its use as a cell for sensing light. The first commercial products using selenium were developed by Werner Siemens in the mid-1870s. The selenium cell was used in the photophone developed by Alexander Graham Bell in 1879. Selenium transmits an electric current proportional to the amount of light falling on its surface. This phenomenon was used in the design of light meters and similar devices. Selenium's semiconductor properties found numerous other applications in electronics. The development of selenium rectifiers began during the early 1930s, and these replaced copper oxide rectifiers because they were more efficient. These lasted in commercial applications until the 1970s, following which they were replaced with less expensive and even more efficient silicon rectifiers.\n\nSelenium came to medical notice later because of its toxicity to human beings working in industries. Selenium was also recognized as an important veterinary toxin, which is seen in animals that have eaten high-selenium plants. In 1954, the first hints of specific biological functions of selenium were discovered in microorganisms by biochemist, Jane Pinsent. It was discovered to be essential for mammalian life in 1957. In the 1970s, it was shown to be present in two independent sets of enzymes. This was followed by the discovery of selenocysteine in proteins. During the 1980s, selenocysteine was shown to be encoded by the codon UGA. The recoding mechanism was worked out first in bacteria and then in mammals (see SECIS element).\n\nNative (i.e., elemental) selenium is a rare mineral, which does not usually form good crystals, but, when it does, they are steep rhombohedra or tiny acicular (hair-like) crystals. Isolation of selenium is often complicated by the presence of other compounds and elements.\n\nSelenium occurs naturally in a number of inorganic forms, including selenide, selenate, and selenite, but these minerals are rare. The common mineral selenite is not a selenium mineral, and contains no selenite ion, but is rather a type of gypsum (calcium sulfate hydrate) named like selenium for the moon well before the discovery of selenium. Selenium is most commonly found as an impurity, replacing a small part of the sulfur in sulfide ores of many metals.\n\nIn living systems, selenium is found in the amino acids selenomethionine, selenocysteine, and methylselenocysteine. In these compounds, selenium plays a role analogous to that of sulfur. Another naturally occurring organoselenium compound is dimethyl selenide.\n\nCertain solids are selenium-rich, and selenium can be bioconcentrated by some plants. In soils, selenium most often occurs in soluble forms such as selenate (analogous to sulfate), which are leached into rivers very easily by runoff. Ocean water contains significant amounts of selenium.\n\nAnthropogenic sources of selenium include coal burning, and the mining and smelting of sulfide ores.\n\nSelenium is most commonly produced from selenide in many sulfide ores, such as those of copper, nickel, or lead. Electrolytic metal refining is particularly productive of selenium as a byproduct, obtained from the anode mud of copper refineries. Another source was the mud from the lead chambers of sulfuric acid plants, a process that is no longer used. Selenium can be refined from these muds by a number of methods. However, most elemental selenium comes as a byproduct of refining copper or producing sulfuric acid. Since its invention, solvent extraction and electrowinning (SX/EW) production of copper produces an increasing share of the worldwide copper supply. This changes the availability of selenium because only a comparably small part of the selenium in the ore is leached with the copper.\n\nIndustrial production of selenium usually involves the extraction of selenium dioxide from residues obtained during the purification of copper. Common production from the residue then begins by oxidation with sodium carbonate to produce selenium dioxide, which is mixed with water and acidified to form selenous acid (oxidation step). Selenous acid is bubbled with sulfur dioxide (reduction step) to give elemental selenium.\n\nAbout 2,000 tonnes of selenium were produced in 2011 worldwide, mostly in Germany (650 t), Japan (630 t), Belgium (200 t), and Russia (140 t), and the total reserves were estimated at 93,000 tonnes. These data exclude two major producers, the United States and China. A previous sharp increase was observed in 2004 from 4–5 to $27/lb. The price was relatively stable during 2004–2010 at about US$30 per pound (in 100-pound lots) but increased to $65 /lb in 2011. The consumption in 2010 was divided as follows: metallurgy – 30%, glass manufacturing – 30%, agriculture – 10%, chemicals and pigments – 10%, and electronics – 10%. China is the dominant consumer of selenium at 1,500–2,000 tonnes/year.\n\nDuring the electro winning of manganese, the addition of selenium dioxide decreases the power necessary to operate the electrolysis cells. China is the largest consumer of selenium dioxide for this purpose. For every tonne of manganese, an average 2 kg selenium oxide is used. \n\nThe largest commercial use of Se, accounting for about 50% of consumption, is for the production of glass. Se compounds confer a red color to glass. This color cancels out the green or yellow tints that arise from iron impurities typical for most glass. For this purpose, various selenite and selenate salts are added. For other applications, a red color may be desired, produced by mixtures of CdSe and CdS.\n\nSelenium is used with bismuth in brasses to replace more toxic lead. The regulation of lead in drinking water applications with the Safe Drinking Water Act of 1974 made a reduction of lead in brass necessary. The new brass is marketed under the name EnviroBrass. Like lead and sulfur, selenium improves the machinability of steel at concentrations around 0.15%. Selenium produces the same machinability improvement in copper alloys.\n\nLithium–selenium (Li–Se) battery is one of the most promising system for energy storage in the family of lithium batteries. Li–Se battery is an alternative to Lithium–sulfur battery with an advantage of high electrical conductivity.\n\nCopper indium gallium selenide is a material used in solar cells.\n\nAmorphous selenium (α-Se) thin films have found application as photoconductors in flat panel x-ray detectors. These detectors utilize the amorphous selenium to capture and convert incident x-ray photons directly into electric charge.\n\nBeginning from 1933 until the 1990s, Selenium was used for rectifiers, the such called selenium rectifiers.\n\nSmall amounts of organoselenium compounds have been used to modify the catalysts used for the vulcanization for the production of rubber.\n\nThe demand for selenium by the electronics industry is declining. Its photovoltaic and photoconductive properties are still useful in photocopying, photocells, light meters and solar cells. Its use as a photoconductor in plain-paper copiers once was a leading application, but in the 1980s, the photoconductor application declined (although it was still a large end-use) as more and more copiers switched to organic photoconductors. Though once widely used, selenium rectifiers have mostly been replaced (or are being replaced) by silicon-based devices. The most notable exception is in power DC surge protection, where the superior energy capabilities of selenium suppressors make them more desirable than metal oxide varistors.\n\nZinc selenide was the first material for blue LEDs, but gallium nitride dominates that market. Cadmium selenide was an important component in quantum dots. Sheets of amorphous selenium convert X-ray images to patterns of charge in xeroradiography and in solid-state, flat-panel X-ray cameras. Ionized selenium (Se+24) is one of the active mediums used in X-ray lasers.\n\nSelenium is a catalyst in some chemical reactions, but it is not widely used because of issues with toxicity. In X-ray crystallography, incorporation of one or more selenium atoms in place of sulfur helps with multiple-wavelength anomalous dispersion and single wavelength anomalous dispersion phasing.\n\nSelenium is used in the toning of photographic prints, and it is sold as a toner by numerous photographic manufacturers. Selenium intensifies and extends the tonal range of black-and-white photographic images and improves the permanence of prints.\n\nSe is used as a gamma source in industrial radiography.\n\nAlthough it is toxic in large doses, selenium is an essential micronutrient for animals. In plants, it occurs as a bystander mineral, sometimes in toxic proportions in forage (some plants may accumulate selenium as a defense against being eaten by animals, but other plants, such as locoweed, require selenium, and their growth indicates the presence of selenium in soil). See more on plant nutrition below.\n\nSelenium is a component of the unusual amino acids selenocysteine and selenomethionine. In humans, selenium is a trace element nutrient that functions as cofactor for reduction of antioxidant enzymes, such as glutathione peroxidases and certain forms of thioredoxin reductase found in animals and some plants (this enzyme occurs in all living organisms, but not all forms of it in plants require selenium).\n\nThe glutathione peroxidase family of enzymes (GSH-Px) catalyze certain reactions that remove reactive oxygen species such as hydrogen peroxide and organic hydroperoxides:\n\nThe thyroid gland and every cell that uses thyroid hormone use selenium, which is a cofactor for the three of the four known types of thyroid hormone deiodinases, which activate and then deactivate various thyroid hormones and their metabolites; the iodothyronine deiodinases are the subfamily of deiodinase enzymes that use selenium as the otherwise rare amino acid selenocysteine. (Only the deiodinase, iodotyrosine deiodinase, which works on the last breakdown products of thyroid hormone, does not use selenium.)\n\nSelenium may inhibit Hashimoto's disease, in which the body's own thyroid cells are attacked as alien. A reduction of 21% on TPO antibodies is reported with the dietary intake of 0.2 mg of selenium.\n\nIncreased dietary selenium reduces the effects of mercury toxicity, although it is effective only at low to modest doses of mercury. Evidence suggests that the molecular mechanisms of mercury toxicity includes the irreversible inhibition of selenoenzymes that are required to prevent and reverse oxidative damage in brain and endocrine tissues. An antioxidant, selenoneine, which is derived from selenium and has been found to be present in the blood of bluefin tuna, is the subject of scientific research regarding its possible roles in inflammatory and chronic diseases, methylmercury detoxification, and oxidative damages.\n\nFrom about three billion years ago, prokaryotic selenoprotein families drive the evolution of selenocysteine, an amino acid. Selenium is incorporated into several prokaryotic selenoprotein families in bacteria, archaea, and eukaryotes as selenocysteine, where selenoprotein peroxiredoxins protect bacterial and eukaryotic cells against oxidative damage. Selenoprotein families of GSH-Px and the deiodinases of eukaryotic cells seem to have a bacterial phylogenetic origin. The selenocysteine-containing form occurs in species as diverse as green algae, diatoms, sea urchin, fish, and chicken. Selenium enzymes are involved in the small reducing molecules glutathione and thioredoxin. One family of selenium-bearing molecules (the glutathione peroxidases) destroys peroxide and repairs damaged peroxidized cell membranes, using glutathione. Another selenium-bearing enzyme in some plants and in animals (thioredoxin reductase) generates reduced thioredoxin, a dithiol that serves as an electron source for peroxidases and also the important reducing enzyme ribonucleotide reductase that makes DNA precursors from RNA precursors.\n\nTrace elements involved in GSH-Px and superoxide dismutase enzymes activities, i.e. selenium, vanadium, magnesium, copper, and zinc, may have been lacking in some terrestrial mineral-deficient areas. Marine organisms retained and sometimes expanded their selenoproteomes, whereas the selenoproteomes of some terrestrial organisms were reduced or completely lost. These findings suggest that, with the exception of vertebrates, aquatic life supports selenium use, whereas terrestrial habitats lead to reduced use of this trace element. Marine fishes and vertebrate thyroid glands have the highest concentration of selenium and iodine. From about 500 million years ago, freshwater and terrestrial plants slowly optimized the production of \"new\" endogenous antioxidants such as ascorbic acid (vitamin C), polyphenols (including flavonoids), tocopherols, etc. A few of these appeared more recently, in the last 50–200 million years, in fruits and flowers of angiosperm plants. In fact, the angiosperms (the dominant type of plant today) and most of their antioxidant pigments evolved during the late Jurassic period.\n\nThe deiodinase isoenzymes constitute another family of eukaryotic selenoproteins with identified enzyme function. Deiodinases are able to extract electrons from iodides, and iodides from iodothyronines. They are, thus, involved in thyroid-hormone regulation, participating in the protection of thyrocytes from damage by HO produced for thyroid-hormone biosynthesis. About 200 million years ago, new selenoproteins were developed as mammalian GSH-Px enzymes.\n\nDietary selenium comes from nuts, cereals and mushrooms. Brazil nuts are the richest dietary source (though this is soil-dependent, since the Brazil nut does not require high levels of the element for its own needs).\n\nThe U.S. Recommended Dietary Allowance (RDA) for teenagers and adults is 55 µg/day.\nSelenium as a dietary supplement is available in many forms, including multi-vitamins/mineral supplements, which typically contain 55 or 70 µg/serving. Selenium-specific supplements typically contain either 100 or 200 µg/serving.\n\nIn June 2015 the U.S. Food and Drug Administration (FDA) published its final rule establishing the requirement of minimum and maximum levels of selenium in infant formula.\n\nThe selenium content in the human body is believed to be in the 13–20 milligram range.\n\nCertain species of plants are considered indicators of high selenium content of the soil because they require high levels of selenium to thrive. The main selenium indicator plants are \"Astragalus\" species (including some locoweeds), prince's plume (\"Stanleya\" sp.), woody asters (\"Xylorhiza\" sp.), and false goldenweed (\"Oonopsis\" sp.)\n\nSelenium may be measured in blood, plasma, serum, or urine to monitor excessive environmental or occupational exposure, to confirm a diagnosis of poisoning in hospitalized victims, or investigate a suspected case of fatal overdose. Some analytical techniques are capable of distinguishing organic from inorganic forms of the element. Both organic and inorganic forms of selenium are largely converted to monosaccharide conjugates (selenosugars) in the body prior elimination in the urine. Cancer patients receiving daily oral doses of selenothionine may achieve very high plasma and urine selenium concentrations.\n\nAlthough selenium is an essential trace element, it is toxic if taken in excess. Exceeding the Tolerable Upper Intake Level of 400 micrograms per day can lead to selenosis. This 400 µg Tolerable Upper Intake Level is based primarily on a 1986 study of five Chinese patients who exhibited overt signs of selenosis and a follow up study on the same five people in 1992. The 1992 study actually found the maximum safe dietary Se intake to be approximately 800 micrograms per day (15 micrograms per kilogram body weight), but suggested 400 micrograms per day to avoid creating an imbalance of nutrients in the diet and to accord with data from other countries. In China, people who ingested corn grown in extremely selenium-rich stony coal (carbonaceous shale) have suffered from selenium toxicity. This coal was shown to have selenium content as high as 9.1%, the highest concentration in coal ever recorded.\n\nSigns and symptoms of selenosis include a garlic odor on the breath, gastrointestinal disorders, hair loss, sloughing of nails, fatigue, irritability, and neurological damage. Extreme cases of selenosis can exhibit cirrhosis of the liver, pulmonary edema, or death. Elemental selenium and most metallic selenides have relatively low toxicities because of low bioavailability. By contrast, selenates and selenites have an oxidant mode of action similar to that of arsenic trioxide and are very toxic. The chronic toxic dose of selenite for humans is about 2400 to 3000 micrograms of selenium per day. Hydrogen selenide is an extremely toxic, corrosive gas. Selenium also occurs in organic compounds, such as dimethyl selenide, selenomethionine, selenocysteine and methylselenocysteine, all of which have high bioavailability and are toxic in large doses.\n\nOn 19 April 2009, 21 polo ponies died shortly before a match in the United States Polo Open. Three days later, a pharmacy released a statement explaining that the horses had received an incorrect dose of one of the ingredients used in a vitamin/mineral supplement compound that had been incorrectly prepared by a compounding pharmacy. Analysis of blood levels of inorganic compounds in the supplement indicated the selenium concentrations were ten to fifteen times higher than normal in the blood samples, and 15 to 20 times higher than normal in the liver samples. Selenium was later confirmed to be the toxic factor.\n\nSelenium poisoning of water systems may result whenever new agricultural runoff courses through normally dry, undeveloped lands. This process leaches natural soluble selenium compounds (such as selenates) into the water, which may then be concentrated in new \"wetlands\" as the water evaporates. Selenium pollution of waterways also occurs when selenium is leached from coal flue ash, mining and metal smelting, crude oil processing, and landfill. The resultant high selenium levels in waterways were found to cause congenital disorders in oviparous species, including wetland birds and fish. Elevated dietary methylmercury levels can amplify the harm of selenium toxicity in oviparous species.\n\nIn fish and other wildlife, selenium is necessary for life, but toxic in high doses. For salmon, the optimal concentration of selenium is about 1 microgram selenium per gram of whole body weight. Much below that level, young salmon die from deficiency; much above, they die from toxic excess.\n\nThe Occupational Safety and Health Administration (OSHA) has set the legal limit (Permissible exposure limit) for selenium in the workplace at 0.2 mg/m over an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a Recommended exposure limit (REL) of 0.2 mg/m over an 8-hour workday. At levels of 1 mg/m, selenium is immediately dangerous to life and health.\n\nSelenium deficiency can occur in patients with severely compromised intestinal function, those undergoing total parenteral nutrition, and in those of advanced age (over 90). Also, people dependent on food grown from selenium-deficient soil are at risk. Although New Zealand soil has low levels of selenium, adverse health effects have not been detected in the residents.\n\nSelenium deficiency, defined by low (<60% of normal) selenoenzyme activity levels in brain and endocrine tissues, occurs only when a low selenium level is linked with an additional stress, such as high exposures to mercury or increased oxidant stress from vitamin E deficiency.\n\nSelenium interacts with other nutrients, such as iodine and vitamin E. The effect of selenium deficiency on health remains uncertain, particularly in relation to Kashin-Beck disease. Also, selenium interacts with other minerals, such as zinc and copper. High doses of Se supplements in pregnant animals might disturb the Zn:Cu ratio and lead to Zn reduction; in such treatment cases, Zn levels should be monitored. Further studies are needed to confirm these interactions.\n\nIn the regions (e.g. various regions within North America) where low selenium soil levels lead to low concentrations in the plants, some animal species may be deficient unless selenium is supplemented with diet or injection. Ruminants are particularly susceptible. In general, absorption of dietary selenium is lower in ruminants than other animals, and is lower from forages than from grain. Ruminants grazing certain forages, e.g., some white clover varieties containing cyanogenic glycosides, may have higher selenium requirements, presumably because cyanide is released from the aglycone by glucosidase activity in the rumen and glutathione peroxidases is deactivated by the cyanide acting on the glutathione moiety. Neonate ruminants at risk of white muscle disease may be administered both selenium and vitamin E by injection; some of the WMD myopathies respond only to selenium, some only to vitamin E, and some to either.\n\nA number of correlative epidemiological studies have implicated selenium deficiency (measured by blood levels) in a number of serious or chronic diseases, such as cancer, diabetes, HIV/AIDS, and tuberculosis. In addition, selenium supplementation has been found to be a chemopreventive for some types of cancer in some types of rodents.\nOne study of 118 exocrine pancreatic cancer (EPC) patients and 399 hospital controls in eastern Spain found high selenium concentrations to be inversely associated with the risk of EPC. In randomized, blinded, controlled prospective trials in humans, selenium supplementation has not succeeded in reducing the incidence of any disease, nor has a meta-analysis of such selenium supplementation studies detected a decrease in overall mortality. However, selenium supplementation may be beneficial in cancer patients receiving radiotherapy.\n\n\n"}
{"id": "12676148", "url": "https://en.wikipedia.org/wiki?curid=12676148", "title": "Shilendra Kumar Singh", "text": "Shilendra Kumar Singh\n\nShilendra Kumar Singh or S.K. Singh (24 January 1932 – 1 December 2009) was an Indian diplomat. He was Governor of Arunachal Pradesh from December 2004 to September 2007 and Governor of Rajasthan from September 2007 until he died in office in December 2009.\n\nSingh was Indian Foreign Secretary from 1989 to 1990. Prior to becoming Governor of Arunachal Pradesh, he was secretary-general of a think tank in Delhi, the University of Pennsylvania Institute for the Advanced Study of India. He was appointed as Governor of Rajasthan on 19 August 2007, left his position as Governor of Arunachal Pradesh on 4 September 2007, and was sworn in as Governor of Rajasthan on 6 September.\n\nHe was the son of a nationalist zamindar of the erstwhile United Provinces, and a former Dewan of Alwar. A topper throughout school and college, he was an alumnus of St Johns College, Agra which is affiliated to Agra University where he received a bachelor's degree in History, Sanskrit and Hindi. He attended the Agra University and received a master's degree in History and an LLB Degree. Thereafter he read Persian and International Law at Trinity College, Cambridge.\n\nHe was married to Manju Singh. His younger son Kanishka Singh is a political aide to Rahul Gandhi and his elder son, Shashank Singh, has an MBA from Harvard University, and currently works as an investment banker in Mumbai.\n\nWhile in Arunachal Pradesh, Singh was an extremely vocal advocate articulating that Arunachal Pradesh is a non-negotiable part of sovereign India. He also crusaded for the Inner Line Permit and restricted area permit required for travel to Arunachal Pradesh to be abolished. In addition, he worked hard for ensuring connectivity of Arunachal Pradesh with the rest of India by building an airport in the state, constructing a railway line and improving the road network.\n\nIn February 1989, Singh was appointed Foreign Secretary of India. He held the personal rank of Grade-I Ambassador, the highest in the Indian Foreign Service. Prior to becoming Foreign Secretary, he was India's longest serving Ambassador to Pakistan from 1985 until 1989. He also served as Ambassador to Austria from 1982–1985, Additional Foreign Secretary from 1979–1982, Ambassador to Afghanistan from 1977–1979 and Ambassador concurrently to Jordan, Lebanon and Cyprus from 1974–1977. He was the longest-serving Official Spokesman of the Government of India from 1969–74. In 1968–69 he served in the Ministry of Commerce as Director Foreign Trade.\n\nSingh began his career in the Indian Foreign Service in 1954. From 1956 to 1959, he was Third Secretary in Iran and concurrently attended the Tehran University to study the Persian language. From 1959–62 he was assigned to various desks in the Foreign Office in Delhi. From 1962–68 he was a member of the Permanent Mission of India to the United Nations in New York.\n\nSingh was President of the Group of 77 and also served as India's Governor on the Board of Governors of the International Atomic Energy Agency in Vienna. Singh has been a member of 19 Indian delegations to the UN General Assembly and the United Nations Commission on Human Rights. Singh has monitored for the Commonwealth and the United Nations, general elections in South Africa, Kenya, Algeria, Lesotho, Malawi and Sierra Leone \n\nSingh has taught History at Agra University. He was a Visiting Professor and Member of the Academic Council of Jawaharlal Nehru University, Delhi.\n\nSingh was a frequent writer and commentator on international relations, geopolitics and current developments.\n\nHe died at Sir Ganga Ram Hospital in Delhi on 1 December 2009, aged 77, after a brief illness.\n\n"}
{"id": "10860760", "url": "https://en.wikipedia.org/wiki?curid=10860760", "title": "Slovenské elektrárne", "text": "Slovenské elektrárne\n\nSlovenské elektrárne, a.s. is an electric utility company based in Bratislava, Slovak Republic, and successor to the former state monopoly. It operates nuclear, hydroelectric and fossil fuel power plants. Since July 2016, 66% of Slovenské elektrárne's shares is owned by Slovak Power Holding BV, a company founded and 50:50 percent controlled by the Czech industrial group Energetický a průmyslový holding and the Italian energy company Enel.\n\nSlovenské elektrárne has signed a business agreement with Consorzio Paleocapa on September 12, 2010, for future collaboration in fossil fuel power plants operation in Italy and Slovakia.\n\n"}
{"id": "1951467", "url": "https://en.wikipedia.org/wiki?curid=1951467", "title": "Springboard", "text": "Springboard\n\nA springboard or diving board is used for diving and is a board that is itself a spring, i.e. a linear flex-spring, of the cantilever type.\n\nSpringboards are commonly fixed by a hinge at one end (so they can be flipped up when not in use), and the other end usually hangs over a swimming pool, with a point midway between the hinge and the end resting on an adjustable fulcrum.\n\nModern springboards are made out of a single-piece extrusion of aircraft-grade aluminum. The Maxiflex Model B, the board used in all major competitive diving events, is made out of such aluminum, and is heat treated for a yield strength of . The slip-resistant surface of the board is created using an epoxy resin, finished with a laminate of flint silica and alumina in between the top coats of resin. This thermal-cured resin is aqua-colored to match the water of a clean pool.\n\nThe spring constant of a springboard is usually adjusted by way of a fulcrum that is located approximately mid way along the springboard. Springboards are usually operated in a linear regime where they approximately obey Hooke's law. When loaded with a diver, the combination of the diver's approximately constant mass, and the constant stiffness of the spring(board) result in a resonance frequency that is adjustable by way of the spring constant (set by the fulcrum position). Since the resulting system is in an approximately linear regime, it may be modeled fairly accurately by a second order differential equation. Typically the resonance frequency can be adjusted over a range of a 2:1 or 3:1 ratio.\n\nThe fulcrum of competitive diving boards travels over a range of , and is set by way of a foot wheel that is approximately in diameter. To stiffen the spring (as if tightening it), the foot wheel is usually turned counter clockwise. Some may find this counter intuitive, since usually things are tightened by turning clockwise. However, with a little experience, people realize the fulcrum moves in the direction the bottom of the foot faces when placed on the foot wheel.\n\nSpringboards are usually located either above the water surface. It is very seldom that one is mounted at a height other than these two standard heights.\n\nBefore around 1960, springboards, usually made of wood, were located at heights of either , or above the water. American artist Norman Rockwell's painting titled \"Boy on High Dive\" (1947) shows a typical wooden springboard of the early 20th century era at the 7 m height.\n\nAfter an incident in Washington in 1993, most US and other pool builders are reluctant to equip a residential swimming pool with a diving springboard so home diving pools are much less common these days. In the incident, 14-year-old Shawn Meneely made a \"suicide dive\" (holding his hands at his sides, so that his head hit the bottom first) in a private swimming pool and was seriously injured and became a tetraplegic. The lawyers for the family, Jan Eric Peterson and Fred Zeder, successfully sued the diving board manufacturer, the pool builder, and the National Spa and Pool Institute (NSPI) over the inappropriate depth of the pool.\nThe NSPI had specified a minimum depth of which proved to be insufficient in the above case. The pool into which Meneely dived was not constructed to the published standards. The standards had changed after the diving board was installed on the non-compliant pool by the homeowner. But the courts held that the pool \"was close enough\" to the standards to hold NSPI liable. The multimillion-dollar lawsuit was eventually resolved in 2001 for US$6.6 million ($8 million after interest was added) in favor of the plaintiff. The NSPI was held to be liable, and was financially strained by the case. It filed twice for Chapter 11 bankruptcy protection and was successfully reorganized into a new swimming pool industry association.\n"}
{"id": "20011696", "url": "https://en.wikipedia.org/wiki?curid=20011696", "title": "Stara Planina Wind Farm", "text": "Stara Planina Wind Farm\n\nThe Stara Planina Wind Farm () is a proposed wind power project in Varna, Bulgaria. It will have 30 individual wind turbines with a nominal output of around 2 MW each that will deliver up to 60 MW of power, enough to power over 23,940 homes, with a capital investment required of approximately US$120 million.\n"}
{"id": "17551973", "url": "https://en.wikipedia.org/wiki?curid=17551973", "title": "Sweet Crude", "text": "Sweet Crude\n\nSweet Crude is a documentary film about Nigeria's oil-rich Niger Delta directed by Sandy Cioffi. The film premiered in April 2009 at the Full Frame Documentary Film Festival and has since screened at 30 film festivals around the world and has won numerous awards.\n\nOn April 12, 2008, members of the \"Sweet Crude\" filmmaking crew were detained by the Nigerian military Joint Task Force while traveling by boat in the Niger Delta. The crew was taken into custody and subsequently handed over to the Nigerian State Security Services. They were held for seven days without being charged and without access to legal counsel. They were released Friday, April 18.\n\nFrom the \"Sweet Crude\" website:\n\nSweet Crude has been nominated at Oaxaca Film Fest.\n\n"}
{"id": "5555728", "url": "https://en.wikipedia.org/wiki?curid=5555728", "title": "Transition zone (Earth)", "text": "Transition zone (Earth)\n\nThe transition zone is part of the Earth’s mantle, and is located between the lower mantle and the upper mantle, between a depth of 410 and 660 km (250 to 400 mi). The Earth’s mantle, including the transition zone, consists primarily of peridotite, an ultramafic igneous rock.\n\nThe mantle was divided into the upper mantle, transition zone, and lower mantle as a result of sudden seismic-velocity discontinuities at depths of 410 and 660 km (250 to 400 mi). This is thought to occur as a result of rearrangement of grains in olivine (which constitutes a large portion of peridotite) at a depth of 410 km, to form a denser crystal structure as a result of the increase in pressure with increasing depth. Below a depth of 660 km, evidence suggests due to pressure changes ringwoodite minerals change into two new denser phases, bridgmanite and periclase. This can be seen using body waves from earthquakes, which are converted, reflected or refracted at the boundary, and predicted from mineral physics, as the phase changes are temperature and density-dependent and hence depth dependent.\n\nA single peak is seen in all seismological data at 410 km which is predicted by the single transition from α- to β- MgSiO (olivine to wadsleyite). From the Clapeyron slope the Moho discontinuity is expected to be shallower in cold regions, such as subducting slabs, and deeper in warmer regions, such as mantle plumes.\n\nThis is the most complex discontinuity seen. It appears in PP precursors (a wave which reflects off the discontinuity once) only in certain regions but is always apparent in SS precursors. It is seen as single and double reflections in receiver functions for P to S conversions over a broad range of depths (640–720 km, or 397–447 mi). The Clapeyron slope predicts a deeper discontinuity in cold regions and a shallower discontinuity in hot regions. This discontinuity is generally linked to the transition from ringwoodite to bridgmanite and periclase. This is thermodynamically an endothermic reaction and creates a viscosity jump. Both characteristics cause this phase transition to play an important role in geodynamical models. Cold downwelling material might pond on this transition.\n\nThere is another major phase transition predicted at 520 km for the transition of olivine (β to γ) and garnet in the pyrolite mantle. This one is only sporadically been observed in seismological data.\n\nOther non-global phase transitions have been suggested at a range of depths.\n"}
{"id": "45700548", "url": "https://en.wikipedia.org/wiki?curid=45700548", "title": "Two-dimensional semiconductor", "text": "Two-dimensional semiconductor\n\nA two-dimensional semiconductor (also known as 2D semiconductor) is a type of natural semiconductor with thicknesses on the atomic scale. The rising research attention towards 2D semiconductors started with a discovery by Geim and Novoselov et al. in 2004, when they reported a new semiconducting material graphene, a flat monolayer of carbon atoms arranged in a 2D honeycomb lattice. A 2D monolayer semiconductor is significant because it exhibits stronger piezoelectric coupling than traditionally employed bulk forms, which enables 2D materials applications in new electronic components used for sensing and actuating. In this emergent field of research in solid-state physics, the main focus is currently on designing nanoelectronic components by the use of graphene as electrical conductor, hexagonal boron nitride as electrical insulator, and a transition metal dichalcogenide as semiconductor.\n\nGraphene's two surfaces are single sheets of carbon atoms arranged in a hexagonal honeycomb lattice. Having two surfaces and lacking bulk makes it the thinnest possible material but also 5 times stronger than steel due to pi and sigma orbital bonds. Graphene has high electron mobility and high thermal conductivity. Although graphene can be used in different applications, one issue regarding graphene is its lack of a band gap, which poses a problem in particular with digital electronics because it is unable to switch off field-effect transistors (FETs).\nNanosheets of other group-IV elements (Si, Ge and Sn) present structural and electronic properties similar to graphene.\n\nMonolayer hexagonal boron nitride (h-BN), also known as ‘white graphene’, is structurally similar to graphite and features a honeycomb arrangement with alternating boron and nitrogen atoms in place of carbon. h-BN has a higher energy gap (5.97 eV) than graphene, thus functions as an insulator instead of a semimetal. However, it can also function as a semiconductor with enhanced conductivity due to its zigzag sharp edges and vacancies. h-BN is often used as substrate and barrier due to its insulating property. Furthermore, h-BN also has a large thermal conductivity and mechanical strength. Thus, it can be employed as a support for metal catalyst due to its chemical, thermal, acid-base stability and high thermal conductance.\nTransition metal dichalcogenides (TMDCs) are a class of two-dimensional materials, which have the chemical formula MX, where M represents transition metals from group VI, V and VI, and X represents a chalcogen such as sulfur, selenium or tellurium. MoS, MoSe, MoTe, WS and WSe are TMDCs. TMDCs have layered structure with a plane of metal atoms in between two planes of chalcogen atoms as shown in Figure 1. Each layer is bonded strongly in plane, but weakly in interlayers. Therefore, TMDCs can be easily exfoliated into atomically thin layers through various methods. TMDCs show layer-dependent optical and electrical properties. When exfoliated into monolayers, the band gaps of several TMDCs change from indirect to direct, which lead to broad applications in nanoelectronics and optoelectronics.\n\n2D semiconductor materials are often synthesized using a chemical vapor deposition (CVD) method. Because CVD can provide large-area, high-quality, and well-controlled layered growth of 2D semiconductor materials, it also allows synthesis of two-dimensional heterojunctions. When building devices by stacking different 2D materials, mechanical exfoliation followed by transferring is often used. Other possible synthesis methods include chemical exfoliation, hydrothermal synthesis, and thermal decomposition.\n\nSome devices applications include electronic devices, photonic and energy harvesting devices, and flexible and transparent substrates.\n\n2D Semiconductors can be used as transistors for digital electronics. The impure charges at the interfaces that are free of dangling bonds, allow for 2D semiconductors to run low-power devices. The 2D semiconductor interface has future potential in nano circuits due to its ability to optimize and regulate thermal transfer. \n2D semiconductors have potential for application in the harvesting of solar energy. The atomically thin structure allows for lower surface recombination velocity, which leads to better photocurrent conduction. An improvement on solar cell performance has been shown, while stacking 2D semiconductors with multilayers of graphene.\n\nThe thin layer of 2D materials can be used for flexible electronics. In particular, 2D MoS can be used to create thin displays and wearable electronics due to its out of plane flexibility, strong covalent bonds, and diverse electronic properties.\n"}
{"id": "31969546", "url": "https://en.wikipedia.org/wiki?curid=31969546", "title": "Weather Information Exchange Model", "text": "Weather Information Exchange Model\n\nThe Weather Information Exchange Model (WXXM) is a platform that was originally designed by EUROCONTROL for the exchange of weather related information between users.\n\nIt is now a proposed standard of the Open Geospatial Consortium (OGC) and is used by both Eurocontrol and the FAA.\n"}
