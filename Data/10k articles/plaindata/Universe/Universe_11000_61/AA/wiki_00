{"id": "25115903", "url": "https://en.wikipedia.org/wiki?curid=25115903", "title": "ANSI C12.10", "text": "ANSI C12.10\n\nANSI C12.10 is the ANSI \"American National Standard for Physical Aspects of Watt-hour Meters\".\n\nThis standard covers the physical aspects of both detachable and bottom-connected watt-hour meters and associated registers. These include ratings, internal wiring arrangements, pertinent dimensions, markings and other general specifications.\nThis standard includes references to latest version of ANSI C12.1 and ANSI C12.20 for performance requirements. Dimensions and other relevant specifications have been coordinated with ANSIC12.7-2005 American National Standard Requirements for Watthour Meters Sockets.\n\n"}
{"id": "43248134", "url": "https://en.wikipedia.org/wiki?curid=43248134", "title": "Anticrystal", "text": "Anticrystal\n\nAn anticrystal is a theoretical solid that is completely disordered, making it the opposite of a crystal. The mechanical properties of even a slightly disordered solid can have more in common with an anticrystal than with a crystal.\n\nAll naturally occurring crystals contain disordered areas (defects). Scientific descriptions typically assume a perfect crystal, extrapolating from that point based on defect prevalence. However, given sufficient defects, extrapolation from perfect crystals fails. Amorphous materials may display regions with atoms in repeating patterns, but without crystalline order. This means that their properties cannot be inferred from those of a perfect crystal.\n\nThe phase transition that occurs when a fluid becomes a disordered solid under pressure is called the jamming transition. Phase transitions occur when a liquid becomes a solid or a gas. Another way of producing a solid is by putting atoms, molecules or larger particles together under high pressure. Extrapolations from the jamming transition showed that even fairly orderly materials exhibited behaviors closer to those of the anticrystal than a perfect crystal.\n\nAnticrystal principles can also provide insight into crystalline materials. For example, strengthening metal alloys often involves shrinking their crystalline areas, such that their behaviors are better described by anticrystals.\n"}
{"id": "23244566", "url": "https://en.wikipedia.org/wiki?curid=23244566", "title": "Avion (car)", "text": "Avion (car)\n\nThe Avion is a prototype sportscar that achieves over 100 MPG. The Avion car is based on a simple concept: fuel economy is largely determined by aerodynamic drag and vehicle weight. The Avion uses existing automotive components, an existing high-efficiency automotive diesel engine and marries them to a lightweight aluminum frame and highly aerodynamic composite body. The Avion was an official contender in the Progressive Insurance Automotive X Prize.\n\nThe Avion was developed in 1979 by Craig Henderson and Bill Green after graduating from Western Washington University in Bellingham, Washington where they had worked at the Vehicle Research Institute. The prototype was completed in 1984 and set the Guinness world record for fuel economy in 1986 at 103.7 mpg.\n\nThe plan, at the time the car was designed, was to manufacture the Avion in limited quantities and sell into the car enthusiast market. But the real price of gasoline fell steadily from 1979 through the 1980s and interest in highly fuel-efficient cars disappeared along with the interest of potential investors. \n\nThe dramatic increase in real fuel prices from 2000 to 2008 has renewed interest in automobile fuel economy. The original Avion was taken out of storage and an updated version was entered in the Progressive Automotive X Prize competition. Recent testing, using the original body and replacing the original Volkswagen Rabbit diesel engine with the Smart Car ForTwo diesel show 80 MPG at and a remarkable 114 MPG at .\n\nThe car was designed to be manufactured in small volume using existing automotive components, including a small automotive diesel engine. A lightweight composite body of highly aerodynamic design is attached to an aluminum frame, and features Butterfly doors.\n\n"}
{"id": "6873384", "url": "https://en.wikipedia.org/wiki?curid=6873384", "title": "Bitumen-based fuel", "text": "Bitumen-based fuel\n\nBitumen-based fuel is fuel specifically developed for industrial use. Raw bitumen, processed from Bituminous rocks, has an extremely high viscosity.\n\nBitumen has an extremely high viscosity, between 8 and 10 API degrees (at ambient temperatures), rendering it unusable for use in electric power stations. Bitumen can be modified by mixing it with fresh water and a small amount of phenol-based surfactant. The resulting mixture has properties similar to conventional fuel oil.\n\nA newer version of bitumen-based fuel has replaced the original version with an alcohol-based surfactant, making it easier to transport the fuel and eliminating the health concerns associated with the phenol group of surfactants.\n\nThe most well known bitumen-based fuel has been developed by Intevep, the Research and Development Affiliate of Petroleos de Venezuela SA (PDVSA), in a collaboration with BP, and is branded \"Orimulsion.\" It is an emulsion of natural bitumen mined from the Orinoco Belt and fresh water. \n\nBitumen-based fuel is currently used as a commercial boiler fuel in power plants in Canada, Japan, Lithuania, and China. Commonly available air pollutant control technology can limit emissions from Orimulsion to levels considered Best Available Control Technology, as defined by the United States Environmental Protection Agency.\n\n"}
{"id": "4623969", "url": "https://en.wikipedia.org/wiki?curid=4623969", "title": "Calcium hydride", "text": "Calcium hydride\n\nCalcium hydride is the chemical compound with the formula CaH, and is therefore an alkaline earth hydride. This grey powder (white if pure, which is rare) reacts vigorously with water liberating hydrogen gas. CaH is thus used as a drying agent, i.e. a desiccant.\n\nCaH is a saline hydride, meaning that its structure is salt-like. The alkali metals and the alkaline earth metals heavier than beryllium all form saline hydrides. A well-known example is sodium hydride, which crystallizes in the NaCl motif. These species are insoluble in all solvents with which they do not react. CaH crystallizes in the PbCl (cotunnite) structure.\n\nCalcium hydride is prepared from its elements by direct combination of calcium and hydrogen at 300 to 400 °C. \n\nCaH is a reducing agent for the production of metal powders from the oxides of Ti, V, Nb, Ta, and U. It is proposed to operate via its decomposition to Ca metal:\n\nCaH has been used for hydrogen production. In the 1940s, it was available under the trade name \"Hydrolith\" as a source of hydrogen:\n'The trade name for this compound is \"hydrolith\"; in cases of emergency, it can be used as a portable source of hydrogen, for filling airships. It is rather expensive for this use.'\nThe reference to \"emergency\" probably refers to wartime use. The compound has, however, been widely used for decades as a safe and convenient means to inflate weather balloons. Likewise, it is regularly used in laboratories to produce small quantities of highly pure hydrogen for experiments. The moisture content of diesel fuel is estimated by the hydrogen evolved upon treatment with CaH.\n\nThe reaction of CaH with water can be represented as follows:\n\nThe two hydrolysis products, gaseous H and Ca(OH), are readily separated from the dried solvent.\n\nCalcium hydride is a relatively mild desiccant and, compared to molecular sieves, probably inefficient. Its use is safer than more reactive agents such as sodium metal or sodium-potassium alloy. Calcium hydride is widely used as a desiccant for basic solvents such as amines and pyridine. It is also used to dry alcohols.\n\nDespite its convenience, CaH has a few drawbacks:\n\nDuring the Battle of the Atlantic, German submarines used calcium hydride as a sonar decoy called bold.\n\n"}
{"id": "33949877", "url": "https://en.wikipedia.org/wiki?curid=33949877", "title": "Clarence J. Lebel", "text": "Clarence J. Lebel\n\nClarence J. Lebel was an American inventor of fluorescent lamp and holder of 9 other patents, first President of Audio Instrument Company, and first president of Audio Engineering Society\n\n"}
{"id": "30727051", "url": "https://en.wikipedia.org/wiki?curid=30727051", "title": "Corona set", "text": "Corona set\n\nIn mathematics, the corona or corona set of a topological space \"X\" is the complement β\"X\"\\\"X\" of the space in its Stone–Čech compactification β\"X\".\n\nA topological space is said to be σ-compact if it is the union of countably many compact subspaces, and locally compact if every point has a neighbourhood with compact closure. The corona of a σ-compact and locally compact Hausdorff space is a sub-Stonean space, i.e., any two open σ-compact disjoint subsets have disjoint compact closures.\n\n"}
{"id": "490476", "url": "https://en.wikipedia.org/wiki?curid=490476", "title": "Dugout canoe", "text": "Dugout canoe\n\nA dugout canoe or simply dugout is a boat made from a hollowed tree trunk. Other names for this type of boat are logboat and monoxylon. \"Monoxylon\" (\"μονόξυλον\") (pl: \"monoxyla\") is Greek -- \"mono-\" (single) + \"ξύλον xylon\" (tree) -- and is mostly used in classic Greek texts. In Germany they are called einbaum (\"one tree\" in English). Some, but not all, pirogues are also constructed in this manner.\n\nDugouts are the oldest boats archaeologists have found, dating back about 8,000 years to the Neolithic Stone Age. This is probably because they are made of massive pieces of wood, which tend to preserve better than, e.g., bark canoes. Along with bark canoe and hide kayak, dugout boats were also used by indigenous peoples of the Americas.\n\nConstruction of a dugout begins with the selection of a log of suitable dimensions. Sufficient wood needed to be removed to make the vessel relatively light in weight and buoyant, yet still strong enough to support the crew and cargo. Specific types of wood were often preferred based on their strength, durability, and density. The shape of the boat is then fashioned to minimize drag, with sharp ends at the bow and stern.\n\nFirst the bark is removed from the exterior. Before the appearance of metal tools, dugouts were hollowed out using controlled fires. The burnt wood was then removed using an adze. Another method using tools is to chop out parallel notches across the interior span of the wood, then split out and remove the wood from between the notches. Once hollowed out, the interior was dressed and smoothed out with a knife or adze.\n\nMore primitive designs keep the tree's original dimensions, with a round bottom. However, it is possible to carefully steam the sides of the hollow log until they are pliable, then bend to create a more flat-bottomed \"boat\" shape with a wider beam in the centre.\n\nFor travel in the rougher waters of the ocean, dugouts can be fitted with outriggers. One or two smaller logs are mounted parallel to the main hull by long poles. In the case of two outriggers, one is mounted on either side of the hull.\n\nThe Dufuna canoe from Nigeria is an 8000-year-old dugout, the oldest boat discovered in Africa, and the third-oldest worldwide.\nThe well-watered tropical rainforest and woodland regions of sub-Saharan Africa provide both the waterways and the trees for dugout canoes, which are commonplace from the Limpopo River basin in the south through East and Central Africa and across to West Africa. African Teak is the timber favoured for their construction, though this comprises a number of different species, and is in short supply in some areas. Dugouts are paddled across deep lakes and rivers or punted through channels in swamps (see \"makoro\") or in shallow areas, and are used for transport, fishing and hunting, including, in the past, the very dangerous hunting of hippopotamus. Dugouts are called pirogues in Francophone areas of Africa.\n\nAn 8000-year-old dugout canoe was found by archaeologists in Kuahuqiao, Zhejiang Province, in east China. This is the earliest canoe found in Asia.\n\nThe Moken, an ethnic group that lives in Myanmar's Mergui Archipelago and the north of Thailand as sea nomads, still builds and uses dugout canoes. According to the Moken's accounts of their people's origin, a mythical queen punished the forbidden love of their ancestral forefather for his sister-in-law by banishing him and his descendants to life on sea in dugout canoes with indentations fore and aft (\"a mouth that eats and a rear that defecates\"), symbolizing the unending cycle of ingestion, digestion and evacuation.\n\nA centuries-old unfinished dugout boat, a big banca (five tons, measuring 8 by 2 by 1.5 meters) was accidentally retrieved on November, 2010 by Mayor Ricardo Revita at Barangay Casanicolasan, Rosales, Pangasinan, Philippines, in Lagasit River, near Agno River. It is now on display in front of the Municipal Town Hall.\n\nIn ancient many dugouts were made from linden wood, for several reasons. First, was abundant in the Paleolithic after the melting of the Weichselian glaciation and readily available. Secondly it grew to be one of the tallest trees in the forests of the time, making it easier to build longer boats. Linden wood also lends itself well to carving and doesn't split or crack easily. It is lighter and therefore boats made from it have a better cargo capacity and are easier to carry, than most other tree types from the European old-growth forests.\n\nThe Pesse canoe, found in the Netherlands, is a dugout which is believed to be the world's oldest boat, carbon dated to between 8040 BCE and 7510 BCE. Other dugouts discovered in the Netherlands include two in the province of North Holland: in 2003, near Uitgeest, dated at 617-600 BC; and in 2007, near Den Oever, dated at 3300-3000 BC.\n\nDugouts have also been found in Germany. In German, the craft are known as \"einbaum\" (one-tree). In the old Hanseatic town of Stralsund three log-boats were excavated in 2002. Two of the boats were around 7,000 years old and are the oldest boats found in the Baltic area. The third boat (6,000 years old) was 12 meters long and holds the record as the longest dugout in the region. The finds have partly deteriorated due to poor storage conditions.\n\nIn 1991, remains of a linden wood log-boat of nearly 6 meters were found at Männedorf-Strandbad in Switzerland at Lake Zürich. The boat has since been dated to be 6,500 years old.\nIn 1902 an oak log boat over 15m long and 1m wide, was found at Addergoole Bog, Lurgan, County Galway, Ireland and delivered to the National Museum of Ireland. The Lurgan boat radiocarbon date was 3940 +/- 25 BP. The boat has holes suggesting that it had an outrigger or was joined to another boat.\n\nIn 2012, at Parc Glyndwr, Monmouth, Monmouthshire, Wales, UK, an excavation by Monmouth Archeological Society, revealed three ditches suggesting a Neolithic dugout trimaran of similar length to the Lurgan log boat, carbon dated 3700+/-35 BP.\n\n\"De Administrando Imperio\" details how the Slavs built monoxyla that they sold to Rus' in Kiev. These ships were then used against the Byzantine Empire during the Rus'–Byzantine Wars of the 9th and 10th centuries. They used dugouts to attack Constantinople and to withdraw into their lands with bewildering speed and mobility. Hence, the name of Δρομίται (\"people on the run\") applied to the Rus in some Byzantine sources. The monoxyla were often accompanied by larger galleys, that served as command and control centres. Each Slavic dugout could hold from 40 to 70 warriors.\n\nThe Cossacks of the Zaporozhian Host were also renowned for their artful use of dugouts, which issued from the Dnieper to raid the shores of the Black Sea in the 16th and 17th centuries. Using small, shallow-draft, and highly maneuverable galleys known as \"chaiky\", they moved swiftly across the Black Sea. According to the Cossacks' own records, these vessels, carrying a 50 to 70 man crew, could reach the coast of Anatolia from the mouth of the Dnieper River in forty hours.\n\nMore than 40 pre-historic log-boats have been found in the Czech Republic. The latest discovery was in 1999 of a 10 m long log-boat in Mohelnice (Šumperk District). It was cut out of a single oak log and has a width of 1.05 m. The log-boat has been dated to around 1,000 BC and is kept at the 'Mohelnice Muzeum' (Museum of National History). Geographically, Czech log-boat sites and remains are clustered along the Elbe and Morava Rivers.\n\nPoland is known for the socalled \"Lewin\"-type log-boats, found at Lewin Brzeski, Koźle and Roszowicki Las accordingly. These boats, are characterized by square or trapezoidal cross-section, rectangular hull-ends and low height of the sides in relation to vessel length. In addition, nearly all the Lewin-type boats have a single hole in the bow and two at the stern. The low height is a result of the parent log being split lengthwise in half, in order to obtain two identical timbers from a single trunk. The advantage lies in the resulting identical twin hulls, which are then joined to form a double-hulled raft. The paired hulls were joined by transverse poles, which did not go through the holes in the platform ends but were fastened to the top walls or in special grooves at the hull ends. These vessels were typically 7–12 m in length, and the largest of them could carry up to 1.5 tons of cargo because of the special design. The Lewin type logboats are usually associated with the Przeworsk culture in the early centuries AD.\nMany pre-historic dugout boats have been found in Scandinavia. These boats were used for transport on calmer bodies of water, fishing and maybe occasionally for whaling and sealing. Dugouts require no metal parts, and were common amongst the Stone Age people in Northern Europe until large trees suitable for making this type of watercraft became scarce. Length was limited to the size of trees in the old-growth forests—up to in length. In Denmark in 2001 and some years prior to that, a few dugout canoes of linden wood, was unearthed in a large scale archaeological excavation project in Egådalen, just north of Aarhus. They have been carbon dated to the years 5210-4910 BCE and they are the oldest known boats in Northern Europe.\n\nLater models increased freeboard (and seaworthiness) by lashing additional boards to the side of the boat. Eventually, the dugout portion was reduced to a solid keel, and the lashed boards on the sides became a Lapstrake hull.\n\nIn the United Kingdom, two log boats were discovered in Newport, Shropshire and are now on display at Harper Adams University Newport. The Iron Age residents of Great Britain, were known to have used logboats for fishing and basic trade. In 1964, a logboat was uncovered in Poole Harbour, Dorset. The Poole Logboat dated to 300 BC, was large enough to accommodate 18 people and was constructed from a giant oak tree. It is currently located in the Poole Museum. An even older logboat (the Hanson log boat) was unearthed in 1998 in Shardlow south of Derby. It has been dated to the Bronze Ages around 1.500 BC and is now exhibited at Derby Museum and Art Gallery. There was another pre-historic boat at the same location, but it was buried \"in situ\".\n\nIn Northern Europe, the tradition of making dugout canoes survived into the 20th and 21st centuries only in Estonia, where seasonal floods in Soomaa, a 390 km² wilderness area, make conventional means of transportation impossible. In recent decades a new surge of interest in making dugouts (Estonian \"haabjas\") has revitalized the ancient tradition.\n\nDugout canoes were constructed throughout the Americas, where suitable logs were available. The indigenous people of the Pacific Northwest are very skilled at crafting wood. Best known for totem poles up to tall, they also construct dugout canoes over long for everyday use and ceremonial purposes.\n\nIn 1978, Geordie Tocher and two companions sailed a , dugout canoe (the \"Orenda II\"), made of Douglas fir, and based on Haida designs (but with sails), from Vancouver, British Columbia, Canada to Hawaii to add credibility to stories that the Haida had travelled to Hawaii in ancient times. Altogether they ventured some 4,500 miles (7,242 km) after two months at sea.\n\nThe dugout canoes were made mostly of huge cedar logs in the state of Washington for the ocean travellers, but natives that lived on the smaller rivers used smaller cedar logs.\n\nIn the Pacific Islands, dugout canoes are very large, made from whole mature trees and fitted with outriggers for increased stability in the ocean, and were once used for long-distance travel. Such are the very large waka used by Māori who came to New Zealand probably from East Polynesia, about 1280. Such vessels carried 40 to 80 warriors in calm sheltered coastal waters or rivers. It is believed that trans-ocean voyages were made in Polynesian catamarans and one hull, carbon-dated to about 1400, was found in New Zealand in 2011. In New Zealand smaller waka were made from a single log, often Totara, because of its lightness, strength and resistance to rotting. Larger waka were made of about seven parts lashed together with flax rope. All waka are characterized by very low freeboard. In Hawaii, \"waa\" (canoes) are traditionally manufactured from the trunk of the \"koa\" tree. They typically carry a crew of six: one steersman and five paddlers.\n\nThe Pacific Ocean has been the nursery for many different forms of dugout sailing craft. They differ in their sail plan (\"i.e.\", crab-claw or half-crab-claw, Latin, or triangular), hull formats (single, double, catamaran or proa), the absence or presence of a beam (a bridge for a double hull). Hull shapes and end forms vary greatly. Masts can \"be right or made of double spars.\" Hulls can be constructed by assembling boards or digging out tree trunks. Intended use (fish, war, sea voyage) and geographical features (beach, lagoon, reefs) are reflected in design. Importantly, there is an important dividing line: some craft use a tacking rig; others \"shunt\" that is change tack \"by reversing the sail from one end of the hull to the other.\" Tacking rigs are similar to those seen in most parts of the world, but shunting rigs change tack by reversing the sail from one end of the hull to the other and sailing in the opposite direction (the \"Pushmi-pullyu\" of the sailing world).\n\nThe Solomon Islanders have used and continue to use dugout canoes to travel between islands. In World War II these were used during the Japanese occupation - with their small visual and noise signatures these were among the smallest boats used by the Allied forces in World War II. After the sinking of PT-109, Biuku Gasa reached the shipwrecked John F. Kennedy by dugout.\n\n\n"}
{"id": "39176314", "url": "https://en.wikipedia.org/wiki?curid=39176314", "title": "Elias Gyftopoulos", "text": "Elias Gyftopoulos\n\nElias Panayiotis Gyftopoulos (; July 4, 1927June 23, 2012) was a Greek-American engineer who contributed to thermodynamics both in its general formulation and its quantum foundations.\n\nGyftopoulos received an undergraduate degree in mechanical and electrical engineering in 1953 from the National Technical University of Athens, and a Doctor of Science degree in electrical engineering at the Massachusetts Institute of Technology in 1958. At MIT, he initially focused on nuclear reactor safety and control. After meeting professors George N. Hatsopoulos and Joseph H. Keenan, his interests moved towards thermodynamics, in an attempt to give a consistent and rigorous exposition, free of the logical flaws and the limitations commonly associated with this discipline: the result was a non-statistical theory, applicable to both macroscopic and microscopic systems, both in equilibrium and in non-equilibrium. His research culminated in the effort to give a quantum basis to thermodynamics with a physical theory unifying mechanics and Thermodynamics.\n\n"}
{"id": "33334880", "url": "https://en.wikipedia.org/wiki?curid=33334880", "title": "Energy in Bahrain", "text": "Energy in Bahrain\n\nEnergy in Bahrain describes energy and electricity production, consumption and import in Bahrain. Baharain is net energy exporter.\n\nPrimary energy use was in Bahrain in 2009 110 TWh and 139 TWh per million persons and in 2008 107 TWh and 139 TWh/million people.\n\nBahrain was the first place on the Arabian side of the Persian Gulf where oil was discovered. The First Oil Well, Bahrain situated below Jebel Dukhan has operated since 1932. It was operated by Bahrain Petroleum Company.\n\nBahrain Petroleum Company (BAPCO) wholly owned by the government of Bahrain, is a fully integrated oil company.\n\nBanagas is a large natural gas company.\n\n"}
{"id": "1917342", "url": "https://en.wikipedia.org/wiki?curid=1917342", "title": "Gelcoat", "text": "Gelcoat\n\nGelcoat or 'Gel Coat' is a material used to provide a high-quality finish on the visible surface of a fibre-reinforced composite. The most common gelcoats are thermosetting polymers based on epoxy or unsaturated polyester resin chemistry. Gelcoats are modified resins which are applied to moulds in the liquid state. They are cured to form crosslinked polymers and are subsequently backed with thermoset polymer matrix composites which are often mixtures of polyester resin and fiberglass, or epoxy resin which is most commonly used with carbon fibre for higher specific strength. \n\nThe manufactured component, when sufficiently cured and removed from the mould, presents the gelcoated surface. This is usually pigmented to provide a coloured, glossy surface which improves the aesthetic appearance of the article, such as the surface of a boat hull. \n\nMany marine craft and some aircraft are manufactured using composite materials with an outer layer of gelcoat, typically 0.5 mm to 0.8 mm (0.02 in to 0.03 in) thick. Gelcoats are designed to be durable, providing resistance to ultraviolet degradation and hydrolysis. \n\nSpecialized gelcoats can be used to manufacture the moulds which in turn are used to manufacture components. These require very high levels of durability to overcome the mechanical and thermal stresses encountered during the curing and demoulding processes. \n\nSuitable resin chemistries for the manufacture of gelcoats vary, but the most commonly encountered are unsaturated polyesters or epoxies. Within each of these categories, the resin chemistries are further subdivided.\n\nIn addition to any pigment a gelcoat will, if necessary, contain a thixotropic additive to assist its tenacity to vertical portions of the mould whilst it cures.\n"}
{"id": "45382676", "url": "https://en.wikipedia.org/wiki?curid=45382676", "title": "HVDC SylWin1", "text": "HVDC SylWin1\n\nHVDC SylWin1 is a high voltage direct current (HVDC) link under construction to transmit Offshore wind power to the power grid of the German mainland. The project differs from most HVDC systems in that one of the two converter stations is built on a platform in the sea. Voltage-Sourced Converters with DC ratings of 864 MW, ±320 kV are used and the total cable length is 205 km. The project is similar to the HVDC BorWin2 project but has slightly higher power and voltage ratings. It is being built by the Siemens/ Prysmian consortium and was handed over to its owner, TenneT, in April 2015.\n\n\n"}
{"id": "5297589", "url": "https://en.wikipedia.org/wiki?curid=5297589", "title": "Halpin–Tsai model", "text": "Halpin–Tsai model\n\nHalpin–Tsai model is a mathematical model for the prediction of elasticity of composite material based on the geometry and orientation of the filler and the elastic properties of the filler and matrix. The model is based on the self-consistent field method although often consider to be empirical.\n\n\n"}
{"id": "5484721", "url": "https://en.wikipedia.org/wiki?curid=5484721", "title": "Handcycle", "text": "Handcycle\n\nA handcycle is a type of human-powered land vehicle powered by the arms rather than the legs, as on a bicycle. Most handcycles are tricycle in form, with two coasting rear wheels and one steerable powered front wheel. Despite usually having three wheels, they are also known as \"handbikes\".\n\nMany manufacturers have designed and released hand-powered recumbent trikes, or handcycles. Handcycles are a regular sight at HPV meets and are beginning to be seen on the streets. They commonly follow a delta design with front wheels driven by standard derailleur gearing powered by hand cranks. Brake levers are usually mounted on the handholds which are usually mounted in phase, unlike pedal cranks, which are usually 180° out of phase. This allows the rider to more easily use their torso to help propel the cycle. The entire crank assembly and the front wheel turn together, allowing the rider to steer and crank simultaneously.\n\nSome designs use two front wheels and a single rear wheel, while others use lean-steer designs.\n\nA handcycle is not a wheelchair, handcycle has a crank and gears, while a wheelchair has push-rims directly on the main wheels.\n\nHandcycles come in a variety of styles, making them accessible to people with a wide variety of disabilities. There are also hybrids between a handcycle, a recumbent bike and a tricycle.\n\nFork steer handcycles represent the majority of handcycles sold. They work well for both low and high-level spinal injuries, and most have adjustable footrests, seat angle, and come with a variety of gearing, wheel and tire configurations depending on intended use: racing, recreation, or touring. Manufacturers of this type of handcycle include Invacare (Top End), Intrepid Equipment, Varna, Schmicking and Sunrise Medical (Quickie).\n\nRiders turn lean steer handcycles by leaning into the turn. There is a longer learning curve with lean steer handcycles and they are significantly less stable at high speed. The lean steer system feels similar to mono skiing: using your whole body to steer the handcycle. Lean steer handcycles can work well for lower-level injuries; although, some athletes with high-level disability use them as well. Manufacturers of this type of handcycle include Lighting Handcycles and Brike International Ltd. (Freedom Ryder).\n\nAnother type of lean steer hand trike has two steering rear wheels and one non-steerable, powered front wheel with handholds offset at 180°, similar to pedal cranks, that can be operated with only one hand, thus making it easy to ride on an up-hill, and it can be ridden in a tighter curve with the automatic rear wheels steering system.\n\nThe off-road is different from other handcycles in that there are two wheels in front and one behind, and it has a lower gear ratio range. This gives the cycle the ability to tackle steep slopes and permits handcycle mountain biking. The addition of a wider tire with suitable tread makes some mountain biking possible on standard road bikes.\n\nHandcycles have also been used for touring, and to better accommodate this interest, some manufacturers incorporate mudguards and pannier cargo racks. As handcycles have evolved they have become progressively lighter, and they have better gearing for long climbs and long distance touring.\n\n"}
{"id": "47297119", "url": "https://en.wikipedia.org/wiki?curid=47297119", "title": "Hypatia (stone)", "text": "Hypatia (stone)\n\nHypatia is a small stone, thought to be the first known specimen of a comet nucleus.\n\nHypatia was discovered in December 1996 by Aly A. Barakat at , in the same area where Libyan desert glass is found.\n\nThe rock has been named after Hypatia of Alexandria ( 350–370 AD – 415 AD) – the outstanding philosopher, astronomer, mathematician, and inventor.\n\nTests done in South Africa show that Hypatia contains microscopic diamonds and that it is of extraterrestrial origin. It is thought to have been part of the body whose impact caused the creation of Libyan desert glass. It probably fell to Earth about 28 million years ago. It has a very unusual chemical composition, parts of it could be older than the solar system.\n\nIn 2018 Georgy Belyanin of the university of Johannesburg and colleages have found compounds including polyaromatic hydrocarbons and silicon carbide associated with a nickel phosphide compound not found in the solar system before. Other facts supporting the otherworldly origin of the stone include ratios of silicon to carbon opposite to those of Earth, Mars or Venus, but consistent with interstellar dust.\n\n"}
{"id": "14948458", "url": "https://en.wikipedia.org/wiki?curid=14948458", "title": "IEC 60038", "text": "IEC 60038\n\nInternational Standard IEC 60038:1983 defines a set of standard voltages for use in low voltage and high voltage AC electricity supply systems.\n\nWhere two voltages are given below separated by \"/\", the first is the root-mean-square voltage between a phase and the neutral connector, whereas the second is the corresponding root-mean-square voltage between two phases (exception: the category shown below called \"One Phase\", where 240 V is the root-mean-square voltage between the two legs of a split phase). The three-phase voltages are for use in either four-wire (with neutral) or three-wire (without neutral) systems.\n\n\nSuppliers using 220 V / 380 V or 240 V / 415 V systems were expected by the standard to migrate to the recommended value of 230 V / 400 V by the year 2003. This migration has already been largely completed, at least within the European Union.\n\n\n\nTable 3 of IEC 60038 lists nominal voltages above 1 kV and not exceeding 35 kV. There are two series, one from 3 kV up to 35 kV and another one from 4.16 kV up to 34.5 kV.\n\nTable 4 shows nominal voltages above 35 kV and not exceeding 230 kV.\n\nTable 5 is systematically different, as the highest voltage for equipment is the characteristic value exceeding 245 kV. The enumeration begins at 300 kV and ends with 1200 kV.\n\n\n"}
{"id": "14954531", "url": "https://en.wikipedia.org/wiki?curid=14954531", "title": "Ian Angus (activist)", "text": "Ian Angus (activist)\n\nIan Angus (born 1945) is a Canadian ecosocialist activist. Angus joined the New Democratic Party (NDP) in 1962 and then the Young Socialists (YS) in Ottawa in 1964. He was active in the YS and the League for Socialist Action into the 1970s. Angus participated in the formation of the Canadian Trostkyist party Revolutionary Workers League (RWL; fusion of the LSA with the Revolutionary Marxist Group and Groupe Marxiste Revolutionaire) in 1977. He left the RWL in 1980, and has been an independent Marxist writer, educator, and activist since.\n\nAngus is the editor of \"Climate and Capitalism\". He founded and edited the \"Socialist History Project\" and was an editor of \"Socialist Voice\". He was a founding member and Coordinating Committee Member of \"Ecosocialist International Network.\" He was a member of the \"Canadian Dimension\" editorial collective and an advisory editor of \"Socialist Resistance\". In 2007 he was a co-founder of the Ecosocialist International Network; in 2008 he was co-author of the EIN's \"Belem Ecosocialist Declaration\". In addition to authoring several articles in \"Climate and Capitalism\" and numerous contributions to \"Monthly Review\", Angus has written articles for \"New Scientist\" and \"International Socialism\", and has authored three books, co-authored one (with Simon Butler, co-editor of \"Green Left Weekly\", and edited another (see below).\n\n\n"}
{"id": "30973647", "url": "https://en.wikipedia.org/wiki?curid=30973647", "title": "Infinite Wind Energy", "text": "Infinite Wind Energy\n\nInfinite Wind Energy, LLC (IWE) is a small wind turbine company located in Northern New Jersey. The company makes proprietary wind turbines which are powered with counter-rotating blades that use 2 blades on each side that counter-rotate. The technology was awarded as the \"Best Green Company\" at the NJTC conference of 2010.\n\n"}
{"id": "35069600", "url": "https://en.wikipedia.org/wiki?curid=35069600", "title": "International Convention Relating to Intervention on the High Seas in Cases of Oil Pollution Casualties", "text": "International Convention Relating to Intervention on the High Seas in Cases of Oil Pollution Casualties\n\nInternational Convention Relating to Intervention on the High Seas in Cases of Oil Pollution Casualties 1969 (INTERVENTION 1969) is an international maritime convention affirming the right of a coastal State to \"take such measures on the high seas as may be necessary to prevent, mitigate or eliminate grave and imminent danger to their coastline or related interests from pollution or threat of pollution of the sea by oil, following upon a maritime casualty or acts related to such a casualty\".\n\nThe 1967 Torrey Canyon disaster when the oil spilled from the tanker severely damaged coastal and marine environment and wildlife of the coastal State signalled a need to empower coastal State to take necessary measures to protect itself from pollution incidents outside this State's territory, i.e. on the high seas. In doing so, it was also deemed necessary to protect the legitimate interests of ship-owners, cargo owners and the flag States and the principle of the freedom of the high seas.\n\nThe new Convention was drafted within the framework of the International Maritime Organization (IMO) and adopted at the international conference in Brussels, Belgium in 1969 entering into force in 1975. In 1973 the Protocol relating to Intervention on the High Seas in Cases of Marine Pollution by Substances other than Oil was adopted extending the provision of the 1969 Convention to other hazardous substances. The list of hazardous substances covered by Protocol was amended and extended in 1991, 1996 and 2002.\n\nAs of October 2016, the convention has 89 state parties.\n\nThe Convention applies to all seagoing vessels except warships or other vessels owned or operated by a State and used on Government non-commercial service.\n\nWhile exercising the right to take measures \"necessary to prevent, mitigate or eliminate grave and imminent danger to their coastline or related interests\" from oil pollution, the coastal State is obligated to:\n\n\n\n"}
{"id": "43371430", "url": "https://en.wikipedia.org/wiki?curid=43371430", "title": "Kand Dam", "text": "Kand Dam\n\nKand Dam is small earth core rock-fill dam under construction in North Waziristan Agency of FATA, Pakistan.\n\nThe construction of dam started in 2011 and was expected to be complete by September 2014 with projected cost of PKR 198.145 Million. Due to military operations, construction of the dam was suspended in June 2014 at 86% progress. The dam has a height of and a length of . If completed, the dam would irrigate of land, with a total water storage capacity of , and a catchment area of .\n\n"}
{"id": "6366835", "url": "https://en.wikipedia.org/wiki?curid=6366835", "title": "Landfill mining", "text": "Landfill mining\n\nLandfill mining and reclamation (LFMR) is a process whereby solid wastes \nwhich have previously been landfilled are excavated and processed. The function of landfill mining is to reduce the amount of landfill mass encapsulated within the closed landfill and/or temporarily remove hazardous material to allow protective measures to be taken before the landfill mass is replaced. In the process, mining recovers valuable recyclable materials, a combustible fraction, soil, and landfill space. The aeration of the landfill soil is a secondary benefit regarding the landfill's future use. The combustible fraction is useful for the generation of power. The overall appearance of the landfill mining procedure is a sequence of processing machines laid out in a functional conveyor system. The operating principle is to excavate, sieve and sort the landfill material.\n\nThe concept of mining was introduced as early as 1953 at the Hiriya landfill operated by the Dan Region Authority next to the city of Tel Aviv, Israel. Waste contains many resources with high value, the most notable of which are non-ferrous metals such as aluminium cans and scrap metal. The concentration of aluminium in many landfills is higher than the concentration of aluminum in bauxite from which the metal is derived.\n\nLandfill mining is also possible in countries where land is not available for new landfill sites. In this instance landfill space can be reclaimed by the extraction of biodegradable waste and other substances then refilled with wastes requiring disposal.\n\nMining construction landfill sites is the simplest form of landfill mining. Construction landfills in the United States contain three basic components, wood, scrap metal and gypsum, or drywall, along with a minimal amount of other construction materials. The wood collected can be used as fuel in coal burning power plants and the scrap metal reprocessed. European landfills tend to have more masonry from demolished bricks, tiles and concrete.\n\nMining of municipal landfills is more complicated and has to be based on the expected content of the landfill. Older landfills, in the United States before 1994, were often capped and closed, essentially entombing the waste. This can be beneficial for waste recovery. It can also create a higher risk for toxic waste and leachate exposure as the landfill has not fully processed the stewing wastes. Mining of bioreactor landfills and properly stabilized modern sanitary landfills provides its own benefits. The biodegradable wastes are more easily sieved out, leaving the non-biodegradable materials readily accessible. The quality of these materials for recycling and reprocessing purposes is not as high as initially recycled materials, however materials such as aluminum and steel are usually excluded from this. \nLandfill mining is most useful as a method to remediate hazardous landfills. Landfills that were established before landfill liner technology was well established often leak their unprocessed leachate into underlying aquifers. This is both an environmental hazard and also a legal liability. In the US, the Environmental Protection Agency requires closed landfills to be monitored for at least 30 years after waste placement ceases. Mining the landfill simply to lay a safe liner is a last, but sometimes necessary resort.\n\nThe parts of the mining process are the different mining machines. Depending on the complexity of the process more or fewer machines can be used. Machinery is easily transported on trucks from site to site, mounted on trailers.\n\nAn excavator or front end loader uncovers the landfilled materials and places them on a moving floor conveyor belt to be taken to the sorting machinery. A trommel is used to separate materials by size. First, a large trommel separates materials like appliances and fabrics. A smaller trommel then allows the biodegraded soil fraction to pass through leaving non-biodegradable, recyclable materials on the screen to be collected. \n\nAn electromagnet is used to remove the ferrous material from the waste mass as it passes along the conveyor belt.\n\nA front end loader is used to move sorted materials to trucks for further processing.\n\nOdor control sprayers are wheeled tractors with a cab and movable spray arm mounted on a rotating platform. A large reservoir tank mounted behind the cab holds neutralizing agents, usually in liquid form, to reduce the smell of exposed wastes.\n\nDepending on the level of resource recovery, material can be put through an air classifier which separates light organic material from heavy organic material. The separate streams are then loaded, by front end loaders, onto trucks either for further processing or for sale. Further manual processing can be done on site if processing facilities are too far away to justify the transportation costs.\n\n"}
{"id": "11522746", "url": "https://en.wikipedia.org/wiki?curid=11522746", "title": "List of late spring flowers", "text": "List of late spring flowers\n\nThese flowers come into bloom in late Spring season:\n\n"}
{"id": "36837622", "url": "https://en.wikipedia.org/wiki?curid=36837622", "title": "Marcy South", "text": "Marcy South\n\nMarcy South is a high voltage power line in New York that runs from Fraser Substation in Delaware County to Marcy Substation in Oneida County. It was constructed amid heavy controversy in the late 1980s by the Power Authority of the State of New York.\n\nThe Power Authority of the State of New York announced plans to deliver hydroelectric power from Canada to the New York City region in 1982.\n\nIt became fully operational on June 1, 1988.\n\nThe power line met with vigorous and sometimes highly contentious and violent opposition from local property owners from its proposition to its planning and surveying, and even its construction\n\nThe project began in 2016 and involved the installation of three capacitor banks. The capacitor banks were installed to raise the voltage and keep it constant, which enhances transmission efficiency. Two capacitor banks were installed by New York Power Authority, the other installed by NYSEG at the Fraser Substation.\n\nSince its construction, other projects including a high-voltage DC line have been proposed for the same route.\n"}
{"id": "276741", "url": "https://en.wikipedia.org/wiki?curid=276741", "title": "Medium-density fibreboard", "text": "Medium-density fibreboard\n\nMedium-density fibreboard (MDF) is an engineered wood product made by breaking down hardwood or softwood residuals into wood fibres, often in a defibrator, combining it with wax and a resin binder, and forming panels by applying high temperature and pressure. MDF is generally denser than plywood. It is made up of separated fibres, but can be used as a building material similar in application to plywood. It is stronger and much denser than particle board.\n\nThe name derives from the distinction in densities of fibreboard. Large-scale production of MDF began in the 1980s, in both North America and Europe.\n\nOver time, the term \"MDF\" has become a generic name for any dry process fibre board. MDF is typically made up of 82% wood fibre, 9% urea-formaldehyde resin glue, 8% water and 1% paraffin wax. and the density is typically between 500 kg/m (31 lb/ft) and 1,000 kg/m (62 lb/ft). The range of density and classification as \"light\", \"standard\", or \"high\" density board is a misnomer and confusing. The density of the board, when evaluated in relation to the density of the fibre that goes into making the panel, is important. A thick MDF panel at a density of 700–720 kg/m may be considered as high density in the case of softwood fibre panels, whereas a panel of the same density made of hard wood fibres is not regarded as so. The evolution of the various types of MDF has been driven by differing need for specific applications.\n\nThere are different kinds of MDF (sometimes labeled by colour):\n\nAlthough similar manufacturing processes are used in making all types of fibreboard, MDF has a typical density of 600–800 kg/m³ or 0.022–0.029 lb/in, in contrast to particle board (160–450 kg/m³) and to high-density fibreboard (600–1,450 kg/m³).\n\nIn Australia and New Zealand, the main species of tree used for MDF is plantation-grown radiata pine; but a variety of other products have also been used, including other woods, waste paper and fibres. Where moisture resistance is desired, a proportion of eucalypt species may be used, making use of the endemic oil content of such trees.\n\nThe trees are debarked after being cut. The bark can be sold for use in landscaping, or burned in on-site furnaces. The debarked logs are sent to the MDF plant, where they go through the chipping process. A typical disk chipper contains 4–16 blades. Any resulting chips that are too large may be re-chipped; undersized chips may be used as fuel. The chips are then washed and checked for defects. Chips may be stored in bulk, as a reserve for manufacturing.\n\nCompared to other fibre boards, such as Masonite, MDF is characterised by the next part of the process, and how the fibres are processed as individual, but intact, fibres and vessels, manufactured through a dry process. The chips are then compacted into small plugs using a screw feeder, heated for 30–120 seconds to soften the lignin in the wood, then fed into a defibrator. A typical defibrator comprises two counter-rotating discs with grooves in their faces. Chips are fed into the centre and are fed outwards between the discs by centrifugal force. The decreasing size of the grooves gradually separates the fibres, aided by the softened lignin between them.\n\nFrom the defibrator, the pulp enters a 'blowline', a distinctive part of the MDF process. This is an expanding circular pipeline, initially 40 mm in diameter, increasing to 1500 mm. Wax is injected in the first stage, which coats the fibres and is distributed evenly by the turbulent movement of the fibres. A urea-formaldehyde resin is then injected as the main bonding agent. The wax improves moisture resistance and the resin initially helps reduce clumping. The material dries quickly in the final heated expansion chamber of the blowline and expands into a fine, fluffy and lightweight fibre. This fibre may be used immediately, or stored.\n\nDry fibre gets sucked into the top of a 'pendistor', which evenly distributes fibre into a uniform mat below it, usually of 230–610 mm thickness. The mat is pre-compressed and either sent straight to a continuous hot press or cut into large sheets for a multi-opening hot press. The hot press activates the bonding resin and sets the strength and density profile. The pressing cycle operates in stages, with the mat thickness being first compressed to around 1.5× the finished board thickness, then compressed further in stages and held for a short period. This gives a board profile with zones of increased density, thus mechanical strength, near the two faces of the board and a less dense core.\n\nAfter pressing, MDF is cooled in a star dryer or cooling carousel, trimmed and sanded. In certain applications, boards are also laminated for extra strength.\n\nThe environmental impact of MDF has greatly improved over the years. Today, many MDF boards are made from a variety of materials. These include other woods, scrap, recycled paper, bamboo, carbon fibres and polymers, forest thinnings and sawmill off-cuts.\n\nAs manufacturers are being pressured to come up with greener products, they have started testing and using non-toxic binders. New raw materials are being introduced. Straw and bamboo are becoming popular fibres because they are a fast-growing renewable resource.\n\nMDF does not contain knots or rings, making it more uniform than natural woods during cutting and in service. However, MDF is not entirely isotropic, since the fibres are pressed tightly together through the sheet. Typical MDF has a hard, flat, smooth surface that makes it ideal for veneering, as there is no underlying grain to telegraph through the thin veneer as with plywood. A so-called \"Premium\" MDF is available that features more uniform density throughout the thickness of the panel.\n\nMDF may be glued, doweled or laminated. Typical fasteners are T-nuts and pan-head machine screws. Smooth-shank nails do not hold well, and neither do fine-pitch screws, especially in the edge. Special screws are available with a coarse thread pitch, but sheet-metal screws also work well. MDF isn't susceptible to splitting when screws are installed in the face of the material but, due to the alignment of the wood fibres, may split when screws are installed in the edge of the board without pilot holes.\n\n\n\nMDF is often used in school projects because of its flexibility.\nSlatwall Panels made from MDF are used in the shop fitting industry.\nMDF is primarily used for internal use applications due to its poor moisture resistance. it is available in raw form with fine sanded surface or with decorative overlay.\n\nMDF is also usable for furniture such as cabinets, because of its strong surface.\n\nWhen MDF is cut, a large quantity of dust particles are released into the air. It's important a respirator is worn and that the material is cut in a controlled and ventilated environment. It's good practice to seal exposed edges to limit emissions from binders contained in this material.\n\nFormaldehyde resins are commonly used to bind together the fibres in MDF, and testing has consistently revealed that MDF products emit free formaldehyde and other volatile organic compounds that pose health risks at concentrations considered unsafe, for at least several months after manufacture. Urea-formaldehyde is always being slowly released from the edges and surface of MDF. When painting, it is a good idea to coat all sides of the finished piece in order to seal in the free formaldehyde. Wax and oil finishes may be used as finishes but they are less effective at sealing in the free formaldehyde.\n\nWhether these constant emissions of formaldehyde reach harmful levels in real-world environments is not yet fully determined. The primary concern is for the industries using formaldehyde. As far back as 1987, the U.S. EPA classified it as a \"probable human carcinogen\" and, after more studies, the WHO International Agency for Research on Cancer (IARC), in 1995, also classified it as a \"probable human carcinogen\". Further information and evaluation of all known data led the IARC to reclassify formaldehyde as a \"known human carcinogen\" associated with nasal sinus cancer and nasopharyngeal cancer, and possibly with leukaemia in June 2004.\n\nAccording to International Composite Board Emission Standards (ICBES), there are 3 European formaldehyde classes, namely: E0, E1 and E2. This classification is based on the measurement of formaldehyde emission levels. For instance, E0 is classified as having less than 3 milligrams of formaldehyde out of every 100 grams of the glue used in particleboard and plywood fabrication. E1 and E2, conversely, are classified as having 9 and 30 grams of formaldehyde per 100 grams of glue respectively. All around the world variable certification and labeling schemes are there for such products that can be explicit to formaldehyde release, like that of Californian Air Resources Board (CARB).\n\nVeneered MDF provides many of the advantages of MDF with a decorative wood veneer surface layer. In modern construction, spurred by the high costs of hardwoods, manufacturers have been adopting this approach to achieve a high quality finishing wrap covering over a standard MDF board. One common type uses oak veneer. Making veneered MDF is a complex procedure, which involves taking an extremely thin slice of hardwood (approx 1-2mm thick) and then through high pressure and stretching methods wrapping them around the profiled MDF boards. This is only possible with very simple profiles because otherwise when the thin wood layer has dried out, it will break at the point of bends and angles.\n\n\n\n"}
{"id": "7724562", "url": "https://en.wikipedia.org/wiki?curid=7724562", "title": "Nuna 3", "text": "Nuna 3\n\nThe Nuna 3 is a solar car developed by Nuon Solar Team form the Delft University of Technology in 2004-2005 for the 2005 World Solar Challenge.\n\nIt succeeded the Nuna2, the solar car that scored a second consecutive win for this solar team by winning the World Solar Challenge for the third time in a row.\n\nNuna 3 was one of the favourites for the 2005 edition of the World Solar Challenge with a pre-race test-drive recorded top speed of 130 km/h. The final result was that the 3021 kilometers between Darwin and Adelaide were covered in a record 29 hours and 11 minutes, averaging about 103 km/h.\n\nIt has very efficient solar cells of a type normally used to power orbital satellites (as had the previous Nunas), and it has better aerodynamics and is lighter than its predecessors.\n\nIt was designed and built by 11 students from different disciplines of the Delft University of Technology, who have partly put their studies on hold for this. They used the hightech labs and workshops of the University and, as with the Nuna 2, they received advice from Wubbo Ockels, the first Dutch astronaut and professor at the University.\n\nTo have a good chance to win, the car has to:\n\nThe solar cells are made of gallium arsenide (GaAs) and consist of three layers. Sunlight that penetrates the upper layer is used in the lower layers, resulting in an efficiency of over 26%. This type of solar cell is among the best available currently. Apart from efficiency, size also matters, so the entire upper surface of the Nuna 3 is covered with them, except for the cockpit.\n\nEfficiency is optimal when the cells are hit by the solar rays perpendicularly. If not, output is reduced by roughly the cosine of the angle with the perpendicular. Because the 2005 race was held in September (as opposed to October or November in previous years) the sun was lower in the sky (it's earlier in spring). To compensate for this, as many cells as possible were placed at the sides, most notably on the wheel caps.\nA solar cell gives a certain amount of current for a certain amount of sunlight. The voltage depends on the load (more precisely the resistance of the load). The power is the product of voltage and current and therefore also depends on the load. Over a certain voltage the current of the solar cell quickly drops to zero, as the graph illustrates.\n\nHowever, the batteries have a fairly constant voltage, which also has a rather different value than that of the solar cells. So a voltage transformation is needed. A special type of DC-DC converter is used to ensure the load resistance presented to the solar cells is such that the solar cells give maximum power, so also at the top of the green line in the graph. This is called a Maximum power point tracker (MPPT). Here too, the goal is to have this conversion achieve maximum efficiency (>97%).\n\nThe aerodynamic drag is an important part of the total resistance. Important are the frontal surface and the streamline. Any deviation from the ideal streamline will cause turbulence, which costs energy. The ideal streamline is achieved in various stages:\nFrom meteorological data from the area where the contest is to take place, it can be concluded that there will likely be a strong side-wind. The wheel caps of the Nuna 3 are designed such that a sidewind will have a propulsory effect.\n\nThe electromotor is totally encased in the rear wheel to minimise loss through mechanical transmission from motor to wheel (such as in a normal car in the gear box and cardan). The motor is an improved version of the original 1993 Motor of the Spirit of Biel III by the Engineering School of Biel, Switzerland (now: Berner Fachhochschule Technik und Informatik). The improvements are due to completely redeveloped digital power electronics and control, realized 1999. They allowed for 50% more power (over 2400 W) and a 45% higher torque compared to the 1993 Spirit of Biel II. The efficiency of the total drive system (including the power electronics losses) is also improved and is now over 98%. But as the graph shows this depends somewhat on the speed and increases with speed. The design was initially made to reach its maximum performance at the normal cruising speed of the solar car at around 100 km/h.\n\nDuring one of the test drives in the Netherlands the Nuna 3 achieved a speed of 130 km/h. On the first day of the race the car achieved a top speed of 140 km/h. For comparison, the Sunraycer (the first winner of the Solar Challenge race) attained a top speed of 109 km/h in 1987.\n\nThe winner of the North American Solar Challenge from the University of Michigan (USA) was considered to be one of the most important opponents. Other important contestants were the MIT (also USA) and the Japanese Ashiya University team. In 2005 there were also two other European contestants, the Dutch Raedthuys Solar Team from the University of Twente and the Belgian Umicore Solar Team from Leuven.\n\n\nThis average speed, which could lead to maximum speeds of 140 km/h speeds on downhill section, well exceeding speed limits on the Australian highway, has led to rules changes for future races.\n\n"}
{"id": "1100862", "url": "https://en.wikipedia.org/wiki?curid=1100862", "title": "Ontario Energy Board", "text": "Ontario Energy Board\n\nThe Ontario Energy Board () regulates natural gas and electricity utilities in the province of Ontario, Canada. This includes setting rates, and licensing all participants in the electricity sector including the Independent Electricity System Operator (IESO), generators, transmitters, distributors, wholesalers and electricity retailers, as well as natural gas marketers who sell to low volume customers.\n\nTo ensure an adequate level of consumer protection in the energy markets, the Board developed codes of conduct for gas marketers and electricity retailers, and established a complaint resolution process for energy consumers. The Board also provides a broad range of information to energy consumers about electricity and natural gas in Ontario.\n\nThe Board oversees the electricity market and ensures regulated gas and electricity monopoly utilities comply with Board decisions and orders. This includes conducting audits, performing compliance monitoring activities and monitoring various aspects of the gas and electricity utilities’ financial operating performance.\n\nIn the electricity sector, the Board sets transmission and distribution rates, and approves the IESO's budget and fees. The Board also sets the regulated price of electricity for residential and small business consumers on the Regulated Price Plan. Consumers who have signed contracts with an electricity retailer will pay the price set out in their contract.\nThe Board licenses all electricity retailers who sell electricity to residential and small commercial consumers.\n\nBoard approval is required prior for: \n\nThe Board also monitors markets in the electricity sector and reports to the Minister of Energy and Infrastructure on the efficiency, fairness, transparency and competitiveness of the markets, and reports any abuse or potential abuse of market power. The Board may also be asked to review the IESO market rules and consider appeals of IESO orders.\n\nIn the natural gas sector, utilities are required to submit the rates they propose to charge their customers to the Board for review. The Board approves rates associated with the cost to transport, store and distribute natural gas from utilities to consumers as well as charges to administer natural gas accounts. The Board also approves the price utilities can charge consumers for the natural gas they use. Natural gas utilities do not make a profit on the sale of natural gas. It is sold to consumers with no mark-up. Consumers who have signed contracts with a natural gas marketer will pay the price set out in their contract.\n\nThe Board licenses all natural gas marketers who sell natural gas to residential and small commercial consumers.\n\nThe Board is required to determine if constructing a natural gas pipeline is in the public interest by considering need, safety, economic feasibility, community benefits, security of supply and environmental impacts. Each municipality may grant a gas utility the right to deliver gas service and use road allowances or utility easements within its borders. The specific terms and conditions of these franchise agreements between the municipality and the utility are subject to Board approval.\n\nThe Board also reviews applications by gas distributors to create and operate underground gas storage areas and designates geological formations suitable to store natural gas in Ontario. \nBoard approval is also required before a natural gas utility can sell its distribution system or amalgamate with another distributor.\n\nThere are currently two default service providers of natural gas in Ontario, Enbridge and Union Gas. These two entities are regulated by the Board.\nThe Board does not regulate competitive services in the natural gas sector. These include the sale of natural gas, water heater rentals and repair or maintenance services. These products and services are competitive services and can be obtained from various companies.\n\n\n"}
{"id": "3216057", "url": "https://en.wikipedia.org/wiki?curid=3216057", "title": "Pellet stove", "text": "Pellet stove\n\nA pellet stove is a stove that burns compressed wood or biomass pellets to create a source of heat for residential and sometimes industrial spaces. By steadily feeding fuel from a storage container (hopper) into a burn pot area, it produces a constant flame that requires little to no physical adjustments. Today's central heating systems operated with wood pellets as a renewable energy source can reach an efficiency factor of more than 90%. \n\nScrap wood and ship-lap burners have been around since at least the early 20th century easily seen in the use of barrel stoves, braziers, and oil drum fires in depression-era Hooverville historical media. Professionally built wood-fired ovens with sawdust hoppers were used in the early part of the 20th century. All of these units used scrap wood or sawdust. In 1930, the Presto-Log was invented reusing scrap sawdust from the Potlatch pine mill in Lewiston, Idaho for domestic heat. From this came the miniaturized pellet stove, which emerged from Washington State in the 1980s.\n\nThe pellet stove changed in appearance over the years from a simple, boxy workhorse design, to a modern heating appliance. Pellet stoves can be either free standing units or fireplace inserts vented into an existing chimney. Most pellet stoves are constructed using large, heat conductive, steel or cast-iron pieces, with stainless steel to encase circuitry and exhaust areas.\n\nPellet furnaces and pellet boilers are also available in addition to the decorative stove. These units can be retrofitted into existing home heating systems with only minor changes to existing ductwork and or plumbing.\n\nThe heating industry has considerably shifted toward biomass stoves and heating devices based on efficient combustible and renewable resources. This was a trend that began with the 1973 oil crisis causing the creation of the first pellet stoves. Even so, pellet stoves have become a viable, economical, and popular option for home heating systems only in the last ten years. Between 1998 and 2010, 824,410 pellet stoves and fireplace inserts were made in the U.S..\n\nWhile some stoves are UL listed for fuels other than pellets, such as wheat, corn, sunflower seeds, and cherry pits, many pellet stove manufacturers recommend the use of a corn and pellet mixture.\n\nThe pellet fuel is delivered from the storage facility or the day tank (single stoves) into the combustion chamber. With the heat generated, circuit water is heated in the pellet boiler. In central heating systems the hot water then runs through the heating circuit. The heat distribution is the same as other central heating systems. Unlike oil or gas heating, the inclusion of a hot water reservoir is recommended with pellet heating systems to save hot water until it is needed.\n\nMost pellet stoves are self igniting and cycle themselves on and off under thermostatic control. Stoves with automatic ignition can be equipped with remote controls. Recent innovations include integrated microcontroller monitoring of various safety conditions and can run diagnostic tests if an imminent problem arises.\n\nA properly cleaned and maintained pellet stove should not create creosote, the sticky, flammable substance that causes chimney fires. Pellets burn very cleanly and create only a layer of fine fly ash as a byproduct of combustion. The grade of pellet fuel affects the performance and ash output. Premium grade pellets produce less than one percent ash content, while standard or low grade pellets produce up to six percent ash. Pellet stove users should be aware of the extra maintenance required with a lower grade pellet, and that inconsistent wood quality can cause serious effects to the electronic machinery over a short period of time.\n\nA pellet stove is normally associated with pelletized wood. However, many pellet stoves will also burn fuels such as grain, corn, seeds, or woodchips. In some pellet stoves, these fuels may need to be mixed with wood pellets. Pelletized trash (containing mostly waste paper) is also a fuel for pellet stoves.\n\nUnlike wood stoves which operate exclusively on a principle of chimney draft, a pellet stove must use specially sealed exhaust pipe to prevent exhaust gases escaping into the living space due to the air pressure produced by a combustion blower. Pellet stoves require certified double walled venting, normally three or four inches in diameter with a stainless steel interior and galvanized exterior. Because pellet stoves have a forced exhaust system, they have the advantage of not always requiring a vertical rise to vent, although a vertical run to induce some draft is recommended to prevent leakage in the case of a power outage. Like a modern gas appliance, pellet stoves can be vented horizontally through an outside wall and terminated below the roof line, making it an excellent choice for structures without an existing chimney. If an existing chimney is available, manufacturers urge use of a correctly sized stainless steel liner the length of the chimney for proper drafting. Modern building techniques have created tightly sealed homes, forcing many pellet stove manufacturers to recommend their stoves be installed with outside air intake to ensure the stoves will run efficiently and prevent potential negative pressure within the home.\n\nPellet stoves are approved for use in mobile homes, while standard wood burning stoves are not.\n\nIn many states pellet fuel is exempt from sales tax. \n\nUntil January 1, 2012, in most states in the U.S., a 75% efficient pellet stove was eligible for a tax credit up to 30% of the cost of the appliance as part of the 25C provision, plus labor.\n\nA pellet stove normally consists of these components, whether basic or complex:\n\n\nTo properly function, a pellet stove uses electricity and can be connected to a standard electrical outlet. A pellet stove, like an automatic coal stoker, is a consistent heater consuming fuel that is fed evenly from a refillable hopper into the burn pot (a perforated cast-iron or steel basin), through a motorized system. The most commonly used distributor is an auger system that consists of a spiral length of metal encased in a tube. This mechanism is either located above the burn pot or slightly beneath and guides a portion of pellet fuel from the hopper upwards until it falls into the burn pot for combustion.\n\nFan systems are necessary for clean, economical performance. The flame produced is concentrated and intense in the small area of the burn pot as a combustion blower introduces air into the bottom of the burn pot, while also forcing exhaust gases into the chimney. While some pellet stoves will be hot to the touch (especially on the viewing window), most manufacturers utilize a series of cast-iron or steel heat exchangers that run along the back and top areas of the visible firebox. With a convection blower, room air is circulated through the heat exchangers and directed into the living space. This method allows for a much higher efficiency than the radiant heat of a hand-fed wood or coal stove, and will in most cases cause the top, sides, and back of the stove to be at most warm to the touch. Along with convection air, an exhaust fan forces air from the firebox through special venting specifically made for pellet fuel. This cycle of circulation is an integral part of the combustion system as well, for the concentrated high temperature flame will quickly overheat the firebox. The possible problems associated with overheating are electrical component failure and flames traveling into the auger tube causing a hopper fire. As safeguards, all pellet stoves are equipped with heat sensors, and sometimes vacuum sensors, enabling the controller to shut down if an unsafe condition is detected. For daily maintenance, an ash vacuum is recommended. These are similar to shop vacs, but are designed for the removal of ash materials. These vacuums are available with a pellet stove kit which enables the cleaning of the interior areas of the stove which improves efficiency.\n\nPellet stoves can either be lit manually or through an automatic igniter. The igniter piece resembles a car's electric cigarette lighter heating coil. Most models have automatic ignition and can be readily equipped with thermostats or remote controls.\n\nA corn stove is designed for whole kernel shelled corn kernel combustion and is similar to a pellet stove. The chief difference between a pellet stove and a dedicated corn stove is the addition of metal stirring rod within the burnpot or an active ash removal system. These vary in design slightly, but usually consist of one long metal stalk with smaller rods welded at a perpendicular angle, in order to churn the burn pot as it spins. An active ash removal system consists of augers at the bottom of the burn pot that evacuate the ash and clinkers. During a normal burn cycle, the sugar content within corn (and other similar bio-fuels) will cause the ashes to stick together, forming a hard mass. The metal stirring rod breaks apart these masses, causing a much more consistent burn. While there is demand to create stoves that are able to burn multiple fuels with minimal adjustments, some pellet stoves are not designed to stir fuel and cannot burn corn fuel.\n\n"}
{"id": "39383383", "url": "https://en.wikipedia.org/wiki?curid=39383383", "title": "Polymer electrolyte membrane electrolysis", "text": "Polymer electrolyte membrane electrolysis\n\nProton exchange membrane (PEM) electrolysis is the electrolysis of water in a cell equipped with a solid polymer electrolyte (SPE) that is responsible for the conduction of protons, separation of product gases, and electrical insulation of the electrodes. The PEM electrolyzer was introduced to overcome the issues of partial load, low current density, and low pressure operation currently plaguing the alkaline electrolyzer.\n\nHowever, a recent scientific comparison showed that state-of-the-art alkaline water electrolysis shows competitive or even better efficiencies than PEM water electrolysis. This comparison moreover showed that many of the advantages such as gas purities or high current densities that were ascribed to PEM water electrolysis are also achievable by alkaline water electrolysis. Electrolysis is an important technology for the production of hydrogen to be used as an energy carrier.\n\nWith fast dynamic response times, large operational ranges, and high efficiencies, water electrolysis is a promising technology for energy storage coupled with renewable energy sources.\n\nThe use of a PEM for electrolysis was first introduced in the 1960s by General Electric, developed to overcome the drawbacks to the alkaline electrolysis technology. The initial performances yielded 1.88 V at 1.0 A/cm which was, compared to the alkaline electrolysis technology of that time, very efficient. In the late 1970s the alkaline electrolyzers were reporting performances around 2.06 V at 0.215 A/cm, thus prompting a sudden interest in the late 1970s and early 1980s in polymer electrolytes for water electrolysis.\n\nA thorough review of the historical performance from the early research to that of today can be found in chronological order with many of the operating conditions in the 2013 review by Carmo et al.\n\nOne of the largest advantages to PEM electrolysis is its ability to operate at high current densities. This can result in reduced operational costs, especially for systems coupled with very dynamic energy sources such as wind and solar, where sudden spikes in energy input would otherwise result in uncaptured energy. The polymer electrolyte allows the PEM electrolyzer to operate with a very thin membrane (~100-200 μm) while still allowing high pressures, resulting in low ohmic losses, primarily caused by the conduction of protons across the membrane (0.1 S/cm) and a compressed hydrogen output.\n\nThe polymer electrolyte membrane, due to its solid structure, exhibits a low gas crossover rate resulting in very high product gas purity. Maintaining a high gas purity is important for storage safety and for the direct usage in a fuel cell. The safety limits for H in O are at standard conditions 4 mol-% H in O.\n\nAn electrolyzer is an electrochemical device to convert electricity and water into hydrogen and oxygen, these gases can then be used as a means to store energy for later use. This use can range from electrical grid stabilization from dynamic electrical sources such as wind turbines and solar cells to localized hydrogen production as a fuel for fuel cell vehicles. The PEM electrolyzer utilizes a solid polymer electrolyte (SPE) to conduct protons from the anode to the cathode while insulating the electrodes electrically. Under standard conditions the enthalpy required for the formation of water is 285.9 kJ/mol. A portion of the required energy for a sustained electrolysis reaction is supplied by thermal energy and the remainder is supplied through electrical energy.\n\nThe actual value for open circuit voltage of an operating electrolyzer will lie between the 1.23 V and 1.48 V depending how the cell/stack design utilizes the thermal energy inputs. This is however quite difficult to determine or measure because an operating electrolyzer also experiences other voltage losses from internal electrical resistances, proton conductivity, mass transport through the cell and catalyst utilization to name a few.\n\nThe half reaction taking place on the anode side of a PEM electrolyzer is commonly referred to as the Oxygen Evolution Reaction (OER). Here the liquid water reactant is supplied to catalyst where the supplied water is oxidized to oxygen, protons and electrons.\n\nThe half reaction taking place on the cathode side of a PEM electrolyzer is commonly referred to as the Hydrogen Evolution Reaction (HER). Here the supplied electrons and the protons that have conducted through the membrane are combined to create gaseous hydrogen.\n\nThe illustration below depicts a simplification of how PEM electrolysis works, showing the individual half-reactions together along with the complete reaction of a PEM electrolyzer. In this case the electrolyzer is coupled with a solar panel for the production of hydrogen, however the solar panel could be replaced with any source of electricity.\n\nAs per the second law of thermodynamics the enthalpy of the reaction is:\n\nWhere formula_1 is the Gibbs free energy of the reaction, formula_2 is the temperature of the reaction and formula_3 is the change in entropy of the system.\n\nThe overall cell reaction with thermodynamic energy inputs then becomes:\n\nThe thermal and electrical inputs shown above represent the minimum amount of energy that can be supplied by electricity in order to obtain an electrolysis reaction. Assuming that the maximum amount of heat energy (48.6 kJ/mol) is supplied to the reaction, the reversible cell voltage formula_4 can be calculated.\n\nwhere formula_5 is the number of electrons and formula_6 is Faraday's constant. The calculation of cell voltage assuming no irreversibilities exist and all of the thermal energy is utilized by the reaction is referred to as the lower heating value (LHV). The alternative formulation, using the higher heating value (HHV) is calculated assuming that all of the energy to drive the electrolysis reaction is supplied by the electrical component of the required energy which results in a higher reversible cell voltage. When using the HHV the voltage calculation is referred to as the thermoneutral voltage.\n\nThe performance of electrolysis cells, like fuel cells, are typically compared by plotting their polarization curves, which is obtained by plotting the cell voltage against the current density. The primary sources of increased voltage in a PEM electrolyzer (the same also applies for PEM fuel cells) can be categorized into thee main areas, Ohmic losses, activation losses and mass transport losses. Due to the reversal of operation between a PEM fuel cell and a PEM electrolyzer, the degree of impact for these various losses is different between the two processes.\n\nThe performance of a PEM electrolysis system is typically compared by plotting the overpotential versus the cells current density. This essentially results in a curve that represents the power per square centimeter of cell area required to produce hydrogen and oxygen. Conversely to the PEM fuel cell, the better the PEM electrolyzer the lower the cell voltage at a given current density. The figure below is the result of a simulation from the Forschungszentrum Jülich of a 25 cm single cell PEM electrolyzer under thermoneutral operation depicting the primary sources of voltage loss and their contributions for a range of current densities.\n\nOhmic losses are an electrical overpotential introduced to the electrolysis process by the internal resistance of the cell components. This loss then requires an additional voltage to maintain the electrolysis reaction, the prediction of this loss follows Ohm's law and holds a linear relationship to the current density of the operating electrolyzer.\n\nThe energy loss due to the electrical resistance is not entirely lost. The voltage drop due to resistivity is associated with the conversion the electrical energy to heat energy through a process known as Joule heating. Much of this heat energy is carried away with the reactant water supply and lost to the environment, however a small portion of this energy is then recaptured as heat energy in the electrolysis process. The amount of heat energy that can be recaptured is dependent on many aspects of system operation and cell design.\n\nThe Ohmic losses due to the conduction of protons contribute to the loss of efficiency which also follows Ohm's law, however without the Joule heating effect. The proton conductivity of the PEM is very dependent on the hydration, temperature, heat treatment, and ionic state of the membrane.\n\nFaradaic losses describe the efficiency losses that are correlated to the current, that is supplied without leading to hydrogen at the cathodic gas outlet. The produced hydrogen and oxygen can permeate across the membrane, referred to as crossover. Mixtures of both gases at the electrodes result. At the cathode, oxygen can be catalytically reacted with hydrogen on the platinum surface of the cathodic catalyst. At the anode, hydrogen and oxygen do not react at the iridium oxide catalyst. Thus, safety hazards due to explosive anodic mixtures hydrogen in oxygen can result. The supplied energy for the hydrogen production is lost, when hydrogen is lost due to the reaction with oxygen at the cathode and permeation from the cathode across the membrane to the anode corresponds. Hence, the ratio of the amount of lost and produced hydrogen determines the faradaic losses. At pressurized operation of the electrolyzer the crossover and the correlated faradaic efficiency losses increase.\n\nHydrogen evolution due to pressurized electrolysis is comparable to an isothermal compression process, which is in terms of efficiency preferable compared to mechanical isotropical compression. However, the contributions of the afore mentioned faradaic losses increase with operating pressures. Thus, in order to produce compressed hydrogen, the in-situ compression during electrolysis and subsequent compression of the gas have to be pondered under efficiency considerations.\n\nThe ability of the PEM electrolyzer to operate, not only under highly dynamic conditions, but also in part-load and overload conditions is one of the reasons for the recently renewed interest in this technology. The demands of an electrical grid are relatively stable and predictable, however when coupling these to energy sources such as wind and solar, the demand of the grid rarely matches the generation of the renewable energy. This means energy produced from renewable sources such as wind and solar must have a buffer, or a means of storing off-peak energy.\n\nWhen determining the electrical efficiency of PEM electrolysis, the higher heat value (HHV) can be used. This is because the catalyst layer interacts with water as steam. As the process operates at 80 °C for PEM electrolysers the waste heat can be redirected through the system to create the steam, resulting in a higher overall electrical efficiency. The lower heat value (LHV) must be used for alkaline electrolysers as the process within these electrolysers requires water in liquid form and uses alkalinity to facilitate the breaking of the bond holding the hydrogen and oxygen atoms together. The lower heat value must also be used for fuel cells, as steam is the output rather than input.\n\nPEM electrolysis has an electrical efficiency of about 80% in working application, in terms of hydrogen produced per unit of electricity used to drive the reaction. The efficiency of PEM electrolysis is expected to reach 82-86% before 2030, while also maintaining durability as progress in this area continues at a pace.\n"}
{"id": "309304", "url": "https://en.wikipedia.org/wiki?curid=309304", "title": "Propellant mass fraction", "text": "Propellant mass fraction\n\nIn aerospace engineering, the propellant mass fraction is the portion of a vehicle's mass which does not reach the destination, usually used as a measure of the vehicle's performance. In other words, the propellant mass fraction is the ratio between the propellant mass and the initial mass of the vehicle. In a spacecraft, the destination is usually an orbit, while for aircraft it is their landing location. A higher mass fraction represents less weight in a design. Another related measure is the payload fraction, which is the fraction of initial weight that is payload.It can be applied to a vehicle, a stage of a Vehicle or to a Rocket Propulsion System\n\nThe propellant mass fraction is given by:\n\nAnd because,\n\nit follows that:\n\nWhere:\n\nIn rockets for a given target orbit, a rocket's mass fraction is the portion of the rocket's pre-launch mass (fully fueled) that does not reach orbit. The propellant mass fraction is the ratio of just the propellant to the entire mass of the vehicle at takeoff (propellant plus dry mass). In the cases of a single stage to orbit (SSTO) vehicle or suborbital vehicle, the mass fraction equals the propellant mass fraction; simply the fuel mass divided by the mass of the full spaceship. A rocket employing staging, which are the only designs to have reached orbit, has a mass fraction higher than the propellant mass fraction because parts of the rocket itself are dropped off en route. Propellant mass fractions are typically around 0.8 to 0.9.\n\nIn aircraft, mass fraction is related to range, an aircraft with a higher mass fraction can go farther. Aircraft mass fractions are typically around 0.5.\n\nWhen applied to a rocket as a whole, a low mass fraction is desirable, since it indicates a greater capability for the rocket to deliver payload to orbit for a given amount of fuel. Conversely, when applied to a single stage, where the propellant mass fraction calculation doesn't include the payload, a higher propellant mass fraction corresponds to a more efficient design, since there is less non-propellant mass. Without the benefit of staging, SSTO designs are typically designed for mass fractions around 0.9. Staging increases the payload fraction, which is one of the reasons SSTO's appear difficult to build.\n\nFor example, the complete Space Shuttle system has:\n\nGiven these numbers, the propellant mass fraction is formula_8.\n\nThe mass fraction plays an important role in the rocket equation:\n\nWhere formula_10 is the ratio of final mass to initial mass (i.e., one minus the mass fraction), formula_11 is the change in the vehicle's velocity as a result of the fuel burn and formula_12 is the effective exhaust velocity (see below).\n\nThe term effective exhaust velocity is defined as:\n\nwhere \"I\" is the fuel's specific impulse in seconds and \"g\" is the \"standard acceleration of gravity\" (note that this is not the local acceleration of gravity).\n\nTo make a powered landing from orbit on a celestial body without an atmosphere requires the same mass reduction as reaching orbit from its surface, if the speed at which the surface is reached is zero.\n\n"}
{"id": "2887560", "url": "https://en.wikipedia.org/wiki?curid=2887560", "title": "Rayleigh flow", "text": "Rayleigh flow\n\nRayleigh flow refers to frictionless, non-Adiabatic flow through a constant area duct where the effect of heat addition or rejection is considered. Compressibility effects often come into consideration, although the Rayleigh flow model certainly also applies to incompressible flow. For this model, the duct area remains constant and no mass is added within the duct. Therefore, unlike Fanno flow, the stagnation temperature is a variable. The heat addition causes a decrease in stagnation pressure, which is known as the Rayleigh effect and is critical in the design of combustion systems. Heat addition will cause both supersonic and subsonic Mach numbers to approach Mach 1, resulting in choked flow. Conversely, heat rejection decreases a subsonic Mach number and increases a supersonic Mach number along the duct. It can be shown that for calorically perfect flows the maximum entropy occurs at M = 1. Rayleigh flow is named after John Strutt, 3rd Baron Rayleigh.\n\nThe Rayleigh flow model begins with a differential equation that relates the change in Mach number with the change in stagnation temperature, T. The differential equation is shown below.\n\nSolving the differential equation leads to the relation shown below, where T* is the stagnation temperature at the throat location of the duct which is required for thermally choking the flow.\n\nThese values are significant in the design of combustion systems. For example, if a turbojet combustion chamber has a maximum temperature of T* = 2000 K, T and M at the entrance to the combustion chamber must be selected so thermal choking does not occur, which will limit the mass flow rate of air into the engine and decrease thrust.\n\nFor the Rayleigh flow model, the dimensionless change in entropy relation is shown below.\n\nThe above equation can be used to plot the Rayleigh line on a Mach number versus ΔS graph, but the dimensionless enthalpy, H, versus ΔS diagram is more often used. The dimensionless enthalpy equation is shown below with an equation relating the static temperature with its value at the choke location for a calorically perfect gas where the heat capacity at constant pressure, c, remains constant.\n\nThe above equation can be manipulated to solve for M as a function of H. However, due to the form of the T/T* equation, a complicated multi-root relation is formed for M = M(T/T*). Instead, M can be chosen as an independent variable where ΔS and H can be matched up in a chart as shown in Figure 1. Figure 1 shows that heating will increase an upstream, subsonic Mach number until M = 1.0 and the flow chokes. Conversely, adding heat to a duct with an upstream, supersonic Mach number will cause the Mach number to decrease until the flow chokes. Cooling produces the opposite result for each of those two cases. The Rayleigh flow model reaches maximum entropy at M = 1.0 For subsonic flow, the maximum value of H occurs at M = 0.845. This indicates that cooling, instead of heating, causes the Mach number to move from 0.845 to 1.0 This is not necessarily correct as the stagnation temperature always increases to move the flow from a subsonic Mach number to M = 1, but from M = 0.845 to M = 1.0 the flow accelerates faster than heat is added to it. Therefore, this is a situation where heat is added but T/T* decreases in that region.\n\nThe area and mass flow rate are held constant for Rayleigh flow. Unlike Fanno flow, the Fanning friction factor, \"f\", remains constant. These relations are shown below with the * symbol representing the throat location where choking can occur.\n\nDifferential equations can also be developed and solved to describe Rayleigh flow property ratios with respect to the values at the choking location. The ratios for the pressure, density, static temperature, velocity and stagnation pressure are shown below, respectively. They are represented graphically along with the stagnation temperature ratio equation from the previous section. A stagnation property contains a '0' subscript.\n\nThe Rayleigh flow model has many analytical uses, most notably involving aircraft engines. For instance, the combustion chambers inside turbojet engines usually have a constant area and the fuel mass addition is negligible. These properties make the Rayleigh flow model applicable for heat addition to the flow through combustion, assuming the heat addition does not result in dissociation of the air-fuel mixture. Producing a shock wave inside the combustion chamber of an engine due to thermal choking is very undesirable due to the decrease in mass flow rate and thrust. Therefore, the Rayleigh flow model is critical for an initial design of the duct geometry and combustion temperature for an engine.\n\nThe Rayleigh flow model is also used extensively with the Fanno flow model. These two models intersect at points on the enthalpy-entropy and Mach number-entropy diagrams, which is meaningful for many applications. However, the entropy values for each model are not equal at the sonic state. The change in entropy is 0 at M = 1 for each model, but the previous statement means the change in entropy from the same arbitrary point to the sonic point is different for the Fanno and Rayleigh flow models. If initial values of s and M are defined, a new equation for dimensionless entropy versus Mach number can be defined for each model. These equations are shown below for Fanno and Rayleigh flow, respectively.\n\nFigure 3 shows the Rayleigh and Fanno lines intersecting with each other for initial conditions of s = 0 and M = 3.0 The intersection points are calculated by equating the new dimensionless entropy equations with each other, resulting in the relation below.\n\nThe intersection points occur at the given initial Mach number and its post-normal shock value. For Figure 3, these values are M = 3.0 and 0.4752, which can be found the normal shock tables listed in most compressible flow textbooks. A given flow with a constant duct area can switch between the Rayleigh and Fanno models at these points.\n\n\n\n"}
{"id": "8951767", "url": "https://en.wikipedia.org/wiki?curid=8951767", "title": "Reinforced thermoplastic pipe", "text": "Reinforced thermoplastic pipe\n\nReinforced thermoplastic pipe (RTP) is a generic term referring to a reliable high strength synthetic fibre (such as glass, aramid or carbon), initially developed in the early 1990s by Wavin Repox, Akzo Nobel and by Tubes d'Aquitaine from France, who developed the first pipes reinforced with synthetic fibre to replace medium pressure steel pipes in response to growing demand for non-corrosive conduits for application in the onshore oil and gas industry, particularly in the Middle East. \nTypically, the materials used in the construction of the pipe might be Polyethylene (PE), Polyamide-11 or PVDF and may be reinforced with Aramid or Polyester fibre although other combinations are used.\nMore recently the technology of producing such pipe, including the marketing, rests with a few key companies, one of which is Pipelife with Soluforce where it is available in coils up to length. These pipes are available in pressure ratings from . Over the last few years this type of pipe has been acknowledged as a standard alternative solution to steel for oilfield flowline applications by certain oil companies and operators. The great advantage of this pipe is also its very fast installation time compared to steel pipe when considering the welding time as average speeds up to /day have been reached installing RTP in ground surface.\n\nPrimarily, the pipe provides benefit to applications where steel may rupture due to corrosion and installation time is an issue.\n\nThe idea of synthetic fibre reinforced pipe has origins in the flexible hose and offshore industry where it has been frequently used for applications such as control lines in umbilicals and production flowlines for over 30 years. However, the commercialisation and realisation of a competitive product for the onshore oil industry came from a partnership between Teijin Aramid (supplier of aramid fibre Twaron) and Wavin Repox (manufacturer of reinforced thermoset pipes), where Bert Dalmolen initiated a project to develop such a pipe. He was later employed by Pipelife where a state of the art production line was developed to produce RTP. Pipelife also developed a pipe reinforced with steel wire to achieve even higher pressure ratings of over using steel reinforcement.\nMr Chevrier (Tubes d'Aquitaine) also developed machinery that could produce such pipes, but was not successful in commercialising RTP.\n\n\n\n\n"}
{"id": "6208104", "url": "https://en.wikipedia.org/wiki?curid=6208104", "title": "Richard Sears McCulloh", "text": "Richard Sears McCulloh\n\nRichard Sears McCulloh (18 March 1818 – 1894) was an American civil engineer and professor of mechanics and thermodynamics at the Washington and Lee University, Lexington, Virginia.\n\nMcCulloh was born on 18 March 1818 in Baltimore, Maryland, United States.\nHe graduated from the College of New Jersey in 1836, then studied chemistry in Philadelphia with James Curtis Booth from 1838 to 1839.\nFrom 1846 to 1849 he worked for the U.S. Mint in Philadelphia.\nMcCulloh was appointed professor of natural philosophy at Princeton University on 24 October 1849, and then professor of natural and experimental philosophy at Columbia College on 3 April 1854.\n\nDuring the American Civil War, McCulloh disappeared from New York after the draft riots and in October 1863 McCulloh went to Richmond, Virginia to become the consulting chemist of the Confederate Nitre and Mining Bureau.\nIn response, Columbia College expelled him from his professorship.\nWhile in Richmond, he helped \"the Confederacy in making a chemical weapon\".\nHis experiments in creating a lethal gas were proved successful in February 1865, but before the weapon could be used in practice Richmond fell in April 1865. McCulloh fled the city but was captured two months later off the coast of Florida, and for almost two years was imprisoned in the Virginia State Penitentiary.\n\nAfter being released, in 1866 McCulloh was appointed to the new \"McCormick Professorship of Experimental Philosophy & Applied Mathematics\" at Washington and Lee College. \nHe resigned later during financial retrenchment.\nIn 1869 he was a member of a faculty committee that created an expensive plan for expanding the Washington College curriculum dramatically.\nIn January 1870 he was a Professor of Natural Philosophy at Washington College.\nIn 1878, McCulloh received an honorary doctorate of law degree from Washington and Lee University.\n\nMcCulloh was interested in a range of practical and scientific subjects. He prepared a plan for organizing the naval observatory.\nHe wrote on the use of hydrometers to measure sugar and alcohol content of liquids, and wrote a treatise on electricity.\nHe invented a method of refining California gold that involved combining the ore with zinc.\nThis invention was similar to an independent invention by his former teacher James Curtis Booth, and the two men agreed to combine their inventions into a single patent, which they sold to an interested industrialist.\n\nIn 1876, a collection of McCulloh's lecture notes were published in a book entitled \"Treatise on the Mechanical Theory of Heat and its Application to the Steam Engine, Etc.\" McCulloh acknowledged the pioneering work of James Prescott Joule and Nicolas Léonard Sadi Carnot in establishing the laws of thermodynamics. He went on to say of this discipline that \"there are few, if any, branches of natural science which are not more or less dependent upon the great truths under consideration\". He gave as an example the view that the body of an animal was essentially a \"heat engine\", fueled by the food consumed.\n\n\n\n"}
{"id": "27116", "url": "https://en.wikipedia.org/wiki?curid=27116", "title": "Scandium", "text": "Scandium\n\nScandium is a chemical element with symbol Sc and atomic number 21. A silvery-white metallic d-block element, it has historically been classified as a rare-earth element, together with yttrium and the lanthanides. It was discovered in 1879 by spectral analysis of the minerals euxenite and gadolinite from Scandinavia.\n\nScandium is present in most of the deposits of rare-earth and uranium compounds, but it is extracted from these ores in only a few mines worldwide. Because of the low availability and the difficulties in the preparation of metallic scandium, which was first done in 1937, applications for scandium were not developed until the 1970s. The positive effects of scandium on aluminium alloys were discovered in the 1970s, and its use in such alloys remains its only major application. The global trade of scandium oxide is about 10 tonnes per year.\n\nThe properties of scandium compounds are intermediate between those of aluminium and yttrium. A diagonal relationship exists between the behavior of magnesium and scandium, just as there is between beryllium and aluminium. In the chemical compounds of the elements in group 3, the predominant oxidation state is +3.\n\nScandium is a soft metal with a silvery appearance. It develops a slightly yellowish or pinkish cast when oxidized by air. It is susceptible to weathering and dissolves slowly in most dilute acids. It does not react with a 1:1 mixture of nitric acid (HNO) and 48% hydrofluoric acid (HF), possibly due to the formation of an impermeable passive layer. Scandium turnings ignite in air with a brilliant yellow flame to form scandium oxide.\n\nIn nature, scandium is found exclusively as the isotope Sc, which has a nuclear spin of 7/2; this is its only stable isotope. Thirteen radioisotopes have been characterized with the most stable being Sc, which has a half-life of 83.8 days; Sc, 3.35 days; the positron emitter Sc, 4 h; and Sc, 43.7 hours. All of the remaining radioactive isotopes have half-lives less than 4 hours, and the majority of these have half-lives less than 2 minutes. This element also has five nuclear isomers, with the most stable being Sc (\"t\" = 58.6 h).\n\nThe isotopes of scandium range from Sc to Sc. The primary decay mode at masses lower than the only stable isotope, Sc, is electron capture, and the primary mode at masses above it is beta emission. The primary decay products at atomic weights below Sc are calcium isotopes and the primary products from higher atomic weights are titanium isotopes.\n\nIn Earth's crust, scandium is not rare. Estimates vary from 18 to 25 ppm, which is comparable to the abundance of cobalt (20–30 ppm). Scandium is only the 50th most common element on Earth (35th most abundant in the crust), but it is the 23rd most common element in the Sun. However, scandium is distributed sparsely and occurs in trace amounts in many minerals. Rare minerals from Scandinavia and Madagascar such as thortveitite, euxenite, and gadolinite are the only known concentrated sources of this element. Thortveitite can contain up to 45% of scandium in the form of scandium oxide.\n\nThe stable form of scandium is created in supernovas via the r-process.\n\nThe world production of scandium is in the order of 15 tonnes per year, in the form of scandium oxide. The demand is about 50% higher, and both the production and demand keep increasing. In 2003, only three mines produced scandium: the uranium and iron mines in Zhovti Vody in Ukraine, the rare-earth mines in Bayan Obo, China, and the apatite mines in the Kola peninsula, Russia; since then many other countries have built scandium-producing facilities, including 5 tonnes/year (7.5 tonnes/year ScO) by Nickel Asia Corporation and Sumitomo Metal Mining in the Philippines. In each case scandium is a byproduct from the extraction of other elements and is sold as scandium oxide.\n\nTo produce metallic scandium, the oxide is converted to scandium fluoride and then reduced with metallic calcium.\n\nMadagascar and the Iveland-Evje region in Norway have the only deposits of minerals with high scandium content, thortveitite (Sc,Y)(SiO) and kolbeckite ScPO·2HO, but these are not being exploited.\n\nThe absence of reliable, secure, stable, long-term production has limited the commercial applications of scandium. Despite this low level of use, scandium offers significant benefits. Particularly promising is the strengthening of aluminium alloys with as little as 0.5% scandium. Scandium-stabilized zirconia enjoys a growing market demand for use as a high-efficiency electrolyte in solid oxide fuel cells. \n\nBecause of its rarity, scandium is among the most expensive elements. Price for pure scandium fluctuates between 4,000 and 20,000 US dollars per kilogram. Meanwhile, the limited market generates a variety of prices at any given time. In 2010, at the peak of the rare-earths shortage, the price of scandium rose to over 15,000 US dollars per kilogram, and the widely commercially used scandium oxide (ScO) was selling above 7 000 US dollars per kilogram. Since then the limited demand coupled with steady production keeps the price at its 20-year average.\n\nScandium chemistry is almost completely dominated by the trivalent ion, Sc. The radii of M ions in the table below indicate that the chemical properties of scandium ions have more in common with yttrium ions than with aluminium ions. In part because of this similarity, scandium is often classified as a lanthanide-like element.\n\nThe oxide and the hydroxide are amphoteric:\n\nα- and γ-ScOOH are isostructural with their aluminium hydroxide oxide counterparts. Solutions of in water are acidic due to hydrolysis.\n\nThe halides ScX, where X= Cl, Br, or I, are very soluble in water, but ScF is insoluble. In all four halides, the scandium is 6-coordinated. The halides are Lewis acids; for example, ScF dissolves in a solution containing excess fluoride ion to form [ScF]. The coordination number 6 is typical for Sc(III). In the larger Y and La ions, coordination numbers of 8 and 9 are common. Scandium triflate is sometimes used as a Lewis acid catalyst in organic chemistry.\n\nScandium forms a series of organometallic compounds with cyclopentadienyl ligands (Cp), similar to the behavior of the lanthanides. One example is the chlorine-bridged dimer, [ScCpCl] and related derivatives of pentamethylcyclopentadienyl ligands.\n\nCompounds that feature scandium in the oxidation state other than +3 are rare but well characterized. The blue-black compound CsScCl is one of the simplest. This material adopts a sheet-like structure that exhibits extensive bonding between the scandium(II) centers. Scandium hydride is not well understood, although it appears not to be a saline hydride of Sc(II). As is observed for most elements, a diatomic scandium hydride has been observed spectroscopically at high temperatures in the gas phase. Scandium borides and carbides are non-stoichiometric, as is typical for neighboring elements.\n\nLower oxidation states (+2, +1, 0) have also been observed in organoscandium compounds.\n\nDmitri Mendeleev, who is referred to as the father of the periodic table, predicted the existence of an element \"ekaboron\", with an atomic mass between 40 and 48 in 1869. Lars Fredrik Nilson and his team detected this element in the minerals euxenite and gadolinite in 1879. Nilson prepared 2 grams of scandium oxide of high purity. He named the element scandium, from the Latin \"Scandia\" meaning \"Scandinavia\". Nilson was apparently unaware of Mendeleev's prediction, but Per Teodor Cleve recognized the correspondence and notified Mendeleev.\n\nMetallic scandium was produced for the first time in 1937 by electrolysis of a eutectic mixture of potassium, lithium, and scandium chlorides, at 700–800 °C. The first pound of 99% pure scandium metal was produced in 1960. Production of aluminium alloys began in 1971, following a US patent. Aluminium-scandium alloys were also developed in the USSR.\n\nLaser crystals of gadolinium-scandium-gallium garnet (GSGG) were used in strategic defense applications developed for the Strategic Defense Initiative (SDI) in the 1980s and 1990s.\n\nIn early 2018, evidence was gathered from spectrometer data of significant scandium, vanadium and yttrium abundances in red giant stars in the Nuclear Star Cluster (NSC) in the Galactic Center. Further research showed that this was an illusion caused by the relatively low temperature (below 3,500 K) of these stars masking the abundance signals, and that this phenomenon was observable in other red giants.\n\nThe addition of scandium to aluminium limits the grain growth in the heat zone of welded aluminium components. This has two beneficial effects: the precipitated AlSc forms smaller crystals than in other aluminium alloys, and the volume of precipitate-free zones at the grain boundaries of age-hardening aluminium alloys is reduced. Both of these effects increase the usefulness of the alloy. However, titanium alloys, which are similar in lightness and strength, are cheaper and much more widely used.\n\nThe alloy AlLiMgScTi is as strong as titanium, light as aluminium, and hard as ceramic.\n\nThe main application of scandium by weight is in aluminium-scandium alloys for minor aerospace industry components. These alloys contain between 0.1% and 0.5% of scandium. They were used in the Russian military aircraft, specifically the MiG-21 and MiG-29.\n\nSome items of sports equipment, which rely on high-performance materials, have been made with scandium-aluminium alloys, including baseball bats and bicycle frames and components. Lacrosse sticks are also made with scandium. The American firearm manufacturing company Smith & Wesson produces semi-automatic pistols and revolvers with frames of scandium alloy and cylinders of titanium or carbon steel.\n\nDentists use erbium-chromium-doped yttrium-scandium-gallium garnet (Er,Cr:YSGG) lasers for cavity preparation and in endodontics.\n\nThe first scandium-based metal-halide lamps were patented by General Electric and initially made in North America, although they are now produced in all major industrialized countries. Approximately 20 kg of scandium (as ScO) is used annually in the United States for high-intensity discharge lamps. One type of metal-halide lamp, similar to the mercury-vapor lamp, is made from scandium triiodide and sodium iodide. This lamp is a white-light source with high color rendering index that sufficiently resembles sunlight to allow good color-reproduction with TV cameras. About 80 kg of scandium is used in metal-halide lamps/light bulbs globally per year.\n\nThe radioactive isotope Sc is used in oil refineries as a tracing agent. Scandium triflate is a catalytic Lewis acid used in organic chemistry.\n\nElemental scandium is considered non-toxic, though extensive animal testing of scandium compounds has not been done. The median lethal dose (LD) levels for scandium chloride for rats have been determined as 4 mg/kg for intraperitoneal and 755 mg/kg for oral administration. In the light of these results, compounds of scandium should be handled as compounds of moderate toxicity.\n\n"}
{"id": "27062985", "url": "https://en.wikipedia.org/wiki?curid=27062985", "title": "Shiraz Biogas Power Plant", "text": "Shiraz Biogas Power Plant\n\nShiraz Biogas Power Plant is a biogas powerplant situated in Shiraz, Iran. The plant uses gasification of biomass to produce biofuel for a pilot thermal power station with a capacity of 1.065 MW. The plant was approved in 2001 and construction started on 27 September 2007. The plant which became operational in 2009, can generate more than 8,000 MWh of electricity per year from biodegradable waste.\n\n"}
{"id": "1919848", "url": "https://en.wikipedia.org/wiki?curid=1919848", "title": "Singapore Airlines Flight 006", "text": "Singapore Airlines Flight 006\n\nSingapore Airlines Flight 006 (SQ006/SIA006) was a scheduled Singapore Airlines passenger flight from Singapore Changi Airport to Los Angeles International Airport via Chiang Kai-shek International Airport (now Taiwan Taoyuan International Airport) in Taipei, Taiwan. On 31 October 2000, at 23:17 Taipei local time (15:17 UTC), the Boeing 747-412 operating the flight attempted to take off from the wrong runway at Chiang Kai-shek International Airport during a typhoon. The aircraft crashed into construction equipment on the runway, killing 81 of the 179 occupants aboard. 98 initially survived the impact, but 2 passengers died later from injuries in a hospital. As of 2018, the accident is the third-deadliest on Taiwanese soil. It was the first fatal accident involving a Boeing 747-400, and the first and only Singapore Airlines crash to result in fatalities. It was also the second 747-400 to be written off, the other being B-165 at Kai Tak International Airport.\n\nThe aircraft involved in the accident was a Boeing 747-412, registered as 9V-SPK with manufacturer's serial number 28023, powered by four Pratt & Whitney PW4056 engines. It was the 1099th Boeing 747 built and had been delivered to Singapore Airlines on 21 January 1997. It was one of 2 Singapore Airlines 747-412s (The other being 9V-SPL) that was painted in the special Tropical MegaTop Paint Scheme to promote new First and Business Class Items. It had its last maintenance check on 16 September 2000 and had no defects during the inspection and at the time of the accident.\n\nThe captain of the flight was Foong Chee Kong (age 41). He was an experienced pilot with more than 11,200 recorded flight hours, of which more than 2,000 were in Boeing 747-400 aircraft. He was considered a competent and above-average pilot. The first officer, Latiff Cyrano (age 36), had more than 2,400 total flight hours. The third member of the crew was relief pilot Ng Kheng Leng (age 38) with approximately 5,500 total flight hours.\n\nAt 15:00 UTC, 23:00 Taipei local time on 31 October 2000, 9V-SPK left Bay B5 during heavy rain caused by Typhoon Xangsane. At 23:05:57, ground control cleared the aircraft to taxi to runway 05L via taxiway SS WC then NP. At 23:15:22, the aircraft was cleared for takeoff on runway 05L. Many carriers in Southeast and East Asia take off during inclement weather.\n\nAfter a six-second hold, at 23:16:36, the crew attempted takeoff on runway 05R – which had been closed for repairs – instead of the assigned runway 05L (which ran parallel to 05R). The captain correctly heard that he needed to take off at 05L, but he turned too soon and lined up with 05R. The airport was not equipped with ASDE, a ground radar which allows the air traffic controllers to monitor aircraft movements on the ground.\nDue to poor visibility in the heavy rain, the flight crew did not see that construction equipment, including two excavators, two vibrating rollers, one small bulldozer, and one air compressor, had been parked on runway 05R. In addition, the runway contained concrete Jersey barriers and pits. About 41 seconds later, the aircraft collided with the machinery and broke into 3 major pieces. The fuselage was torn in two, and the engines and landing gear separated. A crane tore the left wing from the aircraft, forcing the jet back onto the ground. The nose struck a scoop loader, with a following large fire, destroying the forward section of the fuselage and the wings. 79 of 159 passengers and 4 of 20 crew members died in the accident. Many of the dead were seated in the middle section of the aircraft; the fuel stored in the wings exploded and incinerated through that section. At 23:17:36, the emergency bell sounded and 41 firefighting vehicles, 58 ambulances, 9 lighting units, and 436 personnel were dispatched to assist survivors and extinguish the fire. Chemical extinguishing agents rained on the aircraft at about three minutes after the impact. At 23:35, roughly 10 minutes after the impact, the fire was brought under control. At 23:40, non-airport ambulances and emergency vehicles from other agencies congregated at the north gate. At 00:00 Taipei time on 1 November, the fire was mostly extinguished and the front part of the aircraft was destroyed. Authorities established a temporary command centre.\n\n179 passengers and crew, including 3 children and 3 infants, were on the aircraft at the time of the crash. Of the 179 occupants, 83 were killed, 39 suffered from serious injuries, 32 had minor injuries, while 25 were uninjured. Amongst those who perished, there were 4 crew members. 81 passengers and crew died on impact immediately after the crash and 2 passengers died at a hospital.\n\nThe passengers mostly consisted of Taiwanese and Americans.\n\nAmongst the Singaporeans who perished were Elma Thwaites, mother of Singapore Turf Club horse-trainer Malcolm Thwaites, Dr. Sung Kah Kay (), assistant professor of the National University of Singapore's Department of Computer Science, Dr. Sung's wife, Jennifer Loo Tak Wing, and Captain Lim Kim Hock, a Republic of Singapore Air Force pilot on his way to the Air National Guard to attend the Advanced Fighter Weapons Instructor Course. In addition, four of the dead were Motorola employees. \nAmongst perished passengers of other nationalities were the president and two vice-presidents of Buena Park, California-based Ameripec Inc. Kevin Rice, a professor at UC Davis, survived the crash with more than 12% of his body burned, as did John Diaz, a vice-president of MP3.com, who survived the crash with injuries not related to burns. William Wang, who later founded Vizio, survived with only carbon monoxide poisoning.\n\nThe captain, co-pilot and relief pilot originated from Singapore on another SQ 006 flight the day before the accident, rested at a hotel in Taipei, and boarded SQ 006 on October 31. The crew consisted of 12 males and 8 females. All three flight crew members survived the crash. The co-pilot received minor injuries. The pilot and relief pilot sustained no injuries. Of the 17 cabin crew members, 4 died, 4 received serious injuries, and 9 received minor injuries.\n\nOf the passengers, 79 died, 35 received serious injuries, 22 received minor injuries, and 23 were uninjured.\n\nThe aircraft had 5 first-class passengers, 28 business-class passengers (9 on lower deck and 19 on upper deck), and 126 economy-class passengers. Of the first class passengers, 1 received a minor injury and 4 received no injuries. Of the business-class passengers, 14 (2 on lower deck, 12 on upper deck) died, 2 (1 on lower deck, 1 on upper deck) received serious injuries, 7 (2 on lower deck, 5 on upper deck) received minor injuries, and 8 (4 on lower deck, 4 on upper deck) were uninjured. Of the economy class passengers, 65 died, 33 received serious injuries, 14 received minor injuries, and 11 were uninjured. The lower deck passengers who died were seated in rows 22 through 38. 64 of 76 passengers in the forward economy section were killed by the explosion of the centre fuel tank, which resulted in intense fire. In the upper deck of the business class section, 12 of 19 passengers and 1 of 2 flight attendants died due to smoke inhalation and fire; 10 bodies, originating from the upper deck of business class, were found between the stairwell and the 2L exit on the main deck. All passengers in the aft economy section survived.\n\nOf the passengers on the TPE-LAX leg, 77 flew from Singapore and 82 flew from Taipei. Of the passengers originating from Singapore, 37 died. Of the passengers originating from Taipei, 42 died. Of the three male passengers identified as infants, including two Indians originated from Singapore and one Taiwanese originated from Taipei, all three died.\n\nThe Department of Forensic Pathology Institute of Foreign Medicine, Ministry of Justice performed seven autopsies. One person died from impact injuries, and six people died from severe burns. Many passengers on the flight sustained burns since jet fuel splashed onto the passengers.\n\nLin Ming-liang, a 45-year-old Taiwanese passenger bearing burns to more than 86% of his body, died of his injuries at Chang Gung Memorial Hospital (t: 長庚紀念醫院 \"Chánggēng Jìniàn Yīyuàn\"), Linkou, Taipei County (now New Taipei City) on Sunday 5 November 2000. Lee Suet Yee, a hospitalised Singaporean woman bearing burns to 95% of her body, died of her injuries in a Taiwanese hospital on 24 November 2000.\n\nDiaz did not receive burns; he received lung damage and \"body shock,\" which resulted in compressed joints with soft tissue damage. When Diaz appeared on \"The Oprah Winfrey Show\", he used a walker.\n\nAn investigation into the accident was conducted by the Aviation Safety Council (ASC) of the Republic of China. The final report was issued by the ASC on 24 April 2002. In the report section \"Findings Related to Probable Causes,\" which detailed factors that played a major role in the circumstances leading to the accident, it was stated that the flight crew did not review the taxi route, despite having all the relevant charts, and as a result did not know the aircraft had entered the wrong runway. Upon entering the wrong runway, the flight crew had neglected to check the para visual display (PVD) and the primary flight display (PFD), which would have indicated that the aircraft was lined up on the wrong runway. According to the ASC, these errors, coupled with the imminent arrival of the typhoon and the poor weather conditions, caused the flight crew to lose situational awareness and led them to attempt to take off from the wrong runway.\n\nImmediately after the accident occurred, James Boyd, a Singapore Airlines spokesperson in Los Angeles, stated that no fatalities occurred in the crash; the airline statement was later revised to state that fatalities occurred.\n\nThe airline initially stated that reports of the aircraft taking the wrong runway were untrue before the fact that the wrong runway was used was proven true.\n\nKhan Mahmood, an Atlanta man whose sister and parents died in SQ006, criticised the airline for taking too much time to notify relatives.\n\nA counselling centre opened at Los Angeles International Airport to deal with relatives of passengers.\n\nRelatives of victims provided blood samples to identify bodies.\n\nThe report by ASC was deemed controversial by Singapore's Ministry of Transport, Singapore Airlines and the International Federation of Air Line Pilots' Associations (IFALPA), among others.\n\nSingaporean officials protested that the report did not present a full account of the incident and was incomplete, as responsibility for the accident appeared to have been placed mainly on the flight crew of SQ006, while other equally valid contributing factors had been played down. The team from Singapore that participated in the investigation felt that the lighting and signage at the airport did not measure up to international standards. Some critical lights were missing or not working. No barriers or markings were put up at the start of the closed runway, which would have alerted the flight crew that they were on the wrong runway. The Singapore team felt that these two factors were given less weight than was proper, as another flight crew had almost made the same mistake of using runway 05R to take off days before the accident.\n\nSingapore Airlines also issued a statement after the release of the ASC report. In their statement, Singapore Airlines reiterated the points brought up by the Singapore investigators and added that air traffic control (ATC) did not follow their own procedure when they gave clearance for SQ006 to take off despite ATC's not being able to see the aircraft. Singapore Airlines also clarified that the para visual display (PVD) was meant to help the flight crew maintain the runway centerline in poor visibility, rather than to identify the runway in use.\n\nThe statement by Kay Yong (T: 戎 凱, P: \"Rēng Kǎi\"), managing director of the Republic of China's Aviation Safety Council, implied that pilot error played a major role in the crash of the Boeing 747-400, which led to the deaths of 83 people. He stated that the airport should have placed markers stating that the runway was closed to takeoffs and landings.\n\nIn general, airport runways that are closed are not normally lighted, to make it clear they are not in use. At Chiang Kai-Shek International Airport, a single switch controlled green lights on the common taxiway to both runways and on the centreline of runway 05R. Civil Aeronautics Administration Deputy Director Chang Kuo-cheng said runway 05L was fully lit on Tuesday night by white and yellow lights and only the green centreline lighting was illuminated on closed runway 05R. On the taxiway to the runways, four large signs point the way to runway 05L, he added, and he refused to state explicitly that pilot error was the primary cause of the mix-up.\n\nRunway 05R was not blocked off by barriers because part of the strip was used by landing planes to taxi back to the airport terminal.\nThe pilot confirmed twice with the control tower that he was on the correct runway; controllers did not know the plane had actually gone on to the wrong runway because the airport lacked ground radar and the plane was out of sight of the tower at the time of its takeoff attempt.\n\nJohn Wiggans, a survivor of the crash, stated in a \"USA Today\" article that the staff were unable to help the passengers escape from the aircraft due to being frozen by fear and/or due to lack of competence in emergency procedures; Wiggans was seated in the upper deck business class area. \"The Straits Times\" carried reports of flight attendants saving lives of passengers. One story from the newspaper stated that Irene Ang Miau Lee (洪妙丽 \"Hóng Miàolì\") escaped the crash, ran back into the aircraft to attempt to save passengers, and died.\n\n\"The Australian\" reported that some flight attendants helped passengers and some flight attendants fled the aircraft before all passengers were accounted for. Genevieve Jiang of \"The Electric New Paper\" stated that the pilots attempted to help the passengers.\n\nThe Taiwanese report stated that the relief pilot (Crew Member 3, or CM-3) said in an interview that he was the first to leave the cockpit and the last to leave the aircraft (Pg. 108/508). A passenger sitting in seat 17A stated that the Right Upper Deck Door flight attendant directed him to the main deck via the stairs. The flight attendant died (Pg. 108/508).\n\nUpper deck passengers and flight attendants stated that the Crew-In-Charge flight attendant (CIC) travelled upstairs after the first impact; the Crew-In-Charge flight attendant died (Pg. 109/508).\n\nThe 3R and 3L flight attendants died; they were seated in the middle of the aircraft (Pg. 110/508).\n\nAfter the release of the ASC report, Republic of China public prosecutors called upon the flight crew of SQ006 to return to the ROC for questioning and the three-member crew complied. Rumours abounded at the time that the pilots might be detained in the ROC and charged with negligence. IFALPA had previously stated that it would advise its members of the difficulties of operating into the ROC if the flight crew of SQ006 were prosecuted. The prosecutors did not press charges and the flight crew were allowed to leave the ROC.\n\nThe accident aircraft 9V-SPK was painted in Singapore Airlines special promotion livery, a scheme called \"Tropical\", at the time of the accident. The special livery was intended to promote Singapore Airlines new first class and business class products. After the accident, 9V-SPK's sister aircraft, 9V-SPL, the only other aircraft painted with the promotional livery, was immediately removed from service and repainted with standard Singapore Airlines livery. Not until 2015 would another Singapore Airline's airframe be painted in any livery other than the standard for Singapore Airlines or Star Alliance.\n\nDozens of survivors and relatives of those killed filed lawsuits against the airline and ROC authorities. Despite a Taiwanese High Prosecutor's decision to not prosecute the pilots for the first three years after the crash, Singapore Airlines subsequently fired the captain and first officer in 2002.\n\nThe Association of Asian American Yale Alumni named the Tina E. Yeh Community Service Fellowship program after Tina Eugenia Yeh, an American who boarded SQ006 in Taipei and died.\n\nBy 8 November 2000, several bodies were scheduled to be repatriated. Of the bodies:\nThe bodies of 14 Taiwanese passengers and the others remained in Taipei to be collected by relatives.\n\nBy 2 November 2000, 40 passengers and crew were hospitalised, of whom 11 were later released that night. On 5 November 2000, 34 passengers and crew remained hospitalised. 64 were discharged from the hospitals. Lin Ming-Liang, a Taiwanese passenger, died that day. On 8 November 2000, 24 passengers and crew remained hospitalised: 20 in the Republic of China (Taiwan), 3 in Singapore and 1 in the United States. The Republic of Singapore Air Force deployed a specially configured KC-135R for the medical evacuation of critical Singaporean victims. 73 survivors, 40 who were not hospitalised and 33 who were discharged, had either returned home or continued with their travel.\n\nThe film \"Thread That Binds\" includes an interview with Farzana Abdul Razak, a surviving flight attendant.\n\nThe \"Mayday\" on Season 12 Episode 3 titled \"Caution to the Wind\" featured the process of the whole investigation.\n\n\n\n\n\n\n"}
{"id": "3421567", "url": "https://en.wikipedia.org/wiki?curid=3421567", "title": "Solar Team", "text": "Solar Team\n\nThe University of Calgary Solar Car Team is a multi-disciplinary student-run solar car racing (\"raycing\") team at the University of Calgary, based in Calgary, Alberta, Canada. It was established to design and build a solar car to compete in the American Solar Challenge (ASC) (previously named the North American Solar Challenge) and the World Solar Challenge (WSC). The team is primarily composed of undergraduate students studying Engineering, Business, Science, Arts and Kinesiology. The mission of the University of Calgary Solar Car Team is to educate the community about sustainable energy and to serve as an interdisciplinary project through which students and faculty from various departments can collaborate in supporting sustainable energy.\n\nThe University of Calgary Solar Car Team was established in the fall of 2004. The team was created to build a solar powered vehicle to complete in the 2005 North American Solar Challenge.\n\nThe team performed a \"miracle\" by managing to establish a strong student base with which to construct the car, procure significant sponsorship and successfully build a highly successful vehicle with limited experience all in approximately 9 months. Established teams have two years to refine existing designs between rayces.\n\nIn preparation for its first rayce, the University of Calgary Solar Team constructed and tested a prototype of their designs before building the final car. The X1 was a mock-up of and predecessor to Soleon. The X1 was used for driver training and allowed the team to test various design decisions to help ensure a successful final product. The X1 was constructed from a steel chassis with a fibreglass shell which was coated with gelcoat which made the vehicle approximately twice the final weight of its sister car.\n\nIn its first year of existence the University of Calgary Solar Team successfully competed in the NASC and the WSC. In the 2005 NASC, Soleon, their first generation rayce car placed 13th out of 17 cars that made it to the finish line. In the 2005 WSC Soleon placed 10th overall (out of 18) and first in its class. After hearing about this success, Seymour Schulich was inspired to donate $25 million (another $25 million was matched by the Alberta government) to the University of Calgary Engineering department, which was renamed the Schulich School of Engineering.\n\nSince the success of Soleon in the 2005 races, the team had to redesign for the new regulations for WSC, and prepare for the harder competition it faced from changing class to the higher, more competitive Challenge class. This class included higher efficiency solar cells, upright seating, and teams that had been raycing for the last 20 years. After shipping their new car to Australia, and testing it before scrutineering, the car had a rear tire blow out on the race track in Darwin, and resulted in the car spinning around having the tail section impacting into the guard rail and ripped from the car. The team then had to rebuild and redesign the tail section in one night before racing. Despite the higher competition and race track crash, the team managed to be the first (of six) Canadian teams to cross the timing finish line, finish 8th (out of 19) in the Challenge class, and 15th (out of 37) overall.\n\nSchulich I was improved after WSC 2007 for racing in the 2008 North American Solar Challenge. The rayce from Dallas, Texas to Calgary lasted ten days, with the University of Calgary Solar Team placing 6th (out of 15).\n\nThe University of Calgary's 3rd generation car, Schulich Axiom, was first raced in the 2010 ASC. The race spanned 1770 km from Tulsa, Oklahoma to Chicago, Illinois. The team finished in 6th place (of 18 teams) and received both the Sportsmanship and Mechanical Engineering awards for the race. With regulation changes for the 2011 WSC, the team re-engineered the design of Schulich Axiom and completely rebuilt the solar car. Some of the changes made include switching to silicon solar cells and reducing the weight of the car.\n\nThe 2011 WSC takes place October 16–23, 2011 and runs from Darwin, Northern Territory to Adelaide, South Australia. The University of Calgary Solar Team has entered Schulich Axiom in the race.\n\nSchulich Delta was designed over the course of eight months, and construction took another three months. Delta was a radical departure for the team, featuring two doors, four wheels, a passenger seat and cargo space for the very first time.\n\nThe team has entered Schulich Delta to compete in the Cruiser class in the 2013 World Solar Challenge from October 6–13, 2013.\n\nMaximum Achieved Speed: ~70 km/h\nSolar Array Type: none (stickers merely for show)\nChassis: Steel Space frame\nShell Composition: Fibreglass & Gelcoat\nCommissioned: May 2005\nDecommissioned: June 2006\nCurrent Uses: X1 has been decommissioned. The chassis is all that remains. It is suspended against a wall in the University of Calgary Solar Team's workshop.\n\nMaximum Achieved Speed: 140 km/h\nSolar Array Type: Silicon\nChassis: Aluminum Space frame\nShell Composition: Carbon Fiber & Kevlar\nWeight: ~500 lbs \nCommissioned: June 2005\nDecommissioned: July 2007\nCurrent Uses: In the fall of 2008 Soleon was donated to the Calgary Telus World of Science and was on display for 2 years. Soleon is now retired and looking for a nice warm garage to rest.\n<poem>\n\n</poem>\n\nMaximum Achieved Speed: 105 km/h\nSolar Array Type: Gallium arsenide (GaAs) Triple-junction \nChassis: Steel Space frame\nShell Composition: Carbon Fiber & Kevlar\nWeight: ~520 lbs \nCommissioned: September 2007\nDecommissioned: May 2011\nCurrent Uses: Participated in the 2007 Panasonic World Solar Challenge and the 2008 North American Solar Challenge. Since Axiom is now being used for driver training, mechanical testing and PR events, Schulich I has been retired.\n<poem>\n\n</poem>\n\nMaximum Achieved Speed: 130 km/h\nSolar Array Type: Gallium arsenide (GaAs) Triple-junction \nChassis: Carbon Fiber & Kevlar\nShell Composition: Carbon Fiber & Kevlar\nWeight: ~600 lbs \nCommissioned: October 2009\nCurrent Uses: Placed 6th overall in the 2010 North American Solar Challenge. Schulich Axiom (2010) is now predominantly being used as a display vehicle.\n<poem>\n\n</poem>\n\nMaximum Achieved Speed: 110 km/h\nSolar Array Type: Silicon Monocrystalline (Si) UC Solar Embedded \nChassis: Carbon Fiber \nShell Composition: Carbon Fiber \nWeight: ~390 lbs \nCommissioned: May 2011 \nCurrent Uses: Planning on racing in the 2011 World Solar Challenge. All improvements have since been completed to Schulich Axiom. \"It is evident from the previous race that weight is no minor detail. We have taken Axiom on its diet and the result is stunning. Axiom has dropped from around 600 lbs. without driver and ballast to 390 lbs. A loss of 210 lbs!\" -Mico Madamesila\n<poem>\n\n</poem>\n\n"}
{"id": "2333474", "url": "https://en.wikipedia.org/wiki?curid=2333474", "title": "TORRO scale", "text": "TORRO scale\n\nThe TORRO tornado intensity scale (or T-Scale) is a scale measuring tornado intensity between T0 and T11. It was proposed by Terence Meaden of the Tornado and Storm Research Organisation (TORRO), a meteorological organisation in the United Kingdom, as an extension of the Beaufort scale.\n\nThe scale was tested from 1972 to 1975 and was made public at a meeting of the Royal Meteorological Society in 1975. The scale sets T0 as the equivalent of 8 on the Beaufort scale and is related to the Beaufort scale (B) by the formula:\n\nand conversely:\n\nThe Beaufort scale was first introduced in 1805, and in 1921 quantified. It expresses the wind speed (v) by the formula:\n\nMost UK tornadoes are T6 or below with the strongest known UK tornado being a T8. For comparison, the strongest detected winds in a United States tornado (during the 1999 Oklahoma tornado outbreak) would be T11 using the following formulae:\n\nwhere \"v\" is wind speed and \"T\" is TORRO intensity number. Wind speed is defined as a 3-second gust at 10 m AGL.\n\nAlternatively, the T-Scale formula may be expressed as:\n\nor\n\nTORRO claims it differs from the Fujita scale in that it is \"purely\" a wind speed scale, whereas the Fujita scale relies on damage for classification, but in practice, damage is utilised almost exclusively in both systems to infer intensity. That is because such a proxy for intensity is usually all that is available, although users of both scales would prefer direct, objective, quantitative measurements. The scale is primarily used in the United Kingdom whereas the Fujita scale is the primary scale used in North America, continental Europe, and the rest of the world.\n\nAt the 2004 European Conference on Severe Storms, Dr. Meaden proposed a unification of the TORRO and Fujita scales as the Tornado Force or TF Scale. In 2007 in the United States, the Enhanced Fujita Scale replaced the original Fujita Scale from 1971. It made substantial improvements in standardizing damage descriptors through expanding and refining damage indicators and associated degrees of damage, as well as calibrated tornado wind speeds to better match the associated damage. However, the EF Scale is biased to US construction practices. As of 2014, only the United States and Canada have adopted the EF scale.\n\nUnlike with the F scale, no analyses have been undertaken at all to establish the veracity and accuracy of the T scale damage descriptors. The scale was written in the early 1970s, and does not take into account changes such as the growth in weight of vehicles or the great reduction in numbers and change of type of railway locomotives, and was written in an environment where tornadoes of F2 or stronger are extremely rare, so little or no first-hand investigation of actual damage at the upper end of the scale was possible. The TORRO scale has more graduations than the F scale which makes it arguably more useful for tornadoes on the lower end of the scale; however, such accuracy and precision are not typically attainable in practice. Brooks and Doswell stated that \"the problems associated with damage surveys and uncertainties associated with estimating wind speed from observed damage make highly precise assignments dubious\". In survey reports, Fujita ratings sometimes also have extra qualifications added (\"minimal F2\" or \"upper-end F3 damage\"), made by investigators who have experience of many similar tornadoes and relating to the fact that the F scale is a damage scale, not a wind speed scale.\n\nTornadoes are rated after they have passed and have been examined, not whilst in progress. In rating the intensity of a tornado, both direct measurements and inferences from empirical observations of the effects of a tornado are used. Few anemometers are struck by a tornado, and even fewer survive, so there are very few in-situ measurements. Therefore, almost all ratings are obtained from remote sensing techniques or as proxies from damage surveys. Weather radar is used when available, and sometimes photogrammetry or videogrammetry estimates wind speed by measuring tracers in the vortex. In most cases, aerial and ground damage surveys of structures and vegetation are utilised, sometimes with engineering analysis. Also sometimes available are ground swirl patterns (cycloidal marks) left in the wake of a tornado. If an on site analysis is not possible, either for retrospective ratings or when personnel cannot reach a site, photographs, videos, or descriptions of damage may be utilised.\n\nThe 12 categories for the TORRO scale are listed below, in order of increasing intensity. Although the wind speeds and photographic damage examples are updated, which are more or less still accurate. However, for the actual TORRO scale in practice, damage indicators (the type of structure which has been damaged) are predominantly used in determining the tornado intensity.\n\n\n\n"}
{"id": "2591421", "url": "https://en.wikipedia.org/wiki?curid=2591421", "title": "Tamala Park, Western Australia", "text": "Tamala Park, Western Australia\n\nTamala Park is an unpopulated locality in Perth, Western Australia. It sits on the border between the City of Wanneroo and the City of Joondalup local authorities, and separates the Clarkson-Butler region from the suburbs of Joondalup.\n\nThe Mooro group of Noongar were familiar with the area, and several of their traditional stories and legends refer to local Tamala Park land features, such as Waukolup Hill, although evidence suggests that they lived much further east, closer to modern-day Wanneroo Road.\n\nThe suburb was formally established by excision of parts of Mindarie, Clarkson and Burns Beach on 9 September 1988.\n\nAt present, Tamala Park is mostly unoccupied bushland, primarily used as a landfill and recycling centre. Two arterial roads, Marmion Avenue and Connolly Drive, run through it and link the suburbs on each side. It is a large locality, extending from the Joondalup railway line in the east, to the coast of the Indian Ocean, where it leads onto Burns Beach to the south and Claytons Beach in Mindarie to the north.\n\nTamala Park is in the process of being developed. The Tamala Park Regional Council (TPRC) was established to develop of land in the Tamala Park locality. The Council comprises 12 councillors representing the 7 owner councils that make up the TPRC as follows:\n\n\nTamala Park is the 10th regional and 154th local government council to be established by proclamation in the Government Gazette in February 2006.\n"}
{"id": "37522426", "url": "https://en.wikipedia.org/wiki?curid=37522426", "title": "Tetramethylammonium", "text": "Tetramethylammonium\n\nTetramethylammonium (TMA) or (MeN) is the simplest quaternary ammonium cation, consisting of four methyl groups attached to a central nitrogen atom, and is isoelectronic with neopentane. It is positively charged and can only be isolated in association with a counter-ion. Common salts include tetramethylammonium chloride and tetramethylammonium hydroxide. Tetramethylammonium salts are used in chemical synthesis and are widely employed in pharmacological research.\n\nIn the toxicological literature, \"naturally occurring\" tetramethylammonium (anion unspecified) is often referred to by the name \"tetramine\". Unfortunately, this non-systematic or \"trivial\" name is also used for other chemical entities, including a toxic rodenticide (Tetramethylenedisulfotetramine). Similarly, the acronym \"TMA\", which is frequently used for tetramethylammonium in the pharmacological literature, may also refer to the investigational drug 3,4,5-trimethoxyamphetamine, which, being a close structural analog of mescaline, has been the subject of numerous publications.\n\nTMA has been detected in or isolated from a number of marine organisms, mostly amongst the Cnidaria and Mollusca, notably in some species of \"Neptunea\" (commonly called whelks) that are eaten by humans. It has also been found in one plant, the African \"Courbonia virgata\" (Cappariaceae).\n\nOne of the most straightforward methods of preparing a simple salt containing the tetramethylammonium ion is by the reaction between trimethylamine and a methyl halide:\n\n[C]-labeled TMA has been made by this method.\n\nAlthough this reaction is suitable for the common halides, tetramethylammonium salts with more complex anions may be prepared by salt metathesis reactions, e.g. tetramethylammonium borohydride has been made from tetramethylammonium hydroxide as shown:\n\nMeN[OH] + Na[BH] → MeN[BH] + Na + HO\n\nAlthough TMA salts do possess some of the phase-transfer catalytic properties that are characteristic of quaternary ammonium compounds, they tend to behave atypically because of the relatively high \"hydrophilicity\" of the TMA cation.\n\nTMA cation is hydrophilic. The partition coefficient of TMA iodide in octanol-water, \"P\", is (or ).\n\nIn the TMA cation, the methyl groups are tetrahedrally arranged around the central N atom, as is evident from X-ray crystallographic studies of various of its salts. From measurements taken on molecular models, it has been estimated that the diameter of the TMA ion is ~0.6 nm; From more accurate physico-chemical measurements, the ionic radius for TMA is given as 0.322 nm; several thermodynamic parameters for the TMA ion are also recorded. The paper by Aue et al. gives a good discussion of the methods by which the ionic radius was determined.\n\nThe pharmacological literature on tetramethylammonium is extensive. In general, TMA is a cholinomimetic whose effects mimic most of those produced by exogenous acetylcholine.\n\nPharmacological experiments with TMA have been performed using one of its salts, typically the chloride, bromide or iodide, since these anions were not expected to interfere with the actions of the TMA cation. In the early pharmacological literature, however, there are references to the use of \"tetramethylammonium hydroxide\" or \"tetramethylammonium hydrate\", which were meant to facilitate comparison between weight-based dosages of different TMA salts, but did not involve the actual use of tetramethylammonium hydroxide, whose strong basicity would have been incompatible with physiological conditions.\n\nA thorough review of the pharmacology of TMA from a toxicological perspective, and current up to 1989, has been given by Anthoni and co-workers. Thus, the effects of TMA on nicotinic and muscarinic ACh receptors first stimulate, then block neurotransmission in sympathetic and parasympathetic ganglia, with depolarization. TMA also acts as an agonist at muscarinic receptors in post-ganglionic nerve endings in smooth muscles, cardiac muscle, and exocrine glands. In skeletal muscle, TMA initially causes fasciculations, then paralysis, as a result of the depolarization from stimulation of nicotinic ACh receptors.\n\nAbsorption: TMA is readily absorbed from the gastro-intestinal tract. Studies on the rat jejunum indicated that TMA absorption involved a combination of simple diffusion and carrier-mediated transport, with nearly 100% absorption occurring within 60 to 90 minutes. By comparison, tetraethylammonium and tetrapropylammonium ions were only absorbed to the extent of ~30%.\n\nDistribution: Intraperitoneal administration of radio-labeled tetramethylammonium iodide to mice showed that TMA was rapidly distributed to all parts of the body, with the highest concentrations being in the kidney and liver. Similar results were reported by Neef and co-workers using rats.\n\nMetabolism and excretion: Parenteral administration of radio-labeled tetramethylammonium iodide to rats resulted in almost the whole dose being excreted in urine, without any evidence of metabolic transformation.\n\nThe human toxicology of TMA (under the name \"tetramine\" has been studied primarily in the context\nof accidental poisoning after ingestion of \"Neptunea\" species. Symptoms include the following: nausea, vomiting, headache, vertigo/dizziness, impaired vision/temporary blindness, diplopia, photophobia, lack of balance, feeling of intoxication and urticaria. These symptoms appear within 30 minutes but recovery is usually complete after a few hours. Only one account of human death following ingestion of TMA (from the plant \"Courbonia virgata\") has been recorded.\nAlthough many of these symptoms can be accounted for on the basis of impairment of neurotransmission in the autonomic nervous system, there also seem to be distinct indications of central affects.\n\nIn animal studies, parenteral administration of TMA-containing extracts from \"Neptunea\" to mice, cats and fish mainly show effects involving skeletal muscles: there are muscular fasciculations, convulsions, loss of balance, motor paralysis and ultimately cessation of respiration.\n\nThe lethal oral dose of TMA for humans has been estimated at 3–4 mg/kg. The lethal dose for rats was estimated to be ~45–50 mg/kg, p.o., and ~15 mg/kg, i.p.\n\nLD for TMA chloride: 25 mg/kg (mouse, i.p.); 40 mg/kg (mouse, s.c.).\nLC for TMA chloride: 462 mg/L for 96 hrs. (Fathead minnow, \"Pimephales promelas\").\n"}
{"id": "18743234", "url": "https://en.wikipedia.org/wiki?curid=18743234", "title": "The Land is Ours", "text": "The Land is Ours\n\nThe Land is Ours is a British land rights campaign advocating access to the land, its resources, and the planning processes set up in 1995 by George Monbiot and others.\n\nTheir first campaign was the occupation of the disused Wisley Airfield in Surrey by 400 people in 1995, from which there was a live broadcast on the BBC's \"Newsnight\" programme. Nearby St. George's Hill is symbolically significant as the site of a 1649 protest, when the Diggers planted vegetables on the common land there. \n\nThroughout the summer of 1996, the group set up Pure Genius!!, an eco-village on a derelict former distillery site owned by Guinness in Wandsworth, London. The squatted community was evicted the day before the London Wildlife Trust were meeting to officially designate it as a conservation site containing many species of flowers and birds classed as extremely rare in London.\n\nOn 1 April 1999, on the 350th anniversary of Gerrard Winstanley and the Diggers' occupation of the same hill, The Land Is Ours organised a rally, then occupied land at St. Georges Hill near Weybridge, Surrey.\n\nIn April 2004, The Land Is Ours occupied Castell Henllys, a tourist site with reconstructed Iron Age roundhouses, in protest at Pembrokeshire Coast National Park's decision to demolish That Roundhouse at nearby Brithdir Mawr.\n\nIn 2009, a group inspired by The Land Is Ours opened Kew Bridge Eco Village, a squat on land owned by property developers St George; this was evicted on 27 May 2010.\n\n"}
{"id": "199410", "url": "https://en.wikipedia.org/wiki?curid=199410", "title": "Thin-film transistor", "text": "Thin-film transistor\n\nA thin-film transistor (TFT) is a special kind of field-effect transistor made by depositing thin films of an active semiconductor layer as well as the dielectric layer and metallic contacts over a supporting (but non-conducting) substrate. A common substrate is glass, because the primary application of TFTs is in liquid-crystal displays (LCDs). This differs from the conventional transistor, where the semiconductor material typically \"is\" the substrate, such as a silicon wafer.\n\nTFTs can be made using a wide variety of semiconductor materials. A common material is silicon. The characteristics of a silicon-based TFT depend on the silicon's crystalline state; that is, the semiconductor layer can be either amorphous silicon, microcrystalline silicon, or it can be annealed into polysilicon.\n\nOther materials which have been used as semiconductors in TFTs include compound semiconductors such as cadmium selenide, or metal oxides such as zinc oxide or hafnium oxide. An application for hafnium oxide is as a high-κ dielectric. TFTs have also been made using organic materials, referred to as organic field-effect transistors or OTFTs.\n\nBy using transparent semiconductors and transparent electrodes, such as indium tin oxide (ITO), some TFT devices can be made completely transparent. Such transparent TFTs (TTFTs) can be used for construction of video display panels.\nBecause conventional substrates cannot withstand high annealing temperatures, the deposition process must be completed under relatively low temperatures. Chemical vapor deposition and physical vapor deposition (usually sputtering) are applied. The first solution-processed TTFTs, based on zinc oxide, were reported in 2003 by researchers at Oregon State University. The Portuguese laboratory CENIMAT at the Universidade Nova de Lisboa has produced the world's first completely transparent TFT at room temperature.\n\nThe best known application of thin-film transistors is in TFT LCDs, an implementation of LCD technology. Transistors are embedded within the panel itself, reducing crosstalk between pixels and improving image stability.\n\n, many color LCD TVs and monitors use this technology. TFT panels are frequently used in digital radiography applications in general radiography. A TFT is used in both direct and indirect capture as a base for the image receptor in medical radiography.\n\nAMOLED (active-matrix organic light-emitting diode) screens also contain a TFT layer.\n\nThe most beneficial aspect of TFT technology is its use of a separate transistor for each pixel on the display. Because each transistor is small, the amount of charge needed to control it is also small. This allows for very fast re-drawing of the display.\n\nThis picture does not include the actual light-source (usually cold-cathode fluorescent lamps or white LEDs), just the TFT-display matrix.\n"}
{"id": "29433051", "url": "https://en.wikipedia.org/wiki?curid=29433051", "title": "Tidal stream generator", "text": "Tidal stream generator\n\nA tidal stream generator, often referred to as a tidal energy converter (TEC), is a machine that extracts energy from moving masses of water, in particular tides, although the term is often used in reference to machines designed to extract energy from run of river or tidal estuarine sites. Certain types of these machines function very much like underwater wind turbines, and are thus often referred to as tidal turbines. They were first conceived in the 1970s during the oil crisis.\n\nTidal stream generators are the cheapest and the least ecologically damaging among the three main forms of tidal power generation.\n\nTidal stream generators draw energy from water currents in much the same way as wind turbines draw energy from air currents. However, the potential for power generation by an individual tidal turbine can be greater than that of similarly rated wind energy turbine. The higher density of water relative to air (water is about 800 times the density of air) means that a single generator can provide significant power at low tidal flow velocities compared with similar wind speed. Given that power varies with the density of medium and the cube of velocity, water speeds of nearly one-tenth the speed of wind provide the same power for the same size of turbine system; however this limits the application in practice to places where tide speed is at least 2 knots (1 m/s) even close to neap tides. Furthermore, at higher speeds in a flow between 2 and 3 metres per second in seawater a tidal turbine can typically access four times as much energy per rotor swept area as a similarly rated power wind turbine.\n\nNo standard tidal stream generator has emerged as the clear winner, among a large variety of designs. Several prototypes have shown promise with many companies making bold claims, some of which are yet to be independently verified, but they have not operated commercially for extended periods to establish performances and rates of return on investments.\n\nThe European Marine Energy Centre recognizes six principal types of tidal energy converter. They are horizontal axis turbines, vertical axis turbines, oscillating hydrofoils, venturi devices, Archimedes screws and tidal kites.\n\nThese are close in concept to traditional windmills, but operating under the sea. They have most of the prototypes currently operating, including:\n\nTocardo, a Dutch-based company, has been running tidal turbines since 2008 on the Afsluitdijk, near Den Oever. \nTypical production data of tidal generator shown\nof the T100 model as applied in Den Oever. Currently 1 River model (R1) and 2 tidal models (T) are in production with a 3rd T3 coming soon. Power production for the T1 is around 100 kW and around 200 kW for the T2.\n\nThe AR-1000, a 1MW turbine developed by Atlantis Resources Corporation that was successfully deployed at the EMEC facility during the summer of 2011. The AR series are commercial scale, horizontal axis turbines designed for open ocean deployment. AR turbines feature a single rotor set with fixed pitch blades. The AR turbine is rotated as required with each tidal exchange. This is done in the slack period between tides and held in place for the optimal heading for the next tide. AR turbines are rated at 1MW @ 2.65 m/s of water flow velocity.\n\nThe Kvalsund installation is south of Hammerfest, Norway. Although still a prototype, a turbine with a reported capacity of 300 kW was connected to the grid on 13 November 2003.\n\nSeaflow, a 300 kW Periodflow marine current propeller type turbine was installed by Marine Current Turbines off the coast of Lynmouth, Devon, England, in 2003. The 11m diameter turbine generator was fitted to a steel pile which was driven into the seabed. As a prototype, it was connected to a dump load, not to the grid.\n\nIn April 2007 Verdant Power began running a prototype project in the East River between Queens and Roosevelt Island in New York City; it was the first major tidal-power project in the United States. The strong currents pose challenges to the design: the blades of the 2006 and 2007 prototypes broke and new reinforced turbines were installed in September 2008.\n\nFollowing the Seaflow trial, a full-size prototype, called SeaGen, was installed by Marine Current Turbines in Strangford Lough in Northern Ireland in April 2008. The turbine began to generate at full power of just over 1.2 MW in December 2008 and is reported to have fed 150 kW into the grid for the first time on 17 July 2008, and has now contributed more than a gigawatt hour to consumers in Northern Ireland. It is currently the only commercial scale device to have been installed anywhere in the world. SeaGen is made up of two axial flow rotors, each of which drive a generator. The turbines are capable of generating electricity on both the ebb and flood tides because the rotor blades can pitch through 180˚.\n\nOpenHydro, an Irish company exploiting the Open-Centre Turbine developed in the U.S., has a prototype being tested at the European Marine Energy Centre (EMEC), in Orkney, Scotland.\nA prototype semi-submerged floating tethered tidal turbine called Evopod has been tested since June 2008 in Strangford Lough, Northern Ireland at 1/10 scale. The UK company developing it is called Ocean Flow Energy Ltd. The advanced hull form maintains optimum heading into the tidal stream and is designed to operate in the peak flow of the water column.\n\nIn 2010, Tenax Energy of Australia proposed to put 450 turbines off the coast of Darwin, Australia, in the Clarence Strait. The turbines would feature a rotor section approximately 15 metres in diameter with a slightly larger gravity base. The turbines would operate in deep water well below shipping channels. Each turbine is forecast to produce energy for between 300 and 400 homes.\n\nTidalstream, a UK-based company, commissioned a scaled-down Triton 3 turbine in the Thames. It can be floated to its site, installed without cranes, jack-ups or divers and then ballasted into operating position. At full scale the Triton 3 in 30-50m deep water has a 3MW capacity, and the Triton 6 in 60-80m water has a capacity of up to 10MW, depending on the flow. Both platforms have man-access capability both in the operating position and in the float-out maintenance position.\n\nInvented by Georges Darreius in 1923 and patented in 1929, these turbines can be deployed either vertically or horizontally.\n\nThe Gorlov turbine is a variant of the Darrieus design featuring a helical design that is in a large scale, commercial pilot in South Korea, starting with a 1MW plant that opened in May 2009 and expanding to 90MW by 2013. Neptune Renewable Energy's Proteus project employs a shrouded vertical axis turbine that can be used to form an array in mainly estuarine conditions.\n\nIn April 2008, the Ocean Renewable Power Company, LLC (ORPC) successfully completed testing its proprietary turbine-generator unit (TGU) prototype at ORPC's Cobscook Bay and Western Passage tidal sites near Eastport, Maine. The TGU is the core of the OCGen technology and uses advanced design cross-flow (ADCF) turbines to drive a permanent magnet generator located between the turbines and mounted on the same shaft. ORPC has developed TGU designs that can be used for generating power from river, tidal and deep water ocean currents.\n\nTrials in the Strait of Messina, Italy, started in 2001 of the Kobold turbine concept.\n\nUsing flow augmentation measures, for example a duct or shroud, the incident power available to a turbine can be increased. The most common example uses a shroud to increase the flow rate through the turbine, which can be either axial or crossflow.\n\nThe Australian company Tidal Energy Pty Ltd undertook successful commercial trials of efficient shrouded tidal turbines on the Gold Coast, Queensland in 2002. Tidal Energy delivered their shrouded turbine in northern Australia where some of the fastest recorded flows (11 m/s, 21 knots) are found. Two small turbines will provide 3.5 MW. Another larger 5 meter diameter turbine, capable of 800 kW in 4 m/s of flow, was planned as a tidal powered desalination showcase near Brisbane Australia.\n\nOscillating devices do not have a rotating component, instead making use of aerofoil sections which are pushed sideways by the flow. Oscillating stream power extraction was proven with the omni- or bi-directional Wing'd Pump windmill. During 2003 a 150 kW oscillating hydroplane device, the Stingray, was tested off the Scottish coast. The Stingray uses hydrofoils to create oscillation, which allows it to create hydraulic power. This hydraulic power is then used to power a hydraulic motor, which then turns a generator.\n\nPulse Tidal operate an oscillating hydrofoil device in the Humber Estuary. Having secured funding from the EU, they are developing a commercial scale device to be commissioned 2012.\n\nThe bioSTREAM tidal power conversion system, uses the biomimicry of swimming species, such as shark, tuna, and mackerel using their highly efficient Thunniform mode propulsion. It is produced by Australian company BioPower Systems.\n\nA 2 kW prototype relying on the use of two oscillating hydrofoils in a tandem configuration has been developed at Laval University and tested successfully near Quebec City, Canada, in 2009. A hydrodynamic efficiency of 40% has been achieved during the field tests.\n\nVenturi effect devices use a shroud or duct in order to generate a pressure differential which is used to run a secondary hydraulic circuit which is used to generate power. A device, the Hydro Venturi, is to be tested in San Francisco Bay.\n\nA tidal kite turbine is an underwater kite system or paravane that converts tidal energy into electricity by moving through the tidal stream. An estimated 1% of 2011's global energy requirements could be provided by such devices at scale.\nErnst Souczek of Vienna, Austria, on August 6, 1947, filed for a patent US2501696; assignor of one-half to Wolfgang Kmentt, also of Vienna. Their water kite turbine disclosure demonstrated a rich art in water-kite turbines. In similar technology, many others prior to 2006 advanced water-kite and paravane electric generating systems. In 2006, a tidal kite turbine was developed by Swedish company Minesto. They conducted its first sea trial in Strangford Lough in Northern Ireland in the summer of 2011. The test used kites with wingspan of 1.4m. \nIn 2013 the Deep Green pilot plant began operation off Northern Ireland. The plant uses carbon fiber kites with a wingspan of 8m (or 12m). Each kite has a rated power of 120 kilowatts at a tidal flow of 1.3 meters per second.\nMinesto's kite has a wingspan of . The kite has neutral buoyancy, so doesn't sink as the tide turns from ebb to flow. Each kite is equipped with a gearless turbine to generate which is transmitted by the attachment cable to a transformer and then to the electricity grid. The turbine mouth is protected to protect marine life.\nThe 14-meter version has a rated power of 850 kilowatts at 1.7 meters per second.\nThe kite is tethered by a cable to a fixed point. It \"flies\" through the current carrying a turbine. It moves in a figure-eight loop to increase the speed of the water flowing through the turbine tenfold. Force increases with the cube of velocity, offering the potential to generate 1,000-fold more energy than a stationary generator.\nThat maneuver means the kite can operate in tidal streams that move too slowly to drive earlier tidal devices, such as the SeaGen turbine.\nThe kite was expected to work in flows as low per second, while first-generation devices need over 2.5s. Each kite will have a capacity to generate between 150 and 800 kW. They can be deployed in waters deep.\n\nThere are a number of individuals and companies developing tidal energy converters across the world. A database of all know tidal energy developers is kept up-to-date here: Tidal energy developers\n\nThe world's first marine energy test facility was established in 2003 to kick start the development of the wave and tidal energy industry in the UK. Based in Orkney, Scotland, the European Marine Energy Centre (EMEC) has supported the deployment of more wave and tidal energy devices than at any other single site in the world. EMEC provides a variety of test sites in real sea conditions. Its grid connected tidal test site is located at the Fall of Warness, off the island of Eday, in a narrow channel which concentrates the tide as it flows between the Atlantic Ocean and North Sea. This area has a very strong tidal current, which can travel up to 4 m/s (8 knots) in spring tides. Tidal energy developers currently testing at the site include Alstom (formerly Tidal Generation Ltd), ANDRITZ HYDRO Hammerfest, OpenHydro, Scotrenewables Tidal Power, and Voith.\n\nRWE's npower announced that it is in partnership with Marine Current Turbines to build a tidal farm of SeaGen turbines off the coast of Anglesey in Wales, near the Skerries.\n\n\"The Skerries project located in Anglesey, Wales, will be one of the first arrays deployed using the Siemens owned Marine Current Turbines SeaGen S tidal turbines. The marine consent for the project was recently awarded, the first tidal array to be consented in Wales. The 10MW array will be fully operational in 2015.\" - CEO of Siemens Energy Hydro & Ocean Unit Achim Wörner\n\nIn November 2007, British company Lunar Energy announced that, in conjunction with E.ON, they would be building the world's first deep-sea tidal energy farm off the coast of Pembrokshire in Wales. It will provide electricity for 5,000 homes.\nEight underwater turbines, each 25 metres long and 15 metres high, are to be installed on the sea bottom off St David's peninsula. Construction is due to start in the summer of 2008 and the proposed tidal energy turbines, described as \"a wind farm under the sea\", should be operational by 2010.\n\nBritish Columbia Tidal Energy Corp. plans to deploy at least three 1.2 MW turbines in the Campbell River or in the surrounding coastline of British Columbia by 2009.\n\nAlderney Renewable Energy Ltd was granted a licence in 2008 and is planning to use tidal turbines to extract power from the notoriously strong tidal races around Alderney in the Channel Islands. It is estimated that up to 3 GW could be extracted. This would not only supply the island's needs but also leave a considerable surplus for export, using a France-Alderney-Britain cable (FAB Link) which is expected to go online by 2020.\n\nNova Scotia Power has selected OpenHydro's turbine for a tidal energy demonstration project in the Bay of Fundy, Nova Scotia, Canada and Alderney Renewable Energy Ltd for the supply of tidal turbines in the Channel Islands.\n\nPulse Tidal are designing a commercial device with seven other companies who are expert in their fields. The consortium was awarded an €8 million EU grant to develop the first device, which will be deployed in 2012 and generate enough power for 1,000 homes.\n\nScottishPower Renewables are planning to deploy ten 1MW HS1000 devices designed by Hammerfest Strom in the Sound of Islay.\n\nIn March 2014, the Federal Energy Regulatory Committee (FERC) approved a pilot license for Snohomish County PUD to install two OpenHydro tidal turbines in Admiralty Inlet, WA. This project is the first grid-connected two-turbine project in the US; installation is planned for the summer of 2015. The OpenHydro tidal turbines that Snohomish County PUD will use are designed to be placed directly into the seafloor at a depth of roughly 200 feet, so that there will be no effect on commercial navigation overhead. The license granted by the FERC also includes plans to protect fish, wildlife, as well as cultural and aesthetic resources, in addition to navigation. Each turbine measures 6 meters in diameter, and will generate up to 300 kW of electricity. In September 2014, the project was canceled due to cost concerns. \n\nTidal energy converters can have varying modes of operating and therefore varying power output. If the power coefficient of the device \"formula_1\" is known, the equation below can be used to determine the power output of the hydrodynamic subsystem of the machine. This available power cannot exceed that imposed by the Betz limit on the power coefficient, although this can be circumvented to some degree by placing a turbine in a shroud or duct. This works, in essence, by forcing water which would not have flowed through the turbine through the rotor disk. In these situations it is the frontal area of the duct, rather than the turbine, which is used in calculating the power coefficient and therefore the Betz limit still applies to the device as a whole.\n\nThe energy available from these kinetic systems can be expressed as:\n\nwhere:\n\nRelative to an open turbine in free stream, ducted turbines are capable of as much as 3 to 4 times the power of the same turbine rotor in open flow.\n\nWhile initial assessments of the available energy in a channel have focus on calculations using the kinetic energy flux model, the limitations of tidal power generation are significantly more complicated. For example, the maximum physical possible energy extraction from a strait connecting two large basins is given to within 10% by:\nwhere\n\nAs with wind power, selection of location is critical for the tidal turbine. Tidal stream systems need to be located in areas with fast currents where natural flows are concentrated between obstructions, for example at the entrances to bays and rivers, around rocky points, headlands, or between islands or other land masses. The following potential sites are under serious consideration:\n\n\nModern advances in turbine technology may eventually see large amounts of power generated from the ocean, especially tidal currents using the tidal stream designs but also from the major thermal current systems such as the Gulf Stream, which is covered by the more general term marine current power. Tidal stream turbines may be arrayed in high-velocity areas where natural tidal current flows are concentrated such as the west and east coasts of Canada, the Strait of Gibraltar, the Bosporus, and numerous sites in Southeast Asia and Australia. Such flows occur almost anywhere where there are entrances to bays and rivers, or between land masses where water currents are concentrated.\n\nThe main environmental concern with tidal energy is associated with blade strike and entanglement of marine organisms as high speed water increases the risk of organisms being pushed near or through these devices. As with all offshore renewable energies, there is also a concern about how the creation of EMF and acoustic outputs may affect marine organisms. It should be noted that because these devices are in the water, the acoustic output can be greater than those created with offshore wind energy. Depending on the frequency and amplitude of sound generated by the tidal energy devices, this acoustic output can have varying effects on marine mammals (particularly those who echolocate to communicate and navigate in the marine environment such as dolphins and whales). Tidal energy removal can also cause environmental concerns such as degrading farfield water quality and disrupting sediment processes. Depending on the size of the project, these effects can range from small traces of sediment build up near the tidal device to severely affecting nearshore ecosystems and processes.\n\nOne study of the Roosevelt Island Tidal Energy (RITE, Verdant Power) project in the East River (New York City), used 24 split beam hydroacoustic sensors (scientific echosounder) to detect and track the movement of fish both upstream and downstream of each of six turbines. The results suggested (1) very few fish using this portion of the river, (2) those fish which did use this area were not using the portion of the river which would subject them to blade strikes, and (3) no evidence of fish traveling through blade areas. \n\nWork is currently being conducted by the Northwest National Marine Renewable Energy Center (NNMREC)to explore and establish tools and protocols for assessment of physical and biological conditions and monitor environmental changes associated with tidal energy development.\n\n"}
{"id": "6517038", "url": "https://en.wikipedia.org/wiki?curid=6517038", "title": "Very large floating structure", "text": "Very large floating structure\n\nVery large floating structures (VLFSs) or very large floating platforms (VLFPs) are manmade islands, which may be constructed to create floating airports, bridges, breakwaters, piers and docks, storage facilities (for oil & natural gas), wind and solar power plants, for military purposes, to create industrial space, emergency bases, entertainment facilities (such as casinos), recreation parks, mobile offshore structures and even for habitation. Currently, several different concepts have been proposed for building floating cities or huge living complexes. Some units have been constructed and are presently in operation.\n\nFloating structures offer several advantages over more permanent structures which might extend from the shore into open water:\n\nVLFS differ from watercraft in that the usable area is the top surface instead of the internal (hold) areas. Thus a useful VLFS will cover significant area. It can be constructed by joining the necessary number of floating units together. The design of the floating structure must comport with safety and strength requirements, operating conditions, etc. Steel, concrete (prestressed or reinforced hybrid) or steel-concrete composite materials may be used to build the floating structure. The motion of the floating structure due to wind or wave action must be substantially neutralized, to ensure the safety of people and facilities on a VLFS, and to allow useful activities. VLFS must be securely moored to the ocean bed.\n\nCurrent designs for VLFS fall into two categories: semi-submersible, and pontoon.\n\nThe semi-submersible-type VLFS has a raised platform above sea level using column tubes; it is more suitable for deployment in high seas with large waves. In open sea, where the waves are relatively large, the semi-submersible VLFS minimizes the effects of waves while maintaining a constant buoyant force. Semi-submersible types are used for petroleum exploration in deep waters. They are fixed in place by column tubes, piles, or other bracing systems.\n\nThe pontoon-type VLFS platform rests on the water surface and is intended for deployment in calm waters such as a cove, a lagoon or a harbor. Its basic element is a simple box structure; it usually offers high stability, low manufacturing cost and easy maintenance and repair. The pontoon type is supported by its buoyancy on the sea surface. The pontoon type is flexible compared to other kinds of offshore structures, so that the elastic deformations are more important than their rigid body motions. Thus, hydroelastic analysis is uppermost in designing the pontoon-type VLFS. Together with the motion of the floating structure, the response of the structure to water waves and the impact on the entire fluid domain have to be studied.\n\nPontoon-type VLFS are also known in the literature as mat-like VLFS because of their small draft in relation to the length dimensions. Very large pontoon-type floating structures are often called \"Mega-Floats\". As a rule, the Mega-Float is a floating structure having at least one length dimension greater than 60 meters. Horizontally large floating structures can be from 500 to 5000 meters in length and 100 to 1000 meters in width, with typical thickness of 2 to 10 meters.\n\nAir-cushion supported Mega-Floaters are mega floaters that are supported by an air cushion. They were invented by Jan Van Kessel of TU Delft.\n\nMany large floating structures have been conceptualized, including a golf course,\na farm, and habitable long-term living complexes (seasteading).\n\nSome large floating structures that have been built include floating airports and floating landing platforms for returning rockets.\n\n, the largest offshore structure built is the \"Mega-Float\", a floating airport prototype that was constructed in Tokyo Bay from 1998 to 1999. It is one kilometer in length, and was primarily intended as a test vehicle, to research the loadings and responses of such installations. This project was substituted as a study project to provide more definite information about a proposed floating runway at Kansai International Airport, which was not built (an artificial island was instead constructed to support the runway).\n\nIn the 2010s, Space Exploration Technologies (SpaceX) contracted with a Louisiana shipyard to build a floating landing platform for reusable orbital launch vehicles. The platform had an approximately landing pad surface and was capable of precision positioning with diesel-powered azimuth thrusters so the platform can hold its position for launch vehicle landing. This platform was first deployed in January 2015 when SpaceX attempted a controlled descent flight test to land the first stage of Falcon 9 Flight 14 on a solid surface after it was used to loft a contracted payload toward Earth orbit. The platform utilizes GPS position information to navigate and hold its precise position. The rocket landing leg span is and must not only land within the -wide barge deck, but must also deal with ocean swells and GPS errors.\nSpaceX CEO Elon Musk first displayed a photograph of the \"autonomous spaceport drone ship\" in November 2014. The ship is designed to hold position to within , even under storm conditions.\n\nOn 8 April 2016, the first stage of the rocket that launched the Dragon CRS-8 spacecraft, successfully landed on the drone ship named \"Of Course I Still Love You,\" the first successful landing of a rocket booster on a floating platform.\n\n, Blue Origin is intending to make the first stage boosters of New Glenn be reusable, and recover launched boosters downrange on the Atlantic Ocean via a ship that is underway acting as a floating movable landing platform. The hydrodynamically-stabilized ship increases the likelihood of successful recovery in rough seas.\n\nThe Shell floating LNG plant is under construction to process and liquify offshore natural gas into liquified natural gas for transport and storage.\nThe Shell project is scheduled to begin processing gas in 2016.\n\n\n"}
{"id": "13588861", "url": "https://en.wikipedia.org/wiki?curid=13588861", "title": "Wartberg culture", "text": "Wartberg culture\n\nThe Wartberg culture (), sometimes: Wartberg group (\"Wartberggruppe\") or Collared bottle culture (\"Kragenflaschenkultur\") is a prehistoric culture from 3,600 -2,800 BC of the later Central European Neolithic. It is named after its type site, the Wartberg, a hill (306m asl) near Niedenstein-Kirchberg in northern Hesse, Germany.\n\nThe Wartberg culture is currently known to have a distribution in northern Hesse, southern Lower Saxony and western Thuringia; a southern extent as far as the Rhein-Main Region is possible, but not definitely proven at this point.\n\nThe term Wartberg culture describes a group of sites with similar characteristic finds from circa 3600-2800 BC. The Wartberg culture appears to be a regional development derived from Michelsberg and Baalberge culture antecedents. It is contemporary, and in contact, with Bernburg culture and Funnel Beaker (TRB). The Corded Ware and Single Grave cultures succeed it.\n\nIts best known sites are Wartberg, near Kirchberg, Hasenberg, a hill near Lohne, as well as Güntersberg and Bürgel, hills near Gudensberg (all of the above are located on basalt outcrops in the fertile Fritzlar basin), and from the Calden earthwork enclosure. Nearly all settlements identified so far are in hilltop locations: an enclosed site at Wittelsberg near Amöneburg is an exception. Virtually all the known settlements appear to have come into existence several hundred years after the development of Wartberg pottery (see below); early Wartberg settlement activity remains mostly unknown as yet.\n\nFinds from the Wartberg and its sister sites included fragmented bones, mainly of cattle, pig, sheep/goat and deer, but also of other wild animals, like bear or beaver; human bone fragments also occur in some of the settlements. Originally, the Wartberg (first excavated in the later 19th century) was interpreted as a cult place, but the remains of coarse handmade pottery and of mud wall cladding do suggest settlement activity.\n\nWartberg material is also found in a number of gallery graves (a type of megalithic tomb). Their connection with the Wartberg settlements was only recognised in the 1960s and 1970s, thus the tombs are sometimes treated separately as the Hessian-Westphalian stone cist group (\"Hessisch-Westfälische Steinkistengruppe\").\n\nThese include the tombs at Züschen near Fritzlar, at Lohra, at Naumburg-Altendorf, at Hadamar-Niederzeuzheim (now rebuilt in a park at Hachenburg), at Beselich-Niedertiefenbach, at Warburg, Rimbeck and at Grossenrode, as well as two tombs near the Calden enclosure. A tomb at Muschenheim near Münzenberg may also belong to the same type, as may a further one at Bad Vilbel near Frankfurt am Main which was destroyed after 1945.\nThe best known of these tombs are those of Züschen, Lohra, Niederzeuzzheim and Altendorf. They normally contained the inhumed remains of multiple individuals (the Altendorf tomb contained at least 250 people) of all ages and both sexes. Lohra is an exception insofar as there the dead were cremated. Gravegoods are scarce but include pottery (collared bottles), stone tools and animal bones, especially the jawbones of foxes, which may have played a totemic role. The Züschen tomb is also remarkable for the presence of rock art.\nSome of the tombs can be directly associated with nearby hilltop sites or settlements, that is, the Züschen tomb with the Hasenberg and the Calden tombs with the earthwork. According to the German archaeologist Waltraud Schrickel, the association with gallery graves suggests a west European influence, perhaps from the Paris Basin in France, where very similar tombs occur. The Wartberg tombs appear to start developing around 3400 BC, earlier than most of the known settlements.\n\nA loose distribution of standing stones occurs in northern Hesse and west Thuringia. Although their dates are unknown, their geographic spread appears to coincide with that of Wartberg material, perhaps suggesting a connection.\n\nThe Calden earthwork, a large enclosure northwest of modern Kassel, was built around 3700 BC. It is an irregular enclosure of two ditches and a palisade, encompassing an area of 14 hectares. The enclosure has five openings, perhaps comparable to British Causewayed enclosures. Although it can with some certainty be seen as derived from the Michelsberg tradition, material associated with its early phases suggests a close connection with early Wartberg. It appears to have been a tradition for several centuries to bury animal bones (food refuse?) and broken pots in pits dug into the partially filled-in earthwork ditches. The ditches also contain the remains of many human inhumations. This activity continued until circa 2000 BC and was particularly intensive during the Wartberg period. Two nearby graves postdate the earthwork by several centuries, but coincide with that activity. While the original function of the earthwork is not necessarily explained by these finds, it appears likely that at least during later phases of its use it had a ritual significance, perhaps connected with a cult of the dead.\nIn contrast, the enclosure around the settlement at Wittelsberg appears to be simply protective/defensive in nature.\n\nWartberg pottery is handmade and mostly very coarse. Typical shapes in the mid-4th millennium include saucepans with inturned rim and deep incisions, cups with strap handles, collared bottles (\"Kragenflaschen\"). The presence of pottery with deeply incised patterns as well as of clay drums suggest connections with the Funnel Beaker culture (TRB) of Central Germany.\nIn the later Wartberg, strap-handled cups, funnel beakers, varied bowls, large pots with holes below the rim and collared bottles occur. The frequent presence of collared bottles, not least in the tombs, is of special interest. The bottles are made with somewhat more care than other vessels; their very specific shape suggests a special function, often suggested to be connected with the storage of special material, like vegetable oil or sulphur, perhaps for healing purposes.\n\nSlate axes are very common, slate blades also occur. The Wartberg culture produced fine stone arrowheads with well defined tangs and \"wings\".\nA variety of bone tools, mainly points, has been found both in tombs and settlements.\n\nLittle can be said about the economy of the Wartberg group. The location of sites and certain finds suggest a broadly sedentary society susbsisting from agriculture and animal husbandry, but hunting may play a considerable economic role. The Wartberg area appears to be in general trade contact with its neighbouring regions.\n\nThe presence of earthworks and of collective tombs indicates different levels of collective effort, thus implying a considerable degree of social organisation.\n\nWartberg material is on display at the following museums:\n\n\n\n"}
{"id": "24896917", "url": "https://en.wikipedia.org/wiki?curid=24896917", "title": "Water engine", "text": "Water engine\n\nThe water engine is a positive-displacement engine, often closely resembling a steam engine with similar pistons and valves, that is driven by water pressure. The supply of water was derived from a natural head of water, the water mains, or a specialised high-pressure water supply such as that provided by the London Hydraulic Power Company. Water mains in the 19th century often operated at pressures of 30 to 40 psi, while hydraulic power companies supplied higher pressure water at anything up to 800 psi.\n\nThe term water motor () was more commonly applied to small Pelton wheel type turbines driven from a mains water tap (e.g. Whitney Water Motor), and mainly used for light loads, for example sewing machines.\n\nIn the nineteenth century, the terms \"hydraulic motor\" and \"hydraulic engine\" often implied reference to any motor driven by liquid pressure, including water motors and water engines used in hydropower, but today mentions of hydraulic motors, unless otherwise specified, usually refer more specifically to those that run on hydraulic fluid in the closed hydraulic circuits of hydraulic machinery.\n\nBecause water is incompressible, the valve gear of water engines is more complicated than that used in steam engines, and some water engines even had a small secondary engine solely to power the operation of their valves. Closing a valve too quickly can cause very large pressures to result, and pipework to explode (a phenomenon similar to water hammer), and in addition to valves designed to close slowly, many water engines used air chambers to provide some absorption of force by compressing the air in them.\n\nIt is unclear when or where water engines were invented, but it is possible that they were first used in the mines in central Germany; certainly such a device was described by Robert Fludd after he had visited Germany around 1600.\n\nDuring the 19th century water engines were extensively used in the city of London, operating on high-pressure water supplied by the London Hydraulic Power Company via its extensive network of pipes. Even when practical electric motors entered use, water engines remained popular for some years as they possessed several advantages: they were quiet, reliable, cheap to run, compact, safe, and could be relied on to operate reliably in damp or waterlogged conditions unsuited to electrical apparatus, such as powering water pumps in mines, where their ability to continue operating even while completely submerged was a major advantage.\n\nOther applications included usage by the railway companies, where they powered railway turntables, cranes, hoists, etc., revolving stages at the London Palladium and Coliseum Theatre, and powering pipe organs.\n\nThe largest possible design of a water engine is the directly acting water-column engine or water column machine (German: \"Wassersäulenmaschine\"). Such devices had been in use for pumping purposes in different mining areas since the middle of the eighteenth century and one was used, for example, by Georg Friedrich von Reichenbach in 1810 to pump brine from Berchtesgaden to Reichenhall. \n\nSimilar to the function of a hydraulic ram the water being admitted is transported by another medium. The differently-sized pistons of the water-column engine run on a single axle; its control loosely resembles that of a steam engine. Water-column engines were used in the transportation of brine, pumping it from one place to another. \n\nThe water engine was also successfully used in washing machines, e. g. from 1914 by the firm of Miele. These washing machines, which were very common especially in rural areas until the 1960s, comprised a wooden tub with a rotating cross built into the cover. This 'star handle' was rotated in regular, to and fro, movements by two pistons which were connected to the water mains. The washing effect was achieved by the constant movement of the washing in the washtub filled with soap suds (\"Lauge\") and/or water. \n\nThe large amount of water used was less important because plenty of used water was often available and was very cheap. In addition, in thrifty rural households the water used to drive it was often used for other purposes as well.\n\nA prerequisite for the correct function of the water engine was sufficient pressure in the water pipes. In times of high water consumption (before or after work) the water pressure was often insufficient. In hard winters, in which the water pipes often froze, the water engine could not be used. For these reasons the washing machines still had a device that enable them to be rotated by 'muscle power'.\n\nWith the invention of the modern washing machine these washtubs with their water engines disappeared from the market.\n\n"}
{"id": "6924052", "url": "https://en.wikipedia.org/wiki?curid=6924052", "title": "Wax fire", "text": "Wax fire\n\nA wax fire is created when melted or boiling wax is doused in water. The ensuing reaction creates a large fireball or enlarges the flame of the already existing fire incredibly. Only a small amount of wax and water is needed to create a wax fire.\n\nFollowing the basic rules of the fire triangle, for a reaction to take place three ingredients are required: oxygen, fuel, and heat. In the case of wax melted down, only the top surface has access to oxygen, so the fire progresses slowly. When water is added to the wax, two things happen. Firstly, the water — being denser than wax — sinks to the bottom of the container. Secondly, as burning wax quickly reaches a temperature of well over 200 degrees C, the water instantly vapourises. When water changes from a liquid to a gas, there is more than a thousand-fold increase in volume. The water expands violently, and throws the hot wax layer above it into the air as small droplets. The wax now has a much bigger surface area exposed to oxygen so combustion takes place very quickly.\n\nFor similar reasons, water should never be used to extinguish burning grease or fat, which both behave similarly to wax. Water is ineffective at putting out other flammable liquid fires, but in most liquids (e.g. petrol), the water remains as a liquid, and spreads the fire by allowing the liquid to float and burn on top of it. One should instead use baking soda to extinguish a wax fire.\n\n\n"}
{"id": "24630880", "url": "https://en.wikipedia.org/wiki?curid=24630880", "title": "Wright-Hennepin Cooperative Electric Association", "text": "Wright-Hennepin Cooperative Electric Association\n\nWright-Hennepin Cooperative Electric Association (WH) is a non-profit, member-owned energy and service cooperative located in Rockford, Minnesota. The company serves more than 45,000 electric accounts in western Hennepin County, Minnesota and most of Wright County, Minnesota.\n\nIn 1937 farmers in rural Wright and western-Hennepin counties tried to get electricity to their homes. The investor-owned utilities would not work with them because they couldn’t profitably serve the rural area, where homes and businesses were further apart and more equipment investments would need to be made.\n\nAfter that rejection, the farmers joined together and created an electric cooperative. Each person who joined WH became a \"member\" and took one share of ownership of the cooperative. Nine members are elected to serve on the Board of Directors. They determine the cooperative's strategic direction, provide financial oversight, set electric rates, and provide other governance for the cooperative.\n\n"}
{"id": "19262028", "url": "https://en.wikipedia.org/wiki?curid=19262028", "title": "ZZ diboson", "text": "ZZ diboson\n\nZZ dibosons are rare pairs of Z bosons. They were first observed by the experiments at the Large Electron–Positron Collider (ALEPH, DELPHI, L3 and OPAL). The first observation in a hadron collider was made by the scientists of DØ collaboration at Fermilab. They are force-carrying particles produced in proton–antiproton collisions at the Tevatron, the world’s second highest-energy particle accelerator (after the CERN Large Hadron Collider). The observation of the ZZ dibosons was announced at a Fermilab seminar on 30 July 2008.\n\nThe rarest diboson processes after ZZ dibosons are those involving the Higgs boson, so seeing ZZ diboson is an essential step in demonstrating the ability to see the Higgs boson. ZZ dibosons are the latest in a series of observations of pairs of gauge bosons (force-carrying particles) by DØ and its sister experiment CDF (also at Tevatron).\n\nFinal analysis of the data for this discovery was done by a team of international researchers including scientists of American, Belgian, British, Georgian, Italian, and Russian nationalities. The observations began with the study of the already-rare production of W bosons plus photons (); then Z bosons plus photons (); then observation of W pairs (); then a mix of W and Z boson (). The ZZ () is the combination which has the lowest predicted likelihood of production in the Standard Model due to the smaller couplings.\n\n\n"}
