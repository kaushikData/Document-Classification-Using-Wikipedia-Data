{"id": "22878312", "url": "https://en.wikipedia.org/wiki?curid=22878312", "title": "Allotropes of boron", "text": "Allotropes of boron\n\nBoron can be prepared in several crystalline and amorphous forms. Well known crystalline forms are α-rhombohedral, β-rhombohedral, and β-tetragonal. In special circumstances, boron can also be synthesized in the form of its α-tetragonal and γ-orthorhombic allotropes. Two amorphous forms, one a finely divided powder and the other a glassy solid, are also known. Although at least 14 more allotropes have been reported, these other forms are based on tenuous evidence or have not been experimentally confirmed, or are thought to represent mixed allotropes, or boron frameworks stabilized by impurities. Whereas the β-rhombohedral phase is the most stable and the others are metastable, the transformation rate is negligible at room temperature, and thus all five phases can exist at ambient conditions. Amorphous powder boron and polycrystalline rhombohedral β-boron are the most common forms. The latter allotrope is a very hard grey material, about ten percent lighter than aluminium and with a melting point (2080 °C) several hundred degrees higher than that of steel.\n\nElemental boron has been found in star dust and meteorites but does not exist in the high oxygen environment of Earth. It is difficult to extract from its compounds. The earliest methods involved reduction of boric oxide with metals such as magnesium or aluminium. However, the product is almost always contaminated with metal borides. Pure boron can be prepared by reducing volatile boron halides with hydrogen at high temperatures. Very pure boron, for use in semiconductor industry, is produced by the decomposition of diborane at high temperatures, followed by purification via zone melting or the Czochralski process. Even more difficult to prepare are single crystals of pure boron phases, due to polymorphism and the tendency of boron to react with impurities; typical crystal size is ~0.1 mm.\n\nα-rhombohedral boron has a unit cell of twelve boron atoms. The structure consists of icosahedra in which each boron atom has five nearest neighbors within the icosahedron. If the bonding were the conventional covalent type then each boron would have donated five electrons. However, boron has only three valence electrons, and it is thought that the bonding in the icosahedra is achieved by the so-called 3-center electron-deficient bonds where the electron charge is accumulated at the center of a triangle formed by three adjacent atoms.\n\nThe isolated icosahedra are not stable; thus boron is not a molecular solid, but the icosahedra in it are connected by strong covalent bonds.\n\nPure α-tetragonal can only be synthesized as thin layers deposited on an underlying substrate of isotropic boron carbide (BC) or nitride (BN). Most examples of α-tetragonal boron are in fact boron-rich carbide or nitrides.\n\nβ-rhombohedral boron has a unit cell containing 105–108 atoms. Most atoms form B discrete icosahedra; a few form partially interpenetrating icosahedra, and there are two deltahedral B units, and a single central B atom. For a long time, it was unclear whether the α or β phase is most stable at ambient conditions; however, gradually a consensus was reached that the β phase is the most thermodynamically stable allotrope.\nThe β phase was produced in 1960 by hydrogen reduction of BBr on hot tungsten, rhenium or tantalum filaments at temperatures 1270–1550 °C (i.e. chemical vapor deposition). Further studies have reproduced the synthesis and confirmed the absence of impurities in this phase.\nThe γ-phase can be described as a NaCl-type arrangement of two types of clusters, B icosahedra and B pairs. It can be produced by compressing other boron phases to 12–20 GPa and heating to 1500–1800 °C, and remains stable at ambient conditions. There is evidence of significant charge transfer from B pairs to the B icosahedra in this structure; in particular, lattice dynamics suggests the presence of significant long-range electrostatic interactions.\n\nThis phase was reported by Wentorf in 1965, however neither structure nor chemical composition were established. The structure was solved using \"ab initio\" crystal structure prediction calculations and confirmed using single crystal X-ray diffraction.\n\nSullenger \"et al.\" (1969) and McConville \"et al.\" (1976) reported a cubic allotrope of boron, obtained in argon plasma experiments, with a unit cell of 1705±3 atoms and a density of 2.367 g/cm. While this allotrope is occasionally mentioned in the literature, no subsequent work appears to have been published either confirming or discrediting its existence. Donohue (1982) commented that the number of atoms in the unit cell did not appear to be icosahedrally related (the icosahedron being a motif common to boron structures).\nCompressing boron above 160 GPa produces a boron phase with an as yet unknown structure. Contrary to other phases, which are semiconductors, this phase is a metal and becomes a superconductor with a critical temperature increasing from 4 K at 160 GPa to 11 K at 250 GPa. This structural transformation occurs at pressures at which theory predicts the icosahedra will dissociate. Speculation as to the structure of this phase has included face-centred cubic (analogous to Al); α-Ga, and body-centred tetragonal (analogous to In). It has also been suggested that the nonmetal-metal transition is simply the result of a band gap closure, as occurs with iodine, rather than a structural transition.\n\nThere exist several two-dimensional forms of boron (together called borophenes), and even more are predicted theoretically.\n\nThe discovery of the quasispherical allotropic molecule borospherene (B) was announced in July 2014.\n\nAmorphous boron contains B regular icosahedra that are randomly bonded to each other without long range order. Pure amorphous boron can be produced by thermal decomposition of diborane at temperatures below 1000 °C. Annealing at 1000 °C converts amorphous boron to β-rhombohedral boron. Amorphous boron nanowires (30–60 nm thick) or fibers can be produced by magnetron sputtering and laser-assisted chemical vapor deposition, respectively; and they also convert to β-rhombohedral boron nanowires upon annealing at 1000 °C.\n\n"}
{"id": "3158658", "url": "https://en.wikipedia.org/wiki?curid=3158658", "title": "Banat Air Flight 166", "text": "Banat Air Flight 166\n\nBanat Air Flight 166 was an Antonov Antonov An-24 (registration ) chartered on 13 December 1995 from Romavia by Banat Air.\n\nIt was due to fly from Verona, Italy, to Timişoara, Romania, when it crashed shortly after take-off, killing all eight crewmembers and 41 passengers. It later emerged that the aircraft was severely overloaded and its wings were contaminated with ice and snow. The accident was the 116th loss of an Antonov 24.\n\nWhilst parked in parking spot B6 at Verona-Villafranca Airport, snow fell continuously and the outside temperature was 0 °C. After forty-one passengers boarded Flight 166 to Romania, the pilot declined to have the plane deiced. At just past 19:30 local time, the aircraft taxied to the end of runway 23; however heavy traffic delayed the departure.\n\nWhen the Banat Air flight was cleared for takeoff, the outside temperature was below the freezing point. Shortly after lifting off, the aircraft reached its maximum speed. Banking to the right, the airspeed dropped dramatically, and so the pilot applied nose down elevator, causing the speed to increase again. Continuing their right hand bank, the flight crew again applied nose up elevator. The speed then dropped significantly, and the plane banked at sixty seven degrees. The pilots were unable to regain control of the plane and it struck the ground right-wing first, breaking up and bursting into flames.\n\nInvestigators concluded that there were multiple causes for the accident, including the disruption of airflow over the wings due to ice formation on the wings, due to the plane taking off without being de-iced. They also determined that spatial disorientation and the plane being overloaded by about 2000 kilograms played key parts in the accident.\n\n\n"}
{"id": "8968249", "url": "https://en.wikipedia.org/wiki?curid=8968249", "title": "Biofuel policy of Malaysia", "text": "Biofuel policy of Malaysia\n\nThe biofuel policy of Malaysia is documented in Malaysia's National Biofuel Policy document.\n\nYanmar, a Japan-based global manufacturer of diesel engines planned to build a research facility in Malaysia to conduct research on the development of palm oil biodiesel. It plans to develop and test biodiesel for the industrial diesels it develops for its machines and generators. The research facility will be set up in Kota Kinabalu.\n\nIn 2014, after many delays Malaysia began the introduction in the sale of B5 biodiesel in most petrol stations around the country. This would be eventually replaced by B7 in late 2015.\n"}
{"id": "58573773", "url": "https://en.wikipedia.org/wiki?curid=58573773", "title": "Bioinspiration", "text": "Bioinspiration\n\nBioinspiration is the development of novel materials, devices, and structures inspired by biological evolution and refinement which has occurred over millions of years. The goal is to improve modeling and simulation of the biological system to attain a better understanding of the nature's critical structural features, such as a wing, for use in future bioinspired designs. Bioinspiration differs from biomimicry in that the latter aims to precisely replicate the designs of biological materials. Bioinspired research is a return to the classical origins of science: it is a field based on observing the remarkable functions that characterize living organisms, and trying to abstract and imitate those functions.\n\nIdeas in science and technology often arise from studying nature. In the 16 and 17 century, G. Galilei, J. Kepler and I. Newton studied the motion of the sun and the planets and developed the first empirical equation to describe gravity. A few years later, M. Faraday and J. C. Maxwell derived the fundamentals of electromagnetism by examining interactions between electrical currents and magnets. The studies of heat transfer and mechanical work lead to the understanding of thermodynamics. However, quantum mechanics originated from the spectroscopic study of light. Current objects of attention are originated in chemistry but the most abundant of them are found in biology, e.g. the study of genetics, characteristics of cells and the development of higher animals and disease.\n\nBio-inspiration is a solidly established strategy in the field of chemistry, but it is not a mainstream approach. Especially, this research is still developing its scientific and technological systems, on academic and industrial levels. \n\nThis field dates back from the 1980s but in the 2010s, many natural phenomena have not been studied.,\n\nBio-inspired research is quite different from chemistry research. This research does not focus on complexity and microscopic things like molecular structure. It is based on observing and understanding the functions from the products of biological evolution.\n\nThere are various kinds of organisms and many different strategies that have proved successful in biology at solving some functional problem. Some kinds of high-level bio functions may seem simple, but they are supported by many layers of underlying structures, processes, molecules and their elaborate interaction. There is no chance to run out of phenomena for bio-inspired research.\n\nOften, bio-inspired research about something can be much easier than precisely replicating the source of inspiration. For example, researchers do not have to know how a bird flies to make an airplane.\n\nBio-inspiration returns to observation of nature as a source of inspiration for problem-solving and make it part of a grand tradition. The simplicity of many solutions emerge from a bio-inspired strategy, combined with the fact that different geographical and cultural regions have different types of contact with animals, fish, plants, birds and even microorganisms. This means different regions will have intrinsic advantages in areas in which their natural landscape is rich. So bio-inspired research is trans-cultural field.\n\nThere are many technical applications available nowadays that are bioinspired. However, this term should not be mixed up with biomimicry. For example, an airplane in general is bioinspired by birds. The wing tips of an airplane are biomimetic because its original function of minimizing turbulence and therefore needing less energy to fly, is not changed or improved compared to nature's original. Also, Nano 3D printing method is also one of the novel method for bioinspiration. Plants and animals have particular properties which are often related to their composition of nano- and micro surface structures. Many research have already been tried to mimic \"Salvinia molesta\" leaves for superhydrophobicity, gecko's toes which increase the amount of attractive Van der Waals force that lead to adhesiveness even on slippery surfaces, and moth antennae which inspire a new approach to detect chemical leaks, drugs and explosives.\n"}
{"id": "146320", "url": "https://en.wikipedia.org/wiki?curid=146320", "title": "Birmingham Dribbler", "text": "Birmingham Dribbler\n\nBirmingham Dribbler or carpet railway describes a type of very early model railway. It is a bit of a misnomer, as the railway featured a model live steam railway locomotive, but no track – the locomotive was simply run across the floor. In some cases, the front wheels were even made steerable so that they could be run in a circle without track. They first appeared in the 1840s and became very popular Victorian model railway toys.\n\nThe steam locomotives were very simple, usually made in brass, with a pair of simple oscillating cylinders driving the main wheels. They were basically a boiler mounted on wheels, although simple decoration (usually bands of lacquer) was sometimes applied. Track was not used – the boiler was filled with water, the burner lit, and when steam was being produced, the locomotive was placed on the floor and allowed to run until either the water or fuel ran out or the engine crashed into the furniture. Very quickly, after a number had exploded, simple safety valves were fitted.\n\nThey quickly gained the nickname of Birmingham Dribblers (or sometimes \"Piddlers\"), as large numbers of them were made in Birmingham, England, and they had the unfortunate habit of leaving a trail of water behind them as they ran across the floor. Very often this trail would be mixed with the fuel used for the burner, and there were numerous incidents of fires caused by the locomotive crashing into furniture and over-turning so that the burning fuel was spilled over the floor. As time passed, embellishments were added, such as wooden buffer beams, buffers and steam whistles.\n\nNot all Birmingham Dribblers are Victorian antiques. In the late 1970s to 1990s, a brass, self-assembly kit for a Birmingham Dribbler model was manufactured by Maxwell Hemmens Precision Steam Models of Yorkshire, UK. Completed models are still available from John Hemmens.\n"}
{"id": "2870697", "url": "https://en.wikipedia.org/wiki?curid=2870697", "title": "Bisulfite", "text": "Bisulfite\n\nBisulfite ion (IUPAC-recommended nomenclature: hydrogen sulfite) is the ion HSO. Salts containing the HSO ion are termed bisulfites also known as sulfite lyes. For example, sodium bisulfite is NaHSO.\n\nSome evidence may suggest that the proton in bisulfite ion is located on sulfur, giving rise to \"C\" symmetry. There is, however, some evidence from O NMR spectroscopy to suggest that two tautomeric forms of HSO exist in dynamic equilibrium, one which has the proton attached to sulfur (HSO) and one which is protonated at oxygen (HOSO). The \"C\" structure is supported by X-ray crystallography and, in aqueous solution, by Raman spectroscopy (ν(S–H) = 2500 cm).\n\nBisulfite salts are typically prepared by treatment of alkaline solutions with excess sulfur dioxide:\n\nHSO is the conjugate base of sulfurous acid, HSO:\nSulfurous acid is not an isolable compound and does not appear to exist in solution either. An equilibrium that is much more consistent with spectroscopic evidence is given :\n\nHSO is a weak acidic species with a p\"K\" of 6.97. Its conjugate base is the sulfite ion, SO:\n\nBisulfites are reducing agents, as are all sulfites and sulfur dioxide, which contains sulfur in the same oxidation state (+4).\n\nBisulfite salts are common additives to the drug epinephrine in order to prevent its oxidation to adrenochrome and resulting inactivation. Bisulfites can sometimes cause an allergic reaction. This is different from the common sulfa drugs allergy. The quantity of bisulfite in medical pain blockers that initiates Type 1 hypersensitivity has been determined by Fraser and Huang.\n\n"}
{"id": "2314331", "url": "https://en.wikipedia.org/wiki?curid=2314331", "title": "Blast gate", "text": "Blast gate\n\nBlast gates are gate valves used to focus a dust collection system's vacuum pressure for maximum dust (or other material) extraction at the desired location. Blast gates are positioned near individual pieces of machinery and operate by being, by default, closed — blocking air flow. When one blast gate is opened, all available suction is focused at that location, maximizing the amount of material collected.\n\nNote that in larger dust collection system installations with more available power, multiple blast gates may be opened at the same time without detriment to collection abilities at individual locations. In fact, some systems are so powerful that at least one blast gate \"must\" be open at all times, or the system can collapse itself.\n"}
{"id": "5044345", "url": "https://en.wikipedia.org/wiki?curid=5044345", "title": "Burgas–Alexandroupoli pipeline", "text": "Burgas–Alexandroupoli pipeline\n\nThe Burgas–Alexandroupoli pipeline was a proposed oil pipeline project for transportation of Russian and Caspian oil from the Bulgarian Black Sea port of Burgas to the Greek Aegean port of Alexandroupoli. It was seen as an alternative route for Russian oil, bypassing the Bosporus and the Dardanelles. However, in December 2011 the project was suspended by the Bulgarian government due to environmental and supply concerns.\n\nThe pipeline project was proposed in 1993–1994 by several Russian and Greek companies. In 1994, for construction of the pipeline Greece and Bulgaria signed a bilateral agreement, followed by a memorandum of cooperation, signed by Greece and Russia.\n\nIn February 1998, a Greek consortium for pipeline construction named Bapline was established, and in May 1998, a memorandum of creation of the Transbalkan Oil Pipeline Company was signed. In 2000, a technical specifications and an economic evaluation of the project were prepared by the German company ILF.\n\nA joint protocol for preparing the pipeline's construction was signed by the three countries in January 2005. The political memorandum between governments was signed on 12 April 2005. An inter-governmental agreement on the project was agreed on 7 February 2007, and it was signed on 15 March 2007 in Athens, by the relevant ministers of the three countries, in the presence of their leaders, Vladimir Putin (Russian president), Sergey Stanishev (Bulgarian prime-minister), and Kostas Karamanlis (prime-minister of Greece). The agreement establishing the international project company was signed in Moscow on 18 December 2007 and the company—Trans-Balkan Pipeline B.V.—was incorporated in the Netherlands on 6 February 2008.\n\nConstruction of the pipeline was scheduled to start in October 2009, and was estimated to be completed by 2011. However, the project was delayed as the Bulgarian government coming to power in July 2009 started to reconsider its participation in the project. On 19 October 2009, Italy, Russia and Turkey signed an inter-governmental agreement agreeing the participation of Russian oil companies in the competing Samsun-Ceyhan pipeline project. On 11 June 2010, Prime Minister of Bulgaria Boyko Borisov announced that Bulgaria would not participate in the project to due strong opposition from the local population of Burgas. Later it was said that the government would await an environmental impact assessment before making a final decision about termination of the project. On 7 December 2011, the Bulgarian government officially decided to terminate its participation in the project and proposed that the tripartite inter-governmental agreement be terminated by mutual consent.\n\nThe main pipeline with a diameter of would be long, and it would transport 15-23 million tons of oil per year during the first phase, as well as 35 million during the second. The pipeline would have three oil refilling stations, two of which in Bulgaria (the first one at Neftochim close to Burgas) and one at Alexandroupoli. The project included reconstruction of Burgas and Alexandroupolis terminals, including oil tanks with a capacity of 600,000 tons in Burgas, and 1,200,000 tons in Alexandroupolis.\n\nThe pipeline was expected to cost up to €1 billion. The investment scheme was not agreed, and it was not decided from which sources the pipeline would be filled.\n\nThe pipeline was to be constructed and owned by the Dutch-registered Trans-Balkan Pipeline B.V. In this company, a stake of 51% of shares belongs to the Burgas–Alexandroupolis Pipeline Consortium, a joint venture of Russian Transneft, Rosneft and Gazprom Neft. Bulgarian Burgas–Alexandroupolis Project Company-BG, a subsidiary of Technoexportstroy, owns 24.5% of shares. Greece consortium HELPE S.A. - THRAKI S.A., a joint venture between Hellenic Petroleum and Thraki, which is owned by Prometheus Gas and the Latsis Group, owns 23.5%, while the Government of Greece has 1%.\n\nThere were speculations that the part of Bulgarian and Hellenic stakes could be sold to other oil companies as Chevron, TNK-BP and KazMunayGas. Also Andrei Dementyev, a deputy industry and energy minister of Russia, has proposed that Kazakhstani KazMunayGas and other shareholders of the Caspian Pipeline Consortium could get a stake in the project. Kazakhstan's Energy Minister Baktykozha Izmukhambetov had said that Kazakhstan wants to buy a stake in the pipeline consortium.\n\nThere were several competitive pipeline projects, such as the AMBO pipeline from Burgas to Vlorë, Pan-European Pipeline from Constanţa to Trieste, Odessa-Brody-Plotsk pipeline, Kiykoy-Ibrice pipeline, and Samsun-Ceyhan pipeline — all aimed to transport oil from the Black Sea bypassing Turkish straits. The project of the Burgas–Alexandroupoli pipeline was described as one of the shortest pipeline through a plain terrain and therefore to be one of the cheapest and cost effective. The critics of the Burgas–Alexandroupoli pipeline project raised environmental concerns because of oil tankers traffic in the Aegean Sea, which contains numerous submerged rocks and island populations dependent on tourism and fishing. It has been mentioned that a possible oil spill in the Aegean would be devastating for Greece's tourism industry. The residents of Burgas and Sozopol in Bulgaria voted against in the pipeline in local referendums in the spring of 2008.\n\n"}
{"id": "56115043", "url": "https://en.wikipedia.org/wiki?curid=56115043", "title": "Chandrasekhar-Kendall function", "text": "Chandrasekhar-Kendall function\n\nChandrasekhar-Kendall functions are the axisymmetric eigenfunctions of the curl operator, derived by Subrahmanyan Chandrasekhar and P.C. Kendall in 1957, in attempting to solve the force-free magnetic fields. The results were independently derived by both, but were agreed to publish the paper together.\n\nIf the force-free magnetic field equation is written as formula_1 with the assumption of divergence free field (formula_2), then the most general solution for axisymmetric case is\n\nwhere formula_4 is a unit vector and the scalar function formula_5 satisfies the Helmholtz equation, i.e.,\n\nThe same equation also appears in fluid dynamics in Beltrami flows where, vorticity vector is parallel to the velocity vector, i.e., formula_7.\n\nTaking curl of the equation formula_1 and using this same equation, we get\n\nIn the vector identity formula_10, we can set formula_2 since it is solenoidal, which leads to a vector Helmholtz equation,\n\nEvery solution of above equation is not the solution of original equation, but the converse is true. If formula_5 is a scalar function which satisfies the equation \nformula_6, then the three linearly independent solutions of the vector Helmholtz equation are given by\n\nwhere formula_4 is a fixed unit vector. Since formula_17, it can be found that formula_18. But this is same as the original equation, therefore formula_19, where formula_20 is the poloidal field and formula_21 is the toroidal field. Thus, substituting formula_21 in formula_20, we get the most general solution as\n\nTaking the unit vector in the formula_25 direction, i.e., formula_26, with a periodicity formula_27 in the formula_25 direction with vanishing boundary conditions at formula_29, the solution is given by\n\nwhere formula_31 is the Bessel function, formula_32, the integers formula_33 and formula_34 is determined by the boundary condition formula_35 The eigenvalues for formula_36 has to be dealt separately.\nSince here formula_26, we can think of formula_25 direction to be toroidal and formula_39 direction to be poloidal, consistent with the convention.\n\n"}
{"id": "45748", "url": "https://en.wikipedia.org/wiki?curid=45748", "title": "Chariot", "text": "Chariot\n\nA chariot is a type of carriage driven by a charioteer, usually using horses to provide rapid motive power. Chariots were used by armies as transport or mobile archery platforms, for hunting or for racing, and as a conveniently fast way to travel for many ancient people.\n\nThe word \"chariot\" comes from the Latin term carrus, a loanword from Gaulish. A chariot of war or one used in military parades was called a \"car\". In ancient Rome and some other ancient Mediterranean civilizations, a \"biga\" required two horses, a \"triga\" three, and a \"quadriga\" four.\n\nThe chariot was a fast, light, open, two-wheeled conveyance drawn by two or more horses that were hitched side by side, and was little more than a floor with a waist-high guard at the front and sides. It was initially used for ancient warfare during the Bronze and Iron Ages; but, after its military capabilities had been superseded by cavalry, as horses were gradually bred to be bigger, the chariot was used for travel, in processions, for games, and in races.\n\nThe critical invention that allowed the construction of light, horse-drawn chariots was the spoked wheel. The earliest spoke-wheeled chariots date to ca. 2000 BC. The use of chariots peaked around 1300 BC (see Battle of Kadesh). Chariots had lost their military importance by the 1st century AD, but chariot races continued to be popular in Constantinople until the 6th century.\n\nHorses were introduced to Transcaucasia at the time of the Kura-Araxes culture, beginning about 3300 BC. (Archeologists have not found earlier horse bones in the area.) During the Kura-Araxes period, horses seem to become quite widespread, with signs of domestication.\n\nThe domestication of the horse was an important step toward civilization. An increasing amount of evidence supports the hypothesis, that horses were domesticated in the Eurasian Steppes (Dereivka in Ukraine) approximately 4000-3500 BC.\n\nThe invention of the wheel used in transportation most likely took place in Mesopotamia or the Eurasian steppes in modern-day Ukraine. Evidence of wheeled vehicles appears from the mid 4th millennium BC near-simultaneously in the Northern Caucasus (Maykop culture), and in Central Europe. The earliest vehicles may have been ox carts.\n\nStarokorsunskaya kurgan in the Kuban region of Russia contains a wagon grave (or chariot burial) of the Maikop Culture (which also had horses). The two solid wooden wheels from this kurgan have been dated to the second half of the fourth millennium. Soon thereafter the number of such burials in this Northern Caucasus region multiplied.\n\nAs David Anthony writes in his book The Horse, the Wheel and Language, in Eastern Europe, the earliest well-dated depiction of a wheeled vehicle (a wagon with two axles and four wheels) is on the Bronocice pot (c. 3500 BC). It is a clay pot excavated in a Funnelbeaker settlement in Swietokrzyskie Voivodeship in Poland.\n\nThe oldest securely dated real wheel-axle combination in Eastern Europe is the Ljubljana Marshes Wheel (c. 3150 BC).\n\nThe earliest records of chariots are the arsenal inventories of the palatial centres in Mycenaean Greece, as described in Linear B tablets from the 15th-14th centuries BC. The tablets distinguish between \"assembled\" and \"dismantled\" chariots.\n\nThe latter Greeks of the first millennium BC had a (still not very effective) cavalry arm, and the rocky terrain of the Greek mainland was unsuited for wheeled vehicles. Consequently, in historical Greece the chariot was never used to any extent in war. Nevertheless, the chariot retained a high status and memories of its era were handed down in epic poetry. Linear B tablets from Mycenaean palaces record large inventories of chariots, sometimes with specific details as to how many chariots were assembled or not (i.e. stored in modular form). Later the vehicles were used in games and processions, notably for races at the Olympic and Panathenaic Games and other public festivals in ancient Greece, in \"hippodromes\" and in contests called \"agons\". They were also used in ceremonial functions, as when a \"paranymph\", or friend of a bridegroom, went with him in a chariot to fetch the bride home.\n\nHerodotus (\"Histories\", 5. 9) Reports that chariots were widely used in the Pontic–Caspian steppe by the Sigynnae.\n\nGreek chariots were made to be drawn by two horses attached to a central pole. If two additional horses were added, they were attached on each side of the main pair by a single bar or \"trace\" fastened to the front or \"prow\" of the chariot, as may be seen on two prize vases in the British Museum from the Panathenaic Games at Athens, Greece, in which the driver is seated with feet resting on a board hanging down in front close to the legs of the horses. The biga itself consists of a seat resting on the axle, with a rail at each side to protect the driver from the wheels. Greek chariots appear to have lacked any other attachment for the horses, which would have made turning difficult.\n\nThe body or \"basket\" of the chariot rested directly on the axle (called \"beam\") connecting the two wheels. There was no suspension, making this an uncomfortable form of transport. At the front and sides of the basket was a semicircular guard about 3 ft (1 m) high, to give some protection from enemy attack. At the back the basket was open, making it easy to mount and dismount. There was no seat, and generally only enough room for the driver and one passenger.\n\nThe reins were mostly the same as those in use in the 19th century, and were made of leather and ornamented with studs of ivory or metal. The reins were passed through rings attached to the collar bands or yoke, and were long enough to be tied round the waist of the charioteer to allow for defense.\n\nThe wheels and basket of the chariot were usually of wood, strengthened in places with bronze or iron. They had from four to eight spokes and tires of bronze or iron. Due to the widely spaced spokes, the rim of the chariot wheel was held in tension over comparatively large spans. Whilst this provided a small measure of shock absorption, it also necessitated the removal of the wheels when the chariot was not in use, to prevent warping from continued weight bearing. Most other nations of this time had chariots of similar design to the Greeks, the chief differences being the mountings.\n\nAccording to Greek mythology, the chariot was invented by Erichthonius of Athens to conceal his feet, which were those of a dragon.\n\nThe most notable appearance of the chariot in Greek mythology occurs when Phaëton, the son of Helios, in an attempt to drive the chariot of the sun, managed to set the earth on fire. This story led to the archaic meaning of a \"phaeton\" as one who drives a chariot or coach, especially at a reckless or dangerous speed. Plato, in his \"Chariot Allegory\", depicted a chariot drawn by two horses, one well behaved and the other troublesome, representing opposite impulses of human nature; the task of the charioteer, representing reason, was to stop the horses from going different ways and to guide them towards enlightenment.\n\nThe Greek word for chariot, ἅρμα, \"hárma\", is also used nowadays to denote a tank, properly called άρμα μάχης, \"árma mákhēs\", literally a \"combat chariot\".\n\nThe Trundholm sun chariot is dated to c. 1400 BC (see Nordic Bronze Age). The horse drawing the solar disk runs on four wheels, and the Sun itself on two. All wheels have four spokes. The \"chariot\" comprises the solar disk, the axle, and the wheels, and it is unclear whether the sun is depicted as the chariot or as the passenger. Nevertheless, the presence of a model of a horse-drawn vehicle on two spoked wheels in Northern Europe at such an early time is astonishing.\n\nIn addition to the Trundholm chariot, there are numerous petroglyphs from the Nordic Bronze Age that depict chariots. One petroglyph, drawn on a stone slab in a double burial from c. 1000 BC, depicts a biga with two four-spoked wheels.\n\nThe use of the composite bow in chariot warfare is not attested in northern Europe.\n\nThe Celts were famous for their chariots and modern English words like \"car\", \"carriage\" and \"carry\" are ultimately derived from the native Brythonic language (Modern Welsh: \"Cerbyd\"). The word \"chariot\" itself is derived from the Norman French \"charriote\" and shares a Celtic root (Gaulish: \"karros\"). Some 20 iron-aged chariot burials have been excavated in Britain, roughly dating from between 500 BC and 100 BC. Virtually all of them were found in East Yorkshire - the exception was a find in 2001 in Newbridge, 10 km west of Edinburgh.\n\nThe Celtic chariot, which may have been called \"karbantos\" in Gaulish (compare Latin \"carpentum\"), was a \"biga\" that measured approximately 2 m (6.56 ft) in width and 4 m (13 ft) in length.\n\nBritish chariots were open in front. Julius Caesar provides the only significant eyewitness report of British chariot warfare:\n\nTheir mode of fighting with their chariots is this: firstly, they drive about in all directions and throw their weapons and generally break the ranks of the enemy with the very dread of their horses and the noise of their wheels; and when they have worked themselves in between the troops of horse, leap from their chariots and engage on foot. The charioteers in the meantime withdraw some little distance from the battle, and so place themselves with the chariots that, if their masters are overpowered by the number of the enemy, they may have a ready retreat to their own troops. Thus they display in battle the speed of horse, [together with] the firmness of infantry; and by daily practice and exercise attain to such expertness that they are accustomed, even on a declining and steep place, to check their horses at full speed, and manage and turn them in an instant and run along the pole, and stand on the yoke, and thence betake themselves with the greatest celerity to their chariots again.\n\nChariots play an important role in Irish mythology surrounding the hero Cú Chulainn.\n\nChariots could also be used for ceremonial purposes. According to Tacitus (\"Annals\" 14.35), Boudica, queen of the Iceni and a number of other tribes in a formidable uprising against the occupying Roman forces, addressed her troops from a chariot in 61 AD:\n\nThe last mention of chariot use in battle seems to be at the Battle of Mons Graupius, somewhere in modern Scotland, in 84 AD. From Tacitus (\"Agricola\" 1.35–36) \"The plain between resounded with the noise and with the rapid movements of chariots and cavalry.\" The chariots did not win even their initial engagement with the Roman auxiliaries: \"Meantime the enemy's cavalry had fled, and the charioteers had mingled in the engagement of the infantry.\"\n\nLater through the centuries, the chariot, became commonly known as the \"war wagon\". The \"war wagon\" was a medieval development used to attack rebel or enemy forces on battle fields. The wagon was given slits for archers to shoot enemy targets, supported by infantry using pikes and flails and later for the invention of gunfire by hand-gunners; side walls were use for protection against archers, crossbowmen, the early use of gunpowder and cannon fire.\n\nIt was especially useful during the Hussite Wars, ca. 1420, by Hussite forces rebelling in Bohemia. Groups of them could form defensive works, but they also were used as hardpoints for Hussite formations or as firepower in pincer movements. This early use of gunpowder and innovative tactics helped a largely peasant infantry stave off attacks by the Holy Roman Empire's larger forces of mounted knights.\n\nThe only intact Etruscan chariot dates to c. 530 BC and was uncovered as part of a chariot burial at Monteleone di Spoleto. Currently in the collection of the Metropolitan Museum of Art, it is decorated with bronze plates decorated with detailed low-relief scenes, commonly interpreted as depicting episodes from the life of Achilles.\n\nIn Urartu (860–590 BC), the chariot was used by both the nobility and the military. In Erebuni (Yerevan), King Argishti of Urartu is depicted riding on a chariot which is dragged by two horses. The chariot has two wheels and each wheel has about eight spokes. This type of chariot was used around 800 BC.\n\nIn the Roman Empire, chariots were not used for warfare, but for chariot racing, especially in circuses, or for triumphal processions, when they could be drawn by as many as ten horses or even by dogs, tigers, or ostriches. There were four divisions, or \"factiones\", of charioteers, distinguished by the colour of their costumes: the red, blue, green and white teams. The main centre of chariot racing was the Circus Maximus, situated in the valley between the Palatine and Aventine Hills in Rome. The track could hold 12 chariots, and the two sides of the track were separated by a raised median termed the \"spina\". Chariot races continued to enjoy great popularity in Byzantine times, in the Hippodrome of Constantinople, even after the Olympic Games had been disbanded, until their decline after the Nika riots in the 6th century. The starting gates were known as the Carceres.\n\nAn ancient Roman car or chariot drawn by four horses abreast together with the horses drawing it was called a \"Quadriga\", from the Latin \"quadriugi\" (of a team of four). The term sometimes meant instead the four horses without the chariot or the chariot alone. A three-horse chariot, or the three-horse team drawing it, was a \"triga\", from \"triugi\" (of a team of three). A two-horse chariot, or the two-horse team drawing it, was a \"biga\", from \"biugi\".\n\nSome scholars argue that the horse chariot was most likely a product of the ancient Near East early in the 2nd millennium BCE. Archaeologist Joost Crouwel writes that \"Chariots were not sudden inventions, but developed out of earlier vehicles that were mounted on disk or cross-bar wheels. This development can best be traced in the Near East, where spoke-wheeled and horse-drawn chariots are first attested in the earlier part of the second millennium BCE...\" and were illustrated on a Syrian cylinder seal dated to either the 18th or 17th century BC.\n\nIt is widely believed that wheeled transport was invented in Mesopotamia. Nevertheless, recent archaeological evidence seems to indicate otherwise, pointing to Neolithic Europe.\n\nAccording to Christoph Baumer, the earliest discoveries of wheels in Mesopotamia come from the first half of the third millennium BC – more than half a millennium later than the first finds from the Kuban region. At the same time, in Mesopotamia, some intriguing early pictograms of a sled that rests on wooden rollers or wheels have been found. They date from about the same time as the early wheel discoveries in Europe and may indicate knowledge of the wheel.\n\nThe earliest fully developed spoke-wheeled horse chariots are from the chariot burials of the Andronovo (Timber-Grave) sites of the Sintashta-Petrovka Proto-Indo-Iranian culture in modern Russia and Kazakhstan from around 2000 BC. This culture is at least partially derived from the earlier Yamna culture. It built heavily fortified settlements, engaged in bronze metallurgy on an industrial scale and practiced complex burial rituals reminiscent of Hindu rituals known from the \"Rigveda\" and the \"Avesta\".\n\nOver the next few centuries, the Andronovo culture spread across the steppes from the Urals to the Tien Shan, likely corresponding to the time of early Indo-Iranian cultures.\n\nChariots figure prominently in Indo-Iranian mythology. Chariots are also an important part of both Hindu and Persian mythology, with most of the gods in their pantheon portrayed as riding them. The Sanskrit word for a chariot is \"rátha-\" (m.), which is cognate with Avestan \"raθa-\" (also m.), and in origin a substantiation of the adjective Proto-Indo-European ' meaning \"having wheels\", with the characteristic accent shift found in Indo-Iranian substantivisations. This adjective is in turn derived from the collective noun ' \"wheels\", continued in Latin \"rota\", which belongs to the noun ' for \"wheel\" (from ' \"to run\") that is also found in Germanic, Celtic and Baltic (Old High German \"rad\" n., Old Irish \"roth\" m., Lithuanian \"rãtas\" m.).\n\nThe earliest depiction of vehicles in the context of warfare is on the Standard of Ur in southern Mesopotamia, c. 2500 BCE. These are more properly called wagons or carts and were double-axled and pulled by oxen or a hybrid of a donkey and a female onager, named Kunga in the city of Nagar which was famous for breeding them. The hybrids were used by the Eblaite, early Sumerian, Akkadian and Ur III armies. Although sometimes carrying a spearman with the charioteer (driver), such heavy wagons, borne on solid wooden wheels and covered with skins, may have been part of the baggage train (e.g., during royal funeral processions) rather than vehicles of battle in themselves.\n\nThe Sumerians had a lighter, two-wheeled type of cart, pulled by four asses, and with solid wheels. The spoked wheel did not appear in Mesopotamia until the mid-2000s BCE.\n\nChariots are frequently mentioned in the Hebrew Tanakh and the Greek Old Testament, respectively, particularly by the prophets, as instruments of war or as symbols of power or glory. First mentioned in the story of Joseph (Genesis 50:9), \"Iron chariots\" are mentioned also in Joshua (17:16,18) and Judges (1:19,4:3,13) as weapons of the Canaanites and Israelites. 1 Samuel 13:5 mentions chariots of the Philistines, who are sometimes identified with the Sea Peoples or early Greeks.\n\nExamples from The Jewish Study Bible of Tanakh (\"Jewish Bible\") include:\n\n\nExamples from the King James Version of Christian Bible include:\n\nJezreel (city) has been identified as the chariot base of King Ahab. And the decorated lynchpin of Sisera's chariot was identified at a site identified as his fortress Harosheth Haggoyim.\n\nThe chariot and horse were introduced to Egypt by the Hyksos invaders in the 16th century BCE and undoubtedly contributed to the military success of the Egyptians. In the remains of Egyptian and Assyrian art, there are numerous representations of chariots, which display rich ornamentation. The chariots of the Egyptians and Assyrians, with whom the bow was the principal arm of attack, were richly mounted with quivers full of arrows. The Egyptians invented the yoke saddle for their chariot horses in c. 1500 BCE. As a general rule, the Egyptians used chariots as mobile archery platforms; chariots always had two men, with the driver steering the chariot with his reins while the main archer aimed his bow and arrow at any targets within range. The best preserved examples of Egyptian chariots are the four specimens from the tomb of Tutankhamun. Chariots can be carried by two or more horses.\n\nThe oldest testimony of chariot warfare in the ancient Near East is the Old Hittite Anitta text (18th century BCE), which mentions 40 teams of horses (in the original cuneiform spelling: 40 \"ṢÍ-IM-TI\" ANŠE.KUR.RA) at the siege of Salatiwara. Since the text mentions \"teams\" rather than \"chariots\", the existence of chariots in the 18th century BCE is uncertain. The first certain attestation of chariots in the Hittite empire dates to the late 17th century BCE (Hattusili I). A Hittite horse-training text is attributed to Kikkuli the Mitanni (15th century BCE).\n\nThe Hittites were renowned charioteers. They developed a new chariot design that had lighter wheels, with four spokes rather than eight, and that held three rather than two warriors. It could hold three warriors because the wheel was placed in the middle of the chariot and not at the back as in Egyptian chariots. Typically one Hittite warrior steered the chariot while the second man was usually the main archer; the third warrior would either wield a spear or sword when charging at enemies or hold up a large shield to protect himself and the others from enemy arrows. \n\nHittite prosperity largely depended on their control of trade routes and natural resources, specifically metals. As the Hittites gained dominion over Mesopotamia, tensions flared among the neighboring Assyrians, Hurrians, and Egyptians. Under Suppiluliuma I, the Hittites conquered Kadesh and, eventually, the whole of Syria. The Battle of Kadesh in 1274 BCE is likely to have been the largest chariot battle ever fought, involving over 5,000 chariots.\n\nThe Persians succeeded Elam in the mid 1st millennium. They may have been the first to yoke four horses to their chariots. They also used scythed chariots. Cyrus the Younger employed these chariots in large numbers at the Battle of Cunaxa.\nHerodotus mentions that the Libyans and the Indus satrapy supplied cavalry and chariots to Xerxes the Great's army. However, by this time, cavalry was far more effective and agile than the chariot, and the defeat of Darius III at the Battle of Gaugamela (331 BCE), where the army of Alexander simply opened their lines and let the chariots pass and attacked them from behind, marked the end of the era of chariot warfare (barring the Seleucid and Pontic powers, India, China, and the Celtic peoples).\n\nThe earliest archaeological evidence of chariots in China, a chariot burial site discovered in 1933 at Hougang, Anyang in Henan province, dates to the rule of King Wu Ding of the late Shang Dynasty (c. 1200 BCE). Oracle bone inscriptions suggest that the western enemies of the Shang used limited numbers of chariots in battle, but the Shang themselves used them only as mobile command-vehicles and in royal hunts.\nDuring the Shang Dynasty, members of the royal family were buried with a complete household and servants, including a chariot, horses, and a charioteer. A Shang chariot was often drawn by two horses, but four-horse variants are occasionally found in burials.\n\nJacques Gernet claims that the Zhou dynasty, which conquered the Shang ca. 1046 BC, made more use of the chariot than did the Shang and \"invented a new kind of harness with four horses abreast\". The crew consisted of an archer, a driver, and sometimes a third warrior who was armed with a spear or dagger-axe. From the 8th to 5th centuries BCE the Chinese use of chariots reached its peak. Although chariots appeared in greater numbers, infantry often defeated charioteers in battle.\n\nMassed-chariot warfare became all but obsolete after the Warring-States Period (476–221 BC). The main reasons were increased use of the crossbow, use of long halberds up to 18 feet long and pikes up to 22 feet long, and the adoption of standard cavalry units, and the adaptation of mounted archery from nomadic cavalry, which were more effective. Chariots would continue to serve as command posts for officers during the Qin dynasty (221-206 BC) and the Han Dynasty (206 BCE-220 AD), while armored chariots were also used during the Han Dynasty against the Xiongnu Confederation in the Han–Xiongnu War (133 BC to 89 AD), specifically at the Battle of Mobei (119 BC).\n\nBefore the Han Dynasty, the power of Chinese states and dynasties was often measured by the number of chariots they were known to have. A country of a thousand chariots ranked as a medium country, and a country of ten thousand chariots ranked as a huge and powerful country.\n\nChariots figure prominently in the Rigveda, evidencing their presence in India in the 2nd millennium BCE. Among Rigvedic deities, notably Ushas (the dawn) rides in a chariot, as well as Agni in his function as a messenger between gods and men.\nThere are some depictions of chariots among the petroglyphs in the sandstone of the Vindhya range. Two depictions of chariots are found in Morhana Pahar, Mirzapur district. One depicts a biga and the head of the driver. The second depicts a quadriga, with six-spoked wheels, and a driver standing up in a large chariot box. This chariot is being attacked. One figure, who is armed with a shield and a mace, stands in the chariot's path; another figure, who is armed with bow and arrow, threatens the right flank. It has been suggested (speculated) that the drawings record a story, most probably dating to the early centuries BCE, from some center in the area of the Ganges–Yamuna plain into the territory of still Neolithic hunting tribes. The very realistic chariots carved into the Sanchi stupas are dated to roughly the 1st century.\n\nThe scythed chariot was invented by the King of Magadha, Ajatashatru around 475 BCE. He used these chariots against the Licchavis. A scythed war chariot had a sharp, sickle-shaped blade or blades mounted on each end of the axle. The blades, used as weapons, extended horizontally for a metre on the sides of the chariot.\n\nThere is a chariot displayed at the AP State Archaeology Museum, Hyderabad, Telangana.\n\nA popular legend that has been around since at least 1937 traces the origin of the 4 ft  in standard railroad gauge to Roman times, suggesting that it was based on the distance between the ruts of rutted roads marked by chariot wheels dating from the Roman Empire. This is encouraged by the fact that the otherwise peculiar distance is almost exactly 5 Roman feet but there is no evidence to span the millennium and a half between the departure of the Romans from Britain and the adoption of the gauge on the Stockton and Darlington railroad in 1825.\n\n\n\n"}
{"id": "13933711", "url": "https://en.wikipedia.org/wiki?curid=13933711", "title": "Dynamic voltage scaling", "text": "Dynamic voltage scaling\n\nDynamic voltage scaling is a power management technique in computer architecture, where the voltage used in a component is increased or decreased, depending upon circumstances. Dynamic voltage scaling to increase voltage is known as overvolting; dynamic voltage scaling to decrease voltage is known as undervolting. Undervolting is done in order to conserve power, particularly in laptops and other mobile devices, where energy comes from a battery and thus is limited, or in rare cases, to increase reliability. Overvolting is done in order to increase computer performance.\n\nThe term \"overvolting\" is also used to refer to increasing static operating voltage of computer components to allow operation at higher speed (overclocking).\n\nMOSFET-based digital circuits operate using voltages at circuit nodes to represent logical state. The voltage at these nodes switches between a high voltage and a low voltage during normal operation—when the inputs to a logic gate transition, the transistors making up that gate may toggle the gate's output.\n\nAt each node in a circuit is a certain amount of capacitance. Capacitance can be thought of as a measure of how long it takes for a given current to produce a given voltage change. The capacitance arises from various sources, mainly transistors (primarily gate capacitance and diffusion capacitance) and wires (coupling capacitance). Toggling a voltage at a circuit node requires charging or discharging the capacitance at that node; since currents are related to voltage, the time it takes depends on the voltage applied. By applying a higher voltage to the devices in a circuit, the capacitances are charged and discharged more quickly, resulting in faster operation of the circuit and allowing for higher frequency operation.\n\nMany modern components allow voltage regulation to be controlled through software (for example, through the BIOS). It is usually possible to control the voltages supplied to the CPU, RAM, PCI, and PCI Express (or AGP) port through a PC's BIOS.\n\nHowever, some components do not allow software control of supply voltages, and hardware modification is required by overclockers seeking to overvolt the component for extreme overclocks. Video cards and motherboard northbridges are components which frequently require hardware modifications to change supply voltages.\n\nThese modifications are known as \"voltage mods\" in the overclocking community.\n\nUndervolting is reducing the voltage of a component, usually the processor, reducing temperature and cooling requirements, and possibly allowing a fan to be omitted.\n\nThe \"switching power\" dissipated by a chip using static CMOS gates is \"C·V·f\", where C is the capacitance being switched per clock cycle, V is the supply voltage, and f is the switching frequency, so this part of the power consumption decreases quadratically with voltage. The formula is not exact however, as many modern chips are not implemented using 100% CMOS, but also use special memory circuits, dynamic logic such as domino logic, etc. Moreover, there is also a static leakage current, which has become more and more accentuated as feature sizes have become smaller (below 90 nanometres) and threshold levels lower.\n\nAccordingly, dynamic voltage scaling is widely used as part of strategies to manage switching power consumption in battery powered devices such as cell phones and laptop computers. Low voltage modes are used in conjunction with lowered clock frequencies to minimize power consumption associated with components such as CPUs and DSPs; only when significant computational power is needed will the voltage and frequency be raised.\n\nSome peripherals also support low voltage operational modes. For example, low power MMC and SD cards can run at 1.8 V as well as at 3.3 V, and driver stacks may conserve power by switching to the lower voltage after detecting a card which supports it.\n\nWhen leakage current is a significant factor in terms of power consumption, chips are often designed so that portions of them can be powered completely off. This is not usually viewed as being dynamic voltage scaling, because it is not transparent to software. When sections of chips can be turned off, as for example on TI OMAP3 processors, drivers and other support software need to support that.\n\nThe speed at which a digital circuit can switch states - that is, to go from \"low\" (VSS) to \"high\" (VDD) or vice versa - is proportional to the voltage differential in that circuit. Reducing the voltage means that circuits switch slower, reducing the maximum frequency at which that circuit can run. This, in turn, reduces the rate at which program instructions that can be issued, which may increase run time for program segments which are sufficiently CPU-bound.\n\nThis again highlights why dynamic voltage scaling is generally done in conjunction with dynamic frequency scaling, at least for CPUs. There are complex tradeoffs to consider, which depend on the particular system, the load presented to it, and power management goals. When quick responses are needed, clocks and voltages might be raised together. Otherwise, they may both be kept low to maximize battery life.\n\nThe 167-processor AsAP 2 chip enables individual processors to make extremely fast (on the order of 1-2ns) and locally controlled changes to their own supply voltages. Processors connect their local power grid to either a higher (VddHi) or lower (VddLow) supply voltage, or can be cut off entirely from either grid to dramatically cut leakage power.\n\nAnother approach uses per-core on-chip switching regulators for dynamic voltage and frequency scaling (DVFS).\n\nUnix system provides a userspace governor, allowing to modify the cpu frequencies (though limited to hardware capabilities).\n\nDynamic frequency scaling is another power conservation technique that works on the same principles as dynamic voltage scaling. Both dynamic voltage scaling and dynamic frequency scaling can be used to prevent computer system overheating, which can result in program or operating system crashes, and possibly hardware damage. Reducing the voltage supplied to the CPU below the manufacturer's recommended minimum setting can result in system instability.\n\nThe efficiency of some electrical components, such as voltage regulators, decreases with increasing temperature, so the power used may increase with temperature causing thermal runaway. Increases in voltage or frequency may increase system power demands even faster than the CMOS formula indicates, and vice versa.\n\nThe primary caveat of overvolting is increased heat: the power dissipated by a circuit increases with the square of the voltage applied, so even small voltage increases significantly affect power. At higher temperatures, transistor performance is adversely affected, and at some threshold, the performance reduction due to the heat exceeds the potential gains from the higher voltages. Overheating and damage to circuits can occur very quickly when using high voltages.\n\nThere are also longer-term concerns: various adverse device-level effects such as hot carrier injection and electromigration occur more rapidly at higher voltages, decreasing the lifespan of overvolted components.\n\n"}
{"id": "31676698", "url": "https://en.wikipedia.org/wiki?curid=31676698", "title": "Energy in Indonesia", "text": "Energy in Indonesia\n\nEnergy in Indonesia describes energy and electricity production, consumption, import and export in Indonesia. In 2009 Indonesia produced oil, coal, natural gas and palm oil, utilised also as energy raw material in 2010. Renewable energy potential in Indonesia is high: solar, wind, hydro and geothermal energy. Tropical rain forests and peat land areas have extensive coal storage. Indonesia is geologically unstable country.\nAccording to IEA Indonesia was the 10th top natural gas producer in 2009: 76 billion cubics (bcm) 2.5% of world production of which 36 bcm was exported. In 2009 Indonesia was the 5th top coal producer: 263 million tonnes hard coal and 38 million tonnes brown. The majority of this, 230 Mt of hard coal, was exported. Indonesia has significant energy resources, starting with oil – it has 22 billion barrels of conventional oil and gas reserves, of which about 4 billion are recoverable. That's the equivalent of about 10 years of oil production and 50 years of gas. It has about 8 billion barrels of oil-equivalent of coal-based methane (CBM) resources. It has 28 billion tonnes of recoverable coal and has 28 gigawatts (GW) of geothermal potential.\n\nAccording to IEA energy production increased 34% and export 76% from 2004 to 2008 in Indonesia.\n\nIndonesia is well-supplied with medium and low-quality thermal coal. At current rates of production, Indonesia's coal reserves are expected to last for over 80 years. In 2009 Indonesia was the world's second top coal exporter sending coal to, for example, China, India, Japan and Italy. Kalimantan (Borneo) and South Sumatra are the centres of Indonesia’s coal mining. In recent years, production in Indonesia has been rising rapidly, from just over 200 mill tons in 2007 to over 400 mill tons in 2013. Recently (December 2013), the chair of the Indonesian Coal Mining Association said the production in 2014 may reach 450 mill tons.\n\nThe Indonesian coal industry is rather fragmented. Output is supplied by a few large producers and a large number of small firms. Large firms in the industry include the following:\n\n\nCoal production poses risks for deforestation in Kalimantan. According to one Greenpeace report, a coal plant in Indonesia has decreased the fishing catches and increased the respiratory-related diseases,\n\nOil is a major sector in the Indonesian economy. During the 1980s, Indonesia was a significant oil-exporting country. Since 2000, domestic consumption has continued to rise while production has been falling, so in recent years Indonesia has begun importing increasing amounts of oil. Within Indonesia, there are considerable amounts of oil in Sumatra, Borneo, Java, and West Papua Province. There are said to be around 60 basins across the country, only 22 of which have been explored and exploited. Main oil fields in Indonesia include the following:\n\n\nThere is growing recognition in Indonesia that the gas sector has considerable development potential. In principle, the Indonesian government is supporting moves to give increasing priority to investment in natural gas. In practice, private sector investors, especially foreign investors, have been reluctant to invest because many of the problems that are holding back investment in the oil sector also affect investment in gas. At present (mid 2013), main potential gas fields in Indonesia are believed to include the following:\n\n\nThere is potential for tight oil and shale gas in northern Sumatra and eastern Kalimantan. There are estimated to be 46 trillion cubic feet of shale gas and 7.9 billion barrels of shale oil which could be recovered with existing technologies. Pertamina has taken the lead in using hydraulic fracturing to explore for shale gas in northern Sumatra. Chevron Pacific Indonesia and NuEnergy Gas are also pioneers in using fracking in existing oil fields and in new exploration. Environmental concerns and a government-imposed cap on oil prices present barriers to full development of the substantial shale deposits in the country. Sulawesi, Seram, Buru, Irian Jaya in eastern Indonesia have shales that were deposited in marine environments which may be more brittle and thus more suitable for fracking than the source rocks in western Indonesia which have higher clay content.\n\nWith 453 trillion cubic feet Coal Bed Methane (CBM) reserve mainly in Kalimantan and Sumatra, Indonesia has potential to redraft its energy charts as United States with its Shale Gas. But with low enthusiastic to develop CBM project, the government only targeted 8.9 million metric standard cubic feet per day (mmscfd) for 2015.\n\nThe contribution of renewable sources of energy to energy supply as a percentage of total primary energy (potential) supply in 2010 was 34.5%. Renewable generation sources supplied 5% to 6% of Indonesia's electricity in 2015. Indonesia has set a target of 26% of electricity generation from renewable sources by 2025.\n\nAn estimated 55% of Indonesia's population, i.e. 128 million people primarily rely upon traditional biomass (mainly wood) for cooking. Reliance on this source of energy has the disadvantage that poor people in rural areas have little alternative but to collect timber from forests, and often cut down trees, to collect wood for cooking.\n\nA pilot project of Palm Oil Mill Effluent (POME) Power Generator with capacity of 1 Megawatt has been inaugurated in September 2014. Indonesia has many Palm Oil Mills.\n\nIndonesia has set a target of 2 GW installed capacity in hydroelectricity, including 0.43 GW micro hydro, by 2025.\n\nIndonesia uses some geothermal energy. According to the Renewable Energy Policy Network's \"Renewables 2013 Global Status Report\", Indonesia has the third largest installed generating capacity in the world. With 1.3 GW installed capacity, Indonesia trails only the United States (3.4 GW) and the Philippines (1.9 GW). However it leads Mexico (1.0 GW), Italy (0.9 GW), New Zealand (0.8 GW), Iceland (0.7 GW), and Japan (0.5 GW). Current official policy is to encourage the increasing use of geothermal energy for electricity production. Geothermal sites in Indonesia include the Wayang Windu Geothermal Power Station and the Kamojang plant, both in West Java.\n\nThe development of the sector has been proceeding rather more slowly than hoped. Expansion appears to be held up by a range of technical, economic, and policy issues which have attracted considerable comment in Indonesia. However, it has proved difficult to formulate policies to respond to the problems.\n\nLow wind speeds mean that there is limited scope for large-scale energy generation from wind in Indonesia. Only small (<10 kW) and medium (<100 kW) generators are feasible. Accordingly, a very small amount of (off-grid) electricity is generated using wind power. For example, a small plant was established at Pandanmino, a small village on the south coast of Java in Bantul Regency, Yogyakarta Province, in 2011. However it was established as experimental plant and it is not clear whether funding for long-term maintenance will be available.\n\nThe Indonesian solar PV sector is relatively underdeveloped but has significant potential. However, for a range of reasons, it is unlikely that it will be practical to expand electricity output from solar sources in Indonesia quickly. A range of technical, financial, economic and social constraints are likely to be constraints on the rapid installation of solar power in Indonesia, including in rural areas.\n\nOutput from the solar photovoltaic sector is almost exclusively set aside for decentralised rural electrification. In 2011 the sector produced a relatively small amount of electricity—only 22 MWh.\n\nMuch energy in Indonesia is used for domestic transportation. The dominance of private vehicles - mostly cars and motorbikes - in Indonesia has led to an enormous demand for fuel. Energy consumption in the transport sector is growing by about 4.5% every year. There is therefore an urgent need for policy reform and infrastructure investment to enhance the energy efficiency of transport, particularly in urban areas.\n\nThere are large opportunities to reduce both the energy consumption from the transport sector, for example through the adoption of higher energy efficiency standards for private cars/motorbikes and expanding mass transit networks. Many of these measures would be more cost-effective than the current transport systems. There is also scope to reduce the carbon intensity of transport energy, particularly through replacing diesel with biodiesel or through electrification. Both would require comprehensive supply chain analysis to ensure that the biofuels and power plants are not having wider environmental impacts such as deforestation or air pollution.\n\nAccess to electricity\n\nOver 50% of households in 2011 had an electricity connection. An estimated 63 million people in 2011 did not have direct access to electricity.\n\nOrganisations\n\nThe electricity sector, dominated by the state-owned electricity utility Perusahaan Listrik Negara, is another major consumer of primary energy.\n\nIndonesian firms\n\n\nForeign firms\n\n\nThe CO2 emissions of Indonesia in total were over Italy in 2009. However, in all greenhouse gas emissions including construction and deforestation in 2005 Indonesia was top-4 after China, US and\nBrazil.\n"}
{"id": "18063804", "url": "https://en.wikipedia.org/wiki?curid=18063804", "title": "Eugene C. Bingham", "text": "Eugene C. Bingham\n\nEugene Cook Bingham (8 December 1878 – 6 November 1945) was a professor and head of the department of chemistry at Lafayette College. Bingham made many contributions to rheology, a term he is credited (along with Markus Reiner) with introducing. He was a pioneer in both its theory and practice. The type of fluid known as a Bingham plastic or Bingham Fluid is named after him, as is Bingham Stress. He was also one of the people responsible for the construction of the Appalachian Trail.\n\nBingham was born on 8 December 1878 in Cornwall, Vermont.\n\nHe was awarded the Franklin Institute's Certificate of Merit in 1921 for his variable pressure viscometer. In 1922, as chairman of the Metric Committee of the American Chemical Society, he campaigned for the United States to adopt the metric system.\n\nBingham died on 6 November 1945 in Easton, Pennsylvania.\n\nThe Society of Rheology has awarded the Bingham Medal annually since 1948.\n\n\n"}
{"id": "12963827", "url": "https://en.wikipedia.org/wiki?curid=12963827", "title": "Fallstreak hole", "text": "Fallstreak hole\n\nA fallstreak hole (also known as a cavum, hole punch cloud, punch hole cloud, skypunch, cloud canal or cloud hole) is a large gap, usually circular or elliptical, that can appear in cirrocumulus or altocumulus clouds. Such holes are formed when the water temperature in the clouds is below freezing but the water, in a supercooled state, has not frozen yet due to the lack of ice nucleation. When ice crystals do form, a domino effect is set off due to the Bergeron process, causing the water droplets around the crystals to evaporate: this leaves a large, often circular, hole in the cloud.\n\nIt is thought that the introduction of large numbers of tiny ice crystals into the cloud layer sets off this domino effect of fusion which creates the hole. The ice crystals can be formed by passing aircraft, which often have a large reduction in pressure behind the wing- or propeller-tips. This cools the air very quickly, and can produce a ribbon of ice crystals trailing in the aircraft's wake. These ice crystals find themselves surrounded by droplets, and grow quickly by the Bergeron process, causing the droplets to evaporate and creating a hole with brush-like streaks of ice crystals below it. An early satellite documentation of elongated fallstreak holes over the Florida Panhandle that likely were induced by passing aircraft appeared in Corfidi and Brandli (1986). Fallstreak holes are more routinely seen by the higher resolution satellites of today (e.g, see third ilustration accompanying this article).\n\nThe articles by Westbrook and Davies (2010) and Heymsfield et al. (2010) explain the processes behind the formation of fallstreak holes in greater detail, and show some observations of their microphysics and dynamics. Such clouds are not unique to any one geographic area and have been photographed from many places.\n\nBecause of their rarity and unusual appearance, fallstreak holes have been mistaken for or attributed to unidentified flying objects.\n\n"}
{"id": "10111396", "url": "https://en.wikipedia.org/wiki?curid=10111396", "title": "Fillet (picture framing)", "text": "Fillet (picture framing)\n\nIn the picture framing industry, a fillet (also referred to as a slip) is a small piece of moulding which fits inside a larger frame or, typically, underneath or in between matting, used for decorative purposes. The picture framing term is probably related to, though not necessarily derived from, the engineering term, which it is frequently pronounced similarly to; however, unlike the use of fillets in mechanical engineering, the use of \"fillets\" in picture frames is wholly decorative. \n\n\"Fillet\" can be pronounced in two ways. One way is to pronounce it as if it were \"fill-it\", as the similar term from mechanical engineering is pronounced. The other is similar to the French-derived culinary term. Either is acceptable in English, though most frame shops prefer one or the other pronunciation.\n\nFillets are typically made of soft or hard wood, and feature a flat \"lip\" which can fit underneath a mat; the non-lip portion is what is displayed. Except for their shape and size (which is understandably small), fillets are constructed similarly to picture frames, usually from wood or polystyrene. Metal fillets are very rare. Fillets are available in a number of styles and finishes, including gold and silver leaf finishes.\n\nThe fillet is normally used as decoration in the lining of a picture frame or underneath a mat inside one; the intent is to help draw the eye inwards to the document being framed. \n\nHowever, one can also use inverted fillets as form of picture frame on small, flat objects, as seen below:\n\nIn this case, the card was glued to the lip of the inverted fillet (which is thus hidden behind the back of the card).\n\nObjects such as this that have been framed using inverted fillets can be backed and then affixed to wire for hanging, displayed on an easel, or used inside of a larger shadowbox display. It is important to note that only very small, extremely flat objects can be framed using only an inverted fillet, as a fillet lacks the depth of a traditional picture frame, and due to its size, weight and construction, could not support a great amount of weight on its own.\n\n"}
{"id": "21204089", "url": "https://en.wikipedia.org/wiki?curid=21204089", "title": "Forrest H. Duttlinger Natural Area", "text": "Forrest H. Duttlinger Natural Area\n\nThe Forrest H. Dutlinger Natural Area is a protected area in Clinton County, Pennsylvania, United States that includes a old-growth forest of eastern hemlock, American beech, black cherry, sugar maple, and northern red oak. There are also eastern white pines, but a few were selectively logged around 1900. The largest tree is an eastern hemlock, diameter at breast height and tall. \n\nThe old-growth forest once lay on the boundary of two lumber companies, the Goodyear and Lackawanna, but was apparently spared because of a dispute over a surveying error.\n\nForrest Dutlinger was a forester for the state of Pennsylvania from 1909 to 1959, beginning his career at a time of massive clear cutting of forests without any reforestation by the timber companies. Major fires were widespread and common due to most machinery being steam driven; the fires used to boil the water would ignite the surrounding area. Dutlinger also watched helplessly as the Asian chestnut blight killed all the American Chestnut trees in a matter of years. The chestnut was the most common hardwood tree in the forest at the time, and its magnificent lumber and nuts as a food source for wildlife have never been replaced.\n\n\n"}
{"id": "1708807", "url": "https://en.wikipedia.org/wiki?curid=1708807", "title": "HVDC Visby–Näs", "text": "HVDC Visby–Näs\n\nThe HVDC Visby–Näs is a bipolar HVDC electric power transmission system between Visby and a wind power centre near Näs on Gotland, Sweden. The project went into service in 1999. The system operates at 80 kV with a maximum power of 50 megawatts. This HVDC system allows for voltage regulation in the connected AC systems.\n\nBecause obtaining a right-of-way for an overhead line is a lengthy and expensive procedure, the 70 kilometer line is constructed as an underground cable. Since an alternating current three-phase underground cable would have been more expensive, the HVDC system was selected for this project.\n\n"}
{"id": "9209693", "url": "https://en.wikipedia.org/wiki?curid=9209693", "title": "Helically Symmetric Experiment", "text": "Helically Symmetric Experiment\n\nThe Helically Symmetric Experiment (HSX), stylized as Helically Symmetric eXperiment, is an experimental plasma confinement device at the University of Wisconsin-Madison, with design principles that are hoped to be incorporated into a fusion reactor. The HSX is a modular coil stellarator which is a toroid-shaped pressure vessel with external electromagnets which generate a magnetic field for the purpose of containing a plasma.\n\nA stellarator is a magnetic confinement fusion device which generates all required magnetic fields to confine high temperature plasma by external magnetic coils. In contrast, in tokamaks and reversed field pinches the magnetic field is created by the interaction of external magnets and an electrical current flowing through the plasma. The lack of this large externally driven plasma currents makes stellarators suitable for steady-state fusion power plant.\n\nHowever, due to non-axisymmetric nature of the fields, conventional stellarators have a combination of toroidal and helical modulation of the magnetic field lines that leads to high transport of plasma out of the confinement volume at fusion relevant conditions. This large transport in conventional stellarators can limit their performance as a fusion reactor. \n\nThis problem can be largely reduced by tailoring the magnetic field geometry. The dramatic improvements in computer modeling capability in the last two decades has helped to \"optimize\" the magnetic geometry to reduce this transport, resulting in a new class of stellarators called \"quasi-symmetric stellarators\". Computer-modeled odd-looking electromagnets will directly produce the needed magnetic field configuration. These devices combine the good confinement properties of tokamaks and the steady-state nature of conventional stellarators. The Helically Symmetric Experiment (HSX) at the University of Wisconsin-Madison is such a quasi-helically symmetric stellarator (helical axis of symmetry).\n\nThe magnetic field in HSX is generated by a set of 48 twisted coils arranged in four field periods. HSX typically operates at a magnetic field of 1 Tesla at the center of the plasma column. A set of auxiliary coils is used to deliberately break the symmetry to mimic conventional stellarator properties for comparison. \n\nHSX vacuum vessel is made of stainless steel, and is helically shaped to follow the magnetic geometry. \n\nPlasma formation and heating is achieved using 28 GHz, 100 kW electron cyclotron resonance heating (ECRH). A second 100 kW gyrotron has recently been installed on HSX to perform heat pulse modulation studies. \n\nPlasmas as high as 3 kilo electronvolts in temperature and about 8x10/cc in density are routinely formed for various experiments.\n\nHSX has a large set of diagnostics to measure properties of plasma and magnetic fields. The following gives a list of major diagnostics and subsystems.\n\nHSX has made and continues to make fundamental contributions to the physics of quasisymmetric stellarators that show significant improvement over the conventional stellarator concept. These include:\n\nA large number of experimental and computational research works are being done in HSX by students, staff and faculties. Some of them are in collaboration with other universities and national laboratories, both in the USA and abroad. Major research projects at present are listed below:\n\n\n\n\n"}
{"id": "2898953", "url": "https://en.wikipedia.org/wiki?curid=2898953", "title": "Hot cathode", "text": "Hot cathode\n\nIn vacuum tubes and gas-filled tubes, a hot cathode or thermionic cathode is a cathode electrode which is heated to make it emit electrons due to thermionic emission. This is in contrast to a cold cathode, which does not have a heating element. The heating element is usually an electrical filament heated by a separate electric current passing through it. Hot cathodes typically achieve much higher power density than cold cathodes, emitting significantly more electrons from the same surface area. Cold cathodes rely on field electron emission or secondary electron emission from positive ion bombardment, and do not require heating. There are two types of hot cathode. In a \"directly heated cathode\", the filament is the cathode and emits the electrons. In an \"indirectly heated cathode\", the filament or \"heater\" heats a separate metal cathode electrode which emits the electrons.\n\nFrom the 1920s to the 1960s, a wide variety of electronic devices used hot-cathode vacuum tubes. Today, hot cathodes are used as the source of electrons in fluorescent lamps, vacuum tubes, and the electron guns used in cathode ray tubes and laboratory equipment such as electron microscopes.\n\nA cathode electrode in a vacuum tube or other vacuum system is a metal surface which emits electrons into the evacuated space of the tube. Since the negatively charged electrons are attracted to the positive nuclei of the metal atoms, they normally stay inside the metal and require energy to leave it. This energy is called the \"work function\" of the metal. In a hot cathode, the cathode surface is induced to emit electrons by heating it with a filament, a thin wire of refractory metal like tungsten with current flowing through it. The cathode is heated to a temperature that causes electrons to be 'boiled off' of its surface into the evacuated space in the tube, a process called \"thermionic emission\".\n\nThere are two types of hot cathodes:\n\nThe main reason for using an indirectly heated cathode is to isolate the rest of the vacuum tube from the electric potential across the filament, allowing vacuum tubes to use alternating current to heat the filament. In a tube in which the filament itself is the cathode, the alternating electric field from the filament surface would affect the movement of the electrons and introduce hum into the tube output. It also allows the filaments in all the tubes in an electronic device to be tied together and supplied from the same current source, even though the cathodes they heat may be at different potentials.\n\nTo improve electron emission, cathodes are usually treated with chemicals, compounds of metals with a low work function. These form a metal layer on the surface which emits more electrons. Treated cathodes require less surface area, lower temperatures and less power to supply the same cathode current. The untreated thoriated tungsten filaments used in early vacuum tubes (called \"bright emitters\") had to be heated to 2500 °F (1400 °C), white-hot, to produce sufficient thermionic emission for use, while modern coated cathodes produce far more electrons at a given temperature, so they only have to be heated to 800–1100 °F (425–600 °C).\n\nThe most common type of indirectly heated cathode is the oxide-coated cathode, in which the nickel cathode surface has a coating of alkaline earth metal oxide to increase emission. One of the earliest materials used for this was barium oxide; it forms a monatomic layer of barium with an extremely low work function. More modern formulations utilize a mixture of barium oxide, strontium oxide and calcium oxide. Another standard formulation is barium oxide, calcium oxide, and aluminium oxide in a 5:3:2 ratio. Thorium oxide is used as well. Oxide-coated cathodes operate at about 800-1000 °C, orange-hot. They are used in most small glass vacuum tubes, but are rarely used in high-power tubes because the coating is degraded by positive ions that bombard the cathode, accelerated by the high voltage on the tube.\n\nFor manufacturing convenience, the oxide-coated cathodes are usually coated with carbonates, which are then converted to oxides by heating. The activation may be achieved by microwave heating, direct electric current heating, or electron bombardment while the tube is on the exhausting machine, until the production of gases ceases. The purity of cathode materials is crucial for tube lifetime. The Ba content significantly increases on the surface layers of oxide cathodes down to several tens of nanometers in depth, after the cathode activation process. The lifetime of oxide cathodes can be evaluated with a stretched exponential function. The survivability of electron emission sources is significantly improved by high doping of high‐speed activator.\n\nBarium oxide reacts with traces of silicon in the underlying metal, forming barium silicate (BaSiO) layer. This layer has high electrical resistance, especially under discontinuous current load, and acts as a resistor in series with the cathode. This is particularly undesirable for tubes used in computer applications, where they can stay without conducting current for extended periods of time.\n\nBarium also sublimates from the heated cathode, and deposits on nearby structures. For electron tubes, where the grid is subjected to high temperatures and barium contamination would facilitate electron emission from the grid itself, higher proportion of calcium is added to the coating mix (up to 20% of calcium carbonate).\n\nLanthanum hexaboride (LaB) and cerium hexaboride (CeB) are used as the coating of some high-current cathodes. Hexaborides show low work function, around 2.5 eV. They are also resistant to poisoning. Cerium boride cathodes show lower evaporation rate at 1700 K than lanthanum boride, but it becomes equal at 1850 K and higher. Cerium boride cathodes have one and a half times the lifetime of lanthanum boride, due to its higher resistance to carbon contamination. Boride cathodes are about ten times as \"bright\" as the tungsten ones and have 10-15 times longer lifetime. They are used e.g. in electron microscopes, microwave tubes, electron lithography, electron beam welding, X-Ray tubes, and free electron lasers. However these materials tend to be expensive.\n\nOther hexaborides can be employed as well; examples are calcium hexaboride, strontium hexaboride, barium hexaboride, yttrium hexaboride, gadolinium hexaboride, samarium hexaboride, and thorium hexaboride.\n\nA common type of directly heated cathode, used in most high power transmitting tubes, is the thoriated tungsten filament, discovered in 1914 and made practical by Irving Langmuir in 1923. A small amount of thorium is added to the tungsten of the filament. The filament is heated white-hot, at about 2400 °C, and thorium atoms migrate to the surface of the filament and form the emissive layer. Heating the filament in a hydrocarbon atmosphere carburizes the surface and stabilizes the emissive layer. Thoriated filaments can have very long lifetimes and are resistant to the ion bombardment that occurs at high voltages, because fresh thorium continually diffuses to the surface, renewing the layer. They are used in nearly all high-power vacuum tubes for radio transmitters, and in some tubes for hi-fi amplifiers. Their lifetimes tend to be longer than those of oxide cathodes.\n\nDue to concerns about thorium radioactivity and toxicity, efforts have been made to find alternatives. One of them is zirconiated tungsten, where zirconium dioxide is used instead of thorium dioxide. Other replacement materials are lanthanum(III) oxide, yttrium(III) oxide, cerium(IV) oxide, and their mixtures.\n\nIn addition to the listed oxides and borides, other materials can be used as well. Some examples are carbides and borides of transition metals, e.g. zirconium carbide, hafnium carbide, tantalum carbide, hafnium diboride, and their mixtures. Metals from groups IIIB (scandium, yttrium, and some lanthanides, often gadolinium and samarium) and IVB (hafnium, zirconium, titanium) are usually chosen.\n\nIn addition to tungsten, other refractory metals and alloys can be used, e.g. tantalum, molybdenum and rhenium and their alloys.\n\nA barrier layer of other material can be placed between the base metal and the emission layer, to inhibit chemical reaction between these. The material has to be resistant to high temperatures, have high melting point and very low vapor pressure, and be electrically conductive. Materials used can be e.g. tantalum diboride, titanium diboride, zirconium diboride, niobium diboride, tantalum carbide, zirconium carbide, tantalum nitride, and zirconium nitride.\n\nA \"cathode heater\" is a heated wire filament used to heat the cathode in a vacuum tube or cathode ray tube. The cathode element has to achieve the required temperature in order for these tubes to function properly. This is why older electronics often needs some time to \"warm up\" after being powered on; this phenomenon can still be observed in the cathode ray tubes of some modern televisions and computer monitors. The cathode heats to a temperature that causes electrons to be 'boiled out' of its surface into the evacuated space in the tube, a process called thermionic emission. The temperature required for modern oxide-coated cathodes is around .\n\nThe cathode is usually in the form of a long narrow sheet metal cylinder at the center of the tube. The heater consists of a fine wire or ribbon, made of a high resistance metal alloy like nichrome, similar to the heating element in a toaster but finer. It runs through the center of the cathode, often being coiled on tiny insulating supports or bent into hairpin-like shapes to give enough surface area to produce the required heat. Typical heaters have a ceramic coating on the wire. When it's bent sharply at the ends of the cathode sleeve, the wire is exposed.\nThe ends of the wire are electrically connected to two of the several pins protruding from the end of the tube. When current passes through the wire it becomes red hot, and the radiated heat strikes the inside surface of the cathode, heating it. The red or orange glow seen coming from operating vacuum tubes is produced by the heater.\n\nThere is not much room in the cathode, and the cathode is often built with the heater wire touching it. The inside of the cathode is insulated by a coating of alumina (aluminum oxide). This is not a very good insulator at high temperatures, therefore tubes have a rating for maximum voltage between cathode and heater, usually only 200 to 300 V.\n\nHeaters require a low voltage, high current source of power. Miniature receiving tubes for line-operated equipment use on the order of 0.5 to 4 watts for heater power; high power tubes such as rectifiers or output tubes use on the order of 10 to 20 watts, and broadcast transmitter tubes might need a kilowatt or more to heat the cathode. \nThe voltage required is usually 5 or 6 volts AC. This is supplied by a separate 'heater winding' on the device's power supply transformer that also supplies the higher voltages required by the tubes' plates and other electrodes. One approach used in transformerless line-operated radio and television receivers such as the All American Five is to connect all the tube heaters in series across the supply line. Since all the heaters are rated at the same current, they would share voltage according to their heater ratings.\n\nBattery-operated radio sets used direct-current power for the heaters (commonly known as filaments), and tubes intended for battery sets were designed to use as little filament power as necessary, to economize on battery replacement. The final models of tube-equipped radio receivers were built with subminiature tubes using less than 50 mA for the heaters, but these types were developed at about the same time as transistors which replaced them.\n\nWhere leakage or stray fields from the heater circuit could potentially be coupled to the cathode, direct current is sometimes used for heater power. This eliminates a source of noise in sensitive audio or instrumentation circuits.\n\nThe majority of power required to operate low power tube equipment is consumed by the heaters. Transistors have no such power requirement, which is often a great advantage.\n\nThe emissive layers on coated cathodes degrade slowly with time, and much more quickly when the cathode is overloaded with too high current. The result is weakened emission and diminished power of the tubes, or in CRTs diminished brightness.\n\nThe activated electrodes can be destroyed by contact with oxygen or other chemicals (e.g. aluminium, or silicates), either present as residual gases, entering the tube via leaks, or released by outgassing or migration from the construction elements. This results in diminished emissivity. This process is known as \"cathode poisoning\". High-reliability tubes had to be developed for the early Whirlwind computer, with filaments free of traces of silicon.\n\nSlow degradation of the emissive layer and sudden burning and interruption of the filament are two main failure modes of vacuum tubes.\n\n\n"}
{"id": "20987638", "url": "https://en.wikipedia.org/wiki?curid=20987638", "title": "India Nature Watch", "text": "India Nature Watch\n\nIndia Nature Watch, usually referred to as INW, is a non-commercial community website that focuses on sharing photographs of Indian wildlife. The site was started in 2005 by Sudhir Shivaram, Kalyan Varma, Yathin S K and Vijay Cavale.\n\nINW allows uploads into eight categories: \"Birds, Mammals, Reptiles & Amphibians, Butterflies & Moths, Landscape, Insects & Other Invertebrate, Flora and Others\" and currently hosts close to 400,000 photographs of Indian wildlife. The copyright of images hosted on the site remains with the photographer, although the site does encourage photographers to release photographs under more liberal licenses like Creative Commons.\n\nThe site was started by the moderators of a popular mailing list called \"india-nature-pixs\" when Yahoo stopped storing of attachments on its groups service. The aim of the site is to help document and share India's rich but threatened wildlife through the means of photography, with the help of a community of wildlife photographers in India. Photographs posted on the site have uncovered new ranges for species and documentation of rare wildlife, though the website has come under fire for being emblematic of an Indian wildlife photography culture that has failed to support conservation efforts in any meaningful way.\n\nINW also maintains a strong neutral and non-conflict culture and discourages posting of controversial photographs. It is believed to be the most popular site in India for wildlife photographs.\n\n"}
{"id": "3604289", "url": "https://en.wikipedia.org/wiki?curid=3604289", "title": "Intelligent electronic device", "text": "Intelligent electronic device\n\nAn Intelligent Electronic Device (IED) is a term used in the electric power industry to describe microprocessor-based controllers of power system equipment, such as circuit breakers, transformers and capacitor banks.\n\nIEDs receive data from sensors and power equipment and can issue control commands, such as tripping circuit breakers if they sense voltage, current, or frequency anomalies, or raise/lower voltage levels in order to maintain the desired level. Common types of IEDs include protective relaying devices, On Load Tap Changer controllers, circuit breaker controllers, capacitor bank switches, recloser controllers, voltage regulators etc. This is generally controlled by a setting file. The testing of setting files is typically one of the most time consuming roles of a protection tester.\n\nDigital protective relays are primarily IEDs, using a microprocessor to perform several protective, control and similar functions. A typical IED can contain around 5-12 protection functions, 5-8 control functions controlling separate devices, an autoreclose function, self monitoring function, communication functions etc. Hence, they are aptly named as Intelligent Electronic Devices.\n\nSome recent IEDs are designed to support the IEC61850 standard for substation automation, which provides interoperability and advanced communications capabilities.\n\n"}
{"id": "519796", "url": "https://en.wikipedia.org/wiki?curid=519796", "title": "Iodide", "text": "Iodide\n\nAn iodide ion is the ion I. Compounds with iodine in formal oxidation state −1 are called iodides. This page is for the iodide ion and its salts, not organoiodine compounds. In everyday life, iodide is most commonly encountered as a component of iodized salt, which many governments mandate. Worldwide, iodine deficiency affects two billion people and is the leading preventable cause of intellectual disability.\n\nIodide is one of the largest monatomic anions. It is assigned a radius of around 206 picometers. For comparison, the lighter halides are considerably smaller: bromide (196 pm), chloride (181 pm), and fluoride (133 pm). In part because of its size, iodide forms relatively weak bonds with most elements.\n\nMost iodide salts are soluble in water, but often less so than the related chlorides and bromides. Iodide, being large, is less hydrophilic compared to the smaller anions. One consequence of this is that sodium iodide is highly soluble in acetone, whereas sodium chloride is not. The low solubility of silver iodide and lead iodide reflects the covalent character of these metal iodides. A test for the presence of iodide ions is the formation of yellow precipitates of these compounds upon treatment of a solution of silver nitrate or lead(II) nitrate.\n\nAqueous solutions of iodide salts dissolve iodine better than pure water. This effect is due to the formation of the triiodide ion, which is brown:\n\nIodide salts are mild reducing agents and many react with oxygen to give iodine. A reducing agent is a chemical term for an antioxidant. Its antioxidant properties can be expressed quantitatively as a redox potential :\n\nBecause iodide is easily oxidized, some enzymes readily convert it into electrophilic iodinating agents, as required for the biosynthesis of myriad iodide-containing natural products. Iodide can function as an antioxidant reducing species that can destroy reactive oxygen species such as hydrogen peroxide:\n\nIodargyrite - natural, crystalline silver iodide - is the most common iodide mineral currently known. Iodide anions may sometimes also be found combined with mercury, copper and lead, but minerals with such compositions are even more scarce.\n\nIodine can assume oxidation states of −1, +1, +3, +5, or +7. A number of neutral iodine oxides are also known.\n\n"}
{"id": "51267693", "url": "https://en.wikipedia.org/wiki?curid=51267693", "title": "Kovvada Atomic Power Project", "text": "Kovvada Atomic Power Project\n\nKovvada Atomic Power Project is a proposed 6,600 MW nuclear power station in the state of Andhra Pradesh, India. The project is planned over an area of 2067 acres. According to a GV Ramesh, the project director at NPCIL, close to 485 acres of land has already been handed over for the project by the Srikakulam district administration. The acquisition of the remaining 1582 acres of land is expected to be completed by October 2017. \n"}
{"id": "54533671", "url": "https://en.wikipedia.org/wiki?curid=54533671", "title": "Liopropoma emanueli", "text": "Liopropoma emanueli\n\nThe Cape Verde or Cape Verdes basslet (\"Liopropoma emanueli\") is a species of basslet endemic to the Atlantic waters around Cape Verde, western Africa where it is found at depths of about and in rocky areas. Its length is not well understood.\n\nThe type of grouper, the basslet was first founded in the Danger diving site southwest of Tarrafal in the island of Santiago at 15°15'51.22\" N and23°45'35.41\" W, below overhanging large boulder, 20 m in depth. It was named and described by Peter Wirtz and Ulrich K. Schliewen in 2012. They are founded in the north of Santiago and likely the southern part.\n\nThe species is named in honour of Emanuel d’Oliveira, whose knowledge of the marine fauna of Santiago Island has been a great help to the first author during many dives.\n"}
{"id": "53437170", "url": "https://en.wikipedia.org/wiki?curid=53437170", "title": "March 2017 North American blizzard", "text": "March 2017 North American blizzard\n\nThe March 2017 North American blizzard was a major late-season blizzard that affected the Northeastern United States, New England and Canada, dumping up to of snow in the hardest hit areas, mainly New York, Vermont, New Hampshire and Southern Quebec. Forming out of an extratropical cyclone near the Northwest, the storm system dived into the northern portions of the United States, dropping light to moderate snow across the Great Lakes, Upper Midwest on March 11–12 before reaching the Ohio Valley the next day. It later coalesced into a powerful nor'easter off the East Coast, producing a swath of heavy snowfall across a large portion of the Northeast. The storm was given various unofficial names, such as \"Winter Storm Stella\", \"Blizzard Eugene\", and \"Blizzard of 2017\".\n\nAhead of the storm, residents prepared in advance for the major nor'easter, with blizzard warnings issued for several states, including New York, Pennsylvania, New Jersey, Connecticut, Rhode Island, and Massachusetts. Several officials had crews with salt trucks ready to deploy to clear roads. The system also disrupted travel across the country, with numerous flight cancellations at most of the major airports in the Northeast. It dropped a swath of moderate snow accumulation as it moved across the northern tier of the country, with as much as reported. The storm was also responsible for ending a record streak without snowfall in Chicago, Illinois, where no snow had occurred since December 25, 2016.\n\nOn March 9, an extratropical cyclone formed in the North Pacific Ocean. On March 11, it began to affect parts of the Northwestern United States as well as British Columbia in Canada. It eventually moved ashore later that day and transferred its energy to a new surface low, which began to move southeastwards into the United States as an Alberta clipper. The system moved swiftly across the Upper Midwest throughout the day of March 12, dropping a swath of accumulating snow of as frontogenesis took place. On March 13 at 15:00 UTC, the Weather Prediction Center began issuing storm summaries while the system was located west-northwest of St. Louis, Missouri. Throughout the day, a weak secondary area of low pressure formed in the Gulf of Mexico and drifted northeastwards, while not expected to fuse with the other low to its north, it helped inject moisture from the ocean over the state of Florida, which gradually began to merge with the outermost fringes of the northerly system that had now moved into the Ohio Valley.\n\nBy 21:00 UTC that night, a new surface low developed off the Georgia coastline with a central pressure of , eventually becoming the dominant low of the nor'easter. The storm began to rapidly deepen as it moved parallel to the East Coast of the United States, with the central pressure dropping to by 15:00 UTC on March 14 while it was just off the Maryland coastline. The storm continued to intensify as it drifted northeastwards towards Long Island, continuing to produce an expansive area of snow with heavier rates embedded in snowbands across Connecticut, northern New York and most of interior New England, as well as parts of Canada. The low subsequently reached its peak intensity of while just inland over Long Island. By 20:00 UTC, most of the snow had come to an end in New Jersey, Delaware, and Washington D.C., as the low began to move inland over New England; subsequently it also began to weaken as it traveled further inland, and by early on March 15, snow began to end in more parts of the region. The system continued to weaken as it moved slowly through upper New England, the system continued to weaken, consequently, the Weather Prediction Center terminated storm summaries on the winter storm as nearly most of the moderate to heavy snow had stopped in the region and switched to rain. On March 18, the low that was formerly the blizzard had moved out to sea and dissipated.\n\nPredictions of the storm were criticized by some due to overestimation of the predicted snowfall totals in the major metropolitan areas including New York City, with \"The Daily Mail\" calling it \"the blizzard that WASN'T\". On March 14, New York Governor Andrew Cuomo stated that the storm was not as bad as previously anticipated, due to the change over to a mix of snow and sleet, but advised residents to not let their guard down, as the storm was still predicted to cause high wind gusts and coastal flooding.\n\nThe reduction in snowfall totals was due to a shift in the storm's track to the west more towards the New Jersey coastline, which resulted in more mixed precipitation rather than snow. Initially, the National Weather Service predicted that the blizzard would leave New York City with up to (rivaling it almost with the Great Blizzard of 1888), however these totals were later reduced due to the change in the system's track. Similarly, the metro area faced a similar situation a little over two years prior where New York City was predicted to receive up to of snow, but only received less than half of the predicted amount due to a shift in the storm's track by .\n\nMeteorologists at the National Weather Service were aware of the changing conditions that led to lesser snow accumulations along the coast the night prior to the expected event. In a multi-office conference, however, forecasters decided to maintain the higher-than-likely snowfall predictions \"out of extreme caution.\" They sought to avoid sending mixed and/or incorrect messages about a dangerous storm by maintaining a steady forecast.\n\nAmtrak made several adjustments to service on the Northeast Corridor in preparation of the storm. On the \"Acela Express\", service was suspended between New York City and Boston and reduced between Washington, D.C. and New York City on March 14. \"Northeast Regional\" trains were placed on a modified schedule on March 14 with several trains shortened or cancelled. \"Keystone Service\" trains were placed on a severe weather schedule for March 14. Bieber Transportation Group cancelled buses to Philadelphia and New York City on March 14.\n\nPresident Donald Trump postponed a meeting with Angela Merkel due to the nor'easter.\n\nOn March 11, the National Weather Service issued blizzard watches for parts of the Northeast, including New York City.\n\nLate on March 12, officials issued a hazardous travel advisory in advance of the storm, which was predicted to bring up to of snow to parts of the state, including Staten Island.\n\nThe following day on March 13, New York City mayor Bill de Blasio urged the residents of the region to avoid traveling at any point due to the dangerous conditions and also allowing for sanitation crews to respond faster. The New York City Department of Sanitation said that they had nearly 700 salt spreaders across the boroughs of the state, and 1,600 plows would be dispatched to clear the roadways. New York Governor Andrew Cuomo advised everyone in a statement that \"[I] encourage all New Yorkers in affected regions to plan ahead, and avoid any unnecessary travel as the storm progresses,\" and also said to expect disruptions to travel and transportation.\n\nA state of emergency was declared in New York City on March 13, in which the subway system will be shut down on March 14. The state also declared state of emergency.\n\nOn March 13, a snow emergency was declared for Philadelphia, which was to go into effect later that night. 50,000 tons of salt were said to be available and salting would begin when the snow arrived. Pennsylvania Governor Tom Wolf signed a proclamation of disaster that day and stated that speeds would be restricted on most major freeways. Several businesses and attractions in Philadelphia closed on March 14 including the Philadelphia Zoo and the Philadelphia Museum of Art. SEPTA made changes to bus and train service in anticipation of the storm, with service on several bus routes altered or suspended and Regional Rail service running on a modified Saturday schedule on March 14. Several flights at Philadelphia International Airport on March 14 were cancelled in anticipation of the storm. The Berks Area Regional Transportation Authority and Lehigh and Northampton Transportation Authority cancelled all service on March 14. The United States Postal Service closed post offices and cancelled mail delivery for several locations in Pennsylvania on March 14.\n\nSchools in Northern New Jersey have announced closures for Tuesday. A state of emergency was later declared by Governor Chris Christie, with state offices closed on March 14. New Jersey Transit suspended bus service starting at midnight on March 14 and implemented weekend schedules on commuter rail and light rail lines for March 14. PATCO Speedline announced they would be operating on a reduced snow schedule on March 14.\n\nIn Delaware, Governor John Carney issued a level one driving warning for New Castle County and DMV offices in New Castle County were closed on March 14.\n\nWashington, D.C., was issued a winter storm warning on March 13. MetroAccess is issued to shut down on March 14.\n\nVirginia Governor Terry McAuliffe also declared a state of emergency late on March 13. The state of emergency was to allow state agencies to assist local governments as they respond to the storm. Roughly 4,500 pieces of equipment were ready to plow once snow totals began to exceed two inches.\n\nA state of emergency was declared in Maryland by Governor Larry Hogan, urging people to prepare for the storm and stay off the roads.\n\nIn Boston, the Massachusetts Emergency Management Agency said that they had mechanics working on loads of equipment to get ready for plowing the roads. Approximately 130 flights were cancelled as of the morning of March 13.\n\nIn advance of the nor'easter, the Connecticut Department of Transportation readied 634 trucks and 250 contractors. On March 13, Connecticut Governor Dannel Malloy issued a statewide travel ban, ordering all non-essential first and second shift employees to remain home. Prominent educational institutions, such as the University of Connecticut and Yale University, closed campuses while local districts shut down as well. The Department of Motor Vehicles cancelled all scheduled road tests. State police planned to ready additional staff leading up to the storm. Bridgeport Mayor Joe Ganim declared a snow emergency late on March 12 while Hartford officials warned city residents of a parking ban beginning at 8 p.m. EDT the following day. The city of New Haven issued a citywide travel ban effective on March 14. Airport officials at Bradley International Airport began organizing plans for snow removal in the wake of the snowstorm. The Metropolitan Transportation Authority deployed extra staff and specialized equipment, while Peter Pan Bus Lines canceled services from upstate New York to Washington D.C. Eversource Energy and The United Illuminating Company contacted city and town leaders for organization prior to the storm and assistance in its wake. At 4 p.m. EST (21:00 UTC) nearly the whole state went into a blizzard warning, except for shoreline areas of Middlesex and New London counties.\n\nIn Rhode Island, parking bans were issued in cities statewide on March 13. Utilities crews prepared for the snow on March 14.\n\nSome town hall meetings were canceled are postponed in New Hampshire, including Manchester, due to the storm. Schools around the southern part of the state closed on March 14.\n\nThe Maine Department of Transportation had to prepare for the storm in Eastern Maine on March 13.\n\nWinter storm warnings were issued in the Canadian Maritimes on March 13 and for all Southern and Eastern Quebec. Because the system tracked farther inland than expected on the US East Coast, snow accumulations forecast constantly increased on March 12–13 in Ontario and Quebec.\n\nSnow started falling in the early hours of March 14. West Springfield had received 3 inches of snow by 9:15 a.m. EST (12:15 UTC).\n\nHurricane-force wind gusts of were recorded in Wellfleet, Massachusetts and of on Plum Island.\n\nExcept for pockets, most of the snow dissipated in the night of March 14. Due to the wind cycle, Boston was at nearly on the night of March 14.\n\nSnow started falling in the early hours of March 14. Except for pockets, most of the snow dissipated in the night of March 14. A man died in East Hartford after being hit by a plow truck. Approximately 1,700 customers lost power during the storm. Some areas, including Middletown got up to of snow.\n\nSnow started falling in the early hours of March 14. Except for pockets, most of the snow dissipated in the night of March 14. Rhode Island wasn't as badly hit as other states, due to its location to the Atlantic Ocean. It toppled a wind turbine, due to winds.\n\nSnow started falling in the three states of Maine, Vermont, and New Hampshire on the morning of March 14.\n\nMaine experienced blizzard conditions in some areas. Except for pockets, the snow ended in the mid-afternoon of March 15.\n\nBurlington, Vermont snow's lingered around for a while. The snow ended on the morning of March 15.\n\nThe nor'easter produced maximum wind gusts (at elevation) of at Mount Washington, New Hampshire. The snow ended on the morning of March 15.\n\nWestern New York started getting hit by snow during the evening of March 13. The strongest parts of the storm on March 14 hit the Catskills area of the state. The blizzard warning for New York City was rescinded early in the morning. Freezing rain and sleet was common in the southern areas of the state, along with flooding. By the evening of March 15, except for small bands of snow in Central New York, the snow had ended. 3-6 deaths were reported in the state.\n\nSnow started falling on the night of March 13. The snow had ended by the evening of March 14. Flooding was also caused by this storm. Along with high winds, beach erosion was common along the southern shore.\n\nSnow started falling on the night of March 13. Except for small pockets, the snow ended by the early-morning of March 15. The National Guard ended bringing a sick child to the hospital during the storm. 40,000 people lost power during the storm. 3 deaths have been reported from the state. Mail delivery from the United States Postal Service was suspended in many areas.\n\nSnow started falling on the night of March 13. It had turned into sleet by the mid-morning of March 14. It left the state by the late-afternoon of March 14.\n\nSnow started falling on the evening of March 13. It had turned into sleet by the mid-morning of March 14. It left the state by the morning of March 14.\n\nSnow started falling on the evening of March 13. By the start of the day of March 14, it had turned into a wintry mix, then to rain. It left the area by the afternoon of March 14. Washington Dulles airport's flights starting departing at the end of the day.\n\nThe snow began hitting Ontario and Quebec on March 13 around noon. It rapidly intensified in the afternoon over portions of Southern Quebec and the Eastern Townships before becoming a powerful blizzard over Montreal and its South Shore, as heavy snow bands came from the South-East and did a wrap-around effect just on the South Shore of Montreal, where the snow fell at a rate of more than 7.5 cm/hr (3 in/hr) for more than 6 hours between 6PM and midnight. Environment Canada reported that a blizzard officially occurred in Montreal and Quebec City. The storm continued to track Northeast and affected Quebec City and Eastern Quebec where blizzard conditions were also occurring in the night. At the end of the blizzard, 18 cm (7 in) were recorded in Ottawa, 40 cm (16 in) in Montreal, 35 cm (14 in) in Quebec City, 55 cm (22 in) in Sherbrooke, 70 cm (28 in) in Drummondville, and more than 75 cm (30 in) in several locations such as Saint-Hubert, Vaudreuil-Dorion and Saint-Jean-sur-Richelieu.\n\nWinds from the Northeast increased in the Saint Lawrence River between Montreal and Quebec City in the evening, producing the blizzard. Wind gusts reached 107 km/h (66 mph) at Montreal Pierre-Elliott Trudeau International Airport, 113 km/h (70 mph) at Saint-Hubert Airport on the South Shore and 140 km/h (87 mph) at Quebec International Airport. Numerous road pileups occurred, most notably on Ontario Highway 401 near Mallorytown, on Quebec highway 20 near Saint-Zotique (which caused a major fire, destroying several semis and killing one of their drivers), on highway 10 near Magog, on highway 40 near Lavaltrie and on Highway 20 near Sainte-Hélène de Bagot. Road closures included highway 15 near the USA border, highway 10 near Magog, highway 20 in Saint-Zotique and Saint-Eugène, and most notably on highway 13 on Montreal Island, where several hundreds of cars and trucks were left trapped for more than 14 hours due to communication and logistic issues complicating the evacuation.\n\nIn Quebec, many areas were left without power for more than 24 hours. In Quebec city, the Saint-Lawrence river stepped out of its riverbed, flooding both areas of Quebec City and Lévis. Five people were killed during the storm itself. At least two more (both elderly males) were found dead in Montreal in parked cars over the following days, presumably killed by heart attacks while attempting to clear them out.\n\nThe storm started affected New Brunswick in the afternoon on March 14, with the other Atlantic Canadian provinces being hit in the early evening. The Maritime's snow ended at the night of March 15, even though Newfoundland countines to have snow.\n\nThe first phase of the storm hit the Midwest on March 13, causing up to of snow in some areas. 2 deaths were reported in Wisconsin.\n\nMultiple states ended up getting dustings of snow on March 12.\n\nIn the British Isles, the remnants of the storm caused rain to fall across the region, turning to snow in the mountains of Scotland.\n\nThe storm has received several different unofficial names from different media outlets. The Weather Channel, which names significant winter storms that have disruptive impacts on major cities, assigned the name \"Stella\" to the winter storm. Connecticut based WFSB dubbed the storm \"Blizzard Eugene\". The National Weather Service has stated though that, unlike hurricanes, it does not name winter storms. The practice of winter storm naming remains controversial in the United States.\n"}
{"id": "27714702", "url": "https://en.wikipedia.org/wiki?curid=27714702", "title": "Mingbulak oil spill", "text": "Mingbulak oil spill\n\nThe Mingbulak oil spill also known as the Fergana Valley oil spill was the worst terrestrial oil spill in the history of Asia. The oil spill was caused by a blowout on March 2, 1992 at the Mingbulak oil field in the Fergana Valley, Uzbekistan at well #5. The Crude oil released from the well burned for two months. The blowout resulted in the release of to per day. In total, were collected behind emergency dykes. The oil stopped flowing by itself. A total of 285,000 tons of oil were released, and it was the fifth largest oil spill in history. The spill is considered the largest inland spill in history.\n\n\n"}
{"id": "1594030", "url": "https://en.wikipedia.org/wiki?curid=1594030", "title": "Moisture sensitivity level", "text": "Moisture sensitivity level\n\nMoisture sensitivity level relates to the packaging and handling precautions for some semiconductors. The MSL is an electronic standard for the time period in which a moisture sensitive device can be exposed to ambient room conditions (30 °C/85%RH at Level 1; 30 °C/60%RH at all other levels).\n\nIncreasingly, semiconductors have been manufactured in smaller sizes. Components such as thin fine-pitch devices and ball grid arrays could be damaged during SMT reflow when moisture trapped inside the component expands.\n\nThe expansion of trapped moisture can result in internal separation (delamination) of the plastic from the die or lead-frame, wire bond damage, die damage, and internal cracks. Most of this damage is not visible on the component surface. In extreme cases, cracks will extend to the component surface. In the most severe cases, the component will bulge and pop. This is known as the \"popcorn\" effect.\n\nIPC (Association Connecting Electronic Industries) created and released IPC-M-109, Moisture-sensitive Component Standards and Guideline Manual (\"not active\").\n\nMoisture sensitive devices are packaged in a moisture barrier antistatic bag with a desiccant and a moisture indicator card which is sealed.\n\nIPC-M-109 includes seven documents. According to : Moisture/reflow sensitivity classification for plastic\nIntegrated circuit (IC) SMDs, there are eight levels of moisture sensitivity. Components must be mounted and reflowed within the allowable period of time (floor life out of the bag).\n\n\nIPC/JEDEC J-STD-020E, Moisture/Reflow Sensitivity Classification for Nonhermetic Surface Mount Devices, December 2014.\n"}
{"id": "2579057", "url": "https://en.wikipedia.org/wiki?curid=2579057", "title": "Nature Conservancy (UK)", "text": "Nature Conservancy (UK)\n\nThe Nature Conservancy was a British government agency established by Royal Charter in 1949.\n\nThe Nature Conservancy was superseded by the Nature Conservancy Council in 1973.\n"}
{"id": "19210425", "url": "https://en.wikipedia.org/wiki?curid=19210425", "title": "Next of Kin (nonfiction)", "text": "Next of Kin (nonfiction)\n\nNext of Kin is a 1997 book by Roger Fouts combining his experiences with Washoe and other chimpanzees who learned American Sign Language, and a polemic in favor of great ape personhood.\n\n"}
{"id": "1278087", "url": "https://en.wikipedia.org/wiki?curid=1278087", "title": "Nissan Titan", "text": "Nissan Titan\n\nThe Nissan Titan is a full-size pickup truck manufactured in the United States for the North American market by Nissan. It was named for the Titans of Greek mythology.\n\nDevelopment of the Titan began in September 1999, with design work under Diane Allen. Giovanny Arroba's TA60 exterior was chosen in late 2000, with a final production freeze in July 2001. The design language of the future truck was previewed by the 2001 Alpha T concept shown at the 2001 Detroit Auto Show, which had previously developed through November 2000. \n\nProduction began on September 21, 2003 and sales on December 1, 2003. The Titan used Nissan's new full-size F-Alpha platform. This new platform was shared with the Nissan Armada and Infiniti QX56 SUVs, with all three manufactured in Canton, Mississippi, United States. The first generation Titan continued without a major redesign through 2015.\n\nAll models came standard with a 32-valve, 5.6-liter engine, VK56DE, which generates ( on 2004–2006 models) and of torque. The first generation Titan came equipped with a fully boxed ladder frame and was available in either rear-wheel drive or a shift-on-the-fly four-wheel-drive system coupled with a five-speed RE505A automatic transmission. An automatic brake-limited slip (ABLS) system was available on all Titans. The first generation was available as a King Cab (extended cab) or a crew cab with a full-sized back seat, with no regular cab being offered. The King Cab featured a bed, while the crew cab had a bed. In 2008, a longer wheelbase model was offered with either an bed on the King Cab or a bed on the crew cab. There were originally four trim levels available: the S, SV, Pro-4x, SE, and LE. The SE and LE trim was eventually replaced by the luxury SL trim. The S was the base model, the SV a mid-level model with more features, the PRO-4X was the off-road-oriented version, and the top level SL was offered with features like 20-inch alloy wheels as standard equipment.\n\nFeatures available on the first generation included:\n\nThe first generation Titan carried a five-star rating from the National Highway Traffic Safety Administration for driver frontal crash, and a four-star rating for passenger frontal crash.\n\nThe second-generation Titan was to be a lightly reskinned, rebadged version of the Dodge Ram, but those plans fell through with the 2008 worldwide financial crisis.\n\nNissan unveiled the second generation Titan at the 2015 North American International Auto Show. The second generation Titan was designed in California, engineered in Michigan, tested in Arizona, and is assembled in Mississippi. The V8 Cummins is built in Indiana and Tennessee. \n\nCummins has partnered with Nissan and has announced that the next generation Titan will offer a Cummins 5.0-liter turbo diesel V8 (after plans with Dodge fell through) that produces almost of torque. The engine is referred to as the ISV. The engine will be built in Columbus, Indiana, and have a different version of the engine for commercial trucks. The 5.6-liter gasoline engine will remain standard. Additionally, the gasoline engine has increased in power compared to the previous model, producing and of torque mated to a 7-speed automatic.\n\nThe 2nd-generation Titan is available in two forms, regular and XD, with the XD having been released for sale first. The XD version is built on a heavy-duty frame based on Nissan's commercial vehicle line and includes the Cummins diesel engine as an option. The platform is shared with the Nissan NV.\n\n\n"}
{"id": "42053487", "url": "https://en.wikipedia.org/wiki?curid=42053487", "title": "Offset well", "text": "Offset well\n\nAn offset well is an existing wellbore that may be used as a guide for planning a well. Many offsets could be referred to in the planning of a well, to identify subsurface geology and pressures. Offset well data may be combined with seismic data and prior experience. Where offset data is lacking, well planners will be more conservative, allowing for a greater range of contingencies and expenses.\n\nHigh quality offset well data is highly sought after by planners for optimizing their designs, and is also used retrospectively to benchmark performance. Offset data from competing companies is particularly coveted but very hard to obtain due to a profound reluctance by oil and gas operators to share their offset data with competitors.\n\nAs well planning becomes more complex, regulated and expensive, access to offset well data becomes increasingly important for well planning and benchmarking.\n"}
{"id": "2327063", "url": "https://en.wikipedia.org/wiki?curid=2327063", "title": "PAMELA detector", "text": "PAMELA detector\n\nPAMELA (Payload for Antimatter Matter Exploration and Light-nuclei Astrophysics) was a cosmic ray research module attached to an Earth orbiting satellite. \"PAMELA\" was launched on 15 June 2006 and was the first satellite-based experiment dedicated to the detection of cosmic rays, with a particular focus on their antimatter component, in the form of positrons and antiprotons. Other objectives included long-term monitoring of the solar modulation of cosmic rays, measurements of energetic particles from the Sun, high-energy particles in Earth's magnetosphere and Jovian electrons. It was also hoped that it may detect evidence of dark matter annihilation. PAMELA operations were terminated in 2016, as were the operations of the host-satellite Resurs-DK1.\n\n\"PAMELA\" was the largest device up to the time built by the Wizard collaboration, which includes Russia, Italy, Germany and Sweden and has been involved in many satellite and balloon-based cosmic ray experiments such as Fermi-GLAST. The 470 kg, US$32 million (EU€24.8 million, UK£16.8 million) instrument was originally projected to have a three-year mission. However, this durable module remained operational and made significant scientific contributions until 2016.\n\n\"PAMELA\" is mounted on the upward-facing side of the Resurs-DK1 Russian satellite. It was launched by a Soyuz rocket from Baikonur Cosmodrome on 15 June 2006. \"PAMELA\" has been put in a polar elliptical orbit at an altitude between 350 and 610 km, with an inclination of 70°.\n\nThe apparatus is 1.3 m high, has a total mass of 470 kg and a power consumption of 335 W. The instrument is built around a permanent magnet spectrometer with a silicon microstrip tracker that provides rigidity and dE/dx information. At its bottom is a silicon-tungsten imaging calorimeter, a neutron detector and a shower tail scintillator to perform lepton/hadron discrimination. A Time of Flight (ToF), made of three layers of plastic scintillators, is used to measure the velocity and charge of the particle. An anticounter system made of scintillators surrounding the apparatus is used to reject false triggers and albedo particles during off-line analysis.\n\nPreliminary data (released August 2008, ICHEP Philadelphia) indicate an excess of positrons in the range 10–60 GeV. This is thought to be a possible sign of dark matter annihilation:\nhypothetical WIMPs colliding with and annihilating each other to form gamma rays, matter and antimatter particles. Another explanation considered for the indication mentioned above is the production of electron-positron pairs on pulsars with subsequent acceleration in the vicinity of the pulsar.\n\nThe first two years of data were released in October 2008 in three publications. The positron excess was confirmed and found to persist up to 90 GeV. Surprisingly, no excess of antiprotons was found. This is inconsistent with predictions from most models of dark matter sources, in which the positron and antiproton excesses are correlated.\n\nA paper, published on 15 July 2011, confirmed earlier speculation that the Van Allen belt could confine a significant flux of antiprotons produced by the interaction of the Earth's upper atmosphere with cosmic rays. The energy of the antiprotons has been measured in the range of 60–750 MeV. Cosmic rays collide with atoms in the upper atmosphere creating antineutrons, which in turn decay to produce the antiprotons. They were discovered in a part of the Van Allen belt closest to Earth. When an antiproton interacts with a normal particle, both are annihilated. Data from PAMELA indicated that these annihilation events occurred a thousand times more often than would be expected in the absence of antimatter. The data that contained evidence of antimatter were gathered between July 2006 and December 2008.\n\nBoron and carbon flux measurements were published in July 2014, important to explaining trends in cosmic ray positron fraction.\n\nThe summary document of the operations of PAMELA was published in 2017.\n\nBetween 1 and 100 GeV, \"PAMELA\" is exposed to one hundred times as many electrons as antiprotons. At 1 GeV there are one thousand times as many protons as positrons and at 100 GeV ten thousand times as many. Therefore, to correctly determine the antimatter abundances, it is critical that PAMELA is able to reject the matter background. The PAMELA collaboration claimed in The electron hadron separation performance of the PAMELA electromagnetic calorimeter that less than one proton in 100,000 is able to pass the calorimeter selection and be misidentified as a positron when the energy is less than 200 GeV.\n\nThe ratio of matter to antimatter in cosmic rays of energy less than 10 GeV that reach PAMELA from outside the solar system depends on solar activity and in particular on the point in the 11 year solar cycle. The \"PAMELA\" team has invoked this effect to explain the discrepancy between their low energy results and those obtained by \"CAPRICE\", \"HEAT\" and \"AMS-01\", which were collected during that half of the cycle when the solar magnetic field had the opposite polarity. It is important to note that these results are consistent with the series of positron / electron measurements obtain by \"AESOP\", which has spanned coverage over both polarities. Also the \"PAMELA\" experiment has contradicted an earlier claim by the \"HEAT\" experiment of anomalous positrons in the 6 GeV to 10 GeV range.\n\n\n"}
{"id": "256322", "url": "https://en.wikipedia.org/wiki?curid=256322", "title": "Peter Tait (physicist)", "text": "Peter Tait (physicist)\n\nPeter Guthrie Tait FRSE (28 April 1831 – 4 July 1901) was a Scottish mathematical physicist and early pioneer in thermodynamics. He is best known for the mathematical physics textbook \"Treatise on Natural Philosophy\", which he co-wrote with Kelvin, and his early investigations into knot theory,\n\nHis work on knot theory contributed to the eventual formation of topology as a mathematical discipline. His name is known in graph theory mainly for Tait's conjecture.\n\nTait was born in Dalkeith on 28 April 1831 the only son of Mary Ronaldson and John Tait, secretary to the 5th Duke of Buccleuch. \n\nHe was educated at Dalkeith Grammar School then Edinburgh Academy. He then studied Maths and Physics at the University of Edinburgh, and then went to Peterhouse, Cambridge, graduating as senior wrangler and first Smith's prizeman in 1852. As a fellow and lecturer of his college he remained at the University for a further two years, before leaving to take up the professorship of mathematics at Queen's College, Belfast. There he made the acquaintance of Thomas Andrews, whom he joined in researches on the density of ozone and the action of the electric discharge on oxygen and other gases, and by whom he was introduced to Sir William Rowan Hamilton and quaternions.\n\nIn 1860, Tait succeeded his old master, James D. Forbes, as professor of natural philosophy at the University of Edinburgh, and occupied the Chair until shortly before his death. The first scientific paper under Tait's name only was published in 1860. His earliest work dealt mainly with mathematical subjects, and especially with quaternions, of which he was the leading exponent after their originator, William Rowan Hamilton. He was the author of two text-books on them—one an \"Elementary Treatise on Quaternions\" (1867), written with the advice of Hamilton, though not published till after his death, and the other an \"Introduction to Quaternions\" (1873), in which he was aided by Philip Kelland (1808–1879), one of his teachers at the University of Edinburgh. Quaternions was also one of the themes of his address as president of the mathematical section of the British Association for the Advancement of Science in 1871.\n\nHe also produced original work in mathematical and experimental physics. In 1864, he published a short paper on thermodynamics, and from that time his contributions to that and kindred departments of science became frequent and important. In 1871, he emphasised the significance and future importance of the \"principle of the dissipation of energy\" (second law of thermodynamics). In 1873 he took thermoelectricity for the subject of his discourse as Rede lecturer at Cambridge, and in the same year he presented the first sketch of his well-known thermoelectric diagram before the Royal Society of Edinburgh.\n\nTwo years later, researches on \"Charcoal Vacua\" with James Dewar led him to see the true dynamical explanation of the Crookes radiometer in the large mean free path of the molecule of the highly rarefied air. From 1879 to 1888, he engaged in difficult experimental investigations. These began with an inquiry into what corrections were required for thermometers operating at great pressure. This was for the benefit of thermometers employed by the \"Challenger\" expedition for observing deep-sea temperatures, and were extended to include the compressibility of water, glass, and mercury. This work led to the first formulation of the Tait equation, which is widely used to fit liquid density to pressure. Between 1886 and 1892 he published a series of papers on the foundations of the kinetic theory of gases, the fourth of which contained what was, according to Lord Kelvin, the first proof ever given of the Waterston-Maxwell theorem (equipartition theorem) of the average equal partition of energy in a mixture of two gases. About the same time he carried out investigations into impact and its duration.\n\nMany other inquiries conducted by him might be mentioned, and some idea may be gained of his scientific activity from the fact that a selection only from his papers, published by the Cambridge University Press, fills three large volumes. This mass of work was done in the time he could spare from his professorial teaching in the university. For example, in 1880 he worked on the Four color theorem and proved that it was true if and only if no snarks were planar.\n\nIn addition, he was the author of a number of books and articles. Of the former, the first, published in 1856, was on the dynamics of a particle; and afterwards there followed a number of concise treatises on thermodynamics, heat, light, properties of matter and dynamics, together with an admirably lucid volume of popular lectures on Recent Advances in Physical Science.\n\nWith Lord Kelvin, he collaborated in writing the well-known \"Treatise on Natural Philosophy\". \"Thomson and Tait,\" as it is familiarly called (\" T and T' \" was the authors' own formula), was planned soon after Lord Kelvin became acquainted with Tait, on the latter's appointment to his professorship in Edinburgh, and it was intended to be an all-comprehensive treatise on physical science, the foundations being laid in kinematics and dynamics, and the structure completed with the properties of matter, heat, light, electricity and magnetism. But the literary partnership ceased in about eighteen years, when only the first portion of the plan had been completed, because each of the members felt he could work to better advantage separately than jointly. The friendship, however, endured for the remaining twenty-three years of Tait's life.\n\nTait collaborated with Balfour Stewart in the \"Unseen Universe\", which was followed by \"Paradoxical Philosophy\". It was in his 1875 review of \"The Unseen Universe\", that William James first put forth his Will to Believe Doctrine. Tait's articles include those he wrote for the ninth edition of the \"Encyclopædia Britannica\" on light, mechanics, quaternions, radiation, and thermodynamics, and the biographical notices of Hamilton and James Clerk Maxwell.\n\nHe died in Edinburgh on 4 July 1901. He is buried in the second terrace down from Princes Street in the burial ground of St John's Episcopal Church, Edinburgh.\n\nThe Tait conjectures are three conjectures made by Tait in his study of knots. The Tait conjectures involve concepts in knot theory such as alternating knots, chirality, and writhe. All of the Tait conjectures have been solved, the most recent being the Flyping conjecture, proved my Morwen Thistlethwaite and William Menasco in 1991.\n\n\nTait was married to Margaret Archer Porter (1839-1926), the sister of (1) William Archer Porter, a lawyer and educationist who served as the Principal of Government Arts College, Kumbakonam and tutor and secretary to the Maharaja of Mysore, (2) James Porter (Master of Peterhouse, Cambridge) and (3) Jane Bailie Porter, who married Alexander Crum Brown, the Scottish organic chemist.\n\nTait was an enthusiastic golfer and, of his seven children, two, Frederick Guthrie Tait (1870–1900) and John Guthrie Tait (1861–1945) went on to become gifted amateur golf champions. He was an all-round sportsman and represented Scotland at international level in rugby union. Tait himself had, in 1891, invoked the Magnus effect to explain the influence of spin on the flight of a golf ball. His daughter Edith Tait was married to Rev. Harry Reid, who later became Bishop of Edinburgh.\n\nHis son William Archer Porter Tait was a civil engineer.\n\nTait was a lifelong friend of James Clerk Maxwell, and a portrait of Tait by Harrington Mann is held in the James Clerk Maxwell Foundation museum in Edinburgh.\n\n"}
{"id": "9918319", "url": "https://en.wikipedia.org/wiki?curid=9918319", "title": "Polyiodide", "text": "Polyiodide\n\nThe polyiodides are a class of polyhalogen anions composed entirely of iodine atoms. The most common and simplest member is the triiodide ion, . Other known, larger polyiodides include [I], [I], [I], [I], [I], [I], [I], [I], [I], [I], [I], [I], [I], [I], [I] and [I].\n\nThe polyiodides can be made by addition of stoichiometric amounts of I to solutions containing I and , with the presence of large counter-cations to stabilize them. For example, KI·HO can be crystallized from a saturated solution of KI when a stoichiometric amount of I is added and cooled.\n\nPolyiodides are characterized by their highly complex and variable structures, and can be considered as associations of I, I, and units. Discrete polyiodides are usually linear, reflecting the origin of the ion. The more complex two- or three-dimensional network structures of chains and cages are formed as the ions interact with each other, with their shapes depending on their associated cations quite strongly. The table below lists the polyiodide salts which have been structurally characterized, along with their counter-cation.\n"}
{"id": "53443624", "url": "https://en.wikipedia.org/wiki?curid=53443624", "title": "Primocryst", "text": "Primocryst\n\nA primocryst is a reference to the earliest-formed crystals, in contact with each other in a magma. These may also be referred to as \"cumulus crystals\".\n"}
{"id": "50433642", "url": "https://en.wikipedia.org/wiki?curid=50433642", "title": "Renewable energy in Kazakhstan", "text": "Renewable energy in Kazakhstan\n\nThere is enormous potential for renewable energy in Kazakhstan, particularly from wind and small hydropower plants. The Republic of Kazakhstan has the potential to generate 10 times as much power as it currently needs from wind energy alone. But renewable energy accounts for just 0.6 percent of all power installations. Of that, 95 percent comes from small hydropower projects.<ref name=\"http://www.eurasia.undp.org/\"></ref> The main barriers to investment in renewable energy are relatively high financing costs and an absence of uniform feed-in tariffs for electricity from renewable sources. The amount and duration of renewable energy feed-in tariffs are separately evaluated for each project, based on feasibility studies and project-specific generation costs. Power from wind, solar, biomass and water up to 35 MW, plus geothermal sources, are eligible for the tariff and transmission companies are required to purchase the energy of renewable energy producers. An amendment that introduces and clarifies technology-specific tariffs is now being prepared. It is expected to be adopted by Parliament by the end of 2014. In addition, the World Bank’s Ease of Doing Business indicator shows the country to be relatively investor-friendly, ranking it in 10th position for investor protection.\n\nKazakhstan is a party to the UN Framework Convention on Climate Change (1995) and ratified the Kyoto Protocol in 2009. Kazakhstan has committed to reduce greenhouse gas emissions.<ref name=\"http://www.climatechange.kz/index.php?option=com_content&view=article&id=4&Itemid=12\"></ref> Having more renewable energy in the energy balance of Kazakhstan is one of the most effective mechanisms to reduce harmful effects of the energy sector and to diversify the national power generation capacity.\n\nTo help Kazakhstan meet its goals for renewable energy generation, the European Bank for Reconstruction and Development (EBRD) is launching the Kazakhstan Renewable Energy Financing Facility (KazREFF). The KazREFF aims to provide development support and debt finance to renewable energy projects which meet required commercial, technical and environmental criteria. Renewable energy technologies supported will include solar, wind, small hydropower, geothermal, biomass, and biogas. The Facility comprises an amount of up to €50 million for financing projects together with up to €20 million of concessional finance from Clean Technology Fund (CTF), and the technical assistance funded by the Japanese government through the Japan-EBRD Cooperation Fund (JECF).<ref name=\"http://www.kazreff-ser.com/\"></ref>\n\nIn 2013, the Government of Kazakhstan adopted a new law, On Supporting the Use of Renewable Energy Sources. This promotes technology-specific feed-in tariffs for selected renewable energy technologies, such as biomass, solar, wind, geothermal and hydropower, up to 35 MW.<ref name=\"http://www.government.kz/en/\"></ref> The cost of the programme is estimated at KZT 1,100 billion (c. €5.3 billion). A plan to develop alternative and renewable energy in Kazakhstan for 2013-2020 was adopted by the Government in 2013. The plan aims to install about 1040 MW renewable energy capacity by 2020, including 793 MW from wind, 170 MW from hydro and 4 MW from solar sources. The cost of the plan is estimated at KZT 317.05 billion (c. €1.25 billion). Also in 2013, the Government of Kazakhstan adopted the Energy Efficiency 2020 programme, which plans to reduce energy consumption by 10 percent annually until 2015. A long-term strategy for Kazakhstan (until 2050) was also adopted in 2012. The strategy sets an ambitious goal of generating 50 percent of all power from alternative energy sources, including renewable sources. There are more incentives for investment in renewable energy.<ref name=\"http://www.ren21.net/status-of-renewables/global-status-report/\"></ref>\n\nOn November 22, 2012 Astana was chosen by the International Exhibitions Bureau (BIE) as the venue to host EXPO-2017, which focused on future energy issues. The theme of Future Energy is aimed to concentrate on both the future of energy but also on the potential energies of the future. Kazakhstan is very aware that the time has come for the world to move from fossil fuels to renewable energy sources. The selection of Astana to serve as host city is especially notable, because EXPO-2017 was the first time that a major international exhibition of this kind was held in a country from the former Soviet Union. More than 100 countries and 10 international organizations participated. The exhibition gathered and demonstrated best global developments in the field of energy conservation, as well as latest technology achievements in solar, wind and water energies. Moreover, the energy for the exhibition itself was obtained from renewable energy sources produced domestically.<ref name=\"https://zenodo.org/record/13918/files/pdf.pdf\"></ref>\n\nSmall hydropower plants are the most rapidly developing areas of use of renewable energy in the country. Thus, in the period from 2007 to 2010 the Almaty region introduced five small hydropower plants with a total installed capacity of 20 MW.<ref name=\"http://www.rfc.kegoc.kz/vozmozhnosti-vozobnovlyaemyx-istochnikov-energii-v-kazaxstane/\"></ref> One of the important areas of energy efficiency of Kazakhstan's economy is construction of hydroelectric power plants on small rivers operating without retaining dams.\nHydropower accounts for approximately 13% percent of Kazakhstan's total generating capacity delivering around 7.78TWh from 15 large (450 MW)hydropower station with a total capacity of 2.248GW.<ref name=\"http://www.resourcegovernance.org/\"></ref> Large hydropower plants comprise the Bukhtyrma (750MW), Shulbinsk (702MW) and Ust-Kamenogorsk (315MW) plants on the Irtysh River, the Kapshagai (364MW) plant on the Ili River, the Moinak (300MW) plant on the Charyn Rriver and the Shardarinskaya (104MW) plant on the Syrdarya River. Small (1–10MW) and medium-scale (10–50MW) hydropower projects have become more popular because of their low cost, reliability and apparent environmental friendliness.<ref name=\"http://www.smallhydroworld.org/\"></ref> There are seven small hydropower plants (<10MW), with a total installed capacity of 78MW and an estimated potential of 13TWh, spanning east and south Kazakhstan, Zhambyl and Almaty provinces. According to the experts, provided the smaller hydropower stations are installed about 8 billion kWh can produced per year and this is more than enough to meet the demand that is now satisfied through imports from Central Asia.\nIn December 2011 the Moynak hydropower plant (300 MW) was put into operation within the realization of the State Program for Rapid Industrial-innovative Development. A number of the projects to build smaller hydropower plants are being implemented in southern Kazakhstan.<ref name=\"http://www.buro247.kz/lifestyle/expo-2017/kak-kazakhstan-razvivaet-zelenyu-energetiku.html\"></ref>\n\nKazakhstan has areas with high insolation that could be suitable for solar power, particularly in the south of the country, receiving between 2200 and 3000h of sunlight per year, which equals 1200–1700 kW/m2 annually. Both concentrated solar thermal and solar photovoltaic (PV) have potential.There is a 2MW solar PV plant near Almaty and six solar PV plants are currently under construction in the Zhambyl province of southern Kazakhstan with a combined capacity of 300MW.<ref name=\"http://www.bourabai.kz/toe/kazenergy.htm\"></ref> In addition to solar PV, concentrated solar thermal is advantageous given it does not require water for operation so can be used in desert and semi-desert areas, the materials (steel, glass,and concrete) are domestically produced in Kazakhstan and readily available, and solar thermal plants store energy in the form of heat, which is far more efficient than the batteries used in PV systems and allows electricity to be produced on demand, even after the sun has set, enabling both base and peak loads to be met. There are no current plans to install a concentrated solar thermal plant although the government plans to create 1.04GW of renewable energy capacity by 2020. The South-Kazakhstan, Kyzylorda oblast and the Aral region are the most suitable locations to build solar power plants.\n\nThe most significant project in this field implemented in 2002 in Kazakhstan and financed by the UN was to install 50 prism solar power plants with capacity of 100 liters of water each, and 50 solar stills, using the water from the Syr Darya river to provide the residents of two villages in the Aral region for drinking water and heating.<ref name=\"http://large.stanford.edu/courses/2010/ph240/sagatov1/docs/kaz_energy_resources_ru.pdf\"></ref>\n\nIn particular, according to the Plan of Activities for Alternative and Renewable Energy in Kazakhstan, it is planned to put into operation about 28 solar energy projects until the end of 2020 with total installed capacity of 713.5 MW.<ref name=\"http://kazcham.com/renewable-energy-in-kazakhstan-more-than-1-gw-until-2020/\"></ref>\n\nThe European Bank for Reconstruction and Development (EBRD) financed two solar parks in Kazakhstan. The first one, 50MW Burnoye Solar 1, was established in April 2014. The second one, known as Burnoye Solar 2, is also 50MW and will be located in the Zhambyl region.\n\nKazakhstan's steppe geography makes it suitable for wind energy applications and the estimated potential of wind energy that can be economically developed is about 760GW. About 50% of Kazakhstan's territory has average wind speeds suitable for energy generation (4–6 m/s) with the strongest potential in the Caspian Sea, central and northern regions. The most promising individual sites are in the Almaty region in the Djungar (Dzhumgarian) Gates, 600 km northeast of Almaty close to the Xinjiang border and the Chylyk Corridor 100 km east of Almaty. Wind potentials of 525Wm2 in the Djungar Gates and 240Wm in the Chylyk corridor have been estimated with power production from wind turbines potentially achieving 4400 kW/h/MW and 3200 kW/h/MW respectively.<ref name=\"http://www.windenergy.kz/\"></ref> Currently, the Ministry of Industry and New Technologies selected 10 sites to build large wind power plants (WPP) with total capacity of 1,000 MW with a view to commercial production of electricity in the amount of 2-3 billion kWh. Currently only one wind energy plant is operating in Kazakhstan; the Kordai wind power plant with 1500 kW capacity was launched in December 2011 in Zhambyl region.<ref name=\"http://kisi.kz/en/categories/economy-and-energy/posts/future-of-renewable-energy-in-kazakhstan406\"></ref>\n\nOne of Kazakhstan’s power companies, Samruk-Energy JSC, was recently awarded a $94 million loan from the Eurasian Development Bank to build Kazakhstan’s largest wind farm. The project will produce 172 million kilowatt/hours of electrical energy per year, save more than 60 million tons of coal, and reduce emissions of greenhouse gases.<ref name=\"http://kzgreenenergy.com/wind-energy/\"></ref>\n\nThe first wind generator production plant in the post-Soviet region is set to be constructed in Kazakhstan's Aktobe. This project, with a cost of 84 million euros (US$95.3 million), is expected to create 500 jobs.\n\nKazakhstan has 76.5Mha agricultural land, 10Mha forest and 185Mha steppe grasslands providing abundant biomass wastes and residues which have the potential to generate arrange of bioenergy services. Kazakhstan produces and exports crops such as wheat (winter and spring), rye (winter), maize (for grain), barley (winter and spring), oats, millet, buckwheat, rice and pulses, with an average grain yield of 17.5–20 Mt, which equates to roughly 12–14Mt of biomass wastes.<ref name=\"http://www.fao.org/home/en/\"></ref> Biomass wastes are currently poorly exploited and only ~10% of the total volume of the residues isused, mostly as a feed additive for livestock; the proportion of rural households using biomass cook stoves for cooking and heating is currently unknown.Organic wastes are also a potential source of energy and at least 400,000 households are known to keep cattle, horses and sheep. It has been estimated that electricity generation potential in Kazakhstan from biomass is 35 billion kWh per year and heat generation potential is 44 million Gcal per year.<ref name=\"http://www.energypartner.kz/\"></ref> Various external funding agencies(UNDP, GEF, HIVOS Foundation) have supported the development of biogas initiatives including the Biogas Training Centre at the Eco-museum in Karanga (2002–2003) and the ‘Azure Flame’ Central Kazakhstan Biogas Education Centre (2004–2005) however despite this promotion there is only one large scale biogas unit currently in operation in the country which is a 360kWe biogas plant run at Vostok village in the Kostanai region.The Vostok biogas unit consists of two 2400m digesters operating with a feedstock of 40 t/day of cow, sheep and camel manure, grain residues and 1t/day of slaughterhouse waste. The plant was installed in 2011 by Karaman-K Ltd. and Zorg Biogas with an aim of delivering 3 million kWh of electricity annually.<ref name=\"http://zorg-biogas.com/?lang=en\"></ref>\nAnother potential area is the use of biogas, which is produced from the waste of farms and poultry factories. Kazakhstan has a significant number of livestock and poultry. Methane production potential of the waste in cattle is more than 85 thousand tons. Potential methane production from waste-water communal services is about 3 million tonnes.<ref name=\"http://led-ca.net/vozobnovlyaemyie-istochniki-energii/energiya-biomassyi\"></ref>\n\nIn spite of considerable renewable energy potential there are still significant barriers to address including: low electricity tariffs; transmission losses and inefficient technologies; weak regulatory and legal frameworks to stimulate the use of renewable energy in the electricity sector; persistent governmental body reforms; inadequate levels and quality of scientific support; awareness and information barriers; and a high-risk business environment.<ref name=\"http://www.invest.nauka.kz/reviews/ways_of_development_of_biofuel_kazakh_energy.php\"></ref> Obstacles to renewable energy promotion in Kazakhstan are similar to the ones that are persisting in Russia.\n\nIn 2016, Kazakhstan's capital Astana started testing and implementing energy-saving systems in construction. Thus, the Kazakhstan Centre for Modernisation and Development of Housing and Communal Services moved to a new building equipped with energy-saving wind and solar energy systems.\n\nKazakhstan encourages SME's to develop and implement green energy projects. To that end, Kazakhstan's DAMU Entrepreneurship Development Fund (DAMU) and European Investment Bank (EIB) has signed two contracts to finance SMEs working to mitigate climate change and protect the environment. The EIB agreed to provide €200 million (£169.04m) of funding to support small sustainable projects in Kazakhstan.\n\nThe Energy Ministry of Kazakhstan announced 2017 to be the \"Green Energy\" year with 37 new projects aimed at attracting investment in the renewable energy projects throughout the country.\n\nOne of Kazakhstan's primary goals in its transition to green economy set by President Nazarbayev is to achieve 50% of total electricity to be generated by renewable sources by 2050. As of mid-2017, there were 50 enterprises operating in Kazakhstan that produced energy from renewable sources with a total capacity of 300 megawatts.\n"}
{"id": "24677311", "url": "https://en.wikipedia.org/wiki?curid=24677311", "title": "René Ngongo", "text": "René Ngongo\n\nRené Ngongo (born October 1961 in Goma, Republic of the Congo) is a Congolese biologist, environmentalist and political activist. Ngongo graduated from the University of Kisangani with a bachelor's degree in Biology in 1987. In 1994, he created the NGO OCEAN (Organisation Concertée des Ecologistes et Amis de la Nature) in order to protect the DRC's natural resources.\nIn 2009, René Ngongo received the Right Livelihood Award \"for his courage in confronting the forces that are destroying the Congo’s rainforests and building political support for their conservation and sustainable use”.\n\n"}
{"id": "26428", "url": "https://en.wikipedia.org/wiki?curid=26428", "title": "Rosetta Stone", "text": "Rosetta Stone\n\nThe Rosetta Stone is a granodiorite stele, found in 1799, inscribed with three versions of a decree issued at Memphis, Egypt in 196 BC during the Ptolemaic dynasty on behalf of King Ptolemy V. The top and middle texts are in Ancient Egyptian using hieroglyphic script and Demotic script, respectively, while the bottom is in Ancient Greek. As the decree has only minor differences between the three versions, the Rosetta Stone proved to be the key to deciphering Egyptian hieroglyphs, thereby opening a window into ancient Egyptian history.\n\nThe stone, carved during the Hellenistic period, is believed to have originally been displayed within a temple, possibly at nearby Sais. It was probably moved during the early Christian or medieval period, and was eventually used as building material in the construction of Fort Julien near the town of Rashid (Rosetta) in the Nile Delta. It was rediscovered there in July 1799 by a French soldier named Pierre-François Bouchard during the Napoleonic campaign in Egypt. It was the first Ancient Egyptian bilingual text recovered in modern times, and it aroused widespread public interest with its potential to decipher this previously untranslated hieroglyphic language. Lithographic copies and plaster casts began circulating among European museums and scholars. British troops having meanwhile defeated the French, under the Capitulation of Alexandria in 1801 the original stone came into British possession and was transported to London. It has been on public display at the British Museum almost continuously since 1802 and is the most-visited object there.\n\nStudy of the decree was already under way when the first full translation of the Greek text appeared in 1803. It was 20 years, however, before the transliteration of the Egyptian scripts was announced by Jean-François Champollion in Paris in 1822; it took longer still before scholars were able to read Ancient Egyptian inscriptions and literature confidently. Major advances in the decoding were recognition that the stone offered three versions of the same text (1799); that the demotic text used phonetic characters to spell foreign names (1802); that the hieroglyphic text did so as well, and had pervasive similarities to the demotic (Thomas Young, 1814); and that, in addition to being used for foreign names, phonetic characters were also used to spell native Egyptian words (Champollion, 1822–1824).\n\nEver since its rediscovery, the stone has been the focus of nationalist rivalries, including its transfer from French to British possession during the Napoleonic Wars, a long-running dispute over the relative value of Young and Champollion's contributions to the decipherment and, since 2003, demands for the stone's return to Egypt.\n\nTwo other fragmentary copies of the same decree were discovered later, and several similar Egyptian bilingual or trilingual inscriptions are now known, including two slightly earlier Ptolemaic decrees (the Decree of Canopus in 238 BC, and the Memphis decree of Ptolemy IV, c. 218 BC). The Rosetta Stone is, therefore, no longer unique, but it was the essential key to modern understanding of Ancient Egyptian literature and civilisation. The term \"Rosetta Stone\" is now used in other contexts as the name for the essential clue to a new field of knowledge.\n\nThe Rosetta Stone is listed as \"a stone of black granodiorite, bearing three inscriptions ... found at Rosetta\" in a contemporary catalogue of the artefacts discovered by the French expedition and surrendered to British troops in 1801. At some period after its arrival in London, the inscriptions on the stone were coloured in white chalk to make them more legible, and the remaining surface was covered with a layer of carnauba wax designed to protect the Rosetta Stone from visitors' fingers. This gave a dark colour to the stone that led to its mistaken identification as black basalt. These additions were removed when the stone was cleaned in 1999, revealing the original dark grey tint of the rock, the sparkle of its crystalline structure, and a pink vein running across the top left corner. Comparisons with the Klemm collection of Egyptian rock samples showed a close resemblance to rock from a small granodiorite quarry at Gebel Tingar on the west bank of the Nile, west of Elephantine in the region of Aswan; the pink vein is typical of granodiorite from this region.\n\nThe Rosetta Stone is high at its highest point, wide, and thick. It weighs approximately . It bears three inscriptions: the top register in Ancient Egyptian hieroglyphs, the second in the Egyptian Demotic script, and the third in Ancient Greek. The front surface is polished and the inscriptions lightly incised on it; the sides of the stone are smoothed, but the back is only roughly worked, presumably because this would have not been visible when it was erected.\n\nThe Rosetta Stone is a fragment of a larger stele. No additional fragments were found in later searches of the Rosetta site. Owing to its damaged state, none of the three texts is absolutely complete. The top register, composed of Egyptian hieroglyphs, suffered the most damage. Only the last 14 lines of the hieroglyphic text can be seen; all of them are broken on the right side, and 12 of them on the left. The following register of demotic text has survived best; it has 32 lines, of which the first 14 are slightly damaged on the right side. The final register of Greek text contains 54 lines, of which the first 27 survive in full; the rest are increasingly fragmentary due to a diagonal break at the bottom right of the stone.\n\nThe stele was erected after the coronation of King Ptolemy V and was inscribed with a decree that established the divine cult of the new ruler. The decree was issued by a congress of priests who gathered at Memphis. The date is given as \"4 Xandicus\" in the Macedonian calendar and \"18 Meshir\" in the Egyptian calendar, which corresponds to March 27, 196 BC. The year is stated as the ninth year of Ptolemy V's reign (equated with 197/196 BC), which is confirmed by four priests named who officiated in that same year: Aëtus son of Aëtus was priest of the divine cults of Alexander the Great and the five Ptolemies down to Ptolemy V himself; his three colleagues, named in turn in the inscription, led the worship of Berenice Euergetis (wife of Ptolemy III), Arsinoe Philadelphos (wife and sister of Ptolemy II), and Arsinoe Philopator, mother of Ptolemy V. However, a second date is also given in the Greek and hieroglyphic texts, corresponding to , the official anniversary of Ptolemy's coronation. The inscription in demotic conflicts with this, listing consecutive days in March for the decree and the anniversary. It is uncertain why such discrepancies exist, but it is clear that the decree was issued in 196 BC and that it was designed to re-establish the rule of the Ptolemaic kings over Egypt.\n\nThe decree was issued during a turbulent period in Egyptian history. Ptolemy V Epiphanes reigned from 204 to 181 BC, the son of Ptolemy IV Philopator and his wife and sister Arsinoe. He had become ruler at the age of five after the sudden death of both of his parents, who were murdered in a conspiracy that involved Ptolemy IV's mistress Agathoclea, according to contemporary sources. The conspirators effectively ruled Egypt as Ptolemy V's guardians until a revolt broke out two years later under general Tlepolemus, when Agathoclea and her family were lynched by a mob in Alexandria. Tlepolemus, in turn, was replaced as guardian in 201 BC by Aristomenes of Alyzia, who was chief minister at the time of the Memphis decree.\n\nPolitical forces beyond the borders of Egypt exacerbated the internal problems of the Ptolemaic kingdom. Antiochus III the Great and Philip V of Macedon had made a pact to divide Egypt's overseas possessions. Philip had seized several islands and cities in Caria and Thrace, while the Battle of Panium (198 BC) had resulted in the transfer of Coele-Syria, including Judaea, from the Ptolemies to the Seleucids. Meanwhile, in the south of Egypt, there was a long-standing revolt that had begun during the reign of Ptolemy IV, led by Horwennefer and by his successor Ankhwennefer. Both the war and the internal revolt were still ongoing when the young Ptolemy V was officially crowned at Memphis at the age of 12 (seven years after the start of his reign), and the Memphis decree issued.\n\nThe stele is a late example of a class of donation stelae, which depicts the reigning monarch granting a tax exemption to the resident priesthood. Pharaohs had erected these stelae over the previous 2,000 years, the earliest examples dating from the Egyptian Old Kingdom. In earlier periods, all such decrees were issued by the king himself, but the Memphis decree was issued by the priests, as the maintainers of traditional Egyptian culture. The decree records that Ptolemy V gave a gift of silver and grain to the temples. It also records that there was particularly high flooding of the Nile in the eighth year of his reign, and he had the excess waters dammed for the benefit of the farmers. In return for these concessions, the priesthood pledged that the king's birthday and coronation days would be celebrated annually, and that all the priests of Egypt would serve him alongside the other gods. The decree concludes with the instruction that a copy was to be placed in every temple, inscribed in the \"language of the gods\" (hieroglyphs), the \"language of documents\" (demotic), and the \"language of the Greeks\" as used by the Ptolemaic government.\n\nSecuring the favour of the priesthood was essential for the Ptolemaic kings to retain effective rule over the populace. The High Priests of Memphis—where the king was crowned—were particularly important, as they were the highest religious authorities of the time and had influence throughout the kingdom. Given that the decree was issued at Memphis, the ancient capital of Egypt, rather than Alexandria, the centre of government of the ruling Ptolemies, it is evident that the young king was anxious to gain their active support. Thus, although the government of Egypt had been Greek-speaking ever since the conquests of Alexander the Great, the Memphis decree, like the two preceding decrees in the series, included texts in Egyptian to show its connection to the general populace by way of the literate Egyptian priesthood.\n\nThere exists no one definitive English translation of the decree because of the minor differences between the three original texts, and because modern understanding of the ancient languages continues to develop. An up-to-date translation by R. S. Simpson appears on the British Museum website, based on the demotic text. It can be compared with Edwyn R. Bevan's full translation in \"The House of Ptolemy\" (1927), based on the Greek text with footnote comments on variations between this and the two Egyptian texts.\n\nThe stele almost certainly did not originate in the town of Rashid (Rosetta) where it was found, but more likely came from a temple site farther inland, possibly the royal town of Sais. The temple from which it originally came was probably closed around AD 392 when Eastern Roman emperor Theodosius I ordered the closing of all non-Christian temples of worship. The original stele broke at some point, its largest piece becoming what we now know as the Rosetta Stone. Ancient Egyptian temples were later used as quarries for new construction, and the Rosetta Stone probably was re-used in this manner. Later it was incorporated in the foundations of a fortress constructed by the Mameluke Sultan Qaitbay (c. 1416/18–1496) to defend the Bolbitine branch of the Nile at Rashid. There it lay for at least another three centuries until its rediscovery.\n\nTwo other inscriptions containing the same Memphis decree have been found since the discovery of the Rosetta Stone: the Nubayrah Stele, and an inscription found at the Temple of Philae (on the Philae obelisk). Unlike the Rosetta Stone, the hieroglyphic texts of these other copies of the decree were relatively intact. The Rosetta Stone had been deciphered long before they were found, but later Egyptologists, including Wallis Budge, used these other copies to refine the reconstruction of the hieroglyphs that must have been used in the lost portions of the hieroglyphic text on the Rosetta Stone.\n\nNapoleon's 1798 campaign in Egypt came at (and helped cause) the beginning of a burst of Egyptomania in Europe, and especially France. A corps of 167 technical experts (\"savants\"), known as the \"Commission des Sciences et des Arts\", accompanied the French expeditionary army to Egypt. On 1799, French soldiers under the command of Colonel d'Hautpoul were strengthening the defences of Fort Julien, a couple of miles north-east of the Egyptian port city of Rosetta (modern-day Rashid). Lieutenant Pierre-François Bouchard spotted a slab with inscriptions on one side that the soldiers had uncovered. He and d'Hautpoul saw at once that it might be important and informed General Jacques-François Menou, who happened to be at Rosetta. The find was announced to Napoleon's newly founded scientific association in Cairo, the Institut d'Égypte, in a report by Commission member Michel Ange Lancret noting that it contained three inscriptions, the first in hieroglyphs and the third in Greek, and rightly suggesting that the three inscriptions were versions of the same text. Lancret's report, dated 1799, was read to a meeting of the Institute soon after . Bouchard, meanwhile, transported the stone to Cairo for examination by scholars. Napoleon himself inspected what had already begun to be called \"la Pierre de Rosette\", the Rosetta Stone, shortly before his return to France in August 1799.\n\nThe discovery was reported in September in \"Courrier de l'Égypte\", the official newspaper of the French expedition. The anonymous reporter expressed a hope that the stone might one day be the key to deciphering hieroglyphs. In 1800, three of the Commission's technical experts devised ways to make copies of the texts on the stone. One of these experts was Jean-Joseph Marcel, a printer and gifted linguist, who is credited as the first to recognise that the middle text was written in the Egyptian Demotic script, rarely used for stone inscriptions and seldom seen by scholars at that time, rather than Syriac as had originally been thought. It was artist and inventor Nicolas-Jacques Conté who found a way to use the stone itself as a printing block to reproduce the inscription. A slightly different method was adopted by Antoine Galland. The prints that resulted were taken to Paris by General Charles Dugua. Scholars in Europe were now able to see the inscriptions and attempt to read them.\n\nAfter Napoleon's departure, French troops held off British and Ottoman attacks for another 18 months. In March 1801, the British landed at Aboukir Bay. Menou was now in command of the French expedition. His troops, including the Commission, marched north towards the Mediterranean coast to meet the enemy, transporting the stone along with many other antiquities. He was defeated in battle, and the remnant of his army retreated to Alexandria where they were surrounded and besieged, the stone now inside the city. Menou surrendered on August 30.\n\nAfter the surrender, a dispute arose over the fate of the French archaeological and scientific discoveries in Egypt, including the artefacts, biological specimens, notes, plans, and drawings collected by the members of the commission. Menou refused to hand them over, claiming that they belonged to the Institute. British General John Hely-Hutchinson refused to relieve the city until Menou gave in. Scholars Edward Daniel Clarke and William Richard Hamilton, newly arrived from England, agreed to examine the collections in Alexandria and claimed to have found many artefacts that the French had not revealed. In a letter home, Clarke said that \"we found much more in their possession than was represented or imagined\".\n\nHutchinson claimed that all materials were property of the British Crown, but French scholar Étienne Geoffroy Saint-Hilaire told Clarke and Hamilton that the French would rather burn all their discoveries than turn them over, referring ominously to the destruction of the Library of Alexandria. Clarke and Hamilton pleaded the French scholars' case to Hutchinson, who finally agreed that items such as natural history specimens would be the scholars' private property. Menou quickly claimed the stone, too, as his private property. Hutchinson was equally aware of the stone's unique value and rejected Menou's claim. Eventually an agreement was reached, and the transfer of the objects was incorporated into the Capitulation of Alexandria signed by representatives of the British, French, and Ottoman forces.\n\nIt is not clear exactly how the stone was transferred into British hands, as contemporary accounts differ. Colonel Tomkyns Hilgrove Turner was to escort it to England, but he claimed later that he had personally seized it from Menou and carried it away on a gun-carriage. In a much more detailed account, Edward Daniel Clarke stated that a French \"officer and member of the Institute\" had taken him, his student John Cripps, and Hamilton secretly into the back streets behind Menou's residence and revealed the stone hidden under protective carpets among Menou's baggage. According to Clarke, their informant feared that the stone might be stolen if French soldiers saw it. Hutchinson was informed at once and the stone was taken away—possibly by Turner and his gun-carriage.\n\nTurner brought the stone to England aboard the captured French frigate HMS \"Egyptienne\", landing in Portsmouth in February 1802. His orders were to present it and the other antiquities to King George III. The King, represented by War Secretary Lord Hobart, directed that it should be placed in the British Museum. According to Turner's narrative, he and Hobart agreed that the stone should be presented to scholars at the Society of Antiquaries of London, of which Turner was a member, before its final deposit in the museum. It was first seen and discussed there at a meeting on 1802.\n\nIn 1802 the Society created four plaster casts of the inscriptions, which were given to the universities of Oxford, Cambridge, and Edinburgh and to Trinity College Dublin. Soon afterwards, prints of the inscriptions were made and circulated to European scholars. Before the end of 1802, the stone was transferred to the British Museum, where it is located today. New inscriptions painted in white on the left and right edges of the slab stated that it was \"Captured in Egypt by the British Army in 1801\" and \"Presented by King George III\".\n\nThe stone has been exhibited almost continuously in the British Museum since June 1802. During the middle of the 19th century, it was given the inventory number \"EA 24\", \"EA\" standing for \"Egyptian Antiquities\". It was part of a collection of ancient Egyptian monuments captured from the French expedition, including a sarcophagus of Nectanebo II (EA 10), the statue of a high priest of Amun (EA 81), and a large granite fist (EA 9). The objects were soon discovered to be too heavy for the floors of Montagu House (the original building of The British Museum), and they were transferred to a new extension that was built onto the mansion. The Rosetta Stone was transferred to the sculpture gallery in 1834 shortly after Montagu House was demolished and replaced by the building that now houses the British Museum. According to the museum's records, the Rosetta Stone is its most-visited single object, and a simple image of it has been the museum's best selling postcard for several decades.\nThe Rosetta Stone was originally displayed at a slight angle from the horizontal, and rested within a metal cradle that was made for it, which involved shaving off very small portions of its sides to ensure that the cradle fitted securely. It originally had no protective covering, and it was found necessary by 1847 to place it in a protective frame, despite the presence of attendants to ensure that it was not touched by visitors. Since 2004, the conserved stone has been on display in a specially built case in the centre of the Egyptian Sculpture Gallery. A replica of the Rosetta Stone is now available in the King's Library of the British Museum, without a case and free to touch, as it would have appeared to early 19th-century visitors.\n\nThe museum was concerned about heavy bombing in London towards the end of the First World War in 1917, and the Rosetta Stone was moved to safety, along with other portable objects of value. The stone spent the next two years below ground level in a station of the Postal Tube Railway at Mount Pleasant near Holborn. Other than during wartime, the Rosetta Stone has left the British Museum only once: for one month in October 1972, to be displayed alongside Champollion's \"Lettre\" at the Louvre in Paris on the 150th anniversary of the letter's publication. Even when the Rosetta Stone was undergoing conservation measures in 1999, the work was done in the gallery so that it could remain visible to the public.\n\nPrior to the discovery of the Rosetta Stone and its eventual decipherment, the ancient Egyptian language and script had not been understood since shortly before the fall of the Roman Empire. The usage of the hieroglyphic script had become increasingly specialised even in the later Pharaonic period; by the 4th century AD, few Egyptians were capable of reading them. Monumental use of hieroglyphs ceased after the closing of all non-Christian temples in 391 by Roman Emperor Theodosius I; the last known inscription is dated to , found at Philae and known as the Graffito of Esmet-Akhom.\n\nHieroglyphs retained their pictorial appearance, and classical authors emphasised this aspect, in sharp contrast to the Greek and Roman alphabets. In the 5th century, the priest Horapollo wrote \"Hieroglyphica\", an explanation of almost 200 glyphs. His work was believed to be authoritative, yet it was misleading in many ways, and this and other works were a lasting impediment to the understanding of Egyptian writing. Later attempts at decipherment were made by Arab historians in medieval Egypt during the 9th and 10th centuries. Dhul-Nun al-Misri and Ibn Wahshiyya were the first historians to study hieroglyphs, by comparing them to the contemporary Coptic language used by Coptic priests in their time. The study of hieroglyphs continued with fruitless attempts at decipherment by European scholars, notably Johannes Goropius Becanus in the 16th century, Athanasius Kircher in the 17th, and Georg Zoëga in the 18th. The discovery of the Rosetta Stone in 1799 provided critical missing information, gradually revealed by a succession of scholars, that eventually allowed Jean-François Champollion to solve the puzzle that Kircher had called the riddle of the Sphinx.\n\nThe Greek text on the Rosetta Stone provided the starting point. Ancient Greek was widely known to scholars, but they were not familiar with details of its use in the Hellenistic period as a government language in Ptolemaic Egypt; large-scale discoveries of Greek papyri were a long way in the future. Thus, the earliest translations of the Greek text of the stone show the translators still struggling with the historical context and with administrative and religious jargon. Stephen Weston verbally presented an English translation of the Greek text at a Society of Antiquaries meeting in April 1802.\n\nMeanwhile, two of the lithographic copies made in Egypt had reached the Institut de France in Paris in 1801. There, librarian and antiquarian Gabriel de La Porte du Theil set to work on a translation of the Greek, but he was dispatched elsewhere on Napoleon's orders almost immediately, and he left his unfinished work in the hands of colleague Hubert-Pascal Ameilhon. Ameilhon produced the first published translations of the Greek text in 1803, in both Latin and French to ensure that they would circulate widely. At Cambridge, Richard Porson worked on the missing lower right corner of the Greek text. He produced a skilful suggested reconstruction, which was soon being circulated by the Society of Antiquaries alongside its prints of the inscription. At almost the same moment, Christian Gottlob Heyne in Göttingen was making a new Latin translation of the Greek text that was more reliable than Ameilhon's, which was first published in 1803. It was reprinted by the Society of Antiquaries in a special issue of its journal \"Archaeologia\" in 1811, alongside Weston's previously unpublished English translation, Colonel Turner's narrative, and other documents.\n\nAt the time of the stone's discovery, Swedish diplomat and scholar Johan David Åkerblad was working on a little-known script of which some examples had recently been found in Egypt, which came to be known as Demotic. He called it \"cursive Coptic\" because he was convinced that it was used to record some form of the Coptic language (the direct descendant of Ancient Egyptian), although it had few similarities with the later Coptic script. French Orientalist Antoine-Isaac Silvestre de Sacy had been discussing this work with Åkerblad when he received one of the early lithographic prints of the Rosetta Stone in 1801 from Jean-Antoine Chaptal, French minister of the interior. He realised that the middle text was in this same script. He and Åkerblad set to work, both focusing on the middle text and assuming that the script was alphabetical. They attempted to identify the points where Greek names ought to occur within this unknown text, by comparing it with the Greek. In 1802, Silvestre de Sacy reported to Chaptal that he had successfully identified five names (\"\"Alexandros\", \"Alexandreia\", \"Ptolemaios\", \"Arsinoe\", and Ptolemy's title \"Epiphanes\"\"), while Åkerblad published an alphabet of 29 letters (more than half of which were correct) that he had identified from the Greek names in the demotic text. They could not, however, identify the remaining characters in the Demotic text, which, as is now known, included ideographic and other symbols alongside the phonetic ones.\n\nSilvestre de Sacy eventually gave up work on the stone, but he was to make another contribution. In 1811, prompted by discussions with a Chinese student about Chinese script, Silvestre de Sacy considered a suggestion made by Georg Zoëga in 1797 that the foreign names in Egyptian hieroglyphic inscriptions might be written phonetically; he also recalled that as early as 1761, Jean-Jacques Barthélemy had suggested that the characters enclosed in cartouches in hieroglyphic inscriptions were proper names. Thus, when Thomas Young, foreign secretary of the Royal Society of London, wrote to him about the stone in 1814, Silvestre de Sacy suggested in reply that in attempting to read the hieroglyphic text, Young might look for cartouches that ought to contain Greek names and try to identify phonetic characters in them.\n\nYoung did so, with two results that together paved the way for the final decipherment. In the hieroglyphic text, he discovered the phonetic characters \"\"p t o l m e s\" (in today's transliteration \"p t w l m y s\") that were used to write the Greek name \"Ptolemaios\"\". He also noticed that these characters resembled the equivalent ones in the Demotic script, and went on to note as many as 80 similarities between the hieroglyphic and Demotic texts on the stone, an important discovery because the two scripts were previously thought to be entirely different from one another. This led him to deduce correctly that the Demotic script was only partly phonetic, also consisting of ideographic characters imitated from hieroglyphs. Young's new insights were prominent in the long article \"Egypt\" that he contributed to the \"Encyclopædia Britannica\" in 1819. He could make no further progress, however.\n\nIn 1814 Young first exchanged correspondence about the stone with Jean-François Champollion, a teacher at Grenoble who had produced a scholarly work on ancient Egypt. Champollion saw copies of the brief hieroglyphic and Greek inscriptions of the Philae obelisk in 1822, on which William John Bankes had tentatively noted the names \"Ptolemaios\" and \"Kleopatra\" in both languages. From this, Champollion identified the phonetic characters \"k l e o p a t r a\" (in today's transliteration \"q l i҆ w p ꜣ d r ꜣ.t\"). On the basis of this and the foreign names on the Rosetta Stone, he quickly constructed an alphabet of phonetic hieroglyphic characters, which appears in his famous 1822 \"Lettre à M. Dacier\" sent to Bon-Joseph Dacier, secretary of the Paris Académie des Inscriptions et Belles-Lettres and immediately published by the Académie. In the postscript Champollion notes that similar phonetic characters seemed to occur in both Greek and Egyptian names, a hypothesis confirmed in 1823, when he identified the names of pharaohs Ramesses and Thutmose written in cartouches at Abu Simbel. These far older hieroglyphic inscriptions had been copied by Bankes and sent to Champollion by Jean-Nicolas Huyot. From this point, the stories of the Rosetta Stone and the decipherment of Egyptian hieroglyphs diverge, as Champollion drew on many other texts to develop an Ancient Egyptian grammar and a hieroglyphic dictionary which were published after his death in 1832.\n\nWork on the stone now focused on fuller understanding of the texts and their contexts by comparing the three versions with one another. In 1824 Classical scholar Antoine-Jean Letronne promised to prepare a new literal translation of the Greek text for Champollion's use. Champollion in return promised an analysis of all the points at which the three texts seemed to differ. Following Champollion's sudden death in 1832, his draft of this analysis could not be found, and Letronne's work stalled. François Salvolini, Champollion's former student and assistant, died in 1838, and this analysis and other missing drafts were found among his papers. This discovery incidentally demonstrated that Salvolini's own publication on the stone, published in 1837, was plagiarism. Letronne was at last able to complete his commentary on the Greek text and his new French translation of it, which appeared in 1841. During the early 1850s, German Egyptologists Heinrich Brugsch and Max Uhlemann produced revised Latin translations based on the demotic and hieroglyphic texts. The first English translation followed in 1858, the work of three members of the Philomathean Society at the University of Pennsylvania.\n\nWhether one of the three texts was the standard version, from which the other two were originally translated, is a question that has remained controversial. Letronne attempted to show in 1841 that the Greek version, the product of the Egyptian government under the Macedonian Ptolemies, was the original. Among recent authors, John Ray has stated that \"the hieroglyphs were the most important of the scripts on the stone: they were there for the gods to read, and the more learned of their priesthood\". Philippe Derchain and Heinz Josef Thissen have argued that all three versions were composed simultaneously, while Stephen Quirke sees in the decree \"an intricate coalescence of three vital textual traditions\". Richard Parkinson points out that the hieroglyphic version strays from archaic formalism and occasionally lapses into language closer to that of the demotic register that the priests more commonly used in everyday life. The fact that the three versions cannot be matched word for word helps to explain why its decipherment has been more difficult than originally expected, especially for those original scholars who were expecting an exact bilingual key to Egyptian hieroglyphs.\n\nEven before the Salvolini affair, disputes over precedence and plagiarism punctuated the decipherment story. Thomas Young's work is acknowledged in Champollion's 1822 \"Lettre à M. Dacier\", but incompletely, according to British critics: for example, James Browne, a sub-editor on the \"Encyclopædia Britannica\" (which had published Young's 1819 article), anonymously contributed a series of review articles to the \"Edinburgh Review\" in 1823, praising Young's work highly and alleging that the \"unscrupulous\" Champollion plagiarised it. These articles were translated into French by Julius Klaproth and published in book form in 1827. Young's own 1823 publication reasserted the contribution that he had made. The early deaths of Young (1829) and Champollion (1832) did not put an end to these disputes. The authoritative work on the stone by British Museum curator E. A. Wallis Budge (1904) gives special emphasis to Young's contribution compared with Champollion's. In the early 1970s, French visitors complained that the portrait of Champollion was smaller than one of Young on an adjacent information panel; English visitors complained that the opposite was true. The portraits were in fact the same size.\n\nEgypt first requested the return of the Rosetta Stone in July 2003, on the British Museum's 250th anniversary. Zahi Hawass, the chief of Egypt's Supreme Council of Antiquities, asked that the stele be repatriated to Egypt, commenting that it was the \"icon of our Egyptian identity\". He repeated the proposal two years later in Paris, listing the stone as one of several key items belonging to Egypt's cultural heritage, a list which also included: the iconic bust of Nefertiti in the Egyptian Museum of Berlin; a statue of the Great Pyramid architect Hemiunu in the Roemer-und-Pelizaeus-Museum in Hildesheim, Germany; the Dendara Temple Zodiac in the Louvre in Paris; and the bust of Ankhhaf from the Museum of Fine Arts, Boston.\n\nDuring 2005, the British Museum presented Egypt with a full-sized replica of the stele. This was initially displayed in the renovated Rashid National Museum, close to the site where the stone was found. In November 2005, Hawass suggested a three-month loan of the Rosetta Stone, while reiterating the eventual goal of a permanent return. In December 2009, he proposed to drop his claim for the permanent return of the Rosetta Stone if the British Museum lent the stone to Egypt for three months for the opening of the Grand Egyptian Museum at Giza in 2013. These requests were refused.\n\nAs John Ray has observed, \"the day may come when the stone has spent longer in the British Museum than it ever did in Rosetta.\" There is strong opposition among national museums to the repatriation of objects of international cultural significance such as the Rosetta Stone. In response to repeated Greek requests for return of the Elgin Marbles from the Parthenon and similar requests to other museums around the world, in 2002 over 30 of the world's leading museums — including the British Museum, the Louvre, the Pergamon Museum in Berlin and the Metropolitan Museum in New York City — issued a joint statement declaring that \"objects acquired in earlier times must be viewed in the light of different sensitivities and values reflective of that earlier era\" and that \"museums serve not just the citizens of one nation but the people of every nation\".\n\nThe Digital Rosetta Stone Project is a collaboration between the University of Leipzig's Digital Humanities Chair and the Institute of Egyptology; and the British Museum and the Digital Epigraphy and Archaeology Project, to make available an annotated transcription of each of the three versions of the text, as well as providing them in XML format. High-resolution images and a high-resolution 3D model of the stone will also be produced.\n\nThe term \"Rosetta stone\" has been used idiomatically to represent a crucial key in the process of decryption of encoded information, especially when a small but representative sample is recognised as the clue to understanding a larger whole. According to the \"Oxford English Dictionary\", the first figurative use of the term appeared in the 1902 edition of the \"Encyclopædia Britannica\" relating to an entry on the chemical analysis of glucose. Another use of the phrase is found in H. G. Wells' 1933 novel \"The Shape of Things to Come\", where the protagonist finds a manuscript written in shorthand that provides a key to understanding additional scattered material that is sketched out in longhand, both handwritten and typed.\n\nSince then, the term has been widely used in other contexts. For example, Theodor W. Hänsch in a 1979 \"Scientific American\" article on spectroscopy wrote that \"the spectrum of the hydrogen atoms has proved to be the Rosetta stone of modern physics: once this pattern of lines had been deciphered much else could also be understood\". Fully understanding the key set of genes to the human leucocyte antigen has been described as \"the Rosetta Stone of immunology\". The flowering plant \"Arabidopsis thaliana\" has been called the \"Rosetta Stone of flowering time\". A Gamma ray burst (GRB) found in conjunction with a supernova has been called a Rosetta Stone for understanding the origin of GRBs. The technique of Doppler echocardiography has been called a Rosetta Stone for clinicians trying to understand the complex process by which the left ventricle of the human heart can be filled during various forms of diastolic dysfunction.\n\nThe name has also become used in various forms of translation software. Rosetta Stone is a brand of language-learning software published by American company Rosetta Stone Ltd. \"Rosetta\" is the name of a \"lightweight dynamic translator\" that enables applications compiled for PowerPC processors to run on Apple systems using an x86 processor. \"Rosetta\" is an online language translation tool to help localisation of software, developed and maintained by Canonical Ltd. as part of the Launchpad project. Similarly, Rosetta@home is a distributed computing project for predicting protein structures from amino acid sequences (or \"translating\" sequence into structure). The Rosetta Project brings language specialists and native speakers together to develop a meaningful survey and near-permanent archive of 1,500 languages, intended to last from AD 2000 to 12,000. The European Space Agency's \"Rosetta\" spacecraft was launched to study a comet named 67P/Churyumov–Gerasimenko in the hope that determining its composition would reveal the origin of the Solar System.\n\n\n"}
{"id": "852171", "url": "https://en.wikipedia.org/wiki?curid=852171", "title": "Sigmar Gabriel", "text": "Sigmar Gabriel\n\nSigmar Hartmut Gabriel (born 12 September 1959) is a German politician who was Minister for Foreign Affairs from 2017 to 2018 and Vice-Chancellor of Germany from 2013 to 2018. He was Leader of the Social Democratic Party of Germany (SPD) from 2009 to 2017, which made him the party's longest-serving leader since Willy Brandt. He was the Federal Minister of the Environment from 2005 to 2009 and the Federal Minister for Economic Affairs and Energy from 2013 to 2017. From 1999 to 2003 Gabriel was Prime Minister of Lower Saxony.\n\nGabriel is a member of the Seeheimer Kreis, an official internal grouping of the party with liberal economic positions.\n\nGabriel was born in Goslar, West Germany, the son of Walter Gabriel (1921–2012), a municipal civil servant, and Antonie Gabriel (1922–2014), a nurse. Gabriel's parents divorced in 1962, and for the next six years he lived with his father and grandmother Lina Gabriel, while his sister lived with their mother. After a lengthy custody battle his mother was awarded custody for both children in 1969.\n\nGabriel's father was a Lutheran originally from Hirschberg im Riesengebirge in Silesia, while his mother was a Catholic originally from Heilsberg in the Ermland (Warmia) region of East Prussia who had most recently lived in Königsberg; both parents came as refugees to West Germany during the flight and expulsion of Germans during the Second World War. Refugees from the eastern provinces often suffered prejudices in West Germany, and his mother's family were often disregarded as \"Poles\" in West Germany. Sigmar Gabriel has described his family history as a \"wild story of flight and expulsion\" and noted that his parents dealt with the trauma of expulsion in different ways. According to Gabriel, his father was physically and emotionally abusive to him and was an enthusiastic supporter of the national socialist ideology \"until his dying breath;\" Walter Gabriel however never saw active service during the war, due to suffering from polio. His mother was involved in relief and solidarity work for Poland during the period of martial law in Poland.\n\nSigmar Gabriel attended school in Goslar, and served as a soldier in the German Air Force from 1979 to 1981. He studied politics, sociology and German at the University of Göttingen from 1982 and passed the first state examination as a grammar school teacher in 1987 and the second state examination in 1989.\n\nGabriel joined the SPD in 1977 and soon held a number of positions in local politics. In 1990, he was first elected to the State Parliament of Lower Saxony, where he led the SPD parliamentary group from 1998 until 1999.\n\nOn 15 December 1999, after the resignation of Gerhard Glogowski, who had succeeded Gerhard Schröder in office, Gabriel became Minister-President of Lower Saxony. He had previously won an internal party vote against Wolfgang Jüttner and Thomas Oppermann. He served until 4 March 2003. During these years, he was widely presented as a protégé of Schröder, and even as a possible successor as chancellor.\n\nAfter being voted out of office in 2003, Gabriel became the SPD's \"Representative for Pop Culture and Pop Discourse\" from 2003 to 2005, for which he was bestowed the nickname \"Siggi Pop\".\n\nFrom 2005 to 2009 Gabriel was the Federal Minister for the Environment, Nature Conservation and Nuclear Safety in the first cabinet of Angela Merkel (CDU).\n\nDuring his time in office, Gabriel promoted the International Renewable Energy Agency. He also led the German delegation to the 2006 United Nations Climate Change Conference in Nairobi. In 2007, when Germany held the presidency of the Council of the European Union, he led the negotiations between European Union environment ministers on an ambitious effort to cut greenhouse gas emissions to 20 percent below 1990 levels. That same year, he accompanied Merkel on a two-day visit to Greenland to see the Ilulissat Icefjord, a UNESCO world heritage site, and the Sermeq Kujalleq glacier in order to get a firsthand look at the effects of global warming.\n\nFollowing the SPD's defeat in the federal election of 2009, Franz Müntefering resigned from the position of party chairman of the Social Democratic Party. Gabriel was nominated as his successor and was elected on 13 November 2009. He was re-elected as party chairman for a further two years at the SPD party conference in Berlin on 5 December 2011, receiving 91.6 percent of the vote.\n\nDuring his early years as chairman, Gabriel pushed through internal party reforms. He abolished the party steering committee in favor of an expanded executive committee and led the regular party conventions, the most important meetings for the party. He also played a critical role in founding the Progressive Alliance in 2013 by canceling the SPD payment of its £100,000 yearly membership fee to the Socialist International in January 2012. Gabriel had been critical of the Socialist International's admittance and continuing inclusion of undemocratic \"despotic\" political movements into the organization.\n\nFor the 2013 federal election, Gabriel was considered a possible candidate to challenge incumbent Chancellor Angela Merkel but deemed too “unpopular and undisciplined” at the time. As a consequence, he and the other members of the party's leadership agreed to nominate Peer Steinbrück after Frank-Walter Steinmeier, the party's parliamentary leader, withdrew from the contest.\n\nDuring the election campaign, Gabriel became the first SPD leader to address a party convention of Alliance '90/The Greens; in his speech, he called for a red–green alliance to defeat Merkel in the elections.\n\nIn 2013, Gabriel turned the Social Democrats’ third successive defeat to Angela Merkel in the federal election into a share of government, after successfully navigating the three-month process of coalition negotiations and a ballot of about 475,000 party members, who endorsed the accord. At the time, he was widely considered to have negotiated skillfully, particularly considering the relative weakness of his party, which had received just over 25 percent of the vote in the elections, against more than 41 percent for Merkel's conservative bloc.\n\nAt an SPD convention shortly after the elections, however, Gabriel and the other members of the party's leadership were punished by delegates who re-elected them to their posts with reduced majorities; he received 83.6 percent of members’ ballots after 91.6 percent at the previous vote in 2011.\n\nGabriel, who serves as vice-chancellor in the third Merkel cabinet, took on responsibility for Germany's energy overhaul as part of a newly configured Economy Ministry. Since late 2016, he has been a member of the German government's cabinet committee on Brexit at which ministers discuss organizational and structural issues related to the United Kingdom's departure from the European Union.\n\nSpeculation about Gabriel's future as leader of the SPD has been brewing since he registered just 74 percent in a party delegates' vote of confidence in December 2015 – the lowest for an SPD leader in 20 years. On 24 January 2017 Gabriel announced that we will not run as candidate for chancellor in 2017; instead, he proposed that Martin Schulz become candidate and replace him as party chairman.\n\nGabriel also announced that he will succeed Frank-Walter Steinmeier as Minister for Foreign Affairs. He took office on 27 January 2017, the previous Parliamentary State Secretary Brigitte Zypries followed Gabriel as Federal Minister of Economic Affairs and Energy.\n\nAs Foreign Minister Gabriel has said Germany's \"arms will remain outstretched\" to the US to continue the trans-Atlantic alliance between the two countries. However he has said that Germany will step into global markets the US abandons and take on a bigger role on the international stage if Donald Trump continues his protectionist and isolationist policies.\n\nGabriel has been staunchly against German soldiers remaining in Afghanistan. In 2010, he called for an independent assessment that would determine whether the U.S. counter-insurgency strategy would succeed. However, he voted in favor of extending German participation in the NATO-led security mission ISAF in 2009, 2010, 2011 and 2012.\n\nOn the occasion of the sixtieth anniversary of the founding of the State of Israel, Gabriel participated in the first joint cabinet meeting of the governments of Germany and Israel in Jerusalem in March 2008. In 2012, after having visited Hebron and the Palestinian territories, he said the Palestinians in those areas were systematically discriminated against and called Israel an \"Apartheid Regime\".\n\nWhile German members of parliament call out Iran's human rights violations and Nazanin Boniadi, advocate for the Center for Human Rights in Iran, described \"systemic gender apartheid\" where women advocating equal rights are regularly imprisoned, homosexuality is illegal and can carry the death penalty, Gabriel became the first top level German government visitor to Iran in 13 years as well as the first senior figure from any large western country's government to visit the country since it struck an agreement on its nuclear program, the Joint Comprehensive Plan of Action, only days earlier. Travelling with a delegation of German industry representatives keen to move back into the Iranian market, he met with President Hassan Rouhani, Foreign Minister Mohammad Javad Zarif and Oil Minister Bijan Namdar Zangeneh.\n\nIn one of the strongest comments by Germany to push for a federal solution for Ukraine, Gabriel told German weekly \"Welt am Sonntag\" in August 2014 that a federal structure was the only option to resolve pro-Russian unrest in the country. He added that Germany's priority was to prevent direct conflict between Russia and its southern neighbour. Commenting on the international sanctions regime against Russia, Gabriel stated in early 2015 that “we want to help resolve the conflict in Ukraine but don’t want to force Russia to its knees.” He later suggested that Europe consider easing sanctions in exchange for cooperation in Syria. Ukrainian-American historian Alexander J. Motyl has accused Gabriel of \"appeasement\" and \"a complete betrayal of everything democratic socialists claim to stand for.\"\nIn September 2015, amid the European migrant crisis, Gabriel visited the Zaatari refugee camp in Jordan to learn more about the plight of Syrians fleeing the violence in the ongoing Syrian civil war that erupted in 2011. Gabriel publicly urged Saudi Arabia to stop supporting religious radicals, amid growing concern among about the country's funding of Wahhabi mosques in Germany which are accused of breeding dangerous Islamists.\nIn January 2016, Gabriel participated in the first joint cabinet meeting of the governments of Germany and Turkey in Berlin. Later that year, he called any accession of Turkey to the European Union in the near term an \"illusion.\"\n\nAfter the G7 summit in 2017, Sigmar Gabriel stated that the United States, with Donald Trump as president, has \"weakened\" the West and that the balance of power has now shifted. The remark comes days after Merkel stated, in an apparent policy shift, that \"Europeans must really take our fate into our own hands\".\n\nIn June 2017, Gabriel criticized the draft of new U.S. sanctions against Russia that target EU–Russia energy projects, including Nord Stream 2 gas pipeline. In a joint statement Gabriel and Austria's Chancellor Christian Kern said that \"Europe's energy supply is a matter for Europe, and not for the United States of America.\" They also said: \"To threaten companies from Germany, Austria and other European states with penalties on the U.S. market if they participate in natural gas projects such as Nord Stream 2 with Russia or finance them introduces a completely new and very negative quality into European-American relations.\"\n\nGabriel is a supporter of the Campaign for the Establishment of a United Nations Parliamentary Assembly, an organisation which campaigns for democratic reformation of the United Nations, and the creation of a more accountable international political system. He argued the U.N. needed to be made \"more effective, transparent, and democratic through a reform of its structures and decision-making procedures\".\n\nIn March 2018, after his departure as German foreign minister, Gabriel published an opinion piece about the future of the relations between Turkey (under AKP rule) and the West, where he advocated for an inclusive stance towards Turkey and criticized the policy of the United States in that regard.\n\nOn the occasion of the G20 summit in 2011, Gabriel joined Ed Miliband, the leader of the UK's Labour Party, and Håkan Juholt, the chairman of the Swedish Social Democratic Party, in suggesting a “new deal” for economic growth. They also said G20 leaders should commit to the introduction of a financial transaction tax for all major financial centers and an agreement to separate consumer and investment banking.\n\nIn a letter to the European Commissioner for Trade, Karel De Gucht, Gabriel stated in March 2014 that “special investment-protection provisions are not required in an agreement between the E.U. and the U.S” on a Transatlantic Trade and Investment Partnership (TTIP). Instead, he later called for a public trade and investment court to replace the current system of private arbitration, and to enable appeals against arbitration rulings. Meanwhile, he has continuously warned against overblowing expectations for an economic boost from TTIP but maintained that the pact was needed to set high common standards for consumers. By August 2016, Gabriel said talks on TTIP had \"de facto\" failed.\n\nIn September 2014, Gabriel rejected the inclusion of an investor-state dispute settlement clause in the Comprehensive Economic and Trade Agreement (CETA) between Canada and the European Union, prompting a renegotiation that delayed the entry into force of the agreement. Following the renegotiations, he championed CETA to demonstrate the center-left party's business credentials.\n\nIn a 2014 meeting with French economist Thomas Piketty, whose best-selling work \"Capital in the Twenty-First Century\" calls for a wealth tax, Gabriel rejected such a progressive levy on capital as “crazy” for business. He also argued that a wealth tax would generate no more than 8 billion euros ($9.9 billion) a year.\n\nTogether with his French counterpart Emmanuel Macron, Gabriel presented a joint proposal in 2015 to set up a common eurozone budget.\n\nFollowing the Fukushima Daiichi nuclear disaster in 2011, Gabriel harshly criticized the International Atomic Energy Agency, saying it had promoted “the construction of nuclear plants in all parts of the world, even in war and crisis regions. That needs to stop.”\n\nIn 2015, Gabriel opposed a European Commission proposal for regional power-capacity markets, according to which utilities are paid for providing backup electricity at times when power generated by renewable sources, such as the sun and wind, cannot supply the grid. A free market backstopped by an emergency reserve will be cheaper and work just as well as capacity markets, Gabriel told \"Handelsblatt\". He later warned against a hasty exit from coal-fired power generation, concerned that such a move could pile more pressure on producers still wrestling with the planned shutdown of nuclear plants by 2022.\n\nEarly in his tenure as Federal Minister of Economic Affairs and Energy, Gabriel vowed a much more cautious approach to licensing arms exports, unnerving the sizeable defense industry and signaling a change in policy from the previous coalition government under which sales rose. In August 2014, he withdrew permission for Rheinmetall to build a military training center east of Moscow.\n\nGabriel is bound by pledges to his SPD to reduce arms sales to states that abuse human rights and the rule of law or where such sales may contribute to political instability. He has stated that controls over the final destination of small arms sold to such nations are still insufficient. However, he also indicated that the government would not universally block deals with countries outside of Germany's traditional alliances. Deals with such countries could be approved because of \"special foreign-policy or security interests.\" He suggested that in future the Federal Foreign Office may be a more appropriate body for deciding whether to allow exports, and called for common European arms exports. In late 2015, his ministry approved a merger of German tank maker Krauss-Maffei Wegmann (KMW) with the French armoured vehicle maker Nexter. Gabriel has been criticized by opposition leaders and the press for failing to prevent several deals that resulted in a significant rise in German arms exports during his tenure, although a paradigm shift (lifting of the prohibition against arms exports in zones of war and crisis) already occurred before that.\n\nIn May 2014, Gabriel and France's economy and digital minister Arnaud Montebourg sent the European Commissioner for Competition, Joaquín Almunia, a letter criticizing the settlement of a three-year antitrust probe into Google; Gabriel later “warmly welcomed” the launch of EU antitrust charges against Google in April 2015.\n\nIn September 2014, Gabriel called Google, Amazon.com and Apple Inc. “anti-social” for skirting appropriate taxation. In early 2015, Gabriel and his French counterpart Emmanuel Macron wrote in a joint letter to Vice-President of the European Commission Andrus Ansip that the growing power of some online giants “warrants a policy consultation with the aim of establishing an appropriate general regulatory framework for ‘essential digital platforms.’”\n\nIn 2016, during a series of Chinese bids for German engineering firms, Gabriel publicly called for a European-wide safeguard clause which could stop foreign takeovers of firms whose technology is deemed strategic for the future economic success of the region.\n\nIn April 2014, human rights lawyer Mo Shaoping was blocked from meeting Gabriel during his visit to China, despite the minister saying ahead of the meeting that he wanted to meet critical voices.\n\nDuring a 2015 visit to King Salman of Saudi Arabia, Gabriel launched an unusual public effort to persuade Saudi authorities to free imprisoned writer Raif Badawi and grant him clemency, amplifying Germany’s political voice in a region in which its influence had largely been limited to economic issues in years past. He had been urged by MPs and human rights organizations to take up Badawi's case before his trip. His outspoken criticism of Saudi justice was unusual for Western leaders visiting the country, a close ally for the West in fighting terrorism and Islamic State militants, particularly given Germany’s status as Saudi Arabia’s third-largest source of imports. While the U.S. State Department had previously also criticized the Badawi sentence, U.S. Secretary of State John Kerry did not talk about the case publicly when he visited Riyadh only days before.\n\nDuring a subsequent trip to Qatar, Gabriel called on the emir of Qatar, Sheikh Tamim Bin Hamad Al Thani and other senior officials to do better in protecting foreign household workers who face abuse from their employers.\n\nIn 2010, Gabriel called the speeches of Thilo Sarrazin, his party colleague who wrote critically about immigration by accusing Muslims of refusing to integrate and of “dumbing down” German society, \"verbal violence\". He stated that although Sarrazin described many things that were accurate, his conclusions did not fit into the egalitarian “ideals” of Social Democracy anymore.\n\nIn 2016, a German court nullified Gabriel's controversial decision to grant a special permission for the country's biggest supermarket chain Edeka to buy grocery store chain Kaiser's, owned by Tengelmann Group. The judges raised questions about the minister's \"bias and a lack of neutrality\" in the case, saying he had held secret discussion during the decision making process.\n\n\n\nGabriel has a daughter, Saskia, born in 1989, with his former girlfriend, who is of Jewish origin and whose grandparents were murdered in Auschwitz. Gabriel was subsequently married to his former high school student Munise Demirel, who is of Turkish origin, from 1989 to 1998, and they had no children. In 2012 he married dentist Anke Stadler, with whom he has been in a relationship since 2008; their daughter Marie was born in 2012. His daughter Thea was born on March 4, 2017.\n\nIn December 2016, Gabriel underwent bariatric surgery in Offenbach to shrink his stomach and help manage his diabetes.\n\n\n"}
{"id": "46618525", "url": "https://en.wikipedia.org/wiki?curid=46618525", "title": "Solar hybrid power systems", "text": "Solar hybrid power systems\n\nSolar hybrid power systems are hybrid power systems that combine solar power from a photovoltaic system with another power generating energy source. A common type is a photovoltaic diesel hybrid system, combining photovoltaics (PV) and diesel generators, or diesel gensets, as PV has hardly any marginal cost and is treated with priority on the grid. The diesel gensets are used to constantly fill in the gap between the present load and the actual generated power by the PV system.\n\nAs solar energy is fluctuating, and the generation capacity of the diesel genesets is limited to a certain range, it is often a viable option to include battery storage in order to optimize solar's contribution to the overall generation of the hybrid system.\n\nThe best business cases for diesel reduction with solar and wind energy can normally be found in remote locations because these sites are often not connected to the grid and transport of diesel over long distances is expensive. Many of these applications can be found in the mining sector and on islands \n\nIn 2015, a case-study conducted in seven countries concluded that in all cases generating costs can be reduced by hybridising mini-grids and isolated grids. However, financing costs for diesel-powered electricity grids with solar photovoltaics are crucial and largely depend on the ownership structure of the power plant. While cost reductions for state-owned utilities can be significant, the study also identified short-term economic benefits to be insignificant or even negative for non-public utilities, such as independent power producers, given historical costs at the time of the study.\n\nOther solar hybrids include solar-wind systems. The combination of wind and solar has the advantage that the two sources complement each other because the peak operating times for each system occur at different times of the day and year. The power generation of such a hybrid system is more constant and fluctuates less than each of the two component subsystems.\n\nThe intermittent / non-dispatchable solar PV at the prevailing low tariffs clubbed with Pumped-heat electricity storage can offer cheapest dispatchable power round the clock on demand.\n\nThough Solar PV generates cheaper intermittent power during the day light time, it needs the support of sustainable power generation sources to provide round the clock power. Solar thermal plants with thermal storage are clean sustainable power generation to supply electricity round the clock. They can cater the load demand perfectly and work as base load power plants when the extracted solar energy is found excess in a day. Proper mix of solar thermal (thermal storage type) and solar PV can fully match the load fluctuations without the need of costly battery storage.\n\nDuring the day time, the additional auxiliary power consumption of a solar thermal storage power plant is nearly 10% of its rated capacity for the process of extracting solar energy in the form of thermal energy. This auxiliary power requirement can be made available from cheaper solar PV plant by envisaging hybrid solar plant with a mix of solar thermal and solar PV plants at a site. Also to optimise the cost of power, generation can be from the cheaper solar PV plant (33% generation) during the day light whereas the rest of the time in a day is from the solar thermal storage plant (67% generation from Solar power tower and parabolic trough types) for meeting 24 hours base load operation. When solar thermal storage plant is forced to idle due to lack of sunlight locally during cloudy days in monsoon season, it is also possible to consume (similar to a lesser efficient, huge capacity and low cost battery storage system) the cheap surplus / infirm power from solar PV, wind and hydro power plants by heating the hot molten salt to higher temperature for converting stored thermal energy in to electricity during the peak demand hours when the electricity sale price is profitable.\n\n"}
{"id": "679929", "url": "https://en.wikipedia.org/wiki?curid=679929", "title": "Stone (unit)", "text": "Stone (unit)\n\nThe stone or stone weight (abbreviation: st.) is an English and imperial unit of mass now equal to 14 pounds (6.35029318 kg).\n\nEngland and other Germanic-speaking countries of northern Europe formerly used various standardised \"stones\" for trade, with their values ranging from about 5 to 40 local pounds (roughly 3 to 15 kg) depending on the location and objects weighed. The United Kingdom's imperial system adopted the wool stone of 14 pounds in 1835. With the advent of metrication, Europe's various \"stones\" were superseded by or adapted to the kilogram from the mid-19th century on. The stone continues in customary use in Britain and Ireland used for measuring body weight, but was prohibited for commercial use in the UK by the Weights and Measures Act of 1985.\n\nThe name \"stone\" derives from the use of stones for weights, a practice that dates back into antiquity. The Biblical law against the carrying of \"diverse weights, a large and a small\" is more literally translated as \"you shall not carry a stone and a stone (), a large and a small\". There was no standardised \"stone\" in the ancient Jewish world, but in Roman times stone weights were crafted to multiples of the Roman pound. Such weights varied in quality: the Yale Medical Library holds 10 and 50-pound examples of polished serpentine, while a 40-pound example at the Eschborn Museum is made of sandstone.\n\nThe English stone under law varied by commodity and in practice varied according to local standards. The Assize of Weights and Measures, a statute of uncertain date from , describes stones of 5 merchants' pounds used for glass; stones of 8 lb. used for beeswax, sugar, pepper, alum, cumin, almonds, cinnamon, and nutmegs; stones of 12 lb. used for lead; and the of  lb. used for wool. In 1350, Edward III issued a new statute defining the stone weight, to be used for wool and \"other Merchandizes\", at 14 pounds, reaffirmed by Henry VII in 1495.\nIn England, merchants traditionally sold potatoes in half-stone increments of 7 pounds. Live animals were weighed in stones of 14 lb; but, once slaughtered, their carcasses were weighed in stones of 8 lb. Thus, if the animal's carcass accounted for of the animal's weight, the butcher could return the dressed carcasses to the animal's owner stone for stone, keeping the offal, blood and hide as his due for slaughtering and dressing the animal. Smithfield market continued to use the 8 lb stone for meat until shortly before the Second World War. The \"Oxford English Dictionary\" also lists:\nThe Scottish stone was equal to 16 Scottish pounds (17 lb 8 oz avoirdupois or 7.936 kg). In 1661, the Royal Commission of Scotland recommended that the Troy stone be used as a standard of weight and that it be kept in the custody of the burgh of Lanark. The tron (or local) stone of Edinburgh, also standardised in 1661, was 16 tron pounds (24 lb 1 oz avoirdupois or 9.996 kg). In 1789, an encyclopedic enumeration of measurements was printed for the use of \"his Majesty's Sheriffs and Stewards Depute, and Justices of Peace, ... and to the Magistrates of the Royal Boroughs of Scotland\" and provided a county-by-county and commodity-by-commodity breakdown of values and conversions for the stone and other measures. The Scots stone ceased to be used for trade when the Act of 1824 established a uniform system of measure across the whole of the United Kingdom, which at that time included all of Ireland.\n\nBefore the early 19th century, as in England, the stone varied both with locality and with commodity. For example, the \"Belfast stone\" for measuring flax equaled 16.75 avoirdupois pounds. The most usual value was 14 pounds. Among the oddities related to the use of the stone was the practice in County Clare of a stone of potatoes being 16 lb in the summer and 18 lb in the winter.\n\nThe 1772 edition of the Encyclopædia Britannica defined the stone:STONE also denotes a certain quantity or weight of some commodities. A stone of beef, in London, is the quantity of eight pounds; in Hertfordshire, twelve pounds; in Scotland sixteen pounds.\n\nThe Weights and Measures Act of 1824, which applied to all of the United Kingdom, consolidated the weights and measures legislation of several centuries into a single document. It revoked the provision that bales of wool should be made up of 20 stones, each of 14 pounds, but made no provision for the continued use of the stone. Ten years later, a stone still varied from 5 pounds (glass) to 8 pounds (meat and fish) to 14 pounds (wool and \"horseman's weight\"). However, the Act of 1835 permitted using a stone of 14 pounds for trade but other values remained in use. James Britten, in 1880 for example, catalogued a number of different values of the stone in various British towns and cities, ranging from 4 lb to 26 lb. The value of the stone and associated units of measure that were legalised for purposes of trade were clarified by the Weights and Measures Act 1835 as follows:\nIn 1965, the then Federation of British Industry informed the British Government that its members favoured adopting the metric system. The Board of Trade, on behalf of the Government, agreed to support a ten-year metrication programme. There would be minimal legislation, as the programme was to be voluntary and costs were to be borne where they fell. Under the guidance of the Metrication Board, the agricultural product markets achieved a voluntary switchover by 1976. The stone was not included in the Directive 80/181/EEC as a unit of measure that could be used within the EEC for \"economic, public health, public safety or administrative purposes\", though its use as a \"supplementary unit\" was permitted. The scope of the directive was extended to include all aspects of the EU internal market as from 1 January 2010.\n\nWith the adoption of metric units by the agricultural sector, the stone was, in practice, no longer used for trade; and, in the Weights and Measures Act 1985, passed in compliance with EU directive 80/181/EEC, the stone was removed from the list of units permitted for trade in the United Kingdom. In 1983, in response to the same directive, similar legislation was passed in Ireland. The Act repealed earlier acts that defined the stone as a unit of measure for trade. (British law had previously been silent regarding other uses of the stone.)\n\nThe stone remains widely used in the UK and Ireland for human body weight: in those countries people may commonly be said to weigh, e.g., \"11 stone 4\" (11 stones and 4 pounds), rather than \"72 kilograms\" as in many other countries, or \"158 pounds\" (the conventional way of expressing the same weight in the US). The correct plural form of \"stone\" in this context is \"stone\" (as in, \"11 stone\" or \"12 stone 6 pounds\"); in other contexts, the correct plural is \"stones\" (as in, \"Please enter your weight in stones and pounds\"). In Australia and New Zealand, metrication has almost entirely displaced stones and pounds since the 1970s.\n\nIn many sports in both Britain and Ireland, such as professional boxing, wrestling and horse racing, the stone is used to express body weights.\n\nThe use of the stone in the British Empire was varied. In Canada for example, it never had a legal status.\nShortly after the United States declared independence, Thomas Jefferson, then Secretary of State presented a report on weights and measures to the U.S. House of Representatives. Even though all the weights and measures in use in the United States at the time were derived from English weights and measures, his report made no mention of the stone being used. He did, however, propose a decimal system of weights in which his \"[decimal] pound\" would have been and the \"[decimal] stone\" would have been .\nBefore the advent of metrication, units called \"stone\" (German: Stein; Dutch: steen; Polish: kamień) were used in many North-Western European countries. Its value, usually between 3 and 10 kg, varied from city to city and sometimes from commodity to commodity. The number of local \"pounds\" in a stone also varied from city to city. During the early 19th century, states such as the Netherlands (including Belgium) and the South Western German states, which had redefined their system of measures using the \"kilogramme des Archives\" as a reference for weight (mass), also redefined their stone to align it with the kilogram.\n\nThis table shows a selection of stones from various North European Continental cities:\n\nAlthough the advent of the metric system spelt the demise of the stone as a unit of measure, the stone was used in some early discussions and implementations of the metric system. In his \"Philosophical essay\" written in 1668, John Wilkins proposed a system of measure whose unit of length, the \"standard\", was approximately one metre and whose unit of mass was the mass of a cubic \"standard\" of rainwater (which would have been approximately 1,000 kg). He proposed that one tenth of this mass (100 kg) should be called a \"stone\". In 1791, a few years before the French Revolutionary Government agreed on the metre as the basis of the metric system, Thomas Jefferson, in a report to Congress proposed that the United States should adopt a decimal currency system (which was adopted) and a decimal-based system of measure (which was not adopted). Jefferson's proposal for units of measure included a \"decimal pound\" equal to in the customary system and a \"decimal stone\" of 10 such decimal pounds or of the customary units.\n\nNeither Wilkins' nor Jefferson's proposals were adopted; but, in the Netherlands, where the metric system was adopted in 1817, the \"pond\" (pound) was set equal to a kilogram. In modern colloquial Dutch, a \"pond\" is used as an alternative for 500 grams or half a kilogram, and the \"steen\" (stone), which had previously been 8 Amsterdam pond (3.953 kg), was redefined as being 3 kg.\n\n\n"}
{"id": "9432014", "url": "https://en.wikipedia.org/wiki?curid=9432014", "title": "Tantalum hafnium carbide", "text": "Tantalum hafnium carbide\n\nTantalum hafnium carbide is a refractory chemical compound with a general formula TaHfC, which can be considered as a solid solution of tantalum carbide and hafnium carbide. Individually, these two carbides have the highest melting points among the binary compounds, and , respectively, and their \"alloy\" with a composition TaHfC is believed to have a melting point of .\n\nVery few measurements of melting point in tantalum hafnium carbide have been reported, because of the obvious experimental difficulties at extreme temperatures. A 1965 study of the TaC-HfC solid solutions at temperatures 2225–2275 °C found a minimum in the vaporization rate and thus maximum in the thermal stability for TaHfC. This rate was comparable to that of tungsten and was weakly dependent on the initial density of the samples, which were sintered from TaC-HfC powder mixtures, also at 2225–2275 °C. In a separate study, TaHfC was found to have the minimum oxidation rate among the TaC-HfC solid solutions. TaHfC was manufactured by Goodfellow company as a 45 µm powder at a price of $9,540/kg (99.0% purity).\n\nIndividual tantalum and hafnium carbides have a rocksalt cubic lattice structure. They are usually carbon deficient and have nominal formulas TaC and HfC, with x = 0.7–1.0 for Ta and x = 0.56–1.0 for Hf. The same structure is also observed for at least some of their solid solutions. The density calculated from X-ray diffraction data is 13.6 g/cm for TaHfC. Hexagonal NiAs-type structure (space group P63/mmc, No. 194, Pearson symbol hP4) with a density of 14.76 g/cm was reported for TaHfC.\n\nIn 2015 atomistic simulations predicted that a Hf-C-N material could have a melting point exceeding TaHfC by 200 K. This has yet to be verified by experimental evidence.\n"}
{"id": "851681", "url": "https://en.wikipedia.org/wiki?curid=851681", "title": "Tenebrescence", "text": "Tenebrescence\n\nTenebrescence, also known as \"reversible photochromism\", is the ability of minerals to change colour when exposed to sunlight. The effect can be repeated indefinitely, but is destroyed by heating.\n\nTenebrescent minerals include hackmanite, spodumene and tugtupite.\n\nTenebrescent behavior is exploited in synthetic materials for the manufacture of self-adjusting sunglasses, which darken on exposure to sunlight.\n"}
{"id": "5951080", "url": "https://en.wikipedia.org/wiki?curid=5951080", "title": "The Green Crusade", "text": "The Green Crusade\n\nThe Green Crusade is a 1998 book by Charles T. Rubin, a political science professor at Duquesne University, criticizing the environmentalist movement.\n\n\"Publishers Weekly\" wrote:\n"}
{"id": "23799015", "url": "https://en.wikipedia.org/wiki?curid=23799015", "title": "Unified power flow controller", "text": "Unified power flow controller\n\nA unified power flow controller electrical device for providing fast-acting reactive power compensation on high-voltage electricity transmission networks. It uses a pair of three-phase controllable bridges to produce current that is injected into a transmission line using a series transformer. The controller can control active and reactive power flows in a transmission line. \n\nUnified Power Flow Controller (UPFC), as a representative of the third generation of FACTS devices, is by far the most comprehensive FACTS device, in power system steady-state it can implement power flow regulation, reasonably controlling line active power and reactive power, improving the transmission capacity of power system, and in power system transient state it can realize fast-acting reactive power compensation, dynamically supporting the voltage at the access point and improving system voltage stability, moreover, it can improve the damping of the system and power angle stability. \n\nThe UPFC uses solid state devices, which provide functional flexibility, generally not attainable by conventional thyristor controlled systems. The UPFC is a combination of a static synchronous compensator (STATCOM) and a static synchronous series compensator (SSSC) coupled via a common DC voltage link. \n\nThe main advantage of the UPFC is to control the active and reactive power flows in the transmission line. If there are any disturbances or faults in the source side, the UPFC will not work.The UPFC operates only under balanced sine wave source.The controllable parameters of the UPFC are reactance in the line, phase angle and voltage. The UPFC concept was described in 1995 by L. Gyugyi of Westinghouse. The UPFC allows a secondary but important function such as stability control to suppress power system oscillations improving the transient stability of power system.\n\n\n"}
{"id": "5535224", "url": "https://en.wikipedia.org/wiki?curid=5535224", "title": "Weigh lock", "text": "Weigh lock\n\nA weigh lock is a specialized canal lock designed to determine the weight of barges in order to assess toll payments based upon the weight and value of the cargo carried. This requires that the unladen weight of the barge be known.\n\nA barge to be weighed was brought into a supporting cradle connected by levers to a weighing mechanism. The water was then drained and the scale balance adjusted to determine the barge gross weight. Subtracting the tare weight (the weight of the barge when empty) would give the cargo weight. Originally weighlocks measured the weight of the barge, initially by measuring the displacement of water from the lock by collecting the liquid in a separate measuring chamber after the barge had entered. This method also requires that the unladen weight of the barge be known.\n\n\n"}
{"id": "8309537", "url": "https://en.wikipedia.org/wiki?curid=8309537", "title": "Wind turbine design", "text": "Wind turbine design\n\nWind turbine design is the process of defining the form and specifications of a wind turbine to extract energy from the wind.\n\nThis article covers the design of horizontal axis wind turbines (HAWT) since the majority of commercial turbines use this design.\n\nIn 1919, the physicist Albert Betz showed that for a hypothetical ideal wind-energy extraction machine, the fundamental laws of conservation of mass and energy allowed no more than 16/27 (59.3%) of the kinetic energy of the wind to be captured. This Betz' law limit can be approached by modern turbine designs which may reach 70 to 80% of this theoretical limit.\n\nIn addition to aerodynamic design of the blades, design of a complete wind power system must also address design of the hub, controls, generator, supporting structure and foundation. Further design questions arise when integrating wind turbines into electrical power grids.\n\nThe shape and dimensions of the blades of the wind turbine are determined by the aerodynamic performance required to efficiently extract energy from the wind, and by the strength required to resist the forces on the blade. \n\nThe aerodynamics of a horizontal-axis wind turbine are not straightforward. The air flow at the blades is not the same as the airflow far away from the turbine. The very nature of the way in which energy is extracted from the air also causes air to be deflected by the turbine. In addition the aerodynamics of a wind turbine at the rotor surface exhibit phenomena that are rarely seen in other aerodynamic fields.\n\nIn 1919, the physicist Albert Betz showed that for a hypothetical ideal wind-energy extraction machine, the fundamental laws of conservation of mass and energy allowed no more than 16/27 (59.3%) of the kinetic energy of the wind to be captured. This Betz' law limit can be approached by modern turbine designs which may reach 70 to 80% of this theoretical limit.\n\nThe speed at which a wind turbine rotates must be controlled for efficient power generation and to keep the turbine components within designed speed and torque limits. The centrifugal force on the spinning blades increases as the square of the rotation speed, which makes this structure sensitive to overspeed. Because the power of the wind increases as the cube of the wind speed, turbines have to be built to survive much higher wind loads (such as gusts of wind) than those from which they can practically generate power. Wind turbines have ways of reducing torque in high winds.\n\nA wind turbine is designed to produce power over a range of wind speeds. The cut-in speed is around 3–4 m/s for most turbines, and cut-out at 25 m/s. If the rated wind speed is exceeded the power has to be limited. There are various ways to achieve this.\n\nA control system involves three basic elements: sensors to measure process variables, actuators to manipulate energy capture and component loading, and control algorithms to coordinate the actuators based on information gathered by the sensors.\n\nAll wind turbines are designed for a maximum wind speed, called the survival speed, above which they will be damaged. The survival speed of commercial wind turbines is in the range of 40 m/s (144 km/h, 89 MPH) to 72 m/s (259 km/h, 161 MPH). The most common survival speed is 60 m/s (216 km/h, 134 MPH). Some have been designed to survive .\n\nStalling works by increasing the angle at which the relative wind strikes the blades (angle of attack), and it reduces the induced drag (drag associated with lift). Stalling is simple because it can be made to happen passively (it increases automatically when the winds speed up), but it increases the cross-section of the blade face-on to the wind, and thus the ordinary drag. A fully stalled turbine blade, when stopped, has the flat side of the blade facing directly into the wind.\n\nA fixed-speed HAWT (Horizontal Axis Wind Turbine) inherently increases its angle of attack at higher wind speed as the blades speed up. A natural strategy, then, is to allow the blade to stall when the wind speed increases. This technique was successfully used on many early HAWTs. However, on some of these blade sets, it was observed that the degree of blade pitch tended to increase audible noise levels.\n\nVortex generators may be used to control the lift characteristics of the blade. The VGs are placed on the airfoil to enhance the lift if they are placed on the lower (flatter) surface or limit the maximum lift if placed on the upper (higher camber) surface.\n\nFurling works by decreasing the angle of attack, which reduces the induced drag from the lift of the rotor, as well as the cross-section. One major problem in designing wind turbines is getting the blades to stall or furl quickly enough should a gust of wind cause sudden acceleration. A fully furled turbine blade, when stopped, has the edge of the blade facing into the wind.\n\nLoads can be reduced by making a structural system softer or more flexible. This could be accomplished with downwind rotors or with curved blades that twist naturally to reduce angle of attack at higher wind speeds. These systems will be nonlinear and will couple the structure to the flow field - thus, design tools must evolve to model these nonlinearities.\n\nStandard modern turbines all furl the blades in high winds. Since furling requires acting against the torque on the blade, it requires some form of pitch angle control, which is achieved with a slewing drive. This drive precisely angles the blade while withstanding high torque loads. In addition, many turbines use hydraulic systems. These systems are usually spring-loaded, so that if hydraulic power fails, the blades automatically furl. Other turbines use an electric servomotor for every rotor blade. They have a small battery-reserve in case of an electric-grid breakdown. Small wind turbines (under 50 kW) with variable-pitching generally use systems operated by centrifugal force, either by flyweights or geometric design, and employ no electric or hydraulic controls.\n\nFundamental gaps exist in pitch control, limiting the reduction of energy costs, according to a report from a coalition of researchers from universities, industry, and government, supported by the Atkinson Center for a Sustainable Future. Load reduction is currently focused on full-span blade pitch control, since individual pitch motors are the actuators currently available on commercial turbines. Significant load mitigation has been demonstrated in simulations for blades, tower, and drive train. However, there is still research needed, the methods for realization of full-span blade pitch control need to be developed in order to increase energy capture and mitigate fatigue loads.\n\nA control technique applied to the pitch angle is done by comparing the current active power of the engine with the value of active power at the rated engine speed (active power reference, Ps reference). Control of the pitch angle in this case is done with a PI controller controls. However, in order to have a realistic response to the control system of the pitch angle, the actuator uses the time constant Tservo, an integrator and limiters so as the pitch angle to be from 0° to 30° with a rate of change (± 10° per sec).\n\nFrom the figure at the right, the reference pitch angle is compared with the actual pitch angle b and then the error is corrected by the actuator. The reference pitch angle, which comes from the PI controller, goes through a limiter. Restrictions on limits are very important to maintain the pitch angle in real term. Limiting the rate of change is very important especially during faults in the network. The importance is due to the fact that the controller decides how quickly it can reduce the aerodynamic energy to avoid acceleration during errors.\n\nModern large wind turbines are variable-speed machines. When the wind speed is below rated, generator torque is used to control the rotor speed in order to capture as much power as possible. The most power is captured when the tip speed ratio is held constant at its optimum value (typically 6 or 7). This means that as wind speed increases, rotor speed should increase proportionally. The difference between the aerodynamic torque captured by the blades and the applied generator torque controls the rotor speed. If the generator torque is lower, the rotor accelerates, and if the generator torque is higher, the rotor slows down. Below rated wind speed, the generator torque control is active while the blade pitch is typically held at the constant angle that captures the most power, fairly flat to the wind. Above rated wind speed, the generator torque is typically held constant while the blade pitch is active.\n\nOne technique to control a permanent magnet synchronous motor is Field Oriented Control. Field Oriented Control is a closed loop strategy composed of two current controllers (an inner loop and outer loop cascade design) necessary for controlling the torque, and one speed controller.\n\nConstant torque angle control\n\nIn this control strategy the d axis current is kept zero, while the vector current is align with the q axis in order to maintain the torque angle equal with 90. This is one of the most used control strategy because of the simplicity, by controlling only the Iqs current. So, now the electromagnetic torque equation of the permanent magnet synchronous generator is simply a linear equation depend on the Iqs current only.\n\nSo, the electromagnetic torque for Ids = 0 (we can achieve that with the d-axis controller) is now:\n\nT= 3/2 p (λ I + (L-L) I I )= 3/2 p λ I\n\nSo, the complete system of the machine side converter and the cascaded PI controller loops is given by the figure in the right. In that we have the control inputs, which are the duty rations m and m, of the PWM-regulated converter. Also, we can see the control scheme for the wind turbine in the machine side and simultaneously how we keep the I zero (the electromagnetic torque equation is linear).\n\nModern large wind turbines are typically actively controlled to face the wind direction measured by a wind vane situated on the back of the nacelle. By minimizing the yaw angle (the misalignment between wind and turbine pointing direction), the power output is maximized and non-symmetrical loads minimized. However, since the wind direction varies quickly the turbine will not strictly follow the direction and will have a small yaw angle on average. The power output losses can simply be approximated to fall with (cos(yaw angle)). Particularly at low-to-medium wind speeds, yawing can make a significant reduction in turbine output, with wind direction variations of ±30° being quite common and long response times of the turbines to changes in wind direction. At high wind speeds, the wind direction is less variable.\nBraking of a small wind turbine can be done by dumping energy from the generator into a resistor bank, converting the kinetic energy of the turbine rotation into heat. This method is useful if the kinetic load on the generator is suddenly reduced or is too small to keep the turbine speed within its allowed limit.\n\nCyclically braking causes the blades to slow down, which increases the stalling effect, reducing the efficiency of the blades. This way, the turbine's rotation can be kept at a safe speed in faster winds while maintaining (nominal) power output. This method is usually not applied on large grid-connected wind turbines.\n\nA mechanical drum brake or disk brake is used to stop turbine in emergency situation such as extreme gust events or over speed. This brake is a secondary means to hold the turbine at rest for maintenance, with a rotor lock system as primary means. Such brakes are usually applied only after blade furling and electromagnetic braking have reduced the turbine speed generally 1 or 2 rotor RPM, as the mechanical brakes can create a fire inside the nacelle if used to stop the turbine from full speed. The load on the turbine increases if the brake is applied at rated RPM. Mechanical brakes are driven by hydraulic systems and are connected to main control box. \n\nThere are different size classes of wind turbines. The smallest having power production less than 10 kW are used in homes, farms and remote applications whereas intermediate wind turbines (10-250 kW ) are useful for village power, hybrid systems and distributed power. The world's largest wind turbine, an 8-MW turbine located at the Burbo Bank Extension wind farm in Liverpool Bay, United Kingdom, was installed in 2016. Utility-scale turbines (larger than one megawatt) are used in central station wind farms, distributed power and community wind.\nFor a given survivable wind speed, the mass of a turbine is approximately proportional to the cube of its blade-length. Wind power intercepted by the turbine is proportional to the square of its blade-length. The maximum blade-length of a turbine is limited by both the strength, the stiffness of its material, and transportation considerations.\n\nLabor and maintenance costs increase only gradually with increasing turbine size, so to minimize costs, wind farm turbines are basically limited by the strength of materials, and siting requirements.\n\nTypical modern wind turbines have diameters of and are rated between 500 kW and 2 MW. As of 2017 the most powerful turbine, the Vestas V-164, is rated at 9.5 MW and has a rotor diameter of 164m.\n\nIncreasingly large wind turbines are being designed, manufacturers have not yet come close to the maximum size. The largest turbines are or will be as big as skyscrapers.\n\nThe nacelle is housing the gearbox and generator connecting the tower and rotor. Sensors detect the wind speed and direction, and motors turn the nacelle into the wind to maximize output.\n\nIn conventional wind turbines, the blades spin a shaft that is connected through a gearbox to the generator. The gearbox converts the turning speed of the blades 15 to 20 rotations per minute for a large, one-megawatt turbine into the faster 1,800 revolutions per minute that the generator needs to generate electricity. Analysts from GlobalData estimate that gearbox market grows from $3.2bn in 2006 to $6.9bn in 2011, and to $8.1bn by 2020. Market leaders were Winergy in 2011. The use of magnetic gearboxes has also been explored as a way of reducing wind turbine maintenance costs.\n\nFor large, commercial size horizontal-axis wind turbines, the electrical generator is mounted in a nacelle at the top of a tower, behind the hub of the turbine rotor. Typically wind turbines generate electricity through asynchronous machines that are directly connected with the electricity grid. Usually the rotational speed of the wind turbine is slower than the equivalent rotation speed of the electrical network: typical rotation speeds for wind generators are 5–20 rpm while a directly connected machine will have an electrical speed between 750 and 3600 rpm. Therefore, a gearbox is inserted between the rotor hub and the generator. This also reduces the generator cost and weight. Commercial size generators have a rotor carrying a field winding so that a rotating magnetic field is produced inside a set of windings called the stator. While the rotating field winding consumes a fraction of a percent of the generator output, adjustment of the field current allows good control over the generator output voltage.\n\nOlder style wind generators rotate at a constant speed, to match power line frequency, which allowed the use of less costly induction generators. Newer wind turbines often turn at whatever speed generates electricity most efficiently. The varying output frequency and voltage can be matched to the fixed values of the grid using multiple technologies such as doubly fed induction generators or full-effect converters where the variable frequency current produced is converted to DC and then back to AC. Although such alternatives require costly equipment and cause power loss, the turbine can capture a significantly larger fraction of the wind energy. In some cases, especially when turbines are sited offshore, the DC energy will be transmitted from the turbine to a central (onshore) inverter for connection to the grid.\n\nGearless wind turbines (also called direct drive) get rid of the gearbox completely. Instead, the rotor shaft is attached directly to the generator, which spins at the same speed as the blades. \n\nAdvantages of PMDD generators over gear-based generators include increased efficiency, reduced noise, longer lifetime, high torque at low rpm, faster and precise positioning, and drive stiffness. PMDD generators \"eliminate the gear-speed increaser, which is susceptible to significant accumulated fatigue torque loading, related reliability issues, and maintenance costs.\" \n\nTo make up for a direct drive generator's slower spinning rate, the diameter of the generator's rotor is increased so that it can contain more magnets to create the required frequency and power. Gearless wind turbines are often heavier than gear-based wind turbines. A study by the EU called \"Reliawind\" based on the largest sample size of turbines has shown that the reliability of gearboxes is not the main problem in wind turbines. The reliability of direct drive turbines offshore is still not known, since the sample size is so small.\n\nExperts from Technical University of Denmark estimate that a geared generator with permanent magnets may use 25 kg/MW of the rare-earth element Neodymium, while a gearless may use 250 kg/MW.\n\nIn December 2011, the US Department of Energy published a report stating critical shortage of rare-earth elements such as neodymium used in large quantities for permanent magnets in gearless wind turbines. China produces more than 95% of rare-earth elements, while Hitachi holds more than 600 patents covering Neodymium magnets.\nDirect-drive turbines require 600 kg of permanent magnet material per megawatt, which translates to several hundred kilograms of rare-earth content per megawatt, as neodymium content is estimated to be 31% of magnet weight. Hybrid drivetrains (intermediate between direct drive and traditional geared) use significantly less rare-earth materials.\nWhile permanent magnet wind turbines only account for about 5% of the market outside of China, their market share inside of China is estimated at 25% or higher.\nIn 2011, demand for neodymium in wind turbines was estimated to be 1/5 of that in electric vehicles.\n\nThe ratio between the speed of the blade tips and the speed of the wind is called tip speed ratio. High efficiency 3-blade-turbines have tip speed/wind speed ratios of 6 to 7.\nModern wind turbines are designed to spin at varying speeds (a consequence of their generator design, see above). Use of aluminum and composite materials in their blades has contributed to low rotational inertia, which means that newer wind turbines can accelerate quickly if the winds pick up, keeping the tip speed ratio more nearly constant. Operating closer to their optimal tip speed ratio during energetic gusts of wind allows wind turbines to improve energy capture from sudden gusts that are typical in urban settings.\n\nIn contrast, older style wind turbines were designed with heavier steel blades, which have higher inertia, and rotated at speeds governed by the AC frequency of the power lines. The high inertia buffered the changes in rotation speed and thus made power output more stable.\n\nIt is generally understood that noise increases with higher blade tip speeds. To increase tip speed without increasing noise would allow reduction the torque into the gearbox and generator and reduce overall structural loads, thereby reducing cost.\nThe reduction of noise is linked to the detailed aerodynamics of the blades, especially factors that reduce abrupt stalling. The inability to predict stall restricts the development of aggressive aerodynamic concepts. Some blades (mostly on Enercon) have a winglet to increase performance and/or reduce noise.\n\nA blade can have a lift-to-drag ratio of 120, compared to 70 for a sailplane and 15 for an airliner.\n\nIn simple designs, the blades are directly bolted to the hub and are unable to pitch, which leads to aerodynamic stall above certain windspeeds. In other more sophisticated designs, they are bolted to the pitch bearing, which adjusts their angle of attack with the help of a pitch system according to the wind speed to control their rotational speed. The pitch bearing is itself bolted to the hub. The hub is fixed to the rotor shaft which drives the generator directly or through a gearbox.\n\nThe number of blades is selected for aerodynamic efficiency, component costs, and system reliability. Noise emissions are affected by the location of the blades upwind or downwind of the tower and the speed of the rotor. Given that the noise emissions from the blades' trailing edges and tips vary by the 5th power of blade speed, a small increase in tip speed can make a large difference.\n\nWind turbines developed over the last 50 years have almost universally used either two or three blades. However, there are patents that present designs with additional blades, such as Chan Shin's Multi-unit rotor blade system integrated wind turbine.\nAerodynamic efficiency increases with number of blades but with diminishing return. Increasing the number of blades from one to two yields a six percent increase in aerodynamic efficiency, whereas increasing the blade count from two to three yields only an additional three percent in efficiency. Further increasing the blade count yields minimal improvements in aerodynamic efficiency and sacrifices too much in blade stiffness as the blades become thinner.\n\nTheoretically, an infinite number of blades of zero width is the most efficient, operating at a high value of the tip speed ratio. But other considerations lead to a compromise of only a few blades.\n\nComponent costs that are affected by blade count are primarily for materials and manufacturing of the turbine rotor and drive train. Generally, the lower the number of blades, the lower the material and manufacturing costs will be. In addition, the lower the number of blades, the higher the rotational speed can be. This is because blade stiffness requirements to avoid interference with the tower limit how thin the blades can be manufactured, but only for upwind machines; deflection of blades in a downwind machine results in increased tower clearance. Fewer blades with higher rotational speeds reduce peak torques in the drive train, resulting in lower gearbox and generator costs.\n\nSystem reliability is affected by blade count primarily through the dynamic loading of the rotor into the drive train and tower systems. While aligning the wind turbine to changes in wind direction (yawing), each blade experiences a cyclic load at its root end depending on blade position. This is true of one, two, three blades or more. However, these cyclic loads when combined together at the drive train shaft are symmetrically balanced for three blades, yielding smoother operation during turbine yaw. Turbines with one or two blades can use a pivoting teetered hub to also nearly eliminate the cyclic loads into the drive shaft and system during yawing. A Chinese 3.6 MW two-blade is being tested in Denmark. Mingyang won a bid for 87 MW (29 * 3 MW) two-bladed offshore wind turbines near Zhuhai in 2013.\n\nFinally, aesthetics can be considered a factor in that some people find that the three-bladed rotor is more pleasing to look at than a one- or two-bladed rotor.\n\nIn general, ideal materials should meet the following criteria: \n\nThis narrows down the list of acceptable materials. Metals would be undesirable because of their vulnerability to fatigue. Ceramics have low fracture toughness, which could result in early blade failure. Traditional polymers are not stiff enough to be useful, and wood has problems with repeatability, especially considering the length of the blade. That leaves fiber-reinforced composites, which have high strength and stiffness and low density, as a very attractive class of materials for the design of wind turbines.\n\nWood and canvas sails were used on early windmills due to their low price, availability, and ease of manufacture. Smaller blades can be made from light metals such as aluminium. These materials, however, require frequent maintenance. Wood and canvas construction limits the airfoil shape to a flat plate, which has a relatively high ratio of drag to force captured (low aerodynamic efficiency) compared to solid airfoils. Construction of solid airfoil designs requires inflexible materials such as metals or composites. Some blades also have incorporated lightning conductors.\n\nNew wind turbine designs push power generation from the single megawatt range to upwards of 10 megawatts using larger and larger blades. A larger area effectively increases the tip-speed ratio of a turbine at a given wind speed, thus increasing its energy extraction.\nComputer-aided engineering software such as HyperSizer (originally developed for spacecraft design) can be used to improve blade design.\n\nAs of 2015 the rotor diameters of onshore wind turbine blades are as large as 130 meters, while the diameter of offshore turbines reach 170 meters. In 2001, an estimated 50 million kilograms of fibreglass laminate were used in wind turbine blades.\n\nAn important goal of larger blade systems is to control blade weight. Since blade mass scales as the cube of the turbine radius, loading due to gravity constrains systems with larger blades. Gravitational loads include axial and tensile/ compressive loads (top/bottom of rotation) as well as bending (lateral positions). The magnitude of these loads fluctuates cyclically and the edgewise moments (see below) are reversed every 180° of rotation.\nTypical rotor speeds and design life are ~10 and 20 years, respectively, with the number of lifetime revolutions on the order of 10^8. Considering wind, it is expected that turbine blades go through ~10^9 loading cycles.\nWind is another source of rotor blade loading. Lift causes bending in the flapwise direction (out of rotor plane) while air flow around the blade cause edgewise bending (in the rotor plane). \nFlapwise bending involves tension on the pressure (upwind) side and compression on the suction (downwind) side. \nEdgewise bending involves tension on the leading edge and compression on the trailing edge.\n\nWind loads are cyclical because of natural variability in wind speed and wind shear (higher speeds at top of rotation).\n\nFailure in ultimate loading of wind-turbine rotor blades exposed to wind and gravity loading is a failure mode that needs to be considered when the rotor blades are designed. The wind speed that causes bending of the rotor blades exhibits a natural variability, and so does the stress response in the rotor blades. Also, the resistance of the rotor blades, in terms of their tensile strengths, exhibits a natural variability.\n\nIn light of these failure modes and increasingly larger blade systems, there has been continuous effort toward developing cost-effective materials with higher strength-to-mass ratios. In order to extend the current 20 year lifetime of blades and enable larger area blades to be cost-effective, the design and materials need to be optimized for stiffness, strength, and fatigue resistance.\n\nThe majority of current commercialized wind turbine blades are made from fiber-reinforced polymers (FRPs), which are composites consisting of a polymer matrix and fibers. The long fibers provide longitudinal stiffness and strength, and the matrix provides fracture toughness, delamination strength, out-of-plane strength, and stiffness. Material indices based on maximizing power efficiency, and having high fracture toughness, fatigue resistance, and thermal stability, have been shown to be highest for glass and carbon fiber reinforced plastics (GFRPs and CFRPs).\n\nManufacturing blades in the 40 to 50 metre range involves proven fibreglass composite fabrication techniques. Manufactures such as Nordex SE and GE Wind use an infusion process. Other manufacturers use variations on this technique, some including carbon and wood with fibreglass in an epoxy matrix. Other options include preimpregnated (\"prepreg\") fibreglass and vacuum-assisted resin transfer molding. Each of these options use a glass-fibre reinforced polymer composite constructed with differing complexity. Perhaps the largest issue with more simplistic, open-mould, wet systems are the emissions associated with the volatile organics released. Preimpregnated materials and resin infusion techniques avoid the release of volatiles by containing all VOCs. However, these contained processes have their own challenges, namely the production of thick laminates necessary for structural components becomes more difficult. As the preform resin permeability dictates the maximum laminate thickness, bleeding is required to eliminate voids and ensure proper resin distribution.\nOne solution to resin distribution a partially preimpregnated fibreglass. During evacuation, the dry fabric provides a path for airflow and, once heat and pressure are applied, resin may flow into the dry region resulting in a thoroughly impregnated laminate structure.\n\nEpoxy-based composites have environmental, production, and cost advantages over other resin systems. Epoxies also allow shorter cure cycles, increased durability, and improved surface finish. Prepreg operations further reduce processing time over wet lay-up systems. As turbine blades pass 60 metres, infusion techniques become more prevalent; the traditional resin transfer moulding injection time is too long as compared to the resin set-up time, limiting laminate thickness. Injection forces resin through a thicker ply stack, thus depositing the resin where in the laminate structure before gelation occurs. Specialized epoxy resins have been developed to customize lifetimes and viscosity.\n\nCarbon fibre-reinforced load-bearing spars can reduce weight and increase stiffness. Using carbon fibres in 60 metre turbine blades is estimated to reduce total blade mass by 38% and decrease cost by 14% compared to 100% fibreglass. Carbon fibres have the added benefit of reducing the thickness of fiberglass laminate sections, further addressing the problems associated with resin wetting of thick lay-up sections. Wind turbines may also benefit from the general trend of increasing use and decreasing cost of carbon fibre materials.\n\nAlthough glass and carbon fibers have many optimal qualities for turbine blade performance, there are several downsides to these current fillers, including the fact that high filler fraction (10-70 wt%) causes increased density as well as microscopic defects and voids that often lead to premature failure.\nRecent developments include interest in using carbon nanotubes (CNTs) to reinforce polymer-based nanocomposites. CNTs can be grown or deposited on the fibers, or added into polymer resins as a matrix for FRP structures. Using nanoscale CNTs as filler instead of traditional microscale filler (such as glass or carbon fibers) results in CNT/polymer nanocomposites, for which the properties can be changed significantly at very low filler contents (typically < 5 wt%). They have very low density, and improve the elastic modulus, strength, and fracture toughness of the polymer matrix. The addition of CNTs to the matrix also reduces the propagation of interlaminar cracks which can be a problem in traditional FRPs.\n\nFurther improvement is possible through the use of carbon nanofibers (CNFs) in the blade coatings. A major problem in desert environments is erosion of the leading edges of blades by wind carrying sand, which increases roughness and decreases aerodynamic performance. The particle erosion resistance of fiber-reinforced polymers is poor when compared to metallic materials and elastomers, and needs to be improved. It has been shown that the replacement of glass fiber with CNF on the composite surface greatly improves erosion resistance. CNFs have also been shown to provide good electrical conductivity (important for lightning strikes), high damping ratio, and good impact-friction resistance. These properties make CNF-based nanopaper a prospective coating for wind turbine blades.\n\nAnother important source of degradation for turbine blades is lightning damage, which over the course of a normal 25-year lifetime is expected to experience a number of lightning strikes throughout its service. The range of damage caused from lightning strikes goes from merely surface level scorching and cracking of the laminate material, to ruptures in the blade or full separation in the adhesives that hold the blade together.It is most common to observe lightning strikes on the tips of the blades, especially in rainy weather due to the copper wiring within attracting lightning. The most common method to combat this, especially in non-conducting blade materials like GFRPs and CFRPs, is to add lightning \"arresters\", which are merely metallic wiring that provides an uninterrupted path to the ground, skipping the blades and gearbox entirely to eliminate the risk of damage in those components.\n\nThe Global Wind Energy Council (GWEC) predicts that wind energy will supply 15.7% of the world’s total energy needs by the year 2020, and 28.5% by the year 2030. This dramatic increase in global wind energy generation will require installation of a newer and larger fleet of more efficient wind turbines and the consequent decommissioning of aging ones. Based on a study carried out by the European Wind Energy Association, in the year 2010 alone, between 110 and 140 kilotons of composites were consumed by the wind turbine industry for manufacturing blades. The majority of the blade material will eventually end up as waste, and in order to accommodate this level of composite waste, the only option is recycling. Typically, glass-fibre-reinforced-polymers (GFRPs) compose of around 70% of the laminate material in the blade. GFRPs hinder incineration and are not combustible. Therefore, conventional recycling methods need to be modified. Currently, depending on whether individual fibres can be recovered, there exists a few general methods for recycling GFRPs in wind turbine blades:\n\nWind velocities increase at higher altitudes due to surface aerodynamic drag (by land or water surfaces) and the viscosity of the air. The variation in velocity with altitude, called wind shear, is most dramatic near the surface.\nTypically, the variation follows the wind profile power law, which predicts that wind speed rises proportionally to the seventh root of altitude. Doubling the altitude of a turbine, then, increases the expected wind speeds by 10% and the expected power by 34%. To avoid buckling, doubling the tower height generally requires doubling the diameter of the tower as well, increasing the amount of material by a factor of at least four.\n\nAt night time, or when the atmosphere becomes stable, wind speed close to the ground usually subsides whereas at turbine hub altitude it does not decrease that much or may even increase. As a result, the wind speed is higher and a turbine will produce more power than expected from the 1/7 power law: doubling the altitude may increase wind speed by 20% to 60%. A stable atmosphere is caused by radiative cooling of the surface and is common in a temperate climate: it usually occurs when there is a (partly) clear sky at night. When the (high altitude) wind is strong (a 10-meter wind speed higher than approximately 6 to 7 m/s) the stable atmosphere is disrupted because of friction turbulence and the atmosphere will turn neutral. A daytime atmosphere is either neutral (no net radiation; usually with strong winds and heavy clouding) or unstable (rising air because of ground heating—by the sun). Here again the 1/7 power law applies or is at least a good approximation of the wind profile. Indiana had been rated as having a wind capacity of 30,000 MW, but by raising the expected turbine height from 50 m to 70 m, the wind capacity estimate was raised to 40,000 MW, and could be double that at 100 m.\n\nFor HAWTs, tower heights approximately two to three times the blade length have been found to balance material costs of the tower against better utilisation of the more expensive active components.\n\nRoad size restrictions makes transportation of towers with a diameter of more than 4.3 m difficult. Swedish analyses show that it is important to have the bottom wing tip at least 30 m above the tree tops, but a taller tower requires a larger tower diameter. A 3 MW turbine may increase output from 5,000 MWh to 7,700 MWh per year by going from 80 to 125 meter tower height. A tower profile made of connected shells rather than cylinders can have a larger diameter and still be transportable. A 100 m prototype tower with TC bolted 18 mm 'plank' shells has been erected at the wind turbine test center Høvsøre in Denmark and certified by Det Norske Veritas, with a Siemens nacelle. Shell elements can be shipped in standard 12 m shipping containers, and 2½ towers per week are produced this way.\n\nAs of 2003, typical modern wind turbine installations use towers about 210 ft (65 m) high.\nHeight is typically limited by the availability of cranes.\nThis has led to a variety of proposals for \"partially self-erecting wind turbines\" that, for a given available crane, allow taller towers that put a turbine in stronger and steadier winds, and \"self-erecting wind turbines\" that can be installed without cranes.\n\nCurrently, the majority of wind turbines are supported by conical tubular steel towers. These towers represent 30% – 65% of the turbine weight and therefore account for a large percentage of the turbine transportation costs. The use of lighter materials in the tower could greatly reduce the overall transport and construction cost of wind turbines, however the stability must be maintained.\nHigher grade S500 steel costs 20%-25% more than S335 steel (standard structural steel), but it requires 30% less material because of its improved strength. Therefore, replacing wind turbine towers with S500 steel would result in net savings both in weight and cost.\n\nAnother disadvantage of conical steel towers is that constructing towers that meet the requirements of wind turbines taller than 90 meters proves challenging. High performance concrete shows potential to increase tower height and increase the lifetime of the towers. A hybrid of prestressed concrete and steel has shown improved performance over standard tubular steel at tower heights of 120 meters. Concrete also gives the benefit of allowing for small precast sections to be assembled on site, avoiding the challenges steel faces during transportation. One downside of concrete towers is the higher CO2 emissions during concrete production as compared to steel. However, the overall environmental benefit should be higher if concrete towers can double the wind turbine lifetime.\n\nWood is being investigated as a material for wind turbine towers, and a 100 metre tall tower supporting a 1.5 MW turbine has been erected in Germany. The wood tower shares the same transportation benefits of the segmented steel shell tower, but without the steel resource consumption.\n\nAll grid-connected wind turbines, from the first one in 1939 until the development of variable-speed grid-connected wind turbines in the 1970s, were fixed-speed wind turbines.\nAs recently as 2003, nearly all grid-connected wind turbines operated at exactly constant speed (synchronous generators) or within a few percent of constant speed (induction generators).\nAs of 2011, many operational wind turbines used fixed speed induction generators (FSIG).\nAs of 2011, most new grid-connected wind turbines are variable speed wind turbines—they are in some variable speed configuration.\n\nEarly wind turbine control systems were designed for peak power extraction, also called maximum power point tracking—they attempt to pull the maximum possible electrical power from a given wind turbine under the current wind conditions.\nMore recent wind turbine control systems deliberately pull less electrical power than they possibly could in most circumstances, in order to provide other benefits, which include:\n\nThe generator in a wind turbine produces alternating current (AC) electricity. Some turbines drive an AC/AC converter—which converts the AC to direct current (DC) with a rectifier and then back to AC with an inverter—in order to match the frequency and phase of the grid. However, the most common method in large modern turbines is to instead use a doubly fed induction generator directly connected to the electricity grid.\n\nA useful technique to connect a permanent magnet synchronous generator to the grid is by using a back-to-back converter. Also, we can have control schemes so as to achieve unity power factor in the connection to the grid. In that way the wind turbine will not consume reactive power, which is the most common problem with wind turbines that use induction machines. This leads to a more stable power system. Moreover, with different control schemes a wind turbine with a permanent magnet synchronous generator can provide or consume reactive power. So, it can work as a dynamic capacitor/inductor bank so as to help with the power systems' stability. \n\nBelow we show the control scheme so as to achieve unity power factor :\n\nReactive power regulation consists of one PI controller in order to achieve operation with unity power factor (i.e. Q = 0 ). It is obvious that I has to be regulated to reach zero at steady-state (I = 0).\n\nWe can see the complete system of the grid side converter and the cascaded PI controller loops in the figure in the right.\n\nWind turbines, by their nature, are very tall slender structures, this can cause a number of issues when the structural design of the foundations are considered. The foundations for a conventional engineering structure are designed mainly to transfer the vertical load (dead weight) to the ground, this generally allows for a comparatively unsophisticated arrangement to be used. However, in the case of wind turbines, the force of the wind's interaction with the rotor at the top of the tower creates a strong tendency to tip the wind turbine over. This loading regime causes large moment loads to be applied to the foundations of a wind turbine. As a result, considerable attention needs to be given when designing the footings to ensure that the foundation will resist this tipping tendency.\n\nOne of the most common foundations for offshore wind turbines is the monopile, a single large-diameter (4 to 6 metres) tubular steel pile driven to a depth of 5-6 times the diameter of the pile into the seabed. The cohesion of the soil, and friction between the pile and the soil provide the necessary structural support for the wind turbine.\n\nIn onshore turbines the most common type of foundation is a gravity foundation, where a large mass of concrete spread out over a large area is used to resist the turbine loads. Wind turbine size & type, wind conditions and soil conditions at the site are all determining factors in the design of the foundation. \n\nThe modern wind turbine is a complex and integrated system. Structural elements comprise the majority of the weight and cost. All parts of the structure must be inexpensive, lightweight, durable, and manufacturable, under variable loading and environmental conditions. Turbine systems that have fewer failures, require less maintenance, are lighter and last longer will lead to reducing the cost of wind energy.\n\nOne way to achieve this is to implement well-documented, validated analysis codes, according to a 2011 report from a coalition of researchers from universities, industry, and government, supported by the Atkinson Center for a Sustainable Future.\n\nThe major parts of a modern turbine may cost (percentage of total): tower 22%, blades 18%, gearbox 14%, generator 8%.\n\nThe design specification for a wind-turbine will contain a power curve and guaranteed availability. With the data from the wind resource assessment it is possible to calculate commercial viability.\nThe typical operating temperature range is . In areas with extreme climate (like Inner Mongolia or Rajasthan) specific cold and hot weather versions are required.\n\nWind turbines can be designed and validated according to IEC 61400 standards.\n\nUtility-scale wind turbine generators have minimum temperature operating limits which apply in areas that experience temperatures below . Wind turbines must be protected from ice accumulation. It can make anemometer readings inaccurate and which, in certain turbine control designs, can cause high structure loads and damage. Some turbine manufacturers offer low-temperature packages at a few percent extra cost, which include internal heaters, different lubricants, and different alloys for structural elements. If the low-temperature interval is combined with a low-wind condition, the wind turbine will require an external supply of power, equivalent to a few percent of its rated power, for internal heating. For example, the St. Leon Wind Farm in Manitoba, Canada, has a total rating of 99 MW and is estimated to need up to 3 MW (around 3% of capacity) of station service power a few days a year for temperatures down to . This factor affects the economics of wind turbine operation in cold climates.\n\n\n\n"}
