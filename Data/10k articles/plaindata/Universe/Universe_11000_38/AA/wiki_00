{"id": "15112639", "url": "https://en.wikipedia.org/wiki?curid=15112639", "title": "AltCar Expo", "text": "AltCar Expo\n\nAltCar Expo is the alternative energy and transportation expo in Santa Monica Civic Auditorium.\n\nAdmission is free.\n\nIn the 2008 Expo (September 26 and 27), the Chevrolet Volt prototype was seen by more than 15,000 people in Santa Monica at AltCar Expo.\n\n\n"}
{"id": "896", "url": "https://en.wikipedia.org/wiki?curid=896", "title": "Argon", "text": "Argon\n\nArgon is a chemical element with symbol Ar and atomic number 18. It is in group 18 of the periodic table and is a noble gas. Argon is the third-most abundant gas in the Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor (which averages about 4000 ppmv, but varies greatly), 23 times as abundant as carbon dioxide (400 ppmv), and more than 500 times as abundant as neon (18 ppmv). Argon is the most abundant noble gas in Earth's crust, comprising 0.00015% of the crust.\n\nNearly all of the argon in the Earth's atmosphere is radiogenic argon-40, derived from the decay of potassium-40 in the Earth's crust. In the universe, argon-36 is by far the most common argon isotope, as it is the most easily produced by stellar nucleosynthesis in supernovas.\n\nThe name \"argon\" is derived from the Greek word , neuter singular form of meaning \"lazy\" or \"inactive\", as a reference to the fact that the element undergoes almost no chemical reactions. The complete octet (eight electrons) in the outer atomic shell makes argon stable and resistant to bonding with other elements. Its triple point temperature of 83.8058 K is a defining fixed point in the International Temperature Scale of 1990.\n\nArgon is produced industrially by the fractional distillation of liquid air. Argon is mostly used as an inert shielding gas in welding and other high-temperature industrial processes where ordinarily unreactive substances become reactive; for example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning. Argon is also used in incandescent, fluorescent lighting, and other gas-discharge tubes. Argon makes a distinctive blue-green gas laser. Argon is also used in fluorescent glow starters.\n\nArgon has approximately the same solubility in water as oxygen and is 2.5 times more soluble in water than nitrogen. Argon is colorless, odorless, nonflammable and nontoxic as a solid, liquid or gas. Argon is chemically inert under most conditions and forms no confirmed stable compounds at room temperature.\n\nAlthough argon is a noble gas, it can form some compounds under various extreme conditions. Argon fluorohydride (HArF), a compound of argon with fluorine and hydrogen that is stable below , has been demonstrated. Although the neutral ground-state chemical compounds of argon are presently limited to HArF, argon can form clathrates with water when atoms of argon are trapped in a lattice of water molecules. Ions, such as , and excited-state complexes, such as ArF, have been demonstrated. Theoretical calculation predicts several more argon compounds that should be stable but have not yet been synthesized.\n\n\"Argon\" (Greek , neuter singular form of meaning \"lazy\" or \"inactive\"), is named in reference to its chemical inactivity. This chemical property of this first noble gas to be discovered impressed the namers. An unreactive gas was suspected to be a component of air by Henry Cavendish in 1785. Argon was first isolated from air in 1894 by Lord Rayleigh and Sir William Ramsay at University College London by removing oxygen, carbon dioxide, water, and nitrogen from a sample of clean air. They had determined that nitrogen produced from chemical compounds was 0.5% lighter than nitrogen from the atmosphere. The difference was slight, but it was important enough to attract their attention for many months. They concluded that there was another gas in the air mixed in with the nitrogen. Argon was also encountered in 1882 through independent research of H. F. Newall and W. N. Hartley. Each observed new lines in the emission spectrum of air that did not match known elements.\n\nUntil 1957, the symbol for argon was \"A\", but now is \"Ar\".\n\nArgon constitutes 0.934% by volume and 1.288% by mass of the Earth's atmosphere, and air is the primary industrial source of purified argon products. Argon is isolated from air by fractionation, most commonly by cryogenic fractional distillation, a process that also produces purified nitrogen, oxygen, neon, krypton and xenon. The Earth's crust and seawater contain 1.2 ppm and 0.45 ppm of argon, respectively.\n\nThe main isotopes of argon found on Earth are (99.6%), (0.34%), and (0.06%). Naturally occurring , with a half-life of 1.25 years, decays to stable (11.2%) by electron capture or positron emission, and also to stable (88.8%) by beta decay. These properties and ratios are used to determine the age of rocks by K–Ar dating.\n\nIn the Earth's atmosphere, is made by cosmic ray activity, primarily by neutron capture of followed by two-neutron emission. In the subsurface environment, it is also produced through neutron capture by , followed by proton emission. is created from the neutron capture by followed by an alpha particle emission as a result of subsurface nuclear explosions. It has a half-life of 35 days.\n\nBetween locations in the Solar System, the isotopic composition of argon varies greatly. Where the major source of argon is the decay of in rocks, will be the dominant isotope, as it is on Earth. Argon produced directly by stellar nucleosynthesis, is dominated by the alpha-process nuclide . Correspondingly, solar argon contains 84.6% (according to solar wind measurements), and the ratio of the three isotopes Ar : Ar : Ar in the atmospheres of the outer planets is 8400 : 1600 : 1. This contrasts with the low abundance of primordial in Earth's atmosphere, which is only 31.5 ppmv (= 9340 ppmv × 0.337%), comparable with that of neon (18.18 ppmv) on Earth and with interplanetary gasses, measured by probes.\n\nThe atmospheres of Mars, Mercury and Titan (the largest moon of Saturn) contain argon, predominantly as , and its content may be as high as 1.93% (Mars).\n\nThe predominance of radiogenic is the reason the standard atomic weight of terrestrial argon is greater than that of the next element, potassium, a fact that was puzzling when argon was discovered. Mendeleev positioned the elements on his periodic table in order of atomic weight, but the inertness of argon suggested a placement \"before\" the reactive alkali metal. Henry Moseley later solved this problem by showing that the periodic table is actually arranged in order of atomic number (see History of the periodic table).\n\nArgon's complete octet of electrons indicates full s and p subshells. This full valence shell makes argon very stable and extremely resistant to bonding with other elements. Before 1962, argon and the other noble gases were considered to be chemically inert and unable to form compounds; however, compounds of the heavier noble gases have since been synthesized. The first argon compound with tungsten pentacarbonyl, W(CO)Ar, was isolated in 1975. However it was not widely recognised at that time. In August 2000, another argon compound, argon fluorohydride (HArF), was formed by researchers at the University of Helsinki, by shining ultraviolet light onto frozen argon containing a small amount of hydrogen fluoride with caesium iodide. This discovery caused the recognition that argon could form weakly bound compounds, even though it was not the first. It is stable up to 17 kelvins (−256 °C). The metastable dication, which is valence-isoelectronic with carbonyl fluoride and phosgene, was observed in 2010. Argon-36, in the form of argon hydride (argonium) ions, has been detected in interstellar medium associated with the Crab Nebula supernova; this was the first noble-gas molecule detected in outer space.\n\nSolid argon hydride (Ar(H)) has the same crystal structure as the MgZn Laves phase. It forms at pressures between 4.3 and 220 GPa, though Raman measurements suggest that the H molecules in Ar(H) dissociate above 175 GPa.\n\nArgon is produced industrially by the fractional distillation of liquid air in a cryogenic air separation unit; a process that separates liquid nitrogen, which boils at 77.3 K, from argon, which boils at 87.3 K, and liquid oxygen, which boils at 90.2 K. About 700,000 tonnes of argon are produced worldwide every year.\n\nAr, the most abundant isotope of argon, is produced by the decay of K with a half-life of 1.25 years by electron capture or positron emission. Because of this, it is used in potassium–argon dating to determine the age of rocks.\n\nArgon has several desirable properties:\n\nOther noble gases would be equally suitable for most of these applications, but argon is by far the cheapest. Argon is inexpensive, since it occurs naturally in air and is readily obtained as a byproduct of cryogenic air separation in the production of liquid oxygen and liquid nitrogen: the primary constituents of air are used on a large industrial scale. The other noble gases (except helium) are produced this way as well, but argon is the most plentiful by far. The bulk of argon applications arise simply because it is inert and relatively cheap.\n\nArgon is used in some high-temperature industrial processes where ordinarily non-reactive substances become reactive. For example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning.\n\nFor some of these processes, the presence of nitrogen or oxygen gases might cause defects within the material. Argon is used in some types of arc welding such as gas metal arc welding and gas tungsten arc welding, as well as in the processing of titanium and other reactive elements. An argon atmosphere is also used for growing crystals of silicon and germanium.\nArgon is used in the poultry industry to asphyxiate birds, either for mass culling following disease outbreaks, or as a means of slaughter more humane than the electric bath. Argon is denser than air and displaces oxygen close to the ground during gassing. Its non-reactive nature makes it suitable in a food product, and since it replaces oxygen within the dead bird, argon also enhances shelf life.\n\nArgon is sometimes used for extinguishing fires where valuable equipment may be damaged by water or foam.\n\nLiquid argon is used as the target for neutrino experiments and direct dark matter searches. The interaction between the hypothetical WIMPs and an argon nucleus produces scintillation light that is detected by photomultiplier tubes. Two-phase detectors containing argon gas are used to detect the ionized electrons produced during the WIMP–nucleus scattering. As with most other liquefied noble gases, argon has a high scintillation light yield (about 51 photons/keV), is transparent to its own scintillation light, and is relatively easy to purify. Compared to xenon, argon is cheaper and has a distinct scintillation time profile, which allows the separation of electronic recoils from nuclear recoils. On the other hand, its intrinsic beta-ray background is larger due to contamination, unless one uses argon from underground sources, which has much less contamination. Most of the argon in the Earth’s atmosphere was produced by electron capture of long-lived ( + e → + ν) present in natural potassium within the Earth. The activity in the atmosphere is maintained by cosmogenic production through the knockout reaction (n,2n) and similar reactions. The half-life of is only 269 years. As a result, the underground Ar, shielded by rock and water, has much less contamination. Dark-matter detectors currently operating with liquid argon include DarkSide, WArP, ArDM, microCLEAN and DEAP. Neutrino experiments include ICARUS and MicroBooNE, both of which use high-purity liquid argon in a time projection chamber for fine grained three-dimensional imaging of neutrino interactions.\n\nArgon is used to displace oxygen- and moisture-containing air in packaging material to extend the shelf-lives of the contents (argon has the European food additive code E938). Aerial oxidation, hydrolysis, and other chemical reactions that degrade the products are retarded or prevented entirely. High-purity chemicals and pharmaceuticals are sometimes packed and sealed in argon.\n\nIn winemaking, argon is used in a variety of activities to provide a barrier against oxygen at the liquid surface, which can spoil wine by fueling both microbial metabolism (as with acetic acid bacteria) and standard redox chemistry.\n\nArgon is sometimes used as the propellant in aerosol cans for such products as varnish, polyurethane, and paint, and to displace air when preparing a container for storage after opening.\n\nSince 2002, the American National Archives stores important national documents such as the Declaration of Independence and the Constitution within argon-filled cases to inhibit their degradation. Argon is preferable to the helium that had been used in the preceding five decades, because helium gas escapes through the intermolecular pores in most containers and must be regularly replaced.\n\nArgon may be used as the inert gas within Schlenk lines and gloveboxes. Argon is preferred to less expensive nitrogen in cases where nitrogen may react with the reagents or apparatus.\n\nArgon may be used as the carrier gas in gas chromatography and in electrospray ionization mass spectrometry; it is the gas of choice for the plasma used in ICP spectroscopy. Argon is preferred for the sputter coating of specimens for scanning electron microscopy. Argon gas is also commonly used for sputter deposition of thin films as in microelectronics and for wafer cleaning in microfabrication.\n\nCryosurgery procedures such as cryoablation use liquid argon to destroy tissue such as cancer cells. It is used in a procedure called \"argon-enhanced coagulation\", a form of argon plasma beam electrosurgery. The procedure carries a risk of producing gas embolism and has resulted in the death of at least one patient.\n\nBlue argon lasers are used in surgery to weld arteries, destroy tumors, and correct eye defects.\n\nArgon has also been used experimentally to replace nitrogen in the breathing or decompression mix known as Argox, to speed the elimination of dissolved nitrogen from the blood.\n\nIncandescent lights are filled with argon, to preserve the filaments at high temperature from oxidation. It is used for the specific way it ionizes and emits light, such as in plasma globes and calorimetry in experimental particle physics. Gas-discharge lamps filled with pure argon provide lilac/violet light; with argon and some mercury, blue light. Argon is also used for blue and green argon-ion lasers.\n\nArgon is used for thermal insulation in energy-efficient windows. Argon is also used in technical scuba diving to inflate a dry suit because it is inert and has low thermal conductivity.\n\nArgon is used as a propellant in the development of the Variable Specific Impulse Magnetoplasma Rocket (VASIMR). Compressed argon gas is allowed to expand, to cool the seeker heads of some versions of the AIM-9 Sidewinder missile and other missiles that use cooled thermal seeker heads. The gas is stored at high pressure.\n\nArgon-39, with a half-life of 269 years, has been used for a number of applications, primarily ice core and ground water dating. Also, potassium–argon dating and related argon-argon dating is used to date sedimentary, metamorphic, and igneous rocks.\n\nArgon has been used by athletes as a doping agent to simulate hypoxic conditions. In 2014, the World Anti-Doping Agency (WADA) added argon and xenon to the list of prohibited substances and methods, although at this time there is no reliable test for abuse.\n\nAlthough argon is non-toxic, it is 38% denser than air and therefore considered a dangerous asphyxiant in closed areas. It is difficult to detect because it is colorless, odorless, and tasteless. A 1994 incident, in which a man was asphyxiated after entering an argon-filled section of oil pipe under construction in Alaska, highlights the dangers of argon tank leakage in confined spaces and emphasizes the need for proper use, storage and handling.\n\n\n"}
{"id": "5824446", "url": "https://en.wikipedia.org/wiki?curid=5824446", "title": "Arroba", "text": "Arroba\n\nArroba was a Portuguese and Spanish custom unit of weight, mass or volume. Its symbol is @.\n\nThe word \"arroba\" has its origin in Arabic \"ar-rubʿ\" (الربع) or \"quarter,\" specifically the fourth part (of a quintal), which defined the average load which a donkey could carry.\n\nIn weight it was equal to 32 pounds (14.7 kg) in Portugal and 25 pounds (11.5 kg) in Spain.\n\nArroba and bushel as weight units are similar (15 kg).\n\nThe unit is still used in Portugal by cork merchants, and in Brazil by the agricultural sector. The modern metric arroba used in these country life activities is defined as .\n\nIn Peru the arroba is equivalent to .\n\nIn Bolivia nationally it is equivalent to . However locally there are many different values, ranging from in Inquisivi to in Baures.\n\nIn Spanish-speaking and Portuguese-speaking countries, \"arroba\" has continued as the word for the \"@\" symbol used in Internet email addresses.\n\n"}
{"id": "7663284", "url": "https://en.wikipedia.org/wiki?curid=7663284", "title": "Barabız", "text": "Barabız\n\nBarabus (rendering of Tatar \"barabız\" “we are going” + English \"bus\") was a winter public transport in 19th – early 20th centuries, probably the first public transport in Kazan after cabs. They were operated by private carriers who were poor Tatar commoners from surrounding villages. A typical barabus was a sledge sheeted with sacking. Barabus was a transport of paupers competing with cabs, horse railways and later tramway. Until the 1930s, when trams were installed in the suburbs and any private enterprise was prohibited, barabuses were the only transport to connect quarters of poor mill-hands with other parts of the city.\n"}
{"id": "2500127", "url": "https://en.wikipedia.org/wiki?curid=2500127", "title": "Crossing the Lines", "text": "Crossing the Lines\n\nThe Crossing the Lines project brings the communities of Utrecht (the Netherlands) and Mortsel (Belgium) and the County of Essex (Great Britain) together to protect and redevelop flood defencelines in Northwest Europe in an environmentally sustainable manner.\n\nThis partnership will develop the defence lines of \"Nieuwe Hollandse Waterlinie\" (Utrecht), the east coast of the UK (Essex) and \"Vesting Antwerpen\" (Mortsel).\n\n"}
{"id": "52821475", "url": "https://en.wikipedia.org/wiki?curid=52821475", "title": "D-space", "text": "D-space\n\nIn mathematics, a topological space formula_1 is a D-space if for any family formula_2 of open sets such that formula_3 for all points formula_4, there is a closed discrete subset formula_5 of the space formula_1 such that formula_7.\n\nThe notion of D-spaces was introduced by Eric Karel van Douwen and E.A. Michael. It first appeared in a 1979 paper by van Douwen and Washek Frantisek Pfeffer in the Pacific Journal of Mathematics. Whether every Lindelöf and regular topological space is a D-space is known as the D-space problem. This problem is among twenty of the most important problems of set theoretic topology.\n\n"}
{"id": "44911815", "url": "https://en.wikipedia.org/wiki?curid=44911815", "title": "Dhanushsagar", "text": "Dhanushsagar\n\nDhanushsagar is a religious place of worship for Hindus where the Patala bhaana of Shiva's bow is housed. The significance of Patala bhaana receives a mention in the Hindu epic Ramayana, wherein Rama during the Sita swayamvara broke the bow of Shiva into three pieces. Akasha bhaana flew to Dhanushkodi in Raameshwaram, bhoomi bhaana housed at Dhanushadham and paatala bhaana creating Dhanushsagar. The bow has been seen by devotees till the early 1980s after which it has got submerged due to the ever-increasing pollution. The lake is 1 km from the famous Janaki temple of Janakpur (erstwhile Mithila). Janakpur draws its fame as the birthplace of Maharani Sita who was one of the principal deities of Ramayana. Presently the area surrounding the lake is used by road side sellers. There are a few bathing ghats built around the lake for public use. A walk around the lake gives a few glimpses of Maa Gayatri temple and Gangasagar which is colacated with Dhanushsagar.\n"}
{"id": "18769542", "url": "https://en.wikipedia.org/wiki?curid=18769542", "title": "Directional Recoil Identification from Tracks", "text": "Directional Recoil Identification from Tracks\n\nThe Directional Recoil Identification from Tracks (DRIFT) detector is a low pressure negative ion time projection chamber (NITPC) designed to detect weakly interacting massive particles (WIMPs) - a prime dark matter candidate.\n\nThere are currently two DRIFT detectors in operation. DRIFT-IId, which is located 1100m underground in the Boulby Underground Laboratory at the Boulby Mine in North Yorkshire, England, and DRIFT-IIe, which is located on the surface at Occidental College, Los Angeles, CA, USA.\n\nThe DRIFT collaboration ultimately aims to develop and operate an underground array of DRIFT detectors for observing and reconstructing WIMP-induced nuclear recoil tracks with enough precision to provide a signature of the dark matter halo.\n\nThere are numerous experiments worldwide attempting to detect the energy deposition that is expected to occur when a WIMP directly collides with an atom of ordinary matter. Ultra sensitive experiments are required to detect the low energy and extremely rare interaction that is predicted to occur between a WIMP and the nucleus of an atom in a target material. The DRIFT detectors vary from the majority of WIMP detectors in their use of a low pressure gas as a target material. The low pressure gas means that an interaction within the detector causes an ionisation track of measurable length compared to the point like interactions seen in detectors with solid or liquid target materials. Such ionisation tracks can be reconstructed in three dimensions to determine not only the type of particle that caused it, but from which direction the particle came. This directional sensitivity has the potential to prove the existence of WIMPs by their distinct directional signature.\n\nThe DRIFT detector's target material is a 1 m cubical drift chamber filled with a low pressure mixture of carbon disulfide (CS) and carbon tetrafluoride (CF) gases (, respectively). It is predicted that WIMPs will occasionally collide with the nucleus of a sulfur or carbon atom in the carbon disulfide gas causing the nucleus to recoil. An energetic recoiling nucleus will ionise gas particles creating a path of free electrons. These free electrons readily attach to the electronegative CS molecules creating a track of ions. The gas volume is divided in half by a cathode at , which produces a static electric field that causes these negative ions to drift, whilst maintaining the track structure, to the MWPC planes at two ends of the detector. Addition of of oxygen to the gas mixture has been the key to full fiducialisation of sensitive volume of the DRIFT detector.\n\nDRIFT-IId published Spin-dependent limits in 2012.\n\n"}
{"id": "878461", "url": "https://en.wikipedia.org/wiki?curid=878461", "title": "Earth's orbit", "text": "Earth's orbit\n\nAll celestial bodies in the Solar System, including planets such as our own, orbit around the Solar System's centre of mass. The sun makes up 99.76% of this mass which is why the centre of mass is extremely close to the sun.\n\nEarth's orbit is the trajectory along which Earth travels around the Sun. The average distance between the Earth and the Sun is 149.60 million km (92.96 million mi), and one complete orbit takes  days (1 sidereal year), during which time Earth has traveled 940 million km (584 million mi). Earth's orbit has an eccentricity of 0.0167.\n\nAs seen from Earth, the planet's orbital prograde motion makes the Sun appear to move with respect to other stars at a rate of about 1° (or a Sun or Moon diameter every 12 hours) eastward per solar day. Earth's orbital speed averages about 30 km/s (108,000 km/h; 67,000 mph), which is fast enough to cover the planet's diameter in 7 minutes and the distance to the Moon in 4 hours.\n\nFrom a vantage point above the north pole of either the Sun or Earth, Earth would appear to revolve in a counterclockwise direction around the Sun. From the same vantage point, both the Earth and the Sun would appear to rotate also in a counterclockwise direction about their respective axes.\n\nHeliocentrism is the scientific model that first placed the Sun at the center of the Solar System and put the planets, including Earth, in its orbit. Historically, heliocentrism is opposed to geocentrism, which placed the Earth at the center. Aristarchus of Samos already proposed a heliocentric model in the 3rd century BC. In the 16th century, Nicolaus Copernicus' \"De revolutionibus\" presented a full discussion of a heliocentric model of the universe in much the same way as Ptolemy had presented his geocentric model in the 2nd century. This \"Copernican revolution\" resolved the issue of planetary retrograde motion by arguing that such motion was only perceived and apparent. \"Although Copernicus's groundbreaking book...had been [printed] over a century earlier, [the Dutch mapmaker] Joan Blaeu was the first mapmaker to incorporate his revolutionary heliocentric theory into a map of the world.\"\n\nBecause of Earth's axial tilt (often known as the obliquity of the ecliptic), the inclination of the Sun's trajectory in the sky (as seen by an observer on Earth's surface) varies over the course of the year. For an observer at a northern latitude, when the north pole is tilted toward the Sun the day lasts longer and the Sun appears higher in the sky. This results in warmer average temperatures, as additional solar radiation reaches the surface. When the north pole is tilted away from the Sun, the reverse is true and the weather is generally cooler. North of the Arctic Circle and south of the Antarctic Circle, an extreme case is reached in which there is no daylight at all for part of the year, and continuous daylight during the opposite time of year. This is called polar night and midnight sun. This variation in the weather (because of the direction of the Earth's axial tilt) results in the seasons.\n\nBy astronomical convention, the four seasons are determined by the solstices (the two points in the Earth's orbit of the maximum tilt of the Earth's axis, toward the Sun or away from the Sun) and the equinoxes (the two points in the Earth's orbit where the Earth's tilted axis and an imaginary line drawn from the Earth to the Sun are exactly perpendicular to one another). The solstices and equinoxes divide the year up into four approximately equal parts. In the northern hemisphere winter solstice occurs on or about December 21; summer solstice is near June 21; spring equinox is around March 20; and autumnal equinox is about September 23. The effect of the Earth's axial tilt in the southern hemisphere is the opposite of that in the northern hemisphere, thus the seasons of the solstices and equinoxes in the southern hemisphere are the reverse of those in the northern hemisphere (e.g. the northern summer solstice is at the same time as the southern winter solstice).\n\nIn modern times, Earth's perihelion occurs around January 3, and the aphelion around July 4 (for other eras, see precession and Milankovitch cycles). The changing Earth–Sun distance results in an increase of about 6.9% in total solar energy reaching the Earth at perihelion relative to aphelion. Since the southern hemisphere is tilted toward the Sun at about the same time that the Earth reaches the closest approach to the Sun, the southern hemisphere receives slightly more energy from the Sun than does the northern over the course of a year. However, this effect is much less significant than the total energy change due to the axial tilt, and most of the excess energy is absorbed by the higher proportion of water in the southern hemisphere.\n\nThe Hill sphere (gravitational sphere of influence) of the Earth is about 1,500,000 kilometers (0.01 AU) in radius, or approximately 4 times the average distance to the moon. This is the maximal distance at which the Earth's gravitational influence is stronger than the more distant Sun and planets. Objects orbiting the Earth must be within this radius, otherwise they can become unbound by the gravitational perturbation of the Sun.\n\nThe following diagram shows the relation between the line of solstice and the line of apsides of Earth's elliptical orbit. The orbital ellipse goes through each of the six Earth images, which are sequentially the perihelion (periapsis — nearest point to the Sun) on anywhere from January 2 to January 5, the point of March equinox on March 19, 20, or 21, the point of June solstice on June 20, 21, or 22, the aphelion (apoapsis — farthest point from the Sun) on anywhere from July 3 to July 5, the September equinox on September 22, 23, or 24, and the December solstice on December 21, 22, or 23. The diagram shows an exaggerated shape of Earth's orbit; the actual orbit is less eccentric than pictured.\nBecause of the axial tilt of the Earth in its orbit, the maximal intensity of Sun rays hits the Earth 23.4 degrees north of equator at the June Solstice (at the Tropic of Cancer), and 23.4 degrees south of equator at the December Solstice (at the Tropic of Capricorn).\n\nMathematicians and astronomers (such as Laplace, Lagrange, Gauss, Poincaré, Kolmogorov, Vladimir Arnold, and Jürgen Moser) have searched for evidence for the stability of the planetary motions, and this quest led to many mathematical developments and several successive \"proofs\" of stability for the Solar System. By most predictions, Earth's orbit will be relatively stable over long periods.\n\nIn 1989, Jacques Laskar's work indicated that the Earth's orbit (as well as the orbits of all the inner planets) can become chaotic and that an error as small as 15 meters in measuring the initial position of the Earth today would make it impossible to predict where the Earth would be in its orbit in just over 100 million years' time. Modeling the Solar System is a subject covered by the n-body problem.\n\n"}
{"id": "15318444", "url": "https://en.wikipedia.org/wiki?curid=15318444", "title": "Environmental Law Alliance Worldwide", "text": "Environmental Law Alliance Worldwide\n\nThe Environmental Law Alliance Worldwide (ELAW) is a public interest, nonprofit, environmental organization that helps communities protect the environment and public health through law. ELAW helps partners strengthen and enforce laws to protect themselves and their communities from toxic pollution and environmental degradation. ELAW provides legal and scientific tools and support that local advocates need to challenge environmental abuses.\n\nELAW was founded in 1989 by lawyers from Australia, Canada, Chile, Ecuador, Indonesia, Malaysia, Peru, the Philippines, Sri Lanka, and the United States. The founders were gathered at the University of Oregon's Public Interest Environmental Law Conference. ELAW's U.S. office is in Eugene, Oregon.\n\nELAW has received grants from the MacArthur Foundation and the Charles Stewart Mott Foundation for projects in conservation and sustainable development.\n\n"}
{"id": "9671882", "url": "https://en.wikipedia.org/wiki?curid=9671882", "title": "Felling", "text": "Felling\n\nFelling is the process of cutting down individual trees, an element of the task of logging. The person cutting the trees is a \"feller\".\n\nIn hand felling, an axe, saw, or chainsaw is used to \"fell\" a tree, followed up by limbing and bucking in traditional applications. In the modern commercial logging industry, felling is typically followed by limbing and skidding.\n\nA feller-buncher is a motorized vehicle with an attachment which rapidly cuts and gathers several trees in the process of felling them. \n\nIn cut-to-length logging a harvester performs the tasks of a feller-buncher additionally doing the delimbing and bucking of the trees as well. When harvesting wood from a felled tree, the recommended methods should be followed in order to get more wood recovery. The suggested trend is to make deeper cuts and smaller openness when performing undercuts. \n\nThis is the guiding or aiming slot for the tree and is a V-shaped notch placed on the side of the tree in the direction of the falling. There are two types of undercut: \n\n\nThis cut is made on the opposite side of the tree and is helpful in the process of felling by releasing the stress on the back of the tree. \n\nThis was an experiment conducted regarding felling trees and the continuous felling of trees in boom-corridors which might lead to an increase in harvester productivity. An efficient way to do this would be to use felling heads which would increase efficiency and fall time. \n"}
{"id": "1415752", "url": "https://en.wikipedia.org/wiki?curid=1415752", "title": "Fiat Doblò", "text": "Fiat Doblò\n\nThe Fiat Doblò is a panel van and leisure activity vehicle produced by Italian automaker Fiat since 2000. It was unveiled at the Paris Motor Show in October 2000.\n\nIt was first launched to the public in the Netherlands, and received the \"2006 International Van of the Year\" award by an international jury from 19 countries. In Singapore, a 1.4 litre LAV variant is marketed as the Fiat Panorama in five and seven seater versions. The first Doblò was sold in January 2001.\n\nThe Doblò carries a payload of up to , with an interior volume of . The Doblò uses Fiat Strada's platform, in turn derived from the Fiat Palio's one, using a rigid axle with leaf springs at the rear, instead of a torsion beam with coil springs as on the Palio.\n\nIt is manufactured by Fiat's Tofaş subsidiary factory in Bursa, Turkey, in Brazil since 2002 and in Russia and Vietnam. Turkish models have an engine range that includes a 1.4 litre petrol, a 1.9 litre MultiJet, and a 16 valve 1.3 litre MultiJet.\n\nIn North Korea, Pyonghwa Motors produces Doblò branded as its own name Ppeokkugi. The facelift version came in October 2005, and was restyled with modifications to the front and rear light groups, and the total design of the front part.\n\nLaunched in 2002, the Brazilian Doblòs were initially available with two 16 valve petrol engines, a 1.3 litre Fire and a 1.6 litre Torque. From 2004 to 2009, the only engine available in Brazil was an 8 valve 1.8 litre \"Ecotec\", supplied by General Motors do Brasil. This engine was produced initially in a petrol version, and later as flex fuel.\n\nIn September 2003, Fiat Brazil introduced an off road 4x2 version called Fiat Doblò Adventure, also with the straight-4 \"Ecotec\" 1800 cc engine. It has revised exterior look with bigger bumpers and mouldings and raised ride height and spare wheel on the rear. \n\nIn 2009, the whole Adventure line (Doblò, Idea, Strada and Palio Weekend) was equipped with a locking differential. The line was rebadged as Adventure Locker. Only in the model year of 2010, the Brazilian Doblò and the Doblò Adventure were updated with the European facelift of 2005. \n\nBesides the 1.8 litre \"Powertrain\", Doblò is now equipped with a 1.4 litre Fire flex engine. In the model year of 2011, the 8 valve 1.8 litre \"Ecotec\" engine was replaced by the brand new 16 valve 1.8 litre \"E.torQ\" engine, produced by Fiat Powertrain Technologies.\n\nMicro-Vett Fiat Doblò has three battery versions:\n\nThe vehicle uses a 30 kW (60 kW peak) motor from Ansaldo Electric Drives, that gives top speed.\n\nOn October 2, 2007, a sixty day demonstration of the All-Electric Fiat Doblo was begun. The Electric engine is powered by a custom 18 kWh Altairnano high performance NanoSafe(R) battery pack, travelled in an urban delivery circuit.\n\nThe custom battery pack was fully recharged in less than ten minutes a total of three times using AeroViroments' high voltage, 125 kW rated, rapid charging system. The vehicle was driven an estimated total of during the sixty day demonstration period, which translates to an annual equivalent use of .\n\nThe all new Doblò (Type 263) was launched in the beginning of 2010, and it is built in Turkey by Tofaş. The 2010 Doblò uses the Fiat Small platform, derived from the Grande Punto, with a new bi link independent rear suspension instead of a torsion beam, which has wheelbase, luggage compartment, and low CO emissions (129 g/km with the 1.3 Multijet engine). The Doblò is also sold by General Motors European Opel and Vauxhall brands as Combo.\n\nThese two features are combined for the Fiat Doblò Cargo XL, a high roofed, long wheelbase panel van model, with a one tonne payload, equipped with the 1.6 litre Multijet common rail diesel. The XL, which can carry as much as the bigger and more expensive Scudo, was presented in the United Kingdom in May 2013.\n\nIn other markets the XL appeared in 2012, and it is available with all diesel engines excepting the 1.3, and also the 1.4 T-Jet. There is also an XL Combi, with a version of the 2.0 diesel.\n\nIn February 2010, Tofaş have revealed their development activities on the All-Electric version of their Doblò 2010.\n\nThe vehicle itself was also introduced to press in July 2010, as \"The First Commercial Electrical Vehicle Developed in Turkey\". It has been also revealed that, Tofaş will be FIAT's development pole for electric light commercial vehicles (LCV). In the one millionth ceremony of the Doblo, the Doblo EV was tested by press and Turkish Minister of Industry and Commerce, Nihat Ergün.\n\nIntroduced at the Hanover Motor Show, the 2015 Fiat Doblò receives a revised front end with new headlamps, grille, and front bumper to coincide with the release of the Ram ProMaster City.\nThe Ram ProMaster City (Type 636) is an Americanised version of the Fiat Doblò introduced in the model year of 2015, to succeed the Dodge Caravan based C/V Tradesman. The ProMaster City is built in the same plant in Turkey as the Doblò but is imported to North America. \n\nTo circumvent the chicken tax, only passenger vans are imported into North America, with cargo vans being post import conversions.\n\nUnlike the Doblò, passenger versions of the ProMaster City use solid metal panels instead of glass in its rear quarters, and third row seating and the lift tailgate options are not offered. The 2.4 litre Tigershark engine mated to the 948TE nine speed automatic transmission is the only power train available for the ProMaster City. \n\n Only for Ram ProMaster City\n\n"}
{"id": "2304203", "url": "https://en.wikipedia.org/wiki?curid=2304203", "title": "Filter capacitor", "text": "Filter capacitor\n\nFilter capacitors are capacitors used for filtering of undesirable frequencies. They are common in electrical and electronic equipment, and cover a number of applications, such as:\n\nFilter capacitors are not the same as reservoir capacitors, the tasks the two perform are different, albeit related.\n\nMany filtering tasks have specific types of capacitor that are required or typically used for the task.\n\nElectrolytic capacitors are usually used due to high capacity at low cost and low size. Smaller non-electrolytics may be paralleled with these to compensate for electrolytics' poor performance at high frequencies.\n\nCeramic plate capacitors are usually favoured due to extremely low inductance and low cost. Where precision is needed, silver mica capacitors offer superior precision and stability. Where manual tunability is required, plastic film trimmers are sometimes used, though it has long been more popular to adjust the inductor to achieve tuning.\n\nDisc and plate ceramic capacitors are used due to particularly low inductance. Often a ceramic disc sits in a notch cut in the PCB, with the tracks soldered directly to the disc for best performance.\n\nAt microwave frequencies, the (FR4) Printed circuit board (PCB) material acts as a capacitor, and the PCB track has inherent inductance. The net result depends on the ratio of capacitance and inductance present.\n\nIncreasing PCB track width causes additional capacitance, and thus a net capacitance. Narrowing track width reduces capacitance, produces a net inductance.\n\nComputers use large numbers of filter capacitors, making size an important factor. Solid tantalum and wet tantalum capacitors offer some of the best CV (capacitance/voltage) performance in some of the most volumetrically efficient packaging available. High currents and low voltages also make low equivalent series resistance (ESR) important. Solid tantalum capacitors offer low ESR versions that can often meet ESR requirements but they are not the lowest ESR option among all capacitors. Solid tantalums have an additional issue which must be addressed during the design stage. Solid tantalum capacitors must be voltage derated in all applications. A 50% voltage derating is recommended and generally accepted as the industry standard; e.g.: A 50V solid tantalum capacitor should never be exposed to an actual application voltage above 25V. Solid tantalum capacitors are very reliable components if the proper care is taken and all design guidelines are carefully followed. Unfortunately, the failure mechanism for a solid tantalum capacitor is a short which will result in a violent flaring up and smoking on a PCB capable of damaging other components in close proximity as well as completely destroying the capacitor. Fortunately, most solid tantalum capacitor failures will be immediate and very evident. Once in application solid tantalum capacitor performance will improve over time and the chances of a failure due to component mis-manufacturing decrease. Wet tantalums are a type of the electrolytic capacitor, using a tantalum pellet in an electrolytic material sealed in a hermetic package. This type of tantalum capacitor does not require the same derating that a solid tantalum does and its failure mechanism is open. A 10% to 20% voltage derating curve is recommended for wet tantalums when operating from 85C to 125C. Wet tantalums are not commonly referred to as just 'electrolytics' because usually 'electrolytic' refers to aluminium electrolytics.\n\nCeramic (for values <0.47 micro-farad-µF) and electrolytic (for 0.47 µF and up) are normally the preferred types where their performance is sufficient, since these are the lowest cost types of capacitors. Hence they are very popular in filters of many types.\n\nMains filter capacitors are usually encapsulated wound plastic film types, since these deliver high voltage rating at low cost, and may be made self healing and fusible.\nMains filter capacitors are often ceramic RFI/EMI suppression capacitors.\nThe additional safety requirements for mains filtering are:\n\nA wound plastic film mains rated capacitor plus series resistor are incorporated into a single component envelope for convenience and robustness. This reduces switch arcing and RFI. The most common combination of values is 0.1 µF + 100 Ω.\n\nCeramic disc capacitors are usually used in snubber circuits for low voltage motors for their low inductance and low cost.\n\nLow ESR (equivalent series resistance) electrolytics are often required to handle the high ripple current.\n"}
{"id": "15427832", "url": "https://en.wikipedia.org/wiki?curid=15427832", "title": "Firelog", "text": "Firelog\n\nA firelog is a manufactured log constructed to be used as wood fuel. Firelogs are designed to be inexpensive, while being easier to ignite, and burn longer, and more efficiently than firewood. Firelogs are traditionally manufactured using two methods. The first uses only compressed sawdust and the second uses sawdust and paraffin, which is mixed and extruded into a log shape. The extruded firelogs are individually wrapped in paper packaging which can be ignited to start burning the firelog as the paraffin is readily combustible.\n\nA new cleaner firelog has now been developed using waste fibre from the oil palm fruit bunches of South East Asia. Unlike sawdust logs these burn with zero sulfur emissions. Also unlike sawdust logs, no trees need to be felled to produce these firelogs. While it is beneficial that the oil palm derived logs use waste fibre, the overall impact of palm oil plantations is problematic because vast areas of virgin tropical rain forest in Borneo and Sumatra are being clear cut to open up land for palm plantations. This activity directly threatens habitats of endangered species such as the orangutan.\n\nOther new types of firelogs include one made from waste wax-cardboard such as that used in the packing of perishable foods for shipment, which is used to create a compressed cardboard firelog, and another made from renewable Greek cotton plants, offering a high energy content.\n\nThe materials used for a traditional firelog are variable, the sawdust used is often commercial wood waste from manufacturers, or waste agricultural biomass (nut shells, fruit pits, etc.); additionally bio-wax may be used in lieu of paraffin (petroleum-based wax).\n\nThere are now a number of wood and wax firelogs made using renewable materials. These are made using plant or animal based renewable waxes such as palm oil. These logs can be considered to be carbon neutral firelogs during combustion as the carbon released on combustion is the same carbon absorbed when the plants are growing.\nSulphur emissions are virtually eliminated with renewable firelogs as they do not contain paraffin waxes.\n\n\n"}
{"id": "12762147", "url": "https://en.wikipedia.org/wiki?curid=12762147", "title": "GAMA Enerji", "text": "GAMA Enerji\n\nGAMA Enerji A.Ş. is a Turkish company founded in 2002 that engages in building, financing and investing in energy and water utility infrastructure. While project development, construction and operation of power plants are its main focuses, power generation and trading are also a part of its activities.\n\nThe total power generation capacity of the GAMA Enerji is 1,715.80 MW including two CCGT power plants in Galway, Ireland and Kirikkale, Turkey. GAMA Enerji also owns Disi Mudawara, the Amman water conveyance project by the Ministry of Water of Jordan. Despite the headquarters is located in Ankara, the company is active in energy trading business with its affiliate \"GATES Enerji\" established in Istanbul.\n\nGeneral Electric Energy Financial Services (GE EFS) acquired 50% of the shares of GAMA Enerji in 2007 and held its position as a shareholder until 2015. In 2015 International Finance Corporation (IFC), a member of the World Bank Group, and a fund managed by IFC acquired 27% of shares of the company. In late 2015, Malaysia's state electricity utility, Tenaga Nasional (TNB) has bought a 30 percent stake in GAMA Enerji.\n"}
{"id": "26484783", "url": "https://en.wikipedia.org/wiki?curid=26484783", "title": "George Kerevan", "text": "George Kerevan\n\nGeorge Kerevan (born 28 September 1949) is a Scottish journalist, economist, and Scottish National Party politician. He was the Member of Parliament (MP) for East Lothian from 2015, until he lost his seat at the snap 2017 general election.\n\nBorn in Glasgow, Kerevan was educated at Kingsridge Secondary School in Knightswood and the University of Glasgow, graduating with a First-class MA degree in political economy.\n\nKerevan held academic posts at Napier College, including Senior Lecturer in Economics, from 1975–2000, specialising in energy economics. He was associate editor of \"The Scotsman\" from 2000 to 2009, and was the chief executive of What If Productions (Television) Ltd. He is co-organiser of the Prestwick World Festival of Flight.\n\nKerevan was a member of the International Marxist Group, a Trotskyist group, between 1972-77. He later served as a Labour councillor in Edinburgh from 1984–1996. In 1996, he left Labour to join the Scottish National Party. He went on to stand unsuccessfully as the SNP candidate for Edinburgh East at the 2010 UK general election, as well as an SNP candidate in the Lothian region in the 2011 Scottish Parliament election.\n\nKerevan eventually stood successfully as the SNP candidate for East Lothian at the 2015 UK general election. He won 25,104 votes, a majority of 6,803, and unseated the then-incumbent Labour MP Fiona O'Donnell. He was a member of the House of Commons Treasury Select Committee. He subsequently lost his seat in the 2017 snap election to Martin Whitfield of the Labour Party, who won with a majority of 3,083 votes over Kerevan.\n\nHe is the co-author, with Alan Cochrane, of \"Scottish Independence: Yes or No\", published in April 2014.\n\n"}
{"id": "576456", "url": "https://en.wikipedia.org/wiki?curid=576456", "title": "Great Blizzard of 1888", "text": "Great Blizzard of 1888\n\nThe Great Blizzard of 1888 or Great Blizzard of '88 (March 11 – March 14, 1888) was one of the most severe recorded blizzards in the history of the United States of America. The storm, referred to as the Great White Hurricane, paralyzed the East Coast from the Chesapeake Bay to Maine, as well as the Atlantic provinces of Canada. Snowfalls of fell in parts of New Jersey, New York, Massachusetts, Rhode Island, and Connecticut, and sustained winds of more than produced snowdrifts in excess of . Railroads were shut down, and people were confined to their houses for up to a week. Railway and telegraph lines were disabled, and this provided the impetus to move these pieces of infrastructure underground. Emergency services were also affected.\n\nThe weather preceding the blizzard was unseasonably mild with heavy rains that turned to snow as temperatures dropped rapidly.\nThe storm began in earnest shortly after midnight on March 12 and continued unabated for a full day and a half. The National Weather Service estimated this Nor'easter dumped as much as of snow in parts of Connecticut and Massachusetts, while parts of New Jersey and New York had up to . Most of northern Vermont received from to in this storm.\n\nDrifts were reported to average , over the tops of houses from New York to New England, with reports of drifts covering three-story houses. The highest drift () was recorded in Gravesend, New York. It was reported that of snow fell in Saratoga Springs, New York; in Albany, New York; of snow in New Haven, Connecticut; and of snow in New York City. The storm also produced severe winds; wind gusts were reported, although the highest official report in New York City was , with a gust reported at Block Island. New York's Central Park Observatory reported a minimum temperature of , and a daytime average of on March 13, the coldest ever for March.\n\nIn New York, neither rail nor road transport was possible anywhere for days, and drifts across the New York–New Haven rail line at Westport, Connecticut, took eight days to clear. Transportation gridlock as a result of the storm was partially responsible for the creation of the first underground subway system in the United States, which opened nine years later in Boston. The New York Stock Exchange was closed for two days.\n\nSimilarly, telegraph infrastructure was disabled, isolating Montreal and most of the large northeastern U.S. cities from Washington, D.C. to Boston for days. Following the storm, New York began placing its telegraph and telephone infrastructure underground to prevent their destruction.\n\nFire stations were immobilized, and property loss from fire alone was estimated at $25 million (equivalent to $ million in ).\nThe blizzard resulted in the founding of the Christman Bird and Wildlife Sanctuary located near Delanson, New York.\n\nFrom Chesapeake Bay through the New England area, more than 200 ships were either grounded or wrecked, resulting in the deaths of at least 100 seamen. More than 400 people died from the storm and the ensuing cold, including 200 in New York City alone. Efforts were made to push the snow into the Atlantic Ocean. Severe flooding occurred after the storm due to melting snow, especially in the Brooklyn area, which was susceptible to flooding because of its topography.\n\nNot all areas were notably affected by the Blizzard of 1888; an article in the \"Cambridge Press\" published five days after the storm noted that the \"fall of snow in this vicinity was comparatively small, and had it not been accompanied by a strong wind it would have been regarded as rather trifling in amount, the total depth, on a level, not exceeding ten inches\".\n\nRoscoe Conkling, an influential Republican politician, died as a result of the storm.\n\nEdward Rutherfurd's 2009 novel \"New York\" has a dramatic section set during the blizzard.\n\nRichard Peck (writer)'s 1989 novel \"Voices After Midnight\", in which three California teenagers living in an old New York townhouse find themselves continually slipping back in time, also depicts the events of the blizzard dramatically during its climax.\n\nRosemary Simpson's novel \"What the Dead Leave Behind\" has also been set at this time. John R. Maxim's novel, \"Time Out of Mind\" (1986) has flashbacks to this period and describes effects of the storm.\n\n\"BLIZZARD! The Storm That Changed America\" is a 2000 Children's history book by Jim Murphy.\n\nIn the \"Doctor Who\" Big Finish Productions audio adventure \": The Great White Hurricane\", the TARDIS arrives in New York the day before the Great Blizzard, resulting in the First Doctor and Susan Foreman becoming caught up in a local gang conflict that ends with Susan and one of the gang trapped on the frozen Hudson river, while Ian Chesterton and Barbara Wright help an abused wife find and rescue her son from his alcoholic father, ending in a desperate rescue attempt when the father and son are part of a group of passengers trapped on a train that was crossing a bridge before snow forced it to stop.\n\n\n"}
{"id": "6512221", "url": "https://en.wikipedia.org/wiki?curid=6512221", "title": "Guimaras oil spill", "text": "Guimaras oil spill\n\nThe Guimaras oil spill occurred in the Panay Gulf on August 11, 2006 when the oil tanker M/T \"Solar 1\" sank off the coast of Guimaras and Negros islands in the Philippines, causing what is considered as the worst oil spill in the country.\n\nThe oil tanker M/T \"Solar 1\", carrying more than two million liters of bunker fuel, sank during a violent storm approximately off the southern coast of Guimaras at around\nmidnight on August 11, 2006, causing some of oil to pour into the gulf, that traveled up through the Guimaras Strait and Iloilo Strait. Siphoning the remaining 1.5 million liters from the sunken tanker, at a depth of more than , was scheduled for March 2007.\n\nThe oil spill adversely affected marine sanctuaries and mangrove reserves in three out of five municipalities in Guimaras Island and reached the shores of Iloilo and Negros Occidental. The oil spill occurred in the Guimaras Strait that connects the Visayan Sea with the Sulu Sea, and is considered a rich fishing ground that supplies most of the demand for the entire country. (NDCC, August 2006)\n\nHaribon sent two biologists to Guimaras to assess the damage and talk to the affected communities regarding their immediate needs. Haribon provided assistance particularly for the long-term rehabilitation of the area. The government evacuated the affected families who had been exposed to the toxic elements of the crude oil. According to reports gathered in the field, people contracted skin diseases associated with these elements.\n\nSeveral causes have been cited, including bad weather and human error. Allegations have been made stating that the tanker only had a capacity of 1.2 million liters, implying the possibility of overloading. Other investigations have claimed that the ship's Captain was not qualified to sail the vessel.\n\nThe spill damaged Taklong Island National Marine Reserve, a marine sanctuary for feeding and breeding ground for fish and other species. The oil slick also posed a threat to the blue crab industry in the municipality of Enrique B. Magalona in Negros Occidental.\n\nDr. Jose Ingles, eco-region coordinator of the World Wide Fund for Nature in the Philippines, Indonesia and Malaysia, said that the damage may be felt by at least two generations. He warned that the disaster may have damaged the reefs and mangroves, scarring the ecosystem and causing seafood yields to significantly decrease. According to him, the worst hit would be the shorelines, the coasts and the swamplands with mangroves. This will greatly impact the livelihood of the fishermen, mostly living in poor conditions.\n\nIn the south-southeast of the spill site is located the Sulu Sea, a deep-water area frequented by commercially valued fish such as blue marlin and the yellowfin tuna, prized by the towns of southern Negros Occidental province as an important source of income for the communities. The oil slick may damage this thriving local industry.\n\nOn August 22, 2006, the Philippine Coast Guard stated that the spill has affected 20 communities in 4 municipalities in Guimaras. It also threatened 27 communities in Iloilo province and 17 others in Negros Occidental.\n\nA villager from Barangay Lapaz, Nueva Valencia, Guimaras, became the first casualty directly affected by the spill. He died after inhaling the fumes of the oil sludge caused him to contract cardio-respiratory disease. Two sailors from the ship were also reported missing.\n\nDue to the extent of the disaster, the cleanup was expected to reach three years.\n\nOn August 19, the Philippine government has asked the governments of Indonesia, Japan and the United States to help assist with the cleanup.\n\nPresident Gloria Macapagal-Arroyo created Task Force Guimaras on August 22 in order to oversee both the cleanup of the oil spill and the retrieval of the 1.5 million liters of fuel oil still remaining inside the tanker. The government also ordered the creation of the Special Board of Marine Inquiry to determine who and what caused the spill.\n\nGuimaras Governor JC Rahman Nava has objected to the proposal of disposing the oil wastes within the province.\n\nClemente Cancio, President of Sunshine Maritime Development Corporation (SMDC), the company which owns M/T Solar I, said that their foreign insurer is willing to pay the cost of damage brought about by the oil spill.\n\nPresident Gloria Arroyo ordered a full investigation into the country's worst oil spill that devastated marine ecosystems in the central Philippines. Arroyo also ordered the Justice Department to join a special task force heading an investigation and cleanup on the island of Guimaras, where some of coastline, including stretches of pristine beaches, had been affected by the oil slick from the sunken tanker. \"We shall do everything in our power to right the wrongs caused by this unfortunate incident,\" Arroyo said after visiting the island, adding that she was deeply pained by the disaster that she declared a \"national calamity\".\n\nOn August 17, British oil experts, sent by SMDC's foreign insurer, arrived in Guimaras to assess the situation. SMDC stated that the experts will check the extent of the oil pollution. The Britons conducted an aerial survey over Guimaras Island and made recommendations based on their findings.\n\nA four-man team from the U.S. Coast Guard arrived on August 23 to assist in determining the exact location of the tanker.\n"}
{"id": "10833408", "url": "https://en.wikipedia.org/wiki?curid=10833408", "title": "Helium hydride ion", "text": "Helium hydride ion\n\nThe hydrohelium(1+) cation, HeH, also known as the helium hydride ion or helium-hydride molecular ion, is a positively charged ion formed by the reaction of a proton with a helium atom in the gas phase, first produced in the laboratory in 1925. It is isoelectronic with molecular hydrogen. It is the strongest known acid, with a proton affinity of 177.8 kJ/mol. It has been suggested that HeH should occur naturally in the interstellar medium, but it has not yet been detected. It is the simplest heteronuclear ion, and is comparable with the hydrogen molecular ion, . Unlike , however, it has a permanent dipole moment, which makes its spectroscopic characterization easier. The calculated dipole moment of HeH is 2.26 or 2.84.\n\nHHe cannot be prepared in a condensed phase, as it would protonate any anion, molecule or atom with which it were associated. However it is possible to estimate a \"hypothetical\" aqueous acidity using Hess's law:\n\nA free energy change of dissociation of −360 kJ/mol is equivalent to a p\"K\" of −63.\n\nThe length of the covalent bond in HeH is 0.772 Å.\n\nOther helium hydride ions are known or have been studied theoretically. , which has been observed using microwave spectroscopy, has a calculated binding energy of 25.1 kJ/mol, while has a calculated binding energy of 0.42 kJ/mol.\n\nThe dihelium hydride cation is formed by the reaction of dihelium cation with molecular hydrogen:\nHeH is a linear ion with hydrogen in the centre.\n\nThe helium hydride cation reacts with most substances. It has been shown to add a proton to O, NH, SO, HO, and CO, giving OH, , , HO, and . Other molecules such as nitric oxide, nitrogen dioxide, nitrous oxide, hydrogen sulfide, methane, acetylene, ethylene, ethane, methanol and acetonitrile react but break up due to the large amount of energy produced. One technique used to study reactions between organic substances and HeH is to make a tritium derivative of the organic compound. Decay of tritium to He followed by its extraction of a hydrogen atom yields HeH which is then surrounded by the organic material and will in turn react.\n\nExtra helium atoms can attach to HeH to form larger clusters such as HeH, HeH, HeH, HeH and HeH which is particularly stable.\n\nThe helium hydride ion is formed during the decay of tritium in the molecule HT or tritium molecule T. Although excited by the recoil from the beta decay, the molecule remains bound together.\n\nHeH is thought to exist in the interstellar medium, although it has not yet been unambiguously detected. It is believed to be the first compound to have formed in the universe, and is of fundamental importance in understanding the chemistry of the early universe. This is because hydrogen and helium were almost the only types of atoms formed in Big Bang nucleosynthesis. Stars formed from the primordial material should contain HeH, which could influence their formation and subsequent evolution. In particular, its strong dipole moment makes it relevant to the opacity of zero-metallicity stars. HeH is also thought to be an important constituent of the atmospheres of helium-rich white dwarfs, where it increases the opacity of the gas and causes the star to cool more slowly.\n\nSeveral locations have been suggested as possible places HeH might be detected. These include cool helium stars, H II regions, and dense planetary nebulae (in particular NGC 7027). Detecting HeH spectroscopically is complicated by the fact that one of its most prominent spectral lines, at 149.14 μm, coincides with a doublet of spectral lines belonging to the methylidyne radical ⫶CH.\n\nHeH could be formed in the cooling gas behind dissociative shocks in dense interstellar clouds, such as the shocks caused by stellar winds, supernovae and outflowing material from young stars. If the speed of the shock is greater than about 90 km/s, quantities large enough to detect might be formed. If detected, the emissions from HeH would then be useful tracers of the shock.\n\nUnlike the helium hydride ion, the neutral helium hydride \"molecule\" is not stable in the ground state. However, it does exist in an excited state as an excimer, and its spectrum was first observed in the mid 1980s.\n\nUnless otherwise stated, numerical data are taken from Weast, R. C. (Ed.) (1981). \"CRC Handbook of Chemistry and Physics\" (62nd Edn.). Boca Raton, FL: CRC Press. .\n\nJ. Chem. Phys. 41, 1646 (1964)\n"}
{"id": "4125182", "url": "https://en.wikipedia.org/wiki?curid=4125182", "title": "Hibiscus acetosella", "text": "Hibiscus acetosella\n\nHibiscus acetosella, the cranberry hibiscus or African rosemallow, is an flowering plant of the genus \"Hibiscus\" or rosemallow. The word \"acetosella\" is of Latin origin and is derived from an old name for sorrel (Oxalis) which comes from the sour taste experienced when eating the young leaves of the plant. \"Hibiscus acetosella\" is also known colloquially as false roselle, maroon mallow, red leaved hibiscus, and red shield hibiscus. It is one of the approximately 200–300 species that are seen in sub-tropic and tropic regions. This ornamental is usually found in abandoned fields or open areas, marshes, and forest clearings. Cranberry hibiscus is a member of a perennial group known as hardy hibiscus. In contrast to the tropical hibiscus, hardy hibiscus can tolerate colder conditions, are more vigorous, longer lasting, and have larger flowers. In colder climates, \"Hibiscus acetosella\" is easily an annual, but is often regarded as a perennial to zone 8–11. During one season, the plant can grow tall and wide as a shrub-subshrub.\n\nThe foliage of cranberry hibiscus is similar to that of the Japanese maple. It has dicot leaves which vary in shape from 3-5-lobed to un-lobed or undivided in the upper leaves of the plant and are generally the size of a small child's hand, about 10×10 cm. They tend to be alternate, simple, and deeply cut with crenate or jagged edges. Leaf color is observed as a dark maroon to a patchy red/green appearance. Stipules are linear, measured approximately 1.5 cm in length. Both stems and petioles (3–11 cm in length) are smooth or generally free from hair. Acetosella is further divided into a section called Furcaria, which is a group of approximately 100 species that have non-fleshy calyx or sepals. The sepals contain 10 veins, 5 of which run to the apices of the segments; the other 5 run to the sinuses. Stems tend to be variegated. Flowers are solitary and sit atop a 1 cm long pedicel. They vary in color and are most often the dark maroon that is characteristic of the foliage with darker vein-like markings. Flowers are rarely yellow in color and are about 5 cm {2 inches} deep. Each flower contains numerous stamens at about 2 cm in length. The cranberry hibiscus is bisexual and is thought to be self-pollinating. It produces seeds that are reniform and dark brown with dimensions of 3×2.5 mm.\n\n\"Hibiscus acetosella\" is an allotetraploid [2n = 4x = 72] with a genome composition of AABB. It is often used to transfer genetic resistance to root-knot nematodes with compatible Hibiscus species. Cranberry hibiscus is often grown after tomatoes and potatoes and related species of which are not resistant to nematodes\n\n\"Hibiscus acetosella\" is thought to have come about via hybridization between \"Hibiscus asper Hook.f.\" and \"Hibiscus surattensis L.\" secondary to their cultivation. It was first recognized in 1896 by French botanists as a distinct plant and given the name it currently has. The plant was probably first found growing around African villages in the southern DR Congo-Angola-Zambia region. The crop was brought to Brazil and South-East Asia where it was most likely used as sustenance for slaves. It is now considered more popular in Brazil than its original location in Africa, where it is now regularly cultivated and eaten as a spinach-like green.\n\nCranberry hibiscus is cultivated in medium altitudes in areas of high rainfall although it does do fairly well in droughts. It requires moist soil with good drainage and a range of partial shade to full sun exposure. The plant does well in slightly acidic conditions with a soil pH between 6.1 and 6.5. Cranberry hibiscus tends to flower late in season when days are shorter. Flowers open for a few hours during the late fall to early winter at midday. Although the plant itself remains in bloom for a few weeks, once open, a flower remains so for just one day. Plants typically succumb to cold weather in the Midwest prior to flowers appearing\n\nSeeds germinate easily within 3–4 days in a container but tend to grow rapidly. Light is not required for germination. Cranberry hibiscus propagates well with cuttings, which will take root in soil or water. The plant can be maintained in an oval form by pinching or cutting it back during the summer. Otherwise, it will have one dominant stem.\n\nCranberry hibiscus is mostly known for its slightly sour or pleasantly tart young leaves which are commonly used as a vegetable, either raw or cooked. In South America, the leaves are used sparingly in salads and stir-fries. Leaves are eaten in small quantities due to acid content and because they are mucilaginous. Cranberry hibiscus leaves also contribute to the décor of various dishes since they retain their color after being cooked.\nFlowers are used to make teas or other drinks where they contribute color rather than taste. In Central America the flowers are combined with ice, sugar, lemon, or lime juice and water to make a purple lemonade.\n\nThe root is edible however thought of as fibrous and distasteful. Contrary to similar species such as the \"Hibiscus sabdariffa\", the calyx or sepals of \"Hibiscus acetosella\" is non-fleshy and not eaten. In Angola a tea made from the leaves of cranberry hibiscus are used as a post-fever tonic and to treat anemia. The plant is also utilized to treat myalgias by crushing leaves into cold water to bathe children. The plant is thought to contain polyphenols, a compound that may combat inflammation and is commonly used to treat inflammatory diseases.\n"}
{"id": "28895751", "url": "https://en.wikipedia.org/wiki?curid=28895751", "title": "Home Energy Saver", "text": "Home Energy Saver\n\nHome Energy Saver is a set of on–line resources developed by the U.S. Department of Energy at the Lawrence Berkeley National Laboratory intended to help consumers and professional energy analysts, analyze, reduce, and manage home energy use.\n\nThe Home Energy Saver energy assessment tool allows consumers to conduct a do-it-yourself home energy audit and provides specific recommendations to help lower household energy consumption and utility costs. By entering a zip code, users get estimates for typical and efficient homes in their area. The estimates break down energy consumption by \"end use\". End uses reported by Home Energy Saver include: heating, cooling, water heating, major appliances, small appliances, and lighting.\n\nThe more details a user enters, (e.g., insulation levels, roofing, age of major equipment, how systems are used) the more customized the assessment results and energy efficiency recommendations become. The tailored reports allows consumers to drill into estimated cost of improvements, anticipated payback time, projected utility bill savings, and how much energy use and green house gas production will be reduced. Consumers can vary the energy efficiency assumptions and the upgrade costs, (e.g., replacing the default values with actual estimates from contractors) and recalculate the payback times and other details.\n\nThe Home Energy Saver website includes a section called LEARN which offers tips about energy savings, an explanation of the house-as-system energy efficiency approach, and other information to help people understand how energy is used in a home.\n\nWhen launched in 1994, Home Energy Saver was the first and only online home energy calculator. Thereafter, 6 million people have used it to analyze their home energy use. Nearly 1 million people visit the site each year. In 2009, a second version of the tool, Home Energy Saver Professional, was launched. This advanced version provides a low cost, interactive energy simulation/assessments tool for contractors, building professionals, weatherization professionals, and building designers.\n\nThe Home Energy Saver is built on DOE-2, a computer program for building heating and cooling energy analysis and design. DOE-2 performs a thermal load simulation that accounts for heating and cooling equipment and thermal distribution efficiencies, infiltration, and thermostat management. User-entered zip codes are mapped to one of about 300 unique \"weather tapes\" that impose a year's worth of local weather conditions on the home to determine heating and cooling needs.\n\nHome Energy Saver extends DOE-2 in a number of ways to improve the simulation model. For example, when users enter their actual electricity tariffs, the predictive power of the model improves. Other methods are used to calculate the energy used by appliances, water heating, and lighting.\n\nThe public domain HES calculation methods and underlying data are clearly documented on the website. Other web-based tool developers are welcome to use this information at no cost, providing that the source is properly credited.\n\nThe Home Energy Saver enables users to quantify the benefits of improving the energy efficiency and comfort of homes in the following ways:\n\n\nThe energy improvement recommendations are drawn from the National Residential Energy Efficiency Measures Database.\n\nEach year, the R&D 100 Awards recognize the year's 100 most significant, innovative, newly introduced research and development advances. The awards are recognized in industry, government, and academia as proof that a product is one of the most innovative ideas of the year, nationally and internationally. Home Energy Saver and Hohm received an R&D 100 Award in 2010.\n\nHome Energy Saver received the U.S. Department of Energy's \"Energy 100\" award as one of the best 100 scientific and technological accomplishments over DOE's 23-year lifetime. The discoveries were chosen based on their impact in saving consumers money and improving quality of life.\n\nPC Magazine recognized Home Energy Saver in 2004 as one of the \"Top 100 Undiscovered Websites.\n\nMSN-Money rates Home Energy Saver among the \"Best Sites for Free Government Help\" including it in the list of \"The 100 most Useful Sites on the Internet.\n\nOrganizations who want to provide their customers tools to predict home energy consumption can license the Home Energy Saver Application Programming Interfaces (APIs).\n\nMicrosoft, the first organization to license the Home Energy Saver, uses it to drive Microsoft Hohm.\n\n"}
{"id": "14425296", "url": "https://en.wikipedia.org/wiki?curid=14425296", "title": "Hume-Rothery rules", "text": "Hume-Rothery rules\n\nThe Hume-Rothery rules, named after William Hume-Rothery, are a set of basic rules that describe the conditions under which an element could dissolve in a metal, forming a solid solution. There are two sets of rules; one refers to substitutional solid solutions, and the other refers to interstitial solid solutions.\n\nFor substitutional solid solutions, the Hume-Rothery rules are as follows:\n\n\nFor interstitial solid solutions, the Hume-Rothery rules are:\n\n"}
{"id": "12247158", "url": "https://en.wikipedia.org/wiki?curid=12247158", "title": "Hybrid models of forest production", "text": "Hybrid models of forest production\n\nHybrid models of forest production, sometimes abbreviated to \"hybrid models\", combine growth and yield modelling with physiological modelling.\n\n\n\n"}
{"id": "22713707", "url": "https://en.wikipedia.org/wiki?curid=22713707", "title": "Integrated Operations in the High North", "text": "Integrated Operations in the High North\n\nIntegrated Operations in the High North (IOHN, IO High North or IO in the High North) is a unique collaboration project that during a four-year period starting May 2008 is working on designing, implementing and testing a Digital Platform for what in the Upstream Oil and Gas Industry is called the next or second generation of Integrated Operations. \nThe work on the Digital platform is focussed on capture, transfer and integration of Real-time data from the remote production installations to the decision makers. A risk evaluation across the whole chain is also included. The platform is based on open standards and enables a higher degree of interoperability. Requirements for the digital platform come from use cases defined within the Drilling and Completion, Reservoir and Production and Operations and Maintenance domains. The platform will subsequently be demonstrated through pilots within these three domains. \n\nThis new platform is considered an important enabler for safe and sustainable operations in remote, vulnerable and hazardous areas such as the High North, but the technology is clearly also applicable in more general applications.\n\nThe IOHN project consortium consists of 23 participants, including operators, service providers, software vendors, technology providers, research institutions and universities. In addition, the Norwegian Defence Force is working with the project to resolve common infrastructural and interoperability challenges.\n\nThe project is managed by Det Norske Veritas (DNV). Nils Sandsmark was the project manager during the initiation and start-up phase. Frédéric Verhelst took over as project manager from the beginning of 2009.\n\nFinancing comes from the participants and the Research Council of Norway (RCN) for parts of the project (GOICT\nand AutoConRig).\n\nThe consortium consists of the following 22 participants (in alphabetical order):\n\n"}
{"id": "18727727", "url": "https://en.wikipedia.org/wiki?curid=18727727", "title": "Kim Bồng woodworking village", "text": "Kim Bồng woodworking village\n\nKim Bồng woodworking village () is a village located in Cẩm Kim commune, Hội An, Quảng Nam Province, most notable for its carpentry (including cabinet making and shipbuilding) and traditional woodworking products. Established in the 15th century, it reached its peak in the 18th century, during which time village craftsmen contributed their skills in woodworking to many different projects, including the Imperial capital in Huế. Using their shipbuilding skills, they supplied ships and \"ghe bầu\" (large boats used for sailing) for the activities of the busy commercial port of Hội An.\n\nTo deal with a marked decline of interest in the woodworking profession during the 20th century, the village successfully offered training and other incentives to young apprentices, resulting in an increase to over 200 woodworkers and 18 different woodcarving companies as of 2008. Additionally, a successful community-based tourism project in Kim Bồng has allowed greater tourism revenue for the village; the venture's success has been suggested as a pattern for future sustainable tourism projects throughout Southeast Asia.\n\nThe village's name comes from the Vietnamese \"kim\" (yellow) and \"bồng\" (floating), supposedly after the jackfruit wood that sometimes floats on the Thu Bồn River.\n\nKim Bồng was settled in the 15th century, supposedly by four soldiers from the army of Emperor Lê Lợi, who founded the Later Lê Dynasty. According to traditional stories, these four soldiers were adept at woodworking, and went on to establish the village's four most notable craft families (Huynh, Nguyen, Phan, and Truong), many of whose members carry on that trade to the present day. As the neighbouring town of Hội An developed during the late 16th and early 17th centuries, Kim Bồng's carpenters and woodworkers became more widely known; in the 17th century, local carpenters were supposedly commissioned to build a warship for the Spanish navy. Craftsmen from Kim Bồng also produced most of the detail work on the buildings of the former Imperial capital in Huế, and, more recently, on Vietnamese revolutionary leader Ho Chi Minh's tomb.\n\nIn the present day, Kim Bồng craftsmen are often involved in restoration projects. For example, since the old town of Hội An was designated a UNESCO World Heritage Site in 1999, many of the village's artisans have found work restoring historic buildings, some of which have remained otherwise untouched for hundreds of years. Local craftsmen have also worked on restoration projects in nearby Da Nang, and in Quảng Ninh Province.\n\nAs its popular appellation suggests, the economy of Kim Bồng has long been dominated by carpentry (including cabinetmaking and shipbuilding) and woodworking. Kim Bồng woodwork is featured on unique columns, rafters and furniture found throughout the greater Hội An area and Quảng Nam Province; local craftsmen have also been employed in many high-profile projects in Vietnam, including detail work on the buildings of the former Imperial capital in Huế, and on Vietnamese revolutionary leader Ho Chi Minh's tomb.\n\nIn more recent years, woodworking as a profession fell out of favour with young people, mainly due to poor returns: the average income of a woodworker in Kim Bồng is about VND 1.5 million (US$85) per month. By the 1990s, few master carvers remained in the village. To help promote the profession, Cẩm Kim commune created a program allowing young people to receive free training in carpentry and woodworking, along with providing a monthly stipend of VND 150,000 ($8) and tools of the trade. Training courses are provided by master carver Huynh Ri, whose family includes 12 generations of woodcarvers. Several other local woodworking studios also provide on-the-job training to apprentice woodcarvers. These training programs have resulted in an increase in skilled woodworkers: the village numbered over 200 workers and 18 different woodcarving companies as of 2008. These results were lauded by UNESCO as \"keeping the traditional skills and intangible heritage of the town of Hoi An and its surrounding villages alive\".\n\nTourism is a more recent contributor to the local economy, beginning in 2002, when the Vietnam National Administration of Tourism (VNAT) led a community-based tourism project in Kim Bồng, together with UNESCO and the United Nations Conference on Trade and Development/World Trade Organization's Export-led Poverty Reduction Programme (EPRP). The village was selected as a promising location for the project because of its proximity to Hội An (already a major tourist destination), which provided an existing tourist base, and its existing craft sector. A dual pedestrian-bicycle trail was established to lead visitors through the village to see the local woodworking shops, where they are able to observe craftsmen working and purchase their products. Concurrent with the development of infrastructure, a tourism service cooperative was established, as well as a skills training program for members and a marketing program which resulted in market linkages with several major hotels and tour operators operating in Hội An. Local and provincial tourism authorities have also incorporated the village into festivals and promotional campaigns. The success of the venture has led it to be considered a model case on which future sustainable tourism projects throughout Southeast Asia can be patterned.\n\n\n"}
{"id": "38609354", "url": "https://en.wikipedia.org/wiki?curid=38609354", "title": "Komekurayama Solar Power Plant", "text": "Komekurayama Solar Power Plant\n\nThe Komekurayama Solar Power Plant (米倉山太陽光発電所) is a 10 megawatt (MW) solar photovoltaic power station located at Mt. Komekura. It is the third solar plant built by Tepco, and was completed on January 27, 2012. In the first year of operation, it produced 14,434 MWh, which was about 20% greater than anticipated.\n\n"}
{"id": "671039", "url": "https://en.wikipedia.org/wiki?curid=671039", "title": "Linoleum", "text": "Linoleum\n\nLinoleum, also called Lino, is a floor covering made from materials such as solidified linseed oil (linoxyn), pine rosin, ground cork dust, wood flour, and mineral fillers such as calcium carbonate, most commonly on a burlap or canvas backing. Pigments are often added to the materials to create the desired colour finish.\n\nThe finest linoleum floors, known as \"inlaid\", are extremely durable, and were made by joining and inlaying solid pieces of linoleum. Cheaper patterned linoleum came in different grades or gauges, and were printed with thinner layers which were more prone to wear and tear. High quality linoleum is flexible and thus can be used in buildings where a more rigid material (such as ceramic tile) would crack.\n\nLinoleum was invented by Englishman Frederick Walton. In 1855, Walton happened to notice the rubbery, flexible skin of solidified linseed oil (linoxyn) that had formed on a can of oil-based paint and thought that it might form a substitute for India rubber. Raw linseed oil oxidizes very slowly, but Walton accelerated the process by heating it with lead acetate and zinc sulfate. This made the oil form a resinous mass into which lengths of cheap cotton cloth were dipped until a thick coating formed. The coating was then scraped off and boiled with benzene or similar solvents to form a varnish. Walton initially planned to sell his varnish to the makers of water-repellent fabrics such as oilcloth, and patented the process in 1860. However, his method had problems: the cotton cloth soon fell apart, and it took months to produce enough of the linoxyn. Little interest was shown in Walton's varnish. In addition, his first factory burned down, and he suffered from persistent and painful rashes.\n\nWalton soon came up with an easier way to transfer the oil to the cotton sheets, by hanging them vertically and sprinkling the oil from above, and he tried mixing the linoxyn with sawdust and cork dust to make it less tacky. In 1863 he applied for a further patent, which read: \"For these purposes canvas or other suitable strong fabrics are coated over on their upper surfaces with a composition of oxidized oil, cork dust, and gum or resin ... such surfaces being afterward printed, embossed, or otherwise ornamented. The back or under surfaces of such fabrics are coated with a coating of such oxidized oils, or oxidized oils and gum or resin, and by preference without an admixture of cork.\"\n\nAt first Walton called his invention \"Kampticon\", which was deliberately close to Kamptulicon, the name of an existing floor covering, but he soon changed it to Linoleum, which he derived from the Latin words \"linum\" (flax) and \"oleum\" (oil). In 1864 he established the Linoleum Manufacturing Company Ltd., with a factory at Staines, near London. The new product did not prove immediately popular, mainly due to intense competition from the makers of Kamptulicon and oilcloth. The company operated at a loss for its first five years, until Walton began an intensive advertising campaign and opened two shops in London for the exclusive sale of Linoleum. Walton's friend Jerimiah Clarke designed the linoleum patterns, typically with a Grecian urn motif around the borders.\n\nOther inventors began their own experiments after Walton took out his patent, and in 1871 William Parnacott took out a patent for a method of producing linoxyn by blowing hot air into a tank of linseed oil for several hours, then cooling the material in trays. Unlike Walton's process, which took weeks, Parnacott's method took only a day or two, although the quality of the linoxyn was not as good. Despite this, many manufacturers opted to use the less expensive Parnacott process.\n\nWalton soon faced competition from other manufacturers, including a company which bought the rights to Parnacott’s process, and launched its own floor covering, which it named Corticine, from the Latin \"cortex\" (bark or rind). Corticine was mainly made of cork dust and linoxyn without a cloth backing, and became popular because it was cheaper than linoleum.\n\nBy 1869 Walton's factory in Staines, England was exporting to Europe and the United States. In 1877, the Scottish town of Kirkcaldy, in Fife, became the largest producer of linoleum in the world, with no fewer than six floorcloth manufacturers in the town, most notably Michael Nairn & Co., which had been producing floorcloth since 1847.\n\nWalton opened the American Linoleum Manufacturing Company in 1872 on Staten Island, in partnership with Joseph Wild, the company's town being named Linoleumville (renamed Travis in 1930). It was the first U.S. linoleum manufacturer, but was soon followed by the American Nairn Linoleum Company, established by Sir Michael Nairn in 1887 (later the Congoleum Nairn Company, and The Congoleum Corporation of America), in Kearny, New Jersey. Congoleum now manufactures sheet vinyl and no longer has a linoleum line. \n\nIn 2016 a Dutch flooring producer changed the old concept of a factory manufactured linoleum in rolls or tiles to a liquid poured version (liquid lino) of the linoleum which is applied seamlessly on site. By adding a hybrid extra vegetable based binder the liquid lino sets overnight. This hybrid bindersystem makes the liquid lino highly chemical resistant and permanently flexible. \n\nWalton was unhappy with Michael Nairn & Co's use of the name Linoleum and brought a lawsuit against them for trademark infringement. However, the term had not been trademarked, and he lost the suit, the court opining that even if the name \"had\" been registered as a trademark, it was by now so widely used that it had become generic, only 14 years after its invention. It is considered to be the first product name to become a generic term.\n\nBetween the time of its invention in 1860 and its being largely superseded by other hard floor coverings in the 1950s, linoleum was considered to be an excellent, inexpensive material for high-use areas. In the late nineteenth and early twentieth centuries, it was favoured in hallways and passages, and as a surround for carpet squares. However, most people associate linoleum with its common twentieth century use on kitchen floors. Its water resistance enabled easy maintenance of sanitary conditions and its resilience made standing easier and reduced breakage of dropped china.\n\nOther products devised by Walton included Linoleum Muralis in 1877, which became better known as Lincrusta. Essentially a highly durable linoleum wallcovering, Lincrusta could be manufactured to resemble carved plaster or wood, or even leather. It was very successful, and inspired a much cheaper imitation, Anaglypta, originally devised by one of Walton’s showroom managers.\n\nWalton also tried integrating designs into linoleum during the manufacturing stage, coming up with granite, marbled, and jaspé (striped) linoleum. For the granite variety, granules of various colours of linoleum cement were mixed together, before being hot-rolled. If the granules were not completely mixed before rolling, the result was marbled or jaspé patterns.\n\nWalton’s next product was inlaid linoleum, which resembled encaustic tiles, in 1882. Previously, linoleum had been produced in solid colours, with patterns printed on the surface if required. In inlaid linoleum, the colours extend all the way through to the backing cloth. Inlaid linoleum was made using a stencil type method where different-coloured granules were placed in shaped metal trays, after which the sheets were run through heated rollers to fuse them to the backing cloth. In 1898 Walton devised a process for making straight-line inlaid linoleum that allowed for crisp, sharp geometric designs. This involved strips of uncured linoleum being cut and pieced together patchwork-fashion before being hot-rolled. Embossed inlaid linoleum was not introduced until 1926.\n\nThe heavier gauges of linoleum are known as “battleship linoleum”, and are mainly used in high-traffic situations like offices and public buildings. It was originally manufactured to meet the specifications of the U.S. Navy for warship deck covering on enclosed decks instead of wood, hence the name. Most U.S. Navy warships removed their linoleum deck coverings following the attack on Pearl Harbor, as they were considered too flammable. (Use of linoleum persisted in U.S. Navy submarines.) Royal Navy warships used the similar product “Corticine”.\n\nEarly in the twentieth century, a group of Dresden artists adapted the printmaking techniques for woodcut prints to linoleum, thus creating the linocut printmaking technique. Prominent artists who created linocut prints included Picasso and Henri Matisse.\n\nLinoleum has largely been replaced as a floor covering by polyvinyl chloride (PVC), which is often colloquially but incorrectly called linoleum or lino. PVC has similar flexibility and durability to linoleum, but also has greater brightness and translucency, and is relatively less flammable. The fire-retardant properties of PVC are due to chlorine-containing combustion products, some of which are highly toxic. Dioxins are released by burning PVC. While the polymer itself is generally considered safe, additives such as plasticizers, and unintentional impurities such as free monomers, are considered a hazard by some: see the health and safety section of the main PVC article for more information and references.\n\n"}
{"id": "18205036", "url": "https://en.wikipedia.org/wiki?curid=18205036", "title": "Living in the Hothouse", "text": "Living in the Hothouse\n\nLiving in the Hothouse: How Global Warming Affects Australia is a 2005 book by Professor Ian Lowe which is a sequel to his \"Living in the Greenhouse\" (1989). The book presents a detailed analysis of climate change science and the likely impact of climate change in Australia. \"Living in the Hothouse\" also offers a critical overview of the Howard government's policy response to climate change in Australia. \n\nIan Lowe, AO, is a scientist, environmental policy analyst, and president of the Australian Conservation Foundation, who has served on many federal, state and local government committees. \n\nOther books by Ian Lowe include \"Reaction Time\" and \"A Big Fix\".\n"}
{"id": "5908793", "url": "https://en.wikipedia.org/wiki?curid=5908793", "title": "Load duration curve", "text": "Load duration curve\n\nA load duration curve illustrates the variation of a certain load in a downward form such that the greatest load is plotted in the left and the smallest one in the right. On the time axis, the time duration for which each certain load continues during the day is given.\n\nThere are some facts about the LDC that can be summarized as:\nA load duration curve (LDC) is used in electric power generation to illustrate the relationship between generating capacity requirements and capacity utilization.\n\nA LDC is similar to a load curve but the demand data is ordered in descending order of magnitude, rather than chronologically. The LDC curve shows the capacity utilization requirements for each increment of load. The height of each slice is a measure of capacity, and the width of each slice is a measure of the utilization rate or capacity factor. The product of the two is a measure of electrical energy (e.g. kilowatthours).\n\nA price duration curve shows the proportion of time for which the price exceeded a certain value.\n\nTogether, the price duration curve and load duration curve enable the analyst to understand the behaviour of the electricity market, for example, the likelihood of peaking power plant being required for service, and the impact that this might have on price.\n"}
{"id": "53006420", "url": "https://en.wikipedia.org/wiki?curid=53006420", "title": "M7 Japan", "text": "M7 Japan\n\nM7 Japan is a brand of auto parts and energy drinks. The lubricant brand is M7 Japan and it was founded in 2006. The brand has expanded its line of car and motorcycle engine oil to semi-synthetic and fully synthetic specifications. In 2011, M7 Japan started to develop their own energy drink and vitamin drink named Drive M7. The ingredients include carbonated water, vitamins from the vitamin B group, caffeine, taurine, and chlorophyll.\n\nSince its inception, M7 Japan and Drive M7 have been involved in motor racing competition such as GP 2 series (support race for Formula 1), drift racing, SuperGT, and MotoGP, including the Aspar Racing Team and the Moto3 racing team SIC Racing Team. Drive M7 has chosen former MotoGP World Champion, Nicky Hayden to be their world brand ambassador in 2014 and 2016 respectively.\n"}
{"id": "1614482", "url": "https://en.wikipedia.org/wiki?curid=1614482", "title": "Metropolitan-Vickers", "text": "Metropolitan-Vickers\n\nMetropolitan-Vickers, Metrovick, or Metrovicks, was a British heavy electrical engineering company of the early-to-mid 20th century formerly known as British Westinghouse. Highly diversified, they were particularly well known for their industrial electrical equipment such as generators, steam turbines, switchgear, transformers, electronics and railway traction equipment. Metrovick holds a place in history as the builders of the first commercial transistor computer, the Metrovick 950, and the first British axial-flow jet engine, the Metropolitan-Vickers F.2. Their factory in Trafford Park, Manchester, was for most of the 20th century one of the biggest and most important heavy engineering facilities in Britain and the world.\n\nMetrovick started as a way to separate the existing British Westinghouse Electrical and Manufacturing Company factories from United States control, which had proven to be a hindrance to gaining government contracts during the First World War. In 1917 a holding company was formed to try to find financing to buy the company's properties.\n\nIn May 1917, control of the holding company was obtained jointly by the Metropolitan Carriage, Wagon and Finance Company, of Birmingham, chaired by Dudley Docker, and Vickers Limited, of Barrow-in-Furness. On 15 March 1919, Docker agreed terms with Vickers, for Vickers to purchase all the shares of the Metropolitan Carriage, Wagon and Finance Company for almost thirteen million pounds. On 8 September 1919, Vickers changed the name of the British Westinghouse Electrical and Manufacturing Company to Metropolitan Vickers Electrical Company.\n\nThe immediate post-war era was marked by low investment and continued labour unrest. Fortunes changed in 1926 with the formation of the Central Electricity Board which standardized electrical supply and led to a massive expansion of electrical distribution, installations, and appliance purchases. Sales shot up, and 1927 marked the company's best year to date.\n\nOn 15 November 1922 the BBC was registered and the BBC's Manchester station, 2ZY, was officially opened on 375 metres transmitting from the Metropolitan Vickers Electricity works in Old Trafford.\n\nIn 1928 Metrovick merged with the rival British Thomson-Houston (BTH), a company of similar size and basically the same product lineup. Combined, they would be one of the few companies able to compete with Marconi or English Electric on an equal footing. In fact the merger was marked by poor communication and intense rivalry, and the two companies generally worked at cross purposes.\n\nThe next year the combined company was purchased by the Associated Electrical Industries (AEI) holding group, who also owned Edison Swan (Ediswan); and Ferguson, Pailin & Co, manufacturers of electrical switchgear in Openshaw, Manchester. The rivalry between Metrovick and BTH continued, and AEI was never able to exert effective control over the two competing subsidiary companies.\n\nProblems worsened in 1929 with the start of the great depression, but Metrovick's overseas sales were able to pick up some of the slack, notably a major railway electrification project in Brazil. By 1933 world trade was growing again, but growth was nearly upset when six Metrovick engineers were arrested and found guilty of espionage and \"wrecking\" in Moscow after a number of turbines built by the company in and for the Soviet Union proved to be faulty. The British government intervened; the engineers were released and trade with Russia was resumed after a brief embargo.\n\nDuring the 1930s Metropolitan Vickers produced two dozen very large diameter (3m/10 ft) three-phase AC traction motors for the Hungarian railway's V40 and V60 electric locomotives. The 1640 kW rated power machinery, designed by Kálmán Kandó, was paid for by British government economic aid.\n\nIn 1935 the company built a 105 MW steam turbogenerator, the largest in Europe at that time, for the Battersea Power Station.\n\nIn 1936 Metrovick started work with the Air Ministry on automatic pilot systems, eventually branching out to gunlaying systems and building radars the next year. In 1938 they reached an agreement with the Ministry to build a turboprop design developed at the Royal Aircraft Establishment (RAE) under the direction of Hayne Constant. It is somewhat ironic that BTH, their erstwhile partners, were at the same time working with Frank Whittle on his pioneering jet designs.\n\nIn mid-1938, MV's were given a contract to build Avro Manchester twin-engined heavy bombers under licence from A.V. Roe. As this type of work was very different from their traditional heavy engineering activities, a new factory was built on the western side of Mosley Road and this was completed in stages through 1940. There were significant problems producing this aircraft, not least being the unreliability of the Rolls-Royce Vulture engine and that the first 13 Manchesters were destroyed in a \"Luftwaffe\" bombing raid on Trafford Park on 23 December. Despite this the firm went on to complete 43 examples. With the design of the much improved four-engined derivative, the Avro Lancaster, MV switched production to that famous type, supplied with Rolls-Royce Merlin engines from the Ford Trafford Park shadow factory. Three hangars were erected on the southside of Manchester's Ringway Airport for assembly and testing of their Lancasters, before a policy switch was made to assembling them in a hangar at Avro's Woodford airfield. By the end of the war, MV's had built 1,080 Lancasters. These were followed by 79 Avro Lincoln derivatives before remaining orders were cancelled and MV's aircraft production ceased in December 1945.\n\nIn 1940 the turboprop effort was re-engineered as a pure jet engine after the successful run of Whittle's designs. The new design became the Metrovick F.2 and eventually flew in 1943 on a Gloster Meteor. Considered to be too complex to bother with, Metrovick then re-engineered the design once again to produce roughly double the power, while at the same time starting work on a much larger design, the Metrovick F.9 \"Sapphire\". Although the F.9 proved to be a winner, the Ministry of Supply nevertheless forced the company to sell the jet division to Armstrong Siddeley in 1947 to reduce the number of companies in the business.\n\nIn addition to building aircraft, other wartime work included the manufacture of both Dowty and Messier undercarriages, automatic pilot units, searchlights and radar equipment.\n\nThe post-war era led to massive demand for electrical systems, leading to additional rivalries between Metrovick and BTH as each attempted to one-up the other in delivering ever-larger turbogenerator contracts. Metrovick also expanded their appliance division during this time, becoming a well known supplier of refrigerators and stoves.\n\nThe design and manufacture of sophisticated scientific instruments, such as electron microscopes, and mass spectrometers, became an important area of scientific research for the company.\n\nIn 1947 a Metrovick G.1 Gatric gas turbine was fitted to the Motor Gun Boat \"MGB 2009\", making it the world's first gas turbine powered naval vessel. The Bluebird K7 jet-propelled 3-point hydroplane in which Donald Campbell broke the 200 mph water speed barrier was powered with a Metropolitan-Vickers Beryl jet engine producing 3,500 lbf (16 kN) of thrust. The K7 was unveiled in late 1954. Campbell succeeded on Ullswater on 23 July 1955, where he set a record of 202.15 mph (325.33 km/h), beating the previous record by some 24 mph (39 km/h) held by Stanley Sayres.\n\nAnother major area of expansion was in the diesel locomotive market, where they combined their own generators and traction motors, with third-party diesel engines to develop in 1950 the WAGR X class 2-Do-2 locomotive and in 1958 the type 2 Co-Bo, later re-classified under the TOPS system as the British Rail Class 28. This diesel-electric locomotive was unusual on two counts; its Co-Bo wheel arrangement and its Crossley 2-Stroke diesel engine (evolved from a World War II marine engine). Intended as part the British Railways Modernisation Plan, the twenty-strong fleet saw service between Scotland and England before being deemed unsuccessful and withdrawn towards the end of the 1960s. Metrovick also produced the CIE 001 Class (originally 'A' Class) from 1955, the first production mainline diesels in Ireland.\n\nMetropolitan Vickers also produced electrical equipment for the British Rail Class 76 (EM1), and British Rail Class 77 (EM2), 1.5 kV DC locomotives, built at Gorton Works for the electrification of the Woodhead Line in the early 1950s. Larger but broadly similar locomotives were also supplied to the NSWGR as their Class 46. The company also designed the British Rail Class 82, 25 kV AC locomotives built by Beyer Peacock in Manchester using Metrovick electrical equipment. The company also supplied electrical equipment for the British Rail Class 303 \"Blue Train\" electric multiple units.\n\nDuring the 1950s the company built a large power transformer works at Wythenshawe, near Manchester. The factory was opened in 1957 and later closed by GEC in 1971, after which it was sold to the American compressor manufacturer Ingersoll Rand.\n\nIn 1961, the Russian cosmonaut Yuri Gagarin was invited to the company's factory at Trafford Park as part of his tour of Manchester.\n\nThe rivalry between Metrovick and BTH was eventually ended in an unconvincing fashion when the AEI management eventually decided to rid themselves of both brands and be known as AEI universally, a change they made on 1 January 1960. This move was almost universally resented within both companies. Worse, the new brand name was utterly unknown to their customers, leading to a noticeable fall-off in sales and AEI's stock price.\n\nWhen AEI attempted to remove the doubled-up management structures, they found this task to be even more difficult. By the mid-1960s the company was struggling under the weight of two complete management hierarchies, and they appeared to be unable to control the company any more. This allowed AEI to be purchased by General Electricity Company in 1967, which was later restructured into many other companies, including Marconi plc in 1999, later Marconi Corporation plc, and others.\n\n\n\n"}
{"id": "54082774", "url": "https://en.wikipedia.org/wiki?curid=54082774", "title": "Ministry of Water Supply (Nepal)", "text": "Ministry of Water Supply (Nepal)\n\nMinistry of Water Supply (Nepal) is government body that is responsible to provide effective, sustainable and quality water supply and sanitation to the people of Nepal. \n\n\n"}
{"id": "55605352", "url": "https://en.wikipedia.org/wiki?curid=55605352", "title": "Nanowire lasers", "text": "Nanowire lasers\n\nSemiconductor nanowire lasers are nano-scaled lasers that can be embedded on chips and constitute an advance for computing and information processing applications. Nanowire lasers are coherent light sources (single mode optical waveguides) as any other laser device, with the advantage of operating at the nanoscale. Built by molecular beam epitaxy, nanowire lasers offer the possibility for direct integration on silicon, and the construction of optical interconnects and data communication at the chip scale. Nanowire lasers are built from III–V semiconductor heterostructures. Their unique 1D configuration and high refractive index allow for low optical loss and recirculation in the active nanowire core region. This enables subwavelength laser sizes of only a few hundred nanometers . Nanowires are Fabry–Perot resonator cavities defined by the end facets of the wire, therefore they do not require polishing or cleaving for high-reflectivity facets as in conventional lasers .\n\nNanowire lasers can be grown site-selectively on Si/SOI wafers with conventional MBE techniques, allowing for pristine structural quality without defects. Nanowire lasers using the group-III nitride and ZnO materials systems have been demonstrated to emit in the visible and ultraviolet, however infrared at the 1.3–1.55 μm is important for telecommunication bands. Lasing at those wavelengths has been achieved by removing the nanowire from the silicon substrate . Nanowire lasers have shown pulse durations down to <1ps , and enable repetition rates greater than 200GHz . Also, nanowire lasers have shown to store the phase information of a pulse over 30ps when excited with subsequent pulse pairs. Mode locked lasers at the nano-scale are therefore feasible with such configurations.\n"}
{"id": "3407453", "url": "https://en.wikipedia.org/wiki?curid=3407453", "title": "Nd:YCOB", "text": "Nd:YCOB\n\nNd-doped YCOB (Nd:YCaO(BO)) is a nonlinear optical crystal, which is commonly used as an active laser medium. It can be grown from a melt by the Czochralski technique. It belongs to the monoclinic system with space group C-Cm. Each neodymium ion replaces a yttrium ion in the YCOB crystal structure.\n\n"}
{"id": "4772239", "url": "https://en.wikipedia.org/wiki?curid=4772239", "title": "Pao (unit)", "text": "Pao (unit)\n\nThe pao is an obsolete unit of dry measure (mass) which was used in South Asia. The name may come from the Punjabi ਪਾਓ \"páo\", which was a traditional charge of one quarter of a seer per every maund of grain that was weighed, converted into a tax by Sawan Mal. Turner also cites a Sindhi word \"pāu\" () meaning a quarter of a seer.\n\nThe pao was recorded in the Bengal Presidency in 1850, but was not considered to be an integral part of the local system of weights. It was equal to four chitaks, and hence a quarter of a seer: the equivalent Imperial weight at the time was given as 7 oz. 10 dwt. Troy (233.3 grams). The use of a quarter-seer weight in Ahmedabad had also been noted in a British East India Company survey of South Asian metrology carried out in 1821: the name of the unit was not recorded, but it would have been equivalent to 4 oz. 3 dr. 17 gr. avoirdupois (119.8 grams) based on the measurement of the Ahmedabad seer.\n\nIn Nepal, the pao () was of a dharni, and equivalent to about 194.4 grams in 1966. Convenient \"pau\" units of both 200 grams and 250 grams are in current use in retail sales in different parts of the country.\n\nIn Pakistan, the pao was slightly heavier, at 233.3 grams.\n\nAs to Afghanistan, it was reported in 1950 that 1 pao ≈ 1 lb (450 grams) in Kabul, with four paos to one charak and sixteen paos to a seer.\n\n"}
{"id": "30876688", "url": "https://en.wikipedia.org/wiki?curid=30876688", "title": "Particulates", "text": "Particulates\n\nAtmospheric aerosol particles – also known as atmospheric particulate matter, particulate matter (PM), particulates, or suspended particulate matter (SPM) – are microscopic solid or liquid matter suspended in the atmosphere of Earth. The term \"aerosol\" commonly refers to the particulate/air mixture, as opposed to the particulate matter alone. Sources of particulate matter can be natural or anthropogenic. They have impacts on climate and precipitation that adversely affect human health.\n\nSubtypes of atmospheric particles include suspended particulate matter (SPM), thoracic and respirable particles, inhalable coarse particles, which are coarse particles with a diameter between 2.5 and 10 micrometers (μm) (PM), fine particles with a diameter of 2.5 μm or less (PM), ultrafine particles, and soot.\n\nThe IARC and WHO designate airborne particulates a Group 1 carcinogen. Particulates are the deadliest form of air pollution due to their ability to penetrate deep into the lungs and blood streams unfiltered, causing permanent DNA mutations, heart attacks, respiratory disease, and premature death. In 2013, a study involving 312,944 people in nine European countries revealed that there was no safe level of particulates and that for every increase of 10 μg/m in PM, the lung cancer rate rose 22%. The smaller PM were particularly deadly, with a 36% increase in lung cancer per 10 μg/m as it can penetrate deeper into the lungs. Worldwide exposure to PM contributed to 4.1 million deaths from heart disease and stroke, lung cancer, chronic lung disease, and respiratory infections in 2016. Overall, ambient particulate matter ranks as the sixth leading risk factor for premature death globally. \n\nSome particulates occur naturally, originating from volcanoes, dust storms, forest and grassland fires, living vegetation and sea spray. Human activities, such as the burning of fossil fuels in vehicles, stubble burning, power plants, wet cooling towers in cooling systems and various industrial processes, also generate significant amounts of particulates. Coal combustion in developing countries is the primary method for heating homes and supplying energy. Because salt spray over the oceans is the overwhelmingly most common form of particulate in the atmosphere, \"anthropogenic\" aerosols—those made by human activities—currently account for about 10 percent of the total mass of aerosols in our atmosphere.\n\nThe composition of aerosols and particles depends on their source.\nWind-blown mineral dust tends to be made of mineral oxides and other material blown from the Earth's crust; this particulate is light-absorbing. Sea salt is considered the second-largest contributor in the global aerosol budget, and consists mainly of sodium chloride originated from sea spray; other constituents of atmospheric sea salt reflect the composition of sea water, and thus include magnesium, sulfate, calcium, potassium, etc. In addition, sea spray aerosols may contain organic compounds, which influence their chemistry. The drift/mist emissions from the wet cooling towers is also source of particulate matter as they are widely used in industry and other sectors for dissipating heat in cooling systems.\n\nSecondary particles derive from the oxidation of primary gases such as sulfur and nitrogen oxides into sulfuric acid (liquid) and nitric acid (gaseous). The precursors for these aerosols—i.e. the gases from which they originate—may have an anthropogenic origin (from fossil fuel or coal combustion) and a natural biogenic origin. In the presence of ammonia, secondary aerosols often take the form of ammonium salts; i.e. ammonium sulfate and ammonium nitrate (both can be dry or in aqueous solution); in the absence of ammonia, secondary compounds take an acidic form as sulfuric acid (liquid aerosol droplets) and nitric acid (atmospheric gas), all of which may contribute to the health effects of particulates.\n\nSecondary sulfate and nitrate aerosols are strong light-scatterers. This is mainly because the presence of sulfate and nitrate causes the aerosols to increase to a size that scatters light effectively.\n\nOrganic matter (OM) can be either primary or secondary, the latter part deriving from the oxidation of VOCs; organic material in the atmosphere may either be biogenic or anthropogenic. Organic matter influences the atmospheric radiation field by both scattering and absorption. Another important aerosol type is elemental carbon (EC, also known as \"black carbon\", BC): this aerosol type includes strongly light-absorbing material and is thought to yield large positive radiative forcing. Organic matter and elemental carbon together constitute the carbonaceous fraction of aerosols. Secondary organic aerosols (SOAs), tiny \"tar balls\" resulting from combustion products of internal combustion engines, have been identified as a danger to health.\n\nThe chemical composition of the aerosol directly affects how it interacts with solar radiation. The chemical constituents within the aerosol change the overall refractive index. The refractive index will determine how much light is scattered and absorbed.\n\nThe composition of particulate matter that generally causes visual effects such as smog consists of sulfur dioxide, nitrogen oxides, carbon monoxide, mineral dust, organic matter, and elemental carbon also known as black carbon or soot. The particles are hygroscopic due to the presence of sulfur, and SO is converted to sulfate when high humidity and low temperatures are present. This causes the reduced visibility and yellow color.\n\nAerosol particles of natural origin (such as windblown dust) tend to have a larger radius than human-produced aerosols such as particle pollution. The false-color maps in the third image on this page show where there are natural aerosols, human pollution, or a mixture of both, monthly.\n\nAmong the most obvious patterns that the size distribution time series shows is that in the planet’s most southerly latitudes, nearly all the aerosols are large, but in the high northern latitudes, smaller aerosols are very abundant. Most of the Southern Hemisphere is covered by ocean, where the largest source of aerosols is natural sea salt from dried sea spray. Because the land is concentrated in the Northern Hemisphere, the amount of small aerosols from fires and human activities is greater there than in the Southern Hemisphere. Over land, patches of large-radius aerosols appear over deserts and arid regions, most prominently, the Sahara Desert in North Africa and the Arabian Peninsula, where dust storms are common. Places where human-triggered or natural fire activity is common (land-clearing fires in the Amazon from August–October, for example, or lightning-triggered fires in the forests of northern Canada in Northern Hemisphere summer) are dominated by smaller aerosols. Human-produced (fossil fuel) pollution is largely responsible for the areas of small aerosols over developed areas such as the eastern United States and Europe, especially in their summer.\n\nSatellite measurements of aerosols, called aerosol optical thickness, are based on the fact that the particles change the way the atmosphere reflects and absorbs visible and infrared light. As shown in the seventh image on this page, an optical thickness of less than 0.1 (palest yellow) indicates a crystal clear sky with maximum visibility, whereas a value of 1 (reddish brown) indicates very hazy conditions.\n\nIn general, the smaller and lighter a particle is, the longer it will stay in the air. Larger particles (greater than 10 micrometers in diameter) tend to settle to the ground by gravity in a matter of hours whereas the smallest particles (less than 1 micrometer) can stay in the atmosphere for weeks and are mostly removed by precipitation. Diesel particulate matter is highest near the source of emission. Any info regarding DPM and the atmosphere, flora, height, and distance from major sources would be useful to determine health effects.\n\nA complicated blend of solid and liquid particles result in particulate matter and these particulate matter emissions are highly regulated in most industrialized countries. Due to environmental concerns, most industries are required to operate some kind of dust collection system to control particulate emissions. These systems include inertial collectors (cyclonic separators), fabric filter collectors (baghouses), wet scrubbers, and electrostatic precipitators.\n\nCyclonic separators are useful for removing large, coarse particles and are often employed as a first step or \"pre-cleaner\" to other more efficient collectors. Well-designed cyclonic separators can be very efficient in removing even fine particulates, and may be operated continuously without requiring frequent shutdowns for maintenance.\n\nFabric filters or baghouses are the most commonly employed in general industry. They work by forcing dust laden air through a bag shaped fabric filter leaving the particulate to collect on the outer surface of the bag and allowing the now clean air to pass through to either be exhausted into the atmosphere or in some cases recirculated into the facility. Common fabrics include polyester and fiberglass and common fabric coatings include PTFE (commonly known as Teflon). The excess dust buildup is then cleaned from the bags and removed from the collector.\n\nWet scrubbers pass the dirty air through a scrubbing solution (usually a mixture of water and other compounds) allowing the particulate to attach to the liquid molecules. Electrostatic precipitators electrically charge the dirty air as it passes through. The now charged air then passes through large electrostatic plates which attract the charged particle in the airstream collecting them and leaving the now clean air to be exhausted or recirculated.\n\nBesides removing particulates from the source of the pollution, it can also be cleaned in the open air.\n\nAtmospheric aerosols affect the climate of the earth by changing the amount of incoming solar radiation and outgoing terrestrial longwave radiation retained in the earth's system. This occurs through several distinct mechanisms which are split into direct, indirect and semi-direct aerosol effects. The aerosol climate effects are the biggest source of uncertainty in future climate predictions. The Intergovernmental Panel on Climate Change, Third Assessment Report, says: \"While the radiative forcing due to greenhouse gases may be determined to a reasonably high degree of accuracy... the uncertainties relating to aerosol radiative forcings remain large, and rely to a large extent on the estimates from global modelling studies that are difficult to verify at the present time\".\n\nThe direct aerosol effect consists of any direct interaction of radiation with atmospheric aerosols, such as absorption or scattering. It affects both short and longwave radiation to produce a net negative radiative forcing. The magnitude of the resultant radiative forcing due to the direct effect of an aerosol is dependent on the albedo of the underlying surface, as this affects the net amount of radiation absorbed or scattered to space. e.g. if a highly scattering aerosol is above a surface of low albedo it has a greater radiative forcing than if it was above a surface of high albedo. The converse is true of absorbing aerosol, with the greatest radiative forcing arising from a highly absorbing aerosol over a surface of high albedo. The direct aerosol effect is a first order effect and is therefore classified as a radiative forcing by the IPCC. The interaction of an aerosol with radiation is quantified by the single-scattering albedo (SSA), the ratio of scattering alone to scattering plus absorption (\"extinction\") of radiation by a particle. The SSA tends to unity if scattering dominates, with relatively little absorption, and decreases as absorption increases, becoming zero for infinite absorption. For example, the sea-salt aerosol has an SSA of 1, as a sea-salt particle only scatters, whereas soot has an SSA of 0.23, showing that it is a major atmospheric aerosol absorber.\n\nThe Indirect aerosol effect consists of any change to the earth's radiative budget due to the modification of clouds by atmospheric aerosols, and consists of several distinct effects. Cloud droplets form onto pre-existing aerosol particles, known as cloud condensation nuclei (CCN).\n\nFor any given meteorological conditions, an increase in CCN leads to an increase in the number of cloud droplets. This leads to more scattering of shortwave radiation i.e. an increase in the albedo of the cloud, known as the Cloud albedo effect, First indirect effect or Twomey effect. Evidence supporting the cloud albedo effect has been observed from the effects of ship exhaust plumes and biomass burning on cloud albedo compared to ambient clouds. The Cloud albedo aerosol effect is a first order effect and therefore classified as a radiative forcing by the IPCC.\n\nAn increase in cloud droplet number due to the introduction of aerosol acts to reduce the cloud droplet size, as the same amount of water is divided into more droplets. This has the effect of suppressing precipitation, increasing the cloud lifetime, known as the cloud lifetime aerosol effect, second indirect effect or Albrecht effect. This has been observed as the suppression of drizzle in ship exhaust plume compared to ambient clouds, and inhibited precipitation in biomass burning plumes. This cloud lifetime effect is classified as a climate feedback (rather than a radiative forcing) by the IPCC due to the interdependence between it and the hydrological cycle. However, it has previously been classified as a negative radiative forcing.\n\nThe Semi-direct effect concerns any radiative effect caused by absorbing atmospheric aerosol such as soot, apart from direct scattering and absorption, which is classified as the direct effect. It encompasses many individual mechanisms, and in general is more poorly defined and understood than the direct and indirect aerosol effects. For instance, if absorbing aerosols are present in a layer aloft in the atmosphere, they can heat surrounding air which inhibits the condensation of water vapour, resulting in less cloud formation. Additionally, heating a layer of the atmosphere relative to the surface results in a more stable atmosphere due to the inhibition of atmospheric convection. This inhibits the convective uplift of moisture, which in turn reduces cloud formation. The heating of the atmosphere aloft also leads to a cooling of the surface, resulting in less evaporation of surface water. The effects described here all lead to a reduction in cloud cover i.e. an increase in planetary albedo. The semi-direct effect classified as a climate feedback) by the IPCC due to the interdependence between it and the hydrological cycle. However, it has previously been classified as a negative radiative forcing.\n\nSulfate aerosol has two main effects, direct and indirect. The direct effect, via albedo, is a cooling effect that slows the overall rate of global warming: the IPCC's best estimate of the radiative forcing is −0.4 watts per square meter with a range of −0.2 to −0.8 W/m² but there are substantial uncertainties. The effect varies strongly geographically, with most cooling believed to be at and downwind of major industrial centres. Modern climate models addressing the attribution of recent climate change take into account sulfate forcing, which appears to account (at least partly) for the slight drop in global temperature in the middle of the 20th century. The indirect effect (via the aerosol acting as cloud condensation nuclei, CCN, and thereby modifying the cloud properties -albedo and lifetime-) is more uncertain but is believed to be a cooling.\n\nBlack carbon (BC), or carbon black, or elemental carbon (EC), often called soot, is composed of pure carbon clusters, skeleton balls and buckyballs, and is one of the most important absorbing aerosol species in the atmosphere. It should be distinguished from organic carbon (OC): clustered or aggregated organic molecules on their own or permeating an EC buckyball. BC from fossil fuels is estimated by the IPCC in the Fourth Assessment Report of the IPCC, 4AR, to contribute a global mean radiative forcing of +0.2 W/m² (was +0.1 W/m² in the Second Assessment Report of the IPCC, SAR), with a range +0.1 to +0.4 W/m². Bond et al., however, states that \"the best estimate for the industrial-era (1750 to 2005) direct radiative forcing of atmospheric black carbon is +0.71 W/m² with 90% uncertainty bounds of (+0.08, +1.27) W/m²\" with \"total direct forcing by all black carbon sources, without subtracting the preindustrial background, is estimated as +0.88 (+0.17, +1.48) W/m²\"\n\nVolcanoes are a large natural source of aerosol and have been linked to changes in the earth's climate often with consequences for the human population. Eruptions linked to changes in climate include the 1600 eruption of Huaynaputina which was linked to the Russian famine of 1601 - 1603, leading to the deaths of two million, and the 1991 eruption of Mount Pinatubo which caused a global cooling of approximately 0.5 °C lasting several years. Research tracking the effect of light-scattering aerosols in the stratosphere during 2000 and 2010 and comparing its pattern to volcanic activity show a close correlation. Simulations of the effect of anthropogenic particles showed little influence at present levels.\n\nAerosols are also thought to affect weather and climate on a regional scale. The failure of the Indian Monsoon has been linked to the suppression of evaporation of water from the Indian Ocean due to the semi-direct effect of anthropogenic aerosol.\n\nRecent studies of the Sahel drought and major increases since 1967 in rainfall over the Northern Territory, Kimberley, Pilbara and around the Nullarbor Plain have led some scientists to conclude that the aerosol haze over South and East Asia has been steadily shifting tropical rainfall in both hemispheres southward.\n\nThe latest studies of severe rainfall decline over southern Australia since 1997 have led climatologists there to consider the possibility that these Asian aerosols have shifted not only tropical but also midlatitude systems southward.\n\nThe size of the particle is a main determinant of where in the respiratory tract the particle will come to rest when inhaled. Larger particles are generally filtered in the nose and throat via cilia and mucus, but particulate matter smaller than about 10 micrometers, can settle in the bronchi and lungs and cause health problems. The 10-micrometer size does not represent a strict boundary between respirable and non-respirable particles, but has been agreed upon for monitoring of airborne particulate matter by most regulatory agencies. Because of their small size, particles on the order of 10 micrometers or less (PM) can penetrate the deepest part of the lungs such as the bronchioles or alveoli. when asthmatics are exposed to these conditions it can trigger bronchoconstriction\n\nSimilarly, so called fine PM, (often referred to as \"PM\"), tend to penetrate into the gas exchange regions of the lung (alveolus), and very small particles (< 100 nanometers) may pass through the lungs to affect other organs. Penetration of particles is not wholly dependent on their size; shape and chemical composition also play a part. To avoid this complication, simple nomenclature is used to indicate the different degrees of relative penetration of a PM particle into the cardiovascular system. Inhalable particles penetrate no further than the bronchi as they are filtered out by the cilia. Thoracic particles can penetrate right into terminal bronchioles whereas PM, which can penetrate to alveoli, the gas exchange area, and hence the circulatory system are termed respirable particles.\nIn analogy, the inhalable dust fraction is the fraction of dust entering nose and mouth which may be deposited anywhere in the respiratory tract. The thoracic fraction is the fraction that enters the thorax and is deposited within the lung's airways. The respirable fraction is what is deposited in the gas exchange regions (alveoli).\n\nThe smallest particles, less than 100 nanometers (nanoparticles), may be even more damaging to the cardiovascular system. Nanoparticles can pass through cell membranes and migrate into other organs, including the brain. Particles emitted from modern diesel engines (commonly referred to as Diesel Particulate Matter, or DPM) are typically in the size range of 100 nanometers (0.1 micrometer). These soot particles also carry carcinogens like benzopyrenes adsorbed on their surface. Particulate mass is not a proper measure of the health hazard, because one particle of 10 µm diameter has approximately the same mass as 1 million particles of 100 nm diameter, but is much less hazardous, as it is unlikely to enter the alveoli. Legislative limits for engine emissions based on mass are therefore not protective. Proposals for new regulations exist in some countries, with suggestions to limit the particle \"surface area\" or the \"particle count\" (numerical quantity) instead.\n\nThe site and extent of absorption of inhaled gases and vapors are determined by their solubility in water. Absorption is also dependent upon air flow rates and the partial pressure of the gases in the inspired air. The fate of a specific contaminant is dependent upon the form in which it exists (aerosol or particulate). Inhalation also depends upon the breathing rate of the subject.\n\nAnother complexity not entirely documented is how the shape of PM can affect health, except for the needle-like shape of asbestos which can lodge itself in the lungs. Geometrically angular shapes have more surface area than rounder shapes, which in turn affects the binding capacity of the particle to other, possibly more dangerous substances.\n\nThe effects of inhaling particulate matter that has been widely studied in humans and animals include asthma, lung cancer, respiratory diseases, cardiovascular disease, premature delivery, birth defects, low birth weight, and premature death.\n\nInhalation of PM – PM is associated with elevated risk of adverse pregnancy outcomes, such as low birth weight . Maternal PM exposure during pregnancy is also associated with high blood pressure in children. Exposure to PM has been associated with greater reductions in birth weight than exposure to PM. PM exposure can cause inflammation, oxidative stress, endocrine disruption, and impaired oxygen transport access to the placenta, all of which are mechanisms for heightening the risk of low birth weight. Overall epidemiologic and toxicological evidence suggests that a causal relationship exists between long-term exposures to PM and developmental outcomes (i.e. low birth weight). However, studies investigating the significance of trimester-specific exposure have proven to be inconclusive, and results of international studies have been inconsistent in drawing associations of prenatal particulate matter exposure and low birth weight.  As perinatal outcomes have been associated with lifelong health and exposure to particulate matter is widespread, this issue is of critical public health importance and additional research will be essential to inform public policy on the matter.\n\nIncreased levels of fine particles in the air as a result of \"anthropogenic\" particulate air pollution \"is consistently and independently related to the most serious effects, including lung cancer and other cardiopulmonary mortality.\" A large number of deaths and other health problems associated with particulate pollution was first demonstrated in the early 1970s and has been reproduced many times since. PM pollution is estimated to cause 22,000–52,000 deaths per year in the United States (from 2000) contributed to ~370,000 premature deaths in Europe during 2005. and 3.22 million deaths globally in 2010 per the global burden of disease collaboration.\n\nA 2002 study indicated that PM leads to high plaque deposits in arteries, causing vascular inflammation and atherosclerosis – a hardening of the arteries that reduces elasticity, which can lead to heart attacks and other cardiovascular problems. A 2014 meta analysis reported that long term exposure to particulate matter is linked to coronary events. The study included 11 cohorts participating in the European Study of Cohorts for Air Pollution Effects (ESCAPE) with 100,166 participants, followed for an average of 11.5 years. An increase in estimated annual exposure to PM 2.5 of just 5 µg/m was linked with a 13% increased risk of heart attacks. In 2017 a study revealed that PM not only affects human cells and tissues, but also impacts bacteria which cause disease in humans. This study concluded that biofilm formation, antibiotic tolerance, and colonisation of both \"Staphylococcus aureus\" and \"Streptococcus pneumoniae\" was altered by Black Carbon exposure.\n\nThe World Health Organization (WHO) estimated in 2005 that \"... fine particulate air pollution (PM(2.5)), causes about 3% of mortality from cardiopulmonary disease, about 5% of mortality from cancer of the trachea, bronchus, and lung, and about 1% of mortality from acute respiratory infections in children under 5 years, worldwide.\". A 2011 study concluded that traffic exhaust is the single most serious preventable cause of heart attack in the general public, the cause of 7.4% of all attacks.\n\nThe largest US study on acute health effects of coarse particle pollution between 2.5 and 10 micrometers in diameter. was published 2008 and found an association with hospital admissions for cardiovascular diseases but no evidence of an association with the number of hospital admissions for respiratory diseases. After taking into account fine particle levels (PM and less), the association with coarse particles remained but was no longer statistically significant, which means the effect is due to the subsection of fine particles.\n\nParticulate matter studies in Bangkok Thailand from 2008 indicated a 1.9% increased risk of dying from cardiovascular disease, and 1.0% risk of all disease for every 10 micrograms per cubic meter. Levels averaged 65 in 1996, 68 in 2002, and 52 in 2004. Decreasing levels may be attributed to conversions of diesel to natural gas combustion as well as improved regulations.\n\nThe Mongolian government agency recorded a 45% increase in the rate of respiratory illness in the past five years (reported in September 2014). Bronchial asthma, chronic obstructive pulmonary disease and interstitial pneumonia were the most common ailments treated by area hospitals. Levels of premature death, chronic bronchitis, and cardiovascular disease are increasing at a rapid rate.\n\nA study In 2000 conducted in the U.S. explored how fine particulate matter may be more harmful than coarse particulate matter. The study was based on six different cities. They found that deaths and hospital visits that were caused by particulate matter in the air were primarily due fine particulate matter.\n\nParticulate matter can clog stomatal openings of plants and interfere with photosynthesis functions. In this manner, high particulate matter concentrations in the atmosphere can lead to growth stunting or mortality in some plant species.\n\nDue to the highly toxic health effects of particulate matter, most governments have created regulations both for the emissions allowed from certain types of pollution sources (motor vehicles, industrial emissions etc.) and for the ambient concentration of particulates. The IARC and WHO designate particulates a Group 1 carcinogen. Particulates are the deadliest form of air pollution due to their ability to penetrate deep into the lungs and blood streams unfiltered, causing permanent DNA mutations, heart attacks and premature death. In 2013, the ESCAPE study involving 312,944 people in nine European countries revealed that there was no safe level of particulates and that for every increase of 10 μg/m in PM, the lung cancer rate rose 22%. For PM there was a 36% increase in lung cancer per 10 μg/m. In a 2014 meta-analysis of 18 studies globally including the ESCAPE data, for every increase of 10 μg/m in PM, the lung cancer rate rose 9%.\n\nAustralia has set limits for particulates in the air:\n\nIn Canada the standard for particulate matter is set nationally by the federal-provincial Canadian Council of Ministers of the Environment (CCME). Jurisdictions (provinces and territories) may set more stringent standards. The CCME standard for particulate matter 2.5 (PM) as of 2015 is 28 μg/m (calculated using the 3-year average of the annual 98th percentile of the daily 24-hr average concentrations) and 10 μg/m³ (3-year average of annual mean). PM standards will increase in stringency in 2020.\n\nChina has set limits for particulates in the air:\nThe European Union has established the European emission standards, which include limits for particulates in the air:\n\nHong Kong has set limits for particulates in the air:\n\nJapan has set limits for particulates in the air:\nSouth Korea has set limits for particulates in the air:\n\nTaiwan has set limits for particulates in the air:\nThe United States Environmental Protection Agency (EPA) has set standards for PM and PM concentrations. (See National Ambient Air Quality Standards)\n\nIn October 2008, the Department of Toxic Substances Control (DTSC), within the California Environmental Protection Agency, announced its intent to request information regarding analytical test methods, fate and transport in the environment, and other relevant information from manufacturers of carbon nanotubes. DTSC is exercising its authority under the California Health and Safety Code, Chapter 699, sections 57018-57020. These sections were added as a result of the adoption of Assembly Bill AB 289 (2006). They are intended to make information on the fate and transport, detection and analysis, and other information on chemicals more available. The law places the responsibility to provide this information to the Department on those who manufacture or import the chemicals.\n\nOn 22 January 2009, a formal information request letter was sent to manufacturers who produce or import carbon nanotubes in California, or who may export carbon nanotubes into the State. This letter constitutes the first formal implementation of the authorities placed into statute by AB 289 and is directed to manufacturers of carbon nanotubes, both industry and academia within the State, and to manufacturers outside California who export carbon nanotubes to California. This request for information must be met by the manufacturers within one year. DTSC is waiting for the upcoming 22 January 2010 deadline for responses to the data call-in.\n\nThe California Nano Industry Network and DTSC hosted a full-day symposium on 16 November 2009 in Sacramento, CA. This symposium provided an opportunity to hear from nanotechnology industry experts and discuss future regulatory considerations in California.\n\nDTSC is expanding the Specific Chemical Information Call-in to members of the nanometal oxides, the latest information can be found on their website.\n\nKey points in the Colorado Plan include reducing emission levels and solutions by sector. Agriculture, transportation, green electricity, and renewable energy research are the main concepts and goals in this plan. Political programs such as mandatory vehicle emissions testing and the prohibition of smoking indoors are actions taken by local government to create public awareness and participation in cleaner air. The location of Denver next to the Rocky Mountains and wide expanse of plains makes the metro area of Colorado's capital city a likely place for smog and visible air pollution.\n\nThe most concentrated particulate matter pollution resulting from the burning of fossil fuels by transportation and industrial sources tends to be in densely populated metropolitan areas in developing countries such as Delhi and Beijing.\n\nPM10 pollution in coal mining areas in Australia such as the Latrobe Valley in Victoria and the Hunter Region in New South Wales significantly increased during 2004 to 2014. Although the increase did not significantly add to non-attainment statistics the rate of increase has risen each year during 2010 to 2014.\n\nSome cities in Northern China and South Asia have had concentrations above 200 µg/m up to a few years ago. The PM levels in Chinese cities have been extreme in recent years, reaching an all-time high in Beijing on 12 January 2013, of 993 µg/m.\n\nTo monitor the air quality of south China, the U.S. Consulate Guangzhou set a PM 2.5 monitor on Shamian Island in Guangzhou, and displays readings on its official website and social platforms.\n\nMongolia's capital city Ulaanbaatar has an annual average mean temperature of about 0 °C, making it the world's coldest capital city. About 40% of the population lives in apartments, 80% of which are supplied with central heating systems from 3 combined heat and power plants. In 2007, the power plants consumed almost 3.4 million tons of coal. The pollution control technology is in poor condition. \n\nThe other 60% of the population reside in shantytowns (Ger districts), which have developed due to the country's new market economy and the very cold winter seasons. The poor in these districts cook and heat their wood houses with indoor stoves fueled by wood or coal. The resulting air pollution is characterized by raised sulfur dioxide and nitrogen oxide levels and very high concentrations of airborne particles and particulate matter (PM).\nAnnual seasonal average particulate matter concentrations have been recorded as high as 279 µg/m (micrograms per cubic meter). The World Health Organization's recommended annual mean PM level is 20 µg/m, which means that Ulaanbaatar's PM annual mean levels are 14 times higher than recommended.\n\nDuring the winter months in particular, the air pollution obscures the air, affecting the visibility in the city to such an extent that airplanes on some occasions are prevented from landing at the airport.\n\nIn addition to stack emissions, another source unaccounted for in the emission inventory is fly ash from ash ponds, the final disposal place for fly ash that has been collected in settling tanks. Ash ponds are continually eroded by wind during the dry season.\n\n\n"}
{"id": "251720", "url": "https://en.wikipedia.org/wiki?curid=251720", "title": "Praseodymium", "text": "Praseodymium\n\nPraseodymium is a chemical element with symbol Pr and atomic number 59. It is the third member of the lanthanide series and is traditionally considered to be one of the rare-earth metals. Praseodymium is a soft, silvery, malleable and ductile metal, valued for its magnetic, electrical, chemical, and optical properties. It is too reactive to be found in native form, and pure praseodymium metal slowly develops a green oxide coating when exposed to air.\n\nPraseodymium always occurs naturally together with the other rare-earth metals. It is the fourth most common rare-earth element, making up 9.1 parts per million of the Earth's crust, an abundance similar to that of boron. In 1841, Swedish chemist Carl Gustav Mosander extracted a rare-earth oxide residue he called didymium from a residue he called \"lanthana\", in turn separated from cerium salts. In 1885, the Austrian chemist Baron Carl Auer von Welsbach separated didymium into two elements that gave salts of different colours, which he named praseodymium and neodymium. The name praseodymium comes from the Greek \"prasinos\" (πράσινος), meaning \"green\", and \"didymos\" (δίδυμος), \"twin\".\n\nLike most rare-earth elements, praseodymium most readily forms the +3 oxidation state, which is the only stable state in aqueous solution, although the +4 oxidation state is known in some solid compounds and, uniquely among the lanthanides, the +5 oxidation state is attainable in matrix-isolation conditions. Aqueous praseodymium ions are yellowish-green, and similarly praseodymium results in various shades of yellow-green when incorporated into glasses. Many of praseodymium's industrial uses involve its ability to filter yellow light from light sources.\n\nPraseodymium is the third member of the lanthanide series. In the periodic table, it appears between the lanthanides cerium to its left and neodymium to its right, and above the actinide protactinium. It is a ductile metal with a hardness comparable to that of silver. Its 59 electrons are arranged in the configuration [Xe]4f6s; theoretically, all five outer electrons can act as valence electrons, but the use of all five requires extreme conditions and normally, praseodymium only gives up three or sometimes four electrons in its compounds. Praseodymium is the first of the lanthanides to have an electron configuration conforming to the Aufbau principle, which predicts the 4f orbitals to have a lower energy level than the 5d orbitals; this does not hold for lanthanum and cerium, because the sudden contraction of the 4f orbitals does not happen until after lanthanum, and is not strong enough at cerium to avoid occupying the 5d subshell. Nevertheless, solid praseodymium takes on the [Xe]4f5d6s configuration, with one electron in the 5d subshell like all the other trivalent lanthanides (all but europium and ytterbium, which are divalent in the metallic state).\n\nLike most lanthanides, praseodymium usually only uses three electrons as valence electrons, as afterwards the remaining 4f electrons are too strongly bound: this is because the 4f orbitals penetrate the most through the inert xenon core of electrons to the nucleus, followed by 5d and 6s, and this increases with higher ionic charge. Praseodymium nevertheless can continue losing a fourth and even occasionally a fifth valence electron because it comes very early in the lanthanide series, where the nuclear charge is still low enough and the 4f subshell energy high enough to allow the removal of further valence electrons. Thus, similarly to the other early trivalent lanthanides, praseodymium has a double hexagonal close-packed crystal structure at room temperature. At about 560 °C, it transitions to a face-centered cubic structure, and a body-centered cubic structure appears shortly before the melting point of 935 °C.\n\nPraseodymium, like all of the lanthanides (except lanthanum, ytterbium, and lutetium, which have no unpaired 4f electrons), is paramagnetic at room temperature. Unlike some other rare-earth metals, which show antiferromagnetic or ferromagnetic ordering at low temperatures, praseodymium is paramagnetic at all temperatures above 1 K.\n\nPraseodymium has only one stable and naturally occurring isotope, Pr. It is thus a mononuclidic element, and its standard atomic weight can be determined with high precision as it is a constant of nature. This isotope has 82 neutrons, a magic number that confers additional stability. This isotope is produced in stars through the s- and r-processes (slow and rapid neutron capture, respectively).\n\nAll other praseodymium isotopes have half-lives under a day (and most under a minute), with the single exception of Pr with a half-life of 13.6 days. Both Pr and Pr occur as fission products of uranium. The primary decay mode of isotopes lighter than Pr is inverse beta decay or electron capture to isotopes of cerium, while that of heavier isotopes is beta decay to isotopes of neodymium.\n\nPraseodymium metal tarnishes slowly in air, forming a spalling oxide layer like iron rust; a centimetre-sized sample of praseodymium metal corrodes completely in about a year. It burns readily at 150 °C to form praseodymium (III,IV) oxide, a nonstoichiometric compound approximating to PrO:\n\nThis may be reduced to praseodymium(III) oxide (PrO) with hydrogen gas. The dark-coloured praseodymium(IV) oxide, PrO, is the most oxidised product of the combustion of praseodymium and is only obtained by reaction of praseodymium metal with pure oxygen at 400 °C and 282 bar. The reactivity of praseodymium conforms to periodic trends, as it is one of the first and thus one of the largest lanthanides. At 1000 °C, many praseodymium oxides with composition PrO exist as disordered, nonstoichiometric phases with 0 < \"x\" < 0.25, but at 400–700 °C the oxide defects are instead ordered, creating phases of the general formula PrO with \"n\" = 4, 7, 9, 10, 11, 12, and ∞. These phases PrO are sometimes labelled α and β′ (nonstoichiometric), β (\"y\" = 1.833), δ (1.818), ε (1.8), ζ (1.778), ι (1.714), θ, and σ.\n\nPraseodymium is quite electropositive and reacts slowly with cold water and quite quickly with hot water to form praseodymium(III) hydroxide:\n\nPraseodymium metal reacts with all the halogens to form trihalides:\nThe tetrafluoride, PrF, is also known, and is produced by reacting a mixture of sodium fluoride and praseodymium(III) fluoride with fluorine gas, producing NaPrF, following which sodium fluoride is removed from the reaction mixture with liquid hydrogen fluoride. Additionally, praseodymium forms a bronze diiodide; like the diiodides of lanthanum, cerium, and gadolinium, it is a praseodymium(III) electride compound.\n\nPraseodymium dissolves readily in dilute sulfuric acid to form solutions containing the chartreuse Pr ions, which exist as [Pr(HO)] complexes:\n\nDissolving praseodymium(IV) compounds in water results in solutions containing the yellow Pr ions; because of the high positive standard reduction potential of the Pr/Pr couple at +3.2 V, these ions are unstable in aqueous solution, oxidising water and being reduced to Pr. The value for the Pr/Pr couple is −2.35 V.\n\nAlthough praseodymium(V) in the bulk state is unknown, the existence of praseodymium in its +5 oxidation state (with the stable electron configuration of the preceding noble gas xenon) under noble-gas matrix isolation conditions was reported in 2016. The species assigned to the +5 state were identified as [PrO], its O and Ar adducts, and PrO(η-O).\n\nOrganopraseodymium compounds are very similar to those of the other lanthanides, as they all share an inability to undergo π backbonding. They are thus mostly restricted to the mostly ionic cyclopentadienides (isostructural with those of lanthanum) and the σ-bonded simple alkyls and aryls, some of which may be polymeric. The coordination chemistry of praseodymium is largely that of the large, electropositive Pr ion, and is thus largely similar to those of the other early lanthanides La, Ce, and Nd. For instance, like lanthanum, cerium, and neodymium, praseodymium nitrates form both 4:3 and 1:1 complexes with 18-crown-6, whereas the middle lanthanides from promethium to gadolinium can only form the 4:3 complex and the later lanthanides from terbium to lutetium cannot successfully coordinate to all the ligands. Such praseodymium complexes have high but uncertain coordination numbers and poorly defined stereochemistry, with exceptions resulting from exceptionally bulky ligands such as the tricoordinate [Pr{N(SiMe)}]. There are also a few mixed oxides and fluorides involving praseodymium(IV), but it does not have an appreciable coordination chemistry in this oxidation state like its neighbour cerium.\n\nIn 1751, the Swedish mineralogist Axel Fredrik Cronstedt discovered a heavy mineral from the mine at Bastnäs, later named cerite. Thirty years later, the fifteen-year-old Vilhelm Hisinger, from the family owning the mine, sent a sample of it to Carl Scheele, who did not find any new elements within. In 1803, after Hisinger had become an ironmaster, he returned to the mineral with Jöns Jacob Berzelius and isolated a new oxide, which they named \"ceria\" after the dwarf planet Ceres, which had been discovered two years earlier. Ceria was simultaneously and independently isolated in Germany by Martin Heinrich Klaproth. Between 1839 and 1843, ceria was shown to be a mixture of oxides by the Swedish surgeon and chemist Carl Gustaf Mosander, who lived in the same house as Berzelius; he separated out two other oxides, which he named \"lanthana\" and \"didymia\". He partially decomposed a sample of cerium nitrate by roasting it in air and then treating the resulting oxide with dilute nitric acid. The metals that formed these oxides were thus named \"lanthanum\" and \"didymium\". While lanthanum turned out to be a pure element, didymium was not and turned out to be only a mixture of all the stable early lanthanides from praseodymium to europium, as had been suspected by Marc Delafontaine after spectroscopic analysis, though he lacked the time to pursue its separation into its constituents. The heavy pair of samarium and europium were only removed in 1879 by Paul-Émile Lecoq de Boisbaudran and it was not until 1885 that Carl Auer von Welsbach separated didymium into praseodymium and neodymium. Since neodymium was a larger constituent of didymium than praseodymium, it kept the old name with disambiguation, while praseodymium was distinguished by the leek-green colour of its salts (Greek πρασιος, \"leek green\"). The composite nature of didymium had previously been suggested in 1882 by Bohuslav Brauner, who did not experimentally pursue its separation.\n\nPraseodymium is not particularly rare, making up 9.1 mg/kg of the Earth's crust. This value is between those of lead (13 mg/kg) and boron (9 mg/kg), and makes praseodymium the fourth-most abundant of the lanthanides, behind cerium (66 mg/kg), neodymium (40 mg/kg), and lanthanum (35 mg/kg); it is less abundant than the rare-earth elements yttrium (31 mg/kg) and scandium (25 mg/kg). Instead, praseodymium's classification as a rare-earth metal comes from its rarity relative to \"common earths\" such as lime and magnesia, the few known minerals containing it for which extraction is commercially viable, as well as the length and complexity of extraction. Although not particularly rare, praseodymium is never found as a dominant rare earth in praseodymium-bearing minerals. It is always preceded by cerium, lanthanum and usually also by neodymium.\nThe Pr ion is similar in size to the early lanthanides of the cerium group (those from lanthanum up to samarium and europium) that immediately follow in the periodic table, and hence it tends to occur along with them in phosphate, silicate and carbonate minerals, such as monazite (MPO) and bastnäsite (MCOF), where M refers to all the rare-earth metals except scandium and the radioactive promethium (mostly Ce, La, and Y, with somewhat less Nd and Pr). Bastnäsite is usually lacking in thorium and the heavy lanthanides, and the purification of the light lanthanides from it is less involved. The ore, after being crushed and ground, is first treated with hot concentrated sulfuric acid, evolving carbon dioxide, hydrogen fluoride, and silicon tetrafluoride. The product is then dried and leached with water, leaving the early lanthanide ions, including lanthanum, in solution.\n\nThe procedure for monazite, which usually contains all the rare earths, as well as thorium, is more involved. Monazite, because of its magnetic properties, can be separated by repeated electromagnetic separation. After separation, it is treated with hot concentrated sulfuric acid to produce water-soluble sulfates of rare earths. The acidic filtrates are partially neutralised with sodium hydroxide to pH 3–4, during which thorium precipitates as a hydroxide and is removed. The solution is treated with ammonium oxalate to convert rare earths to their insoluble oxalates, the oxalates are converted to oxides by annealing, and the oxides are dissolved in nitric acid. This last step excludes one of the main components, cerium, whose oxide is insoluble in HNO. Care must be taken when handling some of the residues as they contain Ra, the daughter of Th, which is a strong gamma emitter.\n\nPraseodymium may then be separated from the other lanthanides via ion-exchange chromatography, or by using a solvent such as tributyl phosphate where the solubility of Ln increases as the atomic number increases. If ion-exchange chromatography is used, the mixture of lanthanides is loaded into one column of cation-exchange resin and Cu or Zn or Fe is loaded into the other. An aqueous solution of a complexing agent, known as the eluant (usually triammonium edtate), is passed through the columns, and Ln is displaced from the first column and redeposited in a compact band at the top of the column before being re-displaced by . The Gibbs free energy of formation for Ln(edta·H) complexes increases along the lanthanides by about one quarter from Ce to Lu, so that the Ln cations descend the development column in a band and are fractionated repeatedly, eluting from heaviest to lightest. They are then precipitated as their insoluble oxalates, burned to form the oxides, and then reduced to the metals.\n\nLeo Moser (son of Ludwig Moser, founder of the Moser Glassworks in what is now Karlovy Vary in the Czech Republic, not to be confused with the mathematician of the same name) investigated the use of praseodymium in glass colouration in the late 1920s, yielding a yellow-green glass given the name \"Prasemit\". However, at that time far cheaper colourants could give a similar colour, so Prasemit was not popular, few pieces were made, and examples are now extremely rare. Moser also blended praseodymium with neodymium to produce \"Heliolite\" glass (\"Heliolit\" in German), which was more widely accepted. The first enduring commercial use of purified praseodymium, which continues today, is in the form of a yellow-orange \"Praseodymium Yellow\" stain for ceramics, which is a solid solution in the zircon lattice. This stain has no hint of green in it; by contrast, at sufficiently high loadings, praseodymium glass is distinctly green rather than pure yellow.\n\nAs the lanthanides are so similar, praseodymium can substitute for most other lanthanides without significant loss of function, and indeed many applications such as mischmetal and ferrocerium alloys involve variable mixes of several lanthanides, including small quantities of praseodymium. The following more modern applications involve praseodymium specifically, or at least praseodymium in a small subset of the lanthanides:\n\nThe early lanthanides have been found to be essential to some methanotrophic bacteria living in volcanic mudpots, such as \"Methylacidiphilum fumariolicum\": lanthanum, cerium, praseodymium, and neodymium are about equally effective. Praseodymium is otherwise not known to have a biological role in any other organisms, but is not very toxic either. Intravenous injection of rare earths into animals has been known to impair liver function, but the main side effects from inhalation of rare-earth oxides in humans come from radioactive thorium and uranium impurities.\n\n\n\n"}
{"id": "7029214", "url": "https://en.wikipedia.org/wiki?curid=7029214", "title": "Radioactive scrap metal", "text": "Radioactive scrap metal\n\nRadioactive scrap metal is created when radioactive material enters the metal recycling process and contaminates scrap metal.\n\nA \"lost source accident\" occurs when a radioactive object is lost or stolen. Such objects may appear in the scrap metal industry if people mistake them for harmless bits of metal. The International Atomic Energy Agency has provided guides for scrap metal collectors on what a sealed source might look like. The best known example of this type of event is the Goiânia accident, in Brazil.\n\nWhile some lost-source accidents have not involved the scrap metal industry, they are good examples of the likely scale and scope of a lost-source accident. For example, the Red Army left sources behind in Lilo. Another case occurred at Yanango where an Ir radiography source was lost and at Gilan, Iran a radiography source harmed a welder.\n\nRadioactive sources have a wide range of uses in medicine and industry, and it is common for the design (and nature) of a source to be tailored to the specific application. Hence, it is impossible to state with confidence what the \"typical\" source looks like or contains. For instance, antistatic devices include beta and alpha emitters: polonium containing devices have been used to eliminate static electricity in such devices as paint spraying equipment. An overview of the gamma sources used for radiography can be seen at Radiographic equipment, and it is reasonable to consider this to be a good overview of small to moderate gamma sources.\n\n\n\nThe cleanup operation for the Goiânia accident was difficult both because the source containment had been opened, and the radioactive material was water-soluble.\n\nIn 1983, a different incident in Mexico wherein cobalt-60 was spilled in an otherwise similar exposure led to a very different pattern of contamination, since the cobalt in such a source is normally in the form of cobalt metal alloyed with some nickel to improve the mechanical properties of the radioactive metal. If such a source is abused, then the cobalt metal fragments do not tend to dissolve in water or become very mobile. If a cobalt or iridium source is lost at a ferrous metal scrapyard then it is often the case that the source will enter a furnace, the radioactive metal will melt and contaminate the steel from this furnace. In Mexico, some buildings have been demolished because of the level of cobalt-60 in the steel used to make them. Also, some of the steel which was rendered radioactive in the Mexican event was used to make legs for 1400 tables.\n\nIn the case of some high-value scrap metals it is possible to decontaminate the material, but this is best done long before the metal goes to a scrap yard.\n\nIn the case of a caesium source being melted in an electric arc furnace used for steel scrap, it is more likely that the caesium will contaminate the fly ash or dust from the furnace, while radium is likely to stay in the ash or slag. The United States Environmental Protection Agency provide data about the fate of different contaminating elements in a scrap furnace. Four different fates for the element exist: the element can stay in the metal (as with cobalt and ruthenium); the element can enter the slag (as in lanthanides, actinides and radium); the element can enter the furnace dust or fly ash (as with caesium), which accounts for around 5%; or the element can leave the furnace and pass through the bag house to enter the air (as with iodine).\n\nIt is normal to place silicon, aluminium scrap and flux in a furnace. This is heated to form molten aluminium. From the furnace three main streams are obtained, metal product, dross (metal oxides and halides which are skimmed off the molten metal product) and off gases which go to the baghouse. The cooled waste gasses are then allowed out into the environment.\n\nIt is normal that good-quality scrap copper, such as that from a nuclear plant, is refined in one furnace before being refined further in an electrochemical process. The furnace generates impure metal, slag, dust and gases. The dust accumulates in a bag house, while the gases are vented to the atmosphere. The impure metal from the furnace may be further refined in an electrochemical process.\n\nIf the copper refinery includes an electrochemical process after the furnace, then unwanted elements are removed from the impure metal and deposited as anode slime.\n\n\n"}
{"id": "2948536", "url": "https://en.wikipedia.org/wiki?curid=2948536", "title": "Rocket candy", "text": "Rocket candy\n\nRocket Candy, or R-Candy, is a type of rocket propellant for model rockets made with sugar as a fuel, and containing an oxidizer. The propellant can be divided into three groups of components: the fuel, the oxidizer, and the additive(s). The fuel is a sugar; sucrose is the most commonly used. The most common oxidizer is potassium nitrate (KNO). Potassium nitrate is most commonly found in household stump remover. Additives can be many different substances, and either act as catalysts or enhance the aesthetics of the liftoff or flight. A traditional sugar propellant formulation is typically prepared in a 13:7 oxidizer to fuel ratio.\n\nThere are many different methods for preparation of a sugar-based rocket propellant. Dry compression does not require heating, only the grinding of the components and then packing into the motor. However, this method is not recommended for serious experimenting. Dry heating does not actually melt the KNO, but it melts the sugar and then the KNO grains become suspended in the sugar.\n\nThe specific impulse, total impulse, and thrust are generally lower for the same amount of fuel than other composite model rocket fuels, but rocket candy is significantly cheaper.\n\nIn the United States, rocket candy motors are legal to make, but illegal to transport without a low explosives users permit. Since they count as amateur motors, a user must launch them at a sanctioned Tripoli Rocketry Association research launch and must have at least a Tripoli Rocketry Association high power level 2 certification. Similar laws apply in Canada, the UK, and Australia.\n\nRocket candy can be broken down into three major groups of components: fuels, oxidizers, and additives. The fuel is the substance that burns, releasing rapidly expanding gases that provide thrust as they exit the nozzle. The oxidizer provides oxygen, which is required for the burning process. The additives can be catalysts, to speed up or make the burning more efficient. However, some additives are more aesthetic, and can add sparks and flames to liftoff, or add smoke for ease of following the rocket in the air.\n\nMany different sugars can be used as the fuel for rocket candy, including glucose, fructose, and sucrose; however, sucrose is the most common. Sorbitol, a sugar alcohol commonly used as a sweetener in food, produces a less brittle propellant with a slower burn rate. This reduces the risk of cracking propellant grains. Sugars with a double bonded oxygen, such as fructose and glucose, are less thermally stable and tend to caramelize when overheated, but have a lower melting point for ease of preparation. Sugars that only have alcohol groups, like sorbitol, are much less prone to this decomposition. Some other commonly used sugars include erythritol, xylitol, lactitol, maltitol, or mannitol.\n\nThe oxidizer most often used in the preparation of sugar motors is potassium nitrate (KNO). Other oxidizers can be used as well, such as sodium and calcium nitrates as well as mixtures of sodium and potassium nitrate. KNO can be acquired through purchasing a granular “stump remover\" from stores that carry garden supplies. Other rarely used oxidizers are ammonium and potassium perchlorate.\n\nTwo main issues need to be addressed with respect to the oxidizer if one is using potassium nitrate. The most important issue is the purity of the material. If a purchased material does not perform satisfactorily it may be necessary to recrystallize the KNO. The second important issue with respect to the oxidizer portion of a propellant is its particle size. Most propellant makers prefer their KNO ground to a small particle size, such as 100 mesh (about 150 µm) or smaller. This can be done using a coffee grinder. Rock-tumblers can also be used to mill into a fine grained well mixed powder.\n\nAdditives are often added to rocket propellants to modify their burn properties. Such additives may be used to increase or decrease the burn rate of the propellant. Some are used to alter the color of the flame or smoke produced. They can also be used to modify a certain physical property of the propellant itself, such as plasticizers or surfactants to facilitate the casting of the formulation. There are many types of experimental additives; the ones listed here are only the most commonly used.\n\nMetal oxides have been found to increase the burn rate of sugar propellants. Such additives have been found to function best at levels from 1 to 5 percent. Most often used are iron oxides. Red iron oxide is used most often as it is somewhat easier to obtain than the yellow, brown, or black versions. Brown iron oxide exhibits unusual burn rate acceleration properties under pressure.\n\nCarbon in the form of charcoal, carbon black, graphite, etc., can be and sometimes is used as a fuel in sugar formulations. Most often, however, a small amount of carbon is used as an opacifier, making a visible smoke trail. The carbon acts as a heat sink, keeping a portion of the heat of combustion located in the propellant rather than having it transferred quickly to the motor casing.\n\nIf metallic fuels such as aluminum or magnesium are used in a sugar formulation, a danger exists if traces of acids are found in the oxidizer. Acidic materials can react readily with the metal, producing hydrogen and heat, a dangerous combination. The addition of weak bases helps to neutralize these acidic materials, greatly reducing their danger.\n\nTitanium metal flake or sponge (about 20 mesh in size) is often added to sugar formulations at levels from 5 to 10% in order to produce a sparking flame and smoke on lift off.\n\nSurfactants are used to reduce the melting viscosity of sugar propellants. For example, propylene glycol helps reduce the melt viscosity of sucrose based propellants.\n\nA typical sugar propellant formulation is typically prepared in a 13:7 oxidizer to fuel ratio (weight ratio). However, this formulation is slightly fuel rich., and can be varied by up to 10%. There are many different possible formulations that will allow for flight in amateur rocketry.\n\nThere are a number of different methods for preparing a sugar-based rocket propellant. Other than dry compressed, all of these methods involve heating the propellant. These various methods include: dry compressed, dry heated, and dissolved and heated twice.\n\nIn dry compression, the sugar and potassium nitrate are individually ground as finely as possible, and then mixed in a ball mill or tumbler to ensure uniform mixing of the components. This mixture is then compressed into the motor tube, similar to a method for loading black powder. However, this method is rarely used for serious experiments, and careful safety considerations should be made before deciding to employ this method. There is a significant chance for self-ignition while mixing, which could lead to serious injury.\n\nAnother, more common and safer method of preparing a sugar-based rocket propellant is dry heating. First, the potassium nitrate is ground or milled to a fine powder, and then thoroughly mixed with powdered sugar which is then heated. This method does not actually melt the potassium nitrate, as the melting temperature of KNO is 613 degrees Fahrenheit (323 degrees Celsius), but it melts the sugar and coats the grains of KNO with the melted sugar. The melting process must be performed using a heat spreader, so as to avoid creating autoignition hot-spots.\n\nJames Yawn, a well known amateur rocket experimentalist, advocates for the dissolving and heating method. Dissolving and heating the propellant actually dissolves both elements of the propellant and combines them. First, the KNO and sugar are placed in a pot or saucepan. Then, just enough water is added to be able to completely dissolve the KNO and the sugar. The mixture is then heated and brought to a boil until the water evaporates. The mixture will go through several stages, first boiling, then bubbling and spitting, then it will turn to a smooth creamy consistency. There are several advantages to dissolving the sugar and KNO in water before heating. One advantage is that the KNO and the sugar do not have to be finely powdered, because they both end up completely dissolved. This method of preparation also causes the resultant propellant to resist caramelization in the pot, giving more time to pack it into the motors.\n\nSugar based rocket propellants have an average I(specific impulse) of between 115 and 130 seconds. Compare that to the average I of an APCP (Ammonium perchlorate composite propellant), which is 180 to 260 seconds. Sorbitol and KNO based propellants with a typical 35:65 ratio are capable of an I of between 110 and 125 seconds. However, sorbitol and KNO rockets with additives have been recorded as having specific impulses of up to 128 seconds.\n\nXylitol and KNO based rocket propellants are capable of a specific impulse of ~100 seconds. These have an unconfined burn rate of about 1.3 mm/s. Overall, sugar rockets can compete fairly well.\n\nDextrose and KNO based fuels are capable of an I of 118 seconds.\n\nRocket candy is also occasionally known as \"caramel candy\", a term that was popularized by Bertrand R. Brinley, in his pioneering book on amateur rocketry, \"Rocket Manual for Amateurs\", published in 1960. This propellant was used in some of the amateur rockets described by Homer Hickam in his best-selling memoir \"Rocket Boys\".\n\nRocket candy was also employed in a small amateur rocket described by Lt. Col. Charles M. Parkin in a lengthy \"Electronics Illustrated\" article that continued over several issues, beginning in July 1958. Parkin described how to prepare the propellant mixture by using an electric frying pan as a heat source for the melting operation. This article was reprinted in Parkin's book, \"The Rocket Handbook for Amateurs\", which was published in 1959. Parkin's article contributed to the increasing popularity of the rocket candy propellant among amateur rocket groups beginning in the late 1950s and early 1960s.\n\nHamas uses a formulation of rocket candy for short range improvised rocket weapons, due to an abundance of the required materials.\n\nThe Sugar Shot to Space program was formed with the goal \"to loft a rocket powered by a ‘sugar propellant’ into space\" equivalent to 100 km (62.137 mi) in altitude. The \"Double Sugar Shot\" rocket will reach 33 km, or one third of the goal altitude. The first \"Mini Sugar Shot\" rocket, a prototype of the \"Extreme Sugar Shot\" rocket, reached an altitude of 4 km before a catastrophic motor malfunction occurred; contact with the second Mini Sugar Shot rocket was lost at an altitude of nearly 6 km going in excess of mach one. The \"Extreme Sugar Shot\" rocket, the rocket expected to meet the goal of entering space, has not yet been completed and is in the development progress.\n\n\n\"*JTRocketmen\n"}
{"id": "1097424", "url": "https://en.wikipedia.org/wiki?curid=1097424", "title": "Sterno", "text": "Sterno\n\nSterno (\"canned heat\") is a fuel made from denatured and jellied alcohol. It is designed to be burned directly from its can. Its primary uses are in the food service industry for buffet heating and in the home for fondue and as a chafing fuel for heating chafing dishes. Other uses are for camp stoves and as an emergency heat source. It is also a popular fuel for use with toy and model steam and other external combustion engines. Sterno cans were sometimes taken on trips and used to heat curling irons and hot combs for hairstyling, for use when travelers were not near salons providing these services.\n\nThe Sterno brand and trademark is owned by Sterno Products, a portfolio company of Westar Capital LLC based in Corona, California. The brand was purchased from Blyth, Inc. in late 2012. Blyth had acquired the business from Colgate-Palmolive in 1997.\n\nThe name comes from that of the original manufacturer, S. Sternau & Co. of Brooklyn, New York, a maker of chafing dishes, coffee percolators and other similar appliances since 1893. It had previously applied the name to its \"Sterno-Inferno\" alcohol burner. In 1918, it promoted its Sterno Stove as being a perfect gift for a soldier going overseas. In his book \"With the Old Breed\", E. B. Sledge describes its use on the battlefields of the Pacific Theatre in 1944 and 1945.\n\nInvented around 1900, Sterno is made from ethanol, methanol, water and an amphoteric oxide gelling agent, plus a dye that gives it a characteristic pink color. The methanol is added to denature the product, which is intended to make it too toxic for consumption. Designed to be odorless, a 7 oz (198 g) can will burn for up to two hours. It was discovered while producing nitrocellulose during the manufacturing process.\n\nNitrocellulose is a material used in manufacturing explosives and is made by combining shredded wood pulp and adding a nitric sulfuric acid mix. A by-product of the manufacturing process produces a gel-like substance later refined as Sterno.\n\nIn 2007, NASCAR owner/driver Michael Waltrip and his team had severe penalties handed down by officials. Team Vice-President Bobby Kennedy and Crew Chief David Hyder of Waltrip's No. 55 were ejected from the Daytona International Speedway. Hyder was fined $100,000 for his involvement with lining fuel tanks and intake valves with Sterno. NASCAR also docked Waltrip 100 owner points and disqualified his qualifying speed for the Daytona 500. Mid-week, NASCAR determined that the then unknown substance was Sterno. When the highly regulated NASCAR fuel was added, the Sterno would liquefy, giving the car an added octane boost.\n\nThere are many instances of people drinking Sterno to become intoxicated, i.e. as a form of surrogate alcohol. Since the alcohol it contains is denatured, Sterno is poisonous. Bluesman Tommy Johnson alludes to the practice in his song \"Canned Heat Blues\" recorded in 1928. The blues band Canned Heat derived their name from the practice. \n\nThe practice is said to have become popular during Prohibition and during the Great Depression in hobo camps, or \"jungles\", when the Sterno would be squeezed through cheesecloth or a sock and the resulting liquid mixed with fruit juice to make \"jungle juice,\" \"sock wine,\" or \"squeeze\".\n\nThe 1956 American documentary \"On the Bowery\" includes footage of three homeless men straining Sterno cooking fuel to make \"squeeze\" and then drinking the alcohol.\n\nIn an article for the \"Journal of the American Medical Association\" in 1961, Capt. James H. Shinaberger, MC, writes about a study of three people who had suffered methanol poisoning as a result of drinking Sterno. One of the patients \"had been drinking Sterno for about a week and had been in the city prison for 48 hours when severe abdominal pain and vomiting occurred\".\n\nIn December 1963, a rash of 31 deaths in Philadelphia's homeless population was traced to a local store that knowingly sold Sterno to people for them to consume and get drunk.\n\n\n"}
{"id": "58069691", "url": "https://en.wikipedia.org/wiki?curid=58069691", "title": "Terra d'Otranto (extra-virgin olive oil)", "text": "Terra d'Otranto (extra-virgin olive oil)\n\nThe extra-virgin olive oil Terra d'Otranto is produced with the olive cultivars \"Cellina di Nardò\" and \"Ogliarola\" for, at least, 60%. They are mixed with other minor varieties of the local olive groves. Its name is linked with the historical region of \"Terra d'Otranto\" which included almost all the municipalities of the current provinces of Taranto, Brindisi and Lecce. It is recognised as PDO product.\n\nThe cultivation of the olive tree in Terra d'Otranto has been introduced by the Greeks and by Phoenicians. Nevertheless, after the cessation of this activity during the Middle Ages, the Basilian monks started the first booming market of olive oil of this territory.\n\nThe extra-virgin olive oil \"Terra d'Otranto\" is produced in the area between the Ionian and the Adriatic Sea, between the \"Murge\" in the province of Taranto and the \"Serre\" next to Lecce. This territory includes all the cities and villages of the province of Lecce, in the eastern part of the province of Taranto and in the municipalities of Brindisi, Cellino San Marco, Erchie, Francavilla Fontana, Latiano, Mesagne, Oria, San Donaci, San Pancrazio Salentino, San Pietro Vernotico, Torchiarolo and Torre Santa Susanna in the northern part of Salento. The limit of the altitudinal range is 517 m. above sea level. The soil is mainly made of limestone.\nThe extra-virgin olive oil \"Terra d'Otranto\" is light yellow with green shades. It has a fruity taste with some light bitter and spicy aroma. It is perfect for pasta, vegetables and legumes, but it can be used also with secondo courses.\n\nConsorzio tutela olio DOP Terra d'Otranto, Lecce\n\n"}
{"id": "16796840", "url": "https://en.wikipedia.org/wiki?curid=16796840", "title": "Thomas E. Murray", "text": "Thomas E. Murray\n\nThomas E. Murray (October 21, 1860 – July 21, 1929) was an American inventor and businessman who developed electric power plants for New York City as well as many electrical devices which influenced life around the world, including the dimmer switch and screw-in fuse. It has been said that he \"invented everything from the power plant up to the light bulb\".\n\nMurray is considered one of the most prolific inventors in history after Thomas Edison, holding 462 U.S. patents in his name. However, unlike Edison, Murray did not patent the work of others under his name; the employee would have the patent in their name, and assign it to the Murray company. Also, if Murray worked with anyone else on an invention, their name would be listed on the patent.\n\nThomas E. Murray was born in Albany, New York, to an Irish family and was one of 12 children. Upon the death of his father when he was nine, he took three jobs to help support his family.\n\nHis son, Thomas E. Murray Jr., was also an engineer who worked with Edison.\n\nIn 1875, he was an apprentice at the Albany Iron & Machine works. In 1881, at the age of 21, he became the Chief Engineer of the Albany Waterworks. In 1887, Anthony N. Brady hired Murray to run the power station of the Albany Municipal Gas Co,\n\nMurray was responsible for the power stations that powered New York City for the first half of the 20th century. He eventually was in complete charge of all the allied Edison companies in New York City, Brooklyn and Westchester.\n\n\nThomas E. Murray died on July 21, 1929, at \"Wickapogue\", his summer estate in Southampton, Long Island, New York.\n\nMay 4th, 2011 Murray was inducted into the National Inventor's Hall of Fame for the Electric Safety Fuse 920,613.\n\nIn 1910, Murray won the Edward Longstreth Medal from the Franklin Institute.\n\n\n\n"}
{"id": "2229321", "url": "https://en.wikipedia.org/wiki?curid=2229321", "title": "Thunder Bay (film)", "text": "Thunder Bay (film)\n\nThunder Bay is a 1953 American adventure film distributed by Universal International, produced by Aaron Rosenberg, directed by Anthony Mann, and stars James Stewart, Joanne Dru, Gilbert Roland, and Dan Duryea. It was shot in Technicolor and was released on May 21. This film tells the story of two engineers drilling for oil in the Louisiana gulf while dealing with hostility of the local shrimp fishermen fearing for their livelihood and features the first non-western collaboration between Stewart and Mann.\n\nPenniless but full of ideas, Steve Martin (James Stewart) and Johnny Gambi (Dan Duryea), engineers who served in the Navy during World War II, walk down a quiet road on the gulf coast of Louisiana. Teche Bossier (Gilbert Roland), owner of the Port Felicity Fish Co., agrees to drive them into the shrimping town Port Felicity for five dollars. Upon reaching their destination, Gambi rents a shrimp boat from Dominique Rigaud (Antonio Moreno), although the fisherman's daughter Stella (Joanne Dru) distrusts them immediately.\n\nGambi and Steve use the boat to show potential investor Kermit MacDonough (Jay C. Flippen) the location in which they plan to drill for offshore oil. Claiming that he has designed a drilling platform that can withstand any storm, Steve estimates that by investing one million dollars now, they will soon tap an oil reserve worth two billion. His enthusiasm is so infectious that MacDonough agrees to fund the project against the advice of his secretary, Rawlins. However, MacDonough warns Steve that he must discover oil within three months, or his company, due to huge investments made in an offshore oil lease, will put them both out of work.\n\nSeveral weeks later, Gambi meets and falls for Stella's younger sister Francesca (Marcia Henderson), but according to custom, she has been betrothed since childhood to Philippe Bayard. After singing a love song in the local gathering place Bon Chance, Philippe is upset to see Francesca enter with Gambi. Teche, who good-naturedly calls the oilmen \"foreigners,\" agrees to help Steve and Gambi, but Stella refuses to accept Steve's statement that oil will be good for the town, claiming that she learned about \"their kind\" during her stay in Chicago. Nevertheless, the outsiders hire a crew and begin their search for oil.\n\nWhen Teche sees dynamite charges being dropped into the gulf, he begs them to stop, believing that the explosions will kill the shrimp and worsen an already dismal shrimping season. Steve maintains that the charges are safe, but Teche returns to town and incites the fishermen to form an angry mob. He scares the mob away by exploding sticks of dynamite behind them and he placates Stella by warning Gambi to stay away from Francesca. Steve gently advises Francesca to \"go back to [her] people.\"\n\nWith one month gone, Steve drives the building crew relentlessly and the platform and rig are completed on-schedule. He immediately orders the drilling crew to get started and the exhausted Gambi is relieved when a hurricane warning gives the men an excuse to take the night off. Gambi and his men enter the Bon Chance with Francesca, and Philippe furiously punches his rival and starts a brawl. The sheriff arrests the oilmen and Francesca angrily denounces all the men.\n\nDuring the storm, Stella visits Steve at the rig, determined to have Gambi fired so he stops seeing her sister. Steve explains to Stella that if he could pull up a resource that has been in the earth for millions of years, then he will truly have accomplished something. Stella finally abandons her suspicion and kisses Steve, but back in town, Philippe persuades Teche to help him destroy the oil rig. With the hurricane winds rising, Philippe climbs onto the platform and lights a bundle of dynamite, but Steve sees him and the two men fight. Philippe trips and disappears under the waves, and Steve, horrified, assumes that Stella was involved in Philippe's plot.\n\nThe rig survives the storm, and in the morning, drilling begins. However, eight days before the deadline, MacDonough visits Steve and sadly delivers the news that the board of his company has voted to stop the drilling operation on the following day, fearing a penalty for non-payment on their lease. MacDonough has already spent all of his own money and the crew is unable to work for no pay. Gambi soon returns from town, announcing that he has just married Francesca. Steve punches Gambi, who in retort loudly chastises Steve for having driven him and the men too hard. Steve tells them all to leave, intending to do the drilling himself, whereupon Gambi hesitates and then persuades the crew to remain. While the men are drilling, they discover that the troublesome shrimp that have been clogging the valves are actually the huge golden shrimp that have so long eluded the local fishermen.\n\nSteve later takes Francesca to the rig, infuriating Dominique, who inflames the fisherman by declaring that the oilmen will steal their daughters and destroy the town. At Stella's request, Teche go to warn Steve about the impending mob on its way to the rig. There, Steve feigns ignorance about the golden shrimp and asks Teche if he can help him get rid of the creatures. He then addresses the furious mob to assure the men on their concerns: Francesca's marriage is a happy one and moreover, oil will bring progress to Port Felicity. Despite these words, the mob decides to destroy the structure, but at that moment, oil explodes through the rig and onto the platform. Later on, the fishermen discover that the golden shrimp bed is huge, and consequently, the conflict between the oilmen and the fishermen is resolved. Teche then convinces Steve that Stella was not involved in Philippe's plot and the lovers finally come together.\n\n\nProduction for this film started from late September to mid-November 1952. It was filmed in 1.37 to 1 full frame aspect ratio while it was released in 1.85 to 1 anamorphic widescreen.\n\nThe film marked Universal's first use of stereophonic sound, which at the time was presentable only in select theaters. It was also originally planned to be photographed in 3-D, but those plans were scrapped sometime during production.\n\nMost of the picture was shot in Morgan City, Louisiana while some scenes were shot in New Orleans and on an oil-drilling barge thirty miles out in the Gulf of Mexico. While filming the scenes on-location in Louisiana, Dan Duryea slipped and fell from the roof of a tugboat (which appears throughout the film). He suffered a broken rib, contusion, and bruises but was able to continue filming after a day or two of rest.\n\nSome contemporary reviewers complained that the sound from the film's stereophonic presentation, with its use of three speakers, was loud and distracting.\n\nThe film currently has a 6.6/10 rating on IMDb, a 3/5 rating on AllMovie, and an audience score of 59% on the film review aggregator website Rotten Tomatoes, with an average score of 3.4/5, based on 267 reviews.\n\nUniversal first released this film on VHS on March 1, 1992. Then, on June 12, 2007, it was released on DVD as part of the \"James Stewart Screen Legend Collection\", a 3-disc set featuring four other films (\"Next Time We Love\", \"You Gotta Stay Happy\", \"The Glenn Miller Story\", and \"Shenandoah\"). This film was re-released on August 30, 2013 as a stand-alone DVD as part of the \"Universal Vault Series\". (The DVD releases of the movie are not in presented in the film's original 1.33:1 aspect ratio.)\n\n"}
{"id": "23701959", "url": "https://en.wikipedia.org/wiki?curid=23701959", "title": "White lined chipboard", "text": "White lined chipboard\n\nWhite lined chipboard, also referred to as: WLC, GD, GT or UD, is a grade of paperboard typically made from layers of waste paper or recycled fibers. Most often it comes with two to three layers of coating on the top and one layer on the reverse side. Because of its recycled content it will be grey from the inside.\nThe main enduse for this type of board is for packaging of frozen or chilled food, cereals, shoes, toys and others.\n\nHealth risks have been associated with using recycled material in direct food contact. Swiss studies have shown that recycled material can contain significant portions of mineral oil, which may migrate into packed foods. (Mineral oil levels of up to 19.4 mg/kg were found in rice packed in recycled board.)\n\n"}
{"id": "5702917", "url": "https://en.wikipedia.org/wiki?curid=5702917", "title": "Windy Hill Wind Farm", "text": "Windy Hill Wind Farm\n\nWindy Hill Wind Farm is a wind power station near Ravenshoe on the Atherton Tablelands, Queensland, Australia. Windy Hill has 20 wind turbines with a generating capacity of 12 MW of electricity, providing enough power for about 3,500 homes. The cost of the project was A$20 million. It was the first wind farm to be constructed in Queensland and remains the state's largest.\n\nThe power station was commissioned in 2000 and was initially operated by the Stanwell Corporation. In December 2007 Windy Hill was sold to Transfield Services Infrastructure Fund (TSIF) as part of Queensland Government's ClimateSmart 2050 strategy. A new substation was built to allow the wind farm's power to connect to the existing 66 kV transmission line. RATCH-Australia Corporation bought TSIF in 2011.\n\nThe construction contractor for the wind farm was Powercorp, based in Darwin. The wind turbines are located on private land which continues to be used as a dairy farm. Each tower is 44 metres high. The turbines used at the facility are Enercon E40. They can rotate at speeds between 14 rpm to 38 rpm. Power from the turbines is carried by underground cable to the electricity grid.\n\n\n"}
{"id": "33954161", "url": "https://en.wikipedia.org/wiki?curid=33954161", "title": "Wood production", "text": "Wood production\n\nLumber and wood products are created from the trunks and branches of trees through a series of steps, as follows.\n\nMature trees are harvested from pine plantations and also from native forests. Trees harvested at a younger age can produce smaller logs, which can be turned into lower value products. Factors such as the site and climatic conditions, the species, the growth rate, and silviculture can affect the size of a mature tree.\n\nThe native hardwood sawmilling industry originally consisted of small family-owned mills, but this has recently changed to include a small number of larger mills. The mills produce large volumes of standard products, and aim to ensure a \"standard quality of product, efficiently and safely, at low cost, with rapid production time and high output\".\n\nOnce the timber has manipulated in the required fashion, it can be used for its purpose. There are many different purposes for wood including: plywood, veneer, pulp, paper, particleboard, pallets, craft items, toys, instrument-making, furniture production, packing cases, wine barrels, cardboard, firewood, garden mulch, fibre adhesives, packaging and pet litter. Western Australia has a unique substance called ‘bio-char’, which is made from jarrah and pine. Bio-char can be used in the manufacture of silicone and as a soil additive.\nProducts\n\nSoftwoods, such as the Australian eucalyptus, are highly valued, and are used mainly for construction, paper making, and cladding. The term \"roundwood\" describes all the wood that is removed from forests in log form and used for purposes other than fuel. Wood manufacturing residues, such as sawdust and chippings, are collectively known as \"pulp\".\n\nOriginally, \"trees were felled from native forests using axes and hand-held cross-cut saws\". This was a slow process involving manual labour. Nowadays, harvesting is done by a small team of contractors, who are aided by various pieces of machinery. Sawmills were traditionally located within forests, so logs had to be transported over long distances and rough terrain to reach their destination. Soon, waterways were used to transport the logs. Later on, logs were transported via tramlines, \"first by steam-powered log haulers then by steam-powered locomotives, and finally diesel and petrol-powered locomotives\". Even in the modern era, timber is dried in kilns. The first steam railway in Australia opened in Melbourne in 1854. This dramatically changed the nature of timber transportation and made it possible for the sawmilling industry to move inland away from the coast, due to transportation being made quicker and cheaper.\n"}
{"id": "3164011", "url": "https://en.wikipedia.org/wiki?curid=3164011", "title": "Zirconium carbide", "text": "Zirconium carbide\n\nZirconium carbide (ZrC) is an extremely hard refractory ceramic material, commercially used in tool bits for cutting tools. It is usually processed by sintering.\n\nIt has the appearance of a gray metallic powder with cubic crystal structure. It is highly corrosion resistant. This Group IV interstitial transition-metal carbide is also a member of ultra high temperature ceramics or (UHTC). Due to the presence of metallic bonding, ZrC has a thermal conductivity of 20.5 W/m·K and an electrical conductivity (resistivity ~43 μΩ·cm), both of which are similar to that for zirconium metal. The strong covalent Zr-C bond gives this material a very high melting point (~3530 °C), high modulus (~440 GPa) and hardness (25 GPa). ZrC has a lower density (6.73 g/cm) compared to other carbides like WC (15.8 g/cm), TaC (14.5 g/cm) or HfC (12.67 g/cm). ZrC seems suitable for use in re-entry vehicles, rocket/SCRAM jet engines or supersonic vehicles in which low densities and high temperatures load-bearing capabilities are crucial requirements.\n\nLike most carbides of refractory metals, zirconium carbide is sub-stoichiometric, i.e., it contains carbon vacancies. At carbon contents higher than approximately ZrC the material contains free carbon. ZrC is stable for a carbon-to-metal ratio ranging from 0.65 to 0.98.\n\nThe group IVA metal carbides, TiC, ZrC, and SiC are practically inert toward attack by strong aqueous acids (HCl) and strong aqueous bases (NaOH) even at 100' C, however, ZrC does react with HF.\n\nThe mixture of zirconium carbide and tantalum carbide is an important cermet material.\n\nHafnium-free zirconium carbide and niobium carbide can be used as refractory coatings in nuclear reactors. Because of a low neutron absorption cross-section and weak damage sensitivity under irradiation, it finds use as the coating of uranium dioxide and thorium dioxide particles of nuclear fuel. The coating is usually deposited by thermal chemical vapor deposition in a fluidized bed reactor. It also has high emissivity and high current capacity at elevated temperatures rendering it as a promising material for use in thermo-photovoltaic radiators and field emitter tips and arrays.\n\nIt is also used as an abrasive, in cladding, in cermets, incandescent filaments and cutting tools.\n\nZirconium carbide is made by carbo-thermal reduction of zirconia by graphite. Densified ZrC is made by sintering powder of ZrC at upwards of 2000 °C. Hot pressing of ZrC can bring down the sintering temperature and consequently helps in producing fine grained fully densified ZrC. Spark plasma sintering also has been used to produce fully densified ZrC.\n\nPoor oxidation resistance over 800 °C limits the applications of ZrC. One way to improve the oxidation resistance of ZrC is to make composites. Important composites proposed are ZrC-ZrB and ZrC-ZrB-SiC composite. These composites can work up to 1800 °C.\n"}
