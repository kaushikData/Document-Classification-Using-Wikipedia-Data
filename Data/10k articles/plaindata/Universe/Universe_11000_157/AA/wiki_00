{"id": "476384", "url": "https://en.wikipedia.org/wiki?curid=476384", "title": "1948 KLM Constellation air disaster", "text": "1948 KLM Constellation air disaster\n\nA KLM Lockheed L-049 Constellation airliner (named \"Nijmegen\" and registered PH-TEN) crashed into high ground near Glasgow Prestwick Airport, Scotland, on 20 October 1948; all 40 aboard died. A subsequent inquiry found that the accident was likely caused by the crew's reliance on a combination of erroneous charts and incomplete weather forecasts, causing the crew to become distracted and disoriented in the inclement conditions.\n\nThe aircraft was piloted by Koene Dirk Parmentier, one of the winners of the MacRobertson Air Race, widely regarded as one of the great flyers of the era, and KLM's chief pilot. The co-pilot on the flight was Kevin Joseph O'Brien.\n\n\"Nijmegen\" was scheduled to fly from its home base at Schiphol Airport near Amsterdam at 8:00 p.m. CET to New York via Prestwick, with Shannon Airport in Ireland as the alternative stopover point in case of bad weather at Prestwick. The plane's departure was delayed as additional cargo was loaded for transport to Iceland, which would be an additional stop en route from Prestwick to New York.\n\nThe plane eventually left Schiphol at 9:10 p.m., crossed the English coast at Flamborough Head and then flew towards Carlisle before turning and flying up the Scottish coast towards Prestwick.\n\nThe weather forecast Parmentier had been given by the Royal Dutch Meteorological Institute at Schiphol had told him that there was some slight cloud at Prestwick, but that it would likely dissipate by the time the \"Nijmegen\" arrived. This report was incorrect; the weather at Prestwick was steadily deteriorating, with the weather at the alternative destination of Shannon even worse.\n\nParmentier believed that there was a strong crosswind, blowing at right-angles to the main runway (Runway 32) at Prestwick of about 20 knots, which might prevent a landing on it. Prestwick had a second, alternative, runway (Runway 26) which was heading into the wind but had no radar-approach system. However, KLM pilot guidelines drafted by Parmentier himself, forbade a landing at Prestwick in low cloud on the alternative runway.\n\nBy the time of approach, Prestwick was under drizzle and a cloud-base that was almost solid at , forecast to continue from about 11:00 p.m. onwards, around the time the \"Nijmegen\" was approaching the airfield. As the flight had taken off late, they had not picked up the radio message broadcast by Prestwick airfield informing them of this. Parmentier was thus unaware of the deterioration in the weather: were he aware of it he would have been able to divert to Shannon. The routine weather reports broadcast from Prestwick had given a cloud cover of . No new forecasts, which would have told Parmentier of the expected decreased cloud cover were broadcast. Nor did he know that already that evening two airliners from SAS had turned back rather than attempt a landing at Prestwick.\n\nInland of the runway was high ground of over , but the KLM-issued charts which the crew were using did not mark any land higher than . Three miles (5 km) to the north-east of the runway, rising to over , were a set of wireless masts. inland ran a series of electricity pylons and high-tension cables, the main national grid line for South Scotland, carrying 132,000 volts. However the error-riddled charts gave the height of the cables at only .\n\nThe plane made radio contact with approach control at Prestwick shortly before 11:00 p.m. At this point the cross-wind over the main runway had, unknown to Parmentier, dropped to 14 knots which made it within limits to attempt a landing on the main runway. Instead, he decided to attempt an overshoot of the main runway guided by the ground radar controller, followed by a left-hand turn that would bring the plane downwind of the alternate runway. He would then overfly the runway before looping round for his final approach. While it might sound complicated, Parmentier expected to be in visual contact with the ground which would make such an attempt relatively easy.\n\nAt 11:16 p.m. Prestwick broadcast a morse message warning of the deteriorating weather, however as the \"Nijmegen\" had now switched over to voice contact the message would not have been received. On the approach they were told of the decreased cross-wind and decided to attempt a landing on the main runway after all. However, three miles out Parmentier decided that the wind was probably too strong for landing on the main runway and decided to overshoot and land on the alternate. He overflew Runway 26, the lights of which he could now see, climbed to a height of and extended the landing gear ready for landing. At this point they ran into what Parmentier believed was an isolated patch of cloud. However this was the actual cloud-base, which was now as low as in some areas. At this point the \"Nijmegen\" was headed directly for the power cables at which the crew believed to be substantially lower.\n\nParmentier realised the 'isolated fog' he had run into was getting denser, but due to his belief that they would have visual contact with the ground the crew had not attempted to time their flight downwind of the runway. Before he could abort the attempt, the plane crashed into the electricity cables, hitting the main phase conductor line. The crew attempted to turn the now burning aircraft towards the runway with the intent of an emergency landing. However, the faulty charts led them to crash into high ground five miles east-north-east of the airfield at about 23:32 UTC.\n\nAll 30 passengers (22 Dutch, 6 German, 1 British and 1 Irish) and the 10 crew died. Rescue services did not reach the crash-site for over one and a half hours due to confusion over which service was responsible for responding to the crash. By the time they arrived only six people were still alive, and all died within 24 hours.\n\nThe subsequent court of enquiry blamed several factors for the crash:\n\nThe enquiry determined the probable cause for the accident was:\nAmong the passengers and crew were:\n\n\n"}
{"id": "22265215", "url": "https://en.wikipedia.org/wiki?curid=22265215", "title": "807 (vacuum tube)", "text": "807 (vacuum tube)\n\nThe 807 is a beam tetrode vacuum tube, widely used in audio- and radio-frequency power amplifier applications.\n\n807s were used in audio power amplifiers, both for public address and hi-fi application, usually being run in push-pull pairs in class AB1 or AB2 giving up to 120 watts of usable power. The plate voltage limit is 750 volts and the screen grid limited to 300 volts. Because of the 300 volt screen grid voltage limit, the 807 cannot be triode connected for high power applications. Failure to observe this precaution will cause screen grid failure. Less commonly a single 807 was used in a pure class-A, single-ended audio output stage delivering about 10 watts.\n\nThe 807 is not a good choice of tube for typical Ultra-Linear amplifier circuits, as the maximum screen voltage at 300 V is less than half the maximum plate voltage of 750 V. A possible solution is to use an output transformer with a separate ultralinear screen winding, such as the Acrosound TO-350.\n\nThe 807 is fully rated to 60 MHz, derated to 55% at 125 MHz in Class C, Plate-modulated operation, thus they were popular with amateur radio operators (radio hams). \nIn this application a single 807 could be run in class-C as an oscillator or amplifier which could be keyed on and off to transmit Morse Code in CW mode. For voice transmission on AM a final amplifier with one or more 807s, up to about four, could be connected in parallel running class-C. Connecting multiple 807s in parallel produced more power to feed to the antenna. Often the modulator stage (simply a transformer-coupled audio amplifier for A.M., with the secondary of its output transformer in series with the anode supply of the final amplifier), was also constructed using 807s. Many hams found multiple paralleled 807s a cheaper alternative to a single larger valve, such as a single 813, as many military surplus 807s became available cheaply after World War II. In Australia 807s are affectionately referred to as \"stubbies\" because they are almost as ubiquitous as that common Australian beer container.\nThe class C operational values in the info box at the right are for \"anode modulated A.M. operation\"; for CW operation a maximum anode voltage of 600 is permissible, whereby the anode current increases to 100 mA and the anode/plate dissipation rises to 25 watts. The screen voltage is the same, at 300, but its dissipation rises to 3.5 watts.\n37 watts of R.F. power is produced from 220 mW of drive but only a 50% duty cycle is allowed. The maximum allowable negative \"control grid, g1\" excursion allowable is -200 volts and average control grid current is 5mA in both A.M. and CW modes.\nLater versions could be used on CW with a supply voltage up to 750 V and a current of 100 mA to produce 50-55 watts of output power.\n\nThe electrically similar 6L6 was not favored by hams because high transient voltages on the anode when operating in class C could cause a flashover between pins 2 and 3 on the octal base, whereas the 807 had the anode connected to a top cap, physically distant from all the base pins.\n\nThe 1624 (VT-165) is an 807 variant with a directly heated filamentary cathode operating at 2.5 V, 2 A.\n\nThe 1625 (VT-136) is an 807 variant with a 12.6 V heater and a 7-pin base. These tubes were used as RF power amplifiers in some of the SCR-274 and AN/ARC-5 \"command set\" transmitters of WW2. Postwar, 1625 tubes flooded the surplus market, and were available for pennies apiece. Surplus 1625s found some commercial use, notably the use of a pair as modulator tubes in the Heathkit DX-100 amateur transmitter.\n\nThe HY-69 is an 807 variant with a 5-pin base and a directly heated filamentary cathode operating at 6.3 V, 1.6 A.\n\nThe 5933/807W is a ruggedized military version of the 807. It uses a shorter, straight-sided T12 bulb, which provides better element support for improved microphonics and shock/vibration resistance.\n\nThe ATS-25 is a military version with ceramic base.\n\nThe Г-807 (G-807) is a Soviet/Russian version. The 6П7С (6P7S) is similar to Г-807, but with an 8-pin octal base.\n\nThe 807 also found some use as a horizontal output tube in early TV receivers, particularly those manufactured by DuMont. The 807 design (with some \"value engineering\" to reduce production cost) was the basis for the first application-specific horizontal sweep tubes such as the 6BG6G and 6CD6G. The redesign mainly involved the omission of some of the internal RF shielding, and the substitution of a bakelite Octal base for the micanol or ceramic 5-pin.\n\nIn turn, these low cost sweep tube derivatives found some use as RF power amplifiers in homebrew amateur radio transmitters in the 1950s.\n\nHam operators in the US sometimes use the term \"807\" to refer to bottles of beer due to the shape of the tube.\n\n"}
{"id": "39207332", "url": "https://en.wikipedia.org/wiki?curid=39207332", "title": "American Brass Superfund site", "text": "American Brass Superfund site\n\nThe American Brass Superfund site is a former industrial site, located in Henry County, Alabama. American Brass Inc. (ABI) operated a brass smelter and foundry facility on the site between 1978-1992. Prior to its closure in December 1992, the company had been cited by the United States Environmental Protection Agency (EPA), and the Alabama Department of Environmental Management, (ADEM), on several occasions for Resource Conservation and Recovery Act (RCRA) violations, arising from its waste and hazardous waste disposal processes. Site surveys, conducted by ADEM after ABI ceased operations, revealed stockpiles of 150,000 tons of contaminated waste, and extensive soil and groundwater contamination. \n\nAfter assessment by the EPA, it was added to the National Priorities List, in May 1999, for long-term remedial action. \n\n"}
{"id": "917505", "url": "https://en.wikipedia.org/wiki?curid=917505", "title": "Belleville washer", "text": "Belleville washer\n\nA Belleville washer, also known as a coned-disc spring, conical spring washer, disc spring, Belleville spring or cupped spring washer, is a conical shell which can be loaded along its axis either statically or dynamically. A Belleville washer is a type of spring shaped like a washer. It is the frusto-conical shape that gives the washer its characteristic spring.\n\nThe \"Belleville\" name comes from the inventor who in Dunkerque, France, in 1867 patented a spring design which already contained the principle of the disc spring. The real inventor of Belleville washers is unknown.\n\nThrough the years, a lot of different profiles for disc springs have been developed. Today the most used are the profiles with or without\ncontact flats, while some other profiles, like disc springs with trapezoidal cross-section, have lost importance.\n\nIn the different fields, if they are used as springs or to apply a flexible pre-load to a bolted joint or bearing, Belleville washers can be used as a single spring or as a stack. In a spring-stack, disc springs can be stacked in the same or in an alternating orientation and of course it is possible to stack packets of multiple springs stacked in the same direction.\n\nDisc springs have a number of advantageous properties compared to other types of springs:\nThanks to these advantageous properties, Belleville washers are today used in a large number of fields, some examples are listed in the following.\n\nIn the arms industry, Belleville springs are used, for instance, in a number of landmines e.g. the American M19, M15, M14, M1 and the Swedish Tret-Mi.59. The target (a person or vehicle) exerts pressure on the belleville spring, causing it to exceed a trigger threshold and flip the adjacent firing pin downwards into a stab detonator, firing both it and the surrounding booster charge and main explosive filling.\n\nBelleville washers have been used as return springs in artillery pieces, one example being the French Canet range of marine/coastal cannon from the late 1800s (75 mm, 120mm, 152 mm).\n\nSome makers of bolt action target rifles use Belleville washer stacks in the bolt instead of a more traditional spring to release the firing pin, as they reduce the time between trigger actuation and firing pin impact on the cartridge.\n\nBelleville washers, without serrations which can harm the clamping surface, have no significant locking capability in bolted applications. \n\nBelleville washers, when used on the mounting bolts, are also useful as an indicator of swelling or shrinkage of wooden propellers on aircraft (typically experimental aircraft). By torquing their associated bolts to provide a specific gap between sets of washers placed with \"high ends\" facing each other, a change in relative moisture content in the propeller wood will result in a change of the gaps which is often great enough to be detected visually. As propeller balance depends on the weight of blades being equal, a radical difference in Belleville washer gaps may indicate a difference in moisture content—and thus weight—in the adjacent blades.\n\nAs they provide extremely detailed tuning ability, disc springs are used in the automotive (even in Formula One cars) and aircraft industries as vibration-damping elements: the Cirrus SR2x series, uses a Belleville washer setup to damp out nose gear oscillations (or \"shimmy\").\n\nIn the building industry, in Japan stacks of disc springs have been used under buildings as vibration dampers for earthquakes.\n\nMultiple Belleville washers may be stacked to modify the spring constant (or spring rate) or the amount of deflection. Stacking in the same direction will add the spring constant in parallel, creating a stiffer joint (with the same deflection). Stacking in an alternating direction is the same as adding common springs in series, resulting in a lower spring constant and greater deflection. Mixing and matching directions allow a specific spring constant and deflection capacity to be designed.\n\nGenerally, if n disc springs are stacked in parallel (facing the same direction), standing the load, the deflection of the whole stack is equal to that of one disc spring divided by n, then, to obtain the same deflection of a single disc spring the load to apply has to be n times that of a single disc spring. On the other hand, if n washers are stacked in series (facing in alternating directions), standing the load, the deflection is equal to n times that of one washer while the load to apply at the whole stack to obtain the same deflection of one disc spring has to be that of a single disc spring divided by n.\n\nIn a parallel stack, hysteresis (load losses) will occur due to friction between the springs. The hysteresis losses can be advantageous in some systems because of the added damping and dissipation of vibration energy. This loss due to friction can be calculated using hysteresis methods. Ideally, no more than 4 springs should be placed in parallel. If a greater load is required, then factor of safety must be increased in order to compensate for loss of load due to friction. Friction loss is not as much of an issue in series stacks\n\nIn a series stack, the deflection is not exactly proportional to the number of springs. This is because of a \"bottoming out\" effect when the springs are compressed to flat as the contact surface area increases once the spring is deflected beyond 95%. This decreases the moment arm and the spring will offer a greater spring resistance. Hysteresis can be used to calculate predicted deflections in a series stack. The number of springs used in a series stack is not as much of an issue as in parallel stacks even if, generally, the stack height should not be greater than three times the outside diameter of the disc spring. If it is not possible to avoid a longer stack, then it should be divided into 2 or possibly 3 partial stacks with suitable washers. These washers should be guided as exactly as possible.\n\nAs previously said, Belleville washers are useful for adjustments because different thicknesses can be swapped in and out and they can be configured to achieve essentially infinite tunability of spring rate while only filling up a small part of the technician's tool box. They are ideal in situations where a heavy spring force is required with minimal free length and compression before reaching solid height. The downside, though, is weight, and they are severely travel limited compared to a conventional coil spring when free length is not an issue.\n\nA wave washer also acts as a spring, but wave washers of comparable size do not produce as much force as Belleville washers, nor can they be stacked in series.\n\nFor disc springs with a thickness of more than 6.0 mm, DIN 2093 specifies small contact surfaces at points I and III (that is the point where the load is applied and the point where the load touches the ground) in addition to the rounded corners. These contact flats improve definition of the point of load application and, particularly for spring stacks, reduce friction at the guide rod. The result is a considerable reduction in the lever arm length and a corresponding increase in the spring load. This is in turn compensated for by a reduction in the spring thickness.\n\nThe reduced thickness is specified in accordance with the following conditions:\nAs the overall height is not reduced, springs with reduced thickness inevitably have an increased flank angle and a greater cone height than springs of the same nominal dimension without reduced thickness. Therefore, the characteristic curve is altered and becomes completely different.\n\nStarting from 1936, when J. O. Almen e A.Làszlò published a simplified method of calculation, always more accurate and complex methods appeared also in order to include in calculations disc springs with contact flats and reduced thickness. So, although today there are more accurate methods of calculation, the most used are the simple and convenient formulas of DIN 2092 as, for standard dimensions, they produce values which correspond well to the measured results.\n\nConsidering a Belleville washer with outside diameter formula_1, inside diameter formula_2, height \"l\" and thickness \"t\", where formula_3 is the free height, that is the difference between the height and the thickness, the following coefficients are obtained:\n\nThe equation to calculate the load to apply to a single disc spring in order to obtain a deflection \"s\" is:\n\nNote that for disc springs with constant thickness, \"t\"' is equal to \"t\" and consequently formula_9 is 1.\n\nFor what concerns disc springs with contact flats and reduced thickness it has to be said that a paper published on July 2013, demonstrated that the formula_9 equation as defined inside the standard norms is not correct as it would result in every reduced thickness being considered right and this is, of course, impossible. As written in that paper formula_9 should be replaced with a new coefficient, formula_12, which depends not only from the formula_13 ratio but also from the flank angles of the spring.\n\nThe spring constant (or spring rate) is defined as:\n\nIf friction and bottoming-out effects are ignored, the spring rate of a stack of identical Belleville washers can be quickly approximated. Counting from one end of the stack, group by the number of adjacent washers in parallel. For example, in the stack of washers to the right, the grouping is 2-3-1-2, because there is a group of 2 washers in parallel, then a group of 3, then a single washer, then another group of 2.\n\nThe total spring coefficient is:\n\nWhere\nSo, a 2-3-1-2 stack (or, since addition is commutative, a 3-2-2-1 stack) gives a spring constant of 3/7 that of a single washer. These same 8 washers can be arranged in a 3-3-2 configuration (K = 6/7formula_19k), a 4-4 configuration (K = 2formula_19k), a 2-2-2-2 configuration (K = 1/2formula_19k), and various other configurations. The number of unique ways to stack \"n\" washers is defined by the integer partition function \"p\"(\"n\") and increases rapidly with large \"n\", allowing fine-tuning of the spring constant. However, each configuration will have a different length, requiring the use of shims in most cases.\n\n"}
{"id": "45011508", "url": "https://en.wikipedia.org/wiki?curid=45011508", "title": "Billiatt Wilderness Protection Area", "text": "Billiatt Wilderness Protection Area\n\nBilliatt Wilderness Protection Area is a protected area located about north of Lameroo in South Australia.\n\nThe wilderness protection area occupies in land in the gazetted localities of Billiatt, Lameroo and Sandalwood.\n\nThe wilderness protection area was proclaimed under the \"Wilderness Protection Act 1992\" on 24 July 2008 on land excised from the Billiatt Conservation Park. \n\nIt is classified as an IUCN Category Ib protected area.\n\n\n"}
{"id": "1665878", "url": "https://en.wikipedia.org/wiki?curid=1665878", "title": "Biocompatibility", "text": "Biocompatibility\n\nBiocompatibility is related to the behavior of biomaterials in various contexts. The term refers to the ability of a material to perform with an appropriate host response in a specific situation. The ambiguity of the term reflects the ongoing development of insights into how biomaterials interact with the human body and eventually how those interactions determine the clinical success of a medical device (such as pacemaker, hip replacement or stent). Modern medical devices and prostheses are often made of more than one material so it might not always be sufficient to talk about the biocompatibility of a specific material.\n\nSince the immune response and repair functions in the body are so complicated it is not adequate to describe the biocompatibility of a single material in relation to a single cell type or tissue. Sometimes one hears of biocompatibility testing that is a large battery of in vitro test that is used in accordance with ISO 10993 (or other similar standards) to determine if a certain material (or rather biomedical product) is biocompatible. These tests do not determine the biocompatibility of a material, but they constitute an important step towards the animal testing and finally clinical trials that will determine the biocompatibility of the material in a given application, and thus medical devices such as implants or drug delivery devices.\n\nThe word \"biocompatibility\" seems to have been mentioned for the first time in peer-review journals and meetings in 1970 by RJ Hegyeli (Amer Chem Soc Annual Meeting abstract) and CA Homsy et al. (J Macromol Sci Chem A4:3,615, 1970). It took almost two decades before it began to be commonly used in scientific literature (see the graph below).\n\nRecently Williams (again) has been trying to reevaluate the current knowledge status regarding what factors determine clinical success. Doing so notes that an implant may not always have to be positively bioactive but it must not do any harm (either locally or systemically) (Williams, 2008).\n\n\n\nAll these definitions deal with materials and not with devices. This is a drawback since many medical devices are made of more than one material. Much of the pre-clinical testing of the materials is not conducted on the devices but rather the material itself. But at some stage the testing will have to include the device since the shape, geometry and surface treatment etc. of the device will also affect its biocompatibility.\n\nIn the literature, one quite often stumbles upon the adjective form, ‘biocompatible’. However, according to Williams’ definition, this does not make any sense because biocompatibility is contextual, i.e. much more than just the material itself will determine the clinical outcome of the medical device of which the biomaterial is a part. This also points to one of the weaknesses with the current definition because a medical device usually is made of more than one material.\n\nMetallic glasses based on magnesium with zinc and calcium addition are tested as the potential biocompatible metallic biomaterials for biodegradable medical implants\n\nThe scope of the first definition is so wide that D Williams tried to find suitable subgroups of applications in order to be able to make more narrow definitions. In the MDT article from 2003 the chosen supgroups and their definitions were:\n\n\n\n\nIn these definitions the notion of biocompatibility is related to devices rather than to materials as compared to top three definitions. There was a consensus conference on biomaterial definitions in Sorrento September 15–16, 2005.\n\n\n"}
{"id": "4862133", "url": "https://en.wikipedia.org/wiki?curid=4862133", "title": "Blowing Stone", "text": "Blowing Stone\n\nThe Blowing Stone is a perforated sarsen at in Kingston Lisle, Oxfordshire (Berkshire until 1974). The stone is in a garden at the foot of Blowingstone Hill just south of the Icknield Way (B4507), about west of Wantage and about east of White Horse Hill.\n\nBlowingstone Hill is part of the escarpment of the Berkshire Downs, at the crest of which is The Ridgeway.\n\nThe stone is capable of producing a booming sound if someone with the required skill blows into one of the holes the right way. According to legend it could be heard atop White Horse Hill, where 19th-century antiquarians thought King Alfred the Great's Saxon troops had camped, and that this was how Alfred summoned them for the Battle of Ashdown against the Danes in AD 871.\n\nThomas Hughes' novel \"Tom Brown's School Days\" refers to it as the \"Blawing Stwun\" and calls the village \"Kingstone Lisle\".\n\nIt is also one of the \"sacred stones\" mentioned in William Horwood's \"Duncton Wood\", the first book in his fantasy fiction series about a group of moles.\n"}
{"id": "744482", "url": "https://en.wikipedia.org/wiki?curid=744482", "title": "Brushed metal", "text": "Brushed metal\n\nBrushed or dull polished metal is metal with a unidirectional satin finish. It is produced by polishing the metal with a 120–180 grit belt or wheel then softening with an 80–120 grit greaseless compound or a medium non-woven abrasive belt or pad.\n\nCommonly brushed metals include stainless steel, aluminium and nickel. Brushed finishes are popular in both small appliances and whiteware, and feature in architecture and automotive design. The Gateway Arch and DeLorean DMC-12 are both clad in brushed stainless steel. The intensity of the brushed finish is specified as a surface roughness and is typically 0.5–1.5 micrometres R.\n\nBrushing gives metal a distinctive look, as it retains some but not all of its metallic lustre and is given a pattern of very fine lines parallel to the brushing direction. For this reason, it is commonly used for decorative items like jewelry and watches.\n\nA brushed finish is susceptible to damage. Brushed finishes also typically have a detrimental effect on corrosion resistance. In particular the brushed texture limits the ability of fluid to bead on the material surface. In the case of stainless steel the grooves of the finish can accumulate chloride ions which break down the chromium oxide passivation layer, enabling rusting to occur.\n"}
{"id": "57530525", "url": "https://en.wikipedia.org/wiki?curid=57530525", "title": "CNP-300", "text": "CNP-300\n\nThe CNP-300 is a pressurized water nuclear reactor developed by the China National Nuclear Corporation.\nIt is China's first commercial nuclear reactor design.\nThe reactor has a thermal capacity of 999 MW and a gross electrical capacity of 325 MW, with a net output of about 300 MWe.\nDevelopment of the reactor began in the 1970s, based on a nuclear submarine reactor design.\nThe first CNP-300 unit started operations in Qinshan Nuclear Power Plant in 1991.\n\nThe CNP-300 was the first Chinese nuclear reactor to be exported, with the installation of the first unit at Chashma Nuclear Power Plant in Pakistan.\nThe unit began operation in 2000.\nAnother unit was completed in 2011 and other two reactors are under construction at the same plant.\n\n"}
{"id": "5362537", "url": "https://en.wikipedia.org/wiki?curid=5362537", "title": "Carbon finance", "text": "Carbon finance\n\nCarbon finance is a branch of environmental finance that covers financial tools such as carbon emission trading to reduce the impact of greenhouse gases (GHG) on the environment by giving carbon emissions a price.\n\nFinancial risks and opportunities impact corporate balance sheets, and market-based instruments are capable of transferring environmental risk and achieving environmental objectives. Issues regarding climate change and GHG emissions must be addressed as part of strategic management decision-making.\n\nThe general term is applied to investments in GHG emission reduction projects and the creation (origination) of financial instruments that are tradeable on the carbon market.\n\nThe market for the purchase of carbon has grown exponentially since its conception in 1996.\n\nThe following is the estimated size of the worldwide carbon market according to the World Bank:\n\nVolume (millions metric tonnes, MtCO2)\n\n\nThe 1997 Kyoto Protocol recognised Clean Development Mechanism (CDM) allowing the offset of emissions in developed countries by the investment in emission reduction projects in developing countries like China, India or Latin America.\n\nJoint Implementation (JI), is another mechanism that allowed investments in developed countries to generate emission credit for the same or another developed country.\n\nThe World Bank has created the World Bank Carbon Finance Unit (CFU). The World Bank CFU uses money contributed by governments and companies in OECD countries to purchase project-based greenhouse gas emission reductions in developing countries and countries with economies in transition. The emission reductions are purchased through one of the CFU's carbon funds on behalf of the contributor, and within the framework of the Kyoto Protocol's Clean Development Mechanism (CDM) or Joint Implementation (JI). The World Bank is particularly supportive of Program of Activities (PoA) development.\n\n\n"}
{"id": "21193982", "url": "https://en.wikipedia.org/wiki?curid=21193982", "title": "Charcoal", "text": "Charcoal\n\nCharcoal is the lightweight black carbon and ash residue hydrocarbon produced by removing water and other volatile constituents from animal and vegetation substances. Charcoal is usually produced by slow pyrolysis — the heating of wood or other substances in the absence of oxygen. This process is called charcoal burning. The finished charcoal consists largely of carbon.\n\nThe advantage of using charcoal instead of just burning wood is the removal of the water and other components. This allows charcoal to burn to a higher temperature, and give off very little smoke (regular wood gives off a good amount of steam, organic volatiles, and unburnt carbon particles — soot — in its smoke).\n\nHistorically, the production of wood charcoal in locations where there is an abundance of wood dates back to a very ancient period, and generally consists of piling billets of wood on their ends so as to form a conical pile, openings being left at the bottom to admit air, with a central shaft to serve as a flue. The whole pile is covered with turf or moistened clay. The firing is begun at the\nbottom of the flue, and gradually spreads outwards and upwards. The success of the operation depends upon the rate of the combustion. Under average conditions, 100 parts of wood yield about 60 parts by volume, or 25 parts by weight, of charcoal; small-scale production on the spot often yields only about 50%, while large-scale became efficient to about 90% even by the seventeenth century. The operation is so delicate that it was generally left to colliers (professional charcoal burners). They often lived alone in small huts in order to tend their wood piles. For example, in the Harz Mountains of Germany, charcoal burners lived in conical huts called \"Köten\" which are still much in evidence today.\nThe massive production of charcoal (at its height employing hundreds of thousands, mainly in Alpine and neighbouring forests) was a major cause of deforestation, especially in Central Europe. In England, many woods were managed as coppices, which were cut and regrown cyclically, so that a steady supply of charcoal would be available (in principle) forever; complaints (as early as the Stuart period) about shortages may relate to the results of temporary over-exploitation or the impossibility of increasing production to match growing demand. The increasing scarcity of easily harvested wood was a major factor behind the switch to fossil fuel equivalents, mainly coal and brown coal for industrial use.\n\nThe modern process of carbonizing wood, either in small pieces or as sawdust in cast iron retorts, is extensively practiced where wood is scarce, and also for the recovery of valuable byproducts (wood spirit, pyroligneous acid, wood tar), which the process permits. The question of the temperature of the carbonization is important; according to J. Percy, wood becomes brown at 220 °C (428 °F), a deep brown-black after some time at 280 °C (536 °F), and an easily powdered mass at 310 °C (590 °F). Charcoal made at 300 °C (572 °F) is brown, soft and friable, and readily inflames at 380 °C (716 °F); made at higher temperatures it is hard and brittle, and does not fire until heated to about 700 °C (1,292 °F).\n\nIn Finland and Scandinavia, the charcoal was considered the by-product of wood tar production. The best tar came from pine, thus pinewoods were cut down for tar pyrolysis. The residual charcoal was widely used as substitute for metallurgical coke in blast furnaces for smelting. Tar production led to rapid local deforestation. The end of tar production at the end of the 19th century resulted in rapid re-forestation of affected areas.\n\nThe charcoal briquette was first invented and patented by Ellsworth B. A. Zwoyer of Pennsylvania in 1897 and was produced by the Zwoyer Fuel Company. The process was further popularized by Henry Ford, who used wood and sawdust byproducts from automobile fabrication as a feedstock. Ford Charcoal went on to become the Kingsford Company.\n\nCharcoal has been made by various methods. The traditional method in Britain used a clamp. This is essentially a pile of wooden logs (e.g. seasoned oak) leaning against a chimney (logs are placed in a circle). The chimney consists of 4 wooden stakes held up by some rope. The logs are completely covered with soil and straw allowing no air to enter. It must be lit by introducing some burning fuel into the chimney; the logs burn very slowly and transform into charcoal in a period of 5 days' burning. If the soil covering gets torn (cracked) by the fire, additional soil is placed on the cracks. Once the burn is complete, the chimney is plugged to prevent air from entering.\nThe true art of this production method is in managing the sufficient generation of heat (by combusting part of the wood material), and its transfer to wood parts in the process of being carbonised. A strong disadvantage of this production method is the huge amount of emissions that are harmful to human health and the environment (emissions of unburnt methane). As a result of the partial combustion of wood material, the efficiency of the traditional method is low.\n\nModern methods employ retorting technology, in which process heat is recovered from, and solely provided by, the combustion of gas released during carbonisation. (Illustration:). Yields of retorting are considerably higher than those of kilning, and may reach 35%-40%.\n\nThe properties of the charcoal produced depend on the material charred. The charring temperature is also important. Charcoal contains varying amounts of hydrogen and oxygen as well as ash and other impurities that, together with the structure, determine the properties. The approximate composition of charcoal for gunpowders is sometimes empirically described as CHO. To obtain a coal with high purity, source material should be free of non-volatile compounds.\n\n\nCharcoal has been used since earliest times for a large range of purposes including art and medicine, but by far its most important use has been as a metallurgical fuel. Charcoal is the traditional fuel of a blacksmith's forge and other applications where an intense heat is required. Charcoal was also used historically as a source of black pigment by grinding it up. In this form charcoal was important to early chemists and was a constituent of formulas for mixtures such as black powder. Due to its high surface area charcoal can be used as a filter, and as a catalyst or as an adsorbent.\n\nCharcoal burns at temperatures exceeding . By comparison the melting point of iron is approximately . Due to its porosity, it is sensitive to the flow of air and the heat generated can be moderated by controlling the air flow to the fire. For this reason charcoal is still widely used by blacksmiths. Charcoal has been used for the production of iron since Roman times and steel in modern times where it also provided the necessary carbon. Charcoal briquettes can burn up to approximately with a forced air blower forge.\n\nIn the 16th century, England had to pass laws to prevent the country from becoming completely denuded of trees due to production of iron. In the 19th century charcoal was largely replaced by coke, baked coal, in steel production due to cost.\n\nHistorically, charcoal was used in great quantities for smelting iron in bloomeries and later blast furnaces and finery forges. This use was replaced by coke in the 19th Century as part of the Industrial Revolution.\n\nPrior to the Industrial Revolution, charcoal was occasionally used as a cooking fuel. Modern \"charcoal briquettes\", widely used for outdoor cooking, are made with charcoal but may also include coal as an energy source as well as accelerants, binders and filler.\n\nLike many other sources of carbon, charcoal can be used for the production of various syngas compositions; i.e., various CO + H + CO + N mixtures. The syngas is typically used as fuel, including automotive propulsion, or as a chemical feedstock.\n\nIn times of scarce petroleum, automobiles and even buses have been converted to burn wood gas (a gas mixture consisting primarily of diluting atmospheric nitrogen, but also containing combustible gasses, mostly carbon monoxide) released by burning charcoal or wood in a wood gas generator. In 1931 Tang Zhongming developed an automobile powered by charcoal, and these cars were popular in China until the 1950s and in occupied France during World War II (called \"gazogènes\").\n\nCharcoal is used in the production of black powder, which is used extensively in the production of fireworks. It is usually ground into a fine powder, with airfloat grade being the finest particle size available commercially. When used in black powder compositions, it is often ball-milled with other ingredients so that they are intimately mixed together. Certain charcoals perform better when used to make black powder, these include spruce, willow, paulownia and grapevine among others.\n\nCharcoal has started to become popular as a cosmetic product with multiple uses. It is created by obtaining regular bamboo, cut down into smaller pieces and then boiled in distilled water to wash it. Then it is dried out, carbonized in an oven (at roughly 800-1200 degrees Celsius) for many hours and results in raw bamboo charcoal. The use of charcoal in beauty routines intends to utilize its highly effective absorbing properties at a microscopic-scale.\n\nCharcoal may be used as a source of carbon in chemical reactions. One example of this is the production of carbon disulphide through the reaction of sulfur vapors with hot charcoal. In that case the wood should be charred at high temperature to reduce the residual amounts of hydrogen and oxygen that lead to side reactions.\n\nCharcoal may be \"activated\" to increase its effectiveness as a filter. Activated charcoal readily adsorbs a wide range of organic compounds dissolved or suspended in gases and liquids. In certain industrial processes, such as the purification of sucrose from cane sugar, impurities cause an undesirable color, which can be removed with activated charcoal.\nIt is also used to absorb odors and toxins in gases, such as air. Charcoal filters are also used in some types of gas masks. The medical use of activated charcoal is mainly the absorption of poisons. Activated charcoal is available without a prescription, so it is used for a variety of health-related applications. For example, it is often used to reduce discomfort and embarrassment due to excessive gas (flatulence) in the digestive tract.\n\nAnimal charcoal or bone black is the carbonaceous residue obtained by the dry distillation of bones. It contains only about 10% carbon, the remainder being calcium and magnesium phosphates (80%) and other inorganic material originally present in the bones. It is generally manufactured from the residues obtained in the glue and gelatin industries. Its decolorizing power was applied in 1812 by Derosne to the clarification of the syrups obtained in sugar refining; but its use in this direction has now greatly diminished, owing to the introduction of more active and easily managed reagents. It is still used to some extent in laboratory practice. The decolorizing power is not permanent, becoming lost after using for some time; it may be revived, however, by washing and reheating. Wood charcoal also to some extent removes coloring material from solutions, but animal charcoal is generally more effective.\n\nCharcoal is used in art for drawing, making rough sketches in painting and is one of the possible media for making a parsemage. It must usually be preserved by the application of a fixative. Artists generally utilize charcoal in three forms:\n\nOne additional use of charcoal was rediscovered recently in horticulture. Although American gardeners have been using charcoal for a short while, research on Terra preta soils in the Amazon has found the widespread use of biochar by pre-Columbian natives to turn unproductive soil into carbon rich soil. The technique may find modern application, both to improve soils and as a means of carbon sequestration.\n\nCharcoal was consumed in the past as dietary supplement for gastric problems in the form of charcoal biscuits. Now it can be consumed in tablet, capsule or powder form, for digestive effects. Research regarding its effectiveness is controversial.\nTo measure the mucociliary transport time the use was introduced by Passali in combination with saccharin.\n\nRed colobus monkeys in Africa have been observed eating charcoal for the purposes of self-medication. Their leafy diets contain high levels of cyanide, which may lead to indigestion. So they learned to consume charcoal, which absorbs the cyanide and relieves indigestion. This knowledge about supplementing their diet is transmitted from mother to infant.\n\nCharcoal has also been incorporated in toothpaste formulas; however, there is no evidence to determine its safety and effectiveness.\n\nThe use of charcoal as a smelting fuel has been experiencing a resurgence in South America resulting in severe environmental, social and medical problems. Charcoal production at a sub-industrial level is one of the causes of deforestation. Charcoal production is now usually illegal and nearly always unregulated as in Brazil where charcoal production is a large illegal industry for making pig iron.\n\nMassive forest destruction has been documented in areas such as Virunga National Park in the Democratic Republic of Congo, where it is considered a primary threat to the survival of the mountain gorillas. Similar threats are found in Zambia. In Malawi, illegal charcoal trade employs 92,800 workers and is the main source of heat and cooking fuel for 90 percent of the nation's population. Some experts, such as Duncan MacQueen, Principal Researcher–Forest Team, International Institute for Environment and Development (IIED), argue that while illegal charcoal production causes deforestation, a regulated charcoal industry that required replanting and sustainable use of the forests \"would give their people clean efficient energy – and their energy industries a strong competitive advantage\".\n\nThe last section of the film \"Le Quattro Volte\" (2010) gives a good and long, if poetic, documentation of the traditional method of making charcoal. The Arthur Ransome children's series \"Swallows and Amazons\" (particularly the second book, \"Swallowdale\") features carefully-drawn vignettes of the lives and the techniques of charcoal burners at the start of the 20th century, in the Lake District of the UK.\n\n"}
{"id": "26588267", "url": "https://en.wikipedia.org/wiki?curid=26588267", "title": "Clean Energy Expo Asia", "text": "Clean Energy Expo Asia\n\nThe Clean Energy Expo Asia is a trade fair and conference which takes place annual during Singapore International Energy Week (SIEW).\n\nIt was held for the first time at SIEW 2009 It featured five pavilions, showcasing clean energy developments from Australia, Brazil, Europe, Japan and Singapore. The Energy Market Authority's Deputy Chief Executive, David Tan, delivered an address at the Expo.\n\nThe second Expo will take place at SIEW 2010.\n"}
{"id": "46564590", "url": "https://en.wikipedia.org/wiki?curid=46564590", "title": "Dicyanamide", "text": "Dicyanamide\n\nDicyanamide is also known as dicyanamine. The dicyanamide ion is a chemical having the formula . It contains two cyanide groups bound to a central nitrogen anion. The chemical is formed by decomposition of 2-cyanoguanidine. It is used extensively as a counterion of organic and inorganic salts, and also as a reactant for the synthesis of various covalent organic structures.\n\nDicyanimide was used as an anionic component in an organic superconductor that was, when reported in 1990, a superconductor with the highest transition temperature in its structural class. Dean Kenyon has examined the role of this chemical in reactions that can produce peptides. A co-worker then considered this reactive nature and examined the possible role dicyanamide may have had in primordial biogenesis.\n"}
{"id": "1065861", "url": "https://en.wikipedia.org/wiki?curid=1065861", "title": "Drop tank", "text": "Drop tank\n\nIn aviation, a drop tank (external tank, wing tank, or belly tank) is used to describe auxiliary fuel tanks externally carried by aircraft. A drop tank is expendable and often jettisonable. External tanks are commonplace on modern military aircraft and occasionally found in civilian ones, although the latter are less likely to be discarded except in the event of emergency.\n\nThe primary disadvantage with drop tanks is that they impose a drag penalty on the aircraft carrying them. External fuel tanks will also increase the moment of inertia, thereby reducing roll rates for air maneuvres. Some of the drop tank's fuel is used to overcome the added drag and weight of the tank itself. Drag in this sense varies with the square of the aircraft's speed. The use of drop tanks also reduces the number of external hardpoints available for weapons, reduces the weapon-carrying capacity, and increases the aircraft's radar signature.\n\nUsually the fuel in the drop tanks is consumed first, and only when all the fuel in the drop tanks has been used, the fuel selector is switched to the airplane's internal tanks.\n\nSome modern combat aircraft use conformal fuel tanks (CFTs) instead of or in addition to conventional external fuel tanks. CFTs produce less drag and do not take up external hardpoints; however, some versions can only be removed on the ground.\n\nThe drop tank was used during the Spanish Civil War to allow fighter aircraft to carry additional fuel for long-range escort flights without requiring a dramatically larger, heavier, less maneuverable fuselage. During World War II, the German Luftwaffe began using external fuel tanks with the introduction of a 300-liter (80 US gallon) light alloy model for the Ju 87R, a long-range version of the \"Stuka\" dive bomber, in early 1940. The Messerschmitt Bf 109 fighter also used this type of drop tank, starting with the Bf 109E-7 variant introduced in August 1940. Fitted also to the Focke-Wulf Fw 190, the 300 liter tank, available in at least four differing construction formats — including at least one impregnated paper material, single-use version — and varying only slightly in appearance, became the standard volume for most subsequent drop tanks in Luftwaffe service, with a rarely used 900 litre (238 U.S. gallon), fin-stabilized large capacity drop tank used with some marks of the Messerschmitt Bf 110 heavy fighter and other twin-engined Luftwaffe combat aircraft.\n\nThe first drop tanks were designed to be discarded when empty or in the event of combat or emergency in order to reduce drag, weight, and to increase maneuverability. Modern external tanks may be retained in combat, to be dropped in an emergency.\n\nThe Allies commonly used them to allow fighters increased range and patrol time over continental Europe. The RAF used such external fuel tanks in 1942, during the transit of Supermarine Spitfires to Malta.\n\nThe Imperial Japanese navy design specification for what came to be the Japanese Mitsubishi A6M Zero fighter, included endurance with drop tanks of two hours at full power, or six to eight hours at cruising speed. Drop tanks were commonly used with the Zero, even on Combat Air Patrol (CAP). The Zero entered service in 1940.\n\nBomber theorists insisted formations of heavy bombers with elaborate defensive armaments would be self-defending, believing long-range escort fighters to be \"a myth\" as they could be easily forced to drop the tanks by minor harassment at the beginning of the raid being more concerned that long-range medium bombers might compete for resources and so compromise their goal of creating vast fleets of heavy bombers.\n\nIn the face of such entrenched attitudes in 1941 airmen such as Benjamin S. Kelsey and Oliver P. Echols worked quietly to get drop tank technology added to American fighters such as the Lockheed P-38 Lightning.\n\nIt was only with drop tanks supplying of extra fuel per fighter that P-38s could carry out Operation Vengeance, the downing of Admiral Isoroku Yamamoto's airplane. (For this mission, each fighter carried one drop tank of approximately , and a larger one of approximately .\n\nEven after such experience showed the necessity for drop tanks, inflexible thinkers such as 8th Air Force General Ira C. Eaker had to be transferred out of commanding positions (and replaced with Maj. Gen. Jimmy Doolittle) so that drop tanks and range extension plans could be widely implemented in 1944 for American escort fighters.\n\nExternal drop tanks turned the Republic P-47 Thunderbolt from a short-range interceptor aircraft into a long-range escort and air superiority fighter, enabling it to accompany bombers from British Isles into Germany, and made it possible for heavy bomber formations to undertake daylight raids under escort by North American P-51 Mustangs.\n\nThe P-38 could also carry two 300-to-330-gallon drop tanks for its longest sorties. This teardrop-shaped tank design was long and in diameter at its widest point.\n\nFaced by wartime metal shortages and a need to extend the range of fighter craft, the British came up with drop tanks made of glue-impregnated kraft paper, which had excellent tolerance characteristics for extreme heat and cold necessary for operation on an aircraft as well as being waterproof.\n\nSince the glue would slowly dissolve from the solvent effects of the fuel (sometimes developing leaks within a few hours of being loaded with fuel) these were strictly a single-use item, used in typically chilly Northern European conditions, filled immediately before take off, jettisoned in the event of an aborted mission and only being required for the outbound portion of any flight.\n\nSuch papier-mâché tanks were assembled from three main components, the nose cone, tail cone and the body, each shaped over wooden forms, the centre section created by wrapping layers of the impregnated paper around a cylinder, the end caps hand-laminated with petal-shaped pieces sometimes named gores.\n\nBefore final assembly wooden anti-slosh baffles were installed, pipes and fittings were attached and the interiors coated with fuel-resistant lacquer and the three pieces were bonded together in press. Once the tank had cured, it was pressure tested to 6 PSI and passing tanks were given two coats of cellulose dope followed by two coats of aluminium paint. (British drop tanks can be distinguished from outwardly similar metal tanks by colour, paper tanks were silver in appearance, while metal tanks were grey.\n\nSome 13,000 papier-mâché tanks were made and used by the RAF, the vast majority used in the course of the war, conserving a considerable amount of metal. Very few examples survive due to their expendable nature and low intrinsic value at the time of their creation, and the fact that they are not inherently robust. While probably a nuisance for those under the flight path when the empty tanks were released, as they were lightweight and comparatively fragile it is unlikely to cause anything but anxiety, the Germans authorities going so far as to distribute leaflets, explaining that drop tanks are not bombs.\nU.S. paper tanks were developed by Col. Bob Shafer and Col. Cass Hough, who spent many hours developing a 110-gallon (416 litre) paper tank, then getting them into series production at Bowater-Lloyd's of London, only to be told by experts at Wright Field \"paper tanks are absolutely unfeasible and will not do the job for which they are intended\". Since by the time the experts made that pronouncement 8th Air Force fighters had already used more than 15,000 paper tanks without a failure, the criticism was not taken seriously.\n\nHowever it may explain why the most often-used fuel tanks for single-engined American fighters operating in Northern Europe were the 75-gallon (284 litre) capacity all-metal tank (made from two halves of formed aluminium with a prominent horizontal seam running along the tank's midline). Another common metal drop tank was the 150-to-165-gallon model used by P-51s, P-47s and P-38s.\n\nThe Matra JL-100 is a special hybrid drop tank and rocket pack; it combines a rocket launcher in front with 19 SNEB rockets and of fuel behind into one single aerodynamically-shaped pod for mounting on combat aircraft such as the Dassault Mirage IIIs and English Electric Lightnings.\n\nAfter World War II, hot rodders raced the dry lakes of California to set new land speed records. War surplus drop tanks were plentiful and aerodynamically neutral, and it didn't take long to make one into a car, dubbed a lakester. According to GM historians, Bill Burke of the So-Cal Speed Shop first attempted to convert a 168-gallon P-51 Mustang belly tank, before switching to the larger 305-gallon P-38 Lightning tank. Even now, lakesters compete at the Bonneville Salt Flats.\n"}
{"id": "50338185", "url": "https://en.wikipedia.org/wiki?curid=50338185", "title": "Electro-Dynamic Light Company", "text": "Electro-Dynamic Light Company\n\nThe Electro-Dynamic Light Company of New York was a lighting and electrical distribution company organized in 1878. The company held the patents for the first practical system of incandescent electric lighting. It was the first company formally established to provided electric lightning and was the first company organized specifically to manufacture and sell incandescent electric light bulbs. \n\nAlbon Man, a New York attorney, and William E. Sawyer, an electrical engineer, officially formed the Electro-Dynamic Light Company of New York on July 8, 1878. \nThis was by way of a partnership with Man supplying money for experiments. Sources in the late 19th century claimed it to be the first formally established electric-lighting company. \n\nThe Electro-Dynamic Light Company was the first organized specifically to manufacture and sell incandescent electric light bulbs. Man and Sawyer patented the first practical system of incandescent electric lighting and gave the patents to the company. The United States Electric Lighting Company was organized in 1878, weeks after the Electro-Dynamic Company.\n\nThe names of other investor-partners of the company besides Man and Sawyer were: Hugh McCulloch (Man's uncle), William Hercules Hays, James P. Kernochan, Lawrence Myers, and Jacob Hays. Sawyer was about 28 years old and Man about 52 years old at the time the company was formed. They planned on lighting New York City with electricity for one-fortieth the cost of gas lighting. The new company started with capital of $10,000 cash and $290,000 of scrip. It was formed for the purpose of the production of light and power by means of electricity for the lighting of streets and buildings. The company was to make all the equipment necessary to generate and distribute electricity. The distribution of electricity produced by the company was not only for lighting, but for other purposes as well.\n\nIn 1878, the Electro-Dynamic Light Company demonstrated an electric light that was the invention of Sawyer and Man. An exhibition was set up in New York City on October 29, 1878. The same exhibition was mentioned several weeks later in a newspaper of Princeton, Minnesota, and Bismarck, North Dakota. The lamp was described as a strip of pencil carbon graphite connected with two wires to an electric generator. The carbon strip was in a hermetically sealed glass bulb that was filled with nitrogen gas. When electricity was applied, the internal strip developed a temperature of between 30,000 and 50,000 degrees Fahrenheit. Since there was no oxygen in the glass globe the carbon filament did not burn out and produced light instead.\n\nThe demonstration consisted of five electric light bulbs hanging from chandeliers in an office building at the corner of Elm and Walker Streets. Wires came from the electric lights and went to an adjacent room where there was a generator set up to produce electricity. The wires passed through keyholes to the adjoining room. A key was put into the keyhole and turned to switch on the electric current. As the key was turned further around, the electric lights got brighter. This switch idea was demonstrated with all five chandeliers with the electric lamps. An electric meter to measure the amount of electricity used in an office or house for billing purposes was also demonstrated.\n\nThomas Edison's electric lighting discoveries were first shown in September 1878. The Edison Electric-Light Company of New York was organized on October 17, three months after the Electro-Dynamic Company was formally established. The United States Electric-Lighting Company of New York was formed shortly after this to introduce the inventions of Hiram S. Maxim and Edward Weston.\n\nPatents were taken out by Man and Sawyer for all the items needed for electric current distribution. The patents were for the benefit of the Electro-Dynamic Light Company of New York. Man and Sawyer were involved in many legal actions between 1880 and 1884 to protect these patents for electric lighting.\n\nThe Electro-Dynamic Light Company ceased to exist after 1881.\n\n"}
{"id": "1044743", "url": "https://en.wikipedia.org/wiki?curid=1044743", "title": "Erle P. Halliburton", "text": "Erle P. Halliburton\n\nErle Palmer Halliburton (September 22, 1892, near Henning, Tennessee – October 13, 1957, in Los Angeles) was an American businessman specializing in the oil business.\n\nHalliburton was born in Henning, Tennessee, on September 22, 1892. When Halliburton was 12 years old, his father died. At 14, Halliburton left home to support the family. As a youth, he learned how to operate heavy machinery such as a train locomotive, a steam crane and a steam shovel. Later, Halliburton was a salesman in New York.\n\nPrior to the United States's entry into World War I, Halliburton gained exposure to shipboard engineering as a member of the United States Navy. After his honorable discharge in 1915, he headed for the oilfields of California, where he was able to apply techniques analogous to the technology with which he had worked in the Navy. His drive and his sense of innovation soon brought him into conflict with his boss, Almond Perkins. Halliburton later quipped that getting hired and getting fired by the Perkins Oil Well Cementing Company were the two best opportunities he had ever received.\n\nHalliburton then moved to Duncan, Oklahoma where Halliburton invented, perfected, and patented a new method of oil well cementing. According to one of the inscriptions on the pictured monument, Halliburton's method \"isolates the various downhole zones, guards against collapse of the casing and permits control of the well during its producing life.\" In 1919, based on this new method, Halliburton started Duncan's New Method Oil Well Cementing Company. By 1922, the company was operating as the Halliburton Oil Well Cementing Company. On July 5, 1961, it became known as the Halliburton Company.\n\nHalliburton also designed the aluminum suitcases which are now manufactured by Zero Halliburton.\nHalliburton was inducted into the Oklahoma Hall of Fame in 1957.\n\nHalliburton was married to Vida C. Taber Halliburton, but had a few children out of wedlock. Edith Edna Cole, an office employee at the Duncan headquarters gave birth to Carl Thurlo in 1933 after an extensive affair with Erle. Carl is one of a few extramarital children, including Edith's grand daughter, Shirley Kaye, born in 1941, to Memory, oldest daughter of Edith. Memory was 14 at the time of the affair. Memory settled a paternity and support lawsuit in Los Angeles in the 1940's. Shirley Kaye received a cash settlement in 1968. Another child, Billie Jean Thurlo, born in 1930, is said to also be a daughter of Edith Edna Cole and Erle P. Halliburton. Edith Edna Cole was married to MM Bloomfield, Perry Eaton and William Graham. There is a record of Edith Edna Cole being married to William \"Bill\" Thurlo, but there are no birth certificates for Billie Jean and Carl. Edith Edna Cole Bloomfield Thurlo's children; Memory, Inez, Joe Ben, Billie Jean, Carl and Marshal, were born in Duncan, OK. between 1918 and 1941. \n\nIn 1941, Halliburton provided cash for an 80 acre plot of land for Edith Edna Cole and her children near Kingston, OK along the shores of Lake Texoma. Halliburton planned a resort with cabin cruiser boat themed cabins as guest units at Lake Texoma, but it was never built. Halliburton visited Edith and the children in Kingston a few times in the 1940's before Memory moved Shirley to Dayton, OH. Edna married Perry Eaton in 1940 and had two sons with him; James Lee Eaton and Earl P. Eaton. Eaton adopted the older children. Eaton farmed the land and took care of the children in Kingston while Edith worked in Oklahoma City in the aircraft industry during WWII. <ref>Interviews with Carl Thurlo and Billie Jean Thurlo Valentine, Ancestry.com<ref>\n\n"}
{"id": "5507816", "url": "https://en.wikipedia.org/wiki?curid=5507816", "title": "Fibrillogenesis", "text": "Fibrillogenesis\n\nFibrillogenesis is the development of fine fibrils normally present in collagen fibers of connective tissue. It is derived from the Greek \"fibrillo\" (meaning fibrils, or pertaining to fibrils) and \"genesis\" (to create, the process by which something is created).\n\nThe assembly of collagen fibrils, fibrillogenesis appears to be a self-assembly process although there is much speculation about the specifics of the mechanism through which the body produces collagen fibrils. In the body, collagen fibrils are composed of several types of collagen as well as macromolecules. Collagen I is the most abundant structural macromolecule within the vertebrate body and also represents the most abundant collagen found within various collagen fibrils There are immense differences in the types of collagen fibrils that exist within the body. For instance, fibrils within the tendon vary in width and are banded into aggregates that form fibril bundles that resist forces of tension within one dimension. Similarly, fibrils that form the translucent corneal stromal matrix form orthogonal sheets and withstand the force of traction in two dimensions. Remarkably, these two structurally different collagen fibrils are speculated to be formed from the same molecules with Collagen I being the primary collagen found within both structures.\n\nThere is no concrete evidence or agreement on the exact mechanisms of Fibrillogenesis, however, multiple hypotheses based on primary research put forth various mechanisms to consider. Collagen fibrillogenesis occurs in the plasma membrane during embryonic development. Collagen within the body has a denaturation temperature between 32-40 degrees Celsius, the physiological temperature also falls within this range and thereby poses a significant problem. It is therefore a mystery how collagen survives within the tissues in order to yield itself to the formation of collagen fibrils. A postulated solution to the problem of denaturation based on current research, is that newly formed collagen gets stored in vacuoles. The storage vacuoles also contain molecular aggregates that provide the required thermal stability to allow for fibrillogenesis to occur within the body. In the body, fibrillar collagens have over 50 known binding partners. The cell accounts for the variety of binding partners through the localization of the fibrillogenesis process to the plasma membrane in order to maintain control of which molecules bind to each other and further ensure both fibril diversity and assemblies of certain collagen fibrils in different tissues Kader, Hill, and Canty-Larid published a plausible mechanism for the formation of collagen fibrils. Fibronectin a glycoprotein that binds to receptor proteins known as integrins within the cytoskeleton is a key player in the hypothesized method of fibrillogenesis. The interaction between fibronectin and the integrin receptor causes a conformational change in the fibronectin. Additional receptors bind to fibronectin bringing in Collagen I, procollagen I and collagen V. These molecules interact with fibronectin to promote fibril formation on the surface of the cell.\n\nBased on research done using Mice and studies of Ehlers-Danlos Syndrome (EDS), which is characterized by hypermobility of the joints and high levels of skin laxtivity, researcher found that Tenascin-X expression levels correlated with the number of present collagen fibrils. In humans, Tenasin-X is associated with EDS. Through their research, researcher confounded the original hypothesis that tenasin-x interfered with collagen fibrillogenesis and suggest that it acts rather as a regulator of collagen fibrillogenesis. Data suggest tenasin-x is a regulator of collagen fibril spacing. In vitro tests yield evidence that suggest tenasin-x accelerates collagen fibril formation through an additive mechanism when collagen VI is present. In addition to tenasin-x, multiple proteins, glycoconjugates, and small molecules have shown to influence not only the rate of collagen fibrillogenesis, but also the structure of collagen fibrils as well as their size in lab studies.\n\nA better understanding of the mechanisms of collagen fibrillogenesis as well as an understanding of the regulators of the process would allow for a better understanding of diseases that affect collagen fibril formation and assembly such as Ehlers-Danlos Syndrome (EDS). On a broader spectrum, an understanding of the processes that lie behind fibrillogenesis would allow for great advancements in the field of regenerative medicine. A greater understanding would lead to a potential future in which organs and tissue damaged through trauma could be regenerated using the basis of collagen fibrillogenesis.\n\n"}
{"id": "14582040", "url": "https://en.wikipedia.org/wiki?curid=14582040", "title": "Follow the Rabbit-Proof Fence", "text": "Follow the Rabbit-Proof Fence\n\nFollow the Rabbit-Proof Fence is an Australian book by Doris Pilkington, published in 1996. Based on a true story, the book is a personal account of an indigenous Australian family's experiences as members of the Stolen Generation – the forced removal of mixed-race children from their families during the early 20th century. It tells the story of three young Aboriginal girls: Molly (the author's mother), Daisy (Molly's half-sister), and Gracie (their cousin), who are forcibly removed from their families at Jigalong and taken to Moore River, but escape from the government settlement in 1931, and then trek over home by following the rabbit-proof fence, a massive pest-exclusion fence which crossed Western Australia from north to south.\n\nThe book was adapted as a film, \"Rabbit-Proof Fence\", in 2002.\n\nDoris Pilkington had spent much of her early life from the age of four at the Moore River Native Settlement in Western Australia, the same facility the book chronicles her mother, aunt's and cousin's escape from as children. After reuniting with her family, Pilkington says she did not talk to her mother much, and she was not aware of her mother's captivity at Moore River nor the story of her escape, until her Aunt Daisy told her the story. Repeating the story at an Aboriginal family history event in Perth, one of the attendees told Pilkington he was aware of the story and that the case was fairly well-documented. He gave her some documents and clippings which formed the factual backbone of the story on which Pilkington based a first draft.\n\nPilkington submitted the draft to a publisher in 1985 but was told it was too much like an academic paper and that she should try her hand at writing fiction. Her first novel, \"Caprice, A Stockman's Daughter\", won the David Unaipon Literary Award and was published in 1990 by the University of Queensland Press. Pilkington then rewrote and filled out \"Follow the Rabbit-Proof Fence\" following several years of interviewing her mother and aunt, and it was published in 1996.\n\nMolly, her half-sister Daisy and their cousin Gracie are taken to Moore River for schooling to become more like a white person and to eventually be taken to a (more) rural part of Western Australia. The girls escaped from the Settlement and took the 1,600km walk home.\n\nShortly after the book's publication, the film rights were obtained by scriptwriter Christine Olsen, who wrote the script and was persistent in her pitching of the film to Hollywood-based Australian director Phillip Noyce. Noyce agreed to direct the film, which was released in 2002 and starred Everlyn Sampi as Molly, and British actor Kenneth Branagh as A. O. Neville, the Chief Protector of Aborigines.\n"}
{"id": "12244833", "url": "https://en.wikipedia.org/wiki?curid=12244833", "title": "Foot-poundal", "text": "Foot-poundal\n\nThe foot-poundal (symbol: ft-pdl) is a unit of energy that is part of the foot-pound-second system of units, in Imperial units introduced in 1879, and is from the specialized subsystem of English Absolut (a coherent system).\n\nThe foot-poundal is equal to 1/32.174049 that of the more commonly used foot-pound force.\n\n1 foot-poundal is equivalent to:\n\n"}
{"id": "12614260", "url": "https://en.wikipedia.org/wiki?curid=12614260", "title": "Gobius hypselosoma", "text": "Gobius hypselosoma\n\nGobius hypselosoma is a species of goby native to fresh and brackish waters of Madagascar and the Mascarene Islands. It can reach a length of TL.\n"}
{"id": "17593156", "url": "https://en.wikipedia.org/wiki?curid=17593156", "title": "Håvard Kjærstad", "text": "Håvard Kjærstad\n\nHåvard Kjærstad (born 1947) is a Norwegian businessperson.\n\nHe graduated from BI Norwegian Business School in 1972 with a degree in business economy. He was employed at Esso in 1970 and is currently Nordic Retail Sales Manager. He is also chairman of the board at the Norwegian Petroleum Institute.\n\nKjærstad has a fortune of $1.22 million.\n\n"}
{"id": "25580204", "url": "https://en.wikipedia.org/wiki?curid=25580204", "title": "Korea Nuclear Fuel", "text": "Korea Nuclear Fuel\n\nKorea Nuclear Fuel or KNF is a South Korean public enterprise established in 1982 to provide nuclear fuel. It provides nuclear fuels to 20 nuclear power plants in South Korea. The price of the nuclear fuel provided by the company accounts for 60% of the average international price. \n\n"}
{"id": "4720705", "url": "https://en.wikipedia.org/wiki?curid=4720705", "title": "Krasnoyarsk Dam", "text": "Krasnoyarsk Dam\n\nThe Krasnoyarsk Dam is a high concrete gravity dam located on the Yenisey River about upstream from Krasnoyarsk in Divnogorsk, Russia. It was constructed from 1956 to 1972, and it supplies about 6,000 MW (six GW) of power, mostly used to supply the KrAZ (Krasnoyarsky Aluminievyy Zavod, the Krasnoyarsk Aluminum Plant). Both power and aluminum plants are controlled by the RUSAL company.\nBeginning with the opening of the 10th turbine in April 1971, the powerhouse was the world’s single largest power plant until the Grand Coulee Dam in Washington State reached 6,181 MW in 1983. The Krasnoyarsk Dam is held to be a landmark symbol of Krasnoyarsk, and it is depicted on the 10-ruble banknote.\n\nAs a result of the damming, the Krasnoyarsk Reservoir was created. This reservoir, informally known as the Krasnoyarsk Sea, has an area of and a volume of . It is in length and in width at its widest, has an average depth of , and a depth of near the dam.\n\nThe Krasnoyarsk Dam significantly influences the local climate; normally the river would freeze over in the bitterly-cold Siberian winter, but because the dam releases unfrozen water year-round, the river never freezes in the to stretch of river immediately downstream from the dam. In winter, the frigid air interacts with the warm river water to produce fog, which shrouds Krasnoyarsk and other downstream areas.\nThe dam is equipped with a canal inclined plane to allow passage of ships. It is in fact an electric rack railway. The track gauge is , making it the widest-gauge railway of any type in the world. At the time of its construction, this feat of modern engineering allowed for ships to be physically moved in only 90 minutes. \n\n\n"}
{"id": "41916478", "url": "https://en.wikipedia.org/wiki?curid=41916478", "title": "Kwaku Aning", "text": "Kwaku Aning\n\nKwaku Aning (born in 1946) is a Ghanaian diplomat and technologist who served as Deputy Director General and the Head of the Department of Technical Cooperation at the International Atomic Energy Agency. He took up his position on January 1, 2010 and ended in June,2015.\n\nPrior to his appointment as Deputy Director General, Aning served as the Director and Secretary of the Policy Making Organs of the IAEA. He has also been the Representative of the IAEA Director General to the United Nations. He is a member of the board of trustees of Kuwait's Al-Sumait Prize for African Development. \nIn September 2015,Aning became a Governor of IAEA Board of Governors and still serves in this position. Aning took up the position of Chairman,Governing Board of the Ghana Atomic Energy Commission in July 2017.\n\nKwaku Aning attended Accra Academy,a high school in Accra,Ghana. Aning gained a Bachelor's of Science( BSc.)degree in Mechanical Engineering from the University of Science and Technology in 1968, graduating with first class honours;one of the first four persons to obtain first class honours from the University included in this accomplishment was his Accra Academy mate, Samuel Gyasi who later became a Professor at University of California,Berkeley. He entered Princeton University in that same year,1968 receiving a MSc. in Solid State Physics in 1971.Aning obtained a doctoral degree in metallurgy from Columbia University in 1976.\n\nAning started his working career as a Technical Advisor to the UN Conference on Science and Technology for Development.In January 1980,Aning became a Senior Scientific Affairs Officer of the UN Centre for Science and Technology,remaining in this position for the next 12 years.He worked in this role which had a special focus on science and technology development of developing countries.Aning moved on to the UN Peacekeeping Department,working as a Regional Election Officer for the period between March 1992 to June 1994.Kwaku Aning was to be made a Senior Officer,Office of the Secretary-General later on within August 1998 and January 2000.\n\nIn February 2000,Kwaku Aning joined the International Atomic Energy Agency as the Representative of the Director General of the agency to the United Nations in New York.\n\nAning is the Chairman of the Nuclear Power Institute,GAEC.Aning is also Chairman of the Governing Board,Ghana Atomic Energy Commission.\n"}
{"id": "1450654", "url": "https://en.wikipedia.org/wiki?curid=1450654", "title": "Lablab", "text": "Lablab\n\nLablab purpureus is a species of bean in the family Fabaceae. It is native to Africa and it is cultivated throughout the tropics for food. English language common names include hyacinth bean, lablab-bean bonavist bean/pea, dolichos bean, seim bean, lablab bean, Egyptian kidney bean, Indian bean, bataw and Australian pea. It is the only species in the monotypic genus Lablab.\n\nThe plant is variable due to extensive breeding in cultivation, but in general, they are annual or short-lived perennial vines. The wild species is perennial. The thick stems can reach six meters in length. The leaves are made up of three pointed leaflets each up to 15 centimeters long. They may be hairy on the undersides. The inflorescence is made up of racemes of many flowers. Some cultivars have white flowers, and others may have purplish or blue. The fruit is a legume pod variable in shape, size, and color. It is usually several centimeters long and bright purple to pale green. It contains up to four seeds. The seeds are white, brown, red, or black depending on the cultivar, sometimes with a white hilum. Wild plants have mottled seeds. The seed is about a centimeter long.\n\nThe hyacinth bean is an old domesticated pulse and multi-purpose crop. Due to seed availability of one forage cultivar (cv. Rongai), it is often grown as forage for livestock and as an ornamental plant. In addition, it is cited both as a medicinal plant and a poisonous plant.\n\nThe fruit and beans are edible if boiled well with several changes of the water. Otherwise, they are toxic due to the presence of cyanogenic glycosides, glycosides that are converted to hydrogen cyanide when consumed. Signs of poisoning include weakness, vomiting, dyspnea, twitching, stupor, and convulsions. It has been shown that there is a wide range of cyanogenic potential among the varieties.\n\nThe leaves are eaten raw or cooked like spinach. The flowers can be eaten raw or steamed. The root can be boiled or baked for food. The seeds are used to make tofu and tempeh.\n\nIn Bangladesh and West Bengal, the green pods along with the beans, known as \"Sheem\" (শিম), are cooked as vegetables or cooked with fish as a curry.\n\nIn Kerala, it is known as \"Amarakka, Avara\" or \"Amara Payar\" (Malayalam: അമര പയർ ). The beans as well as the bean pods are used in cooking curries. The bean pods are also used (along with spices) for preparing stir-fried dish known as \"Thoran\". \n\nIn Maharashtra, dry preparations with green masala is often made out of these green beans (Ghevda varirties - Shravan ghevda (french beans), Bajirao Ghevda, Ghevda, Walwar, Pavta sheng..) mostly found at the end of monsoon during fasting festivals of Shravan month. \n\nIn Karnataka, the hyacinth bean is made into curry (\"avarekalu saaru\")(), salad (\"avarekaalu usli\"), added to upma (\"avrekaalu uppittu\"), and as a flavoring to Akki rotti. Sometimes the outer peel of the seed is taken out and the inner soft part is used for a variety of dishes. This form is called \"hitakubele avarekalu\", which means \"pressed (\"hitaku\") hyancinth bean, and a curry known as \"Hitikida Avarekaalu Saaru\" is made out of this deskinned beans. \n\nIn Telangana and Andra Pradesh, the bean pods are cut into small pieces and cooked as spicy curry in Pongal festival season. Sometimes the outer peel of the seed when tender and soaked over night is taken out and the inner soft part is used for a variety of dishes. This form is called \"pitakapappu,hanupa/anapa\", which means \"pressed (\"pitaku\") hyancinth bean, and a curry known as Pitikida Anapaginjala Chaaru is made out of this deskinned beans along with \"bajra\" bread; it has been a very special delicacy for centuries.\n\nIn Huế, Vietnam, hyacinth beans are the main ingredient of the dish \"chè đậu ván\" (Hyacinth Bean Sweet Soup).\n\nIn Kenya, the bean called 'Njahe' is popular among several communities, especially the Kikuyu. Seasons were actually based on it i.e the Season of Njahe (Kīmera kīa njahī). It is thought to encourage lactation and has historically been the main dish for breastfeeding mothers. Beans are boiled and mashed with ripe and/or semi-ripe bananas, giving the dish a sweet taste. Today the production is in decline in eastern Africa. This is partly attributed to the fact that under colonial rule in Kenya, farmers were forced to give up their local bean in order to produce common beans (\"Phaseolus vulgaris\") for export.\n\nOther common names include Tonga bean, papaya bean, poor man bean (Australia), Seim (Trinidad), and butter bean (Caribbean).\n\nAccording to the British biologist and taxonomist Bernard Verdcourt, there are two cultivated subspecies of \"Lablab purpureus\" (L.) Sweet: \n(Syn.: \"Dolichos bengalensis\" Jacq., \"Dolichos lablab\" subsp. \"bengalensis\" (Jacq.) Rivals, \"Lablab niger\" subsp. \"bengalensis\" (Jacq.) Cuf.)\nand \n\nin addition to one wild subspecies: \nof which a special variant with lobed leaflets exists only in Namibia: \n\n\n"}
{"id": "53634896", "url": "https://en.wikipedia.org/wiki?curid=53634896", "title": "Materials with memory", "text": "Materials with memory\n\nIn continuum physics, materials with memory, also referred as materials with hereditary effects are a class of materials whose constitutive equations contains a dependence upon the past history of thermodynamic, kinetic, electromagnetic or other kind of state variables.\n\nThe study of these materials arises from the pioneering articles of Ludwig Boltzmann and Vito Volterra, in which they sought an extension of the concept of an elastic material. The key assumption of their theory was that the local stress value at a time depends upon the history of the local deformation up to . In general, in materials with memory the local value of some constitutive quantity (stress, heat flux, electric current, polarization and magnetization, etc.) at a time depends upon the history of the state variables (deformation, temperature, electric and magnetic fields, etc.). The hypothesis that the remote history of a variable has less influence than its values in the recent past, was stated in modern continuum mechanics as the fading memory principle by Bernard Coleman and Walter Noll.\nThis assumption was implicit in the pioneer works: when restricted to cyclic hystories, it traces back to the closed cycle principle stated by Volterra, which leds to a constitutive relation of integral convolution type.\nIn the linear case, this relation takes the form of a Volterra equation\n\nIn the linear case, this relation takes the form of a Volterra equation\n\n\n\n\n"}
{"id": "7019702", "url": "https://en.wikipedia.org/wiki?curid=7019702", "title": "Maund", "text": "Maund\n\nThe maund is the anglicized name for a traditional unit of mass used in British India, and also in Afghanistan, Persia and Arabia: the same unit in the Moghul Empire was sometimes written as mann or mun in English, while the equivalent unit in the Ottoman Empire and Central Asia was called the \"batman\". At different times, and in different South Asian localities, the mass of the maund has varied, from as low as 25 pounds (11 kg) to as high as 160 pounds (72½ kg): even greater variation is seen in Persia and Arabia.\n\nIn British India, the maund was first standardized in the Bengal Presidency in 1833, where it was set equal to 100 Troy pounds (82.28 lbs. av.). This standard spread throughout the British Raj. After the independence of India and Pakistan, the definition formed the basis for metrication, one maund becoming exactly 37.3242 kilograms. A similar metric definition is used in Nepal. In its southern plains one Mann equals 40 Kilograms and is generally used to measure agricultural output.\n\nThe Old English, 'maund' may also be the origin of Maundy Thursday. As a verb, 'maund' : to beg; as a noun, 'a maund' : a small basket held out for alms.\n\nAnglicized as \"maund\", the ' \"mun\" ' as a unit of weight is thought to be of at least Chaldean origin, with Sir Henry Yule attributing Akkadian origins to the word. The Hebrew \"maneh\" (מנה) and the Ancient Greek \"mina\" (μνᾶ) are thought to be cognate. It was originally equal to one-ninth of the weight of an \"artaba\" of water, or approximately four to seven kilograms in modern units.\n\nThe modification of the vowel in the anglicized name is thought to be an indication that the word came into English via Portuguese. The Portuguese version was \"mão\" (, as in the word for \"hand\"), a regular → development in Portuguese.\n\nDuring the reign of Alauddin Khalji of the Delhi Sultanate, 1 \"mann\" was roughly equivalent to 15 kg.\n\nPrinsep (1840) summarizes the evidence as to the weight of the \"mun\" (later \"maund\") during the reign (1556–1605) of Akbar the Great, which comes from the \"Ain-i-Akbari\" written by the vizier Abu'l-Fazl ibn Mubarak (anglicized as \"Abul Fuzl\"). The principal definition is that the \"mun\" is forty \"seers\"; and that each \"seer\" is thirty \"dams\".\nThe problem arises in assigning the values of the smaller units. \n\nThe section of the \"Ain-i-Akbari\" that defines the \"mun\" also defines the \"dam\" as five \"tanks\". A separate section defines the \"tank\" as twenty-four \"ruttees\". However, by the 19th century, the \"tank\" was no longer a uniform unit across the former Mughal territories: Prinsep quotes values of 50 grains (3.24 g) in Darwar, 72 grains (4.67 g) in Bombay and 268 grains (17.37 g) in Ahmednugur. \n\nThe \"jilály\", a square silver rupee coin issued by Akbar, was said by the \"Ain-i-Akbari\" to be 11¼ \"mashas\" in weight: surviving \"jilály\" and other Mughal rupee coins weigh 170–175 Troy grains (11.02–11.34 g), so the \"masha\", defined as eight \"ruttees\", would be about 15½ grains (1 g). \"Masha\" weights sent back to London in 1819 agree with this value. This basis gives a \"mun\" of 34¾ lb. av. (15¾ kg). One \"Koni\" was 4 muns.\n\nHowever, in yet another section of the \"Ain-i-Akbari\", the \"dam\" is said to be \"twenty \"mashas\" seven \"ruttees\"\": using this definition would imply an Imperial mass of about 47 lb. av. (21⅓ kg) for the \"mun\". Between these two values, the maund in Central India was often found to be around 40 lb. av. (18 kg) in the East India Company survey of 1821.\n\nA Maund was 55.5 British pounds under Akbar.\n\nPrinsep's values for the maund come from a survey organized by the East India Company in 1821. The Company's agents were asked to send back examples of the standard weights and measures used in the places they were stationed, and these were compared with the English standards in London by Patrick Kelly, the leading British metrologist of the time. The results were published as an appendix to the second edition of Kelly's \"Universal Cambist\" (1831), and later as a separate book entitled \"Oriental Metrology\" (1832).\n\nIt will be seen from Kelly's results below that Prinsep's generalizations are only partially correct. The Gujarat maund is more closely related to the Central Indian maund than to the standardized Bombay maund, except in the town of Anjar, except that it is divided into 40 seers instead of 20 as was found in Malwa.\n\n"}
{"id": "6696241", "url": "https://en.wikipedia.org/wiki?curid=6696241", "title": "Medium Earth orbit", "text": "Medium Earth orbit\n\nMedium Earth orbit (MEO), sometimes called intermediate circular orbit (ICO), is the region of space around Earth above low Earth orbit (altitude of above sea level) and below geostationary orbit (altitude of above sea level).\n\nThe most common use for satellites in this region is for navigation, communication, and geodetic/space environment science. The most common altitude is approximately ), which yields an orbital period of 12 hours, as used, for example, by the Global Positioning System (GPS). Other satellites in medium Earth orbit include Glonass (with an altitude of ) and Galileo (with an altitude of ) constellations.\nCommunications satellites that cover the North and South Pole are also put in MEO.\n\nThe orbital periods of MEO satellites range from about 2 to nearly 24 hours. Telstar 1, an experimental satellite launched in 1962, orbited in MEO.\n\nThe orbit is home to a number of artificial satellites.\n"}
{"id": "3307890", "url": "https://en.wikipedia.org/wiki?curid=3307890", "title": "Molybdenum disilicide", "text": "Molybdenum disilicide\n\nMolybdenum disilicide (MoSi, or molybdenum silicide), an intermetallic compound, a silicide of molybdenum, is a refractory ceramic with primary use in heating elements. It has moderate density, melting point 2030 °C, and is electrically conductive. At high temperatures it forms a passivation layer of silicon dioxide, protecting it from further oxidation. It is a gray metallic-looking material with tetragonal crystal structure (alpha-modification); its beta-modification is hexagonal and unstable. It is insoluble in most acids but soluble in nitric acid and hydrofluoric acid.\n\nWhile MoSi has excellent resistance to oxidation and high Young's modulus at temperatures above 1000 °C, it is brittle in lower temperatures. Also, at above 1200 °C it loses creep resistance. These properties limits its use as a structural material, but may be offset by using it together with another material as a composite material.\n\nMolybdenum disilicide and MoSi-based materials are usually made by sintering. Plasma spraying can be used for producing its dense monolithic and composite forms; material produced this way may contain a proportion of β-MoSi due to its rapid cooling.\n\nMolybdenum disilicide heating elements can be used for temperatures up to 1800 °C, in electric furnaces used in laboratory and production environment in production of glass, steel, electronics, ceramics, and in heat treatment of materials. While the elements are brittle, they can operate at high power without aging, and their electrical resistivity does not increase with operation time. Their maximum operating temperature has to be lowered in atmospheres with low oxygen content due to breakdown of the passivation layer.\n\nOther ceramic materials used for heating elements are e.g. silicon carbide, barium titanate, and lead titanate composite materials.\n\nMolybdenum disilicide is used in microelectronics as a contact material. It is often used as a shunt over polysilicon lines to increase their conductivity and increase signal speed.\n"}
{"id": "11535922", "url": "https://en.wikipedia.org/wiki?curid=11535922", "title": "Nazimaruttaš kudurru stone", "text": "Nazimaruttaš kudurru stone\n\nThe Nazimaruttash kudurru stone is a boundary stone (kudurru) of Nazimaruttaš, a Kassite king of Babylon, ca. 1307–1282 BC (short chronology). It was found at Susa and is now displayed at the Louvre.\n\nSome kudurrus are known for their portrayal of the king, etc., who consigned it. Most kudurrus portray Mesopotamian gods, which are often portrayed graphically in segmented \"registers\" on the stone. Nazimaruttash's kudurru does not use registers. Instead, graphic symbols are used. Nineteen deities are invoked to curse the foolhardy individual who seeks to desecrate it. Some are represented by symbols, such as a goat-fish for Enki or a bird on a pole for Papsukkal, a spear-head for Marduk or an eight-pointed star for Ishtar. Shamash is represented by a disc.\n\n"}
{"id": "46797381", "url": "https://en.wikipedia.org/wiki?curid=46797381", "title": "Northern Tier Energy", "text": "Northern Tier Energy\n\nNorthern Tier Energy LP was an American downstream energy limited partnership. In addition to owning the SuperAmerica gas station and convenience store chain, it also owned an oil refinery in St. Paul Park, Minnesota and an interest in a pipeline. In 2014 it ranked 525 on the Fortune 1000.\n\nThe company was created in 2010 when TPG Capital acquired $554 million worth of assets from Marathon. Western Refining acquired a controlling interest in the company in 2013 for $775 million. By 2015, Western's ownership stake was 38% and it proposed in October to acquire the remainder of the company; it decided to dissolve Northern Tier early by buying all the shares and pay $860 million to close the deal on June 23, 2016. \n"}
{"id": "26384549", "url": "https://en.wikipedia.org/wiki?curid=26384549", "title": "Nuclear knowledge management", "text": "Nuclear knowledge management\n\nNuclear knowledge management (NKM) is knowledge management as applied in the nuclear technology field. It supports the gathering and sharing of new knowledge and the updating of the existing knowledge base. Knowledge management is of particular importance in the nuclear sector, owing to the rapid development and complexity of nuclear technologies and their hazards and security implications. The International Atomic Energy Agency (IAEA) launched a nuclear knowledge management programme in 2002.\n\nNuclear knowledge management is defined as knowledge management in the nuclear domain. This simple definition is consistent with the working definition used in the IAEA document \"Knowledge Management for Nuclear Industry Operating Organizations\" (2006). Knowledge management (KM) itself is defined as an integrated, systematic approach to identifying, acquiring, transforming, developing, disseminating, using, sharing, and preserving knowledge, relevant to achieving specified objectives.\n\nKnowledge management systems support nuclear organizations in strengthening and aligning their knowledge. Knowledge is the nuclear energy industry’s most valuable asset and resource, without which the industry cannot operate safely and economically. Nuclear knowledge is also very complex, expensive to acquire and maintain, and easily lost. States, suppliers, and operating organizations that deploy nuclear technology are responsible for ensuring that the associated nuclear knowledge is maintained and accessible.\nIn the organizational context, nuclear knowledge management supports the organization's business processes, and involves applying knowledge management practices. These may be applied at any stage of a nuclear facility's life cycle: research and development, design and engineering, construction, commissioning, operations, maintenance, refurbishment and life time extension, waste management, and decommissioning. Nuclear knowledge management issues and priorities are often unique to the particular circumstances of individual Member States and their nuclear industry organizations. Nuclear knowledge management practices enhance and support traditional business functions and goals such as human resource management, training, planning, operations, maintenance, projects, innovation, performance and risk management, information management, process management, organizational learning and information technology support.\nA nuclear knowledge management strategy, with clearly defined objectives, provides a framework for establishing principles, policy, priorities and plans to apply knowledge management practices in the workplace.\nKnowledge management focuses on \"people\" and organizational culture to stimulate and nurture the sharing and use of knowledge; on \"processes\" or methods to find, create, capture and share knowledge; and on \"technology\" to store and assimilate knowledge and to make it readily accessible in a manner which will allow people to work together even if they are not located together. People are the most important component in a KM system and the creation of new knowledge is one of its most valuable byproducts. For a KM system to function properly, the people involved must be willing to share and re-use existing knowledge and to cooperatively generate new knowledge to the advantage of the organization.\n\nDue to the nature of nuclear power plant operating organizations (high hazard but low risk), a number of knowledge management activities and programmes have been in place throughout the industry to manage and control the knowledge and information related to nuclear power plant design, construction, operation and maintenance. Examples of such\nexisting KM activities employed by NPPs and in most other nuclear technology facilities include the following functions:\n\n\nThe implementation of a KM system is not intended to replace any of these systems, but rather should increase the benefits to be derived from these systems in conjunction with the deployment of an integrated management system. Properly implemented KM should increase the benefits to the organization of these existing activities, rather than substituting for them. The lessons learned in the nuclear industry in the past 20 years, moving away from inspection by large quality assurance organizations towards building quality into all facility processes, have considerable relevance for KM implementation.\n\nIt is probable that nuclear knowledge will continue to expand and change. Without diligence in managing nuclear knowledge, substantial portions of it could be lost due to personnel retirements and the likelihood that much of it could be disused or discarded as a result of either negligence or changing priorities. It will be as important to identify and properly treat obsolete, superseded knowledge as it will be to gather and share new knowledge. It is therefore necessary to maintain effective and efficient KM systems.\n\nNKM has become an increasingly important element of the nuclear sector in recent years, resulting from a number of challenges and trends:\n\n\nConcerns about global climate change and the availability of economically exploitable fossil fuels are driving many countries to reconsider the use of nuclear energy. Yet, the innovations required to design, construct, operate and maintain nuclear power plants consistent with international needs and constraints must derive from a strong foundation of well-sustained nuclear knowledge. \n\nIn contrast to knowledge in other scientific domains, the free sharing and uncontrolled use of nuclear knowledge are severely restricted due to concerns about nuclear security and proliferation. On the other hand, ensuring nuclear \"safety\" requires free sharing of information and experience to avoid repetition of accident precursors. Risks to nuclear safety could be very high due to the nature and size of third party liability and the possibility of nuclear security being severely compromised. In managing nuclear knowledge, therefore, an appropriate balance between nuclear safety and security requirements needs to be established.\n\nThe applications of nuclear technology in the non-power areas enumerated above tends to be less controversial than nuclear power. Knowledge in these areas is broadly disseminated and – in many cases – is freely shared. Effective and efficient systems of managing nuclear knowledge form the basis for refining existing applications and developing new, even more widely used applications.\n\nThe importance of nuclear knowledge management is increasingly being recognized in the industry. The International Atomic Energy Agency (IAEA) has been a repository of knowledge related to peaceful applications of nuclear technology from the time the organization was established in 1957. Nuclear Knowledge Management came in the forefront in the IAEA as a formal programme to address Member States' priorities in the 21st century. Several resolutions adopted at the IAEA General Conference since 2002 include knowledge management topics.\n\nThe IAEA Secretariat was urged to assist member states, at their request, in fostering and preserving nuclear education and training in all areas of nuclear technology for peaceful purposes; in developing guidance on and methodologies for planning, designing and implementing nuclear knowledge management programmes; in providing Member States with reliable information resources on the peaceful use of nuclear energy; and in continuing to develop tools and methods to capture, retain, share, utilize and preserve nuclear knowledge.\n\nThe IAEA has organized a number of international meetings, schools and conferences covering a wide range of topics, from general concepts that underpin nuclear knowledge management to specific methods and tools taught at training seminars for practitioners.\n\nThe IAEA Nuclear Knowledge Management Programme was headed by Yanko Yanev (2002–2012) and by John de Grosbois (since 2012).\n\n"}
{"id": "35747211", "url": "https://en.wikipedia.org/wiki?curid=35747211", "title": "Olivia Choong", "text": "Olivia Choong\n\nOlivia Choong Way Sun (born 13 February 1979) is an environmental activist from Singapore. She founded Green Drinks Singapore in November 2007, a non-profit movement that actively raises awareness on pertinent environmental issues, and connects businesses, academia, government, media, Non-Governmental Organisations and individuals for knowledge sharing and collaboration opportunities. She also founded a public relations consultancy Green PR in April 2010, focusing on environmental small and medium enterprises.\n\nIn 2013, she received the EcoFriend award for her environmental contributions to Singapore.\n\nPrior to Green Drinks, Olivia was with then Hill & Knowlton (now Hill+Knowlton Strategies - a global public relations consulting company) office in Singapore. Her portfolio included financial communications, consumer PR and corporate communications. In recent years, Olivia has also taken a keen interest in urban farming and hobby farming, and started The Tender Gardener to document her sustainable living journey, and now teach gardening-related workshops. \n\nIn addition, Olivia contributes articles to Eco-Business.com, InTheLoop, LOHASIA, Public House and Green Kampong. She also serves on the board of Avelife, a youth environmental Non-Governmental Organisation.\n"}
{"id": "56887", "url": "https://en.wikipedia.org/wiki?curid=56887", "title": "Pineapple", "text": "Pineapple\n\nThe pineapple (\"Ananas comosus\") is a tropical plant with an edible multiple fruit consisting of coalesced berries, also called pineapples, and the most economically significant plant in the family Bromeliaceae.\n\nPineapples may be cultivated from the offset produced at the top of the fruit, possibly flowering in five to ten months and fruiting in the following six months. Pineapples do not ripen significantly after harvest. In 2016, Costa Rica, Brazil, and the Philippines accounted for nearly one-third of the world's production of pineapples.\n\nThe word \"pineapple\" in English was first recorded to describe the reproductive organs of conifer trees (now termed pine cones). When European explorers encountered this tropical fruit in the Americas, they called them \"pineapples\" (first referenced in 1664, for resemblance to pine cones).\n\nIn the scientific binomial \"Ananas comosus\", \"ananas\", the original name of the fruit, comes from the Tupi word \"nanas\", meaning \"excellent fruit\", as recorded by André Thevet in 1555, and \"comosus\", \"tufted\", refers to the stem of the fruit. Other members of the genus \"Ananas\" are often called pine, as well, in other languages. \n\nThe pineapple is a herbaceous perennial, which grows to tall, although sometimes it can be taller. In appearance, the plant has a short, stocky stem with tough, waxy leaves. When creating its fruit, it usually produces up to 200 flowers, although some large-fruited cultivars can exceed this. Once it flowers, the individual fruits of the flowers join together to create what is commonly referred to as a pineapple. After the first fruit is produced, side shoots (called 'suckers' by commercial growers) are produced in the leaf axils of the main stem. These may be removed for propagation, or left to produce additional fruits on the original plant. Commercially, suckers that appear around the base are cultivated. It has 30 or more long, narrow, fleshy, trough-shaped leaves with sharp spines along the margins that are long, surrounding a thick stem. In the first year of growth, the axis lengthens and thickens, bearing numerous leaves in close spirals. After 12 to 20 months, the stem grows into a spike-like inflorescence up to long with over 100 spirally arranged, trimerous flowers, each subtended by a bract. \n\nThe ovaries develop into berries, which coalesce into a large, compact, multiple fruit. The fruit of a pineapple is arranged in two interlocking helices, eight in one direction, 13 in the other, each being a Fibonacci number.\n\nThe pineapple carries out CAM photosynthesis, fixing carbon dioxide at night and storing it as the acid malate, then releasing it during the day aiding photosynthesis.\n\nIn the wild, pineapples are pollinated primarily by hummingbirds. Certain wild pineapples are foraged and pollinated at night by bats.\n\nUnder cultivation, because seed development diminishes fruit quality, pollination is performed by hand, and seeds are retained only for breeding. Specifically in Hawaii, where pineapples were cultivated and canned industrially throughout the 20th century, importation of hummingbirds was prohibited.\n\nThe flesh and juice of the pineapple are used in cuisines around the world. In many tropical countries, pineapple is prepared and sold on roadsides as a snack. It is sold whole or in halves with a stick inserted. Whole, cored slices with a cherry in the middle are a common garnish on hams in the West. Chunks of pineapple are used in desserts such as fruit salad, as well as in some savory dishes, including pizza toppings, or as a grilled ring on a hamburger. Crushed pineapple is used in yogurt, jam, sweets, and ice cream. The juice of the pineapple is served as a beverage, and it is also the main ingredient in cocktails such as the \"piña colada\" and in the drink \"tepache\".\n\nIn a 100-gram reference amount, raw pineapple is a rich source of manganese (44% Daily Value, DV) and vitamin C (58% DV), but otherwise contains no essential nutrients in significant quantities (table).\n\nPresent in all parts of the pineapple plant, bromelain is a mixture of proteolytic enzymes. Bromelain is under preliminary research for a variety of clinical disorders, but to date has not been adequately defined for its effects in the human body. Bromelain may be unsafe for some users, such as in pregnancy, allergies, or anticoagulation therapy.\n\nIf having sufficient bromelain content, raw pineapple juice may be useful as a meat marinade and tenderizer. Although pineapple enzymes can interfere with the preparation of some foods or manufactured products, such as gelatin-based desserts or gel capsules, their proteolytic activity responsible for such properties may be degraded during cooking and canning. The quantity of bromelain in a typical serving of pineapple fruit is probably not significant, but specific extraction can yield sufficient quantities for domestic and industrial processing.\n\nThe bromelain content of raw pineapple is responsible for the sore mouth feeling often experienced when eating it, due to the enzymes breaking down the proteins of sensitive tissues in the mouth. Also, raphides, needle-shaped crystals of calcium oxalate that occur in pineapple fruits and leaves, likely cause microabrasions, contributing to mouth discomfort.\n\nThe plant is indigenous to South America and is said to originate from the area between southern Brazil and Paraguay; however, little is known about the origin of the domesticated pineapple (Pickersgill, 1976). MS Bertoni (1919) considered the Paraná–Paraguay River drainages to be the place of origin of \"A. comosus\". The natives of southern Brazil and Paraguay spread the pineapple throughout South America, and it eventually reached the Caribbean, Central America, and Mexico, where it was cultivated by the Mayas and the Aztecs. Columbus encountered the pineapple in 1493 on the leeward island of Guadeloupe. He called it \"piña de Indes\", meaning \"pine of the Indians\", and brought it back with him to Spain, thus making the pineapple the first bromeliad to be introduced by humans outside of the New World. The Spanish introduced it into the Philippines, Hawaii (introduced in the early 19th century, first commercial plantation 1886), Zimbabwe, and Guam. The fruit is said to have been first introduced in Hawaii when a Spanish ship brought it there in the 1500s. The Portuguese took the fruit from Brazil and introduced it into India by 1550.\nThe pineapple was brought to northern Europe by the Dutch from their colony in Surinam. The first pineapple to be successfully cultivated in Europe, is said to have been grown by Pieter de la Court at Meerburg in 1658. In England, a huge \"pineapple stove\" needed to grow the plants had been built at the Chelsea Physic Garden in 1723. In France, King Louis XV was presented with a pineapple that had been grown at Versailles in 1733. Catherine the Great ate pineapples grown on her own estates before her death in 1796. Because of the expense of direct import and the enormous cost in equipment and labour required to grow them in a temperate climate, using hothouses called \"pineries\", pineapples soon became a symbol of wealth. They were initially used mainly for display at dinner parties, rather than being eaten, and were used again and again until they began to rot. By the second half of the 18th century, the production of the fruit on British estates had become the subject of great rivalry between wealthy aristocrats. John Murray, 4th Earl of Dunmore built a hothouse on his estate surmounted by a huge stone cupola 14 metres tall in the shape of the fruit; it is known as the Dunmore Pineapple.\n\nJohn Kidwell is credited with the introduction of the pineapple industry to Hawaii; large-scale pineapple cultivation by US companies began in the early 1900s. Among the most famous and influential pineapple industrialists was James Dole, who moved to Hawaii in 1899 and started a pineapple plantation in 1900. The companies Dole and Del Monte began growing pineapples on the island of Oahu in 1901 and 1917, respectively. Dole's pineapple company began with the acquisition of of land in 1901, and grew into a major company, the Dole Food Company. Maui Pineapple Company began pineapple cultivation on the island of Maui in 1909.\n\nIn the US, in 1986, the Pineapple Research Institute was dissolved and its assets divided between Del Monte and Maui Land and Pineapple. Del Monte took cultivar '73–114', dubbed 'MD-2', to its plantations in Costa Rica, found it to be well-suited to growing there, and launched it publicly in 1996 as 'Gold Extra Sweet', while Del Monte also began marketing '73–50', dubbed 'CO-2', as 'Del Monte Gold'.\n\nDole ceased its cannery operations in Honolulu in 1991, and in 2008, Del Monte terminated its pineapple-growing operations in Hawaii. In 2009, the Maui Pineapple Company reduced its operations to supply pineapples only locally on Maui, and by 2013, only the Dole Plantation on Oahu grew pineapples in a volume of about 0.1 percent of the world's production.\n\nIn 2016, world production of pineapples was 25.8 million tonnes, led by Costa Rica, Brazil, and the Philippines, which collectively accounted for 32% of the global total (table).\n\nIn commercial farming, flowering can be induced artificially, and the early harvesting of the main fruit can encourage the development of a second crop of smaller fruits. Once removed during cleaning, the top of the pineapple can be planted in soil and a new plant will grow. Slips and suckers are planted commercially.\n\nPineapples can be consumed fresh, cooked, juiced, or preserved. They are found in a wide array of cuisines. In addition to consumption, the pineapple leaves are used to produce the textile fiber \"piña\" in the Philippines, commonly used as the material for the men's \"barong Tagalog\" and women's \"baro't saya\" formal wear in the country. The fiber is also used as a component for wallpaper and other furnishings.\n\nThree-quarters of the pineapples sold in Europe are grown in Costa Rica, where pineapple production is highly industrialised. Growers typically use of pesticides per hectare in each growing cycle, a process that may affect soil quality and biodiversity. The pesticides—organophosphates, organochlorines, and hormone disruptors—have the potential to affect workers' health and can contaminate local drinking water supplies. Many of these chemicals have potential to be carcinogens, and may be related to birth defects.\n\nBecause of commercial pressures, many pineapple workers in Costa Rica—60% of whom are Nicaraguan—are paid low wages. European supermarkets' price-reduction policies have lowered growers' incomes. One major pineapple producer contests these claims.\n\nMany cultivars are known. The leaves of the commonly grown \"smooth cayenne\" are smooth, and it is the most commonly grown worldwide. Many cultivars have become distributed from its origins in Paraguay and the southern part of Brazil, and later improved stocks were introduced into the Americas, the Azores, Africa, India, Malaysia and Australia. Varieties include:\nPineapple fruits and peels contain diverse phytochemicals, among which are polyphenols, including gallic acid, syringic acid, vanillin, ferulic acid, sinapic acid, coumaric acid, chlorogenic acid, epicatechin, and arbutin.\n\nPineapples are subject to a variety of diseases, the most serious of which is wilt disease vectored by mealybugs typically found on the surface of pineapples, but possibly in the closed blossom cups. Other diseases include citrus pink disease, bacterial heart rot, anthracnose, fungal heart rot, root rot, black rot, butt rot, fruitlet core rot, and yellow spot virus.\nPineapple pink disease (not citrus pink disease) is characterized by the fruit developing a brownish to black discoloration when heated during the canning process. The causal agents of pink disease are the bacteria \"Acetobacter aceti\", \"Gluconobacter oxydans\", \"Pantoea citrea\". and \"Tatumella ptyseos\".\n\nSome pests that commonly affect pineapple plants are scales, thrips, mites, mealybugs, ants, and symphylids.\n\nHeart-rot is the most serious disease affecting pineapple plants. The disease is caused by \"Phytophthora cinnamoni\" and \"P. parasitica,\" fungi that often affect pineapples grown in wet conditions. Since it is difficult to treat, it is advisable to guard against infection by planting resistant cultivars where these are available; all suckers that are required for propagation should be dipped in a fungicide, since the fungus enters through the wounds.\n\nSome buyers prefer green fruit, others ripened or off-green. A plant growth regulator, Ethephon, is typically sprayed onto the fruit one week before harvest, developing ethylene, which turns the fruit golden yellow. After cleaning and slicing, a pineapple is typically canned in sugar syrup with added preservative.\n\nA pineapple never becomes any riper than it was when harvested.\n\nThe fruit itself is quite perishable and if it is stored at room temperature, it should be used within two days; however, if it is refrigerated, the time span extends to 5–7 days.\n\nMimi Sheller writes: \"The pineapple entered European iconography as a symbol of welcome and hospitality, and also eventually found its way into botanical gardens such as the Chelsea Physic Garden, where it was grown in heated pits.\" The sweet fruit had a \"mysterious aura\" in the Age of Sail because except for a \"small elite with access to glass hothouses\", tropical fruits could only be tasted where they were cultivated. Christopher Cumo writes that \"The Spanish who followed Columbus delighted in eating pineapple and in writing about it for a European public eager to learn of the flora and fauna of the Americas ... The pineapple was first a luxury because transit from the tropics to Europe was expensive in the age of sail. In this respect, pineapple was much like sugar, a commodity of privilege before it became an item of the masses.\" Cumo writes that \"pineapple was the fruit of colonialism\" because the Portuguese, French, Dutch, and British all sought to establish pineapple plantations in the tropics of South America, Central America, and the Caribbean.\n\nIn architecture, pineapple figures are a decorative element symbolizing hospitality. Usually in plaster or carved wood, pineapples images occur in finials, pendants, \"broken\" pediments, and door knockers.\n\nPineapples have long been associated with the Hawaiian Islands, to the extent that the pineapple is sometimes used as a symbol of Hawaii, despite the decline of the pineapple industry in that state. Foods with pineapple in them are sometimes known as \"Hawaiian\" for this reason alone.\n\n"}
{"id": "23703", "url": "https://en.wikipedia.org/wiki?curid=23703", "title": "Potential energy", "text": "Potential energy\n\nIn physics, potential energy is the energy held by an object because of its position relative to other objects, stresses within itself, its electric charge, or other factors.\n\nCommon types of potential energy include the gravitational potential energy of an object that depends on its mass and its distance from the center of mass of another object, the elastic potential energy of an extended spring, and the electric potential energy of an electric charge in an electric field. The unit for energy in the International System of Units (SI) is the joule, which has the symbol J.\n\nThe term \"potential energy\" was introduced by the 19th century Scottish engineer and physicist William Rankine, although it has links to Greek philosopher Aristotle's concept of potentiality.\nPotential energy is associated with forces that act on a body in a way that the total work done by these forces on the body depends only on the initial and final positions of the body in space. These forces, that are called \"conservative forces\", can be represented at every point in space by vectors expressed as gradients of a certain scalar function called \"potential\".\n\nSince the work of potential forces acting on a body that moves from a start to an end position is determined only by these two positions, and does not depend on the trajectory of the body, there is a function known as \"potential\" or \"potential energy\" that can be evaluated at the two positions to determine this work.\n\nThere are various types of potential energy, each associated with a particular type of force. For example, the work of an elastic force is called elastic potential energy; work of the gravitational force is called gravitational potential energy; work of the Coulomb force is called electric potential energy; work of the strong nuclear force or weak nuclear force acting on the baryon charge is called nuclear potential energy; work of intermolecular forces is called intermolecular potential energy. Chemical potential energy, such as the energy stored in fossil fuels, is the work of the Coulomb force during rearrangement of mutual positions of electrons and nuclei in atoms and molecules. Thermal energy usually has two components: the kinetic energy of random motions of particles and the potential energy of their mutual positions.\n\nForces derivable from a potential are also called conservative forces. The work done by a conservative force is\nwhere formula_2 is the change in the potential energy associated with the force. The negative sign provides the convention that work done against a force field increases potential energy, while work done by the force field decreases potential energy. Common notations for potential energy are \"PE\", \"U\", \"V\", and \"E\".\n\nPotential energy is the energy by virtue of an object's position relative to other objects. Potential energy is often associated with restoring forces such as a spring or the force of gravity. The action of stretching a spring or lifting a mass is performed by an external force that works against the force field of the potential. This work is stored in the force field, which is said to be stored as potential energy. If the external force is removed the force field acts on the body to perform the work as it moves the body back to the initial position, reducing the stretch of the spring or causing a body to fall.\n\nConsider a ball whose mass is m and whose height is h. The acceleration g of free fall is approximately constant, so the weight force of the ball mg is constant. Force × displacement gives the work done, which is equal to the gravitational potential energy, thus\n\nThe more formal definition is that potential energy is the energy difference between the energy of an object in a given position and its energy at a reference position.\n\nPotential energy is closely linked with forces. If the work done by a force on a body that moves from \"A\" to \"B\" does not depend on the path between these points (if the work is done by a conservative force), then the work of this force measured from \"A\" assigns a scalar value to every other point in space and defines a scalar potential field. In this case, the force can be defined as the negative of the vector gradient of the potential field.\nIf the work for an applied force is independent of the path, then the work done by the force is evaluated at the start and end of the trajectory of the point of application. This means that there is a function \"U\"(x), called a \"potential,\" that can be evaluated at the two points x and x to obtain the work over any trajectory between these two points. It is tradition to define this function with a negative sign so that positive work is a reduction in the potential, that is \nwhere \"C\" is the trajectory taken from A to B. Because the work done is independent of the path taken, then this expression is true for any trajectory, \"C\", from A to B.\n\nThe function \"U\"(x) is called the potential energy associated with the applied force. Examples of forces that have potential energies are gravity and spring forces.\n\nIn this section the relationship between work and potential energy is presented in more detail. The line integral that defines work along curve \"C\" takes a special form if the force F is related to a scalar field φ(x) so that\nIn this case, work along the curve is given by\nwhich can be evaluated using the gradient theorem to obtain\nThis shows that when forces are derivable from a scalar field, the work of those forces along a curve \"C\" is computed by evaluating the scalar field at the start point \"A\" and the end point \"B\" of the curve. This means the work integral does not depend on the path between \"A\" and \"B\" and is said to be independent of the path.\n\nPotential energy \"U\"=-φ(x) is traditionally defined as the negative of this scalar field so that work by the force field decreases potential energy, that is\n\nIn this case, the application of the del operator to the work function yields,\nand the force F is said to be \"derivable from a potential.\" This also necessarily implies that F must be a conservative vector field. The potential \"U\" defines a force F at every point x in space, so the set of forces is called a force field.\n\nGiven a force field F(x), evaluation of the work integral using the gradient theorem can be used to find the scalar function associated with potential energy. This is done by introducing a parameterized curve γ(t)=r(t) from γ(a)=A to γ(b)=B, and computing,\n\nFor the force field F, let v= dr/dt, then the gradient theorem yields,\n\nThe power applied to a body by a force field is obtained from the gradient of the work, or potential, in the direction of the velocity v of the point of application, that is\n\nExamples of work that can be computed from potential functions are gravity and spring forces.\n\nFor small height changes, gravitational potential energy can be computed using\n\nwhere m is the mass in kg, g is the local gravitational field (9.8 metres per second squared on earth) and h is the height above a reference level in metres.\n\nIn classical physics, gravity exerts a constant downward force F=(0, 0, \"F\") on the center of mass of a body moving near the surface of the Earth. The work of gravity on a body moving along a trajectory r(t) = (\"x\"(t), \"y\"(t), \"z\"(t)), such as the track of a roller coaster is calculated using its velocity, v=(\"v\", \"v\", \"v\"), to obtain\nwhere the integral of the vertical component of velocity is the vertical distance. Notice that the work of gravity depends only on the vertical movement of the curve r(t).\n\nA horizontal spring exerts a force F = (−\"kx\", 0, 0) that is proportional to its deformation in the axial or \"x\" direction. The work of this spring on a body moving along the space curve s(\"t\") = (\"x\"(\"t\"), \"y\"(\"t\"), \"z\"(\"t\")), is calculated using its velocity, v = (\"v\", \"v\", \"v\"), to obtain\nFor convenience, consider contact with the spring occurs at \"t\" = 0, then the integral of the product of the distance \"x\" and the \"x\"-velocity, \"xv\", is \"x\"/2.\n\nThe function \nis called the potential energy of a linear spring.\n\nElastic potential energy is the potential energy of an elastic object (for example a bow or a catapult) that is deformed under tension or compression (or stressed in formal terminology). It arises as a consequence of a force that tries to restore the object to its original shape, which is most often the electromagnetic force between the atoms and molecules that constitute the object. If the stretch is released, the energy is transformed into kinetic energy.\n\nThe gravitational potential function, also known as gravitational potential energy, is:\n\nThe negative sign follows the convention that work is gained from a loss of potential energy.\n\nThe gravitational force between two bodies of mass \"M\" and \"m\" separated by a distance \"r\" is given by\n\nwhere formula_19 is a vector of length 1 pointing from \"M\" to \"m\" and \"G\" is the gravitational constant.\n\nLet the mass \"m\" move at the velocity v then the work of gravity on this mass as it moves from position r(t) to r(t) is given by\nNotice that the position and velocity of the mass \"m\" are given by\n\nwhere e and e are the radial and tangential unit vectors directed relative to the vector from \"M\" to \"m\". Use this to simplify the formula for work of gravity to,\n\nThis calculation uses the fact that\n\nThe electrostatic force exerted by a charge \"Q\" on another charge \"q\" separated by a distance \"r\" is given by Coulomb's Law\n\nwhere formula_19 is a vector of length 1 pointing from \"Q\" to \"q\" and \"ε\" is the vacuum permittivity. This may also be written using Coulomb's constant .\n\nThe work \"W\" required to move \"q\" from \"A\" to any point \"B\" in the electrostatic force field is given by the potential function\n\nThe potential energy is a function of the state a system is in, and is defined relative to that for a particular state. This reference state is not always a real state; it may also be a limit, such as with the distances between all bodies tending to infinity, provided that the energy involved in tending to that limit is finite, such as in the case of inverse-square law forces. Any arbitrary reference state could be used; therefore it can be chosen based on convenience.\n\nTypically the potential energy of a system depends on the \"relative\" positions of its components only, so the reference state can also be expressed in terms of relative positions.\n\nGravitational energy is the potential energy associated with gravitational force, as work is required to elevate objects against Earth's gravity. The potential energy due to elevated positions is called gravitational potential energy, and is evidenced by water in an elevated reservoir or kept behind a dam. If an object falls from one point to another point inside a gravitational field, the force of gravity will do positive work on the object, and the gravitational potential energy will decrease by the same amount.\n\nConsider a book placed on top of a table. As the book is raised from the floor, to the table, some external force works against the gravitational force. If the book falls back to the floor, the \"falling\" energy the book receives is provided by the gravitational force. Thus, if the book falls off the table, this potential energy goes to accelerate the mass of the book and is converted into kinetic energy. When the book hits the floor this kinetic energy is converted into heat, deformation and sound by the impact.\n\nThe factors that affect an object's gravitational potential energy are its height relative to some reference point, its mass, and the strength of the gravitational field it is in. Thus, a book lying on a table has less gravitational potential energy than the same book on top of a taller cupboard, and less gravitational potential energy than a heavier book lying on the same table. An object at a certain height above the Moon's surface has less gravitational potential energy than at the same height above the Earth's surface because the Moon's gravity is weaker. Note that \"height\" in the common sense of the term cannot be used for gravitational potential energy calculations when gravity is not assumed to be a constant. The following sections provide more detail.\n\nThe strength of a gravitational field varies with location. However, when the change of distance is small in relation to the distances from the center of the source of the gravitational field, this variation in field strength is negligible and we can assume that the force of gravity on a particular object is constant. Near the surface of the Earth, for example, we assume that the acceleration due to gravity is a constant (\"standard gravity\"). In this case, a simple expression for gravitational potential energy can be derived using the \"W\" = \"Fd\" equation for work, and the equation\n\nThe amount of gravitational potential energy held by an elevated object is equal to the work done against gravity in lifting it. The work done equals the force required to move it upward multiplied with the vertical distance it is moved (remember \"W = Fd\"). The upward force required while moving at a constant velocity is equal to the weight, \"mg\", of an object, so the work done in lifting it through a height \"h\" is the product \"mgh\". Thus, when accounting only for mass, gravity, and altitude, the equation is:\nwhere \"U\" is the potential energy of the object relative to its being on the Earth's surface, \"m\" is the mass of the object, \"g\" is the acceleration due to gravity, and \"h\" is the altitude of the object. If \"m\" is expressed in kilograms, \"g\" in m/s and \"h\" in metres then \"U\" will be calculated in joules.\n\nHence, the potential difference is\n\nHowever, over large variations in distance, the approximation that \"g\" is constant is no longer valid, and we have to use calculus and the general mathematical definition of work to determine gravitational potential energy. For the computation of the potential energy we can integrate the gravitational force, whose magnitude is given by Newton's law of gravitation, with respect to the distance \"r\" between the two bodies. Using that definition, the gravitational potential energy of a system of masses \"m\" and \"M\" at a distance \"r\" using gravitational constant \"G\" is\n\nwhere \"K\" is an arbitrary constant dependent on the choice of datum from which potential is measured. Choosing the convention that \"K\"=0 (i.e. in relation to a point at infinity) makes calculations simpler, albeit at the cost of making \"U\" negative; for why this is physically reasonable, see below.\n\nGiven this formula for \"U\", the total potential energy of a system of \"n\" bodies is found by summing, for all formula_31 pairs of two bodies, the potential energy of the system of those two bodies.\n\nConsidering the system of bodies as the combined set of small particles the bodies consist of, and applying the previous on the particle level we get the negative gravitational binding energy. This potential energy is more strongly negative than the total potential energy of the system of bodies as such since it also includes the negative gravitational binding energy of each body. The potential energy of the system of bodies as such is the negative of the energy needed to separate the bodies from each other to infinity, while the gravitational binding energy is the energy needed to separate all particles from each other to infinity.\ntherefore,\n\nAs with all potential energies, only differences in gravitational potential energy matter for most physical purposes, and the choice of zero point is arbitrary. Given that there is no reasonable criterion for preferring one particular finite \"r\" over another, there seem to be only two reasonable choices for the distance at which \"U\" becomes zero: formula_34 and formula_35. The choice of formula_36 at infinity may seem peculiar, and the consequence that gravitational energy is always negative may seem counterintuitive, but this choice allows gravitational potential energy values to be finite, albeit negative.\n\nThe singularity at formula_34 in the formula for gravitational potential energy means that the only other apparently reasonable alternative choice of convention, with formula_36 for formula_34, would result in potential energy being positive, but infinitely large for all nonzero values of \"r\", and would make calculations involving sums or differences of potential energies beyond what is possible with the real number system. Since physicists abhor infinities in their calculations, and \"r\" is always non-zero in practice, the choice of formula_36 at infinity is by far the more preferable choice, even if the idea of negative energy in a gravity well appears to be peculiar at first.\n\nThe negative value for gravitational energy also has deeper implications that make it seem more reasonable in cosmological calculations where the total energy of the universe can meaningfully be considered; see inflation theory for more on this.\n\nGravitational potential energy has a number of practical uses, notably the generation of pumped-storage hydroelectricity. For example, in Dinorwig, Wales, there are two lakes, one at a higher elevation than the other. At times when surplus electricity is not required (and so is comparatively cheap), water is pumped up to the higher lake, thus converting the electrical energy (running the pump) to gravitational potential energy. At times of peak demand for electricity, the water flows back down through electrical generator turbines, converting the potential energy into kinetic energy and then back into electricity. The process is not completely efficient and some of the original energy from the surplus electricity is in fact lost to friction.\n\nGravitational potential energy is also used to power clocks in which falling weights operate the mechanism. It's also used by counterweights for lifting up an elevator, crane, or sash window.\nRoller coasters are an entertaining way to utilize potential energy - chains are used to move a car up an incline (building up gravitational potential energy), to then have that energy converted into kinetic energy as it falls.\n\nAnother practical use is utilizing gravitational potential energy to descend (perhaps coast) downhill in transportation such as the descent of an automobile, truck, railroad train, bicycle, airplane, or fluid in a pipeline. In some cases the kinetic energy obtained from potential energy of descent may be used to start ascending the next grade such as what happens when a road is undulating and has frequent dips. The commercialization of stored energy (in the form of rail cars raised to higher elevations) that is then converted to electrical energy when needed by an electrical grid, is being undertaken in the United States in a system called Advanced Rail Energy Storage (ARES).\n\nChemical potential energy is a form of potential energy related to the structural arrangement of atoms or molecules. This arrangement may be the result of chemical bonds within a molecule or otherwise. Chemical energy of a chemical substance can be transformed to other forms of energy by a chemical reaction. As an example, when a fuel is burned the chemical energy is converted to heat, same is the case with digestion of food metabolized in a biological organism. Green plants transform solar energy to chemical energy through the process known as photosynthesis, and electrical energy can be converted to chemical energy through electrochemical reactions.\n\nThe similar term chemical potential is used to indicate the potential of a substance to undergo a change of configuration, be it in the form of a chemical reaction, spatial transport, particle exchange with a reservoir, etc.\n\nAn object can have potential energy by virtue of its electric charge and several forces related to their presence. There are two main types of this kind of potential energy: electrostatic potential energy, electrodynamic potential energy (also sometimes called magnetic potential energy).\n\nElectrostatic potential energy between two bodies in space is obtained from the force exerted by a charge \"Q\" on another charge \"q\" which is given by\n\nwhere formula_19 is a vector of length 1 pointing from \"Q\" to \"q\" and \"ε\" is the vacuum permittivity. This may also be written using Coulomb's constant .\n\nIf the electric charge of an object can be assumed to be at rest, then it has potential energy due to its position relative to other charged objects. The electrostatic potential energy is the energy of an electrically charged particle (at rest) in an electric field. It is defined as the work that must be done to move it from an infinite distance away to its present location, adjusted for non-electrical forces on the object. This energy will generally be non-zero if there is another electrically charged object nearby.\n\nThe work \"W\" required to move \"q\" from \"A\" to any point \"B\" in the electrostatic force field is given by\ntypically given in \"J\" for Joules. A related quantity called \"electric potential\" (commonly denoted with a \"V\" for voltage) is equal to the electric potential energy per unit charge.\n\nThe energy of a magnetic moment formula_44 in an externally produced magnetic B-field has potential energy\n\nThe magnetization in a field is\n\nwhere the integral can be over all space or, equivalently, where is nonzero.\nMagnetic potential energy is the form of energy related not only to the distance between magnetic materials, but also to the orientation, or alignment, of those materials within the field. For example, the needle of a compass has the lowest magnetic potential energy when it is aligned with the north and south poles of the Earth's magnetic field. If the needle is moved by an outside force, torque is exerted on the magnetic dipole of the needle by the Earth's magnetic field, causing it to move back into alignment. The magnetic potential energy of the needle is highest when its field is in the same direction as the Earth's magnetic field. Two magnets will have potential energy in relation to each other and the distance between them, but this also depends on their orientation. If the opposite poles are held apart, the potential energy will be higher the further they are apart and lower the closer they are. Conversely, like poles will have the highest potential energy when forced together, and the lowest when they spring apart.\n\nNuclear potential energy is the potential energy of the particles inside an atomic nucleus. The nuclear particles are bound together by the strong nuclear force. Weak nuclear forces provide the potential energy for certain kinds of radioactive decay, such as beta decay.\n\nNuclear particles like protons and neutrons are not destroyed in fission and fusion processes, but collections of them can have less mass than if they were individually free, in which case this mass difference can be liberated as heat and radiation in nuclear reactions (the heat and radiation have the missing mass, but it often escapes from the system, where it is not measured). The energy from the Sun is an example of this form of energy conversion. In the Sun, the process of hydrogen fusion converts about 4 million tonnes of solar matter per second into electromagnetic energy, which is radiated into space.\n\nPotential energy is closely linked with forces. If the work done by a force on a body that moves from \"A\" to \"B\" does not depend on the path between these points, then the work of this force measured from \"A\" assigns a scalar value to every other point in space and defines a scalar potential field. In this case, the force can be defined as the negative of the vector gradient of the potential field.\n\nFor example, gravity is a conservative force. The associated potential is the gravitational potential, often denoted by formula_47 or formula_48, corresponding to the energy per unit mass as a function of position. The gravitational potential energy of two particles of mass \"M\" and \"m\" separated by a distance \"r\" is\nThe gravitational potential (specific energy) of the two bodies is\nwhere formula_51 is the reduced mass.\n\nThe work done against gravity by moving an infinitesimal mass from point A with formula_52 to point B with formula_53 is formula_54 and the work done going back the other way is formula_55 so that the total work done in moving from A to B and returning to A is\nIf the potential is redefined at A to be formula_57 and the potential at B to be formula_58, where formula_59 is a constant (i.e. formula_59 can be any number, positive or negative, but it must be the same at A as it is at B) then the work done going from A to B is\nas before.\n\nIn practical terms, this means that one can set the zero of formula_62 and formula_47 anywhere one likes. One may set it to be zero at the surface of the Earth, or may find it more convenient to set zero at infinity (as in the expressions given earlier in this section).\nA conservative force can be expressed in the language of differential geometry as a closed form. As Euclidean space is contractible, its de Rham cohomology vanishes, so every closed form is also an exact form, and can be expressed as the gradient of a scalar field. This gives a mathematical justification of the fact that all conservative forces are gradients of a potential field.\n\n\n"}
{"id": "4990250", "url": "https://en.wikipedia.org/wiki?curid=4990250", "title": "Quetta Electric Supply Company", "text": "Quetta Electric Supply Company\n\nThe Quetta Electric Supply Company (QESCO) is an electric distribution company which supplies electricity to the city of Quetta, Balochistan, Pakistan.\n\n"}
{"id": "3516071", "url": "https://en.wikipedia.org/wiki?curid=3516071", "title": "Rig standpipe", "text": "Rig standpipe\n\nA rig standpipe is a solid metal pipe attached to the side of a drilling rig's derrick that is a part of its drilling mud system. It is used to conduct drilling fluid from the mud pumps to the kelly hose. Bull plugs, pressure transducers and valves are found on the rig standpipe.\n"}
{"id": "21699537", "url": "https://en.wikipedia.org/wiki?curid=21699537", "title": "Salt-concrete", "text": "Salt-concrete\n\nSalt-concrete (or \"salzbeton\") is a construction material that is used to reduce the water inflow in mining shafts in salt mines. It is composed of 16% cement, 39% halite, 16% limestone powder, 14% water and 15% sand.\n\nSalt-concrete was used for the first time in 1984 in the potash mine in Rocanville in Canada. A salt-concrete seal was also installed in the Asse II mine in Lower Saxony in 1995.\n\nSince the end of the repository for radioactive waste Morsleben in 1998, the salt dome stability deteriorated to a state where it could collapse. Since 2003, a volume of m of salt-concrete has been pumped into the pit to temporarily stabilize the upper levels. In addition another m of salt-concrete will be used to temporarily stabilize the lower levels.\n\n"}
{"id": "27121", "url": "https://en.wikipedia.org/wiki?curid=27121", "title": "Samarium", "text": "Samarium\n\nSamarium is a chemical element with symbol Sm and atomic number 62. It is a moderately hard silvery metal that slowly oxidizes in air. Being a typical member of the lanthanide series, samarium usually assumes the oxidation state +3. Compounds of samarium(II) are also known, most notably the monoxide SmO, monochalcogenides SmS, SmSe and SmTe, as well as samarium(II) iodide. The last compound is a common reducing agent in chemical synthesis. Samarium has no significant biological role but is only slightly toxic.\n\nSamarium was discovered in 1879 by the French chemist Paul-Émile Lecoq de Boisbaudran and named after the mineral samarskite from which it was isolated. The mineral itself was earlier named after a Russian mine official, Colonel Vassili Samarsky-Bykhovets, who thereby became the first person to have a chemical element named after him, albeit indirectly. Although classified as a rare-earth element, samarium is the 40th most abundant element in the Earth's crust and is more common than such metals as tin. Samarium occurs with concentration up to 2.8% in several minerals including cerite, gadolinite, samarskite, monazite and bastnäsite, the last two being the most common commercial sources of the element. These minerals are mostly found in China, the United States, Brazil, India, Sri Lanka and Australia; China is by far the world leader in samarium mining and production.\n\nThe major commercial application of samarium is in samarium–cobalt magnets, which have permanent magnetization second only to neodymium magnets; however, samarium compounds can withstand significantly higher temperatures, above , without losing their magnetic properties, due to the alloy's higher Curie point. The radioactive isotope samarium-153 is the active component of the drug samarium (Sm) lexidronam (Quadramet), which kills cancer cells in the treatment of lung cancer, prostate cancer, breast cancer and osteosarcoma. Another isotope, samarium-149, is a strong neutron absorber and is therefore added to the control rods of nuclear reactors. It is also formed as a decay product during the reactor operation and is one of the important factors considered in the reactor design and operation. Other applications of samarium include catalysis of chemical reactions, radioactive dating and an X-ray laser.\n\nSamarium is a rare earth metal having a hardness and density similar to those of zinc. With the boiling point of 1794 °C, samarium is the third most volatile lanthanide after ytterbium and europium; this property facilitates separation of samarium from the mineral ore. At ambient conditions, samarium normally assumes a rhombohedral structure (α form). Upon heating to 731 °C, its crystal symmetry changes into hexagonally close-packed (\"hcp\"), however the transition temperature depends on the metal purity. Further heating to 922 °C transforms the metal into a body-centered cubic (\"bcc\") phase. Heating to 300 °C combined with compression to 40 kbar results in a double-hexagonally close-packed structure (\"dhcp\"). Applying higher pressure of the order of hundreds or thousands of kilobars induces a series of phase transformations, in particular with a tetragonal phase appearing at about 900 kbar. In one study, the \"dhcp\" phase could be produced without compression, using a nonequilibrium annealing regime with a rapid temperature change between about 400 and 700 °C, confirming the transient character of this samarium phase. Also, thin films of samarium obtained by vapor deposition may contain the \"hcp\" or \"dhcp\" phases at ambient conditions.\n\nSamarium (and its sesquioxide) are paramagnetic at room temperature. Their corresponding effective magnetic moments, below 2µ, are the 3rd lowest among the lanthanides (and their oxides) after lanthanum and lutetium. The metal transforms to an antiferromagnetic state upon cooling to 14.8 K. Individual samarium atoms can be isolated by encapsulating them into fullerene molecules. They can also be doped between the C molecules in the fullerene solid, rendering it superconductive at temperatures below 8 K. Samarium doping of iron-based superconductors – the most recent class of high-temperature superconductors – allows enhancing their transition temperature to 56 K, which is the highest value achieved so far in this series.\n\nFreshly prepared samarium has a silvery luster. In air, it slowly oxidizes at room temperature and spontaneously ignites at 150 °C. Even when stored under mineral oil, samarium gradually oxidizes and develops a grayish-yellow powder of the oxide-hydroxide mixture at the surface. The metallic appearance of a sample can be preserved by sealing it under an inert gas such as argon.\n\nSamarium is quite electropositive and reacts slowly with cold water and quite quickly with hot water to form samarium hydroxide:\n\nSamarium dissolves readily in dilute sulfuric acid to form solutions containing the yellow to pale green Sm(III) ions, which exist as [Sm(OH)] complexes:\n\nSamarium is one of the few lanthanides that exhibit the oxidation state +2. The Sm ions are blood-red in aqueous solution.\n\nThe most stable oxide of samarium is the sesquioxide SmO. As many other samarium compounds, it exists in several crystalline phases. The trigonal form is obtained by slow cooling from the melt. The melting point of SmO is rather high (2345 °C) and therefore melting is usually achieved not by direct heating, but with induction heating, through a radio-frequency coil. The SmO crystals of monoclinic symmetry can be grown by the flame fusion method (Verneuil process) from the SmO powder, that yields cylindrical boules up to several centimeters long and about one centimeter in diameter. The boules are transparent when pure and defect-free and are orange otherwise. Heating the metastable trigonal SmO to 1900 °C converts it to the more stable monoclinic phase. Cubic SmO has also been described.\n\nSamarium is one of the few lanthanides that form a monoxide, SmO. This lustrous golden-yellow compound was obtained by reducing SmO with samarium metal at elevated temperature (1000 °C) and pressure above 50 kbar; lowering the pressure resulted in an incomplete reaction. SmO has the cubic rock-salt lattice structure.\n\nSamarium forms trivalent sulfide, selenide and telluride. Divalent chalcogenides SmS, SmSe and SmTe with cubic rock-salt crystal structure are also known. They are remarkable by converting from semiconducting to metallic state at room temperature upon application of pressure. Whereas the transition is continuous and occurs at about 20–30 kbar in SmSe and SmTe, it is abrupt in SmS and requires only 6.5 kbar. This effect results in spectacular color change in SmS from black to golden yellow when its crystals of films are scratched or polished. The transition does not change lattice symmetry, but there is a sharp decrease (~15%) in the crystal volume. It shows hysteresis, that is when the pressure is released, SmS returns to the semiconducting state at much lower pressure of about 0.4 kbar.\n\nSamarium metal reacts with all the halogens, forming trihalides:\n\nTheir further reduction with samarium, lithium or sodium metals at elevated temperatures (about 700–900 °C) yields dihalides. The diiodide can also be prepared by heating SmI, or by reacting the metal with 1,2-diiodoethane in anhydrous tetrahydrofuran at room temperature:\n\nIn addition to dihalides, the reduction also produces numerous non-stoichiometric samarium halides with a well-defined crystal structure, such as SmF, SmF, SmF, SmBr, SmBr and SmBr.\n\nAs reflected in the table above, samarium halides change their crystal structures when one type of halide atoms is substituted for another, which is an uncommon behavior for most elements (e.g. actinides). Many halides have two major crystal phases for one composition, one being significantly more stable and another being metastable. The latter is formed upon compression or heating, followed by quenching to ambient conditions. For example, compressing the usual monoclinic samarium diiodide and releasing the pressure results in a PbCl-type orthorhombic structure (density 5.90 g/cm), and similar treatment results in a new phase of samarium triiodide (density 5.97 g/cm).\n\nSintering powders of samarium oxide and boron, in vacuum, yields a powder containing several samarium boride phases, and their volume ratio can be controlled through the mixing proportion. The powder can be converted into larger crystals of a certain samarium boride using arc melting or zone melting techniques, relying on the different melting/crystallization temperature of SmB (2580 °C), SmB (about 2300 °C) and SmB (2150 °C). All these materials are hard, brittle, dark-gray solids with the hardness increasing with the boron content. Samarium diboride is too volatile to be produced with these methods and requires high pressure (about 65 kbar) and low temperatures between 1140 and 1240 °C to stabilize its growth. Increasing the temperature results in the preferential formations of SmB.\n\nSamarium hexaboride is a typical intermediate-valence compound where samarium is present both as Sm and Sm ions at the ratio 3:7. It belongs to a class of Kondo insulators, that is at high temperatures (above 50 K), its properties are typical of a Kondo metal, with metallic electrical conductivity characterized by strong electron scattering, whereas at low temperatures, it behaves as a non-magnetic insulator with a narrow band gap of about 4–14 meV. The cooling-induced metal-insulator transition in SmB is accompanied by a sharp increase in the thermal conductivity, peaking at about 15 K. The reason for this increase is that electrons themselves do not contribute to the thermal conductivity at low temperatures, which is dominated by phonons, but the decrease in electron concentration reduced the rate of electron-phonon scattering.\n\nNew research seems to show that it may be a topological insulator.\n\nSamarium carbides are prepared by melting a graphite-metal mixture in an inert atmosphere. After the synthesis, they are unstable in air and are studied also under inert atmosphere. Samarium monophosphide SmP is a semiconductor with the bandgap of 1.10 eV, the same as in silicon, and high electrical conductivity of n-type. It can be prepared by annealing at 1100 °C an evacuated quartz ampoule containing mixed powders of phosphorus and samarium. Phosphorus is highly volatile at high temperatures and may explode, thus the heating rate has to be kept well below 1 °C/min. Similar procedure is adopted for the monarsenide SmAs, but the synthesis temperature is higher at 1800 °C.\n\nNumerous crystalline binary compounds are known for samarium and one of the group-14, 15 or 16 element X, where X is Si, Ge, Sn, Pb, Sb or Te, and metallic alloys of samarium form another large group. They are all prepared by annealing mixed powders of the corresponding elements. Many of the resulting compounds are non-stoichiometric and have nominal compositions SmX, where the b/a ratio varies between 0.5 and 3.\n\nSamarium forms a cyclopentadienide Sm(CH) and its chloroderivatives Sm(CH)Cl and Sm(CH)Cl. They are prepared by reacting samarium trichloride with NaCH in tetrahydrofuran. Contrary to cyclopentadienides of most other lanthanides, in Sm(CH) some CH rings bridge each other by forming ring vertexes η or edges η toward another neighboring samarium atom, thereby creating polymeric chains. The chloroderivative Sm(CH)Cl has a dimer structure, which is more accurately expressed as (η-CH)Sm(µ-Cl)(η-CH). There, the chlorine bridges can be replaced, for instance, by iodine, hydrogen or nitrogen atoms or by CN groups.\n\nThe (CH) ion in samarium cyclopentadienides can be replaced by the indenide (CH) or cyclooctatetraenide (CH) ring, resulting in Sm(CH) or KSm(η-CH). The latter compound has a similar structure to that of uranocene. There is also a cyclopentadienide of divalent samarium, Sm(CH) – a solid that sublimates at about 85 °C. Contrary to ferrocene, the CH rings in Sm(CH) are not parallel but are tilted by 40°.\n\nAlkyls and aryls of samarium are obtained through a metathesis reaction in tetrahydrofuran or ether:\n\nHere R is a hydrocarbon group and Me stands for methyl.\n\nNaturally occurring samarium has a radioactivity of 128 Bq/g. It is composed of four stable isotopes: Sm, Sm, Sm and Sm, and three extremely long-lived radioisotopes, Sm (half-life \"t\" = 1.06 years), Sm (7 years) and Sm (>2 years), with Sm being the most abundant (natural abundance 26.75%). Sm is listed by various sources either as stable or radioactive isotope.\n\nThe long-lived isotopes,Sm, Sm, and Sm, primarily decay by emission of alpha particles to isotopes of neodymium. Lighter unstable isotopes of samarium primarily decay by electron capture to isotopes of promethium, while heavier ones convert through beta decay to isotopes of europium.\n\nThe alpha decay of Sm to Nd with a half-life of 1.06 years serve for samarium–neodymium dating.\n\nThe half-lives of Sm and Sm are 90 years and 340 days, respectively. All the remaining radioisotopes have half-lives that are less than 2 days, and the majority of these have half-lives that are less than 48 seconds. Samarium also has five nuclear isomers with the most stable being Sm (half-life 22.6 minutes), Sm (\"t\" = 66 seconds) and Sm (\"t\" = 10.7 seconds).\n\nDetection of samarium and related elements was announced by several scientists in the second half of the 19th century; however, most sources give the priority to the French chemist Paul Émile Lecoq de Boisbaudran. Boisbaudran isolated samarium oxide and/or hydroxide in Paris in 1879 from the mineral samarskite ((Y,Ce,U,Fe)(Nb,Ta,Ti)O) and identified a new element in it via sharp optical absorption lines. The Swiss chemist Marc Delafontaine announced a new element \"decipium\" (from meaning \"deceptive, misleading\") in 1878, but later in 1880–1881 demonstrated that it was a mixture of several elements, one being identical to the Boisbaudran's samarium. Although samarskite was first found in the remote Russian region of Urals, by the late 1870s its deposits had been located in other places making the mineral available to many researchers. In particular, it was found that the samarium isolated by Boisbaudran was also impure and contained comparable amount of europium. The pure element was produced only in 1901 by Eugène-Anatole Demarçay.\n\nBoisbaudran named his element \"samaria\" after the mineral samarskite, which in turn honored Vassili Samarsky-Bykhovets (1803–1870). Samarsky-Bykhovets, as the Chief of Staff of the Russian Corps of Mining Engineers, had granted access for two German mineralogists, the brothers Gustav Rose and Heinrich Rose, to study the mineral samples from the Urals. In this sense samarium was the first chemical element to be named after a person. Later the name \"samaria\" used by Boisbaudran was transformed into \"samarium\", to conform with other element names, and samaria nowadays is sometimes used to refer to samarium oxide, by analogy with yttria, zirconia, alumina, ceria, holmia, etc. The symbol \"Sm\" was suggested for samarium; however an alternative \"Sa\" was frequently used instead until the 1920s.\n\nPrior to the advent of ion-exchange separation technology in the 1950s, samarium had no commercial uses in pure form. However, a by-product of the fractional crystallization purification of neodymium was a mixture of samarium and gadolinium that acquired the name of \"Lindsay Mix\" after the company that made it. This material is thought to have been used for nuclear control rods in some early nuclear reactors. Nowadays, a similar commodity product has the name \"samarium-europium-gadolinium\" (SEG) concentrate. It is prepared by solvent extraction from the mixed lanthanides isolated from bastnäsite (or monazite). Since the heavier lanthanides have the greater affinity for the solvent used, they are easily extracted from the bulk using relatively small proportions of solvent. Not all rare-earth producers who process bastnäsite do so on a large enough scale to continue onward with the separation of the components of SEG, which typically makes up only one or two percent of the original ore. Such producers will therefore be making SEG with a view to marketing it to the specialized processors. In this manner, the valuable europium content of the ore is rescued for use in phosphor manufacture. Samarium purification follows the removal of the europium. , being in oversupply, samarium oxide is less expensive on a commercial scale than its relative abundance in the ore might suggest.\n\nWith the average concentration of about 8 parts per million (ppm), samarium is the 40th most abundant element in the Earth's crust. It is the fifth most abundant lanthanide and is more common than elements such as tin. Samarium concentration in soils varies between 2 and 23 ppm, and oceans contain about 0.5–0.8 parts per trillion. Distribution of samarium in soils strongly depends on its chemical state and is very inhomogeneous: in sandy soils, samarium concentration is about 200 times higher at the surface of soil particles than in the water trapped between them, and this ratio can exceed 1,000 in clays.\n\nSamarium is not found free in nature, but, like other rare earth elements, is contained in many minerals, including monazite, bastnäsite, cerite, gadolinite and samarskite; monazite (in which samarium occurs at concentrations of up to 2.8%) and bastnäsite are mostly used as commercial sources. World resources of samarium are estimated at two million tonnes; they are mostly located in China, US, Brazil, India, Sri Lanka and Australia, and the annual production is about 700 tonnes. Country production reports are usually given for all rare-earth metals combined. By far, China has the largest production with 120,000 tonnes mined per year; it is followed by the US (about 5,000 tonnes) and India (2,700 tonnes). Samarium is usually sold as oxide, which at the price of about 30 USD/kg is one of the cheapest lanthanide oxides. Whereas mischmetal – a mixture of rare earth metals containing about 1% of samarium – has long been used, relatively pure samarium has been isolated only recently, through ion exchange processes, solvent extraction techniques, and electrochemical deposition. The metal is often prepared by electrolysis of a molten mixture of samarium(III) chloride with sodium chloride or calcium chloride. Samarium can also be obtained by reducing its oxide with lanthanum. The product is then distilled to separate samarium (boiling point 1794 °C) and lanthanum (b.p. 3464 °C).\n\nDomination of samarium in minerals is unique. Minerals with essential (dominant) samarium include monazite-(Sm) and florencite-(Sm). They are very rare.\n\nSamarium-151 is produced in nuclear fission of uranium with the yield of about\n0.4% of the total number of fission events. It is also synthesized upon neutron capture by samarium-149, which is added to the control rods of nuclear reactors. Consequently, samarium-151 is present in spent nuclear fuel and radioactive waste.\n\nOne of the most important applications of samarium is in samarium–cobalt magnets, which have a nominal composition of SmCo or SmCo. They have high permanent magnetization, which is about 10,000 times that of iron and is second only to that of neodymium magnets. However, samarium-based magnets have higher resistance to demagnetization, as they are stable to temperatures above 700 °C (cf. 300–400 °C for neodymium magnets). These magnets are found in small motors, headphones, and high-end magnetic pickups for guitars and related musical instruments. For example, they are used in the motors of a solar-powered electric aircraft, the Solar Challenger, and in the Samarium Cobalt Noiseless electric guitar and bass pickups.\n\nAnother important application of samarium and its compounds is as catalyst and chemical reagent. Samarium catalysts assist decomposition of plastics, dechlorination of pollutants such as polychlorinated biphenyls (PCBs), as well as the dehydration and dehydrogenation of ethanol. Samarium(III) triflate (Sm(OTf), that is Sm(CFSO)), is one of the most efficient Lewis acid catalysts for a halogen-promoted Friedel–Crafts reaction with alkenes. Samarium(II) iodide is a very common reducing and coupling agent in organic synthesis, for example in the desulfonylation reactions; annulation; Danishefsky, Kuwajima, Mukaiyama and Holton Taxol total syntheses; strychnine total synthesis; Barbier reaction and other reductions with samarium(II) iodide.\n\nIn its usual oxidized form, samarium is added to ceramics and glasses where it increases absorption of infrared light. As a (minor) part of mischmetal, samarium is found in \"flint\" ignition device of many lighters and torches.\nRadioactive samarium-153 is a beta emitter with a half-life of 46.3 hours. It is used to kill cancer cells in the treatment of lung cancer, prostate cancer, breast cancer, and osteosarcoma. For this purpose, samarium-153 is chelated with ethylene diamine tetramethylene phosphonate (EDTMP) and injected intravenously. The chelation prevents accumulation of radioactive samarium in the body that would result in excessive irradiation and generation of new cancer cells. The corresponding drug has several names including samarium (Sm) lexidronam; its trade name is Quadramet.\n\nSamarium-149 has high cross-section for neutron capture (41,000 barns) and is therefore used in the control rods of nuclear reactors. Its advantage compared to competing materials, such as boron and cadmium, is stability of absorption – most of the fusion and decay products of samarium-149 are other isotopes of samarium that are also good neutron absorbers. For example, the cross section of samarium-151 is 15,000 barns, it is on the order of hundreds of barns for Sm, Sm, and Sm, and is 6,800 barns for natural (mixed-isotope) samarium. Among the decay products in a nuclear reactor, samarium-149 is regarded as the second most important for the reactor design and operation after xenon-135.\n\nSamarium hexaboride, abbreviated SmB, has recently been shown to be a topological insulator with potential applications to quantum computing.\n\nSamarium-doped calcium fluoride crystals were used as an active medium in one of the first solid-state lasers designed and constructed by Peter Sorokin (co-inventor of the dye laser) and Mirek Stevenson at IBM research labs in early 1961. This samarium laser emitted pulses of red light at 708.5 nm. It had to be cooled by liquid helium and thus did not find practical applications.\n\nAnother samarium-based laser became the first saturated X-ray laser operating at wavelengths shorter than 10 nanometers. It provided 50-picosecond pulses at 7.3 and 6.8 nm suitable for applications in holography, high-resolution microscopy of biological specimens, deflectometry, interferometry, and radiography of dense plasmas related to confinement fusion and astrophysics. Saturated operation meant that the maximum possible power was extracted from the lasing medium, resulting in the high peak energy of 0.3 mJ. The active medium was samarium plasma produced by irradiating samarium-coated glass with a pulsed infrared (wavelength ~1.05 µm).\n\nThe change in electrical resistivity in samarium monochalcogenides can be used in a pressure sensor or in a memory device triggered between a low-resistance and high-resistance state by external pressure, and such devices are being developed commercially. Samarium monosulfide also generates electric voltage upon moderate heating to about 150 °C that can be applied in thermoelectric power converters.\n\nThe analysis of relative concentrations of samarium and neodymium isotopes Sm, Nd, and Nd allows the determination of the age and origin of rocks and meteorites in samarium–neodymium dating. Both elements are lanthanides and have very similar physical and chemical properties. Therefore, Sm–Nd dating is either insensitive to partitioning of the marker elements during various geological processes, or such partitioning can well be understood and modeled from the ionic radii of the involved elements.\n\nThe Sm ion is a potential activator for use in warm-white light emitting diodes. It offers high luminous efficacy due to the narrow emission bands, however, the generally low quantum efficiency and insufficient absorption in the UV-A to blue spectral region hinders commercial application.\n\nIn recent years it has been demonstrated that nanocrystalline BaFCl:Sm as prepared by a co-precipitation can serve as a very efficient x-ray storage phosphor. The co-precipitation leads to nanocrystallites of the order of 100-200 nm in size and their sensitivity as x-ray storage phosphors is increased an astounding ∼500,000 times because of the specific arrangements and density of defect centres in comparison with microcrystalline samples prepared by sintering at high temperature. The mechanism is based on the reduction of Sm to Sm by trapping electrons that are created upon exposure to ionizing radiation in the BaFCl host. The D- F f-f luminescence lines can be very efficiently excited via the parity allowed 4f →4f 5d transition at around 417 nm. The latter wavelength is ideal for efficient excitation by blue-violet laser diodes as the transition is electric dipole allowed and thus relatively intense (400 l/(mol⋅cm)).\nThe phosphor has potential applications in personal dosimetry, dosimetry and imaging in radiotherapy, and medical imaging.\n\nSamarium salts stimulate metabolism, but it is unclear whether this is the effect of samarium or other lanthanides present with it. The total amount of samarium in adults is about 50 µg, mostly in liver and kidneys and with about 8 µg/L being dissolved in the blood. Samarium is not absorbed by plants to a measurable concentration and therefore is normally not a part of human diet. However, a few plants and vegetables may contain up to 1 part per million of samarium. Insoluble salts of samarium are non-toxic and the soluble ones are only slightly toxic.\n\nWhen ingested, only about 0.05% of samarium salts is absorbed into the bloodstream and the remainder is excreted. From the blood, about 45% goes to the liver and 45% is deposited on the surface of the bones where it remains for about 10 years; the balance 10% is excreted.\n\n"}
{"id": "13266770", "url": "https://en.wikipedia.org/wiki?curid=13266770", "title": "Sialon", "text": "Sialon\n\nSiAlON ceramics are a specialist class of high-temperature refractory materials, with high strength at ambient and high temperatures, good thermal shock resistance and exceptional resistance to wetting or corrosion by molten non-ferrous metals, compared to other refractory materials such as, for example, alumina. A typical use is with handling of molten aluminium. They also are exceptionally corrosion resistant and hence are also used in the chemical industry. SiAlONs also have high wear resistance, low thermal expansion and good oxidation resistance up to above ~1000 °C. They were first reported around 1971.\n\nSiAlONs are ceramics based on the elements silicon (Si), aluminium (Al), oxygen (O) and nitrogen (N). They are solid solutions of silicon nitride (SiN), where Si–N bonds are partly replaced with Al–N and Al–O bonds. The substitution degrees can be estimated from the lattice parameters. The charge discrepancy caused by the substitution can be compensated by adding metal cations such as Li, Mg, Ca, Y and Ln, where Ln stands for lanthanide. SiAlONs exist in three basic forms, which are iso-structural with one of the two common forms of silicon nitride, alpha and beta, and with orthorhombic silicon oxynitride; they are hence named as α, β and O'-SiAlONs.\n\nSiAlONs are produced by first combining a mixture of raw materials including silicon nitride, alumina, aluminium nitride, silica and the oxide of a rare-earth element such as yttrium. The powder mix is fabricated into a \"green\" compact by isostatic powder compaction or slipcasting, for example. Then the shaped form is densified, typically by pressureless sintering or hot isostatic pressing. The sintered part may then need to be machined by diamond grinding (abrasive cutting).\n\nSiAlON ceramics have found extensive use in non-ferrous molten metal handling, particularly aluminium and its alloys, including metal feed tubes for aluminum die casting, burner and immersion heater tubes, injector and degassing for nonferrous metals, thermocouple protection tubes, crucibles and ladles.\n\nIn metal forming, SiAlON is used as a cutting tool for machining chill cast iron and as brazing and welding fixtures and pins, particularly for resistance welding.\n\nOther applications include in the chemical and process industries and the oil and gas industries, due to sialons excellent chemical stability and corrosion resistance and wear resistance properties.\n\nSome rare-earth activated SiAlONs are photoluminescent and can serve as phosphors. Europium(II)-doped β-SiAlON absorbs in ultraviolet and visible light spectrum and emits intense broadband visible emission. Its luminance and color does not change significantly with temperature, due to the temperature-stable crystal structure. It has a great potential as a green down-conversion phosphor for white LEDs; a yellow variant also exists. For white LEDs, a blue LED is used with a yellow phosphor, or with a green and yellow SiAlON phosphor and a red CaAlSiN-based (CASN) phosphor.\n"}
{"id": "41269027", "url": "https://en.wikipedia.org/wiki?curid=41269027", "title": "South Texas Oilfield Expo", "text": "South Texas Oilfield Expo\n\nThe South Texas Oilfield Expo is an oil and gas industry trade show held annually at the Henry B. Gonzalez Convention Center in San Antonio. Produced by trade show production company Event Equity Partners LLC, the expo was previously held at the American Bank Center in Corpus Christi. The 2012 event featured 2000 exhibitors in over 600 booths, and was the largest event held at the American Bank Center since SMG took over the venue in 2004, according to facility administrators.\n\nThe 2014 event, which took place July 9–10, 2014, was recognized by Trade Show Executive's annual \"Fastest 50 Awards & Summit\" as the fifth fastest-growing trade show in North America when measured by net square footage. The 2016 event is scheduled for July 27 and 28, 2016.\n\n"}
{"id": "49259329", "url": "https://en.wikipedia.org/wiki?curid=49259329", "title": "Stock Tank Oil", "text": "Stock Tank Oil\n\nStock Tank Oil refers to the volume of oil after flashing to nominal atmospheric (or other stated) storage pressure and temperature (as opposed to reservoir conditions).\n\nNot to be confused with stock tank original oil-in-place (STOOIP) or stock tank oil-initially-in-place (STOIIP).\n\n"}
{"id": "32045633", "url": "https://en.wikipedia.org/wiki?curid=32045633", "title": "Superdense carbon allotropes", "text": "Superdense carbon allotropes\n\nSuperdense carbon allotropes are proposed configurations of carbon atoms that result in a stable material with a higher density than diamond.\n\nFew hypothetical carbon allotropes denser than diamond are known. All these allotropes can be divided at two groups: the first are hypothetically stable at ambient condition; the second are high-pressure carbon allotropes which become quasi-stable only at high pressure. According to the SACADA\ndatabase, the first group comprises the structures, called hP3, tI12, st12, r8, I41/a, P41212, m32, m32*, t32, t32*, H-carbon and uni. Among them st12 carbon was proposed as far as 1987 in the work of R. Biswas et al.\n\nMP8, OP8, SC4, BC-8 and (9,0) carbon allotropes belong to the second group - they are hypothetically quasi-stable at the high pressure. BC-8 carbon is not only a superdense allotrope but also one of the oldest hypothetical carbon structure - initially it was proposed in 1984 in the work R. Biswas et al. The MP8 structure proposed in the work J. Sun et al., is almost two times denser than diamond - its density is as high as 7.06 g/cm and it is the highest value reported so far.\n\nAll hypothetical superdense carbon allotropes have dissimilar band gaps compared to the others. For example, SC4 is supposed to be a metallic allotrope while st12, m32, m32*, t32, t32* have band gaps larger that 5.0 eV.\n\nThese new materials would have structures based on carbon tetrahedra, and represent the densest of such structures. On the opposite end of the density spectrum is a recently theorized tetrahedral structure called T-carbon. This is obtained by replacing carbon atoms in diamond with carbon tetrahedra. In contrast to superdense allotropes, T-carbon would have very low density and hardness.\n\n"}
{"id": "9538946", "url": "https://en.wikipedia.org/wiki?curid=9538946", "title": "Suspension keel", "text": "Suspension keel\n\nA suspension keel is an extension pylon to the bodywork of single-seat, open wheel racing cars designed with a raised nose cone, to allow the lower suspension arms to be attached to the car approximately parallel to the road surface. In recent years the placing and design of a suspension keel, or the lack of such, has been one of the few distinct variables in Formula One chassis design.\n\nTraditional low nose cone designs (e.g. the McLaren MP4/4) allow the lower suspension arms to be directly attached to the main structural members of the car. However, since the move to high nose cone designs - which allow better use of airflow underneath the car, and to a lesser extent the front wing - location of these lower arms has proven problematic. For ideal suspension geometry, and hence maximum mechanical grip, the lower arms should be long and near parallel with the road. As there is no longer any structural bodywork in these low positions, extensions were developed to allow the suspension to be mounted with correct geometry. Since the advent of high nose designs in the early 1990s, pioneered on the Tyrrell 019 Formula One car, three major keel designs have emerged to solve this problem:\n\nOne limitation of any keel design is that, while the keel influence may vary, the suspension linkages themselves still disrupt the underbody airflow. This problem was exacerbated when the FIA introduced rule changes in that forced teams to mount their front wing in a more elevated position. In response to this, many F1 teams have developed zero-keel chassis designs. Here the keel is removed entirely, and the suspension is mounted directly to the chassis. As the nose cone is in a raised position, this entails that the suspension arms take a distinctly inclined angle with respect to the road surface, reducing suspension efficiency. However, with continued restrictions to aerodynamic downforce through the use of aerofoil wings, and the lighter V8 engines specified from 2006 onwards causing weight distribution to shift forward, many designers apparently consider this drawback to be less significant than the concomitant increase in venturi downforce generated underneath the car; except for Renault and Red Bull, all of the teams in the 2007 Formula One World Championship used a zero-keel design.\n\n"}
{"id": "30041", "url": "https://en.wikipedia.org/wiki?curid=30041", "title": "Technetium", "text": "Technetium\n\nTechnetium is a chemical element with symbol Tc and atomic number 43. It is the lightest element whose isotopes are all radioactive; none are stable, excluding the fully ionized state of Tc. Nearly all technetium is produced synthetically, and only about 18000 tons can be found at any given time in the Earth's crust. Naturally occurring technetium is a spontaneous fission product in uranium ore and thorium ore, the most common source, or the product of neutron capture in molybdenum ores. This silvery gray, crystalline transition metal lies between rhenium and manganese in group 7 of the periodic table, and its chemical properties are intermediate between those of these two adjacent elements. The most common naturally occurring isotope is Tc.\n\nMany of technetium's properties were predicted by Dmitri Mendeleev before the element was discovered. Mendeleev noted a gap in his periodic table and gave the undiscovered element the provisional name \"ekamanganese\" (\"Em\"). In 1937, technetium (specifically the technetium-97 isotope) became the first predominantly artificial element to be produced, hence its name (from the Greek , meaning \"synthetic or artificial\", + \n\nOne short-lived gamma ray-emitting nuclear isomer of technetium—technetium-99m—is used in nuclear medicine for a wide variety of diagnostic tests, such as bone cancer diagnoses. The ground state of this nuclide, technetium-99, is used as a gamma-ray-free source of beta particles. Long-lived technetium isotopes produced commercially are by-products of the fission of uranium-235 in nuclear reactors and are extracted from nuclear fuel rods. Because no isotope of technetium has a half-life longer than 4.2 million years (technetium-98), the 1952 detection of technetium in red giants, helped to prove that stars can produce heavier elements.\n\nFrom the 1860s through 1871, early forms of the periodic table proposed by Dmitri Mendeleev contained a gap between molybdenum (element 42) and ruthenium (element 44). In 1871, Mendeleev predicted this missing element would occupy the empty place below manganese and have similar chemical properties. Mendeleev gave it the provisional name \"ekamanganese\" (from \"eka\"-, the Sanskrit word for \"one)\" because the predicted element was one place down from the known element manganese.\n\nMany early researchers, both before and after the periodic table was published, were eager to be the first to discover and name the missing element. Its location in the table suggested that it should be easier to find than other undiscovered elements.\n\nGerman chemists Walter Noddack, Otto Berg, and Ida Tacke reported the discovery of element 75 and element 43 in 1925, and named element 43 \"masurium\" (after Masuria in eastern Prussia, now in Poland, the region where Walter Noddack's family originated). The group bombarded columbite with a beam of electrons and deduced element 43 was present by examining X-ray diffraction spectrograms. The wavelength of the X-rays produced is related to the atomic number by a formula derived by Henry Moseley in 1913. The team claimed to detect a faint X-ray signal at a wavelength produced by element 43. Later experimenters could not replicate the discovery, and it was dismissed as an error for many years. Still, in 1933, a series of articles on the discovery of elements quoted the name \"masurium\" for element 43. Whether the 1925 team actually did discover element 43 is still debated.\n\nThe discovery of element 43 was finally confirmed in a 1937 experiment at the University of Palermo in Sicily by Carlo Perrier and Emilio Segrè. In mid-1936, Segrè visited the United States, first Columbia University in New York and then the Lawrence Berkeley National Laboratory in California. He persuaded cyclotron inventor Ernest Lawrence to let him take back some discarded cyclotron parts that had become radioactive. Lawrence mailed him a molybdenum foil that had been part of the deflector in the cyclotron.\n\nSegrè enlisted his colleague Perrier to attempt to prove, through comparative chemistry, that the molybdenum activity was indeed from an element with the atomic number 43. In 1937 they succeeded in isolating the isotopes technetium-95m and technetium-97. University of Palermo officials wanted them to name their discovery \"panormium\", after the Latin name for Palermo, \"Panormus\". In 1947 element 43 was named after the Greek word \"τεχνητός\", meaning \"artificial\", since it was the first element to be artificially produced. Segrè returned to Berkeley and met Glenn T. Seaborg. They isolated the metastable isotope technetium-99m, which is now used in some ten million medical diagnostic procedures annually.\n\nIn 1952, astronomer Paul W. Merrill in California detected the spectral signature of technetium (specifically wavelengths of 403.1 nm, 423.8 nm, 426.2 nm, and 429.7 nm) in light from S-type red giants. The stars were near the end of their lives, yet were rich in this short-lived element, indicating that it was being produced in the stars by nuclear reactions. This evidence bolstered the hypothesis that heavier elements are the product of nucleosynthesis in stars. More recently, such observations provided evidence that elements are formed by neutron capture in the s-process.\n\nSince that discovery, there have been many searches in terrestrial materials for natural sources of technetium. In 1962, technetium-99 was isolated and identified in pitchblende from the Belgian Congo in extremely small quantities (about 0.2 ng/kg); there it originates as a spontaneous fission product of uranium-238. The Oklo natural nuclear fission reactor contains evidence that significant amounts of technetium-99 were produced and have since decayed into ruthenium-99.\n\nTechnetium is a silvery-gray radioactive metal with an appearance similar to platinum, commonly obtained as a gray powder. The crystal structure of the pure metal is hexagonal close-packed. Atomic technetium has characteristic emission lines at these wavelengths of light: 363.3 nm, 403.1 nm, 426.2 nm, 429.7 nm, and 485.3 nm.\n\nThe metal form is slightly paramagnetic, meaning its magnetic dipoles align with external magnetic fields, but will assume random orientations once the field is removed. Pure, metallic, single-crystal technetium becomes a type-II superconductor at temperatures below 7.46 K. Below this temperature, technetium has a very high magnetic penetration depth, greater than any other element except niobium.\n\nTechnetium is located in the seventh group of the periodic table, between rhenium and manganese. As predicted by the periodic law, its chemical properties are between those two elements. Of the two, technetium more closely resembles rhenium, particularly in its chemical inertness and tendency to form covalent bonds. Unlike manganese, technetium does not readily form cations (ions with a net positive charge). Technetium exhibits nine oxidation states from −1 to +7, with +4, +5, and +7 being the most common. Technetium dissolves in aqua regia, nitric acid, and concentrated sulfuric acid, but it is not soluble in hydrochloric acid of any concentration.\n\nMetallic technetium slowly tarnishes in moist air and, in powder form, burns in oxygen.\n\nTechnetium can catalyse the destruction of hydrazine by nitric acid, and this property is due to its multiplicity of valencies. This caused a problem in the separation of plutonium from uranium in nuclear fuel processing, where hydrazine is used as a protective reductant to keep plutonium in the trivalent rather than the more stable tetravalent state. The problem was exacerbated by the mutually-enhanced solvent extraction of technetium and zirconium at the previous stage, and required a process modification.\n\nThe most prevalent form of technetium that is easily accessible is sodium pertechnetate, Na[TcO]. The majority of this material is produced by radioactive decay from [MoO]:\nPertechnetate (tetroxidotechnetate) behaves analogously to perchlorate, both of which are tetrahedral. Unlike permanganate (), it is only a weak oxidizing agent.\n\nRelated to pertechnetate is heptoxide. This pale-yellow, volatile solid is produced by oxidation of Tc metal and related precursors:\nIt is a very rare example of a molecular metal oxide, other examples being OsO and RuO. It adopts a centrosymmetric structure with two types of Tc−O bonds with 167 and 184 pm bond lengths.\n\nTechnetium heptoxide hydrolyzes to pertechnetate and pertechnetic acid, depending on the pH: \n\nHTcO is a strong acid. In concentrated sulfuric acid, [TcO] converts to the octahedral form TcO(OH)(HO), the conjugate base of the hypothetical triaquo complex [TcO(HO)].\n\nTechnetium forms a dioxide, disulfide, diselenide, and ditelluride. An ill-defined TcS forms upon treating pertechnate with hydrogen sulfide. It thermally decomposes into disulfide and elemental sulfur. Similarly the dioxide can be produced by reduction of the TcO.\n\nUnlike the case for rhenium, a trioxide has not been isolated for technetium. However, TcO has been identified in the gas phase using mass spectrometry.\n\nTechnetium forms the simple complex . The potassium salt is isostructural with .\n\nThe following binary (containing only two elements) technetium halides are known: TcF, TcF, TcCl, TcBr, TcBr, α-TcCl, β-TcCl, TcI, α-TcCl, and β-TcCl. The oxidation states range from Tc(VI) to Tc(II). Technetium halides exhibit different structure types, such as molecular octahedral complexes, extended chains, layered sheets, and metal clusters arranged in a three-dimensional network. These compounds are produced by combining the metal and halogen or by less direct reactions.\n\nTcCl is obtained by chlorination of Tc metal or TcO Upon heating, TcCl gives the corresponding Tc(III) and Tc(II) chlorides.\n\nThe structure of TcCl is composed of infinite zigzag chains of edge-sharing TcCl octahedra. It is isomorphous to transition metal tetrachlorides of zirconium, hafnium, and platinum.\n\nTwo polymorphs of technetium trichloride exist, α- and β-TcCl. The α polymorph is also denoted as TcCl. It adopts a confacial bioctahedral structure. It is prepared by treating the chloro-acetate Tc(OCCH)Cl with HCl. Like ReCl, the structure of the α-polymorph consists of triangles with short M-M distances. β-TcCl features octahedral Tc centers, which are organized in pairs, as seen also for molybdenum trichloride. TcBr does not adopt the structure of either trichloride phase. Instead it has the structure of molybdenum tribromide, consisting of chains of confacial octahedra with alternating short and long Tc—Tc contacts. TcI has the same structure as the high temperature phase of TiI, featuring chains of confacial octahedra with equal Tc—Tc contacts.\n\nSeveral anionic technetium halides are known. The binary tetrahalides can be converted to the hexahalides [TcX] (X = F, Cl, Br, I), which adopt octahedral molecular geometry. More reduced halides form anionic clusters with Tc–Tc bonds. The situation is similar for the related elements of Mo, W, Re. These clusters have the nuclearity Tc, Tc, Tc, and Tc. The more stable Tc and Tc clusters have prism shapes where vertical pairs of Tc atoms are connected by triple bonds and the planar atoms by single bonds. Every technetium atom makes six bonds, and the remaining valence electrons can be saturated by one axial and two bridging ligand halogen atoms such as chlorine or bromine.\n\nTechnetium forms a variety of coordination complexes with organic ligands. Many have been well-investigated because of their relevance to nuclear medicine.\n\nTechnetium forms a variety of compounds with Tc–C bonds, i.e. organotechnetium complexes. Prominent members of this class are complexes with CO, arene, and cyclopentadienyl ligands. The binary carbonyl Tc(CO) is a white volatile solid. In this molecule, two technetium atoms are bound to each other; each atom is surrounded by octahedra of five carbonyl ligands. The bond length between technetium atoms, 303 pm, is significantly larger than the distance between two atoms in metallic technetium (272 pm). Similar carbonyls are formed by technetium's congeners, manganese and rhenium. Interest in organotechnetium compounds has also been motivated by applications in nuclear medicine. Unusual for other metal carbonyls, Tc forms aquo-carbonyl complexes, prominent being [Tc(CO)(HO)].\n\nTechnetium, with atomic number (denoted \"Z\") 43, is the lowest-numbered element in the periodic table of which all isotopes are radioactive. The second-lightest exclusively radioactive element, promethium, has an atomic number of 61. Atomic nuclei with an odd number of protons are less stable than those with even numbers, even when the total number of nucleons (protons + neutrons) is even, and odd numbered elements have fewer stable isotopes.\n\nThe most stable radioactive isotopes are technetium-98 with a half-life of 4.2 million years (Ma), technetium-97 with 2.6 Ma, and technetium-99 with 211,000 years. Thirty other radioisotopes have been characterized with mass numbers ranging from 85 to 118. Most of these have half-lives that are less than an hour, the exceptions being technetium-93 (half-life: 2.73 hours), technetium-94 (half-life: 4.88 hours), technetium-95 (half-life: 20 hours), and technetium-96 (half-life: 4.3 days).\n\nThe primary decay mode for isotopes lighter than technetium-98 (Tc) is electron capture, producing molybdenum (\"Z\" = 42). For technetium-98 and heavier isotopes, the primary mode is beta emission (the emission of an electron or positron), producing ruthenium (\"Z\" = 44), with the exception that technetium-100 can decay both by beta emission and electron capture.\n\nTechnetium also has numerous nuclear isomers, which are isotopes with one or more excited nucleons. Technetium-97m (Tc; 'm' stands for metastability) is the most stable, with a half-life of 91 days (0.0965 MeV). This is followed by technetium-95m (half-life: 61 days, 0.03 MeV), and technetium-99m (half-life: 6.01 hours, 0.142 MeV). Technetium-99m emits only gamma rays and decays to technetium-99.\n\nTechnetium-99 (Tc) is a major product of the fission of uranium-235 (U), making it the most common and most readily available isotope of technetium. One gram of technetium-99 produces 6.2×10 disintegrations a second (that is, 0.62 GBq/g).\n\nTechnetium occurs naturally in the Earth's crust in minute concentrations of about 0.003 parts per trillion. This totals about 18000 tonnes at any given time, assuming the mass of the Earth's crust is 60000000000000000000006×10 kilograms. Technetium is so rare because technetium-98's half-life is only 4.2 million years. More than a thousand of such periods have passed since the formation of the Earth, so the probability for the survival of even one atom of primordial technetium is effectively zero. However, small amounts exist as spontaneous fission products in uranium ores. A kilogram of uranium contains an estimated 1 nanogram (10 g) of technetium. Some red giant stars with the spectral types S-, M-, and N contain a spectral absorption line indicating the presence of technetium. These red-giants are known informally as technetium stars.\n\nIn contrast to the rare natural occurrence, bulk quantities of technetium-99 are produced each year from spent nuclear fuel rods, which contain various fission products. The fission of a gram of uranium-235 in nuclear reactors yields 27 mg of technetium-99, giving technetium a fission product yield of 6.1%. Other fissile isotopes produce similar yields of technetium, such as 4.9% from uranium-233 and 6.21% from plutonium-239. An estimated 49,000 TBq (78 metric tons) of technetium was produced in nuclear reactors between 1983 and 1994, by far the dominant source of terrestrial technetium. Only a fraction of the production is used commercially.\n\nTechnetium-99 is produced by the nuclear fission of both uranium-235 and plutonium-239. It is therefore present in radioactive waste and in the nuclear fallout of fission bomb explosions. Its decay, measured in becquerels per amount of spent fuel, is the dominant contributor to nuclear waste radioactivity after about 10 to 10 years after the creation of the nuclear waste. From 1945 to 1994, an estimated 160 TBq (about 250 kg) of technetium-99 was released into the environment during atmospheric nuclear tests. The amount of technetium-99 from nuclear reactors released into the environment up to 1986 is on the order of 1000 TBq (about 1600 kg), primarily by nuclear fuel reprocessing; most of this was discharged into the sea. Reprocessing methods have reduced emissions since then, but as of 2005 the primary release of technetium-99 into the environment is by the Sellafield plant, which released an estimated 550 TBq (about 900 kg) from 1995–1999 into the Irish Sea. From 2000 onwards the amount has been limited by regulation to 90 TBq (about 140 kg) per year. Discharge of technetium into the sea resulted in contamination of some seafood with minuscule quantities of this element. For example, European lobster and fish from west Cumbria contain about 1 Bq/kg of technetium.\n\nThe metastable isotope technetium-99m is continuously produced as a fission product from the fission of uranium or plutonium in nuclear reactors:\n\nBecause used fuel is allowed to stand for several years before reprocessing, all molybdenum-99 and technetium-99m is decayed by the time that the fission products are separated from the major actinides in conventional nuclear reprocessing. The liquid left after plutonium–uranium extraction (PUREX) contains a high concentration of technetium as but almost all of this is technetium-99, not technetium-99m.\n\nThe vast majority of the technetium-99m used in medical work is produced by irradiating dedicated highly enriched uranium targets in a reactor, extracting molybdenum-99 from the targets in reprocessing facilities, and recovering at the diagnostic center the technetium-99m produced upon decay of molybdenum-99. Molybdenum-99 in the form of molybdate is adsorbed onto acid alumina () in a shielded column chromatograph inside a technetium-99m generator (\"technetium cow\", also occasionally called a \"molybdenum cow\"). Molybdenum-99 has a half-life of 67 hours, so short-lived technetium-99m (half-life: 6 hours), which results from its decay, is being constantly produced. The soluble pertechnetate can then be chemically extracted by elution using a saline solution. A drawback of this process is that it requires targets containing uranium-235, which are subject to the security precautions of fissile materials.\n\nAlmost two-thirds of the world's supply comes from two reactors; the National Research Universal Reactor at Chalk River Laboratories in Ontario, Canada, and the High Flux Reactor at Nuclear Research and Consultancy Group in Petten, Netherlands. All major reactors that produce technetium-99m were built in the 1960s and are close to the end of life. The two new Canadian Multipurpose Applied Physics Lattice Experiment reactors planned and built to produce 200% of the demand of technetium-99m relieved all other producers from building their own reactors. With the cancellation of the already tested reactors in 2008, the future supply of technetium-99m became problematic.\n\nThe Chalk River reactor was shut down for maintenance in August 2009, and reopened in August 2010. The Petten reactor had a 6-month scheduled maintenance shutdown on Friday, February 19, 2010, and reopened September 2010. With millions of procedures relying on technetium-99m every year, the low supply has left a gap, leaving some practitioners to revert to techniques not used for 20 years. Somewhat allaying this issue is an announcement from the Polish Maria research reactor that they have developed a technique to isolate technetium.\n\nThe long half-life of technetium-99 and its potential to form anionic species creates a major concern for long-term disposal of radioactive waste. Many of the processes designed to remove fission products in reprocessing plants aim at cationic species such as caesium (e.g., caesium-137) and strontium (e.g., strontium-90). Hence the pertechnetate escapes through those processes. Current disposal options favor burial in continental, geologically stable rock. The primary danger with such practice is the likelihood that the waste will contact water, which could leach radioactive contamination into the environment. The anionic pertechnetate and iodide tend not to adsorb into the surfaces of minerals, and are likely to be washed away. By comparison plutonium, uranium, and caesium tend to bind to soil particles. Technetium could be immobilized by some environments, such as microbial activity in lake bottom sediments, and the environmental chemistry of technetium is an area of active research.\n\nAn alternative disposal method, transmutation, has been demonstrated at CERN for technetium-99. In this process, the technetium (technetium-99 as a metal target) is bombarded with neutrons to form the short-lived technetium-100 (half-life = 16 seconds) which decays by beta decay to ruthenium-100. If recovery of usable ruthenium is a goal, an extremely pure technetium target is needed; if small traces of the minor actinides such as americium and curium are present in the target, they are likely to undergo fission and form more fission products which increase the radioactivity of the irradiated target. The formation of ruthenium-106 (half-life 374 days) from the 'fresh fission' is likely to increase the activity of the final ruthenium metal, which will then require a longer cooling time after irradiation before the ruthenium can be used.\n\nThe actual separation of technetium-99 from spent nuclear fuel is a long process. During fuel reprocessing, it comes out as a component of the highly radioactive waste liquid. After sitting for several years, the radioactivity reduces to a level where extraction of the long-lived isotopes, including technetium-99, becomes feasible. A series of chemical processes yields technetium-99 metal of high purity.\n\nMolybdenum-99, which decays to form technetium-99m, can be formed by the neutron activation of molybdenum-98. When needed, other technetium isotopes are not produced in significant quantities by fission, but are manufactured by neutron irradiation of parent isotopes (for example, technetium-97 can be made by neutron irradiation of ruthenium-96).\n\nThe feasibility of technetium-99m production with the 22-MeV-proton bombardment of a molybdenum-100 target in medical cyclotrons following the reaction Mo(p,2n)Tc was demonstrated in 1971. The recent shortages of medical technetium-99m reignited the interest in its production by proton bombardment of isotopically-enriched (>99.5%) molybdenum-100 targets. Other techniques are being investigated for obtaining molybdenum-99 from molybdenum-100 via (n,2n) or (γ,n) reactions in particle accelerators.\n\nTechnetium-99m (\"m\" indicates that this is a metastable nuclear isomer) is used in radioactive isotope medical tests. For example, Technetium-99m is a radioactive tracer that medical imaging equipment tracks in the human body. It is well suited to the role because it emits readily detectable 140 keV gamma rays, and its half-life is 6.01 hours (meaning that about 94% of it decays to technetium-99 in 24 hours). The chemistry of technetium allows it to be bound to a variety of biochemical compounds, each of which determines how it is metabolized and deposited in the body, and this single isotope can be used for a multitude of diagnostic tests. More than 50 common radiopharmaceuticals are based on technetium-99m for imaging and functional studies of the brain, heart muscle, thyroid, lungs, liver, gall bladder, kidneys, skeleton, blood, and tumors.\n\nThe longer-lived isotope, technetium-95m with a half-life of 61 days, is used as a radioactive tracer to study the movement of technetium in the environment and in plant and animal systems.\n\nTechnetium-99 decays almost entirely by beta decay, emitting beta particles with consistent low energies and no accompanying gamma rays. Moreover, its long half-life means that this emission decreases very slowly with time. It can also be extracted to a high chemical and isotopic purity from radioactive waste. For these reasons, it is a National Institute of Standards and Technology (NIST) standard beta emitter, and is used for equipment calibration. Technetium-99 has also been proposed for optoelectronic devices and nanoscale nuclear batteries.\n\nLike rhenium and palladium, technetium can serve as a catalyst. In processes such as the dehydrogenation of isopropyl alcohol, it is a far more effective catalyst than either rhenium or palladium. However, its radioactivity is a major problem in safe catalytic applications.\n\nWhen steel is immersed in water, adding a small concentration (55 ppm) of potassium pertechnetate(VII) to the water protects the steel from corrosion, even if the temperature is raised to . For this reason, pertechnetate has been used as an anodic corrosion inhibitor for steel, although technetium's radioactivity poses problems that limit this application to self-contained systems. While (for example) can also inhibit corrosion, it requires a concentration ten times as high. In one experiment, a specimen of carbon steel was kept in an aqueous solution of pertechnetate for 20 years and was still uncorroded. The mechanism by which pertechnetate prevents corrosion is not well understood, but seems to involve the reversible formation of a thin surface layer (passivation). One theory holds that the pertechnetate reacts with the steel surface to form a layer of technetium dioxide which prevents further corrosion; the same effect explains how iron powder can be used to remove pertechnetate from water. (Activated carbon can also be used for the same purpose.) The effect disappears rapidly if the concentration of pertechnetate falls below the minimum concentration or if too high a concentration of other ions is added.\n\nAs noted, the radioactive nature of technetium (3 MBq/L at the concentrations required) makes this corrosion protection impractical in almost all situations. Nevertheless, corrosion protection by pertechnetate ions was proposed (but never adopted) for use in boiling water reactors.\n\nTechnetium plays no natural biological role and is not normally found in the human body. Technetium is produced in quantity by nuclear fission, and spreads more readily than many radionuclides. It appears to have low chemical toxicity. For example, no significant change in blood formula, body and organ weights, and food consumption could be detected for rats which ingested up to 15 µg of technetium-99 per gram of food for several weeks. The radiological toxicity of technetium (per unit of mass) is a function of compound, type of radiation for the isotope in question, and the isotope's half-life.\n\nAll isotopes of technetium must be handled carefully. The most common isotope, technetium-99, is a weak beta emitter; such radiation is stopped by the walls of laboratory glassware. The primary hazard when working with technetium is inhalation of dust; such radioactive contamination in the lungs can pose a significant cancer risk. For most work, careful handling in a fume hood is sufficient, and a glove box is not needed.\n\n\n\n"}
{"id": "3763642", "url": "https://en.wikipedia.org/wiki?curid=3763642", "title": "Uranium diboride", "text": "Uranium diboride\n\nUranium boride (UB), a compound of uranium and boron, is a very stable glassy boride material that is insoluble in water.\n\nIt is being explored as a method of immobilising uranium-based radioactive waste, and rendering it safe for long term storage. Some applications in endocurietherapy, a method of radiation therapy where in radioactive microspheres are implanted directly into the treatment site and allowed to remain for an extended period of time, may also use this class of material as it would not be attacked while \"in situ\".\n\n"}
{"id": "40197", "url": "https://en.wikipedia.org/wiki?curid=40197", "title": "Vapor pressure", "text": "Vapor pressure\n\nVapor pressure (or vapour pressure in British spelling) or equilibrium vapor pressure is defined as the pressure exerted by a vapor in thermodynamic equilibrium with its condensed phases (solid or liquid) at a given temperature in a closed system. The equilibrium vapor pressure is an indication of a liquid's evaporation rate. It relates to the tendency of particles to escape from the liquid (or a solid). A substance with a high vapor pressure at normal temperatures is often referred to as \"volatile\". The pressure exhibited by vapor present above a liquid surface is known as vapor pressure. As the temperature of a liquid increases, the kinetic energy of its molecules also increases. As the kinetic energy of the molecules increases, the number of molecules transitioning into a vapor also increases, thereby increasing the vapor pressure.\n\nThe vapor pressure of any substance increases non-linearly with temperature according to the Clausius–Clapeyron relation. The atmospheric pressure boiling point of a liquid (also known as the normal boiling point) is the temperature at which the vapor pressure equals the ambient atmospheric pressure. With any incremental increase in that temperature, the vapor pressure becomes sufficient to overcome atmospheric pressure and lift the liquid to form vapor bubbles inside the bulk of the substance. Bubble formation deeper in the liquid requires a higher temperature due to the higher fluid pressure, because fluid pressure increases above the atmospheric pressure as the depth increases. More important at shallow depths is the higher temperature required to start bubble formation. The surface tension of the bubble wall leads to an overpressure in the very small, initial bubbles. Thus, thermometer calibration should not rely on the temperature in boiling water.\n\nThe vapor pressure that a single component in a mixture contributes to the total pressure in the system is called partial pressure. For example, air at sea level, and saturated with water vapor at 20 °C, has partial pressures of about 2.3 kPa of water, 78 kPa of nitrogen, 21 kPa of oxygen and 0.9 kPa of argon, totaling 102.2 kPa, making the basis for standard atmospheric pressure.\n\nVapor pressure is measured in the standard units of pressure. The International System of Units (SI) recognizes pressure as a derived unit with the dimension of force per area and designates the pascal (Pa) as its standard unit. One pascal is one newton per square meter (N·m or kg·m·s).\n\nExperimental measurement of vapor pressure is a simple procedure for common pressures between 1 and 200 kPa. Most accurate results are obtained near the boiling point of substances and large errors result for measurements smaller than . Procedures often consist of purifying the test substance, isolating it in a container, evacuating any foreign gas, then measuring the equilibrium pressure of the gaseous phase of the substance in the container at different temperatures. Better accuracy is achieved when care is taken to ensure that the entire substance and its vapor are at the prescribed temperature. This is often done, as with the use of an isoteniscope, by submerging the containment area in a liquid bath.\n\nVery low vapor pressures of solids can be measured using the Knudsen effusion cell method.\n\nIn a medical context, vapor pressure is sometimes expressed in other units, specifically millimeters of mercury (mmHg). This is important for volatile anesthetics, most of which are liquids at body temperature, but with a relatively high vapor pressure. Anesthetics with a higher vapor pressure at body temperature will be excreted more quickly, as they are exhaled from the lungs.\n\nThe Antoine equation is a mathematical expression of the relation between the vapor pressure and the temperature of pure liquid or solid substances. The basic form of the equation is:\n\nand it can be transformed into this temperature-explicit form:\n\nwhere: formula_3 is the absolute vapor pressure of a substance<br>\n\nA simpler form of the equation with only two coefficients is sometimes used:\n\nwhich can be transformed to:\n\nSublimations and vaporizations of the same substance have separate sets of Antoine coefficients, as do components in mixtures. Each parameter set for a specific compound is only applicable over a specified temperature range. Generally, temperature ranges are chosen to maintain the equation's accuracy of a few up to 8–10 percent. For many volatile substances, several different sets of parameters are available and used for different temperature ranges. The Antoine equation has poor accuracy with any single parameter set when used from a compound's melting point to its critical temperature. Accuracy is also usually poor when vapor pressure is under 10 Torr because of the limitations of the apparatus used to establish the Antoine parameter values.\n\nThe Wagner equation gives \"one of the best\" fits to experimental data but is quite complex. It expresses reduced vapor pressure as a function of reduced temperature.\n\nAs a general trend, vapor pressures of liquids at ambient temperatures increase with decreasing boiling points. This is illustrated in the vapor pressure chart (see right) that shows graphs of the vapor pressures versus temperatures for a variety of liquids. At the normal boiling point of a liquid, the vapor pressure is equal to the standard atmospheric pressure defined as 1 atmosphere (760 Torr or 101.325 kPa or 14.69595 PSI).\n\nFor example, at any given temperature, methyl chloride has the highest vapor pressure of any of the liquids in the chart. It also has the lowest normal boiling point (−24.2 °C), which is where the vapor pressure curve of methyl chloride (the blue line) intersects the horizontal pressure line of one atmosphere (atm) of absolute vapor pressure.\n\nAlthough the relation between vapor pressure and temperature is non-linear, the chart uses a logarithmic vertical axis to produce slightly curved lines, so one chart can graph many liquids. A nearly straight line is obtained when the logarithm of the vapor pressure is plotted against 1/(T+230) where T is the temperature in degrees Celsius. The vapor pressure of a liquid at its boiling point equals the pressure of its surrounding environment.\n\nRaoult's law gives an approximation to the vapor pressure of mixtures of liquids. It states that the activity (pressure or fugacity) of a single-phase mixture is equal to the mole-fraction-weighted sum of the components' vapor pressures:\n\nwhere formula_14 is the mixture's vapor pressure, formula_15 is the mole fraction of component formula_16 in the liquid phase and formula_17 is the mole fraction of component formula_16 in the vapor phase respectively. formula_19 is the vapor pressure of component formula_16. Raoult's law is applicable only to non-electrolytes (uncharged species); it is most appropriate for non-polar molecules with only weak intermolecular attractions (such as London forces).\n\nSystems that have vapor pressures higher than indicated by the above formula are said to have positive deviations. Such a deviation suggests weaker intermolecular attraction than in the pure components, so that the molecules can be thought of as being \"held in\" the liquid phase less strongly than in the pure liquid. An example is the azeotrope of approximately 95% ethanol and water. Because the azeotrope's vapor pressure is higher than predicted by Raoult's law, it boils at a temperature below that of either pure component.\n\nThere are also systems with negative deviations that have vapor pressures that are lower than expected. Such a deviation is evidence for stronger intermolecular attraction between the constituents of the mixture than exists in the pure components. Thus, the molecules are \"held in\" the liquid more strongly when a second molecule is present. An example is a mixture of trichloromethane (chloroform) and 2-propanone (acetone), which boils above the boiling point of either pure component.\n\nThe negative and positive deviations can be used to determine thermodynamic activity coefficients of the components of mixtures.\n\nEquilibrium vapor pressure can be defined as the pressure reached when a condensed phase is in equilibrium with its own vapor. In the case of an equilibrium solid, such as a crystal, this can be defined as the pressure when the rate of sublimation of a solid matches the rate of deposition of its vapor phase. For most solids this pressure is very low, but some notable exceptions are naphthalene, dry ice (the vapor pressure of dry ice is 5.73 MPa (831 psi, 56.5 atm) at 20 °C, which causes most sealed containers to rupture), and ice. All solid materials have a vapor pressure. However, due to their often extremely low values, measurement can be rather difficult. Typical techniques include the use of thermogravimetry and gas transpiration.\n\nThere are a number of methods for calculating the sublimation pressure (i.e., the vapor pressure) of a solid. One method is to estimate the sublimation pressure from extrapolated liquid vapor pressures (of the supercooled liquid), if the heat of fusion is known, by using this particular form of the Clausius–Clapeyron relation:\n\nwhere:\n\n\nThis method assumes that the heat of fusion is temperature-independent, ignores additional transition temperatures between different solid phases, and it gives a fair estimation for temperatures not too far from the melting point. It also shows that the sublimation pressure is lower than the extrapolated liquid vapor pressure (Δ\"H\" > 0) and the difference grows with increased distance from the melting point.\n\nLike all liquids, water boils when its vapor pressure reaches its surrounding pressure. In nature, the atmospheric pressure is lower at higher elevations and water boils at a lower temperature. The boiling temperature of water for atmospheric pressures can be approximated by the Antoine equation:\n\nor transformed into this temperature-explicit form:\n\nwhere the temperature formula_32 is the boiling point in degrees Celsius and the pressure formula_33 is in Torr.\n\nDühring's rule states that a linear relationship exists between the temperatures at which two solutions exert the same vapor pressure.\n\nThe following table is a list of a variety of substances ordered by increasing vapor pressure (in absolute units).\nSeveral empirical methods exist to estimate liquid vapor pressure from molecular structure for organic molecules. Some examples are SIMPOL.1 method, the method of Moller et al., and EVAPORATION (Estimation of VApour Pressure of ORganics, Accounting for Temperature, Intramolecular, and Non-additivity effects).\n\nIn meteorology, the term \"vapor pressure\" is used to mean the partial pressure of water vapor in the atmosphere, even if it is not in equilibrium, and the \"equilibrium vapor pressure\" is specified otherwise. Meteorologists also use the term \"saturation vapor pressure\" to refer to the equilibrium vapor pressure of water or brine above a flat surface, to distinguish it from equilibrium vapor pressure, which takes into account the shape and size of water droplets and particulates in the atmosphere.\n\n\n"}
{"id": "33659051", "url": "https://en.wikipedia.org/wiki?curid=33659051", "title": "Waterside hot water hay pellet furnace", "text": "Waterside hot water hay pellet furnace\n\nThe waterside hot water hay pellet furnace is technology that was developed to convert grass and hay into energy that can used in home heating, also known as grass pellet heating.\n\nThe waterside hot water hay pellet furnace was invented by Gus Swanson a farmer from Pictou County, Nova Scotia. Swanson came up with the idea after search for an affordable alternative to home heating to oil after the price of oil began to increase. Swanson and two of his partners, Philip Landry and Jim Trussler, founded the company LST Energy Inc. as a way to grow and build their hay pellet furnace technology.\n\nThe waterside hot water hay pellet furnace converts hay pellets into energy by burning them in a furnace, wood stove, or pellet stove. The hay pellets are made from dried field hay (grass) that is harvested at the end of season and then pressed into pellets.\n\nSwanson developed a furnace with a local Pictou furnace maker, a Cape Breton company that makes pellet machines, and scientists at the Nova Scotia Agricultural College. While developing the furnace Swanson and his team had problems related to the building up of glass that was produced when the hay was burning in the furnace. This is because hay contains sand and potassium chloride, sometimes referred to as clinkers, and its ashes are heavy. Therefore, when the hay is burning in the furnace the sand turns into glass that can be up to an inch thick and this was causing problems because the glass would build up enough that it was putting the fire out(which was the energy created by the burning of the hay). Thus, Swanson and his team had to find a way to break the newly formed glass back into sand. It took 10 different prototype burning pots before one was created that had an ash breaker that would work.\n\nThe temperature in the water chamber of the furnace can reach the boiling point within seven minutes and at that rate the furnace can burn off the majority of the ash and leave little waste.\nOnce development was complete on the furnace the final working prototype of the Waterside Hay Hot Water Pellet Furnace was 45 inches tall and around a foot in diameter. It can burn 50 – 125 pounds of pellets a day and releases 30,000 – 190,000 BTU's (British thermal units) an hour.\n\nIt is estimated that it will take 8,100 square metres of grass to heat an average Canadian home per year.\n\nSwanson and his company have received grants to help assist in the patent and safety certificate testing from Agri-Futures Nova Scotia, which is the provincial distributor of funds through Agriculture and Agri-Food Canada’s Advancing Canadian Agriculture and Agri-Food (ACAAF) Program.\n\nLST Energy Inc. received a $100,000 prize offered by Innovacorporation for winning first place in a regional technology start-up competition in 2010.\n\nThe Nova Scotia Agricultural College has been helping LST energy Inc. on the development of the hay pellet furnace. In 2009, when LST Energy advanced to the final round of the regional technology start-up competition they had one of their completed prototypes installed and up and running at the Agricultural College.\n\nA Musquodoboit, Nova Scotia company has been recruited to produce the hay pellets suitable for use in the furnace.\n\nHay, which comes from grass, is an economically viable, renewable and sustainable resource. Two acres of hay will heat an average home for the winter and it would only take 4% of Canadian land to produce enough hay to heat every Canadian home. \nThe hay pellets used in the furnace are also an environmental friendly energy source. It is considered a carbon neutral energy source. The hay pellets burning efficiency is increased by its low moisture content and it burns without producing any smoke and as clean or cleaner than any fossil fuel. Wood stoves release 45g of particulate/hour, while hay pellets only product 1.2g/hour.\n\nResearch has been conducted to discover what type of grass is best suited for use in the Waterside Hot Water Hay Pellet Furnace and it was found the reed canary hay pellets, produced from reed canary grass is the most efficient grass pellet source. It emitted 90% less Carbon Dioxide (CO2) than heating oil, propane or natural gas. Eighteen thousand tonnes of CO2 can be saved from being emitted into the atmosphere for every 50 acres of reed canary grass burnt as hay pellets in the Waterside Hot Water Hay Pellet Furnace.\n\nIt’s a potential new source of income for the struggling agricultural industry. This new furnace also has the potential to strengthen the agricultural community in Canada because farmers may soon be able to sell their hay for pellet production. Farmers currently make $30/ton of hay, however it is predicted that if demand for hay increases because it is needed for pellet production that the farmers could potentially make up to $100/ton, with the consumer being charge $200/ton of pellets. Presently, one tonne of hay is equivalent to around $700 worth of heating oil. It is predicted that a farm in Nova Scotia with 100 acres of hay could make up to $50,000 a year selling their hay for production of pellets that will be used in the furnace. An increase in demand for pellets made out of hay could also potentially increase jobs available in rural farming areas across Canada.\n\nHeating a home with hay pellets is a much cheaper alternative to that of oil. Swanson currently heats a three-bedroom apartment, a two-bedroom apartment, and a two-bedroom house using hay pellets and it cost him only $300/month, compared to the $900/month it used to cost him when he was heating these properties with oil.\n"}
{"id": "20611262", "url": "https://en.wikipedia.org/wiki?curid=20611262", "title": "World Ocean", "text": "World Ocean\n\nThe World Ocean or Global Ocean (colloquially the sea or the ocean) is the interconnected system of Earth's oceanic waters, and comprises the bulk of the hydrosphere, covering (70.8%) of Earth's surface, with a total volume of roughly .\n\nThe unity and continuity of the World Ocean, with relatively free interchange among its parts, is of fundamental importance to oceanography. It is divided into a number of principal oceanic areas that are delimited by the continents and various oceanographic features: these divisions are the Atlantic Ocean, Arctic Ocean (sometimes considered a sea of the Atlantic), Indian Ocean, Pacific Ocean, and Southern Ocean, defined by the International Hydrographic Organization (IHO) in 2000, based on evidence that this region of the World Ocean has a distinct ecosystem and a unique impact on global climate. In turn, oceanic waters are interspersed by many smaller seas, gulfs, and bays.\n\nA global ocean has existed in one form or another on Earth for eons, and the notion dates back to classical antiquity in the form of Oceanus. The contemporary concept of the \"World Ocean\" was coined in the early 20th century by the Russian oceanographer Yuly Shokalsky to refer to the continuous ocean that covers and encircles most of Earth.\n\nIf viewed from the southern pole of Earth, the Atlantic, Indian, and Pacific Oceans can be seen as lobes extending northward from the Southern Ocean. Farther north, the Atlantic opens into the Arctic Ocean, which is connected to the Pacific by the Bering Strait, forming a continuous expanse of water.\n\n\nPlate tectonics, post-glacial rebound, and sea level rise continually change the coastline and structure of the world ocean.\n\n\n\n"}
