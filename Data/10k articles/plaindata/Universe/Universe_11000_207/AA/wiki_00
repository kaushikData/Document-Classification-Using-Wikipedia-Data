{"id": "23372495", "url": "https://en.wikipedia.org/wiki?curid=23372495", "title": "ARMZ Uranium Holding", "text": "ARMZ Uranium Holding\n\nARMZ Uranium Holding Co. (AtomRedMetZoloto, a contraction of a Russian phrase meaning \"Atom Rare Metals Gold\") is a Russian uranium mining company. It is wholly owned by Atomenergoprom, a part of Rosatom.\n\nAtomRedMetZoloto was founded in 1992. In 2008, all uranium mines in Russia as well as uranium mining related assets in other countries owned by Rosatom subsidiaries were brought under ARMZ Uranium Holding Co.\n\nARMZ Uranium Holding Co. mines uranium in Russia and Kazakhstan. New operations involve Armenia, Namibia and Canada. In June 2009, ARMZ Uranium Holding Co. acquired 16.6% of shares in the Canadian uranium mining company Uranium One in exchange for a 50% interest in the Karatau, Kazakhstan uranium mining project, a joint venture with Kazatomprom. In December 2013 an internal reorganization of Rosatom extinguished the interest of ARMZ, making Uranium One a direct subsidiary of Rosatom.\n\nIn December 2010, ARMZ agreed to buy Australian-based Mantra Resources for US$1.15 billion, including its stake in a Tanzanian mine.\n\n\n"}
{"id": "37250120", "url": "https://en.wikipedia.org/wiki?curid=37250120", "title": "Ambewela Aitken Spence Wind Farm", "text": "Ambewela Aitken Spence Wind Farm\n\nThe Ambewela Aitken Spence Wind Farm is small wind farm in Ambewela, owned and operated by Ace Wind Power, a subsidiary of Aitken Spence. As of October 2012, it is one of the only few operating multi-megawatt wind farms in Sri Lanka. The wind farm consists of of each, totalling the plant installed capacity to .\n\n"}
{"id": "623884", "url": "https://en.wikipedia.org/wiki?curid=623884", "title": "Austronesia", "text": "Austronesia\n\nAustronesia, in historical terms, refers to the homeland of the peoples who speak Austronesian languages, including Malay (Malaysian-Indonesian), Filipino, the Visayan languages, Ilocano, Javanese, Malagasy, the Polynesian languages, Fijian, Taiwan's Formosan languages, Tetum and around ten-thousand other languages.\n\nThe Austronesian homeland is thought by linguists to have been prehistoric Taiwan.\n\nThe Austronesian language has been considered a coherent field of study for some decades.\n\nAustronesian linguistics has attracted considerable interest.\n\nThe Austronesian linguistics and cultural world incorporates specific contexts of hierarchy which are included in linguistic form.\n\nConsiderable discussion has occurred on the language in Indonesia.\n\nArchaeological linkages of the Austronesian world have been explored as well.\n\nThe name Austronesia comes from the Latin \"austrālis\" \"southern\" plus the Greek \"νήσος\" (\"nêsos\") \"island\".\n\nHowever, in contemporary terminology, the word Austronesia pertains to the regions where Austronesian languages are spoken. Austronesia then covers almost half of the globe, mostly ocean and oceanic islands, starting from Madagascar to the west until Easter Island, to the east.\n\nAustronesia as a region has three traditional divisions: Taiwan (Formosa), the Maritime Southeast Asia, and Austronesian Oceania (Micronesia, Melanesia and Polynesia).\n\nMaritime Southeast Asia covers the modern nations of:\n\n\nAnd as well: The Pattani region of Thailand, and the Chamic areas of Vietnam, Cambodia and Hainan Island.\n\nIslands in the vicinity, with native populations having Malay or mixed Malay ancestry, which are not considered part of the Malay Archipelago include New Guinea and the Marianas Islands.\n\nEastern Sri Lanka, well as parts of the Andaman Islands inhabited by the Orang Laut.\n\nThe term \"Micronesia\" was coined in 1832 by Jules Dumont d'Urville from the Greek roots μικρός \"mikros\" 'small' and νῆσοι \"nēsoi\" 'islands', thus meaning 'small islands'.\n\nPolitically, Micronesia is divided among eight territories:\n\nThe term Melanesia was coined in 1832 by Jules Dumont d'Urville from the Greek meaning 'black islands', in reference to the dark skin of the Melanesians.\n\nThe following islands and groups of islands are traditionally considered part of Melanesia:\n\nOther islands with populations of mixed Melanesian ancestry but are not part of the traditional Melanesian area include:\n\nThe term Polynesia was coined in 1756 by Charles de Brosses from the Greek meaning \"many islands\", describing the multiplicity of the islands in this area of the Pacific.\n\nCountries and territories traditionally included in Polynesia include:\n\nIn addition to these islands in this mid-Pacific Ocean, Polynesia often is meant to include the Polynesian outliers: islands that are culturally or linguistically Polynesian, but that are geographically in Melanesia or Micronesia. Most of these are small or isolated islands, like Rennell or Tikopia in the Solomon Islands.\n\n\n"}
{"id": "24704243", "url": "https://en.wikipedia.org/wiki?curid=24704243", "title": "Biùtiful cauntri", "text": "Biùtiful cauntri\n\nBiùtiful cauntri is a 2007 Italian documentary film about illegal toxic waste dumping in Southern Italy. It was directed by Esmeralda Calabria and Andrea D'Ambrosio and written by Calabria, D'Ambrosio and Peppe Ruggiero. It focuses on the progressive poisoning of thousands of square miles of Southern Italian agricultural land and the deadly effects upon people, animals, and plant life in the areas of Caserta and Naples, and behind that the interwoven relations between the Italian government, corrupt pseudo-legitimate businessmen, and the Italian organized crime group, the Camorra. The title is literally the Italian pronunciation of \"beautiful country\". A secondary focus of the film is governmental inaction, in some cases lasting over a decade and a half, despite the pleas of the people affected.\n\nIt was premiered in November 2007 at the Torino Film Festival, where it received a special mention. It was then released in ten Italian movie theaters in March 2008. On 15 July 2008 the film was released in France, where it received a positive review from Le Monde. The film was released on DVD along with a 90-page book published under the Senza Filtro imprint of Biblioteca Universale Rizzoli.\n\n\n\n - pressbook [in English] - pressbook [in Italian]\n"}
{"id": "1828406", "url": "https://en.wikipedia.org/wiki?curid=1828406", "title": "Blaster (Star Wars)", "text": "Blaster (Star Wars)\n\nA blaster is a fictional gun that appears in the \"Star Wars\" universe. Lucasfilm defines the blaster as \"ranged energized particle weaponry\". Many blasters mirror the appearance, functions, components, operation, and usage of real life firearms. They are also said to be able to be modified with certain add-ons and attachments, with Han Solo's blaster being said to be illegally modified to provide greater damage without increasing power consumption.\n\nThe design of the traditional stormtrooper blaster is based on the real-life Sterling sub-machine gun used by the armed forces of the United Kingdom over the second half of the 20th century, with changes made by the filmmakers such as alterations to the magazine.\n\nIn the films, the design of the blaster rifle was based on the Sterling submachine gun. The design of the blaster pistol owned by the fictional character Han Solo was based on the 7.63-caliber Mauser C96, an early and successful automatic pistol that was used in World War I and World War II. Lucasfilm's prop department added a scope and an emitter nozzle to the pistol. The blaster made for the 1977 film \"\" was lost, and a second blaster was made with resin from the cast used for the first one. The blaster was subsequently used as a prop in \"The Empire Strikes Back\" and \"Return of the Jedi\".\n\nFunctional Sterlings firing blank cartridges were used in some scenes with the laser bolt added later in post-production. These blank cartridges are responsible for the muzzle flash seen on screen and, in some scenes, the cartridges themselves can be seen being ejected from the guns, or the actual sound of the blank cartridge is not dubbed over by a sound effect.\n\nBen Burtt, a sound designer who worked on the \"Star Wars\" films, came up with the sound of blaster fire during a family backpacking trip in the Pocono Mountains in 1976. Burtt hit the guy-wire of an AM radio transmitter tower with a hammer and recorded the sound with a microphone close to the impact.\n\nIn a chapter of the book \"Myth, Media, and Culture in Star Wars\", Michael Kaminski, writing about the influence of Japanese director Akira Kurosawa on the \"Star Wars\" films, said that Kurosawa's \"Ran\" influenced the exchange of blaster fire. Like in \"Ran\", color-coding and an \"onscreen sense of direction\" of blaster fire are used to depict opposing forces. In the \"Star Wars\" original trilogy, rebels employed red blaster fire and often attacked from the left, while the Empire employed green blaster fire and attacked from the right. In \"\", the second film of the prequel trilogy, the color and the direction were reversed. In that film, the Republic employed green and blue blaster fire and attacked from the right, while the Separatists employed red blaster fire and attacked from the left.\n\nThe inner workings of blasters essentially create particle beams to inflict damage. When the trigger is pulled, the blaster chambers a small volume of the fictional Tibanna gas into a \"gas conversion enabler\" (or XCiter). The XCiter excites the gas particles with energy from a power-pack, which attaches to the weapon much like a magazine does to real world weapons. Afterwards, the excited gas is compressed into a beam in the actuating blaster module before being focused by first a prismatic crystal and then the galven circuitry in the barrel of the weapon.\n\nOne prop of Han Solo's blaster was expected to sell at auction for US $200,000-300,000, and another for $500,000.\n\n\n"}
{"id": "41684377", "url": "https://en.wikipedia.org/wiki?curid=41684377", "title": "Brian Norton (engineer)", "text": "Brian Norton (engineer)\n\nBrian Norton (born 1955) is a college president and solar energy technologist. President of Dublin Institute of Technology (DIT), he has been an advocate for diversity of higher education in Ireland. He has also been associated with the relocation of DIT from a multiplicity of scattered buildings to a single city centre campus in the Grangegorman neighbourhood of Dublin and the creation of the Technological University Dublin.\n\nIn 1989 Norton was appointed by Sir Derek Birley as the first Professor in the field of the Built Environment at the University of Ulster, prior to which he taught at Cranfield University. He is a member of the Royal Irish Academy and Fellow of the Irish Academy of Engineering. Norton studied Physics at the University of Nottingham and Engineering at Cranfield University and holds Doctorates from both universities.\n\n"}
{"id": "14060661", "url": "https://en.wikipedia.org/wiki?curid=14060661", "title": "Capillary surface", "text": "Capillary surface\n\nIn fluid mechanics and mathematics, a capillary surface is a surface that represents the interface between two different fluids. As a consequence of being a surface, a capillary surface has no thickness in slight contrast with most real fluid interfaces.\n\nCapillary surfaces are of interest in mathematics because the problems involved are very nonlinear and have interesting properties, such as discontinuous dependence on boundary data at isolated points. In particular, static capillary surfaces with gravity absent have constant mean curvature, so that a minimal surface is a special case of static capillary surface.\n\nThey are also of practical interest for fluid management in space (or other environments free of body forces), where both flow and static configuration are often dominated by capillary effects.\n\nThe defining equation for a capillary surface is called the stress balance equation, which can be derived by considering the forces and stresses acting on a small volume that is partly bounded by a capillary surface. For a fluid meeting another fluid (the \"other\" fluid notated with bars) at a surface formula_1, the equation reads\n\nwhere formula_3 is the unit normal pointing toward the \"other\" fluid (the one whose quantities are notated with bars), formula_4 is the stress tensor (note that on the left is a tensor-vector product), formula_5 is the surface tension associated with the interface, and formula_6 is the surface gradient. Note that the quantity formula_7 is twice the mean curvature of the surface.\n\nIn fluid mechanics, this equation serves as a boundary condition for interfacial flows, typically complementing the Navier–Stokes equations. It describes the discontinuity in stress that is balanced by forces at the surface. As a boundary condition, it is somewhat unusual in that it introduces a new variable: the surface formula_1 that defines the interface. It's not too surprising then that the stress balance equation normally mandates its own boundary conditions.\n\nFor best use, this vector equation is normally turned into 3 scalar equations via dot product with the unit normal and two selected unit tangents:\n\nNote that the products lacking dots are tensor products of tensors with vectors (resulting in vectors similar to a matrix-vector product), those with dots are dot products. The first equation is called the normal stress equation, or the normal stress boundary condition. The second two equations are called tangential stress equations.\n\nThe stress tensor is related to velocity and pressure. Its actual form will depend on the specific fluid being dealt with, for the common case of incompressible Newtonian flow the stress tensor is given by\n\nwhere formula_13 is the pressure in the fluid, formula_14 is the velocity, and formula_15 is the viscosity.\n\nIn the absence of motion, the stress tensors yield only hydrostatic pressure so that formula_16, regardless of fluid type or compressibility. Considering the normal and tangential equations,\n\nThe first equation establishes that curvature forces are balanced by pressure forces. The second equation implies that a static interface cannot exist in the presence of nonzero surface tension gradient.\n\nIf gravity is the only body force present, the Navier–Stokes equations simplify significantly:\n\nIf coordinates are chosen so that gravity is nonzero only in the formula_20 direction, this equation degrades to a particularly simple form:\n\nwhere formula_22 is an integration constant that represents some reference pressure at formula_23. Substituting this into the normal stress equation yields what is known as the Young-Laplace equation:\n\nwhere formula_25 is the (constant) pressure difference across the interface, and formula_26 is the difference in density. Note that, since this equation defines a surface, formula_20 is the formula_20 coordinate of the capillary surface. This nonlinear partial differential equation when supplied with the right boundary conditions will define the static interface.\n\nThe pressure difference above is a constant, but its value will change if the formula_20 coordinate is shifted. The linear solution to pressure implies that, unless the gravity term is absent, it is always possible to define the formula_20 coordinate so that formula_31. Nondimensionalized, the Young-Laplace equation is usually studied in the form \n\nwhere (if gravity is in the negative formula_20 direction) formula_34 is positive if the denser fluid is \"inside\" the interface, negative if it is \"outside\", and zero if there is no gravity or if there is no difference in density between the fluids.\n\nThis nonlinear equation has some rich properties, especially in terms of existence of unique solutions. For example, the nonexistence of solution to some boundary value problem implies that, physically, the problem can't be static. If a solution does exist, normally it'll exist for very specific values of formula_35, which is representative of the pressure jump across the interface. This is interesting because there isn't another physical equation to determine the pressure difference. In a capillary tube, for example, implementing the contact angle boundary condition will yield a unique solution for exactly one value of formula_35. Solutions often aren't unique, this implies that there are multiple static interfaces possible; while they may all solve the same boundary value problem, the minimization of energy will normally favor one. Different solutions are called \"configurations\" of the interface.\n\nA deep property of capillary surfaces is the surface energy that is imparted by surface tension:\n\nwhere formula_38 is the area of the surface being considered, and the total energy is the summation of all energies. Note that \"every\" interface imparts energy. For example, if there are two different fluids (say liquid and gas) inside a solid container with gravity and other energy potentials absent, the energy of the system is\n\nwhere the subscripts formula_40, formula_41, and formula_42 respectively indicate the liquid–gas, solid–gas, and solid–liquid interfaces. Note that inclusion of gravity would require consideration of the volume enclosed by the capillary surface and the solid walls.\n\nTypically the surface tension values between the solid–gas and solid–liquid interfaces are not known. This does not pose a problem; since only changes in energy are of primary interest. If the net solid area formula_43 is a constant, and the contact angle is known, it may be shown that (again, for two different fluids in a solid container)\n\nso that\n\nwhere formula_46 is the contact angle and the capital delta indicates the change from one configuration to another. To obtain this result, it's necessary to sum (distributed) forces at the contact line (where solid, gas, and liquid meet) in a direction tangent to the solid interface and perpendicular to the contact line:\n\nwhere the sum is zero because of the static state. When solutions to the Young-Laplace equation aren't unique, the most physically favorable solution is the one of minimum energy, though experiments (especially low gravity) show that metastable surfaces can be surprisingly persistent, and that the most stable configuration can become metastable through mechanical jarring without too much difficulty. On the other hand, a metastable surface can sometimes spontaneously achieve lower energy without any input (seemingly at least) given enough time.\n\nBoundary conditions for stress balance describe the capillary surface at the contact line: the line where a solid meets the capillary interface; also, volume constraints can serve as boundary conditions (a suspended drop, for example, has no contact line but clearly must admit a unique solution).\n\nFor static surfaces, the most common contact line boundary condition is the implementation of the contact angle, which specifies the angle that one of the fluids meets the solid wall. The contact angle condition on the surface formula_1 is normally written as:\n\nwhere formula_46 is the contact angle. This condition is imposed on the boundary (or boundaries) formula_51 of the surface. formula_52 is the unit outward normal to the solid surface, and formula_53 is a unit normal to formula_1. Choice of formula_53 depends on which fluid the contact angle is specified for.\n\nFor dynamic interfaces, the boundary condition showed above works well if the contact line velocity is low. If the velocity is high, the contact angle will change (\"dynamic contact angle\"), and as of 2007 the mechanics of the moving contact line (or even the validity of the contact angle as a parameter) is not known and an area of active research.\n\n"}
{"id": "49555811", "url": "https://en.wikipedia.org/wiki?curid=49555811", "title": "Clean Energy Ministerial", "text": "Clean Energy Ministerial\n\nThe Clean Energy Ministerial (CEM) are global forums held to promote policies and to share best practices with the aim of accelerating a transition to clean energy. The forums have included partnerships and collaboration between the private sector, public sector. non-governmental organizations, and others. The forum typically incorporated two interrelated features: 1) an annual high-level policy dialogue with energy ministers and other top global stakeholders; and 2) year-round policy-targeted technical initiatives and high-visibility campaigns. The CEM is currently the only regular meeting of energy ministers focused exclusively on clean energy.\n\nPresident Obama announced in a video message at the sixth Clean Energy Ministerial (CEM6) in Mérida, Mexico that the United States would host the seventh Clean Energy Ministerial (CEM7) in 2016. At COP21 in Paris in December, U.S. Department of Energy Secretary Ernest Moniz and California Governor Edmund G. Brown Jr. announced CEM7 would be hosted in San Francisco, California. CEM7 is a high-level meeting of energy ministers coming together to discuss and implement actions of respective climate and clean energy goals put forward at COP21. CEM7 includes a public-private action day with opportunities for governments, companies, and other key stakeholders to highlight ambitious clean energy efforts and announce new actions to help achieve national and global clean energy and climate goals.\n\nThrough the CEM, 23 countries and the European Commission collaborate on efforts to improve energy efficiency, enhance clean energy supply, and expand clean energy access. Members of the CEM as of 2016 are Australia, Brazil, Canada, China, Denmark, European Commission, Finland, France, Germany, India, Indonesia, Italy, Japan, Korea, Mexico, Norway, Russia, Saudi Arabia, South Africa, Spain, Sweden, United Arab Emirates, United Kingdom, United States.\n\nAt the United Nations Framework Convention on Climate Change conference in Copenhagen in December 2009, U.S. Secretary of Energy Steven Chu announced that he would host the first Clean Energy Ministerial to bring together ministers with responsibility for clean energy technologies from the world’s major economies and ministers from a select number of smaller countries that are leading in various areas of clean energy.\n\nMembers of the Clean Energy Ministerial (as of 2016) represent about 90% of global clean energy investment and 75% of the world’s greenhouse gas emissions. Developing countries hold 50% of capacity for building out clean energy, but more than 70% of growth in clean energy investment since 2000 has been in OECD countries. Global investment in clean energy reached $260 billion in 2011; however, the International Energy Agency (IEA) estimated that $5 trillion is needed by 2020 to avoid a dangerous rise in greenhouse gases. The CEM’s low-cost, high-impact year-round initiatives deliver tangible results and enable proven policies, programs, and technologies to realize broader, faster, and lower-cost diffusion and replication among CEM and non-CEM countries. The CEM initiatives are focused on improving energy efficiency worldwide, enhancing clean energy supply, and expanding clean energy access. While CEM initiatives are led by CEM members, participation in initiatives is open to any country.\n\nAs of 2016, the CEM has 10 active initiatives, described below:\nPast initiatives include the Combined Heat and Power (CHP) and Efficient District Heating and Cooling (DHC) Working Group, the Cool Roofs and Pavements Working Group, the Sectoral Working Group, the Bioenergy Working Group, Carbon Capture Use and Storage, and Sustainable Development of Hydropower.[1]\n\nChina hosted the eighth Clean Energy Ministerial (CEM8) in Beijing on 6–8 June 2017. The annual meeting of energy ministers and other high-level delegates from the 24 member countries and the European Union provided an opportunity to leverage high-level political will and private sector leadership to drive ambitious, real-world clean energy policies and actions.\n\nDelegates participated in a series of roundtable discussions which identified barriers and proposed solutions for a range of action areas. They included:\n\n\nThe CEM8 Summary Report identifies the group's findings and recommendations in each of the above areas.\n\nThe United States hosted the CEM7 in San Francisco, California, on June 1–2, 2016, under the leadership of then-U.S. Secretary of Energy Ernest Moniz and California Governor Edmund G. Brown Jr.\n\nThe announcement at the COP was followed by a discussion among other CEM ministers on the role of the CEM post COP21 as a key implementation forum to help countries deliver on their respective national clean energy goals and build capacity to increase ambition even further over time. That discussion included Ali Ibrahim Al-Naimi, Saudi Arabia’s Minister of Petroleum and Mineral Resources, Ibrahim Baylan, Sweden’s Minister of Energy, Amber Rudd, United Kingdom’s Secretary of State for the Department of Energy and Climate Change, and Lars Christian Lilleholt, Denmark’s Minister of Energy, Utilities and Climate.\n\nThe combination of the city and state’s role in advancing clean energy policies along with the concentration of clean technology companies, research and development, and the business community in the region were key deciding factors. San Francisco and the broader Bay Area, which encompasses Silicon Valley, is known as a global hub of the clean energy industry and is home to some of the most innovative technology companies that are playing a crucial role in advancing clean energy globally. California recently signed into law climate and clean energy legislation that sets aggressive targets for the share of the state’s electricity from renewable sources and for energy efficiency savings in buildings.\n\n\"I can think of no better place than California to play host to the world's clean energy leaders,\" said Governor Jerry Brown.\n\nCEM7 is expected to include global energy leaders such as China’s Minister of Science and Technology Wan Gang, European Commissioner for Climate and Energy Miguel Arias Cañete, and India’s Minister of Power, Coal & New & Renewable Energy Piyush Goyal. Leaders from the business and investment community working in clean energy are also expected to participate as well as leaders from international energy organizations, foundations, research institutes, and academia.\n\nThe first Clean Energy Ministerial (CEM1) was hosted by the United States in 2010. The United Arab Emirates hosted the second Clean Energy Ministerial (CEM2) in 2011. The United Kingdom hosted the third Clean Energy Ministerial (CEM3) in 2012. India hosted the fourth Clean Energy Ministerial (CEM4) in 2013. South Korea hosted the fifth Clean Energy Ministerial (CEM5) in 2014. Mexico hosted the sixth Clean Energy Ministerial (CEM6) in 2015.\n\nThe 9th Clean Energy Ministerial (CEM9) and the 3rd Mission Innovation Ministerial (MI-3) was co-hosted by the European Commission together with Denmark, Sweden, Norway, Finland and the Nordic Council of Ministers and take place back-to-back in the cities of Copenhagen and Malmö respectively, on May 22–24, 2018. The overall theme is \"Energy Integration and Transition: towards a competitive and innovative low carbon economy.\"\n\nIn addition to a number of official side events in connection with the two ministerial meetings, activities took place concurrently in and around Copenhagen and Malmö under the umbrella “Nordic Clean Energy Week”, on May 21 – 24, 2018. The Nordic Clean Energy Week is co-hosted by Sweden and Denmark. During this week, politicians, researchers, business and industry gathered to discuss future energy solutions.\n\nVancouver, Canada will host CEM10, the 10th Clean Energy Ministerial and MI-4, the 4the Mission Innovation Ministerial, in May 2019.\n"}
{"id": "9813734", "url": "https://en.wikipedia.org/wiki?curid=9813734", "title": "Coliban Water", "text": "Coliban Water\n\nColiban Water is a regional water corporation in Victoria, Australia, established on 1 July 1992. \n\nThe service area includes 55 towns, of which the Greater City of Bendigo is the largest and also location of the head office.\n\nThe region serviced by Coliban Water extends from Cohuna and Echuca in the north to Kyneton and Trentham in the south. The western boundary incorporates Boort, Wedderburn, Bealiba and Dunolly, with Heathcote and Tooborac to the east.\n\nColiban Water manages, maintains and operates more than 50 reservoirs and water storage basins across North-Central Victoria.\n\nEdward Nucella Emmett worked to establish a reliable water supply for Bendigo, he was the main promoter of Bendigo Waterworks Company, a precursor of Coliban Water. Given the financial problems of the Victorian colonial government and the lack of local government funds he worked to privately fund a new water supply. The Sandhurst Municipal Council controlled a 22-acre ‘Water Reserve’ site along the Bendigo Creek at Golden Square. With funding from wealthy investors in Melbourne he formed the company that was incorporated through parliament. Joseph Brady was the first engineer for the project.\n\n"}
{"id": "21987025", "url": "https://en.wikipedia.org/wiki?curid=21987025", "title": "Compact wind acceleration turbine", "text": "Compact wind acceleration turbine\n\nCompact Wind Acceleration Turbines (CWATs) are a class of wind turbine that uses structures to accelerate wind before it enters the wind-generating element.\nThe concept of these structures has been around for decades but has not gained wide acceptance in the marketplace. In 2008, two companies targeting the mid-wind (100 kW-1 MW) marketplace have received funding from venture capital. The first company to receive funding is Optiwind, which received its series A funding in April 2008, and the second company is Ogin, Inc. (formerly FloDesign Wind Turbine Inc.), which also received its series A funding in April 2008. Optiwind is funded through Charles River Ventures and FloDesign is funded through Kleiner Perkins. Other CWATs under development include the WindTamer from AristaPower, WindCube, Innowind (conceptual offshore application) and Enflo turbines.\n\nCWATs are a new acronym that encompasses the class of machines formerly known as DAWTs (diffuser augmented wind turbines). The technologies mentioned above all use diffuser augmentation that is substantially similar to previous designs as the primary means of acceleration. \nDAWTs were heavily researched by K. Foreman and Oman of Grumman Aerospace in the 1970s and 1980s and Igra in Israel in the 1970s. At the end of a decade of wind tunnel research and design funded by Grumman, NASA, and the DOE, it was determined that the DAWT system's economics were not sufficient to justify commercialization. In the 1990s the Grumman technology was licensed to a New Zealand company, Vortec Wind. The attempt to commercialize the Vortec 7 in New Zealand from 1998 to 2002 proved it to be economically untenable when compared to the dominant HAWT (horizontal axis wind turbine) technology.\n\nUltimately, any wind turbine design must be measured against economic realities. It must positively answer the question, \"is the cost to install and operate the system lower than the cost of other alternatives, including the local electric grid?\" Historically, CWAT/DAWT designs have failed to overcome this hurdle as compared to more conventional HAWT designs. However, there is reason to believe that this equation may be shifting towards these new designs. The two primary drivers of this equation have been the amount of augmentation and the structural implications of these additional design elements.\n\nThe first factor regards power increase and the method of comparison used by DAWT (and more recently CWAT) designers to determine whether the system is worth developing. Grumman and other attempts to commercialize these machines compare their machines to HAWTs based on a rotor area to rotor area comparison. As Van Bussel of Delft (The Science of Making More Torque from Wind: Diffuser Experiments and Theory Revisited, G.J.W. van Bussel, Delft, 2007) pointed out, this is an inaccurate comparison and the comparison of power multiples should be made on the basis of the exit area of the diffuser or shroud not the rotor area. Grumman claimed a 4× increase over an unshrouded turbine based on an acceleration of 1.6 times the ambient wind velocity (An Investigation on Diffuser Augmented Turbines, D.G. Philips, 2003 (reference materials compiled from K.M. Foreman)). A 1.6 acceleration is in fact 2.6 times the power of a HAWT if the ratio of the shrouded rotor to the exit area is 1.6. If however the rotor to exit area ratio is 2.75 (as it was in the Grumman case), the actual power increase over a HAWT with the same swept area as the diffuser exit area is only 1.4× the power (a Cp of .34 related to the exit area, slightly better than a small unducted wind turbine and significantly worse than utility scale wind turbine Cp's). Given that the DAWTs with this ratio have roughly a solidity of 60+% when the blades and the diffuser are accounted for and the solidity of the HAWT is roughly 10%, the cost and amount of material needed to produce the 40% gain outweighs the increase in power.\n\nSecond is the structural requirement in terms of resisting overturning and bending in extreme wind events which all wind turbines must be designed for in accordance with the IEC 61400 series of standards (IEC) . The DAWT structure typically has poor drag characteristics (see D.G. Philips). That combined with higher solidity can lead to substantially greater structural costs than a HAWT in the support structure, the yaw bearing, and the foundation, when using conventional monopole designs. However, the advent of new tower designs, flange geometries and foundation systems appear to be successfully challenging these historical norms but if so then these advances can be equally well applied to improving the economics of conventional HAWT designs.\n\nIn the case of Optiwind (now defunct), there appears to be a growing body of evidence that they believe have solved for both the acceleration and economic challenges posed by CWAT/DAWT designs. Where previous attempts at new designs in this category have focused purely on acceleration magnitude, Optiwind appears to have taken a more holistic approach to their design, considering cost as much as acceleration benefit. In addition, the ongoing operational and maintenance cost of the entire unit appears to be successfully addressed in this design. It is absent the significant cost drivers of HAWT systems - large composite blades, gearbox, yaw motor, pitch control, lubrication, etc. In addition, the novel foundation geometry appears to have mitigated the structural challenges of the conventional monopole foundation design, which was originally conceived to offset the counter-rotational effects (\"wobbling\") of large, three blade turbines. As such, it is reasonable to assume that Optiwind's holistic approach to systemwide costs have led to a series of designs and discoveries that can realistically deliver the economic advantages of accelerated wind at a cost that is less than the net system cost. This is accurate if the Optiwind system is compared to a HAWT purely on rating. The problem therein is, if one compares the Optiwind design based on its stack height (the distance from its lowest turbine to the highest turbine) to a traditional HAWT of the same diameter, the overall power output of the machine is 20% less than that of the HAWT, with all the attendant material and structural expenses generally associated with a CWAT/DAWT. On average a CWAT/DAWT system would need to produce at least 2-3 times the energy a HAWT could produce from the maximum area used by the CWAT/DAWT in order to offset the substantially larger material costs. There is no evidence yet that there are any DAWT/CWAT designs capable of this level of increase when compared on an apples to apples basis with HAWT's.\n\nOgin's MEWT (mixer-ejector wind turbine, another CWAT variation) is differentiated from previous DAWT's by using a lobed two stage diffuser (Grumman and Vortec machine were also two stage, but conical instead of lobed) to equalize the pressure over the exit area of the diffuser. The theory is that creating a uniform pressure distribution with the lobes and the injection of external flow will prevent boundary layer separation in the diffuser thereby allowing the maximum acceleration through rotor. Werle and Presz's (Flodesign's chief scientists) paper, AAIA technical note Ducted Water/Wind turbines revisited - 2007, details the theory behind their design. Maximum acceleration detailed in their paper is 1.8× the ambient velocity from which they derive that 3 times more power is available at the rotor than for an unshrouded turbine. When referred to exit area this multiple drops to parity with the HAWT power. Ogin's turbine based on released images and CAD's appears to be substantially similar to the Vortec and Grumman machines except for the lobed inner annulus. This would indicate that its drag characteristics can be expected to be similar. Newer information on the Ogin website (www.oginenergy.com) shows the lobes flattened out into 2D panels. A number of Ogin wind turbines have been taken down after less than six months, for undisclosed reasons.\n\nThe science of wind acceleration around a structure, as well as the vortex shedding benefits of a shroud/diffuser, are well understood and tested. From Bernoulli forward, science has substantially vetted these concepts and there is general academic consensus as to their veracity and their potential impact on wind power production. DAWT's however have the classic boundary layer separation problem experienced by airfoils at a \"stall\" angle of attack. This significantly reduces the acceleration achievable by a DAWT relative to the theoretical rate indicated by its exit to area ratio, per Flodesign paper mentioned above. It is generally thought that since the amount of power produced by a wind turbine is proportional to the cube of the wind speed, any acceleration benefit is potentially statistically significant in the economics of wind. As noted though this is an inaccurate as it ignores the impact of the exit to area ratio and is therefore an apples to oranges comparison. In the case of a typical CWAT/DAWT the power result in perfect theoretical operation once adjusted for the area of the shroud is actually the square of the velocity at the rotor. As the CWAT/DAWT diverges from theoretical function the power increase drops significantly according to the formula derived from mass conservation,\n\nPower ratio = (A/A)(v/v)\n\nPower ratio = (1/2.75)(27.5 ms/10 ms) = 7.56 increase\n\nSo for example, a DAWT operating at theoretical function of 1.8 with a 2.75 area ratio per Flodesign,\n\nPower ratio = (1/2.75)(18 ms/10 ms) = 2.12 increase\n\nFor the highest claimed velocity increase in a DAWT of 1.6 × freestream,\n\nPower ratio = (1/2.75)(16 ms/10 ms) = 1.48 increase\n\nNot significant enough to offset the associated costs. The problem with optiwind is even more severe since the system only covers a fraction of the swept area available to a HAWT of the stack height.\n\nThe challenge has always been, and remains, installing, operating, and maintaining these structures for a cost that is less than the incremental value gained by their presence. Recent developments in material science, installation methodology and overall system integration have led to the far more realistic view that we are very close to this advent and the dawn of a new, highly sustainable class of wind turbine if the issues elucidated above can be dealt with which still remains highly questionable for the DAWT geometry.\n\nAmong the recent DAWT designs that appear to have a definitive positive power, if not cost, comparison to HAWTs is the Enflo turbine. Based on its rotor:exit ratio and the published power performance this turbine appears to have a confirmed 2 times increase in power output over a HAWT of the diameter of the exit area. It is still unlikely that this machine can scale to larger ratings but based on their published data (not confirmed by third party testing) the Enflo appears to be the best performing DAWT/CWAT yet built.\n\n\n"}
{"id": "14596160", "url": "https://en.wikipedia.org/wiki?curid=14596160", "title": "Continuous cooling transformation", "text": "Continuous cooling transformation\n\nA continuous cooling transformation (CCT) phase diagram is often used when heat treating steel. These diagrams are used to represent which types of phase changes will occur in a material as it is cooled at different rates. These diagrams are often more useful than time-temperature-transformation diagrams because it is more convenient to cool materials at a certain rate than to cool quickly and hold at a certain temperature.\n\nThere are two types of continuous cooling diagrams drawn for practical purposes\n\n"}
{"id": "1608081", "url": "https://en.wikipedia.org/wiki?curid=1608081", "title": "Diamond simulant", "text": "Diamond simulant\n\nA diamond simulant, diamond imitation or imitation diamond is an object or material with gemological characteristics similar to those of a diamond. Simulants are distinct from synthetic diamonds, which are actual diamonds having the same material properties as natural diamonds. Enhanced diamonds are also excluded from this definition. A diamond simulant may be artificial, natural, or in some cases a combination thereof. While their material properties depart markedly from those of diamond, simulants have certain desired characteristics—such as dispersion and hardness—which lend themselves to imitation. Trained gemologists with appropriate equipment are able to distinguish natural and synthetic diamonds from all diamond simulants, primarily by visual inspection.\n\nThe most common diamond simulants are high-leaded glass (i.e., rhinestones) and cubic zirconia (CZ), both artificial materials. A number of other artificial materials, such as strontium titanate and synthetic rutile have been developed since the mid-1950s, but these are no longer in common use. Introduced at the end of the 20th century, the lab-grown product moissanite has gained popularity as an alternative to diamond. The high price of gem-grade diamonds, as well as significant ethical concerns of the diamond trade, have created a large demand for diamond simulants.\n\nIn order to be considered for use as a diamond simulant, a material must possess certain diamond-like properties. The most advanced artificial simulants have properties which closely approach diamond, but all simulants have one or more features that clearly and (for those familiar with diamond) easily differentiate them from diamond. To a gemologist, the most important of differential properties are those that foster non-destructive testing; most of these are visual in nature. Non-destructive testing is preferred because most suspected diamonds are already cut into gemstones and set in jewelry, and if a destructive test (which mostly relies on the relative fragility and softness of non-diamonds) fails, it may damage the simulant—an unacceptable outcome for most jewelry owners, as even if a stone is not a diamond, it may still be of value.\n\nFollowing are some of the properties by which diamond and its simulants can be compared and contrasted.\n\nThe Mohs scale of mineral hardness is a non-linear scale of common minerals' resistances to scratching. Diamond is at the top of this scale (hardness 10), as it is one of the hardest naturally occurring materials known. (Some artificial substances, such as aggregated diamond nanorods, are harder.) Since a diamond is unlikely to encounter substances that can scratch it, other than another diamond, diamond gemstones are typically free of scratches. Diamond's hardness also is visually evident (under the microscope or loupe) by its highly lustrous facets (described as \"adamantine\") which are perfectly flat, and by its crisp, sharp facet edges. For a diamond simulant to be effective, it must be very hard relative to most gems. Most simulants fall far short of diamond's hardness, so they can be separated from diamond by their external flaws and poor polish.\n\nIn the recent past, the so-called \"window pane test\" was commonly thought to be an assured method of identifying diamond. It is a potentially destructive test wherein a suspect diamond gemstone is scraped against a pane of glass, with a positive result being a scratch on the glass and none on the gemstone. The use of hardness points and scratch plates made of corundum (hardness 9) are also used in place of glass. Hardness tests are inadvisable for three reasons: glass is fairly soft (typically 6 or below) and can be scratched by a large number of materials (including many simulants); diamond has four directions of perfect and easy cleavage (planes of structural weakness along which the diamond could split) which could be triggered by the testing process; and many diamond-like gemstones (including older simulants) are valuable in their own right.\n\nThe specific gravity (SG) or density of a gem diamond is fairly constant at 3.52. Most simulants are far above or slightly below this value, which can make them easy to identify if unset. High-density liquids such as diiodomethane can be used for this purpose, but these liquids are all highly toxic and therefore are usually avoided. A more practical method is to compare the expected size and weight of a suspect diamond to its measured parameters: for example, a cubic zirconia (SG 5.6–6) will be 1.7 times the expected weight of an equivalently sized diamond.\n\nDiamonds are usually cut into brilliants to bring out their \"brilliance\" (the amount of light reflected back to the viewer) and \"fire\" (the degree to which colorful prismatic flashes are seen). Both properties are strongly affected by the cut of the stone, but they are a function of diamond's high refractive index (RI—the degree to which incident light is bent upon entering the stone) of 2.417 (as measured by sodium light, 589.3 nm) and high dispersion (the degree to which white light is split into its spectral colors as it passes through the stone) of 0.044, as measured by the sodium B and G line interval. Thus, if a diamond simulant's RI and dispersion are too low, it will appear comparatively dull or \"lifeless\"; if the RI and dispersion are too high, the effect will be considered unreal or even tacky. Very few simulants have closely approximating RI and dispersion, and even the close simulants can be separated by an experienced observer. Direct measurements of RI and dispersion are impractical (a standard gemological refractometer has an upper limit of about RI 1.81), but several companies have devised reflectivity meters to gauge a material's RI indirectly by measuring how well it reflects an infrared beam.\n\nPerhaps equally as important is \"optic character\". Diamond and other cubic (and also amorphous) materials are \"isotropic\", meaning that light entering a stone behaves the same way regardless of direction. Conversely, most minerals are \"anisotropic\", which produces birefringence, or double refraction of light entering the material in all directions other than an optic axis (a direction of single refraction in a doubly refractive material). Under low magnification, this birefringence is usually detectable as a visual doubling of a cut gemstone's rear facets or internal flaws. An effective diamond simulant should therefore be isotropic.\n\nUnder longwave (365 nm) ultraviolet light, diamond may fluoresce a blue, yellow, green, mauve, or red of varying intensity. The most common fluorescence is blue, and such stones may also phosphoresce yellow—this is thought to be a unique combination among gemstones. There is usually little if any response to shortwave ultraviolet, in contrast to many diamond simulants. Similarly, because most diamond simulants are artificial, they tend to have uniform properties: in a multi-stone diamond ring, one would expect the individual diamonds to fluoresce differently (in different colors and intensities, with some likely to be inert). If all the stones fluoresce in an identical manner, they are unlikely to be diamond.\n\nMost \"colorless\" diamonds are actually tinted yellow or brown to some degree, whereas some artificial simulants are completely colorless—the equivalent of a perfect \"D\" in diamond color terminology. This \"too good to be true\" factor is important to consider; colored diamond simulants meant to imitate fancy diamonds are more difficult to spot in this regard, but the simulants' colors rarely approximate. In most diamonds (even colorless ones) a characteristic absorption spectrum can be seen (by a direct-vision spectroscope), consisting of a fine line at 415 nm. The dopants used to impart color in artificial simulants may be detectable as a complex rare-earth absorption spectrum, which is never seen in diamond.\n\nAlso present in most diamonds are certain internal and external flaws or \"inclusions\", the most common of which are fractures and solid foreign crystals. Artificial simulants are usually internally flawless, and any flaws that are present are characteristic of the manufacturing process. The inclusions seen in natural simulants will often be unlike those ever seen in diamond, most notably liquid \"feather\" inclusions. The diamond cutting process will often leave portions of the original crystal's surface intact. These are termed \"naturals\" and are usually on the girdle of the stone; they take the form of triangular, rectangular, or square pits (\"etch marks\") and are seen only in diamond.\n\nDiamond is an extremely effective thermal conductor and usually an electrical insulator. The former property is widely exploited in the use of an electronic \"thermal probe\" to separate diamonds from their imitations. These probes consist of a pair of battery-powered thermistors mounted in a fine copper tip. One thermistor functions as a heating device while the other measures the temperature of the copper tip: if the stone being tested is a diamond, it will conduct the tip's thermal energy rapidly enough to produce a measurable temperature drop. As most simulants are thermal insulators, the thermistor's heat will not be conducted. This test takes about 2–3 seconds. The only possible exception is moissanite, which has a thermal conductivity similar to diamond: older probes can be fooled by moissanite, but newer thermal and electrical conductivity testers are sophisticated enough to differentiate the two materials.\nThe latest development is nano diamond coating, an extremely thin layer of diamond material. If not tested properly it may show the same characteristics as a diamond.\n\nA diamond's electrical conductance is only relevant to blue or gray-blue stones, because the interstitial boron responsible for their color also makes them semiconductors. Thus, a suspected blue diamond can be affirmed if it completes an electric circuit successfully.\n\nDiamond has been imitated by artificial materials for hundreds of years; advances in technology have seen the development of increasingly better simulants with properties ever nearer those of diamond. Although most of these simulants were characteristic of a certain time period, their large production volumes ensured that all continue to be encountered with varying frequency in jewelry of the present. Nearly all were first conceived for intended use in high technology, such as active laser mediums, varistors, and bubble memory. Due to their limited present supply, collectors may pay a premium for the older types.\n\nThe \"refractive index(es)\" column shows one refractive index for singly refractive substances, and a range for doubly refractive substances.\n\nThe formulation of flint glass using lead, alumina, and thallium to increase RI and dispersion began in the late Baroque period. Flint glass is fashioned into brilliants, and when freshly cut they can be surprisingly effective diamond simulants. Known as rhinestones, pastes, or strass, glass simulants are a common feature of antique jewelry; in such cases, rhinestones can be valuable historical artifacts in their own right. The great softness (below hardness 6) imparted by the lead means a rhinestone's facet edges and faces will quickly become rounded and scratched. Together with conchoidal fractures, and air bubbles or flow lines within the stone, these features make glass imitations easy to spot under only moderate magnification. In contemporary production it is more common for glass to be molded rather than cut into shape: in these stones the facets will be concave and facet edges rounded, and mold marks or seams may also be present. Glass has also been combined with other materials to produce composites.\n\nThe first crystalline artificial diamond simulants were synthetic white sapphire (AlO, pure corundum) and spinel (MgO·AlO, pure magnesium aluminium oxide). Both have been synthesized in large quantities since the first decade of the 20th century via the Verneuil or flame-fusion process, although spinel was not in wide use until the 1920s. The Verneuil process involves an inverted oxyhydrogen blowpipe, with purified feed powder mixed with oxygen that is carefully fed through the blowpipe. The feed powder falls through the oxy-hydrogen flame, melts, and lands on a rotating and slowly descending pedestal below. The height of the pedestal is constantly adjusted to keep its top at the optimal position below the flame, and over a number of hours the molten powder cools and crystallizes to form a single pedunculated pear or \"boule\" crystal. The process is an economical one, with crystals of up to 9 centimeters (3.5 inches) in diameter grown. Boules grown via the modern Czochralski process may weigh several kilograms.\n\nSynthetic sapphire and spinel are durable materials (hardness 9 and 8) that take a good polish; however, due to their much lower RI when compared to diamond (1.762–1.770 for sapphire, 1.727 for spinel), they are \"lifeless\" when cut. (Synthetic sapphire is also anisotropic, making it even easier to spot.) Their low RIs also mean a much lower dispersion (0.018 and 0.020), so even when cut into brilliants they lack the \"fire\" of diamond. Nevertheless, synthetic spinel and sapphire were popular diamond simulants from the 1920s until the late 1940s, when newer and better simulants began to appear. Both have also been combined with other materials to create composites. Commercial names once used for synthetic sapphire include \"Diamondette\", \"Diamondite\", \"Jourado Diamond\"', and \"Thrilliant\". Names for synthetic spinel included \"Corundolite\", \"Lustergem\", \"Magalux\", and \"Radiant\".\n\nThe first of the optically \"improved\" simulants was synthetic rutile (TiO, pure titanium oxide). Introduced in 1947–48, synthetic rutile possesses plenty of life when cut—perhaps too much life for a diamond simulant. Synthetic rutile's RI and dispersion (2.8 and 0.33) are so much higher than diamond that the resultant brilliants look almost opal-like in their display of prismatic colors. Synthetic rutile is also doubly refractive: although some stones are cut with the table perpendicular to the optic axis to hide this property, merely tilting the stone will reveal the doubled back facets.\n\nThe continued success of synthetic rutile was also hampered by the material's inescapable yellow tint, which producers were never able to remedy. However, synthetic rutile in a range of different colors, including blues and reds, were produced using various metal oxide dopants. These and the near-white stones were extremely popular if unreal stones. Synthetic rutile is also fairly soft (hardness ~6) and brittle, and therefore wears poorly. It is synthesized via a modification of the Verneuil process, which uses a third oxygen pipe to create a \"tricone burner\"; this is necessary to produce a single crystal, due to the much higher oxygen losses involved in the oxidation of titanium. The technique was invented by Charles H. Moore, Jr. at the South Amboy, New Jersey-based National Lead Company (later NL Industries). National Lead and Union Carbide were the primary producers of synthetic rutile, and peak annual production reached 750,000 carats (150 kg). Some of the many commercial names applied to synthetic rutile include: \"Astryl\", \"Diamothyst\", \"Gava\" or \"Java Gem\", \"Meredith\", \"Miridis\", \"Rainbow Diamond\", \"Rainbow Magic Diamond\", \"Rutania\", \"Titangem\", \"Titania\", and \"Ultamite\".\n\nNational Lead was also where research into the synthesis of another titanium compound—strontium titanate (SrTiO, pure tausonite)—was conducted. Research was done during the late 1940s and early 1950s by Leon Merker and Langtry E. Lynd, who also used a tricone modification of the Verneuil process. Upon its commercial introduction in 1955, strontium titanate quickly replaced synthetic rutile as the most popular diamond simulant. This was due not only to strontium titanate's novelty, but to its superior optics: its RI (2.41) is very close to that of diamond, while its dispersion (0.19), although also very high, was a significant improvement over synthetic rutile's psychedelic display. Dopants were also used to give synthetic titanate a variety of colors, including yellow, orange to red, blue, and black. The material is also isotropic like diamond, meaning there is no distracting doubling of facets as seen in synthetic rutile.\n\nStrontium titanate's only major drawback (if one excludes excess fire) is fragility. It is both softer (hardness 5.5) and more brittle than synthetic rutile—for this reason, strontium titanate was also combined with more durable materials to create composites. It was otherwise the best simulant around at the time, and at its peak annual production was 1.5 million carats (300 kg). Due to patent coverage, all US production was by National Lead, while large amounts were produced overseas by Nakazumi Company of Japan. Commercial names for strontium titanate included \"Brilliante\", \"Diagem\", \"Diamontina\", \"Fabulite\", and \"Marvelite\".\n\nFrom about 1970 strontium titanate began to be replaced by a new class of diamond imitations: the \"synthetic garnets\". These are not true garnets in the usual sense because they are oxides rather than silicates, but they do share natural garnet's crystal structure (both are cubic and therefore isotropic) and the general formula ABCO. While in natural garnets C is always silicon, and A and B may be one of several common elements, most synthetic garnets are composed of uncommon rare-earth elements. They are the only diamond simulants (aside from rhinestones) with no known natural counterparts: gemologically they are best termed \"artificial\" rather than \"synthetic\", because the latter term is reserved for human-made materials that can also be found in nature.\n\nAlthough a number of artificial garnets were successfully grown, only two became important as diamond simulants. The first was yttrium aluminium garnet (YAG; YAlO) in the late 1960s. It was (and still is) produced by the Czochralski, or crystal-pulling, process, which involves growth from the melt. An iridium crucible surrounded by an inert atmosphere is used, wherein yttrium oxide and aluminium oxide are melted and mixed together at a carefully controlled temperature near 1980 °C. A small seed crystal is attached to a rod, which is lowered over the crucible until the crystal contacts the surface of the melted mixture. The seed crystal acts as a site of nucleation; the temperature is kept steady at a point where the surface of the mixture is just below the melting point. The rod is slowly and continuously rotated and retracted, and the pulled mixture crystallizes as it exits the crucible, forming a single crystal in the form of a cylindrical boule. The crystal's purity is extremely high, and it typically measures 5 cm (2 inches) in diameter and 20 cm (8 inches) in length, and weighs 9,000 carats (1.75 kg).\n\nYAG hardness (8.25) and lack of brittleness were great improvements over strontium titanate, and although its RI (1.83) and dispersion (0.028) were fairly low, they were enough to give brilliant-cut YAGs perceptible fire and good brilliance (although still much lower than diamond). A number of different colors were also produced with the addition of dopants, including yellow, red, and a vivid green, which was used to imitate emerald. Major producers included Shelby Gem Factory of Michigan, Litton Systems, Allied Chemical, Raytheon, and Union Carbide; annual global production peaked at 40 million carats (8000 kg) in 1972, but fell sharply thereafter. Commercial names for YAG included \"Diamonair\", \"Diamonique\", \"Gemonair\", \"Replique\", and \"Triamond\".\n\nWhile market saturation was one reason for the fall in YAG production levels, another was the recent introduction of the other artificial garnet important as a diamond simulant, gadolinium gallium garnet (GGG; GdGaO). Produced in much the same manner as YAG (but with a lower melting point of 1750 °C), GGG had an RI (1.97) close to, and a dispersion (0.045) nearly identical to diamond. GGG was also hard enough (hardness 7) and tough enough to be an effective gemstone, but its ingredients were also much more expensive than YAG's. Equally hindering was GGG's tendency to turn dark brown upon exposure to sunlight or other ultraviolet source: this was due to the fact that most GGG gems were fashioned from impure material that was rejected for technological use. The SG of GGG (7.02) is also the highest of all diamond simulants and amongst the highest of all gemstones, which makes loose GGG gems easy to spot by comparing their dimensions with their expected and actual weights. Relative to its predecessors, GGG was never produced in significant quantities; it became more or less unheard of by the close of the 1970s. Commercial names for GGG included \"Diamonique II\" and \"Galliant\".\n\nCubic zirconia or CZ (ZrO; zirconium dioxide—not to be confused with zircon, a zirconium silicate) quickly dominated the diamond simulant market following its introduction in 1976, and it remains the most gemologically and economically important simulant. CZ had been synthesized since 1930 but only in ceramic form: the growth of single-crystal CZ would require an approach radically different from those used for previous simulants due to zirconium's extremely high melting point (2750 °C), unsustainable by any crucible. The solution found involved a network of water-filled copper pipes and radio-frequency induction heating coils; the latter to heat the zirconium feed powder, and the former to cool the exterior and maintain a retaining \"skin\" under 1 millimeter thick. CZ was thus grown in a crucible of itself, a technique called \"cold crucible\" (in reference to the cooling pipes) or \"skull crucible\" (in reference to either the shape of the crucible or of the crystals grown).\n\nAt standard pressure zirconium oxide would normally crystallize in the monoclinic rather than cubic crystal system: for cubic crystals to grow, a stabilizer must be used. This is usually Yttrium(III) oxide or calcium oxide. The skull crucible technique was first developed in 1960s France, but was perfected in the early 1970s by Soviet scientists under V. V. Osiko at the Lebedev Physical Institute in Moscow. By 1980 annual global production had reached 50 million carats (10,000 kg).\n\nThe hardness (8–8.5), RI (2.15–2.18, isotropic), dispersion (0.058–0.066), and low material cost make CZ the most popular simulant of diamond. Its optical and physical constants are however variable, owing to the different stabilizers used by different producers. There are many formulations of stabilized cubic zirconia. These variations change the physical and optical properties markedly. While the visual likeness of CZ is close enough to diamond to fool most who do not handle diamond regularly, CZ will usually give certain clues. For example: it is somewhat brittle and is soft enough to possess scratches after normal use in jewelry; it is usually internally flawless and completely colorless (whereas most diamonds have some internal imperfections and a yellow tint); its SG (5.6–6) is high; and its reaction under ultraviolet light is a distinctive beige. Most jewelers will use a thermal probe to test all suspected CZs, a test which relies on diamond's superlative thermal conductivity (CZ, like almost all other diamond simulants, is a thermal insulator). CZ is made in a number of different colors meant to imitate fancy diamonds (e.g., yellow to golden brown, orange, red to pink, green, and opaque black), but most of these do not approximate the real thing. Cubic zirconia can be coated with diamond-like carbon to improve its durability, but will still be detected as CZ by a thermal probe.\n\nCZ had virtually no competition until the 1998 introduction of moissanite (SiC; silicon carbide). Moissanite is superior to cubic zirconia in two ways: its hardness (8.5–9.25) and low SG (3.2). The former property results in facets that are sometimes as crisp as a diamond's, while the latter property makes simulated moissanite somewhat harder to spot when unset (although still disparate enough to detect). However, unlike diamond and cubic zirconia, moissanite is strongly birefringent. This manifests as the same \"drunken vision\" effect seen in synthetic rutile, although to a lesser degree. All moissanite is cut with the table perpendicular to the optic axis in order to hide this property from above, but when viewed under magnification at only a slight tilt the doubling of facets (and any inclusions) is readily apparent.\n\nThe inclusions seen in moissanite are also characteristic: most will have fine, white, subparallel growth tubes or needles oriented perpendicular to the stone's table. It is conceivable that these growth tubes could be mistaken for laser drill holes that are sometimes seen in diamond (see diamond enhancement), but the tubes will be noticeably doubled in moissanite due to its birefringence. Like synthetic rutile, current moissanite production is also plagued by an as yet inescapable tint, which is usually a brownish green. A limited range of fancy colors have been produced as well, the two most common being blue and green. \n\nNatural minerals that (when cut) optically resemble white diamonds are rare, because the trace impurities usually present in natural minerals tend to impart color. The earliest simulants of diamond were colorless quartz (A form of silica, which also form obsidian, glass and sand), rock crystal (a type of quartz), topaz, and beryl (goshenite); they are all common minerals with above-average hardness (7–8), but all have low RIs and correspondingly low dispersions. Well-formed quartz crystals are sometimes offered as \"diamonds\", a popular example being the so-called \"Herkimer diamonds\" mined in Herkimer County, New York. Topaz's SG (3.50–3.57) also falls within the range of diamond.\n\nFrom a historical perspective, the most notable natural simulant of diamond is zircon. It is also fairly hard (7.5), but more importantly shows perceptible fire when cut, due to its high dispersion of 0.039. Colorless zircon has been mined in Sri Lanka for over 2,000 years; prior to the advent of modern mineralogy, colorless zircon was thought to be an inferior form of diamond. It was called \"Matara diamond\" after its source location. It is still encountered as a diamond simulant, but differentiation is easy due to zircon's anisotropy and strong birefringence (0.059). It is also notoriously brittle and often shows wear on the girdle and facet edges.\n\nMuch less common than colorless zircon is colorless scheelite. Its dispersion (0.026) is also high enough to mimic diamond, but although it is highly lustrous its hardness is much too low (4.5–5.5) to maintain a good polish. It is also anisotropic and fairly dense (SG 5.9–6.1). Synthetic scheelite produced via the Czochralski process is available, but it has never been widely used as a diamond simulant. Due to the scarcity of natural gem-quality scheelite, synthetic scheelite is much more likely to simulate it than diamond. A similar case is the orthorhombic carbonate cerussite, which is so fragile (very brittle with four directions of good cleavage) and soft (hardness 3.5) that it is never seen set in jewelry, and only occasionally seen in gem collections because it is so difficult to cut. Cerussite gems have an adamantine luster, high RI (1.804–2.078), and high dispersion (0.051), making them attractive and valued collector's pieces. Aside from softness, they are easily distinguished by cerussite's high density (SG 6.51) and anisotropy with extreme birefringence (0.271).\n\nDue to their rarity fancy-colored diamonds are also imitated, and zircon can serve this purpose too. Applying heat treatment to brown zircon can create several bright colors: these are most commonly sky-blue, golden yellow, and red. Blue zircon is very popular, but it is not necessarily color stable; prolonged exposure to ultraviolet light (including the UV component in sunlight) tends to bleach the stone. Heat treatment also imparts greater brittleness to zircon and characteristic inclusions.\n\nAnother fragile candidate mineral is sphalerite (zinc blende). Gem-quality material is usually a strong yellow to honey brown, orange, red, or green; its very high RI (2.37) and dispersion (0.156) make for an extremely lustrous and fiery gem, and it is also isotropic. But here again, its low hardness (2.5–4) and perfect dodecahedral cleavage preclude sphalerite's wide use in jewelry. Two calcium-rich members of the garnet group fare much better: these are grossularite (usually brownish orange, rarely colorless, yellow, green, or pink) and andradite. The latter is the rarest and most costly of the garnets, with three of its varieties—topazolite (yellow), melanite (black), and demantoid (green)—sometimes seen in jewelry. Demantoid (literally \"diamond-like\") especially has been prized as a gemstone since its discovery in the Ural Mountains in 1868; it is a noted feature of antique Russian and Art Nouveau jewelry. Titanite or sphene is also seen in antique jewelry; it is typically some shade of chartreuse and has a luster, RI (1.885–2.050), and dispersion (0.051) high enough to be mistaken for diamond, yet it is anisotropic (a high birefringence of 0.105–0.135) and soft (hardness 5.5).\n\nDiscovered the 1960s, the rich green tsavorite variety of grossular is also very popular. Both grossular and andradite are isotropic and have relatively high RIs (around 1.74 and 1.89 respectively) and high dispersions (0.027 and 0.057), with demantoid's exceeding diamond. However, both have a low hardness (6.5–7.5) and invariably possess inclusions atypical for diamond—the byssolite \"horsetails\" seen in demantoid are one striking example. Furthermore, most are very small, typically under 0.5 carats (100 mg) in weight. Their lusters range from vitreous to subadamantine, to almost metallic in the usually opaque melanite, which has been used to simulate black diamond. Some natural spinel is also deep black and could serve this same purpose.\n\nBecause strontium titanate and glass are too soft to survive use as a ring stone, they have been used in the construction of composite or \"doublet\" diamond simulants. The two materials are used for the bottom portion (pavilion) of the stone, and in the case of strontium titanate, a much harder material—usually colorless synthetic spinel or sapphire—is used for the top half (crown). In glass doublets, the top portion is made of almandine garnet; it is usually a very thin slice which does not modify the stone's overall body color. There have even been reports of diamond-on-diamond doublets, where a creative entrepreneur has used two small pieces of rough to create one larger stone.\n\nIn strontium titanate and diamond-based doublets, an epoxy is used to adhere the two halves together. The epoxy may fluoresce under UV light, and there may be residue on the stone's exterior. The garnet top of a glass doublet is physically fused to its base, but in it and the other doublet types there are usually flattened air bubbles seen at the junction of the two halves. A join line is also readily visible whose position is variable; it may be above or below the girdle, sometimes at an angle, but rarely along the girdle itself.\n\nThe most recent composite simulant involves combining a CZ core with an outer coating of laboratory created amorphous diamond. The concept effectively mimics the structure of a cultured pearl (which combines a core bead with an outer layer of pearl coating), only done for the diamond market.\n\n"}
{"id": "52077192", "url": "https://en.wikipedia.org/wiki?curid=52077192", "title": "Duck curve", "text": "Duck curve\n\nIn utility-scale electricity generation, the duck curve is a graph of power production over the course of a day that shows the timing imbalance between peak demand and renewable energy production. In many energy markets the peak demand occurs after sunset, when solar power is no longer available. In locations where a substantial amount of solar electric capacity has been installed, the amount of power that must be generated from sources other than solar or wind displays a rapid increase around sunset and peaks in the mid-evening hours, producing a graph that resembles the silhouette of a duck. In Hawaii, significant adoption of solar generation has led to the more pronounced curve known as the Nessie curve.\n\nWithout any form of energy storage, after times of high solar generation generating companies must rapidly increase power output around the time of sunset to compensate for the loss of solar generation, a major concern for grid operators where there is rapid growth of photovoltaics. Storage can fix these issues if it can be implemented. Flywheels have shown to provide excellent frequency regulation. Short term use batteries, at a large enough scale of use, can help to flatten the duck curve and prevent generator use fluctuation and can help to maintain voltage profile. However, cost is a major limiting factor for energy storage as each technique is expensive to produce at scale.\n\nThe term was coined in 2012 by the California Independent System Operator.\n\nMethods for coping with the rapid increase in demand at sunset reflected in the duck curve, which becomes more serious as the penetration of solar generation grows, include:\n\nA major challenge is deploying mitigating capacity at a rate that keeps up with the growth of solar energy production. The effects of the duck curve have happened faster than anticipated.\n\nThe California Independent System Operator (CAISO) has been monitoring and analyzing the Duck Curve and its future expectations for about a half a century now and their biggest finding is the growing gap between morning and evening hours prices relative to midday hours prices. According to their last study, the U.S. Energy Information Administration, found that the wholesale energy market prices over the past six months during the 5 p.m. to 8 p.m. period (the “neck” of the duck) have increased to $60 per megawatt-hour, compared to about $35 per megawatt-hour in the same time frame in 2016. However, on the other side they have measured a drastic decrease in the midday prices, nearing $15 per megawatt-hour. These high peaks and deep valleys are only showing continues trends of going further apart making this Duck Curve even more prevalent as our renewable energy production continues to grow.\n\nA crucial part of this curve comes from the Net Load (\"the difference between expected load and anticipated electricity production from the range of renewable energy sources\"). In certain times of the year (namely Spring and Summer), the curves create a “belly” appearance in the midday that then drastically increases portraying an “arch” similar to the neck of a duck, consequently the name “The Duck Chart.” During the midday, large amounts of solar energy is created and partially contributes to lower demand for additional electricity. Increasing battery storage can mitigate the issues of solar abundance during the day. When excess solar energy is stored during the day and used in the evening, the price disparity between inexpensive midday and expensive evening energy can be reduced. Enough total solar technology exists to power the world, but there is a current lack of infrastructure to store solar energy for later use. An oversupply of energy during low demand coupled with a lack of supply during high demand explains the large disparity between midday and evening energy prices.\n\nTo understand these deep valleys and the high peaks we need to look at many different variables that go into the renewable energy grid. The green resources such as solar, wind, geothermal, and hydroelectric are increasingly satisfying California’s total electricity needs. Green energy is abundant, which has become an economic issue on the time of use front. However, as of now, the technology that has been implemented puts a lot of control into consumers which leads to issues amongst different operating conditions. In order for it to run smoothly this would require flexible resource potentials to guarantee reliability from the renewable energy grid. The idea of reliability is one of the biggest issues facing the green energy market. Intermittency (“occurring at irregular intervals; not continuous or steady”) can lead to skepticism in consumers. If consumers are to transfer energy into the renewable grid, they must be guaranteed a constant stream of energy at a price/rate that can be maintained, but the Duck Curve issue is proving just the opposite.\n\n"}
{"id": "19110904", "url": "https://en.wikipedia.org/wiki?curid=19110904", "title": "Elk River Wind Project", "text": "Elk River Wind Project\n\nThe Elk River Wind Project is a 150 megawatt wind farm near Beaumont in Butler County, Kansas. The Elk River wind plant's subsidiary is owned by a parent company. The plant has been operating since 2005.\n\nEmpire District Electric selected Elk River, and signed a twenty-year agreement with PPM Energy to purchase wind energy from the farm.\n\n"}
{"id": "19713842", "url": "https://en.wikipedia.org/wiki?curid=19713842", "title": "Engineers Without Borders (Palestine)", "text": "Engineers Without Borders (Palestine)\n\nEngineers Without Borders (EWB) Palestine (or EWB-Palestine) is a Palestine-based registered charity and NGO. Its mission is to \"partner with Palestinian disadvantaged communities to improve their quality of life through the implementation of environmentally and economically sustainable engineering projects, while developing internationally responsible engineers and engineering students.\" \n\nEWB-Palestine is the Palestinian national representative within the Engineers Without Borders International Group.\n\nIn August 2005, EWB-Palestine was created as a provisional member of EWB-International. In July 2006, it was registered as a nonprofit organization with the Ministry of the Interior in Palestine. In September 2008, EWB-Palestine was represented on the EWB-International board of directors.\n\n\n"}
{"id": "28410167", "url": "https://en.wikipedia.org/wiki?curid=28410167", "title": "Epcard", "text": "Epcard\n\nEPCARD (European Program Package for the Calculation of Aviation Route Doses) is a software program that calculates radiation exposure of aircrews. The software code is based on the FLUKA transport code. EPCARD allows calculation of a simulated dose from most important components of penetrating cosmic radiation on any aviation route and for any flight profile at altitudes from 5 to 25 km.\n\nEpcard helps airlines monitor radiation exposure, and comply with regulations relating to this area.\n\nThis software package was developed by scientists of the Institute of Radiation Protection of the Helmholtz Zentrum München, German Research Center for Environmental Health (former GSF - National Research Center for Environment and Health) with support from the European Commission and University of Siegen, Germany.\n\nThe EPCARD program virtually simulates a flight (with time resolution of 1 min) in the “quasi-real” radiation field of cosmic secondary particles. It is based on the energy spectra of neutrons, protons, photons, electrons, positrons, muons, and pions, calculated by means of the FLUKA Monte Carlo code at various altitudes in the Earth’s atmosphere down to sea level, for all possible physical parameters of solar activity and geomagnetic shielding conditions. A large scale set of “fluence-to-dose” conversion coefficients is employed, to calculate dose quantities (in units of microSievert) in terms of ambient dose equivalent, H*(10), and effective dose, E. EPCARD.Net is based on the same physical algorithms as the EPCARD program, but is currently ready to process some extended physical parameters giving more precise information about flight route doses. EPCARD.Net is a completely new code which can be run on many systems such as Microsoft Windows NT/2K/XP/Vista (using both .Net and Mono runtime platform) or ‘UNIX kernel type’ operating systems like Linux, Mac OS X or Solaris (using the Mono runtime platform).\n\nThe Luftfahrt-Bundesamt (German Aviation Authority; LBA, Federal Office for Aviation) and the Physikalisch-Technische Bundesanstalt (National Metrology Institute; PTB) granted official approval for EPCARD version 3.34 in December 2003. EPCARD.Net Professional version 5.4.3 was approved for official use for aircrew dose assessment by LBA and PTB in April 2010.\n\nAmong the users of the software include major German airlines like Lufthansa, Condor Flugdienst, LTU International or the international airline service provider ASISTIM GmbH.\n\nFree of charge on-line dose calculations for any flights can be performed with a simplified version of EPCARD, on the EPCARD web site.\n\n\n"}
{"id": "38584702", "url": "https://en.wikipedia.org/wiki?curid=38584702", "title": "Flights (rotary dryer)", "text": "Flights (rotary dryer)\n\nFlights, also commonly referred to as “lifters,” are used in rotary dryers and rotary coolers to shower material through the process gas stream. Affixed to the interior of the rotary drum, these fin-like structures scoop up material from the bed and shower it through the gas stream as the drum rotates. This showering creates a curtain of material spanning the width of the rotary dryer or cooler, helping to maximize the efficiency of heat transfer.\n\nDepending on the needs of the material and the process, flights are engineered in a variety of designs and placement patterns in order to create a maximum efficiency curtain, while still retaining the integrity of the product.\n"}
{"id": "33324563", "url": "https://en.wikipedia.org/wiki?curid=33324563", "title": "Fuel surrogate", "text": "Fuel surrogate\n\nFuel surrogates are mixtures of one or more simple fuels that are designed to emulate either the physical properties (vapor pressure) or combustion properties (laminar flame speed, heating value, etc.) of a more complex fuel. While surrogate mixtures can demonstrate more than one characteristic of the desired fuel, more often than not different components are required in order to emulate the wide variety of properties that are of interest to researchers. Jet fuel is an example of a fuel requiring a surrogate for experimental research and numerical modelling due to its complexity and high content variability from one batch to the next. Neat hydrocarbon jet fuel surrogate components include decane, dodecane, methylcyclohexane, and toluene. Gasoline surrogate components include n-heptane and iso-octane. Hexadecane is a diesel surrogate component. Biodiesel surrogate components include methyl butyrate and methyl decanoate.\n"}
{"id": "908694", "url": "https://en.wikipedia.org/wiki?curid=908694", "title": "GLARE", "text": "GLARE\n\nGlass reinforced aluminium (GLARE) is a fiber metal laminate (FML) composed of several very thin layers of metal (usually aluminium) interspersed with layers of glass-fiber \"pre-preg\", bonded together with a matrix such as epoxy. The uni-directional pre-preg layers may be aligned in different directions to suit predicted stress conditions.\n\nThough GLARE is a composite material, its material properties and fabrication are very similar to bulk aluminium metal sheets. It has far less in common with composite structures when it comes to design, manufacture, inspection, or maintenance. GLARE parts are constructed and repaired using mostly conventional metal working techniques.\n\nIts major advantages over conventional aluminium are:\n\n\nFurthermore, it is possible to \"tailor\" the material during design and manufacture such that the number, type and alignment of layers can suit the local stresses and shapes throughout the aircraft. This allows the production of double-curved sections, complex integrated panels or very large sheets, for example.\n\nWhile a simple manufactured sheet of GLARE is more expensive than an equivalent sheet of aluminium, considerable production savings can be made using the aforementioned optimization. A structure properly designed for GLARE is significantly lighter and less complex than an equivalent metal structure, requires less inspection and maintenance, and has a longer \"lifetime-till failure\", often making it cheaper, lighter, and safer in the long run.\n\nGLARE is a relatively successful FML, patented by Akzo Nobel in 1987. It has entered commercial application in the Airbus A380. The several patents mention among others as inventors Vogelesang, Schijve, Roebroeks and Marissen, then professors and researchers at the Faculty of Aerospace Engineering, Delft University of Technology, where much of the on FML was done in the 1970s and 1980s.\n\nThe fruition of FML development marks a step in the long history of research that started in 1945 at Fokker, where earlier bonding experience at de Havilland inspired investigation into the improved properties of bonded aluminium laminates compared to monolithic aluminium. Later, NASA got interested in reinforcing metal parts with composite materials as part of the Space Shuttle program led to the introduction of fibers to the bond layers, and the concept of FMLs was born.\n\nFurther research and co-operation of Fokker with Delft University, the Dutch Aerospace Laboratory , 3M, Alcoa and various other companies and institutions led to the first FML, the Aramid fiber based ARALL. This proved to have some cost, manufacturing and application problems (while it had a very high tensile strength; compression, off-axis loading and cyclic loading proved problematic), which lead to an improved version with glass-fiber instead of aramid fibers.\n\nOver the course of the development of the material, which took more than 30 years from start to the major application on the Airbus A380, many other production and development partners have been involved, including Boeing, McDonnell Douglas, Bombardier, and the US Air Force. Over the course of time, companies withdrew from this involvement, sometimes to come back after a couple of years, like Alcoa who withdrew in 1995 to come back in 2004 and withdrew once again in 2010. These strategic decisions show the dynamic nature of innovation processes.\n\nBesides the applications on the Airbus A380 fuselage, GLARE has multiple 'secondary' applications. GLARE is also the material used in the ECOS3 blast-resistant Unit Load Device. This is freight container shown to completely contain the explosion and fire resulting from a bomb such as that used over Lockerbie. Other applications include among others the application in the Learjet 45 and in the past also in cargo floors of the Boeing 737.\n\nGLARE is currently produced by GKN-Fokker in the Netherlands and Airbus in Nordenham, Germany. GKN- Fokker opened a brand new facility next to its existing facilities in Papendrecht, the Netherlands where they produce Glare sheets of , including the milling of doors windows etc. on a 5-axis milling machine with a movable bed.\n\nGlare has also been used to make cargo doors for later models of the C-17 Globemaster III.\n\n\n\n"}
{"id": "12241", "url": "https://en.wikipedia.org/wiki?curid=12241", "title": "Gallium", "text": "Gallium\n\nGallium is a chemical element with symbol Ga and atomic number 31. It is in group 13 of the periodic table, and thus has similarities to the other metals of the group, aluminium, indium, and thallium. Gallium does not occur as a free element in nature, but as gallium(III) compounds in trace amounts in zinc ores and in bauxite. Elemental gallium is a soft, silvery blue metal at standard temperature and pressure, a brittle solid at low temperatures, and a liquid at temperatures greater than (above room temperature, but below the normal human body temperature of , hence, the metal will melt in a person's hands).\n\nThe melting point of gallium is used as a temperature reference point. Gallium alloys are used in thermometers as a non-toxic and environmentally friendly alternative to mercury, and can withstand higher temperatures than mercury. The alloy galinstan (70% gallium, 21.5% indium, and 10% tin) has an even lower melting point of , well below the freezing point of water.\n\nSince its discovery in 1875, gallium has been used to make alloys with low melting points. It is also used in semiconductors as a dopant in semiconductor substrates.\n\nGallium is predominantly used in electronics. Gallium arsenide, the primary chemical compound of gallium in electronics, is used in microwave circuits, high-speed switching circuits, and infrared circuits. Semiconducting gallium nitride and indium gallium nitride produce blue and violet light-emitting diodes (LEDs) and diode lasers. Gallium is also used in the production of artificial gadolinium gallium garnet for jewelry.\n\nGallium has no known natural role in biology. Gallium(III) behaves in a similar manner to ferric salts in biological systems and has been used in some medical applications, including pharmaceuticals and radiopharmaceuticals.\n\nElemental gallium is not found in nature, but it is easily obtained by smelting. Very pure gallium metal has a silvery color and its solid metal fractures conchoidally like glass. Gallium liquid expands by 3.1% when it solidifies; therefore, it should not be stored in glass or metal containers because the container may rupture when the gallium changes state. Gallium shares the higher-density liquid state with a short list of other materials that includes water, silicon, germanium, antimony, bismuth, and plutonium.\n\nGallium attacks most other metals by diffusing into the metal lattice. For example, it diffuses into the grain boundaries of aluminium-zinc alloys and steel, making them very brittle. Gallium easily alloys with many metals, and is used in small quantities in the plutonium-gallium alloy in the plutonium cores of nuclear bombs to stabilize the plutonium crystal structure.\n\nThe melting point of gallium, at 302.9146 K (29.7646 °C, 85.5763 °F), is just above room temperature, and is approximately the same as the average summer daytime temperatures in Earth's mid-latitudes. This melting point (mp) is one of the formal temperature reference points in the International Temperature Scale of 1990 (ITS-90) established by the International Bureau of Weights and Measures (BIPM). The triple point of gallium, 302.9166 K (29.7666 °C, 85.5799 °F), is used by the US National Institute of Standards and Technology (NIST) in preference to the melting point.\n\nThe melting point of gallium allows it to melt in the human hand, and then refreeze if removed. The liquid metal has a strong tendency to supercool below its melting point/freezing point: Ga nanoparticles can be kept in the liquid state below 90 K. Seeding with a crystal helps to initiate freezing. Gallium is one of the four non-radioactive metals (with caesium, rubidium, and mercury) that are known to be liquid at, or near, normal room temperature. Of the four, gallium is the only one that is neither highly reactive (rubidium and caesium) nor highly toxic (mercury) and can therefore be used in metal-in-glass high-temperature thermometers. It is also notable for having one of the largest liquid ranges for a metal, and for having (unlike mercury) a low vapor pressure at high temperatures. Gallium's boiling point, 2673 K, is more than eight times higher than its melting point on the absolute scale, the greatest ratio between melting point and boiling point of any element. Unlike mercury, liquid gallium metal wets glass and skin, along with most other materials (with the exceptions of quartz, graphite, and Teflon), making it mechanically more difficult to handle even though it is substantially less toxic and requires far fewer precautions. Gallium painted onto glass is a brilliant mirror. For this reason as well as the metal contamination and freezing-expansion problems, samples of gallium metal are usually supplied in polyethylene packets within other containers.\nGallium does not crystallize in any of the simple crystal structures. The stable phase under normal conditions is orthorhombic with 8 atoms in the conventional unit cell. Within a unit cell, each atom has only one nearest neighbor (at a distance of 244 pm). The remaining six unit cell neighbors are spaced 27, 30 and 39 pm farther away, and they are grouped in pairs with the same distance. Many stable and metastable phases are found as function of temperature and pressure.\n\nThe bonding between the two nearest neighbors is covalent; hence Ga dimers are seen as the fundamental building blocks of the crystal. This explains the low melting point relative to the neighbor elements, aluminium and indium. This structure is strikingly similar to that of iodine and forms because of interactions between the single 4p electrons of gallium atoms, further away from the nucleus than the 4s electrons and the [Ar]3d core. This phenomenon recurs with mercury with its \"pseudo-noble-gas\" [Xe]4f5d6s electron configuration, which is liquid at room temperature. The 3d electrons do not shield the outer electrons very well from the nucleus and hence the first ionisation energy of gallium is greater than that of aluminium.\n\nThe physical properties of gallium are highly anisotropic, i.e. have different values along the three major crystallographical axes \"a\", \"b\", and \"c\" (see table), producing a significant difference between the linear (α) and volume thermal expansion coefficients. The properties of gallium are strongly temperature-dependent, particularly near the melting point. For example, the coefficient of thermal expansion increases by several hundred percent upon melting.\n\nGallium has 31 known isotopes, ranging in mass number from 56 to 86. Only two isotopes are stable and occur naturally, gallium-69 and gallium-71. Gallium-69 is more abundant: it makes up about 60.1% of natural gallium, while gallium-71 makes up the remaining 39.9%. All the other isotopes are radioactive. The two longest-lived and only commercially important ones are gallium-67 (half-life 3.261 days) and gallium-68 (half-life 67.7 min). Isotopes lighter than gallium-69 usually decay through beta plus decay (positron emission) or electron capture to isotopes of zinc, although the lightest few (with mass numbers 56 through 59) decay through prompt proton emission. Isotopes heavier than gallium-71 decay through beta minus decay (electron emission), possibly with delayed neutron emission, to isotopes of germanium, while gallium-70 can decay through both beta minus decay and electron capture. Gallium-67 is unique among the light isotopes in having only electron capture as a decay mode, as its decay energy is not sufficient to allow positron emission.\n\nGallium is found primarily in the +3 oxidation state. The +1 oxidation state is also found in some compounds, although it is less common than it is for gallium's heavier congeners indium and thallium. For example, the very stable GaCl contains both gallium(I) and gallium(III) and can be formulated as GaGaCl; in contrast, the monochloride is unstable above 0 °C, disproportionating into elemental gallium and gallium(III) chloride. Compounds containing Ga–Ga bonds are true gallium(II) compounds, such as GaS (which can be formulated as Ga(S)) and the dioxan complex GaCl(CHO).\n\nStrong acids dissolve gallium, forming gallium(III) salts such as (gallium sulfate) and (gallium nitrate). Aqueous solutions of gallium(III) salts contain the hydrated gallium ion, . Gallium(III) hydroxide, , may be precipitated from gallium(III) solutions by adding ammonia. Dehydrating at 100 °C produces gallium oxide hydroxide, GaO(OH).\n\nAlkaline hydroxide solutions dissolve gallium, forming \"gallate\" salts (not to be confused with identically-named gallic acid salts) containing the anion. Gallium hydroxide, which is amphoteric, also dissolves in alkali to form gallate salts. Although earlier work suggested as another possible gallate anion, it was not found in later work.\n\nGallium reacts with the chalcogens only at relatively high temperatures. At room temperature, gallium metal is not reactive with air and water because it forms a passive, protective oxide layer. At higher temperatures, however, it reacts with atmospheric oxygen to form gallium(III) oxide, . Reducing with elemental gallium in vacuum at 500 °C to 700 °C yields the dark brown gallium(I) oxide, . is a very strong reducing agent, capable of reducing to . It disproportionates at 800 °C back to gallium and .\n\nGallium(III) sulfide, , has 3 possible crystal modifications. It can be made by the reaction of gallium with hydrogen sulfide () at 950 °C. Alternatively, can be used at 747 °C:\n\nReacting a mixture of alkali metal carbonates and with leads to the formation of \"thiogallates\" containing the anion. Strong acids decompose these salts, releasing in the process. The mercury salt, , can be used as a phosphor.\n\nGallium also forms sulfides in lower oxidation states, such as gallium(II) sulfide and the green gallium(I) sulfide, the latter of which is produced from the former by heating to 1000 °C under a stream of nitrogen.\n\nThe other binary chalcogenides, and , have the zincblende structure. They are all semiconductors but are easily hydrolysed and have limited utility.\n\nGallium reacts with ammonia at 1050 °C to form gallium nitride, GaN. Gallium also forms binary compounds with phosphorus, arsenic, and antimony: gallium phosphide (GaP), gallium arsenide (GaAs), and gallium antimonide (GaSb). These compounds have the same structure as ZnS, and have important semiconducting properties. GaP, GaAs, and GaSb can be synthesized by the direct reaction of gallium with elemental phosphorus, arsenic, or antimony. They exhibit higher electrical conductivity than GaN. GaP can also be synthesized by reacting with phosphorus at low temperatures.\n\nGallium forms ternary nitrides; for example:\n\nSimilar compounds with phosphorus and arsenic are possible: and . These compounds are easily hydrolyzed by dilute acids and water.\n\nGallium(III) oxide reacts with fluorinating agents such as HF or to form gallium(III) fluoride, . It is an ionic compound strongly insoluble in water. However, it dissolves in hydrofluoric acid, in which it forms an adduct with water, . Attempting to dehydrate this adduct forms . The adduct reacts with ammonia to form , which can then be heated to form anhydrous .\n\nGallium trichloride is formed by the reaction of gallium metal with chlorine gas. Unlike the trifluoride, gallium(III) chloride exists as dimeric molecules, , with a melting point of 78 °C. Eqivalent compounds are formed with bromine and iodine, and .\n\nLike the other group 13 trihalides, gallium(III) halides are Lewis acids, reacting as halide acceptors with alkali metal halides to form salts containing anions, where X is a halogen. They also react with alkyl halides to form carbocations and .\n\nWhen heated to a high temperature, gallium(III) halides react with elemental gallium to form the respective gallium(I) halides. For example, reacts with Ga to form :\n\nAt lower temperatures, the equilibrium shifts toward the left and GaCl disproportionates back to elemental gallium and . GaCl can also be produced by reacting Ga with HCl at 950 °C; the product can be condensed as a red solid.\n\nGallium(I) compounds can be stabilized by forming adducts with Lewis acids. For example:\n\nThe so-called \"gallium(II) halides\", , are actually adducts of gallium(I) halides with the respective gallium(III) halides, having the structure . For example:\n\nLike aluminium, gallium also forms a hydride, , known as \"gallane\", which may be produced by reacting lithium gallanate () with gallium(III) chloride at −30 °C:\n\nIn the presence of dimethyl ether as solvent, polymerizes to . If no solvent is used, the dimer (\"digallane\") is formed as a gas. Its structure is similar to diborane, having two hydrogen atoms bridging the two gallium centers, unlike α- in which aluminium has a coordination number of 6.\n\nGallane is unstable above −10 °C, decomposing to elemental gallium and hydrogen.\n\nOrganogallium compounds are of similar reactivity to organoindium compounds. less reactive than organoaluminium compounds, but more reactive than organothallium compounds. Alkylgalliums are monomeric. Lewis acidity decreases in the order Al > Ga > In and as a result organogallium compounds do not form bridged dimers as organoaluminum compounds do. Organogallium compounds are also less reactive than organoaluminum compounds. They do form stable peroxides. These alkylgalliums are liquids at room temperature, having low melting points, and are quite mobile and flammable. Triphenylgallium is monomeric in solution, but its crystals form chain structures due to weak intermolecluar Ga···C interactions.\n\nGallium trichloride is a common starting reagent for the formation of organogallium compounds, such as in carbogallation reactions. Gallium trichloride reacts with lithium cyclopentadienide in diethyl ether to form the trigonal planar gallium cyclopentadienyl complex GaCp. Gallium(I) forms complexes with arene ligands such as hexamethylbenzene. Because this ligand is quite bulky, the structure of the [Ga(η-CMe)] is that of a half-sandwich. Less bulky ligands such as mesitylene allow two ligands to be attached to the central gallium atom in a bent sandwich structure. Benzene is even less bulky and allows the formation of dimers: an example is [Ga(η-CH)] [GaCl]·3CH.\n\nIn 1871, the existence of gallium was first predicted by Russian chemist Dmitri Mendeleev, who named it \"eka-aluminium\" from its position in his periodic table. He also predicted several properties of eka-aluminium that correspond closely to the real properties of gallium, such as its density, melting point, oxide character and bonding in chloride.\n\nMendeleev further predicted that eka-aluminium would be discovered by means of the spectroscope, and that metallic eka-aluminium would dissolve slowly in both acids and alkalis and would not react with air. He also predicted that MO would dissolve in acids to give MX salts, that eka-aluminium salts would form basic salts, that eka-aluminium sulfate should form alums, and that anhydrous MCl should have a greater volatility than ZnCl: all of these predictions turned out to be true.\n\nGallium was discovered using spectroscopy by French chemist Paul Emile Lecoq de Boisbaudran in 1875 from its characteristic spectrum (two violet lines) in a sample of sphalerite. Later that year, Lecoq obtained the free metal by electrolysis of the hydroxide in potassium hydroxide solution. He named the element \"gallia\", from Latin \"Gallia\" meaning Gaul, after his native land of France. It was later claimed that, in one of those multilingual puns so beloved by men of science in the 19th century, he had also named gallium after himself: \"Le coq\" is French for \"the rooster\" and the Latin word for \"rooster\" is \"gallus\". In an 1877 article, Lecoq denied this conjecture. Originally, de Boisbaudran determined the density of gallium as 4.7 g/cm, the only property that failed to match Mendeleev's predictions; Mendeleev then wrote to him and suggested that he should remeasure the density, and de Boisbaudran then obtained the correct value of 5.9 g/cm, that Mendeleev had predicted almost exactly.\n\nFrom its discovery in 1875 until the era of semiconductors, the primary uses of gallium were high-temperature thermometrics and metal alloys with unusual properties of stability or ease of melting (some such being liquid at room temperature). The development of gallium arsenide as a direct band gap semiconductor in the 1960s ushered in the most important stage in the applications of gallium.\n\nGallium does not exist as a free element in the Earth's crust, and the few high-content minerals, such as gallite (CuGaS), are too rare to serve as a primary source. The abundance in the Earth's crust is approximately 16.9 ppm. This is comparable to the crustal abundances of lead, cobalt and niobium. Yet unlike these elements, gallium does not form its own ore deposits with concentrations of > 0.1 wt.% in ore. Rather it occurs at trace concentrations similar to the crustal value in zinc ores, and at somewhat higher values (~ 50 ppm) in aluminium ores, from both of which it is extracted as a by-product. This lack of independent deposits is due to gallium's geochemical behaviour, showing no strong enrichment in the processes relevant to the formation of most ore deposits.\n\nThe United States Geological Survey (USGS) estimates that more than 1 million tons of gallium is contained in known reserves of bauxite and zinc ores. Some coal flue dusts contain small quantities of gallium, typically less than 1% by weight. However, these amounts are not extractable without mining of the host materials (see below). Thus, the availability of gallium is fundamentally determined by the rate at which bauxite, zinc ores (and coal) are extracted.\n\nGallium is produced exclusively as a by-product during the processing of the ores of other metals. Its main source material is bauxite, the chief ore of aluminium, but minor amounts are also extracted from sulfidic zinc ores (sphalerite being the main host mineral). In the past, certain coals were an important source.\n\nDuring the processing of bauxite to alumina in the Bayer process, gallium accumulates in the sodium hydroxide liquor. From this it can be extracted by a variety of methods. The most recent is the use of ion-exchange resin. Achievable extraction efficiencies critically depend on the original concentration in the feed bauxite. At a typical feed concentration of 50 ppm, about 15% of the contained gallium is extractable. The remainder reports to the red mud and aluminium hydroxide streams. Gallium is removed from the ion-exchange resin in solution. Electrolysis then gives gallium metal. For semiconductor use, it is further purified with zone melting or single-crystal extraction from a melt (Czochralski process). Purities of 99.9999% are routinely achieved and commercially available.\n\nIts by-product status means that gallium production is constrained by the amount of bauxite, sulfidic zinc ores (and coal) extracted per year. Therefore, its availability needs to be discussed in terms of supply potential. The supply potential of a by-product is defined as that amount which is economically extractable from its host materials \"per year\" under current market conditions (i.e. technology and price). Reserves and resources are not relevant for by-products, since they \"cannot\" be extracted independently from the main-products. Recent estimates put the supply potential of gallium at a minimum of 2,100 t/yr from bauxite, 85 t/yr from sulfidic zinc ores, and potentially 590 t/yr from coal. These figures are significantly greater than current production (375 t in 2016). Thus, major future increases in the by-product production of gallium will be possible without significant increases in production costs or price. The average gallium price in 2015 was $US317/kg, down from $US688/kg in 2011.\n\nSemiconductor applications dominate the commercial demand for gallium, accounting for 98% of the total. The next major application is for gadolinium gallium garnets.\n\nExtremely high-purity (>99.9999%) gallium is commercially available to serve the semiconductor industry. Gallium arsenide (GaAs) and gallium nitride (GaN) used in electronic components represented about 98% of the gallium consumption in the United States in 2007. About 66% of semiconductor gallium is used in the U.S. in integrated circuits (mostly gallium arsenide), such as the manufacture of ultra-high-speed logic chips and MESFETs for low-noise microwave preamplifiers in cell phones. About 20% of this gallium is used in optoelectronics. Worldwide, gallium arsenide makes up 95% of the annual global gallium consumption.\n\nGallium arsenide is used in a variety of optoelectronic infrared devices. Aluminium gallium arsenide (AlGaAs) is used in high-power infrared laser diodes. The semiconductors gallium nitride and indium gallium nitride are used in blue and violet optoelectronic devices, mostly laser diodes and light-emitting diodes. For example, gallium nitride 405 nm diode lasers are used as a violet light source for higher-density Blu-ray Disc compact data disc drives.\n\nMultijunction photovoltaic cells, developed for satellite power applications, are made by molecular-beam epitaxy or metalorganic vapour-phase epitaxy of thin films of gallium arsenide, indium gallium phosphide, or indium gallium arsenide. The Mars Exploration Rovers and several satellites use triple-junction gallium arsenide on germanium cells. Gallium is also a component in photovoltaic compounds (such as copper indium gallium selenium sulfide Cu(In,Ga)(Se,S)) used in solar panels as a cost-efficient alternative to crystalline silicon.\n\nGallium readily alloys with most metals, and is used as an ingredient in low-melting alloys. The nearly eutectic alloy of gallium, indium, and tin is a room temperature liquid used in medical thermometers. This alloy, with the trade-name \"Galinstan\" (with the \"-stan\" referring to the tin, \"stannum\" in Latin), has a low freezing point of −19 °C (−2.2 °F). It has been suggested that this family of alloys could also be used to cool computer chips in place of water. Gallium alloys have been evaluated as substitutes for mercury dental amalgams, but these materials have yet to see wide acceptance.\n\nBecause gallium wets glass or porcelain, gallium can be used to create brilliant mirrors. When the wetting action of gallium-alloys is not desired (as in Galinstan glass thermometers), the glass must be protected with a transparent layer of gallium(III) oxide.\n\nThe plutonium used in nuclear weapon pits is stabilized in the δ phase and made machinable by alloying with gallium.\n\nAlthough gallium has no natural function in biology, gallium ions interact with processes in the body in a manner similar to iron(III). Because these processes include inflammation, a marker for many disease states, several gallium salts are used (or are in development) as pharmaceuticals and radiopharmaceuticals in medicine. Interest in the anticancer properties of gallium emerged when it was discovered that Ga(III) citrate injected in tumor-bearing animals localized to sites of tumor. Clinical trials have shown gallium nitrate to have antineoplastic activity against non-Hodgkin’s lymphoma and urothelial cancers. A new generation of gallium-ligand complexes such as tris(8-quinolinolato)gallium(III) (KP46)\nand gallium maltolate has emerged. Gallium nitrate (brand name Ganite) has been used as an intravenous pharmaceutical to treat hypercalcemia associated with tumor metastasis to bones. Gallium is thought to interfere with osteoclast function, and the therapy may be effective when other treatments have failed. Gallium maltolate, an oral, highly absorbable form of gallium(III) ion, is an anti-proliferative to pathologically proliferating cells, particularly cancer cells and some bacteria that accept it in place of ferric iron (Fe). Researchers are conducting clinical and preclinical trials on this compound as a potential treatment for a number of cancers, infectious diseases, and inflammatory diseases.\n\nWhen gallium ions are mistakenly taken up in place of iron(III) by bacteria such as \"Pseudomonas\", the ions interfere with respiration, and the bacteria die. This happens because iron is redox-active, allowing the transfer of electrons during respiration, while gallium is redox-inactive.\n\nA complex amine-phenol Ga(III) compound MR045 is selectively toxic to parasites resistant to chloroquine, a common drug against malaria. Both the Ga(III) complex and chloroquine act by inhibiting crystallization of hemozoin, a disposal product formed from the digestion of blood by the parasites.\n\nGallium-67 salts such as gallium citrate and gallium nitrate are used as radiopharmaceutical agents in the nuclear medicine imaging known as gallium scan. The radioactive isotope Ga is used, and the compound or salt of gallium is unimportant. The body handles Ga in many ways as though it were Fe, and the ion is bound (and concentrates) in areas of inflammation, such as infection, and in areas of rapid cell division. This allows such sites to be imaged by nuclear scan techniques.\n\nGallium-68, a positron emitter with a half-life of 68 min, is now used as a diagnostic radionuclide in PET-CT when linked to pharmaceutical preparations such as DOTATOC, a somatostatin analogue used for neuroendocrine tumors investigation, and DOTA-TATE, a newer one, used for neuroendocrine metastasis and lung neuroendocrine cancer, such as certain types of \"microcytoma\". Gallium-68's preparation as a pharmaceutical is chemical, and the radionuclide is extracted by elution from germanium-68, a synthetic radioisotope of germanium, in gallium-68 generators.\n\nGallium is used for neutrino detection. Possibly the largest amount of pure gallium ever collected in a single spot is the Gallium-Germanium Neutrino Telescope used by the SAGE experiment at the Baksan Neutrino Observatory in Russia. This detector contains 55–57 tonnes (~9 cubic metres) of liquid gallium. Another experiment was the GALLEX neutrino detector operated in the early 1990s in an Italian mountain tunnel. The detector contained 12.2 tons of watered gallium-71. Solar neutrinos caused a few atoms of Ga to become radioactive Ge, which were detected. This experiment showed that the solar neutrino flux is 40% less than theory predicted. This deficit was not explained until better solar neutrino detectors and theories were constructed (see SNO).\n\nGallium is also used as a liquid metal ion source for a focused ion beam. For example, a focused gallium-ion beam was used to create the world's smallest book, \"Teeny Ted from Turnip Town\". Another use of gallium is as an additive in glide wax for skis, and other low-friction surface materials.\n\nA well-known practical joke among chemists is to fashion gallium spoons and use them to serve tea to unsuspecting guests, since gallium has a similar appearance to its lighter homolog aluminium. The spoons then melt in the hot tea.\nMetallic gallium is not toxic. However, exposure to gallium halide complexes can result in acute toxicity. The Ga ion of soluble gallium salts tends to form the insoluble hydroxide when injected in large doses; precipitation of this hydroxide resulted in renal toxicity in animals. In lower doses, soluble gallium is tolerated well and does not accumulate as a poison, instead being excreted mostly through urine. Excretion of gallium occurs in two phases: the first phase has a biological half-life of 1 hour, while the second has a biological half-life of 25 hours.\n\n"}
{"id": "7059260", "url": "https://en.wikipedia.org/wiki?curid=7059260", "title": "Genesis Energy Investment", "text": "Genesis Energy Investment\n\nGenesis Energy Investment Company is a solar energy investment company based in Budapest, Hungary, which invests in the emerging photovoltaics market. It is building several identical factories around the world, producing large scale solar panels with high-tech, thin film technology. It is financed by Genesis Capital Management, a technology fund.\n\n"}
{"id": "47720961", "url": "https://en.wikipedia.org/wiki?curid=47720961", "title": "HWCG LLC", "text": "HWCG LLC\n\nHWCG LLC is a not-for-profit consortium of deepwater oil and gas companies. HWCG maintains a comprehensive deepwater well containment response model that can be activated immediately in the event of a US Gulf of Mexico subsea blowout. It comprises oil and gas companies operating in the Gulf and incorporates the consortium’s generic well containment plan. HWCG has a healthy mutual aid component whereby HWCG members will respond and support another member’s incident.\n\nAfter the Deepwater Horizon oil spill, President Obama announced a drilling moratorium on new permits for offshore wells and exploration in the Gulf of Mexico came to a standstill. In response to the suspension, twenty-four deepwater operators came together to establish well containment resources and plans according to the guidelines set forth in BOEMRE’s (BSEE’s) Notice To Lessees No. 2010-N10. These offshore oil and gas companies formed HWCG LLC with the common goal of establishing and maintaining the capability to quickly and comprehensively respond to a subsea blowout.\n\nThe consortium’s response system builds on the equipment proven effective in the containment of the Deepwater Horizon blowout, including the Helix Fast Response System with the Q4000 intervention vessel and Helix Producer 1 from Helix Energy Solutions Group. \n\nHWCG’s core equipment includes two dual-ram capping stacks capable of operating in water depths through 10,000 feet. These capping stacks can effectively shut-in and contain a subsea well. If a flow and capture is required, the system is capable of a process volume of 130,000 barrels of oily fluids per day and 220 million cubic feet of gas per day.\n\nHWCG maintains contracts and operating agreements with over thirty service providers to leverage additional expertise, assistance and equipment. This integrated response solution yielded a tested deployment response time of less than seven days to cap a deepwater well, compared to the nearly 90 days needed to contain the Deepwater Horizon blowout.\n\nHWCG continues to run annual subsea incident response drills and collaborates with members, service sector companies and regulators in order to continually test and improve its response plan.\n\nHWCG currently supports seventeen member companies: Deep Gulf Energy LP, ENI US Operating Company Inc., EnVen Energy Ventures, LLC, Energy Resource Technology GOM, Inc., LLOG Exploration Company, LLC, Marubeni Oil & Gas (USA) Inc., Murphy Exploration & Production Company (USA), Noble Energy Services, Inc., Petrobras USA Inc., Red Willow Offshore, LLC, Repsol Services Company, Ridgewood Energy WCG Member, LLC, Talos ERT, Talos Petroleum LLC, TOTAL E&P USA, INC, Walter Oil & Gas Corporation and W&T Offshore, Inc.\n"}
{"id": "26001349", "url": "https://en.wikipedia.org/wiki?curid=26001349", "title": "Huaneng Yingkou Power Station", "text": "Huaneng Yingkou Power Station\n\nThe Huaneng Yingkou Power Station is a large thermal power station in China, with installed capacity of . As of 2016, the plant is installed with two units, and two units, totalling to . \n\nThe station is fuelled by coal, with an efficiency rate of 330.5 grams consumed for each KWh generated. In 2007 planned capacity was . \n\nNearby Huaneng Yingkou Co-generation Power Plant is a combined heat and power station with installed capacity consisting of two generating units, which commenced operation in December 2009.\n\nAdjacent Yingkou Co-generation Photovoltaic Power Plant is a photovoltaic power station that commenced operation in June 2016.\n\n"}
{"id": "48589334", "url": "https://en.wikipedia.org/wiki?curid=48589334", "title": "Jindo–Jeju HVDC system", "text": "Jindo–Jeju HVDC system\n\nThe Jindo–Jeju HVDC system is a 105 km HVDC submarine cable connection in South Korea between the island of Jindo, close to the Korean Peninsula, and the more distant island of Jeju. The system has a capacity of 400 MW and transmission voltage of ±250 kV and was put into service in 2014. It is the second HVDC link to Jeju Island, after the Haenam–Cheju link completed in the late 1990s (the spelling of the island’s name was changed from Cheju to Jeju in 2000).\n\nThe Jindo–Jeju HVDC system is owned and operated by Korea Electric Power Corporation (KEPCO). The cables were designed and built by LS Cable and System and the converter stations were designed and built by Alstom Grid.\n\nThe scheme is bipolar but unlike the Haenam–Cheju connection, which used a relatively conventional arrangement with two high-voltage cables and a sea return, Jindo–Jeju HVDC system uses metallic return with a total of four cables: three high-voltage cables and one medium-voltage cable. The high-voltage cables use mass-impregnated paper as the insulation material while the medium-voltage cable uses Cross-linked polyethylene (XLPE) insulation.\n\nTwo of the high-voltage cables are normally used as the respective high-voltage conductors for the two converter poles and the medium-voltage cable is normally used as the neutral return conductor, but the third high-voltage cable is capable of being connected in parallel with, or instead of, any of the other three cables, giving a large number of possible operating modes.\n\nThe converter stations use Line-Commutated Converters with a conventional arrangement of a single Twelve-pulse bridge per pole.\n\n"}
{"id": "21305408", "url": "https://en.wikipedia.org/wiki?curid=21305408", "title": "List of glaciers in Mexico", "text": "List of glaciers in Mexico\n\nMexico has about two dozen glaciers, all of which are located on Pico de Orizaba (Citlaltépetl), Popocatépetl and Iztaccíhuatl, the three tallest mountains in the country.\n\n\n"}
{"id": "37920319", "url": "https://en.wikipedia.org/wiki?curid=37920319", "title": "List of spacecraft powered by non-rechargeable batteries", "text": "List of spacecraft powered by non-rechargeable batteries\n\nList of spacecraft powered by non-rechargeable batteries; spacecraft with non-recharged chemical batteries. A select group, but includes famous spacecraft such as \"Sputnik\" and \"Explorer 1\", and the first landers for the Moon, Mars, Venus, Jupiter, and Saturn's moon Titan.\n\nPrimary power comes from a chemical battery, but a secondary system exists. For example, Luna 9 ran out of power after three days.\n\n\n\n"}
{"id": "262465", "url": "https://en.wikipedia.org/wiki?curid=262465", "title": "Mad Max 2", "text": "Mad Max 2\n\nMad Max 2 (originally released in the United States as The Road Warrior and sometimes known as Mad Max 2: The Road Warrior) is a 1981 Australian post-apocalyptic action film directed by George Miller. The film is the second installment in the \"Mad Max\" film series, with Mel Gibson reprising his role as \"Mad\" Max Rockatansky. The film's tale of a community of settlers who moved to defend themselves against a roving band of marauders follows an archetypical \"Western\" frontier movie motif, as does Max's role as a hardened man who rediscovers his humanity when he decides to help the settlers. Filming took place in locations around Broken Hill, in the outback of New South Wales.\n\n\"Mad Max 2\" was released on 24 December 1981, and received ample critical acclaim. Observers praised the visuals and Gibson's role. Noteworthy elements of the film also include cinematographer Dean Semler's widescreen photography of Australia's vast desert landscapes; the sparing use of dialogue throughout the film; costume designer Norma Moriceau's punk mohawked, leather bondage gear-wearing bikers; and its fast-paced, tightly edited and violent battle and chase scenes.\n\nThe film's comic-book post-apocalyptic/punk style popularized the genre in film and fiction writing. It was also a box office success, winning the Best International Film from six nominations at the Saturn Award ceremony, including: Best Director for Miller; Best Actor for Gibson; Best Supporting Actor for Bruce Spence; Best Writing for Miller, Hayes and Hannant; and Best Costume for Norma Moriceau. \"Mad Max 2\" became a cult film, with fan clubs and \"road warrior\"-themed activities continuing into the 21st century, and is now widely considered to be one of the greatest action movies ever made, as well as one of the greatest sequels ever made. The film was preceded by \"Mad Max\" in 1979 and followed by \"Mad Max Beyond Thunderdome\" in 1985 and \"\" in 2015.\n\nTraumatised by the death of his family, Max Rockatansky roams the desert wilderness of a post-apocalyptic Australia in a scarred, black supercharged V-8 Pursuit Special. Scavenging for food and petrol, Max's only companions are an Australian Cattle Dog and a sawed-off shotgun with scarce ammunition. After driving off a gang led by the unhinged biker warrior Wez, and taking petrol from one of their wrecked vehicles, Max finds a nearby gyrocopter and decides to collect its fuel. The gyrocopter is boobytrapped, but Max overpowers the pilot hiding nearby, sparing his life upon being told of a small oil refinery nearby in the wasteland. However, upon arriving, Max finds the compound under siege by the Marauders, a motley gang of racers and motorcyclists of which Wez is a member. The Marauders' leader, a large disfigured man called \"Lord Humungus\", has his gang swarm the complex daily.\n\nBiding his time, Max makes his move when a group of settlers attempt to break out of the compound to find a means to take the fuel tank out of the complex. With the others captured and subjected to torture, rape and death, Max rescues the remaining survivor and offers to get him back to the complex in return for a tank of petrol. The man dies shortly from his wound after Max returns him, and the settlers' leader Papagallo reneges on the deal. The settlers are on the verge of killing Max when the Marauders return and, despite the death of Wez's partner by the metal boomerang of a feral child living within the complex, Humungus offers the settlers safe passage from the territory in exchange for the fuel supply.\n\nMax offers another deal to Papagallo: provide him and the settlers with an abandoned Mack semi-truck found earlier in the film to haul the fuel tanker in exchange for petrol and his freedom. The settlers accept, but keep his car. Max sneaks out with the Feral Kid's help, employing the Gyro Captain's help in reaching the semi. With aerial support, Max drives the semi through the Marauders' encampment into the compound with a livid Humungus refortifying the siege. Though the settlers want Max to escape with them to a beach, Max opts to collect his petrol and leave. However, while attempting to break through the siege, Max is seriously wounded and his car wrecked after being run off the road by Wez in Lord Humungus's nitrous oxide-equipped car. One of Marauders kill Max's dog with a crossbow before Toady's attempt to siphon the fuel from the Pursuit Special's tanks triggers the car self-destruct, which kills both Marauders during the explosion. Max is left for dead, but the Gyro Captain rescues him and flies him back to the compound.\n\nDespite his injuries, Max insists on driving the repaired and now armored truck with the fuel tanker. He leaves the compound, accompanied by the Feral Kid with Papagallo and several of the settlers in armored vehicles to provide protection. Lord Humungus and most of his warriors pursue the tanker, leaving the remaining settlers free to flee the compound in a ramshackle caravan, rigging the compound to explode. After Papagallo and the defenders are killed during the chase, and the Gyro Captain shot down, Max and the Feral Kid find themselves alone against the Marauders as Wez boards the truck to kill the two.\n\nHowever, the semi's head-on collision with Humungus' car kills both him and Wez as the out-of-control truck rolls off the road while the surviving Marauders leave. As the injured Max carries the Feral Kid from the wrecked tanker, he sees not oil, but sand, leaking from the tank, revealing it to be a decoy which allowed the other settlers to escape with the fuel in oil drums hidden inside their vehicles. With Papagallo dead, the Gyro Captain succeeds him as their chief and leads the settlers to the coast, where they establish the \"Great Northern Tribe\". Max remains alone in the desert, once again becoming a drifter while the Feral Kid (as an adult and the Northern Tribe's new leader) is revealed as the narrator, reminiscing about the Road Warrior.\n\n\n\nFollowing the release of \"Mad Max\", director George Miller received a number of offers from Hollywood, including one to direct \"First Blood\". However, Miller instead decided to pursue a rock and roll movie under the working title of \"Roxanne\". After working with writer Terry Hayes on the novelization of \"Mad Max\", Miller and Hayes teamed up to write \"Roxanne\" in Los Angeles but the script was ultimately shelved. Miller then became more intrigued with the idea of returning to the world of \"Mad Max\", as a larger budget would allow him to be more ambitious. \"Making \"Mad Max\" was a very unhappy experience for me,\" said Miller. \"There was strong pressure to make a sequel, and I felt we could do a better job with a second movie.\"\n\nInspired by Joseph Campbell's \"The Hero with a Thousand Faces\" and the work of Carl Jung, Miller recruited Hayes to join the production as a scriptwriter. Brian Hannant also came on board as co-writer and second unit director. Miller says that he was greatly influenced by the films of Akira Kurosawa.\n\nPrincipal photography took place over the course of twelve weeks in the winter of 1981 near Broken Hill. Scenes were shot at the Pinnacles, where the set of the compound was situated. The scene where the Pursuit Special rolls over and explodes was shot at Menindee Road on the Mundi Mundi Plains just outside Broken Hill.\n\nThe original cut of the film was more bloody and violent, but it was cut down heavily by Australian censors. Entire scenes and sequences were deleted completely or edited to receive an \"M\" rating. When it was submitted to the MPAA in the United States, two additional scenes (Wez pulling an arrow out of his arm and a close-up shot of him pulling a boomerang out of his dead boyfriend's head) were shortened. Although there is a version of the film that includes the scenes trimmed down for the MPAA, no version without previous cuts exists.\n\nThe musical score for \"Mad Max 2\" was composed and conducted by Australian composer Brian May, who had previously composed the music for the first film. A soundtrack album was released in 1982 by Varèse Sarabande.\n\nWhen \"Mad Max\" was released in 1980 in the United States, it did not receive a proper release from its distributor, American International Pictures. AIP was in the final stages of a change of ownership after being bought by Filmways, Inc. a year earlier. AIP's problems affected the release of the film and its box office in the US, although \"Mad Max\" proved much more successful when released internationally. Warner Bros. decided to release \"Mad Max 2\" in the United States, but they recognised that the first film was not popular in North America. Although the original \"Mad Max\" was becoming popular through cable channel showings, Warner Bros. decided to change the name of its sequel to \"The Road Warrior\". The advertising for the film, including print ads, trailers, and TV commercials, did not refer to the Max character at all, and all shied away from the fact that the film was a sequel. For the majority of viewers, their first inkling of \"Road Warrior\" being a sequel to \"Mad Max\" was when they saw the black and white, archival footage from the previous film, during the prologue.\n\nThe film was a commercial success, earning $3.7 million in rentals in Australia. As \"The Road Warrior\" in North America, it was a greater success. The film earned $11.3 million in rentals and $23.6 million in grosses. Vestron Video capitalized by releasing \"Mad Max\" on video and subtitling it \"the thrilling predecessor to \"The Road Warrior\".\" Despite the title change, grosses from the US release were on par with other countries. Warner Bros. felt comfortable to keep the title of the third \"Mad Max\" film, \"Mad Max Beyond Thunderdome\", intact for that film's American release.\n\n\"Mad Max 2\" received positive reviews and is regarded by many critics as one of the best films of 1981. The film holds a 98% rating based on 42 reviews on Rotten Tomatoes with and average rating of 8.4/10 and with the consensus, \"\"The Road Warrior\" is everything a bigger-budgeted Mad Max sequel should be: bigger, faster, louder, but definitely not dumber.\" Film critic Roger Ebert of the \"Chicago Sun-Times\" gave the film three-and-a-half stars out of four, praised its \"skillful filmmaking,\" and called it \"a film of pure action, of kinetic energy\", which is \"one of the most relentlessly aggressive movies ever made\". While Ebert pointed out that the film does not develop its \"vision of a violent future world ... with characters and dialogue\", and uses only the \"barest possible bones of a plot\", he praised its action sequences. Ebert called the climactic chase sequence \"unbelievably well-sustained\" and states that the \"special effects and stunts...are spectacular\", creating a \"frightening, sometimes disgusting, and (if the truth be told) exhilarating\" effect.\n\nIn his review for \"The New York Times\", Vincent Canby wrote, \"Never has a film's vision of the post-nuclear-holocaust world seemed quite as desolate and as brutal, or as action-packed and sometimes as funny as in George Miller's apocalyptic \"The Road Warrior\", an extravagant film fantasy that looks like a sadomasochistic comic book come to life\". In his review for \"Newsweek\", Charles Michener praised Mel Gibson's \"easy, unswaggering masculinity\", saying that \"[his] hint of Down Under humor may be quintessentially Australian but is also the stuff of an international male star\".\n\nGary Arnold, in his review for \"The Washington Post\", wrote, \"While he seems to let triumph slip out of his grasp, Miller is still a prodigious talent, capable of a scenic and emotional amplitude that recalls the most stirring attributes in great action directors like Kurosawa, Peckinpah and Leone\". Pauline Kael called \"Mad Max 2\" a \"mutant\" film that was \"...sprung from virtually all action genres\", creating \"...one continuous spurt of energy\" by using \"jangly, fast editing\". However, Kael criticized director George Miller's \"attempt to tap into the universal concept of the hero\", stating that this attempt \"makes the film joyless\", \"sappy\", and \"sentimental\".\n\nThe film's depiction of a post-apocalyptic future was widely copied by other filmmakers and in science fiction novels, to the point that its gritty \"junkyard society of the future look...is almost taken for granted in the modern science-fiction action film.\" \"The Encyclopedia of Science Fiction\" says that \"Mad Max 2\", \"with all its comic-strip energy and vividness...is exploitation cinema at its most inventive.\"\n\nRichard Scheib called \"Mad Max 2\" \"one of the few occasions where a sequel makes a dramatic improvement in quality over its predecessor.\" He said that the film is a \"kinetic comic-book of a film,\" an \"exhilarating non-stop rollercoaster ride of a film that contains some of the most exciting stunts and car crashes ever put on screen.\" Scheib stated that the film transforms the \"post-holocaust landscape into the equivalent of a Western frontier,\" such that \"Mel Gibson's Max could just as easily be Clint Eastwood's tight-lipped Man With No Name\" helping \"decent frightened folk\" from the \"marauding Redskins\".\n\nThe film received much recognition from the Academy of Science Fiction, Fantasy & Horror Films. It won the Saturn Award for Best International Film. It received additional nominations for Best Director, Best Writing, and Best Costume Design. Mel Gibson and Bruce Spence received nods for Best Actor and Best Supporting Actor, respectively. George Miller won the Grand Prize at the Avoriaz Fantastic Film Festival. \"Mad Max 2\" was also nominated for the Hugo Award for Best Dramatic Presentation and was awarded the Los Angeles Film Critics Association award for Best Foreign Film. The film was also recognised by the Australian Film Institute, winning awards for best direction, costume design, editing, production design and sound. It received additional nominations for the cinematography and musical score. Despite receiving the most nominations and wins, it was not nominated for Best Film.\n\nThe \"Mad Max\" series of films, with their emphasis on dystopian, apocalyptic, and post-apocalyptic themes and imagery, have inspired some artists to recreate the look and feel of some aspects of the series in their work. As well, fan clubs and \"road warrior\"-themed activities continue into the 21st century. In 2008, \"Mad Max 2\" was selected by \"Empire\" magazine as one of \"The 500 Greatest Movies of All Time\". Similarly, \"The New York Times\" placed the film on its \"Best 1000 Movies Ever\" list. \"Entertainment Weekly\" ranked \"Mad Max 2\" 93rd on their 100 Greatest Movies of All Time list in 1999, 41st on their updated All-Time 100 Greatest Films in 2013 list, and the character Mad Max as 11th on their list of \"The All Time Coolest Heroes in Pop Culture\". In 2016, James Charisma of \"Playboy\" ranked the film #11 on a list of \"15 Sequels That Are Way Better Than The Originals\".\n\nThe film has a permanent legacy in the small town of Silverton, which is 25 kilometres from Broken Hill in New South Wales, Australia. A museum dedicated to \"Mad Max 2\" was established in 2010 by Adrian and Linda Bennett, who developed the museum after moving to Silverton and building a collection of \"Mad Max\" props and memorabilia.\n\n\n"}
{"id": "1666522", "url": "https://en.wikipedia.org/wiki?curid=1666522", "title": "Madden–Julian oscillation", "text": "Madden–Julian oscillation\n\nThe Madden–Julian oscillation (MJO) is the largest element of the intraseasonal (30- to 90-day) variability in the tropical atmosphere. It was discovered in 1971 by Roland Madden and Paul Julian of the American National Center for Atmospheric Research (NCAR). It is a large-scale coupling between atmospheric circulation and tropical deep convection. Unlike a standing pattern like the El Niño Southern Oscillation (ENSO), the Madden–Julian oscillation is a traveling pattern that propagates eastward at approximately 4 to 8 m/s (14 to 29 km/h, 9 to 18 mph), through the atmosphere above the warm parts of the Indian and Pacific oceans. This overall circulation pattern manifests itself most clearly as anomalous rainfall.\n\nThe Madden–Julian oscillation is characterized by an eastward progression of large regions of both enhanced and suppressed tropical rainfall, observed mainly over the Indian and Pacific Ocean. The anomalous rainfall is usually first evident over the western Indian Ocean, and remains evident as it propagates over the very warm ocean waters of the western and central tropical Pacific. This pattern of tropical rainfall then generally becomes nondescript as it moves over the cooler ocean waters of the eastern Pacific (except over the region of warmer water off the west coast of Central America) but occasionally reappears at low amplitude over the tropical Atlantic and higher amplitude over the Indian Ocean. The wet phase of enhanced convection and precipitation is followed by a dry phase where thunderstorm activity is suppressed. Each cycle lasts approximately 30–60 days. Because of this pattern, the Madden–Julian oscillation is also known as the 30- to 60-day oscillation, 30- to 60-day wave, or intraseasonal oscillation.\n\nDistinct patterns of lower-level and upper-level atmospheric circulation anomalies accompany the MJO-related pattern of enhanced or decreased tropical rainfall across the tropics. These circulation features extend around the globe and are not confined to only the eastern hemisphere. The Madden–Julian oscillation moves eastward at between 4 m/s (14 km/h, 9 mph) and 8 m/s (29 km/h, 18 mph) across the tropics, crossing the Earth's tropics in 30 to 60 days—with the active phase of the MJO tracked by the degree of outgoing long wave radiation, which is measured by infrared-sensing geostationary weather satellites. The lower the amount of outgoing long wave radiation, the stronger the thunderstorm complexes, or convection, is within that region.\n\nEnhanced surface (upper level) westerly winds occur near the west (east) side of the active convection. Ocean currents, up to in depth from the ocean surface, follow in phase with the east-wind component of the surface winds. In advance, or to the east, of the MJO enhanced activity, winds aloft are westerly. In its wake, or to the west of the enhanced rainfall area, winds aloft are easterly. These wind changes aloft are due to the divergence present over the active thunderstorms during the enhanced phase. Its direct influence can be tracked poleward as far as 30 degrees latitude from the equator in both northern and southern hemispheres, propagating outward from its origin near the equator at around 1 degree latitude, or , per day.\n\nThe MJO's movement around the globe can occasionally slow or stall during the summer and early autumn, leading to consistently enhanced rainfall for one side of the globe and consistently depressed rainfall of the other side. This can also happen early in the year. The MJO can also go quiet for a period of time, which leads to non-anomalous storm activity for each region of the globe.\n\nDuring the Northern Hemisphere summer season the MJO-related effects on the Indian and West African summer monsoon are well documented. MJO-related effects on the North American summer monsoon also occur, though they are relatively weaker. MJO-related impacts on the North American summer precipitation patterns are strongly linked to meridional (i.e. north–south) adjustments of the precipitation pattern in the eastern tropical Pacific. A strong relationship between the leading mode of intraseasonal variability of the North American Monsoon System, the MJO and the points of origin of tropical cyclones is also present.\n\nA period of warming sea surface temperatures are found five to ten days prior to a strengthening of MJO-related precipitation across southern Asia. A break in the Asian monsoon, normally during the month of July, has been attributed to the Madden–Julian oscillation, after its enhanced phase moves off to the east of the region into the open tropical Pacific Ocean.\n\nTropical cyclones occur throughout the boreal warm season (typically May–November) in both the north Pacific and the north Atlantic basins—but any given year has periods of enhanced or suppressed activity within the season. Evidence suggests that the Madden–Julian oscillation modulates this activity (particularly for the strongest storms) by providing a large-scale environment that is favorable (or unfavorable) for development. MJO-related descending motion is not favorable for tropical storm development. However, MJO-related ascending motion is a favorable pattern for thunderstorm formation within the tropics, which is quite favorable for tropical storm development. As the MJO progresses eastward, the favored region for tropical cyclone activity also shifts eastward from the western Pacific to the eastern Pacific and finally to the Atlantic basin.\n\nAn inverse relationship exists between tropical cyclone activity in the western north Pacific basin and the north Atlantic basin, however. When one basin is active, the other is normally quiet, and vice versa. The main reason for this appears to be the phase of the MJO, which is normally in opposite modes between the two basins at any given time. While this relationship appears robust, the MJO is one of many factors that contribute to the development of tropical cyclones. For example, sea surface temperatures must be sufficiently warm and vertical wind shear must be sufficiently weak for tropical disturbances to form and persist. However, the MJO also influences these conditions that facilitate or suppress tropical cyclone formation. The MJO is monitored routinely by both the USA National Hurricane Center and the USA Climate Prediction Center during the Atlantic hurricane (tropical cyclone) season to aid in anticipating periods of relative activity or inactivity.\n\nThere is strong year-to-year (interannual) variability in Madden–Julian oscillation activity, with long periods of strong activity followed by periods in which the oscillation is weak or absent. This interannual variability of the MJO is partly linked to the El Niño-Southern Oscillation (ENSO) cycle. In the Pacific, strong MJO activity is often observed 6 – 12 months prior to the onset of an El Niño episode, but is virtually absent during the maxima of some El Niño episodes, while MJO activity is typically greater during a La Niña episode. Strong events in the Madden–Julian oscillation over a series of months in the western Pacific can speed the development of an El Niño or La Niña but usually do not in themselves lead to the onset of a warm or cold ENSO event. However, observations suggest that the 1982-1983 El Niño developed rapidly during July 1982 in direct response to a Kelvin wave triggered by an MJO event during late May. Further, changes in the structure of the MJO with the seasonal cycle and ENSO might facilitate more substantial impacts of the MJO on ENSO. For example, the surface westerly winds associated with active MJO convection are stronger during advancement toward El Niño and the surface easterly winds associated with the suppressed convective phase are stronger during advancement toward La Nina. Globally, the inter annual variability of the MJO is most determined by atmospheric internal dynamics, rather than surface conditions.\n\nThe strongest impacts of intraseasonal variability on the United States occur during the winter months over the western U.S. During the winter this region receives the bulk of its annual precipitation. Storms in this region can last for several days or more and are often accompanied by persistent atmospheric circulation features. Of particular concern are extreme precipitation events linked to flooding. Strong evidence suggests a link between weather and climate in this region from studies that have related the El Niño Southern Oscillation to regional precipitation variability. In the tropical Pacific, winters with weak-to-moderate cold, or La Nina, episodes or ENSO-neutral conditions are often characterized by enhanced 30- to 60-day Madden–Julian oscillation activity. A recent example is the winter of 1996–97, which featured heavy flooding in California and in the Pacific Northwest (estimated damage costs of $2.0–3.0 billion at the time of the event) and a very active MJO. Such winters are also characterized by relatively small sea surface temperature anomalies in the tropical Pacific compared to stronger warm and cold episodes. In these winters, there is a stronger link between the MJO events and extreme west coast precipitation events.\n\nThe typical scenario linking the pattern of tropical rainfall associated with the MJO to extreme precipitation events in the Pacific Northwest features a progressive (i.e. eastward moving) circulation pattern in the tropics and a retrograding (i.e. westward moving) circulation pattern in the mid latitudes of the North Pacific. Typical wintertime weather anomalies preceding heavy precipitation events in the Pacific Northwest are as follows:\n\n\nThroughout this evolution, retrogression of the large-scale atmospheric circulation features is observed in the eastern Pacific–North American sector. Many of these events are characterized by the progression of the heaviest precipitation from south to north along the Pacific Northwest coast over a period of several days to more than one week. However, it is important to differentiate the individual synoptic-scale storms, which generally move west to east, from the overall large-scale pattern, which exhibits retrogression.\n\nA coherent simultaneous relationship exists between the longitudinal position of maximum MJO-related rainfall and the location of extreme west coast precipitation events. Extreme events in the Pacific Northwest are accompanied by enhanced precipitation over the western tropical Pacific and the region of Southeast Asia called by meteorologists the Maritime Continent, with suppressed precipitation over the Indian Ocean and the central Pacific. As the region of interest shifts from the Pacific Northwest to California, the region of enhanced tropical precipitation shifts further to the east. For example, extreme rainfall events in southern California are typically accompanied by enhanced precipitation near 170°E. However, it is important to note that the overall link between the MJO and extreme west coast precipitation events weakens as the region of interest shifts southward along the west coast of the United States.\n\nThere is case-to-case variability in the amplitude and longitudinal extent of the MJO-related precipitation, so this should be viewed as a general relationship only.\n\n"}
{"id": "414021", "url": "https://en.wikipedia.org/wiki?curid=414021", "title": "Maritime Jewel", "text": "Maritime Jewel\n\nMaritime Jewel was a double-hulled oil tanker launched in 1999 and completed in 2000. Entering service that year, the ship was known as MV \"Limburg\" unti 2003. The ship carried crude oil between ports in Iran and Malaysia. In 2002 \"Limburg\" was attacked by suicide bombers, causing roughly to leak into the Gulf of Aden. One crew member was killed and twelve more wounded in the attack. Four days after the attack, the tanker was towed to Dubai where she was repaired and renamed \"Maritime Jewel\". \"Maritime Jewel\" was broken up for scrap at Chittagong, Bangladesh on 15 May 2018.\n\nOrdered as \"Limburg\" the vessel was long overall and between perpendiculars with a beam of . The ship's gross tonnage (GT) was 157,833 tons, with a deadweight tonnage (DWT) of 299,364 tons and a net tonnage (NT) of 108,708 tons. The ship was powered by a diesel engine driving one shaft giving the vessel a maximum speed of . \n\n\"Limburg\"s keel was laid down on 24 May 1999 and the ship was launched on 28 August 1999. \"Limburg\" was completed on 5 January 2000 and entered service that year.\n\nOn 6 October 2002, \"Limburg\" was carrying of crude oil from Iran to Malaysia, and was in the Gulf of Aden off Yemen to pick up another load of oil. She was registered under a French flag and had been chartered by the Malaysian petrol firm Petronas. While she was some distance offshore, suicide bombers rammed an explosives-laden dinghy into the starboard side of the tanker. Upon detonation the vessel caught fire and approximately of oil leaked into the Gulf of Aden. Although Yemeni officials initially claimed that the explosion was caused by an accident, later investigations found traces of TNT on the damaged ship.\n\nOne crew member was killed, and twelve other crew members were injured. The fire was extinguished, and four days later \"Limburg\" was towed to Dubai, United Arab Emirates. The ship was renamed \"Maritime Jewel\", bought by Tanker Pacific, and repaired at Dubai Drydocks from March to August 2003. The attack caused the short-term collapse of international shipping in the Gulf of Aden and as a result, cost Yemen $3.8 million a month in port revenues.\n\nAl Qaeda claimed responsibility for the attack on the Jehad.net website, which has since been shut down. Abd al-Rahim al-Nashiri, who allegedly also planned the USS \"Cole\" bombing, was thought to have been the mastermind of the attack. Osama bin Laden issued a statement, which read:\n\nOn 3 February 2006, Fawaz Yahya al-Rabeiee, who had been sentenced to death for the \"Limburg\" attack, and 22 other suspected or convicted Al-Qaeda members escaped from jail in Yemen. Among them was Jamal al-Badawi, who masterminded the USS \"Cole\" bombing of 12 October 2000. Of the 23 escapees, 13 had been convicted of the \"Cole\" and \"Limburg\" bombings. On 1 October 2006, al-Rabeiee and Mohammed Daylami were shot and killed by Yemeni security forces during raids on two buildings in the capital Sana'a. One of al-Rabeiee's accomplices was also arrested during the raids. In February 2014 Ahmed al-Darbi pleaded guilty before the Guantanamo military commission to helping plan several maritime terrorist attacks including the \"Limburg\" attack. By the time of the attack, al-Darbi was already detained at Guantanamo.\n\n\"Maritime Jewel\" was broken up for scrap at Chittagong, Bangladesh on 1 May 2018.\n\n"}
{"id": "167364", "url": "https://en.wikipedia.org/wiki?curid=167364", "title": "Millstone", "text": "Millstone\n\nMillstones or mill stones are stones used in gristmills, for grinding wheat or other grains.\n\nMillstones come in pairs. The base or \"bedstone\" is stationary. Above the bedstone is the turning \"runner stone\" which actually does the grinding. The runner stone spins above the stationary bedstone creating the \"scissoring\" or grinding action of the stones. A runner stone is generally slightly concave, while the bedstone is slightly convex. This helps to channel the ground flour to the outer edges of the stones where it can be gathered up.\n\nThe runner stone is supported by a cross-shaped metal piece (rind or rynd) fixed to a \"mace head\" topping the main shaft or spindle leading to the driving mechanism of the mill (wind, water (including tide) or other means).\n\nNeolithic and Upper Paleolithic people used millstones to grind grains, nuts, rhizomes and other vegetable food products for consumption. These implements are often called grinding stones. They used either saddle stones or rotary querns turned by hand. Such devices were also used to grind pigments and metal ores prior to smelting.\n\nIn India, grinding stones (\"Chakki\") were used to grind grains and spices. These consist of a stationary stone cylinder upon which a smaller stone cylinder rotates. Smaller ones, for household use, were operated by two people. Larger ones, for community or commercial use, used livestock to rotate the upper cylinder.\n\nThe type of stone most suitable for making millstones is a siliceous rock called burrstone (or buhrstone), an open-textured, porous but tough, fine-grained sandstone, or a silicified, fossiliferous limestone. In some sandstones, the cement is calcareous.\n\nMillstones used in Britain were commonly of two types:\n\n\nIn Europe, a third type of millstone was used. These were uncommon in Britain, but not unknown:\n\n\nThe surface of a millstone is divided by deep grooves called \"furrows\" into separate flat areas called \"lands\". Spreading away from the furrows are smaller grooves called \"feathering\" or \"cracking\". The grooves provide a cutting edge and help to channel the ground flour out from the stones.\n\nThe furrows and lands are arranged in repeating patterns called \"harps\". A typical millstone will have six, eight or ten harps. The pattern of harps is repeated on the face of each stone, when they are laid face to face the patterns mesh in a kind of \"scissoring\" motion creating the cutting or grinding function of the stones. When in regular use stones need to be \"dressed\" periodically, that is, re-cut to keep the cutting surfaces sharp.\n\nMillstones need to be evenly balanced, and achieving the correct separation of the stones is crucial to producing good quality flour. The experienced miller will be able to adjust their separation very accurately.\n\nGrain is fed by gravity from the hopper into the feed-shoe. The shoe is agitated by a shoe handle running against an agitator (\"damsel\") on the stone \"spindle\", the shaft powering the runner stone. This mechanism regulates the feed of grain to the millstones by making the feed dependent on the speed of the runner stone. From the feed shoe the grain falls through the \"eye\", the central hole, of the runner stone and is taken between the runner and the bed stone to be ground. The flour exits from between the stones from the side. The stone casing prevents the flour from falling on the floor, instead it is taken to the \"meal spout\" from where it can be bagged or processed further. \n\nThe runner stone is supported by the rind, a cross-shaped metal piece, on the spindle. The spindle is carried by the \"tentering gear\", a set of beams forming a lever system, or a screw jack, with which the runner stone can be lifted or lowered slightly and the gap between the stones adjusted. The weight of the runner stone is significant (up to ) and it is this weight combined with the cutting action from the porous stone and the patterning that causes the milling process.\n\nMillstones for some water-powered mills (such as Peirce Mill) spin at about 125 rpm.\n\nEspecially in the case of wind-powered mills the turning speed can be irregular. Higher speed means more grain is fed to the stones by the feed-shoe, and grain exits the stones more quickly because of their faster turning speed. The miller has to reduce the gap between the stones so more weight of the runner presses down on the grain and the grinding action is increased to prevent the grain being ground too coarsely. It has the added benefit of increasing the load on the mill and so slowing it down. In the reverse case the miller may have to raise the runner stone if the grain is milled too thoroughly making it unsuitable for baking. In any case the stones should never touch during milling as this would cause them to wear down rapidly. The process of lowering and raising the runner stone is called tentering and lightering. In many windmills it is automated by adding a centrifugal governor to the tentering gear.\nDepending on the type of grain to be milled and the power available the miller may adjust the feed of grain to stones beforehand by changing the amount of agitation of the feed-shoe or adjusting the size of the hopper outlet.\nMilling by millstones is a one-step process in contrast with roller mills in modern mass production where milling takes place in many steps. It produces wholemeal flour which can be turned into white flour by sifting to remove the bran.\n\nAs an old item and symbol for industry, the millstone also has found its place as a charge in heraldry.\n\n\n"}
{"id": "30944615", "url": "https://en.wikipedia.org/wiki?curid=30944615", "title": "Minor tetra", "text": "Minor tetra\n\nThe minor tetra (\"Hyphessobrycon minor\") is a small fish from the Essequibo River in Guyana in South America, closely resembling its relative, the serpae tetra, from the Amazon and Paraguay. These two very similar species are separated geographically, so they would not interbreed.\n\n"}
{"id": "2906020", "url": "https://en.wikipedia.org/wiki?curid=2906020", "title": "Montan wax", "text": "Montan wax\n\nMontan wax, also known as lignite wax or OP wax, is a hard wax obtained by solvent extraction of certain types of lignite or brown coal. Commercially viable deposits exist in only a few locations, including Amsdorf, Germany, and in the Ione Basin near Ione, California. High-graded lignite wax are also found in Yunnan and Jilin, China. \n\nIts color ranges from dark brown to light yellow when crude, or white when refined. Its composition is non-glyceride long-chain (C–C) carboxylic acid esters (62–68 weight %), free long-chain organic acids (22–26%), long-chain alcohols, ketones, and hydrocarbons (7–15%), and resins; it is in effect a fossilized plant wax. Its melting range is 82–95 °C.\n\nIt is used for making car and shoe polishes, paints, and phonograph records, and as lubricant for molding paper and plastics. About a third of total world production is used in car polish. Formerly, its main use was making carbon paper. Unrefined montan wax contains asphalt and resins, which can be removed by refining. Montan wax in polishes improves scuff resistance, increases water repellence, and imparts high gloss.\n\n"}
{"id": "41640192", "url": "https://en.wikipedia.org/wiki?curid=41640192", "title": "Moragahakanda Dam", "text": "Moragahakanda Dam\n\nThe Moragahakanda Dam (), officially as Kulasinghe Reservoir, is a large gravity dam, and the main component of the larger and more complex Moragahakanda — Kalu Ganga Project, currently under construction across the Amban River at Elahera, in the Matale District of Sri Lanka. Construction began on . The maiden waters of the dam was released in January 2017.\nMorgahakanda/Kaluganga project is the last of the Great Mahaveli project\n\nThe larger combined project involves the construction of the Moragahakanda Dam and Reservoir, along with the separate Kalu Ganga Dam and Reservoir, for irrigation and power generation purposes. Both these sites would be located approximately apart.\n\nThe total development cost for both sites totals to approximately (approximately ) and is being carried out by SMEC Holdings and Sinohydro.\n\nA granite Buddha statue built opposite the Moragahakanda reservoir was unveiled on 23 July 2018.\n\nThe original Moragahakanda reservoir was first constructed by King Wasaba in 111 AD.\n\nAccording to the Mahaweli Master Plan of 1968, the development of Mahaweli was divided to three projects named A, B and C out of which the last 'C' project was the Moragahakanda Multi-Purpose Reservoir. In 1977 the project was modified and the Accelerated Mahaweli Scheme(AMS) started and was completed in 6 years. However Moragahakanda was not in the AMS. The J.R. Jayewardene Government would later secure funding for the project from Japan but communal violence delayed the project. The project finally commenced in January 2007 by President Mahinda_Rajapaksa and Construction of the dam was completed in 2018.\n\nThe Moragahakanda Dam, will be a high gravity dam. The dam will create the Moragahakanda Reservoir, which will have an active storage capacity of of water, at a surface elevation of .\n\nTwo additional embankment saddle dams will also be built to contain the Moragahakanda Reservoir. The reservoir of the Kalu Ganga Dam will be linked via tunnel.\n\nWater from both, the Moragahakanda and Kalu Ganga reservoirs, will be primarily used to support agricultural needs to an area of at least . This will increase rice production by 81% or , amounting to an estimated monetary benefit of , annually.\n\nThe reservoirs would also create a source of inland fishing, generating approximately or the monetary equivalent of , annually.\n\nAlong with the reservoir of the Kalu Ganga Dam, an increase of of potable and industrial water supply could be ensured by 2032, to regions including Matale, Anuradhapura, Trincomalee, and Polonnaruwa.\n\nWater from the Moragahakanda Reservoir will be used to power the Moragahakanda Hydroelectric Power Station, also currently under construction. The substitution of this hydropower with traditional fossil fuel power generation is estimated to save up to annually.\n\nConstruction of the power station costs , with an .\n\nThe construction of the dam and reservoir also required the construction of multiple access roads and rerouting of existing main roads, as well as the construction of the long Moragahakanda Bridge costing .\nOn 23 July 2018, under the patronage of president Maithreepala Sirisena, the reservoir has been officially named as Kulasinghe Reservoir, in memory of late Dr. A.N.S Kulasinghe. Deshabandu Dr. A.N.S Kulasinghe was a Sri Lankan Civil Engineer who served in several projects throughout the country.\n\n\n"}
{"id": "20285842", "url": "https://en.wikipedia.org/wiki?curid=20285842", "title": "Mountaintop Removal (film)", "text": "Mountaintop Removal (film)\n\nMountaintop Removal is a 2007 documentary film directed by Michael O'Connell. The film explores how mountaintop removal mining in West Virginia has affected local communities. Filmed over a two-year period, \"Mountain Top Removal\" features community advocates, such as Ed Wiley, Larry Gibson, Julia Bonds, Maria Gunnoe, and Mountain Justice Summer volunteers, in their efforts to oppose the destruction of Southern Appalachia's natural landscape. The film includes commentary from Jeff Goodell, author of \"\", geologists Dr. William Schlesinger and Dr. Peter Taft, and also Bill Raney, President of the West Virginia Coal Association. The film won the \"Reel Current Award\" (presented by Al Gore) at the 2008 Nashville Film Festival. \"Mountaintop Removal\" also received a Jury award at the 2008 Wild and Scenic Film Festival, Audience award at the 2008 Woods Hole Film Festival and was screened at The Lincoln Center on Earth Day April 22, 2008. The film is currently being distributed nationwide on PBS through NETA. The film's soundtrack includes music by Jim Lauderdale, Donna the Buffalo, John Specker and Sarah Hawker.\n\n\n"}
{"id": "241033", "url": "https://en.wikipedia.org/wiki?curid=241033", "title": "Muon neutrino", "text": "Muon neutrino\n\nThe muon neutrino is a lepton, an elementary subatomic particle which has the symbol and no net electric charge. Together with the muon it forms the second generation of leptons, hence the name muon neutrino. It was first hypothesized in the early 1940s by several people, and was discovered in 1962 by Leon Lederman, Melvin Schwartz and Jack Steinberger. The discovery was rewarded with the 1988 Nobel Prize in Physics.\n\nIn 1962 Leon M. Lederman, Melvin Schwartz and Jack Steinberger established by performing an experiment at the Brookhaven National Laboratory that more than one type of neutrino exists by first detecting interactions of the muon neutrino (already hypothesised with the name \"neutretto\"), which earned them the 1988 Nobel Prize.\n\nIn September 2011 OPERA researchers reported that muon neutrinos were apparently traveling at faster than light speed. This result was confirmed again in a second experiment in November 2011. These results have been viewed skeptically by the scientific community at large, and more experiments have/are investigating the phenomenon. In March 2012 the ICARUS team published results directly contradicting the results of OPERA.\n\nLater, in July 2012, the apparent anomalous super-luminous propagation of neutrinos was traced to a faulty element of the fibre optic timing system in Gran-Sasso. After it was corrected the neutrinos appeared to travel with the speed of light within the errors of the experiment.\n\n\n"}
{"id": "47047758", "url": "https://en.wikipedia.org/wiki?curid=47047758", "title": "Natural Forest Standard", "text": "Natural Forest Standard\n\nThe Natural Forest Standard (NFS) is a voluntary carbon standard designed specifically for medium- to large-scale REDD+ projects. The standard places equal emphasis on the combined carbon, social and biodiversity benefits of a project and requires a holistic approach to ensure compliance with the standards requirements and to achieve certification. The NFS applies a standardised risk-based approach to carbon quantification for consistent and comparable baseline calculations and aims to link local actions into national frameworks for reducing the loss of natural forests.\n\nThe NFS excludes commercial resource extraction and focuses on promoting the conservation of natural forests and the biodiversity and social values within them. The NFS requires projects to ensure no net loss of biodiversity and to establish an appropriate benefit distribution mechanism to deliver social benefits to communities within the project area.\nThe NFS demands annual verification by independent third-party carbon auditors using the ISO14064-3 and ISO 14065 frameworks. The resulting certificates for fully verified projects are issued as Natural Capital Credits.\n\nThe NFS was developed in 2011 by Ecosystem Certification Organisation Ltd (ECO), a UK-based not-for-profit organisation, and Ecometrica, the sustainability and earth observation software company based in Edinburgh. The development process included engaging independent expert reviewers for comment and contribution to the standard requirements and methodology. The standard documentation was open for public consultation from 8 August to 12 October 2012 and again from 7 May to 31 July 2013.\n\nNatural Capital Credits (NCCs) are the carbon units generated by NFS projects and represent the combination of net positive environmental impacts achieved by the project. The carbon benefits are quantified using the programmatic risk-based methodology; as such NCCs are denoted in tonnes of CO2e, however the term Natural Capital Credit more accurately reflects the combined values and benefits of the all-encompassing approach of the NFS.\n\nThe methodology adopted by the NFS is based on a standardised risk-based approach and is suitable for medium- to large-scale project application. The methodology NFS AM001, does not involve predicting land use changes in specific places at specific times, but applies a risk-based approach to baseline quantification which allows for a programmatic approach to reducing emissions. This allows efficient, valid and comparable results to be produced akin to performance benchmarking, where projects within a given region can use a consistent set of baseline data and accounting methods which provides a standardised approach to quantification of carbon benefits and is based on forest at risk and not a percentage or absolute rate of loss.\n\nThe methodology allows a combination of remote sensing and ground-based data as monitoring sources for monitoring the emissions from the project areas, with emphasis placed on satellite monitoring, such as PRODES for application in Amazonia.\n\nThe NFS requires that projects are independently, third-party validated and verified using ISO 14064-3 and ISO 14065 frameworks, carried out by industry-recognised, specialist VVB organisations. Projects achieve certification following successful completion of this verification process, and upon confirmation of the carbon assertions by the VVB, in compliance with the standard’s requirements.\n\nThe NFS requires project developers to use the Normative Biodiversity Metric to assess the biodiversity within a project area. The Normative Biodiversity Metric (NBM) is a practical method of assessing the biodiversity value of a given area. The NBM is similar to the concepts of habitat hectares and mean species abundance.\n"}
{"id": "56114285", "url": "https://en.wikipedia.org/wiki?curid=56114285", "title": "Ndugutu Hydroelectric Power Station", "text": "Ndugutu Hydroelectric Power Station\n\nNdugutu Hydroelectric Power Station, also Ndugutu Power Station, is a proposed mini-hydropower station in the Western Region of Uganda.\n\nThe power station would be located on the \"Ndugutu River\", just outside Rwenzori National Park, in Bundibugyo District, in Uganda's Western Region, approximately , by road, southwest of the town of Bundibugyo, the nearest urban center and the location of the district headquarters. This location is in close proximity of the Sindila Hydroelectric Power Station, which is owned by the same developer.\n\nNdugutu HEPS is a run-of-river mini-hydro power plant whose planned maximum installed capacity is 4.8 MW. The project is owned by KMR East Africa Company (also Ndugutu Power Company Uganda Limited), the project developers. The construction of this power station was budgeted at US$15 million, with US$3.2 million in GetFit concessions.\n\nThe project received approval for GetFit support in June 2015. Financial close was reached in 2016. Construction was expected to start during 2017, with completion expected during the fourth quarter of 2018.\n\n\n"}
{"id": "12850203", "url": "https://en.wikipedia.org/wiki?curid=12850203", "title": "Nordex", "text": "Nordex\n\nNordex SE is a European company that designs, sells and manufactures wind turbines. The company's headquarters is located in the German city of Rostock while management is situated in Hamburg. Production takes place in Rostock as well as in China and for a brief time in Jonesboro, Arkansas. The company was founded in 1985 in Give, Denmark. Since then the company steadily grew. In 1995 Nordex was the first company to mass-produce a 1 MW turbine booster\n\nCurrently Nordex manufactures two platforms of wind turbines, rated at 2.4 and 3.3 MW.\n\nIn Europe, Africa and North America Nordex manufactures and sells the Gamma series, a product family comprising the N90/2500, the N100/2500 and the N117/2400. The N90/2500 is a turbine being developed for strong winds. The N100/2500 consists of two versions, Highspeed and Lowspeed, the first one for rather windy locations, the second for medium wind conditions. The N117/2400 was designed especially for low-wind regions (IEC 3). The hub height of the 2.4-2.5 MW windturbines reaches from 65 meters for the N90/2500 to 141 meters for the low wind version of the N117/2400.\n\nIn 2013 Nordex launched the Delta-Class-Series, entering series production in January 2014 with prototypes installed in mid-2013. There will be two new types of turbines, the N100/3300 strong-wind turbine and the N117/3000, which is designed for medium-wind sites. Both turbines feature the rotorblades already used in the Gamma-Series, with the rotorblades of the N117 being slightly upgraded to withstand the higher wind speeds in IEC wind class 2a. Both turbines are equipped with a three-stage gearbox and a doubly fed asynchronous generator.\n\n"}
{"id": "1766716", "url": "https://en.wikipedia.org/wiki?curid=1766716", "title": "Northland (film)", "text": "Northland (film)\n\nNorthland is a brief (approximately 20 minutes running time) 1942 Canadian documentary film on the life of miners, most notable for its having been directed by the expatriate German crime writer, jazz critic, jazz musician, and sexologist Ernest Borneman. It is a production of the National Film Board of Canada.\n\n"}
{"id": "50441727", "url": "https://en.wikipedia.org/wiki?curid=50441727", "title": "Nuclear industry in South Australia", "text": "Nuclear industry in South Australia\n\nThe established nuclear industry in South Australia is focused on uranium mining, milling and the export of uranium oxide concentrate for use in the production of nuclear fuel for nuclear power plants. The state is home to the world's largest known single deposit of uranium, which is worked by BHP Billiton at the Olympic Dam mine. Contaminated legacy sites exist at Maralinga and Emu Field, where nuclear weapons tests were conducted in the 1950s and 1960s and at former uranium mines and milling sites. Nuclear waste is stored by CSIRO at Woomera and future waste storage prospects were considered during the deliberations of the Nuclear Fuel Cycle Royal Commission in 2016. The Commission has recommended that South Australia considers opportunities in nuclear waste storage (including developing a repository for spent nuclear fuel), the establishment of a nuclear fuel leasing scheme and the repeal of prohibitions which currently prevent future nuclear industrial development nationally.\n\nIn June 2017, former Prime Minister Tony Abbott acknowledged fellow former Prime Minister Bob Hawke's support for expanding the nuclear industry and asserted that the \"Australian Labor government under Premier Jay Weatherill would like to develop new industries to supplement the uranium mine at Roxby Downs. Why not have a nuclear submarine servicing facility in that state – and the industries that would inevitably spin-off?\"\n\nUranium mining has occurred in South Australia, since the early 20th century, when radium was the target mineral in uranium-bearing ore. During the Cold War, the Playford government facilitated the development of the Radium Hill uranium mine and the associated Port Pirie uranium treatment complex. These closed in the early 1960s after a seven-year contract of supply had been fulfilled. In the 1970s, the discovery of a massive uranium-bearing IOCG orebody near Roxby Downs led to the eventual opening of the Olympic Dam mine in 1988. In the 2000s, the sector expanded to include in-situ leach mining operations at Beverley, Four Mile and Honeymoon. As of May 2016, Beverley and Honeymoon mines are in care and maintenance mode owing to weak uranium prices in the wake of the Fukushima nuclear disaster.\n\nExploration for uranium in South Australia reached a record high in 2006 with forty companies exploring for the mineral.\n\nUranium mined in South Australia is exported, where it is used in the production of nuclear fuel for use in nuclear power plants. In 2013, uranium oxide concentrate produced in South Australia was being exported to Britain, France, Sweden, Finland, Belgium, Canada and the United States. In 2011, South Australian Premier Jay Weatherill expressed his support for exporting uranium to India, despite its status as a non-signatory to the Nuclear Non-Proliferation Treaty. By December 2015, no further barriers remained preventing such trade.\n\nConcentrations of nuclear waste in South Australia exist in the tailings ponds at the Olympic Dam mine, at the site of the former Port Pirie uranium treatment works and in the tailings block at the former Radium Hill mine. CSIRO operates a nuclear waste storage facility at Woomera in the state's far north. Unsuccessful attempts were made by the Howard Government to establish further nuclear waste storage facilities in South Australia between 1998 and 2004.\n\nA prospective nuclear waste storage site at Barndioota was announced in 2015. The property is owned by Grant Chapman, and the traditional owners are the Adnyamathanha. The site is a candidate for a future National Nuclear Waste Management Facility, where domestically produced nuclear waste, and repatriated, reprocessed spent nuclear fuel from Australia's research reactors at Lucas Heights would be stored. Two other candidate sites exist near Kimba on Eyre Peninsula, and as of 2017, community consultation there is ongoing.\n\nThe Kimba sites are located in the federal electorate of Grey, for which Rowan Ramsay is the sitting member. Ramsey has publicly advocated for the establishment of nuclear waste storage facilities in South Australia, and has stated that he would be comfortable storing it on his own property. Ramsay did not nominate his own property for the project after receiving advice that it would constitute a conflict of interest. Opinion on the benefits and risks associated with establishing a facility has divided the township of Kimba.\n\nOpponents of the establishment of a new national facility for domestically produced nuclear waste believe that such waste should be stored long-term at Lucas Heights, where much of the waste was and continues to be generated. Spokespeople for the opposition include Jim Green of Friends of the Earth and David Sweeney of the Australian Conservation Foundation.\n\nThe prospect of storing nuclear waste in the tunnels of the Olympic Dam mine has also been speculated upon by opinion writers, politicians and the community.\n\nSupport for the development of new nuclear waste storage facilities in South Australia was expressed by the Committee for Adelaide on 6 May 2016.\n\nThe Nuclear Fuel Cycle Royal Commission's final report, which was delivered to the Governor of South Australia on 6 May 2016 recommended the consideration of the establishment of a repository for imported spent nuclear fuel in South Australia. The report was released in full on 9 May 2016.\n\nThe report was put before a Citizens Jury, which ultimately voted not to proceed with investigating the prospect of importing spent nuclear fuel for storage and disposal in South Australia. In December 2016, a group of prominent citizens signed an open letter expressing an opposing view. It stated:\"We, the undersigned, call on South Australia’s elected representatives of all parties to continue to explore this opportunity. We request further investigations into issues that a) are essential for better understanding project feasibility and b) could be investigated at relatively low cost. We call for partnership between the State Government and relevant Federal Government agencies to formally meet with prospective client nations in order to gain greater certainty and ensure we are fully informed as to the nature of this opportunity.\"Signatories were: Fraser Ainsworth AM, Rob Chapman, Tim Cooper AM, Di Davidson AM, Colin Dunsford AM, Geoff Day OAM, Robert Gerard AO, Ian Gould AM, Kathy Gramp, Jim Hazel, Mike Heard, David Klingberg AO, Theo Maras AM, Karlene Maywald, Jim McDowell, Mike Miller AO, Tanya Monro, Creagh O'Connor AM, Leanna Read, Karen Reynolds, Richard Ryan AO, Antony Simpson, Michael Terlet AO, Meera Verma, Graham Walters and Stephen Young.\n\nA similar letter was published in March 2017 on Ben Heard's website, \"Bright New World\". Many of the former signatories signed again, and the following new names were added: Rick Allert AO, Amanda Blair, Corey Bradshaw, Mark Butcher, Matt Clemow, Greg Clothier, Brian Cunningham, Colin Goodall, John Heard AM, Mark Malcolm, Hon. Ian McLachlan AO, Carolyn Mitchell, Craig Mudge AO, Goran Roos, Raymond Spencer, Lissa Van Camp, Jodie Van Deventer, Hon. Trish White, Paul Willis and Stephen Yarwood.\n\nIn March 2017, it was estimated that $30 million would need to be spent to manage nuclear waste stored at Woomera. Barrels containing the wastes were found to be rusting and deteriorating.\n\nA series of British nuclear weapons tests were conducted at Maralinga and Emu Field during the 1950s and early 1960s. Land remains contaminated at these sites and access is restricted.\n\nAustralia has no domestic nuclear weapons nor the capability to develop them. Australia is allied with countries which do maintain nuclear arsenals. As of 2016 the Liberal-National Coalition does not support a prospective ban on the possession of nuclear weapons, while the Australian Labor Party and Australian Greens do.\n\nIn 2015, a Nuclear Fuel Cycle Royal Commission was initiated by the Government of South Australia. It was tasked with investigating opportunities and risks associated with potential expansion of the state's role in the nuclear fuel cycle. Commissioner Kevin Scarce delivered its final report to the Governor of South Australia on 6 May 2016. The Commission's final report recommended the repeal of prohibitions preventing nuclear industrial development in Australia, including the legalisation of nuclear power generation. The report recommended the establishment of a facility to store international stockpiled spent nuclear fuel and the consideration of a nuclear fuel leasing scheme to accompany it. The latter was also described by the Commission as a potential enabler for future enrichment and fuel processing activities, though such further processing developments were deemed to not be feasible within the next decade. The establishment of nuclear power generation in South Australia was also deemed inappropriate given the state's high penetration of solar and wind power.\n\nThe Government of South Australia has allocated $3.6 million to the Department of the Premier and Cabinet for 2016–17 \"to enable the government to engage with the community to develop an informed response to the Nuclear Fuel Cycle Royal Commission Final Report.\"\n\nFollowing the conclusion of the Nuclear Fuel Cycle Royal Commission, the Department of the Premier and Cabinet established a \"YourSAy nuclear?\" website, advertising campaign and Citizens' Jury process. Managed by the New Democracy Foundation, the Citizens' Jury process randomly invited 25,000 South Australians to participate by post. Of those who accepted the invitation, a total of 350 jurors will be chosen to meet and discuss the Nuclear Fuel Cycle Royal Commission's final report, help produce a simplified version for further discussion, and ultimately express their support or rejection of its various recommendations. South Australian company DemocracyCo won the contract to facilitate the first Citizens' Jury. DemocracyCo spokesperson Emily Jenke described the process and its result as \"one of the pieces the Premier and Government will be using to inform their thinking\".\n\nThe first Citizens' Jury was composed of 50 people. They were provided with the Nuclear Fuel Cycle Royal Commission's final report and heard from a panel whose members are listed below.\nThe first Citizens Jury produced a report after hearing witnesses and deliberating over four sitting days. Its publication was followed by the launch of a statewide community consultation program coordinated by the Department of the Premier and Cabinet. The campaign carried the slogan \"Get to know nuclear. Discover. Discuss. Decide\" and included print, radio and television commercials, online discussions and community displays attended by DPC staff.\n\nA second jury was later formed, expanding the cohort of jurors to approximately 350 people.\n\nAfter hearing from a larger cohort of expert witnesses, the citizens' jury ultimately concluded, by a two-thirds majority vote, to not pursue to prospect of the importation of spent nuclear fuel to South Australia under any circumstances. A \"lack of trust\" was cited as a primary driver.\n\nThe prospect of constructing nuclear submarines in South Australia has been raised on various occasions during the 2010s.\n\nIn 2011, the CEO of Defence SA, Andrew Fletcher expressed his personal view that it would be unlikely for Australia's Future Submarine project to commit to producing nuclear powered submarines, unless a nuclear industry was established in Australia beforehand, or if their production was outsourced offshore. He expressed his belief that a commitment to 12 diesel-powered submarines was more likely.\n\nAuthors from UCL Australia have written opinion pieces and produced research papers on the topic. In 2016, the contract for the supply of Australia's Future Submarines Project was awarded to French company Direction des Constructions Navales Services (DCNS), and the Barracuda-class submarine was selected. The Barracuda-class submarine is currently a nuclear powered submarine, but the Australian Government has sought a modified design with diesel-powered pump jet propulsion. The other bidders which were competing for the tender do not make nuclear powered submarines. Australian Cabinet ministers have discussed the merits of keeping the nuclear propulsion option open by choosing the Barracuda-class design and the coalition government is supportive of nuclear industrial development in Australia.\n\nIn 2015, former Rolls Royce nuclear engineer and submarine expert Steve Ludlam was appointed to the Defence SA Advisory Board.\n\nin 2017, former Australian Prime Minister Tony Abbott spoke of the merits of considering nuclear propulsion for Australia's Future Submarine Project, claiming various advantages over diesel propulsion, including range and speed.\nSupport for expanding the nuclear industry in South Australia has been expressed by corporate uranium mining interests Western Mining Corporation (the first owners of the Olympic Dam mine), BHP Billiton (their successors) and the Rio Tinto Group. Industry representative bodies have also expressed their support, including the Minerals Council of Australia and its predecessors, the Uranium Information Centre and the Australian Uranium Association. Other spokespeople supporting nuclear industrial development in South Australia include Richard Yeeles, Nigel McBride from Business SA and Jason Kuchel from the South Australian Chamber of Mines and Energy. Staff and students of UCL Australia have published research papers supporting the exploration of further nuclear industrial development in South Australia. Professor Stefaan Simons has advocated for the consideration of uranium enrichment and nuclear-powered submarines.\n\nIn March 2017, eleven members of the Turnbull Government were listed as openly supporting the prospect of nuclear power in Australia. Listed politicians were: Andrew Broad, James Paterson, Tony Pasin, Tim Wilson, Chris Back, Craig Kelly, Eric Abetz, Andrew Hastie, Warren Entsch, Bridget McKenzie and Rowan Ramsey.\n\nThere has been considerable Australian resistance to uranium mining for some decades. There have been concerns that uranium drives the global nuclear weapons cycle, disturbs or degrades sacred sites, releases carcinogenic radon gas, and contaminates groundwater. Nuclear power is considered by opponents as an unsafe, centralised, and secretive energy option, which creates security risks. High-level radioactive waste management has also been another major concern.\n\nOpponents to the expansion of nuclear industry in South Australia include the Australian Greens (whose spokespeople include Scott Ludlam and Mark Parnell), Friends of the Earth, the Australian Conservation Foundation and the Conservation Council of South Australia. Opposition has also been expressed by Kevin Buzzacott, Eileen Kampakuta Brown, Eileen Wani Wingfield and other elders of several indigenous peoples. The Desert Liberation Front has coordinated protest events at the gates of the Olympic Dam mine in 2012 and 2016 using the names The Lizard's Revenge and The Lizard Bites Back.\n"}
{"id": "38017102", "url": "https://en.wikipedia.org/wiki?curid=38017102", "title": "Order unit", "text": "Order unit\n\nAn order unit is an element of an ordered vector space which can be used to bound all elements from above. In this way (as seen in the first example below) the order unit generalizes the unit element in the reals.\n\nFor the ordering cone formula_1 in the vector space formula_2, the element formula_3 is an order unit (more precisely an formula_4-order unit) if for every formula_5 there exists a formula_6 such that formula_7 (i.e. formula_8).\n\nThe order units of an ordering cone formula_1 are those elements in the algebraic interior of formula_4, i.e. given by formula_11.\n\nLet formula_12 be the real numbers and formula_13, then the unit element formula_14 is an \"order unit\".\n\nLet formula_15 and formula_16, then the unit element formula_17 is an \"order unit\".\n"}
{"id": "26201453", "url": "https://en.wikipedia.org/wiki?curid=26201453", "title": "Prepolymer", "text": "Prepolymer\n\nThe term pre-polymer refers to a monomer or system of monomers that have been reacted to an intermediate molecular mass state. This material is capable of further polymerization by reactive groups to a fully cured high molecular weight state. As such, mixtures of reactive polymers with un-reacted monomers may also be referred to as pre-polymers. The term “pre-polymer” and “polymer precursor” may be interchanged.\n\nTwo molecules of lactic acid can be dehydrated to lactide, a cyclic lactone. A variety of catalysts can polymerise lactide to either heterotactic or syndiotactic polylactide, which as biodegradable polyesters with valuable (inter alia) medical properties are currently attracting much attention.\n\nNowadays, lactic acid is used as a monomer for producing polylactic acid (PLA) which later has application as biodegradable plastic. This kind of plastic is a good option for substituting conventional plastic produced from petroleum oil because of low emission of carbon dioxide. The commonly used process in producing lactic acid is via fermentation, and later to obtain the polylactic acid, the polymerization process follows.\n"}
{"id": "5321285", "url": "https://en.wikipedia.org/wiki?curid=5321285", "title": "Radium and radon in the environment", "text": "Radium and radon in the environment\n\nRadium and radon are important contributors to environmental radioactivity. Radon occurs naturally in the environment as a result of decay of radioactive elements in the soil and it can accumulate in houses built on areas where such decay occurs. This radon is among major causes of cancer, estimated to contribute to about 2% of all cancer related deaths in Europe.\n\nRadium, like radon, is a radioactive element and it is found in small quantities in nature and may thus be hazardous to life if concentrated. Radium has its origins as a decay product of certain isotopes of uranium and thorium. Radium may also be released to the environment as a result of human activity, for example, in inproperly discarded products painted with radioluminescent paint.\n\nResidues from the oil and gas industry often contain radium and its daughters. The sulfate scale from an oil well can be very radium rich. It is the case that the water inside an oil field is often very rich in strontium, barium and radium while seawater is very rich in sulfate so if water from an oil well is discharged into the sea or mixed with seawater the radium is likely to be brought out of solution by the barium/strontium sulfate which acts as a carrier precipitate.\n\nLocal contamination from radium-based radioluminescent paints having been improperly disposed of is not unknown.\n\nEben Byers was a wealthy American socialite whose death in 1932 as a result of using an radioactive quackery product called Radithor is a prominent example of a death caused by radium. Radithor contained approximately 1 μCi (40 MBq) of Ra and 1 μCi of Ra per bottle. Radithor was taken by mouth and radium, being a calcium mimic, has a very long biological halflife in bone.\n\nThe majority of the dose is caused by the decay of the polonium (Po) and lead (Pb) daughters of Rn. By controlling exposure to the daughters the radioactive dose to the skin and lungs can be reduced by at least 90%. This can be done by wearing a dust mask, and wearing a suit to cover the entire body. Note that exposure to smoke at the same time as radon and radon daughters will increase the harmful effect of the radon. In uranium miners radon has been found to be more carcinogenic in smokers than in non-smokers.\n\nRadon concentration in the open air varies between 1 and 100 Bq per cubic metre. Radon can be found in some spring waters and hot springs. The towns of Misasa, Japan, and Bad Kreuznach, Germany boast radium-rich springs which emit radon, as does Radium Springs, New Mexico.\n\nRadon exhausts naturally from the ground, particularly in certain regions, especially but not only regions with granitic soils. Not all granitic regions are prone to high emissions of radon, for instance while the rock which Aberdeen is on is very radium rich the rock lacks the cracks required for the radon to migrate. In other nearby areas of Scotland (to the north of Aberdeen) and in Cornwall/Devon the radon is very much able to leave the rock.\n\nRadon is a decay product of radium which in turn is a decay product of uranium. It is possible to acquire maps of average radon levels in houses to assist in the planning of radon mitigation measures for homes.\n\nNote that while high uranium in the soil/rock under a house does not always lead to a high radon level in air, a positive correlation between the uranium content of the soil and the radon level in air can be seen.\n\nRadon is related to indoor air quality as it blights many homes. (See \"Radon in Houses\" below.)\n\nThe radon (Rn) released into the air decays to Pb and other radioisotopes and the levels of Pb can be measured. It is important to note that the rate of deposition of this radioisotope is very dependent on the season. Here is a graph of the deposition rate observed in Japan.\n\nWell water can be very rich in radon; the use of this water inside a house is an additional route allowing radon to enter the house. The radon can enter the air and then be a source of exposure to the humans, or the water can be consumed by humans which is a different exposure route.\n\nRainwater can be intensely radioactive due to high levels of radon and its decay progenies Bi and Pb; the concentrations of these radioisotopes can be high enough to seriously disrupt radiation monitoring at nuclear power plants. The highest levels of radon in rainwater occurs during thunderstorms, and it is hypothesized that radon is concentrated in thunderstorms on account of the atom's positive electrical charge. Estimates of the age of rain drops have been obtained from measuring the isotopic abundance of radon's short-lived decay progeny in rainwater.\n\nThe water, oil and gas from a well often contains radon. The radon decays to form solid radioisotopes which form coatings on the inside of pipework. In an oil processing plant the area of the plant where propane is processed is often one of the more contaminated areas of the plant as radon has a similar boiling point to propane.\n\nBecause uranium minerals emit radon gas, and their harmful and highly radioactive daughter products, uranium mining is considerably more dangerous than other (already dangerous) hard rock mining, requiring adequate ventilation systems if the mines are not open pit. During the 1950s, a significant number of American uranium miners were Navajo Indians, as many uranium deposits were discovered on Navajo reservations. A statistically significant subset of these miners later developed small-cell lung cancer, a type of cancer usually not associated with smoking, after exposure to uranium ore and radon-222, a natural decay product of uranium. The radon, which is produced by the uranium, and not the uranium itself has been shown to be the cancer causing agent. Some survivors and their descendants received compensation under the Radiation Exposure Compensation Act in 1990.\n\nCurrently the level of radon in the air of mines is normally controlled by law. In a working mine, the radon level can be controlled by ventilation, sealing off old workings and controlling the water in the mine. The level in a mine can go up when a mine is abandoned, it can reach a level which is able to cause the skin to become red (a mild radiation burn). The radon levels in some of the mines can reach 400 to 700 kBq m.\n\nA common unit of exposure of lung tissue to alpha emitters is the working level month (WLM), this is where the human lungs have been exposed for 170 hours (a typical month worth of work for a miner) to air which has 3.7 kBq of Rn (in equilibrium with its decay products). This is air which has the alpha dose rate of 1 working level (WL). It is estimated that the average person (\"general public\") is subject to 0.2 WLM per year, which works out at about 15 to 20 WLM in a lifetime. According to the NRC 1 WLM is a 5 to 10 mSv lung dose (0.5 to 1.0 rem), while the Organisation for Economic Co-operation and Development (OECD) consider that 1 WLM is equal to a lung dose of 5.5 mSv, the International Commission on Radiological Protection (ICRP) consider 1 WLM to be a 5 mSv lung dose for professional workers (and 4 mSv lung dose for the general public). Lastly the United Nations Scientific Committee on the Effects of Atomic Radiation (UNSCEAR) consider that the exposure of the lungs to 1 Bq of Rn (in equilibrium with its decay products) for one year will cause a dose of 61 μSv.\n\nIn humans a relationship between lung cancer and radon has been shown to exist (beyond all reasonable doubt) for exposures of 100 WLM and above. By using the data from several studies it has been possible to show that an increased risk can be caused by a dose as low as 15 to 20 WLM. Sadly these studies have been difficult as the random errors in the data are very large. It is likely that the miners are also subject to other effects which can harm their lungs while at work (for example dust and diesel fumes).\n\nThe fact that radon is present in indoor air has been known at least since 1950s and research on its effects on human health started on early 1970s. The danger of radon exposure in dwellings received more widespread public awareness after 1984, as a result of a case of Stanley Watras, an employee at the Limerick nuclear power plant in Pennsylvania. Mr. Watras set off the radiation alarms (see Geiger counter) on his way \"into\" work for two weeks straight while authorities searched for the source of the contamination. They were shocked to find that the source was astonishingly high levels of radon in his basement and it was not related to the nuclear plant. The risks associated with living in his house were estimated to be equivalent to smoking 135 packs of cigarettes every day.\n\nDepending on how houses are built and ventilated, radon may accumulate in basements and dwellings. The European Union recommends that mitigation should be taken starting from concentrations of 400 Bq/m for old houses, and 200 Bq/m for new ones.\n\nThe National Council on Radiation Protection and Measurements (NCRP) recommends action for any house with a concentration higher than 8 pCi/L (300 Bq/m³).\n\nThe United States Environmental Protection Agency recommends action for any house with a concentration higher than 148 Bq/m (given as 4 pCi/L). Nearly one in 15 homes in the U.S. has a high level of indoor radon according to their statistics. The U.S. Surgeon General and EPA recommend all homes be tested for radon. Since 1985, millions of homes have been tested for radon in the U.S.\n\nBy adding a crawl space under the ground floor, which is subject to forced ventilation the radon level in the house can be lowered.\n\n\n"}
{"id": "29409353", "url": "https://en.wikipedia.org/wiki?curid=29409353", "title": "Refractory lined expansion joint", "text": "Refractory lined expansion joint\n\nA Refractory lined expansion joint is an assembly used in a pipe line to allow it to expand and contract as climate conditions move from hot to cold and helps to ensure that the system remains functional. The refractory-lining can be vibra cast insulation with anchors, abrasion resistant refractory in hex mesh, gunned insulating refractory, or poured insulating refractory. Refractory lined expansion joints can be hinged, in-line pressure balanced, gimbal, tied-universal depending on the temperature, pressure, movement and flow media conditions. \n\nRefractory lined Expansion joints are used in extremely high temperature and high pressure applications and are designed to withstand extreme environments. The Refractory lining within the metallic Expansion joint bellows functions to reduce the \n\npipe wall temperature by 300˚F to 450˚F, depending upon the thickness of the refractory lining. The lining also helps to withstand the abrasive material from the catalyst in FCCU applications.\n\n"}
{"id": "38257238", "url": "https://en.wikipedia.org/wiki?curid=38257238", "title": "Richard McCarthy (activist)", "text": "Richard McCarthy (activist)\n\nRichard McCarthy is the co-founder of the Crescent City Farmers Market and the executive director of Slow Food USA. He was the founder of Market Umbrella and the Farmers Market Coalition. In 2012, he was named a \"Hero of the New South\" by Southern Living magazine. He is a graduate of the London School of Economics. A small selection of McCarthy's personal papers are archived at Loyola University New Orleans.\n\n"}
{"id": "13504648", "url": "https://en.wikipedia.org/wiki?curid=13504648", "title": "Steven Guilbeault", "text": "Steven Guilbeault\n\nSteven Guilbeault, born on June 9, 1970 in La Tuque, Quebec, is a Canadian environmentalist, speaker and writer. A founding member of Équiterre, Quebec’s leading environmental organization, he had a ten-year stint as director and campaign manager for Greenpeace Quebec chapter. He currently serves as Senior Director and spokesperson for Équiterre.  \n\nWhen he was five years old in his hometown of La Tuque in Haute-Mauricie, Steven Guilbeault refused to get down from a tree that he had climbed, in an effort to block a land developer from clearing a wooded area behind his home. The tree was felled a few days later, but the event stands is cited by Steven Guilbeault as the genesis of his environmental activism.\n\nSteven Guibeault has demonstrated great enthusiasm for nature and outdoor sports. A bike courier during his university days, his bike has been his principal mode of transportation, both in summer and in winter since 1989. A driven athlete, he was a competitive downhill skier and played various team sports during his youth. These days, you can find him participating in obstacle courses, marathons and half-marathons. He is also a science fiction lover.\n\nHe is the father of four children.\n\nAfter taking computer science in CEGEP, he enrolled in industrial relations at l'Université de Montréal in 1989. A year later, he switched his major to political science finding himself attracted to international relations, the study of political systems and religion. He minored in theology, exploring questions of international morality, liberation theology, poverty and the environment.\n\nThe activism and civic engagement for which Steven Guilbeault would become known took root during his university days. He became president of his faculty’s student association and also took part in activities organized by Equitas (known at the time as the Canadian Human Rights Foundation). He was also active in the Fédération étudiante universitaire du Québec (FEUQ), where he made the acquaintance of François Rebello and Nicolas Girard, who would later enter the world of politics. He also joined the \"Groupe de recherche en intérêt public\" (GRIP), created out of the protest movement spearheaded by Ralph Nader, the renowned American consumer advocate. There he met Laure Waridel, Sydney Ribaux and François Meloche, with whom he would go on to found Équiterre a few years later.\n\nWhile in university, Steven Guilbeault worked for two years (1992-1993) with the Canadian Human Rights Foundation, an organization dedicated to educating people, both at home and abroad, about human rights issues.\n\nAfter the Earth Summit in Rio de Janeiro in 1993, in which François Meloche participated, that Guilbeault and a group of his friends had the idea of creating a citizen organization, leading to Steven Guilbeault, Laure Waridel, Elizabeth Hunter, Patrick Henn, François Meloche and Sidney Ribaux to found Action for Solidarity, Equity, Environment and Development (ASEED). It acquired not-for-profit status in 1995 and in 1998, it was rebranded as Équiterre. The organization's goal is to propose concrete solutions to make Canada a society where sustainable development and social economy would be central to the actions and concerns of its citizens, organizations and government. Steven Guilbeault was a member of Équiterre's board of directors for many years. \n\nIn 1997, Steven Guilbeault joined Greenpeace Canada. He was put in charge of its climate change division and he managed the climate and energy campaign before being the organization's Quebec Bureau Chief in 2000. In 2005, he coordinated the climate campaign for Greenpeace International.\n\nOn four different occasions, Steven Guilbeault made headlines for Greenpeace. His best known feat was scaling Toronto’s CN Tower in 2001, accompanied by British militant Chris Holden. At the time the tower was the tallest in the world. After ascending to a height of 340m, they unfurled a banner that read: \"Canada and Bush Climate Killers.\" The goal was to grab the world’s attention a week before the UN’s sixth conference on climate change, where the fate of the Kyoto Protocol would be decided.\n\nSteven Guilbeault remained Greenpeace’s Quebec spokesperson until June 8, 2007, at which time he announced his resignation. \n\nIn 2008, he returned to Équiterre, which he had cofounded fifteen years earlier, to work on climate change issues. He currently serves the organization as it's Senior Director and Spokesperson.\n\nSteven Guilbeault sat on the board of the \"Agence de l'efficacité énergétique\" from 2007 to 2009 and chaired the Committee on Emerging Renewable Energy from 2009 to 2011 for the Government of Quebec.\n\nHe also sat on the climate change advisory committees of three successive Quebec governments: Jean Charest’s Liberals, Pauline Marois’ Parti Québécois, and subsequently co-chairing the committee formed by Philippe Couillard’s Liberal government starting in 2014.\n\nIn 2016, he was invited by Justin Trudeau to an event with US Vice President Joe Biden, after having previously sat at the head table at an event honouring Al Gore in Montreal. \n\nStéphane Dion, former federal Minister of the Environment and Climate Change (2004-2006), of Intergovernmental Affairs (1995-2003) and of Foreign Affairs (2015-2017), remakred that Guilbeaukt \"is among the select few in the environmental community with whom it is important to remain in contact, because his reactions and his opinions will count\". Kalee Kreider, formerly with Greenpeace and former Communications Director for Al Gore, said that Steven Guilbeault \"has at once gained the respect of those in government, NGOs and industry.\"\n\nSteven Guilbeault has been courted by numerous political parties. He stated he recognized the importance of politics and has not closed the door to a role at the municipal, provincial or federal level, perhaps later on in his career.\n\nRecognized for his ability to make complex issues easier to understand, Steven Guilbeault is a sought-after speaker in Quebec and the rest of Canada. He is regularly solicited by the media to share his opinion on a variety of environmental issues. He has been a commentator for Radio-Canada, CBC, \"La Presse\" and \"Corporate Knights\" magazine, and has been a columnist for the \"Métro\" newspaper for nearly a decade.\n\nSteven Guilbeault worked as a Senior Consultant for Deloitte and Touche, and served as co-chair of Climate Action Network - International for five years.\n\nHe also chaired the Chamber of Commerce of Metropolitan Montreal's Committee on Sustainable Development from 2007 to 2010. \n\nSince 2009, he has been a strategic consultant for Cycle Capital Management’s venture capital fund, which is dedicated to developing clean technologies.\n\nSteven Guilbeault was named Activist of the Year by \"Ici\" magazine in 2008.\n\nIn 2009, he became a member of the Cercle des Phénix de l’environnement du Québec. That same year the French magazine \"Le Monde\" called him one of the world’s 50 leading players in the field of sustainable development. He is also an honourary fellow of the Royal Canadian Geographical Society.\n\nHe was recognized as one of the 35 most influential figures in the past 35 years by the Fondation Marie-Vincent in 2010 and as an Americas Leader by the US magazine \"Americas Quarterly\".\n\nIn 2012 he received the \"Médaille de l’Université de Montréa\"l (a rare honour, this career achievement award has been bestowed upon such luminaries as Christopher Reeve and Oliver Jones).\n\nIn 2014, he received the Blanche-Lemco-Van-Ginkel award from the Ordre des urbanistes du Québec for his significant contribution to urban planning in Quebec.\n\nIn 2016, Steven Guilbeault received the prestigious \"Impératif français\" award recognizing his exceptional contribution to the vitality of the French language and French culture.\n\n\n"}
{"id": "24958802", "url": "https://en.wikipedia.org/wiki?curid=24958802", "title": "West Durham Wind Farm", "text": "West Durham Wind Farm\n\nWest Durham Wind Farm is a wind farm near Tow Law, County Durham, England.\n\nDeveloped by County Durham-based company the Banks Group, the farm was planned as the largest wind farm in North East England. Construction of the farm began on the 11 July 2008. It was hoped that the commissioning of the turbines would make County Durham the first English county to hit its 2010 renewable energies target. The farm was commissioned in May 2009. In 2009 it was purchased by the Electricity Supply Board\n\nThe wind farm has a nameplate capacity of 24MW, containing twelve Repower MM82 turbines each rated at 2MW. It was the first wind farm containing turbines supported on driven steel tubular piles.\n"}
