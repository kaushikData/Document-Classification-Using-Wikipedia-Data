{"id": "28468303", "url": "https://en.wikipedia.org/wiki?curid=28468303", "title": "Alexander von Humboldt Biological Resources Research Institute", "text": "Alexander von Humboldt Biological Resources Research Institute\n\nThe Alexander von Humboldt Biological Resources Research Institute (), sometimes referred to as , is an independent non-regulatory research institute of the Executive Branch of the Government of Colombia charged with conducting scientific research on the biodiversity of the country including hydrobiology and genetic research. The institute is named after Alexander von Humboldt, a German naturalist who conducted research on the biodiversity of Colombia and Latin America.\n"}
{"id": "34018074", "url": "https://en.wikipedia.org/wiki?curid=34018074", "title": "Amrumbank West", "text": "Amrumbank West\n\nAmrumbank West in a German offshore wind farm in the North Sea owned by E.ON. \nIt is located about 35 km northwest of the island of Heligoland and around 18 km south-west of the Amrum Bank sandbank. \nIt consists of 80 turbines in waters 19–24 m deep.\n\nConstruction cost was around . \nThe project was delayed 15 months by the lack of power lines. \nThe 80 wind turbines are Siemens SWT-3.6–120 with a rated power of 3.6 MW and a rotor diameter of 120 meters. \nOffshore construction began in 2013, and the first turbine was installed in February 2015. \nThe wind farm was commissioned at the end of 2015.\n\nThe seabed surface at the construction site mainly consists of sand. It was initially reinforced by a 2.4-m-thick layer of large stones. However, this hindered installation of the turbine piles, which should be driven through the protection layer deep into the seabed. Therefore, stones were replaced by two layers of geotextile containers, i.e., sandbags made of a special damage-resistant nonwoven geotextile. Empty bags had a size of 1.45 × 2.38 m and could accommodate 1 m of sand; they were filled on the Rømø island up to 80 vol% and weighed 1400 kg each. The seabed protection withstood the St. Jude storm in October 2013 and Cyclone Xaver in December 2013. Starting from December 2013, turbine piles 6 m in diameter were driven through the erosion protection layers.\n\n"}
{"id": "14034974", "url": "https://en.wikipedia.org/wiki?curid=14034974", "title": "Askøy Energi", "text": "Askøy Energi\n\nAskøy Energi (\"English: Askoy Energi\") is a power company that serves Askøy in Norway. It provides the power grid in the municipality, as well as selling electricity through the subsidiary Askøy Energi Kraftomsetning, with a total of 11,000 customers. It was created as a limited company by the municipality in 1995, but was then sold to Fredrikstad Energi in 2001.\n"}
{"id": "758445", "url": "https://en.wikipedia.org/wiki?curid=758445", "title": "Baler", "text": "Baler\n\nA baler, most often called a hay baler is a piece of farm machinery used to compress a cut and raked crop (such as hay, cotton, flax straw, salt marsh hay, or silage) into compact bales that are easy to handle, transport, and store. Often, bales are configured to dry and preserve some intrinsic (e.g. the nutritional) value of the plants bundled. Several different types of balers are commonly used, each producing a different type of bale – rectangular or cylindrical, of various sizes, bound with twine, strapping, netting, or wire.\n\nIndustrial balers are also used in material recycling facilities, primarily for baling metal, plastic, or paper for transport.\n\nBefore the 19th century, hay was cut by hand and most typically stored in haystacks using hay forks to rake and gather the scythed grasses into optimal sized heaps — neither too large (promoting conditions that might create spontaneous combustion), nor too small, so much of the pile is susceptible to rotting. These haystacks lifted most of the plant fibers up off the ground, letting air in and water drain out, so the grasses could dry and cure, to retain nutrition for livestock feed at a later time. In the 1860s, mechanical cutting devices were developed; from these came the modern devices including mechanical mowers and balers. In 1872, a reaper that used a knotter device to bundle and bind hay was invented by Charles Withington; this was commercialized in 1874 by Cyrus McCormick. In 1936, Innes invented an automatic baler that tied bales with twine using Appleby-type knotters from a John Deere grain binder; In 1938 Edwin Nolt filed a patent for an improved version that was more reliable. \n\nThe most common type of baler in industrialized countries today is the round baler. It produces cylinder-shaped \"round\" or \"rolled\" bales. The design has a \"thatched roof\" effect that withstands weather well. Grass is rolled up inside the baler using rubberized belts, fixed rollers, or a combination of the two. When the bale reaches a predetermined size, either netting or twine is wrapped around it to hold its shape. The back of the baler swings open, and the bale is discharged. The bales are complete at this stage, but they may also be wrapped in plastic sheeting by a bale wrapper, either to keep hay dry when stored outside or convert damp grass into silage. Variable-chamber large round balers typically produce bales from in diameter and up to in width. The bales can weigh anywhere from , depending upon size, material, and moisture content. Common modern small round balers (also called \"mini round balers\" or \"roto-balers\") produce bales in diameter and in width, generally weighing from .\n\nOriginally conceived by Ummo Luebben circa 1910, the first round baler did not see production until 1947 when Allis-Chalmers introduced the Roto-Baler. Marketed for the water-shedding and light weight properties of its hay bales, AC had sold nearly 70,000 units by the end of production in 1960. The next major innovation began in 1965 when a graduate student at Iowa State University, Virgil Haverdink, sought out Wesley F. Buchele, a professor of Agricultural Engineering, seeking a research topic for a master thesis. Over the next year Buchele and Haverdink developed a new design for a large round baler, completed and tested in 1966, and thereafter dubbed the Buchele-Haverdink large round baler. The large round bales were about in diameter, long, and they weighed about after they dried—about 80 kg/m5 lb/ft. The design was promoted as a \"Whale of a Bale\" and Iowa State University now explains the innovative design as follows:\n\"Farmers were saved from the backbreaking chore of slinging hay bales in the 1960s, when Iowa State agricultural engineering professor Wesley Buchele and a group of student researchers invented a baler that produced large, round bales that could be moved by tractor. The baler has become the predominant forage-handling machine in the United States.\"\nIn the summer of 1969, the Australian Econ Fodder Roller baler came out, a design that made a ground-rolled bale. In September of that same year, The Hawkbilt Company of Vinton, Iowa, contacted Dr. Buchele about his design, then fabricated a large ground-rolling round baler which baled hay that had been laid out in a windrow, and began manufacturing large round balers in 1970. In 1972, Gary Vermeer of Pella, Iowa, designed and fabricated a round baler after the design of the A-C Roto-Baler, and the Vermeer Company began selling its model 605 - the first modern round baler. The Vermeer design used belts to compact hay into a cylindrical shape as is seen today. In the early 1980s, collaboration between Walterscheid and Vermeer produced the first effective uses of CV joints in balers, and later in other farm machinery. Due to the heavy torque required for such equipment, double Cardan joints are primarily used. Former Walterscheid engineer Martin Brown is credited with \"inventing\" this use for universal joints.\n\nBy 1975, fifteen American and Canadian companies were manufacturing large round balers.\n\nDue to the ability for round bales to roll away on a slope, they require specific treatment for safe transport and handling. Small round bales can typically be moved by hand or with lower-powered equipment. Large round bales, due to their size and weight (they can weigh a ton or more) require special transport and moving equipment.\n\nThe most important tool for large round bale handling is the bale spear or spike, which is usually mounted on the back of a tractor or the front of a skid-steer. It is inserted into the approximate center of the round bale, then lifted and the bale is hauled away. Once at the destination, the bale is set down, and the spear pulled out. Careful placement of the spear in the center is needed or the bale can spin around and touch the ground while in transport, causing a loss of control. When used for wrapped bales that are to be stored further, the spear makes a hole in the wrapping that must be sealed with plastic tape to maintain a hermetic seal.\n\nAlternatively, a grapple fork may be used to lift and transport large round bales. The grapple fork is a hydraulically driven implement attached to the end of a tractor's bucket loader. When the hydraulic cylinder is extended, the fork clamps downward toward the bucket, much like a closing hand. To move a large round bale, the tractor approaches the bale from the side and places the bucket underneath the bale. The fork is then clamped down across the top of the bale, and the bucket is lifted with the bale in tow. Grab hooks installed on the bucket of a tractor are another tool used to handle round bales, and be done by a farmer with welding skills by welding two hooks and a heavy chain to the outside top of a tractor front loader bucket.\n\nThe rounded surface of round bales poses a challenge for long-haul, flat-bed transport, as they could roll off of the flat surface if not properly supported. This is particularly the case with large round bales; their size makes them difficult to flip, so it may not be feasible to flip many of them onto the flat surface for transport and then re-position them on the round surface at the destination. One option that works with both large and small round bales is to equip the flat-bed trailer with guard-rails at either end, which prevent bales from rolling either forward or backward. Another solution is the saddle wagon, which has closely spaced rounded saddles or support posts in which round bales sit. The tall sides of each saddle prevent the bales from rolling around while on the wagon, as the bale settles down in between posts. On 3 September 2010, on the A381 in Halwell near Totnes, Devon, UK an early member of British rock group ELO Mike Edwards was killed when his van was crushed by a large round bale. The cellist, 62, died instantly when the bale fell from a tractor on nearby farmland before rolling onto the road and crushing his van.\n\nA large round bale can be directly used for feeding animals by placing it in a feeding area, tipping it over, removing the bale wrap, and placing a protective ring (a \"ring feeder\") around the outside so that animals don't walk on hay that has been peeled off the outer perimeter of the bale. The round baler's rotational forming and compaction process also enables both large and small round bales to be fed out by unrolling the bale, leaving a continuous flat strip in the field or behind a feeding barrier.\n\nA recent innovation in hay storage has been the development of the silage or haylage bale, which is a high-moisture bale wrapped in plastic film. These are baled much wetter than hay bales, and are usually smaller than hay bales because the greater moisture content makes them heavier and harder to handle. These bales begin to ferment almost immediately, and the metal bale spear stabbed into the core becomes very warm to the touch from the fermentation process.\n\nSilage or haylage bales may be wrapped by placing them on a rotating bale spear mounted on the rear of a tractor. As the bale spins, a layer of plastic cling film is applied to the exterior of the bale. This roll of plastic is mounted in a sliding shuttle on a steel arm and can move parallel to the bale axis, so the operator does not need to hold up the heavy roll of plastic. The plastic layer extends over the ends of the bale to form a ring of plastic approximately wide on the ends, with hay exposed in the center.\n\nTo stretch the cling-wrap plastic tightly over the bale, the tension is actively adjusted with a knob on the end of the roll, which squeezes the ends of the roll in the shuttle. In this example wrapping video, the operator is attempting to use high tension to get a flat, smooth seal on the right end. However, the tension increases too much and the plastic tears off. The operator recovers by quickly loosening the tension and allows the plastic to feed out halfway around the bale before reapplying the tension to the sheeting.\n\nThese bales are placed in a long continuous row, with each wrapped bale pressed firmly against all the other bales in the row before being set down onto the ground. The plastic wrap on the ends of each bale sticks together to seal out air and moisture, protecting the silage from the elements. The end-bales are hand-sealed with strips of cling plastic across the opening.\n\nThe airtight seal between each bale permits the row of round bales to ferment as if they were in a silo bag, but they are easier to handle than a silo bag, as they are more robust and compact. The plastic usage is relatively high, and there is no way to reuse the silage-contaminated plastic sheeting, although it can be recycled or used as a fuel source via incineration. The wrapping cost is approximately US$5 per bale.\n\nAn alternative form of wrapping uses the same type of bale placed on a bale wrapper, consisting of pair of rollers on a turntable mounted on the three-point linkage of a tractor. It is then spun about two axes while being wrapped in several layers of cling-wrap plastic film. This covers the ends and sides of the bale in one operation, thus sealing it separately from other bales. The bales are then moved or stacked using a special pincer attachment on the front loader of a tractor, which does not damage the film seal. They can also be moved using a standard bale spike, but this punctures the airtight seal, and the hole in the film must be repaired after each move.\n\nPlastic-wrapped bales must be unwrapped before being fed to livestock to prevent accidental ingestion of the plastic. Like round hay bales, silage bales are usually fed using a \"ring feeder\".\nIn 1978, Hesston introduced the first \"large square baler,\" capable of compacting hay into more easily transported large square bales that could be stacked and tarped in the field (to protect them from rain) or loaded on trucks or containers for trucking or export. Depending upon the baler, these bales can weigh from 1000 pounds to 2200 pounds for a 3'x3'x9' or 3'x4'x9' bale (versus 900 pounds for a 3'x4' round bale). As the pickup revolves just above the ground surface, the tines pick up and feed the hay into the flake forming chamber, where a \"flake\" of hay is formed before being pushed up into the path of the plunger, which then compresses it with great force (200 to over 750 kilonewtons, depending on model) against the existing bale in the chamber. Once the desired length is achieved, the knotter arm is mechanically tripped to begin the knotting cycle in which several knotters (4-6 is common) tie the 4-6 strings that maintain the bale's shape.\n\nIn the prairies of Canada, the large rectangular balers are also called \"prairie raptors\".\n\nRectangular bales are easier to transport than round bales, since there is little risk of the bale rolling off the back of a flatbed trailer. The rectangular shape also saves space and allows a complete solid slab of hay to be stacked for transport and storage. Most balers allow adjustment of length and it is common to produce bales of twice the width, allowing stacks with brick-like alternating groups overlapping the row below at right angles, creating a strong structure.\n\nThey are well-suited for large-scale livestock feedlot operations, where many tons of feed are rationed every hour. Most often, they are baled small enough that one person can carry or toss them where needed.\n\nDue to the huge rectangular shape, large spear forks, or squeeze grips are mounted to heavy lifting machinery, such as large fork lifts, tractors equipped with front end loaders, telehandlers, hay squeezes or wheel loaders, to lift these bales.\n\nA type of baler that produces small rectangular (often called \"square\") bales was once the most prevalent form of baler, but is less common today. It is primarily used on small acreages where large equipment is impractical, and also for the production of hay for small operations, particularly horse owners who may not have access to the specialized feeding machinery used for larger bales. Each bale is about . The bales are usually wrapped with two, but sometimes three, or more strands of knotted twine. The bales are light enough for one person to handle, about , depending upon the crop and pressure applied (can be 100 lbs for a 16\"x18\" 2-string bale). Many balers have adjustable bale chamber pressure and bale length, so shorter, less-dense bales can be produced for ease of handling.\n\nTo form the bale, the material to be baled (which is often hay or straw) in the windrow is lifted by tines in the baler's \"reel\". This material is then \"packed\" into the bale chamber, which runs the length of one side of the baler (normally the right hand side when viewed from the front) in offset balers. Balers like Hesston models use an in-line system where the hay goes straight through from the pickup to the flake chamber to the plunger and bale-forming chamber. A combination plunger and knife move back and forth in the front of this chamber, with the knife closing the door into the bale chamber as it moves backwards. The plunger and knife are attached to a heavy asymmetrical flywheel to provide extra force as they pack the bales. A measuring device—normally a spiked wheel that is turned by the emerging bales—measures the amount of material that is being compressed and, at the appropriate length it triggers the \"knotters\" that wrap the twine around the bale and tie it off. As the next bale is formed the tied one is driven out of the rear of the baling chamber, where it can either drop to the ground, or sent to a wagon towed behind the baler. When a wagon is used, the bale may be lifted by hand from the chamber by a worker on the wagon who stacks the bales on the wagon, or the bale may be propelled into the wagon by a mechanism on the baler, commonly either a \"thrower\" (parallel high-speed drive belts which throw the bale into the wagon) or a \"kicker\" (mechanical arm which throws the bale into the wagon). In the case of a thrower or kicker, the wagon has high walls on the left, right, and back sides, and a short wall on the front side, to contain the randomly piled bales. This process continues as long as there is material to be baled, and twine to tie it with.\n\nThis form of bale is not much used in large-scale commercial agriculture, because of the costs involved in handling many small bales. However, it enjoys some popularity in small-scale, low-mechanization agriculture and horse-keeping. Besides using simpler machinery and being easy to handle, these small bales can also be used for insulation and building materials in straw-bale construction. Square bales may generally weather better than round bales because a more much dense stack can be put up. However, they don't shed water as round bales do. Convenience is also a major factor in farmers deciding to continue putting up square bales, as they make feeding and bedding in confined areas (stables, barns, etc.) much easier.\n\nMany of these older balers are still to be found on farms today, particularly in dry areas, where bales can be left outside for long periods.\n\nThe automatic-baler for small square bales took on most of its present form in 1938 with the first such baler sold as Arthur S. Young's Automation Baler. It was manufactured in small numbers until acquired by \"New Holland Ag.\"\n\nIn Europe, in as early as 1939, both Claas of Germany and Rousseau SA of France had automatic twine tying pick-up balers. Most of these produced low density bales though. The first successful pick-up balers were made by the Ann Arbor Company in 1929. Ann Arbor was acquired by the Oliver Farm Equipment Company in 1943. Despite their head start on the rest of the field, no Ann Arbor balers carried automatic knotters or twisters and Oliver didn't produce its own automatic tying baler until 1949.\n\nPrior to 1937 the hay press was the common name of the stationary baling implement, powered with a tractor or stationary engine using a belt on a belt pulley, with the hay being brought to the baler and fed in by hand. Later, balers were made mobile, with a 'pickup' to gather up the hay and feed it into the chamber. These often used air cooled gasoline engines mounted on the baler for power. The biggest change to this type of baler since 1940 is being powered by the tractor through its power take-off (PTO), instead of by a built-in internal combustion engine.\n\nIn present-day production, small square balers can be ordered with twine knotters or wire tie knotters.\n\nNot all stationary wire tying balers used 2 wires. It was not uncommon for the larger bale size (usually 17\" x 22\") machines to use 'boards' that had three slots for wires and hence tied three wires per bale. Most North American manufacturers produced these machines as either regular models or as size options. 'Small square' three wire tying pick-up balers were available from the early 1930s, principally from J. I. Case & Co. and Ann Arbor. These machines were hand tying and hand threading machines.\n\nIn the 1940s most farmers would bale hay in the field with a small tractor with 20 or less horsepower, and the tied bales would be dropped onto the ground as the baler moved through the field. Another team of workers with horses and a flatbed wagon would come by and use a sharp metal hook to grab the bale and throw it up onto the wagon while an assistant stacks the bale, for transport to the barn.\n\nA later time-saving innovation was to tow the flatbed wagon directly behind the baler, and the bale would be pushed up a ramp to a waiting attendant on the wagon. The attendant hooks the bale off the ramp and stacks it on the wagon, while waiting for the next bale to be produced.\n\nEventually, as tractor horsepower increased, the thrower-baler became possible, which eliminated the need for someone to stand on the wagon and pick up the finished bales. The first thrower mechanism used two fast-moving friction belts to grab finished bales and throw them at an angle up in the air onto the bale wagon. The bale wagon was modified from a flatbed into a three-sided skeleton frame open at the front, to act as a catcher's net for the thrown bales.\n\nAs tractor horsepower further increased, the next innovation of the thrower-baler was the hydraulic tossing baler. This employs a flat pan behind the bale knotter. As bales advance out the back of the baler, they are pushed onto the pan one at a time. When the bale has moved fully onto the pan, the pan suddenly pops up, pushed by a large hydraulic cylinder, and tosses the bale up into the wagon like a catapult.\n\nThe pan-thrower method puts much less stress on the bales compared to the belt-thrower. The friction belts of the belt-thrower stress the twine and knots as they grip the bale, and would occasionally cause bales to break apart in the thrower or when the bales landed in the wagon.\n\nBales may be picked up from the field and stacked using a self-powered machine called a \"bale stacker\", \"bale wagon\" or \"harobed\". There are several designs and sizes. One type picks up square bales are dropped by the baler with the strings facing upward. The stacker will drive up to each bale, pick it up and set it on a three-bale-wide table (the strings are now facing upwards). Once three bales are on the table, the table lifts up and back, causing the three bales to face strings to the side again; this happens three more times until there are 16 bales on the main table. This table will lift like the smaller one, and the bales will be up against a vertical table. The machine will hold 160 bales (ten tiers); usually there will be cross-tiers near the center to keep the stack from swaying or collapsing if any weight is applied to the top of the stack. The full load will be transported to a barn; the whole rear of the stacker will tilt upwards until it is vertical. There will be two pushers that will extend through the machine and hold the bottom of the stack from being pulled out from the stacker while it is driven out of the barn.\n\nIn Britain (if small square bales are still to be used), they are usually collected as they fall out of the baler in a \"bale sledge\" dragged behind the baler. This has four channels, controlled by automatic mechanical balances, catches and springs, which sort each bale into its place in a square \"eight\". When the sledge is full, a catch is tripped automatically, and a door at the rear opens to leave the eight lying neatly together on the ground. These may be picked up individually and loaded by hand, or they may be picked up all eight together by a \"bale grab\" on a tractor, a special front loader consisting of many hydraulically powered downward-pointing curved spikes. The square eight will then be stacked, either on a trailer for transport, or in a roughly cubic field stack eight or ten layers high. This cube may then be transported by a large machine attached to the three-point hitch behind a tractor, which clamps the sides of the cube and lifts it bodily.\n\nBefore electrification occurred in rural parts of the United States in the 1940s, some small dairy farms would have tractors but not electric power. Often just one neighbor who could afford a tractor would do all the baling for surrounding farmers still using horses.\n\nTo get the bales up into the hayloft, a pulley system ran on a track along the peak of the barn's hayloft. This track also stuck a few feet out the end of the loft, with a large access door under the track. On the bottom of the pulley system was a bale spear, which is pointed on the end and has retractable retention spikes.\n\nA flatbed wagon would pull up next to the barn underneath the end of the track, the spear lowered down to the wagon, and speared into a single bale. The pulley rope would be used to manually lift the bale up until it could enter the mow through the door, then moved along the track into the barn and finally released for manual stacking in tight rows across the floor of the loft. As the stack filled the loft, the bales would be lifted higher and higher with the pulleys until the hay was stacked all the way up to the peak.\n\nWhen electricity arrived, the bale spear, pulley and track system were replaced by long motorized bale conveyors known as hay elevators. A typical elevator is an open skeletal frame, with a chain that has dull spikes every few feet along the chain to grab bales and drag them along. One elevator replaced the spear track and ran the entire length of the peak of the barn. A second elevator was either installed at a 30-degree slope on the side of the barn to lift bales up to the peak elevator, or used dual front-back chains surrounding the bale to lift bales straight up the side of the barn to the peak elevator.\n\nA bale wagon pulled up next to the lifting elevator, and a farm worker placed bales one at a time onto the angled track. Once bales arrived at the peak elevator, adjustable tipping gates along the length of the peak elevator were opened by pulling a cable from the floor of the hayloft, so that bales tipped off the elevator and dropped down to the floor in different areas of the loft. This permitted a single elevator to transport hay to one part of a loft and straw to another part.\n\nThis complete hay elevator lifting, transport, and dropping system reduced bale storage labor to a single person, who simply pulls up with a wagon, turns on the elevators and starts placing bales on it, occasionally checking to make sure that bales are falling in the right locations in the loft.\n\nThe neat stacking of bales in the loft is often sacrificed for the speed of just letting them fall and roll down the growing pile in the loft, and changing the elevator gates to fill in open areas around the loose pile. But if desired, the loose bale pile dropped by the elevator could be rearranged into orderly rows between wagon loads.\n\nThe process of retrieving bales from a hayloft has stayed relatively unchanged from the beginning of baling. Typically workers were sent up into the loft, to climb up onto the bale stack, pull bales off the stack, and throw or roll them down the stack to the open floor of the loft. Once the bale is down on the floor, workers climb down the stack, open a cover over a bale chute in the floor of the loft, and push the bales down the chute to the livestock area of the barn.\n\nMost barns were equipped with several chutes along the sides and in the center of the loft floor. This permitted bales to be dropped into the area where they were to be used. Hay bales would be dropped through side chutes, to be broken up and fed to the cattle. Straw bales would be dropped down the center chute, to be distributed as bedding in the livestock standing/resting areas.\n\nTraditionally multiple bales were dropped down to the livestock floor and the twine removed by hand. After drying and being stored under tons of pressure in the haystack, most bales are tightly compacted and need to be torn apart and fluffed up for use.\n\nOne recent method of speeding up all this manual bale handling is the bale shredder, which is a large vertical drum with rotary cutting/ripping teeth at the base of the drum. The shredder is placed under the chute and several bales dropped in. A worker then pushes the shredder along the barn aisle as it rips up a bale and spews it out in a continuous fluffy stream of material.\n\nIndustrial balers are typically used to compact similar types of waste, such as office paper, Corrugated fiberboard, plastic, foil and cans, for sale to recycling companies. These balers are made of steel with a hydraulic ram to compress the material loaded. Some balers are simple and labor-intensive, but are suitable for smaller volumes. Other balers are very complex and automated, and are used where large quantities of waste are handled.\n\nUsed in recycling facilities, balers are a packaging step that allows for the aforementioned commodities to be broken down into dense cubes of one type of material at a time. There are different balers used depending on the material type. After a specific material is crushed down into a dense cube, it is tied to a bale by a thick wire and then pushed out of the machine. This process allows for easy transport of all materials involved.\n\nTwo-ram baler: A two-ram baler is a baling machine that contains two cylinders and is able to bundle and package most commodities except for cardboard and clear film. This baler is known for its durability and is able to take in more bulky material.\n\nSingle-ram baler: A single-ram baler is a baling machine that contains one cylinder. Because this baler is relatively smaller than the two-ram baler, it is best for small and medium commodities.\n\nClosed door baler: This baler bales clear plastic film.\n\nAmerican baler: This baler bales corrugated materials.\n\n\n"}
{"id": "28856182", "url": "https://en.wikipedia.org/wiki?curid=28856182", "title": "Brazi II Power Station", "text": "Brazi II Power Station\n\nThe Brazi II Power Station is a large thermal power plant located in Brazi, having 3 generation groups 50 MW each resulting a total electricity generation capacity of 150 MW.\n\n\n"}
{"id": "20497431", "url": "https://en.wikipedia.org/wiki?curid=20497431", "title": "Chasing Kangaroos", "text": "Chasing Kangaroos\n\nChasing Kangaroos: A Continent, a Scientist, and a Search for the World's Most Extraordinary Creature, is a 2007 book () by Professor Tim Flannery. The book draws on three decades of travel, research, and field work to explore Australia's kangaroo. Seventy species make up the kangaroo family, which includes wallabies and rat kangaroos.\n\nProfessor Tim Flannery is also author of \"The Weather Makers\", which received much critical acclaim.\n\n"}
{"id": "21768438", "url": "https://en.wikipedia.org/wiki?curid=21768438", "title": "Cielo Wind Power", "text": "Cielo Wind Power\n\nCielo Wind Power is an American wind power developer located in Austin, Texas. This company built it first utility-size wind project in 1998. To date, Cielo Wind Power has developed 1,149 megawatts of wind-generated electricity.\n\nCielo Wind Power has capitalized $1.4 billion and has installed 1,068 wind turbines on over with its first ten projects from 1998 to 2008. Cielo Wind Power has developed and installed 1,149 MW of wind-generated electricity throughout the Southwest. Two out of every three wind turbines installed in Texas from 1994 through 2004 were developed by Cielo.\n\nGroups honoring Cielo Wind Power’s environmental achievements are Ecology Action, Public Citizen Texas, City of Austin Environmental Board, and the Texas Renewable Energy Industries Association.\nCielo Wind Power is a member of or associated with the Texas Renewable Energy Industries Association, the American Wind Energy Association, the Electricity Reliability Council of Texas, Gulf Coast Power, the Texas Sheep and Goat Raisers Association, the Southwestern Cattleman’s Association, the National Association of Tower Erectors, and the Fort Stockton, McCamey and Ozona Chambers of Commerce.\n\n"}
{"id": "34684267", "url": "https://en.wikipedia.org/wiki?curid=34684267", "title": "Contact protection", "text": "Contact protection\n\nContact protection methods are designed to limit the wear and degradation that occur during the normal use of contacts within an electromechanical switch, relay or contactor.\n\nEvery time the contacts of an electromechanical switch, relay or contactor are opened or closed, there is a certain amount of contact wear. The sources of the wear are high current densities in microscopic areas, and the electric arc. Contact wear includes material transfer between contacts, loss of contact material due to splattering and evaporation, and oxidation or corrosion of the contacts due to high temperatures and atmospheric influences.\n\nWhile a pair of contacts is closed, only a small part of the contacts are in intimate contact due to asperities and low-conductivity films. Because of the constriction of the current to a very small area, the current density frequently becomes so high that it melts a microscopic portion of the contact. During the close-to-open (break) transition, a microscopic molten bridge forms and eventually ruptures asymmetrically, transferring contact material between contacts and increasing the surface roughness. This can also occur during the open-to-close (make) transition due to contact bounce.\n\nThe electric arc occurs between the contact points (electrodes) both during the transition from closed to open (break) and from open to closed (make) when the contact gap is small and the voltage is high enough. Heating due to arcing and high current density can melt the contact surface temporarily. If some of the melting material solidifies while the contacts are closed, the contact may stick closed due to a micro-weld, similar to spot welding.\n\nThe arc caused during the contact break (break arc) is similar to arc welding, as the break arc is typically more energetic and more destructive. The arc can cause material transfer between contacts. The arc may also be hot enough to evaporate metal from the contact surface.\n\nThe high temperatures can also cause the contact metals to more rapidly oxidize and corrode.\n\nContacts reach end of life for one of two reasons. Either the contacts fail to break because they are stuck (welded) closed, or the contacts fail to make (high resistance) because of contact corrosion or because excessive material is lost from one or both contacts. These conditions are the result of cumulative material transfer during successive switching operations, and of material loss due to evaporation and splattering.\n\nThere are additional mechanisms for stuck closed failures, such as mechanical interlocking of rough contact surfaces due to contact wear.\n\nThe degradation of the contacts can be limited by including various contact protection methods.\n\nOne method is to add electronic components such as: capacitors, snubbers, diodes, Zener diodes, transient voltage suppressors (TVS), resistors, varistors, in-rush current limiters PTC resistors, NTC resistors, voltage-dependent resistors. However, this is the least effective method as these do neither significantly influence the creation nor suppress the arc between the contacts of the electromechanical power switches, relays and contactors.\n\nA slightly more effective method is to make the contacts themselves larger, i.e., a contactor.\n\nA similar method to increasing contact size is to make the contacts out of more durable metals or metal alloys such as tungsten.\n\nThe most effective methods are to employ arc suppression circuitry including arc suppressors, solid state relays, hybrid power relays, mercury displacement relays and hybrid power contactors.\n\n"}
{"id": "18729208", "url": "https://en.wikipedia.org/wiki?curid=18729208", "title": "Craiova II Power Station", "text": "Craiova II Power Station\n\nThe Craiova II Power Station is a large thermal power plant located in Craiova, Romania, having 2 generation groups of 150 MW each having a total electricity generation capacity of 300 MW.\n\nThere are plans to add another generating group of 150 MW at Craiova II Power Station that will result a total power generating capacity of 450 MWh at a cost of US$225 million.\n\n"}
{"id": "4337289", "url": "https://en.wikipedia.org/wiki?curid=4337289", "title": "Donkey puncher", "text": "Donkey puncher\n\nA donkey puncher is the operator of a small steam donkey, a machine used in logging in the 19th and 20th centuries.\n\nA donkey consists of a steam boiler and steam engine, connected to a winch mounted on a sled called a donkey sled. The donkeys were moved by simply dragging themselves with the winch line. They were used to move logs, by attaching lines to the logs and hauling them.\n\nThe donkey puncher was the machine operator and engineer. Use of the term gained currency in 1920. In later times the donkey puncher was too far away from the end of the line for verbal communication, so whistle codes (steam whistles) were employed. The whistle operator was known as a whistle punk, who was placed between the men attaching the cables (choker setters), and the donkey puncher, so that he could see the choker setters. When the cables were attached, a series of whistle blows signaled the donkey to begin pulling and the choker setters to stay out of harm's way. This is an oversimplification of a closely orchestrated sequence of operations, where mistakes were often fatal and where good men stood in line for the jobs. Although the steam engine, and its whistle, have been replaced by gasoline and diesel engines, the whistle codes are still used in many current logging operations. The whistle has been replaced largely with airhorns.\n\n\n"}
{"id": "48483403", "url": "https://en.wikipedia.org/wiki?curid=48483403", "title": "Embilipitiya Power Station", "text": "Embilipitiya Power Station\n\nThe Embilipitiya Power Station (also sometimes referred to as Ace Power Embilipitiya) is a thermal power station in Embilipitiya, Sri Lanka. The heavy fuel oil-run power station was commissioned in March 2005, and was operated by Aitken Spence (sometimes shortened to \"Ace\"). The power station consisted of fourteen generation units of each, which consumed approximately of fuel oil per day. The Ministry of Power and Energy discontinued purchasing power from the private power station after its license expired in 2015, and hence was subsequently decommissioned. In March 2016 Ceylon Electricity Board decided to recommission the plant due to high electricity demand in the country. The facility cost approximately Rs. 8 billion to develop, and is built on a land on a 33-year lease.\n\n"}
{"id": "7839543", "url": "https://en.wikipedia.org/wiki?curid=7839543", "title": "Essentials of Post–Cold War Deterrence", "text": "Essentials of Post–Cold War Deterrence\n\nEssentials of Post–Cold War Deterrence is a document produced in 1995 as a \"Terms of Reference\" by the Policy Subcommittee of the Strategic Advisory Group (SAG) of the United States Strategic Command (current USSTRATCOM, former CINCSTRAT), a branch of the Department of Defense. The document, drafted under former Commander-in-Chief of CINCSTRAT Admiral Chiles, is to be used as a baseline for future policies and strategies in \"expanding the Deterrence of the Use of Weapons of mass destruction.\" Although originally classified, it has since been declassified and published by the Nautilus Institute.\n\nThe Introduction of the document states the following:\n\nOver the period of the Cold War, both the United States and the Soviet Union developed an understanding of deterrence and its role in preventing war with one another. With the end of the Cold War and the spread of Weapons of mass destruction, deterrence takes on a broader multinational dimension. This paper addresses the broader view of deterrence and the question, \"How do we deter nations, other than the Former Soviet Union, from using Weapons of Mass Destruction?\"\n\nThe article is notable not only for its significance in outlining current United States military strategy and foreign policy, but also for its explicit advocation of ambiguity regarding \"what is permitted\" for other nations and its endorsement of \"irrationality\", or more precisely, the perception thereof, as an important tool in deterrence and foreign policy.\n\nThe document claims that the capacity of the United States in exercising deterrence would be hurt by portraying U.S. leaders as fully rational and cool-headed, stating that: \n\n\n\n"}
{"id": "34957800", "url": "https://en.wikipedia.org/wiki?curid=34957800", "title": "Ford F-Series (eighth generation)", "text": "Ford F-Series (eighth generation)\n\nThe eighth generation of the Ford F-Series is a line of pickup trucks and light- to medium-duty commercial trucks produced by Ford from 1986 to 1991. While the 1980 cab and chassis was carried over to the new model, the 1987 model was more streamlined, and maintenance items were made simpler. The exterior was facelifted with new composite headlamps, a more aerodynamic front end, and circular fenders. Inside, the interior was given a complete redesign. Rear antilock brakes were now standard, the first pickup truck to boast this. For the first time, all models were produced with straight-sided Styleside beds; the Flareside bed was discontinued except for a small number of early 1987 models using leftover 1986 beds with new circular fenders. In 1991 Ford premiered the 9th gen tail lights (the white reverse light was decreased in size) on the last year of the 8th generation.\n\n\nFor 1991, a \"Nite\" trim package was introduced. It included all blacked-out exterior trim, either a pink or blue/purple stripe, and a \"Nite\" decal on the sides of the cargo box.\n\n\nThe new-for-1987 F-Super Duty was essentially a Class 4 truck built as a chassis cab, with an aftermarket bed (specific to its future use) added after the truck was built. The F-Super Duty came with dual fuel tanks with a dash-mounted toggle switch to switch between each tank, while using only a single fuel gauge. It came with a PTO used to power attachments, such as winches or a dump bed, directly from the transmission. F-Super Duty models were rated at about GVWR and came with either the standard 7.5 L (460 CID) gas V8 or the optional 7.3 L (444 CID) diesel V8. All wheels were 10-lug with dual wheels in the rear. This model should not be confused with the later Super Duty commercial line of trucks starting with the 1999 model year.\n\nIn a move to further update the F-Series engine lineup, the 4.9 L inline-6 was converted to fuel injection for 1987. A year later, Ford became the first pickup truck manufacturer to sell a fully non-carbureted engine lineup as the 5.8 L V8 and 7.5 L V8 also gained fuel injection(the 5.0 L V8 had gained fuel injection as an option for 1985 and was made standard in 1986). For 1988, the diesel V8 from International (Navistar) was enlarged to from 420 to 444 cubic inches (6.9 to 7.3 L); this allowed for an increase to and of torque.\n\nWhile the dated 3-speed column-mounted manual transmission was discontinued, much of the rest of the transmission lineup carried over from the 1980-1986 trucks. In 1988, the five-speed ZF S5-42 replaced the Borg-Warner T19 in F-250 and F-350 models. For the F-150 and light-duty F-250, the heavier-duty Borg-Warner T18 4-speed manual remained available, while the Mazda-built M5OD 5-speed manual was added to the model lineup for 4.9 L inline-6 and 5.0 L V8-equipped models.\n\nFour-wheel-drive improvements included the addition of automatic locking hubs for the F-150 in 1989. Models with the 5.0L V8 also had an option of a \"Touch Drive\" electronic transfer case.\n\nFrom 1980 through 1996, Ford offered a four-wheel-drive swing arm independent front suspension called Twin Traction Beam (TTB). Based on its two-wheel-drive twin I-beam suspension from 1965, Ford mounted a Dana 44 differential in the driver-side (front) axle beam and transmitted torque to the passenger-side wheel with a double U-jointed axleshaft. Radius arms and coil springs were still used on the F-150, while the four-wheel-drive F-250 and F-350 got leaf springs. The F-250 received TTB Dana 50 axles, and the F-350 a solid Dana 60 axle.\n\nEngines:\n"}
{"id": "57544206", "url": "https://en.wikipedia.org/wiki?curid=57544206", "title": "Gallatin Fossil Plant", "text": "Gallatin Fossil Plant\n\nThe Gallatin Fossil Plant is a four-unit coal-fired power plant near Gallatin, Tennessee operated by the Tennessee Valley Authority (TVA). It is one of four coal plants in the state of Tennessee, and is located adjacent to the Gallatin Combustion Turbine Plant.\n\nThe Gallatin fossil plant is located on 1,950 acres of land, and consists of four units, with a combined generating capacity of 976 megawatts (MW).\n\nGroundbreaking for the plant occurred on May 11, 1953. Unit one began operation on November 8, 1956, unit two on June 27, 1957, unit three on May 22, 1959, and unit four on August 9, 1959.\n"}
{"id": "5587151", "url": "https://en.wikipedia.org/wiki?curid=5587151", "title": "Germanium dioxide", "text": "Germanium dioxide\n\nGermanium dioxide, also called germanium oxide and germania, is an inorganic compound with the chemical formula GeO. It is the main commercial source of germanium. It also forms as a passivation layer on pure germanium in contact with atmospheric oxygen.\n\nThe two predominant polymorphs of GeO are hexagonal and tetragonal. Hexagonal GeO has the same structure as β-quartz, with germanium having coordination number 4. Tetragonal GeO (the mineral argutite) has the rutile-like structure seen in stishovite. In this motif, germanium has the coordination number 6. An amorphous (glassy) form of GeO is similar to fused silica.\n\nGermanium dioxide can be prepared in both crystalline and amorphous forms. At ambient pressure the amorphous structure is formed by a network of GeO tetrahedra. At elevated pressure up to approximately 9 GPa the germanium average coordination number steadily increases from 4 to around 5 with a corresponding increase in the Ge-O bond distance. At higher pressures, up to approximately 15 GPa, the germanium coordination number increases to 6 and the dense network structure is composed of GeO octahedra. When the pressure is subsequently reduced, the structure reverts to the tetrahedral form. At high pressure, the rutile form converts to an orthorhombic CaCl form.\n\nHeating germanium dioxide with powdered germanium at 1000 °C forms germanium monoxide (GeO).\n\nThe hexagonal (d = 4.29 g/cm3) form of germanium dioxide is more soluble than the rutile (d = 6.27 g/cm3) form and dissolves to form acid, HGeO or Ge(OH). GeO is only slightly soluble in acid but dissolves more readily in alkali to give germanates.\n\nIn contact with hydrochloric acid, it releases the volatile and corrosive germanium tetrachloride.\n\nThe refractive index (1.7) and optical dispersion properties of germanium dioxide makes it useful as an optical material for wide-angle lenses, in optical microscope objective lenses, and for the core of fiber-optic lines. See Optical fiber for specifics on the manufacturing process. Both Germanium and its glass oxide, GeO are transparent to the infrared spectrum. The glass can be manufactured into IR windows and lenses, used for night-vision technology in the military, luxury vehicles, and Thermographic cameras. GeO is preferred over other IR transparent glasses because it is mechanically strong and therefore preferred for rugged military usage.\n\nA mixture of silicon dioxide and germanium dioxide (\"silica-germania\") is used as an optical material for optical fibers and optical waveguides. Controlling the ratio of the elements allows precise control of refractive index. Silica-germania glasses have lower viscosity and higher refractive index than pure silica. Germania replaced titania as the silica dopant for silica fiber, eliminating the need for subsequent heat treatment, which made the fibers brittle.\n\nGermanium dioxide is also used as a catalyst in production of polyethylene terephthalate resin, and for production of other germanium compounds. It is used as a feedstock for production of some phosphors and semiconductor materials.\n\nGermanium dioxide is used in algaculture as an inhibitor of unwanted diatom growth in algal cultures, since contamination with the comparatively fast-growing diatoms often inhibits the growth of or outcompetes the original algae strains. GeO is readily taken up by diatoms and leads to silicon being substituted by germanium in biochemical processes within the diatoms, causing a significant reduction of the diatoms' growth rate or even their complete elimination, with little effect on non-diatom algal species. For this application, the concentration of germanium dioxide typically used in the culture medium is between 1 and 10 mg/l, depending on the stage of the contamination and the species.\n\nGermanium dioxide has low toxicity, but in higher doses it is nephrotoxic.\n\nGermanium dioxide is used as a germanium supplement in some questionable dietary supplements and \"miracle cures\". High doses of these resulted in several cases of germanium poisonings.\n"}
{"id": "677334", "url": "https://en.wikipedia.org/wiki?curid=677334", "title": "Golf cart", "text": "Golf cart\n\nA golf cart (called golf car in ANSI standard Z130.1, since \"carts\" are not self-propelled) is a small vehicle designed originally to carry two golfers and their golf clubs around a golf course or on desert trails with less effort than walking.\n\nGolf carts come in a wide range of formats and are more generally used to convey small numbers of passengers short distances at speeds less than per ANSI Standard z130.1 as originally manufactured. They are generally around wide × long × high and weigh to . Most are powered by 4-stroke engines.\n\nThe price of a golf cart can range anywhere from under US$1,000 to well over US$20,000 per cart, depending on several factors. These factors may include whether or not a fleet of carts is being purchased for a golf course or a country club, for example, and whether the carts are new or used. Other factors may include options such as equipment requirements, and how many people the cart is meant to transport. With the rise in popularity of golf carts, many golf clubs or country clubs offer storage and energy options to golf cart owners. This has led to the modification of golf carts to suit use at a particular golf course. Typical modifications include windshields, ball cleaners, cooler trays, upgraded motor or speed controller (to increase speed and/or torque), and lift kits.\n\nOriginally golf carts were only electrically powered, but in time gasoline-powered variants appeared. The electric variety is now used in many communities where their lack of pollutants, lack of noise, and safety for pedestrians and other carts (due to slow speeds) are beneficial. When purpose-built for general transportation these are called Neighborhood Electric Vehicles (NEVs), but with various operating limitations such as top speed and heavy regulation on which type of streets these types of carts are permitted to be used. These may resemble the golf carts shown above, although some are now being made with all-weather car-like bodies.\n\nThe minimum age to drive a golf cart is 13 in Georgia, Alabama, California, Kansas, Kentucky, Rhode Island, Vermont, and South Carolina. Other US states, such as Florida, have a minimum age of 14–15 years.\n\nReportedly, the first use of a motorized cart on a golf course was by JK Wadley of Texarkana, Texas/Arkansas, who saw a three-wheeled electric cart being used in Los Angeles to transport senior citizens to the grocery store. Later, he purchased a cart and found that it worked poorly on a golf course. The first electric golf cart was custom-made in 1932, but did not gain widespread acceptance. In the 1930s until the 1950s the most widespread use of golf carts was for those with disabilities who could not walk far. By the mid 1950s the golf cart had gained wide acceptance with golfers, with several manufactures (e.g. Victor Adding Machine Co. and Sears Roebuck) producing various models. Most were electric.\nMerle Williams of Long Beach, California was an early innovator of the electric golf cart. He started with knowledge gained from production of electric cars due to World War II gasoline rationing. In 1951 his Marketeer Company began production of an electric golf cart in Redlands, California. E-Z-Go began producing golf cars in 1954, Cushman in 1955, Club Car in 1958, Taylor-Dunn in 1961, Harley-Davidson in 1963, Yamaha Golf Car in 1979 and CT&T in 2002.\n\nMax Walker created the first gasoline-powered golf cart \"The Walker Executive\" in 1957. This three-wheeled vehicle was shaped with a Vespa-style front end and, like any golf cart, carried two passengers and golf bags.\n\nIn 1963 the Harley-Davidson Motor Company began producing golf carts. Over the years they manufactured and distributed thousands of three- and four-wheeled gasoline-powered and electric vehicles that are still highly sought after. The iconic three-wheeled cart, with either a steering wheel or a tiller-based steering control, boasted a reversible two-stroke engine similar to one used today in some high-end snowmobiles. (The engine runs clockwise in forward mode.) In 1982 Harley Davidson sold the production of golf carts to the Columbia Car Company. Many of these gems survive today, and are the prized possessions of proud owners, restorers, and collectors worldwide.\n\nNew technology such as the SoloRider, an adaptive golf cart designed for a single user, is allowing disabled persons access to the golf course and the game itself. The cart’s seat swivels around, extends to an upright position, and allows the golfer to stand upright, be supported, and swing using both hands.\n\nGolf carts are now taking on an extreme nature, being highly modified from their original configuration to perform similar to the growing popularity of the Side by Side (UTV). Modifications as minor as suspension upgrades are commonplace, while entire redesigns may include axles and an engine from a full size automobile.\nSolar-powered golf carts are an alternative to gas or regular charged electric golf cart. While this technology is still new and not as efficient as gas or electric, it is becoming more and more popular. In 2014, citEcar built and tested a solar-powered street-legal golf cart that will travel 105 miles on a single charge.\n\nOne of the most recent developments in golf cart technology is the GolfBoard, a golf cart that is inspired by the skateboard. The GolfBoard is driven by front and back gear boxes providing power to all four wheels. The golfer controls the cart in a standing upright position as if riding skateboard, leaning left or right to make turns. The GolfBoard has been well received by the golfing community, as it speeds up play and, according to the manufacturers, has up to 75% less impact on turf than traditional golf carts. In 2014 the GolfBoard was voted the Best New Product at the PGA Show.\n\nPeachtree City, Georgia has many miles of golf cart paths that link the city together. Golf cart travel is used by a great majority of the community, especially among high school students. McIntosh High School even has a student golf cart parking lot on campus.\n\nOn islands (such as Santa Catalina Island, California, Bald Head Island, North Captiva Island, North Carolina, and Hamilton Island), motor vehicles are sometimes restricted and residents use golf carts instead.\n\nThe Villages, Florida, a retirement community of over 70,000 people, has an extensive golf cart trail system (estimated at around ) and also allows golf carts on many streets. It is the most popular form of transportation in this community.\n\nOn the tropical islands of Belize golf carts are a major form of road transport and can be rented by tourists.\n\nThe residential community of Discovery Bay, Hong Kong does not allow the use of private vehicles apart from a fleet of 520 golf carts \"(excluding the ones operating exclusively in the Golf or the Marina Clubs)\". The remainder of the 20,000 residents rely on a mixture of shuttle buses and hire cars to travel around the township.\n\nThe Palm Springs Area in California contains multiple golf cart communities including PGA West, The Madison Club, The Hideaway, and many other golf course/golf cart communities. The PGA Tour is held at PGA West every January.\n\nAlong with the rising frequency of golf cart crashes, the number of golf-cart-related injuries has increased significantly over the last decade. A study conducted by researchers in the Center for Injury Research and Policy of The Research Institute at the Nationwide Children's Hospital found that the number of golf cart-related injuries rose 132% during the 17-year study period. According to the study, published in the July 2008 issue of the American Journal of Preventive Medicine, there were an estimated 148,000 golf cart-related injuries between 1990 and 2006, ranging from an estimated 5,770 cases in 1990 to approximately 13,411 cases in 2006. More than 30% of golf cart-related injuries involved children under the age of 16.\n\nThe most common type of injury was soft tissue damage, usually just bruises, followed by fractures, constituting 22.3% of the cases, and lacerations, accounting for 15.5% of injuries. Other types of injuries include concussions, internal injuries, subdural hematoma, spinal cord injury, or acute respiratory compromise. While rare, a few cases had severe outcomes: 4 fatalities, 2 paraplegic, and 1 quadriplegic injuries have been documented.\n\nSome of the main causes of injury related to golf cart accidents included cart overturn, falling/jumping from a moving golf cart, collision with another vehicle or stationary object, struck/run over by a cart, getting into or out of a moving cart. Out of all these, \"falling or jumping from a golf cart\" was the most common cause of injury for both adults and children.\n\nOne contributing reason is that current golf cart safety features are insufficient to prevent passenger falls or ejection. Golf carts moving at speeds as low as could readily eject a passenger during a turn. Furthermore, rear-facing golf cart seats are associated with high rates of passenger ejection during fast acceleration, and most standard (stock) golf carts do not have brakes on all four wheels (typically brakes are only on the rear wheels, thus sharply limiting their braking power).\n\nGolf cart injuries are also commonly found in desert areas (e.g. Johnson Valley, California). Driving golf carts on bumpy dirt trails, along cliffs, down rocky trails that should only be traversed using 4-wheel-drive vehicles, can all lead to injuries.\n\nIn 2014, Arizona Governor Jan Brewer signed a law permitting golf cart drivers to drive as close to the right-hand edge of the roadway as possible. Prior to the passage of the law, golf cart drivers received traffic tickets for failing to drive in the center of the roadway. Complementing the new law, a golf cart safety education program was initiated.\n\n"}
{"id": "7371308", "url": "https://en.wikipedia.org/wiki?curid=7371308", "title": "Graphical timeline from Big Bang to Heat Death", "text": "Graphical timeline from Big Bang to Heat Death\n\nThis is the timeline of the Universe from Big Bang to Heat Death scenario. The different eras of the universe are shown. The heat death will occur in 10</sup> years, if protons decay.\n\nUsually the logarithmic scale is used for such timelines but it compresses the most interesting Stelliferous Era too much as this example shows. Therefore, a double-logarithmic scale \"s\" (\"s*100\" in the graphics) is used instead. The minimum of it is only 1, not 0 as needed, and the negative outputs for inputs smaller than 10 are useless. Therefore, the time from 0.1 to 10 years is collapsed to a single point 0, but that does not matter in this case because nothing special happens in the history of the universe during that time.\n\nThe seconds in the timescale have been converted to years by formula_2 using the Julian year.\n"}
{"id": "9106586", "url": "https://en.wikipedia.org/wiki?curid=9106586", "title": "Horseshoe vortex", "text": "Horseshoe vortex\n\nThe horseshoe vortex model is a simplified representation of the vortex system of a wing. In this model the wing vorticity is modelled by a bound vortex of constant circulation, travelling with the wing, and two trailing wingtip vortices, therefore having a shape vaguely reminiscent of a horseshoe. A starting vortex is shed as the wing begins to move through the fluid, which dissipates under the action of viscosity, as do the trailing vortices far behind the aircraft.\n\nThe trailing wingtip vortices are responsible for the component of the downwash which creates induced drag.\n\nThe horseshoe vortex model is unrealistic in that it implies uniform circulation (and hence, according to the Kutta–Joukowski theorem, uniform lift) at all sections on the wingspan. In a more realistic model, the lifting-line theory, the vortex strength varies along the wingspan, and the loss in vortex strength is shed as a vortex \"sheet\" all along the trailing edge, rather than as a single trail at the wing-tips. Nevertheless, the simpler horseshoe vortex model used with a reduced effective wingspan but same mid-plane circulation provides an adequate model for the flows induced far from the aircraft.\n\nThe term horseshoe vortex is also used in wind engineering to describe the flow pattern created by strong winds around the base of a tall building. This effect is amplified by the presence of a low-rise building just upwind. This effect was studied at the UK Building Research Establishment between 1963 and 1973 and the cause of the effect is described in contemporary wind engineering text books.\n\nIn hydrodynamics, a form of horseshoe vortex forms around bluff bodies in the flowing water, for instance around bridge piers. They can cause scouring of bed materials from both upstream and downstream of the pier.\n\nIn nature, a horseshoe vortex can cause a horseshoe cloud to form.\n\n\n"}
{"id": "466716", "url": "https://en.wikipedia.org/wiki?curid=466716", "title": "Hundredweight", "text": "Hundredweight\n\nThe hundredweight (abbreviation: cwt), formerly also known as the centum weight or quintal, is an English, imperial, and US customary unit of weight or mass of various values. Its present value continues to differ between the American and imperial systems. The two values are distinguished in American English as the \"short\" and \"long\" hundredweight and in British English as the \"cental\" and the \"imperial hundredweight\".\n\n\nUnder both conventions, there are 20 hundredweight in a ton, producing a \"short ton\" of 2000 lb and a \"long ton\" of 2240 lb.\n\nThe hundredweight has had many different values. In England in around 1300, various different \"hundreds\" (\"centem\" in Medieval Latin) were defined. The Weights and Measures Act of 1835 formally established the present imperial hundredweight of 112 lb. The use in trade of measures by \"cental\", \"hundredweight\", or \"quintal\" have now been banned in the United Kingdom under the Weights and Measures Act of 1985.\n\nThe United States and Canada came to use the term \"hundredweight\" to refer to a unit of 100 lb. This measure was specifically banned from British use—upon risk of being sued for fraud—by the Weights and Measures Act of 1824 but, in 1879, the measure was legalized under the name \"cental\" in response to legislative pressure from British merchants importing wheat and tobacco from the United States.\n\nThe short hundredweight is commonly used in the US in the sale of livestock and some cereal grains and oilseeds, paper, and concrete additives and on some commodities in futures exchanges.\n\nA few decades ago, commodities weighed in terms of long hundredweight included cattle, cattle fodder, fertilizers, coal, some industrial chemicals, other industrial materials, and so on. However, since increasing metrication in most English-speaking countries, it is now less used. Church bell ringers use the unit commonly, although church bell manufacturers are increasingly moving over to the metric system.\n\nOlder blacksmiths' anvils are often stamped with a three-digit number indicating their total weight in hundredweight, quarter-hundredweight (28 lb), and pounds. Thus, an anvil stamped \"1.1.8\" will weigh 148 lb (112 lb + 28 lb + 8 lb).\n\nThe Imperial hundredweight is used as a measure of vehicle weight in the Bailiwick of Guernsey, although it was redefined as exactly 50.8kg in 1991.\n\n"}
{"id": "18093768", "url": "https://en.wikipedia.org/wiki?curid=18093768", "title": "Hybrid sulfur cycle", "text": "Hybrid sulfur cycle\n\nThe hybrid sulfur cycle (HyS) is a two-step water-splitting process intended to be used for hydrogen production. Based on sulfur oxidation and reduction, it is classified as a hybrid thermochemical cycle because it uses an electrochemical (instead of a thermochemical) reaction for one of the two steps. The remaining thermochemical step is shared with the sulfur-iodine cycle.\n\nThe HyS cycle was initially proposed and developed by Westinghouse Electric Corp. in the 1970s, so it is also known as the \"Westinghouse\" cycle. Current development efforts in the United States are being led by the Savannah River National Laboratory.\n\nThe two reactions in the HyS cycle are as follows:\n\nSulfur dioxide acts to depolarize the anode of the electrolyzer. This results in a significant decrease in the reversible cell potential (and, therefore, the electric power requirement) for reaction (2). The standard cell potential for reaction (2) is -0.158 V at 298.15 K, compared to -1.229 V for the electrolysis of water (with oxygen evolution as the anodic reaction).\n\n"}
{"id": "261362", "url": "https://en.wikipedia.org/wiki?curid=261362", "title": "ITER", "text": "ITER\n\nITER (\"International Thermonuclear Experimental Reactor\") is an international nuclear fusion research and engineering megaproject, which will be the world's largest magnetic confinement plasma physics experiment. It is an experimental tokamak nuclear fusion reactor that is being built next to the Cadarache facility in Saint-Paul-lès-Durance, in Provence, southern France.\n\nITER was proposed in 1987 and designed as the International Thermonuclear Experimental Reactor, according to the \"ITER Technical Basis,\" published by the International Atomic Energy Agency, in 2002. By 2005, the ITER organization abandoned the original meaning of the acronym \"iter\", and instead adopted a new meaning, the Latin word for \"the way.\"\n\nThe ITER thermonuclear fusion reactor has been designed to produce a fusion plasma equivalent to 500 megawatts (MW) of thermal output power for around twenty minutes while 50 megawatts of thermal power are injected into the tokamak, resulting in a ten-fold gain of plasma heating power. \nThereby the machine aims to demonstrate the principle of producing more thermal power from the fusion process than is used to heat the plasma, something that has not yet been achieved in any fusion reactor. \nThe total electricity consumed by the reactor and facilities will range from 110 MW up to 620 MW peak for 30-second periods during plasma operation.\nThermal-to-electric conversion is not included in the design because ITER will not produce sufficient power for net electrical production. The emitted heat from the fusion reaction will be vented to the atmosphere. \n\nThe project is funded and run by seven member entities—the European Union, India, Japan, China, Russia, South Korea, and the United States. The EU, as host party for the ITER complex, is contributing about 45 percent of the cost, with the other six parties contributing approximately 9 percent each.\nIn 2016 the ITER organization signed a technical cooperation agreement with the national nuclear fusion agency of Australia, enabling this country access to research results of ITER in exchange for construction of selected parts of the ITER machine.\n\nConstruction of the ITER Tokamak complex started in 2013 and the building costs are now over US$14 billion as of June 2015. The facility is expected to finish its construction phase in 2025 and will start commissioning the reactor that same year. Initial plasma experiments are scheduled to begin in 2025, with full deuterium–tritium fusion experiments starting in 2035. If ITER becomes operational, it will become the largest magnetic confinement plasma physics experiment in use with a plasma volume of 840 cubic meters, surpassing the Joint European Torus by almost a factor of 10.\n\nThe goal of ITER is to demonstrate the scientific and technological feasibility of fusion energy for peaceful use.\nIt is the latest and largest of more than 100 fusion reactors built since the 1950s.\nITER's planned successor, DEMO, is expected to be the first fusion reactor to produce electricity in an experimental environment. \nDEMO's anticipated success is expected to lead to full-scale electricity-producing fusion power stations and future commercial reactors.\n\nFusion power has the potential to provide sufficient energy to satisfy mounting demand, and to do so sustainably, with a relatively small impact on the environment.\n\nNuclear fusion has many potential attractions. Firstly, its hydrogen isotope fuels are relatively abundant – one of the necessary isotopes, deuterium, can be extracted from seawater, while the other fuel, tritium, would be bred from a lithium blanket using neutrons produced in the fusion reaction itself. Furthermore, a fusion reactor would produce virtually no CO or atmospheric pollutants, and its radioactive waste products would mostly be very short-lived compared to those produced by conventional nuclear reactors.\n\nOn 21 November 2006, the seven participants formally agreed to fund the creation of a nuclear fusion reactor. The program is anticipated to last for 30 years – 10 for construction, and 20 of operation. ITER was originally expected to cost approximately €5 billion, but the rising price of raw materials and changes to the initial design have seen that amount almost triple to €13 billion. The reactor is expected to take 10 years to build with completion scheduled for 2019. Site preparation has begun in Cadarache, France, and procurement of large components has started.\n\nWhen supplied with 300 MW of electrical power, ITER is expected to produce the equivalent of 500 MW of thermal power sustained for up to 1,000 seconds. This compares to JET's consumption of 700 MW of electrical power and peak thermal output of 16 MW for less than a second) by the fusion of about 0.5 g of deuterium/tritium mixture in its approximately 840 m reactor chamber. The heat produced in ITER will not be used to generate any electricity because after accounting for losses and the 300 MW minimum power input, the \noutput will be equivalent to a zero (net) power reactor.\n\nITER began in 1985 as a Reagan–Gorbachev initiative with the equal participation of the Soviet Union, the European Atomic Energy Community, the United States, and Japan through the 1988–1998 initial design phases. Preparations for the first Gorbachev-Reagan Summit showed that there were no tangible agreements in the works for the summit.\n\nOne energy research project, however, was being considered quietly by two physicists, Alvin Trivelpiece and Evgeny Velikhov. The project involved collaboration on the next phase of magnetic fusion research — the construction of a demonstration model. At the time, magnetic fusion research was ongoing in Japan, Europe, the Soviet Union and the US. Velikhov and Trivelpiece believed that taking the next step in fusion research would be beyond the budget of any of the key nations and that collaboration would be useful internationally.\n\nA major bureaucratic fight erupted in the US government over the project. One argument against collaboration was that the Soviets would use it to steal US technology and know-how. A second was symbolic — the Soviet physicist Andrei Sakharov was in internal exile and the US was pushing the Soviet Union on its human rights record. The United States National Security Council convened a meeting under the direction of William Flynn Martin that resulted in a consensus that the US should go forward with the project.\n\nMartin and Velikhov concluded the agreement that was agreed at the summit and announced in the last paragraph of this historic summit meeting, \"... The two leaders emphasized the potential importance of the work aimed at utilizing controlled thermonuclear fusion for peaceful purposes and, in this connection, advocated the widest practicable development of international cooperation in obtaining this source of energy, which is essentially inexhaustible, for the benefit for all mankind.\"\n\nConceptual and engineering design phases carried out under the auspices of the IAEA led to an acceptable, detailed design in 2001, underpinned by US$650 million worth of research and development by the \"ITER Parties\" to establish its practical feasibility. These parties, namely EU, Japan, Russian Federation (replacing the Soviet Union), and United States (which opted out of the project in 1999 and returned in 2003), were joined in negotiations by China, South Korea, and Canada (who then terminated its participation at the end of 2003). India officially became part of ITER in December 2005.\n\nOn 28 June 2005, it was officially announced that ITER would be built in the European Union in Southern France. The negotiations that led to the decision ended in a compromise between the EU and Japan, in that Japan was promised 20% of the research staff on the French location of ITER, as well as the head of the administrative body of ITER. In addition, another research facility for the project will be built in Japan, and the European Union has agreed to contribute about 50% of the costs of this institution.\n\nOn 21 November 2006, an international consortium signed a formal agreement to build the reactor. On 24 September 2007, the People's Republic of China became the seventh party to deposit the ITER Agreement to the IAEA. Finally, on 24 October 2007, the ITER Agreement entered into force and the ITER Organization legally came into existence.\n\nITER's mission is to demonstrate the feasibility of fusion power, and prove that it can work without negative impact. Specifically, the project aims to:\n\nIn 1978, the European Commission, Japan, United States, and USSR joined in the International Tokamak Reactor (INTOR) Workshop, under the auspices of the International Atomic Energy Agency (IAEA), to assess the readiness of magnetic fusion to move forward to the experimental power reactor (EPR) stage, to identify the additional R&D that must be undertaken, and to define the characteristics of such an EPR by means of a conceptual design. Hundreds of fusion scientists and engineers in each participating country took part in a detailed assessment of the then present status of the tokamak confinement concept vis-a-vis the requirements of an EPR, identified the required R&D by early 1980, and produced a conceptual design by mid-1981.\n\nIn 1985, at the Geneva summit meeting in 1985, Mikhail Gorbachev suggested to Ronald Reagan that the two countries jointly undertake the construction of a tokamak EPR as proposed by the INTOR Workshop. The ITER project was initiated in 1988.\n\nWhen deuterium and tritium fuse, two nuclei come together to form a helium nucleus (an alpha particle), and a high-energy neutron.\nWhile nearly all stable isotopes lighter on the periodic table than iron-56 and nickel-62, which have the highest binding energy per nucleon, will fuse with some other isotope and release energy, deuterium and tritium are by far the most attractive for energy generation as they require the lowest activation energy (thus lowest temperature) to do so, while producing among the most energy per unit weight.\n\nAll proto- and mid-life stars radiate enormous amounts of energy generated by fusion processes. Mass for mass, the deuterium–tritium fusion process releases roughly three times as much energy as uranium-235 fission, and millions of times more energy than a chemical reaction such as the burning of coal. It is the goal of a fusion power station to harness this energy to produce electricity.\n\nActivation energies for fusion reactions are generally high because the protons in each nucleus will tend to strongly repel one another, as they each have the same positive charge. A heuristic for estimating reaction rates is that nuclei must be able to get within 100 femtometers (1 × 10 meter) of each other, where the nuclei are increasingly likely to undergo quantum tunneling past the electrostatic barrier and the turning point where the strong nuclear force and the electrostatic force are equally balanced, allowing them to fuse. In ITER, this distance of approach is made possible by high temperatures and magnetic confinement.\nHigh temperatures give the nuclei enough energy to overcome their electrostatic repulsion (see Maxwell–Boltzmann distribution). For deuterium and tritium, the optimal reaction rates occur at temperatures on the order of 100,000,000 K. The plasma is heated to a high temperature by ohmic heating (running a current through the plasma). Additional heating is applied using neutral beam injection (which cross magnetic field lines without a net deflection and will not cause a large electromagnetic disruption) and radio frequency (RF) or microwave heating.\n\nAt such high temperatures, particles have a large kinetic energy, and hence velocity. If unconfined, the particles will rapidly escape, taking the energy with them, cooling the plasma to the point where net energy is no longer produced. A successful reactor would need to contain the particles in a small enough volume for a long enough time for much of the plasma to fuse.\nIn ITER and many other magnetic confinement reactors, the plasma, a gas of charged particles, is confined using magnetic fields. A charged particle moving through a magnetic field experiences a force perpendicular to the direction of travel, resulting in centripetal acceleration, thereby confining it to move in a circle or helix around the lines of magnetic flux.\n\nA solid confinement vessel is also needed, both to shield the magnets and other equipment from high temperatures and energetic photons and particles, and to maintain a near-vacuum for the plasma to populate.\nThe containment vessel is subjected to a barrage of very energetic particles, where electrons, ions, photons, alpha particles, and neutrons constantly bombard it and degrade the structure. The material must be designed to endure this environment so that a power station would be economical. Tests of such materials will be carried out both at ITER and at IFMIF (International Fusion Materials Irradiation Facility).\n\nOnce fusion has begun, high energy neutrons will radiate from the reactive regions of the plasma, crossing magnetic field lines easily due to charge neutrality (see neutron flux). Since it is the neutrons that receive the majority of the energy, they will be ITER's primary source of energy output. Ideally, alpha particles will expend their energy in the plasma, further heating it.\n\nBeyond the inner wall of the containment vessel one of several test blanket modules will be placed. These are designed to slow and absorb neutrons in a reliable and efficient manner, limiting damage to the rest of the structure, and breeding tritium for fuel from lithium-bearing ceramic pebbles contained within the blanket module following the following reactions:\n\nwhere the reactant neutron is supplied by the D-T fusion reaction.\n\nEnergy absorbed from the fast neutrons is extracted and passed into the primary coolant. This heat energy would then be used to power an electricity-generating turbine in a real power station; in ITER this generating system is not of scientific interest, so instead the heat will be extracted and disposed of.\n\nThe vacuum vessel is the central part of the ITER machine: a double walled steel container in which the plasma is contained by means of magnetic fields.\n\nThe ITER vacuum vessel will be twice as large and 16 times as heavy as any previously manufactured fusion vessel: each of the nine torus shaped sectors will weigh between 390 and 430 tonnes. When all the shielding and port structures are included, this adds up to a total of 5,116 tonnes. Its external diameter will measure , the internal . Once assembled, the whole structure will be high.\n\nThe primary function of the vacuum vessel is to provide a hermetically sealed plasma container. Its main components are the main vessel, the port structures and the supporting system. The main vessel is a double walled structure with poloidal and toroidal stiffening ribs between shells to reinforce the vessel structure. These ribs also form the flow passages for the cooling water. The space between the double walls will be filled with shield structures made of stainless steel. The inner surfaces of the vessel will act as the interface with breeder modules containing the breeder blanket component. These modules will provide shielding from the high-energy neutrons produced by the fusion reactions and some will also be used for tritium breeding concepts.\n\nThe vacuum vessel has 18 upper, 17 equatorial and 9 lower ports that will be used for remote handling operations, diagnostic systems, neutral beam injections and vacuum pumping.\n\nOwing to very limited terrestrial resources of tritium, a key component of the ITER reactor design is the breeder blanket. This component, located adjacent to the vacuum vessel, serves to produce tritium through reaction with neutrons from the plasma. There are several reactions that produce tritium within the blanket. produces tritium via n,t reactions with moderated neutrons, produces tritium via interactions with higher energy neutrons via n,nt reactions. Concepts for the breeder blanket include helium cooled lithium lead (HCLL) and helium cooled pebble bed (HCPB) methods. Six different Test Blanket Modules (TBM) will be tested in ITER and will share a common box geometry. Materials for use as breeder pebbles in the HCPB concept include lithium metatitanate and lithium orthosilicate. Requirements of breeder materials include good tritium production and extraction, mechanical stability and low activation levels.\n\nThe central solenoid coil will use superconducting niobium-tin to carry 46 kA and produce a field of up to 13.5 teslas.\nThe 18 toroidal field coils will also use niobium-tin. At their maximum field strength of 11.8 teslas, they will be able to store 41 gigajoules. They have been tested at a record 80 kA. Other lower field ITER magnets (PF and CC) will use niobium-titanium for their superconducting elements. As of now the in-wall shielding blocks to protect the magnets from high energy neutrons are being manufactured and transported from the Avasarala technologies in Bangalore India to the ITER center.\n\nThere will be three types of external heating in ITER: \n\nThe cryostat is a large 3,800-tonne stainless steel structure surrounding the vacuum vessel and the superconducting magnets, in order to provide a super-cool vacuum environment. Its thickness ranging from will allow it to withstand the atmospheric pressure on the area of a volume of 8,500 cubic meters. The total of 54 modules of the cryostat will be engineered, procured, manufactured, and installed by Larsen & Toubro Heavy Engineering.\n\nThe ITER tokamak will use three interconnected cooling systems. Most of the heat will be removed by a primary water cooling loop, itself cooled by water through a heat exchanger within the tokamak building's secondary confinement. The secondary cooling loop will be cooled by a larger complex, comprising a cooling tower, a pipeline supplying water from Canal de Provence, and basins that allow cooling water to be cooled and tested for chemical contamination and tritium before being released into the Durance River. This system will need to dissipate an average power of during the tokamak's operation. A liquid nitrogen system will provide a further of cooling to , and a liquid helium system will provide of cooling to . The liquid helium system will be designed, manufactured, installed and commissioned by Air Liquide.\n\nThe process of selecting a location for ITER was long and drawn out. The most likely sites were Cadarache in Provence-Alpes-Côte-d'Azur, France, and Rokkasho, Aomori, Japan. Additionally, Canada announced a bid for the site in Clarington in May 2001, but withdrew from the race in 2003. Spain also offered a site at Vandellòs on 17 April 2002, but the EU decided to concentrate its support solely behind the French site in late November 2003. From this point on, the choice was between France and Japan. On 3 May 2005, the EU and Japan agreed to a process which would settle their dispute by July.\n\nAt the final meeting in Moscow on 28 June 2005, the participating parties agreed to construct ITER at Cadarache in Provence-Alpes-Côte-d'Azur, France. Construction of the ITER complex began in 2007, while assembly of the tokamak itself was scheduled to begin in 2015.\n\nFusion for Energy, the EU agency in charge of the European contribution to the project, is located in Barcelona, Spain. Fusion for Energy (F4E) is the European Union's Joint Undertaking for ITER and the Development of Fusion Energy. According to the agency's website: F4E is responsible for providing Europe's contribution to ITER, the world's largest scientific partnership that aims to demonstrate fusion as a viable and sustainable source of energy. [...] F4E also supports fusion research and development initiatives [...]\n\nThe ITER Neutral Beam Test Facility aimed at developing and optimizing the neutral beam injector prototype, is being constructed in Padova, Italy. It will be the only ITER facility out of the site in Cadarache.\n\nCurrently there are seven parties participating in the ITER program: the European Union (through the legally distinct organisation Euratom), India, Japan, China, Russia, South Korea, and the United States. Canada was previously a full member, but has since pulled out due to a lack of funding from the federal government. The lack of funding also resulted in Canada withdrawing from its bid for the ITER site in 2003. The host member of the ITER project, and hence the member contributing most of the costs, is the EU.\n\nIn 2007, it was announced that participants in the ITER will consider Kazakhstan's offer to join the program and in March 2009, Switzerland, an associate member of Euratom since 1979, also ratified the country's accession to the European Domestic Agency Fusion for Energy as a third country member. \nThe Prime Minister of the United Kingdom announced on 20 March 2017 that the UK will be withdrawing from Euratom and future involvement in the project is unclear. The future of the Joint European Torus project, which is located in the UK, is also not certain. Some type of associate membership in Euratom is considered a likely scenario, possibly similar to Switzerland. In 2016, ITER announced a partnership with Australia for \"technical cooperation in areas of mutual benefit and interest\", but without Australia becoming a full member.\n\nITER's work is supervised by the ITER Council, which has the authority to appoint senior staff, amend regulations, decide on budgeting issues, and allow additional states or organizations to participate in ITER. The current Chairman of the ITER Council is Won Namkung, and the ITER Director-General is Bernard Bigot.\n\nAs of 2016, the total price of constructing the experiment is expected to be in excess of €20 billion, an increase of €4.6 billion of its 2010 estimate, and of €9.6 billion from the 2009 estimate. Prior to that, the proposed costs for ITER were €5 billion for the construction and €5 billion for maintenance and the research connected with it during its 35-year lifetime. At the June 2005 conference in Moscow the participating members of the ITER cooperation agreed on the following division of funding contributions: 45% by the hosting member, the European Union, and the rest split between the non-hosting members – China, India, Japan, South Korea, the Russian Federation and the USA. During the operation and deactivation phases, Euratom will contribute to 34% of the total costs.\n\nAlthough Japan's financial contribution as a non-hosting member is one-eleventh of the total, the EU agreed to grant it a special status so that Japan will provide for two-elevenths of the research staff at Cadarache and be awarded two-elevenths of the construction contracts, while the European Union's staff and construction components contributions will be cut from five-elevenths to four-elevenths.\n\nIt was reported in December 2010 that the European Parliament had refused to approve a plan by member states to reallocate €1.4 billion from the budget to cover a shortfall in ITER building costs in 2012–13. The closure of the 2010 budget required this financing plan to be revised, and the European Commission (EC) was forced to put forward an ITER budgetary resolution proposal in 2011.\n\nThe U.S. withdrew from the ITER consortium in 2000. In 2006, Congress voted to rejoin, and again contribute financially.\n\nA technical concern is that the 14 MeV neutrons produced by the fusion reactions will damage the materials from which the reactor is built. Research is in progress to determine whether and how reactor walls can be designed to last long enough to make a commercial power station economically viable in the presence of the intense neutron bombardment. The damage is primarily caused by high energy neutrons knocking atoms out of their normal position in the crystal lattice. A related problem for a future commercial fusion power station is that the neutron bombardment will induce radioactivity in the reactor material itself. Maintaining and decommissioning a commercial reactor may thus be difficult and expensive. Another problem is that superconducting magnets are damaged by neutron fluxes. A new special research facility, IFMIF, is planned to investigate this problem.\n\nAnother source of concern comes from the 2013 tokamak parameters database interpolation which says that power load on tokamak divertors will be five times the expected value for ITER and much more for actual electricity-generating reactors. Given that the projected power load on the ITER divertor is already very high, these new findings mean that new divertor designs should be urgently tested. However, the corresponding test facility (ADX) has not received any funding .\n\nA number of fusion researchers working on non-tokamak systems, such as Robert Bussard and Eric Lerner, have been critical of ITER for diverting funding from what they believe could be a potentially more viable and/or cost-effective path to fusion power, such as the polywell reactor.\nMany critics accuse ITER researchers of being unwilling to face up to the technical and economic potential problems posed by tokamak fusion schemes. The expected cost of ITER has risen from US$5 billion to US$20 billion, and the timeline for operation at full power was moved from the original estimate of 2016 to 2027.\n\nA French association including about 700 anti-nuclear groups, Sortir du nucléaire (Get Out of Nuclear Energy), claimed that ITER was a hazard because scientists did not yet know how to manipulate the high-energy deuterium and tritium hydrogen isotopes used in the fusion process.\n\nRebecca Harms, Green/EFA member of the European Parliament's Committee on Industry, Research and Energy, said: \"In the next 50 years, nuclear fusion will neither tackle climate change nor guarantee the security of our energy supply.\" Arguing that the EU's energy research should be focused elsewhere, she said: \"The Green/EFA group demands that these funds be spent instead on energy research that is relevant to the future. A major focus should now be put on renewable sources of energy.\" French Green party lawmaker Noël Mamère claims that more concrete efforts to fight present-day global warming will be neglected as a result of ITER: \"This is not good news for the fight against the greenhouse effect because we're going to put ten billion euros towards a project that has a term of 30–50 years when we're not even sure it will be effective.\"\n\nITER is not designed to produce electricity, but made as a proof of concept reactor for the later DEMO project.\n\nProponents believe that much of the ITER criticism is misleading and inaccurate, in particular the allegations of the experiment's \"inherent danger.\" The stated goals for a commercial fusion power station design are that the amount of radioactive waste produced should be hundreds of times less than that of a fission reactor, and that it should produce no long-lived radioactive waste, and that it is impossible for any such reactor to undergo a large-scale runaway chain reaction. A direct contact of the plasma with ITER inner walls would contaminate it, causing it to cool immediately and stop the fusion process. In addition, the amount of fuel contained in a fusion reactor chamber (one half gram of deuterium/tritium fuel) is only sufficient to sustain the fusion burn pulse from minutes up to an hour at most, whereas a fission reactor usually contains several years' worth of fuel.\nMoreover, some detritiation systems will be implemented, so that at a fuel cycle inventory level of about , ITER will eventually need to recycle large amounts of tritium and at turnovers orders of magnitude higher than any preceding tritium facility worldwide.\n\nIn the case of an accident (or sabotage), it is expected that a fusion reactor would release far less radioactive pollution than would an ordinary fission nuclear station. Furthermore, ITER's type of fusion power has little in common with nuclear weapons technology, and does not produce the fissile materials necessary for the construction of a weapon. Proponents note that large-scale fusion power would be able to produce reliable electricity on demand, and with virtually zero pollution (no gaseous CO, SO, or NO by-products are produced).\n\nAccording to researchers at a demonstration reactor in Japan, a fusion generator should be feasible in the 2030s and no later than the 2050s. Japan is pursuing its own research program with several operational facilities that are exploring several fusion paths.\n\nIn the United States alone, electricity accounts for US$210 billion in annual sales. Asia's electricity sector attracted US$93 billion in private investment between 1990 and 1999. These figures take into account only current prices. Proponents of ITER contend that an investment in research now should be viewed as an attempt to earn a far greater future return. Also, worldwide investment of less than US$1 billion per year into ITER is not incompatible with concurrent research into other methods of power generation, which in 2007 totaled US$16.9 billion.\n\nSupporters of ITER emphasize that the only way to test ideas for withstanding the intense neutron flux is to experimentally subject materials to that flux, which is one of the primary missions of ITER and the IFMIF, and both facilities will be vitally important to that effort. The purpose of ITER is to explore the scientific and engineering questions that surround potential fusion power stations. It is nearly impossible to acquire satisfactory data for the properties of materials expected to be subject to an intense neutron flux, and burning plasmas are expected to have quite different properties from externally heated plasmas. Supporters contend that the answer to these questions requires the ITER experiment, especially in the light of the monumental potential benefits.\n\nFurthermore, the main line of research via tokamaks has been developed to the point that it is now possible to undertake the penultimate step in magnetic confinement plasma physics research with a self-sustained reaction. In the tokamak research program, recent advances devoted to controlling the configuration of the plasma have led to the achievement of substantially improved energy and pressure confinement, which reduces the projected cost of electricity from such reactors by a factor of two to a value only about 50% more than the projected cost of electricity from advanced light-water reactors. In addition, progress in the development of advanced, low activation structural materials supports the promise of environmentally benign fusion reactors and research into alternate confinement concepts is yielding the promise of future improvements in confinement. Finally, supporters contend that other potential replacements to the fossil fuels have environmental issues of their own. Solar, wind, and hydroelectric power all have a relatively low power output per square kilometer compared to ITER's successor DEMO which, at 2,000 MW, would have an energy density that exceeds even large fission power stations.\n\nPrecursors to ITER were EAST, KSTAR, JET, and Tore Supra.\nOther planned and proposed fusion reactors include DEMO, Wendelstein 7-X, NIF, HiPER, and MAST, as well as CFETR (China Fusion Engineering Test Reactor), a tokamak.\n\n\n"}
{"id": "32521129", "url": "https://en.wikipedia.org/wiki?curid=32521129", "title": "International Institute of Tropical Forestry", "text": "International Institute of Tropical Forestry\n\nThe International Institute of Tropical Forestry is a program of the United States Forest Service that was founded in 1939. It is headquartered in Rio Piedras, Puerto Rico, on the grounds of the University of Puerto Rico's Agricultural Experimental Station. Events on May 20, 2014 mark the Institute's 75th anniversary.\n\nIts headquarters building was designed by architect W. Ellis Groben.\n"}
{"id": "42634883", "url": "https://en.wikipedia.org/wiki?curid=42634883", "title": "International Thorium Energy Committee", "text": "International Thorium Energy Committee\n\nThe international Thorium Energy Committee (iThEC) was founded in late 2012 at CERN in Geneva by scientists, engineers, political figures and industrialists under the leadership of its honorary president Carlo Rubbia, to promote the cause of using thorium as a means of reducing existing and future nuclear waste, and also for generating electricity.\n\nAfter its founding, the first action of the committee was to organise an international conference on Thorium, ThEC13, using mostly private funding and institutional support from CERN. The conference lasted four days and attracted wide support from research institutes, energy companies and private individuals who contributed to the establishment of the current state-of-the-art in Thorium technology. Amongst the many contributions to the conference, one may note the announcement of the decision by the companies Solvay and Areva to jointly fund research in Thorium development and the tests by the Norwegian company Thor energy of Thorium fuel rods in the Halden Reactor.\n\nThe Committee is expanding its membership to reach a wider audience and attracted to the ThEC13 conference keynote speakers such as Pascal Couchepin, former president of the Swiss confederation and member of the Liberal Party of Switzerland and Hans Blix, former head of the International Atomic Energy Agency.\n\n"}
{"id": "10413816", "url": "https://en.wikipedia.org/wiki?curid=10413816", "title": "Jakob Maersk oil spill", "text": "Jakob Maersk oil spill\n\nThe Jakob Maersk was an oil tanker registered in Denmark that struck a sand bank on January 29, 1975 while entering the port of Leixões, Portugal, causing a major oil spill.\n\nBuilt in 1966, the tanker was owned by Maerskline Navigation Company, a subsidiary of A.P. Moller, and contracted by Shell Oil Company consisting of a crew of seventeen at the time of the accident. Seven of those seventeen crew members died during the explosion.\n\n\"Jakob Maersk\" was carrying 88,000 tons of crude oil from Kharg Island in Iran while entering the Port of Leixões in the northern part of Portugal to discharge the oil to the Sacor Refinery. Receiving aid from tug boats, the ship grounded on a sand bank, causing a huge explosion and subsequent fire that burned for days. The explosion broke the ship apart, spilling crude oil into the water.\n\nAt about 12:25 P.M. on January 29, 1975, the ship was entering the Port of Leixões in Portugal, while entering the Danish tanker hit sandbar and cause the ship to spill massive amounts of oil into the ocean followed by a few explosions inside the engine room. The cause of this infamous disaster was because of human error. 7 of those 17 crew members died in that explosion, the majority of deaths were engineers.\n\nDuring the time of explosions, the ship began to sink causing survivors to jump into the water, the tugboat Monte de Luz assisted by rescuing survivors that were nearby.\n\nThe \"Jakob Maersk\" oil spill was the second largest spill at the time which occurred in the second largest city in Portugal. Out of the 40,000 to 50,000 tons of oil that were spilled consumed either by the fire or the ocean, 20,000 to 25,000 tons of that oil drifted into the sea and about 15,000 tons came to shore due to the wind direction during the first few days. The explosion caused thick black smoke to rise. The ship burned for 58 continuous hours.\n\nThere were reports of locals being affected by the fire that was caused but it did not escalate into serious effects or injuries.\n\nContainment of the oil spill began with the placement of a floating boom at the harbor entrance. A straw barrier was placed around the wreck to briefly contain the spill while boats spread dispersants.The owners of the ship and the Shell company met together to decide how the oil spill was going to be clean or treated. The cleanup was the responsibility of the Portuguese Navy, Commandant Casquinno was appointed to clean up the oil spill and came up with a plan.The plan was separated into two actions, the first part of the plan was to clean up as much oil as possible that was in the water and the second part of the plan was to clean the oil that washed ashore.\n\nA company called Fina Oil Company was nearby and contributed several drums of Finasol. This oil spill unlike others was very lucky due to the fact that there was an immediate response. There were boats readily available both large and small to use as transportation. Equipment was offered of all types especially heavy equipment that was necessary. Hoses and nozzles were provided by the local fire department. Labor was available from skilled to unskilled which was crucial for this operation.\n\nThe nearby Oporto airport made it easier to deliver specialized equipment within a near proximity. Communication was easily established in a nearby communications facility that was used as the Command Center. The type of shoreline made it an easy accessible area with fairly easy mobility of machinery and personnel. The fire that was caused was in some ways fortunate because it burned most of the fuel and if it had not been for it there would have been an even bigger mess on the shoreline.\n\nBP made a huge contribution to the oil spill by contributing a chemical dispersant via airplane with 140 drums of BP 1100x on January 30, 1975, 150 of dispersant on January 31, 1975, provided a team of 5 to clean up the spill as much as possible. It was approximated that 2,000 barrels of dispersant was used to treat the oil spill. The purpose was to try and eliminate the oil on the coast using the waves as assistance to spread the dispersant. Even though it was a somewhat effective method is merely masked the oil in the sand. Later on machinery was brought in to dig up the contaminated sand and clean it using another method.\n\nThe most affected beach was the shore immediately adjacent to the wreck, where cleanup began with the removal of the upper layer of sand and the application of dispersants. It was bunker C oil a heavily residual oil which made it more difficult. This area was left until late in the cleanup and was extremely difficult to clean because the bunker C oil had been spread and untreated for some time. Dispersant was also added and affected very minimally due to the heavily seated bunker C. The ship's prow became stuck on a set of rocks near the Castelo do Queijo monument, remaining there for about 20 years, eventually becoming a landmark of the city until its removal.\n\nEcological damage appeared to be limited. Only half a dozen oiled birds were discovered during the first week on nearby shores. There was no apparent harmful effect on local fish populations, although a temporary difference in taste was observed. Dead seaweed and molluscs were found, but growth resumed shortly thereafter and populations returned to normal levels.\n\nThe cost of the catastrophe was estimated at 2.8 million dollars by the international Organisation for Economic Co-operation and Development.\n\n\n"}
{"id": "5715706", "url": "https://en.wikipedia.org/wiki?curid=5715706", "title": "List of silicon producers", "text": "List of silicon producers\n\n\n\nA partial list of major producers of wafers (made of high purity silicon, mono- or polycrystalline) includes:\n\n\n"}
{"id": "480282", "url": "https://en.wikipedia.org/wiki?curid=480282", "title": "Maxwell material", "text": "Maxwell material\n\nA Maxwell material is a viscoelastic material having the properties both of elasticity and viscosity. It is named for James Clerk Maxwell who proposed the model in 1867. It is also known as a Maxwell fluid.\n\nThe Maxwell model can be represented by a purely viscous damper and a purely elastic spring connected in series, as shown in the diagram. In this configuration, under an applied axial stress, the total stress, formula_1 and the total strain, formula_2 can be defined as follows:\n\nwhere the subscript D indicates the stress–strain in the damper and the subscript S indicates the stress–strain in the spring. Taking the derivative of strain with respect to time, we obtain:\n\nwhere \"E\" is the elastic modulus and \"η\" is the material coefficient of viscosity. This model describes the damper as a Newtonian fluid and models the spring with Hooke's law.\n\nIf we connect these two elements in parallel, we get a generalized model of Kelvin–Voigt material.\n\nIn a Maxwell material, stress σ, strain ε and their rates of change with respect to time t are governed by equations of the form:\n\nor, in dot notation:\n\nThe equation can be applied either to the shear stress or to the uniform tension in a material. In the former case, the viscosity corresponds to that for a Newtonian fluid. In the latter case, it has a slightly different meaning relating stress and rate of strain.\n\nThe model is usually applied to the case of small deformations. For the large deformations we should include some geometrical non-linearity. For the simplest way of generalizing the Maxwell model, refer to the upper-convected Maxwell model.\n\nIf a Maxwell material is suddenly deformed and held to a strain of formula_8, then the stress decays on a characteristic timescale of formula_9, known as the relaxation time.\n\nThe picture shows dependence of dimensionless stress formula_10 \nupon dimensionless time formula_11:\nIf we free the material at time formula_12, then the elastic element will spring back by the value of\n\nSince the viscous element would not return to its original length, the irreversible component of deformation can be simplified to the expression below:\n\nIf a Maxwell material is suddenly subjected to a stress formula_15, then the elastic element would suddenly deform and the viscous element would deform with a constant rate:\n\nIf at some time formula_12 we would release the material, then the deformation of the elastic element would be the spring-back deformation and the deformation of the viscous element would not change:\n\nThe Maxwell Model does not exhibit creep since it models strain as linear function of time.\n\nIf a small stress is applied for a sufficiently long time, then the irreversible strains become large. Thus, Maxwell material is a type of liquid.\n\nThe complex dynamic modulus of a Maxwell material would be:\n\nThus, the components of the dynamic modulus are :\n\nand\n\nThe picture shows relaxational spectrum for Maxwell material. The relaxation time constant is formula_23.\n\n"}
{"id": "36086871", "url": "https://en.wikipedia.org/wiki?curid=36086871", "title": "Megalithic entrance", "text": "Megalithic entrance\n\nA megalithic entrance is an architectonic feature that enables access to a megalithic tomb or structure. The design of the entrance has to seal the access to the cultic structure in such a way that it is possible to gain access to the interior again, even after a long time, in order to perform rituals. To that end, the practitioners of Nordic megalith architecture, the Wartberg culture and Horgen culture, used several variants, that are also found in other megalithic regions in identical or slightly modified form.\n\nAs the solutions were refined in detail, they all had in common the aim of sealing the structure that its re-opening was possible under difficult but manageable conditions by the tribal community.\n\nIn general the following forms of entrance may be differentiated:\n\nSimple dolmens (upper image)\nDolmens (except No. 4)\nPassage graves (lower image)\nGallery graves and stone cists\n\nVariation 7 has its focus in the Swedish Bohuslän (Dolmen of Haga). The stones forming the entrance were so selected or fashioned that together they form a triangular entrance (top left). This special form, which effectively replaces the lintel, is also found in the region of Languedoc-Roussillon, e.g. at the dolmen of Banelle, which lies near Saint-Hippolyte-du-Fort in the southern French department of Gard.\n\nThe portal entrance used a lintel, a horizontal block placed over two lower supporting stones in order to level out the distance to the capstone. This enabled access, usually only by crawling, through a trilithon opening (top centre), and may be seen across the whole area where Nordic megalithic architecture occurs.\n\nIn portal-like openings in the chamber wall, which, for example, have been made by leaving out a supporting stone, (bottom image: above right and below right), a passage in front of the chamber allows the cross-section of the entrance to be reduced. An example of this type of construction is the Sieben Steinhäuser in Lower Saxony. Such \"chambers without (detected) passages\" may be found in the Netherlands and Schleswig-Holstein. The entrance location and size determines, ultimately, whether the structure is a passage grave or a dolmen (J. Ross). In the Netherlands (Drenthe), where this form is very common, structures with no passages are known as portal graves; which otherwise, as portal tombs form a sub-group of megalithic tombs on the British Isles but structurally have nothing in common with the sites in the province of Drenthe.\n\nVariation 7 is not dissimilar to the so-called port-hole (bottom left), in which the front stone or, as in the diagram, two front stones are hewn out so as to create a circular access hole. The slabs were made of a material that enabled contemporary methods and tools to be used to fashion them. This version occurs Central Europe at sites built by the Wartberg and Horgen cultures in Baden-Württemberg and Switzerland. Some Swedish so-called megalithic stone cists also have port-holes. In German, such a hole is known as a \"Seelenloch\" (\"soul hole\"), a name that originated because of the erroneous assumption that holes were created with the intention of releasing the soul of the deceased (in the minds of the builders). In the Bronze and Iron Age sites on Sardinia and the Iberian Peninsula, similar openings are found, that are also narrow, but nearer the ground, and apse-like, (recess-shaped) with embedded closure stones.\n\nAnother feature of ground-level entrances is a so-called stone sill (\"Schwellenstein\"). This separates the secular or profane area of the passage from the sacred burial chamber. In some cases, it also serves to support the closure stone or slab. In some embedded simple dolmens and portal tomb it is so high that it forms a half-height front stone, enabling access above it, and is thus part of the wall of the chamber.\n\n\n"}
{"id": "1233070", "url": "https://en.wikipedia.org/wiki?curid=1233070", "title": "Mineral lick", "text": "Mineral lick\n\nA mineral lick (also known as a salt lick) is a place where animals can go to lick essential mineral nutrients from a deposit of salts and other minerals. Mineral licks can be naturally occurring or artificial (such as blocks of salt that farmers place in pastures for livestock to lick). Natural licks are common, and they provide essential elements such as phosphorus and the biometals (sodium, calcium, iron, zinc, and trace elements) required in the springtime for bone, muscle and other growth in deer and other wildlife, such as moose, elephants, tapirs, cattle, woodchucks, domestic sheep, fox squirrels, mountain goats and porcupines. Such licks are especially important in ecosystems with poor general availability of nutrients. Harsh weather exposes salty mineral deposits that draw animals from miles away for a taste of needed nutrients. It is thought that certain fauna can detect calcium in salt licks.\n\nMany animals regularly visit mineral licks to consume clay, supplementing their diet with nutrients and minerals. Some animals require the minerals at these sites not for nutrition, but to ward off the effects of secondary compounds that are included in the arsenal of plant defences against herbivory. The mineral contents of these sites usually contain calcium (Ca), magnesium (Mg), sulfur (S) phosphorus (P), potassium (K), and sodium (Na). Mineral lick sites play a critical role in the ecology and diversity of organisms that visit these sites, but little is still understood about the dietary benefits.\n\nThe paths animals made to natural mineral licks and watering holes became the hunting paths predators and early man used for hunting. It is theorized that these salt and water paths became trails and later roads for early man.\n\nNonetheless, many studies have identified other uses and nutritional benefits from other micronutrients that exist at these sites, including selenium (Se), cobalt (Co) and/or molybdenum (Mo). In addition to the utilization of mineral licks, many animals suffer from traffic collisions as they gather to lick salts accumulated on road surfaces. Animals also consume soil (geophagy) to obtain minerals, such as moose from Canada mining for minerals from the root wads of fallen trees.\n\nPeople use salt licks in the husbandry of livestock and to attract or maintain wildlife, whether it be for viewing, photography, farming, or hunting purposes. Maintaining artificial salt licks as a form of baiting is illegal in some states in the United States, but legal in others.\n\nThe indigenous people of America and the Long Hunters watched salt licks to hunt game. Many became well known including Bledsoe Lick in Sumner County, Tennessee; the Blue Lick in central Kentucky; 'Great Buffalo Lick' in Kanawha Salines, now present-day Malden, West Virginia; the French Lick in southern Indiana; and the Blackwater Lick in Blackwater, Lee County, Virginia.\n\nIn Norse mythology, before the creation of the world, it was the divine cow Audhumla who, through her licking of the cosmic salt ice, gave form to Buri, ancestor of the gods and grandfather of Odin. On the first day as Audhumla licked, Buri's hair appeared from the ice, on the second day his head and on the third his body.\n\n\n"}
{"id": "1917497", "url": "https://en.wikipedia.org/wiki?curid=1917497", "title": "Nuclear weapons debate", "text": "Nuclear weapons debate\n\nThe nuclear weapons debate refers to the controversies surrounding the threat, use and stockpiling of nuclear weapons. Even before the first nuclear weapons had been developed, scientists involved with the Manhattan Project were divided over the use of the weapon. The only time nuclear weapons have been used in warfare was during the final stages of World War II when United States Army Air Forces B-29 Superfortress bombers dropped atomic bombs on the Japanese cities of Hiroshima and Nagasaki in early August 1945. The role of the bombings in Japan's surrender and the U.S.'s ethical justification for them have been the subject of scholarly and popular debate for decades.\nNuclear disarmament refers both to the act of reducing or eliminating nuclear weapons and to the end state of a nuclear-free world. Proponents of disarmament typically condemn a priori the threat or use of nuclear weapons as immoral and argue that only total disarmament can eliminate the possibility of nuclear war. Critics of nuclear disarmament say that it would undermine deterrence and make conventional wars more likely, more destructive, or both. The debate becomes considerably complex when considering various scenarios for example, total vs partial or unilateral vs multilateral disarmament.\n\nEven before the first nuclear weapons had been developed, scientists involved with the Manhattan Project were divided over the use of the weapon. Some—notably a number at the University of Chicago Metallurgical Laboratory, represented in part by Leó Szilárd—lobbied early on that the atomic bomb should only be built as a deterrent against Nazi Germany getting a bomb, and should not be used against populated cities. The Franck Report argued in June 1945 that instead of being used against a city, the first atomic bomb should be \"demonstrated\" to the Japanese on an uninhabited area. This recommendation was not agreed with by the military commanders, the Los Alamos Target Committee (made up of other scientists), or the politicians who had input into the use of the weapon. Because the Manhattan Project was considered to be \"top secret\", there was no public discussion of the use of nuclear arms, and even within the U.S. government, knowledge of the bomb was extremely limited.\n\nThe Little Boy atomic bomb was detonated over the Japanese city of Hiroshima on 6 August 1945. Exploding with a yield equivalent to 12,500 tonnes of TNT, the blast and thermal wave of the bomb destroyed nearly 50,000 buildings (including the headquarters of the 2nd General Army and Fifth Division) and killed approximately 75,000 people, among them 20,000 Japanese soldiers and 20,000 Koreans. Detonation of the \"Fat Man\" atomic bomb exploded over the Japanese city of Nagasaki three days later on 9 August 1945, destroying 60% of the city and killing approximately 35,000 people, among them 23,200-28,200 Japanese civilian munitions workers and 150 Japanese soldiers. The role of the bombings in Japan's surrender and the U.S.'s ethical justification for them has been the subject of scholarly and popular debate for decades. J. Samuel Walker suggests that \"the controversy over the use of the bomb seems certain to continue\".\n\nAfter the bombings of Hiroshima and Nagasaki, the world’s nuclear weapons stockpiles grew, and nuclear weapons have been detonated on over two thousand occasions for testing and demonstration purposes. Countries known to have detonated nuclear weapons—and that acknowledge possessing such weapons—are (chronologically): the United States, the Soviet Union (succeeded as a nuclear power by Russia), the United Kingdom, France, the People's Republic of China, India, Pakistan, and North Korea.\n\nIn the early 1980s, following a revival of the nuclear arms race, a popular nuclear disarmament movement emerged. In October 1981 half a million people took to the streets in several cities in Italy, more than 250,000 people protested in Bonn, 250,000 demonstrated in London, and 100,000 marched in Brussels. The largest anti-nuclear protest was held on June 12, 1982, when one million people demonstrated in New York City against nuclear weapons. In October 1983, nearly 3 million people across western Europe protested nuclear missile deployments and demanded an end to the arms race.\n\nUnder the scenario of total multilateral disarmament, there is no possibility of nuclear war. Under scenarios of partial disarmament, there is disagreement as to how the probability of nuclear war would change. Critics of nuclear disarmament say that it would undermine the ability of governments to threaten sufficient retaliation upon an attack to deter aggression against them. Application of game theory to questions of strategic nuclear warfare during the Cold War resulted in the doctrine of mutually assured destruction (MAD), a concept developed, by Robert S. McNamara, among others, in the mid-1960s. The success of MAD in averting nuclear war was theorized to depend upon the “readiness at any time before, during, or after an attack to destroy the adversary as a functioning society.\" Those who believe governments should develop or maintain nuclear-strike capability, usually justify their position with reference to MAD and the Cold War, claiming that a \"nuclear peace\" was the result of both the U.S. and the U.S.S.R. possessing mutual second-strike retaliation capability. Since the end of the cold war, theories of deterrence in international relations have been further developed and generalized in the concept of the stability–instability paradox Proponents of disarmament call into question the assumption that political leaders are rational actors who place the protection of their citizens above other considerations, and highlight, as McNamara himself later acknowledged with the benefit of hindsight, the non-rational choices, chance and contingency which played a significant role in averting nuclear war, for example during the Cuban Missile Crisis of 1962 and the Able Archer 83 crisis of 1983, thus, they argue, evidence trumps theory and deterrence theories cannot be reconciled with the historical record.\n\nKenneth Waltz argues in favor of the continued proliferation of nuclear weapons. In the July 2012 issue of \"Foreign Affairs\" Waltz took issue with the view of most U.S., European, and Israeli, commentators and policymakers that a nuclear-armed Iran would be unacceptable. Instead Waltz argues that it would probably be the best possible outcome, as it would restore stability to the Middle East by balancing Israel's regional monopoly on nuclear weapons. Professor John Mueller of Ohio State University, author of \"Atomic Obsession\" has also dismissed the need to interfere with Iran's nuclear program and expressed that arms control measures are counterproductive. During a 2010 lecture at the University of Missouri, which was broadcast by C-Span, Dr. Mueller has also argued that the threat from nuclear weapons, including that from terrorists, has been exaggerated, both in the popular media, and by officials.\n\nIn contrast, various American government officials, including Henry Kissinger, George Shultz, Sam Nunn, and William Perry. who were in office during the Cold War period, are now advocating the elimination of nuclear weapons in the belief that the doctrine of mutual Soviet-American deterrence is obsolete, and that reliance on nuclear weapons for deterrence is becoming increasingly hazardous and decreasingly effective in the post cold war era A 2011 article in \"The Economist\" argues along similar lines, that risks are more acute in rivalries between relatively new nuclear states that lack the \"security safeguards\" developed by America and the Soviet Union and that additional risks are posed by the emergence of pariah states, such as North Korea (possibly soon to be joined by Iran), armed with nuclear weapons as well as the declared ambition of terrorists to steal, buy or build a nuclear device.\n\n\n"}
{"id": "15114784", "url": "https://en.wikipedia.org/wiki?curid=15114784", "title": "Persistent luminescence", "text": "Persistent luminescence\n\nCommonly referred as phosphorescence, persistent luminescence is the phenomenon encountered in materials which make them glow in the dark after the end of an excitation with UV or visible light.\n\nThe mechanism underlying this phenomenon is not fully understood. However, the phenomenon of persistent luminescence must not be mistaken with fluorescence and phosphorescence (see for definitions and ). Indeed, in fluorescence, the lifetime of the excited state is in the order of a few nanoseconds and in phosphorescence, even if the lifetime of the emission can reach several seconds, the reason of the long emission is due to the deexcitation between two electronic states of different spin multiplicity. For persistent luminescence, it has been known for a long time that the phenomenon involved energy traps (such as electron or hole trap) in a material which are filled during the excitation. After the end of the excitation, the stored energy is gradually released to emitter centers which emit light usually by a fluorescence-like mechanism.\n\nPersistent luminescence materials are mainly used in safety signs, watch dials, decorative objects and toys. They have also been used as nanoprobes in small animal optical imaging.\n\n"}
{"id": "4707045", "url": "https://en.wikipedia.org/wiki?curid=4707045", "title": "Plasma propulsion engine", "text": "Plasma propulsion engine\n\nA plasma propulsion engine is a type of electric propulsion that generates thrust from a quasi-neutral plasma. This is in contrast to ion thruster engines, which generate thrust through extracting an ion current from plasma source, which is then accelerated to high velocities using grids/anodes. These exist in many forms (see electric propulsion). \nPlasma thrusters do not typically use high voltage grids or anodes/ cathodes to accelerate the charged particles in the plasma, but rather uses currents and potentials which are generated internally in the plasma to accelerate the plasma ions. While this results in a lower exhaust velocities by virtue of the lack of high accelerating voltages, this type of thruster has a number of interesting advantages. The lack of high voltage grids of anodes removes a possible limiting element as a result of grid ion erosion. The plasma exhaust is 'quasi-neutral', which means that ion and electrons exist in equal number, which allows simply ion-electron recombination in the exhaust to neutralise the exhaust plume, removing the need for an electron gun (hollow cathode). This type of thruster often generates the source plasma using radio frequency or microwave energy, using an external antenna. This fact, combined with the absence of hollow cathodes (which are very sensitive to all but the few noble gases) allows the intriguing possibility of being able to use this type of thruster on a huge range of propellants, from argon, to carbon dioxide, air mixtures to astronaut urine.\n\nPlasma engines are better suited for long-distance interplanetary space travel missions.\n\nIn recent years, many agencies have developed several forms of plasma-fueled engines, including the European Space Agency, Iranian Space Agency and Australian National University, which have co-developed a more advanced type described as a double layer thruster. However, this form of plasma engine is only one of many types.\n\nPlasma engines have a much higher specific impulse (I) value than most other types of rocket technology. The VASIMR engine is capable of reaching an impulse value of over 12000, while hall thrusters can reach about 2000. This is much higher than the chemical bipropellant fuel that is sometimes used that can reach a specific impulse of 450. With high impulse, these rockets are capable of reaching relatively high speeds. Ex-astronaut Franklin Chang-Diaz claims his VASIMR engine could send a payload to Mars in as little as 39 days while reaching a max velocity of 34 miles per second. The trend is the same for other plasma rockets.\n\nCertain plasma thrusters, such as the mini-helicon, are hailed for their simple design and ease of use. With cheap fuel (a large number of gases or combinations of gases can be used as fuel), and relatively simple theory of performance, plasma rockets can be used more than once, and be easily built. Plasma rockets also do not have to spend all of their fuel all at once unlike traditional chemical rockets. This allows plasma rockets to change speed in flight, and even change direction midflight as well.\n\nFor some plasma thruster technologies, such as Berkant Goksel's tiny plasma thruster, one of the largest problems is generating enough electricity to turn gases into plasma. This same problem plagues Diaz's VASIMR thruster. Diaz's device would need so much electricity, that any vehicle that uses a VASIMR engine would also need several nuclear reactors in order to generate enough power. Not only would the reactors add mass to the payload, this has caused concern by some who fear the possible fallout caused by an explosion of the reactor. Because of this possibility, NASA has previously stopped research in nuclear reactors that could be sent up into space.\n\nAnother common issue plasma rockets have run into is the possibility of the rocket breaking itself. Over time, the plasma these rockets produce will damage the walls of the device ultimately causing it to break. This means that on a mission to Mars, it is possible that the rocket will destroy itself.\n\nLastly, due to their low thrust, plasma engines are not suitable for sending large payloads into space. On average, these rockets provide about 2 pounds of thrust maximum. This is a problem since in order to be financially efficient, heavy payloads need to be sent up every time a mission is scheduled. While plasma engines could take over once in space, chemical rockets would be needed to launch the vehicle.\n\nWhile most plasma engines are still confined to the laboratory, some have seen active flight time and use on missions. As of 2011, NASA, partnered with aerospace company Busek, launched the first hall thruster into space aboard the Tacsat-2 satellite. The thruster was the satellite's main propulsion system. Since then, the company has launched another hall effect thruster in 2011. As time progresses, more plasma thrusters are likely to see flight time on objects that have left Earth's surface. \n\nHelicon thrusters use low-frequency electromagnetic waves (Helicon waves) that exist inside plasma when exposed to a magnetic field. An R-F antennae that wraps around a chamber of gas is used to create the waves and excite the gas. Once the energy provided by the antennae couples with the gas a plasma is created. Once the plasma is formed, the plasma is accelerated out of the engine using a magnetic field of ideal topology. Mini-helicon thrusters, invented by Oleg Batishcev, are small simple thrusters ideal for small maneuvers in space. These thrusters are capable of running off of many different fuels making these simple rockets ideal for long term missions. Its simple design also makes it versatile in that it can be made out of simple materials such as a glass soda bottle. \n\nMagnetoplasmadynamic thrusters (MPD) use the Lorentz force (a force resulting from the interaction between a magnetic field and an electric current) to generate thrust—the electric charge flowing through the plasma in the presence of a magnetic field causing the plasma to accelerate due to the generated magnetic force.\nThe Lorentz force is also crucial to the operation of most pulsed plasma thruster\n\nPulsed inductive thrusters (PIT) also use the Lorentz force to generate thrust, but unlike the magnetoplasmadynamic thruster, they do not use any electrode, preventing their erosion. Ionization and electric currents in the plasma are induced by a rapidly varying magnetic field.\n\nElectrodeless plasma thrusters use the ponderomotive force which acts on any plasma or charged particle when under the influence of a strong electromagnetic energy density gradient to accelerate both electrons and ions of the plasma in the same direction, thereby able to operate without neutralizer.\n\nHall effect thrusters (also called stationary plasma thrusters SPT) combine a strong localized static magnetic field perpendicular to the electric field created between an upstream anode and a downstream cathode called neutralizer, to create a \"virtual cathode\" (area of high electron density) at the exit of the device. This virtual cathode then attracts the ions formed inside the thruster closer to the anode. Finally the accelerated ion beam is neutralized by some of the electrons emitted by the neutralizer.\nSerial production of Hall effect thruster started in Soviet Union in the 1970s. One of the early variants, SPT-100 is now produced under license by European Snecma Moteurs under the name PPS-1350. Similarly BPT-4000 and PPS-5000 are closely related to SPT-140.\nSPT-290 has a thrust of 1.5N, 5-30 kW power and specific impulse 30 km/s, efficiency 65% and weight 23 kg.\n\nVASIMR, short for Variable Specific Impulse Magnetoplasma Rocket, uses radio waves to ionize a propellant into a plasma. Then, a magnetic field accelerates the plasma from the rocket engine, generating thrust.\nThe VASIMR is being developed by Ad Astra Rocket Company, headquartered in Houston, TX. A Nova Scotia, Canada-based company Nautel, is producing the 200 kW RF generators required to ionize the propellant. Some component tests and \"Plasma Shoot\" experiments are performed in a Liberia, Costa Rica laboratory.\nThis project is led by former NASA astronaut Dr. Franklin Chang-Díaz (CRC-USA).\n\nThe Costa Rican Aerospace Alliance has announced development of an exterior support for the VASIMR to be fitted outside the International Space Station. This phase of the plan to test the VASIMR in space is expected to be conducted in 2016. A projected 200 megawatt VASIMR engine could reduce the time to travel from Earth to Jupiter or Saturn from six years to fourteen months, and from Earth to Mars from 6 months to 39 days.\n\nMagnetic sail\n\n"}
{"id": "250460", "url": "https://en.wikipedia.org/wiki?curid=250460", "title": "Potassium bromide", "text": "Potassium bromide\n\nPotassium bromide (KBr) is a salt, widely used as an anticonvulsant and a sedative in the late 19th and early 20th centuries, with over-the-counter use extending to 1975 in the US. Its action is due to the bromide ion (sodium bromide is equally effective). Potassium bromide is used as a veterinary drug, as an antiepileptic medication for dogs.\n\nUnder standard conditions, potassium bromide is a white crystalline powder. It is freely soluble in water; it is not soluble in acetonitrile. In a dilute aqueous solution, potassium bromide tastes sweet, at higher concentrations it tastes bitter, and tastes salty when the concentration is even higher. These effects are mainly due to the properties of the potassium ion—sodium bromide tastes salty at any concentration. In high concentration, potassium bromide strongly irritates the gastric mucous membrane, causing nausea and sometimes vomiting (a typical effect of all soluble potassium salts).\n\nPotassium bromide, a typical ionic salt, is fully dissociated and near pH 7 in aqueous solution. It serves as a source of bromide ions. This reaction is important for the manufacture of silver bromide for photographic film:\n\nAqueous bromide Br also forms complexes when reacted with some metal halides such as copper(II) bromide:\n\nA traditional method for the manufacture of KBr is the reaction of potassium carbonate with an iron(III, II) bromide, FeBr, made by treating scrap iron under water with excess bromine:\n\nThe anticonvulsant properties of potassium bromide were first noted by Sir Charles Locock at a meeting of the Royal Medical and Chirurgical Society in 1857. Bromide can be regarded as the first effective medication for epilepsy. At the time, it was commonly thought that epilepsy was caused by masturbation. Locock noted that bromide calmed sexual excitement and thought this was responsible for his success in treating seizures. In the latter half of the 19th century, potassium bromide was used for the calming of seizure and nervous disorders on an enormous scale, with the use by single hospitals being as much as several tons a year (the dose for a given person being a few grams per day). By the beginning of the 20th century the generic word had become so widely associated with being sedate that bromide came to mean a dull, sedate person or a boring platitude uttered by such a person.\n\nThere was not a better epilepsy drug until phenobarbital in 1912. The British Army has historically been claimed to lace soldiers' tea with bromide to quell sexual arousal but that is likely untrue as doing so would also diminish alertness in battle. Similar stories exist about a number of substances.\n\nBromide compounds, especially sodium bromide, remained in over-the-counter sedatives and headache remedies (such as the original formulation of Bromo-Seltzer) in the US until 1975, when bromides were outlawed in all over-the-counter medicines, due to chronic toxicity. Bromide's exceedingly long half life in the body made it difficult to dose without side effects. Medical use of bromides in the US was discontinued at this time, as many better and shorter-acting sedatives were known by then.\n\nPotassium bromide is used in veterinary medicine to treat epilepsy in dogs, either as first-line treatment or in addition to phenobarbital, when seizures are not adequately controlled with phenobarbital alone. Use of bromide in cats is limited because it carries a substantial risk of causing lung inflammation (pneumonitis) in them. The use of bromide as a treatment drug for animals means that veterinary medical diagnostic laboratories are able as a matter of routine to measure serum levels of bromide on order of a veterinarian, whereas human medical diagnostic labs in the US do not measure bromide as a routine test.\n\nPotassium bromide is not approved by the US Food and Drug Administration (FDA) for use in humans to control seizures. In Germany, it is still approved as an antiepileptic drug for humans, particularly children and adolescents. These indications include severe forms of generalized tonic-clonic seizures, early-childhood-related Grand-Mal-seizures, and also severe myoclonic seizures during childhood. Adults who have reacted positively to the drug during childhood/adolescence may continue treatment. Potassium bromide tablets are sold under the brand name \"Dibro-Be mono\" (Rx-only). The drug has almost complete bioavailability, but the bromide ion has a relatively long half life of 12 days in the blood, making bromide salts difficult to adjust and dose. Bromide is not known to interfere with the absorption or excretion of any other anticonvulsant, though it does have strong interactions with chloride in the body, the normal body uptake and excretion of which strongly influences bromide's excretion.\n\nThe therapeutic index (ratio of effectiveness to toxicity) for bromide is small. As with other antiepileptics, sometimes even therapeutic doses (3 to 5 grams per day, taking 6 to 8 weeks to reach stable levels) may give rise to intoxication. Often indistinguishable from 'expected' side-effects, these include:\n\n\n\nPotassium bromide is transparent from the near ultraviolet to long-wave infrared wavelengths (0.25-25 µm) and has no significant optical absorption lines in its high transmission region.\nIt is used widely as infrared optical windows and components for general spectroscopy because of its wide spectral range. In infrared spectroscopy, samples are analyzed by grinding with powdered potassium bromide and pressing into a disc. Alternatively, samples may be analyzed as a liquid film (neat, as a solution, or in a mull with Nujol) between two polished potassium bromide discs.\n\nDue to its high solubility and hygroscopic nature it must be kept in a dry environment. The refractive index is about 1.55 at 1.0 µm.\n\nIn addition to manufacture of silver bromide, potassium bromide is used as a restrainer in black and white developer formulas. It improves differentiation between exposed and unexposed crystals of silver halide, and thus reduces fog.\n\n"}
{"id": "17286999", "url": "https://en.wikipedia.org/wiki?curid=17286999", "title": "Russian National Wealth Fund", "text": "Russian National Wealth Fund\n\nThe Russian National Wealth Fund is Russia's sovereign wealth fund. It was created after the Stabilization Fund of the Russian Federation was split into two separate investment funds on 30 January 2008. The two funds are the Reserve Fund, which is invested abroad in low-yield securities and used when oil and gas incomes fall, and the National Wealth Fund, which invests in riskier, higher return vehicles, as well as federal budget expenditures. The Reserve Fund was given $125 billion and the National Wealth Fund was given $32 billion. The fund is controlled by the Ministry of Finance. One of the fund's main responsibilities is to support the Russian pension system.\n\nThe National Wealth Fund will receive funds from investment returns or any excess funds that the Reserve Fund produces. The Reserve Fund is capped at 10% of Russian GDP, and any funds over that will be given to the Wealth Fund. The fund also has accumulated $72.71bn (as of 1 September 2016) from taxes and duties it collects on the production and export of oil and gas.\n\nAccording to the Russian Ministry of Finance, the foreign debt securities the fund can invest in must have ratings of AA- or higher by Fitch or Standard & Poor's, or a rating of Aa3 by Moody's. Despite this, the fund agreed to buy (on 17 December 2013) $15 billion of Ukrainian Eurobonds, despite the fact that Ukraine had lower credit ratings at the time.\n\nIt has been proposed that the fund put some of its reserves into infrastructure projects in Russia, so it can provide a boost to the slow modernisation of its infrastructure in a time of otherwise anaemic investment. But as of 18 December 2013 this did not happen.\n\nThe Russian National Wealth Fund was merged in 2017 with the remaining of Russia’s sovereign Reserve Fund. The Reserve fund was built up over years with profits from oil exports but amid low oil price prices was emptied by the end of 2017 and ceased to exist. \n\nThe Russian government still has $65 billion in the National Wealth Fund to cover planned budget shortfalls, but according to financial analysts it might not last for more than three years. The National Wealth Fund with its $65 billion is the only fund left to cover budget deficits, estimated at $21.8 billion in 2018.\n"}
{"id": "28144", "url": "https://en.wikipedia.org/wiki?curid=28144", "title": "Seaborgium", "text": "Seaborgium\n\nSeaborgium is a synthetic chemical element with symbol Sg and atomic number 106. It is named after the American nuclear chemist Glenn T. Seaborg. As a synthetic element, it can be created in a laboratory but is not found in nature. It is also radioactive; the most stable known isotope, Sg, has a half-life of approximately 3.1 minutes.\n\nIn the periodic table of the elements, it is a d-block transactinide element. It is a member of the 7th period and belongs to the group 6 elements as the fourth member of the 6d series of transition metals. Chemistry experiments have confirmed that seaborgium behaves as the heavier homologue to tungsten in group 6. The chemical properties of seaborgium are characterized only partly, but they compare well with the chemistry of the other group 6 elements.\n\nIn 1974, a few atoms of seaborgium were produced in laboratories in the Soviet Union and in the United States. The priority of the discovery and therefore the naming of the element was disputed between Soviet and American scientists, and it was not until 1997 that International Union of Pure and Applied Chemistry (IUPAC) established seaborgium as the official name for the element. It is one of only two elements named after a living person at the time of naming, the other being oganesson, element 118.\n\nTwo groups claimed discovery of the element. Evidence of element 106 was first reported in 1974 by a Russian research team in Dubna led by Yuri Oganessian, in which targets of lead-208 and lead-207 were bombarded with accelerated ions of chromium-54. In total, fifty-one spontaneous fission events were observed with a half-life between four and ten milliseconds. After having ruled out nucleon transfer reactions as a cause for these activities, the team concluded that the most likely cause of the activities was the spontaneous fission of isotopes of element 106. The isotope in question was first suggested to be seaborgium-259, but was later corrected to seaborgium-260.\n\nA few months later in 1974, researchers including Glenn T. Seaborg, Carol Alonso and Albert Ghiorso at the University of California, Berkeley, and E. Kenneth Hulet from the Lawrence Livermore National Laboratory, also synthesized the element by bombarding a californium-249 target with oxygen-18 ions, using equipment similar to that which had been used for the synthesis of element 104 five years earlier, observing at least seventy alpha decays, seemingly from the isotope seaborgium-263m with a half-life of seconds. The alpha daughter rutherfordium-259 and granddaughter nobelium-255 had previously been synthesised and the properties observed here matched with those previously known, as did the intensity of their production. The cross-section of the reaction observed, 0.3 nanobarns, also agreed well with theoretical predictions. These bolstered the assignment of the alpha decay events to seaborgium-263m.\n\nA dispute thus arose from the initial competing claims of discovery, though unlike the case of the synthetic elements up to element 105, neither team of discoverers chose to announce proposed names for the new elements, thus averting an element naming controversy temporarily. The dispute on discovery, however, dragged on until 1992, when the IUPAC/IUPAP Transfermium Working Group (TWG), formed to put an end to the controversy by making conclusions regarding discovery claims for elements 101 to 112, concluded that the Soviet synthesis of seaborgium-260 was not convincing enough, \"lacking as it is in yield curves and angular selection results\", whereas the American synthesis of seaborgium-263 was convincing due to its being firmly anchored to known daughter nuclei. As such, the TWG recognised the Berkeley team as official discoverers in their 1993 report.\n\nSeaborg had previously suggested to the TWG that if Berkeley was recognised as the official discoverer of elements 104 and 105, they might propose the name \"kurchatovium\" (symbol Kt) for element 106 to honour the Dubna team, which had proposed this name for element 104 after Igor Kurchatov, the former head of the Soviet nuclear research programme. However, due to the worsening relations between the competing teams after the publication of the TWG report (because the Berkeley team vehemently disagreed with the TWG's conclusions, especially regarding element 104), this proposal was dropped from consideration by the Berkeley team. After being recognized as official discoverers, the Berkeley team started deciding on a name in earnest:\n\nSeaborg's son Eric remembered the naming process as follows:\n\nThe name \"seaborgium\" and symbol \"Sg\" were announced at the 207th national meeting of the American Chemical Society in March 1994 by Kenneth Hulet, one of the co-discovers. However, IUPAC resolved in August 1994 that an element could not be named after a living person, and Seaborg was still alive at the time. Thus, in September 1994, IUPAC recommended a set of names in which the names proposed by the three laboratories (the third being the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt, Germany) with competing claims to the discovery for elements 104 to 109 were shifted to various other elements, in which \"rutherfordium\" (Rf), the Berkeley proposal for element 104, was shifted to element 106, with \"seaborgium\" being dropped entirely as a name.\n\nThis decision ignited a firestorm of worldwide protest for disregarding the historic discoverer's right to name new elements, and against the new retroactive rule against naming elements after living persons; the American Chemical Society stood firmly behind the name \"seaborgium\" for element 106, together with all the other American and German naming proposals for elements 104 to 109, approving these names for its journals in defiance of IUPAC. At first, IUPAC defended itself, with an American member of its committee writing: \"Discoverers don't have a right to name an element. They have a right to suggest a name. And, of course, we didn't infringe on that at all.\" However, Seaborg responded:\n\nBowing to public pressure, IUPAC proposed a different compromise in August 1995, in which the name \"seaborgium\" was reinstated for element 106 in exchange for the removal of all but one of the other American proposals, which met an even worse response. Finally, IUPAC rescinded these previous compromises and made a final, new recommendation in August 1997, in which the American and German proposals for elements 104 to 109 were all adopted, including \"seaborgium\" for element 106, with the single exception of element 105, named \"dubnium\" to recognise the contributions of the Dubna team to the experimental procedures of transactinide synthesis. This list was finally accepted by the American Chemical Society, which wrote:\n\nSeaborg commented regarding the naming:\n\nSeaborg died a year and a half later, on 25 February 1999, at the age of 86.\n\nSuper-heavy elements such as seaborgium are produced by bombarding lighter elements in particle accelerators that induces fusion reactions. Whereas most of the isotopes of seaborgium can be synthesized directly this way, some heavier ones have only been observed as decay products of elements with higher atomic numbers.\n\nDepending on the energies involved, fusion reactions that generate superheavy elements are separated into \"hot\" and \"cold\". In hot fusion reactions, very light, high-energy projectiles are accelerated toward very heavy targets (actinides), giving rise to compound nuclei at high excitation energy (~40–50 MeV) that may either fission or evaporate several (3 to 5) neutrons. In cold fusion reactions, the produced fused nuclei have a relatively low excitation energy (~10–20 MeV), which decreases the probability that these products will undergo fission reactions. As the fused nuclei cool to the ground state, they require emission of only one or two neutrons, and thus, allows for the generation of more neutron-rich products. The latter is a distinct concept from that of where nuclear fusion claimed to be achieved at room temperature conditions (see cold fusion).\n\nSeaborgium has no stable or naturally occurring isotopes. Several radioactive isotopes have been synthesized in the laboratory, either by fusing two atoms or by observing the decay of heavier elements. Twelve different isotopes of seaborgium have been reported with atomic masses 258–267, 269, and 271, three of which, seaborgium-261, 263, and 265, have known metastable states. All of these decay only through alpha decay and spontaneous fission, with the single exception of seaborgium-261 that can also undergo electron capture to dubnium-261.\n\nThere is a trend toward increasing half-lives for the heavier isotopes; thus the heaviest three known isotopes, Sg, Sg, and Sg, are also the longest-lived, having half-lives in minutes. Some other isotopes in this region are predicted to have comparable or even longer half-lives, with the longest-lived predicted isotope being Sg which is expected to have a half-life of about an hour. Additionally, Sg, Sg, Sg, as well as the predicted Sg have or should have half-lives measured in seconds. All the remaining isotopes have half-lives measured in milliseconds, with the exception of the shortest-lived isotope, Sg, with a half-life of only 92 microseconds.\n\nThe proton-rich isotopes from Sg to Sg were directly produced by cold fusion; all heavier isotopes were produced from the repeated alpha decay of the heavier elements hassium, darmstadtium, and flerovium, with the exceptions of the isotopes Sg, Sg, Sg, and Sg, which were directly produced by hot fusion through irradiation of actinide targets. The twelve isotopes of seaborgium have half-lives ranging from 92 microseconds for Sg to 3.1 minutes for Sg.\n\nSeaborgium is expected to be a solid under normal conditions and assume a body-centered cubic crystal structure, similar to its lighter congener tungsten. It should be a very heavy metal with a density of around 35.0 g/cm, which would be the fourth-highest of any of the 118 known elements, lower only than bohrium (37.1 g/cm), meitnerium (37.4 g/cm) and hassium (41 g/cm), the three following elements in the periodic table. In comparison, the densest known element that has had its density measured, osmium, has a density of only 22.61 g/cm. This results from seaborgium's high atomic weight, the lanthanide and actinide contractions, and relativistic effects, although production of enough seaborgium to measure this quantity would be impractical, and the sample would quickly decay.\n\nSeaborgium is the fourth member of the 6d series of transition metals and the heaviest member of group 6 in the periodic table, below chromium, molybdenum, and tungsten. All the members of the group form a diversity of oxoanions. They readily portray their group oxidation state of +6, although this is highly oxidising in the case of chromium, and this state becomes more and more stable to reduction as the group is descended: indeed, tungsten is the last of the 5d transition metals where all four 5d electrons participate in metallic bonding. As such, seaborgium should have +6 as its most stable oxidation state, both in the gas phase and in aqueous solution, and this is the only oxidation state that is experimentally known for it; the +5 and +4 states should be less stable and the +3 state, the most common for chromium, would be the least stable for seaborgium. Experimental chemical investigation has been hampered due to the need to produce seaborgium one atom at a time, its short half-life, and the resulting necessary harshness of the experimental conditions. The isotope Sg and its isomer Sg are advantageous for radiochemistry: they are produced in the Cm(Ne,5n) reaction.\n\nThis stabilisation of the highest oxidation state occurs in the early 6d elements because of the similarity between the energies of the 6d and 7s orbitals, since the 7s orbitals are relativistically stabilised and the 6d orbitals are relativistically destabilised. This effect is so large in the seventh period that seaborgium is expected to lose its 6d electrons before its 7s electrons (Sg, [Rn]5f6d7s; Sg, [Rn]5f6d7s; Sg, [Rn]5f6d7s; Sg, [Rn]5f6d; Sg, [Rn]5f). Because of the great destabilisation of the 7s orbital, Sg should be even more unstable than W and should be very readily oxidised to Sg. The predicted ionic radius of the hexacoordinate Sg ion is 65 pm, while the predicted atomic radius of seaborgium is 128 pm. Nevertheless, the stability of the highest oxidation state is still expected to decrease as Lr > Rf > Db > Sg. Some predicted standard reduction potentials for seaborgium ions in aqueous acidic solution are as follows:\n\nSeaborgium should form a very volatile hexafluoride (SgF) as well as a moderately volatile hexachloride (SgCl), pentachloride (SgCl), and oxychlorides SgOCl and SgOCl. SgOCl is expected to be the most stable of the seaborgium oxychlorides and to be the least volatile of the group 6 oxychlorides, with the sequence MoOCl > WOCl > SgOCl.\n\nThe volatile seaborgium(VI) compounds SgCl and SgOCl are expected to be unstable to decomposition to seaborgium(V) compounds at high temperatures, analogous to MoCl and MoOCl; this should not happen for SgOCl due to the much higher energy gap between the highest occupied and lowest unoccupied molecular orbitals, despite the similar Sg–Cl bond strengths (similarly to molybdenum and tungsten). Thus, in the first experimental chemical studies of seaborgium in 1995 and 1996, seaborgium atoms were produced in the reaction Cm(Ne,4n)Sg, thermalised, and reacted with an O/HCl mixture. The adsorption properties of the resulting oxychloride were measured and compared with those of molybdenum and tungsten compounds. The results indicated that seaborgium formed a volatile oxychloride akin to those of the other group 6 elements, and confirmed the decreasing trend of oxychloride volatility down group 6:\n\nIn 2001, a team continued the study of the gas phase chemistry of seaborgium by reacting the element with O in a HO environment. In a manner similar to the formation of the oxychloride, the results of the experiment indicated the formation of seaborgium oxide hydroxide, a reaction well known among the lighter group 6 homologues as well as the pseudohomologue uranium.\n\nMolybdenum and tungsten are very similar to each other and show important differences to the smaller chromium, and seaborgium is expected to follow the chemistry of tungsten and molybdenum quite closely, forming an even greater variety of oxoanions, the simplest among them being seaborgate, , which would form from the rapid hydrolysis of , although this would take place less readily than with molybdenum and tungsten as expected from seaborgium's greater size. Seaborgium should hydrolyse less readily than tungsten in hydrofluoric acid at low concentrations, but more readily at high concentrations, also forming complexes such as SgOF and : complex formation competes with hydrolysis in hydrofluoric acid. These predictions have largely been confirmed. In experiments conducted in 1997 and 1998, seaborgium was eluted from cation-exchange resin using a HNO/HF solution, most likely as neutral SgOF or the anionic complex ion [SgOF] rather than . In contrast, in 0.1 M nitric acid, seaborgium does not elute, unlike molybdenum and tungsten, indicating that the hydrolysis of [Sg(HO)] only proceeds as far as the cationic complex [Sg(OH)(HO)] or [Sg(OH)(HO)], while that of molybdenum and tungsten proceeds to neutral [MO(OH))].\n\nThe only other oxidation state known for seaborgium other than the group oxidation state of +6 is the zero oxidation state. Similarly to its three lighter congeners, forming chromium hexacarbonyl, molybdenum hexacarbonyl, and tungsten hexacarbonyl, seaborgium has been shown in 2014 to also form seaborgium hexacarbonyl, Sg(CO). Like its molybdenum and tungsten homologues, seaborgium hexacarbonyl is a volatile compound that reacts readily with silicon dioxide.\n\n"}
{"id": "17594448", "url": "https://en.wikipedia.org/wiki?curid=17594448", "title": "Sheel Kant Sharma", "text": "Sheel Kant Sharma\n\nSheel Kant Sharma was the ninth Secretary General of the South Asian Association for Regional Cooperation (SAARC), serving from 2008 to 2011. He is an expert on energy, and was formerly Indian envoy to Austria.\n\nMaster of Science (Nuclear Physics) from Indian Institute of Technology (IIT), Mumbai (1971).\nPh.D. (High Energy Physics) from Indian Institute of Technology (IIT), Mumbai (1974).\n\nProfessional Background: \nResearch articles co-authored in Physical Review-D (1971), Physical Review Letters (1972) \nConferences attended as representative of India/delegate: \nLanguages: French and Arabic \nHobbies and Extra-curricular Interests: Literature, readings on science & technology. Member of India International Centre and India Habitat Centre; \nSports and Leisure: Basketball, Tennis, Swimming, Yoga, Chess\n\n"}
{"id": "7953485", "url": "https://en.wikipedia.org/wiki?curid=7953485", "title": "Solar savings fraction", "text": "Solar savings fraction\n\nIn discussing solar energy, the solar savings fraction or solar fraction (f) is the amount of energy provided by the solar technology divided by the total energy required.\n\nThe solar savings fraction thus is zero for no solar energy utilization, to 1.0 for all energy provided by solar. The solar savings fraction of a particular system is dependent on many factors such as the load, the collection and storage sizes, the operation, and the climate. As an example, the same solar-thermal water heating system installed in a single-family house in Arizona might have f=0.75 (75%), while in a much colder and cloudier climate, like Pittsburgh, PA, might only have a solar fraction of f=0.3 (30%) or so. Great care is thus needed in designing such systems, and in evaluating their economics.\n\nTo increase the solar savings fraction, energy conservation measures should be employed first before expanding the size of the solar energy collection system. Doing so reduces the need for hot water or space heating, for example, and typically provides the best economic return on the total investment, including the solar energy system.\n\n"}
{"id": "56054874", "url": "https://en.wikipedia.org/wiki?curid=56054874", "title": "Static synchronous series compensator", "text": "Static synchronous series compensator\n\nA static synchronous series compensator or SSSC is a kind of flexible AC transmission system, which consists of a solid-state voltage source inverter coupled with a transformer that is connected in series with a transmission Line. This device could inject an almost sinusoidal voltage in series with the line. This injected voltage could be considered as an inductive or capacitive reactance, which is connected in series with the transmission line. This feature can provide controllable voltage compensation. In addition, SSSC is able to reverse the power flow by injecting a sufficiently large series reactive compensating voltage.\n\n"}
{"id": "5159168", "url": "https://en.wikipedia.org/wiki?curid=5159168", "title": "Stones of Scotland", "text": "Stones of Scotland\n\nThere are many large stones of Scotland of cultural and historical interest, notably the distinctive Pictish stones, but also the other types discussed below.\nThe Stone of Scone, (pronounced 'scoon') also commonly known as the \"Stone of Destiny\" or the \"Coronation Stone\", is a block of sandstone historically kept at the now-ruined abbey in Scone, near Perth, Scotland. It was used for centuries in the coronation of the monarchs of Scotland, the monarchs of England, and, more recently, British monarchs.\n\nAyrshire apparently is endowed with a geology that lends itself towards the formation of rocking stones. There are several rocking stones, or stones that used to rock at one time, in Ayrshire, Scotland.\nA rocking stone is recorded from near the site of Saint Bride's Chapel. This stone stands on top of the Craigs of Kyle near Coylton in Ayrshire. It weighs around 30 tons and rest upon two stones. A large standing stone known as Wallace's stone stands nearby.\n\nThere is a rocking stone near Loch Riecawr in South Ayrshire.\n\nIn the parish of North Carrick in the Straiton District in South Ayrshire, \nabout a quarter of a mile to the west of the White Laise, and near the March Dyke, there is a rocking stone named the Logan Stone. The Logan Stone is a grey granite rock and rests on greywacke, and can easily be moved with one hand. It is 4 feet 3 inches by 4 feet, by 3 feet high.\n\nA rocking stone that some associate with the Druids is on Cuff Hill in Hessilhead, near Beith in North Ayrshire. It no longer rocks due to people digging beneath to ascertain its fulcrum. It is in a small wood and surrounded by a circular drystone wall. An article was published in Cumnock Chronical of 1907 on the reason for the stone being dislodged. Signed by a Messer's Robert Boyle & Robert Currie.\n\nThe Lamagee or Lamargle stone is in the centre of a stone circle in the village of Lugar in East Ayrshire. The Lamargle stone rests on two stones. Local legend has it that the Lamargle stone used to rock, but it no longer does.\n\nNear Lugar in the Parish of Auchinleck in Ayrshire, Scotland is a rocking stone in a hollow by the Bella Water near its junction with the Glenmore Water. It is made of two vertical stones, and a horizontal stone about six feet long, three feet broad and four feet high. It was regarded as a Druidical monument or the grave of a Caledonian hero.\n\nA rocking stone existed in 1913 – 1919 at Sannox on Arran. It sat on a nearly horizontal platform next to the seashore.\n\nThe Clochoderick stone near Howwood and Kilbarchan in Renfrewshire used to rock and it is said that the Druids used it to judge people. The accused was made to sit on the stone and by the way it moved the Druids judged the innocence or guilt of the individual. It is also said to be the burial place of Rhydderch Hael, King of Strathclyde who was the victor at the Battle of Arderydd near Arthuret in the Borders. His victory brought Christianity to Strathclyde.\n\nThis stone could still, with a little effort, be rocked in the 1860s according to the historian John Smith. \nThe megalith known as the Lochmaben Stone was called the Lochmabonstone in a well-known book by Logan Mack in 1926. This stone has, in the Borders context, an unsurpassed extent of history attached to it. It stands in a field, nearly a mile west of the Sark mouth on the Solway Firth, three hundred yards or so above high-water mark on the farm of Old Graitney in Dumfries & Galloway, Scotland. Map reference: NY 3123 6600. The area is also known as Stormont.\n\nThe stone is an erratic, 7' high and 18' in girth and weighs approximately ten tons. It is composed of weathered granite, exposed to severe glacial action.\n\nThe Ogrestone or Thurgartstone near Dunlop in East Ayrshire is thought to have been a rocking stone. However, soil has built up around the base of the Thurgatstone over the years, which now prevents any rocking motion.\n\nThe Thurgatstane / Thorgatstane / Field Spirit Stane / Ogrestane near Dunlop in East Ayrshire is a glacial erratic stone near the middle of a field belonging to Brandleside Farm near to the site of St.Mary's Chapel on the Lugton road.\n\nOn top of the Common Crags overlooking Dunlop and the Glazert is a large procumbent boulder known as the 'Carlin's Stone or Stane'. This stone is not as well known as the Thorgatstane. A Carl is a commoner, a husband or in a derogatory sense, a churl or person of low birth. Carlin is the Scots equivalent of Gaelic \"Cailleach\", meaning a witch or the 'old Hag', goddess of Winter. This would therefore be the Witch's Stone, one of several in Scotland with this name.\n\nNear 'Kirkhill' outside Stewarton are several Kilbrides. Bride, Brigit or St. Brigid was originally a Celtic Goddess linked with the festival of Imbolc, the eve of the first of February. She was the goddess of Spring and was associated with healing and sacred wells, therefore the antithesis of the Carlin. Carlin's Tooth is the name of a rock outcrop in the Scottish borders between Knocks Knowe and Carter Fell (Logan Mack 1926). Several Carling Farms are to be found near Darvel in Ayrshire.\n\nClackmannan (from the Gaelic Clach Mhanainn, 'Stone of Manau') is the name of a small town and local government district in the Central region of Scotland, corresponding to the traditional county of Clackmannanshire, which was Scotland's smallest. The 'Stone of Manau or Manaw' is a monolith of religious significance to the ancient tribes of the area. It has been moved from its original position and placed in the town centre on top of a large standing stone, which was quarried locally.\n\nThe RCHAMS 'Canmore' site lists this unhewn olivine monolith in Darvel, Ayrshire, as a 'possible' standing stone. It is rather curious and its general size and shape suggest a prehistoric standing stone. It has twelve small connected depressions spread over three of its sides. These have been said to link the stone to astronomical observations and to the noon-day sun height at mid-summer. This would link the stone to life-giving powers, fertility and prosperity.\n\nIn 1821 someone attached a round sandstone ball to the top of it with an iron bar. Who or why is unknown. It is 1.6m tall and its original position is also unknown. It used to stand in what is now the main street, at the end of Ranoldcoup Road as shown by an old photograph, and was moved to the town square when the road was widened.\n\nDocumentation shows that prior to the 19th century messings-about, newlywed couples and their wedding parties marched around it for good luck, accompanied by a fiddler. Wedding processions also used to walk three times sunwise round the Dagon stone on the way to the bride's house.\n\nThe annual parade or \"Prawd\", originally held on old New Year's Day, headed by the village band used to walk sunwise round the Dagon stone as a mark of superstitious respect.\n\nDagon is the name of a Philistine god, who was half-man half-fish. But with a Scottish accent it no doubt derives from something much closer to home (assuming it is not just the romantic invention of a Victorian antiquary). It is reminiscent of the Clackmannan stone or Stone of Mannau in Clackmannanshire.\n\nThis glacial erratic stone now lies in Brodie Park in Paisley. It is thought to have been named after a Mr Dove who laid claim to the stone. Originally to be found at the corner of Neilston Road and Rowan Street in Paisley, the stone was the meeting place of the Weavers Union in the South of Paisley and was also used as a \"soapbox\". It was later moved to its present location in Brodie Park. The stone is still used today as the meeting point for the annual Sma' Shots parade. Its ancient significance is unknown, but it has played a significant role in historical times and has probably always been a megalith of social significance.\n\nA large procumbent boulder known on the OS map as the 'Carlin's Stone' lies next to the Carlin Burn near Craigends Farm below Cameron's Moss in East Ayrshire. The name is the same as the example at Dunlop in East Ayrshire. It has been much visited at one time, with the clear remains of a footbridge running to it across the Hareshawmuir Water.\n\nA large boulder in amongst trees near the David Hamilton designed Ladyland House, Kilbirnie, North Ayrshire. Despite the name no clear legend has been preserved regarding this stone in the neighbourhood. The stone has survived being broken up despite the building of the old Ladyland Castle, stone dykes, farm buildings, etc.\n\nThe Grannie Stane (or Granny Stane) is described as \"one of Irvine's prehistoric puzzles\", this boulder is either left behind from the Ice Age or is the last remaining stone of a stone circle – others were removed, by blasting, after the Irvine weir was constructed in 1895, but popular protests saved this remaining stone. The Grannie Stane is visible when the water is low.\n\nThe Muckle or Hare stone is a glacial erratic boulder previously located in a nearby field and moved to the centre of Monkton, near Prestwick, in 2000. A number of tales of witchcraft and evil spirits are associated with it.\n\nNear Laigh Overmuir on the moors above Darvel in East Ayrshire is the Gowk Stane, a glacial erratic boulder located in a prominent position overlooking the upper tributaries of the Glen Water.\n\nIn Largs, North Ayrshire resides a neolithic tomb behind Douglas Park. This monument is known as the Haylie Chambered Tomb and it was once covered by a cairn of stones (known as Margaret's Law). When it was uncovered in the early twentieth century the tomb was dated to around 3000 to 2000 BC.\n\nThe purpose of cup and ring marked stones is unknown, however they may represent family trees, star maps, br related to labyrinths, etc. The carvings on such stones date from the Neolithic or Bronze age times, being as old as 6000 years. This example from Dalgarven Mill in Ayrshire is unusual in having cups and connecting troughs, but no rings and it may therefore have been abandoned at an early stage in its use. Often up to five concentric rings are found circling the central cup.\n\nThere are several stone circles (and other arrangements such as the Celtic Cross formation of the Callanish Stones) in Scotland.\n\nThere are several well-known lone standing stones in Scotland.\n\nThere are a number of famous Picture stones with carvings on them in Scotland.\n\n\n\n\n"}
{"id": "43865672", "url": "https://en.wikipedia.org/wiki?curid=43865672", "title": "Sugar quartz", "text": "Sugar quartz\n\nSugar quartz is a gemstone with a natural surface texture much like fine sugar crystals formed by natural phenomena of micro-crystalline facets.\n\nSugar quartz has a history going back 10,000 years, as referenced in Paleo-Indian. \n\nSugar quartz was referenced three different times in the United States Geological Survey by Joseph Hyde Pratt in \"The Occurrence and Distribution of Corundum in the United States – by Joseph Hyde Pratt\", published in 1901 on page 650 \n\n\"A few of the smaller caverns only, near the surface, could be seen. These were lined with crumbling, rust-colored, oxidized ore, beneath which there was often unaltered galena. Sometimes these caves are lined and partly filled with a light, porous, pumiceous sponge of quartz. This is not the cellular, honeycombed quartz resulting from the removal of ore by oxidizing waters, but is an original spongy crystallization of minute quartz crystals, with some interstitial kaolin. It forms a light friable mass that is strongly suggestive of pumice. It is analogous to the \"sugar quartz\" occurring in vugs, with sericite, in some of the gold- quartz veins of California, although not to the \"sugar quartz\" which results from a crushing of the vein.\" - Joseph Hyde Pratt\n\nSugar quartz has not been seen or found much since the early 1900s. Any findings in present day are considered extremely rare.\n\nIt was referenced seven times in The Mining Investor: Volumes 48-49- January 1, 1907 Critic Publishing Company- Publisher\non page 794 stating \"The ores discovered are invariably free milling, occurring in sugar quartz, sometimes heavily 0‘ E: stained with iron. as is the case with the Grot- \n\nThe most recent known legal publication referencing sugar quartz, a total of 13 times, is Mining and Treatment of Feldspar and Kaolin in the Southern Appalachian Region – Arthur Simeon Watts, published First edition, 7“ June, 1913., including in the Table of Contents referring to sugar quartz being on page 163.\n\nPage 58 of the same book refers to sugar quartz is \"The sugar quartz is therefore the only pure silica present in commercial quantity in the region investigated. When pure its refractory value is cone 34 (1,810° C.). With the small amount of impurity present its deformation point or refractory value is about cone 32 or 33, that is, 1,780° C.\" \n\nSeveral other Native American Arrowheads made out of sugar quartz have been found as referenced in www.ArrowHeadOlogy.com, Lithicasting Lab and Where to Find Arrow Heads\n"}
{"id": "51280385", "url": "https://en.wikipedia.org/wiki?curid=51280385", "title": "Taralga Wind Farm", "text": "Taralga Wind Farm\n\nThe Taralga Wind Farm is a wind farm located near Taralga, New South Wales.\n\nTaralga Wind Farm was CBD Energy/Santander's first and only wind farm. It is a 106.8 megawatt wind farm with 51 turbines. The energy produced by the wind farm can power around 45,000 average Australian households per year, saving over 258,000 tonnes of greenhouse gas emissions per year.\n\nThe Taralga Wind Farm is near Taralga.\n\nOn 20 February 2012, approval was granted by the New South Wales Government for work to commence on the Taralga Wind Farm, after the approval of the Stage 1 CEMP. The project consists of 51 wind turbines generating 106.8 Megawatts of electricity on ridges to the east of Taralga. Electricity generated by the project will be fed into the national power grid through a 37.5 km transmission line to Marulan Substation.\n\nThe project created up to 200 local jobs during the construction phase. Approval of the wind farm followed an unsuccessful challenge by the Taralga Landscape Guardians in the Land and Environment Court of New South Wales to block the project on the grounds of aesthetic and environmental impacts including noise emissions and blighting of the landscape. Chief Justice Brian Preston ruled in favour of approving the wind farm as the long term benefit of reduced greenhouse gas emissions was in the greater public interest. On June 2015, the wind farm was fully commissioned and commenced commercial operations. The layout of the wind farm can be seen through this link.\n\nOn March 2015, the Chinese state-owned utility State Power Investment Corp agreed to purchase the Wind Farm for a reported A$300 million, which includes the A$200 million debt facility from the CBD Energy (now BlueNRGY) and Banco Santander subsidiary Capital Riesgo joint venture. The project is currently operated under an O&M contract with Vestas Australia, and has Wind Prospect CWP as asset Managers.\n\nTo help fund the construction of the wind farm, CBD Energy/Santander signed a A$200 million project finance debt facility agreement with ANZ, CEFC, and EKF. The project had off-take backing from EnergyAustralia\nThe total project cost was A$280 million.\n\n"}
{"id": "583800", "url": "https://en.wikipedia.org/wiki?curid=583800", "title": "Therm", "text": "Therm\n\nThe therm (symbol, thm) is a non-SI unit of heat energy equal to British thermal units (Btu). It is approximately the energy equivalent of burning – often referred to as 1 CCF – of natural gas.\n\nSince natural gas meters measure volume and not energy content, a therm factor is used by natural gas companies to convert the volume of gas used to its heat equivalent, and thus calculate the actual energy use. The therm factor is usually expressed in units of therms per CCF. It will vary with the mix of hydrocarbons in the natural gas. Natural gas with a higher than average concentration of ethane, propane or butane will have a higher therm factor. Impurities, such as carbon dioxide or nitrogen, lower the therm factor.\n\nThe volume of the gas is calculated as if measured at standard temperature and pressure (STP). The heat content of natural gas is solely dependent on the composition of the gas, and is independent of temperature and pressure.\n\nOne therm is equal to about megajoules, kilocalories, or kilowatt-hours. One therm can also be provided by about of natural gas. The therm sometimes has been confused with the thermie. The names of both units come from the Greek word for heat.\n\n\n10 therms are known as a decatherm (sometimes, dekatherm; commonly abbreviated Dth), which is Btu (of whichever type). Further common abbreviations are MDth for a decatherms, and MMDth for decatherms.\n\nUnited Kingdom regulations were amended to replace therms with joules with effect from 1999, with natural gas usually retailed in the derived unit, kilowatt-hours. Despite this, the wholesale UK gas market trades in therms. In the United States, natural gas is commonly billed in CCFs (hundreds of cubic feet) or therms.\n\nAccording to the EPA burning one therm of natural gas produces on average of carbon dioxide.\n\n"}
{"id": "31185", "url": "https://en.wikipedia.org/wiki?curid=31185", "title": "Tonne", "text": "Tonne\n\nThe tonne () (Non-SI unit, symbol: t), commonly referred to as the metric ton in the United States, is a non-SI metric unit of mass equal to 1,000 kilograms; or one megagram (Mg); it is equivalent to approximately pounds, or 0.984 long tons (UK). Although not part of the SI, the tonne is accepted for use with SI units and prefixes by the International Committee for Weights and Measures.\n\nThe metric tonne is derived from the weight of pure water; there are 1,000 litres in one metric tonne.\n\nThe SI symbol for the tonne is \"t\", adopted at the same time as the unit in 1879. Its use is also official for the metric ton in the United States, having been adopted by the United States National Institute of Standards and Technology. It is a symbol, not an abbreviation, and should not be followed by a period. Informal and non-approved symbols or abbreviations include \"T\",”Te”, \"mT\", \"MT\", and \"mt\". Some of these are SI symbols for other units: \"T\" is the SI symbol for the tesla and \"Mt\" is the SI symbol for megatonne (equivalent to one teragram); if describing TNT equivalent units of energy, this is equivalent to 4.184 petajoules.\n\nIn French and all English-speaking countries that are predominantly metric, \"tonne\" is the correct spelling. It is usually pronounced the same as ton , but when it is important to clarify that the metric term is meant, rather than short ton, the final \"e\" can also be pronounced, i.e. \"tonny\" . In Australia, it is also pronounced .\n\nBefore metrication in the UK the unit used for most purposes was the Imperial ton of 2,240 pounds avoirdupois or 20 hundredweight (usually referred to as the long ton in the US), equivalent to 1,016 kg, differing by just 1.6% from the tonne. The UK Weights and Measures Act 1985 explicitly excluded from use for trade certain imperial units, including the ton, unless the item being sold or the weighing equipment being used was weighed or certified prior to 1 December 1980, and even then only if the buyer was made aware that the weight of the item was measured in imperial units.\n\nIn the United States \"metric ton\" is the name for this unit used and recommended by NIST; an unqualified mention of a \"ton\" almost invariably refers to a short ton of , and \"tonne\" is rarely used in speech or writing.\n\n\"Ton\" and \"tonne\" are both derived from a Germanic word in general use in the North Sea area since the Middle Ages (cf. Old English and Old Frisian \"tunne\", Old High German and Medieval Latin \"tunna\", German and French \"tonne\") to designate a large cask, or \"tun\". A full tun, standing about a metre high, could easily weigh a tonne. An English tun (an old wine cask volume measurement equivalent to 954 litres) of wine weighs roughly a tonne, 954 kg if full of water, a little less for wine.\n\nThe spelling \"tonne\" pre-dates the introduction of the SI in 1960; it has been used with this meaning in France since 1842, when there were no metric prefixes for multiples of 10 and above, and is now used as the standard spelling for the metric mass measurement in most English-speaking countries. In the United States, the unit was originally referred to using the French words \"millier\" or \"tonneau\", but these terms are now obsolete. The Imperial and US customary units comparable to the tonne are both spelled \"ton\" in English, though they differ in mass.\n\nOne tonne is equivalent to:\n\nFor multiples of the tonne, it is more usual to speak of thousands or millions of tonnes. Kilotonne, megatonne, and gigatonne are more usually used for the energy of nuclear explosions and other events in equivalent mass of TNT, often loosely as approximate figures. When used in this context, there is little need to distinguish between metric and other tons, and the unit is spelt either as \"ton\" or \"tonne\" with the relevant prefix attached.\n\nA metric ton unit (mtu) can mean within metal (e.g. tungsten, manganese) trading, particularly within the US. It traditionally referred to a metric ton of ore containing 1% (i.e. 10 kg) of metal.\nThe following excerpt from a mining geology textbook describes its usage in the particular case of tungsten:\n\"Tungsten concentrates are usually traded in metric tonne units (originally designating one tonne of ore containing 1% of WO, today used to measure WO quantities in 10 kg units. One metric tonne unit (mtu) of tungsten (VI) contains 7.93 kilograms of tungsten.\" (Walter L Pohl, \"Economic Geology: Principles and Practices\", English edition, 2011, p 183.)\nNote that tungsten is also known as wolfram and has the atomic symbol W.\n\nIn the case of uranium, the acronym \"MTU\" is sometimes considered to be \"metric ton of uranium\", meaning 1,000 kg.\n\nA gigatonne of carbon dioxide equivalent (GtCO2eq) is a unit used by the UN climate change panel, IPCC, to measure the effect of a technology or process on global warming.\n\nThe \"tonne of trinitrotoluene (TNT)\" is used as a proxy for energy, usually of explosions (TNT is a common high explosive). Prefixes are used: kiloton(ne), megaton(ne), gigaton(ne), especially for expressing nuclear weapon yield, based on a specific combustion energy of TNT of about 4.2 MJ/kg (or one thermochemical calorie per milligram). Hence, 1 t TNT = 4.2 GJ, 1 kt TNT = 4.2 TJ, 1 Mt TNT = 4.2 PJ.\n\nThe SI unit of energy is the joule. Assuming that a TNT explosion releases 1,000 small (thermochemical) calories per gram (4.2 kJ/g), one tonne of TNT is equivalent to 4.2 gigajoules.\n\nIn the petroleum industry the tonne of oil equivalent (toe) is a unit of energy: the amount of energy released by burning one tonne of crude oil, approximately 42 GJ. There are several slightly different definitions. This is ten times as much as a tonne of TNT because atmospheric oxygen is used.\n\nLike the gram and the kilogram, the tonne gave rise to a (now obsolete) force unit of the same name, the tonne-force, equivalent to about 9.8 kilonewtons: a unit also often called simply \"tonne\" or \"metric ton\" without identifying it as a unit of force. In contrast to the tonne as a mass unit, the tonne-force or metric ton-force is not acceptable for use with SI, partly because it is not an exact multiple of the SI unit of force, the newton.\n\n\n"}
{"id": "275591", "url": "https://en.wikipedia.org/wiki?curid=275591", "title": "Tornado warning", "text": "Tornado warning\n\nA tornado warning (SAME code: TOR) is an alert issued by national weather forecasting agencies to warn the public that severe thunderstorms with tornadoes are imminent or occurring. It can be issued after a tornado, funnel cloud and rotation in the clouds has been spotted by the public, storm chasers, emergency management or law enforcement.\n\nWhen this happens, the tornado sirens may sound in that area if any sirens are present, informing people that a tornado has been sighted or may be forming nearby (because sirens are generally not heard indoors, residents should not completely depend on them). The issuance of a tornado warning indicates that residents should take immediate safety precautions.\n\nIt is a higher level of alert than a tornado watch, but (in the United States) it can be surpassed by an even higher alert known as a tornado emergency or Particularly Dangerous Situation warning.\n\nThe first official tornado forecast – and tornado warning – was made by United States Air Force Capt. (later Col.) Robert C. Miller and Major Ernest Fawbush, on March 25, 1948. The first such forecast came after the events that transpired five days earlier on March 20, 1948; Miller – a California native who became stationed at Tinker Air Force Base three weeks earlier – was assigned to work the late shift as a forecaster for the base's Air Weather Service office that evening, analyzing U.S. Weather Bureau surface maps and upper-air charts that failed to note atmospheric instability and moisture content present over Oklahoma that would be suitable for producing thunderstorm activity, erroneously forecasting dry conditions for that night. Thunderstorms soon developed southwest of Oklahoma City, and at 9:30 p.m., forecasters from Will Rogers Airport sent a warning to Tinker that the storm encroaching the city was producing wind gusts of and a \"Tornado South on Ground Moving NE!\" Base personnel received an alert written by the Staff Sarg. on duty with Miller, minutes before the twister struck Tinker several minutes later around 10:00 p.m., damaging several military aircraft (with total damage estimated at $10 million) that could not be secured in time before it crossed the base grounds.\n\nFollowing an inquiry the next day before a tribunal of five generals who traveled to Tinker from Washington, D.C., who ruled that the March 20 tornado was an \"act of God[..] not forecastable given the present state of the art\", base commander Gen. Fred Borum tasked Miller and Fawbush to follow up on the board's suggestion to consider methods of forecasting tornadic thunderstorms. Over the next three days, Miller and Fawbush studied reports and charts from previous tornado events to determine the atmospheric conditions favorable for the development of tornadic activity, in an effort to predict such events with some degree of accuracy. At the time, there had not been studies on how tornadoes formed; however, military radars were being adapted for forecasting use, allowing forecasters to see the outlines of storms but not their internal attributes such as rotation. Miller and Fawbush's findings on atmospheric phenomenon present in past outbreaks would aid in their initial forecast, as the day's surface and upper-air analysis charts determined the same conditions present on March 20 were present on the 25th, concluded that central Oklahoma would have the highest risk for tornadoes during the late-afternoon and evening.\n\nBorum, who had put together a severe weather safety plan for base personnel, then suggested that Miller and Fawbush issue a severe thunderstorm forecast, and then asked the men if they would issue a tornado forecast based on the similarities between the conditions that produced the tornado which hit the base five days earlier, which they were reluctant to do. Fawbush wrote the forecast message that Miller would type and issued it to base operations at 2:50 p.m. as thunderstorms were approaching from North Texas. Defying the high odds of two tornadoes hitting the same area in five days, one hit the Tinker campus around 6:00 p.m., to the surprise of Miller (who left the base an hour earlier, believing their forecast would not pan out), who found out about the storm (produced by two thunderstorms that merged to the southwest of Tinker) via a radio report. Miller and Fawbush would not put out another tornado forecast until March 25, 1949, when they successfully predicted tornadic activity would occur in southeastern Oklahoma.\n\nMiller and Fawbush soon would distribute their tornado forecasts to the American Red Cross and Oklahoma Highway Patrol, after giving William Maughan, chief meteorologist at the U.S. Weather Bureau's Oklahoma City office (who provided them with additional archived weather data to help fine-tune their forecasts), permission to relay their forecasts to those agencies. The relative accuracy of the forecasts restarted a debate over their reliability and whether military or civilian agencies should have jurisdiction over the issuance of weather warnings. The USAF had pioneered tornado forecasting and tornado warnings, although John P. Finley had developed the first experimental tornado forecasts in 1885, before he and other officials with the agency were prohibited by the United States Signal Service's weather service from using the word \"tornado\" in forecasts two years later, directing Finley to instead reference \"severe local storms\", a move motivated by concerns by businessmen in the Great Plains that Finley's forecasts would hurt economic development if potential investors believed their areas were tornado-prone. This position on tornado forecasting would be shared with the U.S. Weather Bureau after it was formation in 1890, fearing that it would incite panic among the public if tornadoes were predicted to occur; the side effect of this was that the lack of warning resulted in a steady increase in the number of tornado-related fatalities through the 1950s, with some events prior to 1948 (such as the deadliest tornado in U.S. history, the Tri-State Tornado in March 1925, and the Glazier–Higgins–Woodward tornadoes in April 1947) having death tolls that exceeded well over 100.\n\nIn 1938, the Weather Bureau rescinded its ban on the usage of the word \"tornado\" in weather products disseminated to emergency management personnel. The Bureau would develop a network of volunteer storm spotters in the early 1940s during World War II, to provide warning of tornadoes to workers in munitions plants and strategic factories. The ban on issuing tornado warnings to the general public would not be revoked until Chief of Bureau Francis W. Reichelderfer officially lifted the ban in a Circular Letter issued on July 12, 1950 to all first order stations: \"Weather Bureau employees should avoid statements that can be interpreted as a negation of the Bureau's willingness or ability to make tornado forecasts\", and that a \"good probability of verification\" exist when issuing such forecasts due to the difficulty in accurately predicting tornadic activity. The American Meteorological Society agreed to have Miller and Fawbush present their methodology for forecasting tornadoes during the organization's 1950 meeting in St. Louis; after garnering press coverage for their successful prediction of past tornadoes, AMS representatives decided to open the presentation to the public.\n\nThe Air Force began issuing severe weather forecasts relayed to Weather Bureau offices and emergency personnel in tornado-prone regions through the formation of the Severe Weather Warning Center in 1951, before the Bureau's contention that the USAF intruded on its responsibility to relay such forecasts led to the SWWC limiting the release of its tornado forecasts to military personnel; however, the move to prohibit the USAF from widespread releasing of tornado forecasts led to disapproval and heavy criticism from Oklahoma media outlets, given the agency's continued refusal to provide public tornado warnings. The Weather Bureau issued its first experimental public tornado forecast in March 1952, which proved inaccurate and was released too late to become widely available for public consumption; however, a forecast issued the following evening managed to predict an outbreak of tornadoes across most of the warned seven-state area (from Texas to Indiana).\n\nEven after the U.S. Weather Bureau lifted their ban on tornado warnings, the Federal Communications Commission continued to ban television and radio outlets from broadcasting tornado warnings on-air for the same reasoning cited in the Bureau's abolished ban. Broadcast media followed this ban until 1954, when meteorologist Harry Volkman broadcast the first televised tornado warning over WKY-TV (now KFOR-TV) in Oklahoma City, due to his belief that the banning of tornado warnings over broadcast media cost lives. Through an alert issued by the USAF Severe Weather Warning Center, Volkman opted to interrupt regular programming to warn viewers of a reported tornado approaching the Oklahoma City area; although station management and U.S. Weather Bureau officials were displeased with his move, WKY-TV received numerous telephone calls and letters thanking Volkman for the warning.\n\nFor many years until the early 1980s, an intermediate type of tornado advisory known as a tornado alert was defined by the National Weather Service and issued by the agency's local forecast offices, indicating that tornado formation was imminent. In theory, tornado alerts covered situations such as visible rotation in clouds and certain other phenomena which are portents of funnel cloud formation. The National Weather Service's use of this advisory began to decline after 1974, although it was still listed on public information materials issued by various media outlets, local NWS offices and other entities for another decade or so.\n\nThe criteria which called for tornado alerts in the past now generally result in a tornado warning with clarifying verbiage specifying that the warning was issued because rotation was detected in one way or another, that a wall cloud has formed or a tornado has been spotted or detected. The preferred response to both the tornado alerts and warnings is to take shelter immediately, so distinguishing them could be seen as splitting hairs, especially since storm prediction methods have improved.\n\nThe tornado alert was finally eliminated outright because it was made largely obsolete by the advent of Doppler weather radar, which can detect rotational funnel cloud formations earlier than is typically possible by trained spotters and members of the public. With fewer false-positives, radar also helped reduce public confusion over storm types, strengths and precise locations. The last tornado alert to be officially issued was discussed in earnest following the 1974 Super Outbreak.\n\nThe National Weather Service has the option of issuing a tornado emergency, a severe weather statement with unofficial, enhanced wording that is disseminated when a large, extremely violent tornado is about to impact a densely populated area. This category of weather statement is the highest and most urgent level relating to tornadoes, albeit an unofficial alert product. The first tornado emergency was declared on May 3, 1999, when an F5 tornado struck southern portions of the Oklahoma City metropolitan area, causing major damage exceeding $1 billion. In some cases, such as an F3 tornado that struck the Indianapolis, Indiana metropolitan area on September 20, 2002, a tornado emergency has been declared within the initial issuance of the tornado warning. Not all confirmed tornadoes will be considered a \"tornado emergency\", and such statements are commonly declared when it is believed that the tornado is at a severity in which it would cause a significant threat to life and property.\n\nThe levels of severity increase as follows:\n\nTornado warnings can also be intensified by added wording mentioning that the storm is life-threatening, that it is an extremely dangerous situation, that a large, violent and/or destructive tornado is on the ground or is capable of causing significant property damage.\n\nA tornado warning is issued when any of the following conditions has occurred:\n\nA \"tornado warning\" means there is immediate danger for the warned area and immediate surrounding locations – if not from the relatively narrow tornado itself, from the severe thunderstorm producing (or likely to produce) it. Those in the path of such a storm are urged to take cover immediately, as it is a life-threatening situation. A warning is different from a tornado watch (issued in the United States by a national guidance center, the Storm Prediction Center) which only indicates that conditions are favorable for the formation of tornadoes.\n\nGenerally (but not always), a tornado warning also indicates that the potential is there for severe straight-line winds and/or large hail (in the United States, winds exceeding and/or hail larger than are the respective defined criteria to classify such phenomena as severe; the criteria varies in other countries) from the thunderstorm. A severe thunderstorm warning can be upgraded suddenly to a tornado warning should conditions warrant.\n\nIn the United States, local offices of the National Weather Service outline warnings for tornadoes and severe thunderstorms in polygonal shapes for map-based weather hazard products, which are used to delineate sections of a county, parish or other jurisdiction that the warning covers (which are also referenced in NWS text warning products by the specified sections of the affected jurisdictions), based on the projected path of a storm as determined by Doppler radar at the time of the warning's issuance; however, entire counties/parishes are sometimes included in the warning polygon, especially if they encompass a small geographical area. Prior to October 2007, warnings were issued by the National Weather Service on a per-county basis. Storm Prediction Center and National Weather Service products as well as severe weather alert displays used by some television stations highlight tornado warnings with a red polygon or filled county/parish outline.\n\nIn Canada, similar criteria are used and warnings are issued by regional offices of the Meteorological Service of Canada branch of Environment Canada in Vancouver, Edmonton, Winnipeg, Toronto, Montreal and Halifax (in the province of Ontario, Emergency Management Ontario recently began issuing red alerts for areas of the province that are already under an Environment Canada-issued tornado warning; these red alerts sometimes override the tornado warning if local government or media are participating in the program).\n\nTornado warnings are generated via the Advance Weather Interactive Processing System (AWIPS) and then disseminated through various communication routes accessed by the media and various agencies, on the internet, to NOAA satellites, and on NOAA Weather Radio. Tornado sirens are also usually activated for the affected areas if present (the actual areas where sirens are activated may vary depending on the relay structure of a given jurisdiction's siren network, with some municipalities activating all sirens within their network even in areas not referenced as being included in the warning). Local police or fire departments may dispatch crews not assigned to an existing emergency call to travel within a designated area to warn residents to take tornado safety precautions if sirens are disabled due to technical problems or are not present, while automated phone calls may be made to residents for the same purpose in some areas should such disruptions occur. Additionally, if it is deemed necessary, the National Weather Service has the option of requesting activation of the Emergency Alert System to interrupt television and radio broadcasts to get the bulletin out quickly.\n\nAdvances in technology, both in identifying conditions and in distributing warnings effectively, have been credited with reducing the death toll from tornadoes. The average warning times have increased substantially from -10 to -15 minutes in 1974 to about 15 minutes (in some cases, the lead time can extend to more than an hour's warning of impending tornadoes). In the United States, the tornado death rate has declined from 1.8 deaths per million people per year in 1925 to only 0.11 per million in 2000. Much of this change is credited to improvements in the tornado warning system, via the various advances in the detection of severe local storms, along with an increase in reports visually confirming severe weather activity via storm spotters, public officials and citizens.\n\nThe SKYWARN program, which trains citizens on how to spot tornadoes, funnel clouds, wall clouds, and other severe weather phenomena, is offered by the National Weather Service. Used in tandem with Doppler radar information, eyewitness reports can be very helpful for warning the public of an impending tornado, especially when used for ground truthing.\n\nOther spotter groups such as the Amateur Radio Emergency Service, news media, local law enforcement agencies/emergency management organizations, cooperative observers, and the general public also relay information to the National Weather Service for ground truthing.\n\nBelow is an example of a Tornado Warning issued by the National Weather Service office in Des Moines, Iowa The audio files at right are for Greensburg, Kansas, and upstate South Carolina.\nBelow is an example of an Environment Canada-issued tornado warning for southeastern Saskatchewan.\n\n"}
{"id": "827692", "url": "https://en.wikipedia.org/wiki?curid=827692", "title": "Transmission tower", "text": "Transmission tower\n\nA transmission tower or power tower (electricity pylon or electric pylon in the United Kingdom, Canada and parts of Europe) is a tall structure, usually a steel lattice tower, used to support an overhead power line.\n\nThey are used in high-voltage AC and DC systems, and come in a wide variety of shapes and sizes. Typical height ranges from , though the tallest are the towers of a span of Zhoushan Island Overhead Powerline Tie. In addition to steel, other materials may be used, including concrete and wood.\n\nThere are four major categories of transmission towers: suspension, terminal, tension, and transposition. Some transmission towers combine these basic functions. Transmission towers and their overhead power lines are often considered to be a form of visual pollution. Methods to reduce the visual effect include undergrounding.\n\n\"Transmission tower\" is the name for the structure used in the industry in the United States, and some other English-speaking countries. The term \"pylon\" comes from the basic shape of the structure, an obelisk-like structure which tapers toward the top, and the name is mostly used in the United Kingdom and parts of Europe in everyday colloquial speech. This term is used infrequently in the United States, as the word \"pylon\" is commonly used for many other things, mostly for traffic cones.\n\nThree-phase electric power systems are used for high voltage (66- or 69-kV and above) and extra-high voltage (110- or 115-kV and above; most often 138- or 230-kV and above in contemporary systems) AC transmission lines. The towers must be designed to carry three (or multiples of three) conductors. The towers are usually steel lattices or trusses (wooden structures are used in Canada, Germany, and Scandinavia in some cases) and the insulators are either glass or porcelain discs or composite insulators using silicone rubber or EPDM rubber material assembled in strings or long rods whose lengths are dependent on the line voltage and environmental conditions.\n\nTypically, one or two ground wires, also called \"guard\" wires, are placed on top to intercept lightning and harmlessly divert it to ground.\n\nTowers for high- and extra-high voltage are usually designed to carry two or more electric circuits (with very rare exceptions, only one circuit for 500-kV and higher). If a line is constructed using towers designed to carry several circuits, it is not necessary to install all the circuits at the time of construction. Indeed, for economic reasons, some transmission lines are designed for three (or four) circuits, but only two (or three) circuits are initially installed.\n\nSome high voltage circuits are often erected on the same tower as 110 kV lines. Paralleling circuits of 380 kV, 220 kV and 110 kV-lines on the same towers is common. Sometimes, especially with 110 kV circuits, a parallel circuit carries traction lines for railway electrification.\n\nHigh-voltage direct current (HVDC) transmission lines are either monopolar or bipolar systems. With bipolar systems, a conductor arrangement with one conductor on each side of the tower is used. On some schemes, the ground conductor is used as electrode line or ground return. In this case, it had to be installed with insulators equipped with surge arrestors on the pylons in order to prevent electrochemical corrosion of the pylons. For single-pole HVDC transmission with ground return, towers with only one conductor can be used. In many cases, however, the towers are designed for later conversion to a two-pole system. In these cases, often conductors on both sides of the tower are installed for mechanical reasons. Until the second pole is needed, it is either used as electrode line or joined in parallel with the pole in use. In the latter case, the line from the converter station to the earthing (grounding) electrode is built as underground cable, as overhead line on a separate right of way or by using the ground conductors.\n\nElectrode line towers are used in some HVDC schemes to carry the power line from the converter station to the grounding electrode. They are similar to structures used for lines with voltages of 10–30 kV, but normally carry only one or two conductors.\n\nTowers used for single-phase AC railway traction lines are similar in construction to those towers used for 110 kV three-phase lines. Steel tube or concrete poles are also often used for these lines. However, railway traction current systems are two-pole AC systems, so traction lines are designed for two conductors (or multiples of two, usually four, eight, or twelve). As a rule, the towers of railway traction lines carry two electric circuits, so they have four conductors. These are usually arranged on one level, whereby each circuit occupies one half of the cross arm. For four traction circuits, the arrangement of the conductors is in two-levels and for six electric circuits, the arrangement of the conductors is in three levels.\n\nAC circuits of different frequency and phase-count, or AC and DC circuits, may be installed on the same tower. Usually all circuits of such lines have voltages of 50 kV and more. However, there are some lines of this type for lower voltages. For example, towers used by both railway traction power circuits and the general three-phase AC grid.\n\nTwo very short sections of line carry both AC and DC power circuits. One set of such towers is near the terminal of HVDC Volgograd-Donbass on Volga Hydroelectric Power Station. The other are two towers south of Stenkullen, which carry one circuit of HVDC Konti-Skan and üne circuit of the three-phase AC line Stenkullen-Holmbakullen.\n\nTowers carrying AC circuits and DC electrode lines exist in a section of the powerline between Adalph Static Inverter Plant and Brookston the pylons carry the electrode line of HVDC Square Butte.\n\nThe electrode line of HVDC CU at the converter station at Coal Creek Station uses on a short section the towers of two AC lines as support.\n\nThe overhead section of the electrode line of Pacific DC Intertie from Sylmar Converter Station to the grounding electrode in the Pacific Ocean near Will Rogers State Beach is also installed on AC pylons. It runs from Sylmar East Converter Station to Southern California Edison Malibu Substation, where the overhead line section ends.\n\nIn Germany, Austria and Switzerland some transmission towers carry both public AC grid circuits and railway traction power in order to better use rights of way.\n\nDifferent shapes of Transmission towers are typical for different countries. The Shape also depends on voltage and number of circuits.\n\nDelta pylons are the most common design for single circuit lines, because of their stability. They have a V-shaped body with a horizontal arm on the top, which forms an inverted Delta. Larger Delta Towers usually use two guard cables.\n\nPortal pylons are widely used in Ireland, Scandianvia and Canada. They stand on two legs with one cross arm, which gaves them a H-shape. Up to 110 kV they often were made from wood, but higher voltage lines use steel pylons.\n\nSmaller single circuit pylons may have two small cross arms on one side and one on the other.\n\nOne level pylons only have one cross arm carrying 3 cables on each side. Sometimes they have an additional cross arm for the protection cables. They are frequently used close to airports due to their reduced size.\n\nDanube pylons or \"Donaumasten\" got their name from a line built in 1927 next to the Danube river. They are the most common design in central european countries like Germany or Poland. They have two cross arms, the upper arm carries one and the lower arm carries two cables on each side. Sometimes they have an additional cross arm for the protection cables.\n\nTon shaped towers are the most common design, they have 3 horizontal levels with one cable very close to the pylon on each side. In the United Kingdom the second level is wider than the other ones while in the United States all cross arms have the same width.\n\nChristmas-tree-shaped towers for 4 or even 6 circuits are common in Germany and have 3 cross arms where the highest arm has each one cable, the second has two cables and the third has three cables on each side. The cables on the third arm usually carry circuits for lower high voltage.\n\nTowers may be self-supporting and capable of resisting all forces due to conductor loads, unbalanced conductors, wind and ice in any direction. Such towers often have approximately square bases and usually four points of contact with the ground.\n\nA semi-flexible tower is designed so that it can use overhead grounding wires to transfer mechanical load to adjacent structures, if a phase conductor breaks and the structure is subject to unbalanced loads. This type is useful at extra-high voltages, where phase conductors are bundled (two or more wires per phase). It is unlikely for all of them to break at once, barring a catastrophic crash or storm.\n\nA guyed mast has a very small footprint and relies on guy wires in tension to support the structure and any unbalanced tension load from the conductors. A guyed tower can be made in a V shape, which saves weight and cost.\n\nPoles made of tubular steel generally are assembled at the factory and placed on the right-of-way afterward. Because of its durability and ease of manufacturing and installation, many utilities in recent years prefer the use of monopolar steel or concrete towers over lattice steel for new power lines and tower replacements. \n\nIn Germany steel tube pylons are also established predominantly for medium voltage lines, in addition, for high voltage transmission lines or two electric circuits for operating voltages by up to 110 kV. Steel tube pylons are also frequently used for 380 kV lines in France, and for 500 kV lines in the United States.\n\nA lattice tower is a framework construction made of steel or aluminium sections. Lattice towers are used for power lines of all voltages, and are the most common type for high-voltage transmission lines. Lattice towers are usually made of galvanized steel. Aluminium is used for reduced weight, such as in mountainous areas where structures are placed by helicopter. Aluminium is also used in environments that would be corrosive to steel. The extra material cost of aluminium towers will be offset by lower installation cost. Design of aluminium lattice towers is similar to that for steel, but must take into account aluminium's lower Young's modulus.\n\nA lattice tower is usually assembled at the location where it is to be erected. This makes very tall towers possible, up to (and in special cases even higher, as in the Elbe crossing 1 and Elbe crossing 2). Assembly of lattice steel towers can be done using a crane. Lattice steel towers are generally made of angle-profiled steel beams (L- or T-beams). For very tall towers, trusses are often used.\n\nWood is a material which is limited in use in high-voltage transmission. Because of the limited height of available trees, the maximum height of wooden pylons is limited to approximately . Wood is rarely used for lattice framework. Instead, they are used to build multi-pole structures, such as H-frame and K-frame structures. The voltages they carry are also limited, such as in other regions, where wood structures only carry voltages up to approximately 30 kV.\n\nIn countries such as Canada or the United States, wooden towers carry voltages up to 345 kV; these can be less costly than steel structures and take advantage of the surge voltage insulating properties of wood. , 345 kV lines on wood towers are still in use in the US and some are still being constructed on this technology. Wood can also be used for temporary structures while constructing a permanent replacement.\n\nConcrete pylons are used in Germany normally only for lines with operating voltages below 30 kV. In exceptional cases, concrete pylons are used also for 110 kV lines, as well as for the public grid or for the railway traction current grid. In Switzerland, concrete pylons with heights of up to 59.5 metres (world's tallest pylon of prefabricated concrete at Littau) are used for 380 kV overhead lines. Concrete poles are also used in Canada and the United States.\n\nConcrete pylons, which are not prefabricated, are also used for constructions taller than 60 metres. One example is a tall pylon of a 380 kV powerline near Reuter West Power Plant in Berlin. Such pylons look like industrial chimneys. In China some pylons for lines crossing rivers were built of concrete. The tallest of these pylons belong to the Yangtze Powerline crossing at Nanjing with a height of .\n\nSometimes (in particular on steel lattice towers for the highest voltage levels) transmitting plants are installed, and antennas mounted on the top above or below the overhead ground wire. Usually these installations are for mobile phone services or the operating radio of the power supply firm, but occasionally also for other radio services, like directional radio. Thus transmitting antennas for low-power FM radio and television transmitters were already installed on pylons. On the Elbe Crossing 1 tower, there is a radar facility belonging to the Hamburg water and navigation office.\n\nFor crossing broad valleys, a large distance between the conductors must be maintained to avoid short-circuits caused by conductor cables colliding during storms. To achieve this, sometimes a separate mast or tower is used for each conductor. For crossing wide rivers and straits with flat coastlines, very tall towers must be built due to the necessity of a large height clearance for navigation. Such towers and the conductors they carry must be equipped with flight safety lamps and reflectors.\n\nTwo well-known wide river crossings are the Elbe Crossing 1 and Elbe Crossing 2. The latter has the tallest overhead line masts in Europe, at tall. In Spain, the overhead line crossing pylons in the Spanish bay of Cádiz have a particularly interesting construction. The main crossing towers are tall with one crossarm atop a frustum framework construction. The longest overhead line spans are the crossing of the Norwegian Sognefjord ( between two masts) and the Ameralik Span in Greenland (). In Germany, the overhead line of the EnBW AG crossing of the Eyachtal has the longest span in the country at .\n\nIn order to drop overhead lines into steep, deep valleys, inclined towers are occasionally used. These are utilized at the Hoover Dam, located in the United States, to descend the cliff walls of the Black Canyon of the Colorado. In Switzerland, a NOK pylon inclined around 20 degrees to the vertical is located near Sargans, St. Gallens. Highly sloping masts are used on two 380 kV pylons in Switzerland, the top 32 meters of one of them being bent by 18 degrees to the vertical.\n\nPower station chimneys are sometimes equipped with crossbars for fixing conductors of the outgoing lines. Because of possible problems with corrosion by flue gases, such constructions are very rare.\n\nA new type of pylon will be used in the Netherlands starting in 2010. The pylons were designed as a minimalist structure by Dutch architects Zwarts and Jansma. The use of physical laws for the design made a reduction of the magnetic field possible. Also, the visual impact on the surrounding landscape is reduced.\n\nTwo clown-shaped pylons appear in Hungary, on both sides of the M5 motorway, near Újhartyán. ( )\n\nBefore transmission towers are even erected, prototype towers are tested at tower testing stations. There are a variety of ways they can then be assembled and erected:\n\n\nThe International Civil Aviation Organization issues recommendations on markers for towers and the conductors suspended between them. Certain jurisdictions will make these recommendations mandatory, for example that certain power lines must have overhead wire markers placed at intervals, and that warning lights be placed on any sufficiently high towers, this is particularly true of transmission towers which are in close vicinity to airports.\n\nElectricity pylons often have an identification tag marked with the name of the line (either the terminal points of the line or the internal designation of the power company) and the tower number. This makes identifying the location of a fault to the power company that owns the tower easier.\n\nTransmission towers, much like other steel lattice towers including broadcasting or cellphone towers, are marked with signs which discourage public access due to the danger of the high voltage. Often this is accomplished with a sign warning of the high voltage. At other times, the entire access point to the transmission corridor is marked with a sign. Some countries require that lattice steel towers be equipped with a barbed wire barrier approximately above ground in order to deter unauthorized climbing. Such barriers can often be found on towers close to roads or other areas with easy public access, even where there is not a legal requirement. In the United Kingdom, all such towers are fitted with barbed wire.\n\nTower structures can be classified by the way in which they support the line conductors. Suspension structures support the conductor vertically using suspension insulators. Strain structures resist net tension in the conductors and the conductors attach to the structure through strain insulators. Dead-end structures support the full weight of the conductor and also all the tension in it, and also use strain insulators.\n\nStructures are classified as tangent suspension, angle suspension, tangent strain, angle strain, tangent dead-end and angle dead-end. Where the conductors are in a straight line, a tangent tower is used. Angle towers are used where a line must change direction.\n\nGenerally three conductors are required per AC 3-phase circuit, although single-phase and DC circuits are also carried on towers. Conductors may be arranged in one plane, or by use of several cross-arms may be arranged in a roughly symmetrical, triangulated pattern to balance the impedances of all three phases. If more than one circuit is required to be carried and the width of the line right-of-way does not permit multiple towers to be used, two or three circuits can be carried on the same tower using several levels of cross-arms. Often multiple circuits are the same voltage, but mixed voltages can be found on some structures.\n\nThe following electricity transmission towers are notable due to their enormous height, unusual design, unusual construction site or their use in artworks.\n\n\n"}
{"id": "8718594", "url": "https://en.wikipedia.org/wiki?curid=8718594", "title": "Trolleytruck", "text": "Trolleytruck\n\n\"For the alternative name for a sack truck (trolley truck), see Hand truck\"\n\nA trolleytruck (also known as a freight trolley or trolley truck) is a trolleybus-like vehicle used for carrying cargo instead of passengers. A trolleytruck is usually a type of electric truck powered by two overhead wires, from which it draws electricity using two trolley poles or two pantographs. Two current collectors are required in order to supply and return current, because the return current cannot pass to the ground (as is done by streetcars on rails) since trolleytrucks use tires that are insulators. Lower powered trucks, such as might be seen on the streets of a city, tend to use trolley poles for current collection. Higher powered trucks, such as those used for large construction or mining projects, may exceed the power capacity of trolley poles and have to use pantographs instead. Trolleytrucks have been used in various places around the world and are still in use in cities in Russia and Ukraine, as well as at mines in North America and Africa. Because they draw power from the mains, trolleytrucks can use renewable energy sources – modern trolleytrucks systems are under test in Sweden and Germany along highways using diesel-electric hybrids to reduce emissions.\n\nTrolleytrucks were used in St. Lambrecht, Austria by the Nobel Industries dynamite factory from 16 November 1945 to 21 April 1951. Trolleytrucks were used to carry dynamite over the Alps just after World War II due to the shortages of material that for a time prevented the use of diesel trucks. In the 1950s the material shortages had been alleviated so the trolleytrucks were replaced with diesel trucks and the former power lines were taken down. Some trucks from the abandoned line were reconverted to passenger trams and used along streets in Kapfenberg.\n\nA Ukrainian built trolleytruck started service in Pleven, Bulgaria in 1987, but that truck may no longer be in service since it is stored in the trolleybus depot.\n\nThe Québec Cartier Mining Company used trolleytrucks in its iron ore mine in Québec from 1970 until 1977 when the iron ore deposit was exhausted and the mine closed down. The power supply for this remote mine was a power plant taken out of a diesel electric railroad locomotive.\n\nThe German Federal Ministry for the Environment is building a network of overhead wires along the autobahn for diesel-electric hybrids, allowing trucks to cruise on electric power. A short test stretch has been built in Brandenburg, with longer routes in Hesse and Schleswig-Holstein planned for 2018.\n\nTrolleytrucks were used by the AEM electric utility company of Milan, Italy to supply construction materials and service to the San Giacomo Dam (constructed 1940-1950) and the second Cancano Dam (constructed 1952-1956). The two trolleytruck lines in the Valtellina valley that helped to build then supply the dams\nalong the Spöl river were used from 1938 to 1962.\n\nThe Rössing Uranium Mine in Namibia installed a trolley assist system around 1986. The diesel electric drive Komatsu 730E dump trucks were converted at that time to use trolley power assist for the climb out of the mine to the crusher. The fleet numbered more than 10 vehicles as of 2001.\n\nTrolleytrucks were introduced to the Palabora copper mine in South Africa in 1980.\n\nThe South African Iron and Steel Industrial Corporation (ISCOR) installed a trolley power assist line\nfor diesel electric trucks at its Shishen mine in March 1982. Afterwards the company also installed a trolley power assist system at its Grootegeluk coal mine in Lephalale, South Africa. ISCOR (now known as Mittal Steel South Africa) is the largest user of trolley power assist trolleytruck systems in the world.\n\nMany cities in the Soviet Union operated trolleytrucks. The MAZ-525 truck model was converted to a trolleytruck design in 1954 in Kharkiv, Ukraine. The Kharkiv experiment with trolleytrucks was stopped because of disadvantages.\n\nNowadays trolleytrucks operate in several cities in Ukraine such as Donetsk and Sevastopol as well as cities in Russia such as Bryansk and Saint Petersburg. One type, the KTG-1, is made for service and repair of the urban trolleybus vehicles; while another, the KTG-2, is used for transporting goods.\nThe first public electrified motorway opened in Sweden on 22 June 2016 on a stretch of European route E16 near Gävle, allowing hybrid and battery electric Scania lorries to run from overhead wires.\n\nTrolleytrucks were used in Gümmenen and Mühleberg Switzerland between 1918 and 1922 during the construction of the dam that retains Lake Wohlen. The trucks were built by Tribelhorn, and they used the Stoll system of current collection.\n\nTrolleytrucks have been used in mining operations and in road maintenance projects in the United States.\n\nFrom 1939 to 1964 the International Salt Company mine in River Rouge, Michigan used trolleytrucks that were converted Euclid models. This was an underground salt mine. Batteries were used to power the trucks when they strayed away from the overhead wires. For use within a mine the overhead wires may occasionally be relocated as excavation activity progresses. Hence the trolleytrucks used in mines do not necessarily have a travel route that is as fixed as the trolleytruck routes used in cities.\n\nFrom 1956 to 1971 the Riverside Cement Company in Bloomington, California operated Kenworth dump trucks converted to trolleytruck use at the Crestmore Quarry near Riverside, California. The trucks were equipped with \"extension cords\" for use of electric power near the shovel down in the mine. The long extension cords stored on powered reels aboard the trolleytrucks offered them increased mobility right at the load point.\n\nIn 2015, a demonstration phase will start for an eHighway system in the area served by the Port of Los Angeles and Port of Long Beach. Initially, the eHighway will be a one-mile two-way stretch of road on the north- and south-bound sections of Alameda Street where it intersects with Sepulveda Boulevard in Carson, California. Construction of the system is expected to start immediately, and the first trucks should connect to the system in July 2015. When the trucks aren’t travelling the eHighway, they can run on diesel, compressed natural gas (CNG), battery or other energy source. They are build by Mack Trucks in cooperation with Siemens. The demonstration phase is scheduled to last for one year. \n\nThe El Chino Mine near Santa Rita, New Mexico installed trolleytrucks in 1967. The trucks are equipped with diesel engines and the trolley power is used to assist the trucks up and down the ramp that leads into the mine. This type of double power arrangement is known as a \"trolley assist\" system.\n\nBarrick's Goldstrike mine, Nevada used trolleytrucks from 1994 to 2001 when the trolley system was decommissioned due to a large reconfiguration of the mine. The system was similar to the one used in the Palabora copper mine in South Africa.\nTrolleytrucks were used in the Zambia Consolidated Copper Mines Nchanga Mine in Zambia from 1983 until later in the 1980s. Inexpensive hydroelectricity is generated at the Kariba Power Station along the Zambezi river and distributed throughout the \"copper belt\" of Zambia. The current delivery for the trolley power assisted diesel trucks () was done\nthrough custom designed bus bars and large current collection shoes mounted on very large trolley pole-like collectors.\n\n\n"}
{"id": "35670796", "url": "https://en.wikipedia.org/wiki?curid=35670796", "title": "Valley-fill circuit", "text": "Valley-fill circuit\n\nA valley-fill circuit is a type of passive power factor correction (PFC) circuit.\nFor purposes of illustration, a basic full-wave diode-bridge rectifier is shown in the first stage, which converts the AC input voltage to a DC voltage. \n\nWhen the AC voltage is applied, the rectified line voltage is applied across C1 and C2, as they are both charged via D3 and R1, until C1 and C2 are each charged up to approximately half of the peak line voltage. \nWhen the line voltage falls below the peak, into the \"valley\" phase, Vout begins to fall toward half of the peak line voltage. At this point, C1 and C2 begin to discharge into the load at Vout, via D1 and D2 respectively. \nR1 is needed to prevent a large in-rush current, and electromagnetic interference (EMI).\n\nAn advantage of this design is that it is rather simple. A disadvantage is that the ripple voltage can still be 50% of peak, and have total harmonic distortion (THD) of 35%, which is rather high. A 1998 United States patent, US6141230A, provides a power factor of 0.98 and a THD of 9.61%.\n"}
{"id": "27701446", "url": "https://en.wikipedia.org/wiki?curid=27701446", "title": "Wild Well Control", "text": "Wild Well Control\n\nWild Well Control is a well control company based in Houston, Texas that has worked to mitigate several high-profile well control issues including the Kuwaiti oil fires and the Deepwater Horizon oil spill.\n\nAccording to its website it has responded to 2,700 well control and pressure control events including the majority of the large international well control emergencies.\n\nIt is a subsidiary of Superior Energy Services.\n\nWild Well Control was founded by Joe R. Bowden, Sr. in 1975 (July 15, 1932 – November 12, 2006). Its main competition was Red Adair and Company. In 1991 it was one of the companies used to cap the Kuwaiti oil fires. Its involvement was the subject of the documentary \"Fires of Kuwait\". In 2001 it was acquired by Superior Energy Services.\n\nIn 2008 it received a contract for $750 million to decommission seven downed platforms and related well facilities located offshore Louisiana belonging to BP, Chevron, and Apache Corporation.\n\nIn 2010 it was designated by BP to come up with a way to cap the Deepwater Horizon oil spill. \n\n"}
{"id": "57820113", "url": "https://en.wikipedia.org/wiki?curid=57820113", "title": "Zotye Z100", "text": "Zotye Z100\n\nThe Zotye Z100 is a subcompact hatchback produced by Zotye Auto. Originally launched as the new Jiangnan TT in prototype form, the production version was renamed to Zotye Z100 to fit into the refreshed Zotye product line. \nThe Zotye Z100 debuted during the 2012 Shanghai Auto Show, and was launched in the Chinese market since September 2013, replacing the Jiangnan TT, which was based on the Suzuki Alto CA71 sold from 1988 to 2013 in China. The only engine choice for the Z100 is a 1.0 litre 3 cylinder engine known as the TNN3G10K. A 5 speed manual is also paired with it. It is currently the cheapest car in China ranging from 30,000 yuan to 35,000 yuan. \n\nDespite the styling of the Zotye Z100 being very similar to the Suzuki Alto, and the predecessor, Jiangnan TT being a licensed rebadge version of the Suzuki Alto, the Zotye Z100 has nothing to do with Suzuki, but rather a car with styling heavily inspired by the Suzuki Alto. The Zotye Z100 was discontinued after a short run, but the electric versions including the Zotye Cloud 100Plus and Zotye Cloud 100S continued to be sold.\n\n"}
