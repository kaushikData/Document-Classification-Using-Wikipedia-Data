{"id": "27113087", "url": "https://en.wikipedia.org/wiki?curid=27113087", "title": "2010 World Geothermal Congress", "text": "2010 World Geothermal Congress\n\nThe 2010 World Geothermal Congress took place between April 25-30, 2010 in Bali, Indonesia. It was called the world's biggest geothermal energy conference.\n\nThe World Geothermal Congress is organized every five years by the International Geothermal Association. The previous three conferences took place in Florence, Italy (1995), Beppu-Morioka, Japan (2000) and Antalya, Turkey (2005).\n\nAttendees from 80 countries were discussing better ways to develop geothermal power as an environmentally friendly energy source which can be harnessed in the future for less cost than it is today.\n\nThe Summit was opened by Indonesian president, Susilo Bambang Yudhoyono at Westin Hotel, Nusa Dua, Bali. The opening was marked by the signing of 12 geothermal-related contracts worth in the range of US$5 billion. Among the contracts were agreements between the Indonesian state power firm PT PLN and PT Pertamina Geothermal Energy (PGE) - a geothermal business branch of state oil and gas company PT Pertamina - to develop four geothermal power plants in Sulawesi and Sumatra.\n\nThe Congress concluded with over 2,500 participants signing the Bali Declaration \"Geothermal Energy to Change the World\" during the closing ceremony.\n\n\n"}
{"id": "43196624", "url": "https://en.wikipedia.org/wiki?curid=43196624", "title": "Althorpe Islands Conservation Park", "text": "Althorpe Islands Conservation Park\n\nAlthorpe Islands Conservation Park is a protected area in the Australian state of South Australia occupying the Althorpe Islands, Haystack Island and Seal Island in Investigator Strait near the town of Stenhouse Bay. The conservation park was proclaimed in 1972 following the enactment of the \"National Parks and Wildlife Act 1972\" with the protection initially applying to the Western Islets in the Althorpe Islands, Haystack Island and Seal Island with Althorpe Island itself was not added until 1997. The purpose of the conservation park is ‘to protect important wildlife habitat, particularly for sea-bird populations’. It is classified as an IUCN Category Ia protected area.\n\n"}
{"id": "900", "url": "https://en.wikipedia.org/wiki?curid=900", "title": "Americium", "text": "Americium\n\nAmericium is a synthetic chemical element with symbol Am and atomic number 95. It is radioactive and a transuranic member of the actinide series, in the periodic table located under the lanthanide element europium, and thus by analogy was named after the Americas.\n\nAmericium was first produced in 1944 by the group of Glenn T. Seaborg from Berkeley, California, at the Metallurgical Laboratory of the University of Chicago, a part of the Manhattan Project. Although it is the third element in the transuranic series, it was discovered fourth, after the heavier curium. The discovery was kept secret and only released to the public in November 1945. Most americium is produced by uranium or plutonium being bombarded with neutrons in nuclear reactors – one tonne of spent nuclear fuel contains about 100 grams of americium. It is widely used in commercial ionization chamber smoke detectors, as well as in neutron sources and industrial gauges. Several unusual applications, such as nuclear batteries or fuel for space ships with nuclear propulsion, have been proposed for the isotope Am, but they are as yet hindered by the scarcity and high price of this nuclear isomer.\n\nAmericium is a relatively soft radioactive metal with silvery appearance. Its common isotopes are Am and Am. In chemical compounds, americium usually assumes the oxidation state +3, especially in solutions. Several other oxidation states are known, which range from +2 to +7 and can be identified by their characteristic optical absorption spectra. The crystal lattice of solid americium and its compounds contain small intrinsic radiogenic defects, due to metamictization induced by self-irradiation with alpha particles, which accumulates with time; this can cause a drift of some material properties over time, more noticeable in older samples.\n\nAlthough americium was likely produced in previous nuclear experiments, it was first intentionally synthesized, isolated and identified in late autumn 1944, at the University of California, Berkeley, by Glenn T. Seaborg, Leon O. Morgan, Ralph A. James, and Albert Ghiorso. They used a 60-inch cyclotron at the University of California, Berkeley. The element was chemically identified at the Metallurgical Laboratory (now Argonne National Laboratory) of the University of Chicago. Following the lighter neptunium, plutonium, and heavier curium, americium was the fourth transuranium element to be discovered. At the time, the periodic table had been restructured by Seaborg to its present layout, containing the actinide row below the lanthanide one. This led to americium being located right below its twin lanthanide element europium; it was thus by analogy named after the Americas: \"The name americium (after the Americas) and the symbol Am are suggested for the element on the basis of its position as the sixth member of the actinide rare-earth series, analogous to europium, Eu, of the lanthanide series.\"\n\nThe new element was isolated from its oxides in a complex, multi-step process. First plutonium-239 nitrate (PuNO) solution was coated on a platinum foil of about 0.5 cm area, the solution was evaporated and the residue was converted into plutonium dioxide (PuO) by annealing. After cyclotron irradiation, the coating was dissolved with nitric acid, and then precipitated as the hydroxide using concentrated aqueous ammonia solution. The residue was dissolved in perchloric acid. Further separation was carried out by ion exchange, yielding a certain isotope of curium. The separation of curium and americium was so painstaking that those elements were initially called by the Berkeley group as \"pandemonium\" (from Greek for \"all demons\" or \"hell\") and \"delirium\" (from Latin for \"madness\").\n\nInitial experiments yielded four americium isotopes: Am, Am, Am and Am. Americium-241 was directly obtained from plutonium upon absorption of two neutrons. It decays by emission of a α-particle to Np; the half-life of this decay was first determined as years but then corrected to 432.2 years.\n\nThe second isotope Am was produced upon neutron bombardment of the already-created Am. Upon rapid β-decay, Am converts into the isotope of curium Cm (which had been discovered previously). The half-life of this decay was initially determined at 17 hours, which was close to the presently accepted value of 16.02 h.\n\nThe discovery of americium and curium in 1944 was closely related to the Manhattan Project; the results were confidential and declassified only in 1945. Seaborg leaked the synthesis of the elements 95 and 96 on the U.S. radio show for children \"Quiz Kids\" five days before the official presentation at an American Chemical Society meeting on 11 November 1945, when one of the listeners asked whether any new transuranium element beside plutonium and neptunium had been discovered during the war. After the discovery of americium isotopes Am and Am, their production and compounds were patented listing only Seaborg as the inventor. The initial americium samples weighed a few micrograms; they were barely visible and were identified by their radioactivity. The first substantial amounts of metallic americium weighing 40–200 micrograms were not prepared until 1951 by reduction of americium(III) fluoride with barium metal in high vacuum at 1100 °C.\n\nThe longest-lived and most common isotopes of americium, Am and Am, have half-lives of 432.2 and 7,370 years, respectively. Therefore, any primordial americium (americium that was present on Earth during its formation) should have decayed by now.\n\nExisting americium is concentrated in the areas used for the atmospheric nuclear weapons tests conducted between 1945 and 1980, as well as at the sites of nuclear incidents, such as the Chernobyl disaster. For example, the analysis of the debris at the testing site of the first U.S. hydrogen bomb, Ivy Mike, (1 November 1952, Enewetak Atoll), revealed high concentrations of various actinides including americium; but due to military secrecy, this result was not published until later, in 1956. Trinitite, the glassy residue left on the desert floor near Alamogordo, New Mexico, after the plutonium-based Trinity nuclear bomb test on 16 July 1945, contains traces of americium-241. Elevated levels of americium were also detected at the crash site of a US Boeing B-52 bomber aircraft, which carried four hydrogen bombs, in 1968 in Greenland.\n\nIn other regions, the average radioactivity of surface soil due to residual americium is only about 0.01 picocuries/g (0.37 mBq/g). Atmospheric americium compounds are poorly soluble in common solvents and mostly adhere to soil particles. Soil analysis revealed about 1,900 times higher concentration of americium inside sandy soil particles than in the water present in the soil pores; an even higher ratio was measured in loam soils.\n\nAmericium is produced mostly artificially in small quantities, for research purposes. A tonne of spent nuclear fuel contains about 100 grams of various americium isotopes, mostly Am and Am. Their prolonged radioactivity is undesirable for the disposal, and therefore americium, together with other long-lived actinides, must be neutralized. The associated procedure may involve several steps, where americium is first separated and then converted by neutron bombardment in special reactors to short-lived nuclides. This procedure is well known as nuclear transmutation, but it is still being developed for americium. The transuranic elements from americium to fermium occurred naturally in the natural nuclear fission reactor at Oklo, but no longer do so.\n\nAmericium has been produced in small quantities in nuclear reactors for decades, and kilograms of its Am and Am isotopes have been accumulated by now. Nevertheless, since it was first offered for sale in 1962, its price, about 1,500 USD per gram of Am, remains almost unchanged owing to the very complex separation procedure. The heavier isotope Am is produced in much smaller amounts; it is thus more difficult to separate, resulting in a higher cost of the order 100,000–160,000 USD/g.\n\nAmericium is not synthesized directly from uranium – the most common reactor material – but from the plutonium isotope Pu. The latter needs to be produced first, according to the following nuclear process:\n\nThe capture of two neutrons by Pu (a so-called (n,γ) reaction), followed by a β-decay, results in Am:\n\nThe plutonium present in spent nuclear fuel contains about 12% of Pu. Because it spontaneously converts to Am, Pu can be extracted and may be used to generate further Am. However, this process is rather slow: half of the original amount of Pu decays to Am after about 15 years, and the Am amount reaches a maximum after 70 years.\n\nThe obtained Am can be used for generating heavier americium isotopes by further neutron capture inside a nuclear reactor. In a light water reactor (LWR), 79% of Am converts to Am and 10% to its nuclear isomer Am:\nAmericium-242 has a half-life of only 16 hours, which makes its further up-conversion to Am, extremely inefficient. The latter isotope is produced instead in a process where Pu captures four neutrons under high neutron flux:\n\nMost synthesis routines yield a mixture of different actinide isotopes in oxide forms, from which isotopes of americium can be separated. In a typical procedure, the spent reactor fuel (e.g. MOX fuel) is dissolved in nitric acid, and the bulk of uranium and plutonium is removed using a PUREX-type extraction (Plutonium–URanium EXtraction) with tributyl phosphate in a hydrocarbon. The lanthanides and remaining actinides are then separated from the aqueous residue (raffinate) by a diamide-based extraction, to give, after stripping, a mixture of trivalent actinides and lanthanides. Americium compounds are then selectively extracted using multi-step chromatographic and centrifugation techniques with an appropriate reagent. A large amount of work has been done on the solvent extraction of americium. For example, a 2003 EU-funded project codenamed \"EUROPART\" studied triazines and other compounds as potential extraction agents. A \"bis\"-triazinyl bipyridine complex was proposed in 2009 as such a reagent is highly selective to americium (and curium). Separation of americium from the highly similar curium can be achieved by treating a slurry of their hydroxides in aqueous sodium bicarbonate with ozone, at elevated temperatures. Both Am and Cm are mostly present in solutions in the +3 valence state; whereas curium remains unchanged, americium oxidizes to soluble Am(IV) complexes which can be washed away.\n\nMetallic americium is obtained by reduction from its compounds. Americium(III) fluoride was first used for this purpose. The reaction was conducted using elemental barium as reducing agent in a water- and oxygen-free environment inside an apparatus made of tantalum and tungsten.\n\nAn alternative is the reduction of americium dioxide by metallic lanthanum or thorium:\n\nIn the periodic table, americium is located to the right of plutonium, to the left of curium, and below the lanthanide europium, with which it shares many similarities in physical and chemical properties. Americium is a highly radioactive element. When freshly prepared, it has a silvery-white metallic lustre, but then slowly tarnishes in air. With a density of 12 g/cm, americium is less dense than both curium (13.52 g/cm) and plutonium (19.8 g/cm); but has a higher density than europium (5.264 g/cm)—mostly because of its higher atomic mass. Americium is relatively soft and easily deformable and has a significantly lower bulk modulus than the actinides before it: Th, Pa, U, Np and Pu. Its melting point of 1173 °C is significantly higher than that of plutonium (639 °C) and europium (826 °C), but lower than for curium (1340 °C).\n\nAt ambient conditions, americium is present in its most stable α form which has a hexagonal crystal symmetry, and a space group P6/mmc with lattice parameters \"a\" = 346.8 pm and \"c\" = 1124 pm, and four atoms per unit cell. The crystal consists of a double-hexagonal close packing with the layer sequence ABAC and so is isotypic with α-lanthanum and several actinides such as α-curium. The crystal structure of americium changes with pressure and temperature. When compressed at room temperature to 5 GPa, α-Am transforms to the β modification, which has a face-centered cubic (\"fcc\") symmetry, space group Fmm and lattice constant \"a\" = 489 pm. This \"fcc\" structure is equivalent to the closest packing with the sequence ABC. Upon further compression to 23 GPa, americium transforms to an orthorhombic γ-Am structure similar to that of α-uranium. There are no further transitions observed up to 52 GPa, except for an appearance of a monoclinic phase at pressures between 10 and 15 GPa. There is no consistency on the status of this phase in the literature, which also sometimes lists the α, β and γ phases as I, II and III. The β-γ transition is accompanied by a 6% decrease in the crystal volume; although theory also predicts a significant volume change for the α-β transition, it is not observed experimentally. The pressure of the α-β transition decreases with increasing temperature, and when α-americium is heated at ambient pressure, at 770 °C it changes into an \"fcc\" phase which is different from β-Am, and at 1075 °C it converts to a body-centered cubic structure. The pressure-temperature phase diagram of americium is thus rather similar to those of lanthanum, praseodymium and neodymium.\n\nAs with many other actinides, self-damage of the crystal lattice due to alpha-particle irradiation is intrinsic to americium. It is especially noticeable at low temperatures, where the mobility of the produced lattice defects is relatively low, by broadening of X-ray diffraction peaks. This effect makes somewhat uncertain the temperature of americium and some of its properties, such as electrical resistivity. So for americium-241, the resistivity at 4.2 K increases with time from about 2 µOhm·cm to 10 µOhm·cm after 40 hours, and saturates at about 16 µOhm·cm after 140 hours. This effect is less pronounced at room temperature, due to annihilation of radiation defects; also heating to room temperature the sample which was kept for hours at low temperatures restores its resistivity. In fresh samples, the resistivity gradually increases with temperature from about 2 µOhm·cm at liquid helium to 69 µOhm·cm at room temperature; this behavior is similar to that of neptunium, uranium, thorium and protactinium, but is different from plutonium and curium which show a rapid rise up to 60 K followed by saturation. The room temperature value for americium is lower than that of neptunium, plutonium and curium, but higher than for uranium, thorium and protactinium.\n\nAmericium is paramagnetic in a wide temperature range, from that of liquid helium, to room temperature and above. This behavior is markedly different from that of its neighbor curium which exhibits antiferromagnetic transition at 52 K. The thermal expansion coefficient of americium is slightly anisotropic and amounts to along the shorter \"a\" axis and for the longer \"c\" hexagonal axis. The enthalpy of dissolution of americium metal in hydrochloric acid at standard conditions is , from which the standard enthalpy change of formation (Δ\"H\"°) of aqueous Am ion is . The standard potential Am/Am is .\n\nAmericium readily reacts with oxygen and dissolves well in acids. The most common oxidation state for americium is +3, in which americium compounds are rather stable against oxidation and reduction. In this sense, americium is chemically similar to most lanthanides. The trivalent americium forms insoluble fluoride, oxalate, iodate, hydroxide, phosphate and other salts. Other oxidation states have been observed between +2 and +7, which is the widest range among the actinide elements. Their color in aqueous solutions varies as follows: Am (colorless to yellow-reddish), Am (yellow-reddish), Am; (yellow), Am (brown) and Am (dark green). All oxidation states have their characteristic optical absorption spectra, with a few sharp peaks in the visible and mid-infrared regions, and the position and intensity of these peaks can be converted into the concentrations of the corresponding oxidation states. For example, Am(III) has two sharp peaks at 504 and 811 nm, Am(V) at 514 and 715 nm, and Am(VI) at 666 and 992 nm.\n\nAmericium compounds with oxidation state +4 and higher are strong oxidizing agents, comparable in strength to the permanganate ion () in acidic solutions. Whereas the Am ions are unstable in solutions and readily convert to Am, the +4 oxidation state occurs well in solids, such as americium dioxide (AmO) and americium(IV) fluoride (AmF).\n\nAll pentavalent and hexavalent americium compounds are complex salts such as KAmOF, LiAmO and LiAmO, BaAmO, AmOF. These high oxidation states Am(IV), Am(V) and Am(VI) can be prepared from Am(III) by oxidation with ammonium persulfate in dilute nitric acid, with silver(I) oxide in perchloric acid, or with ozone or sodium persulfate in sodium carbonate solutions. The pentavalent oxidation state of americium was first observed in 1951. It is present in aqueous solution in the form of ions (acidic) or ions (alkaline) which are however unstable and subject to several rapid disproportionation reactions:\n\nThree americium oxides are known, with the oxidation states +2 (AmO), +3 (AmO) and +4 (AmO). Americium(II) oxide was prepared in minute amounts and has not been characterized in details. Americium(III) oxide is a red-brown solid with a melting point of 2205 °C. Americium(IV) oxide is the main form of solid americium which is used in nearly all its applications. As most other actinide dioxides, it is a black solid with a cubic (fluorite) crystal structure.\n\nThe oxalate of americium(III), vacuum dried at room temperature, has the chemical formula Am(CO)·7HO. Upon heating in vacuum, it loses water at 240 °C and starts decomposing into AmO at 300 °C, the decomposition completes at about 470 °C. The initial oxalate dissolves in nitric acid with the maximum solubility of 0.25 g/L.\n\nHalides of americium are known for the oxidation states +2, +3 and +4, where the +3 is most stable, especially in solutions.\n\nReduction of Am(III) compounds with sodium amalgam yields Am(II) salts – the black halides AmCl, AmBr and AmI. They are very sensitive to oxygen and oxidize in water, releasing hydrogen and converting back to the Am(III) state. Specific lattice constants are:\n\nAmericium(III) fluoride (AmF) is poorly soluble and precipitates upon reaction of Am and fluoride ions in weak acidic solutions:\n\nThe tetravalent americium(IV) fluoride (AmF) is obtained by reacting solid americium(III) fluoride with molecular fluorine:\n\nAnother known form of solid tetravalent americium chloride is KAmF. Tetravalent americium has also been observed in the aqueous phase. For this purpose, black Am(OH) was dissolved in 15-M NHF with the americium concentration of 0.01 M. The resulting reddish solution had a characteristic optical absorption spectrum which is similar to that of AmF but differed from other oxidation states of americium. Heating the Am(IV) solution to 90 °C did not result in its disproportionation or reduction, however a slow reduction was observed to Am(III) and assigned to self-irradiation of americium by alpha particles.\n\nMost americium(III) halides form hexagonal crystals with slight variation of the color and exact structure between the halogens. So, chloride (AmCl) is reddish and has a structure isotypic to uranium(III) chloride (space group P6/m) and the melting point of 715 °C. The fluoride is isotypic to LaF (space group P6/mmc) and the iodide to BiI (space group R). The bromide is an exception with the orthorhombic PuBr-type structure and space group Cmcm. Crystals of americium hexahydrate (AmCl·6HO) can be prepared by dissolving americium dioxide in hydrochloric acid and evaporating the liquid. Those crystals are hygroscopic and have yellow-reddish color and a monoclinic crystal structure.\n\nOxyhalides of americium in the form AmOX, AmOX, AmOX and AmOX can be obtained by reacting the corresponding americium halide with oxygen or SbO, and AmOCl can also be produced by vapor phase hydrolysis:\n\nThe known chalcogenides of americium include the sulfide AmS, selenides AmSe and AmSe, and tellurides AmTe and AmTe. The pnictides of americium (Am) of the AmX type are known for the elements phosphorus, arsenic, antimony and bismuth. They crystallize in the rock-salt lattice.\n\nAmericium monosilicide (AmSi) and \"disilicide\" (nominally AmSi with: 1.87 < x < 2.0) were obtained by reduction of americium(III) fluoride with elementary silicon in vacuum at 1050 °C (AmSi) and 1150−1200 °C (AmSi). AmSi is a black solid isomorphic with LaSi, it has an orthorhombic crystal symmetry. AmSi has a bright silvery lustre and a tetragonal crystal lattice (space group \"I\"4/amd), it is isomorphic with PuSi and ThSi. Borides of americium include AmB and AmB. The tetraboride can be obtained by heating an oxide or halide of americium with magnesium diboride in vacuum or inert atmosphere.\n\nAnalogous to uranocene, americium forms the organometallic compound amerocene with two cyclooctatetraene ligands, with the chemical formula (η-CH)Am. A cyclopentadienyl complex is also known that is likely to be stoichiometrically AmCp.\n\nFormation of the complexes of the type Am(n-CH-BTP), where BTP stands for 2,6-di(1,2,4-triazin-3-yl)pyridine, in solutions containing n-CH-BTP and Am ions has been confirmed by EXAFS. Some of these BTP-type complexes selectively interact with americium and therefore are useful in its selective separation from lanthanides and another actinides.\n\nAmericium is an artificial element of recent origin, and thus does not have a biological requirement. It is harmful to life. It has been proposed to use bacteria for removal of americium and other heavy metals from rivers and streams. Thus, Enterobacteriaceae of the genus \"Citrobacter\" precipitate americium ions from aqueous solutions, binding them into a metal-phosphate complex at their cell walls. Several studies have been reported on the biosorption and bioaccumulation of americium by bacteria and fungi.\n\nThe isotope Am (half-life 141 years) has the largest cross sections for absorption of thermal neutrons (5,700 barns), that results in a small critical mass for a sustained nuclear chain reaction. The critical mass for a bare Am sphere is about 9–14 kg (the uncertainty results from insufficient knowledge of its material properties). It can be lowered to 3–5 kg with a metal reflector and should become even smaller with a water reflector. Such small critical mass is favorable for portable nuclear weapons, but those based on Am are not known yet, probably because of its scarcity and high price. The critical masses of two other readily available isotopes, Am and Am, are relatively high – 57.6 to 75.6 kg for Am and 209 kg for Am. Scarcity and high price yet hinder application of americium as a nuclear fuel in nuclear reactors.\n\nThere are proposals of very compact 10-kW high-flux reactors using as little as 20 grams of Am. Such low-power reactors would be relatively safe to use as neutron sources for radiation therapy in hospitals.\n\nAbout 19 isotopes and 8 nuclear isomers are known for americium. There are two long-lived alpha-emitters, Am and Am with half-lives of 432.2 and 7,370 years, respectively, and the nuclear isomer Am has a long half-life of 141 years. The half-lives of other isotopes and isomers range from 0.64 microseconds for Am to 50.8 hours for Am. As with most other actinides, the isotopes of americium with odd number of neutrons have relatively high rate of nuclear fission and low critical mass.\n\nAmericium-241 decays to Np emitting alpha particles of 5 different energies, mostly at 5.486 MeV (85.2%) and 5.443 MeV (12.8%). Because many of the resulting states are metastable, they also emit gamma rays with the discrete energies between 26.3 and 158.5 keV.\n\nAmericium-242 is a short-lived isotope with a half-life of 16.02 h. It mostly (82.7%) converts by β-decay to Cm, but also by electron capture to Pu (17.3%). Both Cm and Pu transform via nearly the same decay chain through Pu down to U.\n\nNearly all (99.541%) of Am decays by internal conversion to Am and the remaining 0.459% by α-decay to Np. The latter subsequently decays to Pu and then to U.\n\nAmericium-243 transforms by α-emission into Np, which converts by β-decay to Pu, and the Pu changes into U by emitting an α-particle.\n\nAmericium is used in the most common type of household smoke detector, which uses Am in the form of americium dioxide as its source of ionizing radiation. This isotope is preferred over Ra because it emits 5 times more alpha particles and relatively little harmful gamma radiation. Element collector Theodore Gray mentions in his book \"The Elements: A Visual Exploration of Every Known Atom in the Universe\":\n\nThe amount of americium in a typical new smoke detector is 1 microcurie (37 kBq) or 0.29 microgram. This amount declines slowly as the americium decays into neptunium-237, a different transuranic element with a much longer half-life (about 2.14 million years). With its half-life of 432.2 years, the americium in a smoke detector includes about 3% neptunium after 19 years, and about 5% after 32 years. The radiation passes through an ionization chamber, an air-filled space between two electrodes, and permits a small, constant current between the electrodes. Any smoke that enters the chamber absorbs the alpha particles, which reduces the ionization and affects this current, triggering the alarm. Compared to the alternative optical smoke detector, the ionization smoke detector is cheaper and can detect particles which are too small to produce significant light scattering; however, it is more prone to false alarms.\n\nAs Am has a roughly similar half-life to Pu (432.2 years vs. 87 years), it has been proposed as an active element of radioisotope thermoelectric generators, for example in spacecraft. Although americium produces less heat and electricity – the power yield is 114.7 mW/g for Am and 6.31 mW/g for Am (cf. 390 mW/g for Pu) – and its radiation poses more threat to humans owing to neutron emission, the European Space Agency is considering using americium for its space probes.\n\nAnother proposed space-related application of americium is a fuel for space ships with nuclear propulsion. It relies on the very high rate of nuclear fission of Am, which can be maintained even in a micrometer-thick foil. Small thickness avoids the problem of self-absorption of emitted radiation. This problem is pertinent to uranium or plutonium rods, in which only surface layers provide alpha-particles. The fission products of Am can either directly propel the spaceship or they can heat a thrusting gas. They can also transfer their energy to a fluid and generate electricity through a magnetohydrodynamic generator.\n\nOne more proposal which utilizes the high nuclear fission rate of Am is a nuclear battery. Its design relies not on the energy of the emitted by americium alpha particles, but on their charge, that is the americium acts as the self-sustaining \"cathode\". A single 3.2 kg Am charge of such battery could provide about 140 kW of power over a period of 80 days. Even with all the potential benefits, the current applications of Am are as yet hindered by the scarcity and high price of this particular nuclear isomer.\n\nThe oxide of Am pressed with beryllium is an efficient neutron source. Here americium acts as the alpha source, and beryllium produces neutrons owing to its large cross-section for the (α,n) nuclear reaction:\n\nThe most widespread use of AmBe neutron sources is a neutron probe – a device used to measure the quantity of water present in soil, as well as moisture/density for quality control in highway construction. Am neutron sources are also used in well logging applications, as well as in neutron radiography, tomography and other radiochemical investigations.\n\nAmericium is a starting material for the production of other transuranic elements and transactinides – for example, 82.7% of Am decays to Cm and 17.3% to Pu. In the nuclear reactor, Am is also up-converted by neutron capture to Am and Am, which transforms by β-decay to Cm:\n\nIrradiation of Am by C or Ne ions yields the isotopes Es (einsteinium) or Db (dubnium), respectively. Furthermore, the element berkelium (Bk isotope) had been first intentionally produced and identified by bombarding Am with alpha particles, in 1949, by the same Berkeley group, using the same 60-inch cyclotron. Similarly, nobelium was produced at the Joint Institute for Nuclear Research, Dubna, Russia, in 1965 in several reactions, one of which included irradiation of Am with N ions. Besides, one of the synthesis reactions for lawrencium, discovered by scientists at Berkeley and Dubna, included bombardment of Am with O.\n\nAmericium-241 has been used as a portable source of both gamma rays and alpha particles for a number of medical and industrial uses. The 59.5409 keV gamma ray emissions from Am in such sources can be used for indirect analysis of materials in radiography and X-ray fluorescence spectroscopy, as well as for quality control in fixed nuclear density gauges and nuclear densometers. For example, the element has been employed to gauge glass thickness to help create flat glass. Americium-241 is also suitable for calibration of gamma-ray spectrometers in the low-energy range, since its spectrum consists of nearly a single peak and negligible Compton continuum (at least three orders of magnitude lower intensity). Americium-241 gamma rays were also used to provide passive diagnosis of thyroid function. This medical application is however obsolete.\n\nAs a highly radioactive element, americium and its compounds must be handled only in an appropriate laboratory under special arrangements. Although most americium isotopes predominantly emit alpha particles which can be blocked by thin layers of common materials, many of the daughter products emit gamma-rays and neutrons which have a long penetration depth.\n\nIf consumed, most of the americium is excreted within a few days, with only 0.05% absorbed in the blood, of which roughly 45% goes to the liver and 45% to the bones, and the remaining 10% is excreted. The uptake to the liver depends on the individual and increases with age. In the bones, americium is first deposited over cortical and trabecular surfaces and slowly redistributes over the bone with time. The biological half-life of Am is 50 years in the bones and 20 years in the liver, whereas in the gonads (testicles and ovaries) it remains permanently; in all these organs, americium promotes formation of cancer cells as a result of its radioactivity.\n\nAmericium often enters landfills from discarded smoke detectors. The rules associated with the disposal of smoke detectors are relaxed in most jurisdictions. In 1994, 17-year-old David Hahn extracted the americium from about 100 smoke detectors in an attempt to build a breeder nuclear reactor. There have been a few cases of exposure to americium, the worst case being that of chemical operations technician Harold McCluskey, who at the age of 64 was exposed to 500 times the occupational standard for americium-241 as a result of an explosion in his lab. McCluskey died at the age of 75 of unrelated pre-existing disease.\n\n\n\n\n"}
{"id": "24355979", "url": "https://en.wikipedia.org/wiki?curid=24355979", "title": "Battletruck", "text": "Battletruck\n\nBattletruck (also known as Warlords of the 21st Century and in Italy) is a 1982 post-apocalyptic science fiction action film co-written and directed by Harley Cokliss and starring Michael Beck, Annie McEnroe, James Wainwright, John Ratzenberger, and Bruno Lawrence. \n\nSet in the aftermath of a devastating thermonuclear war, the plot futuristic tale of collapsed governments and bankrupt countries heralding a new lawless age. A co-production between New Zealand and the United Kingdom, it was filmed on location in New Zealand and starring a number of local actors, and was part of a wave of similarly-themed films made in the wake of the success of the \"Mad Max\" series.\n\nIn the near future, Earth has been devastated by a thermonuclear war over the depleting petroleum reserves. What little petrol remains has become a precious commodity fought over by vicious warlords and mercenaries. A war party led by Straker (James Wainwright) find a vast supply of diesel fuel in a compound once thought to be radioactive. When his daughter Corlie (Annie McEnroe) refuses to execute the previous owners, she runs away from her father's base camp. Fleeing through the open desert, she runs into Hunter (Michael Beck), an ex-soldier armed with a high-tech motorbike, who takes her to shelter at his farm.\n\nAfter keeping her on the farm on a temporary basis, Hunter sends her off to live in the walled city of Clearwater Farm, governed by a strict old-fashioned democracy, where she is quickly accepted by the community. However, she is soon discovered by her father's men, who move to attack the Clearwater community. In the chaos that ensues, Corlie manages to escape back to Hunter's remote hideout.\n\nThe mercenaries terrorise and pillage the city. Straker tortures the resident mechanic Rusty (John Ratzenberger) into giving him the location of Hunter's secret hideout. Straker moves to attack Hunter's base and recapture Corlie. Hunter and Corlie escape on his bike and Straker, in a rage, plows through Hunter's residence with his truck. Hunter takes Corlie back to the Clearwater people and asks Rusty to build him an armored car to attack Straker's \"battletruck\". While Rusty and Hunter and a few others are thus occupied, one of the residents turns traitor and knocks out Coralie, putting her in a wagon and heads out to deliver her back to Straker. Hunter tries to stop him, but the traitor sets an ambush for him and wounds him with a crossbow. Believing that he has killed Hunter, he appears at Straker's headquarters with Corlie in the wagon. \n\nMeanwhile, Hunter regains consciousness and manages to limp back to Clearwater on his bike. While getting patched up there, Rusty finishes the armored car and shortly Hunter takes off in it, despite the fact that he is wounded. He attacks Straker's HQ, plowing through buildings and tents and eventually dropping a grenade into Straker's 50,000 litre diesel supply. He then runs and Straker, now in a towering rage, takes off after him. In the process, he forces the driver to overdo it in the truck, overheating the turbines. This stresses out the driver, (who loves the truck), and leads to dissension between him and Straker. Hunter meanwhile gets some distance ahead, jumps out of the car and climbs to a high place overlooking the road and it is now revealed that the whole attack on Straker's HQ was a ruse to lure the truck into an ambush. The Clearwater people are at the high place waiting for Hunter with his motorcycle and a rocket launcher which Hunter had given them earlier in the movie. Hunter fires a couple of rockets at the truck, one causes slight damage and a small fire, which causes more stress between Straker and the truck driver. The driver attempts to kill Straker, who he feels is uselessly destroying the truck, Straker kills the driver, who slumps over the wheel and now the truck, throttles set to full, is more or less out of control.\n\nBack on the bike again, Hunter manages to jump onto the truck through a hole in the top that one of his rockets had made. A battle ensues, the truck still careening wildly back and forth while Corlie tries to control it with the body of the driver slumped over the wheel and Straker furiously shouting commands to everybody. Eventually, Hunter fights his way to the front, temporarily stuns Straker, grabs Corlie, and jumps with her from the back of the still wildly out of control battle truck before it crashes and explodes.\n\nHunter and Corlie end up back at Clearwater, where Corlie apparently settles for good as part of the community. Ever the loner, Hunter rides off into the sunset on a horse, promising Corlie that he'll be back \"sometime\".\n\n\nBattletruck was filmed on the Central Otago plains in New Zealand. Despite being produced by a Hollywood studio and being considered a Hollywood release, the film largely used New Zealand crew and actors. It followed the success of films such as \"Mad Max\" and was made in New Zealand in part due to the 1981 Writers Guild of America strike.\n\n\"Damnation Alley\" (1977)\n\n \n"}
{"id": "4115", "url": "https://en.wikipedia.org/wiki?curid=4115", "title": "Boiling point", "text": "Boiling point\n\nThe boiling point of a substance is the temperature at which the vapor pressure of the liquid equals the pressure surrounding the liquid and the liquid changes into a vapor.\n\nThe boiling point of a liquid varies depending upon the surrounding environmental pressure. A liquid in a partial vacuum has a lower boiling point than when that liquid is at atmospheric pressure. A liquid at high pressure has a higher boiling point than when that liquid is at atmospheric pressure. For example, water boils at at sea level, but at at altitude. For a given pressure, different liquids will boil at different temperatures. \n\nThe normal boiling point (also called the atmospheric boiling point or the atmospheric pressure boiling point) of a liquid is the special case in which the vapor pressure of the liquid equals the defined atmospheric pressure at sea level, 1 atmosphere. At that temperature, the vapor pressure of the liquid becomes sufficient to overcome atmospheric pressure and allow bubbles of vapor to form inside the bulk of the liquid. The standard boiling point has been defined by IUPAC since 1982 as the temperature at which boiling occurs under a pressure of 1 bar.\n\nThe heat of vaporization is the energy required to transform a given quantity (a mol, kg, pound, etc.) of a substance from a liquid into a gas at a given pressure (often atmospheric pressure).\n\nLiquids may change to a vapor at temperatures below their boiling points through the process of evaporation. Evaporation is a surface phenomenon in which molecules located near the liquid's edge, not contained by enough liquid pressure on that side, escape into the surroundings as vapor. On the other hand, boiling is a process in which molecules anywhere in the liquid escape, resulting in the formation of vapor bubbles within the liquid.\n\nA \"saturated liquid\" contains as much thermal energy as it can without boiling (or conversely a \"saturated vapor\" contains as little thermal energy as it can without condensing).\n\nSaturation temperature means \"boiling point\". The saturation temperature is the temperature for a corresponding saturation pressure at which a liquid boils into its vapor phase. The liquid can be said to be saturated with thermal energy. Any addition of thermal energy results in a phase transition.\n\nIf the pressure in a system remains constant (isobaric), a vapor at saturation temperature will begin to condense into its liquid phase as thermal energy (heat) is removed. Similarly, a liquid at saturation temperature and pressure will boil into its vapor phase as additional thermal energy is applied.\n\nThe boiling point corresponds to the temperature at which the vapor pressure of the liquid equals the surrounding environmental pressure. Thus, the boiling point is dependent on the pressure. Boiling points may be published with respect to the NIST, USA standard pressure of 101.325 kPa (or 1 atm), or the IUPAC standard pressure of 100.000 kPa. At higher elevations, where the atmospheric pressure is much lower, the boiling point is also lower. The boiling point increases with increased pressure up to the critical point, where the gas and liquid properties become identical. The boiling point cannot be increased beyond the critical point. Likewise, the boiling point decreases with decreasing pressure until the triple point is reached. The boiling point cannot be reduced below the triple point.\n\nIf the heat of vaporization and the vapor pressure of a liquid at a certain temperature are known, the boiling point can be calculated by using the Clausius–Clapeyron equation, thus:\n\nwhere:\n\nSaturation pressure is the pressure for a corresponding saturation temperature at which a liquid boils into its vapor phase. Saturation pressure and saturation temperature have a direct relationship: as saturation pressure is increased, so is saturation temperature.\n\nIf the temperature in a system remains constant (an \"isothermal\" system), vapor at saturation pressure and temperature will begin to condense into its liquid phase as the system pressure is increased. Similarly, a liquid at saturation pressure and temperature will tend to flash into its vapor phase as system pressure is decreased.\n\nThere are two conventions regarding the \"standard boiling point of water\": The \"normal boiling point\" is at a pressure of 1 atm (i.e., 101.325 kPa). The IUPAC recommended \"standard boiling point of water\" at a standard pressure of 100 kPa (1 bar) is . For comparison, on top of Mount Everest, at elevation, the pressure is about and the boiling point of water is .\nThe Celsius temperature scale was defined until 1954 by two points: 0 °C being defined by the water freezing point and 100 °C being defined by the water boiling point at standard atmospheric pressure.\n\nThe higher the vapor pressure of a liquid at a given temperature, the lower the normal boiling point (i.e., the boiling point at atmospheric pressure) of the liquid.\n\nThe vapor pressure chart to the right has graphs of the vapor pressures versus temperatures for a variety of liquids. As can be seen in the chart, the liquids with the highest vapor pressures have the lowest normal boiling points.\n\nFor example, at any given temperature, methyl chloride has the highest vapor pressure of any of the liquids in the chart. It also has the lowest normal boiling point (−24.2 °C), which is where the vapor pressure curve of methyl chloride (the blue line) intersects the horizontal pressure line of one atmosphere (atm) of absolute vapor pressure.\n\nThe critical point of a liquid is the highest temperature (and pressure) it will actually boil at.\n\nSee also Vapour pressure of water.\n\nThe element with the lowest boiling point is helium. Both the boiling points of rhenium and tungsten exceed 5000 K at standard pressure; because it is difficult to measure extreme temperatures precisely without bias, both have been cited in the literature as having the higher boiling point.\n\nAs can be seen from the above plot of the logarithm of the vapor pressure vs. the temperature for any given pure chemical compound, its normal boiling point can serve as an indication of that compound's overall volatility. A given pure compound has only one normal boiling point, if any, and a compound's normal boiling point and melting point can serve as characteristic physical properties for that compound, listed in reference books. The higher a compound's normal boiling point, the less volatile that compound is overall, and conversely, the lower a compound's normal boiling point, the more volatile that compound is overall. Some compounds decompose at higher temperatures before reaching their normal boiling point, or sometimes even their melting point. For a stable compound, the boiling point ranges from its triple point to its critical point, depending on the external pressure. Beyond its triple point, a compound's normal boiling point, if any, is higher than its melting point. Beyond the critical point, a compound's liquid and vapor phases merge into one phase, which may be called a superheated gas. At any given temperature, if a compound's normal boiling point is lower, then that compound will generally exist as a gas at atmospheric external pressure. If the compound's normal boiling point is higher, then that compound can exist as a liquid or solid at that given temperature at atmospheric external pressure, and will so exist in equilibrium with its vapor (if volatile) if its vapors are contained. If a compound's vapors are not contained, then some volatile compounds can eventually evaporate away in spite of their higher boiling points.\nIn general, compounds with ionic bonds have high normal boiling points, if they do not decompose before reaching such high temperatures. Many metals have high boiling points, but not all. Very generally—with other factors being equal—in compounds with covalently bonded molecules, as the size of the molecule (or molecular mass) increases, the normal boiling point increases. When the molecular size becomes that of a macromolecule, polymer, or otherwise very large, the compound often decomposes at high temperature before the boiling point is reached. Another factor that affects the normal boiling point of a compound is the polarity of its molecules. As the polarity of a compound's molecules increases, its normal boiling point increases, other factors being equal. Closely related is the ability of a molecule to form hydrogen bonds (in the liquid state), which makes it harder for molecules to leave the liquid state and thus increases the normal boiling point of the compound. Simple carboxylic acids dimerize by forming hydrogen bonds between molecules. A minor factor affecting boiling points is the shape of a molecule. Making the shape of a molecule more compact tends to lower the normal boiling point slightly compared to an equivalent molecule with more surface area.\n\nMost volatile compounds (anywhere near ambient temperatures) go through an intermediate liquid phase while warming up from a solid phase to eventually transform to a vapor phase. By comparison to boiling, a sublimation is a physical transformation in which a solid turns directly into vapor, which happens in a few select cases such as with carbon dioxide at atmospheric pressure. For such compounds, a sublimation point is a temperature at which a solid turning directly into vapor has a vapor pressure equal to the external pressure.\n\nIn the preceding section, boiling points of pure compounds were covered. Vapor pressures and boiling points of substances can be affected by the presence of dissolved impurities (solutes) or other miscible compounds, the degree of effect depending on the concentration of the impurities or other compounds. The presence of non-volatile impurities such as salts or compounds of a volatility far lower than the main component compound decreases its mole fraction and the solution's volatility, and thus raises the normal boiling point in proportion to the concentration of the solutes. This effect is called boiling point elevation. As a common example, salt water boils at a higher temperature than pure water.\n\nIn other mixtures of miscible compounds (components), there may be two or more components of varying volatility, each having its own pure component boiling point at any given pressure. The presence of other volatile components in a mixture affects the vapor pressures and thus boiling points and dew points of all the components in the mixture. The dew point is a temperature at which a vapor condenses into a liquid. Furthermore, at any given temperature, the composition of the vapor is different from the composition of the liquid in most such cases. In order to illustrate these effects between the volatile components in a mixture, a boiling point diagram is commonly used. Distillation is a process of boiling and [usually] condensation which takes advantage of these differences in composition between liquid and vapor phases.\n\n"}
{"id": "4929021", "url": "https://en.wikipedia.org/wiki?curid=4929021", "title": "Bulky waste", "text": "Bulky waste\n\nBulky waste or bulky refuse is a technical term taken from waste management to describe waste types that are too large to be accepted by the regular waste collection. It is usually picked up regularly in many countries from the streets or pavements of the area. This service is provided free of charge in many places, but often a fee has to be paid.\n\nBulky waste items include discarded furniture (couches, recliners, tables), large appliances (refrigerators, ovens, TVs), and plumbing fixtures (bathtubs, toilets, sinks). A large amount (30-60%, depending on area) of bulky waste is picked up by scavengers before it is collected. Branches, brush, logs and other green waste are also categorized as bulky waste, although they may be collected separately for shredding and/or composting.\n\nGrapple trucks, also known as knuckleboom loaders, are often used to collect bulky waste. In the UK, refuse collection vehicles (RCVs) or crushers are being increasingly phased out as more bulky waste is diverted for re-use and recycling.\n\n\n"}
{"id": "37020373", "url": "https://en.wikipedia.org/wiki?curid=37020373", "title": "Cheng rotation vane", "text": "Cheng rotation vane\n\nA fluid flow conditioning device, the cheng rotation vane is a stationary vane fabricated within a pipe piece as a single unit and welded directly upstream of an elbow before the pump inlet, flow meters, compressors, or other downstream equipment.\n\nThe cheng rotation vane is used to eliminate elbow induced turbulence, cavitation, erosion, vibration, which effect pump performance, seal life, impeller life, lead to bearing failure, flow meter accuracy, pipe bursts, and other common pipe problems.\n"}
{"id": "125371", "url": "https://en.wikipedia.org/wiki?curid=125371", "title": "Continuous track", "text": "Continuous track\n\nContinuous track, also called tank tread or caterpillar track, is a system of vehicle propulsion in which a continuous band of treads or track plates is driven by two or more wheels. This band is typically made of modular steel plates in the case of military vehicles and heavy equipment, or synthetic rubber reinforced with steel wires in the case of lighter agricultural or construction vehicles.\n\nThe large surface area of the tracks distributes the weight of the vehicle better than steel or rubber tyres on an equivalent vehicle, enabling a continuous tracked vehicle to traverse soft ground with less likelihood of becoming stuck due to sinking. The prominent treads of the metal plates are both hard-wearing and damage resistant, especially in comparison to rubber tyres. The aggressive treads of the tracks provide good traction in soft surfaces but can damage paved surfaces, so some metal tracks can have rubber pads installed for use on paved surfaces.\n\nContinuous tracks can be traced back as far as 1770 and today are commonly used on a variety of vehicles including bulldozers, excavators, tanks, and tractors, but can be found on any vehicle used in an application that can benefit from the added traction, low ground pressure and durability inherent in continuous track propulsion systems.\n\nPolish mathematician and inventor Józef Maria Hoene-Wroński conceived of the idea in the 1830s. The British polymath Sir George Cayley patented a continuous track, which he called a \"universal railway\". In 1837, a Russian inventor Dmitry Zagryazhsky designed a \"carriage with mobile tracks\" which he patented the same year, but due to a lack of funds and interest from manufacturers he was unable to build a working prototype, and his patent was voided in 1839.\n\nAlthough not a continuous track in the form encountered today, a dreadnaught wheel or \"endless railway wheel\" was patented by the British Engineer James Boydell in 1846. In Boydell's design, a series of flat feet are attached to the periphery of the wheel, spreading the weight. A number of horse-drawn wagons, carts and gun carriages were successfully deployed in the Crimean War, waged between October 1853 and February 1856, the Royal Arsenal at Woolwich manufacturing dreadnaught wheels. A letter of recommendation was signed by Sir William Codrington, the General commanding the troops at Sebastopol.\n\nBoydell patented improvements to his wheel in 1854 (No. 431) – the year his dreadnaught wheel was first applied to a steam engine – and 1858 (No. 356), the latter an impracticable palliative measure involving the lifting one or other of the driving wheels to facilitate turning.\n\nA number of manufacturers including Richard Bach, Richard Garrett & Sons, Charles Burrell & Sons and Clayton & Shuttleworth applied the Boydell patent under licence. The British military were interested in Boydell's invention from an early date. One of the objectives was to transport Mallet's Mortar, a giant 36 in weapon which was under development, but, by the end of the Crimean war, the mortar was not ready for service. A detailed report of the tests on steam traction, carried out by a select Committee of the Board of Ordnance, was published in June 1856, by which date the Crimean War was over, consequently the mortar and its transportation became irrelevant. In those tests, a Garrett engine was put through its paces on Plumstead Common. The Garrett engine featured in the Lord Mayor's show in London, and in the following month that engine was shipped to Australia. A steam tractor employing dreadnaught wheels was built at Bach's Birmingham works, and was used between 1856 and 1858 for ploughing in Thetford; and the first generation of Burrell/Boydell engines was built at the St. Nicholas works in 1856, again, after the close of the Crimean war. Between late 1856 and 1862 Burrell manufactured not less than a score of engines fitted with dreadnaught wheels. In April 1858, \"The Engineer\" gave a brief description of a Clayton & Shuttleworth engine fitted with dreadnaught wheels, which was supplied not to the Western Allies, but to the Russian government for heavy artillery haulage in the Crimea, in the post-war period. Steam tractors fitted with dreadnaught wheels had a number of shortcomings and, notwithstanding the creations of the late 1850s, were never used extensively.\n\nIn August 1858, more than two years after the end of the Crimean War, John Fowler filed British Patent No. 1948 on another form of \"Endless Railway\". In his illustration of the invention, Fowler used a pair of wheels of equal diameter on each side of his vehicle, around which pair of toothed wheels ran a 'track' of eight jointed segments, with a smaller jockey/drive wheel between each pair of wheels, to support the 'track'. Comprising only eight sections, the 'track' sections are essentially 'longitudinal', as in Boydell's initial design. Fowler's arrangement is a precursor to the multi-section caterpillar track in which a relatively large number of short 'transverse' treads are used, as proposed by Sir George Caley in 1825, rather than a small number of relatively long 'longitudinal' treads.\n\nFurther to Fowler's patent of 1858, in 1877, a Russian, Fyodor Blinov, created a tracked vehicle called \"wagon moved on endless rails\" (caterpillars). It lacked self-propulsion and was pulled by horses. Blinov received a patent for his \"wagon\" in 1878. From 1881 to 1888 he developed a steam-powered caterpillar-tractor. This self-propelled crawler was successfully tested and featured at a farmers' exhibition in 1896.\n\nSteam traction engines were used at the end of the 19th century in the Boer Wars. But neither dreadnaught wheels nor continuous tracks were used, rather \"roll-out\" wooden plank roads were thrown under the wheels as required.\nIn short, whilst the development of the continuous track engaged the attention of a number of inventors in the 18th and 19th centuries, the general use and exploitation of the continuous track belonged to the 20th century.\n\nA little-known American inventor, Henry T. Stith, developed a continuous track prototype which was, in multiple forms, patented in 1873, 1880, and 1900. The last was for the application of the track to a prototype off-road bicycle built for his son. The 1900 prototype is retained by his surviving family.\n\nFrank Beamond, a less-commonly known but significant British inventor, designed and built caterpillar tracks, and was granted patents for them in a number of countries, in 1900 and 1907.\n\nAn effective continuous track was invented and implemented by Alvin Orlando Lombard for the Lombard Steam Log Hauler. He was granted a patent in 1901 and built the first steam-powered log hauler at the Waterville Iron Works in Waterville, Maine, the same year. In all, 83 Lombard steam log haulers are known to have been built up to 1917, when production switched entirely to internal combustion engine powered machines, ending with a Fairbanks diesel-powered unit in 1934. Undoubtedly, Alvin Lombard was the first commercial manufacturer of the tractor crawler.\n\nAt least one of Lombard's steam-powered machines apparently remains in working order. A gasoline-powered Lombard hauler is on display at the Maine State Museum in Augusta. In addition, there may have been up to twice as many Phoenix Centipeed versions of the steam log hauler built under license from Lombard, with vertical instead of horizontal cylinders. In 1903, the founder of Holt Manufacturing, Benjamin Holt, paid Lombard $60,000 for the right to produce vehicles under his patent.\n\nAt about the same time a British agricultural company, Hornsby in Grantham, developed a continuous track which was patented in 1905. The design differed from modern tracks in that it flexed in only one direction, with the effect that the links locked together to form a solid rail on which the road wheels ran. Hornsby's tracked vehicles were given trials as artillery tractors by the British Army on several occasions between 1905 and 1910, but not adopted. The Hornsby tractors featured a track-steer clutch arrangement, which is the basis of the modern crawler operation. The patent was purchased by Holt.\n\nContinuous track was first applied to a military vehicle on the British prototype tank Little Willie. British Army officers, Colonel Ernest Swinton and Colonel Maurice Hankey, became convinced that it was possible to develop a fighting vehicle that could provide protection from machine gun fire.\n\nThe name came from a soldier during the tests on the Hornsby crawler, \"trials began at Aldershot in July 1907. The soldiers immediately christened the 70bhp No.2 machine the 'caterpillar'.\"\n\nHolt adopted that name for his \"crawler\" tractors. Holt began moving from steam to gasoline-powered designs, and in 1908 brought out the 40 horsepower \"Holt Model 40 Caterpillar\". Holt incorporated the Holt Caterpillar Company, in early 1910, later that year trademarked the name \"Caterpillar\" for his continuous tracks.\n\nIn a memorandum of 1908, Antarctic explorer Robert Falcon Scott presented his view that man-hauling to the South Pole was impossible and that motor traction was needed. Snow vehicles did not yet exist however, and so his engineer Reginald Skelton developed the idea of a caterpillar track for snow surfaces. These tracked motors were built by the Wolseley Tool and Motor Car Company in Birmingham, tested in Switzerland and Norway, and can be seen in action in Herbert Ponting's 1911 documentary film of Scott's Antarctic Terra Nova Expedition. Scott died during the expedition in 1912, but expedition member and biographer Apsley Cherry-Garrard credited Scott's \"motors\" with the inspiration for the British World War I tanks, writing: \"Scott never knew their true possibilities; for they were the direct ancestors of the 'tanks' in France.\"\n\nDuring World War I, Holt tractors were used by the British and Austro-Hungarian armies to tow heavy artillery and stimulated the development of tanks in several countries. The first tanks to go into action, the Mark I, built by Great Britain, were designed from scratch and were inspired by, but not directly based on, the Holt. The slightly later French and German tanks were built on modified Holt running gear.\n\nCaterpillar Tractor Company began in 1925 from a merger of the Holt Manufacturing Company and the C. L. Best Tractor Company, an early successful manufacturer of crawler tractors.\n\nWith the Caterpillar D10 in 1977, Caterpillar resurrected a design by Holt and Best, the high-sprocket-drive, since known as the \"High Drive\", which had the advantage of keeping the main drive shaft away from ground shocks and dirt,\nand is still used in their larger dozers.\n\nA long line of patents disputes who was the \"originator\" of continuous tracks. There were a number of designs that attempted to achieve a track laying mechanism, although these designs do not generally resemble modern tracked vehicles.\n\nIn 1877 Russian inventor Fyodor Abramovich Blinov created a tracked vehicle called \"wagon moved on endless rails\" (caterpillars). It lacked self-propelling and was horse-drawn. Blinov got a patent for his \"wagon\" the next year. Later, in 1881-1888 he created a steam-powered caterpillar-tractor. This self-propelled crawler was successfully tested and showed at a farmers' exhibition in 1896.\n\nAccording to \"Scientific American\", it was Charles Dinsmoor of Warren, Pennsylvania that invented a \"vehicle\" that was on endless tracks. The article gives a detailed description of the endless tracks and the illustration looks much like today's tracked vehicles. The invention has been patented as No. 351,749 on November 2, 1886.\n\nAlvin O. Lombard of Waterville, Maine was issued a patent in 1901 for the Lombard Steam Log Hauler that resembles a regular railroad steam locomotive with sled steerage on front and crawlers in rear for hauling logs in the Northeastern United States and Canada. The haulers allowed pulp to be taken to rivers in the winter. Prior to then, horses could be used only until snow depths made hauling impossible. Lombard began commercial production which lasted until around 1917 when focus switched entirely to gasoline powered machines. A gasoline-powered hauler is on display at the Maine State Museum in Augusta, Maine.\n\nAfter Lombard began operations, Hornsby in England manufactured at least two full length \"track steer\" machines, and their patent was later purchased by Holt in 1913, allowing Holt to claim to be the \"inventor\" of the crawler tractor. Since the \"tank\" was a British concept it is more likely the Hornsby, which had been built and unsuccessfully pitched to their military, was the inspiration.\n\nIn a patent dispute involving rival crawler builder Best, testimony was brought in from people including Lombard, that Holt had inspected a Lombard log hauler shipped out to a western state by people who would later build the Phoenix log hauler in Eau Claire, Wisconsin, under license from Lombard. The Phoenix Centipeed typically had a fancier wood cab, steering wheel tipped forward at a 45 degree angle and vertical instead of horizontal cylinders.\n\nIn the meantime, a gasoline-powered motor home was built by Lombard for Holman Harry (Flannery) Linn of Old Town, Maine to pull the equipment wagon of his dog & pony show, resembling a trolley car only with wheels in front and Lombard crawlers in rear. Linn had experimented with gasoline and steam-powered vehicles and six-wheel drive before this, and at some point entered Lombard's employment as a demonstrator, mechanic and sales agent. This resulted in a question of proprietorship of patent rights after a single rear-tracked gasoline-powered road engine of tricycle arrangement was built to replace the larger motor home in 1909 on account of problems with the old picturesque wooden bridges. This dispute resulted in Linn departing Maine and relocating to Morris, New York, to build an improved, contour following flexible lag tread or crawler with independent suspension of halftrack type, gasoline and later diesel powered. Although several were delivered for military use between 1917 and 1946, Linn never received any large military orders. Most of the production between 1917 and 1952, approximately 2500 units, was sold directly to highway departments and contractors. Steel tracks and payload capacity allowed these machines to work in terrain that would typically cause the poorer quality rubber tyres that existed before the mid-1930s to spin uselessly, or shred completely.\n\nLinn was a pioneer in snow removal before the practice was embraced in rural areas, with a nine-foot steel v-plow and sixteen foot adjustable leveling wings on either side. Once the highway system became paved, snowplowing could be done by four wheel drive trucks equipped by improving tyre designs, and the Linn became an off highway vehicle, for logging, mining, dam construction, arctic exploration, etc.\n\nContinuous track vehicle steer by applying more or less drive torque to one side of the vehicle than the other, and this can be implemented in a variety of ways.\n\nModern tracks are built from modular chain links which together compose a closed chain. The links are jointed by a hinge, which allows the track to be flexible and wrap around a set of wheels to make an endless loop. The chain links are often broad, and can be made of manganese alloy steel for high strength, hardness, and abrasion resistance.\n\nTrack construction and assembly is dictated by the application. Military vehicles use a track shoe that is integral to the structure of the chain in order to reduce track weight. Reduced weight allows the vehicle to move faster and decreases overall vehicle weight to ease transportation. Since track weight is completely unsprung, reducing it improves suspension performance at speeds where the track's momentum is significant. In contrast, agricultural and construction vehicles opt for a track with shoes that attach to the chain with bolts and do not form part of the chain's structure. This allows track shoes to break without compromising the ability of the vehicle to move and decrease productivity but increases the overall weight of the track and vehicle.\n\nThe vehicle's weight is transferred to the bottom length of track by a number of road wheels, or sets of wheels called bogies. Road wheels are typically mounted on some form of suspension to cushion the ride over rough ground. Suspension design in military vehicles is a major area of development; the very early designs were often completely unsprung. Later-developed road wheel suspension offered only a few inches of travel using springs, whereas modern hydro-pneumatic systems allow several feet of travel and include shock absorbers. Torsion-bar suspension has become the most common type of military vehicle suspension. Construction vehicles have smaller road wheels that are designed primarily to prevent track derailment and they are normally contained in a single bogie that includes the idler-wheel and sometimes the sprocket.\n\nTransfer of power to the track is accomplished by a drive wheel, or \"drive sprocket\", driven by the motor and engaging with holes in the track links or with pegs on them to drive the track. In military vehicles, the drive wheel is typically mounted well above the contact area on the ground, allowing it to be fixed in position. In agricultural crawlers it is normally incorporated as part of the bogie. Placing suspension on the sprocket is possible, but is mechanically more complicated. A non-powered wheel, an \"idler\", is placed at the opposite end of the track, primarily to tension the track, since loose track could be easily thrown (slipped) off the wheels. To prevent throwing, the inner surface of the track links usually have vertical guide horns engaging grooves, or gaps between the doubled road and idler/sprocket wheels. In military vehicles with a rear sprocket, the idler wheel is placed higher than the road wheels to allow it to climb over obstacles. Some track arrangements use return rollers to keep the top of the track running straight between the drive sprocket and idler. Others, called \"slack track\", allow the track to droop and run along the tops of large road wheels. This was a feature of the Christie suspension, leading to occasional misidentification of other slack track-equipped vehicles.\n\nMany World War II German military vehicles, initially (starting in the late 1930s) including all vehicles originally designed to be half-tracks and all later tank designs (after the Panzer IV), had slack-track systems, usually driven by a front-located drive sprocket, the track returning along the tops of a design of overlapping and sometimes interleaved large diameter road wheels, as on the suspension systems of the Tiger I and Panther tanks, generically known by the term \"Schachtellaufwerk\" in German, for both half-track and fully tracked vehicles. There were suspensions with one (sometimes double) wheel per axle, alternately supporting the inner and outer side of the track, and interleaved suspensions with two or three road wheels per axle, distributing the load over the track. \n\nThe choice of overlapping/interleaved road wheels allowed the use of slightly more torsion bar suspension members, allowing any German tracked military vehicle with such a setup to have a noticeably smoother ride over challenging terrain, leading to reduced wear and more accurate fire. There were some major disadvantages with this though, one being on the Russian front, mud would get stuck in-between the overlapping wheels, and would freeze, immobilizing the vehicle. As a tracked vehicle moves, the load of each wheel moves over the track, pushing down and forward that part of the earth, snow, etc. under it, similarly to a wheeled vehicle but to a lesser extent because the tread helps distribute the load. Apparently, on some surfaces, this consumes enough energy to slow the vehicle down significantly, so overlapped and interleaved wheels improve performance (including fuel consumption) by loading the track more evenly. It also must have extended the life of the tracks and possibly of the wheels. The wheels also better protect the vehicle from enemy fire, and mobility is improved when some wheels are missing. But this complicated approach has not been used since World War II ended. This may be related more to maintenance than to original cost. The torsion bars and bearings may stay dry and clean, but the wheels and tread work in mud, sand, rocks, snow and so on. In addition, the outer wheels (up to 9 of them, some double) had to be removed to access the inner ones. In WW II, vehicles typically had to be maintained a few months before being destroyed or captured, but in peacetime vehicles must train several crews, over a period of decades.\n\nTracked vehicles have better mobility over rough terrain than those with wheels. They smooth out the bumps, glide over small obstacles and are capable of crossing trenches or breaks in the terrain. Riding in a fast tracked vehicle feels like riding in a boat over heavy swells. Tracks cannot be punctured or torn. Tracks are much less likely to get stuck in soft ground, mud, or snow since they distribute the weight of the vehicle over a larger contact area, decreasing its ground pressure. In addition, the larger contact area, coupled with the cleats, or grousers, on the track shoes, allows vastly superior traction that results in a much better ability to push or pull large loads where wheeled vehicles would dig in. Bulldozers, which are most often tracked, use this attribute to rescue other vehicles, (such as wheel loaders) which have become stuck in, or sunk into, the ground. Tracks can also give higher maneuverability, as tracked vehicles can turn in place without forward or backward movement by driving the tracks in opposite directions. In addition, should a track be broken, assuming the correct tools are available, it can be repaired without the need for special facilities; something which is crucial in a combat situation.\n\nThe seventy-ton M1 Abrams tank has an average ground pressure of just over . Since tyre air pressure is approximately equal to average ground pressure, a typical car will have an average ground pressure of to .\n\nThe disadvantages of tracks are lower top speed, much greater mechanical complexity, shorter life and the damage that their all-steel versions cause to the surface on which they pass. They are assumed to severely damage hard terrain such as asphalt pavement, but actually have significantly lower ground pressures than equivalent or lighter wheeled vehicles. However, they often cause damage to less firm terrain such as lawns, gravel roads, and farm fields, as the sharp edges of the track easily rout the turf. Accordingly, vehicle laws and local ordinances often require rubberised tracks or track pads. A compromise between all-steel and all-rubber tracks exists: attaching rubber pads to individual track links ensures that continuous track vehicles can travel more smoothly, quickly, and quietly on paved surfaces. While these pads slightly reduce a vehicle's cross-country traction, in theory they prevent damage to any pavement.\n\nAdditionally, the loss of a single segment in a track immobilizes the entire vehicle, which can be a disadvantage in situations where high reliability is important. Tracks can also ride off their guide wheels, idlers or sprockets, which can cause them to jam or to come completely off the guide system (this is called a 'thrown' track). Jammed tracks may become so tight that the track may need to be broken before a repair is possible, which requires either explosives or special tools. Multi-wheeled vehicles, for example, 8 X 8 military vehicles, may often continue driving even after the loss of one or more non-sequential wheels, depending on the base wheel pattern and drive train.\n\nMany manufacturers provide rubber tracks instead of steel, especially for agricultural applications. Rather than a track made of linked steel plates, a reinforced rubber belt with chevron treads is used. In comparison to steel tracks, rubber tracks are lighter, make less noise, create less maximal ground pressure and do not damage paved roads. The disadvantage is that they are not as solid as steel tracks. Previous belt-like systems, such as those used for half-tracks in World War II, were not as strong, and during military actions were easily damaged. The first rubber track was invented and constructed by Adolphe Kégresse and patented in 1913; rubber tracks are often called Kégresse tracks.\n\nProlonged use places enormous strain on the drive transmission and the mechanics of the tracks, which must be overhauled or replaced regularly. It is common to see tracked vehicles such as bulldozers or tanks transported long distances by a wheeled carrier such as a tank transporter or train, though technological advances have made this practice less common among tracked military vehicles than it once was.\n\nTracks may be broadly categorized as \"live\" or \"dead\" track. \"Dead\" track is a simple design in which each track plate is connected to the rest with hinge-type pins. These dead tracks will lie flat if placed on the ground; the drive sprocket pulls the track around the wheels with no assistance from the track itself. \"Live\" track is slightly more complex, with each link connected to the next by a bushing which causes the track to bend slightly inward. A length of live track left on the ground will curl upward slightly at each end. Although the drive sprocket must still pull the track around the wheels, the track itself tends to bend inward, slightly assisting the sprocket and somewhat conforming to the wheels.\nThe pioneer manufacturers have been replaced mostly by large tractor companies such as AGCO, Liebherr Group, John Deere, Yanmar, New Holland, Kubota, Case, Caterpillar Inc., CLAAS. Also, there are some crawler tractor companies specialising in niche markets. Examples are Otter Mfg. Co. and Struck Corporation., with many wheeled vehicle conversion kits available from the American Mattracks firm of Minnesota since the mid-1990s.\n\nRussian off-road vehicles are built by companies such as ZZGT and Vityaz.\n\n"}
{"id": "557186", "url": "https://en.wikipedia.org/wiki?curid=557186", "title": "Creatures 3", "text": "Creatures 3\n\nCreatures 3 is the third game in the \"Creatures\" a-life game series made by Creature Labs. In this installment, the Shee have left Albia in a spaceship, the Shee Ark, to search for a more spherical world. The Ark was abandoned by the Shee because a meteor hit the ship, but the infrastructure still remains in working order.\n\nThere are 6 main \"metarooms\" on the ship; the Norn Terranium, Grendel Jungle, Ettin Desert, Marine area, Bridge, and Engineering Room. The Norn Terranium is where you can safely hatch and raise your norns. The Grendel Jungle is where the Grendel mother (egg-layer) is, and it is well suited for Grendels. The Ettin Desert is where the Ettin mother is; it is a dry, harsh environment for all creatures. The Bridge is where you will find the most gadgets, and also the most Ettins. The Engineering Room is where the Agent Creator is, with which you can create objects for your world.\n\nGrendels are now vicious, unlike the original \"Creatures\" Grendels; these Grendels enjoy hunting down, and then killing norns. The Ettins, which first appeared in \"Creatures 2\", love gathering gadgets and taking them back to the Ettin Desert.\n\nCreatures 3 runs on the CAOS engine, making it highly moddable, but now it is retired and outdated.\n\n\n"}
{"id": "57819774", "url": "https://en.wikipedia.org/wiki?curid=57819774", "title": "Dalrymple ESCRI battery", "text": "Dalrymple ESCRI battery\n\nThe Dalrymple ESCRI battery (Energy Storage for Commercial Renewable Integration) is a 30MW / 8MWh grid-connected battery array on Yorke Peninsula in South Australia. Its role is to provide improved reliability and stability to the electricity network on Yorke Peninsula and South Australia.\n\nThe battery is installed adjacent to the Dalrymple substation, which is at the end of a 275kV power line into the peninsula, and feeds 33kV lines to various towns across the lower end of the peninsula. The substation is also where the Wattle Point Wind Farm feeds electricity into the grid. It is seven kilometres southwest of Stansbury.\n\nThe battery was constructed by Consolidated Power Projects with ABB and Samsung components. It was part-funded by a grant from the Commonwealth Government through the Australian Renewable Energy Agency (ARENA). It was commissioned in June and July 2018. It provides frequency control to the grid, and also enables the possibility for Yorke Peninsula to operate independently of the wider grid in the event of a system failure.\n"}
{"id": "32828323", "url": "https://en.wikipedia.org/wiki?curid=32828323", "title": "Danske Commodities", "text": "Danske Commodities\n\nDanske Commodities (DC) is an independent energy trading house. The company is an international trader of energy-related commodities such as power, gas and climate market products with activities in 37 European countries. \n\nDanske Commodities was founded in September 2004 by Henrik Lind. The company started off with trading electricity across the border between Germany and Denmark, with the first trade implemented on 1 November 2004.\n\nBuilding its foundation on trading on the ‘Day Ahead’ power market, Danske Commodities expanded into the intraday power trading market in 2007. \n\nIn 2009, gas trading and wholesale services, such as energy procurement for supply companies and management of volume and balancing risks, were added to the company’s business activities.\nIn 2011 the company added renewable services optimising the variable output from wind and solar. Today, the company has 6000 MW of renewables under management. \n\nIn 2018, Danske Commodities is present in 37 power markets and in 16 gas markets with a 24/7 trading setup. The company employs approx. 300 employees and is domiciled in Aarhus, Denmark. Besides the headquarter in Denmark, Danske Commodities has offices in United Kingdom (London), Germany (Hamburg) and Turkey (Istanbul). \n\nDanske Commodities’ business consists of two areas: trading and services. \nTRADING\n\nSERVICES\n\n"}
{"id": "363204", "url": "https://en.wikipedia.org/wiki?curid=363204", "title": "Dihedral (aeronautics)", "text": "Dihedral (aeronautics)\n\nDihedral angle is the upward angle from horizontal of the wings or tailplane of a fixed-wing aircraft. \"Anhedral angle\" is the name given to negative dihedral angle, that is, when there is a \"downward\" angle from horizontal of the wings or tailplane of a fixed-wing aircraft.\n\nDihedral angle (or anhedral angle) has a strong influence on dihedral effect, which is named after it. Dihedral effect is the amount of roll moment in a direction produced by the amount of side slip in the opposite direction. Dihedral effect is a critical factor in the stability of an aircraft about the roll axis (the spiral mode). It is also pertinent to the nature of an aircraft's Dutch roll oscillation and to maneuverability about the roll axis.\n\nLongitudinal dihedral is a comparatively obscure term related to the pitch axis of an airplane. It is the angle between the zero-lift axis of the wing and the zero-lift axis of the horizontal tail. Longitudinal dihedral can influence the nature of controllability about the pitch axis and the nature of an aircraft's phugoid-mode oscillation.\n\nWhen the term \"dihedral\" (of an aircraft) is used by itself it is usually intended to mean \"dihedral \"angle\"\". However, context may otherwise indicate that \"dihedral \"effect\"\" is the intended meaning.\n\nDihedral angle is the upward angle from horizontal of the wings of a fixed-wing aircraft, or of any paired nominally-horizontal surfaces on any aircraft. The term can also apply to the wings of a bird. Dihedral angle is also used in some types of kites such as box kites. Wings with more than one angle change along the full span are said to be \"polyhedral\".\n\nDihedral angle has important stabilizing effects on flying bodies because it has a strong influence on the dihedral effect.\n\nDihedral effect of an aircraft is a rolling moment resulting from the vehicle having a non-zero angle of sideslip. Increasing the dihedral angle of an aircraft increases the dihedral effect on it. However, many other aircraft parameters also have a strong influence on dihedral effect. Some of these important factors are: wing sweep, vertical center of gravity, and the height and size of anything on an aircraft that changes its sidewards force as sideslip changes.\n\nDihedral angle on an aircraft almost always implies the angle between two \"paired\" surfaces, \"one on each side of the aircraft\". Even then, it is almost always between the left and right \"wings\". However, mathematically dihedral means the angle between \"any\" two planes. So, in aeronautics, in one case, the term \"dihedral\" is applied to mean the difference in angles between two \"front-to-back\" surfaces:\n\nLongitudinal dihedral is the difference between the angle of incidence of the wing root chord and angle of incidence of the horizontal tail root chord.\n\nLongitudinal dihedral can also mean the angle between the zero-lift axis of the wing and the zero-lift axis of the horizontal tail instead of between the root chords of the two surfaces. This is the more meaningful usage because the directions of zero-lift are pertinent to longitudinal trim and stability while the directions of the root chords are not.\n\nIn geometry, dihedral angle is the angle between two planes. Aviation usage differs slightly from usage in geometry. In aviation, the usage \"dihedral\" evolved to mean the positive, up angle between the left and right wings, while usage with the prefix \"an-\" (as in \"anhedral\") evolved to mean the negative, down angle between the wings.\n\nThe aerodynamic stabilizing qualities of a dihedral angle were described in an influential 1810 article by Sir George Cayley.\n\nIn analysis of aircraft stability, the dihedral effect is also a stability derivative called C meaning the change in rolling moment coefficient (the \"C\") per degree (or radian) of change in sideslip angle (the \"formula_1\").\n\nThe purpose of dihedral effect is to contribute to stability in the roll axis. It is an important factor in the stability of the \"spiral mode\" which is sometimes called \"roll stability\". The dihedral effect does not contribute directly to the restoring of \"wings level\", but it indirectly helps restore \"wings level\" through its effect on the spiral mode of motion described below.\n\nAircraft designers may increase dihedral angle to provide greater clearance between the wing tips and the runway. This is of particular concern with swept-wing aircraft, whose wingtips could hit the runway on rotation/touchdown. In military aircraft dihedral angle space may be used for mounting materiel and drop-tanks on wing hard points, especially in aircraft with low wings. The increased dihedral effect caused by this design choice may need to be compensated for, perhaps by decreasing the dihedral angle on the horizontal tail.\n\nDuring design of a fixed-wing aircraft (or any aircraft with horizontal surfaces), changing dihedral angle is usually a relatively simple way to adjust the overall dihedral effect. This is to compensate for other design elements' influence on the dihedral effect. These other elements (such as wing sweep, vertical mount point of the wing, etc.) may be more difficult to change than the dihedral angle. As a result, differing amounts of dihedral angle can be found on different types of fixed-wing aircraft. For example, the dihedral angle is usually greater on low-wing aircraft than on otherwise-similar high-wing aircraft. This is because \"highness\" of a wing (or \"lowness\" of vertical center of gravity compared to the wing) naturally creates \"more\" dihedral effect itself. This makes it so less dihedral angle is needed to get the amount of dihedral effect needed.\n\nDihedral effect is defined simply to be the rolling moment caused by sideslip and nothing else. Rolling moments caused by other things that may be related to sideslip have different names.\n\nDihedral effect is not caused by \"yaw rate\", nor by the \"rate of sideslip change\". Since dihedral effect is noticed by pilots when \"rudder is applied\", many pilots and other near-experts explain that the rolling moment is caused by one wing moving more quickly through the air and one wing less quickly. Indeed, these are actual effects, but they are not the dihedral effect, which is caused by being \"at\" a sideslip angle, not by getting to one. These other effects are called \"rolling moment due to yaw rate\" and \"rolling moment due to sideslip rate\" respectively.\n\nDihedral effect is not roll stability in and of itself. Roll stability is less-ambiguously termed \"spiral mode stability\" and dihedral effect is a contributing factor to it.\n\nThe dihedral angle contributes to the total dihedral effect of the aircraft. In turn, the dihedral effect contributes to stability of the \"spiral mode\". A \"stable\" spiral mode will cause the aircraft to eventually return to a nominally \"wings level\" bank angle when the angle of the wings is disturbed to become off-level.\n\nIf a disturbance causes an aircraft to roll away from its normal wings-level position as in Figure 1, the aircraft will begin to move somewhat sideways toward the lower wing.\nIn Figure 2, the airplane's flight path has started to move toward its left while the nose of the airplane is still pointing in the original direction. This means that the oncoming air is arriving somewhat from the left of the nose. The airplane now has \"sideslip\" angle in addition to the bank angle. Figure 2 shows the airplane as it presents itself to the oncoming air.\n\nIn Figure 2, the sideslip conditions produce greater angle of attack on the forward-yawed wing and smaller angle of attack on the rearward-yawed wing. This alteration of angle of attack by sideslip is visible in Figure 2. As greater angle of attack produces more lift (in the usual case, when the wing is not near stalling), the forward wing will have more lift and the rearward wing will have less lift. This difference in lift between the wings is a rolling moment, and since it is caused by sideslip, it is dihedral effect (or more correctly, it is a \"contribution\" to the total dihedral effect of the aircraft).\n\nThe rolling moment created by the sideslip (labeled as \"P\") \"tends\" to roll the aircraft back to wings level. More dihedral effect tries to roll the wings in the \"leveling\" direction more strongly, and less dihedral effect tries to roll the wings in the \"leveling\" direction less strongly. Dihedral effect helps stabilize the spiral mode by \"tending\" to roll the wings toward level in proportion to the amount of sideslip that builds up. It's not the whole picture however. At the same time that angle of sideslip is building up, the vertical fin is trying to turn the nose back into the wind, much like a weathervane, minimizing the amount of sideslip that can be present. If there is no sideslip, there can be no restoring rolling moment. If there is less sideslip, there is less restoring rolling moment. Yaw stability created by the vertical fin opposes the tendency for dihedral effect to roll the wings back level by limiting sideslip.\n\nThe spiral mode is the tendency to slowly diverge from, or the tendency to slowly return to wings level. If the spiral mode is stable, the aircraft will slowly return to wings-level, if it is unstable, the aircraft will slowly diverge from wings-level. Dihedral effect and yaw stability are the two primary factors that affect the stability of the spiral mode, although there are other factors that affect it less strongly.\n\nFactors of design other than dihedral angle also contribute to dihedral effect. Each increases or decreases total aircraft dihedral effect to a greater or lesser degree.\n\nWing sweepback also increases dihedral effect. This is one reason for anhedral configuration on aircraft with high sweep angle, as well as on some airliners, even on low-wing aircraft such as the Tu-134 and Tu-154, with the small German 1930s-1945 biplanes of the Bücker Flugzeugbau, the Bucker Jungmann two-seat trainer and more famous Bücker Jungmeister aerobatic competition biplane, both having approximately 11º of wing sweepback giving both designs a degree of dihedral effect, beyond the small amount of dihedral both biplanes' designs also featured.\n\nThe center of mass, usually called the center of gravity or \"CG\", is the balance point of an aircraft. If suspended at this point and allowed to rotate, a body (aircraft) will be balanced. The front-to-back location of the CG is of primary importance for the general stability of the aircraft, but the vertical location has important effects as well.\n\nThe vertical location of the CG changes the amount of dihedral effect. As the \"vertical CG\" moves lower, dihedral effect increases. This is caused by the center of lift and drag being further above the CG and having a longer moment arm. So, the same forces that change as sideslip changes (primarily sideforce, but also lift and drag) produce a larger moment about the CG of the aircraft. This is sometimes referred to as the pendulum effect.\n\nAn extreme example of the effect of vertical CG on dihedral effect is a paraglider. The dihedral effect created by the very low vertical CG more than compensates for the negative dihedral effect created by the strong anhedral of the necessarily strongly downward curving wing.\n\nA side effect of too much dihedral effect, caused by excessive dihedral angle among other things, can be yaw-roll coupling (a tendency for an aircraft to Dutch roll). This can be unpleasant to experience, or in extreme conditions it can lead to loss of control or can overstress an aircraft.\n\nMilitary fighter aircraft often have near zero or even anhedral angle reducing dihedral effect and hence reducing the stability of the spiral mode. This increases maneuverability which is desirable in fighter-type aircraft.\n\nAnhedral angles are also seen on aircraft with a high mounted wing, such as the very large Antonov An-124 and Lockheed Galaxy cargo aircraft. In such designs, the high mounted wing is above the aircraft's center of gravity which confers extra dihedral effect due to the pendulum effect (also called the keel effect) and so additional dihedral angle is often not required. Such designs can have excessive dihedral effect and so be excessively stable in the spiral mode, so anhedral angle on the wing is added to cancel out some of the dihedral effect so that the aircraft can be more easily maneuvered.\n\nMost aircraft have been designed with planar wings with simple dihedral (or anhedral). Some older aircraft such as the Vought F4U Corsair and the Beriev Be-12 were designed with gull wings bent near the root. Modern polyhedral wing designs generally bend upwards near the wingtips (also known as \"tip dihedral\"), increasing dihedral effect without increasing the angle the wings meet at the root, which may be restricted to meet other design criteria.\n\nPolyhedral is seen on gliders and some other aircraft. The McDonnell Douglas F-4 Phantom II is one such example, unique among jet fighters for having dihedral wingtips. This was added after flight testing of the flat winged prototype showed the need to correct some unanticipated spiral mode instability – angling the wingtips, which were already designed to fold up for carrier operations, was a more practical solution than re-engineering the entire wing.\n"}
{"id": "570184", "url": "https://en.wikipedia.org/wiki?curid=570184", "title": "ECOS (BANC magazine)", "text": "ECOS (BANC magazine)\n\nEcos is an online journal by the British Association of Nature Conservationists (BANC). The magazine was founded in 1974. It was a print quarterly journal until 2011 when it went online. The online journal is published three times a year. The journal publishes articles on nature conservation-related topics.\n\n"}
{"id": "41526518", "url": "https://en.wikipedia.org/wiki?curid=41526518", "title": "Electricity sector in Mongolia", "text": "Electricity sector in Mongolia\n\nThe electricity sector in Mongolia ranges from generation, transmission, distribution and sales of electricity in Mongolia.\n\nIn 2010, the total amount of electricity produced by all types of power plant in Mongolia are 4,256.1 GWh (thermal power), 31 GWh (hydroelectric), 13.2 GWh (diesel) and 0.6 GWh (solar and wind).\n\nIn 2012, coal is used to generate 98% of the electricity in Mongolia.\n\n"}
{"id": "4612747", "url": "https://en.wikipedia.org/wiki?curid=4612747", "title": "Embalse Nuclear Power Station", "text": "Embalse Nuclear Power Station\n\nThe Embalse Nuclear Power Station () is one of three operational nuclear power plants in Argentina. It is located on the southern shore of a reservoir on the Río Tercero, near the city of Embalse, Córdoba, 110 km south-southwest of Córdoba City.\n\nThe plant is a CANDU Pressurised Heavy Water Reactor (PHWR). It employs natural uranium (that is, with 0.72% of U) and uses heavy water for cooling and neutron moderation. It has a thermal power of 2,109 MW, and generates 648 MW of electricity, with a net output of about 600 MW, supplying nearly 4.5% of the production of the Argentine Interconnection System (2005).\n\nAdditionally, Embalse produces the cobalt-60 radioisotope, which is employed in medicine (cancer therapy) and industrial applications. Argentina is one of the largest producers and exporters of this isotope in the world, along with Canada and Russia.\n\nEmbalse was started in 1974 and began operation in 1983 (first criticality 13 March 1983, declared commercial 20 January 1984). It was built by an Italian-Canadian consortium formed by AECL, acting as the \"turn-key\" supplier of the nuclear portion, and , the \"turn-key\" supplier of the conventional portion.\n\nOn 31 December 2015, the plant was taken offline, having completed its first operating cycle of about 30 years.\n\nOn 1 September 2016, the plant received the last two of four steam generators, fundamental elements for the life extension of the plant. The plant is being reconditioned to deliver power for another 30 years: the replacement of the four steam generators is one of the key steps.\n\n\n"}
{"id": "7438593", "url": "https://en.wikipedia.org/wiki?curid=7438593", "title": "Enefit Kaevandused", "text": "Enefit Kaevandused\n\nEnefit Kaevandused (former names: Eesti Põlevkivi and Eesti Energia Kaevandused) is a mining company located in Jõhvi, Estonia. It is a subsidiary of Eesti Energia, an Estonian state-owned energy company. The core activity of Enefit Kaevandused is oil-shale mining. The produced oil shale is mainly used to fuel oil shale-fired power stations in the north–east of Estonia. The company has 3,150 employees. The chief executive officer is Valeri Abramov.\n\nEnefit Kaevandused were established in June 1945 as Eesti Põlevkivi, also known by its name in Russian \"Estonslanets\". It was created by merging Kukruse and Käva II mines. In 1946, it took over Viivikonna mine.\n\nIn 1999, Government of Estonia handed 51% of shares of Eesti Põlevkivi to Narva Elektrijaamad. In 2003, Government transferred remained 49% stake in Eesti Põlevkivi to Eesti Energia. Also Narva Elektrijaamad-owned 51% stake was transferred to Eesti Energia and Eesti Põlevkivi became a fully owned subsidiary of Eesti Energia.\n\nEnefit Kaevandused has following subsidiaries:\n\n"}
{"id": "40932009", "url": "https://en.wikipedia.org/wiki?curid=40932009", "title": "Energy efficiency in agriculture", "text": "Energy efficiency in agriculture\n\nEuropean Commission definitions of energy efficiency, are given below: \n\nAccording to article 2(d) of the Regulation (EC) No1099/2008 on energy statistics:\n\n\n\nEuropean Commission requirements regarding energy use across the EU (Directive 2012/27/EU) establish a common framework of measures for the promotion of energy efficiency within the European Union to:\nThe directive also:\n\nProvides for the establishment of indicative national energy efficiency targets for 2020Key measures with implications for the agricultural sector:\n\nIn the framework of the AGREE project [3], several state of the art studies on the energy efficiency of specific agricultural production systems of different types (arable crops, agro-forest, greenhouses, and animal husbandry) were executed in 2012-13 in Europe based on existing data from six countries and were combined in one report.\n\nA stakeholder and driver analysis on energy efficiency in agriculture in all six countries and separate reports Finland, Germany, Greece, Netherlands, Poland, Portugal) are available.\n\nEnergy efficiency measures were proposed for each agricultural system and presented in an overview report. A synthesis and summary report on state of the art, drivers and stakeholders of energy efficiency in agriculture, and potential of energy saving hours is also available.\n\nThe most directly effective measures were taken into account in reporting their effect on energy consumption per unit of product in certain case studies in all seven countries taking into account trade-offs regarding GHG emissions and final farm cost. The results are presented in a report named Economic and environmental analysis of energy efficiency measures in agriculture – Case Studies and trade-offs.\n\nAn intensive stakeholder process, by organising national stakeholders meetings in six countries, revealed the opportunities and drawbacks for a future energy efficient agriculture in Europe. The results of this process are presented for six countries at special reports, one for each country (Finland, Germany, Greece, Netherlands, Poland, Portugal). The results of all reports are summarized in a synthesis report on transnational value of national stakeholders meetings.\n\nThe integration of the perspectives of representatives of different EU regions to achieve a future energy efficient agriculture in Europe, an output of a European transnational stakeholder meeting, is summarized in the Agenda for transnational collaboration. This represents the shared views on how to improve energy efficiency in European agriculture.\n\nAccording to the work done in AGREE, suggestions were given on the definition of energy efficiency in agriculture\n\n"}
{"id": "31929851", "url": "https://en.wikipedia.org/wiki?curid=31929851", "title": "Gobius scorteccii", "text": "Gobius scorteccii\n\nGobius scorteccii is a species of freshwater goby native to Somalia, Africa. This species can reach a length of TL. The specific name honours the Italian herpetologist Giuseppe Scortecci (1898-1973) of the University of Genoa, who was the collector of the type.\n"}
{"id": "633233", "url": "https://en.wikipedia.org/wiki?curid=633233", "title": "Gravitino", "text": "Gravitino\n\nIn supergravity theories combining general relativity and supersymmetry, the gravitino () is the gauge fermion supersymmetric partner of the hypothesized graviton. It has been suggested as a candidate for dark matter.\n\nIf it exists, it is a fermion of spin and therefore obeys the Rarita-Schwinger equation. The gravitino field is conventionally written as \"ψ\" with a four-vector index and a spinor index.\nFor one would get negative norm modes, as with every massless particle of spin 1 or higher. These modes are unphysical, and for consistency there must be a gauge symmetry which cancels these modes: , where \"ε\"(\"x\") is a spinor function of spacetime. This gauge symmetry is a local supersymmetry transformation, and the resulting theory is supergravity.\n\nThus the gravitino is the fermion mediating supergravity interactions, just as the photon is mediating electromagnetism, and the graviton is presumably mediating gravitation. Whenever supersymmetry is broken in supergravity theories, it acquires a mass which is determined by the scale at which supersymmetry is broken. This varies greatly between different models of supersymmetry breaking, but if supersymmetry is to solve the hierarchy problem of the Standard Model, the gravitino cannot be more massive than about 1 TeV/c.\n\nIf the gravitino indeed has a mass of the order of TeV, then it creates a problem in the standard model of cosmology, at least naïvely.\n\nOne option is that the gravitino is stable. This would be the case if the gravitino is the lightest supersymmetric particle and R-parity is conserved (or nearly so). In this case the gravitino is a candidate for dark matter; as such gravitinos will have been created in the very early universe. However, one may calculate the density of gravitinos and it turns out to be much higher than the observed dark matter density.\n\nThe other option is that the gravitino is unstable. Thus the gravitinos mentioned above would decay and will not contribute to the observed dark matter density. However, since they decay only through gravitational interactions, their lifetime would be very long, of the order of in natural units, where \"M\" is the Planck mass and \"m\" is the mass of a gravitino. For a gravitino mass of the order of TeV this would be , much later than the era of nucleosynthesis. At least one possible channel of decay must include either a photon, a charged lepton or a meson, each of which would be energetic enough to destroy a nucleus if it strikes one. One can show that enough such energetic particles will be created in the decay as to destroy almost all the nuclei created in the era of nucleosynthesis, in contrast with observations. In fact, in such a case the universe would have been made of hydrogen alone, and star formation would probably be impossible.\n\nOne possible solution to the cosmological gravitino problem is the split supersymmetry model, where the gravitino mass is much higher than the TeV scale, but other fermionic supersymmetric partners of standard model particles already appear at this scale.\n\nAnother solution is that R-parity is slightly violated and the gravitino is the lightest supersymmetric particle. This causes almost all supersymmetric particles in the early Universe to decay into Standard Model particles via R-parity violating interactions well before the synthesis of primordial nuclei; a small fraction however decay into gravitinos, whose half-life is orders of magnitude greater than the age of the Universe due to the suppression of the decay rate by the Planck scale and the small R-parity violating couplings.\n"}
{"id": "34828285", "url": "https://en.wikipedia.org/wiki?curid=34828285", "title": "International Development Markup Language", "text": "International Development Markup Language\n\nThe International Development Markup Language (IDML) is an XML-based standard for the exchange of information on aid activities. It is used by a number of donors to provide information to the AidData database of development finance.\n\nIDML was developed from 1998 onwards, building on a previous text-file format for exchanging development information, CEFDA (Common Format for Exchange of Development Information).\n\nIdeas from IDML were also fed into the development of the XML format used in the International Aid Transparency Initiative (IATI).\n\nIDML Initiative website with archive of resources from the standards development.\n"}
{"id": "35133726", "url": "https://en.wikipedia.org/wiki?curid=35133726", "title": "It's on the Meter", "text": "It's on the Meter\n\nIt’s on the Meter – World Taxi Challenge was a round-the-world motoring expedition that broke the Guinness World Records for the longest ever journey by taxi and the highest altitude ever reached by taxi. The expedition’s three-man team used a 1992 Fairway Driver London Black Cab to drive 43,319.5 miles (69,716.12 km) around the world.\n\nThe expedition officially began at the London Transport Museum on 17 February 2011 and finished at the same point on 11 May 2012 having circumnavigated the globe. \nThe team raised £20,000 for the British Red Cross; the nominal meter fee for the finished journey was £79,006.80.\n\nThe expedition was conceived of in 2008 when the participants were travelling by taxi and wondered how high a taxi meter fee had ever been.\n\nThe team researched the previous record which stood at 21,691 miles (34,908 km) and was set in 1994. The team then planned a new route from London to Sydney with an estimated distance of 32,000 miles, bought a taxi for £1500 on eBay and began securing sponsorship.\n\nThe expedition departed from the London Transport Museum on 17 February 2011 with support from Boris Johnson and Sir Ranulph Fiennes.\n\nThe team broke the previous record in August 2011 in Tibet having travelled through 34 countries.\n\nThe expedition arrived in Sydney, Australia, nine months after setting off from London having travelled through forty-one countries and three continents.\n\nUpon arrival in Sydney the team announced that they had secured a sponsorship partnership with Smartphone Taxi ordering-app company GetTaxi and would be extending the expedition back to London via the United States, Israel, Russia and Europe.\n\nThe vehicle was shipped from Sydney to San Francisco over the Christmas of 2011 and the team continued the journey from California to New York before air-freighting the car to Israel in March 2012.\n\nThe expedition then shipped from Israel to Greece before continuing back through Russia, Europe and Spain and finishing in London on 11 May 2012.\n\nThe route was designed to take \"“the longest route ever, because taxi drivers always take all the longest way around,”\" and encompassed over fifty countries.\n\nThe expedition started in Covent Garden, London before driving to Dover, England and ferrying over to France. The expedition then passed through Belgium, Netherlands, Germany, Denmark, Sweden and into Finland where the team drove to the Arctic Circle and saw the Northern Lights.\n\nThe expedition then travelled through Russia (where the team were arrested in Moscow), Belarus, Ukraine, Poland, Czech Republic, Austria, Germany, Lichtenstein, Switzerland, France, Monaco, Italy and San Marino. The original route took the team down to Sicily to catch a ferry to Tunisia but due to the conflict in Libya the route was revised to instead pass through the Balkans.\n\nThe team passed through Croatia, Bosnia, Montenegro, Kosovo, Macedonia and Greece before arriving in Turkey in April 2011. Due to the demonstrations in Syria the team further modified the route and next travelled to Georgia and Armenia before heading back into Turkey and down into Iraq. Whilst in northern Kurdistan their radiator burst but a replacement was built in Arbil auto bazaar and the team continued into Iran.\n\nNear the Iranian city of Qom the team were detained and questioned by the secret police after mistakenly camping next to an artillery installation. At this point Archer and Purnell travelled by air to Dubai in order to obtain Pakistani visas and Ellison (who had already secured a visa in the UK) continued through the Baluchistan desert.\n\nThe team was reunited in Pakistan and continued through India, Nepal, Tibet (where the previous record's distance was broken) and China, arriving in Laos in September 2011. The journey then continued through Cambodia, Thailand and Malaysia before the vehicle was shipped from Singapore to Darwin, Australia.\n\nOn arrival in Australia the vehicle was subject to strict quarantine fines but upon its release travelled through the Northern Territory and down the East Coast, arriving at the intended destination on 10 December 2011.\n\nAt this point the team announced that they had partnered with a new sponsor, GetTaxi and now intended to drive the vehicle back to London having circumnavigated the world. The car was shipped from Sydney to San Francisco and the team returned to the UK for a Christmas break.\n\nAfter lengthy delays the car was released from Oakland Port in February 2012 and the team drove across the USA, arriving at New York in March 2012. The car was then air-freighted to Israel from where it will be shipped to Greece before continuing north to Moscow.\n\nThe final leg headed through the Baltics and Eastern Europe before passing through Germany, Luxembourg and France. The car was then taken back to the United Kingdom via the Channel Tunnel and arrived back at the start point in London on 11 May 2012.\n\nThe mileage of the entire journey was 43,208.4 miles (69,537.18 km), more than double the previous record. The nominal taxi fare reached £79,006.80.\n\nThe expedition vehicle was an extensively modified 1992 Austin FX4 taxi named Hannah, after the song Hard Hearted Hannah which tells of a woman who \"hates men and loves to see them suffer\".\n\nThe vehicle was powered by a Nissan 2.7 litre Turbo Diesel engine which the team claimed was the only part of the car not to have broken stating that this is because it is \"Japanese-made whereas the rest of the car was made in England\".\nThe car was purchased for £1500 on eBay and modifications include the addition of winch, snorkel, roof rack and roof box. The car's brakes, suspension, cooling and electric systems were also overhauled and updated. Inside the partition between the driver and passengers was removed, a front passenger seat was added, the rear-facing rear seats were removed and a sound system was installed.\n\nThe mileage of the car when purchased was estimated at 300,000 miles and the team states that it broke down, \"every other day\".\n\nThe team did not have a support vehicle but was joined for the USA leg of the expedition by a United States Yellow Taxi. The team met Jon Anders, previously a resident of Texas, in Pakistan and joked, \"If you buy a Yellow Cab you can join us for the US section\". The driver took the team up on the offer and purchased a Ford Crown Victoria which was named \"Skinny Margarita\" after an old advertisement attached to the roof.\n\nThe expedition was conceived and organised by Leigh Purnell, Johno Ellison and Paul Archer, three friends who met whilst studying at Aston University.\n\nThe expedition raised both awareness and funds for the British Red Cross. The team decided to choose the Red Cross due to the fundraising work they carry out both in the UK and Worldwide as well as the worldwide support they could offer the team.\nThe expedition raised £20,000 for the charity.\n\nA book, \"It's on the Meter: One Taxi, Three Mates and 43,000 Miles of Misadventures around the World\", is due to be released on 10 March 2016.\n\nThe team has also contributed articles to various magazines and blogs and Johno Ellison's account of the team's arrest in Russia was published in upcoming travel book \"From the Grand Canyon to the Great Wall\" released in Summer 2012.\n\n"}
{"id": "33612908", "url": "https://en.wikipedia.org/wiki?curid=33612908", "title": "Les Enfants du Borinage – Lettre à Henri Storck", "text": "Les Enfants du Borinage – Lettre à Henri Storck\n\nThe kids of the coal mine: A letter to Henri Storck (original title: \"Les enfants du Borinage - Lettre a Henri Storck\") is a 1999 documentary film by director Patric Jean about the former mining district Borinage in the Walloon region of Belgium.\n\nThe film is a follow up/homage to Henri Storck's previous 1933 documentary about the Borinage, \"Misère au Borinage\".\n\n\n"}
{"id": "45930", "url": "https://en.wikipedia.org/wiki?curid=45930", "title": "List of index fossils", "text": "List of index fossils\n\nIndex fossils (also known as guide fossils or indicator fossils) are fossils used to define and identify geologic periods (or faunal stages). Index fossils must have a short vertical range, wide geographic distribution and rapid evolutionary trends. Another term, Zone fossil is used when the fossil have all the characters stated above except wide geographical distribution, they are limited to a zone and can't be used for correlations of stratas. \n"}
{"id": "449667", "url": "https://en.wikipedia.org/wiki?curid=449667", "title": "List of semiconductor materials", "text": "List of semiconductor materials\n\nSemiconductor materials are nominally small band gap insulators. The defining property of a semiconductor material is that it can be doped with impurities that alter its electronic properties in a controllable way. \n\nBecause of their application in the computer and photovoltaic industry—in devices such as transistors, lasers, and solar cells—the search for new semiconductor materials and the improvement of existing materials is an important field of study in materials science.\n\nMost commonly used semiconductor materials are crystalline inorganic solids. These materials are classified according to the periodic table groups of their constituent atoms.\n\nDifferent semiconductor materials differ in their properties. Thus, in comparison with silicon, compound semiconductors have both advantages and disadvantages. For example, gallium arsenide (GaAs) has six times higher electron mobility than silicon, which allows faster operation; wider band gap, which allows operation of power devices at higher temperatures, and gives lower thermal noise to low power devices at room temperature; its direct band gap gives it more favorable optoelectronic properties than the indirect band gap of silicon; it can be alloyed to ternary and quaternary compositions, with adjustable band gap width, allowing light emission at chosen wavelengths, and allowing e.g. matching to wavelengths with lowest losses in optical fibers. GaAs can be also grown in a semi-insulating form, which is suitable as a lattice-matching insulating substrate for GaAs devices. Conversely, silicon is robust, cheap, and easy to process, whereas GaAs is brittle and expensive, and insulation layers can not be created by just growing an oxide layer; GaAs is therefore used only where silicon is not sufficient.\n\nBy alloying multiple compounds, some semiconductor materials are tunable, e.g., in band gap or lattice constant. The result is ternary, quaternary, or even quinary compositions. Ternary compositions allow adjusting the band gap within the range of the involved binary compounds; however, in case of combination of direct and indirect band gap materials there is a ratio where indirect band gap prevails, limiting the range usable for optoelectronics; e.g. AlGaAs LEDs are limited to 660 nm by this. Lattice constants of the compounds also tend to be different, and the lattice mismatch against the substrate, dependent on the mixing ratio, causes defects in amounts dependent on the mismatch magnitude; this influences the ratio of achievable radiative/nonradiative recombinations and determines the luminous efficiency of the device. Quaternary and higher compositions allow adjusting simultaneously the band gap and the lattice constant, allowing increasing radiant efficiency at wider range of wavelengths; for example AlGaInP is used for LEDs. Materials transparent to the generated wavelength of light are advantageous, as this allows more efficient extraction of photons from the bulk of the material. That is, in such transparent materials, light production is not limited to just the surface. Index of refraction is also composition-dependent and influences the extraction efficiency of photons from the material.\n\n\nA \"compound semiconductor\" is a semiconductor compound composed of chemical elements of at least two different species. These semiconductors typically form in periodic table groups 13–15 (old groups III–V), for example of elements from the Boron group (old group III, boron, aluminium, gallium, indium) and from group 15 (old group V, nitrogen, phosphorus, arsenic, antimony, bismuth). The range of possible formulae is quite broad because these elements can form binary (two elements, e.g. gallium(III) arsenide (GaAs)), ternary (three elements, e.g. indium gallium arsenide (InGaAs)) and quaternary (four elements, e.g. aluminium gallium indium phosphide (AlInGaP)) alloys.\n\nMetalorganic vapour phase epitaxy (MOVPE) is the most popular deposition technology for the formation of compound semiconducting thin films for devices. It uses ultrapure metalorganics and/or hydrides as precursor source materials in an ambient gas such as hydrogen.\n\nOther techniques of choice include:\n\n\nThe following semiconducting systems can be tuned to some extent, and represent not a single material but a class of materials.\n\nf"}
{"id": "29440334", "url": "https://en.wikipedia.org/wiki?curid=29440334", "title": "Lists of wind farms by country", "text": "Lists of wind farms by country\n\nLists of wind farms by country include:\n\n\n"}
{"id": "949696", "url": "https://en.wikipedia.org/wiki?curid=949696", "title": "Mainspring", "text": "Mainspring\n\nA mainspring is a spiral torsion spring of metal ribbon—commonly spring steel—used as a power source in mechanical watches, some clocks, and other clockwork mechanisms. \"Winding\" the timepiece, by turning a knob or key, stores energy in the mainspring by twisting the spiral tighter. The force of the mainspring then turns the clock's wheels as it unwinds, until the next winding is needed. The adjectives wind-up and spring-powered refer to mechanisms powered by mainsprings, which also include kitchen timers, music boxes, wind-up toys and clockwork radios.\n\nA modern watch mainspring is a long strip of hardened and blued steel, or specialised steel alloy, 20–30 cm long and 0.05-0.2 mm thick. The mainspring in the common 1-day movement is calculated to enable the watch to run for 36 to 40 hours, i.e. 24 hours between daily windings with a power-reserve of 12 to 16 hours, in case the owner is late winding the watch. This is the normal standard for hand-wound as well as self-winding watches. 8-Day movements, used in clocks meant to be wound weekly, provide power for at least 192 hours but use longer mainsprings and bigger barrels. Clock mainsprings are similar to watch springs, only larger.\n\nSince 1945, carbon steel alloys have been increasingly superseded by newer special alloys (iron, nickel and chromium with the addition of cobalt, molybdenum, or beryllium), and also by cold-rolled alloys ('structural hardening'). Known to watchmakers as 'white metal' springs (as opposed to blued carbon steel), these are stainless and have a higher elastic limit. They are less subject to permanent bending (becoming 'tired') and there is scarcely any risk of their breaking. Some of them are also practically non-magnetic.\n\nIn their relaxed form, mainsprings are made in three distinct shapes:\nThe semi-reverse and reverse types provide extra force at the end of the running period, when the spring is almost out of energy, in order to keep the timepiece running at a constant rate to the end.\n\nThe mainspring is coiled around an axle called the arbor, with the inner end hooked to it. In many clocks, the outer end is attached to a stationary post. The spring is wound up by turning the arbor, and after winding its force turns the arbor the other way to run the clock. The disadvantage of this \"open spring\" arrangement is that while the mainspring is being wound, its drive force is removed from the clock movement, so the clock may stop. This type is often used on alarm clocks, music boxes and kitchen timers where it doesn't matter if the mechanism stops while winding. The winding mechanism always has a ratchet attached, with a pawl (called by clockmakers the \"click\") to prevent the spring from unwinding.\n\nIn the form used in modern watches, called the \"going barrel\", the mainspring is coiled around an arbor and enclosed inside a cylindrical box called the barrel which is free to turn. The spring is attached to the arbor at its inner end, and to the barrel at its outer end. The attachments are small hooks or tabs, which the spring is hooked to by square holes in its ends, so it can be easily replaced.\n\nThe mainspring is wound by turning the arbor, but drives the watch movement by the barrel; this arrangement allows the spring to continue powering the watch while it is being wound. Winding the watch turns the arbor, which tightens the mainspring, wrapping it closer around the arbor. The arbor has a ratchet attached to it, with a click to prevent the spring from turning the arbor backward and unwinding. After winding, the arbor is stationary and the pull of the mainspring turns the barrel, which has a ring of gear teeth around it. This meshes with one of the clocks gears, usually the \"center wheel\" pinion and drives the wheel train. The barrel usually rotates once every 8 hours, so the common 40-hour spring requires 5 turns to unwind completely.\n\nThe mainspring contains a lot of energy. Clocks and watches have to be disassembled periodically for maintenance and repair, and if precautions are not taken the spring can release suddenly, causing serious injury. Mainsprings are 'let down' gently before servicing, by pulling the click back while holding the winding key, allowing the spring to slowly unwind. However, even in their 'let down' state, mainsprings contain dangerous residual tension. Watchmakers and clockmakers use a tool called a \"mainspring winder\" to safely install and remove them. Large mainsprings in clocks are immobilized by \"mainspring clamps\" before removal.\n\nMainsprings appeared in the first spring-powered clocks, in 15th-century Europe. It replaced the weight hanging from a cord wrapped around a pulley, which was the power source used in all previous mechanical clocks. Around 1400 coiled springs began to be used in locks, and many early clockmakers were also locksmiths. Springs were applied to clocks to make them smaller and more portable than previous weight-driven clocks, evolving into the first pocketwatches by 1600. Many sources erroneously credit the invention of the mainspring to the Nuremberg clockmaker Peter Henlein (also spelled Henle, or Hele) around 1511. However, many references in 15th-century sources to portable clocks 'without weights', and at least two surviving examples, show that spring-driven clocks existed by the early years of that century. The oldest surviving clock powered by a mainspring is the \"Burgunderuhr\" (Burgundy Clock), an ornate, gilt chamber clock, currently at the Germanisches Nationalmuseum in Nuremberg, whose iconography suggests that it was made around 1430 for Philip the Good, Duke of Burgundy.\n\nThe first mainsprings were made of steel without tempering or hardening processes. They didn't run very long, and had to be wound twice a day. Henlein was noted for making watches that would run 40 hours between windings.\n\nA problem throughout the history of spring-driven clocks and watches is that the force (torque) provided by a spring is not constant, but diminishes as the spring unwinds (see graph). However, timepieces have to run at a constant rate in order to keep accurate time. Timekeeping mechanisms are never perfectly isochronous, meaning their rate is affected by changes in the drive force. This was especially true of the primitive verge and foliot type used before the advent of the balance spring in 1657. So early clocks slowed down during their running period as the mainspring ran down, causing inaccurate timekeeping. \n\nTwo solutions to this problem appeared in the early spring-powered clocks in the 15th century; the \"stackfreed\" and the \"fusee\":\n\nThe stackfreed was an eccentric cam mounted on the mainspring arbor, with a spring-loaded roller that pressed against it. The cam was shaped so that early in the running period when the mainspring was pushing strongly, the stackfreed would provide an opposing force, while later when the mainspring was almost run down and pushing weakly, it would provide a helping force. The stackfreed added a lot of friction and probably reduced a clock's running time substantially; it was rarely used and was abandoned after about a century.\n\nThe fusee was a much longer-lasting innovation. This was a cone-shaped pulley that was turned by a chain wrapped around the mainspring barrel. Its curving shape continuously changed the mechanical advantage of the linkage to even out the force of the mainspring as it ran down. Fusees became the standard method of getting constant torque from a mainspring. They were used in most spring-driven clocks and watches from their first appearance until the 19th century when the going barrel took over, and in marine chronometers until the 1970s.\n\nAnother early device which helped even out the spring's force was \"stopwork\" or \"winding stops\", which prevented the mainspring from being wound up all the way, and prevented it from unwinding all the way. The idea was to use only the central part of the spring's 'torque curve', where its force was more constant. The most common form was the Geneva stop or 'Maltese cross'. Stopwork isn't needed in modern watches.\n\nA fourth device used in a few precision timepieces was the remontoire. This was a small secondary spring or weight which powered the timepiece's escapement, and was itself rewound periodically by the mainspring. This isolated the timekeeping element from the varying mainspring force.\n\nThe modern \"going barrel\", invented in 1760 by Jean-Antoine Lépine, produces a constant force by simply using a longer mainspring than needed, and coiling it under tension in the barrel. In operation, only a few turns of the spring at a time are used, with the remainder pressed against the outer wall of the barrel. Mathematically, the tension creates a 'flat' section in the spring's 'torque curve' (see graph at right) and only this flat section is used. In addition, the outer end of the spring is often given a 'reverse' curve, so it has an 'S' shape. This stores more tension in the spring's outer turns where it is available toward the end of the running period. The result is that the barrel provides approximately constant torque over the watch's designed running period; the torque doesn't decline until the mainspring has almost run down.\n\nThe built-in tension of the spring in the going barrel makes it hazardous to disassemble even when not wound up.\n\nBecause they are subjected to constant stress cycles, up until the 1960s mainsprings generally broke from metal fatigue long before other parts of the timepiece. They were considered expendable items. This often happened at the end of the winding process, when the spring is wound as tightly as possible around the arbor, with no space between the coils. When manually winding, it is easy to reach this point unexpectedly and put excessive pressure on the spring. Another cause was temperature changes. If a watch was fully wound in the evening and the temperature dropped at night, without any slack between the coils the thermal contraction of the long spring could break it loose from its attachments at one end. In earlier times, watch repairers noted that changes in the weather brought in a rash of watches with broken mainsprings. Broken mainsprings were the largest cause of watch repairs until the 1960s. Since then, the improvements in spring metallurgy mentioned above have made broken mainsprings rare.\n\nEven if the mainsprings were not prone to breakage, too much force during winding caused another problem in early watches, called 'knocking' or 'banking'. If very little slack was left in the spring after winding ('overwinding\"), the pressure of the last turn of the winding knob put the end of the spring under excessive tension, which was locked in by the last click of the ratchet. So the watch ran with excessive drive force for several hours, until the extra tension in the end of the spring was relieved. This made the balance wheel rotate too far in each direction, causing the impulse pin on the wheel to knock against the back of the fork horns. This caused the watch to gain time, and could break the impulse pin. In older watches this was prevented with 'stopwork'. In modern watches this is prevented by designing the 'click' with some 'recoil' (backlash), to allow the arbor to rotate backward after winding by about two ratchet teeth, enough to remove excess tension.\n\nAround 1900, when broken watchsprings were more of a problem, some pocketwatches used a variation of the going barrel called the \"motor barrel\" or \"safety barrel\". Mainsprings usually broke at their attachment to the arbor, where bending stresses are greatest. When the mainspring broke, the outer part recoiled and the momentum spun the barrel in the reverse direction. This applied great force to the delicate wheel train and escapement, often breaking pivots and jewels.\n\nIn the motor barrel, the functions of the arbor and barrel were reversed from the going barrel. The mainspring was wound by the barrel, and turned the arbor to drive the wheel train. Thus if the mainspring broke, the destructive recoil of the barrel would be applied not to the wheel train but to the winding mechanism, which was robust enough to take it.\n\nA \"safety pinion\" was an alternate means of protection, used with the going barrel. In this, the centre wheel pinion, which the barrel gear engages, was attached to its shaft with a reverse screw thread. If the spring broke, the reverse recoil of the barrel, instead of being passed on to the gear train, would simply unscrew the pinion.\n\nWatches and clocks are often found stopped with the mainspring fully wound, which led to a myth that winding a spring-driven timepiece all the way up damages it. Several problems can cause this type of breakdown, but it is almost never due to \"overwinding\", as timepieces are designed to handle being wound up all the way. Watch movements, in particular, require regular cleaning and lubrication, and the normal result of neglecting to get a watch cleaned is a watch stopped at full wind. As the watch movement collects dirt and the oil dries up, friction increases, so that the mainspring doesn't have the force to turn the watch at the end of its normal running period, and it stops prematurely. If the owner continues to wind and use the watch without servicing, eventually the friction force reaches the 'flat' part of the torque curve, and quickly a point is reached where the mainspring doesn't have the force to run the watch even at full wind, so the watch stops with the mainspring fully wound. The watch needs service, but the problem is caused by a dirty movement or other defect, not \"overwinding\".\n\nSelf-winding or automatic watches, introduced widely in the 1950s, use the natural motions of the wrist to keep the mainspring wound. A semicircular weight, pivoted at the center of the watch, rotates with each wrist motion. A winder mechanism uses rotations in both directions to wind the mainspring.\n\nIn automatic watches, motion of the wrist could continue winding the mainspring until it broke. This is prevented with a slipping clutch device. The outer end of the mainspring, instead of attaching to the barrel, is attached to a circular expansion spring called the \"bridle\" that presses against the inner wall of the barrel, which has serrations or notches to hold it. During normal winding the bridle holds by friction to the barrel, allowing the mainspring to wind. When the mainspring reaches its full tension, its pull is stronger than the bridle. Further rotation of the arbor causes the bridle to slip along the barrel, preventing further winding. In watch company terminology, this is often misleadingly referred to as an 'unbreakable mainspring'.\n\nAfter decades of use, mainsprings in older timepieces are found to deform slightly and lose some of their force, becoming 'tired' or 'set'. This condition is mostly found in springs in barrels. It causes the running time between windings to decrease. During servicing the mainspring should be checked for 'tiredness' and replaced if necessary. The British Horological Institute suggests these tests:\n\nSome high grade watches have an extra dial on the face indicating how much power is left in the mainspring, often graduated in hours the watch has left to run. Since both the arbor and the barrel turn, this mechanism requires a differential gear that measures how far the arbor has been turned, compared to the barrel.\n\nA mainspring is usually a coiled metal spring, however there are exceptions:\n\n\n"}
{"id": "48823", "url": "https://en.wikipedia.org/wiki?curid=48823", "title": "Malabo", "text": "Malabo\n\nMalabo (; ; formerly Santa Isabel) is the capital of Equatorial Guinea and the province of Bioko Norte. It is located on the north coast of the island of Bioko, formerly known by the Bubis, its indigenous inhabitants, as \"Etulá\", and as \"Fernando Pó\" by the Europeans. The city has a population of approximately 187,302 inhabitants.\n\nSpanish is the official language of the city and of the country as well. Spanish is the most-spoken language and practically the only one used, except some French and Portuguese.\n\nMalabo is the oldest city in Equatorial Guinea. Many buildings in the city are built in a colonial style, dating from the times of Spanish rule, coexisting with modern buildings built since independence. The downtown streets have a square design, with pedestrian areas. This phenomenon causes a feeling of architecture attenuated by the low height of buildings in a combination of architectural Westernization and Africanism.\n\nCiudad de la Paz is a planned city currently under construction in mainland Equatorial Guinea which was designed to replace Malabo as the capital. The institutions of governance of Equatorial Guinea began the process of locating to Oyala in February 2017. \n\nIn 1472, in an attempt to find a new route to India, the Portuguese navigator Fernão do Pó, encountered the island of Bioko, which he called \"Formosa\". Later the island was named after its discoverer, Fernando Pó. At the beginning of the 16th century, specifically in 1507, the Portuguese Ramos de Esquivel made a first attempt at colonization on the island of Fernando Pó. He established a factory in \"Concepción\" (current Riaba) and developed plantations of sugarcane, but the hostility of the insular Bubi people and diseases ended this experience quickly.\n\nWith the treaties of San Ildefonso in 1777 and El Pardo in 1778, during the reign of the Spanish King Carlos III the Portuguese gave to the Spanish island of Fernando Pó, Annobón and the right to conduct trade in the mainland, an area of influence approximately of 800 000 km in Africa, in exchange for the Colonia del Sacramento in the River Plate and the Santa Catalina Island off the Brazilian coast (occupied by the Spaniards). The area stretching from the Niger Delta to the mouth of Ogüé River -in the current Gabon- and included, besides the islands of Fernando Pó and Annobon, the islets of Corisco and Elobeyes. Failed its various unsuccessful attempts to colonize these lands, Spain for its internal problems, lost interest in Spanish Guinea in 1827 and authorized the British use the island as a base for the work of suppression of the slave trade.\n\nIn 1821, the British captain Nelly approached the island of Fernando Pó. He found it abandoned and founded the establishments of \"Melville Bay\" (Riaba) and \"San Carlos\" (now Luba). Some years later, another British captain, William Fitzwilliam Owen, decided to colonize the island and in the north of it -on the site of the present capital- erected a base for British ships hunting European dealers in slaves. Thus arose, on 25 December 1827, \"Port Clarence\" on the ruins of a previous Portuguese settlement. The name was chosen in honor of the Duke of Clarence, who later became King William IV. The Bubis indigenous to the island called it \"\"Ripotó\" (\"place of the foreigners\"). The population of the capital was increased by the arrival of slaves freed by the British. These freedmen were settled in Port Clarence before the establishment of Sierra Leone as a colony for freed slaves. The descendants of these freed slaves remained on the island. They joined other migrants who arrived as free workers from Liberia, Sierra Leone, Ghana, Ivory Coast, Benin, Nigeria and Cameroon, and became the population group called Creole or fernandinos, whose language was a Pidgin Bantu-English with some Spanish elements.\n\nDuring the British period, the British consul automatically became the governor of the colony, including Governor John Beecroft, a British mulatto sailor who modernized the capital, and whose work was later recognized by Spain with a monument in Punta Fernanda.\nIn 1844, when Queen Isabel II of Spain ruled after the regency of her mother Maria Cristina and Baldomero Espartero, in an attempt to modernize Spain and rescue its heritage, Spain let the UK know its desire to regain control of the colony and thus the island. It took another decade to implement this direct control. The capital already had more dynamic and Protestant religious missions which were very successful. Both factors helped to change the attitude of Spain, in addition to internal reasons already alluded.\n\nSpain again took control of the island in 1855 and the capital, Port Clarence, was renamed \"Santa Isabel\", in honor of Queen Isabel II. The capital of the island of Fernando Pó became the capital of Equatorial Guinea.\n\nIts present name was given to the town in 1973 as part of the campaign of President Macías Nguema to replace place names of European origin with African names, in this case honoring Malabo Lopelo Melaka, the last Bubi king. Malabo, the son of King Moka, surrendered to the Spaniards. His uncle Sas Ebuera, head of the Bubi warriors, claimed to represent legitimate Bubi rule and continued resisting, confronting the Spanish openly in 1898. After the Spanish killed Sas Ebuera, Malabo did become king unopposed, but with no authority. Bubi clans and settlements were slow to accept Spanish sovereignty over the island, and the full conquest and pacification of the island was not achieved until 1912.\n\nDuring the so-called \"Reign of Terror\" of Macías Nguema, the dictator suppressed much of the intelligentsia of the country, initiating the process of taking over the positions of the public administration by part of the natives of Mongomo and clan Esangui. Many city residents had to leave. In the last years of his mandate, almost a fifth of the population fled. At that time (1968–1979), Equatorial Guinea received money from the Soviet Union in return for, inter alia, affording port facilities for Soviet naval craft, particularly submarines.\n\nThe infamous Black Beach Prison also known as \"Blay Beach prison\" (or Playa Negra prison) sits at the mouth of the Cónsul River, beside the black beach and behind the Governor's Palace and barracks. Several people have been jailed there in the over the 35 years of dictatorship. Among those imprisoned and tortured are many political leaders such as Rafael Upiñalo (Movimiento), Fabián Nsue (UP), Felipe Ondo Obiang (FDR), Martín Puye of Movement for the Self-Determination of Bioko Island (MAIB) or Plácido Micó of the Social Democratic Convergence for Social Democracy (CPDS).\n\nA group of mercenaries was also jailed at Black Beach for an attempted coup against President Teodoro Obiang Nguema.\n\nMalabo is situated north of the island of Bioko, at coordinates 3° 45' 7.43\" North and 8° 46' 25.32\" East. The south of Malabo is limited by the Cónsul River and just across the river, south-west, is the hospital. West of the city, located about 9 km from the center of Malabo, is renewed Malabo International Airport. In the coastal region north of the city are the bays and capes. The elder is the punta de la Unidad Africana located just behind the Presidential Palace of Malabo and which occupies the entire eastern part of the Bay of Malabo. Another cape of importance is punta Europa located in the west of the city near to the airport.\n\nMalabo features a tropical monsoon climate (Am). Malabo receives on average 1,800 mm of rain per year. The city has a pronounced, albeit short, sunnier (but still cloudy) dry season from December through February. February is normally its driest with 33 mm (0.2 in) of rain falling on average. It also has a very long cloudy wet season that covers the remaining nine months (March–November). On average, the months hit hardest by the wet season are from September to October, with receiving of rain and showers between them.\n\nDaytime temperatures do not vary at all day to day, and only vary a few degrees throughout the entire year. At night, the average low temperature is 20–21°C in every month of the year but January to April have a slightly higher diurnal range because it is clearer. Nonetheless, with only 1,020 hours of sunshine per year, Malabo is one of the cloudiest, wettest and lightning-prone capitals of the world and experiences much fog and haze even when it's not raining in the driest months.\n\nThe current mayor is María Coloma Edjang Mbengono who establishes the municipal services prescribed by law, which are the responsibility of the municipality. These include drinking water and others public sources, lighting, paving of roads, cemeteries, cleaning and sanitation, the sanitary waste treatment and waste, disinfecting, emergency first aid, health inspections and drinks, health inspection of poor housing, sanitation, public banks, slaughterhouses, markets and the elimination of stagnant water.\n\nThrough the Spanish Agency for International Cooperation for Development (AECID), are made several development projects at both regional and national level. Headquartered in the Technical Cooperation Office in Malabo (created in 1984), carried out actions for the development of the culture, health, education and institutional strengthening. Stressing the Cultural Center of Spain in Malabo (CCEM), founded in 2003, where young people are encouraged to feel a cultural space where they can unleash their creative freedom. It also has three geographical axes, in order to capture the largest number of people in the region and contribute to its development. Activities include the training, art, film, theater, music and games, with the two main festivals: Traveling Film Festival of Equatorial Guinea (FECIGE) and the International Festival of Hip Hop in Malabo.\n\nAnother important center is the Hispano-Guinean Cultural Center, from 2012 Equatorial Guinean Cultural Center began as headquarters of Institute Cardinal Cisneros, and then archive, museum and library. It was built in the 1950s.\n\nThe Museum of Modern Art Equatorial Guinea has traditional and contemporary art of the country and the continent. In the city also is the National Library, built in 1916.\n\nMalabo has a relatively young population. Approximately 45% of the population is under 15. Only about 4% of the population is more than 65 years old. Most of the population lives in rural areas of the island.\n\nThe city is predominantly Catholic. More than 80% of the city population is Catholic and about 4% practices a tribal religion. Islam is also present in the city, as is Judaism. Some Christian communities, such as the Mormon and Jehovah's Witnesses, are also present in Malabo, although in smaller numbers.\n\nMalabo is the commercial and financial center. Malabo's economy is based on the administration and other services. Trade is also one of the most prominent and important economic activities, especially since the arrival of US companies which exploit oil wells close to the coast. This trade also comes from the presence of other Americans, Latin Americans, Nigerians, Cameroonians, Spanish and other Central Africans; the headquarters of Bank of Central African States (BEAC) is in Malabo. The building that houses it was originally built by the Banco Popular Español, but after independence became the seat of Banco de Guinea Ecuatorial.\n\nThe main industry in the city is fishing, while cacao and coffee are the main products of export.\n\nMalabo has a high-tonnage port, connected mainly with the ports of Douala, (Cameroon) and Bata, and an air link via an international airport.\n\nThere are about 300 hotel beds, of which only 50 are of quality.\n\nThe National University of Equatorial Guinea (UNGE) and the National Distance Education University (UNED), the latter Spanish-language, have headquarters in the city. The Colegio Nacional Enrique Nvó Okenve, another of the country's universities, has one of its two campuses in the city.\nInternational schools:\n\nMalabo has preserved buildings from the colonial era, such as the Presidential Palace and the Palace of Justice of Malabo. Other colonial buildings are also found downtown, although they are worn; for example the wooden 19th-century buildings on Nigeria and Rey Boncoro streets.\n\nNotable buildings include the Cathedral of Santa Isabel, of the Roman Catholic Archdiocese of Malabo. It is a church in the neo-Gothic style, built between 1897 and 1916. Its architect was Luis Segarra Llairadó, paid by contributions from the government of Spain and the donations of the faithful. It has two spires 40 meters high.\n\nOther points of interest are \"La Gaditana\", known as \"Finca Amilivia\" prior to 1918, the casa Teodolita, built in 1902 and one of the oldest homes in the city, the City Hall building in Malabo, the Church of Elá Nguema, Independence Square, the Casa de España and the bay of the harbor.\n\nThe system of public transport of the capital includes service of buses to make the journey between downtown of Malabo and the neighborhood of Ela Nguema of taxis circulating the city and outlying areas, and car hire called Avis and Europcar.\nThe port of Malabo can theoretically reach a treatment capacity of 200,000 tons/year. The main maritime links are with national destination to Bata and international to Spain and Douala in Cameroon.\n\nThe Malabo International Airport serves the city. It is located 7 km from the center in . It serves long-distance direct flights to Europe and some African capitals. Iberia, Air France and Lufthansa all operate there. Most air traffic links to Bata, Douala (Cameroon), Cotonou (Benin) and Libreville (Gabon) via local airlines Camair-Co, Air Gabon and Ecuato Guineana (EGA).\n\nThe main sports facility of Malabo, and the country, is the Nuevo Estadio de Malabo, with a capacity of 15,250 spectators. The stadium is home to the Equatorial Guinea national football team and hosted matches during the 2012 Africa Cup of Nations. Notably, the Spain national football team, at the time World Champions, played a friendly at this stadium. Currently the stadium also is home to the Sony Elá Nguema, the main club of the country. Also located in Malabo is the Estadio Internacional. The Estadio Internacional has a 6,000 seat capacity. The Equatorial Guinea national football team played here until the Nuevo Estadio was opened.\nThe 2012 Africa Cup of Nations was organized jointly by Gabon and Equatorial Guinea. One of the four venues for the tournament was the Nuevo Estadio de Malabo, the main stadium of the country, constructed in 2007. In Malabo were disputed six matches of the group stage (one match of Group A and five of group B), and one cross of quarterfinals\n\nThe 16 November 2013, the Spain national football team played a friendly match against the Equatorial Guinea national football team. It was the first visit of a European team in the country, and the match was criticized by several organizations, including the president of the LFP Javier Tebas, due to the political situation of the country and the government of Teodoro Obiang.\n\nSome of the top clubs in the country, who have won several times the Primera División de Guinea Ecuatorial are from the city of Malabo. The club with the most league titles is the Sony Elá Nguema with 14. Other clubs from the city that have been proclaimed league champions are the Renacimiento Fútbol Club, the Atlético Malabo or Cafe Bank Sportif. Another club of the city is the Atlético Semu, once champion of Equatoguinean Cup.\n\nAnother important club from the city is the Malabo Kings of basketball, which was champion of the country, and in 2013 was proclaimed champion Central Zone of Africa Basketball Championship, winning in Kinshasa at Talia from Gabon. The Malabo Kings had already finished second in 2011, Yaounde (Cameroon). In 2013 held in Malabo on I Campus of Basketball Ciudad de Malabo organized by the Equatorial Guinea Basketball Federation and Club de Baloncesto Conejero from Spain.\n\nMalobo was originally to host the 2019 African Games but due to economic problems they decide to withdraw its hosting rights and was replaced by Casablanca, Morocco.\n\nMalabo has been significantly affected by Teodoro Obiang Nguema Mbasogo's growing co-operation with the oil industry. The country's production has reached , an increase which led to a doubling of the city's population, but for the vast majority, very little of that wealth has been invested in development.\n\n\n"}
{"id": "10663670", "url": "https://en.wikipedia.org/wiki?curid=10663670", "title": "Martin Luther King Jr. Shoreline", "text": "Martin Luther King Jr. Shoreline\n\nMartin Luther King Jr. Shoreline is a regional park located on the shores of the San Leandro Bay in Oakland, California. Part of the East Bay Regional Parks system, it is named after Civil Rights Movement leader Martin Luther King Jr. The park was established in 1993 on a tract of land leased from the Oakland Airport.\n\n\n"}
{"id": "19623249", "url": "https://en.wikipedia.org/wiki?curid=19623249", "title": "Maruyama Dam", "text": "Maruyama Dam\n\nThe is a dam on the border of Mitake and Yaotsu in Gifu Prefecture, Japan. It was built on the upper reaches of the Kiso River system. It is a gravity dam that is tall. It was built after World War II as part of a large, nationwide dam building project.\n\nSosui Gorge (蘇水峡 \"Sosui-kyō\") was formed by the completion of the dam. Along with Ena Gorge further upstream, the area is part of the Hida-Kisogawa Quasi-National Park.\n"}
{"id": "39264291", "url": "https://en.wikipedia.org/wiki?curid=39264291", "title": "Michael Mobbs", "text": "Michael Mobbs\n\nMichael Mobbs is a Sydney-based author and environmental consultant. He graduated from the Australian National University with a Bachelor of Laws in 1975 and then worked as an environmental lawyer for 19 years. Through this work he developed an interest in sustainability. Mobbs served as an Independent Alderman on the City of Sydney Council from 1985–1987. In the 1990s Mobbs converted his Chippendale home into a more sustainable house by modifying the water, energy and waste systems. He regularly opens his house for guided public tours.\n\nIn 2009, \"The (Sydney) Magazine\" listed Michael Mobbs as one of Sydney's 100 most influential people. He has an ongoing role in the urban food growing movement in Sydney and has been a contributor to the Chippendale verge gardens.\n\n\n"}
{"id": "52163569", "url": "https://en.wikipedia.org/wiki?curid=52163569", "title": "Molybdenum carbide", "text": "Molybdenum carbide\n\nMolybdenum carbide (MoC and MoC) is an extremely hard refractory ceramic material, commercially used in tool bits for cutting tools.\n"}
{"id": "1118317", "url": "https://en.wikipedia.org/wiki?curid=1118317", "title": "Motor–generator", "text": "Motor–generator\n\nA motor–generator (an M–G set) is a device for converting electrical power to another form. Motor–generator sets are used to convert frequency, voltage, or phase of power. They may also be used to isolate electrical loads from the electrical power supply line. Large motor–generators were widely used to convert industrial amounts of power while smaller motor–generators (such as the one shown in the picture) were used to convert battery power to higher DC voltages.\n\nWhile a motor–generator set may consist of distinct motor and generator machines coupled together, a single unit dynamotor (for dynamo–motor) has the motor coils and the generator coils wound around a single rotor; both the motor and generator therefore share the same outer field coils or magnets. Typically the motor coils are driven from a commutator on one end of the shaft, while the generator coils provide output to another commutator on the other end of the shaft. The entire rotor and shaft assembly is smaller, lighter, and cheaper than a pair of machines, and does not require exposed drive shafts.\n\nLow-powered consumer devices such as vacuum tube vehicle radio receivers did not use expensive, noisy and bulky motor–generators. Instead, they used an inverter circuit consisting of a vibrator (a self-exciting relay) and a transformer to produce the higher voltages required for the vacuum tubes from the vehicle's 6 or 12V battery.\n\nIn the context of electric power generation and large fixed electrical power systems, a motor–generator consists of an electric motor mechanically coupled to an electric generator (or alternator). The motor runs on the electrical input current while the generator creates the electrical output current, with power flowing between the two machines as a mechanical torque; this provides electrical isolation and some buffering of the power between the two electrical systems.\n\nOne use is motor–generator is to eliminate spikes and variations in \"dirty power\" (power conditioning) or to provide phase matching between different electrical systems.\n\nAnother use is to buffer extreme loads on the power system. For example, tokamak fusion devices impose very large peak loads, but relatively low average loads, on the electrical grid. The DIII-D tokamak at General Atomics, the Princeton Large Torus (PLT) at the Princeton Plasma Physics Laboratory, and the Nimrod synchrotron at the Rutherford Appleton Laboratory each used large flywheels on multiple motor–generator rigs to level the load imposed on the electrical system: the motor side slowly accelerated a large flywheel to store energy, which was consumed rapidly during a fusion experiment as the generator side acted as a brake on the flywheel. Similarly, the next generation U.S. Navy aircraft carrier Electromagnetic Aircraft Launch System (EMALS) will use a flywheel motor–generator rig to supply power instantaneously for aircraft launches at greater than the ship's installed generator capacity.\n\nMotor–generators may be used for various conversions including:\n\nBefore solid state AC voltage regulation was available or cost effective, motor generator sets were used to provide a variable AC voltage. The DC voltage to the generators armature would be varied manually or electronically to control the output voltage. When used in this fashion, the MG set is equivalent to an isolated variable transformer.\n\nAn Alexanderson alternator is a motor-driven, high-frequency alternator which provides radio frequency power. In the early days of radio communication, the high frequency carrier wave had to be produced mechanically using an Alternator with many poles driven at high speeds. The Alexanderson alternator produced upward of 100 kHz with power outputs upward of 200 kW. While electromechanical converters were regularly used for long wave transmissions in the first three decades of the 20th century, electronic techniques were required at higher frequencies. The Alexanderson alternator was largely replaced by the vacuum tube oscillator in the 1920s.\n\nMotor–generators have even been used where the input and output currents are essentially the same. In this case, the mechanical inertia of the M–G set is used to filter out transients in the input power. The output's electric current can be very clean (noise free) and will be able to \"ride-through\" brief blackouts and switching transients at the input to the M–G set. This may enable, for example, the flawless cut-over from mains power to AC power provided by a diesel generator set.\n\nThe motor–generator set may contain a large flywheel to improve its ride-through; however, consideration must be taken in this application as the motor–generator will require a large amount of current on re-closure, if prior to the pull-out torque is achieved, resulting in a shut down. The in-rush current during re-closure will depend on many factors, however. As an example, a 250 kVA motor generator operating at 300 ampere of full load current will require 1550 ampere of in-rush current during a re-closure after 5 seconds. This example used a fixed mounted flywheel sized to result in a 1/2 Hz per second slew rate. The motor–generator was a vertical type two-bearing machine with oil-bath bearings.\n\nMotors and generators may be coupled by a non-conductive shaft in facilities that need to closely control electromagnetic radiation, or where high isolation from transient surge voltages is required.\n\nMotor–generator sets have been replaced by semiconductor devices for some purposes. In the past, a popular use for MG sets were in elevators. Since accurate speed control of the hoisting machine was required, the impracticality of varying the frequency to a high power AC motor meant that the use of an MG set with a DC hoist motor was a near industry-standard solution. Modern AC variable-frequency drives and compatible motors have increasingly supplanted traditional MG-driven elevator installations, since AC drives are typically more efficient by 50% or more than DC-powered machinery.\n\nAnother use for MG sets was on the southern region of British Rail. They were used to convert the 600 VDC - 850 VDC line supply voltage from the third rail into 70 VDC to power the controls of the EMU stock in use. These have since been replaced with solid state converters on new rolling stock.\n\nOn the other hand, in industrial settings where harmonic cancellation, frequency conversion, or line isolation is needed, MG sets remain a popular solution. A useful feature of the motor–generator is that they can handle large short-term overloads better than semiconductor devices of the same average load rating. Consider that the thermally current-limited components of a large semiconductor inverter are solid-state switches massing a few grams with a thermal time constant to their heat sinks of likely more than 100 ms, whereas the thermally current limited components of an MG are copper windings massing some hundreds of kilos which are intrinsically attached to their own large thermal mass. They also have inherently excellent resistance to electrostatic discharge (ESD).\n\nIn the context of hybrid vehicles and other lightweight power systems, the term \"motor–generator\" can be used to describe a single power transducer that can be used as either an electric motor or a generator, converting between electrical power and mechanical power. In principle, any electrical generator can also serve as an electric motor, or vice versa. The literature distributed by Toyota to describe the Hybrid Synergy Drive is an example of this newer usage.\n\nFrom the 2014 season, Formula 1 racing cars will have what are described as 2 motor-generator units (MGU), single units which can act as \"either\" a generator or a motor. This makes the cars more fuel-efficient by harvesting energy from the turbocharger and under braking. They can be used to provide an additional 160 BHP to the wheels to aid acceleration and overtaking, or can be used to spin the turbo to increase boost pressure faster, thereby reducing turbo lag.\n"}
{"id": "18673517", "url": "https://en.wikipedia.org/wiki?curid=18673517", "title": "Mount Cass Wind Farm", "text": "Mount Cass Wind Farm\n\nThe Mount Cass Wind Farm is a proposed wind farm to be located east of Waipara on Mount Cass in the Canterbury region of New Zealand. It will comprise up to 70 wind turbines along 7 km of a ridge on Mount Cass.\n\n\n\n"}
{"id": "27387883", "url": "https://en.wikipedia.org/wiki?curid=27387883", "title": "Nitrile anion", "text": "Nitrile anion\n\nNitrile anions are nitriles lacking a proton at the position α to the nitrile group. They undergo nucleophilic addition and substitution reactions with various electrophiles.\n\nAlthough nitrile anions are functionally similar to enolates, the extra multiple bond in nitrile anions provides them with a unique ketene-like geometry. Additionally, deprotonated cyanohydrins can act as masked acyl anions, giving products impossible to access with enolates alone. The mechanisms of nitrile addition and substitution are well understood; however, strongly basic conditions are usually required, limiting the reaction's synthetic usefulness.\n\nNitrile anions are most often generated through the action of an appropriate base. However, the p\"K\"s of nitriles span a wide range—at least 20 p\"K\" units. Thus, the proper choice of base is usually substrate dependent. Acetonitriles containing an extra stabilizing electron-withdrawing group (such as an aromatic ring) can usually be deprotonated using hydroxide or alkoxide bases. Unstabilized nitriles, on the other hand, usually require either alkali metal amide bases (such as NaNH) or metal alkyls (such as butyllithium) for effective deprotonation. In the latter case, competitive addition of the alkyl group to the nitrile takes place.\n\nIR spectroscopy studies have demonstrated the existence of at least two tautomeric forms of the nitrile anion (see above).\n\nPolyanions of nitriles can also be generated by multiple deprotonations, and these species produce polyalkylated products in the presence of alkyl electrophiles.\n\nAlternative methods to produce nitrile anions include conjugate addition to α,β-unsaturated nitriles, reduction, and transmetallation.\n\nThe mechanisms of reactions involving nitrile anions depend primarily on the nature of the electrophile involved. Simple alkylations take place by S2 displacement and are subject to the usual stereoelectronic requirements of the process. Phase-transfer catalysis has been employed in alkylations of arylacetonitriles. Nitrile anions can also be involved in Michael-type additions to activated double bonds and vinylation reactions with a limited number of polarized, unhindered acetylene derivatives.\n\nArylation of nitrile anions is also possible, and can take place through different mechanisms depending on the substrates and reaction conditions. Aryl halides lacking electron-withdrawing groups react through an addition-elimination mechanism involving benzyne intermediates. Aryl phosphates and ammoniums react through the S1 pathway, which involves the generation of an aryl radical anion, fragmentation, and bond formation with a nucleophile. Electron transfer to a second molecule of arene carries on the radical chain.\n\nElectron-poor aromatic compounds undergo nucleophilic aromatic substitution in the presence of nitrile anions.\n\nThe primary difficulty for alkylation reactions employing nitrile anions is over-alkylation. In the alkylation of acetonitrile, for instance, yields of monoalkylated product are low in most cases. Two exceptions are alkylations with epoxides (the nearby negative charge of the opened epoxide wards off further alkylation) and alkylations with cyanomethylcopper(I) species. Side reactions may also present a problem; concentrations of the nitrile anion must be high in order to mitigate processes involving self-condensation, such as the Thorpe–Ziegler reaction. Other important side reactions include elimination of the alkyl cyanide product or alkyl halide starting material and amidine formation.\n\nThe cyclization of ω-epoxy-1-nitriles provides an interesting example of how stereoelectronic factors may override steric factors in intramolecular substitution reactions. In the cyclization of 1, for instance, only the cyclopropane isomer 2 is observed. This is attributed to better orbital overlap in the S2 transition state for cyclization. 1,1-disubstituted and tetrasubstituted epoxides also follow this principle.\nConjugated nitriles containing γ hydrogens may be deprotonated at the γ position to give resonance-stabilized anions. These intermediates almost always react with α selectitivity in alkylation reactions, the exception to the rule being anions of \"ortho\"-tolyl nitriles.\n\nFormation of cyanohydrins from carbonyl compounds renders the former carbonyl carbon acidic. After protection of the hydroxyl group with an acyl or silyl group, cyanohydrins can function essentially as masked acyl anions. Because ester protecting groups are base labile, mild bases must be employed with ester-protected cyanohydrins. α-(Dialkylamino)nitriles can also be used in this context.\n\nExamples of arylation and acylation reactions are shown below. Although intermolecular arylations using nitrile anions result in modest yields, the \"intramolecular\" procedure efficiently gives four-, five-, and six-membered benzo-fused rings. Acylation can be accomplished using a wide variety of acyl electrophiles, including carbonates, chloroformates, esters, anyhdrides, and acid chlorides. In these reactions, two equivalents of base are used to drive the reaction towards acylated product—the acylated product is more acidic than the starting material.\nAlkylation of a nitrile anion followed by reductive decyanation was employed in the novel synthesis of (2)-9-dotlecen-1-yl acetate, the sex pheromone of \"Paralobesia viteana\".\nThe most common bases used to deprotonate nitriles are the alkali metal amides, substituted amides, and hydrides. These reagents require inert, anhydrous conditions and careful handling. Polyalkylation is a significant problem for primary or secondary nitriles; however, a number of solutions to this problem exist. Alkylation of cyanoacetates followed by decarboxylation provides one solution. Acylation of primary or secondary nitriles provides a convenient entry to the starting materials for this sequence. Distillation and chromatography are only practical for the separation of mono- and di-alkylated material when the molecular weight difference between the two is large.\n\nAcylation is much more straightforward, as the resulting α-cyanocarbonyl compounds are much more acidic (and less nucleophilic) than corresponding starting materials. Monoacylated products can be obtained easily.\n\nTo a suspension of 24.4 g (1.017 mol) of sodium hydride in 200 mL of anhydrous toluene was added a mixture of 122 g (1.043 mol) of phenylacetonitrile and 150 g (1.095 mol) of isobutyl bromide. The mixture was heated at 65 °C, at which temperature the reaction commenced. The heating mantle was removed, and the flask was cooled in order to keep the reaction from becoming too vigorous during the initial 0.5-hour reaction period. The reaction mixture was refluxed for an additional 5 hours and permitted to stand overnight. Ethanol (40 mL) was cautiously added dropwise, followed by the dropwise addition of 200 mL of water. The organic layer was separated, and the aqueous layer was extracted with benzene. The combined organic layers were washed successively with dilute acid, water, sodium carbonate solution, and water. After filtration through a layer of sodium sulfate, the benzene was evaporated and the product was fractionally distilled to afford 115 g (66%) of 2-phenyl-4-methylvaleronitrile, bp 130–134 °C (10 mm) [lit. (540) bp 136–138 °C (15 mm)].\n"}
{"id": "870889", "url": "https://en.wikipedia.org/wiki?curid=870889", "title": "Plasma globe", "text": "Plasma globe\n\nA plasma globe or plasma lamp (also called plasma ball, dome, sphere, tube or orb, depending on shape) is a clear glass container filled with a mixture of various noble gases with a high-voltage electrode in the center of the container.\n\nWhen voltage is applied, a plasma is formed within the container. Plasma filaments extend from the inner electrode to the outer glass insulator, giving the appearance of multiple constant beams of colored light (see corona discharge and electric glow discharge). Plasma globes were most popular as novelty items in the 1980s.\n\nThe plasma lamp was invented by Nikola Tesla, during his experimentation with high-frequency currents in an evacuated glass tube for the purpose of studying high voltage phenomena. Tesla called his invention an \"inert gas discharge tube\". The modern plasma lamp design was subsequently developed by Bill Parker, a student at MIT.\n\nAlthough many variations exist, a plasma lamp is usually a clear glass sphere filled with a mixture of various gases (most commonly neon, sometimes with other noble gases such as argon, xenon and krypton) at nearly atmospheric pressure. They are driven by high-frequency (approximately ) alternating current at . The drive circuit is essentially a specialized power inverter, in which current from a lower-voltage DC supply powers a high-frequency electronic oscillator circuit whose output is stepped up by a high-frequency, high-voltage transformer. The radio-frequency energy from the transformer is transmitted into the gas within the globe through an electrode at its center. A much smaller hollow glass orb can also serve as an electrode when it is filled with metal wool or a conducting fluid that is in communication with the transformer output. In this case, the radio-frequency energy is admitted into the larger space by capacitive coupling right through the glass. Plasma filaments extend from the inner electrode to the outer glass insulator, giving the appearance of moving tendrils of colored light within the volume of the globe (see corona discharge and electric glow discharge).\n\nSome globes have a control knob that varies the amount of power going to the center electrode. At the very lowest setting that will light or \"strike\" the globe, a single tendril is made. This single tendril's plasma channel engages enough space to transmit this lowest striking energy to the outside world through the glass of the globe. As the power is increased, this single channel's capacity is overwhelmed and a second channel forms, then a third, and so on. The tendrils each compete for a footprint on the inner orb as well. The energies flowing through these are all of the same polarity so they repel each other as like charges: a thin dark boundary surrounds each footprint on the inner electrode.\n\nPlacing a finger tip on the glass creates an attractive spot for the energy to flow, because the conductive human body (having non-ohmic resistance of about 1000 ohms at room temperature) is more easily polarized than the dielectric material around the electrode (i.e. the gas within the globe) providing an alternative discharge path having less resistance. Therefore, the capacity of the large conducting body to accept radio frequency energy is greater than that of the surrounding air. The energy available to the filaments of plasma within the globe will preferentially flow toward the better acceptor. This flow also causes a single filament, from the inner ball to the point of contact, to become brighter and thinner. The filament is brighter because there is more current flowing through it and into the 150 pF capacity, or capacitance, presented by an object, a conducting body, the size of a human. The filament is thinner because the magnetic fields around it, augmented by the now-higher current flowing through it, causes a magnetohydrodynamic effect called self-focusing: the plasma channel's own magnetic fields create a force acting to compress the size of the plasma channel itself.\nMuch of the movement of the filaments is due to heating of the gas around the filament. When gas along the filament is heated, it becomes more buoyant and rises, carrying the filament with it. If the filament is discharging into a fixed object (like a hand) on the side of the globe, it will begin to deform into a curved path between the central electrode and the object. When the distance between the electrode and the object becomes too great to maintain, the filament will break and a new filament will reform between the electrode and the hand. (See also Jacob's Ladder, which exhibits a similar behavior.)\n\nAn electric current is produced within any conductive object near the orb. The glass acts as a dielectric in a capacitor formed between the ionized gas and the hand.\n\nThe globe is prepared by pumping out as much air as is practical. The globe is then back-filled with neon to a pressure similar to one atmosphere. If the radio-frequency power is turned on, if the globe is \"struck\" or \"lit\", now, the whole globe will glow a diffuse red. If a little argon is added, the filaments will form. If a very small amount of xenon is added, the \"flowers\" will bloom at the ends of the filaments.\n\nThe neon available for purchase for a neon-sign shop often comes in glass flasks at the pressure of a partial vacuum. These cannot be used to fill a globe with a useful mixture. Tanks of gas, each with its specific, proper, pressure regulator and fitting, are required: one for each of the gases involved.\n\nOf the other noble gases, radon is radioactive, helium escapes through the glass relatively quickly, and krypton is quite expensive. Other gases can be used, such as mercury vapor. Molecular gases may be dissociated by the plasma.\n\nIn (\"Incandescent Electric Light\", 1894 February 6), Nikola Tesla describes a plasma lamp. This patent is for one of the first high-intensity discharge lamps. Tesla used an incandescent-type lamp globe with a single internal conductive element and excited the element with high voltage currents from a Tesla coil, thus creating the brush discharge emanation. He gained patent protection on a particular form of the lamp in which a light-giving small body or button of refractory material is supported by a conductor entering a very highly exhausted globe or receiver. Tesla called this invention the single terminal lamp, or, later, the \"Inert Gas Discharge Tube\".\n\nThe Groundstar style of plasma globe was created by James Falk and marketed to collectors and science museums in the 1970s and 1980s. Jerry Pournelle in 1984 praised Orb Corporation's Omnisphere as \"the most fabulous object in the entire world\" and \"magnificent ... a new kind of art object\", stating \"you can't buy mine for any price\". \n\nThe technology needed to formulate gas mixtures used in today's plasma spheres was not available to Tesla. Modern lamps typically use combinations of xenon, krypton and neon, although other gases can be used as well. These gas mixtures, along with different glass shapes and integrated-circuit-driven electronics, create the vivid colors, range of motions and complex patterns seen in today's plasma spheres.\n\nPlasma globes are mainly used as curiosities or toys for their unique lighting effects and the \"tricks\" that can be performed on them by users moving their hands around them. They might also form part of a school's laboratory equipment for demonstration purposes. They are not usually employed for general lighting. However, as of recent years, some novelty stores have begun selling a miniature plasma lamp nightlight that can be mounted on a standard light socket.\n\nPlasma globes can be used for experimenting with high voltages. If a conductive plate or wire coil is placed on the globe, capacitive coupling can transfer enough voltage to the plate or coil to produce a small arc or energize a high voltage load. This is possible because the plasma inside the globe and the conductor outside it act as plates of a capacitor, with the glass in between as a dielectric. A step-down transformer connected between the plate and the globe's electrode can produce lower-voltage, higher-current radio frequency output. Careful earth grounding is essential to prevent injury or damage to equipment.\n\nBringing conductive materials or electronic devices close to a plasma globe may cause the glass to become hot. The high voltage radio frequency energy coupled to them from within the globe may cause a mild electric shock to the person touching, even through a protective plastic casing. The radio frequency field produced by plasma lamps can interfere with the operation of touch-pads used on laptop computers, digital audio players, cell phones, and other similar devices. Some types of plasma globes can radiate sufficient radio frequency interference (RFI) to interfere with cordless telephones and Wi-Fi devices several feet or some meters away.\n\nIf an electrical conductor touches the outside of the globe, capacitive coupling can induce enough potential on it to produce a small arc. This is possible because the globe's glass acts as a capacitor dielectric: the inside of the lamp acts as one plate, and the conductive object on the outside acts as the opposite capacitor plate. This is a dangerous action which can damage the globe or other electronic devices, and presents a fire ignition hazard.\n\n"}
{"id": "7645050", "url": "https://en.wikipedia.org/wiki?curid=7645050", "title": "Plasma speaker", "text": "Plasma speaker\n\nPlasma speakers or ionophones are a form of loudspeaker which varies air pressure via a high-energy electrical plasma instead of a solid diaphragm. Connected to the output of an audio amplifier, plasma speakers vary the size of a plasma glow discharge, corona discharge or electric arc which then acts as a massless radiating element, creating the compression waves in air that listeners perceive as sound. The technique is an evolution of William Duddell's \"singing arc\" of 1900, and an innovation related to ion thruster spacecraft propulsion.\n\nThe term ionophone can also be used to describe a transducer for converting acoustic vibrations in plasma into an electrical signal.\n\nThe effect takes advantage of two unique principles: Firstly, ionization of gases causes their electrical resistance to drop significantly, making them extremely efficient conductors, which allows them to vibrate sympathetically with magnetic fields. \nSecondly, the involved plasma, itself a field of ions, has a relatively negligible mass. Thus as current frequency varies, more-resistant air remains mechanically coupled with and is driven by vibration of the more conductive and essentially massless plasma, radiating a potentially ideal reproduction of the sound source.\n\n\"Conventional\" loudspeaker transducer designs use input electrical frequencies to vibrate a significant mass: This driver is coupled to a stiff speaker cone — a diaphragm which pushes air at respective frequencies. But the inertia inherent in its mass resists acceleration — and all changes in cone position. Additionally, speaker cones will eventually suffer tensile fatigue from the repeated shaking of sonic vibration.\n\nThus conventional speaker output, or the fidelity of the device, is distorted by physical limitations inherent in its design. These distortions have long been the limiting factor in commercial reproduction of strong high frequencies. To a lesser extent square wave characteristics are also problematic; the reproduction of square waves most stress a speaker cone.\n\nIn a plasma speaker, as member of the family of massless speakers, these limitations do not exist. The low-inertia driver has exceptional transient response compared to other designs. The result is an even, linear output, accurate even at extreme frequencies beyond any audible range. Such speakers are notable for accuracy and clarity, but not tremendous power because plasmas composed of tiny particles are unable to move large volumes of air. So these designs are more effective as tweeters.\n\nEarly plasma-speaker designs ionized ambient air containing the gases nitrogen and oxygen. In an intense electrical field these gases can produce reactive by-products, and in closed rooms these can reach a hazardous level.\n\nPlasmatronics produced a commercial plasma speaker that used a helium tank to provide the ionization gas. In 1978 Alan E. Hill of the Air Force Weapons Laboratory in Albuquerque, NM, designed the \"Plasmatronics Hill Type I\", a commercial helium-plasma tweeter. This avoided the ozone and nitrogen oxides produced by radio frequency decomposition of air in an earlier generation of plasma tweeters. Theirs is also the only design relying on the quieter glow discharge mode instead of the more common arc and corona discharges. But the operation of such speakers requires a continuous supply of helium.\n\nIn the 1950s, the pioneering DuKane Corporation produced the air-ionizing \"Ionovac\", marketed in the UK as the \"Ionophone\". Currently there remain manufacturers in Germany who use this design, as well as a do-it-yourself design available on the Internet.\n\nTo make the plasma speaker a more widely available product, ExcelPhysics, a Seattle-based company, and Images Scientific Instruments, a New York-based company, both offered their own variant of the plasma speaker as a DIY kit. The ExcelPhysics variant uses a flyback transformer to step up voltage, a 555 timing chip to provide modulation and a 44 kHz carrier signal, and an audio amplifier.\n\nA flame speaker uses a flame for the driver. Some designs dating to the 1950s use combustion of natural gas or candles to produce a plasma through which current is then passed. These combustion designs do not require high voltages to generate a plasma field.\n\nA similar effect is occasionally observed in the vicinity of high-power amplitude-modulated radio transmitters when a corona discharge (inadvertently) occurs from the transmitting antenna, where voltages in the tens of thousands are involved. The ionized air is heated in direct relationship to the modulating signal with surprisingly high fidelity over a wide area. Due to the destructive effects of the (self-sustaining) discharge this cannot be permitted to persist, and automatic systems momentarily shut down transmission within a few seconds to quench the \"flame\".\n\nDespite offering an aspect of ideal sound-reproduction, plasma speaker designs tend not to be used in practical musical systems nor any performing instruments. Due to investment costs, limits in frequency range, and the many practical considerations in safely maintaining any air-coupled plasma, they remain experiments and curiosities.\n\n\n"}
{"id": "31006486", "url": "https://en.wikipedia.org/wiki?curid=31006486", "title": "Renewable Identification Number", "text": "Renewable Identification Number\n\nA Renewable Identification Number (or RIN) is a serial number assigned to a batch of biofuel for the purpose of tracking its production, use, and trading as required by the United States Environmental Protection Agency's Renewable Fuel Standard (RFS) implemented according to the Energy Policy Act of 2005 and the Energy Independence and Security Act of 2007.\n\nAs defined in the regulation:\nUnder RFS2, each batch-RIN generated will continue to uniquely identify not only a specific batch of renewable fuel, but also every gallon-RIN assigned to that batch. Thus the RIN will continue to be defined as follows:\n\nRIN: KYYYYCCCCFFFFFBBBBBRRDSSSSSSSSEEEEEEEE\n\nWhere:\n\nUnder the Energy Policy Act of 2005, the EPA is authorized to set annual quotas dictating what percentage of the total amount of motor fuels consumed in the US must be represented by biofuel blended into fossil fuels. Companies that refine, import or blend fossil fuels are obligated to meet certain individual RFS quotas based on the volume of fuel they introduce into the market. By fulfilling these requirements, the EPA projects that the industry will collectively satisfy the overall national quota they set. To ensure compliance, obligated parties are periodically required to demonstrate they have met their RFS quota by submitting a certain amount of RINs to the EPA. Because each of these RINs represent an amount of biofuel that has been blended into fossil fuels, the RINs submitted to the EPA by obligated parties are a quantitative representation of the amount of biofuel that has been blended into the fossil fuels used in America.\n\nAnyone who owns RINs must register with the EPA on an annual basis and obey mandated record-keeping requirements. RINs are only granted if the registered fuel was made in accordance with EISA rules. These regulations are enforced against both domestic and foreign producers. All RINs are reported to the EPA after creation.\n\nRenewable Identification Numbers can be sold and traded separately from the biofuels that created them. This has given rise to instances of \"RIN fraud\", where improperly created RINs have been sold without any manufacture of corresponding biofuels.\n\n"}
{"id": "43710", "url": "https://en.wikipedia.org/wiki?curid=43710", "title": "Silicon dioxide", "text": "Silicon dioxide\n\nSilicon dioxide, also known as silica, silicic acid or silicic acid anydride is an oxide of silicon with the chemical formula , most commonly found in nature as quartz and in various living organisms. In many parts of the world, silica is the major constituent of sand. Silica is one of the most complex and most abundant families of materials, existing as a compound of several minerals and as synthetic product. Notable examples include fused quartz, fumed silica, silica gel, and aerogels. It is used in structural materials, microelectronics (as an electrical insulator), and as components in the food and pharmaceutical industries.\n\nInhaling finely divided crystalline silica is toxic and can lead to severe inflammation of the lung tissue, silicosis, bronchitis, lung cancer, and systemic autoimmune diseases, such as lupus and rheumatoid arthritis.\n\nUptake of amorphous silicon dioxide, in high doses, leads to non-permanent short-term inflammation, where all effects heal.\n\nIn the majority of silicates, the silicon atom shows tetrahedral coordination, with four oxygen atoms surrounding a central Si atom. The most common example is seen in the quartz polymorphs.\n\nFor example, in the unit cell of α-quartz, the central tetrahedron shares all four of its corner O atoms, the two face-centered tetrahedra share two of their corner O atoms, and the four edge-centered tetrahedra share just one of their O atoms with other SiO tetrahedra. This leaves a net average of 12 out of 24 total vertices for that portion of the seven SiO tetrahedra that are considered to be a part of the unit cell for silica (see 3-D Unit Cell).\n\nSiO has a number of distinct crystalline forms (polymorphs) in addition to amorphous forms. With the exception of stishovite and fibrous silica, all of the crystalline forms involve tetrahedral SiO units linked together by shared vertices in different arrangements. Silicon–oxygen bond lengths vary between the different crystal forms; for example in α-quartz the bond length is 161 pm, whereas in α-tridymite it is in the range 154–171 pm. The Si-O-Si angle also varies between a low value of 140° in α-tridymite, up to 180° in β-tridymite. In α-quartz, the Si-O-Si angle is 144°.\n\nFibrous silica has a structure similar to that of SiS with chains of edge-sharing SiO tetrahedra. Stishovite, the higher-pressure form, in contrast, has a rutile-like structure where silicon is 6-coordinate. The density of stishovite is 4.287 g/cm, which compares to α-quartz, the densest of the low-pressure forms, which has a density of 2.648 g/cm. The difference in density can be ascribed to the increase in coordination as the six shortest Si-O bond lengths in stishovite (four Si-O bond lengths of 176 pm and two others of 181 pm) are greater than the Si-O bond length (161 pm) in α-quartz.\nThe change in the coordination increases the ionicity of the Si-O bond. More importantly, any deviations from these standard parameters constitute microstructural differences or variations, which represent an approach to an amorphous, vitreous, or glassy solid.\n\nThe only stable form under normal conditions is alpha quartz, in which crystalline silicon dioxide is usually encountered. In nature, impurities in crystalline α-quartz can give rise to colors (see list). The high-temperature minerals, cristobalite and tridymite, have both lower densities and indices of refraction than quartz. Since the composition is identical, the reason for the discrepancies must be in the increased spacing in the high-temperature minerals. As is common with many substances, the higher the temperature, the farther apart the atoms are, due to the increased vibration energy.\n\nThe transformation from α-quartz to beta-quartz takes place abruptly at 573 °C. Since the transformation is accompanied by a significant change in volume, it can easily induce fracturing of ceramics or rocks passing through this temperature limit.\n\nThe high-pressure minerals, seifertite, stishovite, and coesite, though, have higher densities and indices of refraction than quartz. This is probably due to the intense compression of the atoms occurring during their formation, resulting in more condensed structure.\n\nFaujasite silica is another form of crystalline silica. It is obtained by dealumination of a low-sodium, ultra-stable Y zeolite with combined acid and thermal treatment. The resulting product contains over 99% silica, and has high crystallinity and surface area (over 800 m/g). Faujasite-silica has very high thermal and acid stability. For example, it maintains a high degree of long-range molecular order or crystallinity even after boiling in concentrated hydrochloric acid.\n\nMolten silica exhibits several peculiar physical characteristics that are similar to those observed in liquid water: negative temperature expansion, density maximum at temperatures ~5000 °C, and a heat capacity minimum. Its density decreases from 2.08 g/cm at 1950 °C to 2.03 g/cm at 2200 °C.\n\nMolecular SiO with a linear structure is produced when molecular silicon monoxide, SiO, is condensed in an argon matrix cooled with helium along with oxygen atoms generated by microwave discharge. \nDimeric silicon dioxide, (SiO) has been prepared by reacting O with matrix isolated dimeric silicon monoxide, (SiO). In dimeric silicon dioxide there are two oxygen atoms bridging between the silicon atoms with an Si-O-Si angle of 94° and bond length of 164.6 pm and the terminal Si-O bond length is 150.2 pm. The Si-O bond length is 148.3 pm, which compares with the length of 161 pm in α-quartz. The bond energy is estimated at 621.7 kJ/mol.\n\nSilica with the chemical formula is most commonly found in nature as quartz, which comprises more than 10% by mass of the earth's crust. Quartz is the only polymorph of silica stable at the Earth's surface. Metastable occurrences of the high-pressure forms coesite and stishovite have been found around impact structures and associated with eclogites formed during ultra-high-pressure metamorphism. The high-temperature forms of tridymite and cristobalite are known from silica-rich volcanic rocks. In many parts of the world, silica is the major constituent of sand.\n\nEven though it is poorly soluble, silica occurs in many plants. Plant materials with high silica phytolith content appear to be of importance to grazing animals, from chewing insects to ungulates. Silica accelerates tooth wear, and high levels of silica in plants frequently eaten by herbivores may have developed as a defense mechanism against predation.\n\nSilica is also the primary component of rice husk ash, which is used, for example, in filtration and cement manufacturing.\n\nFor well over a billion years, silicification in and by cells has been common in the biological world. In the modern world it occurs in bacteria, single-celled organisms, plants, and animals (invertebrates and vertebrates).\nProminent examples include:\n\nCrystalline minerals formed in the physiological environment often show exceptional physical properties (e.g., strength, hardness, fracture toughness) and tend to form hierarchical structures that exhibit microstructural order over a range of scales. The minerals are crystallized from an environment that is undersaturated with respect to silicon, and under conditions of neutral pH and low temperature (0–40 °C).\n\nFormation of the mineral may occur either within the cell wall of an organism (such as with phytoliths), or outside the cell wall, as typically happens with tests. Specific biochemical reactions exist for mineral deposition. Such reactions include those that involve lipids, proteins, and carbohydrates.\n\nIt is unclear in what ways silica is important in the nutrition of animals. This field of research is challenging because silica is ubiquitous and in most circumstances dissolves in trace quantities only. All the same it certainly does occur in the living body, leaving us with the problem that it is hard to create proper silica-free controls for purposes of research. This makes it difficult to be sure when the silica present has had operative beneficial effects, and when its presence is coincidental, or even harmful. The current consensus is that it certainly seems important in the growth, strength, and management of many connective tissues. This is true not only for hard connective tissues such as bone and tooth but possibly in the biochemistry of the subcellular enzyme-containing structures as well.\n\nAn estimated 95% of silicon dioxide produced is consumed in the construction industry, e.g. for the production of Portland cement.\n\nSilica, in the form of sand is used as the main ingredient in sand casting for the manufacture of metallic components in engineering and other applications. The high melting point of silica enables it to be used in such applications.\n\nCrystalline silica is used in hydraulic fracturing of formations which contain tight oil and shale gas.\n\nSilica is the primary ingredient in the production of most glass. The glass transition temperature of pure SiO is about 1475 K. When molten silicon dioxide SiO is rapidly cooled, it does not crystallize, but solidifies as a glass.\n\nThe structural geometry of silicon and oxygen in glass is similar to that in quartz and most other crystalline forms of silicon and oxygen with silicon surrounded by regular tetrahedra of oxygen centers. The difference between the glass and crystalline forms arises from the connectivity of the tetrahedral units: Although there is no long range periodicity in the glassy network ordering remains at length scales well beyond the SiO bond length. One example of this ordering is the preference to form rings of 6-tetrahedra.\n\nFumed silica also known as pyrogenic silica is a very fine particulate or colloidal form of silicon dioxide. It is prepared by burning SiCl in an oxygen-rich hydrogen flame to produce a \"smoke\" of SiO.\n\nThe majority of optical fibers for telecommunication are also made from silica. It is a primary raw material for many ceramics such as earthenware, stoneware, and porcelain.\n\nSilicon dioxide is used to produce elemental silicon. The process involves carbothermic reduction in an electric arc furnace:\n\nSilica is a common additive in food production, where it is used primarily as a flow agent in powdered foods, or to adsorb water in hygroscopic applications. It is used as an anti-caking agent in powdered foods such as spices and non-dairy coffee creamer. It is the primary component of diatomaceous earth. Colloidal silica is also used as a wine, beer, and juice fining agent.\n\nIn pharmaceutical products, silica aids powder flow when tablets are formed.\n\nIn cosmetics, its useful for its light-diffusing properties and natural absorbency.\n\nHydrated silica is used in toothpaste as a hard abrasive to remove tooth plaque.\n\nHydrophobic silica is used as a defoamer component.\n\nIn its capacity as a refractory, it is useful in fiber form as a high-temperature thermal protection fabric.\n\nIt is used as a thermal enhancement compound in the ground source heat pump industry.\n\nSilica is used in the extraction of DNA and RNA due to its ability to bind to the nucleic acids under the presence of chaotropes.\n\nA silica-based aerogel was used in the Stardust spacecraft to collect extraterrestrial particles.\n\nPure silica (silicon dioxide), when cooled as fused quartz into a glass with no true melting point, can be used as a glass fiber for fiberglass.\n\nSilicon dioxide is mostly obtained by mining, including sand mining and purification of quartz. \nQuartz is suitable for many purposes, while chemical processing is required to make a purer or otherwise more suitable (e.g. more reactive or fine-grained) product.\n\nSilica fume is obtained as byproduct from hot processes like ferrosilicon production. It is less pure than fumed silica and should not be confused with that product. The production process, particle characteristics and fields of application of fumed silica are all different from those of silica fume.\n\nPrecipitated silica or amorphous silica is produced by the acidification of solutions of sodium silicate. The gelatinous precipitate or silica gel, is first washed and then dehydrated to produce colorless microporous silica. The idealized equation involving a trisilicate and sulfuric acid is:\nApproximately one billion kilograms/year (1999) of silica were produced in this manner, mainly for use for polymer composites – tires and shoe soles.\n\nThin films of silica grow spontaneously on silicon wafers via thermal oxidation, producing a very shallow layer of about 1 nm or 10 Å of so-called native oxide.\nHigher temperatures and alternative environments are used to grow well-controlled layers of silicon dioxide on silicon, for example at temperatures between 600 and 1200 °C, using so-called dry or wet oxidation with O\nor HO, respectively.\n\nThe native oxide layer is beneficial in microelectronics, where it acts as electric insulator with high chemical stability. It can protect the silicon, store charge, block current, and even act as a controlled pathway to limit current flow.\n\nMany routes to silicon dioxide start with silicate esters, the best known being tetraethyl orthosilicate (TEOS). Simply heating TEOS at 680–730 °C gives the dioxide:\n\nSimilarly TEOS combusts around 400 °C:\n\nTEOS undergoes hydrolysis via the so-called sol-gel process. The course of the reaction and nature of the product are affected by catalysts, but the idealized equation is:\n\nBeing highly stable, silicon dioxide arises from many methods. Conceptually simple, but of little practical value, combustion of silane gives silicon dioxide. This reaction is analogous to the combustion of methane:\nHowever the chemical vapor deposition of silicon dioxide onto crystal surface from silane had been used using nitrogen as a carrier gas at 200-500C.\n\nSilica is converted to silicon by reduction with carbon.\n\nFluorine reacts with silicon dioxide to form SiF and O whereas the other halogen gases (Cl, Br, I) are essentially unreactive.\n\nSilicon dioxide is attacked by hydrofluoric acid (HF) to produce hexafluorosilicic acid:\nHF is used to remove or pattern silicon dioxide in the semiconductor industry.\n\nSilicon dioxide acts as a Lux–Flood acid, being able to react with bases under certain conditions. As it does not contain any hydrogen, it cannot act as a Brønsted–Lowry acid. While not soluble in water, some strong bases will react with glass and have to be stored in plastic bottles as a result.\n\nSilicon dioxide dissolves in hot concentrated alkali or fused hydroxide, as described in this idealized equation:\nSilicon dioxide will neutralise basic metal oxides (e.g. sodium oxide, potassium oxide, lead(II) oxide, zinc oxide, or mixtures of oxides, forming silicates and glasses as the Si-O-Si bonds in silica are broken successively). As an example the reaction of sodium oxide and SiO can produce sodium orthosilicate, sodium silicate, and glasses, dependent on the proportions of reactants:\n\nExamples of such glasses have commercial significance, e.g. soda-lime glass, borosilicate glass, lead glass. In these glasses, silica is termed the network former or lattice former. The reaction is also used in blast furnaces to remove sand impurities in the ore by neutralisation with calcium oxide, forming calcium silicate slag.\nSilicon dioxide reacts in heated reflux under dinitrogen with ethylene glycol and an alkali metal base to produce highly reactive, pentacoordinate silicates which provide access to a wide variety of new silicon compounds. The silicates are essentially insoluble in all polar solvent except methanol.\n\nSilicon dioxide reacts with elemental silicon at high temperatures to produce SiO:\n\nThe solubility of silicon dioxide in water strongly depends on its crystalline form and is three-four times higher for silica than quartz; as a function of temperature, it peaks around 340 °C. This property is used to grow single crystals of quartz in a hydrothermal process where natural quartz is dissolved in superheated water in a pressure vessel that is cooler at the top. Crystals of 0.5–1 kg can be grown over a period of 1–2 months. These crystals are a source of very pure quartz for use in electronic applications.\n\nSilica ingested orally is essentially nontoxic, with an of 5000 mg/kg (5 g/kg). A 2008 study following subjects for 15 years found that higher levels of silica in water appeared to decrease the risk of dementia. An increase of 10 mg/day of silica in drinking water was associated with a decreased risk of dementia of 11%.\n\nInhaling finely divided crystalline silica dust can lead to silicosis, bronchitis, or lung cancer, as the dust becomes lodged in the lungs and continuously irritates the tissue, reducing lung capacities. When fine silica particles are inhaled in large enough quantities (such as through occupational exposure), it increases the risk of systemic autoimmune diseases such as lupus and rheumatoid arthritis compared to expected rates in the general population.\n\nSilica is an occupational hazard for people who do sandblasting, or work with products that contain powdered crystalline silica. Amorphous silica, such as fumed silica, may cause irreversible lung damage in some cases, but is not associated with development of silicosis. Children, asthmatics of any age, those with allergies, and the elderly (all of whom have reduced lung capacity) can be affected in less time.\n\nCrystalline silica is an occupational hazard for those working with stone countertops, because the process of cutting and installing the countertops creates large amounts of airborne silica. Crystalline silica used in hydraulic fracturing presents a health hazard to workers.\n\nIn the body, crystalline silica particles do not dissolve over clinically relevant periods. Silica crystals inside the lungs can activate the NLRP3 inflammasome inside macrophages and dendritic cells and thereby result in production of interleukin, a highly pro-inflammatory cytokine in the immune system.\n\nRegulations restricting silica exposure 'with respect to the silicosis hazard' specify that they are concerned only with silica, which is both crystalline and dust-forming.\n\nIn 2013, the U.S. Occupational Safety and Health Administration reduced the exposure limit to 50 µg/m of air. Prior to 2013, it had allowed 100  µg/m and in construction workers even 250 µg/m.\nIn 2013, OSHA also required \"green completion\" of fracked wells to reduce exposure to crystalline silica besides restricting the limit of exposure.\n\nSiO, more so than almost any material, exists in many crystalline forms. These forms are called polymorphs.\n\n"}
{"id": "43505841", "url": "https://en.wikipedia.org/wiki?curid=43505841", "title": "Solar sharing", "text": "Solar sharing\n\nThe Solar Sharing is an innovative form of financing, based on the participation of the people. target is to develop new solar energy and at the same time, share the economic benefits among those who contributed to the realization of the projects.\nThis new model represents an advance guard for the photovoltaic industry which, however, could soon be greatly revolutionized especially in a period in which development incentives are gradually running out in the world and the traditional possibilities financing projects are reduced at both because of the decline in attractiveness of the sector, that the effects of the global economic crisis which led to a general difficulty of access to credit for businesses.\n\nThe Solar Sharing model is based on the idea of sharing.\nA group of people comes together to build a solar power plant, medium or large, and distributes construction costs within the group. When the plant begins to produce energy, the proceeds from the sale of energy are redistributed within the group, in proportion to the contribution made to the project. The application of this model reduces both initial and maintenance costs, due to economies of scale that arise compared to the creation of many small domestic installations.\n\nThe solar sharing is achieving resounding success, although it is a recent model of development.\nThis is due to its own specific characteristics that enable individuals, even ordinary citizens to become energy producers and enjoy the economic returns that flow from it. All this even in the absence of a space just where achieve a common solar home.\nFor many people it is difficult to achieve a domestic installation due to: \n\nMore and more people deem it most advantageous to purchase a share of a medium or large solar plant. This choice may in fact lead not only to cover the economic costs of domestic energy, but also to generate additional earnings.\n\nThere are several companies around the world that are contributing to the realization of solar sharing and producing clean energy for the planet. Some models involve installing solar panels at ground level, in large open spaces. Other companies install the panels on rooftops.\n\nThere are also numerous examples of cooperatives and associations that offer local financing or a few individual plants. These are actually operating in Italy, Japan, and the United States.\n\nInternational projects that are using solar sharing\n"}
{"id": "134923", "url": "https://en.wikipedia.org/wiki?curid=134923", "title": "Spearfish, South Dakota", "text": "Spearfish, South Dakota\n\nSpearfish (Lakota: \"Hočhápȟe\") is a city in Lawrence County, South Dakota, United States. The population was 10,494 at the 2010 census.\n\nBefore the Black Hills Gold Rush of 1876, the area was used by Native Americans (primarily bands of Sioux but others also ranged through the area). Once the gold rush started, the city was founded in 1876 at the mouth of Spearfish Canyon, and was originally called Queen City. Spearfish grew as a supplier of foodstuffs to the mining camps in the hills. Even today, a significant amount of truck farming and market gardening still occurs in the vicinity.\n\nIn 1887, the accepted history of gold mining in the Black Hills was thrown into question by the discovery of what has become known as the Thoen Stone. Discovered by Louis Thoen on the slopes of Lookout Mountain, the stone purports to be the last testament of Ezra Kind who, along with six others, entered the Black Hills in 1833 (at a time when whites were forbidden by law and treaty from entering the area), \"got all the gold we could carry\" in June 1834, and were subsequently \"killed by Indians beyond the high hill.\" While it may seem unlikely that someone who has \"lost my gun and nothing to eat and Indians hunting me\" would take the time to carve his story in sandstone, there is corroborating historical evidence for the Ezra Kind party.\n\nIn the 20th century, the history of Spearfish was tied very closely to mining and tourism. Architect Frank Lloyd Wright, who visited Spearfish Canyon in 1935, later called the area \"unique and unparalleled elsewhere in our country,\" and wondered, \"How is it that I've heard so little of this miracle and we, toward the Atlantic, have heard so much of the Grand Canyon when this is even more miraculous?\"\n\nThe Homestake Sawmill (previously part of Pope and Talbot, now owned by Neimen Forest Products) was built to supply timbers for the Homestake Mine in Lead (closed January 2002). In 1938, Joseph Meier brought the Luenen Passion Play to settle permanently in Spearfish and become the Black Hills Passion Play, drawing thousands of visitors every year during the summer months. After Meier's death in 2007, the amphitheater and surrounding it were put up for sale.\n\nSpearfish is located at (44.489803, −103.852585).\n\nAccording to the United States Census Bureau, the city has a total area of , of which, is land and is water.\n\nSpearfish Creek is a fast-moving creek that emerges from Spearfish Canyon at Spearfish. It runs roughly south to north through the center of town (parallel to Canyon Street), year round. The creek freezes from the bottom up instead of icing over. This unusual phenomenon occurs due to the very fast rate at which the creek flows. This speed prevents ice from forming except along the bottom of the creek bed where friction and turbulence allow the water to slow down long enough to freeze. Since the creek continues to flow atop this ice, the water level of the creek gradually rises as more ice accumulates on the bottom, in some cases causing flooding on the north side of town where the channel is not as deep.\n\nSpearfish has been assigned the ZIP code 57783 and the FIPS place code 60020. Black Hills State University has its own ZIP code, 57799.\n\nGiven its location at the base of the Black Hills and its proximity to the High Plains, the climate in Spearfish is highly variable at any time of the year. This is especially true in the winter months. According to the Köppen climate classification Spearfish is in a transition zone between subtropical and continental. Due to January being just above the isotherm for continental (according to NOAA figures) it slightly leans towards subtropical, in spite of the cold winter nights. According to Weatherbase’s figures, the climate is instead firmly within the continental zone. Snow depth is limited: even in winter half of all days have no snow on the ground, although on average of fresh snow falls.\n\nSpearfish holds the world record for the fastest recorded temperature change. On January 22, 1943 at about 7:30 a.m. MST, the temperature in Spearfish was −4°F (−20°C). The Chinook wind picked up speed rapidly, and two minutes later (7:32 a.m.) the temperature was +45 °F (+7 °C) above zero. The rise in two minutes set a world record that still holds. By 9:00 a.m., the temperature had risen to 54 °F (12 °C). Suddenly, the chinook died down and the temperature tumbled back to . The drop took only 27 minutes. The sudden change in temperatures caused glass windows to crack and windshields to instantly frost over.\n\nExtreme winter maxima in the district are remarkably warm for its latitude and on January 19, 1921 Spearfish reached a remarkable , not only the hottest January temperature in South Dakota on record, but almost certainly the hottest temperature recorded in or near mid-winter anywhere so far from the equator.\n\nAs of the census of 2010, there were 10,494 people, 4,644 households, and 2,350 families residing in the city. The population density was . There were 5,045 housing units at an average density of . The racial makeup of the city was 93.5% White, 0.4% African American, 2.0% Native American, 1.1% Asian, 0.6% from other races, and 2.3% from two or more races. Hispanic or Latino of any race were 2.7% of the population.\n\nThere were 4,644 households of which 23.1% had children under the age of 18 living with them, 38.5% were married couples living together, 8.9% had a female householder with no husband present, 3.3% had a male householder with no wife present, and 49.4% were non-families. 39.3% of all households were made up of individuals and 16.9% had someone living alone who was 65 years of age or older. The average household size was 2.09 and the average family size was 2.79.\n\nThe median age in the city was 33.2 years. 18.6% of residents were under the age of 18; 20.2% were between the ages of 18 and 24; 22.3% were from 25 to 44; 21.2% were from 45 to 64; and 17.7% were 65 years of age or older. The gender makeup of the city was 47.1% male and 52.9% female.\n\nAs of the census of 2000, there were 8,606 people, 3,638 households, and 1,931 families residing in the city. The population density was 1,409.1 people per square mile (543.8/km²). There were 3,904 housing units at an average density of 639.2 per square mile (246.7/km²). The racial makeup of the city was 95.33% White, 0.35% African American, 2.31% Native American, 0.36% Asian, 0.02% Pacific Islander, 0.33% from other races, and 1.30% from two or more races. Hispanic or Latino of any race were 1.73% of the population. 37.5% were of German, 13.5% Norwegian, 9.6% English and 8.2% Irish ancestry according to Census 2000.\n\nThere were 3,638 households out of which 25.2% had children under the age of 18 living with them, 41.4% were married couples living together, 9.2% had a female householder with no husband present, and 46.9% were non-families. 37.0% of all households were made up of individuals and 15.5% had someone living alone who was 65 years of age or older. The average household size was 2.15 and the average family size was 2.85.\n\nIn the city, the population was spread out with 20.3% under the age of 18, 21.5% from 18 to 24, 23.3% from 25 to 44, 17.9% from 45 to 64, and 17.1% who were 65 years of age or older. The median age was 32 years. For every 100 females, there were 87.1 males. For every 100 females age 18 and over, there were 83.3 males.\n\nAs of 2000 the median income for a household in the city was $26,887, and the median income for a family was $40,257. Males had a median income of $30,242 versus $20,431 for females. The per capita income for the city was $16,565. About 9.8% of families and 17.4% of the population were below the poverty line, including 16.1% of those under age 18 and 9.4% of those age 65 or over.\n\n\"AM radio\"\n\n\n\"FM radio\"\n\n\"Television\"\n\nSpearfish is the home of Black Hills State University, a four-year public university in the South Dakota system. Founded as Spearfish Normal School in 1883, it is still largely a teacher training institution, although its mission has expanded far beyond to include masters programs in Integrative Genomics and Business Administration. It also hosts a summer arts institute, with Spearfish native and international opera star Johanna Meier (daughter of the \"Black Hills Passion Play\" founder Joseph Meier) serving as Artistic Director.\n\nSpearfish is the headquarters and hometown of two bus and coach transport services; Dakota Trailways and Prairie Hills Transit.\n\n\n"}
{"id": "20765905", "url": "https://en.wikipedia.org/wiki?curid=20765905", "title": "Sun Xiaodi", "text": "Sun Xiaodi\n\nSun Xiaodi has spent more than a decade petitioning the central Chinese authorities over radioactive contamination from the No. 792 Uranium Mine in the Gannan Tibetan Autonomous Prefecture in Gansu Province. In 2006, he received the prestigious Nuclear-Free Future Award.\n\n\n"}
{"id": "19447250", "url": "https://en.wikipedia.org/wiki?curid=19447250", "title": "Sun gun", "text": "Sun gun\n\nThe sun gun or heliobeam is a theoretical orbital weapon, which makes use of a concave mirror mounted on a satellite, to shoot sun balls to a small area of the Earth's surface, destroying targets or killing through heat.\n\nThe Scottish mathematician John Napier proposed such a device. In his book \"Secrete Inventionis\" (1596), he published details of a giant mirror to burn enemy ships by focusing the sun's rays on them.\n\nIn 1929, the German physicist Hermann Oberth developed plans for a space station from which a 100-metre-wide concave mirror could be used to reflect sunlight onto a concentrated point on the earth.\n\nLater during World War II, a group of German scientists at the German Army Artillery proving grounds at Hillersleben began to expand on Oberth's idea of creating a superweapon that could utilize the sun's energy. This so-called \"sun gun\" (\"Sonnengewehr\") would be part of a space station above Earth. The scientists calculated that a huge reflector, made of metallic sodium and with an area of , could produce enough focused heat to make an ocean boil or burn a city. After being questioned by officers of the United States, the Germans claimed that the sun gun could be completed within 50 or 100 years.\n\nIn the film \"Die Another Day\", the twentieth installment in the James Bond series of films, the primary antagonist of the film, fictional British billionaire Gustav Graves (in reality the alias of the assumed-to-be-dead North Korean Colonel Tan Sun-Moon), constructs an orbital sun gun code-named \"Icarus\" for the use of cutting a path through the Korean Demilitarized Zone and allowing North Korean troops to invade South Korea. The device was disabled after its control console is destroyed.\n\nA similar concept is used in the \"\" video game. In the game, a special satellite code-named Regia Solis is used to provide a city with clean energy but at full capacity it is powerful enough to destroy said city or other targets.\n\nIn the TV series \"Scorpion\" episode \"Sun of a Gun\", Walter O'Brien's fictional alter ego and his team are sent alongside their friend Sylvester Dodd's estranged father to an African dictator's country to investigate his discovery of a Nazi World War II sun gun project.\n\nIn the \"Star Wars Legends\" book \"\", Rogue Squadron commandeers an orbital solar reflector (used for power generation) is used to boil ocean water in an effort to generate a large enough storm to knock out power on the planet (Coruscant) below.\n\nIn , there is a similar mechanism called the “Sonnengewehr” that is featured in the newspapers.\n\nIn the science fiction novel by René Barjavel \"The Ice People (French: la Nuit des temps)\" the doomsday device build by the gondas looks mostly inspired by the concept of the sun gun.\n\nIn an episode of Futurama, one of these is the result of a failed attempt to reverse global warming with a giant mirror.\n\n"}
{"id": "25997913", "url": "https://en.wikipedia.org/wiki?curid=25997913", "title": "Tactile sensor", "text": "Tactile sensor\n\nA tactile sensor is a device that measures information arising from physical interaction with its environment. Tactile sensors are generally modeled after the biological sense of cutaneous touch which is capable of detecting stimuli resulting from mechanical stimulation, temperature, and pain (although pain sensing is not common in artificial tactile sensors). Tactile sensors are used in robotics, computer hardware and security systems. A common application of tactile sensors is in touchscreen devices on mobile phones and computing.\n\nTactile sensors may be of different types including piezoresistive, piezoelectric, capacitive and elastoresistive sensors.\n\nTactile sensors appear in everyday life such as elevator buttons and lamps which dim or brighten by touching the base. There are also innumerable applications for tactile sensors of which most people are never aware.\n\nSensors that measure very small changes must have very high sensitivities. Sensors need to be designed to have a small effect on what is measured; making the sensor smaller often improves this and may introduce other advantages. Tactile sensors can be used to test the performance of all types of applications. For example, these sensors have been used in the manufacturing of automobiles (brakes, clutches, door seals, gasket), battery lamination, bolted joints, fuel cells etc.\n\nTactile imaging, as a medical imaging modality, translating the sense of touch into a digital image is based on the tactile sensors. Tactile imaging closely mimics manual palpation, since the probe of the device with a pressure sensor array mounted on its face acts similar to human fingers during clinical examination, deforming soft tissue by the probe and detecting resulting changes in the pressure pattern.\n\nRobots designed to interact with objects requiring handling involving precision, dexterity, or interaction with unusual objects, need sensory apparatus which is functionally equivalent to a human's tactile ability. Tactile sensors have been developed for use with robots. Tactile sensors can complement visual systems by providing added information when the robot begins to grip an object. At this time vision is no longer sufficient, as the mechanical properties of the object cannot be determined by vision alone. Determining weight, texture, stiffness, center of mass, coefficient of friction, and thermal conductivity require object interaction and some sort of tactile sensing.\nSeveral classes of tactile sensors are used in robots in warfare and engineering\n\nPressure sensor arrays are large grids of tactels. A \"tactel\" is a ‘tactile element’. Each tactel is capable of detecting normal forces. Tactel-based sensors provide a high resolution ‘image’ of the contact surface. Alongside spatial resolution and force sensitivity, systems-integration questions such as wiring and signal routing are important. Pressure sensor arrays are available in thin-film form. They are primarily used as analytical tools used in the manufacturing and R&D processes by engineers and technicians, and have been adapted for use in robots. Examples of such sensors available to consumers include arrays built from conductive rubber, lead zirconate titanate (PZT), polyvinylidene fluoride(PVDF), PVDF-TrFE, FET, and metallic capacitive sensing elements.\n\nStrain gauges rosettes are constructed from multiple strain gauges, with each gauge detecting the force in a particular direction. When the information from each strain gauge is combined, the information allows determination of a pattern of forces or torques.\n\nA variety of biologically inspired designs have been suggested ranging from simple whisker-like sensors which measure only one point at a time through more advanced fingertip-like sensors, to complete skin-like sensors as on the latest iCub(citation needed). Biologically inspired tactile sensors often incorporate more than one sensing strategy. For example, they might detect both the distribution of pressures, and the pattern of forces that would come from pressure sensor arrays and strain gauge rosettes, allowing two-point discrimination and force sensing, with human-like ability.\n\nAdvanced versions of biologically designed tactile sensors include vibration sensing which has been determined to be important for understanding interactions between the tactile sensor and objects where the sensor slides over the object. Such interactions are now understood to be important for human tool use and judging the texture of an object. One such sensor combines force sensing, vibration sensing, and heat transfer sensing.\n\nRecently, a sophisticated tactile sensor has been made open-hardware, enabling enthusiasts and hobbyists to experiment with an otherwise expensive technology.\nFurthermore, with the advent of cheap optical cameras, novel sensors have been proposed which can be built easily and cheaply with a 3D printer.\n\n\n"}
{"id": "38320103", "url": "https://en.wikipedia.org/wiki?curid=38320103", "title": "Trianel Windpark Borkum", "text": "Trianel Windpark Borkum\n\nTrianel Windpark Borkum (formerly Borkum West II) is an offshore wind farm near Borkum. Its first phase of 40 turbines rated at a total power of 200 MW is operational, with a planned, additional 200 MW in a second phase. The project was approved for construction in 2008 and will cost over €1 billion to construct once fully operational (€900m for phase I alone). Originally known as Borkum West II the name was changed to Trianel Windpark Borkum in early 2013.\n\nPhase 1 of the installation was completed in the 4th quarter of 2014 and consist of 40 Areva M5000-116 turbines (5 MW turbines) on Tripod foundations. It was connected to the grid in August 2015. In the six months before March 2016 the wind farm produced 452.33 GWh, i.e. a capacity factor of 51.6%.\n\nIn September 2016 Senvion was awarded a conditional contract for the second phase, for 32 upgraded 6.2M152 turbines rated at a total power of 203 MW. A final investment decision is expected in the first half of 2017 after which construction could start in early 2018 for a planned completion in the fall of 2019.\n"}
{"id": "15319844", "url": "https://en.wikipedia.org/wiki?curid=15319844", "title": "Upper Valley Land Trust", "text": "Upper Valley Land Trust\n\nThe Upper Valley Land Trust (UVLT), located in the U.S. state of Hanover, New Hampshire, is a 501(c)(3) non-profit land conservation organization that serves over 40 towns in the Upper Connecticut River Valley of Vermont and New Hampshire. Founded in 1985, UVLT helps landowners and communities in its region protect lands that have important natural resource values and help define the rural character of the Upper Valley. UVLT works with willing landowners to protect working farms, forest lands, river and stream frontage, wildlife habitat, scenic landscapes, and recreational resources from future development. The primary tool that UVLT uses to conserve land is a legal document known as a conservation easement which runs with the land in perpetuity. As of 2008, UVLT had conserved over in its region. In a recent Land Trust Alliance (LTA) census, UVLT was ranked 7th in the nation for the number of conservation easements it holds out of more than 1,600 LTA-member land trusts.\n\n"}
{"id": "3467050", "url": "https://en.wikipedia.org/wiki?curid=3467050", "title": "Uranium dioxide", "text": "Uranium dioxide\n\nUranium dioxide or uranium(IV) oxide (), also known as urania or uranous oxide, is an oxide of uranium, and is a black, radioactive, crystalline powder that naturally occurs in the mineral uraninite. It is used in nuclear fuel rods in nuclear reactors. A mixture of uranium and plutonium dioxides is used as MOX fuel. Prior to 1960, it was used as yellow and black color in ceramic glazes and glass.\n\nUranium dioxide is produced by reducing uranium trioxide with hydrogen.\n\nThis reaction plays an important part in the creation of nuclear fuel through nuclear reprocessing and uranium enrichment.\n\nThe solid is isostructural with (has the same structure as) fluorite (calcium fluoride), where each U is surrounded by eight O nearest neighbors in a cubic arrangement. In addition, the dioxides of cerium, plutonium and neptunium have the same structures. No other elemental dioxides have the fluorite structure. Upon melting, the measured average U-O coordination reduces from 8 in the crystalline solid (UO cubes), down to 6.7±0.5 (at 3270 K) in the melt. Models consistent with these measurements show the melt to consist mainly of UO and UO polyhedral units, where roughly of the connections between polyhedra are corner sharing and are edge sharing.\n\nUranium dioxide is oxidized in contact with oxygen to the triuranium octaoxide.\n\nThe electrochemistry of uranium dioxide has been investigated in detail as the galvanic corrosion of uranium dioxide controls the rate at which used nuclear fuel dissolves. See spent nuclear fuel for further details. Water increases the oxidation rate of plutonium and uranium metals.\n\nUranium dioxide is carbonized in contact with carbon, forming uranium carbide and carbon monoxide.\n\nUO + 4 C → UC + 2 CO\n\nThis process must be done under an inert gas as uranium carbide is easily oxidized back into uranium oxide.\n\nUO is used mainly as nuclear fuel, specifically as UO or as a mixture of UO and PuO (plutonium dioxide) called a mixed oxide (MOX fuel), in the form of fuel rods in nuclear reactors.\n\nNote that the thermal conductivity of uranium dioxide is very low when compared with uranium, uranium nitride, uranium carbide and zirconium cladding material. This low thermal conductivity can result in localised overheating in the centres of fuel pellets. The graph below shows the different temperature gradients in different fuel compounds. For these fuels the thermal power density is the same and the diameter of all the pellets are the same.\n\nUranium oxide (urania) was used to color glass and ceramics prior to World War II, and until the applications of radioactivity were discovered this was its main use. In 1958 the military in both the USA and Europe allowed its commercial use again as depleted uranium, and its use began again on a more limited scale. Urania-based ceramic glazes are dark green or black when fired in a reduction or when UO is used; more commonly it is used in oxidation to produce bright yellow, orange and red glazes. Orange-colored Fiestaware is a well-known example of a product with a urania-colored glaze. Uranium glass is pale green to yellow, and often has strong fluorescent properties. Urania has also been used in formulations of enamel and porcelain. It is possible to determine with a Geiger counter if a glaze or glass produced before 1958 contains urania.\n\nPrior to the realisation of the harmfulness of radiation, uranium was included in false teeth and dentures, as its slight fluorescence made the dentures appear more like real teeth in a variety of lighting conditions.\n\nDepleted UO (DUO) can be used as a material for radiation shielding. For example, DUCRETE is a \"heavy concrete\" material where gravel is replaced with uranium dioxide aggregate; this material is investigated for use for casks for radioactive waste. Casks can be also made of DUO-steel cermet, a composite material made of an aggregate of uranium dioxide serving as radiation shielding, graphite and/or silicon carbide serving as neutron radiation absorber and moderator, and steel as the matrix, whose high thermal conductivity allows easy removal of decay heat.\n\nDepleted uranium dioxide can be also used as a catalyst, e.g. for degradation of volatile organic compounds in gaseous phase, oxidation of methane to methanol, and removal of sulfur from petroleum. It has high efficiency and long-term stability when used to destroy VOCs when compared with some of the commercial catalysts, such as precious metals, TiO, and CoO catalysts. Much research is being done in this area, DU being favoured for the uranium component due to its low radioactivity.\n\nThe use of uranium dioxide as a material for rechargeable batteries is being investigated. The batteries could have high power density and potential of 4.7 V per cell. Another investigated application is in photoelectrochemical cells for solar-assisted hydrogen production where UO is used as a photoanode. In earlier times, uranium dioxide was also used as heat conductor for current limitation (URDOX-resistor), which was the first use of its semiconductor properties.\n\nUranium dioxide is also the strongest known piezomagnet in the antiferromagnetic state observed at cryogenic temperatures below 30 kelvins. UO displays a linear magnetostriction that changes sign with the sign of the applied magnetic field, and magnetoelastic memory switching at magnetic fields near 180,000 Oe.\n\nThe band gap of uranium dioxide is comparable to these of silicon and gallium arsenide, near the optimum for efficiency vs band gap curve for absorption of solar radiation, suggesting its possible use for very efficient solar cells based on Schottky diode structure; it also absorbs at five different wavelengths, including infrared, further enhancing its efficiency. Its intrinsic conductivity at room temperature is about the same as of single crystal silicon.\n\nThe dielectric constant of uranium dioxide is about 22, which is almost twice as high as of silicon (11.2) and GaAs (14.1). This is an advantage over Si and GaAs in construction of integrated circuits, as it may allow higher density integration with higher breakdown voltages and with lower susceptibility to the CMOS tunneling breakdown.\n\nThe Seebeck coefficient of uranium dioxide at room temperature is about 750 µV/K, a value significantly higher than the 270 µV/K of thallium tin telluride (TlSnTe) and thallium germanium telluride (TlGeTe) and of bismuth-tellurium alloys, other materials promising for thermoelectric power generation applications and Peltier elements.\n\nThe radioactive decay impact of the U and U on its semiconducting properties was not measured . Due to the slow decay rate of these isotopes, it should not meaningfully influence the properties of uranium dioxide solar cells and thermoelectric devices, but it may become an important factor for VLSI chips. Use of depleted uranium oxide is necessary for this reason. The capture of alpha particles emitted during radioactive decay as helium atoms in the crystal lattice may also cause gradual long-term changes in its properties.\n\nThe stoichiometry of the material dramatically influences its electrical properties. For example, the electrical conductivity of UO is orders of magnitude lower at higher temperatures than the conductivity of UO.\n\nUranium dioxide, like UO, is a ceramic material capable of withstanding high temperatures (about 2300 °C, in comparison with at most 200 °C for silicon or GaAs), making it suitable for high-temperature applications like thermophotovoltaic devices.\n\nUranium dioxide is also resistant to radiation damage, making it useful for rad-hard devices for special military and aerospace applications.\n\nA Schottky diode of UO and a p-n-p transistor of UO were successfully manufactured in a laboratory.\n\nUranium dioxide is known to be absorbed by phagocytosis in the lungs.\n\n\n"}
{"id": "4392706", "url": "https://en.wikipedia.org/wiki?curid=4392706", "title": "Uranium tetrachloride", "text": "Uranium tetrachloride\n\nUranium tetrachloride (UCl) is compound of uranium in oxidation state +4. It was used in the electromagnetic isotope separation (EMIS) process of uranium enrichment. It is one of the main starting materials for organouranium chemistry.\n\nUranium tetrachloride is synthesised generally by the reaction of uranium trioxide (UO) and hexachloropropene. Solvent UCl adducts can be formed by a simpler reaction of UI with hydrogen chloride in organic solvents.\n\nUranium tetrachloride is a hygroscopic, dark green solid, which sublimes in a high vacuum at ca. 500 °C. The crystal structure shows the uranium to be surrounded by eight chlorine atoms, four at 264 pm and the other four at 287pm. The molecule UCl is a Lewis acid and dissolves in solvents that can act as non-protic Lewis bases.\n\nDissolution in protic solvents is more complicated. When UCl is added to water the uranium aqua ion is formed.\nThe aqua ion [U(HO)], (x is 8 or 9) is strongly hydrolyzed. \nThe pK for this reaction is ca. 1.6, so hydrolysis is absent only in solutions of acid strength 1 mol dm or stronger (pH < 0). Further hydrolysis occurs at pH > 3. Weak chloro complexes of the aqua ion may be formed. Published estimates of the log K value for the formation of [UCl](aq) vary from −0.5 to +3 because of difficulty in dealing with simultaneous hydrolysis.\n\nWith alcohols, partial solvolysis may occur.\n\nUranium tetrachloride dissolves in non-protic solvents such as tetrahydrofuran, acetonitrile, dimethyl formamide etc. that can act as Lewis bases. Solvates of formula UClL are formed which may be isolated. The solvent must be completely free of dissolved water, or hydrolysis will occur, with the solvent, S, picking up the released proton.\nThe solvent molecules may be replaced by other ligand in a reaction such as \nThe solvent is not shown, just as when complexes of other metal ions are formed in aqueous solution.\n\nSolutions of UCl are susceptible to oxidation by air, resulting in the production of complexes of the uranyl ion.\n\nUranium tetrachloride is produced commercially by the reaction of carbon tetrachloride with pure uranium dioxide UO at 370 °C. It has been used as feed in the electromagnetic isotope separation (EMIS) process of uranium enrichment. Beginning in 1944, the Oak Ridge Y-12 Plant converted UO to UCl feed for the Ernest O. Lawrence's Alpha Calutrons. Its major benefit being the uranium tetrachloride used in the calutrons is not as corrosive as the uranium hexafluoride used in most other enrichment technologies This process was abandoned in the 1950s. In the 1980s, however, Iraq unexpectedly revived this option as part of its nuclear weapons program. In the enrichment process, uranium tetrachloride is ionized into a uranium plasma.\n\nThe uranium ions are then accelerated and passed through a strong magnetic field. After traveling along half of a circle the beam is split into a region nearer the outside wall which is depleted and a region nearer the inside wall which is enriched in U-235. The large amounts of energy required in maintaining the strong magnetic fields as well as the low recovery rates of the uranium feed material and slower more inconvenient facility operation make this an unlikely choice for large scale enrichment plants.\n\nWork is being done in the use of molten uranium chloride-alkali chloride mixtures as reactor fuels in molten salt reactors. Uranium tetrachloride melts dissolved in a lithium chloride-potassium chloride eutectic have also been explored as a means to recover actinides from irradiated nuclear fuels through pyrochemical nuclear reprocessing.\n"}
{"id": "3488548", "url": "https://en.wikipedia.org/wiki?curid=3488548", "title": "Uranous", "text": "Uranous\n\nUranous is the chemical term for the reduced tetrapositive cation of uranium that exhibits the valence U. It is one of the two common ionic states of uranium found in nature, the other being the oxidised hexapositive ion called uranyl. Uranous compounds are usually unstable; they revert to the oxidised form on exposure to air.\n\nExamples of these compounds include uranium tetrachloride (UCl) and uranium tetrafluoride (UF), which are important in molten salt reactor applications, and uranium dioxide (UO), a common form of nuclear fuel.\n\nThe solvated U ion is normally not present in water. Most of the compounds like UCl are better described with the covalent bond than an ionic bond.\n\nMinerals containing the uranous ion are more subdued in colour, typically brown or black, and occur in reducing environments. Common uranous minerals include: uraninite; pitchblende (a crystalline variant of uraninite); and coffinite \"(Smith,Hutchinson and Blackwell, 1984)\"\n"}
{"id": "34946641", "url": "https://en.wikipedia.org/wiki?curid=34946641", "title": "Waag, Haarlem", "text": "Waag, Haarlem\n\nThe Waag (\"Waegh\") is a former Weigh house in Haarlem that today serves as a café catering to tourists.\n\nThe building was designed by Lieven de Key around 1597 and is built with \"Namense steen\" from Namur, Belgium. It is the only building in Haarlem that was built this way, and was designed in its day as a landmark that befits an authority. The weigh house masters needed to be able to judge the correct measure of a shipload of grain that was delivered in Haarlem. Inside the large cast iron balance can still be seen. The location of the weigh house was strategically located where the Spaarne river joins the \"beek\", a small canal that according to tradition was used to carry fresh water from the dunes to serve the brewers of Haarlem. Haarlem was known for its beer brewing in the 15th-17th centuries. A large wooden crane operated by wheels driven by manpower was used to hoist the grain on ships into the Waag building and back into other ships or carts for further transport. The wooden crane can be seen on most historic pictures of the Spaarne up until 1872.\n\nIn 1821 the top floor of the Waag was rented to the artist club Kunst zij ons doel for drawing classes gathered around a live model. The room is still used for this function, though fewer drawing classes are held nowadays and the rooms are often used for exhibitions. The entrance to the artist club is via the small staircase on the Spaarne side.\n\n"}
{"id": "25174776", "url": "https://en.wikipedia.org/wiki?curid=25174776", "title": "Woodfree uncoated paper", "text": "Woodfree uncoated paper\n\nWoodfree uncoated paper (WFU) or uncoated fine papers are manufactured using wood that has been processed into a chemical pulp that removes the lignin from the wood fibers and may also contain 5–25% fillers. Both softwood and hardwood chemical pulps are used and a minor part of mechanical pulp might be added (often of aspen or poplar). These paper grades are calendered.\n\nWoodfree uncoated papers are of high quality and have a natural look and feel. The properties are good strength, high brightness and good archival characteristics. They provide a non-glare surface suitable for reading and writing.\n\n\"Offset paper\" is a WFU paper with ISO brightness > 80% and a basis weight of 40–300 g/m. Surface strength and low linting are the main parameters, but brightness and opacity are also important.\n\n\"Lightweight offset paper\", also called onionskin, has a basis weight of 25–40 g/m and are normally used for bibles (hence the name Bible paper) and dictionaries.\n"}
