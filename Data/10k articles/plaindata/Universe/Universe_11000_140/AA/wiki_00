{"id": "195678", "url": "https://en.wikipedia.org/wiki?curid=195678", "title": "ABB Group", "text": "ABB Group\n\nABB (ASEA Brown Boveri) (, , ) is a Swiss-Swedish multinational corporation headquartered in Zurich, Switzerland, operating mainly in robotics, power, heavy electrical equipment and automation technology areas. It is ranked 341st in the Fortune Global 500 list of 2018 and has been a global Fortune 500 company for 24 years.\n\nABB is traded on the SIX Swiss Exchange in Zürich, Nasdaq Stockholm and the New York Stock Exchange in the United States.\n\nABB's history goes back to the late 19th century. \"Allmänna Svenska Elektriska Aktiebolaget\" (General Swedish Electrical Limited Company, ASEA) was founded in 1883 by Ludvig Fredholm in Västerås as manufacturer of electrical light and generators. Brown, Boveri & Cie (BBC) was formed in 1891 in Baden, Switzerland, by Charles Eugene Lancelot Brown and Walter Boveri as a Swiss group of electrical companies producing AC and DC motors, generators, steam turbines and transformers.\nABB was created as the result of the merger of ASEA and BBC in 1988. The latter had acquired \"Maschinenfabrik Oerlikon\" in 1967. The former CEO of ASEA, Percy Barnevik, became CEO of ABB, until his resignation in 1996.\nIn 1990, ABB purchased Westinghouse's metering and control division (the load control division was spun off to Cannon Technologies in the late 1990s and the meter division was spun off to Elster Electricity in the early 2000s). Also, in the early 1990s, ABB purchased Combustion Engineering (C-E), headquartered in Stamford and Norwalk, Connecticut, a leading U.S. firm in the development of conventional fossil fuel power and nuclear power supply systems to break into the North American market. Klaus Agthe was CEO of the US operation at the time. Continuing with its expansion plans, ABB purchased Elsag Bailey, a process automation group, in 1997 which included Bailey Controls, Hartmann & Braun, and Fischer & Porter. This was the largest acquisition to date in ABB's history.\n\nABB bought International Combustion Ltd from Rolls-Royce in 1997.\n\nAlstom acquired ABB's boiler and fossil fuel operations in 2000 while its nuclear business was purchased by Westinghouse Electric Company in 2000. In 2000, ABB also signed a contract for the delivery of equipment and services for two North Korean nuclear powerplants to be supplied under an agreement with the Korean Peninsula Energy Development Organization (KEDO), a consortium formed in 1995 by the governments of the United States, Japan, South Korea and the European Union. ABB formally divested from a joint venture named ABB-Alstom Power in 2000, and sold its interest in conventional power generation systems to Alstom Power. ABB's nuclear business was sold to BNFL and merged into Westinghouse Electric Company.\n\nIn 2001, ABB was ranked as number one on the Dow Jones corporate sustainability index for the third year in a row.\n\nIn 2002, ABB asked Lindahl, the company's former chief executive, to return some of his $50 million retirement pay, which its board called excessive. ABB also asked its former chairman Percy Barnevik to pay back part of his $87 million pension package. The size of the pensions was disclosed at the same time as ABB's $691 million net loss for 2001 made headlines and drew sharp criticism in Switzerland and Sweden.\n\nABB's Building Systems business unit was sold off in 2004 to Capvis, a Swiss private equity company, as part of ABB's strategy to focus on power and automation technologies. ABB's building systems businesses in Australia and Hong Kong were sold off the year before, in May 2003, to Downer EDI Limited. Building Systems provided services for building facilities encompassing indoor air quality, building automation as well as power distribution and management.\n\nFinancial debt and lingering asbestos liability brought ABB to the brink of bankruptcy in the early 2000s. In 2006, ABB recovered financially by settling asbestos issues brought by its U.S. subsidiaries, Combustion Engineering and Lummus Global. In August 2007 Lummus Global was sold to CB&I.\n\nIn December 2008, ABB acquired Ber-Mac Electrical and Instrumentation to expand its presence in western Canada's oil and gas industries.\n\nIn 2009, ABB realigned its automation divisions . As of January 1, 2010, the business units in the Automation Products and Robotics divisions were regrouped into two new divisions – Discrete Automation and Motion, and Low Voltage Products. The Process Automation division remained unchanged except for the addition of the instrumentation business from the Automation Products division.\n\nIn May 2010, ABB acquired software company Ventyx for more than $1 billion from Vista Equity Partners. In 2011, on May 9 ABB announced acquisition of Australian-based Mincom Limited from private equity firm Francisco Partners for an undisclosed sum. On July 29, 2011, acquisition has been finalised. Mincom and Ventyx were subsequently integrated under the Ventyx name, and have now been integrated into ABB as the Enterprise Software Product Group.\n\nIn 2011 ABB acquired Baldor Electric USA for $4.2 billion in an all-cash transaction On January 30, 2012, ABB Group acquired Thomas & Betts in a $3.9 billion cash transaction. On June 15, 2012, it completed acquisition of commercial and industrial wireless technology specialists Tropos. In July 2013, ABB acquired Power-One in a $1 billion all-cash transaction, to become the leading global manufacturer of solar inverters . On June 30, 2018, ABB completed its acquisition of GE Industrial Solutions, General Electric's global electrification business. The transaction was announced on September 25, 2017.\n\nABB is the world's largest builder of electricity grids and is active in many sectors, its core businesses being in power and automation technologies. With a long history of growth through mergers and acquisitions, it entered a phase of structure unification since 2014. The company has one corporate division and four production divisions. reorganization in January 2017. ABB implements the matrix structure .\n\nThe Electrification Products division manufactures low- and medium-voltage electrical products, including electric vehicle infrastructure, solar inverters, modular substations, distribution automation; products to protect people, installations and electronic equipment from electrical overload such as enclosures, cable systems and low-voltage circuit breakers; measuring and sensing devices, control products, switches and wiring accessories. The division further makes KNX systems that integrate and automate a building's electrical installations, ventilation systems, and security and data communication networks. Electrification Products also incorporates an Electrification Solutions unit manufacturing low voltage switchgear and motor control centres. Customers include a wide range of industry and utility operations, plus commercial and residential buildings.\n\nThe acquisition of GE Industrial Solutions, which closed in June 2018, further strengthened ABB's #2 global position in electrification.\n\nThe Robotics and Motion division provides products and services for industrial production. It includes electric motors, generators, drives, power electronics and industrial robots. ABB has installed over 300,000 robots. In 2006, ABB opened a manufacturing centre in Shanghai, China. Also, wind generators, solar power inverters and UPS products belong to this division.\n\nIndustrial Automation\n\nThe Industrial Automation division provides systems for control, plant optimization, and industry-specific automation applications. The industries served include oil and gas, power, chemicals and pharmaceuticals, pulp and paper, metals and minerals, marine and turbocharging. The division consists of seven business units: Control Technologies (the world's No 1 DCS supplier); Marine & Ports; Measurement & Analytics; Oil, Gas & Chemicals; Power Generation & Water; Process Industries and Turbocharging.\n\nThe Power Grids division offers components for the transmission and distribution of electricity. The division incorporates ABB's manufacturing network for transformers, switchgear, circuit breakers, and associated high voltage equipment such as digital protective relays. It also offers maintenance services. The division also offers turnkey systems and service for power transmission and distribution grids and for power plants; this includes electrical substations and substation automation systems flexible AC transmission systems (FACTS), high-voltage direct current (HVDC) systems, and network management systems. The division is subdivided into the four business units High Voltage Products, Transformers, Grid Automation and Grid Integration.\n\nIn May 2013, ABB Sécheron SA joined with several groups in Geneva TOSA (Trolleybus Optimisation Système Alimentation, or in English, Trolleybus Power System Optimization) in a one-year demonstration of a trolleybus route using a novel charging system. Rather than overhead wires, charging is accomplished by fixed overhead devices located at stops along the route and at the terminus. Jean-Luc Favre, head of Rail ISI, discussed the promising role of improved electric transport technology in ABB.\n\nABB group saw the market change due to the entrance of the IT industry and partnered up with IBM. IBM is a large player within the technology industry. This helped ABB group in managing the transition into implementing the technology in their core business.\n\nUlrich Spiesshofer has been the chief executive officer since September 2013. The board of directors is chaired by Peter Voser. He was elected in April 2015 and succeeded Hubertus von Grünberg, who had been Chairman since May 2007. Jürgen Dormann was chairman from 2002 to 2007, and Percy Barnevik from 1999 to 2002.\n\nThe largest single stake in the firm is held by the Swedish investment company Investor AB, controlled by the Wallenberg family, which holds 10.48%.\n\n\n\n"}
{"id": "1711063", "url": "https://en.wikipedia.org/wiki?curid=1711063", "title": "Aerodynamic heating", "text": "Aerodynamic heating\n\nAerodynamic heating is the heating of a solid body produced by its high-speed passage through air (or by the passage of air past a test object in a wind tunnel), whereby its kinetic energy is converted to heat by skin friction on the surface of the object at a rate that depends on the viscosity and speed of the air. In science and engineering, it is most frequently a concern regarding meteors, reentry vehicles, and the design of high-speed aircraft.\n\nAt high speeds through the air, the object's kinetic energy is converted to heat through compression and friction. At lower speed, the object will lose heat to the air through which it is passing, if the air is cooler. The combined temperature effect of heat from the air and from passage through it is called the stagnation temperature; the actual temperature is called the recovery temperature. These viscous dissipative effects to neighboring sub-layers make the boundary layer slow down via a non-isentropic process. Heat then conducts into the surface material from the higher temperature air. The result is an increase in the temperature of the material and a loss of energy from the flow. The forced convection ensures that other material replenishes the gases that have cooled to continue the process.\n\nThe stagnation and the recovery temperature of a flow increases with the speed of the flow and are greater at high speeds. The total thermal loading of the object is a function of both the recovery temperature and the mass flow rate of the flow. Aerodynamic heating is greatest at high speed and in the lower atmosphere where the density is greater. In addition to the convective process described above, there is also Thermal radiation from the flow to the body and vice versa with the net direction set by the relative temperature of each.\n\nAerodynamic heating increases with the speed of the vehicle. Its effects are minimal at subsonic speeds but at supersonic speeds beyond about M2.2 it dictates the design/materials of the vehicle structure and internal systems. The heating effects are greatest at leading edges but the whole vehicle heats up to a stabilized temperature if it remains at speed. Aerodynamic heating is dealt with by the use of high temperature alloys for metals, the addition of insulation of the exterior of the vehicle, or the use of ablative material.\n\nAerodynamic heating is a concern for supersonic and hypersonic aircraft.\n\nOne of the main concerns caused by aerodynamic heating arises in the design of the wing. When the structure of an aircraft wing is designed, there are two main considerations that must be accounted for when this aircraft is to fly at subsonic speeds: minimizing weight and maximizing strength. Aerodynamic heating, which occurs at supersonic and hypersonic aircraft speeds, adds an additional consideration in wing structure analysis. In an idealized wing structure, a wing is made up of spars, stringers, and skin segments. In a wing that normally experiences subsonic speeds, there must be a sufficient number of stringers to withstand the axial and bending stresses induced by the lift force acting on the wing. In addition, the distance between the stringers must be small enough that the skin panels do not buckle, and the panels must be thick enough to withstand the shear stress and shear flow present in the panels due to the lifting force on the wing. However, the weight of the wing must be made as small as possible, so the choice of material for the stringers and the skin is an important factor.\n\nAt supersonic airspeeds, aerodynamic heating adds another element to this structural analysis. At normal speeds, spars and stringers experience a load called Delta P, which is a function of the lift force, first and second moments of inertia, and length of the spar. When there are more spars and stringers, the Delta P in each member is reduced, and the area of the stringer can be reduced to meet critical stress requirements. However, the increase in temperature caused by energy flowing from the air (heated by skin friction at these high speeds) adds another load factor, called a thermal load, to the spars. This thermal load increases the net force felt by the stringers, and thus the area of the stringers must be increased in order for the critical stress requirement to be met.\n\nAnother issue that aerodynamic heating causes for aircraft design is the effect of high temperatures on common material properties. Common materials used in aircraft wing design, such as aluminum and steel, experience a decrease in strength as temperatures get extremely high. The Young’s Modulus of the material, defined as the ratio between stress and strain experienced by the material, decreases as the temperature increases. Young’s Modulus is critical in the selection of materials for wing, as a higher value lets the material resist the yield and shear stress caused by the lift and thermal loads. This is because Young's Modulus is an important factor in the equations for calculating the critical buckling load for axial members and the critical buckling shear stress for skin panels. If the Young’s Modulus of the material decreases at high temperatures caused by aerodynamic heating, then the wing design will call for larger spars and thicker skin segments in order to account for this decrease in strength as the aircraft goes supersonic. There are some materials that retain their strength at the high temperatures that aerodynamic heating induces. For example, Inconel X was used for the wing skins of the X-15, a North American aircraft that flew at hypersonic speeds in 1958. Titanium is another high-strength material, even at high temperatures, and is often used for wing frames of supersonic aircraft. The SR-71 used titanium skin panels painted black to reduce the temperature and corrugated to accommodate expansion. Another important design concept for early supersonic aircraft wings was using a small thickness-to-chord ratio, so that the speed of the flow over the airfoil does not increase too much from the free stream speed. As the flow is already supersonic, increasing the speed even more would not be beneficial for the wing structure. Reducing the thickness of the wing brings the top and bottom stringers closer together, reducing the total moment of inertia of the structure. This increases is axial load in the stringers, and thus the area, and weight, of the stringers must be increased. Some designs for hypersonic missiles have used liquid cooling of the leading edges (usually the fuel en route to the engine). The Sprint missile's heat shield needed several design iterations for Mach 10 temperatures.\n\nHeating caused by the very high reentry speeds (greater than Mach 20) is sufficient to destroy the vehicle unless special techniques are used. The early space capsules such as used on Mercury, Gemini, and Apollo were given blunt shapes to produce a stand-off bow shock, allowing most of the heat to dissipate into the surrounding air. Additionally, these vehicles had ablative material that sublimates into a gas at high temperature. The act of sublimation absorbs the thermal energy from the aerodynamic heating and erodes the material away as opposed to heating the capsule. The surface of the heat shield for the Mercury spacecraft had a coating of aluminum with glassfiber in many layers. As the temperature rose to the layers would evaporate and take the heat with it. The spacecraft would become hot but not harmfully so. The Space Shuttle used insulating tiles on its lower surface to absorb and radiate heat while preventing conduction to the aluminum airframe. The damage to the heat shield during liftoff of Space Shuttle \"Columbia\" contributed to its destruction upon reentry.\n\n"}
{"id": "12706857", "url": "https://en.wikipedia.org/wiki?curid=12706857", "title": "Aircraft specific energy", "text": "Aircraft specific energy\n\nAircraft-specific energy is a form of specific energy applied to aircraft and missile trajectory analysis. It represents the combined kinetic and potential energy of the vehicle at any given time. It is the total energy of the vehicle (relative to the Earth's surface) per unit weight of the vehicle and being independent of the mass of the vehicle provides a powerful tool for the design of optimal trajectories. Aircraft-specific energy is very similar to specific orbital energy except that it is expressed as a positive quantity. A zero value of aircraft-specific energy represents an aircraft at rest on the Earth's surface, and increases as speed and altitude increases. Orbital specific energy is zero at infinite altitude and decreases as one approaches the surface of the earth. As with other forms of specific energy, aircraft-specific energy is an intensive property and is represented in units of length since it is independent of the mass of the vehicle.\n\nThe field of trajectory optimization has made use of the concept since the 1950s in the form of energy analysis. In this approach, the specific energy is defined as one of the dynamic states of the problem and is the slowest varying state. All other states such as altitude and flight path angle are approximated as infinitely fast compared to the specific energy dynamics. This assumption allow the solution of optimal trajectories in a relatively simple form.\n\nThe specific energy is computed by the total energy (as defined above relative the Earth's surface) divided by the mass of the vehicle. It is a key element in performance of aircraft and rockets. For a rocket flying vertically (in a vacuum), it is the apogee that the rocket would obtain. It is used extensively in Energy–maneuverability theory that is used to determine the optimal paths for aircraft in dogfights.\n"}
{"id": "41632653", "url": "https://en.wikipedia.org/wiki?curid=41632653", "title": "Amorgos oil spill", "text": "Amorgos oil spill\n\nThe Amorgos oil spill began on 14 January 2001 near Kenting National Park, off the southern coast of Taiwan. \n\nOn 14 January 2001, the Greek merchant vessel \"Amorgos,\" lost power while en route from India to North China. The carrier was transporting approximately 60,000 tons of iron ore and an estimated 1,000 to 1,150 tons of fuel oil when the ship suffered engine failure near Kenting National Park, off the southernmost tip of Taiwan. The crew subsequently abandoned the ship, and all 25 crew members were rescued by the Coast Guard Administration (CGA) of Taiwan. Due to deteriorating weather and sea conditions, the hull of the \"Amorgos\" split, and oil began to leak from the vessel beginning 18 January 2010.\n\nApproximately 1,300 tons of fuel oil leaked from the \"Amorgos\" into the sea surrounding Kenting National Park, causing major damage to the maritime and local environment.\n\nKenting National Park is an ecological attraction that draws millions of tourists each year due to its warm climate and its many natural phenomena, including limestone caves, monsoon forests and coastal rainforests.\n\nAround 4 to 5 kilometers of the Kenting National Park shoreline was oiled by the spillage, creating a hazardous environment for the 200 bird species and estimated 2,200 plant species within the park. Park officials reported that contaminated coral and dead fish, crabs, shrimp, and clams have washed ashore.\n\nThere were many factors that contributed to the delayed response and subsequent clean-up efforts concerning the \"Amorgos\" incident.\n\nThe spill took place about two months after the Marine Pollution Control Act (MPCA) of Taiwan was publicized. As a result, the spill occurred during a transitional period in which the Ministry of Transportation and Communications (MOTC) and its Salvage Council for Maritime Disasters was delegating its authority to the Environmental Protection Agency (EPA). The jurisdiction among the MOTC, CGA, and the EPA was unclear; therefore, it took longer for the EPA to open an investigation into the spill, allowing more time for the oil to cover a larger area and lay waste to maritime and coastal species.\n\nThe second factor was the observance of the Lunar New Year holidays, making it difficult for companies to hire local residents to clean up the mess. After the 5-day holiday, 40 local workers were hired in addition to 8000 soldiers commissioned to take part in the clean-up operations.\n\nThe third factor was the severe weather conditions that hampered efforts to clean up the oil. As a result, clean-up was restricted to manual retrieval of oil using buckets, hand nets, and scoops.\n\nOf the 1,300 tons of fuel oil that was spilt, some has been lost due to natural dispersion and evaporation by means of severe weather and rough seas. The oil was later emulsified due to the wave patterns which subsequently increased the area and volume of the spill. Despite these occurrences, most of the oil reached the Lungkeng Ecological Preservation Area within the Kenting National Park.\n\nThe affected shoreline consists of fossilized coral and various channels, making access to the oiled areas difficult. As a result, manual collection of oil was the only feasible option. Shoreline clean-up began on 25 January 2010, and lasted until about 14 February 2010, in which an estimated total of 300 tons of oil had been collected.\n\nThe EPA later sued Assuranceforeningen Gard—the Norwegian insurer of the \"Amorgos\" as a result of the damage caused by the oil spill. Instead, the EPA settled with Assuranceforeningen Gard in March 2006, resulting in the ship's owner agreeing to pay a total of NT$34 million ().\n\n"}
{"id": "45715", "url": "https://en.wikipedia.org/wiki?curid=45715", "title": "Arecaceae", "text": "Arecaceae\n\nThe Arecaceae are a botanical family of perennial plants. Their growth form can be climbers, shrubs, trees and stemless plants, all commonly known as palms. Those having a tree form are colloquially called palm trees. They are flowering plants, a family in the monocot order Arecales. Currently 181 genera with around 2600 species are known, most of them restricted to tropical and subtropical climates. Most palms are distinguished by their large, compound, evergreen leaves, known as fronds, arranged at the top of an unbranched stem. However, palms exhibit an enormous diversity in physical characteristics and inhabit nearly every type of habitat within their range, from rainforests to deserts.\n\nPalms are among the best known and most extensively cultivated plant families. They have been important to humans throughout much of history. Many common products and foods are derived from palms. In contemporary times, palms are also widely used in landscaping, making them one of the most economically important plants. In many historical cultures, because of their importance as food, palms were symbols for such ideas as victory, peace, and fertility. For inhabitants of cooler climates today, palms symbolize the tropics and vacations.\n\nWhether as shrubs, trees, or vines, palms have two methods of growth: solitary or clustered. The common representation is that of a solitary shoot ending in a crown of leaves. This monopodial character may be exhibited by prostrate, trunkless, and trunk-forming members. Some common palms restricted to solitary growth include \"Washingtonia\" and \"Roystonea\". Palms may instead grow in sparse though dense clusters. The trunk develops an axillary bud at a leaf node, usually near the base, from which a new shoot emerges. The new shoot, in turn, produces an axillary bud and a clustering habit results. Exclusively sympodial genera include many of the rattans, \"Guihaia\", and \"Rhapis\". Several palm genera have both solitary and clustering members. Palms which are usually solitary may grow in clusters and vice versa. These aberrations suggest the habit operates on a single gene.\nPalms have large, evergreen leaves that are either palmately ('fan-leaved') or pinnately ('feather-leaved') compound and spirally arranged at the top of the stem. The leaves have a tubular sheath at the base that usually splits open on one side at maturity. The inflorescence is a spadix or spike surrounded by one or more bracts or spathes that become woody at maturity. This has been contested in the Flowering Leaf Theory which demonstrates (for most monocots and dicots) that the inflorescence is a modified leaf which bears flowers. The flowers are generally small and white, radially symmetric, and can be either uni- or bisexual. The sepals and petals usually number three each, and may be distinct or joined at the base. The stamens generally number six, with filaments that may be separate, attached to each other, or attached to the pistil at the base. The fruit is usually a single-seeded drupe (sometimes berry-like) but some genera (e.g. \"Salacca\") may contain two or more seeds in each fruit.\n\nLike all monocots, palms do not have the ability to increase the width of a stem (secondary growth) via the same kind of vascular cambium found in non-monocot woody plants. This explains the cylindrical shape of the trunk (almost constant diameter) that is often seen in palms, unlike in ring-forming trees. However, many palms, like some other monocots, do have secondary growth, although because it does not arise from a single vascular cambium producing xylem inwards and phloem outwards, it is often called \"anomalous secondary growth\".\n\nThe Arecaceae are notable among monocots for their height and for the size of their seeds, leaves, and inflorescences. \"Ceroxylon quindiuense\", Colombia's national tree, is the tallest monocot in the world, reaching up to 60 m tall. The \"coco de mer\" (\"Lodoicea maldivica\") has the largest seeds of any plant, 40–50 cm in diameter and weighing 15–30 kg each. Raffia palms (\"Raphia\" spp.) have the largest leaves of any plant, up to 25 m long and 3 m wide. The \"Corypha\" species have the largest inflorescence of any plant, up to 7.5 m tall and containing millions of small flowers. \"Calamus\" stems can reach 200 m in length.\n\nMost palms are native to tropical and subtropical climates. Palms thrive in moist and hot climates but can be found in a variety of different habitats. Their diversity is highest in wet, lowland forests. South America, the Caribbean, and areas of the south Pacific and southern Asia are regions of concentration. Colombia may have the highest number of palm species in one country. There are some palms that are also native to desert areas such as the Arabian peninsula and parts of northwestern Mexico. Only about 130 palm species naturally grow entirely beyond the tropics, mostly in humid lowland subtropical climates, in highlands in southern Asia, and along the rim lands of the Mediterranean Sea. The northernmost native palm is \"Chamaerops humilis\", which reaches 44°N latitude in along the coast of southern France. In the southern hemisphere, the southernmost palm is the \"Rhopalostylis sapida\", which reaches 44°S on the Chatham Islands where an oceanic climate prevails. Cultivation of palms is possible north of subtropical climates, and some higher latitude locals such as Ireland, Scotland, England, and the Pacific Northwest feature a few palms in protected locations.\n\nPalms inhabit a variety of ecosystems. More than two-thirds of palm species live in humid moist forests, where some species grow tall enough to form part of the canopy and shorter ones form part of the understory. Some species form pure stands in areas with poor drainage or regular flooding, including \"Raphia hookeri\" which is common in coastal freshwater swamps in West Africa. Other palms live in tropical mountain habitats above 1000 m, such as those in the genus \"Ceroxylon\" native to the Andes. Palms may also live in grasslands and scrublands, usually associated with a water source, and in desert oases such as the date palm. A few palms are adapted to extremely basic lime soils, while others are similarly adapted to extreme potassium deficiency and toxicity of heavy metals in serpentine soils.\n\nPalms are a monophyletic group of plants, meaning the group consists of a common ancestor and all its descendants. Extensive taxonomic research on palms began with botanist H.E. Moore, who organized palms into 15 major groups based mostly on general morphological characteristics. The following classification, proposed by N.W. Uhl and J. Dransfield in 1987, is a revision of Moore's classification that organizes palms into six subfamilies.\n\n\nA few general traits of each subfamily are listed below.\n\nThe Coryphoideae are the most diverse subfamily, and are a paraphyletic group, meaning all members of the group share a common ancestor, but the group does not include all the ancestor's descendants. Most palms in this subfamily have palmately lobed leaves and solitary flowers with three, or sometimes four carpels. The fruit normally develops from only one carpel.\n\nSubfamily Calamoideae includes the climbing palms, such as rattans. The leaves are usually pinnate; derived characters (synapomorphies) include spines on various organs, organs specialized for climbing, an extension of the main stem of the leaf-bearing reflexed spines, and overlapping scales covering the fruit and ovary.\n\nSubfamily Nypoideae contains only one species, \"Nypa fruticans\", which has large, pinnate leaves. The fruit is unusual in that it floats, and the stem is dichotomously branched, also unusual in palms.\n\nSubfamily Ceroxyloideae has small to medium-sized flowers, spirally arranged, with a gynoecium of three joined carpels.\n\nThe Arecoideae are the largest subfamily, with six diverse tribes (Areceae, Caryoteae, Cocoseae, Geonomeae, Iriarteeae, and Podococceae) containing over 100 genera. All tribes have pinnate or bipinnate leaves and flowers arranged in groups of three, with a central pistillate and two staminate flowers.\n\nThe Phytelephantoideae are a monoecious subfamily. Members of this group have distinct monopodial flower clusters. Other distinct features include a gynoecium with five to 10 joined carpels, and flowers with more than three parts per whorl. Fruits are multiple-seeded and have multiple parts.\n\nCurrently, few extensive phylogenetic studies of the Arecaceae exist. In 1997, Baker\" et al.\" explored subfamily and tribe relationships using chloroplast DNA from 60 genera from all subfamilies and tribes. The results strongly showed the Calamoideae are monophyletic, and Ceroxyloideae and Coryphoideae are paraphyletic. The relationships of Arecoideae are uncertain, but they are possibly related to the Ceroxyloideae and Phytelephantoideae. Studies have suggested the lack of a fully resolved hypothesis for the relationships within the family is due to a variety of factors, including difficulties in selecting appropriate outgroups, homoplasy in morphological character states, slow rates of molecular evolution important for the use of standard DNA markers, and character polarization. However, hybridization has been observed among \"Orbignya\" and \"Phoenix\" species, and using chloroplast DNA in cladistic studies may produce inaccurate results due to maternal inheritance of the chloroplast DNA. Chemical and molecular data from non-organelle DNA, for example, could be more effective for studying palm phylogeny.\n\n\nThe Arecaceae are the first modern family of monocots appearing in the fossil record around 80 million years ago (Mya), during the late Cretaceous period. The first modern species, such as \"Nypa fruticans\" and \"Acrocomia aculeata\", appeared 94 Mya, confirmed by fossil \"Nypa\" pollen dated to 94 Mya. Palms appear to have undergone an early period of adaptive radiation. By 60 Mya, many of the modern, specialized genera of palms appeared and became widespread and common, much more widespread than their range today. Because palms separated from the monocots earlier than other families, they developed more intrafamilial specialization and diversity. By tracing back these diverse characteristics of palms to the basic structures of monocots, palms may be valuable in studying monocot evolution. Several species of palms have been identified from flowers preserved in amber, including \"Palaeoraphe dominicana\" and \"Roystonea palaea\". Evidence can also be found in samples of petrified palmwood.\n\nHuman use of palms is as old or older than human civilization itself, starting with the cultivation of the date palm by Mesopotamians and other Middle Eastern peoples 5000 years or more ago. Date wood, pits for storing dates, and other remains of the date palm have been found in Mesopotamian sites. The date palm had a tremendous effect on the history of the Middle East. W.H. Barreveld wrote:\n\nAn indication of the importance of palms in ancient times is that they are mentioned more than 30 times in the Bible, and at least 22 times in the Quran.\n\nArecaceae have great economic importance, including coconut products, oils, dates, palm syrup, ivory nuts, carnauba wax, rattan cane, raffia, and palm wood.\n\nAlong with dates mentioned above, members of the palm family with human uses are numerous.\n\n\nLike many other plants, palms have been threatened by human intervention and exploitation. The greatest risk to palms is destruction of habitat, especially in the tropical forests, due to urbanization, wood-chipping, mining, and conversion to farmland. Palms rarely reproduce after such great changes in the habitat, and those with small habitat ranges are most vulnerable to them. The harvesting of heart of palm, a delicacy in salads, also poses a threat because it is derived from the palm's apical meristem, a vital part of the palm that cannot be regrown (except in domesticated varieties, e.g. of peach palm). The use of rattan palms in furniture has caused a major population decrease in these species that has negatively affected local and international markets, as well as biodiversity in the area. The sale of seeds to nurseries and collectors is another threat, as the seeds of popular palms are sometimes harvested directly from the wild. At least 100 palm species are currently endangered, and nine species have reportedly recently become extinct.\n\nHowever, several factors make palm conservation more difficult. Palms live in almost every type of warm habitat and have tremendous morphological diversity. Most palm seeds lose viability quickly, and they cannot be preserved in low temperatures because the cold kills the embryo. Using botanical gardens for conservation also presents problems, since they can only house a few plants of any species or truly imitate the natural setting. Also, the risk of cross-pollination can lead to hybrid species.\n\nThe Palm Specialist Group of the World Conservation Union (IUCN) began in 1984, and has performed a series of three studies to find basic information on the status of palms in the wild, use of wild palms, and palms under cultivation. Two projects on palm conservation and use supported by the World Wildlife Fund took place from 1985 to 1990 and 1986–1991, in the American tropics and southeast Asia, respectively. Both studies produced copious new data and publications on palms. Preparation of a global action plan for palm conservation began in 1991, supported by the IUCN, and was published in 1996.\n\nThe rarest palm known is \"Hyophorbe amaricaulis\". The only living individual remains at the Botanic Gardens of Curepipe in Mauritius.\n\nPests that attack a variety of species of palm trees include:\n\nThe palm branch was a symbol of triumph and victory in pre-Christian times. The Romans rewarded champions of the games and celebrated military successes with palm branches. Early Christians used the palm branch to symbolize the victory of the faithful over enemies of the soul, as in the Palm Sunday festival celebrating the triumphal entry of Jesus into Jerusalem. In Judaism, the palm represents peace and plenty, and is one of the Four Species of Sukkot; the palm may also symbolize the Tree of Life in Kabbalah.\n\nPanaiveriyamman was an ancient Tamil tree deity related to fertility. Named after \"panai\", the Tamil name for the Palmyra palm, she was also known as Taalavaasini, a name that further related her to all types of palms.\n\nToday, the palm, especially the coconut palm, remains a symbol of the tropical island paradise.\nPalms appear on the flags and seals of several places where they are native, including those of Haiti, Guam, Saudi Arabia, Florida, and South Carolina.\n\nSome species commonly called palms, though they are not true palms, include:\n\n\n"}
{"id": "8378445", "url": "https://en.wikipedia.org/wiki?curid=8378445", "title": "Australian Coal Association", "text": "Australian Coal Association\n\nThe Australian Coal Association (ACA) is the major Australian coal mining industry lobby group. It represents the black coal producers of New South Wales and Queensland and consists of a number of relatively small coal mining companies or subsidiaries of larger corporations in those two states. Australia is the world's largest coal exporter, and black coal is Australia's second largest commodity export, worth more than A$24 billion in the financial year ending June 2008, and $46 billion, or nearly double this amount, for the corresponding calendar year ending December. Black coal provides around 57 per cent of Australia's grid-connected electricity (brown coal around 24%) and is vital for major industries such as steel making and cement manufacture.\n\nOn 23 August 2013, the Australian Coal Association released a statement that it will be subsumed into the Minerals Council of Australia.\n\nThe Australian Coal Association acknowledges that 34 per cent of Australia's greenhouse gas emissions come from burning black and brown coal, primarily for the generation of electricity, but also for steel-making and cement manufacture. In 2003, the coal industry established the COAL21 initiative, bringing together the coal and electric power industries, unions, federal and state governments, and research organisations. Supported through a voluntary company levy, the $1 billion+ commitment will support research, development and demonstration of low-emissions coal technologies. Australia is at the forefront of the development of these technologies. To date, the COAL21 Fund has made commitments of more than $500 million to a number of active and in-development carbon capture and storage research projects. However, critics of the ACA have argued that “no other economy is as dependent on coal exports as ours, so why would anyone else feel the same imperative to lead?” \n\n"}
{"id": "53319292", "url": "https://en.wikipedia.org/wiki?curid=53319292", "title": "Ballycrovane Ogham Stone", "text": "Ballycrovane Ogham Stone\n\nBallycrovane Ogham Stone (CIIC 66) is a ogham stone and National Monument located in County Cork, Ireland.\n\nBallycrovane Ogham Stone stands in a field east-southeast of Ardgroom, overlooking Kenmare Bay.\n\nThis is the tallest known Ogham stone in the world, carved in the 4th–6th century AD.\n\nBallycrovane Ogham Stone is a pillar of stone measuring 470 × 102 × 32 cm and has Ogham carvings incised on two edges. (, \"of Mac-Deichet Uí Thorna\") is carved on it.\n"}
{"id": "619320", "url": "https://en.wikipedia.org/wiki?curid=619320", "title": "Chemical ecology", "text": "Chemical ecology\n\nChemical ecology examines the role of chemical interactions between living organisms and their environment, and the consequences of those interactions on the ethology and evolution of the organisms involved. It is thus a vast and highly interdisciplinary field. Chemical ecology studies focus on the biochemistry of ecology and the specific molecules or groups of molecules that function as signals to initiate, modulate, or terminate a variety of biological processes such as metabolism. Molecules that serve in such roles typically are readily diffusible organic substances of low molecular mass that derive from secondary metabolic pathways, but also include peptides. Chemical ecological processes mediated by semiochemicals may be intraspecific (occurring within a species) or interspecific (occurring between species).\n\nThe field relies on analytical and synthetic chemistry, protein chemistry, genetics, neurobiology, ecology, and evolution.\n\nChemical ecology in plants is the study that integrates the chemistry and biological properties of the plants and their interaction with the environment (i.e. microorganisms, phytophagous insects) and their antagonists. Chemical ecology in plants mainly focuses on how plants fight against herbivory by producing various phytochemical compounds. This results from the chemistry of the plants and also various chemical relationships that plants with other subgroups such as fungi and bacteria through various symbiotic relationships.\n\nThe surface of the primary aerial parts of terrestrial plants is covered by a thin waxy structure known as the cuticle, which has the crucial autecological functions and also plays an important role as an interface in trophic interactions. The cuticle is composed of the cuticular layer and the cuticle proper, which is covered by epicuticular waxes. Whereas the cutin fraction is a polyester-type biopolymer composed of hydroxyl and hydroxy epoxy fatty acids, the cuticular waxes are a complex mixture of long-chain aliphatic and cyclic compounds. These highly lipophilic compounds determine the hydrophobic quality of the plant surface and together with the microstructure of the waxes, vary in a species-specific manner. The physiochemical characteristics contribute to certain optical features, limit transpiration and influence adhesion of particles and organisms, and as a result prevents it from undergoing wilting. Apart from that the cuticle acts like a skin for plants which prevents any mechanical damage to them from the external sources which either living organisms or any other abiotic component.\n\nThere are various ways in which chemical ecology can be evidenced in plants, such as the relationship between fungi and plants is called mycorrhizae. Fungi produces a chemical which decomposes organic matter to which enable the plant roots to increase its surface area to obtain to those nutrients through the help of the root hairs. \n\nThe most important thing that makes it possible for microorganisms to interact with the plants is their ability to establish themselves on the plants surface. In order for the living organisms to establish onto the surface of the plants they need to break the hydrophobic layer of the plant. To do this, the microorganisms secrete special fluids which break down the fats from the cuticle. As a result they are able to establish themselves over the surface.\n\nMost of the hormones in plants are concentrated on their tips. The auxin hormones are responsible for growth of plants and are stimulated by certain stimulus such as light. This phenomenon is called phototropism. This growth enables the plant to obtain essentials such as sunlight which is very necessary for the photosynthesis. Therefore, the cuticle is one of the fundamental parts of the plant due to its physical and chemical properties such as waxy and thin like structure that enables it to be adapted to various mechanism such as hydrophobicity, interactions with microorganisms and growth of plants.\n\nThe chemical ecology of plant-insect interaction is a significant subfield of chemical ecology. In particular, plants and insects are often involved in a chemical evolutionary arms race. As plants develop chemical defences to herbivory, insects which feed on them evolve immunity to these poisons, and in some cases, re-purpose these poisons for their own chemical defence against predators. One of the more well-known examples of this is the monarch butterfly, the caterpillars of which feed on the milkweed plant. Milkweeds contain cardenolide toxins, but monarch butterfly caterpillars have evolved to remain unaffected by the toxin. Instead, they sequester the toxins during their larval stage and the poison remains in the adult, making it unpalatable to predators. Many other such examples of this exist, including \"Manduca sexta\" (hawkmoth) caterpillars which actively sequester nicotine found in the tobacco plant; and the Bella moth, which secrets a quinone-containing froth from its head when disturbed by a potential predator obtained from feeding on \"Crotalaria\" species as a caterpillar.\n\nMarine Chemical Ecology is how organic life in the marine environment use chemicals to eat, interact, reproduce and survive, ranging from microscopic phytoplankton to the many species of crustaceans, sponges, coral and fish.\n\nThe use of chemicals are often used a means of survival for marine organisms. Some crustaceans and mesograzers use particular algae and seaweeds as a means of deterrence by covering their bodies in the these plants. These plants produce alcohols such as pachydictyol-A and dictyol-E, which prevent the predation of the crustacean. When this seaweed is absent, or another seaweed without these alcohols are worn, the rate that these crustaceans are eaten is much higher. Other crustaceans use their natural defences in conjuncture with produced chemicals to defend themselves. Chemicals within their urine help coordinate them into groups. This combined with their spikes make them a much harder target for predators. Others secrete mucus or toxins that make it difficult for predators to eat them, such as the Pardachirus marmoratus that use a toxin capable of paralyzing the jaws of a would-be predator. Simply being a certain colour can serve as a defence mechanism, such as some zoanthids displaying a wide range of colours. This suggests that they may be toxic to eat, whether they are or not.\n\nThe release of chemicals are very important to coordinate marine organisms to reproduce. Some processes are relatively simple, such as attracting one individual to another. Male lampreys attract ovulating females by emitting a bile that can be detected many metres downstream. Other processes can be more complex, such as the mating habits of crabs. Due to the fact that mating can only be done shortly after the female moults from her shell, pheromones are produced before and after the moulting process. Male crabs will find and defend the potential mate until the shell has moulted. However due to the cabalistic tendencies of crabs, an additional pheromone is produced to suppresses this urge.\n\nDetermining dominance among crustaceans are very closely tied to chemical cues. When crustaceans fight to determine dominance they release urine, which helps to determine the victor. After a fight as concluded both individuals will recognize each other in the future through urine, remembering who is the dominant of the two and thereby avoiding a fight. This can also have an impact on future fights. When an individual is exposed to the urine of a dominant crustacean they will act more submissive, and the opposite effect when they are exposed to the urine of a subdominant individual. When individuals are unable to communicate through urine fights can be more unpredictable, resulting in longer fights. \n\n\n\n"}
{"id": "673768", "url": "https://en.wikipedia.org/wiki?curid=673768", "title": "Continental crust", "text": "Continental crust\n\nContinental crust is the layer of igneous, sedimentary, and metamorphic rocks that forms the continents and the areas of shallow seabed close to their shores, known as continental shelves. This layer is sometimes called \"sial\" because its bulk composition is richer in silicates and aluminium minerals and has a lower density compared to the oceanic crust, called \"sima\" which is richer in magnesium silicate minerals and is denser. Changes in seismic wave velocities have shown that at a certain depth (the Conrad discontinuity), there is a reasonably sharp contrast between the more felsic upper continental crust and the lower continental crust, which is more mafic in character.\n\nThe continental crust consists of various layers, with a bulk composition that is intermediate to felsic. The average density of continental crust is about 2.7 g/cm, less dense than the ultramafic material that makes up the mantle, which has a density of around 3.3 g/cm. Continental crust is also less dense than oceanic crust, whose density is about 2.9 g/cm. At 25 to 70 km, continental crust is considerably thicker than oceanic crust, which has an average thickness of around 7–10 km. About 40% of Earth's surface is currently occupied by continental crust.\nIt makes up about 70% of the volume of Earth's crust.\n\nBecause the surface of continental crust mainly lies above sea level, its existence allowed land life to evolve from marine life. Its existence also provides broad expanses of shallow water known as epeiric seas and continental shelves where complex metazoan life could become established during early Paleozoic time, in what is now called the Cambrian explosion.\n\nAll continental crust ultimately derives from the fractional differentiation of oceanic crust over many millions of years. This process has occurred, and continues to occur today, primarily as a result of the volcanism associated with subduction.\n\nThere is little evidence of continental crust prior to 3.5 Ga. About 20% of the continental crust's current volume was formed by 3.0 Ga. There was relatively rapid development on shield areas consisting of continental crust between 3.0 and 2.5 Ga. During this time interval, about 60% of the continental crust's current volume was formed. The remaining 20% has formed during the last 2.5 Ga.\n\nIn contrast to the persistence of continental crust, the size, shape, and number of continents are constantly changing through geologic time. Different tracts rift apart, collide and recoalesce as part of a grand supercontinent cycle.\nThere are currently about 7 billion cubic kilometers of continental crust, but this quantity varies because of the nature of the forces involved. The relative permanence of continental crust contrasts with the short life of oceanic crust. Because continental crust is less dense than oceanic crust, when active margins of the two meet in subduction zones, the oceanic crust is typically subducted back into the mantle. Continental crust is rarely subducted (this may occur where continental crustal blocks collide and overthicken, causing deep melting under mountain belts such as the Himalayas or the Alps). For this reason the oldest rocks on Earth are within the cratons or cores of the continents, rather than in repeatedly recycled oceanic crust; the oldest intact crustal fragment is the Acasta Gneiss at 4.01 Ga, whereas the oldest oceanic crust (located on the Pacific Plate offshore of Kamchatka) is from the Jurassic (~180 Ma). Continental crust and the rock layers that lie on and within it are thus the best archive of Earth's history.\n\nThe height of mountain ranges is usually related to the thickness of crust. This results from the isostasy associated with orogeny (mountain formation). The crust is thickened by the compressive forces related to subduction or continental collision. The buoyancy of the crust forces it upwards, the forces of the collisional stress balanced by gravity and erosion. This forms a keel or mountain root beneath the mountain range, which is where the thickest crust is found.\nThe thinnest continental crust is found in rift zones, where the crust is thinned by detachment faulting and eventually severed, replaced by oceanic crust. The edges of continental fragments formed this way (both sides of the Atlantic Ocean, for example) are termed passive margins.\n\nThe high temperatures and pressures at depth, often combined with a long history of complex distortion, cause much of the lower continental crust to be metamorphic - the main exception to this being recent igneous intrusions. Igneous rock may also be \"underplated\" to the underside of the crust, i.e. adding to the crust by forming a layer immediately beneath it.\n\nContinental crust is produced and (far less often) destroyed mostly by plate tectonic processes, especially at convergent plate boundaries. Additionally, continental crustal material is transferred to oceanic crust by sedimentation. New material can be added to the continents by the partial melting of oceanic crust at subduction zones, causing the lighter material to rise as magma, forming volcanoes. Also, material can be accreted horizontally when volcanic island arcs, seamounts or similar structures collide with the side of the continent as a result of plate tectonic movements. Continental crust is also lost through erosion and sediment subduction, tectonic erosion of forearcs, delamination, and deep subduction of continental crust in collision zones.\nMany theories of crustal growth are controversial, including rates of crustal growth and recycling, whether the lower crust is recycled differently from the upper crust, and over how much of Earth history plate tectonics has operated and so could be the dominant mode of continental crust formation and destruction.\n\nIt is a matter of debate whether the amount of continental crust has been increasing, decreasing, or remaining constant over geological time. One model indicates that at prior to 3.7 Ga ago continental crust constituted less than 10% of the present amount.\nBy 3.0 Ga ago the amount was about 25%, and following a period of rapid crustal evolution it was about 60% of the current amount by 2.6 Ga ago. The growth of continental crust appears to have occurred in \"spurts\" of increased activity corresponding to five episodes of increased production through geologic time.\n\n\n\n"}
{"id": "494759", "url": "https://en.wikipedia.org/wiki?curid=494759", "title": "David McTaggart", "text": "David McTaggart\n\nDavid Fraser McTaggart (June 24, 1932 – March 23, 2001) was a Canadian-born environmentalist who played a central part in the foundation of Greenpeace International.\n\nAn excellent all-around athlete, as a young man he won three consecutive Canadian National Badminton Championships in men's singles (1956–1958) and represented that country in badminton's Thomas Cup (men's world team championship) competition. Prior to his involvement in Greenpeace he had prospered as a builder and developer.\n\nIn 1972, responding to an ad in the newspapers, he used his personal boat to protest the testing of nuclear weapons in the Pacific by the French government. After getting his boat damaged and being physically hurt by the French Military, his protest succeeded in 1974 when the French announced the end of their atmospheric nuclear testing program. McTaggart spent the next several years pursuing legal action against the French government and assisting in the formation of Greenpeace affiliates across Western Europe. In 1979 he brokered an agreement that led to the formation of Greenpeace International, ending the leadership of the original founding group based in Vancouver, Canada.\nHe became chairman and chief spokesman for Greenpeace in 1979, retiring in 1991 to live on an olive farm in Paciano, Umbria, Italy.\nMcTaggart continued to participate in Greenpeace forums after retirement for the rest of his life. He and singer Bryan Adams did a massive postcard campaign to help create the Southern Antarctic Whale Sanctuary. For nearly two years they toured the world asking thousands of concert goers to write to countries involved with whaling to support the sanctuary.\nThe Southern Ocean Whale Sanctuary was established by the IWC in 1994 with 23 countries supporting the agreement and Japan opposing it.\n\nTe Vaka dedicated its song \"Sei Ma Le Losa\" to McTaggart, who was killed in a car accident on March 23, 2001, near his home in Italy.\n\nIn 1987 McTaggart founded the Third Millennium Foundation, a US 501(c)(3) dedicated to continuing his work for disarmament, peace, and a sustainable future. The foundation, headquartered in his former home in Paciano, Italy, continues today promoting local and global projects in his memory.\n\n\n"}
{"id": "34995146", "url": "https://en.wikipedia.org/wiki?curid=34995146", "title": "Dieudonné plank", "text": "Dieudonné plank\n\nIn mathematics, the Dieudonné plank is a specific topological space introduced by . It is an example of a metacompact space that is not paracompact.\n\n"}
{"id": "4224120", "url": "https://en.wikipedia.org/wiki?curid=4224120", "title": "Dioscorea oppositifolia", "text": "Dioscorea oppositifolia\n\nDioscorea oppositifolia is a type of yam (\"Dioscorea\") native to Myanmar (Burma) and to the Indian Subcontinent (India, Sri Lanka, Bangladesh).\n\nThe plant previously called \"D. opposita\" is now considered to be the same species as \"D. oppositifolia\". However \"Dioscorea polystachya\" is often incorrectly called \"Dioscorea opposita\" as well. Botanical works that point out that error may list, e.g., \"Dioscorea opposita\" auct. non Thunb. as a synonym of \"D. polystachya\".\n\n\n"}
{"id": "32511182", "url": "https://en.wikipedia.org/wiki?curid=32511182", "title": "Elasto-plastic self-consistent modeling", "text": "Elasto-plastic self-consistent modeling\n\nElasto-plastic self-consistent modeling, shortened EPSC, is a method of modeling often used in materials science.\n"}
{"id": "19001916", "url": "https://en.wikipedia.org/wiki?curid=19001916", "title": "Electricity sector in Paraguay", "text": "Electricity sector in Paraguay\n\nParaguay is one of the few countries in Latin America that has maintained an integrated public monopoly on electricity. Hydropower comprises nearly 100 percent of electricity in Paraguay; 90 percent of generated energy is exported, with neighboring Argentina and Brazil receiving the majority. Paraguay is one of the world’s largest electricity net exporters.\n\nBecause of the dominance of hydroelectricity, tariffs (mostly residential) are remarkably below the averages for the region. However, despite the abundance of resources, the Paraguayan electricity system faces difficulty due to the lack of investment in transmission and distribution networks. In addition, distribution losses are among the highest in the region.\n\nParaguay is the only country in Latin America with almost 100 percent hydroelectric generation capacity (8,116 MW) in 2005.\n\nParaguay operates two binational hydroelectric dams. Itaipu dam, by far the largest power station in the country, is operated with \nBrazil and has an installed capacity of 7000 MW (86 percent of Paraguay's generation capacity). Yacyretá, the second largest hydroelectric facility, has an installed capacity of 900 MW (11 percent), and is operated with Argentina. A third plant, Acaray has an installed capacity of 210 MW (3 percent). Thermal plants contribute less than 0.1 percent.\n\nAll of Paraguay's electricity for domestic consumption comes from a single facility, the binational 14 GW Itaipu hydroelectric dam.\n\"Source\": ESMAP, 2006. Installed capacity shown for Itaipu and Yacyretá refers only to the Parguayan share in these plants.\n\nWhile total generation amounted to 51.17 TWh in 2005, consumption was only 5.01 TWh, with exports as high as 43.8 TWh.\n\nIn 2005, total electricity consumed in Paraguay was 5.01 TWh, which corresponds to 849 kWh per capita. Electricity generated by Itaipu and Acaray, located in the East of the country, is transported to the West (to the Asunción area), where over 60% of the total national consumption is located.\n\nElectricity consumption by consumer group is divided as follows:\n\n\nIn 2004, the country consumed only 16% of its 50% share of Itaipu’s production, exporting the rest to Brazil. As for Yacyreta, Paraguay consumes less than 1% of its share, exporting the rest to Argentina.\n\nThe electricity interconnections that allow power exchanges with Brazil and Argentina are:\n\"Source\": ESMAP, 2006\n\nIn 2005, almost 90% of the population in Paraguay had access to electricity, which is just slightly below than the 94.6% average for LAC \n\nThe 2002 Census revealed that 87% of the households without electricity were located in rural areas, where access was about 77%. Rural coverage varies considerably among the different regions of the country. It is lowest in the remote and sparsely populated Chaco, or Western region. The table below shows rural coverage by Department for 2002:\n\nSee also:Departments of Paraguay(including a map)\n\n\"Source\": Pulfer, 2005 (from 2002 Census)\n\nSince 2004, the National Electricity Administration (ANDE) has been carrying out a Program to Recover Distribution Works under the Self-Help System (\"Sistema de Autoayuda\"), which aims at the regularization of all the low and medium voltage distribution networks. This program, with a 10-year time-horizon, is implemented according to priorities defined by the conservation status of the networks involved. Under this program, installations that do not comply with current ANDE's rules are replaced.\n\nIn 2005, the average number of interruptions per subscriber was 16.4, while duration of interruptions per subscriber was 7.58 hours. While the number of interruptions is just slightly above than the weighted average for LAC, 13 interruptions, the duration is well below the weighted average of 14 hours.\n\nDespite consuming less than 6 TWh per year and exporting close to 45 TWh per year, Paraguay faces blackouts as well as a serious risk of suffering an energy crisis. This is the result of the limitations of both the transmission and distribution systems. The ceiling of the system is placed by ANDE’s at 1,700 MW, with demand above 1,500 MW in 2008. Transmission capacity is urgently needed to avoid a supply crisis in a system in which quality and an adequate technical service is practically nonexistent.\n\nDifferent authors believe that the price received for the electricity sold to Brazil (from Paraguay’s share in Itaipu) and also to Argentina to some extent (from its share in Yacyreta) is currently too low. The “fair price” established by the Itaipu Treaty was conceived on the basis of a “compensation for concession of energy” and not on the basis of a commercial exchange. This price has remained very low (about US$2.81 per MWh). It is argued that, if this price was more in line with actual electricity prices in the Brazilian market, Paraguay would have enough resources to strengthen its electricity transmission capacity.\n\nIn 2005, distribution losses in Paraguay were has high as 31%, well above the 13.5% weighted average for LAC and up from about 22% in 2001 \n\nSystem losses have become a serious problem in the last few years, having followed a continuous upward trend. The highest percentage of losses occurs in the National Interconnected System (SIN), while the remaining corresponds to the bi-national enterprises. In the SIN, distribution losses represented 23% of the total in 2003, while transmission losses, according to ANDE, were 7.3%. ANDE has established a 23% target for electricity losses for the year 2010.\n\nResponsibilities in the Paraguayan electricity sector are concentrated in a single, vertically integrated public monopoly, the National Electricity Administration (\"Administración Nacional de Electricidad\", ANDE).\n\nLaw 167/93 indicates that the Vice ministry of Mines and Energy (under the Ministry of Public Works and Communication) is responsible for establishing and guiding energy policy, as well as for the study of the technical, economic, financial and legal aspects that promote energy use. However, the Vice ministry does not have the adequate resources to effectively perform its functions.\n\nIn practice, all the energy responsibilities are concentrated in ANDE, which is the \"de facto\" electricity regulator and provider. ANDE also elaborates the tariff structure, which is then analyzed and approved by the Economic Council of the Executive Power. The Council usually sets lower tariffs to the ones proposed by ANDE, which leads to a lack of resources for the necessary investment for adequate performance of the electricity system.\n\nANDE controls the country’s entire electricity market, including generation, transmission and distribution. ANDE operates only one hydroelectric dam, Acaray, and six thermal power plants, with total installed capacity of 220 MW. It is also responsible for Paraguay’s share of Itaipú and Yacyretá, the two bi-national hydroelectric facilities (See bi-national facilities above).\n\nANDE operates 2,100 miles of transmission lines in the Interconnected National System, divided in 6 subsystems, and 670 miles of distribution lines. It is also responsible for all of the distribution, with two exceptions: CLYFSA (\"Compañía de Luz y Fuerza, S.A.\"), which has a concession to distribute and commercialize electricity in Villarrica, and the \"Empresas Distribuidoras Menonitas del Chaco Central\".\n\nIn April 1973, the governments of Paraguay and Brazil signed the Itaipu Treaty, by which it was decided to create a binational entity to hydroelectric use of the Paraná River. This entity was constituted by ANDE (Paraguay) and ELECTROBRAS (Brazil). US$100 million were contributed in equal parts by both companies.\n\nIn December 1973, the governments of Argentina and Paraguay signed the Yacyreta Treaty, by which ANDE and \"Agua y Energía\" constituted the Binational Entity, whose aim is the hydroelectric use of the Paraná river. US$100 million was contributed in equal parts by each company.\n\nIn 1971, Paraguay and Argentina created the River Parana Joint Commission (\"Comisión Mixta del Río Paraná\", COMIP), which started to carry out different studies (pre-feasibility, environmental, etc.) for the Corpus project, to be located upstream of the Paraná river, close to the towns of Corpus (in the Argentina Misiones Province and Puerto Bella Vista in Paraguay. In the mid-1980s, Argentina, Paraguay and Brazil signed a tripartite agreement that established the operating height of the project, which would allow to bring into line the operation of Corpus with those of Yacyreta and Itaipu.\nThe different alternatives for this project are still under study. As a large hydroelectric project, with installed capacity of about 3,000 MW and annual generation of about 19,000 GWh, Corpus is a controversial project that is opposed both at the regional and social levels. In April 1996, in a plebiscite in the Misiones Province, the construction of the dam was opposed by almost 89% of the voters.\n\nIn 2006, the average national tariff in Paraguay was US$0.080 per kWh Tariffs for the different consumer groups were:\n\n\nIn November 2004, the Paraguayan Government approved Law 2,501, which broadened the electricity social tariff applied by ANDE. The social tariff is applied to residential users below 150kWh of monthly consumption. Currently, about 37% of total customers benefit from this tariff. ANDE estimates that this share will gradually increase to 56% of the total.\n\nInvestments for maintenance and expansion of the necessary assets to provide electricity service have been executed with the support of multilateral credit institutions.\n\nThe National Electricity Administration (\"Administración Nacional de Electricidad\", ANDE), Paraguay’s state-owned utility, controls the country’s entire electricity market, including generation, transmission and distribution.\n\nTwo small companies buy electricity from ANDE and have concessions to distribute and sell it: CLYFSA (Compañía de Luz y Fuerza, S.A.) in Villarrica, and the \"Empresas Distribuidoras Menonitas del Chaco Central\".\n\nThe Environmental Directorate (\"Secretaría del Ambiente\", SEAM) is the institution in charge of environmental issues in Paraguay, focusing on natural resources management and preservation.\n\nParaguay emitted 3.85 million tons of CO2 in 2005, which corresponds to just 0.61 tCO2 per capita annually, the lowest rate in the LAC region after Haiti’s.\n\nCurrently (August 2008), there are no registered CDM projects in any sector in Paraguay. The low emission factor of a fully hydroelectric system is most likely the reason for the absence of this type of projects in the electricity sector.\n\nCurrently, the Inter-American Development Bank (IDB) is contributing funds and assistance to one project in the electricity sector in Paraguay:\n\n\nThe IDB is also providing technical assistance under two activities:\n\n\nCasco Carreras, 2008. \"Presente y Futuro del Sector Energético Nacional\". Centro de Análisis y Difusión de la Economía Paraguaya\n\nESMAP, 2006. \"Estrategia para el desarrollo del sector eléctrico del Paraguay\".\n\nSuarez Montorfano, 2007. \"El Proyecto hidroeléctrico Corpus Christi\"\n\n"}
{"id": "34296669", "url": "https://en.wikipedia.org/wiki?curid=34296669", "title": "Exciton-polaritons", "text": "Exciton-polaritons\n\nExciton-polaritons are a type of polaritons, hybrid light and matter quasiparticles arising from the strong coupling of the electromagnetic dipolar oscillations of excitons (either in bulk or quantum wells) and photons.\n\nThe coupling of the two oscillators, photons modes in the semiconductor optical microcavity and excitons of the quantum wells, results in the energy anticrossing of the bare oscillators, giving rise to the two new normal modes for the system, known as the upper and lower polariton resonances (or branches). The energy shift is proportional to the coupling strength (dependent, e.g., on the field and polarization overlaps). The higher energy or upper mode (UPB, upper polariton branch) is characterized by the photonic and exciton fields oscillating in-phase, while the LPB (lower polariton branch) mode is characterized by them oscillating with phase-opposition. Microcavity exciton-polaritons inherit some properties from both of their roots, such as a light effective mass (from the photons) and a capacity to interact with each other (from the strong exciton nonlinearities) and with the environment (including the internal phonons, which provide thermalization, and the outcoupling by radiative losses). In most cases the interactions are repulsive, at least between polariton quasi-particles of the same spin type (intra-spin interactions) and the nonlinearity term is positive (increase of total energy, or blueshift, upon increasing density).\n\nPolaritons are also characterized by non-parabolic energy-momentum dispersion relations, which limit the validity of the parabolic effective-mass approximation to a small range of momenta\nThey also have a spin degree-of-freedom, making them spinorial fluids able to sustain different polarization textures. Exciton-polaritons are composite bosons which can be observed to form Bose-Einstein condensates,\nand sustain polariton superfluidity and quantum vortices \nand are prospected for emerging technological applications. \nMany experimental works currently focus on polariton lasers, optically addressed transistors, nonlinear states such as solitons and shock waves, long-range coherence properties and phase transitions, quantum vortices and spinorial patterns. Modelization of exciton-polariton fluids mainly rely on the use of GPE (Gross–Pitaevskii equations) which are in the form of nonlinear Schrödinger equations.\n\n\n"}
{"id": "4597716", "url": "https://en.wikipedia.org/wiki?curid=4597716", "title": "Fermi point", "text": "Fermi point\n\nThe term Fermi point has two applications but refers to the same phenomena (special relativity):\n\nFor both applications count that the symmetry between particles and anti-particles in weak interactions is violated:\nAt this point the particle energy E = cp is zero.\nIn nanotechnology this concept can be applied to electron behavior. An electron when as single particle is a Fermion obeying the Pauli exclusion principle.\n\nFermionic systems that have a Fermi surface (FS) belong to a universality class in quantum field theory. Any collection of fermions with weak repulsive interactions belongs to this class. At the fermi point, the break of symmetry can be explained by assuming a vortex or singularity will appear as a result of the spin of a fermi particle (quasiparticle, Fermion) in one dimension of the three-dimensional momentum space.\n\nThe Fermi point is one particular electron state. The Fermi point refers to an event chirality of electrons is involved and the diameter of a carbon nanotube for which the nanotube becomes metallic. As the structure of a carbon nanotube determines the energy levels that the carbon's electrons may occupy, the structure affects macroscopic properties of the nanotube structure, most notably electrical and thermal conductivity.\n\nFlat graphite is a conductor except when rolled up into small cylinders. This circular structure inhibits the internal flow of electrons and the graphite becomes a semiconductor; a transition point forms between the valence band and conduction band. This point is called the Fermi point. If the diameter of the carbon nanotube is sufficiently great, the necessary transition phase disappears and the nanotube may be considered a conductor.\n\nFor a given (\"n\",\"m\") nanotube, if \"n\" - \"m\"=3\"q\" (where \"q\" is an integer), then the nanotube is metallic, otherwise the nanotube is a semiconductor. Thus all armchair nanotubes (\"n\"=\"m\") are metallic, and nanotubes (5,0), (6,4), (9,1), etc. are semiconducting.\n\n"}
{"id": "22081656", "url": "https://en.wikipedia.org/wiki?curid=22081656", "title": "Garigliano Nuclear Power Plant", "text": "Garigliano Nuclear Power Plant\n\nGarigliano Nuclear Power Plant was a nuclear power plant located at Sessa Aurunca (Campania), in southern Italy. It was named after the river Garigliano.\n\nConsisting of one 150MWe BWR from General Electric, it operated from 1964 until 1982. First criticality was on 5 June 1963, with grid connection 1 January 1964 and full commercial operation from 1 June in that year. Final shutdown was 1 March 1982.\n\nGarigliano was in 1964 the fourth BWR ever worldwide commercial operated, and had the second highest MW-capacity after Dresden Nuclear Power Plant unit 1. \n\n"}
{"id": "47827692", "url": "https://en.wikipedia.org/wiki?curid=47827692", "title": "Giant oscillator strength", "text": "Giant oscillator strength\n\nGiant oscillator strength is inherent in excitons that are weakly bound to impurities or defects in crystals.\n\nThe spectrum of fundamental absorption of direct-gap semiconductors such as gallium arsenide (GaAs) and cadmium sulfide (CdS) is continuous and corresponds to band-to-band transitions. It begins with transitions at the center of the Brillouin zone, formula_1. In a perfect crystal, this spectrum is preceded by a hydrogen-like series of the transitions to \"s\"-states of Wannier-Mott excitons. In addition to the exciton lines, there are surprisingly strong additional absorption lines in the same spectral region. They belong to excitons weakly bound to impurities and defects and are termed 'impurity excitons'. Anomalously high intensity of the impurity-exciton lines indicate their giant oscillator strength of about formula_2 per impurity center while the oscillator strength of free excitons is only of about formula_3 per unit cell. Shallow impurity-exciton states are working as antennas borrowing their giant oscillator strength from vast areas of the crystal around them. They were predicted by Emmanuel Rashba first for molecular excitons and afterwards for excitons in semiconductors. Giant oscillator strengths of impurity excitons endow them with ultra-short radiational life-times formula_4 ns.\n\nInterband optical transitions happen at the scale of the lattice constant which is small compared to the exciton radius. Therefore, for large excitons in direct-gap crystals the oscillator strength formula_5 of exciton absorption is proportional to formula_6 which is the value of the square of the wave function of the internal motion inside the exciton formula_7 at coinciding values of the electron formula_8 and hole formula_9 coordinates. For large excitons formula_10 where formula_11 is the exciton radius, hence, formula_12, here formula_13 is the unit cell volume. The oscillator strength formula_14 for producing a bound exciton can be expressed through its wave function formula_15 and formula_5 as\n\nformula_17 .\n\nCoinciding coordinates in the numerator, formula_18, reflect the fact the exciton is created at a spatial scale small compared with its radius. The integral in the numerator can only be performed for specific models of impurity excitons. However, if the exciton is weakly bound to impurity, hence, the radius of the bound exciton formula_19 satisfies the condition formula_19 ≥ formula_11 and its wave function of the internal motion formula_7 is only slightly distorted, then the integral in the numerator can be evaluated as formula_23. This immediately results in an estimate for formula_14\n\nformula_25 .\n\nThis simple result reflects physics of the phenomenon of giant oscillator strength: coherent oscillation of electron polarization in the volume of about formula_26.\n\nIf the exciton is bound to a defect by a weak short-range potential, a more accurate estimate holds\n\nformula_27.\n\nHere formula_28 is the exciton effective mass, formula_29 is its reduced mass, formula_30 is the exciton ionization energy, formula_31 is the binding energy of the exciton to impurity, and formula_32 and formula_33 are the electron and hole effective masses.\n\nGiant oscillator strength for shallow trapped excitons results in their short radiative lifetimes\n\nformula_34\n\nHere formula_35 is the electron mass in vacuum, formula_36 is the speed of light, formula_37 is the refraction index, and formula_38 is the frequency of emitted light. Typical values of formula_39 are about nanoseconds, and these short radiative lifetimes favor the radiative recombination of excitons over the non-radiative one. When quantum yield of radiative emission is high, the process can be considered as resonance fluorescence.\n\nSimilar effects exist for optical transitions between exciton and biexciton states.\n\nAn alternative description of the same phenomenon is in terms of polaritons: giant cross-sections of the resonance scattering of electronic polaritons on impurities and lattice defects.\n\nWhile specific values of formula_14 and formula_39 are not universal and change within collections of specimens, typical values confirm the above regularities. In CdS, with formula_42 meV, were observed impurity-exciton oscillator strengths formula_43. The value formula_44 per a single impurity center should not be surprising because the transition is a collective process including many electrons in the region of the volume of about formula_45. High oscillator strength results in low-power optical saturation and radiative life times formula_46 ps. Similarly, radiative life times of about 1 ns were reported for impurity excitons in GaAs. The same mechanism is responsible for short radiative times down to 100 ps for excitons confined in CuCl microcrystallites.\n\nSimilarly, spectra of weakly trapped molecular excitons are also strongly influenced by adjacent exciton bands. It is an important property of typical molecular crystals with two or more symmetrically-equivalent molecules in the elementary cell, such as benzine and naphthalene, that their exciton absorption spectra consist of doublets (or multiplets) of bands strongly polarized along the crystal axes as was demonstrated by Antonina Prikhot'ko. This splitting of strongly polarized absorption bands that originated from the same molecular level and is known as the 'Davydov splitting' is the primary manifestation of molecular excitons. If the low-frequency component of the exciton multiplet is situated at the bottom of the exciton energy spectrum, then the absorption band of an impurity exciton approaching the bottom from below is enhanced in this component of the spectrum and reduced in two other components; in the spectroscopy of molecular excitons this phenomenon is sometimes referred to as the 'Rashba effect'. As a result, the polarization ratio of an impurity exciton band depends on its spectral position and becomes indicative of the energy spectrum of free excitons. In large organic molecules the energy of impurity excitons can be shifted gradually by changing the isotopic content of guest molecules. Building on this option, Vladimir Broude developed a method of studying the energy spectrum of excitons in the host crystal by changing the isotopic content of guest molecules. Interchanging the host and the guest allows studying energy spectrum of excitons from the top. The isotopic technique has been more recently applied to study the energy transport in biological systems.\n\n"}
{"id": "20130081", "url": "https://en.wikipedia.org/wiki?curid=20130081", "title": "Heptadecanoic acid", "text": "Heptadecanoic acid\n\nHeptadecanoic acid, or margaric acid, is a saturated fatty acid. Its molecular formula is CH(CH)COOH. It occurs as a trace component of the fat and milkfat of ruminants, but it does not occur in any natural animal or vegetable fat at high concentrations. For example, it only comprises 2.2% of the fats from the fruit of the durian species \"Durio graveolens\". However, in the 19th and early 20th centuries, there were numerous reports of the acid being found in natural fats in significant amounts. Most likely, these were cases of misidentifying a eutectic mixture of palmitic and stearic acids. Salts and esters of heptadecanoic acid are called heptadecanoates.\n"}
{"id": "21973091", "url": "https://en.wikipedia.org/wiki?curid=21973091", "title": "Hibernia Gravity Base Structure", "text": "Hibernia Gravity Base Structure\n\nThe Hibernia Gravity Base Structure is the world's largest offshore oil platform, on the Hibernia oilfield south east of St. John’s, Newfoundland, Canada. \n\nA 600 kilotonne gravity base structure (GBS) built after the \"Ocean Ranger\" disaster, it sits in of water directly on the floor of the North Atlantic Ocean off St. John's, Newfoundland at .\n\nThis GBS is designed to resist iceberg forces, and supported a topsides weighing 39000 tonnes at towout, increasing to 58000 tonnes in operation. There were significant challenges faced by the engineering firms Doris Development Canada, Morrison Hershfield and Mobil Technology, in developing a structural solution with adequate strength which was also constructible. In addition, unusual design situations resulted from the construction methods and the structural components used.\n\nThe majority of the construction was performed at a site in Bull Arm, Trinity Bay, Newfoundland and Labrador. A new community housing 3,500 workers was constructed, with its own cafeteria, gym and entertainment facilities.\n\nMany of the topsides modules were constructed locally, with some sourced internationally. The 550,000-ton slipform concrete GBS was built inside a drydock and mated with the topsides in the nearby deepwater construction site. Kiewit performed outfitting of equipment inside utility shafts, and provided construction management services for the gravity base structure. \n\nThe assembled GBS was towed out on May 23, 1997 and installed in position on June 5. First oil was produced on November 17, 1997, four weeks ahead of schedule. \n\nHibernia Gravity Base Structure\n"}
{"id": "1754976", "url": "https://en.wikipedia.org/wiki?curid=1754976", "title": "Isocyanide", "text": "Isocyanide\n\nAn isocyanide (also called isonitrile or carbylamine) is an organic compound with the functional group -N≡C. It is the isomer of the related cyanide (-C≡N), hence the prefix \"iso\". The organic fragment is connected to the isocyanide group via the nitrogen atom, not via the carbon. They are used as building blocks for the synthesis of other compounds.\n\nThe C-N distance in isocyanides is very short, 1.158 Å in methyl isocyanide. The C-N-C angles are near 180°.\n\nAkin to carbon monoxide, isocyanides are described by two resonance structures, one with a triple bond between the nitrogen and the carbon and one with a double bond between. The π lone pair of the nitrogen, responsible for the zwitterionic structure, stabilizes the structure and is responsible of the linearity of isocyanides, although the reactivity of isocyanides reflects some carbene character, at least in a formal sense. Thus, both resonance structures are useful representations. They are susceptible to polymerization.\n\nIsocyanides exhibit a strong absorption in their IR spectra in the range: 2165–2110 cm\n\nThe electronic symmetry about the isocyanide N nucleus results in a slow quadrupolar relaxation so that C-N nuclear spin coupling can be observed, with coupling constants of \"ca.\" 5 Hz for the isocyanide C nucleus and 5–14 Hz for the C nucleus which the isocyanide group is attached to.\n\nTheir disagreeable odour is legendary. To quote from Lieke, \"\"Es besitzt einen penetranten, höchst unangenehmen Geruch; das Oeffnen eines Gefässes mit Cyanallyl reicht hin, die Luft eines Zimmers mehrere Tage lang zu verpesten, ...\" (It has a penetrating, extremely unpleasant odour; the opening of a flask of allyl [iso]cyanide is enough to foul up the air in a room for several days). Note that in Lieke's day, the difference between isocyanide and nitrile was not fully appreciated.\n\nIvar Karl Ugi states that \"The development of the chemistry of isocyanides has probably suffered only little delay through the characteristic odor of volatile isonitriles, which has been described by Hofmann and Gautier as 'highly specific, almost overpowering', 'horrible', and 'extremely distressing'. It is true that many potential workers in this field have been turned away by the odour, but this is heavily outweighed by the fact that isonitriles can be detected even in traces, and that most of the routes leading to the formation of isonitriles were discovered through the odor of these compounds.\"\" Isocyanides have been investigated as potential non-lethal weapons.\n\nSome isocyanides convey less offensive odours such as malt, natural rubber, creosote, mild cherry or old wood. Non-volatile derivatives such as tosylmethyl isocyanide do not have objectionable odors.\n\nWhile some isocyanides (\"e.g.,\" cyclohexyl isocyanide) are toxic, others \"exhibit no appreciable toxicity for mammals\". Referring to ethyl isocyanide, toxicological studies in the 1960s at Bayer showed that \"oral and subcutaneous doses of 500-5000 mg/kg can be tolerated by mice\".\n\nThe first isocyanide, allyl isocyanide, was reported in 1859 by the chemist Lieke from the reaction of allyl iodide and silver cyanide. Normally the alkylation of an alkali metal cyanide gives a nitrile, but the silver ion protects the carbon end of the cyanide.\n\nCommonly, isocyanides are synthesized by dehydration of formamides. The formamide can be dehydrated with toluenesulfonyl chloride, phosphorus oxychloride, phosgene, diphosgene, or the Burgess reagent.\n\nIn the carbylamine reaction (also known as the Hofmann isocyanide synthesis) potassium hydroxide reacts with chloroform to produce dichlorocarbene. This then converts primary amines to isocyanides. As it is only effective for primary amines it is used as a chemical test for their presence.\n\nAnother route to isocyanides is by reaction of organolithium compounds with oxazoles and benzoxazoles:\n\nThe benzoxazole deprotonates at the 2-position by \"n\"-butyllithium. The resulting organolithium compound exists in chemical equilibrium with the \"2-isocyanophenolate\", which can be captured by an electrophile such as an acid chloride. Being an ester the formed isocyanate in the example above behaves uncharacteristically with reportedly a mild cherry smell.\n\nIsocyanides are stable to strong base (they are often made under strongly basic conditions), but they are sensitive to acid. In the presence of aqueous acid, isocyanides hydrolyse to the corresponding formamides:\nThis reaction is used to destroy odorous isocyanide mixtures. Some isocyanides can polymerize in the presence of Lewis and Bronsted acids.\n\nIsocyanides participate in many multicomponent reactions of interest in organic synthesis, two of which are: the Ugi reaction and the Passerini reaction.\n\nIsocyanides also participate in cycloaddition reactions, such as the [4+1] cycloaddition with tetrazines. Depending on the degree of substitution of the isocyanide, this reaction converts isocyanides into carbonyls or gives stable cycloadducts. They also undergo insertion into the C–Cl bonds of acyl chlorides in the Nef isocyanide reaction, a process that is believed to be concerted and illustrates their carbene character.\n\nIsocyanides have also been shown to be a useful reagent in palladium catalysed reactions with a wide variety of compounds being formed using this method.\n\nIsocyanides form coordination complexes with most transition metals. They behave as electron-rich analogues of carbon monoxide. For example tert-Butyl isocyanide forms Fe(tBuNC), which is analogous to Fe(CO). Although structurally similar, the analogous carbonyls differ in several ways, mainly because t-BuNC is a better donor ligand than CO. Thus, Fe(tBuNC) is easily protonated, whereas its counterpart Fe(CO) is not.\n\nOnly few naturally occurring compounds exhibit the isocyanide functionality. The first was discovered in 1957 in an extract of the mold \"Penicillium notatum\" Westling. The compound xanthocillin later was used as an antibiotic. Since then numerous other isocyanides have been isolated. Most of the marine isocyanides are terpenoid, while some of the terrestrial isocyanides originate from α-aminoacids.\n\nWhereas in IUPAC nomenclature in most cases the suffix \"nitrile\" or \"carbonitrile\" is used for organic cyanides (R-C≡N), \nnames for isocyanides have the prefix \"isocyano\". IUPAC names become isocyanomethane, isocyanoethane, isocyanopropane, etc.\n\nThe suffix \"isonitrile\" can be ambiguous, since the carbon counting is different from \"nitrile\". For example, \"ethanenitrile\" ( CHCN) and \"ethaneisonitrile\" (CHNC) are not isomers, as the prefix \"iso\" in the suffix might suggest. In contrast, \"isocyanide\" does not have this ambiguity: \"ethyl cyanide\" (CHCN) and \"ethyl isocyanide\" (CHNC) are indeed isomers.\n\nThe sometimes used term \"carbylamine\" conflicts with systematic nomenclature. An amine always has three single bonds, whereas an isocyanide has only one single and one multiple bond.\n"}
{"id": "575126", "url": "https://en.wikipedia.org/wiki?curid=575126", "title": "Isolation transformer", "text": "Isolation transformer\n\nAn isolation transformer is a transformer used to transfer electrical power from a source of alternating current (AC) power to some equipment or device while isolating the powered device from the power source, usually for safety reasons. Isolation transformers provide galvanic isolation and are used to protect against electric shock, to suppress electrical noise in sensitive devices, or to transfer power between two circuits which must not be connected. A transformer sold for isolation is often built with special insulation between primary and secondary, and is specified to withstand a high voltage between windings.\nIsolation transformers block transmission of the DC component in signals from one circuit to the other, but allow AC components in signals to pass. Transformers that have a ratio of 1 to 1 between the primary and secondary windings are often used to protect secondary circuits and individuals from electrical shocks between energized conductors and earth ground. \nSuitably designed isolation transformers block interference caused by ground loops. Isolation transformers with electrostatic shields are used for power supplies for sensitive equipment such as computers, medical devices, or laboratory instruments.\nSometimes the term is used to emphasize that a device is not an autotransformer whose primary and secondary circuits are connected. Power transformers with specified insulation between primary and secondary are not usually described only as \"isolation transformers\" unless this is their primary function. Only transformers whose \"primary\" purpose is to isolate circuits are routinely described as isolation transformers.\n\nIsolation transformers are designed with attention to capacitive coupling between the two windings. The capacitance between primary and secondary windings would also couple AC current from the primary to the secondary. A grounded Faraday shield between the primary and the secondary greatly reduces the coupling of common-mode noise. This may be another winding or a metal strip surrounding a winding. \nDifferential noise can magnetically couple from the primary to the secondary of an isolation transformer, and must be filtered out if a problem occurs.\n\nSome small transformers are used for isolation in pulse circuits.\n\nIn electronics testing and servicing, an isolation transformer is a 1:1 (under load) power transformer used for safety. Without it, exposed live metal in a device under test is at a hazardous voltage relative to grounded objects such as a heating radiator or oscilloscope ground lead (a particular hazard with some old vacuum-tube equipment with live chassis). With the transformer, as there is no conductive connection between transformer secondary and earth, there is no danger in touching a live part of the circuit while another part of the body is earthed.\n\nElectrical isolation is considered to be particularly important on medical equipment, and special standards apply. Often the system must additionally be designed so that fault conditions do not interrupt power, but generate a warning.\n\nIsolation transformers are also used for the power supply of devices not at ground potential. An example is the Austin transformer for the power supply of air-traffic obstacle warning lamps on radio antenna masts. Without the isolation transformer, the lighting circuits on the mast would conduct radio-frequency energy to ground through the power supply.\n\n\n"}
{"id": "15428666", "url": "https://en.wikipedia.org/wiki?curid=15428666", "title": "Jacqui Katona", "text": "Jacqui Katona\n\nJacqui Katona is a western-educated Aboriginal woman who led the campaign to stop the Jabiluka uranium mine in the Northern Territory. In 1998 the Mirrar Aboriginal people, together with environmental groups, used peaceful on-site civil disobedience to create one of the largest blockades in Australia's history. Katona won the 1999 U.S. Goldman Environmental Prize, with Yvonne Margarula, in recognition of efforts to protect their country and culture against uranium mining.\n\n\n"}
{"id": "53520679", "url": "https://en.wikipedia.org/wiki?curid=53520679", "title": "Kilgallioch", "text": "Kilgallioch\n\nKilgallioch Wind Farm is a 96 turbine wind farm in South Ayrshire, Scotland with a total capacity of up to 239 megawatts (MW). Consent granted by the Scottish Government in February 2013 with construction starting in 2015 and completed in 2017.\n\nOn 13 January 2017 a turbine under construction catastrophically collapsed during a storm.\n\nOn 15 March 2017 Portuguese construction worker António João Linares, who was working for turbine manufacturer Gamesa, was killed when he fell 8 metres within a tower.\n\n"}
{"id": "38022583", "url": "https://en.wikipedia.org/wiki?curid=38022583", "title": "Lady Urmia", "text": "Lady Urmia\n\nLady Urmia () is an Iranian documentary film by Mohammad Ehsani. It was released in 2012 in Iran, distributed by EhsaniPictures.\n\nThe film is a poetic documentary about Lake Urmia, in Iranian Azerbaijan, which is drying up completely. The environmental catastrophe will not only affect Iran, but also neighbors such as Iraq and Turkey. The film is narrated in the voice of the Lake itself, asking for help and trying to gain international reaction.\n"}
{"id": "37873411", "url": "https://en.wikipedia.org/wiki?curid=37873411", "title": "Land grant to Munnabittu kudurru", "text": "Land grant to Munnabittu kudurru\n\nThe Land grant to Munnabittu kudurru is an elongated egg-shaped black limestone ancient Mesopotamian narû or entitlement stele (kudurru), 46.5 cm high and 20.5 cm wide, which details the reconfirmation of a gift of 30 of land (around 750 acres) by Kassite king Marduk-apla-iddina I to his servant Munnabittu (a name meaning \"fugitive, refugee\"), son of Ṭābu-melû (probably a Hurrian name). It is significant because, in addition to portraying eighteen divine icons around its top, it lists forty-seven gods in its inscription, more than any other similar object.\n\nRecovered from Susa during the French excavations under Jacques de Morgan at the turn of the twentieth century, excavation reference Sb 26, it is currently located in the Musée du Louvre. The text covers around three quarters of the surface of the sides with the top part engraved with a relief of religious iconography.\n\nIt records the granting of a tract of land in the limits of the town of Šaknanâ, on the banks of the Mēdandan canal, district of Ḫudādu (Baghdad?), originally by Meli-Šipak. The failure to issue a record of this deed resulted in its contention by Munnabbittu’s neighbor, Aḫūnea (probably the hypocoristic form of his name), son of Dayyān-Marduk, who laid claim to a three and twenty \"qa\" portion of the field, claiming that \"it is the 'gate' of my field\". On appeal to Marduk-apla-iddina I, the former governor of Ḫudādu, Kidin-Ninurta, under whose period in office the original grant had been made, and Ṣir-šum-iddina, his successor, together with various city elders, were consulted and unanimously upheld Munnabittu’s claim. Ṣir-šum-iddina and the scribe Bēl-ippašra were dispatched to resurvey the property and confirmed its size.\n\n\nWitnesses:\n\n\nThe kudurru's significance lies in its extensive list of Mesopotamian deities used in the curse section, the longest by far to appear on any similar object, where around a dozen usually suffice. The elaborate endorsements, however, provided no protection to the monument as within around fifteen years it was taken back to Elam as war-booty by the invading army of Šutruk-Naḫḫunte. The following gives the names of the gods and goddesses in the order in which they appear in the text, with the cuneiform synonym in parentheses when the name is not written phonetically. The divine symbols are numbered as per Hinke's diagram (opposite).\nIšḫara (8. scorpion), the only symbol not named\n\n"}
{"id": "6318968", "url": "https://en.wikipedia.org/wiki?curid=6318968", "title": "List of materials properties", "text": "List of materials properties\n\nA material's property (or material property) is an intensive property of some material, i.e. a physical property that does not depend on the amount of the material. These quantitative properties may be used as a metric by which the benefits of one material versus another can be compared, thereby aiding in materials selection.\n\nA property may be a constant or may be a function of one or more independent variables, such as temperature. Materials properties often vary to some degree according to the direction in the material in which they are measured, a condition referred to as anisotropy. Materials properties that relate to different physical phenomena often behave linearly (or approximately so) in a given operating range. Modeling them as linear can significantly simplify the differential constitutive equations that the property describes.\n\nSome materials are used in relevant equations to predict the attributes of a system a priori. \n\nThe properties are measured by standardized test methods. Many such methods have been documented by their respective user communities and published through the Internet; see ASTM International.\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "58946628", "url": "https://en.wikipedia.org/wiki?curid=58946628", "title": "List of rocks and stones", "text": "List of rocks and stones\n\nThe following is a list of rocks and stones around the world.\n"}
{"id": "53667030", "url": "https://en.wikipedia.org/wiki?curid=53667030", "title": "Notch tensile strength", "text": "Notch tensile strength\n\nThe notch tensile strength (NTS) of a material is the value given by performing a standard tensile strength test on a notched specimen of the material. The ratio between the NTS and the tensile strength is called the notch strength ratio (NSR).\n\n"}
{"id": "1913997", "url": "https://en.wikipedia.org/wiki?curid=1913997", "title": "Okra", "text": "Okra\n\nOkra or okro (, ), known in many English-speaking countries as ladies' fingers or ochro, is a flowering plant in the mallow family. It is valued for its edible green seed pods. The geographical origin of okra is disputed, with supporters of West African, Ethiopian, and South Asian origins. The plant is cultivated in tropical, subtropical and warm temperate regions around the world.\n\nThe name \"okra\" is most often used in the UK, United States and the Philippines, with a variant pronunciation in Caribbean English and Nigeria of \"okro\". The word \"okra\" is from the Igbo . The plant and its seed pods are also known as \"lady's fingers\". In various Bantu languages, okra is called \"(ki)ngombo\" or a variant, and this is possibly the origin of the name \"gumbo\", used in parts of the United States and the English-speaking Caribbean (via Portuguese \"quingombo\"). In India, it is known by the names \"vendakkai\" (alternatively \"bendakkai\") and \"bhindi\".\n\nOkra is an allopolyploid of uncertain parentage (proposed parents include \"Abelmoschus ficulneus\", \"A. tuberculatus\" and a reported \"diploid\" form of okra). Truly wild (as opposed to naturalised) populations are not known with certainty and the species may be a cultigen. The geographical origin of okra is disputed, with supporters of South Asian, Ethiopian and West African origins. Supporters of a South Asian origin point to the presence of its proposed parents in that region. Supporters of a West African origin point to the greater diversity of okra in that region. The Egyptians and Moors of the 12th and 13th centuries used the Arabic word for the plant, \"bamya\", suggesting it had come into Egypt from Arabia, but earlier it was probably taken from Ethiopia to Arabia. The plant may have entered southwest Asia across the Red Sea or the Bab-el-Mandeb straight to the Arabian Peninsula, rather than north across the Sahara, or from India. One of the earliest accounts is by a Spanish Moor who visited Egypt in 1216 and described the plant under cultivation by the locals who ate the tender, young pods with meal. From Arabia, the plant spread around the shores of the Mediterranean Sea and eastward. The plant was introduced to the Americas by ships plying the Atlantic slave trade by 1658, when its presence was recorded in Brazil. It was further documented in Suriname in 1686. Okra may have been introduced to southeastern North America from Africa in the early 18th century. By 1748, it was being grown as far north as Philadelphia. Thomas Jefferson noted it was well established in Virginia by 1781. It was commonplace throughout the Southern United States by 1800, and the first mention of different cultivars was in 1806.\n\nThe species is a perennial, often cultivated as an annual in temperate climates, and often grows to around tall. It is related to such species as cotton, cocoa, and hibiscus. The leaves are long and broad, palmately lobed with 5–7 lobes. The flowers are in diameter, with five white to yellow petals, often with a red or purple spot at the base of each petal. The fruit is a capsule up to long with pentagonal cross-section, containing numerous seeds.\n\n\"Abelmoschus esculentus\" is cultivated throughout the tropical and warm temperate regions of the world for its fibrous fruits or pods containing round, white seeds. It is among the most heat- and drought-tolerant vegetable species in the world and will tolerate soils with heavy clay and intermittent moisture, but frost can damage the pods. In cultivation, the seeds are soaked overnight prior to planting to a depth of . Germination occurs between six days (soaked seeds) and three weeks. Seedlings require ample water. The seed pods rapidly become fibrous and woody and, to be edible as a vegetable, must be harvested when immature, usually within a week after pollination. Okra is available in two varieties, green and red. Red okra carries the same flavor as the more popular green okra and differs only in color. When cooked, the red okra pods turn green.\n\nThe most common disease afflicting the okra plant is verticillium wilt, often causing a yellowing and wilting of the leaves. Other diseases include powdery mildew in dry tropical regions, leaf spots, and root-knot nematodes.\n\nThe products of the plant are mucilaginous, resulting in the characteristic \"goo\" or slime when the seed pods are cooked; the mucilage contains soluble fiber. Pods are cooked, pickled, eaten raw, or included in salads. Okra may be used in developing countries to mitigate malnutrition and alleviate food insecurity.\n\nRaw okra is 90% water, 2% protein, 7% carbohydrates and negligible in fat. In a 100 gram amount, raw okra is rich (20% or more of the Daily Value, DV) in dietary fiber, vitamin C and vitamin K, with moderate contents of thiamin, folate and magnesium (table).\n\nOkra leaves may be cooked in a similar way to the greens of beets or dandelions. The leaves are also eaten raw in salads. Okra seeds may be roasted and ground to form a caffeine-free substitute for coffee. When importation of coffee was disrupted by the American Civil War in 1861, the \"Austin State Gazette\" said, \"An acre of okra will produce seed enough to furnish a plantation with coffee in every way equal to that imported from Rio.\"\n\nGreenish-yellow edible okra oil is pressed from okra seeds; it has a pleasant taste and odor, and is high in unsaturated fats such as oleic acid and linoleic acid. The oil content of some varieties of the seed is about 40%. At 794 kg/ha, the yield was exceeded only by that of sunflower oil in one trial. A 1920 study found that a sample contained 15% oil. A 2009 study found okra oil suitable for use as a biofuel.\n\nBast fibre from the stem of the plant has industrial uses such as the reinforcement of polymer composites. The mucilage produced by the okra plant can be used for the removal of turbidity from waste water by virtue of its flocculent properties.\n"}
{"id": "21116493", "url": "https://en.wikipedia.org/wiki?curid=21116493", "title": "Our World 2.0", "text": "Our World 2.0\n\n\"Our World 2.0\" was launched in July 2008, in time for the 34th G8 summit.\n\nIn August 2009, \"Our World 2.0\" became part of \"The Guardian's\" Environment Network.\n\nThe central tenet of \"Our World 2.0\" is that humanity can use its collective knowledge, technology and design to facilitate creativity, innovation, and collaboration among people in order to respond to these challenges.\n\n\"Our World 2.0\" uses of Creative Commons licensing to enable other interested parties to copy and modify the materials contained in the web-zine. It uses open source software called WordPress.\n"}
{"id": "10125894", "url": "https://en.wikipedia.org/wiki?curid=10125894", "title": "Panjiang Investment Holdings", "text": "Panjiang Investment Holdings\n\nPanjiang Investment Holdings Group was known as Panjiang Coal and Electric Power Group () is a coal mining and energy company in China.\n"}
{"id": "38543041", "url": "https://en.wikipedia.org/wiki?curid=38543041", "title": "Philip Wolfe (engineer)", "text": "Philip Wolfe (engineer)\n\nPhilip Rowland Wolfe MBE is one of the pioneers of the British renewable energy sector.\n\nHe first became involved in the 1970s, leading various photovoltaics companies until the turn of the century. As Director-General of the Renewable Energy Association he led the campaign for Feed-in Tariffs and the Renewable Heat Incentive.\n\nHe has written many publications and is responsible for a number of innovations and initiatives.\n\nHe was appointed Member of the Order of the British Empire (MBE) in the 2016 New Year Honours for services to renewable energy and the energy sector.\n\nThe campaign for the introduction of the Renewable Heat Incentive and Feed-in tariffs in the United Kingdom was led by Friends of the Earth and the Renewable Energy Association, when Philip Wolfe was Director General, between 2003 and 2009. He edited the first blueprint for these measures to assist early government drafting.\n\nHe first proposed the Energy hierarchy, and initiated the consumer assurance REAL Code (since renamed Renewable Energy Consumer Code) for microgeneration.\n\nAs general manager of Lucas Industries' solar power subsidiary in the early 1970s, Philip Wolfe negotiated the joint venture with BP to create what became BP Solar and was its first Chief Executive.\n\nHe was a founding director of the European Photovoltaic Industry Association (EPIA, since renamed Solar Power Europe) and its third President from 1987 to 1989. He was a founding director of the Renewable Energy Association and its Director General from 2002 to 2009.\n\nHe is an expert on solar parks and has pioneered their introduction in the UK.\n\nHis background in utility-scale solar power led to Wolfe's involvement in the community sector when he was appointed as chairman of Westmill Solar Co-operative and led the public offering and acquisition of the world's largest community-owned solar power station.\n\nHe was subsequently involved in the creation of Community Energy England, to represent the community energy sector in the United Kingdom, and was its first elected chairman in 2014. He was a member of the British government's Shared Ownership Taskforce, and appointed its vice-chair in 2015.\n\nAmongst Philip Wolfe's innovations were the UK's first: grid-connected solar power station at Marchwood, building-integrated renewables at Energy World in Milton Keynes (opened by then Prime Minister, Margaret Thatcher), and solar roofing slate.\n\nThe Solar Generation, Wiley-IEEE\n\nSolar Photovoltaic Projects in the mainstream energy market, Routledge\n\nSustainable Energy Options for business, DōShorts\n\nEnergy hierarchy\n\nPriorities for low carbon transition, The Policy Network\n\nPreliminary blueprint: Feed-in Tariffs and Renewable Heat Incentive, Renewable Energy Association\n"}
{"id": "10418611", "url": "https://en.wikipedia.org/wiki?curid=10418611", "title": "Photodarkening", "text": "Photodarkening\n\nPhotodarkening is an optical effect observed in the interaction of laser radiation with \namorphous media (glasses) in optical fibers.\nUntil now, such creation of color centers was reported only in glass\nfibers \n. Photodarkening limits the density of excitations in fiber lasers and amplifiers. The experimental results suggest that operating at a saturated regime helps to reduce photodarkening.\n\nOne could expect the term photodarkening to refer to any process when any object becomes non-transparent (dark) due to illumination with light. Formally, the darkening of the photo-emulsion also could be considered as photodarkening. However, recent papers use this term meaning reversible creation of absorbing color centers in optical fibers. One may expect that the effect is not specific for fibers; therefore, the definition should cover wide class of phenomena, excluding, perhaps, non-reversible darkening of photographic emulsions.\nAccording to the Encyclopedia of Laser Physics and Technology, photodarkening is the effect that the optical losses in a medium can grow when the medium is irradiated with light at certain wavelengths. We may also define photodarkening as reversible creation of absorption centers in optical media at the illumination with\nlight.\n\nThe inverse of the timescale at which photodarkening occurs can be interpreted as photodarkening rate \n\nUsually, photodarkening is attributed to creation of color centers due to resonant interaction of electromagnetic field with an active medium \n\nThe phenomenon, similar to photodarkening in fibers, was recently observed in chunks of Yb-doped ceramics and crystals. At the high concentration of excitations, the absorption jumps up, causing the avalanche of the broadband luminescence.\nIncrease of absorption can be caused by formation of color centers by electrons in the conduction band, created by several neighboring excited ions. (The energy of one or two excitations is not sufficient to pop an electron into the conduction band). This explains, why the rate of darkening is strong function of the intensity of the exciting beam (as in the case with optical fibers discussed above). In the experiments, the\nthermal effects are important; therefore only the initial stage of the avalanche\ncan be interpreted as photodarkening, and such interpretation is not yet confirmed. Recent work pointed out the role of thulium contamination. Through laser pump and signal absorption, and energy transfer from ytterbium; thulium is able to emit UV light, known to create color centers in silica glass. Although the actual mechanism of photodarkening is still unknown, a reliable setup to test the photodarkening properties of different types of fibers has been recently reported.\n"}
{"id": "17267092", "url": "https://en.wikipedia.org/wiki?curid=17267092", "title": "Project Hot Seat", "text": "Project Hot Seat\n\nProject Hot Seat is a campaign started by Greenpeace. Its goal is to apply intense pressure on members of The United States Congress in order to implement policies that will curb and cut U.S. greenhouse gas emissions, and what Phil Radford, Greenpeace Executive Director said was the \"kind of organizing that is going to be key to making the environmental movement into a viable political force in Congress and around the country.\".\n\nSome of Project Hot Seats aims include reaching a national cap and trade system that makes real reductions within a decade, a national renewable energy standard of at least 20% by 2020, and an increase in average fuel economy to 40 mpg. Project members work to raise awareness of global warming by organizing events such as The International Day of Action. This was a project in which volunteers throughout the world held rallies and outreach events to raise concern for global warming. The most recent was held on December 8, 2007. Some of the events included 25 people taking a polar bear swim in Puget Sound. The project also engages in human art to get its message across. Over 300 participants in Florida sat on a beach in the shape of the state of Florida with the southern tip dipping into the ocean. Below the state they used their bodies to spell out the words \"Save our State\".\n\n"}
{"id": "3488132", "url": "https://en.wikipedia.org/wiki?curid=3488132", "title": "Quality Protein Maize", "text": "Quality Protein Maize\n\nThe grain of quality protein maize (QPM) varieties contains nearly twice as much lysine and tryptophan, amino acids that are essential for humans and monogastric animals. QPM is a product of conventional plant breeding (i.e., it is not genetically modified) and an example of biofortification.\n\nQPM was developed by Surinder Vasal and Evangelina Villegas at the International Maize and Wheat Improvement Center (CIMMYT) in the late 1990s. For their achievement, they won the 2000 World Food Prize.\n\nIn Central and South America, Africa, and Asia, several hundred million people rely on maize as their principal daily food, for weaning babies, and for feeding livestock. Unfortunately maize (corn) has two significant flaws; it lacks the full range of amino acids, namely lysine and tryptophan, needed to produce proteins, and has its niacin (vitamin B) bound in an indigestible complex. The Mayans and Aztecs used to boil maize in the alkaline limewater which broke down the complex so that the Niacin became available. However, in the main this practice did not transfer to the Old World or settlers in the \"New World\" which resulted in epidemics of Pellagra from the 16th century onwards. In addition diets high in corn produce a condition known as wet-malnutrition a person is receiving sufficient calories, but her or his body malfunctions due to a lack of protein. A chronic lack of protein in the diet leads to kwashiorkor.\n\nThus, conventional maize is a poor-quality food staple; unless consumed as part of a varied diet which is beyond the means of most people in the developing world.\n\nQPM produces 70–100% more of lysine and tryptophan than the most modern varieties of tropical maize. These two amino acids allow the body to manufacture complete proteins, thereby eliminating wet-malnutrition. In addition tryptophan can be converted in the body to Niacin, which theoretically reduces the incidence of Pellagra.\n\nModified maize with higher protein content dated back to the 1920s, and the \"opaque-2\" variety had been developed in 1963. While its lysine and tryptophan levels were better than those of conventional maize, opaque-2 had lower yields and a soft, chalky kernel, which made it more susceptible to ear rot and insect damage. Moreover, the taste and kernel appearance dissatisfied consumers, who ultimately rejected the enhanced-protein varieties in the market.\n\nSurinder Vasal and Evangelina Villegas began their collaborative research in Mexico in the early 1970s while they were working at CIMMYT. Dr. Villegas was in charge of the lab investigating protein quality and Dr. Vasal was a plant breeder newly assigned to work on developing QPM varieties that would gain widespread acceptance.\n\nIntegrating cereal chemistry and plant breeding techniques, Drs. Vasal and Villegas collaborated to combine the existing opaque-2 maize with genetic modifiers. Through the 1970s, they produced and analyzed germplasms at an astonishing rate, sometimes processing up to 25,000 samples a year. By the mid-1980s, they had produced a QPM germplasm with hard kernel characteristics and good taste similar to the traditional grain and with much higher quality levels of lysine and tryptophan.\n\nHowever, their discovery remained unexploited for years because many nutritionists felt that protein could be added to the diets of the most poor in other ways. In the early 1990s, CIMMYT gained the international support and funding to begin promoting QPM in Ghana and several other African countries. Since then, QPM has also yielded very positive results in China, Mexico, and parts of Central America.\n\nBabies and adults consuming QPM are healthier and at lower risk for malnutrition disorders such as marasmus and kwashiorkor, and data from Latin America and Africa show the grain’s role in reversing the effects of malnutrition in those already affected. QPM offers 90% the nutritional value of skim milk, the standard for adequate nutrition value. At a time when UNICEF reports that 1,000,000 infants and small children are starving each month, the inclusion of QPM in daily rations improves health and saves lives. Additionally, pigs fed QPM experience rapid weight gain and are ready for market sooner or can provide an additional quality protein source for small farm families.\n\nQPM hybrids have been developed and tested for varying climatic and growing conditions; QPM varieties are grown on roughly 9 million acres (36,000 km²) worldwide. Meanwhile, QPM research and development have spread from Mexico to throughout Latin America and to Africa, Europe, and Asia. In Guizhou, the poorest province in China, QPM hybrid yields are 10% higher than those of other hybrids, and the crop has enabled new pig production enterprises, bringing increased food security and disposable income. In total, the QPM germplasm has grown to contribute over US$1 billion annually to the economies of developing countries.\nIn India Centre of Excellence on Processing & Value Addition of Maize has been established at Udaipur city of Rajasthan under the Rashtriya Krishi Vikas Yojna to ensure better utilization of quality Protein maize in commercial food products and Industry. This centre has developed several bakery products like Biscuit, cake muffins, extruded products puffcorns and pasta using QPM flour.\n"}
{"id": "23681458", "url": "https://en.wikipedia.org/wiki?curid=23681458", "title": "Recrystallization (chemistry)", "text": "Recrystallization (chemistry)\n\nIn chemistry, recrystallization is a technique used to purify chemicals. By dissolving both impurities and a compound in an appropriate solvent, either the desired compound or impurities can be removed from the solution, leaving the other behind. It is named for the crystals often formed when the compound precipitates out. Alternatively, \"recrystallization\" can refer to the natural growth of larger ice crystals at the expense of smaller ones.\n\nIn chemistry, recrystallization is a procedure for purifying compounds. The most typical situation is that a desired \"compound A\" is contaminated by a small amount of \"impurity B\". There are various methods of purification that may be attempted (see Separation process), recrystallization being one of them. There are also different recrystallization techniques that can be used such as:\n\nTypically, the mixture of \"compound A\" and \"impurity B\" is dissolved in the smallest amount of hot solvent to fully dissolve the mixture, thus making a saturated solution. The solution is then allowed to cool. As the solution cools the solubility of compounds in solution drops. This results in the desired compound dropping (recrystallizing) from solution. The slower the rate of cooling, the bigger the crystals form.\n\nIn an ideal situation the solubility product of the impurity, B, is not exceeded at any temperature. In that case the solid crystals will consist of pure A and all the impurity will remain in solution. The solid crystals are collected by filtration and the filtrate is discarded. If the solubility product of the impurity is exceeded, some of the impurity will co-precipitate. However, because of the relatively low concentration of the impurity, its concentration in the precipitated crystals will be less than its concentration in the original solid. Repeated recrystallization will result in an even purer crystalline precipitate. The purity is checked after each recrystallization by measuring the melting point, since impurities lower the melting point. NMR spectroscopy can also be used to check the level of impurity. Repeated recrystallization results in some loss of material because of the non-zero solubility of compound A.\n\nThe crystallization process requires an initiation step, such as the addition of a \"seed\" crystal. In the laboratory a minuscule fragment of glass, produced by scratching the side of the glass recrystallization vessel, may provide the nucleus on which crystals may grow. \nSuccessful recrystallization depends on finding the right solvent. This is usually a combination of prediction/experience and trial/error. The compounds must be more soluble at the higher temperature than at the lower temperatures. Any insoluble impurity is removed by the technique of hot filtration.\n\nThis method is the same as the above but where two (or more) solvents are used. This relies on both \"compound A\" and \"impurity B\" being soluble in a first solvent. A second solvent is slowly added. Either \"compound A\" or \"impurity B\" will be insoluble in this solvent and precipitate, whilst the other of \"compound A\"/\"impurity B\" will remain in solution. Thus the proportion of first and second solvents is critical. Typically the second solvent is added slowly until one of the compounds begins to crystallize from solution and then the solution is cooled. Heating is not required for this technique but can be used.\n\nThe reverse of this method can be used where a mixture of solvent dissolves both A and B. One of the solvents is then removed by distillation or by an applied vacuum. This results in a change in the proportions of solvent causing either \"compound A\" or \"impurity B\" to precipitate.\n\nHot filtration can be used to separate \"compound A\" from both \"impurity B\" and some \"insoluble matter C\". This technique normally uses a single-solvent system as described above. When both \"compound A\" and \"impurity B\" are dissolved in the minimum amount of hot solvent, the solution is filtered to remove \"insoluble matter C\". This matter may be anything from a third impurity compound to fragments of broken glass. For a successful procedure, one must ensure that the filtration apparatus is hot in order to stop the dissolved compounds crystallizing from solution during filtration, thus forming crystals on the filter paper or funnel.\n\nOne way to achieve this is to heat a conical flask containing a small amount of clean solvent on a hot plate. A filter funnel is rested on the mouth, and hot solvent vapors keep the stem warm. Jacketed filter funnels may also be used. The filter paper is preferably fluted, rather than folded into a quarter; this allows quicker filtration, thus less opportunity for the desired compound to cool and crystallize from the solution.\n\nOften it is simpler to do the filtration and recrystallization as two independent and separate steps. That is dissolve \"compound A\" and \"impurity B\" in a suitable solvent at room temperature, filter (to remove insoluble compound/glass), remove the solvent and then recrystallize using any of the methods listed above.\n\nCrystallization requires an initiation step. This can be spontaneous or can be done by adding a small amount of the pure compound (a seed crystal) to the saturated solution, or can be done by simply scratching the glass surface to create a seeding surface for crystal growth. It is thought that even dust particles can act as simple seeds.\n\nGrowing crystals for X-ray crystallography can be quite difficult. For X-ray analysis, single perfect crystals are required. Typically a small amount (5–100 mg) of pure compound is used, and crystals are allowed to grow very slowly. Several techniques can be used to grow these perfect crystals:\n\n\n\n\n\n\nFor ice, recrystallization refers to the growth of larger crystals at the expense of smaller ones. Some biological antifreeze proteins have been shown to inhibit this process, and the effect may be relevant in freezing-tolerant organisms.\n\n\n"}
{"id": "37379", "url": "https://en.wikipedia.org/wiki?curid=37379", "title": "Relative density", "text": "Relative density\n\nRelative density, or specific gravity, is the ratio of the density (mass of a unit volume) of a substance to the density of a given reference material. Specific gravity usually means relative density with respect to water. The term \"relative density\" is often preferred in scientific usage. It is defined as a ratio of density of particular substance with that of water.\n\nIf a substance's relative density is less than one then it is less dense than the reference; if greater than 1 then it is denser than the reference. If the relative density is exactly 1 then the densities are equal; that is, equal volumes of the two substances have the same mass. If the reference material is water then a substance with a relative density (or specific gravity) less than 1 will float in water. For example, an ice cube, with a relative density of about 0.91, will float. A substance with a relative density greater than 1 will sink.\n\nTemperature and pressure must be specified for both the sample and the reference. Pressure is nearly always 1 atm (101.325 kPa). Where it is not, it is more usual to specify the density directly. Temperatures for both sample and reference vary from industry to industry. In British brewing practice the specific gravity as specified above is multiplied by 1000. Specific gravity is commonly used in industry as a simple means of obtaining information about the concentration of solutions of various materials such as brines, sugar solutions (syrups, juices, honeys, brewers wort, must, etc.) and acids\n\nRelative density (\"RD\") or specific gravity (\"SG\") is a dimensionless quantity, as it is the ratio of either densities or weights\n\nwhere \"RD\" is relative density, \"ρ\" is the density of the substance being measured, and \"ρ\" is the density of the reference. (By convention \"ρ\", the Greek letter rho, denotes density.)\n\nThe reference material can be indicated using subscripts: \"RD\", which means \"the relative density of \"substance\" with respect to \"reference\"\". If the reference is not explicitly stated then it is normally assumed to be water at 4 °C (or, more precisely, 3.98 °C, which is the temperature at which water reaches its maximum density). In SI units, the density of water is (approximately) 1000 kg/m or 1 g/cm, which makes relative density calculations particularly convenient: the density of the object only needs to be divided by 1000 or 1, depending on the units.\n\nThe relative density of gases is often measured with respect to dry air at a temperature of 20 °C and a pressure of 101.325 kPa absolute, which has a density of 1.205 kg/m. Relative density with respect to air can be obtained by\n\nWhere \"M\" is the molar mass and the approximately equal sign is used because equality pertains only if 1 mol of the gas and 1 mol of air occupy the same volume at a given temperature and pressure i.e. they are both Ideal gases. Ideal behaviour is usually only seen at very low pressure. For example, one mol of an ideal gas occupies 22.414 L at 0 °C and 1 atmosphere whereas carbon dioxide has a molar volume of 22.259 L under those same conditions.\n\nThe density of substances varies with temperature and pressure so that it is necessary to specify the temperatures and pressures at which the densities or masses were determined. It is nearly always the case that measurements are made at nominally 1 atmosphere (101.325 kPa the variations caused by changing weather patterns) but as relative density usually refers to highly incompressible aqueous solutions or other incompressible substances (such as petroleum products) variations in density caused by pressure are usually neglected at least where apparent relative density is being measured. For true (\"in vacuo\") relative density calculations air pressure must be considered (see below). Temperatures are specified by the notation \"T/T)\" with \"T\" representing the temperature at which the sample's density was determined and \"T\" the temperature at which the reference (water) density is specified. For example, SG (20 °C/4 °C) would be understood to mean that the density of the sample was determined at 20 °C and of the water at 4 °C. Taking into account different sample and reference temperatures we note that while SG = 1.000000 (20 °C/20 °C) it is also the case that RD = 0.998203/0.998840 = 0.998363 (20 °C/4 °C). Here temperature is being specified using the current ITS-90 scale and the densities used here and in the rest of this article are based on that scale. On the previous IPTS-68 scale the densities at 20 °C and 4 °C are, respectively, 0.9982071 and 0.9999720 resulting in an RD (20 °C/4 °C) value for water of 0.9982343.\n\nThe temperatures of the two materials may be explicitly stated in the density symbols; for example:\nwhere the superscript indicates the temperature at which the density of the material is measured, and the subscript indicates the temperature of the reference substance to which it is compared.\n\nRelative density can also help to quantify the buoyancy of a substance in a fluid, or determine the density of an unknown substance from the known density of another. Relative density is often used by geologists and mineralogists to help determine the mineral content of a rock or other sample. Gemologists use it as an aid in the identification of gemstones. Water is preferred as the reference because measurements are then easy to carry out in the field (see below for examples of measurement methods).\n\nAs the principal use of relative density measurements in industry is determination of the concentrations of substances in aqueous solutions and these are found in tables of RD vs concentration it is extremely important that the analyst enter the table with the correct form of relative density. For example, in the brewing industry, the Plato table, which lists sucrose concentration by mass against true RD, were originally (20 °C/4 °C) that is based on measurements of the density of sucrose solutions made at laboratory temperature (20 °C) but referenced to the density of water at 4 °C which is very close to the temperature at which water has its maximum density of \"ρ\"() equal to 0.999972 g/cm (or 62.43 lb·ft). The ASBC table in use today in North America, while it is derived from the original Plato table is for apparent relative density measurements at (20 °C/20 °C) on the IPTS-68 scale where the density of water is 0.9982071 g/cm. In the sugar, soft drink, honey, fruit juice and related industries sucrose concentration by mass is taken from this work which uses SG (17.5 °C/17.5 °C). As a final example, the British RD units are based on reference and sample temperatures of 60 °F and are thus (15.56 °C/15.56 °C).\n\nRelative density can be calculated directly by measuring the density of a sample and dividing it by the (known) density of the reference substance. The density of the sample is simply its mass divided by its volume. Although mass is easy to measure, the volume of an irregularly shaped sample can be more difficult to ascertain. One method is to put the sample in a water-filled graduated cylinder and read off how much water it displaces. Alternatively the container can be filled to the brim, the sample immersed, and the volume of overflow measured. The surface tension of the water may keep a significant amount of water from overflowing, which is especially problematic for small samples. For this reason it is desirable to use a water container with as small a mouth as possible.\n\nFor each substance, the density, \"ρ\", is given by\n\nWhen these densities are divided, references to the spring constant, gravity and cross-sectional area simply cancel, leaving\n\nRelative density is more easily and perhaps more accurately measured without measuring volume. Using a spring scale, the sample is weighed first in air and then in water. Relative density (with respect to water) can then be calculated using the following formula:\n\nwhere\n\nThis technique cannot easily be used to measure relative densities less than one, because the sample will then float. \"W\" becomes a negative quantity, representing the force needed to keep the sample underwater.\n\nAnother practical method uses three measurements. The sample is weighed dry. Then a container filled to the brim with water is weighed, and weighed again with the sample immersed, after the displaced water has overflowed and been removed. Subtracting the last reading from the sum of the first two readings gives the weight of the displaced water. The relative density result is the dry sample weight divided by that of the displaced water. This method works with scales that can't easily accommodate a suspended sample, and also allows for measurement of samples that are less dense than water.\n\nThe relative density of a liquid can be measured using a hydrometer. This consists of a bulb attached to a stalk of constant cross-sectional area, as shown in the adjacent diagram.\n\nFirst the hydrometer is floated in the reference liquid (shown in light blue), and the displacement (the level of the liquid on the stalk) is marked (blue line). The reference could be any liquid, but in practice it is usually water.\n\nThe hydrometer is then floated in a liquid of unknown density (shown in green). The change in displacement, Δ\"x\", is noted. In the example depicted, the hydrometer has dropped slightly in the green liquid; hence its density is lower than that of the reference liquid. It is, of course, necessary that the hydrometer floats in both liquids.\n\nThe application of simple physical principles allows the relative density of the unknown liquid to be calculated from the change in displacement. (In practice the stalk of the hydrometer is pre-marked with graduations to facilitate this measurement.)\n\nIn the explanation that follows,\n\nSince the floating hydrometer is in static equilibrium, the downward gravitational force acting upon it must exactly balance the upward buoyancy force. The gravitational force acting on the hydrometer is simply its weight, \"mg\". From the Archimedes buoyancy principle, the buoyancy force acting on the hydrometer is equal to the weight of liquid displaced. This weight is equal to the mass of liquid displaced multiplied by \"g\", which in the case of the reference liquid is \"ρVg\". Setting these equal, we have\n\nor just\n\nExactly the same equation applies when the hydrometer is floating in the liquid being measured, except that the new volume is \"V\" - \"A\"Δ\"x\" (see note above about the sign of Δ\"x\"). Thus,\n\nCombining (1) and (2) yields\n\nBut from (1) we have \"V\" = \"m\"/\"ρ\". Substituting into (3) gives\n\nThis equation allows the relative density to be calculated from the change in displacement, the known density of the reference liquid, and the known properties of the hydrometer. If Δ\"x\" is small then, as a first-order approximation of the geometric series equation (4) can be written as:\n\nThis shows that, for small Δ\"x\", changes in displacement are approximately proportional to changes in relative density.\n\nA pycnometer (from Greek: πυκνός (puknos) meaning \"dense\"), also called pyknometer or specific gravity bottle, is a device used to determine the density of a liquid. A pycnometer is usually made of glass, with a close-fitting ground glass stopper with a capillary tube through it, so that air bubbles may escape from the apparatus. This device enables a liquid's density to be measured accurately by reference to an appropriate working fluid, such as water or mercury, using an analytical balance.\n\nIf the flask is weighed empty, full of water, and full of a liquid whose relative density is desired, the relative density of the liquid can easily be calculated. The particle density of a powder, to which the usual method of weighing cannot be applied, can also be determined with a pycnometer. The powder is added to the pycnometer, which is then weighed, giving the weight of the powder sample. The pycnometer is then filled with a liquid of known density, in which the powder is completely insoluble. The weight of the displaced liquid can then be determined, and hence the relative density of the powder.\n\nThere is also a gas-based manifestation of a pycnometer known as a \"gas pycnometer\". It compares the change in pressure caused by a measured change in a closed volume containing a reference (usually a steel sphere of known volume) with the change in pressure caused by the sample under the same conditions. The difference in change of pressure represents the volume of the sample as compared to the reference sphere, and is usually used for solid particulates that may dissolve in the liquid medium of the pycnometer design described above, or for porous materials into which the liquid would not fully penetrate.\n\nWhen a pycnometer is filled to a specific, but not necessarily accurately known volume, \"V\" and is placed upon a balance, it will exert a force\n\nwhere \"m\" is the mass of the bottle and \"g\" the gravitational acceleration at the location at which the measurements are being made. \"ρ\" is the density of the air at the ambient pressure and \"ρ\" is the density of the material of which the bottle is made (usually glass) so that the second term is the mass of air displaced by the glass of the bottle whose weight, by Archimedes Principle must be subtracted. The bottle is, of course, filled with air but as that air displaces an equal amount of air the weight of that air is canceled by the weight of the air displaced. Now we fill the bottle with the reference fluid e.g. pure water. The force exerted on the pan of the balance becomes:\n\nIf we subtract the force measured on the empty bottle from this (or tare the balance before making the water measurement) we obtain.\n\nwhere the subscript n indicated that this force is net of the force of the empty bottle. The bottle is now emptied, thoroughly dried and refilled with the sample. The force, net of the empty bottle, is now:\n\nwhere \"ρ\" is the density of the sample. The ratio of the sample and water forces is:\n\nThis is called the Apparent Relative Density, denoted by subscript A, because it is what we would obtain if we took the ratio of net weighings in air from an analytical balance or used a hydrometer (the stem displaces air). Note that the result does not depend on the calibration of the balance. The only requirement on it is that it read linearly with force. Nor does \"RD\" depend on the actual volume of the pycnometer.\n\nFurther manipulation and finally substitution of \"RD\", the true relative density (the subscript V is used because this is often referred to as the relative density \"in vacuo\"), for \"ρ\"/\"ρ\" gives the relationship between apparent and true relative density.\n\nIn the usual case we will have measured weights and want the true relative denstiy. This is found from\n\nSince the density of dry air at 101.325 kPa at 20 °C is 0.001205 g/cm and that of water is 0.998203 g/cm we see that the difference between true and apparent relative densities for a substance with relative density (20 °C/20 °C) of about 1.100 would be 0.000120. Where the relative density of the sample is close to that of water (for example dilute ethanol solutions) the correction is even smaller.\n\nThe pycnometer is used in ISO standard: ISO 1183-1:2004, ISO 1014–1985 and ASTM standard: ASTM D854.\n\nTypes\n\n\n\"Hydrostatic Pressure-based Instruments\": This technology relies upon Pascal's Principle which states that the pressure difference between two points within a vertical column of fluid is dependent upon the vertical distance between the two points, the density of the fluid and the gravitational force. This technology is often used for tank gaging applications as a convenient means of liquid level and density measure.\n\n\"Vibrating Element Transducers\": This type of instrument requires a vibrating element to be placed in contact with the fluid of interest. The resonant frequency of the element is measured and is related to the density of the fluid by a characterization that is dependent upon the design of the element. In modern laboratories precise measurements of relative density are made using oscillating U-tube meters. These are capable of measurement to 5 to 6 places beyond the decimal point and are used in the brewing, distilling, pharmaceutical, petroleum and other industries. The instruments measure the actual mass of fluid contained in a fixed volume at temperatures between 0 and 80 °C but as they are microprocessor based can calculate apparent or true relative density and contain tables relating these to the strengths of common acids, sugar solutions, etc. The vibrating fork immersion probe is another good example of this technology. This technology also includes many coriolis-type mass flow meters which are widely used in chemical and petroleum industry for high accuracy mass flow measurement and can be configured to also output density information based on the resonant frequency of the vibrating flow tubes.\n\n\"Ultrasonic Transducer\": Ultrasonic waves are passed from a source, through the fluid of interest, and into a detector which measures the acoustic spectroscopy of the waves. Fluid properties such as density and viscosity can be inferred from the spectrum.\n\n\"Radiation-based Gauge\": Radiation is passed from a source, through the fluid of interest, and into a scintillation detector, or counter. As the fluid density increases, the detected radiation \"counts\" will decrease. The source is typically the radioactive isotope cesium-137, with a half-life of about 30 years. A key advantage for this technology is that the instrument is not required to be in contact with the fluid—typically the source and detector are mounted on the outside of tanks or piping.\n\n\"Buoyant Force Transducer\": the buoyancy force produced by a float in a homogeneous liquid is equal to the weight of the liquid that is displaced by the float. Since buoyancy force is linear with respect to the density of the liquid within which the float is submerged, the measure of the buoyancy force yields a measure of the density of the liquid. One commercially available unit claims the instrument is capable of measuring relative density with an accuracy of ± 0.005 RD units. The submersible probe head contains a mathematically characterized spring-float system. When the head is immersed vertically in the liquid, the float moves vertically and the position of the float controls the position of a permanent magnet whose displacement is sensed by a concentric array of Hall-effect linear displacement sensors. The output signals of the sensors are mixed in a dedicated electronics module that provides a single output voltage whose magnitude is a direct linear measure of the quantity to be measured.\n\nSubstances with a relative density of 1 are neutrally buoyant, those with RD greater than one are denser than water, and so (ignoring surface tension effects) will sink in it, and those with an RD of less than one are less dense than water, and so will float.\n\nExample:\n\n\n"}
{"id": "4002187", "url": "https://en.wikipedia.org/wiki?curid=4002187", "title": "Rushcart", "text": "Rushcart\n\nThe rushcart ceremony, derives from Rogationtide. Parishioners would process around the parish once a year, bearing rushes. They would end up at the parish church and place the rushes on the floor of the church, to replace worn-out rushes. In modern times the ceremony is practised only in parts of northern England including Lancashire and Cumbria among others.\n\nAccording to John Cutting, the earliest record of rushbearing is 1385 at Tavistock.\n\nThe custom of strewing cut vegetation on the floors of churches began at an earlier date: the plants commonly used were hay, straw or rushes and together with strewing herbs they improved the comfort for those using the church. Before the Reformation churches served for many secular as well as religious purposes and seating was not usual until the early years of the 16th century. Renewal of the floor covering was usually carried out before major festivals such as Easter and the patronal festival. Since these were among the few times in the year available for merrymaking ceremonies grew up and were handed down by tradition.\n\nAs towns grew in size, the places where rushes still grew were further and further from the church itself. Also changes in the way churches were furnished such as box pews and in the 19th century more effective heating in churches made the ceremonies redundant. The ceremonies either lapsed, or became longer and larger. The earliest depictions of rushcarts are in \"Rush-Bearing\" (1891) by Burton. One illustration shows morris dancers and a rushcart at Failsworth Pole, near Manchester, about 1820. Another, from 1821, is a painting by Alexander Wilson of an event at Long Millgate, Manchester. They now appear to be confined to the north west of England. At least 5 rushbearing ceremonies still occur in Cumbria where girls dressed in green process around the town.\n\nThe Rushcart grew into a festival held on the annual wakes week or mill holidays. There would be music, dancing and other entertainments. Each village would try to outdo the others by building a bigger or more elaborate structure with the front covered by a sheet decorated with tinsel and artificial flowers and hung with polished copper, brass and silver household items.\nBehold the rush-cart, and the throng<br>\nOf lads and lasses pass along:<br>\nNow, view the nimble morris-dancers,<br>\nThe blithe, fantastic, antic prancers,<br>\nBedeck'd in gaudiest profusion,<br>\nWith ribbons in a sweet confusion<br>\nOf brilliant colours, richest dyes,<br>\nLike wings of moths and butterflies-<br>\nWaving white kerchiefs in the air,<br>\nAnd crossing here, re-crossing there,<br>\nAnd up and down, and everywhere:<br>\nSpringing, bounding, gaily skipping,<br>\nDeftly, briskly, no one tripping:<br>\nAll young fellows, blithe and hearty,<br>\nThirty couples in the party ...<br>\nThe coming of the railways led to a decline in interest in Rushcarts as the local population were able to travel further afield for their annual break. The Rushcarts eventually died out in the early 20th century. There is a curious similarity between this festival and the Hindu festival of the chariot of Jagannath.\n\nFrance and Woodall in their \"A New History of Didsbury\" give the text of an anonymous account of the rushcart perhaps of the 1860s and entries in the churchwardens' accounts for 1733 and 1808 among other statements recorded by local people. It is uncertain when the rushbearing was ended in Didsbury, certainly not before 1870. The associated rowdyism was not thought desirable by the more sober parishioners of the time according to Alfred Burton in his \"Rushbearing\". However Fletcher Moss's \"Fifty Years of Public Work\" includes photographs of the Didsbury rushcarts of 1882 and 1911, the last occasion. (If the dates are genuine Burton is either mistaken or it was discontinued for some years and then revived.) In the nearby township of Chorlton cum Hardy, the ceremony took place on the eve of the last Sunday in July though very little is known about how long it continued to be observed.\n\nAn account of the Fallowfield Rushcart was given by Annie C. Williamson in her book about the township (1888). It was part of the Fallowfield Wakes celebrations and often included Robin Hood and Maid Marian seated on a pile of rushes heaped upon a farm cart. The cart was accompanied by the sound of pipes, penny whistles, clogs being used to beat time on the ground, and the shouts of the people.\n\nThe Gorton rushbearing ceremony was relaunched by the Gorton Morrismen in 1980 having last been celebrated in 1874. It ceased again in 1991 but was resurrected \"one last time\" in 2009 to celebrate the 100th year of Gorton becoming a part of Manchester.\n\n\n\n\n"}
{"id": "727110", "url": "https://en.wikipedia.org/wiki?curid=727110", "title": "Samuel Hunter Christie", "text": "Samuel Hunter Christie\n\nSamuel Hunter Christie FRS (22 March 1784 – 24 January 1865) was a British scientist, physicist and mathematician.\n\nHe studied mathematics at Trinity College, Cambridge, where he won the Smith's Prize and was second wrangler. He was particularly interested in magnetism, studying the earth's magnetic field and designing improvements to the magnetic compass. Some of his magnetic research was done in collaboration with Peter Barlow. He became a Fellow of the Royal Society in 1826, delivered their Bakerian Lecture in 1833 and served as their Secretary from 1837 to 1853. In 1833 he published his 'diamond' method, the forerunner of the Wheatstone bridge, in a paper on the magnetic and electrical properties of metals, as a method for comparing the resistances of wires of different thicknesses. However, the method went unrecognised until 1843, when Charles Wheatstone proposed it, in another paper for the Royal Society, for measuring resistance in electrical circuits. Although Wheatstone presented it as Christie's invention, it is his name, rather than Christie's, that is now associated with the device.\n\nChristie taught mathematics at the Royal Military Academy, Woolwich, from 1838 until his retirement in 1854. \nHe died at Twickenham, on 24 January 1865.\n\nA portrait photograph of Christie in 1865 by Ernest Edwards is held by the National Portrait Gallery. \nHe had ten children (five with each wife), of which eight survived him. \nHis eldest son with his second wife was the astronomer William Henry Mahoney Christie (1845–1922).\n\nSamuel Christie is the son of one James Christie, although this was almost certainly not the auctioneer James Christie (founder of the great auction house). \nInstead he was probably the son of a James Christie who in 1821 described himself as a tailor, late of Leicester Square but then of Newman Street, and who died in 1825 aged eighty-six. Because they had the same name, some confusion has arisen between the two James Christie's and many websites incorrectly state that he was the son of the auctioneer. \nBut, as the latter occupied a house in Pall Mall from 1768 until 1803, and died in that year, it seems certain that the James Christie who lived in Leicester Square was not the auctioneer.\n\n\n"}
{"id": "49331986", "url": "https://en.wikipedia.org/wiki?curid=49331986", "title": "Self-Protect High-Energy Laser Demonstrator", "text": "Self-Protect High-Energy Laser Demonstrator\n\nThe Self-Protect High-Energy Laser Demonstrator (SHiELD) is a directed energy weapons development program. The objective of this programme is to demonstrate the ability of a laser system mounted on aircraft. The program will develop and integrate a moderate power laser in a fighter-compatible pod. It was reported that United States Air Force is considering to get defensive laser weapon for fifth and sixth generation fighter jets by 2021.\n"}
{"id": "19128515", "url": "https://en.wikipedia.org/wiki?curid=19128515", "title": "Silylium ion", "text": "Silylium ion\n\nA silylium ion is a reactive silyl-containing cation with the formula . With three rather than the usual four bonds to Si, silylium ions are the silicon analogues of carbenium ions. They can be viewed as protonated silylenes. A well-characterized example is trimesitylsilylium, . This salt has been crystallized with an anionic carborane, a weakly coordinating anion. This cation is related to trityl (), with the extra methyl groups providing steric protection, compensating for the greater size of Si vs C. Its Si NMR chemical shift is 225.5 ppm, downfield of TMS, which indicates that the cation is quite \"naked\". In contrast, MeSiOTf, normally considered a source of electrophilic silicon, has a Si NMR shift of 43 ppm.\n"}
{"id": "51921147", "url": "https://en.wikipedia.org/wiki?curid=51921147", "title": "Spin gapless semiconductor", "text": "Spin gapless semiconductor\n\nSpin gapless semiconductors are a novel class of materials with unique electrical band structure for different spin channels in such a way that there is no band gap (i.e., 'gapless') for one spin channel while there is a finite gap in another spin channel.\n\nIn a spin-gapless semiconductor, conduction and valence band edges touch, so that no threshold energy is required to move electrons from occupied (valence) states to empty (conduction) states. This gives spin-gapless semiconductors unique properties: namely that their band structures are extremely sensitive to external influences (e.g., pressure or magnetic field). \n\nBecause very little energy is needed to excite electrons in an SGS, charge concentrations are very easily ‘tuneable’. For example, this can be done by introducing a new element (doping) or by application of a magnetic or electric field (gating).\n\nA new type of spin gapless semiconductor identified in 2017, known as Dirac-type spin-gapless semiconductors, has linear dispersion and is considered an ideal platform for massless and dissipationless spintronics because spin-orbital coupling opens a gap for the spin fully polarized conduction and valence band, and as a result, the interior of the sample becomes an insulator, however, an electrical current can flow without resistance at the sample edge. This effect, the quantum anomalous Hall effect has only previously been realised in magnetically doped topological insulators.\n\nElectron mobility in such materials is two to four orders of magnitude higher than in classical semiconductors.\n\nThe spin gapless semiconductor was first proposed as a new spintronics concept and a new class of candidate spintronic materials in 2008 in a paper by Xiaolin Wang of the University of Wollongong in Australia. \n\nThe spin gapless semiconductor is a promising candidate material for spintronics because its charged particles can be fully spin-polarised, so that spin can be controlled via only a small applied external energy.\n"}
{"id": "865107", "url": "https://en.wikipedia.org/wiki?curid=865107", "title": "Stover", "text": "Stover\n\nStover is the leaves and stalks of field crops, such as corn (maize), sorghum or soybean that are commonly left in a field after harvesting the grain. It is similar to straw, the residue left after any cereal grain or grass has been harvested at maturity for its seed. It can be directly grazed by cattle or dried for use as fodder. Stover has attracted some attention as a potential fuel source, and as biomass for fermentation or as a feedstock for cellulosic ethanol production. Stover from various crops can also be used in mushroom compost preparation.\n\nThe word 'stover' derives from the English legal term 'estovers', referring to the right of tenants to cut timber.\n\n"}
{"id": "33633277", "url": "https://en.wikipedia.org/wiki?curid=33633277", "title": "Substitutional fuel", "text": "Substitutional fuel\n\nSubstitutional fuels are the fuels which can replace, partially or completely, the conventional fuels.\nIt includes biodiesel, biogas, alcohol, myco-diesel, algal fuel, metal fuel.\n"}
{"id": "12302694", "url": "https://en.wikipedia.org/wiki?curid=12302694", "title": "Thermomechanical generator", "text": "Thermomechanical generator\n\nThe Harwell TMG Stirling engine, an abbreviation for \"Thermo-Mechanical Generator\", was invented in 1967 by E. H. Cooke-Yarborough at the Harwell Labs of the United Kingdom Atomic Energy Authority. It was intended to be a remote electrical power source with low cost and very long life, albeit by sacrificing some efficiency. The TMG (model TMG120) was at one time the only Stirling engine sold by a manufacturer, namely HoMach Systems Ltd., England.\n\nThe engine has near isothermal cylinders because 1) the heater area covers the entire cylinder end, 2) it is a short stroke device, with wide shallow cylinders, yielding a high surface area to volume ratio, 3) the average thickness of the gas space is about 0.1 cm, and 4) the working fluid is Helium, a gas having good thermal properties for Stirling engines. \n\nThe engine's displacer also has very low losses. These low-loss operating characteristics simplify the engine analysis, compared to more conventional Stirling engines.\n\nThe design has many advantages over conventional Stirling engines. The simplicity of the heater greatly reduces the cost by allowing the TMG to avoid the need for a brazed tubular or finned heater, which can account for 40% of the cost of a conventional Stirling engine. The heat exchangers for the heater and cooler are mechanically trivial. The regenerator is a simple annulus, referred to as a \"flat plate\". Along with the cylinder wall and the displacer, there are a total of four regenerating surfaces. The TMG is a free piston engine. There are no rolling bearings or sliding seals, thus there is very little friction or wear. The working space is hermetically sealed, allowing it to contain pressurized helium gas for many thousands of hours. \n\nThe displacer is a stainless steel can, 27 cm in diameter. It is suspended by a low-loss planer metal spring centered in a 27.4 cm diameter cylinder. The 2 mm radial clearance is divided into two concentric annular gaps by a thin, open-ended cylinder, which is fixed to the engine's cylinder. This annulus acts as the regenerator, which is much less costly than a wire-mesh type. \n\nThe engine is a \"free-cylinder\" design, in which the entire engine is mounted on springs and allowed to vibrate slightly. This allows the displacer to be driven by positive feedback from the motion of the power piston and the magnets in the linear-alternator magnets, which have a combined weight of 10 kg.\n\nThe unique power piston was invented by Cooke-Yarborough, and is called an \"articulated diaphragm\". It consists of a stainless steel annulus, with an outer diameter of 35 cm and an inner diameter of 26 cm. This annulus is clamped to the engine on the outer edge by two flexible rubber o-rings, and on the inner edge it is similarly clamped, in this case to a rigid center hub that makes up the piston's center. The o-rings flex but do not slide, thus no lubricant is needed and there is negligible wear in the entire machine. \n\nThe compression space is located between the power-piston hub and the displacer, and this space is cooled by direct conduction through the power piston. A developmental model of the TMG contained a double articulated diaphragm containing cooling water, which was pumped by a thermosyphon. The depth of the compression space varies from 0.2 to 2.7 mm, as governed by the 2 mm displacer stroke and the 1.5 mm power piston stroke moving 90 degrees out of phase.\n\nThe TMG engine successfully overcomes many of the economic and mechanical difficulties common in conventional Stirling engines. However, there are some limitations of this design. The simple, low-cost annular regenerator is inefficient compared to other types, (and this contributes to this engine's somewhat low thermal efficiency of only 10%). The mechanical limitations of the articulated diaphragm only allow a maximum stroke of an estimated 3 mm. These properties limit the maximum obtainable power to about 500 - 1000 Watts from an engine of this design. Nevertheless, it is rare for a low-cost Stirling engine to obtain this high level of reliability and operating life, which can only be attributed to the ingenuity of the design.\n"}
{"id": "22974745", "url": "https://en.wikipedia.org/wiki?curid=22974745", "title": "Truganina Explosives Reserve", "text": "Truganina Explosives Reserve\n\nThe Truganina Explosives Reserve was a secure storage facility near Altona in the Australian state of Victoria. It was in operation from 1901 to 1962 to store mainly civilian explosives for mining and construction. The camp included several storage sheds and a jetty, which were connected by a narrow-gauge horse-drawn tramway. Like the Dry Creek explosives depot at Port Adelaide, the site is a testimony to history and transportation in Australia. \n\nAltona's Truganina Explosives Reserve is located approximately south-west of Melbourne, and west of Williamstown on the shores of Port Phillip Bay. \n\nThe Nobel explosives factory (later ICI, then Orica) in Deer Park was set-up in 1873 to produce explosives, especially gelignite and dynamite, for quarries, mines, as well as for road, rail, dam and tunnel construction with the intention to become independent of imports from Britain and South Africa. These explosives were initially stored in specially designed magazines (Jack's Magazine) on the banks of the Maribyrnong River, upstream of Footscray, before being shipped to other parts of Australia or to New Zealand, New Guinea and the Pacific. As the population of Footscray increased, a more remote location for explosives storage was sought. In 1900, Altona had less than fifty inhabitants. The Truganina Explosives Reserve, located less than from Laverton railway station, was finally selected as a convenient location for a new explosives storage site due to its secluded coastal location.\n\nMost of the land had been owned by George Thomas Chirnside, before he agreed in 1896 to swap of his land against of poor quality land of the government of Victoria. The Victorian Government's Victorian Act 1456 is known as the Powder Magazines Act of 1896. A Victorian Act authorized the governor to exchange this land to set-up an explosives reserve and to build and operate a narrow gauge railway line.\n\nThe 610 mm (2 ft) narrow-gauge tramway line began at Laverton railway station and ran along what are now Merton Street and Queen Street through the Truganina Explosives Reserve and then to a jetty at Laverton Creek on Altona Bay. It had eight passing loops parallel to the mainline at the storage facility, as well as sheds and dead-end sidings at Laverton station.\n\nExplosives were delivered by the Victorian Railways from the factory in Deer Park to Laverton railway station. There, the explosives were reloaded by human chain from the railway wagons into the horse-drawn narrow-gauge wagons. The narrow-gauge railway wagons were then hauled by Clydesdale draft horses at a speed of about to the explosives reserve. The narrow-gauge railway line was 2.7 km (133 chains) long. It was in operation until 1936, when rail transport was replaced by road transport. Upon arriving at the reserve, the explosives were stored in the magazines, until they were taken to be loaded onto ships for onward transport. Nine explosives transports were carried out each day with 200 explosives boxes of 50 pounds (22.7 kg) each. Nine horses and 43 wagons were used.\n\nWhen the explosives had to be shipped to other ports, the explosive boxes were taken by narrow-gauge railway to small boats (lighters) moored at the pier. The specially designed motor-less sailing ships were towed by tugs from the jetty to their moorings at Williamstown. From there lighters took their cargo to larger ships anchored at special explosives buoys in Port Philip Bay.\n\nEach magazine had a size of about and could store 20 tons of explosives. The magazines were made of brick, with tile roofs. The roofs were not attached to the walls - they stayed there under their own weight. This was so that, in the event of an explosion, the roof would lift off, minimising damage to the building. The explosives were stacked on air-permeable shelves, so that air could circulate around the boxes at any time. The wooden boxes for explosives were made with brass nails or with only dovetail joints to minimize the possibility of sparking. Each magazine was surrounded on three sides by a large earth wall, with an open side facing away from human activity. These earthworks were designed to protect the workers and their families from explosions. If such an explosion had taken place, the mounds were designed to direct the explosion upwards and outwards and contain the damage. The magazines were built as light as possible to minimize damage caused by flying splinters, with the same design as used in and Port Adelaide.\n\nThe operation of the explosives reserve and the narrow gauge railway was managed by the Trade and Customs Commissioner. The site was officially opened on 1 May 1901, and was enclosed by a high, long galvanized corrugated iron fence. Careful handling, transportation and storage of the explosive was of paramount importance to ensure safety for employees and residents. Employees who handled the explosives were instructed to wear leather aprons to protect their clothes and to wear canvas overshoes to prevent sparks. Boots with nailed leather soles were considered too dangerous, because of the possibility of the nails causing sparks, which could have resulted in an explosion.\n\nBy 1950, the explosives storage in Altona had reached its peak. Sixty-one magazines were in operation. Of these, 52 were used by Nobel Industries, which became later Imperial Chemical Industries of Australia and New Zealand (ICIANZ), and nine by the state government. A total of 36 employees were employed in the explosives reserve. During this time, the population of Altona grew to 4,000. Therefore, the risk of explosives storage in Altona was re-assessed and alternative locations were evaluated. On 11 May 1962, the auxiliary sailing ship \"Failie\" became the last vessel to be loaded at the Truganina explosives reserve; all remaining explosives were transported to a newly-built explosives warehouse at Point Wilson. The first delivery from Point Wilson took place on 25 May 1962.\n\nAfter the closure of the Truganina Explosives Reserve in 1962 the Victorian Government sold most of the land, but retained for the State Labour Inspectorate for Destruction of Dangerous Goods. Until closed in 1994, unwanted explosives from throughout Victoria were brought to this site for safe destruction in a specially constructed bunker. In 1976, of the 16 hectares were transferred to the State Environmental Protection Agency for use as a vehicle test station, which was closed in June 1999. In June 2000, the Government of Victoria commissioned the Hobsons Bay City Council to administer the former Truganina Explosives Reserve on their behalf as a recreational park.\n\nThere were no significant accidents during operation. The stables in Truganina's explosives reserve were burnt down in 1904, presumably by a swagman, however the suspect was not arrested for lack of evidence.\n\nOn 9 April 1946 an ammunition lighter had grounded in a storm and was feared to be in danger of blowing up. It was loaded with 300 tons of ammunition, mainly shells. The ammuniton could not be unloaded at low tide onto trucks, because of seaweed and the softness of the sand. Thus it was tried to pull the lighter back into the sea by tugs during high tide.\n\nThe salt marshes and ancient sand dunes have a high conservation value and are the location of rare animal and plant species. Areas of indigenous, exotic and saline vegetation and the hills of the dune system form landscapes with different characteristics that seem timeless. The high corrugated sheet metal fence has protected the site from human entry, leaving it largely undisturbed for more than 100 years, creating a natural, native ecosystem. The reserve is home to three species of birds of local importance, the white-bellied sea eagle, Nankeen night heron and the brown quail. It also houses four bat species including chocolate wattled bat, white-striped free-tailed bat, south-eastern slider, eight other species of mammals and two species of reptiles. The Altona skipper butterfly is a rare and threatened species of butterfly, which has its main habitat at only at two other local sites, where it can find chaffey saw sedge (Ghania filum) to feed from.\n\nArchaeological research on the property has uncovered many stone artifacts, including ground-edge axes, anvils and hammer-stones, indicating that the land was inhabited by Aboriginal tribes in the coastal area for some 6,500 years. Remnants of indigenous settlement were also found on the property, which together with the artifacts show that the area was used as a storage area. The Department of Treasury and Finance conducted archeological investigations in the former explosives reserve in 1995 and 1996, during which consultants found six artifact sites but no scarred trees, hearths, hearth stones, bone remains or shell scatters.\n\nThe area is part of the traditional land of the Yalukit-willam clan, which settled in the coastal areas that stretch from the northern shores of Port Phillip to Wilson's Promontory. Little is known about the lifestyle of the Yalukit-willam clan. The Wurrundjeri Tribe Land Compensation Council and the Council of Cultural Heritage take care of the region's cultural heritage.\nThe name of the explosives reserve is derived from Truganini (1812-1876), who was long considered the last true Aboriginal Tasmanian. She was a daughter of the tribal elder Mananga of the Aborigines of Bruny Island.\n\nThe Truganina Explosives Reserve is listed under Hermes number 70270 in the Victorian Heritage Database Report. The historical attributes of the site are of Regional Significance. The site is still state owned and has been nominated for listing in the Victorian State Heritage Register. The Keepers Quarters residence is already listed as a local heritage by the Hobson's Bay City Council.\n\nOnly little remains of the former tramway have survived. The only visible part of the route can be seen on the south side of the reserve, where it ran in a curve through a gate towards the pier. Some rails with the embossing \"WIW Australia\" and a crown symbol are embedded in a in a concrete channel. The crown symbol is probably a trademark of the Commonwealth Steel Company, whose Waratah Iron Works supplied many railways. The route then disappears there underneath the earthworks of a modern footpath.\nThe railway embankment, which was made of bluestone ballast, became visible during road works on the northeast corner of Queen Street and Merton Street. At this point the right of way of the narrow-gauge tramway line ran with a suitable radius over the property situated at the corner. Another section of the road is preserved near the ford westwards of Merton Street, again only as the earth dam, which turns west from the entrance to Laverton railway station and is partly overbuilt with a modern cycle path. The rails and sleepers are missing in these two sections and other sections of the routes within the reserve, but gravel and few metal artifacts are still visible. The sections within the reserve are either buried or overgrown.\n\n"}
{"id": "3060924", "url": "https://en.wikipedia.org/wiki?curid=3060924", "title": "Volcanic gas", "text": "Volcanic gas\n\nVolcanic gases are gases given off by active (or, at times, by dormant) volcanoes. These include gases trapped in cavities (vesicles) in volcanic rocks, dissolved or dissociated gases in magma and lava, or gases emanating directly from lava or indirectly through ground water heated by volcanic action.\n\nThe sources of volcanic gases on Earth include: \nSubstances that may become gaseous or give off gases when heated are termed volatile substances.\n\nThe principal components of volcanic gases are water vapor (HO), carbon dioxide (CO), sulfur either as sulfur dioxide (SO) (high-temperature volcanic gases) or hydrogen sulfide (HS) (low-temperature volcanic gases), nitrogen, argon, helium, neon, methane, carbon monoxide and hydrogen. Other compounds detected in volcanic gases are oxygen (meteoric), hydrogen chloride, hydrogen fluoride, hydrogen bromide, nitrogen oxide (NO), sulfur hexafluoride, carbonyl sulfide, and organic compounds. Exotic trace compounds include mercury, halocarbons (including CFCs), and halogen oxide radicals.\n\nThe abundance of gases varies considerably from volcano to volcano, with volcanic activity and with tectonic setting. Water vapour is consistently the most abundant volcanic gas, normally comprising more than 60% of total emissions. Carbon dioxide typically accounts for 10 to 40% of emissions.\n\nVolcanoes located at convergent plate boundaries emit more water vapor and chlorine than volcanoes at hot spots or divergent plate boundaries. This is caused by the addition of seawater into magmas formed at subduction zones. Convergent plate boundary volcanoes also have higher HO/H, HO/CO, CO/He and N/He ratios than hot spot or divergent plate boundary volcanoes.\n\nMagma contains dissolved volatile components, as described above. The solubilities of the different volatile constituents are dependent on pressure, temperature and the composition of the magma. As magma ascends towards the surface, the ambient pressure decreases, which decreases the solubility of the dissolved volatiles. Once the solubility decreases below the volatile concentration, the volatiles will tend to come out of solution within the magma (exsolve) and form a separate gas phase (the magma is super-saturated in volatiles).\n\nThe gas will initially be distributed throughout the magma as small bubbles, that cannot rise quickly through the magma. As the magma ascends the bubbles grow through a combination of expansion through decompression and growth as the solubility of volatiles in the magma decreases further causing more gas to exsolve. Depending on the viscosity of the magma, the bubbles may start to rise through the magma and coalesce, or they remain relatively fixed in place until they begin to connect and form a continuously connected network. In the former case, the bubbles may rise through the magma and accumulate at a vertical surface, e.g. the 'roof' of a magma chamber. In volcanoes with an open path to the surface, e.g. Stromboli in Italy, the bubbles may reach the surface and as they pop small explosions occur. In the latter case, the gas can flow rapidly through the continuous permeable network towards the surface. This mechanism has been used to explain activity at Santiaguito, Santa Maria volcano, Guatemala and Soufrière Hills Volcano, Montserrat. If the gas cannot escape fast enough from the magma, it will fragment the magma into small particles of ash. The fluidised ash has a much lower resistance to motion than the viscous magma, so accelerates, causing further expansion of the gases and acceleration of the mixture. This sequence of events drives explosive volcanism. Whether gas can escape gently (passive eruptions) or not (explosive eruptions) is determined by the total volatile contents of the initial magma and the viscosity of the magma, which is controlled by its composition.\n\nThe term `closed system' degassing refers to the case where gas and its parent magma ascend together and in equilibrium with each other. The composition of the emitted gas is in equilibrium with the composition of the magma at the pressure, temperature where the gas leaves the system. In `open system' degassing, the gas leaves its parent magma and rises up through the overlying magma without remaining in equilibrium with that magma. The gas released at the surface has a composition that is a mass-flow average of the magma exsolved at various depths and is not representative of the magma conditions at any one depth.\n\nMolten rock (either magma or lava) near the atmosphere releases high-temperature volcanic gas (>400 °C). \nIn explosive volcanic eruptions, the sudden release of gases from magma may cause rapid movements of the molten rock. When the magma encounters water, seawater, lake water or groundwater, it can be rapidly fragmented. The rapid expansion of gases is the driving mechanism of most explosive volcanic eruptions. However, a significant portion of volcanic gas release occurs during quasi-continuous quiescent phases of active volcanism.\n\nAs magmatic gas travelling upward encounters meteoric water in an aquifer, steam is produced. Latent magmatic heat can also cause meteoric waters to ascend as a vapour phase. Extended fluid-rock interaction of this hot mixture can leach constituents out of the cooling magmatic rock and also the country rock, causing volume changes and phase transitions, reactions and thus an increase in ionic strength of the upward percolating fluid. This process also decreases the fluid's pH. Cooling can cause phase separation and mineral deposition, accompanied by a shift toward more reducing conditions. At the surface expression of such hydrothermal systems, low-temperature volcanic gases (<400 °C) are either emanating as steam-gas mixtures or in dissolved form in hot springs. At the ocean floor, such hot supersaturated hydrothermal fluids form gigantic chimney structures called black smokers, at the point of emission into the cold seawater.\n\nThe gas release can occur by advection through fractures, or via diffuse degassing through large areas of permeable ground as diffuse degassing structures (DDS). At sites of advective gas loss, precipitation of sulfur and rare minerals forms sulfur deposits and small sulfur chimneys, called fumaroles. Very low-temperature (below 100 °C) fumarolic structures are also known as solfataras. Sites of cold degassing of predominantly carbon dioxide are called mofettes. Hot springs on volcanoes often show a measurable amount of magmatic gas in dissolved form.\n\nVolcanic gases were collected and analysed as long ago as 1790 by Scipione Breislak in Italy. The composition of volcanic gases is dependent on the movement of magma within the volcano. Therefore, sudden changes in gas composition often presage a change in volcanic activity. Accordingly, a large part of hazard monitoring of volcanoes involves regular measurement of gaseous emissions. For example, an increase in the CO content of gases at Stromboli has been ascribed to injection of fresh volatile-rich magma at depth within the system. \n\nVolcanic gases can be sensed (measured in-situ) or sampled for further analysis. Volcanic gas sensing can be:\n\nSulphur dioxide (SO) absorbs strongly in the ultraviolet wavelengths and has low background concentrations in the atmosphere. These characteristics make sulphur dioxide a good target for volcanic gas monitoring. It can be detected by satellite-based instruments, which allow for global monitoring, and by ground-based instruments such as DOAS. DOAS arrays are placed near some well-monitored volcanoes and used to estimate the flux of SO emitted. The Multi-Component Gas Analyzer System (Multi-GAS) is also used to remotely measure CO and SO. The fluxes of other gases are usually estimated by measuring the ratios of different gases within the volcanic plume, e.g. by FTIR, electrochemical sensors at the volcano crater rim, or direct sampling, and multiplying the ratio of the gas of interest to SO by the SO flux.\n\nDirect sampling of volcanic gas sampling is often done by a method involving an evacuated flask with caustic solution, first used by Robert W. Bunsen (1811-1899) and later refined by the German chemist Werner F. Giggenbach (1937-1997), dubbed \"Giggenbach-bottle\". Other methods include collection in evacuated empty containers, in flow-through glass tubes, in gas wash bottles (cryogenic scrubbers), on impregnated filter packs and on solid adsorbent tubes.\n\nAnalytical techniques for gas samples comprise gas chromatography with thermal conductivity detection (TCD), flame ionization detection (FID) and mass spectrometry (GC-MS) for gases, and various wet chemical techniques for dissolved species (e.g., acidimetric titration for dissolved CO, and ion chromatography for sulfate, chloride, fluoride). The trace metal, trace organic and isotopic composition is usually determined by different mass spectrometric methods.\n\nCertain constituents of volcanic gases may show very early signs of changing conditions at depth, making them a powerful tool to predict imminent unrest. Used in conjunction with monitoring data on seismicity and deformation, correlative monitoring gains great efficiency. Volcanic gas monitoring is a standard tool of any volcano observatory. Unfortunately, the most precise compositional data still require dangerous field sampling campaigns. However, remote sensing techniques have advanced tremendously through the 1990s. The Deep Earth Carbon Degassing Project is employing Multi-GAS remote sensing to monitor 9 volcanoes on a continuous basis.\n\nVolcanic gases were directly responsible for approximately 3% of all volcano-related deaths of humans between 1900 and 1986. Some volcanic gases kill by acidic corrosion; others kill by asphyxiation. The greenhouse gas, carbon dioxide, which is odorless, is emitted from volcanoes, accounting for nearly 1% of the annual global total. Some volcanic gases including sulfur dioxide, hydrogen chloride, hydrogen sulfide and hydrogen fluoride react with other atmospheric particles to form aerosols.\n\n"}
{"id": "38260417", "url": "https://en.wikipedia.org/wiki?curid=38260417", "title": "Xitieshan Solar Park", "text": "Xitieshan Solar Park\n\nCGN's Xitieshan Solar Park is a 100 megawatt (MW) photovoltaic power station located in the Qinghai Province, China. Construction was completed in three phases, Xitieshan Phase I was 10 MW, Xitieshan Phase II was 30 MW, and Xitieshan Phase III was 60 MW. It was completed on 30 September 2011, and at the time was the largest grid connected photovoltaic power station in the world.\n\n\n"}
