{"id": "2249310", "url": "https://en.wikipedia.org/wiki?curid=2249310", "title": "Aether theories", "text": "Aether theories\n\nAether theories (also known as ether theories) in physics propose the existence of a medium, the aether (also spelled \"ether\", from the Greek word (), meaning \"upper air\" or \"pure, fresh air\"), a space-filling substance or field, thought to be necessary as a transmission medium for the propagation of electromagnetic or gravitational forces. The assorted \"aether theories\" embody the various conceptions of this \"medium\" and \"substance\"\". This early modern aether has little in common with the aether of classical elements from which the name was borrowed. Since the development of special relativity, theories using a substantial aether fell out of use in modern physics, and were replaced by more abstract models.\n\nIsaac Newton suggests the existence of an aether in the Third Book of \"Opticks\" (1718): \"Doth not this aethereal medium in passing out of water, glass, crystal, and other compact and dense bodies in empty spaces, grow denser and denser by degrees, and by that means refract the rays of light not in a point, but by bending them gradually in curve lines? ...Is not this medium much rarer within the dense bodies of the Sun, stars, planets and comets, than in the empty celestial space between them? And in passing from them to great distances, doth it not grow denser and denser perpetually, and thereby cause the gravity of those great bodies towards one another, and of their parts towards the bodies; every body endeavouring to go from the denser parts of the medium towards the rarer?\"\n\nIn the 19th century, luminiferous aether (or ether), meaning light-bearing aether, was a theorized medium for the propagation of light (electromagnetic radiation). However, a series of increasingly complex experiments had been carried out in the late 1800s like the Michelson-Morley experiment in an attempt to detect the motion of Earth through the aether, and had failed to do so. A range of proposed aether-dragging theories could explain the null result but these were more complex, and tended to use arbitrary-looking coefficients and physical assumptions. Joseph Larmor discussed the aether in terms of a moving magnetic field caused by the acceleration of electrons.\n\nJames Clerk Maxwell said of the aether, \"In several parts of this treatise an attempt has been made to explain electromagnetic phenomena by means of mechanical action transmitted from one body to another by means of a medium occupying the space between them. The undulatory theory of light also assumes the existence of a medium. We have now to show that the properties of the electromagnetic medium are identical with those of the luminiferous medium.\"\n\nHendrik Lorentz and George Francis FitzGerald offered within the framework of Lorentz ether theory a more elegant solution to how the motion of an absolute aether could be undetectable (length contraction), but if their equations were correct, Albert Einstein's 1905 special theory of relativity could generate the same mathematics without referring to an aether at all. This led most physicists to conclude that this early modern notion of a luminiferous aether was not a useful concept. Einstein however stated that this consideration was too radical and too anticipatory and that his theory of relativity still needed the presence of a medium with certain properties.\n\nFrom the 16th until the late 19th century, gravitational phenomena had also been modelled utilizing an aether. The most well-known formulation is Le Sage's theory of gravitation, although other models were proposed by Isaac Newton, Bernhard Riemann, and Lord Kelvin. None of those concepts are considered to be viable by the scientific community today.\n\nEinstein sometimes used the word \"aether\" for the gravitational field within general relativity, but this terminology never gained widespread support.\n\nQuantum mechanics can be used to describe spacetime as being non-empty at extremely small scales, fluctuating and generating particle pairs that appear and disappear incredibly quickly. It has been suggested by some such as Paul Dirac that this quantum vacuum may be the equivalent in modern physics of a particulate aether. However, Dirac's aether hypothesis was motivated by his dissatisfaction with quantum electrodynamics, and it never gained support from the mainstream scientific community.\n\nRobert B. Laughlin, Nobel Laureate in Physics, endowed chair in physics, Stanford University, had this to say about ether in contemporary theoretical physics:\n\nLouis de Broglie stated, \"Any particle, ever isolated, has to be imagined as in continuous \"energetic contact\" with a hidden medium.\"\n\nAccording to the philosophical point of view of Einstein, Dirac, Bell, Polyakov, ’t Hooft, Laughlin, de Broglie, Maxwell, Newton and other theorists, there might be a medium with physical properties filling 'empty' space, an aether, enabling the observed physical processes.\n\nAlbert Einstein in 1894 or 1895: \"The velocity of a wave is proportional to the square root of the elastic forces which cause [its] propagation, and inversely proportional to the mass of the aether moved by these forces.\"\n\nAlbert Einstein in 1920: \"We may say that according to the general theory of relativity space is endowed with physical qualities; in this sense, therefore, there exists an Aether. According to the general theory of relativity space without Aether is unthinkable; for in such space there not only would be no propagation of light, but also no possibility of existence for standards of space and time (measuring-rods and clocks), nor therefore any space-time intervals in the physical sense. But this Aether may not be thought of as endowed with the quality characteristic of ponderable media, as consisting of parts which may be tracked through time. The idea of motion may not be applied to it.\"\n\nPaul Dirac wrote in 1951: \"Physical knowledge has advanced much since 1905, notably by the arrival of quantum mechanics, and the situation [about the scientific plausibility of Aether] has again changed. If one examines the question in the light of present-day knowledge, one finds that the Aether is no longer ruled out by relativity, and good reasons can now be advanced for postulating an Aether ... We have now the velocity at all points of space-time, playing a fundamental part in electrodynamics. It is natural to regard it as the velocity of some real physical thing. Thus with the new theory of electrodynamics [vacuum filled with virtual particles] we are rather forced to have an Aether\".\n\nJohn Bell in 1986, interviewed by Paul Davies in \"The Ghost in the Atom\" has suggested that an Aether theory might help resolve the EPR paradox by allowing a reference frame in which signals go faster than light. He suggests Lorentz contraction is perfectly coherent, not inconsistent with relativity, and could produce an aether theory perfectly consistent with the Michelson-Morley experiment. Bell suggests the aether was wrongly rejected on purely philosophical grounds: \"what is unobservable does not exist\" [p. 49]. Einstein found the non-aether theory simpler and more elegant, but Bell suggests that doesn't rule it out. Besides the arguments based on his interpretation of quantum mechanics, Bell also suggests resurrecting the aether because it is a useful pedagogical device. That is, many problems are solved more easily by imagining the existence of an aether.\n\nEinstein remarked \"God does not play dice with the Universe\". And those agreeing with him are looking for a classical, deterministic aether theory that would imply quantum-mechanical predictions as a statistical approximation, a hidden variable theory. In particular, Gerard 't Hooft conjectured that: \"We should not forget that quantum mechanics does not really describe what kind of dynamical phenomena are actually going on, but rather gives us probabilistic results. To me, it seems extremely plausible that any reasonable theory for the dynamics at the Planck scale would lead to processes that are so complicated to describe, that one should expect apparently stochastic fluctuations in any approximation theory describing the effects of all of this at much larger scales. It seems quite reasonable first to try a classical, deterministic theory for the Planck domain. One might speculate then that what we call quantum mechanics today, may be nothing else than an ingenious technique to handle this dynamics statistically.\" In their paper Blasone, Jizba and Kleinert \"have attempted to substantiate the recent proposal of G. ’t Hooft in which quantum theory is viewed as not a complete field theory, but is in fact an emergent phenomenon arising from a deeper level of dynamics. The underlying dynamics are taken to be classical mechanics with singular Lagrangians supplied with an appropriate information loss condition. With plausible assumptions about the actual nature of the constraint dynamics, quantum theory is shown to emerge when the classical Dirac-Bergmann algorithm for constrained dynamics is applied to the classical path integral [...].\"\n\nLouis de Broglie, \"If a hidden sub-quantum medium is assumed, knowledge of its nature would seem desirable. It certainly is of quite complex character. It could not serve as a universal reference medium, as this would be contrary to relativity theory.\"\n\nIn 1982, Ioan-Iovitz Popescu, a Romanian physicist, wrote that the aether is \"a form of existence of the matter, but it differs qualitatively from the common (atomic and molecular) substance or radiation (photons)\". The \"fluid aether\" is \"governed by the principle of inertia and its presence produces a modification of the space-time geometry\". Built upon Le Sage's \"ultra-mundane corpuscles\", Popescu's theory posits a finite Universe \"filled with some particles of exceedingly small mass, traveling chaotically at speed of light\" and material bodies \"made up of such particles called \"etherons\"\".\n\nSid Deutsch, a professor of electrical engineering and bioengineerig, conjectures that a \"spherical, spinning\" \"aether particle\" must exist in order \"to carry electromagnetic waves\" and derives its diameter and mass using the density of dark matter.\n\nA degenerate Fermi fluid model, \"composed primarily of \"electrons and positrons\"\" that has the consequence of a speed of light decreasing \"with time on the scale of the age of the universe\" was proposed by Allen Rothwarf. In a cosmological extension the model was \"extended to predict a \"decelerating expansion of the universe\"\".\n\n\n"}
{"id": "33542161", "url": "https://en.wikipedia.org/wiki?curid=33542161", "title": "Aluminium dross recycling", "text": "Aluminium dross recycling\n\nAluminium dross, a byproduct of the aluminium smelting process, can be mechanically recycled to separate the residual aluminium metal from the aluminium oxide.\n\nThe mechanical process of recycling does not use any toxic chemicals previously used in the process of extracting the valuable aluminium in the dross.\n\nHot dross processing system whereby the majority of metal is recovered without chemically reducing the aluminium oxides. The dross is first crushed then separated into aluminium metal rich particles and aluminium oxide rich particles based on density. The metal rich particles are then melted in a furnace to remove the remaining oxide particles.\n\nRecycling aluminium dross mechanically is an environmentally sensitive method, and is not toxic. This is completely different from how aluminium metal used to be extracted from dross using an array of hazardous chemicals which resulted in a concentrated highly toxic 'salt cake' residue.\n\nAn operating aluminium dross recycling plant (news coverage) https://www.youtube.com/watch?v=t_z8jlDgdCU\n\nA variety of products can be made from the residual aluminium dross after it is recycled into aluminium oxide. See more information on aluminium oxide. Aluminium oxide has a variety of industrial uses which includes being used in paint, dye, concrete, explosives, and fertilizer.\n\nAluminium dross recycling is a completely different process to strictly aluminium recycling. Aluminium recycling is where pure aluminium metal products (previously used in another form) are re-melted into aluminium ingots and then re-used to new aluminium products. While aluminium dross recycling is where the dross, a byproduct of the smelting process in the creation of aluminium from bauxite, can be mechanically recycled thus separating the residual aluminium metal from the aluminium oxide.\n"}
{"id": "31251819", "url": "https://en.wikipedia.org/wiki?curid=31251819", "title": "Anaerobic Digestion and Biogas Association", "text": "Anaerobic Digestion and Biogas Association\n\nThe Anaerobic Digestion and Bioresources Association (ADBA), formerly the Anaerobic Digestion and Biogas Association, is a United Kingdom-based trade association for the anaerobic digestion and associated industries.\n\nADBA was founded in September 2009 by its then chairman Lord Redesdale and 10 founder member companies to represent businesses involved in the anaerobic digestion and biogas industries. Its objective is to help remove the barriers to anaerobic digestion that are faced and to support its members to grow their businesses. Its principal aim is to enable and facilitate the development of a mature anaerobic digestion industry in the UK within 10 years.\n\nRecognising there was no industry group that exclusively represented the emerging anaerobic digestion industry in the UK (previously the Renewable Energy Association and the Association for Organics Recycling had break out groups related to anaerobic digestion) ADBA was formed by a number of UK-based companies which specialise in anaerobic digestion technologies including Clarke Energy, Entec, Kirk Environmental and Monsal.\n\nDuring its relatively short time in existence, ADBA has made a number of significant contributions to the development of legislation including promoting higher levels of feed-in tariffs for digestion plants and a biomethane carbon credit trading platform. It now represents over 370 member companies.\n\nOn 1 October 2014, the ADBA announced that it was changing its name with immediate effect to the Anaerobic Digestion & Bioresources Association, \"in response to a rapidly changing political and economic landscape.\"\n\n"}
{"id": "42393640", "url": "https://en.wikipedia.org/wiki?curid=42393640", "title": "Bezimenne gas field", "text": "Bezimenne gas field\n\nThe Bezimenne gas field natural gas field located on the continental shelf of the Black Sea. It was discovered in 1997 and developed by Chornomornaftogaz. It started commercial production in 1997. The total proven reserves of the Bezimenne gas field are around , and production is slated to be around in 2015.\n"}
{"id": "6043426", "url": "https://en.wikipedia.org/wiki?curid=6043426", "title": "Biodegradable waste", "text": "Biodegradable waste\n\nBiodegradable waste includes any organic matter in waste which can be broken down into carbon dioxide, water, methane or simple organic molecules by micro-organisms and other living things by composting, aerobic digestion, anaerobic digestion or similar processes. In waste management, it also includes some inorganic materials which can be decomposed by bacteria. Such materials include gypsum and its products such as plasterboard and other simple organic sulfates which can decompose to yield hydrogen sulphide in anaerobic land-fill conditions. \n\nIn domestic waste collection, the scope of biodegradable waste may be narrowed to include only those degradable wastes capable of being handled in the local waste handling facilities.\n\nBiodegradable waste can be found in municipal solid waste (sometimes called biodegradable municipal waste, or BMW) as green waste, food waste, paper waste, and biodegradable plastics. Other biodegradable wastes include human waste, manure, sewage, sewage sludge and slaughterhouse waste. In the absence of oxygen, much of this waste will decay to methane by anaerobic digestion.\n\nIn many parts of the developed world, biodegradable waste is separated from the rest of the waste stream, either by separate kerb-side collection or by waste sorting after collection. At the point of collection such waste is often referred to as \"green waste\". Removing such waste from the rest of the waste stream substantially reduces waste volumes for disposal and also allows biodegradable waste to be composted.\n\nBiodegradable waste can be used for composting or a resource for heat, electricity and fuel by means of incineration or anaerobic digestion. Swiss \"Kompogas\" and the Danish \"AIKAN\" process are examples of anaerobic digestion of biodegradable waste. While incineration can recover the most energy, anaerobic digestion plants retain nutrients and make compost for soil amendment and still recover some of the contained energy in the form of biogas. Kompogas produced 27 million Kwh of electricity and biogas in 2009. The oldest of the company's lorries has achieved 1,000,000 kilometers driven with biogas from household waste in the last 15 years.\n\nFeatured in an edition of \"The Economist\" that predicted events in 2014, it was revealed that Massachusetts creates roughly 1.4 million tons of organic waste every year. Massachusetts, along with Connecticut and Vermont, are also going to enact laws to divert food waste from landfills.\n\nIn small and densely populated states, landfill capacity is limited so disposal costs are higher ($60–90 per ton in MA compared to national average of $49). Decomposing food waste generates methane, a notorious greenhouse gas. However, this biogas can be captured and turned into energy through anaerobic digestion, and then sold into the electricity grid.\n\nAnaerobic digestion grew in Europe, but is starting to develop in America. Massachusetts is increasing its production of anaerobic digesters.\n\nThe main environmental threat from biodegradable waste is the production of methane and other greenhouse gases.\n"}
{"id": "26284297", "url": "https://en.wikipedia.org/wiki?curid=26284297", "title": "Bloom Energy Server", "text": "Bloom Energy Server\n\nThe Bloom Energy Server (the Bloom Box) is a solid oxide fuel cell (SOFC) power generator made by Bloom Energy, of Sunnyvale, California, that takes a variety of input fuels, including liquid or gaseous hydrocarbons produced from biological sources, to produce electricity at or near the site where it will be used. It can withstand temperatures of up to . According to the company, a single cell (one 100 mm × 100 mm plate consisting of three ceramic layers) generates 25 watts.\n\nThe fuel cells have an operational life expectancy of around 10 years; based on predictions on fuel costs, the \"break even\" point for those who purchase the device is around 8 years. Several other companies competing in the same energy market have demonstrated that their devices function with greater operational efficiency than the Bloom Server, and \"Forbes\" magazine has suggested that most of the Bloom Server's reputation is based on hype rather than actual efficient operation or savings in energy costs. The cell's technology continues to rely on non-renewable sources of energy to produce electricity, and because it is not a hydrogen fuel cell, it still produces carbon dioxide (an important greenhouse gas) during operation.\n\nBloom stated in 2011 that two hundred servers had been deployed in California for corporations including eBay, Google, Yahoo, and Wal-Mart.\n\nThe Bloom Energy Server uses thin white ceramic plates of size 100 × 100 mm. \nEach plate is coated with a green nickel oxide-based ink on one side, forming the anode, and another black (probably Lanthanum strontium manganite) ink on the cathode side.\n\"Wired\" reported that the secret ingredient may be yttria-stabilized zirconia based upon that was granted to Bloom in 2009; this material is also one of the most common electrolyte materials in the field. , assigned to Bloom Energy Corporation, says that the \"electrolyte includes yttria stabilized zirconia and a scandia-stabilized zirconia, such as a scandia ceria stabilized zirconia\". \nScSZ has a higher conductivity than YSZ at lower temperatures, which provides greater efficiency and higher reliability when used as an electrolyte. Scandia is scandium oxide () which is a transition metal oxide that costs between US$1,400 and US$2,000 per kilogram in 99.9% pure form. Current annual worldwide production of scandium is less than 2,000 kilograms. Most of the 5,000 kilograms used annually is sourced from Soviet era stockpiles.\n\nTo save money, the Bloom Energy Server uses inexpensive metal alloy plates for electric conductance between the two ceramic fast ion conductor plates. In competing lower temperature fuel cells, platinum is required at the cathode.\n\nThe current cost of each hand-made 100 kW Bloom Energy Server is $700,000–800,000. In 2010, the company announced plans for a smaller, home sized Bloom server priced under $3,000. Bloom estimated the size of a home-sized server at 1 kW, although others recommended 5 kW.\n\nThe capital cost is $7–8 per watt.\n\nAccording to the New York Times (Green Blog), in early 2011 \"... Bloom Energy ... unveiled a service to allow customers to buy the electricity generated by its fuel cells without incurring the capital costs of purchasing the six-figure devices... Under the Bloom Electrons service, customers sign 10-year contracts to purchase the electricity generated by Bloom Energy Servers while the company retains ownership of the fuel cells and responsibility for their maintenance... 'We’re able to tell customers, ‘You don’t have to put any money up front, you pay only for the electrons you use and it’s good for your pocketbook and good for planet,’ ' [CEO K.R. Sridhar] said.\"\n\nOn 24 February 2010, Sridhar claimed that his devices were making electricity for $0.08–.10/kWh using natural gas, cheaper than today's electricity prices in some parts of the United States, such as California. Twenty percent of the cost savings depend upon avoiding transfer losses that result from energy grid use.\n\nBloom Energy claimed to be developing power purchase agreements to sell electricity produced by the boxes, rather than selling the boxes themselves, in order to address customers' fears about box maintenance, reliability, and servicing costs.\n\nAs of 2010, 15% of the power consumed by eBay was generated via the use of Bloom Energy Servers. At the time, after factoring in tax incentives which effectively halved the initial cost, eBay expected a three-year payback period based on the then $0.14/kWh cost of commercial electricity in California.\n\nThe company says that its first 100-kW Bloom Energy Servers were shipped to Google in July 2008. Four such servers were installed at Google's headquarters, which became Bloom Energy's first customer. Another installation of five boxes produces up to 500 kW at eBay headquarters California. Bloom Energy stated that their customers include Staples (300 kW – December 2008), Walmart (800 kW – January 2010), FedEx (500 kW), The Coca-Cola Company (500 kW) and Bank of America (500 kW). Each of these installations were located in California.\n\nA 1-megawatt Bloom Box fuel cell system installed at Yahoo headquarters in Sunnyvale, California in 2014 is designed to \"power one-third of the electricity to the buildings on Yahoo’s campus.\"\n\nSridhar announced plans to install Bloom Energy Servers in third world nations. Ex-Chairman of the Joint Chiefs of Staff, Colin Powell, now a Bloom\nEnergy board member, said the Bloom Energy generators could be useful to the military because they are lighter, more efficient, and generate less heat than traditional generators.\n\nBloom Energy Servers stack small fuel cells to operate in concert. Bloom Energy's approach of assembling fuel-cell stacks that enables individual plates to expand and contract at the same rate at high temperatures. However, other solid oxide fuel cell producers have solved the problem of different expansion rates of cells in the past. Scott Samuelsen of the University of California, Irvine National Fuel Cell Research Center questioned the operational life of Bloom Servers. \"At this point, Bloom has excellent potential, but they have yet to demonstrate that they've met the bars of reliability.\" Lawrence Berkeley National Laboratory expert Michael Tucker claimed, \"Because they operate at high temperatures, they can accept other fuels like natural gas and methane, and that's an enormous advantage... The disadvantage is that they can shatter as they are heating or cooling.\"\n\nVenture capitalist John Doerr asserted that the Bloom Energy Server is cheaper and cleaner than the grid. An expert at Gerson Lehrman Group wrote that, given today's electricity transmission losses of about 7% and utility-size gas-fired power stations efficiency of 33–48%, the Bloom Energy Server is up to twice as efficient as a gas-fired power station. \"Fortune\" stated that \"Bloom has still not released numbers about how much the Bloom Box costs to operate per kilowatt hour\" and estimates that natural gas rather than bio-gas will be its primary fuel source. AP reporter Jonathan Fahey in \"Forbes\" wrote: \"Are we really falling for this again? Every clean tech company on the planet says it can produce clean energy cheaply, yet not a single one can. Government subsidies or mandates keep the entire worldwide industry afloat. Hand it to Bloom, the company has managed to tap into the hype machine like no other clean tech company in memory.\" \n\nBloom claims a conversion efficiency of around 50%. A modern combined cycle gas turbine power plant (CCGT) can reach 60% overall efficiency, while cogeneration can achieve greater than 95% efficiency. Sridhar stated that Bloom's products convert chemical energy to electrical energy in one step, are more fuel efficient than current gas-fired power stations and reduce transmission/distribution losses by producing power where it is used.\n\nEach Bloom Energy Server ES5700 is said to provide 200 kW of power, similar to the baseload needs of 160 average homes or one office building. The average monthly electricity consumption for a U.S. residential utility customer in 2012 was 903 kWh per month (or 1.24 kW mean load).\n\nSridhar said the boxes have a 10-year life span, although that could include replacing the cells during that period. The CEO of eBay says Bloom Energy Servers have saved the company $100,000 in electricity bills since they were installed in mid-2009, Fortune Magazine contributor Paul Keegan calls that figure \"meaningless without the details to see how he got there\".\n\nThe largest disadvantage is the high operating temperature which results in longer start-up times and mechanical and chemical compatibility issues.\n\nAssuming a 50% future cost reduction, one could argue that the best case scenario for the 200 kW unit would be a capital (installed) cost comparable to today's 100 kW units, i.e., around $800,000. Using average electricity ($0.10/kWh) and natural gas ($3/MMBtu) prices and assuming a 6% per year maintenance/operating cost apart from fuel, the break-even period for the device comes to over 8 years, based on published performance numbers.\n\nLong term cost consideration varies because backup generators are no longer necessary since the power grid acts as the emergency backup. No longer having to maintain and replace generators would reduce the break even period.\n\nA Gerson Lehrman Group analyst wrote that GE dismantled its fuel cell group five years ago and Siemens almost dismantled theirs. GE Power Conversion is researching a SOFC power hybrid. United Technologies is the only large conglomerate that has competitive fuel cell technology. Toshiba has technology to provide energy for a small device, not a neighborhood.\n\nSprint owns 15 patents on hydrogen fuel cells and is using 250 fuel cells to provide backup power for its operations. Sprint has been using fuel cell power since 2005. In 2009, Sprint's fuel cell program received a grant of $7.3 million from the United States Department of Energy to expand the hydrogen capacity of its fuel cell tanks from providing up to 15 hours of backup power, to 72 hours. Sprint partnered with ReliOn and Altergy for fuel cell manufacture, and with Air Products as a hydrogen supplier. German fuel cell firm P21 has been working on similar projects to supply backup power for cellular operations. United Technologies makes fuel cells costing $4,500 per kilowatt.\n\nIn October 2009, the Department of Energy awarded nearly USD $25 million in grants for research and development of solar fuels.\n\nIn October 2012, the US government awarded Bloom Energy $70,710,959 under its section 1603 energy awards program.\n\nA competitor claimed the Bloom Box uses a \"thick electrolyte\" that requires 900 °C temperatures to overcome electrical resistance. Topsoe Fuel Cell and Ceres Power instead employ \"thick anode\" technology that allows operation at cooler temperature. Ceres has a four-year program to install 37,500 units in the homes of customers of the UK's British Gas.\n\nBallard Power's comparably scaled products are based on proton exchange membrane fuel cells. Ballard's 150 kW units are intended for mobile applications such as municipal buses, while their larger 1 MW stationary systems are configured from banks of 11 kW building blocks.\n\nAnother competitor in Europe and Australia is Ceramic Fuel Cells. It claims an efficiency of 60% for the power-only units; these fuel cells are based on technology spun off from Australia's CSIRO.\n\n\n"}
{"id": "3143285", "url": "https://en.wikipedia.org/wiki?curid=3143285", "title": "Chemosterilant", "text": "Chemosterilant\n\nA chemosterilant is a chemical compound that causes reproductive sterility in an organism. They may be used to control pest populations by sterilizing males. More technically, a chemosterilant is any chemical compound used to control economically destructive or disease-causing pests (usually insects) by causing temporary or permanent sterility of one or both of the sexes or preventing maturation of the young to a sexually functional adult stage. \n\nThe mating of sterilized insects with fertile insects produces no offspring, and if the number of sterile insects is kept constant, the percentage of sterile insects will increase, and fewer young will be produced in each successive generation. Chemosterilants should be applied in the larval or pupal stage of the insect to give rise to sterile adults or in the newly emerged adults before they become sexually mature.\n\nTwo types of chemosterilants are commonly used:\n"}
{"id": "3501824", "url": "https://en.wikipedia.org/wiki?curid=3501824", "title": "Circle of Life Foundation", "text": "Circle of Life Foundation\n\nCircle of Life was founded by Julia Butterfly Hill. The US-based organization counts a number of celebrities and west-coast business leaders as supporters, advisors, and backers. Julia Butterfly Hill founded it.\n"}
{"id": "22486896", "url": "https://en.wikipedia.org/wiki?curid=22486896", "title": "Compact linear Fresnel reflector", "text": "Compact linear Fresnel reflector\n\nA compact linear Fresnel reflector (CLFR) – also referred to as a concentrating linear Fresnel reflector – is a specific type of linear Fresnel reflector (LFR) technology. Linear Fresnel reflectors use long, thin segments of mirrors to focus sunlight onto a fixed absorber located at a common focal point of the reflectors. These mirrors are capable of concentrating the sun's energy to approximately 30 times its normal intensity. This concentrated energy is transferred through the absorber into some thermal fluid (this is typically oil capable of maintaining liquid state at very high temperatures). The fluid then goes through a heat exchanger to power a steam generator. As opposed to traditional LFR's, the CLFR utilizes multiple absorbers within the vicinity of the mirrors.\n\nThe first linear Fresnel reflector solar power system was developed in Italy in 1961 by Giovanni Francia of the University of Genoa. Francia demonstrated that such a system could create elevated temperatures capable of making a fluid do work. The technology was further investigated by companies such as the FMC Corporation during the 1973 oil crisis, but remained relatively untouched until the early 1990s. In 1993, the first CLFR was developed at the University of Sydney in 1993 and patented in 1995. In 1999, the CLFR design was enhanced by the introduction of the advanced absorber. In 2003 the concept was extended to 3D geometry. Research published in 2010 showed that higher concentrations and / or higher acceptance angles could be obtained by using nonimaging optics to explore different degrees of freedom in the system such as varying the size and curvature of the heliostats, placing them at a varying height (on a wave-shape curve) and combining the resulting primary with nonimaging secondaries.\n\nThe reflectors are located at the base of the system and converge the sun's rays into the absorber. A key component that makes all LFR's more advantageous than traditional parabolic trough mirror systems is the use of \"Fresnel reflectors\". These reflectors make use of the Fresnel lens effect, which allows for a concentrating mirror with a large aperture and short focal length while simultaneously reducing the volume of material required for the reflector. This greatly reduces the system's cost since sagged-glass parabolic reflectors are typically very expensive. However, in recent years thin-film nanotechnology has significantly reduced the cost of parabolic mirrors.\n\nA major challenge that must be addressed in any solar concentrating technology is the changing angle of the incident rays (the rays of sunlight striking the mirrors) as the sun progresses throughout the day. The reflectors of a CLFR are typically aligned in a north-south orientation and turn about a single axis using a computer controlled solar tracker system. This allows the system to maintain the proper angle of incidence between the sun's rays and the mirrors, thereby optimizing energy transfer.\n\nThe absorber is located at the focal line of the mirrors. It runs parallel to and above the reflector segments to transport radiation into some working thermal fluid. The basic design of the absorber for the CLFR system is an inverted air cavity with a glass cover enclosing insulated steam tubes, shown in Fig.2. This design has been demonstrated to be simple and cost effective with good optical and thermal performance.\n\nFor optimum performance of the CLFR, several design factors of the absorber must be optimized.\n\nAs opposed to the traditional LFR, the CLFR makes use of multiple absorbers within the vicinity of its mirrors. These additional absorbers allow the mirrors to alternate their inclination, as illustrated in Fig. 3. This arrangement is advantageous for several reasons.\n\nAreva Solar (Ausra) built a linear Fresnel reflector plant in New South Wales, Australia. Initially a 1 MW test in 2005, it was expanded to 5MW in 2006. This reflector plant supplemented the 2,000 MW coal-fired Liddell Power Station. The power generated by the solar thermal steam system is used to provide electricity for the plant's operation, offsetting the plant's internal power usage. AREVA Solar built the 5 MW Kimberlina Solar Thermal Energy Plant in Bakersfield, California in 2009. This is the first commercial linear Fresnel reflector plant in the United States. The solar collectors were produced at the Ausra factory in Las Vegas. In April 2008, AREVA opened a large factory in Las Vegas, Nevada to produce linear Fresnel reflectors. The factory was planned to be capable of producing enough solar collectors to provide 200 MW of power per month.\n\nIn March 2009, the German company Novatec Biosol constructed a Fresnel solar power plant known as PE 1. The solar thermal power plant uses a standard linear Fresnel optical design (not CLFR) and has an electrical capacity of 1.4 MW. PE 1 comprises a solar boiler with mirror surface of approximately . The steam is generated by concentrating sunlight directly onto a linear receiver, which is above the ground. An absorber tube is positioned in the focal line of the mirror field where water is heated into saturated steam. This steam in turn powers a generator. The commercial success of the PE 1 led Novatec Solar to design a 30 MW solar power plant known as PE 2. PE 2 has been in commercial operation since 2012.\n\nFrom 2013 on Novatec Solar developed a molten salt system in cooperation with BASF. It uses molten salts as heat transfer fluid in the collector which is directly transferred to a thermal energy storage. A salt temperature of up to facilitate to run a conventional steam turbine for Electricity generation, Enhanced oil recovery or Desalination. A molten salt demonstration plant was realized on PE 1 to proof the technology. Since 2015 FRENELL GmbH, a management buy-out of Novatec Solar took over the commercial development of the direct molten salt technology.\n\nSolar Fire, an appropriate technology NGO in India, has developed an open source design for a small, manually operated, 12 kW peak Fresnel concentrator that generates temperatures up to and can be used for various thermal applications including steam powered electricity generation.\n\nThe largest CSP systems using Compact linear Fresnel reflector technology is the 125 MW Reliance Areva CSP plant in India.\n\n"}
{"id": "4945092", "url": "https://en.wikipedia.org/wiki?curid=4945092", "title": "Digital magnetofluidics", "text": "Digital magnetofluidics\n\nDigital magnetofluidics is a method for moving, combining, splitting, and controlling drops of water or biological fluids using magnetic fields. This is accomplished by adding superparamagnetic particles to a drop placed on a superhydrophobic surface. Normally this type of surface would exhibit a lotus effect and the drop of water would roll or slide off. But by using magnetic fields, the drop is stabilized and its movements and structure can be controlled.\n\nDrop movement is possible due to the influence of an applied magnetic field. The paramagnetic particles inside the water drops become magnetized. The consequent magnetic dipole interactions among the particles cause them to form chain-like clusters, which follow the magnetic field lines and aggregate further to form long filaments. When the magnet is displaced, the clusters move and drive the motion of the drop.\n\nMultiple drops can be moved simultaneously using different local magnetic fields. By moving the fields together, drops can be combined. This is useful as a method of adding a biological or chemical detection agent to the drop.\n\nDrops may also be split through the action of separate magnetic fields. First, two separate fields are brought together. Then as the fields are moved apart, separate particle clusters are formed and push against the surface tension of the drop eventually ripping the drop into two separate drops.\n\nThe first demonstration of this method was done under the direction of Dr. Antonio Garcia (Arizona State University) and Dr Sonia Melle (Universidad Complutense de Madrid, Spain), by doctoral student Ana Egatz-Gomez (Arizona State University), who worked at the laboratory generously provided by Dr Miguel Angel Rubio (Universidad Nacional de Educacion a Distancia, Madrid, Spain). Research to better understand the physics of digital magnetofluidics and to develop biomedical applications is currently being performed in collaboration with researchers at Arizona State University and Los Alamos National Laboratory.\n\nIt is believed that this method can lead to the development of so-called \"Open Drop Assays\" where individual drops of blood and other biological fluids can be rapidly analyzed to diagnose and treat diseases.\n\n[1] A. Egatz-Gomez, S. Melle, A.A. García, S. Lindsay, M.A. Rubio, P. Domínguez, T. Picraux, J. Taraci, T. Clement, and M. Hayes, “Superhydrophobic Nanowire Surfaces for Drop Movement Using Magnetic Fields,” in Proc. NSTI Nanotechnology Conference and Trade Show, 2006, pp. 501–504.\n\n[2] A. Egatz-Gómez, S. Melle, A.A. García, S.A. Lindsay, M. Márquez, P. Domínguez-García, M.A. Rubio, S.T. Picraux, J.L. Taraci, and T. Clement, “Discrete magnetic microfluidics,” Applied Physics Letters, vol. 89, pp. 034106, 2006.\n\n[3] A. Egatz-Gómez, J. Schneider, P. Aella, D. Yang, P. Domínguez-García, S. Lindsay, S.T. Picraux, M.A. Rubio, S. Melle, and M. Marquez, “Silicon nanowire and polyethylene superhydrophobic surfaces for discrete magnetic microfluidics,” Applied Surface Science, vol. 254, (no. 1), pp. 330–334, 2007.\n\n[4] A.A. García, A. Egatz-Gómez, S.A. Lindsay, P. Domínguez-García, S. Melle, M. Marquez, M.A. Rubio, S.T. Picraux, D. Yang, and P. Aella, “Magnetic movement of biological fluid droplets,” Journal of Magnetism and Magnetic Materials, vol. 311, (no. 1), pp. 238–243, 2007.\n\n[5] S. Lindsay, T. Vázquez, A. Egatz-Gómez, S. Loyprasert, A.A. Garcia, and J. Wang, “Discrete microfluidics with electrochemical detection,” The Analyst, vol. 132, (no. 5), pp. 412–416, 2007.\n\n[6] J. Schneider, A. Egatz-Gómez, S. Melle, S. Lindsay, P. Domínguez-García, M.A. Rubio, M. Márquez, and A.A. García, “Motion of viscous drops on superhydrophobic surfaces due to magnetic gradients,” Colloids and Surfaces A: Physicochemical and Engineering Aspects, 2007.\n\n[7] S. Melle Hernandez, A. Gomez, T. Picraux S, J. Gust, M. Hayes, S. Lindsay, A. Garcia, J. Wang, and T. Vazquez-Alvarez, “DIGITAL MAGNETOFLUIDIC DEVICES AND METHODS,” US Patent WO/2007/101174\n"}
{"id": "46692187", "url": "https://en.wikipedia.org/wiki?curid=46692187", "title": "Ductwork airtightness", "text": "Ductwork airtightness\n\nDuctwork airtightness can be defined as the resistance to inward or outward air leakage through the ductwork envelope (or ductwork shell). This air leakage is driven by differential pressures across the ductwork envelope due to the combined effects of stack and fan operation (in case of a mechanical ventilation system).\n\nFor a given HVAC system, the term ductwork refers to the set of ducts and fittings (tees, reducers, bends, etc.) that are used to supply the air to or extract the air from the conditioned spaces. It does not include components such as air handlers, heat recovery units, air terminal devices, coils. Attenuators, dampers, access panels, etc. are a part of the ductwork but have more functions than conveying the air and are therefore also referred to as technical ductwork products.\n\nDuctwork airtightness is the fundamental ductwork property that impacts the uncontrolled leakage of air through duct leaks.\n\nTypical reasons for poor ductwork airtightness include:\n\nAn airtight ductwork has several positive impacts:\n\nSweden is often considered as a reference for airtight ducts: the requirements introduced in AMA (General material and workmanship specifications) starting in 1950 have led to excellent ductwork airtightness on a regular basis in Sweden.\n\nIn the US, there has been a significant amount of work showing energy saving potentials on the order of 20-30% in homes; and 10-40% in commercial buildings with airtight ducts \n\nThe ASIEPI project technical report on building and ductwork airtightness estimated the heating energy impact of duct leakage in a ventilation system on the order of 0-5 kWh per m of floor area per year plus additional fan energy use for a moderately cold European region (2500 degree-days).\n\nDuct leakage affects more severely the energy efficiency of systems that include air heating or cooling.\n\nThere are two major systems to classify ductwork airtightness, one based on European standards, the other based on ASHRAE standard 90.1-2010. Both are based on the leakage airflow rate at a given duct pressure divided by the product of the duct surface area and the same duct pressure raised to the power 0.65. \n\nThe relationship between pressure and leakage air flow rate is defined by the power law model between the airflow rate and the pressure difference across the ductwork envelope as follows:\n\nq=C∆p\n\nwhere:\n\nThis law enables to assess the airflow rate at any pressure difference regardless the initial measurement.\nThreshold limits in ductwork airtightness classifications usually assume an airflow exponent of 0,65.\n\nDuctwork airtightness levels can be measured by temporarily connecting a device (sometimes called a duct leakage tester to pressurize the ductwork including duct-mounted components. Air flow through the pressurizing device creates an internal, uniform, static pressure within the ductwork. The aim of this type of measurement is to relate the pressure differential across the ductwork to the air flow rate required to produce it. Generally, the higher the air flow rate required to produce a given pressure difference, the less airtight the ductwork. This pressurization technique is described in standard test methods such as EN 12237 and EN 1507, ASHRAE standard 90.1-2010. It is similar in principle to that used to characterize building airtightness.\n\nAt construction stage, the airtightness of individual components depends on the design (rectangular or round ducts, pressed or segmented bends, etc.) and assembly (seam type and welding quality). \nComponents with factory-fitted sealing devices (e.g., gaskets, clips) meant to ease and accelerate the installation process are widely used in Scandinavian countries. \nA variety of techniques are widely used to tighten duct systems on site, including gaskets, tapes, sealing compound (mastic), internal duct lining, aerosol duct sealing. So-called \"duct tapes\" are often not suited for sealing ducts, which explains why, in the US, the International Energy Conservation Code (IECC) requires any tape used on duct board or flexible ducts to be labeled in accordance with UL 181A or 181B.\n\n"}
{"id": "34537642", "url": "https://en.wikipedia.org/wiki?curid=34537642", "title": "Electric go-kart", "text": "Electric go-kart\n\nAn electric go-kart is a go-kart powered by one or two electric motors and batteries.\nMany manufacturers offer electric go-karts.\n\nAcceleration is usually better than thermic model and the speed is sufficient for use on most kart circuits. Torque in electric motors are greater than that of the gas engine. They are ideal for quick take offs and off road climbing.\n\nElectric go-karts are low maintenance, requiring only that the lead-acid batteries of the cars be plugged into an array of chargers after each run. Since they are pollution-free and emit no smoke, the racetracks can be indoors in controlled environments. Most fully charged electric karts can run a maximum of 20 minutes before performance is affected. An expensive alternative is the use of Lithium iron phosphate LiPO4 lithium batteries. They last much longer and carry more power per pound than lead acid batteries.\n\nElectric power Go-Karts do not have hot engines or a tank full of gas which can prove to be safer in an accident.\n\nBatteries are still very expensive and the autonomy is not that good. However, charging can be achieved in about 30 minutes and it is possible to swap batteries.\n\nThe ERDF Masters Kart racing event took place at the Paris-Bercy Arena in Paris, France in December 2011. Drivers from different auto racing series such as Formula 1, GP2 Series, WRC, DTM, IndyCar or kart racing got to compete with electric karts powered by a 40 hp brushless type electric motor.\n\nThere are a few other events for electric karts such as e-Kart, a university challenge, also in France.\n\nIn the US, the Red Line Oil Karting Championship of Northern California started hosting in 2013 a field of Ekarts (Category V, Group 2, Class 1) competing for the Rattlesnake Electric Sport Championship. Most weekends, lap times were within less than a second of the fastest laps, with reliabity much better than their gas cousins.\n\nIn Canada, the G-Zero Championship Racing Series is set to start racing on temporary city street circuits in 2016. The G-Zero series uses all-electric zero-emissions karts built by EVC Racing of Indianapolis IN featuring a blend of parts used in motorcycle racing and new innovative battery technology.\n\nSince 2006, an annual electric karting challenge is organized by associations and e-Kart. This Challenge brings together manufacturers, schools, academic institutions (electrical engineering). This competition is played with machines expanding from 10 to 67 kilowatts, it takes place over three days and includes many tests (endurance 4 hours, best lap times, acceleration from stop over a distance of 50 meters, 10-minute races ...).\n\nIn 2013 the challenge has become international. It gathered 26 teams with 34 karts and 200 participants.\n\nIn 2015, Latvian company Blue Shock Race launched new technology type electric karts. BSR2017 Blue Shock Race kart is first kart in world, which have changeable battery with small, extremely effective lithium battery pack, with one charge can drive 10-15 min. BSR2017 kart is most competitive kart in rental kart sector right now. \n\nWorld’s First National Electric Kart Championship \nIn 2018 Latvia has become the first country in the World to officially hold the National Karting Championship for electric karts in classes TeK and TeK Open. The Championship kicked-off on May 1 on the historical Kandava go-kart track and during the season 6 rounds have been completed on different tracks in total. The Latvian Electric Kart Championship finals ended on the Jelgava track “Rulītis”, where the winners of the Championship in the overall ranking were determined. \n\nThe first champion to take the gold medal was Ričards Irbe, who won 5 times in a row. The second place in the overall ranking belongs to Raivis Veiksans, who took the silver, while the third place and the bronze medal belongs to Raistis Plukss. 16 different racers from Latvia and Lithuania participated in the competition altogether. \nIn the Championship all the racers started off on electric kart powertrains made by Blue Shock Race, with a power output of 15 kW in Tek class and up to 25 kW power output in TeK Open class. During the Championship the best lap time was shown by Raivis Veiksans: 49.836 seconds. \n\nThe Championship was launched in partnership with the LMT Autosport Academy, which has been engaging in involving young people in motorsports for several years now. Thanks to the experience of the Academy and involvement of “-teen” technical schools in the Latvian Electric Kart Championship, it has become possible to gather 10 teams, which have worked hard on improving their equipment and have started off in the Championship. \nBlue Shock Race is a company that has been working with electric karts for 4 years already, developing this technology both in Latvia and throughout the World. Thanks to the Blue Shock Race experience, budget-friendly, technologically simple, and racing-friendly solutions have been created, allowing the racers to start off in the electric kart classes. \n\nSince another World’s Electric Kart Championship was launched in Germany on May 13, now both of these countries, Latvia and Germany, can be considered as pioneers when it comes to holding National Electric Kart Championships, and in fact, both countries deserve to bear the title of the First Championship.\nCurrently Blue Shock Race is working on the development of new racing karts with a maximum output up to 55 kW with an ultimate racing capacity that can accelerate to 100km/h in about 2,2 seconds, making this class an upper professional class. \n\nIn 2018 FIA and IOC have introduced Electric Karting as the first motorsport in the Youth Olympics and taking it to the 2024 Olympics in Paris, that’s when the Blue Shock Race has set aim to go for the first Olympic Gold medals in the Electric Karting division. \nAfter Latvian national electric kart championship stage 4 in Kandava Latvian company Blue Shock Race launched new electric sports kart for professionals. This kart are capable to compete with DD2 division karts. In Latvia have TeK Open class where is allowed to race with 25kW karts and in 2019 will be more electric kart divisions. \n\n\n"}
{"id": "12985985", "url": "https://en.wikipedia.org/wiki?curid=12985985", "title": "Forest product", "text": "Forest product\n\nA forest product is any material derived from forestry for direct consumption or commercial use, such as lumber, paper, or forage for livestock. Wood, by far the dominant product of forests, is used for many purposes, such as wood fuel (e.g. in form of firewood or charcoal) or the finished structural materials used for the construction of buildings, or as a raw material, in the form of wood pulp, that is used in the production of paper. All other non-wood products derived from forest resources, comprising a broad variety of other forest products, are collectively described as non-timber forest products.\n\nMany forest management policies have been implemented that impact forest product economics, including forest access restrictions, harvesting fees, and harvest limits. Deforestation, global warming and other environmental concerns have increasingly affected the availability and sustainability of forest products, as well as the economies of regions dependent upon forestry around the world. In recent years, the idea of sustainable forestry, which aims to preserve crop yields without causing irreversible damage to ecosystem health, has changed the relationship between environmentalists and the forest products industry. Stakeholders in the forest products industry include government departments, commercial enterprises, non-governmental organizations (NGOs), policy-makers and analysts, private and international organizations.\n\nThe Food and Agriculture Organization of the United Nations publishes an annual yearbook of forest products. The FAO Yearbook of Forest Products is a compilation of statistical data on basic forest products for all countries and territories of the world. It contains series of annual data on the volume of production and the volume and value of trade in forest products. It includes tables showing direction of trade and average unit values of trade for certain products. Statistical information in the yearbook is based primarily on data provided to the FAO Forestry Department by the countries through questionnaires or official publications. In the absence of official data, FAO makes an estimate based on the best information available.\n\nFAO also publishes an annual survey of pulp and paper production capacities around the world. The survey presents statistics on pulp and paper capacity and production by country and by grade. The statistics are based on information submitted by correspondents worldwide, most of them pulp and paper associations, and represents 85% of the world production of paper and paperboard.\n\n"}
{"id": "9875903", "url": "https://en.wikipedia.org/wiki?curid=9875903", "title": "Gammator", "text": "Gammator\n\nӀA Gammator was a gamma irradiator made by the Radiation Machinery Corporation during the U.S. Atoms for Peace project of the 1950s and 1960s. The gammator was distributed by the \"Atomic Energy Commission to schools, hospitals, and private firms to promote nuclear understanding.\" Around 120-140 Gammators were distributed throughout the U.S. and the whereabouts of several of them are unknown, although the Department of Energy has removed and destroyed many of the units.\nA Gammator weighed about 1,850 pounds and contained about 400 curies of caesium-137 in a pellet roughly the size of a pen. \n\nBecause of the massive shielding of a Gammator, the machine is very safe when used as intended (e.g. school science experiments); according to the Los Alamos National Laboratory, it is similar to machines used to irradiate blood. However, this amount of nuclear material could pose a significant problem if used as the radioactive component in a dirty bomb.\n"}
{"id": "49351894", "url": "https://en.wikipedia.org/wiki?curid=49351894", "title": "Grimsel Tunnel", "text": "Grimsel Tunnel\n\nThe Grimsel Tunnel () is a proposed tunnel for power transmission and rail transport in Switzerland. it was planned to run under the Grimsel Pass and link the Zentralbahn at the north end with the Matterhorn Gotthard Bahn at the south, with planned opening in approximately 2025. The Canton of Bern, Canton of Valais, and Swissgrid unveiled their joint plans on 4 February 2016.\n\nThe tunnel is proposed to carry a single-track metre gauge railway and railway electrification system. The total length of the new Grimsel Line () route containing the tunnel would be . It would link two groups of existing railway lines constructed to one-metre track gauge in Switzerland, forming a contiguous route of .\nThe power transmission cables would run at 380kV and replace Swissgrid's existing overhead power line, and allow the removal of the 121 electricity pylons that had been in place for sixty years.\n\nThe intended railway route would continue from the Brünig railway line at Meiringen railway station, via the Meiringen–Innertkirchen railway, to a stop at Innertkirchen, then via new stations at Guttannen and Handegg (\"\") to Oberwald railway station for continuation via the Furka Base Tunnel. Travel time between Meiringen and Oberwald would be approximately 38 minutes—a reduction of three hours.\n\nA company called was founded by the promoters, with Peter Teuscher as its chair person.\n\nIn 2016 the estimated cost was 580-million Swiss Francs. The split cost of 290-million Swiss Francs each for railway and power transmission usage would less than the individual estimated costs of 490-million Swiss Francs for a power-only tunnel or 430-million Swiss Francs for a rail-only tunnel.\nThe tunnel route had first been proposed in 1860.\n\n"}
{"id": "33673594", "url": "https://en.wikipedia.org/wiki?curid=33673594", "title": "Heat cost allocator", "text": "Heat cost allocator\n\nHeat cost allocators are devices attached to individual radiators in buildings that measure the total heat output of the individual radiator. Heat cost allocators can be either electronic, where one or two electronic thermosensors and a microcontroller are used to calculate the heat consumption of radiator by the temperature difference between the radiator and the air in room, or evaporative, where a special, calibrated liquid in a capillary tube records the total heat absorbed from the air (for which an average allowance is made) in addition to that output by the radiator.\n"}
{"id": "28336543", "url": "https://en.wikipedia.org/wiki?curid=28336543", "title": "High Level Advisory Group on Climate Financing", "text": "High Level Advisory Group on Climate Financing\n\nUnited Nations Secretary-General Ban Ki-Moon established a High-Level Advisory Group on Climate Change Financing (AGF) on 12 February 2010 for the duration of ten months. The group's aim was to \"study potential sources of revenue that will enable achievement of the level of climate change financing that was promised during the United Nations Climate Change Conference in Copenhagen in December 2009.\"\n\nThe group was co-chaired by Jens Stoltenberg, Prime Minister of Norway, Meles Zenawi, Prime Minister of the Federal Democratic Republic of Ethiopia. Guyana President Bharrat Jagdeo was the third head of state on the board, but was not a co-chair. Members included experts from developed countries, developing countries, and from international development organizations and the academic world. British Prime Minister Gordon Brown co-chaired with Zenawi from the group's formation in February 2010 to 6 June 2010, when he was replaced by Stoltenberg.\n\nThe group's mandate was to develop practical proposals on how to significantly scale-up long-term financing for mitigation and adaptation strategies in developing countries from various public as well as private sources.\n\nThe High-Level Advisory Group released its final report on 5 November 2010, just ahead of the 2010 United Nations Climate Change Conference in Cancun, Mexico. The report concluded that it is \"challenging but feasible\" to reach the goal of mobilizing US$100 billion annually for climate actions in developing countries by 2020.\nThe AGF Report examined various approaches, including existing and new public funding and increased private flows. Its definition of “public” finance includes “direct budget contributions” as one strand, with five others envisaging finance from carbon market auction revenues; revenue from international transport (shipping and airline taxes); carbon taxation; multilateral funds (most notably, IMF Special Drawing Rights); and an international financial transaction tax. Two work streams considering private finance will cover “using public finance to leverage private investment/finance” (including debt swaps and insurance schemes) and carbon markets (which includes CDM reform and sectoral proposals). In addition to the main report, they published eight different work streams paper, providing technical information and analysis for each finance source.\n\nAlthough the AGF Report did not build a blueprint for implementing these sources, it does assess all sources based on eight criteria, which includes revenue, efficiency (carbon efficiency - the impact of a method on setting a price for carbon externality and overall efficiency - taking into account impacts on developed country growth and risks, equity (distribution of revenue), incidence (who really pays for the climate change mitigation and adaptation actions - should avoid payment by developing countries or inclusion of developing countries’ contribution in counting towards 100billion, practicality (feasibility before 2020), reliability, additionality to Official Development Assistance and acceptability (domestic political acceptability in both developed and developing countries).\n\nCritics claimed that the group could contribute to the downgrading of UNFCCC negotiations, as well as complaining of a lack of transparency and a significant gender bias. Also, some civil society organizations do not agree that US 100 billion per year is sufficient for climate change financing, but overall, NGOs are content with the pressure on developed countries brought by the AGF report.\n\nThe United States government rejected all new innovative sources at international scale proposed in the AGF report, namely, Financial Transaction Tax (FTTs), Special Drawing Rights (SDRs), and Bunker Fuels in the Maritime and Aviation Sector. Although the cap-and-trade bill was rejected at the Congress in 2010, the U.S. government still considers a carbon market as the more viable way to finance climate change activities.\n\nThe European Union in general favors innovative sources. With the fate of the Kyoto Protocol undetermined beyond 2012, the EU has limited offset projects in Least Developed Countries. Under the G20 leadership of the French presidency, the EU considered a Financial Transaction Tax at the European Union level, and channel the revenue for climate, health, education and other international development purposes. A detailed report was published stating European Commission's response to the AGF report. Although \"takes note\" is relatively weak wording, the report was referenced in all submissions to the UNFCCC regarding climate finance, especially innovative sources.\n\nOutside the UNFCCC system, the AGF report is extensively referenced in climate financing discussions at the G20, European Union, International Maritime Organization, and other international forums. As many other potential financing sources, accessing any new sources will require political will. Efforts have been made under the G20 to remove fossil fuel subsidies, but they were not successful once again at the recent G20 meeting in Seoul.\n\nSimilar to the AGF report, there are many high-profile reports; addressing climate finance sources with a focus on innovative sources. The international community is making critical decisions on how to mobilize up to US$100 billion per year by 2020 based on recommendations in these reports.\n\n"}
{"id": "15289778", "url": "https://en.wikipedia.org/wiki?curid=15289778", "title": "Human-electric hybrid vehicle", "text": "Human-electric hybrid vehicle\n\nA human-electric hybrid vehicle is a hybrid vehicle, or more specifically a hybrid human powered vehicle, whose drivetrain consists of a human being and an electric motor/generator (and one or more electricity-storage device(s) such as a battery(ies) or ultracapacitor(s)). Some vehicles are able to operate off both human power and be plugged in to operate on battery power.\n\nIt can have characteristics of a bicycle, velomobile or other lightweight human operated vehicles with the addition of faster acceleration and regenerative braking, allowing a higher average velocity, especially in hilly terrain.\n\nSome vehicles have a clutch and three or more wheels, allowing the operator to continue pedalling and charge up the electricity-storage device during traffic stops.\n"}
{"id": "26576001", "url": "https://en.wikipedia.org/wiki?curid=26576001", "title": "Illustrations of the Family of Psittacidae, or Parrots", "text": "Illustrations of the Family of Psittacidae, or Parrots\n\nIllustrations of the Family of Psittacidae, or Parrots contains 42 lithographs with original hand painted colour by Edward Lear.\n\nLear started painting parrots in 1830 when he was 18 years old, and by 1832 he had published 42 paintings of parrots as lithographic plates bound together as a book. A total of 175 books were made of which about 100 survive today. He painted live parrots at the London Zoo and some in private collections. The quality of his paintings of parrots established his reputation as one of the best natural history artists of his time.\n\nThe young Lear gained access to parrots in private collections through contacts he made while sketching at London Zoo. He met Benjamin Leadbeater, a taxidermist and trader in specimens, who is credited in the captions as possessing several of the birds depicted. Another primary source of specimens was the menagerie of Edward Smith Stanley, 13th Earl of Derby and then president of the Linnean Society (1828—1833). Lear met Stanley in 1831 and spent time studying the parrots amongst his large collection of animals. Noted as the pinnacle of his natural history productions, during the period before his eyesight began to fail, the illustrations are regarded as exquisitely accurate and appealing. The work was a forerunner to the major volumes of bird paintings by Gould and Audubon, who had both worked with Lear. Sketches and studies for this work are included in the major Lear art collection held at the Harvard University Houghton Library.\n\nThe lithographic plates for Lear's publication were produced by Charles Joseph Hullmandel, a printer noted for his reproduction of fine art. The full title is \"Illustrations of the family of Psittacidæ, or parrots: the greater part of them species hitherto unfigured, containing forty-two lithographic plates, drawn from life, and on stone\".\n"}
{"id": "213835", "url": "https://en.wikipedia.org/wiki?curid=213835", "title": "Incandescence", "text": "Incandescence\n\nIncandescence is the emission of electromagnetic radiation (including visible light) from a hot body as a result of its temperature. The term derives from the Latin verb \"incandescere,\" to glow white. \n\nIncandescence is a special case of thermal radiation. Incandescence usually refers specifically to visible light, while thermal radiation refers also to infrared or any other electromagnetic radiation.\n\nFor information on the intensity and spectrum (color) of incandescence, see thermal radiation.\n\nIn practice, virtually all solid or liquid substances start to glow around (977 ˚F), with a mildly dull red color, whether or not a chemical reaction takes place that produces light as a result of an exothermic process. This limit is called the Draper point. The incandescence does not vanish below that temperature, but it is too weak in the visible spectrum to be perceivable.\n\nAt higher temperatures, the substance becomes brighter and its color changes from red towards white and finally blue.\n\nIncandescence is exploited in incandescent light bulbs, in which a filament is heated to a temperature at which a fraction of the radiation falls in the visible spectrum. The majority of the radiation however, is emitted in the infrared part of the spectrum, rendering incandescent lights relatively inefficient as a light source. If the filament could be made hotter, efficiency would increase; however, there are currently no materials able to withstand such temperatures which would be appropriate for use in lamps.\n\nMore efficient light sources, such as fluorescent lamps and LEDs, do not function by incandescence.\n\nSunlight is the incandescence of the \"white hot\" surface of the sun.\n\nThe word \"incandescent\" is also used figuratively to describe a person who is so angry that they are imagined to glow or burn red hot or white hot.\n\n\n"}
{"id": "21951571", "url": "https://en.wikipedia.org/wiki?curid=21951571", "title": "Ishrat Hussain Usmani", "text": "Ishrat Hussain Usmani\n\nIshrat Hussain Usmani, NI (Urdu: ڈاکٹر عشرت حيسن عتثمانى‎ 15 April 1917 – 17 June 1992), best known as I. H. Usmani, was a Pakistani bureaucrat and an atomic physicist who was the second chairman of Pakistan Atomic Energy Commission (PAEC) from 1960 to 1972; as well as the associate director of the Space Research Commission.\n\nDuring his career, he was also the Chairman of the Board of governors of the International Atomic Energy Agency (IAEA) from 1962 to 1963, and played a vital role there in country's peaceful development of nuclear technology to acquire the facilities. To his peer, he is remembered as one of chief architect of country's nuclear power expansion and also given co-credited to established country's first nuclear power plant in Karachi in co-operation with Canada, with Abdus Salam.\n\nAs a bureaucrat, he lobbied for science and development to become part of national politics and his efforts were also involved sending hundreds of young Pakistan's students abroad to pursue higher education in the field of nuclear technology. Due to his long tenure as chairman of the atomic energy commission, Usmani is colloquially known as father of the \"atomic energy commission\", a title given to his peers.\n\nUsmani was born into a respected, cultural, upper middle class, and an educated family of Delhi and Aligarh. After his school education in Aligarh he joined his maternal uncle Dr Khwaja Abdul Hamied, the founder of CIPLA and a pioneer of pharmaceutical industry in India, and joined the St Xavier's College Bombay from where he obtained in 19, his BS (with honours) in Physics and later obtained MSc in Physics from Bombay University. In 1937, the Ishrat Usmani proceeded to the Imperial College, University of London, for research in atomic physics with the Nobel Laureate Professor P.M.S. Blackett, and he produced a thesis entitled \"A study of the growth of compound crystals by electron diffraction\" in 1939. He completed his doctorate in Atomic Physics from the Imperial College of Science and Technology, London, after writing a brief thesis on Electron diffraction, prior to start of World War II. He thereafter successfully appeared in the Indian Civil Service Examination (ICS)and became the first ever entrant to that service with a PhD. On Partition of the undivided India into post independent India and Pakistan he opted to serve in Pakistan and served the Government of Punjab.\n\nIn 1950, while at London, he was personally invited and delegated by dr. Alvin M. Weinberg, dr. Robert Charpi, Karl Z. Morgan— the scientists who had worked in Manhattan Project— to the United States where he carried out his research in nuclear power and reactor technology at the Oak Ridge National Laboratory whereas he served as a director of Oak Ridge National Laboratory.\n\nUsmani returned to Pakistan in 1954, joining the Directorate of Science the same year. He played a vital role and served in several senior administrative positions in Pakistan Government. In 1958, Usmani volunteered to join the newly established nuclear government agency, the Pakistan Atomic Energy Commission, and personally tasked himself to build the nuclear power program. Dr.Nazir Ahmed (physicist) was the chairman of the Commission at that time. Usmani played an important role in formulating the nuclear policy for Government of Pakistan. His recommendation and the newly proposed nuclear policy were gladly accepted by the then prime minister of Pakistan Husain Shaheed Suhrawardy and his p0sition in the government was upgraded to Minister of State. In 1959 Zulfikar Ali Bhutto, who then Energy Minister in Ayub Khan's Cabinet, appointed him as a member of the Pakistan Atomic Energy Commission.\n\nIn 1960, Nazir Ahmad lost the slot as the Chairman of Pakistan Atomic Energy Commission to Usmani, who became its second chairman, on a request of President Ayub Khan. One of the earliest tasks he initiated was to begin building the man-power for the nuclear power industry. He introduced the scholarship program at the commission and sent hundreds of scientists abroad. Usmani requested his lifelong friends Dr. Alvin Martin Weinberg and Dr. Robert Charpi to allow Pakistan's foreign exchange students to carry out their research at Oak Ridge National Laboratory (ORNL) and Argonne National Laboratory (ANL), asking them to arrange an on-the-job training programme in nuclear science and engineering for a team of PAEC personnel. In 1965, after Salam undertook to establish a world-class physics institute in Pakistan, Usmani lobbied for it in the United States. The institute is now called the Pakistan Institute of Nuclear Science and Technology (PINSTECH). Building a world-class research establishment also gave Salam the opportunity to exercise his abundant artistic talent. He took particular interest in creating a laboratory that was a masterpiece of architecture, first by choosing the world-famous Edward Durrell Stone as architect, and then by paying full attention to every detail in the construction and the furnishing of the facility.\n\nProfessor Abdus Salam was Usmani's most trusted friend and adviser in science policy in the 1960s. He met with Salam when the latter was the professor of Theoretical Physics at the Imperial College of Science and Technology. He provided the crucial support to Salam in establishing the International Center for Theoretical Physics (ICTP), and played a supportive role to make Abdus Salam the Director of the International Centre for Theoretical Physics. Salam and Usmani worked as a powerful team to obtain national and international support for the development of science and technology as fundamental to economic growth. It was Salam's advice to Usmani to establish the Pakistan Atomic Energy Center at Lahore where he made D. Ishfaq Ahmad as its first scientific director. Abdus Salam also helped Usmani to establish the various atomic research centres such as Nuclear Institute for Agriculture and Biology (NIAB) in Faisalabad, and the Nuclear Institute for Food and Agriculture (NIFA) in Islamabad.\n\nDr. I.H. Usmani conceived the Pakistan Institute of Nuclear Science and Technology as an architecturally inspiring edifice that would motivate scientists, and as many other Pakistani scientists, Usmani had worked closely with Abdus Salam on building nuclear power plants. Usmani became the second chairman of Pakistan Atomic Energy Commission, where he, along with Dr. Abdus Salam, became an instrument in setting up nuclear research labs in Pakistan.\n\nBy the 1971, the Pakistan Atomic Energy Commission (PAEC) had turned into the world's leading nuclear organisation, and led PAEC in many international organisations. His efforts to build the nuclear industry had turned Pakistan into the first Muslim country in the nuclear power capability. Over the years, Usmani carefully and painstakingly developed the country's atomic energy program, and supervised the construction of the facilities that were producing prolific publications in nuclear technology. In spite of being close to Bhutto, Usmani developed serious differences with and resentment towards Bhutto, after Bhutto continued interfering in his work. Therefore, Usmani began to transfer scientists in different laboratories and directorates, to keep the scientists away to work on the atomic bombs. Prior to start of the East Pakistan crises, followed by the 1971 \"Winter war\", Usmani had disclosed all the facilities, technical institutes, and called back its personnel to West-Pakistan. During this time, Usmani intensified Pakistan's non-nuclear weapon policy, and was instrumental in promoting the Nuclear Non-Proliferation Treaty (NPT).\n\nAfter witnessing the war, Usman's relations with Bhutto further deteriorated and Usmani began criticising Bhutto and his policies. He was an outspoken and even a harsh critic of Bhutto's government policies which duly brought about an increase in the number of his enemies, even in his government agency. In January 1972, Abdus Salam arranged and participated in a secret meeting which later emerged as \"Multan Meeting\" where Salam invited Usmani to meet with Prime minister Zulfikar Ali Bhutto.\nLarge and loud complaints against Usmani were lodged; his peers and junior scientists, as well as his seniors, were turned against him. His actions of replacing and transferring scientists in different directorates that disrupted the research were criticised. Bhutto lost no time to announce, nuclear engineer Munir Ahmad Khan. to be PAEC's new chairman. At this meeting, Usmani was the only scientist to have protested against the projecy atomic bomb project to build the nuclear deterrence against India, while Abdus Salam remained silent in support of Bhutto when Usmani turned to Salam for the support. Usmani asked Prime minister Bhutto not to divert the peaceful programme to aggressive nuclear weapons, but Bhutto rebuffed, while Salam provided his support to appoint Munir Khan as the scientific director of the atomic bomb project.\n\nAfter the meeting, Usmani reached out to Bhutto and privately tried to have a conversation with Bhutto to reverse the decision of developing the atomic weapons. However, Prime Minister Bhutto patiently listened to him and declined his advice. The Following year, he was safely silenced. According to the Pakistan Defence Megazine, Usmani had opposed the decision of developing nuclear weapons \"because at the time Pakistan did not have the necessary infrastructure needed for such a technologically giant and ambitious project\". Still, as Bhutto needed the civilian infrastructure to be built, he established the , he appointed Usmani Minister of Science in 1972.\n\nIn November 1972, when the Kanupp-I was inaugurated, Usmani was deliberately not invited by Prime minister Bhutto, instead was accompanied by Abdus Salam and Munir Ahmad Khan at the \"Kanupp-I\" ceremony. This was the foundation of Usmani's disagreement with Bhutto and later he claimed that in many of the scientific projects he was not taken into confidence by Bhutto. Usmani soon resigned. Bhutto immediately replaced Usmani with Dr. Mubashir Hassan, Bhutto's close friend and confidant who would later play a vital political role in scientific research on atomic bomb project.\n\nUsmani contributed in the rise of Pakistan's science and wholeheartedly provided his bureaucratic support to Abdus Salam to establish the Space Research Commission (SUPARCO)— the supreme national astrophysics and space authority— as a space-wing in the PAEC. Usmani was put jointly in charge (associate director) of Space Research Commission with Abdus Salam being the first and founding director. In 1962, Usmani and Salam travelled to United States where they had a brief meeting with NASA's officials and due to their hard efforts, the United States and the NASA's engineers and scientists visited Pakistan where NASA decided to set up the country's first spaceport, Sonmiani Terminal Launch.\n\nHowever, during the successive period, Abdus Salam decided to separate the authority from the PAEC; therefore, after reaching out to President Ayyub Khan, Salam succeeded in separating the authority, being its execute director in 1962. Abdus Salam brought in Brigadier-General and aerospace engineer Dr. Wladyslaw Turowicz of PAF in the space program, appointing him the director of the Sonmiani Terminal Launch. Soon the rocket testing programme was initiated by General Turowicz and Abdus Salam witnessed the country's first rocket launch, the \"Rehbar-I\" in 1964.\n\nDue to Bhutto's intensification of his nuclear policy, that was completely disagreed and often protested by Usmani on numerous occasions at the cabinet-level meeting, led him to resign from his government post of which he was appointed by Bhutto. As science minister, Usmani helped established the Pakistan Science Foundation— the government agency for the promotion of Science and Technology. As science minister, Usmani presented the idea of Scientific Services, parallel to the Civil Service of Pakistan, with many scientist would soon follow him, for instance Munir Ahmad Khan who later took his place.\n\nHowever, Usmani departed from the country and took an international assignment of the United Nations. Usmani was appointed the adviser to the UN Environment Programme (UNEP), headquartered and located in Nairobi, Kenya, leading the surveys and reports on Solar radiation management and renewable energy in the developing states. Usmani later went on to established the Solar radiation management centres in Sri Lanka and Senegal, and in 1978, Usmani left the UNEP to join the IAEA.\n\nUsmani became the Chairman of the Board of Governors of the International Atomic Energy Agency, and headed many conferences entitled \"Atoms for Peace\". In 1978, Shah of Iran Mohammad Rezā Pahlavi invited Usmani to Iran to conduct a scientific survey to establish the three commercial nuclear power plants in the country, but the scheme was never performed due to the Iranian Revolution, and in 1980, Usmani joined the United Nations Scientific Committee on the Effects of Atomic Radiation (UNSCEAR) where he urged for peaceful use of nuclear technology.\n\nWhile there, he produced a brief investigative report on the 1986 Chernobyl disaster and made his efforts to enhance the NPT. Unlike Salam, who remained associated with country's atomic bomb programme, Usmani was ejected from the atomic bomb programme. In 1981, Usmani published the influential technical article at the \"\"Nucleonics Week\"— an influential European nuclear publication— claiming that the atomic bomb project has been failed and is unlikely ever to be capable of producing even the crudest of nuclear devices; therefore the programme is near collapse. Although, Usmani was notified and knew well that in fact, the atomic bomb project was a complete success and the atomic bomb program has gone mature and passed the critical phase of producing the fissile cores had been achieved since 1978. His publication played an influential role in convincing the United States' policy to ease off the nuclear embargo on Pakistan.\n\nUsmani served as an energy adviser to the United Nations in New York, and adviser to the UNSCEAR until 1985. Soon his resignation from the United Nations, Usmani joined the Bank of Credit and Commerce International, (BCCI) as an adviser and remaining their until 1991. He finally took the retirement and returned to Pakistan after long 17 years. While in Pakistan, Usmani became a consultant of the New and Emerging Sciences and Technology (NEST), a scientific think tank based in Pakistan.\n\nUsmani remained a vital scientific figure in Pakistan's Civil Service, and is widely given the credit of presenting the idea of scientific civil service, with many engineers and scientists would soon follow his footsteps. However, he is most remembered for established the country's nuclear industry, and was involved in the civil-peaceful projects as part of Pakistan's During the 1960s, Usmani's effort was involved in .\n\nIt was Usmani's effort to send 500 scientists, engineers, mathematicians, and physicist into the best institutions of United States and Europe. In 1972, KANUPP was inaugurated by the Prime Minister of Pakistan; KANUPP was successfully commissioned marking Pakistan's entry in the nuclear age as the second developing – and the only Muslim – country to draw energy from the heart of the atom.\n\nDr. Usmani peacefully died in Karachi on 17 June 1992, and the occasion brought tears to the eyes of many scientists and reformers who regarded him with affection. In May 1998, the Government of Pakistan belatedly recognised Usmani's vital services by awarding the Pakistan's highest civilian award, Nishan-i-Imtiaz posthumously by the prime minister Nawaz Sharif when Pakistan conducted its first successful nuclear tests.\n\n\n"}
{"id": "17610694", "url": "https://en.wikipedia.org/wiki?curid=17610694", "title": "J. Horace McFarland", "text": "J. Horace McFarland\n\nJ. Horace McFarland (1859–1948) from McAlisterville, Pennsylvania was a leading proponent of the \"City Beautiful Movement\" in the United States.\n\nMcFarland was the son of Union Civil War colonel George F. McFarland. He lived and worked most of his adult life in Harrisburg, Pennsylvania, residing at an estate he named Breeze Hill in the Bellevue Park area of the city. At the estate, McFarland established gardens that featured numerous trees, vegetables, and, most prominently, roses. Photos of his famous gardens reside in the Smithsonian institution. McFarland served as president of the American Civic Association (ACA) from 1904 to 1924 and the American Rose Society. McFarland and the ACA were a major force promoting civic improvement, environmental conservation, and beautification in the United States. McFarland helped organize the defense of Niagara Falls from development efforts by power companies, worked to protect Yosemite National Park with the famous environmental preservationist John Muir, who has been hailed as the father of the National Park Service.\n\nHe is remembered for a statement at the first Conference of Governors held at the White House, Washington D.C., in 1908:\n\nHis papers are held at the Pennsylvania State Archives.\n"}
{"id": "30720835", "url": "https://en.wikipedia.org/wiki?curid=30720835", "title": "January 31 – February 2, 2011 North American blizzard", "text": "January 31 – February 2, 2011 North American blizzard\n\nThe January 31 – February 2, 2011 North American winter storm, also called the 2011 Groundhog Day Blizzard, was a powerful and historic winter storm, situated around the United States and Canada on Groundhog Day. During the initial stages of the storm, some meteorologists predicted that the system would affect over 100 million people in the United States. The storm brought cold air, heavy snowfall, blowing snow, and mixed precipitation on a path from New Mexico and northern Texas to New England and Eastern Canada. The Chicago area saw 21.2 inches of snow and blizzard conditions, with winds of over 60 mph. With such continuous winds, the Blizzard continued to the north and affected Eastern and Atlantic Canada. The most notable area affected in Canada was Toronto and the Greater Toronto Area. Blizzard conditions affected many other large cities along the storm's path, including Tulsa, Oklahoma City, Kansas City, St. Louis, Springfield, El Paso, Las Cruces, Des Moines, Milwaukee, Detroit, Indianapolis, Dayton, Cleveland, New York City, New York's Capital District, and Boston. Many other areas not normally used to extreme winter conditions, including Albuquerque, Dallas and Houston, experienced significant snowfall or ice accumulation. The central Illinois National Weather Service in Lincoln, Illinois issued only their fourth Blizzard Warning in the forecast office's 16-year history. Snowfall amounts of 20 to 28 inches were forecast for much of Northern and Western Illinois.\n\nAn ice storm ahead of the winter storm's warm front also brought hazardous conditions to much of the American Midwest and New England, and many areas saw well over of ice accumulation. Numerous power outages, flight cancellations, airport closures, road closures, roof collapses, rail and bus cancellations, mail stoppages, and school, government, and business closures took place ahead of and after the storm; many of these disruptions lasted several days. Several tornado touchdowns were reported in Texas and a tornado watch was issued for parts of Alabama, ahead of the cold front in the warm sector of the storm. In addition, thundersnow was recorded at some locations, including downtown Chicago. At least 24 deaths were reported to be related to the storm, many of them in shoveling or auto-related incidents. The total damages from the ice storm alone may exceed US $1 billion.\n\nA system with a maximum pressure of followed behind it, moving across Montana. A low pressure system from the Pacific Ocean later came ashore over Northern California and crossed the Rocky Mountains, merging with the Alberta Clipper low and a developing Texas low drawing moisture from the northwestern Gulf of Mexico. The storm later intensified, and moved northeast, developing a long warm front stretching toward the New England states, and moving northeast along this jet stream track.\n\nLake effect snow events started over Lake Ontario and Lake Michigan from northeasterly winds. Following the predominant jet pattern, the storm developed a very rapid forward trajectory and began to migrate toward the lower Great Lakes. The heaviest snow fell in a wide swath from central Oklahoma to Illinois, Indiana and the Ohio Valley. An official blizzard warning was issued in Southern Ontario for the first time since 1993, although the Canadian definition changed in 2010.\n\nBecause the storm dumped some of snow in parts of Nova Scotia, and winds up to some 50 km/h (31 mph) to some areas in eastern Canada, schools and businesses were closed on Thursday morning, the 3rd of February. Lower Sackville near Halifax received of snow.\n\nNumerous school, bus and flight cancellations occurred in the province in preparation for the biggest winter storm during the winter of 2010–2011. A barn roof collapsed during the storm in the community of Baie Verte.\n\nThe storm dropped 20-30 centimetres of snow over Southern Ontario. Hamilton saw more than 25 centimetres due to an intense Lake Effect band from the west end of Lake Ontario caused by an enhanced wind from the east-northeast, Toronto was spared more than was forecasted with 15 centimetres and a winter storm warning in effect. Areas from the Lake Huron shoreline east to London and Hamilton were under a Blizzard Warning. There were reports of thundersnow in Windsor, Ontario when the storm began to hit the region Tuesday night on February 1; the city and nearby Chatham-Kent also declared a snow emergency, effectively enacting a parking ban to ease snowplow efforts, due to forecasted snow totals of 30+ centimetres, and the snow clean-up in the city is likely to cost $700,000 CAD, about 1.5 times more than normal. The Toronto District School Board and Toronto Catholic District School Board closed all schools for the first time since the Blizzard of 1999, a controversial decision given the less than anticipated outcome and snowfall totals resulting from the storm. Schools were also closed in the Windsor area and elsewhere.\n\nA traffic pile-up stretching three kilometres near Montreal, Quebec involving a school bus and many other vehicles sent 29 people to hospital for injuries. All schools in the Eastern Townships School Board near Sherbrooke were closed.\n\nWind speeds exceeding hit areas near Clarenville and Bonavista, while schools in eastern parts of St. John's were closed.\n\nNorthern Mexico suffered widespread infrastructure damage from the storm, and several weather-related deaths. In Chihuahua City, the temperature dropped to 1 degree below zero Fahrenheit. Ciudad Juárez, which lies just across the border from El Paso, Texas, in the Mexican state of Chihuahua, a regional state of emergency was declared Tuesday evening, just ahead of the cold weather system, with Mexican authorities urging citizens to stay indoors. Despite the snow and ice that developed across the borderland, the major International Bridges remained open during the blizzard. Additionally, to help ease the electricity crash across Texas due to the freezing weather, Mexican officials arranged for the transfer of 280 megawatts of power to the United States via utility hookups located in Nuevo Laredo (across from Laredo, Texas) and Piedras Negras, Coahuila (near Eagle Pass, Texas). The cold wave behind the storm's cold front left temperatures plunging to -18 °C (0 °F) in Ciudad Juárez metropolitan area, and in the mountains area plunging to -23 (-9 °F), resulting in the deaths of at least six people in the coldest temperatures recorded in the area in at least half a century. In addition, 35 animals died at a zoo, and closures of schools and factories occurred in the city.\n\nOn Wednesday, authorities in Juárez announced that convoys would be traveling out to remote regions and slum areas to ensure that citizens are warm and have the supplies they need to get through the next few days. On Thursday, Mexican officials suspended energy exports to Texas, citing cold weather damage at five power stations across Mexico that resulted in a total loss of 1,000 megawatts of electricity in Northern Mexico. Power stations in Mexico were able to meet the resulting energy demands in Northern Mexico, but could not spare additional electricity to aid Texas. In Juarez, overnight temperatures in the single digits left 90% of the city without water service due to frozen pipes, and the failure of thermoelectric generators at a power station in Samalayuca, 30 miles south of Juarez, left citizens without power for roughly five hours.\n\nIn Monterrey, Nuevo León's capital city, the cold air killed many trees and other types of tropical plants. Snow was observed in the high peaks in the mountains and the fountain in the main Alameda park got frozen overnight.\n\nConnecticut experienced up to 10 inches of snow and 3/4 inch ice accumulations, resulting in widespread tree damage and power outages. The additional snow and ice accumulation on top of several feet of snow prior to the storm led to roof collapses in Bethany, Waterbury, and Middletown. The West Rock Tunnel on the Wilbur Cross Parkway was closed for several hours due to accidents caused by slippery conditions, while service was disrupted on the Metro-North Railroad and at Bradley International Airport. The heavy snow caused at least 136 roof collapses of barns, greenhouses and other farm structures.\n\nIn Chicago, in anticipation of the imminent blizzard conditions, 1,300 flights were canceled at O'Hare and Midway airports. By 4:30pm, CST (22:30 GMT), the storm reached blizzard status with sustained winds exceeding , with white-out conditions being reported by spotters in the Old Town neighborhood on the city's North Side. while Lake Shore Drive was temporarily shut down due to impassable conditions. City officials said on February 2, that at least 900 cars and buses were stranded on Lake Shore Drive, with their drivers and passengers being trapped in some cases for as long as 12 hours (many drivers opting to stay with their cars in the false-fear of being ticketed for abandoning their vehicles instead of walking the short distance to the high-rise buildings lining the drive), but that closing the roadway earlier could have resulted in disastrous traffic conditions and possible accidents on other Chicago area streets. Tow trucks began pulling cars from Lake Shore Drive on the evening of February 2, and moving them into six temporary lots for motorists who abandoned their vehicles to arrive and claim. The city of Chicago was unable to keep track of the license plates for each vehicle, which led to complaints from many drivers and by the time they located their vehicles, many were unable to retrieve them from the lots because they were parked bumper-to-bumper.; on February 3, the City of Chicago reopened Lake Shore Drive to traffic before rush hour.\n\nThe Chicago Public Schools announced, on February 1, that some schools will be closed and some will still be open on the following day (Wednesday, February 2), which marked the first cancellation of classes district wide since the Blizzard of 1999. Heavy snow and high sustained winds gusting in excess of , caused rail switches to freeze on the CTA's Red Line and blew a portion of the roof off Wrigley Field. Northwestern University, Illinois Institute of Technology and the University of Chicago canceled classes Wednesday for the first time in over a decade due to the weather. Over 39,000 state workers were ordered not to come into work due to the weather; this was the largest figure since a blizzard in 1978. Mail service was stopped on Wednesday for six post office regions in Northern Illinois. Amtrak train service out of Chicago was also canceled across Illinois on Wednesday.\n\nIn the central part of the state, numerous municipalities were all but shut down by the storm. On Monday, residents rushed to the stores to stock up on groceries, and numerous stores reported record sales. On Tuesday, several school districts and universities pre-emptively canceled classes for Tuesday evening and all-day Wednesday. Many school districts planned to close a second day in a row, on Thursday. About of snow fell Monday night. Tuesday afternoon brought heavy snowfall and sustained winds, with gusts of over . Local government officials encouraged all businesses to close down, and local hospitals braced for the storm by preparing living and sleeping areas for essential personnel. Flights from area airports were canceled, and local officials repeatedly urged residents not to travel, since because of the whiteout conditions, snow plows had been taken off the roads. Interstate 80 was closed Tuesday night between Morris and Princeton. On Wednesday, I-290 and Illinois Route 53 were shut down from Lake Cook Road in Arlington Heights to St. Charles Road in Elmhurst. Forty vehicles were abandoned on Route 53. Parts of Interstate 57 were also shut down. The state police described most expressways as \"impassable\". 50 motorists stranded on Illinois Route 47 south of Huntley received assistance from a snowmobile club, while dozens of motorists had to be rescued on Illinois Route 72, west of Hampshire. During the storm's peak on Tuesday night, more than 100,000 customers were without electricity across the state, including 79,000 ComEd customers across Northern Illinois and 35,800 Ameren customers in Central Illinois. Several charities set up shelters for the homeless and those stranded by the blizzard, and governor Pat Quinn mobilized 500 Illinois National Guard troops to help rescue stranded motorists. Hundreds of motorists had been rescued off Interstates 290, 55, 57, and 80. In addition, over 80 traffic accidents were reported.\n\n11 snow-related deaths had been reported in Illinois by February 3. The body of an individual was recovered from Lake Michigan by Chicago Police. The pedestrian had reportedly been walking on a lake-front pathway when he had been blown into the lake by strong winds. In Grayslake, a man was killed in a crash while driving through the storm, while a woman in Mundelein died from hypothermia in her vehicle. A man in Chicago was also found dead in his home, which had no heat. In Barrington, a teacher died of a heart attack while leaving school on Tuesday. Five cardiac-related deaths from shoveling snow occurred in Lyons, Downers Grove, Mount Prospect, Carol Stream, and Glendale Heights. In rural LaSalle County, a man died while trying to walk through the storm after his vehicle was stranded on a rural road.\n\n21.2 inches of snow fell at Chicago-O'Hare International Airport, making this the third largest total snowfall in Chicago history, after the infamous Chicago Blizzard of 1967, and the Blizzard of 1999. 24 Inches fell at the 1 N Abingdon mesonet site in Knox County, in West Central Illinois. This was the largest snowfall in the history of the mesonet. Drifts of 10 to 15 feet also occurred. Snowfall rates exceeded 4 inches per hour for a few hours on Tuesday evening as well along with thunder and lightning.\n\nAdditional official snowfall totals included 20.9 inches at Chicago-Midway International Airport, 16.4 inches at the National Weather Service office in Romeoville, and 14.3 inches at Chicago Rockford International Airport. The storm's highest total of 27 inches was reported in northwest suburban Roselle and Medinah, Illinois. Peak gusts during the blizzard included 61 mph at O'Hare and 67 mph along the lakefront.\n\nNear Wheatfield, a teenage boy and a hitchhiker he picked up were killed during the blizzard when a semi crashed into the compact car they were driving in. Central Indiana saw ice, followed by snow and high winds, which gusted over 50 mph. A peak of 50,000 Duke Energy customers were without power due to the storm, including nearly half of the Purdue University campus at one point. A 57-year-old South Haven resident collapsed and died after clearing snow from his driveway. The city of Indianapolis received nearly a half inch of ice from the blizzard, effectively paralyzing the city and leaving many without power.\n\nSoutheastern Iowa saw up to 18.5 inches of snow. The heaviest snow fell in the eastern half of the state. Des Moines fared slightly better, where only 6.5 inches fell. Some roads remained closed on Wednesday night, and over the course of the storm, state troopers responded to 151 accidents and assisted 428 motorists.\n\nIn Kansas, 53 counties were declared disaster areas. Especially hard hit were eastern sections of the state, which saw over a foot of snow and whiteout conditions. Government offices and the state legislature were closed on Wednesday, but expected to reopen on Thursday. At least two deaths were blamed on the storm.\n\nBaltimore received freezing rain during the day on 1 February, which changed to rain as temperatures rose on 2 February, and the overall icing in that region was less than expected.\n\nIn Berkshire county snowfall amounts of 10 inches accumulated.\n\nA 73-year-old Dansville man was killed in a vehicle crash. Universities that closed due to the snow include Western Michigan University, Kendall College of Art and Design, Grand Valley State University, Michigan State University, University of Michigan Flint, University of Michigan Dearborn, Wayne State University and Central Michigan University.\n\nIn Missouri, a state of emergency was declared by Governor Jay Nixon, who activated the Missouri National Guard. On February 1, Interstate 70, which runs east-west from St. Louis to Kansas City, the entire width of Missouri, was closed by the Missouri Department of Transportation due to white-out conditions and increasing snowfall. It was the first time in Missouri history that any interstate was closed across the entire state.\n\nKansas City was under a blizzard warning for only the 2nd time since 1980, and only the 3rd time in its entire history. Columbia experienced the town's first blizzard warning with this storm in their history.\n\nMany local school districts canceled classes, the University of Missouri shut down for an unprecedented three successive days. The University of Central Missouri in Warrensburg, Missouri (which received 23 inches of snow, which in turn broke the all-time record for the town for snowfall in one day) was closed an unprecedented three days as well. A scheduled St. Louis Blues hockey game on February 1 was postponed until the 22nd. Areas of Missouri also reported significant sleet accumulation. In St. Louis, some MetroLink service was suspended due to ice on the rails. Several malls were closed due to ice in the parking lots. One person in central Missouri was killed during the storm.\n\nIn New Jersey, snow, rain and ice were all problems. In central New Jersey Ice storm warnings were put into effect. In portions of northern New Jersey, the forecast called for 1'+ of snow and over 1\" of ice. The roads were slippery and it was hard for cars to maneuver on the roadways.\n\nUp to two feet of snow fell in the Sangre de Cristo, and the Central Mountain Chain of New Mexico, while up to 6 inches fell in the Albuquerque Metro Area. The heaviest snowfall totals were 23 inches at the Santa Fe Ski Area, and 20 inches at Sandia Peak east of Albuquerque, Bonito Lake in Lincoln County, and Tres Ritos in Taos County. A 180-mile stretch of Interstate 25 was closed between Las Cruces and Belen due to strong winds and blowing snow. On Thursday evening, Governor Susana Martinez declared a state of emergency across southern New Mexico, due to the steadily decreasing natural gas supply brought about by the catastrophic failure of the El Paso Electric Company's power grid.\n\nNew York City received almost an inch of ice from freezing rain during the night of 1–2 February, causing public transportation on both bus routes and the Long Island Rail Road to be either delayed or shut down entirely. One Long Island resident was killed by a fire sparked by cooking fuel during the storm.\n\nOhio was on the warm sector of the low-pressure system. On the night of January 31-February 1, the Cleveland and Akron area received a Winter Storm Warning from the NWS Cleveland Field Office for snow and freezing rain. On Monday night 3-6 inches of snow fell during the pre-frontal warm front. During the overnight hours of February 1–2, as the center of low pressure moved from Missouri to lower Indiana, it carried a warm front, with warm air advection and a shallow cold air pool at the bottom. This led to freezing rain in parts of Northeast Ohio. In Canton ice accretion ranged from 0.5 to 0.75 inch, which led to power lines and trees crashing, leaving almost 40,000 people without power. In the Greater Cleveland area, there was 0.1 inch of ice accretion and scattered outages in the Cleveland suburbs of North Royalton, where 2,000 people lost power, and also in parts of Garfield Heights and Maple Heights. Scattered outages were reported in other parts of the area.\n\nThe temperatures overnight went from at 7:00PM to at 5:00 AM turning the freezing rain to liquid rain, and the NWS canceled the Winter Storm Warning earlier at 5:00. On Wednesday morning as the low moved to New England, cold air advected behind the low and temperatures had plummeted to the middle-20s Fahrenheit by 4:00 PM with Cleveland receiving 1-2 inches of snow and breezy conditions.\n\nIn the Dayton area, an Ohio Highway Trooper and his wife died from carbon monoxide poisoning from a running generator that built up gas in their home after the home lost power.\n\nThe heavy snowfall, along with sleet and some freezing rain, began developing over Oklahoma and the Texas panhandle on the evening of January 31, with a state of emergency declared by Governor Mary Fallin earlier that day. As a result of the emergency declaration, a state law prohibiting price increases of more than 10 percent on most goods and services during and for 30 days after an emergency declaration went into effect, and will remain in effect for 180 days after the declaration order for prices of repairs, remodeling and construction. The Salvation Army of Central Oklahoma opened three shelters and one warming station for those stranded by the storm outdoors, the homeless, and those who lost power during the storm; two in Oklahoma City, one in Norman and one in El Reno, with teams from the Oklahoma chapter of the American Red Cross placed on standby. Will Rogers World Airport in Oklahoma City and Tulsa International Airport were closed, with Will Rogers remaining closed for 20 hours; I-44 from Stroud to the Missouri state line, Interstate 40 near Okemah and westbound lanes of I-40 east of Henryetta were among many major highways closed, and the Indian Nation, Creek and Muskogee turnpikes were all either closed entirely or in stretches.\n\nMost school districts in the state including the Oklahoma City and Tulsa public school districts, as well as most Oklahoma City government offices were shut down a day in advance of the storm. The United States Postal Service released a statement saying that it was attempting to make deliveries across the state but that \"some areas may be undeliverable\", due to the heavy snow and very low visibility; mail delivery in Oklahoma City did not occur in most areas due to the conditions. Temperatures across the state on February 1 and 2nd hovered in the single digits to mid-teens. Winds gusted to near at times creating ground blizzard conditions across the eastern half of the state; wind chill values dropped as low as in Boise City, the lowest recorded wind chill in the state since the deployment of the Oklahoma Mesonet. Heavy snow caved in the roof of a building on the Hard Rock Hotel & Casino complex in Tulsa containing a poker room and electronic casino games, the damage was confined to an area that was part of the original structure built in 1992. There was no one injured as a result of the roof collapse as no people were in the affected area at the time; the hotel towers, a concert venue, a convention center, and retail operations at the complex were unaffected and remained open. The \"Tulsa World\" newspaper canceled its print editions on February 2, 3 and 4, citing the heavy snowfall and hazardous road conditions that could compromise the safety of their newspaper carriers, making it the first time in the newspaper's 111-year history that the print edition had to be canceled; however, the newspaper did continue to publish its electronic editions on its website. A section of a boat dock at the Tera Miranda Marina Resort on the Monkey Island arm of Grand Lake collapsed due to significant snow accumulations on its roof, destroying four boats valued at about $450,000.\n\nWill Rogers World Airport recorded an estimated 11.6 inches of snow, smashing the all-time daily snowfall record for the month of February for Oklahoma City (the previous record was 6.5 inches on February 7, 1986). Tulsa also set an all-time snowfall record for the storm for February 1 and the month of February, as the Tulsa International Airport received 14 inches of accumulated snowfall (the previous February snowfall record for the city of Tulsa was 10.5 inches in February 2003, and the previous record for snowfall in a single 24-hour period in Tulsa was 12.9 inches on March 8–9, 1994).Owasso, Oklahoma received the most snowfall accumulation in Oklahoma with 21 inches. Ironically days earlier on January 29, wildfires had burned parts of central and south-central Oklahoma, and ten central and south-central Oklahoma counties were placed under a burn ban due to very dry, wildfire-prone conditions. State Insurance Commissioner John Doak issued an emergency order to allow licensed claims adjustors outside of Oklahoma to help assess damages and losses from the storm for 90 days. On February 2, Governor Fallin asked the White House to approve an emergency disaster declaration request for all 77 Oklahoma counties. In a statement by Fallin, state and local governments would receive 75% reimbursement for expenses associated with responding to the storm if the declaration is approved, including overtime costs, costs associated with operating shelters and clearing snow and ice-covered roads. That evening, President Barack Obama granted Fallin's federal emergency request, authorizing the Department of Homeland Security and FEMA to coordinate disaster relief efforts in the state of Oklahoma.\n\nOklahoma State University held its home basketball game on February 2 against the University of Missouri as scheduled, despite the difficulty the Missouri team had arriving in Stillwater due to the blizzard. As a result of the storm, the university provided free tickets to fans who were able to attend the game at Gallagher-Iba Arena, which Oklahoma State won in a 76-70 upset against the #15 Tigers.\n\nThe storm system has caused at least three deaths in Oklahoma, one in a sledding accident and two in an auto crash. On February 1, a 20-year-old Oklahoma City woman died due to injuries suffered in a sledding accident near Lake Stanley Draper, in which the sled being pulled by a vehicle veered off the road, flinging the woman into a guardrail; she was pronounced dead at the scene. Two days later as slick road conditions continued across parts of the state, a truck carrying eight people ran off of a bridge and fell into the Spring River (which had been covered in ice), on I-44 in Ottawa County near Miami, killing two people; one of two westbound lanes of I-44 was reopened to traffic the previous evening after blizzard conditions made it impassible.\n\nIn portions of Pennsylvania north of Philadelphia, ice storm warnings were put into effect.\ndropped several inches of sleet and snow in the Poconos and included a long period of freezing rain that produced ice accretions of up to half an inch in the Lehigh Valley and the Philadelphia suburbs. The ice tore down numerous tree limbs, trees, and subsequently, power lines.\n\nPrecipitation started as snow across the region during the early morning of the 1st. As warmer air moved in aloft, the precipitation changed to sleet and freezing rain by the morning rush in the local Philadelphia area, a mixture of sleet and freezing rain by the end of the morning commute in Berks County and the Lehigh Valley and a wintry mix late in the morning in the Poconos. Precipitation tapered off to mainly freezing drizzle during the afternoon and early evening of the 1st. Heavier precipitation moved in again during the evening of the 1st and fell as freezing rain in the Philadelphia suburbs, a mixture of sleet and freezing rain in Berks County and the Lehigh Valley and mainly a snow and sleet mixture in the Poconos. Overnight colder air moved in aloft in over the Poconos and precipitation changed back to all snow for a few hours. Toward sunrise on the 2nd, this process started to reverse at both the surface and aloft. Warmer air was moving north again and the freezing rain changed to plain rain across the Philadelphia suburbs and Berks County around 8 a.m. EST and the Lehigh Valley around 9 a.m. EST. In the Poconos, precipitation changed to freezing rain around 7 a.m. EST and ended as freezing rain around 11 a.m. EST on the 2nd. Representative snow and sleet accumulations included 5.4 inches in Tobyhanna (Monroe County), 5.0 inches in Pocono Summit (Monroe County), 3.5 inches in Delaware Water Gap (Monroe County), 2.1 inches at the Lehigh Valley International Airport, 1.5 inches in Albrightsville (Carbon County) and 1.0 inch in Easton and Martins Creek (Northampton County). Representative ice accretions included 0.50 inches in Glenmoore (Chester County), Sping Mount (Montgomery County) and Emmaus (Lehigh County), 0.40 inches in East Nantmeal (Chester County) and Lansdale (Montgomery County), 0.38 inches in Kutztown (Berks County) and Allentown (Lehigh County), 0.33 inches in Feasterville (Bucks County) and 0.25 inches in Bangor (Northampton County).\n\nMany trees still had snow on them from the winter storm of the previous week to exacerbate the damage. Nearly 300,000 power outages occurred. PECO Energy reported about 185,000 of its southeastern Pennsylvania customers lost power. Power was not completely restored to the last few until the afternoon of the 6th. Pennsylvania Power and Light reported about 79,000 of their customers lost power in Eastern and Central Pennsylvania; while Metropolitan Edison reported around 14,000 of its customers lost power in Berks County. Numerous schools cancelled classes on both the 1st and 2nd. Recycling and garbage pick-ups were delayed. This winter storm added additional strains to snow removal budgets and tight salt supplies. Reading, Hamburg, Boyertown, Birdsboro, Barto, Bechtelsville and Douglassville all suffered power outages. In Bucks County, downed wires in Milford caused a basement fire in one home on Sleepy Hollow Road. In Montgomery County, the worst reported tree and ice damage occurred in Lansdale and Hatfield. A utility pole fire in Pottstown knocked out power to the borough's water treatment plant. There were over 100 reports of downed wires throughout Northampton County.\n\nIn Northampton and Lehigh County, numerous crashes occurred on U.S. Route 22, Pennsylvania State Route 33 and Interstate 78. On Interstate 78, a driver swerved to avoid hitting a plow truck and was injured. In Bethlehem, a driver was injured after his vehicle rolled over on Schoenersville Road. Also in Bethlehem, a 100-foot section of a porch roof collapsed on the evening of the 2nd on Glendale Avenue from the weight of ice and snow. Three vehicles were damaged. In Berks County, Pennsylvania State Routes 345 (near Birdsboro) and 625 (south of Reading) were closed. In Chester County, there were several slip and fall injuries reported, mainly on the 1st. Just east of Exton, Northbound U.S. Route 202 was closed between Pennsylvania State Routes 30 and 401 because of an accident with injuries on the 2nd. Two roadways were closed because of downed trees and wires in North Coventry Township. One roadway was also closed in West Vincent Township.\n\nIn Texas the storm caused widespread disruption of road and air traffic, including flights into and out of Dallas-Fort Worth International Airport and Love Field. Rolling blackouts were instituted across the state as high demand for electricity left the power grid overloaded and unable to handle the demand. Governor Rick Perry asked for citizens to conserve as much electricity as they can to help ease the overloaded power grids. ERCOT, the governing body responsible for most of the electricity distribution in Texas, reported that more than 75% of the state was affected by rolling blackouts on February 2nd; at one point demand for energy was so great that utility companies began to purchase electricity off the national grids to meet the demand. Parts of Texas were expected to experience additional rolling blackouts Wednesday and Thursday as workers labor to get the electric systems back up and running. Post-analysis indicated that the cold temperatures had caused over 150 generators to encounter difficulties; loss of supply, instrumentation failures, and gas well-head freezing were some of the source causes.\n\nThroughout the Dallas-Fort Worth Metroplex, multiple large school districts were closed for a record-setting 5 days in a row, letting students out a whole week because of road hazards due to ice and snow. An ice storm affected areas as far south as Houston behind the main storm front, while three men were killed near Houston in traffic accidents. The storm adversely affected activities in the week leading up to Super Bowl XLV, which was played at Cowboys Stadium in Arlington, Texas.\n\nThe storm caused a failure at a water treatment plant near Donna, Texas, prompting officials to issue a boil water advisory.\n\nIn El Paso, Texas, the storm left major roadways slippery with ice and snow, and the abrupt demands placed on El Paso's utility services resulted in sporadic reports of loss of water and natural gas capability. Freezing temperatures resulted in the total failure of both of the city's natural gas power plants, resulting in rolling blackouts across the city. The loss of power had a ripple effect across the region, as the power failure left water and gas utilities without the power needed to operate pumps to move the water and natural gas to customers. This resulted in the complete cancellation of activities at all area independent school districts and institutions of higher education on Wednesday, Thursday, Friday, and the following Monday. In total, nearly 200,000 El Paso Electric customers went without power at some point as a result of the storm, while 1,200 Texas Gas Service customers went without gas. Over 157 water main breaks due to cold temperatures were reported to the El Paso Water Utilities, which when combined with the frozen water pumping equipment and abnormally high demand for water left El Paso water reservoirs dangerously low. Stage 2 mandatory water restrictions, which permit the use of water for drinking only, were implemented Monday night as the water utility worked to raise the water levels in the reservoirs, and on Wednesday the water restrictions were lifted. That same Wednesday it was announced that federal and state officials would conduct an investigation into El Paso Electric as a result of the spectacular failure of the utility during the blizzard.\n\nIn Wisconsin, Governor Scott Walker declared a state of emergency in 29 Wisconsin counties due to the snowstorm, and deployed 75 Wisconsin National Guard soldiers. Early on February 2, the state's emergency management agency issued a Civil Danger Warning warning drivers completely off the roads at the risk of being stranded due to dangerous conditions forcing county plows, law enforcement and salters off the roads, a declaration distributed via NOAA Weather Radio's Emergency Alert System and local media outlets, and otherwise only issued for other major events such as terrorist attacks and water contamination emergencies. The same warning was issued hours later completely disallowing travel within Lake County, Illinois. Interstate 94 and Interstate 43 south of Milwaukee to the state line were both closed for a time due to dangerous conditions and many stranded vehicles.\n\nNearly all government buildings, schools, and public facilities were closed for February 2, 2011 in the southeastern region of the state, including Milwaukee, Waukesha, Racine, Kenosha, Sheboygan, and Madison, with Racine and Kenosha receiving the largest amount of snow, just shy of 24 inches. Three people died of cardiac-related illnesses while clearing snow in Milwaukee.\n\nStrong gale-force winds were expected in many areas, especially places northwest of the Appalachian Mountains. A storm warning for the entirety of Lake Michigan went up on 1 February, replacing an existing gale warning. Sustained winds of 39 to 55 mph and gusts to 70 mph or higher were reported over portions of Illinois, Wisconsin, and Lake Michigan for several hours at the height of the storm according to the National Weather Service.\n\nParts of Texas and Louisiana east to the Mississippi Valley and Florida Panhandle experienced or were to experience rapid drops in temperature and flash freeze events after the squall line moved through.\n\nLocalized flooding occurred in northeastern Illinois, near the coast of Lake Michigan where strong winds brought storm surge and lakeshore flooding.\n\nSevere thunderstorms erupted in many areas of the Midwest and Southeastern United States. Thunderstorms accompanied both heavy rain and snow. Tornadoes were reported in Texas, and a tornado watch was issued for parts of Alabama. An EF1 tornado damaged two homes in Rusk County, Texas.\n\nLocal governments ahead of the storm prepared residents on procedures to follow during the storm. This included parking and driving restrictions and preparation of road clearing equipment. Street clearing crews applied chemicals to the roadways to pre-melt ice and snow and checked equipment prior to the event.\n\nA state of emergency was declared in several American states, including Illinois, Oklahoma, and Missouri.\n\nAt least 6,400 flight cancellations occurred across North America before the storm. Impact was severe at Chicago's O'Hare International Airport, as over 1,100 flights were canceled there. A less severe but still a major impact was at Toronto Pearson International Airport in Toronto where about 300 of its 1,400 daily flights were canceled.\n\nBy the end of February 2, at least 13,000 individual flight cancellations had taken place across North America.\n\nMany local and widespread power outages affected locations along the storm track, including in Illinois, Ohio, Oklahoma, New Mexico, Indiana, Texas, Colorado and Kentucky.\n\nThe storm affected the Dallas, Texas area, bringing a coating of ice to the ground after a rapid freeze. This caused some damage ahead of Super Bowl XLV. Snow falling from the roof of Cowboys Stadium caused several injuries.\n\n\n"}
{"id": "19450817", "url": "https://en.wikipedia.org/wiki?curid=19450817", "title": "Kaiwera Downs Wind Farm", "text": "Kaiwera Downs Wind Farm\n\nThe Kaiwera Downs Wind Farm is a proposed wind farm to be located in the Southland region of New Zealand. It is expected to have a maximum capacity of 240MW and use up 83 turbines. It will be owned and operated by Tilt Renewables.\n\nThe project received resource consent in June 2008.\n\nThe wind farm will be about 15 kilometres south-east of Gore, within an area of .\n\n"}
{"id": "55583736", "url": "https://en.wikipedia.org/wiki?curid=55583736", "title": "Kudurru for Šitti-Marduk", "text": "Kudurru for Šitti-Marduk\n\nThe Kudurru for Šitti-Marduk is a white limestone boundary stone (Kudurru) of Nebuchadrezzar I, a king of the 2nd Dynasty of Isin, ca. the late 12th century BC. He is known to have made at least four kudurru boundary stones.\n\nSome kudurrus are known for their representations of the king, etc, who conscripted the stones production. Most kudurrus are attested by honored gods of Mesopotamia and are often displayed graphically in segmented registers on the stone.\n\nThe obverse of the \"Kudurru for Šitti-Marduk\" is composed of six registers, with gods, beings (a Scorpion man for example), etc. The recto contains cuneiform text, relating the military services of Šitti-Marduk.\n\n\n"}
{"id": "366603", "url": "https://en.wikipedia.org/wiki?curid=366603", "title": "Lake Natron", "text": "Lake Natron\n\nLake Natron is a salt and soda lake in Arusha Region in northern Tanzania. It is in the Gregory Rift, which is the eastern branch of the East African Rift. The lake is within the Lake Natron Basin, a Ramsar Site wetland of international significance.\nThe lake is fed principally by the Southern Ewaso Ng'iro River, which rises in central Kenya, and by mineral-rich hot springs. It is quite shallow, less than deep, and varies in width depending on its water level. The lake is a maximum of long and wide. The surrounding area receives irregular seasonal rainfall, mainly between December and May totalling per year. Temperatures at the lake are frequently above .\n\nHigh levels of evaporation have left behind natron (sodium carbonate decahydrate) and trona (sodium sesquicarbonate dihydrate). The alkalinity of the lake can reach a pH of greater than 12. The surrounding bedrock is composed of alkaline, sodium-dominated trachyte lavas that were laid down during the Pleistocene period. The lavas have significant amounts of carbonate but very low calcium and magnesium levels. This has allowed the lake to concentrate into a caustic alkaline brine.\n\nThe color of the lake is characteristic of those where very high evaporation rates occur. As water evaporates during the dry season, salinity levels increase to the point that salt-loving microorganisms begin to thrive. Such halophile organisms include some cyanobacteria that make their own food with photosynthesis as plants do. The red accessory photosynthesizing pigment in the cyanobacteria produces the deep reds of the open water of the lake and the orange colors of the shallow parts of the lake. The alkali salt crust on the surface of the lake is also often colored red or pink by the salt-loving microorganisms that live there.\nSalt marshes and freshwater wetlands around the edges of the lake do support a variety of plants.\n\nMost animals find the lake's high temperature (up to 60 °C) and its high and variable salt content inhospitable. Nonetheless, Lake Natron is home to some endemic algae, invertebrates, and birds. In the slightly less salty water around its margins, some fish can also survive.\n\nThe lake is the only regular breeding area in East Africa for the 2.5 million lesser flamingoes, whose status of \"near threatened\" results from their dependence on this one location. When salinity increases, so do cyanobacteria, and the lake can also support more nests. These flamingoes, the single large flock in East Africa, gather along nearby saline lakes to feed on \"Spirulina\" (a blue-green algae with red pigments). Lake Natron is a safe breeding location because its caustic environment is a barrier against predators trying to reach their nests on seasonally forming evaporite islands. Greater flamingoes also breed on the mud flats.\n\nThe lake has inspired the nature documentary by Disneynature, for its close relationship with the lesser flamingoes as their only regular breeding area.\n\nTwo endemic fish species, the alkaline tilapias \"Alcolapia latilabris\" and \"A. ndalalani\", also thrive in the waters at the edges of the hot spring inlets. \"A. alcalica\" is also present in the lake, but is not endemic.\n\nThe area around the salt lake is not inhabited but there is some herding and some seasonal cultivation. Threats to the salinity balance from increased siltation influxes will come from more projected logging in Natron watersheds and a planned hydroelectric power plant on the Ewaso Ng'iro across the border in Kenya. Although development plans include construction of a dike at the north end of the lake to contain the freshwater, the threat of dilution to this breeding ground may still be serious. There is no formal protection.\n\nA new threat to Lake Natron is the proposed development of a soda ash plant on its shores. The plant would pump water from the lake and extract the sodium carbonate to convert to washing powder for export. Accompanying the plant would be housing for over 1000 workers, and a coal-fired power station to provide energy for the plant complex. In addition, there is a possibility the developers may introduce a hybrid brine shrimp to increase the efficiency of extraction.\nAccording to Chris Magin, the RSPB's international officer for Africa, \"The chance of the lesser flamingoes continuing to breed in the face of such mayhem are next to zero. This development will leave lesser flamingoes in East Africa facing extinction\". Seventy-five percent of the world's lesser flamingoes are born on Lake Natron. Currently a group of more than fifty East African conservation and environmental institutions are running a worldwide campaign to stop the planned construction of the soda ash factory by Tata Chemicals Ltd of Mumbai, India and National Development Corporation of Tanzania. The group working under the umbrella name Lake Natron Consultative Group is being co-ordinated by Ken Mwathe, Conservation Programme Manager at BirdLife International's Africa Secretariat.\n\nAs per communication on June 2008, Tata Chemicals shall not proceed with the Natron Project and further re-examination of this project will be subject to the Ramsar Wetlands plan, which is currently under preparation.\n\nBecause of its unique biodiversity, Tanzania named the Lake Natron Basin to the Ramsar List of Wetlands of International Importance on 4 July 2001. The lake is also the World Wildlife Fund East African halophytics ecoregion.\n\nThere are a number of campgrounds near the lake, which is also the base for climbing Ol Doinyo Lengai.\n\n\n"}
{"id": "11830536", "url": "https://en.wikipedia.org/wiki?curid=11830536", "title": "Line regulation", "text": "Line regulation\n\nLine regulation is the ability to maintain a constant output voltage level on the output channel of a power supply despite changes to the input voltage level.\n\n"}
{"id": "23920468", "url": "https://en.wikipedia.org/wiki?curid=23920468", "title": "List of software for nanostructures modeling", "text": "List of software for nanostructures modeling\n\nThis is a list of computer programs that are used to model nanostructures at the levels of classical mechanics and quantum mechanics.\n\n"}
{"id": "1286190", "url": "https://en.wikipedia.org/wiki?curid=1286190", "title": "Lithium chloride", "text": "Lithium chloride\n\nLithium chloride is a chemical compound with the formula LiCl. The salt is a typical ionic compound, although the small size of the Li ion gives rise to properties not seen for other alkali metal chlorides, such as extraordinary solubility in polar solvents (83.05 g/100 mL of water at 20 °C) and its hygroscopic properties.\n\nThe salt forms crystalline hydrates, unlike the other alkali metal chlorides. Mono-, tri-, and pentahydrates are known. The anhydrous salt can be regenerated by heating the hydrates. Molten LiCl hydrolyzes to give LiOH and HCl.\nLiCl also absorbs up to four equivalents of ammonia/mol. As with any other ionic chloride, solutions of lithium chloride can serve as a source of chloride ion, e.g., forming a precipitate upon treatment with silver nitrate:\n\nLithium chloride is produced by treatment of lithium carbonate with hydrochloric acid. It can in principle also be generated by the highly exothermic reaction of lithium metal with either chlorine or anhydrous hydrogen chloride gas. Anhydrous LiCl is prepared from the hydrate by heating with a stream of hydrogen chloride.\n\nLithium chloride is mainly used for the production of lithium metal by electrolysis of a LiCl/KCl melt at . LiCl is also used as a brazing flux for aluminium in automobile parts. It is used as a desiccant for drying air streams. In more specialized applications, lithium chloride finds some use in organic synthesis, e.g., as an additive in the Stille reaction. Also, in biochemical applications, it can be used to precipitate RNA from cellular extracts.\n\nLithium chloride is also used as a flame colorant to produce dark red flames.\n\nLithium chloride is used as a relative humidity standard in the calibration of hygrometers. At a saturated solution (45.8%) of the salt will yield an equilibrium relative humidity of 11.30%. Additionally, lithium chloride can itself be used as a hygrometer. This deliquescent salt forms a self-solution when exposed to air. The equilibrium LiCl concentration in the resulting solution is directly related to the relative humidity of the air. The percent relative humidity at can be estimated, with minimal error in the range , from the following first order equation: RH=107.93-2.11C, where C is solution LiCl concentration, percent by mass.\n\nMolten LiCl is used for the preparation of carbon nanotubes, graphene and lithium niobate.\n\nLithium chloride has been shown to have strong acaricidal properties, being effective against \"Varroa destructor\" in populations of honey bees.\n\nLithium salts affect the central nervous system in a variety of ways. While the citrate, carbonate, and orotate salts are currently used to treat bipolar disorder, other lithium salts including the chloride were used in the past. For a short time in the 1940s lithium chloride was manufactured as a salt substitute, but this was prohibited after the toxic effects of the compound were recognized.\n\n\n"}
{"id": "12025885", "url": "https://en.wikipedia.org/wiki?curid=12025885", "title": "Manx Electricity Authority", "text": "Manx Electricity Authority\n\nThe Manx Electricity Authority () was a Statutory Board of the Isle of Man Government which generated and supplied electricity for the Isle of Man. In 2014 it became part of the Manx Utilities Authority when it was merged with the Isle of Man Water and Sewerage Authority.\n\nElectricity generation is provided on the island from the following sources\n\nIn addition there is also the Isle of Man to England Interconnector, an AC submarine power cable connecting the transmission system of the Isle of Man to that of Great Britain.\n\n\n"}
{"id": "8993488", "url": "https://en.wikipedia.org/wiki?curid=8993488", "title": "Maritime coast range ponderosa pine forest", "text": "Maritime coast range ponderosa pine forest\n\nThe maritime coast range ponderosa pine forests are rare temperate forest assemblages associated with a limited range portion of the Santa Cruz Mountains of northern California. There are only three known small forests of this type, all situated in Santa Cruz County, California. The dominant tree species is the ponderosa pine. \n\nThis sparse forest type thrives on very sandy Zayante soils that are isolated pockets of decomposing sandstone from the Miocene terraces of the coastal range. These forests are deemed to be relicts of once larger expanses found when this region was geologically even younger, and hence had more evidence of the sandstone erosion of the ancient uplifted ocean floor. \n\nOne of these three forests is located atop a ridge that straddles the Carbonera Creek and Zayante Creek watersheds of Santa Cruz County, California within the western slopes of the Santa Cruz Mountains. \n\nThe forest in the Carbonera Creek watershed is also home to two endemic insects whose narrow range is closely associated with the maritime coast range ponderosa pine forests.\n\n\n"}
{"id": "52999446", "url": "https://en.wikipedia.org/wiki?curid=52999446", "title": "Mızıkçam", "text": "Mızıkçam\n\nMızıkçam is an old pine tree in Kütahya Province, western Turkey. It is a registered natural monument of the country.\n\nMızıkçam is located at Domurköy village of Domaniç district in Kütahya Province. It is a black pine (\"Pinus nigra\"). Its age is dated to be more than 700 years old. The tree was registered a natural monument on July 12, 1993. The protected area of the plant covers .\n"}
{"id": "43660225", "url": "https://en.wikipedia.org/wiki?curid=43660225", "title": "NASA GL-10 Greased Lightning", "text": "NASA GL-10 Greased Lightning\n\nThe GL-10 Greased Lightning is a hybrid diesel-electric tiltwing aircraft.\n\nThe wing has eight electric motor driven propellers while the horizontal stabilizer has two. In the future full-scale version, power will be generated by two 6 kW (8 hp) diesel engines which will charge lithium ion batteries. The propellers on the leading edge of the wing provide high speed flow, and thus lift, on the wing even in low forward velocity flight allowing pitch, roll, and yaw control authority during the critical transition phase from hover to forward flight.\n\nThe VTOL capability of this new class of UAV eliminates the requirement for additional ground support equipment like launch catapults and landing catch mechanisms. In addition, the propellers are designed for a relatively low tip speed resulting in a marked reduction in noise. The aircraft is designed to complete several vertical take-off and landings during its mission with a loiter endurance of 24 hours in the forward flight mode. The GL-10 performed transitions between vertical and horizontal flight in 2015.\n\n"}
{"id": "16327970", "url": "https://en.wikipedia.org/wiki?curid=16327970", "title": "Northwest Regional Development Agency", "text": "Northwest Regional Development Agency\n\nThe Northwest Regional Development Agency (NWDA) was the regional development agency for the North West England region and was a non-departmental public body. It was abolished on 31 March 2012.\n\nThe Agency was responsible for the economic development and regeneration of the Northwest of England. As a business-led organisation, the NWDA provided a link between the needs of businesses and Government policies. As such, a major responsibility for the Agency was to help create an environment in which businesses in the region could flourish through offering business support, encouraging new start-ups, matching skills provision to employer needs and bringing business investment into the region. \n\nThe Agency funded or managed a series of financial support products for businesses in the region. \n\nGeographically, the Agency covered Greater Manchester including Manchester and Salford, Merseyside including Liverpool, Cheshire and Warrington, Cumbria, including the Lake District and Lancashire including Preston. It operated from its main offices in Warrington, with additional offices in Liverpool, Manchester, Preston and Penrith. \n\nThe Agency was one of the principal players in the creation of MediaCityUK in Salford Quays, home for a number relocated BBC Departments, as well as a major creative and digital village in its own right. It was also playing a strong role in the development of The Waterfront Barrow-in-Furness.\n\nThe NWDA was funded by central Government and responsible to the Department for Business, Innovation and Skills. \n"}
{"id": "34824850", "url": "https://en.wikipedia.org/wiki?curid=34824850", "title": "Placzek transient", "text": "Placzek transient\n\nThe Placzek transient is a phenomenon studied in nuclear engineering. The Placzek transient occurs when a population of monoenergetic neutrons of energy E elastically scatter within a homogeneous medium. In each collision the neutrons impart a fraction of their energy to the nuclei in the medium, losing up to a maximum of\n\nwhere A is the atomic number of the medium. In nuclear engineering, neutrons that have not yet undergone a collision are called the 1st generation, those that have undergone a single collision are the 2nd generation, those that have undergone two collisions are the 3rd generation, and so on. The neutrons from each generation collectively form the total neutron population within the medium.\n\nThe Placzek transient is a discontinuity of the neutron flux, and derivatives of the flux, at integer multiples of formula_3. The transient results from the fact that after the 1st generation, every neutron can have at minimum an energy of formula_4 due to elastic scattering. Those neutrons that have energy less than formula_5 can only consist of neutrons in the 2nd, 3rd, or latter generations. This trend repeats itself at each multiple of formula_3. Thus, the discontinuity in the flux arises from the fact that at each multiple of formula_3 the neutron flux is accumulated from one fewer neutron generation to the left of the discontinuity than to the right.\n\nThe Placzek transient can be derived analytically by solving for the neutron flux using a piecewise function solution to a differential equation involving a Heaviside step function in energy intervals of width formula_8. The transient can also be observed in some special case Monte Carlo neutron transport simulation codes.\n"}
{"id": "884897", "url": "https://en.wikipedia.org/wiki?curid=884897", "title": "Polyimide", "text": "Polyimide\n\nPolyimide (sometimes abbreviated PI) is a polymer of imide monomers. Polyimides have been in mass production since 1955. With their high heat-resistance, polyimides enjoy diverse applications in roles demanding rugged organic materials, e.g. high temperature fuel cells, displays, and various military roles. A classic polyimide is Kapton, which is produced by condensation of pyromellitic dianhydride and 4,4'-oxydianiline.\n\nAccording to the composition of their main chain, polyimides can be:\n\nAccording to the type of interactions between the main chains, polyimides can be:\n\nSeveral methods are possible to prepare polyimides, among them:\nDianhydrides used as precursors to these materials include pyromellitic dianhydride, benzoquinonetetracarboxylic dianhydride and naphthalene tetracarboxylic dianhydride. Common diamine building blocks include 4,4'-diaminodiphenyl ether (\"DAPE\"), meta-phenylenediamine (\"MDA\"), and 3,3-diaminodiphenylmethane. Hundreds of diamines and dianhydrides have been examined to tune the physical and especially the processing properties of these materials. These materials tend to be insoluble and have high softening temperatures, arising from charge-transfer interactions between the planar subunits.\n\nThermosetting polyimides are known for thermal stability, good chemical resistance, excellent mechanical properties, and characteristic orange/yellow color. Polyimides compounded with graphite or glass fiber reinforcements have flexural strengths of up to and flexural moduli of . Thermoset polymer matrix polyimides exhibit very low creep and high tensile strength. These properties are maintained during continuous use to temperatures of up to and for short excursions, as high as . Molded polyimide parts and laminates have very good heat resistance. Normal operating temperatures for such parts and laminates range from cryogenic to those exceeding . Polyimides are also inherently resistant to flame combustion and do not usually need to be mixed with flame retardants. Most carry a UL rating of VTM-0. Polyimide laminates have a flexural strength half life at of 400 hours.\n\nTypical polyimide parts are not affected by commonly used solvents and oils — including hydrocarbons, esters, ethers, alcohols and freons. They also resist weak acids but are not recommended for use in environments that contain alkalis or inorganic acids. Some polyimides, such as CP1 and CORIN XLS, are solvent-soluble and exhibit high optical clarity. The solubility properties lend them towards spray and low temperature cure applications.\n\nPolyimide materials are lightweight, flexible, resistant to heat and chemicals. Therefore, they are used in the electronics industry for flexible cables and as an insulating film on magnet wire. For example, in a laptop computer, the cable that connects the main logic board to the display (which must flex every time the laptop is opened or closed) is often a polyimide base with copper conductors. Examples of polyimide films include Apical, Kapton, UPILEX, VTEC PI, Norton TH and Kaptrex.\nPolyimide is used to coat optical fibers for medical or high temperature applications.\n\nAn additional use of polyimide resin is as an insulating and passivation layer in the manufacture of digital semiconductor and MEMS chips. The polyimide layers have good mechanical elongation and tensile strength, which also helps the adhesion between the polyimide layers or between polyimide layer and deposited metal layer. The minimum interaction between the gold film and the polyimide film, coupled with high temperature stability of the polyimide film, results in a system that provides reliable insulation when subjected to various types of environmental stresses.\n\nMulti-layer insulation used on spacecraft is usually made of polyimide coated with thin layers of aluminum. The gold-like material often seen on the outside of spacecraft is actually single aluminized polyimide, with the single layer of aluminum facing in. The yellowish-brown polyimide gives the surface its gold-like color.\n\nPolyimide powder can be used to produce parts and shapes by sintering technologies (hot compression molding, direct forming, and isostatic pressing). Because of their high mechanical stability even at elevated temperatures they are used as bushings, bearings, sockets or constructive parts in demanding applications. To improve tribological properties, compounds with solid lubricants like graphite, PTFE, or molybdenum sulfide are common. Polyimide parts and shapes include P84 NT, VTEC PI, Meldin, Vespel, and Plavis.\n\nIn coal-fired power plants, waste incinerators, or cement plants, polyimide fibres are used to filter hot gases. In this application, a polyimide needle felt separates dust and particulate matter from the exhaust gas.\n\nPolyimide is also the most common material used for the reverse osmotic film in purification of water, or the concentration of dilute materials from water, such as maple syrup production.\n\nPolyimide is used for medical tubing, e.g. vascular catheters, for its burst pressure resistance combined with flexibility and chemical resistance.\n\nThe semiconductor industry uses polyimide as a high-temperature adhesive; it is also used as a mechanical stress buffer. \n\nSome polyimide can be used like a photoresist; both \"positive\" and \"negative\" types of photoresist-like polyimide exist in the market.\n\nThe IKAROS solar sailing spacecraft uses polyimide resin sails to operate without rocket engines.\n\n\n\n"}
{"id": "26466899", "url": "https://en.wikipedia.org/wiki?curid=26466899", "title": "Simulated Electronic Launch Minuteman", "text": "Simulated Electronic Launch Minuteman\n\nSimulated Electronic Launch Minuteman (SELM) is a method used by the United States Air Force to verify the reliability of the LGM-30 Minuteman intercontinental ballistic missile. SELM replaces key components at the Launch Control Center to allow a physical \"keyturn\" by missile combat crew members. This test allows end-to-end verification in the ICBM launch process.\n\nThe Air Force Nuclear Weapons Center, Intercontinental Ballistic Missile (ICBM) Systems Directorate at Hill AFB, Utah provides technical support to SELM tests The information obtained from tests provide a complete assessment of the weapon systems for Air Force Global Strike Command (AFGSC).\n\n\n"}
{"id": "22940609", "url": "https://en.wikipedia.org/wiki?curid=22940609", "title": "Soil gas", "text": "Soil gas\n\nSoil gases are the gases found in the air space between soil components. The primary soil gases include nitrogen, carbon dioxide and oxygen. The oxygen is critical because it allows for respiration of both plant roots and soil organisms. Other natural soil gases are atmospheric methane and radon. Some environmental contaminants below ground produce gas which diffuses through the soil such as from landfill wastes, mining activities, and contamination by petroleum hydrocarbons which produce volatile organic compounds. Soil gases can diffuse into buildings, the chief concerns among these pollutants are radon which is radioactive and causes cancer and methane which can be flammable at only 4.4% concentration.\n\nGases fill soil pores in the soil structure as water drains or is removed from a soil pore by evaporation or root absorption. The network of pores within the soil aerates, or ventilates, the soil. This aeration network becomes blocked when water enters soil pores. Not only are both soil air and soil water very dynamic parts of soil, but both are often inversely related.\n\nComposition of air in soil and atmosphere:\n\nGas molecules in soil are in continuous thermal motion according to the kinetic theory of gases, there is also collision between molecules - a random walk.\n\nIn soil, a concentration gradient causes net movement of molecules from high concentration to low concentration, this gives the movement of gas by diffusion. Numerically, it is explained by Fick's law of diffusion.\n"}
{"id": "31908310", "url": "https://en.wikipedia.org/wiki?curid=31908310", "title": "Source London", "text": "Source London\n\nSource London is a network of electric vehicle charging points in London. It is owned by IER.\n\nCharging points are located in residential streets, public car parks, at supermarkets, shopping centres and similar places. Use of a Source London branded charging point requires registration with the network's website and the payment of an annual fee of £48 per vehicle. Users are required to pay the annual subscription (also payable in monthly instalments of £4/month) along with 3.6p/min for each charging session on their modern chargers. Registered members are issued with a card that is swiped on the charging point's card reader to permit charging an unlimited number of times.\n\nFirst announced in November 2010 and launched on 27 May 2011 by London Mayor Boris Johnson, it is the first citywide network in London and initially provides 150 charging points across the capital with plans to expand coverage to 1,300 charging points by 2013.\n\nSource London was originally a Transport for London-led consortium of public and private sector organizations. The IT infrastructure was developed by Siemens and the network is partly funded by Scottish and Southern Energy and National Car Parks. Other organisations involved include Heathrow Airport, Gatwick Airport, Asda, Capital Shopping Centres, Sainsbury's, IKEA, Whittington Hospital, Enterprise Rent-a-Car and London Underground. The Department for Transport provided £9.3 million 50% match funding for the development of the network's infrastructure. The subscription fee for the scheme was originally an annual flat-rate £10 per vehicle, with no per-charge fees.\n\nIER have taken over the management of the Source London charging network from Transport for London, since 1 September 2014. Most of the actual charge points are still owned by the boroughs and business owners, and it is still their responsibility to fix faults.\n\nThe expansion of the network will be achieved, in part, by integrating existing charging points previously operated independently by London Borough councils. At launch, 11 boroughs had installed or were planning to install Source London charging points, or were intending to upgrade their own charging points for integration into the network. Ten other boroughs had committed to the network.\n\nSource London is working with the Department for Transport's Office for Low Emission Vehicles and cities in the UK with the aim of developing a national charging point network.\n\nIn 2014 it was reported that Source London's network, formed by taking on operational responsibility for various borough's chargepoints, had problems with chargepoints being out of action. Source London says it has been working with individual boroughs to take full ownership and responsibility of the existing charging infrastructure, and has so far agreed with London Boroughs of Barnet, Brent, Bromley, Camden, Greenwich, Hackney, Hammersmith and Fulham, Hounslow, Islington, Kensington and Chelsea, Merton, Richmond, Southwark, Sutton, Wandsworth, Westminster, and with TfL.\n\n"}
{"id": "689767", "url": "https://en.wikipedia.org/wiki?curid=689767", "title": "Spherical pendulum", "text": "Spherical pendulum\n\nIn physics, a spherical pendulum is a higher dimensional analogue of the pendulum. It consists of a mass \"m\" moving without friction on the surface of a sphere. The only forces acting on the mass are the reaction from the sphere and gravity.\n\nOwing to the spherical geometry of the problem, spherical coordinates are used to describe the position of the mass in terms of (\"r\", \"θ\", \"φ\"), where \"r\" is fixed. In what follows \"l\" is the constant length of the pendulum, so \"r\" = \"l\".\n\nThe Lagrangian is \n\nThe Euler–Lagrange equations give :\n\nand\nshowing that angular momentum is conserved.\n\nThe Hamiltonian is\n\nwhere\n\nand\n\n"}
{"id": "4936560", "url": "https://en.wikipedia.org/wiki?curid=4936560", "title": "Standard Market Design", "text": "Standard Market Design\n\nEstablished by the Federal Energy Regulatory Commission, Standard Market Design is a set of established guidelines governing the sale of electrical power and the operations of electrical transmission lines in the United States of America.\n\nThe objective of standard market design for wholesale electric markets is to establish a common market framework that promotes economic efficiency and lower delivered energy costs, maintains power system reliability, mitigates significant market power and increases the choices offered to wholesale market participants. All customers should benefit from an efficient competitive wholesale energy market, whether or not they are in states that have elected to adopt retail access.\n"}
{"id": "4232812", "url": "https://en.wikipedia.org/wiki?curid=4232812", "title": "Terracette", "text": "Terracette\n\nEarly investigators believed that animals grazing the hillsides caused them, but further examination revealed places where terracettes abruptly ended at steep rock faces or at soils of different composition. Other sites show livestock trails cutting across terracettes. The conclusion is that although animals may accentuate them, they are not the cause.\n\n\n"}
{"id": "587271", "url": "https://en.wikipedia.org/wiki?curid=587271", "title": "Torsion spring", "text": "Torsion spring\n\nA torsion spring is a spring that works by torsion or twisting; that is, a flexible elastic object that stores mechanical energy when it is twisted. When it is twisted, it exerts a force (actually torque) in the opposite direction, proportional to the amount (angle) it is twisted. There are various types. For example, clocks use a spiral wound torsion spring sometimes called a \"clock spring\" or colloquially called a mainspring. Those types of torsion springs are also used for attic stairs, clutches, and other devices that need near constant torque for large angles or even multiple revolutions.\n\nA torsion bar is a straight bar of metal or rubber that is subjected to twisting (shear stress) about its axis by torque applied at its ends. A more delicate form used in sensitive instruments, called a torsion fiber consists of a fiber of silk, glass, or quartz under tension, that is twisted about its axis. The other type, a helical torsion spring, is a metal rod or wire in the shape of a helix (coil) that is subjected to twisting about the axis of the coil by sideways forces (bending moments) applied to its ends, twisting the coil tighter. This terminology can be confusing because in a helical torsion spring the forces acting on the wire are actually bending stresses, not torsional (shear) stresses.\nAs long as they are not twisted beyond their elastic limit, torsion springs obey an angular form of Hooke's law:\n\nwhere formula_2 is the torque exerted by the spring in newton-meters, and formula_3 is the angle of twist from its equilibrium position in radians. formula_4 is a constant with units of newton-meters / radian, variously called the spring's torsion coefficient, torsion elastic modulus, rate, or just spring constant, equal to the change in torque required to twist the spring through an angle of 1 radian. It is analogous to the spring constant of a linear spring. The negative sign indicates that the direction of the torque is opposite to the direction of twist.\n\nThe energy \"U\", in joules, stored in a torsion spring is:\n\nSome familiar examples of uses are the strong, helical torsion springs that operate clothespins and traditional spring-loaded-bar type mousetraps. Other uses are in the large, coiled torsion springs used to counterbalance the weight of garage doors, and a similar system is used to assist in opening the trunk (boot) cover on some sedans. Small, coiled torsion springs are often used to operate pop-up doors found on small consumer goods like digital cameras and compact disc players. Other more specific uses:\n\n\nThe torsion balance, also called torsion pendulum, is a scientific apparatus for measuring very weak forces, usually credited to Charles-Augustin de Coulomb, who invented it in 1777, but independently invented by John Michell sometime before 1783. Its most well-known uses were by Coulomb to measure the electrostatic force between charges to establish Coulomb's Law, and by Henry Cavendish in 1798 in the Cavendish experiment to measure the gravitational force between two masses to calculate the density of the Earth, leading later to a value for the gravitational constant.\n\nThe torsion balance consists of a bar suspended from its middle by a thin fiber. The fiber acts as a very weak torsion spring. If an unknown force is applied at right angles to the ends of the bar, the bar will rotate, twisting the fiber, until it reaches an equilibrium where the twisting force or torque of the fiber balances the applied force. Then the magnitude of the force is proportional to the angle of the bar. The sensitivity of the instrument comes from the weak spring constant of the fiber, so a very weak force causes a large rotation of the bar.\n\nIn Coulomb's experiment, the torsion balance was an insulating rod with a metal-coated ball attached to one end, suspended by a silk thread. The ball was charged with a known charge of static electricity, and a second charged ball of the same polarity was brought near it. The two charged balls repelled one another, twisting the fiber through a certain angle, which could be read from a scale on the instrument. By knowing how much force it took to twist the fiber through a given angle, Coulomb was able to calculate the force between the balls. Determining the force for different charges and different separations between the balls, he showed that it followed an inverse-square proportionality law, now known as Coulomb's law.\n\nTo measure the unknown force, the spring constant of the torsion fiber must first be known. This is difficult to measure directly because of the smallness of the force. Cavendish accomplished this by a method widely used since: measuring the resonant vibration period of the balance. If the free balance is twisted and released, it will oscillate slowly clockwise and counterclockwise as a harmonic oscillator, at a frequency that depends on the moment of inertia of the beam and the elasticity of the fiber. Since the inertia of the beam can be found from its mass, the spring constant can be calculated.\n\nCoulomb first developed the theory of torsion fibers and the torsion balance in his 1785 memoir, \"Recherches theoriques et experimentales sur la force de torsion et sur l'elasticite des fils de metal &c\". This led to its use in other scientific instruments, such as galvanometers, and the Nichols radiometer which measured the radiation pressure of light. In the early 1900s gravitational torsion balances were used in petroleum prospecting. Today torsion balances are still used in physics experiments. In 1987, gravity researcher A.H. Cook wrote:\n\nThe most important advance in experiments on gravitation and other delicate measurements was the introduction of the torsion balance by Michell and its use by Cavendish. It has been the basis of all the most significant experiments on gravitation ever since.\n\nTorsion balances, torsion pendulums and balance wheels are examples of torsional harmonic oscillators that can oscillate with a rotational motion about the axis of the torsion spring, clockwise and counterclockwise, in harmonic motion. Their behavior is analogous to translational spring-mass oscillators (see Harmonic oscillator#Equivalent systems). The general equation of motion is:\n\nIf the damping is small, formula_7, as is the case with torsion pendulums and balance wheels, the frequency of vibration is very near the natural resonant frequency of the system:\n\nTherefore, the period is represented by:\n\nThe general solution in the case of no drive force (formula_10), called the transient solution, is:\n\nwhere:\n\nThe balance wheel of a mechanical watch is a harmonic oscillator whose resonant frequency formula_14 sets the rate of the watch. The resonant frequency is regulated, first coarsely by adjusting formula_15 with weight screws set radially into the rim of the wheel, and then more finely by adjusting formula_4 with a regulating lever that changes the length of the balance spring.\n\nIn a torsion balance the drive torque is constant and equal to the unknown force to be measured formula_17, times the moment arm of the balance beam formula_18, so formula_19. When the oscillatory motion of the balance dies out, the deflection will be proportional to the force:\n\nTo determine formula_17 it is necessary to find the torsion spring constant formula_4. If the damping is low, this can be obtained by measuring the natural resonant frequency of the balance, since the moment of inertia of the balance can usually be calculated from its geometry, so:\n\nIn measuring instruments, such as the D'Arsonval ammeter movement, it is often desired that the oscillatory motion die out quickly so the steady state result can be read off. This is accomplished by adding damping to the system, often by attaching a vane that rotates in a fluid such as air or water (this is why magnetic compasses are filled with fluid). The value of damping that causes the oscillatory motion to settle quickest is called the critical damping formula_24:\n\n\n\n"}
{"id": "20763176", "url": "https://en.wikipedia.org/wiki?curid=20763176", "title": "Turtle Wax", "text": "Turtle Wax\n\nTurtle Wax is a manufacturer of automotive appearance products. The company was founded by Benjamin Hirsch in Chicago in 1941 and is currently headquartered in Addison, Illinois, having relocated from Willowbrook, Illinois in 2016.\n\nHirsch's main product, a liquid car wax, was initially called Plastone, until Hirsch changed the product name to create the association with a turtle's hard shell. Hirsch died in 1966 and successive generations of his family have remained involved with the company. Its advertising jingle (\"Turtle Wax gives that hard shell finish\"), created early in its history by the Doner Company, became very well known.\n\nTurtle Wax is the largest automotive appearance products company in the world and distributes its products in more than 90 countries.\n\nThe company's primary product lines include cleaning and polishing products for cars including glass, painted surfaces, uncoated metals, leather, wheels, and tires. As of 2017, Turtle Wax primarily serves the retail consumer market; the company sold its Professional Products arm focused on professional detailer and commercial car wash customers to Cambridge, Ontario based Transchem Inc. in 2013. Turtle Wax has marketed its cleaning products for non-automotive applications, as well.\n\nTurtle Wax also offers automotive performance chemicals such as engine treatment products and formula oils under the Marvel Mystery Oil and CD-2 brands. Additionally, the company operates full-service car wash facilities in the Chicago Metropolitan area.\n\n"}
{"id": "11421569", "url": "https://en.wikipedia.org/wiki?curid=11421569", "title": "UNGG reactor", "text": "UNGG reactor\n\nThe UNGG (\"Uranium Naturel Graphite Gaz\") is an obsolete nuclear power reactor design developed by France. It was graphite moderated, cooled by carbon dioxide, and fueled with natural uranium metal. The first generation of French nuclear power stations were UNGGs, as was Vandellos unit 1 in Spain. Of ten units built, all were shut down by end 1994, most for economic reasons due to staffing costs.\n\nThe UNGG and the Magnox are the two main types of gas cooled reactor (GCR). A UNGG reactor is often referred to simply as a \"GCR\" in English documents, or sometimes loosely as a \"Magnox\". It was developed independently of and in parallel to the British Magnox design, and to meet similar requirements. The first UNGG reactors at Marcoule used horizontal fuel channels and a concrete containment structure. Chinon A1 used vertical fuel channels, as did the British Magnox reactors, and a steel pressure-vessel.\n\nThe fuel cladding material was magnesium-zirconium alloy in the UNGG, as opposed to magnesium-aluminium in Magnox. As both claddings react with water, they can be stored in a spent fuel pool for short times only, making short-term reprocessing of the fuel essential, and requiring heavily shielded facilities for this.\n\nThe programme was a succession of units, with changes to the design increasing power output. In the experimental phase they were built by the Commissariat à l'Énergie Atomique (CEA), and later by Électricité de France (EDF). The largest UNGG reactor build was Bugey 1 with a net electrical output of 540 MW.\n\n\nThe earlier units, at Chinon and Marcoule, had heat exchangers outside the main pressure vessel; Later units (Saint-Laurent, Bugey and Vandellos) moved these heat exchangers to inside the pressure vessel.\n\n\n"}
{"id": "9542135", "url": "https://en.wikipedia.org/wiki?curid=9542135", "title": "Westminster Stone theory", "text": "Westminster Stone theory\n\nThe Westminster Stone theory refers to the belief held by some historians and scholars that the stone which traditionally rests under the Coronation Chair is not the true Stone of Destiny but a 13th-century substitute. Since the chair has been located in Westminster Abbey since that time, adherents to this theory have created the title 'Westminster Stone' to avoid confusion with the 'real' stone (sometimes referred to as the Stone of Scone).\n\nOne of the most vocal proponents of this theory was writer and historian Nigel Tranter, who consistently presented the theory throughout his non-fiction books and historical novels. Other historians have held this view, including James S. Richardson, who was an Inspector of Ancient Monuments in the mid-twentieth century. Richardson produced a monograph on the subject.\n\nThe Stone of Destiny was the traditional Coronation Stone of the Kings of Scotland and, before that, the Kings of Dalriada. Legends associate it with Saint Columba, who might have brought it from Ireland as a portable altar. In AD 574, the Stone was used as a coronation chair when Columba anointed and crowned Aedan King of Dalriada.\n\nThe Stone of Destiny was kept by the monks of Iona, the traditional headquarters of the Scottish Celtic church, until Viking raiding caused them to move to the mainland, first to Dunkeld, Atholl, and then to Scone. Here it continued to be used in coronations, as a symbol of Scottish Kingship.\n\nIn his attempts to conquer Scotland, Edward I of England invaded in 1296 at the head of an army. Sacking Berwick, beating the Scots at Dunbar, and laying siege to Edinburgh Castle, Edward then proceeded to Scone, intending to take the Stone of Destiny, which was kept at Scone Abbey. He had already taken the Scottish regalia from Edinburgh, which included Saint Margaret's Black Rood relic, but to confiscate an object so precious to the Scots, and so symbolic of their independence, would be a final humiliation. He carried it back to Westminster Abbey. By placing it within the throne of England, he had a potent symbol of his claim for overlordship. It is this stone which sat in Westminster until 1996, when it was returned to Scotland.\n\nAccording to the Westminster Stone theory, the stone Edward removed was not the real Stone of Destiny, but a substitute. The English army was at the Scottish border in mid-March, 1296, and did not reach Scone until June. With three months to anticipate Edward's arrival, there was ample time and incentive for a switch to be made, in order to protect the original relic. Such a substitution could have been instigated by the Abbot of Scone, who stood as custodian. The 'Stone of Destiny' could therefore have been transported to a place of safety, and Edward fobbed off with a different piece of sandstone.\n\nThere are many theories regarding the possible resting place of the 'True Stone' since, inspired by logical deduction and, in some cases, fantastical, wishful thinking.\n\nNigel Tranter believed the True Stone was originally hidden by the Abbot of Scone, and eventually entrusted to the care of Aonghus Óg Mac Domhnaill, by Robert the Bruce. Aonghus Óg hid it in his native Hebrides, where the stone probably remains.\n\nOne legend records that after the True Stone was given into the keeping of Aonghus Óg, its keepership passed into the branch of the clan who settled in Sleat. A descendant of this line, C. Iain Alasdair MacDonald, wrote to Tranter, claiming he was now the custodian of the Stone, which was hidden on Skye.\n\nIt has also been suggested that the stone was hidden by monks in the River Tay. One rumour claims that the stone is held by the Knights Templar. However, this rumour might apply to the .\n\n\n\"On the 19th of November, as the servants belonging to the West Mains of Dunsinane-house, were employed in carrying away stones from the excavation made among the ruins that point out the site of Macbeth's castle here, part of the ground they stood on suddenly gave way, and sank down about six feet, discovering a regularly built vault, about six feet long and four wide. None of the men being injured, curiosity induced them to clear out the subterranean recess, when they discovered among the ruins a large stone, weighing about 500l []. which is pronounced to be of the meteoric or semi-metallic kind. This stone must have lain here during the long series of ages since Macbeth's reign. Besides it were also found two round tablets, of a composition resembling bronze. On one of these two lines are engraved, which a gentleman has thus deciphered.— 'The sconce (or shadow) of kingdom come, until Sylphs in air carry me again to Bethel.' These plates exhibit the figures of targets for the arms. [...] The curious here, aware of such traditions, and who have viewed these venerable remains of antiquity, agree that Macbeth may, or rather must, have deposited the stone in question at the bottom of his Castle, on the hill of Dunsinane (from the trouble of the times), where it has been found by the workmen. This curious stone has been shipped for London for the inspection of the scientific amateur, in order to discover its real quality.\"\n\nThe Westminster Stone theory is not accepted by many historians, or those responsible for the care of the Stone. There are many strong arguments against the theory.\n\nOn Christmas Day 1950, the Westminster Stone was taken from the abbey by four Scottish students. It remained hidden until April 1951, when a stone was left in Arbroath Abbey. Some speculate that this stone is not the one taken from the Abbey, but merely a copy.\n\nThe stone left in Arbroath was damaged, for the Westminster Stone had broken in half when removed from the Coronation Chair, but had been repaired by Glasgow stonemason Robert Gray. However, Gray had made replicas of the Stone in the 1930s, and further fuelled speculation by declaring later that he did not know which stone had been sent back to London as \"there were so many copies lying around\".\n\nThis scenario receives support from a plaque placed in St Columba's Parish Church in Dundee, which claims to mark the site of the 'Stone of Scone', given to them in 1972 by 'Baillie Robert Gray'.\n\nThe apparent disrespect shown towards the Stone by Gray and the students is explained by Nigel Tranter, who had some claim to knowledge, as the students asked him to act as an intermediary after the removal of the stone. Tranter later stated that Gray inserted a note inside the Westminster Stone, when repairing it, to the effect that it was 'a block of Old Red Sandstone of no value to anyone', although other reports state that Gray never revealed what the note said.\n\nHowever, in the 1940s, the British Geological Survey, had carried out a survey of the Stone when the Coronation Chair was undergoing conservation work. The fault line had been noticed as well as the many marks and features of the Stone's surface. This allowed verification of the authenticity of the returned item.\n\nA scanray examination conducted by the Home Office Police Scientific Development Branch in 1973 confirmed the presence of 'three metal rods and sockets, one being at right angles to the other two'. This also indicated that the repaired Westminster Stone, not a replica, had been returned.\n\nThe apparent absence of thirteenth and fourteenth century Scottish mentions of the Stone of Scone, and their lack of reaction to Edward's theft, compared with the wealth of legends developed in later centuries, have given rise to the theory that the Stone of Scone was never a relic of great significance to the Scots, but 'talked up' by Edward as useful propaganda. By creating a relic which, in the popular eye of the English, endorsed his claim as 'Lord Paramount', he was making a shrewd political statement. By continuing to flaunt the stone in front of later generations of Scots, the hoax became a self-fulfilling taunt.\n\n"}
{"id": "49310912", "url": "https://en.wikipedia.org/wiki?curid=49310912", "title": "Ximenynic acid", "text": "Ximenynic acid\n\n\"Not to be confused with Ximenic acid, a 26 carbon omega-9 fatty acid.\"\nXimenynic acid is trans-11-octadecen-9-ynoic acid, a long-chain acetylenic fatty acid.\n\nIt was discovered in the fruit kernels of 3 South American ximenia species (and so named). and found to have the formula CHO.\n\nIt can be extracted from the fruit kernels of the Santalum obtusifolium (Sandalwood) and the Australian sandalwood Santalum spicatum\n\nIt is also found in seed oil of other plants in the Santalaceae family, including the native cherry Exocarpos cupressiformis and sweet quandong Santalum acuminatum.\n\nIt was the subject of a 2003 European patent (for use in food). The patent application was deemed withdrawn in August 2012.\n\nIt is used in some skincare products.\n"}
{"id": "40336877", "url": "https://en.wikipedia.org/wiki?curid=40336877", "title": "Yale Program on Climate Change Communication", "text": "Yale Program on Climate Change Communication\n\nThe Yale Program on Climate Change Communication (YPCCC) is a research center within the School of Forestry and Environmental Studies at Yale University that conducts scientific research on public climate change knowledge, attitudes, policy preferences, and behavior at the global, national, and local scales. It grew out of a conference held in Aspen, Colorado in 2005.\n\nAs of 2017 the program was led by Anthony Leiserowitz, and it put out a daily 90 second audio program carried by around 350 radio stations, articles in the media, and a series of videos published monthly, and provided training to help television weather presenters and reporters discuss climate change.\n\nIn 2017 the program was given a \"Friend of the Planet\" award by the National Center for Science Education in 2017. In 2018, Leiserowitz and YPCCC researchers received the Warren J. Mitofsky Innovators Award, given by the American Association for Public Opinion Research. The award recognized \"a new statistical method to downscale national public opinion estimates using multiple regression and post stratification (MPR) survey data collection methodology.\"\n"}
{"id": "35771637", "url": "https://en.wikipedia.org/wiki?curid=35771637", "title": "Zambia Forestry College", "text": "Zambia Forestry College\n\nThe Zambia Forestry College (ZFC) was established in 1949 to provide technical training in forestry. In the same year it produced the first forest guards.\n\nIn the following year, Forest Rangers were trained. The College has since been growing to cope with the changing demand for natural resource trained staff. By 1963, over 300 Forest Rangers (Certificate holders) and Forest Guards had been trained.\n\nTraining for Foresters (Diploma holders) commenced in 1963 with nine (9) students. By the end of 1977, 131 Foresters and one (1) female Forester completed her training successfully signifying that this field was gender friendly. The college has now been upgraded with equipment, facilities and staff.\n"}
